{"title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies", "authors": ["Harshit Joshi", "Shicheng Liu", "James Chen", "Robert Weigle", "Monica S. Lam"], "abstract": "Programming LLM-based knowledge and task assistants that faithfully conform to developer-provided policies is challenging. These agents must retrieve and provide consistent, accurate, and relevant information to address user's queries and needs. Yet such agents generate unfounded responses (\u201challucinate\"). Traditional dialogue trees can only handle a limited number of conversation flows, making them inherently brittle. To this end, we present KITA a programmable framework for creating task-oriented conversational agents that are designed to handle complex user interactions. Unlike LLMS, KITA provides reliable grounded responses, with controllable agent policies through its expressive specification, KITA Worksheet. In contrast to dialog trees, it is resilient to diverse user queries, helpful with knowledge sources, and offers ease of programming policies through its declarative paradigm. Through a real-user study involving 62 participants, we show that KITA beats the GPT-4 with function calling baseline by 26.1, 22.5, and 52.4 points on execution accuracy, dialogue act accuracy, and goal completion rate, respectively. We also release 22 real-user conversations with KITA manually corrected to ensure accuracy.", "sections": [{"title": "Introduction", "content": "Task-oriented dialog (TOD) agents that can interact with users to achieve some goal have many diverse applications, including customer support, financial services, and medical form-filling, and are of great interest to researchers and industry practitioners (Budzianowski et al., 2018; Amazon, 2023; Google, 2024). Helpful TOD agents must understand the user's requests, guide the conversations, and provide relevant information to users, with the help of different data sources or APIs.\nRecent research has successfully leveraged the In-Context Learning (ICL) ability of Large Lan-"}, {"title": "Related Works", "content": "A wide variety of commercial and open-sourced products (Amazon, 2023; Press, 2024; Xie et al., 2022; Google, 2024; Microsoft, 2022a,b; Reach, 2022; Bocklisch et al., 2017; Watson, 2022) exist that help developers program a conversational virtual assistant using dialogue trees, with slight differences in design. For instance, Press (2024); Google (2024); Microsoft (2022a); Reach (2022); Watson (2022) allow users to interactively program a dialogue tree with a graphical user interface. Developers can manipulate various building blocks that classify user intents, sometimes with the help of built-in NLU (natural language understanding) modules. RASA allows developers to declare a list of global intents and program linear conversational paths accordingly (Bocklisch et al., 2017). Converse allows developers to program a special kind of \"and-or\" trees (Xie et al., 2022).\nIn dialogue trees, developers explicitly program all possible dialogue turns and responses. The resulting dialogues are very structured and easily controllable. However, This leads to exponentially many possible dialogue paths, almost impossible to exhaust in real-life scenarios."}, {"title": "LLM and task-oriented dialogues", "content": "A series of recent works attempts to integrate LLMs with TOD, showing its capability in dialogue state tracking (Hu et al., 2022; Feng et al., 2023; Hude\u010dek and Dusek, 2023; Li et al., 2024; Zhang et al., 2023b). In particular, Li et al. (2024) uses GPT's function calling capability for state tracking, which we compare against in Section 6.\nWhen building end-to-end dialogue agents with LLMs, existing works typically feed the entire set of instructions to the model for response generation (Zhang et al., 2023b). While this works well on smaller domains, LLMs struggle to follow all instructions in real-life situations (Liu et al., 2024a), as we will demonstrate in Section 6. Recently, a popular framework Nemo-Guardrails (Rebedea et al., 2023), which allows programs to add \"guardrails\" to LLM-based conversational systems, has started to gain community attention. Operating under a simple trigger-action model, Nemo-Guardrails cannot handle multi-turn conversations where the dialogue state needs to be tracked, e.g., slot-fillings across multiple turns."}, {"title": "Design of the KITA Worksheet", "content": "Traditionally, task-oriented agents in NLP literature were designed as slot-filling frameworks. The users were prompted for specific values to fill predefined slots based on their utterances. These slots provide values to the parameters of API calls. However, slots are insufficient for capturing knowledge-oriented queries. Instead, formal representations or query languages should be used (Andreas et al., 2020; Lam et al., 2022; Liu et al., 2024b).\nContrary to dialog trees, we design KITA Worksheet as a high-level declarative specification, not too different from the information we would give to a human operator. It is designed to be read by our KITA agent to perform the given task. We describe the design goals along with the design below."}, {"title": "Design Objectives", "content": "Conditional inputs. Online tasks today are primarily implemented as webpages, with each website containing numerous pages. Users navigate the website by (1) choosing possible pages from a menu, which often opens up to more websites or (2) filling in requested fields iteratively. Suppose a user wants to report a lost coat. After they navigate the page for lost items, they need to report the flight information if it was lost on a plane and the"}, {"title": "The KITA Worksheet", "content": "The KITA Worksheet is a high-level declarative specification of a TOD agent task designed to achieve the above design objectives. A task specification consists of developer-defined types, knowledge corpus schemas, API calls, and a set of worksheets. A worksheet, inspired by the versatility of webforms, consists of a set of (potentially optional or conditional) typed inputs of interests and the"}, {"title": "Query Handling", "content": "As discussed above, the task includes the schemas of all knowledge bases to be used in the task. To keep track of the dialogues involving databases, we introduce a degenerate worksheet, the KB-Worksheet. Each query issued by the user will instantiate a KB-Worksheet automatically derived from the KB schema. The worksheet has the following fields: NL query: a string of the form answer(s), where s is the de-contextualized (i.e. self-contained) query in natural language. This is expected to be produced by the agent's semantic parser. SUQL query: the SUQL query associated with the NL query. KB result: the result of execut-"}, {"title": "Composition of Worksheets", "content": "Compositions of queries and APIs are supported by passing the result of an instance of a worksheet in as a field of another worksheet. For instance, the semantic parser translates \"I want to book an Italian restaurant in NYC for two on Valentine's day\u201d into 2 partially filled worksheets:\n1. A KB-worksheet w\u2081 instantiated from the restaurant schema, where NL query has value\nAnswer(SELECT * FROM restaurants\nWHERE 'italian' = ANY(cuisines)\nAND location = 'NYC';\")\n2. A worksheet w\u2082 instantiated from BookRestaurant where restaurant = w\u2081, date = \"02/14/2024\", and num_people=2."}, {"title": "The KITA Agent Design", "content": "Despite the impressive natural understanding capabilities of LLMs, they often struggle with maintaining relevant contextual information across longer conversations. This leads to hallucinated or fabricated values and repeating questions. To mitigate this, we use the KITA Worksheet to track the dialog state. Specifically, at each turn, the current state of the KITA Worksheet and the previous conversational turn are provided as input to both the LLM-based semantic parser and the response generator. This prevents the system from forgetting critical field values and inadvertently generating fictitious ones. Furthermore, to address the challenge of LLMs failing to solicit required parameters, we utilize a programmable agent policy that checks all the fields that need to be captured and suggests the next appropriate action.\nThe KITA agent has these 3 components: a contextual semantic parser that translates user utterance in the context of the dialogue, the agent policy, and the response generation as in Figure 3.\nContextual Semantic Parsing The contextual semantic parser translates the user utterance given the current dialogue state and generates the new"}, {"title": "Experiment: A Slot-Filling Task", "content": "Before we launch into the discussion of our real user study on 3 real-life applications, we perform a small comparison study on one of the more complex examples of a slot-based benchmark. We evaluate KITA on the banking domain of the StarV2 dataset (Zhao et al., 2023). We chose this domain because its program logic is relatively more complex than others, and existing agents perform poorly on it. AnyTOD (Zhao et al., 2023) has the SOTA result on StarV2. With KITA, the agent policy for the banking domain can be specified in 9 lines of code, as opposed to 31 lines in Any-TOD. We only provide three examples to the LLM-based semantic parser"}, {"title": "Evaluation with Real Users", "content": "We evaluate KITA across three distinct applications with varying requirements to demonstrate the expressiveness and context-handling capabilities."}, {"title": "Baseline", "content": "We compare our system against OpenAI's GPT-4-turbo, leveraging its functional calling abilities, which we call GPT-4(FC). This baseline closely follows Li et al. (2024). Each worksheet is defined as a function, and the worksheet-level instructions are provided in the function description. The high-level policies are provided in the system prompt. Moreover, we provide the baseline system with the ability to use the Answer() function for external knowledge access."}, {"title": "Applications", "content": "We build two visually identical systems for all the applications, one that uses KITA and the other uses GPT-4 (FC). All the KITA Worksheet are provided in Appendix C.\nRestaurant Reservation Making a restaurant reservation requires finding a suitable restaurant and providing booking information to complete a transaction. We use the real-life dataset containing restaurants from Yelp.com from Liu et al. (2024b).\nTicket Submission In this study, we aim to replicate a subset of tasks found within a university's student services portal. University student services portals typically contain various tasks categorized"}, {"title": "Evaluation Metrics", "content": "Semantic Parsing Accuracy For each user turn, we manually inspect the code generated by the semantic parser for correct APIs and Databases and filled fields. We define the gold Semantic Parsing output (SP) as the set of correct API calls (A), Database calls (D), and fields to fill (F). Then for each user utterance, SP = {s\u2081, s\u2082,..., s\u2098}, where si \u2208 {A\u222aD\u222aF} and m is the total number of choices, such that m = |A\u222aD\u222aF|. The Semantic Parsing Accuracy (SP Acc) for a system is defined as the number of correct choices in the semantic parser's output divided by m.\nExecution Accuracy We manually inspect each turn to check whether the agent executes the correct API and databases. For each agent turn, let the executions be E = {e\u2081, e\u2082,..., e\u2098} where e\u1d62 is an API or database call. We evaluate whether each e\u1d62 is a true positive or false positive. We calculate the Execution (Ex Acc) as the number of true positives divided by the number of true and false positives for all the execution calls in a conversation.\nAgent Dialogue Act Accuracy For each turn, we manually inspect whether the agent's dialogue act follows the policies provided by the developer . Formally, for each turn, we define a list of gold acts a\u2081, a\u2082,..., a\u2098 where a\u1d62 \u2208 A, all the possible agent dialogue acts. The Agent Dialogue Act Accuracy (DA Acc) for a system is defined as the number of correctly predicted actions divided by m. For GPT-4 (FC), we map its responses to the equivalent elements in the power set of all the possible actions.\nGoal Completion Rate We define Goal Completion Rate (Goal CR) as the user's ability to successfully complete the task with the system's assistance. with the appropriate parameter values, then the goal is considered completed. Goal Completion Rate is a binary metric for each conversation, where 1 denotes that the goal was completed, and 0 indicates that the goal was not achieved."}, {"title": "Evaluation Results", "content": "Table 2 compares KITA against GPT-4 (FC) across three metrics and find that KITA performs significantly better than GPT-4 (FC) on all three domains. We observe that KITA consistently demonstrates a high semantic parsing rate (exceeding 85%), indicating that KITA Worksheet is simple to understand for LLMs with few shot examples. The marginally lower SP Acc (85.8%) observed in the Ticket Submission application can be attributed to the application's complexity, featuring several worksheets (= 8) and API fields (= 28), as shown in Table 1. Additionally, the higher Ex Acc can be attributed to providing compressed context as a worksheet state, enabling the LLM to invoke the correct API and execute the suitable database query. The superior performance on DA Acc can be ascribed to our agent's capability to provide turn-by-turn instructions rather than presenting all the instructions at once, as is the case with GPT-4 (FC). The results validate the benefit of programmable policies in delivering a reliable assistant.\nIn terms of the final Goal Completion Rate, we observe that GPT-4 (FC) scores relatively higher in restaurant reservations, the domain it is most familiar with and well represented in existing dialogue datasets (Ye et al., 2022; Rastogi et al., 2020). Similar results are also observed by Zhang et al. (2023a) and Hude\u010dek and Dusek (2023). However, GPT 4 (FC) struggles with less familiar domains, like ticket submission and course enrollment. We"}, {"title": "Error Analysis", "content": "We analyze all the error cases for our system and GPT-4 (FC) and provide examples in the Appendix.\nGPT-4 (Function Calling) GPT 4 (FC) fails to use the provided Answer() function and responds directly to user queries, leading to fictitious responses. We note that it hallucinates in (7/10), (4/11), and (5/10) conversations for course enrollment, ticket submission, and restaurant reservation domains. Moreover, it prematurely invokes the submission API in all three domains and disregards instructions such as failing to seek confirmation before invoking API's. More error analysis is Appendix E.\nKITA We analyze errors in the Ticket Submission application. In 21% of the cases, the agent fails to handle cases where the user refuses to provide information for a required field, resulting in an unassigned value. Another 21% of errors stem from the semantic parser's inability to call all the necessary worksheets or populate the correct parameter values. 43% of errors were due to incorrect usage of Answer() function, either by using it incorrectly to query knowledge sources or by neglecting to use it altogether. In another 14% of errors, the LLM-based parser failed to initiate a new worksheet when the user attempted to start a new transaction and instead updated an existing worksheet.\nWe also observe that 33% and 66% errors in semantic parsing are due to creating erroneous worksheets or incorrect fields for Course Enrollment and Restaurant Reservation assistant. On the other hand, there are 66% and 33% errors due to incorrect usage of Answer()."}, {"title": "Conclusion", "content": "We introduce KITA, a novel framework for building knowledge-integrated task assistants with LLMs, with KITA Worksheet, a high-level specification that allows for detailed control over conversation flows. Our real user studies with 62 participants demonstrate KITA drastically outperforms traditional LLM-based systems and dialogue trees.The accompanying dataset with 180 dialogue turns pro-"}, {"title": "Limitation", "content": "As an LLM-based system, KITA's performance is directly tied to the capability of the underlying LLM. The non-deterministic nature of Language Models can also lead to performance variations across different runs.\nBeing a programmable framework, the performance of KITA is influenced by the specific policies implemented by developers for new domains. The selection of few-shot examples is also expected to impact the agent's performance. To address this, we will provide comprehensive guidelines and tools for developers to create effective policies and select optimal few-shot examples in our release.\nWe acknowledge that the additional intermediate LLM calls introduced by KITA will lead to higher costs and increased latency. However, we believe these trade-offs are necessary to deliver a reliable and accurate integrated task and knowledge assistant."}, {"title": "Ethical Considerations", "content": "Large Language Models have been increasingly utilized to build various task-oriented agents. We propose a novel method to enhance their accuracy and reliability. We do not anticipate any harm resulting from this work.\nFor the user evaluation of the Course Enrollment application, we recruited university students who voluntarily participated in the study, awarding each participant an Amazon gift card worth $10 per 15 minutes. For the Restaurant Reservation and Ticket Submission applications, we used the Prolific platform to recruit participants and compensated them fairly, beyond the minimum wage. Our procedure has been approved by the Institutional Review Board (IRB) at our institution. All collected information is anonymous. We also remove any personal identifiable information from the collected dialogues.\nOur code will be released publicly under the Apache License, Version 2.0, and the collected data will be made available to the community."}, {"title": "Experimental Settings", "content": "We used OpenAI's GPT 4-turbo for semantic parsing and response generation. The underlying SUQL system uses GPT 3-turbo. All the experiments were performed before June 15, 2024. The semantic parser uses a temperature of 0.0, and the response generation module uses a temperature of 0.7."}, {"title": "User Study", "content": "We use the same user interface for KITA and GPT 4 (FC) as shown in Figure 6"}]}