{"title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies", "authors": ["Harshit Joshi", "Shicheng Liu", "James Chen", "Robert Weigle", "Monica S. Lam"], "abstract": "Programming LLM-based knowledge and task assistants that faithfully conform to developer-provided policies is challenging. These agents must retrieve and provide consistent, accurate, and relevant information to address user's queries and needs. Yet such agents generate unfounded responses (\"hallucinate\"). Traditional dialogue trees can only handle a limited number of conversation flows, making them inherently brittle. To this end, we present KITA a programmable framework for creating task-oriented conversational agents that are designed to handle complex user interactions. Unlike LLMS, KITA provides reliable grounded responses, with controllable agent policies through its expressive specification, KITA Worksheet. In contrast to dialog trees, it is resilient to diverse user queries, helpful with knowledge sources, and offers ease of programming policies through its declarative paradigm. Through a real-user study involving 62 participants, we show that KITA beats the GPT-4 with function calling baseline by 26.1, 22.5, and 52.4 points on execution accuracy, dialogue act accuracy, and goal completion rate, respectively. We also release 22 real-user conversations with KITA manually corrected to ensure accuracy.", "sections": [{"title": "Introduction", "content": "Task-oriented dialog (TOD) agents that can interact with users to achieve some goal have many diverse applications, including customer support, financial services, and medical form-filling, and are of great interest to researchers and industry practitioners (Budzianowski et al., 2018; Amazon, 2023; Google, 2024). Helpful TOD agents must understand the user's requests, guide the conversations, and provide relevant information to users, with the help of different data sources or APIs.\nRecent research has successfully leveraged the In-Context Learning (ICL) ability of Large Lan-guage Models (LLMs) to develop zero-shot and few-shot task-oriented dialogue agents, achieving superior results to fine-tuning pretrained models (Hude\u010dek and Du\u0161ek, 2023; Zhang et al., 2023a). Furthermore, the function-calling capability of LLMs now allows them to invoke provided functions and use their outputs to assist in task completion (Patil et al., 2023; Kim et al., 2023). However, despite these strengths, LLM's capabilities present critical limitations that hinder their application in task-oriented systems. Notably, they are unreliable and prone to generating misleading information, or \u201challucinations\u201d, often using convincing and confident language (Bang et al., 2023). Moreover, even with function-calling, LLMs offer minimal control to TOD agent developers over the dialogue flow, making it challenging to manage interactions with users. Although complex instructions can be added to the prompts, as instructions accumulate, LLMs struggle to maintain consistent attention across all directives, often neglecting some (Liu et al., 2024a), resulting in unreliable behavior.\nWhile dialogue trees can offer explicit control and reliability over the conversations for task-oriented tasks, they are inherently brittle. Dialogue flows must be explicitly hard-coded, making it infeasible to cover the all the exponentially many possible dialogues. Furthermore, dialogue trees are very limited in addressing subsequent user inquiries, as their rigid framework impedes the integration of diverse data sources and the utilization of knowledge assistants. This makes using dialogue trees for unified tasks and knowledge assistants exceptionally challenging.\nTo this end, we present KITA, an open-domain LLM-based Knowledge Integrated with Tasks Assistant. We propose a novel specification, KITA Worksheet that provides explicit control to the TOD agent developer through programmable policies to manage dialogue flow and deliver high-level support for integrated knowledge assistants. KITA Worksheet enables programming policies in the declarative paradigm, in contrast to the much more complex imperative approach employed by dialogue trees. KITA Worksheets can express a variety of real-world tasks, ranging from restaurant booking assistants that require hybrid knowledge retrieval capabilities to handling complex workflows as encapsulated in web pages.\nMoreover, KITA can facilitate the composition of tasks and knowledge queries. As illustrated in Figure 1, the user asks to book an Italian restaurant in NYC for two on Valentine's Day. Our agent uses a few-shot LLM-based semantic parser to understand users' queries and translate them into a composition of API invocation (BookRestaurant) and knowledge query (Answer) with a succinct Python-like syntax. The agent policy maintains the dialogue state, executes actions, and proposes the subsequent dialog acts. Finally, the response generator uses the dialogue state and dialog acts to generate a response to the user's initial query.\nWe present the following contributions:"}, {"title": "Related Works", "content": "2.1 Dialogue Tree-based frameworks\nA wide variety of commercial and open-sourced products (Amazon, 2023; Press, 2024; Xie et al., 2022; Google, 2024; Microsoft, 2022a,b; Reach, 2022; Bocklisch et al., 2017; Watson, 2022) exist that help developers program a conversational virtual assistant using dialogue trees, with slight differences in design. For instance, Press (2024); Google (2024); Microsoft (2022a); Reach (2022); Watson (2022) allow users to interactively program a dialogue tree with a graphical user interface. Developers can manipulate various building blocks that classify user intents, sometimes with the help of built-in NLU (natural language understanding) modules. RASA allows developers to declare a list of global intents and program linear conversational paths accordingly (Bocklisch et al., 2017). Converse allows developers to program a special kind of \"and-or\" trees (Xie et al., 2022).\nIn dialogue trees, developers explicitly program all possible dialogue turns and responses. The resulting dialogues are very structured and easily controllable. However, This leads to exponentially many possible dialogue paths, almost impossible to exhaust in real-life scenarios.\n2.2 LLM and task-oriented dialogues\nA series of recent works attempts to integrate LLMs with TOD, showing its capability in dialogue state tracking (Hu et al., 2022; Feng et al., 2023; Hude\u010dek and Dusek, 2023; Li et al., 2024; Zhang et al., 2023b). In particular, Li et al. (2024) uses GPT's function calling capability for state tracking, which we compare against in Section 6.\nWhen building end-to-end dialogue agents with LLMs, existing works typically feed the entire set of instructions to the model for response generation (Zhang et al., 2023b). While this works well on smaller domains, LLMs struggle to follow all instructions in real-life situations (Liu et al., 2024a), as we will demonstrate in Section 6. Recently, a popular framework Nemo-Guardrails (Rebedea et al., 2023), which allows programs to add \"guardrails\" to LLM-based conversational systems, has started to gain community attention. Operating under a simple trigger-action model, Nemo-Guardrails cannot handle multi-turn conversations where the dialogue state needs to be tracked, e.g., slot-fillings across multiple turns."}, {"title": "Design of the KITA Worksheet", "content": "Traditionally, task-oriented agents in NLP literature were designed as slot-filling frameworks. The users were prompted for specific values to fill pre-defined slots based on their utterances. These slots provide values to the parameters of API calls. However, slots are insufficient for capturing knowledge-oriented queries. Instead, formal representations or query languages should be used (Andreas et al., 2020; Lam et al., 2022; Liu et al., 2024b).\nContrary to dialog trees, we design KITA Worksheet as a high-level declarative specification, not too different from the information we would give to a human operator. It is designed to be read by our KITA agent to perform the given task. We describe the design goals along with the design below.\n3.1 Design Objectives\nConditional inputs. Online tasks today are primarily implemented as webpages, with each website containing numerous pages. Users navigate the website by (1) choosing possible pages from a menu, which often opens up to more websites or (2) filling in requested fields iteratively. Suppose a user wants to report a lost coat. After they navigate the page for lost items, they need to report the flight information if it was lost on a plane and the terminal if it was lost at the terminal, etc. It is not a single API call with a fixed set of parameters.\nProgrammable Agent Policy. Task-oriented agents not only just passively execute user commands but have their own objectives. For example, after a user books a flight, the agent may wish to offer the chance to book a rental car at a discount. Or, if the user is checking into a flight that is known to be delayed, the agent should inform the user. In other words, developers need to have the ability to code the agent policy in terms of actions to take and information to be supplied to the user. To ensure control, ease of development, and quick updates, it is important to let developers specify the policy rather than training a neural policy via dialogue training samples.\nComposition of APIs and queries. We observe that a single user utterance can combine parameters for an API with queries, suggesting that we need to support full compositionality between APIs and queries. Consider the following example:\nExample 1: A restaurant reservation agent may start by asking the user:\nAgent: \"Hi, I am the restaurant reservation assistant. Which restaurant would you like to book?\u201d.\nA traditional TOD system would expect the user's response to directly provide a restaurant name to fill the corresponding slot. However, users often do not know which restaurant they want, but may however offer characteristics of the restaurants they want to book as well as details for the reservation. For example:\nUser: \"I want to book an Italian restaurant in NYC for two on Valentine's day\u201d.\nHere, the result of the query (Restaurant) is supplied as an argument to a task (BookRestaurant). Moreover, agents must record all the relevant parameters in the dialogue state. This example highlights how users can respond to a system's question with another query while simultaneously providing information about other relevant task parameters.\n3.2 The KITA Worksheet\nThe KITA Worksheet is a high-level declarative specification of a TOD agent task designed to achieve the above design objectives. A task specification consists of developer-defined types, knowledge corpus schemas, API calls, and a set of worksheets. A worksheet, inspired by the versatility of webforms, consists of a set of (potentially optional or conditional) typed inputs of interests and the arbitrary actions to take.\nA worksheet, as illustrated in Figure 2, has a name (WS Name), a predicate (WS Predicate) indicating when it is activated, and a set of fields. The top-level worksheet is unconditionally executed, and the rest of the worksheets are activated if their corresponding predicates are true. Each field has these attributes:\n\u2022 Predicate: whether the field is active\n\u2022 Input: whether the field is an input or an internal value, the latter is computed rather than solicited from the user\n\u2022 Type: if the type is \u201cEnum", "Enum Values\" field\n\u2022 Name": "the field name\n\u2022 Description: a natural language description\n\u2022 Don't Ask: if true, the agent saves the information if offered by the user, but does not solicit it. An example of such a field could be: \"Is the user annoyed?\u201d. In this case, the system won't explicitly ask the user if they are annoyed; however, if the user mentions that they are, the value can be set to True.\n\u2022 Required: if true, solicits the user for a value\n\u2022 Confirmation: if true, confirms the value with the user, which is useful if an undesirable side effect can result from a mistaken value.\n\u2022 Actions: code (in Python) to be executed whenever a value is assigned to the variable.\nFinally, each worksheet also has a WS actions field, where the developer can provide Python code to be executed when all the required fields are filled. Several built-in actions are provided to the developer: (1) say (str) responds to the user with the given string str. (2) propose (ws, [fld,val]*) instantiates a new worksheet ws with the given field value pairs.\nWorksheets do not just specify the information to be gathered, they are also used to keep track of the user supplied values in the dialogue so far. For example, if the users book two restaurants, then the dialogue history will be represented by 2 different instances of the BookRestaurant worksheet.\nIn Figure 2, we illustrate a KITA Worksheet created for the ticket submission agent, with two worksheets and schema for free-text corpus (in a darker shade). The first worksheet is the main worksheet, which needs to be submitted using submit_ticket API. It is denoted by WS under the Type column. This worksheet has no predicate, meaning it can be updated by the user or the agent at any time.\n3.3 Query Handling\nAs discussed above, the task includes the schemas of all knowledge bases to be used in the task. To keep track of the dialogues involving databases, we introduce a degenerate worksheet, the KB-Worksheet. Each query issued by the user will instantiate a KB-Worksheet automatically derived from the KB schema. The worksheet has the following fields: NL query: a string of the form answer(s), where s is the de-contextualized (i.e. self-contained) query in natural language. This is expected to be produced by the agent's semantic parser. SUQL query: the SUQL query associated with the NL query. KB result: the result of executing the SUQL query.\nThe action associated with the NL query field is to invoke the SUQL parser to convert the NL query into SUQL. The action with the SUQL query is to execute the query if all the required parameters are available.\n3.4 Composition of Worksheets\nCompositions of queries and APIs are supported by passing the result of an instance of a worksheet in as a field of another worksheet. For instance, the semantic parser translates \"I want to book an Italian restaurant in NYC for two on Valentine's day\u201d into 2 partially filled worksheets:\n1.  A KB-worksheet $w_1$ instantiated from the restaurant schema, where NL query has value\n`Answer (SELECT * FROM restaurants WHERE 'italian' = ANY (cuisines) AND location = 'NYC';"}, {"title": "The KITA Agent Design", "content": "Despite the impressive natural understanding capabilities of LLMs, they often struggle with maintaining relevant contextual information across longer conversations. This leads to hallucinated or fabricated values and repeating questions. To mitigate this, we use the KITA Worksheet to track the dialog state. Specifically, at each turn, the current state of the KITA Worksheet and the previous conversational turn are provided as input to both the LLM-based semantic parser and the response generator. This prevents the system from forgetting critical field values and inadvertently generating fictitious ones. Furthermore, to address the challenge of LLMs failing to solicit required parameters, we utilize a programmable agent policy that checks all the fields that need to be captured and suggests the next appropriate action.\nThe KITA agent has these 3 components: a contextual semantic parser that translates user utterance in the context of the dialogue, the agent policy, and the response generation as in Figure 3.\nContextual Semantic Parsing The contextual semantic parser translates the user utterance given the current dialogue state and generates the new dialogue state. Our active and completed worksheets are a complete encapsulation of information relevant for understanding the next user statement. Thus, they are used as formal context rather than the complete history of utterances.\nThe output of the parser is an updated set of worksheets. The user may (1) supply values to fields that are anticipated in existing worksheets; (2) modify a previously filled field or even remove its value; (3) initiate new tasks or queries. In the last case, new worksheets will be created.\nAgent Policy The agent policy module interprets the state of the worksheet to determine its actions. The agent can communicate with the user through a set of 5 agent dialogue acts (Figure 4). The policy execution consists of the following steps:\n1.  If there are new database queries, the agent policy follows the actions on the instantiated KB-worksheets. A new NL query is translated into an SUQL query using the SUQL parser; if required parameters are missing, the agent policy uses the AskAct policy to ask users for the missing values. If the SUQL query is ready to be executed, it saves the returned result in the KB-worksheet.\n2.  Results of these databases are reported using the ReportAct.\n3.  It examines all the newly populated fields in the order in the worksheet. If the field is indicated as requiring confirmation, it issues the ConfirmationAct action. Otherwise, execute any associated developer-defined actions that need no confirmation, or for which confirmation has been received.\n4.  After all the newly filled fields are processed, the agent policy finds the first unfilled field and invokes the AskAct on it.\n5.  If all the required fields are filled and all their corresponding actions are completed, then execute the developer-defined action associated with the entire worksheet.\n6.  If the worksheet's result is used as an input field in other worksheets, assign its value to such fields.\nResponse Generator All the dialogue acts produced by the agent policy are supplied to the generator, along with new KITA Worksheet state to generate a helpful response to the user."}, {"title": "Experiment: A Slot-Filling Task", "content": "Before we launch into the discussion of our real user study on 3 real-life applications, we perform a small comparison study on one of the more complex examples of a slot-based benchmark. We evaluate KITA on the banking domain of the StarV2 dataset (Zhao et al., 2023). We chose this domain because its program logic is relatively more complex than others, and existing agents perform poorly on it. AnyTOD (Zhao et al., 2023) has the SOTA result on StarV2. With KITA, the agent policy for the banking domain can be specified in 9 lines of code, as opposed to 31 lines in Any-TOD. We only provide three examples to the LLM-based semantic parser; AnyTOD finetunes T5XXL (13B) model on all domains except the one tested. ToD achieves a weighted System action F1 (SaF1) of 65; KITA achieves an impressive weighted SaF1 of 83 on a randomly sampled subset of 100 conversations from the banking domain. Furthermore, our analysis indicates that most of our errors are caused by inconsistent annotations in the dataset. (Worksheet, error description, and other experimental details are present in Appendix C)."}, {"title": "Evaluation with Real Users", "content": "We evaluate KITA across three distinct applications with varying requirements to demonstrate the expressiveness and context-handling capabilities.\n6.1 Baseline\nWe compare our system against OpenAI's GPT-4-turbo, leveraging its functional calling abilities, which we call GPT-4 (FC). This baseline closely follows Li et al. (2024). Each worksheet is defined as a function, and the worksheet-level instructions are provided in the function description. The high-level policies are provided in the system prompt. Moreover, we provide the baseline system with the ability to use the Answer() function for external knowledge access.\n6.2 Applications\nWe build two visually identical systems for all the applications, one that uses KITA and the other uses GPT-4 (FC). All the KITA Worksheet are provided in Appendix C.\nRestaurant Reservation Making a restaurant reservation requires finding a suitable restaurant and providing booking information to complete a transaction. We use the real-life dataset containing restaurants from Yelp.com from Liu et al. (2024b).\nTicket Submission In this study, we aim to replicate a subset of tasks found within a university's student services portal. University student services portals typically contain various tasks categorized under different sections and subsections, posing a navigational challenge for students seeking to locate the appropriate link. Moreover, these portals often contain a vast corpus of free-text data, which students must peruse before submitting a ticket. We evaluated agents' capability to handle nested webpages with predicates and subsequent actions.\nCourse Enrollment Finally, we evaluate the performance of KITA as a course enrollment assistant, which combines hybrid data sources to search for course details and fill out complicated nested forms. The assistants allow students to ask questions about course requirements, student reviews, and ratings while filling out their enrollment forms. We collect a real-life dataset containing courses from the Computer Science program, with 4 tables (courses, offerings, ratings, and programs).\nStudy Design: We use Prolific to recruit 22 participants for Restaurant Reservations and 20 users who identified as students for Ticket Submission. We recruited 20 university students to evaluate the Course Enrollment assistant. We instructed them to attempt to book a reservation, submit an issue ticket, and enroll in two courses, respectively. We randomly assigned users to one of the two systems. In total, we collected 99, 81, and 127 turns with KITA, and 90, 70, and 144 turns with With GPT 4 (FC), respectively. More details on instructions provided to the users are in Appendix B.\n6.3 Evaluation Metrics\nSemantic Parsing Accuracy For each user turn, we manually inspect the code generated by the semantic parser for correct APIs and Databases and filled fields. We define the gold Semantic Parsing output (SP) as the set of correct API calls (A), Database calls (D), and fields to fill (F). Then for each user utterance, SP = {$s_1, s_2, \u2026, s_m$}, where $s_i \u2208 {A \u222a D \u222a F}$ and m is the total number of choices, such that $m = |A \u222a D \u222a F|$. The Semantic Parsing Accuracy (SP Acc) for a system is defined as the number of correct choices in the semantic parser's output divided by m.\nExecution Accuracy We manually inspect each turn to check whether the agent executes the correct API and databases. For each agent turn, let the executions be $E = {e_1, e_2, ..., e_m}$ where $e_i$ is an API or database call. We evaluate whether each $e_i$ is a true positive or false positive. We calculate the Execution (Ex Acc) as the number of true positives divided by the number of true and false positives for all the execution calls in a conversation.\nAgent Dialogue Act Accuracy For each turn, we manually inspect whether the agent's dialogue act follows the policies provided by the developer . Formally, for each turn, we define a list of gold acts $a_1, a_2,..., a_m$ where $a_i \u2208 A$, all the possible agent dialogue acts. The Agent Dialogue Act Accuracy (DA Acc) for a system is defined as the number of correctly predicted actions divided by m. For GPT-4 (FC), we map its responses to the equivalent elements in the power set of all the possible actions.\nGoal Completion Rate We define Goal Completion Rate (Goal CR) as the user's ability to successfully complete the task with the system's assistance. with the appropriate parameter values, then the goal is considered completed. Goal Completion Rate is a binary metric for each conversation, where 1 denotes that the goal was completed, and 0 indicates that the goal was not achieved."}, {"title": "Evaluation Results", "content": "7.1 User Studies\nTable 2 compares KITA against GPT 4 (FC) across three metrics and find that KITA performs significantly better than GPT-4 (FC) on all three domains. We observe that KITA consistently demonstrates a high semantic parsing rate (exceeding 85%), indicating that KITA Worksheet is simple to understand for LLMs with few shot examples. The marginally lower SP Acc (85.8%) observed in the Ticket Submission application can be attributed to the application's complexity, featuring several worksheets (= 8) and API fields (= 28), as shown in Table 1. Additionally, the higher Ex Acc can be attributed to providing compressed context as a worksheet state, enabling the LLM to invoke the correct API and execute the suitable database query. The superior performance on DA Acc can be ascribed to our agent's capability to provide turn-by-turn instructions rather than presenting all the instructions at once, as is the case with GPT-4 (FC). The results validate the benefit of programmable policies in delivering a reliable assistant.\nIn terms of the final Goal Completion Rate, we observe that GPT-4 (FC) scores relatively higher in restaurant reservations, the domain it is most familiar with and well represented in existing dialogue datasets (Ye et al., 2022; Rastogi et al., 2020). Similar results are also observed by Zhang et al. (2023a) and Hude\u010dek and Dusek (2023). However, GPT 4 (FC) struggles with less familiar domains, like ticket submission and course enrollment. We observe that the higher number of predicates, necessitating several instructions in the Ticket Submission application, makes it extremely challenging for GPT-4 (FC) to assist users in completing their tasks effectively. In most cases, GPT-4 (FC) does not elicit all the required fields from the user, hence making incomplete API calls. Moreover, despite having access to the Answer() function, GPT-4 (FC) often hallucinates non-existent courses and fails to enroll students.\nOn the contrary, we observe that KITA facilitates accurately completing and achieving their goals. We note that KITA effectively aids the users in completing their tasks (\u2265 80%) in both the Restaurant Reservation and Ticket Submission applications. For the Course Enrollment assistant, we observe that users who could not complete the task abandoned the conversation prematurely. In most cases, this is due to the database not having enough information to answer the query. Nonetheless, KITA still drastically outperforms GPT-4 (FC), which uses the same database.\n7.2 Error Analysis\nWe analyze all the error cases for our system and GPT-4 (FC) and provide examples in the Appendix.\nGPT-4 (Function Calling) GPT 4 (FC) fails to use the provided Answer() function and responds directly to user queries, leading to fictitious responses. We note that it hallucinates in (7/10), (4/11), and (5/10) conversations for course enrollment, ticket submission, and restaurant reservation domains. Moreover, it prematurely invokes the submission API in all three domains and disregards instructions such as failing to seek confirmation before invoking API's. More error analysis is Appendix E.\nKITA We analyze errors in the Ticket Submission application. In 21% of the cases, the agent fails to handle cases where the user refuses to provide information for a required field, resulting in an unassigned value. Another 21% of errors stem from the semantic parser's inability to call all the necessary worksheets or populate the correct parameter values. 43% of errors were due to incorrect usage of Answer() function, either by using it incorrectly to query knowledge sources or by neglecting to use it altogether. In another 14% of errors, the LLM-based parser failed to initiate a new worksheet when the user attempted to start a new transaction and instead updated an existing worksheet.\nWe also observe that 33% and 66% errors in semantic parsing are due to creating erroneous worksheets or incorrect fields for Course Enrollment and Restaurant Reservation assistant. On the other hand, there are 66% and 33% errors due to incorrect usage of Answer()."}, {"title": "Conclusion", "content": "We introduce KITA, a novel framework for building knowledge-integrated task assistants with LLMs, with KITA Worksheet, a high-level specification that allows for detailed control over conversation flows. Our real user studies with 62 participants demonstrate KITA drastically outperforms traditional LLM-based systems and dialogue trees.The accompanying dataset with 180 dialogue turns pro-vides a resource for further research and underscores the practical applicability of our approach.\nLimitation\nAs an LLM-based system, KITA's performance is directly tied to the capability of the underlying LLM. The non-deterministic nature of Language Models can also lead to performance variations across different runs.\nBeing a programmable framework, the performance of KITA is influenced by the specific policies implemented by developers for new domains. The selection of few-shot examples is also expected to impact the agent's performance. To address this, we will provide comprehensive guidelines and tools for developers to create effective policies and select optimal few-shot examples in our release.\nWe acknowledge that the additional intermediate LLM calls introduced by KITA will lead to higher costs and increased latency. However, we believe these trade-offs are necessary to deliver a reliable and accurate integrated task and knowledge assistant.\nEthical Considerations\nLarge Language Models have been increasingly utilized to build various task-oriented agents. We propose a novel method to enhance their accuracy and reliability. We do not anticipate any harm resulting from this work.\nFor the user evaluation of the Course Enrollment application, we recruited university students who voluntarily participated in the study, awarding each participant an Amazon gift card worth $10 per 15 minutes. For the Restaurant Reservation and Ticket Submission applications, we used the Prolific platform to recruit participants and compensated them fairly, beyond the minimum wage. Our procedure has been approved by the Institutional Review Board (IRB) at our institution. All collected information is anonymous. We also remove any personal identifiable information from the collected dialogues.\nOur code will be released publicly under the Apache License, Version 2.0, and the collected data will be made available to the community."}]}