{"title": "SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models", "authors": ["Yi Wu", "Zikang Xiong", "Yiran Hu", "Shreyash S. Iyengar", "Nan Jiang", "Aniket Bera", "Lin Tan", "Suresh Jagannathan"], "abstract": "Despite significant advancements in large language models (LLMs) that enhance robot agents' understanding and execution of natural language (NL) commands, ensuring the agents adhere to user-specified constraints remains challenging, particularly for complex commands and long-horizon tasks. To address this challenge, we present three key insights, equivalence voting, constrained decoding, and domain-specific fine-tuning, which significantly enhance LLM planners' capability in handling complex tasks. Equivalence voting ensures consistency by generating and sampling multiple Linear Temporal Logic (LTL) formulas from NL commands, grouping equivalent LTL formulas, and selecting the majority group of formulas as the final LTL formula. Constrained decoding then uses the generated LTL formula to enforce the autoregressive inference of plans, ensuring the generated plans conform to the LTL. Domain-specific fine-tuning customizes LLMs to produce safe and efficient plans within specific task domains. Our approach, Safe Efficient LLM Planner (SELP), combines these insights to create LLM planners to generate plans adhering to user commands with high confidence. We demonstrate the effectiveness and generalizability of SELP across different robot agents and tasks, including drone navigation and robot manipulation. For drone navigation tasks, SELP outperforms state-of-the-art planners by 10.8% in safety rate (i.e., finishing tasks conforming to NL commands) and by 19.8% in plan efficiency. For robot manipulation tasks, SELP achieves 20.4% improvement in safety rate. Our datasets for evaluating NL-to-LTL and robot task planning will be released in github.com/lt-asset/selp.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements in large language models have significantly improved robots' abilities to understand and plan given natural language commands [1]\u2013[3]. This breakthrough substantially broadens the scope of tasks that robots can autonomously perform with high adaptability across various domains such as autonomous driving [4], robotics task and motion planning [2,5,6], and human-robot collaboration [7]. For example, LLM planners can interpret a command such as \"cook a steak and then wash the pan\", and seamlessly organize this into a plan for cooking followed by cleaning. Combined with prompt-based techniques such as in-context learning and chain-of-thoughts reasoning [2, 8]\u2013[10], LLM planners bring improvements on multiple planning tasks.\nDespite these progresses, LLM planners reach their performance limits as the complexity of commands increases [8]-\n[10]. This complexity manifests in different dimensions:\ncommands may involve intricate logical dependencies with multiple pre- and post-conditions, or tasks may span long time horizons, requiring flawless execution at each step.\nTypically, to evaluate a planner's ability to handle complex tasks, two critical metrics are considered: safety, defined as the planner's compliance with given commands, and efficiency, measured as the time at which a robot completes a task. With increasingly more complex commands, existing LLM planners produce more unsafe and inefficient plans, preventing them from being applied to complex or real-world domains. Fig. 1 shows an example where the user requires the drone to visit rooms with some constraints on the visiting order. GPT-4 generates an unsafe plan (shown in the purple block) that disobeys the constraints.\nAnother challenge appears when fine-tuning LLM plan- ners with safety and efficiency objectives. These objectives can sometimes conflict, making it difficult for a model to learn to balance them. Safety often requires conservative planning, incorporating redundancies, and thorough checks to avoid errors, which can lead to longer execution times and lower efficiency. On the other hand, optimizing for efficiency typically involves minimizing the number of steps and the time taken to complete a task, which can increase the risk of unsafe plans.\nSELP effectively addresses these limitations. Similar to the existing technique [11], SELP starts with translating NL into a set of LTL specifications as an intermediate represen- tation. However, SELP provides confidence in the correct- ness of these LTL specifications with a equivalence voting mechanism, which checks the logical equivalence of LTL specifications and selects the majority as the specification. The key observation is that an LLM with over 50% accuracy in generating correct LTL specifications can provide high confidence in correctness through majority voting. Then, SELP directly uses the majority of LTL specification for constrained decoding on an LLM planner [2, 8]-[10]. The constrained decoding translates LTL specifications into a B\u00fcchi automaton that monitors and masks inconsistent to- kens, enforcing the LLM to resample until the plan conforms to the given specifications. Finally, we fine-tune the LLM to boost both efficiency and safety. For the same example in Fig. 1, SELP produces a safe plan (green box), which is also efficient during simulation (the green trajectory in (c)) with 34.85% less execution time.\nIn summary, this paper makes the following contributions:\n\u2022 We propose an equivalence voting mechanism to in- crease confidence in generating correct LTL specifica- tions from natural language."}, {"title": "II. RELATED WORK", "content": "LLM Agents for Robotics: LLMs have shown promising capabilities in robotics scenarios when tasked with agent planning [3,12]-[15]. Recent work [2, 16] applies LLMs for planning with robotic affordances and [1,3, 17] contribute their novel formulations of using LLMs to generate Python code as robot plans. A closely related approach to this work is Safety-Chip [11], which proposes a safety constraint mod- ule to monitor action sequences generated by LLMs using LTL automata. If an action is unsafe, Safety-Chip re-prompts the LLM to analyze and regenerate an action. In contrast, we employ constrained decoding to effectively prune unsafe actions by directly modifying LLMs' probability distribution. Additionally, we enhance the LLM's planning capability through training rather than relying solely on prompting. [18] uses LLMs to generate Signal Temporal Logic (STL) and then employs a solver-based STL planner to generate trajectories, while our work focuses on developing learning- based LLM planner. Other approaches [19, 20] convert NL to Planning Domain Definition Language (PDDL) as input for classic planners to generate plans. However, directly using PDDL to solve planning problems limits the ability to improve plan efficiency through fine-tuning and struggles to scale to long-horizon, logic-complex planning problems due to the inherent computational complexity of PDDL solvers.\nTranslating NL to LTL: Efforts to convert NL into LTL span from traditional recurrent neural network [21]\u2013 [23] to latest works based on LLMs [24]-[26]. However, two common challenges were the contamination of the training or testing datasets with noise and the decreased performance with the increased complexity of NL or LTL. Our strategy resolves these problems by employing LTL grammar and the paraphrasing capabilities of LLMs to create more semanti- cally diverse and complex datasets, enabling more efficient training of LTL translation."}, {"title": "III. PRELIMINARIES", "content": "Linear Temporal Logic: Robotic systems frequently em- ploy LTL to formalize complex motion plans and verify task execution [27]-[29]. The grammar of LTL specification is defined recursively as:\n$\\varphi := \\alpha | \\neg \\varphi | \\varphi \\wedge \\varphi | \\varphi V \\varphi | X\\varphi|G\\varphi|F\\varphi|\\varphi U \\varphi$ (1)\nHere, a is an atomic proposition mapping an environment state to a Boolean value. Standard logical operators include \u00ac (negation), \u2227 (conjunction), V (disjunction), and \u2192 (im- plication). Temporal operators are X (next), G (globally), F (eventually), and U (until).\nB\u00fcchi Automaton: Every LTL formula can be represented as a B\u00fcchi automaton $B = (Q, q_\u03bf, \\Sigma, \\delta, F)$, where Q is a finite set of states, $q_0 \\in Q$ is the initial state, \u03a3 is the input alphabet, $\\delta: Q \\times 2^\u03a3 \\rightarrow 2^Q$ is the transition function, and $F \\subseteq Q$ is the set of accepting states.\nTask Planning with Co-Safe LTL Constraints: Let S be the set of robot states and A be the set of robot actions.\nTask planning aims to find a sequence of actions $a_1, a_2,...$, where $a_i \\in A$, which satisfies the LTL specification. This sequence should generate: (1) A sequence of robot states $S_0, S_1, S_2,...$ where $s_i \\in S$, and (2) a run of the B\u00fcchi automaton $q_0, q_1, q_2, ...$ where $q_i \\in Q$. The plan must satisfy"}, {"title": "IV. APPROACH", "content": "Fig. 2 shows an overview of our framework. In this section, we explain how we collect data (Sec. IV-A) for fine- tuning an LLM translator (Sec. IV-B) and an LLM planner (Sec. IV-D) to generate time-efficient task plans. We design an effective equivalence voting mechanism that enhances NL-LTL translation (Sec. IV-B) and a novel LTL-enforced constrained decoding algorithm (Sec. IV-C) to ensure the safety of generated plans.\nData Collection\nLTL translation To generate diverse NL-LTL pairs for both training and test, we follow [31] to use context-free grammars to automatically generate LTL formulas. Then, for each LTL formula, we parse its syntax tree and translate it to a structured English description. Since such structured English is monotonous and less natural, we apply GPT-3.5 to paraphrase each generated English description follow- ing [24]. To create test data, we use GPT-4 to paraphrase the data.\nPlan Generation Given an NL task description ltask and an environment description lenv, the planner model is expected to generate a safe and efficient plan P. To create training data for LLMs to learn to generate such a plan, we search through safe plans from the automatically produced LTL formulas and then select the most efficient plan based on their simulation time. Specifically, we combine a navigation task specified by an LTL formula $\\phi_o$ with N constraint LTL formulas $\\phi_1,...,\\Phi_N$, and convert the combined LTL specification $\\phi = \\phi_o \\wedge  \\bigwedge_{i=1}^{N}\\phi_i$ into a B\u00fcchi automaton B. Using brute-force search over B, we generate a set of action sequences {P} that result in accepting runs. We then simulate these plans, evaluate their time costs, and choose the most efficient plan for training the LLM Planner."}, {"title": "B. LTL Translation", "content": "We finetune an LLM to generate an LTL specification given an NL description. Following prior work [25], we perform lifted LTL translation for generalization to different environments. For example, the NL description \"Head to Walmart and then CVS\" will be lifted as \"Head to A and then B\", then translated to LTL formula F(A & FB), and grounded back to F(Walmart & FCVS) with a mapping {A \u2192 Walmart, B \u2192 CVS}. We also adopt LTL formulas in prefix format to avoid parenthesis matching [25].\nTo increase the accuracy of LTL translation, we apply a voting mechanism [32] combined with chain-of-thoughts during LLMs' inference process to accurately capture the temporal logic contained in the user's description. For ex- ample, the command in Fig.3 implies that if the agent visits A, then in the next step it should visit B. To let the LLM correctly translate such temporal logic, we first prompt the LLM to explain the sentence and paraphrase it in a chain-of-thoughts manner to express the temporal logic explicitly. Thus, the paraphrased sentence will clearly convey the temporal logic, making it easier for the LLM to compre- hend. The fine-tuned LLM takes the paraphrased sentence as input and generates LTL specifications. As NL is diverse, we let the LLM generate 20 explanations and paraphrases given a user command, for each of which we sample 10 LTL formulas using the fine-tuned LTL model. These LTL specifications are grouped by their logical equivalency. We use the spot.are_equivalent function in Spot [33] to check if two LTL specifications are equivalent. Finally, the LTL specification from the set with the maximum cardinality is selected as the output."}, {"title": "C. Constrained Decoding for Plan Generation", "content": "To ensure safety, it is critical that plans should adhere to user-specified constraints. We propose a constrained de- coding algorithm enforced by LTL to prune unsafe actions. Given an LTL specification \u03a6, its automaton B, and an input text I = (lenv, ltask, A1:i\u22121) to an LLM, assume the agent is currently at automaton state qi-1 and the LLM generates an action string ai. We check the validity of ai by progressing"}, {"title": "D. Fine-Tuning Planner", "content": "Besides safety, the efficiency of task plans is a crucial concern, as it imposes practical constraints on the plan's viability in real-world scenarios. This challenge lies outside the capabilities of LTL constraint checking, which solely en- forces safety, leaving the demand of efficiency unaddressed. We introduce a fine-tuning phase for our LLM Planner to bridge this gap, where we finetune an LLM with an efficient plan Pe for each task (i.e., the most efficient plan we sampled in Sec.IV-A). The fine-tuning enables LLMS to learn how to prioritize generating safe plans with the shortest completion time. Assume the textual form of Pe is a sequence of m tokens Pe = {Y1,Y2,...., Ym}. The training minimizes the negative log-likelihood loss: LLM = $\\sum_{i=1}^{m}- log p(Y_i | Y_{<i}, l_{task}, l_{env}).$"}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "Our approach, SELP, introduces three key insights: equiv- alence voting for robust LTL translation, constrained decod- ing for safe plan generation, and domain-specific fine-tuning for efficient planning. SELP addresses limitations in handling complex, long-horizon tasks with multiple constraints. Our experiments answer the following research questions:\nRQ1: What is the complexity of our newly introduced datasets compared to existing benchmarks?\nRQ2: What are the safety, completion rate, and execution time of SELP compared to existing LLM planners?\nRQ3: How does equivalence voting improve the accuracy and robustness of LTL translation from natural language?\nRQ4: What impact does constrained decoding have on the safety and efficiency of generated plans?\nRQ5: How does domain-specific fine-tuning enhance the planner's ability to generate efficient plans?"}, {"title": "A. Experimental Setup", "content": "1) Dataset and Simulation Environment: We create two new datasets for training and evaluation: a drone navigation dataset-DroneNav, and a tabletop manipulation dataset- TabletopManip. These datasets address the limitations of existing datasets, which are either (1) relatively simple, which are unsuitable for evaluating long-horizon task plan- ning [1,21,22,24], or (2) for common household tasks [3,11], which primarily harness LLMs' common sense for household routines, which is not the focus of this work.\nDataset complexity (RQ1) The syntax trees of LTL specifications [24] in DroneNav and TabletopManip have an average depth of 6.89 and 6.71, and an average width of 11.83 and 11.26, respectively, compared to an aver- age depth of 3.46-3.77 and width of 1.78-1.98 in other datasets [21, 22, 24]. To further illustrate the complexity of our dataset, we analyzed the automatons translated from LTL specifications in our dataset. For DroneNav, the average number of nodes and edges of automatons are 354.0 and 21191.5; for TabletopManip, the number of nodes and edges are 338.2 and 26321.6. These two datasets will be released in github.com/lt-asset/selp.\ni). DroneNav: DroneNav consists of navigation tasks requiring an agent to visit a set of locations in a non- predefined order (e.g., visiting all rooms in the building), while conforming to constraints (e.g., the green room must be visited before visiting the yellow room). Each task has multiple feasible plans. To evaluate the effectiveness of SELP in planning navigation tasks of varying complexities, we create test data with different numbers (from 1 to 5) of constraints. The drone simulation environment has a three- or four-story building with twelve rooms, as shown on the right side of Fig. 1. We randomize the room locations and the initial position of the drone to create different environment layouts. We customize this domain in PyBullet Drones [34] and control the drone to follow the output plan from LLMS with a PID controller. We further deployed the simulation results to the real world, as shown in Fig. 6 and our video.\nii). TabletopManip: TabletopManip dataset instructs an agent to perform pick-and-place tasks, i.e., moving blocks"}, {"title": "B. Plan Generation Result (RQ2)", "content": "We evaluate SELP and existing LLM planners with four metrics: safety rate (SF, the percentages of plans that satisfy the task specification), completion rate (CP, the percentages of plans that complete the navigation or manipulation regard- less of constraints), plan execution time cost (ET, the average execution time of safe plans in time-steps), and planning time cost (PT, the average planning time in seconds).\nWe compare SELP with a brute-force search approach (Sec. IV-A) to generate plans from LTL formulas (i.e., LTL+BFS). Since LTL+BFS searches the entire space that conforms to LTL specifications, any plans generated by the brute-force approach are expected to conform to the LTL specifications. However, it may generate inefficient plans. We set a time limit of 300 seconds for all techniques except for GPT-4, due to GPT-4's hight cost (instead, the prompting iteration limit for GPT-4 is 30). Timeout is regarded as failures to generate a safe or complete plan.\nTable I shows that SELP significantly outperforms other techniques in both drone navigation and tabletop manipula- tion tasks. For drone navigation, SELP achieves the highest safety rate of 95.2%, the highest completion rate of 100%, and the lowest average execution time of 581.89 time-steps. For tabletop manipulation, it achieves the highest safety rate of 93.6%, the highest completion rate of 99.4%, and an average execution time of 805.2 time-steps. In contrast, baseline LLMs and Code as Policies make poor use of constraints for plan generation, which is reflected in their low safety rates (3.0%\u201337.6%). Safety Chip also uses LTL specifications to enhance safety, achieving a higher safety rate of 84.4% and 73.2% for the respective tasks, but still worse than SELP's performance. LTL+BFS has a safety rate lower (by 10.6% and 19.6%) than SELP due to timeout. Its ET is 31.0% and 15.5% longer than SELP since it has no knowledge of the environment. Compared to the two"}, {"title": "C. LTL Translation Results (RQ3)", "content": "We compare SELP's LTL translation component with two LTL translation approaches, Lang2LTL [25] and Copy- Net [37], for navigation tasks. We re-trained Lang2LTL with CodeLlama2-7b for a fair comparison. Table II shows that SELP's translation module achieves 88.4% and 98.0% accu- racy without and with equivalence voting on the DroneNav dataset, showing an improvement of 9.8%. For the Table- topManip dataset, accuracy without and with equivalence voting is 87.4% and 95.2%, with an improvement of 7.8%.\nWe further evaluate our translation module on two crowd- sourced LTL translation datasets: the OSM dataset [21] and the Cleanup World dataset [22]. The result (the first two columns of Table II) shows that the voting mechanism consistently improves the accuracy by 2.6% on OSM and by 8.0% on Cleanup World compared with Lang2LTL, achieving the highest accuracy on both benchmarks."}, {"title": "D. Constrained Decoding and Fine-Tuning (RQ4 & RQ5)", "content": "Table III presents the ablation study results, comparing SELP with and without finetuning with plan data (FT) and constrained decoding (CD). SELP w/o FT shows lower safety, and completeness, with a significantly longer execu- tion time, which justifies the necessity of fine-tuning. SELP outperforms SELP w/o CD in safety, and completeness. However, for drone navigation, SELP has a slightly longer ET than SELP w/o CD due to that CD reshapes the proba- bility distribution of the LLM planner to ensure safety. This degeneration in ET (-7.6%) is acceptable considering the importance of achieving a higher safety rate (+14.4%). SELP, with both FT and CD, achieves the highest performance in terms of safety and completeness."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "We propose a novel approach SELP to generate both safe and efficient plans. SELP consists of an LTL translator with a voting mechanism and a fine-tuned planner with a constrained decoding algorithm. Our experiment on drone navigation and tabletop manipulation tasks demonstrate: (1) the voting mechanism effectively improves LTL translation accuracy (2) the constrained decoding algorithm is critical for ensuring safety (3) domain-specific fine-tuning is essential to adapt LLM to generate efficient plans as well as meet safety standards. SELP outperforms SOTA LLM planners and is generablizable to different domains.\nWe note a few limitations: (1) we only consider generating task plans with finite steps despite LTL's capability to express plans with infinite steps; (2) we do not design a feedback mechanism. However, it is straightforward to re-generate a plan when SELP fails to produce a safe plan or when the generated plan is inconsistent with the NL task description. For future work, we will focus on the following aspects: (1) consider more objectives such as energy consumption. (2) include vision information and expand on multi-modality."}]}