{"title": "AN EXTENSIVE EVALUATION OF PDDL CAPABILITIES\nIN OFF-THE-SHELF LLMS", "authors": ["Kaustubh Vyas", "Damien Graux", "S\u00e9bastien Montella", "Pavlos Vougiouklis", "Ruofei Lai", "Keshuang Li", "Yang Ren", "Jeff Z. Pan"], "abstract": "In recent advancements, large language models (LLMs) have exhibited profi-\nciency in code generation and chain-of-thought reasoning, laying the groundwork\nfor tackling automatic formal planning tasks. This study evaluates the potential of\nLLMs to understand and generate Planning Domain Definition Language (PDDL),\nan essential representation in artificial intelligence planning. We conduct an ex-\ntensive analysis across 20 distinct models spanning 7 major LLM families, both\ncommercial and open-source. Our comprehensive evaluation sheds light on the\nzero-shot LLM capabilities of parsing, generating, and reasoning with PDDL.\nOur findings indicate that while some models demonstrate notable effectiveness\nin handling PDDL, others pose limitations in more complex scenarios requiring\nnuanced planning knowledge. These results highlight the promise and current lim-\nitations of LLMs in formal planning tasks, offering insights into their application\nand guiding future efforts in AI-driven planning paradigms.", "sections": [{"title": "1 INTRODUCTION", "content": "Automated planning has long been a cornerstone of artificial intelligence, traditionally relying on\nexplicit domain knowledge encoded in formal languages such as PDDL. In recent years, the rapid\nevolution of large language models (LLMs) has sparked considerable interest in their ability to\nbridge the gap between natural language descriptions and formal planning representations.\nEarly studies by Zuo et al. (2024) and Oswald et al. (2024) demonstrated that LLMs are capable\nof translating natural language descriptions into syntactically valid PDDL representations. How-\never, these pioneering works also revealed significant gaps, as the generated planning domains fre-\nquently diverge from gold-standard models, both syntactically and semantically. This observation\nhas spurred further research into the underlying reasoning capabilities of LLMs and their potential\nrole in executing complete planning tasks\nAdvancement in LLMs fuelled recent efforts that looked into how these multi-billion parameter\nmodels can be best employed as agents Huang et al. (2024). Building on this momentum, several\nstrategies have been proposed to map user instructions into PDDL problems Pallagani et al. (2023);\nLiu et al. (2023a); Dagan et al. (2023); Gestrin et al. (2024); Zhang et al. (2024), without however\nproviding conclusive evidence for the feasibility of the task in the general domain. These studies un-\nderscore both the promise and the challenges inherent in leveraging LLMs for complex planning and\nreasoning tasks, where transforming natural language into an executable agentic workflow remains\na non-trivial endeavor.\nIn this study, we step back to examine the fluency of twenty LLMs from seven major families in\nthe PDDL language, focusing on their ability to parse, generate, and reason with PDDL. Specifi-\ncally, we leverage the Planetarium benchmark Zuo et al. (2024) alongside the dataset introduced by\nOswald et al. (2024) to assess how well these models understand and generate actions, problems, and\nplans. By analyzing a randomly sampled subset of over 13,000 (NL-instruction, PDDL-problem)\npairs, our results show that although some models demonstrate moderate proficiency in handling\nPDDL, the majority struggle to convert natural language instructions into fully correct PDDL rep-\nresentations. This challenge is especially evident in smaller LLMs, which often fail to produce\nparsable PDDL."}, {"title": "2 EXTENSIVE PDDL CAPABILITY EVALUATION", "content": "From a high-level point of view, PDDL involves three types of elements: the domains to represent\nthe possible actions available in a certain space, the problems which roughly encode the premise\nand the goal of a real world operation to be performed in a defined space (i.e. domain) and finally\nthe plans that represent the effective set of actions to be run to perform the real world operation,\nachieving the goal.\nTherefore, practically, we stressed the considered LLMs to generate all or part of the aforementioned\nelements, while maintaining a wide set of evaluation scores across the involved steps to fuel the\ndiscussion and draw conclusions."}, {"title": "2.1 ACTION GENERATION", "content": "Task Signature = [input: NL instruction, PDDL domain predicates; output: PDDL action]\nWe rely on the benchmark proposed by Oswald et al. (2024) to evaluate the action genera-\ntion capabilities: given a seed domain file and the NL description of an action, we let the LLM\ngenerate it in proper PDDL syntax. In their article, the authors shared a set of 32 NL-to-Action\ninstructions distributed across 9 popular PDDL domains. We enriched these by generating 4\nNL-variations for each NL-to-instruction pair to obtain a dataset of 160 [(1 + 4) \u00d7 32] instructions.\nTo assess the results, we score along the following dimensions: Parsable: Determines if the output\nconforms to correct PDDL syntax. Solvable: Measures how well the action integrates into the\ntarget domain (e.g. the action may be syntactically correct but involving type mismatches, wrong\nnumber of variables for some predicates,...). Equivalent: Syntactically valid PDDL that integrates\nwith the desired domain under the domain equivalence heuristic.\nTo measure the similarity between the generated action and the gold standard, we calculate the\nnormalised differences in their preconditions and effects, and then subtract this value from one to\nderive a similarity score.\nSimilarity = 1 - \\frac{|A_{pre} \\Delta A'_{pre}| + |A_{ef} \\Delta A'_{ef}|}{|A_{pre} \\cup A'_{pre}| + |A_{ef} \\cup A'_{ef}|}\nWhere $A_{pre}$, $A_{ef}$ are preconditions and effects in the gold action and $A'_{pre}$, $A'_{ef}$ are preconditions and\neffects in the LLM generated action."}, {"title": "2.2 PROBLEM GENERATION", "content": "Task Signature = [input: NL instruction, PDDL domain; output: PDDL problem]\nWe choose the Planetarium benchmark to evaluate the problem generation capabilities of\nmodels Zuo et al. (2024). The benchmark was primarily selected due its size that enabled a\ncomprehensive evaluation on our side. In particular, we randomly selected 10% of the full dataset,\nresulting in a test set consisting of 13 203 (NL-instruction, PDDL-problem) pairs. Metrics for this\nset of experiments are as above (with a slight difference): Parsable: generated PDDL adheres to\nthe syntactic rules of the language, Solvable: the generated problem can be effectively processed\nby existing PDDL planners, reflecting its practical utility, Equivalent: matches the gold standard in\nboth structure and semantics.\nWhen it comes to measure the similarity between the gold and the generated PDDL problem, we\nuse ChrF Popovi\u0107 (2015) as it is a standard metric to evaluate code generation tasks Evtikhiev et al."}, {"title": "2.3 PLAN GENERATION", "content": "Task Signature = [input: PDDL domain, PDDL problem; output: Plan]\nFinally, although LLMs are not expected to outperform conventional planners since their\nreasoning capabilities rely on intrinsic parametric knowledge rather than explicit logical reason-\ning we also aimed to assess their ability to plan in PDDL when provided with pairs of domain\nand problem. For this purpose, we selected domain-problem pairs from the Planetarium benchmark\nto prompt the models for plan generation. To evaluate generalisation, we categorised these problems\nbased on their level of abstractness, classifying descriptions as either explicit or abstract. Explicit\ndescriptions are direct propositions found in the PDDL problem (e.g., \u201cblock1 is on block2\"),\nwhereas abstract descriptions summarise a state (e.g., \"all blocks are in a single tower\"). Because\nthese descriptions encapsulate both the initial and goal states, there are four possible categories: (1)\nAbstract initial and goal states, (2) Abstract initial but explicit goal, (3) Explicit initial but abstract\ngoal and (4) Explicit initial and goal states. In total, we selected 40 representatives from each\ncategory, yielding 160 pairs. The correctness of the generated plans is then verified using VAL, a\ntool that assesses whether a plan is compatible with the specified PDDL domain and problem.\""}, {"title": "2.4 CONSIDERED LLMS", "content": "To review the capabilities of language models to deal with PDDL, we utilised LLMs from several\nleading organisations, ensuring that both general-purpose and specialist models (i.e. chatting, code\ngeneration or instruction-following modes) are considered. Our set of models includes LLMs from\n\u2022 OpenAI (GPT-3.5-turbo, GPT-40-mini, GPT-40),\n\u2022 Anthropic (Claude-3-Haiku and Claude-3-Sonnet),\n\u2022 Google (Gemini-1.5-Pro, Gemini-1.5-Flash and Gemma-2-9B-it),\n\u2022 Meta (LLaMA-3.1-8B-Instruct, LLaMA-3.1-70B-Instruct, and LLaMA3.1-405B-Instruct),\n\u2022 Mistral (Large2, 7B-Instruct, and Codestral),\n\u2022 DeepSeek (Coder-V2 and Chat-V2),\n\u2022 Alibaba (Qwen2-1.5B-Instruct, Qwen2.5-7B-Instruct, Qwen2.5-Coder-7B-Instruct, and\nQwen2.5-72B-Instruct).\nOverall, this set involves members of 7 distinct providers, including commercial and open LLMs.\nIn addition, this set allows us to compare behaviors and performances across different parameter\nnumbers and specialities."}, {"title": "2.5 RESULTS", "content": "Domain (Fig.1A) We review the performance of 20 distinct LLMs in populating PDDL domain\nfiles with new actions based on NL instructions. While most LLMs perform well in generating\ncorrect actions, a notable decline in performance is observed in their ability to produce equivalent\nactions. Among the models, GPT-40, Qwen2.5-72B-instruct, and Mistral-Large2 stand out as the\ntop performers across all three metrics for action generation. In contrast, some models consistently\nfail to adhere to the required action syntax. Notably, the entire LLaMA family performs very poorly,\nirrespective of the number of parameters. It is worthwhile noting that all the models have their\nrespective parsable and solvable values very close, in other words the difference between them for a\nmodel is of few points. This implies that not only models are able to generate proper PDDL syntax\n(parsable) but they comply with the given domain (solvable), such a property could be useful if the\nmodels were used as assistants, see Figure 2 and its associated discussion for more details.\nProblem (Fig.1B) We next assessed the ability of LLMs to generate complete PDDL problems\nbased on NL instructions and a corresponding PDDL domain. While most models can produce\nsyntactically correct and parsable PDDL problems, their performance declines significantly when\nrequired to solve the problem for generating a plan or producing problems equivalent to the gold.\nInterestingly, the LLaMA family, which struggled with syntax in action evaluations, demonstrates\nimproved accuracy for this task. Even though LLaMA-3.1-405B achieves the highest equivalency\nrate at about 32%, its performance \u2013and that of all off-the-shelf models\u2013 remains inadequate for\nthis task, suggesting that further techniques such as few-shot prompting, fine-tuning, or other en-\nhancements are necessary to assist PDDL problem generation, as explored by Zuo et al. (2024) for\ninstance. Furthermore, models are not consistent through the three metrics: for instance GPT-40-\nPlan (Fig.1C) Investigating the plan generation, as expected, we find that given a PDDL domain\nand problem, the models struggle to generate PDDL plans. This was tested on 160 data points,\nwith Gemini-1.5-pro performing the best, yet achieving a valid plan in only 16.87% of the cases.\nIn contrast, the BFWS-FF planner succeeded in generating a conclusive plan 86.25% of the time.\nAdditionally, we explored the plan generation relative to the abstractness of the initial state and goal\nof the PDDL problem. Across all LLMs, we observe that they perform better when the initial state\nof the PDDL problem is abstract, though, no such pattern is noticed regarding the abstractness of the\ngoal. Once again, the models are not performing similarly across the different tasks. Typically, our\nsmallest model in the mix (Qwen2-1.5B-Instruct) which had scores almost all null for the domain\nand problem tasks, happens to be in the top-5 for the plan generation."}, {"title": "2.6 DISCUSSIONS", "content": "Our results indicate that while most LLMs can generate syntactically correct PDDL, they largely\nlack the capacity to generate effective problems and plans for addressing the input instructions. This\nbehaviour becomes increasingly evident as the complexity of the experimental setup rises.\nParameter Number With the exception of the LLaMa family, an increased number of parameters\nin LLMs does not consistently lead to better PDDL fluency. This suggests that current pre- and post-\ntraining approaches are not effectively scaling these models to meet the demands of complex PDDL\ngeneration, including, but not limited to, long-horizon planning tasks. A clear challenge emerges\nwith models like the LLaMA family (see Fig.1), which, while effective in problem generation, strug-\ngle significantly with action generation. This issue stems from a syntactic bias: for example, instead\nof the correct keyword\": precondition"}, {"content": "they generate \u201c:preconditions"}, {"content": "making actions\nunparsable. Similar patterns are observed in Gemma-2-9B-it, Mistral-7B-Instruct, or Qwen2.5-72B-\nInstruct, which incorrectly output \"(action...)\" rather than \u201c(:action...)"}, {"content": "Similarly,\nwhile generating problems, models often struggle with maintaining correct action sequences in the\ngoal, occasionally placing semantically similar actions in the goal that are not defined in the domain,\nleading to mismatches.\nLLMs as copilots However, our findings, in Fig.2, reveal that despite these challenges, LLM-\ngenerated PDDL actions and problems demonstrate a high degree of closeness to the gold standard.\nThis suggests that, while the models (off-the-shelf) may not yet be fully reliable for independent\nuse, they hold strong potential as supportive tools. By generating near-accurate PDDL structures,\nthese models can serve as co-pilots, streamlining the drafting process and allowing experts to focus\non refinement and optimization rather than building from the ground up. The position articulated\nin Kambhampati et al. (2024) underscores that, although LLMs may not inherently plan effectively,\nthey can nonetheless play a significant supportive role in LLM-modulo planning frameworks. This"}, {"title": "3 RELATED WORK PDDL LLM", "content": "The generation of PDDL domains and problems has recently garnered significant attention\nas a means to enhance planning via large language models (LLMs) Strobel & Kirsch (2020);\nSilver & Chitnis (2020); Silver et al. (2022); Vyas et al. (2025). In parallel, the advent of sophisti-\ncated prompting techniques has unlocked new applications for LLMs Liu et al. (2023b); Graux et al.\n(2024). Nonetheless, while LLMs have demonstrated planning capabilities Huang et al. (2024), they\ncontinue to struggle with long-horizon planning, uncertainty in generated plans, and generalisation\nto unseen domains Sermanet et al. (2023). Consequently, several works have aimed to bridge the\ngap between the probabilistic nature of LLMs and the deterministic requirements of PDDL-based\nplanners. For instance, Collins et al. (2022) compared the out-of-distribution robustness of PDDL-\naugmented LLMs with human reasoning, highlighting clear limitations in current LLM approaches.\nIn many settings, LLMs have proven more effective at translating natural language into formal\nrepresentations rather than performing the planning itself, as noted in works such as Alford et al.\n(2009); Helmert (2009); Xie et al. (2023). This observation has spurred strategies that decom-\npose the problem into translating user instructions into PDDL problems, solving these problems\nvia formal logic within the PDDL framework, and then translating the resulting plans back into\nnatural language Pallagani et al. (2023); Liu et al. (2023a); Dagan et al. (2023); Silver et al. (2024);\nGestrin et al. (2024); Mahdavi et al. (2024); Zhang et al. (2024).\nMore recent contributions have further refined the dialogue between LLMs and planning. Hao et al.\n(2023) propose that reasoning with a language model can be reinterpreted as planning with an in-\nte"}, {"title": "4 CONCLUSION", "content": "In this study, we experimentally reviewed the PDDL capabilities of a large panel of language models:\ntwenty in total, representing multiple dimensions of the current state-of-the-art. Our evaluations\nshow that (some) LLMs can be used to generate actions to complete PDDL domains, they may\nalso be used to assist in the task of generating PDDL problems from NL instructions. However, as\nexpected, they reveal being poor planners and it is better to rely on \"real\" planners which have been\ndeveloped by the community for decades. Surprisingly also, behaviours given a specific model are\nnot uniform across tasks as good performers (even leaders) for a certain PDDL aspect may turn out\nto be among the worst ones later. Overall, we hope to pave the road to future efforts in AI-driven\nplanning challenges."}, {"title": "A EXAMPLES OF 0-SHOT PROMPTS", "content": "In order to give a better idea on the prompts we triggered at the language models, we provide in this\nAppendix an example for each of the tested task, i.e. Action creation, Problem generation and Plan\ncreation. We refer the reader to the main body of the article for more details, see e.g. Figure 1 (A, B\nand C) for details of the results\u2074 . In particular, here we provide:\n\u2022 The action generation (put-down) for the BLOCKS domain;\n\u2022 A problem generation in blocksworld domain (init=holding_one);\n\u2022 A plan generation in blocksworld domain(init=on_table,goal=tower).\nPrompt and result for the action generation (put-down) for the BLOCKS domain\nGiven a description of an action in some domain, convert it to Planning Domain Definition\nLanguage (PDDL) action. You may only use the allowed predicates for each action.\nAllowed Predicates:\n(handempty): the hand is empty.\n(holding ?x - block): block x is held.\n(clear ?x - block): block x is clear.\n(on ?x - block ?y - block) : block x is on block y.\n(ontable ?x - block): block x is on the table.\nInput: The action, \u201cput-down\u201d will have the hand put down a block.\nPDDL Action:\n(:action put-down\n:parameters (?x - block)\n:precondition (holding ?x)\n:effect (and (not (holding ?x)) (clear ?x) (handempty) (ontable ?x))\n)\nA problem generation in blocksworld domain (init=holding_one)\nProvide me with the complete, valid problem PDDL file that describes the following plan-\nning problem directly without further explanations or texts. The domain for the planning\nproblem is:\n(define (domain blocksworld) (:requirements :strips) (:predicates (arm-empty) (clear ?x)\n(holding ?x) (on ?x ?y) (on-table ?x)) (:action pickup :parameters (?ob) :precondition (and\n(clear ?ob) (on-table ?ob) (arm-empty)) :effect (and (holding ?ob) (not (clear ?ob)) (not (on-\ntable ?ob)) (not (arm-empty)))) (:action putdown :parameters (?ob) :precondition (holding\n?ob) :effect (and (clear ?ob) (arm-empty) (on-table ?ob) (not (holding ?ob))) ) (:action stack\n:parameters (?ob ?underob) :precondition (and (clear ?underob) (holding ?ob)) :effect (and\n(arm-empty) (clear ?ob) (on ob underob) (not (clear ?underob)) (not (holding ?ob)))) (:ac-\ntion unstack :parameters (?ob ?underob) :precondition (and (on ?ob ?underob) (clear ?ob)\n(arm-empty)) :effect (and (holding ?ob) (clear ?underob) (not (on ?ob ?underob)) (not (clear\n?ob)) (not (arm-empty)))))\nPlanning problem:\nYou have 17 blocks. You are holding bl. b2 is clear. b2 is on the table. b3 is clear. b3 is on\nthe table. b4 is clear. b4 is on the table. b5 is clear. b5 is on the table. b6 is clear. b6 is on\nthe table. b7 is clear. b7 is on the table. b8 is clear. b8 is on the table. b9 is clear. b9 is on\nthe table. b10 is clear. b10 is on the table. b11 is clear. b11 is on the table. b12 is clear. b12\nis on the table. b13 is clear. b13 is on the table. b14 is clear. b14 is on the table. b15 is clear.\nb15 is on the table. b16 is clear. b16 is on the table. b17 is clear. b17 is on the table.\nYour goal is to stack the blocks into a towers of heights 1, 1, 1, 2, 3, 9.\nProblem PDDL:\n(define (problem holding_one_to_tower_1_1_1_2_3_9)\n(:domain blocksworld)\n(:requirements :strips)\n(:objects b1 b10 b11 b12 b13 b14 b15 b16b17 b2 b3 b4 b5 b6 b7 b8 b9)\n(:init (clear b10) (clear b11) (clear b12) (clear b13) (clear b14) (clear b15) (clear b16)\n(clear b17) (clear b2) (clear b3) (clear b4) (clear b5) (clear b6) (clear b7) (clear b8) (clear\nb9) (holding bl) (on-table b10) (on-table b11) (on-table b12) (on-table b13) (on-table b14)\n(on-table b15) (on-table b16) (on-table b17) (on-table b2) (on-table b3) (on-table b4) (on-\ntable b5) (on-table b6) (on-table b7) (on-table b8) (on-table b9))\n(:goal (and (arm-empty) (clear b1) (on-table b1) (clear b2) (on-table b2) (clear b3) (on-\ntable b3) (clear b4) (on b4 b5) (on-table b5) (clear b6) (on b6 b7) (on b7 b8) (on-table b8)\n(clear b9) (on b9 b10) (on b10 b11) (on b11 b12) (on b12 b13) (on b13 b14) (on b14 b15)\n(on b15 b16) (on b16b17) (on-table b17)))\n)\nPlan generation in blocksworld domain (init=on_table, goal=tower)\nGiven a PDDL domain and a PDDL problem file, come up with the plan associated with the\nproblem. The domain describes the possible actions and their effects, while the problem file\ndetails the specific scenario to be solved. Do not generate anything but the correct plan\nDomain PDDL:\n(define (domain blocksworld) (:requirements :strips) (:predicates (arm-empty) (clear ?x)\n(holding ?x) (on ?x ?y) (on-table ?x)) (:action pickup :parameters (?ob) :precondition (and\n(clear ?ob) (on-table ?ob) (arm-empty)) :effect (and (holding ?ob) (not (clear ?ob)) (not (on-\ntable ?ob)) (not (arm-empty)))) (:action putdown :parameters (?ob) :precondition (holding\n?ob) :effect (and (clear ?ob) (arm-empty) (on-table ?ob) (not (holding ?ob)))) (:action stack\n:parameters (?ob ?underob) :precondition (and (clear ?underob) (holding ?ob)) :effect (and\n(arm-empty) (clear ?ob) (on ?ob ?underob) (not (clear ?underob)) (not (holding ?ob)))) (:ac-\ntion unstack :parameters (?ob ?underob) :precondition (and (on ?ob ?underob) (clear ?ob)\n(arm-empty)) :effect (and (holding ?ob) (clear ?underob) (not (on ?ob ?underob)) (not (clear\n?ob)) (not (arm-empty)))))\nProblem PDDL:\n(define (problem on_table_to_tower_1_1_1_1_3_13)(:domain blocksworld)(:requirements\n:strips)(:objects b1 b10 b11 b12 b13 b14 b15 b16 b17 b18 b19 b2 b20 b3 b4 b5 b6 b7\nb8 b9)(:init (arm-empty) (clear b1) (clear b10) (clear b11) (clear b12) (clear b13) (clear b14)\n(clear b15) (clear b16) (clear b17) (clear b18) (clear b19) (clear b2) (clear b20) (clear b3)\n(clear b4) (clear b5) (clear b6) (clear b7) (clear b8) (clear b9) (on-table bl) (on-table b10)\n(on-table b11) (on-table b12) (on-table b13) (on-table b14) (on-table b15) (on-table b16)\n(on-table b17) (on-table b18) (on-table b19) (on-table b2) (on-table b20) (on-table b3) (on-\ntable b4) (on-table b5) (on-table b6) (on-table b7) (on-table b8) (on-table b9))(:goal (and\n(arm-empty) (clear b1) (on-table b1) (clear b2) (on-table b2) (clear b3) (on-table b3) (clear\nb4) (on-table b4) (clear b5) (on b5 b6) (on b6 b7) (on-table b7) (clear b8) (on b8 b9) (on b9\nb10) (on b10 b11) (on b11 b12) (on b12 b13) (on b13 b14) (on b14 b15) (on b15 b16) (on\nb16 b17) (on b17b18) (on b18 b19) (on b19 b20) (on-table b20))))\nPlan:"}]}