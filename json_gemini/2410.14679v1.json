{"title": "HyperCausalLP: Causal Link Prediction using Hyper-Relational Knowledge Graph", "authors": ["Utkarshani Jaimini", "Cory Henson", "Amit Sheth"], "abstract": "Causal networks are often incomplete with missing causal links. This is due to various issues, such as missing observation data. Recent approaches to the issue of incomplete causal networks have used knowledge graph link prediction methods to find the missing links. In the causal link A causes B causes C, the influence of A to C is influenced by B which is known as a mediator. Existing approaches using knowledge graph link prediction do not consider these mediated causal links. This paper presents HyperCausalLP, an approach designed to find missing causal links within a causal network with the help of mediator links. The problem of missing links is formulated as a hyper-relational knowledge graph completion. The approach uses a knowledge graph link prediction model trained on a hyper-relational knowledge graph with the mediators. The approach is evaluated on a causal benchmark dataset, CLEVRER-Humans. Results show that the inclusion of knowledge about mediators in causal link prediction using hyper-relational knowledge graph improves the performance on an average by 5.94% mean reciprocal rank.", "sections": [{"title": "Introduction", "content": "Causality is traditionally represented using a causal network, where the nodes represent events and edges represent the causal link between two events (Pearl 2009). Consider an example of a simple binary causal link: A causes B as shown in Figure 1(A). In this case, A is the cause, and B is the effect. Such causal links can also be chained together where A causes B and then B causes C. In a more complex case, there is a causal link between A and C that is mediated by B. The nodes A and C are called the cause and effect respectively, and the node B is called a mediator. A mediator helps in explaining the relationship between cause (independent node) and its effect (dependent node). It provides insights into the pathway linking cause and effect, capturing the contextual information. A complete network with all causal links is important for many downstream applications. In practice, however, causal networks are often incomplete with missing causal links. Recent approaches have successfully resolved this issue by encoding the causal network within a triple-based knowledge graph (i.e., Resource Description Framework (RDF) (Jaimini, Henson, and Sheth 2023)) and then using knowledge graph link prediction techniques to find the missing causal links (Jaimini, Henson, and Sheth 2024). While the existing approaches using knowledge graph (KG) link prediction can predict direct binary causal links, e.g., A causes B, they cannot predict the more complex mediated causal links, e.g., A causes C mediated by B. The mediated link captures the context information."}, {"title": "Related work", "content": "Knowledge graph link prediction The KG link prediction approach ranges from translation-based models, semantic matching models, and convolutional neural network-based models (Rossi et al. 2021; Wang et al. 2017; Wang, Qiu, and Wang 2021). These methods learn embedding for each entity and relation and use a scoring function to predict the likelihood of a triple being true. The graph neural network-based methods use message-passing approaches utilizing semantically rich neighborhood information present in the KG (Vashishth et al. 2019; Schlichtkrull et al. 2018; Nguyen et al. 2022; Mohamed et al. 2023; Li et al. 2024).\nCausal link prediction The existing techniques for causal link prediction typically focus on predicting binary links within knowledge graphs and lack specific tailoring for identifying causal links. The existing approaches often simplify the modeling of causality into a binary triple. The recent work has aimed to generate event-related causal knowledge graphs from sources like Wikipedia and Wikidata, incorporating causal predicates like hasCause and hasEffect (Hassanzadeh 2022). These graphs represent events as nodes and cause-effect relationships as links, with the objective of predicting future events by analyzing the underlying causes and effects of similar past events. Evaluation of causal link prediction tasks often uses established techniques for knowledge graph link prediction. The causal ontology provides a representation platform for both triple-based and more intuitive hyper-relational graph-based causality representation (Jaimini, Henson, and Sheth 2023). The recent work on incorporating causal AI and causal network concepts into knowledge graph link prediction laid the foundation for causal link prediction with causal weights using weighted KG embedding model (Jaimini, Henson, and Sheth 2024).\nHyper-relational knowledge graph link prediction The appeal to modelling hyper-relational graphs are motivated from conventional triple-based KG embedding models which simplifies the complex property qualifiers. The convolutional model incorporates complex triples with k qualifiers (key, value) in one fact (Guan et al. 2019). However, all the qualifier pairs are treated equally and does not distinguish between main triple and relation-specific qualifiers.\nThe HyperCausalLP approach proposed in this paper innovatively builds upon learned causal networks by transforming them into a CausalKG. It is among the first to use the prior causal structure knowledge encoded in a causal network which in turn is represented in the causal knowledge graph. It distinguishes between the main and the mediated causal link. This transformation allows for the application of KG techniques to discover additional, previously unrecognized causal links, thereby enriching and expanding the causal network beyond what is possible with traditional methods alone. The HyperCausalLP approach predicts new causal links in a KG utilizing the causal weight and four causal relations, i.e., causes, causedBy, causesType, and causedByType."}, {"title": "Problem Formulation", "content": "The causal link prediction is formulated as a KG link prediction problem. This section defines the primary concepts, including causal relations, causal link, causal entity, qualifier, hyper-relation, and causal knowledge graph.\nCausal knowledge graph: A causal knowledge graph CausalKG is a hyper-relational KG that includes causal knowledge in the form of causal relations and causal entities. CausalKG = (N, R, E, Ec):\n\u2022 N: a set of nodes representing entities\n\u2022 R: a set of labels representing relations\n\u2022 E \u2286 N \u00d7 R \u00d7 N: a set of edges representing links between pairs of entities. Each link is a triple <h, r, t>, where h is the head entity, r is the relation, t is the tail entity.\n\u2022 N_c \u2286 N: a set of nodes representing causal entities\n\u2022 R_c \u2286 R: a set of labels representing causal relations\n\u2022 R_m \u2286 R: a set of labels representing qualifier relations\n\u2022 N_m \u2286 N_c: a set of nodes representing qualifier entities\n\u2022 E_c \u2286 N_c \u00d7 R_c \u00d7 N_c \u00d7 P(R_m \u00d7 N_m): a set of edges representing causal hyper-relation link connecting pairs of causal entities. P denotes the power set."}, {"title": "Methods", "content": "The HyperCausalLP approach is structured into four primary phases (see Figure 2): (1) finding and encoding the known causal relations into a causal network, (2) translating the causal network into a hyper-relational CausalKG, conformant to the hyper-relational causal ontology incorporating the qualifier pairs (i.e. mediated links), (3) learning hyper-relational KG embedding for the CausalKG, and (4) predicting new causal links in the KG."}, {"title": "Causal Network", "content": "A causal network is a graphical model structured as a directed acyclic graph (Pearl 2009). In this model, nodes represent events, and edges indicate the causal links between these events. The causal network denoted as CN = (N_en, E_cn), such that N_en is the set of nodes in the causal network, E_en is the set of edges between nodes. The direction of each edge in the network indicates the direction of causality. Given a three-node causal network, the causal links can have three different orientation structures- serial, fork, and collider. A serial structure is one where a causal association is traversed in a series, such as the first event is responsible for causing the second event, and the second event is responsible for causing the third event. In the fork structure, the first event is responsible for causing both the second and the third event. In the collider structure, two independent events are together responsible for causing the third event. However, in this paper, we only focus on the serial structure (Figure 1 (A)). The first node is considered a cause-entity, the second node is the mediator-entity, and the third node is the effect-entity."}, {"title": "Hyper-relational Causal Knowledge Graph", "content": "The process of transforming data from a causal network into a hyper-relational causal knowledge graph (CausalKG) involves several straightforward conversions:\n\u2022 $N_{cn}$ \u2192 Ne: nodes in the causal network become causal entities in the CausalKG. The mediator nodes in the causal network become mediator entities in the CausalKG, which are represented as the qualifier entities.\n\u2022 $E_{cn}$ \u2192 Ec: edges in the causal network become causal links in the CausalKG, of the form <$n_{cause}$, 'causes, $n_{effect}$, r_m, \u041f\u043c>\nThe CausalKG also incorporates other causal relations and qualifier relations such as : causedBy, causesType, causedByType,\nhas Mediator, and has MediatorType. The CausalKG consists of all the information from the causal network and is conformant to the hyper-relational causal ontology (Jaimini, Henson, and Sheth 2023; Jaimini and Sheth 2022). The causal ontology is rooted in concepts from causal AI like causal Bayesian networks and do-calculus (Jaimini, Henson, and Sheth 2023). It is used to define the semantics and structure of causal relations and the nodes in the causal network. The ontology defines the primary concepts used to structure a CausalKG, including causal entities, causal relations, and mediators.\nThe CausalKG is used for causal link prediction using KG link prediction. There are two causal link prediction tasks: causal explanation and causal prediction. The goal of causal explanation is to predict the type of a cause-entity that is linked to an effect-entity. The goal of causal prediction is to predict the type of an effect-entity that is linked to a cause-entity. The goal for both tasks is not to predict the specific cause-entity (in the case of causal explanation) or effect-entity (in the case of causal prediction) instance but the type of these respective entities. The cause-entity (in the case of causal explanation) and effect-entity (in the case of causal prediction) are not directly linked with the cause-entity type and effect-entity, respectively. They are two-hop away: <$n_{effect}$, 'causedBy, $n_{cause}$>, <$n_{cause}$, rdf: type, type> for causal explanation; and <$n_{cause}$, 'causes, $n_{effect}$>, <$n_{effect}$, rdf : type, type> for causal prediction. The embedding models make predictions about directly linked entities. To overcome the issue of two-hop link prediction, CausalKG uses reified relation (see Figure 3)- 1) for causal prediction: causeType (r_causesType \u2208 R_c) to add a link connecting a cause-entity with the type of an effect-entity, and 2) for causal explanation: causedByType (r_causedByType \u2208 R_c) to add a link connecting an effect-entity with the type of a cause-entity. Along with all the above knowledge, the CausalKG also integrates additional domain knowledge associated with the entities that are not distinctly mentioned in the causal network."}, {"title": "CausalKG Embedding and Link Prediction", "content": "The CausalKG is converted into a low-dimensional continuous latent vector space representation called KG embeddings (KGE). The KGE is used for downstream tasks such as link prediction, entity classification, triple classification, etc., (Wang et al. 2017). The proposed HyperCausalLP approach uses KG embedding algorithms to generate embedding that will be used for causal link prediction. The proposed approach learns two types of KGEs for a CausalKG: 1) CausalKGE-Base embedding without mediators (no hyper-relations), and 2) CausalKGE-M embeddings with mediators as hyper-relations (represented using qualifier pairs). The CausalKGE-Base embedding is trained using the causal links, ignoring the mediators associated with each link. The CausalKGE-M embedding, on the other hand, is trained using the causal links with the mediators as the hyper-relational links (i.e. qualifiers). The CausalKGE-Base and CausalKGE-M embeddings are evaluated on the task of causal link prediction using KG link prediction."}, {"title": "Experiments", "content": "The proposed, HyperCausalLP, hyper-relational graph based causal link prediction approach is evaluated using the KG link prediction for two distinct causal link prediction tasks The above evaluation is demonstrated using a causal benchmark dataset. This section details the data, pre-processing steps, creation of a CausalKG from the dataset, experimental setup, evaluation metrics, and description of the evaluation with additional domain knowledge. (Please refer to supplementary for additional details)"}, {"title": "Data", "content": "CLEVRER-Humans is a causal benchmark dataset featuring human-annotated causal judgments about physical events depicted in videos (Mao et al. 2022). The videos display moving objects that vary in shape (sphere, cube, and cylinder), color (blue, red, yellow, green, purple, gray, cyan, and brown), and material (metal and rubber). Each object can be involved in one of 27 distinct events, such as enter, exit, collide, move, hit, bump, and roll. CLEVRER-Humans captures the causal information from these events using a Causal Event Graph (CEG), where the graph's nodes represent event descriptions from the videos and the directed edges indicate causal relationships. The edges of the CEGs are evaluated by human annotators to determine the strength of the causal links between the nodes. These edges are scored on a scale from 1 to 5, where 1 means \"not responsible at all,\" 2 means \"a bit responsible,\" 3 means \"moderately responsible,\" 4 means \"quite responsible,\" and 5 means \"extremely responsible.\". It is the only large scale causal dataset with 891 causal networks (i.e., CEG) which provides ground truth for the causal links."}, {"title": "Data Pre-processing", "content": "The initial step in generating a CLEVRER-Humans CausalKG involves pre-processing the CEGs. The CEGs serve as a proxy for a causal network, and their pre-processing is crucial to ensure they align with the definition of a causal network. In a causal network, edges represent causal links between nodes. The first step in this process is to remove edges with a score of 1, indicating no causal responsibility between the two nodes. Next, to maintain the structure of a directed acyclic graph, edges that create cycles in the CEGs are removed. Finally, CEGs are excluded if they do not have any remaining causal links or have a depth of less than 2 from the root node to the leaf node. After pre-processing, we are left with 764 CEGs."}, {"title": "Hyper-relational CausalKG", "content": "A hyper-relational CausalKG is created from CLEVRER-Humans by encoding the causal information within the CEGs in RDF format, adhering to the causal ontology. The proposed approach creates two different KG: CausalKG-Base and CausalKG-M (Figure 1). The CausalKG-Base is a simple KG with causal links, whereas CausalKG-M is a hyper-relational KG, which consists of mediators as hyper-relations (qualifiers). The hyper-relation with the mediator information between two given nodes in the CEG is encoded using RDF-star format. The KG not only includes causal relationships but also details about events (such as hit, collide, push, etc.), the involved objects, and their attributes. CEGs serve as graphical representations of events in the videos.\nTo represent information from the CEGs, we utilize three ontologies: the causal ontology, the scene ontology (prefixed with \"so:\"), and the semantic sensor network ontology (prefixed with \"ssn:\u201d). The causal ontology is employed for events (as causal entities), causal relations, and their corresponding causal mediators (i.e., qualifier pairs). The scene and sensor ontologies depict additional video information, such as scenes, objects, and object characteristics (Wickramarachchi, Henson, and Sheth 2021; Taylor et al. 2019). Each video is depicted as a scene (so:Scene) using scene ontology concepts. This includes representing and connecting the events within the scene (using the so:includes relation), the objects involved (using the so:hasParticipant relation), and the object characteristics (using the ssn:hasProperty relation) (Wickramarachchi, Henson, and Sheth 2021). In total, the CausalKG from CLEVRER-Humans contains >48K links, 5664 entities, 31 entity types, and 10 relations."}, {"title": "Diversifying the Available Knowledge", "content": "The CausalKGE-Base and CausalKGE-M embeddings are generated and evaluated on different CLEVRER-Humans CausalKG subgraph structures for the tasks of causal explanation and causal prediction, as illustrated in Figure 6. In the case of CausalKG-M and the given subgraph, the hyper-relations (qualifier pairs) are associated with causes, and causedBy causal relation as shown in Figure 3. Various graph structures are utilized to assess the performance of HyperCausalLP when different types of information are available in the CausalKG. Specifically, two distinct subgraph structures are defined with increasing levels of expressivity. 1. The first graph structure, C, shown in Figure 6(a), contains only links with causal relations. 2. The second graph structure, CT, shown in Figure 6(b), includes links with causal relations and causal entity types (i.e., rdf:type).\nWe optimized the hyper-parameters for each of these graph structures for causal link prediction tasks i.e., causal explanation and prediction tasks. The CausalKGE-Base models for each graph structures are trained on their respective optimized hyper-parameters (Please refer to supplementary text for more details). The CausalKGE-M model is trained on the StarE hyper-parameters (Galkin et al. 2020). The trained CausalKGEs are then employed for causal link prediction tasks using well-established link prediction methods."}, {"title": "Evaluation Metrics", "content": "HyperCausalLP was evaluated using the KG link prediction for causal link prediction. For a given set of causal links E_c in CausalKG, a set of corrupted links T' are generated by altering the tail t_e or head h_e of a set of causal links, <h_e, r_c,t_e, Q>, with another causal entity in the KG. Such as replacing the head with $h' \u2260 h_e$ results in <$h'_e, r_c,t_e, Q$> and replacing the tail with $t' \u2260 t_e$ results in <$h_e, r_c,t'_e, Q$>. The model assigns scores to the true link <$h_e, r_c, t_e, Q$> and corrupted links <$h'_e, r_c,t_e, Q$>, <$h_e, r_c,t'_e, Q$> \u2208 T'. The scores are sorted to obtain the rank of the true link. The filtered evaluation setting and filtered corrupted links T' are used to exclude the links present in the training and validation set. The performance of the HyperCausalLP was evaluated using two metrics- Mean reciprocal rank (MRR), and Hits@K (Hits @K, where K=1,3,10). MRR is the mean over the reciprocal of individual ranks of the test links. Hits@k is the ratio of test links present among the top k-ranked links. The higher values of both metrics signify the better performance of the model. The experiments are performed on a server with NVIDIA TESLA V100 GPU (32 GB GPU memory) and Intel Xeon Platinum 8260 CPU @2.40GHz."}, {"title": "Results and Discussion", "content": "To evaluate HyperCausalLP, we first transformed the CEGs (i.e., causal network) in the CLEVRER-Humans dataset to a hyper-relational CausalKG (RQI). The causal links in the hyper-relational CausalKG preserve the structure of the causal relations. The hyper-relational CausalKG from CLEVRER-Humans is then transformed into KG embeddings. We consider two types of embeddings: baseline embeddings (i.e., without mediators as hyper-relations) and mediated embeddings. HyperCausalLP was evaluated on CausalKG generated from the CLEVRER-Humans dataset for causal link prediction tasks using the trained KG embeddings (RQ2). The approach was evaluated on CausalKG-M with StarE with two hyper-relations (i.e., hasMediator and hasMediatorType) along with different CausalKG subgraphs (Figure 6)\nTable 2, Table 1 shows the performance of MRR and Hit@K(k=1,3,10) for five KGE models evaluated on different CausalKG subgraph which demonstrate the use of additional knowledge. The results (i.e MRR, HitK) shows a significant increase in the performance of CausalKG-M over CausalKG-Base, the baseline models with no hyper-relations (or mediator information) and just links ((RQ3)). The CausalKG-Base was evaluated with four KGE models-TransE, DistMult, HolE, and ComplEx. The incorporation of additional knowledge (i.e., CT) in the CausalKG-M across different mediator setup shows improved MRR performance over the simpler C subgraph by 5.47% on average for the causal link prediction tasks ((RQ4)). The incorporating mediators with causal link provides an additional knowledge which is crucial for the causal link prediction task. The hyper-relation, hasMediator and hasMediatorType performs the best comparing the MRRs and Hit@k across the board. We successfully demonstrated the knowledge incorporated in the hyper-relations (qualifies) significantly improves the causal link prediction."}, {"title": "Conclusion", "content": "The paper introduced an approach to finding missing causal link in an incomplete causal network. The HyperCausalLP, a hyper-relational KG based causal link prediction using KG prediction. The proposed method incorporates the mediator information from the CBN as a hyper-relation in the KG. The KGE models trained with qualifier (mediator, or hyper-relations) outperform all baseline KGE metrics without qualifiers. The results demonstrate that an effective fusion of causal links with qualifier (mediator, or hyper-relations) in a KG can facilitate the completion of incomplete causal network. Future work will investigate incorporating a varied number and type of mediators as hyper-relations, which will allow multi-hop causal entity prediction. We would also like to extend the HyperCausalLP with a selection of hyper-relational KG embedding models."}]}