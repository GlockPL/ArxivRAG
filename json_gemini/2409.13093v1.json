{"title": "Guided Profile Generation Improves Personalization with LLMs", "authors": ["Jiarui Zhang"], "abstract": "In modern commercial systems, including Recommendation, Ranking, and E-Commerce platforms, there is a trend towards improving customer experiences by incorporating Personalization context as input into Large Language Models (LLMs). However, LLMs often struggle to effectively parse and utilize sparse and complex personal context without additional processing or contextual enrichment, underscoring the need for more sophisticated context understanding mechanisms. In this work, we propose Guided Profile Generation (GPG), a general method designed to generate personal profiles in natural language. As is observed, intermediate guided profile generation enables LLMs to summarize, and extract the important, distinctive features from the personal context into concise, descriptive sentences, precisely tailoring their generation more closely to an individual's unique habits and preferences. Our experimental results show that GPG improves LLM's personalization ability across different tasks, for example, it increases 37% accuracy in predicting personal preference compared to directly feeding the LLMs with raw personal context.", "sections": [{"title": "1 Introduction", "content": "Within the context of personalization tasks, personal profiling has been extensively employed. Conventional methodologies typically rely on substantial datasets such as graph-based similarities. These profiles often exhibit 'neighborhoods' and 'relationships' within the data, posing challenges for immediate interpretability without supplementary processing. Recently, LLMs have demonstrated robust capabilities in tasks related to reasoning and generation, leading to a growing interest in leveraging LLMs for personalization services. However, distinguished from other Naturual Language Processing (NLP) tasks, we identify two primary challenges in personalization with LLMs.\nThe first challenge is the complexity of personal contexts and the sparsity of their key information. For example, a person's distinctive writing style may only be discernible in a small portion of their writing, whereas the remainder of the writing style tends to be more generic. As is shown in recent studies (Liu et al., 2023b), LLMs have challenges in capturing comprehensive information within lengthy contexts, making it easy to overlook the smaller portions that contain distinctive writing styles. Previous studies (Lewis et al., 2020; Salemi et al., 2023) have attempted to address this challenge by context retrieval. However, context retrievers frequently rely on surface-level ranking strategies, such as keyword similarity. Such an approach, while straightforward, may not always align with the nuanced needs of personalization tasks.\nThe second challenge lies in the balance between generalization and personalization. While LLMs have demonstrated considerable performance on general tasks, they still struggle to generate output that fully aligns with users' desired behaviors and directions (Bang et al., 2023). Rather, they prioritize imitating the majority of their training sets (Karpathy, 2023). Figure 1 illustrates a personalized task involving the paraphrasing of a tweet to match someone's distinctive writing style. From the personal context, it is noticeable that the individual tends to use block letters to emphasize actions and feelings. However, the model closely mirrors the original question input when receiving the personal context and question directly, which can be reachable even without personal context. When we instruct LLM to describe the person's writing style, rather than noticing the spatial use of capitalization, it pays attention to the emotion, and content, which are not our desired 'writing styles'. Steering LLM outputs precisely is always a challenge. To address it, previous work has attempted to apply reinforcement learning from human feed-"}, {"title": "2 Related Work", "content": "LLMs have demonstrated robust performance through scaling up, in-context learning (Brown et al., 2020), reinforcement learning from human feedback (Ouyang et al., 2022), and instruction tuning (Wei et al., 2021), making them capable of complex reasoning tasks (Hendrycks et al., 2020; Srivastava et al., 2022; Jiang et al., 2023a, 2024).\nThe performance of the model is sensitive to input and output manners, making prompt optimization (Yao et al., 2022; Wei et al., 2022; Kojima et al., 2022; Huang et al., 2024) a popular topic.\nThere has been a growing interest in using LLMS for personalization. LLM-Rec (Lyu et al., 2023) utilizes LLMs as recommenders by prompting them with recommendation instructions and employing graph-based engagements. However, this approach lacks emphasis on the crafting of user profiles. LAMP (Salemi et al., 2023) attempts to integrate a context retriever to avoid the need for feeding the entire personal context to LLMs, but the retrieved personal context still proves challenging for LLMs to easily comprehend. PALR (Chen, 2023) uses LLMs to generate user profiles for personalized recommendation and fine-tuned llama (Touvron et al., 2023) to generate ranking. However, the exploration of more effective methods for crafting user profiles in natural language based on personal contexts with diverse structures remains underexplored. Other studies also explore the use of LLMs to augment graph-based recommendation system (Lyu et al., 2023), support human writing creativity (Chakrabarty et al., 2023), personalized writing education (Li et al., 2023a), dialogue systems (Fan and Jiang, 2023) and healthcare assistant (Liu et al., 2023c).\nFor datasets, LAMP (Salemi et al., 2023) introduces seven language tasks that necessitate personalization. These tasks include tweet paraphrasing and email subject generation, among others. Notably, tweet paraphrasing serves as a comprehensive test bed for evaluating personalized writing style imitation using LLMs. Amazon review (He and McAuley, 2016) provides abundant online purchase history and shopping reviews, enabling the creation of a preference prediction dataset for product purchasing. PER-CHAT (Wu et al., 2021) is an open-domain single-turn dialogue dataset collected from Reddit. In PER-CHAT, each dialogue response is paired with related comment history from the same user, enabling personal profile crafting. Other datasets like MovieLens (Harper and Konstan, 2015), Recipe (Majumder et al., 2019), PERSONA-CHAT (Zhang et al., 2018) are also widely used. We evaluate GPG by personalized preference prediction, tweet paraphrasing, and dialogue generation sets in this paper."}, {"title": "3 Guided Profile Generation", "content": "Given a personal context PC, and a task T, the objective of personalization is to align with the individual's behavior and successfully accomplish the task. In contemporary commercial systems, personal profile crafting proves advantages for both accuracy and efficiency, achieved by providing a clear reflection of a person's behavior and ensuring reusability without the need to process the raw context again. Given the impressive capabilities of LLMs, there is a natural inclination to leverage them for integrating raw PC and generating personal profiles. However, our early investigation indicates that these approaches may not achieve the expected performance (Figure 1). Moreover, the lack of human-annotated data for intermediate personal profiles makes direct optimization through fine-tuning a challenging option.\nWe propose GPG, a general method for personalization with LLMs through personal profile generation. The proposed method of GPG is presented in Figure 2. Different from joint learning with downstream personalization tasks for LLM, which adopts Reinforcement Learning from Human Feedback (RLHF), we adopt a much more cost-effective yet efficient method. This method focuses on gener-"}, {"title": "3.1 High-level Workflow", "content": "The first step is Personal Context Digestion. In this step, we pose task-specific questions to the LLM, guiding it to digest PC in our desired direction. For instance, in the scenario of predicting a customer's preferred product based on their purchase history, we prompt the model to sequentially generate product categories. The main purpose of this step is to get direction and key information for the next step. Note that differentiated from few-shot prompting which needs a large amount of in-context corpus crafted by humans, in GPG, only one specific question is designed for each task.\nThe second step is Guided Profile Generation. The response of the previous steps serves as guidance for the generation of the personal profile. Similar to (Li et al., 2023b),\nwe concatenate the PC and guidance as input. We instruct the LLM to generate descriptive sentences serving as the personal profile. In contrast to high-dimensional representations, our profile is explainable, enabling easy diagnosis of inadequacies. Moreover, our profile is language model orthogonal, facilitating broader applications and seamless future development.\nThe final step is Response Generation. The generated personal profile is used to finish the final task. To provide sufficient information, we do not exclude the raw personal context in our main experiment. In section 5, we conduct a detailed experiment study of the effect of the inclusion of PC and guidance."}, {"title": "4 Evaluation Tasks and Metrics", "content": "Our proposed method can be applied to a wide range of personalization tasks to overcome the challenge given by raw personal contexts. In this work, we mainly focus on the task of personalized preference prediction, text paraphrasing, and dialogue continuation."}, {"title": "4.1 Task of Preference Prediction", "content": "In commercial systems, accurately predicting a user's preference is one of the most crucial tasks. This prediction holds the potential to benefit various downstream tasks (e.g., personal recommendation). However, reliance on large databases and specific models, like assessing the similarity between different users, poses limitations. The design of these models often restricts access to additional information, such as the full name and detailed product information on the Internet. Furthermore, these large databases are not always readily accessible for common use. In contrast, LLMs exhibit the"}, {"title": "4.2 Task of Text Paraphrasing", "content": "Though simple for humans, it is underexplored whether LLMs can detect and imitate the text-writing styles for different individuals. Such capability is crucial since in recent times, LLMs have been widely used as writing assistants. In this sec-"}, {"title": "4.3 Task of Dialogue Response Generation", "content": "Besides writing style imitation discussed in section 4.2, the ability of AI assistants to accurately reflect an individual's opinion is also crucial. This task is particularly challenging due to the opinions are often implicit and multifaceted in a raw personal context, and should be selectively employed based on the requirements of different tasks.\nWe focus on dialogue continuation in practice. In particular, we leverage PER-CHAT (Wu et al., 2021) collected from open-domain discussions on Reddit. PER-CHAT collects each individual's comment history, and the task is to use the history as a signal of personal preference and help the individual answer the question. We do not include the retrieved personal profile from the paper for simplicity. To improve the relevance between the comment history and target response, we measure their semantic similarities based on sentence-transformer (Reimers and Gurevych, 2019), and select a subset having a maximum similarity larger than 0.4. We also exclude instances with max similarities larger than 0.6 to avoid overlap between comment history and target response.\nMetrics. We consider semantic level similarity"}, {"title": "5 Experiments", "content": "We use OpenAI's gpt-3.5-turbo-1106 as our major LLM all through the tasks; during inference, we keep the temperature at 0 (greedy decoding) to gain a deterministic result and set max_tokens to 100. We report the result with a single run due to the greedy decoding."}, {"title": "5.1 Baselines.", "content": "For the comparison purpose, we present the following baselines to illustrate the effectiveness of GPG:\n1. Direct Generation without Personal Context. (DG w/o PC) We consider the LLMs' native response to the question since they have been trained on numerous corpus. For example, LLMs could have knowledge about the general tweet writing style, thus having the ability to reshape a sentence to such a style. The input is formalized as {Q}.\n2. Direct Generation with Personal Context. (DG w/ PC) In this baseline, we feed the PC to LLM and ask them directly to generate the answer to our question. The input is formalized as {PC}{Q}."}, {"title": "5.2 GPG Specifications.", "content": "In the task of Preference Prediction, we guide the LLM to generate the personal profile by providing the product categories. To this end, we first ask the LLM \u201cProvide the product category of above one by one, each of them use less than 10 words, split by a comma:", "paraphrasing": "Capitalization, Emoji, Abbreviation, Punctuation. Then we instruct LLM to select the most distinctive features in the personal context, specifically our instruction is: Among the usage of 1. Capitalization, 2. Emoji, 3. Abbreviation, 4. Punctuation, which is the most distinctive feature of the above tweets?. Then LLM will generate the profile based on the self-selected category and use the generated profile together with the guidance to finish the task.\nIn the Dialogue Response Generation Task, We expect the generated personal profile to be a summary of these texting habits and personal opinions. Inspired by the original paper, we instruct LLM to generate the basic personal information from their comment history, the aspects include: \u201cpets\u201d, \u201cfamily\u201d, \u201cresidence\u201d, \u201cfavorites\u201d, \u201cpartner\u201d, \u201cpossessions", "gender\u201d, \u201cself-description": "Then the above aspects are used to craft the personal profile."}, {"title": "5.3 Experimental Results", "content": "Table 1 shows the performance on our Amazon preference prediction dataset of different prompting strategies. LLM improves its performance by 50.23% when adding the personal context to its input. Furthermore, this improvement can be fur-"}, {"title": "6 Analysis and Discussions", "content": "We conduct an ablation study to better understand the benefit of each component of GPG, on preference prediction and text paraphrasing tasks. the result is shown in Table 3. Specifically, we analyze the impact of incorporating personal context (PC), guidance(G, context digestion), and personal profile (PP) during the generation of final response. Next, we will provide a detailed analysis based on the result.\nCan we exclude raw personal context when generating an answer? In our experiment, we initially incorporated the personal context as part of the input to mitigate the risk of information loss. However, in practice, it is inefficient to keep the personal context as input during every run. To this end, we remove the personal context during the final task generation. Compared with the direct generation, GPG improve the performance by 17.53% (absolute) in predicting purchase preference, generations without raw personal context (sixth-row in Table 3) could approximate 61.04% of such improvement, indicating a considerable trade-off between the expense and performance. However, in text paraphrasing, the performance after removing the raw personal context is worse than a direct generation, underlining the higher importance of personal context in text paraphrasing.\nCan personal context digestion directly benefit the downstream tasks? As is shown by our result, personal context digestion can help LLMs generate better descriptive personal profiles. Thus, we are curious whether such a benefit is directly applicable to the final task generation. To this end, we skip the generation of descriptive personal profiles and directly perform downstream tasks after context digestion, the result is shown in the last two rows of Table 3. Surprisingly, the guidance itself is functioning even worse than an unguided personal profile (third row) in both of the tasks, suggesting: 1. Despite being beneficial in enhancing the generation of personal profiles, the guidance itself is not immediately effective for improving the performance of the final task. 2. A descriptive personal profile helps the model be better at personalization."}, {"title": "6.2 Error analysis and Observations.", "content": "Profile Generation helps LLM be more certain about making selections. We find LLMs frequently opt to abstain from responding when faced with uncertain information. To better understand this behavior of LLMs, we select all of the 'abstain' answers and report the ratios of correct, incorrect,"}, {"title": "6.3 Limitation and Future Works", "content": "Integrating multiple aspects personalization.\nOur experiments are conducted on a single source of personal context. In practice, the complete profile of an individual should be drawn from multiple aspects. For example, a person's purchase preference can be related to their gender, age, habit, or even the weather where they live. Due to the difficulty of cross-platform data collection, most of the off-the-shelf personalization data are from a single source. Constructing datasets containing personal contexts from multiple sources for each individual could be interesting. In addition, it is also challenging to integrate data from multiple aspects. While wisely designed mechanisms like graph contrastive learning (Chen et al., 2023) could potentially incorporate different types of information, unifying graph information into natural language is\na lightweight alternative (Zhang et al., 2022; Jiang et al., 2023b), obtaining better explainability at the same time. We believe our findings bring useful insight into this future direction.\nMultimodal personalization. Recently, multimodal large language models (MLLMs) (Dai et al.; Liu et al., 2023a) have shown promising capabilities in various tasks. Such advancement opens the possibility of multimodal personalization. For example, an individual's preference for clothes could be highly related to the designs, which are not easily described by text. In such studies, the undesired and generic MLLM outputs could be a problem, applying a visual crop (Zhang et al., 2023) directed by visual search (Wu and Xie, 2023) as a 'guidance' would be interesting. In addition, other modalities such as sound (Meta AI Research, 2023), and sensor data like heart rates (Ni et al., 2019) are also considerable."}, {"title": "7 Conclusion", "content": "In this work, we present Guided Profile Generation GPG, a novel method leveraging LLMs for personalization tasks through profile generation and context digestion. We conduct extensive experiments on various personalization tasks, including preference prediction, text paraphrasing, and dialogue continuation. Despite the superior performance, GPG generates a personal profile in pure natural descriptive language, which is interpretable and easily diagnosable. Moreover, we reveal why and how the guidance and descriptive personal profile improve the performance. We hope our research can pave the way for personalization applications with AI models in the future."}, {"title": "A Examples of Three Tasks", "content": "In Figure 4, we present examples of the three tasks under our test, we include raw personal context, personal context digestion, and personal profile in each example. The prompts for generating personal context digestion and personal profiles can be found in section 5.2."}, {"title": "B Challenges in Open-Ended Personalization Tasks.", "content": "When addressing open-ended tasks like dialogue continuation, LLMs encounter more challenges in aligning with personal preferences and texting habits. One example is shown in Table 5, where LLMs are trying to give a generic response to the question rather than a personalized one. This tendency aligns with findings reported in (Karpathy, 2023) that LLM would prioritize imitating the majority of their training data. While such a phenomenon is not bad in itself as it helps LLMs leverage huge amounts of data and obtain impressive capabilities, it is not a desired behavior in personalization."}, {"title": "C Statistics of Three Tasks.", "content": "Table 6 presents the statistics of three included tasks. We report the total count of data instances (# Data) and the average number of user activities (# Activities) within each personal context. Specifically, in the Preference Prediction task, # Activities represents the average number of products a user has purchased before. In Text Paraphrasing, it represents the average number of history Tweets. In Dialogue Response Generation, it represents the average number of dialogue responses within the personal context."}]}