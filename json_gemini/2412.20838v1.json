{"title": "DUAL-SPACE AUGMENTED INTRINSIC-LORA FOR WIND TURBINE SEGMENTATION", "authors": ["Shubh Singhal", "Ra\u00fcl P\u00e9rez-Gonzalo", "Andreas Espersen", "Antonio Agudo"], "abstract": "Accurate segmentation of wind turbine blade (WTB) images\nis critical for effective assessments, as it directly influences\nthe performance of automated damage detection systems.\nDespite advancements in large universal vision models, these\nmodels often underperform in domain-specific tasks like\nWTB segmentation. To address this, we extend Intrinsic\nLORA for image segmentation, and propose a novel dual-\nspace augmentation strategy that integrates both image-level\nand latent-space augmentations. The image-space augmenta-\ntion is achieved through linear interpolation between image\npairs, while the latent-space augmentation is accomplished by\nintroducing a noise-based latent probabilistic model. Our ap-\nproach significantly boosts segmentation accuracy, surpassing\ncurrent state-of-the-art methods in WTB image segmentation.", "sections": [{"title": "1. INTRODUCTION", "content": "Operational damages to wind turbine blades (WTBs) can\ngreatly impact their efficiency [1] and may even lead to com-\nplete failure [2]. Regular visual inspections and preventive\nmaintenance are crucial to ensure timely repairs. These in-\nspections are typically conducted using drones that capture\nhigh-resolution images, allowing for detailed analysis to\nguide maintenance decisions [3]. As the wind energy sector\nrapidly expands, the need for automated WTB assessment\nsolutions is increasing, with image segmentation emerging as\na key image processing task in this process [4].\nDeep learning methods, particularly convolutional neural\nnetworks (CNNs), have driven significant advances in image\nsegmentation research. Encoder-decoder architectures [5, 6]\nhave become foundational frameworks by effectively captur-\ning and reconstructing spatial relationships. Some notable\nmodels like DeepLabv3+ [7] and ResNeSt [8] achieve re-\nmarkable success by utilizing atrous convolutions and multi-\nscale feature extraction techniques. The integration of atten-\ntion mechanisms with CNNs, such as U-NetFormer [9], have\nfurther enhanced segmentation capabilities by improving\nglobal context understanding [10, 11]. In the realm of WTB\nsegmentation, these advancements have inspired tailored\nmodels like BU-Net [4], which incorporates a post-processing\nhole-filling algorithm to refine segmentation results.\nThere has been growing interest in universal image seg-\nmentation models trained in a zero-shot manner using vast\namounts of data, particularly large vision models like SAM\n[12] and DINO [13]. These models employ self-supervised\nvision transformers that learn meaningful representations\nfrom data through self-attention mechanisms. However, in\npractical applications, these universal segmentation methods\noften underperform compared to state-of-the-art models and\ncannot be trained directly due to the lack of comprehensive\ndatasets. Intrinsic LoRA [14] presents a promising approach\nby fine-tuning generative models trained on large datasets,\nenabling supervised learning with minimal labeled data.\nIn this work, we extend Intrinsic LORA for image seg-\nmentation and demonstrate its effectiveness in a real-world\napplication. Specifically, we adapt pretrained Stable Diffu-\nsion models [15] for WTB segmentation by modifying the\nsegmentation masks to meet the dimensional requirements of\nthe pretrained model. These initial results, however, produce\nsuboptimal performance. To address this, we explore sev-\neral augmentation techniques. Initially, we apply traditional\ndata augmentation methods to the input images [16, 17, 18],\nwhich prove particularly effective. Then, inspired by prior re-\nsearch that stabilizes the training of generative models in the\nlatent space [19, 20, 21], we introduce a Bayesian adaptation\nof Intrinsic LoRA for image segmentation, modeling the la-\ntent vectors in a probabilistic augmented framework. By inte-\ngrating both image-level and latent-space augmentations (see\nFig. 1), our dual-space augmentation approach substantially\nimproves segmentation performance, surpassing state-of-the-\nart methods in WTB segmentation by a large margin."}, {"title": "2. METHODOLOGY", "content": "This section outlines our adaptation of the Intrinsic LoRA [14]\nmethod for image segmentation. We begin by reviewing the\ncore principles of Intrinsic LoRA and its application in ex-\ntracting image intrinsics. Next, we proceed by illustrating\nhow we tailored this approach to create segmentation maps.\nFinally, we propose a novel dual-space augmentation method\nthat operates in both image and latent spaces."}, {"title": "2.1. Intrinsic LORA", "content": "Intrinsic-LoRA [14] harnesses the implicit understanding\nof image intrinsics within generative models to produce\nhigh-quality supervised outputs. By introducing learnable\nLORA [22] adaptors 0, an image-to-image generative diffu-\nsion model can be fine-tuned with minimal labeled samples\nto generate the desired outputs $y \\in \\mathbb{R}^{H \\times W \\times 3}$.\nGiven a pretrained Stable Diffusion model [15], the in-\nput image $x \\in \\mathbb{R}^{H \\times W \\times 3}$ is encoded by the encoder E to a\n(E)\nlower-dimensional latent space $z_x = E(x)$. The obtained\nlatent vector $z_x^{(E)}$ is fed to the denoising U-Net [23] model U$\\theta$\nalong with a text prompt t. This prompt is the image intrin-\nsic to be extracted like \"depth\", \"normal\" and so forth, and is\nencoded by a pretrained CLIP [24] tokenizer T, obtaining the\ntransformed output latent vector $z_x^{(U)} = U_\\theta(z_x^{(E)}, T(t))$.\nIntrinsic-LoRA adapts the diffusion model to a supervised\ntask by optimizing the LoRA adaptors on top of the self- and\ncross-attention layers [25] of a single step dense predictor U-\nNet model. The adaptors are optimized to minimize the\ndifferences between the transformed latent vector $z_x^{(U)}$ and\nthe encoded ground-truth $z_y^{(E)} = E(y)$:\n$\\min_\\theta E_x[d(z_x^{(U)}, z_y^{(E)})]$,\n(1)\nwhere d is a specific-task dissimilarity metric. Finally, the\ndecoder D transforms back $z_x^{(U)}$ to the image space, obtaining\nthe predicted intrinsic map $\\hat{y} = D(z_x^{(U)})$. Both the encoder\nE and decoder D are frozen during training."}, {"title": "2.2. Segmentation-based Intrinsic LoRA (SI-LORA)", "content": "Intrinsic LoRA is built upon image-to-image generative mod-\nels, thus, it handles 3-channel inputs and outputs. However, in\nour image segmentation problem, we need to distinguish be-\ntween background and foreground, requiring a single-channel\noutput. Hence, we define y as the concatenation along the\nthird dimension of the ground-truth segmentation mask $m \\in\n\\mathbb{R}^{H \\times W}$. Similarly, the model's decoded output $\\hat{y}$ remains a 3-\nchannel image, which we convert back into a single-channel\nmask $\\hat{m}$ by averaging across the three channels $\\hat{y}_c$, obtaining\n$\\min_\\theta E_x [MSE(z_x^{(U)}, z_y^{(E)}))], \\quad y = m \\otimes 1_3, \\quad \\hat{m} = \\frac{1}{3} \\sum_{c=1}^3 \\hat{y}_c,$\n(2)\nwhere $1_3$ is a 3-dimensional vector of ones, and $\\otimes$ denotes\nthe outer product. Additionally, two adjustments were made\nto ensure effective segmentation: the dissimilarity metric d"}, {"title": "2.3. Dual-space Augmentation (DSA SI-LORA)", "content": "After successfully adapting the Intrinsic-LoRA method for\nour segmentation task, we shift our focus to enhance its per-\nformance. Data augmentation techniques in the image space\nhave been widely explored and implemented to improve\nlearning-based models [17, 18]. One particularly notable\nmethod is MixUp [16], which generates synthetic images\nthrough the linear interpolation of multiple samples. Specif-\nically, given two images and their corresponding labels from\nthe training set, $(x_1, m_1)$ and $(x_2, m_2)$, MixUp produces a\nnew augmented sample $(x', m')$ as follows:\n$x' = \\lambda x_1 + (1 - \\lambda)x_2, \\quad m' = \\lambda m_1 + (1 - \\lambda)m_2,$\n(3)\nwhere $\\lambda \\in [0, 1]$ is a mixing coefficient sampled from a Beta\ndistribution with parameters $\\alpha, \\beta = 0.4$, which governs the\ninterpolation between the two images and their labels.\nWhile these techniques have proven effective, our contri-\nbution lies in extending augmentation to the latent space. Tra-\nditional diffusion models operated in the image space, how-\never, Stable Diffusion demonstrated the effectiveness of shift-\ning the diffusion process to the latent space [15]. Drawing\ninspiration from this and VAEs [26], we augment the training\nby parametrizing the latent vector $z_x^{(E)}$ as a Bayesian input for\nthe U-Net U$\\theta$. In particular, the augmented $z_x^{\\prime (E)}$ is modeled\nas an isotropic Gaussian with an identity covariance matrix:\n$z_x^{\\prime (E)} \\sim \\mathcal{N}(E(x'), I_d)$.\n(4)\nThis probabilistic approach enhances the U-Net's robust-\nness by accommodating a wide range of latent inputs, instead\nof relying solely on deterministic encodings. To manage the\nstochastic nature of the sampling during backpropagation, we\nreparameterize the sampling process to a fixed base distribu-\ntion. Consequently, the augmented latent input $z_x^{\\prime (E)}$ is com-\nputed by introducing a noise variable $\\epsilon$, drawn from a stan-\ndard multivariate Gaussian distribution:\n$z_x^{\\prime (E)} \\leftarrow E(x') + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I_d)$.\n(5)\nAn overview of Segmentation-based Intrinsic LoRA (SI-\nLORA) with dual-space augmentation is illustrated in Fig. 2."}, {"title": "3. EXPERIMENTAL RESULTS", "content": "In the following section, we first present the implementation\ndetails used to successfully train our model, along with the\ndataset employed. Next, we provide an in-depth evaluation of\nthe performance of SI-LoRA, including each data augmenta-\ntion strategy. This is followed by qualitative assessments that\nhighlight the effectiveness of our dual-space augmented SI-\nLORA. We then compare our model with various state-of-the-\nart segmentation algorithms. Finally, we demonstrate its ro-\nbustness by comparing its performance across different wind-\nfarms in the test set, showcasing exceptional results across\ndiverse environments."}, {"title": "3.1. Dataset and Implementation Details", "content": "The dataset utilized to train (1712 images) and evaluate (320\nimages) the proposed method is taken from [4]. The input\nimages and ground-truth segmentation masks are resized to\n512x 512. Decoupled regularization [27] with a weight de-\ncay of $10^{-2}$, an initial learning rate of $10^{-4}$ and a batch size\nof 2 is employed. The training is stopped after 30 epochs.\nFor LoRA adaptors, we choose the rank 8, consistent with\nthe original study [14]. For generating binary masks, we use\nOtsu's method to threshold the model predictions. The exper-\niments were performed on an NVIDIA GeForce RTX 3090."}, {"title": "3.2. Ablation Study", "content": "Ablation studies were conducted to better understand the in-\ndividual contribution of different augmentation techniques\nin the image and latent space. We compare four different\nmodel configurations: (1) SI-LORA (Sec. 2.2) without data\naugmentation, (2) SI-LoRA with image-space augmentation\nimplemented in terms of MixUp [16], (3) SI-LORA with\nlatent-space augmentation implemented in terms of noise-\nbased probabilistic model (Sec. 2.3), and (4) SI-LORA with\nboth image- and latent-space augmentation. Distinct metrics\nare evaluated to highlight the contributions of each data aug-\nmentation strategy, including the overall performance metrics\nof accuracy, recall, F1-score, and mean IoU (mIoU).\nTab. 1 showcases that applying no augmentation tech-\nniques (row 1) results in the lowest performance across all\nmetrics, serving as a baseline for comparison. Introducing\nlatent-space augmentation alone (row 2) shows a significant\nimprovement in all metrics, particularly a 22.03% increase in\nF1-score and a 20.48% improvement in mIoU. This suggests\nthat augmenting the latent space helps the model generalize\nbetter by simulating diverse, realistic variations in feature\nrepresentations. When only image-space augmentation is\napplied (row 3), the model further boosts performance, effec-\ntively enriching the training data with more variability. Fi-\nnally, combining both augmentation strategies (row 4) yields\nthe highest performance across all metrics, with an accuracy\nof 99.15%, F1-score of 98.84%, and an mIoU of 97.69%.\nThese results demonstrates the synergistic benefits of apply-\ning both image- and latent-space augmentation techniques in"}, {"title": "3.3. Qualitative Evaluation", "content": "To qualitatively illustrate the segmentation masks produced\nby various augmentation strategies, Fig. 3 presents five exam-\nples where dual-space segmentation is essential for achieving\nhigh-quality results. As discussed in Sec. 3.2, SI-LORA strug-\ngles to generate smooth maps, leading to poor segmentation\nin many instances. While SI-LORA can detect some edges\nof the wind turbine structure (see the second and third exam-\nples in Fig. 3), it fails to identify all the turbine components,\nfocusing only on a single section.\nWhen applying image- or latent-space augmentation, we\nobserve that SI-LORA produces smoother maps, and the gen-\nerated masks include the inner regions of the wind turbine\nblade (WTB), rather than just outlining the structure's edges.\nHowever, even with this improvement, SI-LORA still falls\nshort of fully capturing all parts of the wind turbine, as seen\nin all five instances. By combining both augmentation strate-\ngies, the model effectively resolves these challenging cases,"}, {"title": "3.4. Quantitative Evaluation", "content": "To evaluate our proposed method, we conducted a compar-\native analysis as shown in Tab. 2, benchmarking SI-LORA\nagainst popular segmentation models. The evaluation was\nperformed on a test set of 200 turbine images from various\nwindfarms [4]. In its initial form, SI-LoRA underperformed\nacross all metrics, lagging behind all competing models. This\nwas primarily due to overfitting on the training masks, which\nsignificantly hindered its ability to generalize to newly ac-\nquired, unseen test images. This limitation prompted us to\nexplore augmentation techniques aimed at enhancing its per-\nformance and generalization capabilities.\nBy introducing dual-space augmentation (DSA), combin-\ning MixUp [16] for image-space variability with noise-based\nprobabilistic models for latent-space diversification, we de-\nveloped DSA SI-LORA. As shown in the table, DSA SI-LORA\ndramatically outperforms the original SI-LoRA, surpassing\nstate-of-the-art models by a large margin across all major met-\nrics, except precision. These results highlight the effective-\nness of our augmentation strategies in enhancing generaliza-\ntion and overall performance, overcoming overfitting and im-\nproving segmentation models' robustness in real-world appli-\ncations. This demonstrates that pretrained generative models\ncan be efficiently fine-tuned with limited data to perform real-\nworld supervised tasks, such as WTB segmentation."}, {"title": "3.5. Windfarm Dissimilarity", "content": "The test dataset used in our study comprises 20 images from\nvarious windfarms [4], captured using different drone con-\nfigurations and locations. To evaluate the robustness of dual-\nspace augmented SI-LORA (DSA SI-LORA), Fig. 4 presents a\nboxplot illustrating the performance across 10 distinct wind-\nfarms. This figure offers insights into the robustness of DSA\nSI-LORA in WTB image segmentation.\nThe boxplot reveals consistently high average perfor-\nmance metrics, including accuracy, F1-score, and mIoU, with\nminimal variability in performance distribution. These results\nindicate that DSA SI-LoRA effectively generates accurate\nmasks across a range of input environments."}, {"title": "4. CONCLUSION", "content": "In conclusion, this paper presents a significant advancement\nin wind turbine blade (WTB) image segmentation through\nthe development of the dual-space augmented Segmentation-\nbased Intrinsic LORA (SI-LORA). By extending the capabili-\nties of Intrinsic LoRA to image segmentation and employing\nan innovative dual-space augmentation strategy, our method\nfine-tunes generative pretrained models using minimal data,\naddressing the limitations of large vision universal models\nin specialized domains. In particular, the dual-space strat-\nergy integrates linear interpolation in the image space and\nprobabilistic augmentation in the latent space, leading to\nsubstantial improvements in segmentation accuracy. Our ex-\nperiments demonstrate that dual-space augmented SI-LoRA\nconsistently outperforms existing state-of-the-art models in\nWTB segmentation, delivering robust performance across\nwindfarms. These results highlight the potential of SI-LORA\nas a powerful tool for improving the automation and reliabil-\nity of wind turbine maintenance, ultimately contributing to\nthe sustainability and efficiency of wind energy operations."}]}