{"title": "Versatile Incremental Learning: Towards Class\nand Domain-Agnostic Incremental Learning", "authors": ["Min-Yeong Park", "Jae-Ho Lee", "Gyeong-Moon Park"], "abstract": "Incremental Learning (IL) aims to accumulate knowledge\nfrom sequential input tasks while overcoming catastrophic forgetting.\nExisting IL methods typically assume that an incoming task has only\nincrements of classes or domains, referred to as Class IL (CIL) or Do-\nmain IL (DIL), respectively. In this work, we consider a more challeng-\ning and realistic but under-explored IL scenario, named Versatile In-\ncremental Learning (VIL), in which a model has no prior of which of\nthe classes or domains will increase in the next task. In the proposed\nVIL scenario, the model faces intra-class domain confusion and inter-\ndomain class confusion, which makes the model fail to accumulate new\nknowledge without interference with learned knowledge. To address these\nissues, we propose a simple yet effective IL framework, named Incremen-\ntal Classifier with Adaptation Shift cONtrol (ICON). Based on shifts\nof learnable modules, we design a novel regularization method called\nCluster-based Adaptation Shift control (CAST) to control the model to\navoid confusion with the previously learned knowledge and thereby ac-\ncumulate the new knowledge more effectively. Moreover, we introduce an\nIncremental Classifier (IC) which expands its output nodes to address\nthe overwriting issue from different domains corresponding to a single\nclass while maintaining the previous knowledge. We conducted exten-\nsive experiments on three benchmarks, showcasing the effectiveness of\nour method across all the scenarios, particularly in cases where the next\ntask can be randomly altered. Our implementation code is available at\nhttps://github.com/KHU-AGI/VIL.", "sections": [{"title": "1 Introduction", "content": "Recently, Incremental Learning (IL) strategies [3\u20136,8,9,11\u201313,17,19,20,23,24,26,\n28, 29, 33, 34, 36, 37, 39\u201341,41] have made significant progress in leveraging deep\nneural networks in a situation when multiple input tasks arrive sequentially. The\nmain challenge of IL is catastrophic forgetting [18], which refers to a phenomenon\nin the model that significantly forgets what it has learned previously. The main-\nstream scenarios to tackle catastrophic forgetting within IL typically fall into\ntwo categories: Class IL (CIL) where tasks possess disjoint label spaces within\nthe same domain (see Figure la, and Domain IL (DIL) where tasks share the\nsame label space but exhibit distinct distributions (see Figure 1b. Most of the\nrecent IL studies have focused on either CIL or DIL scenarios [6, 29, 34, 36, 37].\nThese existing settings are based on a strong assumption that sequential\ninput tasks always share the same classes or domains, i.e., only classes or domains\ncan increase, and this assumption makes the existing methods impractical to\napply to the real world. For example, the models for self-driving cars should\ncontinuously learn increasing classes of objects while the domains where a car lies\ncontinuously change by different environments (e.g., weather conditions, regions,\netc.). Therefore, the models need to learn new classes or domains sequentially\nwhen they cannot expect what will increment afterward. Yet, this situation is\nunder-explored in the existing IL settings although it is crucial for the model\nfunction well in real-world scenarios.\nIn this paper, to alleviate the aforementioned assumption, we introduce a new\nIL scenario called Versatile Incremental Learning (VIL) for the first time,\nwhich is more challenging and realistic than the existing CIL or DIL settings.\nVIL aims to deal with a situation where the incoming tasks can contain new\nclasses in the same domain, the same classes in a new domain, or new classes\nin a new domain. In the VIL setting, the model encounters new tasks without\nknowing how these tasks will increase, as depicted in Figure 1c. In this class and\ndomain-agnostic incremental scenario, the goal is for the models to learn how to\naccumulate task-specific knowledge continuously without forgetting, regardless\nof the incremental type of incoming tasks.\nTo investigate how the novel VIL scenario is challenging, we conducted ex-\nperiments on three different datasets. As shown in Figure 2, existing CIL and\nDIL methods fail in the VIL scenario. We analyze that existing CIL methods\nface severe drift in the classifier while learning new domains that share the same\nclasses. In the case of DIL methods, they fail on VIL due to inter-domain class\nconfusion, which is caused by their strong assumption of increasing only the do-"}, {"title": "2 Related Work", "content": "More Realistic IL Scenario. Recently, cross-domain IL, which sequentially\nlearns classes from different domains, has begun to be studied [1,27,35,38]. This\nis a more difficult and realistic scenario than traditional class IL or domain IL,\nbecause the large domain gap between each task, coupled with the learning of\ndiscrete classes for each task, poses challenges for knowledge transfer. However,\nthe existing methods [1,27,35] restrict this setting in which each subsequent task\nalways has unseen classes on different domains. Another work [38] considers\nthe setting that early tasks have only increasing classes, and the others have\nonly increasing domains. This setting does not consider that classes or domains\ncan increase at any time in the real world. In this paper, we introduce a more\nrealistic and general scenario where the model learns consecutive tasks without\nprior knowledge of how inputs will increase. The absence of prior knowledge\nregarding the increment type allows the VIL scenario to encompass not only\ntraditional IL scenarios (CIL and DIL) but also more realistic cross-domain IL\nas a subset of task streams.\nRegularization for IL. Regularization methods for IL have evolved to pre-\nvent catastrophic forgetting by adding regularization terms with reference to\nthe old model. In general, the existing regularization methods can be catego-\nrized into weight regularization and function regularization [32]. EWC [9], SI [4],"}, {"title": "3 Method", "content": "In this section, we propose a simple yet effective incremental learning frame-\nwork named ICON to address the problems of VIL aforementioned. We first\nintroduce the proposed VIL scenario and briefly review the problems that derive\nfrom the under-explored VIL scenario in Section 3.1. Next, we propose two novel\nmethods: Cluster-based Adaptation Shift Control (CAST) and Incremental Clas-\nsifier (IC) in Section 3.2 and Section 3.3, respectively. Finally, we describe the\nwhole training scheme with an optimization objective in Section 3.4."}, {"title": "3.1 Scenario Description of VIL", "content": "Previously, the types of IL can be categorized into CIL and DIL, which have\nlimitations in that they assume that what will increase in the next task compared\nto the current task is fixed with class or domain. However, in the real-world, class,\ndomain, or both can be increased at a time. Therefore, we introduce a new IL\nscenario named Versatile-Incremental Learning (VIL) which better suits for the\nreal-world. In the VIL scenario, only classes, only domain or both can increase\nin the very following task and we describe each scenario in Table 1 and illustrate\nit in Figure 1. As shown in Table 1, the existing CIL setting is fixed to have only\ndisjoint label space, and the DIL setting is fixed to have only disjoint domain\nspace. However, in a task stream of VIL, two sequential tasks can have disjoint\nlabel space, disjoint domain space, or both. In these differences, the model in\nthe VIL scenario suffers from the problems as follows.\nIn the proposed VIL scenario, the model fails on VIL due to intra-class do-\nmain confusion and inter-domain class confusion that is derived from the ever-\ndynamically changing input distribution. Furthermore, the model faces severe\ndrift in the classifier while learning new domains that share the same classes.\nTo address these problems, we propose Cluster-based Adaptation Shift con Trol\n(CAST) to prevent model confusion and Incremental Classifier (IC) to prevent\nweight drift from different domains corresponding to a single class. We precisely\nexplain each proposed method in the following sections."}, {"title": "3.2 Cluster-based Adaptation Shift Control", "content": "In existing CIL and DIL scenarios, the model can accumulate knowledge steadily\nwithout any guidance about updating directions of learnable weights since do-\nmains or classes are shared for the entire tasks, which makes the accumulation\nof knowledge easier. However, in the VIL scenario, there is no prior knowledge\nof what will increment and what will remain stationary in the following task\nwhether it is classes or domain. Consequently, this makes it difficult to accu-\nmulate knowledge in a steady direction along the entire tasks. Therefore, it is\nnecessary to have guidance for a model about how to accumulate the knowledge\npreventing its current shift from moving capriciously. Here, we propose Cluster-\nbased Adaptation Shift conTrol (CAST) loss for this sake.\nIn order to learn the current task without affecting the various knowledge\nlearned previously, we regularize the direction of updates in current adapters\nwith respect to the directions of updates in previous tasks. For this sake, the\nmodel saves weights of adapters $A_{t-1}^{prev}$ before learning task t-1 as shown in\nFigure 4. After learning task t - 1, $V_{t-1}$ which we define as the shift in adapter\nwhile learning the task is measured by subtracting $A_{t-1}^{prev}$ from $A_{t-1}^{after}$, where\n$A_{t-1}^{after}$ is the adapter weights after learning task t \u2212 1 as follows:\n$V_{t-1} = A_{t-1}^{after} - A_{t-1}^{prev}$.\nHere, the subscripts of A and V indicate the task identity, while the superscripts\nof A indicate the status with regard to the current task. The shift $V_{t-1}$ in the\ndirection of task t-1 is then saved to a shift pool. As shown in Figure 4, the shift\npool saves all previous shifts obtained after learning each task. It is followed by\nclustering the entire shifts in the shift pool saved until task t-1 using the K-\nMeans algorithm. Then, when training the following task t, the shift of adapter\nfor current iteration i, $V_t$ is calculated using the current weights of adapter A\nfor each iteration. Here, we define the shift in the direction of current learning\nin comparison with the state before the beginning of the task t as follows:\n$V_t = A_i^{after} - A_i^{prev}$,\nwhere $A_i^{prev}$ is the adapter weights before learning task t.\nThe subtraction of weights implies the meaning of the direction of learning\nthe task, and it can be derived from the formula of classic gradient descent for\nparameter update as follows:\n$A_i^{t+1} = A_i^t - \\eta \\frac{\\partial L}{\\partial A_i^t}$, $A_i^t = A_i^{t-1} - \\eta \\frac{\\partial L}{\\partial A_i^{t-1}}$.\nFrom Equation 3,\n$A_i^t = A_i^0 - \\eta \\sum_{k=0}^{i-1} \\frac{\\partial L}{\\partial A_i^k}$.\n. $V_i = A_i^t - A_i^{prev} = A_i - A_i^0 = -\\eta \\sum_{k=0}^{i-1} \\frac{\\partial L}{\\partial A_i^k}$.\nWe can replace $A_i^t$ using $A_i^{t-1}$, and after successive replacement from $A_i^t$ to $A_i^0$,\nthe subtraction of two weights is expressed in the form of summation of gradients,\nwhich is accumulated gradients. Therefore, by simply subtracting two weights,\nwe can utilize the shift in the direction of the current iteration with regard to\nthe state before learning task t.\nAfter the calculation of $V_i$, the model predicts the index of the cluster which\n$V_t$ belongs to for each iteration among clusters established via K-Means before\nlearning task t. The prediction is done by selecting a cluster whose center is\nthe closest with $V_i$. The cluster that $V_t$ belongs to is notated as $S_t$, and other\nclusters as $S_t'$. The shifts that belong to the rest of clusters $S_t'$ represent the di-\nrections of previous tasks whose directions are distinctive from current learning.\nTherefore, to prevent the direction of current learning $V_t$ from colliding with\nthose directions, they are used to regularize the current learning. The regular-\nization of the direction of current learning is done by making $V_t$ to be orthogonal\nwith shifts in $S_t'$. Finally, the equation for CAST loss is defined as follows:\n$L_{CAST} = \\sum_j \\frac{V_iV_j}{||V_i||||V_j||} w_j = \\sum_{V_j \\in S_t'} w_j \\frac{||V_i - V_j||^2}{\\sum_{V_k \\in S_t'}||V_i - V_k||^2}$.\nwhere $V_j \\in S_t'$, $S_t' = \\{V_1, V_2, ...,V_{t-1}\\} \u2013 S_t$. We consider all shifts in $S_t'$\nusing weighted sum in the loss, with $w_j$ being acquired using Euclidean distance\nbetween $V_t$ and $V_j$ in $S_t'$, thereby considering the discrepancy of current shift\nand each $V_j$ differentially. As a result, the CAST loss leads the current shift not to\naffect the shifts in the shift pool while adapting to the current task. Specifically,\nthe updates of weights in the current task are adjusted in the direction that\npreserves the direction of disparate tasks, while fine-tuning. Hence, the model\ncan accumulate knowledge in a stable direction with regard to all tasks, even\nwhen the input tasks change arbitrarily. As the sequence of tasks increases, the\nmodel can further benefit from CAST by regularizing the direction of shifts and\nthereby accumulating knowledge in succession."}, {"title": "3.3 Incremental Classifier", "content": "In the proposed VIL scenario, the existing CIL methods have not considered\nthe same class in different domains, resulting in a forgetting problem due to the"}, {"title": "5 Conclusion", "content": "In this work, we proposed a new IL scenario named Versatile Incremental Learn-\ning (VIL), that reflects a more complex real-world derived from random incre-\nmental streams (classes, domains, or both) without any incremental prior knowl-\nedge. We defined the key challenges in VIL and proposed a novel framework,\ncoined ICON (Incremental Classifier with Adaptation Shift cONtrol), composed\nof Cluster-based Adaptation Shift conTrol (CAST) loss and Incremental Classi-\nfier (IC). We demonstrated that ICON showed SOTA performance in the pro-\nposed VIL, as well as existing IL scenarios, and its effectiveness through various\nexperiments. We look forward to our proposed VIL scenario serves as a new\nstarting point for real-world IL field.\nNevertheless, there is still room for improvement in our work, especially re-\ngarding the scenario. A scenario that considers a varying number of classes and\ndomains in a task can deal with a more realistic scenario, since in real-world,\nthe distributions of classes and domains in a task can change."}]}