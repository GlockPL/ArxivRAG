{"title": "BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks", "authors": ["Sushilkumar Yadav", "Irem Bor-Yaliniz"], "abstract": "Federated Learning (FL) has emerged as a transformative approach in healthcare, enabling collaborative model training across decentralized data sources while preserving user privacy. However, performance of FL rapidly degrades in practical scenarios due to the inherent bias in non Independent and Identically distributed (non-IID) data among participating clients, which poses significant challenges to model accuracy and generalization. Therefore, we propose the Bias-Aware Client Selection Algorithm (BACSA), which detects user bias and strategically selects clients based on their bias profiles. In addition, the proposed algorithm considers privacy preservation, fairness and constraints of wireless network environments, making it suitable for sensitive healthcare applications where Quality of Service (QoS), privacy and security are paramount. Our approach begins with a novel method for detecting user bias by analyzing model parameters and correlating them with the distribution of class-specific data samples. We then formulate a mixed-integer non-linear client selection problem leveraging the detected bias, alongside wireless network constraints, to optimize FL performance. We demonstrate that BACSA improves convergence and accuracy, compared to existing benchmarks, through evaluations on various data distributions, including Dirichlet and class-constrained scenarios. Additionally, we explore the trade-offs between accuracy, fairness, and network constraints, indicating the adaptability and robustness of BACSA to address diverse healthcare applications.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements on user equipment, sensors, processors and AI methods are transforming healthcare by generating and processing large volumes of granular data [1]. However, burdens of preserving the privacy of data and transferring local data to a centralized server to be processed creates many challenges. On the one hand, privacy-preserving distributed AI methods, such as Federated Learning (FL), hit two birds with one stone by allowing the participants to share the trained models instead of raw data, which are compact in size and protects data privacy [2]. On the other hand, FL provides comparable results to that of centralized machine learning methods solely under ideal conditions [3]\u2013[5], and that is rarely the situation in practical applications. The participating devices would have non-homogeneous data distributions [4], [6], different computation capabilities [7], unstable communication channels and additional constraints due to their unique limitations, such as battery level. Among many practical considerations, the focus of this study is data heterogeneity, i.e., non-IID data distributions among clients. Non-IID data may be formed due to a variety of factors, including data size imbalance, for example when a hospital is data-rich whereas some clinics have scarce data, and/or data partitioning imbalance, where clients do not have complete data sets in terms of labels and/or features as illustrated in Fig. 1 via clients with different health concerns [1], [8]. There are recent attempts to develop metrics and a through understanding of heterogeneity from the perspective of FL [9], however, none of the metrics in the literature are widely adopted by the community yet. Two benchmark studies in FL with non-IID distributions rely on random client selection [10], [11]. On the contrary, recent studies in [12]\u2013[15] employ various client selection (or model combination) strategies to mitigate adverse effects of non-IID data. However, these studies depend on the existence of auxiliary IID data, e.g., by collecting a subset of data from clients. The studies in [16], [17] require users to share data characteristics, e.g., distribution of classes and number of samples, to select a statistically favorable client set. Both data collection in the former studies and exposure data characteristics in the latter ones are privacy violations. Instead, studies in [18] and [7] investigate model characteristics for client selection. For example, [18] reduces communication cost and increases accuracy by clustering IoT users based on cosine difference among local models while considering strict networking constraints. However, the proposed architecture necessitates existence of devices that can serve as cluster heads and create new vulnerabilities against adversarial attacks. On the contrary to the limitations of previous studies, the proposed method can estimate the class distribution without additional data or architectural constraints by only investigating model parameters to reveal bias of clients with inspiration from the recent explainable-AI (XAI) studies. We then formulate the client selection problem as a mixed-integer non-linear optimization and use the bias estimations to obtain the most class balanced group while considering fairness among clients. We show that the proposed bias-aware client selection algorithm (BACSA) provides robustness and efficiency against non-IID data without exploiting or exposing clients, and therefore a suitable method to be used in healthcare applications.\nThe rest of the paper is organized as follows. Background information and notations are introduced in Sec. II, followed by the presentation of the proposed method in Sec. III. Then we show the effectiveness of BACSA via experiments in Sec. IV, and conclude the paper with final discussions and future work in Sec. V."}, {"title": "II. PRELIMINARIES", "content": "The following is the terminalogy used regarding data sets [17]:\n\u2022 Local dataset means the local dataset owned by the clients. In this study, it is assumed that the local datasets are heterogenous both in terms of number of sample sizes and the distribution of the sample size over the classes. Therefore, the local data sets are both size imbalanced and class imbalanced. Class imbalance includes one or more data-rich classes, one or more classes with data scarcity and one or more absent classes for each client.\n\u2022 The aggregation of the local dataset from all the clients forms the global dataset. Global dataset is assumed to be class balanced, which means that all classes exist in the global set.\n\u2022 Grouped dataset is the dataset formed after selecting the clients. The goal is to make the grouped data set as balanced as possible in terms of both class and size.\nWe assume there are K clients of an FL scheme, and there is one central server to operate FL. Let $E(W)$ be the error function associated with the global objective function, $F(W)$ where W indicates the model. The central server has an initial model $W_o$, which must be distributed to each client, k, for them to train the model on their local data set $D_k$. Once the trained initial model by a client k, $W_k$, is receieved, bias towards each class $B_{ik}$, can be estimated as the proportion of number of samples from each class as shown in Sec. III-B. Assume a neural network with one input layer with $I + 1$ input nodes, one output layer with $M + 1$ nodes, and $S$ hidden layers with $L + 1$ nodes. Also let $r, s$, and $u$ denote input layer, hidden layers, and output layer, respectively. Then, let $x^{(r)}_i$ represent a neuron $v$ at the $r$th input layer, and $[w^{(m)}_1, w^{(m)}_2,..., w^{(m)}_{M+1}]$ represent the vector of last layer weights. Let $D_k = {d_1, d_2, ..., d_j, ..., d_{N_k} }$ be the data samples of client k, where $|D_k| \\approx N_k$ is the total number of samples of client k, and j indicates data samples throughout this paper. Then, the total number of samples available globally is $N \\approx \\sum_{k=1}^K N_k$. The global set of classes is defined as $C = {C_1, C_2, ..., C_i}$, where $|C_k| \\equiv \\Gamma$ indicates the total number of classes. Furthermore, $P_{ik}$ indicates true proportion of class i in $D_k$, as defined in Sec. III-B. For a class $c_i$, the true and predicted labels are indicated by $y_i$ and $\\hat{y_i}$, respectively. A binary variable $A_k$ is used to indicate whether a client k participates in the current communication round, t."}, {"title": "III. METHODOLOGY", "content": "In order to combat non-IID data with both class partition and data size disparities, multiple issues need to be addressed as discussed so far. Therefore, the proposed model has four parts:\n\u2022 A specific weight initialization for $W_o$ which is shown to help with bias removal and increase accuracy compared to random weight initialization,\n\u2022 The bias detection method which indicates the data-rich, scarce or absent classes in local data,\n\u2022 Fixing the number of local samples that are used by each client to train the model, which prevents the bias of data-rich clients and/or classes, and\n\u2022 Client selection based on the detected bias to select a subset of clients whose models provides minimum bias after aggregation.\nPrior to training, last layer weights of the initial global model, $W_o$ are initialized as follows:\n$W_o = \\frac{1}{\\sqrt{ I_f \\times L \\times M }},$\t\t\t\t(1)\nwhere $I_f$ is the number of input features, M is the number of neurons in the output layer, and L is the number of neurons in the second last layer. The typical value range in (1) is lower than random values used in the state-of-the-art methods, such as Xavier-Glorot [19] and He [20], and ensures to capture the gradient change. In Sec. IV, we show the improvement in both bias detection and prediction accuracy with Monte Carlo simulations.\nLet $\\hat{y_i}$ be the predicted label and let $y_i$ be the true label for a particular class i, and $a_i^{(s)}$ indicate the activation output for a sample $d_j$. For a particular client $k^1$,\n$\\frac{\\partial E}{\\partial w_{i,j}^{(u,s)}} = (y_{ij} - y_i) a_i^{(s)}$,\t\t\t(2)\n$\\frac{\\partial E}{\\partial w_{i,j}^{(s,r)}} = ((y_{ij} - y_i) w_{i,j}^{(s,r)}) x_i^{(r)}$\nAs a result, the gradient can be calculated as follows.\n$.:. \\nabla E_i(W) = \\sum_j \\frac{\\partial E}{\\partial w_{i,j}^{(u,s)}}$,\n$.:. \\nabla E(W) = \\sum_{j=1}^{N_k} \\nabla E_i(W)$.\nThen, the weight update expression becomes\n$W^{new} = W^{old} - \\eta (\\nabla E(W))$,\t\t\t\t(4)\nwhere $\\eta$ is the learning factor. Furthermore, considering only the last layer\n$w_{ij}^{(u,s)} = w_{ij}^{(u,s)} - \\eta_j ( (y_{ij} - y_i) a_i^{(s)} )$\t\t\t\t(5)\nIn terms of existence of a class i in $D_k$, (5) indicates\n1) If a client has data from class i, then $(\\hat{y_{ij}} - y_i)$ will be non-positive, therefore $\\nabla (w)$ will be negative. Then, $w_{ij}^{(u,s)}$ will be non-negative.\n2) Otherwise, $(\\hat{y_{ij}}-y_i)$ will be non-negative, therefore $\\nabla (w)$ will be positive. Then, $w_{ij}^{(u,s)}$ will be non-positive.\nAs a result of (5), the global server can calculate the average of the weights for all the classes from the last layer of a received model, $W_k$. If a client k does not have data from all the classes, the trained model's last layer will show bias, in the form of dominant weights for the existing and/or data-rich classes in $D_k$. As stated in [21], when training DNN for a binary classification problem consisting of label a and label b respectively, the expectations of gradient square for different classes have the following approximate relation\n$\\frac{E||\\nabla E(w_a)||^2}{E||\\nabla E(w_b)||^2} \\approx \\frac{n_a^2}{n_b^2},$\t\t\t\t(6)\nwhere E denotes the error function of the neural network, $n_a$ and $n_b$ are the number of samples for class a and class b, respectively.\nIn this study, we extend the above idea to a multi-class scenario. Initialize the last layer weights with the initialization mentioned in Sec. III-A. After training, it satisfies the following relation\n$\\frac{E max(0, w_{new})||^2}{E max(0, w_{new})||^2} \\approx \\frac{n_i^2}{n_l^2},$\t\t\t(7)\nwhere $n_i$ and $n_l$ are the number of samples for class i and class l, respectively, where $i \\neq l, c \\in C_k$. To bring the ratio on a common scale for all the clients, we modify the ratio as follows\n$\\beta_{i,k} = \\frac{\\frac{E||max(0, w_{new})||^2}{\\sum_{c=1}^K E||max(0, w_{new})||^2}}{\\frac{n_i^2}{N_{ik}} \\sum_{c=1}^K \\frac{n_c^2}{N_{ck}}},$\t\t\t\t(8)\nwhere $\\beta_{i,k}$ be the estimated proportions for class i in client k. Then, the percentage error in estimating the proportion for a class i, $k_i$, is obtained as\n$K_i = \\frac{1}{K} \\sum_{k=1}^K \\frac{|P_{ik} - B_{ik}|}{P_{ik}} \\times 100.$\t\t\t(9)\nIn this section, we propose the bias-aware client selection algorithm (BACSA), which is based on the formulation of the problem as a mixed integer non-linear problem.\nAssume $A_k$ be the binary variable that indicates whether a client k is selected or not and $\\beta_{ik}$ be the estimated proportion of class i in $D_k$. Let S/N be the Signal-to-Noise ratio and Let $\\gamma_i$ be the average proportion of class i across the selected clients such that\n$\\Upsilon_i = \\sum_{i=1}^{\\Gamma} \\sum_{k=1}^{K} A_k \\beta_{i,k},$\t\t\t\t(10)\nand then variance of $\\gamma_i$ becomes\n$Var(q_i) = \\sum_{i=1}^{\\Gamma} \\sum_{k=1}^{K} A_k (\\beta_{i,k} - \\Upsilon_i)^2$\nThen the objective function is to minimize the variance to encourage uniformity in the selected clients becomes\n$min \\sum_{i=1}^{\\Gamma} \\sum_{k=1}^{K} \\{ A_k (\\beta_{i,k} - \\Upsilon_i)^2 + v \\frac{3 \\ln(\\Gamma) * 2 m_{tk}}{@ * S/N} \\}$\t\t(11)\nwhere $\\Gamma$ is the total number of classes, $m_{tk}$ is the count of client k at round r, v is the exploration and exploitation factor, @ is a scaling/weighting factor. Consider the following distributed optimization over FL, when the number of local training samples that can be used is fixed as $N_o$\n$\\min_{W \\in R^d} \\{F(W) \\approx \\frac{N_0}{N} \\sum_{k=1}^{K} F_k(W) \\},$\t\t\t(12)\nThen the typical weighted term for the $k^{th}$ device can be omitted and the global objective function, $F(W)$ can be written as\n$\\min_{W \\in R^d} \\{F(W) \\approx \\sum_{k=1}^{K} F_k(W) \\}.$\t\t\t(13)\nSince $F_k (W)$ represents the expected loss of the user k, The local objective function $F_k(w)$ is defined as\n$F_k(W) = \\frac{1}{N_o} \\sum_{j=1}^{N_o} (l_k(W),$\t\t\t(14)\n$l_k(W)$ measures the loss of model W in predicting label y with input x. BACSA is summed in 1."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "In all our experiments, we simulated cross device federated learning where only a fraction of devices will be available in each communication cycle. Since most of the devices are resource constrained, we used a CNN model with two convolution layers and three Feed Forward Neural Network (FFNN) layers. Each device performs the computation for 5 epochs with a batch size of 32. Under ideal conditions, the benchmark accuracy with this model is approximately ~ 84% with CIFAR-10 dataset [22] consisting of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The local optimizer is SGD with a weight decay of 5e-4, and learning rate, $\\eta = 0.01$. We terminate the FL training after 2000 communication rounds and then evaluate the model's performance on the test dataset of CIFAR-10. In addition to CIFAR-10, we also used the NIH Chest X-ray (CXR) dataset [23] to demonstrate our class proportion estimation mechanism. NIH dataset consists of 51,759 samples from 14 classes as shown in Fig. 4, excluding the 'No Finding' class with each sample size of 1024x1024 pixels.\nWe use IID data distribution as the benchmark, where the total number of samples at each client is equal ($N_k = N,\\forall k$), and each client k has equal number of samples from all classes. For non-IID scenario, the global data set contains equal samples of all the classes, however, that is distributed unevenly to local clients. We considered two strategies for data distribution:\n1) Dirichlet-a distribution [24] is parameterized by the concentration parameter, $\\alpha$. As $\\alpha$ decreases, the data distribution becomes more heterogenous as seen in Fig. 2(a) and 2(b). It is used as a benchmark from the literature.\n2) In order to further test BACSA, we utilize a class-constrained data distribution (CCDD), where each client can have only a certain number of classes, $\\Phi$. This scenario demonstrates the effect of missing class as seen in Fig. 2(c) and 2(d).\nThe communication channel is assumed to be stable across all clients and all clients can send their trained model to the global model. At a particular communication cycle, only a subset of clients will participate in the FL process. FL setup is same throughout all our experiments. Distribution of medical data between hospitals is demonstrated by using MNIST dataset in [8]. Similarly, we utilize the CIFAR-10 dataset, which consists of images more closely resembling medical images in terms of complexity compared to MNIST dataset. We assume a total of 20 clients (hospitals) to best simulate a real-world environment and the client selection algorithm selects 5 of them in each communication cycle.\nFig. 5 demonstrates the effect of weight initialization proposed in (1) compared to a widely used legacy initialization [19]. We use 100 Monte Carlo simulations H = 100 with Dirichlet distribution ($\\alpha = 0.1$). In order to calculate estimation error, we use (9) such that $\\frac{1}{H} \\sum_{h=1}^{H} \\hat K_i$\nwhere h indicates each Monte Carlo simulation. Results show a consistently superior performance with up to 12% more accuracy in class proportion estimation. For Dirichlet-based non-IID data distribution with $\\alpha = 0.5$, Fig. 3(a) shows the plot for class proportion estimation for individual clients using (8). For CCDD, Fig. 3(b) shows the plot for label proportions estimation for individual clients using the weight ratios. For NIH Chest Xray dataset, Fig. 3(c) shows the plot for estimation of label proportions corresponding to each client by using weight ratios. It is clearly seen that the class proportion estimation using the proposed weight initialization is closer to the true class proportion compared to the legacy weight initialization. The proposed technique effectively captures underlying trends in the data distribution, allowing the model to identify bias and tackle for class imbalances more accurately. Since CIFAR-10 is a global balanced dataset, when all clients [hospitals] participate in training, the final aggregated model does not diverge significantly, resulting in faster and smoother convergence. This can be used as a benchmark to evaluate the accuracy achieved on non-IID data. However, if the dataset is not globally balanced, then the accuracy drops significantly [17] and this is where the bias removal algorithms need to be implemented. Bias reduction techniques become crucial in such scenarios to ensure that the model does not favor the over-represented classes while under-performing on the under-represented ones.\nFig. 7 and Table I demonstrates the performance of BACSA and BACSA with fixed sample size (BACSA-FS) compared to several benchmarks. We also compared the result with client selection using greedy technique where it just selects clients which forms the most globally class balanced scenario. Results demonstrate improvement in the convergence and accuracy using BACSA as compared to the greedy technique.\nUsing our proposed method, we can see that the convergence gD1raph improved significantly for the same non-IID (CCDD $\\Phi = 2$) data. BACSA-FS and BACSA achieves more stable convergence as seen in Fig. 7 and Table I. The Fig. 6(a) show that $m_{tk}$ prevents exploitation of clients with desirable data characteristics. In addition, Fig. 6(b) shows that BACSA-SNR increases participation of users with high Signal-to-Noise-Ratio (SNR), which increases efficiency of communications. On the other hand, due to their favorable data characteristics, some clients with low SNR participated more often than clients with high SNR in Fig. 6(c), where Greedy approach is employed.\nEven though BACSA aims to select clients to minimize bias, the aggregation can still lead to some weight divergence. This is because the bias estimations are not exact and may include inaccuracies, which can contribute to the divergence. Nevertheless, by employing our technique, we can still achieve performance comparable to full client participation with a globally balanced dataset. Importantly, BACSA achieves this without violating individual privacy, as all data remains de-centralized, and only model updates are shared during the aggregation process. This ensures that sensitive medical data from different clients (e.g., hospitals) is kept private while still benefiting from collective training.\nFor the NIH Health Care dataset, we demonstrated the bias estimation, which is the main focus of this paper. However, due to the time constraints, we were unable to train the CNN model to plot its accuracy. The image samples are 1024x1024 pixels, and even with resizing, training a larger CNN model would require additional time."}, {"title": "V. CONCLUSIONS AND FUTURE WORK", "content": "In this paper, we introduce BACSA to address the challenges of bias detection, client selection and privacy preservation in FL. BACSA reduces the bias introduced by non-IID data distributions across clients. This ensures that over-represented classes do not disproportionately influence the model, while underrepresented classes are not neglected. As a result, BACSA promotes a more equitable learning process, ultimately leading to more balanced model performance across diverse client datasets, reducing bias, and enhancing fairness in federated learning scenarios compared to the state-of-art benchmarks. Furthermore, we proposed extension of BACSA with fixed sample size, BACSA-FS, and SNR consideration, BACSA-SNR. While BACSA-FS is shown to improve convergence graph, BACSA-SNR prioritizes channel conditions for client selection. To demonstrate robustness, we test BACSA on both widely used Dirichlet distribution and the proposed CCDD, which can represent challenging healthcare scenarios. Thanks to the proposed weight initialization and class estimation methods, similar accuracy to the methods in the literature with privacy violations are obtained while preserving the privacy of clients. For future work, we would like to support our observations and experiments with theoretical analysis and conduct experiments with data sets from healthcare. We also would like to investigate aspects of privacy protection beyond avoiding direct data or data characteristics sharing."}]}