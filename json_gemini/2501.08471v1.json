{"title": "Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition", "authors": ["Md Meem Hossain", "The Anh Han", "Safina Showkat Ara", "Zia Ush Shamszaman"], "abstract": "Human Activity Recognition (HAR) has gained significant importance with the growing use of sensor-equipped devices and large datasets. This paper evaluates the performance of three categories of models: classical machine learning, deep learning architectures, and Restricted Boltzmann Machines (RBMs) using five key benchmark datasets of HAR (UCI-HAR, OPPORTUNITY, PAMAP2, WISDM, and Berkeley MHAD). We assess various models, including Decision Trees, Random Forests, Convolutional Neural Networks (CNN), and Deep Belief Networks (DBNs), using metrics such as accuracy, precision, recall, and F1-score for a comprehensive comparison. The results show that CNN models offer superior performance across all datasets, especially on the Berkeley MHAD. Classical models like Random Forest do well on smaller datasets but face challenges with larger, more complex data. RBM-based models also show notable potential, particularly for feature learning. This paper offers a detailed comparison to help researchers choose the most suitable model for HAR tasks.", "sections": [{"title": "1 Introduction", "content": "In recent years, Human Activity Recognition (HAR) has become increasingly important due to its wide range of applications [1] in healthcare [2], smart homes[3], security [4], and human-computer interaction [5]. The rapid devel-opment of sensor technology has further enhanced the potential of HAR to revolutionize these fields. While HAR research has been conducted since the late 1990s [6], technological advancements have accelerated progress and ex-panded the possibilities for accurately recognizing human activities. Sensor-based and vision-based methods are two main approaches for collecting data for HAR [7]. Vision-based HAR involves using visual information from surveillance cameras, smartphones and wearable cameras or special cameras [8]. Sensors-based approaches rely on data collected from various sensors such as GPS, ac-celerometers, gyroscopes, microphones, magnetometers, and inertial measure-ment units (IMUs) [9]. These sensors are commonly embedded in smartphones [10], smartwatches[11], fitness trackers and other available devices [12]. Over the past decade, HAR has benefited from advancements in sensor technology [13], especially the development of low-power, low-cost, high-capacity, minia-turized sensors, and wire and wireless communication networks [14, 7, 15, 16]. As sensor technology has evolved to provide more sophisticated and diverse data, researchers are now working on integrating data from multiple sensors and sources [17]. This integration enables context processing [18], developing advanced algorithms and technology for activity recognition and inference [19], and developing more complex and practical HAR applications. Machine Learn-ing [20, 21, 22, 23], Deep Learning [4, 2, 24, 25, 1, 23, 26, 27] and other Artificial Intelligence approaches play a vital role in extracting meaningful patterns and features to recognize and classify the precise activity or behaviour by an indi-vidual at a specific instant utilizing sensor data [28].\nDespite the significant advancements in HAR, it remains a challenging task due to the diversity and complexity of human activities. One of the primary challenges lies in developing models that can effectively and efficiently recognize various activities across different scenarios. The complexity of activity patterns, the diversity of data sources (e.g., wearable sensors, video data), and the growing size of datasets make it difficult to design a single algorithm [29] that generalizes well across multiple contexts. Researchers have explored a broad spectrum of techniques, from traditional machine learning methods [22, 30] to sophisticated deep learning architectures [31, 25, 27]. Each of these approaches has its unique strengths and limitations, and understanding their comparative performance [32] is crucial for making informed decisions in real-world applications [33]\nWhile many models have been developed for HAR, there is a pressing need for a comprehensive evaluation across different model families, including classi-cal machine learning, deep learning, and generative models. Such a comparison is crucial for understanding which models perform best under varying conditions and data complexities, guiding practitioners in selecting the right approach for their specific needs. Previous works have shown remarkable progress in the development of sophisticated algorithms and approaches for extracting useful insights from HAR data [34, 35, 36]. Researchers have investigated a variety of HAR techniques, including classic machine learning methods and more advanced deep learning architectures [20, 37, 1, 22, 26, 27]. Traditional machine learn-ing algorithms, such as Support Vector Machines (SVMs), K-nearest Neighbour"}, {"title": "2 Related Works", "content": "Several approaches have been developed to improve the accuracy and effective-ness of activity recognition systems [59, 60]. Human activity represents the different physical acts and gestures that individuals carry out in living their daily lives. These acts embody the spending of energy and can be anything from just walking, sitting, and eating to running, dancing, and even playing a musical instrument. However, it is human activity recognition that helps in identifying and categorizing this diverse human activity with the help of tech-nology and various data analysis techniques. Among them, the most useful and popular medium for classifying human activities is Machine Learning models. These models learn and recognize patterns in data to make a difference between various activities based on unique movement and energy patterns. The early works related to HAR focus on the classification and recognition of human ac-tivities using classical machine learning. Table 1 provides an overview of prior studies, highlighting key models, datasets, and performance metrics that have shaped the development of HAR methodologies.\nRecently, [20] showed various machine learning models involving Decision Tree, Random Forest, Gradient Boosting DT, Logistic regression, Linear SVC, and RBF SVM classifier with the identification of activities such as sitting, walk-ing, and standing in daily life. [24] proposed a model where they applied deep learning methodologies as feature extraction and traditional machine learning as a classifier for identifying human activities using smartphone sensors. In the paper [59, 60] experimented with three HAR datasets Pampap 2 (519,185 records), SWELL (189, 000 records), and MHealth (102,959 records) to apply the number of ML Techniques. Researchers like [60] and [61] presented the best accuracy model where SVM achieved 98.8% and Random Forest outperformed from 74.39% to 92.97%. They also presented the training process of SVM and Random Forest, in which decision boundaries or construction of the ensem-ble models would effectively separate different activities. Traditional machine learning algorithms excel in scenarios where interpretability is essential, as they provide insights into the features and factors that contribute to classification decisions. So, the effectiveness of traditional machine learning lies in its ability to classify activity by learning patterns and relationships from labelled training data. However, traditional machine learning methods have some limitations to understanding complex patterns over time and automatically picking out details from data[62, 63]. Deep learning has the potential to overcome these limitations by automatically learning from raw data and understanding complex patterns that change over time [64]. Recently, deep learning approaches have brought about a revolutionary change in the field of Human Activity recognition.\n[24] and [66] utilized a wide range of DL models including CNN, RNN in-cluding LSTM, Bi-LSTM and GRU and Multi-layer Perception (MLP) which is a forward structured ANN. [44] developed a CNN-based method to capture local dependence and preserve feature scale invariant to recognize human activities and the proposed model outperformed the state-of-the-art methods. Another exploration by [39] analyzed RNN with LSTM to design LSTM architecture"}, {"title": "3 Research Design and Data Collection", "content": "This section outlines the research strategy and data collection methods used to evaluate various machine learning models for HAR. We used five bench-mark datasets: UCI-HAR, OPPORTUNITY, PAMAP2, WISDM, and Berkeley MHAD, each chosen for its distinct features and problems. The models ex-amined include classical machine learning techniques like Decision Trees and Random Forests, as well as deep learning architectures like CNN and RBMs, specifically DBNs and DBMs. We discuss the performance indicators used in our analysis, including accuracy, precision, recall, and F1-score, and provide a methodology for evaluating the models' capabilities in real-world HAR applica-tions."}, {"title": "3.1 Datasets", "content": "One of the critical parts of our research is to select appropriate datasets. In the data collection process for our comprehensive comparative study, we focused on the dataset's complexity and whether the datasets are already extensively solved or not for classification solutions. To ensure meaningful comparison, we chose four publicly available datasets to conduct our experiments. The following sections provide a clear picture of the datasets to describe the basics of the four datasets."}, {"title": "3.1.1 UCI-HAR", "content": "[65] The UCI-HAR is a data collection from 30 users between 19 to 48 years. Each person performed six activities (walking, walking upstairs, walking down-stairs, sitting, standing, laying) with 561 features belonging to accelerometer and gyroscope sensors of a smartphone (Samsung Galaxy S11) wearing on the waist [75, 68]. The smartphone's built-in accelerometer and gyroscope recorded data and the dataset measurement from triaxial accelerometers and gyroscope sensors. The data was recorded at a frequency of 50 Hz. The obtained dataset was divided into 2 sets where training data was generated by 70% of the users and 30% test data [76]. According to the statistical analysis, the dataset con-tains a large amount of data, totalling 748,406 individual samples. Table 2 contains classes of UCI-HAR and their proportions of data for each class"}, {"title": "3.1.2 Opportunity", "content": "[77]\nThe opportunity dataset is a multimodal dataset designed for Human Ac-tivity Recognition from wearable, mobile and ambient sensors to benchmark human activity recognition algorithms (classification, automatic data segmen-tation, sensor fusion, feature extraction etc.) [78]. The sensor data was collected from subjects wearing a set of wearable devices including wrist, chest, hip, and dominant forearm. The data was collected at a frequency of 30 HZ. The dataset includes precisely annotated data from a group of 4 subjects both male and fe-male to support the perception and learning of various human activities such as"}, {"title": "3.1.3 P\u0410\u041c\u0410\u0420 2", "content": "[81]\nThe PAMAP 2 dataset includes measurements from different sensors such as tri-axial accelerometer, gyroscope, Magnetometer, and heart rate data. This dataset is a collection of data collected from 9 subjects performing 18 different physical activities including walking, running, and climbing stairs. The sensor data was collected from subjects while wearing 3 IMUs devices on the arm, chest, and ankle and the heart rate data was collected from an HR-monitor[82]. The data was recorded at a frequency of 100 Hz. The PAMAP 2 Table 3 dataset is a valuable resource for researchers working on activity recognition. The dataset can be developed algorithms for data processing, segmentation, feature extraction and classification [83]."}, {"title": "3.1.4 WISDM (Wireless Sensor Data Mining)", "content": "[84]\nWISDM (Wireless Sensor Data Mining) acquired from WISDM Lab is a project of Fordham University that is focused on collecting and mining data from accelerometers and gyroscopes of phones and watches. The dataset contains data collected from 36 subjects, each of whom was asked to perform six types of human activities including upstairs, downstairs walking, jogging, sitting, and standing for specific periods. Accelerometer data measured through different dimensions X, Y and Z axes. The data was recorded at a frequency of 20 Hz."}, {"title": "3.1.5 The Berkeley MHAD (Multimodal Human Action Database)", "content": "Table 5 is a database of human activity data collected using multiple devices including RGB Cameras, a depth sensor (Kinect V1), an inertial sensor (3-axis accelerometer) a thermal sensor and a microphone. The dataset contains 12 actions including multiple sensor modalities, depth images, infrared images, skeleton joint positions, and inertial sensor data performed by 7 male and 5 female subjects in the range of 23-30 years of age. Each subject performed"}, {"title": "3.2 Models", "content": ""}, {"title": "3.2.1 Decision Tree", "content": "Decision Trees are a supervised learning algorithm used for both classification and regression tasks, effective in classifying activities like walking, running, or sitting by creating simple rules based on sensor data features like acceleration and orientation [89]. Decision trees Figure 1 are built in a top-down manner where each node contains a single value, and the root node represents the en-tire dataset. Each branch represents the outcome of the decision. Decision trees work by splitting data into subsets recursively based on chosen criteria depending on the trimming process. Splitting data can be done by impurity measurement such as GINI index and entropy[90, 91].\nThe Decision tree algorithm starts the root node and follows the branches down the tree until it reaches a leaf node to predict the values for new data[92]. Let's express the concept of a decision tree through the following equation:\n$y = f(x_1,x_2,...,x_n)$\nwhere\ny is the target variable (class or regression value)\nf is the decision tree function\nX1, X2,..., In are the input features"}, {"title": "3.2.2 Random Forest", "content": "Breiman [93] developed Random Forest which is an ensemble learning method that improves robustness and accuracy. It is particularly useful for HAR due to its ability to manage complex sensor data and reduce overfitting by combining multiple decision trees as described Figure 2. The random forest algorithm involves a multi-step process [89].\nSampling This is the key step where subsets are selected from datasets. Es-pecially, one dataset contains K number of records, n random records chosen with a subset of m features from k records. This process introduces randomness and diversity into the model.\nConstruction\nAfter sampling, individual decisions that constructed from each subset which is built with n random records and m features.\nOutput\nEvery decision tree generates its own set of predictions or outputs based on the data it was trained on.\nVoting\nFor the final prediction majority voting applies for the classification and aver-aged technique used for regression.\n$y = argmax_k avg(f_k(x)), k = 1, . . ., K$\ny is the predicted target variable (class or regression value)\n(fk(x)) is the prediction of the kth decision tree in the random forest\nK is the number of decision trees in the random forest"}, {"title": "3.2.3 Logistic regression", "content": "Logistic regression is a predictive analysis like other regression analysis [69, 94]. It describes data and explains the connection between one dependent binary variable meaning that it can take on only two variables such as \"1\" or \"0\", \"yes\" or \"no\", \"true\" or \"false\", \"sick\" or \"healthy\", and in the context of HAR, it distinguishes between two activities like sitting versus standing or walking versus running. Logistic regression starts by fitting a linear regression model to the data. The linear regression model predicts a continuous value, which is passed through a logistic function or sigmoid function S-shaped curve that takes a real number as input and outputs a value between 0 and 1 to produce a probability [95]. Equation (3) represents a mathematical expression used in a machine learning context, specifically for logistic regression with L2 regulariza-tion. It's trying to find the best set of weights W* to make predictions based on data.\n$W* arg min \\sum_{i=1}^{n} log (1 + exp(-y_iw^Txi)) + \\lambda w^Tw$"}, {"title": "3.2.4 Linear SVC", "content": "Linear SVC (Support Vector Classification) is a supervised classification algo-rithm extending Support Vector Machine (SVM) capabilities for scenarios where data can be neatly divided to be used for binary and multiclass classification tasks[96]. It is particularly effective for classifying human activities based on sensor data, such as accelerometer, gyroscope, and magnetometer readings and ensuring a robust classification performance across various tasks. It works by finding a hyperplane that maximizes the distance between two classes, effec-tively dividing the data so that each side contains points from only one class [97]. Once the hyperplane is determined, specific features of a new instance can be input into the classification model to predict its class. For linear kernels, linear SVC is a faster implementation of SVM [98]. The equation is finding the best weights (w*) and bias (b*) for an SVM model. It tries to strike a balance between having small weights (to prevent overfitting) and minimizing the clas-sification error (to ensure good performance in classifying data points), where the trade-off is controlled by the regularization parameter c.\n$(w*, b*) = argmin_{w,b} \\frac{||w||}{2} + c \\sum_{i=1}^{n} \\xi_i$"}, {"title": "3.2.5 RBF SVM", "content": "Radial Basis Function Support Vector Machine (RBF SVM) is a type of SVM algorithm that uses a radial basis function as a kernel function for binary clas-sification and it is recommended in scenarios where data is linearly inseparable or non-linear. Using the mapping technique input data transform into a higher dimensional space where the data become linearly separable[99]. After map-ping using the RBF kernel, a SVM classification is used to find a hyperplane and then perform the classification using the basic Idea of Linear SVC. RBF SVM performs well in non-linear and bidimensional scenarios[100, 101]. RBF SVM is particularly effective due to its ability to capture complex relationships in sensor data from smartphones and wearables. By maximizing the non-linear transformation capabilities of the RBF kernel, HAR systems can accurately classify various human activities, such as walking, running, and sitting, even in diverse environments and conditions. Equation 5 plays an important role in computing hyperplanes.\n$\\max_{a_i} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \u03b1_i \u03b1_j y_i y_j. rbf _ kernel (x_i, x_j)$\nwhere ai and aj are the Lagrange multipliers, yi and yj are the labels of points xi and xj, and rbf_kernel(xi, xj) is the RBF kernel."}, {"title": "3.2.6 K-nearest Neighbour (KNN)", "content": "KNN is a versatile supervised machine learning algorithm that can be used for both classification and regression tasks, including applications in HAR. It works by finding similar data points from the same labels or value and nearest data from different labels, see Figure 3.\nK-nearest Neighbour tries to make accurate predictions by finding the k most similar instance in the training set to a new instance and predicts the label of the new instance[70, 102, 103]. When classifying a new activity, KNN examines nearby data points of various labels (e.g., walking, running, sitting) and assigns the most common label among these neighbours to the new instance. However, it measures the distance between the test data point and every point within the training dataset."}, {"title": "3.2.7 Convolution Neural Network (CNN)", "content": "CNN is an artificial neural network specially designed to learn directly from data[104, 105]. It is particularly useful for automatically extracting spatial features from raw sensor data and capturing patterns in time-series signals. CNN architecture is structured with various specialized layers, each serving a distinct role in the network's architecture. The layers include an input layer, an output layer, convolutional layers, pooling layers, and fully connected layers [106] Figure 4.\nThe convolutional layers extract complex features from the input data by apply-ing a convolution operation to the input data which is a mathematical operation.\nThese layers are used to reduce the size of the features produced by the con-volutional layers. By this action, the number of parameters is reduced in the network to make the network more computationally efficient.\nJust before the output layer, the final fully connected layers combine the out-comes of convolutional and pooling layers and make a prediction.\nThe output layer generates classification results on the outputs of the fully con-nected layers"}, {"title": "3.2.8 Recurrent Neural Network (RNN)", "content": "RNN Figure 5 is designed for time series or sequential data, where data points have a temporal order. In standard neural networks, all inputs and outputs are considered independent of one another [107].\nHowever, in scenarios like Human Activity Recognition (HAR), where sensor data is captured in continuous sequences, such as accelerometer and gyroscope readings, past information is crucial for predicting future activities [108]. The hidden state of the RNN plays a key role in maintaining context from prior inputs, enabling the network to recognize patterns in sequential data, such as distinguishing between walking, running, or sitting, based on the flow of sensor signals [109]. RNNs are an effective solution for processing and understanding temporal relationships in HAR datasets. There are three main components of RNN:\nThis layer receives the raw data or features. Its purpose is to pass this data to the subsequent layers for processing.\nThese layers perform the core computation of the neural network. They are re-sponsible for processing the input data and learning the long-term dependencies in the data.\nThis layer is the final layer in the neural network. This layer is responsible for producing the network's prediction and classification."}, {"title": "3.2.9 Long Short-term Memory (LSTM)", "content": "LSTM networks, designed by Hochreiter and Schmidhuber [110], were intro-duced to address the shortcomings of standard RNNs in handling long-term dependencies in sequential data. While RNNs are capable of capturing recent information, they often struggle to retain and utilize data stored in long-term memory, leading to diminished performance in tasks requiring an understand-ing of extended sequences. LSTM overcomes this limitation by incorporating feedback connections, allowing it to process entire sequences of data, not just individual points [111, 112]. This makes LSTM particularly efficient for tasks involving sequential data, such as text, speech, time series, and Human Activity Recognition (HAR). In HAR, where sensor data from devices like smartphones and wearables is gathered over time, LSTM's ability to retain and process long-term dependencies helps in accurately identifying activities over extended pe-riods. Memory cells at the LSTM architecture are core to enable the network to retain crucial information over long sequences, making it a powerful tool for sequential data prediction and understanding. These memory cells have three key components: Input Gate\nThe input gate regulates how much of the new input is allowed to enter the cell.\nThese layers perform the core computation of the neural network. They are re-sponsible for processing the input data and learning the long-term dependencies in the data.\nThis layer is the final layer in the neural network. This layer is responsible for producing the network's prediction and classification."}, {"title": "3.2.10 BiLSTM (Bi-directional Long Short-Term Memory)", "content": "BiLSTM is a type of RNN and an extension of the LSTM architecture Figure 7 designed to handle sequential data. Unlike traditional LSTM, which processes sequences in a single direction either forward or backward, BiLSTM processes the sequence in both directions [48]. It uses two LSTM layers: one processes the sequence from past to future (forward), and the other processes it from future to past (backwards). This bidirectional approach allows BiLSTM to capture dependencies and context from both previous and future steps in the sequence, making it particularly effective in tasks where understanding long-term rela-tionships is essential. In particular, in fields like Human Activity Recognition (HAR), where sensor data from wearable devices is analyzed over time, BiL-STM can extract valuable information from both earlier and later time steps, enabling more accurate predictions of activities such as walking or running. The architecture's key feature is the fusion of information from both directions, with the outputs of the forward and backward LSTM layers integrated to produce the final result [111, 112]. This makes BiLSTM well suited for HAR tasks, as well as other domains like natural language processing and speech recognition."}, {"title": "3.2.11 Gated recurrent units (GRUs)", "content": "GRUs are a type of RNN and a simplified version of LSTM Figure 8 introduced by Jun-Young Chung et al. [113]. Both GRUs and LSTMs are widely used in time-series and sequence-based tasks, including HAR, where modelling temporal dependencies in data is critical. GRUs, in particular, are effective in HAR because they can efficiently process sequential data. The gating mechanisms in GRUs allow the model to control the flow of information through the network. These gates decide what information should be kept, forgotten, or updated, which is vital in HAR, where long-term dependencies need to be captured to correctly recognize activities. GRUs achieve this with fewer parameters than LSTM, making them computationally efficient while maintaining competitive performance [114]. GRUs use two gating Mechanisms:\nThis gate determines how much of the previous state should be kept or forgotten.\nThis update gate controls which parts of the current state should be updated.\nThese gates allow the GRU to effect model sequential data by retaining rel-evant information from the past and removing irrelevant information."}, {"title": "3.2.12 Artificial Neural Network (ANN)", "content": "ANNs are machine learning models inspired by the human brain, consisting of interconnected nodes or artificial neurons that process information like biological neurons do [115, 116]. In HAR, ANNs analyze data from sensors in smartphones or wearables to identify activities such as walking or running. Information flows through various layers in an ANN, with each connection having an adjustable weight. During the learning process, ANNs optimize these weights to minimize the difference between predicted and actual outputs, improving classification accuracy in HAR tasks [72]. ANNs are typically structured into three main layers [117] Figure 9shown below.\n$M_k = f(\\sum_{i=1}^{l_k} w_{kj} f(\\sum_{i=1}^{u}W_{ji}x_i + W_{j0} + W_{ko}))$ where $f$\"The activation of the neuron, denoted by Mk, is a function of the weighted sum of its inputs, xi, where k is the index of the input and jis the index of the neuron. The weights between the neuron j and the neuron i and between the neuron j and the output k are denoted by Wj; and Wkj, respectively.\nInput layers receive the input data, such as an image or a text string process it and deliver it to the next layer.\nThere are one or more hidden layers in ANN architecture to perform complex computations on the input data and learn to extract features that are useful for the task.\nThe output layer produces the final prediction on classification. ANN is trained by feeding them large amounts of data and allowing them to the relationships between the inputs and designed output. After training, it can be used to make predictions or decisions on new data.\""}, {"title": "3.2.13 Deep Belief Networks (DBNs)", "content": "DBNs are a generative graphical model or a class of deep neural networks with many hidden layers consisting of visible (input) units, hidden units, and output units[118, 43]. In DBNs, the visible units (input) can take binary or real values whereas the hidden units are often binary. Generally, units in one layer are con-nected to the adjacent layers, this term except in a sparse DBN. The connection between the top two layers is not directed, all the other layers are directed[56] Figure 10 Constructing a DBN involves a process of layering Multiple Restricted Boltzmann Machine (RBMs) a top of another layer. This stacking of RBMS forms the foundation of DBN architecture. RBMs are a type of generative model that can learn to represent the probability distribution of a set of data[119].\nTherefore, DBN is particularly powerful in modelling complex patterns and ex-tracting meaningful features from large and high-dimensional datasets. DBN has demonstrated success in achieving state-of-the-art results in various domains including Human Activity Recognition, natural language processing, and speech and image recognition."}, {"title": "3.2.14 Deep Boltzmann Machines (DBMs)", "content": "DBMs are generative, unsupervised deep learning models comprising three lay-ers that learn complex representations and high-level features, making them ideal for HAR. They can capture intricate patterns in sequential data from sen-sors, such as smartphones and wearables [120]. Similar to DBNS, DBMs consist of multiple layers of RBMs. However, a key distinction is that in DBMs, all connections between the RBMs are undirected [56] Figure 11, allowing for more flexible learning of feature hierarchies.\nThis undirected nature enables DBMs to better represent the complex depen-dencies [121, 122] between different activities and their corresponding sensor readings in HAR tasks. By leveraging their ability to learn high-level features from raw sensor data, DBMs can improve the accuracy of activity classification and enhance the interpretability of the underlying patterns, ultimately facilitat-ing more robust HAR systems."}, {"title": "3.3 Evaluation measures for performance", "content": "The evaluation of a Human Activity Recognition Performance is crucial in mea-suring its effectiveness. In this experimental study, evaluating all the models for human activity recognition, we considered some commonly used evaluation ma-trices such as accuracy, recall, precision and F1-score. These selected methods offer a significant perspective allowing us to gain a comprehensive understanding of the models' performance."}, {"title": "3.3.1 Accuracy", "content": "Accuracy is a fundamental performance metric that describes how the model performs accuracy on a given test data to provide the number of correctly clas-sified samples over the number of samples. The model's performance depends on a high accuracy score which ranges from 0 to 100.\n$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$"}, {"title": "3.3.2 Precision", "content": "Precision is defined as the percentage of correctly classified or predicted samples over the total number of classified or predicted positive (True and False) samples. In terms of Human Activity Recognition (HAR), precision helps identify specific activity, reducing false positive classification."}, {"title": "3.3.3 Recall", "content": "Recall or sensitivity is the percentage of correctly predicted positive samples to the total actual samples. A higher recall indicates that the model used in our experiment is better at capturing all instances of the positive class in HAR.\n$Recall = \\frac{TP}{TP + FN}$"}, {"title": "3.3.4 F1-score", "content": "F1-score combines precision and recall developing a balanced metric that con-siders both false positive and false negative.\n$F1 Score = \\frac{2* Precision * Recall}{Precision + Recall}$\nF1-score calculated as the weighted average of precision and recall each given a weight of 2."}, {"title": "3.3.5 Confusion Matrix", "content": "Confusion matrix is a table matrix that visualizes the full performance of the classification models by comparing its predicted labels with the actual labels of the data. In the table, columns represent the predicted classes, and rows represent the actual classes."}, {"title": "4 Performance Metrics and Results Analysis", "content": "In this section, we provide the findings from our comparative analysis of the machine learning models used for HAR across the selected benchmark datasets. We thoroughly analyse the performance results, focusing on key metrics such as accuracy, precision, recall, and F1-score, which are critical for determining model success in real-world scenarios. The topic focuses on the differences in performance between classical machine learning models, deep learning archi-tectures, and RBMs, emphasizing their strengths and limitations concerning dataset features. By examining these findings, we hope to better understand the implications for selecting optimal models for HAR tasks and suggest possible areas for future research and advancement in this quickly expanding field."}, {"title": "4.1 Result for UCI-HAR dataset", "content": "UCI-HAR dataset includes 10,299 samples. From this number, we partitioned 7,352 samples for the training set and reserved 2,947 samples for the testing set. After sample partitioning, we trained classical machine learning models, deep learning models, and Restricted Boltzmann Machines. Subsequently, we evaluated the performance of each model using standard performance metrics which are explained in Subsection 3.3.\nSeveral classical machine learning including RBF SVM, Linear SVC and Logistic Regression achieved the highest performance exceeding scores of 0.95 across all metrics: accuracy, precision, recall and F1 score. Random forest also performed well with scores surpassing 0.92, as shown in Table 6. However, KNN and decision tree were slightly less accurate with scores of over 0.85.\nAmong deep learning models, CNN and ANN performed as the top per-formers achieving exceptional scores above 0.94. However, RNN, LSTM, Bi-directional LSTM, and GRUs demonstrated lower performances with scores ranging from 0.78 to 0.85, see Table 7.\nBoth DBNs and DBMs achieved remarkable scores exceeding 0.94 on differ-ent evaluation metrics, as shown in Table 8.\nFigure 12 provides a visual comparison of the performance metrics of clas-sical Machine learning, deep learning and RBMs models on UCI-HAR dataset."}, {"title": "4.2 Result for opportunity dataset", "content": "525,660 samples were in the opportunity dataset, 341, 679 were used in training, and 183,981 were used in testing process. After training and testing each model type, the experiment results indicated that random forest achieved exception performance with accuracy (0.92), precision (0.94), recall (0.93), and F1-score (0.93), see Table 9.\nDecision tree and K-nearest neighbour achieved impressive results. Linear Regression Linear SVC and RBF SVM did not perform well due to limitations in handling the complexity of big data.\nThe result in Table 10 shows that in the deep learning model, CNN achieved the highest scores in performance metrics with impressive accuracy (0.89), pre-cision (0.91), recall (0.90) and F1-score (0.90). Table indicates that Artificial neural network (ANN) and Bi-directional Long Short-term Memory (LSTM) are still showing strong performance, while Recurrent Neural Network (RNN), Long Short-term Memory (LSTM), and Gated Recurrent Units (GRU) addi-tional optimization not having better performance compare with other models.\nRestricted Boltzmann Machines (RBMs) delivered a remarkable performance in opportunity dataset with Deep Belief Networks (DBNs) and Deep Boltzmann"}, {"title": "4.3 Result for PAMAP2 (Physical Activity Monitoring Dataset)", "content": "PAMAP2 dataset consists of 19,42,874 samples. Splitting the dataset into train-ing and testing sets with 15,54,297 samples in the training dataset and 388,575 samples in the testing dataset. After training and testing, the result shows that Decision tree, Random Forest and k-nearest Neighbour in the classical model category achieved a performance metrics score of 1.0. Logistic regression, Linear SVC, and RBF SVM gained an impressive score in the evaluation, see Table 12.\nIn the deep learning category, CNN, ANN, and LSTM achieved performance metrics with scores ranging from 0.98 to 0.99, see Table 13"}]}