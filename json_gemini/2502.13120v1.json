{"title": "Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language\nin a Coreference Context", "authors": ["Marion Bartl", "Thomas Brendan Murphy", "Susan Leavy"], "abstract": "Gender-inclusive language is often used with\nthe aim of ensuring that all individuals, regard-\nless of gender, can be associated with certain\nconcepts. While psycholinguistic studies have\nexamined its effects in relation to human cog-\nnition, it remains unclear how Large Language\nModels (LLMs) process gender-inclusive lan-\nguage. Given that commercial LLMs are gain-\ning an increasingly strong foothold in everyday\napplications, it is crucial to examine whether\nLLMs in fact interpret gender-inclusive lan-\nguage neutrally, because the language they\ngenerate has the potential to influence the\nlanguage of their users. This study exam-\nines whether LLM-generated coreferent terms\nalign with a given gender expression or reflect\nmodel biases. Adapting psycholinguistic meth-\nods from French to English and German, we\nfind that in English, LLMs generally maintain\nthe antecedent's gender but exhibit underly-\ning masculine bias. In German, this bias is\nmuch stronger, overriding all tested gender-\nneutralization strategies.", "sections": [{"title": "1 Introduction", "content": "Over the last few decades, activism by feminist lin-\nguists has led to increased use of gender-neutral or\ngender-fair wording, especially in grammatical gen-\nder languages such as French or German (Usinger\nand M\u00fcller, 2024; Burnett and Pozniak, 2021).\nThe aim of these forms is to alleviate masculine-\ndefault bias and establish representation for people\nwith non-binary gender identities (Freed, 2020).\nPsycholinguistic studies have shown that gender-\nneutral alternatives can increase the visibility of\nwomen and non-binary people (Tibblin et al., 2023;\nFatfouta and Sczesny, 2023).\nAs Large Language Models (LLMs) are embed-\nded into everyday systems and are used as writ-\ning assistants and content creators, the language\nthey generate can have an impact on equal treat-\nment and linguistic representation of women and\nnon-binary people. However, while gender bias in\nNLP is well-researched (Stanczak and Augenstein,\n2021), gender-inclusive language in the context of\nLLMs has only begun to be investigated (Bartl and\nLeavy, 2024; Watson et al., 2025, a.o.). The pro-\ncessing of gender-inclusive vs. gendered language\nremains under-explored in English LLMs (Watson\net al., 2023) and, to our knowledge, entirely unex-\namined in German LLMs. To address this, we aim\nto compare the processing of gendered and gender-\ninclusive language in both English, a notional gen-\nder language, and German, a grammatical gender\nlanguage.\nWe adapt a psycholinguistic study by Tibblin\net al. (2023) to explore how the presence of mas-\nculine, feminine or neutral gender in one sentence\ninfluences (1) the likelihood of a reference to that\ngender in a subsequent sentence and (2) the gen-\nder mentioned in an LLM-generated completion.\nWe find that while English LLMs generally keep\nantecedent and coreferent gender consistent, they\nare unlikely to use they as a singular pronoun and\ncontain underlying masculine bias. The German\nLLM we tested showed a strong preference for\nmasculine coreferents, regardless of the gender or\ngender-inclusive strategy used in the antecedent\nphrase. We also find evidence that German gender-\ninclusive language strategies increase the probabil-\nity of feminine and neutral gender. This finding\nencourages us to believe that the use of gender-\ninclusive over generic masculine expressions in\nGerman LLMs has the potential to diversify gender\nrepresentation."}, {"title": "Contributions", "content": "This study translates psycholin-\nguistic methodologies to LLMs, enabling com-\nparisons between human and model reasoning.\nIt introduces a novel approach to assessing\nwhether gender-inclusive expressions promote"}, {"title": "2 Background", "content": "The field of feminist psycholinguistics is con-\ncerned with evaluating human biases related to lan-\nguage. Studies have shown how masculine gener-\nics are in fact not interpreted generically (Noll\net al., 2018), and that changing the language to be\ngender-inclusive also increases mental representa-\ntion for women and non-binary people (Sato et al.,\n2025; Mirabella et al., 2024). The term gender-\ninclusive language describes linguistic strategies\nand neologisms to eliminate male-as-norm bias\n(chairman\u2192chairperson) and emphasize alterna-\ntive terms that do not reinforce a heteronormative,\nbinary model of gender (husband/wife\u2192spouse).\nLarge Language Models (LLMs) have also been\nshown to exhibit various social biases, including\ngender bias (Gupta et al., 2024). However, few stud-\nies ha explored the processing of gender-inclusive\nlanguage within LLMs. There are two main areas\nof investigation: gender-inclusive role nouns (fire\nfighter, chairperson, etc.) and gender-neutral pro-\nnouns such as singular they. The present research\naddresses both.\nTo investigate the processing of gender-\ninclusive role nouns in LLMS, Watson et al.\n(2023) adapted a psycholinguistic study on sen-\ntence acceptability judgments and social attitudes\nfor BERT (Papineau et al., 2022; Devlin et al.,\n2019). They first calculated BERT's relative proba-\nbility of a given masculine, feminine or neutral role\nnoun (e.g. fireman/firewoman/fire fighter) within a\nsentence context. BERT's responses were then con-\nnected to the social attitudes of the human partici-\npants giving the same responses. The researchers\nfound that BERT aligned most with people who\nhad moderate to conservative views.\nThere are several studies examining gender-\nneutral pronouns in LLMs. For instance, Brandl\net al. (2022) draw on psycholinguistic research into\nSwedish neopronouns and adapted an eye-tracking\nstudy for LLMs. They demonstrated that while hu-\nmans do not have trouble processing neopronouns\nare associated with greater processing difficulty in\nLLMs. Correspondingly, models also have lower\npronoun fidelity for feminine and singular they pro-\nnouns, which means that they are less likely to\nuse them even if they were introduced alongside a\ncorresponding entity (Gautam et al., 2024). When\ncomparing an LLM's processing of singular they\nin a generic sense vs. referring to a specific person,\nmodels have less trouble with generic they (Baum-\nler and Rudinger, 2022). In terms of social atti-\ntudes, Watson et al. (2023) found that BERT's prob-\nabilities for singular they resembled the judgments\nof participants with low to moderate acceptance of\nnon-binary gender.\nThe psycholinguistic studies that have previously\nbeen adapted for LLMs, as well as the research the\npresent study is based on, often contain anaphora\nbetween two sentences. Anaphora is defined \u201cin\na looser sense, [as] any relation in which some-\nthing is understood in the light of what precedes\nit\" (Matthews, 2014). The preceding term is called\nthe antecedent, while the referring term is the coref-\nerent. The resolution of this relationship, finding\nthe corresponding antecedent for a coreferent, is a\nlarge research field within NLP. Coreference Res-\nolution (CR) is is relevant for downstream NLP\ntasks such as named entity recognition, summa-\nrization or question answering (Liu et al., 2023).\nCR systems have previously been shown to exhibit\ngender bias, relying on stereotypes for prediction\ninstead of syntactic information or real-world gen-\nder distributions (Rudinger et al., 2018; Kotek et al.,\n2023).\nTo evaluate CR systems for gender bi-\nases, challenge datasets based on the Winograd\nschema (Levesque et al., 2012) were developed\n(Rudinger et al., 2018; Zhao et al., 2018). These\ndatasets contain instances in which a pronoun\nmust be resolved to refer to one of two pre-\nviously mentioned entities, such as in the sen-\ntence \"The paramedic performed CPR on the pas-\nsenger even though she/he/they knew it was too\nlate.\" (Rudinger et al., 2018). While the challenge\ndatasets mostly contain a single sentence, and as-\nsess the resolution of pronouns in the singular, this\nresearch focuses on coreference between two dif-\nferent sentences in both singular and plural.\nIn German, the issue of gender-inclusive lan-\nguage is more intricate than in English. German\nmarks nouns, articles and adjectives for mascu-\nline, feminine or neutral gender, traditionally us-"}, {"title": "3 Methodology", "content": "In order to uncover how LLMs process gender-\ninclusive in contrast to gendered language, we\nadapted Tibblin et al.'s (2023) study design of sen-\ntence pairs containing antecedent and coreferent\nphrases (\u00a73.1). We used several LLMs (\u00a73.2) for\nour experiments on measuring the probability of\nspecific gendered or gender-neutral terms (\u00a73.3)\nand analyzing the gender contained in model gen-\nerations (\u00a73.4).\nWe adapted a study design with 44 sentence pairs\nby Tibblin et al. (2023). The French sentences\nin this study designe were translated into English\nand German using ChatGPT and manually verified.\nEach instance in the dataset contains two subse-\nquent phrases. Phrase 1 contains an antecedent, a\nplural noun phrase that is either gendered (kings,\nau pair girls) or gender-neutral (oenologists, volun-\nteers). Phrase 2 contains as the coreferent the noun\nmen or women. The content of the phrases can be\ncoherent (1a) or incoherent (1b).\n(1) a. The midwives were entering the hospi-\ntal. Given the good weather, some of the\n(women men) were not wearing jackets.\nb. The referees were watching the match\nin the rain. Because of the good weather,\nmost of the men were wearing shorts.\nUsing the 11 incoherent instances (cf. 1b) vs. tak-\ning them out had little impact on the outcome of our\ninitial experiments, we therefore retained all 44 in-\nstances for experiments measuring coreferent prob-\nability. Translating the data into English did not\nalways retain the original gender of the antecedent\n(H\u00f4tesses de l'airfem \u2013 flight attendantsneut). The\noriginal data moreover contained imbalanced num-\nbers of gendered/gender-neutral antecedents, which\nwas undesirable for our analysis. We therefore de-\ncided to use the data as templates. A template con-\nsists of two phrases, the first one with a placeholder\nfor an antecedent, the second with a placeholder\nfor a coreferent."}, {"title": "3.1.1 Data for Measuring Coreferent\nProbability", "content": "English Our final English dataset comprises\n13,464 instances for the plural (PL) condition and\n14,652 instances for the singular (SG) condition.\nThe PL dataset includes 34 antecedent triplets, each\npaired with three coreferent nouns\u2014men, women,\nand people-across 44 templates. The SG dataset\nconsists of 37 antecedent triplets, each paired with\nthe pronouns he, she, and they, across 44 templates.\nTo collect the English antecedents, we utilized gen-\ndered terms and their neutral replacements from\nBartl and Leavy (2024), selecting terms that shared\nthe same neutral equivalent for both masculine and\nfeminine forms (e.g. swordswoman-swordsman-\nfencer). Any triplets that were semantically im-\nplausible within our template context (e.g., hu-\nmankinds) were manually excluded. This resulted\nin 34 verified triplets for the PL condition and 37\nfor the SG condition.\nGerman The final German dataset comprises\n10,560 instances, constructed from 10 antecedents,\neach having eight gender-inclusive variations,\npaired with three coreferent nouns-M\u00e4nner \u2018men',\nFrauen 'women', and Personen \u2018persons'-across\n44 templates. To ensure a truly gender-neutral an-\ntecedent noun phrase, we maintained coreferent\npairs in the plural form, as the German singular\ninherently marks gender through its article. Instead\nof translating the English triplets we used profes-\nsions from the French data to avoid data expan-\nsion, given that each antecedent in English had only\nthree variations, whereas German antecedents had\neight (Table 5 in Appendix A). The German gender-\ninclusive strategies used are outlined in Table 2.\nThey include masculine and feminine forms for"}, {"title": "3.1.2 Data for Coreferent Generation", "content": "In the second set of experiments, we used the mod-\nels to generate the continuation of Phrase 2 instead\nof measuring the probability of specific corefer-\nents. The final dataset for coreferent generation\ncomprised 630 instances for English and 160 in-\nstances for German. We worked with heavily re-\nduced datasets to minimize annotation workloads\nand reduce variability in the generations. The En-\nglish dataset was reduced by using the 33 templates\nwith coherent phrases (Example (1a)) and selecting\na reduced set of seven high-frequency plural triplets\n(Table 3). For German, we used the same ten an-\ntecedent terms in eight gender variations (\u00a73.1.1)\nwith 2 coherent templates."}, {"title": "3.2 Models", "content": "We used six English and one German LLM in the\nexperiments (Table 4 in Appendix A). The mod-\nels were selected to enable comparison between\nmodel sizes and performances. For the English\nexperiments we used GPT-2 (Radford et al., 2019)\nas a baseline, allowing for comparability due to its\nwidespread use in prior research. We also tested\nan adaptation of GPT-2 by Bartl and Leavy (2024),\nin which the model was fine-tuned with gender-\nneutral data in order to mitigate gender stereotyp-\ning in the model. This model is particularly rele-\nvant because our experiments assess how gender-\nneutral language is processed by LLMs. It can\ntherefore provide insights into how a model that\nhas seen additional gender-neutral language would\nprocess gender-neutral language differently. We\nalso tested the 1B, 7B and 13B models from the\nOLMO suite (Groeneveld et al., 2024a), which are\nfully open-source, improving transparency for the\nresearch community. The different sizes allow us\nto show the impact of model size on the process-\ning of gendered language. Qwen2.5 (32B) (Yang\net al., 2024) was included as our largest model and\nthe best performing pre-trained single-model LLM\non the huggingface OpenLLM Leaderboard at the\ntime of experimentation (December 2024) within\nthe hardware limitations of our institution."}, {"title": "3.3 Measuring Coreferent Probability", "content": "We used the LLMs to predict the joint two phrases\nup to the coreferent (men/women/people), and\nthen obtained the log probability of the coreferent\n(log(p)) from the probability distribution over the\nvocabulary. For split coreferents, we took the prob-\nability of the first component token. Averaging the\nprobabilities of all component tokens would have\ninflated probabilities, as each component serves as\na strong predictor for the subsequent token."}, {"title": "3.4 Coreferent Generation and Annotation", "content": "We used the models to generate eight tokens for\nEnglish and ten for German. The generated contin-\nuations were then annotated for gender of the entity\nmentioned, and whether the mentioned entity was\na coreferent of the antecedent in the first sentence.\nEnglish Three annotators were recruited out of\na pool of PhD researchers at our institution. Two\nwere native and one was a fluent English speaker.\nAll annotators were paid \u20ac60 for 630 items of\nannotation, each with two labels per item (gender\nand coreference). The annotation guidelines can\nbe found in Figure 4 in the Appendix.\nFleiss' kappa was calculated to assess inter-\nannotator agreement. For the gender labels,\nthe annotations showed $\\kappa = 0.757$. For the\ncoreference labels, the annotators reached a\nslightly lower score of $\\kappa = 0.671$. This is not\nsurprising given that coreference labeling might\nhave been complicated by mentions of several en-\ntities or ambiguous phrasing, among others. How-\never, both of these scores are in the range of \"sub-\nstantial agreement\", according to Landis and Koch\n(1977). We then calculated the final gender and\ncoreference labels based on the majority label.\nInstances for which all three annotators provided\ndifferent labels were labeled as NULL. There were\n22 NULL labels for gender and eight NULL labels\nfor the presence of coreference.\nGerman (pilot) Due to the lack of German-\nspeaking annotators one of the authors, who is a\nnative speaker of German, annotated the German\nsentence completions in a pilot experiment. Each\ncompletion was annotated for mentioned gender\nand presence of a coreferent to the antecedent."}, {"title": "4 Results", "content": "This section lays out the results for our experiments\non coreferent probability and coreferent generation.\nFor each of these, we will first present the English\nand then the German results."}, {"title": "4.1 Coreferent Probability", "content": "English For our English results, we provide il-\nlustrations for and discuss Qwen-2.5 in detail, as it\nis the largest and best performing model of those\nwe evaluated. Its results would therefore mirror\nmost closely state-of-the-art models. However, the\nresults for all English models (except the fine-tuned\nmodel) follow similar patterns. We provide results\nand illustrations for the other models, such as the\nOLMo suite (Figure 5), and the fine-tuned GPT-2\n(Figure 6) in Appendix B.\nWe performed a two-way ANOVA on the coref-\nerent probabilities produced by Qwen-2.5 (and all\nother models, cf. Table 6 in the Appendix), testing\nthe effect of antecedent and coreferent gender on\nthe probability of the coreferent. Effect sizes were\nlabeled following Field et al.'s (2012) recommen-\ndations. The ANOVA showed that in the PL set-\nting, the main effect of antecedent gender is statisti-\ncally significant and small (F(2, 13455) = 138.59,\np < .001; $\\eta^2$ = 0.02, 95% CI [0.02, 1.00]), which\nalso applied to the main effect of coreferent gen-\nder (F(2, 13455) = 178.33, p < .001; $\\eta^2$ = 0.03,\n95% CI [0.02, 1.00]). The interaction between an-\ntecedent and coreferent gender is statistically signif-\nicant and large (F(4, 13455) = 809.94, p < .001;\n$\\eta^2$ = 0.19, 95% CI [0.18, 1.00]). This indicates\nthat in the coreference constructions we are in-\nvestigating, the probability of the coreferent is\nmost influenced by the correspondence between\nantecedent and coreferent gender.\nFigure 1 illustrates the distribution of coreferent\nprobability for the English Qwen-2.5 model in both\nPL and SG setting. In the PL setting, the model be-\nhaves as expected, producing the highest coreferent\nprobability when antecedent gender and coreferent\ngender correspond (e.g. The bowmen were going\ndown the street. Some of the men were in a good\nmood.). However, for feminine antecedents, mascu-\nline coreferents have the second highest probability,\nindicating masculine bias in the model. The Tukey\npost-hoc test showed a 21% lower probability for\nneutral than masculine coreferents following fem-\ninine antecedents (F:N/F:M = $e^{-0.236} \\approx 0.79$,\np < .001). This masculine bias is also evident for\nneutral antecedents. Here, the Tukey post-hoc test\nshowed a probability that was three times higher\nfor masculine than feminine coreferents following\nneutral antecedents (N:M/N:F = $e^{1.107} \\approx 3.03$,\np < .001).\nThe SG setting (Figure 1b) is similar to the PL\nin that matching antecedent and coreferent gen-\nder result in the highest probability for masculine\nand feminine coreferents, for which we used the\npronouns he and she, respectively. Similar to the\nPL, he as a coreferent had a 31% higher proba-"}, {"title": "4.2 Coreferent Generation", "content": "English As discussed in Section 3.4, we used\nmajority voting over our three annotation labels to\ngenerate the final labels. Out of 630 sentence com-\npletions, 396 (62.86%) were labeled as containing a\ncoreferent of the antecedent, 226 (35.87%) were la-\nbeled as not containing a coreferent, and 8 (1.27%)\ninstances were inconclusive (labeled NULL).\nWe ran $\\chi^2$ tests of independence for both\nthe coreference and no-coreference groups,\nwhich were statistically significant (p < .001).\nEffect sizes were labeled following Funder\nand Ozer's (2019) recommendations. In the\ncoreference group, the effect of antecedent gen-\nder is very large, ($\\chi^2$ = 739.57, p < .001; Ad-"}, {"title": "5 Discussion", "content": "Both experiments on measuring coreferent proba-\nbility and generation of coreferents demonstrated\nthat generally, models tend to match coreferent gen-\nder to the antecedent gender. However, there are\nseveral caveats to this observation. For English\nmodels, whether or not the gender of the coreferent\naligns with the antecedent depends on whether the\nsentences are singular or plural. Our English coref-\nerent probability experiments in the singular set-\nting (Figure 1b) showed that when the antecedent is\nneutral, the masculine pronoun he has the highest\nprobability instead of they, meaning that models\nstruggle to interpret the pronoun they as a singular\npronoun. This finding was also reported by Gautam\net al. (2024). In language generation applications,\nthis might contribute to the erasure of people of\nnon-binary gender who use they/them pronouns, as\nwell as reinforce male-as-norm biases when people\nof unknown gender are referenced with masculine\npronouns (Cao and Daum\u00e9, 2021).\nFurthermore, in the English plural experiments\nthe most probable coreferent gender generally fol-\nlows the gender of the antecedent. However, the\nsecond- and third-highest gender probabilities paint\na more nuanced picture (Figure 1). For both fem-\ninine and neutral antecedents, masculine corefer-\nents are second-most likely. This illustrates bias,\nbecause an equitable model would display similar\nprobabilities for feminine and masculine corefer-\nents given a gender-neutral antecedent. For femi-\nnine antecedents, it would also assign higher proba-\nbilities to neutral over masculine coreferents. Thus,\nwhile the model prioritizes gendered context clues-\na desirable behavior\u2013it still exhibits an underlying\nmasculine default bias.\nThis masculine bias was not just underlying but\nclearly visible in our German experiments. Measur-\ning the probability of specific coreferents showed\nthat M\u00e4nner 'men' always had a higher probability\nthan either the feminine coreferent Frauen 'women'\nor neutral coreferent Personen \u2018persons'. This im-\nportant finding shows that gender bias in the model\noutweighs information it received in the prompt,\nwhich might lead to a reinforcement of male-as-\nnorm bias through a likely prevalence of masculine\nterms in the output. It is important to note, how-\never, that the coreferent generation experiments\nfor German did not show masculine bias to the"}, {"title": "6 Conclusion", "content": "This research adapted Tibblin et al.'s (2023)'s psy-\ncholinguistic experiments on the effects on gender-\nfair language on anaphora resolution to the domain\nof LLMs. We investigated how the use of gendered\nor gender-inclusive language within one sentence\ninfluences the generation of language in consec-\nutive sentences. Our findings indicate that while\nEnglish LLMs are likely to continue to use the gen-\nder of a mentioned entity in a subsequent sentence,\nthere is an underlying prevalence for masculine\ngender. For German, this bias appears more pro-\nnounced, with masculine gender always having\nthe highest probability in spite of feminine or neu-\ntral gender information in the previous sentence.\nHowever, with reference to Tibblin et al.'s (2023)\nfindings, gender-inclusive language strategies in\nGerman also increase the probability of feminine\nand gender-neutral referents. This research there-\nfore supports the value of using gender-inclusive\nlanguage in an LLM context, especially in under-\nrepresented languages like German."}, {"title": "7 Limitations", "content": "There are several limitations to our work. Firstly,\nthe types of models covered mainly included\nsmaller LLMs (1.5\u201332 billion parameters) due to\nhardware restrictions at our institution. In contrast,\nrecently released DeepSeek-V3, contains a total of"}]}