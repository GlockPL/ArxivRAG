{"title": "Cloud Atlas: Efficient Fault Localization for Cloud\nSystems using Language Models and Causal Insight", "authors": ["Zhiqiang Xie", "Kun Zhang", "Yujia Zheng", "Lizi Ottens", "Christos Kozyrakis", "Jonathan Mace"], "abstract": "Runtime failure and performance degradation is commonplace in modern cloud\nsystems. For cloud providers, automatically determining the root cause of incidents\nis paramount to ensuring high reliability and availability as prompt fault localiza-\ntion can enable faster diagnosis and triage for timely resolution. A compelling\nsolution explored in recent work is causal reasoning using causal graphs to capture\nrelationships between varied cloud system performance metrics. To be effective,\nhowever, systems developers must correctly define the causal graph of their system,\nwhich is a time-consuming, brittle, and challenging task that increases in difficulty\nfor large and dynamic systems and requires domain expertise. Alternatively, au-\ntomated data-driven approaches have limited efficacy for cloud systems due to\nthe inherent rarity of incidents. In this work, we present Atlas, a novel approach\nto automatically synthesizing causal graphs for cloud systems. Atlas leverages\nlarge language models (LLMs) to generate causal graphs using system documenta-\ntion, telemetry, and deployment feedback. Atlas is complementary to data-driven\ncausal discovery techniques, and we further enhance Atlas with a data-driven\nvalidation step. We evaluate Atlas across a range of fault localization scenarios\nand demonstrate that Atlas is capable of generating causal graphs in a scalable\nand generalizable manner, with performance that far surpasses that of data-driven\nalgorithms and is commensurate to the ground-truth baseline.", "sections": [{"title": "Introduction", "content": "Modern cloud systems are large-scale, complex, and dynamic, combining many inter-operating\nservices. Runtime failure and performance degradation occurs frequently, arising for many reasons\nincluding software bugs, hardware failures, incorrect high-level design and unanticipated workload\ndynamics [10]. To combat such incidents, engineers continuously monitor the health of cloud\nsystems [15, 26] using detailed telemetry of data emitted by the systems. An incident is triggered\nwhen a top-level health metric, such as end-to-end request latency or API error rate, exceeds an\nacceptable threshold; on-call engineers must then investigate, localize, and mitigate the incident"}, {"title": "2 Background", "content": "Fault Localization. Most incident investigations today are a manual process overseen or driven by\na human operator, with little automation [15, 26]. Human-driven investigations implicitly leverage\nthe human's mental model of system behavior to navigate the space of recorded metrics and system\ncomponents. From experience, code, and familiarity with system design, humans understand the\nrelationships between different metrics and reason using their system knowledge to determine what\nto investigate via a chain of cause and effect.\nCausal Reasoning. Despite promising results in controlled environments, little automation is\ndeployed in practice: data-driven approaches are inhibited by high dimensionality, excessive corre-\nlations, and high integration overhead [25]. As a possible solution, causal reasoning is compelling,\nbecause it scopes measurements based on their direct causal influences [27, 12, 34, 20] and because"}, {"title": "3 Observations", "content": "Atlas automates rules-based construction of causal graphs for computer system telemetry. This\nsection describes the key intuitions behind Atlas; in \u00a74, we present Atlas's end-to-end design.\nDomain Knowledge from System Documentation. Causal relationships between system telemetry\nderive from a high-level model of system components and interactions. In practice, it is exceedingly\nrare for such a model to be explicitly formalized. Instead, developers predominantly communicate\nthe high-level behavior of a system through design and architecture documents, describing in text\nthe system components, topology, and interactions. Examples can be found in many open-source\nsoftware projects [2, 29]. System descriptions use a high level of abstraction and make heavy\nreference to well-known systems concepts such as replication, load balancing, containers, processes,\netc. Telemetry can be similarly related to system concepts: measurements use descriptive names and\nare typically accompanied by descriptions of what is being measured. Atlas leverages this observation\nby utilizing LLMs to interpret text-based system descriptions to extract causal relationships. LLMs\nhave knowledge of common systems concepts and are able to interpret design documents.\nCausal Relationships from System Interactions. Although systems can expose a large amount\nof telemetry, the relationships between measurements are not arbitrary. We observe that direct\ncausal relationships between telemetry only arise when there is an interaction between corresponding\ncomponents. For example, the throughput of service A running on server X can only have a direct\ncausal influence on CPUx utilization because A is directly interacting with the CPU by running\ninstructions on it. By contrast, there can be no direct influence on server Y's CPUy utilization;\nthat dependency can only be established indirectly through other intermediate components, such as\nsome service B running on Y. Moreover, software systems are designed in a modular, hierarchical\nmanner to mitigate complexity; it is universally discouraged to tightly couple software components.\nTherefore, we only need to consider causal relationships between measurements from components\nthat directly interact with one another. Atlas leverages this observation from system documentation,\nwhich typically describes directly which components interact with others, as well as distributed trace\ndata [26] to directly observe runtime interactions.\nScalability from Decomposition. Thanks to the locality of interaction and causal relationships, Atlas\ndoes not need to present an LLM with wide-ranging information about the system to identify causal\nrelationships. Instead, it can decompose the task into smaller, manageable pieces, inspecting locally\nconnected components and their relationships independently. Atlas is thus scalable by design; as the\nsize of a system scales up, it increases the number of LLM interactions, but not the complexity of\ninputs or outputs to and from the LLM for each iteration.\nReconciling with the Ground Truth. Systems do not measure everything that can truly be measured.\nFor example, RPC servers in general might measure throughput, queueing time, latency, and request"}, {"title": "4 Design", "content": "Overview. Fig. 1 depicts the end-to-end pipeline of Atlas. Atlas processes descriptions of system\ncomponents, metrics, and caller-callee relationships, as well as an optional corpus of common\ncomponent and metric descriptions. Using an agent-based approach, Atlas represents each system\ncomponent as a separate LLM agent with relevant descriptions. Atlas iteratively enumerates all\npossible metrics for each component and prompts the LLM accordingly to identify causal relationships\nand their directionality between interacting agents. It then combines these outputs into a single graph,\ncollapsing indirect causal relationships through unmeasured nodes. Finally, Atlas presents the\ncandidate causal graphs to users and provides an interface for interactively refining the candidate\ngraph through review and feedback on a small set of proposed causal relationships.\n4.1 Inputs\nThe inputs to Atlas are organized as follows:\n\u2022 A collection of named system components (e.g. services, processes, etc.) and corresponding\ntextual descriptions.\n\u2022 A collection of named measurements and corresponding text descriptions where each measure-\nment is associated with a system component.\n\u2022 A list of caller-callee relationships between components.\n\u2022 A list of computational resources available to components with corresponding text descriptions.\nDescriptions can be concise or verbose; for example, the description of a gateway server may simply\nbe, \"Website gateway receives the client request.\""}, {"title": "4.2 Instantiating Agents", "content": "Atlas conceptualizes each component in the system as an agent. Agents are categorized as one of\nthe following classes: request, service, or resource. Each agent is assigned relevant information\nabout its role: component descriptions, metric descriptions, and resource descriptions. Each agent\nis also assigned the information about any components it directly interacts with; only the following\nkinds of interaction are considered: (a) a request invokes a service; (b) a request utilizes a resource;\n(c) a service utilizes a resource; (d) a service invokes another service. Each agent corresponds to a\nbounding box in Fig. 2."}, {"title": "4.3 Metrics Enumeration: Creating Nodes for the Causal Graph", "content": "As motivated in \u00a73, in addition to having all available metrics of system components as nodes within\nthe causal graph (blue nodes in Fig. 2a), we also enumerate typical measurements associated with\nthose components and convert them to be nodes as indicated in orange in Fig. 2a."}, {"title": "4.4 Causal Relationship Examination: Connecting the Nodes", "content": "Atlas iteratively evaluates whether a causal relationship exists between pairs of measurements.\nAtlas only considers measurements that either (a) exist within the same component; or (b) exist on\ncomponents that directly interact with one another. Atlas prompts the LLM from the perspective of\none agent: it furnishes the LLM with the information known by that agent about its own role and the\npair of measurements, asks whether there exists a causal relationship between the two measurements,\nand if so, asks what the direction of the causal influence is. Atlas uses common techniques to\nconstruct the prompt: chain of thoughts [35] and alternating order of options with repeating queries\nfor consistent output [37]. We provide concrete prompt examples in Appendix A.\nAtlas employs a semantic cache to store the full semantics of each query and its result. This\noptimization greatly reduces the number of times Atlas prompts the LLM because the same set of\ncomponents can be instantiated in multiple places in large-scale systems, with the same semantics and\nthus same causal relationships between measurements. By utilizing cached responses, the execution\ntime and token cost of Atlas is greatly reduced."}, {"title": "4.5 Graph Construction", "content": "Atlas combines the individual causal relationships discovered during the previous step into a causal\ngraph. The resulting causal graph is over-complete: it includes nodes for all measurements recorded\nby the system, and can also include nodes for common measurements that could be recorded by\nthe system but are not (i.e., unobserved measurements). We call this graph the confounder graph\nbecause it exposes potential unobserved confounders; we do not discard the confounder graph because\nknowledge of potential confounders may be useful for users in some future causal reasoning task or\nin revisiting the choice of measurements made by the system.\nTo produce the final causal graph, Atlas duplicates the confounder graph and deletes all unobserved\nnodes. To delete an unobserved node, Atlas removes the node while preserving any transitive causal\ninfluence that may exist, for example, if A and B are observed, but U is unobserved, then A \u2192 U \u2192 B\ncollapses to A \u2192 B. The locations of these collapsed unobserved nodes are recorded, which will be\nuseful for fault localization as explained in \u00a75.3. By removing unobserved nodes, causal relationships\nthat were previously indirect may now be direct."}, {"title": "4.6 Data-driven Human-in-the-loop Pareto Refinement", "content": "Atlas lacks guarantees that the resulting causal graph is correct, so it employs an optional human-\nin-the-loop refinement step to identify and correct four kinds of errors that may exist in the graph:\ncycles, false positives, false negatives, and reversed directionality. As motivated in \u00a73, we employ\ndata-driven approaches to filter out a small set of candidates for feedback and refinement. Specifically,\nwe: 1) Apply Markov blanket discovery to examine all proposed causal relationships. We sample five"}, {"title": "5 Evaluation", "content": "Our evaluation aims to answer the following key questions:\n\u2022 Does Atlas generate superior causal graphs compared to traditional data-driven causal discovery\nalgorithms? (\u00a75.1)\n\u2022 How effective are the causal graphs generated by Atlas for fault localization use cases? (\u00a75.2)\nIn addition to addressing the questions above, our evaluation concludes with three Atlas case studies\n(\u00a75.3).\nAtlas Variants. To better understand the contribution of Atlas' design, our evaluation compares\nthree different variants of Atlas: NA\u00cfVELLM uses a one-shot LLM prompt to construct the graph. It\nprovides all of the text descriptions used by Atlas in a single input, and prompts the LLM to generate\nall edges of the causal graph. ATLAS+V utilizes the full Atlas pipeline including the data-driven\nvalidation step described in \u00a74.6. ATLAS utilizes the full pipeline, but omits the final data-driven\nvalidation step. All Atlas variants use GPT-4-turbo as the LLM. Due to non-deterministic LLM\noutputs, we repeat all Atlas experiments 5 times and report averaged results.\nData-driven Causal Discovery. We compare the causal graphs generated by Atlas to those produced\nby the following data-driven causal discovery algorithms: GES [6], GRaSP [17], and PC [32]. All\nexperiments are also repeated 5 times and averaged results are reported.\nExisting Scenarios. We make use of several pre-existing datasets from prior work that provide\nobservational data and ground-truth causal graphs for systems scenarios: the Middleware Oriented\nMessage activity (MoM) and Antivirus Activity (AA) scenarios from prior IT system monitoring\nwork [1] and the Microservices latency scenario from the DoWhy causal reasoning library [8]. We\nsupplement the observational data with brief textual descriptions of the system components.\nNew Scenarios. To evaluate Atlas at larger scale, we have developed a discrete event simulator that\ncan simulate the dynamics of cloud environments including dynamic service topologies, execution\nflow, resource contention, workloads, and faults. Within this simulator we implement a model serving\nservice and workload, following the design of DLIS [31]. Fig. 3 depicts the high-level execution flow:\na client's request reaches a router and is load-balanced to a worker server; it enters a queue, and when"}, {"title": "5.1 Comparison on Causal Graph Construction", "content": "In this experiment, we apply all causal graph construction techniques to all datasets. We measure the\neffectiveness of each technique by calculating the F1 score of the edges of the constructed graphs\nwith respect to a ground truth baseline. We present the results in Table 1.\nIn general, while different causal discovery algorithms (GES, GRaSP, PC) exhibit unique strengths\ndepending on the data distribution, they generally perform poorly in system troubleshooting scenarios\nas indicated by the results in Table 1. This underperformance is primarily due to a fundamental bias\nin system measurement data: most data is collected during normal operating states as abnormal states\nare rare, diverse, and often fail to be recorded. Additionally, these algorithms tend to perform worse\nas the number of nodes increases.\nBy contrast, ATLAS attains the highest F1 scores across all datasets. On small datasets, ATLAS\neither generates the same causal graph as the ground-truth, or has additional superfluous edges.\nATLAS maintains strong performance as the graph size increases. ATLAS+V demonstrates further\nimprovements over the baseline ATLAS: the additional data validation and Pareto refinement steps\nfurther improve the quality of the causal graph. The average number of proposed and accepted graph\nmodifications of ATLAS+V is included in Table 1."}, {"title": "5.2 End-to-end Fault Localization on Model Serving", "content": "We evaluate the impact of Atlas for fault localization use cases, and demonstrate that Atlas' superior\ncausal graphs result in significantly improved fault localization performance. We focus on the three\nModelServing scenarios for which we have separate normal-state and failure-state observational\ndatasets.\nWe utilize an off-the-shelf fault localization algorithm (distribution_change) from the DoWhy\ncausal reasoning library [3]. This algorithm takes as input a causal graph, a dataset of normal-state\nobservations, and a dataset of failure-state observations. The algorithm calculates and outputs an\nattribution score for each dataset feature, representing the likelihood that the feature is the root cause.\nWe apply the algorithm separately using the causal graphs generated by ATLAS and ATLAS+V, and to\nthe ground-truth causal graph. To serve as comparison, we also apply the algorithm to the highest\nscoring causal graph generated by GES, GRaSP, or PC (as reported in \u00a75.1). We consider a failure to\nbe correctly identified if the true root cause appears in the output and evaluate the top-1 and top-3\nranked features. We repeat this process for all failure datasets.\nTable 2 reports results averaged across the 7, 13, and 24 failure scenarios for ModelServing -S, -M, and\n-L respectively. The results illustrate that the ATLAS and ATLAS+V graphs are sufficient for identifying\nroot causes across most failure scenarios. Moreover, they do not perform significantly worse than the\nground-truth causal graph. Upon inspection, we found that Atlas graphs were succeeding and failing\nfor the same scenarios as the ground-truth causal graph. By contrast to Atlas, the graphs generated by\ncausal discovery algorithms perform poorly and do not reliably localize faults.\nThese results indicate that F1 scores are not a sufficient indicator that a causal graph is effective for\nfault localization. We highlight two reasons for this. First, counterfactual reasoning is only conducted\non the subgraph of causal predecessors of the symptom node, whereas the F1 score measures the\nrelative correctness of the entire graph. Second, a single incorrect edge or inverted directionality can\nhave a minor effect on the F1 score, but a significant effect on the efficacy of causal reasoning. When\nexamining the causal graphs produced by Atlas, we found that most incorrect edges do not change the\nconnectivity of the causal graph and do not break the chain of causality from symptom to root cause,\nenabling comparable performance to the ground truth. We examine this effect in more detail in \u00a75.3."}, {"title": "5.3 Case Studies", "content": "We examine the causal graph in the ModelServing scenario to better understand the behavior of fault\nlocalization and its limitations with respect to causal graphs.\nLocalize the Real Fault Beyond Discrete Signals. A key strength of causal reasoning compared to\nother fault localization techniques is its robustness to diverse telemetry signals, including discrete,"}, {"title": "6 Related Work", "content": "LLMs for System Troubleshooting. RCACopilot [5] proposed a pipeline that leverages LLMs as\npowerful text processing tools to summarize historical incidents, match them with newly occurred\nincidents, and synthesize possible root causes and mitigations based on historical data. This ex-\nemplifies a line of research [30] utilizing LLMs as information processing and reasoning engines.\nHowever, the effectiveness of these approaches strongly depends on the historical data, as identical\nsymptoms can arise from entirely different causes, and similar symptoms may have never occurred\nbefore. Atlas employs a two-stage approach to overcome this limitation: LLMs are used to process\ndomain knowledge and assist in causal graph construction, while the reasoning is powered by a causal\nreasoning engine that utilizes abundant measurement data.\nCausal Discovery. Causal discovery aims to uncover causal relations from observational data\nwithout any interventional experiments. Classical algorithms include constraint-based methods (e.g.,\nPC [32]), score-based methods (e.g., GES [7]), and many others (e.g., GRaSP [17]). Recently,\nlarge language models (LLMs) have demonstrated impressive empirical performance in addressing\nsome causality-related tasks [16, 36, 24, 22, 33, 14, 21]. Although LLM-based methods lack\ncomprehensive theoretical guarantees, their notable successes in diverse scenarios highlight their\npotential applicability in complex real-world tasks, where assumptions for identifiability theory often\ndo not hold perfectly in practice.\nCausal Reasoning for System Troubleshooting. Several research works leverage the causal\nstructure of service dependency graphs, where nodes are common service measurements such\nas latency [9, 19, 23, 34, 20]. This causal structure only relates a small number of externally-visible\nmeasurements, however it can serve as a useful starting point for constructing causal graphs, e.g. by\nincluding more metrics and their causal relationships [4, 18]. For more diverse measurements such as\nhardware utilization, service rate, or application-defined metrics, no universal rules or mapping exists.\nCausal discovery algorithms have been utilized for microservice metrics [11], and face the challenges\noutlined in this paper. Chaos engineering is a compelling approach to uncover the diversity of system\nexecution behaviors in small scale [12]; however scaling such an approach to a full cloud system\nrepresents a significant challenge."}, {"title": "7 Limitations and Future Work", "content": "Constructing causal graphs is a key step for effective fault localization. However, end-to-end there\nremain several obstacles. First, causal reasoning algorithms scale poorly to large graphs; we have\nidentified several optimization opportunities based on graph decomposition that we are leveraging in\nour ongoing work. Second, causal graphs require special handling for the temporal feedback cycles\nthat exist in systems, which cannot be represented as a DAG. Third, the causal graph is insufficient\nfor representing all semantics of a system, such as semantic equivalence between components that\nare represented by different subgraphs. Lastly, domain knowledge can provide hints as to the correct\ncausal mechanism to assign to each node; this is not currently captured. Our future work on Atlas\nwill be guided by user feedback from open-sourcing the project."}, {"title": "A Sample Input Files", "content": "A.1 Trace File\nFollowing is a sample trace file from ModelServingS dataset. This can be automatically extracted\nfrom traces of requests and system deployment configs.\n{\n\"request.Client\": {\n\"service_description\": \"client that sends request to the router\",\n\"resources\": {},\n\"callees\":[\n\"Client-Router\"\n]\n},\n\"request.Client.Client-Router\": {\n\"service_description\": \"network communication that\nsend request from client to router\",\n\"resources\": {},\n\"callees\":[\n\"Router\"\n]\n},\n\"request.Client.Router\": {\n\"service_description\": \"router that processes and\ndispatches request to different servers\",\n\"resources\": {},\n\"callees\": [\n\"Router-Queue_0\"\n]\n},\n\"request.Client.Router-Queue_0\": {\n\"service_description\": \"network communication that\nsend request from router to servers\",\n\"resources\": {},\n\"callees\": [\n\"Queue_0\"\n]\n},\n\"request.Client.Queue_0\": {\n\"service_description\": \"when requests are received at a server,\nthey are buffered in the queue and waited to be executed.\nRequests will be dequeued and processed by the batcher\nwhen resources are available\",\n\"resources\": {},\n\"callees\":[]\n},\n\"request.Client.Batcher_0\": {\n\"service_description\": \"when resources are available,\nthe batcher will check the queue and create a batch of\nmin(available requests, max batch size) requests\nand send it to the model inference service\",\n\"resources\": {},\n\"callees\": [\n\"Queue_0\"\n]\n},\n\"request.Client.ModelInference_0\": {\n\"service_description\": \"model inference service that"}, {"title": "A.2 Measurement Description", "content": "Following is a measurement description file explaining all the available metrics for different kinds of\nsystem components. These information can usually be found from documentation of observability\nframework and the observed system.\n{\n\"Client\": {\n\"request_level\": {\n\"latency\": \"The time taken for a request to be processed from\nthe time it is sent to the time the response is received\"\n}\n},\n\"Client-Router\": {\n\"request_level\": {\n\"latency\": \"The time taken for an invoked service to\nprocess the request\"\n}\n},\n\"Router\": {\n\"request_level\": {\n\"latency\": \"The time taken for an invoked service to\nprocess the request\"\n},\n\"service_level\": {\n\"throughput\": \"The number of requests that\na service successfully processes per second\"\n}\n},\n\"Router-Queue\": {\n\"request_level\": {\n\"latency\": \"The time taken for an invoked service to\nprocess the request\"\n}\n},\n\"Queue\": {\n\"request_level\": {\n\"latency\": \"The time waited by a request in the queue\nbefore it is dequeued\",\n\"queue_length\": \"The number of requests waiting in the queue\nwhen a request is enqueued\"\n},"}, {"title": "A.3 Common Metrics", "content": "This file is used to realize metric enumeration for a more complete graph construction as discussion\nin \u00a73.\n{\n\"service\": {\n\"request_level\": {\n\"latency\": \"The time taken for an invoked service\nto process the request\"\n},\n\"service_level\": {"}, {"title": "B Sample Prompt", "content": "Here is an sample prompt for the \"Queue_0\" to figure out the causal relationship between its\n\"queue_length\" and \"dequeueing_rate\".\n[\n{'role': 'system', 'content': 'You are a service named Queue in a software\nsystem and your job is: when requests are received at a server, they are buffered\nin the queue and waited to be executed. Requests will be dequeued and\nprocessed by the batcher when resources are available. You are about to figure\nout the causal relationship between a metric of you and a metric of another system\ncomponent.'},\n{ 'role': 'user', 'content': 'queue_length is a metric of you and it means\nthe number of requests waiting in the queue when a request is enqueued.\ndequeueing_rate is another metric of you and it means the rate at which requests\nare being dequeued, in requests per second. If we can only choose one, which\nof the following cause-and-effect relationship is more likely?\nA. A change in \"queue_length\" of you directly causes a change in \"dequeue-\ning_rate\" of Queue_0.\nB. These two metrics do not directly influence each other, even if they might\nbe correlated through other components in the system.\nC. A change in \"dequeueing_rate\" of Queue_0 directly causes a change in\nqueue_length of you.\nPlease think step by step to make sure that you have the right answer. Please\nselect from one of the following options: [A, B, C] as the final answer. Put it as the\nonly content in the last line.'}\n]\nHere is another sample prompt for the \"ModelInference\" to figure out how its \"execution_batch_size\"\ninfluence the max_batch_size of \"Batcher\".\n['role': 'system', 'content': 'You are a service named ModelInference in a\nsoftware system and your job is: model inference service that runs the model\ninference on the batched requests. You are about to figure out the causal relation-\nship between a metric of you and a metric of another system component.', 'role':\n'user', 'content': 'Batcher_0 is the next service that requests will invoke after you\nfinish processing them, whose job is: when resources are available, the batcher\nwill check the queue and create a batch of min(available requests, max batch\nsize) requests and send it to the model inference service execution_batch_size\nis a metric of you and it means The number of requests that are processed in a\nsingle batch. max_batch_size is a metric of the next service and it means The\nmaximum size of a batch that can be created. If we can only choose one, which\nof the following cause-and-effect relationship is more likely?\nA. These two metrics do not directly influence each other, even if they might\nbe correlated through other components in the system."}]}