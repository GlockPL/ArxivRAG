{"title": "SemiDFL: A Semi-Supervised Paradigm for Decentralized Federated Learning", "authors": ["Xinyang Liu", "Pengchao Han", "Xuan Li", "Bo Liu"], "abstract": "Decentralized federated learning (DFL) realizes cooperative model training among connected clients without relying on a central server, thereby mitigating communication bottlenecks and eliminating the single-point failure issue present in centralized federated learning (CFL). Most existing work on DFL focuses on supervised learning, assuming each client possesses sufficient labeled data for local training. However, in real-world applications, much of the data is unlabeled. We address this by considering a challenging yet practical semi-supervised learning (SSL) scenario in DFL, where clients may have varying data sources: some with few labeled samples, some with purely unlabeled data, and others with both. In this work, we propose SemiDFL, the first semi-supervised DFL method that enhances DFL performance in SSL scenarios by establishing a consensus in both data and model spaces. Specifically, we utilize neighborhood information to improve the quality of pseudo-labeling, which is crucial for effectively leveraging unlabeled data. We then design a consensus-based diffusion model to generate synthesized data, which is used in combination with pseudo-labeled data to create mixed datasets. Additionally, we develop an adaptive aggregation method that leverages the model accuracy of synthesized data to further enhance SemiDFL performance. Through extensive experimentation, we demonstrate the remarkable performance superiority of the proposed DFL-Semi method over existing CFL and DFL schemes in both IID and non-IID SSL scenarios.", "sections": [{"title": "Introduction", "content": "Federated Learning (FL) enables collaborative learning among distributed clients while keeping their data local and preventing \"data islands\". However, traditional Centralized Federated Learning (CFL) relies on a central server to aggregate model parameters from all clients, which suffers from high communication bottleneck and single-point-failure problems. Decentralized Federated Learning (DFL) addresses this issue by enabling direct communication between clients and their connected neighbors for model aggregation. By removing the central server, DFL alleviates the communication bottleneck of traditional FL and enhances model scalability and robustness. Existing CFL and DFL approaches are mostly designed for supervised learning, which relies heavily on large quantities of labeled data for model training. However, collecting and labeling extensive datasets in real-world applications is challenging due to time constraints, high costs, and the need for expert knowledge. Furthermore, clients often possess diverse data sources (e.g., labeled, unlabeled, or both) with heterogeneous distributions. This raises this paper's key question: How can DFL be effective when clients have labeled and unlabeled data sources in highly non-iid scenarios? Semi-supervised learning (SSL) provides an effective approach to leverage unlabeled data for improved model performance. The main idea is to estimate pseudo-labels for unlabeled data, enhancing model training alongside data augmentation methods. Thus far, researchers have developed SSL methods for centralized federated learning scenarios, where a central server facilitates the sharing of supervised information among clients. However, applying these methods to DFL is challenging due to the lack of central coordination. To the best of our knowledge, no SSL method has been specifically designed for DFL with diverse data sources and non-IID data distributions. Designing a practical and effective semi-supervised DFL method presents several challenges introduced by limited labels in non-IID settings. First, accurately estimating pseudo-labels is crucial in SSL, but non-IID datasets make unbiased predictions challenging for a client's local model in DFL. Second, relying only on labeled and pseudo-labeled data may be insufficient for model training particularly for clients with limited labeled data, while unbiased data generation in highly non-IID DFL scenarios is challenging. In this paper, we propose a semi-supervised learning paradigm for DFL (SemiDFL) to deal with the above challenges, by establishing consensus in both model and data spaces. Specifically, we propose a neighborhood pseudo-labeling method that introduces neighborhood classifiers for estimating pseudo-labels and uses neighborhood-qualified pseudo-label numbers to update the filtering threshold. This approach effectively improves the quality of pseudo-labeling and qualified pseudo-labeled data filtering, thereby enhancing classifier model training. We then design a consensus-based diffusion model for each client to generate synthesized data with a similar data distribution for further data MixUp operation combined with labeled and pseudo-labeled data. This forms a consensus data space among clients and therefore benefits the model training process and alleviates the non-IID issue. Instead of using average aggregation in the global consensus process, we design an adaptive aggregation method based on each classifier's accuracy on synthesized data generated by its diffusion model. This approach enhances model aggregation efficiency, forming a more effective consensus model space for both classifier and diffusion, which alleviates data source divergence and improves overall model performance. Our paper mainly makes the following contributions:\n\u2022 SemiDFL Paradigm: To our best knowledge, SemiDFL is the first semi-supervised DFL paradigm that is effective for clients with diverse data sources (labeled, unlabeled, and both) in highly non-IID settings. We innovatively propose consensus model and data spaces in SemiDFL to address the challenges of limited labels and non-IID data in semi-supervised DFL scenarios.\n\u2022 Consensus data space: We design neighborhood pseudo labeling to improve the pseudo labeling quality of each client by combining its neighborhood information, and utilize the consensus-based DFL rule to train a unified diffusion model to generate synthesized data for further data MixUp. This helps to build a consensus data space among all clients to boost the classifier training.\n\u2022 Consensus model space: We design an adaptive consensus mechanism based on each classifier model's performance on generated data to dynamically aggregate neighborhood diffusion and classifier models, circumventing the need of an extra shared dataset for model performance evaluation. This helps establish a better consensus model space across diverse clients.\n\u2022 Extensive Experiments: We comprehensively evaluate SemiDFL through extensive experiments on different datasets, models, SSL settings, and non-IID degrees. The results verified SemiDFL's superior performance against existing methods."}, {"title": "Preliminaries and Related Work", "content": "Decentralized Federated Learning\nConsider a DFL system with a set N = {1,2,..., N} of clients, where each client i has a general local model \u03b8i and a private dataset Xi containing Xi data samples. The goal of DFL is to minimize the total loss across all N clients:\n\n$\\min_{\\Theta} \\frac{1}{N} \\sum_{i=1}^{N} l(\\theta_i; X_i)$,\n\nwhere \u0398 = {\u03b8i, i \u2208 N} is the set of all local \u03b8i, l(\u03b8i; Xi) represents the local loss function of client i. DFL typically runs over T rounds, with the following procedures executed sequentially in each round t:\n\u2022 Local training: Each client i independently trains its local model on its dataset Xi. The update is given by:\n\n$\\theta_i^{t+1/2} = \\theta_i^t - \\eta \\nabla l(\\theta_i^t)$,\n\nwhere \u03b8i^t+1/2 is the locally optimized model, \u03b7 is the learning rate, and \u2207 is the gradient. Notably, it can be multiple local training iterations in each round t.\n\u2022 Global consensus: Each client i exchanges its local optimized model with its connected neighbors, and then aggregates the updates using a consensus mechanism:\n\n$\\theta_i^{t+1} = \\sum_{j \\in G_i} W_{ij} \\theta_j^{t+1/2}$ ,\n\nwhere Gi denotes the sub-graph centered on client i (including client i and its neighbors), wij is the aggregation weight of client j on client i, \u03b8i^t+1 is the globally updated model for client i in round t + 1.\nSemi-supervised Learning Objective in DFL\nWe consider a practical SSL scenario with three types of clients based on their various data sources.\n\u2022 Labeled Client (L-client): clients with only a few labeled data samples.\n\u2022 Unlabeled Client (U-client): clients with only unlabeled data samples.\n\u2022 Mixed Client (M-client): clients with both a few labeled data samples and many unlabeled samples.\nWe consider a system consisting of L-client set NL, U-client set Nu, and M-client set NM. The aim of semi-supervised learning in DFL system is to jointly minimize the objectives of all clients as follows:\n\n$\\min(\\sum_{i \\in N_L} l(L_i;\\theta_i) + \\sum_{j \\in N_U} l(U_j; \\theta_j) + \\sum_{k \\in N_M} l(M_k; \\theta_k))$ ,\n\nwhere Li, Ui and Mk represent the datasets of L-, U- and M-clients, respectively. For Mi, we further denote its labeled and unlabeled data as M_k^l and M_k^u, respectively.\nRelated Works\nSemi-supervised learning (SSL) aims to leverage unlabeled data to enhance machine learning model performance, especially when unlabeled data predominates. A classical SSL method is pseudo-labeling, an entropy minimization approach that estimates a data sample's label based on model predictions. Pseudo-labeling is often combined with data augmentation techniques (e.g., MixUp, MixMatch, FixMatch) to boost SSL performance. The main idea behind data augmentation is to expand the training dataset by interpolating data samples. Recent work proposes using a diffusion model to generate synthesized data, further improving data augmentation in SSL. Existing federated learning approaches primarily focus on supervised learning with fully labeled datasets, which may be impractical in many real-world scenarios, as noted in . One research direction assumes a labeled server with unlabeled clients. In , model parameters are divided between servers with labeled data and clients with unlabeled data. The study suggests training and aggregating a server model with labeled data to guide parallel client models with unlabeled data. Another research direction assumes that some clients have labeled data. The work proposes using a shared GAN model to generate synthesized data, creating a unified data space to enhance federated SSL performance. RSCFed tackles the challenges of federated semi-supervised learning in non-iid settings by employing random sub-sampling and distance-reweighted model aggregation. CBAFed uses a fixed pseudo-labeling strategy to prevent catastrophic forgetting and designs class-balanced adaptive thresholds based on local data distributions to address SSL challenges in the federated learning setting. However, without a central coordinator server, it is challenging to apply SSL methods for FL to DFL scenarios with varying data sources and non-IID data distribution. To our knowledge, there is currently no SSL method specifically tailored for DFL that addresses the challenges of diverse data sources and non-IID data distributions."}, {"title": "Methodology", "content": "Overview of SemiDFL\nSemiDFL aims to establish consensus in both model and data spaces among connected clients, addressing the challenge of limited labels in semi-supervised DFL without data sharing. It achieves consensus model space through global consensus on classifiers and diffusion models (presented by \u03c6i and \u03c8i respectively, i \u2208 N) during the DFL training process. All consensus-based diffusion models generate synthesized data following a similar distribution, which is then mixed with labeled and pseudo-labeled data to form a consensus data space. The framework of SemiDFL is illustrated with key components described below:\n\u2022 Neighborhood Pseudo-Labeling: After training local classifier model \u03c6i, i \u2208 N, client i first estimates pseudo-labels of its unlabeled samples (if it has) using local model \u03c6i and then filters unlabeled samples with qualified pseudo-label. Notably, neighborhood classifiers are introduced to enhance the pseudo-labeling process, and neighborhood-qualified pseudo-label numbers are used to adaptively update the filtering threshold.\n\u2022 Consensus MixUp: Following pseudo-labeling, each client i trains a diffusion model \u03c8i using labeled and/or pseudo-labeled samples. Notably, all diffusion models \u03c8i, i \u2208 N are aggregated based on a consensus mechanism, leading to a unified diffusion model. This makes synthesized data Di, i \u2208 N generated from diffusion models \u03c8i, i \u2208 N follows a similar distribution (consensus data space) for subsequent MixUp.\n\u2022 Adaptive Aggregation: Instead of using constant weights for classifier and diffusion models aggregation to form consensus model space, each client i adaptively aggregates its neighborhood models wij based on classifier performance. Each client i samples an extra small dataset from Di, i \u2208 N (share a similar distribution) to evaluate its classifier. This not only ensures that all local models are evaluated on a shared dataset but also helps to circumvent data island problems in DFL.\nNeighborhood Pseudo-Labeling\nPseudo-Labeling For the n-th indexed unlabeled data sample un \u2208 U or un \u2208 $M^u$ of client i, we estimate its pseudo-label using the client's classifier model \u03c6i, combined with label-invariant data augmentation and a label sharpening method. We first compute the label prediction pin \u2208 R1\u00d7C (C is the number of categories) for sample un as follows:\n\n$p_n^i = \\frac{1}{K} \\sum_{k=1}^K F(u_{n,k}; \\phi_i)$,\n\nwhere K is the number of variants for data augmentation, such as image rotation and cropping, F(un,k; \u03c6i) is the classifier with un,k being the k-th augmented variant of sample un.\nWe then estimate the pseudo-label of un using label sharpening. The probability that un is predicted as class c is given by:\n\n$\\hat{p}_{n,c}^i = \\frac{(p_{n,c}^i)^{1/Z}}{\\sum_{c'=1}^C (p_{n,c'}^i)^{1/Z}}$\n\nwhere pic is the probability of class c in pni, and Z > 1 amplifies the dominating classes.\nNeighborhood Pseudo-Labeling (NPL) In the challenging SemiDFL scenario with non-IID data, traditional pseudo-labeling methods suffer from high divergence among clients and noisy pseudo-labels, making them inadequate for providing high-quality supervision independently. We propose leveraging neighborhood information to address these challenges. On the one hand, we introduce neighborhood classifiers to predict the label of a sample un's variant in client i. This design combines client i and its neighborhood classifiers' label predictions, thereby enhancing the robustness of pseudo-label prediction and reducing instability in highly non-IID settings. Specifically, we modify the label prediction as:\n\n$p_n^i = \\frac{1}{K} (F(u_{n,1}; \\phi_i) + \\sum_{k=2}^K F(u_{n,k}; \\phi_k))$,\n\nwhere \u03c6k is a randomly selected model from the neighborhood set Gi of client i, i.e., {\u03c6j, j \u2208 Gi}, for each data variant un,k. On the other hand, we design a neighborhood adaptive class-wise threshold to filter noisy pseudo-label predictions, inspired by the dynamic threshold determination in. First, we calculate the number of samples with pseudo-label prediction probability above a manually defined threshold \u03c4, given by:\n\n$\\sigma_i^{t,c} = \\sum_{n=1}^{U_i} \\mathbb{I}(max(p_n^i) > \\tau) \\cdot \\mathbb{I}(argmax(p_n^i) = c)$,\n\nwhere U_i is the number of samples of all the unlabeled data in current client i with pseudo-label prediction probability above the threshold in class c and $\\mathbb{I}(\\cdot)$ is an indicator, taking 1 if the condition in the parentheses is true, and 0 otherwise. Then, the threshold is adaptively updated by:\n\n$\\tau_i^{t,c} = \\frac{\\sigma_i^{t,c}}{max(max(\\sigma_i^{t,c}), i \\in G_i)}$,\n\nwhere \u03c4it,c is the neighborhood adaptive threshold. This helps balance the number of pseudo-label samples, reducing the negative impact of non-IID data.\nConsensus MixUp\nLocal MixUp (L-MixUp) After filtering unlabeled samples with qualified pseudo-labels for client i, we generate mixed samples using MixUp based on the union set of labeled dataset Li and pseudo-labeled samples Pi for local classifier model training. Suppose (xm, ym) and (xn, yn) are two m- and n-th indexed data samples in the union set Li \u222a Pi. The MixUp operation produces:\n\nx' = \u03bbxm + (1 \u2212 \u03bb)xn,\ny' = \u03bbym + (1 \u2212 \u03bb)yn,\n\nwhere \u03bb is a hyper-parameter that determines the mixing ratio, (x', y') is the mixed data sample.\nConsensus MixUp (C-MixUp) L-MixUp leads to suboptimal performance in the DFL scenarios with few and non-IID labeled data because data sharing is not allowed among agents. For this issue, we propose the consensus MixUp (C-MixUp) which facilitates data imputation across all agents without raw data sharing. C-MixUp employs a generative learning manner to form a consensus data space, enabling the generation and mixing of data samples without data sharing. For each client i, we adopt a diffusion model to generate synthesized data. In the training phase, we first obtain the noisy latent Xh by progressively adding noise to input data X0, where h denotes a randomly sampled diffusion timestep. Then, We train a diffusion model D(\u00b7; \u03c8i) to predict the noise \u03f5 added on Xh by minimizing the following objective l'(\u00b7; \u03c8i):\n\nl'(\u00b7; \u03c8i) = Eh,X0,\u03f5\u223cN (0,1) [|| D(Xh, c, h; \u03c8i) \u2212 \u03f5||2]\n\nwhere \u03c8i is parameter of the diffusion model, x is a data sample with c being its class. Notably, the X0 could come from the labeled or unlabeled dataset, and \u03f5 maybe its real class or generated pseudo-label. In the sampling phase, pseudo-images are generated via deterministic sampling combined with the classifier-free method from the trained diffusion model. We denote this generated dataset by diffusion model as Di. Notably, the local diffusion model \u03c8i is globally updated through a consensus mechanism during the DFL training process. This ensures that all local \u03c8i converge to a unified model, thus all generated datasets Di, i \u2208 N follow a similar data distribution. The generated data from Di is then combined with X_i and Pi to produce more mixed samples for enhancing local training. Specifically, we create a new union set Li \u222a Pi \u222a Di to improve the MixUp process. This forms a consensus data space.\nAdaptive Aggregation In the vanilla DFL setting, each agent's aggregation weight is fixed, based on the communication topology and consensus strategy. This unchanging influence on neighbors is inefficient in the DFL-Semi scenario. Ideally, agents with better performance should exert more influence, i.e., have larger aggregation weights. However, assuming a shared test dataset to evaluate each client's performance is impractical due to privacy constraints. Nevertheless, since all datasets Di, i \u2208 Gi share a similar distribution, making them ideal for performance evaluation. To reduce computing cost, each client randomly samples an tiny validation dataset D'i from Di to evaluate its performance for determining the aggregation weights of neighbors at the t-th round. We use ai to denote the accuracy of model i on the validation dataset D'i. The adaptive weight is then obtained by\n\nWij = \\frac{exp(a_i - \\bar{a})}{\u03a3_{j \\in G_i} exp(a_j - \\bar{a})},\n\nwhere $\\bar{a_i}$ = $\\frac{1}{|G_i|} \u03a3_{j \\in G_i} a_j$ is the averaged accuracy in the sub-graph Gi with $|G_i|$ being the number of clients in the sub-graph."}, {"title": "Experiments", "content": "Experimental Setup\nWe use the decentralized communication topology in Figure 1(a) as an example to evaluate SemiDFL on different datasets, various labeled data ratios, and non-IID degrees. More detailed experimental settings and parameters can be found in the supplementary material.\nDatasets and Models We evaluate SemiDFL on MNIST and Fashion-MNIST using Convolutional Neural Network (CNN), and on CIFAR-10 using ResNet-18. Hyper-Parameters We adopt the same method in to simulate different non-IID data distribution degrees. Specifically, the non-IID degree is captured by a sample allocation probability \u03b1, with smaller \u03b1 indicating a higher non-IID degree. The percentage of total labeled data in the union of all clients' data is denoted by the labeled data ratio r. We train models for 500 global rounds on all datasets. In each global training round, each client performs E (25 for MNIST, 50 for Fashion-MNIST and CIFAR-10) iterations of local training via mini-batch SGD with a batch size of B = 10. Other hyper-parameters during local model training are inherited from the default settings of Adam\n\nTable 2 shows that NPL consistently outperforms both Vanilla PL and Adaptive APL across all settings. While APL improves Vanilla PL by incorporating an adaptive filtering threshold, it still lags in performance within the DFL scenario due to dynamic and noisy supervision, especially in highly non-IID cases. NPL significantly enhances model performance by leveraging neighborhood information and the number of qualified pseudo-labels in each round to refine supervision. This verifies the effectiveness and superiority of the proposed neighborhood pseudo-labeling method.\nConsensus MixUp To demonstrate the efficacy of the proposed C-MixUp method, we compare the following three variants. Notably, a client's labeled and pseudo-labeled data can be an empty set if it lacks this data source.\n\u2022 Local MixUp (L-MixUp): Each client performs local MixUp using labeled and pseudo-labeled data to generate mixed data for local classifier training.\n\u2022 C-MixUp with GAN (w/ GAN): Each client performs C-MixUp leveraging labeled data, pseudo-labeled data, and synthesized data generated by a consensus-based GAN model to create mixed data for local classifier training.\n\u2022 C-MixUp with Diffusion (w/ Diffusion, Ours): Each client performs C-MixUp using labeled data, pseudo-labeled data, and synthesized data generated by a consensus-based diffusion model to produce mixed data for local classifier training.\nTable 3 shows that our proposed C-MixUp method consistently outperforms all three variants. Additionally, both C-MixUp with diffusion and GAN achieve higher accuracy than L-MixUp, particularly in highly non-iid scenarios (small \u03b1). This verifies the efficacy of the consensus data space designed by C-MixUp in semi-supervised DFL tasks.\nAdaptive Aggregation We examine the efficacy of adaptive aggregation by comparison with its three variants:\n\u2022 Constant weight: Clients in a sub-graph use a constant weight to aggregate their classifier and diffusion models.\n\u2022 Adaptive on test dataset (AdaTest): Clients aggregate models based on adaptive weights determined by their accuracy on an extra test dataset. For this ablation study only, we assume clients have access to an extra shared test dataset.\n\nTable 4 demonstrates that the proposed AdaGen outperforms constant weight aggregation and shows comparable performance to AdaTest, despite not having access to an extra shared test dataset. This enables effective performance evaluation while preserving data privacy."}, {"title": "Conclusion", "content": "This paper proposes SemiDFL, the first semi-supervised DFL paradigm through constructing consensus data and model spaces among clients to tackle the challenges of limited labels and highly non-IID data distributions in DFL. SemiDFL utilizes neighborhood information to enhance the estimation and filtering of pseudo-labels for unlabeled samples, improving both the quality and robustness of pseudo-labeling. Additionally, a consensus-based diffusion model generates synthesized data with a similar distribution, facilitating MixUp and forming a consensus data space that mitigates non-IID issues in classifier training. We further design an adaptive aggregation strategy based on each client's performance to establish a more effective consensus model space, enhancing classifier performance. Extensive experimental evaluations demonstrate the superior performance of SemiDFL compared to existing semi-supervised learning methods in DFL scenarios."}, {"title": "Reproducibility Checklist", "content": "This paper:\n\u2022 Includes a conceptual outline and/or pseudocode description of AI methods introduced. (yes)\n\u2022 Clearly delineates statements that are opinions, hypothesis, and speculation from objective facts and results. (yes)\n\u2022 Provides well marked pedagogical references for less-familiare readers to gain background necessary to replicate the paper. (yes)\n\u2022 Does this paper make theoretical contributions? (no)\nDoes this paper rely on one or more datasets? (yes)\n\u2022 A motivation is given for why the experiments are conducted on the selected datasets. (yes)\n\u2022 All novel datasets introduced in this paper are included in a data appendix. (NA)\n\u2022 All novel datasets introduced in this paper will be made publicly available upon publication of the paper with a license that allows free usage for research purposes. (NA)\n\u2022 All datasets drawn from the existing literature (potentially including authors' own previously published work) are accompanied by appropriate citations. (yes)\n\u2022 All datasets drawn from the existing literature (potentially including authors' own previously published work) are publicly available. (yes)\n\u2022 All datasets that are not publicly available are described in detail, with explanation why publicly available alternatives are not scientifically satisficing. (NA)\nDoes this paper include computational experiments? (yes)\n\u2022 Any code required for pre-processing data is included in the appendix. (no).\n\u2022 All source code required for conducting and analyzing the experiments is included in a code appendix. (no)\n\u2022 All source code required for conducting and analyzing the experiments will be made publicly available upon publication of the paper with a license that allows free usage for research purposes. (yes)\n\u2022 All source code implementing new methods have comments detailing the implementation, with references to the paper where each step comes from. (yes)\n\u2022 If an algorithm depends on randomness, then the method used for setting seeds is described in a way sufficient to allow replication of results. (yes)\n\u2022 This paper specifies the computing infrastructure used for running experiments (hardware and software), including GPU/CPU models; amount of memory; operating system; names and versions of relevant software libraries and frameworks. (yes)\n\u2022 This paper formally describes evaluation metrics used and explains the motivation for choosing these metrics. (yes)\n\u2022 This paper states the number of algorithm runs used to compute each reported result. (yes)\n\u2022 Analysis of experiments goes beyond single-dimensional summaries of performance (e.g., average; median) to include measures of variation, confidence, or other distributional information. (yes)\n\u2022 The significance of any improvement or decrease in performance is judged using appropriate statistical tests (e.g., Wilcoxon signed-rank). (yes)\n\u2022 This paper lists all final (hyper-)parameters used for each model/algorithm in the paper's experiments. (yes)\n\u2022 This paper states the number and range of values tried per (hyper-) parameter during development of the paper, along with the criterion used for selecting the final parameter setting. (partial)"}]}