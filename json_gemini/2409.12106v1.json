{"title": "Measuring Human and AI Values based on Generative Psychometrics with Large Language Models", "authors": ["Haoran Ye", "Yuhang Xie", "Yuanyi Ren", "Hanjun Fang", "Xin Zhang", "Guojie Song"], "abstract": "Human values and their measurement are long-standing interdisciplinary inquiry. Recent advances in AI have sparked renewed interest in this area, with large language models (LLMs) emerging as both tools and subjects of value measurement. This work introduces Generative Psychometrics for Values (GPV), an LLM-based, data-driven value measurement paradigm, theoretically grounded in text-revealed selective perceptions. We begin by fine-tuning an LLM for accurate perception-level value measurement and verifying the capability of LLMs to parse texts into perceptions, forming the core of the GPV pipeline. Applying GPV to human-authored blogs, we demonstrate its stability, validity, and superiority over prior psychological tools. Then, extending GPV to LLM value measurement, we advance the current art with 1) a psychometric methodology that measures LLM values based on their scalable and free-form outputs, enabling context-specific measurement; 2) a comparative analysis of measurement paradigms, indicating response biases of prior methods; and 3) an attempt to bridge LLM values and their safety, revealing the predictive power of different value systems and the impacts of various values on LLM safety. Through interdisciplinary efforts, we aim to leverage AI for next-generation psychometrics and psychometrics for value-aligned AI.", "sections": [{"title": "1 Introduction", "content": "Value theory, a cornerstone of philosophical inquiry, is paramount in guiding ethical decision-making and shaping societal norms [66]. Value measurement is a long-standing interdisciplinary endeavor for elucidating how specific values underpin and justify the worth of actions, objects, and concepts [76].\nTraditional psychometrics often measure human values through self-report questionnaires, where participants rate the importance of various values in their lives. However, these tools are limited by response biases, resource demands, inaccuracies in capturing authentic behaviors, and inability to handle historical or subjective data [59]. Therefore, data-driven tools have been developed to infer values from textual data, such as social media posts [59, 26]. These tools can reveal personal values without relying on explicit self-reporting, but they are mostly dictionary-based, matching text to predefined value lexicons. Consequently, they often fail to grasp the nuances of semantic meaning and context-dependent value expressions. Additionally, these tools tend to be static and inflexible, relying on expert-defined lexicons that are not easily adaptable to new or evolving values.\nThe rise of large language models (LLMs) opens up new possibilities for data-driven value mea-surement. Models like GPT-4 have shown remarkable capabilities in understanding nuances in language and context. Recent studies have demonstrated that LLMs can effectively approximate annotators' and even psychologists' judgments on value-related tasks [86, 63]. This work introduces Generative Psychometrics for Values (GPV), an LLM-based, data-driven value measurement paradigm grounded in the theory of text-revealed selective perceptions. GPV overcomes the limitations of self-reports and dictionary-based tools by leveraging LLMs' advanced semantic understanding. It extracts contextualized and value-laden perceptions (e.g., I believe that everyone deserves equal rights and opportunities.) from texts and decodes underlying values (e.g., Universalism) for arbitrary value systems. These perceptions function similarly to psychometric items in self-report questionnaires, often supporting or opposing specific values [76]. Notably, GPV enables the automatic generation of such items and their adaptation to any given data.\nWe begin by fine-tuning Llama 3 [24] for accurate perception-level value measurement. Benchmarked with established psychometric items, we demonstrate that the fine-tuned Llama 3 [24], referred to as ValueLlama, outperforms both state-of-the-art general and task-specific LLMs. Subsequently, we verify the capability of LLMs to parse texts into perceptions. The integration of perception-level value measurement and perception parsing forms the core pipeline of the GPV. Applying GPV to a large collection of human-authored blogs, we validate its stability and validity in measuring individual values, and its superiority over prior psychological tools.\nMeanwhile, the rapid evolution of LLMs raises significant concerns about their potential misalignment with human values. Recent literature treats LLMs as subjects of value measurement [50], employing self-report questionnaires [30, 58, 34, 37] or their variants [63]. However, these tools are inherently static, inflexible, and unscalable, as they rely on closed-ended questions derived from limited psychometric inventories.\nTo address these limitations, we extend the GPV paradigm to LLMs. Experimenting across 17 LLMs and 4 value theories, we advance the current art of LLM value measurement in several aspects. Firstly, GPV constitutes a novel evaluation methodology that does not rely on static psychometric inventories but measures LLM values based on their scalable and free-form outputs. In this manner, we mitigate response bias demonstrated in prior tools and enable context-specific value measurements. Secondly, we conduct the first comparative analysis of different measurement paradigms, where GPV yields better measurement results regarding validity and utility. Lastly, we present novel findings regarding value systems and LLM values. Despite the popularity of Schwartz's value theory within the AI community, alternative value systems like VSM [31] indicate better predictive power. In addition, values like Long Term Orientation positively contribute to the predicted safety scores, while values like Masculinity negatively contribute.\nBelow we summarize our contributions:\n\u2022 We introduce Generative Psychometrics for Values (GPV), a novel LLM-based value mea-surement paradigm grounded in text-revealed selective perceptions. GPV is accompanied by a fine-tuned LLM, ValueLlama, with state-of-the-art performance in perception-level value measurement (\u00a7 3).\n\u2022 Applying GPV to human-authored blogs, we demonstrate its stability, validity, and superiority over prior psychological tools (\u00a7 4).\n\u2022 Applying GPV to LLMs, we enable LLM value measurements based on their scalable, free-form, and context-specific outputs. With extensive evaluations across 17 LLMs and 4 value theories, we demonstrate the superiority of GPV and novel findings regarding value systems and LLM values (\u00a7 5)."}, {"title": "2 Related Work", "content": "2.1 Value Measurements for Human\nThe measurement of individual values is pivotal in elucidating the driving forces and mechanisms underlying human behavior [76, 66, 66]. Due to the intricate relationship between behavior and values,"}, {"title": "3 Generative Psychometrics for Values", "content": "3.1 Value Measurement with Selective Perceptions\nValues are an individual's concepts of transituational goals, reflecting interests within motivational do-mains and guiding principles in life [76]. Value measurement quantitatively evaluates the significance attributed to various values through individuals' behavioral and linguistic data [3, 53, 66]. Given any pluralistic value system as a reference frame, we formalize the value measurement task as follows.\nDefinition 3.1 (Value Measurement). Value measurement is a function f:\n$f: (V, D) \\rightarrow w\\in\\mathbb{R}^n$.\n(1)\nHere, $V = {v_1, v_2,..., v_n}$ denotes a value system, where each $v_i$ represents a particular value dimension that motivates specific behaviors; D denotes the individuals' behavioral and linguistic data; and $w = (w_1, w_2, ..., w_n)$ is a value vector with $w_i$ indicating the relative importance of $v_i$.\nExtensive research in psychology explores the underlying mechanisms of f, by which human values influence behaviors and behaviors reflect underlying values [3, 53, 76, 66]. GPV instantiates this process through value-driven selective perceptions [60, 4].\nPersonal values are demonstrable determinants of what individuals select to perceive, observe, and prioritize in their environment [60, 4]. For example, when considering a construction project of a new park, individuals who value Hedonism will emphasize the recreational benefits, while those who prioritize Economic Efficiency will focus on the project's cost. These differing perceptions encode value-laden information and value orientations of individuals. Traditional psychometric inventories [77, 41, 6] adopt such contextual perceptions, commonly referred to as items, as organized stimulus. For example, VSM [31] include perceptions like \"It is important to get recognition for good performance\" and \"It is important to have security of employment\". They are designed to measure the value dimensions of Masculinity and Individualism, respectively. Each perception either supports or opposes a value. In the above examples, the former supports Masculinity, while the latter opposes Individualism. These traditional psychometric inventories mostly compile static and unscalable perceptions, covering a limited measurement range. They also necessitate an additional self-report process to assess the individual's agreement with the items.\nGPV, illustrated in Fig. 1, advances psychometrics by leveraging LLMs to dynamically generate perceptions according to given behavioral and linguistic data. Compared with traditional tools, GPV (1) effectively mitigates response bias and resource demands by dispensing with self-reports; (2) captures authentic behaviors instead of relying on forced ratings; (3) can handle historical or subjective data; (4) measures values in open-ended value spaces and easily adapts to new or evolving values without expert effort; and (5) enables more scalable and flexible value measurement.\n3.2 Perception-level Value Measurement\nPerception. We define perceptions, the atomic measurement units, by the following properties: (1) A perception should be value-laden and accurately describe the measurement subject, ensuring meaningful measurement. (2) A perception is an atomic measurement unit, ensuring unambiguous measurement. (3) A perception is well-contextualized and self-contained, ensuring that it alone is sufficient for value measurement. (4) All perceptions comprehensively cover all value-laden aspects of the measured subject, ensuring that no related content in the data is left unmeasured.\nTraining. We fine-tune Llama-3-8B [24] to perform perception-level value measurement in an open-ended value space, i.e., not restricted to a predefined value system. The fine-tuning involves the following two tasks [86] using datasets of ValueBench [63] and ValuePrism [86]: (1) Relevance classification determines whether a perception is relevant to a value. (2) Valence classification determines whether a perception supports, opposes, or remains neutral (context-dependent) towards a value. Both tasks are formulated as generating a label given a value and a perception. We present further training details in Appendix A.\nInference. We refer to the fine-tuned Llama-3-8B as ValueLlama. Given a value system $V = {v_1, v_2, ..., v_n}$ and a sentence of perception s, we employ ValueLlama to calculate the relevance and valence probability distribution of each value $v_i$ to s, respectively denoted as $P_{rel}(\\cdot|v_i, s)$ and"}, {"title": "4 GPV for Humans", "content": "This section measures human values using 791 blogs from the Blog Authorship Corpus [75]. We evaluate GPV through standard Psychological metrics including stability, construct validity, concurrent validity, and predictive validity, and demonstrate its superiority over established psychological tools.\n4.1 Validation\nStability. As values are relatively stable psychological constructs for humans [69, 71, 39], we expect that the same individual should exhibit consistent value tendencies across different scenarios. Across 48888 perception-value pairs, 86.6% of the perception-level measurement results are consistent with the individual-level aggregated results, indicating desirable stability. Detailed results and extended discussions are shown in Appendix C.1.\nConstruct Validity. Construct validity is the extent to which a test measures what it claims to measure. In Schwartz's value system, some values are theoretically positively correlated, such as Self-Direction and Stimulation, while others are negatively correlated, such as Power and Benevolence. Altogether, the 10 Schwartz values form a circumplex structure [78, 82], where values that are closer together are more compatible, while those that are farther apart are more conflicting (Fig. 2a). We employ multidimensional scaling (MDS) to evaluate the construct validity of the Schwartz's value system [22, 12]. Based on the correlation between values derived from GPV measurement results, we project both the 10 basic values and the 4 higher-order values onto two-dimensional MDS plots. Then, we assess whether their relative positions align with the theoretical structure. As illustrated in Fig. 2, basic values belonging to the same category (represented by the same color) generally cluster together. Higher-order opposing values are positioned farther apart. The relative positions of a few values do not strictly follow the theoretical structure. For example, Conservation is relatively distant from the other three higher-order values. Such deviations may reflect a gap between the values"}, {"title": "5 GPV for Large Language Models", "content": "We evaluate 17 LLMs across 4 value systems using three measurement tools: self-report ques-tionnaires [34], ValueBench [63], and GPV. Unless otherwise specified, we use LLM-generated value-eliciting questions for GPV to ensure a comprehensive and thorough measurement of each value. The detailed experimental setup is described in Appendix D.1.\nAcross 19910 perception-value pairs, 86.8% perception-level measurement results are consistent with the LLM-level aggregated results, indicating desirable stability; we present the detailed results in Appendix D.2.\nThis section focuses on comparing GPV against prior measurement tools. We defer the value measure-ment results of all LLMs to Appendix D.4.\n5.1 Comparative Analysis of Construct Validity\nUsing the measurement results from 17 LLMs as data points, we compute the correlation between each pair of values in Schwartz's value system. The correlation results are visualized in a heatmap for"}, {"title": "5.3 Discussions", "content": "Superiority of GPV. We discuss that the superior construct validity can be attributed to the knowl-edge embedded within ValueLlama and its ability to inject such knowledge into the measurement process. During pertaining and our fine-tuning, ValueLlama learns the correlations between differ-ent values. Therefore, when measuring LLM values, ValueLlama can leverage such knowledge to generate more coherent value representations, ensuring the construct validity of the measurement results. The superior value representation utility of GPV may be attributed to the context-specific value measurements. Values are relatively stable traits for humans. However, we may not treat LLMs as monolithic entities with consistent values like humans, which emphasizes the need for context-specific evaluations [67]. GPV, for the first time, enables such context-specific measurements. Overall, compared to prior tools, using GPV for LLM value measurements (1) mitigates response bias and yields more theoretically valid results; (2) is more practically relevant for measuring LLM values based on their scalable and free-form responses; and (3) enables context-specific measurements.\nLimitations and Future Work. The current studies are limited to the evaluation of LLMs in English. Since the used languages are shown to affect the values of LLMs [17], future research should consider multi-lingual measurements. Additionally, future investigations should explore the spectrum of values an LLM can exhibit, examining how different profiling prompts affect this spectrum. Nevertheless, as R\u00f6ttger et al. [67] suggest, current alignment algorithms establish default model positions and behaviors, making it meaningful to evaluate the values and opinions reflected in these defaults. It is plausible that future models, as a result of more comprehensive alignment, will display more consistent value profiles and reduced variability in their responses to different prompts."}, {"title": "6 Conclusion", "content": "This paper introduces GPV, an LLM-based tool designed for value measurement, theoretically based on text-revealed selective perceptions. Experiments conducted through diverse lenses demonstrate the superiority of GPV in measuring both human and AI values.\nGPV offers promising opportunities for both sociological and technical research. In sociological re-search, GPV enables scalable, automated, and cost-effective value measurements that reduce response bias compared to self-reports and provide more semantic nuance than prior data-driven tools. It is highly flexible and can be used independently of specific value systems or measurement contexts. For technical research, GPV presents a new perspective on value alignment by offering interpretable and actionable value representations for LLMs."}]}