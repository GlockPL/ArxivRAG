{"title": "ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing", "authors": ["Haozhe Lei", "Yunfei Ge", "Quanyan Zhu"], "abstract": "The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI.", "sections": [{"title": "I. INTRODUCTION", "content": "Modern artificial intelligence (AI), such as machine learning (ML) technologies, are becoming increasingly integrated into many infrastructures, including smart transportation systems and healthcare infrastructures. In healthcare, they have shown the potential to help healthcare infrastructure in patient scheduling [1], [2], pathological analysis [3], and care management [4]. While there are significant benefits, there are concerns regarding zero-day vulnerabilities and the expanded attack surface.\nPenetration testing is a valuable ethical hacking method for uncovering vulnerabilities in increasingly complex infrastructures and devising remediation strategies. As these infrastructures become more complex, with millions of interconnected devices, scalability emerges as a critical challenge. It is essential to develop a distributed, modular, and automated approach that addresses device-level testing needs while considering global influences through interconnectivity. Another challenge stems from the dynamic nature of networked devices and their vulnerabilities. There is a growing need for adaptive and automated approaches to continuously update the vulnerability landscape, ensuring that threats are exhaustively identified, risks accurately assessed, and remediation measures properly applied. The third challenge arises from the integration of AI capabilities into the infrastructure. The emergence of adversarial AI/ML introduces new and evolving threat vectors, which are designed to evade detection and testing. There is a need for the development of automated and strategic approaches that can intelligently outmaneuver their evolving nature through continuous knowledge acquisition and learning.\nTo this end, we establish a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing (ADAPT)."}, {"title": "II. RELATED WORKS", "content": "Traditional manual penetration testing performed by skilled IT professionals is time-consuming, resource-intensive, and prone"}, {"title": "III. ADAPT FRAMEWORK AND METHODOLOGIES", "content": "This section, we present the ADAPT framework introduced in Figure 1. It consists of a meta-game framework and a neuro-symbolic framework."}, {"title": "A. Meta-game-based Automated Penetration Testing", "content": "We propose a meta-security game over a network graph where the macro strategic game represents strategic attack activities between nodes, while the micro tactic game details tactic-level attack procedures on each local node. Let the directed graph G = (V, E) represent the target network topology, where V is a set of nodes (e.g., server, database, device), and E \u2286 V \u00d7 V is a set of directed edges representing connections (e.g., SSH, RDP, cloud services) from node u to node v. Self-loops are allowed as they indicate continued exploration of the same node. Let v\u00ba \u2208 V be the initial foothold in the system. As an ethical attacker, the penetration tester aims to explore available information, exploit discovered vulnerabilities, and influence critical assets inside the healthcare infrastructure network.\nMicro Tactic Games: To model the interactions between the attacker and the defender at each local node, we use extensive-form game tree to explicitly and visually represent the sequential moves, possible outcomes, and information available at each decision point. We assume that all players have perfect recall; i.e., the player remembers every piece of information that he knows from the past, including his moves, the other player's moves, or chance moves. The structure of the game tree is inspired by the intrusion kill chain [16], a concept that outlines the structure of intrusions. This model guides analysis to inform actionable security intelligence.\nFor each node $v \\in V$ in the network, the Micro Tactic Game (MTG) is defined as $\\Gamma_v = (N_v \\cup {c}, H_v, P, {A_i}_{i\\in N_v \\cup c}, o, {u_i}_{i\\in N_v}, Z_v)$. Here, $N = {a,d}$ represents the players, the attacker (a) and the defender (d), while c represents system randomness with fixed policy $\u03c3_c$. Each vertex $h \\in H_v$ in the game tree represents a sequence of actions, referred to as history. The function P(h) determines whose turn it is at each decision point (attacker, defender, or nature) for a given history vertex h. A is a set of actions available to player i, and A(h) describes the feasible actions for the player at vertex h. $Z_v$ represents the possible outcomes for each tactic in the game, corresponding to the results at the leaf vertices of the game tree. We assume the outcomes are either remaining in the current node or leading to another connected node, denoted as $Z_v = {u | u \\in V, (v, u) \\in E}$. Finally, the utility function u determines the payoff or cost for player i when reaching a certain outcome.\nBy solving the extensive-form game, we are able to obtain the optimal local penetration for the attacker under possible defense plans. Given the nature's fixed policy (if any) and the plan profile of the attacker and the defender, i.e., $\u03a6^v = (\u03c3_a, \u03c3_d, \u03c3_c)$, we denote $\u03c4^v(z | \u03a6^v) \\in [0, 1]$ as the tactic outcome probability, which is the joint probability of reaching that outcome under $\u03a6^v$.\nMacro Strategic Process: One key component in the MTG is the utility function for each outcome, u(z), for all $z \\in Z_v$ and $i\\in N$. Utilities represent the payoff or cost of staying or moving to the next node and must be evaluated globally, considering neighboring nodes and their connections. After local exploration and exploitation, the attacker can use obtained credentials or discovered vulnerabilities to move to different nodes, a process known as lateral movement. The attacker's movement and the creation of the attack kill chain depend on the network topology and the expected utilities of each node. We model this decision-making process across the network using an MDP, a Macro Strategic Process (MSP).\nThe Macro Strategic Process (MSP) for the attacker within the MEGA-PT framework is characterized by a tuple $\u039b^a = (S, A^a, T, R, \u03b3)$, where S = V represents the network nodes as states, $A^a = E$ represents the connections between nodes as the action space, T denotes the transition success probability function, R represents the movement rewards, and \u03b3 is the discounting factor. The success of an attack attempt is influenced by the attacker's capability. For the purposes of this analysis, the transition success probability is defined as follows: if the attacker opts to remain at the same node, the probability of staying in the same state is 1. When the attacker chooses to move to a different node via an outgoing edge, the probability of a successful transition to the new node is denoted by $C_a \\in [0, 1]$, reflecting the attacker's skill level. If the attack attempt to move is unsuccessful, the attacker remains in the current node. The reward function R provides positive rewards $V(v')$ based on importance of the node for moving to the next node $v' \\in V$ and negative penalties $M_a \\in R^\u2212$ for remaining at the same node without progress.\nMeta-Security Game: Unlike traditional MDPs, where the attacker can freely choose actions to optimize expected utility, in the realistic penetration testing settings, the attack strategy in the network-level depends on explorations at the local nodes. If the attacker does not find any vulnerabilities leading to the next node, they cannot move forward. Therefore, the global attacks strategy in the MSP relies on the outcomes of the MTG. For each node $v \\in V$, the optimal local penetration plans determine the probability of each tactic outcome,"}, {"title": null, "content": "denoted as $T_v(z)$, where z represents an outgoing edge from v. This probability indicates the likelihood that the attacker will select a particular action $a^a = (v, z)$ in the global attack strategy. For node $v \\in V$, given the MTG $\u0393^v$ and the local plan profile $\u03a6^v$, the global attack strategy is given by\n$\\pi^a(a^a = (v, z) | s = v) = \u03c4^v(z | \u0424^v), \\forall z \\in Z_v$. (1)\nPolicy evaluation estimates the effectiveness of the global attack strategy, $\u03c0^a$, by calculating expected cumulative utilities. This involves computing value functions using Bellman equations. For each state s \u2208 S, the value function under $\u03c0^a$ is given by:\n$V^{\\pi^a}(s) = \\sum_{a^a \\in A^a} \\pi^a(a^a | s) \\sum_{s' \\in V} T(s' | s, a^a) [R(s, a^a, s') + \u03b3V^{\\pi^a}(s')]$. (2)\nThis value represents the expected return starting from state s and following the global attack strategy $\u03c0^a$. In the MTG, the utility of each outcome z at node v reflects the expected reward from taking that action and moving to the next node. The utility functions in the MTG are defined as $u(z = u) = \\sum_{s' \\in V} T(s' | s = v,a^a = (v,u)) [R(s, a^a, s') + \u03b3V^{\\pi^a}(s')]$. The defender's utility is the negative of the attacker's utility:\n$u_d(z) = \u2212u_a(z)$ for all $z \\in Z_v$.\nThe exploration at each local MTG generates the global attack strategy, while the estimated value for each node through policy evaluation under the current strategy represent the expected outcome utilities at each MTG. Together, the MSP and the MTGs constitute a meta-security game that captures decision-making in penetration testing at both network and node levels. A detailed example can be found in Section IV.\nDefinition 1 (Meta-Security Game). Given the network system graph G = (V,E), the meta-security game is composed of two parts: $\u039e = (\\{\u0393_v\\}_{v\\in V}, \u039b^a)$, where ${\\\u0393_v\\}_{v\\in V}$ is the set of MTGs and $\u039b^a$ is the MSP.\nThe MSP and the MTGs are inherently coupled, hence, a holistic solution concept is necessary for the proposed meta-security game.\nDefinition 2 (Meta Penetration Playbook). Consider the meta-security game $\u039e = (\\{\u0393_v\\}_{v\\in V}, \u039b^a)$ defined in Definition 1, the meta penetration playbook $\u00a7 = (\\{\u03a6_v\\}_{v\\in V}, \u03c0^a)$ is composed of the local penetration profiles at each node and the global attack strategy. They satisfy two conditions: 1) policy Dependency - the global attack strategy $\u03c0^a$ at the macro strategy process depends on the local penetration plans ${\\{\u03a6_v\\}_{v\\in V}}$; 2) value Dependency - for each MTG at node $v \\in V$, the utility of each tactic expected outcome depends on the policy evaluation results of global attack strategy $\u03c0^a$\nDefinition 3 (Network Risk Score). Consider the meta-security game $\u039e$ defined in Definition 1 and the corresponding meta penetration playbook \u00a7 defined in Definition 2, the network risk score of node $v \\in V$ is defined as $w(v | \u03be) = \\begin{cases}\n1 - (\\frac{V^{\\pi^a}(v)}{V_{max}}) & \\text{if } V^{\\pi^a}(v) \\ge 0, \\\\\n0 & \\text{otherwise,}\n\\end{cases}$ where $V^{\\pi^a}(v)$ is the policy evaluation value function under the meta penetration playbook."}, {"title": "B. Neural-Symbolic Penetration Algorithm", "content": "Consider a partially known meta-security game $\u039e = (\\{\u0393_v\\}_{v\\in V}, \u039b^a)$, assuming that unknown information only occurs at the entry point and the edge node of the network. From the attacker's perspective, denote these nodes as the web server $v_o$ and the Al center server $v_a$ that stores and trains ML models. To solve this meta-game with incomplete information, we present the algorithm for solving a meta-penetration testing playbook, followed by an explanation of how neural-symbolic libraries assist in automating adaptation to networks with incomplete information.\n2) Symbolic Adaptation of MTGs\nIn the meta-security game with incomplete information, our goal is to explore the MTGs with partially or completely unknown information, and the flow diagram is shown in Figure 2. As an example, we consider the MTGs of the entry node and the edge node in the network, denoted as $\u0393^o$ and $\u0393^{od}$, respectively. We use First-Order-Logic (FOL) representation $\\kappa^v$ [17] to describe the properties of the network servers in Table I.\nFor each node $v \\in V$, we assume that there is a finite property set that captures all possible configurations on the node,"}, {"title": null, "content": "denoted by $K^v := {\\kappa^i\\}_{i\\in[1,\\ldots,|K_v|]}$. Property exploration refers to the expansion and updating of the property set $K_v$ associated with node v. In the web server, assuming it is using a Linux operating system and has a Microsoft Defender, the properties are represented as $K^o = {\\text{is-linux(\u00b7), is-microsoftD(\u00b7)}}$. Assume the penetration tester is using an automated fuzzing technique [5] to explore the node server and discovers a new vulnerability that allows attacker bypass authentication check. Then, the updated property set of the node is $K^{o,} = {\\text{is-linux(\u00b7), is-microsoftD(\u00b7), can-bypassD(\u00b7)}}$. Following the same logic, we can describe an Al server using the Windows system with the Windows Defender's Protection, where an ethical attacker intends to perform an evasion attack on the ML model tactic technique (detail will be described in the following section), as $K^{od} = {\\text{is-windows(\u00b7), is-windowsD(\u00b7), evadeMLmodel(\u00b7)}}$.\nWe use a knowledge library to store all MTGs related to node $v \\in V$, formally defined as follows.\nDefinition 4 (Knowledge Library). Consider that a knowledge library $L^v$ is a set of MTGs corresponding to a specific node v, defined as $L^v := {\u0393^v(K^u)}_{K^u\\in POW(P^v)}$, where $P^v$ contains all possible node properties for v and $POW(P^v) = {U|U \u2286 Pu}$ is the power set of $P^v$.\nFor given property set $K^v$ and knowledge library $L^v$, a symbolic adaptation process is to find a $\u0393 \\in L^v$ that satisfies:\n$\\bigwedge_{i=1}^{|K^v|} (\\Gamma\\rightarrow \\kappa_l^v)$\\n$\\kappa_v \\in P_v\\ \\ \\ \\ \\forall K_v$, is true. (3)\nHere, we assume that for any possible property set $K^v$, there exist a feasible node description of v that satisfies (3). By defining the solution of the penetration playbook as neural and the adaptation of node properties as symbolic, we present a conceptual workflow of ADAPT in Algorithm 2.\nSince the knowledge library may be imperfect and unable to fully describe the node properties, there is a need to constantly update the knowledge library. Due to the limited space, we leave the discussion for future work."}, {"title": "IV. HOSPITAL CASE STUDY", "content": "In this section, we discuss a case study of a typical IT infrastructure within a healthcare environment, i.e., a hospital network architecture shown in Figure 3, referring to [18] and [19]. The attacker accesses the hospital network from a web server and targets the AI center in subnet B. Through this example, we aim to highlight the uniqueness of the MTG design in an AI-enhanced network and emphasize the guidance and value of our algorithm for users in such networks.\nReal-life examples show the ongoing need for hospitals to deploy AI servers locally [20], typically on the edge"}, {"title": "A. Penetration Path to access the AI Center", "content": "Figure 4 illustrates an example of the meta-security game in the hospital network shown in Figure 3. The attacker starts from the web server and tries to access the AI center by penetrating the AI managerial applications server and the API gateway server. To conserve space in this paper, we present the MTG of the web server following the MITRE ATT&CK"}, {"title": "B. Impact Techniques", "content": "The goal for the attacker is to interrupt, erode confidence in, or destroy the machine learning systems and data. Traditionally, Techniques used for impact can include destroying or tampering with data. Following the MITRE ATLAS framework [22], we use examples to illustrate the differences between three different impact techniques' MTG trees.\nErode ML Model Integrity: Attacks can happen during the model training, i.e., damage on the model integrity. To influence the ML model's integrity, there are two primary approaches. The first approach is to directly alter the model, which is efficient and straightforward but also more likely to be detected [23]. The second approach is to poison the training data [11], [13], thereby degrading the model's performance-often summarized as \"garbage in, garbage out.\"\nEvade ML Model: Attacks can also occur during model access. An attacker can craft adversarial data that prevents a machine learning model from correctly identifying the contents of the data. This technique can be used to evade downstream tasks where machine learning is utilized. One example of this type of impact technique is the bypassing of Cylance antivirus products [15]. As a result, this impact can cause the adversary's desired effect on the target model, leading to consequences such as misclassification, missed detections, or maximized energy consumption.\nDenial of ML Service: By this impact technique, the attacker is targeting ML systems' accessibility instead of integrity. The attacker focuses on generating a flood of requests for degrading or shutting down the service. Recall the massive disaster that occurred in July 2024, when the \"blue screen of death\" affected most Microsoft computers in airports and hospitals [24]. Although this incident was caused by a system"}, {"title": "C. Numerical Experiments", "content": "This experiments section provides insight into the risk assessment process of penetration testing in an AI-enhanced hospital network. Assume the attacker chooses to erode the integrity of a regression ML model (using a support vector machine in this case) through a data poisoning algorithm as described in [11], which can degrade the model's accuracy.\nWe maintain the hospital network configuration as shown in Figure 3 and assume this ML model is placed in the AI center node of subnet B as the critical asset of the network. Let the risk score $w(v | \u03be)$ of the entry node be directly identical to the data poisoning ratio, and denote the network uses non-sophisticated defenders that only use fixed strategies. By iterating the attacker's skill level from 0 to 1 with an interval of 0.1, we obtain the experimental results shown in the left of Figure 6."}, {"title": "V. CONCLUSION", "content": "In this work, we propose ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing. ADAPT addresses the critical demands of modern healthcare infrastructure and has the ability to dynamically adjust to evolving threats, and its effectiveness in securing AI systems against zero-day vulnerabilities underscores its potential as a vital tool for enhancing cybersecurity in healthcare environments. The case study demonstrates a real-life hospital network structure and showcases the framework's effectiveness in addressing various tactical techniques employed by attackers. In numerical experiments, the results show around 98% improvement in reducing the risk score of the system by using the purple teaming defender as the replacement of a fixed strategy defender."}]}