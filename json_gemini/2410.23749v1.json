{"title": "LSEAttention is All You Need for Time Series Forecasting", "authors": ["Dizhen Liang"], "abstract": "Transformer-based architectures have achieved remarkable success in natural language processing and computer vision. However, their performance in multivariate long-term forecasting often lags behind simpler linear baselines. Previous studies have identified the traditional attention mechanism as a significant factor contributing to this limitation. To unlock the full potential of transformers for multivariate time series forecasting, I introduce LSEAttention, an approach designed to address entropy collapse and training instability commonly observed in transformer models. I validate the effectiveness of LSEAttention across various real-world multivariate time series datasets, demonstrating that it not only outperforms existing time series transformer models but also exceeds the performance of some state-of-the-art models on specific datasets.", "sections": [{"title": "1. Introduction", "content": "Multivariate time series forecasting is crucial in diverse domains such as finance, healthcare, and environmental monitoring, where the goal is to predict future values based on historical data. This task is particularly challenging in long-term forecasting, as it necessitates models that can effectively capture feature correlations and long-term dependencies across multiple time series. Recent research has increasingly focused on applying transformer architectures to time series forecasting, leveraging their capacity to model complex temporal interactions through self-attention mechanisms. However, despite their potential, state-of-the-art approaches for multivariate time series forecasting still primarily rely on linear models, such as those proposed by Ni et al. [1], raising concerns about the efficacy of transformers in this context, particularly given their suboptimal performance and inherent complexity."}, {"title": "1.1. Transformer-based Long-term Time Series Forecasting", "content": "The application of transformers to time series forecasting gained momentum following the introduction of the Transformer model [2] which established its potential as a universal backbone for various tasks across multiple modalities. The attention mechanism at the core of this architecture is formulated as follows:\n\n$Attention(Q, K, V) = Softmax(\\frac{QKT}{\\sqrt{dk}})V, (1)$\n\nwhere Q, K, and V represent the query, key, and value matrices, respectively, and dk denotes the dimension of the key vectors. This formulation allows transformers to dynamically weigh the significance of various input elements, facilitating the capture of intricate dependencies within the data.\n\nRecent studies have tailored transformer models specifically for long-term time series forecasting. For instance, Informer [3] introduces ProbSparse self-attention and distillation techniques to efficiently identify the most relevant keys for forecasting, thereby reducing computational complexity and enhancing interpretability by focusing on essential temporal signals. Similarly, Autoformer [4] employs decomposition and auto-correlation mechanisms, effectively merging classical and modern methodologies to enhance model performance.\n\nFEDformer [5] incorporates a Fourier-enhanced module that achieves linear complexity in both time and space, significantly improving scalability and efficiency for long sequences. Instead of concentrating solely on point-wise attention, PatchTST [6] emphasizes patch-level attention by treating patches, rather than individual time steps, as input units, which enables the model to capture richer semantic information across multiple time series a critical aspect for effective long-term forecasting.\n\nThe challenges associated with applying transformers to time series forecasting are further highlighted by Ilbert et al. [7] in their SAMformer model. SAMformer integrates Reversible Instance Normalization (RevIN) [8] to address shifting data distributions and incorporates Sharpness-Aware Minimization (SAM) to improve training stability. This approach tackles critical issues, including entropy collapse and training instability, that have impeded transformer models in this domain."}, {"title": "1.2. Entropy Collapse", "content": "In computer vision and natural language processing, attention matrices can experience entropy or rank collapse, as demonstrated by Dong et al. [9]. This issue is exacerbated in time series forecasting due to the frequent fluctuations inherent in temporal data, leading to substantial performance degradation. Ilbert et al. [7] identify the attention mechanism as a primary contributor to this problem and introduce SAM to mitigate it, thus enhancing model performance. However, the fundamental causes of entropy collapse remain inadequately addressed in the literature, warranting further exploration of its underlying mechanisms and effects on model performance."}, {"title": "1.3. Contributions", "content": "In this work, I present the following contributions:\n\n\u2022 A novel theoretical framework linking entropy collapse with numerical stability, aimed at restoring the intended functionality of the softmax operation.\n\n\u2022 Introduction of the LSEAttention module, a variation of traditional multi-head attention that addresses the entropy collapse issue, thereby enhancing the trainability and performance of transformers for time series forecasting.\n\n\u2022 Empirical validation of my approach on widely used multivariate long-term forecasting datasets, demonstrating that transformers equipped with LSEAttention outperform state-of-the-art models."}, {"title": "2. Proposed Approach", "content": ""}, {"title": "2.1. Problem Formulation", "content": "In multivariate time series forecasting, the objective is to predict future values P for each channel, represented as $Y \\in R^{C \\times P}$. This prediction is based on historical time series data of length L across C channels, encapsulated in the input matrix $X \\in R^{C \\times L}$. The goal is to train a predictive model $f_w : R^{C \\times L} \\rightarrow R^{C \\times P}$, parameterized by w, to minimize the mean squared error (MSE) between the predicted and actual values. The MSE is defined as:\n\n$MSE = \\frac{1}{C} \\sum_{c=1}^{C} ||Y_c - f_w(X_c)||^2, (2)$\n\nwhere $Y_c$ and $X_c$ denote the true future values and historical input sequences for each channel c."}, {"title": "2.2. Motivation", "content": "Transformers depend heavily on their point-wise attention mechanism to capture temporal associations. However, this reliance can lead to a phenomenon known as attention collapse, where the attention matrices converge to similar values across inputs and prone to identical matrices, resulting in poor generalization. The underlying issue of entropy collapse remains underexplored, particularly concerning the usgae of transformer on time-series forecasting. Since the conditional number of softmax is defined similar to LSE (Log-Sum-Exp) which hints the numerical instability issue might be the core reason of attention collapse.\n\nThe condition number of a function quantifies its sensitivity to small input changes; a high condition number indicates that slight perturbations can lead to significant variations in output. For the softmax function, defined as:\n\n$softmax(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}} (3)$\n\nwhere $x_i$ represents the i-th element of the input vector and n is the total number of elements, the condition number is notably high. This instability can manifest as issues such as over-attention or entropy collapse, characterized by attention matrices with excessively high diagonal values (indicating overflow) and extremely low non-diagonal values (indicating underflow) .\n\nTo address these challenges, I propose a module termed LSEAttention, which integrates the Log-Sum-Exp (LSE) trick proposed by Blanchard et al. [10] along with the Gaussian Error Linear Unit (GELU) activation function introduced by Hendrycks et al. [11]. The LSE trick alleviates numerical instability arising from overflow and underflow through normalization. The softmax function can be reformulated using LSE as follows:\n\n$softmax(x_i) = \\frac{e^{x_i}}{e^{LSE(x)}}, (4)$\n\nwhere $e^{LSE(x)}$ denotes the exponential of the log-sum-exp function, enhancing numerical stability.\nNormalizing the LSE yields:\n\n$y = log(\\sum_{i=1}^{n} e^{x_i}) (5)$\n\nwhere a is a constant and max value utilized for normalization in practice. This simplifies to:\n\n$y = a + log(\\sum_{i=1}^{n} e^{x_i - a}) (6)$\n\nand can be reformulated in a numerically stable manner as:\n\n$g_j = \\frac{e^{x_j - a}}{\\sum_{i=1}^{n} e^{x_i - a}}, j = 1, ..., n, (7)$\n\nwhere $g_j$ represents the j-th component of the stabilized softmax output."}, {"title": "", "content": "This can be further expressed as:\n\n$g_j = exp(x_j - a - log(\\sum_{i=1}^{n} e^{x_i - a})), (8)$\n\nwhere $\\sum_{i=1}^{n} e^{x_i}$ serves as the normalization factor, ensuring that the outputs sum to one.\nAdditionally, the GELU activation function provides smoother probabilistic activations, which help stabilize extreme log probability values before applying the exponential function, thereby mitigating abrupt transitions in attention scores. By approximating the ReLU function [12] with a smooth curve incorporating the cumulative distribution function (CDF) of the standard normal distribution, GELU reduces sudden shifts in activations that can occur with traditional ReLU. This property is particularly advantageous for stabilizing transformer-based attention mechanisms, where abrupt changes in activation can lead to numerical instability and gradient explosion.\nThe GELU function is formally defined as:\n\n$GELU(x) = x \\cdot \\Phi(x), (9)$\n\nwhere (x) represents the CDF of the standard normal distribution. This formulation ensures that GELU applies varying levels of scaling to inputs based on their magnitude, reducing the amplification of extreme values. The smooth, probabilistic nature of GELU allows for a gradual transition of input values, which, in turn, mitigates the impact of large gradient fluctuations during training.\nThis property becomes essential when combined with the Log-Sum-Exp (LSE) trick, which normalizes the softmax function in a numerically stable manner. Together, LSE and GELU prevent overflow and underflow in the exponential operations within softmax, resulting in a stabilized range of attention scores. This synergy enhances the robustness of transformer models by ensuring that attention weights remain well-distributed across tokens, ultimately leading to more stable gradients and improved convergence during training.\nIn traditional transformer architectures, the ReLU (Rectified Linear Unit) activation function used in the Feed-Forward Network (FFN) is susceptible to the \"dying ReLU\" problem, where neurons can become inactive by outputting zero for all negative input values. This leads to a zero-gradient scenario for those neurons, effectively stalling their learning process and contributing to instability during training.\nTo address these challenges, Parametric ReLU (PReLU) is employed as an alternative activation function. PReLU introduces a learnable slope for negative inputs, allowing for a non-zero output even when the input is negative. This adaptation not only alleviates the dying ReLU problem but also facilitates a smoother transition between negative and positive activations, thereby enhancing the model's ability to learn from all regions of the input space [13]. The presence of a non-zero gradient for negative values promotes improved gradient flow, which is crucial for training deeper architectures. Consequently, the use of PReLU contributes to overall training stability and helps maintain active representations, ultimately leading to enhanced model performance."}, {"title": "2.3. LATST: Overall Structure", "content": "The proposed LSEAttention Time-Series Transformer (LATST) Fig. 1 builds upon the modifications discussed in Motivation Sec. 2, introducing a key enhancement: Reversible Instance Normalization. This normalization technique is particularly effective for mitigating discrepancies between training and testing data distributions in time series forecasting tasks as in [7]\n\nThe architecture retains a traditional temporal self-attention mechanism, integral to the LSEAttention module. To assess the efficacy of the LSEAttention component, I conducted an ablation study comparing LATST with the Gaussian Error Linear Unit (GeLU) in the Feedforward Neural Network (FFN) against a variant utilizing the Rectified Linear Unit (ReLU). The details of this study can be found in Ablation Study of Sec. 3.\n\nOverall, the LATST architecture consists of a single-layer transformer framework augmented with substitution modules, allowing for adaptive learning while maintaining the robustness of attention mechanisms. This design facilitates effective modeling of temporal dependencies and enhances performance in time series forecasting tasks."}, {"title": "3. Experiments", "content": ""}, {"title": "3.1. Dataset", "content": "I conduct experiments on eight publicly available datasets of real-world multivariate time series that are widely recognized for long-term forecasting. These datasets include four Electricity Transformer Temperature datasets: ETTh1, ETTh2, ETTm1, and ETTm2, as well as the Electricity, Weather and Traffic datasets are sourced from [4]. The Exchange dataset is from [14]. Each time series is segmented based on a specified input length to facilitate effective modeling."}, {"title": "Sequence and Prediction Length:", "content": "In accordance with prior works, I set the input sequence length at 336 time steps. The prediction length, which indicates the number of future time steps for which I aim to forecast data, varies among the set {96, 192, 336, 720}. This flexibility in prediction length allows for an evaluation of the model's performance across different forecasting horizons."}, {"title": "Evaluation Metric:", "content": "Consistent with previous studies, I employ the widely used evaluation metric, mean squared error (MSE). This metric has been a standard choice in earlier works and is defined as follows:\n\n$MSE = \\frac{1}{N} \\sum_{i=1}^{N} (Y_i - Y'_i)^2, (10)$\n\nwhere N is the total number of samples, $Y_i$ is the i-th prediction, and $Y'_i$ represents the corresponding ground truth value."}, {"title": "3.2. Baseline", "content": "I compare the performance of LATST against leading transformer-based models, including SAMformer [7], TSMixer [15], iTransformer [16], and PatchTST [6]."}, {"title": "Hyperparameters:", "content": "For all experiments, the hyperparameter settings for LATST are derived from those used in PatchTST, with a batch size fixed at 8 for simplicity."}, {"title": "3.3. Performance Analysis", "content": "LATST demonstrates superior performance by achieving the best mean squared error (MSE) scores in 21 out of 32 scenarios across the evaluated eight datasets. This remarkable consistency underscores the model's robustness and adaptability in addressing diverse time series forecasting tasks. Specifically, LATST outperforms all other transformer-based models on the Electricity, Traffic, and Weather datasets across all evaluated metrics, indicating its efficacy in managing complex temporal dependencies.\n\nWhen comparing LATST directly with SAMformer, LATST exhibits an overall improvement of 4.3% in MSE. Furthermore, LATST surpasses the Transformer model by a substantial margin of 19.11%, highlighting its enhanced predictive capabilities. The modifications introduced in LATST, including the integration of the Log-Sum-Exp trick and refined attention mechanisms, contribute to this performance enhancement, allowing the model to better capture long-range dependencies and temporal patterns.\n\nThe detailed performance metrics for each dataset and prediction length are summarized in Tab. 2. Notably, LATST consistently achieves the lowest MSE across multiple input lengths for datasets such as ETTh1, ETTh2, and Electricity. For instance, in the Electricity dataset, LATST records an MSE of 0.131 for a prediction length of 96, significantly outperforming the closest competitor, SAMformer, which achieves an MSE of 0.155. This trend is replicated across various prediction horizons, demonstrating the model's ability to maintain stability and robustness under different forecasting conditions.\n\nConsistency Across Datasets: The model's ability to achieve the best MSE scores in a significant number of scenarios reinforces its robustness and generalizability to diverse forecasting challenges. The performance stability observed across different datasets suggests that LATST effectively learns and captures underlying temporal patterns, enabling it to adapt well to varying data distributions and dynamics. For example, in the Traffic dataset, LATST maintains lower MSE values even at longer prediction horizons, indicating its resilience against overfitting and its capacity to generalize beyond training conditions."}, {"title": "3.4. Ablation Study", "content": "In this section, I present a comprehensive ablation study aimed at quantitatively assessing the impact of various architectural components within the LATST framework. By systematically removing or modifying key elements, such as the GeLU and the PReLU, I isolate their contributions to the overall performance of the model. For consistency, I fix the experimental parameters to a prediction length of 96 and utilize four datasets: ETTh2, ETTm1, ETTm2, and Exchange Rate.\n\nPreliminary results from the ablation study, as shown in Tab. 3, indicate that the inclusion of the PReLU activation function leads to a significant improvement on the ETTm2 dataset, while providing only marginal enhancements for the other datasets. This observation suggests that the performance gains associated with PReLU may not arise solely from its inherent properties; rather, it appears that the ReLU activation function may hinder the performance of the LSEAttention model due to the numerical instability introduced by its sharp activation characteristics.\nTo further investigate the contribution of the Log-Sum-Exp trick, I conducted an experiment comparing LATST with a Transformer model that replaces the GeLU activation function.\nAs illustrated in Tab. 4, the LATST model utilizing the Log-Sum-Exp trick significantly outperforms the Transformer model, despite a notable decline in performance compared to the original configuration. This indicates that the Log-Sum-Exp trick plays a crucial role in maintaining the effectiveness of the LATST architecture, even in the absence of the GeLU activation function. The improvement achieved through the Log-Sum-Exp trick is attributed to its ability to stabilize gradient computations during training, thereby facilitating the learning of more complex patterns.\nThese findings not only elucidate the effectiveness of various components within the LATST architecture but also provide valuable insights for future enhancements. I aim to explore optimal configurations of these modules to further refine the model's performance and expand its applicability to more complex time series forecasting challenges."}, {"title": "4. Conclusion and Future Work", "content": "In this paper, I present an innovative solution to mitigate the entropy collapse phenomenon observed in Transformers applied to time series forecasting. Our empirical results confirm the effectiveness and robustness of the proposed LATST approach across a variety of forecasting contexts. Although I do not exhaustively explore all potential causes of entropy collapse, I introduce a novel module specifically designed to address this issue.\nLooking ahead, future research will focus on a comprehensive investigation of the remaining factors contributing to entropy collapse. This exploration aims to identify additional modifications and enhancements that could further improve the stability and performance of Transformer models in time series forecasting.\nIn summary, I believe that our work not only addresses critical challenges associated with the entropy collapse phenomenon but also sets the stage for future advancements in time series forecasting methodologies."}]}