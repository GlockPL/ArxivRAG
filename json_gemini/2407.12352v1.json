{"title": "SENTAUR: Security Enhanced Trojan Assessment Using LLMs Against Undesirable Revisions", "authors": ["Jitendra Bhandari", "Rajat Sadhukhan", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri"], "abstract": "A globally distributed IC supply chain brings risks due to untrusted third parties. The risks span inadvertent use of hardware Trojan (HT), inserted Intellectual Property (3P-IP) or Electronic Design Automation (EDA) flows. HT can introduce stealthy HT behavior, prevent an IC work as intended, or leak sensitive data via side channels. To counter HTs, rapidly examining HT scenarios is a key requirement. While Trust-Hub benchmarks are a good starting point to assess defenses, they encompass a small subset of manually created HTs within the expanse of HT designs. Further, the HTs may disappear during synthesis. We propose a large language model (LLM) framework SENTAUR to generate a suite of legitimate HTs for a Register Transfer Level (RTL) design by learning its specifications, descriptions, and natural language descriptions of HT effects. Existing tools and benchmarks are limited; they need a learning period to construct an ML model to mimic the threat model and are difficult to reproduce. SENTAUR can swiftly produce HT instances by leveraging LLMs without any learning period and sanitizing the HTs facilitating their rapid assessment. Evaluation of SENTAUR involved generating effective, synthesizable, and practical HTs from TrustHub and elsewhere, investigating impacts of payloads/triggers at the RTL. While our evaluation focused on HT insertion, SENTAUR can generalize to automatically transform an RTL code to have defined functional modifications.", "sections": [{"title": "I. INTRODUCTION", "content": "Chip manufacturers face increasing challenges due to the scale and complexity of System-on-Chip (SoC) designs specif-ically targeted for modern embedded systems and Internet-of-Things (IoT) devices. Consequently, SoC designers, under time-to-market pressures and resource limitations, have turned to outsourcing hardware designs and utilizing Third-Party Electronic Design Automation tools or Intellectual Property cores (combined 3P-EDA/IP) from global vendors. This outsourcing presents numerous benefits, including cost reduction by minimizing internal team overheads, utilization of special-ized skills through specialist firms for efficient resource alloca-tion, faster development for crucial time-to-market scenarios, and access to a wider global talent pool with diverse skill sets. However, the security and reliability of 3P-EDA/IPs remain uncertain, posing risks when relying on untrusted IPs and EDA tools. This raises concerns about potential malicious alterations within an IC, capable of causing side-channel leakages of sensitive data, functional changes, performance reduction, or denial of service (DoS). These malicious hard-ware alterations by unauthorized entities within the IC supply chain are commonly known as Hardware Trojans (HTs) [1], which can even lead to the extraction of secret keys, enabling an adversary to modify the chip\u2019s configurations and gain full control of the chip [2]. The standard design flow of an SoC commencing from design-level specification to physical IP development in a third-party environment is shown in Figure I (a). It highlights various stages within the IC supply chain identified as possible points where HTs could be injected. The adaptability of IP cores at higher abstraction levels in the design cycle makes it easy for attackers to insert HTs. Hence, developing detection and countermeasures against HTs at the design phase i.e. at the softIP level is critical [3], [4]; their elimination becomes costly in later stages. To measure the effectiveness of a countermeasure, designers need the ability to swiftly investigate the attack space susceptible to HT insertion for that design [5].\nThe HT benchmarks on Trust-Hub [6] are static and limited concerning the diverse nature of SoC development. According to [7] most Trust-Hub benchmarks rely on unrealistic assumptions. They show that 3-out-of-83 HT benchmarks are effective. Further, FPGA/ASIC development process entails designing control and data paths requiring deep hardware expertise. When modifications/additions are frequent to ac-celerate an algorithm, it can result in frequent obsolescence problems. Unlike software that can be updated or recompiled, IC designs cannot incorporate changes seamlessly. There is a critical need for a platform-independent framework to add functions to an IC design at RTL."}, {"title": "A. Key Contributions", "content": "SENTAUR is an LLM-based HT assessment flow shown in Figure I (b). Given a design specification and corresponding RTL, we query SENTAUR to generate HTs based on a HT trigger class, and payload class. Our contributions are:\n\u2022 A novel use of conversational LLMs to generate RTL that is synthesizable using a HT netlist from Trust-Hub. A recent study [7] shows that most HTs are not correct and effective after synthesis. We use LLMs to insert HTs which after synthesis persist.\n\u2022 SENTAUR is a flexible, versatile, and platform-independent LLM-based toolchain for inserting design templates given functional descriptions of the design. It can be used by an adversary to insert or analyze the effect of HTs and by a designer to plug in templates.\n\u2022 Validate SENTAUR flow from an attacker view using the Xilinx platform. We inserted different HTs in the RTL and validated the designs using the Xilinx FPGA."}, {"title": "B. Related Works", "content": "In this section, we will discuss the state-of-art research in HT insertion and detection. The very first work in this direction is the development of an extensive repository of HTs available at Trust-Hub [6]. However, Trust-Hub is restricted to the num-ber of HT circuits that cover only a fraction of the potential landscape for inserting HTs in digital circuits, thereby restrict-ing the development of varied countermeasures. To overcome this limitation TAINT [8] tool is proposed where HT insertion is done at the various stages of the design cycle. However, the tool anticipates that the user will choose the trigger nets based on recommendations provided by the tool itself. In [9] the authors proposed an automated tool TRIT to insert HTs in a design by configuring various parameters such as the number of trigger nets, the count of rare nets among these triggers, rare-net threshold determined through signal probability of nets, and the selection of payload. Despite expanding the range of inserted HTs, the TRIT methodology cannot identify the best trigger and payload nets. The work [10] proposes a flow that explores Trojans in physical design layouts restricted to ASIC layouts and applicable at the backend stage. Similarly, in [11] Trojan space is explored at the backend stages of FPGA design flow. In [12], the authors proposed aflow called HAL that inserts countermeasures against Trojan attacks but doesn't explore the Trojan space.\nYu et al. [13] proposed a methodology that identifies rare nets using the transition probability of nets to insert HTs. MIMIC [14] leverages ML to insert HTs. MIMIC ML model was developed by extracting 16 functional and structural attributes from existing HT samples, creating numerous HTs tailored for specific designs. MIMIC process is intricate, involves multiple stages, and requires extensive learning time to train the model. Trojan Playground [15] functions the same way where Reinforcement Learning (RL) is used requiring extensive training of the model. We propose an LLM-based tool flow SENTAUR that does not involve a time-consuming training process and is user-friendly in generating extensive set of HTs and insert them into an RTL design. A summary of SENTAUR tool and its benefits are shown in Table I."}, {"title": "II. SENTAUR: TOOL FLOW AND CAPABILITIES", "content": "A. Hardware Trojan Threat Model\nOur proposed flow SENTAUR aims to assess malicious possible HT circuits in RTL code, concerning trigger, and payload design. SENTAUR is capable of analyzing or iden-tifying trigger-based or continuously active HTs in an RTL code given its specification, including those with a payload circuit intended to alter functionality, reduce performance, leak sensitive data, or disrupt service. Our approach focuses on HT insertion during the design stage through scenarios involving deliberate manual manipulation by untrustworthy 3PIP vendors or 3P-EDA tools targeting the RTL netlist.\nB. Motivating Use Case\nKrieg et al. [7] argue that the assumptions underlying TrustHUB HT benchmarks are unlikely to apply in real-world scenarios. In this section, we will show LLMs can help generate a synthesizable code that reproduces the result as intended. For this, we analyzed the AES-T800 benchmark for our experiment which is also used in [7] to demonstrate that the benchmark violates the correctness and persistence property after synthesizing the netlist. HT insertion in the AES-T800 benchmark detects a predetermined sequence of input plaintext and then illicitly transmits the AES secret key via a hidden communication channel. However, in [7] it has been found that post-synthesis the trigger signal rises, but it appears that it doesn't occur due to the predefined sequence. Instead, it rises right after the circuit reset goes off. Hence using these benchmarks requires manual intervention by hardware experts. They sanitize the designs to make them synthesizable ensuring usability, correctness, and consistency. We leveraged the power of LLM to generate a synthesizable code efficiently. We chose GPT-4 in our experiment. On prompting GPT-4 as shown below the RTL is generated as shown in Listing 1. We synthesized the code using Xilinx Vivado and simulated the post-synthesized using the benchmark from Trust-Hub. The simulated result of the post-synthesized netlist is shown in Figure 2; after detecting the sequence of four input states the trigger signal goes high."}, {"title": "C. Tool Flow", "content": "In the last section, we have seen how LLM could generate an RTL code of the Trust-Hub [6] Trojan benchmark that after synthesis gives functionally correct and intended results. We verified the result using gate-level simulation against the Trojan benchmark provided in Trust-HUb. In this section, we will formalize the flow and introduce an automation framework SENTAUR that will generate RTL codes given the specification of the RTL design through an LLM as shown in Figure I (b). Our proposed flow is a three-stage process\n1) RTL Generation/Analysis using Specification: The func-tion description of the design under consideration is given to the LLM to generate variations in functionality concerning logic, state machine, I/O pattern, and signal analyses. These functionalities are generated based on some trigger condition specified to LLM based upon time, input-output patterns, or physical conditions. Given that under the purview of HT insertion the generated functionality varies under different trigger conditions, the final effect can be seen as either DoS, leakage of signal values, or degradation of design performance."}, {"title": "D. SENTAUR Tool Capabilities", "content": "We will delve into the details of two capabilities in this section and examine how the tool can be utilized in scenarios involving attackers, defenders, and designers.\n1) Signal Declarations and Connections: SENTAUR pos-sesses the capability to incorporate, modify, or eliminate signals, enabling the introduction of new signals tailored for HT-related functions or the alteration of existing signals to include malicious logic. The tool's manipulation of signal connections can be utilized to establish covert communication pathways between the inserted module and external entities. The tool supports various signal modifications:\nInput/Output Signals: The tool augments module declaration by incorporating input/output signals based on user-defined parameters. It caters to scenarios where signals are omitted.\nJoin Signals: These signals unify signals. By replacing the original signal name with the joint signal name, the tool facil-itates adding these combined signals into the design. Route and join signals are convenient pathways for transmitting signals that trigger HTs or instructions activating malicious actions.\nAdd-on Signals: specified in the extra signals parameter inte-grate into the module declaration.\n2) File Manipulation: SENTAUR reads the RTL netlist, ap-plies modifications, and saves the modified RTL netlist to the file. This aligns with an attacker's objective of surreptitiously injecting HT logic without raising suspicion.\nSENTAUR offers valuable functionality for modifying HDL files in designs. It can rename modules, manage signal declara-tions and connections, and manipulate RTL netlists. Designers can customize FPGA/ASIC designs to meet requirements, integrate subsystems, and streamline design processes by utilizing SENTAUR. Its features grant attackers the ability to obfuscate and embed malicious HTs within FPGA/ASIC designs. Additionally, SENTAUR aids assessing vulnerabilities in FPGA/ASIC designs and studying impacts of HTs."}, {"title": "III. EXPERIMENTAL RESULTS", "content": "A. Setup\nFor our study, we integrated GPT-4 to our proposed flow SENTAUR in generating and assessing various HT functional-ities. Our RTL benchmark set consists of HTs from Trust-Hub viz. AES-T600, AES-T800, AES-T900, and standard IP dual-port RAM from Xilinx integrated with Processing System (PS) along with additional logic to control the IP. The motivation to choose dual-port RAM for our experiments is that it finds applications in various fields, including dig-ital signal processing, networking, multiprocessing systems, and high-performance computing. Dual-port RAM refers to a type of memory structure that enables two separate read and write operations to occur simultaneously requiring two different clocks. This memory setup allows for independent and simultaneous access to the data stored within it. It's commonly utilized in scenarios where two different processes or modules need access to the same memory resource without causing conflicts or delays. For testing the changes done on RTL by our proposed flow SENTAUR, we employed a real-world Xilinx FPGA of the Zynq-7000 family with device part xc7z020clg400-1. We built a Linux image for the PS with jupyter notebook interface compatibility, to control and program the functionality of our SoC design using Python code, with the capability to read and write the memory. Figure 3 and Figure 4 shows the design implemented in the FPGA without and with the HT presence, respectively. This validates that the modification done on top of the RTL by the GPT-4 on the RTL is synthesizable."}, {"title": "B. Result I: Analysis on Generation of HTs", "content": "For this study, we took various combinations of triggers and effects for our analysis. Specifically, we took 5 triggers {time-based, logic-based, address, state-based, input-based} and 3 effects {Denial-of-service (DoS), Performance Degra-dation (Perf. Degrade), Information Leakage (Inf. Leak)}, respectively. Table II gives the overall taxonomy as well as the description of each trigger. For our effects:\n\u2022 Perf. Degrade by introducing a dead band which com-promises the performance in terms of output being 0 for some small interval at a regular instant (similar to having some delay in between 2 transmissions) with a slight impact in the amplitude as shown in Figure 5.\n\u2022 Info. Leak signifies side-information leakage as shown in Figure 6 through the use of different channels than the one used for signal transmission, thus making an adversary aware of the data being transmitted to some other users. This can compromise the privacy of a user.\n\u2022 DoS by making the output 0 thus denying any service by not transmitting the required data as shown in Figure 7.\nWe generated the required changes in the RTL by appropri-ately prompting the GPT-4 with the information of the desired result. To compare the ones generated by the RTL and how a designer would have written them, we compared the LUTs and FFs required by each of them. Table II summarizes our result of the different overheads required in both scenarios demonstrating a comparable result when LLM is used. In addition, we took a few examples from the Trust-Hub [6]"}, {"title": "C. Result II: Assessment of HTs", "content": "For the second set of analyses, we focused on manually written HT codes, using LLM (GPT-4), to evaluate these codes for malicious components or indicators of suspicious activity. To ensure a comprehensive assessment, we employed a variety of code combinations as detailed in Table II including examples from Trust-Hub [6]. A key strength of GPT-4 is its ability to summarize and analyze code, allowing it to identify potential vulnerabilities within the code. Crucial to this process is the use of carefully crafted prompts, which guide the LLMs in their analysis. We structured the prompts around four specific areas: logic, state machines, I/O pins, and signal analysis, aligning with the methodology depicted in Figure I(b). This targeted approach enabled the harnessing of GPT-4 analytical capabilities to detect and flag areas in the HT codes that might pose security risks.\n\u2022 I/O pin: In this analysis, it looks for any I/O pins that are used for some sort of condition (or trigger) that can modify the result in the code.\n\u2022 State Machine: In this, the analysis seeks to flag FSMs that look for a particular sequence and depending on that satisfy some condition that can affect the result. There can be many FSMs in a real-world RTL code, which from a human point of view become quite difficult to keep track of, so if LLM can point to only those FSMs where there is some suspicious behavior, it will be of tremendous help from a designer point of view.\n\u2022 Logic: This is the most common flag detected by LLMs in various scenarios, indicating distinct logic in the code or dependency on specific conditions to activate. While this might trigger false alarms, focusing on thorough code scrutiny, especially concerning security, outweighs the potential risks of overlooking critical issues.\n\u2022 Signal: For this, we look for any potentially vulnerable signal that can trigger some part of the inactive logic in normal operations. LLMs can do a great job in reporting only those signals where a human has to go through the whole code and follow the transition of the signal which becomes cumbersome in a large codebase.\nTable II summarizes our findings under the column name 'Assessment'. It shows the part of the code being flagged as potentially vulnerable by the LLM."}, {"title": "IV. CONCLUSION AND DISCUSSION", "content": "SENTAUR is a framework leveraging an LLM to generate a diverse set of legitimate HTs at the RTL. Unlike existing tools that require a learning period to replicate threat models, SEN-TAUR rapidly generates HT instances using LLMs, bypassing the learning phase. It effectively assesses Trust-Hub HTs, conducting comprehensive evaluations with practical use cases and Trust-Hub benchmarks, and exploring diverse impacts and trigger mechanisms at the RTL level. While our primary focus is HT insertion evaluation, SENTAUR also offers a flexible framework for automated modifications of RTL to integrate specific functionalities. Future direction involves extending this work to insert functionalities post-synthesized netlist."}]}