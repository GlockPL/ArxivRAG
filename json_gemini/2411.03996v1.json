{"title": "Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis", "authors": ["ALEXANDROS GKILLAS", "ARIS LALOS"], "abstract": "Anomaly and missing data constitute a thorny problem in industrial applications. In recent years, deep learning enabled anomaly detection has emerged as a critical direction, however the improved detection accuracy is achieved with the utilization of large neural networks, increasing their storage and computational cost. Moreover, the data collected in edge devices contain user privacy, introducing challenges that can be successfully addressed by the privacy-preserving distributed paradigm, known as federated learning (FL). This framework allows edge devices to train and exchange models increasing also the communication cost. Thus, to deal with the increased communication, processing and storage challenges of the FL based deep anomaly detection NN pruning is expected to have significant benefits towards reducing the processing, storage and communication complexity. With this focus, a novel compression-based optimization problem is proposed at the server-side of a FL paradigm that fusses the received local models broadcast and performs pruning generating a more compressed model. Experiments in the context of anomaly detection and missing value imputation demonstrate that the proposed FL scenario along with the proposed compressed-based method are able to achieve high compression rates (more than 99.7%) with negligible performance losses (less than 1.18%) as compared to the centralized solutions.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the Internet of Things (IoT) has revolution-ized the industry discipline, paving the way for better efficiency, safety, and security in the manufacturing processes [1]. Industry 4.0 emerged recently, as an efficient paradigm to handle the need of the inter-connectivity of Industrial IoT (IIoT), enabling the access to real time datasets derived from dispersed edge devices, which can sense the environment and process data in an autonomous and decentralized manner [2]. Nonetheless, the deployment of IoT devices in the Industrial domain introduces some crucial challenges. To be more specific, the quality of the derived multidimensional data is often degraded by various factors e.g., faulty sensors and communication failures, thus introducing various types of anomalies (e.g. data instances that significantly deviate from the majority of data instances such as missing values and/or outliers) [3]\u2013[6] and affecting heavily the performance of various IIoT tasks, such as classification [7], prediction [8]. To address the problem of anomaly detection and restoration numerous centralized solutions has been developed over the years. The considered problem has been studied under various scenarios and settings. Especially, utilizing the advances in deep learning, data-driven models including RNN [9], GAN [10], Transformers [11] and CNN [12] have been getting attention achieving state-of-the-art results in the considered problem. Nonetheless, the above deep learning models re-quire massive amounts of training data and significant com-puting and storage resources, thus rendering them unsuitable for IIoT edge devices. More importantly, in several cases the available data produced from a single industrial site may be insufficient for learning accurate machine/deep learning models to address efficiently Anomaly detection, a.k.a. outlier detection or novelty detection [13], [14]. An intuitive solution to tackle the above issue is to gather data collected from different parties and/or design at the same time more compact NN models. However, due to privacy constraints [2], the industrial entities may be reluctant to expose their owned dataset, while still being interested in an AI model trained"}, {"title": null, "content": "using their own and privately owned datasets of others. Towards this direction, Federated learning (FL), as a secure distributed framework is capable of addressing the above challenges [15], enabling the clients to collaboratively learn a deep learning model without sharing their own private datasets [16]\u2013[18]. The privacy-preserving and distributed nature of the FL promotes such solutions at the network edge, where each IIoT device can be considered as a client con-taining one or more sensors that measure different physical quantities, thus recording a part of the generated multivariate data instances. Both the FL principle, that is based on the frequent exchange of trained models between the edge de-vices and the server, but also the limited computational and storage resources in IIoT devices render the compression and acceleration of the models an imperative requirement.\nThus our work focuses on providing an efficient framework for multivariate time series data by utilizing compressed NNs at the edge following the FL paradigm, allowing the training of the models from a small subset of data instances. It is important to note that existing literature has predominantly focused on less practical scenarios in which edge devices or clients possess sensors that measure identical physical quan-tities, leading to a shared feature space [19]\u2013[25]. However, these scenarios may not be feasible in real-world situations, as different clients may have distinct sensors measuring different features. To address this limitation, our study explores a more realistic federated learning scenario, wherein each client is equipped with a unique sensor that measures only a portion of the multidimensional (multivariate) time series data, resulting in univariate data owned by the clients. Through the use of FL, the clients collaboratively aim to capture the multivariate information by integrating their individual univariate data, effectively reconstructing the full spectrum of information from the diverse sensor inputs.\nFurthermore, inspired by the compression and acceleration techniques aiming to reduce the size of deep learning net-works [26]\u2013[30] and considering the limitations of the IIoT edge devices in terms of computational and power resources [2], [31], a novel compression-based optimization problem is proposed at the server-side in order to fuse the local models broadcast by the edge devices, thus deriving a compressed global model with reduced number of weights without si-multaneously affecting its performance accuracy, providing compression rates (weight pruning) greater than 99.7% while preserving at the same time the performance.\nTo sum up, the key contributions of this paper are the following:"}, {"title": null, "content": "\u2022\n\u2022\nA realistic federated learning scenario is proposed con-sidering that the edge devices contain sensors that mea-sure only a part of multidimensional time series data. In other words, from univariate data\nA novel compressed based fusion rule is proposed at the server-side to combine the local models of the edge devices, providing compressed global models with high compression rates and no performance accuracy losses."}, {"title": null, "content": "\u2022\nExtensive evaluation studies in the context of anomaly detection and missing value imputation demonstrate that the proposed federated learning scenario along with the proposed compressed-based optimization problem are able to achieve high compression rates (more than 99.7%) with negligible performance losses (less than 1.18% and 5%) for the two considered problems as compared to the centralized solutions."}, {"title": "II. RELATED WORKS AND PRELIMINARIES", "content": "In this section, we provide an overview of the existing liter-ature on Federated Learning (FL) in multivariate time series data."}, {"title": "A. RELATED WORKS", "content": "Several studies have explored the use of FL for multivariate time series data analysis, aiming to improve the efficiency and accuracy of data processing in distributed settings. These works have demonstrated the potential benefits of FL in various applications [19]\u2013[25]. In more detail study in [19], [25] focused on a federated learning scenario for machinery fault diagnosis using the FedAvg algorithm. Study in [20] introduced a GAN-based imputation method under the FL framework to solve the missing value imputation problem for multivariate data. Similar to the previous studies, method [21]-[23] used the FL method to detect anomalies in mul-tidimensional time series datasets. However, these studies assume a shared feature space among the clients or edge devices, limiting the practicality of their approaches in real-world scenarios where different clients may possess distinct sensors measuring diverse features. Moreover, the aforemen-tioned approaches utilize different versions of the fedAvg algorithm [32], neglecting the fact that training large-scale deep learning models via Federated Learning can be compu-tationally for edge devices with limited resources.\nMotivated by these limitations, in this work, we develop an efficient approach for handling multivariate time series data in a federated learning context, focusing on the practicality and resource efficiency of compressed deep learning models in edge computing environments. Our approach consists of two primary strategies: initially, by concentrating on univariate time series data from diverse sensors, we inherently simplify the data and reduce the model input data size, making the deep learning models more efficient, especially in resource-constrained edge computing environments. Secondly, we in-corporate a compression mechanism specifically designed to compress the deep learning models while retaining the crucial information necessary for accurate analysis of multivariate data. This compression is performed on the server side during the fusion of client models in the FL process.\nThe proposed approach offers a more practical solution for multivariate time series data analysis in federated learning contexts by considering diverse sensors and features in real-world scenarios. Although the focus is on univariate time series data, it effectively utilizes the multivariate informa-tion through the federated learning process. This enables the"}, {"title": "III. PROPOSED FEDERATED LEARNING IN IOT ARCHITECTURE", "content": "To formulate the examined federated learning framework, a network with N edge devices is considered. Each edge device i\u2208 {1,2,...,N} consists of M\u00a1 sensors measuring different physical quantities e.g., temperature, humidity, energy con-sumption, e.t.c.. Particularly, each device i has locally a time series dataset \\(Y_{i} = {y_{i}^{1},y_{i}^{2},...,y_{i}^{T_{i}}}\\) comprised of a sequence of \\(T_{i}\\) measurements. The t\u2013th measurement \\(y_{i}^{t} \u2208 R^{M_{i}}\\) contain \\(M_{i}\\) features measured at the time step t. Figure 1 illustrates the proposed federated architecture, in the case where each edge device consists of only one sensor, thus containing univariate data (i.e., \\(M_{i} = 1\\)).\nNonetheless, in IIoT applications, the local time series data \\(Y_{i}\\) of each edge device may contain anomaly measurements due to faulty sensors and communication failures. In cen-tralized solutions, the complete time series dataset from all involved edge devices \\(Y \u2208 R^{D\u00d7T} = {Y_{i}}_{i=1}^{N}\\), where \\(D = N \u00d7 M_{i}\\), is required to be gathered in a sever in order to train a machine/deep learning for addressing the anomaly detection and restoration problem. However, this approach not only introduces a substantial burden on the communication links between the server and edge devices, as the devices need to upload their data to server but also may entail risks regarding the privacy of each device.\nTo this end, in this study, a novel distributed approach is proposed that pushes all the involved computations toward to the edge. In particular, taking into consideration, the compu-tational and power limitations of the edge devices [2], [31], a resource efficient federated learning architecture is derived, allowing the edge devices to learn a compressed global model without sharing their local datasets. Note that in this scenario the edge devices do not share the same feature space (i.e., each edge device may contain different sensors), hence the considered federated learning approach constitutes a non i.i.d. problem."}, {"title": "IV. PROPOSED RESOURCE EFFICIENT FEDERATED LEARNING METHODOLOGY", "content": "In this section, details of the proposed resource efficient federated learning approach is provided, describing the main operations of the involved entities, that is the centralized server and the dispersed edge devices."}, {"title": "A. SERVER-SIDE", "content": "On the server-side, the server aims to compute a global model by utilizing a fusion rule that combines all the received lo-cal models from the dispersed edge devices. In vanilla FL methodology [32], the server employs an average update rule of the edge devices models derived by the following optimization problem.\n\\(0_{8}^{m} = arg \\min \\sum_{i=1}^{N} ||0_{i}^{m} - 0_{8}^{m}||\\)\nHowever, considering that the limited computational and power resources of the edge devices impose major restrictions during the training and more importantly the inference time, in this study, a model compression fusion rule is proposed, which aims to combine the local models by calculating a com-pressed global model and thus achieving model compression with negligible accuracy loss. Hence, the proposed optimiza-tion problem is described by the following cost function\n\n\\( \\sum_{i=1}^{N} \\frac{1}{2}||0_{i}^{m} - 0_{8}^{m}|| + \u03bb||0_{8}^{m}||_{1} \\)\n\nwhere \u03bb is a positive scalar constants that controls the relative importance of the l \u2013 1 sparsity imposed regularizer, promoting sparsity in the global model. After solving the pro-posed optimization problem, the server conveys the derived compressed global model back to all edge devices, and the next communication round is performed."}, {"title": "1) Efficient ADMM solver", "content": "The proposed compression fusion rule in (2), although convex requires special treatment due to the non-smooth l 1 term. In view of this, the ADMM methodology [34] is employed by introducing an auxiliary variable Z in order to decouple the original problem into two individual sub-problems. Thus, problem (2) can be written as follows,\n\n\\( \\sum_{i=1}^{N} \\frac{1}{2}||0_{i}^{m} - 0_{8}^{m}|| + ||Z||_{1} \\)\n\ns.t. Z = \\(0_{8}^{m}\\)\nThe corresponding augmented Lagrangian function of problem (4) is given by\nL =\n\\( \\sum_{i=1}^{N} \\frac{1}{2}||0_{i}^{m} - 0_{8}^{m}|| + \u03bb||Z||_{1} + u^{T} (Z - 0_{8}^{m}) \\)\n+\\( \\frac{b}{2}||Z - 0_{8}^{m}||\\)\nwhere u denotes the Lagrange multiplier associated with the constraint [34], and b > 0 stands for the penalty parameter."}, {"title": null, "content": "Hence, a sequence of individual sub-problems emerges, given by,\n\\(0_{8}^{mk+1} = arg \\min L(0_{8}^{m}, Z^{k}, u^{k}) \\)\n\\(Z^{k+1} = arg \\min L(0_{8}^{m,k+1}, Z, u^{k})\\)\n\\(u^{k+1} = arg \\min L(0_{8}^{m,k+1}, Z^{k+1}, u)\\)\nThe solutions of the above problems are\n\\(0_{8}^{m,k+1} = arg \\min L(0,Z^{k}, u^{k})\\)\n\\(Z^{k+1} = soft (0_{8}^{m,k+1} \u2013 u^{k}, \u03bb/b) \\)\n\\(u^{k+1} = u^{k} +b(Z^{k+1} \u2013 0_{8}^{m,k+1})\\)\nwhere the soft (.,\u03c4) denotes the soft-thresholding operator x = sign(x)max(| x | \u2212\u03c4, 0). The aforementioned steps are repeated iteratively until convergence is achieved. Once this occurs, the server sends the compressed global model to the edge devices."}, {"title": "B. EDGE DEVICES-SIDE", "content": "Focusing on the edge-device side, at every communication round m, each device i receives the compressed global model \\(0_{8}^{m}\\) and aims to update its local model \\(0_{i}^{m}\\) by employing its private local time series dataset \\(Y_{i}\\).\nConsidering, that the time series data \\(Y_{i}\\) exhibit strong dependencies across the dimension of the time, we employ the sliding window methodology [35] to effectively capture these dependencies. In more detail, the local time series data \\(Y_{i}\\) of each edge device i is processed into overlapping sequences with time length w, \\({X_{i}^{q}}\\). In other words, each derived se-quence \\(X_{i}^{q} = {y_{i}^{t}, y_{i}^{t+1},...,y_{i}^{t+w-1}} \u2208 R^{M_{i}\u00d7w},q = 1,\u2026 Q\\) consists of w measurements of the dataset \\(Y_{i}\\).\nOnce the local dataset \\(X_{i}\\) is formulated, the edge device proceeds with the training procedure. To ensure that the local model will remain close to the compressed global model \\(0_{8}^{m}\\) during the training procedure, a regularized objective function is utilized\narg \\(min_{0_{i}^{m}} L_{i}(X_{i}, 0) + \u03bc || 0_{i}^{m} \u2013 0_{8}^{m}||\\)\nwhere \\(L_{i}(\u00b7)\\) denotes a general definition of the loss function describing any supervised/unsupervised learning problem, where its parameters are the local time series dataset and the local model. Additionally, the second term known as proximal regularization term [36] is added to the objective function to assist in the compression process performed by the server. Its primary purpose is to keep the local model closely aligned with the compressed global model, hence ensuring that the compression performed at the server remains effective.\nIt should be highlighted that the above optimization prob-lem is equivalent to the original neural network training plus a L2 regularizer, thus it can be solved employing the stochastic gradient descent, since both terms are differentiable. After the local updates, the participated devices broadcast their models back to the centralized server."}, {"title": "C. MASKED FINE-TUNING PROCESS", "content": "The proposed federated learning framework aims to develop a highly compressed and accurate global model, which may necessitate a significant number of communication rounds. To expedite this process and improve the global model's per-formance accuracy and convergence, a masked retraining step is implemented. This step involves additional J iterations, known as fine-tuning rounds, between the server and the edge devices.\nDuring the fine-tuning rounds, edge devices are instructed to update only the non-zero weights in their local training pro-cess. This selective updating is achieved by applying masks to the gradients of zero weights in the local models, effectively preventing any updates to those weights. Thus, for the rest fine-tuning rounds\nOn the server-side, the aggregation of local models from edge devices takes into account that only the non-zero weights have been updated during the fine-tuning rounds. Therefore, the server employs a straightforward aggregation fusion rule, as outlined in (1), to calculate the new global model while maintaining the zero weights untouched.\nThe masked retraining communication rounds are per-formed iteratively until the compressed global model's per-formance accuracy reaches a satisfactory level. This process ensures that the global model is both resource-efficient and accurate, making it suitable for real-world applications, par-ticularly in resource-constrained edge computing environ-ments."}, {"title": "D. AUTOENCODER-BASED MODEL FOR ANOMALY DETECTION AND RESTORATION", "content": "To address the anomaly detection and restoration problem in multidimensional time series data, an autoencoder-based model is proposed, deployed by the participated edge devices. In general the autoencoder aims to copy its input to its output, by projecting the data into a low dimensional latent space [37]. Due to their simplicity and low computational com-plexity, autoencoders are ideal models for edge devices with limited processing capabilities."}, {"title": null, "content": "To increase the receptive field of the autoencoder, thus capturing the strong time dependencies among the time series data \\(Y_{i}\\), we follow the sliding window approach, detailed in Section IV-B. Having derived the pre-processed local datasets \\(X_{i}\\), each edge-device i aims to train a local autoencoder-based model utilizing the regularized optimization problem in (7) and employing as loss function in optimization problem (7), the following,\n\n\\(L_{i}(X_{i}, 0) = \\sum ||x_{i}^{p} - \\hat{x_{i}^{p}}|| = \\sum ||x_{i}^{q} - D(E(x_{i}^{q}))||, \\)\n\nwhere \\(x_{i}^{p} \u2208 R^{1,1} = M_{i} \u00d7 w\\) denotes the vectorized version of the pre-processed local data \\(X_{i}\\), E(\u00b7) denotes the encoder network aiming to to compute the intrinsic hidden represen-tation of the input data and D(\u00b7) is the decoder network that targets to decode the derived hidden representation of the encoding process back to the input data. Note that in case where the local datasets contain missing value anomalies the norm |||| only considers the contribution of the observed values, ignoring the missing values of the local time series data. Hence, during the training procedure of the local serial-ized autoencoder model i.e., vn, the backpropagation updates only those weights associated with the observed values of the input."}, {"title": "Detect Anomalies", "content": "Focusing on the anomaly detection task, the above loss function enables the autoencoder-based models of the edge devices to learn the distribution of the normal data inside the local training datasets. Thus, once the models are trained, they are capable of estimating data points very similar to the training normal data distribution. During the inference stage, the estimated values will follow the distribution of the normal data. Hence, if an anomalous measurement occurs, the trained models will fail to recon-struct it accurately. In more detail, when the reconstruction error (anomaly score) exceeds a certain threshold E, the corresponding data point is determined as an anomaly [3]. To define a proper threshold for the anomaly detection approach, we employ the following relation\n\n\\(E = \u03bc + c \u00b7 \u03c3\\)\n\nwhere \u03bc, \u03c3 denote the mean and variance values of the train-ing data reconstruction error and c is a user-defined parameter that controls the sensitivity of the threshold."}, {"title": "V. EXPERIMENTAL PART", "content": "To highlight the efficiency and applicability of the proposed resource efficient federated learning framework, extensive experiments were curried out on a real-world multidimen-sional time series dataset in the context of the missing value imputation and anomaly detection problems.\nDataset [38]:The considered multivariate time series dataset consists of 27 features derived from dispersed wireless sensors measuring various physical quantities e.g., tempera-ture, humidity, pressure, energy consumption from a building. The derived measurements were recorded every 10 minutes"}, {"title": null, "content": "Parameter Settings: Concerning the dataset, a time win-dow with size w = 50 was employed to split the time series data into overlapping sequences. For the centralized and the FL-multivariate scenario, since the share the same feature space (i.e., the same number of features) an autoencoder with two layers of size 128, 64, 64, 128} was used. Additionally, for the proposed FL-univariate scenario an autoencoder with size {64, 32, 32, 64} was employed. Regarding the training of the centralized scenario, we used 50 epochs with learning rate equal to le-03. For the two FL scenarios, we employed 30 epochs with learning rate equal to le 03 during the training of the local models at the edge devices, and 30 communications rounds."}, {"title": "A. ANOMALY DETECTION AND RESTORATION - REAL WORLD DATASET", "content": "Detect Outliers: In this application, the goal is to detect the anomaly measurements in the time series dataset. To this end, we split the dataset into training, validation and test set intro-ducing randomly outlier points per feature (i.e., points that exceed 3 times the maximum value of each feature). Specifi-cally, we explored two anomaly rates i.e., {10%, 30%}. Table 1 summarizes the anomaly detection results in terms of preci-sion, recall and accuracy metrics. As can be clearly seen the pro- posed FL-univariate method, although it considers edge-devices with different sensors, it is able to exhibit competitive performance against the FL-multivariate approach that con-siders devices with the same feature space and the centralized solution. Furthermore, the compressed federated learning ver-sions of the FL-univariate and FL-multivariate approaches are able to achieve high compression rates without sacrificing accuracy.\nMissing value Imputation: In this IIoT application, the Missing Completely at Random (MCAR) methodology is employed to insert missing values in the training, validation"}, {"title": "VI. CONCLUSIONS", "content": "In this work, the problem of anomaly detection and restora-tion was studied under a resource efficient federated learning perspective. To overcome the limitations of the centralized solutions, the the proposed federated learning scheme pushes all the involved computations at the edge, where each edge de-vice measures only a part of a multidimensional time series. In addition, considering the limited computational and power re-sources of the IIoT edge devices, a novel compression-based optimization problem is proposed at the server-side in order to fuse the local models broadcast by the edge devices, thus deriving a compressed global model with reduced number of weights without simultaneously affecting its performance accuracy. Extensive experiments were performed on a real-world time series dataset, examining the missing value impu-tation and anomaly detection problems to highlight the effi-ciency and applicability of the proposed compressed-based federated learning framework. The proposed framework is able to achieve compression rates greater than 99.7% with-out any degradation to its performance."}]}