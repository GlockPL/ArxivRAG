{"title": "Extractive Schema Linking for Text-to-SQL", "authors": ["Michael Glass", "Mustafa Eyceoz", "Shankar Subramanian", "Gaetano Rossiello", "Long Vu", "Alfio Gliozzo"], "abstract": "Text-to-SQL is emerging as a practical interface for real world databases. The dominant paradigm for Text-to-SQL is cross-database or schema-independent, supporting application schemas unseen during training. The schema of a database defines the tables, columns, column types and foreign key connections between tables. Real world schemas can be large, containing hundreds of columns, but for any particular query only a small fraction will be relevant. Placing the entire schema in the prompt for an LLM can be impossible for models with smaller token windows and expensive even when the context window is large enough to allow it. Even apart from computational considerations, the accuracy of the model can be improved by focusing the SQL generation on only the relevant portion of the database. Schema linking identifies the portion of the database schema useful for the question.\nPrevious work on schema linking has used graph neural networks, generative LLMs, and cross encoder classifiers. We introduce a new approach to adapt decoder-only LLMs to schema linking that is both computationally more efficient and more accurate than the generative approach. Additionally our extractive approach permits fine-grained control over the precision-recall trade-off for schema linking.", "sections": [{"title": "Introduction", "content": "Databases play a crucial role in the realm of business and various other domains due to the wealth of information they contain. However, harnessing this abundance of data to effectively address important queries and gather valuable insights can often prove to be challenging. Text-to-SQL is an approach to constructing queries over databases by using natural language which is then translated to Structured Query Language (SQL). Because Text-to-SQL offers the potential to enable anyone to gather insights, generate reports, answer questions and create dashboards backed by live data it has received a lot of attention from the research community (Rai et al., 2023), (Dong et al., 2023).\nDatabases are structured according to a schema, providing metadata on the set of tables and the columns within each table. Each column is defined by its name and datatype, and the schema may include constraints such as primary keys and foreign keys. Figure 3 illustrates a simple example of a database schema using Data Definition Language (DDL) statements. These \u2018CREATE TABLE' statements represent one method of defining a database schema for a Text-to-SQL system (Gao et al., 2023).\nEarly work on Text-to-SQL (Zelle and Mooney, 1996), (Iyer et al., 2017) focused on training a model for a specific database. More recently, Text-to-SQL systems are trained to be schema-independent (Zhong et al., 2017), (Yu et al., 2018). A schema-independent system can generate SQL queries from natural language questions over any provided database schema, rather than being trained to construct queries over only one database. This is important for two reasons: first, we can gather question-SQL pairs over training schemas to train the system and then deploy to unseen business schemas; second, the schema can change, growing and adapting to requirements while the Text-to-SQL system continues to function. Because a schema-independent Text-to-SQL system is expected to work across schemas, the schema must be provided along with the natural language question as an input. However, this introduces another problem: the schema can be very large while only a small fraction will be needed to generate the query.\nThe size of the schema presents several challenges: token limits, computational costs, and the need for precision in SQL generation. Modern Text-to-SQL systems rely on foundational Large Language Models (LLM), particularly those trained extensively on code (Scholak et al., 2021), (Shaw"}, {"title": "Related Work", "content": "RAT-SQL (Wang et al., 2020) represents an early approach to Text-to-SQL using a pre-LLM schema linking methodology. It combines GloVe embeddings (Pennington et al., 2014) with a BiLSTM (Hochreiter and Schmidhuber, 1997) to process question, column, and table names, generating vector representations for schema elements and query terms. Subsequently, a Graph Neural Network (GNN) models the relationships between tables and columns, informed by the database schema. Relationships between question tokens and schema elements are established through n-gram matching for names and value matching for column contents.\nIn the realm of LLM-based schema linking, there are primarily two approaches: generative and cross-encoder. A generative approach is a natural choice since the SQL generation uses a generative LLM, and can be implemented in either a few-shot or a fine-tuned manner.\nDIN-SQL (Pourreza and Rafiei, 2023) utilizes GPT-4 (Achiam et al., 2023) with decomposed in-context learning for schema linking, SQL generation, and SQL debugging. This process is facilitated by prompt engineering tailored for GPT-4, where few-shot prompts are enhanced with a chain-of-thought technique. For instance, schema linking prompts begin with the directive \u201cLet's think step by step,\" followed by the question. In the few-shot examples, this is followed with a step where the question is repeated and the value or values requested are connected to columns of specific tables. Subsequent steps identify necessary joins and specify cell values needed in the WHERE clause, culminating in a summary of all schema links for straightforward extraction from the generated text. While intuitive, this approach has limitations in performance and lacks a mechanism to provide confidence scores for the schema links.\nDTS-SQL (Pourreza and Rafiei, 2024) adopts a generative approach for schema linking at the table level, predicting a list of relevant tables based on the given question and the entire database schema. This method involves fine-tuning models for both schema linking and SQL generation.\nAnother prominent method involves the use of a transformer encoder, or cross-encoder. RESD-"}, {"title": "Approach", "content": "We combine the key strength of the generative approach: using large, modern code LLMs, with the strength of the cross-encoder approach: a probability for each schema item, enabling recall-oriented predictions. Furthermore, we introduce fine-grained schema linking which predicts a probability for each role a database column could play in the SQL query."}, {"title": "Data Preparation", "content": "The first step in training a schema linker is to gather ground truth. A Text-to-SQL dataset can also provide ground truth for schema linking by examining the SQL queries to find what tables and columns are used in the query. Earlier approaches used a simple token matching strategy to find the tables and columns referenced by a SQL statement (Li et al., 2023a). This is accurate enough to train an effective model, but it is not usable for an evaluation of the schema linker. We found that a majority of mismatches between our schema linker and the ground truth were problems with the ground truth. Rather than token matching, we parse and analyze the SQL statements for each question, simplifying table aliases as needed to identify the columns of each table that are referenced. We use mo-sql-parsing for this static analysis. This produces a ground truth where each natural language question, plus the associated database schema is mapped to a set of relevant, qualified column names, i.e. table.column.\nWhen parsing we also build an indicator vector for each column, indicating what roles it plays in the SQL query. By predicting the roles for each column we assist the downstream SQL generation in constructing the query. The roles we consider are:\n\u2022 selected: used in any SELECT, either outermost or a sub-select.\n\u2022 join: used in any JOIN ON statement.\n\u2022 condition: involved in any comparison other than joins.\n\u2022 order: used in an ORDER BY clause.\n\u2022 group: used in a GROUP BY clause.\nSometimes a table is relevant for a question, but no specific column is needed. For example, in a query such as SELECT COUNT(*) FROM singer, the singer table is needed but no specific column is needed. In this case, we simply indicate the first column from the table is relevant.\nIn contrast, SL-SQL (Lei et al., 2020a) uses a mix of automatic and manual annotation to produce a ground truth for schema linking that also connects the tables and columns in the relevant schema to specific words in the question. We compare our fully automatically generated ground truth to this annotation and find many differences. Out of 7000 Spider training examples there are differences in 4816. Most of these cases are columns that are not mentioned explicitly in the question but are necessary for joining two tables. Considering only those"}, {"title": "Generative Schema Linking", "content": "As an initial experiment we implemented a fine-tuned generative approach to schema linking. In this approach we train a generative model to produce a comma separated list of qualified column names. At inference time, many samples are drawn from the generative model to produce multiple candidate lists of relevant columns. This both increases recall and provides a crude confidence estimation by scoring each column according to how many times it is generated. However, fine-tuning open source code LLMs for generative schema linking did not match the accuracy of state-of-the-art systems based on GPT-4 (Achiam et al., 2023)."}, {"title": "Extractive Schema Linking", "content": "To address the deficits of the generative approach, we developed a decoder-only extractive approach to schema linking: ExSL. In the extractive approach, rather than generate new tokens autoregressively, we use the final vector representation of key input tokens to predict which parts of the database schema are relevant. This is similar to the cross-encoder model of RESDSQL (Li et al., 2023a). However, with the exception of CodeT5 (Wang et al., 2021), modern code LLMs are decoder-only models. Therefore to make use of the code knowledge these models obtain in pre-training, we adapt the extractive approach to a decoder-only model.\nNote that in a decoder-only model, the final hidden vector for each token only considers itself and the tokens before it (Vaswani et al., 2017). Since it is likely beneficial to see the entire schema before determining what is relevant, we repeat the columns as a list of candidates after the entire schema and the question. In this way, predictions for relevance are always made with the entire question and schema within the attention mask.\nIf the entire schema is too large, the schema"}, {"title": "Focused Schema", "content": "After applying the extractive schema linker there is a probability prediction for each qualified column. In order to determine what subset of the schema is deemed relevant, and therefore included in the SQL generation prompt, we need to set a threshold or select a top-k. Since there is considerable variation in the number of needed columns for different queries, a threshold is more appealing than selecting the top-k. Intuitively, recall is more important than precision when selecting a threshold. The SQL generation can ignore columns that are not needed for the query. However, without a needed column in recall, the SQL generation will be unable to generate the correct query, unless it is lucky enough to guess the name of the needed column. In section 5.3 we explore the impact of selecting the threshold and validate our intuition that recall is more important than precision.\nAfter schema linking, only the columns with predicted relevance probability above the threshold are retained as input to the SQL generation. The gray box shows the format for our fine-grained schema linking output in the prompt for SQL generation. We provide a list of columns for each role sorted by their predicted probability for that role. When no columns are relevant for a role (logit threshold -3.0) 'None' is provided."}, {"title": "SQL Generation", "content": "To assess the end-to-end impact of the schema linking we also train SQL generation models. This model takes the subset of the schema selected by the schema linker along with the natural language question and generates the SQL query. We train separate models to consume the column-level, ExSLc, and the fine-grained, ExSLf, focused schemas.\nThe schema linking model produces a query-pertinent subset of the database schema to feed a downstream SQL generation model. For overall end-to-end performance, the SQL generation model needs to be robust to noise from the upstream schema linking. We present a strategy to prepare the training data for a SQL generation model toward such end-to-end robustness. The training data to fine-tune an LLM for SQL generation could use either the full schema or the exact subset of the schema required for the SQL query in the input prompt, with the corresponding ground truth SQL query as the target. Using the full schema is either impossible in the case of very large schemas due to input token length limits, or expensive. Training on the exact ground truth schema subset leaves the SQL generation model unprepared for inevitable errors from the schema linker.\nWe propose to make the SQL generation model robust toward flawed schema linking with a more careful choice of the training data set. For each training data instance in Text-to-SQL training data sets, we first construct the set difference between the full schema set and the exact query-pertinent schema subset. We then sample randomly from this set difference to introduce a controlled level of \"noise\". For example, if the set difference contains 10 elements, 20% noise would correspond to any two elements sampled from this set and added to the ground truth schema subset. This exposes the SQL generation model to diverse, noisy inputs for the focused schema, thereby imparting robustness by mimicking errors from the upstream schema linker."}, {"title": "Datasets", "content": "We train and evaluate on the popular Spider dataset (Yu et al., 2018) (CC BY-SA 4.0). Spider is the most well studied cross-database Text-to-SQL dataset and allows comparison of our schema linker with the previous state-of-the-art. The English questions are categorized as easy, medium, hard and extra-hard based on the required complexity of the SQL query. We also consider three variants of the Spider dataset, developed to create additional challenges and test the robustness of Text-to-SQL systems: Spider-DK (Domain Knowledge) (Gan et al., 2021b), Spider-Syn (Synonyms) (Gan et al., 2021a), and Spider-Realistic (Deng et al., 2021)\nTable 1 shows the basic statistics for the datasets we used. In all cases the schemas for training do not overlap with the schemas for dev or test.\nWe also evaluate on the recently introduced BIRD dataset (Li et al., 2024) (CC BY-SA 4.0), which contains over 12,751 unique question-SQL pairs, covering 95 large databases that span 37 professional fields, including blockchain, healthcare, and education among others. BIRD emphasizes the challenges of noisy database values as well as external knowledge that connects the natural language question to database values."}, {"title": "Evaluation", "content": "Our primary experiments consider the evaluation of the schema linker component at predicting the columns involved in the ground truth SQL statement for each question. For comparison to prior art we also consider table-level metrics measuring the precision and recall of tables found by the schema linker. DTS-SQL uses this metric since it does not produce column-level relevance predictions.\nThe value of schema linking is justified primarily through its impact in final Text-to-SQL performance. In our end-to-end evaluation, we compare the accuracy of SQL generation when provided different schema links. We assess that a generated SQL query is correct if it produces the same results as the gold standard SQL query. We use the Spider and BIRD evaluation scripts to measure execution accuracy."}, {"title": "Component Evaluation", "content": "Table 2 shows our table-level evaluations. Our baseline generative schema linker produces better recall at the cost of precision. Using either the coarse or fine-grained extractive schema linking outperforms DTS-SQL simultaneously on both precision and recall across all datasets.\nWe compare a simple fine-tuned Generative schema linker, the cross-encoder schema linker of RESDSQL, and the generative chain-of-thought prompting of DIN-SQL (using GPT-4) with our extractive, decoder-only approach. Both the generative and extractive models are fine-tuned from DeepSeek Coder 6.7B.\nTable 3 has the component level evaluation of the schema linker. Unfortunately there is no standard metric for evaluation of schema linking. RESDSQL (Li et al., 2023a) uses ROC AUC, while others use precision and recall over different ground truths (Lei et al., 2020a), (Liu et al., 2021), (Lei et al., 2020b). We report area under the precision / recall curve to summarize precision and recall across different thresholds, the F6 measure to integrate precision and recall with a focus on recall, and ROC AUC for comparison to previous work.\nAcross all metrics and all datasets our extractive schema linkers outperform both the generative approach and the prior state-of-the-art. Coarse-grained schema linking (ExSL) is typically better for the component metrics of relevant column prediction, but ExSLf shows impact in Section 5.2. Additionally the extractive approach is more than twenty times faster than the autoregressive generative approach."}, {"title": "End-to-end Evaluation", "content": "To assess the value of schema linking on the final SQL generation, we consider three cases: 1) no schema linking, using the full schema, 2) using exactly the relevant schema, mimicking perfect schema linking, 3) using a trained schema linker. In case three we examine each of the schema linkers considered in our component evaluation.\nTables 5 shows that schema linking with an accurate, recall oriented schema linker is helpful relative to using the entire schema as input. ExSL f"}, {"title": "Precision/Recall Trade-Off", "content": "In this study, we explore how the F3 scores of the schema linker influence the performance of SQL generation that utilizes these schema links. We analyze FB scores at various logit thresholds ranging from 0 to -6. For each threshold, we first calculate the FB score for the schema linker, then generate SQL queries based on the schema links, and finally assess the accuracy of these queries. Our goal is to determine the Spearman rank correlation between the FB scores, which serve as a component metric for schema linking, and the ultimate metric of SQL execution accuracy.\nThis analysis allows us to identify the FB score, particularly the F6 score, as a critical component metric for evaluating schema linkers. We observe that selecting a logit threshold based on the F6 score consistently yields the best or second-best results in terms of SQL generation accuracy across all considered thresholds.\nThe FB score is calculated as follows:\n$F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{(\\beta^2 \\cdot \\text{precision}) + \\text{recall}}$"}, {"title": "Additional Analysis", "content": "Another way to consider the impact of schema linking on the end-to-end task of SQL generation is to examine how the correctness of the generated SQL varies with the correctness of the schema linking. Since both the schema linking and SQL generation are likely to be more accurate on easier Text-to-SQL instances, we also break this analysis down by question difficulty, grouping \"hard\" and \"extra-hard\" into just \"hard\". Table 8 buckets the instances in each benchmark by their schema link-ing F-score and gives the execution accuracy for each bucket. We see that when the schema linking is more accurate we get a much higher execution accuracy.\nTable 9 shows the performance of SQL generation on instances where schema linking did not identify all relevant columns. The execution accuracy of such instances is very low, between 15 and 40 percent depending on the dataset. The correctly executing queries are sometimes a result of the LLM's world knowledge, for example knowing the airport code for a city can eliminate the need to join on a table mapping airport codes to city names. Rarely, SQL generation can correctly guess a column name. Finally, many of the \u201ccorrectly executing\u201d queries in the subset of incomplete recall"}, {"title": "Conclusion", "content": "By focusing on the relevant parts of the database schema, schema linking reduces the computational load and improves the accuracy of SQL query generation. We introduce a novel method for extractive schema linking in Text-to-SQL systems, utilizing modern decoder-only large language models (LLMs). This approach not only demonstrates improved computational efficiency but also achieves superior accuracy compared to contemporary generative methods. Extensive evaluations on Spider, multiple variants, and BIRD establish a new state-of-the-art in schema linking. The introduction of a probability-based model for schema linking allows for a controllable balance between precision and recall. SQL generation also benefits from the fine-grained schema linking we introduce, which predicts the role or roles of each relevant column."}, {"title": "Schema Linking Ground Truth", "content": "Figure 6 shows an example of our process for constructing schema linking ground truth. To find the ground truth schema links for a question in the training set, we start from the ground truth SQL query. We parse the query and identify all column mentions. We will also release this ground truth alongside our open source code.\nThe adjacent question and SQL pairs show examples of SL-SQL schema linking annotations. In the first case the schema linking annotation correctly requires the employee.lastname, which is not in the ground truth SQL query where customer.lastname is selected instead. Question 2, in contrast, shows the mixture of automatic and manual annotation can add unneeded tables and columns (customers is not needed).\nThe most frequent cause of mismatch between SL-SQL annotations and our ground truth is when the SL-SQL annotation omits a column because it does not have a close string match with the question, and annotators neglected to manually add it."}, {"title": "Open Source Model Comparison", "content": "For our initial experiments we attempted both schema linking and SQL generation with a number of open source models. We used StarCoder (Li et al., 2023b), WizardCoder (Luo et al., 2023) and DeepSeek Coder (Guo et al., 2024). These models were chosen for their permissive licenses, competitive performance and for the availability of models with 15B parameters or less - to permit many experiments with a reasonable computational budget. We find that for both schema linking and SQL generation the DeepSeek Coder model provides the best performance while also using the fewest parameters.\nTable 10 gives the initial performance of these models at schema linking. ROC refers to the area under the Receiver Operating Curve, which is the probability that a random relevant schema item is ranked higher than a random irrelevant schema item. This is the metric reported by RESDSQL for"}, {"title": "Hyperparameters", "content": "We use the same training hyperparameters for generative, ExSLc, and ExSLf."}]}