{"title": "TradExpert: Revolutionizing Trading with Mixture of Expert LLMs", "authors": ["Qianggang Ding", "Haochen Shi", "Bang Liu"], "abstract": "The integration of Artificial Intelligence (AI) in the financial\ndomain has opened new avenues for quantitative trading, par-\nticularly through the use of Large Language Models (LLMs).\nHowever, the challenge of effectively synthesizing insights\nfrom diverse data sources and integrating both structured and\nunstructured data persists. This paper presents TradeExpert,\na novel framework that employs a mix of experts (MoE) ap-\nproach, using four specialized LLMs, each analyzing distinct\nsources of financial data, including news articles, market data,\nalpha factors, and fundamental data. The insights of these ex-\npert LLMs are further synthesized by a General Expert LLM\nto make a final prediction or decision. With specific prompts,\nTradeExpert can be switched between the prediction mode\nand the ranking mode for stock movement prediction and\nquantitative stock trading, respectively. In addition to existing\nbenchmarks, we also release a large-scale financial dataset to\ncomprehensively evaluate TradeExpert's effectiveness. Our\nexperimental results demonstrate TradeExpert's superior per-\nformance across all trading scenarios.", "sections": [{"title": "Introduction", "content": "The fusion of artificial intelligence with financial analytics\nhas spawned a new era of innovation, particularly with the\ninfusion of Large Language Models (LLMs) into the realm\nof finance. These models, which have formerly excelled in\nnatural language processing (NLP) tasks, are now being tai-\nlored to decode the complex and cryptic narratives of fi-\nnancial data. This adaptation is driven by a crucial insight:\nFinancial markets are not just numbers-crunching engines\nbut complicated information systems where the subtleties of\nnews articles, reports, and economic indicators interweave\nto influence market dynamics.\nBefore the advent of LLMs, traditional financial mod-\nels (Zeng et al. 2023; Yang et al. 2020; Liu et al. 2020;\nBaek and Kim 2018), primarily relied on quantitative meth-\nods such as statistical analysis, time series forecasting, and\neconometric models. These models often struggled to in-\ncorporate unstructured data such as news articles or fi-\nnancial reports without manual intervention. As a result,\nthe development of LLMs tailored for financial applica-\ntions has progressed rapidly. Initial ventures into this do-\nmain repurposed general LLMs such as GPTS (Brown 2020;"}, {"title": "Problem Definition", "content": "In this study, we aim to trade stocks using a framework that\nincorporates Large Language Models (LLMs).\nThe input data comprises four primary components:\n\u2022 News: Textual information from news articles pertinent\nto the stock and market conditions.\n\u2022 Market Data: Historical OHLCV (Open, High, Low,\nClose, Volume) data representing the stock's trading ac-\ntivity.\n\u2022 Alpha Factors: Quantitative indicators and signals be-\nlieved to possess predictive power regarding stock price\nmovements.\n\u2022 Fundamental Data: Earnings call transcripts and funda-\nmental metrics reflecting the company's economic health\nand performance.\nTask 1: Stock movement prediction is a fundamental\nchallenge in quantitative trading, which involves the pre-\ndiction of future price trends based on multifaceted data\nsources. Formally, let D = {(xi, yi)}=1 denote our dataset,\nwhere xi represents the input vector for the i-th stock on day\nt, and yi \u2208 {Rise, Fall} is the corresponding label indicat-\ning whether the stock price will rise or fall on day t + 1. The\ninput xi can be expressed as:\nXi = {Newsi, Market, Factors, Fundamental;}\n(1)\nOur objective is to learn a predictive function f param-\neterized by @ such that fo(xi) \u2248 yi, where fe is modeled\nusing LLMs. The model outputs a binary prediction, \"Rise\"\nor \"Fall\" indicating the predicted stock price movement.\nTask 2: Stock trading simulation involves evaluating the\nperformance of Buy-and-Hold strategy based on the Top-\nK ranked stocks sorted by TradExpert. This task simulates\nreal-market trading scenarios to assess the profitability and\nrisk of TradExpert using metrics including Annualized Re-\nturn (AR), Sharpe Ratio (SR), Annualized Volatility (AV),\nand Maximum Drawdown (MD)."}, {"title": "Methodology", "content": "In this study, we propose TradExpert, a novel framework\nleveraging the MoE LLMs approach, where four LLMs\nserve as specialized experts for distinct sources of financial\ndata. A General Expert LLM then synthesizes the summaries\nof the four Expert LLMs to produce the final output. The\npipeline of TradExpert is shown in Figure 2.\nIn TradExpert, all expert LLMs are built on the LLaMA-\n2-7B backbone LLM (Touvron et al. 2023b) and are super-\nvised and fine-tuned using the LoRA mechanism (Hu et al.\n2022). Before training and fine-tuning, we preprocess the\nraw datasets to construct prompts, instructions, and ground-\ntruth responses for each LLM. An overall description of the\npreprocessed datasets is demonstrated in Table 1. The details\nwill be introduced in the following."}, {"title": "News Analyst", "content": "The News Analyst LLM is designed to analyze texts of news\narticles to predict stock movements. The prompt and instruc-\ntion for fine-tuning the LLM are shown in Figure 3. The out-\nputs from the News Analyst LLM include not only a predic-\ntion of the stock movement but also a reasoning of how the\nnews article relates to the predicted movement in order to\nemploy a Chain-of-Thought (CoT) (Wei et al. 2022) reason-\ning approach. The ground-truth reasonings are pre-generated\nby the OpenAI GPT-4 API using instructions and prompts\nthat incorporate the actual stock movements and the texts of\nnews articles."}, {"title": "Market Analyst", "content": "The Market Analyst LLM focuses on analyzing historical\nOHLCV (Open, High, Low, Close, Volume) data to predict\nstock movements. However, time series data is inherently\ncontinuous and lacks the discrete token structure that LLMs\nare designed to process. This misalignment poses a signifi-\ncant challenge in effectively utilizing LLMs on time series.\nTo this end, we utilize a reprogramming mechanism (Jin\net al. 2024) to reprogram the input financial time series into\ntext prototype representations.\nFormally, let an OHLCV data instance be $X^{(i)} \\in \\mathbb{R}^{N \\times T}$\nwhich consists of N variables across T time steps. $X^{(i)}$ is\nfirst divided and embedded into a sequence of patch em-\n$\\{X_p^{(i)}\\}\\in \\mathbb{R}^{N \\times L_p \\times d_m}$\nwhere Lp and dm are the\nnumber of patches and the patch embedding dimension re-\nspectively. The patches are then reprogrammed using a col-\nlection of text prototypes E' \u2208 RV'\u00d7D, which is achieved\nby linearly probing the LLM's pre-trained word embedding\nE\u2208 RVXD, where V and V' are the size of the vocabu-\nlary of the LLM and the text prototypes ( V' \u00ab V), and\nD is the embedding dimension. The reprogrammed patches\nare generated using a multi-head cross-attention mechanism:\n$Z_i^{(i)} = Softmax(\\frac{Q_k^{(i)} K_k^{(i) T}}{\\sqrt{d_k}}) V_k^{(i)}$\nwhere query $Q^{(i)}_k = XW_k^Q$, key $K_k^{(i)} = E'W_k^K$, and value $V_k^{(i)} = E'W_k^V$\nfor each head k. The reprogrammed embeddings $O^{(i)}$ are ob-\ntained by aggregating the outputs from each attention head\nand projecting them to the hidden dimensions of the back-\nbone LLM. Finally, the reprogrammed embeddings are aug-"}, {"title": "Alpha Expert", "content": "The Alpha Expert specializes in processing expression-based alpha factors, which are technical indicators and\nalgorithm-generated factors believed to possess predictie\npower regarding stock price movements.\nWe leverage GPT-4's capability of understanding com-\nplex expressions to pre-generate a language description for\neach factor. In this way, we built our Alpha database, where\nan alpha record consists of:\n\u2022 Expression: The mathematical or logical formula used\nto compute the alpha factor based on OHLCV data.\nE.g. rank (ts_argmax(corr(ts_rank(close,10), ts_rank (volume, 10), 10), 5))\n\u2022 Description: Generated by GPT-4 with prompts that include the expression.\nFor each stock, we first calculate the values of all alpha factors based on OHLCV data and then derive a comprehensive score via a LightGBM-based model (Ke et al.\n2017). Subsequently, we select Top-K alphas that contribute\nmost significantly to this comprehensive score. Descriptions\nof these Top-K alphas are retrieved from the database and, along with the calculated values, are included in the prompts\nand instructions for the Alpha Expert."}, {"title": "Fundamental Analyst", "content": "The Fundamental Analyst LLM specializes in analyzing\nfundamental data, including earnings call transcripts and fi-\nnancial metrics, to predict stock price movements on a quar-\nterly basis. The procedure of the Fundamental Analyst LLM\nis similar to that of the News Analyst LLM, with key dif-\nferences being that the fundamental data is updated quar-\nterly and, therefore, the movement predictions are made for\nthe next quarter. The response should include a prediction in\none of the following five categories: \u201cStrong Rise\", \"Moder-\nate Rise\", \"No Change\", \"Moderate Fall\", or \"Strong Fall\",\nfollowed by a reasoning."}, {"title": "General Expert", "content": "The General Expert LLM can operate in two distinct modes:\nprediction mode and ranking mode. Both modes begin by\nsummarizing the reports (historical conversation including\ninstructions, prompts, and responses) from the four special-\nized experts due to the limitations on input context length of\nthe backbone LLM.\nIn prediction mode, used for stock movement prediction,\nthe summarized reports are used to construct a prompt with a\nprediction prefix. Given the summarized reports, the General\nExpert LLM outputs a binary prediction indicating whether\nthe stock will rise or fall.\nIn ranking mode, used for stock trading, the General Ex-\npert LLM functions as a comparator to establish the rank-\ning ability. Specifically, given the summarized reports of\ntwo stocks, the General Expert LLM would determine which\nstock is likely to perform better in the future. To generate a\nTop-K ranking of stocks, we employ a relaxed comparison-\nbased sorting similar to BubbleSort: We initially compare\nevery pair of stocks and count the number of wins for each\nstock. Subsequently, we sort these counts to establish the\nrankings for stocks. Although algorithms like QuickSort and\nvanilla BubbleSort offer fewer comparisons for Top-K se-\nlection on average O(N log N) and O(N \u00b7 K), we propose\nto use this relaxed comparison-based sorting alogrithm with\nO(N2) due to the non-transitive nature of LLM-based com-\nparator (Liu et al. 2024). Therefore, more comparisons tend\nto yield more accurate rankings in practice.\nThe General Expert LLM is finetuned on both tasks of\nstock movement prediction and stock comparison simulta-\nneously. The instructions and prompts are shown in Figure 5."}, {"title": "Experiments", "content": "In this section, we conduct a comprehensive evaluation for\nTradExpert framework on two main tasks: stock movement\nprediction and stock trading simulation. Our experiments\naims to address the following research questions: RQ1:\nHow does TradExpert perform in stock movement predic-\ntion compared with state-of-the-art baselines? RQ2: What\nare the potential profits and associated risks of TradExpert\nin the backtesting on the real market? RQ3: How effective\nis the reasoning capability of TradExpert for unstructured\ndata? RQ4: What is the significance of each expert within\nthe TradExpert framework? RQ5: Why we choose the re-\nlaxed comparison-based sorting algorithm in TradExpert?\nDatasets\nWe include two categories of datasets in our experiments:\n\u2022 Benchmark Datasets: We use publicly available bench-\nmark datasets in stock movement prediction research in-\ncluding CIKM18 (Wu et al. 2018), ACL18 (Xu and Co-\nhen 2018), and BigData22 (Soun et al. 2022) datasets.\n\u2022 Proprietary Datasets: We also utilize our proprietary\ndatasets, which include extensive historical OHLCV\ndata, news articles, alpha factors, and fundamental met-\nrics for a comprehensive analysis.\nExperimental Setup\nIn our experiments, the four expert LLMs and the Gen-\neral Expert LLM are bulit on the LLaMA-2-7B bakcbone\nmodel (Touvron et al. 2023b) and are finetuned via\nLORA (Hu et al. 2022) mechanism.\nStock Movement Prediction: TradExpert works in pre-\ndiction mode, that is, the General Expert LLM reponses a\nbinary prediction indicating whether a stock will rise or fall\nthe next day. Methods are evaluated using binary classifica-\ntion metrics such as accuracy (Acc) and Matthews Correla-\ntion Coefficient (MCC).\nStock Trading Simulation: TradExpert works in ranking\nmode, that is, the General Expert LLM acts as a compara-\ntor to sort the stocks. We simulate the real profit and risk of\nTradExpert by executing trades based on the Top-K ranked\nstocks. TradExpert and baselines are evaluated using metrics\nincluding Annualized Return (AR), Sharpe Ratio (SR), An-\nnualized Volatility (AV), and Maximum Drawdown (MD).\nBaselines\nFor stock movement prediction, the baselines include: (1)\nHybrid Models: StockNet (Xu and Cohen 2018), ALSTM-\nW (Soun et al. 2022), ALSTM-D (Soun et al. 2022),\nSLOT (Soun et al. 2022). 2) Large Language Mod-\nels: GPT-4 (Achiam et al. 2023), Gemini (Team et al.\n2023), LLaMA2-70B (Touvron et al. 2023b), LLaMA3-\n8B (AI@Meta 2024), FinMA-7B (Xie et al. 2023), FinGPT-\nLlaMA2-7B (Yang, Liu, and Wang 2023), InternLM-\n7B (Cai et al. 2024), Falcon-7B (Almazrouei et al. 2023),\nMixtral-7B (Jiang et al. 2023).\nFor stock trading simulation, the baselines include:\n(1)Traditional Models: Random Forest (Breiman 2001),\nDecision Tree (Loh 2011), SVM (Cortes and Vapnik 1995).\n(2) Deep Learning Models: A2C (Mnih et al. 2016),\nPPO (Schulman et al. 2017), SARL (Ye et al. 2020),\nEIIE (Jiang, Xu, and Liang 2017), and DeepTrader (Wang"}, {"title": "Results", "content": "Stock Movement Prediction We implemented all base-\nlines ourselves or utilized existing open-source codes, ex-\ncept the closed-source model SLOT, for which we refer to\nthe metrics reported in the relevant paper. To ensure a fair\ncomparison, we only included the News Analyst and Mar-\nket Analyst in TradExpert, named TradExeprt-NM. The re-\nsults are shown in Table 2. As we can see, among hybrid\nmodels, SLOT achieves outstanding accuracy and MCC on\nthe ACL18, benefitting from the proposed global market\nguidance. Among LLMs, InternLM shows remarkable per-\nformance, particularly on our proprietary S&P500 dataset.\nOur proposed TradExpert-NM, utilizing a mixture of ex-\npert LLMs approach, consistently outperformed other mod-\nels across all datasets except for MCC on the ACL18, show-\ncasing its superior performance. Noting that BigData22,\nACL18, and CIKM18 are relatively small datasets with texts\nfrom tweets, while our S&P500 dataset consist of news arti-\ncles with much more words. This difference in text lengths\ncontributes to the more significant improvements obtained\nby TradExpert-7B-NM on the S&P500 dataset.\nStock Trading Simulation We perform backtesting to\nevaluate TradExpert and baselines. To reduce computational\ncosts in backtesting, we limit the stock pool to about 30\nstocks on the DOW 30, a subset of the S&P 500. For Trad-\nExpert, we implement a Buy-and-Hold trading strategy on\nthe Top-K stocks ranked by TradExpert. The backtesting pe-"}, {"title": "Ablation Study", "content": "The Impacts of Experts To evaluate the effectiveness of\neach expert within the TradExpert framework, we created\nmultiple versions of TradExpert, each with a specific expert\nremoved. By comparing the performance of these modified\nframeworks, we can assess the impact of each expert on the\noverall functionality of TradExpert. The results in Table 4\nreveal the varying degrees of impact of each expert. The\nMarket Analyst and the News Analyst emerged as the most\ncritical, significantly influencing profitability and risk man-\nagement, as seen by the largest drop in AR and AV when\nthey were removed, respectively. The Alpha Expert is obvi-\nously less impactful than the Market Analysts and the News\nAnalysts. The Fundamental Analyst had the smallest effect\non daily trading metrics, but provided essential long-term\nstability, evident from the modest changes in AR and MD\nupon its removal. This highlights a strategic balance in Trad-\nExpert, where each expert contributes uniquely to the final\ndecision and prediction.\nThe Effectiveness of Structured Data Reasoning. We\nshow the effectiveness by comparing TradExpert-MA with\ntraditional models for structured data like OHLCV data and\nalpha factors. We use a genetic programming-based sym-\nbolic regression model as our baseline, which mines alpha\nexpressions aimed at predicting the RankIC of day T + 1's\nreturns. TradExpert-MA is built on top of the same alphas,\nwhere News and Fundamental experts were removed to ex-\nclude affects from other sources. We compare TradExpert-\nMA with the combination of alphas using metrics of Ran-\nkIC and RankICIR. The results are shown in Table 5. The\nimprovements over the alpha combination demonstrate the\nreasoning ability of TradExpert for structured data.\nThe Choices of Ranking algorithm In TradExpert, we\nimplement the Top-K ranking by sorting all stocks com-\npletely using a relaxed comparison-based algorithm, where\nTradExpert serves as the comparator. To justify our choice\nof this seemingly cumbersome approach, we conducted\ncomparison experiments with other theoretically more ef-\nficient ranking algorithms. Specifically, our alternatives in-\nclude QuickSort and BubbleSort with time complexity\nO(N log N) and O(N\u00b7K), respectively. The comparison re-\nsults in Table 6 demonstrate that our approach outperforms\nothers, despite having a higher computational complexity.\nThis is attributed to the non-transitive nature of LLM-based\ncomparator. Therefore, a greater number of comparisons\nyield more accurate rankings in TradExpert."}, {"title": "Conclusion", "content": "In this study, we introduced TradeExpert, a novel framework\nthat harnesses the power of LLMs to enhance stock trading\nstrategies. By integrating multiple specialized LLMs, each\nfocused on distinct aspects of financial data, TradeExpert\nprovides a comprehensive and nuanced analysis that signif-\nicantly outperforms traditional financial models in practice.\nLooking ahead, our goal is to explore how to employ Trade-\nExpert in the high-frequency trading scenario and extend its\ncapabilities to encompass a wider range of global markets.\nLimitation Although TradExpert has notable strengths,\nits processing time poses certain challenges. On average,\nit takes 4.7 seconds for a single stock with an Nvidia\nA5000 GPU. For daily trading, this processing time is gener-\nally manageable. However, for scenarios demanding quicker\ndecision-making, such as high-frequency trading, TradEx-\npert's latency becomes a notable drawback."}]}