{"title": "Leveraging Large Language Models for Solving Rare MIP Challenges", "authors": ["Teng Wang", "Wing-Yin Yu", "Ruifeng She", "Wenhan Yang", "Taijie Chen", "Jianping Zhang"], "abstract": "Mixed Integer Programming (MIP) has been extensively applied in areas requiring mathematical solvers to address complex instances within tight time constraints. However, as the problem scale increases, the complexity of model formulation and finding feasible solutions escalates significantly. In contrast, the model-building cost for end-to-end models, such as large language models (LLMs), remains largely unaffected by problem scale due to their pattern recognition capabilities. While LLMs, like GPT-4, without fine-tuning, can handle some traditional medium-scale MIP problems, they struggle with uncommon or highly specialized MIP scenarios. Fine-tuning LLMs can yield some feasible solutions for medium-scale MIP instances, but these models typically fail to explore diverse solutions when constrained by a low and constant temperature, limiting their performance. In this paper, we propose and evaluate a recursively dynamic temperature method integrated with a chain-of-thought approach. Our findings show that starting with a high temperature and gradually lowering it leads to better feasible solutions compared to other dynamic temperature strategies. Additionally, by comparing results generated by the LLM with those from Gurobi, we demonstrate that the LLM can produce solutions that complement traditional solvers by accelerating the pruning process and improving overall efficiency.", "sections": [{"title": "I. INTRODUCTION", "content": "Mixed Integer Programming (MIP) is a fundamental tool in many optimization domains, such as the Traveling Salesman Problem (TSP) [1], facility location planning [2]. MIP also plays a particularly critical role in time-sensitive applications like transportation and network scheduling [3]; therefore, finding a feasible solution within a short time frame is essential to maintaining system operability and avoiding downtime.\nThe traditional approach to solve MIP problems is the branch-and-bound (B&B) algorithm [4]. While this method guarantees to find the optimal solution for a given instance, the efficiency of mathematical solvers that use such method like Gurobi [5] diminishes as the problem scale increases [6]. Moreover, the complexity of model formulation grows significantly with the dimensionality of the problem. For example, the growth rate of the complexity of a 3D bin-packing problem [7] is considerably higher than that of a 2D bin-packing problem [8].\nTo expedite the search for optimal solutions, mathematical solvers implement various techniques such as heuristics, cutting planes, parallelism, presolve [9]. However, despite these advanced methods, solvers still face challenges in efficiently handling large-scale MIP problems within tight time constraints. Large language models (LLMs), with their strong pattern recognition capabilities, can achieve similar objectives with only minimal data and modeling information. For instance, Yang et al. [10] pioneered the application of Chain-of-Thought (CoT) reasoning [11] in large language models such as GPT-3.5 [12] and GPT-4 [13] to address problems like the TSP using only the coordinates of cities, without explicitly requiring distances between each pair of cities. This approach reduces the time complexity from O(n\u00b2), typically required for distance calculations in traditional mathematical solvers, offering a more efficient solution.\nHowever, the previous work by Yang et al. [10] has several drawbacks. First, the instance data is generated from randomly sampled integers, which may reduce its validity as a demonstration of the LLMs capabilities in real-world MIP applications. Second, the TSP is a well-known and extensively studied problem, meaning LLMs have been trained on similar data and the same TSP model numerous times. In our experiments, we observed that without fine-tuning, LLMs often struggle with novel and complex models and frequently fail to grasp the MIP modeling process. These factors raise concerns about the robustness of LLMs in real-world applications.\nOur work focuses on how to integrate LLMs into real-world applications. To demonstrate the generalizability of LLMs in real-world scenarios, we developed a fine-grained simulator and utilized the operational dataset provided by DiDi in November 2016 to simulate the passenger-driver matching process in the ride-pooling market using MIP. Our work is divided into three main components: (1) We construct a carpooling MIP model based on real-world data while capturing and storing vehicle locations, order locations, MIP instances, and intermediate feasible solution statuses for future training purposes. (2) Leveraging the pattern recognition capabilities of LLMs and CoT reasoning, we generate prompts using only abstract information from the carpooling dataset, bypassing the need to compute MIP parameters, like the distance between the vehicle and the user's order, explicitly. We then perform supervised fine-tuning on LLaMA 3.1 (8B) [14] to discover better feasible solutions, comparing these with the top three feasible solutions generated by traditional mathematical solvers. The results from LLM can be used to accelerate the pruning process in conventional mathematical solvers. (3) We employ recursive dynamic temperature adjustments to refine the quality of feasible solutions generated by the LLM. Through a strategy of starting at a higher temperature and gradually reducing it, we observe significant improvements in solution quality. By systematically evaluating performance under various temperature schedules, we identify the highly effective strategy for enhancing the effectiveness and consistency of the solutions produced."}, {"title": "II. RELATED WORK", "content": "MIP plays a crucial role in combinatorial optimization, with applications in planning [2], scheduling [15], and routing [16]. Traditional methods like B&B [4] have been widely used to solve MIP problems. However, these methods can be computationally intensive, leading to growing interest in enhancing MIP solvers with machine learning (ML) and LLMs.\nRecent works integrating ML with MIP can be categorized into two main approaches [17]: exact algorithms and heuristic algorithms. For exact methods like B&B, ML models have been used to optimize branching variable selection and node selection, significantly improving solution efficiency [18] [19]. On the heuristic side, techniques like Large Neighborhood Search and Feasibility Pump have benefited from ML integration, leading to higher solution quality and computational efficiency [20] [21]. Additionally, Graph Neural Networks have been leveraged to represent MIP instances, enhancing decision-making processes like branching and node selection [18]. Reinforcement learning is also increasingly applied in both exact and heuristic methods to support adaptive decision-making within the B&B framework [22].\nWith the advent of LLMs and the rise of AI agents, more research has focused on translating natural language into operations research problems [23] [24]. Although zero-shot learning typically performs poorly on complex problems, LLMs have significant potential, and their performance can be improved through techniques like the chain of thought [11], tree of thought [25], and self-consistency [26]. Yang et al.'s work [10] utilizes models like PaLM [27] and GPT-4 [13] to tackle linear regression and the TSP with CoT reasoning, demonstrating success on small-scale problems. Our work fine-tunes the LLaMA 3.1 (8B) model [14] using both model information and real MIP instance data capable of generating feasible solutions, and proposes an adaptive temperature strategy that iteratively enhances LLM performance, leading to the generation of even more optimized feasible solutions."}, {"title": "III. METHOD", "content": "Given that LLMs have been trained on numerous traditional MIP problems, such as the TSP, and considering the limitations in the generalizability of previous work due to the use of non-real-world data, we aim to assess the potential of LLMs in MIP under real-world conditions. To achieve this, we construct a carpooling MIP model and develop a simulator to replicate the vehicle dispatching process. The DiDi operational dataset, which consists of the location and time of orders from November 2016, serves as the foundation for generating real-world data in this study. The input is a long text containing information about the locations of orders and the positions of various categories of vehicles, while the output is feasible solutions for dispatching these vehicles to different users."}, {"title": "A. Problem Statement", "content": "There are two types of vehicles: (1) empty vehicles and (2) vehicles with one passenger. Additionally, we assume that each order is associated with a single customer and that a vehicle can accommodate at most two passengers at a time. Our goal is to minimize the total distance traveled for picking up customers, subject to the above constraints. The detailed method for calculating the distance in various scenarios is provided in AppendixVI-B.\nThe notation is as follows:\n$X_{ij}$ is a decision variable indicating whether empty car i is assigned to user j.\n$Y_{ijk}$ is a decision variable indicating whether empty car i is assigned to pick up user j and then user k.\n$Z_{ij}$ is a decision variable indicating whether car i with one passenger willing to share is assigned to user j.\n- $d_{ij}$ is the distance between vehicle i and user j.\n$d'_{jk}$ is the distance between user j and user k."}, {"title": "1. Objective Function", "content": "The objective is to minimize the total distance between vehicles and passengers across all segments of the vehicle paths:\n$\\min \\sum_{i=1}^{n_1} \\sum_{j=1}^{m} x_{ij} d_{ij}+\\sum_{i=1}^{n_1} \\sum_{j=1}^{m} \\sum_{k=1,k\\neq j}^{m} Y_{ijk} (d_{ij}+d_{jk})+\\sum_{i=1}^{n_2} \\sum_{j=1}^{m} zijdig$"}, {"title": "2. Constraints", "content": "Order Coverage: Each user is assigned to exactly one vehicle:\n$\\sum X_{ij} + \\sum \\sum (Y_{ijk} + Y_{ikj}) + \\sum Z_{i',j} = 1, \\forall j$\n$i$ $k,j\\neq k$ $i'$\nVehicle Capacity for Empty Vehicles: Each empty vehicle picks up at most two people:\n$\\sum X_{ij} + \\sum \\sum Y_{ijk} \\leq 1, \\forall i$\n$j$ $j$$k$$j$\nVehicle Capacity for Shared Rides: Each vehicle with one passenger picks up at most one more person:\n$\\sum Zij \\leq 1, \\forall i$\n$j$\nBinary Variable Constraints:\n$X_{ij}, Y_{ijk}, Zi,j \\in {0,1}, \\forall i, j, k$"}, {"title": "3. Analysis of the Constraint Matrix", "content": "As discussed in the previous constraints part, Figure 1 illustrates the relationship between the model-building time and the number of sets. The shape of the constraint matrix is given by:\n$(m + n + p, m. p + m \\cdot p^2 + n \\cdot p)$\nThe complexity of the constraint matrix increases significantly as the size of the set grows, resulting in a very high level of computational complexity. This makes it infeasible to solve the problem instantly if the size of the set increases significantly."}, {"title": "B. Data Collection and Prompt Generation", "content": "Prior to fine-tuning the LLMs, we first identify the positions of the orders and the various types of vehicles. The next step is to generate the labels, which consist of the intermediate feasible solution and the optimal solution for this MIP instance.\n1) Data Storage: When the simulator constructs and solves the MIP instances using the Gurobi solver, we capture several critical pieces of information that include (1) the location of every vehicle and order, (2) the status of intermediate feasible solutions, and (3) the optimal solution.\n2) Prompt Generation: Following the collection of raw and intermediate data, we compile the LaTeX code for the model-building process, the details of each vehicle and order scenario, and both feasible and optimal solutions into a text format, as presented in Appendix VI-A. This information is then used to generate the desired prompt for subsequent training and inference processes."}, {"title": "C. Recursive CoT with dynamic temperature", "content": "Since LLMs, after fine-tuning, exhibit a strong ability to grasp problem patterns, they often produce the same feasible solution at lower temperatures even when the prompt suggests that this solution isn't optimal. Despite recursive adjustments from lower temperatures to higher temperatures intended to explore a broader solution space, LLMs may still become trapped in the previous bad solutions. Thus, a temperature strategy is needed to effectively explore diverse possibilities and enhance solution quality.\nTo address this, we employ a recursive approach with dynamic temperature to leverage CoT effectively. Our strategy involves initially generating feasible solutions with a high temperature to explore a broader solution space. We then iteratively refine these solutions by gradually lowering the temperature. This dynamic temperature adjustment begins with a high temperature to facilitate exploration and progressively decreases to a low temperature to focus on refinement. This balanced approach helps us improve solution diversity and quality, ultimately leading to better feasible solutions. Figure 2 illustrates the entire workflow of training and inference."}, {"title": "IV. EXPERIMENT", "content": "Using LLMs to retrieve the exact optimal solution for medium and large-scale MIP instances is currently impractical. However, due to their strong pattern recognition capabilities, fine-tuned LLMs can provide satisfactory feasible solutions that serve as upper bounds for minimization problems.\nWe aim to explore the potential of LLMs in this context. If LLMs can provide satisfactory feasible solutions during the model-building process, or if traditional solvers like Gurobi face challenges in finding feasible solutions for large-scale instances, these LLM-generated solutions could serve as valuable upper bounds to accelerate the pruning process. By comparing the solutions generated by LLMs with the top three feasible solutions produced by traditional mathematical solvers, we can potentially leverage LLM-generated solutions to enhance pruning strategies and improve overall solver efficiency."}, {"title": "A. Comparision with Gurobi", "content": "We fine-tuned the LLaMA-3.1-Instruct-8B model for the following experiment and split 10% of the total instances in the generated dataset, which contains 12,500 MIP instances, as our test dataset.\nWe compare the best feasible solution obtained from the LLM using three recursive calls, where the temperature gradually decreases from 1 to 0.1 to 0.01, against the first three feasible solutions generated by GUROBI [5], CPLEX [28], and COPT [29] to evaluate which approach achieves a smaller gap. The gap is calculated using the formula:\n$gap = \\frac{current objective value - optimal value}{current objective value}$\nFigure 3 illustrates the relationship between the scale of the MIP instance and the gap observed from LLMs, GUROBI, CPLEX, and COPT. The fine-tuned LLaMA 3.1 (8B) model is able to generate feasible solutions that are much closer to the optimal solution compared to the first three feasible solutions generated by traditional mathematical solvers."}, {"title": "B. Ablation", "content": "To demonstrate the effectiveness of the temperature adjustment strategy from higher to lower in enhancing the performance of our fine-tuned LLaMA 3.1 8B model, we conduct a comparison across several scenarios. These include cases (1) where the temperature initially rises from 0.01 to 1 and then falls back to 0.01 recursively, (2) where the temperature remains constant at 0.01 during recursive calls, (3) where a single temperature setting of 0.01 is used, and (4) where the temperature progressively rises from 0.01 to 0.1 to 1 with each recursion. This comparative analysis highlights the impact of each strategy on the model's ability to generate optimal feasible solutions.\nThe comparison results for medium-scale MIP instances are shown in Figure 4. The solution quality score represents the percentage of feasible solutions generated by LLMs that have a smaller gap compared to the Gurobi solver. The average score in the test dataset is illustrated in Table I. The optimal approach involves using a high temperature to encourage LLMs to explore a broader range of possibilities, which helps prevent them from getting trapped in specific nodes. Subsequently, lowering the temperature exploits and refines the better results, allowing for improved solution quality."}, {"title": "V. CONCLUSION", "content": "Our study evaluates the potential of LLMs to address unknown MIP models and uses the carpooling dispatch case to demonstrate how LLMs can enhance efficiency in finding better feasible solutions. This, in turn, can expedite traditional mathematical solvers' processes by pruning unnecessary nodes. We also examine the effectiveness of various temperature management strategies for find-tuned LLama-3.1-8B in solving medium-scale MIP instances. The comparison results reveal that different temperature management approaches significantly influence the quality of feasible solutions obtained by the model. Starting with a high temperature to explore more nodes and then exploiting better solutions by gradually lowering the temperature improves the quality of feasible solutions generated by LLMs."}, {"title": "A. Prompt template", "content": "Prompt Template\nVI. APPENDIX\nYour task is to find the optimal solution for a carpool dispatch problem. If you cannot find the optimal solution, you should try to return a better feasible solution. The background is as follows:\nRules for vehicle-order pair:\n\u2022\tEach order is for one user only.\n\u2022\tEach car can accept up to two orders.\n\u2022\tThere are three possible scenarios:\n1)\tTwo people simultaneously hail a ride within a certain time range and decide to share the ride. The car will pick up Person A first, then Person B, and drop off Person A first, followed by Person B.\n2)\tA person willing to share a ride, Person A, is already in the car, and the car has started the trip. A new carpool request from Person B is received. The car will go from its current location to pick up Person B, drop off Person A, and finally drop off Person B.\n3)\tA person takes a ride from start to finish without any carpooling.\nThe objective is to minimize the total Manhattan distance between vehicles and users, considering all segments of the vehicle paths:\nLaTex code for building car pooling MIP model\nYou are given x and y coordinates (which are transformed from latitude and longitude using the Mercator projection method) for every empty vehicle, one-person vehicle, and user. The format is as follows:\nEMPTY VEHICLES: (0) (x0, y0), (1) (x1, y1) # Use \"\\n\" if no vehicles.\nONE ORDER VEHICLES: (0) (x0, y0), (1) (x1, y1) # Use \"\\n\" if no one-order vehicles.\nUSERS: (0) (x0, y0), (1) (x1, y1) # Use \"\\n\" if no users.\nAfter transforming the latitude and longitude into x and y, it's much easier to calculate the Manhattan distance between two places. The Manhattan distance between (x0, y0) and (x1, y1) = abs(x1-x0) + abs(y1-y0)\nEMPTY VEHICLES: (0) (86.97, 35.86), (1) (85.23, 36.74), (2) (95.62, 28.43),\nONE ORDER VEHICLES: (0) (90.55, 35.17), (1) (101.43, 44.49), (2) (100.56, 44.77),\nUSERS: (0) (90.33, 35.82), (1) (97.04, 41.87), (2) (100.91, 42.75),\nBelow are some previous solutions. You can derive the optimal solution straightforwardly or derive the intermediate feasible solution step by step.\nThe term \"gap\" refers to the difference between the best-known solution and the best possible solution (optimal solution) within a given tolerance. The smaller the gap, the better the feasible solution. The format of previous solutions is:\nx: (EMPTY_0, USER_5) (EMPTY_2, USER_3)... # Car whose index is 'EMPTY_0' is assigned to user whose index is 'USER_5', and so on.\ny: (EMPTY_1, USER_1, USER_0) (EMPTY_3, USER_10, USER_9)... # Car whose index is 'EMPTY_1' picks up user whose index is 'USER_1', then user whose index is 'USER_0', and so on.\nZ: (ONE_REQUEST_0, USER_6), (ONE_REQUEST_1, USER_7)... # Car whose index is 'ONE_REQUEST_0' with one existing passenger picks up user whose index is 'USER_6', and so on.\nThe x line is \"\\n\" if no one is assigned to a car alone. The y line is \"\\n\" if no two people are assigned to share a car.\nThe z line is \"\\n\" if no one is assigned to a car with one existing passenger.\none of solutions starts:\nx: (0, 1) (1, 0)\nz: (1, 2)\ngap: 1.0, objective value: 24.36\none of solutions ends\n(--more exemplars"}, {"title": "B. The Method for Calculating Distance", "content": "Considering the high computational cost and impracticality of using Dijkstra's algorithm to calculate distances for each instance, we simplify the model by calculating Manhattan distances when formulating the MIP. However, in the simulation process, Dijkstra's algorithm is employed to simulate vehicle movement."}]}