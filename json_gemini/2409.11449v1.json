{"title": "Evaluation of pretrained language models on music understanding", "authors": ["Yannis Vasilakis", "Rachel Bittner", "Johan Pauwels"], "abstract": "Music-text multimodal systems have enabled\nnew approaches to Music Information Research\n(MIR) applications such as audio-to-text and\ntext-to-audio retrieval, text-based song gener-\nation, and music captioning. Despite the re-\nported success, little effort has been put into\nevaluating the musical knowledge of Large Lan-\nguage Models (LLM). In this paper, we demon-\nstrate that LLMs suffer from 1) prompt sensi-\ntivity, 2) inability to model negation (e.g. \"rock\nsong without guitar\"), and 3) sensitivity to-\nwards the presence of specific words. We quan-\ntified these properties as a triplet-based accu-\nracy, evaluating the ability to model the relative\nsimilarity of labels in a hierarchical ontology.\nWe leveraged the Audioset ontology to generate\ntriplets consisting of an anchor, a positive (rele-\nvant) label, and a negative (less relevant) label\nfor the genre and instruments sub-tree. We eval-\nuated the triplet-based musical knowledge for\nsix general-purpose Transformer-based models.\nThe triplets obtained through this methodol-\nogy required filtering, as some were difficult to\njudge and therefore relatively uninformative for\nevaluation purposes. Despite the relatively high\naccuracy reported, inconsistencies are evident\nin all six models, suggesting that off-the-shelf\nLLMs need adaptation to music before use.", "sections": [{"title": "1 Introduction", "content": "The capability of Large Language Models (LLM)\nto obtain informative context-dependent word em-\nbeddings with long-range inter-token dependencies\nshowed that they can be used effectively to encode\nknowledge from several domains without manually\ncurating datasets.\nDuring the last 5 years, the scientific commu-\nnity combined audio-based Deep Neural Networks\n(DNN) with LLMs to form audio-text models, lead-\ning to improved performance on several music ap-\nplications such as audio-to-text retrieval and text-\nto-audio retrieval (Huang et al., 2022; Manco et al.,"}, {"title": "2 Related Work", "content": null}, {"title": "2.1 BERT", "content": "Bidirectional Encoder Representations from Trans-\nformers (BERT) (Devlin et al., 2019; Sun et al.,"}, {"title": "2.2 Large Language Models in Music\nInformation Research", "content": "Transformer-based models have been introduced\nin several applications. Zero-shot classification\nutilizes word embeddings to infer a classifier on un-\nseen classes based on the similarity of the new class\nlabel with the labels of the known classes (Du et al.,\n2024). Audio-to-text and text-to-audio retrieval is\nsuccessful in aligning audio and text embeddings\nusing music/caption pairs (Manco et al., 2022;\nHuang et al., 2022). Automatic music caption uses\nmusic embeddings to condition an LLM (Manco\net al., 2021; Gardner et al., 2024) to generate music\ndescriptions. Lastly, sentence similarity has been\nused to weigh intra-caption similarity in contrastive\nloss functions (Manco et al., 2022; van den Oord\net al., 2018)."}, {"title": "3 Evaluation of language models on\nmusical knowledge", "content": "As far as we are concerned, a linguistic evalua-\ntion dataset of musical knowledge doesn't exist\napart from language-based artist similarity (Ora-\nmas et al., 2018, 2015).\nInformation used for semantic similarity is usu-\nally scraped from websites and we argue that this in-\nformation is not directly useable. Generally, these\nwebsites highlight the history of the queried la-\nbel without juxtaposing related concepts, audio at-\ntributes or providing slang labels and abbreviations.\nAlso, their massive size can hinder inspection and\ntherefore, reduce their value as evaluation sets.\nWe argue that an evaluation dataset needs to be\ncleaned and inspected thoroughly before increasing\nits size. This hasn't been done in captioning and\ntagging datasets, as most are weakly annotated and\nhave highly noisy annotations (Choi et al., 2018).\nTherefore, we chose to utilize an ontology with\nless than 200 musical labels which have a manage-\nable size, can be manually inspected and filtered.\nHowever, we need to acknowledge that most exist-\ning ontologies are far from being exhaustive. We\ndrew inspiration from the Semantic Textual Similar-\nity task (Ojha et al., 2024; Dong et al., 2021; Wahle\net al., 2022) that contains pairs of sentences and\ntheir degree of similarity but proposed a method of\nobtaining such sentences automatically leveraging\na taxonomy.\nWe evaluated 6 general-purpose Transformer-\nbased models (Reimers and Gurevych, 2019) for\nsentence similarity using musical terminology. In\ndetail, a global average pooling layer is appended\non top of the final layer and the sentence embedding\nis calculated as the mean of the respective token\nembeddings. The models used are MPNet, Distil-\nROBERTa, MiniLM and ALBERT trained on differ-\nent corpora. More information about the models is\nprovided in appendix section B and tables 1, 2."}, {"title": "3.1 Audioset and its ontology", "content": "Large-scale annotated datasets have been essential\nfor Computer Vision. Drawing inspiration from\nthis, Audioset (Gemmeke et al., 2017) was pro-\nposed which has \u2248 1.79 million 10-second long\naudio snippets scraped from YouTube, annotated\nwith a hierarchical ontology of 632 audio classes.\nThe creation of their taxonomy focused on two\nproperties: (1) labels must be recognizable by typi-\ncal listeners without additional information beyond\nthe label, and (2) the taxonomy must be comprehen-\nsive enough to describe most real-world recordings\nadequately. After finalizing the taxonomy, annota-\ntors were given a 10-second audio clip and a label.\nThey had to choose from \u201cpresent\u201d, \u201cnot present\",\nor \"unsure\" to indicate whether the audio and la-\nbel used were positively, negatively, or uncertainly\nrelated, respectively.\nIn this paper, we use the Audioset sub-tree"}, {"title": "3.2 Triplet-based musical knowledge\nquantification", "content": "To curate the music knowledge corpus for LLM\nevaluation, we leverage the aforementioned sub-\ntrees of the Audioset ontology and generate triplets.\nSpecifically, we form triplets of an anchor, a pos-\nitive and a negative label. The positive and neg-\native labels are defined relative to their semantic\nsimilarity with respect to the anchor label. If the\nanchor is more similar to label 1 than label 2, label\n1 is the positive and label 2 is the negative label.\nThis method can encode abstract relationships be-\ntween labels, including comparisons between non-\nhomogeneous labels (e.g., \"happy music\", \"rock\nmusic\", \"reggae music\") but is left for future work\nas it requires more elaborate ontologies.\nWe use the distance between the labels based\non each tree to quantify their relative similarity. A\nvalid triplet is defined as one where the anchor-\npositive is less than the anchor-negative distance.\nAfter obtaining the valid triplets, we manually in-\nspect them and remove the ones that are ambiguous,"}, {"title": "3.3 Experiments and results", "content": "After obtaining the sentence embedding using\ntriplets, cosine similarity will be used to evaluate\nthe relative semantic similarity. Anchor-positive\nand anchor-negative cosine similarity will be com-\npared and a triplet will be regarded as correct if\nthe first is greater than the second. A thorough\nanalysis of the results is provided in the appendix\nchapter D. Finally, the accuracy of correct triplets\nwill be calculated and reported."}, {"title": "3.3.1 Prompt sensitivity", "content": "Wrapping queried labels in a prompt is useful (Rad-\nford et al., 2021) but we are not aware of a thor-\nough analysis of the performance variance con-\ncerning different prompts. As a result, we used\n20 musically informed prompts. The exact word-\ning of the prompts is provided in appendix C.1.\nSeveral words as \"music\", \"recording\" or \"sound\"\nhave been used, to simulate human music cap-\ntions/descriptions.\nThe standard deviation reported is relatively high\nfor every case apart from the paraphrased-MiniLM\nmodel as presented in table 1. As the prompts\ndo not provide additional information, it can be\nargued that the models are moderately sensitive\nto the prompts and \u201cmusical\u201d words added can be\nuseful. Lastly, the best model according to model\nsize and performance is paraphrased-ALBERT."}, {"title": "3.3.2 Inability to model negation", "content": "Despite the acquired grammatical understanding re-\nported by LLMs, they cannot model negation (e.g.\n\"not rock\") (Garc\u00eda-Ferrero et al., 2023). To vali-\ndate if this holds for musical labels, we constructed\na separate list of triplets for both \"Musical Genre\"\nand \"Musical Instruments\". For each valid triplet\nobtained, we extracted unique anchor-positive pairs\nand introduced a negative label as a negation of the\nanchor and positive labels. We are left with 3756\nand 8284 negative triplets for Genres and Instru-\nments respectively. These were then used alongside\n4 negative prompts, listed in appendix C.2."}, {"title": "3.3.3 Sensitivity towards the presence of\nspecific words", "content": "Using artificially generated definitions of labels\ninstead of generic prompts led to an increased\nzero-shot image classification accuracy (Pratt et al.,\n2023). Drawing inspiration from this and lever-\naging single-sentence definitions provided by Au-\ndioset, we evaluate the performance when using\nthe label-free definition and the combination of the\nlabel and definition simultaneously.\nExcluding the label from the definition leads to\na drop in every experiment, meaning that models\nmight be sensitive to labels and not the semantics\nprovided indirectly by the definition. On the other\nhand, the definition leads to an increment in accu-\nracy in most cases, as shown in table 2."}, {"title": "4 Conclusions and future work", "content": "In this paper, we quantified the musical knowledge\nof six Transformer-based models based on triplet\naccuracy with musical labels for genres and instru-\nments. We identified three shortcomings: prompt\nsensitivity, difficulty modeling negation and sensi-\ntivity to specific words.\nTo overcome these shortcomings, we propose\nusing augmentation during training and varying the\nprompt structures to avoid prompt sensitivity. This\napproach can utilize definitions to substitute labels\nwith their definitions. To address negation model-\ning, we suggest multi-task learning that includes\ntagging negative labels in a caption and maximizing\nthe distance between negative and positive versions\nof the tags in contrastive losses.\nWe recommend using lexical databases (e.g.\nWordNet), which offer more elaborate music con-\ncept relationships, instead of using a tree to obtain\ntriplets. We highlight that further filtering needs to\nbe done to form meaningful triplets and produce\ngood-quality evaluation datasets. Lastly, despite\nreporting increments when definitions are used, fur-\nther testing is required."}, {"title": "B Language models used", "content": "All the models used are pretrained and then fine-\ntuned for sentence similarity on several corpora\nof pairs. Paraphrase models share the same fine-\ntuning dataset and the same happens for the re-\nmaining 4, with an additional 50 million sentence\npairs for all-distilroberta-v1. More information can\nbe found in the respective papers, Sentence Trans-\nformer 4 package documentation and Hugging Face\nwebsites 5.\nMPNet unifies the Masked Language Modeling\n(MLM) and Permuted Language Modeling pre-\ntasks, used by BERT (Devlin et al., 2019) and\nXLNet (Yang et al., 2019) respectively, to train\na Transformer backbone. The tokens of the input\nare permuted, a set of them is masked and the ob-\njective is to predict the masked section, while the"}, {"title": "C Prompts used", "content": null}, {"title": "C.1 Prompt sensitivity", "content": "The prompts used for evaluating the sensitivity\ntowards different musically informed prompts of\nTransformer-based models are:\n1. \u201cThe sound of <label>\"\n2. \"Music made with <label>\"\n3. \"A <label> track\"\n4. \"This is a recording of <label>\"\n5. \"A song with <label>\"\n6. \"A track with <label> recorded\"\n7. \u201cA music project with <label>\"\n8. \"Music made from <label>\"\n9. \"Music of <label>\"\n10. \u201cA music recording of <label>\"\n11. \u201cThis song is made from <label>\"\n12. \u201cThe song has <label>\"\n13. \u201cMusic song with <label>\"\n14. \u201cMusic song with <label> recorded\"\n15. \"Musical sounds from <label>\"\n16. \"This song sounds like <label>\"\n17. \"This music sounds like <label>\"\n18. \"Song with <label> recorded\"\n19. \"A <label> music track\"\n20. \"Sound of <label>\""}, {"title": "C.2 Negation modeling", "content": "The four prompts used to evaluate the inability to\nmodel negation:\n1. \"No <label>\"\n2. \u201cNot the sound of <label>\"\n3. \"Doesn't sound like <label>\"\n4. \"Not music from <label>\u201c"}, {"title": "C.3 Examples of removed triplets", "content": "As stated in 3.2, there were some triplets of ambigu-\nous quality. We argue that removing these is far\nmore important than building a very big evaluation\ndataset.\nFor reference, we present 10 triplets of different\nambiguousness levels for each category in table 4."}, {"title": "D Detailed experiment results", "content": null}, {"title": "D.1\nPrompt sensitivity", "content": "Generally, prompt sensitivity is evident in every\nmodel. The biggest and best model, all-mpnet-base-\nv2, has the largest and one of the largest variances\nfor instruments (figure 1) and genres respectively\n(figure 2).\nParaphrase-MiniLM-L3-v2 had the smallest vari-\nance for genres, at the expense of a lower accuracy.\nThis might be due to the different distillation pro-\ncess chosen. If an application demands robustness\ntowards prompt sensitivity, that would be the best\nchoice.\nApart from all-mpnet-base-v2, every model had\napproximately the same variance when the outliers\nwere discarded, as can be seen in figure 1."}, {"title": "D.2 Negation modeling", "content": "By far the worst deficiency found is the inability\nof Transformer-based models to model negation.\nThese failed to surpass random choice in every\nexperiment, while altering the prompt led to a sig-\nnificant decrease in accuracy, up to \u2248 20%. This is\npresented in table 3a.\nThis result can have large implications on de-\nveloping or evaluating captioning systems, as\ndatasets (Agostinelli et al., 2023; Manco et al.,\n2023) contain negation and following these results,\ncan lead to erroneous inference. Also, joint audio-\ntext models, also known as two-tower systems, can\nbe negatively impacted. Further testing is required\nin the future."}]}