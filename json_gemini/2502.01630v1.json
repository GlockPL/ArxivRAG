{"title": "TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents\nwith Memory in Multi-Session Dialogues", "authors": ["Yubin Ge", "Salvatore Romeo", "Jason Cai", "Raphael Shu", "Monica Sunkara", "Yassine Benajiba", "Yi Zhang"], "abstract": "Temporal reasoning in multi-session dialogues\npresents a significant challenge which has been\nunder-studied in previous temporal reasoning\nbenchmarks. To bridge this gap, we propose\na new evaluation task for temporal reason-ing in multi-session dialogues and introduce\nan approach to construct a new benchmark\nby augmenting dialogues from LoCoMo and\ncreating multi-choice QAs. Furthermore, we\npresent TReMu, a new framework aimed at en-hancing the temporal reasoning capabilities of\nLLM-agents in this context. Specifically, the\nframework employs time-aware memorization\nthrough timeline summarization, generating re-trievable memory by summarizing events in\neach dialogue session with their inferred dates.\nAdditionally, we integrate neuro-symbolic tem-poral reasoning, where LLMs generate Python\ncode to perform temporal calculations and se-lect answers. Experimental evaluations on pop-ular LLMs demonstrate that our benchmark is\nchallenging, and the proposed framework sig-nificantly improves temporal reasoning perfor-mance compared to baseline methods, raising\nfrom 29.83 on GPT-40 via standard prompting\nto 77.67 via our approach and highlighting its\neffectiveness in addressing temporal reasoning\nin multi-session dialogues.", "sections": [{"title": "1 Introduction", "content": "In the context of multi-session dialogues, tempo-ral reasoning is both critical and challenging for\nLLM-agents. As the number of dialogue sessions\nincreases, storing and retrieving relevant informa-tion efficiently becomes more difficult (Maharana\net al., 2024). LLMs often face challenges in man-aging large, long-term dialogues, such as failing\nto retrieve specific temporal details from long his-tory and dialogues exceed the input limit of LLMs.\nAdditionally, research has shown that LLMs over-look important contextual information from long\ndialogue histories due to the accumulation of ir-relevant historical data, referred to as \"historical\nnoise\" (Wang et al., 2023). These challenges un-derscore the need for enhanced temporal reasoning\ncapabilities in LLM-agents for effective handling\nof multi-session dialogues.\nHowever, most existing temporal reasoning\nbenchmarks cannot be used directly for this study,\nbecause they are built on shorter texts, such as\nstories and Wikipedia articles, that contain clear\ntemporal information (Chen et al., 2021; Wang and\nZhao, 2024; Xiong et al., 2024). Even benchmarks\ndesigned for dialogues, like TimeDial (Qin et al.,\n2021) and LoCoMo (Maharana et al., 2024), do not\nexplicitly account for the special temporal charac-teristics in multi-session dialogues, such as relative\ntime and cross-session dependency. For instance,\nspeakers often use relative time expressions instead\nof specific dates, requiring the model to infer exact\nevent times. Moreover, it is common for speakers\nto recall past events from previous sessions, creat-ing cross-session dependencies, where events from\ndifferent sessions involve the same or related en-tities and reflect changes over time. This further\nrequires LLMs to retain context effectively when\nreasoning about events across multiple sessions.\nIn this work, we present TReMu (Temporal\nReasoning for LLM-Agents in Multi-Session Di-alogues), a novel framework designed to enhance\ntemporal reasoning in multi-session dialogues. Our\nframework introduces time-aware memorization,\nwhich uses timeline summarization to generate\nsummaries for each dialogue session, identifying\nevents and associating them with their inferred\ndates. These summaries, linked to specific times\n(either session times or inferred event dates), serve\nas retrievable memory. This effectively addresses\nevents expressed in relative time by distinguishing\nwhen such an event occurred from when it was\nmentioned by the speaker.\nDuring reasoning, we propose a neuro-symbolic\ntemporal reasoning approach inspired by recent\nwork that integrates LLMs with symbolic reason-ing, translating questions into symbolic language\nbefore using a solver to find answers (Pan et al.,\n2023; Olausson et al., 2023). Specifically, given\na temporal question, we retrieve relevant memory\nand instruct the LLMs to generate Python code.\nThis approach leverages the LLMs' strong Python\ncoding capabilities and existing Python libraries for\ntemporal calculations. The generated code serves\nas an intermediate rationale. By executing the code\nline-by-line, the model follows step-by-step reason-ing similar to CoT (Wei et al., 2022), leading the\nmodel to select the correct answer.\nDue to the absence of temporal reasoning eval-uation benchmarks specific to multi-session dia-logues, we propose a method to construct a new\nevaluation benchmark focusing on two key tempo-ral characteristics: relative time and cross-session\ndependency. By augmenting dialogues from Lo-CoMo (Maharana et al., 2024), we create multiple-choice temporal questions spanning three types of\nreasoning to evaluate the temporal reasoning capa-bilities of LLMs in this context.\nWe evaluate our framework based on three pop-ular LLMs-GPT-40, GPT-40-mini, and GPT-3.5-Turbo-on our benchmark. The results show that\nour benchmark is challenging, revealing subopti-mal performance for LLMs. In contrast, our frame-work demonstrates superior performance compared\nto baseline methods, such as CoT, highlighting the\neffectiveness of our approach in improving tempo-ral reasoning in multi-session dialogues."}, {"title": "Our contributions are as follows:", "content": "\u2022 We propose a new framework for temporal rea-soning in multi-session dialogues, integrating\ntime-aware memorization and neuro-symbolic\ntemporal reasoning.\n\u2022 We propose a method to construct a tempo-ral reasoning evaluation benchmark for multi-session dialogues by augmenting an existing\ndataset, explicitly covering the temporal char-acteristics of relative time and cross-session\ndependency.\n\u2022 Through extensive experiments, we empiri-cally show that temporal reasoning in multi-session dialogues poses significant challenges\nfor LLMs, even with strategies like CoT. How-ever, our framework significantly improves\nLLMs' temporal reasoning in this context."}, {"title": "2 Benchmark Construction", "content": "In this section, we introduce the construction\npipeline to build our temporal QA benchmark\nfor evaluating LLM-agents' temporal reasoning\nin multi-session dialogues. As mentioned earlier,\nwe mainly focus on the two temporal characteris-tics in multi-session dialogues: relative time and\ncross-session dependency."}, {"title": "2.1 Benchmark Design", "content": "We propose augmenting an existing multi-turn di-alogue dataset to create a benchmark for evalu-ating LLM-agents' temporal reasoning in multi-session dialogues. After a thorough examination,\nwe selected LoCoMo (Maharana et al., 2024),\nwhich comprises dialogues averaging 600 turns and\n16,000 tokens across up to 32 sessions. In compari-son to existing multi-session dialogue datasets, Lo-CoMo features the longest dialogues and the most\nsessions, thus presenting a greater challenge. The\ndetailed statistics of LoCoMo and its comparison\nwith other relevant datasets are shown in Table 1.\nAs mentioned earlier, our benchmark focuses on\ntwo key temporal characteristics in multi-session\ndialogues: relative time and cross-session depen-dency. To achieve this, we follow previous bench-marks (Chen et al., 2021; Xiong et al., 2024; Wang\nand Zhao, 2024) by creating temporal QA pairs\nbased on temporal events in the dialogues. Specifi-cally, we design each temporal QA based on either\na single event or a pair of events:\n\u2022 Single Event: We select events expressed with\nrelative time and develop a temporal reasoning type\ncalled Temporal Anchoring, which asks for the ex-act time of the event.\n\u2022 Two Events: We choose pairs of relevant\nevents from different sessions that exhibit cross-session dependency. We also consider relative time\nas an extra factor to increase the complexity of\nthe questions. Two temporal reasoning types are\napplied: Temporal Precedence, which asks which\nevent occurred first, and Temporal Interval, which\nasks for the duration between the two events."}, {"title": "2.2 Construction Pipeline", "content": "To construct our benchmark, we follow the design\nof our benchmark and utilize a systematic step-by-step approach with GPT-4o. The prompt for each\nstep is shown in Appendix Sec.A.\nStep 1: Temporal Event Extraction We begin by\nprompting GPT-40 to extract all temporal events\nfrom each dialogue session. In addition, we instruct\nGPT-40 to annotate the relative time expressions\nfor these events, facilitating the selection process\nfor creating temporal QAs.\nStep 2: Temporal Event Linking Next, we link\nthe extracted events containing cross-session depen-dency within the dialogue. We prompt GPT-40 with\nthe extracted events and instruct it to group those\nrelated to the same or relevant entities across differ-ent sessions, particularly those reflecting changes\nin attributes over time. For example, the event \"De-bra Ryan told her mentor about her business idea\"\nfrom an early session is linked to \"Debra Ryan\nstarted her own business\" from a later session.\nStep 3: Temporal QA Creation Once the tempo-ral events are processed, we prompt GPT-40 to se-lect those events that meet the criteria for different\ntemporal reasoning types and generate multiple-choice temporal QAs. Additionally, we create\nunanswerable questions, as in prior QA bench-marks (Rajpurkar et al., 2018), to comprehensively\nassess models' temporal reasoning capabilities.\nStep 4: Quality Control We observe various\nnoises in generated QAs, such as incorrect infer-ences about exact times or the selection of events\nwith ambiguous time expressions (e.g., \"the other\nday\"). To ensure the benchmark's quality, we\nfollow recent temporal reasoning benchmarks for\nLLMs, such as TGQA (Xiong et al., 2024), to per-form quality control. We manually review each\nquestion to verify that it aligns with our design\nspecifications and that the answers are correctly\ngrounded in the dialogue. We also revise well-constructed questions with incorrect answers and\nremove any unreasonable ones. The final temporal\nQA benchmark covers time intervals from days to\nmonths and its statistics and details are presented\nin Table 2. Particularly, our final benchmark not\nonly contains more temporal QAs than LoCoMo,\nbut also include unanswerable questions, which are\nnot covered in LoCoMo. We also include examples\nof QAs for different temporal reasoning types in\nAppendix Sec. \u0412."}, {"title": "3 Methodology", "content": "3.1 Preliminary: Memory-Augmented\nLLM-Agents\nTo address the limit of LLMs struggling in retain-ing information from long input text, recent studies\nhave demonstrated that equipping LLM agents with\nmemory can efficiently support long-turn conver-sations (Lu et al., 2023; Packer et al., 2023; Zhong\net al., 2024). Therefore, we base our study on\nmemory-augmented LLM-agents.\nThe general pipeline of memory-augmented\nLLM-agents comprises three stages: memoriza-tion, retrieval, and response. In the memorization\nstage, the model summarizes each dialogue session\nand stores these summaries as memory. During\nthe retrieval stage, the model retrieves the most\nrelevant memory for the current dialogue session.\nThis retrieved memory is then concatenated with\nthe ongoing dialogue to generate the next response.\nFor temporal reasoning in multi-session dia-logues, we can apply this pipeline by summarizing\neach dialogue session, retrieving relevant memory\nfor each temporal question, and using this informa-tion to select the answer. Specifically, we build our\nframework based on MemoChat (Lu et al., 2023),\nwhich effectively realizes this three-stage process\nthrough prompting and has demonstrated effective-ness in handling long-range dialogues.\n3.2 TReMu\nBuilding on the memory-augmented LLM-agent\npipeline, we introduce our framework called\nTReMu as shown in Algorithm 1. The framework\nconsists of two key components: time-aware mem-orization and neuro-symbolic temporal reasoning."}, {"title": "3.2.1 Time-aware Memorization", "content": "As LLMs may struggle with capturing temporal\ninformation in dialogues, particularly relative time,\nwe propose a time-aware memorization strategy\nusing timeline summarization (Steen and Markert,\n2019; Rajaby Faghihi et al., 2022; Sojitra et al.,\n2024). Specifically, for each dialogue session\ntagged with its timestamp, we prompt the LLM to\ngenerate its summary while also summarizing men-tioned events occurring on different inferred dates.\nThe prompt is shown in Appendix Sec.C. This al-lows us to obtain a series of summaries for a single\ndialogue session, with each summary is linked to\na specific date. By distinguishing between when\nan event occurred and when it was mentioned, this\ntime-aware memorization could improve temporal\nreasoning and enable more precise event tracking\nacross the dialogue sessions."}, {"title": "3.2.2 Neuro-symbolic Temporal Reasoning", "content": "Allen's interval algebra (Allen, 1983) provides a\nfoundation for solving various types of temporal\nreasoning by identifying event timestamps and per-forming temporal comparisons or calculations. For\nexample, determining the difference between the\ntimestamps of two events allows us to resolve tem-poral interval problems. Building on the interval\nalgebras, previous works have developed various\nneuro-symbolic models to integrate symbolic rea-soning with neural networks (Garcez and Lamb,\n2003; Zhou et al., 2021).\nAdditionally, researchers have explored neuro-symbolic reasoning for LLMs. By providing LLMs\nwith clear instructions about the grammar of the\nsymbolic language and offering a few demonstra-tions as in-context examples, LLMs can accurately\ntranslate problems into different symbolic lan-guage, such as first-order logic (Han et al., 2022).\nOnce the problem is translated, symbolic solvers\ncan be employed to solve it, and it has been demon-strated to outperform methods like CoT for multi-hop reasoning tasks (Pan et al., 2023).\nInspired by the above motivations, we propose\nleveraging LLMs to translate temporal reasoning\nquestions into Python code, which can then be ex-ecuted to derive answers. The detailed prompts\nare shown in Appendix Sec.D. The underlying rea-sons stem from the strong ability of state-of-the-art LLMs in generating Python code in multiple\ncode generation benchmarks and by the availability\nof Python libraries, such as datetime and dateu-til, which support temporal calculations. Partic-"}, {"title": "4 Experiments", "content": "4.1 Baselines and Metrics\nWe build our framework using various backbone\nLLMs: GPT-40, GPT-40-mini, and GPT-3.5-Turbo. Particularly, for GPT-3.5-Turbo, many of\nLoCoMo dialogues are longer than its input length,\nwe then follow LoCoMo (Maharana et al., 2024)\nwhich earlier dialogues are omitted.\nParticularly, in our setting of multi-session di-alogues, where conversations may exceed the in-put limits of LLMs, we also consider the memory\nmechanism as a critical component of baselines\nin order to feed complete dialogue information.\nTherefore, following recent research on tempo-ral reasoning with LLMs (Wang and Zhao, 2024;\nXiong et al., 2024), we compare our approach with\nthe following baseline methods, including direct\nprompting and LLM-agents with memory:\n\u2022 Standard Prompting (SP): The entire dia-logue is provided along with each temporal\nquestion, with additional instructions for se-lecting the correct answer.\n\u2022 Chain-of-Thought (CoT) (Wei et al., 2022):\nSimilar to SP, but with additional instructions\nfor LLMs to solve questions step-by-step.\n\u2022 MemoChat (Lu et al., 2023): Given that\nmulti-turn dialogues can exceed the model's\ninput length, and since our approach builds\non memory-augmented LLM-agents, Memo-Chat serves as a baseline where we modify the\nresponse stage to answer temporal questions.\n\u2022 MemoChat + CoT: This baseline applies CoT\nin the response stage to answer temporal ques-tions step-by-step using the retrieved memory.\n\u2022 Timeline + CoT: Based on the framework of\nmemory-augmented LLM-agents, we modify\nthe original memorization with our proposed\ntimeline summarization and combine it with\nCoT as a baseline.\nFor evaluation metrics, we primarily use accu-racy to assess the overall performance of temporal\nreasoning. In addition, for unanswerable questions,\nwe calculate precision, recall, and the F1 score\nto specifically measure performance on this subset\nof questions. Specifically, precision is computed\nas the accuracy of questions the model predicts\nas \"unanswerable,\" while recall is determined by\nthe accuracy of questions where the ground truth\nanswer is \"unanswerable.\""}, {"title": "4.2 Experimental Results", "content": "The results are shown in Tables 3, 4, and 5 for\nGPT-40, GPT-40-mini, and GPT-3.5-Turbo, respec-tively. On the recent benchmark TRAM (Wang and\nZhao, 2024), existing LLMs have shown strong\nperformance via direct prompting. For instance,\non TRAM, GPT-4 achieves an accuracy of 82 with\nCoT, and GPT-3.5 reaches 71.40 using CoT. In con-trast, our benchmark poses a greater challenge, as\nGPT-40 achieves only 61.67 with CoT and 29.83\nwith SP, while GPT-3.5's performance is signifi-cantly lower, with 25.83 using CoT and 23.83 with\nSP. These gaps are likely due to the challenging\ncontext of multi-session dialogues and the temporal\ncharacteristics in multi-session dialogues, which\nare not explicitly covered by previous benchmarks.\nBesides, our proposed framework outperforms\nall baseline methods across all three LLMs in terms\nof both accuracy and F1 score, with a notable in-crease in accuracy from 29.83 with SP to 77.67"}, {"title": "4.3 Execution Failure Study", "content": "We observe that LLMs occasionally generate\nPython code with syntax errors, such as typos or\nmismatched brackets. To delve into this, we mea-sure the percentage of generated code that fails to\nexecute and, during inference, we regenerate the\ncode when such errors occur. The results, shown\nin Figure 2, indicate that the percentages of ex-ecution failure are generally low across all three\nLLMs, demonstrating the reliability of our Python-based symbolic reasoning approach. As expected,\nGPT-40 exhibits the lowest rate of execution fail-ure, while GPT-3.5-Turbo has the highest, corre-sponding to the overall performance differences we\ndemonstrate above in temporal reasoning among\nthese models. This likely reflects the inherent per-formance gap between the LLMs."}, {"title": "4.4 Case Study", "content": "In this section, we demonstrate how the two key\ncomponents of our framework-time-aware mem-"}, {"title": "5 Related Work", "content": "Temporal Reasoning for LLMs. Recent ad-vancements in large language models (LLMs) have\nbrought significant improvements in reasoning ca-pabilities (Huang and Chang, 2023), leading to\ngrowing interest in temporal reasoning (Chu et al.,\n2024; Qiu et al., 2024). Existing approaches primar-ily address this challenge through time-aware lan-guage modeling. For example, Kanashiro Pereira;\nTan et al. propose fine-tuning strategies to enhance\ntemporal reasoning, while Zhou et al.; Yang et al.\nintroduce auxiliary objectives to incorporate exter-nal temporal knowledge. However, studies such\nas Chu et al.; Qiu et al. show that state-of-the-art\nLLMs still exhibit suboptimal performance in tem-poral reasoning with prompting techniques. Our\nframework differs from these works by utilizing\nmemory-augmented LLM agents, enhancing mem-orization through timeline summarization, and in-tegrating neuro-symbolic reasoning as an interme-diate step for answering temporal questions.\nMulti-session Dialogues. Several studies have\nfocused on multi-session dialogues and developed\nbenchmarks to address this task. Xu et al. intro-duced MSC, the first multi-session dataset incorpo-rating time intervals between sessions. Similarly,\nBae et al. proposed a dynamic memory manage-ment method to maintain up-to-date user informa-tion and introduced a Korean multi-session dia-logue dataset. Jang et al. created the CONVERSA-TION CHRONICLES dataset, designed for long-term conversations that integrate time intervals and\ndetailed speaker relationships. More recently, Ma-harana et al. introduced LoCoMo, a dataset featur-ing long-term dialogues spanning up to 35 sessions.\nWhile our work is situated within this context, it\nspecifically targets temporal reasoning, addressing\nthe temporal characteristics of relative time and\ncross-session dependency, which have not been\nexplicitly explored in prior research."}, {"title": "6 Conclusion", "content": "In this paper, we address the critical challenge of\ntemporal reasoning in multi-session dialogues for\nLLM-agents. We present a method to construct\na temporal reasoning evaluation benchmark by\naugmenting dialogues from LoCoMo, specifically\ntargeting the temporal characteristics of relative\ntime and cross-session dependency. Furthermore,\nwe introduce a novel framework which combines\ntime-aware memorization through timeline summa-rization with neuro-symbolic temporal reasoning"}, {"title": "7 Limitations", "content": "Our work has several limitations. First, our con-structed temporal reasoning benchmark consists\nof multiple-choice questions, while real multi-session dialogues involve users interacting with\nLLM agents in a generative manner. A benchmark\nthat incorporates generative temporal reasoning\nquestions could more accurately reflect the agents'\nreasoning abilities in practical scenarios. We plan\nto extend our current benchmark to support genera-tive question-answering in future work.\nAdditionally, we observe that the LoCoMo dia-logues contain some temporal ambiguities that can\naffect reasoning over related events. For instance,\nif a speaker mentions on a Tuesday that an event\noccurred \"last Monday,\" it is unclear whether the\nevent happened the previous day or on the Monday\nof the prior week. However, in real applications,\nLLM agents could potentially resolve such ambi-guities by asking follow-up clarifying questions."}, {"title": "A Prompts for Benchmark Construction", "content": "We use GPT-40 to construct a temporal reason-ing benchmark for multi-session dialogues. The\nfirst step is the temporal event extraction using the\nprompt shown in Figure 5. Then the prompt for\nthe second step, temporal event linking, is shown\nin Figure 6. With the grouped temporal events, we\nuse the prompt in Figure 7 to create temporal QAs."}, {"title": "B Examples of Temporal QAs in Constructed Benchmark", "content": "We show examples of final temporal QAs for differ-ent temporal reasoning types in Figure 8, 9 and 10.\nIn each example, we highlight the ground truth an-swer as green and show the corresponding selected\ntemporal events for constructing the question below\nthe question."}]}