{"title": "Historical Ink: Semantic Shift Detection for 19th Century Spanish", "authors": ["Tony Montes", "Laura Manrique-G\u00f3mez", "Rub\u00e9n Manrique"], "abstract": "This paper explores the evolution of word meanings in 19th-century Spanish texts, with an emphasis on Latin American Spanish, using computational linguistics techniques. It addresses the Semantic Shift Detection (SSD) task, which is crucial for understanding linguistic evolution, particularly in historical contexts. The study focuses on analyzing a set of Spanish target words. To achieve this, a 19th-century Spanish corpus is constructed, and a customizable pipeline for SSD tasks is developed. This pipeline helps find the senses of a word and measure their semantic change between two corpora using fine-tuned BERT-like models with old Spanish texts for both Latin American and general Spanish cases. The results provide valuable insights into the cultural and societal shifts reflected in language changes over time.", "sections": [{"title": "1 Introduction", "content": "The study of how word meanings evolve over time, influenced by social, historical, and political fac- tors, is a fundamental pursuit within linguistics and natural language processing. This evolution poses challenges in detection and interpretation, often addressed through the Semantic Shift Detection (SSD) task, also known as Lexical Semantic Change Detection task (LSCD) (Montanelli and Periti, 2023; Hu et al., 2021). Traditionally reliant on manual methods such as discourse analysis, recent computational linguistics advancements have revolutionized this field. These approaches streamline analysis and open doors to interdisciplinary research applications spanning sociology, history, and beyond, offering invaluable insights into cultural and societal shifts using digitized corpora.\nIn 2013, static word embeddings, also known as word vector representations, were first introduced by Mikolov et al. (2013) using the bag-of-words and skip-gram architectures. These embeddings represent words as static vectors that remain unchanged and are based on their surrounding words. Hamilton et al. (2016) first proposed using these embeddings for the SSD task by employing di- achronic word2vec static embeddings to measure word meaning changes across consecutive decades. Various approaches have been explored to automate this task effectively. Montanelli and Periti (2023) proposed using contextual embeddings instead to capture multiple meanings assigned to the same word due to polysemy and homonymy, which static embeddings cannot achieve. This was accomplished by comparing multiple BERT-like Language Models (Devlin et al., 2018) such as XLM-ROBERTa.\nIn this paper, we focus on two things: crafting a 19th-century Spanish corpus (Cold) from sources spanning 1800 to 1914 and creating a customizable pipeline for assessing the SSD task. Utilizing this pipeline, we analyze the semantic changes of a set of target words, for both the global context and the specific Latin-American context. We explore a variety of known and novel solutions for the SSD task by comparing the 19th-century Spanish corpus with the Spanish portion of the \"EUBook- Shop\" corpus as the modern corpus (Cnew) (Ca\u00f1ete, 2019)."}, {"title": "2 Related Work", "content": "Recent advances in Semantic Shift Detection have leveraged many computational approaches based on natural language processing techniques. Contextual embeddings, capable of capturing multiple- word usages and meanings, have been used in most of the state-of-the-art solutions, summarized by Montanelli and Periti (2023) who defines a classification framework based on three dimensions of analysis: meaning representation (form- and sense-oriented approaches), time awareness (time- oblivious and -aware) and learning modality (super- vised and unsupervised, referencing to the injection of external knowledge support like a dictionary), useful for Contextualized Semantic Shif Detection. Martinc et al. (2020) and Giulianelli et al. (2020) explore transformer-based BERT models for detecting semantic change. Martinc et al. uses contextualized embeddings to capture shifts in word usage over time, outperforming traditional tech- niques like Word2Vec and Glove by leveraging BERT's dynamic word representations. Giulianelli et al. (2020) adopt an unsupervised approach, obtaining and clustering word representations to measure change over time, aligning with human judg- ments. Both studies underscore the effectiveness of BERT-based models in identifying and analyzing diachronic linguistic changes.\nAlthough most of the research in the field of semantic change has been done on a wide scope of languages, Spanish hasn't played such an important role in this field, except for some research, like LSCDiscovery in Spanish, a task presented by Zamora-Reina et al. (2022). This task has fa- cilitated the development and evaluation of SSD systems in this language, accompanied by an unan- notated Spanish corpus for both modern and old texts, which has a size of 22M and 13M tokens respectively. Additionally, the task paper highlighted effective techniques and approaches within the solutions. The most successful solution for the LCSDiscovery task was GlossReader, developed by Rachinskiy and Arefyev (2022), which involved fine-tuning XLM-RoBERTa, a Language Model trained on more than 100 languages, with old En- glish datasets and employing the model zero-shot cross-lingual transferability of the model to build contextualized embeddings for Spanish, and using this fine-tuned model for SSD tasks. This approach has demonstrated good performance, especially in avoiding issues associated with word form bias and labor-intensive annotation requirements. These advancements underscore the increasing significance and potential of computational methodologies in enhancing our comprehension and automation of semantic shifts in multiple languages.\nAlso, Hu et al. (2021) present a set of method- ological considerations for low-resource languages such as 15th-century Spanish, where a lower amount of data is available, and the data is not as clean as in other high-resource languages such as English and Mandarin Chinese, stating that common SSD techniques are also useful for these cases, but must be used carefully, under a set of consider- ations."}, {"title": "3 Data", "content": "Selecting the data is a crucial step for the relia- bility of the results. The LSCDiscovery shared task provides a useful corpus for old Spanish texts within the years 1810-1906, with a size of 13M tokens (Zamora-Reina et al., 2022). However, this paper aims to construct a larger old Spanish corpus, also adding more presence from Latin-American countries. The main sources selected and filtered for this corpus were Project Gutenberg which was filtered by language and by the given date ranges (1800-1914), The British Library books (portion from 1800-1899) which was also filtered by language (British Library Labs, 2021), and the LatamXIX dataset from the Historical Ink project which contains Latin American texts from newspapers within years 1845-1899 (Manrique-G\u00f3mez et al., 2024).\n3.1 Cleaning\nThe cleaning step is essential for The British Li- brary and Project Gutenberg datasets since some texts from these sources consisted solely of chapter, book, or newspaper titles, or were filled with numbers and other characters that added noise to the dataset. In the case of the LatamXIX dataset, these noisy rows were already filtered and complemented with an LLM OCR correction process that corrected many OCR errors within the corpus, making it cleaner and more fittable for the SSD task, as it preserves better semantic meaning for words and less noise.\nFor The British Library books, an initial filter was applied using word confidence information to retain only those books with a mean OCR word confidence higher than 0.5. This experimental threshold was set to balance data loss (2.26% of rows) and text quality. After conducting several revisions with different examples, it was observed that this threshold maintained a high standard of text quality. Therefore, it was selected as the optimal balance"}, {"title": "3.2 Chunking", "content": "As the historical texts from the corpus come from books and newspapers, many are very large, or some are very short with an average of ~ 110 words and ~ 140 tokens per text. For BERT-like models, the maximum sequence length consists of 512 tokens, which is insufficient for large texts like the current corpus texts.\nBecause of this, it's necessary to chunk the large texts within the dataset in a number shorter than 512 tokens. A much lower number was selected to make the chunked corpus fit for many different Language Models (LMs), for instance, a maximum of 256 tokens per text chunk, where a token was measured by training a new tokenizer over the cleaned version of the corpus.\nDuring this step, over 67.6% of the rows were chunked, adding 460,543 new rows. Each row was transformed into a part of a paragraph or left as a whole paragraph (no chunking) with no more than 256 tokens while preserving as much semantic meaning as possible. The preservation of semantic meaning in the chunked segments was achieved by splitting through punctuation marks and common paragraph-sentence separators."}, {"title": "4 Methodology", "content": "To achieve effectively the desired task, and be able to perform a quality analysis of the results, we have defined the pipeline observed in Figure 3, with the following steps:\n1. Find the occurrences of a given word w in Cold and Cnew corpora.\n2. Retrieve the word embeddings in the found occurrences, using a BERT-like language model.\n3. Cluster the word usage by its meaning (sense), and average to get the centroids of the clusters.\n4. Perform the SSD task to identify lost/gained senses and measure the semantic change of the word ($s_w$).\nIt's important to note that the pipeline was designed as a flexible and reusable solution for various contexts and configurable stages. Beyond analyzing the specific case of 19th-century Spanish, we propose a modular, plug-and-play pipeline with numerous adjustable stages. Each component of the pipeline can be used independently and configured for different use cases, ensuring versatility and adaptability for further research or applications.\n4.1 Find the Occurrences\nGiven corpora Cold and Cnew, finding all texts where a word w is used is straightforward when looking for exact occurrences. However, this task becomes more complex with inflectional variations typical of languages like Spanish. For example, the word \"crear\" (to create) may appear as \"creaste\" (you created) or \"creado\" (created). Stemming can help by extracting the base form of the word, but it may lose some contextual meanings.\nAlso, in old Spanish, language rules have changed significantly, as noted by Montgomery (1966). These changes are detectable using the semi-automated framework presented as part of the Historical Ink project (Manrique-G\u00f3mez et al., 2024), which extracts useful lists of surface forms (i.e. specific appearance of a word in a given context) for words that underwent orthographic changes in 19th-century Latin-American Spanish (e.g., \"luces\" historically written as \"luzes\").\nTo address these challenges, we propose a method to find occurrences of a given word w in diachronic corpora Cold and Cnew. This method organizes all word's expected usages and tokenizes both the word and the searching text, searching for each subword within a list of different orthographic forms of writing a given word.\nFor example, the word \"gente\" would be searched in Cold as \"gente\", \"jente\" (surface form), \"gent\", or \"jent\" in that order. This method relies heavily on the tokenizer, so using one trained in the specific language is recommended for better performance.\n4.2 Word Embeddings\nFor the SSD task, contextual embeddings are very useful as they can capture the evolving meaning of words over time. By considering the surrounding context of a word within a sentence or document, contextual embeddings can provide an enhanced representation of its semantics, enabling the detection of particular shifts in meaning. In particular, there are some BERT-like LMs trained on Spanish corpora. Some of the most representative are BETO: Spanish Bert in both uncased and cased versions (Ca\u00f1ete et al., 2020), Multilingual BERT in both uncased and cased versions, which has an"}, {"title": "4.3 Clustering", "content": "We applied a joint clustering approach, combining both corpora within the same set of embeddings before clustering. Given two corpus Cold and Cnew, and a particular word w, the sets \u03a9w,old and \u03a9w,new are defined as the set of word embeddings gener- ated in each corpus respectively, for the word w.\nThe clustering algorithm is meant to find the different meanings of a word within a given pe- riod, and overall the whole timespan of both Cold and Cnew periods. This generates a well-known Diachronic Word Usage Graph (DWUG) for the word in both periods (Schlechtweg et al., 2021), allowing to perform the semantic shift detection and change measurement between old and new periods, as seen in Figure 4, where each color refers to a word meaning.\nThe particular algorithms used were Affinity Propagation and KMeans with an automatic K finder under a certain score function such as silhouette score or inertia. The main problem with KMeans are words with a single meaning across the whole timespan. As common KMeans K- evaluation metrics are not fittable for one-cluster evaluation, so it wouldn't be possible to validate if the best number of clusters should be just one. As this occurs for many of the target words se- lected for analysis, a very good alternative for it is the Affinity Propagation (AP) clustering algorithm with a damping parameter of 0.975; this parameter was selected through a test with different values and a manually-driven evaluation of the number of clusters automatically selected by the algorithm. Selecting a high damping value for the AP algo-"}, {"title": "4.4 Semantic Shift Measurement", "content": "Once clustering is performed, the measurement for Semantic Shift is straightforward. There are two main divisions of the SSD task which are Binary Change Detection (BCD) and Graded Change Detection (GCD) (Zamora-Reina et al., 2022), where Graded Change Detection is the most common and useful, but also the most challenging task for change classification, which consists of ranking a list of target words based on their degree of change (Periti and Tahmasebi, 2024).\nThe consolidation of techniques for measuring semantic shift detection has been a high-growth area, with the proposal of many different tech- niques, some of them comparing sets of embed- dings (e.g. the clusters), and others comparing indi- vidual embeddings (e.g. the centroids). Montanelli and Periti (2023) present a survey that compiles many of the most used state-of-the-art techniques for grading the semantic shift of a word between two temporal-different corpora, classifying them between form- and sense-based approaches.\nGiven m number of clusters (senses) for the word w, returned by the clustering algorithm, we define \u03a8w.s.t as the cluster with the sense s for the word w in the period t, such that all the senses compound the whole set of embeddings.\n\u03a9w,1 = \u222ams=1 \u03a8w,s,t t = {new, old} (1)\nFor these clusters, a centroid embedding is com- puted as the average:\n\u03a8w,s,t = avg(\u03a8w,s,t) t = {new, old} (2)\nFinally, two different formulas were taken from Montanelli and Periti (2023) to measure the semantic shift f, based on the cosine similarity function (CS). With this shift, for each word, we would have as many semantic shifts f as the number of clusters given by the algorithm (m), so we could determine which senses have had a diachronic shift and which haven't, for each word.\nCosine Distance (CD):\nfCD(W, s) = 1 \u2013 CS (\u03c8w,s,old, \u03a8w,s,new) (3)\nInverted similarity over Word Prototype (PRT):\nfPRT(W, s) = 1 / CS (\u03c8w,s,old, \u03c8w,s,new) (4\nIt should be noted that if a sense is not present within a period, whether old or new period, fCD should be 1.0, meaning a complete change of the given sense. If the sense is absent from the embeddings of the old period (\u03c8w,s,old = 0), it means that the sense was gained in modern Spanish; otherwise, if the sense only exists in the embeddings of the old period (\u03a8w,s,new = 0), it means that the sense was lost in modern Spanish, as seen in Figure 4 where the sense 1 (orange color) is not present in the modern WUG.\nFor this task, it is crucial to consider the frequency of points per cluster within each period. If a cluster has significantly fewer points in a period, specifically less than 10% of the total, we classify these points as either misclassifications or obsolete words. This allows us to treat the cluster as a gained or lost sense. We chose this threshold based on testing with few known examples, where it provided the best performance in detecting gained and lost senses."}, {"title": "5 Evaluation and Model Selection", "content": "As mentioned, several pre-trained Language Mod- els (LMs) are available for large Spanish corpora. We needed an evaluation method to select the best model for our analysis. The LSCDiscovery shared task (Zamora-Reina et al., 2022) provides over 65,000 annotated examples for 100 target words using the DURel framework proposed by Schlechtweg et al. (2018). This annotated corpus is highly useful for evaluating the LMs, as its time period is within the 19th century. Even though the LSCDiscovery task differs from the one in this paper, it offers a valuable benchmark. Our task focuses on detecting the different meanings of a word in a diachronic corpora and measuring their"}, {"title": "6 Results", "content": "The results of the trained model focus on a specific group of 255 target words selected for their historical significance and relevance to generate hy- potheses about potential semantic shifts over time, confirming the consistency of the results. Some examples of the DWUGs analyzed in this section are available in Appendix C for both AP and KMeans.\nOne of the main results of this research was to highlight the success and failure cases for both AP and KMeans clustering algorithms, as both were used to compute the senses of all 255 words. Affinity Propagation (AP) performed poorly in many cases where it couldn't detect multiple usages of a word, such as \"grave\" (serious/bass), or detected many different senses for other words, such as \"honor\" (honour), as shown in Figure C2. However, it effectively detected single-sense words, a task that KMeans wasn't capable of due to metrics used to choose the best K. However, KMeans performed very well in most cases, effectively de- tecting and clustering the senses of multi-meaning words over time.\nAs displayed in Figure C2, some words like \u201crey\" (king) and \"usurer\u201d (usurer) present neither poly- semy nor notable historical changes. However, the term \"mujeres\u201d (women), as shown in Figure 4, shows a change in modern usage. This finding is particularly interesting in the context of both historical discourse analysis in gender studies and historical linguistics studies, as it is an example of computational verification.\nThe semantic transformation of the word women, as plotted in Figure 4 and in Appendix B, primarily pertains to the antiquated use of \u201cmujeres\" designating a particular group of female individu- als. In 19th-century Spanish, lexical tradition man- dated the rigorous use of masculine forms of nouns and adjectives as the universal form, encompassing both genders (feminine and masculine) (Porto- Dapena, 1975). Thus, the word \u201chombres\u201d (men) could be used as a synonym for humanity, while the use of \u201cmujeres\u201d (women) was more likely to be reserved for describing a private group of women. Twentieth-century gender studies introduced a unified meaning to the word \u201cmujeres\". Joan W. Scott famously stated that \"-Women's experience- or- women's culture- exists only as the expression of female particularity in contrast to male universality\" (Scott, 1988). This idea explains the rupture in the modern usage of the word women towards the relational concept of gender in the 20th century (Lux and P\u00e9rez, 2020).\nConsequently, the term \u201cmujeres\u201d evolved from a specific designation to a broader and more in- clusive reference, reflecting significant social and cultural shifts in gender discourse. As we have ob- served, the contemporary usage of \"mujeres\u201d tends to encompass all women more generically, since it was not until the 20th century that historical consid- eration began to differentiate \"women\" as a collec- tive separate from \"men\". In the past, the term was used to refer to a distinct group of women, thereby distinguishing women from other plural nouns such as men, children, or even animals. Modern usage of \"women\" almost exclusively serves to differentiate women from men.\nOther insightful results demonstrate both how the polysemy of words changes over time, as seen in examples in Appendix A, and the particulari- ties of word semantics diachronically used in Latin American Spanish. Historical linguistics studies acknowledge \"El espa\u00f1ol de Am\u00e9rica\" as a main Spanish variant, for which corpus studies are yet to be conducted. Newspapers are recognized as a legitimate source for exploring the particularities of linguistic variants (Guti\u00e9rrez Mat\u00e9 and Diez del Corral Areta, 2023). Hence, the LatamXIX dataset we used to model the quantitative experiments might initiate a triangulation with new regional research. For example, we have observed how the term \u201cinfancia\" (infancy/childhood), as depicted in Figure C1, was predominantly used in the 19th century as an abstract reference to the nascent phase of objects, entities, or people. This sug- gests a metaphorical use of the word, indicative of a broader, symbolic interpretation of \"infancy\" or \"early development\" during this era.\nNewly formed Latin American nations in the 19th century viewed themselves as children re- cently independent from their mother, metropolitan Spain. Consequently, the term \"infancia de la patria\" (infancy of the nation) described the contradictory and highly unstable political and social times experienced in Latin America during that era. These old meanings have largely been sup- planted by the modern understanding of \"childhood\", which specifically refers to the population segment of children. These results align with the"}]}