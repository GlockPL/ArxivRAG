{"title": "WSSM: GEOGRAPHIC-ENHANCED HIERARCHICAL STATE-SPACE MODEL FOR GLOBAL STATION WEATHER FORECAST", "authors": ["Songru Yang", "Zili Liu", "Zhenwei Shi", "Zhengxia Zou"], "abstract": "Global Station Weather Forecasting (GSWF), a prominent meteorological research area, is pivotal in providing timely localized weather predictions. Despite the progress existing models have made in the overall accuracy of the GSWF, executing high-precision extreme event prediction still presents a substantial challenge. The recent emergence of state-space models, with their ability to efficiently capture continuous-time dynamics and latent states, offer potential solutions. However, early investigations indicated that Mamba underperforms in the context of GSWF, suggesting further adaptation and optimization. To tackle this problem, in this paper, we introduce Weather State-space Model (WSSM), a novel Mamba-based approach tailored for GSWF. Geographical knowledge is integrated in addition to the widely-used positional encoding to represent the absolute special-temporal position. The multi-scale time-frequency features are synthesized from coarse to fine to model the seasonal to extreme weather dynamic. Our method effectively improves the overall prediction accuracy and addresses the challenge of forecasting extreme weather events. The state-of-the-art results obtained on the Weather-5K subset underscore the efficacy of the WSSM.", "sections": [{"title": "I. INTRODUCTION", "content": "Global Station Weather Forecasting (GSWF) plays a vital role in providing localized and accurate weather predictions worldwide [1, 2]. It supports critical sectors such as disaster management, agriculture, and transportation by enabling precise, site-specific forecasts, which are increasingly important in mitigating the impacts of climate change and extreme weather events [3].\nExisting data-driven approaches to GSWF typically model the problem as a time series forecasting task. These methods leverage historical weather observations to predict future conditions, often employing advanced time series models such as multilayer perception (MLP) [8, 15, 17], Long Short-Term Memory (LSTM) [4] and Transformer [5-7]. By directly applying these state-of-the-art models, researchers aim to capture the complex temporal dependencies and nonlinear patterns inherent in weather data, offering a promising alternative to traditional physics-based forecasting methods. Despite the effectiveness of existing time series models, these approaches often struggle to accurately model the complex dynamical processes governing atmospheric behavior. Such limitations arise from their limited ability to capture long-range dependencies and underlying physical structures critical for precise weather forecasting [9].\nRecently, state-space models, such as the Mamba model [10, 16], have shown significant potential in time series modeling due to their ability to efficiently capture continuous-time dynamics and latent states. However, early investigations have revealed that Mamba underperforms compared to Transformer-based state-of-the-art methods in the context of GSWF [2]. This suggests that while Mamba excels in general time series tasks, further adaptation and optimization are required to address the unique challenges posed by the complex dynamical processes inherent in GSWF.\nTo address the challenges mentioned above, we propose a novel Mamba-based model architecture, namely WSSM (Weather State-space Model), tailored specifically to the characteristics of the GSWF task. Specifically, to leverage the acquisition time and location that is highly correlated with the attributes of meteorological signals, we designed a Geographical encoding to introduce the geographical information such as acquisition time and location into feature encoding. Meanwhile, meteorological signals exhibit hierarchical characteristics, from macroscopic trends to microscopic fluctuations under different time resolutions. We have designed a shared encoder named Hierarchical Bi-Mamba encoder, which comprehensively extracts the coarse to fine features of hierarchical sequences in a multi-resolution bidirectional scanning manner. Finally, we highlight the frequency characteristics of meteorological signals and design a Time-frequency Bi-Mamba block as the basic unit of the encoder, to better model the changes from low to high frequency in hierarchical signals through a learnable frequency filtering. By incorporating domain-specific insights and adapting the state-space modeling framework to better capture the intricate temporal and spatial dependencies of weather dynamics, our approach aims to bridge the performance gap with Transformer-based methods while leveraging Mamba's strengths in efficiency and modeling continuous-time processes.\nThe primary contributions of this paper can be encapsulated as follows: 1) We propose a novel Mamba-based method WSSM for Global Station Weather Forecasting which integrates geographical information and hierarchical encoding to facilitate weather dynamics modeling and extreme weather event forecasts. 2) We design a geographical encoding to embed the acquisition time and location. A hierarchical Bi-Mamba encoder built with Time-frequency Bi-Mamba blocks is further proposed to integrate sequence features at multi-scale. 3) We compare the proposed method with various advanced methods on the Weather-5K [2] subset containing 100 stations. The results demonstrate that our method achieves state-of-the-art performance with particularly outstanding performance in extreme weather forecasts."}, {"title": "II. METHODOLOGY", "content": "To enhance the performance of the Mamba model on the task of station weather forecasting, we considered the geographical information relevance of meteorological signals and further designed the WSSM model based on the SSM structure from the perspective of multiscale in time and frequency. In the WSSM model, we put forward three innovation modules: a Geographical encoding, a hierarchical Mamba encoder, and a time-frequency Bi-Mamba block. The overall structure of the WSSM is shown in Fig. 1."}, {"title": "B. Geographical encoding", "content": "Most existing methods regard meteorological signals as sliced 1-D time series and ignore the real-world temporal-spatial environment in which these signals are generated, such as acquisition time or sensor location. However, such information is highly relevant to weather dynamics and cannot be reflected within a short observation window. To address this, we propose Geographical encoding, which allows the model to capture geographical-related patterns and increase the accuracy of the predictions.\nGeographical encoding includes time encoding and location encoding. As shown in Fig. 1 (a), for station location, we encode the normalized longitude, latitude, and elevation through 3 independent linear layers to obtain location embeddings $E_{lat}$, $E_{lon}$, and $E_{ele}$. For acquisition time, we encode the timestamps of year, month, day, and hour through 4 independent linear layers to obtain time embeddings $E_y$, $E_m$, $E_d$, and $E_h$. We perform Geographical encoding on the feature input to the encoder and decoder. The mathematical representation of this process is as follows:\n$GeoEnc(x) = Linear_{lat,y,...}(lat_x, year_x, ...),$\n$h = Embedding(x) + PosEnc(x) + GeoEnc(x),$\nwhere x is the input weather sequence, and h is the sequence feature input to the encoder and decoder. When encoding the features input to the decoder, future timestamps are used."}, {"title": "C. Hierarchical Bi-Mamba encoder", "content": "We designed a Hierarchical Bi-Mamba encoder to handle features of meteorological signals at multiple time resolutions. As shown in Fig. 1 (b), firstly, we perform hierarchical patch encoding on the input time series to obtain a set of micro-to-macro features, namely $[S_{N_0}, S_{N_1}, ..., S_{N_l}]$ where $N_i$ is the number of patches ($N_0 > N_1 > ... > N_l$). Then, we use the Bi-Mamba encoder to process them sequentially from $N_l$ to $N_0$, enabling the network to learn the patterns in meteorological variables from coarse to fine. Between two successive scales, we insert the average pooled previous features into the start and end positions of the current sequence, so that the encoder can explicitly utilize the global prior of the previous scale when processing the current one. Across all scales, we bilinearly sample the low-scale features to the highest scale as the final encoder output. The mathematical process between two scales can be expressed as follows:\n$S_{N_i} = Patchify(h, patchsize_i) \\in R^{M \\times N_i \\times d}$,\n$Z_{N_i} = Encoder(S_{N_i}) \\in R^{M \\times N_i \\times d}$,\n$hp_{N_i} = Average(z_{N_i}) \\in R^{M \\times 1 \\times d}$,\n$S_{N_{i-1}} = Patchify(h, patchsize_{i-1}) \\in R^{M \\times N_{i-1} \\times d}$,\n$S'_{N_{i-1}} = Concat[hp_{N_i}, S_{N_{i-1}}, hp_{N_i}] \\in R^{M \\times N_{i-1}+2 \\times d}$,\n$Z_{N_{i-1}} = Encoder(S'_{N_{i-1}})[1 : -1] \\in R^{M \\times N_{i-1} \\times d}$,\n$z = Upscale(z_{N_i}) + Upscale(z_{N_{i-1}}) \\in R^{M \\times N_0 \\times d}$,\nWhere $z_{N_i}$ is the feature at scale ni, $hp_{N_i}$ is the average pooled head patch of scale ni, z is the final encoded feature.\nThrough this process, we compress the multi-scale features into a single encoder, which improves the prediction accuracy."}, {"title": "D. Time-frequency Bi-Mamba block", "content": "Frequency information is more suitable for characterizing the periodicity and extremity that occur simultaneously in meteorological signals by low and high frequency components [13][14]. We designed a time-frequency Bi-Mamba block with the ability to extract features across the time domain, the frequency domain, and between multiple variables simultaneously as the basic unit of the Hierarchical Bi-Mamba encoder in II-C.\nAs shown in Fig. 1 (c), firstly, we expand the unidirectional Mamba into a bidirectional Mamba $BM(\u00b7)$ to enhance the feature extraction ability [12]. Then, we transform the fused time-domain features from the two Mamba blocks into the frequency domain. A learnable filter $F(\u00b7)$ is added to adaptively screen the important frequency components. After transforming the features back from the frequency domain to the time domain, we employed a simple interaction MLP $I(\u00b7)$ for the information interaction among multiple variables to explore the correlations among the variables. The mathematical process in the time-frequency Bi-Mamba block can be expressed as follows:\n$z_f, z_b = z, Flip(z) \\in R^{M \\times N \\times d}$,\n$z_{Tf}, z_{Tb} = BM(z_f, z_b)$,\n$z_T = z_T + Flip(z_{Tb})$,\n$z_F = iFFT(FFT(z_T) \\cdot FFT(F(Average(z_T)))),$\n$z_I = z_F \\cdot I(Average(z_F)) \\in R^{M \\times N \\times d}$,\nThrough this process, frequency is intensively incorporated into feature extraction, which enhances the model's ability to predict sudden changes."}, {"title": "III. EXPERIMENTS", "content": "We carried out experiments on the 100 meteorological stations subset of the WEATHER-5K dataset to substantiate the efficacy of our method. The entire WEATHER-5K dataset contains data on temperature, dewpoint temperature, wind speed, wind direction, and sea level pressure from 5,672 meteorological stations around the world, covering a period of 10 years with an hourly interval. We obtained the subset by randomly sampling from it.\nWe set the length of the observation to last 48 hours and predicted all 5 variables in 48, 72, and 120 hours. The train/val/test (2014-2021/2022/2023) are divided by time coverage with in total 7003.3k/866.5k/866.5k samples."}, {"title": "B. Evaluation Protocol and Metrics", "content": "To assess the performance, we utilized widely recognized evaluation metrics, including Mean Absolute Error (MAE), Mean Squared Error (MSE) for overall precision, and Symmetric Extremal Dependence Index (SEDI) for precision on abrupt change."}, {"title": "C. Implementation Details", "content": "Architecture Details: WSSM sets the dimension d = 128, and the block number K = 2. The hierarchical patching parameters (window, stride) are (16, 8), (8, 4), and (2, 1). The unidirectional SSM implementation refers to [11].\nTraining Details: WSSM employs MSEloss function for training. We utilize the AdamW optimizer with a learning rate of 0.0001 and a cosine annealing scheduler with a linear warmup to decay the learning rate. Our batch size is set to 1024, and the maximum iteration is 60000."}, {"title": "D. Comparison with the State-of-the-Art", "content": "We have compared the proposed WSSM with a series of state-of-the-art time series prediction methods, including FEDformer[5], iTransformer[6], Pyraformer[7], DLinear[8], and Mamba[10]. The comparative results on MAE and MSE are presented in Tab. I. As illustrated, the proposed WSSM achieved the optimal or suboptimal performance on > 77% evaluation metrics, surpassing the contemporary state-of-the-art method Pyraformer (69%). Moreover, our major advantage lies in the extreme weather forecast. In the comparison of SEDI shown in Table II, our method significantly outperforms all other methods by up to 90%(0.21 \u2192 2.81). For variables with more extreme conditions, such as wind direction and wind rate, our prediction has greater advantages in extreme situations but is suboptimal in accuracy. Further, methods that achieve high overall accuracy often underperform in extreme weather events, such as Pyraformer. Conversely, the opposite is true for iTransformer. This is caused by only fitting the low-frequency components and high-frequency variations. Our method can maintain state-of-the-art performance in overall prediction while gaining a significant advantage on SEDI, indicating that we can not only learn the low-frequency trends but also capture the high-frequency fluctuations, which aligns with our original intention of incorporating hierarchical encoding and frequency. The comprehensive results underscore the effectiveness of our improvements to the Mamba-based model for GSWF."}, {"title": "IV. CONCLUSION", "content": "In this paper, we improve the state-space model, enabling it to achieve state-of-the-art performance that surpasses Transformer-based methods in the global station weather forecasting task. Specifically, we have proposed a Geographical encoding, which incorporates real-world time and location information, allowing the model to understand the absolute spatio-temporal position of weather sequences. In addition, we have designed a Time-frequency Bi-Mamba block and further constructed a Hierarchical Bi-Mamba encoder to synthesize the time-frequency-multivariable features of multi-temporal resolution sequences through the hierarchical bidirectional scanning. Experimental results on the Weather-5K subset underscore the effectiveness of our proposed modules. The WSSM brings a great leap in high-accuracy extreme weather event prediction as well as achieves the best overall performance. This innovative approach paves the way for more accurate and efficient global station weather forecasting."}]}