{"title": "Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow", "authors": ["Behrooz Azarkhalili", "Maxwell Libbrecht"], "abstract": "This paper introduces Generalized Attention Flow (GAF), a novel feature attribution method for Transformer-based models to address the limitations of current approaches. By extending Attention Flow and replacing attention weights with the generalized Information Tensor, GAF integrates attention weights, their gradients, the maximum flow problem, and the barrier method to enhance the performance of feature attributions. The proposed method exhibits key theoretical properties and mitigates the shortcomings of prior techniques that rely solely on simple aggregation of attention weights. Our comprehensive benchmarking on sequence classification tasks demonstrates that a specific variant of GAF consistently outperforms state-of-the-art feature attribution methods in most evaluation settings, providing a more reliable interpretation of Transformer model outputs.", "sections": [{"title": "Introduction", "content": "Feature attribution methods are essential to develop interpretable machine and deep learning models. These methods assign a score to each input feature, quantifying its contribution to the model's output and thereby enhancing the understanding of model predictions.\nThe rise of Transformer models with self-attention mechanism has driven the need for feature attribution methods for interpreting these models (Vaswani et al., 2017; Bahdanau et al., 2016; Devlin et al., 2019; Sanh et al., 2020; Kobayashi et al., 2021). Initially, attention weights were considered potential feature attributions, but recent studies have questioned their effectiveness in explaining deep neural networks (Abnar and Zuidema, 2020; Jain and Wallace, 2019; Serrano and Smith, 2019). Consequently, various post hoc techniques have been developed to compute feature attributions in Transformer models.\nRecent advancements in XAI have introduced numerous gradient-based methods, including Grads and AttGrads (Barkan et al., 2021), which leverage saliency to interpret Transformer outputs. Qiang et al. (2022) proposed AttCAT, integrating features, their gradients, and attention weights to quantify input influence on model outputs. Yet, many of these techniques still focus primarily on the gradients of attention weights and inherit the limitations of earlier attention-based approaches.\nLayer-wise Relevance Propagation (LRP) (Bach et al., 2015; Voita et al., 2019) transfers relevance scores from output to input. Chefer et al. (2021b,a) proposed a comprehensive methodology enabling information propagation through all Transformer components. Yet, this approach relies on specific LRP rules, limiting its applicability across various Transformer architectures.\nMany existing methods to evaluate feature attributions in Transformers fail to capture pairwise interactions among features. This limitation arises from the independent computation of importance scores, which neglects feature interactions. For example, when calculating gradients of attention weights, they propagate directly from the output to the individual input feature, ignoring interactions. Additionally, many methods applied to compute feature attributions in Transformers violate pivotal axioms such as symmetry, sensitivity, efficiency, and linearity (Shapley, 1952; Sundararajan et al., 2017; Sundararajan and Najmi, 2020) (Sec. 3.5).\nAbnar and Zuidema (2020) recently introduced Attention Flow to overcome these limitations in XAI methods. Attention Flow considers attention weights as capacities in a maximum flow problem and compute feature attributions using its solution. This approach naturally captures the influence of attention mechanisms, as the paths of high attention through a network correspond to the flow of information from features to outputs. Applicable to any encoder-only Transformer, Attention Flow has demonstrated strong potential to improve model interpretability (Abnar and Zuidema, 2020; Modarressi et al., 2023; Kobayashi et al., 2020, 2021).\nSubsequently, Ethayarajh and Jurafsky (2021) attempted to bridge attention flows and XAI by leveraging Shapley values (Shapley, 1952, 2016). While their goal was to demonstrate that Attention Flows can be interpreted as Shapley values under specific conditions, they overlooked the issue of non-uniqueness in such flows (Sec. 3.3).\nOur contributions. In this work, we propose Generalized Attention Flow (GAF), a method that not only satisfies crucial theoretical properties but also demonstrates improved empirical performance. The primary contributions of our work are:\n1. We proposed Generalized Attention Flow, which generates feature attributions by utilizing the log barrier method to solve a regularized maximum flow problem within a capacity network derived from functions applied to attention weights. Rather than defining capacities solely based on attention weights, we will introduce alternatives using the gradients of these weights (GF) or the product of attention weights and their gradients (AGF).\n2. We address the non-uniqueness issue in Attention Flow, which previously undermined some of its proposed theoretical properties (Ethayarajh and Jurafsky, 2021), and demonstrate that non-unique solutions are frequent in practice. To resolve this, we introduce barrier regularization, proving that feature attributions obtained from the regularized maximum flow problem are Shapley values and satisfy the axioms of efficiency, symmetry, nullity, and linearity (Shapley, 1952, 2016; Young, 1985; Chen et al., 2023b).\n3. We conduct extensive benchmarking of the proposed attribution methods based on Generalized Attention Flow, comparing them against various state-of-the-art attribution techniques. Our results show that a specific variant of the proposed method outperforms previous methods for classification tasks across most evaluation scenarios, as measured by AOPC (Barkan et al., 2021; Nguyen, 2018; Chen et al., 2020), LOdds (Chen et al., 2020; Shrikumar et al., 2018), and classification metrics.\n4. We have developed an open-source Python package to compute feature attributions leveraging Generalized Attention Flow. This package is highly flexible, and can compute the feature attributions of any encoder-only Transformer model available in the Hugging Face Transformers package (Wolf et al., 2020). Moreover, our methods are easily adaptable for a variety of NLP tasks."}, {"title": "Preliminaries", "content": ""}, {"title": "Multi-Head Attention Mechanism", "content": "Given the input sequence $X \\in \\mathbb{R}^{t\\times d}$, where $d$ is the dimensionality of the model's input vectors and $t$ is the number of tokens, the multi-head self-attention mechanism computes attention weights for each element in the sequence employing the following steps:\n\u2022 Linear Transformation:\n$Q_i = XW_i^Q, K_i = XW_i^K, V_i = XW_i^V$ (1)\nHere $Q_i, K_i\\in \\mathbb{R}^{t\\times d_k}$ and $V_i \\in \\mathbb{R}^{t\\times d_v}$, where $d_k$ and $d_v$ represent the dimensionality of the key vector and value vector respectively, and $i$ represents the index of the attention head.\n\u2022 Scaled Dot-Product Attention:\n$A^*(Q_i, K_i, V_i) = A_iV_i$ (2)\nwhere the matrix of attention weights $A_i\\in \\mathbb{R}^{t\\times t}$ is defined as:\n$A_i = \\text{softmax}(\\frac{Q_iK_i^\\top}{\\sqrt{d_k}})$ (3)\n\u2022 Concatenation and Linear Projection:\n$\\text{MultiHead}(X) = \\text{Concat}(A_1, ..., A_h)W^O$ (4)\nwhere the matrix $\\text{MultiHead}(X)\\in \\mathbb{R}^{t\\times d}$ and the matrix $W^O\\in \\mathbb{R}^{h\\cdot d\\times d}$.\nFor a Transformer with $l$ attention layers, the attention weights at each layer can be defined as multi-head attention weights:\n$\\hat{A} = \\text{Concat}(A_1, A_2,..., A_h) \\in \\mathbb{R}^{h\\times t\\times t}$ (5)\nExtending this to a Transformer architecture itself, the Transformer attention weights $A$ can be defined as:\n$A = \\text{Concat}(\\hat{A}_1, \\hat{A}_2, ..., \\hat{A}_l) \\in \\mathbb{R}^{l\\times h\\times t\\times t}$ (6)\nwhere $A_j \\in \\mathbb{R}^{h\\times t\\times t}$ is the multi-head attention weight for the $j$-th attention layer."}, {"title": "Minimum-Cost Circulation & Maximum Flow Problem", "content": "Definition 2.1 (Minimum Cost Circulation).\nGiven a network $G = (V, E, u, l, c)$ with $|V| = n$ vertices and $|E| = m$ edges, where $c_{ij}$ is the cost, $l_{i,j}$ and $u_{i,j}$ are respectively the lower and upper capacities (or demands) for the edge $(i, j) \\in E$, a circulation is a function $f : E \\rightarrow \\mathbb{R}_{\\geq 0}$ s.t.\n$l_{ij} \\leq f_{ij} \\leq u_{ij}, \\quad \\forall (i, j) \\in E \\\\\n\\sum_{j:(i,j)\\in E}f_{ij} - \\sum_{j:(j,i)\\in E} f_{ji} = 0, \\quad \\forall i \\in V.$ (7)\nThe min-cost circulation problem is to compute the circulation $f$ minimizing the cost function $\\sum_{(i,j)\\in E} C_{ij} f_{ij}$\nThe minimum-cost circulation problem can be algebraically written as the following primal-dual linear programming (LP) problem (Van Den Brand et al., 2021; Chen et al., 2023a):\n(Primal) $\\underset{\\substack{Bf=0 \\\\ l \\le f \\le u}}{\\text{arg min }} c^\\top f \\quad i.e. \\quad \\underset{\\substack{Bf=0 \\\\ l \\le f \\le u \\le \\tilde{u}}}{\\text{arg min }} c^\\top f$,\n(Dual) $\\underset{B^\\top y + s=c}{\\text{arg max }} \\sum_i \\min \\left(l_i s_i, u_i s_i\\right)$ (8)\nwhere $B_{m\\times n}$ is the edge-vertex incidence matrix. For a directed graph, the entries of the matrix $B$ are defined as follows:\n$B_{ev} = \\begin{cases}-1, & \\text{if vertex $v$ is the tail of edge $e$,} \\\\ 1, & \\text{if vertex $v$ is the head of edge $e$,} \\\\ 0, & \\text{if edge $v$ is not incident to vertex $e$.}\\end{cases}$\nRemark 2.1. The maximum flow problem can be considered as a specific minimum-cost circulation problem. Here, $B$ is the edge-vertex incidence matrix of the input graph after we added to it an edge $e(t, s)$ that connects the target $t$ to the source $s$ and its lower capacity $l_{t,s}$ be 0 and its upper capacity $u_{t,s}$ be $||u||_1$. Also, the cost vector $c$ is a vector in which $C_{t,s} = -1$ and $c_e = 0$ for all other edges $e \\in E$ (Cormen et al., 2009)."}, {"title": "Barrier Methods for Constrained Optimization", "content": "Consider the following optimization problem:\n$f^* = \\underset{\\substack{a(f)=0 \\\\ \\beta(f)\\leq 0}}{\\text{arg min }} \\xi(f)$ (9)\nwhere $h$ represents a convex inequality constraint, $g$ represents an affine equality constraint, and $f^*$ denote the optimal solution.\nThe interior of the constraint region is defined as $S = {f | a(f) = 0, \\beta(f) < 0}$. Assuming the region $S$ is nonempty and convex, we introduce the barrier function $\\psi(f)$ on $S$ that is continuous and approaches infinity as $f$ approaches to the boundary of the region, specifically $\\lim_{\\beta(f)\\rightarrow 0^-} \\psi(f) = \\infty$. One common example of barrier functions is the log barrier function, which is represented as $\\log(-\\beta(f))$.\nGiven a barrier function $\\psi(f)$, we can define a new objective function $\\xi(f)+\\mu\\psi(f)$, where $\\mu$ is a positive real number, which enables us to eliminate the inequality constraints in the original problem and obtain the following problem:\n$f^*_{\\mu} = \\underset{a(f)=0}{\\text{arg min }} \\xi(f) + \\mu\\psi(f)$ (10)\nTheorem 2.1. For any strictly convex barrier function $\\psi(f)$, convex function $\\xi(f)$, and $\\mu > 0$, there exists a unique optimal point $f^*_{\\mu}$. Furthermore, $\\lim_{\\mu\\rightarrow 0} f^*_{\\mu} = f^*$, indicating that for any arbitrary $\\epsilon > 0$, we can select a sufficiently small $\\mu > 0$ such that $||f^*_{\\mu} - f^*|| < \\epsilon$ (van den Brand et al., 2023)."}, {"title": "Methods", "content": ""}, {"title": "Information Tensor", "content": "In Transformer models, information propagation occurs through pathways facilitated by the attention mechanism. These pathways can be conceptualized as routes within a graph structure, where tokens are represented by nodes and computations are denoted by edges. The capacities of these edges correspond to meaningful computational quantities that reflect the flow of information through the neural network (Ferrando and Voita, 2024; Mueller, 2024).\nFirst, attention weights can represent the flow of information through the neural network during the feed-forward phase of training, quantifying the importance of different input parts in generating the output (Abnar and Zuidema, 2020; Ferrando and Voita, 2024). Additionally, the gradient of attention weights captures the flow of information during back-propagation, quantifying how changes in the output influence the attention weights throughout the network during training (Barkan et al., 2021). Therefore, a combined view of attention weights"}, {"title": "Generalized Attention Flow", "content": "and their gradients can simultaneously represent information circulation during both feed-forward and back-propagation, offering a comprehensive perspective on the network's information dynamics (Barkan et al., 2021; Qiang et al., 2022; Chefer et al., 2021b,a).\nOur Generalized Attention Flow generlize this foundation by leveraging an information tensor, $\\bar{A} \\in \\mathbb{R}^{l\\times t\\times t}$, to aggregate Transformer attention weights $A$, as defined in eq. 6. Based on the above insights, we present three aggregation functions to define information tensors (Barkan et al., 2021; Chefer et al., 2021b).\n1. Attention Flow (AF):\n$A := \\mathbb{E}_h(A)$\n2. Attention Grad Flow (GF):\n$A := \\mathbb{E}_h([\\nabla_A \\bar{y}]_+)$\n3. Attention \u00d7 Attention Grad Flow (AGF):\n$A := \\mathbb{E}_h([A\\nabla_A \\bar{y}]_+)$\nHere, $[x]_+ = \\text{max}(x,0)$, $\\nabla_A \\bar{y}$ represents the Hadamard product, $\\nabla_A := \\frac{\\partial y_t}{\\partial A}$ where $y_t$ is the model's scalar output, and $\\mathbb{E}_h$ denotes the mean across attention heads.\nIn Generalized Attention Flow, we use the attention mechanism for feature attribution by developing a network flow representation of a Transformer or other attention-based model. We will assign capacities to the edges of this graph corresponding to information tensor defined in Sec. 3.1. We then solve the maximum flow problem to compute the optimal flow passing through any output node (or, more generally, any node in any layer) to any input node. The flow traversing through an input node (token) indicates the importance or attribution of that particular node (token).\nTo determine the maximum flow from all output nodes to all input nodes, we leverage the concept of multi-commodity flow (App. A.2 and App. B). This involves the introduction of a super-source node $s_s$ and a super-target node $s_t$ with a large capacity $u_{\\infty}$. The connectivity between layers and capacities between nodes are established using the information tensors, effectively forming a layered graph (App. B).\nTo formalize the generating of the information flow, consider a Transformer with $l$ attention layers, an input sequence $X \\in \\mathbb{R}^{t\\times d}$, and its information tensor $\\bar{A}\\in \\mathbb{R}^{l\\times t\\times t}$. Using the information tensor $\\bar{A}$, we can construct the layered attribution graph $G$ with its adjacency matrix $A$, its edge-vertex incidence matrix $B$, lower capacity matrix $l$ and its integral version $\\tilde{l}$, upper capacity matrix $u$ and its integral version $\\tilde{u}$ employing either Algorithm 1 or Algorithm 2. Afterward, we will substitute the obtained matrices into the primal form of eq. 8 to compute the desired optimal flow.\nTo clarify Algorithm 1 and Algorithm 2 further, we detail the process of constructing the layered attribution graph $G$, which has an adjacency matrix of shape $(2 + t \\times (l + 1), 2 + t \\times (l + 1))$, serving as the input for the maximum flow problem. Nodes at layer $l \\in {1,...,l}$ and token $i \\in {1,...,t}$ are designated as $v_{\\ell, i}$. The following guidelines outline the process to define the upper and lower bound capacities:\n\u2022 To connect nodes $v_{1,i}$ to the super-target node $v_{st}$, we define $u[0, i] = u_{\\infty}$ for $1 < i < t$.\n\u2022 The upper-bound capacity from node $v_{\\ell+1,i}$ to node $v_{\\ell,j}$ is defined as $u[I_{i,\\ell+1}, I_{j,\\ell}] = A_{\\ell, i, j}$ for $\\ell\\in {1,...,l}$, $i \\in {1, ...,t}$, and $j\\in {1,...,t}$, where $I_{i,\\ell+1} = i + t * l$ and $I_{j,\\ell} = j + t * (l - 1)$.\n\u2022 To connect the super-source node $v_{ss}$ to nodes $v_{\\ell+1,i}$, we define $u[i + t * l, 1 + t * (l + 1)] = u_{\\infty}$ for $1 < i < t$.\n\u2022 The lower-bound capacity is defined as $l = 0$."}, {"title": "Non-uniqueness of Maximum Flow", "content": "The maximum flow problem lacks strict convexity, meaning it does not necessarily yield the unique optimal solution. We found that the maximum flow problem associated with the graphs constructed employing Generalized Attention Flow also fails to yield the unique optimal flow (App. C)."}, {"title": "Log Barrier Regularization of Maximum Flow", "content": "To address the non-uniqueness challenge in the maximum flow problem, we reformulate the minimum-cost circulation problem as follows:\n$\\underset{\\substack{Bf=0 \\\\ \\beta(f)\\leq 0}}{\\text{arg min }} c^\\top f$ (11)"}, {"title": "Axioms of Feature Attributions", "content": "In XAI, axioms are core principles that guide the evaluation of explanation methods, ensuring their reliability, interpretability, and fairness. These axioms provide standards to measure the effectiveness and compliance of explanation techniques. Our proposed methods meet four essential axioms, as proved by the following theorem and corollaries."}, {"title": "Shapley values", "content": "Definition 3.1 (Shapley values). For any value function $\\vartheta : 2^N \\rightarrow \\mathbb{R}$ where $N = {1, 2, ..., n}$, Shapley values $\\phi(\\vartheta) \\in \\mathbb{R}^n$ can be computed by averaging the marginal contribution of each feature over all possible feature combinations:\n$\\phi_i(\\vartheta) = \\sum_{S \\subseteq N \\setminus {i}} \\frac{|S|!(n-|S|-1)!}{n!} (\\vartheta(S \\cup {i}) - \\vartheta(S))$ (14)\nShapley values are the unique feature attributions that satisfy four fairness-based axioms: efficiency (completeness), symmetry, linearity (additivity), and nullity (Shapley, 1952, 2016; Young, 1985) (App. A.3). Initially, a value function based on model accuracy was proposed (Lundberg and Lee, 2017), but since then, various alternative payoff functions have been introduced (Jethani et al., 2022; Sundararajan and Najmi, 2020), each providing distinct feature importance scores.\nTheorem 3.1 (Log Barrier Regularization of Generalized Attention Flow Outcomes Shapley Values). Given a layered attribution graph $G(A, u, l, c, s_s, s_t)$ which has been defined using either of Algorithm 1 or Algorithm 2, let $V$ be the set of all nodes in $G$, and $N \\subset V$ such that all nodes in $N$ are chosen from the same layer. Now, suppose $f^*$ is the optimal unique solution of eq. 12, and for every $S \\subset N$, define the payoff function $\\vartheta(S) := |f^*(S)| = \\sum_{i \\in S}|f_{out}(i)|$ where $|f_{out}(i)|$ is the total outflow value of a node $i$. Then, it can be proven that for each node $i \\in N$, $\\phi_i(\\vartheta) = |f_{out}(i)|$ represents the Shapley value (Proof in App. E).\nCorollary 3.2. Theorem 3.1 implies that the feature attributions obtained by eq. 12 are Shapley values and, consequently, satisfy the axioms of efficiency, symmetry, nullity, and linearity."}, {"title": "Experiments", "content": "In this section, we comprehensively evaluate the effectiveness of our methods for NLP sequence classification. While our approach is versatile and applicable to various NLP tasks, including question answering and named entity recognition, which use encoder-only Transformer architectures, this assessment focuses only on sequence classification."}, {"title": "Transformer Models", "content": "In our evaluations, we use a specific pre-trained model from the HuggingFace Hub (Wolf et al., 2020) for each dataset and compare our explanation methods against others to assess their performance (App. F.1)."}, {"title": "Datasets", "content": "Our method's assessment encompasses sequence classification spanning binary classification tasks on datasets including SST2 (Socher et al., 2013), Amazon Polarity (McAuley and Leskovec, 2013), Yelp Polarity (Zhang et al., 2016), and IMDB (Maas et al., 2011), alongside multi-class classification on the AG News dataset (Zhang et al., 2015). To minimize computational overhead, we conduct the experiments using a subset of 5,000 randomly selected samples from the Amazon, Yelp, and IMDB datasets, while utilizing the full test sets for the other datasets (App. F.1)."}, {"title": "Benchmark Methods", "content": "Our experiments compare the methods introduced in Sec. 3.1 with several well-known explanation methods tailored for Transformer models. To evaluate attention-based methods such as RawAtt and Rollout (Abnar and Zuidema, 2020), attention gradient-based methods like Grads, AttGrads (Barkan et al., 2021), CAT, and AttCAT (Qiang et al., 2022), as well as LRP-based methods such as PartialLRP (Voita et al., 2019) and TransAtt (Chefer et al., 2021b), we adapted the repository developed by Qiang et al. (2022). Moreover, we implemented classical attribution methods such as Integrated Gradient (Sundararajan et al., 2017), KernelShap (Lundberg and Lee, 2017), and LIME (Ribeiro et al., 2016) using the Captum package (Kokhlikyan et al., 2020)."}, {"title": "Evaluation Metric", "content": "AOPC: One of the important evaluation metrics employed is the Area Over the Perturbation Curve (AOPC), a measure that quantifies the impact of masking top k% tokens on the average change in prediction probability across all test examples. The AOPC is calculated as follows:\n$\\text{AOPC}(k) = \\frac{1}{N} \\sum_{i=1}^N p(\\hat{y}|x_i) - p(\\hat{y}|x_i^{k\\%})$ (15)\nwhere N is the number of examples, $\\hat{y}$ is the predicted label, $p(\\hat{y}|\\cdot)$ is the probability on the predicted label, and $x_i^{k\\%}$ is defined by masking the k% top-scored tokens from $x_i$. To avoid arbitrary choices for k, we systematically mask 10%, 20%,..., 90% of the tokens in decreasing saliency order, resulting in $x_i^{10\\%}, x_i^{20\\%},...,x_i^{90\\%}$.\nLOdds: Log-odds score is derived by averaging the difference of negative logarithmic probabilities on the predicted label over all test examples before and after masking k% top-scored tokens.\n$\\text{LOdds}(k) = \\frac{1}{N} \\sum_{i=1}^N \\log \\frac{p(\\hat{y}|x_i^{k\\%})}{p(x_i)}$ (16)"}, {"title": "Results", "content": "We assessed various explanation methods by masking the top k% of tokens across multiple datasets and measuring their AOPC and LOdds scores. Tab. 1 presents the average scores for different k values, proving that the AGF method consistently outperforms others by achieving the highest AOPC and lowest LOdds scores, effectively identifying and masking the most important tokens for model predictions. Additionally, the GF method surpasses most baseline approaches. Evaluations based on classification metrics further confirm these findings. (App. D.1, App. D.2).\nAdditionally, we assessed the aforementioned explanation methods by masking the bottom k% of tokens across datasets and measuring AOPC and LOdds scores, detailed in Tab. 2. The AGF method achieved the highest LOdds and lowest AOPC across most datasets, highlighting its ability to pinpoint important tokens for model predictions, with the GF method also surpassing many baseline methods in this context.\nIn contrast, the Yelp dataset presents a unique challenge, as our methods do not perform optimally in terms of AOPC and LOdds metrics. This is likely due to the prevalence of conversational language, slang, and typos in Yelp reviews, which adversely"}, {"title": "Conclusion", "content": "In this study, we propose Generalized Attention Flow, an extension of Attention Flow. The core idea behind Generalized Attention Flow is applying the log barrier method to the maximum flow problem, defined by information tensors, to derive feature attributions. By leveraging the log barrier method, we resolve the non-uniqueness issue in optimal flows originating from the maximum flow problem, ensuring that our feature attributions are Shapley values and satisfy efficiency, symmetry, nullity, and linearity axioms.\nOur experiments across various datasets indicate that our proposed AGF (and GF) method generally outperforms other feature attribution methods in most evaluation scenarios. It could be valuable for future research to explore whether alternative definitions of the information tensor could enhance AGF's effectiveness."}, {"title": "Limitations", "content": "The primary limitation of our proposed method is the increased running time of the optimization problem in eq. 12 as the number of tokens grows (Lee and Sidford, 2020; van den Brand et al., 2021). Moreover, it's important to note that optimization problems generally cannot be solved in parallel.\nAlthough recent theoretical advancements have developed almost-linear time algorithms to solve the optimization problem described in eq. 12 (Tab. 7), their computational cost is still significant, particularly when we have long input sequences. Nevertheless, we found that the practical runtime of our method is comparable to other XAI methods (Tab. 8)."}, {"title": "Preliminaries", "content": ""}, {"title": "Maximum Flow", "content": "Definition A.1 (Network Flow). Given a network $G = (V, E, s, t, u)$, where s and t are the source and target nodes respectively and $u_{ij}$ is the capacity for the edge $(i, j) \\in E$, a flow is characterized as a function $f: E\\rightarrow \\mathbb{R}_{\\geq 0}$ s.t.\n$f_{ij} \\leq u_{ij} \\quad \\forall (i, j) \\in E \\\\\n\\sum_{j:(i,j)\\in E}f_{ij} - \\sum_{j:(j,i)\\in E} f_{ji} = 0, \\quad \\forall i \\in V, i \\neq s,t$ (17)\nWe define $| f_{out}(i)|$ to be the total outflow value of a node $i$ and $| f_{in}(i)|$ to be the total inflow value of a node $i$. For a given set $K \\subset V$ of nodes, we define $|f(K)| = \\sum_{i\\in K}|f_{out}(i)|$ for every flow $f$. The value of a flow in a given network $G = (V, E, s, t, u)$ is denoted as $|f| = \\sum_{v:(s,v)} f_{sv} - \\sum_{v:(v,s)} f_{vs} = | f_{out}(s)| - | f_{in}(s)|$, and a maximum flow is identified as a feasible flow with the highest attainable value ."}, {"title": "Multi-Commodity Maximum Flow", "content": "The multi-commodity maximum flow problem aims to generalize the maximum flow problem by considering multiple source-sink pairs instead of a single pair. The objective of this new problem is to determine multiple optimal flows, $f_1(\\cdot, \\cdot), ..., f'(\\cdot, \\cdot)$, where each $f^k(\\cdot, \\cdot)$ represents a feasible flow from source $s_k$ to sink $t_k$.\n$\\sum_{k=1}f^k(i, j) \\leq u(i, j) \\quad \\forall (i, j)\\in E$ (18)\nTherefore, the multi-commodity maximum flow problem aims to maximize the objective function $\\sum_{k=1} \\sum_{v:(v,s_k)} f_k(s_k, v)$.\nTo solve the multi-commodity maximum flow problem, we can easily transform it into a standard maximum flow problem. This can be achieved by introducing two new nodes, a \"super-source\" node $s_s$ and a \"super-target\" node $s_t$. The \"super-source\" node $s_s$ should be connected to all the original sources $s_i$ through edges with finite capacities, while the \"super-target\" node $s_t$ should be connected to all the original sinks $t_i$ through edges with finite capacities:\n\u2022 Each outgoing edge from the \"super-source\" node $s_s$ to each source node $s_i$ is assigned a capacity that is equal to the total capacity of the outgoing edges from the source node $s_i$."}, {"title": "Shapley values", "content": "\u2022 Each incoming edge from an original \"super-target\" node $s_t$ to each sink node $t_i$ is assigned a capacity that is equal to the total capacity of the incoming edges to the sink node $t_i$.\nIt is easy to demonstrate that the maximum flow from $s_s$ to $s_t$ is equivalent to the maximum sum of flows in a feasible multi-commodity flow within the original network."}, {"title": "Shapley values", "content": "The Shapley value", "vartheta": 2, "1985)": "nEfficiency: The Shapley values must add up to the total value of the game", "vartheta(N)$.\nSymmetry": "If two players are equal in their contributions to any coalition", "Dummy)": "If a player has no impact on any coalition", "0$.\nLinearity": "If the game $\\vartheta(\\cdot)$ is a linear combination of two games $\\vartheta_1(\\cdot), \\vartheta_2(\\cdot)$ for all $S \\subseteq N$, i.e. $\\vartheta(S) = \\vartheta_1(S) + \\vartheta_2(S)$ and $(c \\cdot \\vartheta)(S) = c \\cdot \\vartheta(S), \\forall c\\in \\mathbb{R}$, then the Shapley value in the game $\\vartheta$ is also a linear combination of that in the games $\\vartheta_1$ and $\\vartheta_2$, i.e. $\\forall i \\in N, \\phi_i(\\vartheta_1) = \\phi_i(\\vartheta_1) + \\"}]}