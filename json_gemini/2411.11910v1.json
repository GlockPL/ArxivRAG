{"title": "AIGS: GENERATING SCIENCE FROM AI-POWERED AUTOMATED FALSIFICATION", "authors": ["Zijun Liu", "Kaiming Liu", "Yiqi Zhu", "Xuanyu Lei", "Zonghan Yang", "Zhenhe Zhang", "Peng Li", "Yang Liu"], "abstract": "Rapid development of artificial intelligence has drastically accelerated the development of scientific discovery. Trained with large-scale observation data, deep neural networks extract the underlying patterns in an end-to-end manner and assist human researchers with highly-precised predictions in unseen scenarios. The recent rise of Large Language Models (LLMs) and the empowered autonomous agents enable scientists to gain help through interaction in different stages of their research, including but not limited to literature review, research ideation, idea implementation, and academic writing. However, AI researchers instantiated by foundation model empowered agents with full-process autonomy are still in their infancy. In this paper, we study AI-Generated Science (AIGS), where agents independently and autonomously complete the entire research process and discover scientific laws. By revisiting the definition of scientific research (Popper, 1935), we argue that falsification is the essence of both human research process and the design of an AIGS system. Through the lens of falsification, prior systems attempting towards AI-Generated Science either lack the part in their design, or rely heavily on existing verification engines that narrow the use in specialized domains. In this work, we propose BABY-AIGS as a baby-step demonstration of a full-process AIGS system, which is a multi-agent system with agents in roles representing key research process. By introducing FALSIFICATIONAGENT, which identify and then verify possible scientific discoveries, we empower the system with explicit falsification. Experiments on three tasks preliminarily show that BABY-AIGS could produce meaningful scientific discoveries, though not on par with experienced human researchers. Finally, we discuss on the limitations of current BABY-AIGS, actionable insights, and related ethical issues in detail.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep learning has revolutionized scientific research (LeCun et al., 2015; Vaswani et al., 2017; Jumper et al., 2021; Achiam et al., 2023). Leveraging the enormous amount of experimental data, deep learning methods extract the underlying patterns in an end-to-end manner and effectively generalize to unobserved scenarios. The breakthroughs from deep learning in scientific domains, such as protein structure prediction (Jumper et al., 2021), gravitational wave detection (George & Huerta, 2018), and plasma control (Degrave et al., 2022), have received award-winning recognition. As a result, AI for Science has emerged as a highly-regarded research field (Wang et al., 2023a).\nIn the paradigm of AI for Science, AI primarily serves as a tool to assist researchers in making discoveries. With the rapid development of foundation models and autonomous agents (Park et al., 2023), AI techniques nowadays boast the capabilities of general-purposed textual understanding and autonomous interaction with the external world. These capabilities lead to the successful applications of AI-as-research-assistants, ranging from single-cell analysis (Hou & Ji, 2024) to drug discovery (Wang et al., 2023b). The capability of providing research assistance leads to a more ambitious challenge: Can foundation model-powered agents be autonomous researchers, independently completing the entire process of scientific discovery, thereby transforming AI for Science into AI-Generated Science (AIGS)?\nWhen constructing an AIGS system with full-process autonomy, the desiderata of the system design should refer to the definition of the scientific research process itself. As stated by Popper (1935), scientific research follows a systematic process of proposing novel hypotheses, conducting experiments through trial and error, and falsifying these hypotheses to conclude. While it is widely-believed that creativity is indispensable in the process of research - which is also accounted in previous work (Si et al., 2024) - the central component of scientific research is falsification: designing and executing experiments to validate or refute hypotheses, and falsified hypotheses pose positive contributions to scientific progress as well\u00b2. Moreover, experienced researchers accumulate practical skills or reusable workflows (Gil et al., 2007) from hands-on experimentation, which eases the design and execution of experiments and hypothesis falsification. The abstraction of workflows in experiments enables effective reuse, which reflects a high level of executability in scientific research. To recapitulate, a creative idea is the beginning of a piece of scientific research, which is followed by experiments and analyses to be conducted; executability forms the basis for falsification, and a sequence of logically consistent falsification processes turns a novel idea into scientific discoveries with genuine creativity. As a result, falsification is the foundation of AI-Generated Science, pillared by experimenting scaffolds accounting for executability and targeting at the ultimate goal of research creativity.\nSeveral preliminary works have been proposed to explore the potential of AIGS, which can be roughly divided into three lines. In the first line, researchers evaluate and improve the capability of LLMs to generate research ideas with high creativity (Si et al., 2024; Hu et al., 2024b). The second line emphasizes the executability of research experiments, e.g., benchmarks like MLA-gentBench (Liu et al., 2023) and MLE-Bench (Chan et al., 2024) aim to evaluate the agentic ability of LLMs to achieve high performance on the provided benchmarks via code generation. These two lines of research investigate distinct sub-stages in the research process, failing to address the full-process autonomy. The third line of research attempts to construct end-to-end AIGS systems that cover both creativity and executability. MLR-copilot (Li et al., 2024b) takes existing research papers as input, and produces execution results by both generating ideas and implementing experiments. AI Scientist (Lu et al., 2024) further claims to be able to organize the generated ideas and experimental results into research papers as the output. This line of research arouses significant excitement in the community, but is feedbacked with controversy: Criticisms include the incremental nature of the generated knowledge \"tweaks\u201d, as well as the poor quality of the generated code and the paper presentation\u00b3. Indeed, as further benchmarked by Discovery World (Jansen et al., 2024) and ScienceAgentBench (Chen et al., 2024d), an automatic AIGS system that produces novel research in an end-to-end manner is still in the early stages, with significant gaps remains underexplored, especially in the area of autonomous falsification. Furthermore, while specialized systems like AlphaGeometry (Trinh et al., 2024) have achieved striking domain-specific performances, they rely heavily on the existing verification engines, which alleviate the need of autonomous falsification by AI itself."}, {"title": "2 THE DEVELOPMENT OF AI-ACCELERATED SCIENTIFIC DISCOVERY", "content": "In this section, we review and envision the development of AI-accelerated scientific discovery as four paradigms (Figure 2): (I) AI as a Performance Optimizer, where deep neural networks are trained with large-scale observation data in a specific scientific problem to extract the patterns in an end-to-end manner. In this paradigm, the AI techniques are used to optimize the specific prediction / regression performance in the pre-defined scientific problem with the consideration of out-of-domain generalization. (II) AI as a Research Assistant, where LLM-driven research copilots are used to assist the human research process. The synergy between Paradigm (I) and (II) forms the AI-powered acceleration of scientific discovery nowadays. (III) AI as an Automated Scientist. In this regime, foundation model empowered agents with scientist-like behavior should complete the entire research process, ranging from the initial idea proposal to the ultimate delivery of the scientific findings. (IV) AI Forms a Research Community. Upon the prosperity of fully-autonomous AI researchers depicted in the previous stage, we envision the collaborations among the agentic researchers foster an AI-formed research community."}, {"title": "2.1 AI AS A PERFORMANCE OPTIMIZER: DISCOVERIES IN SPECIFIC TASKS", "content": "With the rise of deep learning, AI has significantly impacted scientific discoveries across various fields, particularly in optimizing specific tasks by exploring well-defined search spaces or extracting patterns from piles of data. Utilizing specialized deep learning models, scientific break-"}, {"title": "2.2 AI AS A RESEARCH ASSISTANT: CO-PILOT IN HUMAN-AI COLLABORATION", "content": "Equipped with expanding scientific knowledge and generative capabilities, LLMs gradually exhibit great potential to assist researchers at various stages of the research process.\nLiterature review is a fundamental but tedious step for scientific research, highlighting the need for autonomous agents for this task. Advanced LLMs are employed to identify relevant literature for a given research topic and generate structured summaries (Haman & \u0160koln\u00edk, 2024; Huang & Tan, 2023). For instance, Sharma et al. (2021) introduces a retrieval-augmented framework to produce reliable summaries based on latest studies. Furthermore, Hsu et al. (2024) utilizes LLMs to organize scientific studies within hierarchical structures and Li et al. (2024d) develops an agentic pipeline that produces comparative literature summaries guided by human workflows. In summary, LLM-based agents have demonstrated the capability to produce readable and detailed literature reviews.\nFor research ideation, LLMs are employed to generate reasonable hypotheses (Wang et al., 2024a; Qi et al., 2023; Zhou et al., 2024) based on internal knowledge and supplementary inputs. To compare the quality of LLM-generated ideas with human experts, a large-scale human study (Si et al., 2024) finds that LLMs can generate research ideas of higher novelty but slightly weaker feasibility. Furthermore, Kumar et al. (2024) and Girotra et al. (2023) evaluate the idea generation capabilities of different LLMs and recognize their potential to serve as the sources of inspiration. To enhance LLM-driven ideation, Baek et al. (2024), Nigam et al. (2024a) and Nigam et al. (2024b) develop multi-agent ideation frameworks based on scientific literature, generating novel research proposals to accelerate the life-cycle of research process. Despite these advancements, generating ideas that balance both novelty and feasibility remains a significant challenge for LLM-based agents (Si et al., 2024). To evolve initial proposals into validated knowledge therefore demands substantial effort.\nThe attempts in AI-assisted idea implementation and auto-experimentation are usually conducted as repo-level coding tasks, given the growing coding capabilities of LLMs. Focused on research-related repo-level coding, Jimenez et al. (2024), Liu et al. (2023) and Chan et al. (2024) present challenging coding benchmarks targeting machine learning and software engineering tasks. Meanwhile, Yang et al. (2024a), Wang et al. (2024b) and Tao et al. (2024) leverage agentic collaboration to automated coding from language instructions, offering promising avenues to reduce researchers' coding workloads and enhance efficiency. However, the vision for agents to autonomously implement novel ideas and conduct experiments end-to-end imposes significantly higher demands on coding agents. Current challenges include a relatively low success rate Lu et al. (2024) and frequent misalignment between proposed ideas and their coding implementations, highlighting the need for improvements in both execution reliability and alignment with research objectives.\nIn the realm of academic writing, LLMs can be utilized for drafting structured outlines, refining human-written texts and presenting research findings. Recent studies (Liang et al., 2024b; Geng & Trotta, 2024) have demonstrated a steady increase for LLM usage in scientific writing. This trend presents both opportunities and challenges for academia. When properly used, LLMs"}, {"title": "2.3 AI AS AN AUTOMATED SCIENTIST: TOWARDS END-TO-END SCIENTIFIC DISCOVERY", "content": "Structured in well-organized agentic pipelines, LLMs are increasingly capable of tackling complex tasks collaboratively, with end-to-end scientific research being one of the most ambitious and challenging applications. For instance, Lu et al. (2024) develops an iterative multi-agent framework that supports the entire research process, from proposing novel ideas to presenting polished findings. Similarly, Li et al. (2024b) introduces an automated research system for machine learning, and Manning et al. (2024) employs LLMs to simulate scientists for social science research. Beyond research systems, Jansen et al. (2024) proposes a simulation environment designed to challenge agents in automated scientific discovery. Despite these advancements, current end-to-end research systems still fall short of generating falsifiable scientific findings, constrained by the capabilities of both designed framework and foundation models. While previous research (Lu et al., 2024) has yielded well-formulated outcomes, the vision of automated science discovery still requires further efforts."}, {"title": "2.4 AI FORMS A RESEARCH COMMUNITY: ENABLE ACADEMIC SWARM INTELLIGENCE", "content": "Throughout human history, scientific progress has been greatly driven by collaboration, connection, and discussion among scientists, highlighting the power of a vibrant research community. We propose that a research community of AI scientists could significantly accelerate the pace of automated scientific discovery. For agentic community construction, LLM-driven agents can be organized to generate believable, human-like behaviors (Park et al., 2022; Gao et al., 2024; Park et al., 2023) and to perform specific roles as assigned (Li et al., 2024a; Hua et al., 2023; Xu et al., 2023). Although agent-based simulations of research communities are in an early developmental stage, they represent a promising avenue for the future of fully automated, AI-driven research."}, {"title": "3 BABY-AIGS: A BABY STEP TOWARDS FULL-PROCESS AIGS", "content": "In this section, we elaborate how a baby-step system towards the full-process AIGS is designed, in terms of design principles, overall system design, and detailed implementations."}, {"title": "3.1 DESIGN PRINCIPLES OF A FULL-PROCESS AIGS SYSTEM", "content": "The typical research process for human scientists (Popper, 1935) generally consists of two main stages: the pre-falsification stage, which encompasses exploration of research ideas, refinement of methodologies, and theoretical or empirical analysis, and the falsification stage, which involves hypothesizing scientific laws and validating these hypotheses based on theoretical or empirical findings. In research fields like machine learning, empirical results for falsification process, i.e. ablation studies, are collected after researchers design and build a system, and conduct experiments. In contrast, other fields operate differently. For example, in physics or biology, empirical results are gathered from instruments or equipment after the experimental design and execution, while in mathematics or the humanities, theoretical insights are often derived through logical reasoning or"}, {"title": "3.2 BABY-AIGS SYSTEM DESIGN", "content": "Heading towards a full-process system for automated scientific discovery, we present the design of BABY-AIGS system in this section. We imitate the practice of human researchers and shape it into an LLM-powered multi-agent system. And we also take into account the capacity and behaviors of current foundation models to ensure the executability in implementation.\nThe overall input for the system would be the topic of the research field, an accessible and configurable experiment environment, and other optional resources like a literature base; and the final outcome would be a verbal scientific discovery and the falsification process that support or falsify it. Following the principles in Section 3.1, the BABY-AIGS system operates in two phases (Figure 3):\n1. Pre-Falsification: This phase contains several stages, such as idea formation, methodology design, experiment execution, result analysis, etc., and operates iteratively for M turns, aiming to explore and refine the proposed idea and method through feedback including experimental outcomes, reviews, etc. Specifically, the experimental results of turn 0 is from a trivial methodology at the default setting, e.g., no operation, identical mapping, etc. The multi-turn log of agent communications is recorded for Falsification. For better efficiency,"}, {"title": "3.3 DETAILED IMPLEMENTATION", "content": "In the following sections, we elaborate on the the detailed implementation of our AIGS system through DSL, multi-sampling strategy, and three main agents: PROPOSALAGENT, REVIEWAGENT, and FALSIFICATIONAGENT. The rest of optional modules have been omitted for the sake of clarity. In order to aid in the elaboration of the following sections, we present the research topic of data"}, {"title": "3.3.1 DOMAIN-SPECIFIC LANGUAGE (DSL)", "content": "A domain-specific language (Mernik et al., 2005) is created specifically for a particular application domain, providing greater expressiveness and ease of use within that domain compared to general-purpose languages, traditionally for programming languages. However, we observed that the situation is the same for agents in the AIGS systems. When conducting scientific research, agents have access to a wide and diverse action space, making it challenging to perform error-free long-sequence actions for every stage of the research process, particularly when translating the methodology into executable actions for experimentation. For instance, in machine learning research, an agent may edit multiple code files and manipulate large amount of data, as part of the methodology execution. However, limited by the current capacity of foundation models, it remains a severe challenge for agents to carry out the proposed experiment with both full-process autonomy and satisfiable success rates (Jimenez et al., 2024; Chan et al., 2024; Lu et al., 2024) without dedicated interface design (Yang et al., 2024a; Wang et al., 2024b) or tool use (Paranjape et al., 2023; Qin et al., 2024).\nIn BABY-AIGS, we extend the original definition of DSL in programming to semi-structure objects with pre-defined grammars, making it a bridge that fills the gap between the proposed methodology and experimentation. The DSL restricts the action space of the agents while maintaining the freedom for agents to conduct proposed methods at the same time, through dedicated design with human effort. To utilize the capabilities of current LLMs"}, {"title": "3.3.2 PROPOSALAGENT", "content": "As the first step towards the scientific research, idea formation and methodology design usually lay the foundation for valuable insights or impactful discoveries from falsification process based on empirical results, i.e., creativity in the AIGS system. We refer to the corresponding module in"}, {"title": "3.3.3 REVIEWAGENT", "content": "Drawing inspiration from human practice, we recognize that significant insights and breakthroughs often emerge from in-depth analysis of experiments and reflection on methodology based on empirical results. To facilitate this process, we design REVIEWAGENT to analyze the experimental results and provide feedback to PROPOSALAGENT, iteratively improving the overall proposal.\nIn order to conduct a comprehensive and constructive review, REVIEWAGENT performs analysis at different levels of granularity. For fine-grained analysis, REVIEWAGENT examines comprehensive experimental logs, analyzing intermediate results from multi-level metrics which could be pre-defined by human researchers, e.g. performance indicators of the benchmark, or self-generated in code segment (examples for data engineering shown in Table 1). The review of the experimental"}, {"title": "3.3.4 MULTI-SAMPLING STRATEGY", "content": "In this section, we formalize the multi-sampling strategy employed in the pre-falsification phase of BABY-AIGS system. This strategy is designed for better efficiency and quality of iterative exploration by parallel executing PROPOSALAGENT, EXPAGENT, REVIEWAGENT, etc. for multiple threads, combined with reranking to retain the most promising threads for further exploration.\nAs shown in Figure 3, the multi-sampling strategy operates orthogonal to the iterative refinement of the proposal, where the pre-falsification process of each iteration $i$ involves parallel sampling across $N$ threads, and each sampled thread represents a full pre-falsification process, including ideation, experimentation, reviewing, etc. Formally, let $S^{(i)} = {s^{(i)}_1, s^{(i)}_2, ..., s^{(i)}_N}, i = 1, ..., M$ represent the set of threads sampled in iteration $i$. Each sample $s^{(i)}_j, j = 1,..., N$ undergoes experiments and reranking based on pre-defined criteria, and only a subset with top-ranked samples $S^{(i)}_{top}$ of size $N_s$ is retained for the next iteration. The process can be summarized as follows:\n1. Sampling Step: In each iteration $i$, the system generates $N$ samples ${s^{(i)}_1, s^{(i)}_2, ... , s^{(i)}_N}$ in parallel. If the former samples $S^{(i-1)}_{top}$ are available, i.e., it is not the first iteration,"}, {"title": "3.3.5 FALSIFICATIONAGENT", "content": "In the research process, there is usually a gap between the experimental results indicating improvement in performance and the final conclusions of the scientific findings, and human researchers usually perform ablation studies to verify the authenticity of scientific discoveries. We term progress like this falsification, which is a critical step towards full-process automated scientific discoveries.\nRecognizing the importance of falsification, we introduce FALSIFICATIONAGENT, a novel component not present in previous work (Lu et al., 2024; Su et al., 2024). FALSIFICATIONAGENT has access to all history records, including proposals from PROPOSALAGENT, experiment results from EXPAGENT, and reviews from REVIEWAGENT. We hypothesize that scientific discoveries are more likely to emerge from significant experimental phenomena, i.e. changes in results, thus, FALSIFICATIONAgent in BabY-AIGS first performs a \"Significance Screening\" to identify adjacent turns of pre-falsification phase with greatest performance discrepancies, as shown in Figure 6. Following this, FALSIFICATIONAGENT generates scientific discovery candidates from these selected turns. Then FALSIFICATIONAGENT generates the plans and the ablated methods for ablation experiments. We require that at most T plans are made for each discovery candidate, indicating that at most T ablation experiments will be conducted, and each ablation experiment focuses on the verification of a single factor that may influence the experimental result. Specifically, FALSIFICATIONAGENT must select an iteration as the baseline for the ablation study, and FALSIFICATIONAGENT follows the \"Experiment Settings\" of the baseline, and modify the methodology according to the ablated factor.\nAttempting to reach a robust and reliable conclusion of the ablation study, both baseline and ablation experiments are repeated multiple times. FALSIFICATIONAGENT is given the complete record of these experiments to decide the validity of the associated scientific principle. If a particular discovery withstands this process and consistently produces results similar to those in the main experiment, it is regarded as a verified and valuable scientific discovery. And it is falsified otherwise.\nFormally, the outcome of FALSIFICATIONAGENT, which is also the output of BABY-AIGS, is:\nScientific Discovery = FALSIFICATIONAGENT (Research Topic | History),\nwhere\nHistory = {Proposal (i), Exp. Res. (i), Review (i)},M i=1,S\nand FALSIFICATIONAGENT(\u00b7 |.) indicates the agentic workflow. We also provide an example on the data engineering research to better describe the different parts of the output of FALSIFICATION-AGENT in BABY-AIGS as follows, in which specific parts of the methodology are ablated and reasonable conclusions are made based on the results of the ablation experiment:"}, {"title": "3.4 AUTOMATED FULL-PROCESS RESEARCH EXPERIMENT", "content": "3.4.1 SELECTED RESEARCH TOPICS\nWe conduct experiments on three primary research topics in machine learning to evaluate BABY-AIGS in autonomous full-process research. Formally, let $D_k = {(x_i, y_i)}^n_{i=1}$ denote the k-th benchmark of a given ML problem, where $x_i$ represents input features and $y_i$ represents the corresponding labels. The goal is building a system $f : X \\rightarrow Y$ that maximizes metric functions $L_k (f(x), y)$ over all benchmark $D_k$. We split benchmarks into validation and test ones, and only the former is available in the pre-falsification phase, avoiding wrong scientific discoveries from over-fit results.\nData Engineering Data engineering is a critical research topic that focuses on the identification, extraction, and processing of relevant data features that significantly influence model performance. We formulate the research goal as follows: Given a data set $H$ that contains instruction-response pairs, the goal is to identify the key distinguishing characteristics of $H$, which in turn enables the system to filter and extract high-quality data subsets $H' \\subset H$ for the development of LLMs. This process is crucial to improving the quality and relevance of data for a wide range of areas, ensuring downstream tasks, such as in-context learning (Brown et al., 2020) and Supervised Fine-Tuning (SFT) for LLM alignment (Ouyang et al., 2022), are more effective. Specifically, we leverage Alpaca-GPT4 dataset (Peng et al., 2023) as the dataset $H$. We follow previous work (Liu et al., 2024; Chen et al., 2024b; Li et al., 2024c; Zhao et al., 2024) in this field and let the AIGS systems write principles for LLMs to rate data samples and extract the top rated ones as the refined dataset. Thus, for BABY-AIGS, we input the description of the topic and design the main DSL as a list of required principles for the evaluation of the data sample and a threshold indicating the least number of principles that a data sample in the refined dataset has to pass.\nSelf-Instruct Alignment The self-instruct alignment (Wang et al., 2023c) is a well adopted data synthesis paradigm for LLM alignment. The objective of this research topic is to synthesize a set of SFT data with high quality and diversity for LLM alignment (Ouyang et al., 2022) by rewriting a seed set of data, thereby enhancing the performance of the fine-tuned model on this dataset. In the research process, an AIGS system is required to construct an optimal set of instructions from a seed instruction dataset, which are used to generate an instruction-response dataset from LLMs. This dataset is then leveraged to refine the alignment of an LLM via SFT. In the experiment, we rewrite the original seed instruction set, and use the same LLM in instruction synthesis and response generation for SFT data. Specifically, for BABY-AIGS, the DSL is designed as an option whether to use the seed instruction set, and a list of requirements for the given LLM to generate instructions.\nLanguage Modeling Language modeling is a core research topic in natural language processing that aims to improve the ability of a model to understand and generate human language. Currently, the mainstream approach is generative pre-training (Radford et al., 2018), and the objective is to maximize the perplexity of the next token prediction, i.e. minimize the model perplexity. The AIGS system seeks to explore different architectural and training schedule modifications to enhance quality of language model pre-trained on large corpora. We designed DSL of the BABY-AIGS system as a set of constrained configurations of model architecture and training hyper-parameters.\nEach of these research topics requires unique methodological innovations of an AIGS system to foster high creativity, executability, and falsification capabilities. We demonstrate the pre-defined grammars of BABY-AIGS in Figure 5. Please refer to Appendix B for detailed settings."}, {"title": "3.4.2 EVALUATION SETTINGS", "content": "We evaluate BABY-AIGS based on three key principles central to AIGS systems as proposed in Section 3.1: falsification, creativity, and executability. We introduce the AI Scientist (Lu et al., 2024) as the baseline of the automated research system, and also select published literature from top conference as the baseline of research from experienced human researchers.\nFalsification We assess BABY-AIGS 's ability to perform falsification through human evaluation, focusing on the falsification process carried out by FALSIFICATIONAGENT. This process involves hypothesizing potential influencing factors, identifying the key variables that may impact experimental results, designing and conducting ablation experiments, and ultimately validating the real factors contributing to the experimental significance. The human evaluation is carried out by volunteer researchers with experience in publishing at top-tier conferences. Evaluators assess the fal-"}, {"title": "3.5 QUANTITATIVE AND QUALITATIVE ANALYSIS", "content": "BABY-AIGS could produce valid scientific discoveries with falsification process. To validate the falsification process in BABY-AIGS, we assess its ability to perform ablation studies and identify causative factors for experimental results. The qualitative analysis in Table 2 shows that FALSIFICATIONAGENT could produce valid scientific discoveries in current design, as the maximum value of each metric is tied to the top-conference baseline, contributing positively to the automation of scientific insights. However, there are two critical findings that indicate further improvement is needed. (1) The average value of the importance score is higher than the consistency and correctness score, indicating that FALSIFICATIONAGENT could identify important factors potentially related to a scientific discovery but failed to design a concrete experiment plan and verify the hypothesis. The failure could be attribute to the capacity of foundation model or the lack of high-quality demonstration of experiment design in prompts. (2) The p-values indicate that the falsification process of BABY-AIGS is significantly less satisfactory than the existing literature from top conferences from human perspectives, which emphasizes the importance of designing user-friendly interfaces besides refining the design of ablation experiments. Also, we acknowledge that the scale of the study is small compared to Si et al. (2024), which requires future effort.\nBABY-AIGS demonstrates creativity during research idea exploration and refinement. Table 3, Table 4, and Table 5 show the results of the test benchmarks for data engineering, self-instruct alignment, and language modeling research experiments, respectively, where BABY-AIGS outperforms the baseline method, demonstrating the system's creativity in ideation and corresponding method design. For data engineering, BABY-AIGS outperforms AI Scientist with a significant margin, demonstrating the effectiveness of the enriched feedback, including multi-granular metrics, verbose review on both experiment process and methodology design, etc., in exploring research idea. However, the result of SFT alignment is inferior than Deita (Liu et al., 2024), indicating that the lack of validation benchmarking of specific downstream tasks might result in an suboptimal outcome."}, {"title": "3.6 DISCUSSIONS", "content": "Q1: How do current LLMs perform in the falsification process? Falsification (Popper, 1935) is essential in AIGS systems as it provides a rigorous mechanism for verification of potential scientific discoveries, a core component in the scientific method. In BABY-AIGS, FALSIFICATIONAGENT plays the corresponding role. Thus, it demands related abilities in the foundation model, such as reasonable hypothesis generation, ablation experiment design, summarization and self-correction based on input empirical results, etc. As shown in the case in Section 3.3.5 and Table 2, current LLMs are far from desired in the agentic workflow of FALSIFICATIONAGENT. Additionally, the constraints may come from the ability of the LLM to understand the environment outside FALSIFICATIONAGENT. For instance, from our observation, FALSIFICATIONAGENT seldom proposes experiment plans beyond the provided experiment templates. In this case, although DSL makes sure the executability of the experimentation by omitting extra operations, the experiment process would differ from the original plan, thus creating inconsistency.\nQ2: How does the BABY-AIGS system boost creativity? BABY-AIGS enhances creativity by integrating a multi-sampling approach combined with re-ranking, allowing it to generate diverse research proposals and rank them based on validation benchmarks. We provide detailed results of an ablation study of this process in Table 7. We observed that the performance on the test benchmark is steadily increasing with multi-sampling with large numbers of threads. This strategy is related to search-based inference-cost scaling methods (Snell et al., 2024; Brown et al., 2024). The insight is to pick random high-performing samples for better overall performance. However, since the objective of AIGS is to discover science on a research topic, the reranking method here could"}, {"title": "Q3: Why could DSL help with executability?", "content": "The use of a Domain-Specific Language (DSL) in BABY-AIGS facilitates executability by providing a structured and executable representation of ideas and methodologies proposed by PROPOSALAGENT. DSL enhances the system's ability to translate complex scientific workflows into actionable experiment plans. As shown in Table 6, DSL significantly improved success rates in generating scientific discoveries, regardless of correctness, underscoring its role in achieving high executability. We acknowledge that the design of DSL requires human effort and might not be able to cover all possible method implementations. However, we believe it is a promising interface between agents and experimentation in full-process research."}, {"title": "4 LIMITATIONS AND ACTIONABLE INSIGHTS", "content": "Envisioning the future of AI-Generated Science systems powered by foundation models in real-world, in this section, we enumerate a few limitations for current BABY-AIGS system and provide insights on the next steps of research for AIGS.\nBalance idea diversity and system executability. As discussed in Section 3.3.1, the design of the DSL enhances the system executability but may constrain the idea diversity. Achieving a balance between idea diversity and system executability requires further empirical analysis. One potential avenue is enabling agents to develop their own DSLs, which could enhance the executability of generated ideas without diminishing their diverse potential.\nEstablish systematic mechanisms for evaluation and feedback. The quality of AIGS system depends heavily on rigorous evaluation of prior proposals, methods, and results. Current approaches often adopt a peer review format, leveraging LLMs to generate feedback on results and guide future optimization (Lu et al., 2024; Yu et al., 2024; Jin et al., 2024). However, it remains unclear whether this method is the most effective for large-scale research settings. Future work should explore systematic mechanisms to analyze outcomes across iterations, maximizing experience transfer and continuous improvement.\nStrengthen the falsification procedure. Our research underscores the importance of falsification to enhance the scientific rigor of the research findings. While we have prototyped the falsification process in our BABY-AIGS system, more efforts are required to strengthen the modules related to knowledge falsification, including the exploitation of the patterns and relationships derived from historical experiments for the guidance of refined research proposals. Besides, it is also vital for AIGS systems to investigate whether the delivered new scientific knowledge could generalize across diverse research domains in an autonomous manner.\nExpand channels for scientific knowledge dissemination. Facilitating the exchange of AI-Generated Science is critical, both between humans and AI and among AI systems. While Lu et al. (2024) focus on disseminating knowledge through research papers, alternative formats like posters, podcasts, and videos are gaining traction with the rise of multi-modal agents. Future research should also explore more efficient communication channels between Al systems, beyond structured text or natural language (Pham et al., 2024; Chen et al., 2024c).\nExploring communication dynamics among autonomous AI researchers. As discussed in Section 2, the advancement of AI-accelerated scientific discovery spans four paradigms, culminating in the emergence of an autonomous AI research community (Paradigm IV). Within this community, individual agentic researchers engage in interactions that parallel collaborative dynamics found in human scientific networks. Analyzing these communication dynamics is essential to understand how fully-autonomous AI agents might effectively collaborate, exchange knowledge, and drive collective progress. In particular, a deeper exploration of these interactions in a multi-agent system will help establish communication frameworks that support optimal collaboration, fostering a robust and productive AI-accelerated research community."}, {"title": "5 ETHICS AND IMPACT STATEMENT", "content": "In our BABY-AIGS system, the agent did not perform harmful operations on computer systems or environment because of the design of DSL, task constraints and no"}]}