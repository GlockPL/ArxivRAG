{"title": "M\u00b3-20M: A Large-Scale Multi-Modal Molecule Dataset for Al-driven Drug Design and Discovery", "authors": ["Siyuan Guo", "Lexuan Wang", "Chang Jin", "Jinxian Wang", "Han Peng", "Huayang Shi", "Wengen Li", "Jihong Guan", "Shuigeng Zhou"], "abstract": "This paper introduces M\u00b3-20M, a large-scale Multi-Modal Molecular dataset that contains over 20 million molecules. Designed to support AI-driven drug design and discovery, M\u00b3-20M is 71 times more in the number of molecules than the largest existing dataset, providing an unprecedented scale that can highly benefit training or fine-tuning large (language) models with superior performance for drug design and discovery. This dataset integrates one-dimensional SMILES, two-dimensional molecular graphs, three-dimensional molecular structures, physicochemical properties, and textual descriptions collected through web crawling and generated by using GPT-3.5, offering a comprehensive view of each molecule. To demonstrate the power of M3-20M in drug design and discovery, we conduct extensive experiments on two key tasks: molecule generation and molecular property prediction, using large language models including GLM4, GPT-3.5, and GPT-4. Our experimental results show that M\u00b3-20M can significantly boost model performance in both tasks. Specifically, it enables the models to generate more diverse and valid molecular structures and achieve higher property prediction accuracy than the existing single-modal datasets, which validates the value and potential of M\u00b3-20M in supporting AI-driven drug design and discovery.\nThe dataset is available at https://github.com/bz99bz/M-3.", "sections": [{"title": "Introduction", "content": "Drug design and discovery is an important field in pharmacy, which aims to identify new therapeutic compounds and optimize their properties for clinical use. 1-5 This process involves the prediction of molecule-target interactions 6-9 and molecular properties, 10\u201313 and the design or generation of targeted molecules, 14\u201318 which are fundamental for developing effective and safe drugs. In recent years, various models trained or pre-trained and fine-tuned using massive data, such as, 19-27 have emerged as powerful tools in this domain. These models leverage large datasets and sophisticated algorithms to generate new compounds, predict molecular structures, and analyze their biochemical properties, significantly advancing the process of drug design and discovery. However, most existing molecular datasets for model training are limited to single-modality, failing to capture the characteristics of molecules completely, thus\nhampering the building of powerful models for drug design and discovery.\nRecent works 23,28,29 have been paying increasing attention to multi-modal molecule datasets. Zeng29 introduced a deep-learning system that bridges molecular structures and biomedical texts, achieving comprehension comparable to human professionals. Liu et al. 28\ndeveloped a multi-modal model for text-based retrieval and editing of molecular structures,\nfacilitating advanced molecular text analysis. Liu et al.23 presented a multi-modal large\nlanguage model for molecular science that integrates graphs, images, and texts to support\nvarious downstream tasks. However, datasets used in these works still suffer from significant\nlimitations. On the one hand, these datasets are typically small in size, encompassing a limited chemical space that restricts the generalization power of the trained or tuned models.\nOn the other hand, the absence of complete modalities of molecular data undermines the"}, {"title": null, "content": "performance of computational models.\nTo address these limitations, this paper presents a new and large-scale multi-modal integrated molecule dataset called M\u00b3-20M for AI-driven drug design and discovery. M\u00b3-20M\ncontains more than 20 million molecules with their SMILES strings, 2D graphs, 3D structures,\nphysicochemical properties, and textual descriptions, providing unprecedented data scale,\ndiversity, and comprehensiveness for training models of superior performance for various\ndrug design and discovery downstream tasks. Concretely, M\u00b3-20M is 71 times more in the\nnumber of molecules than the largest existing dataset. 28 It collects physicochemical properties\nfrom the PubChem database30 and enriches the description texts of molecules by both web\ncrawling and GPT-3.5 generation. Therefore, each molecule's SMILES corresponds to its 2D\ngraph and 3D structure, physicochemical properties, and description texts.\nIn summary, M\u00b3-20M stands out of the existing datasets in at least the following three\naspects: 1) Large scale: it contains over 20 million molecules, which is the largest open-\naccess multi-modal molecule dataset for AI-driven drug design and discovery, to the best\nof our knowledge. 2) Comprehensive modalities: M\u00b3-20M boasts a more complete\nrange of modalities, including one-dimensional molecular SMILES strings, two-dimensional\nmolecular graphs, three-dimensional molecular structures, physicochemical properties, and\ntextual descriptions. Such multi-modal data offers a holistic perspective of each molecule,\nbenefiting model training and tuning for drug design and discovery. Additionally, we offer\ntools to generate 2D molecular graph images that facilitate compound patent retrieval,\nand to crawl PubMed for research articles related to specific molecules, thereby enriching\ntextual descriptions. 3) Supporting various tasks: M\u00b3-20M can support model training\nand tuning for various downstream drug design and discovery tasks, including molecule\ngeneration, molecular property prediction, lead optimization, and virtual screening. It also\ncan aid in tasks such as pharmacokinetics modeling and drug-target interaction prediction.\nMoreover, we construct seven multimodal sub-datasets, QM9-MM, MOSES-MM, BACE-MM,"}, {"title": null, "content": "BBBP-MM, HIV-MM, ClinTox-MM, and Tox21-MM, to facilitate more accurate and robust\nmolecular property prediction.\nTo demonstrate the power of M\u00b3-20M in supporting drug design and discovery, extensive\nexperiments on two basic tasks, molecule generation and molecular property prediction, are\nconducted using large language models including GLM4, 31 GPT-3.5,32 and GPT-4.33 The\nexperimental results show that M\u00b3-20M can significantly boost model performance in both\ntasks. Concretely, with M\u00b3-20M, the above models can generate more diverse and valid\nmolecular structures, and achieve higher property prediction accuracy than with existing\nsingle-modal datasets, thus verifying the value and potential of M\u00b3-20M in supporting\nAI-driven drug design and discovery."}, {"title": "Related Work", "content": "Multi-modal molecular data is becoming increasingly important in artificial intelligence and\nmolecular biology. which can provide more comprehensive and rich information, bringing"}, {"title": null, "content": "new opportunities and challenges to drug discovery, molecular property prediction, and\ngeneration tasks. For example, Wang et al. 34 pointed out that the use of multi-modal data,\nincluding sequence, structure, text etc., can improve the accuracy of drug discovery. However,\nthe challenges faced by multi-modal data cannot be ignored, as different data types often\nnecessitate distinct methods for organization, storage and processing as well as learning.\nAdditionally, ensuring data consistency and integrity also poses a critical issue, with various\nforms of data potentially exhibiting semantic gaps or inconsistencies. Therefore, there is\nan urgent need to overcome the above issues to create a large-scale multi-modal integrated\ndataset for model training or tuning in drug design and discovery. In what follows, we\nbriefly review the related work in three perspectives, molecular representation, single and\ntwo-modality molecule datasets, and multi-modality molecule datasets."}, {"title": "Molecular representations", "content": "Molecules can be represented by various modalities of information, 35,36 including one-\ndimensional sequences, two-dimensional graphs or images, three-dimensional structures,\nand molecular properties as well as textual descriptions. One-dimensional sequences primarily\nconsist of SMILES strings, molecular fingerprints, and algebraic topology-based characteri-\nzations. Two-dimensional representations include molecular graphs and images generated\nusing toolkits such as RDKit37 or Open Babel. 38 Three-dimensional structures are catego-\nrized into molecular graphs and grids, 39 containing atomic coordinates that provide detailed\nspatial information. Molecular textual descriptions offer additional information derived from\nexperiments. Single-modal data is a reduction of the complete structural information of the\nmolecules, which means the representations learned from single-modal suffer from information\nloss. For example, two SMILES may represent the same molecule or a two-dimensional molec-\nular graph cannot distinguish between the conformations. Therefore, integrating multi-modal\ninformation is crucial for molecular modeling and model training in drug design and discovery."}, {"title": "Single-modal and two-modal molecule datasets", "content": "Most existing molecule datasets are limited to single or dual modalities, restricting the general-\nization power of trained models. 40-44 These datasets typically have only one-dimensional (1D)\nSMILES strings, or two-dimensional (2D) structures, or three-dimensional (3D) structures,\nand usually lack textual molecular descriptions. For instance, MOSES 45 comprises 4,591,276\nmolecules filtered by molecular weight, ranging from 250 to 350 Daltons, and contains solely\none-dimensional SMILES representations. Similarly, ZINC, 46 which serves as a repository of\ncommercially available compounds for virtual screening, contains over 1.3 billion molecules\nobtained from 310 catalogs across 150 vendors, encompassing 2D graphs and, for the majority,\n3D structures. Zeng et al.29 presented a deep learning system that connects molecular\nstructures with biomedical texts, demonstrating a level of comprehension comparable to that\nof human experts."}, {"title": "Multi-modal molecule datasets", "content": "With the development of AI-driven drug design and discovery, multi-modal data have become\nincreasingly important in recent years. Up to now, only a few datasets have been introduced\nto address this need, each with distinct purposes and contributions.\nLiu et al. 28 constructed PubChemSTM, a dataset containing over 280,000 chemical\nstructure-text pairs. Despite PubChemSTM's ability to generalize novel biochemical concepts\nacross various benchmarks, its dataset volume remains insufficient. Subsequently, the igcdata\ndataset 23 was proposed, which comprises 220,000 descriptions sourced from PubChem and\nChEBI-20.47 Although these two datasets provide valuable resources, their relatively small\nscale restricts their utility for training high-performance models. Beyond scale, these two\ndatasets also lack the diversity and completeness of molecular modalities necessary for\nrobust model development. Issues such as sparse or overly brief textual descriptions further\nexacerbate this limitation, leading to suboptimal training outcomes of drug design and\ndiscovery models."}, {"title": "Dataset Construction", "content": "This section introduces the dataset construction process and some statistic information of the\ndataset. Molecular data is collected from existing databases PubChem, ZINC and QM9, and\nthen processed to get multiple representations of molecules, including SMILES strings, 2D\nand 3D structures, physicochemical properties, and textual descriptions. Notably, we enhance"}, {"title": null, "content": "molecular textual descriptions by generating using GPT-3.5 with an expert scoring mechanism\nto ensure that these descriptions are both scientifically accurate and practically useful. All\nthe data are integrated into a comprehensive dataset with over 20 million molecules."}, {"title": "Data Collection", "content": "Figure 2 shows the pipeline for constructing our multi-modal molecular dataset M\u00b3-20M.\nTo obtain molecules and the corresponding molecular graphs and 3D structures, we first\ncollect molecules from the PubChem, ZINC, and QM9 databases for their extensive molecular\ncoverage and reliable data quality. Then, we utilize the Chem function of RDKit to extract\natomic features and chemical bond characteristics and convert them into 2D molecular graphs.\nAdditionally, we employ the PubChem API to batch download SDF files containing the 3D\nstructures of molecules and use the GetAtomPosition function of RDKit to calculate the 3D\ncoordinates of the central atoms.\nTextual descriptions serve as a bridge for large language models to comprehend multi-\nmodal molecules. The remarkable recognition accuracy and robustness of the CLIP 49\nmodel exemplify the benefits of effectively linking textual descriptions with other modality\ninformation of molecules. Similarly, since textual descriptions of molecules facilitate a deeper\nunderstanding of chemical information, we meticulously construct these descriptions in the\ndataset using three approaches: 1) For the molecules that have textual descriptions in"}, {"title": null, "content": "PubChem, we directly extract the texts from PubChem. 2) For the molecules that do not\nhave textual descriptions but have physicochemical properties in PubChem, we transform\nthese physicochemical property values into textual descriptions, which will be detailed later. 3)\nFor those without physicochemical property values or not present in the PubChem database,\nwe generate their textual descriptions by GPT-3.5. We present the details in the following\nsections.\nInitially, we utilized textual data from PubChem; however, only a subset of molecules in\nPubChem contains associated textual descriptions. The sparsity of text information leads\nto poor performance of the trained or tuned models. So we resort to text augmentation.\nTo generate textual descriptions for molecules having physicochemical property values in\nPubChem, we extract 26 key physicochemical properties and their values from PubChem,\nincluding Molecular Weight, XLogP3, Hydrogen Bond Donor Count, Hydrogen Bond Acceptor\nCount, Rotatable Bond Count, Exact Mass, Monoisotopic Mass, Topological Polar Surface\nArea, Heavy Atom Count, Formal Charge, Complexity, Isotope Atom Count, Defined Atom\nStereocenter Count, Undefined Atom Stereocenter Count, Defined Bond Stereocenter Count,\nUndefined Bond Stereocenter Count, Covalently-Bonded Unit Count, Canonicalization Status,\nPhysical Description, Color/Form, Odor, Boiling Point, Melting Point, Flash Point, and\nSolubility Density.\nConcretely, we search for these properties using the compound identifier (CID) in PubChem,\nensuring all data complied with licensing requirements and utilizing the open interface provided\nby PubChem. After collecting 19,175,245 pieces of raw data, we transform the properties of\neach molecule into structured descriptions using the template \u201cproperty name is a specific\nvalue\u201d. Here, \u201cproperty name\u201d indicates any of the 26 properties, and \u201cspecific value\u201d means\na concrete value of the property.\nFurthermore, we expand seven downstream task datasets with multi-modal information\nfrom our dataset by associating the PubChem CIDs of molecules, including molecule generation\ndatasets MOSES and QM9, and molecular property prediction datasets such as BBB\u0420, \u0412\u0410\u0421\u0415,"}, {"title": null, "content": "HIV, Tox21, and ClinTox. This expansion enables model enhancement with multi-modal\ninformation for both molecule generation and property prediction tasks. The expanded\ndatasets are denoted as MOSES-MM, QM9-MM, BBB\u0420-\u041c\u041c, \u0412\u0410\u0421\u0415-MM, HIV-MM, Tox21-\nMM, and ClinTox-MM, respectively."}, {"title": "Text Description Generation by GPT-3.5", "content": "As mentioned above, for molecules lacking physicochemical properties or not present in\nPubChem, we generate molecular textual descriptions as a molecule captioning task by using\nthe GPT-3.5 API. Figure 3 illustrates the process of molecular description text generation.\nInitially, we use the following prompt to guide GPT-3.5 in generating descriptions based solely\non SMILES strings: \u201cYou are an expert chemist. Given the molecular SMILES, your task is\nto provide a detailed description of the molecule using your experienced chemical knowledge.\u201d"}, {"title": null, "content": "However, this approach results in issues such as incorrect naming of SMILES strings\nand misidentifying functional groups. To address these problems, inspired by the CO-STAR\n(Context-Objective-Style-Tone-Audience-Response) framework, we rewrite the original prompt\nas follows to enhance the output quality: \u201cYou are an expert chemist with a comprehensive\nunderstanding of molecular structures and chemistry. Using your extensive knowledge, please\ndescribe the molecule represented by the following SMILES string. Focus on its structural\nfeatures, potential chemical properties, and any known applications or reactions it may\nparticipate in. Use only the information inferred from the SMILES representation; do not"}, {"title": null, "content": "create or infer any hypothetical or novel names for the molecule.\u201d\nUtilizing this enhanced prompt, we generated 1,073,845 descriptions using GPT-3.5, which\nis only 0.934% of the total descriptions. The proportion of synthetic data to real data is very\nlow and will not have a negative impact on real data. The following section elaborates on\nthe quality control measures implemented through the Human Expert Scoring Mechanism to\nensure the precision and reliability of the generated descriptions."}, {"title": "Generated Text Quality Control by Human Expert Scoring", "content": "To ensure the reliability and utility of the generated textual descriptions, we implement an\nexpert scoring mechanism inspired by some recent works. 50,51 We recruit six undergraduate\nand postgraduate chemistry students from top China universities, all having excellent academic\nrecords. They evaluate the accuracy and usefulness of the generated texts, ensuring that the\ntextual descriptions are both scientifically valid and practically useful.\nThis mechanism assesses the textual descriptions from four dimensions: accuracy, ef-\nfectiveness, comprehensiveness, and simplicity, as established in previous works on natural\nlanguage generation and evaluation.52,53 Each description can earn a maximum score of 10\npoints. The scoring system is structured as follows:\n1. Accuracy (Maximum 5 points)\n(a) Correct Description (5 points): The molecular description is entirely accurate,\ncontaining no scientific errors. This includes correct usage of chemical terms,\naccurate structural representation, and proper property identification.\n(b) Slight Errors (2-4 points): Minor inaccuracies are present, such as small\nstructural mistakes or minor property deviations. These errors should not impede\noverall comprehension. Notably, any incorrect identification of functional groups\nresults in a 1 point deduction.\n(c) Serious Errors (0 points): Major inaccuracies are present, such as entirely"}, {"title": null, "content": "incorrect chemical terminology or wrong molecular names, stripping the description\nof scientific value.\n2. Effectiveness (Maximum 2 points)\n(a) Highly Valid (2 points): The description highlights key molecular properties,\nsuch as reactivity or pharmacodynamics, and may include useful applications or\nfuture prospects.\n(b) Moderately Effective (1 point): While the description includes valid informa-\ntion, it may lack detailed analysis or specific application scenarios.\n(c) Ineffective Description (0 points): The description fails to convey crucial\nproperties or applications and lacks practical utility.\n3. Comprehensiveness (Maximum 2 points)\n(a) Very Comprehensive (2 points): The description extensively covers multiple\naspects of the molecule, including structure, physicochemical properties, reactivity,\nand potential applications.\n(b) Fairly Comprehensive (1 point): Several aspects of the molecule are described,\nthough some areas may lack depth.\n(c) Incomplete (0 points): The description is limited to one aspect of the molecule\nand significantly lacks breadth.\n4. Simplicity (Maximum 1 point)\n(a) Concise (1 point): Succinct, clearly articulated, and free of redundant informa-\ntion.\n(b) Not Concise (0 points): Verbose and repetitive, detracting from clarity and\nconciseness."}, {"title": null, "content": "Each text description is evaluated based on a maximum score of 10 points. For every 100\ngenerated molecules, 10% are randomly selected for expert scoring. Descriptions scoring above\n5 points are considered qualified, while those below 5 points are regenerated. Descriptions\nwith significant inaccuracies (0 points in accuracy) will also be regenerated."}, {"title": "Statistic Results", "content": "This section presents some statistic information of the M\u00b3-20M dataset to highlight its\ncomprehensive annotations, diverse textual descriptions and physicochemical properties, which\ncan significantly enhance its utility for molecular research and AI-driven drug discovery. By\ncomparing it with existing datasets such as PubChem, we emphasize the enhancements in both\nscale and quality that M\u00b3-20M offers. The section further delves into word distribution a key\nfeature of textual data, and explores correlations among physicochemical properties through\nadvanced statistical techniques like Principal Component Analysis (PCA). Additionally, we\noutline the robust maintenance protocols established to ensure our dataset's accuracy and\nusability for the research community. These findings demonstrate the dataset's value as a\nfundamental resource for molecular representation learning and related applications."}, {"title": "Textual Descriptions", "content": "Figure 4 shows a comparison of molecule descriptions between PubChem and our M\u00b3-20M.\nThe PubChem description bar is relatively small, reaching only 360,133, while the M\u00b3-20M\nannotation description bar towers over it, marking a count of 20,249,090. This enhancement\nis critical for AI-driven drug design and discovery, as the increased volume and details of\ndescriptions facilitate more comprehensive analysis and model training."}, {"title": "Word Distribution in Description Texts", "content": "Figure 5 presents the top 20 most frequently occurring words in the textual descriptions\nof our dataset, plotted alongside their respective frequencies to emphasize their relative\nprominence. The most commonly used terms, such as 'natural,' 'product,' and 'acid,' appear\ntens of thousands of times, underscoring their central role in describing molecular properties\nand functions. Additional notable terms, including 'related,' 'organisms,' and 'amino,'\nfurther highlight the biological and chemical contexts associated with these molecules. This\nvisualization of word frequencies provides valuable insights into molecular datasets' linguistic\npatterns and descriptive focus."}, {"title": "Physicochemical Properties", "content": "Table 2 and Figure 6 provide a detailed overview of the specific names, corresponding\nquantities, and reference of the 26 key physicochemical properties extracted from PubChem.\nOf the 26 key physicochemical properties, 18 are computed using professional software 1,\nwhile the remaining 8 represent experimental values sourced from the CAMEO Chemicals\ndatabase and Hazardous Substances Data Bank (HSDB). Notably, 18 of these properties"}, {"title": null, "content": "their ability to capture significant variance in the dataset. Thus, we select these two properties\nas the first and second principal components for Principal Components Analysis (PCA) and\nvisualize the molecular space of randomly sampled 10000 molecules as shown in Figure 8."}, {"title": "Dataset Maintenance", "content": "To ensure the accessibility and accuracy of the M\u00b3-20M dataset, we have organized a dedicated\nmaintenance team consisting of six members, including three doctoral students and three\nmaster's students. This team will perform regular maintenance twice a week, correcting any\nerrors and updating the dataset as needed. This rigorous maintenance protocol supports the\ncommunity's exploration of molecular representation and downstream molecular tasks and\nfacilitates the training of large models with improved versatility and robustness."}, {"title": "Supporting Various Downstream Tasks", "content": "The M3-20M dataset supports model training and tuning for various downstream drug design\nand discovery tasks. While general large language models have achieved remarkable success\nin natural language processing, their performance in specialized fields like drug design and"}, {"title": null, "content": "discovery still has significant room for improvement. Figure 9 illustrates how to use the\nM3-20M dataset to enhance large language models (LLMs) or train models for downstream\ndrug design and discovery tasks, which consists of three paradigms: prompting, finetuning,\nand training from scratch.\nPrompt engineering involves carefully constructing input prompts to guide a general\nlarge language model (LLM) in generating more accurate outputs tailored to drug design\nand discovery. By leveraging our M\u00b3-20M dataset, prompt engineering allows the model to\nquickly adapt to this field without altering its internal parameters. Fine-tuning refers to\nfurther training the LLMs on the M\u00b3-20M dataset, adjusting certain model parameters based\non existing pre-training. This process enables the model to better align with the specific\ncharacteristics and needs of drug design and discovery while retaining its general language\nknowledge. Training from scratch entails building and training a language model on drug\ndesign and discovery domain data. This approach necessitates a large volume of training"}, {"title": null, "content": "data, which our M\u00b3-20M dataset can adequately provide. By utilizing our M\u00b3-20M dataset\nthrough prompt engineering, fine-tuning, and training from scratch, the general LLM's drug\ndesign and discovery capabilities can be enhanced from multiple perspectives and to varying\ndegrees.\nM\u00b3-20M also can aid in tasks such as pharmacokinetics modeling and drug-target in-\nteraction prediction. Moreover, we construct seven multimodal sub-datasets, QM9-MM,\nMOSES-MM, \u0412\u0410\u0421\u0415-\u041c\u041c, BBBP-MM, HIV-MM, ClinTox-MM, and Tox21-MM, to facilitate\nmore accurate and robust molecular property prediction. We also provide tools for generating\nmolecular images to support compound patent searches and for crawling PubMed to find\narticles related to specific molecules, thereby enhancing textual descriptions."}, {"title": "Dataset Evaluation", "content": "In this section, we evaluate the effectiveness of the M\u00b3-20M dataset on two fundamental\ndownstream tasks: molecule generation and molecular property prediction. We primarily\nperform prompt tuning and in-context learning on the closed-source large language models\nGLM4, GPT-3.5, and GPT-4, while also conducting fine-tuning on the open-source model\nLlama3-8b. Additionally, our dataset can be applied to other tasks, including name prediction,"}, {"title": "Molecule Generation", "content": "We utilize the GLM-4, GPT-3.5, and GPT-4 APIs to evaluate the power of M\u00b3-20M in\nmolecule generation. Through in-context learning (ICL), 54 we provide 10 randomly selected\nmulti-modal examples (including SMILES strings of molecules, three-dimensional atomic coor-\ndinates, and descriptions) and single-modal examples (containing only SMILES), respectively.\nSubsequently, 100 molecules are generated randomly for each setup.\nWe analyze the performance of models trained on single-modal and multi-modal datasets\nin molecule generation using three metrics: validity, uniqueness, and novelty. The results,\npresented in Table 3, demonstrate the superiority of multi-modal datasets across all metrics\nand models.\nValidity measures the proportion of chemically valid generated molecules. Multi-modal\ndatasets consistently outperform single-modal ones. For instance, GLM4's validity improves"}, {"title": null, "content": "from 72.73% to 85.37%, GPT-3.5's from 76.01% to 84.8%, and GPT-4's from 92.3% to\n97.99%.\nUniqueness assesses the diversity of generated molecules. Multi-modal datasets show\nsignificant improvements: GLM4's uniqueness rises from 68.17% to 82.25%, GPT-3.5's from\n46.46% to 93.86%, and GPT-4's from 58.64% to 70.17%.\nNovelty evaluates the proportion of generated novel molecules. Multi-modal datasets\nshow substantial improvements, with GLM4's novelty increasing from 97.90% to 98.10%,\nGPT-3.5's from 85.72% to 96.51%, and GPT-4's from 90.66% to 98.95%."}, {"title": null, "content": "Furthermore, Table 4 summarizes the molecular generation performance of our M\u00b3-\n20M dataset using MOSES-MM as the benchmark. Multi-modal data enhances SNN/Test\nperformance for GPT-3.5 and GPT-4, showing increased similarity to the test set. For\nFrag/Test, multi-modal data boosts GLM4 to 0.27% and GPT-4 to 0.20%. In Scaf/Test, all\nmodels improve with multi-modal data; GLM4 rises to 0.07%, while GPT-3.5 and GPT-4 each\nimprove to 0.01%. Regarding Filters, GLM4's pass rate increases to 0.80% with multi-modal\ndata, while GPT-3.5 maintains 1.0%.\nMetrics like logP, SA, QED, and molecular weight are assessed using the Wasserstein-1\ndistance to the MOSES-MM test set, where lower values indicate better performance. Multi-\nmodal data significantly reduces logP distance, especially for GPT-3.5 (0.99) and GPT-4\n(0.92), indicating superior predictions. In SA, multi-modal data improves scores for GPT-3.5\nand GPT-4, reducing distances to 0.57 and 0.54, respectively. QED scores improve with\nmulti-modal data, reaching 0.12 for both models. For molecular weight, predictions improve\nfor GLM4, reducing the distance to 105.72."}, {"title": null, "content": "These findings demonstrate that our multi-modal dataset significantly enhances molecule\ngeneration models across nearly all metrics, highlighting the benefit of integrating diverse\nmolecular representations. The results support the widespread use of multi-modal data in\nmolecular research to develop more robust and versatile generative models."}, {"title": "Molecular Property Prediction", "content": "We refer to MoleculeNet4 and divide the molecular property prediction task into regression\ntask and classification task."}, {"title": "Regression tasks", "content": "To test the effectiveness of our multi-modal dataset in support of\nmolecule property prediction tasks, we conduct an ablation experiment on the QM9-MM\ndataset with three settings: using only the SMILES strings of molecules; using both the\nSMILES strings and 3D coordinates of molecules; and using the SMILES strings, 3D coordi-\nnates and the textual descriptions of molecules. We consider two regression tasks: predicting\nthe dipole moment (\u03bc) and isotropic polarizability (a) of the given molecules. We employ\nGPT-3.5, GPT-4, and GLM-4 APIs to infer the molecular properties respectively. For each\nmolecule to be inferred, we provide the corresponding molecule information in the prompt\nbased on the different versions of the settings and randomly select four additional molecule\nexamples to help the LLMs better understand the chemical structure and the relation between\nthe molecule information and the prediction ground truth."}, {"title": null, "content": "The metric we use for the regression tasks is Mean Absolute Error (MAE), measuring the\naverage magnitude of errors between predicted values and actual values. The smaller the\nMAE value, the more accurate the prediction. The formula of the MAE metric is as follows:\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$ (1)\nwhile n is the number of samples, yi is predicted value, and \u0177 is the ground truth value.\nThe results in Table 6 show that providing more information with multi-modal data in the\nprompt can help LLMs better understand molecules and their chemical properties. Except\nfor the task of predicting the dipole moment using GPT-4, all other models and tasks achieve\nthe best results on the multi-modal dataset, which proves the effectiveness and high quality\nof our dataset."}, {"title": "Classification tasks", "content": "We evaluate the performance of single-modal and multi-modal\ndatasets on various molecular property prediction tasks, focusing on accuracy mean (ACC\nMean), accuracy variance (ACC Variance), and accuracy standard deviation (ACC Standard\nDeviation). The results are summarized in Table 7.\nACC Mean measures the average accuracy of the models. Multi-modal datasets show\nimprovements over single-modal datasets. For example, the BACE-MM dataset's ACC Mean\nincreases from 0.5680 to 0.5780, and the BBBP-MM dataset sees an increase from 0.2280\nto 0.2720. The ClinTox-MM dataset improves from 0.9260 to 0.9280, while the HIV-MM"}, {"title": null, "content": "dataset shows a higher ACC Mean for single-modal data (0.9740) compared to multi-modal\n(0.9680). These results suggest that multi-modal datasets typically enhance model accuracy.\nACC Variance indicates the variability in accuracy. The ClinTox-MM dataset's variance\ndecreases from 0.0005 to 0.0002 with multi-modal data, indicating more stable performance.\nACC Standard Deviation provides insight into the distribution of accuracy values. The\nClinTox-MM dataset sees a reduction from 0.0230 to 0.0130, suggesting enhanced consistency."}, {"title": "Conclusion", "content": "In this paper, we introduce M\u00b3-20M, a new and large-scale multi-modal molecular dataset con-\ntaining over 20 million molecules. Extensive experiments demonstrate M\u00b3-20M's effectiveness\nin boosting the performance of various models in molecule generation and property prediction.\nM\u00b3-20M's integration of SMILES strings, 2D graphs, 3D structural data, physicochemical\nproperties, and molecular textual descriptions provides a rich foundation for developing\nhigh-performance generative models for AI-driven drug design and discovery."}]}