{"title": "SNAP: Stopping Catastrophic Forgetting in Hebbian Learning with Sigmoidal Neuronal Adaptive Plasticity", "authors": ["Tianyi Xu", "Patrick Zheng", "Shiyan Liu", "Sicheng Lyu", "Isabeau Pr\u00e9mont-Schwarz"], "abstract": "Artificial Neural Networks (ANNs) suffer from catastrophic forgetting, where the learning of new tasks causes the catastrophic forgetting of old tasks. Existing Machine Learning (ML) algorithms, including those using Stochastic Gradient Descent (SGD) and Hebbian Learning typically update their weights linearly with experience i.e., independently of their current strength. This contrasts with biological neurons, which at intermediate strengths are very plastic, but consolidate with Long-Term Potentiation (LTP) once they reach a certain strength. We hypothesize this mechanism might help mitigate catastrophic forgetting. We introduce Sigmoidal Neuronal Adaptive Plasticity (SNAP) an artificial approximation to Long-Term Potentiation for ANNs by having the weights follow a sigmoidal growth behaviour allowing the weights to consolidate and stabilize when they reach sufficiently large or small values. We then compare SNAP to linear weight growth and exponential weight growth and see that SNAP completely prevents the forgetting of previous tasks for Hebbian Learning but not for SGD-base learning.", "sections": [{"title": "1 Introduction", "content": "Continual learning is a remarkable human ability that allows for the sequential acquisition of new tasks while minimizing disruptions to previously learned knowledge. This capability supports the accumulation of skills and information throughout one's lifetime. However, artificial neural networks, particularly those trained with standard gradient descent methods, struggle with this process, often suffering from catastrophic forgetting-where new learning significantly degrades performance on earlier tasks [9].\nTraditional deep learning approaches assume training data are independent and identically distributed (i.i.d.), which clashes with the sequential nature of continual learning [3]. Even in humans, training on i.i.d. data can lead to suboptimal performance, suggesting that conventional models may not effectively replicate the learning dynamics observed in biological systems [1, 2].\nBoth Hebbian Learning and Stochastic Gradient Descent (SGD) trained models employ what we will call linear weight growth. By linear weight growth we mean that the size of the of the weight update"}, {"title": "2 Related Works", "content": "The challenge of continual learning has been extensively studied, with various approaches proposed for networks with fixed capacity. These methods can generally be classified into three main categories: replay, regularization-based, and parameter isolation [7]. Replay methods, inspired by the brain's episodic replay during sleep and rest, periodically revisit stored samples during or after learning a new task, effectively rehearsing previous knowledge [6]. Previous attempts at avoiding catastrophic forgetting with Hebbian Learning have used pseudo-replay methods [8]. Regularization-based methods draw inspiration from the brain's synaptic meta-plasticity, adjusting each synaptic weight based on its estimated importance, as determined by other techniques [4]. Lastly, parameter isolation methods allocate specific model parameters to different tasks, allowing for specialization without interference [11]. SNAP effectively uses the weight strength to determine importance and can be considered an implicit regularization-based method. To the best of our knowledge, it is the first method which does not require any additional machinery which explicitly keeps track of previous learning, like stored past data, pseudo-patterns, or past weights to prevent catastrophic forgetting."}, {"title": "2.1 Catastrophic Forgetting", "content": "The challenge of continual learning has been extensively studied, with various approaches proposed for networks with fixed capacity. These methods can generally be classified into three main categories: replay, regularization-based, and parameter isolation [7]. Replay methods, inspired by the brain's episodic replay during sleep and rest, periodically revisit stored samples during or after learning a new task, effectively rehearsing previous knowledge [6]. Previous attempts at avoiding catastrophic forgetting with Hebbian Learning have used pseudo-replay methods [8]. Regularization-based methods draw inspiration from the brain's synaptic meta-plasticity, adjusting each synaptic weight based on its estimated importance, as determined by other techniques [4]. Lastly, parameter isolation methods allocate specific model parameters to different tasks, allowing for specialization without interference [11]. SNAP effectively uses the weight strength to determine importance and can be considered an implicit regularization-based method. To the best of our knowledge, it is the first method which does not require any additional machinery which explicitly keeps track of previous learning, like stored past data, pseudo-patterns, or past weights to prevent catastrophic forgetting."}, {"title": "3 Theory", "content": "Let $W_{ij}$ be the synaptic weight linking presynaptic neuron j to postsynaptic neuron i in an ANN. For example, in the case of an MLP (without bias terms) with ReLU activation where neuron i is on layer l + 1 with activation value $h_i^{l+1}$ and neuron j, on layer l, has activation value $h_j^l$ we have\n$h_i^{l+1} = ReLU(\\sum_j W_{ij}h_j^l)$. Let us also assume for the sake of simplicity that the weights are positive.\nGiven that the weight is initialized with value $W_{ij}^{(0)}$ and given a learning algorithm and data which give a weight update $\\delta W_{ij}^{(t)}$ at training step t, then with standard machine learning we have that the"}, {"title": "4 Experiments", "content": "We train an MLP with one hidden layer (cf. section A.1 for more details on the architecture) using either Hebbian Learning (cf. section A.4 for more details on our implementation of Hebbian Learning) or SGD with cross-entropy loss, on i.i.d. datasets (MNIST and FashionMNIST).\nFor Hebbian Learning, we can see from Fig. 2 that as long as we choose the right hyperparameter \u03bb (which controls the strength of lateral inhibition cf. section A.4 for more details) all types of weight growth can performe roughly equally well in the i.i.d. setting. The same is true for the SGD trained network (cf. table 6)."}, {"title": "4.1 Experiment 1: I.I.D. Data", "content": "We train an MLP with one hidden layer (cf. section A.1 for more details on the architecture) using either Hebbian Learning (cf. section A.4 for more details on our implementation of Hebbian Learning) or SGD with cross-entropy loss, on i.i.d. datasets (MNIST and FashionMNIST).\nFor Hebbian Learning, we can see from Fig. 2 that as long as we choose the right hyperparameter \u03bb (which controls the strength of lateral inhibition cf. section A.4 for more details) all types of weight growth can performe roughly equally well in the i.i.d. setting. The same is true for the SGD trained network (cf. table 6)."}, {"title": "4.2 Experiment 2: Sequential Task Learning", "content": "To test sequential task learning we turn both MNIST and FashionMNIST into sequential tasks by sequentially training the model on five tasks where task 1 trains only on images of classes 0 and 1,"}, {"title": "5 Conclusions", "content": "In this paper, we investigated sigmoidal weight growth as a neuro-inspired mechanism to prevent catastrophic forgetting in sequential task learning.\nHebbian learning naturally suffers slightly less than SGD-trained networks from catastrophic forgetting, but still suffers from it enough that it cannot train successfully on many sequential tasks.\nWe chose the value of 80% accuracy because with the network sizes with which we experimented, 80% is close to, but slightly less than the top accuracies which we achieve."}, {"title": "A Supplementary Material", "content": "Our models follow a simple architecture, (Figure 5), that consists of three layers: input, hidden, and output."}, {"title": "A.1 Neural Net Architecture", "content": "Our models follow a simple architecture, (Figure 5), that consists of three layers: input, hidden, and output."}, {"title": "A.2 Notation Introduction", "content": null}, {"title": "A.3 Hyperparameter Specification", "content": "For all experiments, our models use the hyperparameters specified in Table 3. We evaluated the optimal values of n (as defined in Equation 11) and a for seven weight growth model configurations: linear-linear, sigmoid-linear neuron, sigmoid-linear synapse, exponential-linear neuron, exponential-exponential neuron, sigmoid-sigmoid neuron, and sigmoid-sigmoid synapse. These evaluations were conducted on both MNIST and FashionMNIST datasets.\nIn these configurations, the first term refers to the growth function applied to the hidden layer, and the second term to the output layer. Growth can be either neuron-wise (applied across all synapses"}, {"title": "I.I.D. Experiments Hyperparameters", "content": "For all experiments, our models use the hyperparameters specified in Table 3. We evaluated the optimal values of n (as defined in Equation 11) and a for seven weight growth model configurations: linear-linear, sigmoid-linear neuron, sigmoid-linear synapse, exponential-linear neuron, exponential-exponential neuron, sigmoid-sigmoid neuron, and sigmoid-sigmoid synapse. These evaluations were conducted on both MNIST and FashionMNIST datasets.\nIn these configurations, the first term refers to the growth function applied to the hidden layer, and the second term to the output layer. Growth can be either neuron-wise (applied across all synapses"}, {"title": "A.4 Hebbian Learning", "content": "During forward propagation, lateral inhibition\u2014a mechanism where excited neurons suppress their neighbors-promotes sparse, distinct activations, enhancing contrast in stimuli. Our model uses equation (8), where increasing the A parameter results in sparser hidden layer neuron activations."}, {"title": "A.4.1 Lateral Inhibition in Feedforward Propogation", "content": "During forward propagation, lateral inhibition\u2014a mechanism where excited neurons suppress their neighbors-promotes sparse, distinct activations, enhancing contrast in stimuli. Our model uses equation (8), where increasing the A parameter results in sparser hidden layer neuron activations.\n$a_i = ReLU\\left(\\sum_j W_{ij} x_j\\right)$    (7)\n$h_i = \\frac{a_i}{\\lambda \\cdot max_k(a_k)}$    (8)"}, {"title": "A.4.2 Weight Update Mechanism", "content": "Most existing approaches train neural network layers sequentially: first, the initial layer is trained on all the data, and then the outputs from this trained layer are used as inputs to the next layer, and so on. While this method may simplify training, we do not consider it realistic or practical for real-world applications where simultaneous learning is often required. Therefore, in our approach, we train all layers simultaneously, allowing the network to learn in a more integrated and biologically relevant manner.\nIn what follows, (pre-SNAP) weight updates use equation 9 to update their weights.\n$W_{ij} = \\alpha r_{ij},$    (9)\nwhere a is the learning rate and the learning rule prescribes $r_{ij}$.\nHidden Layer Weight Update Rule: The hidden layer employs Sanger's rule (11)[10], which extends the basic Hebbian Learning rule introduced in Equation (10)[5]. Basic Hebbian learning updates weights based on the product of the presynaptic activity $x_j$ and postsynaptic activity $h_i$, reinforcing the connections between co-active neurons.\n$r_{ij} = h_i x_j$    (10)\nSanger's rule builds on this by aiming to make the neurons represent orthogonal features. It se-quentially extracts principal components by subtracting the projection onto previously extracted components, as shown in Equation (11). The term $\\sum_{k=1}^{i-1} h_k w_{kj}$ represents the projection onto the previous outputs, ensuring each neuron's weight vector remains orthogonal to those of prior neurons."}, {"title": "A.5 Derivation of Weight Growth Updates", "content": "Assuming that we have\n$W_{ij}^{(T)} = \\sigma \\left(W_{ij}^{(0)} + \\sum_{t=1}^T \\delta W_{ij}^{(t)} \\right),$    (13)\nwhere $\\sigma(x) = \\frac{1}{1+e^{-x}}$ is the sigmoid function. Then we have that\n$W_{ij}^{(T)} - W_{ij}^{(T-1)} = \\sigma \\left(W_{ij}^{(0)} + \\sum_{t=1}^T \\delta W_{ij}^{(t)} \\right) - \\sigma \\left(W_{ij}^{(0)} + \\sum_{t=1}^{T-1} \\delta W_{ij}^{(t)} \\right)$    (14)\n$= \\left(1 - \\sigma \\left(W_{ij}^{(0)} + \\sum_{t=1}^{T-1} \\delta W_{ij}^{(t)} \\right) \\right) \\sigma \\left(W_{ij}^{(0)} + \\sum_{t=1}^{T-1} \\delta W_{ij}^{(t)} \\right) \\delta W_{ij}^{(T)} \\qquad (15)$\n$= \\left(1 - W_{ij}^{(T-1)}\\right) W_{ij}^{(T-1)} \\delta W_{ij}^{(T)},$    (16)\nwhere (14) is the first order expansion in the Taylor series, (15) uses the identity that the derivative of the sigmoid is $\\sigma'(x) = (1 - \\sigma(x))\\sigma(x)$, and (16) comes from using (13).\nSimilarly, if instead we wish to have exponential weight growth such that\n$W_{ij}^{(T)} = exp \\left(W_{ij}^{(0)} + \\sum_{t=1}^T \\delta W_{ij}^{(t)} \\right)$    (17)\nThen we have that\n$W_{ij}^{(T)} - W_{ij}^{(T-1)} = exp \\left(W_{ij}^{(0)} + \\sum_{t=1}^{T-1} \\delta W_{ij}^{(t)} \\right) \\delta W_{ij}^{(T)}$    (18)\n$= exp \\left(W_{ij}^{(0)} + \\sum_{t=1}^{T-1} \\delta W_{ij}^{(t)} \\right) \\delta W_{ij}^{(T)}$    (19)\n$= W_{ij}^{(T-1)} \\delta W_{ij}^{(T)},$    (20)\nwhere (18) is the first order expansion in the Taylor series, (19) uses the identity that the derivative of the exponential is the exponential, and (20) comes from using (17)."}, {"title": "A.6 SGD: Effect of Weight Growth on Forgetting", "content": "In order to see if having a sigmoidal weight growth could also help mitigate catastrophic forgetting when training with SGD, we repeated all our experiments but this time the $W_{ij}$ in Table 1 were obtained using SGD on cross-entropy loss rather through Hebbian learning. The network architecture stayed the same and the applied weight changes were still the $\\Delta W_{ij}$ of Table 1.\nAs can be seen from Fig. 6 and Fig. 7, having sigmoidal weight growth does not prevent catastrophic forgetting when learning with SGD, though it slows down the forgetting slightly compared to the usual linear weight growth."}]}