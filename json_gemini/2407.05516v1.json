[{"title": "Background", "authors": ["Jin Woo Lee", "Jaehyun Park", "Min Jun Choi", "Kyogu Lee"], "abstract": "While significant advancements have been made in music generation and dif-ferentiable sound synthesis within machine learning and computer audition, thesimulation of instrument vibration guided by physical laws has been underexplored.To address this gap, we introduce a novel model for simulating the spatio-temporalmotion of nonlinear strings, integrating modal synthesis and spectral modelingwithin a neural network framework. Our model leverages physical properties andfundamental frequencies as inputs, outputting string states across time and spacethat solve the partial differential equation characterizing the nonlinear string. Em-pirical evaluations demonstrate that the proposed architecture achieves superioraccuracy in string motion simulation compared to existing baseline architectures.", "sections": [{"title": "Introduction", "content": "The investigation of wave propagation along strings, encompassing both theoretical and experimentaldimensions, has persisted for well over a century [1, 2]. In the relentless pursuit of verisimilitude andexpressive fidelity in simulating wave phenomena, numerous studies have been investigated to bridgethe gap between theoretical underpinnings and empirical sound measurements [3]. Advancementsleveraging computational power to mimic the intricate physical processes in musical instrumentshave given rise to numerical sound synthesis, now a cornerstone in the field of virtual sound synthesis[4, 5]. Schwarz [6] presents a systematic study of parametric and physical models for music audiosynthesis. Parametric models include signal models, such as spectral modeling synthesis [7]. Physicalmodels encompass techniques such as modal synthesis, digital waveguides [8, 9], or finite-differencetime-domain (FDTD) methods [4, 10].\nOver recent years, the advancement of hardware acceleration for artificial intelligence has enabledthe emergence of numerous techniques for neural audio synthesis [11], including autoregressivegeneration [12], adversarial training [13] with phase coherence [14], and approximated physicalmodels [15]. The concept of differentiable digital signal processing (DDSP) was first introducedby Engel et al. [16], aiming to incorporate a known signal model into neural networks to achievea domain-appropriate inductive bias. While the DDSP model can be considered a differentiableversion of spectral modeling synthesis, a wide variety of works have explored the differentiableimplementation of other audio signal processing methods, such as the subtractive method [17],waveshaping [18], and frequency modulation [19, 20]. Subsequent research has demonstrated variousapplications of DDSP, including music performance synthesis [21], speech synthesis and voiceconversion [22, 23], and sound effect generation [24]. Renault et al. [25] extended DDSP to create apolyphonic synthesizer, explicitly modeling properties specific to piano strings, such as inharmonicityand detuning induced by string stiffness, based on a parametric model of these phenomena [26]. Thismodel efficiently synthesizes piano sound from MIDI input, achieving a high mean opinion score onnaturalness. However, it still shows room for improvement compared to sampling-based methods[27] and physical modeling methods [28].\nDespite the growing recognition of DDSP as a promising sound synthesis methodology, its extensionto physical modeling remains underexplored. In the context of musical sound synthesis, someattempts have been made to synthesize rigid-body contact sounds of arbitrary shapes using neuralnetworks supervised by finite-element method (FEM) solvers. Jin et al. [29, 30] propose a neuralnetwork that predicts contact sounds from voxelized objects, inspired by the modal technique thatsynthesizes sound using eigenvalues and eigenvectors. Diaz et al. [31] leverage a differentiableinfinite impulse response filter to synthesize contact sounds from rasterized occupancy grids in anend-to-end manner. These methods can interactively synthesize sounds for various contact conditionsand materials with notable efficiency, circumventing the need for an offline optimization processtypical of modal techniques. However, these methods, which resort to the FEM solver, are vulnerablein modeling the dynamic behavior (e.g., glissando, vibrato) or in simulating the motion of the object.This vulnerability demands the need for further research to enhance the capability of neural networksin physical modeling for more dynamic and complex sound synthesis scenarios.\nIn this regard, we propose a novel model for simulating the spatio-temporal motion of nonlinearstrings, integrating modal synthesis and spectral modeling within a neural network framework. Theproposed model leverages physical properties and fundamental frequencies as inputs, outputtingstring states across time and space that solve the partial differential equation (PDE) characterizing thenonlinear string. Empirical evaluations demonstrate that the proposed architecture achieves superioraccuracy in string motion simulation compared to the baseline architectures. The main contributionsare as follows:\n\u2022 We present differentiable modal synthesis for physical modeling (DMSP) that simulates dynamicnonlinear string motion by synthesizing sound using the physical properties of the string.\n\u2022 To the best of our knowledge, this is the first approach that is differentiable and can synthesize themotion and the sound of a musical string with a dynamic control over the pitch and the materialproperties.\n\u2022 We provide an extensive empirical evaluation demonstrating the importance of modal decomposi-tion and the proper choice of loss function."}, {"title": "Background", "content": "2.1 Physical Modeling of Musical String Instrument\nLinear Damped Stiff String. The string model discussed in this paper is a damped nonlinear stiffstring. To introduce the nonlinear string, we first formulate the governing equations for the dampedlinear stiff string system and derive the corresponding modal solution.\n$\\partial_{tt}u = \\gamma^2\\partial_{xx}u - \\kappa^2\\partial_{xxxx}u - 2\\sigma_0\\partial_t u$ (1)\nThe linear string of its length L, vibrating with wave speed \u03b3, stiffness \u03ba, and frequency-independentdamping factor \u03c3\u2080, is described by Equation 1. Given the initial conditions (IC) for x \u2208 \u03a9 =\n[-L/2, +L/2] as u(x, 0) = u\u2080(x) and \u2202\u209cu(x, 0) = 0, and appropriate boundary conditions (BC),the corresponding solution u(x, t) represents the motion of a damped linear stiff string. Particularly,for a clamped boundary condition, i.e., u(\u00b1L/2,t) = \u2202\u2093u(\u00b1L/2,t) = 0 for all t \u2208 [0,\u221e), ananalytic solution can be obtained as follows.\n$\\begin{aligned}\nu(x, t) &=\\sum_{n=1}^{\\infty} X_{n}(x) T_{n}(t) \\\\X_{n}(x) &=c_{1}\\left(\\sin \\mu_{n} x-\\frac{\\sin \\mu_{n} L / 2}{\\sinh v_{n} L / 2} \\sinh v_{n} x\\right)+c_{2}\\left(\\cos \\mu_{n} x-\\frac{\\cos \\mu_{n} L / 2}{\\cosh v_{n} L / 2} \\cosh v_{n} x\\right) \\\\T_{n}(t) &=e^{-\\sigma_{0} t} \\cos \\left(\\sqrt{\\mu_{n}^{4} \\kappa^{2}+\\mu_{n}^{2} \\gamma^{2}-\\sigma_{0}^{2}} t\\right)\\end{aligned}$ (2a) (2b) (2c)\nThe derivation of Equation 2 can be found in Appendix C. The allowed values of \u00b5\u2099 and \u03bd\u2099 aredetermined by the boundary conditions, while the coefficients c\u2081 and c\u2082 are determined using the initialcondition \u2211\u2099\u208c\u2081\u221e X\u2099(x) = u\u2080(x). Determining these values typically requires an offline numericalsolving process, where the obtained values can be stored in memory for real-time computation ofu(x, t). The stiffness modeled by the 4th order derivative induces a hyperbolic solution, resultingin non-integer multiples of the mode frequencies \u03c9\u2099, which leads to physical inharmonicity. Thedamping factor \u03c3\u2080 causes an exponential decay in the temporal amplitude.\nNonlinear Damped Stiff String. The generalization of the linear waveEquation 1 to nonlinear string vibrations was first introduced by Kirchhoff[32] and Carrier [33]. The Kirchhoff\u2013Carrier system models elastic stringsin two dimensions, and when extended so that transverse and longitudinalmotions are coupled, phantom partials can be exhibited, resulting in a richertimbre [34]. A model of such planar string vibration is as follows [35, 36].\n$\\begin{aligned}\\partial_{t t} u=\\gamma^{2} \\partial_{x x} u-\\gamma^{2} \\frac{\\alpha}{2} \\partial_{x}\\left(\\partial_{x} u\\right)^{2}-\\kappa^{2} \\partial_{x x x x} u-2 \\sigma_{0} \\partial_{t} u+2 \\sigma_{1} \\partial_{t} \\partial_{x x} u \\\\ \\partial_{t t} \\zeta=\\gamma^{2} \\partial_{x x} \\zeta-\\gamma^{2} \\frac{\\alpha}{2} \\partial_{x}\\left(\\partial_{x} \\zeta^{2}\\right)-2 \\sigma_{0} \\partial_{t} \\zeta+2 \\sigma_{1} \\partial_{t} \\partial_{x x} \\zeta\\end{aligned}$ (3a) (3b)\nHere, u(x, t) and \u03b6(x, t) represent the transverse and longitudinal displacements of a string, respec-tively, for all (x, t) \u2208 \u03a9 \u00d7 [0,\u221e). q = \u2202\u2093u and p = \u2202\u2093\u03b6 serves as the auxiliary coupling system, as\u2202\u209cq = \u2202\u2093\u2202\u209cu and \u2202\u209cp = \u2202\u2093\u2202\u209c\u03b6 [37]. A more detailed background on the derivation of Equation 3can be found in Appendix B. The boundary condition, which may vary depending on the string beingmodeled, is chosen to be that of the clamped boundary condition:\nu(x,t) = \u2202\u2093u(x,t) = 0, \u2200(x, t) \u2208 \u2202 \u00d7 [0,\u221e). (4)\nGiven an initial condition u\u2080 := u(x, 0) defined on x \u2208 \u03a9, the solution u(x, t) associated with thecondition of Equation 4 simulates the motion of the string for physical modeling and sound synthesisof string instruments. Due to the coupling between Equation 3a and Equation 3b, the obtainedsolution exhibits features found in elastic strings, such as pitch glide and phantom partials. Thesefeatures become more pronounced for larger displacements and are difficult to approach separately asin the linear case. The solution can be approximated through various physical modeling techniquessuch as finite-difference time-domain [38], digital waveguides [39], or functional transformationmethod [40]."}, {"title": "Differentiable Digital Signal Processing", "content": "In the field of neural networks, numerous audio researchers have been engaged in the development oftechniques that leverage the ease of automatic gradient backpropagation in neural networks for thepurpose of audio parameter estimation. To address the challenge of estimating the latent parameters ofa sound, some approaches implement the synthesis part as-is using automatic differentiation package[20, 43] so that the gradient can back-propagate through it to update the parameters directly, while themajority of approaches train neural networks to estimate the parameters in an auto-encoder framework[16, 22, 47]. As one of the most seminal studies of the latter approach, DDSP is widely used toefficiently synthesize nonlinear and dynamic sounds. Based on the spectral modeling synthesisframework, the time-domain signal is modeled via short-time Fourier transforms (STFTs) dividedinto deterministic (harmonic) and stochastic (noisy) parts to synthesize the sound. As the causality ofSTFT frames is modeled through gated recurrent units (GRUs), DDSP requires as many recursionsas N\u209c, the number of frames. The harmonics of a DDSP are given by an integer multiple of thefundamental frequency (f\u2080), and the noise is synthesized from filtered noise. These DDSPs, whilestill a remarkable advancement, have strong structural constraints on the deterministic part to captureenough perceptually rich tones such as inharmonicity due to stiffness or phantom partials due tononlinearity. A study by Renault et al. [25] also points this out, and uses the parametric model [26]for inharmonicity and detune, but there is room for improvement as it is an approximation model thatrelies on instrument-specific modifiers rather than reflecting stiffness physics."}, {"title": "Differentiable Modal Synthesis for Physical Modeling (DMSP)", "content": "This section introduces a novel differentiable nonlinear string sound synthesizer. Table 1 provides asummary of the methods discussed. While modal synthesis stands out for its efficiency, it is solelyapplicable to linear models and necessitates pre-computation to determine the number of modesdenoted as N\u2098. On the other hand, FDTD computes highly nonlinear and dynamic solutions butdemands a substantial computational load due to iterative updates across both temporal (N\u209c) andspatial (N\u2093) samples. In contrast, differentiable audio processing methods offer efficient nonlinearsound synthesis, typically leveraging a smaller number of frames (N\u209c) compared to the total timesamples (N\u209c). However, they often lack physical controllability. In this regard, we propose DMSP,which approximates the solution of Equation 3 efficiently by leveraging Equation 2 in the form ofneural networks. Figure 1 provides a visual depiction of the DMSP.\n3.1 Problem Statement\nThe objective of this study is to establish a mapping from the parameter space to the solution space,utilizing a finite set of observations comprising parameter-solution pairs from this mapping. Wedelineate this objective as follows: Consider the partial differential equation depicted in Equation 3,applicable for (x, t) within \u03a9 \u00d7 [0, \u221e), with clamped boundary conditions as specified in Equation 4,where \u03a9 represents a bounded domain in \u211d\u1d3a. We assume that the solution u : \u03a9 \u00d7 [0, \u221e) \u2192 \u211dresides within the Banach space U. For a given PDE parameter p \u2208 P and initial condition u\u2080 \u2208 U,let S : P \u2192 U denote a nonlinear map, specifically, the FDTD numerical solver tailored to the contextof this study. Assume that we are provided with observations {p\u207d\u2071\u207e, u\u207d\u2071\u207e}\u1d62\u208c\u2081\u1d3a, where p\u207d\u2071\u207e comprisesindependent and identically distributed (i.i.d.) samples drawn from a probability measure supportedon P, and u\u207d\u2071\u207e = S(p\u207d\u2071\u207e) potentially contains noise. Our goal is to construct an approximation of Sdenoted as S\u2091 : P \u2192 U, and select parameters \u03b8\u2217 \u2208 \u211d\u1d3a\u03b8 such that S\u03b8\u2217 \u2248 S. Leveraging S\u2091, one cancompute the solution \u00fb = S\u03b8(p) corresponding to a new parameter p \u2208 P. By specifying values forx and t, one can then either synthesize the sound of the string picked-up (also referred to as read-out)at a specific location x\u2080 as \u00fb(x\u2080, t), or simulate the motion of the string by concatenating \u00fb(x, t)across all x \u2208 \u03a9. In practice, \u03a9 and [0,\u221e) are bounded and discretized to form an evenly distributedspatio-temporal grid as \u211d\u1d3a\u02e3 \u00d7 \u211d\u1d3a\u1d57 \u2282\u2229 \u00d7 [0, \u221e), where the spatial grid samples are uniformlydistributed in space according to the length of the equally spaced intervals L/N\u2093 and the temporalgrid samples uniformly distributed according to the frequency of a fixed audio sampling rate."}, {"title": "Network Architecture", "content": "Parameter Encoder. To effectively capture material features inherent in the PDE parameter values,the parameter encoder leverages a random Fourier feature (RFF) layer [48, 49]. Given T60 frequenciesf\u1d40\u2076\u2070 and their corresponding times t\u1d40\u2076\u2070 for i = 1, 2, the frequency-dependent damping coefficients\u03c3\u2080 (and \u03c3\u2081, if applicable) are derived using Equation 24. Subsequently, the frequency-independentdamping factor exp(\u2212\u03c3\u2080t) is computed, explicitly multiplied by the mode amplitudes. All PDEparameters p = {\u03ba, \u03b1, \u03c3\u2080, \u03c3\u2081} \u2208 \u211d\u2074 \u2282P are encoded into a feature vector h \u2208 \u211d\u2074\u00d7\u1d48 with a Fourierembedding size of d = 256.\nAM and FM Blocks. As illustrated in Figure 3, DMSP employs amplitude modulation (AM) andfrequency modulation (FM) modules to modulate the mode frequencies and amplitudes of the linearsolution, as depicted in Equation 2, to synthesize the solution of the nonlinear wave described inEquation 3. We utilize two multilayer perceptrons (MLPs) for the modulation layers. Althougha simpler and perhaps more conventional choice of architecture would be a GRU, to the decoderarchitecture of DDSP [16], we choose MLPs for their slightly better empirical results. It's noteworthythat DDSP decodes the sinusoidal frequency envelope with fixed frequency values. In contrast, DMSPdecodes both the envelope and the frequency values independently, employing two distinct MLPblocks, namely AM and FM.\nMode Estimator. As detailed in subsection 2.1, determining allowed values for mode frequenciesand amplitudes, corresponding to specific initial and boundary conditions of the string, typicallyinvolves a root-finding process conducted offline. While these numerical solvers offer high accuracyup to a specified iterative threshold, they necessitate pre-computation, as illustrated in Table 1. Themode estimator module within DMSP estimates the modes from the initial condition using an MLP.The initial condition is parameterized by a pluck position p\u2093 and its peak amplitude p\u2090. Subsequently,the physical properties \u03ba, \u03b3, \u03c3\u2080, and \u03c3\u2081 are encoded using a random Fourier feature (RFF) layer. Themode frequencies and amplitudes are then estimated by the MLP, followed by the application ofsuitable scaling activations. It's pertinent to note that the mode estimator operates independently andis trained separately from the other modules. During training, the ground truth modes (computedusing the modal decomposition method) are fed into the AM and FM blocks, ensuring accuratesynthesis while training the synthesis part of the model."}, {"title": "Loss Function", "content": "In training DMSP, we employ a combination of four loss terms: (1) waveform l\u2081 loss that measuresthe L\u2081 discrepancy between the synthesized waveform and the ground truth waveform, (2) Multi-scalespectral (MSS) loss that captures spectral differences across multiple scales, ensuring fidelity inspectral representation, and (3) Pitch loss (Lf\u2080) that penalizes deviations from the ground truthfundamental frequency (f\u2080). Optimizing the frequency parameters of sinusoidal oscillators viagradient descent over an audio loss function poses a challenge due to the non-convex nature ofthe optimization problem, as highlighted in various studies [50, 51]. Damped sinusoids offer aworkaround for the issue of non-convexity concerning frequency parameters [51], or alternativemetrics are proposed to mitigate the risk of falling into bad local minima [52, 53]. In our approach,we adopt a parameter regression joint training strategy, akin to the pre-training phase of the workby Engel et al. [54]. Among the output mode frequencies, we optimize one frequency componentto match the target fundamental frequency (f\u2080) annotated using CREPE [55]. As the comparisonmodels are all aware of the frequency of the mode they are outputting, the models are updated tominimize the discrepancy between the fundamental frequency estimated as the lowest one of themodes (denoted by f\u2080) and the ground-truth f\u2080 of the FDTD-simulated audio estimated via CREPEas Lf\u2080 = || f\u2080 - f\u2080||\u2081."}, {"title": "Experiments", "content": "This section introduces the empirical investigation that seeks to find the answers to the followingquestions: (1) how much does the modal synthesis-based inductive bias of a neural network advantagephysical modeling sound synthesis, (2) how much does it improve nonlinearity and what physicalanalysis is possible, and (3) to what extent are techniques required for training such model."}, {"title": "Experimental Setup", "content": "Dataset. We use the StringFDTD-Torch [43], the open-source nonlinear string simulator, to computethe solution of the Equation 3 in a temporal sampling rate of 48 kHz and a spatial sampling rate. Thesolution is upsampled to a spatial resolution of 256 using a bivariate spline approximation over arectangular spatio-temporal mesh upto the 5th order degree. We simulate 10263 different strings byrandomly augmenting the material properties, e.g., \u03ba, \u03b1, \u03c3\u2080, and \u03c3\u2081, with various plucking profiles\u03c6\u2080. The simulation results in a total amount of 729.8 hours of wave files that corresponds to the1-sec string sounds picked up at 256 different positions for each string. For the test data, 715 stringsare newly synthesized with the parameters sampled in i.i.d. The test data consists of 336 linear(\u03b1 = 1) and 379 nonlinear (\u03b1 > 1) strings, each of which has a 256 spatial grid size, resulting inapproximately 50 hours of wave files. Table 4 specifies the range of the sampled PDE parameters.\nBaselines. As the first attempt to tackle the task of neural audio synthesis from the physical properties,we compare our proposed model to three other models. We consider three baselines, namely: Modaland DDSPish, and DDSPish without FM. Modal synthesis is the linear wave solution as in Equation 1,where the modal frequencies and the shape functions are pre-computed. DDSPish is a neural networkbased on the harmonic plus noise model, similar to DDSP. Yet, this -ish suffix emphasizes that thismodel is different from the DDSP model [16]. DDSPish does not have a reverb module but insteadadds frequency modulation, and most notably it has a parameter encoder that allows generatingsounds from physical parameters. Please see Appendix D for more details of the baselines.\nEvaluation Metrics. We report results on three metrics, signal-distortion-ratio (SDR), scale-invariantsignal-distortion-ratio (SI-SDR) [56], multi-scale spectral (MSS) distance, and the pitch difference inHz. The MSS metric for the evaluation was computed using the short-time Fourier transformation(STFT) with 513 number of frequency bins and the hop size of 256 samples. The Pitch metric iscomputed as the l\u00b9 norm of the difference between f\u2080 and f\u2080."}, {"title": "Results", "content": "Differentiable Sound Synthesis. The efficacy of DMSP is studied as shown in Table 2. First, themodal synthesis method calculates a linear solution for a damped stiff string, and the mode forthe linear test set is calculated offline. The discrepancy between the outcomes of modal synthesisand FDTD in the linear case can be attributed to the absence of frequency-dependent damping inEquation 1. In other words, the frequency information serves as an oracle for the Modal, as evidencedby its lowest pitch score, but the decay of amplitude over time is not sufficiently modeled, which iswhere the remaining models demonstrate superior performance. Considering the DDSPish models,the MSS is approximately 1.6 dB ahead of the DMSPs, but the difference can reach up to 44 dBin the case of the SI-SDR. It is worth noting that \u03b1 is uniformly sampled within the range (1,25)for the training data, falling into the category of the nonlinear strings. In the case of nonlineartest set, the difference between the modal solution and the FDTD solution becomes larger. On theother hand, DDSPish models based on spectral modeling synthesis but learned without using anymodal information show the lowest performance. The superiority of DMSP is even more pronouncedin the nonlinear case. While Modal, which can only cover the solution to the linear case, showsattenuated performance, the DMSPs demonstrate the best performance in all metrics. In particular,DMSP-Hybrid, which precomputes the mode frequency like Modal, performs FM and AM for thenonlinear solution, showing an SI-SDR improvement of nearly 31 dB and an MSS improvement"}, {"title": "Controllable Physical Simulation", "content": "The quantitative scores forvarious physical condition parameters are visualized in Figure 5.Trends show how the results of Modal synthesis and DMSPvary for different pickup positions (x), stiffness (\u03ba), tension(\u03b1), pluck amplitude (p\u2090), and pluck position (p\u2093). Of these,\u03b1 and p\u2090 in particular are known to increase the nonlinearityof the string as they increase in magnitude, which can be seenby the lower Modal synthesis scores. For DMSP, we see anoverall improvement in the score, with a lower propensity fornonlinearity. Figure 4 depicts the simulated state of the stringas the pluck position in the initial condition is varied. TheFigure 5: Objective scores overresults synthesized by DMSP can reconstruct a very accurate physical parameters.\ninitial condition, similar to the results simulated by FDTD. Thevibration propagating through time along the string exhibits a distinct behavior contingent upon theinitial condition. FDTD employs a recursive calculation of displacement, necessitating a number ofiterations equal to the number of samples at the audio sampling rate. In contrast, DMSP is capable ofobtaining the desired displacement in both time and space simultaneously."}, {"title": "String Sound Synthesis", "content": "Spectrograms of the test samples are visualized in Figure 6. The instan-taneous frequencies are identified in a rainbow color map, where the color intensities represent thelogarithmic magnitude of the power spectra. The FDTD-simulated spectrogram clearly shows pitchglide and phantom partials at the beginning of the pluck. In contrast, modal synthesis methods thatmodel linear solutions do not show these nonlinear characteristics. The DDSPish-XFM model employsa harmonic pitch skeleton comprising integer multiples of f\u2080, thereby precluding the inharmoicitiesresulting from stiffness. The DDSPish model demonstrates enhanced mode estimation capabilitiesthrough learned FM, which modulates the harmonic pitch skeleton to be inharmonic. However,there is scope for further improvement in frequency estimation, particularly in instances wheret the FM learning process is unstable for high frequencies. On the other hand, the DMSP model,which estimates the mode frequency and amplitude from u\u2080, shows an improved pitch skeleton andstable frequency estimation. The DMSP-Hybrid model, which learns to AM and FM the sinusoidaloscillators of the modal solution that requires mode precomputation, shows the most similar resultsto FDTD."}, {"title": "Ablation Study", "content": "The ablation study on the choice of the training loss functions is presented in Table 3.Overall, for linear strings, the performance does not vary much depending on which loss is used,especially for pitch. This is due to the alpha masking applied to the FM block, which is designed toprevent FM from occurring when alpha is 1. This is the main factor that determines the nonlinearityof the string. For AM, there is no masking depending on alpha, so the remaining metrics except pitchdo vary. For nonlinear data, the learning results vary depending on the loss design.\nMotion Synthesis. The main advantage of this neural net based on modal synthesis is that it cansynthesize not only sound but also motion, which is one of the main characteristics of physicalmodeling techniques. In particular, the DMSP is able to visualize the corresponding string motionas a video, despite the fact that the receptive field and computational complexity required to obtaina solution u(x, t) for a single spatio-temporal point is of order 1, as shown in Table 1, when thesesolutions are pooled for a given x \u2208 \u03a9 and t \u2208 [0,1), the corresponding string motion can bevisualized as a video. Figure 7 visualizes the resulting transverse displacement of the string overtime (horizontal axis) and space (vertical axis). As mentioned earlier, the transverse displacement ofthe FDTD is coupled to the longitudinal motion, which is why it differs from the Modal synthesisoutput, which synthesizes the motion of a linear damped stiff string. The results output by DMSPshow improved accuracy."}, {"title": "Conclusion", "content": "We present a novel neural network-based method that efficiently simulates plucked string motions.Our differentiable modal synthesis for physical modeling (DMSP) can simulate a dynamic nonlinearstring motion by synthesizing the sound using the physical properties of the string. It is an efficientapproximation of existing physical modeling methods. We demonstrate the efficacy of training theneural network using mode frequency information by extending the DDSP with a modal synthesispipeline. This opens the door to a new field of differentiable audio signal processing, extending itto the field of physical modeling for musical sound synthesis. While the proposed method offerscontrol over several physical parameters of a musical instrument, it still faces limitations in terms ofgeneralizing to physical parameters and sounds in real-world measurements. This study paves the wayfor future research in this area. To the best of our knowledge, this is the first study to simultaneouslysynthesize sound and motion from the properties of a stringed instrument."}, {"title": "Proof of the Linear Damped Stiff String Solution", "content": "Proposition 1. A solution to the damped linear stiff string model Equation 1 with a clamped boundarycondition u(\u00b1L/2,t) = ux(\u00b1L/2,t) = 0 and the initial condition given as u(x, 0) = u\u2080(x) anddu(x, 0) = 0 can be expressed as\n$\\begin{aligned}u(x, t) &=\\sum_{n=1}^{\\infty} X_{n}(x) T_{n}(t) \\\\X_{n}(x) &=c_{1}\\left(\\sin \\mu_{n} x-\\frac{\\sin \\mu_{n} L / 2}{\\sinh v_{n} L / 2} \\sinh v_{n} x\\right)+c_{2}\\left(\\cos \\mu_{n} x-\\frac{\\cos \\mu_{n} L / 2}{\\cosh v_{n} L / 2} \\cosh v_{n} x\\right) \\\\T_{n}(t) &=e^{-\\sigma_{0} t} \\cos \\left(\\sqrt{\\mu_{n}^{4} \\kappa^{2}+\\mu_{n}^{2} \\gamma^{2}-\\sigma_{0}^{2}} t\\right)\\end{aligned}$\nProof. As it is hinted in Equation 2a, the procedure to derive Equation 2b and Equation 2c uses themethod of separation of variables. The derivation consists of three main steps that start by trying theansatz u(x, t) = X(x)T(t). Substituting this ansatz into the Equation 1 gives\n$\\frac{\\partial^{2}}{\\partial x^{2}} X(x) \\frac{\\partial^{4}}{\\partial x^{4}} X(x) T^{\\prime\\prime} T^{\\prime}+2 \\sigma_{0} \\frac{X}{X}-\\frac{X}{X}=\\frac{T}{T} \tbinom{<}{>} 0$\nwith s \u2208 \u211d as the separation constant.\n1. Solving for T.\nT'' + 2\u03c3\u2080T' \u00b1 s\u00b2T = 0 (6)\nRoots of the characteristic polynomial of this equation are \u03b2\u00b0 = \u2212\u03c3\u2080 \u00b1 \u221as\u00b2 = 5\u00b2. Threesolutions are available:\n\u2022 Overdamping (\u03c3\u2642 > s\u00b2): T = A\u2081e\u03b2+t + A2e\u03b2-t\n\u2022 Critical damping (\u03c3\u00b2 = s\u00b2): T = (A1 + A2t)e-rot\n\u2022 Underdamping (\u03c3\u00b2 < 5\u00b2): Rewrite the roots as \u03b2+ = \u2212\u03c3\u2080 + iw and \u03b2_ = \u2212\u03c3\u2080 \u2013 \u1f62with w = \u221a2 \u2013 \u03c3\u03be, \u03ce = \u221a2 + \u03c3\u00b2, then\nT = e-\u03c3\u2080t(A\u2081ei\u03c9t + Aze-\u03c9t) (7)\nThe initial condition dru(x, 0) = 0 implies A2 = 0 yielding the real solution of theform T = A\u2081e-rot coswt. This implies that the only valid root is \u03b2+ = \u2212\u03c3\u03bf + \u03af\u03c9,hence it is enough to consider the -s case only, in the Equation 5.\nThis work only considers the underdamped case where the \u03c3\u2080 is sufficiently small, as itshould be in a reasonable string model for any musical purposes.\n2. Solving for X.\n$\\frac{\\partial^{4}}{\\partial x^{4}} X(x) = \\frac{\\gamma^2}{\\kappa^2}\\frac{\\partial^2}{\\partial x^{2}} X(x)+\\frac{s^2}{\\kappa^2}X = 0$ (8)\nSubstitute l = \u03b3\u00b2/2\u03ba\u00b2 and m = s\u00b2/\u03ba\u00b2. The roots of the characteristic polynomial for thisequation are \u00b1\u221al \u00b1 \u221al\u00b2 + m where l \u2013 \u221al\u00b2 + m \u2264 0. Therefore the solution is rewrittenas\nX(x) = B\u2081 sin \u00b5\u03b1 + B2 sinh vx + B3 cos \u03bcx + B4 cosh vx (9)\n\u221a\u221al2 + m + l. By applying the boundary conditionu(L/2,t) = 0 to the even and odd functions each, then obtain\n$\\begin{aligned}&B_{2}=-\\frac{\\sin \\mu \\frac{L}{2}}{\\sinh v \\frac{L}{2}} B_{1} \\text { and } B_{4}=-\\frac{\\cos \\mu \\frac{L}{2}}{\\cosh v \\frac{L}{2}} B_{3} \tbinom{}{}\\\\&X(x)=B_{1}\\left(\\sin \\mu x-\\frac{\\sin \\mu \\frac{L}{2}}{\\sinh v \\frac{L}{2}} \\sinh v x\\right)+B_{3}\\left(\\cos \\mu x-\\frac{\\cos \\mu \\frac{L}{2}}{\\cosh v \\frac{L}{2}} \\cosh v x\\right).\\end{aligned}$ (11)"}, {"title": "Finding allowed values that satisfy the conditions", "content": "Substituting the ansatz by Equation 7 and Equation 11 summarizes the solution as\n$\\begin{aligned"}, "u(x, t) &=e^{-\\sigma_{0} t} \\cos \\left(\\sqrt{\\mu^{2} \\kappa^{2}+\\mu^{2} \\gamma^{2}-\\sigma_{0}^{2}} t\\right) \\\\&\\times \\left[c_{1}\\left(\\sin \\mu x-\\frac{\\sin \\mu \\frac{L}{2}}{\\sinh v \\frac{L}{2}} \\sinh v x\\right)+c_{2}\\left(\\cos \\mu x-\\frac{\\cos \\mu \\frac{L}{2}}{\\cosh v \\frac{L}{2}} \\cosh v x\\right)\\right] \\\\&\\text { As mentioned earlier, the coefficients } c_{1}=A_{1} B_{1} \\text { and } c_{2}=A_{1} B_{3} \\text { are determined by the } \\\\&\\text { allowed values that satisfy the initial condition } \\sum_{n=1}^{\\infty} X_{n}(x)=u_{0}(x) \\text { . To determine the } \\\\&\\text { allowed values of } \\mu \\text { , apply the boundary condition } u(L / 2, t)=u_{x}(L / 2, t)=0 \\text { to the even } \\\\&\\text { function that gives } \\\\&B_{3} \\cos \\mu \\frac{L}{2}=-B_{4} \\cosh v \\frac{L}{2} \\text { and } -\\mu B_{3} \\sin \\mu \\frac{L}{2}=-v B_{4} \\sinh v \\frac{L}{2} \\\\&\\text { or alternatively, } \\\\&\\mu \\tan \\mu \\frac{L}{2}=-v \\tanh v \\frac{L}{2} \\\\\\&\\text { Similarly, applying the same boundary condition to the odd function gives } \\\\&B_{3} \\sin \\mu \\frac{L}{2}=-B_{4} \\sinh v \\frac{L}{2} \\text { and } \\left(\\mu B_{3} \\cos \\mu \\frac{L}{2}=-v B_{4} \\cosh v \\frac{L}{2}\\right) \\\\&\\text { or equivalently, } \\\\&\\mu \\tan \\mu \\frac{L}{2}=-v \\tanh v \\frac{L}{2} \\\\\\&\\text { By finding the values of } \\mu \\text { and } v=\\sqrt{\\mu^{2}+2 l} \\text { that satisfy the Equation } 14 \\text { and Equation } 16 \\text { as } \\\\\\&\\mu_{n} \\text { and } v_{n}, \\text { one can determine{\n    \"title\": \"Differentiable Modal Synthesis for Physical Modeling\nof Planar String Sound and Motion Simulation\",\n    \"authors\": [\n        \"Jin Woo Lee\",\n        \"Jaehyun Park\",\n        \"Min Jun Choi\",\n        \"Kyogu Lee\"\n    ],\n    \"abstract\":", "While significant advancements have been made in music generation and dif-ferentiable sound synthesis within machine learning and computer audition, thesimulation of instrument vibration guided by physical laws has been underexplored.To address this gap, we introduce a novel model for simulating the spatio-temporalmotion of nonlinear strings, integrating modal synthesis and spectral modelingwithin a neural network framework. Our model leverages physical properties andfundamental frequencies as inputs, outputting string states across time and spacethat solve the partial differential equation characterizing the nonlinear string. Em-pirical evaluations demonstrate that the proposed architecture achieves superioraccuracy in string motion simulation compared to existing baseline architectures.", "sections\": [\n        {\n            \"title\": \"Introduction", "content\": \"The investigation of wave propagation along strings, encompassing both theoretical and experimentaldimensions, has persisted for well over a century [1, 2]. In the relentless pursuit of verisimilitude andexpressive fidelity in simulating wave phenomena, numerous studies have been investigated to bridgethe gap between theoretical underpinnings and empirical sound measurements [3]. Advancementsleveraging computational power to mimic the intricate physical processes in musical instrumentshave given rise to numerical sound synthesis, now a cornerstone in the field of virtual sound synthesis[4, 5]. Schwarz [6] presents a systematic study of parametric and physical models for music audiosynthesis. Parametric models include signal models, such as spectral modeling synthesis [7]. Physicalmodels encompass techniques such as modal synthesis, digital waveguides [8, 9], or finite-differencetime-domain (FDTD) methods [4, 10].\nOver recent years, the advancement of hardware acceleration for artificial intelligence has enabledthe emergence of numerous techniques for neural audio synthesis [11], including autoregressivegeneration [12], adversarial training [13] with phase coherence [14], and approximated physicalmodels [15]. The concept of differentiable digital signal processing (DDSP) was first introducedby Engel et al. [16], aiming to incorporate a known signal model into neural networks to achievea domain-appropriate inductive bias. While the DDSP model can be considered a differentiableversion of spectral modeling synthesis, a wide variety of works have explored the differentiableimplementation of other audio signal processing methods, such as the subtractive method [17],waveshaping [18], and frequency modulation [19, 20]. Subsequent research has demonstrated variousapplications of DDSP, including music performance synthesis [21], speech synthesis and voiceconversion [22, 23], and sound effect generation [24]. Renault et al. [25] extended DDSP to create apolyphonic synthesizer, explicitly modeling properties specific to piano strings, such as inharmonicityand detuning induced by string stiffness, based on a parametric model of these phenomena [26]. Thismodel efficiently synthesizes piano sound from MIDI input, achieving a high mean opinion score onnaturalness. However, it still shows room for improvement compared to sampling-based methods[27] and physical modeling methods [28].\nDespite the growing recognition of DDSP as a promising sound synthesis methodology, its extensionto physical modeling remains underexplored. In the context of musical sound synthesis, someattempts have been made to synthesize rigid-body contact sounds of arbitrary shapes using neuralnetworks supervised by finite-element method (FEM) solvers. Jin et al. [29, 30] propose a neuralnetwork that predicts contact sounds from voxelized objects, inspired by the modal technique thatsynthesizes sound using eigenvalues and eigenvectors. Diaz et al. [31] leverage a differentiableinfinite impulse response filter to synthesize contact sounds from rasterized occupancy grids in anend-to-end manner. These methods can interactively synthesize sounds for various contact conditionsand materials with notable efficiency, circumventing the need for an offline optimization processtypical of modal techniques. However, these methods, which resort to the FEM solver, are vulnerablein modeling the dynamic behavior (e.g., glissando, vibrato) or in simulating the motion of the object.This vulnerability demands the need for further research to enhance the capability of neural networksin physical modeling for more dynamic and complex sound synthesis scenarios.\nIn this regard, we propose a novel model for simulating the spatio-temporal motion of nonlinearstrings, integrating modal synthesis and spectral modeling within a neural network framework. Theproposed model leverages physical properties and fundamental frequencies as inputs, outputtingstring states across time and space that solve the partial differential equation (PDE) characterizing thenonlinear string. Empirical evaluations demonstrate that the proposed architecture achieves superioraccuracy in string motion simulation compared to the baseline architectures. The main contributionsare as follows:\n\u2022 We present differentiable modal synthesis for physical modeling (DMSP) that simulates dynamicnonlinear string motion by synthesizing sound using the physical properties of the string.\n\u2022 To the best of our knowledge, this is the first approach that is differentiable and can synthesize themotion and the sound of a musical string with a dynamic control over the pitch and the materialproperties.\n\u2022 We provide an extensive empirical evaluation demonstrating the importance of modal decomposi-tion and the proper choice of loss function."], "content": "2.1 Physical Modeling of Musical String Instrument\nLinear Damped Stiff String. The string model discussed in this paper is a damped nonlinear stiffstring. To introduce the nonlinear string, we first formulate the governing equations for the dampedlinear stiff string system and derive the corresponding modal solution.\n$\\partial_{tt}u = \\gamma^2\\partial_{xx}u - \\kappa^2\\partial_{xxxx}u - 2\\sigma_0\\partial_t u$ (1)\nThe linear string of its length L, vibrating with wave speed \u03b3, stiffness \u03ba, and frequency-independentdamping factor \u03c3\u2080, is described by Equation 1. Given the initial conditions (IC) for x \u2208 \u03a9 =\n[-L/2, +L/2] as u(x, 0) = u\u2080(x) and \u2202\u209cu(x, 0) = 0, and appropriate boundary conditions (BC),the corresponding solution u(x, t) represents the motion of a damped linear stiff string. Particularly,for a clamped boundary condition, i.e., u(\u00b1L/2,t) = \u2202\u2093u(\u00b1L/2,t) = 0 for all t \u2208 [0,\u221e), ananalytic solution can be obtained as follows.\n$\\begin{aligned}\nu(x, t) &=\\sum_{n=1}^{\\infty} X_{n}(x) T_{n}(t) \\\\X_{n}(x) &=c_{1}\\left(\\sin \\mu_{n} x-\\frac{\\sin \\mu_{n} L / 2}{\\sinh v_{n} L / 2} \\sinh v_{n} x\\right)+c_{2}\\left(\\cos \\mu_{n} x-\\frac{\\cos \\mu_{n} L / 2}{\\cosh v_{n} L / 2} \\cosh v_{n} x\\right) \\\\T_{n}(t) &=e^{-\\sigma_{0} t} \\cos \\left(\\sqrt{\\mu_{n}^{4} \\kappa^{2}+\\mu_{n}^{2} \\gamma^{2}-\\sigma_{0}^{2}} t\\right)\\end{aligned}$ (2a) (2b) (2c)\nThe derivation of Equation 2 can be found in Appendix C. The allowed values of \u00b5\u2099 and \u03bd\u2099 aredetermined by the boundary conditions, while the coefficients c\u2081 and c\u2082 are determined using the initialcondition \u2211\u2099\u208c\u2081\u221e X\u2099(x) = u\u2080(x). Determining these values typically requires an offline numericalsolving process, where the obtained values can be stored in memory for real-time computation ofu(x, t). The stiffness modeled by the 4th order derivative induces a hyperbolic solution, resultingin non-integer multiples of the mode frequencies \u03c9\u2099, which leads to physical inharmonicity. Thedamping factor \u03c3\u2080 causes an exponential decay in the temporal amplitude.\nNonlinear Damped Stiff String. The generalization of the linear waveEquation 1 to nonlinear string vibrations was first introduced by Kirchhoff[32] and Carrier [33]. The Kirchhoff\u2013Carrier system models elastic stringsin two dimensions, and when extended so that transverse and longitudinalmotions are coupled, phantom partials can be exhibited, resulting in a richertimbre [34]. A model of such planar string vibration is as follows [35, 36].\n$\\begin{aligned}\\partial_{t t} u&=\\gamma^{2} \\partial_{x x} u-\\gamma^{2} \\frac{\\alpha}{2} \\partial_{x}\\left(\\partial_{x} u\\right)^{2}-\\kappa^{2} \\partial_{x x x x} u-2 \\sigma_{0} \\partial_{t} u+2 \\sigma_{1} \\partial_{t} \\partial_{x x} u \\\\ \\partial_{t t} \\zeta&=\\gamma^{2} \\partial_{x x} \\zeta-\\gamma^{2} \\frac{\\alpha}{2} \\partial_{x}\\left(\\partial_{x} \\zeta^{2}\\right)-2 \\sigma_{0} \\partial_{t} \\zeta+2 \\sigma_{1} \\partial_{t} \\partial_{x x} \\zeta\\end{aligned}$ (3a) (3b)\nHere, u(x, t) and \u03b6(x, t) represent the transverse and longitudinal displacements of a string, respec-tively, for all (x, t) \u2208 \u03a9 \u00d7 [0,\u221e). q = \u2202\u2093u and p = \u2202\u2093\u03b6 serves as the auxiliary coupling system, as\u2202\u209cq = \u2202\u2093\u2202\u209cu and \u2202\u209c\u03b6 [37]. A more detailed background on the derivation of Equation 3can be found in Appendix B. The boundary condition, which may vary depending on the string beingmodeled, is chosen to be that of the clamped boundary condition:\nu(x,t) = \u2202\u2093u(x,t) = 0, \u2200(x, t) \u2208 \u2202 \u00d7 [0,\u221e). (4)\nGiven an initial condition u\u2080 := u(x, 0) defined on x \u2208 \u03a9, the solution u(x, t) associated with thecondition of Equation 4 simulates the motion of the string for physical modeling and sound synthesisof string instruments. Due to the coupling between Equation 3a and Equation 3b, the obtainedsolution exhibits features found in elastic strings, such as pitch glide and phantom partials. Thesefeatures become more pronounced for larger displacements and are difficult to approach separately asin the linear case. The solution can be approximated through various physical modeling techniquessuch as finite-difference time-domain [38], digital waveguides [39], or functional transformationmethod [40]."}, {"title": "Differentiable Digital Signal Processing", "content": "In the field of neural networks, numerous audio researchers have been engaged in the development oftechniques that leverage the ease of automatic gradient backpropagation in neural networks for thepurpose of audio parameter estimation. To address the challenge of estimating the latent parameters ofa sound, some approaches implement the synthesis part as-is using automatic differentiation package[20, 43] so that the gradient can back-propagate through it to update the parameters directly, while themajority of approaches train neural networks to estimate the parameters in an auto-encoder framework[16, 22, 47]. As one of the most seminal studies of the latter approach, DDSP is widely used toefficiently synthesize nonlinear and dynamic sounds. Based on the spectral modeling synthesisframework, the time-domain signal is modeled via short-time Fourier transforms (STFTs) dividedinto deterministic (harmonic) and stochastic (noisy) parts to synthesize the sound. As the causality ofSTFT frames is modeled through gated recurrent units (GRUs), DDSP requires as many recursionsas N\u209c, the number of frames. The harmonics of a DDSP are given by an integer multiple of thefundamental frequency (f\u2080), and the noise is synthesized from filtered noise. These DDSPs, whilestill a remarkable advancement, have strong structural constraints on the deterministic part to captureenough perceptually rich tones such as inharmonicity due to stiffness or phantom partials due tononlinearity. A study by Renault et al. [25] also points this out, and uses the parametric model [26]for inharmonicity and detune, but there is room for improvement as it is an approximation model thatrelies on instrument-specific modifiers rather than reflecting stiffness physics."}, {"title": "Differentiable Modal Synthesis for Physical Modeling (DMSP)", "content": "This section introduces a novel differentiable nonlinear string sound synthesizer. Table 1 provides asummary of the methods discussed. While modal synthesis stands out for its efficiency, it is solelyapplicable to linear models and necessitates pre-computation to determine the number of modesdenoted as N\u2098. On the other hand, FDTD computes highly nonlinear and dynamic solutions butdemands a substantial computational load due to iterative updates across both temporal (N\u209c) andspatial (N\u2093) samples. In contrast, differentiable audio processing methods offer efficient nonlinearsound synthesis, typically leveraging a smaller number of frames (N\u209c) compared to the total timesamples (N\u209c). However, they often lack physical controllability. In this regard, we propose DMSP,which approximates the solution of Equation 3 efficiently by leveraging Equation 2 in the form ofneural networks. Figure 1 provides a visual depiction of the DMSP.\n3.1 Problem Statement\nThe objective of this study is to establish a mapping from the parameter space to the solution space,utilizing a finite set of observations comprising parameter-solution pairs from this mapping. Wedelineate this objective as follows: Consider the partial differential equation depicted in Equation 3,applicable for (x, t) within \u03a9 \u00d7 [0, \u221e), with clamped boundary conditions as specified in Equation 4,where \u03a9 represents a bounded domain in \u211d\u1d3a. We assume that the solution u : \u03a9 \u00d7 [0, \u221e) \u2192 \u211dresides within the Banach space U. For a given PDE parameter p \u2208 P and initial condition u\u2080 \u2208 U,let S : P \u2192 U denote a nonlinear map, specifically, the FDTD numerical solver tailored to the contextof this study. Assume that we are provided with observations {p\u207d\u2071\u207e, u\u207d\u2071\u207e}\u1d62\u208c\u2081\u1d3a, where p\u207d\u2071\u207e comprisesindependent and identically distributed (i.i.d.) samples drawn from a probability measure supportedon P, and u\u207d\u2071\u207e = S(p\u207d\u2071\u207e) potentially contains noise. Our goal is to construct an approximation of Sdenoted as S\u2091 : P \u2192 U, and select parameters \u03b8\u2217 \u2208 \u211d\u1d3a\u03b8 such that S\u03b8\u2217 \u2248 S. Leveraging S\u2091, one cancompute the solution \u00fb = S\u03b8(p) corresponding to a new parameter p \u2208 P. By specifying values forx and t, one can then either synthesize the sound of the string picked-up (also referred to as read-out)at a specific location x\u2080 as \u00fb(x\u2080, t), or simulate the motion of the string by concatenating \u00fb(x, t)across all x \u2208 \u03a9. In practice, \u03a9 and [0,\u221e) are bounded and discretized to form an evenly distributedspatio-temporal grid as \u211d\u1d3a\u02e3 \u00d7 \u211d\u1d3a\u1d57 \u2282\u2229 \u00d7 [0, \u221e), where the spatial grid samples are uniformlydistributed in space according to the length of the equally spaced intervals L/N\u2093 and the temporalgrid samples uniformly distributed according to the frequency of a fixed audio sampling rate."}, {"title": "Network Architecture", "content": "Parameter Encoder. To effectively capture material features inherent in the PDE parameter values,the parameter encoder leverages a random Fourier feature (RFF) layer [48, 49]. Given T60 frequenciesf\u1d40\u2076\u2070 and their corresponding times t\u1d40\u2076\u2070 for i = 1, 2, the frequency-dependent damping coefficients\u03c3\u2080 (and \u03c3\u2081, if applicable) are derived using Equation 24. Subsequently, the frequency-independentdamping factor exp(\u2212\u03c3\u2080t) is computed, explicitly multiplied by the mode amplitudes. All PDEparameters p = {\u03ba, \u03b1, \u03c3\u2080, \u03c3\u2081} \u2208 \u211d\u2074 \u2282P are encoded into a feature vector h \u2208 \u211d\u2074\u00d7\u1d48 with a Fourierembedding size of d = 256.\nAM and FM Blocks. As illustrated in Figure 3, DMSP employs amplitude modulation (AM) andfrequency modulation (FM) modules to modulate the mode frequencies and amplitudes of the linearsolution, as depicted in Equation 2, to synthesize the solution of the nonlinear wave described inEquation 3. We utilize two multilayer perceptrons (MLPs) for the modulation layers. Althougha simpler and perhaps more conventional choice of architecture would be a GRU, to the decoderarchitecture of DDSP [16], we choose MLPs for their slightly better empirical results. It's noteworthythat DDSP decodes the sinusoidal frequency envelope with fixed frequency values. In contrast, DMSPdecodes both the envelope and the frequency values independently, employing two distinct MLPblocks, namely AM and FM.\nMode Estimator. As detailed in subsection 2.1, determining allowed values for mode frequenciesand amplitudes, corresponding to specific initial and boundary conditions of the string, typicallyinvolves a root-finding process conducted offline. While these numerical solvers offer high accuracyup to a specified iterative threshold, they necessitate pre-computation, as illustrated in Table 1. Themode estimator module within DMSP estimates the modes from the initial condition using an MLP.The initial condition is parameterized by a pluck position p\u2093 and its peak amplitude p\u2090. Subsequently,the physical properties \u03ba, \u03b3, \u03c3\u2080, and \u03c3\u2081 are encoded using a random Fourier feature (RFF) layer. Themode frequencies and amplitudes are then estimated by the MLP, followed by the application ofsuitable scaling activations. It's pertinent to note that the mode estimator operates independently andis trained separately from the other modules. During training, the ground truth modes (computedusing the modal decomposition method) are fed into the AM and FM blocks, ensuring accuratesynthesis while training the synthesis part of the model."}, {"title": "Loss Function", "content": "In training DMSP, we employ a combination of four loss terms: (1) waveform l\u2081 loss that measuresthe L\u2081 discrepancy between the synthesized waveform and the ground truth waveform, (2) Multi-scalespectral (MSS) loss that captures spectral differences across multiple scales, ensuring fidelity inspectral representation, and (3) Pitch loss (Lf\u2080) that penalizes deviations from the ground truthfundamental frequency (f\u2080). Optimizing the frequency parameters of sinusoidal oscillators viagradient descent over an audio loss function poses a challenge due to the non-convex nature ofthe optimization problem, as highlighted in various studies [50, 51]. Damped sinusoids offer aworkaround for the issue of non-convexity concerning frequency parameters [51], or alternativemetrics are proposed to mitigate the risk of falling into bad local minima [52, 53]. In our approach,we adopt a parameter regression joint training strategy, akin to the pre-training phase of the workby Engel et al. [54]. Among the output mode frequencies, we optimize one frequency componentto match the target fundamental frequency (f\u2080) annotated using CREPE [55]. As the comparisonmodels are all aware of the frequency of the mode they are outputting, the models are updated tominimize the discrepancy between the fundamental frequency estimated as the lowest one of themodes (denoted by f\u2080) and the ground-truth f\u2080 of the FDTD-simulated audio estimated via CREPEas Lf\u2080 = || f\u2080 - f\u2080||\u2081."}, {"title": "Experiments", "content": "This section introduces the empirical investigation that seeks to find the answers to the followingquestions: (1) how much does the modal synthesis-based inductive bias of a neural network advantagephysical modeling sound synthesis, (2) how much does it improve nonlinearity and what physicalanalysis is possible, and (3) to what extent are techniques required for training such model."}, {"title": "Experimental Setup", "content": "Dataset. We use the StringFDTD-Torch [43], the open-source nonlinear string simulator, to computethe solution of the Equation 3 in a temporal sampling rate of 48 kHz and a spatial sampling rate. Thesolution is upsampled to a spatial resolution of 256 using a bivariate spline approximation over arectangular spatio-temporal mesh upto the 5th order degree. We simulate 10263 different strings byrandomly augmenting the material properties, e.g., \u03ba, \u03b1, \u03c3\u2080, and \u03c3\u2081, with various plucking profiles\u03c6\u2080. The simulation results in a total amount of 729.8 hours of wave files that corresponds to the1-sec string sounds picked up at 256 different positions for each string. For the test data, 715 stringsare newly synthesized with the parameters sampled in i.i.d. The test data consists of 336 linear(\u03b1 = 1) and 379 nonlinear (\u03b1 > 1) strings, each of which has a 256 spatial grid size, resulting inapproximately 50 hours of wave files. Table 4 specifies the range of the sampled PDE parameters.\nBaselines. As the first attempt to tackle the task of neural audio synthesis from the physical properties,we compare our proposed model to three other models. We consider three baselines, namely: Modaland DDSPish, and DDSPish without FM. Modal synthesis is the linear wave solution as in Equation 1,where the modal frequencies and the shape functions are pre-computed. DDSPish is a neural networkbased on the harmonic plus noise model, similar to DDSP. Yet, this -ish suffix emphasizes that thismodel is different from the DDSP model [16]. DDSPish does not have a reverb module but insteadadds frequency modulation, and most notably it has a parameter encoder that allows generatingsounds from physical parameters. Please see Appendix D for more details of the baselines.\nEvaluation Metrics. We report results on three metrics, signal-distortion-ratio (SDR), scale-invariantsignal-distortion-ratio (SI-SDR) [56], multi-scale spectral (MSS) distance, and the pitch difference inHz. The MSS metric for the evaluation was computed using the short-time Fourier transformation(STFT) with 513 number of frequency bins and the hop size of 256 samples. The Pitch metric iscomputed as the l\u00b9 norm of the difference between f\u2080 and f\u2080."}, {"title": "Results", "content": "Differentiable Sound Synthesis. The efficacy of DMSP is studied as shown in Table 2. First, themodal synthesis method calculates a linear solution for a damped stiff string, and the mode forthe linear test set is calculated offline. The discrepancy between the outcomes of modal synthesisand FDTD in the linear case can be attributed to the absence of frequency-dependent damping inEquation 1. In other words, the frequency information serves as an oracle for the Modal, as evidencedby its lowest pitch score, but the decay of amplitude over time is not sufficiently modeled, which iswhere the remaining models demonstrate superior performance. Considering the DDSPish models,the MSS is approximately 1.6 dB ahead of the DMSPs, but the difference can reach up to 44 dBin the case of the SI-SDR. It is worth noting that \u03b1 is uniformly sampled within the range (1,25)for the training data, falling into the category of the nonlinear strings. In the case of nonlineartest set, the difference between the modal solution and the FDTD solution becomes larger. On theother hand, DDSPish models based on spectral modeling synthesis but learned without using anymodal information show the lowest performance. The superiority of DMSP is even more pronouncedin the nonlinear case. While Modal, which can only cover the solution to the linear case, showsattenuated performance, the DMSPs demonstrate the best performance in all metrics. In particular,DMSP-Hybrid, which precomputes the mode frequency like Modal, performs FM and AM for thenonlinear solution, showing an SI-SDR improvement of nearly 31 dB and an MSS improvement"}, {"title": "Controllable Physical Simulation", "content": "The quantitative scores forvarious physical condition parameters are visualized in Figure 5.Trends show how the results of Modal synthesis and DMSPvary for different pickup positions (x), stiffness (\u03ba), tension(\u03b1), pluck amplitude (p\u2090), and pluck position (p\u2093). Of these,\u03b1 and p\u2090 in particular are known to increase the nonlinearityof the string as they increase in magnitude, which can be seenby the lower Modal synthesis scores. For DMSP, we see anoverall improvement in the score, with a lower propensity fornonlinearity. Figure 4 depicts the simulated state of the stringas the pluck position in the initial condition is varied. TheFigure 5: Objective scores overresults synthesized by DMSP can reconstruct a very accurate physical parameters.\ninitial condition, similar to the results simulated by FDTD. Thevibration propagating through time along the string exhibits a distinct behavior contingent upon theinitial condition. FDTD employs a recursive calculation of displacement, necessitating a number ofiterations equal to the number of samples at the audio sampling rate. In contrast, DMSP is capable ofobtaining the desired displacement in both time and space simultaneously."}, {"title": "String Sound Synthesis", "content": "Spectrograms of the test samples are visualized in Figure 6. The instan-taneous frequencies are identified in a rainbow color map, where the color intensities represent thelogarithmic magnitude of the power spectra. The FDTD-simulated spectrogram clearly shows pitchglide and phantom partials at the beginning of the pluck. In contrast, modal synthesis methods thatmodel linear solutions do not show these nonlinear characteristics. The DDSPish-XFM model employsa harmonic pitch skeleton comprising integer multiples of f\u2080, thereby precluding the inharmoicitiesresulting from stiffness. The DDSPish model demonstrates enhanced mode estimation capabilitiesthrough learned FM, which modulates the harmonic pitch skeleton to be inharmonic. However,there is scope for further improvement in frequency estimation, particularly in instances wheret the FM learning process is unstable for high frequencies. On the other hand, the DMSP model,which estimates the mode frequency and amplitude from u\u2080, shows an improved pitch skeleton andstable frequency estimation. The DMSP-Hybrid model, which learns to AM and FM the sinusoidaloscillators of the modal solution that requires mode precomputation, shows the most similar resultsto FDTD."}, {"title": "Ablation Study", "content": "The ablation study on the choice of the training loss functions is presented in Table 3.Overall, for linear strings, the performance does not vary much depending on which loss is used,especially for pitch. This is due to the alpha masking applied to the FM block, which is designed toprevent FM from occurring when alpha is 1. This is the main factor that determines the nonlinearityof the string. For AM, there is no masking depending on alpha, so the remaining metrics except pitchdo vary. For nonlinear data, the learning results vary depending on the loss design.\nMotion Synthesis. The main advantage of this neural net based on modal synthesis is that it cansynthesize not only sound but also motion, which is one of the main characteristics of physicalmodeling techniques. In particular, the DMSP is able to visualize the corresponding string motionas a video, despite the fact that the receptive field and computational complexity required to obtaina solution u(x, t) for a single spatio-temporal point is of order 1, as shown in Table 1, when thesesolutions are pooled for a given x \u2208 \u03a9 and t \u2208 [0,1), the corresponding string motion can bevisualized as a video. Figure 7 visualizes the resulting transverse displacement of the string overtime (horizontal axis) and space (vertical axis). As mentioned earlier, the transverse displacement ofthe FDTD is coupled to the longitudinal motion, which is why it differs from the Modal synthesisoutput, which synthesizes the motion of a linear damped stiff string. The results output by DMSPshow improved accuracy."}, {"title": "Conclusion", "content": "We present a novel neural network-based method that efficiently simulates plucked string motions.Our differentiable modal synthesis for physical modeling (DMSP) can simulate a dynamic nonlinearstring motion by synthesizing the sound using the physical properties of the string. It is an efficientapproximation of existing physical modeling methods. We demonstrate the efficacy of training theneural network using mode frequency information by extending the DDSP with a modal synthesispipeline. This opens the door to a new field of differentiable audio signal processing, extending itto the field of physical modeling for musical sound synthesis. While the proposed method offerscontrol over several physical parameters of a musical instrument, it still faces limitations in terms ofgeneralizing to physical parameters and sounds in real-world measurements. This study paves the wayfor future research in this area. To the best of our knowledge, this is the first study to simultaneouslysynthesize sound and motion from the properties of a stringed instrument."}, {"title": "Proof of the Linear Damped Stiff String Solution", "content": "Proposition 1. A solution to the damped linear stiff string model Equation 1 with a clamped boundarycondition u(\u00b1L/2,t) = ux(\u00b1L/2,t) = 0 and the initial condition given as u(x, 0) = u\u2080(x) anddu(x, 0) = 0 can be expressed as\n$\\begin{aligned}u(x, t) &=e^{-\\sigma_{0} t} \\cos \\left(\\sqrt{\\mu^{2} \\kappa^{2}+\\mu^{2} \\gamma^{2}-\\sigma_{0}^{2}} t\\right) \\\\&\\times \\left[c_{1}\\left(\\sin \\mu x-\\frac{\\sin \\mu \\frac{L}{2}}{\\sinh v \\frac{L}{2}} \\sinh v x\\right)+c_{2}\\left(\\cos \\mu x-\\frac{\\cos \\mu \\frac{L}{2}}{\\cosh v \\frac{L}{2}} \\cosh v x\\right)\\right] \\\\&\\text { As mentioned earlier, the coefficients } c_{1}=A_{1} B_{1} \\text { and } c_{2}=A_{1} B_{3} \\text { are determined by the } \\\\&\\text { allowed values that satisfy the initial condition } \\sum_{n=1}^{\\infty} X_{n}(x)=u_{0}(x) \\text { . To determine the } \\\\&\\text { allowed values of } \\mu \\text { , apply the boundary condition } u(L / 2, t)=u_{x}(L / 2, t)=0 \\text { to the even } \\\\&\\text { function that gives } \\\\&B_{3} \\cos \\mu \\frac{L}{2}=-B_{4} \\cosh v \\frac{L}{2} \\text { and } -\\mu B_{3} \\sin \\mu \\frac{L}{2}=-v B_{4} \\sinh v \\frac{L}{2} \\\\&\\text { or alternatively, } \\\\&\\mu \\tan \\mu \\frac{L}{2}=-v \\tanh v \\frac{L}{2} \\\\\\&\\text { Similarly, applying the same boundary condition to the odd function gives } \\\\&B_{3} \\sin \\mu \\frac{L}{2}=-B_{4} \\sinh v \\frac{L}{2} \\text { and } \\left(\\mu B_{3} \\cos \\mu \\frac{L}{2}=-v B_{4} \\cosh v \\frac{L}{2}\\right) \\\\&\\text { or equivalently, } \\\\&\\mu \\tan \\mu \\frac{L}{2}=-v \\tanh v \\frac{L}{2}\\\\T = A\u2081e\u03b2+t + Aze-\u03c9t \\\\\\\\frac{\\partial^{4}}{\\partial x^{4}} X(x) = \\frac{\\gamma^2}{\\kappa^2}\\frac{\\partial^2}{\\partial x^{2}} X(x)+\\frac{s^2}{\\kappa^2}X = 0\nB\u2081 = (A1 + A2t)e-rot,  f (1) < f(2)\\[f^{\\prime}=1 ; \\int f(x)=\\sin \\frac{L}{2} B_{1} \\text { and } B_{4}=-\\frac{\\cos \\mu \\frac{L}{2}}{\\cosh v \\frac{L}{2}} B_{3}\n\\left(\\sin \\mu x-\\frac{\\sin \\mu \\frac{L}{2}}{\\sinh v \\frac{L}{2}} \\sinh v x\\right)+B_{3}\\left(\\cos \\mu x-\\frac{\\cos \\mu \\frac{L}{2}}{\\cosh v \\frac{L}{2}} \\cosh v x\\right).\\end{aligned}$"}, {"title": "Energy and Frequency", "content": "Energy and frequency: The energy is defined as $E=\\int_{-L / 2}^{L / 2}\\left(u_{t}^{2}+c^{2} u_{x}^{2}+e^{2} u_{x x}^{2}\\right) d x$, which is the sum of the kinetic and elastic potentials of the string. We compute this function using the numerical estimation in the simulation results. After substituting our solution $u(x, t)$, we can see that the energy function is related to the value of the spectrum: $E=F\\left(A^{2}\\left|T(\\omega)\\right|^{2}\\right)$. Also, we can see that $\\omega=\\sqrt{\\frac{T}{\\rho}}+\\sqrt{\\frac{E J}{\\rho}} \\mu_{m}^{2}=C_{0}+C_{1} \\mu_{m}^{2}$, which is the relationship with the frequency, where $E J$ is defined as the stiff parameter. Thus, we also show the stiffness parameters $(\\omega / \\sqrt{e})$ for comparing energy and frequency as a function for $C_{0}$ for verifying the effectiveness, which can be controlled independently. Our model has better estimation, because $E \\approx F^{-1}\\left(A^{2}\\left|T(\\omega)\\right|^{2}\\right)$ in $C_{0} \\approx k$\\n\\begin{aligned} &\\sigma_{0}=\\frac{6 \\log (10)}{\\frac{\\xi_{1}}{\\xi_{1}-\\xi_{2}}\\left(\\frac{1}{t_{T 60}^{(2)}}\\right.\\\\\\\\frac{6 \\log (10)}{\\frac{\\xi_{2}}{\\xi_{1}-\\xi_{2}}\\left(\\frac{1}{t_{T 60}^{(2)}}\\right)} \\\\&1 \\le i \\le 2 \\\\\\text{for i = 1.2}&\\text{as energy loss increases}   T60\\text { when } f_{T 60}^{(1)}<f_{T 60}^{(2)}\\end{aligned}"}]