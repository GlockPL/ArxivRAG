{"title": "Differentiable Modal Synthesis for Physical Modeling of Planar String Sound and Motion Simulation", "authors": ["Jin Woo Lee", "Jaehyun Park", "Min Jun Choi", "Kyogu Lee"], "abstract": "While significant advancements have been made in music generation and dif-ferentiable sound synthesis within machine learning and computer audition, the simulation of instrument vibration guided by physical laws has been underexplored. To address this gap, we introduce a novel model for simulating the spatio-temporal motion of nonlinear strings, integrating modal synthesis and spectral modeling within a neural network framework. Our model leverages physical properties and fundamental frequencies as inputs, outputting string states across time and space that solve the partial differential equation characterizing the nonlinear string. Empirical evaluations demonstrate that the proposed architecture achieves superior accuracy in string motion simulation compared to existing baseline architectures.", "sections": [{"title": "Introduction", "content": "The investigation of wave propagation along strings, encompassing both theoretical and experimental dimensions, has persisted for well over a century [1, 2]. In the relentless pursuit of verisimilitude and expressive fidelity in simulating wave phenomena, numerous studies have been investigated to bridge the gap between theoretical underpinnings and empirical sound measurements [3]. Advancements leveraging computational power to mimic the intricate physical processes in musical instruments have given rise to numerical sound synthesis, now a cornerstone in the field of virtual sound synthesis [4, 5]. Schwarz [6] presents a systematic study of parametric and physical models for music audio synthesis. Parametric models include signal models, such as spectral modeling synthesis [7]. Physical models encompass techniques such as modal synthesis, digital waveguides [8, 9], or finite-difference time-domain (FDTD) methods [4, 10].\nOver recent years, the advancement of hardware acceleration for artificial intelligence has enabled the emergence of numerous techniques for neural audio synthesis [11], including autoregressive generation [12], adversarial training [13] with phase coherence [14], and approximated physical models [15]. The concept of differentiable digital signal processing (DDSP) was first introduced by Engel et al. [16], aiming to incorporate a known signal model into neural networks to achieve a domain-appropriate inductive bias. While the DDSP model can be considered a differentiable version of spectral modeling synthesis, a wide variety of works have explored the differentiable implementation of other audio signal processing methods, such as the subtractive method [17], waveshaping [18], and frequency modulation [19, 20]. Subsequent research has demonstrated various applications of DDSP, including music performance synthesis [21], speech synthesis and voice conversion [22, 23], and sound effect generation [24]. Renault et al. [25] extended DDSP to create a polyphonic synthesizer, explicitly modeling properties specific to piano strings, such as inharmonicity and detuning induced by string stiffness, based on a parametric model of these phenomena [26]. This model efficiently synthesizes piano sound from MIDI input, achieving a high mean opinion score on naturalness. However, it still shows room for improvement compared to sampling-based methods [27] and physical modeling methods [28].\nDespite the growing recognition of DDSP as a promising sound synthesis methodology, its extension to physical modeling remains underexplored. In the context of musical sound synthesis, some attempts have been made to synthesize rigid-body contact sounds of arbitrary shapes using neural networks supervised by finite-element method (FEM) solvers. Jin et al. [29, 30] propose a neural network that predicts contact sounds from voxelized objects, inspired by the modal technique that synthesizes sound using eigenvalues and eigenvectors. Diaz et al. [31] leverage a differentiable infinite impulse response filter to synthesize contact sounds from rasterized occupancy grids in an end-to-end manner. These methods can interactively synthesize sounds for various contact conditions and materials with notable efficiency, circumventing the need for an offline optimization process typical of modal techniques. However, these methods, which resort to the FEM solver, are vulnerable in modeling the dynamic behavior (e.g., glissando, vibrato) or in simulating the motion of the object. This vulnerability demands the need for further research to enhance the capability of neural networks in physical modeling for more dynamic and complex sound synthesis scenarios.\nIn this regard, we propose a novel model for simulating the spatio-temporal motion of nonlinear strings, integrating modal synthesis and spectral modeling within a neural network framework. The proposed model leverages physical properties and fundamental frequencies as inputs, outputting string states across time and space that solve the partial differential equation (PDE) characterizing the nonlinear string. Empirical evaluations demonstrate that the proposed architecture achieves superior accuracy in string motion simulation compared to the baseline architectures. The main contributions are as follows:\n\u2022 We present differentiable modal synthesis for physical modeling (DMSP) that simulates dynamic nonlinear string motion by synthesizing sound using the physical properties of the string.\n\u2022 To the best of our knowledge, this is the first approach that is differentiable and can synthesize the motion and the sound of a musical string with a dynamic control over the pitch and the material properties.\n\u2022 We provide an extensive empirical evaluation demonstrating the importance of modal decomposition and the proper choice of loss function."}, {"title": "Background", "content": "2.1 Physical Modeling of Musical String Instrument\nLinear Damped Stiff String. The string model discussed in this paper is a damped nonlinear stiff string. To introduce the nonlinear string, we first formulate the governing equations for the damped linear stiff string system and derive the corresponding modal solution.\n$\\partial_{tt}u = \\gamma^2\\partial_{xx}u - \\kappa^2\\partial_{xxxx}u - 2\\sigma_0\\partial_t u$ (1)\nThe linear string of its length L, vibrating with wave speed $\\gamma$, stiffness $\\kappa$, and frequency-independent damping factor $\\sigma_0$, is described by Equation 1. Given the initial conditions (IC) for $x \\in \\Omega = [-L/2, +L/2]$ as $u(x, 0) = u_0(x)$ and $\\partial_t u(x, 0) = 0$, and appropriate boundary conditions (BC), the corresponding solution $u(x, t)$ represents the motion of a damped linear stiff string. Particularly, for a clamped boundary condition, i.e., $u(\\pm L/2,t) = \\partial_x u(\\pm L/2,t) = 0$ for all $t \\in [0,\\infty)$, an analytic solution can be obtained as follows.\n$\\begin{aligned} u(x,t) &= \\sum_{n=1}^{\\infty} X_n(x)T_n(t)  \\label{eq:linear_string_solution} \\\\ X_n(x) &= c_1 \\left( \\sin \\mu_n x - \\frac{\\sin \\mu_n L/2}{\\sinh v_n L/2} \\sinh v_n x \\right) + c_2 \\left( \\cos \\mu_n x - \\frac{\\cos \\mu_n L/2}{\\cosh v_n L/2} \\cosh v_n x \\right) \\\\ T_n(t) &= e^{-\\sigma_0 t} \\cos \\left( \\sqrt{\\mu_n^4 \\kappa^2 + \\mu_n^2 \\gamma^2 - \\sigma_0^2} t \\right) = e^{-\\sigma_0 t} \\cos \\left( \\omega_n t \\right) \\end{aligned}$ (2a)\n(2b)\n(2c)\nThe derivation of Equation 2 can be found in Appendix C. The allowed values of $\\mu_n$ and $\\nu_n$ are determined by the boundary conditions, while the coefficients $c_1$ and $c_2$ are determined using the initial condition $\\sum_{n=1}^{\\infty} X_n(x) = u_0(x)$. Determining these values typically requires an offline numerical solving process, where the obtained values can be stored in memory for real-time computation of $u(x, t)$. The stiffness modeled by the 4th order derivative induces a hyperbolic solution, resulting in non-integer multiples of the mode frequencies $\\omega_n$, which leads to physical inharmonicity. The damping factor $\\sigma_0$ causes an exponential decay in the temporal amplitude.\nNonlinear Damped Stiff String. The generalization of the linear wave Equation 1 to nonlinear string vibrations was first introduced by Kirchhoff [32] and Carrier [33]. The Kirchhoff\u2013Carrier system models elastic strings in two dimensions, and when extended so that transverse and longitudinal motions are coupled, phantom partials can be exhibited, resulting in a richer timbre [34]. A model of such planar string vibration is as follows [35, 36].\n$\\begin{aligned} \\partial_{tt}u &= \\gamma^2\\partial_{xx}u - \\frac{\\gamma^2}{2} \\alpha^2 \\partial_x \\left( \\partial_x u^2 \\right) - \\kappa^2\\partial_{xxxx}u - 2\\sigma_0 \\partial_t u + 2\\sigma_1 \\partial_t \\partial_{xx}u \\\\ \\partial_{tt}\\zeta &= \\gamma_a^2\\partial_{xx}\\zeta - \\frac{\\gamma_a^2}{2} \\partial_x \\left( \\partial_x \\zeta^2 \\right) - 2\\sigma_0 \\partial_t \\zeta + 2\\sigma_1 \\partial_t \\partial_{xx}\\zeta \\end{aligned}$ (3a)\n(3b)\nHere, $u(x, t)$ and $\\zeta(x, t)$ represent the transverse and longitudinal displacements of a string, respectively, for all $(x, t) \\in \\Omega \\times [0,\\infty)$. $q = \\partial_x u$ and $p = \\partial_x \\zeta$ serves as the auxiliary coupling system, as $\\partial_t q = \\partial_x \\partial_t u$ and $\\partial_t p = \\partial_x \\partial_t \\zeta$ [37]. A more detailed background on the derivation of Equation 3 can be found in Appendix B. The boundary condition, which may vary depending on the string being modeled, is chosen to be that of the clamped boundary condition:\n$u(x,t) = \\partial_x u(x,t) = 0, \\quad \\forall (x, t) \\in \\partial \\Omega \\times [0,\\infty)$. (4)\nGiven an initial condition $u_0 := u(x, 0)$ defined on $x \\in \\Omega$, the solution $u(x, t)$ associated with the condition of Equation 4 simulates the motion of the string for physical modeling and sound synthesis of string instruments. Due to the coupling between Equation 3a and Equation 3b, the obtained solution exhibits features found in elastic strings, such as pitch glide and phantom partials. These features become more pronounced for larger displacements and are difficult to approach separately as in the linear case. The solution can be approximated through various physical modeling techniques such as finite-difference time-domain [38], digital waveguides [39], or functional transformation method [40]."}, {"title": "Differentiable Modal Synthesis for Physical Modeling (DMSP)", "content": "This section introduces a novel differentiable nonlinear string sound synthesizer. Table 1 provides a summary of the methods discussed. While modal synthesis stands out for its efficiency, it is solely applicable to linear models and necessitates pre-computation to determine the number of modes denoted as $N_m$. On the other hand, FDTD computes highly nonlinear and dynamic solutions but demands a substantial computational load due to iterative updates across both temporal ($N_t$) and spatial ($N_x$) samples. In contrast, differentiable audio processing methods offer efficient nonlinear sound synthesis, typically leveraging a smaller number of frames ($N$) compared to the total time samples ($N_t$). However, they often lack physical controllability. In this regard, we propose DMSP, which approximates the solution of Equation 3 efficiently by leveraging Equation 2 in the form of neural networks.\n3.1 Problem Statement\nThe objective of this study is to establish a mapping from the parameter space to the solution space, utilizing a finite set of observations comprising parameter-solution pairs from this mapping. We delineate this objective as follows: Consider the partial differential equation depicted in Equation 3, applicable for $(x, t)$ within $\\Omega \\times [0, \\infty)$, with clamped boundary conditions as specified in Equation 4, where $\\Omega$ represents a bounded domain in $R^{N'}$. We assume that the solution $u : \\Omega \\times [0, \\infty) \\to R$ resides within the Banach space $\\mathcal{U}$. For a given PDE parameter $p \\in \\mathcal{P}$ and initial condition $u_0 \\in \\mathcal{U}$, let $S : \\mathcal{P} \\to \\mathcal{U}$ denote a nonlinear map, specifically, the FDTD numerical solver tailored to the context of this study. Assume that we are provided with observations $\\{p^{(i)}, u^{(i)}\\}_{i=1}^{N}$, where $p^{(i)}$ comprises independent and identically distributed (i.i.d.) samples drawn from a probability measure supported on $\\mathcal{P}$, and $u^{(i)} = S(p^{(i)})$ potentially contains noise. Our goal is to construct an approximation of $S$ denoted as $S_\\theta : \\mathcal{P} \\to \\mathcal{U}$, and select parameters $\\theta^* \\in R^{N_\\theta}$ such that $S_{\\theta^*} \\approx S$. Leveraging $S_\\theta$, one can compute the solution $\\hat{u} = S_\\theta(p)$ corresponding to a new parameter $p \\in \\mathcal{P}$. By specifying values for $x$ and $t$, one can then either synthesize the sound of the string picked-up (also referred to as read-out) at a specific location $x_0$ as $\\hat{u}(x_0, t)$, or simulate the motion of the string by concatenating $\\hat{u}(x, t)$ across all $x \\in \\Omega$. In practice, $\\Omega$ and $[0,\\infty)$ are bounded and discretized to form an evenly distributed spatio-temporal grid as $R^{N_x} \\times R^{N_t} \\subset \\Omega \\times [0, \\infty)$, where the spatial grid samples are uniformly distributed in space according to the length of the equally spaced intervals $L/N_x$ and the temporal grid samples uniformly distributed according to the frequency of a fixed audio sampling rate."}, {"title": "Network Architecture", "content": "3.2 Network Architecture\nParameter Encoder. To effectively capture material features inherent in the PDE parameter values, the parameter encoder leverages a random Fourier feature (RFF) layer [48, 49]. Given T60 frequencies $f_{T60}^{(i)}$ and their corresponding times $t_{T60}^{(i)}$ for $i = 1, 2$, the frequency-dependent damping coefficients $\\sigma_0$ (and $\\sigma_1$, if applicable) are derived using Equation 24. Subsequently, the frequency-independent damping factor $\\exp(-\\sigma_0 t)$ is computed, explicitly multiplied by the mode amplitudes. All PDE parameters $p = \\{\\kappa,\\alpha,\\sigma_0, \\sigma_1\\} \\in R^{4\\cdot C_p}$ are encoded into a feature vector $h \\in R^{4 \\times d}$ with a Fourier embedding size of $d = 256$.\nAM and FM Blocks. As illustrated in Figure 3, DMSP employs amplitude modulation (AM) and frequency modulation (FM) modules to modulate the mode frequencies and amplitudes of the linear solution, as depicted in Equation 2, to synthesize the solution of the nonlinear wave described in Equation 3. We utilize two multilayer perceptrons (MLPs) for the modulation layers. Although a simpler and perhaps more conventional choice of architecture would be a GRU, to the decoder architecture of DDSP [16], we choose MLPs for their slightly better empirical results. It's noteworthy that DDSP decodes the sinusoidal frequency envelope with fixed frequency values. In contrast, DMSP decodes both the envelope and the frequency values independently, employing two distinct MLP blocks, namely AM and FM.\nMode Estimator. As detailed in subsection 2.1, determining allowed values for mode frequencies and amplitudes, corresponding to specific initial and boundary conditions of the string, typically involves a root-finding process conducted offline. While these numerical solvers offer high accuracy up to a specified iterative threshold, they necessitate pre-computation, as illustrated in Table 1. The mode estimator module within DMSP estimates the modes from the initial condition using an MLP. The initial condition is parameterized by a pluck position $p_x$ and its peak amplitude $p_a$. Subsequently, the physical properties $\\kappa, \\gamma, \\sigma_0$, and $\\sigma_1$ are encoded using a random Fourier feature (RFF) layer. The mode frequencies and amplitudes are then estimated by the MLP, followed by the application of suitable scaling activations. It's pertinent to note that the mode estimator operates independently and is trained separately from the other modules. During training, the ground truth modes (computed using the modal decomposition method) are fed into the AM and FM blocks, ensuring accurate synthesis while training the synthesis part of the model."}, {"title": "Loss Function", "content": "3.3 Loss Function\nIn training DMSP, we employ a combination of four loss terms: (1) waveform $l_1$ loss that measures the $L_1$ discrepancy between the synthesized waveform and the ground truth waveform, (2) Multi-scale spectral (MSS) loss that captures spectral differences across multiple scales, ensuring fidelity in spectral representation, and (3) Pitch loss ($L_{f_0}$) that penalizes deviations from the ground truth fundamental frequency ($f_0$). Optimizing the frequency parameters of sinusoidal oscillators via gradient descent over an audio loss function poses a challenge due to the non-convex nature of the optimization problem, as highlighted in various studies [50, 51]. Damped sinusoids offer a workaround for the issue of non-convexity concerning frequency parameters [51], or alternative metrics are proposed to mitigate the risk of falling into bad local minima [52, 53]. In our approach, we adopt a parameter regression joint training strategy, akin to the pre-training phase of the work by Engel et al. [54]. Among the output mode frequencies, we optimize one frequency component to match the target fundamental frequency ($f_0$) annotated using CREPE [55]. As the comparison models are all aware of the frequency of the mode they are outputting, the models are updated to minimize the discrepancy between the fundamental frequency estimated as the lowest one of the modes (denoted by $\\hat{f_0}$) and the ground-truth $f_0$ of the FDTD-simulated audio estimated via CREPE as $L_{f_0} = || f_0 - \\hat{f_0}||_1$."}, {"title": "Experiments", "content": "This section introduces the empirical investigation that seeks to find the answers to the following questions: (1) how much does the modal synthesis-based inductive bias of a neural network advantage physical modeling sound synthesis, (2) how much does it improve nonlinearity and what physical analysis is possible, and (3) to what extent are techniques required for training such model."}, {"title": "Conclusion", "content": "We present a novel neural network-based method that efficiently simulates plucked string motions. Our differentiable modal synthesis for physical modeling (DMSP) can simulate a dynamic nonlinear string motion by synthesizing the sound using the physical properties of the string. It is an efficient approximation of existing physical modeling methods. We demonstrate the efficacy of training the neural network using mode frequency information by extending the DDSP with a modal synthesis pipeline. This opens the door to a new field of differentiable audio signal processing, extending it to the field of physical modeling for musical sound synthesis. While the proposed method offers control over several physical parameters of a musical instrument, it still faces limitations in terms of generalizing to physical parameters and sounds in real-world measurements. This study paves the way for future research in this area. To the best of our knowledge, this is the first study to simultaneously synthesize sound and motion from the properties of a stringed instrument."}]}