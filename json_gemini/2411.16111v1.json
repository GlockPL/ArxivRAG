{"title": "LLMPirate: LLMs for Black-box Hardware IP Piracy", "authors": ["Vasudev Gohil", "Matthew DeLorenzo", "Veera Vishwa Achuta Sai Venkat Nallam", "Joey See", "Jeyavijayan Rajendran"], "abstract": "The rapid advancement of large language models (LLMs) has enabled the ability to effectively analyze and generate code nearly instantaneously, resulting in their widespread adoption in software development. Following this advancement, researchers and companies have also begun integrating LLMs across the hardware design and verification process. However, these highly potent LLMs can also induce new attack scenarios upon security vulnerabilities across the hardware development process. One such attack vector that has not been explored so far is intellectual property (IP) piracy. Given that this attack can manifest as rewriting hardware designs to evade piracy detection, it is essential to thoroughly evaluate LLM capabilities in performing this task and assess the mitigation abilities of current IP piracy detection tools.\nTherefore in this work we propose LLMPirate, the first LLM-based technique able to generate pirated variations of circuit designs that successfully evade detection across multiple state-of-the-art piracy detection tools. We devise three solutions to overcome challenges related to integration of LLMs for hardware circuit designs, scalability to large circuits, and effectiveness, resulting in an end-to-end automated, efficient, and practical formulation. We perform an extensive experimental evaluation of LLMPirate using eight LLMs of varying sizes and capabilities and assess their performance in pirating various circuit designs against four state-of-the-art widely-used piracy detection tools. Our experiments demonstrate that LLMPirate is able to consistently evade detection on 100% of tested circuits across every detection tool. Additionally, we showcase the ramifications of LLMPirate using case studies on IBEX and MOR1KX processors and a GPS module, that we successfully pirate. We envision that our work motivates and fosters the development of better IP piracy detection tools.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements within artificial intelligence and computing performance have greatly accelerated the development of large language models (LLMs), with state-of-the-art models (including OpenAI's ChatGPT [57] and Google's Bard [65]) achieving groundbreaking performance in natural language processing and gaining mass popularity [35]. With the ability to effectively interpret text prompts and generate human-like responses [53], LLMs have proven effective across a variety of tasks, such as language translation [41], text summarization [64], and generating code [24]. This widespread applicability has resulted in the rapid adoption of LLMs across various industries, serving as chat-bots for customer service [64], documentation aids in healthcare [45], and coding assistants for programmers [24]. These applications have prompted companies and researchers to further explore the most effective ways in which LLMs can be tailored and utilized to automate specified tasks and processes, including the software and hardware design workflow."}, {"title": "A. LLMs for Code Generation", "content": "Given the success of LLMs in natural language processing, many models are also extensively trained on large datasets of open-source code with the specific purpose of generating functionally correct programs based upon a prompt description [46]. These programming-oriented LLMs are utilized in a variety of applications within the software and hardware development processes. Through Microsoft's Github CoPilot, the advantages of LLMs are applied directly to the software development environment, providing context-aware code suggestions and refactoring recommendations [26]. In fact, Microsoft reported that the first versions of CoPilot tools substantially increase productivity on common enterprise information worker tasks [14]. Similarly, OpenAI's widely utilized GPT-4 model also has strong performance in software engineering tasks, including the ability to generate programs from pseudocode and explain its results in natural language [11].\nFollowing advancements in the software domain, semiconductor companies have also begun utilizing generative artificial intelligence (AI), specifically LLMs, within various stages of hardware integrated circuit design process, including the generation of register-transfer level (RTL) code. Semiconductor giant NVIDIA's ChipNeMo explores fine-tuning smaller LLMs for industrial chip-design, in which their 70-billion parameter model was able to outperform OpenAI's GPT-4 in electronic design automation (EDA) tools' script generation [43]. ChipGPT from Cadence demonstrated the first proof-of-concept LLM technology in chip design, able to load architecture and design specifications to accelerate test-bench creation and RTL code generation [10]. Cadence has also developed the Cadence.AI generative AI platform for applications in digital circuit design, analog circuit design, debug and verification, and printed circuit board design [13]. Likewise, Synopsys, another EDA enterprise, has developed Synopsys.ai Copilot that harnesses generative AI with LLMs throughout their EDA suite, aiding in tedious workflow tasks including test pattern generation, verification coverage, and design space exploration [66]. RapidGPT from Rapid Silicon provides similar auto-complete capabilities tailored to field-programmable gate array design [20].\nLLMs can also be offensively leveraged by threat actors to execute attacks that exploit various software and hardware security vulnerabilities. For instance, RatGPT utilizes GPT-4 as a proxy method to distribute malicious software through the use of openly accessible LLM plugins, enabling access to the victim's machine [6]. Additionally, GPThreats-3 [8] explores how LLMs (GPT-3) can be utilized to generate malware itself, demonstrating success through a building-block prompting strategy. To attack hardware systems, LLMs can"}, {"title": "B. Impact of IP Piracy", "content": "The theft of hardware design IP, or IP piracy, is a significant concern within the system-on-chip design flow [16]. This can be attributed to the globalization of the integrated circuits supply chain, where semiconductor companies outsource their IP design to (potentially untrusted) fabrication entities to reduce the cost and time of chip production [34]. This has caused an increased risk of theft of IP assets shared by vendors (including RTL designs), causing significant security and economic consequences. A recent instance is observed within the dynamic random-access memory (DRAM) market. Micron, who held 20-25% of the global DRAM market share, reported estimated losses of $8.75 billion to IP piracy alone in 2018, demonstrating significant economic impacts [55]. Additionally, the semiconductor industry has been largely impacted, with the U.S. Trade Representative reporting losses between $225 to $600 billion as a result of Chinese theft of American IP [56], [19], [50].\nTo address this threat across the hardware design process, a number of hardware IP protection techniques [40] as well as piracy detection tools such as GNN4IP are utilized [78]. However, piracy detection tools such as GNN4IP have not been thoroughly tested. In this work, we show how LLMs can be used to pirate IPs and successfully evade tools such as GNN4IP."}, {"title": "C. Our Goals and Contributions", "content": "We propose an end-to-end automated LLM-based IP piracy scheme, LLMPirate, using which we can rewrite circuits, i.e., Verilog netlists, such that they evade detection by various IP piracy detection tools. Figure 1 illustrates the high-level idea. This requires designing an appropriate task for a given LLM, such that prompting it with a target netlist results in a design that is functionally equivalent to the original circuit, but is also different enough to not be flagged by piracy detection tools.\nHowever, several challenges exist in designing such an end-to-end automated IP piracy framework. First, LLMs are trained on extremely limited hardware designs, i.e., circuits described in hardware description languages such as Verilog"}, {"title": "D. Why LLMs?", "content": "A natural question here could be about the need of LLMS for hardware IP piracy. LLMs have shown tremendous improvement over the past few years, and today's LLMs are proficient at a variety of tasks including programming [37]. However, as we demonstrate in Sec. IV-A, LLMs still struggle with understanding simple Verilog netlists. Given this limitation of LLMs, a potential approach for a malicious human developer can be to manually rewrite netlists. However, such an approach would not be scalable. Additionally, the limitations of this manual approach are exacerbated by the fact that different piracy detection techniques use different types of algorithms (e.g., graph structural similarity, \"fingerprints\" of hashed Verilog netlist structures, and text-based comparisons). Another limitation of the manual approach is the requirement of additional effort for every new piracy detection technique. In contrast, LLMPirate offers an end-to-end automated flow to easily and quickly pirate hardware circuit netlists, enabling proper evaluation of existing and new piracy detection techniques."}, {"title": "II. BACKGROUND", "content": ""}, {"title": "A. Large Language Models", "content": "In recent years, large language models (LLMs) have emerged as powerful tools in natural language processing and related fields. These models, often based on deep learning architectures, exhibit remarkable capabilities in tasks such as text generation, translation [41], and sentiment analysis [42]. LLMs learn to represent language patterns and context by training on massive amounts of text data. Notable examples include GPT-3.5 (used in ChatGPT) [59], GPT-4 [58], Gemini [28], and Llama [47], among others. The remarkable success of LLMs can be attributed to their architectural innovation, in which transformer architectures are leveraged to enable parallel processing of sequential data, thereby efficiently capturing complex linguistic patterns and dependencies within text [75]."}, {"title": "B. Code Generation with Large Language Models", "content": "Among other avenues, LLMs have also brought a paradigm shift in code generation [37]. LLMs have demonstrated remarkable proficiency in generating code across different programming languages [15]. By leveraging the vast knowledge encoded in their pre-trained parameters, these models can"}, {"title": "C. IP Piracy Detection", "content": "Although there are many noteworthy works for measuring similarity, we choose four techniques for our evaluation, as explained next. Our selection of target similarity detection techniques ranges from the earliest tools with high popularity, MOSS [2], to the most recent, GNN4IP [78], which uses machine learning. We also select other tools, SIM [32] and Jplag [38], based on their high accuracy, impact, and popularity (see Table I for an overview). MOSS is arguably the most widely-used similarity measurement tool for codes. It has been used globally for decades [71], [73], [9], [18], has over 300K active accounts [21], and is also used in (or for the basis of) commercial tools for similarity detection, such as Gradescope [54] and Codequiry [17]. GNN4IP is the most powerful similarity measurement tool for Verilog, as it was developed with the specific objective of detecting IP piracy in Verilog code. Jplag, like MOSS, is also a widely-used similarity measurement tool that is used in universities [18]. Overall, our selection represents a set of similarity detection tools that use different frameworks, demonstrate excellent performance, and have been used extensively.\nGNN4IP is a piracy detection tool developed with the specific purpose of detecting hardware IP piracy [78]. It converts Verilog descriptions of hardware IP into graph representations and performs graph convolutions on those graphs in order to extract their node embeddings. By finding the cosine similarity between the embeddings of different IPs, it then becomes possible to determine if IP piracy has occurred.\nMOSS is a piracy detection tool developed by Stanford University [2], primarily utilized for detecting plagiarism in code across students in college-level computer science courses. MOSS uses the winnowing algorithm [69], which first breaks down code into tokens and hashes them using a hash function,"}, {"title": "III. THREAT MODEL", "content": "We consider a standard black-box attacker model applicable to piracy detection or similarity measurement techniques such as GNN4IP, MOSS, Jplag, and SIM. In this context, we establish the following assumptions about the attacker:\nAttacker's Knowledge. We assume a black-box setting, where the attacker lacks access to the detection tool's internal parameters (e.g., ML model's parameters or training labels, or internal parameters used in algorithms of the detection tool). The attacker can only make black-box queries to obtain output similarity scores or predicted labels (in case of ML-based techniques).\nAttacker's Capacity. The piracy attack occurs after the detection tool is finalized. Especially in case of machine learning (ML)-based techniques, the attack occurs after the model has undergone training. The detection tool remains fixed, and the adversary lacks the ability to alter its parameters or structure. For instance, the attacker cannot introduce model poisoning (for ML-based techniques) or inject backdoors.\nAttacker's Abilities. The attacker can rewrite the netlist arbitrarily, but not alter the netlist's functionality. Additionally, the attacker must adhere to circuit design rules.\nAttacker's Goal. The attacker's objective is to generate netlists that lead to misclassification by the target detection tool(s). For instance, when the target detection tool is GNN4IP, the attacker aims to create a pirated version of an original netlists such that GNN4IP incorrectly classifies the pirated netlist as \"not pirated\". Or, when the target detection tool is MOSS, the attacker aims to pirate an original netlist such that MOSS returns a low enough similarity score (determined by a threshold, explained in Sec. V)."}, {"title": "IV. METHODOLOGY", "content": "In this section, we first provide a preliminary formulation to pirate firm hardware intellectual property (IP), i.e., gate-level Verilog netlists, using LLMs. Then, we show that this preliminary formulation only works to an extent and doesn't help us successfully pirate IPs. Then we delve into the details of the limitations and describe the different challenges that need to be overcome to achieve our goal. We also devise solutions to address these challenges and build our framework, which successfully pirates hardware IP and evades detection by state-of-the-art piracy detection tools solely through black-box LLM access."}, {"title": "A. LLMs for Pirating IPs - Formulation, Challenges, and Solutions", "content": "Here, we devise a preliminary formulation using LLMs to pirate IPs in the form of gate-level netlists. To that end, consider the example prompt shown in Listing 1. Here, we simply ask the LLM to rewrite a Verilog gate-level netlist for an OR gate. Mathematically, this formulation can be represented as follows: The response R is obtained from the underlying distribution\n$p(R|Q,\\theta),$ (1)\nwhere $\\theta$ denotes the parameters of the LLM, Q denotes the query, and p represents the probability (since LLMs' responses are not deterministic).\nListing 2 contains the code portion of an example response from the LLM.2 The generated netlist is a valid gate-level netlist, but it is not functionally equivalent to the original (as it implements an AND gate, not an OR gate). Similar results hold true for other simple netlists as well, which leads us to the first challenge in pirating IPs."}, {"title": "Challenge 1: Difficulty Understanding and Rewriting Simple Hardware Circuit Netlists", "content": "Although LLMs understand the syntax of gate-level netlists and generate syntactically correct netlists that compile successfully, the generated netlists do not maintain the same functionality even for extremely small and simple modules. This is likely because most of the Verilog codes available on GitHub and other sources for"}, {"title": "Solution A: Prompt Syntax Translation For Hardware Netlists", "content": "To address this challenge, we revise the formulation to (i) extract only the relevant parts (i.e., the gates and not the module declarations, endmodule declaration, etc.) from the Verilog netlist, and (ii) translate the syntax of the extracted gates into a more generic format of Boolean functions (as opposed to gate declarations in the standard Verilog syntax). For instance, the standard Verilog syntax of \"or U1 (c, a, b);\" would be translated into a generic Boolean function format as \"c = OR(a,b)\u201d. Mathematically, in this updated formulation, the response R is obtained from the underlying distribution\n$p(R|T(Q),\\theta),$ (2)\nwhere T(Q) denotes that the query, Q, is processed to extract the relevant parts (i.e., the gates). These gates are then translated (denoted by T(\u00b7)) into a generic Boolean function format, which assists the LLM in generating better responses. Finally, note that the response R is also post-processed using $T^{-1}$, the inverse of T, to translate the generic Boolean function syntax back to the standard Verilog syntax. We omit this in the formulation for the sake of clarity. For additional information regarding the translation process, see Sec. VII-G of the Appendix.\nListings 3 and 4 show the translated prompt, T(Q), according to this updated formulation and the corresponding response, R, from GPT-3.5, respectively. As shown, the LLM is not only able to understand the provided circuit in the generic Boolean function format, but it actually rewrites the circuit correctly using the NAND and NOT Boolean functions while maintaining the overall functionality. Thus, theoretically, LLMs can be used to modify gates with the objective of evading evade piracy detection tools. However, in practice, when we use the above formulation (i.e., the one in Eq. (2)), we face challenges related to scalability and effectiveness. Next, we describe these challenges and how we overcome them."}, {"title": "Challenge 2: Lack of Scalability to Large Netlists", "content": "Although the LLM successfully rewrites the netlist in the example above, that example contains a toy netlist with just one gate. Real-world netlists contain several thousands, if not hundreds of thousands, of gates. To check the formulation's capability in scaling to larger netlists, we test for a small standard benchmark circuit, c17, which contains 6 gates, as shown in Listing 5. Following the formulation in Eq. (2), we query the LLM with the prompt shown in Listing 6. The LLM's response in Listing 7 shows that although it follows the instruction and uses different Boolean operators, the resulting circuit is"}, {"title": "Challenge 3: Limited Token Context Windows of LLMs", "content": "Another limitation of the above formulation is that rewriting netlists by simply providing all gates to the LLM is not possible. This is because all LLMs have finite input token context windows, meaning that the prompt size cannot be too large. For example, OpenAI's GPT-3.5 LLM (more specifically, gpt-3.5-turbo-0125) has a context window of 16,385 tokens [60], which, assuming \u22484 characters per token [63], translates to \u224865,540 characters. However, practical netlists containing thousands or more gates have hundreds of thousands of characters. Thus, it is not possible to rewrite realistic netlists by providing all gates to LLMs."}, {"title": "Solution B: Pre-characterization and Divide-and-conquer", "content": "To address these challenges, we modify the formulation by characterizing the given netlist, as explained next. Suppose we wish to rewrite a given Verilog gate-level netlist. Instead of simply extracting all the gates and translating them to create one big prompt (as shown in Listings 5 and 6), we first analyze the netlist and extract all the different gate types (e.g., 2-input AND gates, 3-input AND gates, XOR gates, etc.). Then, for each unique gate type, we create a representative circuit in a generic Boolean function format, as explained in Solution A above. Finally, for each representative circuit in the generic Boolean function format, we independently prompt the LLM to rewrite that circuit. Note that, for each representative circuit (i.e., gate type), we devise lists of specific Boolean operators (different from the gate in the original circuit) and instruct"}, {"title": "Challenge 4: Error-prone Single-shot Netlists", "content": "The final issue with the formulation described so far is that it only allows the LLMs one chance to generate a functionally equivalent circuit that uses different Boolean operators. However, due to randomness in the LLMs' responses and differing training processes (including number of parameters, size and quality of training data, and training processes such as pre-training, fine tuning, instruction tuning, reinforcement learning, etc.),"}, {"title": "Solution: Feedback-guided Interactive Formulation", "content": "To overcome this issue and ensure that LLMs are not penalized for minor mistakes, we leverage the interactive capabilities of LLMs by combining them with multi-level fine-grained feedback. More specifically, we allow the target LLM M attempts for each different gate type in G, the set of unique gate types. For each attempt, we first check if the generated response results in a valid circuit, i.e., the syntax adheres to the generic format of Boolean functions in which the input circuit is provided. If the response does not pass this check, we provide the LLM feedback about its incorrect format and ask it to try again. On the other hand, if the response passes this check, we then check if the generated circuit follows our instructions regarding the allowed set of Boolean operators (i.e., the allowed operators specified in the prompt instruction). If the circuit fails this second check, we provide the LLM feedback about the use of operators that are not allowed and ask it to try again. However, if the circuit passes this second check, we move on to the third check where we evaluate the functional equivalence of the generated circuit to the original circuit. Again, if the generated circuit is not functionally-equivalent to the original circuit, we provide the LLM feedback about the non-equivalence and ask it to try again. Whereas, if the generated circuit passes this third check, we save the generated circuit (for later use in pirating circuits) and move on to the next gate type. Note that, for each gate type, if any of the three checks fails, we count it as a failed attempt (and increment the counter for the number of attempts), so each LLM has M attempts to pass all three checks combined. As evidenced by our results, such interactive feedback-guided approach significantly improves LLMs performance (see Sec. V-H).\nThe updated mathematical representation for this formulation is as follows: The final response (after potentially up to M attempts) RM for the ith unique gate type is obtained from the underlying distribution\n$p(R\\vert C(R)\\frown T(Q),\\theta), j\\in \\{1, 2, ..., M\\}, \\forall i \\in \\{1, 2, ..., |G|\\},$ (4)\nwhere R denotes the LLM's response in the $j^{th}$ attempt for the $i^{th}$ unique gate type, and C(\u00b7) denotes a function that analyzes the response for the three checks mentioned above (syntax, allowed operators, and functionality) and produces a feedback according to the result of the checks. Additionally, $\\frown$ denotes concatenation, which combines the feedback with the original circuit, creating the query for the next attempt. We use this final formulation to generate functionally-equivalent but structurally different circuits for all unique gate types in the target netlist.\nNext, we describe our end-to-end flow of pirating Ver-"}, {"title": "B. Putting It All Together", "content": "Figure 2 illustrates the end-to-end flow. Given a netlist (or a set of netlists) to be pirated, we first perform pre-characterization (Solution B), which analyzes the netlist(s) to extract the different gate types. Then, for each different gate type, we use the list of allowed Boolean operators in Table II to create prompts following the generic Boolean operator syntax (Solution A). For instance, for each of the different AND gate types in the target netlist(s) (e.g., 2-input AND gate, 3-input AND gate, etc.), we create three prompts, one for each of the allowed Boolean operators: [NAND], [NOR], [OR, NOT]. This way, we create prompts for all different gate types for each of the corresponding allowed Boolean operators.\nThen, we pick a target LLM and query it for responses to these prompts, one after another. Additionally, as explained in Solution, after each response, we perform a series of checks (for syntax, use of only allowed Boolean operators, and functional equivalence). If any of these checks fail, we provide appropriate feedback to the LLM using a follow-up prompt. For instance, if the generated circuit fails the functionality check, we provide the following feedback \u201cThis is not correct because the functionality is not the same as the original circuit. Can you try again? Below is the original circuit:\", followed by the original circuit in the generic Boolean function format provided in the initial prompt. In this way, we provide the LLM M attempts to generate a circuit that passes all three checks. If, during any attempt, the LLM is successful, we save the generated circuit as a valid transformation of the original circuit so we can later use it for pirating netlists. For example Boolean transformations, see Sec. VII-I of the Appendix. On the other hand, even after M attempts, if the LLM is unable to generate a a circuit that passes all three checks, we exit the loop and move on to the next allowed Boolean operator or to the next gate type. Thus, at the end, we obtain a dictionary of functionally equivalent transformations for all (or some, depending on the success of the LLM) different gate types using all (or some) of the different allowed Boolean operators for the corresponding gate type. For further information regarding the contribution of each solution within the framework, see the ablation study in Sec. VII-E of the Appendix.\nNext, we describe how to pirate a given netlist using this dictionary of transformations. Recall that, for each different gate type, we have multiple transformations in the dictionary. In order to select the exact transformation to apply for a given gate when pirating a netlist, we devise five mapping strategies: AND_NOT, NAND, NOR, OR_NOT, and random. The NAND mapping strategy only uses the [NAND] transformation, the AND_NOT mapping strategy only uses the [AND, NOT] transformation, and so on. Finally, we pirate a given netlist using each of the five mapping strategies (one by one) by replacing the gates in the original netlist according to the transformation determined by the mapping strategy. Additionally, to overcome randomness, we repeat this process N times and evaluate each of the N \u00d7 5 pirated versions using the piracy detection tools to obtain the similarity scores.\nNote that, to ensure ease-of-use and wide application, the entire LLMPirate flow described above is automated end-to-end, from characterizing netlists, to creating prompts, querying LLMs, performing the three checks, providing feedback to the LLMs, creating pirated versions of netlists, and finally evaluating them using the detection tools. Additionally, we ensure that the pirated netlists are functionally equivalent to the original netlists through exhaustive simulation-based testing. We further validate equivalence using Cadence Conformal Equivalence Checker [12], an industry-standard commercial formal equivalence checker. We describe this in more detail in Sec. VII-D of the Appendix. Next, we demonstrate LLMPirate's efficacy in pirating netlists and evading a variety of detection tools.\""}, {"title": "V. RESULTS", "content": "We conduct a detailed experimental investigation of the capabilities of different LLMs to pirate hardware IPs. Next, we detail our experimental setup."}, {"title": "A. Experimental Setup", "content": "We implement LLMPirate using Python. We set M, the maximum number of attempts available to the LLMs, to be 5. We set N, the number of pirated netlists created for each mapping strategy to capture the effect of randomness (Sec. IV-B), to be 5. We use a dataset of 31 different Verilog netlists from the GNN4IP repository for our experiments [1]."}, {"title": "B. Main Piracy Results", "content": "Figure 3 shows the distribution of best (i.e., the lowest) similarity scores from the four detection tools for the 32 netlists in our dataset. It is clear that using LLMPirate, we are successfully able to pirate all 32 netlists against all four detection tools with very limited variance in performance. Note that since MOSS limits use to 100 queries per day per user [2],"}, {"title": "C. LLMs Against GNN4IP", "content": "To evaluate the LLMs' ability to pirate Verilog netlists, we first analyze GNN4IP's similarity scores between each of the pirated netlists and the original netlists. Figure 4, summarizes these values across all 32 netlists for each LLM. Note that the distribution of similarity scores plotted for each netlist for each LLM are for the best mapping strategies for that netlist and LLM.\nHere are the key takeaways from the figure: (i) Most"}, {"title": "D. LLMs Against MOSS", "content": "Here, we repeat the evaluation process using MOSS as the piracy detection tool. As explained in Sec. V-B, due to restrictions on the number of queries, the plots for MOSS in Figure 5 are bar plots showing the single similarity score instead of box plots showing the distribution of similarity scores. Note that these single similarity scores still provide enough information to analyze the performance of LLMs against MOSS. Also, as in Sec. V-C, the similarity score plotted for each netlist for each LLM is for the best mapping strategy for that netlist and LLM.\nHere are the key takeaways: (i) All LLMs except CL-7B evade MOSS for all netlists. (ii) As with GNN4IP, CL-13B"}, {"title": "E. LLMs Against JPlag", "content": "Here, we use the same evaluation procedure using Jplag as the piracy detection tool. In the interest of space, we plot the figure in Sec. VII-B of the Appendix (Figure 15) and explain the key takeaways here: (i) Most closed-source LLMs (CoPilot, GPT-3.5, GPT-4, Claude) successfully evade detection across all 32 netlists. (ii) As seen before, CL-13B performs better than the smaller CL-7B. (iii) As with MOSS, the open-source Llama3-8B performs almost as well as the larger models, successfully bypassing JPlag for all but one netlists."}, {"title": "F. LLMs Against SIM", "content": "The evaluation is again repeated using SIM as the piracy detector, with Figure 16 (in Appendix Sec. VII-B) illustrating the similarity scores. Here are the key takeaways: (i) Due to the lack of compatibility with Verilog and the text mode of operation of SIM, it results in unusually high similarity scores because Verilog keywords (e.g., nand, and, etc.) are repeated frequently in the netlists. (ii) Nonetheless, GPT-3.5 and GPT-4 still evade SIM for 25 netlists. (iii) Llama3-8B, with 11 successes, performs the best among open-source models."}, {"title": "G. Analysis of Mapping Strategies", "content": "So far, we analyzed the main piracy results against four detection tools, and the performance of different LLMs against different tools. Now, we take a closer look at the performance of the five mapping strategies, AND_NOT, NAND, NOR, OR_NOT, and random. More specifically, to understand the relative performance of these mapping strategies, we analyze them in terms of the number of successful instances of evasions (over all netlists and all LLMs) and the average similarity scores of those instances against GNN4IP (Figure 6). It is evident that the random strategy yields the largest number of"}, {"title": "H. LLMs' Performance Comparison", "content": "Next, we compare the performance of the LLMs in generating successful transformations according to the allowed Boolean operators in Table II (e.g., AND gate using NOR operators, etc.). Recall that we allow each LLM a maximum of M = 5 attempts for each different gate type. Additionally, if an attempt fails, we also provide fine-grained feedback about syntax, use of correct Boolean operators, or functionality in allow the LLM to fix its mistakes. To that end, Figure 7 shows the total number of successful transformations generate by different LLMs as a function of the number of attempts. It is evident that, after 5 attempts, there are two classes of LLM in terms of number of successful transformations. The first class consists of GPT-4, CoPilot, Claude, and GPT-3.5, with 33, 28, 23, and 21 successful transformations, respectively. The second class consists of CL-13B, Gemini, Llama3-8B, and CL-7B, with significantly fewer successful transformations. This explains why the LLMs from the second class are sometimes unable to evade some detection tools. A surprising observation is that Gemini (one of the closed-source LLM that performs similar to the GPT models on other common tasks) struggles with our task of rewriting circuits. The exact reason behind this is difficult to know, however, a possible reason could be a lack of enough Verilog/circuit training data. Another observation from the figure is that all LLMs improve with more attempts and feedback. This validates our Solution of devising a feedback-guided interactive formulation for our task.\nWe also analyze the impact of multiple attempts through"}, {"title": "I. Case Study on the IBEX Processor: Ramifications of LLMPirate", "content": "In this subsection, we demonstrate and discuss the performance of LLMPirate on a real-world netlist, the IBEX processor [44] in more detail. Specifically, we run our end-to-end automated flow of LLMPirate to pirate the processor using our mapping strategies and the corresponding transformations obtained from the eight LLMs. Then, we query GNN4IP to get the similarity scores between our pirated netlists and the original netlist. Note that, similar to related works, we assume full-scan access to ensure compatibility of the netlists with GNN4IP [27]. Figure 9 compares the distribution of the GNN4IP similarity scores for the eight LLMs. Note that, as earlier, the distributions are for the best-performing strategy. We observe that seven out of the eight LLMs (all except CL-7B) successfully evade GNN4IP. Thus, LLMPirate easily fools GNN4IP into classifying pirated versions of IBEX as not pirated. Moreover, the distribution of the GNN4IP similarity scores is extremely low for CoPilot and Claude, meaning that not only is GNN4IP evaded, the magnitude of the incorrect detection is extremely high. This case study demonstrates the capabilities of LLMPirate, which can lead to piracy of practical netlists, and failure of the state-of-the-art piracy detection tool in catching it."}, {"title": "J. Case Study on Larger Netlists: Scalability of LLMPirate", "content": "Recall that LLMPirate first generates and caches (i.e.", "netlists": "a GPS module from Common Evaluation Platform [52", "5": "containing \u2248 158K gates. We observed that LLMPirate generates pirated netlists within seconds. Additionally, these netlists successfully evade MOSS [2", "38": "and SIM [32", "78": "always classifies these LLMPirate-generated netlists as pirated. This unusual result might lead one to"}]}