{"title": "Mew: Multiplexed Immunofluorescence Image Analysis through an Efficient Multiplex Network", "authors": ["Sukwon Yun", "Jie Peng", "Alexandro E. Trevino", "Chanyoung Park", "Tianlong Chen"], "abstract": "Recent advancements in graph-based approaches for multiplexed immunofluorescence (mIF) images have significantly propelled the field forward, offering deeper insights into patient-level phenotyping. However, current graph-based methodologies encounter two primary challenges: Cellular Heterogeneity, where existing approaches fail to adequately address the inductive biases inherent in graphs, particularly the homophily characteristic observed in cellular connectivity; and Scalability, where handling cellular graphs from high-dimensional images faces difficulties in managing a high number of cells. To overcome these limitations, we introduce Mew, a novel framework designed to efficiently process mIF images through the lens of multiplex network. Mew innovatively constructs a multiplex network comprising two distinct layers: a Voronoi network for geometric information and a Cell-type network for capturing cell-wise homogeneity. This framework equips a scalable and efficient Graph Neural Network (GNN), capable of processing the entire graph during training. Furthermore, Mew integrates an interpretable attention module that autonomously identifies relevant layers for image classification. Extensive experiments on a real-world patient dataset from various institutions highlight Mew's remarkable efficacy and efficiency, marking a significant advancement in mIF image analysis.", "sections": [{"title": "1 Introduction", "content": "Multiplexed immunofluorescence (mIF) imaging is a pivotal technique for the simultaneous detection and visualization of multiple protein targets within a single tissue sample. Utilizing antibodies labeled with diverse fluorescent dyes, mIF enables the identification and quantification of numerous biomarkers at the cellular level. This method offers a comprehensive view of the cellular composition and spatial interplay within tissue microenvironments, proving invaluable in oncology, immunology, and pathology."}, {"title": "2 Related Works", "content": "Multiplexed Immunofluorescence Image Analysis. Multiplexed immunofluorescence (mIF) imaging is a sophisticated technique that allows for the simultaneous detection and quantification of multiple biomarkers within a single tissue section, providing a comprehensive view of the cellular and molecular landscapes. The field of mIF image analysis has witnessed considerable evolution, transitioning from early methods employing traditional image processing techniques to the latest advancements that integrate spatial information with deep learning. Initially, mIF approaches predominantly relied on spectral unmixing and manual annotation for identifying and quantifying cellular markers. Introducing convolutional neural networks (CNNs) marked a significant leap forward, enhancing cell classification, feature extraction, and biomarker detection. Notably, the adoption of deep learning architectures like U-Net and 3D U-Net for dense volumetric segmentation has set new benchmarks in the field. Moreover, the application of GANs for data augmentation and the innovative use of transformers for capturing long-range dependencies within images have further enriched the analytical capabilities in mIF analysis. Recent research frontiers have moved towards incorporating spatial information, with innovations like SPACE-GM exemplifying this trend. SPACE-GM, leveraging spatial cellular graphs, employs graph-based ML models to elucidate intricate spatial cell interactions, thereby enriching our understanding of the tissue microenvironment. Despite these advancements, optimally addressing cellular heterogeneity in the context of graph-based ML remains a critical challenge to be addressed.\nGraph Neural Networks. Graph-based ML has seen a surge of innovation with the development of various models, each marking a milestone in the field. Graph Convolutional Network (GCN) played a crucial role in popularizing Graph Neural Networks (GNNs) by adapting convolutional principles to graphs. Building upon this, the Graph Attention Network (GAT) introduced attention mechanisms, enabling refined weighting of node interactions. GraphSAGE furthered this progression by facilitating inductive learning via a novel neighborhood sampling and aggregation approach. Addressing scalability, the Scalable Inception Graph Neural Networks (SIGN) streamlined the application to larger graphs through precomputed neighborhood information. ClusterGCN tackled large-scale graph learning by employing graph clustering techniques. In the realm of heterogeneous graphs, Deep Multiplex Graph Infomax (DMGI) leveraged unsupervised learning across varied node and edge types. More recently, High-order Deep Multiplex Infomax (HDMI) has innovatively incorporated high-order mutual information for self-supervised node embedding. Collectively, these models have significantly advanced graph-based ML, addressing challenges like scalability, heterogeneity, and unsupervised learning. Despite these advancements, their application to extensive spatial image datasets, such as mIF data, remains underexplored, particularly in terms of cellular heterogeneity and scalability."}, {"title": "3 Methodology", "content": "In this section, we present Mew, a novel algorithm tailored for mIF image analysis through a multiplex network approach, utilizing Voronoi and Cell-type networks. Initially, for a given mIF image, preprocessing steps like Delaunay triangulation and cell segmentation are executed to derive two distinct networks based on different edge types to generate a multiplex network (Sec 3.1). Keeping the multiplex network concept central, we apply scalable Graph Neural Networks for efficient training in a whole graph perspective with a stochastic edge sampling technique (Sec 3.2). This is followed by the Voronoi-Cell-type Attention, which seamlessly integrates the information of each network (Sec 3.3), culminating in the prediction of the patient's phenotype.\nTask - Patient-level Phenotyping: Binary Classification and Hazard Modeling. For each image I in a set of patient samples with a total number of \\(I_N\\), we transform these images into a series of graphs \\(G_1, G_2, ..., G_{I_N}\\). Each graph, \\(G_i\\), for all \\(i \\le I_N\\), consists of a set of nodes and edges that represent sample i and its associated phenotypes \\(Y_i\\). These phenotypes are categorized into two groups: Binary Classification and Hazard Modeling. For each phenotype prediction task, a multi-task learning approach is adopted, which integrates the losses from each task, such as the primary outcome or recurrence in the case of binary classification. Reformulated as a graph classification task within a supervised learning framework, the primary objective of Mew is to develop a scalable, efficient graph model that can accurately predict the phenotype of a given sample."}, {"title": "3.1 Multiplex Network Generation", "content": "This section outlines the process of generating a multiplex network from spatial cellular graphs, incorporating two distinct relational types. Initially, with each sample provided as an image, constructing a graph structure becomes imperative to harness the geometry information. This involves leveraging a message-passing scheme with connected neighbors. To extract geometric data like cell coordinates, we utilize the preprocessing approach of SPACE-GM [59]. Here, cell nuclei, identified using the DeepCell neural-network segmentation tool [19], are processed with segmentation masks to yield 2D cellular coordinates represented as discrete points in Euclidean space. Subsequently, to delineate neighborhood relations, Delaunay triangulation was applied to these cellular centroids. This results in Voronoi diagrams linked via circumcircle centers. Each image is thus transformed into a graph where nodes represent cellular centroids and edges denote connections between neighboring Voronoi polygons. Formally, this graph is represented as follows:\n\\[G^I = (V^I,\\mathcal{E}^I),\\forall I \\in \\{1, ..., I_N\\}\\]\nwhere \\(G^I\\) represents the Voronoi graph of image sample I, comprising a set of cellular nodes \\(V^I\\) and their connecting edges \\(\\mathcal{E}^I\\).\nConcurrently, individual cell biomarkers identified by CODEX are processed through principal component analysis (PCA) and Louvain graph clustering [2], yielding cell-type annotations for each cell. Diverging from existing approaches that use cell-type as a mere feature within a concatenated matrix, we adopt an orthogonal strategy. We argue that cell-type information can provide distinctive direction besides the geometry information, which contains shared expressions of biomarkers, and overall cell-type populations can play a crucial role in graph classification tasks like predicting primary outcomes or HPV infection. This approach addresses the cellular heterogeneity observed in Figure 2 (a) through message-passing exclusively among nodes sharing the same cell-type. Formally, for a set of cell-types \\(C^I\\) in image I, they are depicted as follows:\n\\[G'^I = (V'^I,\\mathcal{E}'^I),\\forall I \\in \\{1, ..., I_N\\}\\]\nwhere \\(\\mathcal{E}'^I = \\{(v'_i,v'_j)|C^I_i = C^I_j, \\forall i, j \\in \\{1, ..., |V'^I|\\}, i \\neq j\\}\\)\nwhere \\(G'^I\\) represents the additional graph composed of nodes \\(V^I\\) and edges \\(\\mathcal{E}'^I\\) that connect nodes sharing the same cell-type. It's crucial to note that, since the nodes (i.e., cell nuclei) originate from the same image I, the node sets are identical (\\(V^I = V'^I\\)), as depicted in Figure 3. However, the relationship type varies (\\(\\mathcal{E}^I \\neq \\mathcal{E}'^I\\)). Incorporating this cell-type network results in a multiplex (multi-layered) network as follows:\n\\[\\tilde{G}^I = (G^I,G'^I)\\]\nwhere \\(\\tilde{G}^I\\) denotes a multiplex network comprising the Voronoi network \\(G^I\\), which captures local geometric information, and the cell-type network \\(G'^I\\), responsible"}, {"title": "3.2 Scalable Graph Neural Network", "content": "Now, given a multiplex network, the challenge lies in efficiently handling the graph input to derive node embeddings rich in information relevant to phenotype prediction. Direct application of Graph Neural Networks (GNN) [9,27,58] to the dataset is hindered by scalability challenges, as detailed in Figure 2 (b). The number of cells per sample in the dataset varies widely, from 837 to 19,611, with an average of 6,691 cells, culminating in a total of 2,061,066 cells. This presents a significant challenge compared to current Graph Neural Networks, typically benchmarked on datasets with a single graph of 2,000-19,000 nodes. To address such scalability issues, inspired by the efficient precomputation and fast training and inference of SIGN [13], we apply a similar precomputing strategy first to the Voronoi network (\\(G^I\\)), which can be described as follows:\n\\[\\mathcal{H}^I = \\sigma([X^IW^{(0)}, A^{(1)}X^IW^{(1)}, ..., A^{(K)}X^IW^{(K)}])\\]\n\\[Z = g(\\mathcal{H}^IW_z)\\]\nwhere \\(\\mathcal{H}^I \\in \\mathbb{R}^{|V^I|\\times D(K+1)}\\) is a concatenated embedding matrix for \\(|V^I|\\) nodes in image I, encompassing the original matrix and K-hop elements, each transformed into a hidden dimension D. \\(A^{(k)} \\in \\mathbb{R}^{|V^I|\\times |V^I|}, \\forall k \\le K\\) represents the symmetrically normalized adjacency matrix (\\(D^{-1/2}\\hat{A}D^{-1/2}\\), with self-loops added, \\(\\hat{A}\\), and its corresponding degree matrix D) after k iterations of multiplication, capturing up to k-hop neighbor cells in image I. \\(W^{(k)} \\in \\mathbb{R}^{F\\times D}\\) is a weight matrix transforming the original feature space F into the embedding space D for each k. The concatenated output, comprising message-aggregated (AX) matrices and parameters, now generates the embedding matrix\\(^{\\circledR}\\), \\(Z \\in \\mathbb{R}^{|V^I|\\times D}\\), processed by the final weight matrix \\(W_z \\in \\mathbb{R}^{D(K+1)\\times D}\\) with nonlinearities \\(\\sigma\\) and \\(\\xi\\). Notably, these elements \\(X^I, A^1X^I, A^{(1)}X^I, A^{(k)}X^I\\) can be efficiently precomputed\nDiscussion on Message-Aggregation in the Cell-type Network. Recall that we are working with a multiplex network (\\(\\tilde{G}\\)), where the cell-type network (\\(G'\\)) plays a pivotal role alongside the Voronoi network (G). One might consider employing scalable GNNs as discussed in Equation 4. However, since all nodes of the same cell type are directly connected in \\(G'\\), each node accesses its neighbors in just 1-hop, as shown in Figure 3 (refer to the Cell-type network). Although effective for aggregating information from the same cell-type nodes, this 1-hop approach does not incorporate new information beyond the 2-hop range, limiting the message-passing scheme's generalizability, particularly in distinguishing between short-range and long-range connections.\nTo address this and enhance generalizability, we introduce a new Stochastic Edge Sampling technique that samples edge indices based on their distance. A simple method is to introduce an edge-deleting hyperparameter and delete edges (\\(\\mathcal{E}'\\)) in the cell-type network. However, selecting a fixed hyperparameter could disrupt meaningful connections by not adequately considering the semantics of neighboring and distant relationships. Our method capitalizes on the normalized distances between cellular centroids derived from Voronoi polygons. Contrary to SPACE-GM, which considers edges shorter than 20 \\(\\mu\\)m as neighboring and designs separate embeddings based on edge length, we directly use distance as a probability for edge sampling. These distances, normalized between 0 and 1, role as the main resource for our stochastic edge sampling strategy. We construct a distance pair matrix, \\(P^I \\in \\mathbb{R}^{|V^I|\\times |V^I|}\\), and its complement, \\(\\bar{P}^I = 1 - P^I\\), adhering to the principle that closer nodes are more influential [36]. Biologically, the importance of proximity among identical cell types is underscored by studies indicating that neighboring cells of the same type often form local clusters or specialized microenvironments.\nIn essence, our stochastic edge sampling method aims to differentiate the influence of neighboring versus distant nodes, thereby enriching the model's ability to capture biologically significant interactions. This approach can be formally expressed as follows:\n\\[A^I_{ij} = \\begin{cases}\n1 & \\text{if } \\text{Bernoulli}((\\bar{P}^I_{ij})) = 1 \\\\\n0 & \\text{Otherwise}\n\\end{cases}\\]"}, {"title": "3.3 Voronoi-Cell-type Attention", "content": "Equipped with two embedding matrices, Z and Z', derived from the Voronoi network and the Cell-type network respectively, we now apply Voronoi-Cell-type Attention. This mechanism is designed to autonomously discern the significance of each network's contribution towards relevant downstream tasks, such as binary classification or hazard modeling. Focusing on a specific cell's embedding vector, l, in image I, the attention mechanism operates as follows:\n\\[\\tilde{z}^I_l = \\alpha^I_{l,\\text{Voronoi}}z^I_l + \\alpha^I_{l,\\text{Cell-type}}z'^I_l\\]\nwhere \\(\\tilde{z}^I_l \\in \\mathbb{R}^D\\) is the resulting embedding vector that encapsulates the significance of each network. Here, attention coefficients are calculated as \\(\\alpha^I_{l,\\text{Voronoi}} = \\frac{\\exp(a)}{\\exp(a) + \\exp(a')}\\) and \\(\\alpha^I_{l,\\text{Cell-type}} = \\frac{\\exp(a')}{\\exp(a) + \\exp(a')}\\), where a = LeakyReLU\\((\\alpha^Tz^I_l)\\) and a' = LeakyReLU\\((\\alpha^Tz'^I_l)\\) indicate attention scores, derived using a learnable vector \\(\\alpha \\in \\mathbb{R}^D\\) and LeakyReLU activation with a negative slope of 0.3. This method discerns the relative importance of the Voronoi (emphasizing coordinate information of neighboring cells or localized tumor microenvironments) and cell-type networks (highlighting specific cell-type populations and related information) for predictions. For binary classification task, the final training loss for Mew integrates both networks' knowledge, calculated via \\(\\mathcal{L}_{ce} = \\Sigma_{l\\in I_N} CE(Pool(P_l), y^I)\\), where \\(CE(.)\\) represents cross-entropy loss between the pooled predictions P and their labels. A 3-layer MLP serves as the prediction head, mapping embeddings to class predictions, with dimensions reflecting nodes \\(|V^I|\\) and classes C. For the hazard modeling task, Cox partial likelihood substitutes the cross-entropy loss to refine the Stochastic Gradient Descent loss calculation [29]."}, {"title": "4 Experiments", "content": "Experimental Settings. Given that the mIF image benchmark dataset is not widely publicized, we chose to utilize the most recently available datasets from primary human cancer resections, following the precedent set by SPACE-GM [59]. The data originates from three distinct institutions: the University of Pittsburgh Medical Center (UPMC), Stanford University (Stanford), and the Dana-Farber Cancer Institute (DFCI). This compilation includes three different 40-plex CODEX datasets, totaling 658 sample images. These samples encompass 139 patients diagnosed with head-and-neck cancer (HNC) and 110 patients with colorectal cancer (CRC), resulting in the datasets being categorized as UPMC-HNC, Stanford-CRC, and DFCI-HNC. In the UPMC-HNC dataset, we split the 7 coverslips into 4 for training, 1 for validation, and 2 for testing, and perform binary classification and hazard modeling tasks for patient-level phenotyping. For the Stanford-CRC dataset, given 4 coverslips, we allocate 2 for training, 1 for validation, and 1 for testing, proceeding with the same tasks. To ensure robust predictions, we randomly generated 3 folds for both UPMC-HNC and Stanford-CRC, each with different training, validation, and test coverslips. In the DFCI-HNC dataset, we perform a generalization task using all UPMC-HNC samples for training and evaluate on unseen DFCI-HNC images. We used biomarker expression and cell size as features for both the Voronoi and cell-type networks, while cell type information was used to build the cell-type network. To ensure a fair comparison, we incorporated cell type information as additional features in other baselines. For more detailed experimental settings, including evaluation metrics, baselines, and implementation details, please refer to Appendix C."}, {"title": "4.1 Patient-level Phenotype Prediction", "content": "In Tables 1 and 2, we showcase the performance results of phenotype prediction across the UPMC-HNC, Stanford-CNC, and DFCI-HNC datasets. Our observations highlight: (1) Above all, compared to all the baselines with each specific downstream task, Mew consistently outperforms in both Binary Classification and Hazard Modeling, with notable improvements of 21.14% and 8.93% in Average (BC) compared to the most recent SPACE-GM model and the top-performing GCN model in Table 2. (2) Notably, Mew also excels in the Generalization task, with improvements of 8.47% over the most recent and top-performing SPACE-GM model. This success is attributed to our unique multiplex network approach, particularly the effective use of a cell-type network in the Generalization task. This network leverages the commonality of cell compositions across domains in mIF images (e.g., B cells and tumor cells), thereby establishing the uniqueness of our work. (3) While multiplex network models like HDMI show potential in the Recurrence task in Binary Classification (see Table 1) due to their incorporation of high-order mutual information, the lack of a cell-type network prevents the multiplex network framework from fully benefiting, especially in the mIF image domain. (4) GNNs that manage heterophilous environments, such as FAGCN, encounter difficulties in analyzing mIF images. This underscores that when analyzing mIF images, it is crucial not only to manage the heterophilous environment but also to simultaneously capture geometric information, which aligns with the design principles of Mew."}, {"title": "4.2 In-depth analysis of Mew", "content": "Ablation Studies. In Figure 5, we unveil key insights: (1) A synergistic benefit is observed when combining both the Voronoi network (G) and the Cell-type network (G') to generate a Multiplex network (\\(\\tilde{G}\\)), rather than relying solely one of them. (2) The Stochastic Edge Sampling technique (S) fully leverages its benefits within the Multiplex network framework, as its application solely to the Cell-type network omits information from the Voronoi network. (3) Given a Multiplex network, the optimal strategy for information fusion transcends mere addition or concatenation; the integration of the Voronoi-Cell-type Attention emerges as the most effective approach. (4) In Figure 5 (b), within the 'Recurrence Interval' plot, although the performance of Mew and the Voronoi network (G) seem comparable, it is crucial to note that a multi-task learning setting is employed for each patient-level phenotyping task, such as Binary Classification or Hazard Modeling. This distinction becomes evident in the 'Survival Length' task, where Mew exhibits superior performance compared to using the Voronoi network alone, thereby underscoring the effectiveness of our proposed framework.\nHow Cell-type network contributes? Here, we explore the effectiveness of Mew, with a focus on the Cell-type network's contribution to heterophilous scenarios. Figure 6 (a) showcases a comparison between the performance of Mew and SPACE-GM. The histogram plot reveals that most images fall within low homophily rates (e.g., 0.25-0.34), where the performance disparity between Mew and SPACE-GM becomes evident. We delved deeper into a scenario where the performance disparity was most pronounced, notably in the 0.28 to 0.30 bin where Mew accurately identified the phenotype and included a representative cellular graph example from that bin. As illustrated by Figure 6 (b), our analysis of the distribution of attention scores across layers highlighted the Cell-type network's critical role, with an average attention score of 0.66, in contrast to the Voronoi network's 0.34. Importantly, the Cell-type network highlighted the significance of various tumor cells, like Tumor 2 (Ki67 Proliferating) a marker for proliferation rates and highlighted B cells, signaling an immune response to the tumor. This level of detail and insight was unattainable with the Voronoi network alone, which primarily captures local geometric heterogeneity. Overall, these findings emphasize the Cell-type network's capacity to improve phenotype prediction, providing valuable interpretability in heterophilous settings."}, {"title": "4.3 Scalability and Generalizability of Mew", "content": "Scalability. This section highlights the criticality of scalability in the preprocessing, training, and evaluation phases of the graph model. Table 3 demonstrates how Mew adeptly addresses scalability challenges. This is largely attributed to the implementation of scalable GNNs, which significantly reduce preprocessing time compared to SPACE-GM. SPACE-GM traditionally saves 3-hop neighbors as chunks prior to training, resulting in considerable time complexity and memory usage, often exceeding an hour. While this approach may expedite the training process, the overwhelming preprocessing costs diminish overall efficiency. Mew, on the other hand, offers two primary advantages: (1) It broadens the node perspective by incorporating the entire graph directly (\\(|V|\\)=117,974 versus SPACE-GM's \\(|V|\\)=1,071), avoiding the need for manual sampling and storing of 3-hop local graphs as chunks, thereby reducing preprocessing time significantly. (2) It achieves remarkably low evaluation times due to the upfront preprocessing efforts (0.53s to evaluate 53 graphs versus SPACE-GM's 60.28s). Once the precomputation of AX is completed, the bulk of computational work shifts to the forward pass of the weight parameters and the precomputed ones. As a result, Mew stands out as an exceptionally efficient and feasible model for real-world phenotype prediction, where swift decision-making is crucial.\nGeneralizability. To achieve greater generalizability in real-world scenarios where cell-type annotations may be unavailable, a straightforward remedy is to utilize and harmonize with recent advancements in cell-type annotation methods [6,41] to supplement annotations, enabling the construction of cell-type networks for running Mew. When annotations are partially available, pseudo-labeling methods such as Label Propagation [62] can be used. In extreme cases with no annotations, K-Means clustering [28] can provide a cell type index. We verify applicability in such cases using the Broad Bioimage Benchmark Collection and demonstrate generalizability to other domains such as Whole Slide Images in Appendix D."}, {"title": "5 Limitation", "content": "Despite the effectiveness and efficiency of Mew in processing mIF images, relying exclusively on image modality in real-world scenarios may lead to suboptimal outcomes for patient-level phenotype prediction. Intriguingly, our future work will aim to incorporate additional modalities, such as genomic and clinical data, to enhance the final prediction accuracy. In this context, we anticipate that the current multiplex network can be further expanded by adding layers specific to each modality, provided common properties, such as cell indices, are available. This approach promises to significantly enrich the model's interpretability and predictive power by leveraging the synergies between different types of data."}, {"title": "6 Conclusion", "content": "In this paper, we address two critical challenges inherent in applying spatial graph-based ML to mIF images: \u2460 Cellular Heterogeneity and \u2461 Scalability of mIF cellular graphs. Recognizing the heterogeneous nature of cellular data, we propose the generation of a Multiplex Network by incorporating an additional Cell-type network, naturally complementing the inductive biases of GNNs. Furthermore, to ensure practical applicability in real-world scenarios, we have developed a scalable Graph Neural Networks equipped with a novel stochastic edge sampling technique. This architecture is further enhanced by a Voronoi-Cell-type Attention which assesses the significance of each network. Rigorous testing on real-world patient datasets has consistently highlighted the robustness and superior efficacy of our proposed method, Mew, showcasing its potential to pioneer a new and promising direction for advancing mIF image analysis."}]}