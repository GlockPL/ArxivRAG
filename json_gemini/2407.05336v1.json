{"title": "Artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization", "authors": ["Jakob M\u00f6kander", "Ralph Schroeder"], "abstract": "In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, i.e., the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards Al systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby Al systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that Al-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens' sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that Al systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means \u2013 they cannot dictate the ends. Nonetheless, the use of Al in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, Al-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.", "sections": [{"title": "1. Introduction", "content": "The use of artificial intelligence (AI) systems increasingly permeates modern societies, including the public sector (Wirtz et al., 2019). This means that many decisions that were previously made by human experts are now made by Al systems (Zarsky, 2016). The drivers behind this development are clear: enabled by recent advances in machine learning (ML) research and fuelled by the growing availability of large, fine-grained digital data sources (Wiggins & Jones 2023), Al systems can improve the efficiency and consistency of existing decision-making processes and enable new solutions to complex optimization problems (Taddeo & Floridi 2018). Al systems enable good governance in two ways: directly, by automating and personalizing public service delivery, and indirectly, by informing policy design through more accurate forecasting and simulations of complex systems (Margetts & Dorobantu, 2019). These advantages are not merely hypothetical. Empirical studies have documented governments' use of Al systems across a range of applications and geographic settings; from streamlining immigration procedures through biometric and biographic matching in New Zealand (Nalbandian, 2022) to facilitating preventive healthcare in China (Sun & Medaglia, 2019).\nHowever, the use of Al systems in the public sector is coupled with ethical and legal risks. For example, it may produce discriminatory outcomes, violate individual privacy, and enable human-wrongdoing (Tsamados et al., 2021). A study of COMPAS \u2013 an Al-powered decision tool used by US courts to predict criminal recidivism \u2013 found that it systematically discriminated against African-American defendants by overestimating their likelihood of reoffending (Angwin et al., 2016). Another controversy took place in the Netherlands, this time surrounding a data-driven welfare fraud detection system referred to as 'SyRI.' In addition to discriminating against minorities, it was found that SyRI's linking of personal data from multiple sources did not comply with the right to privacy under the European Convention on Human Rights (van Bekkum & Borgesius, 2021). In short, there are many examples of instances where Al systems have caused harm, or at least failed to work as advertised (Kapoor & Narayanan, 2022).\nAgainst this backdrop, it is understandable that researchers and policymakers have called for increased fairness, accountability, and transparency with respect to the use of Al systems. There is, for example, a vast academic literature on how to design and deploy Al systems that are legal, ethical, and safe. Standard-setting bodies have provided similar guidance\u00b2 and policymakers have proposed hard regulations to manage the risks Al systems pose.\u00b3 These initiatives tend to emphasize the novelty of Al systems and the ethical challenges they pose. The upside of this framing is that it gives a sense of urgency to the cause of addressing the issues under consideration here. However, there are also downsides to overemphasizing the novelty of specific technologies and social phenomena.\nIn this paper, we argue that the contemporary discourse concerning the social challenges associated with the use of Al in the public sector is best understood against the backdrop of a longer trajectory whereby calculability is increasingly imposed on social processes. Specifically, we demonstrate that the use of Al systems in the public sector can be viewed as a continuation and intensification of ongoing rationalization and bureaucratization processes. Drawing on the work of Max Weber, we take the core of these processes to be the replacement of personalistic rule, tradition, and emotion as motivations for behaviour by instrumental rationality, i.e., the most calculable, efficient, predictable,"}, {"title": "2. Artificial intelligence as Weberian rationalization", "content": "In this section, we define the two central concepts of our analysis: Al and rationalization. Both are disputed concepts which have eluded widely agreed-upon definitions. For example, Legg and Hutter (2007) list no fewer than 70 competing and partly conflicting definitions of Al. Similarly, the term rationalization has different meanings in different contexts.\nFollowing the OECD (2021), we define an Al system as a machine that can, for a given set of objectives, make predictions, recommendations, or decisions influencing its environment. It does so by processing input data to (i) perceive its environment, (ii) abstract perceptions into models of the external environment, and (iii) use model inference to structure information or perform actions in an automated manner. An Al system \"learns\" insofar as it updates its model and internal decision-making logic as it is fed new input data. The model itself can be based on ML algorithms such as deep neural networks (LeCun et al., 2015), formal logic as in expert systems (Giarratano & Riley, 2004), or a combination thereof as in hybrid systems (Marcus, 2020). In some cases, a model based on deterministic rules offers a single recommendation. In other cases, models based on probabilistic reasoning can offer a variety of recommendations. In each case, however, pre-defined objectives stipulated by humans guide both the model inference phase and the subsequent execution.\nFor our purposes, this definition has three advantages. First, it bypasses any distracting discussions about machine consciousness by focusing solely on the observable characteristics and operations of Al systems. As noted by Esposito (2022), if Al systems appear intelligent, this is not because they have learned how to think but because we have learned how to communicate with them in ways that advance our purposes. Second, the definition is broad enough to encompass symbolic (logic-based) and sub-symbolic (ML-based) Al systems, both of which play important roles in optimizing social policies and automating their execution. Third, it highlights how Al systems operate with varying levels of complexity and autonomy in larger human-centric decision-making processes (M\u00f6kander et al., 2023). To explain why that is the case, we must first define our second central concept.\nWith rationalization, Weber understood a long-term process whereby beliefs based on tradition are replaced by rules based on logic and (instrumental) efficiency (Brubaker, 1984). As Weber observed, the process of rationalization takes different forms in the economic, political, and cultural spheres of life (Gellner, 1992), which makes it difficult to summarize neatly. But we focus here on politics and how the state imposes calculability on social processes. As we shall see, this is where Weber's ideas fit closely with how Al systems can both automate and optimize policymaking processes.\nIn relation to the state, Weber thought that rationalization was synonymous with a machine-like apparatus of rules, i.e., bureaucratization. The modern state for Weber thus rests on the legitimacy of legal authority or domination via a system of predictable and impersonal rules (Mommsen, 1984; Breuer, 1998). Legal-rational authority is embodied in bureaucracy and closely related to instrumental rationality since it contrasts with traditional or charismatic authority. The advantage of this form of rule is equal treatment and greater efficiency. The disadvantage, in Weber's view, is his famous \"iron\ncage\", i.e., the inescapability of structures that constrain freedom because they leave less room for individual autonomy (Baehr, 2001). Weber's idea of history was rather pessimistic on this point. He thought that the disenchantment of the modern world went hand in hand with ever-greater constraints on freedom. But it is not necessary to follow his pessimism: a well-working state bureaucracy can also allow more space to lead one's private life in an unfettered way.\nThe point to stress from Weber's theory of rationalization is that computation can be viewed as a ubiquitous phenomenon not limited to Al systems or other technical artefacts. As he puts it, the \"peculiar modern Western form of capitalism [is]...strongly influenced by its technological conditions. Its rationality is today essentially dependent on the calculability of the most important technical factors. But this means fundamentally that it is dependent on the peculiarities of modern science, especially the natural sciences based on mathematics and exact and rational experiment\" (Weber, 1967: 24). Weber's \"disenchantment\" is thus based on the idea that \u201cone can, in principle, master all things by calculation\" (1948: 139) \u2013 and computation by ML-based Al systems is perhaps the prime current instantiation of that mastery.\nWe are not the first to observe the link between the use of Al systems in the public sector and long-standing rationalization processes. In Digital Weberianism, Muellerleile and Robertson (2018) argue that, far from constituting a radical rupture, the use of Al systems and data in today's digitizing society show strong traces of the logic of Weber's bureaucracy. Similarly, Vogl et al. (2020) document British local governments' use of Al systems to describe the emergence of what they call an algorithmic bureaucracy. These works have provided a theoretical framework on which our analysis builds. Yet our contribution moves beyond previous work in two ways. First, we explore the implications of rationalization in a specific domain: Al-driven tax policy optimization. Second, we highlight the normative tensions associated with Al rationalization and spell out their implications for the ongoing discourse on fairness, accountability, and transparency in Al research and system design.\nBefore proceeding, it should be noted that Al systems facilitate the operations of the bureaucratic state in two conceptually distinct ways. First, they can be used to automate routine tasks, such as diagnosing patients, grading essays, or calculating tax returns. Historically, such tasks have been performed by \"street-level bureaucrats\" (Lipsky, 1980) who, despite following rules that theoretically applied equally to all citizens, inevitably operated with some degree of discretion. In an article titled Rule by Automation, Sparks and Jayaram (2022) argue that Al systems can promote freedom and equality by automating the tasks of street-level bureaucrats. By eliminating human discretionary power, rule by automation reduces our dependence on the intentional and arbitrary will of other actors and reduces social hierarchy. Hence, Sparks and Jayaram conclude, rule by automation should be supported for the same reasons as the rule of law.\nSecond, Al systems can be used to gather and process information to inform or optimize policies designed to reach specific normative ends. Of course, controlled policy experiments are difficult to conduct (Barnow, 2010). However, bureaucracies already claim to apply \u201cevidence-based policymaking\", i.e., the idea that policies should be informed by objective knowledge about the state of the world and the causal effects of specific interventions (Cartwright & Hardie, 2012). This is where Al systems come in. By leveraging the growing availability of fine-grained digital data sources, Al systems can perform large-scale policy experiments in real time and \u2013 based on the feedback from such experiments \u2013 optimize policy to achieve objectives defined by human policymakers."}, {"title": "3. Bureaucratization, tax policy, and equality", "content": "In this section, we review relevant literature about tax policy. In doing so, we show how the institutional histories of nation-states and the associated civic behaviour of national populations shape each other. We also highlight how taxation - and experiments with tax policy - can be used to achieve different normative ends.\nThe rationalization of taxation played a central role in the emergence of modern state bureaucracies. The pre-modern state had neither the capacity nor the information necessary to collect taxes directly without using intermediaries (Scott, 1998). Medieval tax systems involved collective obligations and non-monetary quotas - based on rules of thumb or traditions on towns and villages, which were administered by local nobility. The story of how modern taxation regimes emerged with warfare between modern European states is well-known (Tilly, 1990). Subsequent developments meant that rational taxation rests on explicit and calculable rules that are systematically enforced on whole populations. The point is that sources of revenue have a major impact on patterns of state formation (Moore, 2004), and that states require intermediaries including information gathering infrastructures and bureaucratic organizations \u2013 to collect taxes from their populations).\nFollowing a similar line of reasoning, Weber argued that rational taxation is a way of financing the state that encourages and is encouraged by the expansion of bureaucracies. Because collecting taxes effectively is complex and requires cooperation across state agencies, it required modern states to invest in new capabilities and spearheaded the broader development of bureaucratic institutions (Dandeker, 1990; Besley & Persson, 2009). Today, most developed countries have highly rationalized\ntax systems supported by large state bureaucracies. However, the relationship between a state's institutional history and the civic behaviour of its population is dynamic (Steinmo, 1993). Citizens who are required to pay taxes are more likely to feel ownership of government activities and to make demands for representation. Similarly, governments in need of tax revenue have stronger incentives to make reciprocal concessions to taxpayers and encourage tax compliance. Consequently, variations in cultural, economic, and political factors in the early modern period influenced not only the features of different countries' tax systems but also the attitudes and behaviours of their populations with respect to taxation.\nTo illustrate this point, it is useful to consider how taxation works in Sweden and the US, which are often perceived as cases that lie at the extremes of the \u201cvarieties of capitalism\" (Pontusson, 2005). In Willingness to Pay, Steinmo and D'Attoma (2021) demonstrate through empirical research - which includes data from the two countries \u2013 that people tend to obey laws and trust institutions more in societies where the rules are clear, coherent, and consistently applied. Paying taxes is disliked in the US partly because it requires a lot of effort to file tax returns and partly because everyone thinks everyone else is getting a better deal from the plethora of tax breaks and exemptions. It can be added that these exemptions are not a matter of tax officials' discretion; rather, the US uses taxation to pursue social policy in various ways, or lawmakers provide exemptions to appeal to their various supporters. In Sweden, the opposite is the case. The Swedish tax system is universal and transparent; everyone can find out how much others are paying and there is little pandering to different groups via deductions. It is also highly efficient; a simple click on one's mobile phone suffices for most people to file tax returns.\nThis is a good place to consider some reasons why Al systems are likely to be employed to automate taxation and optimize tax policy. To start with, the monetary nature of modern economies and the digitalization of the financial system mean that taxation lends itself to calculation and thus rationalization. As Sweden's case illustrates, data regarding people's income and wealth are readily available in digital form. Further, how tax systems are designed shapes people's attitudes towards paying taxes. As previously stated, people dislike paying taxes when it involves lots of work and they suspect others are getting a better deal. An automated tax system that reduces the scope for arbitrary exemptions would address both concerns. Finally, while few citizens understand complex policy issues like taxation, everyone can understand - and partake in the discussion about - the normative ends that taxation should be directed towards (Steinmo, 1993).\nThis brings us to the second key point: how tax policy can be used to reshape inequality. Researchers have long studied different tax policies and their effects on economic redistribution (Steinmo, 2010; Hobson, 2003; Prasad, 2018). Mostly, the levelling of income via taxation and public transfers is rather small (Tanzi & Schuhknecht, 2000). As Steinmo (2010:156) observes: \u201cIn the United States \u2013 as in most countries - the major recipient of public transfers is the middle class.\" However, Steinmo (2010: 153) also notes that \u201cthe US is unique in the extent to which it attempts to regulate, reward, subsidize and manipulate the behaviour of different actors through its tax system rather than through public spending.\" This means that taxation is one of the levers states can use to reduce economic inequality provided the tax policy is directed towards that end.\nFairness in relation to taxation is, of course, part of a larger debate about equality. And the public's ideas about equality are far from consolidated. Citizens perceive that taxes are their contribution to society or to each other. While perceptions matter, Prasad (2018: 214) highlights a critical tension:"}, {"title": "4. Al-driven tax policy to reduce economic inequality: a thought experiment", "content": "In this section, we propose a thought experiment in which Al systems are employed to optimize tax policy and automate taxation to achieve a given normative end: minimizing economic inequality. The aim thereby is to provide an example of how the use of Al systems in the public sector is both a continuation and intensification of Weberian rationalization as well as to highlight the normative tensions to which it gives rise.\nConsider the following hypothetical situation: there is a broad political consensus in a specific nation-state regarding the aim of reducing economic inequality, and the policy debate now centres on how that objective can be reached. Admitedly, such a situation is highly unlikely to materialize. Political consensus is rare (Rorty, 2021). Moreover, minimizing inequality is only one conceivable policy goal; others could be envisaged. However, under the assumption that there is a broad political consensus to reduce economic inequality, policymakers are left with a problem of mechanism design: how to find a policy under which the affected economic agents yield the desired outcome (Myerson, 1981).\nHitherto, policymakers have approached such a quest by drawing on economic theory regarding taxation (Ramsey, 1927; Mirrlees, 1971; Saez, 2001) and evidence from experimental research on the relationship between policy, civic behaviour, and inequality (Spicer & Becker, 1980; Agranov & Palfrey,2015). However, while useful, theoretical approaches to policy design are limited since they fail to capture the complexity of the real world (Hayek, 1973). Moreover, although policy experiments have become popular, they are hard to design, and results tend to suffer from limited external validity (Peters et al., 2016). Whether produced by lab or field experiments, it is often unclear how well empirical findings about the effectiveness of specific policies generalize between different social and temporal contexts. Historically, policymakers have thus faced significant uncertainty regarding the actual outcomes of different tax policies.\nThis is where Al rationalization comes in. Rather than having humans decide what the policy should be, leaving the actual outcome uncertain, policymakers only need to define the goal function, establish constraints, and employ Al systems to optimize the policy. In Section 2, we defined an Al system as a machine that can, for a given set of objectives, make decisions influencing its environment. It does so in two steps: first, by processing input data to build models of the environment and, subsequently, by using model inference to inform or perform actions in an automated manner. Al systems \"learn\" insofar as they update their models when fed with new input data. Provided that the goal function is clearly defined, such systems thus offer a fundamentally new approach to policymaking: one that is data-driven and based on learning from continuous feedback.5\nThe idea behind Al-driven policy optimization is straightforward but requires some understanding of reinforcement learning (RL). Simplified, RL is a technique to train Al systems based on neural networks operating in unknown environments to learn the optimal policy (i.e., set of decisions) to maximize a reward function (Sutton & Barto, 2018). As a framework for solving decision problems, RL has been widely employed in areas like natural language processing and medical diagnostics (Mousavi et al., 2018). However, RL is particularly apt for policy optimization for two reasons. First, RL means learning from mistakes. Because RL maintains a balance between exploration (trying out what works) and exploitation (trying again what has worked in the past), Al systems using RL learn from their own experience over time and do not require all the data needed to solve a problem to be available upfront. Second, RL approaches optimization problems holistically, without dividing them into subtasks. This makes Al systems based on RL well-suited for complex decision problems where the long-term reward is prioritized over short-term benefits.\nWith this, we can return to our thought experiment. Using RL, an Al system could (i) perform large-scale policy experiments on populations, (ii) observe the effects of different policies in real time, and (iii) continuously revise and refine the tax policy to reduce economic inequality. Al-driven tax policy optimization is thus a good example of Weberian rationalization. Recall that instrumental rationality refers to the most calculable, predictable, and efficient ways of achieving any given policy objective. In this case, that objective is to achieve a more equal distribution of resources by finding more effective ways to shape taxpayers' behaviour.\nImplementing Al-driven tax policy optimization would require policymakers to make three system design choices upfront. First, policymakers would need to define a goal function. To optimize for economic equality, the goal function could include both (i) income inequality metrics, like the Gini index or the Thiel index, and (ii) wealth inequality metrics, like the Gini coefficient or the Palma ratio. How to define the goal function is a non-trivial question that lies beyond this paper's scope. However, some general observations can be made. To start with, policymaking is always a multi-variable optimization. Hence, any goal function is likely to consist of a plurality of complementary metrics. Further, equality could be conceived in different ways. Whereas utilitarians and egalitarians focus on ensuring equal outcomes, liberals focus on providing equal capabilities. An Al system employed to maximize equality could equally favour a liberal notion since it is easier to create good records of how much money people have than what they do with it or how it affects their subjective well-being.6\nSecond, policymakers would need to decide on which variables the Al system should be able to manipulate. To maximize its goal function, the Al system would require the ability to manipulate the variables constituting a holistic tax policy, including tax base (what should be taxed?), tax rates (how should different assets or incomes be taxed?), tax exemptions (what deductions should be allowed?), and tax credits (what rebates and subsidies should be granted?). However, it should be noted that Al systems based on RL put no value on variables that are not part of the goal function or subject to explicit constraints.\u201d Consequently, there are good reasons to limit the number of levers the Al system has control over, e.g., to reduce the likelihood of unintended harms.\nThird, policymakers would need to define what data sources the Al system should be able to access. To optimize the tax policy to achieve maximal economic equality, the system would need access to economic data (regarding citizens' incomes and wealth), sociological data (regarding citizens'\nattitudes and behaviour) as well as information about how these data change over time. Further, to perform policy experiments, the Al system cannot rely on aggregate data but needs access to fine-grained data on how individuals and groups change their behaviours in response to specific policy treatments. Such experimentation is already a favoured tool in economics (Mascagani, 2017). The difference is that, fed with relevant input data in a seamless and continuous manner, the Al system would conduct large-scale, real-time experiments on the same population for which it optimizes the policy. Therefore, it would overcome the concerns regarding external validity traditionally associated with policy experiments.\nSome further clarifications are needed. The key feature of Al-driven policy optimization is learning. This means that while the Al system uses data about taxpayers' income, wealth, and behaviour as inputs to calculate the optimal tax policy to minimize economic inequality, this optimum would need to be continually adjusted to account for changing economic and social circumstances. Further, as already indicated, learning is contextual. In Section 3, we demonstrated how each country's institutional history, tax policies, and the civic behaviour of its population shape each other. This means that it is, theoretically, possible to shape the behaviours of populations in the direction of their stated preferences with technocratic solutions. However, it also means that the borders of nation-states would be the main constraint within which learning takes place.\nLet us now summarize our thought experiment. We explored the idea of using Al systems to optimize the tax policy of a nation-state to promote economic equality within its population. This would take the form of repeated large-scale experimentation to learn about the behaviour and preferences of taxpayers and the effectiveness and feasibility of different tax policies. This feedback would then be used to continuously adjust the tax policy and shape the behaviour and preferences of the population in line with that policy. This is a critical point, since research has shown that voters often go against their own interests in terms of tax policies (Bartels, 2005). Shaping the preferences of citizens in such a way would mean control through (Al-generated) knowledge, which is fully in line with instrumental rationalization. However, it would mean treating the population as experimental subjects.\nOf course, our thought experiment is subject to both technical and political limitations. For example, although it is clear in principle how an Al system could be used to optimize tax policy, many technical challenges, such as data access, could hamper its implementation. Al-driven tax policy optimization would require that all financial transactions are made digitally and linked to a centralized national data infrastructure. Currently, even countries with highly digitized economies and high institutional trust (like Sweden) fail to meet that bar, and most countries fall well short of it. Other challenges include how to define the goal function, how to design, train and validate the Al system, and how to build adequate safeguards into the system. Finally, linking and analysing large social scale data across multiple sources is bound to come into tension with privacy regulations, as the controversy surrounding SyRI, the Dutch welfare detection fraud system discussed in Section 1, illustrated.\nThat said, the idea of using Al systems to optimize tax policy is not just a hypothetical proposition (as in this paper) but a growing field of research at the intersection of economics and computer science. In an article titled Optimal taxation and insurance using machine learning, Kasy (2018) proposes a framework that resembles our thought experiment. By combining insights from optimal policy theory and statistical decision theory, Kasy shows how Al systems can perform (quasi-) experiments on taxpayers and draw on this experimental evidence to iteratively choose the policy that maximizes social welfare. The details of Kasy's proposal concern us less here than his conclusion, which is that Al-driven policy optimization \u201cleads to tractable, explicit expressions characterizing the optimal policy choice\" and that this \"points toward a large area of potential applications for machine learning methods in informing policy.\"\nKasy's conclusions are echoed by Zheng et al. (2022). In an article titled The Al Economist, Zheng et al. argue that \"the challenge with policy design comes from the need to solve highly nonstationary decision-making problems where all actors (both taxpayers and the government) are learning.\" The solution, they suggest, is to design an Al system that uses a two-level RL framework in which both taxpayers and social planners adapt their behaviour and policies to maximize their respective goal functions. Zheng et al. use simulation to show that an Al system based on \"two-level RL can find policies that yield higher social welfare than standard baselines\" and that Al-driven policy optimization \"can be useful without the need for human-coded, application-specific rules.\" Like our thought experiment, Zheng et al. employ Al systems based on RL to optimize taxation policy. The difference is that while they limit the use of Al systems to simulations that inform policy, our thought experiment envisions an automated implementation of the (continuously) shifting optimal policy.\nThe findings presented by Kasy (2018) and Zheng et al. (2022) indicates that the technical limitations associated with our thought experiment may be overcome by further research. In contrast, the political limitations may seem insurmountable. Our thought experiment builds on the (unrealistic) assumptions that there is a political consensus to minimize inequality and that technocrats have the freedom to implement the necessary policies. Yet this limitation has little bearing on our overarching argument: we do not propose that Al-driven policy optimization should be implemented, nor do we seek to provide a road map for how it could be done. Instead, the purpose of our thought experiment is to highlight the normative tensions to which Al rationalization gives rise. We can now turn to these."}, {"title": "5. Freedom, equality, and self-determination in the iron cage", "content": "Our analysis has shown that building a machine-like tax system via a bureaucratic state is conceivable. However, as this section explains, such a use of Al systems would surface and intensify the social and ethical tensions inherent in Weberian rationalization.\nTo begin with, using an Al system to optimize tax policy to achieve a predefined normative end \u2013 like maximizing economic equality comes at the expense of other, competing values. Take individual freedom as an example. Both freedom and equality are central ideals of the political ideologies in modern democracies. However, as Charvet (1981) demonstrates, there is a tension between freedom and equality, or between the value of (free) self-determining individuals and the (equal) value that each member of the ethical community accords to the other. Charvet argues in a Kantian vein that individuals must be valued for themselves, for their own ends, to constitute an object of value. But in modern liberal democracies, this individual value must be valued equally for all persons.\nConsequently, there is a stand-off between equality and freedom that cannot be reconciled since \"equal value\" and \"free individual self-determination\" depend on each other.\nThe core - Kantian \u2013 idea is that the value we place on each other must not be instrumental, whereby we treat each other as means. Yet, that is precisely what an Al-driven tax policy optimization does. To maximize equality, the Al system would not only adjust the tax policy to extract the maximum amount of resources from different taxpaying individuals or groups, it would also learn their behaviours through continuous experimentation \u2013 and use that knowledge to shape their future attitudes and preferences. The tension here is that Al rationalization increases centralized control, which is at odds with individual autonomy in relation to the individual's resources. It is important to note that, in our case, this instrumentalization of people applies only to one part of peoples' lives (taxation). Weberian fears of disenchantment may thus be overblown; it is still possible to value people for reasons other than the resources they provide. However, given that taxpaying is a major part of citizens' political life and likewise a major part of the state's efforts to legitimize legal authority \u2013 the rules governing taxation play a large role in people's sense of fairness.\nNote that Al rationalization \u2013 as envisioned in our thought experiment \u2013 is not incompatible with ideas of justice per se. The aims of Al-driven tax policy optimization are consequentialist and seek a redistribution of resources in line with values that have been democratically agreed upon. Rather, the problem is that this control of resources is centralized and hypostatized to the exclusion of other competing political values and overrides citizens' sense of their (non-instrumental) obligations to each other. These tensions sit at the heart of rationalization and have been articulated in different ways by social thinkers from Weber onwards. Yet Al rationalization gives rise to a further normative tension: in theory, the limit of rationalization is that science can only provide the means, it cannot dictate the ends (Cantwell-Smith, 2019). But insofar as Al systems are used to shape the behaviours and preferences of citizens, they de facto shape ends.\nIt is worth stressing that this problem is not unique to Al-driven tax policy. The more general problem is that new technologies and scientific discoveries go against the free will or autonomy of ethical decision-making. How technology or the disenchantment of the world by science undermines Kantian ethics in a Weberian vein has been noticed, among others, by Gellner in Legitimation of Belief. According to Gellner (1975:187), the solution is to grant ourselves \u201ca partial exemption from this cold world since we imposed the order on the world in the first place.\" This is also what Weber meant when he counterposed \u201cvalue\" rationality to \u201cinstrumental\u201d rationality. Value rationality is the idea that human choices should be exempt from being instrumentalized (Brubaker 1984), and it is also why there is such resistance to the idea of technological determinism, whereby it is thought that humans are made subject to impersonal forces. One way to overcome this dilemma is to make the implementation of new technologies subject to democratic acceptance, thus aligning the technological system to human values or needs. 10\nA \"meta\" reflection can be made here. Al could help facilitate with democratic deliberation in aggregating the inputs of democratic decision-making about what ends technologies should be employed for. In this case, the \"value\" that is being optimized for is democracy, whether this is conceptualized as \u201cone person, one vote\" (each person's value to be valued equally) or in some otherway (such as the aggregation of those values in representatives or interest groups). In any event, there is an uneasy \"truce\u201d here which leads to many ethical and social quandaries. What is new for our thought experiment is that the use of Al systems to rationalize taxation directly affects the main way in which citizens are bound to each other with respect to the major ethical and political principles embodied in the state. And, if an Al-driven tax policy was applied, it could fundamentally reshape those principles.\nThis is a good place to restate two key points. The first is that Al-driven policy optimization would merely be an intensification of ongoing rationalization processes, which are likely to continue even without this specific application of Al systems. The second is that, as with other technologies, the implementation of Al rationalization is likely to be complex and opaque and, hence, not readily understood by the public. Yet the very idea of Al rationalization, of applying such a \"cold\", impersonal order to human relations, even if it pertains to the population level rather than to individuals, would likely be regarded as a cause for ethical concerns. While such concerns might be misconceived, the reality, as Weber would have diagnosed it, of a disenchanting technology displacing self-determining beings, and in this case the ethical grounding of the political community of citizens, needs to be addressed in the design and application of Al systems in the public sector.\nSo far, we have focused on highlighting the normative tensions associated with Al rationalization. However, there are also ways in which Al rationalization can benefit the institutions and processes of liberal democracy. In our thought experiment, the technical details of the workings of the Al-driven tax system may be beyond the public's grasp. However, the ethical principles of egalitarian redistributions are not - and they can be formulated with greater clarity and pursued more rigorously by Al rationalization than legacy policymaking techniques. This would surface the tensions between competing normative visions and enable a discourse about what kind of society citizens want to live in and what trade-offs they are willing to make in the process. For example, one alternative to the egalitarian utilitarian interpretation of equality would be one that maximizes equal opportunities, perhaps in a Rawlsian way, whereby the veil of ignorance (Rawls, 1971) is made transparent instead, or in line with Sen's (1993) capabilities approach. In short, the advantage of Al-driven policy optimization is that it requires that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny and debate.\nOur discussion in this section can be summarised as follows. Al-driven policy optimization is indeed within the realm of possibility. In fact, the use of experiments to find the most effective policies and computers to execute those policies efficiently and consistently would merely be a continuation of existing rationalization and bureaucratization processes. However, as our thought experiment has shown, Al rationalization highlights several normative tensions that are often overlooked in the existing literature. Specifically, Al-driven policy optimization can come at the exclusion of other competing political values and may not only override citizens' sense of their (non-instrumental) obligations to each other but also undermine their self-understandings as self-determining beings.\nConsidered in isolation, each of these tensions has been discussed by different scholars in different contexts. The tension stemming from the incompatibility of different values was examined, among others, by Isaiah Berlin. In his essay The pursuit of the ideal, Berlin (1988: 10) writes that \"Values can clash. They can be incompatible between cultures, between groups within the same culture, and between you and me. Both liberty and equality are among the primary goals pursued by human beings. But total equality demands the restraint on liberty.\u201d Similarly, the tensions concerning theoptimization of social systems were noted already by Norbert Wiener. As he wrote in The Human Use of Human beings (Wiener, 1954, p212): \u201cThe machine, which can learn and can make decisions on the basis of its learning, will in no way be obliged to make such decisions as we should have made, or will be acceptable to us.\" Finally, the tensions that stem from Al systems shaping human preferences in ways that undermine notions of humans as self-determining beings has been documented by sociologists (Zuboff, 2015) and economists (Thaler & Sunstein, 2008) alike.\nWhat is novel in our exposition is that we have shown that these tensions cannot be simply overcome by building Al systems that are legal, ethical, and safe. There are of course social and ethical challenges that can be addressed through transparency obligations and rigorous engineering practices (Thomas et al., 2023). This is especially true for harms resulting from Al systems failing to operate as advertised. However, it is worth noting that transparency and instrumental rationality build on the very same assumptions that fuel Weberian rationalization processes. Consequently, proposals to design and deploy Al systems in ways that are \"fair, transparent, and accountable\u201d risk exacerbating rather than alleviating the tensions associated with Al-driven policy optimization discussed in this section."}, {"title": "6. Conclusion", "content": "In this paper, we have argued that the social and ethical challenges associated with the use of Al systems in the public sector are best understood against a longer-term trajectory whereby calculability is increasingly imposed on social processes. This claim is based on the observation that computation is a ubiquitous phenomenon, not one unique to Al systems. In fact, Weber defined \u201crationalization\" as the processes whereby traditions, in so far as they serve to guide actions, and random chance are replaced with instrumental rationality, i.e., the most calculable, predictable, and efficient ways of achieving any given objective. And that is precisely what Al-driven policy optimization does.\nForegrounding the continuity between Al-driven policy optimization and larger rationalization processes has two direct implications for the contemporary policy discourse: first, that the social and ethical challenges associated with Al systems intensify ongoing rationalization and bureaucratization processes are distinct from those resulting from Al systems failing to work as advertised; and, second, these two distinct sets of social and ethical challenges call for different remedies, which sometimes stand in tension with each other. Let us consider these in turn.\nTo start with, our thought experiment with Al-driven tax policy optimization highlights normative tensions that have hitherto received comparatively little attention from policymakers and researchers alike. The literature on fairness, accountability, and transparency in ML focuses on identifying and mitigating harms that result from Al systems failing to perform as intended. For example, Al systems may discriminate against specific individuals and groups (Mehrabi et al, 2021), cause privacy breaches by leaking sensitive data (Narayanan & Shmatikov, 2016), and cause material harm due to malfunctioning or misaligned specifications (Sherer, 2015). These are indeed pressing challenges that demand rigorous treatment from technology providers and policymakers alike. However, as our thought experiment - using Al systems to optimize tax policy to promote social and economic equality - shows, there are other normative tensions that result not from Al systems failing to work as intended but that they intensify ongoing rationalization and bureaucratization processes. These tensions include that Al-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens' sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. What unites these tensions is that theydo not, even in principle, hinge on any malfunctioning or misspecification. Instead, they are likely to be exacerbated as Al systems become increasingly scalable and capable.\nFurther, emphasizing the link between Al-driven policy optimization and Weberian rationalization suggests that there are limits to what can be achieved through transparency obligations and robust engineering practices. Some of the social and ethical risks Al systems pose can indeed be addressed through proactivity in design. For example, a study by Buolamwini and Gebru (2018) found that gender classification systems were less accurate for darker-skinned females than lighter-skinned males. After being confronted with these findings, technology providers speedily improved the accuracy of their Al systems. This suggests that the problem was not intrinsic but rather resulted from inadequate software development processes and risk management systems, or lack of 'guardrails'. Similarly, other harms that result from Al systems failing to perform as intended can be addressed by ensuring that such systems are used in ways that are legal, ethical, and safe, i.e., by increasing the level of control.\nIn contrast, the normative tensions stemming from rationalization are not only alleviated but can also be exacerbated when the level of control is increased. This is because the drive towards ensuring that Al systems are designed and used in ways that are fair, transparent, and accountable is based on the same assumptions that fuel rationalization and bureaucratization processes in the first place. These assumptions include the modern ideas that (i) science can sweep away oppressive legal systems and economic policies and replace them with a rule of reason that would rescue humans from moral injustices and (ii) societal processes are calculable and quantifiable (Watson & M\u00f6kander, 2023). In fact, building Al systems that are fair, transparent, and accountable is fully in line with the rationalistic ideal of finding the most calculable, predictable, and efficient way of achieving any given objective. However, doing so also propels the disenchantment of the natural world and imposes a cold, impersonal logic to social relationships. This is the essence of Weber's \u201ciron cage.\"\nBefore concluding, let us return to the argument put forward by Sparks and Jayaram (2022) in Rule by Automation. They right in observing that the use of Al systems in the public sector constrains the space for human discretionary power in the execution of established rules, and thus reduces decision subjects' dependence on arbitrariness and chance. They are also right in concluding that rule by automation should therefore be supported for the same reasons as the rule of law. However, the impact of our formal laws and policies on society and its members has hitherto been cushioned by their inconsistent application and enforcement that results from chance and the discretion exercised by human decision-makers at various levels of the bureaucratic hierarchy.\nWhat our thought experiment with Al-driven policy optimization suggests is that, were our formal laws, policies, and procedures all pursued rationally, i.e., in the most calculable, predictable, and efficient way possible, we could find that we are not so comfortable with them in the first place. This point mainly serves to highlight, however, that making more explicit the aims with which technology can serve us would be a valuable service that Al-driven optimization can provide, if combined with the appropriate guardrails. In the case of tax policies, these guardrails would need to ensure that the aims of policy, democratically arrived at, are implemented in a consistent and transparent way. And the implementation would depend, as discussed earlier, on state capacity, both in the sense of a capable apparatus for gathering information and a bureaucratic organization that works in a transparent and fair - impersonal - way.\nTo conclude, some of the hardest social and ethical challenges surfaced by Al systems are not unique to computer-centric information processing but mirror tensions at the heart of larger rationalization processes. Tackling these tensions are not only about ensuring that Al systems are designed and deployed in ways that are \"legal, ethical, and safe\" but also and perhaps primarily about confronting hard questions about what (types of) criteria, motivations, and evidence are to be considered legitimate (or at least socially acceptable) for different (private and public) decision-making processes."}]}