{"title": "NEURAL CIRCUIT ARCHITECTURAL PRIORS\nFOR QUADRUPED LOCOMOTION", "authors": ["Nikhil X. Bhattasali", "Venkatesh Pattabiraman", "Lerrel Pinto", "Grace W. Lindsay"], "abstract": "Learning-based approaches to quadruped locomotion commonly adopt generic\npolicy architectures like fully connected MLPs. As such architectures contain\nfew inductive biases, it is common in practice to incorporate priors in the form\nof rewards, training curricula, imitation data, or trajectory generators. In nature,\nanimals are born with priors in the form of their nervous system's architecture,\nwhich has been shaped by evolution to confer innate ability and efficient learning.\nFor instance, a horse can walk within hours of birth and can quickly improve with\npractice. Such architectural priors can also be useful in ANN architectures for AI.\nIn this work, we explore the advantages of a biologically inspired ANN architecture\nfor quadruped locomotion based on neural circuits in the limbs and spinal cord\nof mammals. Our architecture achieves good initial performance and comparable\nfinal performance to MLPs, while using less data and orders of magnitude fewer\nparameters. Our architecture also exhibits better generalization to task variations,\neven admitting deployment on a physical robot without standard sim-to-real meth-\nods. This work shows that neural circuits can provide valuable architectural priors\nfor locomotion and encourages future work in other sensorimotor skills.", "sections": [{"title": "INTRODUCTION", "content": "Learning-based approaches to quadruped locomotion commonly adopt generic policy architectures\nlike fully connected multilayered perceptrons (MLPs) (Rudin et al., 2022; Smith et al., 2022; Agarwal\net al., 2022). As such architectures contain few inductive biases, they must rely on training to develop\ndesired behaviors. Simple reward functions often do not lead to naturalistic or robust behavior (Heess\net al., 2017). Therefore, it is common in practice to incorporate priors in the form of rewards (Rudin\net al., 2022), training curricula (Agarwal et al., 2022; Rudin et al., 2022), imitation data (Bin Peng\net al., 2020; Merel et al., 2019b), or trajectory generators (Schaal, 2006; Iscen et al., 2019).\nIn nature, animals are born with priors in the form of their nervous system's architecture, which has\nbeen shaped by evolution to confer innate ability and efficient learning (Zador, 2019; Cisek, 2019).\nFor instance, a horse can walk within hours of birth and can quickly improve with practice, and\nhumans have strong inductive biases for perceiving and interacting with the world (Lake et al., 2017).\nThese inductive biases are a reflection of highly structured neural circuit connectivity (Luo, 2021),\nwhich combines innate and learning mechanisms in stark contrast to generic ANN architectures.\nCan such architectural priors also be useful in ANN architectures for AI? Bhattasali et al. (2022)\ninvestigated this by introducing Neural Circuit Architectural Priors (NCAP). Using a case study of the\nnematode C. elegans, the proposed Swimmer NCAP translated neural circuits for swimming into an\nANN architecture controlling a simulated agent from an AI benchmark (Tassa et al., 2020). Swimmer\nNCAP achieved good performance, data efficiency, and parameter efficiency compared to MLPs, and\nits modularity facilitated interpretation and transfer to new body designs. As such, Swimmer NCAP\ndemonstrated several possible advantages of biologically inspired architectural priors for AI.\nHowever, it remained unknown whether the approach could scale to more complex animals and\ntasks. C. elegans has a nervous system of only 302 neurons and highly stereotyped connectivity,\nand its connectome has long been mapped (White et al., 1986). In contrast, mammalian nervous\nsystems have millions or billions of neurons (Herculano-Houzel et al., 2006; 2007) with more variable\nconnectivity and no mapped connectome, so it was not obvious how such circuits could inspire AI."}, {"title": "RELATED WORK", "content": "Our work builds on an extensive literature in neuroscience, robotics, and artificial neural networks.\nFor conciseness, we highlight the most relevant ones to our work:\nCentral Pattern Generators Central pattern generators (CPGs) are neural circuits that produce\nrhythmic activity in the absence of rhythmic inputs, and they underlie many movements including\nchewing, breathing, and locomotion. Roboticists have developed CPG-like controllers for a variety of\ntasks, and these controllers come in diverse forms (Ijspeert, 2008; Yu et al., 2014). For example, the\ndesired movement can be directly engineered using trajectory generators (for instance, swing/stance\ntrajectories) that are adjusted by a higher-level controller (Iscen et al., 2019). Alternatively, a policy\ncan adopt an action space of controllable abstract oscillators to flexibly modulate (Bellegarda &\nIjspeert, 2022; Shafiee et al., 2023). In this work, we take a biologically constrained approach that\ninstantiates a CPG using a network of neurons, some of which have intrinsic bursting dynamics.\nNeuromechanical Models Neuromechanical models are used in computational neuroscience to\ndevelop insights about the interactions between the musckuloskeletal system and the nervous system\n(Ausborn et al., 2021; Markin et al., 2016). Recently, several neuromechanical models have been\ndeveloped for the rodent (Merel et al., 2019a; Tata Ramalingasetty et al., 2021) and the fly (Lobato-\nRios et al., 2022; Wang-Chen et al., 2023), which will enable new understanding about how animals\nperform movement. In this work, we build upon insights gleaned from neuromechanical models, but\nour goal is not to control a realistic musckuloskeletal simulation. Rather, we aim to translate insights\nfrom biology to AI and robotics, which leads us to model at a higher level of abstraction."}, {"title": "METHODS", "content": "We translate neuroscientific models of quadruped locomotion circuits into an ANN architecture for\ncontrolling a robot. In Section 3.1, we review key background about the neuroscience of locomotion.\nIn Section 3.2, we describe the computational units that are building blocks in our Quadruped NCAP\narchitecture. In Section 3.3, we describe the connectivity of NCAP and its interface with the robot."}, {"title": "BIOLOGICAL LOCOMOTION", "content": "Quadrupeds locomote by rhythmically flexing and extending their limbs in a coordinated gait to\npropel the body forward. They control their velocity by producing various gaits (such as walk, trot,\ngallop, and bound), and they adapt to different conditions using sensory information. Quadruped\nmammals (including mice, cats, dogs, and horses) exhibit considerable differences in appearance,\nbut comparative anatomical studies have revealed a remarkable homology in body structure and\nneural circuitry between them, which makes sense given their shared evolutionary heritage (Grillner\n& El Manira, 2020). Neuroscience research across many animal systems has shed light on how\nlocomotion is achieved through the complex interaction between the musculoskeletal system and\nneural circuits in the limbs, spinal cord, and higher brain regions (Grillner & El Manira, 2020).\nSurprisingly, neural circuits in the limbs and spinal cord are sufficient to produce locomotion, while\nhigher brain regions are important to initiate and regulate locomotion (Rybak et al., 2015). Classic\nstudies strikingly demonstrated evidence of such organization using decerebrate animals, in which\nmost of the brain was severed from the spinal cord, yet the animal could still walk and even transition\nbetween gaits when tugged along a treadmill (Whelan, 1996). Recent studies have leveraged advances\nin experimental tools like molecular genetics to precisely map and manipulate locomotor circuits\nwith cell-type specificity (Kiehn, 2016; Ausborn et al., 2021).\nWe summarize below a well-supported neuroscientific model of locomotor circuits (Figure 1), which\nis based on data from cats and transgenic mice, and which adopts the abstraction of genetically\ndefined neural populations with rate-coded activity. For details, please refer to the referenced works."}, {"title": "ARCHITECTURE UNITS", "content": "Our NCAP architecture adopts a continuous-time framework for modeling neurons. We find that\n2 computational units can capture the cell types in this circuit: a Basic unit and an Oscillator unit\n(Figure 2). Many neuromechanical modeling works, including Danner et al. (2017), use biophysical\nneuron models that incorporate the conductances, reversal potentials, and activation/inactivation\ndynamics of ion channel currents (for instance, a persistent sodium current for bursting). Such\ncomplexity is not needed for Al purposes, so we follow Bhattasali et al. (2022) by simplifying\nthese neurons to create computational units with fewer and more interpretable hyperparameters. We\ndescribe below the main properties of these units. For details and equations, please see Appendix A.1.\nBasic Unit This neuron model is standard in computational neuroscience. Rate-coded inputs raise\nor lower the internal voltage, which is leaky. If the internal voltage rises beyond a threshold, the\nneuron generates rate-coded output activity according to an activation function.\nOscillator Unit This neuron model abstracts an intrinsically bursting neuron (Danner et al., 2017).\nIt generates oscillating output activity in the absence of inputs. In response to inputs, it scales its\nactive and quiet phases, and it transitions to a silent mode under strong inhibition and to a tonic\nmode under strong excitation. These properties enable the unit to shift its oscillation phase to pulse\nwaveforms, and entrain its oscillation phase to periodic waveforms. We provide a detailed derivation\nand evaluation of this model in a concurrent manuscript (Bhattasali et al., 2024, in submission)."}, {"title": "ARCHITECTURE STRUCTURE", "content": "Robot Body We target a standard robotic body in order to investigate the effectiveness of archi-\ntectural priors in AI settings (Figure 3A). Unlike animals, the robot does not use highly redundant\nmuscles that produce linear force; instead, it uses a single rotational motor per joint that produces"}, {"title": "EXPERIMENTS", "content": "Tasks We train our architecture on simulated tasks built atop the MuJoCo physics engine (Todorov\net al., 2012) that control the Unitree A1 robot (Appendix B.1). The tasks are structured as 15-second\nepisodes during which the robot must locomote forwards at a fixed target speed of Walk (0.5 m/s)\nor Run (1.0 m/s), and across terrains of Flat or Bumpy (Appendix B.2). The tasks provide at each\ntimestep a reward proportional to the running speed, with maximum reward of 1 at the target speed\nin the forward direction (Appendix B.3). This task structure and reward design is based directly on\nSmith et al. (2022) in order to facilitate comparison to existing work.\nBaselines We compare against multilayered perceptrons (MLPs) of 2 hidden layers. By default,\nwe compare to MLP(256,256), which is a reasonably sized architecture commonly used in the AI\nand robotics literature. Importantly, we choose to baseline against MLPs as they exemplify an\narchitecture without priors, which contrasts with our NCAP architecture with priors, facilitating a\nclean comparison. Our goal in this work is not to compare how different classes of prior stack up\ngenerally, but rather to explore the value of neural circuit-inspired architectural priors in particular.\nAs architectural priors are somewhat orthogonal to other forms of priors (including reward, training\ncurricula, and imitation priors), future work could combinatorially combine our prior with others.\nAlgorithm We train both NCAP and MLP architectures using evolution strategies to maximize\nepisodic return (Appendix C.1). Such gradient-free optimization is easiest to use with our NCAP\narchitecture, and it has successfully and popularly been used to train MLPs in continuous control\n(Salimans et al., 2017). In preliminary experiments, we compare evolution strategies to standard\non-policy and off-policy reinforcement learning algorithms (Appendix C.2), and we confirm similar\nperformance across algorithms when training MLPs on our tasks (Appendix D.1)."}, {"title": "PERFORMANCE AND DATA EFFICIENCY", "content": "NCAP successfully learns to locomote across various speeds and terrains (Figure 4A). For representa-\ntive examples of NCAP's behavior and neural activity, please see Videos 1.\nHow does NCAP compare to MLP on performance and data efficiency? NCAP achieves comparable\nasymptotic performance to MLP across tasks (Figure 4A). Moreover, due to its priors, an untrained\nNCAP achieves significantly better initial performance than an untrained MLP. The performance of\nNCAP improves with training as the AF and PF weights are refined. In addition, NCAP's training\ntrajectories are less variable than the MLP's.\nInterestingly, NCAP appears to train more data efficiently than MLP for the harder Bumpy tasks.\nFor instance, on the Bumpy/Run task, NCAP reaches asymptotic performance about 500 epochs (or\n8 million timesteps) before MLP. However, NCAP reaches slightly lower asymptotic performance\nthan MLP for the easier Flat tasks. We attribute this to a regularization effect in NCAP, as it is\nconstrained in the solutions it can learn. In contrast, MLP can learn to exploit the simulator for\nadditional performance gains, which is easier to do on Flat than Bumpy tasks.\nThis is supported by the qualitative performance of NCAP and MLP. Using footfall plots, we examine\nlearned gaits on the Flat/Walk task for different training seeds (Figure 4B, Videos 2). MLP develops\na good walking gait on seed 3, a mediocre limping gait on seed 2, and a failed on-the-floor shuffle on\nseed 1; this behavior is starkly evident in Videos 2. Notably, this high variability is occluded in the\nperformance curve (Figure 4A). In contrast, NCAP exhibits more naturalistic and consistent gaits due\nto its RG prior. Such gaits would require more priors to elicit from MLP (for example, reward or\nimitation priors)."}, {"title": "PARAMETER EFFICIENCY", "content": "Are the performance and data efficiency advantages of NCAP merely due to having fewer parameters?\nWe test MLP with fewer parameters by varying the hidden layer sizes from 4 to 256. Surprisingly,\nperformance and data efficiency degrade significantly (Figure 5A), showing that it is not merely\nhaving fewer parameters that is beneficial. Rather, the specific structure of NCAP matters."}, {"title": "GENERALIZATION TO TERRAIN AND BODY VARIATIONS", "content": "How well does NCAP generalize to unseen environments compared to MLP? We evaluate the archi-\ntectures across a variety of terrain and body variations (Figure 6). In each setting, the architectures\nare trained in one condition, then tested in altered conditions. Across these variations, NCAP's\ngeneralization matches, and often exceeds, that of MLP. Surprisingly, MLP performance degrades\ndramatically on Bumpy terrain, despite the differences in bumpiness seeming minor by human\nstandards (Figure B.1). In contrast, NCAP performs more robustly."}, {"title": "GENERALIZATION TO THE PHYSICAL ROBOT", "content": "How well does NCAP generalize to the real world compared to MLP? We deploy the architectures to\na physical Unitree A1 quadruped robot after training on the Bumpy/Walk task (Appendix B.4). We\nexpect the domain gap to be large since we do not perform controller tuning or system identification\nwith the physical robot, the simulated training does not apply aggressive domain randomization (a\nform of task prior), and the architectures do not have a mechanism for online adaptation.\nMLP falls immediately due to its erratic and unstable actions, often launching the robot aggressively\ninto the wall (Figure 7). Despite our best efforts, we cannot elicit a successful walking trial. In contrast,\nNCAP is remarkably robust to the large domain gap, walking successfully on most trials, though with\nless smoothness than in simulation (Figure 7). We attribute NCAP's success to a combination of the\nRG module maintaining a stable rhythm in the face of sensor noise and the AF module triggering\ncorrective responses in the face of perturbations. Lastly, we deploy an untrained NCAP and observe\nthat it is stable and produces slight walking movements with small foot displacements (Videos 3)."}, {"title": "DISCUSSION", "content": "In this work, we introduce Quadruped NCAP, a biologically inspired ANN architecture for quadruped\nlocomotion based on neural circuits in the limbs and spinal cord of mammals. Our architecture\nachieves good initial performance and comparable final performance to MLPs, while using less data\nand orders of magnitude fewer parameters. Our architecture also exhibits better generalization to task\nvariations, even admitting deployment on a physical robot without standard sim-to-real methods.\nLimitations Our study faces several limitations. First, we rely on a hand-tuned RG module and BC\ncommand, which might not be the optimal parameters that a learning-based approach could discover.\nSecond, we neglect musculoskeletal factors in the quadruped action space that could make learning\neasier or more robust.\nFuture Work We focus on fixed speed locomotion in this work, but an obvious next step is to\nenable the RG to transition between gaits in a speed-dependent manner, which may largely involve a\nhigher-level controller that alters brainstem commands for different speeds. Another extension is to\nadd postural adjustment, turning, and righting mechanisms to the architecture based on understanding\nof the underlying neural circuits. Finally, as architectural priors are somewhat orthogonal to other\nforms of priors, it may be beneficial to train NCAP with additional reward, task, or imitation priors.\nOverall, we believe that this work shows that neural circuits can provide valuable architectural\npriors for locomotion in more complex animals and encourages future work in yet more complex\nsensorimotor skills."}, {"title": "ARCHITECTURE DETAILS", "content": "The adaptation thresholds $a_{\\text{quiet}}, a_{\\text{active}}$ are calculated that determine the min/max values of adaptation\n$a$ at which the internal voltage $v$ jumps between active (+1) and quiet (-1) states:\n$a_{\\text{active}}^0 = \\frac{1 - \\exp(T_{\\text{quiet}})}{1 - \\exp(T_{\\text{active}} + T_{\\text{quiet}})}$\n$a_{\\text{quiet}}^0 = a_{\\text{active}}^0 \\exp(T_{\\text{active}})$\n$a_{\\text{active}}^1 = \\frac{1 - \\exp(T_{\\text{quiet}} \\cdot K_{\\text{quiet}})}{1 - \\exp(T_{\\text{active}} \\cdot K_{\\text{active}} + T_{\\text{quiet}} \\cdot K_{\\text{quiet}})}$\n$a_{\\text{quiet}}^1 = a_{\\text{active}}^1 \\exp(T_{\\text{active}} \\cdot K_{\\text{active}})$\nDepending on the strength of the input signal at a given time, the quiet-to-active and active-to-quiet\nadaptation thresholds interpolate between the calculated min/max values. Adaptation $a$ exponentially\ndecays towards 0 when the neuron is active (the neuron depletes the adaptation variable) and towards\n1 when quiet (the neuron replenishes the adaptation variable). Voltage $v$ jumps instantaneously to a\nnew state when an adaptation threshold is reached.\n{\nf0-a if v = +1 (active)\n1-a if v = -1 (quiet)\n${-1 if a(t) < a_{\\text{quiet}}(t) \\text{ and } x(t) < V_{\\text{tonic}}\\ (\\text{active} \\rightarrow \\text{quiet})\n+1 if a(t) \\geq a_{\\text{active}}(t) \\text{ and } x(t) \\geq 0\\ (\\text{quiet} \\rightarrow \\text{active})\nv(t) \\text{ otherwise}\nTa da\n4 dt =\n}\\text{,$\n4 dt=a clip(B + \u03a3\u2081 Wiyi, -1,1)z clip(x, 0, 1)interpolate(z, a_{\\text{active}}^1, a_{\\text{active}}^0)interpolate(z, a_{\\text{quiet}}^1, a_{\\text{quiet}}^0The neuron's activation function $f$ determines the voltage-adaptation-firing relationship:\ny = f(v,a,x), f ={\ninterpolate(a, 0.5, 1.0) if v = +1 (active)\nif v -1 (quiet)\n0"}, {"title": "SIMULATED ROBOT", "content": "We train our architecture on simulated tasks built using DeepMind Composer (Tassa et al., 2020) atop\nthe MuJoCo physics engine (Todorov et al., 2012) using a Unitree A1 robot model imported from\nMuJoCo Menagerie (Zakka et al., 2022).\nThe observation and action interfaces with the agent are normalized to [-1,1]. The action space is\ndesigned with a default standing pose corresponding to actions of 0 and joint limits corresponding to\nactions of \u00b11.\nA proportional-derivative (PD) controller is employed to convert the target joint positions generated\nby the agent $q_{\\text{target}} = a_t$ into joint torque commands for the actuators:\n$\\tau = k_p(q_{\\text{target}} - q) - k_d \\cdot \\dot{q}$\nwith joint positions $q$, joint velocities $\\dot{q}$, proportional gain $k_p$, and derivative gain $k_d$.\nThe simulation runs with a control timestep of 0.03 seconds and a physics timestep of 0.001 seconds."}, {"title": "TASK STRUCTURE", "content": "The tasks are formulated as 15-second episodes. The agent incurs a penalty and the episode resets\nif the robot falls over or if any part of its base touches the ground. At the start of each episode, the\nfriction coefficient of the foot is randomized. The agent is trained to move at a fixed velocity of Walk\n(0.5 m/s) or Run (1.0 m/s) over either Flat or Bumpy terrain (Figure B.1)."}, {"title": "TASK REWARDS", "content": "We adopt the reward function from Smith et al. (2022), which uses the forward linear velocity in the\nrobot frame $v_x$, the target forward velocity $\\upsilon_{\\text{target}}$, and the angular yaw velocity $\\omega_z$.\nThe overall reward combines a forward velocity reward and a rotational penalty. The tolerance\nfunction $r_v$ encourages the agent to maintain a forward velocity near the target with some allowable\ndeviation, while the rotational penalty reduces unnecessary rotational movements, ensuring stable\nand forward-directed motion:\n{1"}]}