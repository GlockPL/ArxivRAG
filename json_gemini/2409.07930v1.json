{"title": "A convolutional neural network approach to deblending seismic data", "authors": ["Jing Sun", "Sigmund Slang", "Thomas Elboth", "Thomas Larsen Greiner", "Steven McDonald", "Leiv-J Gelius"], "abstract": "For economic and efficiency reasons, blended acquisition of seismic data is becoming more and more commonplace. Seismic deblending methods are always computationally demanding and normally consist of multiple processing steps. Besides, the parameter setting is not always trivial. Machine learning-based processing has the potential to significantly reduce processing time and to change the way seismic deblending is carried out. We present a data-driven deep learning-based method for fast and efficient seismic deblending. The blended data are sorted from the common source to the common channel domain to transform the character of the blending noise from coherent events to incoherent distributions. A convolutional neural network (CNN) is designed according to the special character of seismic data, and performs deblending with comparable results to those obtained with conventional industry deblending algorithms. To ensure authenticity, the blending was done numerically and only field seismic data were employed, including more than 20000 training examples. After training and validation of the network, seismic deblending can be performed in near real time. Experiments also show that the initial signal to noise ratio (SNR) is the major factor controlling the quality of the final deblended result. The network is also demonstrated to be robust and adaptive by using the trained model to firstly deblend a new data set from a different geological area with a slightly different delay time setting, and secondly deblend shots with blending noise in the top part of the data.", "sections": [{"title": "INTRODUCTION", "content": "In conventional seismic acquisition, the time interval between successive shot records is large enough to avoid the overlap of desired reflection events. This implies that the source domain often is poorly sampled since the total number of shots needs to be kept at an acceptable minimum to reduce the operational costs (Berkhout, 2008). To overcome such limitations in efficiency, the concept of blended acquisition has been introduced, where two or more shots are fired overlapping or almost simultaneously with time differences defined by a small random jitter (Barbier, 1982; Timoshin and Chizhik, 1982; Vaage, 2005; Beasley, 2008; Huo et al., 2009; Berkhout et al., 2010). To decompose the blended data into separate source contributions is a challenging task in seismic processing. Unlike many denoising problems, the coherent character of the blending noise closely resembles that of the signals to be recovered. Thus, to only perform the deblending operation directly on the source gathers is probably not an optimal approach.\nDuring recent years, several attempts have been made to develop effective deblending techniques that aim to combine low computational cost and high data quality. Currently existing deblending methods can be divided into: inversion-based methods, denoising-based methods, combinations of above two and seismic apparition. A large number of algorithms have been proposed and here we only mention a few as examples."}, {"title": null, "content": "The fundamental concept of inversion-based methods is to add appropriate constraint to the specific blending equation, and solve the inversion problem by inverting the matrix of the forward modeling operator or by using an iterative framework that iteratively estimates the useful signal and subtracts the blending noise. Berkhout (2008) proposed to apply a data-driven inversion of the blended records, and Neelmani et al. (2008, 2010) used a forward modeling approach to deblend the simultaneously acquired seismic data. An alternative inversion strategy was introduced by Herrmann et al. (2009), where the actual seismic deblending step was carried out in the Curvelet domain. These approaches have been followed by a series of refinements of the iterative formulation (Mahdad et al., 2011, 2012; Doulgeris and Bube, 2012; Chen et al., 2014). On the other hand, Wapenaar et al. (2012 a, b) suggested that the deblending of densely sampled sources can be implemented as a direct (i.e. non-iterative) inversion of the blending operator by taking the spatial band-limitation into account.\nDenoising-based methods make use of the nature of the random jitter and typically resort seismic data from the shot domain to another domain where contributions from nearly simultaneously fired sources are incoherent. Examples involve sorting into the common channel, common offset, and common midpoint domain, often in combinations with data transforms to, for example, Wavelet (Chakraborty et al., 1995), Curvelet (Candes et al., 2006), Shearlet (Kutyniok and Lim, 2011), Seislet (Fomel et al., 2010) or Radon (Helgason, 1999) domain. In this way, the deblending process can be reformulated as the problem of removing incoherent noise (Moore et al., 2008; Akerberg et al., 2008; Maraschini, 2012; Chen, 2015).\nAll these methods discussed have in common that the full set of calculations needs to be repeated for each new blended data set."}, {"title": null, "content": "Robertsson et al. (2016) proposed to reconstruct recorded interfering wavefields from two or more sources excited simultaneously by the principle of signal apparition, and extended it to separate seismic data acquired with multiple sources (Andersson et al., 2016). In blending acquisition, the amplitudes of N shot and N+1 shot will be similar if they are fired nearly simultaneously, and the blending noise will appear in almost the entire record length of each shot. Seismic apparition tries to solve this problem by going to the F-K domain. However, when deploying a large number of sources, the sampling requirement of seismic apparition is such that all the sources need to be fired very often. This makes it very difficult to maintain a reasonable source volume and to have time to fill the individual guns with enough air. Furthermore, the so-called flawless diamond of seismic apparition becomes increasingly small as we add sources. It only goes up to around 10Hz for a hexa-source setup. These combined problems probably mean that seismic apparition style shooting is suboptimal when 5 to 6 simultaneous sources are deployed.\nIn this paper we propose an alternative processing path based on Machine Learning (ML). Even though the ML methods are computer intensive during the training process, once the network is fully trained the application of such methods can be carried out in nearly real time. According to LeCun et al. (2015), a disadvantage of conventional machine-learning techniques is the limitation in their ability to process natural data in their raw form. After proper normalization of such data, conventional ML techniques can perform better. However, in applications such as computer vision related tasks, a class of techniques called deep learning is more commonly used.\nDeep learning, as a ML technique, allows computational models that are composed of"}, {"title": null, "content": "multiple processing layers to learn to represent data using multiple levels of abstraction (LeCun et al., 2015). Traditionally, this learning process has been achieved by the use of fully connected deep-layer artificial neural networks (ANNs). However, for many data applications the important features are of a more local character (i.e. a given pixel in an image is most likely correlated with neighboring pixels), and the concept of Convolutional Neural Networks (CNNs) has been introduced (Goodfellow et al., 2016). The core of a CNN is a hierarchy of local filters being trained to extract the essential features of the training data relevant for the application in question. Such networks have recently attracted much attention in various fields of science and engineering, including geophysics. Many successful applications have been reported due to easy access to user-friendly open-source software, such as Google Tensorflow (Abadi et al, 2016), PyTorch (Paszke et al., 2017), in combination with increasingly powerful hardware (CPU and GPU) available at fairly moderate cost.\nWithin the field of seismic image classification and interpretation, CNNs have already proved to be useful. Qian et al. (2018) proposed the use of a deep convolutional autoencoder (DCAE) network for seismic facies recognition based on prestack seismic data. Waldeland et al. (2018) demonstrated how CNNs could be used to classify different seismic textures with special emphasize on salt bodies. Xiong et al. (2018) trained a CNN to automatically detect and map fault zones using 3D seismic images, whereas Wu et al. (2019) proposed to use CNNs to pick the first arrivals of microseismic events. Baardman et al. (2018, 2019) proposed the use of a CNN to classify data patches in a \u201cblended\u201d and \u201cnon-blended\" class. A second, regression based, CNN was then employed to deblend the \u201cblended\" patches, but only synthetic data were considered."}, {"title": null, "content": "Although not yet fully investigated, the use of CNNs in seismic noise attenuation has also started to develop. Liu et al. (2018) used a 3D CNN architecture to remove random noise from a 3D poststack seismic data set. Ma et al. (2018) managed to attenuate multiples, linear noise and random noise simultaneously through the use of a CNN. However, only controlled data were employed and both the training and test data sets were computed from the same model. Slang et al. (2019) employed marine seismic field data and demonstrated successful applications within deblending and denoising using CNNs. Within the area of seismic data interpolation and reconstruction, Mandelli et al. (2018, 2019) proposed to reconstruct missing seismic traces in the prestack domain by employing a convolutional autoencoder. They applied this network to solve the joint problem of synthetic data interpolation and Gaussian-noise attenuation. Wang et al. (2018 a, b) introduced an 8-layer residual learning network (ResNet) based on CNNs to interpolate seismic data without aliasing.\nFrom this review of the seismic CNN literature, it follows that the use of field data is rather limited. Moreover, applications within denoising are dominated by the removal of Gaussian type noise. Such noise is of limited interest in real seismic data applications where we are normally concerned by various types of coherent or semi-coherent noise. Thus, the actual performance of a CNN within seismic denoising needs to be more properly addressed. In many of the current studies published, the amount of data used is not representative for problems in the seismic field. A fundamental requirement in ML is the access to a statistically large enough set of data that can be split into feasible subsets for training, validation and testing. Otherwise, there is a high chance of overfitting.\nIn this paper, the feasibility of employing CNNs within the area of deblending is"}, {"title": null, "content": "investigated. To fully ensure that this study is as realistic as possible, only real marine field data is used. The data diversity is also properly addressed by using 21000, 4500 and 1500 images respectively for training, validation and testing.\nThis paper is organized as follows. In the first section a brief description of the main CNN concepts is given, followed by a section describing and discussing the actual architecture being employed to deblend seismic data. As already discussed, resorting data to obtain incoherency in the blended contribution, transforms the deblending problem to one of removing incoherent noise. In this paper a sorting to the common channel domain is performed before the actual training by the CNN.\nIn the third section examples of employing the proposed network to blended field data with time delays of 1.8s \u00b1 0.2s random jitter are presented. The effect of SNR on the deblending quality is also discussed in this section. In the fourth section we illustrate the robustness of the proposed approach. The same trained network is then applied to a new blended field data set from a different geological area and with slightly different time delays of 2.0s \u00b1 0.25s random jitter. The results obtained are equally good in deblending accuracy. The fifth section compares the CNN approach to deblending with the results obtained employing conventional denoising algorithms. Finally, a set of conclusions is given."}, {"title": "BASIC CONCEPTS OF CNN", "content": "Fully connected layers are frequently used in deep learning ANNs, but do not represent an ideal architecture for seismic data for two main reasons. Firstly, a fully connected layer is computationally significantly more demanding than a convolutional layer, since each neuron is connected to every neuron in the previous layer and each connection has its own learnable"}, {"title": null, "content": "parameter, commonly referred to as its weight. By contrast, each neuron in a convolutional layer is only connected to a few neurons in the previous layer, and shares the same set of weights (cf. Figure 1). Seismic data sets tend to be large where each shot gather may typically contain more than $10^6$ data samples, making the use of fully connected layers very challenging given the large memory requirements and need for high-performance computing.\nSecondly, as suggested by the name, a convolutional layer applies a convolution operation on the input based on a bank of filter kernels (also called convolution matrix or mask). Let $A \\in \\Re^{3x3}$ denote the input image with elements $a_{k,l}$ for $k,l\\in \\{0,2\\}$, $O \\in \\Re^{2x2}$ denote the output image with elements $o_{m,n}$ for $m, n \\in \\{0,1\\}$ and $W \\in \\Re^{2x2}$ denotes the filter kernel with weights $W_{ij}$ for $i, j \\in \\{0,1\\}$. Figure 1 gives an example of how the 2 \u00d7 2 filter works on the 3 \u00d7 3 image with stride equals to 1, to give the output image (with mirrored kernel to ensure convolution). The stride is defined by the distance between two consecutive positions of the filter kernel (Dumoulin and Visin, 2018). The 2D convolution operation to the left in this figure can be represented by the neural network configuration shown to the right where the filter weights are represented by color-coding. Take the orange square inside the red box as an example. In this case, the result from the convolution comes from the linear combination $W_{1,1}a_{1,1} + W_{1,0}a_{1,2} + W_{0,1}a_{2,1} + W_{0,0}a_{2,2} = o_{1,1}$, where the kernel is linked to the orange neuron inside the red circle in the network by the gray arrow. As shown to the right in Figure 1, only four blue neurons in the previous layer are connected through weights (filter coefficients) with the orange neuron inside the red circle (with weights being color coded according to the color scheme chosen for the filter coefficients).\nAccording to Goodfellow et al. (2016), this type of architecture makes CNNs well"}, {"title": null, "content": "suited for 2D images where neighboring pixels are connected to form local patterns. It should therefore be possible to deblend seismic data after common channel resorting, where the unblended data (data from the first source) exhibits a continuous and coherent form but the blending noise (data from other sources) manifests itself as incoherent contributions."}, {"title": null, "content": "The term convolutional neural network (CNN) is used in a broad sense. In fact, all artificial neural networks containing one or more convolutional layers can be classified as CNNs. A feedforward neural network consists of basic units represented by the neurons that are stacked into layers, with the output of one layer serving as the input for the next one. The complete neural network can be thought of as a complicated nonlinear transformation of the input into a predicted output that depends on the learnable weights and biases of all the neurons in the input layer, the hidden layers and output layer (Mehta et al., 2019).\nConsider a training data set $\\{T_i,\\tilde{T}_i\\}_{i=1}^M$ where $T$ and $\\tilde{T}$ defines the clean (ground truth) and contaminated data respectively. Since in our case, the contamination in $\\tilde{T}$ is spatially discontinuous in the chosen gather domain, we want to construct and train a function (network) $f_{w,b}:\\tilde{T} \\rightarrow T$, which preserve the spatially continuous character in the seismic"}, {"title": null, "content": "image. The function $f_{w,b}$ is in our case based on a conventional feed forward CNN architecture with no dense layers. Let $N_l$ denote the number of features and $k_l = 1,2,..., N_l$ denote the $k'th$ convolution filter in layer $l=1,2,..., L$. The feature mapping from an arbitrary layer to the next can be summarized by the expression\n$Z_k^{[l]} = \\sum\\limits_{k_l-1=1}^{N_{l-1}} (W_{k k_{l-1}}^{[l]} * A_{k_{l-1}}^{[l-1]}) + B_k^{[l]}$,\nwhere $W_{k k_{l-1}}^{[l]} \\in \\Re^{f_l \\times f_l}$ contains the weights and $B_k^{[l]}$ is a matrix of same size as $Z_k^{[l]}$ containing the biases. The notation $*$ denotes the convolutional process. In equation 1, $A_{k_{l-1}}^{[l-1]}$ represents one of the activations from the previous layer. The activation is defined by a non-linear transformation on all $k_l = 1,2,..., N_l$ mappings of the feature maps, and defines the output from layer $l-1$ to layer $l$. The activation of layer $l$ can be represented by the general expression\n$A^{[l]} = \\varphi^{[l]}(Z^{[l]}),$\nwhere $\\varphi^{[l]}$ is the non-linear function. In our case, we chose the Leaky Rectified Linear Unit or Leaky ReLU (Maas et al., 2013) defined as\n$A_i^{[l]} = max(Z_i^{[l]}, \\alpha Z_i^{[l]}).$\nIt is a modified version of the more conventionally used ReLU function where a slope is introduced for negative arguments. In the seismic case, we observed that the slope value $\\alpha$ seems to benefit from being larger than the small values advocated in the literature for conventional images. In fact, we employed $\\alpha = 0.4$, as opposed to the typical value of $\\alpha = 0.01$ used in the non-seismic case. The use of the conventional ReLU activation function may cause a problem called \u201cdead neurons\u201d. In the case where input to a ReLU with its weights is negative, the output will be 0, causing the gradient also to be 0. If instead Leaky ReLU is used, the gradient will never be 0 and this problem is avoided."}, {"title": null, "content": "The convolution process of going from an arbitrary layer l-1 to layer l represented by the first term on the right-hand-side of equation 1 is illustrated in Figure 2 for one single element in the matrix $Z_k^{[l]}$. The matrix $W_k^{[l]}$ represents the $k_l$ 'th filter kernel spanning all activations in layer l-1 producing each of the $k_l = 1,2,..., N_l$ feature maps in layer l.\n\nThe logistic function, also known as sigmoid function, is also a common activation function in neural networks. The sigmoid activation function is defined as\n$\\varphi(x) = \\frac{1}{1+e^{-x}},$\nIn our case the network performance increased by using the sigmoid function in the output layer, which defines the predicted clean image\n$\\tilde{T} = \\sigma(\\sum\\limits_{k_{L-1}=1}^{N_{L-1}} (W_{k k_{L-1}}^{[L]} * A_{k_{L-1}}^{[L+1]}) + B_k^{[L]}),$\nWe fit the predicted data by minimizing the $L_2$ loss of the difference between the clean target images $T$ and the prediction $\\tilde{T}$,\n$L_2(W,B) = \\frac{1}{2}||T-\\tilde{T}||^2.$\nIn order to find the weights and biases that minimize equation 6, we train the network using a first-order gradient method for stochastic optimization, known as RMSprop (Tieleman"}, {"title": null, "content": "and Hinton, 2012).\nFor the training process we split the training data into three data sets: a training set, a validation set and a test set. The data sets are constructed by sorting the training data randomly, and distributing them such that approximately 80% of the total number of data samples is used for training, 15% for validation and 5% for testing. In terms of training, the network adjusts the weights and biases based on the difference between ground truth and the predicted output. The final model (in terms of weights and biases) is chosen according to the best fit on the validation set. After the training and validation phases are complete, the performance of the network is checked by applying the model to the independent test data.\nWhen discussing a CNN architecture, it is important to notice that seismic data contains very different structural information compared to a conventional image. To illustrate these differences, Figure 3 shows a conventional image to the left and its seismic counterpart to the right. On direct comparison, the seismic image contains a much narrower band in both temporal and spatial frequencies making the texture different from the conventional image. Equally important, the conventional image is in colors (RBG) so the input to a CNN network will be three channels, one for each color, opposed to the seismic case which is only represented by one channel of grey-levels. Also, the dynamic range of a seismic image is often large compared to that of a picture, especially for prestack data, where amplitudes within a typical gather vary by 3 orders of magnitude or more. This means that the blending noise we try to remove might typically be 1000 times stronger when compared to the unblended signals underneath. Deblending is therefore a non-trivial signal processing problem that, as mentioned in the introduction, is receiving a lot of attention from both industry and academic research. These"}, {"title": null, "content": "major differences imply that well-established CNN architectures employed within image processing may not be ideal when applied to seismic gathers. Thus, new designs need to be developed and tested for each application in question. In the next section, a CNN architecture developed for the deblending problem is introduced and discussed."}, {"title": "A CNN ARCHITECTURE FOR SEISMIC DEBLENDING", "content": "We now present and discuss the proposed CNN architecture for denoising/deblending of seismic data. The input data are assumed to be resorted from the common source to the common channel domain to make the blending noise incoherent. To reduce the size of the seismic data volume, the data were resampled from 2 to 4ms. Moreover, the data were also segmented into smaller subsets of size 800 time samples \u00d7 40 traces, and normalized to fall in the range 0 to 1 by the following equations,\n$blended_{norm} = (blended +1)/2, blended_{norm} \\in [0,1],$\n$truth_{norm} = (truth +1)/2, truth_{norm} \\in [0,1],$\nwhere maxxer is the maximum absolute value of the blended data and ground truth/unblended data. We use $blended_{norm}$ and $truth_{norm}$ as the input of the network, and this"}, {"title": null, "content": "process is reversible. The output of the network can be denormalized by\n$output_{denorm} = (output\\times2-1)\\times maxxer .\nThe complete CNN design employed in this study is shown schematically in Figure 4."}, {"title": null, "content": "The proposed CNN has 8 convolutional layers in total and can be classified as a deep network. The convolutional operations to produce the first 5 hidden layers have 64 kernels with size 3 \u00d7 3, which for the last 2 hidden layers are reduced to 32 kernels with size 3 \u00d7 3. The Leaky Rectified Linear Unit (Leaky ReLU) is used as an activation function in every convolutional layer except the last convolutional layer where the Sigmoid is employed. In addition, Batch Normalization (BatchNorm) is used in the initial part of the network.\nBatchNorm is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). According to Ioffe and Szegedy (2015), BatchNorm addresses the problem called internal covariate shift by normalizing layer inputs. In traditional deep networks, high learning rates may result in gradients that explode or vanish, as well as solutions stuck in local minima. BatchNorm helps to avoid zero values in the network, which easily appear due to the large dynamic range in prestack (blended) data gathers. A disagreement exists in the literature, whether the issue of covariate shift enables BatchNorm to improve training."}, {"title": null, "content": "Santurkar et al. (2018) suggested that BatchNorm makes the optimization landscape significantly smoother, thus inducing a more predictive and stable behavior of the gradients, allowing for faster training.\nCompared to typical CNNs employed in conventional image analysis, no downscaling is applied in our model. Take max pooling (Boureau et al., 2010; Scherer et al., 2010) as an example, the objective of adding it to image classification models is to down-sample an input representation, reducing its dimensionality, and also to help avoid overfitting by providing an abstracted form of the representation. However, in seismic deblending, it is important to preserve as much as possible of the geological information while removing blending noise. Thus, in our case, the network is designed without downscaling to reduce potential blurring and precision loss. The learning rate started from 0.001 and automatically multiplied by a factor 0.9 every second epoch.\nHaving introduced the basics of the CNN in use, we give a more detailed discussion of the various main design choices."}, {"title": "Filter size", "content": "Different filter sizes were tested as part of the design process for the CNN. Larger filter sizes of 7 x 7 and 5 x 5 were tested but the performance of the trained network was found to be poorer than in the case of 3 x 3 filters. Figure 5 shows an example of a deblended source gather (after resorting from common channel gathers) for three different sizes of the convolutional filters."}, {"title": "Number of filters", "content": "Different combinations of filter banks were tested in order to optimize the design. The performance quality was quantified using the loss. Figure 6 shows an example of the loss function (training and validation) for two set of filter combinations, respectively denoted model 1 and model 2: 64 and 32 (the one used in the actual CNN) and 32 and 16."}, {"title": "Number of layers", "content": "It is not given that adding more layers or more neurons to a CNN will improve its performance. Redundancy will result in increased training time and the waste of computational power. In order to analyze the authenticity effects of adding more layers to the network, we carried out a comprehensive quality control of the feasibility maps output from each layer. The main idea was to obtain a maximum of complementary features and avoid \u2018dead' convolutional filters (e.g. with no action on the data). Figure 7 shows an example of a collection of feature maps for the last hidden layer in the final design of our CNN. Because of limited space, only 6 out of 32 panels are shown here. We can see how the network decomposes the data partially in character and partially in frequency bands, and with some features enhancing the blended noise whereas others enhance the signal to be recovered."}, {"title": "FIELD DATA EXAMPLES", "content": "In the first part of this field study, we used 1300 unblended marine split-spread shot gathers from a 2017 survey in the Barents Sea (Vinje et al., 2017). From this set of data, we constructed blended shots by adding two consecutive shots with a fixed delay time perturbed with a predefined random jitter. By changing the delay time, various source configurations could be simulated. In the example considered, the delay time was set to 1.8s \u00b1 0.2s of random jitter. This implies a rather challenging case, where the blended contribution appears at larger traveltimes, thus superimposing the weaker reflections in the unblended source gathers (e.g. the events to be recovered). The training, validation and test data sets consisted of 21000, 4500 and 1500 images respectively with 40 traces per image after sorting to the common channel domain. In fact, we can choose any number of traces per image, but too few traces will be insufficient to capture local geology and too many traces will be difficult to fit into memory. The training process (35 epochs) employing a deep CNN requires significant computational power, and for this particular test the run time was approximately 140 hours on a standard CPU, but only 7 hours on a fairly modern GPU. However, once the network was properly trained, deblending of a single gather could be done in nearly real time. Information about the CPU and GPU used is as follows:\nCPU: Intel Xeon E5-16200, 3.60Hz, 10 MB Cache, 4 Cores, 8 Threads,\nGPU: Nvidia GeForce GTX TITAN Black, 6GB.\nAs already discussed, a more optimized denoising problem is achieved by resorting the data into the common channel domain. In this domain, the blending noise will transform from coherent to incoherent events."}, {"title": null, "content": "Figure 8 shows an example of a result obtained using the trained network in the common channel domain. Figures 8a-c represent the ground truth (e.g. the unblended source gather), the blended source gather and the deblended result output from the CNN, respectively. Moreover, Figures 8d and e show respectively a difference plot between the ground truth and the deblended result, and the noise removed by the proposed CNN. As part of this combined figure, the amplitude spectra of the ground truth and the deblended result are also shown. We can observe that the network has performed overall well. To further quantify the quality of the deblending, we computed the sum of the absolute amplitude in each pixel in Figure 8d and found it to be only 0.226% of the same measure computed in the ground truth represented by Figure 8a. This is a quite encouraging result."}, {"title": null, "content": "The actual noise removed by the network is shown in Figure 8e. Its incoherent characteristic can easily be seen from this figure. The corresponding amplitude spectrum is also shown below. Direct comparison with the spectra computed from the ground truth and the removed noise show strong correlation. Thus, as expected, this type of noise is far from the ideal Gaussian distribution.\nTo further investigate the performance of our CNN, we apply the trained network on an ensemble of common channel test data and resort back to the shot domain. Figure 9 shows an example of such a deblended source gather. The sequence of subfigures is the same as in Figure 8. It can be seen that the blending noise has been mostly removed. The sum of the absolute"}, {"title": null, "content": "amplitude values in each pixel in Figure 9d is only 0.241% of that in Figure 9a. However, weak residuals are still present, and we observe a pattern of blank stripes in the deblended shot gather, which coincide with the very strong water-bottom reflections from the N+1 shot."}, {"title": null, "content": "To add some more insight into the observations made in Figure 9, we repeated the experiment but with the blended contribution being scaled down with a given factor before being superimposed the ground truth. Four different scenarios were investigated with the value of the factor being respectively 0.8, 0.6, 0.4 and 0.2. As the factor becomes lower, the SNR of the blended data is increasing (the events of the ground truth become stronger relative the blended events).\nFigure 10 shows a summary of the results obtained after resorting to the shot domain. The number in the upper left corner of the picture indicates the percentage of blending noise that was introduced. The number in the upper right corner indicates the sum of the absolute amplitude values in each pixel in the picture relative the ground truth (set to 100%). To enhance the comparison, only a zoomed part of the image within the target zone (red box in Figure 9) is shown for each experiment. It can clearly be seen, that the SNR is the major factor controlling the quality of the final result."}, {"title": null, "content": "deblended data.\nTo add some more insight into the observations made in Figure 9, we repeated the experiment but with the blended contribution being scaled down with a given factor before being superimposed the ground truth. Four different scenarios were investigated with the value of the factor being respectively 0.8, 0.6, 0.4 and 0.2. As the factor becomes lower, the SNR of the blended data is increasing (the events of the ground truth become stronger relative the blended events).\nFigure 10 shows a summary of the results obtained after resorting to the shot domain. The number in the upper left corner of the picture indicates the percentage of blending noise that was introduced. The number in the upper right corner indicates the sum of the absolute amplitude values in each pixel in the picture relative the ground truth (set to 100%). To enhance the comparison, only a zoomed part of the image within the target zone (red box in Figure 9) is shown for each experiment. It can clearly be seen, that the SNR is the major factor controlling the quality of the final result."}, {"title": null, "content": "Before closing this field data section", "now": "firstly, how well will a trained network perform on data from another survey and different geological area? Secondly, how well will a trained network perform on another blending case where the blended shots have blending noise in the top part of the data? If we can avoid time-consuming retraining it will make the use of a CNN much more attractive, since the data processing time will be dramatically reduced compared to a conventional approach.\nTo test out how robust and adaptive our proposed network is, we firstly used the trained model from the Barents Sea study discussed above to deblend data from a different survey campaign. This new data set had a slightly different delay time of 2.0s \u00b1 0.25s random jitter, but more importantly was acquired in the North Sea (Dehlie et al., 2018). Thus, the geology of this latter area is very different from that of the Barents Sea, being separated by a distance of almost 2000km. Figure 11 shows an example of a deblended result in the common channel domain. Correspondingly, Figure 12 shows a deblended shot gather after resorting back to the shot domain. Direct comparisons between Figures 8 and 11 and between Figures 9 and 12 show that the new deblended data are of similar quality.\nNext, we considered the second blended shots that had blending noise in the top part of the data. The same trained CNN as before was employed to deblend such second shots without retraining. Appendix A gives an example of a deblended second shot (N+1) as well as results obtained in the common channel domain. It can be seen that the network performs well but slightly poorer than in the case of the first of the blended shots (N) as expected.\nThese"}]}