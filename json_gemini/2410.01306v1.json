{"title": "Emotion-Aware Response Generation Using Affect-Enriched Embeddings with LLMs", "authors": ["Abdur Rasool", "Muhammad Irfan Shahzad", "Hafsa Aslam", "Vincent Chan"], "abstract": "There is a need for empathetic and coherent responses in automated chatbot-facilitated psychotherapy sessions. This study addresses the challenge of enhancing the emotional and contextual understanding of large language models (LLMs) in psychiatric applications. We introduce a novel framework that integrates multiple emotion lexicons, including NRC Emotion Lexicon, VADER, WordNet, and SentiWordNet, with state-of-the-art LLMs such as LLAMA 2, Flan-T5, ChatGPT 3.0, and ChatGPT 4.0. The primary dataset comprises over 2,000 therapy session transcripts from the Counseling and Psychotherapy database, covering discussions on anxiety, depression, trauma, and addiction. We segment the transcripts into smaller chunks, enhancing them with lexical features, and computing embeddings using BERT, GPT-3, and RoBERTa to capture semantic and emotional nuances. These embeddings are stored in a FAISS vector database, enabling efficient similarity search and clustering based on cosine similarity. Upon user query, the most relevant segments are retrieved and provided as context to the LLMs, significantly improving the models' ability to generate empathetic and contextually appropriate responses. Experimental evaluations demonstrate that incorporating emotion lexicons enhances empathy, coherence, informativeness, and fluency scores. Our findings highlight the critical role of emotional embeddings in improving LLM performance for psychotherapy.", "sections": [{"title": "Introduction", "content": "Mental health disorders represent a significant global challenge, impacting approximately 450 million individuals worldwide and resulting in an estimated $1 trillion in productivity losses annually (D. Arias, Saxena, & Verguet, 2022; Brown et al., 2020). In the United States alone, nearly 51.5 million adults experience mental illness each year, underscoring the critical need for accessible and effective mental health care solutions (Adams & Nguyen, 2022). Central to these mental health issues are psychological emotions, which play a crucial role in shaping behaviors, thoughts, and overall well-being (Gross & Jazaieri, 2014). Conditions such as depression, anxiety, and bipolar disorder profoundly affect emotional states, necessitating timely psychological interventions. However, the availability of professional counseling is often constrained by high costs and limited resources (Coombs, Meriwether, Caringi, & Newcomer, 2021; Haugen, McCrillis, Smid, & Nijdam, 2017).\nIn recent years, advancements in Artificial Intelligence (AI) and machine learning have revolutionized emotion recognition, enabling more sophisticated analysis of human emotions through modalities such as text, speech, and facial expressions (Dalvi, Rathod, Patil, Gite, & Kotecha, 2021). These technologies have been effectively utilized across various domains, including customer service and healthcare. However, despite significant progress, existing AI models often fall short of generating nuanced, empathetic responses that fully resonate with users, particularly in the context of mental health (Khare, Blanes-Vidal, Nadimi, & Acharya, 2023). For instance, while BERT has shown promise in emotion detection within therapy transcripts, it lacks the capability to produce empathetic and contextually appropriate responses (Kumar & Jain, 2022). Similarly, LLMs like Alpaca and Generative Pre-trained Transformer-4 (GPT-4) have demonstrated potential in mental health prediction tasks but still struggle to capture the full depth of human emotions in response generation (Xu et al., 2024).\nRecent research has begun to explore the integration of emotion lexicons with neural networks to enhance the emotional understanding and response generation capabilities of AI models. For example, Nandwani and Verma combined Convolutional Neural Networks (CNNs) with the NRC (National Research Council Canada) Emotion Lexicon to improve emotion detection from text, achieving deeper emotional insights (Nandwani & Verma, 2021). Likewise, Arias and colleagues employed Recurrent Neural Networks (RNNs) alongside the VADER (Valence Aware Dictionary for Sentiment Reasoning) sentiment analysis tool to analyze social media posts for signs of depression, yielding significant improvements in sensitivity and specificity (F. Arias, Nunez, Guerra-Adames, Tejedor-Flores, & Vargas-Lombardo, 2022). These studies highlight the potential of combining lexicon-based approaches with neural networks."}, {"title": null, "content": "However, existing models still struggle to fully capture the intricacies of human emotions, often leading to responses that do not adequately reflect the user's emotional state. The advent of LLMs such as GPT-3 (Brown et al., 2020), GPT-4 (Kalyan, 2024), and the Fine-Tuned Language Model (Flan-T5) (Chung et al., 2024) has opened new avenues for understanding and generating human-like text, particularly in mental health applications (Xu et al., 2024). For example, Xu et al. (2023) demonstrated the use of GPT-4 in enhancing mental health question-answering tasks (Rodrigues et al., 2024). Gao et al. explored Flan-T5's effectiveness in predicting mental health outcomes from social media data (Nowacki, Sitek, & Rybi\u0144ski, 2024). When fine-tuned for specific tasks, these models have shown promise in improving mental health prediction and response generation. However, despite these advancements, integrating emotional lexicons into LLMs for enhanced empathetic response generation remains underexplored. This gap results in models that excel in either detection or generation but fail to synergistically combine these capabilities to fully resonate with users emotionally (Gu et al., 2024; Ma, Mei, & Su, 2023).\nIn this study, we aim to bridge this gap by introducing a novel framework that integrates multiple emotion lexicons-NRC Emotion Lexicon, VADER, WordNet, and SentiWordNet with state-of-the-art LLMs, including LLAMA 2, Flan-T5, ChatGPT 3.0, and ChatGPT 4.0. Our approach involves segmenting therapy session transcripts, enhancing them with lexical features, and computing affect-enriched embeddings using models like BERT, GPT-3, and RoBERTa. These embeddings are stored in a FAISS vector database, enabling efficient retrieval of contextually relevant segments based on cosine similarity. By providing these enriched segments as context to the LLMs, we significantly enhance their ability to generate empathetic and contextually appropriate responses. Our experimental evaluations, conducted with and without emotion lexicon resources, demonstrate that incorporating these lexicons leads to substantial improvements in empathy, coherence, informativeness, and fluency scores. This approach advances the performance of LLMs in psychotherapy applications and holds significant social impact and public health potential by improving the quality of automated mental health support."}, {"title": "Proposed Methodology", "content": "Our approach evaluates the effectiveness of using lexicon dictionaries with various LLMs to enhance emotional state detection and response in a psychiatric context, as presented in Figure 1."}, {"title": "Dataset", "content": "The primary dataset used in this study consists of psychotherapy transcripts from the Counseling and Psychotherapy Transcripts, Client Narratives, and Reference Works database (Shapira et al., 2021). This resource includes over 2,000 transcripts of therapy sessions, patient narratives, and reference works. The dialogues in these transcripts cover a wide range of topics and discussions, including therapeutic interventions, patient histories, emotional disclosures, coping mechanisms, and interactions between therapists and clients. Specific topics discussed include anxiety, depression, relationship issues, trauma, addiction, grief, self-esteem, and personal growth."}, {"title": "Text Extraction & Splitting", "content": "The extraction process involves removing irrelevant information such as session metadata, timestamps, and non-verbal cues. This allows the focus to be on essential text elements that convey emotional states. For example, irrelevant information is removed by using regex patterns to filter out non-essential text. Segmenting the text into smaller chunks allows for detailed and precise analysis. For instance, the text is split into sentences and further into phrases that capture nuanced emotions.\nLet T be the complete transcript, S\u1d62 be sentences in T, and P\u1d62\u2c7c be phrases within each sentence.\n T = {S\u2081, S\u2082, ..., S\u2099}\n S\u1d62 = {P\u1d62\u2081, P\u1d62\u2082, ..., P\u1d62\u2098}\nThis segmentation helps in creating manageable chunks, preserving context and enhancing embedding effectiveness. For example, the sentence \"I feel anxious about my job\" can be split into phrases like \"I feel anxious\" and \"about my job,\" both retaining the emotional context which is crucial for"}, {"title": null, "content": "generating meaningful and empathetic responses. We incorporated the following emotion lexicons to enrich this dataset with emotional cues.\n\u2022\tThe NRC Emotion Lexicon is a list of English words associated with eight basic emotions: anger, fear, anticipation, trust, surprise, sadness, joy, and disgust. This lexicon helps identify and categorize emotional expressions within the text, adding a layer of emotional understanding to the analysis (Al Maruf et al., 2024).\n\u2022\tThe VADER lexicon is designed for sentiment analysis in social media contexts. VADER assigns a sentiment score to each word, and is particularly effective in analyzing short, informal texts, making it a valuable tool for understanding the sentiment conveyed in conversational language (Hutto & Gilbert, 2014).\n\u2022\tWordNet is a lexical database that groups English words into synsets, representing specific concepts and their semantic relations. It aids in understanding word meanings and context in text analysis (Miller, 1995).\n\u2022\tSentiWordNet extends WordNet by assigning sentiment scores (positive, negative, or neutral) to synonym sets, making it useful for sentiment analysis in various contexts (Esuli & Sebastiani, 2006)."}, {"title": "Embedding Transformation", "content": "For embedding transformation, we use default embeddings like BERT (Qin et al., 2023) and RoBERTa (Luo, Phan, &\nReiss) from Hugging Face, and embeddings from OpenAI\nare GPT-3 and Codex (Hadi et al., 2023). These embeddings convert each transcript segment into high-dimensional vectors, capturing essential semantic and emotional nuances crucial for effective vector retrieval and response generation.\nThe embeddings serve as numerical representations of transcript segments, allowing models to deeply process and understand the text. By converting text into high-dimensional vectors, models capture and analyze semantic and emotional content, enabling nuanced text analysis and accurate response generation.\nGiven a transcript segment x, it is transformed into an embedding \u03a6(x) using an embedding model:\n\u03a6(x) = EmbeddingModel (x)  (1)\nwhere EmbeddingModel could be any specific LLM. The transformation \u03a6(x) maps the transcript segment x into a high-dimensional vector space.\nAssuming x is represented by a sequence of tokens (x\u2081, x\u2082, ..., x\u2099), each token x\u1d62 is embedded into a vector e\u1d62. To capture contextual dependencies, a self-attention mechanism computes a weighted sum of the embeddings:\n a\u1d62 = \u03a3\u2c7c\u208c\u2081\u207f \u03b1\u1d62\u2c7ce\u2c7c (2)\nwhere \u03b1\u1d62\u2c7c are the attention weights calculated as (Huang, Liang, Qin, Zhong, & Lin, 2023):\n\u03b1\u1d62\u2c7c = exp(e\u1d62\u22c5e\u2c7c) / \u03a3\u2096\u208c\u2081\u207f exp(e\u1d62\u22c5e\u2096) (3)\nThis results in a context-aware embedding for each token, aggregated to form the final representation:\n\u03a6(x) = \u03a3\u1d62\u208c\u2081\u207f a\u1d62 (4)"}, {"title": "Vector Retrieval", "content": "We store the embedded vectors in an efficient vector database designed for high-dimensional data, specifically using FAISS (Facebook AI Similarity Search). FAISS enables fast similarity search and clustering of dense vectors, which is essential for our large-scale machine learning tasks(Ghadekar, Mohite, More, Patil, & Mangrule, 2023). In our study, FAISS stores and retrieves embeddings efficiently.\nGiven an input query q, FAISS retrieves the most relevant transcript segments {x\u1d62} by computing the cosine similarity between the query embedding \u03a6(q) and the stored embeddings,\n{\u03a6(x)}: sim (q, x\u1d62) = \u03a6(q)\u22c5\u03a6(x\u1d62) / |\u03a6(q)||\u03a6(x\u1d62)| (5)\nFor example, if a user queries about feeling anxious, FAISS finds the closest matching transcript segments related to anxiety. This helps the model generate a response that is relevant and empathetic to the user's concern."}, {"title": "Response Generation", "content": "The selected LLMs generate responses based on retrieved segments. Vector retrieval provides relevant transcript segments {x\u1d62} for a given input query q. The response generation process is formulated as:\nr = LLM (q, {x\u1d62})  (6)\nwhere r is the generated response, q is the input query, and {x\u1d62} are the retrieved segments.\nLexicon resources enhance the models' empathetic and coherent response capabilities by providing emotional cues and semantic meanings. For example, the system retrieves relevant segments and generates a supportive response if a user queries about feeling anxious. Algorithm 1 shows the response generation of the proposed framework. It starts by initializing t to 0 and iterates through each transcript segment x\u209c in X. For each segment, it computes the embedding \u03a6(x\u209c) using the embedding model E. If elements from the"}, {"title": null, "content": "lexicon L are present in x\u209c, the algorithm enhances the embedding by computing \u03c8 with \u03b4(e\u1d62, L) and updates \u03a6(x\u209c). If no such elements are found, \u03c8(x\u209c) remains unchanged. After processing all segments, the algorithm increments t and repeats the process. Finally, it applies the function \u03a8 to the set of segments X and their embeddings \u03a6(X), generating the emotion-aware responses R. The function \u03a8 processes the transcript segments and their embeddings to produce the final set of emotion-aware responses stored in R. The following LLMs are used to generate responses."}, {"title": "Flan-T5 Large", "content": "A well-known model for natural language understanding tasks, optimized for text-to-text transformations. In this model, the probability of generating an output sequence y given an input sequence x is represented as (Chung et al., 2024):\nP(y | x) = \u220f\u209c\u208c\u2081\u1d40 P(y\u209c | y_<.t, x; \u03b8) (7)\nwhere y is the output sequence, x is the input sequence, and \u03b8 represents the model parameters.\nThe derivation involves modeling the conditional probability of each token y\u209c in the output sequence, given the previous tokens y_<.t and the input sequence x."}, {"title": "Llama 2 13B", "content": "It's a large-scale model with robust understanding and generation capabilities, particularly effective in handling longer contexts and providing nuanced responses. Its autoregressive generation process is represented as (Touvron et al., 2023):\nP(x\u209c | x_<.t) = softmax (W\u2095h\u209c) (8)\nwhere x\u209c is the current token, x_<.t are the preceding tokens, W\u2095 is a weight matrix, and h\u209c represents the hidden state at time t.\nThis captures the dependencies and context within the input sequence, allowing the model to generate coherent and contextually appropriate text."}, {"title": "ChatGPT 3.5", "content": "It is a widely used model with general conversational abilities, expected to show marked improvements in empathy and coherence with lexicons due to its conversational design. The decoding process is modeled by (Brown et al., 2020):\nP(y\u209c | y_<.t, x) = softmax (W\u1d67y\u209c\u208b\u2081 + W\u2093x + b) (9)\nwhere y\u209c is the generated token at time t, y_<.t are the preceding tokens in the output sequence, x is the input sequence, W\u1d67 and W\u2093 are weight matrices, and b is a bias term.\nThis formulation allows the model to generate each token y\u209c based on the preceding context and the input sequence."}, {"title": "ChatGPT 4", "content": "The latest iteration in the GPT series, has advanced training on diverse datasets and is expected to provide balanced improvements across all metrics with different lexicons. Its autoregressive nature of generation is modeled as (Liu et al., 2023):\nP(x\u209c | x_<.t) = softmax (W\u209ch\u209c\u208b\u2081 + b\u209c) (10)\nwhere x\u209c is the token at position t, x_<.t are the preceding tokens, W\u209c is a weight matrix specific to the position t, h\u209c\u208b\u2081 is the hidden state from the previous step, and b\u209c is a bias term.\nThis equation models the probability distribution of the current token based on the hidden states derived from preceding tokens, ensuring the generation of contextually coherent responses."}, {"title": "Quality Metrics", "content": "We define several metrics to evaluate the quality of the chatbot's responses. Each metric assigns a score based on specific criteria. The functions are:\nEmpathy Score\nIt evaluates how empathetic a response is. Instead of a simple modulo operation, we use a more complex function to capture the nuances of empathy in language. The score is calculated as follows (Lima & Os\u00f3rio, 2021):\nE = \u03a3\u1d62\u208c\u2081\u1d3a weight\u1d62 \u22c5 emotion\u1d62 / \u03a3\u1d62\u208c\u2081\u1d3a weight\u1d62 (11)\nwhere weight\u1d62 represents the importance of the i-th emotional word, and emotion\u1d62 is the intensity of the emotion"}, {"title": null, "content": "conveyed by the i-th word in the response. This weighted sum captures the overall empathetic content more effectively.\nCoherence Score\nIt assesses the coherence of a response by measuring the logical flow and consistency of the text. It is determined by (Marchenko, Radyvonenko, Ignatova, Titarchuk, &\nZhelezniakov, 2020):\nC = \u03a3\u1d62\u208c\u2081\u1d3a\u207b\u00b9 exp(-d(w\u1d62, w\u1d62\u208a\u2081) / \u03c3\u00b2) (12)\nwhere d(w\u1d62, w\u1d62\u208a\u2081) is the semantic distance between consecutive words w\u1d62 and w\u1d62\u208a\u2081, and \u03c3 is a scaling factor that adjusts the sensitivity to semantic distances. This formulation uses the exponential function to penalize significant semantic gaps, ensuring a coherent response.\nInformativeness Score\nIt measures how informative a response is by considering the amount and relevance of information provided. The score is given by (Senbel, 2021):\nI = log(1+ \u03a3\u1d62\u208c\u2081\u1d3a tf - idf (w\u1d62)) (13)\nwhere tf - idf (w\u1d62) is the term frequency-inverse document frequency of word w\u1d62. This logarithmic function accounts for the diminishing returns of adding more information, emphasizing the importance of key terms.\nFluency Score\nIt evaluates the fluency of a response, ensuring it reads naturally. The score is calculated as (Villalobos, Torres-Sim\u00f3n, Pacios, Paul, & Del R\u00edo, 2023):\nF = 1/N \u03a3\u1d62\u208c\u2081\u1d3a P(w\u1d62 | w\u1d62\u208b\u2081, w\u1d62\u208b\u2082, ..., w\u1d62\u208b\u2099) (14)\nwhere P(w\u1d62 | w\u1d62\u208b\u2081, w\u1d62\u208b\u2082, ..., w\u1d62\u208b\u2099) is the conditional probability of word w\u1d62 given its n-gram history.\nThis average probability captures the smoothness and naturalness of the language used. To calculate the average score for a given metric, the following formula is used\nA = 1/M \u03a3\u1d62\u208c\u2081\u1d39 metric_function(response\u1d62) (15)\nwhere M is the total number of responses, and metric_function is one of the defined metric functions. The 'metric_function' dictionary maps the four critical evaluation criteria to their respective scoring functions. The overall performance score for each model is calculated as:\nScoreavg = 1/4(E + C + I + F) (16)"}, {"title": "Baseline Performances", "content": "In our initial evaluation, we assessed the baseline performance (without lexicon adding) of four state-of-the-art LLMs in the context of psychotherapy-related tasks. Each model was evaluated across four key metrics: empathy, coherence, informativeness, and fluency. The results are summarized in Table 1."}, {"title": "Affect-Enriched LLMs Comparisons", "content": "We tested the same four LLMs on psychotherapy-related metrics to evaluate the impact of incorporating NRC lexicons to enrich the effects of embedding. The results based on NRC affect enrichment are summarized in Table 2."}, {"title": "LLMs Responses Comparison", "content": "We have demonstrated the comparative analysis of generated responses from four LLMs with and without affect-enriched embeddings. Figure 3 presents this comparison based on the enrichment of one lexicon (NRC Emotion Lexicon) with the same question. The questionnaire-based performance reveals the significant impact of integrating the lexicon on the response generation by LLMs.\n\u2022\tLlama 2 13B shows a significant improvement with the NRC dataset. Without it, the model provides a standard, albeit somewhat shallow, response that acknowledges the user's feelings but lacks detailed guidance. With the NRC dataset, the model's response becomes more empathetic and actionable, offering practical advice like talking to a supervisor or documenting the incident. This enhancement highlights Llama 2 13B's increased ability to process emotional content effectively, making the interaction more supportive and useful.\n\u2022\tFlan-T5 struggles to generate emotionally nuanced responses without the NRC dataset, often offering basic acknowledgments like \"He praised his colleague,\" which lack depth. While the NRC dataset helps the model adopt a more empathetic tone, the responses remain fragmented and fail to engage with the user's emotional nuances fully. This issue is partly due to Flan-T5's tokenization mechanism, which is capped at 512 tokens. When inputs exceed this limit, the model may truncate the text, leading to incomplete or disjointed responses. Additionally, the special tokens used to capture specific emotions can disrupt the flow of the response, further limiting its effectiveness.\n\u2022\tChatGPT 3.5 delivers a coherent and supportive response even without the NRC dataset, though it remains somewhat generic. The model recognizes the user's frustration and suggests speaking with a colleague or supervisor."}, {"title": null, "content": "When the NRC dataset is applied, the response becomes more emotionally attuned, reflecting a better understanding of the user's anger, though the advice itself does not significantly change. This indicates that the NRC dataset enhances the tone of the response more than the content.\n\u2022\tChatGPT 4 also benefits from the NRC dataset. Initially, without it, the responses are mechanical, simply recognizing that the client is upset. With the NRC dataset, the model adopts a more empathetic tone, providing thoughtful advice and encouraging positive actions. This shift suggests that ChatGPT 4, like ChatGPT 3.5, enhances its emotional engagement with the integration of the NRC dataset, improving the overall supportiveness of the interaction.\nThe comparative analysis underscores the value of integrating affect-enriched embeddings into LLMs, particularly for applications requiring emotional sensitivity and coherence. While the NRC dataset significantly improves the empathetic tone of responses, the results also highlight the challenges of balancing emotional engagement with the coherence and informativeness of the output."}, {"title": "Discussion", "content": "The integration of emotion lexicons with LLMs has demonstrated significant potential in enhancing the empathy and contextual understanding of AI-driven responses within psychotherapy applications. Our study reveals that while LLMs like Flan-T5, ChatGPT 3.5, and ChatGPT 4 excel in emotional engagement, the incorporation of lexicons such as NRC, VADER, WordNet, and SentiNet introduces a complex trade-off between empathy and coherence.\nA primary challenge was the token limitation in Flan-T5 Large and Llama 2 13B, leading to indexing errors and difficulty processing longer inputs, which are crucial in psychotherapy. Addressing this through model truncation or attention optimization could improve the handling of extended dialogues. Another challenge was balancing informativeness with other metrics like empathy and coherence. For instance, ChatGPT 3.5's 400% improvement in informativeness with the VADER lexicon led to a 50% drop in coherence and fluency (Table 3). This highlights the trade-off between providing detailed information and maintaining conversational quality, which is essential in therapeutic settings.\nBalancing empathy with coherence and informativeness also proved difficult. Integrating NRC lexicons improved empathy scores (Table 2), but often reduced coherence, as seen in models like ChatGPT 4. This suggests that while LLMs can be tuned for emotional engagement, maintaining balance across metrics remains a challenge.\nAdditionally, some models showed good metric scores but failed to generate coherent responses, indicating a gap between quantitative metrics and actual performance. Llama"}, {"title": null, "content": "2, for example, generated multiple outputs for a single response on the NRC dataset, emphasizing the need for better context handling and response generation. Informativeness was particularly challenging, as models often sacrificed coherence and fluency to provide more detail. This underscores the need for advanced metrics that capture the nuances of empathy and coherence without compromising informativeness.\nThese findings underline the need for a more nuanced approach to integrating emotional embeddings in AI models for mental health applications. While emotional sensitivity is crucial, maintaining a balance of coherence and informativeness is essential to generate meaningful and supportive responses. This balance is particularly critical in therapeutic settings where logical consistency and clarity are as important as emotional resonance."}, {"title": "Conclusion", "content": "This study advances AI-driven psychotherapy by integrating emotion lexicons with state-of-the-art LLMs. While the results highlight significant improvements in empathy and contextual understanding, they also reveal critical challenges, particularly in balancing empathy with coherence and informativeness. The trade-offs observed in models such as Flan-T5 and ChatGPT 3.5 and the token limitations in Llama 2 13B underscore the complexity of developing emotionally intelligent AI systems. To address these challenges, model fine-tuning specifically for psychiatric use cases, with a balanced dataset, is recommended. Additionally, implementing long-context handling techniques and refining evaluation metrics to capture these models' nuanced performance better are essential steps forward. Future work should also focus on expanding the dataset to include more diverse emotional contexts and conducting human evaluations to gain deeper insights into the models' performance in real-world applications."}]}