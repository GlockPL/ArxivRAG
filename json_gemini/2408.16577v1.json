{"title": "Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning", "authors": ["Boyu Chen", "Junjie Liu", "Zhu Li", "Mengyue yang"], "abstract": "Learning representations with a high Probability of Necessary and Sufficient Causes (PNS) has been shown to enhance deep learning models' ability. This task involves identifying causal features that are both sufficient (guaranteeing the outcome) and necessary (without which the outcome cannot occur). However, current research predominantly focuses on unimodal data, and extending PNS learning to multimodal settings presents significant challenges. The challenges arise as the conditions for PNS identifiability-Exogeneity and Monotonicity-need to be reconsidered in a multimodal context, where sufficient and necessary causal features are distributed across different modalities. To address this, we first propose conceptualizing multimodal representations as comprising modality-invariant and modality-specific components. We then analyze PNS identifiability for each component, while ensuring non-trivial PNS estimation. Finally, we formulate tractable optimization objectives that enable multimodal models to learn high-PNS representations, thereby enhancing their predictive performance. Experiments demonstrate the effectiveness of our method on both synthetic and real-world data.", "sections": [{"title": "Introduction", "content": "Probability of Necessary and Sufficient Causes (PNS) measures the likelihood of a feature set being both necessary and sufficient for an outcome (Pearl 2009). Recently, PNS estimation has been successfully extended to guide representation learning in unimodal data, improving models' ability to capture the underlying causal information from data (Yang et al. 2024; Wang and Jordan 2021; Chen et al. 2024; Cai et al. 2024). However, applying PNS estimation to multimodal context remains underexplored, even though it is increasingly important to learn meaningful representations from diverse modalities (Xu et al. 2024; Liu et al. 2024b; Liang et al. 2024a,b; Swamy et al. 2024; Tang et al. 2024; Dong et al. 2023). The challenges in this application arise from the difficulty in satisfying two conditions for PNS identifiability: Exogeneity and Monotonicity.\nExogeneity requires causal features to be identifiable from observational data without influence from unmeasured confounders. In multimodal scenarios, inter-modal interactions can compromise this condition. Additionally, treating multimodal data as unimodal can violate Exogeneity, since the features may become unidentifiable without strong assumptions or additional supervision (Yang et al. 2024; Wang and Jordan 2021; Locatello et al. 2019; Liu et al. 2021).\nMonotonicity, on the other hand, implies that causal features monotonically influence outcome prediction. However, the intricate interactions in multimodal data could result in non-monotonic relationships. The high-dimensional, continuous nature of such data further complicates the assessment of consistent directional effects across modalities.\nTo address the challenges and extend PNS estimation into multimodal scenarios, we propose viewing multimodal hidden features as consisting of two components: modality-invariant contains shared information across different modalities, and modality-specific retains the unique characteristics of each modality (Zhang et al. 2019; Ramachandram and Taylor 2017; Guo, Wang, and Wang 2019; Gao et al. 2020; Li, Wang, and Cui 2023). Then, we derive how to satisfy PNS identifiability for them and introduce additional contraints for non-trivial PNS estimation. Using these insights, we design objective functions for learning high-PNS multimodal representations.\nOur contributions are: First, we introduce the concept of PNS in multimodal representation learning and analyze its associated challenges. Second, we propose considering multimodal features as two components and derive PNS estimation tailored for these components. Finally, we propose optimization objectives based on these findings to enhance multimodal representation learning. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of our method."}, {"title": "Related Works", "content": "Causal representation learning. Causal representation learning aims to identify underlying causal information from observational data (Sch\u00f6lkopf et al. 2021), which is crucial for enhancing the trustworthiness of machine learning tasks, particularly in explanation, generalization, and robustness (Arjovsky et al. 2019; Hu et al. 2018; Ahuja et al. 2020; Gamella and Heinze-Deml 2020). It mainly encompasses causal relationship discovery and causal feature learning. Causal relationship discovery (Peters et al. 2014; Zheng et al. 2018; Huang et al. 2020; Zhu, Ng, and Chen 2019) focuses on uncovering the causal structure among variables. On the other hand, causal feature learning (Zhang et al. 2020; Chen et al. 2022; Louizos et al. 2017; Yang et al. 2021; Lu et al. 2021) aims to extract features that have a causal relationship with the target outcome. To extract meaningful features, the PNS (Pearl 2009), proposed in Pearl's framework, serves as a powerful tool. By capturing causal features with high PNS values, learned representations can improve the stability and interpretability of deep learning models. Recognizing this potential, recent studies have explored PNS applications in causal feature learning, including learning invariant representations (Yang et al. 2024), identifying causally relevant features (Cai et al. 2024), and formulating efficient low-dimensional representations (Wang and Jordan 2021). However, they primarily focus on unimodal data, leaving the challenges of multimodal data unaddressed.\nMultimodal learning. Multimodal learning focuses on capturing meaningful representations from multiple modalities (Islam et al. 2023; Zhang, Kong, and Zhou 2023; Tran et al. 2024; Liu et al. 2024a). To achieve this, various methods have been developed to disentangle multimodal representations into modality-invariant and modality-specific parts (Shi et al. 2019; Tsai et al. 2018; Mai, Hu, and Xing 2020; Wang et al. 2017; Li, Wang, and Cui 2023).\nOur study bridges these two areas to address the challenges of applying PNS estimation in multimodality. We propose viewing multimodal representations as two components, derive how to compute non-trival PNS for them, and use the theoretical finding to design objective functions for learning high-PNS multimodal representations."}, {"title": "Problem Setup", "content": "Preliminaries\nLet $m\\in \\{1, ..., N \\}$ be the indicator for modality M, where N is the total number of modalities. For a modality m, $(X^m, Y)$ denotes a sample point, where $X^m \\subset \\mathbb{R}^{d_m}$ and $Y\\subset \\mathbb{R}^{d_y}$ represents feature and label variables, respectively. $d_m$ and $d_y$ represent the dimensionality of these vectors. A multimodal data point $(X, Y)$ includes all its samples presented in all modalities $(\\{X^m\\}_{M=1}^N, Y)$ and its specific instance is denoted as $(\\{x^m\\}_{m=1}^N,y)$.\nMultimodal representation learning commonly assumes that $(X, Y)$ consists of two distinct hidden representations: modality-invariant and modality-specific (Zhang et al. 2019; Ramachandram and Taylor 2017; Guo, Wang, and"}, {"title": "Probability of Necessary and Sufficient Cause", "content": "The PNS measures the likelihood of a feature set being both necessary and sufficient for an outcome. A feature is considered necessary if it is indispensable for causing an outcome, and sufficient if it alone can ensure the outcome.\nDefinition 1 (PNS (Pearl 2009)) Let Z be the causal features of outcome Y. z and z are two different implementations of Z. The PNS of Z with respect to Y on z and z is defined as:\n$PNS(z, z) :=\nP(Y_{do(Z=z)} = y|Z = z,Y \\neq y)P(Z = z,Y \\neq y)\n+ P(Y_{do(Z=z)} \\neq y|Z = z,Y = y)P(Z = z,Y = y)$\nThe counterfactual probability $P(Y_{do(Z=z)} = y | Z = z, Y \\neq y)$ represents the likelihood of $Y = y$ when we force the manipulable variable Z to be a fixed value $do(Z = z)$ (do-operator) given a certain factual observation $Z = z$ and $Y\\neq y$. This also applies to the other counterfactual probability $P(Y_{do(Z=\\bar{z})} \\neq y|Z = z,Y = y)$. The first and second terms in PNS correspond to the probabilities of sufficiency and necessity, respectively. A high PNS value indicates that the set of features Z has a high probability of being both necessary and sufficient for the outcome Y.\nComputing counterfactual probabilities is challenging due to the difficulty or impossibility of collecting counterfactual data in real-world scenarios. Fortunately, PNS defined on counterfactual distribution can be estimated by the data when Exogeneity and Monotonicity are satisfied.\nDefinition 2 (Exogeneity (Pearl 2009)) Z is exogenous to Y if the intervention probability is identified by conditional probability: $P(Y_{do(Z=z)} = y) = P(Y = y | Z = z)$.\nDefinition 3 (Monotonicity (Pearl 2009)) Y is monotonic to Z if and only if either: $P(Y_{do(Z=z)} = y)P(Y_{do(Z=z)} \\neq y) = 0$ or $P(Y_{do(Z=z)} \\neq y)P(Y_{do(Z=z)} = y) = 0$.\nLemma 1 ((Pearl 2009)) If Z is exogenous relative to Y, and Y is monotonic relative to Z, then:\n$PNS(z, z) =P(Y = y | do(Z = z))\n- P(Y = y | do(Z = z))\n=P(Y = y | Z = z) \u2013 P(Y = y | Z = z)$  (1)\nTo ensure interpretable representations in PNS calculation, we assume that minor perturbations to the causal feature preserve their semantic meaning. Specifically, we define Z as \u03b4-Semantic Separable relative to Y if it satisfies:\nAssumption 1 (\u03b4-Semantic Separability) for implementations z and z of Z, there exist \u03b4 > 0, where $||z - \\bar{z}||_2 > \u03b4$."}, {"title": "Multimodal Representation Disentanglement", "content": "Multimodal representation disentanglement, which we refer to as the disentangling approach, aims to separate multimodal data into two distinct types of representations (Shi et al. 2019; Tsai et al. 2018; Mai, Hu, and Xing 2020; Wang et al. 2017; Li, Wang, and Cui 2023). It extracts modality-invariant representation $R^I \\subset \\mathbb{R}^{d_{Z_I}}$ and modality-specific representation $R^S \\subset \\mathbb{R}^{d_{Z_S}}$ from a given $X^m$, which correspond closely to the underlying invariant $Z_I$ and specific $Z_S$ components, respectively. A disentangling approach (top-left in fig. 2) mainly consists of three parts:\n1) Feature Extractor \u03a6(\u00b7) disentangles input $X^m$ into two types of representations:\n$[R_I^m, R_S^m] := \\Phi(X^m)$\n2) Predictors utilize the representations to predict the outcome Y. The main predictor $F_P(\\cdot)$ employs all representations $P = [R_I^1,R_S^1,..., R_I^M,R_S^M]$ to predict Y. During training, some disentangling approaches incorporate auxiliary predictors $(F_m(\\cdot)$ and $\\bar{F}_m(\\cdot))$ to predict Y based on individual representation types, helping to infuse outcome-related information into the representations. For instance, in fig. 2, $F_1^I(R_1^I)$ is utilized to predict Y.\n3) Additional module(s) enhance the learning process. These modules can vary depending on the specific approach. For instance, knowledge distillation can be used in disentangling process to enhance the performance of representation learning (Li, Wang, and Cui 2023)."}, {"title": "PNS in Multimodality", "content": "To address the challenges of calculating PNS for multimodal data, we propose decomposing each sample into modality-invariant ($Z_I$) and modality-specific ($Z_S$) hidden variables. We then derive how to compute non-trival PNS for each component separately.\nPNS for Modality-Invariant Variables\nBased on eq. (1), PNS of $Z_I$ is estimated based on:\n$PNS_I(z, z) :=P(Y = y | do(Z_I = z))\n\u2013 P(Y = y | do(Z_I = z))$  (2)\nThis equation involves intervening on $Z_I$ while keeping the modality-specific part unchanged. The intervention probability term $P(Y = y | do(Z_I = z))$ represents the probability of outcome Y = y when $Z_I$ is set to z. It can be estimated by evaluation function $P(Y = y | Z_I = z, M = m)$ due to the following equation:\n$P(Y = y | do(Z_I = z)) =\n\\sum_mP(Y = y | do(Z_I = z), M = m)P(M = m)dm$ (3)\n$P(Y = y | Z_I = z,M = m)$ can be estimated by observational samples of $(X^m, Y)$ from the same modality m. These samples naturally contain variations in $Z_I$ while keeping the modality-specific part unchanged, inherently satisfying Exogeneity as $P(Y = y | do(Z_I = z), M = m) =\nP(Y = y | Z_I = z, M = m)$. This also applies to estimate $P(Y = y | do(Z_I = \\bar{z}))$.\nBy considering multimodal representation as comprising two components, we find the modality-invariant component naturally satisfies Exogeneity. If Monotonicity also holds, PNS of $Z_I$ can be estimate based on observational data. Constraints for Monotonicity are designed during the learning process, which will be discussed in the following section.\nPNS for Modality-Specific Variables\nSimilarly, PNS of $Z_S$ is estimated based on:\n$PNS_S(z, z) :=P(Y = y | do(Z_S = z))\n- P(Y = y | do(Z_S = z))$  (4)\nTo estimate the intervention term $P(Y = y | do(Z_S = z))$ and $P(Y = y | do(Z_S = \\bar{z}))$, similar to the analysis process in eq. (3), we need to collect data samples that allow us to identify the intervention probability. We use a multimodal sample $(\\{x^m\\}_{m=1}^N,y)$ that includes the same modality-invariant value presented in all possible modalities. However, the dataset only indicates $P(Y = y|do(M = m))$, which intervenes on modality M, not on modality-specific variable $Z_S$. This only allows us to obtain:\n$PNS_M (m, m) :=P(Y = y | do(M = m))\nN\n- P(Y = y | do(M = m)) = 0$ (5)\nThe equation equals to zero as different $x^m$ in $(\\{x^m\\}_{m=1}^N,y)$ has same y. We further decompose the intervention term $P(Y = y | do(M = m))$ by front criteria (Pearl 2009):\n$P(Y = y | do(M = m)) =\n\\int P(Y = y, Z_S = z | do(M = m))dz\n=\\int P(Y = y | do(Z_S = z))P(Z_S = z | do(M = m))dz$ (6)\nGiven that the observational data indicates $P(Y = y | do(M = m)) = P(Y = y | M = m)$, the term $P(Y = y | do(Z_S = z))P(Z_S = z | do(M = m))$ can be estimated. This also applies to estimate $P(Y = y | do(M = m))$.\nWe can regard $P(Y = y | do(Z_S = z))$ and $P(Z_S = z | do(M = m))$ as predictor and feature inference, respectively. Based on eq. (5) and eq. (6), calculating non-trivial $PNS(z, z) \\neq 0$ (eq. (4)) requires:\n$P(Z_S = z | do(M = m)) \\neq P(Z_S = z | do(M = m))$\nwhich can be translated to learn the mapping $F : \\mathbb{R}^{d_{Z_S}} \\rightarrow \\mathbb{R}^{d_{y}}$ to select the features that ensure:\n$P(F(z|m) \\neq F(z|\\bar{m})) > 0$ (7)\nThis constraint is crucial for estimating a non-trivial $PNS_S(z, z)$ from multimodal observational data, where directly satisfying Exogeneity and Monotonicity is difficult."}, {"title": "Multimodal Representation Learning via PNS", "content": "Building upon our theoretical findings, we aims to obtain modality-invariant representation $R_I^m$ and modality-specific representation $R_S^m$ with high PNS values. Our approach begins by utilizing an existing disentanglement technique to extract both representations. Following this, we design objective functions that encourage learning each representation with a high PNS value while implementing constraints to ensure non-trivial PNS estimation.\nComplement Representation\nTo evaluate PNS for multimodal representations as outlined in eq. (2) and eq. (4), we need to obtain the complement $\\bar{z}$ for feature value z of Z. This means finding complement modality-invariant representation $C_I^m \\subset \\mathbb{R}^{d_{Z_I}}$ for $R_I^m$ and complement modality-specific representation $C_S^m \\subset \\mathbb{R}^{d_{Z_S}}$ for $R_S^m$. Both $C_I^m$ and $C_S^m$ should maintain similar properties to $R_I^m$ and $R_S^m$, respectively, while leading to different outcome predictions. For instance, if $F_m^I(R_I^m)$ predicts Y, then $\\bar{F}_m^I(C_I^m)$ should predict a label different from Y.\nHowever, it is difficult to directly obtain $C_I^m$ and $C_S^m$ in real-world scenario. To solve this problem, we propose using an complement extractor \u03c6 (bottom-left of fig. 2), which shares the same structure as \u03a6 but is a separate network. \u03c6 can learn the complement representations for $X^m$ as:\n$[C_I^m,C_S^m] := \\phi(X^m)$\nIn the training process, \u03c6 extracts $C_I^m$ and $C_S^m$ from $X^m$, and the auxiliary predictors are then trained to predict outcomes that differ from Y based on these complement representations. The rationale is to encourage the generation of complement representations through a process analogous to the original feature extraction, preserving the underlying data structure while introducing meaningful variations.\nPNS for Modality-Invariant Representation\nWe design the following objective to encourage $R_I^m$ having a high PNS value:\n$\\mathcal{L}_{m,I}^{cpns} := \\mathcal{L}_{m,I}^{pred} + \\mathcal{L}_{m,I}^{cf} + \\mathcal{L}^{constr}$  (8)\n$\\mathcal{L}_{m,I}^{pred}$ is defined as $\\mathcal{L}_{pred}(Y, F_m^I(R_I^m))$, where $\\mathcal{L}_{pred}$ is a loss function that increases as $F_m^I(R_I^m)$ deviates from Y. Optimizing $\\mathcal{L}_{m,I}^{pred}$ increases the probability of the prediction being close to Y when the modality-invariant representation is set to $R_I^m$. This aims to encourage representation to capture a high $P(Y = y | do(Z_I = z))$ in eq. (2).\n$\\mathcal{L}_{m,I}^{cf}$ is defined as $\\mathcal{L}_{cf}(Y, \\bar{F}_m^I(C_I^m))$, where $\\mathcal{L}_{cf}$ is a loss function that increases when $\\bar{F}_m^I(C_I^m)$ is close to Y. Optimizing $\\mathcal{L}_{m,I}^{cf}$ decreases the probability of the prediction being close to Y when the modality-invariant representation is set to $C_I^m$. This helps learn representations that capture a low value for $P(Y = y | do(Z_I = \\bar{z}))$ in eq. (2).\nThe specific implementations of $\\mathcal{L}_{pred}$ and $\\mathcal{L}_{cf}$ may vary depending on different scenarios. We will detail our implementation in the experiment section. Together, optimizing $\\mathcal{L}_{m,I}^{pred} + \\mathcal{L}_{m,I}^{cf}$ represents the process of improving the PNS in eq. (2).\n$\\mathcal{L}^{constr}$ serves as a Monotonicity constraint, defined as $\\mathcal{L}^{constr} = \\mathcal{L}_{pred}(Y, F_m^I(R_I^m)) * \\mathcal{L}_{cf}(Y, \\bar{F}_m^I(C_I^m))$. Optimizing this term encourages representations to satisfy"}, {"title": "Experiment", "content": "We evaluate MRLNS using both synthetic and real-world datasets. First, we employ synthetic datasets to show that MRLNS can obtain representations with high PNS values. Then, we utilize real-world datasets to demonstrate MRLNS's ability to enhance the performance of its adapted disentangling approach. All experiments are conducted on a Linux system with an NVIDIA Tesla V100 PCIe GPU.\nSynthetic Dataset Experiments\nOur synthetic dataset experiment aims to demonstrate MRLNS's effectiveness in learning essential information (sufficient and necessary causes) from multimodal data. We adapt the data generation and evaluation process from (Yang et al. 2024). This process involves generating deterministic variables that directly determine the outcome, along with other variables, which are then mixed. Subsequently, representations are extracted from these mixed variables by a neural network to predict outcomes. For evaluation, we use Distance Correlation (Jones, Forrest et al. 1995) to measure how well each type of variable is captured in the learned representations. Higher correlation values indicate more relevant information captured. As deterministic variables directly influence the outcome, they possess high PNS. Consequently, a method achieving high distance correlation between deterministic variables and representations can effectively captures essential, high-PNS information.\nGenerating the Synthetic Dataset. We generate a synthetic dataset based on four types of variables. These variables are used to construct a two-modality sample and its corresponding label. The variables are generated as follows:\nSufficient and Necessary (SN) cause variable $s_n$ is the deterministic variable and generated from a Bernoulli distribution B(0.5), with probability of 0.5 to be 1. It directly determines the label Y through the relationship $Y = s_n \\oplus B(0.15)$, where \u2295 is the XOR operation.\nSufficient and Unnecessary (SF) cause variable $s_f$ is generated by transforming $s_n$. When $s_n = 0, s_f = B(0.1)$, and when $s_n = 1, s_f = s_n$.\nInsufficient and Necessary (NC) cause variable $n_c$ is generated as $I(s_n = 1) \\cdot B(0.9)$, where $I(\\cdot)$ is indicator function.\nSpurious correlation (SC) variable $s_c$ is generated to have a spurious correlation with the SN cause, defined as $s \\cdot s_n + (1 - s)N(0,1)$, where $s \\in [0,1)$ is the degree of spurious correlation and N(0, 1) denotes the standard Gaussian distribution.\nBased on these variables, we construct a feature vector $h = [s_n \\cdot 1_d, s_f \\cdot 1_d, n_c \\cdot 1_d, s_p \\cdot 1_d] + N(0,0.3)$, where $1_d$ is a d-dimensional vector of ones and d is set to 7. Following fig. 1, we create synthetic multimodal data with modality-invariant and modality-specific components. The first 3 elements of each variable serve as the modality-invariant component. For modality-specific features, we allocate the next 2 elements to modality 1 and the last 2 to modality 2. We then form temporary feature vectors $h^1$ and $h^2$ for each modality by combining the invariant component with their respective specific elements. To introduce varying"}, {"title": "PNS for Modality-Specific Representation", "content": "Similar to eq. (8), to encourage $R_S^m$ to have a high PNS value, we formulate the objective:\n$\\mathcal{L}_{m,S}^{cpns} := \\mathcal{L}_{m,S}^{pred} + \\mathcal{L}_{m,S}^{cf} + \\mathcal{L}^{constr}$  (9)\n$\\mathcal{L}_{m,S}^{pred}$ and $\\mathcal{L}_{m,S}^{cf}$ are similar to $\\mathcal{L}_{m,I}^{pred}$ and $\\mathcal{L}_{m,I}^{cf}$ in eq. (8). They are set as $\\mathcal{L}_{pred}(Y, F_m^S(R_S^m))$ and $\\mathcal{L}_{cf}(Y, \\bar{F}_m^S(C_S^m))$, respectively.\nTo obtain non-trival PNS, we design the constraint term $\\mathcal{L}^{constr} = \\mathcal{L}_{cf}(F(R_S^m), F(C_S^{\\bar{m}}))$, where $m \\neq \\bar{m}$. Optimizing this term aims to increase $P(F(z|m) \\neq F(z|\\bar{m}))$ in eq. (7) as this probability increase as $F_m(R_S^m)$ deviates from $F_m^S(C_S^{\\bar{m}})$. This aims to encourage the non-trival PNS estimation. $C_S^{\\bar{m}}$ is generated by $\\phi(X^{\\bar{m}})$, where $X^m$ and $X^{\\bar{m}}$ are different modalities of the same multimodal data X.\nMultimodal Representation Learning via\nNecessary and Sufficient Causes\nWe want the disentangling approach to learn representations with high PNS values, by optimizing the overall loss:\n$\\mathcal{L}^{total} := \\mathcal{L}^{task} + \\sum_{m=1}^N(\\mathcal{L}_{m,I}^{cpns} + \\mathcal{L}_{m,S}^{cpns})$ (10)\n$\\mathcal{L}^{cpns} = \\sum_{m=1}^N \\sum_{i \\in \\{I,S\\}}(\\mathcal{L}_{m,i}^{pred} + \\mathcal{L}_{m,i}^{cf})$\n$\\mathcal{L}^{constr} = \\sum_{m=1}^N (\\mathcal{L}^{constr} + \\mathcal{L}^{constr})$\nWe define $\\mathcal{L}^{cpns} = \\sum_{i \\in \\{I,S\\}}\\mathcal{L}_{m,i}^{cpns}$ as PNS loss term, and $\\mathcal{L}^{constr} = \\sum_{i \\in \\{I,S\\}}\\mathcal{L}^{constr}$ as constraint loss term. $\\mathcal{L}^{task}$ is the loss for the original task of the disentangling approach. For example, it could include $\\mathcal{L}_{pred}(Y, F_P(P))$ in the multimodal prediction task.\nWe name our algorithm for optimizing $\\mathcal{L}^{total}$ as MRLNS (Multimodal Representation Learning via Necessity and Sufficiency Causes). It builds upon an existing disentangling approach, adapting this approach to optimize $\\mathcal{L}^{total}$ instead of the original $\\mathcal{L}^{task}$. This adaptation involves using an complement extractor, which could be the network that mirrors the structure of the disentangling approach's feature extractor, to generate complement representations. Then, these representations, along with the original ones, are fed into auxiliary predictors (created if not present in the chosen disentangling approach) to optimize $\\mathcal{L}^{cpns} + \\mathcal{L}^{constr}$. During training, all components - including the feature extractor, complement extractor, predictors, and other parts of the chosen disentangling approach are optimized. Once training is complete, the complement extractor and auxiliary predictors are discarded, leaving the trained disentangling approach ready for use, as illustrated in the top-right of fig. 2."}, {"title": "Experiment", "content": "We evaluate MRLNS using both synthetic and real-world datasets. First, we employ synthetic datasets to show that MRLNS can obtain representations with high PNS values. Then, we utilize real-world datasets to demonstrate MRLNS's ability to enhance the performance of its adapted disentangling approach. All experiments are conducted on a Linux system with an NVIDIA Tesla V100 PCIe GPU.\nSynthetic Dataset Experiments\nOur synthetic dataset experiment aims to demonstrate MRLNS's effectiveness in learning essential information (sufficient and necessary causes) from multimodal data. We adapt the data generation and evaluation process from (Yang et al. 2024). This process involves generating deterministic variables that directly determine the outcome, along with other variables, which are then mixed. Subsequently, representations are extracted from these mixed variables by a neural network to predict outcomes. For evaluation, we use Distance Correlation (Jones, Forrest et al. 1995) to measure how well each type of variable is captured in the learned representations. Higher correlation values indicate more relevant information captured. As deterministic variables directly influence the outcome, they possess high PNS. Consequently, a method achieving high distance correlation between deterministic variables and representations can effectively captures essential, high-PNS information.\nGenerating the Synthetic Dataset. We generate a synthetic dataset based on four types of variables. These variables are used to construct a two-modality sample and its corresponding label. The variables are generated as follows:\nSufficient and Necessary (SN) cause variable $s_n$ is the deterministic variable and generated from a Bernoulli distribution B(0.5), with probability of 0.5 to be 1. It directly determines the label Y through the relationship $Y = s_n \\oplus B(0.15)$, where \u2295 is the XOR operation.\nSufficient and Unnecessary (SF) cause variable $s_f$ is generated by transforming $s_n$. When $s_n = 0, s_f = B(0.1)$, and when $s_n = 1, s_f = s_n$.\nInsufficient and Necessary (NC) cause variable $n_c$ is generated as $I(s_n = 1) \\cdot B(0.9)$, where $I(\\cdot)$ is indicator function.\nSpurious correlation (SC) variable $s_c$ is generated to have a spurious correlation with the SN cause, defined as $s \\cdot s_n + (1 - s)N(0,1)$, where $s \\in [0,1)$ is the degree of spurious correlation and N(0, 1) denotes the standard Gaussian distribution.\nBased on these variables, we construct a feature vector $h = [s_n \\cdot 1_d, s_f \\cdot 1_d, n_c \\cdot 1_d, s_p \\cdot 1_d] + N(0,0.3)$, where $1_d$ is a d-dimensional vector of ones and d is set to 7. Following fig. 1, we create synthetic multimodal data with modality-invariant and modality-specific components. The first 3 elements of each variable serve as the modality-invariant component. For modality-specific features, we allocate the next 2 elements to modality 1 and the last 2 to modality 2. We then form temporary feature vectors $h^1$ and $h^2$ for each modality by combining the invariant component with their respective specific elements. To introduce varying"}, {"title": "PNS for Modality-Specific Representation", "content": "Similar to eq. (8)", "objective": "n$\\mathcal{L"}, {"m,S}^{cpns}": "mathcal{L"}, {"loss": "n$\\mathcal{L"}, {"total}": "mathcal{L}^{task} + \\sum_{m=1}^N(\\mathcal{L}_{m,I}^{cpns} + \\mathcal{L}_{m,S}^{cpns})$ (10)\n$\\mathcal{L}^{cpns} = \\sum_{m=1}^N \\sum_{i \\in \\{I,S\\}}(\\mathcal{L}_{m,i}^{pred} + \\mathcal{L}_{m,i}^{cf})$\n$\\mathcal{L}^{constr} = \\sum_{m=1}^N (\\mathcal{L}^{constr} + \\mathcal{L}^{constr})$\nWe define $\\mathcal{L}^{cpns} = \\sum_{i \\in \\{I,S\\}}\\mathcal{L}_{m,i}^{cpns}$ as PNS loss term, and $\\mathcal{L}^{constr} = \\sum_{i \\in \\{I,S\\}}\\mathcal{L}^{constr}$ as constraint loss term. $\\mathcal{L}^{task}$ is the loss for"}]}