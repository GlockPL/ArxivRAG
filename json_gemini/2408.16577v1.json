{"title": "Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning", "authors": ["Boyu Chen", "Junjie Liu", "Zhu Li", "Mengyue yang"], "abstract": "Learning representations with a high Probability of Necessary and Sufficient Causes (PNS) has been shown to enhance deep learning models' ability. This task involves identifying causal features that are both sufficient (guaranteeing the outcome) and necessary (without which the outcome cannot occur). However, current research predominantly focuses on unimodal data, and extending PNS learning to multimodal settings presents significant challenges. The challenges arise as the conditions for PNS identifiability-Exogeneity and Monotonicity-need to be reconsidered in a multimodal context, where sufficient and necessary causal features are distributed across different modalities. To address this, we first propose conceptualizing multimodal representations as comprising modality-invariant and modality-specific components. We then analyze PNS identifiability for each component, while ensuring non-trivial PNS estimation. Finally, we formulate tractable optimization objectives that enable multimodal models to learn high-PNS representations, thereby enhancing their predictive performance. Experiments demonstrate the effectiveness of our method on both synthetic and real-world data.", "sections": [{"title": "Introduction", "content": "Probability of Necessary and Sufficient Causes (PNS) measures the likelihood of a feature set being both necessary and sufficient for an outcome (Pearl 2009). Recently, PNS estimation has been successfully extended to guide representation learning in unimodal data, improving models' ability to capture the underlying causal information from data (Yang et al. 2024; Wang and Jordan 2021; Chen et al. 2024; Cai et al. 2024). However, applying PNS estimation to multimodal context remains underexplored, even though it is increasingly important to learn meaningful representations from diverse modalities (Xu et al. 2024; Liu et al. 2024b; Liang et al. 2024a,b; Swamy et al. 2024; Tang et al. 2024; Dong et al. 2023). The challenges in this application arise from the difficulty in satisfying two conditions for PNS identifiability: Exogeneity and Monotonicity.\nExogeneity requires causal features to be identifiable from observational data without influence from unmeasured confounders. In multimodal scenarios, inter-modal interactions can compromise this condition. Additionally, treating multimodal data as unimodal can violate Exogeneity, since the features may become unidentifiable without strong assumptions or additional supervision (Yang et al. 2024; Wang and Jordan 2021; Locatello et al. 2019; Liu et al. 2021).\nMonotonicity, on the other hand, implies that causal features monotonically influence outcome prediction. However, the intricate interactions in multimodal data could result in non-monotonic relationships. The high-dimensional, continuous nature of such data further complicates the assessment of consistent directional effects across modalities.\nTo address the challenges and extend PNS estimation into multimodal scenarios, we propose viewing multimodal hidden features as consisting of two components: modality-invariant contains shared information across different modalities, and modality-specific retains the unique characteristics of each modality (Zhang et al. 2019; Ramachandram and Taylor 2017; Guo, Wang, and Wang 2019; Gao et al. 2020; Li, Wang, and Cui 2023). Then, we derive how to satisfy PNS identifiability for them and introduce additional contraints for non-trivial PNS estimation. Using these insights, we design objective functions for learning high-PNS multimodal representations.\nOur contributions are: First, we introduce the concept of PNS in multimodal representation learning and analyze its associated challenges. Second, we propose considering multimodal features as two components and derive PNS estimation tailored for these components. Finally, we propose optimization objectives based on these findings to enhance multimodal representation learning. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of our method."}, {"title": "Related Works", "content": "Causal representation learning. Causal representation learning aims to identify underlying causal information from observational data (Sch\u00f6lkopf et al. 2021), which is crucial for enhancing the trustworthiness of machine learning tasks, particularly in explanation, generalization, and robustness (Arjovsky et al. 2019; Hu et al. 2018; Ahuja et al. 2020; Gamella and Heinze-Deml 2020). It mainly encompasses causal relationship discovery and causal feature learning. Causal relationship discovery (Peters et al. 2014; Zheng et al. 2018; Huang et al. 2020; Zhu, Ng, and Chen 2019)"}, {"title": "Problem Setup", "content": "Preliminaries\nLet $m \\in \\{1, ..., N \\}$ be the indicator for modality $M$, where $N$ is the total number of modalities. For a modality $m$, $(X, Y)$ denotes a sample point, where $X^m \\subset \\mathbb{R}^{d_m}$ and $Y \\subset \\mathbb{R}^{d_Y}$ represents feature and label variables, respectively. $d_m$ and $d_y$ represent the dimensionality of these vectors. A multimodal data point $(X, Y)$ includes all its samples presented in all modalities $(\\{X^m\\}_{M=1}^N, Y)$ and its specific instance is denoted as $(\\{x^m\\}_{m=1}^N, y)$.\nMultimodal representation learning commonly assumes that $(X, Y)$ consists of two distinct hidden representations: modality-invariant and modality-specific (Zhang et al. 2019; Ramachandram and Taylor 2017; Guo, Wang, and"}, {"title": "Probability of Necessary and Sufficient Cause", "content": "The PNS measures the likelihood of a feature set being both necessary and sufficient for an outcome. A feature is considered necessary if it is indispensable for causing an outcome, and sufficient if it alone can ensure the outcome.\nDefinition 1 (PNS (Pearl 2009)) Let $Z$ be the causal features of outcome $Y$. $z$ and $\\bar{z}$ are two different implementations of $Z$. The PNS of $Z$ with respect to $Y$ on $z$ and $\\bar{z}$ is defined as:\n$PNS(z, \\bar{z}) :=\nP(Y_{do(Z=z)} = y|Z = z,Y \\neq y)P(Z = z,Y \\neq y) \\\\\n+ P(Y_{do(Z=\\bar{z})} \\neq y|Z = \\bar{z},Y = y)P(Z = \\bar{z},Y = y)$\nThe counterfactual probability $P(Y_{do(Z=z)} = y | Z = z, Y \\neq y)$ represents the likelihood of $Y = y$ when we force the manipulable variable $Z$ to be a fixed value $do(Z = z)$ (do-operator) given a certain factual observation $Z = z$ and $Y\\neq y$. This also applies to the other counterfactual probability $P(Y_{do(Z=\\bar{z})} \\neq y|Z = \\bar{z},Y = y)$. The first and second terms in PNS correspond to the probabilities of sufficiency and necessity, respectively. A high PNS value indicates that the set of features $Z$ has a high probability of being both necessary and sufficient for the outcome $Y$.\nComputing counterfactual probabilities is challenging due to the difficulty or impossibility of collecting counterfactual data in real-world scenarios. Fortunately, PNS defined on counterfactual distribution can be estimated by the data when Exogeneity and Monotonicity are satisfied.\nDefinition 2 (Exogeneity (Pearl 2009)) $Z$ is exogenous to $Y$ if the intervention probability is identified by conditional probability: $P(Y_{do(Z=z)} = y) = P(Y = y | Z = z)$.\nDefinition 3 (Monotonicity (Pearl 2009)) $Y$ is monotonic to $Z$ if and only if either: $P(Y_{do(Z=z)} = y)P(Y_{do(Z=z)} \\neq y) = 0$ or $P(Y_{do(Z=z)} \\neq y)P(Y_{do(Z=z)} = y) = 0$.\nLemma 1 ((Pearl 2009)) If $Z$ is exogenous relative to $Y$, and $Y$ is monotonic relative to $Z$, then:\n$PNS(z, \\bar{z}) =P(Y = y | do(Z = z)) \\\\\n\u2013 P(Y = y | do(Z = \\bar{z})) \\\\\n=P(Y = y | Z = z) \u2013 P(Y = y | Z = \\bar{z})$\nTo ensure interpretable representations in PNS calculation, we assume that minor perturbations to the causal feature preserve their semantic meaning. Specifically, we define $Z$ as $\\delta$-Semantic Separable relative to $Y$ if it satisfies:\nAssumption 1 (\u03b4-Semantic Separability) for implementations $z$ and $\\bar{z}$ of $Z$, there exist $\\delta > 0$, where $||z - \\bar{z}||_2 > \\delta$."}, {"title": "Multimodal Representation Disentanglement", "content": "Multimodal representation disentanglement, which we refer to as the disentangling approach, aims to separate multimodal data into two distinct types of representations (Shi et al. 2019; Tsai et al. 2018; Mai, Hu, and Xing 2020; Wang et al. 2017; Li, Wang, and Cui 2023). It extracts modality-invariant representation $R_I \\subset \\mathbb{R}^{d_{Z_I}}$ and modality-specific representation $R_S \\subset \\mathbb{R}^{d_{Z_S}}$ from a given $X^m$, which correspond closely to the underlying invariant $Z_I$ and specific $Z_S$ components, respectively. A disentangling approach (top-left in fig. 2) mainly consists of three parts:\n1) Feature Extractor $\\Phi(\\cdot)$ disentangles input $X^m$ into two types of representations:\n$[R_I^m, R_S^m] := \\Phi(X^m)$\n2) Predictors utilize the representations to predict the outcome $Y$. The main predictor $F_P(\\cdot)$ employs all representations $P = [R_I^1, R_S^1, ..., R_I^m, R_S^m, ..., R_I^N, R_S^N]$ to predict $Y$. During training, some disentangling approaches incorporate auxiliary predictors $(F_I(\\cdot)$ and $F_S(\\cdot))$ to predict $Y$ based on individual representation types, helping to infuse outcome-related information into the representations. For instance, in fig. 2, $F_I^1(R_I^1)$ is utilized to predict $Y$.\n3) Additional module(s) enhance the learning process. These modules can vary depending on the specific approach. For instance, knowledge distillation can be used in disentangling process to enhance the performance of representation learning (Li, Wang, and Cui 2023)."}, {"title": "PNS in Multimodality", "content": "To address the challenges of calculating PNS for multimodal data, we propose decomposing each sample into modality-invariant ($Z_I$) and modality-specific ($Z_S$) hidden variables. We then derive how to compute non-trival PNS for each component separately."}, {"title": "PNS for Modality-Invariant Variables", "content": "Based on eq. (1), PNS of $Z_I$ is estimated based on:\n$PNS_I(z, \\bar{z}) :=P(Y = y | do(Z_I = z)) \\\\\n\u2013 P(Y = y | do(Z_I = \\bar{z}))$\nThis equation involves intervening on $Z_I$ while keeping the modality-specific part unchanged. The intervention probability term $P(Y = y | do(Z_I = z))$ represents the probability of outcome $Y = y$ when $Z_I$ is set to $z$. It can be estimated by evaluation function $P(Y = y | Z_I = z, M = m)$ due to the following equation:\n$P(Y = y | do(Z_I = z)) = \\sum_m\nP(Y = y | do(Z_I = z), M = m)P(M = m)dm$\n$P(Y = y | Z_I = z,M = m)$ can be estimated by observational samples of $(X^m, Y)$ from the same modality $m$. These samples naturally contain variations in $Z_I$ while keeping the modality-specific part unchanged, inherently satisfying Exogeneity as $P(Y = y | do(Z_I = z), M = m) = P(Y = y | Z_I = z, M = m)$. This also applies to estimate $P(Y = y | do(Z_I = \\bar{z}))$.\nBy considering multimodal representation as comprising two components, we find the modality-invariant component naturally satisfies Exogeneity. If Monotonicity also holds, PNS of $Z_I$ can be estimate based on observational data. Constraints for Monotonicity are designed during the learning process, which will be discussed in the following section."}, {"title": "PNS for Modality-Specific Variables", "content": "Similarly, PNS of $Z_S$ is estimated based on:\n$PNS_S(z, \\bar{z}) :=P(Y = y | do(Z_S = z)) \\\\\n- P(Y = y | do(Z_S = \\bar{z}))$\nTo estimate the intervention term $P(Y = y | do(Z_S = z))$ and $P(Y = y | do(Z_S = \\bar{z}))$, similar to the analysis process in eq. (3), we need to collect data samples that allow us to identify the intervention probability. We use a multimodal sample $(\\{x^m\\}_{m=1}^N, y)$ that includes the same modality-invariant value presented in all possible modalities. However, the dataset only indicates $P(Y = y|do(M = m))$, which intervenes on modality $M$, not on modality-specific variable $Z_S$. This only allows us to obtain:\n$PNS_M (z, \\bar{z}) :=P(Y = y | do(M = m)) \\\\\n- P(Y = y | do(M = m)) = 0$\nThe equation equals to zero as different $x^m$ in $(\\{x^m\\}_{m=1}^N, y)$ has same $y$. We further decompose the intervention term $P(Y = y | do(M = m))$ by front criteria (Pearl 2009):\n$P(Y = y | do(M = m)) = \\int\nP(Y = y, Z_S = z | do(M = m))dz = \\int\nP(Y = y | do(Z_S = z))P(Z_S = z | do(M = m))dz$\nGiven that the observational data indicates $P(Y = y | do(M = m)) = P(Y = y | M = m)$, the term $P(Y = y | do(Z_S = z))P(Z_S = z | do(M = m))$ can be estimated. This also applies to estimate $P(Y = y | do(M = m))$.\nWe can regard $P(Y = y | do(Z_S = z))$ and $P(Z_S = z | do(M = m))$ as predictor and feature inference, respectively. Based on eq. (5) and eq. (6), calculating non-trivial $PNS(z, \\bar{z}) \\neq 0$ (eq. (4)) requires:\n$P(Z_S = z | do(M = m)) \\neq P(Z_S = z | do(M = m))$\nwhich can be translated to learn the mapping $F: \\mathbb{R}^{d_{Z_S}} \\rightarrow \\mathbb{R}^{d_y}$ to select the features that ensure:\n$P(F(z|m) \\neq F(z|\\bar{m})) > 0$\nThis constraint is crucial for estimating a non-trivial $PNS_S(z, \\bar{z})$ from multimodal observational data, where directly satisfying Exogeneity and Monotonicity is difficult."}, {"title": "Multimodal Representation Learning via PNS", "content": "Building upon our theoretical findings, we aims to obtain modality-invariant representation $R_I^m$ and modality-specific representation $R_S^m$ with high PNS values. Our approach begins by utilizing an existing disentanglement technique to extract both representations. Following this, we design objective functions that encourage learning each representation with a high PNS value while implementing constraints to ensure non-trivial PNS estimation."}, {"title": "Complement Representation", "content": "To evaluate PNS for multimodal representations as outlined in eq. (2) and eq. (4), we need to obtain the complement $\\bar{z}$ for feature value $z$ of $Z$. This means finding complement modality-invariant representation $C_I^m \\subset \\mathbb{R}^{d_{Z_I}}$ for $R_I^m$ and complement modality-specific representation $C_S^m \\subset \\mathbb{R}^{d_{Z_S}}$ for $R_S^m$. Both $C_I^m$ and $C_S^m$ should maintain similar properties to $R_I^m$ and $R_S^m$, respectively, while leading to different outcome predictions. For instance, if $F_I^m(R_I^m)$ predicts $Y$, then $F_I^m(C_I^m)$ should predict a label different from $Y$.\nHowever, it is difficult to directly obtain $C_I^m$ and $C_S^m$ in real-world scenario. To solve this problem, we propose using an complement extractor $\\phi$ (bottom-left of fig. 2), which shares the same structure as $\\Phi$ but is a separate network. $\\phi$ can learn the complement representations for $X^m$ as:\n$[C_I^m, C_S^m] := \\phi(X^m)$\nIn the training process, $\\phi$ extracts $C_I^m$ and $C_S^m$ from $X^m$, and the auxiliary predictors are then trained to predict outcomes that differ from $Y$ based on these complement representations. The rationale is to encourage the generation of complement representations through a process analogous to the original feature extraction, preserving the underlying data structure while introducing meaningful variations."}, {"title": "PNS for Modality-Invariant Representation", "content": "We design the following objective to encourage $R_I^m$ having a high PNS value:\n$L_{m,I}^{cpns} := L_{m,I}^{pred} + L_{m,I}^{cf} + L_{m,I}^{constr}$\n$L_{m,I}^{pred}$ is defined as $L_{pred}(Y, F_I^m(R_I^m))$, where $L_{pred}$ is a loss function that increases as $F_I^m(R_I^m)$ deviates from $Y$. Optimizing $L_{m,I}^{pred}$ increases the probability of the prediction being close to $Y$ when the modality-invariant representation is set to $R_I^m$. This aims to encourage representation to capture a high $P(Y = y | do(Z_I = z))$ in eq. (2).\n$L_{m,I}^{cf}$ is defined as $L_{cf}(Y, F_I^m(C_I^m))$, where $L_{cf}$ is a loss function that increases when $F_I^m(C_I^m)$ is close to $Y$. Optimizing $L_{m,I}^{cf}$ decreases the probability of the prediction being close to $Y$ when the modality-invariant representation is set to $C_I^m$. This helps learn representations that capture a low value for $P(Y = y | do(Z_I = \\bar{z}))$ in eq. (2).\nThe specific implementations of $L_{pred}$ and $L_{cf}$ may vary depending on different scenarios. We will detail our implementation in the experiment section. Together, optimizing $L_{m,I}^{pred} + L_{m,I}^{cf}$ represents the process of improving the PNS in eq. (2).\n$L_{m,I}^{constr}$ serves as a Monotonicity constraint, defined as $L_{m,I}^{constr} = L_{pred}(Y, F_I^m(R_I^m)) * L_{cf}(Y, F_I^m(C_I^m))$. Optimizing this term encourages representations to satisfy"}, {"title": "PNS for Modality-Specific Representation", "content": "Similar to eq. (8), to encourage $R_S^m$ to have a high PNS value, we formulate the objective:\n$L_{m,S}^{cpns} := L_{m,S}^{pred} + L_{m,S}^{cf} + L_{m,S}^{constr}$\n$L_{m,S}^{pred}$ and $L_{m,S}^{cf}$ are similar to $L_{m,I}^{pred}$ and $L_{m,I}^{cf}$ in eq. (8). They are set as $L_{pred}(Y, F_S^m(R_S^m))$ and $L_{cf}(Y, F_S^m(C_S^m))$, respectively.\nTo obtain non-trival PNS, we design the constraint term $L_{m,S}^{constr} = L_{cf}(F^\\bar{m}(R_S^m), F^\\bar{m}(C_S^\\bar{m}))$, where $\\bar{m} \\neq m$. Optimizing this term aims to increase $P(F(z|m) \\neq F(z|\\bar{m}))$ in eq. (7) as this probability increase as $F^\\bar{m}(R_S^m)$ deviates from $F^\\bar{m}(C_S^\\bar{m})$. This aims to encourage the non-trival PNS estimation. $C_S^\\bar{m}$ is generated by $\\phi(X^\\bar{m})$, where $X^m$ and $X^\\bar{m}$ are different modalities of the same multimodal data $X$."}, {"title": "Multimodal Representation Learning via Necessary and Sufficient Causes", "content": "We want the disentangling approach to learn representations with high PNS values, by optimizing the overall loss:\n$L_{total} := L_{task} + \\sum_{m=1}^N(L_{m,I}^{cpns} + L_{m,S}^{cpns})$\n$L_{total}^{cpns} := L_{task} + L^{cpns} + L^{constr}$\nWe define $L^{cpns} = \\sum_{m=1}^N(\\sum_{i=I,S}(L_{m,i}^{pred} + L_{m,i}^{cf}))$ as PNS loss term, and $L^{constr} = \\sum_{m=1}^N(\\sum_{i=I,S}(L_{m,i}^{constr}))$ as constraint loss term. $L_{task}$ is the loss for the original task of the disentangling approach. For example, it could include $L_{pred}(Y, F_P([R_I^m, R_S^m]))$ in the multimodal prediction task.\nWe name our algorithm for optimizing $L_{total}$ as MRLNS (Multimodal Representation Learning via Necessity and Sufficiency Causes). It builds upon an existing disentangling approach, adapting this approach to optimize $L_{total}$ instead of the original $L_{task}$. This adaptation involves using an complement extractor, which could be the network that mirrors the structure of the disentangling approach's feature extractor, to generate complement representations. Then, these representations, along with the original ones, are fed into auxiliary predictors (created if not present in the chosen disentangling approach) to optimize $L^{cpns} + L^{constr}$. During training, all components - including the feature extractor, complement extractor, predictors, and other parts of the chosen disentangling approach are optimized. Once training is complete, the complement extractor and auxiliary predictors are discarded, leaving the trained disentangling approach ready for use, as illustrated in the top-right of fig. 2."}, {"title": "Experiment", "content": "We evaluate MRLNS using both synthetic and real-world datasets. First, we employ synthetic datasets to show that MRLNS can obtain representations with high PNS values. Then, we utilize real-world datasets to demonstrate MRLNS's ability to enhance the performance of its adapted disentangling approach. All experiments are conducted on a Linux system with an NVIDIA Tesla V100 PCIe GPU."}, {"title": "Synthetic Dataset Experiments", "content": "Our synthetic dataset experiment aims to demonstrate MRLNS's effectiveness in learning essential information (sufficient and necessary causes) from multimodal data. We adapt the data generation and evaluation process from (Yang et al. 2024). This process involves generating deterministic variables that directly determine the outcome, along with other variables, which are then mixed. Subsequently, representations are extracted from these mixed variables by a neural network to predict outcomes. For evaluation, we use Distance Correlation (Jones, Forrest et al. 1995) to measure how well each type of variable is captured in the learned representations. Higher correlation values indicate more relevant information captured. As deterministic variables directly influence the outcome, they possess high PNS. Consequently, a method achieving high distance correlation between deterministic variables and representations can effectively captures essential, high-PNS information."}, {"title": "Generating the Synthetic Dataset", "content": "We generate a synthetic dataset based on four types of variables. These variables are used to construct a two-modality sample and its corresponding label. The variables are generated as follows:\nSufficient and Necessary (SN) cause variable $sn$ is the deterministic variable and generated from a Bernoulli distribution $B(0.5)$, with probability of 0.5 to be 1. It directly determines the label $Y$ through the relationship $Y = sn \\oplus B(0.15)$, where $\\oplus$ is the XOR operation.\nSufficient and Unnecessary (SF) cause variable $sf$ is generated by transforming $sn$. When $sn = 0$, $sf = B(0.1)$, and when $sn = 1$, $sf = sn$.\nInsufficient and Necessary (NC) cause variable $nc$ is generated as $I(sn = 1) \\cdot B(0.9)$, where $I(\\cdot)$ is indicator function.\nSpurious correlation (SC) variable $sc$ is generated to have a spurious correlation with the SN cause, defined as $s\\cdot sn + (1 \u2212 s)\\mathcal{N}(0, 1)$, where $s \\in [0,1)$ is the degree of spurious correlation and $\\mathcal{N}(0, 1)$ denotes the standard Gaussian distribution.\nBased on these variables, we construct a feature vector $h = [sn\\cdot 1_d, sf \\cdot 1_d, nc \\cdot 1_d, sp\\cdot 1_d] + \\mathcal{N}(0,0.3)$, where $1_d$ is a d-dimensional vector of ones and $d$ is set to 7. Following fig. 1, we create synthetic multimodal data with modality-invariant and modality-specific components. The first 3 elements of each variable serve as the modality-invariant component. For modality-specific features, we allocate the next 2 elements to modality 1 and the last 2 to modality 2. We then form temporary feature vectors $h^1$ and $h^2$ for each modality by combining the invariant component with their respective specific elements. To introduce varying"}, {"title": "Results and Discussion", "content": "The disentangling approach (denoted as Net) is trained by optimizing only $L_{task}$ in eq. (10), while MRLNS is trained based on this approach by optimizing $L_{total}$ in eq. (10). To evaluate their performance, for modality 1, we compute the distance correlation between the extracted representation $[R_I^1, R_S^1]$ and each variable type (SN, SF, NC, and SC) in $X^1$. Similarly, for modality 2, we use $[R_I^2, R_S^2]$ and variables in $X^2$. To show the effect of constraint term $L^{constr}$ in eq. (10), we train a variant of MRLNS (denoted as Net+PNS) by optimizing only $L_{task} + L^{cpns}$ in eq. (10). We run the experiment 10 times.\nTable 1 and table 2 present the distance correlation values between the learned representations and the ground truth variables under varying degrees of spurious correlation ($s$). Our analysis focuses on the results for SN, the variables that directly determines $Y$. A higher distance correlation indicates a better representation. Two tables show that MRLNS consistently outperforms both Net and Net+PNS in capturing the SN causes across various degrees of $s$ for both modalities. This demonstrates MRLNS's effectiveness in learning representations with high PNS. While Net+PNS shows some improvement over Net, MRLNS consistently surpasses both, underscoring the importance of the full optimization objective, including the constraint term, in enforcing the learning of non-trivial PNS.\nAdditionally, the distance correlation with spurious information increases as $s$ increases. These results indicate that when data contains more spurious correlations, MRLNS tends to capture some of this spurious information. However, MRLNS still maintains its ability to extract SN causes effectively, which highlights the robustness of MRLNS."}, {"title": "Real-world Dataset Experiments", "content": "To evaluate MRLNS in real-world scenarios, we adapt an existing disentangling approach to optimize the loss of eq. (10) on multimodal datasets."}, {"title": "Real-world Datasets", "content": "We utilize CMU-MOSI (Zadeh et al. 2016) and CMU-MOSEI (Zadeh et al. 2018), two widely-used datasets for multimodal emotion recognition. Both datasets provide samples labeled with sentiment scores ranging from highly negative (-3) to highly positive (3), and are available in aligned and unaligned versions. CMU-MOSI consists of 2,199 short monologue video clips, split into 1,284 training, 229 validation, and 686 testing samples. CMU-MOSEI, a larger dataset, contains 22,856 movie review video clips from YouTube, divided into 16,326 training, 1,871 validation, and 4,659 testing samples."}, {"title": "Disentangling Approach", "content": "We implement MRLNS by adapting the Decoupled Multimodal Distillation (DMD) method (Li, Wang, and Cui 2023), a state-of-the-art disentangling approach. For its feature extractor, DMD uses"}, {"title": "Implementation of MRLNS", "content": "To implement MRLNS, we utilize the DMD's framework and hyper-parameters based on its publicly available code. We then add a complement extractor mirroring the architecture of DMD's feature extractor. To optimize eq. (10), we empirically define $L_{pred}$ as the mean absolute error (MAE) and $L_{cf}(Y, \\hat{Y}) = max(0, 4 \u2013 ||MAE(Y, \\hat{Y})||)$. This $L_{cf}$ increases as the predicted label $\\hat{Y}$ approaches the true $Y$. $L_{task}$ is the original DMD loss. By adapting DMD according to fig. 2, we create DMD+MRLNS, which optimizes the full $L^{total}$ in eq. (10). To show the effect of the constraint term $L^{constr}$ in eq. (10), we train DMD+PNS, a variant that optimizes only $L_{task} + L^{cpns}$ in eq. (10)."}, {"title": "Baselines", "content": "We evaluate DMD, DMD+PNS, and DMD+MRLNS, and compare them with state-of-the-art methods for emotion score prediction under the same dataset settings: TFN (Zadeh et al. 2017), LMF (Liu and Shen 2018), MFM (Tsai et al. 2019), RAVEN (Wang et al. 2019), MCTN (Pham et al. 2019), and Graph-MFN (Zadeh et al. 2018). Following these works, we evaluate the performance using: (1) 7-class accuracy (Acc_7), (2) binary accuracy (Acc_2), and (3) F1 score (F1)."}, {"title": "Results and Discussion", "content": "The experimental results on the CMU-MOSI and CMU-MOSEI datasets are presented in table 3 and table 4, respectively. We observe that applying MRLNS to the DMD improves performance across all evaluation metrics on both datasets, regardless of whether the data is aligned or unaligned. This improvement demonstrates the effectiveness of encouraging the disentangling approach to learn high-PNS representations based on MRLNS. By focusing on features that are both necessary and sufficient for accurate predictions, the model learns more informative and discriminative representations, which in turn leads to better performance.\nFurthermore, results on DMD+PNS show that removing the constraint term results in a performance drop compared to the full DMD+MRLNS model. This highlights the importance of using constraint to ensure that the multimodal representations capture the desired high-PNS properties."}, {"title": "Limitation", "content": "MRLNS builds upon existing disentangling approaches to learn effective representations by incorporating PNS. However, MRLNS relies on the assumption that the representations learned by the models exhibit \u03b4-Semantic Separability. Determining the appropriate value for \u03b4 remains a challenge, as it may vary depending on the specific task and dataset. Moreover, completely and successfully disentangling the representation into modality-invariant and modality-specific components is an open problem in the field (Zhang et al. 2019; Ramachandram and Taylor 2017; Guo, Wang, and Wang 2019; Gao et al. 2020). The disentanglement process itself may introduce noise, which could affect the performance of MRLNS. Despite these limitations, we believe that MRLNS represents a novel insight in multimodal representation learning."}, {"title": "Conclusion", "content": "Our study identifies the key challenges in applying PNS estimation to multimodal data and propose viewing multimodal representations as comprising modality-invariant and modality-specific components to address these challenges. Building upon the theoretical derivations of PNS for these components, we develop a method that enhances multimodal models by encouraging them to learn representations with high PNS. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of our method."}]}