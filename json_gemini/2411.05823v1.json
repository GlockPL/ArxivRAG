{"title": "FLEXCAD: UNIFIED AND VERSATILE CONTROLLABLE CAD GENERATION WITH FINE-TUNED LARGE LANGUAGE MODELS", "authors": ["Zhanwei Zhang", "Shizhao Sun", "Wenxiao Wang", "Deng Cai", "Jiang Bian"], "abstract": "Recently, there is a growing interest in creating computer-aided design (CAD) models based on user intent, known as controllable CAD generation. Existing work offers limited controllability and needs separate models for different types of control, reducing efficiency and practicality. To achieve controllable generation across all CAD construction hierarchies, such as sketch-extrusion, extrusion, sketch, face, loop and curve, we propose FlexCAD, a unified model by fine-tuning large language models (LLMs). First, to enhance comprehension by LLMs, we represent a CAD model as a structured text by abstracting each hierarchy as a sequence of text tokens. Second, to address various controllable generation tasks in a unified model, we introduce a hierarchy-aware masking strategy. Specifically, during training, we mask a hierarchy-aware field in the CAD text with a mask token. This field, composed of a sequence of tokens, can be set flexibly to represent various hierarchies. Subsequently, we ask LLMs to predict this masked field. During inference, the user intent is converted into a CAD text with a mask token replacing the part the user wants to modify, which is then fed into FlexCAD to generate new CAD models. Comprehensive experiments on public dataset demonstrate the effectiveness of FlexCAD in both generation quality and controllability.", "sections": [{"title": "INTRODUCTION", "content": "A computer-aided design (CAD) model is a digital representation of a 2D or 3D object. It has been widely used across numerous industries, including architecture, product design and manufacturing, facilitating precise, efficient, and innovative development. In commonly used CAD tools like SolidWorks and AutoCAD, sketch-and-extrude modeling (SEM) is prevalent. This involves drawing 2D sketches and then extruding them into 3D shapes. Compared to other representations, such as Constructive Solid Geometry (CSG), B-rep, or voxel and point cloud-based formats, SEM, incorporating multiple CAD construction hierarchies including sketch-extrusion, extrusion, sketch, face, loop and curve (see Fig. 3(a)), directly illustrates the drawing process of a 3D object. This allows for easy editing and reuse of CAD models, which is essential in CAD development.\nRecently, there is an increasing interest in developing generative models to automatically produce SEM of a CAD model\u00b9. Specifically, DeepCAD focuses on uncontrollable generation, where a CAD model is generated from a randomly sampled vector. However, providing controllability, i.e., generating CAD models according to user intent, is crucial for the practical application of generative models. To address this, SkexGen and Hnc-cad implement disentangled codebooks to offer some levels of control. As each codebook encodes a particular construction hierarchy, their controllability is quite restricted. For instance, SkexGen does not allow selecting a specific sketch for modifications when a CAD model comprises multiple sketches, nor can it handle finer-grained hierarchies such as faces and loops. Hnc-cad lacks control over the topology and geometry of curves. In summary, existing methods face challenges in providing adequate controllability across all CAD construction hierarchies. Additionally, they require separate models to deliver different types of control, which is inefficient and less practical.\nThe emergence of large language models (LLMs) offers insights for addressing these challenges. First, LLMs have exhibited remarkable success in handling diverse user queries with a single and unified model. This phenomenon not only occurs in natural language tasks but also extends to other areas with domain-specific fine-tuning, such as human motion generation and crystal material synthesis. Second, LLMs might have acquired CAD-related knowledge during the pre-training by learning CAD-specific codes, such as JSCAD codes. Third, prior to the rise of LLMs, small transformer-based models were explored for tasks like uncontrollable generation and image-to-sketch translation in the 2D sketch domain, showcasing the possibility of LLMs from a different perspective.\nIn this work, we introduce FlexCAD, a unified model designed for controllable CAD generation across all hierarchies by fine-tuning LLMs. As shown in Fig. 1, FlexCAD receives the original CAD model along with the part the user wants to modify (highlighted in blue). Here, users can specify the part in any hierarchy. FlexCAD then generates multiple new CAD models, altering only the selected part. To achieve these abilities, first, FlexCAD translates a CAD model into a concise and structured text (see Fig. 3). Specifically, in each sketch, the curve type (e.g., a line) is directly represented as textual tokens. The numerical data indicating geometry (e.g., point coordinates in a line) is converted into decimal integers and then into textual tokens. A special token is added to mark the end of each hierarchy. Tokens from the finer-level hierarchy are concatenated to form the representation for the coarser-level hierarchy. We use a similar way to convert each extrusion. Consequently, unlike the one-hot representation used in, FlexCAD provides a concise text representation of a CAD model, facilitating easier processing and understanding by LLMs. Second, FlexCAD introduces a hierarchy-aware masking strategy to enable fine-tuning LLMs for various controllable CAD generation tasks (see Fig. 2). During training, we replace a hierarchy-aware field, which contains a sequence of tokens in the CAD text, with a mask token. This field can be set adaptably to reflect various hierarchies. Then, we ask LLMs to predict the masked field. To achieve this, we design prompt templates for all hierarchies, where the mask tokens are tailored to match the corresponding hierarchies. These templates are uniformly sampled at each epoch during the fine-tuning of LLMs. In this way, we ensure that the generation tasks for all hierarchies are learned in a single and unified model. Besides, unlike that requires multi-stage training, FlexCAD achieves end-to-end training. During inference, a CAD model is represented as a CAD text with a mask token replacing the part the user wants to change. The masked CAD text is fed into the"}, {"title": "REPRESENTING CAD AS STRUCTURED TEXT", "content": "Following the conventional definition of SEM of a CAD model there are multiple construction hierarchies, as illustrated in Fig. 3(a). A 'curve', i.e., line l, arc a, or circle c, forms the base level, represented by one, two, or four points respectively. Each point is denoted by its x and y coordinates. A 'loop' L denotes a closed path, comprising either a single curve (i.e., circle) or multiple curves (e.g., line-arc-line). A 'face' F is a 2D area, characterized by a single loop or an outer loop with one or multiple inner loops acting as holes. A 'sketch' S is composed of one or multiple faces, sharing a common extrusion command. An 'extrusion' E is a command that extends a sketch from a 2D plane into a 3D body. A \u2018sketch-extrusion\u2019 SE represents a single sketch-extrusion 3D body. A\u2018CAD model\u2019 M comprises one or multiple SE entities. As shown in Fig. 3(b), we represent a CAD model as a succinct and structured text. Specifically, in each sketch, we start by representing a curve since it is the base level. The curve type (i.e., line, arc or circle) is represented directly as textual tokens. The point coordinates of the curve, which are numerical, are expressed as decimal integers and then converted into textual tokens. This contrasts with that uses binary representation for point coordinates. For example, when discretizing coordinates into a 64\u00d764 grid, denotes the center coordinate as ([0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1]), while we represent it as (31,31). Next, the curve is denoted as a sequence of textual tokens, with the first one indicating its type and the others representing point coordinates (the text with a blue background in Fig. 3(b)). Notably, we add a special textual token 'H_end' to mark the end of each hierarchy, where H \u2208 {curve, loop, face, sketch, extrusion}. This is also different from where one-hot vectors are used as ending flags. We concatenate tokens of multiple curves to create the representation for a loop (the text with a green background in Fig. 3(b)). Then, we use a similar way to form representations of other hierarchies, including face and sketch (the texts with red and yellow backgrounds in Fig. 3(b)). Furthermore, an extrusion can also be represented using textual tokens, with the first one specifying its type (e.g., add or cut) and the others denoting its numerical attributes (the text with a brown background in Fig. 3(b)). Finally, a complete CAD model is assembled by concatenating all the textual tokens"}, {"title": "FINE-TUNING LLMS WITH HIERARCHY-AWARE MASK PREDICTION", "content": "In the following, with the structured text representation (referred to as CAD text for simplicity), we introduce how to fine-tune LLMs to develop a unified model for various controllable CAD generation tasks. In general, during training, a hierarchy-aware field in the CAD text is replaced with a mask token. The field, which consists of a sequence of tokens, can be designed to reflect different CAD construction hierarchies. Next, LLMs are asked to predict the masked field (see Fig. 2(a)). To accomplish this, we design different prompt templates, where the mask tokens are designed to align with the corresponding hierarchies (see Fig. 4). During inference, given a CAD model, with a defined mask token, users can specify the part they want to modify (see Fig. 2(b)). Below, we further detail the design of prompt templates, the unified training and inference processes.\nA prompt template includes an instruction with a special mask token replacing a hierarchy-aware field, and an answer containing the tokens of this field. Specifically, for the CAD level, we mask each internal sketch-extrusion with [sketch-extrusion mask]. In this case, other than the sketch-extrusion number, no information from the original CAD model is preserved. Fig. 4(b) shows an example. This allows us to freely generate CAD models with the expected number of sketch-extrusions during inference, facilitating the creation of CAD models with varying complexity. For the sketch-extrusion, sketch and extrusion levels, we replace the relevant field with [sketch-extrusion mask], [sketch mask], or [extrusion mask], respectively. Fig. 4(c) shows an example with one masked sketch-extrusion. For the face (loop) levels, given a face (loop), if it exclusively forms a sketch (face), we mask this face (loop) with [face mask] ([loop mask]). In cases where multiple faces (loops) belong to the same sketch (face), we use a corresponding number of mask tokens to mask them all at once. Fig. 4(d) illustrates an example, where two loops are replaced by two mask tokens. With this strategy, the model learns to generate faces (loops) with varying numbers as described in different instructions. For the curve level, all curves of the same loop are masked with their type indicated in the mask token (i.e., line, arc or circle). Fig. 4(e) presents an example where four curves (arc-line-arc-line) belonging to the same loop are masked simultaneously. As the curve is the fundamental hierarchical level, the control of the topology and geometry of a sketch comes from it. Specifically, once trained and given a loop, by keeping its internal curve type and number unchanged, we can only modify the geometry. Alternatively, by varying the type or number of curves, we can alter the topology."}, {"title": "Unified Training by Sampling Prompt Templates", "content": "At each epoch, for a given CAD text, we uniformly sample a prompt template from the above seven hierarchies. The instruction in the template asks LLMs to predict the masked field autoregressively. Then, the cross-entropy (CE) loss between the prediction and the answer in the template is back-propagated to update the LLMs. To sum up, the advantage here is two-fold. First, by randomly choosing existing prompt templates at each epoch, we aim to establish a unified controllable generation model for various hierarchies. Second, beyond the existing prompt templates, we can incorporate new templates that support other tasks, such as unconditional generation. Notably, we fine-tune LLMs using LoRA which allows a few parameters to be trainable while keeping most parameters fixed. This allows us to leverage the advantages of large-scale models while accelerating model convergence.\nDuring inference, a CAD model is first converted to a CAD text, with a mask token replacing the part that needs modification. This masked CAD text is then input into the fine-tuned LLMs to produce predictions. After infilling the masked text with these predictions, FlexCAD can provide various CAD texts that can be rendered into diverse CAD models. Notably, users do not have to strictly adhere to the masking pattern defined in the training process. For example, although the prompt template, used in training, masks all the loops tied to a face simultaneously, this is not mandatory in the inference. Due to the strong generalization capability of LLMs, it is possible to only mask a single loop for local editing, as illustrated in Fig. 2(b)."}, {"title": "EXPERIMENTS", "content": ""}, {"title": "EXPERIMENTAL SETUP", "content": "For consistency with prior work, we evaluate our FlexCAD on the DeepCAD dataset. This dataset comprises 178,238 sketch-and-extrusion sequences, divided randomly into training, validation, and test sets in a ratio of 90%-5%-5%. To ensure data quality, we follow SkexGen to remove duplicate and invalid sequences. Subsequently, we convert all resultant CAD sequences into texts, as mentioned in Sec. 3.1.\nWe adopt the transformers toolbox and select Llama-3-8B as the base LLM, which achieves superior performance among open-source LLMs. For the 8B model, we use LoRA to fine-tune only 0.042% of their parameters, approximately 3.4 million. The LoRA rank and alpha are set to 8 and 32. The model is trained on four A6000 GPUs. we employ the AdamW optimizer , set the batch size to 32, use a cosine annealing learning rate of 5 \u00d7 10-4, and train for 30 epochs. During the inference process, we set the sampling temperature \u03c4 and Top-p at 1.1 and 0.9, respectively."}, {"title": "PERFORMANCE COMPARISION WITH EXISTING METHODS", "content": "We compare our FlexCAD with GPT-4o, one of the most powerful closed-source LLMs, and two state-of-the-art SEM-based baselines: SkexGen and Hnc-cad. Since SkexGen and Hnc-cad cannot simultaneously control CAD generation across all hierarchies as ours, we choose the sketch-level and extrusion-level controllable generation tasks for comparison following the principles below. First, they are common tasks that can be handled by each baseline. Second, there are official implementations of baselines for these tasks. For GPT-4o, Hnc-cad and FlexCAD, given a CAD model from the test set, we randomly mask either a sketch or an extrusion and predict the corresponding masked field. Notably, despite our best efforts, SkexGen still has slightly different task settings compared to the"}, {"title": "REPRESENTING CAD AS STRUCTURED TEXT", "content": "As shown in Table 4, when evaluated on the sketch-level controllable generation task, our FlexCAD displays robustness across different circle representations, with Four points showing a slight edge.\nEach extrusion operation is represented by 18 parameters: BVVTTTRRRRRRRRRSOO.\n- B represents one of the three Boolean operations: add, cut or intersect. It occupies 1 parameter.\n- V indicates the displacements of the top and the bottom planes from the reference plane in which a sketch is extruded to form a solid. It occupies 2 parameters.\n- T represents the 3D translation applied to the extruded solid. It occupies 3 parameters.\nR represents the 3D rotation of the extrusion direction. It occupies 9 parameters.\nS represents the uniform scaling factor. It occupies 1 parameter.\n- O represents the center of scaling as a 2D coordinate. It occupies 2 parameters."}, {"title": "A.2 DETAILED RESULTS FOR HUMAN EVALUATION", "content": "We present the detailed distribution of the Realism scores as mentioned in Table 1. As shown in the Fig. 8, the distributions for GPT-4o, SkexGen, and Hnc-cad are skewed towards the 'less realistic' end. Conversely, our FlexCAD demonstrates a primarily symmetric distribution, suggesting that the crowd workers struggle to differentiate between the generated models and the training set."}, {"title": "A.3 QUANTITATIVE RESULTS FOR OTHER HIERARCHIES", "content": "In this section, we report the quantitative results across other hierarchies, including CAD, sketch-extrusion, face, loop and curve levels. By combining the data from Table 1 and Table 5, we observe that there is not a significant difference in performance across all hierarchies. These results together illustrate the effectiveness of our FlexCAD across all hierarchies."}, {"title": "SENSITIVITY ANALYSIS OF KEY HYPER-PARAMETERS IN SAMPLING", "content": "In this part, we perform a sensitivity analysis on key hyperparameters in inference, including the sampling temperature \u03c4 and Top-p. As shown in Table 6, as either \u03c4 or Top-p increases, the performance of the first five metrics exhibits improvement, whereas the performance of the last deteriorates. Essentially, higher values of \u03c4 or Top-p lead to predictions that are more random and varied, while the overall prediction validity PV declines. In our experiments, we made a trade-off by selecting the values of \u03c4 and Top-p to guarantee that the PV value remains above 90%."}, {"title": "A.5 UNCONDITIONAL GENERATION TASK", "content": "Our FlexCAD can easily achieve unconditional CAD generation by simply adding a prompt template during training. Specifically, given a CAD text, the instruction in the prompt template can be as concise as 'Below is a description of a CAD sequence:', while the corresponding answer is the whole CAD text. The quantitative and qualitative results shown in Table 7 and Figure 17 verify the effectiveness of our FlexCAD in unconditional CAD generation. Notably, as shown in Table 7, our JSD exhibits the poorest performance. However, upon adjusting the sampling temperature \u03c4 or Top-p to maintain the PV value at around 80%, the JSD value enhances significantly to 0.78."}, {"title": "LIMITATIONS AND FUTURE WORK", "content": "We measure the inference time on one A6000 GPU (with a batch size of 1) for the extrusion-level generation, averaging over 1,000 runs. The inference time of our FlexCAD (based on Llama-3-8B) is slightly higher than that of SkexGen and Hnc-cad, at 0.56 seconds compared to 0.15 seconds and 0.38 seconds, respectively. Notably, we trained and tested Llama-3-70B using four A100 GPUs (with a batch size of 1 per GPU), yet the average inference time is still close to 3 seconds. Although LLMs demonstrate promising performance, they generally lack efficiency. while the task of controllable CAD generation is not particularly demanding in terms of real-time inference requirements, the slight increase in inference time of our FlexCAD (based on Llama-3-8B) is acceptable given the promising performance.\nDespite the significant progress, our FlexCAD sometimes generates hallucinations. For example, when we implement curve-level controllable generation by replacing the original loops with 5, 6, 7, or 8 lines, our FlexCAD tends to generate plausible CAD texts. The CAD models produced from these texts typically exhibit irregular polygonal shapes, as illustrated in Fig. 9. Interestingly, when the modifications are limited to 4 lines, the generated predictions tend to be more structurally regular, as illustrated in Fig. 16. We select loops composed of 4, 5, 6, 7, or 8 lines in the training set for analysis. The ratio is approximately 77.9%-6.2%-9.5%-1.7%-4.7%. Consequently, the fundamental reason behind these hallucinations may stem from data imbalance, which could potentially be mitigated by collecting additional data.\nIn this paper, we fine-tune LLMs to achieve controllable CAD generation. However, several unexplored domains warrant investigation. One such domain involves determining how LLMs can be effectively utilized for text-based generation tasks, such as providing a descriptive text like 'Create a desk.' to generate a corresponding CAD model. Since LLMs possess robust capabilities in controllable CAD generation and text comprehension, in future work, we aim to build a more advanced multi-modal LLM tailored for the text-based CAD generation task."}, {"title": "METHODOLOGY", "content": "In this section, we introduce FlexCAD, a unified model for controllable CAD generation across all construction hierarchies. As shown in Fig. 1, it receives an original CAD model along with the part the user wants to modify (highlighted in blue), and generates multiple new CAD models with only the selected part altered. To achieve this, as illustrated in Fig. 2, FlexCAD first translates a CAD"}]}