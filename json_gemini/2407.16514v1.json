{"title": "Is 3D Convolution with 5D Tensors Really Necessary for Video Analysis?", "authors": ["Habib Hajimolahoseini", "Walid Ahmed", "Austin Wen", "Yang Liu"], "abstract": "In this paper, we present a comprehensive study and propose several novel techniques for implementing 3D convolutional blocks using 2D and/or 1D convolutions with only 4D and/or 3D tensors. Our motivation is that 3D convolutions with 5D tensors are computationally very expensive and they may not be supported by some of the edge devices used in real-time applications such as robots. The existing approaches mitigate this by splitting the 3D kernels into spatial and temporal domains, but they still use 3D convolutions with 5D tensors in their implementations. We resolve this issue by introducing some appropriate 4D/3D tensor reshaping as well as new combination techniques for spatial and temporal splits. The proposed implementation methods show significant improvement both in terms of efficiency and accuracy. The experimental results confirm that the proposed spatio-temporal processing structure outperforms the original model in terms of speed and accuracy using only 4D tensors with fewer parameters.", "sections": [{"title": "I. INTRODUCTION", "content": "During the past few years, 3D convolutional neural net- works have become dominant in the area of video anal- ysis, especially for action recognition [3], [6], [7], [15], [22], [23], [25], [26], [36], [38], [40], [41]. However, 3D convolution is computationally very expensive, which may cause problems in real-time applications. That is mostly because the common strategy in video processing models is to expand a well-known 2D image architecture into a 3D spatio-temporal model [14]. For example, C3D [32] and I3D [3] are the 3D versions of VGG-16 [28] and Inception-V1 [31], respectively. Although this type of architectures could reach the state-of-the-art in accuracy, it has been proved that this 2D to 3D expansion approach is not optimal in terms of computational costs [6]. For example, the 3D version of ResNet used in video processing uses around 27 times more mathematical operations than its 2D version used in image recognition [16], [38].\nIn order to increase the efficiency of deep learning models, different strategies have been proposed in the literature [1], [2], [8]-[13], [18]. In video processing applications, early attempts were mostly focused on using 2D convolutions with some tricks in order to include the motion analysis as well. Two-stream networks are examples of this type of methods in which one stream is used for spatial processing while motion analysis is performed in the second stream using 2D convolutions [27], [37]. However, the computational costs added by the optical flow calculation in the motion stream prevent these methods from being efficient in real- time applications. On the other hand, there are some other 2D based networks e.g. TSM [23] and TIN [26] that perform the motion analysis by shifting some of the features along the temporal dimension in order to provide the ability of information exchange between the adjacent frames.\nAnother straightforward approach is to split the network architecture by performing the 2D convolutions in some layers of the network for spatial processing while applying the 3D convolutions for spatio-temporal analysis in the rest of the model. In [39], it is shown that efficiency and accuracy could be improved by applying 2D convolutions to the early layers of the network to extract high-level semantic infor- mation from frames. The temporal representation learning is then performed at the top of the network by applying 3D convolutional layers to these high-level features. ECO architecture is one of the most famous networks in this category [42].\nA similar strategy is to use different pathways for spatial and temporal analysis as proposed in the SlowFast architec- ture [7]. In that network, the spatial processing is performed in the Slow pathway using more features at a lower frame rate, while the temporal analysis is done in the Fast pathway using less features at a higher frame rate. They then extended their work to a single path architecture called X3D, in which a tiny 2D network is progressively expanded in different dimensions to a 3D architecture instead of just adding an extra temporal dimension to a 2D image based network [6].\nOn the other hand, instead of splitting the network into 2D and 3D layers or different pathways, another alternative solution is to factorize each 3D layer into spatial and temporal domains throughout the network. In this approach, every 3D convolutional block is decomposed into a spatial 2D convolution followed by a temporal 1D convolution. S3D [39], P3D [24] and R(2+1)D [35] are some of the well-known architectures in this category. As presented in R(2+1)D architecture, one benefit of this approach is that the network capacity could be doubled by adding an extra non-linear function in between the 2D and 1D convolutions while preserving the number of parameters [35]. This could lead to a higher accuracy and efficiency comparing to the original 3D convolutional networks.\nFactorization of the 3D blocks can go even deeper by decomposing the kernels into a consecutive sequence of one- dimensional filters across all directions in order to improve the efficiency even more [19]. However this implies a strong assumption that the convolutional kernels are of rank-1 so that the matrix decomposition is reversible by cross produc- tion of all 1D components [21].\nOn the other hand, some networks take advantage of channel-wise separable convolutions or group convolutions."}, {"title": "II. PROPOSED METHOD", "content": "A regular 3D convolutional layer and its 5D input/output shapes are shown in Fig.1. As shown in this figure, it applies a 3D convolution operation to both special (X, Y) and temporal dimensions (T) at the same time to extract the spatio-temporal information. Note that in almost all of the video analysis models, spatial dimensions w and h of the kernels are the same. Therefore, we assume: w = h = d for the sake of simplicity in representations. The output would have the shape of \\(B \\times T' \\times X' \\times Y' \\times S\\), where T', X' and Y' are the new temporal and spatial dimensions and S is the number of output channels.\nIn order to avoid using 5D tensors, we first reshape the input data into 4D format by multiplying its first 2 dimensions as shown in Fig.2. Then, in order to avoid applying 3D operations, we replace the 3D convolutional layer in Fig.2 with the proposed structure shown in 3.\nAs shown in Fig.3, we apply the spatial and temporal processing independent from each other in two parallel branches: spatial branch which analyses the data in its X and Y dimensions, and temporal branch which analyses the input in its temporal domain T.\n**A. Spatial Analysis**\nEach frame of the video can be considered as a static image with spatial 2D data. In the spatial analysis branch, the first 2D convolution applies the spatial analysis to each frame by multiplying the X and Y dimensions with a d x d kernel. This will generate a 4D tensor of size: \\(B \\times T,,,S\\) in which the lowercase \u201cs\u201d is an integer representing the stride."}, {"title": "B. Temporal Analysis", "content": "On the other hand, in the temporal analysis branch, we only analyze the relationship between each pixel of the im- ages in consecutive frames. To do this, the input tensor is first reshaped by multiplying the vertical and horizontal pixels of the frames: \\(B,T, X \\times Y, C'\\). Then, a 2D convolution with kernel d \u00d7 1 and strides of (s, s\u00b2) is applied to the 2nd and 3rd dimensions of the 4D tensor which performs both the temporal analysis and spatial striding at the same time. The reason behind using s\u00b2 as our spatial stride is that the X and Y dimensions are multiplied and applying an s\u00b2 stride to the 3rd dimension will shrink each of X and Y dimensions by a factor of s. Therefore, this square stride guarantees that the output of the temporal branch will have the exact same size as that of the spatial branch. This will make combining the output of two spatial and temporal branches very straightforward by simply adding them together. The resulting tensor generated by adding of two branches outputs will also have the same size as each of the branch outputs: \\(B,,,S\\)."}, {"title": "III. EXPERIMENTAL RESULTS", "content": "We choose ECO-Lite architecture (with a minor mod- ification) as the baseline in our experiments [42]. This architecture is composed of two parts: a set of 2D layers called 2D-Net for spatial analysis of individual frames, and a set of 3D layers called 3D-Net for spatio-temporal analysis of the feature representations learned from the 2D-Net. The first few layers of Inception-V3 [30] (originally BN-Inception [17] in the ECO paper) is used as the 2D-Net while the last few layers of 3D-Resnet18 [33] is adopted for the 3D-Net. The modified ECO-Lite architecture is presented in Table I.\nThere are multiple reasons for choosing the ECO-Lite architecture in our experiments. First of all, it is simple for implementation and efficient during both training and inference. Second of all, almost half of the architecture consists of 2D convolutional layers from Inception-V3 which we do not need to change during our experiments with different 3D simulations techniques in the 3D-Net. This will provide us with a huge benefit in terms of training time as we can initialize the 2D-Net using the Inception-V3 pre-trained weights on a large image dataset e.g. ImageNet [4]. This will also enable us to transfer knowledge between our different 3D simulation experiments as we only change the 3D-Net during our experiments while 2D-Net stays untouched.\nExperiments are performed on NVIDIA V100 GPUs. In the experiments, all 3D Convolutional layers in ECO-Lite architecture are replaced by one of the equivalent structures in literature that resemble the 3D convolution including: R(2+1)D [35], P3D-A, -B, and -C [24] and Rank-1 [21]. Two versions of the proposed structure are also implemented, in which the last block in Fig.3 (the yellow add block) that combines the temporal and spatial branches are adding (Proposed-add) or concatenation (Proposed-cat) operations. Concatenation is done along the last dimension of the tensors (channels).\nThe number of training parameters, floating points op- erations per second (FLOPs) and inference speed in terms of frame per second (FPS) of all of the structures are also compared with that of the baseline Conv3D module in Table II. As seen in this table, the proposed method with adding block (Prop-Add) has only 16.3 million parameters which is 51% less than the baseline (Conv3D). the FLOPs also drops by 51% and the inference speed improves by 12%, which is the highest speed-up among all other implementations.\nIn order to evaluate the performance of different struc- tures, we use two datasets including Kinetics-400 [20] and UCF-101 [29]. The experimental results for the different structures on these datasets are shown in Table III. In this table, the 3D layers of ECO-Lite architecture are trained from scratch while the 2D blocks are initialized using the ImageNet weights of Inception-V3. The performance results of pretraining on Kinetics dataset and then finetuning on UCF is also reported in Table IV. In this experiment, the model is first trained on Kinetics dataset for 50 epochs and then finetuned on UCF for 100 epochs.\nAs seen in these tables, the proposed technique is more efficient and even more accurate than the other methods, even the baseline 3D-CNN which uses 5D tensors. More specifi- cally, the Proposed-Cat method has the highest accuracy on both Kinetics and UCF datasets in both cases, even better than the baseline. The possible reason could be the higher non-linearity caused by the new structures which increases the capacity of the networks. If the number of parameters is not an issue, the Proposed-Cat structure is the best choice among all of the techniques. The Proposed-Add shows the highest speed-up among all of the techniques although it does not have the highest accuracy. However, it still preserves the accuracy higher than the baseline. Therefore, it could be a good choice when the speed and efficiency is a priority."}, {"title": "IV. CONCLUSION", "content": "In this work, we studied some techniques for imple- menting the 3D convolutional layers using 2D and/or 1D convolutions with only 4D and/or 3D tensors. The existing approaches reshapes the 5D tensors at the begigning of the models and analyses the data in two different branches including spatial and temporal domains. We performed this by introducing some appropriate 4D/3D tensor reshaping as well as new combination techniques for spatial and temporal splits. The proposed implementation methods show signifi- cant improvement both in terms of efficiency and accuracy. We have performed multiple experiments on both NVIDIA's GPUs as well as Huawei's Ascend AI accelerators. In summary we solved the existing problems with conventional 3D-CNN as follows:\n\u2022 Appropriate reshaping techniques in the parallel struc- ture of the proposed method allows us to use 4D tensors throughout the entire system instead of 5D\n\u2022 Also, the 4D tensors in both branches will have the same shapes after processing which makes them more efficient to combine by adding\n\u2022 Using only 2D kernels enables us to implement the spatial and temporal processing much more efficiently with significantly lower memory consumption, which are critical in real-time applications especially for edge devices in real-world applications."}]}