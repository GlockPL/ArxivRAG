{"title": "DNN-GDITD: Out-of-distribution detection via Deep Neural Network based Gaussian Descriptor for Imbalanced Tabular Data", "authors": ["Priyanka Chudasama", "Anil Surisetty", "Aakarsh Malhotra", "Alok Singh"], "abstract": "Classification tasks present challenges due to class imbalances and evolving data distributions. Addressing these issues requires a robust method to handle imbalances while effectively detecting out-of-distribution (OOD) samples not encountered during training. This study introduces a novel OOD detection algorithm designed for tabular datasets, titled Deep Neural Network-based Gaussian Descriptor for Imbalanced Tabular Data (DNN-GDITD). The DNN-GDITD algorithm can be placed on top of any DNN to facilitate better classification of imbalanced data and OOD detection using spherical decision boundaries. Using a combination of Push, Score-based, and focal losses, DNN-GDITD assigns confidence scores to test data points, categorizing them as known classes or as an OOD sample. Extensive experimentation on tabular datasets demonstrates the effectiveness of DNN-GDITD compared to three OOD algorithms. Evaluation encompasses imbalanced and balanced scenarios on diverse tabular datasets, including a synthetic financial dispute dataset and publicly available tabular datasets like Gas Sensor, Drive Diagnosis, and MNIST, showcasing DNN-GDITD's versatility.", "sections": [{"title": "1 Introduction", "content": "In complex domains such as finance [1], manufacturing [2], and self-driving vehicles [4], numerous safety-critical decisions must be made. Here, spotting unusual patterns in the presence of imbalanced classes is essential, as Out-of-distribution (OOD) points may get confused as minority classes (or vice versa). For instance, an autonomous vehicle usually observes more red/green lights vs. a yellow light. However, a self-driving car detected the moon as a yellow light [4]. Since the model wasn't trained on the moon, moon is an OOD sample. Paying special attention to OOD detection is crucial in these situations. While performing the classification of these datasets in an imbalanced setting for detecting low events"}, {"title": "2 Related Work", "content": "Out of Distribution (OOD) detection methods can be broadly classified into three categories:\n1. Considering an extra OOD class during training\n2. Confidence score based OOD detection\n3. Assuming data's distribution and then modeling it.\nExtra OOD class during training: In these OOD methods such as [3], [14] an extra class is added as an OOD class during training. The extra class contains sample points different from instances of k considered classes. Here, the classification problem becomes a normal classification problem with k+1 classes during training and testing. Thus, any classification algorithm can be used if an additional OOD class is added during training. However, the sample count of OOD should be comparable to the count of each k class of interest; otherwise, the OOD pattern may not get captured. Liang and Srikant [14] proposed the ODIN algorithm for OOD detection. ODIN does not require changing a pre-trained neural network to classify pre-defined k classes. It uses temperature scaling and adds small perturbations to the input to separate the softmax score distributions between ID and OOD instances. ODIN used the OOD class to tune hyper-parameters to decide the perturbation intensity and temperature scaling using a validation set containing the OOD class.\nConfidence-score based OOD detection: Hendrycks and Gimpel [15] created a baseline for finding OOD samples during training. Such methods do not require an OOD class during training but instead rely on a confidence score. They used softmax probability scores to classify in and out-of-distribution samples. Their method is based on the assumption that correctly classified examples have higher softmax probabilities than incorrectly classified and OOD examples. Unfortunately, DNN tends to have high confidence even on samples they have never seen before [17,20]. Further, Guo et al. [23] experimentally show the need for calibrating DNNs as they tend to have high confidence and less accuracy. As an alternative, K. Lee et al. [7] use Mahalanobis distance-based confidence score with respect to the closest class-conditional distribution out of k classes. Their algorithm applies to any pre-trained softmax neural classifier (without re-training) for detecting OOD samples. However, as K. Lee et al. [6] explains, DNNs trained using softmax are not optimal in distinguishing OOD samples from in-distribution (ID) samples. Works such as [33-36] show that prediction probability from a softmax distribution has a poor direct correspondence to confidence. Softmax-based classifiers tend to overlap significantly between difficult ID and OOD samples. Difficult ID samples are those whose probability value tends to be same for all of the classes, making the model less confident in it's prediction, same is seen for OOD samples. For this reason, there is less gap between confidence scores of an ID vs an OOD sample.\nAssuming data's distribution and modeling it: In this approach, just like the previous approach we do not require OOD samples during training. Here, the assumption is rather made on the distribution of training classes. For instance,"}, {"title": "3 Problem Definition", "content": "Let {X, Y} be the collection of all samples seen during training. We assume that there are k distinct classes. Thus, for x \u2208 X we have it's corresponding label, yx \u2208 {1,2,..., k}. Further, let the entire training and testing dataset be denoted as D := Dtrain U Dtest. Here, Dtrain = {X,Y} with k distinct classes and Dtest = {X', Y'}, where the predictions of input samples X' are evaluated against labels Y'. However, the Dtest may contain samples from either the k classes (seen during training) or from a distribution not seen during training, called an OOD class. Further, the considered k classes are imbalanced. Having an imbalanced class during the training makes the problem of OOD detection during testing more challenging. In such a setting, the classifier is supposed to rightly assign the sample x into one of the k imbalanced classes or label OOD when yx f/{1,2, . . ., k}. Thus, the aim is to propose a classification module that can work in an imbalanced setting and efficiently classify any testing sample into either one of the k classes or as an OOD sample."}, {"title": "4 Proposed Algorithm: DNN-GDITD", "content": "Consider a training sample x \u2208 X with corresponding ground-truth yx \u2208 Y. OOD detection via DNN-GDITD is a classification module that takes embedding vectors f(x) from a DNN f(:, W) \u2208 Rd, with learnable parameters W. Inspired by Gaussian Discriminant Analysis, the proposed DNN-GDITD tries to transform the embedding space into a collection of independent Gaussian-distributed clusters (spheres) for k classes seen during training with spherical decision boundaries. Consequently, each cluster i \u2208 {1,2,...,k} is assumed to have a mean \u03bc\u03b5 and standard deviation \u03c3\u03af.\nSuppose we're given a training instance x sampled from mini-batch B from Dtrain. We define its distance from the ith cluster for i \u2208 {1,2,... k} in the latent space using the ith class conditional probability as:\nDi(x) := -log Pr(xi) (2)\nFurther, we assume that data in latent space is distributed as k independent Gaussian spheres. Thus Pr(xi) \u2248 N(\u03bc\u03b9, \u03c3\u2081) for i \u2208 {1, 2, . . . k}. Hence,\nDi(x) = -log N(f(x)|\u03bc, \u03a3), (3)\nwhere \u03bc = [\u03bc1, \u03bc2,... \u03bc\u03ba] and \u2211 = [\u03c31,02,...\u03c3\u03ba] * I. Here, Ikxk is the identity matrix. Consequently, the distance from a given training data point x from the ith cluster in the latent space can be defined as:\nDi(x) =  (||f(x) \u2013 \u03bc\u03af||2)/(20) + log(i)d, (4)\nwhere d is the dimension of the latent space.\nUsing the above-mentioned class-specific distance, the objective for the proposed DNN-GDITD algorithm is to:"}, {"title": "4.1 Pull loss", "content": "Let us consider a training instance x with ground truth label yx, sampled from mini-batch B\u2208 Dtrain. Then, we define pull loss as follows:\nLp = \u2211 Dy (x) = \u03a3 (||f(x) \u2013 \u03bcy || 2)/(202) + log(ry)d (6)"}, {"title": "4.2 Scores based loss (SL)", "content": "We want (y(x) \u2265 0 and $i(x) < 0 for i \u2260 yx. To achieve it, we create a score-based loss. When i \u2260 yx, we want to have a negative score from the rest of the classes (i(x) < 0). The loss Lst in this case takes the exponential of score Sy (x), ensuring that scores are negative for the rest of the classes. Similarly, when i Yx, we want the score to be positive. Thus, we feed in the negative scores through ReLU activation and also take the log of scores to ensure we get smaller values for scores. Essentially, the score loss is defined as:\nLSL = (\u03a3\u03c7\u03b5\u0392 \u03a3exp(((x)) for i \u2208 {1,2,...,k}\\{yYx},\n(\u03a3\u0395\u0392 (ReLU(-yz(x)) + log(1 + (y(x)2)), else (7)"}, {"title": "4.3 Effective focal loss (EFL)", "content": "Lastly, to tackle classification in an imbalanced setting, we use weighted focal loss. Focal loss [18] is usually used for object detection and in classification [19]. It helps to emphasize difficult examples during backpropagation. Further, Cui et al. [19] introduced class-balanced loss using an effective number for class imbalance classification. We use this effective number to create a weighted focal loss, which we call effective focal loss (EFL). Cui et al. [19] measure data overlap by associating a small neighboring region with each sample rather than a single point. Thus, effective focal loss for sample x with actual class yx and corresponding class's predicted probability py\u2082 (x) is defined as:\nEFloss(yx, Pyx):= (1-\u03b2)/(1 - \u0412\u043f\u0443\u0445)-(1-pyx(x))log(pyx(x)) (8)\nHere, y is the focus parameter. Increasing y increases the focus on difficult sample learning. y = 0 will give us the usual cross-entropy loss. The effective number, \u03b2 is usually considered as 1/#|B|, where ny is the number of samples of class yx in current batch B. We use EFL as defined on both D(x) and (i(x) as follows:\nLEFL1 = \u2211 EFloss(y2,1/D(x)). (9)\nLEFL2 = \u2211 EFloss (yz, \u00c7i(x)). (10)\nCollectively, the net loss for the proposed DNN-GDITD algorithm is given as:\nLnet = Lp + LSL + LEFL\u2081 + LEFL2 (11)\nPost training, the label \u1ef9x for a testing data point x is predicted as per the maximum argument of $i(x) := \u03c3\u03b9 Di(x). If (x) is negative for all i \u2208"}, {"title": "5 Experiments details and Analysis", "content": "We show the efficacy of DNN-GDITD on four different tabular datasets: (i) Synthetic financial, (ii) Gas Sensor [8], (iii) Drive Diagnosis [11], and (iv) MNIST [5]. Table 1 gives all the datasets' details. These four datasets are selected to showcase the efficacy of the proposed work in all three scenarios: highly imbalanced, imbalanced, and balanced. We use the synthetic financial dataset to showcase results in highly imbalanced settings. The synthetic financial dataset is created from a fraud dataset using a modified SMOTE [13] technique to preserve privacy. It consists of three labels: legitimate-dispute, first-party fraud (FPF), and third-party fraud (TPF), with FPF:TPF:legitimate-dispute ratio being 08:46:46. Thus, the synthetic financial dataset falls under a highly imbalanced data category. For all other publicly available datasets mentioned above, we consider the OOD class as class 0. The minority class is considered without loss of generality as class 1 for the Drive and MNIST datasets as they are balanced. Gas Sensor is an imbalanced data with a minority class as class 2.\nFurther, to show the efficacy of OOD detection in an imbalanced setting, we introduce different levels of imbalance into the data using Minority-class Down-Sampling Ratios (MDSR). MDSR indicates the percentage of data to be considered from the considered minority class at random to create D for training and testing. We use different MDSR values ranging from 1, representing zero down-sampling, to 0.10, meaning that only 10% of minority class data originally present will be used during training as a part of ID class. Further, as Synthetic financial data is highly imbalanced we use MDSR values of 1,0.3 and 0.25 only, so that enough samples of minority class are seen per batch during training."}, {"title": "5.1 Datasets", "content": "We show the efficacy of DNN-GDITD on four different tabular datasets: (i) Synthetic financial, (ii) Gas Sensor [8], (iii) Drive Diagnosis [11], and (iv) MNIST [5]. Table 1 gives all the datasets' details. These four datasets are selected to showcase the efficacy of the proposed work in all three scenarios: highly imbalanced, imbalanced, and balanced. We use the synthetic financial dataset to showcase results in highly imbalanced settings. The synthetic financial dataset is created from a fraud dataset using a modified SMOTE [13] technique to preserve privacy. It consists of three labels: legitimate-dispute, first-party fraud (FPF), and third-party fraud (TPF), with FPF:TPF:legitimate-dispute ratio being 08:46:46. Thus, the synthetic financial dataset falls under a highly imbalanced data category. For all other publicly available datasets mentioned above, we consider the OOD class as class 0. The minority class is considered without loss of generality as class 1 for the Drive and MNIST datasets as they are balanced. Gas Sensor is an imbalanced data with a minority class as class 2.\nFurther, to show the efficacy of OOD detection in an imbalanced setting, we introduce different levels of imbalance into the data using Minority-class Down-Sampling Ratios (MDSR). MDSR indicates the percentage of data to be considered from the considered minority class at random to create D for training and testing. We use different MDSR values ranging from 1, representing zero down-sampling, to 0.10, meaning that only 10% of minority class data originally present will be used during training as a part of ID class. Further, as Synthetic financial data is highly imbalanced we use MDSR values of 1,0.3 and 0.25 only, so that enough samples of minority class are seen per batch during training."}, {"title": "5.2 Implementation Details", "content": "We follow the original settings proposed by the authors in respective baselines [6, 7, 15]. For our experiments, we used 128 as the latent dimension size in all 3-layers of the MLP network. We used the Adam optimizer with a learning rate of 0.001 and a batch size of 200 for all four datasets for Softmax [15] and Mahalanobis [7]. We use Block Coordinate Descent (BCD) [21] with a batch size"}, {"title": "5.3 Results and Analysis", "content": "The test data comprises ID and OOD samples. In Table 2, we report classification accuracy for the ID classes and AUPR for minority classes at various MDSR rates. Since the minority class's data is less compared to other ID classes, reporting classification accuracy for the minority class will not help in justifying a model's performance. Thus, we report AUPR values from various models for the minority class. Furthermore, for OOD samples seen during testing, we show the efficacy of our algorithm DNN-GDITD using three metrics: TNR at 85% TPR, AUROC, and AUPR score as the OOD class has almost as many samples as the rest of the ID classes. This helps us validate our model on all the aspects of OOD detection.\nFurther, we have divided Table 2 into two parts, one for imbalanced datasets in Table 2(a) and the other for balanced datasets in Table 2(b). This helps us understand the efficacy of our algorithm on both balanced and unbalanced settings separately. Consequently, during training, the same MDSR value in balanced and unbalanced settings can have different ratios of considered minority class samples compared to the rest of ID class samples. To visually showcase the proposed DNN-GDITD algorithm's efficacy, we show classification accuracy plots for ID data, AUPR for OOD, and AUPR for minority classes at various MDSR rates"}, {"title": "5.4 Ablation", "content": "We conducted an ablation study to demonstrate the effectiveness of each loss component proposed in Table 3. In the DNN-GDITD algorithm, we have 4 losses functions i.e., pull loss (6), SL (7), EFL1 (9) and EFL2 (10). We show the the losses performance on the Gas sensor [8] dataset when only one out of 4 loss is considered vs when only one loss is omitted using the metrics mentioned in Section 5.3. Table 3 suggests that performance without an individual loss (the remaining other three losses used in training) is greater than the performance obtained with the individual loss only. The only exception is when only the score-based loss is employed. The score-based loss ensures that the score value (i(x) is non-negative from its class and negative for the rest of the classes, thereby enforcing that the data point should belong to its own cluster. However, comparing the AUPR score of the OOD class while using only SL with DNN-GDITD, we observe a dip of 2.42% as SL in isolation doesn't ensure compact cluster formation. Further, EFL2 performs poorly for both the OOD and minority classes. As a cross-entropy-based loss, EFL2 tends to increase the difference between scores for the actual class and the rest. However, it does not enforce any condition on the sign of (i(x). This suggests the need to incorporate SL alongside EFL2 loss. Similarly, EFL\u2081 increases the difference between the distance of a data point for the actual class versus the remaining classes. However, it does not enforce that the distance of the data point from its class should be close to zero. Thus, a pull loss should be used in conjunction with EFL1. Further, as observed, omitting SL results in poor performance, justifying the necessity of using both distance-based and score-based losses to achieve the best overall performance."}, {"title": "6 Significance and Conclusion", "content": "We propose a novel method (DNN-GDITD) based on Gaussian Discriminator analysis to tackle class imbalance in tabular datasets during training and detect OOD samples while testing. DNN-GDITD consists of four loss functions. Pull and EFL1 losses reduce the intra-class distance. SL and EFL2 ensure that the score of a data point for its class is non-negative while the score of the data point from other classes is negative. The EF1 takes the reciprocal distance of training samples from all the classes to handle the imbalanced setting. In this work, we show experimental evaluation on four benchmark datasets. After comparing DNN-GDITD with current SOTA methods, we observe that DNN-GDITD gives the best performance in OOD-detection for tabular datasets with an average boost of 3.32% and comparable performance for classifying in-distribution samples. However, as outliers can be present in various domains, we believe DNN-GDITD can be extended to other domains/modalities."}]}