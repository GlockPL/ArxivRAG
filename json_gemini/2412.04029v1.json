{"title": "Considerations Influencing Offense-Defense Dynamics From Artificial Intelligence", "authors": ["Giulio Corsi", "Kyle Kilian", "Richard Mallah"], "abstract": "The rapid advancement of artificial intelligence (AI) technologies presents profound challenges to societal safety. As AI systems become more capable, accessible, and integrated into critical services, the dual nature of their potential is increasingly clear. While AI can enhance defensive capabilities in areas like threat detection, risk assessment, and automated security operations (Hassanin and Moustafa, 2024), it also presents avenues for malicious exploitation and large-scale societal harm, for example through automated influence operations and cyber attacks (Goldstein et al., 2023; Xu et al., 2024a).\nUnderstanding the dynamics that shape AI's capacity to both cause harm and enhance protective measures is essential for informed decision-making regarding the deployment, use, and integration of advanced AI systems. This paper builds on recent work on offense-defense dynamics within the realm of AI (Schneier, 2018; Garfinkel and Dafoe, 2021), proposing a taxonomy to map and examine the key factors that influence whether AI systems predominantly pose threats or offer protective benefits to society. By establishing a shared terminology and conceptual foundation for analyzing these interactions, this work seeks to facilitate further research and discourse in this critical area.", "sections": [{"title": "1 Introduction", "content": "The rapid advancement of artificial intelligence (AI) technologies presents profound challenges to societal safety. As AI systems become more capable, accessible, and integrated into critical services, the dual nature of their potential is increasingly clear. While AI can enhance defensive capabilities in areas like threat detection, risk assessment, and automated security operations (Hassanin and Moustafa, 2024), it also presents avenues for malicious exploitation and large-scale societal harm, for example through automated influence operations and cyber attacks (Goldstein et al., 2023; Xu et al., 2024a).\nUnderstanding the dynamics that shape AI's capacity to both cause harm and enhance protective measures is essential for informed decision-making regarding the deployment, use, and integration of advanced AI systems. This paper builds on recent work on offense-defense dynamics within the realm of AI (Schneier, 2018; Garfinkel and Dafoe, 2021), proposing a taxonomy to map and examine the key factors that influence whether AI systems predominantly pose threats or offer protective benefits to society. By establishing a shared terminology and conceptual foundation for analyzing these interactions, this work seeks to facilitate further research and discourse in this critical area.\nResearch Objectives:\n1. Identifying and defining a taxonomy of key factors influencing the proliferation of offensive and defensive uses of AI relative to society.\n2. Exploring the implications of these dynamics for AI governance and policy."}, {"title": "2 Offense-Defense Dynamics in the Context of AI Impacts", "content": "The concept of offense-defense dynamics originates from international relations and military strategy, where it is used to assess the likelihood of conflict and the strategic balance between opposing forces (Lynn-Jones, 1995; Zhao et al., 2022). In that context, the balance between offensive and defensive capabilities influences nations' decisions regarding aggression, deterrence, and arms development.\nApplying this concept to AI involves examining the interplay between an AI system's capacity to cause societal harm and its ability to mitigate risks through defensive applications. There is a growing body of research exploring both offensive and defensive applications of AI in various domains, such as cybersecurity (Hassanin and Moustafa, 2024; Weng and Wu, 2024), influence operations (Goldstein et al., 2023; Hunter et al., 2024), and CBRN (Chemical, Biological, Radiological, and Nuclear) threats (Security, 2024; Urbina et al., 2022). However, the overall balance and dynamics between societally offensive and defensive AI capabilities remain unclear and often contentious. This section introduces key concepts and definitions that underpin the application of offense-defense theory to A\u0399."}, {"title": "2.1 Prioritizing Societal Impacts", "content": "In applying offense-defense theory principles to AI, we adopt a global framing that reflects the necessity of considering the widespread impacts of AI systems on society as a whole. Unlike traditional dyadic analyses that focus on the interactions between two specific entities, our approach positions society itself as the primary entity affected by AI. This global perspective is essential as the effects of releasing an advanced AI system are inherently global, influencing not just specific adversaries or defenders but the entire societal landscape. By treating society as the first party, we can factor it out of the dyadic equation and focus on how the effects of an AI model causally radiate from its release. This allows for the analysis of the offense-defense dynamics of a model in terms of its impact on societal structures, vulnerabilities, and defenses.\nIn this context, we are not merely considering the offense-defense balances of individual models in isolation. Instead, we are examining how each model's offensive and defensive capabilities interact with societal factors to influence the overall balance of threats and protections within the global community. An AI system's potential for societal harm or benefit is determined by a complex interplay of factors, including its technical characteristics, the contexts in which it is deployed, and the ways in which its capabilities propagate through society.\nTherefore, when discussing offense-defense dynamics in AI, it is crucial to prioritize the factors that enable the proliferation of offensive or defensive applications from a societal perspective. This approach acknowledges that the key metrics of an AI system's impact lie not only in its individual characteristics but in how its release shapes the broader landscape of technological capabilities and their societal consequences."}, {"title": "2.2 Offense-Defense Neutrality", "content": "In applying this framing to AI, it is important to recognize that advanced AI systems are inherently dual-use and generally agnostic to offensive or defensive orientations; the same underlying technologies can be harnessed albeit with some notable exceptions for both beneficial and harmful purposes (Brundage et al., 2018; Kim et al., 2024; Grinbaum and Adomaitis, 2024; Hickey, 2024). For instance, machine learning algorithms designed for pattern recognition can be employed to enhance cybersecurity by detecting anomalies, or conversely, to develop sophisticated cyber-attacks that evade detection (Choquet et al., 2024). This duality underscores the fact that the potential for offense or defense is not an intrinsic characteristic of the AI technology itself. Instead, it is shaped by how the technology is developed, deployed, and controlled within specific technical and contextual frameworks.\nThe orientation of an AI system towards societal offense or defense emerges from a complex interplay of sociotechnical factors that include attributes such as a system's capabilities and adaptability, and contextual factors such as the regulatory environment and ongoing international tensions. A given AI system can also be offense-dominant within one application area"}, {"title": "2.3 Asymmetries in AI Offense-Defense Dynamics", "content": "While AI technologies may be fundamentally neutral, significant asymmetries can emerge naturally in their offensive and defensive applications. Similar to the lessons learned from cybersecurity, these asymmetries may emerge from differences in resource requirements, technological barriers, and strategic advantages inherent to offensive and defensive applications (Locatelli, 2011; Kello, 2013; Huntley, 2016). When applying offense-defense theory to AI, it becomes evident that offensive AI applications can often possess intrinsic advantages, being comparatively easier to develop and deploy.\nThe offensive advantage in AI applications stems from the fact that exploiting existing vulnerabilities typically requires less coordination and planning than comprehensive defense. For instance, the generation of disinformation through deepfake technologies can be accomplished with relatively accessible tools (Helmus, 2022; Seger et al., 2023; Cave and \u00d3h\u00c9igeartaigh, 2018), producing a spectrum of impacts and permeation levels that may be challenging to anticipate and counteract. This ease of offensive deployment contrasts sharply with the demands of defensive measures (Shevlane, 2022). This balance will tend to be magnified exponentially as a risk surface grows exponentially.\nDefensive applications, by their nature, often necessitate more sophisticated solutions, greater collaboration among stakeholders, and continual adaptation to evolving threats. Developing effective defenses against AI-driven offenses involves complex challenges such as detecting subtle anomalies, countering adaptive adversaries, and integrating protective measures across multiple systems and platforms. These requirements create higher barriers to entry and sustained efficacy for defensive AI applications. The naturally occurring asymmetries between offensive and defensive AI applications are likely to be a key element in the understanding and modeling of offense-defense dynamics for AI."}, {"title": "2.4 Core Definitions", "content": "Finally, to effectively analyze and discuss the offense-defense dynamics in AI, it is important to establish a common vocabulary. The following definitions provide a foundation for our taxonomy, allowing for consistent communication and analysis of the complex interplay between offensive and defensive applications of AI technologies. These terms will be used throughout the remainder of this paper to explore the factors influencing the societal impact of AI systems.\nOffensive AI Applications: AI systems designed or utilized to conduct attacks, exploit vulnerabilities, or disrupt systems and societies. Such applications make society more at risk. Examples include automated hacking tools, deepfake technologies used in influence operations, autonomous weapon systems, and AI-augmented malware.\nDefensive AI Applications: Al systems designed or utilized to protect, detect, and respond to threats. These applications make societies safer. Examples include AI-driven fraud detection systems, AI-enhanced threat monitoring and anomaly detection, and Intrusion"}, {"title": "3 Offense-Defense Dynamics Taxonomy", "content": "To systematically analyze the factors influencing the offensive and defensive applications of AI systems, we introduce the Offense-Defense Dynamics Framework. This taxonomy comprises six interrelated elements that collectively shape the proliferation and impact of offensive and defensive AI applications within a given context. These elements are derived from the bottom-up, analyzing known examples of defensive and offensive AI uses, and abstracting from these to identify general patterns and principles. By analyzing these elements, we aim to provide a structured approach to understanding how AI technologies can shift the balance between societal risk and safety.\nThe six elements that compose the taxonomy are:\n1. Raw Capability Potential\n2. Accessibility and Control\n3. Adaptability\n4. Proliferation, Diffusion, and Release Methods\n5. Safeguards and Mitigations\n6. Sociotechnical Context"}, {"title": "3.1 Raw Capability Potential", "content": "Definition: Raw Capability Potential refers to the inherent abilities of an AI system to perform actions that can be utilized either offensively or defensively, independent of any external safeguards or mitigations. It represents the fundamental power of the AI system to harm or protect societal assets, infrastructure, individuals, or the biosphere, based solely on its technical capacities. This concept focuses on what an AI system can do at a fundamental level, without considering its current usage or any protective measures in place.\nImportance in Offense-Defense Dynamics: The raw capabilities of an AI system set the baseline for both its potential benefits and risks. Advanced capabilities enable sophisticated defensive measures, such as enhanced threat detection and response, but they also increase the potential for offensive applications, like automated cyber-attacks or the creation of disinformation at scale.\nWhen assessing Raw Capability Potential, we currently consider two primary, high-level dimensions:\n\u2022 Capabilities Breadth: This refers to the range of tasks and domains an AI system can operate in, reflecting its versatility and expertise across domains and modalities. It encompasses the system's ability to function across multiple areas, from natural language processing to mathematical modeling. For example, a large language model ca-"}, {"title": "3.2 Accessibility and Control", "content": "Definition: Accessibility and Control refer to who can access, use, and operate an AI system in its existing form, and the mechanisms that govern and restrict this access. It focuses on user authentication, licensing for use, and control mechanisms that determine who can interact with the AI system as it currently exists, without modification. This concept also considers whether other AI systems can access or interface with the system in question, which is increasingly relevant in scenarios involving multi-agent systems.\nImportance in Offense-Defense Dynamics: The level of accessibility and control over an AI system significantly influences its potential for both beneficial use and misuse. Systems that are widely accessible, with minimal control and low barriers to entry, may be more susceptible to exploitation for offensive purposes. Conversely, restricted access can limit the spread of defensive applications but also reduces the risk of unauthorized use. Balancing accessibility and control is essential to maximize societal benefits while minimizing risks.\nWhen assessing Accessibility and Control, we currently consider two high-level dimensions likely to influence offense-defense dynamics:\n\u2022 Access Level: This includes considerations on an AI system's access level (public, restricted or confidential), access type (open source, proprietary with public API or closed system), and access cost (low, medium or high). For example, an open-source language model like LLAMA is highly accessible, being free and open-source. This high accessibility can facilitate its use in defensive applications, such as medical assistance and content moderation (Li et al., 2023; Kumar et al.). However, it also lowers the barrier to offensive applications, such as generating malicious disinformation and exploiting privacy vulnerabilities (Choquet et al., 2024; Kim et al., 2024). Additionally, disparities in access can influence the effectiveness of defensive measures while amplifying vulnerabilities. Enti-"}, {"title": "3.3 Adaptability", "content": "Definition: Adaptability refers to the capacity of an AI system to be modified, customized, or repurposed beyond its original context or intended use. Key factors influencing adaptability include the accessibility of model weights and fine-tuning capabilities, the feasibility of model distillation or knowledge transfer, and the presence of modular components that can be independently updated or replaced.\nImportance in Offense-Defense Dynamics: An AI system's adaptability significantly impacts its potential for both offensive and defensive applications. Highly adaptable systems can be swiftly repurposed for new tasks or domains, which can be advantageous for defensive measures by allowing rapid responses to emerging threats. However, this flexibility also presents risks, as malicious actors may exploit adaptable systems for harmful purposes. Moreover, the adaptability of AI systems influences the likelihood of unintended consequences. As systems are modified or repurposed, there's an increased potential for introducing new vulnerabilities or expanding the attack surface, which could shift the balance in offense-defense dynamics.\nWhen assessing Adaptability, we currently consider two high-level dimensions likely to influence offense-defense dynamics:\n\u2022 Modifiability: This dimension encompasses the ease with which an AI system can be altered, including the feasibility of fine-tuning and the presence of modular and extensible architectures. These characteristics enable a model to be modified and repurposed beyond its initial scope. For instance, an open-source model with accessible weights and a modular structure exhibits a high degree of modifiability. This allows for fine-tuning the model for specific offensive and defensive applications, ranging from swift detection of malicious activities (Nguyen et al., 2023) to potentially generating harmful content or unethical advice (Qi et al., 2023; Dong et al., 2024).\n\u2022 Knowledge Transferability: This aspect relates to the AI system's ability to transfer its learned knowledge and capabilities to new tasks, domains, or model architectures. It encompasses mechanisms such as model distillation and transfer learning. High knowledge transferability allows an AI system to be quickly adapted or compressed for new applications without extensive retraining. For instance, a model with strong distillation capabilities could be compressed into a lightweight version for edge device deployment, enhancing its adaptability for various defensive applications like real-time threat detection (Montasari, 2023). Conversely, transfer learning capabilities could enable rapid adapta-"}, {"title": "3.4 Proliferation, Diffusion, and Release Methods", "content": "Definition: This element refers to the strategies and mechanisms through which an AI model can be distributed, shared, and disseminated across society. It focuses on the strategies and pathways through which AI systems become available and are integrated into various contexts.\nImportance in Offense-Defense Dynamics: The manner in which Al systems are released and proliferate affects how quickly and widely they can be adopted for both offensive and defensive purposes. Open and uncontrolled release methods can lead to rapid diffusion, increasing the potential for misuse, while controlled release can limit access to authorized users but may also slow down beneficial adoption. Assessing proliferation and diffusion methods is key for understanding the positive and negative proliferation dynamics of AI technologies in society.\nWhen assessing Proliferation, Diffusion, and Release Methods, we currently consider two high-level dimensions likely to influence offense-defense dynamics:\n\u2022 Distribution Control: This dimension includes the release method (such as fully open-source release, open weights release, or closed-source release) and the degree of control exerted over distribution. For instance, the phased release strategy employed for GPT-4, where access was initially restricted to approved developers and gradually expanded, exemplifies high distribution control. This approach enables careful monitoring and adjustment of the model's impact, potentially mitigating early risks and vulnerabilities. In contrast, the release of BLOOM, a large language model with openly available weights and code, demonstrates low distribution control. While this open approach may facilitate research into AI models, it may also heighten the risks of misuse or unintended applications (Seger et al., 2023).\n\u2022 Model Reach and Integration: This dimension involves the ease with which an AI model can be deployed across various platforms and integrated into existing systems. It encompasses factors such as the model's size, compatibility with different hardware, and interoperability with various software ecosystems. Models with high reach and integration can be rapidly deployed across diverse geographical regions and easily incorporated into a wide range of applications. For instance, a lightweight language model that can run efficiently on mobile devices and integrate seamlessly with popular messaging platforms would have high reach and integration. This characteristic can accelerate the adoption of AI for beneficial purposes, such as real-time language translation or content moderation. However, it also increases the potential for widespread misuse, enabling malicious actors to quickly deploy AI for tasks like generating personalized phishing messages or creating large-scale disinformation campaigns. For example, GPT-J, an open-source language model, demonstrates a high deployment reach and integration due to its complete availability, relatively compact size (6 billion parameters), and ease of deployment. This rapid dissemination has enabled various potential misuses, including the creation of WormGPT, a language model designed for cybercriminal activities (Firdhous et al.)."}, {"title": "3.5 Safeguards and Mitigations", "content": "Definition: Safeguards and Mitigations encompass a comprehensive set of measures implemented to prevent misuse and limit potential harm from AI systems. This includes technical"}, {"title": "3.6 Sociotechnical Context", "content": "Definition: The Sociotechnical Context refers to the broader technological, social, and political environment in which the AI system operates and interacts. It includes factors such as regulatory frameworks, public awareness, geopolitical tensions, and the robustness of technological infrastructure.\nImportance in Offense-Defense Dynamics: The sociotechnical context can either amplify or mitigate the risks associated with AI technologies. A supportive environment with robust regulations, international cooperation, and high public awareness can enhance defensive applications and promote responsible use of AI. Conversely, a hostile context marked by geopolitical tensions, ineffective regulations, and low public awareness can increase the likelihood of proliferation of offensive applications and misuse of AI technologies. Understanding the sociotechnical context is essential for stakeholders to develop appropriate strategies and policies.\nWhen assessing Sociotechnical Context, we consider two main dimensions:\n\u2022 Geopolitical Stability: This includes factors such as international cooperation, conflicts and tensions, and global power dynamics in AI. The geopolitical environment influences motivations for developing offensive or defensive AI capabilities and affects collaboration on AI governance. For example, increasing tensions between major powers in Al de- velopment, such as the US and China, could lead to an arms race scenario, potentially prioritizing offensive applications over safety considerations (Cave and \u00d3h\u00c9igeartaigh, 2018; Meacham, 2023)."}, {"title": "3.7 Framework Interactions", "content": "Notably, the six elements of the Offense-Defense Dynamics Framework form a complex, interconnected system rather than existing in isolation. This interconnectedness is crucial for a comprehensive understanding of AI's offense-defense dynamics and for developing effective policies and strategies. Each element-Raw Capability Potential, Accessibility and Control, Adaptability, Proliferation, Diffusion, and Release Methods, Safeguards and Mitigations, and Sociotechnical Context influences and is influenced by the others in a web of dynamic rela- tionships.\nThese interdependencies manifest in various ways throughout the taxonomy. For example, an AI system's level of access control significantly impacts proliferation patterns, as open-source models with minimal restrictions tend to diffuse more rapidly than closed, proprietary systems. Similarly, the regulatory environment and geopolitical climate, encapsulated in the Sociotechnical Context, exert a pervasive influence across all other elements. They shape the speed and manner of AI proliferation, the development of capabilities, and the implementation of safeguards. Further, highly adaptable systems, while offering flexibility for various applications, may pose challenges for implementing effective safeguards, as they can be more easily modified to circumvent protective measures.\nAdditionally, within this interconnected model, certain elements emerge as clear leverage points, exerting disproportionate influence on the overall offense-defense dynamics. Accessibility and Control, for instance, can serve as a critical bottleneck; regardless of an AI system's raw capabilities or adaptability, tightly controlled access can significantly limit its potential for both offensive and defensive applications. Similarly, robust Safeguards and Mitigations can act as a bottleneck for offensive applications, potentially neutralizing threats even from highly capable and adaptable systems. The Sociotechnical Context, through its influence on policy decisions and international cooperation, can become a significant leverage affecting all other elements.\nUnderstanding these complex interactions is essential for the analysis of AI's potential societal impacts. It highlights the need for a holistic, systems-level approach to managing offense- defense dynamics in AI, where changes in one element are considered in light of their potential ripple effects throughout the entire taxonomy. This perspective can inform more effective strategies for maximizing the defensive potential of AI while mitigating its offensive risks, ultimately contributing to a safer and more beneficial integration of AI into society."}, {"title": "3.8 Applying the Offense-Defense Dynamics Taxonomy: The Use of AI to Generate and Detect Disinformation", "content": "To demonstrate the practical application of the Offense-Defense Dynamics Taxonomy, we present an illustrative example examining how AI models capable of generating multimodal content can be used both to produce and to detect disinformation and coordinated influence operations. The following explores the implications of each taxonomy element for offensive and defensive applications of AI within information environments."}, {"title": "4 Implications for AI Governance and Policy", "content": "AI offense-defense dynamics have several important policy implications, particularly in shaping regulatory frameworks around the development, deployment, and control of advanced AI systems. Developing a granular understanding of offense-defense dynamics can give policymakers a more detailed view of how and to what degree advanced AI systems might be leveraged for attacks, where critical vulnerabilities are most prominent, and areas to expend resources to ensure critical infrastructure or the information ecosystems remain secure (e.g., from malicious attacks or AI system failures). At a regulatory level, this core of a framework can highlight the risks of specific company policies, such as open model weights or open access, and how, combined with highly capable models, could lead to bad actors harnessing the most capable models or losing control.\nThe presented framing focuses on the interactions and interdependencies across AI system capabilities, access and diffusion, and control measures to highlight under which conditions advanced AI systems could favor offense over defense: A better understanding of these interac-"}, {"title": "5 Future Work", "content": "While this taxonomy offers an initial lens to understand how AI technologies influence societal risk and safety, future research should aim to empirically operationalize it, for example by developing granular quantitative elements for each element. By establishing measurable indicators for factors such as capability breadth, adaptability, and accessibility, the taxonomy's utility for policymakers and practitioners can be significantly enhanced. These metrics would support more precise risk assessments and inform critical decisions related to the development, deployment, and regulation of AI technologies.\nA promising method to operationalize the taxonomy is through the application of graph theory and hypergraphs to fully map the complex interdependencies between its elements. By representing key factors like raw capability potential, adaptability, and sociotechnical context as nodes and edges in a network, researchers can visualize relationships that illustrate how these elements influence offense-defense balances. This graphical representation allows for a clearer understanding of the intricate connections between factors. Using computational models based on these graphs, researchers can simulate different scenarios, predicting how changes in one element affect the overall dynamics. This approach enables the identification of critical nodes"}, {"title": "6 Conclusions", "content": "The advancement of artificial intelligence presents great opportunities for societal benefit alongside significant risks of harm. This paper introduced the a taxonomy of considerations shaping offense-defense dynamics as a means to dissect and understand the factors influencing whether AI technologies contribute more to societal safety or risk.\nBy defining key concepts such as Raw Capability Potential, Accessibility and Control, Adaptability, Proliferation, Diffusion, and Release Methods, Safeguards and Mitigations, and Sociotechnical Context, we provide an initial structured approach to analyze the potential impacts of AI systems. This sociotechnically informed framing underscores that while AI technologies may be inherently neutral, their impact is heavily influenced by how they are developed, deployed, and governed.\nThe implications for AI governance and policy are profound. Policymakers must navigate the delicate balance between fostering innovation and ensuring security, promoting defensive applications while curbing offensive uses. Future work is essential to refine this taxonomy and enhance its applicability, and empirical validation and enhanced modeling will be critical in advancing our understanding of offense-defense dynamics. An emerging Offense-Defense Dynamics Framework may serve as a guide for developing nuanced policies that consider the complex nature of these potent technologies."}]}