{"title": "Weight Scope Alignment: A Frustratingly Easy Method for Model Merging", "authors": ["Yichu Xu", "Xin-Chun Li", "Le Gan", "De-Chuan Zhan"], "abstract": "Merging models becomes a fundamental procedure in some applications that consider model efficiency and robustness. The training randomness or Non-I.I.D. data poses a huge challenge for averaging-based model fusion. Previous research efforts focus on element-wise regularization or neural permutations to enhance model averaging while overlooking weight scope variations among models, which can significantly affect merging effectiveness. In this paper, we reveal variations in weight scope under different training conditions, shedding light on its influence on model merging. Fortunately, the parameters in each layer basically follow the Gaussian distribution, which inspires a novel and simple regularization approach named Weight Scope Alignment (WSA). It contains two key components: 1) leveraging a target weight scope to guide the model training process for ensuring weight scope matching in the subsequent model merging. 2) fusing the weight scope of two or more models into a unified one for multi-stage model fusion. We extend the WSA regularization to two different scenarios, including Mode Connectivity and Federated Learning. Abundant experimental studies validate the effectiveness of our approach.", "sections": [{"title": "Introduction", "content": "As a technique for combining multiple deep models into a single model, model fusion [36, 26] [36] has gained widespread applications across various domains, including Mode Connectivity [4, 9, 10] and Federated Learning [1, 40, 55]. First, the model interpolation could shed light on the properties of the mode connectivity in neural networks [16, 11, 14]. Then, due to data privacy protection, transmitting intermediate models across edge nodes and fusing them on the server has been the common procedure in federated learning [50, 35, 39]. To be brief, model fusion matters a lot in these applications and has attracted a wide range of research interest. The primary goal of model fusion is to retain the capabilities of the original models while achieving improved generalization, efficiency, and robustness.\n\nThe coordinate-based parameter averaging is the most common approach for model fusion in deep neural networks [40, 36, 52]. The research on mode connectivity involves a linear or piece-wise interpolation between models [16, 48], while federated learning takes the averaging of local models from edge nodes for aggregation [40, 7]. Although parameter averaging exhibits favorable properties, it may not perform optimally in more complex training scenarios, especially when faced with various training conditions or Non-Independent and Identically Distributed (Non-I.I.D.) data. For example, the Non-I.I.D. data in federated learning means that the data of local nodes are naturally heterogeneous, making the model aggregation suffer from diverged update directions [21, 24]. Additionally, the property of permutation invariance that neural networks own exacerbates the challenge of model fusion because of the neuron misalignment phenomenon [10, 57, 5, 15]. Hence, solutions have been proposed from the aspect of element-wise regularization [35, 1, 7] or mitigating the permutation invariance [37, 3, 45, 43]. Few of these methods, however, have considered the impact of weight ranges across models on model fusion.\n\nIn this paper, we investigate the influence of different training conditions on model weight distributions (defined as Weight Scope) and further study model merging under various weight scopes. We first conduct several experiments under various training hyper-parameters or data quality conditions and find that the weight scopes of the converged models differ a lot, a phenomenon we define as \"weight scope mismatch\". Figure 1 illustrates the model weight distributions under different training conditions, revealing noticeable differences despite all distributions being approximated by Gaussian distributions. Specifically, the top five sub-figures are parameters from models that use the same optimizer, while the bottom ones take different optimizers. In the rightmost of Figure 1, the linear interpolation results that reflect the mode connectivity property are also provided. Clearly, the mismatched weight scope leads to a worse linear interpolation, highlighting the impact of weight range inconsistency on model fusion. To intuitively explain, parameters with similar distributions can be aggregated more easily, whereas those with dissimilar distributions often present challenges in model merging."}, {"title": "Related Works", "content": "Model fusion is a fundamental technique in several applications. The related scenarios and solutions are introduced as follows.\n\nModel Merging in Mode Connectivity. Visualizing loss landscape is an intuitive way to understand the mode connectivity [33, 17, 38], where the landscape is shown in a 2-dim or 3-dim space via model interpolations. The model interpolations between the initialization and the converged model could reflect the monotonic linear interpolation phenomenon [16, 11, 51, 46]. [13] bridges the model connectivity and lottery ticket hypothesis [12], proposing a method for model pruning. Mode connectivity is also related to the model optimization and generalization [29, 8].\n\nThe work [16] also points out that two independent minima suffer a barrier in their linear interpolation, which attracts several solutions to decrease the barrier. [9, 14] make a notable discovery that the independent minima are possible to be connected via a simple piece-wise or quadratic curve. [42, 52] find that the minima fine-tuned from the same pre-trained model could mitigate the barrier in linear interpolation. [10] guesses that the independent minima are located in the same basin with the consideration of permutation invariance, conjecturing that the minima matched via the simulated annealing algorithm encounter no barrier. [45] propose the weight-based and activation-based matching method via the optimal transport. [47] decreases the barrier via both the permutation alignment and the quadratic curve. [3] employs three distinct neuron-matching methods to corroborate the low-barrier hypothesis. Although the permutation invariance is considered in these works, the mismatch of weight scope in neural networks is also fundamental to model fusion. Our proposed method could further decrease the barrier on the basis of these works.\n\nModel Merging in Federated Learning. Federated learning (FL) aims to break the limitation of data privacy, utilizing a server that collaborates with client devices to train a model [55]. As the most standard algorithm in FL, FedAvg [40] takes a simple coordinate-based parameter averaging on the server to accomplish the model fusion process. A huge challenge that FL faces is the Non-I.I.D. data [21, 28], where the inherent data heterogeneity leads to weight divergence during local training [24]. Applying coordinate-wise regularization on local models is a popular solution to solve the Non-I.I.D. challenge in FL. [34] claims that weight decay [32] can lead to divergent optimization objectives among Non-I.I.D. clients in FL. [60, 35] introduce a proximal term in local optimization. This term helps align local optimization more closely with given model parameters, facilitating model aggregation. Additionally, [28] implements constraints on the local gradient directions of each client, nudging them closer to a global direction. However, the coordinate-wise regu-"}, {"title": "Proposed Methods", "content": "3.1 Preliminaries\n\nWe introduce a collection of models, denoted as K, with the size of the collection |K| \u2265 1. Each model within this collection is constructed based on the same underlying model architecture. The distinctiveness among the models in K arises from the variations in their weight layers, which are derived from training under various hyper-parameters or different data.\n\nTo encapsulate the statistical characteristics of the weight layers across different models, we denote the weight matrix of the lth layer in the kth model as w\u02e1\u2096. Our assumption is that the elements within this matrix follow a Gaussian distribution which is characterized by its mean \u00b5\u02e1 and standard deviation \u03c3\u02e1. The assumption is rational and we will empirically present the weight distributions of the converged model in Section 5.1. Formally, the distribution of the weight matrix w\u02e1\u2096 is as follows:\n\np(w\u02e1\u2096) = N(\u00b5\u02e1, (\u03c3\u02e1)\u00b2),    (1)\n\n\u00b5\u02e1 = \\frac{1}{|w\u02e1\u2096|} \u2211_{w\u2208w\u02e1\u2096} w, \u03c3\u02e1 = \u221a{\\frac{1}{|w\u02e1\u2096|} \u2211_{w\u2208w\u02e1\u2096} (w - \u00b5\u02e1)\u00b2}.     (2)\n\nIn Equation 2, we apply Maximum Likelihood Estimation to derive the standard deviation \u03c3\u02e1 and mean \u00b5\u02e1 of the weight w.\n\n3.2 Weight Scope Alignment\n\nFirstly, we introduce Weight Scope Regularization. Then, for more complex multi-stage fusion, we propose Weight Scope Fusion for better target alignment.\n\nWeight Scope Regularization. Given a weight distribution N(\u03bc, \u03c3\u00b2) and a target weight distribution N(\u03bc\u0303, \u03c3\u0303\u00b2), our method endeavors to ensure consistency between them. This consistency is crucial for guaranteeing scope-matched distribution among the new models in the subsequent model fusion. To achieve this, we employ a divergence measure known as the Kullback-Leibler (KL) divergence, specifically focusing on calculating the divergence between the two univariate Gaussian distributions, which is given by:\n\n D_{KL} = \\frac{1}{2} [log(\\frac{\\tilde{\u03c3}\u00b2}{\u03c3\u00b2}) + \\frac{\u03c3\u00b2 + (\u03bc - \\tilde{\u03bc})^2}{\\tilde{\u03c3}\u00b2} - 1] ,       (3)\n\nwhere \u03bc\u0303, \u03c3\u0303 are hyperparameters. By minimizing the KL divergence between the training models' weight distribution and their goal, it ensures that the weight distributions are closely aligned, facilitating more effective and harmonious model fusion.\n\nWeight Scope Fusion. In some complex scenarios with large amounts of models and multiply stages of model merging, a given pre-defined weight distribution is not adaptable. Therefore, we propose a method named Weight Scope Fusion to enhance the applicability of Weight Scope Regularization. Focusing on the weights of the lth layer, we assume that each weight w\u02e1\u2096, k \u2208 K, follows its own Gaussian distribution, and they are independent of each other. We can get the fused Gaussian distribution N(\u03bc\u0303\u02e1, (\u03c3\u0303\u02e1)\u00b2) by:\n\n\u03bc\u0303\u02e1 = \\frac{1}{|K|}\u2211_{k\u2208K} \u03bc\u02e1\u2096, (\u03c3\u0303\u02e1)\u00b2 = \\frac{1}{|K|}\u2211_{k\u2208K} (\u03c3\u02e1\u2096)\u00b2.        (4)\n\n3.3 Analysis and Comparisons with Other Methods\n\nWe next provide some analysis of the proposed simple method, especially the comparisons with existing works.\n\nComparison with Weight Decay. Weight decay [32] stands as a cornerstone in model regularization, advocating for weight constraints that push the weights towards zero and promote uniformity. Considering a weight vector, denoted as w\u2208 R\u207f, with elements [w\u2081, w\u2082,..., w\u2099]. For ease of analysis, we define the mean, standard deviation, and L2 norm of this vector as follows: \u03bc = \\frac{1}{n}\u2211_{i=1}^{n} w\u1d62, \u03c3 = \u221a{\\frac{1}{n}\u2211_{i=1}^{n}(w\u1d62 - \u03bc)\u00b2, ||w||\u2082 = \u221a{\u2211_{i=1}^{n} w\u1d62\u00b2}.\n\nThe weight decay term is formulated as \u03bb||w||\u2082\u00b2. We can express weight decay in terms of \u03bc and \u03c3 as follows:\n\n\\frac{\u03bb}{2} ||w||\u2082\u00b2 = \\frac{\u03bbn}{2} (\u03c3\u00b2 + \u03bc\u00b2).         (5)\n\nThe weight decay term brings the mean and variance of model weights close to zero, and several research [1, 28] has designed FL algorithms with adjustment of weight decay term in local training. However, the impact of weight decay on models can not determine the shape of weight distributions and could not align parameter distributions under different conditions. Hence, it does not necessarily lead to a harmonization of the model scopes before fusion.\n\nComparison with Proximal Term. The proximal term is used to keep the model weight w and another one w\u0303 \u2208 R\u207f as close as possible during the update of w, which is represented as ||w \u2212 w\u0303 ||\u2082\u00b2. In FedProx [35], the proximal term constrains the local models to stay close to the global model, thereby ensuring stability during model fusion. For clarity, we also define \u03bc\u0303 and \u03c3\u0303 as the mean and standard deviation of vectors w\u0303. The proximal term can be decomposed as follows:\n\n||w - w\u0303||\u2082\u00b2 = n\u03c3\u00b2 + n\u03bc\u00b2 + n\u03c3\u0303\u00b2 + n\u03bc\u0303\u00b2 - 2 \u2211_{i=1}^{n} w\u1d62 w\u0303\u1d62.        (6)\n\nBecause the part of n\u03c3\u0303\u00b2 + n\u03bc\u0303\u00b2 can be seen as a constant term, the proximal term differs from weight decay by only an additional term of -2 \u2211_{i=1}^{n} w\u1d62 w\u0303\u1d62, which encourage the weights in w to align with the direction of w\u0303 as closely as possible. However, the restriction is too strict because it requires the direction alignment for each specific element. This may limit the normal training process and perturb the effects of other loss functions.\n\nIn the context of model fusion, weight decay represents a more flexible approach, while the proximal term seems to introduce directional constraints additionally. Both of them have overlooked the influence of weight scope on model fusion and are unable to align weight scopes, as demonstrated in Figure 11. Our proposed method aims to achieve consistency in model weight ranges for improved model fusion results."}, {"title": "Applications of WSA", "content": "This section presents the applications of Weight Scope Alignment to mode connectivity and federated learning. They can be seen as one-stage and multi-stage model fusion scenarios, respectively. While the specific processes or the model set to be fused may differ across them, they all share the common thread of leveraging the proposed WSA as a constraint during training.\n\n4.1 Mode Connectivity\n\nGiven two well-trained models, w\u2081 and w\u2082, the loss barrier along their linear interpolation path is:\n\nmax_{\u03b1\u2208[0,1]} L ((1-\u03b1)w\u2081 + \u03b1w\u2082) \u2013 [(1 \u2212 \u03b1)L (w\u2081) + \u03b1L (w\u2082)],       (7)\n\nwhere \u03b1 is the interpolation coefficient, and the loss barrier represents the point of maximum loss increase along the linear interpolation path. A higher loss barrier suggests that the two models may not be in the same basin within the loss landscape, while a lower loss barrier indicates linear mode connectivity.\n\nBoth OTFusion [45] and Git Re-basin [3] have improved the way they perform model interpolation by considering neuron matching. They calculate matching relationships \u03a0 between the weights of each layer in the two models, using a permutation matrix or optimal transport matrix, leading to the fusion formula:\n\n(1 \u2013 \u03b1)w\u2081 + \u03b1\u03a0w\u2082.        (8)\n\nOur approach can easily be integrated into the aforementioned model interpolation methods to achieve improved mode connectivity. For separately trained models, they are typically randomly initialized from the same distribution, and their weight scopes are similar. The mean \u03bc\u0303 and standard deviation \u03c3\u0303 of the target weight distribution are the hyperparameters and keep invariant during each model's training. We incorporate a Weight Scope Regularization term (i.e., Equation 3) to ensure that the weight range remains close to the target weight scope. With our method, the weight scope of the converged models are matched, which is beneficial for searching the matching matrix.\n\n4.2 Federated Learning\n\nModel fusion is a fundamental procedure in Federated Learning (FL), i.e., improving the performance of joint training by merging models trained on different data sources. Its challenge lies in the fact"}, {"title": "Experiments", "content": "In Section 5.1, we verify that different training conditions lead to variations in weight scope, and the differences between weight scope can affect the performance of model merging. In Section 5.2, we explore the effectiveness of the WSA method in the mode connectivity scenario. In Section 5.3, we demonstrate the performance improvements achieved by WSA in various federated learning scenarios and analyze the impact of the method.\n\n5.1 Basic Experiments\n\nObservations. Our basic assumption is that the weight scope could be formulated as the Gaussian distribution. Hence, we first study the weight distributions of the models. The first observation is that the converged weight scope is irrelevant to the way of weight initialization, e.g., the Kaiming uniform or the Kaiming normal initialization method [18]. Figure 3 shows the weight distributions of several layers in VGG16 [44] with BatchNorm [23], where we train the network on CIFAR-100 [31] for 200 epochs. In the Appendix, we will present\nThe Influence of Weight Scope on Model Fusion. We then investigate the difference of weight scope under different conditions, which include: 1) hyperparameters, e.g., optimizer, batch-size, learning rate, and weight decay; 2) data quality, e.g., label imbalance, label noise, feature noise, and data size. For each condition, we select two specific settings, and then train models under the same setting or not. For example, the optimizer could be SGD or Adam [30], and we train three models with each using SGD, SGD, and Adam as the optimizer, respectively. Then, we plot the weight scopes of these models and investigate the linear interpolation accuracy. Figure 1 shows that models trained using different optimizers own varying weight scopes and the interpolation meets an obvious barrier. The details of training conditions and the corresponding illustration results can be found in the Appendix.\n\nFrom Figure 1, we can observe that the weight scopes under the same training condition are near the same. In fact, we calculate their KL divergence, and the results are near zero. Hence, we calculate the average KL divergence of weight scopes under different conditions, e.g., the average divergence of Gaussian distributions in the bottom five sub-figures (the \"KL D.\" column in Table 1). Additionally, we calculate the barriers of the two interpolated curves, and their difference, which are listed in columns of \"Ba(=)\", \"Ba(\u2260)\", and \"Diff\" in Table 1. In the table, the \"Ba(=)\" column is commonly smaller than \"Ba(\u2260)\", which verifies that models under the same condition are indeed similar in weight scopes. Empirically, for models under different conditions, a larger KL divergence corresponds to a larger"}, {"title": "Performance in Mode Connectivity", "content": "To investigate the effectiveness of our approach on mode connectivity, we apply the proposed WSA to OTFusion [45] and Git Re-Basin [3]. Specifically, we first initialize and train two models, and plot the vanilla interpolation curve. Then, we use the activation-based OTFusion method to search for an alignment and plot the interpolated curve after matching. Finally, we replace the models with another two models trained using the WSA as introduced in Section 4.1 and also use the OTFusion to search the alignment matrix. The results are shown in Figure 5. OTFusion could decrease the barrier of vanilla interpolation, and our proposed WSA could improve its performance further.\n\nThen, we combine our WSA with Git Re-Basin, which searches the permutation matrix instead of an optimal transport matrix compared with OTFusion. Similar to OTFusion, we also train models"}, {"title": "Federated Learning", "content": "To simulate various clients, we employ a Dirichlet distribution to allocate data across clients for the CIFAR-10, CIFAR-100, and CINIC-10 datasets [22], utilizing the parameter a to control data heterogeneity. Figure 17 and Figure 18 depict the data distribution among clients for a values of 0.5 and 1.0, respectively, with lower a values indicating increased data heterogeneity. The training convergence curves in 10 clients and 100 clients setting are illustrated in Figure 19.\n\nOur experiments are conducted using the FedExP framework \u00b2. The experimental setup includes a learning rate of 0.01, weight decay of 10\u207b\u2074, a decay of the learning rate by 0.998 in each round, a maximum gradient norm of 10, a fusion alpha of 1.0, and 20 local steps for all models and datasets. Specifically for FedProx, \u03bc is set to 0.1, 1, and 0.001 for CIFAR-10, CIFAR-100, and CINIC-10, respectively. In the case of FedExp, \u03f5 is maintained at 0.001 which is identified as the optimal value for all three datasets in [25]."}, {"title": "Conclusion", "content": "In this study, we investigate the impact of different weight ranges of model parameters on model merging. We observe that models trained under various conditions exhibit inconsistencies in their weight ranges, leading to a decrease in fusion performance. To address this issue, we propose Weight Scope Alignment method, which utilize Weight Scope Regularization to constrain the alignment of weight scopes during training, ensuring that the model's weights closely match the specified scope. Moverover, for multi-stage fusion scenarios, we design Weight Scope Fusion to fuse the weight scopes"}]}