{"title": "A Cascaded Dilated Convolution Approach for Mpox Lesion Classification", "authors": ["Ayush Deshmukh"], "abstract": "Abstract-The global outbreak of Mpox virus, classified as a Public Health Emergency of International Concern by WHO, presents significant diagnostic challenges due to its visual similarity to other skin lesion diseases. Current clinical detection techniques face limitations in accuracy and efficiency, necessitating improved automated diagnostic solutions. This study introduces a novel Cascaded Atrous Group Attention (CAGA) module, specifically designed to enhance multi-scale feature representation while optimizing computational efficiency. By integrating CAGA with EfficientViT-L1 as the backbone architecture, this approach achieves state-of-the-art performance with a score of 0.98 \u00b1 0.0229 on the MCSI dataset, while reducing model parameters by 37.5% compared to the original EfficientViT-L1. This reduction in computational complexity maintains diagnostic accuracy while enabling broader deployment across resource-constrained healthcare settings. Extensive validation across two other benchmark datasets, including MSID and MSLD, demonstrate the model's robustness, consistently outperforming existing approaches. Findings suggest that CAGA's efficient feature extraction mechanism could be adapted for other medical imaging tasks requiring fine-grained visual discrimination. Code and model are available here.\nIndex Terms-Mpox Classification, Image Classification, Vision Transformers, Atrous Attention", "sections": [{"title": "I. INTRODUCTION", "content": "The recent global outbreak of the Mpox virus has posed significant challenges for public health authorities and researchers worldwide [1] [2]. As this zoonotic disease rapidly spread beyond endemic regions, it affected multiple non-endemic countries, including the Netherlands [2], Greece [3], Portugal [4], and France [5]. To date, the outbreak has infected over 100,000 individuals across hundreds of countries [6]. This surge has made the need for effective detection and diagnostic methods increasingly urgent. Traditional approaches relying on clinical symptoms and laboratory testing have proven slow and laborious in the face of this evolving outbreak [7] [8].\nThe clinical presentation of Mpox shares notable similarities with other skin lesion-based diseases, such as Chickenpox and Measles. Like these conditions, Mpox can manifest with a range of skin lesions, including rashes and vesicular eruptions, which can complicate the differentiation between these diseases. This overlap with other diseases that present with comparable skin lesions has posed significant challenges in distinguishing Mpox from other infectious diseases with similar manifestations, thereby impacting the accuracy and timeliness of diagnosis [9].\nFurthermore, the limitations of existing diagnostic techniques, including reporting delays and the challenges in identifying transmission sources, have further exacerbated the detection challenges. The need for improved, timely, and accurate detection methods has become paramount to contain the outbreak and mitigate its public health impact. In response to this escalating crisis, the World Health Organization (WHO) declared Mpox a Public Health Emergency of International Concern (PHEIC).\nOver the last decade, Convolutional Neural Networks have had tremendous impact in skin lesion classification [10] [11] [12] [13]. The emergence of these deep learning methodologies presents a promising avenue for Mpox detection and management [14] [15].\nWhile progress has been made in infectious disease imaging, research on Mpox remains limited. These investigations have primarily concentrated on three critical methodological domains: adapting pre-trained medical imaging models [16] [17], developing specialized neural network structures [18], and implementing advanced feature extraction techniques to capture the unique morphological characteristics of Mpox skin lesions [19].\nWhile early applications of deep learning to Mpox detection show promise, they are constrained by several critical methodological issues. The current research landscape is marked by considerable variation in model development and validation, with many studies evaluating models using only a single dataset. Moreover, comparative studies often use flawed assessment strategies, such as comparing attention-based models against a narrow set of non-attention-based architectures. These limited comparisons compromise the scientific reliability of performance assessments in Mpox detection.\nDespite the demonstrated effectiveness of transformer-based architectures in skin lesion classification [20] [21], their application to Mpox detection has been remarkably limited. Most existing studies focus predominantly on traditional Convolutional Neural Networks or basic custom architectures, leaving a significant gap in leveraging the capabilities of transformer models for this specific task.\nThe lack of standardized benchmark datasets and consistent evaluation metrics further complicates the comparative analysis of different deep-learning approaches for Mpox detection. These methodological constraints have hindered the translation of research findings into clinical practice. They also raise significant concerns about the reliability and robustness of current computational diagnostic techniques. Consequently,"}, {"title": "II. RELATED WORKS", "content": "Convolutional Neural Networks (CNNs) have been instrumental in advancing the field of computer vision [22] [23] [24] [25] [26] [27]. In recent years, Transformers [28] have achieved remarkable success in natural language processing (NLP) tasks. Inspired by this success, researchers have explored the application of Transformers to computer vision, with one of the most influential efforts being the Vision Transformer (ViT) [29]. ViT was one of the first pure Transformer-based models to achieve state-of-the-art results on ImageNet. Unlike CNNs, which rely on local receptive fields and other inductive biases, ViT processes images as sequences of patches, enabling a more global understanding of the visual content. However, their lack of inherent inductive biases, such as locality, makes them computationally intensive and heavily dependent on large-scale data [29] [30] [31] [32]. Hybrid architectures [33] [34] [35] [36] [37] seek to balance these trade-offs, integrating convolutional operations to model local features while leveraging attention mechanisms for global context. This study enhances the convolutional backbone of EfficientViT [38] by integrating a novel Cascaded Atrous Group Attention mechanism, which significantly improves its computational efficiency and performance.\nDeep learning has shown promise for Mpox classification, offering potential improvements in early diagnosis and outbreak control. As noted in [39], these algorithms are effective in diagnosing Mpox from skin lesions but still face challenges in development and implementation.\n[19] created a dataset of 139,198 skin lesion images, with Mpox and non-Mpox cases. They developed the MPXV-CNN, a deep convolutional neural network that demonstrated high sensitivity and specificity in validation and testing, and introduced PoxApp, a web-based tool that facilitates its use in patient management. [18] presented a novel approach for Mpox detection using an attention-powered MobileNetV2 architecture. The authors emphasized the importance of interpretability"}, {"title": "III. METHODOLOGY", "content": "This section presents the Cascaded Atrous Group Attention (CAGA) framework. I first provide a comprehensive overview of the framework, followed by detailed explanations of its key components: the Cascaded Atrous Attention (CAA) module and the Cascaded Group Attention (CGA) mechanism.\nI introduce Cascaded Atrous Group Attention (CAGA), (see Fig. 1 (right)) an architecture that builds upon the Cascaded Group Attention (CGA) [41] framework. While the CGA directly processes each attention head using standard self-attention, this work replaces this mechanism with the proposed Cascaded Atrous Attention (CAA). By integrating multi-scale dilated convolutions and a sophisticated self-attention mechanism for each dilation, CAA enhances the feature representation capabilities of the CGA approach.\nI propose a multi-scale feature extraction module called Cascaded Atrous Attention (CAA). This module leverages parallel dilated convolutions to effectively capture contextual information at multiple receptive fields. Building upon ASPP's use of varying dilation rates, CAA introduces a cascaded approach that combines dilated inputs with a self-attention mechanism for enhanced feature representation. Fig. 2 provides an illustration of the proposed CAA module.\nI incorporate dilation rates $d \\in \\{1,2,3\\}$ applied to convolution operations with kernel size $k \\times k$ (typically $3 \\times 3$) across each attention head $X_i \\in R^{h\\times H \\times W}$, where $(H,W)$ is the resolution, h denotes the dimensionality of the attention head, and $1 < i < n$, where n is the total number of heads. Which is followed with a 1 \u00d7 1 convolution to transform the feature map into appropriate dimensionality required for self attention. Let $H' = \\frac{H-k}{s}+1$ and $W' = \\frac{W-k}{s}+1$, then the output after dilated convolution is denoted as $X^{d \\in \\{1,2,3\\}} \\in R^{(3 \\times d_{qkv}) \\times H' \\times W'}$,\nwhere $k_{eff} = k + (k - 1)(d \u2013 1)$ represents the effective kernel size. Here, $d_{qkv}$ is the dimension of query, key, and value embeddings, and s is the stride. The resulting feature map is split into $Q_d, K_d,V_d \\in R^{d_{qkv} \\times (H' \\times W')}$ and passed to the self-attention module. The self-attention then is computed as:\n$Attn_d = Softmax(\\frac{Q_d(K_d)^T}{\\sqrt{d_{qkv}}}) V_d$ (1)\nI introduce a hierarchical cascading approach to dilated-self-attention maps, enabling a progressive spatial context aggregation mechanism. The model incrementally integrates proximal and broader neighborhood features, creating a multi-scale representation that captures nuanced spatial dependencies across different contextual granularities. To address dimensionality disparities between the dilated attention maps and subsequent dilated convolutional inputs, I implement a 1 \u00d7 1 convolution projection layer, thereby ensuring dimensional consistency.\n$X^i = X + Proj(Attn_{d-1}), \\quad 1 < d \\leq 3$ (2)\nEach dilated attention map is interpolated to restore the feature representation to its original spatial resolution of (H, W). These maps are then concatenated and subsequently projected back to match the attention head dimensionality."}, {"title": "IV. EXPERIMENTAL RESULTS AND ANALYSIS", "content": "This section introduces the dataset and implementation details, followed by a comparison of the proposed approach with state-of-the-art methods. The proposed methodology is compared to six models, which are shown in Table II. All the models mentioned in Table II are pre-trained on ImageNet.\nIn contrast, for EfficientViT-CAGA, only the EfficientViT convolutional backbone is pre-trained, while the DSConv and CAGA module are initialized using the Xavier uniform method.\nTo evaluate the performance of the proposed method, I selected three benchmark datasets. All images in the datasets are resized to 224 x 224.\nThe Mpox Close Skin Image Dataset (MCSI) [17] comprises four classes: Mpox, Chickenpox, Acne, and Normal, with each class containing 100 images.\nThe Monkeypox Skin Images Dataset (MSID) [51] contains 770 total images distributed across four classes: Mpox, Chickenpox, Measles, and Acne.\nThe Monkeypox Skin Lesion Dataset (MSLD) [52] [53] is a binary classification dataset with two classes: Mpox and Others (comprising Chickenpox and Measles). The total dataset size is 228 image.\nI utilize the ImageNet pre-trained EfficientViT-L1 [38] as the backbone architecture, with the head initialized randomly. The implementation is done using PyTorch [54] and trained on Tesla T4 GPUs. For pre-trained models I use Pytorch Image Models [55]. I employ the AdamW optimizer with a learning rate on the order of 10\u20135. The learning rate is adjusted using an ExponentialLR scheduler with a decay rate of 0.95, and training is regulated by an Early Stopping mechanism with a patience of 9 epochs.\nFor the CAA module, I utilize dilation rates d\u2208 {1,2,3}, which are adjusted for each dataset, across a total of 3 attention heads. Each attention head has an embedding dimension of 16, while the dimensions for the query, key, and value embeddings (dqkv) are set to 8. The weights are initialized using the Xavier uniform method.\nThe bolded results for each metric indicate the highest score among all models, while the second-highest scores are underlined. For parameters and FLOPs, the smallest value is bolded, and the second smallest is underlined.\n$X_i = X + X_{i-1}, \\quad 1 < i < n$ (3)\n$X = X + Proj(Concat[X_i]_{i=1:n})$ (4)"}, {"title": "V. CONCLUSION", "content": "In this work, I explored the use of Atrous Attention to effectively capture multi-scale context for Mpox skin lesion classification. I introduced the novel Cascaded Group Attention (CAGA) module, which significantly reduces computational complexity while maintaining state-of-the-art performance across multiple benchmark Mpox classification datasets. In future work, I aim to expand the application of CAGA to broader tasks, including disease segmentation and object detection, further showcasing its versatility."}]}