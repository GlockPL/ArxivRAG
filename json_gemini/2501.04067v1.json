{"title": "Explainable Time Series Prediction of Tyre Energy in Formula One Race Strategy", "authors": ["Jamie Todd", "Junqi Jiang", "Aaron Russo", "Steffen Winkler", "Stuart Sale", "Joseph McMillan", "Antonio Ragot"], "abstract": "Formula One (F1) race strategy takes place in a high-pressure and fast-paced environment where split-second decisions can drastically affect race results. Two of the core decisions of race strategy are when to make pit stops (i.e. replace the cars' tyres) and which tyre compounds (hard, medium or soft, in normal conditions) to select. The optimal pit stop decisions can be determined by estimating the tyre degradation of these compounds, which in turn can be computed from the energy applied to each tyre, i.e. the tyre energy. In this work, we trained deep learning models, using the Mercedes-AMG PETRONAS F1 team's historic race data consisting of telemetry, to forecast tyre energies during races. Additionally, we fitted XGBoost, a decision tree-based machine learning algorithm, to the same dataset and compared the results, with both giving impressive performance. Furthermore, we incorporated two different explainable AI methods, namely feature importance and counterfactual explanations, to gain insights into the reasoning behind the forecasts. Our contributions thus result in an explainable, automated method which could assist F1 teams in optimising their race strategy.", "sections": [{"title": "1 Introduction", "content": "Formula One (F1) is a popular sport all over the globe, with some Grand Prix races exceeding 100 million TV viewers. The significant prize pools mean that competing teams will go to great lengths to maximise the performance of their cars. Because of this, analysing historical race data is essential for teams as they provide useful insights into how various factors affect the car performance. One of the most important factors is the tyre degradation, i.e. how different tyre compounds wear and degrade over time, which lowers the grip they provide and thus the car's speed. This means teams must optimise their strategies in their selection of which tyre compounds to use and when to pitstop, i.e. leave the race to change tyres. A major contributor to the rate of tyre degradation is the fluctuating energy applied to each tyre, i.e. the tyre energy. This energy represents the sliding power, which is calculated using a physics-based model, comprising variables such as the forces on the tyre and the slip velocity. Al models have not as of yet, as far as we are aware, been used in F1 to forecast tyre degradation. The industry standard for predicting this phenomenon is using simple linear models, which are clearly trustworthy but are often manually calculated and thus time-consuming, and do not take covariate data into account.\nMeanwhile, sophisticated time series prediction models such as Long Short-Term Memory (LSTM) [8] and Transformers [22] have"}, {"title": "2 Related Work", "content": "Time series prediction (also referred to as time series forecasting) concerns training a model to predict the future values of targets based on their previously observed values and/or that of covariates. These covariates are external variables that can be used as inputs to help improve the accuracy of predictions.\nVarious deep learning architectures have been integrated into time series forecasting. RNNs have been the basis of many forecasting models, such as DeepAR by Salinas et al. [19]. The LSTM architecture [8], a specialised form of RNN, has shown great potential in applying time series forecasting in fields such as macroeconomics [11] and iron-making [20]. Transformers [22], which were designed to handle sequence-to-sequence tasks, also see effective use in forecasting time series. PatchTST by Nie et al. [16], a Transformer-based model, was the first to be trained on \"patched\" time series, where the input series is divided into equal-sized patches, inspiring other models such as TSMixer [7], a lightweight model composed entirely of multi-layer perception modules. Meanwhile, the Temporal Fusion Transformer (TFT) by Lim et al. [15] pushed the state-of-the-art in terms of both accuracy and innovation, consisting of an interpretability module,\nAccurate predictions alone may not warrant the use of such models in high-risk industries, as the models' lack of interpretability requires users to blindly trust their predictions, which would mean that risks are taken without justification. \u03a7\u0391\u0399 methods aim to help users understand how Al models compute outputs in an accessible manner [2]. The best XAI methods should be (among other features) interpretable and trustworthy [17], features which would undoubtedly be desirable in this application.\nFeature importance is one of the most popular explanation types for tabular data, assigning an importance value to each feature reflecting how significant the feature was when computing the prediction [3]. Temporal Importance Model Explanation (TIME) by Sood et al. [21] is an XAI method based on feature importance that calculates the importance of each input feature for the model at each time step. This is achieved via repeatedly perturbing the input tensor fed to the model and analysing the differences in results, enabling the user to know when and to what degree certain variables contribute to the model's output.\nCounterfactual explanations assess how a model was dependent on external factors when making a particular prediction, focusing on the differences to obtain the opposite prediction [3]. CausalImpact by Brodersen et al. [4] is a method based on counterfactual explanations which infers the impact of an \"intervention\" (an event that significantly affects future target values) on time series data, achieved by modelling the counterfactual scenario where the intervention did not occur and comparing the difference.\nIn this paper, we will experiment with both TIME and CausalImpact. To the best of our knowledge, there are no"}, {"title": "3 Time Series Forecasting of Tyre Energy", "content": "In this section we detail our study, namely: the dataset used (\u00a73.1); the track state encodings (\u00a73.2); how the data was partitioned (\u00a73.3); our problem formulation (\u00a73.4); and the deployed forecasting models and XAI methods (\u00a73.5)."}, {"title": "3.1 Time Series Data", "content": "We were provided with both serialised and tabular raw data by the Mercedes-AMG PETRONAS F1 Team, taken from real-time sources such as the car telemetry and GPS. After processing, aligning and merging the raw data, we produced a tabular time series of 0.1s resolution for each race and both drivers from the team, covering the 2020 to 2023 seasons. Some events were excluded as will be discussed in \u00a73.3. Each time series contained the following covariates:\n\u2022 Time into race (float);\n\u2022 Car speed and its uncertainty (float);\n\u2022 Lap number (int);\n\u2022 Distance around track and distance uncertainty (float);\n\u2022 Steering wheel angle (float);\n\u2022 Under/oversteer coefficient (float);\n\u2022 Lift and coast (boolean) and its distance (float);\n\u2022 Gear (int);\n\u2022 Brake (percentage from 0-100);\n\u2022 Throttle (percentage from 0-100);\n\u2022 Engine speed (float);\n\u2022 Fuel load (float);\n\u2022 Track temperature (float);\n\u2022 Pit stop status (boolean);\n\u2022 DRS enabled (boolean) and Pod disabled (boolean);\n\u2022 Track state (categorical, see \u00a73.2).\nThe target variables were the energies applied to each of the four tyres. Time was measured from the race start (time = 0) until the end of the raw data sources (roughly five seconds after the car crosses the finish line). In addition to the above covariates, the car's latitude and longitude were stored for visualising model performance around the track, but were not an input to the model."}, {"title": "3.2 Track State Encodings", "content": "The track state is a categorical covariate, representing the current race conditions. In F1, green-flag signifies standard conditions, yellow-flag prohibits cars from overtaking due to a minor incident, and red-flag conveys a race suspension, where cars must drive carefully to the pit lane. Safety cars and virtual safety cars deploy in response to track incidents, enforcing cars to adhere to strict speed limits. Thus, the track state significantly influences other covariates, such as car speed, and so four distinct encoding methods were evaluated:\n\u2022 exclude the track state from the input data entirely;\n\u2022 one-hot encoding the state;\n\u2022 encode the state in order based on expected car speed;"}, {"title": "3.3 Dataset Partitioning", "content": "Since there are a wide variety of tracks in F1, fixed training, validation and test sets were decided on with the following properties:\n\u2022 The training, validation and test sets consisted of 20, 6 and 7 events respectively, ranging from the 2020 to 2023 seasons.\n\u2022 Each event had 2 races, one for each Mercedes driver, with the end of one race being immediately followed by the start of the next race.\n\u2022 The datasets contained a mixture of faster open tracks and slower street circuits, to explore the models' adaptability to various environments.\n\u2022 The validation and test sets contained both seen and unseen tracks. A seen (unseen) track was one the models had (had not, respectively) been trained on from another season.\nRaces that took place under wet conditions, were suspended, or lacked necessary data were excluded from the datasets."}, {"title": "3.4 Problem Formulation", "content": "For each time step of the test set, the time series forecasting model received the previous 100 time steps of input data and needed to forecast the immediate next value for the energies of each tyre (giving four targets in total). Contrary to standard forecasting tasks, the input data contained only covariate values; no past ground truth values for tyre energies were supplied to the model. The model's objective was to minimise the root mean squared error (RMSE) of the complete test set for the tyre energies."}, {"title": "3.5 Forecasting Models and XAI Methods", "content": "The following deep learning models were developed using the PyTorch library for time series forecasting: RNN [18], LSTM [8] and Gated Recurrent Unit (GRU) [6]. In addition, the TFT [15] was adapted for this task using the PyTorch Forecasting library. Linear regression and XGBoost [5], both statistical approaches, were integrated as baselines.\nTo provide insight into the models' predictions, we incorporated both TIME [21], a temporal Feature Importance algorithm, and CausalImpact [4], a statistical Counterfactual Explanation method."}, {"title": "4 Evaluation and Discussion", "content": "In this section, we evaluate and discuss the results of the time series forecasting models (\u00a74.1) and the incorporated XAI algorithms (\u00a74.2). Our experiments were conducted on a Linux cluster with AMD EPYC 7742 CPU, 1TB RAM, and RTX 6000 GPU."}, {"title": "4.1 Time Series Forecasting", "content": "We first performed hyperparameter tuning on the training set to optimise our deep learning models, utilising state-of-the-art"}, {"title": "4.2 Explainable AI", "content": "Figure 6 ranks the feature importance of the observed covariates for the green-flag TFT, taken from its in-built interpretability module. Steering WheelAngle, which affects how sharply the car takes corners, is the most important variable for forecasting tyre energies. Overall, the ranking of the variables is logical and is along the lines of what we were expecting, with the most relevant covariates having greater significance. For example, PitStop, which signifies whether a pit stop is taking place, is the second most important variable. This is intuitive as a car is stationary during a pit stop and thus no energy is applied to the tyres.\nTIME [21] produces a heat map as shown in Figure 7, which displays the temporal feature importance for the generalised TFT model. This heat map covers a ten-second window of a corner turn,"}, {"title": "5 Conclusions and Future Work", "content": "In this work, we implemented and trained three different recurrent neural network models, and integrated a state-of-the-art transformer model, to forecast tyre energies given only past covariate data. While all of these models vastly outperformed the linear regression baseline, XGBoost proved to be a very powerful tool for this particular time series forecasting task, albeit with its weaknesses such as high memory requirements and rigid training time. Despite this, we found alternative methods to improve model accuracy, such as specialising models to particular tracks. Furthermore, we incorporated XAI techniques to justify the models' predictions.\nFuture work will be focused on extending the models' capabilities to handle practice and qualifying session data to boost accuracy, as well as reconsidering which covariates could be added or removed to improve performance. More explainability methods could be utilised and assessed alongside those we have introduced here, both empirically with datasets and in user studies with race strategists to determine their effectiveness along typical XAI properties such as faithfulness [9], i.e. how closely the explanations replicate the models, and trust [10], i.e. how much users are willing to trust the model. The real-world use of our models is currently limited to post-race analysis due to their iterative processing of complete race data. Enhancing our models to process real-time data and compute predictions on the fly will extend their use to live races, potentially giving F1 teams an edge over their competitors. Finally, we would like to investigate how our models translate to the wider automotive industry, given the increasing importance of tyre degradation for air pollution as electric vehicles become widespread [12]."}]}