{"title": "Athena: Retrieval-augmented Legal Judgment\nPrediction with Large Language Models", "authors": ["Xiao Peng", "Liang Chen"], "abstract": "Recently, large language models (LLMs) like ChatGPT, LLaMA, and Claude\nhave prevailed in countless domains, including legal scenarios. With LLMs' rapid\ntechnological progress, the development of prompt engineering (PE) as an inter-\nface between the LLMs and real-world applications has drawn the attention of all\ndevelopers. Various PE methods have been proposed to overcome real-world chal-\nlenges, such as few-shot prompting, chain-of-thought, and retrieval-augmented\ngeneration (RAG). However, RAG for legal judgment prediction (LJP) is still\nunderexplored. To address this, we propose \"Athena\", a novel framework culti-\nvating RAG as a core preprocess component to enhance LLMs' performance on\nspecialized tasks. Athena constructs a knowledge base for accusations, attached\nwith a semantic retrieval mechanism through vectorization. Our experiments\nshow that Athena's overall performance has improved significantly, achieving\nstate-of-the-art results on the CAIL2018 dataset. Our ablation study on the in-\ncontext window size parameter further reproduces LLMs' \"lost-in-the-middle\"\nphenomenon with a relative positional variation. And with moderate hyper-\nparameter-tuning, we can achieve at most 95% of accuracy accordingly. We also\nstudy the impact of query rewriting and data distribution, providing possible\ndirections for future research based on former analyses.", "sections": [{"title": "Introduction", "content": "Shakespeare once wrote, \"We know what we are, but know not what we may be\".\nPursuing knowledge is an ancient urge for all human beings, especially with the recent\ngrowth of information transportation bandwidth driven by the Internet. The wisdom\nhierarchy of DIKW indicates a path between the chaotic ocean of information and\nthe wisdom of artificial general intelligence, as it's already embedded in the minds of\nhuman beings (Rowley, 2007).\nIn the meantime, the research and applications of large language models grow\nrapidly, entering the fourth paradigm of natural language processing (Zhao et al.,\n2023). The scaling law proposed by Kaplan et al. (2020) ensures LLMs' general ability\nincreases with more data and more computational power involved, while the upper\nbound of the scaling law remains a mystery.\nLLMs, training on large-scale datasets, make breakthroughs while suffering from\nhallucinations and poor deductive abilities. Knowledge and wisdom are rarely found.\nPrompt engineering techniques built upon these foundation models take a step\nfurther, alleviating LLMs' lack of expert knowledge and skills. As one of the PE\u0395\nmethods, RAG utilizes an external knowledge base to accurately provide contextual\ninformation for LLM to infer with much less hallucinations.\nFor legal judgment prediction, existing methods attempt to make the judgment\nbased on LLMs' inner ability inherited from pertaining. As a result, any novel updates\non regulation terms will be out of reach for such systems and new accusations will be\nunrecognizable. This weakness in existing methods restricts their applications in\nthe real world."}, {"title": "Related works", "content": "Large language models have been trending recently (Zhao et al., 2023; Minaee\net al., 2024). By introducing the attention mechanism into natural language pro-\ncessing (NLP), Transformer significantly accelerates the development of language\nmodels (Vaswani, 2017). BERT and GPT-series (especially GPT-3.5) explore the\ntransformer's potential and bring the NLP research into the \"pre-train and prompt\"\nparadigm (Devlin, 2018; Radford et al., 2018, 2019; Brown, 2020; Ouyang et al., 2022).\nAfter that, the scaling law in Kaplan et al. (2020) promotes LLMs to scale to trillions\nof parameters, such as GPT-4 in Achiam et al. (2023), Tele-FLM in Li et al. (2024).\nRecently, smaller models with competitive capability aiming for edging deployment\nhave also drawn attention to the research community, such as Mini-CPM in Hu et al.\n(2024); Yao et al. (2024) and DeepSeek in Bi et al. (2024); DeepSeek-AI (2024). These\nLLMs, known for their great generalizability, serve as foundation models for versatile\ntasks in the real world."}, {"title": "Prompt Engineering", "content": "The development of foundation models provides a footstone for prompt engi-\nneering, as their instruction-following and context-understanding abilities increase\ndramatically. First, in-context learning such as zero-shot prompting in Kojima et al.\n(2022) and few-shot prompting in Brown (2020) enhances LLMs' output format.\nSecond, chain-of-thought prompting (CoT) in Wei et al. (2022) helps LLMs follow\nthe guide of reductionism, solving complex problems step by step. Third, retrieval-\naugmented generation brings external knowledge and facts into LLMs, alleviating their\nhallucination phenomenon (Lewis et al., 2020). Most recently, agentic workflows and\nframeworks have further expanded the borderline of LLMs' capability, such as ReAct\nin Yao et al. (2022), XAgent in Team (2023), MetaGPT in Hong et al. (2023), and\nAutoGen in Wu et al. (2023)."}, {"title": "Legal Judgment Prediction", "content": "In general, legal judgment prediction is considered a text classification problem tackled\nthrough machine learning methods (Feng et al., 2022). For instance, Katz et al. (2017)\npredicts the judgment results of the Supreme Court of the United States with Random\nForest. Deep learning is widely applied in LJP. Chalkidis et al. (2019) introduces\nan additional classification layer on top of BERT, processing truncated documents\nas input. Gan et al. (2021) encodes first-order logic legal rules as features feeding\ninto a co-attention network-based model. Recently, LLMs have been integrated into\nLJP as zero-shot reasoners. Legal syllogism prompting, as proposed by Jiang and\nYang (2023), attempts to instruct LLMs in legal reasoning through a modified CoT\ntechnique.ADAPT enhances LLMs' capabilities through fine-tuning with multi-task\nsynthetic trajectories (Deng et al., 2024). However, the potential of LLMs, particularly\nwhen integrated with novel prompt engineering techniques on the LJP task, is still\nawaiting further cultivation."}, {"title": "Methodology", "content": ""}, {"title": "Problem Definition", "content": "Legal judgment prediction can be defined as the process of forecasting the judgment\noutcome of a particular legal case. Let's consider a dataset L comprising diverse\nlegal cases 11, 12, ..., In and another set J representing potential judgments j1, 2, ..., \u0130n\n(referred to as an accusation list). The Legal Judgment Prediction (LJP) task, as\ndepicted in Equation 1, involves establishing a functional mapping f that links the\nspace of legal case datasets L to the accusation list J.\n$J = f(L)$ (1)\nWith the introduction of large language models, the functional mapping can be\nimplemented as an LLM, as illustrated in Equation 2. The LLM inference engine"}, {"title": "Overall Framework", "content": "The overall framework of \"Athena\", as demonstrated in Fig. 2, consists of two major\nworkflows: the prompting workflow and the knowledge retrieval workflow. These two\nworkflows split on the given legal case and converge at the prompt template.\nIn the prompting workflow, an analyzer gathers real-world legal cases related to\ncrimes, constructing natural language descriptions of these cases. Each legal case\ndescription is then fed into a prompt template to form a descriptive text for the LLM.\nThe LLM digests it and provides structured output accordingly. Finally, the judgment\nprediction can be extracted from the structured output.\nIn the knowledge retrieval workflow, the legal case description serves as a query\nto the accusation knowledge base. This knowledge base contains various accusation\nnames along with their corresponding description, including definitions and examples.\nThe experts can further refine these generated descriptions. By assessing the seman-\ntic similarity between the query and descriptions in the knowledge base, the top-k\naccusation candidates are retrieved and fed into the aforementioned prompt template."}, {"title": "Knowledge Base Construction", "content": "For any labeled LJP dataset, each legal case comes with a corresponding accusation\nlabel. As shown in Fig. 3, the construction of the knowledge base can be organized into"}, {"title": "Experiment", "content": ""}, {"title": "Setting", "content": "Our dataset is constructed based on the CAIL2018 dataset (Xiao et al., 2018; Zhong\net al., 2018). The dataset contains 68 kinds of accusations in total. We sample the\nfirst 256 legal cases containing 43 kinds of accusations from the original dataset for\nthe following experiment.\nFor the LLM foundation model, we use ChatGPT with the following versions:\nGPT-3.5-turbo, GPT-4-turbo, and GPT-40. For the primary experiment, we set the\nparameter k of the knowledge base to infinity retrieving all accusation candidates. We\nalso chose OpenAI embeddings as the embedding function for vectorization.\nThe methods implemented are illustrated in Fig. 4, encompassing four distinct\napproaches:\n\u2022 Baseline: The baseline is implemented as a bare prompt that provides the legal\ncase description and tells the LLM to complete the judgment.\n\u2022 Zero-shot chain-of-thought (CoT): Chain-of-thought prompting is a special\ninstruction to promote the LLM to make inferences one step at a time while pro-\nviding exemplary cases. The zero-shot version of CoT is implemented by explicitly\nadding a phrase called \"Let's think step by step\" into the prompt (Wei et al., 2022;\nKojima et al., 2022).\n\u2022 Legal syllogism prompting: Legal syllogism is a logical reasoning method used\npredominantly in the field of law to reach a conclusion based on a set of premises\n(Jiang and Yang, 2023). Compared with CoT, legal syllogism prompting explicitly\nindicates the deductive logic in legal areas for LLM to process, by adding a prefix\ndefinition of legal syllogism into the prompt. This is equivalent to embedding expert\nknowledge into the LLM.\n\u2022 Athena: Our framework goes beyond by enhancing the LLM with RAG's capabili-\nties. Athena retrieves potential similar accusation candidates to provide insight for\nthe LLM. Note that the few-shot prompting is self-included in Athena's retrieving\nmechanism because each candidate is associated with its description and example.\nThe formatting instructions will guide the LLM in following the exact inference\nworkflow."}, {"title": "Result", "content": "The results are detailed in Table 1. Initially, for relatively smaller models like GPT-\n3.5, all performances exhibit similarly low scores. This could be due to both the\nlimited contextual ability and reasoning ability of the LLM. Second, with the increase\nin model capability from GPT-3.5-turbo to GPT-40, the accuracy increases consis-\ntently, indicating the importance of foundation models. Third, both zero-shot-CoT and\nlegal syllogism prompting outperform the baseline, for powerful models like GPT-40.\nNotably, Athena significantly outperforms all other methods with the GPT-4 series.\nThis highlights the effectiveness and necessity of prompt engineering, especially RAG."}, {"title": "Ablation Study", "content": ""}, {"title": "In-context Window Size k", "content": "As mentioned above in the main experiment, when retrieving top-k accusation candi-\ndates C, the default parameter is set to k = \u221e (k as the in-context window size for\nthe LLM). This setting is equivalent to retrieving all accusations in the database as\na ranked sequence. In this part, we further investigate the impact of k through the\nablation study.\nAs clearly shown in Table 2, the overall performance of Athena's LLMs follows\na pattern where with an increase in the in-context window size k, the performance\nof Athena initially increases, then declines, and eventually stabilizes at a moderate\nwindow size k.\nThe Hit Rate in Table 2 reflects the overall likelihood across the entire sampled\ndataset of retrieving the correct accusation candidate for the LLM, as illustrated in\nEquation 8. Here, C denotes the collection of the retrieved accusation candidates, Ctrue\nrepresents the correct accusation candidate (equal to the label of the given legal case),"}, {"title": "Query Rewriting", "content": "In this part, we investigate the impact of query rewriting in constructing the knowledge\nbase. For comparison, we design two types of descriptions for the vectorization process,\nwhich constitutes the third step of the knowledge base construction."}, {"title": "Data Distribution", "content": "The CAIL2018 dataset exhibits extreme imbalance with heavy-tailed data distribu-\ntion. In this part, we aim at the accuracy distribution across all legal accusation\nclasses. To address this, we create a new balanced dataset from a larger subset of\nthe CAIL2018 dataset (denoted as Llarge), which contains approximately 0.75 million\nlegal cases. Subsequently, we extract at most 64 cases for each accusation from this\nsubset to generate a rebalanced dataset.\nWe define the average accuracy and weight accuracy as follows. For each accusation\nci in the set {C1, C2,...,Cm}, where m is the size of accusation set for Llarge, the\naccuracy is denoted as acc(ci) and the total number of corresponding legal cases in\nLlarge is denoted as |Lci|. The average accuracy and weight accuracy are calculated"}, {"title": "Discussion", "content": "Athena has successfully introduced RAG into the LJP task. Unlike the recently\nproposed framework in Deng et al. (2024), which includes five unstable fine-tuning\nsubtasks, our framework is entirely fine-tuning-free. This is achieved through the adept\nutilization of versatile prompt engineering techniques. This not only enhances Athena\nwith scalability and generalizability but is particularly advantageous in scenarios\nwhere the computation resources are low. The automatic construction of the retrieving\nsystem paves the way for novel accusation classes and even novel classification tasks.\nAthena still suffers from a lack of legal expertise, particularly in areas such as\nsimilarity matching and judgment decisions. Our former case analysis shows that most\nof the bad cases are hard even for human non-experts.\nFor future work, we outline several potential directions for advancement. First,\noptimizing the retrieval subsystem stands out as a key area of focus. Automatic and\ncarefully crafted query rewriting schema for LJP plays an essential part in improving\nthe Hit Rate. Multi-channel retrieval and other assembled algorithms could enhance\nrecall performance while introducing novel challenges such as dynamic query rewriting\nschema management. Moreover, the ranking mechanism can be naturally replaced by\nany textual ranking model like an existing LJP classifier based on BERT or fine-tuned\nsmaller LLMS.\nSecond, the LLMs' inference logic can be optimized. The agentic workflow can\nbe introduced into LJP including modules such as reflection, router, tool usage, etc.\nFor example, the in-context window can be rectified to scale or move during the LJP\nprocess when the LLM detects that the current output judgment is incorrect."}, {"title": "Conclusion", "content": "In this work, we introduced \"Athena\", a novel framework that leverages RAG to\nenhance the performance of LLMs in LJP. By integrating an external knowledge base\nthrough semantic retrieval, Athena substantially enhances prediction accuracy, achiev-\ning state-of-the-art results on the CAIL2018 dataset. Our ablation study demonstrates\nthe effectiveness of utilizing a moderate in-context window size and query rewriting to\nenhance retrieval performance. The observed imbalanced performance due to skewed\ndata distribution brings insights into the requirement for legal expertise. Athena's\nmethodology effectively tackles key limitations of LLMs, such as hallucinations and\nlack of domain-specific knowledge, paving the way for more reliable AI-assisted legal\ndecision-making. Future endeavors will focus on optimizing the retrieval subsystem and\nrefining LLM inference logic such as including complex agentic workflows to further\nenhance Athena's capabilities and impact in the realm of legal judgment prediction."}]}