{"title": "Integrated Encoding and Quantization to Enhance Quanvolutional Neural Networks", "authors": ["DANIELE LIZZIO BOSCO", "BEATRICE PORTELLI", "GIUSEPPE SERRA"], "abstract": "Image processing is one of the most promising applications for quantum machine learning (QML). Quanvolutional Neural Networks with non-trainable parameters are the preferred solution to run on current and near future quantum devices. The typical input preprocessing pipeline for quanvolutional layers comprises of four steps: optional input binary quantization, encoding classical data into quantum states, processing the data to obtain the final quantum states, decoding quantum states back to classical outputs. In this paper we propose two ways to enhance the efficiency of quanvolutional models. First, we propose a flexible data quantization approach with memoization, applicable to any encoding method. This allows us to increase the number of quantization levels to retain more information or lower them to reduce the amount of circuit executions. Second, we introduce a new integrated encoding strategy, which combines the encoding and processing steps in a single circuit. This method allows great flexibility on several architectural parameters (e.g., number of qubits, filter size, and circuit depth) making them adjustable to quantum hardware requirements. We compare our proposed integrated model with a classical convolutional neural network and the well-known rotational encoding method, on two different classification tasks. The results demonstrate that our proposed model encoding exhibits a comparable or superior performance to the other models while requiring fewer quantum resources.", "sections": [{"title": "I. INTRODUCTION", "content": "The field of Quantum Machine Learning (QML) applied to Computer Vision has gathered increasing interest in the last decade, combining quantum computing and machine learning to develop new algorithms which may lead to more efficient and optimized computer vision models [1]. A promising approach in image processing is the application of Quantum Convolutional Neural Networks, also known as Quanvolutional Neural Networks (hereafter QuanvNN), which aim to enhance classical models through hybrid (classical-quantum) architectures. However, current quantum devices are still characterized by a limited number of qubits and the absence of error correction. This hinders QML from matching the performance of classical ML methods. Therefore, the applications of QuanvNNs are currently limited to simple architectures and small datasets because of several constraints, including: the low number of available qubits, the need to reduce circuit depth to avoid decoherence, and technical optimization constraints. For instance, while deep learning relies on gradient descent for parameter updates, quantum neural networks require the use of the parameter shift rule [2], which involves a large amount of additional circuit measurements and is unreliable in absence of error correction. This makes large scale QuanvNN optimization currently impractical.\nTo avoid the need to optimize quantum circuit parameters, a solution is the use of quanvolutional layers with non-trainable parameters, as introduced in [3]. These layers can be used in hybrid models for preprocessing the input dataset, acting as random feature extractors which might identify features that are challenging to"}, {"title": "II. RELATED WORK", "content": "Previous research has developed two main classes on quanvolutional methods: the ones where quantum circuits parameters have learnable parameters, and the methods where they have fixed non-learnable parameters (i.e. only the classical parameters are learned).\nThese quantum convolutional models include parameterized circuits, which can be trained together with the classical parameters via the parameter shift rule or similar techniques.\nThe most common approach consists in encoding the input image in a quantum state, processing it via one or more quantum convolutional layers, decoding the final state, and finally passing it to a classical architecture.\nFor example, [14] implemented this kind of QuanvNN for the classification of High Energy Physic particles on the LArTPC dataset. Their model encodes each pixel of a $2 \\times 2$ patch in a qubit by converting it in rotation angles. The processing circuit has 4 qubits and a fixed architecture which contains parameterized rotations. These parameters are initialized randomly and iteratively optimized during training. The output of the quantum circuit is then decoded and passed to a series of classical fully connected layers, which are jointly trained with the quantum circuit.\nOther works apply the same architecture to the classification of 2D radiological images [11] and several multi-class classification tasks on MNIST, Medical MNIST, and CIFAR-10 [12]. The former tests the effectiveness of several encoding methods which require one qubit per pixel (threshold encoding, rotational encoding, and"}, {"title": "A. QuanvNNS WITH LEARNABLE PARAMETERS", "content": "These quantum convolutional models include parameterized circuits, which can be trained together with the classical parameters via the parameter shift rule or similar techniques.\nThe most common approach consists in encoding the input image in a quantum state, processing it via one or more quantum convolutional layers, decoding the final state, and finally passing it to a classical architecture.\nFor example, [14] implemented this kind of QuanvNN for the classification of High Energy Physic particles on the LArTPC dataset. Their model encodes each pixel of a $2 \\times 2$ patch in a qubit by converting it in rotation angles. The processing circuit has 4 qubits and a fixed architecture which contains parameterized rotations. These parameters are initialized randomly and iteratively optimized during training. The output of the quantum circuit is then decoded and passed to a series of classical fully connected layers, which are jointly trained with the quantum circuit.\nOther works apply the same architecture to the classification of 2D radiological images [11] and several multi-class classification tasks on MNIST, Medical MNIST, and CIFAR-10 [12]. The former tests the effectiveness of several encoding methods which require one qubit per pixel (threshold encoding, rotational encoding, and"}, {"title": "B. QuanvNNS WITH NON-LEARNABLE PARAMETERS", "content": "Although parameterized circuits are extensively used in the literature, the process of optimizing their parameters is currently very resource-expensive. For this reason, several works focused on QuanvNNs with non-learnable parameters. These parameters are usually randomly initialized and remain fixed, while the classical layers of the network undergo the standard training procedure. Another advantage of used a non-learnable quanvolutional layer is that its output can be pre-computed for all the input patches in the dataset, further reducing the amount of quantum circuit executions required to train the model.\nThis kind of QuanvNNs was first introduced by Henderson in [3]. In this work, the authors use a classical CNN preceded by a quanvolutional layer. The authors use threshold encoding on $3 \\times 3$ input patches, meaning"}, {"title": "A. QUANVOLUTIONAL LAYERS", "content": "Quanvolutional layers are the fundamental component of QuanvNNs, and are based on classical convolutional filters, which have transformed the field of image processing and computer vision. Similarly to their classical counterparts, they extract meaningful features from images in a locally space-invariant manner, but they also exploit the capability of quantum circuits to extract complex features that are difficult to obtain classically.\nQuanvolutional layers comprise of one or multiple quanvolutional filters, which perform operations on a local subsection of the input data through quantum circuits.\nA filter, also called kernel, maps a subsection of $k \\times k$ input data (pixels) $X_{1},...,X_{k^{2}} = x$ to a single scalar value. The input x is usually referred to as a \"patch\". In the classical approach, this mapping is performed using classical operations, such as a scalar product between the patch values and the filter's weights, and the addition of a bias. A quantum convolutional filter acts in a similar manner, with the important difference that the mapping is performed through a quantum circuit.\nMore in detail, as mentioned in the Introduction, each filter performs the following operations:\n* Encoding: the classical data (i.e. pixels in the patch x) are encoded in a quantum state;\n* Processing: the quantum state representing the classical data is processed through a sequence of gates;\n* Decoding: classical information is extracted from the final quantum state.\nThe following sections describe the three phases in more detail."}, {"title": "B. ENCODING", "content": "In general, encoding strategies are implemented as quantum circuits which are applied before the processing step. Their aim is to embed the classical inputs into a quantum state before further processing."}, {"title": "1) Rotational Encoding", "content": "The most common approach to data encoding in quanvolutional models is through the use of rotational encoding with $R_{x}$ gates [8]. The parametric gate $R_{x}(\\theta)$ is defined as\n$R_{x}(\\theta) = \\begin{pmatrix} cos(\\frac{\\theta}{2}) & -i sin(\\frac{\\theta}{2})\\\\ -i sin(\\frac{\\theta}{2}) & cos(\\frac{\\theta}{2}) \\end{pmatrix}$,\nand is obtained by the matrix exponential $exp(-i\\theta X)$, where X denotes one of the Pauli gates. This approach is also known as angle encoding.\nIn a quanvolutional filter of size $k \\times k$, each pixel $p_{i}$ is encoded on a different qubit. This implies that encoding $k^{2}$ pixels requires a circuit with exactly $k^{2}$ qubits. Consequently, as k increases, this approach becomes unsustainable for devices with a lower qubit count. Conversely, it may also reduce the expressivity of the filter for lower values of k.\nAs the matrix exponential has a period of $2\\pi$, each pixel is mapped to a rotation angle before the encoding. For example, if $p_{i} \\in [0, 1]$, then $p_{i}$ is encoded as $R_{x}(p_{i}\\pi)$ applied to the i-th qubit. Formally, the mapping of a patch of size $k \\times k$ to the corresponding quantum state can be written as\n$|0\\rangle^{\\otimes n} \\rightarrow |\\Psi(x)\\rangle = \\prod^{n}_{j=1} (cos(\\frac{x_{j}\\pi}{2}) |0\\rangle - i sin(\\frac{x_{j}\\pi}{2}) |1\\rangle),$\nwith $n = k^{2}$."}, {"title": "2) Threshold Encoding", "content": "Another method of encoding classical data in quanvolutional filters is by threshold encoding. It consists in first performing a binarization of the image, and then encoding pixels with value 0 with the identity gate I, and pixels with value 1 with the X gate. As in the previous case, the pixel $p_{i}$ is encoded in the i-th qubit. This encoding process inevitably results in significant information loss due to the image binarization, and can only be applied to datasets that are resilient to this procedure.\nIt is important to note that the threshold encoding is equivalent to the rotational encoding after performing input binarization, as $R_{x}(\\pi)$ is equivalent to the X gate up to a global phase of -i."}, {"title": "3) Higher Order Encoding", "content": "The rotational encoding can be enhanced with additional entangling gates, to obtain the so-called higher order encoding [11], [19]. In this encoding, after the rotational gates, there are a set of $R_{zz}(x_{i}x_{j})$ applied to the i-th and j-th qubits. This encoding is more expressive, but requires additional $k^{2} (k^{2} - 1) / 2$ gates and a larger circuit depth."}, {"title": "4) Other Notable Encodings", "content": "Other encodings, which are usually not employed in quanvolutional approaches, aim to reduce the number of qubits needed to encode an image. For examples Flexible Representation of Quantum Images (FRQI) [20] can encode an image of size $k \\times k$ with $2 log_{2}(k) + 1$ qubits, as long as k is a power of two. However, this method requires $k^{4}$ gates. Novel Enhanced Quantum Image Representation (NEQR) [18] is an improvement on the FRQI encoding that stores input data using the basis states instead of the amplitudes."}, {"title": "C. PROCESSING", "content": "Following the encoding phase, the processing section of the circuit usually consists of a randomly generated sequence of parametric and non-parametric gates. In this section we focus on the original procedure described in [3], as it is commonly used in the literature when implementing non-learnable QuanvNNs and it is the method used in this work to create the processing circuits.\nThe parametric circuit is constructed from a set of single-qubit gates, and a set of two-qubit gates.\nThe single-qubit gates are generated as follows: a maximum of $2k^{2}$ gates drawn from the set $[R_{x}(\\theta), R_{y}(\\theta), R_{z}(\\theta), S, T, H]$. Each gate is applied to a random qubit, and $\\theta$ is a random rotation parameter. As regards the two-qubit gates, each pair of qubits $q_{j}, q_{k}$ has a fixed probability (usually p = 0.15) of having a gate applied to them. The gate is randomly selected"}, {"title": "D. DECODING", "content": "Finally, each quantum state must be translated into a classical, scalar value, in order to construct a new input for the following layer of the model. To achieve this, it is first necessary to measure each quantum state. Subsequently, the distribution obtained from the measurement can be converted into a real number. This step can be performed in several ways, e.g. the number of qubits in the |1\u27e9 state in the most measured state can be counted [3]. A different approach is the one used by [11], where the authors obtain the expectation value for each observable in the circuit. Therefore, the output of the circuit is a vector instead of a single number, i.e. an output channel is generated for each qubit in the circuit."}, {"title": "E. EXPRESSIBILITY OF A QUANTUM CIRCUIT", "content": "Expressibility is one of the most significant descriptors of a parametric quantum circuit. It can be defined as the ability of the circuit to uniformly cover the Hilbert space of the underlying quantum system (i.e., the circuit's ability to explore the Bloch sphere in the case of a single qubit). Moreover, researchers have shown a strong positive correlation between the expressibility of a quantum circuit used in a variational quantum classifier and its performance [15].\nThe expressibility index has first been proposed in [22]. It is calculated by comparing the fidelities distribution of states obtained by a circuit U to the fidelities distribution of random states of the system, which corresponds to the Haar random states ensemble.\nIn order to compute the expressibility, the authors first approximate the former distribution by randomly sampling two sets of parameters $\\theta_{1}, \\theta_{2} \\in \\Theta$ of the parametric quantum circuit U. They then compute the fidelity $|\\langle U(\\theta_{1})|U(\\theta_{2}) \\rangle|^{2}$ between the states obtained with the corresponding sets of parameters.\nSubsequently, they compute the Kullback-Leibner divergence between the distribution $P_{U}(F; \\Theta)$ and the distribution of random states $P_{Haar}(F)$, which is known to be equal to $(N - 1)(1 - F)^{N-2}$, where N is the dimension of the quantum system [23], obtaining\n$Expr (U(\\theta)_{\\theta \\in \\Theta}) = D_{KL} (P_{U}(F; \\Theta) || P_{Haar}(F)).$\nThe formula to compute $D_{KL}$ of two continuous random variables P and Q is\n$D_{KL}(P||Q) = \\int^{\\infty}_{-\\infty} p(x) log(\\frac{p(x)}{q(x)}) dx,$\nwhere p and q denote the probability densities of P and Q.\nIf the value of $D_{KL}$ (and therefore Expr) is close to zero, then the two distributions are similar (i.e. in our case, the parametric quantum circuit U is very expressive).\nIt is important to note that in general expressibility is computed for variational circuits, while the circuits considered in this work have randomly generated or feature-dependent parameters. In this context, it represents the ability of a circuit to extract diverse features from the input data."}, {"title": "A. DATA QUANTIZATION", "content": "To enhance computational efficiency during the preprocessing stage, two techniques are employed: first the input data is quantized, and then quantum circuit outputs for each unique patch are memoized. Previous works utilized a binary image quantization and a look-up table (memoization) to expedite dataset processing. In general, binary quantization significantly reduces data fidelity, with the potential for complete loss of information (see Fig. 2). Therefore, a higher number of quantization levels is employed to preserve of as much information as possible while maintaining computational practicality. The proposed quantization approach extends binary quantization by introducing a quantization level, denoted as N.\nThe formula used to quantize a pixel is\n$q(x) = \\frac{\\lfloor x \\cdot N \\rfloor}{N-1},$\nwhere $x \\in [0, 1)$ is the original pixel intensity. In other terms, when a image is quantized to N levels, we first extract from the interval [0,1] the N points $\\{0, \\frac{1}{N-1}, \\frac{2}{N-1},..., \\frac{N-1}{N-1}\\}$. Then, for each image I, each pixel value is mapped to the closest point in the set, obtaining a quantized image $q(I)$.\nThe memoization technique is implemented by constructing a look-up table that links each quantized input patch to the output computed by the circuit. The table is filled-in dynamically while preprocessing the dataset. This process ensures that unnecessary computations for absent patches are avoided, as only the patches actually encountered in the dataset are processed.\nThis methodology allows to balance the trade-off between detail retention (preserving information) and computational load (efficient processing). A higher N value offers finer details at the expense of expanding the memoization table and needing more quantum circuit executions. Conversely, a lower N value simplifies the process and reduces computational demands, but this is achieved at the cost of losing input information. Fig. 2 displays some examples of the effect of quantization for different values of N."}, {"title": "B. INTEGRATED ENCODING", "content": "The proposed method is based on the use of classical data as a rotation angle for multi-qubit entangling gates, with the objective of directly encoding data into the processing section of the circuit. The rationale behind this approach is that it removes the dependency between the size of the kernel and the nunber of qubits required, thus enabling their selection independently. This approach is"}, {"title": "V. EXPERIMENTAL DESIGN", "content": "The experiments are conducted on binary and multiclass classification problems across two different datasets. The aim of the experiments is to understand the performance of the proposed integrated quanvolutional model for different mapping functions a(), compared to the standard rotational encoding approach. Each setting is tested for different kernel sizes, and is finally compared to a classical CNN."}, {"title": "A. DATASETS", "content": "To test our proposed model, we selected two image classification datasets from different fields:\n* MiraBest [13] comprises images of galaxies, classified according to the Fanaroff-Riley morphology into three macro-classes: FR-I, FR-II, and Hybrid. We use Version 12 of the dataset, which consists of only the samples labeled as Confident (as opposed to Uncertain) and discards the Hybrid class, which contains 19 Confident samples only. The resulting dataset comprises 770 samples, of which 339 belong to the FR-I class and 431 to the FR-II class. Each sample is normalized and down-scaled to a size of 30 x 30.\n* LArTPC (Liquid Argon Time Projection Chamber) [14] is a dataset consisting of realistic simulations of"}, {"title": "B. TESTED MODELS", "content": "We compare our proposed quanvolutional model with integrated encoding (QNN-Int) with a classical CNN model and a quanvolutional network using rotational encoding (QNN-Rot). Additionally, we test three different mapping functions a(\u00b7) to map pixel intesities to rotations angles in QNN-Int. Finally, for both quanvolutional models, multiple kernel sizes are tested to determine their effect on the model's performance. Following are the implementation details of the models. Fig. 4 shows a schema of the architecture.\n* CNN: a classical convolutional neural network. The structure of the model contains one convolutional layer and two fully connected layers. The convolutional layer consists of 16 output channels, has a filter size of 3\u00d73 with no padding, and is followed by a ReLU, and a Max Pooling layer of size 2 \u00d7 2. The first fully connected layer has 32 output features, while the second one, which is also the output layer, has a number of outputs equal to 7 or 2, depending on the task. Each fully connected layer is followed by a ReLU activation function. The convolutional layer and the first fully connected layer are followed by a Droupout layer, with probability of 0.2, to prevent overfitting.\n* QNN-Rot: quanvolutional model with rotational encoding. The model consists in the same architecture described above, with a quanvolutional layer stacked on top. The number of output channels on the quanvolutional layer is 8, and the first Conv layer is modified is take as input 8 channels instead of one. Each filter is padded to have the same input and output dimensions.\nThe tested filter sizes are: $2 \\times 2$, $3 \\times 3$, and $4 \\times 4$, with a qubit requirement n of 4, 9, and 16. Larger filter sizes were not tested due to the high resource demands associated with their simulation, which was unfeasible on our device. The processing circuit follows the standard implementation describe in Section III-C. The connection probability used for the circuit generation is set to 0.15.\n* QNN-Int: quanvolutional model using the proposed integrated circuit. The structure of the model is the same as the one described for the QNN with the rotational encoding, with the quanvolutional layer on top of the CNN. The layer comprises 8 channels, and each filter is padded so that the output of the layer has the same dimensions of the input.\nThe number of qubits is set to n = 4 to balance the expressivity of the model with the resources required for its implementation. The tested filter sizes are: $2 \\times 2$, $3 \\times 3$, $4 \\times 4$ and $5 \\times 5$.\nRegarding the mapping function a(\u00b7), three options were considered:\n* Simple: $x \\rightarrow x\\pi$\n* RndMul: $x \\rightarrow 2\\beta x \\pi$\n* RndLin: $x \\rightarrow (\\beta x + \\sigma)\\pi$\nwhere x is the pixel value normalized in [0, 1], and $\\beta, \\sigma$ are random parameters selected uniformly in"}, {"title": "C. DECODING", "content": "To obtain the output of the quanvolutional filter, we need a way to decode the quantum state through a measurement. In this work, we choose to measure the output state $U(x)|\\Psi_{0}\\rangle$ with the projector $M = Z^{\\otimes n}$. The expectation value is obtained as\n$p = \\langle \\Psi_{0}|U(x)^{\\dagger} M U(x)|\\Psi_{0}\\rangle.$\nTo translate the output measurement to a scalar value, we compute the average number of qubits that were measured in the |1\u27e9 state after repeating the measurement for a fixed number of times. This method was chosen as it is more resilient to the stochasticity of the measurements than the one based only on the most common measured output [3]. As an example, consider a circuit that for a given input patch x returns an equal superposition of the states $|0\\rangle^{\\otimes n}$ and $|1\\rangle^{n}$. If the filter output depends only on the most common state measured, then the output has a 50% chance of being 0 or 1, while by taking into account all the measured states we have an output of 0.5."}, {"title": "D. IMPLEMENTATION DETAILS", "content": "All models are trained using the ADAM optimizer with a learning rate of 0.0003, with a batch size of 16. As loss, we use log softmax. The training process employs early stopping with a patience of 10, i.e. the training halts if the training loss fails to improve over 10 consecutive epochs. For the QNN-Int-RndLin model the patience is"}, {"title": "E. EXPRESSIBILITY MEASUREMENT", "content": "To compute expressibility of a quanvolutional circuit, we compute $2^{10}$ fidelities of the circuit by creating pairs of random input vectors. We then calculate the discretized version of Expr as follows:\n$\\sum_{i \\in bins} P(i) log (\\frac{P(i)}{Q(i) + \\epsilon}),$\nwhere bins are obtained by dividing the interval [0, 1] in 50 equal-sized intervals, P(i) is the number of fidelities in the i-th bin, and Q(i) is obtained from the distribution of $P_{Haar}$. The additive constant $\\epsilon = 10^{-16}$ is used for numerical stability in the computation.\nAll the randomly initialized non-learnable parameters of the circuits (e.g. $\\Theta$ in the QNN-Rot, $\\sigma, \\beta$ in QNN-Int) are maintained fixed while measuring the $2^{10}$ fidelities."}, {"title": "VI. EXPERIMENTAL RESULTS", "content": "In the following, we present an analysis of the effect of data quantization on the datasets. Then, we report the results of the classification experiments conducted on MiraBest and LArTPC. Finally, we perform an expressibility analysis for QNN-Int and QNN-Rot."}, {"title": "A. DATA QUANTIZATION", "content": "We perform a preliminary analysis of the impact of data quantization, restricted to 3\u00d73 patches on the four datasets: MNIST, CIFAR10, MiraBest, and LArTPC. We focus on two metrics: information loss and reduction in number of circuit execution. The former is calculated as the MSE between the original and quantized images. The latter is calculated by comparing the total number of 3 \u00d7 3 patches in the whole dataset and the number of unique 3 \u00d7 3 patches obtained after quantization.\nFig. 5 shows the trend of the information loss (MSE, y-axis) depending on the quantization level (x-axis) for all datasets. The theoretical maximum MSE between the original and quantized images for each quantization level N, given by (5), is shown as a dashed line. The actual average MSE calculated on the datasets is shown as solid lines. We can see that the actual MSE on the datasets can be significantly lower than the upperbound (e.g., for LArTPC and MiraBest). This largely depends on the variability of pixel intensities in the original dataset. For example, CIFAR10 contains real-life images of animals, vehicles, and objects (see Fig. 2), resulting in a high variability and an MSE close to the upper bound. On the other hand, the images in LArTPC and MiraBest contain large black backgrounds with (relatively) small mostly-white objects, which lead to lower error rates during quantization.\nThe acceptability of information loss is contingent upon the characteristics of the dataset in question. For instance, N = 2 is an acceptable quantization level for MNIST, whose images remain recognizable after the process, but not for CIFAR10. In general, we expect that levels of N < 20 may result in a loss of information that negates any potential quantum advantage that could be obtained through quanvolutional approaches.\nFig. 6 reports the percentage of reduction in circuit executions (y-axis) given the quantization level (x-axis) for all datasets. The plot shows that quantizing to N = 10 levels reduces the number circuit executions by 92% for all datasets. The reduction reaches 99% for MiraBest and LArTPC, potentially allowing significant savings in terms of resource utilization. As the number of quantization levels increases, the effect of quantization remains significant for several datasets: N = 100 leads to a 95% reduction for MiraBest and LArTPC, and an 80%"}, {"title": "B. CLASSIFICATION PERFORMANCE", "content": "Table 3 reports the average classification accuracy of all models tested on the MiraBest dataset (two classes). The average accuracy of the classical CNN model is 71.039%.\nQNN-Rot surpasses the performance of the CNN for"}, {"title": "C. EXPRESSIBILITY ANALYSIS", "content": "Fig. 7 shows a comparison of the expressibility of the proposed QNN-Int model with QNN-Rot using different kernel sizes. To increase the readability of the plots, we show the value of Expr', computed as Expr' = - ln(Expr), so that higher values correspond to an increased expressivity.\nWhen computing the expressibility of the proposed QNN-Int circuit with a fixed number of qubits and features (Figs. 7, upper row), we observe that increasing the number of gates L (moving right on the x-axis) leads to increasingly more expressive circuits (increased Expr'). This implies that it is possible to select a priori the value of L in order to obtain a desired value of expressibility.\nIncreasing the kernel size k leads to a higher increase in expressibility with a lower number of gates. For example, QNN-Int-Simple reaches Expr' = 2 with 25 gates when k = 2, 14 gates with k = 3, and 12 gates with k = 4.\nWhen comparing the three different mapping functions a, we observe that Simple and RndMul display a similar trend, while RndLin has significantly lower expressibility for all kernel sizes. Therefore, we expect RndLin to reach a lower classification accuracy compared to the other two functions.\nAs regards QNN-Rot, the x-axis of the plots in the lower row of Fig. 7 reports the probability p instead of the number of gates. This is because the number of gates in a circuit with rotational encoding depends on p and k and it averages at $k^{2} + p k^{2} (k^{2} - 1)$. One can select different values of the connection probability p to obtain circuits with different length. We observe that QNN-Rot circuits are generally less expressive than QNN-Int. Additionally, their expressibility does not depend on the number of operations involved. For every value of p there is no statistically significant difference in the value of Expr', which only increases with the kernel size k.\nThese observations are in line with the experimental results, which show that QNN-Int-Simple and QNN-Int-RndMul tend to outperform QNN-Rot in classification tasks."}, {"title": "D. DISCUSSION", "content": "Overall, the results of the classification experiments on both datasets show that the proposed QNN-Int model reliably surpasses the performance of the QNN-Rot model for all kernel sizes, and was always able to surpass the performance of a classical CNN.\nIn the QNN-Int model, the function chosen to map pixel intensities to rotation angles plays an important role and can lead to very different performances. Among the tested functions, Simple and RndMul performed the best, while RndLin often reached lower performances"}, {"title": "VII. CONCLUSIONS", "content": "In this work, we presented a new quanvolutional model and preprocessing pipeline to make data quantization, encoding, and processing more efficient on NISQ devices. The proposed flexible quantization approach enabled a significant reduction in the number of quantum circuit executions required to process the datasets considered in this work. In particular, we obtained a reduction of over 95% circuit executions when using 3 \u00d7 3 kernels, while losing a negligible amount of information. This technique has the potential to be highly beneficial for quanvolutional approaches applied to tasks with similar properties.\nOur experiments also show that the proposed QNN-Int model can match or surpass the performance of classical CNN models on different datasets and with different parameter configurations. When compared with a standard quanvolutional model with rotational encoding (QNN-Rot), QNN-Int-Simple and QNN-Int-RndMul surpassed its performance on all tested configurations.\nThe proposed integrated encoding model features a large number of hyperparameters, including the number"}]}