{"title": "AssistantX: An LLM-Powered Proactive Assistant in Collaborative\nHuman-Populated Environment", "authors": ["Nan Sun", "Bo Mao", "Yongchang Li", "Lumeng Ma", "Di Guo", "Huaping Liu"], "abstract": "The increasing demand for intelligent assistants\nin human-populated environments has motivated significant\nresearch in autonomous robotic systems. Traditional service\nrobots and virtual assistants, however, struggle with real-\nworld task execution due to their limited capacity for dynamic\nreasoning and interaction, particularly when human collabo-\nration is required. Recent developments in Large Language\nModels have opened new avenues for improving these systems,\nenabling more sophisticated reasoning and natural interaction\ncapabilities. In this paper, we introduce AssistantX, an LLM-\npowered proactive assistant designed to operate autonomously\nin a physical office environment. Unlike conventional service\nrobots with limited reasoning capabilities, AssistantX leverages\na novel multi-agent architecture, PPDR4X, which provides it\nwith advanced inference capabilities, as well as comprehensive\ncollaboration awareness. By effectively bridging the gap be-\ntween virtual operations and physical interactions, AssistantX\ndemonstrates robust performance in managing complex real-\nworld scenarios. Our evaluation highlights the architecture's\neffectiveness, showing that AssistantX can respond reactively to\nclear instructions, actively retrieve supplementary information\nfrom memory, and proactively seek collaboration from team\nmembers to ensure successful task completion. More details\nand videos can be found at https://assistantx-agent.\ngithub.io/AssistantX/.", "sections": [{"title": "I. INTRODUCTION", "content": "Imagine having a capable assistant; you would naturally\nexpect it to handle various tasks on your behalf. For instance,\nif you wish to print a file but lack access to a printer, your ex-\npectation is simply to send the file to the assistant, which will\nmanage the rest-locating someone with a printer, requesting\nthem to print it, and ultimately returning the printed document\nto you. During this process, you wouldn't be concerned\nabout what transpires beyond receiving the printed file; any\nuncertainties or challenges can be autonomously addressed by\nthe assistant itself. Unfortunately, current service robots fall\nshort of such expectations due to their limited inference and\ncollaboration capabilities in navigating dynamic uncertainties\nwithin real-world environments. This inadequacy motivates\nus to develop AssistantX: an LLM-powered embodied agent\ndesigned for clarifying user instructions, exploring physical\nenvironments, and communicating with other team members\nfor assistance (see Fig.1). AssistantX is implemented through\na multi-agent architecture that can also be easily adapted for\nuse in various settings."}, {"title": "II. RELATED WORK", "content": ""}, {"title": "A. Mobile Robots in Human-Populated Environments", "content": "Mobile robots operating in human-populated environments\nhave become a major focus in robotics and embodied\nAl research. Early studies emphasized robots working in\nstructured settings with minimal human interaction, but"}, {"title": "B. LLM-Based Multi-Agent Systems", "content": "The development and deployment of multi-agent systems\nhave significantly evolved in recent years, especially with\nthe advent of large language models [8]. Refs. [9]-[14]\nleveraged a multi-agent framework to handle the task of\nGUI operations for smart devices. Ref. [15] also utilized a\nmulti-agent framework to autonomously discuss and evaluate\nthe quality of generated responses. Furthermore, Ref. [16]\nand Ref. [17] evaluated LLMs using multi-agent systems.\nThe systems were also widely deployed in communications\nbetween agents and humans for more detailed information\n[18]-[20]. Ref. [21] explored the integration of heterogeneous\ncyber agents into a collaborative network, enabling them to\nwork together and share intelligence across diverse systems\nand environments."}, {"title": "III. PROBLEM FORMULATION", "content": "Our objective is to develop an intelligent assistant robot\nframework that facilitates robots in accurately perceiving,\nanalyzing, and executing user commands within intricate of-\nfice settings, thereby enhancing users' efficiency in managing\ndaily tasks.\nGiven an office environment E, we assume it contains J\ndistinct working locations denoted as L = {l1,...,lj}, and\nthe set of the working person in this office is denoted as\nH = {h1,\u2026,hn}, where N is the number of these humans.\nThe location of the i-th person is denoted as Loc(hi) \u2208 L.\nIn this work, we study the general problem for an intelligent"}, {"title": "IV. METHODOLOGY", "content": "To address the inadequacy of inference capabilities in\ncurrent service robot systems, we present a multi-agent\nframework for AssistantX called PPDR4X (see Fig.3). In\na given office scenario, PPDR4X is capable of accurately\nperceiving the surroundings and human intentions, thereby\nformulating comprehensive plans based on user instructions.\nIt can also autonomously execute tasks and engage in self-\nreflection, even when the instructions are complex and lacking\nin detail. PPDR4X equips AssistantX with a problem-solving\nmindset similar to that of a human assistant, facilitating\nseamless integration into authentic work environments for"}, {"title": "A. Memory Unit", "content": "Memory Unit serves as the fundamental cornerstone of\nthe entire framework, it stores the initial dynamic map data\nprovided by human operators. As AssistantX carries out\ncommands, it updates the relevant virtual and physiscal world\ninformation. Concurrently, the agent's cognitive processes\nand actions throughout this procedure will also be recorded\nwithin it. To enhance AssistantX's efficiency in planning\nand executing consecutive operations, Memory Unit stores\nboth individual and group chat records generated during the\nexecution of instructions. Memory Unit will encapsulate,\nprocess, and organize both long-term memory (dynamic\nmap information in E) and short-term memory (comprising\ndialogue data D, thoughts generated by agents, and executed\ncyber tasks TC and real-world tasks TR). We use Mt\nto denotes the memory package that encompasses all the\nmemory data stored at Memory Unit at t time for effective\nutilization by Perception Agent."}, {"title": "B. Perception Agent", "content": "We anticipate AssistantX will possess human-like capabili-\nties in perceiving users' original instructions, virtual environ-\nment information, and real-world environment information.\nSo we build up Perception Agent as the initial phase in\nour pipeline. Perception Agent demonstrates proficiency in\nprocessing and amalgamating diverse data information based\non users' directives. It encapsulates both the intention infor-\nmation and the content of AssistantX's present surroundings,\nas well as its physical state, into a comprehensive perception\npackage intended for further elaboration by Planning Agent.\nThe perceptual process can be articulated as follows:\nPCt = perceive(I, Mt, SOt-1)   (1)\nwhere perceive(\u00b7) represents the perceiving process of LLM\nand PCt denotes the current t time perception package, while\nMt represents the memory package derived from Memory\nUnit at t time and SOt-1 denotes the summarized history\noperations generated by Planning Agent at t 1 time."}, {"title": "C. Planning Agent", "content": "The ultimate goal of a planning agent is to ensure that the\ngenerated plan aligns with the user's intention while opti-\nmizing for efficiency. This involves a continuous process of\nevaluation and adjustment, where a planning agent may itera-\ntively refine the plan as new information becomes available or\nas tasks are partially completed. Planning Agent in PPDR4X\nentails a thorough analysis of the t time perception package\nPCt to understand the current context, while meticulously\nconsidering all the historical information archived in Memory\nUnit. To enhance computational efficiency and planning\naccuracy as the data stored in Memory Unit continues to\naccumulate, Planning Agent provides a succinct summary\nof historical operations denoted as SO before formulating a\ndetailed plan. We articulate this process of making a holistic\nplan as follows:\nPLt = plan(Mt,PCt, SOt,Rt-1)   (2)\nwhere plan(\u00b7) represents the planning process of LLM, while\nPLt denotes the newly generated plan at t time and Rt-1\nrepresents the reflection result generated by Reflection Agent\nduring the previous iteration at t \u2013 1 time."}, {"title": "D. Decision Agent", "content": "Decision Agent is responsible for determining the specific\nactions that AssistantX must execute to fulfill the user's\ninstructions. This agent acts as the executor of the strategic\nplans, translating high-level objectives into precise operational\nsteps. To facilitate AssistantX to execute commands more\nsmoothly and achieve satisfying execution outcomes, we\ndefine an Action Xspace (see Table I) to guide the task\ngeneration process of Decision Agent.\nIn some cases, however, the outcome of an action executed\nby AssistantX may diverge from the anticipated result. Prior\nto generating and undertaking subsequent actions, Decision\nAgent will also evaluate the reflective outcomes from the\npreceding step to ensure that no critical tasks are overlooked or\nomitted. The decision-making process is designed to ensure\nthat actions are both feasible and aligned with the user's\nultimate goals, as outlined below:\nTCt,TRt = decide(Mt, PCt,PLt,TCt-1,TRt-1, Rt-1)   (3)\nwhere decide() denotes the decision process of LLM."}, {"title": "E. Reflection Agent", "content": "After TCt and TRt were executed separately, correspond-\ning alterations occur in the virtual environment, real-world\ncontext, and robot state, which can be found in Mt+1\nand PCt+1. Reflection Agent is tasked with assessing the\noutcomes of this task and rendering binary judgments 'Y' or\n'N'-based on its evaluation of these alterations. A 'Y' output\nindicates that Reflection Agent perceives the task's results\nas meeting the expected outcomes, whereas a 'N' output\nsignifies a deviation from those expectations. Reflection Agent\nwill integrate the binary outcome and its reflective reasons\nabout the outcome into a cohesive reflection result, which\nsubsequently prompts future planning and decision-making.\nThis reflective procedure is denoted as the following formula:\nRt = reflect(Mt,PCt, PLt, TCt, TRt, Mt+1, PCt+1)   (4)\nwhere reflect() represents the reflective process of LLM."}, {"title": "V. EXPERIMENT", "content": ""}, {"title": "A. Environment", "content": "To validate our framework in the physical world, we\ndeveloped a hybrid experimental platform, as is shown\nin Fig.4. This platform comprises two main components:\na semantic map mirroring our current real-world work\nenvironment, and a customized service robot equipped with\na smartphone."}, {"title": "B. Dataset", "content": "To build an objective, comprehensive, and diverse dataset,\nwe conducted an online survey titled: \"Which tasks would\nyou most prefer a service robot to assist you with in an\noffice environment?\". The questionnaire included 10 common\nscenario options, along with an open-ended text box for\nadditional suggestions. Over 300 students and faculty mem-\nbers from more than 10 universities and research institutions\nparticipated in the survey. Using the insights from these\nresponses, we developed a dataset to rigorously evaluate the\neffectiveness of our architecture in fulfilling user instructions.\nThe dataset comprises 30 base instructions along with their\ncorresponding 250 variants. For the base instructions, we\nensure that all relevant personnel are in their designated\npositions and can effectively coordinate with AssistantX to\ncomplete the instructions. In contrast, the variant instructions\nemerge as new branches from the base instructions, created\nwhen, for various reasons, the relevant personnel fail to\ncooperate with the robot as required. These variants introduce"}, {"title": "C. Evaluation", "content": "To assess the effectiveness of our architecture, we set\nsix evaluation metrics in TABLE II. We evaluated the\nperformance of GPT-40, Claude-3.5-Sonnet, and GLM-4-Plus\nas the base models for our framework, with detailed results\nprovided in TABLE III. For English instructions, ChatGPT-40\noutperformed the other two models, leading us to select it\nas the base model for our framework. The comprehensive\ntest results of our architecture can be found in TABLE IV,\nwhere it indicates that our multi-agent framework offers strong\neffectiveness and stability.\nTo further validate the effectiveness of each agent, we\nconducted ablation experiments, with detailed results also\nshown in Table IV. Our findings indicate that Planning Agent\nare crucial for effective instruction execution, as its removal\nin ablation experiments led to a significant decrease in both\nthe success and completion rates of instructions. Meanwhile,\nReflection Agent plays a key role in improving the redun-\ndant rates. Perception Agent further enhance performance,\neven when the framework is already functioning optimally,\ndemonstrating the significant impact on overall robustness(see\nFig.7).\nIn the ablation tests, we also analyzed the task error rates of\ndifferent instructions at their reachable depths (see Fig.8). The\nresults demonstrated that our architecture exhibits exceptional\nrobustness, maintaining stability even when handling long\nsequences of complex instructions. In contrast, the error rates\nof other ablated frameworks increased exponentially as the\ntasks progressed. More details can be found at https://\nassistantx-agent.github.io/AssistantX/."}, {"title": "VI. CONCLUSION", "content": "In this study, we present AssistantX, an advanced LLM-\npowered proactive assistant, designed to operate autonomously\nin a real-world office environment. By leveraging the PPDR4X\narchitecture, we endowed AssistantX with the ability to\nautonomously interpret, plan, and execute both cyber and real-"}]}