{"title": "Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks", "authors": ["Kai Li", "Khalid Zaman", "Xingfeng Li", "Masato Akagi", "Masashi Unoki"], "abstract": "Early detection of factory machinery malfunctions is crucial in industrial applications. In machine anomalous sound detection (ASD), different machines exhibit unique vibration-frequency ranges based on their physical properties. Meanwhile, the human auditory system is adept at tracking both temporal and spectral dynamics of machine sounds. Consequently, integrating the computational auditory models of the human auditory system with machine-specific properties can be an effective approach to machine ASD. We first quantified the frequency importances of four types of machines using the Fisher ratio (F-ratio). The quantified frequency importances were then used to design machine-specific non-uniform filterbanks (NUFBs), which extract the log non-uniform spectrum (LNS) feature. The designed NUFBs have a narrower bandwidth and higher filter distribution density in frequency regions with relatively high F-ratios. Finally, spectral and temporal modulation representations derived from the LNS feature were proposed. These proposed LNS feature and modulation representations are input into an autoencoder neural-network-based detector for ASD. The quantification results from the training set of the Malfunctioning Industrial Machine Investigation and Inspection dataset with a signal-to-noise (SNR) of 6 dB reveal that the distinguishing information between normal and anomalous sounds of different machines is encoded non-uniformly in the frequency domain. By highlighting these important frequency regions using NUFBs, the LNS feature can significantly enhance performance using the metric of AUC (area under the receiver operating characteristic curve) under various SNR conditions. Furthermore, modulation representations can further improve performance. Specifically, temporal modulation is effective for fans, pumps, and sliders, while spectral modulation is particularly effective for valves.", "sections": [{"title": "I. INTRODUCTION", "content": "Anomalous sound detection (ASD) for machine condition monitoring enables workers to arrange maintenance work to fix machine problems in the earliest stages of the anomaly, thus preventing sustained damage, reducing maintenance costs and optimizing production efficiency [1]. Developing advanced ASD systems is an important component of the fourth industrial revolution and has received increasing attention [2], [3].\nASD can be classified into two types of problems [4], that is, supervised ASD in which recordings of anomalous events to be detected are available in training, and unsupervised ASD in which recordings of the anomalous events are not available in training. Most methods for ASD are based on an unsupervised autoencoder (AE) model [5]\u2013[7] because of difficulties in collecting anomalous sounds that can cover all possible types of anomalies [8]. These methods are used to detect \"unknown\" anomalous sounds that have not been observed using reconstruction errors. However, because the training procedure does not incorporate anomalous sounds, the effectiveness of such models may be limited if the learned features also fit with the anomalous sounds.\nMany sophisticated models have been adapted and applied to further improve the effectiveness of back-end detectors [9]\u2013[11]. For example, the WaveNet architecture was used by Hayashi, et al. [12]. Marchi et al. [13] proposed an ASD approach that uses a denoising AE architecture with feedforward and long-short-term-memory units. The self-supervised approaches were used [14], [15] to provide some additional information, i.e., machine type and machine identity. Hoang et al. [16] proposed an AE architecture, called Fully-Connected U-Net, to replace the conventional AE model. However, the performance of deep neural network (DNN)-based ASD methods depends significantly on the discrimination of acoustic front-ends. The acoustic front-end refers to the pre-processing stage that extracts features from raw audio signals before feeding them into the DNN. If the front-end can effectively capture and represent the relevant acoustic features, the DNN will have better discrimination power.\nThe human auditory system has been shown to be effective and robust against noise in many types of recognition tests [17]\u2013[19]. Therefore, it is intuitive to include the properties of human auditory in the extraction of acoustic front-ends for potential performance enhancement. The novel aspect of this paper is investigating acoustic features and representations inspired by various stages of the auditory system for machine ASD.\nVarious computational auditory models (CAMs) have been proposed to simulate these auditory processes. They are based on neurophysiological, biophysical, and psychoacoustical investigations at various stages of the auditory system [20]\u2013[22]."}, {"title": "II. COMPUTATIONAL AUDITORY MODELS", "content": "To establish a foundation for the proposed features and representations, we briefly discuss the CAMs presented in previous studies [39] and [40]. As illustrated in Fig. 1, there are basically two modules in CAMs. The first one is the cochlea module for the auditory-spectral analysis, and the second one is the central cortical module for modulation analysis.\nA. Cochlea Module for Auditory-spectral Analysis\nThe cochlea module models the peripheral functions of the auditory system, specifically the role of the cochlea as a frequency analyzer. Chi et al. [40] used a bank of 128 overlapping asymmetric constant-Q bandpass filters to mimic the frequency selectivity of the cochlea. These filters decompose the acoustic signal into distinct frequency components, simulating how the basilar membrane in the cochlea processes sound.\nThe output from each filter undergoes non-linear compression, mimicking the saturation behavior of inner hair cells, followed by a lateral inhibitory network that enhances spectral resolution by sharpening the filter responses. The envelope of the signal is then extracted, producing an auditory spectrogram that represents the time-frequency distribution of the sound.\nThe auditory spectrogram produced with the linear cochlear module is similar to the magnitude response of a Mel-scaled Fourier-transform-based spectrogram. This similarity is due to the constant-Q criterion of the filterbank in the cochlear module, which sets the bandwidth proportional to the center frequency. This criterion mirrors the effects of logarithmic filter spacing in the Mel scale. Additionally, the local envelope extraction process in the cochlear module also approximates the magnitude of a Fourier transform-based spectrogram, capturing the energy distribution across frequencies over time in a manner consistent with how a Mel-scaled spectrogram operates. Therefore, the extracted auditory spectrogram can also be replaced with a Mel spectrogram through a simplified method, as in a previous study [26].\nThe Mel filterbank (MFB) and GFB are widely used and share similar characteristics, as they both have the property that the bandwidth is proportional to the center frequency. The GFB is considered the best representation of the auditory characteristics of the cochlea because it closely mimics the frequency selectivity of the human auditory system. The MFB is the most commonly used in engineering applications due to its simplicity and effectiveness. However, in machine ASD, the importance of different frequency regions may not decrease with the increase in frequency for different types of machines. These two filterbanks, particularly the MFB, may not be optimal for machine ASD because they are designed to mimic human hearing rather than capturing the specific spectral-temporal characteristics that may be more relevant for identifying anomalies in machine sounds.\nB. Central Cortical Module for Modulation Analysis\nThe central cortical module models the spectro-temporal selectivity of neurons within the auditory cortex, focusing on how these neurons process and analyze complex auditory signals. This module further analyzes the auditory spectrogram, which is initially generated by the cochlear module, by applying two-dimensional filters tuned to various STM parameters. These parameters include rate, which reflects the velocity of temporal variations in the spectro-temporal envelope (measured in Hz), and scale, which characterizes the density of these variations along the log-frequency axis (measured in cycles per octave).\nThe output of this cortical processing is referred to as the STM representation, which captures the spectral-temporal structures of an input sound at each time instant. These structures encompass various auditory features, such as pitch, harmonicity, formant spacing, amplitude modulation (AM), and frequency modulation (FM). Pitch, AM, and FM, are closely related to the prosody and timbre of the sound, while the others are related to its spectral characteristics. The STM representation, therefore, encodes both prosodic and spectral features, making it a valuable tool for tasks such as speech emotion recognition [33], [40]."}, {"title": "III. PROPOSED METHODS FOR MACHINE ASD", "content": "Figure 2 illustrates the block diagram of the proposed STM analysis method. The process begins with the training dataset, which has an SNR of 6 dB. The first step involves calculating the F-ratio, which is then used to design machine-specific NUFBs. Subsequently, the short-time Fourier transform (STFT) is applied to the training set to obtain the time-frequency representation. The output from the STFT is processed through the designed NUFBs, and the resulting power spectrum is converted to a logarithmic scale before being passed through a modulation filterbank. The output of the logarithmic operation is the LNS feature. This sequence produces two sets of modulation representations: TM and SM, as illustrated in the lower part of the figure. This section focuses on the three main components of the STM analysis process: the calculation of the machine-wise F-ratio, design of machine-specific NUFBs, and STM analysis.\nA. Calculation of Machine-wise F-ratio\nThe frequency bands with more discriminative features should have high inter-class variances and low intra-class variances between normal and anomalous sound classes [30]. Therefore, we define the F-ratio for machine $m$ as\n$F_{m}=\\frac{1}{C} \\frac{\\sum_{c=1}^{C}\\left(U_{m, c}-U_{m}\\right)^{2}}{\\frac{2}{C} \\sum_{c=1}^{C} \\sum_{i=1}^{N}\\left(x_{m, c}^{i}-U_{m, c}\\right)^{2}},$ (1)\nwhere $x_{m, c}^{i}$ is the sub-band energy of the $i$-th audio of class $c$ with $i=1,2, \\ldots, N, m \\in\\{$ fan, pump, slider, valve $\\}$, and $c \\in\\{$ normal, anomaly $\\}$. $U_{m, c}$ and $u_{m}$ are defined as:\n$U_{m, c}=\\frac{1}{N} \\sum_{i=1}^{N} x_{m, c}^{i}$ (2)\n$U_{m}=\\frac{1}{2 N} \\sum_{c}^{C} \\sum_{i=1}^{N} x_{m, c}^{i}$ (3)\nThey are used to calculate the variables that represent the sub-band energy averages for class $c$ and for all classes, respectively.\nEquation (1) is the ratio between the inter-class and the intra-class variances of the speech power in a given frequency band. A larger value obtained in a frequency band means that more discriminative information is encoded in that band.\nB. Design of Machine-specific Non-uniform Filterbanks\nTo show the correctness of the quantification results, we designed NUFBs and used them to extract the LNS feature for each machine. The NUFBs were designed by highlighting (narrower bandwidth and higher filter distribution density) the frequency bands with relatively high F-ratios.\nThe distribution density of the triangular band-pass filters is assigned to be directly proportional to the F-ratios. On the contrary, the bandwidth of the triangular band-pass filters is assigned to be inversely proportional to the F-ratios. The steps for designing an NUFB are as follows:\n1) calculate the weight $k$ on the basis of the $F_{m}, k=\\frac{f s}{\\left(2 \\times \\sum F_{m}\\right)}$, where $f_{s}$ is the sampling frequency,\n2) calculate the cumulative sum of the weighted $F_{m}, C S=$ Cumsum $\\left(k \\times F_{m}\\right)$,\n3) fit the curve of the mapping frequency from the linear scale to the adaptive scale by using the cubic spline interpolation,\n4) calculate the center frequencies and bandwidth of the triangular band-pass filters $C(j)$ on the basis of the fitting curve, and\n5) design an NUFB with the non-uniform resolutions.\nC. Spectral-temporal Modulation Analysis\nThis section details the extraction of SM, TM, and STM representations using modulation filters with specific cut-off frequencies and designed machine-specific NUFBs. Let us define the output of the filterbank design as $s(n,t)$, where $n$ refers to the number of channels in the filterbanks, and $t$ is the number of frames. The $k$th modulated representation in the $n$th channel can then be calculated as\n$s(n, k, t)=r(k, t) * s(n, t), 1 \\leq k \\leq K,$ (4)\nwhere $r(k,t)$ is the impulse response of the $k$th modulation filter, and $K$ is the number of modulation channels. Different modulation channels have different cut-off frequency. A high modulation frequency corresponds to fast modulations and vice versa.\nSM focuses on capturing variations in the spectral content of the sound signal. It provides insights into how the energy distribution across different frequency bands changes over time. TM captures the temporal dynamics of the sound signal, emphasizing how the amplitude varies over time. This is particularly useful for identifying temporal patterns such as periodicity or irregularities in machine sounds. STM combines both spectral and temporal information, providing a comprehensive representation of the modulation characteristics of audio. These multi-resolution feature representations capture the interaction between spectral and temporal variations, providing a robust tool for distinguishing between normal and anomalous sounds."}, {"title": "IV. ANOMALY SOUND DETECTION USING AUTOENCODER MODEL", "content": "The AE model consists of three primary modules: the encoder, bottleneck layer, and decoder. The encoder compresses the input data into a lower-dimensional representation, capturing the essential features of the normal sound. The bottleneck layer, which has the smallest number of neurons, acts as a constraint that forces the model to learn the most important features. The decoder then reconstructs the input data from this compressed representation.\nEach module of the AE model is constructed using fully connected layers. The batch normalization and activation functions of the rectified linear unit (ReLU) are followed after each fully connected layer. The mean squared error (MSE) is utilized as the cost function to optimize the AE model. The MSE measures the average squared difference between the input and the reconstructed output, providing a clear indication of how well the model has learned to replicate normal sounds.\nDuring training, the AE model learns to minimize the MSE for normal sound examples, effectively capturing their inherent patterns and characteristics. In the testing phase, sound samples are passed through the trained AE model, and the reconstruction error is calculated. Sound samples that result in high reconstruction errors are flagged as anomalous."}, {"title": "V. DATABASE STATISTICS", "content": "The MIMII dataset [41] comprises normal and abnormal sounds from four types of industrial machines: fans, pumps, sliders, and valves. Each type of machine includes multiple individual models identified by specific IDs. For instance, fan machines have four different IDs: 0, 2, 4, and 6. Each sound example in the dataset is 10 seconds long, recorded at a 16-kHz sampling rate using 8 microphones.\nThe MIMII dataset is publicly available with recordings at three different SNRs: -6, 0, and 6 dB. Real factory noise was recorded in multiple factories and added to the original machine sounds to create these different SNR conditions. Notably, there are three subsets of sound recordings, each corresponding to a different SNR level.\nNormal and abnormal sounds were recorded in a reverberant environment, capturing the typical operating conditions of these machines. The background noise, recorded in real factories, was mixed with the machine sounds to simulate realistic conditions. The dataset includes a total of 14,719 sound files for normal conditions and 3,300 for abnormal conditions, as detailed in Table I.\nWe seleectd the MIMII dataset for our experiments due to its comprehensive coverage of machine types and realistic noise conditions. Fans exhibit unbalanced or clogging problems in abnormal situations, pumps encounter leakage or clogging problems, sliders suffer from rail damage or lack of grease, and valves encounter various contaminations. This dataset provides a robust foundation for developing and testing anomaly detection methods in industrial settings."}, {"title": "VI. EXPERIMENTAL SETUP AND EVALUATION METRIC", "content": "To extract the LMS feature, 10-s audio clips were first split into different frames with frame lengths of 64 ms and hop lengths of 32 ms. The Mel spectrogram feature was then extracted with the following parameters: n_fft=1024, hop_length=512, num_filters=128, and power = 2.0. We extracted the LNS and LGS features using the same configuration but different types of filterbanks compared with the LMS feature. Five consecutive frames with a sliding window were concatenated into one feature vector with a dimension of 640 and fed into the detector. For example, we assumes that the input signal is $X=\\left\\{X_{t}\\right\\}_{t=1}^{T}$ where $X_{t} \\in \\mathbb{R}^{M}$, and $M$ and $T$ are the number of Mel-filters and time-frames, respectively. Then, the acoustic feature at t was obtained by concatenating consecutive frames of the feature as $V_{t} \\in \\mathbb{R}^{D}$, where $D=P \\times M, P=5, M=128$ and $D=640$. For the modulation representations, the dimension $D=P \\times M \\times K$, where K is the number of modulation channels. K is equal to 6, 6, and 12 for SM, TM and STM, respectively. The reconstruction error is calculated as\n$E(X)=\\frac{1}{T} \\sum_{t=1}^{T} \\frac{1}{D}||V_{t}-r(V_{t})||_{2},$ (5)\nwhere $r(t)$ is the vector reconstructed with the AE model, and $||2$ is L2 norm.\nIn our implementation, three variations of the AE model were explored, each differing in the number of neurons in the fully connected layers: 64, 128, and 256. These variations enable us to assess the impact of model complexity on detection performance. Detailed information on the layer structure for each variation is provided in Table II.\nModulation filters include a low-pass filter with a cut-off frequency of 2 Hz and band-pass filters with cut-off frequencies of [2, 4], [4, 8], [8, 16], [16, 32], and [32, 64] Hz. All filters were designed with the Butterworth infinite impulse response (IIR) filter.\nWe used the area under the receiving operating characteristic curve (AUC) as the evaluation metric to assess the performance of proposed features and representations. The AUC represents the degree or measure of separability achieved with the AE model: an AUC of 1.0 indicates perfect classification, while an AUC of 0.5 suggests no discriminative power, equivalent to random guessing."}, {"title": "VII. EVALUATION RESULTS", "content": "Timbre features [42], such as boominess, brightness, depth, roughness, and sharpness, are well-established in audio analysis for their effectiveness in capturing the tonal quality and texture of sounds. These features are crucial for differentiating between various sound sources and understanding the auditory characteristics. The modulation representations, however, are highly effective in capturing dynamic variations in both time and frequency domains, including not only the qualities reflected by timbre features but also additional discriminative information such as temporal rhythm and spectral changes [38]. We compared the performance of timbre features with the proposed features and representations. By comparing these two feature sets, the aim was to evaluate whether the STM representations offer a significant advantage over timbre features in distinguishing machine anomalies.\nIn this section, we present and analyze the experimental results on machine ASD using the MIMII dataset. We evaluated the performance of proposed LNS feature in comparison with the timbral, LMS, and LGS features. We also discuss the effectiveness of the STM representations derived from LMS, LGS, and LNS features under SNRs of -6 dB, 0 dB, and 6 dB.\nA. Results of Frequency Quantification\nFigure 3 presents the quantification results of frequency importance for different machines and IDs using the F-ratio. Training data with SNR = 6 dB were used for the calculations and the frequency importance was normalized from 0 to 1.\nThe MFB and GFB are designed according to the pitch perception and auditory perception of the human ear, respectively, and traditionally emphasize lower-frequency regions. However, the F-ratio results in Fig. 3 reveal that discriminative information between normal and anomalous sounds is distributed non-uniformly across the frequency spectrum. For some machines and their specific IDs, higher-frequency regions contain significant discriminative information. For instance, in the case of the Pump ID 4, slider ID 6, and Valve ID 4, there were notable peaks in the mid- to high- frequency regions, indicating that these frequencies are important for distinguishing between normal and anomalous sounds. This contrasts with the general MFB tendency and highlights the need for machine-specific frequency analysis.\nSimilar machines exhibited consistent trends in frequency band importance. For example, the fans (Fan IDs 0, 2, 4, and 6) consistently showed higher importance in the lower-frequency regions, though the exact distribution varies slightly across different IDs. The designed machine-specific NUFBs are illustrated in Fig. 4. Narrower bandwidth and higher filter distribution density appear in the frequency regions that exhibit higher F-ratios.\nFigure 5 presents a comparative analysis of the LMS and proposed LNS feature using normal and abnormal audio signals emitted from slider ID 6 with an SNR of 6 dB. The figure illustrates how the LNS feature, designed based on the quantification results, enhance the resolution and discriminative power of frequency regions with higher F-ratios. In the LMS feature, the frequency importance decreases from lower to higher frequencies, resulting in a broader and smoother frequency representation. In contrast, the LNS feature focus on regions with higher F-ratios, leading to finer granularity and clearer representation of these critical frequencies. The differences between normal and abnormal sounds are more distinct in the LNS feature. This is especially visible in the frequency regions, where the F-ratios are higher. For instance, at frequencies around 100 and 5,000 Hz, the LNS feature reveal distinct patterns that differentiate normal and abnormal conditions more effectively than the LMS.\nB. Results of proposed LNS feature\nTable III presents the comparison of various features, including timbral, LMS, LGS, and LNS features, for four types of machines at an SNR of 6 dB. Timbral features include boominess, brightness, depth, roughness, sharpness, amplified shimmer (AS), and amplified predominant frequency (APF), as reported in a previous study [38]. The results of the LNS feature are proposed in this paper.\nThe LNS feature consistently outperformed the timbral features in all machine types except the pump. For instance, in the case of the fan, the LNS feature achieved an average score of 0.950, significantly higher than the best timbral feature (brightness), which has an average score of 0.828. Similarly, for the slider, the LNS feature attained an average score of 0.980, compared with the highest timbral feature score of 0.884 (roughness). The LNS feature also demonstrated superior performance compared with the LMS and LGS features. For the slider, the LNS feature achieved an average score of 0.980, while the LMS and LGS features reached 0.868 and 0.941, respectively. For the valve machine, the LNS feature showed a marked improvement with a score of 0.842 compared with 0.673 and 0.801 from the LMS and LGS features, respectively.\nThe slider showed the most significant improvement with LNS feature, with perfect scores for IDs 0 and 4, indicating its effectiveness in capturing anomaly-related patterns. The fan and valve also benefited notably from the LNS feature, though the improvement was less pronounced than for the slider. On average, the LNS feature achieved the highest scores across all machines with a total average score of 0.881, compared with the average scores of 0.808 and 0.863 for the LMS and LGS features, respectively, significantly higher than the average scores of the individual timbral features.\nWhile the overall performance of the LNS feature was superior, there were instances in which the performance was suboptimal. Notable examples include pump ID 6 and valve ID 6. This problem can be attributed to the independent calculation method of frequency band importance while using the F-ratio. Consequently, unique operational characteristics or noise patterns of pump ID 6 and valve ID 6 may not be effectively captured with the LNS feature.\nUnlike the timbral features, which are fixed and may not effectively capture relevant information across different types of sounds, the LNS feature were designed to adaptively emphasize important frequency regions, thus capturing more discriminative features to the distinction between normal and anomalous sounds, as demonstrated by the consistent improvement in detection scores.\nC. Results of Spectral-temporal Modulation Analysis\nTable IV presents the averaged results for different modulation representations derived from the LMS, LGS, and LNS features in four types of machines under varying SNR conditions (-6, 0, and 6 dB). Despite being calculated from data with an SNR of 6 dB, the LNS feature performed well across all SNR levels, consistently outperforming the LMS features in average AUC. For example, at -6 dB SNR, the average AUC for the LNS feature was 0.702, while that for the LMS feature was 0.662. This trend continued at 0 and 6 dB SNR levels, with the LNS feature achieving average AUC scores of 0.785 and 0.881, respectively.\nThe STM representation derived from the LNS feature outperformed those derived from the LMS and LGS features across all SNR conditions on average. For example, at -6 dB SNR, STM (LNS) achieved an AUC of 0.702 compared to 0.624 and 0.657 of STM (LMS) and STM (LGS), respectively. The TM derived from the LNS feature showed a significant improvement over the LMS, particularly for the fan, pump, and slider. At 6 dB SNR, TM (LNS) achieved AUC scores of 0.974, 0.945, and 0.930, respectively. The SM derived from the LNS feature performed well for the valve. At -6 dB SNR, SM (LNS) achieved an AUC of 0.737, compared to 0.434 and 0.505 for SM (LMS) and SM (LGS), respectively.\nAlthough STM combine the advantages of SM and TM, it does not always produce the best performance for all types of machines. This is evident in the valve at 0 dB SNR, where STM (LNS) achieved an AUC of 0.528, which is lower than both SM (0.757) and TM (0.559). This may be due to the increased complexity of STM representations, which could lead to insufficient capture of anomaly patterns when using a simple AE model.\nOverall, the results indicate that the proposed LNS feature, particularly in the TM and STM representations, significantly enhance anomaly detection performance across various machine types and SNR levels. However, certain types of machines, such as valves, require further optimization to improve detection accuracy. A more detailed discussion on why the effectiveness of modulation representations varies across different machines is provided in Section VIII.\nD. Results of Different Model Settings\nTable V presents the AUC performance of TM, SM, and STM (derived from the proposed LNS feature) with three different model configurations across various types of machines. The best results for each modulation representation and machine type are in bold.\nPerformance can be further increased by increasing the number of neurons in fully connected layers. Specifically, for the fan and slider using TM, increasing the number of neurons from 64 to 128 led to an increase in AUC from 0.85 to 0.88 and from 0.87 to 0.91, respectively. However, increasing the number of neurons from 128 to 256 does not result in a significant performance improvement.\nThese machines benefit significantly from the TM and STM representations, with Models 2 and 3 providing the best results. This suggests that the temporal dynamics captured with these representations are crucial for detecting anomalies in these machines. The pump showed balanced performance across all feature types, with TM and STM representations performing similarly well. This indicates that both spectral and temporal information is important for this type of machine. The valve exhibited lower overall performance, with the SM performing better than the TM and STM representations. This suggests that anomalies in the valve may be more related to spectral characteristics than temporal dynamics.\nE. Performance Comparison with Existing Methods\nTable VI compares the averaged AUC performance of our proposed feature representations (TM, SM, and STM derived from LNS) with existing systems on the MIMII dataset. The results were averaged on four machine IDs (0, 2, 4, 6) and three SNR levels (-6, 0, and 6 dB).\nThe best performance for the fan was reported by Inoue et al. [46] with an AUC of 0.88 using a convolutional neural network (CNN) with ensemble data augmentation. Our methods, both the TM and STM representations, achieved an AUC of 0.88, which is similar to the best-performing method. However, the SM representation showed a lower AUC of 0.66. In the case of the pump, the highest AUC of 0.93 was again reported by Inoue et al. [46]. Our TM and STM representations achieved a high AUC of 0.89, which is competitive with but slightly lower than the best-performing method.\nFor the slider, Inoue et al. [46], Giri et al. [47], and Ding et al. [50] reported outstanding AUCs of 0.99, 0.97, and 0.97, respectively. Our TM and STM representations achieved a high AUC of 0.91, which is close but not the highest. The SM representation had an AUC of 0.86. The valve showed the highest performance from Inoue et al. [46] and Giri et al. [47] with AUC of 0.99 and 0.97, respectively. Among the proposed representations, the best performance was from the SM representation with an AUC of 0.78.\nIn summary, our proposed representations performed well across the fan, pump, and slider, achieving outstanding results compared with most AE-based methods. However, they do not outperform methods that utilize complex training systems with data-augmentation techniques."}, {"title": "VIII. DISCUSSION", "content": "To explain why the proposed modulation representations, particularly TM and STM, demonstrated strong performance for the fan, pump, and slider but not for the valve, we present a comparison of spectrograms between normal and anomalous sounds for these four types of machines, as illustrated in Fig. 6.\nIn the machine ASD task, modulation representations capture the dynamic changes in both the spectral and temporal domains of an audio signal. These representations are closely related to the concepts of periodicity and harmonicity, which are key features in detecting anomalies in machine sounds. Periodicity refers to the regular, repeating patterns in the time domain. Modulation representations, particularly TM, can effectively capture these periodic patterns by analyzing the rate at which the amplitude or frequency content changes over time.\nHarmonicity refers to the alignment and relationship of frequencies within a sound, typically resulting in a harmonic series where the frequencies are integer multiples of a fundamental frequency. This is often seen in mechanical sounds with regular, cyclic components. SM representation are well-suited to capture harmonicity because they analyze how frequency components are organized and how they evolve over time. A normal sound might exhibit strong harmonicity, whereas an anomalous sound might introduce inharmonic components or alter the existing harmonic structure.\nIndustrial fans generate a continuous, stationary sound due to the constant flow of air or gas. The sound produced typically has a strong periodicity in the time domain, corresponding to the rotating blades, and harmonicity in the frequency domain due to the regular motion of the fan blades. TM and STM representations can effectively capture the periodicity and harmonicity in fan sounds. Anomalous sounds, such as changes in blade rotation speed or disruptions in airflow, can manifest as deviations from this regular pattern, which STM representation can detect. The strong periodic and harmonic structure of fan sounds makes them well-suited for detection using modulation representations, leading to improved ASD performance.\nWater pumps produce a more complex sound, combining stationary components (continuous operation) with non-stationary elements (variations in flow or pressure). The sound might exhibit periodicity corresponding to the pump cycles and some harmonic structures due to the mechanical components. STM and TM representations can capture the regular, cyclical nature of a pump's operation, as well as any anomalies that disturb this regularity. Anomalous sounds might appear as irregularities in the temporal or spectral patterns, which STM representation can detect. Since pump has both stationary and non-stationary features, modulation representations can enhance ASD performance by distinguishing between normal operation and subtle deviations caused by anomalies.\nLinear slide systems generate sounds that are typically stationary but may include transient, non-stationary elements depending on the movement speed and direction. The regular movement of the slider creates a rhythmic pattern in the sound, which might have harmonicity. Modulation representations are effective in capturing the rhythmic, periodic patterns of slider sounds. Anomalies in slider operation, such as changes in speed or friction, would likely disrupt the regular sound pattern. STM representation can detect these disruptions by analyzing the deviations in both temporal and spectral modulations, resulting in improved ASD performance.\nSolenoid valves produce non-stationary sounds due to repetitive opening and closing. These sounds might not exhibit strong periodicity or harmonicity because the operation is more irregular and transient. The nature of the sound could be more impulse-like, with rapid changes and less continuity. The lack of strong periodicity and harmonicity in valve sounds makes them less suitable for modulation-based analysis. STM and TM representations rely on detecting regular patterns or deviations from such patterns, but in the case of valves, the sound might not have a consistent structure for these representations to analyze effectively. As a result, the modulation representations might not capture the anomalous features as clearly as they do with the other machines, leading to poorer ASD performance.\nIn summary, modulation representations are effective for machines such as fans, pumps, and sliders due to the presence of periodicity and harmonicity in their normal operation sounds, which are disrupted by anomalies. However, for valves, the irregular and transient nature of the sound lacks the consistent patterns that modulation representations rely on, making them less effective for ASD in this case."}, {"title": "IX. CONCLUSION", "content": "We quantified and visualized the importance of the frequency for different machines using a statistical method, the F-ratio. Our analysis revealed that discriminative information is distributed non-uniformly across the frequency spectrum, with certain machines and IDs showing more significant differences in the higher frequency regions. On the basis of these findings, we designed machine-specific NUFBs and proposed LNS features to emphasize frequency bands with relatively high F-ratios, enhancing the extraction of discriminative features.\nWe proposed STM representations derived from the proposed LNS features, with the aim of capturing variation information in the spectral and temporal domains for machine ASD. The proposed LNS feature and their modulation representations (SM, TM, and STM) were evaluated using a simple unsupervised AE model on the MIMII database with SNR levels of -6, 0, and 6 dB. The results indicated that our proposed LNS feature and modulation representations can significantly improve the performance of MFB feature. Specifically, temporal modulation proves to be effective for fans, pumps, and sliders, while spectral modulation is particularly effective for valves. Furthermore, the effectiveness of our proposed features and representations is highly competitive compared to existing methods.\nFuture work will focus on integrating more sophisticated neural network-based detectors to further enhance the performance of ASD systems. Furthermore, exploring other machine learning techniques and optimizing the design of filterbanks could yield further improvements, contributing to the development of more robust and efficient anomaly detection systems."}]}