{"title": "AI-DRIVEN SKIN CANCER DIAGNOSIS: GRAD-CAM AND EXPERT ANNOTATIONS FOR ENHANCED INTERPRETABILITY", "authors": ["Iv\u00e1n Matas", "Carmen Serrano", "Francisca Silva-Claver\u00eda", "Amalia Serrano", "Tom\u00e1s Toledo-Pastrana", "Bego\u00f1a Acha"], "abstract": "An AI tool has been developed to provide interpretable support for the diagnosis of BCC via teledermatology, thus speeding up referrals and optimizing resource utilization. The interpretability is provided in two ways: on the one hand, the main BCC dermoscopic patterns are found in the image to justify the BCC/Non BCC classification. Secondly, based on the common visual XAI Grad-CAM, a clinically inspired visual explanation is developed where the relevant features for diagnosis are located. Since there is no established ground truth for BCC dermoscopic features, a standard reference is inferred from the diagnosis of four dermatologists using an Expectation Maximization (EM) based algorithm. The results demonstrate significant improvements in classification accuracy and interpretability, positioning this approach as a valuable tool for early BCC detection and referral to dermatologists. The BCC/non-BCC classification achieved an accuracy rate of 90%. For clinically-inspired XAI results, the detection of BCC patterns useful to clinicians reaches 99% accuracy. As for the Clinically-inspired Visual XAI results, the mean of the Grad-CAM normalized value within the manually segmented clinical features is 0.57, while outside this region it is 0.16. This indicates that the model struggles to accurately identify the regions of the BCC patterns. These results prove the ability of the AI tool to provide a useful explanation.", "sections": [{"title": "1 Introduction", "content": "Skin cancer is the most commonly diagnosed cancer worldwide, with Melanoma, Basal Cell Carcinoma (BCC), and Squamous Cell Carcinoma (SCC) being the most prevalent types. BCC accounts for approximately 75% of all skin cancers, making it the most frequent form. It has well-established clinical criteria for diagnosis, yet there is significant variability in the presence of these clinical criteria between cases [1, 2, 3, 4].\nMany research efforts seek to diagnose various skin diseases. Additionally, the number of published papers has increased significantly in recent years, driven by the development of public databases [5, 6, 7, 8]. Although these databases are accessible and comprehensive for everyone, the clinical criteria used for diagnosis are not readily available. To develop a tool that is useful from a medical perspective, it is crucial to provide not only classification metrics, but also a detailed diagnosis explaining the detected clinical features, thereby offering a more comprehensive result. In this context, Serrano at al. [9] developed a clinically inspired skin lesion classification tool through the detection of dermoscopic criteria for BCC.\nXAI techniques such as Grad-CAM [10] play a crucial role in improving the transparency and interpretability of CNNs\nin any kind of medical diagnostics. By offering visual explanations of the decision-making process, these methodologies\nallow medical professionals to gain insight into the predictive mechanisms of AI models, thus fostering trust and\nacceptance in AI-driven diagnostics. In recent years, XAI has become an active field of research and numerous review\npapers have been published [11, 12, 13].\nIn particular, there are some recent papers on XAI in skin image analysis. Barata et al. uses attention modules to\nimprove explainability in hierarchical skin lesion diagnosis [14]. Chanda et al. developed a multimodal XAI system\nto support dermatologists in diagnosing melanoma, which offers text and region-based explanations alongside its\ndiagnostic predictions [15]. Rezk et al. developed an interpretable skin cancer diagnosis model using clinical images\nto assist general practitioners in early detection and referral. Their approach incorporates visual explanations of the\nmodel's decisions based on Grad-CAM++ [16].\nIn these previous works, XAI is used to visualize the regions where the models have focused to extract features. The\nproposed method goes a step further: It proposes a clinical interpretation by localizing regions of clinical interest for\ndiagnosis, specifically BCC dermoscopic features, and providing clinical labels."}, {"title": "2 Methodology", "content": "In modern healthcare, primary care physicians use teledermatology systems to receive high-quality diagnostic images\nremotely, allowing preliminary diagnoses of Basal Cell Carcinoma (BCC) using established patterns [4, 17]. Suspected\nBCC cases are promptly referred to dermatology specialists, improving healthcare efficiency, reducing waiting times,\nand facilitating early intervention.\nTeledermatology is crucial in areas with limited specialist access and its integration with AI tools promises to enhance\ndiagnostic accuracy and efficiency. This work aims to develop an AI tool to assist in this process by providing a\nbinary classification of BCC/non-BCC with interpretable results Fig. 1 illustrates the current and proposed diagnostic\nworkflows."}, {"title": "2.1 Database", "content": "The entire database was provided by the Dermatology Unit of the \"Hospital Universitario Virgen Macarena\" and were\nsent over 2 years from 60 primary care centers. The dataset comprises 1559 dermoscopic images divided into 3 subsets.\nFour dermatologists provided different types of annotation according to the subsets. Specifically:\n\u2022 The first subset consisted of 1089 dermoscopic images. Initially, the labeling annotations for these images\nwere the presence or absence of each of the dermoscopic features involved in the diagnosis of BCC.\n\u2022 A second subset of 334 images is additionally enriched with dermatologist delineations of BCC dermoscopic\npatterns within each image. More than one segmented area may appear on an image if there are multiple\npatterns in the BCC lesion. In the Fig. 3 an example is shown.\n\u2022 The third subset is made up of 136 non-BCC images, mostly consisting of nevus lesions, from the ISIC archive\n[8].\nTable 1 summarizes the distribution of labels in the database. As can be seen in this table, the database has a significant\nclass imbalance, with SW and MG underrepresented. Several techniques have been used to address this problem."}, {"title": "2.1.1 Label codification", "content": "Each image may contain multiple dermoscopic patterns. Therefore, a one-hot coding scheme was used to encode the\nlabels during image annotation and subsequently to process the dermatologists' annotations. Each image label is a\nbinary word and each BCC dermoscopic pattern is a digit, where 1 means presence and 0 means absence. The seven\npatterns that can appear in a BCC lesion are[4, 18, 17]: Pigment Network (PN) (negative criterion), Ulceration (U),\nOvoid Nests (ON), Multiglobules (MG), Maple Leaf-like (ML), Spoke Wheel (SW), Arborizing Telangiectasia (AT)\n(Fig. 2). Thus, each label is a vector of dimensions [1x7]. In Table 2 there are some examples of this process."}, {"title": "2.1.2 Standard Reference Inferring", "content": "The accepted ground truth (GT) for BCC diagnosis is biopsy. However, there is no established GT for BCC dermoscopic\npatterns, which are subjectively assessed by dermatologists. Several studies have reported a low kappa coefficient\nwhen measuring inter-dermatologist agreement in determining the different dermoscopic patterns present in a lesion\n[19, 17]. Therefore, an adequate SR inferred from the consensus of several dermatologists is required. An Expectation-\nMaximization (EM) based algorithm [20] was implemented to derive a single SR for model training from multiple\nspecialist labels. This algorithm consolidates multilabel annotations from different dermatologists and generates a\nsingle inferred SR that encapsulates the collective expertise of the raters. Silva et al. [21] used this algorithm to infer\nand SR from BCC pattern annotations and demonstrated that integrating this diverse expertise mitigates the subjectivity\ninherent in diagnosing the BCC pattern and improves the reliability and robustness of the classification model."}, {"title": "2.2 Clinical inspired XAI", "content": "From a clinical point of view, achieving 100% accuracy in detecting BCC dermoscopic patterns is not crucial for a\ncorrect diagnosis of BCC. A dermatologist requires detecting just one correct BCC dermoscopic pattern to make an\naccurate BCC diagnosis. Therefore, a useful clinically-inspired XAI should provide any of the following outcomes: if\nno patterns are detected, it predicts non-BCC; if the PN pattern is detected, it serves as a negative criterion, explaining a\nnon-BCC prediction; and if any other BCC pattern is detected, the prediction is positive for BCC."}, {"title": "2.3 Clinical visual X\u0391\u0399", "content": "To develop this concept, expert-generated segmentations are used. As detailed in Sect. 2.1, a subset of samples was\nsegmented by a specialist. A dermatologist performed an individual segmentation of each BCC pattern for each image.\nUnderstanding the decision-making process of convolutional neural networks (CNNs) is critical for clinical applications\nwhere interpretability is as important as performance metrics. The most common visualization techniques in explainable\nAI (XAI) are activation maps and gradient-weighted class activation mapping (Grad-CAM). Activation Maps, as\ndescribed by Zhou et al. [22], extract features from different network layers to show which patterns the model focuses\non, although they may not always directly correlate with specific outcomes. On the other hand, Grad-CAM, as described\nin detail by Selvaraju et al. [10], uses the gradients of the predicted class that flow into the final convolutional layer to\nproduce a localization map. The clinically-inspired explanation that we proposed in this paper is based on Grad-CAM.\nHowever, additional information is provided. For this study, the segmentations of individual BCC patterns (see 2.1)\nwere combined into a single segmented image, as shown in Fig. 3. And these manual segmentations were overlaid with\nactivation maps to validate the clinical information provided by Grad-CAM. In this way, the explanation is not only\nwhere the AI tool is paying attention, but also what the dermoscopic pattern of that region is."}, {"title": "3 Results", "content": "3.1 Implementation details\nThe chosen optimizer was the AdamW schedule-free optimizer [23], with a mini-batch size of 32, and dropout rate with\na rate of 0.3 to prevent overfitting. Focal loss [24] has been used to address class imbalance.\nData augmentation techniques [25, 26] applied included rotation, perspective transformation, and Gaussian blur.\nDue to the limited size of our database, a stratified k-fold cross-validation was implemented to ensure a comprehensive\nevaluation of the model's performance. This approach mitigates the risk of biased training and testing distributions,\nespecially crucial in datasets with imbalanced class distributions."}, {"title": "3.2 Clinical-inspired XAI: BCC diagnosis with additional label information", "content": "This section analyzes the performance of the AI tool for BCC detection in conjunction with the labels provided to\nexplain this classification. Table 3 presents metrics that summarize this performance. The metrics are averaged over\nall folds. This table has three parts. The first part shows the performance of the AI tool in the binary classification.\nThe second part shows its performance in detecting BCC dermoscopic patterns. Finally, the third part represents the\naccuracy of the labels that provide the clinical explanation.\nOverall, the BCC/non-BCC diagnostic performance is high, around 0.9 for all metrics. However, the BCC pattern\ndetection performance has to be analysed with a deeper insight. Minority classes tend to attain low recall because\nthe AI tool trained with unbalanced databases tends to favor majority classes. As shown in Sect. 2.1, SW, MG and\nML are underrepresented classes. Strategies such as data augmentation and advanced sampling, a one-vs-all strategy\ncombined with stratified k-fold cross-validation helped to achieve a more balanced classification across patterns, thereby\nimproving overall model performance. However, the metrics achieved should not be analyzed in the same way as\nBCC/non-BCC performance. They should only be evaluated to the extent that they provide a correct explanation for the\nbinary classification. It is not relevant if the AI tool misses a specific BCC pattern, but if it misses any BCC pattern, as\nclinicians diagnose skin lesions in the same way. This further evaluation is summarized in the third part of Table 3. As\nshown in this table, 73 percent of non-BCC lesions without any BCC pattern, 95 percent of non-BCC lesions with PN,\nand 99 percent of BCC lesions with some BCC pattern are correctly labeled as such."}, {"title": "3.3 Clinical-inspired Visual XAI", "content": "This section aims to quantify the accuracy of the AI tool in focusing on the correct part of the lesion, specifically the\nBCC dermoscopic patterns identified by clinicians. To this end, BCC pattern areas delineated by dermatologists will be\ncompared with model activated areas. This will provide a quantitative measure of the model's agreement with human\ndiagnostic criteria and demonstrate its ability to accurately identify critical features of BCC lesions.\nTo quantify the accuracy of the model activation areas with respect to the areas of clinical interest the conditional\nprobability density functions of the normalized GradCAM values within and outside the area segmented by derma-\ntologist were estimated. Let \\(z(x, y)\\) the GradCAM value at position (x, y). Let denote \\(F_g\\) the area segmented by the\ndermatologist and \\(B_g\\) the background. \\(P (z (x, y) | F_g)\\) is the probability density function of GradCAM values for\npixels \\((x, y) \\in F_g\\) and \\(wP (z (x, y) | B_g)\\) is the probability density function of GradCAM values for pixels \\((x, y) \\in B_g\\).\nFig. 4 illustrates this analysis. Fig. 4a shows the original BCC lesion. Fig. 4b shows the Grad-CAM map. Fig. 4c\nshows the dermatologist's segmentation overlaid on the Grad-CAM map. Fig. 4d shows an example of the two\nconditional probability density functions. The orange curve represents \\(P (z (x, y) | B_g)\\), and the blue curve represents\n\\(P (z (x, y) | F_g)\\). The orange curve is centered near 0, indicating low activation outside the mask, while the blue curve\nshows significant Grad-CAM information within the clinical segmentation, indicating that the model extracts features\nfrom the same region as the specialist.\nTable 4 summarizes the information extracted from these probability density function. Specifically, mean, standard\ndeviation of \\(z (x, y)\\) for \\((x, y) \\in F_g\\) and \\((x, y) \\in B_g\\) respectively, and the intersection area between \\(P (z (x, y) | F_g)\\)\nand \\(P (z (x, y) | B_g)\\) are shown. This table shows that correctly predicted samples have a larger mean standard deviation\nthan incorrectly predicted samples. In addition, the intersection area is larger in these cases. These facts prove that the\nmodel is not able to pay attention to the areas of clinical interest in the incorrect predictions."}, {"title": "4 Discussion and conclusion", "content": "In this paper, an AI tool for BCC diagnosis that provides a clinical explanation has been developed. It achieves two\nmain achievements that make it very clinically significant. First, this tool will contribute to changing the protocol of\nteledermatology, reducing the waiting time for diagnosis and intervention in an area of 60 geographically dispersed\nprimary health centers. Second, its clinically inspired double explanation increases its usefulness."}]}