{"title": "AI-DRIVEN SKIN CANCER DIAGNOSIS: GRAD-CAM AND EXPERT ANNOTATIONS FOR ENHANCED INTERPRETABILITY", "authors": ["Iv\u00e1n Matas", "Carmen Serrano", "Francisca Silva-Claver\u00eda", "Amalia Serrano", "Tom\u00e1s Toledo-Pastrana", "Bego\u00f1a Acha"], "abstract": "An AI tool has been developed to provide interpretable support for the diagnosis of BCC via teledermatology, thus speeding up referrals and optimizing resource utilization. The interpretability is provided in two ways: on the one hand, the main BCC dermoscopic patterns are found in the image to justify the BCC/Non BCC classification. Secondly, based on the common visual XAI Grad-CAM, a clinically inspired visual explanation is developed where the relevant features for diagnosis are located. Since there is no established ground truth for BCC dermoscopic features, a standard reference is inferred from the diagnosis of four dermatologists using an Expectation Maximization (EM) based algorithm. The results demonstrate significant improvements in classification accuracy and interpretability, positioning this approach as a valuable tool for early BCC detection and referral to dermatologists. The BCC/non-BCC classification achieved an accuracy rate of 90%. For clinically-inspired XAI results, the detection of BCC patterns useful to clinicians reaches 99% accuracy. As for the Clinically-inspired Visual XAI results, the mean of the Grad-CAM normalized value within the manually segmented clinical features is 0.57, while outside this region it is 0.16. This indicates that the model struggles to accurately identify the regions of the BCC patterns. These results prove the ability of the AI tool to provide a useful explanation.", "sections": [{"title": "1 Introduction", "content": "Skin cancer is the most commonly diagnosed cancer worldwide, with Melanoma, Basal Cell Carcinoma (BCC), and Squamous Cell Carcinoma (SCC) being the most prevalent types. BCC accounts for approximately 75% of all skin cancers, making it the most frequent form. It has well-established clinical criteria for diagnosis, yet there is significant variability in the presence of these clinical criteria between cases [1, 2, 3, 4].\nMany research efforts seek to diagnose various skin diseases. Additionally, the number of published papers has increased significantly in recent years, driven by the development of public databases [5, 6, 7, 8]. Although these databases are accessible and comprehensive for everyone, the clinical criteria used for diagnosis are not readily available. To develop a tool that is useful from a medical perspective, it is crucial to provide not only classification metrics, but also a detailed diagnosis explaining the detected clinical features, thereby offering a more comprehensive result. In this context, Serrano at al. [9] developed a clinically inspired skin lesion classification tool through the detection of dermoscopic criteria for BCC."}, {"title": "2 Methodology", "content": "In modern healthcare, primary care physicians use teledermatology systems to receive high-quality diagnostic images remotely, allowing preliminary diagnoses of Basal Cell Carcinoma (BCC) using established patterns [4, 17]. Suspected BCC cases are promptly referred to dermatology specialists, improving healthcare efficiency, reducing waiting times, and facilitating early intervention.\nTeledermatology is crucial in areas with limited specialist access and its integration with AI tools promises to enhance diagnostic accuracy and efficiency. This work aims to develop an AI tool to assist in this process by providing a binary classification of BCC/non-BCC with interpretable results Fig. 1 illustrates the current and proposed diagnostic workflows."}, {"title": "2.1 Database", "content": "The entire database was provided by the Dermatology Unit of the \"Hospital Universitario Virgen Macarena\" and were sent over 2 years from 60 primary care centers. The dataset comprises 1559 dermoscopic images divided into 3 subsets. Four dermatologists provided different types of annotation according to the subsets. Specifically:\n\u2022 The first subset consisted of 1089 dermoscopic images. Initially, the labeling annotations for these images were the presence or absence of each of the dermoscopic features involved in the diagnosis of BCC.\n\u2022 A second subset of 334 images is additionally enriched with dermatologist delineations of BCC dermoscopic patterns within each image. More than one segmented area may appear on an image if there are multiple patterns in the BCC lesion. In the Fig. 3 an example is shown.\n\u2022 The third subset is made up of 136 non-BCC images, mostly consisting of nevus lesions, from the ISIC archive [8]."}, {"title": "2.1.1 Label codification", "content": "Each image may contain multiple dermoscopic patterns. Therefore, a one-hot coding scheme was used to encode the labels during image annotation and subsequently to process the dermatologists' annotations. Each image label is a binary word and each BCC dermoscopic pattern is a digit, where 1 means presence and 0 means absence. The seven patterns that can appear in a BCC lesion are[4, 18, 17]: Pigment Network (PN) (negative criterion), Ulceration (U), Ovoid Nests (ON), Multiglobules (MG), Maple Leaf-like (ML), Spoke Wheel (SW), Arborizing Telangiectasia (AT) (Fig. 2). Thus, each label is a vector of dimensions [1x7]. In Table 2 there are some examples of this process."}, {"title": "2.1.2 Standard Reference Inferring", "content": "The accepted ground truth (GT) for BCC diagnosis is biopsy. However, there is no established GT for BCC dermoscopic patterns, which are subjectively assessed by dermatologists. Several studies have reported a low kappa coefficient when measuring inter-dermatologist agreement in determining the different dermoscopic patterns present in a lesion [19, 17]. Therefore, an adequate SR inferred from the consensus of several dermatologists is required. An Expectation-Maximization (EM) based algorithm [20] was implemented to derive a single SR for model training from multiple specialist labels. This algorithm consolidates multilabel annotations from different dermatologists and generates a single inferred SR that encapsulates the collective expertise of the raters. Silva et al. [21] used this algorithm to infer and SR from BCC pattern annotations and demonstrated that integrating this diverse expertise mitigates the subjectivity inherent in diagnosing the BCC pattern and improves the reliability and robustness of the classification model."}, {"title": "2.2 Clinical inspired XAI", "content": "From a clinical point of view, achieving 100% accuracy in detecting BCC dermoscopic patterns is not crucial for a correct diagnosis of BCC. A dermatologist requires detecting just one correct BCC dermoscopic pattern to make an accurate BCC diagnosis. Therefore, a useful clinically-inspired XAI should provide any of the following outcomes: if no patterns are detected, it predicts non-BCC; if the PN pattern is detected, it serves as a negative criterion, explaining a non-BCC prediction; and if any other BCC pattern is detected, the prediction is positive for BCC."}, {"title": "2.3 Clinical visual X\u0391\u0399", "content": "To develop this concept, expert-generated segmentations are used. As detailed in Sect. 2.1, a subset of samples was segmented by a specialist. A dermatologist performed an individual segmentation of each BCC pattern for each image.\nUnderstanding the decision-making process of convolutional neural networks (CNNs) is critical for clinical applications where interpretability is as important as performance metrics. The most common visualization techniques in explainable AI (XAI) are activation maps and gradient-weighted class activation mapping (Grad-CAM). Activation Maps, as described by Zhou et al. [22], extract features from different network layers to show which patterns the model focuses on, although they may not always directly correlate with specific outcomes. On the other hand, Grad-CAM, as described in detail by Selvaraju et al. [10], uses the gradients of the predicted class that flow into the final convolutional layer to produce a localization map. The clinically-inspired explanation that we proposed in this paper is based on Grad-CAM.\nHowever, additional information is provided. For this study, the segmentations of individual BCC patterns (see 2.1) were combined into a single segmented image, as shown in Fig. 3. And these manual segmentations were overlaid with activation maps to validate the clinical information provided by Grad-CAM. In this way, the explanation is not only where the AI tool is paying attention, but also what the dermoscopic pattern of that region is."}, {"title": "3 Results", "content": "The chosen optimizer was the AdamW schedule-free optimizer [23], with a mini-batch size of 32, and dropout rate with a rate of 0.3 to prevent overfitting. Focal loss [24] has been used to address class imbalance.\nData augmentation techniques [25, 26] applied included rotation, perspective transformation, and Gaussian blur.\nDue to the limited size of our database, a stratified k-fold cross-validation was implemented to ensure a comprehensive evaluation of the model's performance. This approach mitigates the risk of biased training and testing distributions, especially crucial in datasets with imbalanced class distributions."}, {"title": "3.2 Clinical-inspired XAI: BCC diagnosis with additional label information", "content": "This section analyzes the performance of the AI tool for BCC detection in conjunction with the labels provided to explain this classification. Table 3 presents metrics that summarize this performance. The metrics are averaged over"}, {"title": "3.3 Clinical-inspired Visual XAI", "content": "This section aims to quantify the accuracy of the AI tool in focusing on the correct part of the lesion, specifically the BCC dermoscopic patterns identified by clinicians. To this end, BCC pattern areas delineated by dermatologists will be compared with model activated areas. This will provide a quantitative measure of the model's agreement with human diagnostic criteria and demonstrate its ability to accurately identify critical features of BCC lesions.\nTo quantify the accuracy of the model activation areas with respect to the areas of clinical interest the conditional probability density functions of the normalized GradCAM values within and outside the area segmented by derma-tologist were estimated. Let $z(x, y)$ the GradCAM value at position (x, y). Let denote $F_g$ the area segmented by the dermatologist and $B_g$ the background. $P(z(x, y) | F_g)$ is the probability density function of GradCAM values for pixels $(x, y) \\in F_g$ and $wP(z(x, y) | B_g)$ is the probability density function of GradCAM values for pixels $(x, y) \\in B_g$.\nFig. 4 illustrates this analysis. Fig. 4a shows the original BCC lesion. Fig. 4b shows the Grad-CAM map. Fig. 4c shows the dermatologist's segmentation overlaid on the Grad-CAM map. Fig. 4d shows an example of the two conditional probability density functions. The orange curve represents $P(z(x, y) | B_g)$, and the blue curve represents $P(z(x, y) | F_g)$. The orange curve is centered near 0, indicating low activation outside the mask, while the blue curve shows significant Grad-CAM information within the clinical segmentation, indicating that the model extracts features from the same region as the specialist."}, {"title": "4 Discussion and conclusion", "content": "In this paper, an AI tool for BCC diagnosis that provides a clinical explanation has been developed. It achieves two main achievements that make it very clinically significant. First, this tool will contribute to changing the protocol of teledermatology, reducing the waiting time for diagnosis and intervention in an area of 60 geographically dispersed primary health centers. Second, its clinically inspired double explanation increases its usefulness."}]}