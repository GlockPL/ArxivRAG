{"title": "Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging", "authors": ["Yang Qi", "Jiaxin Cai", "Jing Lu", "Runqing Xiong", "Rongshang Chen", "Liping Zheng", "Duo Ma"], "abstract": "Prenatal ultrasound evaluates fetal growth and detects congenital abnormalities during pregnancy, but the examination of ultrasound images by radiologists requires expertise and sophisticated equipment, which would otherwise fail to improve the rate of identifying specific types of fetal central nervous system (CNS) abnormalities and result in unnecessary patient examinations. We construct a deep learning model to improve the overall accuracy of the diagnosis of fetal cranial anomalies to aid prenatal diagnosis. In our collected multi-center dataset of fetal craniocerebral anomalies covering four typical anomalies of the fetal central nervous system (CNS): anencephaly, encephalocele (including meningocele), holoprosencephaly, and rachischisis, patient-level prediction accuracy reaches 94.5%, with an AUROC value of 99.3%. In the subgroup analyzes, our model is applicable to the entire gestational period, with good identification of fetal anomaly types for any gestational period. Heatmaps superimposed on the ultrasound images not only provide a visual interpretation for the algorithm but also provide an intuitive visual aid to the physician by highlighting key areas that need to be reviewed, helping the physician to quickly identify and validate key areas. Finally, the retrospective reader study demonstrates that by combining the automatic prediction of the DL system with the professional judgment of the radiologist, the diagnostic accuracy and efficiency can be effectively improved and the misdiagnosis rate can be reduced, which has an important clinical application prospect. All code is available at https://github.com/xiaqi7/Fetal-ultrasound.", "sections": [{"title": "I. INTRODUCTION", "content": "Ultrasonography is popular as a non-invasive and radiation-free prenatal diagnostic method for its convenience and low cost [1]. Antenatal ultrasound is a crucial imaging tool during pregnancy. It not only assesses fetal growth and development and detects congenital anomalies, but also provides important diagnostic information and support to clinicians through de-tailed imaging of the fetus and its associated structures [2]. In ultrasound, physicians can assess the presence of congenital anomalies in the fetus with the help of two-dimensional (2D) and three-dimensional (3D) imaging, thus helping to signifi-cantly reduce the incidence of congenital disabilities. However, fetal ultrasound still faces some challenges in clinical practice, such as high fetal mobility, excessive abdominal wall thickness in pregnant women, and differences in interpretation between different observers [3]. In fetal ultrasound, the acquisition of correct fetal position and standard planes relies on the expertise of the technician, and even experienced technicians find it time-consuming and laborious to take manual measure-ments such as head circumference (HC), biparietal diameter (BPD), and occipitofrontal diameter (OFD). Optimizing the prenatal ultrasound diagnosis process can significantly reduce the workload of the sonographer; therefore, the application of artificial intelligence (AI) and deep learning (DL) techniques in ultrasound imaging can significantly speed up the prenatal examination process while improving the accuracy and con-sistency of the diagnosis.\nArtificial Intelligence is widely used in medicine today [4]. Deep learning, a subset of AI, automatically extracts features from large amounts of data and performs efficient pattern recognition and prediction using deep neural network models [5]. Deep learning has been widely applied in medical image processing, including the analysis of ultrasound images [6]. Convolutional neural networks (CNN) are widely used as one of the most powerful methods in deep learning [7]. CNN is capable of extracting complex features from medi-cal images for disease detection, diagnosis, and monitoring, greatly improving the accuracy and efficiency of medical image analysis [8]. CNN is very promising in the detection of standard fetal ultrasound plane. Yu et al. [9] proposed a deep convolutional neural network (DCNN)-based method for automatic identification of fetal facial standard planes (FFSPs), which solves the problem of lack of performance of the traditional handcrafted feature methods in the identification of FFSP. Chen et al. [10] used a composite architecture of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) [11] for in-plane and cross-plane feature learning. However, most studies using Al for fetal imaging have focused on the identification of normal fetal structures, and few have used AI to classify and diagnose images of fetal congenital malformations [12, 13]."}, {"title": "II. RESULTS", "content": "Patient data\nWe collected a dataset of abnormal pregnant women with fetal central nervous system anomalies from Xiamen Univer-sity Affiliated First Hospital. Our dataset for model training and evaluation consisted of 1,662 fetal ultrasound images and 699 ultrasound videos. To make full use of the information in the videos, we use a computer script to convert these videos to still images frame by frame. To ensure that each frame clearly shows the abnormal state of the fetus and is distinct from the previous frame, we extracted one image every 80 frames from the start frame to the end frame. By this method, we extracted 5038 still images from the video. Eventually, as shown in Table I, we obtained a dataset containing 6700 anomaly images (1662 original images plus 5038 images extracted from the video). These fetal images were derived from the ultrasound findings of 37 pregnant women. The types of anomalies diagnosed in the fetus of each pregnant woman's womb included four categories: rachischisis, encephalocele (including meningocele), holoprosencephaly, and anencephaly. These four types of anomalies are representative of several types of fetal craniocerebral anomalies, all of which are neural tube defects or developmental anomalies with varying characteristics and degrees of severity. These pregnant women underwent ultrasound examinations at Xiamen University First Affiliated Hospital between 2019 and 2023. As shown in Table II, in addition to ultrasound images, we collected data from 19 different pregnant women, as well as radiological and pathological reports related to the fetuses. For example, in a report for gestational age of 29 weeks and 2 days shown in Fig. 1, the ultrasound report provides a comprehensive set of fetal measurements, including the estimated fetal weight (EFW), biparietal diameter (BPD), head circumference (HC), amniotic fluid index (AFI), and Doppler measurement data, among other indicators. To validate the classification performance of the model, we also collected prenatal ultrasound images of normal pregnant women from Xiamen Medical College Affiliated Second Hospital. This additional dataset contains four basic standard section images of mid-trimester fetuses, namely, thalamic transverse section, lateral ventricle transverse section, cerebellar transverse section, and spinal longitudinal section, with a specific number of 3207 images. We mixed the normal fetal dataset of Xiamen Medical College Affili-ated Second Hospital with the abnormal dataset of Xiamen University Affiliated First Hospital for more comprehensive model validation. The reference number of ethical approval is 2021052, adhering to the principles of the Declaration of Helsinki. The feature extraction and pre-processing methods for all datasets are described in detail in the Materials and Methods section.\nModel Performance\nUsing a deep learning (DL) system to predict the fetal cerebral-cranial anomaly dataset, we first performed image-level testing. Specifically, we predicted the category of ab-normality for each ultrasound image of the test pregnant women in each fold in the leave-one-out method of cross-validation. Eventually, we aggregated the prediction results for each image in all folds and obtained various performance metrics at the image level: accuracy of 73%, precision of 60.43%, recall of 65.7%, F1 value of 61.8%, and AUROC of 87.41%. In our experiments, we utilized subject operating characteristic (ROC) curves to assess the ability of the model to distinguish between anomalous cases. The ROC curves for four fetal anomaly categories, anencephaly, encephalocele (including meningocele), holoprosencephaly, and rachischisis, are presented in Fig. 2. The AUC values for each anomaly category were 0.85, 0.89, 0.88, and 0.87, respectively, indi-cating that the model has a high true-positive rate and low false-positive rate in detecting these anomalies. The use of AUC (area under the curve) as an assessment metric in the examination of central nervous system (CNS) abnormalities is due to its ability to comprehensively assess the overall perfor-mance of the model in distinguishing between abnormality-type scenarios at different thresholds, providing probabilistic predictions to support clinical decision-making.\nWe also demonstrated the performance of the model in terms of CNS aberration checking using Micro-average ROC"}, {"title": "III. DISCUSSION", "content": "In this study, we constructed and validated a deep learning (DL) model-based prediction system for fetal cerebral-cranial anomalies, focusing on the automatic detection of central nervous system (CNS) abnormalities in ultrasound images. By training a dataset covering four typical fetal cerebral-cranial anomalies, including anencephaly, encephalocele (including meningocele), holoprosencephaly, and rachischisis, we con-structed an efficient and accurate diagnostic model.\nCurrently, there are relatively few studies using artificial in-telligence (AI) to predict fetal cerebral-cranial anomalies, and most of the existing models are limited to binary classification (normal vs. abnormal) or identifying general intracranial image patterns [15, 16, 17]. In contrast, our approach not only dis-tinguishes between normal and abnormal fetal cranial images but also accurately predicts specific types of abnormalities. It provides detailed and specific diagnosis for physicians, reduces their workload, especially in resource-constrained areas for prenatal screening, and has very high prediction accuracy. The results of the study showed that the model performed in terms of classification accuracy (94.5%) and AUROC value (99.3%), implying that the model is able to efficiently differentiate between normal and abnormal cases and has a well-balanced predictive ability for each type of abnormality, which provides more reliable decision support for the clinic.\nSpecific predictive outcomes enable families to receive targeted counselling to help them better understand potential outcomes and prepare for necessary postnatal treatment or in-terventions. It also facilitates early detection of abnormalities, which is critical for timely surgery or other treatment and may significantly improve the long-term prognosis of affected infants. The high precision and recall of our model minimizes unnecessary follow-up tests, reduces patient anxiety, and en-sures that only truly abnormal cases receive further attention. Our DL system outperforms humans in the prediction of fetal cerebral-cranial anomalies, especially in the prediction of cerebral-cranial anomalies with accuracy and speed far exceeding that of physicians.\nThrough subgroup analyzes, we found that the predictive ability of the DL system varied at different gestational stages. Especially in the middle gestation stage (13-28 weeks), the predictive performance of the model was significantly im-proved and the accuracy was significantly better than that in the early gestation stage (<12 weeks). In the early stage, the identification accuracy of the model is limited by the poor clarity of the ultrasound images because the fetal organs and structures are not yet fully developed. However, as the pregnancy progresses and the fetal structure becomes clearer, the model is able to extract key features and classify them more accurately. Because of this, deep learning models still suffer from the \u2018black box' problem, i.e., their decision-making process lacks interpretability, which limits their clinical appli-cations. To improve the transparency of the model, we use heatmaps to overlay the original ultrasound images to help clinicians visualize the basis of the model decisions. Heatmaps not only enhance the interpretability of the model but also improve the accuracy of lesion detection, which plays a key role, especially in complex cases and images with blurred edges. In addition, to address the problem of category imbal-ance (e.g., fewer samples of anencephalic children), we used a weighted cross-entropy loss function to improve the model's performance on a few categories. Although the DL system in this study achieved significant results on several metrics, the model still needs to be combined with the judgment of experienced radiologists in practical applications. The study demonstrated that a DL system combined with physician judgment can significantly improve diagnostic accuracy by using the DL system as an auxiliary tool to help quickly locate and screen for abnormalities, thereby improving diagnostic efficiency and reducing misdiagnosis and underdiagnosis.\nFalse positives were also observed in this study, where nor-mal fetuses were misdiagnosed with cerebral-cranial anoma-lies. False-positive results lead to a detailed review by the sonographer, and if a definitive diagnosis cannot be made, referral to a specialist may be necessary. Although this process helps to improve diagnostic accuracy, frequent referrals may increase the workload of specialists, especially in resource-constrained areas, and may prolong the waiting time of patients and affect the efficiency of healthcare services. Referral cen-ters have demonstrated high specificity and sensitivity in the detection of CNS abnormalities, and these centers are able to"}, {"title": "IV. MATERIALS AND METHODS", "content": "Filtering datasets\nIn order to maximize the accuracy of predicting fetal cerebral-cranial anomalies and to remove non-essential content that potentially affects the prediction, additional filtering was applied to the dataset. In the complete fetal ultrasound dataset, each ultrasound image includes information about each fetal mother and the source of the image in addition to the fetal ontology part, which would lead to data leakage during model training and not getting a good training model. At the same time, some of the images also include all kinds of textual data measured on fetal cerebral-cranial anomalies and other non-fetal body images, such as DV-S, DV-D, blood flow velocity waveform maps, and other color Doppler technology measured data, which will have a positive effect on the doctor's judgment of fetal anomalies, but to get these data need additional instruments to measure, which undoubtedly increase the cost of ultrasound examination. Our model focuses on fetal images and achieves excellent performance without these additional data, which definitely reduces the cost of ultrasound examination significantly. We have cropped the non-fetal body parts of these ultrasound images.\nBaseline model\nWe adopt the ResNet34 model from Deep Learning Systems as the main architecture. ResNet34 is a convolutional neural network based on Residual Network (ResNet), which solves the problem of gradient vanishing in deep network training by introducing residual blocks. The model contains multiple residual blocks, each consisting of two convolutional layers with inputs added directly to the outputs via jump connections. The specific structure of ResNet34 consists of an initial 7x7 convolutional layer, four stages of residual blocks (with feature maps numbering 64, 128, 256, and 512 respectively), as well as a globally averaged pooling layer and a fully connected layer. By using the ResNet34 model, we were able to efficiently extract complex features from fetal brain cranial anomaly images and achieve high accuracy in different types of anomaly classification tasks.\nConstruction of the DL system\nIn this study, we used Leave-One-Out Cross-Validation (LOOCV) to evaluate the performance of the models and select the optimal model for each fold. Leave-One-Out Cross-Validation is a special cross-validation method in which only one sample at a time is set aside as the validation set and all the remaining samples are used as the training set. This method is particularly effective when the dataset is small, as it maximizes the use of available data and reduces the variance of the model. In each leave-one-out cross-validation, we trained a model and evaluated its performance on the set-aside validation set. We chose the model that performed best on the validation set as the optimal model for that fold. Eventually, we saved all these optimal models and combined them into an integrated model. We use Averaging in the integrated learning approach to derive the prediction results. Through this integrated approach, we not only take advantage of the diversity of multiple models, but also improve the stability and generalization of the models. Averaging reduces the variance of individual models, making the final prediction results more reliable. In addition, this method is highly tractable and computationally efficient in practical applications for many types of machine learning.\nDividing dataset\nTo ensure the accuracy and rigor of the prediction, we adopted a strict data partitioning strategy in leave-one-out cross-validation. Specifically, in the fetal cerebral-cranial anomalies dataset, the entire ultrasound image data of each pregnant woman is only used as a test set in any cross-validation and does not appear in the training set. This means"}, {"title": "Training details", "content": "In our study, the 'best model' performance is the set of optimal models for each fold based on the leave-one-out cross-validation. All models were trained using the AdamW optimizer with an initial learning rate of 0.0005 and a weight decay of 0.05. In order to improve the training stability and convergence speed of the models, we adopted a learning rate scheduling strategy and used a Warmup strategy in the early stages of training. We used a linear Warmup strategy within the first epoch to gradually increase the learning rate from 0 to a preset initial learning rate of 0.0005. After the Warmup phase, the learning rate continued to be adjusted according to the cosine annealing strategy. This strategy helps the model to find a suitable optimization direction in the early stage of training, reduces the risk of gradient explosion, and accelerates convergence. Our experimental environment is configured as follows: Intel Xeon Gold 6138 CPU @ 2.00GHz, 96GB of RAM, and an NVIDIA RTX 2080 Ti GPU with 11GB of video memory. The system runs the Windows operating system and utilizes the PyTorch framework for development. To ensure that the model achieves optimal performance on the validation set, we evaluate the validation accuracy of the model at the end of each epoch. If the validation accuracy of the current epoch is higher than the previously recorded optimal validation accuracy, the optimal validation accuracy is updated. If the validation accuracy does not improve for consecutive epochs, we trigger the early stop mechanism to stop the training process. This early stop mechanism helps prevent overfitting and saves computational resources."}]}