{"title": "Towards Explaining Uncertainty Estimates in Point Cloud Registration", "authors": ["Ziyuan Qin", "Jongseok Lee", "Rudolph Triebel"], "abstract": "Iterative Closest Point (ICP) is a commonly used algorithm to estimate transformation between two point clouds. The key idea of this work is to leverage recent advances in explainable AI for probabilistic ICP methods that provide uncertainty estimates. Concretely, we propose a method that can explain why a probabilistic ICP method produced a particular output. Our method is based on kernel SHAP (SHapley Additive exPlanations). With this, we assign an importance value to common sources of uncertainty in ICP such as sensor noise, occlusion, and ambiguous environment. The results of the experiment show that this explanation method can reasonably explain the uncertainty sources, providing a step towards robots that know when and why they failed in a human interpretable manner.", "sections": [{"title": "1 Introduction", "content": "Point cloud registration plays an essential role in many tasks in robotics and computer vision, such as simultaneous localization and mapping [1], grasping [2], and augmented reality [3]. Iterative Closest Point (ICP) is a widely used algorithm to register two point clouds [4]. Given the source and reference point clouds and an initial transformation estimate, the ICP iteratively minimizes the Euclidean distance between pairs of matching points from both point clouds.\nIn practice, the ICP pose estimation process is usually affected by several sources of uncertainty. These include sensor noise, initial pose uncertainty, partial overlap, under-constrained situations, and intrinsic ICP randomness [5, 6, 7]. Due to the error incurred by these error sources, a single pose estimate is often insufficient to obtain a robust transformation and accurately localize a moving object. Thus, many ICP algorithms provide not only the point estimate of transformation but also the uncertainty estimate for the transformation parameters [5, 7, 6, 8, 9]. Depending on how these sources of uncertainty vary, the uncertainty also varies.\nGiven the uncertainty of the pose estimate produced by any uncertainty-aware point cloud registration algorithm, this work uses the SHAP kernel to build a model-agnostic explanation module and identify the association between uncertainty sources and estimated uncertainty in point cloud registration [10], so that after removing or mitigating the sources, the pose estimates achieve a lower uncertainty and arrive at a better localization. To the best of our knowledge, this work is the first attempt to show that uncertainty estimates in point cloud registration can be explained in a human interpretable manner."}, {"title": "2 Background on Explanation Methods", "content": "To attribute uncertainty to various sources, we rely on the existing explanation method. In this section, we provide background on the additive feature attribution method, LIME, Shapley values, and eventually how the kernel SHAP combines these ideas into a linear model with desirable properties."}, {"title": "Additive Feature Attribution Method", "content": "Let f be the initial model to be explained and g the explanation model. Local methods explain a prediction f(x) using a single input x. These methods use simplified inputs x', which are mapped to the original inputs x by a function x = hx(x'). The goal is to ensure g(z') \u2248 f(hx(z')) whenever z' \u2248 x' [10]. Methods like LIME [11] and SHAP [10] follow the additive feature attribution framework, represented by a linear function of binary variables:\n$$g(z') = \\phi_0 + \\sum_{i=1}^{M} \\phi_i z_i,$$\nwhere z' \u2208 {0,1}M, M is the number of simplified features, and \u00f3i \u2208 R. According to Equation (1), explanation models assign an effect i to each feature. Summing the feature attributions i and the bias 40 approximates the output f (x) of the original model."}, {"title": "LIME (Local Interpretable Model-agnostic Explanations)", "content": "LIME [11] is proposed to satisfy three criteria: interpretable (qualitative understanding between input and response), local fidelity (explanation locally approximates model near prediction) and model-agnostic (explanation method applicable to any model). When using a local linear explanation model, LIME follows Equation (1), and is therefore an additive feature attribution method. To find 6, LIME minimizes the following objective function with respect to x:\n$$arg \\min_{g \\in G} L(f, g, \\pi_{x'}) + \\Omega(g),$$\nwhere G is a set of interpretable models, L(f, g, \u03c0\u03b1') measures the unfaithfulness of g in approxi- mating f locally, and \u03a9(g) captures the complexity of the explanation. By minimizing L weighted by the local kernel \u03c0\u03b1' and controlling the complexity with \u03a9, LIME ensures both local fidelity and interpretability."}, {"title": "Kernel SHAP", "content": "In cooperative game theory, players cooperate in a coalition and receive a certain payoff. Depending on their individual contribution to the total payoff, Shapley value assigns a contribution to each player. This idea in game theory can easily be extended to model explanations, where each player represents a feature, and the coalition value signifies model prediction [12, 13, 14].\nThere are three desirable properties with additive feature attribution methods: 1) local accuracy, 2) missingness, and 3) consistency. Surprisingly, SHAP (SHapley Additive exPlanation) values, proposed by [10], provide the unique additive feature importance measure that adheres to the three properties. While precise calculation of SHAP values can be computationally expensive, the subsequent Kernel SHAP method achieves similar approximation accuracy with fewer evaluations of the original model.\nProposed and proved in [10], Shapley kernel can induce Shapley values consistent with Equation (1) and the three properties to solve Equation (2):\n$$\\Omega(g) = 0$$\n$$\\pi_{x'}(z') = \\frac{(M-1)}{(M){|z'|}(M - |z'|)}$$\n$$L(f,g, \\pi_{x'}) = \\sum_{z' \\in Z}(f(h_x(z')) \u2013 g(z'))^2 \\pi_{x'}(z')$$\nGiven that g(z') is assumed to follow a linear form in Equation (1) and L represents a quadratic loss, Equation (2) can be solved via weighted linear regression. The weighting function \u03c0\u03b1' forms the basis of the Shapley kernel, and the entire process of weighted linear regression is termed the kernel SHAP."}, {"title": "3 On the Problem of Explainable ICP", "content": "In this section, we first present the background on ICP, the sources of uncertainty in ICP, and existing uncertainty techniques. Then, we present our main goal and motivate why we should explain uncertainty in ICP."}, {"title": "3.1 Iterative Closest Point", "content": "ICP aligns a source point cloud with a target point cloud by estimating the rigid transformation (rotation and translation) between them [15]. Since the correct point correspondences are unknown and the searching process is not differentiable, it is generally impossible to determine the optimal rotation and translation in one step. Thus, iterations are performed, each consisting of two steps:\nFirst step: Using an initial pose = {x, y, z, roll, pitch, yaw}, the point correspondences are established by minimizing the distance function. There are two variants of the distance function: point-to-point [4] and point-to-plane [16]. The commonly used point-to-point distance metric is:\n$$point-to-point(s', R) = \\min_{r_j \\in R}||r_i - s_i||,$$\nwhere si, rj \u2208 R\u00b3 are the corresponding pair of points in 3D space belonging to source cloud S = {si}N=1 and reference cloud R = {r;}M=1 respectively. s' = (Rsi + t) is a transformed point in the source cloud, t \u2208 R\u00b3 is a translation vector consisting of 01:3 and R \u2208 R3\u00d73, parametrized by 04:6, represents a rotation matrix. Second step: Estimate the relative rigid transformation R and t by minimizing the distance between each pair of corresponding points. The point-to-point cost function has the following form:\n$$argmin L(\\theta) = \\frac{1}{N}\\sum_i ||(R s_i + t) - r_i||^2.$$\nThe estimated rigid transformation consists of rotation R and translation t. R is in the special orthogonal group SO(3) := {R \u2208 R3\u00d73 | RTR = I, det(R) = 1} and t \u2208 R\u00b3. Combining both rotation and translation, in homogeneous coordinate, the rigid transformation lives in the group of special Euclidean transformations: SE(3) := {$g = \\begin{bmatrix} R & t\\\\ 0 & 1 \\end{bmatrix}$ | R\u2208 SO(3), t \u2208 R3}\u2282 R4\u00d74."}, {"title": "3.2 Sources of ICP Uncertainty", "content": "According to the literature [5, 6, 7], the uncertainty of ICP uncertainty comes mainly from five possible sources: sensor noise, initial pose uncertainty, partial overlap, under-constrained situations, intrinsic ICP randomness.\nSensor noise: the sensor noise consists of both sensor white noise and sensor bias noise. Sensor white noise is caused when each point measured in a point cloud is influenced by an independent random sensor noise, a function of the point depth and beam angle [17]. Sensor bias noise is induced when the observed points share common errors caused by environmental conditions such as the temperature drift effect, distortion due to sensor calibration, and the physical nature or texture of the perceived material [18].\nInitial pose uncertainty: If the initialization of the pose has a large uncertainty, the solution would converge to a local minimum rather than the attraction area of the true solution [9, 7].\nPartial overlap: partial overlap refers to a situation where there is a limited amount of overlap between the points in the cloud of sources and target points. This limitation may arise from the viewpoint of the sensor, occlusions, or the relative motion between the sensor and the scene. It can be challenging to establish reliable correspondences between the two point clouds, leading to alignment uncertainty [6, 19]."}, {"title": "3.3 Uncertainty Estimation in ICP", "content": "There exist many ICP algorithms that either produce a single transformation estimate like the original ICP [4] or are uncertainty-based, which provide a distribution of possible poses and estimate the pose uncertainty [20, 6]. In this work, we utilize ICP to demonstrate that the explanation method can indeed produce reasonable estimates. That is, if our explanation works for the original ICP producing a single pose estimate, it could easily adapt to any other ICP algorithm, single estimate or not. Multiple pose estimates are sampled to compute the uncertainty estimate using the Kullback-Leibler (KL) divergence. More details are discuss in our experiments later."}, {"title": "3.4 Problem Statement", "content": "We have looked into how ICP functions, what may cause them to fail, and uncertainty quantification techniques. Our goal is to not only estimate the uncertainty but also explain the uncertainty. We argue that in ICP, the explanations should be in human interpretable concepts, which are the sources of ICP uncertainty in our scenario. Several advantages can exist. First, knowing the causes of uncertainty, we can perform active perception at a symbolic level, e.g., at a robotic task level, we might be able to use robot controls to eliminate ICP failures. Furthermore, such information can be used in a teleoperation setup. A human operator might be able to react to perception failures better if the operator is informed about what is causing the failures."}, {"title": "4 On How to Perturb the Three Uncertainty Sources", "content": "Sensor noise and partial overlap are perturbed by altering the input point clouds, whereas initial pose uncertainty is perturbed by transforming the initial poses."}, {"title": "4.0.1 Sensor Noise", "content": "As described in Section 3.2, sensor noise is comprised of sensor white noise and sensor bias noise. Since the sensor white noise is more straightforward to model, it is represented as a zero-mean Gaussian noise without loss of generality. The noise is then added to each point in the two input point clouds."}, {"title": "4.0.2 Initial Pose Uncertainty", "content": "As derived in [7], given a small rotation \u03b1, \u03b2, \u03b3 around the x, y, z axes respectively, the full rotation R can be linearly approximated as:\n$$R=\\begin{bmatrix}1 & -\\gamma & \\beta\\\\ \\gamma & 1 & -\\alpha\\\\ -\\beta & \\alpha & 1\\end{bmatrix} = I_3 + \\begin{bmatrix}0 & -\\gamma & \\beta\\\\ \\gamma & 0 & -\\alpha\\\\ -\\beta & \\alpha & 0\\end{bmatrix} = I_3 + \\delta^\\wedge,$$"}, {"title": "4.0.3 Partial Overlap", "content": "For a pair of input point clouds P\u2081 and P\u2082, an overlapping ratio can be computed similar to that in [19]. Given ground truth absolute pose T\u2081 and T\u2082, the point clouds are transformed from local camera frame to world frame: P\u2081 and P\u2082. For each point p in P\u2082, the nearest neighbor NN(p) in P\u2081 is found using kNN with k = 1. The neighbor is valid only if the Euclidean distance between p and NN(p) is no larger than d = 0.2 m. Calculating the ratio between the number of valid neighbors and number of points in P\u2081 yields the overlap ratio:\n$$O_{1,2} = \\frac{N}{|P_1|},\\quad where N = \\sum_{p \\in P_2} 1(||NN(p) \u2013 p|| \u2264 d).$$\nIn reality, the means to perturb input point clouds P\u2081 and P\u2082 with partial overlap are various and depend on the specific scenario, a simple but effective way to reduce overlapping region is as follows. Given the current overlap ratio O1,2, P\u2082 is perturbed to reach target overlap ratio O1,2 = O1,2 \u2212 \u03bb, with \u03bb > 0. By simple calculation, N \u2013 |P1|\u00b7 O1,2 points need to be removed from the overlapping region in P2 to reduce current overlap ratio by \u03bb."}, {"title": "5 The Proposed Method", "content": "We note that sensor noise and partial overlap affect the source and reference point clouds, whereas initial pose uncertainty influences the range of sampled initial poses. As mentioned in Section 3.1, ICP takes the input point clouds and initial poses and produces a set of pose estimates. Finally, uncertainty is estimated using KL divergence in Section 3.3. Given different levels of perturbation, the input point clouds and initial poses would change, and the ICP algorithm would yield different uncertainty estimates. Kernel SHAP is then used to explain how important each uncertainty source contributes to the uncertainty estimate. As kernel SHAP uses the additive feature attribution method in Equation (1), the explanation is:\n$$g(z') = \\phi_{snsn} + \\phi_{ip}z_{ip} + \\phi_{po}z_{po}$$\nwhere 'sn, zip,zpo \u2208 {0,1} represent simplified input features, \u00d3sn, \u0424\u0456\u0440, \u0424\u0440\u043e \u2208 R refer to the attributed importance of initial pose uncertainty, sensor noise, and partial overlap, respectively. For an instance i and uncertainty source j, zij = 1 signifies that the feature is present, and input is perturbed in this fashion, whereas 0 indicates the absence of uncertainty source j, thus not perturbed by such feature and is thus the reference value. Note that the bias o is omitted because the expected value for the unperturbed case is 0, i.e., all zij = 0 for all j \u2208 {1, ..., M}."}, {"title": "6 Experiments", "content": "This section shows the experimental setup and how kernel SHAP explains ICP uncertainty in two experiments. The initial experimental setup includes how much to perturb the three uncertainty sources and how the pose uncertainty is estimated.\nRanges of Perturbations for Uncertainty Sources: To analyze the effect of each uncertainty source: sensor noise, initial pose uncertainty, and partial overlap, a sensible range for each source is specified.\nAs the mean bias value for Hokuyo sensor is found as 5 cm in [18], the Gaussian sensor noise N(0, \u03c3) is added to the two input point clouds with o from 0 m to 0.1 m, with a step size of 0.01 m.\nAs shown in Equation (4), Tinit is perturbed by the small initial pose uncertainty \u00a7 ~ N(0, s\u03a3), which is applied with a scale s from 1 to 2, with a step size of 0.1.\nSince the number of points in each point cloud is on the order of 105, removing points in the partial overlap region of two point clouds would result in a big change in uncertainty estimate. Thus, \u03bb, difference between original overlap ratio 01,2 and target overlap ratio 01,2, is set relatively small. Given O1,2 > 0.1, A ranges from 0 to 0.1, with a step size of 0.01.\nPose Uncertainty Estimation: In this work, we estimate the pose uncertainty using the KL divergence between the pseudo-true distribution and the perturbed distribution. The pseudo-true distribution is computed by sampling 100 ICP pose estimates of unperturbed inputs: initial pose sampled with zero-mean Gaussian with s\u2211, where s = 1, around the ground truth pose, without sensor noise, and unaltered overlap ratio. In contrast, the perturbed distribution is calculated by sampling 100"}, {"title": "6.1 Different Perturbations for the Same Pair of Input Point Clouds in Apartment", "content": "In this section, we examine various perturbation sets to understand how kernel SHAP elucidates the sources of uncertainty in point clouds 6 and 7 from the Apartment sequence in the Challenging datasets [22]. In the following, summary plot, waterfall plot, and feature dependence plots are illustrated.\nSummary plot. We utilize summary plot to demonstrate the overall impact of each source of uncertainty. In Figure 2, sensor noise correspond to the largest SHAP values, indicating that they contribute the most to pose uncertainty. Positive SHAP values correspond to perturbed features (high feature values, red dots), while when features are unperturbed (low feature values, blue dots), the attributed SHAP value would be close to zero. However, there are a few cases where the SHAP values are negative, as opposed to our predictions.\nWaterfall plot. Waterfall plot shows the contribution of each uncertainty source to individual data instances. In Figure 3, sensor noise is 9 cm, initial pose uncertainty has scale 1.1, and partial overlap eliminates 9% points in overlapping region of reference point cloud 7. Among the three uncertainty sources, sensor noise is more important than partial overlap, and initial pose uncertainty has the least influence on uncertainty.\nFeature dependence plots. Feature dependence plots show the relationship between different sources of uncertainty and their corresponding SHAP values. In all three plots in Figure 4, an increasing trend of SHAP values vs. feature values could be observed. In Figure 4a, for any given sensor noise, high initial pose uncertainty (red dots) seems to reduce the influence of sensor noise, as shown by lower SHAP values. This suggests that when initial pose uncertainty is the dominant factor, it overshadows the influence of sensor noise. In Figure 4b and Figure 4c, this interaction effect is less stark."}, {"title": "6.2 Same Perturbation for Contiguous Pairs of Point Clouds in Different Sequences", "content": "In this section, the perturbation of the three uncertainty sources is fixed to the mean value: {0.05, 1.5, 0.05}. Feature effects are analyzed across contiguous point clouds pairs in all 8 sequences of Challenging datasets. This experimental setup mirrors practical scenarios, where perturbations are fixed and the importance of each uncertainty sources is determined.\nAfter removing outliers using interquartile range, the SHAP values of the three uncertainty sources are analyzed. Table 1 displays the median SHAP values for each uncertainty source across all sequences. Except for the sequence Mountain, the SHAP values consistently follow the order: sensor noise > partial overlap > initial pose uncertainty. This suggests that, in this perturbation setting, reducing sensor noise would significantly decrease uncertainty across all sequences.\nWhile explanation methods assess feature-prediction correlations, causality between uncertainty sources and pose uncertainty estimates remains unsettled. Exploring the causal relationship requires causal inference and is left for future research. In addition, we plan to improve and merge the proposed method to deal with uncertainty in learning-based systems [23, 24, 25]. Using such methods, we further envision developing a semi-autonomous robotic system [26, 27] where the human operator can be informed of why the system has failed and take actions to reduce the uncertainty."}, {"title": "7 Conclusion", "content": "This work employs kernel SHAP to explain the relationship between uncertainty sources and uncertainty estimates. In Section 6.1, the effects of each uncertainty source at different perturbation levels are analyzed for the same input point clouds, yielding mostly nonnegative and interpretable SHAP values. In Section 6.2, the effects of uncertainty sources under the same perturbation level are studied across contiguous point cloud pairs in all sequences, providing insights into the importance of each source. As kernel SHAP is model-agnostic, it can also explain other ICP algorithms, such as Stein ICP [6]. Kernel SHAP remains applicable even if the range or step of uncertainty sources changes or additional sources, like under-constrained scenarios or ICP randomness, are introduced."}]}