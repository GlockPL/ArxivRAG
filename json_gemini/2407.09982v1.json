{"title": "Artificial intelligence and machine learning applications\nfor cultured meat", "authors": ["Michael E. Todhunter", "Sheikh Jubair", "Ruchika Verma", "Rikard Saqe", "Kevin Shen", "Breanna Duffy"], "abstract": "Cultured meat has the potential to provide a complementary meat industry with reduced\nenvironmental, ethical, and health impacts. However, major technological challenges remain which\nrequire time- and resource-intensive research and development efforts. Machine learning has the\npotential to accelerate cultured meat technology by streamlining experiments, predicting optimal\nresults, and reducing experimentation time and resources. However, the use of machine learning in\ncultured meat is in its infancy. This review covers the work available to date on the use of machine\nlearning in cultured meat and explores future possibilities. We address four major areas of cultured\nmeat research and development: establishing cell lines, cell culture media design, microscopy and\nimage analysis, and bioprocessing and food processing optimization. This review aims to provide the\nfoundation necessary for both cultured meat and machine learning scientists to identify research\nopportunities at the intersection between cultured meat and machine learning.", "sections": [{"title": "Introduction", "content": "Food production generates about a quarter of global greenhouse gas emissions and causes other\nnegative impacts on the environment and human health (1,2). Animal products, including meat,\nseafood, eggs, and dairy contribute more than 56% of food's emissions, despite providing only 37%\nof protein and 18% of calorie intake (3). Meat production is a large sector, producing 328 Mt in 2020\nand expected to expand to 374 Mt by 2023, based on estimates from the Organisation for Economic\nCo-operation and Development (OECD) and the Food and Agriculture Organization (FAO) of the\nUnited Nations (4). In light of projected growth in the global population and income, these estimates\nprojected that meat consumption will increase by 14%. To meet global meat demand and limit global\nwarming to 1.5\u00b0C there is a need for major changes in the production of meat (5,6). Cultured meat"}, {"title": null, "content": "(CM), known by many names including \u201ccell-based\u201d or \u201ccultivated\u201d meat, is an emerging technology\nthat uses tissue engineering and biomanufacturing techniques to produce animal meat through cell\nculture rather than animal husbandry. Proponents of the technology herald its potential to provide an\noption for producing animal agriculture products with reduced environmental, ethical, and health\nimpacts (7,8). However, major technological challenges remain in bringing CM products to market\nand achieving their proposed benefits (9). Many challenges stem from the fact that the technologies\nfor mammalian tissue culture come primarily from the medical field, where the scale is much lower\nand the market has weaker incentives to reduce the costs of production. However, if these\ntechnologies are to be applied to food, the challenges of scale and cost must be addressed.\nSome specific improvements to CM can be, and have been, made using traditional experimental\napproaches. However, tackling some of the more complex research questions requires more advanced\napproaches and experimental conditions. In recent years, an increasing number of groups have been\nusing methods enhanced by artificial intelligence (AI), and in particular its subset machine learning\n(ML), for such tasks. ML can streamline experiments, predict optimal results, and reduce\nexperimentation time and resources. There are many opportunities for ML to accelerate research\ndevelopment and reduce costs in CM. Some companies have indicated the use of ML in CM product\ndevelopment or CM-associated services (10\u201317), but very little of this progress in applying ML to\nCM has been shown or validated in the public domain. Academic and government-supported\nresearch in this space is emerging, including at the University of California at Davis, Virginia Tech,\nTufts University, and The CentRe of Innovation for Sustainable banking and Production of cultivated\nMeats (CRISP Meats). However, few publications on the topic exist to date (18\u201321). An increase in\nopen public research on the use of ML to optimize and scale CM production would greatly accelerate\nthe application of ML to the CM field.\nIn this review, we aim to provide a foundation necessary for researchers, from the CM or ML fields,\nto identify research opportunities at the intersection between CM and ML. We first provide a brief\noverview of both fields. Subsequent sections delve into both existing and potential ML applications\nfor optimizing cell lines, formulating culture media, aiding cell culture microscopy and image\nanalysis, and optimizing bioreactor and food processing parameters. Note that we have focused on\nCM challenges to which ML can be applied, and this should not be seen as a comprehensive review\nof all challenges in the CM or ML fields. As applications of ML in CM are limited, we discuss how\nML methods that have been applied in other areas of bioinformatics can be adopted to solve tasks in\nCM."}, {"title": "Background on the Fields of Cultured Meat and Machine Learning", "content": null}, {"title": "Cultured Meat", "content": "CM aims to replicate the taste and texture of animal tissue within a manufacturing system using\nanimal cells (Figure 1). First, cells from a species of interest are selected or engineered for desirable\ngrowth and differentiation traits in vitro. The selected cells are grown in a suitable medium,\nproviding the nutrients and signaling cues that would normally be provided in the body. At early\nstages, such as cell selection, the cell culture may start at a small scale in plastic dishes or flasks. Cell\nculture is eventually scaled up to industrial-scale bioreactors, devices capable of controlling\nenvironmental temperature, pH, dissolved oxygen, and nutrient exchange at large volumes (22).\nOnce enough cells are grown, they are differentiated into mature cell types. At this stage, the cell\nculture may be formed into a tissue (i.e. structured product, such as a steak) or a cell slurry, which is\nlater processed into a meat product (i.e. unstructured product, such as ground beef)."}, {"title": null, "content": "This process leans heavily on medical tissue engineering, an area of research that has been studied for\nnearly 40 years and has been commercialized at a small scale for simple grafts of cell-laden scaffolds\nfor skin and cartilage. However, complete tissues, such as skin with hair follicles and sebaceous\nglands or functional muscle, still face technological barriers (23). While tissue function is not critical\nfor CM, using this technology for the production of food comes with unique constraints, especially\nthe need for larger scale, lower costs, and materials that are both edible and palatable.\nCommercial and academic interest in CM has grown rapidly in the last decade. The number of\ncompanies working on CM grew from 1 to over 170 from 2011 to 2023, with over 3 billion dollars of\ninvestment (24). Similarly, academic interest in the field has grown dramatically, with 350+ papers\npublished on CM in the last 2 years, more than all other years prior (with tracking) combined (24). In\nparallel, cost estimates for CM have come down significantly in the last decade: from the first CM\ndemonstration in 2013 of a 140-gram burger at approximately \u20ac250,000 (25), to recent claims of\ncosts as low as $7.70/lb from industry developers (26). However, these industry cost claims have yet\nto be proven publicly. Furthermore, CM production has yet to be shown on a scale close to that\nneeded to offset even a fraction of current meat consumption (27). Current production capacity is not\nknown, but estimates range from 1-10 kg/y, compared to the 3.2x1011 kg/y produced by\nconventional meat (28). Highly optimized industrial mammalian cell lines, such as Chinese hamster\novary (CHO), are still produced at a much lower scale and higher cost than needed for food\nproduction (28). Given that consumers are unlikely to want to consume hamster ovary cells,\nsignificant technological challenges must be overcome for meat and seafood-relevant cells to be\nproduced at a scale and cost needed to replace a meaningful portion of the conventional meat market."}, {"title": "Machine Learning", "content": "An ML workflow involves a series of steps, as illustrated in Figure 2, which starts with preparation\nof the dataset. A dataset typically consists of datapoints, each one an observation with features that\ndescribe the datapoint. The type of data varies widely: numerical, time series, text, images, audio,\nvideo, sequential, graph, or any combination of these. Since the data must be in a numerical form for\nthe subsequent steps, a data transformation step converts the data to numerical values. The next step\nis the preprocessing of raw data, where procedures such as imputing missing values and reducing\ndata dimensionality are undertaken.\nSubsequently, an integral component of the ML methodology is dividing data into distinct subsets:\ntraining, validation, and testing. Some common approaches, such as K-fold cross-validation,\nleave-one-out, and holdout validation, can typically be used for most problems (30). Prior to model\ntraining, it may be necessary to employ feature selection or extraction techniques on the training set\nto identify the most informative variables in the data, and these features must be used in both the test\nand validation sets to maintain the integrity of the evaluation process.\nThe culmination of this preparatory work is a dataset suitable for training an ML model. Typically,\nexperiments are conducted with different ML algorithms/architectures (such as random forests,\nk-means, and deep neural networks) to settle on the most performant overall model. However,\nsometimes the choice of ML model depends on the type of data. For example, convolutional neural\nnetworks (CNNs) are preferred for image data since they can extract spatial features from the image\n(31). On the other hand, recurrent neural networks (RNNs) are typically used for sequential data\nsince they can remember information in a long sequence through their gate mechanism (32).\nThe training set is instrumental in building the model since the model adjusts its parameters to learn\nthe distribution of the training set. The validation set is required for fine-tuning the model's"}, {"title": null, "content": "hyperparameters and ensuring that the model generalizes well beyond the training data, thereby\navoiding overfitting. Finally, the test set provides a measure of the model's predictive accuracy and\noverall performance in real-world scenarios. Some of the typical performance metrics for\nclassification tasks are accuracy, precision, recall, and F1-Score. Typical performance metrics for\nregression are R\u00b2 score, mean absolute error, and mean square error (33). However, lots of other\nperformance metrics are used depending on the tasks and types of data. The purpose of performance\nmetrics is to compare the performance between different models and also to understand how a model\nis performing overall for the specific task."}, {"title": "Types of Machine Learning:", "content": "ML methodologies can be broadly classified into three categories: supervised, unsupervised, and\nreinforcement learning (RL). In supervised learning, the model is trained on a labeled dataset, where\neach example is paired with an outcome or label that aligns with the objective of the specific task at\nhand. Consider the goal of predicting gene expression levels from DNA sequences; here, the data\npoint would be the DNA sequence, while the associated expression level serves as the label. The\nmodel hones its predictive capability by learning the relationship between input features and their\ncorresponding labels. When it comes to evaluation, the trained model is tasked with predicting labels\nfor new, unseen data points. Key traditional supervised learning models include logistic/linear\nRegression, k-nearest neighbours, and support vector machines. The supervised ML approach has\nmade significant contributions across various domains in bioinformatics, enabling advancements in\nDNA segmentation, gene expression prediction, and protein structure prediction (34).\nUnsupervised learning, in contrast, does not rely on labeled data. It is particularly useful when the\ngoal is to unearth underlying patterns or structures within the data, independent of predefined\noutcomes. This makes unsupervised learning a potent tool for exploratory analysis, especially in\nscenarios where labeled data is scarce or when the structure of the data is not fully understood. Some\nof the key unsupervised learning approaches are k-means, hierarchical clustering, and density-based\nspatial clustering of applications with noise. Unsupervised learning has been successfully applied in\ngrouping functionality-related genes, microarray analysis, and biological image segmentation\n(34,35).\nRL is a dynamic and adaptive approach well-suited for situations where a machine is required to\nmake a series of decisions to achieve a desired goal or perform an optimization task, offering a\nframework for learning through interaction (36). Within this paradigm, an agent\u2014often an advanced\nML model in deep RL -engages in a sequential decision-making process, each time interacting with\na complex environment represented by a set of variables that define the current state of the\nenvironment. The agent executes actions, transitioning between states, and ultimately may reach a\nterminal state, signaling the conclusion of the decision sequence. The RL framework incorporates a\nsystem of rewards and penalties, with the agent receiving feedback in the form of rewards for\nbeneficial actions or penalties for undesirable outcomes. The objective for the agent is to devise a\nstrategy that maximizes cumulative rewards, thus steering towards the most optimal actions to attain\nits final goal. RL has recently been applied to bioinformatics (37\u201339) and gained lots of attention\nbecause of its success in areas, such as sequence alignment (40) and protein loop sampling (41)."}, {"title": "Neural Networks:", "content": "Recent advances in applying ML to biology are based on neural networks, a subset of ML methods\nthat can be employed in all three ML categories: supervised, unsupervised, and RL (42). ML models"}, {"title": null, "content": "with neural networks are often referred to as deep neural networks when there are multiple layers of\nneural networks in the architecture of the model, a method more broadly known as deep learning.\nThese neural network layers typically attempt to mimic the activity of brain neurons, where each\nneuron employs a mathematical function that alters the data it receives from the previous layer\n(43,44). At first, the data is fed into an input layer, which then connects to hidden layer(s) (used for\ncomputing), and finally an output layer, designed to deliver the final prediction. The model learns by\noptimizing the function parameters of each node. Some popular neural network architectures are feed\nforward networks, CNNs, RNNs, and transformers (43\u201345). Deep learning models typically capture\ncomplex biological processes and incorporate heterogeneous data in the model through its different\nlayers, which may be a necessity for many optimization and prediction tasks in CM (46). It can be\napplied to both supervised and unsupervised scenarios. In RL, deep learning models can be employed\nas agents as well (47)."}, {"title": "Generative AI:", "content": "Generative AI is another subfield of unsupervised learning which typically aims to generate new data\nor samples based on the patterns learned from the training data. Variational Autoencoders (VAEs)\n(48-50), which employ deep learning, are the first generation of generative AI models. VAEs\ntypically employ two deep learning models: i) an encoder that encodes the input into a latent space\nand ii) a decoder that predicts the input by matching the distribution of the latent space by applying\nvariational inference techniques. Together, the encoder and decoder minimize the reconstruction loss\nof the input. Figure 3 shows the general architecture of VAE.\nThe second generation of generative models is deep adversarial networks (51,52). These architectures\nalso have two networks: a generator and a discriminator. Initially, generators generate new data\nrandomly and discriminators classify whether the generated sample is original or generated.\nIteratively, both the generator and discriminator learn how to generate a better sample and distinguish\nbetween original or generated sample. Eventually, the generator learns to generate realistic data\nsamples that are difficult for the discriminator to distinguish from real data.\nRecent advances in generative AI are mostly based on transformers (45), which have revolutionized\nvarious fields including natural language processing, computer vision, and bioinformatics (53,54).\nTransformers have demonstrated exceptional capabilities in capturing long-range dependencies and\nmodeling complex sequential data. In bioinformatics, methodologies heavily draw inspiration from\nNLP techniques due to the inherent similarities between biological sequences and natural language\ntexts. By employing transformers, researchers are able to effectively model biological sequences such\nas DNA, RNA, and protein sequences, leading to significant advancements in tasks such as sequence\ngeneration, structure prediction, and drug discovery (38,53\u201356)."}, {"title": "Graph Neural Networks:", "content": "Graph neural networks (GNNs) are another area of ML that works with graph structured data and\nbiological networks, such as via protein interaction networks, gene coexpression networks, and\nmetabolic networks (57,58). A biological network or biological graph typically is arranged in terms\nof nodes and edges, where the nodes are biological entities (i.e. genes, proteins, metabolites, etc) and\nthe edges indicate how these entities relate to one another. GNNs are based on the principle of\nmessage passing, where each node in the graph aggregates all embeddings (messages) of its\nneighbour nodes and updates the weights of pooled messages through a neural network. There are\nthree main tasks in graph structured data. The first one is link prediction between two biological"}, {"title": null, "content": "entities. Examples of link prediction are predicting the interactions between proteins or predicting\ninteractions between genes/regulatory elements (59,60). The second task is node functionality\nprediction. For example, predicting an unknown function of a protein based on the physical\ninteractions between proteins in the protein interaction network (61). The third application of ML in\nnetwork analysis is to classify sub-network functionality. Figure 4 shows different ML tasks in a\ngraph or network structured data. Muzio et al. classified functions of subnetwork based on a\nmolecule's toxicity or solubility (61). In addition, ML is also applied to obtain subnetwork\nembedding where the subnetwork is represented as a vector preserving the important information\nwithin the subnetwork in a numeric form. This embedding can facilitate further analysis of the\nsubnetwork and is used for various downstream tasks (62)."}, {"title": "Cell Lines", "content": "Meat consists of various cell types, predominantly muscle cells (approximately 90%), with fat and\nconnective tissue cells accounting for the remaining 10% (63). Additionally, there are some vascular,\nneural, and tissue-resident immune cells present in small amounts (63\u201365). To provide the taste,\ntexture, and aroma expected in meat, most CM development has focused on muscle, fat, and\nconnective tissue production. Cells will also likely contribute to the nutritional properties of CM\nproducts, and cell optimization may be used to tailor the nutritional profile of CM (66,67).\nThe cell types used to produce CM range from lineage-committed progenitor cells (e.g. muscle\nsatellite cells, myoblasts, or preadipocytes) to stem cells able to differentiate into a broader set of\ncells (e.g. mesenchymal stem cells, embryonic stem cells, or induced pluripotent stem cells) (64).\nDevelopers may use primary cells, meaning cells that are isolated directly from an animal. However,\ncell lines, which are established cultures of cells that have been selected and optimized, are ideal\nbecause they are more consistent, characterized, and reduce the use of animals in the supply chain.\nFurthermore, immortalized cell lines or pluripotent stem cells are of particular interest due to their\nability to escape the typical limits on population doublings seen in most primary cells (i.e. Hayflick\nlimit) (68,69). A detailed review of cells used in the production of CM can be found elsewhere (65).\nFew CM-relevant cell lines are currently well characterized and commercially available, with most\ncoming from model organisms used in biomedical research, such as mouse, rat, or zebrafish, and cell\nlines for many agricultural species still need to be developed (70). Cell lines for marine species,\nespecially invertebrates such as mollusks or crustaceans, are especially underdeveloped, with only a\nfew reported cell lines and not all are food-relevant species (71\u201380). For many species, there is a lack\nof basic knowledge of their physiology and the biochemistry required for in vitro culture or\nimmortalization (70,81). The lack of knowledge of molecular and genetic markers as well as few\nspecies-specific antibodies available makes identifying and curating cell lines difficult for\nunder-studied species. ML can help biologists analyze complex cellular data to assist with identifying\nideal cell line populations and optimizing existing cell lines through gene perturbations."}, {"title": "Network analysis is a tool to model biological interactions", "content": "Optimization of cell lines is often challenging because it requires understanding the \u201cstate\u201d of a cell\nor cell population (i.e. what the gene and protein networks are doing) and selecting or engineering for\ndesired cell states. Measuring and predicting these states involves interpreting complex interactions\nbetween genes and proteins, identifying those that are important for specific qualities, and predicting\nhow perturbations will affect the whole network. ML can be used to model this complex network\nthrough an area of study known as network analysis. Network analysis is used throughout sections 3\nand 4, so a general overview is first presented here."}, {"title": null, "content": "Most of the earlier works in network analysis, such as DeepWalk (82\u201384), LINE (85), Node2Vec\n(86,87) are inspired by NLP or community detection methods of social networks. These methods\nprimarily use multiple random walks from a specific node to obtain a subnetwork. The objective is to\nobtain a vector embedding of the specific node by following a skip-gram strategy employed in NLP\n(88). The obtained embedding maximizes the probability of predicting the neighboring nodes\nobtained by random walks. This embedding can be used for most of the network analysis tasks\ndescribed previously. However, these approaches often do not preserve the graph structure\ninformation which may lead to information loss.\nIn recent years, GNNs have been employed in graph-structured data and biological networks. While\nthe objective remains the same for network analysis with GNN, the primary difference between the\nNLP approach and the GNN is that since GNNs are built for working with graph structured data,\neach node in the graph aggregates information from its neighbours while preserving the connectivity\ninformation in the GNN. GNNs have been implemented to predict protein interactions (89,90),\nmolecular interactions (91,92), metabolite-disease associations (93) and obtain subnetwork\nembeddings (94) that can be used to identify the functions of a biological subnetwork. Generative\ndeep learning strategies, such as VAEs and deep adversarial network-based models, are also trained\non biological networks by employing GNNs (95,96). The most famous example to date is\nAlphaFold2, a deep learning GNN model that was employed on amino acid sequences to predict\nmore than 200 million protein structures (38). This is a significant advance in the field of structural\nbiology which can be used in protein design, drug target prediction, cell type identification, and\nantibody development. AlphaFold2 can play a big role in designing new proteins and understanding\nthe physical relationships between proteins (97).\nNetwork analysis can employ multiple types of biological data within a multi-omics setting. Since\neach omics technique typically captures a specific biological process, integrating multi-omics data\ncan provide a holistic overview of the biological process. In a multi-omics ML approach, different\nML models are employed on different types of data (such as genomics, transcriptomics, proteomics,\nand metabolomics) to obtain numerical representations. These numerical representations are then\ncombined together to obtain a more informative representation used to predict final outputs. For\nexample, MOGONET employs a GNN on mRNA expression, DNA methylation, and miRNA\nexpression data to predict disease information (98). Similar datasets can also be used for CM to\npredict cell line features. More applications of multi-omics ML methods are discussed in section 3.2.\nFurthermore, network analysis can help determine aroma and flavor (99). Since meat aroma and\nflavor are largely controlled by metabolic pathways (100), network analysis can be applied to\nbiosynthetic pathways to enhance or add flavors to CM products. Network optimization has been\nused to design yeast that overexpress licorice glycoside (101), and although licorice is a flavor that\nfew would want in a steak, one could imagine more savory corollaries. In other yeast experiments,\ntranscriptomic network analysis has been used to improve acid resistance, and acid resistance is just\nas important to mammalian culture as to microbial culture (102)."}, {"title": "Machine Learning Can Help to Analyze Complex Omics Data to Identify and\nCharacterize New Cell Lines", "content": "\u201cOmics\u201d approaches, such as genomics, transcriptomics, proteomics, and metabolomics, are powerful\ntools for identifying and characterizing cell lines. In particular, RNA sequencing (RNA-seq)\ntechnologies are commonly used to quantify cellular gene expression to validate and optimize cell\nlines. However, analyzing RNA-seq or other -omics data across many candidate cells is a complex"}, {"title": null, "content": "and daunting analytical task. ML can help these analyses in multiple ways, including by grouping\nfunctionality-related cells using an unsupervised approach (94), profiling gene expression using a\nsupervised approach (103), and identifying different tissue types using unsupervised (104,105) and\nsemi-supervised approaches (106).\nUsing gene expression data to cluster cells based on cell type or behavior can help explain\nheterogeneity among cell populations and discover subpopulations with beneficial characteristics.\nWhen establishing cells for CM production, scientists may want to isolate only certain cell types with\noptimal attributes or remove undesirable cell types. For example, using single cell RNA-seq\n(scRNA-seq) Messemer et al. found that an isolation from cattle muscle contained 11 distinct cell\ntypes (107). This work led to a better understanding of the cells derived from a primary isolation, as\nwell as cell surface markers suitable for the identification and separation of populations by flow\ncytometry. Additionally, in a recent preprint, Melzener et al. used RNA-seq to study subpopulations\nduring muscle differentiation, understanding cell fates with an aim to improve the efficiency of cell\ndifferentiation and maturation (108). ML is also increasingly being explored for the modeling of cell\ntrajectories via scRNA-seq (109).\nUnsupervised ML can help to map cellular heterogeneity by grouping functionality-related cells,\nidentifying cell sub-populations, and performing dimensionality reduction (104,105,110). Typically,\nthe input to the unsupervised ML model is gene expression data obtained from RNA-seq. In\nconventional ML frameworks, which are not based on neural networks, the outcome is generally an\nassigned cluster number for each cell or gene. For an in-depth exploration of how traditional ML\ntechniques are applied in this context, we direct readers to the comprehensive review by Petegrosso\net al. (111). In contrast, unsupervised deep learning methods predominantly leverage autoencoders,\nwhich compress high-dimensional cellular data into a more manageable lower-dimensional space\nwhile retaining essential information (104,105,110). This lower dimensional representation of the\nencoder can be used to obtain clusters of cells (104,105,112\u2013114) and can be further fine tuned for\ngene expression profiling (42,115).\nRecently, another family of autoencoders that uses GNNs has been employed to obtain the lower\ndimensional representation of transcriptomics data. These GNN-based autoencoders use the\nknowledge of biological networks, such as gene-gene relationships, cell interaction networks, protein\ninteraction networks and biological pathways, along with gene expression data to obtain a more\nrobust and informative representation of cells and genes (94,110,116\u2013120). The GNN autoencoders\nare unique compared to traditional autoencoders as they encode information on biological interaction\nbetween entities along with structural information and biological properties.\nSemi-supervised approaches have been employed in many tasks, such as learning responses due to\ngene perturbation, different functional score prediction due to gene knockouts, identifying different\ntissue types, and transcriptome analysis\n(106,121-126). These models are adept at leveraging both labeled and unlabeled data, typically\nemploying the unlabeled data to train an autoencoder and then using the labeled data to fine-tune the\nautoencoder toward the target outcomes (106,123,127). Fine-tuning is the process of adjusting\npretrained model parameters for a specific task by utilizing a small labeled dataset. The\nsemi-supervised approach is notably different from its unsupervised counterpart as it provides a\ndegree of guided learning, which is crucial when the available labeled data is sparse but critical for\nthe identification of specific labels. For instance, while the categorization of cells based on functional\nsimilarities may fall under unsupervised learning-grouping cells by inherent characteristics\u2014the"}, {"title": null, "content": "task of pinpointing cell doublets could benefit from a semi-supervised model that utilizes a limited\nset of known doublet samples to enhance its predictive accuracy.\nIn addition to transcriptomic data, further single-cell multimodal sequencing technologies have been\ndeveloped that provide cell-specific information, such as chromatin accessibility (scATAC-seq) (128)\nand surface proteins (CITE-seq) (129). These data types provide complimentary insight into\nscRNA-seq, such as improving accuracy in modeling gene regulatory networks in the case of\nscATAC-seq (130,131). This understanding can aid in CM-related tasks, such as identifying\ntranscriptomic/epigenetic markers predictive of high proliferation and differentiation potential given\npreviously observed variability in primary cell culture performance (132\u2013134).\nIn an ML context, autoencoders and GNN-based deep learning models are mostly applied to this\nmultimodal data (135). Some of these autoencoders employ individual encoders and decoders for\neach modality. We refer the readers to a review of multimodal single-cell models, and a review on\ngeneral best practices for single cell analysis, to learn more about the topic (135,136)."}, {"title": "Antibody Design for Characterization and Isolation of Novel Species can be Aided by\nMachine Learning", "content": "In cell line development it is crucial to both characterize cells, commonly via omics data (as\ndiscussed above) or visual identification (discussed in section 5), and isolate the cells of interest,\ntypically using flow cytometry cell sorting. Visual identification and flow cytometry both require the\nuse of antibodies with specific binding affinity to known cellular markers. Markers of muscle cell\ndifferentiation are well understood for most mammalian species (137). However, in under-explored\nspecies, such as fish or aquatic invertebrates, these proteins are not always shared with mammalian\ncells or, to the degree they are, have low sequence conservation (138). For example, recent work with\nan Atlantic mackerel (Scomber scombrus) skeletal muscle cell line found that antibodies for the\nmuscle satellite cell marker paired-box protein 7 (PAX7) was successful, while early myogenic\nmarker myoblast determination protein 1 (MYOD) was not (80). Surface markers, which are most\ncommonly used during flow cytometry cell sorting, are particularly understudied in CM-relevant cell\ntypes, with most existing research focused on immunology (138,139).\nAttempts at validating commonly used mammalian antibodies in fish have led to issues with\ncross-reactivity and specificity, suggesting that establishing cell lines for CM research will require\nthe repurposing of existing antibodies, if not the development of fully novel antibodies (140). The\nuse of ML on omics data has been shown to aid antibody development, such as via improving species\ncross-reactivity, antibody co-optimization, and binding affinity (141\u2013143). The autoencoder model\ntotalVI, trained on joint scRNA-seq and CITE-seq data, is able to provide insight into many key\nvariables that would aid antibody development: the identification of novel differentially expressed\nfeatures to target in a given cell subpopulation, the improved prediction of false positive/negative\nsurface proteins, the reduction of technical bias common in antibody-based measurements such as\n\"background\", and the improvement of experimental design by helping determine optimal antibody\ntitrations/sequencing depths for balancing cost and signal-to-noise ratio (144). For a full review of\ncomputational methods relevant to antibody development, readers are pointed to (145)."}, {"title": "Machine Learning Can Map and Enhance Genetic Traits to Optimize Cell Lines", "content": "Gene editing can be used to enhance or alter cellular traits to generate cell lines optimized for CM\nproduction, such as accelerating growth, extending growth (i.e. immortalization), reducing input\ncosts, or tailoring the flavor and nutrition. For example, manipulating cellular metabolism has a large"}, {"title": null, "content": "potential for increasing the efficiency (and therefore reducing costs) of CM products (9,146). As\nanother example, Stout et al. engineered cells to overexpress FGF2, eliminating the need for FGF2\nsupplementation in media through autocrine signaling (147). Because many of the species used in\nCM are under-studied, their genome regulatory networks are not yet well understood, slowing efforts\nfor gene editing. ML offers an opportunity to accelerate gene editing technology.\nGenes typically have many regulatory regions, such as upstream and downstream regions,\nuntranslated regions, promoters, and enhancers. These regulatory regions determine where, when,\nand how much a gene is expressed. Thus, to apply gene editing technology, identifying these\nregulatory regions is an essential task where ML models have been applied successfully\n(53,148,149). The most relevant modern ML techniques demonstrated to be useful for these tasks are\ngenerative adversarial networks (150,151) and convolutional neural networks (152).\nATAC-sequencing is a very useful data modality for informing on this set of tasks (153).\nMore recently, researchers have adopted transformers and architectures similar to large language\nmodels, such as BERT, to segment regulatory regions and predict expression levels (53). These\nmodels are typically trained on a large number of DNA sequences or similar kinds of data using a\nsupervised fashion by employing a masking strategy to generate a labeled dataset when labels are not\navailable (53,148). This entails subdividing a DNA sequence into numerous smaller fragments,\ntypically employing a k-mers based approach, where a k-mer is a subsequence of length k within the\nDNA. Selected k-mers are then masked within the sequence. The objective of the transformer-based\nmodel is to predict those masked parts of the sequence while imitating the interactions among\ndifferent fragments (53,154). By predicting the masked fragment, the model learns the underlying\nstructure of the DNA sequences. The resulting output is a set of numerical vectors, often referred to\nas embeddings, representing each k-mer, encapsulating the sequence information. These vector\nrepresentations can be further used to fine-tune the model for various downstream tasks, such as\nsegment identification, sequence alignment, and gene expression prediction where limited"}]}