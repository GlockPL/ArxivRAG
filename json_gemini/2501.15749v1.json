{"title": "LLM-powered Multi-agent Framework for Goal-oriented Learning in Intelligent Tutoring System", "authors": ["Tianfu Wang", "Yi Zhan", "Jianxun Lian", "Zhengyu Hu", "Nicholas Jing Yuan*", "Qi Zhang", "Xing Xie", "Hui Xiong*"], "abstract": "Intelligent Tutoring Systems (ITSs) have revolutionized education by offering personalized learning experiences. However, as goal-oriented learning, which emphasizes efficiently achieving specific objectives, becomes increasingly important in professional contexts, existing ITSs often struggle to deliver this type of targeted learning experience. In this paper, we propose GenMentor, an LLM-powered multi-agent framework designed to deliver goal-oriented, personalized learning within ITS. GenMentor begins by accurately mapping learners' goals to required skills using a fine-tuned LLM trained on a custom goal-to-skill dataset. After identifying the skill gap, it schedules an efficient learning path using an evolving optimization approach, driven by a comprehensive and dynamic profile of learners' multifaceted status. Additionally, GenMentor tailors learning content with an exploration-drafting-integration mechanism to align with individual learner needs. Extensive automated and human evaluations demonstrate GenMentor's effectiveness in learning guidance and content quality. Furthermore, we have deployed it in practice and also implemented it as an application. Practical human study with professional learners further highlights its effectiveness in goal alignment and resource targeting, leading to enhanced personalization. Supplementary resources are available at https://github.com/GeminiLight/gen-mentor.", "sections": [{"title": "1 INTRODUCTION", "content": "Intelligent Tutoring Systems (ITSs) have made significant strides in supporting personalized learning experiences by leveraging machine learning (ML) technologies [19]. These systems increasingly utilize data-driven insights across key aspects, such as managing learning materials [15, 37], profiling learner status [27, 30], and delivering personalized feedback [10, 39]. However, many ML-based ITSs suffer from fragmentation due to technical inconsistencies across modules. They also exhibit limited adaptability to emerging topics, often requiring extensive retraining to accommodate new educational topics. Recently, large language models (LLMs) have presented new opportunities to enhance ITS by offering interactive feedback through conversational interfaces [20]. Existing studies on LLM-based ITS [7, 16, 22] demonstrate their facilitation in content generation, query response, and problem-solving. However, while LLMs excel at dialogue-based engagement, they often remain reactive, merely responding to learner queries without proactively guiding learners toward their objectives [17]. This reactivity also limits their capacity to gain a comprehensive understanding of learners, thus weakening the personalization [22].\nAs educational demands continue to diversify, especially within professional and lifelong learning contexts, learners increasingly seek systems that support personal or career-specific goals [6]. For example, an employee assigned a task or seeking new jobs that involve unfamiliar technology may feel uncertain about where to start or what specific skills to develop. Without clear guidance, they risk becoming overwhelmed or wasting time on less relevant content [1]. Such learners would benefit from a system that bridges this gap by quickly identifying their knowledge deficiencies and providing targeted content to help them acquire the precise skills needed to complete the objective efficiently. This personalized approach, known as goal-oriented learning, goes beyond merely delivering information, focusing on guiding goal achievement [13]. However, traditional ITSs often rely on static curricula, offering broad content that may not adequately address the unique needs of individual learners. Additionally, LLM-based dialogue ITSs tend to be reactive rather than actively guide learners to achieve goals. As a result, these systems struggle to provide goal-oriented, personalized guidance, especially in fast-paced, professional contexts.\nTo address these gaps, we propose a perspective shift toward goal-oriented learning for transforming ITSs. As illustrated in Figure 1, unlike traditional ITSs that rely primarily on static curricula or reactive engagement, our approach emphasizes proactively guiding learners to achieve their specific goals. In goal-oriented ITSs, the learning process is driven by the learner's objectives rather than a predefined curriculum. By identifying skill gaps and profiling learner status, these systems can deliver more personalized pathways and tailored content, enabling learners to rapidly acquire the necessary skills to meet their specific goals. Notably, LLMs hold promising potential due to their remarkable ability to understand"}, {"title": "2 RELATED WORKS", "content": "2.1 Intelligent Tutoring System\nIntelligent Tutoring Systems (ITSs) are designed to provide personalized experiences, mimicking one-on-one human tutoring [4]. With advances in machine learning, modern ITSs have shifted toward leveraging data-driven approaches for material management [15, 37], learner modeling [27, 30], and feedback provision [10, 39]. Despite these advancements, existing ML-based ITSs often combine several ML-based models for distinct tasks, resulting in technical inconsistencies and data fragmentation, and lacking generalizability for emerging topics. Additionally, they rely on static content and predefined curricula, focusing on general knowledge acquisition rather than dynamically adjusting to individual learner goals. Recently, several works [7, 8, 16, 22] have integrated LLMs into ITS as a conversational tutor due to their excellent abilities in understanding and generation of LLMs. Otherwise, these systems can not proactively guide learners toward their long-term objectives due to their reactive nature and dialogue-based engagement. In our work, we explore a unified LLM-based multi-agent framework for ITS, which addresses the fragmentation that often arises from separate traditional ML models for ITS and enhances consistency across tutoring phases. Furthermore, we focus on providing proactive learning guidance for goal achievement, which differs from traditional ITS for broad knowledge acquisition.\n2.2 LLM-powered Multi-agent Systems\nUnlike individual LLM agents that operate independently, LLM-based multi-agent systems employ multiple LLM agents with diverse profiles to collaboratively tackle tasks [9]. By distributing"}, {"title": "3 PROBLEM STATEMENT", "content": "In goal-oriented learning, the focus is on achieving specific objectives efficiently, such as completing a project or mastering job-related skills. This requires proactive guidance to avoid unfocused learning and to improve goal completion efficiency. A goal-oriented ITS aims to customize learning pathways and content, enabling learners to quickly acquire the knowledge needed to meet their specific goals. Formally, let \\(U_t = (S_0, P, B)\\) represent the learner's profile, where \\(S_0\\), P, B denote the learner's initial knowledge status, preferences, and behavior patterns, respectively. Given a specific goal G, the learner must master a set of skills \\(S'\\) necessary to achieve this objective. Our aim is to efficiently minimize the skill gap \\(AS = S' - S_0\\) with a personalized and adaptive learning experience by scheduling a personalized learning path L and tailored contents C based on P, B, and real-time learner interactions I. To accomplish this, the system should address three key sub-tasks:\n\u2022 Skill Gap Identification. This step identifies the skills gap between the learners' current knowledge and the skills required to achieve their goals. First, goal G is mapped to the necessary skills, \\(f : G \\rightarrow S'\\), and then the skill gap \\(AS_0\\) is identified by \\(f: (S_0, S') \\rightarrow S_0\\), where the \\(S_0\\) is derived from learner's provided individual information \\(I_0\\).\n\u2022 Adaptive Learner Modeling. This module continuously update learner profiles by incorporating interaction data \\(I_t\\) at timestep t, yielding \\(f: (U_{t-1}, \\triangle S_0, I_t) \\rightarrow (U_t, \\triangle S_t)\\). This enables the system to track cognitive progress, recognize learning preferences, identify and behavior patterns.\n\u2022 Personalized Resource Delivery. To efficiently close the skill gap \\(\\triangle S_t\\), this module dynamically schedules an engaging learning path \\(L_t\\) and delivers tailored learning content \\(C_t\\), i.e., \\(f: (U_t, \\triangle S_t) \\rightarrow (L_t, C_t)\\). The path should adapt to the learner's evolvable progress and preferences, while the content should be high-quality, goal-relevant and personalized."}, {"title": "4 THE GENMENTOR FRAMEWORK", "content": "In this work, we propose an LLM-powered multi-agent framework for goal-oriented learning in ITS, named GenMentor. To address the above intricate sub-tasks, we distribute responsibilities across multiple LLM agents, allowing them to collaboratively manage different tasks. As illustrated in Figure 2, this system begins with accurately assessing the skill gap between the learner's current skills and the target objective. Once this gap is identified, the ITS generates a personalized learning path with an evolvable optimization method for both learning efficiency and engagement. Furthermore, the system curates and generates content that is goal-oriented, up-to-date, and tailored to the learner's specific needs, ensuring the learner focuses on the most relevant and targeted content. During the learning process, the generated learner profile are continuously adjusted with the newly learner's interactions, enabling dynamical adaptation to the learner's evolving progress, preferences and needs.\n4.1 Skill Gap Identification\nTo personalize the learning experience toward achieving specific goals, we identify the skill gap, i.e., the necessary skills bridging the learner's current cognitive status and target objectives. Mapping these goals accurately requires the LLM to grasp the goal's nuances, given their often abstract and high-level nature. However, direct prompting LLMs may produce irrelevant, unnecessary or incomplete skills, impeding effective goal achievement. Thus, we build a customized goal-to-skills dataset with Chain of Thought (CoT) [34] to fine-tune LLMs, improving the goal alignment of identified gap.\n4.1.1 CoT-enabled Dataset Construction. Given the absence of a directly relevant dataset for our task, we turn to job posting datasets, which contain detailed information on job roles, descriptions, and required skills. These datasets provide foundational insights into the expectations and requirements for various roles. By extracting pairs of job summaries (comprising roles and brief job descriptions) and their corresponding core skills, we construct a goal-to-skill dataset, treating these job summaries as goals. However, direct fine-tuning on these datasets may fall short in accurately mapping goals to skills, largely due to the abstract and high-level language common in job descriptions. To address this limitation, we employ CoT reasoning [34], introducing intermediate steps that clarify the logical connections between job responsibilities and the necessary skills. The CoT process involves breaking down the goals into key tasks, identifying the required skills for each task, and determining the proficiency levels needed, producing samples of <job summary, reasoning tracks, required skills>. See Appendix A.1 for more details. This approach facilitates capturing the nuanced relationships between goals and skills, thereby improving fine-tuning accuracy.\n4.1.2 Fine-tuning LLM for Goal Alignment. Using the constructed goal-to-skills dataset, we fine-tune the LLM as skill identifier to accurately map goals to specific skills. This step ensures that this agent identifies relevant and complete skills while filtering out unnecessary skills, focusing on efficient goal achievement.\n4.1.3 Gap Identification Process. This process begins with goal-to-skills mapping, \\(S' = \\text{LLM}_{\\text{skill-identifier}}(G)\\), where the learning goal is mapped to a set of skills that are the core competencies needed for the goal. Next, identified skills are compared with learner's initial cognitive status based on provided information to establish the skill gap, \\(AS = \\text{LLM}_{\\text{skill-identifier}}(S', S_0)\\). This step filters out already-mastered skills and highlights areas needing improvement."}, {"title": "4.2 Adaptive Learner Modeling", "content": "Understanding the learner's status is essential for ITS as it personalizes learning by adapting content to their needs, and providing targeted feedback [2]. Instead of traditional ML-based methods lacking generalization and integration while LLM-based dialogue remain reactive, here, we explore how to explicitly leverage LLM to achieve the comprehensive and dynamic learner profile U.\n4.2.1 Comprehensive Learner Profile. To capture learner's knowledge status and provide customized learning resources that align with goals and preferences, we consider three fundamental aspects to create a comprehensive learning profile U, informed by educational theories [2, 26, 29]. These aspects are as follows:\n\u2022 Cognitive Status S. To monitor the learner's knowledge acquisition, we track learning progress and assess mastery of required skills. We represent these skills as a set of competencies the learner has mastered and those they still need to acquire, along with corresponding metrics of progress and mastery. This approach highlights remaining skill gaps and enables the system to provide targeted content to help the learner achieve their goals.\n\u2022 Learning Preferences P. Recognizing the diverse ways learners absorb information, this aspect captures individual preferences such as preferred content styles (e.g., concise summaries, detailed explanations) and preferred activity types (e.g., reading, active querying, interactive exercises). These insights enable the system to adapt its instructional methods and dynamically adjust the content delivery to enhance learner engagement and knowledge comprehension.\n\u2022 Behavioral Patterns B. By analyzing interaction data, we aim to identify behavioral trends that affect learning engagement, such the system usage frequency and the time consumption variability of learning sessions. Infrequent use and irregular time consumption (e.g., long time spent in one session) may signal disengagement or difficulty. These insights allow for proactive interventions, such as motivational messages or adjusted content difficulty, to maintain learner momentum toward their goals.\n4.2.2 Dynamic Learner Modeling. Initially, based on provided information of learner \\(I_0\\) (e.g., resume) and identified skill gaps \\(\\triangle\\), we use a learner profiler to create a preliminary profile, i.e., \\(U_0 = \\text{LLM}_{\\text{learner-profiler}}(I_0, \\triangle S_0)\\), capturing aforementioned three aspects. This initial profile serves as the starting point, may having limitations or inaccuracies. As the learner interacts with the system, their profile is continuously updated and refined based on collected dynamic interactions \\(I_t\\) (e.g., real-time performance data and proactive feedback) at each timestep t, i.e., \\(U_t = \\text{LLM}_{\\text{learner-profiler}}(U_{t-1}, I_t)\\). During each session learning at timestep t, the system collects learner feedback and tracks metrics like performance and time use as interaction data \\(I_t\\). For learning preferences P, data on time spent on different activities and feedback identify favored content, enabling dynamic adjustment of instructional content. For example, if a learner favors interactive exercises, the system prioritizes these activities by offering more exercises. Regarding behavioral patterns B, platform usage frequency and engagement consistency help gauge motivation. For example, irregular patterns (e.g., prolonged durations on single sessions or infrequent login) prompt interventions like trigger motivational prompts or adjusted content difficulty to maintain engagement and prevent frustration. After each session, the system assesses the progress of cognitive status by quiz scores and learner-reported feedback. It updates the learning process and skill mastery and identifies the remaining skill gap for future learning. An illustrative example is shown in Figure 3."}, {"title": "4.3 Personalized Resource Delivery", "content": "To effectively close identified skill gaps, GenMentor employs a personalized, adaptive content delivery method that dynamically aligns resources with each learner's unique profile and progress. Concretely, given the skill gap \\(\\triangle S_t\\) and learner profile \\(U_0\\) obtained"}, {"title": "4.3.1 Learner Simulator via Adaptive Profiling", "content": "To achieve adaptations of learning resources while minimizing reliance on direct user feedback, we design an LLM agent-based feedback mechanism that simulates the learner responses. Specifically, leveraging real-time learner profiles \\(U_t\\), a learner simulator employs the role-playing method to anticipate learner feedback for delivered resources [24]. This simulation serves as a proxy to optimize delivered resources without requiring direct learner feedback. For learning paths, the learner simulator evaluates factors such as efficiency, engagement, and task difficulty, while anticipating learner reactions to tailored content (e.g., asking for more exercise, or feedbacking too high difficulties). This method allows the system to proactively adjust the learning resource to better match learner intentions and preferences, maximizing comprehension and sustaining motivation."}, {"title": "4.3.2 Evolvable Learning Path Scheduling", "content": "We use a path scheduler equipped with CoT reasoning ability to plan effective and engaged learning pathways that effectively support skill acquisition. Initially, it constructs an initial learning path \\(L_0 = \\text{LLM}_{\\text{path-scheduler}}(U_0, \\triangle S_0)\\) based on the identified skill gap \\(\\triangle S_0\\), and the initialized learner profile \\(U_0\\). This path is refined iteratively with feedback from the learner simulator, ensuring the learning path becomes progressively challenging and motivational for the learner. As the learning process progresses, the learner profile \\(U_t\\) is continuously updated to incorporate insights into the learner's evolving preferences, abilities, and progress. After completing a session at timestep t, the path scheduler dynamically re-evaluates and adjusts the learning path \\(L_{t-1}\\) with the updated profile, while generating \\(L_t = \\text{LLM}_{\\text{path-scheduler}}(U_t, S_t, L_{t-1})\\). If the learner approves, the updated learning path \\(L_t\\) replaces the previous one. By iteratively evaluating and adjusting the learning path, this adaptive scheduling mechanism ensures alignment with learner's evolving needs."}, {"title": "4.3.3 Tailored Content Curation", "content": "To offer learners relevant, personalized learning content, GenMentor employs a content creator with an exploration-drafting-integration mechanism to curate materials, including documents and quizzes. To ensure accuracy and up-to-date information, the content creator integrates web search tools for retrieval-augmented generation (RAG). Specifically, for a given learning session \\(l_i\\), the content creator begins with the exploration to identify goal-related knowledge points across diverse perspectives. It then drafts content based on a systematic document outline considering the learner's preferences, and finally integrates feedback from the learner simulator to refine and finalize the learning material. This approach ensures that the content remains accurate and learner-focused, facilitating goal achievement.\nGoal-oriented Knowledge Exploration. Key knowledge points are identified to ensure the learning content is both comprehensive and aligned with the learner's goals. Guided by practical learning [28, 32], the content covers foundational concepts that provide the necessary background knowledge, practical insights that help bridge the gap between theoretical knowledge and real-world application, and problem-solving strategies that equip learners with techniques to address challenges, fostering critical thinking and adaptability. The content creator uses the session title as a query, to retrieve the latest information. Combining this up-to-date information with the inherent knowledge of the LLM, it identifies the relevant knowledge points and organizes them into a structured document outline. This outline, derived by \\(o_i = \\text{LLM}_{\\text{content-creator}}(U_t, \\triangle S_t, L_t, l_i)\\), serves as the foundation for subsequent drafting, ensuring that the content remains targeted, current, and aligned with the learner's objectives.\nRAG-based Section Drafting. When drafting content of each section, to mitigate common issues in direct LLM generation such as hallucinations and long-tail inaccuracies [11, 35], the content creator integrates high-quality retrieved information. It formulates queries by combining the session title and section titles to retrieve relevant and reliable data. This retrieved information is then re-customized to align with the learner's profile, ensuring the content is both informative and engaging. These section drafts, \\(d_i = \\text{LLM}_{\\text{content-creator}}(U_t, \\triangle S_t, L_t, l_i, o_i)\\), are tailored to match the learner's preference and progress, improving the personalization.\nIntegration and Refinement. The section drafts are synthesized into a cohesive document and then the learner simulator provides the mimicked feedback of learner and assesses logical structure and coherence. The content creator refines sections requiring improvement, ensuring each part aligns with the learner's needs. Once refined, these sections are seamlessly integrated into the final learning document. Quizzes are generated alongside the document to enhance learner engagement and test knowledge mastery. This process is denoted as \\(c_i = \\text{LLM}_{\\text{content-creator}}(U_t, \\triangle S_t, L_t, l_i, o_i, d_i)\\). This method further ensures the final content is logically organized and learner-tailored, promoting both comprehension and motivation."}, {"title": "5 EXPERIMENTS", "content": "To evaluate the effectiveness of GenMentor's output items, we conduct both LLM-based automated and human evaluations.\n5.1 Implementations and Settings\nWe implement GenMentor with two popular LLMs, GPT-40 (2024-08-06) [3] and Llama 3.2 [31] (3B). For the skill identifier, both two LLMs are fine-tuned in Azure AI Studio on our custom goal-to-skill dataset, using a batch size of 3, and a maximum of 10 epochs. content creator uses the Bing search tool to access the internet, retrieving up to 5 results per query to ensure concise and relevant"}, {"title": "5.2 LLM-based Automated Evaluation", "content": "Following prior works [12, 25, 38], we use GPT40 as an automated evaluator due to its strong alignment with human judgments. We adopt the 5-point Likert scale assessment to evaluate outputs.\n5.2.1 Overall Experiment Setup. We adopt a resume dataset 1 to represent diverse learner information and a subset of a job posting dataset to define target learning goals (excluded from the skill identifier model's training data). To construct the testing dataset, we randomly matched resumes with job postings to simulate the input information provided by learners and predefined goals. The testing dataset included five types of occupations, with a total of 200 samples. For each sample, we simulate a learner with a specific resume as learner information \\(S_0\\), aimed to acquire the skills required for a target job position G. We focus on three key output items: identified skills, learning path and learning content, measured by different metrics that impact on learning experience.\n5.2.2 Evaluating Goal-to-skill Mapping. We compare GenMentor with three approaches: (1) Direct Prompt (DirPrompt) and (2) CoT-Prompt, where the CoT reasoning is integrated into the prompt no or yes. Lastly, we include a variant of GenMentor, (3) w/o Tracks, which removes track-based guidance to assess its impact. All methods use the same learner information and learning goal as input. To evaluate the quality of goal-to-skill mapping, we regard the skill requirements extracted from job postings as ground truth and use LLM to measure three metrics: Recall, the proportion of identified skills out of ground truth, assessing the comprehensiveness; Precision, the necessity by calculating the proportion of correct skills among the generated outputs; and Goal Alignment, indicating how well the identified skills align with the given learning goal.\nAs shown in Table 1, GenMentor with GPT-40 outperforms all baselines across all metrics, achieving a Recall of 0.67, Precision of 0.63, and Goal Alignment of 4.28, demonstrating its ability to generate comprehensive, accurate, and goal-aligned skill mappings. The track-based guidance in GenMentor is useful in most metrics, as removing it reduces Goal Alignment to 4.05, highlighting the importance of structured guidance. While CoTPrompt, with its reasoning steps, performs better than DirPrompt, both baselines fall short of GenMentor, particularly in precision and alignment."}, {"title": "5.2.3 Evaluating Learning Path", "content": "To assess the quality of the learning path scheduled by GenMentor, we evaluate its effectiveness in two dimensions: Progression, which measures the logical flow and scalability of difficulty, and Engagement, which assesses the degree to which the path keeps learners motivated and interested. Higher scores on these metrics indicate better performance. We compare GenMentor with DirPrompt and CoTPrompt, introduced above. They are given the same learner profile \\(U_0\\) and skill gap \\(AS_0\\) initialized by GenMentor to schedule the learning path statically. As shown in Table 2, GenMentor achieves the highest scores across both metrics, outperforming the baselines in both Progression (4.56) and Engagement (4.71) with GPT-40, and 4.09 and 4.32 with Llama, respectively. CoTPrompt performs moderately well but remains below GenMentor, while DirPrompt shows significantly lower performance. It demonstrates that the use of CoT prompts notable benefits for this planning task requiring effective reasoning. Comparing CoTPrompt without mimicked feedback reveals, we observe that the learner simulator plays a crucial role in further enhancing the quality of the scheduled learning path. These results underscore the importance of incorporating CoT reasoning and mimicked feedback to optimize learning path scheduling."}, {"title": "5.2.4 Evaluating Learning Content", "content": "We compare GenMentor with three baselines: (1) DirGen, which generates content directly without structured guidance; (2) RAG, which incorporates RAG via the search tool; and (3) OutlineRAG, which first prepares a document outline and then drafts each section for integration. Additionally, we consider a variation of GenMentor for comparison: (4) w/o Refinement that skips the refinement step, using initial section drafts as the final document. To assess the quality of learning content generated by GenMentor, we evaluate its performance across four key dimensions: Goal Relevance, Content Quality, Engagement, and Personalization. Given the same initialized learner profile \\(U_p\\), skill gap \\(AS_0\\) and learning path \\(L_0\\) derived by GenMentor in the previous stage as input data, these methods produce a set of learning documents of each learning session.\nAs shown in Figure 4, GenMentor consistently outperforms the baselines across most metrics for both GPT-40 and LLaMA-based models, particularly excelling in Personalization. With GPT-40, GenMentor achieves notable scores in Personalization (4.17) and Content Quality (4.86), showcasing its ability to deliver high-quality content tailored to learners' preferences. While OutlineRAG and the w/o Refinement perform closely, they fall short in Personalization (3.79 and 3.85), indicating that the refinement step using mimicked learner feedback enhances customization. DirGen and RAG exhibit"}, {"title": "5.2.5 Human Validation on Automated Evaluation", "content": "To assess the quality of these results in automated evaluation, we compare automated scores with human grading on sampled results. The results show 5 out of 7 metrics exhibit a statistically significant positive correlation. Please see Appendix A.2 for details."}, {"title": "5.3 Human Preference Evaluation", "content": "To further evaluate the effectiveness of GenMentor, we conduct a pairwise human evaluation comparing it to strong baselines. For skill gap and learning path, the baseline method is CoTPrompt, while for learning content, the baseline used is OutlineRAG. The results are shown Table 5. We observe that GenMentor was more favored, showcasing its ability to produce high-quality outputs. See Appendix A.3 for detailed experimental setup and result analysis."}, {"title": "6 END-TO-END HUMAN STUDY", "content": "We have deployed GenMentor in practice and conducted the human study with professional learners for further evaluation.\n6.1 Practical Deployment\nWe have deployed GenMentor within our private product, the AIEP platform, launched in October 2024. AIEP is designed to empower employees with AI-driven tools to enhance productivity and streamline skill development. In AIEP, GenMentor supports critical functionalities, including learning path scheduling, resource generation, and learner modeling management, all integrated through API-based interactions. Additionally, we have implemented GenMentor as an independent web-based application tailored for goal-oriented learning and personalized tutoring. This application enables learners to engage in various educational activities for goal achievement, such as skill gap identification, scheduling learning paths, and personalized content delivery. The user-friendly interface facilitates a highly interactive learning experience, allowing learners to achieve their goals efficiently and effectively. This application also has been adopted by employees at Microsoft and partner vendor companies, demonstrating its practical value in enhancing professional development. Please see Appendix A.4 for details on the application.\n6.2 Human Study Procedure\nTo study GenMentor's practical effectiveness, we engaged 20 employees from diverse professional backgrounds, including 10 tech-related professionals (e.g., engineers, researchers) and 10 non-tech professionals (e.g., product managers, human resource specialists). Each participant had prior experience with our GenMentor application as well as traditional MOOC platforms and LLM-based chatbots (e.g., Microsoft Copilot, ChatGPT). The study included a questionnaire assessing output quality, learning efficiency, and user experience, followed by interviews to discuss GenMentor's strengths and limitations compared to existing tutoring systems.\n6.3 Questionnaire Findings\nResults are shown in the table 6 and our findings are as follows.\nClear learning guidance for goal achievement (\u2460\u2461). 18 participants agreed that the system effectively identifies skills aligned with their goals, resulting in a high rating of 4.6 \u00b1 0.8. The learning path offered by GenMentor was rated as 4.3 \u00b1 0.8, with participants noting that it breaks down learning objectives into manageable steps. One participant highlighted, \"The clear guidance made it easier to navigate addressing complex tasks and achieve goals.\"\nPersonalized and contextually relevant content (\u2462\u2463). GenMentor's personalized content was well-received, with participants rating the generated content as useful and personalized, scoring 4.2 \u00b1"}, {"title": "6.4 Interview and Discussion", "content": "To gain deeper insights into GenMentor's potential, we conduct interviews comparing it with existing learning platforms and tutors.\n6.4.1 Comparison with Traditional MOOCs. Compared to MOOC platforms, participants valued GenMentor for its ability to customize learning paths, narrow the learning focus, and enhance content personalization. 15 participants specifically highlighted its automated skill gap identification feature, which helps clarify learning needs and streamline content delivery. Additionally, the platform's dynamic content adjustment and progress tracking capabilities were praised for keeping learners engaged and facilitating efficient goal achievement (highlighted by 8 participants). Despite these strengths, participants suggested areas for improvement, such as incorporating more diverse and interactive content formats (noted by 13 participants) and enhancing the depth of subject matter (noted by 12 participants). Furthermore, Participants identified scenarios where GenMentor excels, such as providing personalized guidance for specific skill development (highlighted by 15 participants) (noted by 13 participants). While MOOCs offer broad-topic coverage through systematic general curricula, GenMentor's tailored and adaptive approach clearly outperforms MOOCs in scenarios requiring focused, goal-oriented learning.\n6.4.2 Comparison with Search-enhanced Chatbots. Participants identified GenMentor's key advantages over search-enhanced chatbots in providing personalized learning paths and interactive guidance for task-specific learning (highlighted by 17 participants). 13 participants praised its clear and structured learning progression, which uniquely aligns content with learners' goals. Unlike the generic and reactive responses of chatbots, GenMentor reduces proactively asking of learners and fostering focused learning, while dynamically adjusting its content based on real-time learner progress (noted by 9 participants). While GenMentor outperformed chatbots in goal-oriented learning experience, participants suggested improvements, such as adding more diverse multimedia resources (noted by 8 participants) and optimizing system responsiveness to enhance real-time interactions (noted by 7 participants). Participants found GenMentor particularly advantageous for scenarios like breaking down complex topics into manageable learning paths (noted by 16 participants). Although chatbots may excel in quick problem-solving, GenMentor's structured, goal-driven approach delivers a deeper, more interactive learning experience."}, {"title": "7 CONCLUSION", "content": "In this paper, we presented GenMentor, an LLM-powered multi-agent framework for goal-oriented learning in ITS, designed to deliver highly personalized, goal-oriented learning experiences. GenMentor advances beyond existing ITSs by proactively guiding learners efficiently toward their goals through accurate skill gap identification, adaptive learner profiling, and personalized resource delivery. Through extensive evaluations, including automated and human evaluation, GenMentor demonstrated superior performance in key outputs, including identifying skill gaps, aligning learning paths, and delivering tailored content. Real-world deployment and user studies further validated its effectiveness in fostering efficient and personalized learning in professional contexts. Overall, with its adaptive design and learner-centric approach, GenMentor showcases the transformative potential of LLMs in advancing personalized and goal-oriented education."}, {"title": "A APPENDIX", "content": "Due to page limitation, we provide supplementary resources at https://github.com/GeminiLight/gen-mentor in addition to the Appendix, including demo, prompts, data and more insights.\nA.1 Details on Goal-to-skill Dataset\nTo construct the goal-to-skill dataset, we use the LinkedIn job posting dataset from Kaggle\u00b2, which contains more than 0.12 million job postings across various positions. We filter the dataset based on the word count, retaining only postings with at least 500 words. This process results in a refined subset of 58,064 postings. From this subset, we randomly sample 10,000 postings to create the training dataset and 200 postings as the validation dataset, ensuring balanced representation across position types. For each sample,"}]}