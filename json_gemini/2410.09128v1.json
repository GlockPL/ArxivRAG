{"title": "TIGER: Temporally Improved Graph Entity Linker", "authors": ["Pengyu Zhang", "Congfeng Cao", "Paul Groth"], "abstract": "Knowledge graphs change over time, for example, when new entities are introduced or entity descriptions change. This impacts the performance of entity linking, a key task in many uses of knowledge graphs such as web search and recommendation. Specifically, entity linking models exhibit temporal degradation - their performance decreases the further a knowledge graph moves from its original state on which an entity linking model was trained. To tackle this challenge, we introduce TIGER: a Temporally Improved Graph Entity Linker. By incorporating structural information between entities into the model, we enhance the learned representation, making entities more distinguishable over time. The core idea is to integrate graph-based information into text-based information, from which both distinct and shared embeddings are based on an entity's feature and structural relationships and their interaction. Experiments on three datasets show that our model can effectively prevent temporal degradation, demonstrating a 16.24% performance boost over the state-of-the-art in a temporal setting when the time gap is one year and an improvement to 20.93% as the gap expands to three years. The code and data are made available at https://github.com/pengyu-zhang/TIGER-Temporally-Improved-Graph-Entity-Linker.", "sections": [{"title": "Introduction", "content": "A Knowledge Graph (KG) is a structured representation of facts, consisting of entities, relationships between them and their attributes [6]. KGs such as DBpedia [3], YAGO [16], and Wikidata [21], not only capture the relationships between entities but also contain rich textual attributes. These and other KGs play an important role in web applications such as recommendation systems [33] and question answering [11]. However, performance on the above applications is frequently limited by the ambiguity of entities mentioned in the text. For example, 'apple' could refer to a fruit or a multinational technology company.\nHence, the task of Entity Linking (EL) has emerged as a vital step in both producing and using KGs. EL aims to connect mentions of entities in text to their corresponding entities in a KG. Even though there are many works in EL, only a few consider the time aspect. In real-world scenarios, KGs evolve over time [18], existing entities (continual entities) may change their meanings over time due to societal development, and previously non-existent entities (new entities) may appear. For example, entity descriptions from Wikipedia constantly evolve (e.g., the most frequent meaning of the term 'corona' changed around 2020). New entities emerge (e.g., 'COVID-19' was"}, {"title": "Related Work", "content": "Entity Linking. Entity Linking (EL) sometimes called Wikification, is the connecting of mentions of entities in the text to a knowledge base and is a widely studied topic in NLP. We refer the reader to [12] for a detailed survey of the topic. Here, we focus on key challenges faced by current EL models. One of these challenges is linking textual mentions to unseen entities, known as zero-shot learning [7]. For instance, [26] introduces a conceptually two-stage, highly effective BERT-based zero-shot EL model called BLINK. [4] proposed a neuro-symbolic, multi-task learning approach to mitigate the problem of diminishing returns. They improved BLINK's performance with much less data by exploiting auxiliary information about entity types. To address the issue of an entity not being present in the knowledge base, NASTyLinker [5] clusters mentions and entities using dense representations from Transformers and, if multiple entities are assigned to a single cluster, it resolves conflicts by calculating transitive mention-entity affinities. Building on the idea of understanding intricate relationships between entities, [19] introduced a novel concept of representing entities in multi-dimensional spaces, which could further refine the EL process. Furthermore, [17] proposes a hierarchical multi-task model to extract ultra-fine type information that can help to learn contextual commonality and improve their generalization ability to tackle the overfitting problem. An additional challenge related to unseen entities is the problem addressed in this paper, temporal EL, where both unseen and changing entities must be linked [30].\nSeveral existing studies have sought to combine graph vectors with textual content to address the zero-shot problem. Among them, KG-ZESHEL [10] stands out for its innovative approach. Their approach lies in integrating graph vectors, which provide a route to combine textual and graph knowledge from knowledge graphs. This information fusion could enhance the model's ability to resolve ambiguities and improve EL accuracy. However, the study primarily focuses"}, {"title": "GNN-based Knowledge Graph Models", "content": "Graph Neural Networks (GNNs) integrate the topological and attribute information inherent in graph data through deep neural networks, thereby generating more refined node feature representations [28]. Recently, several studies have focused on using node features derived from graph representation learning in the context of knowledge graphs. For instance, the Contextualized Graph Attention Network (CGAT) [8] effectively leverages both local and non-local graph context information of KG entities. Essential entities for a target entity are extracted from the entire KG via a biased random walk, thereby incorporating non-local context within the KG. DSKREG [25] proposed learning the relevance distribution of associated items from knowledge graphs and sampling relevant items by this distribution to prevent the exponential growth of a node's receptive field. The work in [32] creates a dense, high-coverage semantic subgraph by linking question entity nodes to candidate entity nodes via text sentences from Wikipedia."}, {"title": "Temporal Degradation", "content": "Temporal change on the web has been well documented both for structured [1] and unstructured information [2]. However, temporal dependency in models is often overlooked. The common assumption is that once a model reaches the desired level of quality, it can be deployed without requiring further updates or retraining [20]. This assumption, however, may not hold true for tasks involving KGs, where entities evolve over time. The impact of temporal variation of KGs on model performance has been shown in several use cases ranging from online shopping [29] and internet of things [27]. The TempEL paper highlights the same need to address temporal degradation for EL, which we do here."}, {"title": "Task Formulation and Definition", "content": "Entity Linking (EL). The EL task takes a given text document D as input, which comprised of a list of tokens [w1,..., wr], where r indicates the document's length. Within this document, there exists a list of entity mentions MD containing n distinct elements [m1,..., mn], where each mention mi corresponds to a span of continuous tokens in D, represented as mi = D [x, y]. The model subsequently yields a list of mention-entity pairs {(mi, ei)}i\u2208[1,n]\u00b7 Every entity ei correlates with an entry within a comprehensive knowledge base (KB), such as Wikipedia. It is assumed that both the title and description of these entities are available, a standard premise in EL [9].\nGraph. A graph is defined as G = (V, E), where V is the set of N nodes (i.e., entities) {01, 02, , UN}. E is the set of M edges (i.e., relations) represented as {e1,2,\u2026, \u0435\u043c}, where each er is a pair of nodes from V, such as ei = (va, Ub). A graph is termed homogeneous when all its nodes and edges belong to the same type, where the number of node types is 1, and the number of edge types is also 1 [24]."}, {"title": "Dataset Construction", "content": "We combined the TempEL dataset, a benchmark for temporal EL, with Wikidata5M to explore the benefits of structured knowledge graphs. Our resultant dataset has five segments: two text-based (entity description and mention context) and three graph-based"}, {"title": "Approach", "content": "Figure 3 illustrates our model's framework. The core concept is combining text-based information (entity description, mention, and its context at t\u2081) with graph-based data (structure graph, feature graph, and feature matrix at t\u2081) during training. This integration not only enhances accuracy at t\u2081 but also at subsequent times like t2. For inference, the model solely relies on text-based information, including entity description, mention, and context.\nWe now walk through the framework. First, the bi-encoder module employs two separate BERT transformers to transform mention context and entity description into dense vectors ym and ye. Entity candidates are scored via the dot product of these vectors. We introduce Le to maximize the correct entity's score against randomly sampled entities.\nSecond, we input the pre-constructed structure graph, feature graph, and feature matrix into the Distinct and Shared Convolution Modules. Understanding the shared and unique features in both graphs, we use a shared-parameter strategy to derive common embeddings labeled as Zsr and Zsf. A consistency loss Ls is introduced to emphasize shared features. Meanwhile, distinction losses Ldr and Laf are used to retain the distinctiveness of Zr from Zsr and Zf from Zsf, respectively. Lastly, all loss functions are unified for joint optimization."}, {"title": "Bi-encoder Module", "content": "Mention Representation. Following [26], the mention representation Tm is constructed from word-pieces of the surrounding context and the mention:\n[CLS] ctxt1 [Ms] mention [Me] ctxt [SEP] (1)\nwhere ctxt, ctxt, denote word-pieces tokens before and after the mention, and [Ms], [Me] tag the mention. The input's maximum length is set to 128, consistent with the BLINK model.\nEntity Representation. The representation Te consists of word-pieces of the entity title and its description:\n[CLS] title [ENT] description [SEP] (2)\nwhere [ENT] separates the title and description.\nEncoding. Using the bi-encoder architecture from [26], we encode descriptions into vectors ye and ym:\nYm = red (T1 (Tm)) (3)\nYe = red (T2 (Te)) (4)\nHere, T\u2081 and T2 are transformers, and red(.) reduces the sequence of vectors into a single vector.\nScoring. Entity candidate scores are computed via dot-product:\ns (m, ei) = YmYei (5)"}, {"title": "Relation Convolution Module", "content": "We input the structure graph (from entity relationships), feature graph (from entity features), and feature matrix (based on token frequencies in entity descriptions) into the Distinct and Shared Convolution Modules.\nDistinct Convolution Module. We believe that our model can extract valuable insights from different entity relationships. By feeding the adjacency matrices Af and Ar based on entity structure and feature graphs into Distinct Convolution Modules, we obtain two specific embeddings Zf and Zr.\nUtilizing the pre-constructed feature matrix X and adjacency matrix Af that based on feature graph, the output of the l-th layer, Z), can be represented as:\nZ = ReLU ((DAD) Z) (6)\nwith W as the weight matrix for the l-th GCN layer, initial Z7(0) = X. Af = Af + If and Df is the diagonal degree matrix of Af. The final layer output is denoted as Zf. In this way, we can learn the entities embedding which captures the specific information Zf in feature space.\nSimilarly, using the adjacency matrix Ar that based on structure graph and feature matrix X, the output embedding Zr can be calculated in the same way as in feature graph.\nShared Convolution Module. The feature graph and structure graph are not entirely independent. In the Entity Linking (EL) task, entity feature may be correlated with the feature graph or in structure graph or both of them, which is difficult to know beforehand. Therefore, we not only need to extract the embedding in these two graph, but also to extract the shared information. To address this, we use Shared Convolution Module with parameter sharing strategy. Using GCN on the feature adjacency matrix Af, the embedding Zsf is:\nZ = ReLUD ((DAD) Z) (7)\nwith W as the l-th GCN layer weight matrix and initial Z7(0) = X. Similarly, using the adjacency matrix Ar that based on structure graph and feature matrix X, the output embedding Zsr can be calculated in the same way as in feature graph."}, {"title": "Objective Function", "content": "In order to achieve high EL accuracy, we use the EL loss function Le, distinct convolution loss function Lar and Laf, shared convolution loss function Ls.\nEL Loss Function Le. The objective is to train the network such that it maximizes the score of the correct entity compared to the other entities from the same batch. Specifically, for each training pair (mi, ei) within a batch of N pairs, the loss is given by:\nLe (Mi, Ci) = -s (mi, ei) + log exp (s (mi, ej)) (8)\nj=1\nShared Convolution Loss Function Ls. Given the output embeddings Zsr and Zsf from the GCN with shared weight matrices, the aim is to capture the similarity across n entities. The shared convolution loss ensures that the similarity matrices for both embeddings are consistent, resulting in the following constraint:\n||Zsr - Zsf||2 (9)"}, {"title": "Distinct Convolution Loss Functions Lar and Laf", "content": "To ensure the embeddings Zr and Zsr, derived from the same adjacency matrix Ar, capture distinct information, we employ the Hilbert-Schmidt Independence Criterion (HSIC) [14]. The HSIC measure is defined as:\nHSIC (Zr, Zsr) = (n \u2212 1)\u00af2tr (RK&RKsr), (10)\nwhere Ks and Ksr are the Gram matrices, with entries krij = kr (zr, zi) and ksr,ij = ksr (zor, zsr). Matrix R = I - ee, where I is the identity matrix and e is an all-ones column vector. An inner product kernel function computes KrKsr.\nThe same HSIC measure enhances the disparity between embeddings Zf and Zsf from same adjacency matrix Af:\nHSIC (Zf, Zsf) = (n \u2212 1)\u00af\u00b2tr (RK&RKsf), (11)\nThus, the distinct convolution loss La is:\nLd = Ldr + Ldf = HSIC (Zr, Zsr) + HSIC (Zf, Zsf). (12)\nOverall Objective Function. The overall objective function, combining EL and convolution losses, is given by:\nL = Le+aLs + bLd (13)\nwhere a and b are weights for the shared and distinct convolution losses, respectively."}, {"title": "Evaluation", "content": "This section evaluates the proposed model and presents its performance on three datasets. The implementation of our approach is based on the original codebase BLINK\u00b3 [26] and AM-GCN\u2074 [22]. We compare our approach to the BLINK and SpEL5 [13] model. We selected BLINK and SpEL as baselines because of their relevance and performance benchmarks in the field. BLINK has excellent scalability and serves as part of our model's codebase. SpEL, the latest state-of-the-art as of 2023, provides a current standard for evaluating our model's improvements. Experimental details can be found in [31]"}, {"title": "Datasets", "content": "Our proposed model is evaluated on three datasets which are summarized in Table 1."}, {"title": "Training Details", "content": "We reuse the same hyperparameter settings from [26] and the same bert_uncased_L-8_H-512_A-8 pre-trained model to train the bi-encoder. The recall@N is used as the evaluation metric, where N equals 1, 2, 4, 8, 16, 32, and 64, respectively. If the correct answer appears within the top N predictions of the model, it is considered a correct prediction. The bi-encoder is trained on the ZESHEL dataset across five epochs, utilizing 128 mentions and 128 entity tokens at a learning rate 1e-05. Conversely, the bi-encoder undergoes training for one epoch on our dataset, maintaining similar mention and entity token quantities and learning rates. The training process employs an annual training approach and tests on all test sets. More details are provided in the supplementary material [31]."}, {"title": "Main Results", "content": "Table 2 illuminates the effectiveness of our model in mitigating temporal degradation using results derived from the Graph-TempEL dataset. Here, we use continual entities and new entities as the training set. Each column in the table represents the years' gap between the training and testing datasets, as denoted by the digits from 0 to 3. For instance, 0 implies that training and testing datasets come from the same year, while 3 indicates that the model was trained in 2019 and tested in 2022. The rows are divided based on various metrics: @1 to @64. 'Boost' displays a comparison be- Our Model's Result-Baseline Model's Result\ntween our model TIGER and SpEL model, calculated as Boost =\nBaseline Model's Result"}, {"title": "Qualitative Comparison", "content": "Our model excels at accurately predicting ambiguous samples where the context is unclear or multiple interpretations exist. For example, when analyzing political events with multiple actors, our model accurately determines the correct association. In the passage\n\"... Sarah Huckabee Sanders and attorney general Leslie Rutledge announced campaigns California governor Gavin Newsom was elected in 2018 with 61.9% of the vote and is running for reelection for a second term. On September 14 2021 a recall election was held.\"\nOur model correctly associates the mention \"recall election\" with the 2021 CALIFORNIA GUBERNATORIAL RECALL ELECTION entity, whereas the BLINK instead links to the 2021 OHIO 15TH CONGRESSIONAL DISTRICT SPECIAL ELECTION.\nAdditionally, we observed that our model exhibits a higher prediction accuracy for samples related to temporal aspects.\nFor example, in the passage:\n\"Dundalk entered the 2021 season as the FAI Cup holders, and were still the League of Ireland Cup holders from 2019...\"\nour model correctly identified the mention \"FAI Cup\" as referring to the 2021 FAI CUP entity whereas the BLINK linked to the 2009-10 IN SCOTTISH FOOTBALL entity."}, {"title": "Conclusion and Future Work", "content": "This paper introduces TIGER, a Temporally Improved Graph Entity Linker, to address temporal degradation. By adaptively combining the distinct and shared features between different entity relationships, the model is able to ensure that the semantic differences between different entities remain intact and do not diminish over time. We expanded the TempEL dataset by incorporating yearly entity relationships from the Wikidata5M dataset, creating Graph-TempEL, which enhances its suitability for studying temporal degradation. The dataset provides four yearly snapshots from 2019 to 2022. Each snapshot features entity descriptions, mention contexts, structure and feature graphs, and an entity feature matrix. Experiments on Graph-TempEL dataset show that our model can effectively prevent temporal degradation, demonstrating a 16.24% performance boost over the state-of-the-art in a temporal setting when the time gap is one year and an improvement to 20.93% as the gap expands to three years. Going forward, we see a few areas of future work:\nContrastive Learning. Contrastive learning has been extensively applied to graph neural networks in recent research, yet its application to temporal datasets remains limited. When a dataset contains snapshots from different years, some entities will likely appear in multiple snapshots. If certain relationships between entities repeatedly occur in various snapshots, these entity pairs can be assumed to have stronger connections. Such pairs can then serve as high-quality positive samples. Conversely, entity pairs that had relationships that subsequently disappeared can serve as negative samples. With these high-quality positive and negative samples, the model's performance can potentially be improved under unsupervised conditions.\nMultilingual Entity Linking. Despite language differences, relationships may share similarities, allowing for multilingual entity linking. While existing methods like [15] concentrate on multilingual aligned embedding and community detection in graphs, there is limited research addressing the issue of temporal degradation in multilingual contexts. Our work is currently limited to English, with low-resource datasets not covered. If multilingual entity descriptions and entity relationships exist at time t1, the model could benefit from these diverse language resources, thereby further improving the accuracy at time t2 and better preventing temporal degradation."}]}