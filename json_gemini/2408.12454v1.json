{"title": "Relaxed Rotational Equivariance via G-Biases in Vision", "authors": ["Zhiqiang Wu", "Licheng Sun", "Yingjie Liu", "Jian Yang", "Hanlin Dong", "Shing-Ho J. Lin", "Xuan Tang", "Jinpeng Mi", "Bo Jin", "Xian Wei"], "abstract": "Group Equivariant Convolution (GConv) can effectively handle rotational symmetry data. They assume uniform and strict rotational symmetry across all features, as the transformations under the specific group. However, real-world data rarely conforms to strict rotational symmetry commonly referred to as Rotational Symmetry-Breaking in the system or dataset, making GConv unable to adapt effectively to this phenomenon. Motivated by this, we propose a simple but highly effective method to address this problem, which utilizes a set of learnable biases called the G-Biases under the group order to break strict group constraints and achieve Relaxed Rotational Equivarant Convolution (RREConv). We conduct extensive experiments to validate Relaxed Rotational Equivariance on rotational symmetry groups $C_n$ (e.g. $C_2$, $C_4$, and $C_6$ groups). Further experiments demonstrate that our proposed RREConv-based methods achieve excellent performance, compared to existing GConv-based methods in classification and detection tasks on natural image datasets.", "sections": [{"title": "Introduction", "content": "Symmetry prior such as equivariance plays a vital role in deep learning (Bogatskiy et al. 2022; He et al. 2021; Esteves 2020; Ravanbakhsh, Schneider, and Poczos 2017). Given the assumption of perfect symmetry in data, recent works on equivariant networks are constrained to operate as strict equivariant or invariant functions. They have been shown to learn inherent symmetry information without additional data, achieving excellent results with improved efficiency and generalization ability (Cohen and Welling 2016a,b; Kondor and Trivedi 2018; Ghosh et al. 2022; Kaba et al. 2023; Kaba and Ravanbakhsh 2024).\nHowever, real-world physical systems seldom adhere to perfect symmetry due to the influence of external factors, a phenomenon commonly termed Symmetry-Breaking (Wang, Walters, and Yu 2022; Barone and Theophilou 2008; Wang et al. 2024; Vernizzi and Wheater 2002; Ghosh et al. 2022; Kaba and Ravanbakhsh 2024). We observed Symmetry-Breaking occurrences within the visual domain.\nIn this paper, we mainly focus on rotational symmetry and explore the rotational Symmetry-Breaking based on GConv (Cohen and Welling 2016a) on the rotation group $C_n$ in computer vision. Therefore, by rethinking the construction process and principles of GConv, we found that under strict group G transformations (G-transformations), each G-transformation convolution filter shares the same copy value, differing only in their positions. This is the key to GConv's strict equivariance. For example, in the $C_4$ group, GConv cannot effectively model objects or scenes with rotations other than 90, 180, and 270 degrees. Therefore, we focus on how to relax the strict G-transformation convolution filter value-sharing problem to adapt to rotational Symmetry-Breaking.\nInspired by convolution biases, we introduce a set of learnable biases under the group order to add to the G trans-formation convolution filter. We referred to these biases as G-Biases, and these GConv on the rotation groups $C_4$ with G-Biases as Relaxed Rotational Equivarant Convolution (RREConv). The rotational equivariance of GConv is called Strict Rotational Equivariance (SRE), and for RREConv, it is called Relaxed Rotational Equivariance (RRE) in our paper. The difference between GConv and RREConv filters can"}, {"title": "Related works", "content": "Strict Rotational Equivariance (SRE). Strict Rotational Equivariance is critical for neural networks handling rotated data, especially in computer vision tasks involving 2D images and 3D objects (Marcos, Volpi, and Tuia 2016). As demonstrated by the pioneering work (Cohen and Welling 2016a), introducing group equivariance into traditional CNNs led to the development of novel G-CNNs. Foundational networks such as (Li et al. 2018; Marcos et al. 2017; Chidester, Do, and Ma 2018; Weiler and Cesa 2021), have achieved notable success in exploring the rotational equivariance of images. In (Veeling et al. 2018; M\u00fcller et al. 2021), the application of rotational equivariance in medicine has achieved excellent performance due to the frequent presence of rotational equivariance in medical data. Moreover, rotational equivariance is also prevalent in 2D object detection. For instance, ReDet (Han et al. 2021) introduces rotational equivariance into aerial object detection. MORE-Net (Zhu et al. 2022) proposes the multi-oriented ground objects detector to extract rotation-invariant semantic representations. In addition, EquiSym (Seo et al. 2022) outputs group equivariant score maps for rotational centers through end-to-end rotational equivariant feature maps. Rotational equivariance has also seen significant advancements in 3D vision. In\nRelaxed Rotational Equivariance (RRE). However, the methods of SRE mentioned above make them poorly suited for handling rotational Symmetry-Breaking in both 2D and 3D fields, as they assume that the data exhibits perfect rotational symmetry, which is rarely the case in real-world scenarios (Wu, Hu, and Kong 2015; Dieleman, De Fauw, and Kavukcuoglu 2016; Kavukcuoglu et al. 2009). In contrast, explorations into RRE reveal a significant gap in the current research. While SRE models are effective under ideal conditions, they fall short when dealing with the more common, imperfect symmetries in the real world. In some theoretical works (Kaba and Ravanbakhsh 2024; Kaba et al. 2023), they meticulously analyze the importance and potential application scenarios of relaxed equivariance. Partial rotational equivariance, as highlighted in (Romero and Lohit 2023), is more effective for representing real-world data compared to full rotational equivariance. Similarly, (van der Ouderaa, Romero, and van der Wilk 2022) emphasizes that equivariance constraints can be overly restrictive. (Wang et al. 2024) explores the relaxed equivariance of physical systems. These methods confirm that relaxed equivariance (e.g., especially RRE) is more suitable for real-world scenarios.\nRotational Symmetry and Symmetry-Breaking. Rotational symmetry (Li, Nagano, and Terashi 2024), a fundamental concept in natural systems, pertains to objects or patterns that retain their appearance when rotated by specific angles (Barone and Theophilou 2008). Though prevalent in theoretical models, this pristine form of symmetry is often disrupted in real-world scenarios, a phenomenon referred to as rotational Symmetry-Breaking (Vernizzi and Wheater 2002). Recent progress in understanding these deviations has spurred the creation of new methodologies aimed at tackling Symmetry-Breaking challenges. For instance, methodologies suggested by (Desai, Nachman, and Thaler 2022) propose techniques to integrate Symmetry-Breaking elements into models, enhancing their performance in tasks such as data mining and analysis. However, most researchers focus on rotational symmetry and often overlook the phenomenon of rotational Symmetry-Breaking. Therefore, this paper primarily focuses on addressing the phenomenon of rotational Symmetry-Breaking."}, {"title": "Preliminary", "content": "Definition of Strict Equivariance. Assume that an input group representation $\u03c6_x$ of G acts on X and an output group"}, {"title": "Group Equivariant Convolution", "content": "Group Equivariant Convolution (GConv) achieves equivariant inductive bias by sharing weights through convolution filters under group transformations. In a special case, CNNs achieve translational equivariance through translational transformations on the plane $Z^2$.\nIn the beginning, define a group operator $G(\u03b8)$ performs the G-transformations in the last two dimensions and cyclical permutations in the input channel dimension for $\u03b8$, and the symbol [...] denotes the Pytorch style index operation. For convenience, we also define $C_l$, $k_l$, $h_l$, and $w_l$ denote the channel number, kernel (or filter) size, width, and height of the 2D input (or the output) in the l-layer, respectively. These definitions are used in the following text.\nRegular Convolution. Assume the input $Y_l$ of size $[C_l, h_l, w_l]$ on the plane $Z^2$, and the convolution filter $F_l^{Z^2}$"}, {"title": "Relaxed Rotational Equivariant Filter", "content": "The construction of the Relaxed Rotational Equivariant Filter (RREF) is the key to our method. Assume an initial weight $W_l^F$ of size $[C_{l+1}, C_l, G_l, k_l, k_l]$ with Kaiming distribution on the group G in the l-layer, where G = $C_n$, and $G_l = n$ for our RRE especially. Define a set of affine matrices A = {$A_i$ | i \u2208 {0,1,\u2026\u2026, n \u2212 1}} for the G-transformation, where\nBefore G-transformation for coordinates, assume the coordinate system is at the center of 2D plane, and define a function CoorSet(0) to obtain the set of all coordinates of 0. For all $u \u2208 [1, C_{l+1}], m \u2208 [1, C_l], n \u2208 [1, G_l], 2D coordinate pair (x, y) \u2208 CoorSet($W_l^F$[u, m, n, :, :]), we can obtain new 2D coordinate pair ($x_i$, $y_i$) after G-transformation for coordinates on $W_l^F$ as follows:\nNow, we can obtain the strict rotational equivariant i-filter at group order i on G as follows:\nif ($x_i$, $y_i$) \u2208 CoorSet($F_{G;i}^l$[u, m, n, :,:]). Note that some out-of-bounds coordinates of $F_{G;i}^l$ may occur in some groups (e.g. $C_6$, and $C_8$) except $C_2$ and $C_4$. Based on this reason, some coordinates remain unassigned after the G-transformation from $W_l^F$. For these coordinates, we employ Bilinear Interpolation. For our RREF, we introduce a set of learnable G-biases $B_G$ = {$B_{G;i}^l$ | i \u2208 {0,1,\u2026,n \u2212 1}},\nwhere the size of $B_{G;i}^l$ is [$C_{l+1}$, 1, 1, $k_l$, $k_l$], with Zero distribution in the l-layer. Note that $B_{G;i}^l$ can be updated end-to-end during the training period to adapt the Symmetry-Breaking in the dataset. Therefore, the final values of $B_{G;i}^l$ in l-layer are"}, {"title": "Relaxed Rotational Lift Convolution", "content": "Assume the input $X_1$ of size [$C_1$, $h_1$, $w_1$] on the plane $Z^2$ in the first layer. Similar to the lift convolution in equation (4), for all u \u2208 [1, $C_2$], Relaxed Rotational Lift Convolution (RRLConv) can be performed by convolving over the input channel $C_1$, and summing up the outputs as follows:\nNote that, the constructions of $R_l^F$ and $F_G^l$ for l > 2 are the same, with $R_l^F$ being slightly different in that it has no extra input dimension $G_l$."}, {"title": "Relaxed Rotational Equivariant Convolution", "content": "Also, assume the input $X_i$ of size [$C_{l+1}$, $C_l$, $G_l$, $h_l$, $w_l$] in the l-layer (l \u2265 2) on the group G, i.e., the group $C_n$. Similar to the group convolution in equation (5), for all \u03ba \u2208 [1, $C_{l+1}$], v \u2208 [1, $G_{l+1}$], RREConv can be performed by convolving over the input channel $C_l$ and the input group dimension $G_l$, and summing up the outputs as follows:"}, {"title": "Model Architecture", "content": "Based on our RREConv, we propose a Relaxed Rotational Equivariance Network (RRENet). Considering the significant computational and parameter overhead caused by the additional G dimension, we redesign the point-wise and depth-wise versions of our RREConv. We typically adopt the classic structure of ResNet (He et al. 2016), where each PD RREBlock consists of two Point-wise RRECBAS adjusting the input and output channels, with two PD RRECBAs in between, and residual connections are used, as shown in Figure 4. We also propose a Relaxed Rotational Equivariance Detetor (RREDet). We use RREDet as a backbone to obtain three scale features in 2-layer, 3-layer, 4-layer, and the FPN+PAN architecture as the neck layer to obtain the final three scale features of size 80 x 80, 40 x 40, and 20 \u00d7 20 for different-size object detection. Note that, the feature maps in 4-layer are firstly input to the G-SPPF for Spatial Pyramid Pooling (He et al. 2014). Then these features are fed into the G-Max Pooling. Finally, the obtained features are as inputs for the YOLOv8 detector, as shown in Figure 5. Here, the size of the input is 640 \u00d7 640."}, {"title": "Experiments", "content": "In this section, we conduct extensive ablation experiments to demonstrate the effectiveness of our proposed RREConv in both classification and object detection tasks. All the parameters are set the same, and all the experiments are conducted on dual RTX-4090 GPU. We evaluate our method on the CIFAR10/100 datasets for the classification tasks, and the PASCAL VOC07+12 and MS COCO 2017 datasets for the\nDatasets\nCIFAR10/100. The CIFAR-10 dataset consists of 60,000 color images in 10 classes (6000 images per class), with 50,000 for training and 10,000 for testing. CIFAR-100 is similar but with 100 classes (600 images per class) organized into 20 superclasses. We perform classification ablation experiments on these two datasets.\nPASCAL VOC07+12. The PASCAL VOC07 dataset has 5,000 training images with annotations for over 12,000 objects. Its successor, VOC12, offers 11,000 training images with annotations for approximately 27,000 objects across 20 object classes. Our ablation experiments focus on the combined VOC 07+12 dataset for 2D object detection.\nMS COCO 2017. The MS COCO 2017 dataset comprises 330K images, with annotations for object detection, segmentation, and tracking in 200K images. Spanning 80 categories like cars, animals, and specific items like umbrellas and sports gear, our experiments verify our method's generalizability on this diverse dataset.\nTraining Details\nData Augmentation. We adopted the same settings as YOLOv8, mainly including Mosaic, Mixup, random perspective, and HSV augmentations.\nParameter Setting. All models are trained for 200 epochs with resized size 224 \u00d7 224 for classification tasks, and 300 epochs with resized size 640 \u00d7 640 for 2D object detection tasks. For both tasks, we use an SGD optimizer with an initial learning rate (lr) of 0.01 and momentum of 0.9.\nExperimental Results\nAblation Experiments in Classification. To evaluate the effectiveness of our proposed RREConv, we conduct extensive ablation experiments on the CIFAR10 / 100 datasets,"}, {"title": "Conclusion", "content": "In this paper, we delve into the realm of rotational equivariant networks employed for modeling natural datasets, showcasing their superior performance in leveraging 2D or 3D rotation groups. Despite their advancements, existing rotational equivariant networks operate under the assumption of a strict uniform rotational symmetry prevalent across all features. However, the reality of natural datasets unveils a different story, where data seldom adheres to strict rotational symmetry but rather aligns with a relaxed rotational symmetry pattern, characterized by rotational Symmetry-Breaking. This inability to effectively accommodate rotational Symmetry-Breaking scenarios, particularly within natural datasets, necessitates a novel approach. To tackle this challenge, we introduce a simple yet powerful method involving a collection of adaptable G-Biases. Utilizing this innovative mechanism, we put forth the concept of Relaxed Rotational Equivarant Convolution (RREConv), tailored to address the nuances of relaxed rotational symmetry. Building upon our RREConv framework, we present RRENet, designed for classification tasks, and RREDet, optimized for 2D object detection missions. Through rigorous experimentation, our results unequivocally demonstrate the efficacy of our approach when applied to vision tasks involving natural datasets. Exploring symmetry breaking with rotational equivariance, both within the realms of 2D and 3D fields represents a compelling avenue for future research. We firmly believe that incorporating this relaxation principle into models improves their ability to accurately represent symmetry-breaking phenomena in real-world contexts."}, {"title": "Additional Experiments", "content": "RotMNIST. We conduct experiments on the RotMNIST dataset to validate the robustness of our RRENet, as detailed in Table 1. From the table, it can be seen that the top-1 accuracy of our RRENet-n (C8) is almost close to 1.\nCIFAR-10/100. We conduct experiments on the CIFAR-10/100 test dataset based on the YOLOv8-n-cls architecture. We replaced all regular convolutions in the YOLOv8-n-cls\nPASCAL VOC07+12. We conduct ablation experiments on the PASCAL VOC07+12 test dataset based on the YOLOv8-n architecture. We replaced all regular convolutions in the YOLOv8-n-cls architecture with our PD RREConv, using RRLConv in the first layer and G-Max Pooling in the last layer. In Table 3, the models with RRE outperform those with SRE in both $AP^{test}_{50}$ and $AP^{test}_{50:95}$, which once again proves the effectiveness of our RRE in 2D object detection tasks."}]}