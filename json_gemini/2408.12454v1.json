{"title": "Relaxed Rotational Equivariance via G-Biases in Vision", "authors": ["Zhiqiang Wu", "Licheng Sun", "Yingjie Liu", "Jian Yang", "Hanlin Dong", "Shing-Ho J. Lin", "Xuan Tang", "Jinpeng Mi", "Bo Jin", "Xian Wei"], "abstract": "Group Equivariant Convolution (GConv) can effectively han-dle rotational symmetry data. They assume uniform and strictrotational symmetry across all features, as the transformations under the specific group. However, real-world datararely conforms to strict rotational symmetry commonly re-ferred to as Rotational Symmetry-Breaking in the system ordataset, making GConv unable to adapt effectively to thisphenomenon. Motivated by this, we propose a simple buthighly effective method to address this problem, which uti-lizes a set of learnable biases called the G-Biases under thegroup order to break strict group constraints and achieveRelaxed Rotational Equivarant Convolution (RREConv). Weconduct extensive experiments to validate Relaxed RotationalEquivariance on rotational symmetry groups Cn (e.g. C2, C4,and C6 groups). Further experiments demonstrate that ouroposed RREConv-based methods achieve excellent perfor-mance, compared to existing GConv-based methods in clas-sification and detection tasks on natural image datasets.", "sections": [{"title": "Introduction", "content": "Symmetry prior such as equivariance plays a vital role indeep learning (Bogatskiy et al. 2022; He et al. 2021; Esteves2020; Ravanbakhsh, Schneider, and Poczos 2017). Giventhe assumption of perfect symmetry in data, recent workson equivariant networks are constrained to operate as strictequivariant or invariant functions. They have been shownto learn inherent symmetry information without additionaldata, achieving excellent results with improved efficiencyand generalization ability (Cohen and Welling 2016a,b;Kondor and Trivedi 2018; Ghosh et al. 2022; Kaba et al.2023; Kaba and Ravanbakhsh 2024).\nHowever, real-world physical systems seldom adhere toperfect symmetry due to the influence of external fac-tors, a phenomenon commonly termed Symmetry-Breaking(Wang, Walters, and Yu 2022; Barone and Theophilou2008; Wang et al. 2024; Vernizzi and Wheater 2002; Ghoshet al. 2022; Kaba and Ravanbakhsh 2024). We observedSymmetry-Breaking occurrences within the visual domain.A common example can be seen in Figure 1. In (a), a carturns by 90 degrees, which can be challenging to achieveprecisely in practical situations. Conversely, in (b), a carturns by less than 90 degrees, often with a slightly random-ized angle change, reflecting a more realistic depiction of acar's turning motion in real-world settings. Strict rotationalsymmetry constraints significantly impede equivariant net-works from accurately modeling real-world physical scenar-ios and performing visual perception.\nIn this paper, we mainly focus on rotational symmetryand explore the rotational Symmetry-Breaking based onGConv (Cohen and Welling 2016a) on the rotation group Cnin computer vision. Therefore, by rethinking the construc-tion process and principles of GConv, we found that understrict group G transformations (G-transformations), each G-transformation convolution filter shares the same copy value,differing only in their positions. This is the key to GConv'sstrict equivariance. For example, in the C4 group, GConvcannot effectively model objects or scenes with rotationsother than 90, 180, and 270 degrees. Therefore, we focuson how to relax the strict G-transformation convolution fil-ter value-sharing problem to adapt to rotational Symmetry-Breaking.\nInspired by convolution biases, we introduce a set oflearnable biases under the group order to add to the G trans-formation convolution filter. We referred to these biases asG-Biases, and these GConv on the rotation groups C4 withG-Biases as Relaxed Rotational Equivarant Convolution(RREConv). The rotational equivariance of GConv is calledStrict Rotational Equivariance (SRE), and for RREConv, itis called Relaxed Rotational Equivariance (RRE) in our pa-per. The difference between GConv and RREConv filters can"}, {"title": "Related works", "content": "Strict Rotational Equivariance (SRE). Strict RotationalEquivariance is critical for neural networks handling ro-tated data, especially in computer vision tasks involv-ing 2D images and 3D objects (Marcos, Volpi, and Tuia2016). As demonstrated by the pioneering work (Cohen andWelling 2016a), introducing group equivariance into tra-ditional CNNs led to the development of novel G-CNNs.Foundational networks such as (Li et al. 2018; Marcos et al.2017; Chidester, Do, and Ma 2018; Weiler and Cesa 2021),have achieved notable success in exploring the rotationalequivariance of images. In (Veeling et al. 2018; M\u00fcller et al.2021), the application of rotational equivariance in medicinehas achieved excellent performance due to the frequent pres-ence of rotational equivariance in medical data. Moreover,rotational equivariance is also prevalent in 2D object detec-tion. For instance, ReDet (Han et al. 2021) introduces rota-tional equivariance into aerial object detection. MORE-Net(Zhu et al. 2022) proposes the multi-oriented ground ob-jects detector to extract rotation-invariant semantic represen-tations. In addition, EquiSym (Seo et al. 2022) outputs groupequivariant score maps for rotational centers through end-to-end rotational equivariant feature maps. Rotational equivari-ance has also seen significant advancements in 3D vision. In\nRelaxed Rotational Equivariance (RRE). However, themethods of SRE mentioned above make them poorly suitedfor handling rotational Symmetry-Breaking in both 2D and3D fields, as they assume that the data exhibits perfect rota-tional symmetry, which is rarely the case in real-world sce-narios (Wu, Hu, and Kong 2015; Dieleman, De Fauw, andKavukcuoglu 2016; Kavukcuoglu et al. 2009). In contrast,explorations into RRE reveal a significant gap in the currentresearch. While SRE models are effective under ideal con-ditions, they fall short when dealing with the more common,imperfect symmetries in the real world. In some theoreti-cal works (Kaba and Ravanbakhsh 2024; Kaba et al. 2023),they meticulously analyze the importance and potential ap-plication scenarios of relaxed equivariance. Partial rotationalequivariance, as highlighted in (Romero and Lohit 2023),is more effective for representing real-world data comparedto full rotational equivariance. Similarly, (van der Ouderaa,Romero, and van der Wilk 2022) emphasizes that equivari-ance constraints can be overly restrictive. (Wang et al. 2024)explores the relaxed equivariance of physical systems. Thesemethods confirm that relaxed equivariance (e.g., especiallyRRE) is more suitable for real-world scenarios.\nRotational Symmetry and Symmetry-Breaking. Rotational symmetry (Li, Nagano, and Terashi 2024), a funda-mental concept in natural systems, pertains to objects orpatterns that retain their appearance when rotated by spe-cific angles (Barone and Theophilou 2008). Though preva-lent in theoretical models, this pristine form of symmetryis often disrupted in real-world scenarios, a phenomenonreferred to as rotational Symmetry-Breaking (Vernizzi andWheater 2002). Recent progress in understanding these de-viations has spurred the creation of new methodologiesaimed at tackling Symmetry-Breaking challenges. For in-stance, methodologies suggested by (Desai, Nachman, andThaler 2022) propose techniques to integrate Symmetry-Breaking elements into models, enhancing their perfor-mance in tasks such as data mining and analysis. How-ever, most researchers focus on rotational symmetry andoften overlook the phenomenon of rotational Symmetry-Breaking. Therefore, this paper primarily focuses on ad-dressing the phenomenon of rotational Symmetry-Breaking."}, {"title": "Preliminary", "content": "Definition of Strict Equivariance. Assume that an inputgroup representation 6x of G acts on X and an output group"}, {"title": "Group Equivariant Convolution", "content": "Group Equivariant Convolution (GConv) achieves equiv-ariant inductive bias by sharing weights through convolu-tion filters under group transformations. In a special case,CNNs achieve translational equivariance through transla-tional transformations on the plane Z2.\nIn the beginning, define a group operator G(0) performs the G-transformations in the last two dimensions and cycli-cal permutations in the input channel dimension for o, andthe symbol [...] denotes the Pytorch style index operation.For convenience, we also define C\u0131, k\u0131, h\u0131, and wr denote the channel number, kernel (or filter) size, width, and heightof the 2D input (or the output) in the l-layer, respectively.These definitions are used in the following text.\nRegular Convolution. Assume the input Yi of size[Ci, hi, wi] on the plane Z2, and the convolution filter FZ2of size [C1+1, C\u0131, k\u0131, k\u0131]. For all u \u2208 [1, C1+1], a regular con-volution in the l-layer can be performed by convolving overthe input channel C\u012e and summing up the outputs as follows:\n\nV1+1[4, :, :] = \u2211\u03bd\u03b9[m, :, :] * F\u013e\u00b2 [u, m, :, :], (3)\nm\nwith the size of Yi+1 is [Cl+1, hi+1, wi+1], in which Cl+1,hi+1 and wi+1 denote the output channel number, height andwidth in the l-layer (or the input channel number, height andwidth in the {l + 1}-layer), respectively. And the operator *\ndenotes convolution operation.\nLift Convolution. The first layer of G-CNNs typicallylifts the input on the plane Z2 to the group G. Assume theinput Y\u2081 of size [C1, h1, w1] and the initial weight W\u00b2 withKaiming distribution of size [C2, C1, k1, k1] on the plane Z2in the first layer. Therefore, we obtain the full lift convolu-tion filter FG = IG(W\u00b2\u00b2) of size [C2, G2, C1, k1, k1] thatcontains an additional dimension G2 for the output group.Note that FF is constructed from W\u00b2\u00b2 during each forwardfunction. For all u \u2208 [1, C2], v \u2208 [1, G2], a lift convolutioncan be performed by convolving over the input channel C1and summing up the outputs as follows:\n\n\u04232[u, v, :, :] = \u2211 V1 [m, :, :] * F\u00a3[u, v, m, :,:], (4)\nm\nwith the size of the output V2 is [C2, G2, h2, W2].\nGroup Convolution. Unlike the input on the plane Z2,GConv typically encodes the added group G in an extratensor dimension. Therefore, assume the input Vi of size[Ci, Gi, h, w] on the group G, where Gi denotes the di-mension of G in the l-layer (l > 2), and the initial weightW with Kaiming distribution of size [C1+1, C\u0131, G\u0131, k\u0131, k\u0131]contains an additional dimension Gi for the input group.Then, we obtain the full group convolution filter FG =G(WF) of size [C1+1, G1+1, C\u0131, G\u0131, k\u0131, k\u0131] containing anadditional dimension G1+1 for the output group. For allu \u2208 [1, C1+1], v \u2208 [1, Gi+1], a group convolution can beperformed by convolving over the input channel Ci and in-put group dimension G\u0131, and summing up the outputs as fol-lows:\n\nV1+1[4, \u03c5, :, :] = \u03a3\u03a3\u03bd\u03b9[m, n :,:] * FF [u, v, m, n, :, :], (5)\nm n\nwith the size of the output Vi+1 is [Cl+1, G1+1, hi+1, Wi+1].Since the group convolution is the function f:G\u2192G,we have Gl+1 = G\u0131 = Dim(G), where Dim(G) is thedimensions of G (e.g, 2 on C2, 4 on C4, and 8 on C8)."}, {"title": "The Proposed Method", "content": "This paper focuses on a specific case: Relaxed RotationalEquivariance (RRE) for rotational Symmetry-Breaking onthe rotation group Cn. Then we introduce the method ofour proposed Relaxed Rotational Equivarant Convolution(RREConv), and the model architecture for both classifica-tion and detection tasks based on RREConv in 2D vision."}, {"title": "Relaxed Rotational Equivariant Filter", "content": "The construction of the Relaxed Rotational Equivariant Fil-ter (RREF) is the key to our method. Assume an initialweight W of size [C1+1, C\u0131, G\u0131, k\u0131, k\u0131] with Kaiming dis-tribution on the group G in the l-layer, where G = Cn,and G\u2081 = n for our RRE especially. Define a set of affinematrices A = {A\u00a1 | i \u2208 {0,1,\u2026\u2026, n \u2212 1}} for the G-transformation, where\nAi =\ncos (2\u03c0\u03af/n) \u2013 sin (2\u03c0\u03af/n)\nsin (2\u03c0\u03af/\u03b7) cos (2\u03c0\u03af/\u03b7)\n(6)\nBefore G-transformation for coordinates, assume the coor-dinate system is at the center of 2D plane, and define a func-tion CoorSet(0) to obtain the set of all coordinates of 0.For all u \u2208 [1, C1+1], m \u2208 [1, C1], n \u2208 [1, G\u0131], 2D coordi-nate pair (x, y) \u2208 CoorSet(WF[u, m, n, :, :]), we can ob-tain new 2D coordinate pair (x, y) after G-transformationfor coordinates on We as follows:\n(xi, yi) = Ai (x, y), \u2200i \u2208 {0,1,\u2026,n-1} (7)\nNow, we can obtain the strict rotational equivariant i-filter atgroup order i on G as follows:\nFG;i[u, m, n, xi, \u0176i] = WF [u, m, n, x, y], (8)\nif (xi, yi) \u2208 CoorSet(FF[u, m, n, :,:]). Note that someout-of-bounds coordinates of FG, may occur in somegroups (e.g. C6, and C8) except C2 and C4. Based on thisreason, some coordinates remain unassigned after the G-transformation from WF. For these coordinates, we employBilinear Interpolation. For our RREF, we introduce a set oflearnable G-biases BG = {BG,i | i \u2208 {0,1,\u2026,n1}},where the size of B\u0122\u203a\u00b2 is [Cl+1, 1, 1, k\u0131, k\u0131], with Zero distribution in the l-layer. Note that BF can be updated end-to-endduring the training period to adapt the Symmetry-Breakingin the dataset. Therefore, the final values of BF in l-layer aredetermined by datasets. Then, the relaxed rotational equiv-ariant i-filter at group order i on G as follows:\nGi\nR[u, m, n, :,:] = FG,\u00b2[u, m, n, :,:] + B\u00b2 [u, 1, 1, :, :]. (9)\nThus, the full RREF in the l-layer can be stacked as follows:\nR = Stack({RGi | i \u2208 {0, 1, \u2026\u2026 n \u2212 1}}), (10)\nwith the size of [C1+1, G1+1, C\u0131, G\u0131, k\u0131, k\u0131]. An easily under-standable construction of the RREF can be seen in Figure 3."}, {"title": "Relaxed Rotational Lift Convolution", "content": "Assume the input X\u2081 of size [C1, h1, W\u2081] on the plane Z2in the first layer. Similar to the lift convolution in equation(4), for all u \u2208 [1, C2], Relaxed Rotational Lift Convolution(RRLConv) can be performed by convolving over the inputchannel C1, and summing up the outputs as follows:\nC1\nX2[u, v, :, :] = \u2211 X1 [m, :, : ] * R\u00a3[u, v, m, :,:]. (11)\nm\nNote that, the constructions of Rf and RF for l > 2 are thesame, with Rf being slightly different in that it has no extrainput dimension G1."}, {"title": "Relaxed Rotational Equivariant Convolution", "content": "Also, assume the input Xi of size [C1+1, C1, G\u0131, hi, wi] inthe l-layer (l \u2265 2) on the group G, i.e., the group Cn.Similar to the group convolution in equation (5), for all\u03ba \u2208 [1, C1+1], v \u2208 [1, G1+1], RREConv can be performedby convolving over the input channel Ci and the input groupdimension G\u0131, and summing up the outputs as follows:\nC G\n\u03a7\u03b9+1[4, \u03c5, :,:] = \u03a3\u03a3x[m, n :, :] * RF [u, v, m, n, :, :],\nm n\nwith the size of [C1+1, G1+1, C1, G\u03b9, \u03ba\u03b9, \u03ba\u03b9]."}, {"title": "Model Architecture", "content": "Based on our RREConv, we propose a Relaxed RotationalEquivariance Network (RRENet). Considering the signifi-cant computational and parameter overhead caused by theadditional G dimension, we redesign the point-wise anddepth-wise versions of our RREConv. We typically adoptthe classic structure of ResNet (He et al. 2016), where eachPD RREBlock consists of two Point-wise RRECBAS adjust-ing the input and output channels, with two PD RRECBAs inbetween, and residual connections are used, as shown in Fig-ure 4. We also propose a Relaxed Rotational EquivarianceDetetor (RREDet). We use RREDet as a backbone to ob-tain three scale features in 2-layer, 3-layer, 4-layer, and theFPN+PAN architecture as the neck layer to obtain the finalthree scale features of size 80 x 80, 40 x 40, and 20 \u00d7 20 fordifferent-size object detection. Note that, the feature maps in4-layer are firstly input to the G-SPPF for Spatial PyramidPooling (He et al. 2014). Then these features are fed into theG-Max Pooling. Finally, the obtained features are as inputsfor the YOLOv8 detector, as shown in Figure 5. Here, thesize of the input is 640 \u00d7 640."}, {"title": "Experiments", "content": "In this section, we conduct extensive ablation experiments todemonstrate the effectiveness of our proposed RREConv inboth classification and object detection tasks. All the param-eters are set the same, and all the experiments are conductedon dual RTX-4090 GPU. We evaluate our method on theCIFAR10/100 datasets for the classification tasks, and thePASCAL VOC07+12 and MS COCO 2017 datasets for the"}, {"title": "Conclusion", "content": "In this paper, we delve into the realm of rotational equivari-ant networks employed for modeling natural datasets, show-casing their superior performance in leveraging 2D or 3Drotation groups. Despite their advancements, existing rota-tional equivariant networks operate under the assumptionof a strict uniform rotational symmetry prevalent across allfeatures. However, the reality of natural datasets unveils adifferent story, where data seldom adheres to strict rota-tional symmetry but rather aligns with a relaxed rotationalsymmetry pattern, characterized by rotational Symmetry-Breaking. This inability to effectively accommodate ro-tational Symmetry-Breaking scenarios, particularly withinnatural datasets, necessitates a novel approach. To tacklethis challenge, we introduce a simple yet powerful methodinvolving a collection of adaptable G-Biases. Utilizing thisinnovative mechanism, we put forth the concept of RelaxedRotational Equivarant Convolution (RREConv), tailored toaddress the nuances of relaxed rotational symmetry. Buildingupon our RREConv framework, we present RRENet, de-signed for classification tasks, and RREDet, optimized for2D object detection missions. Through rigorous experimen-tation, our results unequivocally demonstrate the efficacy ofour approach when applied to vision tasks involving natu-ral datasets. Exploring symmetry breaking with rotationalequivariance, both within the realms of 2D and 3D fields rep-resents a compelling avenue for future research. We firmlybelieve that incorporating this relaxation principle into mod-els improves their ability to accurately represent symmetry-breaking phenomena in real-world contexts."}, {"title": "Additional Experiments", "content": "RotMNIST. We conduct experiments on the RotMNISTdataset to validate the robustness of our RRENet, as detailedin Table 1. From the table, it can be seen that the top-1 ac-curacy of our RRENet-n (C8) is almost close to 1.\nPASCAL VOC07+12. We conduct ablation experimentson the PASCAL VOC07+12 test dataset based on theYOLOv8-n architecture. We replaced all regular convo-lutions in the YOLOv8-n-cls architecture with our PDRREConv, using RRLConv in the first layer and G-MaxPooling in the last layer. In Table 3, the models with RREoutperform those with SRE in both Apest and AP95,which once again proves the effectiveness of our RRE in2D object detection tasks.\nCIFAR-10/100. We conduct experiments on the CIFAR-10/100 test dataset based on the YOLOv8-n-cls architecture.We replaced all regular convolutions in the YOLOv8-n-cls"}]}