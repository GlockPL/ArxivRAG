{"title": "Granular-ball Representation Learning for Deep CNN on Learning with Label Noise", "authors": ["Dawei Dai", "Hao Zhu", "Shuyin Xia", "Guoyin Wang"], "abstract": "In actual scenarios, whether manually or automatically an-notated, label noise is inevitably generated in the training data, which can affect the effectiveness of deep CNN models. The popular solutions require data cleaning or designing additional optimizations to punish the data with mislabeled data, thereby enhancing the robustness of models. However, these methods come at the cost of weakening or even losing some data during the training process. As we know, content is the inherent attribute of an image that does not change with changes in annotations. In this study, we propose a general granular-ball computing (GBC) module that can be embedded into a CNN model, where the classifier finally predicts the label of granular-ball (gb) samples instead of each individual samples. Specifically, considering the classification task: (1) in forward process, we split the input samples as gb samples at feature-level, each of which can correspond to multiple samples with varying numbers and share one single label; (2) during the backpropagation process, we modify the gradient allocation strategy of the GBC module to enable it to propagate normally; and (3) we develop an experience replay policy to ensure the stability of the training process. Experiments demonstrate that the proposed method can improve the robustness of CNN models with no additional data or optimization.", "sections": [{"title": "1 Introduction", "content": "In recent years, deep CNN models have achieved great success in many fields owing to their powerful feature representation and learning abilities [42]. However, their usefulness is usually dependent on high-quality annotated data. Typically,"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Noise Filtering", "content": "A direct approach to deal with label noise is to design a specific method to remove mislabeled data. Han et al. [7] proposed a co-learning noise memory method, in which two networks with different learning capabilities were designed to perform collaborative learning on small batches of data to filter noise label samples. Guo et al. [6] developed principled learning strategies to achieve the goal of effectively dealing with a large number of noisy data label imbalances. Jiang et al. [12] proposed learning other types of neural networks, called MentorNet, to supervise the training of basic deep networks (i.e., StudentNet), during which MentorNet could provide StudentNet with a course (sample weight scheme) to focus on samples with potentially correct labels. Jie et al. [11] proposed making the learning rate change periodically the model swinging between overfitting and underfitting, resulting in the loss of samples with noise labels changing considerably to detect noise label samples. Jindal et al. [14] introduced a nonlinear processing layer to model the data with incorrect labels, thereby preventing the model from overfitting noise. Yao et al. [35] considered that co-learning could not accurately express the true learning status of a network by manually setting"}, {"title": "2.2 Noise Containment", "content": "These methods attempt to design specialized optimization goals to construct robustness models. Manwani et al. [20] verified that risk minimization using the 0-1 loss function had noise tolerance characteristics and the square error loss only tolerated uniform noise. Sukhbaatar et al. [26] introduced an additional noise layer in a neural network that adjusted the output to match the distribution of noise labels so that the probability transfer matrix continuously tended toward the true probability transfer matrix during the training process. Azadi et al. [1] proposed an auxiliary image regularization technique, encouraging the model to select reliable images to improve the learning process. Jindal et al. [13] augmented a standard deep network using a SoftMax layer that model the label-noise statistics before training the deep network. Zhuang ed al. [41] proposed an end-to-end weakly supervised deep-learning framework which was robust to label noise in web images. Li et al. [17] proposed a unified distillation framework to use \"edge\" information to \"hedge\" the risk of learning from noisy labels. Patrini et al. [22] proposed a forward correction method that does not depend on the application domain and network architecture, but only needs to know the probability of each class being polluted into another class. Zhang et al. [40] proposed a robust generalized cross-entropy (GCE) loss which combined the fast convergence speed of cross-entropy and the robustness advantages of the mean absolute error. Wang et al. [28] proposed a symmetric cross-entropy learning method that symmetrically enhances the CE using reverse cross-entropy corresponding to robust noise. Jun Shu et al. [23] proposed a meta-learning method to train a reliable network with a set of clean and small data to guide the subsequent training of noisy data, so as to alleviate the adverse effects of label noise or long-tail data on model training. Harutyunyan et al. [8] proposed a method to control the label noise information in the weights of neural networks, which reduced the label memorization problem. Ma et al. [19] proposed to combine two mutually"}, {"title": "2.3 Granluar Computing", "content": "Chen[3] pointed out that the brain gives priority to recognizing a \"wide range\" of contour information in image recognition, and human cognition has the characteristics of \"global precedence\". This differs from major existing artificial intelligence algorithms, which use the most fine-grained points as inputs. Granular computing can be used to partition data distribution and knowledge space. Wang [27] introduced a large-scale cognitive rule into granular computing and proposed multigranular cognitive computing. Xia and Wang [32] proposed hyperspheres of different sizes to represent \"grains\" and proposed GBC, in which a large gb represented coarse granularity, while a small gb represented fine-granularity. Xia et al. [31] proposed the granular-ball support vector machine (GBSVM) method, in which gb samples replaced the original finest-grained sample; this method exhibited better efficiency and robustness than the traditional classifier. GBC has also been applied in many other fields to improve model generalizability or efficiency, such as rough sets [33], sampling [34], fuzzy sets [30]. In this study, we develop an extended GBC framework to construct robust deep CNN models for learning with label noise."}, {"title": "3 METHODOLOGY", "content": ""}, {"title": "3.1 Motivation", "content": "At present, the learning process of all deep CNN models attempts to map each individual sample in the training dataset to its label, that is, a single-granularity information processing mode. Therefore, containing a certain proportion of labeled noise in the training dataset can affect the usefulness of neural models. The popular solutions enhance the robustness of models at the cost of weakening or even losing the mislabeled data. In this study, we propose a GBC module that can be embeded in the CNN models, it splits the feature vectors of the input into multi-granularity grains (gb samples). Consequently, the final classifier learns the mapping of each gb sample to its label (Fig. 2). Intuitively, the proportion of gb samples with incorrect labels that generated based on content similarity is unlikely to exceed or may even be much lower that of individual samples. Therefore, multi-granularity information processing can perform better robustness than that of a single and finest-granularity."}, {"title": "3.2 Overview of our method", "content": "For image classification tasks, a deep CNN model can be divided into the feature-learning module (FLM) and classifier, and FLM converts the input images into low-dimensional feature vectors, based on which the classifier predicts the label of each individual image sample. In this study, we design a GBC module and integrate it into FLM and classifier modules. And we develop an experience replay strategy to train the model, which requires the input images to be divided into empirical and non-empirical samples. As shown in Fig. 2, (1) through the FLM, two types of input images are converted into a set of low-dimensional feature vectors; (2) each empirical sample from the experience pool is not required to reproduce the gb sample, and the center vector of each empirical gb sample is updated using the feature vectors of individual samples belonging to that gb sample that have just been updated; (3) the GBC module splits the feature vector set of non-empirical samples into the MG grains (i.e., gb samples), each of which contains different number individual samples and corresponds to one single label; (4) a portion of high-purity gb samples is placed as empirical gb samples into the experience pool; and (5) two types of gb samples are merged, and classifier predicts the label of each gb sample rather than the individual sample in the training process. In the error backpropagation of the GBC Layer, we adopt a similar average pooling operation to copy the error of the gb samples to all individual samples within it. In the reasoning process, each individual sample can be considered to be one gb sample."}, {"title": "3.3 Adaptive gb Sample Generation", "content": "Definition 1: Given a granular-ball sample $gb_i$, it can contain individual samples with different labels, each of label can correspond different number individual samples. We define $label_j$ that corresponds the most individual samples as the label of this $gb_i$, $|label_j|$ as the number of individual samples with $label_j$ in $gb_i$, $|gb_i|$ as the number of individual samples in $gb_i$, and $p_{gb_i}$ as the purity of $gb_i$, then:\n$p_{gb_i} = \\frac{|label_j|}{|gb_i|}$                              (1)\nDefinition 2: A set of a low-dimensional feature vector $D \\in R^d$ is given. We define $C$ as the center of gravity of all individual sample points in a gb sample $gb_i$, $v_i$ as the feature vector of an individual sample in $gb_i$, and $v_c$ as the center vector of $gb_i$, then:\n$v_c = \\frac{1}{|gb_i|}\\sum_{i=1}^{|gb_i|} v_i$           (2)\nA formal description of the proposed GBC module is expressed in Eq. 3. N denotes the total number of samples in the input, m denotes the number of gb sample divided by the input. The construction of gb sample needs to meet the following constraints: (1) each gb sample meets the purity requirements; (2) each gb sample should cover as many samples as possible, and its number should be as few as possible. The purpose of the GBC module is to divide a single-granularity input into a multi-granularity (MG) representation at the feature level. The overall process is summarized in Algorithm 1.\n$f(x, w) \\rightarrow g(gb, \\theta)$, \ns.t. Min $N / \\sum_{j=1}^m(|gb_i|) + m$,\ns.t. $quality(gb_i) \\geq T$.                                                (3)"}, {"title": "3.4 Error Backpropagation in GBC Layer", "content": "The batch input of $N_b$ samples can be mapped to be $N_b$ $d_o$-dimensional feature vectors ([Nb, do]) through the FLM, and GBC layer further divides them into $N_{gb}$ gb samples ([Ngb, do]), usually $N_b > N_{gb}$. Because of the inconsistency between the input of the FLM and the classifier, error propagation is interrupted between GBC and FLM. Consequently, the error corresponding to each gb sample is returned to the GBC layer during the backpropagation process. However, only the error corresponding to each individual sample ensures that the learning module learns layer-by-layer. The GBC layer performs a similar average pooling operation at the feature level of the input samples. Therefore, we adopt a similar operation to copy the error of the gb samples to all individual samples within it."}, {"title": "3.5 Experience Replay", "content": "Since the individual samples for each iteration are drawn randomly, gb samples generated for each iteration can exhibit non-static distribution. Consequently,"}, {"title": "4 Experiments", "content": "We applied our method on base ResNet (RN) [9], DenseNet (DN) [10] and contrastive learning [16,36] models, and then we conducted experiments on several image classification datasets (including CIFAR-10, CIFAR-100, CIFAR-10N and ANIMAL-10N). Among them, the noise in CIFAR-10 and CIFAR-100 is gener-"}, {"title": "4.1 Experiments Settings", "content": "Dataset. For CIFAR-10 and CIFAR-100 datasets, we test two types of label noise: symmetric noise(Sym.) and asymmetric noise(Asym.). For symmetric noise, a fixed proportion of samples being randomly selected from each category for random label modification; for asymmetric noise, we flipped labels between DEER\u2194HORSE, BIRD\u2194AIRPLANE, TRUCK\u2194AUTOMOBILE, and CAT\u2194DOG(Asym.). ANIMAL-10N dataset contains 5 pairs of confusing ANIMAL with atotal of 55,000 images, which are crawled from several online search engines using the predifined labels as the search keyword; the images are then classified by 15 recruited participants; each participant annotated a total of 6,000 images with 600 images per-class; after removing irrelevant images, the training dataset contains 50,000 images and the test dataset contains 5,000 images; the noise rate is about 8% [25]. CIFAR-10N, variations of CIFAR-10 with human-annotated real-world noisy labels collected from Amazon's Mechanical Turk [29].\nImplementation details. We implemented the proposed method in PyTorch and conducted experiments on a 24 GB NVIDIA RTX 3090 GPU. We used SGD with Nesterov momentum and set the initial learning rate to 0.1, momentum to 0.9, and minibatch size to 512-1024. The learning rate was dropped by 0.1 at 32k and 48k iterations, and we trained for 64k iterations. The basic models used in the experiments were ResNet and DenseNet models. We used cross-entropy losses with a weight decay of 0.0001. For GBC layer setting, the purity p was set to a value between 0.6 and 1.\nBaseline methods. To evaluate our method, we also compared our method to other methods that also without additional data and optimization: (1) CE, which uses Cross-Entropy loss to train the DNNs on noisy datasets. (2) Forward [22], which corrects loss values by a label transition matrix. (3) LIMIT [8], which introduces noise into the gradient to avoid memorization. (4) SLN [4], which proposes to combat label noise by adding noise to the data labels. (5) CTRR [36], which proposes a contrastive regularization function to learn robust contrastive representations of data over noisy data."}, {"title": "4.2 Comparisons with the Original Models", "content": "We first applied the proposed GBC module on two classical models (ResNet and DenseNet) and trained them on the benchmark dataset which contained different proportions of labeled noise. The comparison results of the original CNN and our GB_CNN models are listed in Table 1, Table 2 and Fig. 3. From the results, we can make two major observations:\n(1) The purpose of our proposed method is not to push the state-of-the-art performance of the original models leanring on clean data, but to reduce the influence of label noise. From the results in Table 1, we can note that the CNN models with embedding the GBC module can perform almost as well as the"}, {"title": "4.3 Comparisons with Other Methods", "content": "Since, PreAct ResNet-18 (PRN18, see Table 4), a much wider and larger model compared with RN20, 32, 44, 56 and DN121, was used to construct the experiments in the previous studies, and thus, to ensure fairness in comparison, we"}, {"title": "5 Conclusion", "content": "In the practice, a certain proportion of samples with wrong labels always occurs when collecting data, which can affect the effectiveness of models. Consequently, labels can often change due to subjective factors, while the content of the sample or its feature do not change with changes in the labeling. Inspired by this, we propose learning the multi-granularity representations based on the feature similarity, where the classifier can predict the label of each gb sample instead of the individual samples. The experimental results verify that the proposed method can improve the robustness of deep CNN models without any additional data and optimization. Nevertheless, our proposed still needs improvement in classification tasks with many categories, which is worth further exploration."}]}