{"title": "MelissaDL x Breed: Towards Data-Efficient On-line Supervised Training of Multi-parametric Surrogates with Active Learning", "authors": ["Sofya Dymchenko", "Abhishek Purandare", "Bruno Raffin"], "abstract": "Artificial intelligence is transforming scientific computing with deep neural network surrogates that approximate solutions to partial differential equations (PDEs). Traditional off-line training methods face issues with storage and I/O efficiency, as the training dataset has to be computed with numerical solvers up-front. Our previous work, the Melissa framework, addresses these problems by enabling data to be created \"on-the-fly\" and streamed directly into the training process. In this paper we introduce a new active learning method to enhance data-efficiency for on-line surrogate training. The surrogate is direct and multi-parametric, i.e., it is trained to predict a given timestep directly with different initial and boundary conditions parameters. Our approach uses Adaptive Multiple Importance Sampling guided by training loss statistics, in order to focus NN training on the difficult areas of the parameter space. Preliminary results for 2D heat PDE demonstrate the potential of this method, called Breed, to improve the generalization capabilities of surrogates while reducing computational overhead.", "sections": [{"title": "Introduction", "content": "The advancement of artificial intelligence (AI) applications in the natural and physical sciences, referred to as AI4Science (AI4S), has noticeably accelerated in recent years [26]. Remarkable examples include molecule docking modeling (AlphaFold 3 [1]) and weather forecasting (NeuralGCM [22], ClimaX [33], Aurora [5]). This progress has been enabled by combining large training data sets, advanced neural architectures, and parallel computational resources.\nParticular attention has been given to deep surrogates a class of neural networks (NNs) that approximate the solution of partial differential equations (PDEs) used to describe various scientific phenomena. PDE solutions are classically obtained using numerical methods such as Finite Elements Method or Finite Volumes Method. However, these methods are compute and memory intensive. Deep surrogates are expected to deliver quality solutions during inference at a fraction of the memory and computational cost of these solvers.\nDeep surrogates can be trained with little to no data, as in Physics Informed NNs (PINNs) [36, 41], where the PDE residuals, initial and boundary conditions (IC, BC) are imposed as soft constraints through the loss. Yet, a wide variety of neural architectures, ranging from Graph Neural Networks [35] and Neural Operators [2, 27] to Diffusion Models [23] and Visual Transformers [18], are trained with numerical simulations data. A surrogate can also be trained in a multi-parametric context with varying ICs and BCs to develop a more generic model. [18] presented a general purpose PDE foundation model that can be finetuned to obtain a specific PDE solution, while [10] proposed a neural operator architecture that generalizes to unseen geometries. Since all these NN are trained in a supervised manner using data produced by the PDE solver they aim to substitute - their performance depends on both training set quantity and quality.\nA standard approach is to train surrogates off-line: first, a dataset is generated with traditional PDE solvers and stored on disk; then, the surrogate is trained in an epoch-based manner by reading back the dataset from disk. When scaled, this approach suffers from two main limitations: 1) storage capabilities limit the dataset size, thus compromising data quantity, fidelity, and/or diversity; 2) writing and reading the dataset creates an I/O bottleneck, thus impairing efficiency during training. In previous works [28, 29, 38], we tackled both limitations by demonstrating an on-line training approach for multi-parametric surrogates with the Melissa framework: the dataset is generated and directly sent to training, bypassing the storage. It allowed us to train a surrogate faster and with higher generalization abilities due to a significantly larger training dataset. In addition, on-line training enables the steering of the data creation"}, {"title": "Background", "content": "Consider partial differential equations (PDE) of the form:\n$N[u](x, t) = f (x, t)$ (1)\n$Bi [u](xi, t) = gi(xi, t)$ Vx \u2208 X, xi \u2208 Xi, t \u2208 T (2)\n$I [u] (x, 0) = h(x)$ (3)\nwhere u(x, t) is a quantity of interest described by the PDE (e.g., temperature value) defined on a bounded domain Q = X \u222a TCRd+1. N[u] is a differential operator acting on u(x, t), Bi [u] are boundary conditions operators (BCs) for boundaries U\u00a1 \u2200X\u2081 = \u2200X \u2208 X, and I [u] is an initial condition operator (IC). Let denote A the vector that encompasses all parameters of PDE (physical constants, coefficients of f, g, h).\nMost common numerical solvers use mesh-based spatial and temporal discretization and produce trajectories sequentially. To obtain the numerical solution for a considered PDE, we have to 1) provide equation-based functional definitions, domain bounds, and vector \u03bb; and 2) select spatial discretization size Md \u00b7 \u2200x = X and temporal discretization size T\u00b7 \u2200t = T. The second defines the size of spatial coordinates set X and the number of iterations needed for an autoregressive solver. This not only affects the data fidelity level and approximation quality but also the required memory and computation demands. Let us denote a produced solution field at time step t = i \u00b7 \u2200t for a given Aj as xji = {\u00fb(x, t)|x \u2208 X}, then the solver produces one-by-one a trajectory:\nAj : [xj,0 \u2192 Xj,1 \u2192 \u00b7\u00b7\u00b7 \u2192 xj,T] =: xj\nThe deep surrogate model ue (with weights \u03b8) approximates the PDE solution u(x, t), thereby aiming to substitute a numerical solver. There are different types of surrogate architectures. It can be designed to predict the solution directly, i.e., u\u03b8 (X, t) = xt, or autoregressively, i.e., u\u03b8 (xt) = Xt+\u2200t. As we mentioned in Section 1, the surrogate can be multi-parametric: u\u03b8 (X, t, j) = xj. In the scope of this paper, we consider multi-parametric direct surrogates; details are provided in Section 4."}, {"title": "Simulation-based deep learning"}, {"title": "The Melissa DL framework", "content": "Melissa DL [28, 29, 38] is an HPC framework designed for deep learning tasks where the NN is trained with simulation data. It consists of three elements: clients, a server, and a launcher (for details, see Appendix A). By default the server uniformly samples input parameters A for each of S clients across the input parameter space A. Each client then runs the solver on the provided inputs and streams the data (timesteps) to the server. The launcher only submits a subset of all clients based on allocated resources. This enables the server to dynamically select new input parameters for pending' clients, which we refer to as global steering (hereafter, simply steering). It is key to unlocking data-efficient surrogate training with active learning methods."}, {"title": "Active learning steering of data creation for on-line surrogate training", "content": "Active learning is a possible solution for data-efficient surrogate training, as it can help to reduce the number of simulations to execute while maintaining the surrogate quality. Generally, AL's goal is to improve NN training by choosing the most informative examples, based on an acquisition function and a query method, to be labeled by an oracle (or a human) and given to the NN. In our context, \"labeling by an oracle\" is analogous to \"executing a solver\" and \"choosing examples\" - to \"sampling solver inputs \u03bb\".\nHowever, classical AL methods are not adapted to our on-line training context. Extra computational and memory costs imposed by well-known AL techniques are highly undesirable. First, the input parameters choice decision has to be fast not to pause the surrogate training process as the priority is to keep GPUs busy. Second, the incurred extra memory footprint should be limited to avoid disk storage to keep on-line training efficient.\nTo develop AL methods for on-line training, we take inspiration from methods proposed for data-free PINNs [12, 25, 43] and extend our previously proposed method called Breed [14]. In our supervised setting, instead of choosing collocation points, we have to choose input parameters A and run an autoregressive solver. In our compute-constrained setting, we aim to use only per-sample loss values as it does not require any extra computation. In our memory-constrained setting, we are not able to recompute loss values for all training points but instead have to use \"outdated\" loss values, i.e. loss values obtained from the NN at anterior learning steps. Additionally, instead of having a pool of points to choose from, we adaptively sample new points based on previous points loss statistics, inspired by Population Monte Carlo algorithms [9]. We detail the proposed method, Breed, in the following."}, {"title": "Loss-deviation based acquisition metric", "content": "We want to define training sample informativeness through NN loss: the higher the loss, the higher the impact on NN training. At iteration i of the fixed-state NN uo\u1d62, there is an underlying probability distribution of NN failure Le\u1d62 over input domain A, which we choose to represent through the self-normalized loss function L(\u00b7):\n$Lo\u2081 (j') \u2248 \\frac{\\sum_{t\\in T} L(uo; (X, t, \\lambda j'), xj't)}{\\sum_{\\lambda \\lambda \\in \\Lambda i} \\sum_{t\\in T} L(u\u03b8; (X, t, \u03bb), xjt)}$"}, {"title": "Adaptive Multiple Importance Sampling", "content": "Instead of choosing points from a pool or a dataset, we want to sample new points according to progressing Le. We propose to use an Adaptive Multiple Importance Sampling (AMIS) algorithm, inspired by the Population Monte Carlo (PMC) algorithm and previously presented in off-line context [14]. An Importance Sampling (IS) goal is to build a proposal probability distribution q, which is easy to sample from, to approximate an unknown target distribution \u03c0, which can be evaluated up to a normalizing constant.\nIn PMC, the proposal is built iteratively. At iteration i q(i) is a mixture (population) of N proposals: q(i) = \u2211n=1:Nq\u207d\u207f\u207e (\u03bc\u03c0\u03b9), \u03a3). The initial locations \u03bc\u03b7 are given or chosen randomly and \u03a3 = \u03c3\u03b9\u03b1 is a hyperparameter. Next, one random value is sampled from each\n$x\u1d62\u207d\u207f\u207e \u223c q\u2099\u207d\u2071\u207e(\u03bc\u2099, \u03c3)$ (7)\n$w\u2099\u207d\u2071\u207e = \\frac{\\pi(x\u1d62\u207d\u207f\u207e)}{q\u207d\u2071\u207e(x\u1d62\u207d\u207f\u207e)}$ (8)\nThen a multinomial distribution with weights {whi)}n=1:N is trialed N times, i.e., we resample {xi) }n=1:N with replacements and obtain {xn; }n\u2081\u2208{1:N},i=1:N. The resampled values are used as new location parameters \u03bc\u03c0i+1).\n$w_{j'} = \\frac{Q_{j'}}{\\sum_{\\lambda j \\in \\Lambda i} Q_j}$ (9)\n$\\Lambda jk \\sim Mult(\\Lambda ^i, w_j, K)$ (10)\n$q^{(s)}(+) = \\sum_k q^{(s)}(+) = \\sum Gauss(\\cdot |\\lambda jk, \\sigma).$\" (11)\n\""}, {"title": "HPC implementation details", "content": "We expand the Melissa DL server with the steering mechanism (Figure 2) to apply Breed. The resampling is triggered by the server periodically based on the NN training iteration. Firstly, the server acquires a consistent view of the launcher's job submissions. Secondly, it identifies the simulations that have not yet been submitted for resampling the inputs and, finally, starts the resampling algorithm.\nThe Melissa launcher has a limit m on the maximum number of jobs allowed to run simultaneously, determined by the available resources. Assuming the trigger is invoked while currently running or submitted simulation Sk, where k is the highest simulation ID observed from the launcher's perspective. The exact start time of the next simulations from Sk+1 to Sk+m-1 cannot be determined due to the inherent uncertainty of the batch scheduler. Therefore, the server always chooses Sk+m as the starting point and thus avoids inconsistencies that lead to resampling the parameters that may have been already submitted.\nThe primary limitation of this approach lies in selecting the appropriate trigger period. For instance, if the period is too frequent, a resampled generation might never execute with the same parameters as it is likely to be overwritten multiple times. Consequently, this value is left to the user's discretion, taking into account the execution speeds of both the solvers and the training process."}, {"title": "Experimental study", "content": "We experiment with a 2D Heat PDE solver called HeatPDE (Appendix B.1), focusing on the analysis of the method's hyperparameters space and its performance with different NN sizes. We compare our method to an on-line training of a surrogate where input parameters are sampled uniformly, which we refer to as Random. We chose the heat PDE case due to its relatively low computational demands and ease of interpretability.\nThe surrogate is trained to directly predict the discretized temperature field: u\u03b8 (\u03bb, t) = \u00fbx(x, t), where \u03bb = [To, T1, T2, T3, T4] \u20ac [100,500]5 care the initial and four boundary temperatures and t \u2208 [0, 1, ..., 100]. We choose a multilayer perceptron with an input layer of 6 neurons, L hidden layers of H neurons with ReLU activation, and an output of M\u00b2 = 642 neurons. It is trained using Adam optimizer with a learning rate of 1e-3 and batch size B = 128. The simulations run budget is S = 800, and the pre-created fixed validation set has 200 full-trajectory simulations with parameters generated from a quasi-uniform Halton sequence."}, {"title": "Study description", "content": "We conduct two systematic studies: across different model configurations (Figure 3a) and across different Breed hyperparameters (Figure 3b). All other configuration values are fixed for fair comparison (see appendix Table 1). We vary:\n(1) The hidden size H and number of layers L of the fully connected NN;\n(2) The 3 parameters associated with sampling: window size N and period P (implementation), width \u03c3 (PMC);\n(3) The 3 parameters associated with r value: (rs, re, rc).\nThe model configuration affects its expressivity and capability to capture more complex data. It directly connects to overfitting and underfitting phenomena, which in an on-line setting are specifically important. We study values H = [16, 32, 64] and L = [1, 2, 3], run two experiments, with Random and Breed steering.\nThe window size defines the size of the proposal population, which might affect distribution approximation: smaller values can make it \"unstable\" while bigger values can make it \"outdated\". We study values [50, 600, 1000].\nThe period affects the computational load \u2013 how often we perform resampling. It can also affect the distribution approximation quality as Breed is trying to follow a dynamically changing target Le. Currently, the period is static, but we expect to extend it to an adaptive trigger that uses the usual MCMC modeling metrics, e.g., effective size and expected improvement. We study values [10, 50, 100, 300, 500].\nThe tuning of width \u03c3 is a known issue in PMC algorithms. Smaller values might make the sampling too \"myopic\" while bigger values might make it not concentrative enough. Finding a golden middle is challenging. We study values [1.0, 5.0, 10.0, 25.0].\nThe biggest tuning burden is created by r-value, as it is specific to the problem, the model, and parameter P. However, this mixing ratio was the simplest technique for the exploitation-exploration dilemma, which also appears in MCMC modeling and reinforcement learning. We chose a \"linear-constant\" change scheme based on heuristics from our previous work, where we noticed that a"}, {"title": "Results discussion", "content": "While overall Breed performance is not clearly better than Random, which can be explained by HeatPDE case simplicity, we see a specific pattern. Given higher expressivity to the model, Random experiments tend to show overfitting, which is especially noticeable for H = 16, L = 3, while Breed training and validation curves stay close 2 (Figure 3a).\nWe see overfitting for some hyperparameter values (Figure 3b), i.e., high rs and low \u03c3. As for the convergence, we observe that higher window sizes and lower periods tend to make training divergent at the beginning, which affects further iterations. Within the rs study, we see that value 0.5 also shows divergence at earlier iterations, but at later ones, converges faster, and its training loss is higher than validation loss, which is a good sign of generalization abilities. Consequently, re and re affect the training as well.\nApart from performance analysis, we conducted explorative analysis across training statistics. Our central insight is that the conditional distribution of input parameters created overall for the run is clearly shifted when we use Breed (Figure 4). We calculated a per input vector deviation, which represents how large is the difference between the temperatures T0:5, and built a histogram. In Figure 4b, we compare the fixed configuration run with the\n2In Melissa, a training thread may operate more frequently than a receiving thread. It can result in more training iterations independent of the run configuration, which we observe in figures."}, {"title": "Related work", "content": "The question of active learning originated in the context of training NNs with a finite dataset [39]. The goal is to \"select a small subset of unlabeled samples from a large pool of data for labeling and training, while achieving comparable generalization performance to learning on the entire dataset\" [6]. Active learning in that context relies on two main criteria. The first one is based on uncertainty, choosing samples that the neural models are most uncertain about. The second is based on diversity, selecting samples bringing diversity in the feature space compared to the already labeled ones [6]. It is tackled in various ways: measuring samples uncertainty by approximating training dynamics [24, 40], calculating samples influence [19],"}, {"title": "Conclusion", "content": "In this paper, we introduced an active learning method for data-efficient on-line training of deep surrogates using the Melissa framework. Our approach steers data creation by leveraging loss statistics and Importance Sampling: it guides the solvers to compute trajectories with input parameters in hard-to-learn regions. Preliminary results with the heat equation showed Breed's potential to improve NN generalization ability without computational overhead, as well as an interpretable choice of points. Future work will focus on conducting experiments for larger-scale and more complex dynamic PDEs, refining the method with advanced sampling techniques, and reducing the set of hyperparameters by developing self-adaptive techniques."}, {"title": "Melissa DL Architecture", "content": "The launcher controls the workflow by interacting with the cluster's batch scheduler. It initiates the server, a Python-based code using PyTorch for multi-GPU training. The server manages the training process and defines the simulation instances, known as clients. The server then sends a request to the launcher for submitting clients based on allocated resources. Once a client starts, it connects dynamically to the server.\nThe server maintains a memory buffer called the reservoir, which goal is to reduce training bias and avoid GPU starvation. Newly received data from the clients are stored in the reservoir, replacing older data randomly. If all reservoir samples are new, client executions are paused temporarily. The server asynchronously creates random batches from the reservoir for NN training, allowing each reservoir sample to be reused multiple times. See [28] for a detailed description of the reservoir algorithm."}, {"title": "General setup details", "content": "The experiments consider the classical heat equation (HeatPDE) on a 2D rectangular domain:\n$\\frac{\\partial u(x, t)}{\\partial t} = \\alpha \\frac{\\partial^2 u(x, t)}{\\partial x^2}$ (13)\nu((x\u2081 = 0, x2), t) = T\u2081, u((x\u2081 = L, x2), t) = T\u2082 (14)\nu((x\u2081, x\u2082 = 0), t) = T\u2083, u((x\u2081, x\u2082 = L), t) = T\u2084 (15)\nu(x, t = 0) = To (16)\nwhere u(x, t) is the field temperature, a is the thermal diffusivity and [To, T1, T2, T3, T4] are the initial and 4 boundary temperatures. The solution is approximated with an in-house solver that implements a finite difference method with an implicit Euler scheme. The temperature field is discretized on a MX M Cartesian grid and generated for T = 100 time steps representing \u2200t = 0.01 seconds each. In this study, the thermal diffusivity is fixed to a = 1m\u00b2.s\u207b\u00b9, and"}, {"title": "Experiment orchestration", "content": "To facilitate a broad analysis study, we employ Snakemake[31], a workflow management system that enables the execution and management of scalable, reproducible analysis studies. In our case, the workflow creates configuration files for Melissa runs across chosen grid. To ensure the reproducibility\u00b3 of our experiments, we utilize Nix [13] package manager. The experiments were conducted on the Grid5000 [3] cluster using OAR scheduler [8]. Each Melissa client as well as the server run one 48 processes MPI job, each one scheduled on a 48 core node."}, {"title": "Experiments additional details", "content": "Here we provide the Table 1 with exact hyperparameters used in the study, and 6 is the visualisation of correlation matrix."}]}