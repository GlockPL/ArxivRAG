{"title": "Large Language Models are Few-shot Multivariate Time Series Classifiers", "authors": ["Yakun Chen", "Zihao Li", "Chao Yang", "Xianzhi Wang", "Guandong Xu"], "abstract": "Large Language Models (LLMs) have been extensively applied in time series analysis. Yet, their utility in the few-shot classification (i.e., a crucial training scenario due to the limited training data available in industrial applications) concerning multivariate time series data remains underexplored. We aim to leverage the extensive pre-trained knowledge in LLMs to overcome the data scarcity problem within multivariate time series. Specifically, we propose LLM-Few, an LLM-enhanced framework to investigate the feasibility and capacity of LLMs for few-shot multivariate time series classification. This model introduces a Patch-wise Temporal Convolution Encoder (PTCEnc) to align time series data with the textual embedding input of LLMs. We further fine-tune the pre-trained LLM decoder with Low-rank Adaptations (LoRA) to enhance its feature representation learning ability in time series data. Experimental results show that our model outperformed state-of-the-art baselines by a large margin, achieving 125.2% and 50.2% improvement in classification accuracy on Handwriting and EthanolConcentration datasets, respectively. Moreover, our experimental results demonstrate that LLM-based methods perform well across a variety of datasets in few-shot MTSC, delivering reliable results compared to traditional models. This success paves the way for their deployment in industrial environments where data are limited. Our code is available at: https://anonymous.4open.science/r/llm-fewshot-mtsc-C608.", "sections": [{"title": "1 Introduction", "content": "Multivariate Time Series Classification (MTSC) is a challenging task due to its high-dimensional and complex data structures, which requires the consideration of intra-class similarities and inter-class differences across various classes [1]. The inherent complexity stems from the need to model and interpret intricate interactions and dependencies among multiple time-indexed variables, which can vary widely in behavior and influence across different domains. In many scenarios, collecting labeled data to train deep learning models is challenging, leading to the emergence of the few-shot learning problem. For example, in the healthcare field [2], Electrocardiogram (ECG) time series data are important for diagnosing cardiac arrhythmias; however, the labeled ECG data available for training are often limited due to expensive data collection, time-consuming labor annotation, and patient privacy issues. The data scarcity makes few-shot learning an increasingly important topic. Another important application is the Internet of Things (IoT) and edge computing, the smart devices make intelligent decisions using their own collected time series data which can also be considered a few-shot learning scenario [3].\nClassical deep learning models, illustrated in Figure 1 (a), tend to overfit small-scale training datasets; they often fail to generalize and cover various test data distributions, causing significant performance degradation under limited training samples. Existing limited studies on few-shot MTSC [4, 5] heavily rely on the transfer learning strategy, illustrated in Figure 1 (b). These methods generally pre-train a model on various source datasets and then fine-tune it on the target dataset. However, time series data"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Few-shot Learning for MTSC", "content": "Statistical and Machine learning methods have first been applied to MTSC tasks, including Dynamic Time Warping (DTW) [10], a distance calculation function, can compensate for possible confounding offset with some realignment of series and combined with support vector machine to classify multivariate time series data. Random Convolutional Kernel Transform (ROCKET) [11], with many random convolution kernels, is another efficient method without the parameter update during training. However, they are not effective when dealing with high-dimensional data because require using hand-crafted features. Classical statistical and machine learning methods like Dynamic Time Warping (DTW) [10] and Random Convolutional Kernel Transform (ROCKET) [11] have been used in multivariate time series classification. DTW adjusts time series alignment and, combined with support vector machines, classifies data effectively. ROCKET uses random convolution kernels and does not update parameters during training. However, both methods struggle with high-dimensional data as they depend on hand-crafted features.\nWith the development of deep learning methods, Recurrent structures, including GRU and LSTM, have first been used to solve the MTSC problem [12]. Later, Convolutional Neural Network (CNN) was adopted because of its success in the CV field and higher efficiency for parallel computing compared to the recurrent structure [13]. Transformer-based models first emerged for NLP and then were later applied to MTSC because they combine the advantage of both recurrent and convolutional models. Dyformer [14] uses a hierarchical pooling layer to decompose time series data and gates to process and fuse information among subsequences. Shapeformer [15] considers using shapelets to identify similarities within classes. However, when it comes to few-shot scenarios, the above state-of-the-art models possibly cannot avoid overfitting problems and fail to learn generalizable features within and between classes.\nLimited research focuses on few-shot MTSC. The initial idea is to enlarge the training datasets using the data from different domains [16] or applying data augmentation methods through time and frequency domain [17]. This type of data is inherently unstable. Performance hinges on whether the model's ability to learn within-class similarities through this process is effective in distinguishing unseen test data across multiple classes. Meta-learning is another possible solution for few-shot scenarios by fusing meta-features and using triplet loss to learn the representations within and across classes [7, 18]. A similar design uses contrastive learning, which is a self-supervised learning paradigm, to have a 2-stage training: a self-supervised pre-training and label supervised fine-tuning [19]. However, all the above methods do not actually solve the few-shot problem because they all require external reliable time series data to learn temporal patterns and serve as the knowledge for the downstream classification task."}, {"title": "2.2 LLM Applications for Time Series Analysis", "content": "LLMs are popular and prominent within the time series analysis, providing a new perspective for learning temporal patterns. Researchers focus on how to reprogram time series data and then feed it into LLMs to improve performance. The first pioneering work [20] converts numerical data into text versions to let the LLMs finish the probabilistic forecasting task. PromptCast considers a similar way to design a hard prompt to encode the time series input [21]. However, this kind of method omits the fact that the frequency of numbers appearing in text is very low, and the meaning of numbers in the semantic space is inconsistent with its in the time series data. More recent work considers using alignment modules to convert multivariate time series data into embedding and then put them into LLMs in the next step. Some effective modules in past research include Instance Norm and Patching [22, 23]. Another inspiring direction is decomposing time series into trend, seasonal and residual parts and then adding three parts together to generate input embedding [24, 25]. All the above efforts are aimed at activating the sequence modeling ability of LLM to understand the temporal features in time series, which are unseen in its pre-training tasks. They also point out the importance of aligning time series and text semantic spaces."}, {"title": "3 LLMFew", "content": ""}, {"title": "3.1 Problem Definition", "content": ""}, {"title": "3.1.1 Multivariate Time Series Classification", "content": "Given a multivariate time series data $X = {x_1, x_2,\u2026, x_M } \u2208 R^{M\u00d7L}$ annotated by a label $y_n \u2208 S$, $|S| = N$, where M is the number of series, L is the sequence length, and N is the number of class. The multivariate time series classifier can be formulated as $f:R^{M\u00d7L} \u2192 Z^N$, which aims to distinguish the multivariate time series data into N different categories by $\u0192 (X) = y_n$ and return the class label $y_n$\u00b7"}, {"title": "3.1.2 Few-shot Learning (FSL)", "content": "FSL problems are predominantly supervised learning tasks. Specifically, few-shot classification involves developing a classifier based on only a small number of labeled examples for each class. We consider the N-way-K-shot classification in which the model f is exposed only to $K \u00d7 N$ samples. This learning approach is termed as K-shot learning. Let $D_{train} = {(X_i, y_i)}_{i=1}^{KXN}$ be the K-shot training dataset, the objective is to train a model f to minimize the discrepancy between its predictions and the true class labels over the training dataset $D_{train}$."}, {"title": "3.2 Framework", "content": "Our model framework is depicted in Figure 2. LLMFew is an LLM-enhanced framework with four main modules: a Patching layer, a Patch-wise Temporal Convolution Encoder (PTCEnc), an LLM decoder with Low-Rank Adaptation (LoRA) fine-tuning and lastly a classification head."}, {"title": "3.2.1 Patching", "content": "We adopt a Patching Layer to process multivariate time series input, which has been widely used in Transformer-based Models for learning local semantic information [26].\nThe multivariate time series X, with M features and L time steps, can be split into M univariate series $x_m \u2208 R^{1\u00d7L}$. Each univariate time series $x_m$ is divided into patches independently. We denote the patch length as P and the stride (the non-overlapping region between two consecutive patches) as S, then the patching layer will generate a sequence of patches $x_m \u2208 R^{P\u00d7N_P}$, where $N_p$ is the number of patches, $N_p = [\\frac{(L-P)}{S}] + 2$. We pad S repeated numbers of the last value $x \u2208 R$ to the end of the original sequence before patching to prevent losing information at the end of the sequences. The patching layer can be formalized as:\n$X_P = Patching(X)$ (1)\nwhere $X_P \u2208 R^{M\u00d7P\u00d7N_P}$ are the patches of the input multivariate time series X. After the patching layer, the number of input tokens is reduced from L to approximately L/S, which is helpful in reducing the memory usage and computational complexity when fine-tuning the LLM decoder later."}, {"title": "3.2.2 Patch-wise Temporal Convolution Encoder (PTCEnc)", "content": "We put the patches of the input $X_P$ into PTCEnc to align the time series representations to the input of LLMs, i.e. text token embeddings. Inspired by the Temporal Convolutional Network (TCN) [27], PTCEnc is a structure consisting of stacked causal"}, {"title": "3.2.3 LLM Decoder with LoRA Fine-tuning", "content": "We employ decoder-based LLMs as the backbone to extract time series representations. Inside the LLM block, we apply LoRA [28], a Parameter-Efficient Fine-Tuning (PEFT) method to inject trainable rank decomposition matrix A and B into each Transformer block in the LLM to reduce the size of trainable parameters. To leverage the sequential ability of LLMs, we apply LoRA to fine-tune the Query, Key and Value parameters of attention layers in LLMs. We denote the rank of the LoRA module by r, which is a hyperparameter reflecting the amount of information the module can contain. Assuming that the input of Query and Key in an attention layer is $h_0$ with size d and the output is h with size k, then $A \u2208 R^{d\u00d7r}$, $B\u2208 R^{r\u00d7k}$, and $r < min(d, k)$. This process can be formalized as:\n$h = W_0h_0 + \\frac{\u03b1}{r}ABh_0$, (3)\nwhere $W_0$ denotes the pretrained weight matrix, \u03b1 is a hyperparameter that acts similarly to the learning rate. We trained the attention-related parameters in each layer and used the representation of the last hidden state as the output of the LLM decoder."}, {"title": "3.2.4 Classification Head and Loss Function", "content": "We perform a skip connection with an element-wise addition of outputs from the PTCEnc and LLM decoder to fuse the two embeddings. Lastly, We flattened the fused embedding H and fed them through the final MLP-based classification head, which outputs a vector with probabilities of each time series class. This process can"}, {"title": "4 Experiments", "content": "In our experiments, we first demonstrate that our model consistently outperforms all baselines in 1-shot learning. Second, we discuss model performance in K-shot learning scenarios, with the conclusion that with the increase of k, the model performance increases, but the marginal benefit diminishes. We also provide the average accuracy when training on the full datasets, and our model can achieve a competitive performance with all baselines. Besides, the results for different LLMs in our framework show that choosing LLMs is also a data-centric task, especially since Large LLMs do not work for small datasets. Additionally, we conduct an ablation study to validate the effectiveness of each component in our model. We conduct key hyperparameter sensitivity analysis, and their values should be chosen based on the dimension and sequence length of the dataset. Finally, we assessed inference time and memory cost."}, {"title": "4.1 Experimental Setup", "content": ""}, {"title": "4.1.1 Datasets", "content": "Following [23], we choose 10 MTSC datasets from the UEA Archive [29], covering different fields: EthanolConcentration (EC), FaceDetection (FD), Handwriting (HW), Heartbeat (HB), JapaneseVowels (JV), PEMS-SF (PS), SelfRegulationSCP1 (SCP1), SelfRegulationSCP2 (SCP2), SpokenArabicDigits (SAD), and UWaveGestureLibrary (UGL). These datasets provide different characteristics, with a range of features from 3 to 963, sequence length up to 1751 and the number of classes up to 26."}, {"title": "4.1.2 Baselines", "content": "We included 11 state-of-the-art baselines from different categories for a comprehensive comparison.\n\u2022 MLP-based Method\n\u2022 DLinear [30]: a combination of a decomposition scheme used in Autoformer and FEDformer with linear layers.\n\u2022 CNN-based Method\nTimesNet [31]: uses a parameter-efficient inception block to discover multiple periods and capture temporal 2D-variations.\n\u2022 Transformer-based Methods\nAutoformer [32]: a decomposition architecture with an Aoto-Correlation mechanism.\nCrossformer [33]: a Transformer-based model utilizing cross-dimension dependency for MTS forecasting.\nFEDformer [34]: a frequency enhanced decomposed transformer.\nInformer [35]: an efficient transformer-based model with a ProbSparse self-attention module.\nPatchTST [26]: uses segmentation of time series into subseries-level patches and channel-independence mechanism.\nReformer [36]: uses locality-sensitive hashing and reversible residual layers for efficient transformer.\nVanilla Transformer [37]: the classical transformer architecture.\n\u2022 Contrastive-based Method\nTF-C [5]: a Time-Frequency Consistency mechanism for contrastive learning.\n\u2022 LLM-based Method\nOneFitsAll [23]: a unified framework that uses a frozen pre-trained language model for all major types of time series analysis tasks.\nSome of the baselines were originally developed for forecasting tasks and later extended to classification tasks. To make a fair comparison, we implement baselines with their official codes."}, {"title": "4.1.3 Few-shot Evaluation", "content": "We use classification accuracy to evaluate models and calculate an average accuracy to comprehensively demonstrate model capabilities. We conduct an N-way-K-shot classification task. In K-shot learning scenarios, we randomly select K samples from each class to conduct a K-shot training dataset. We report the accuracy performance only on the test dataset, which is the same as the classic evaluation for model training on the full train dataset."}, {"title": "4.1.4 Implementation Details", "content": "We conduct all experiments on a Linux interactive high-performance computing machine with 2 Nvidia A40 GPUs, each with 48GB of memory and CUDA 11.8. We use bfloat16 to speed up the LoRA fine-tuning and inference of LLMs and reduce the memory usage simultaneously. We set the training epoch as 200 and the learning rate as 0.0002 with decaying 80% every 50 epochs. All reported experimental results are averages of over 5 runs to avoid the impact of randomness brought by hardware equipment. See Section 3 in the Appendix for more details on implementation and hyperparameter settings."}, {"title": "4.2 Result Analysis", "content": ""}, {"title": "4.2.1 Overall Performance", "content": "Table 2 compares the classification accuracy of LLMFew against all baselines on 10 UEA real-world datasets under the 1-shot learning setting, i.e. only 1 sample per class in the training dataset. To make a fair comparison with OneFitsAll, in Table 2, the results for LLMFew are implemented by GPT2-117M, not the best performance among all kinds of LLMs. We discuss the performance difference in the latter Section. Overall, LLMFew outperforms all other baselines. Notably, LLMFew is particularly effective on challenging datasets, especially for HW and EC datasets, with 152.2% and 50.2% improvements, respectively. These two datasets can be considered hard because HW has the most classes of 26, and EC includes an extremely long time series at the length of 1751, compared to the other datasets in the benchmark. The satisfactory performance with EC also shows that our model can activate LLM's long sequence modeling ability in the time series field. However, LLMFew has not achieved a significant improvement on the PS dataset. PS is a traffic dataset characterized by exceptionally high dimensionality with 963 features. This phenomenon prompts us to consider how to model the relationships between features in the MTSC task as dimensions increase, particularly to support classification outcomes in domains like traffic datasets where the relationships between dimensions are very closely intertwined.\nAdditionally, there are some important insights related to the baselines. The well-known end-to-end Transformer-based time series models have failed to achieve satisfactory performance, demonstrating that pre-training knowledge in LLMs is essential and that the Transformer structure alone is insufficient for few-shot MTSC tasks. Besides, the TF-C model, initially pre-trained on a sleep ECG dataset, was fine-tuned with our dataset. Despite this, the results were highly variable across different datasets. It delivered a satisfactory performance on SCP2, ranking second, but struggled significantly with the HW dataset, showing almost no learning. This observation underscores a critical challenge in few-shot learning with traditional approaches-the distributional disparity between the source and target datasets. Another noteworthy observation is that OneFitsAll, which utilizes a partially frozen GPT as its backbone, does not exhibit outstanding performance in few-shot scenarios. In this approach, only the positional embedding and normalization layers are trained, making the operation more akin to directly mapping time series representations to the text semantic space of LLMs. This direct design is efficient but lacks interpretability. LLMs struggle to understand modalities that are not present in their pre-trained datasets. This highlights the necessity of fine-tuning, as LLMs must learn unique information from time series data to effectively integrate it with their existing world knowledge."}, {"title": "4.2.2 K-shot Learning Performance", "content": "Figure 3 shows the average classification accuracy for baselines and LLMFew with K-shot setting\u00b9. It can be concluded that, for all models, performance improves as k"}, {"title": "4.2.3 Results with Full Train Datasets", "content": "Figure 4 presents the results using the classical training paradigm, where the model is trained on all available samples and evaluated on the test dataset. This is the same evaluation method used for classical end-to-end models in [23]. This analysis was conducted to evaluate how our model's performance evolves as the number of training samples increases (beyond just a few) and to determine if it can effectively learn from these additional samples. The model is expected to demonstrate robustness to varying sample sizes. LLMFew consistently outperforms all state-of-the-art baselines, proving that its performance is both satisfactory and reliably stable for MTSC tasks.\nFigure 4 displays the average classification accuracy for each model across 10 datasets, representing the overall performance of the models."}, {"title": "4.2.4 Performance of Different Sizes of LLMs", "content": "Table 3 shows the classification accuracy of LLMFew variants with different LLMs, including GPT2 small, medium, and large versions (117M, 345M, and 774M) [38], Qwen (0.5B and 1.5B) [39], Phi3 (3.8B) [40] and Llama3 (8B) [41]. To ensure a fair comparison among the LLM variants, we used LoRA to fine-tune the same set of parameters, specifically the Q, K, and V parameters within the attention layers. We selected LLMs with varying parameter sizes to explore the potential for a scaling law [42], where LLMs with more parameters might demonstrate superior performance on our specific topic. Because of GPU memory limitations, we did not include larger LLMs (e.g., Llama2-13B) in our analysis. Across all datasets, it's difficult to draw a straightforward conclusion regarding the relationship between LLM size and performance. However, the choice of LLM might depend on the specific dataset. For example, the JV dataset, which has a dimension of 12 and a length of 29, achieves state-of-the-art performance with an LLM of approximately 300M parameters. Conversely, the PS"}, {"title": "4.2.5 Ablation Study", "content": "To evaluate the effectiveness of each component and its contribution to overall classification accuracy, we developed three variants of LLMFew, with their accuracy reported in Table 4. The w/o PTCEnc variant replaces the PTCEnc with a simple 1D convolution module, aligning the input feature dimensions with the LLM embedding dimensions. The Frozen variant bypasses LoRA for fine-tuning the LLM's parameters by freezing them and instead trains only the PTCEnc and classification head. Lastly, the w/o LLM variant removes the LLM decoder, feeding the time series embedding (i.e., the output of the PTCEnc) directly to the classification head. With the removal of each component from our framework, performance degrades to varying degrees. Across all four datasets, Frozen achieves the second-best performance, demonstrating that the LLM's pre-trained capabilities are valuable in MTSC, even without fine-tuning its parameters. When comparing with w/o LLM, it's evident that the frozen LLM decoder plays a significant role in enhancing overall performance. Additionally, the PTCEnc plays a crucial role in effectively learning and aligning the MTS input with the LLM's embedding space, particularly in the HW dataset with the largest number of classes."}, {"title": "4.2.6 Inference Time and Memory Cost", "content": "Figure 5 shows the inference time and memory usage for LLM-based methods (One-FitsAll and LLMFew variants) on the PEMS-SF dataset, which can be considered as the most difficult one among 10 datasets. We also report the average classification accuracy for all models. The satisfactory model should have competitive performance with low memory usage and short inference time. So, we expect the model to appear in the upper left corner with a small dot. It is worth noting that on the PEMS-SF dataset, it is not the case that the larger the model, the better the performance. This"}, {"title": "4.2.7 Hyperparameter Sensitivity Analysis", "content": "This section aims to explore how specific hyperparameters in the patching layer and PTCEnc influence the model's performance. Figure 6 illustrates the impact of key hyperparameters in the patching layer and PTCEnc. We choose 4 different values for the parameters and evaluate their performance. We choose {128, 256, 512, 1024} for the convolution hidden state size, {1, 2, 3, 4, 5} for the depth of stacked layers, {3, 4, 5, 6, 7} for the convolution kernel size, and {(16,8), (32, 16), (64, 32), (128, 64)} for the patch length and stride. Different datasets exhibit varying optimal hidden channel sizes depending on their sizes and complexities. Larger hidden channel sizes can capture more information but may lead to overfitting and slower training speeds. A similar conclusion applies to the depth of the temporal convolution structure. Deeper layers have larger dilation factors and wider receptive fields, enabling them to learn coarse and global temporal relationships. However, as the number of layers increases, the model also becomes more prone to overfitting. The kernel size directly influences the size of the receptive field. A kernel size that is too large may overlook local features and, due to the increased number of convolution parameters, can easily lead to overfitting, especially on datasets with limited training samples, such as in few-shot scenarios. In our experiments, a kernel size of 3 proved to be the best choice for most datasets. When selecting patch length and stride, we opted not to conduct a grid search and"}, {"title": "5 Conclusion", "content": "In this work, we address an overlooked yet critical gap in Multivariate Time Series Classification (MTSC): the few-shot learning scenarios, which are especially important when training data is limited, a common scenario in many industrial environments where obtaining labeled data is costly and time-consuming. To bridge this gap, we introduce LLMFew, a model designed to explore the potential of Large Language Models (LLMs) in few-shot MTSC tasks. LLMFew leverages the powerful pre-trained representations of LLMs, enabling effective generalization from minimal data and overcoming the bottleneck faced by traditional models in low-data regimes. Our experiments on real-world datasets including those for gesture, action, and audio recognition-demonstrate that LLMFew effectively addresses the data scarcity problem in few-shot learning. The insights gained from our study offer a promising direction for applying LLMs to other few-shot time series tasks. Moving forward, we aim to enhance the interpretability of LLMs in time series applications and further investigate which aspects of LLMs are most effective for learning temporal representations in multivariate time series."}]}