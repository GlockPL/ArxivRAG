{"title": "AnomalySD: Few-Shot Multi-Class Anomaly Detection with Stable Diffusion Model", "authors": ["Zhenyu Yan", "Qingqing Fang", "Wenxi Lv", "Qinliang Su"], "abstract": "Anomaly detection is a critical task in industrial manufacturing, aiming to identify defective parts of products. Most industrial anomaly detection methods assume the availability of sufficient normal data for training. This assumption may not hold true due to the cost of labeling or data privacy policies. Additionally, mainstream methods require training bespoke models for different objects, which incurs heavy costs and lacks flexibility in practice. To address these issues, we seek help from Stable Diffusion (SD) model due to its capability of zero/few-shot inpainting, which can be leveraged to inpaint anomalous regions as normal. In this paper, a few-shot multi-class anomaly detection framework that adopts Stable Diffusion model is proposed, named AnomalySD. To adapt SD to anomaly detection task, we design different hierarchical text descriptions and the foreground mask mechanism for fine-tuning SD. In the inference stage, to accurately mask anomalous regions for inpainting, we propose multi-scale mask strategy and prototype-guided mask strategy to handle diverse anomalous regions. Hierarchical text prompts are also utilized to guide the process of inpainting in the inference stage. The anomaly score is estimated based on inpainting result of all masks. Extensive experiments on the MVTec-AD and VisA datasets demonstrate the superiority of our approach. We achieved anomaly classification and segmentation results of 93.6%/94.8% AUROC on the MVTec-AD dataset and 86.1%/96.5% AUROC on the VisA dataset under multi-class and one-shot settings.", "sections": [{"title": "1 INTRODUCTION", "content": "Anomaly detection is a critical computer vision task in industrial inspection automation. It aims to classify and localize the defects in industrial products, specifically to predict whether an image or pixel is normal or abnormal [3]. Due to the scarcity of anomalies, existing methods typically assume that it is possible to collect training data from only normal samples in the target domains. Therefore, existing mainstream anomaly detection methods mainly follow the unsupervised learning manner and can be divided into two paradigms, i.e.,reconstruction-based [18, 34, 38] and embedding-based methods [5, 6, 25]. Reconstruction-based methods mainly use generative models such as Autoencoders (AE) [27] or Generative Adversarial Networks (GAN) [11] to learn to reconstruct normal images and assume large reconstruction errors when reconstructing anomalies.\nWhile embedding-based methods aim to learn an embedding neural network to capture embeddings of normal patterns and compress them into a compact embedding space [6, 25].\nAlthough the astonishing performance achieved by previous methods, most of them assume that there are hundreds of normal images available for training. But in the real world, this assumption cannot always be fulfilled. It is likely that there are only a few normal data available due to the high cost of labeling or data privacy policies, which is called the few-normal-shots setting. Under such a scenario, performance degeneration of traditional anomaly detection methods is observed as they require abundant normal data to well capture the normal pattern [30]. Parallel to this, the bulk of existing works follow the one-for-one paradigm as shown in Figure 1(a), which needs to train a bespoke model for each category. This paradigm results in heavy computational and memory costs and more resources are required to store different models. Moreover, the one-for-one paradigm is not flexible for real-world applications. In practice, different components may be produced on the same industrial assembly line, which needs to switch different models to detect different anomalies or deploy multiple networks with different weights but the same architecture. The additional expenses caused by the lack of flexibility are completely prodigal.\nThe issues mentioned above have been already noticed in the most current study. Given only a few normal data, enlarging the training dataset [16, 33] and patch distribution modeling [26, 30] are promising approaches. GraphCore [33] directly enlarges the normal feature bank through data augmentation and trains a graph neural network on it to figure out anomalies. RegAD [16] is based on contrastive learning to learn the matching mechanism, which is"}, {"title": "2 RELATED WORK", "content": "Anomaly Detection. The mainstream anomaly detection meth-ods can be divided into two trends: embbeding-based methods,reconstruction-based methods. Embedding-based methods primar-ily detect anomalous samples in the feature space. Most of thesemethods utilize networks pre-trained on ImageNet [9] for featureextraction and then calculate the anomaly score by measuring thedistance between anomalous and normal samples in the featurespace [5, 6, 25]. While some embbeding-based methods employknowledge distillation to detect anomalies based on the differencesbetween teacher and student networks [4, 8]. Reconstruction-basedmethods primarily aim to train the model to learn the distributionof patterns in normal samples. AE-based methods [10, 41] and in-painting methods [18, 34, 38] are both based on the assumptionthat the model can effectively reconstruct normal images but failwith anomalous images, resulting in large reconstruction errors. Inthe case of VAE-based generative models [7, 21] learn the distributionof normal in the latent space. Anomaly estimation is carriedout by assessing the log-likelihood gap between distributions. ForGAN-based generative models [1, 2, 14, 19, 28, 29], the discrimi-nator compares the dissimilarity between test images and imagesrandomly generated by the generator as a criterion for anomalymeasurement.\nFew-Shot Anomaly Detection. Few-shot anomaly detectionis developed for the situation where only a few normal data areavailable. TDG [30] proposed to leverage a hierarchical generativemodel that learns the multi-scale patch distribution of each supportimage. DiffNet [26] normalizing flow to estimate the density offeatures extracted by pre-trained networks. To compensate for thelack of training data, RegAD [16] introduced additional datasets tolearn the matching mechanism through contrastive learning andthen detect anomalies by different matching behaviors of samples.Although these methods can handle the few-shot anomaly detectiontask, none of them take the multi-class setting into consideration.Recently, WinCLIP [17] revealed the power of pre-trained vision-language model in few-shot anomaly detection task. It divides theimage into multi-scale patches and utilizes CLIP [22] to calculate thedistance between patches and the designed description of normalityand anomaly as the anomaly score. Thanks to the generalizationability of CLIP [22], WinCLIP also has the ability to handle multi-class setting."}, {"title": "3 PRELIMINARIES", "content": "3.1 Denoising Diffusion Probabilistic Model\nThe Denoising Diffusion Probabilistic Model (DDPM) [13] is a typeof generative model inspired by the data diffusion process. DDPMconsists of a forward diffusion process and a reverse denoisingprocess. In the forward diffusion process, at every time step, weadd a small noise into the data as \\(x_{t} = \\sqrt{1 - \\beta_{t}}x_{t-1} + \\sqrt{\\beta_{t}}\\epsilon_{t}\\), wherexo denotes the original image; \\(\\epsilon_{t} \\sim N(0, I)\\) represents the standardGaussian noise; and \\(\\beta_{t}\\) is used to control the noise strength addedat the time step t, which is often a very small value from \\( \\in (0, 1)\\). Itcan be easily shown that \\(x_{t}\\) can be directly obtained from \\(x_{0}\\) as\n\\(x_{t} = x_{0} \\sqrt{\\bar{a}_{t}} + \\epsilon_{t} \\sqrt{1 - \\bar{a}_{t}},\\)\n(1)\nwhere \\(\\bar{a}_{t} = \\prod_{i=1}^{t} a_{i}\\) with \\(a_{i} \\simeq (1 - \\beta_{i})\\). In DDPM, it seeks to learnthe reverse process of the forward diffusion process by learning amodel to predict \\(x_{t-1}\\) solely based on \\(x_{t}\\). It is shown in DDPM that"}, {"title": "3.2 Stable Diffusion Model", "content": "Based on DDPM, the Stable Diffusion Model(SD) [23] introduces apre-trained AutoEncoder with the encoder \\(&(\\cdot)\\) to compress imagex into latent representation \\(z = & (x)\\) and the decoder \\(D(\\cdot)\\) to recover the latent features to image \\(D(z)\\). The adaptation of AutoEn-coder helps SD to generate high-resolution images in good qualitywhen the DDPM process is utilized in the latent space by replacing xin Sec 3.1 with z. Besides, SD introduces the condition mechanismsto guide the generation of images by the cross-attention modulesin the denoising U-Net. For the condition y, SD first encodes it by apre-trained encoder \\(\\tau(\\cdot)\\), like CLIP text encoder for text condition.Then, SD introduces the condition y into the i-th intermediate layerof U-Net with a cross-attention mechanism\n\\(attention(Q, K, V) = softmax (\\frac{Q K^{T}}{\\sqrt{d}}). V,\\)\n(4)\nwith \\(Q = W_{Q}^{(i)} \\epsilon_{\\theta}(z_{t})\\), \\(K = W_{K}^{(i)} \\tau(y)\\), \\(V = W_{V}^{(i)} . \\tau(y)\\), where\\(\\epsilon_{\\theta}^{(i)} (z_{t})\\) represents the flattened output from the intermediate layeri of denoising network \\(\\epsilon_{\\theta}(\\cdot)\\), \\(W_{Q}^{(i)} \\in R^{d\\times d}\\), \\(W_{K}^{(i)}, W_{V}^{(i)} \\in R^{d\\times d\\tau}\\)are learnable weight parameters. Using the attention mechanisms,conditional information like text prompt can be introduced to guidethe denoising process, leading to the training objective function\n\\(L_{SD} = E_{\\&(x), y, \\epsilon \\sim N(0,I), t \\sim [1,T]} [|| \\epsilon - \\epsilon_{\\theta}(z_{t}, t, \\tau(y) ||^{2}].\\)(5)\nIn our paper, the conditional information y specifically refers totextual prompts and \\(\\tau(\\cdot)\\) means the text encoder in CLIP. Withthe learned denoising network \\(\\epsilon_{\\theta} (z_{t}, t, \\tau(y))\\) in SD, we first samplea standard Gaussian noise \\(z_{T}\\) and then feed it into the denoisingnetwork. After many steps of denoising, a denoised latent repre-sentation \\(z_{0}\\) is obtained, which is then passed into the pre-traineddecoder \\(D(\\cdot)\\) to produce the image x."}, {"title": "4 THE PROPOSED METHOD", "content": "For the few-shot anomaly detection and localization, we assumethe availability of several normal images from multi-classes C:\n\\(X_{N} = \\{X_{1}, X_{2},..., X_{c}\\},\\)\n(6)\n\\(X_{c} = \\{x_{c,1},..., x_{c,K}\\}.\\)\nThe collected dataset comprises various texture and object imagesfrom different classes in which the possible value c can be carpets,bottles, zippers and other categories. The number of images avail-able for each class is limited, with only K shots available, with K"}, {"title": "4.1 Adapt SD to Anomaly Detection", "content": "Distinguishing from the SD for image generation tasks, adaptingSD for anomaly detection requires to accurately inpaint anoma-lous areas into normal ones. To achieve this target, we specificallyfine-tune the denoising network and decoder of VAE in SD foranomaly detection. With only few shots of normal samples frommulti-classes, to obtain a unified model that can be applied to allcategories, we specifically design mask m and prompt y to guidethe fine-tuning process of the inpainting pipeline of SD.\nGiven an image \\(x \\in R^{3\\times H\\times W}\\) and mask \\(m\\in \\{0,1\\}^{H\\times W}\\), wefirst encode the original image x and masked image \\((1-m) \\cdot x\\) bythe encoder of VAE in SD, get \\(z = & (x)\\) and \\(z^{*} = & ((1 - m) \\cdot x)\\).Through the forward diffusion process, we can get the noisy latentfeature of timestamp t by:\n\\(z_{t} = z_{0} \\sqrt{\\bar{a}_{t}} + \\epsilon_{t}\\sqrt{1 - \\bar{a}_{t}}, \\ \\ \\ \\  \\epsilon_{t} \\sim N(0, 1),\\)\n(7)\nwhere \\(z_{0} = z\\) is the feature of timestamp 0. The mask m can also bedownsampled to the same size of z and results as \\(\\tilde{m}\\). By concatenate"}, {"title": "4.2 Inpainting Anomalous Areas in Images with Finetuned SD", "content": "For an image x, if there is a given mask m which can mask mostparts of the anomalous areas, we can utilize the fine-tuned SDto inpaint the masked area and obtain a inapinted image \\(\\tilde{x}\\). In the inference stage of fine-tuned SD, if we use standard Gausiannoise \\(z \\sim N(0, I)\\) as the starting step of the denoising process, thegenerated images could show significant variability comparing withthe original ones, making them not suitable for anomaly detectionand localization.\nTo address this issue, we control the added noise strength bysetting the starting step of the denoising process at \\(T = \\lambda \\cdot T\\), where\\(\\lambda \\in [0, 1]\\). Given the latent feature \\(z = & (x)\\), we get a noisy latent"}, {"title": "4.3 Anomaly Score Estimation", "content": "For a test image x, we can get its corresponding inpainted image \\(\\tilde{x}\\)which are assumed to be recovered into normal ones. However, thedifference between inpainted and original images is hard to mea-sure at pixel level which only has 3 channels. Considering LPIPSloss used in fine-tuning the decoder of VAE, we also use featuresextracted from pre-trained AlexNet to measure the difference be-tween x and \\(\\tilde{x}\\). For the features extracted from layer l of AlexNet,the distance of original and inpainted images in position (h, w) ofcorresponding feature maps can be calculated as\n\\([D^{(l)}(x, \\tilde{x})]_{h,w} =|| w^{(l)} \\odot ([\\phi^{(l)}(x)]_{h,w} - [\\phi^{(l)}(\\tilde{x})]_{h,w}) || .\\)(16)\nWe upsample \\(D_{l}\\) to the image size and add distances from all layersto get the score\n\\(D(x, \\tilde{x}) = \\sum_{l} Upsample(D^{(l)}(x, \\tilde{x})).\\)(17)\nFor the multi-scale masks, in scale k, using every mask \\(M_{i,j}^{(k)}\\)can get inpainted image \\(\\tilde{x}\\), thus distance map \\(D(x,\\tilde{x})\\) can beobtained according to (17). For the scale k, combining masks fordifferent patches, we can get a score map\n\\(\\tilde{S}^{(k)} = \\sum_{i,j} D(x, \\tilde{x}).\\)(18)\nAggregating different scale anomaly maps by harmonic mean, wecan get the final anomaly map from multi-scale masks:\n\\(S_{ms} = |K| (\\sum_{k\\in K} [\\tilde{S}^{(k)}]^{-1})^{-1}\\)(19)"}, {"title": "5 EXPERIMENT", "content": "5.1 Experimental Setups\nDatasets. Our experiments are conducted on the MVTec-ADand VisA datasets, which simulate real-world industrial anomaly\nevaluation metrics. Referring to previous work, in image-levelanomaly detection, we utilize metrics such as the Area Under theReceiver Operating Characteristic Curve (AUROC), Average Preci-sion (AUPR), and F1-max for better evaluation under situation ofdata imbalance. For pixel-level anomaly localization, we employpixel-wise AUROC and F1-max, along with Per-Region Overlap(PRO) scores."}, {"title": "5.4 Conclusion", "content": "We propose a SD-based framework AnomalySD, which detects andlocalizes anomalies under few shot and multi-class settings. Weintroduce a combination of hierarchical text prompt and mask de-signs to adapt SD for anomaly detection and use multi-scale masks,prototype-guided masks to mask anomalies and restore them intonormal patterns via finetuned SD. Our approach achieves competi-tive performance on the MVTec-AD and VisA datasets for few-shotmulti-class anomaly detection. For further improvement, adaptiveprompt learning and noise guidance is a promising direction to reduce the reliance on manually set prior information and transitionto a model-adaptive learning process."}]}