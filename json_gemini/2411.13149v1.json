{"title": "YCB-LUMA: YCB Object Dataset with Luminance Keying for Object Localization", "authors": ["Thomas P\u00f6llabauer"], "abstract": "Localizing target objects in images is an important task\nin computer vision. Often it is the first step towards solving a variety\nof applications in autonomous driving, maintenance, quality insurance,\nrobotics, and augmented reality. Best in class solutions for this task rely\non deep neural networks, which require a set of representative training\ndata for best performance. Creating sets of sufficient quality, variety,\nand size is often difficult, error prone, and expensive. This is where the\nmethod of luminance keying [10,8] can help: it provides a simple yet ef-\nfective solution to record high quality data for training object detection\nand segmentation. We extend previous work that presented luminance\nkeying on the common YCB-V set of household objects [14] by record-\ning the remaining objects of the YCB superset. The additional variety\nof objects addition of transparency, multiple color variations, non-rigid\nobjects further demonstrates the usefulness of luminance keying and\nmight be used to test the applicability of the approach on new 2D object\ndetection and segmentation algorithms.", "sections": [{"title": "1 Introduction", "content": "Deep learning-based algorithms dominate the task of object detection deliver-ing state-of-the-art accuracy, but relying on the availability of large volumes\nof high-quality annotated training data. As highlighted in previous work, Deep\nNeural Networks (DNNs) demand substantial annotated datasets to achieve op-timal performance. Traditionally, this data is obtained through manual label-ing, which is both error-prone and time-consuming, or through rendering, which\nnecessitates detailed geometry and material information. These methods pose\nsignificant challenges, particularly for small-scale applications where resources\nand time are limited, making it uneconomical to generate the required data.\nA streamlined and efficient method for acquiring high-quality training data\ncan significantly broaden the applicability of deep learning techniques, even for\nniche applications. While chroma keying has been a popular technique for back-ground replacement in image processing, it often suffers from issues such as color"}, {"title": "2 Related Work", "content": "The YCB object set has proven to be a valuable contribution to the field. Espe-cially its subset YCB-V is of great importance to the evaluation of the 6 degrees\nof freedom pose estimation problem and has been included as a \"classic core\ndataset\" into the Benchmark of Pose Estimation algorithms (BOP) [4,5,6,13].\nAdditional efforts were invested to extend the dataset to evaluate additional\nmodalities such as neuromorphic cameras [11,12], stereo vision [9], and multi-camera setups [2].\nLuminance keying as described in [10] follows the tradition of previous meth-ods, placing the target objects in front of different colors used for keying, such\nas white, green, or gray [3,7,15], or more complex backgrounds such as checker-boards [1], extracting the objects from the background and - using image aug-mentation methods use the data to fit the target algorithm. Compared to\nprevious methods focusing on color, luminance keying proved to be simpler to\nuse while using the data to train 2D detectors outperformed chroma keying using\na typical green screen [10]."}, {"title": "3 Methodology", "content": "Following the method of data recording with luminance keying, utilizing a 99.99%\nlight absorbing background [10], we record the additional objects as found in the\nYCB dataset. These new recordings complement the original ones depicting all\nof the objects to be found in the YCB-V subset. All of the newly recorded ob-jects are represented in Figure 1. Additional relevant meta data is presented in\nFigure 2.\nIn contrast to the YCB-V subset, the new objects contain a wider range of\nappearances: there are now multiple transparent objects, such as objects made\nof transparent plastics and others made of glass, more metallic surfaces, such as\non the fork, knife, and spoon, multiple alterations of the same objects, such as\nthe same lego pieces, but of different colors, as well as deformable objects, such\nas the yellow chain and the white piece of cord. Whenever there are multiple\nvariations of a target object, we differentiate between them by creating separate\nsubfolders. This allows to test for generalization, for instance, by training on one\nvariation and testing on another, or to combine all variations within the training\nor test set, if required.\nFor easy processing of these and other objects, which have been recorded fol-lowing the same setup, we provide some scripts to automatically extract training\ndata for 2D object detector training from the recordings."}, {"title": "4 Discussion", "content": "We extended the previously available recordings of the YCB-V object dataset by\nthe remaining YCB objects, following the luminance keying approach. Our data\nallows for performance evaluation of 2D object detectors and segmentation algo-rithms. We provide our recordings, together with processing code for automated\nmasking, at https://huggingface.co/datasets/tpoellabauer/YCB-LUMA and\nhttps://github.com/tpoellabauer/ycb-luma.\nIf you are interested in the full YCB dataset, please also download the YCB-V\nsubset from https://huggingface.co/datasets/tpoellabauer/YCB-V-LUMA."}]}