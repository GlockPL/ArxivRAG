{"title": "ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources", "authors": ["Shuting Yang", "Zehui Liu", "Wolfgang Mayer", "Ningpei Ding", "Ying Wang", "Yu Huang", "Pengfei Wu", "Wanli Li", "Lin Li", "Hong-Yu Zhang", "Zaiwen Feng"], "abstract": "Recent developments in large language models (LLMs) have led to significant improvements in intelligent dialogue systems' ability to handle complex inquiries. However, current LLMs still exhibit limitations in specialized domain knowledge, particularly in technical fields such as agriculture. To address this problem, we propose ShizishanGPT, an intelligent question answering system for agriculture based on the Retrieval Augmented Generation (RAG) framework and agent architecture. ShizishanGPT consists of five key modules: including a generic GPT-4 based module for answering general questions; a search engine module that compensates for the problem that the large language model's own knowledge cannot be updated in a timely manner; an agricultural knowledge graph module for providing domain facts; a retrieval module which uses RAG to supplement domain knowledge; and an agricultural agent module, which invokes specialized models for crop phenotype prediction, gene expression analysis, and so on. We evaluated the ShizishanGPT using a dataset containing 100 agricultural questions specially designed for this study. The experimental results show that the tool significantly outperforms general LLMs as it provides more accurate and detailed answers due to its modular design and integration of different domain knowledge sources. Our source code, dataset, and model weights are publicly available at https://github.com/Zaiwen/CropGPT.", "sections": [{"title": "1 Introduction", "content": "Recently, the advancement of large model technology has marked a significant milestone in the field of artificial intelligence, showcasing impressive performance"}, {"title": "2 Related Works", "content": "This section reviews related works on enhancing large language models (LLMs), focusing on the integration of Retrieval Augmented Generation (RAG) and agent-based frameworks, the use of knowledge graph-enhanced models, and the application of external tools. It also discusses the implementation of knowledge graphs in agriculture, showcasing how these technologies improve the accuracy and utility of large models in complex tasks."}, {"title": "2.1 RAG and Agent-Based Frameworks for LLM Enhancement", "content": "Since the advent of LLMs like ChatGPT, these models have excelled in a variety of language tasks [6] but still face challenges such as hallucinations [7], outdated knowledge, and data constraints that affect their reliability, especially in tasks requiring extensive and precise knowledge like open-domain question answering and commonsense reasoning. The implementation of RAG has provided a pathway to address some of these limitations by enhancing the response accuracy of LLMs in knowledge-intensive scenarios. The concept of Retrieval-Augmented Generation, initially proposed by Lewis et al [8]. RAG has significantly enhanced the effectiveness of LLM responses by providing contextual grounding from existing documents during the generation process [9]. RAG merges the retrieval and"}, {"title": "2.2 Knowledge Graph Enhanced Large Models", "content": "LLMs have become an important technology in modern AI, especially in the field of Natural Language Processing (NLP), and are widely used in a variety of language understanding and generation tasks. These models, such as OpenAI's GPT family, Google's BERT [12] and T5 [13], Facebook's BART [14], LLama [15], learn rich linguistic, contextual, and knowledge information by pre-training on large-scale datasets, enabling them to perform various linguistic tasks without explicit task instructions. In particular, LLMs have demonstrated exceptional capabilities in question-answering systems. These models can provide exhaustive answers and generate innovative answers in specific situations by learning from data, facts and world knowledge. For example, GPT-3 [16], with its large model structure and training data, can answer complex questions without external database support.\nTo further improve answer quality and accuracy, knowledge graphs and external tools are becoming increasingly important in modern LLM-based QA systems. For example, in December 2023, a research team from China Agricultural University (CAU) released 'Shennong Big Model 1.0' [17], an industry big model applied to the agricultural field. The model is trained from a large amount of high-quality agricultural knowledge data, including more than 10 million agricultural knowledge mapping data, more than 50 million modern agricultural production data and more than 20,000 agricultural books. Based on the traditional big model technology architecture, it integrates knowledge graph, vector database and other technologies to improve the accuracy of the answers."}, {"title": "2.3 External Tools Enhanced Large Models", "content": "Tool-enhanced Large Language Models (LLM) and agent-based large language models frameworks have received much attention for their application in agriculture. The Tool Augmented Large Language Model framework utilises information from external tools to enhance the capabilities of the language model. [18]"}, {"title": "2.4 Knowledge Graphs in Agriculture", "content": "In agriculture, researchers are harnessing knowledge graphs to boost production efficiency and sustainability. These graphs amalgamate diverse agricultural data, aiding in decision-making and providing precise management solutions.\nKnowledge graphs, with their structured representation of knowledge, enhance the interpretability of large language models used in their training [23]. Therefore, introducing knowledge graphs in the training process of large language models helps to improve the interpretability of large language models. For example, Rezayi et al [24] proposed the AgriBERT model for matching food and nutrients. The model, based on the structure of the BERT language model, was pre-trained on a corpus dataset of academic journals and fine-tuned by augmenting the answers with a map of agricultural expertise, and the results showed a significant improvement in the matching ability of the model. AgriKG [25], a comprehensive agricultural knowledge graph utilized in this study, employs natural language processing to extract and connect entities and their relationships from extensive agricultural data. This graph supports applications such as entity retrieval and intelligent QA. Leveraging AgriKG, this study develops an intelligent QA system using large-scale language models. This system integrates AgriKG's data with user queries to deliver effective QA services."}, {"title": "3 System Design", "content": null}, {"title": "3.1 Design of Prompt", "content": "In order to ensure that the model is able to generate relevant and accurate responses to the complex needs of the agricultural domain, special attention"}, {"title": "3.2 Workflow of System", "content": "The general workflow of the system is as follows: When a user inputs a question, the system analyzes the question and selects the most relevant type of problem description from its various functional modules. It then calls the appropriate tools to complete the task. After receiving feedback, the large language model dynamically adjusts the next step of the plan based on the feedback. Finally, it summarizes based on the results and its own knowledge, ultimately providing the user with a clear and useful answer. Our system employs the ReAct architecture; if the agent's first tool selection fails, it reanalyzes the problem based on the returned results, chooses other appropriate tools for iterative execution, can also decompose the problem into sub-problems, calls tools to obtain feedback, and then executes the next step based on the feedback."}, {"title": "3.3 System Architecture", "content": "We propose an intelligent QA system for agricultural knowledge based on the RAG framework and agent architecture, which adopts an integrated architecture that combines advanced artificial intelligence techniques and data management technologies, aiming to provide efficient and accurate QA services. The system comprises multiple modules optimized for a specific function to ensure comprehensive and accurate question answering, shown in Figure 2. Specifically, the system utilizes a large pre-trained language model to handle generic queries and a search engine module to access the latest agricultural data and research in real time. In addition, the system is embedded with a search vector database of specialized literature to support accurate answers to in-depth domain questions. Using the AgriKG knowledge graph, the system can provide detailed answers to complex questions about crop types, suitable growing conditions, etc. The system also integrates several small prediction models, such as maize phenotype prediction (Resnet model architecture) and rice gene promoter enrichment value prediction, to provide accurate agricultural decision support. The synergistic work of these modules, managed through a unified user interface, ensures the simplicity and efficiency of the system's operation, enabling users to get instant and accurate answers to their natural language queries, thus greatly improving the intelligence of agricultural production and management."}, {"title": "3.4 Modules in the Architecture", "content": "The modules are as follows:"}, {"title": "4 Experiments", "content": "Dataset: Since there was no suitable QA dataset to fully test system performance, we did the work of building an agricultural QA dataset. Firstly, some representative problems are found from existing agricultural databases, academic papers, agricultural knowledge websites, etc. We consider crop cultivation, agricultural technology, pest control, agricultural processing and other aspects to ensure a comprehensive and diverse set of issues. After getting the seed questions for each aspect, we used ChatGPT's help to generate some related questions to expand our problem set. The quality of the dataset is then improved by manual screening to remove duplicate questions and irrelevant content. In order to ensure the accuracy and reliability of the answers, we get the correct answers to these questions from professional agricultural websites. Finally, a dataset containing 100 high-quality question answer pairs was constructed as the experimental benchmark to evaluate and test the performance of the system in the field of agricultural QA."}, {"title": "4.1 Machine Scoring", "content": "Method: We use BLEU, ROUGE, and GLEU to score standard and system-generated answers. For each question, a reference answer on a professional agricultural website is used as the benchmark for the answer generated by the evaluation system. The answers generated by each system were scored using the following evaluation indicators.\nBLEU: Calculates the n-gram overlap between the system's generated answers and all reference answers, and calculates BLEU scores based on accuracy, recall, and n-gram matches. Relying too heavily on phrase matching in BLEU scoring is not advisable, as it may fail to consider contextual and semantic nuances. ROUGE: Calculates the degree of n-gram overlap between the system generated answer and the reference answer, and calculates the ROUGE score based on n-gram matches of different lengths. GLEU: The system evaluates the syntactic and semantic consistency between the generated answer and the reference answer, and calculates the GLEU score based on n-gram matches of"}, {"title": null, "content": "different lengths. GLEU provides a more fine-grained assessment than BLEU, but is more computationally expensive.\nA higher score indicates that the answers generated by the system are largely similar to the standard answers, while a lower score indicates a gap."}, {"title": null, "content": "Scoring Standard:\nComposite Score = a \u00d7 BLEUScore + \u03b2 \u00d7 ROUGEScore + \u03b3 \u00d7 GLEUScore"}, {"title": null, "content": "Among them, \u03b1, \u03b2,\u03b3 are the weights of each evaluation index, and \u03b1+\u03b2+\u03b3 = 1, here we set a, \u03b2, \u03b3 to 0.4, 0.4, 0.2 respectively. The following is the specific formula of each evaluation index:\nBLEUScore = BP X"}, {"title": null, "content": "Where BP is the short penalty factor and BLEUn represents the BLEU fraction of an n-gram.\nBLEUn"}, {"title": null, "content": "Count_clip(n) is the minimum number of N-grams that the system generates to match the reference answer. Count_gen(n) is the number of N-grams in the answer generated by the system.\nROUGEScore (RS) = (1-1) \u00d7ROUGEL+\u03bb\u00d7 (ROUGESU\u00d7\u03c91+ROUGELS\u00d7\u03c92)"}, {"title": null, "content": "Where A is the long sentence penalty factor, ROUGEsu is the unordered ROUGE fraction, ROUGELS is the ordered ROUGE fraction, w\u2081 and w2 are the weights,\nandw\u2081 + w2 = 1, where we set A to 0.1 and both w\u2081 and w2 to 0.5.\n4\n\u03a3"}, {"title": null, "content": "GLUEScore =\nnGLEU =\u03a3=1 GLUEn\n4\n2 \u00d7 Count_match(n)\nCount_gen(n) + Count_ref(n)"}, {"title": null, "content": "Count_match(n) is the number of N-grams matched between the system generated answer and the reference answer. Through the above formula, we can get a comprehensive score considering multiple evaluation indicators. Adjust the weights of a, \u03b2, \u03b3, \u03b4, \u03bb, \u03c9\u2081, and w\u2082, and weigh the importance of different evaluation indicators according to specific needs to get the final result.\nResult: We evaluated the performance of the ShizishanGPT in the agricultural question answering task and compared it with several other models. The results of the comparison are shown in Figure 3. We set the standard answer score in the data set to 1.0, and it can be seen that ShizishanGPT significantly outperforms"}, {"title": "4.3 Ablation Experiments", "content": "We conducted an ablation experiment to demonstrate each component's impact on our system. We disabled individual aspects of the system, such as RAG and external predictive models, and evaluated the system's performance again. We used the same QA dataset, metrics, and analysis procedure as in the previous experiment. Table 3 shows the results of our experiment for the different configurations."}, {"title": "5 Limitations", "content": "Although the results of our experiment are encouraging, it is important to discuss potential limitations.\nDataset limitations: The dataset used in this article was generated by GPT-4 and may be affected by the quality of the questions due to limitations and biases in GPT-4's training data and question generation capabilities. Since the seed problem was found manually, the representativeness of the dataset may also have certain limitations.\nScope limitations: In terms of universality and generalization, the research in this paper may only apply to a specific environment or scope of questions. The research in this article may apply only to the field of agriculture and only to specific crops and regions."}, {"title": "6 Conclusion", "content": "This study successfully integrates a knowledge graph-enhanced large-scale language model with an external tool module and a retrieval vector database module to construct a comprehensive intelligent QA system for agriculture. Experimental results show that the system exhibits good performance and accuracy in answering agriculture-related questions, and the response quality of the system is further enhanced by calling the external tool module and retrieval vector database module.\nWe have successfully demonstrated intelligent querying, reasoning, and retrieval of agricultural knowledge, providing more comprehensive and effective support for agricultural production and decision-making. In the future, we will further improve the system's responses and the scope of questions it can address to meet the growing demand for agricultural information."}]}