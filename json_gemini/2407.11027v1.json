{"title": "A robust three-way classifier with shadowed granular-balls based on justifiable granularity", "authors": ["Jie Yang", "Lingyun Xiaodiao", "Guoyin Wang", "Witold Pedrycz", "Shuyin Xia", "Qinghua Zhang", "Di Wu"], "abstract": "The granular-ball (GB)-based classifier introduced by Xia, exhibits adaptability in creating coarse-grained information granules for input, thereby enhancing its generality and flexibility. Nevertheless, the current GB-based classifiers rigidly assign a specific class label to each data instance and lacks of the necessary strategies to address uncertain instances. These far-fetched certain classification approachs toward uncertain instances may suffer considerable risks. To solve this problem, we construct a robust three-way classifier with shadowed GBs for uncertain data. Firstly, combine with information entropy, we propose an enhanced GB generation method with the principle of justifiable granularity. Subsequently, based on minimum uncertainty, a shadowed mapping is utilized to partition a GB into Core region, Important region and Unessential region. Based on the constructed shadowed GBs, we establish a three-way classifier to categorize data instances into certain classes and uncertain case. Finally, extensive comparative experiments are conducted with 2 three-way classifiers, 3 state-of-the-art GB-based classifiers, and 3 classical machine learning classifiers on 12 public benchmark datasets. The results show that our model demonstrates robustness in managing uncertain data and effectively mitigates classification risks. Furthermore, our model almost outperforms the other comparison methods in both effectiveness and efficiency.", "sections": [{"title": "I. INTRODUCTION", "content": "Granular computing (GrC) [1]\u2013[4] focuses on the formation, processing, and communication of information granules, aiming to mimic human cognitive thinking in addressing complex problems. Rough sets [5], fuzzy sets [6], and quotient spaces [7] are three primary models of GrC. Rough sets are widely used to measure the uncertainty and incompleteness inherent in information systems. To handle continuous data, neighborhood rough sets (NRS) [8] introduce the concept of neighborhood granulation to convert the equivalence relation into the covering relation in neighborhood space. Furthermore, numerous extended GrC-based classifiers [9]\u2013[13] were developed by utilizing information granules as the fundamental computational unit, enhancing the efficiency of knowledge discovery. However, a notable limitation of these classifiers is that they primarily treat granules as a preliminary feature processing method, without modifying the underlying mathematical model or elevating the core performance of the classifiers themselves.\nBased on the idea of GrC, granular-ball computing (GBC) [14]\u2013[16], introduced by Xia, represents a groundbreaking approach to data processing and knowledge representation. This method replaces traditional information granule inputs with granular-balls (GBs), adhering to the principle of global topology precedence [17]. Over the years, GBC has undergone continuous advancements in terms of its methodologies and applications. Xia [18] proposed the GB-based kNN, which significantly outperforms the existing kNN in terms of efficiency, especially when dealing with large-scale datasets, achieving an improvement of hundreds of times. Furthermore, Xia [19] introduced a novel rough sets model, namely, granular-ball rough sets (GBRS). Compared to traditional NRS methods, GBRS stands out as a multi-granularity learning tool, offering greater robustness and efficiency by substituting neighborhood granules with GBs. In addition, Chen [20] proposed a GB-based attribute selector to achieve the superior classification performance through effective feature reduction. Xie [21] introduced a fast and stable GB generation method based on the attention mechanism. Xie [22] constructed a multi-granularity representation of the data using the GBC model, thereby boosting the algorithm's time efficiency. Chen [23] innovated by introducing a novel GB-based density peaks clustering, resulting in significantly reduced runtime without the need for parameterization. However, current researches on GB generation in GBC only consider the purity thresholds to control the granularity of GB space, which is not in accord with various practical applications.\nFrom the perspective of the justifiable granularity principle [24]\u2013[26], both coverage and specificity should be taken into account during the GB generation process. Coverage refers to a GB that encompass as much experimental evidence (data) as possible. Specificity refers to all GBs generated on the universe having distinct and well-defined semantics or all GBs being well distinguished from each other. Typically, the fewer the data instances in a GB, the higher the specificity. Therefore, it is significant to generate justifiable GB space to solve problems by combining with the level of coverage and specificity. Moreover, the above GB-based classification methods rigidly ascribe a fixed class label to each data instance, lacking strategies to handle instances with uncertainty. The methodology of uncertain data classification is invaluable in mitigating decision risk and enhancing decision efficiency through human-machine collaboration, thus playing a pivotal role in decision support systems. For instance, when applying classification methods to develop a computer-aided diagnosis (CAD) system for liver cancer [27], it is crucial to accurately classify uncertain tumors for further cautious diagnosis and certain far-fetched classifications produced by the system may cause serious costs.\nAs is well known, three-way decision (3WD) [28]\u2013[30] theory proposed by Yao has emerged as a promising approach to tackle complex problems involving uncertainty. The fundamental principle of 3WD lies in dividing a universe into three distinct regions, with each region corresponding to a specific decision action. As a generalization of the traditional two-way decision model, 3WD further incorporates a third option, enabling a trisecting-and-acting approach to decision-making. Currently, 3WD has found widespread application across various fields [31]\u2013[34]. Xu [35] enhanced the flexibility and evolution capability of concept learning, addressing the limitations of existing two-way learning approaches by incorporating a novel cognitive mechanism and movement 3WD method. Zhang [36] introduced an efficient multi-scale decision system method that integrates a sequential 3WD model with the Hasse diagram to optimize scale combination selection and attribute reduction. Du [37] presented a novel multistep three-way clustering algorithm that enhances the accuracy and adaptability of cluster representations. In term of the advantage of 3WD, to address the limitations of GB-based classification models in classifying uncertain data, we introduce 3WD to construct the three-way approximations of GBs, which is called shadowed GBs. More detailed, the traditional GBs are extended to shadowed GBs for both certain regions and uncertain boundaries from the perspective of uncertainty, and shadowed GBs constructs a tripartitioned approximation of data distribution for three-way classification. The data instances will be categorized into a certain class or an uncertain case based on their locations relative to the shadowed GBs. Specifically, the Core region of GBs corresponding to the same class is confidently determined the class of instances, whereas the Important region has uncertainty for classification, and the Unessential region has almost no contribution to classification. This ensures more effective to classify uncertain data. The major contributions of this paper are summed up as follows:\n(1) Combine with information entropy, we propose an improved GB generation method based on the principle of justifiable granularity.\n(2) We introduce 3WD to construct and optimize shadowed GBs for modeling uncertain data.\n(3) We further establish a three-way classifier with shadowed GBs to categorize data instances into certain classes and uncertain case.\nThe following sections of this paper are structured with the subsequent manner. In section II is a review of related preliminary definitions. In Section III, an improved GB generation method is constructed based on the principle of justifiable granularity. In Section IV introduces the construction of shadowed GBs. Then, a three-way classifier with shadowed GBs is presented. The relevant experiments for the verification of viability and rationality of our models are shown in Section V. Finally, Section VI summarizes the conclusions."}, {"title": "II. PRELIMINARIES", "content": "In this section, to set up the framework of this paper, we recall some necessary definitions related to GBC, shadowed sets and 3WD.\nGBC is first proposed by Xia [18], which is to use GBs to cover the sample space and replace traditional information granules with GBs for data processing. We first define the GBC as follow:\nDefinition 1. (GBC) [18] Let $U = \\{x_1, x_2, ..., x_n\\}$ be a nonempty finite set. Generating $\\mathcal{G}$ to replace the inputs for computation can be called GBC. Where $\\mathcal{G} = \\{gb_1, gb_2,..., gb_m\\}$ is a granular-ball space of U, and a granular-ball $gb_i$ covers a subset of U such that $gb_i = \\{x_{i1}, x_{i2}, ..., x_{i|gb_i|}\\}(i = 1, 2, ..., m)$.\nAlthough a single GB contains a complete subset of D, we need to use some attributes of GB to replace the inputs for accelerated computation. Common attributes are defined as follow:\nDefinition 2. (GB Attributes) [18] Let $U = \\{x_1, x_2, ..., x_n\\}$ be a non-empty finite set, and $\\mathcal{G} = \\{gb_1, gb_2,..., gb_m\\}$ is a granular-ball space of U. For each $gb_i \\in \\mathcal{G}$, $gb_i = \\{x_{i1}, x_{i2}, ..., x_{i|gb_i|}\\}(i = 1,2,...,m)$, its attributes can be defined as follow:\n$c_{gb_i} = \\frac{1}{|gb_i|} \\sum_{j=1}^{|gb_i|} x_{ij}$\n$r_{gb_i} = \\frac{1}{|gb_i|} \\sum_{j=1}^{|gb_i|} ||x_{ij} - c_{gb_i} ||,$\n$l_{gb_i} = max(l_{ij}(j = 1, 2, ..., n)),$\n$\\rho_{gb_i} = \\frac{|\\{x_{ij} | l_{ij} = l_{gb_i}\\}|}{|gb_i|}$   (1)\nWhere $c_{gb_i}$ is the center, $r_{gb_i}$ is the radius, $l_{gb_i}$ is the label, and $\\rho_{gb_i}$ is the purity of $gb_i$. $l_{ij}$ is the label of $x_{ij}(j = 1, 2, ..., |gb_i|)$.\nThe above attributes are commonly used in GBC, where the center and label of GB are generally used to replace all the samples in the GB as a input, and the radius and purity of GB are used as a weight of this input, which can distinguish the contributions of different GB.\nShadowed sets [38] was proposed by Pedrycz and constructed through the fuzzy-rough transformation of fuzzy sets, which provided an effective tool to model and analyze the concepts with uncertainty. We can describe fuzzy-rough transformation as follows:"}, {"title": "III. GRANLUAR-BALL GENERATION BASED ON JUSTIFIABLE GRANULARITY", "content": "For GB generation, there are different approaches, e.g., using k-means [18] or using k-division [42] to split the GB. However, all generation methods can be summarized as starting with a GB that initially covers all samples, and then iteratively split it until a control condition is satisfied. The detailed process of GB generation method is outlined in Algorithm S1 of supplementary file. A key point in GB generation is setting the control condition, which directly affect the results of GB generation. Currently, most GB generation methods used purity as the control condition [18], [21], [23], [42], [43]. Although this approach offers the advantages such as fast computation and strong interpretability, it overlooks the uncertainty existed in original dataset. As shown in Fig. 1, GB generation with purity tend to generate more GBs when facing noise. This brings about two deficiencies as follows:\n(1) Overly split the final GBs, leading to a lack of justifiable granularity for problem solving and increase the number of GBs in subsequent calculations.\n(2) Generated GBs with noise label that impacts further compution and reduces the robustness of the GBC.\nTo solve the above problems, searching for a reasonable stop condition is critical. Pedrycz [26] proposed two criteria behind the principle of justifiable granularity, namely coverage and specificity, and they are conflict with each other [44]. Based on the coverage entropy and specificity entropy on GBs are defined as follows:\nDefinition 8. (Coverage Entropy) Let $U = \\{x_1, x_2, ..., x_n\\}$ be a non-empty finite set, and $\\mathcal{G} = \\{gb_1, gb_2,..., gb_m\\}$ is a granular-ball space of U. For each $gb_i \\in \\mathcal{G}(i = 1,2,..., m)$, the coverage entropy of $gb_i$ is formulated as follow:\n$H_{gb_i} = -\\frac{|gb_i|}{|D|} log \\frac{|gb_i|}{|D|}$   (7)\nThe coverage entropy of G is formulated as follow:\n$\\mathbb{H}_G = \\sum_{gb_i \\in G} H_{gb_i}$   (8)\nDefinition 9. (Specificity Entropy) Let $U = \\{x_1, x_2, ..., x_n\\}$ be a non-empty finite set, and $\\mathcal{G} = \\{gb_1, gb_2,..., gb_m\\}$ is a"}, {"title": "IV. THREE-WAY CLASSIFICATION WITH SHADOWED GRANLUAR-BALLS", "content": "GBC uses GB attributes in Definition 2 to replace the inputs, which results in each sample contributing equally to the GB it belongs to. For example, when faces with classification problems in GBC, GB attributes only offer the center and radius of each GB, and predicted sample only have two states, in or not in the GB. Although this method is simple enough, it ignores the high uncertainty of sample points near the radius, in other words, it lacks robustness. To address this issue, we construct shadowed GBs based on 3WD theory. First, the GB membership for samples is defined as follow:\nDefinition 11. (GB Membership) Let $U = \\{x_1, x_2, ..., x_n\\}$ be a non-empty finite set, and $\\mathcal{G} = \\{gb_1, gb_2,..., gb_m\\}$ is a granular-ball space of U. Given a membership function $\\mu_{gb_i} : gb \\rightarrow [0,1]$ to each $gb_i \\in \\mathcal{G}(i = 1,2,..., m)$. The GB membership for each sample $x \\in gb_i$ is formulated as follow:\n$\\mu_{gb_i}(x) = exp \\big( -\\frac{d(x, c_{gb_i})^2}{2\\sigma^2 r_{gb_i}}\\big)$   (13)\nWhere $\\sigma$ is the function order, $c_{gb_i}$ is the center of $gb_i$, $r_{gb_i}$ is the radius of $gb_i$, and $d(x, c_{gb_i})$ is the distance between $x$ and $c_{gb_i}$.\nWhen a sample is at the center of GB, its GB membership takes the maximum value of 1, and it decreases as the sample moves away from the center. In this paper, we set $\\sigma = 1$, so the membership of sample near the GB radius is close to 0.5. This is related to the calculation of the GB radius using the mean value. If the GB radius calculation uses the maximum value, $\\sigma$ needs to be adjusted to ensure that the membership is reasonable. Then, based on the fuzzy-rough transformation theory, we defined the shadowed GB as follow:\nDefinition 12. (Shadowed GB) Let $U = \\{x_1, x_2, ..., x_n\\}$ be a non-empty finite set, and $\\mathcal{G} = \\{gb_1, gb_2,..., gb_m\\}$ is a granular-ball space of U. For each $gb_i \\in \\mathcal{G}(i = 1,2,..., m)$, a mapping that maps GB memberships into a triplet set $\\{0, [0,1], 1\\}$ can be called shadowed GB, and the mapping is formulated as follows:\n$\\hat{\\mu}_{gb_i}(x) = \\begin{cases} 1, & \\mu_{gb_i}(x) \\ge 1 - \\alpha \\\\ \\mu_{gb_i}(x), & \\alpha < \\mu_{gb_i}(x) < 1-\\alpha \\\\ 0, & \\mu_{gb_i}(x) \\le \\alpha  \\end{cases}$   (14)\nWhere $x \\in gb_i$, and $(\\alpha,1 - \\alpha)$ is the threshold pair of shadowed GB.\nWe analyzed the changes of uncertainty variance and fuzziness with the changing of $\\alpha$, as shown in Fig. 3. When $\\alpha$ decreases, fewer GB memberships are mapped to certain negative and certain positive regions, meaning uncertainty variance decreases. Conversely, more GB memberships remain in fuzzy case, resulting in an increase in fuzziness. This indicates that uncertainty variance and fuzziness are conflicting criteria. We utilize GB membership to distinguish the contribution of samples to their GBs. However, if the uncertainty variance is excessively high, it will cause many samples to collapse into binary states, rendering the GB membership ineffective. Thus, it is crucial to keep the uncertainty variance as low as possible. Additionally, we employ shadowed GB to expedite further computations. However, if the fuzziness is too high, it will result in an excessive number of fuzzy memberships that must be processed, defeating the purpose of using shadowed GB. Therefore, it is essential to minimize fuzziness to maintain the efficiency of the shadowed GB. We need to search for a balance point between uncertainty variance and fuzziness. To achieve this, we defined the optimal $\\alpha$ as follow:"}, {"title": "V. EXPERIMENTAL STUDIES", "content": "In this section, we comprehensively compared our proposed 3WC-SGB with other three-way classifiers (3WC-FNC [45], 3WC-SVM [46]), state-of-the-art GB-based classifiers as inputs. We compared with GBKNN, GBG++, and ACCGBKNN in terms of prediction time and the results are in Table III. It can be observed that based on the mapping approach of shadowed GB, the time required for comparing samples with each GB is significantly reduced during sample classification. This is because only samples mapped to the important area require further processing, while those located in the core area samples can directly proceed to voting, greatly reducing prediction time. This performance becomes more pronounced as noise rates increase because GB-based classifiers tend to produce more GBs when facing noise, and these noise-induced GBs are often particularly small. However, dealing with noise GB-based classifiers still compute and sort these balls, while 3WC-SGB directly maps them to unessential area. Therefore, 3WC-SGB will exhibit a greatly improved on efficiency.\nWe conducted experiments with all compared classifiers on various datasets with different noise rates. Here, only the results with traditional classifiers is listed in Table IV, as the comparison with 3WD classifiers and GB-based classifiers has already been mentioned in Section V-A and Section V-B. From Table IV, although 3WC-SGB experiences some loss in Recall, the analysis of the F1 Sorce indicates that this loss is acceptable. 3WC-SGB consistently maintains a significant lead over traditional algorithms across various noise rates. It closely resembles SVM only in low noise rate, but significant differences emerge as the noise rate increases. It is evident that 3WC-SGB holds a considerable advantage in robustness.\nNext, we conducted Nemenyi post-hoc tests on all compared algorithms. This test aim to visually demonstrate the signi-ficant differences between different algorithms. The results are presented in Fig. 8. \"CD\" stands for Critical Difference, representing the critical range. It is obvious that the results obtained from the Friedman test are consistent with those from the Wilcoxon test. At low noise rate, there is no significant difference between 3WC-SGB and some other algorithms. As noise increases, there is a noticeable rise in the algorithm\u2019s ranking, leading to significant differences between 3WC-SGB and other algorithms. This indicates that the robustness of 3WC-SGB indeed presents a significant advantage over other algorithms.\nThe comprehensive analysis underscores the robustness of 3WC-SGB across various noise rates. Its consistent outperformance in Precision, F1 Sorce, and Cost, particularly in high noise environments. Therefore, 3WC-SGB matches the effectiveness of top-tier classifiers on most datasets. Moreover 3WC-SGB significantly enhances classification effectiveness in scenarios characterized by high levels of noise."}, {"title": "VI. CONCLUSION", "content": "In this paper, we improved GBC by addressing the limitations in GB generation, and then proposed the 3WC-SGB. Experimental results on 12 datasets demonstrate that the shadowed GBs generated based on justifiable granularity have excellent compatibility with 3WD and significantly improve the performance of the classifier, particularly its robustness. However, our work still has some limitations, for example, searching for justifiable granularity GBs still has an additional time overhead in sorting that cannot be ignored. The focus of our future work will be on the following three aspects:\nDesign an incremental mechanism into 3WC-SGB to deal with streaming data, enabling the model can dynamic and efficient classifies in real-time scenarios.\nSearched for a novel GB split method to ensure that each split consistently increases the distinct semantics of the new GB, leading to a effectively reduce in GB generation time.\nIntroducing shadowed GBs into other fields to comprehensive explore its strengths and weaknesses with normal GB."}]}