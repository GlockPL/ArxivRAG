{"title": "GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification", "authors": ["Ximing Wen", "Wenjuan Tan", "Rosina O. Weber"], "abstract": "Pretrained transformer-based Language Models (LMs) are well-known for their ability to achieve significant improvement on text classification tasks with their powerful word embeddings, but their black-box nature, which leads to a lack of interpretability, has been a major concern. In this work, we introduce GAProtoNet, a novel white-box Multi-head Graph Attention-based Prototypical Network designed to explain the decisions of text classification models built with LM encoders. In our approach, the input vector and prototypes are regarded as nodes within a graph, and we utilize multi-head graph attention to selectively construct edges between the input node and prototype nodes to learn an interpretable prototypical representation. During inference, the model makes decisions based on a linear combination of activated prototypes weighted by the attention score assigned for each prototype, allowing its choices to be transparently explained by the attention weights and the prototypes projected into the closest matching training examples. Experiments on multiple public datasets show our approach achieves superior results without sacrificing the accuracy of the original black-box LMs. We also compare with four alternative prototypical network variations and our approach achieves the best accuracy and F1 among all. Our case study and visualization of prototype clusters also demonstrate the efficiency in explaining the decisions of black-box models built with LMs.", "sections": [{"title": "1 Introduction", "content": "Deep learning models, especially transformer-based Language Models (LMs) such as BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019) have significantly contributed to advancements in NLP, offering word embeddings as powerful tools for text classification. However, despite their state-of-art performance, their complexity and black-box nature obscure the decision-making process and hinder their interpretability. Now more and more real-world applications also desire classification models built with LMs to be interpretable, since it allows end-users to comprehend the decision-making process, fostering trust and encouraging adoption. To address this need, there is growing interest in enhancing the interpretability of LMs and the related text classification models in general.\nRecent efforts have focused on redesigning neural networks to be inherently interpretable, based on the classic framework of prototypical learning (Datta and Kibler, 1995). These models actively learn prototype vectors hrough training, which are representative cases from previous observations, to explain decisions more intuitively. This methodology is first introduced into image domain by Li et al. (2018) and Chen et al. (2019), and then applied in text classification field with different structure variations (Ming et al., 2019; Hong et al., 2020; Pluci\u0144ski et al., 2021; Das et al., 2022). However, despite this white-box framework being efficient in training and improving the model's intrinsic interpretability, there is still some performance gap compared with the original black-box models.\nOn the other hand, there exist strategies such as graph attention network (GAT) (Velickovic et al., 2017), that is known for its ability to capture the importance of neighboring nodes in a graph through attention mechanisms, enabling more effective and expressive feature representation learning for each node. This approach allows GAT to dynamically assign different weights to different neighbors, which enhances the model's performance on various graph-based tasks(Wang et al., 2019; Xie et al., 2020; Bhatti et al., 2023). This inspires us to analogize learning the relatedness between the input vector and the prototype vectors as constructing edges and learning their weights between nodes.\nTo address the challenge of the performance gap, we propose a novel white-box Multi-head Graph Attention-based Prototypical Network (GAProtoNet) designed to explain the decisions of text classification models built with LM encoders. Our approach incorporates a prototype layer on top of a fine-tuned LM and utilizes multi-head graph attention (Velickovic et al., 2017) to efficiently learn an interpretable prototypical representation by selectively constructing edges between encoded representations and their neighboring prototypes. In the reference time, the decision is solely based on a linear combination of prototypes weighted by the attention scores assigned by attention heads. Our model archives superior performance without sacrificing the accuracy of the original LM while facilitating transparent decision-making progress. The novelty of our work lies in being the first to represent prototypes and input vectors as nodes within graphs, and actively train prototype vectors utilizing edges constructed by graph attention for interpretable text classification. The contribution of our work can be summarized as follows:\n\u2022 We propose a new prototypical framework that leverages multi-head graph attention to selectively construct edges between input and prototypes which indicates relatedness. Our model is inherently interpretable and the performance is superior without sacrificing the accuracy of the original models.\n\u2022 We did extensive comparison experiments with variations of prototype-based networks on five public benchmark datasets, including binary, four-label, ten-label classification. Our approach achieves the best accuracy and F1.\n\u2022 We evaluate the interpretability of GAProtoNet through various design criteria and demonstrate that the explanations provided by GAProtoNet are of high quality.\nThe next section describes our proposed approach. \u00a73 presents experiments, while \u00a74 presents an analysis of the interpretability exhibited in the proposed approach. We describe related work in \u00a75. We conclude in \u00a76 where we reiterate our contribution. Limitations and future work are pointed out in \u00a77."}, {"title": "2 Graph-Attention ProtoNet", "content": "Figure 1 illustrates the overall architecture of GAProtoNet, which consists of three major components: (1) Text Embedding based on Language Models (LMs), responsible for converting input text into high-dimensional vectors that capture its semantic information; (2) Prototype Layer, responsible for forming multiple typical prototype vectors that encapsulate distinct semantic aspects of the input text as well as enhancing the interpretability of the model; and (3) Graph Attention Mechanism, which efficiently learn the relatedness between the text embedding vector and its neighboring prototype vectors, which are later used to form a prototypical representation of the text and passed to output layer. Detailed descriptions for each component are presented in the following subsections."}, {"title": "2.1 Text Embedding encoded by Language Models (LMs)", "content": "Given the remarkable performance of pre-trained language models ROBERTa, XLNet, and DistilBERT on a wide range of NLP tasks, we leverage their capabilities for efficient text embeddings. These models have been trained on vast text datasets and can be fine-tuned for specific downstream tasks. By utilizing these pre-trained language models, we embed input text into high-dimensional vectors, which serve as representations that capture the deep semantic information of the text:\n$s = LM(x)$ (1)\nwhere x denotes the input text. s is the semantic information representation vector."}, {"title": "2.2 Prototype Layer", "content": "In the prototype layer, we define M prototype vectors $P = {p_j}_{j=1}^{M}$ that represent typical features in the vector space of training data. For each semantic representation vector passed from the text embedding layer, we compute the attention score vector indicating the relatedness between itself and all prototype vectors with a graph attention model introduced in \u00a72.3.\nNote that these prototype vectors are randomly initialized. They are learned through active training with loss defined in \u00a72.5. Their representativeness is improved by updating the weights during each training epoch, resulting in an inherently interpretable classifier."}, {"title": "2.3 Graph Attention Mechanism", "content": "The graph attention mechanism in our model captures the relatedness between the embedding text vector and the prototype vectors, allowing for the derivation of prototypical representations for the embedding vectors mentioned in \u00a72.2. To effectively capture diverse semantic aspects and intricate patterns in the data, we utilized a multi-head approach to comprehensively model this relatedness. The query nodes in the graph represent the input text embedding vector while the key nodes represent the prototype vectors. Edges and weights are constructed based on the following approach:\nSingle-Head Linear Transformation For each text embedding input s, we utilize matrix $W_q$ to transform it into query node q. For each prototype $p_j$, we utilized matrix $W_k$ to transform it into $k_j$:\n$q=W_qs, k_j=W_kp_j$ (2)\nMulti-Head Linear Transformation Now instead of using one single set of weight, we utilize a set of learnable matrix linear transformations ${W_q^i}_{i=1}^{H}$ and ${W_k^i}_{i=1}^{H}$, to generate a series of query nodes ${q_i}_{i=1}^{H}$ and prototypes ${k_{ij}}_{i=1}^{H}$ with H representing the number of attention heads. For each head i, we have:\n$q_i = W_q^i s, k_{ij} = W_k^i p_j$ (3)\nAttention Score Computation After the transformation with each head i, we calculate the similarity between the node qi and the nodes ${k_{ij}}_{j=1}^{M}$ based on the dot product:\n$sim(q_i, k_{ij}) = dot(q_i,k_{ij})/\\sqrt{d_k}$ (4)\nwhere $d_k$ denotes the dimension of key node vector k.\nThe attention scores are then derived by applying the sigmoid activation function $\\sigma$ to the similarity vector:\n$\\alpha_{ij} = \\sigma(sim(q_i, k_{ij}))$ (5)\nThis attention score represents the weight of each prototype p in shaping the decision-making process. As shown in Figure 1, our experimental results demonstrate that each attention head tends to activate prototypes corresponding to distinct semantic aspects. Moreover, the attention scores assigned to negative and positive prototypes suggest a bias towards a negative or positive final classification, respectively.\nGraph Edge Construction For each attention head i, a graph is constructed by activating edges between the transformed prototype nodes k and text embedding node q when attention scores exceed a certain threshold $\\tau$. For each attention head i, the edge between the transformed prototype q and transformed j-th prototype node kj can be expressed as:\n$E = {(q_i, k_{ij}) | \\alpha_{ij} > \\tau }$ (6)\nInterpretable Prototypical Representation The prototypical representation vector for the text embedding vector s is formed by computing a linear combination of the neighboring prototype nodes from all attention heads weighted by the attention score.\nFor each attention head i, we first normalize the attention scores for neighboring transformed prototype nodes of qi. Thus, for each prototype node kj under attention head i, its normalized score is:\n$\\gamma_{ij}=\\frac{\\alpha_{ij}}{\\sum_{k \\in N(q_i)} \\alpha_{ik}}$ (7)\nThe prototypical representation vector r for s under attention head i is computed as:\n$r_i = \\sum_{j \\in N(q_i)} \\gamma_{ij}k_{ij}$ (8)\nwhere N(qi) is the set of neighboring nodes for node q under attention head i constructed under the definition of E in 6.\nOutput Layer The interpretable prototypical representations obtained from all heads are concatenated to form a single vector. This vector is then utilized as input for the output layer to perform text classification."}, {"title": "2.4 Prototype Projection", "content": "To understand the natural language meaning of each prototype vector $p_j$, we match each prototype with the sample text embedding vector $s_j$ in the dataset D that has the highest similarity, and assign that sample $x_j$ as the prototype text. Let D represent the training dataset, then:\nText of $p_j \\leftarrow arg\\max_{x_j \\in D} sim(s_j, p_j)$ (9)\nwhere sim($s_j$, $p_j$) denotes the similarity measure between the sample text $s_j$ and the prototype vector $p_j$.\nDuring text classification tasks, we observe the graph model formed between embedded text and prototypes, as well as the edge weights, to interpret the classification process."}, {"title": "2.5 Training Objective", "content": "In this study, our designed composite loss function consists of three key components: Accuracy Loss, Proximity Loss, and Diversity Loss.\nAccuracy Loss For the task of text classification, we employ the cross-entropy loss as the primary objective function to guide the model training. This loss measures the discrepancy between the predicted probability distribution from the model and the true labels, thus optimizing the model to assign higher probabilities to the correct classes. Specifically, the accuracy loss is defined as:\n$\\mathcal{L}_{Acc}(Y, \\hat{y}) = -\\sum_{i=1}^{N} y_i \\log(\\hat{y_i}),$ (10)\nwhere N is the number of samples, $y_i$ is the true label of sample i, $\\hat{y_i}$ is the predicted probabilities.\nProximity Loss To ensure that each prototype learned by the model can find a most similar sample in the training data, we introduce the Proximity Loss. This loss measures the distance between prototypes and data points, penalizing prototype-sample pairs that are far apart. We use Euclidean distance as the distance metric and calculate the minimum distance between each prototype and all samples. The average of the minimum distances across all prototypes is then taken as the Proximity Loss:\n$\\mathcal{L}_{Prox} = \\frac{1}{M}\\sum_{j=1}^{M}\\min_{s_i} ||p_j - s_i||^2$ (11)\nwhere M is the number of prototypes, $p_j$ is the vector representation of the j-th prototype, and $s_i$ is the embedded vector representation of the i-th sample in the training set.\nDiversity Loss To encourage diversity among prototypes and avoid redundancy, we introduce the Diversity Loss. This loss aims to encourage prototypes to be distributed as diversely as possible in the feature space. We achieve this by penalizing the average distance between all pairs of prototypes:\n$\\mathcal{L}_{Div} = \\frac{1}{M(M - 1)}\\sum_{j=1}^{M}\\sum_{i \\neq j} ||p_j - p_k||^2$ (12)\nComposite Loss Function By combining the above three loss functions, we obtain the composite loss function:\n$\\mathcal{L} = \\lambda_1 \\cdot \\mathcal{L}_{Acc} + \\lambda_2 \\cdot \\mathcal{L}_{Prox} + \\lambda_3 \\cdot \\mathcal{L}_{Div}$ (13)"}, {"title": "3 Performance Experiments", "content": "In this section are discussed the datasets used in the experiments, and the models used as black-box baselines, prototypical baselines, and the variations of the proposed approach. The overall hypothesis is that the proposed approach performs on par with black-box and outperforms prototype baselines in the dataset used for text classification."}, {"title": "3.1 Datasets and Metric", "content": "We evaluate our approach on three binary public benchmark datasets: Hotel Reviews \u00b9prepared by (Hong et al., 2020), IMDb \u00b2 and Yelp Polarity Reviews. All of them are balanced datasets. To demonstrate our model's performance on more challenging tasks, we also evaluate it on Tweet (Mohammad et al., 2018) and Yahoo (Zhang et al., 2015), which are 4-class and 10-class datasets seperately.\nMetric We use accuracy, recall and F1-Score as metrics to evaluate models' performance. For each model, we run 5 times and calculate the average as the final reported results."}, {"title": "3.2 Models and Settings", "content": "We select three black-box LM as baselines and four different prototype-based variations for comparison experiments. We also test two variations of GAProtoNet, one with a single attention head and another with attention heads = 4. We train each model with one single NVIDIA GTX 3090 or GTX 4090. We use Adam as the optimizer and the learning rate is 1e - 4. Due to the limitation of GPU RAM, we choose a batch size of 4 and an accumulated gradient step of 64.\nLM Baselines We select the following pre-trained black-box language model without prototypes as the powerful baselines: DistilBERT (Sanh et al., 2019), RoBERTa-large (Liu et al., 2019) and XLNet (Yang et al., 2019). For all the three LMs, we use the same simple MLP (multilayer perceptron) with two hidden layers over the output of the CLS token from the last hidden layer of the LM encoder for classification."}, {"title": "3.3 Experiment Result", "content": "Binary Classification Thr first three section in Table 1 summarizes our evaluation results on binary classification. We observe that GAProtoNet either closely matches or exceeds the performance of its baseline LLM across our experiments, supporting GAProtoNet's interpretability is not achieved at the cost of performance. Within four types of prototypical variations, ProtoTEX and ProtoryNet have the best performance for accuracy, recall, and F1 for all three datasets, but GAProtoNet still improves 3%-6% upon their performance. This indicates that leveraging graph attention to construct edges between input embeddings and prototypes could be more efficient than heuristic distance measurement. For the variations of GAProtoNet, multi-head GAProtoNet have better performance compared with single-head, with the RoBERTa as the encoder showing the best results. This could be due to that the multi-head attention enables the network to capture semantic meanings from different perspectives, thus potentially improving the network's performance.\nExtend to Multi-label Classification The last two section in Table 1 summarizes our evaluation results on multi-label classification. For the 4-class dataset, our model is the best overall. For the 10-class dataset, our model is better than all other prototype-based models and comparable to black-box models. This confirms the robustness of our model observed in binary classification and also shows that our model produces accuracy comparable or better than black-box model even when the task is more challenging. Comparing our model against other prototype-based architectures, the performance is better in all the experiments done so far.\nThe consistent results across five datasets support our hypothesis in the beginning that GAProtoNet can perform on par with black-box and outperform prototype baselines. The performance improvement demonstrated by GAProtoNet indicates graph attention for prototypical networks can achieve better overall performance, thus validating our contribution."}, {"title": "4 Interpretability Analysis", "content": "In this section, we analyze our model's interpretability from two perspectives. First, we use case studies to demonstrate how prototypes and their surrounding edges to the input node, constructed with graph attention, are used to explain the model's decision-making process. Second, we evaluate the quality of our prototypes. We demonstrate their representativeness through visualization, showing that they are distributed dispersedly within the training data space. Additionally, we assess the distinctiveness of the prototypes by examining how it varies with the number of prototypes and analyzing its impact on the model's prediction performance."}, {"title": "4.1 Case study", "content": "Figure 3 illustrates an example of using multi-graph attention heads and prototypes to explain a classification result. The input text is a Yelp review about a restaurant. In this instance, eleven out of twenty prototypes are activated by four attention heads, indicating edges constructed between them and the input text. Figure 2 illustrates the activation of prototypes using attention Head 3 as an example. Specifically, five positive prototypes related to food quality are activated, and edges are constructed between the input text and the activated prototypes, with the attention scores representing the edge weights. This activation reflects the positive sentiment towards food quality expressed in the original text.\nWe observe that different prototypes, representing various aspects of the restaurant, are activated by different attention heads. Head 1 activates prototypes related to service and price, Head 2 to service, Head 3 to food, and Head 4 to waiting time. In this text input, all different aspects of the text are captured by each attention head and then construct the edge between the input and the prototypes. Interestingly, prototypes related to service are activated by Head 2, even though the input text does not explicitly mention service. This suggests that the model might infer a positive attitude towards service based on implicit cues in the text. It also indicates that the aspects activated by different attention heads can overlap rather than being fully distinct."}, {"title": "4.2 Prototype quality and performance", "content": "Prototype Distribution Visualization Since prototypes are used to interpret the model, they should capture as many representative features from the data as possible, indicating an even distribution within the training data space. A straightforward way to verify this is through visualization. Since our prototype vectors and training data are high-dimension vectors, we first use t-SNE (t-distributed Stochastic Neighbor Embedding) (Van der Maaten and Hinton, 2008) to do dimension deduction before the visualization. This method is effective at preserving the local structure of the data so the distribution pattern won't change when projected from higher dimension space to lower dimension space. The visualization of prototype vectors for a multi-head GAProtoNet with the prototype number of k = 20 is shown in Figure 4. The orange dots represent prototypes while the blue dots represent training data. We can see that the prototype vectors are evenly distributed within the training data space and test results show that those prototype vectors are of high orthogonality. This indicates that the space formed by these vectors can cover most of the data points so we can use limited prototypes to represent any point in the training data."}, {"title": "Prototype Distinguishness and Model Performance", "content": "Since the prototypes are used both for interpreting results and making decisions, we are interested in how the hyperparameter k of their number affects the model's interpretability and classification performance. For interpretability, we measure the number of distinguished prototypes. Distinguishness indicates that if more than one prototype vector projects onto the same sample data point, it is counted only once. For classification performance, we measure the accuracy. We conduct experiments varying the number of prototypes k from 10 to 40 on a multi-head GAProtoNet with RoBERTa-large as the encoder across the three datasets. The percentage of distinguished prototypes and classification accuracy is shown in Figure 5. We observe the accuracy achieves the highest when k = 20 across three datasets then drops with k increasing. The corresponding trend for the percentage of distinguished vectors is also dropping from k = 20 to k = 40. We reason that increasing k can only improve the model's expressiveness until a certain point, in our case k = 20. After the point, prototypes will lose distinguishness and therefore hurts model's classification performance. Instead of observing a trade-off between interpretability and accuracy, our experiments show that they are positively related with each other."}, {"title": "5 Related Work", "content": "Li et al. (2018) and Chen et al. (2019) introduce prototype-based architecture into interpretable image classification by proposing a prototype layer, where prototypes are randomly initialized and are made meaningful through training. Ming et al. (2019) brought this approach into NLP domain by adding a sequence encoder before the prototype layer. However, despite this intrinsically interpretable model demonstrating compelling results, there are still some performance gaps compared to the original black-box model.\nIn the NLP domain, researchers attempt to minimize the performance gap by trying different structure variations. Hong et al. (2020) used Sentence Universal Encoder (Cer et al., 2018) and added an LSTM layer (Hochreiter and Schmidhuber, 1997) between the prototype layer and the output layer to better capture the patterns in the trajectory of prototypes. Pluci\u0144ski et al. (2021) propose a new structure that operates on the prototypes in the form of phrases. Das et al. (2022) applied a new distance measurement metric and further minimized the accuracy gap but they only compared with the black-box models and lack of comparison with other prototype-based variations.\nAll the above approaches utilize variations of heuristic distance metric (e.g. cosine similarity or Euclidean distance) to calculate the distance vector or matrix between the input vectors and prototypes, which serves as the sole input to the output layer. We hypothesize that only passing a heuristic distance metric may omit essential upstream information, thereby impairing performance. This motivates us to improve the current structure by calculating relatedness with the attention mechanism, which could potentially preserve more information (Vaswani et al., 2017).\nConsidering all the limitations of the current approaches, there is a need for a new prototypical network that can further minimize the performance gap compared with the original black-box model and at the same time prototypes can be effectively trained through active learning."}, {"title": "6 Conclusion", "content": "We contribute an interpretable prototypical deep learning architecture that is advanced with graph attention on binary text classification. Our experiments show our approach outperforms both other interpretable and black-box architectures on three datasets. We also conduct a comprehensive analysis to show good interpretability of our approach."}, {"title": "7 Limitation", "content": "To demonstrate these prototypes can support user explainability in addition to making the architecture interpretable, we will include user study in our future work."}]}