{"title": "MARKERS IDENTIFICATION FOR RELATIVE POSE ESTIMATION\nOF AN UNCOOPERATIVE TARGET", "authors": ["Batu Candan", "Simone Servadio"], "abstract": "This paper introduces a novel method using chaser spacecraft image processing\nand Convolutional Neural Networks (CNNs) to detect structural markers on the\nEuropean Space Agency's (ESA) Environmental Satellite (ENVISAT) for safe de-\norbiting. Advanced image pre-processing techniques, including noise addition\nand blurring, are employed to improve marker detection accuracy and robustness.\nInitial results show promising potential for autonomous space debris removal, sup-\nporting proactive strategies for space sustainability. The effectiveness of our ap-\nproach suggests that our estimation method could significantly enhance the safety\nand efficiency of debris removal operations by implementing more robust and au-\ntonomous systems in actual space missions.", "sections": [{"title": "INTRODUCTION", "content": "The escalating problem of space debris necessitates innovative solutions for identification and\nremoval, particularly for large defunct satellites like ESA's ENVISAT, an inactive Earth observation\nsatellite. In the past ten years, deep learning (DL) has profoundly influenced the development of\ncomputer vision algorithms, enhancing their performance and robustness in various applications like\nimage classification, segmentation, and object tracking. This momentum has carried into spacecraft\npose estimation, where DL-based methods have begun to surpass traditional feature-engineering\ntechniques as reported in the literature [1-3], corner and marker detection algorithms such as Shi-\nTomasi, Hough Transform methods [4, 5].\nCNNs have the edge over feature-based methods primarily due to their enhanced robustness\nagainst poor lighting conditions and their streamlined computational demands. However, when\nit comes to space imagery, the scenario changes due to the distinct challenges such as high contrast,\nlow signal-to-noise ratio, and inferior sensor resolution, which can diminish accuracy. Generally,\nthe scarcity of extensive synthetic space image datasets, crucial for comprehensive CNN training,\nnecessitates the use of networks pre-trained on terrestrial images. To adapt these for space ap-\nplications, transfer learning is employed, focusing on training only select layers of the CNN [6].\nDetection of the keypoints such as corners involves predicting the 2D projections of specific 3D\nkeypoints from the spacecraft's imaged segments using a deep learning model. These keypoints\nare usually determined by the spacecraft's CAD model. In the absence of a CAD model, meth-\nods like multiview triangulation or structure from motion are employed to create a 3D wireframe\nmodel that includes these keypoints [7, 8]. Keypoint location regression technique involves direct\nestimation of the keypoint positions [9, 10]. Segmentation-driven method utilizes a network with\ndual functions, segmentation and regression, to deduce keypoint locations. The image is sectioned\ninto a grid, isolating the spacecraft within certain grid cells. Keypoint positions are then computed\nas offsets within these identified cells, enhancing prediction accuracy. Variations of this model have\nbeen optimized for space deployment, reducing parameter count without compromising on predic-\ntion accuracy [11, 12]. Heatmap prediction method represents the likelihood of keypoint locations,\nfrom which the highest probability points are extracted as the actual locations. Moreover there is a\nbounding box approach using the enclosing bounding boxes over the keypoints are predicted along\nwith the confidence scores rather than utilizing the keypoint locations or heatmaps [13, 14].\nOn the other hand, estimation involves deducing the value of a desired quantity from indirect,\nimprecise, and noisy observations. When this quantity is the current state of a dynamic system, the\nprocess is termed, where the best estimate is obtained by eliminating noise from the measurements.\nMoreover, estimation of the relative position and the prediction of the target attitude are crucial\nfor safe proximity operations. This necessitates complex on-board computations at a frequency en-\nsuring accuracy requirements are met. However, the limited computational power of current space\nprocessors constrains the estimation processes that can be implemented. Therefore, developing ef-\nficient algorithms that minimize computational demands while maintaining necessary performance\nand reaching the best estimate are crucial for the success of these missions. This estimate is pro-\nduced by an optimal estimator, a computational algorithm that processes data to maximize a specific\nperformance index, effectively utilizing available data, system knowledge, and disturbance infor-\nmation. For linear and Gaussian scenarios, the posterior distribution remains Gaussian, and the\nKalman Filter (KF) is used to compute its mean and covariance matrix. However, practical prob-\nlems are often nonlinear, leading to non-Gaussian probability density functions. Various techniques\naddress nonlinear estimation problems. One straightforward method is linearizing the dynamics\nand measurement equations around the current estimate, as done in the Extended Kalman Filter\n(EKF), which applies KF mechanics to a linearized system. Higher-order Taylor series approxima-\ntions can extend the EKF's first-order approximation. The Gaussian Second Order Filter (GSOF),\nfor example, truncates the Taylor series at the second order to better handle system nonlineari-\nties. This requires knowledge of the estimation error's central moments up to the fourth order to\ncalculate the Kalman gain. For instance, while the EKF uses first-order truncation requiring co-\nvariance matrices, the GSOF requires third and fourth central moments of the state distribution.\nThe GSOF approximates the prior PDF as Gaussian at each iteration and performs a linear update\nbased on a second-order approximation of the posterior estimation error. Other linear filters use\ndifferent approximations, such as Gaussian quadrature, spherical cubature, ensemble points, central\ndifferences, and finite differences [15]. Alternatively, the Unscented Kalman Filter (UKF) employs\nthe unscented transformation to better manage nonlinearities in dynamics and measurements, typ-\nically achieving higher accuracy and robustness than the EKF. The UKF uses this transformation\nfor a more precise approximation of the predicted mean and covariance matrix, remaining a lin-\near estimator where the estimate is a linear function of the current measurement. The UKF offers\na solution by using the unscented transformation, which avoids linearization by propagating care-\nfully selected sample points through the nonlinear system, providing superior performance in such\nsituations [16, 17].\nThis study presents a novel approach using image processing from a chaser spacecraft to de-\ntect structural markers on the ENVISAT satellite, and a estimation framework utilizing unscented\nKalman filtering facilitating its safe de-orbiting. Utilizing high-resolution imagery, the project em-"}, {"title": null, "content": "ploys advanced CNN for precise marker detection, essential for the subsequent removal process.\nThe methodology incorporates image pre-processing, including noise addition and blurring, to en-\nhance feature detection accuracy under varying space conditions. Preliminary results demonstrate\nthe system's efficacy in identifying corner points on the satellite, and ability to keep translational and\nrotational estimates in appropriate levels promising a significant leap forward in automated space\ndebris removal technologies. This work builds upon recent advancements in space debris monitor-\ning and removal strategies, echoing the urgent call for action highlighted in studies such as [18, 19,\n20], which emphasize the growing threat of space debris and the necessity for effective removal\nmechanisms [21]. Our findings indicate a scalable solution for debris management, aligning with\nthe proactive strategies recommended by the Inter-Agency Space Debris Coordination Committee\n(IADC) [22]."}, {"title": "METHODOLOGY", "content": null}, {"title": "Dynamics", "content": "In the following analysis, several assumptions are made to simplify the dynamics modeling of\nthe chaser and target spacecraft. Firstly, it is presumed that the inertia properties of both the chaser\nand the target are perfectly known beforehand. This assumption simplifies the dynamic modeling\nby removing uncertainties related to mass distribution and moments of inertia. Secondly, the mo-\ntion of the chaser spacecraft is considered deterministic. This means that the trajectory and state\nof the chaser are precisely known and not affected by any form of noise or uncertainties, lead-\ning to an idealized model of the chaser's dynamics. Lastly, neither flexible dynamics nor external\ndisturbances are taken into account. The analysis ignores the effects of external factors such as\ngravitational perturbations, atmospheric drag, or solar radiation pressure. This simplification im-\nplies that the translational and rotational dynamics of the spacecraft are decoupled, allowing for\nindependent analysis of these two aspects. These assumptions streamline the analysis by focusing\non the primary dynamics without the added complexity of uncertain factors or external influences.\nAbsolute Chaser Motion: The chaser motion is described by the following equations, where \u03bc\nis the gravitational parameter of the Earth, r is the position of the chaser centre of mass with respect\nto the Earth, and @ is the true anomaly in the orbit of the chaser.\n$$= \\sqrt{r0^2 - \\frac{\\mu}{r}}$$\n$$\\ddot{\\theta} = -2\\dot{r}\\dot{\\theta}$$"}, {"title": "Relative Translational Dynamics", "content": "The target, ENVISAT, has its relative translational dynamic\nequations developed with respect to the chaser local-vertical-local-horizontal (LVLH) frame of the\nchaser. The target relative position, denoted as rr, and relative velocity, vr, are defined in the chaser\nLVLH frame as expressed\n$$r_r = xi + yj + zk$$\n$$v_r = \\dot{x}i + \\dot{y}j + \\dot{z}k$$"}, {"title": null, "content": "In this context, x, y, and z are the three components of the vector r, within the chaser LVLH\nframe, and i, j, and k represent the respective unit vectors of the reference frame. Thus, the equa-\ntions of motion of the target for its relative translational dynamics are able to be written in the\nfollowing way.\n$$\\ddot{x} = 2\\dot{\\theta}\\dot{y} + \\ddot{\\theta}y + \\dot{\\theta}^2x - \\frac{\\mu(\\Upsilon + x)}{[(\\Upsilon + x)^2 + y^2 + z^2]^{3/2}} + \\frac{\\mu}{\\Upsilon^2}$$\n$$\\ddot{y} = -2\\dot{\\theta}\\dot{x} - \\ddot{\\theta}x + \\dot{\\theta}^2y - \\frac{\\mu y}{[(\\Upsilon + x)^2 + y^2 + z^2]^{3/2}}$$\n$$\\ddot{z} = \\frac{\\mu z}{[(\\Upsilon + x)^2 + y^2 + z^2]^{3/2}}$$"}, {"title": "Rotational Dynamics", "content": "The relative orientation of the body-fixed frame on the target with respect\nto the body-fixed frame of the chaser can be represented with a rotational matrix \u0393. Thus, the relative\nangular velocity wr in the target body-fixed reference frame is dependent on the angular velocity\nof the chaser we and the angular velocity of the target wt, both represented in their own body-fixed\nreference frames.\n$$\\omega_r = \\omega_t - \\Gamma \\omega_c$$\n$$\\dot{\\omega}_r = \\dot{\\omega}_t - \\Gamma \\dot{\\omega}_c + \\omega_r \\Lambda \\Gamma \\omega_c$$\nThe relative attitude of the target is established by the parametrization of rotation matrix \u0393. The\nModified Rodriguez Parameters (MRP) are utilized as the minimal set of three parameters that\nallows to overcome singularities and to describe every rotation. The quaternion representing the\norientation of ENVISAT is expressed as q, which consists of four components: 90, 91, 92, and 93.\nThe three-axis angular velocity of ENVISAT is represented by w, with components Wx, Wy, and wz.\n$$q$$\n$\\begin{bmatrix} q_1 \\\\ q_2 \\\\ q_3 \\\\ q_4 \\end{bmatrix} =$\n$\\begin{bmatrix} \\hat{n} \\sin \\frac{\\phi}{2} \\\\ \\cos \\frac{\\phi}{2} \\end{bmatrix}$$"}, {"title": null, "content": "Note that \u00een is the unit vector corresponding to the axis of rotation and @ is the rotation angle.\nMRPs are connected to the quaternions in the following way.\n$$p = \\frac{q}{(1 + q_4)} = \\hat{n} \\tan \\frac{\\phi}{4}$$\nVector p is the MRP vector, with dimension of 3 \u00d7 1. The kinematic equation of motion are able\nto be derived by using the target's relative angular velocity, therefore the time evolution of the MRP\nis described as following.\n$$\\dot{p} = \\frac{1}{2}[(1-p^Tp)I_3 + 2pp^T + 2[p^]]\\omega_r$$\nNote that I3 is a 3 \u00d7 3 identity matrix and [p^] is a 3 \u00d7 3 cross product matrix given as following.\n$$[p^] = $$\n$\\begin{bmatrix}\n0 & -p_3 & p_2 \\\\\np_3 & 0 & -p_1 \\\\\n-p_2 & p_1 & 0\n\\end{bmatrix}$$\nThe rotation matrix that connects the chaser body-fixed frame and the target body-fixed frame\ncan thus be derived as following.\n$$\\alpha_1 = \\frac{4-p^Tp}{(1 + p^Tp)^2}$$\n$$\\alpha_2 = \\frac{8}{(1 + p^Tp)^2}$$\n$$\\Gamma(p) = I_3 - \\alpha_1 [p^] + \\alpha_2[p^]^2$$\nThe absolute rotational dynamics of the chaser is described by the torque-free Euler equations.\nThe relative attitude dynamics are obtained by substituting the kinematics relationship in the Euler\nabsolute equations of the target spacecraft.\n$$J_t\\dot{\\omega_r} + \\omega_r \\land J_t\\omega_r = M_{app} \u2013 M_g \u2013 M_{ci}$$\nNote that Jt is the matrix of inertia of the target, Mapp is the apparent torques, Mg is the gyro-\nscopic torques, and Mci is the chaser-inertial torques.\n$$M_{app} = J_t\\omega_r \\land \\Gamma \\omega_c$$\n$$M_g = \\Gamma \\omega_c \\land J_t\\Gamma \\omega_c + \\omega_r \\land J_t\\omega_c + \\Gamma \\omega_c \\land J_t\\omega_r$$\n$$M_{ci} = J\\Gamma\\dot{\\omega_c}$$"}, {"title": "ENVISAT Satellite Simulation", "content": "The simulation of the spacecraft, specifically the ENVISAT satellite, was meticulously conducted\nin MATLAB. In this controlled environment, we generated detailed models of the satellite's orienta-\ntion and movement patterns, replicating the complex dynamics encountered in orbit. By leveraging\nMATLAB's computational tools, we were able to create accurate ground truth data for both the pose\nand marker locations on the satellite by propagating the equations of motion of the chaser and the\ntarget satellites via using Runge-Kutta-Fehlberg method. This simulation process was critical in\nestablishing a reliable dataset that mirrors the real-world conditions the satellite would experience\nin the space."}, {"title": "Data Preparation", "content": "Upon completion of the simulation, the generated images, encapsulating the precise pose and\nmarker information of the satellite, were transferred to a Python environment for further processing.\nThe transition from MATLAB to Python was essential for integrating the simulation data with the\nimage processing and machine learning pipeline that follows.\nIn Python, one of the initial steps involved converting the RGB images obtained from the sim-\nulation into gray-scale. This conversion is pivotal for the subsequent corner detection process, as\nworking with gray-scale images reduces computational complexity and focuses the analysis on the"}, {"title": "CONVOLUTIONAL NEURAL NETWORK", "content": "CNN is a type of deep learning model designed to process data with a grid-like topology, such\nas images. CNNs use convolutional layers to automatically and adaptively learn spatial hierarchies\nof features from input data. Key components include convolutional layers, pooling layers, and fully\nconnected layers. The architecture of CNNs has evolved from simpler models like AlexNet to more\ncomplex ones like High-Resolution Network (HR.Net). These advancements have significantly\nenhanced their ability to perform tasks like image and video recognition, object detection, and\nmore. The advantages of using CNNs over traditional neural networks in computer vision include:\n\u2022 CNNs weight-sharing mechanism reduces the number of trainable parameters, improving\ngeneralization and reducing overfitting.\n\u2022 Simultaneous learning of feature extraction and classification layers leads to a well-organized\nmodel output that heavily relies on extracted features.\n\u2022 Implementing large-scale networks is more straightforward with CNNs compared to other\nneural network types.\nThe CNN architecture consists of multiple layers, each serving a distinct function:\n\u2022 Convolutional Layer: The core component, using filters (kernels) to process input images and\ngenerate feature maps.\n\u2022 Pooling Layer: Sub-samples feature maps to reduce their size while retaining dominant in-\nformation, using methods like max, min, and global average pooling.\n\u2022 Activation Function: Determines whether a neuron should be activated, mapping inputs to\noutputs."}, {"title": null, "content": "\u2022 Fully Connected Layer: Each neuron connects to all neurons in the previous layer, serving as\nthe classifier.\n\u2022 Loss Functions: Calculate the error between predicted and actual outputs, guiding the learning\nprocess."}, {"title": "CNN Architecture", "content": "Over the past decade, numerous CNN architectures have been introduced. These architectures\nhave significantly enhanced performance across various applications through structural changes,\nregularization, and parameter optimization. Notably, major improvements have stemmed from re-\norganizing processing units and developing new blocks, particularly by increasing network depth.\nThis section examines key CNN architectures from AlexNet in 2012 to the High-Resolution (HR)\nmodel in 2020, analyzing features like input size, depth, and robustness to guide researchers in se-\nlecting the appropriate architecture for their tasks [23]. In our work, chosen neural network model is\nbased on L-CNN, a novel neural network designed for comprehensive wire-frame parsing in an end-\nto-end manner [24]. This network comprises four main components: a feature extraction backbone,\na junction proposal module, a line verification module, and a connecting line sampling module.\nStarting with an RGB image as input, L-CNN efficiently outputs a vectorized representation di-\nrectly, bypassing heuristic methods. The architecture of L-CNN is fully differentiable, allowing for\nend-to-end training via back-propagation. This capability harnesses the full potential of cutting-\nedge neural network designs for effective scene parsing."}, {"title": "UNSCENTED KALMAN FILTER (UKF)", "content": "UKF is an estimation algorithm designed to handle nonlinear systems. Unlike the Extended\nKalman Filter (EKF), which relies on linearizing the system and measurement equations using\nfirst-order Taylor expansions, the UKF employs the unscented transformation to directly address\nnonlinearity without linearization. However, it is important to underline that it still employs a linear\nmeasurement update [26], which better fits the limited computational power of onboard computers.\nThis method involves propagating a set of carefully chosen sample points through the nonlin-\near system to accurately capture the posterior mean and covariance. The primary advantage of\nthe UKF lies in its ability to provide superior performance in highly nonlinear environments. By\navoiding the inaccuracies introduced by linearization, the UKF ensures a more robust and accurate\nestimation process. In the context of spacecraft pose estimation, particularly for missions involving\nrendezvous with uncooperative targets, the UKF is invaluable. It improves the prediction of the\nspacecraft's relative position and attitude, crucial for safe and precise proximity operations. The\nUKF's effectiveness is demonstrated through its application in various scenarios, such as the Eu-\nropean Space Agency's e.deorbit mission, which targets the ENVISAT satellite. The performance\nof the UKF, evaluated through numerous numerical simulations, highlights its advantages in terms\nof accuracy, robustness, and computational efficiency, making it a preferred choice for handling the\nnonlinear dynamics of space missions [27]."}, {"title": "Algorithm Steps", "content": "The weights for the sigma points in the Unscented Kalman Filter (UKF) are determined using\nthe parameters \u03b1, \u03b2, and \u03ba. These parameters help in controlling the spread and scaling of the\nsigma points around the mean. The parameter a determines the spread of the sigma points, \u043a \u0456\u0455 \u0430\nsecondary scaling parameter, and \u1e9e is used to incorporate prior knowledge of the distribution (for\nGaussian distributions, \u03b2 = 2 is optimal). The scaling parameter A is computed as:\n$$\\lambda = \\alpha^2(L + \\kappa) - L$$\nwhere L is the dimensionality of the state vector.\nThe weights for the mean and covariance of the sigma points are given by:\n$$W_c^{(0)} = W_m^{(0)} = \\frac{\\lambda}{L+\\lambda}$$\n$$W_m^{(0)} = \\frac{\\lambda}{L+\\lambda} + (1 - \\alpha^2 + \\beta)$$\n$$W_c^{(i)} = W_m^{(i)} = \\frac{1}{2(L + \\lambda)}, i = 1, ..., 2L$$\nHere $W_m^{(i)}$ are the weights for the mean. $W_c^{(i)}$ are the weights for the covariance and \u5165 is the\ncomposite scaling parameter. These weights ensure that the sum of the weights is 1, which maintains\nthe consistency of the state estimation process."}, {"title": "Summary of Parameters", "content": "\u2022\na: Determines the spread of the sigma points around the mean. Typically a small positive\nvalue.\n\u2022 \u03b2: Incorporates prior knowledge of the distribution. For Gaussian distributions.\n\u2022\n\u043a: A secondary scaling parameter, usually set to 0 or 3-L.\nThe UKF algorithm can be summarized in the following steps:\nInitialization\n$$x_0 = $$\n$\\begin{bmatrix} x_{0,1} \\\\ x_{0,2} \\\\ : \\\\ x_{0,n} \\end{bmatrix}$$\n$$P_0 = $$\n$\\begin{bmatrix}\nP_{0,11} & P_{0,12} & ... & P_{0,1n} \\\\\nP_{0,21} & P_{0,22} & ... & P_{0,2n} \\\\\n: & : & ... & : \\\\\nP_{0,n1} & P_{0,n2} & ... & P_{0,nn} \\end{bmatrix}$$\nFirst, the initial state estimate 20 and the initial state covariance matrix Po are defined. These\nrepresent the initial guess of the state and its uncertainty.\nPrediction Step\n$$\\mathbb{X}_k =$$\n$\\begin{cases}\n\\hat{x}_{k\u22121} & \\text{for } i = 0 \\\\\n\\hat{x}_{k\u22121} + (\\sqrt{(L + \\lambda)P_{k-1}})_i & \\text{for } i = 1, ..., L \\\\\n\\hat{x}_{k\u22121} - (\\sqrt{(L + \\lambda)P_{k-1}})_{i-L} & \\text{for } i = L + 1, ..., 2L\n\\end{cases}$$\nwhere X(i) are the sigma points, 2k\u22121 is the previous state estimate, Pk\u22121 is the previous state\ncovariance, L is the dimension of the state, and A is a scaling parameter.\n$$\\mathbb{X}_{k|k-1} = f(\\mathbb{X}_{k-1}, u_{k-1})$$\nwhere f is the state transition function and uk-1 are the control inputs.\n$$\\hat{x}_{k|k-1} = \\sum_{i=0}^{2L} W_m^{(i)}\\mathbb{X}_{k|k-1}$$\nwhere W(i)\nare the weights for the mean.\n$$\\mathbb{P}_{k|k-1} = \\sum_{i=0}^{2L} W_m^{(i)} (\\mathbb{X}_{k|k-1} - \\hat{x}_{k|k-1}) (\\mathbb{X}_{k|k-1} - \\hat{x}_{k|k-1})^T$$\nwhere W(i)\nare the weights for the covariance and the process noise covariance is set 0."}, {"title": "Update Step", "content": "$$\\mathbb{Y}_k^{(i)} = h(\\mathbb{X}_{k|k-1}^{(i)} )$$\nwhere h is the measurement function and y) is the sigma points that are transformed through the\nmeasurement function. The predicted measurement mean zk is computed as following.\n$$\\mathbb{Z}_k = \\sum_{i=0}^{2L} W_m^{(i)} \\mathbb{Y}_k^{(i)}$$\nThe predicted measurement covariance Sk is calculated as:\n$$S_k = \\sum_{i=0}^{2L} W_c^{(i)} (\\mathbb{Y}_k^{(i)} - \\mathbb{Z}_k) (\\mathbb{Y}_k^{(i)} - \\mathbb{Z}_k)^T + R_k$$\nwhere Rk is the measurement noise covariance. Kalman gain Kk is calculated as following.\n$$T_k = \\sum_{i=0}^{2L} W_m^{(i)} (\\mathbb{X}_{k|k-1}^{(i)} - \\hat{x}_{k|k-1}) (\\mathbb{Y}_k^{(i)} - \\mathbb{Z}_k)^T$$\n$$K_k = T_k S_k^{-1}$$\nNow, the state and the state covariance can be updated as following.\n$$\\hat{x}_k = \\hat{x}_{k|k-1} + K_k(\\mathbb{Z}_k - \\mathbb{Z}_k)$$\n$$P_k = \\mathbb{P}_{k|k-1} - K_k S_k K_k^T$$\nOverall, the UKF stands out as a powerful tool in the realm of nonlinear estimation, offering\nsignificant improvements over traditional methods by leveraging its nonlinear transformation capa-\nbilities."}, {"title": "FILTERING", "content": "The measurement model in filtering combines translational and rotational information. However,\nthe propagation of dynamics can be separated into translational and rotational components, result-\ning in a faster and more efficient estimation of relative translational states (relative position r, and\nrelative velocities vr) and relative rotational states (MRP, p and angular velocities, wr). This ap\nproach allows the state vector, although 12 components long, to be divided into two separate parts\nof 6 components each, propagating the translational and rotational models in parallel. The filters\nuse a 4th-order Runge-Kutta integrator for propagation. At the start, the required marker positions\nand chaser absolute states are loaded, and an initial estimate of the relative states, in terms of mean\nand covariance, is provided. Before beginning the estimation, the filter uses information from the\nprevious step to calculate marker visibility if it is not already given. Depending on the simulation\nrequirements, the filter can operate with the entire set of markers or limit measurements to three"}, {"title": null, "content": "markers, with the selection process explained later. Additionally, measurement failures can be in-\ncluded in the simulation. Finally, the estimated relative states are compared with the true states\npropagated by the dynamics simulator to evaluate filter performance."}, {"title": "MEASUREMENT MODEL", "content": null}, {"title": "Markers Creation", "content": "Filters require accurate measurements to effectively correct the predicted values and accurately\ndetermine the target's attitude. Most filters for space applications depend on camera image process-\ning. In practical scenarios, the image processing software is configured to identify target points in\neach captured image, known as markers. The software processes the camera image, identifies the\nmarker positions, and then transmits this information to the filter. Selecting markers is a complex\ntask influenced by the target's shape, volume, and color, as the image processing must be rapid.\nCommonly, target corners are selected as markers, utilizing reliable corner detection algorithms like\nthe Harris-Stephens [28] and F\u00f6rstner algorithms. Effective interaction between the filter and the\nimage processing software is crucial. After an initial period during which the first measurements are\ntaken and the position error rapidly decreases, the communication should be optimized to expedite\nmarker estimation. Once the filter completes its iterative cycle, it can inform the camera where to\nsearch for markers in the subsequent image. This enables the camera software to analyze a smaller\nimage region, reducing the need to process all pixels and focusing only on those near the predicted\nmarker positions. In the context of the ENVISAT relative pose estimation problem, it was decided\nto use the corners of the main body as markers and track their positions over time. Figure 2 already\nillustrates the dimensions of the spacecraft. The European Space Agency online sources provide de-\ntails about ENVISAT's mass, the location of its center of mass (without propellant), its moments of\ninertia (without propellant), as well as its geometrical center and volume. Consequently, the marker\npositions can offer valuable information since the position of each marker is well known with re-\nspect to the centre of mass. By tracking the trajectory of these markers, the filter can reconstruct the\nstate of the spacecraft and calculate its relative position and velocity. The main body of ENVISAT,\nexcluding the solar panel, can be modeled as a simple parallelepiped with 8 corners. These corners\nare selected as filter markers, and their positions relative to the center of mass are known. Each\nmarker is identified by a letter, resulting in markers labeled A, B, C, D, E, F, G, and H."}, {"title": "Measurement Equations", "content": "The state vector has 12 components that can be divided in four parts, divided into four equal parts.\nEach part, composed by three elements, describes one aspect of the attitude on the target satellite,\nENVISAT.\n$$x = (x, y, z, \\dot{x}, \\dot{y}, \\dot{z}, p_1, p_2, p_3, \\omega_{r,x}, \\omega_{r,y}, \\omega_{r,z})$$\nThe four key components to be tracked are: the relative position between the centers of mass of the\ntarget and chaser, the relative velocity of the center of mass, the Modified Rodrigues Parameters\n(MRP), and the angular velocities. Therefore, it is necessary to evaluate the marker positions based\non the known state to compare the predicted measurements with the actual measurements obtained\nfrom the camera system during the update phase of the algorithm. Let u represent the position\nvector of the chaser's center of mass relative to ENVISAT's center of mass. The measurements\nfor each marker are calculated individually as follows: the marker position vector vi is initially"}, {"title": null, "content": "expressed in the target's reference frame. This vector is then transformed into the chaser's reference\nframe by multiplying it with the rotation matrix \u0393. Finally, the position of each marker relative to\nthe chaser is determined through a simple vector difference.\n$$z_i = \\Gamma v_i - u$$\nHere, zi represents the position of a marker relative to the chaser's center of mass, and the rotation\nmatrix \u0393 is derived from the MRP. Note that MRPs are the part of the state vector, so this is the\nrelation between the states and the measurements too."}, {"title": "Markers Visibility", "content": "The presented measurement model relies on the positions of the 8 corners of ENVISAT's main\nbody. However, the camera cannot capture all marker positions in a single frame because some\nmarkers are obscured by ENVISAT's structure. As a result, the filter cannot use the entire set\nof markers simultaneously; it must adjust its measurements frame by frame based on the visible\nmarkers. Consequently, the size of the measurement vector varies depending on the number of\nvisible markers. Each marker contributes three position components to the observation, so the\nmeasurement vector 2 will have 3\u00b7 i components, where i = 0,...,8. The requirement for face\nvisibility is determined by the following equation: If the scalar product between the relative position\nvector of the chaser and the target, and the unit vector perpendicular to the face is negative, it\nindicates that the face is oriented towards the camera, making the markers on that face visible.\n$$u \\hat{n} <0 \\text{ for } i = a,...,\\zeta$$\nThe filter uses the state information at the beginning of each observation to predict which markers\nwill be visible in the next step, preparing to receive the correct number of measurements from the\ncamera. It has hardcoded the arrangement of ENVISAT's faces according to the vectors \u00een, thereby\npredicting marker visibility. The filter handles marker visibility in a binary manner, assigning a\nvalue of 1 if a marker is visible and 0 if it is not."}, {"title": "PRELIMINARY RESULTS", "content": "Our initial findings demonstrate promising outcomes in the detection and analysis of structural\nmarkers on the ENVISAT satellite through processed imagery. This approach not only enhances\nthe robustness of our detection algorithms under varied operational scenarios but also aligns with\nthe typical image quality captured by space-borne sensors. Each image in our dataset underwent a\npre-processing phase where Gaussian noise and blur were applied. The addition of Gaussian noise\nis intended to mimic the electronic noise and sensor imperfections typically found in spacecraft\nimaging systems. This noise simulates the random variations in pixel intensity that occur due to\nvarious factors including thermal effects and the response of the sensor to cosmic radiation. Si-\nmultaneously, a Gaussian blur was applied to replicate the slight blurring effect caused by minute\nfocusing discrepancies or motion effects that can occur in a spacecraft's optical system."}, {"title": "CONCLUSIONS", "content": "In conclusion, our work successfully demonstrates the capability of a modified CNN to detect\ncorner locations on the ENVISAT satellite, marking a significant advancement in the field of space\ndebris monitoring and removal. Through the use of advanced image processing techniques and\nneural network architectures, we have established a robust method for identifying crucial struc-\ntural markers on satellite imagery, which are vital for the planning and execution of debris removal\nmissions. Looking ahead, the detected corner location data present a valuable asset for enhancing\nnavigational accuracy and operational efficiency in space debris management. In future work, we\nplan to integrate the CNN module which gives corner location data within an UKF framework on-\nline to further refine the pose estimation and tracking of space objects. This integration aims to\novercome the limitations of current tracking systems by providing more accurate and reliable state"}, {"title": null, "content": "estimation under the complex and dynamic conditions of space environments. Moreover, the UKF\nis going to be improved by trying to implement online adaptation of the measurement noise matrix\nrather than setting it into a constant matrix. The potential for this advanced approach to significantly"}]}