{"title": "Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data", "authors": ["Zhi Zhang", "Yan Liu", "Mengxia Gao", "Yu Yang", "Jiannong Cao", "Wai Kai Hou", "Shirley Li", "Sonata Yau", "Yun Kwok Wing", "Tatia M. C. Lee"], "abstract": "Psychological resilience, defined as the ability to rebound from adversity, is crucial for mental health. Compared with traditional resilience assessments through self-reported questionnaires, resilience as-sessments based on neurological data offer more objective results with biological markers, hence significantly enhancing credibility. This paper pro-poses a novel data-efficient model to address the scarcity of neurological data. We employ Neuro Kolmogorov-Arnold Networks as the structure of the prediction model. In the training stage, a new trait-informed multimodal representation algorithm with a smart chunk technique is proposed to learn the shared latent space with limited data. In the test stage, a new noise-informed inference algorithm is proposed to address the low signal-to-noise ratio of the neurological data. The proposed model not only shows impressive performance on both public datasets and self-constructed datasets but also pro-vides some valuable psychological hypotheses for future research.", "sections": [{"title": "1 Introduction", "content": "In contemporary society, psychological stress has emerged as a pervasive challenge affecting individuals across demo-graphic boundaries, regardless of age or gender [Panicker and Gayathri, 2019]. As research into sources of stress, such as those found in the workplace, has advanced, more re-searchers realize that eliminating these stressors is challeng-ing [Lazarus, 2020]. Consequently, the study of resilience, describes the maintenance of stable good mental health or the quick recovery of mental health during or after stressor exposure, has garnered increasing attention in recent years [Kalisch et al., 2017]. Related work shows that after experi-encing stressful events, some individuals adapt by maintain-ing stability and functioning well, whereas others may con-tinue to experience distress [Dong et al., 2018].\nIn the past decades, psychological resilience has been assessed through self-reported questionnaires [Connor and"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Kolmogorov-Arnold Networks", "content": "Kolmogorov-Arnold Networks (KAN) [Liu et al., 2025; Liu et al., 2025] are neural networks inspired by the Kolmogorov-Arnold representation theorem, which represents multivariate continuous functions as sums of univariate continuous func-tions. By introducing learnable univariate functions instead of fixed activation functions, KAN enhances model flexibil-ity and interpretability [Somvanshi et al., 2024].\nRecent studies have demonstrated that KANs offer com-petitive performance in terms of generalization. Zhang et al. [Zhang and Zhou, 2024] provide an analysis of KAN's generalization abilities, establishing theoretical generaliza-tion bounds. Alter et al. [Alter et al., 2024] analyze the ro-bustness of KANs under adversarial attacks. Samadi et al. [Samadi et al., 2024] reveal that smooth KANs embedded with domain-specific knowledge can reduce the data needed for training.\nRecent applications further show significant potential in health and medical [Tang et al., 2024; Jahin et al., 2024; Aghaomidi and Wang, 2024]. However, the application of KANs to EEG and fMRI remains unexplored."}, {"title": "2.2 Multimodal Representation Learning", "content": "Multimodal representation learning aims to learn unified representations from different data modalities, which has achieved remarkable success across various domains [Man-zoor et al., 2023].\nRecent advances demonstrate the effectiveness of joint visual-textual embeddings. Radford et al. propose CLIP [Radford et al., 2021], and show the alignment between vi-sual and textual features through pre-training on large-scale image-text pairs, enabling zero-shot classification of unseen objects. Subsequent works enhanced this paradigm. Gao et"}, {"title": "3 Methodology", "content": "In this section, we propose a method for psychological re-silience prediction from multimodal neuroimaging data. Let $D_{N} = \\{(e_n, M_n, Y_n)\\}_{n=1}^{N}$ denote a dataset of $N$ subjects, where $y_n$ represents the psychological resilience label, and neuroimaging data consists of two modalities. Electroen-cephalography (EEG) signals $e_n \\in R^{C \\times T}$, where $C$ denotes the number of channels and $T$ represents the number of time-points. Functional magnetic resonance imaging (fMRI) sig-nals $m_n \\in R^{R \\times L}$, where $R$ denotes the number of regions of interest (ROIs) and $L$ represents the number of scans."}, {"title": "3.1 Neuro Kolmogorov-Arnold Networks", "content": "Recognizing the distinct characteristics of each modality, in-stead of using a single network architecture to process all modalities, we introduce modality-specific variants to KANs.\nFor EEG signals, which offer excellent temporal resolu-tion capable of capturing neural events at millisecond scale [Sturzbecher and de Araujo, 2012], we propose a hybrid ar-chitecture combining KANs with time-wise convolutions and electrode-wise convolutions. Here, we first employ time-wise convolution to model temporal patterns:\n$TWC(X^{TW})_{i,\\alpha} = \\sigma(\\sum_{k=1}^{K} V^{TW}_{i+k-1,d} w_{k,d})$\nwhere $X^{TW} \\in R^{L \\times D}$ represents the input to time-wise convolution, $W^{TW} \\in R^{K \\times D}$ denotes learnable temporal filters with kernel size $K$, and $\\sigma$ is the SELU activation function [Klambauer et al., 2017]. Following time-wise convolutions, we apply electrode-wise convolution to aggregate temporal patterns across electrodes:\n$EWC(X^{EWC})_{i,o} = \\sigma(\\sum_{d=1}^{D} X^{EWC}_{i,d} W^{EW}_{d})$\nwhere $X^{EWC} \\in R^{L \\times D}$ represents the input to EWC and $W^{EW} \\in R^{D \\times O}$ represents learnable spatial filters that map from $D$ input electrodes to $O$ output channels, with each filter learning to detect specific spatial patterns.\nThen, we stack time-wise convolution to recognize patterns through hierarchical receptive fields. To aggregate informa-"}, {"title": "3.2 Triat-informed Multimodal Representation Learning", "content": "Recognizing that resilience is a relatively stable character trait [Steyer et al., 1999]. For example, one hour or two hours af-ter falling asleep, it is rare for subjects to show significant increase or decrease in stress resilience. Meanwhile, neu-roimaging data is typically recorded over long periods, such as sleep EEG which is usually recorded for around 6 hours. We propose to chunk the long recording of neuroimaging data into small time segments, and use these chunks as samples. In detail, we define a chunk augmentation function $AUG(\\cdot)$ as:\n$AUG(X) = \\{x_i | X_i = \\{X_{d,t} | d \\in [1, D], t \\in [iS, iS + L]\\}\\}_\\{i=0\\}^\\{K-1\\}$\nwhere $L$ denotes the chunk length, $V$ denotes the overlap be-tween adjacent chunks, and $S = L - V$.\nBecause both modalities reflect resilience-related neural patterns and resilience is a stable trait, we hypothesize that resilience-related representations from the same subject should maintain consistency across both temporal chunks and modalities. Therefore, we propose contrastive learning to align multimodal representations. Following CLIP [Radford et al., 2021], we use the batch of data to construct positive and negative pairs, training the model to maximize the similarity between positive pairs and minimize the similarity between negative pairs:\n$\\mathcal{L}\\_{neu} = \\frac{1}{2} (\\mathcal{L}(E, M) + \\mathcal{L}(M, E))$\nwhere $E$ and $M$ represent batches of EEG and fMRI features respectively."}, {"title": "3.3 Noise-informed Psychological Resilience Prediction", "content": "It is known that EEG and fMRI can contain noise unrelated to resilience. For example, eye movements in EEG signals can affect signal quality [Jiang et al., 2019]. Physiologi-cal changes can lead to fMRI signal variations that represent noise rather than brain activity of interest [Liu, 2016].\nWe observe that while both EEG and fMRI data may be affected by noise, causing out-of-distribution representations for psychological resilience, they are influenced by different noise sources, resulting in distinct distributions. When both EEG and fMRI have low noise levels, their in-distribution psychological resilience patterns lead to similar representa-tions, as they successfully capture subject patterns enforced by the contrastive loss without noise interference.\nTherefore, we propose to calculate the similarity between EEG and fMRI representations of the same subject and use this similarity as a metric to identify noisy chunks, assigning them lower weights:\n$SIM(n) = [\\sum_i sim (\\hat{e}\\_n^i, \\hat{m}\\_n^i)] \\| [\\sum\\_j sim (\\hat{e}\\_n^i, \\hat{m}\\_n^i)]$\nwhere $\\hat{e}\\_n^i$ and $\\hat{m}\\_n^i$ denote the representations from the $i$-th chunk of EEG and $j$-th chunk of fMRI of subject $n$ respec-tively, and $||$ represents concatenation. Finally, we can use a simple k-nearest neighbors approach to derive new subjects's prediction by retrieving the most similar subjects:\n$\\hat{y} = \\frac{1}{k} \\sum_{i\\in\\mathcal{N}\\_k(SIM(n))} y_i$\nwhere $\\mathcal{N}\\_k(SIM(n))$ denotes the indices of k-nearest neigh-bors of $SIM(n)$ in the training set representations."}, {"title": "4 Experiments", "content": "We conducted experiments on two datasets: the RESIL and LEMON dataset [Babayan et al., 2019]. The RESIL Dataset is a self-constructed dataset comprising 45 subjects (21 males, 24 females, average age 29.9). For EEG data, signals are recorded for each subject during sleep using six electrodes (F3, F4, C3, C4, O1, O2) placed following the 10-20 system. The sleep recordings were bandpass filtered (0.3Hz-35Hz), resampled to 100Hz, and normalized accord-ing to the Z-score standardization [Wang et al., 2024]. Then, we obtained the imaging data using a 3T Philips MRI scanner, with the resting-state fMRI data acquired and processed fol-lowing Gao et al. [Gao et al., 2020]. For behavioral data, we collected the social relationship quality scale (SRQS), Lubben social network scale (LSNS), intolerance of uncer-tainty scale (IUS), general self-efficacy scale (GSES), and meaning in-life questionnaire (MLQ). We use the Connor-Davidson resilience scale (CD-RISC) as ground-truth.\nThe LEMON Dataset is a public dataset comprising 227 healthy participants comprising a young (108 males, 45 fe-males, average age 25.1) and an elderly group (37 males, 37 females, average age 67.6).\nIn the experiments, we trained the model for 20 epochs with a batch size of 128 samples. The learning rate was set to 0.001 with a weight decay of 0.0. For prediction, we set k to 5. We used the Adam optimizer for optimization. We"}, {"title": "4.1 Comparative Experiments", "content": "We first conduct comparative experiments on the RESIL dataset and the LEMON dataset to evaluate the performance of the proposed method against state-of-the-art methods. We first compare our method with multimodal learning methods, including DCCA [Andrew et al., 2013], DGCCA [Benton et al., 2019], CLIP [Radford et al., 2021], SLIP [Mu et al., 2022], and CLIPMixup [Oh et al., 2024], by replacing the proposed multimodal learning algorithm. We then replace temporal-aware KAN with EEG models, including EEGNet [Lawhern et al., 2018], TCNet [Ingolfsson et al., 2020], Conformer [Song et al., 2022], LMDA [Miao et al., 2023], Labram [Jiang et al., 2024a], CSPNet [Jiang et al., 2024b], and TSLANet [Eldele et al., 2024]. Finally, we replace spatial-aware KAN with fMRI models, including BrainGNN [Li et al., 2021], BNT [Kan et al., 2022], and BrainNPT [Hu et al., 2024].\nAs shown in Table 1, the proposed method outperforms"}, {"title": "4.2 Ablation Study", "content": "We conduct an ablation study to investigate the effectiveness of different designs in the proposed method. First, we ab-late the Neuro Kolmogorov-Arnold Networks (KAN) opera-tion and use multiple-layer perception with linear layers and ReLU activation functions for non-linear modeling. We then ablate the Triat-informed Multimodal Representation Learn-ing (MRL) and replace it with the trivial CLIP loss for mul-timodal alignment. Finally, we remove the Noise-informed Prediction (NP) and use the chunk-level representation for classification and regression with the averaged ensemble, i.e., making predictions using chunk-level representations sepa-rately and ensembling the results as the final prediction.\nAs shown in Table 2, the performance drops on both datasets regardless of which design is ablated, showing that all modules contribute to the resilience prediction. We can find that ablating NP leads to the largest performance degra-dation on both datasets, suggesting without NP, the model fails to aggregate informative chunks and derive subject-level representations. Additionally, we observe that subject-aware"}, {"title": "4.3 Interpretability Experiments", "content": "We then investigate the interpretability of the proposed method in psychological resilience. To locate informative patterns, we assign EEG and fMRI chunks into high and low-resilience groups. For EEG, we follow [Chung et al., 2024] by adding perturbations to frequency bands at different electrodes and observing the resulting changes in multimodal similarity to derive importance scores. For fMRI analysis, due to numerous functional connections, we adopt guided backpropagation [Springenberg et al., 2014] to calculate the similarity between modalities and perform backpropagation, using the absolute gradient to derive importance scores. We"}, {"title": "4.4 Exploration Experiments", "content": "To gain further insights, we conduct experiments to explore the complementarity and consistency between modalities. For complementarity, we visualize EEG and fMRI represen-tations on a 2D plane using t-SNE for the RESIL dataset sam-ples. We use red and blue colors to indicate high and low resilience respectively, while circles represent EEG features and triangles represent fMRI features.\nAs shown in Fig. 3, low resilience samples cluster on one side while high resilience samples cluster on the other, demonstrating successful alignment between EEG, fMRI, and behavioral data. Subjects with similar mental states are pulled closer, while those with different mental states are pushed apart. We observe that EEG distributions are concen-trated but show overlap between low and high resilience clus-ters, while fMRI distributions are dispersed but show instance"}, {"title": "4.5 Case Study", "content": "Finally, we conduct a case study to investigate the insights of NP, specifically examining why different chunks should be treated differently. We begin by forming EEG and fMRI chunk pairs from the same subject and iterating through these pairs. We bin the chunk pairs according to similarities be-tween their multimodal representations and record the sample number across different similarity levels. We then evaluate classification performance using individual chunk pairs and analyze the performance distribution across different similar-ity levels.\nAs shown in Fig. 5, we observe that the similarity follows a long-tail distribution, where most EEG and fMRI samples are similar, but some exhibit low similarity. This indicates that while most chunks are successfully aligned, some remain un-aligned. Furthermore, we find that chunks with low alignment show poor classification accuracy (around 65% when similar-ity is 0.05), suggesting these might be noisy chunks or chunks lacking resilience-related information. Based on these find-ings, we design our model to highlight aligned chunks while neglecting unaligned ones, achieving over 85% accuracy with discriminative subject-level representations."}, {"title": "5 Conclusions and Future Work", "content": "This paper proposes a novel data-efficient model to predict resilience based on EEG and fMRI data. Several new tech-niques including a multimodal alignment algorithm to dis-cover the nonlinear hidden patterns, a chucking algorithm for data argument, and a noise-informed inference algorithm to assess the quality of the neurological data, work together on the KAN-based architecture, and have achieved the im-pressive performance compared with SOTA algorithms on both RESIL and LEMON datasets. Interpretability experi-ments reveal learned patterns while exploration experiments show the complementarity and consistency between modal-ities. Recent work has also demonstrated the potential of KANs in providing interpretable symbolic formulas. In fu-ture work, we plan to leverage the interpretability of KANS to derive deeper neuropsychological insights."}]}