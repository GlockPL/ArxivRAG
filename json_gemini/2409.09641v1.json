{"title": "AACessTalk: Fostering Communication between Minimally Verbal Autistic Children and Parents with Contextual Guidance and Card Recommendation", "authors": ["Dasom Choi", "SoHyun Park", "Kyungah Lee", "Hwajung Hong", "Young-Ho Kim"], "abstract": "As minimally verbal autistic (MVA) children communicate with parents through few words and nonverbal cues, parents often struggle to encourage their children to express subtle emotions and needs and to grasp their nuanced signals. We present AACESSTALK, a tablet-based, AI-mediated communication system that facilitates meaningful exchanges between an MVA child and a parent. AACESSTALK provides real-time guides to the parent to engage the child in conversation and, in turn, recommends contextual vocabulary cards to the child. Through a two-week deployment study with 11 MVA child-parent dyads, we examine how AACESSTALK fosters everyday conversation practice and mutual engagement. Our findings show high engagement from all dyads, leading to increased frequency of conversation and turn-taking. AACESSTALK also encouraged parents to explore their own interaction strategies and empowered the children to have more agency in communication. We discuss the implications of designing technologies for balanced communication dynamics in parent-MVA child interaction.", "sections": [{"title": "1 Introduction", "content": "Minimally verbal autistic (MVA)\u00b9 children engage in communication mainly with nonverbal cues, non-speech vocalizations, or a small repertoire of words or fixed phrases [53]. Regardless of the form, communication with parents is just as essential for autistic children's emotional and social development as it is for non-autistic children [12]. However, parents often shoulder the significant responsibility of driving this communication, initiating conversations by asking questions, interpreting nuanced communicative signals, and constantly responding to encourage the child's participation [29, 66]. As parents manage these interactions with little cooperation from their children, they experience feelings of isolation and frustration [31].\nTo encourage the child's participation in communication, many parents have adopted Augmentative and Alternative Communication (AAC) systems, such as symbol cards, that children can use instead of verbalizing their message [13]. While these tools enable MVA children to express themselves by selecting visualized symbols of words, they are often criticized for failing to capture the child's authentic thoughts and feelings as the symbols tend to prioritize functional communication over the user's personal context and true intent [27, 102]. Most AAC systems are pre-programmed with \"necessary words\" chosen by service providers and, in most cases, by parents [5, 75]. As a result, children's messages are often limited to the boundaries set by parents rather than reflecting children's unique experiences and perspectives.\nPrevious studies have examined how MVA children can take a more active role in communication with their parents. Parent training, often conducted with therapists in face-to-face settings [64, 107], remotely [9, 95], or self-guided by video materials [28, 47], have equipped parents with strategies to encourage their children to communicate [51, 78]. Research in special education and HCI also proposed conversational storyboards based on behavioral data [15, 98], or customizable AAC systems that generate vocabularies based on geographical data [32, 82] or photographs [38, 39]. However, previous attempts have primarily considered education-oriented language-learning contexts that target either parents or children, lacking an integrated approach to empower both parties in everyday communication on the fly.\nIn this work, we aim to support the agency of both parents and MVA children in reciprocal communication by designing and developing an intelligent system that mediates their conversational interaction. To that end, we conducted formative interviews with nine autism experts and five parents of MVA children to better understand communication challenges between parents and MVA children and glean insights from professional practices to enhance communication. The interviews revealed that parents exert significant control over the structure and topics of conversation, underscoring the need to support turn-taking between parents and children around mutually engaging subjects.\nBased on these insights, we designed and developed AACESSTALK (Figure 1), a communication mediation system that fosters meaningful exchanges of ideas and emotions through mutual contribution between MVA children and their parents. AACESSTALK runs on a tablet accompanied by a hardware button (Figure 1, bottom) for taking turns, providing an environment for explicit turn-taking conversations. On the parent's turn, the app provides guide messages on what and how to respond to the child (Figure 1, left). On the child's turn, the app curates a set of vocabulary cards relevant to the conversational context (Figure 1, right). To accommodate a range of in-situ, daily topics, AACESSTALK leverages large language models (LLMs) to generate parental guidance and card curation, based on the parent's voice input transcribed in text and the child's input in selected cards.\nTo examine how parents and MVA children interact with AACESSTALK and how the system impacts their communication, we conducted a two-week home deployment study with 11 parent-child dyads in South Korea. Our results show a considerable level of participant engagement in communication through AACESSTALK, carrying out 232 conversation sessions in total. During these interactions, parents incorporated AACESSTALK's parental guidance in 78% of their turns, and children selected a total of 2,244 AAC cards recommended by the system. The debriefing interviews and daily surveys revealed that AACESSTALK alleviated parental pressure to have MVA children produce complete sentences and provided the children chances to express their communicative intent. Furthermore, using AACESSTALK motivated parents to depart from brief and instructive dialogue, turning conversations with their MVA children into daily routines focused on empathy and understanding.\nThe contribution of this work is fourfold:\n(1) Findings from a formative study with nine autism experts and five parents of MVA children, revealing the unique challenges in communication between minimally verbal autistic children and their parents, along with the current best practices in the field.\n(2) The design and implementation of AACESSTALK, an AI-driven communication mediation system that supports turn-taking conversations, offering parental guidance to parents and recommending AAC cards to the child, encouraging mutual participation in parent-child communication."}, {"title": "2 Related Work", "content": "In parent-child communication, a child's self-expression is fundamental in establishing a shared understanding, which allows parents to address the child's unique needs and challenges effectively [63]. However, forming this shared understanding is often challenging within neurodiverse dyads-comprising MVA children and non-autistic parents [120]. This is because, first, MVA children often have lower intrinsic motivation to communicate [86], and thus reveal less of their inner selves to their parents. Second, they tend to express their needs and opinions through various modalities beyond verbal language, such as touch, sound, pointing, and gestures [104]. Even their nonverbal vocalizations can hold emotional and self-expressive information [52], yet parents often struggle to interpret these subtle communication cues [29]. While communication difficulties in these neurodiverse dyads stem from differences in how they perceive and express the world, many educational and technological efforts have focused on teaching and supporting verbal communication to MVA children [21, 55].\nThe field of HCI has contributed numerous assistive communication technologies aimed at empowering MVA children to have a \"voice.\" Importantly, these recent efforts redefine having a \"voice\" not just as the ability to speak, but as enabling MVA children to represent themselves by having a communicative agency [3]. This paradigm shift also aligns with the Ability-Based Design approach [117, 118], which focuses on individuals' abilities rather than limitations, encouraging MVA children to engage in communication on their own terms. For example, Wilson et al. developed a personalized interactive dictionary that taps into MVA children's special interests to motivate self-expression [111]. Researchers have also proposed tangible devices that enable MVA children to express themselves through sound, light, touch, and body movement [91, 113], AAC tools with symbolic images or photos [38, 39], and letterboards [1, 73]. Some have even involved the children as design partners in creating these technologies [39, 112]. While previous studies have facilitated more independent self-expression in MVA children, there has been relatively less focus on how parents engage in communication with MVA children. Communication inherently involves interdependent actions that require mutual effort from all parties. Bennett et al. [11] applied the concept of interdependence from Disability Studies to the design of assistive technology (AT), proposing that AT needs to support collaborative efforts among people with disabilities, those they interact with, and their surrounding environments. Through the lens of interdependence, current communication technologies for MVA children-parent dyads predominantly focus on facilitating access for MVA children. This unilateral targeting can inadvertently overlook neurotypical parents' accessibility to engage in conversations with their neurodiverse child, potentially leading to frustration and feelings of alienation [31]. Thus, we see a critical opportunity in designing AT that assist communication by accommodating the needs of both MVA child and the parent. Specifically, our work integrates previously separated communication supports for parents and MVA children into a unified system to mediate real-time interactions."}, {"title": "2.2 Parenting Technology Support", "content": "There has been a growing emphasis on family-centered support for autistic children, highlighting the need for parents to actively engage in setting goals, making decisions, and implementing interventions at home to improve interactions with their children [14]. This led parents to learn new modes of communication, adapt their interaction styles, and modify their home environments [2, 6]. Moreover, for the successful integration of those changes and interventions, including AAC, parents are required to have specialized training to learn effective strategies [19, 33, 41, 43, 76, 85]. Despite these efforts, the visibility of improvements or responses from autistic children to these interventions can vary significantly [83], making it challenging for parents to reflect on and adjust their parenting and communication strategies.\nThe HCI researchers have explored real-time interventions to assist parents in interacting with their children. Several studies aim to facilitate parental reflection by providing direct access to interaction data. For example, the Dyadic Mirror [57], a wearable mirror worn around a child's neck, shows parents live views of their own face, increasing their awareness of emotional states. SpecialTime [49] utilizes a predefined set of guidelines derived from Parent-Child Interaction Therapy (PCIT) to track parent interactions and provide auto-labeled feedback after conversation. Another tool, TalkLime [93], employs real-time visualizations to analyze the number of utterances, initiation ratios, and turn-taking between parents and children.\nBuilding on advances in multimodal sensors and Al automation, recent studies offer more direct feedback and contextual guidance by analyzing conversation dynamics between parents and children. TalkBetter [50] monitors conversations between parents and language-delayed children, triggering alerts when parents show undesirable language habits, such as interrupting, speaking too quickly, or not waiting. Captivate! [61] focuses on play sessions with language-delayed children, identifying objects of joint focus and displaying related phrases on a tablet. TIPS [48] offers context-responsive recommendations of American Sign Language (ASL) for hearing parents of Deaf and Hard of Hearing (DHH) children. While numerous technological attempts have demonstrated the potential of at-home parental guidance, there have been few efforts to support parents of autistic children, particularly in minimally verbal contexts. Thus, our work extends this line of research by integrating professional knowledge and approaches for enhancing interaction with autistic children into guidance strategies, specifically supporting parents in communicating with their MVA children."}, {"title": "2.3 AAC for MVA children", "content": "Symbol-based AAC tools, which allow users to select symbolic images representing specific objects or concepts, have been widely adopted by MVA children to facilitate their self-expression and social participation [62]. While the effectiveness of AAC in learning language and requesting needs has become evident [96], several barriers persist in its implementation for everyday conversation [27]. Low-tech AAC in the form of paper cards, often used in the initial stages of adoption, is time-consuming for parents to prepare [23] and has limited portability when carrying many images [46]. As for high-tech AAC devices, such as tablets, children often struggle to navigate numerous cards to find those suitable for specific communication purposes [26, 67]. Although these tools commonly support configuring a preset of the AAC vocabulary in advance for that reason, the presets are not flexible to cover serendipitous topics that arise in real-time, everyday conversations [23, 45, 97]. Moreover, the vocabulary presets are often selected by others, mostly parents, which makes it uncertain whether they truly reflect the child's intentions [5, 75].\nA large body of research on AAC technologies has focused on recommending appropriate vocabulary or symbols, primarily aimed at enabling AAC users to participate in communication more efficiently. Early work employed rule-based algorithms to predict relevant words or similar symbols based on the user's input of alphabets or symbols [99, 105]. Subsequently, several works analyzed the speech of a conversation partner with Natural Language Processing and suggested context-appropriate noun phrases to users [115, 116]. Recently, the introduction of AI and Large Language Models (LLMs) has allowed for the recommendation of relevant sentences based on users' abbreviated text entry [20, 100, 101]. Furthermore, Vargas et al. [38, 40] have developed AI-driven AAC boards, which create narrative stories with vocabulary cards based on photos provided by users. Neamtu et al. [74] also proposed LIVOX, an AI-based system that recommends pictograms based on the user's geographic location and time data.\nAlthough existing systems have shown a promising avenue for AI-driven AAC technologies, they rarely target communication with MVA children, which calls for consideration beyond the quick navigation of cards. Many of these children tend to exhibit a significant gap between receptive and expressive language [22], which means they may know specific words and phrases but struggle to recall them when needed. In this context, building on prior research on AI-based AAC recommendations, we aim to explore how AI can act as a stimulus to prompt expressions in MVA children, potentially their vocabulary."}, {"title": "3 Formative Study", "content": "To inform the design of AACESSTALK, we conducted 14 semi-structured interviews with autism experts and parents of MVA children. We aimed to understand the challenges in communication between MVA children and their parents and identify professional practices and parental efforts to enhance communication. We tailored the interview protocols for each group-experts and parents-and conducted the interviews separately to better elicit their unique experiences and perspectives. Both interview studies were approved by the Institutional Review Board."}, {"title": "3.1 Procedure and Analysis", "content": "For both groups, the interviews were conducted either in-person or remotely depending on the participant's convenience and availability."}, {"title": "3.1.1 Interviews with Autism Experts", "content": "We recruited nine autism experts (E1-9) by distributing flyers to local private psychiatry hospitals and child development centers. The participants included two child psychiatrists, two child development specialists, two speech-language pathologists, one child psychotherapist, one elementary special education teacher, and one behavioral therapist. The experts had an average of 15.56 years of experience (ranged 8-25 years), and all of them had clinical experiences with MVA children in promoting their language and behavioral development.\nWe first asked about the communication challenges MVA children and their parents have, the patterns of AAC adoption and usage within these families, and the strategies experts used to understand the intentions of MVA children and facilitate reciprocal conversations. Following this, we presented a video prototype to prompt experts to grasp the concept of an AI-driven communication mediation system. The video depicted a scenario in which a parent and a MVA child discussed \u201cwhat happened today\" using a tablet-based application that suggests conversational guides to the parent and AAC symbols to the child. We asked the experts about the clinically desired direction of conversations, principles of parental guidance, potential opportunities for Al integration, and any potential risks. The interviews lasted about 1 to 1.5 hours. We offered a 100,000 KRW (approx. 80 USD) gift card as compensation."}, {"title": "3.1.2 Interviews with Parents of MVA Children", "content": "We recruited five parents (F1-5) of MVA children by snowball sampling and the internal network of one researcher, who is both an autism specialist and a parent-child counselor for autistic families. The participants included four mothers and one father, with an average age of 44.2 years (ranged 36-51, SD = 5.11). Four of the parents had sons, and one had a daughter, with the children's average age being 9 years (ranged 6-14, SD = 2.83). Three families actively used low-tech AAC with paper symbol cards at home and in educational settings, while the other two had been advised to adopt AAC but not yet tried.\nThe interviews, which lasted about an hour, began by discussing the communication characteristics of MVA children and the parents' experiences with AAC adoption and application. To better capture the nature of current interactions between parents and their MVA children in everyday conversation, we provided a comic strip (See Figure 9a) with images of a parent and a child and blank speech bubbles. Parents were asked to fill in the bubbles with examples of enjoyable or challenging conversations they had with their child. We then asked about the efforts parents had made to enhance communication with their child, the strategies that led to successful outcomes, and any difficulties they encountered in the process. Finally, we explained the basic concept and capabilities of LLMs and invited parents to share their expectations regarding the potential role of Al in supporting parent-child communication. We offered a 50,000 KRW (approx. 40 USD) gift card as compensation."}, {"title": "3.1.3 Analysis", "content": "All interviews were audio-recorded and later transcribed. Applying Thematic Analysis [18], one researcher open-coded the transcript to identify emerging themes. All researchers on the team held multiple rounds of discussions to finalize the themes. In the following, we present the results from the formative study."}, {"title": "3.2 Finding 1: Parent-Led Conversations", "content": "Both our expert and parent participants pointed out that conversations between MVA children and their parents are often led by parents, where the parent's level of engagement is markedly higher than that of the child. This was particularly evident in two aspects: the conversation structure and the content of the conversation."}, {"title": "3.2.1 Control over the Conversation", "content": "We found that most parents had a significant level of control over the entire conversation with their MVA children. For example, all conversations were initiated by the parent, as MVA children often have challenges in making spontaneous communication attempts [89]. The parent also determined when to conclude the conversation upon noting nonverbal signals from the child getting overwhelmed or disengaged. Even during conversations, when the child remained silent or slow to respond, parents would steer the interaction by asking continuous questions to prevent the conversation from coming to a halt. As a result, most interactions involved minimal turn-taking, typically only 0 to 1 exchange.\nIn conversation with children who are unfamiliar with self-expression and social interaction, it is natural and encouraged for the parent to guide the conversation [24]. However, some experts pointed out that such asymmetric dynamics could limit the child's opportunities to learn that communication is an effective means to convey their intentions, leaving them as passive participants. Experts suggested that for meaningful conversations that enhance parent-child bonding, the system should support reciprocal exchanges between the child and parent. E7 remarked: \u201cBoth the parent and the child need to learn that a conversation isn't something you do alone. It's back-and-forth. But because one person (the parent) is speaking and the other (the MVA child) isn't, they participate in asymmetrical ways, so they've had fewer chances to really build this skill.\""}, {"title": "3.2.2 Teaching Speech instead of Communication", "content": "Parent participants reflected that their conversations with their MVA children at home often focused on repeatedly teaching essential words for daily life, with an emphasis on producing correct sentences. F1 mentioned, \"As my child grows older and has to go to preschool or school without me, they need to at least know how to say things like 'bathroom' or 'water.' It feels urgent to make sure they can say those basic words.\" Experts noted that parents can become so absorbed in honing their child's speech that they mistakenly believe a few spoken words mean they're having a conversation. E4 said: \u201cAutistic kids often repeat the same word over and over throughout the day. So the parents take that as a chance to ask questions. But the kid just keeps saying the same word. In the end, there's nothing shared between them.\" They propose that instead of teaching what the parent believes necessary, it's important to establish a shared interest between the parent and child and provide rich resources and stimuli that can enable the child to express their thoughts and feelings."}, {"title": "3.3 Finding 2: Lack of Actionable Parental Guidance", "content": "Regarding parents' challenges in improving conversations with their MVA children, most parent participants mentioned difficulty in applying key principles and strategies from parent training in day-to-day conversations. Considering the broad spectrum of characteristics displayed by autistic children, the communication guides currently available to parents are often too general and impractical. F3 remarked: \"After my child was diagnosed with autism, I bought these huge, thick books, watched every YouTube video by doctors, and got all sorts of pamphlets from the therapy sessions on how to guide conversations. I know what's important now. But all that material is really broad. When I try to use it with my child, I just freeze, and the words don't come out right.\" Similarly, F4 recalled, \"My child's speech therapist once told me, 'Most of your conversations with your child are just questions. You need to diversify your interactions.' It was a huge revelation. But then I realized I have no idea what to say if I'm not asking a question.\"\nSome parents (F2 and F4) closely observed how the therapist conversed with their child during clinic sessions and then practiced the therapist's phrases at home. However, they pointed out that it's impossible to collect examples for every situation and topic."}, {"title": "3.4 Reflection: Opportunities for Als as Communication Mediators", "content": "To address the challenges mentioned above, parent participants have implemented various professional supports and workarounds. Most of them (F1, F3, F4, and F5) attended parent training sessions led by therapists, and some (F1, F2, and F3) created customized AAC cards using photos of objects, people, and activities from their child's daily life. However, they noted that these approaches are not always readily available and impose significant time and cost burdens, raising concerns about their long-term sustainability. This led participants to express the expectation that AI could provide low-cost, accessible at-home guidance for parents and AAC card curation for MVA children. F5 remarked, \"I heard AI can make drawings now. The first thing I thought was, it'd be great if it could make AAC cards for my kid. My child's growing up, but I can't keep up with making the cards. So lately, I feel like they're not really useful anymore.\" Experts also recognized the potential of AI to broaden the range of expression and interaction in parent-child conversations. However, they emphasized that the parent and child should remain the primary drivers of the conversation, with Al's suggestions serving only as a point of reference."}, {"title": "4 AACESSTALK", "content": "Informed by the formative study, we designed and developed AACESSTALK, a communication mediation system for both parent and MVA child. In this section, we discuss our design rationales from formative interviews and literature, user interface and system components of AACESSTALK, description of generative pipelines, and implementation details."}, {"title": "4.1 Design Rationales", "content": "From the formative interviews, experts stressed the importance of MVA children having more control throughout the conversation process, thereby inviting them to engage in back-and-forth exchanges with their parents. Given that autistic children are often visual learners [58], we decided to provide visual and behavioral cues to make them better understand the flow of conversation and effectively express their intentions through actions. To this end, we set the system on a tablet device so that both the parent and child can visually track the conversation while jointly focusing on the screen. When starting a conversation, the parent and child are guided to select a topic together. Finally, a shared turn pass button (Figure 1, bottom) serves as a turn-switching signal, reinforcing the concept of turn-taking in a tangible way.\nConsidering the parents' needs for immediately applicable conversation guides, we leveraged LLMs to provide context-aware guidance grounded in expert knowledge, along with relevant conversational examples. Drawing on strategies from the Hanen More than Words program [107], we identified 12 parent response types to promote communication with MVA children (see Table 2), which were reviewed by one of our expert authors and then incorporated into the LLM prompts. Additionally, based on Parent-Child Interaction Therapy (PCIT) [35], we outlined three types of negative conversational patterns that parents should avoid (see Table 3). When such responses are detected during conversations, parents would receive real-time feedback.\nUpon the experts' concerns about parents' overreliance on AI suggestions, we implemented two safeguards. First, we limited the number of guides provided on a screen to three, allowing parents their own room to ideate proactively. Second, the example utterances would not appear automatically; instead, parents must tap guides to reveal the examples. In doing so, we intended to encourage parents to internalize the guidance and implement it in their own words. All guides, examples, and feedback are presented in a concise, glanceable format to minimize disruption during conversation.\nMVA children often struggle to retrieve the appropriate words, even when they have something to express [109]. Generating a variety of AAC cards using LLMs can help the MVA child to recognize unmet needs and boost self-expression. Considering the age and vocabulary of MVA children, we simplified the AAC board into a more accessible format. We structured the AAC board into four categories: Topic, Action, Emotion, and Core. This setup provides balanced exposure to various linguistic components. Topic and Action words are contextually generated by the LLM, whereas Emotion words are curated from a predefined set of 12 basic emotions-which were crafted in consultation with experts-specifically aimed at autistic children who struggle to grasp complex and subtle emotions [4]. Typical AAC tools provide Yes and No as Core cards by default. We expanded them to include I don't know, which allows children to avoid habitual, non-meaningful responses, and How about you, mom/dad? to facilitate mutual exchange in conversations (See Figure 3-3). To reduce cognitive load, each category presents only four cards at a time, resulting in a total of 12 AI-recommended cards and four default options on the screen. A refresh button is also provided, allowing children to request new recommendations if the initial ones do not meet their needs, ensuring they are not forced to choose a word that doesn't align with their intent. Moreover, for children who struggle with symbol recognition, photos of familiar people, places, and objects are pre-uploaded and used as custom AAC symbols."}, {"title": "4.2 User Interface and Interaction with AACESSTALK", "content": "Users first select conversation topic (Figure 3-1), then the interface moves to the parent's turn, displaying parental guides on the screen (Figure 3-2). By starting with the parent's turn, we aimed to gather contextual hints from parent's speech to recommend suitable AAC cards. If the child wanted to take their turn first, the user could simply press a turn pass button to skip the parent's turn and move directly to the child's. Once the parent completes their turn, it transitions to the child's turn, showing the AAC board (Figure 3-3). This alternating exchange between parent and child continues until the conversation concludes (Figure 3-4).\nHere, we illustrate a hypothetical scenario of a MVA child-parent communication with AACESSTALK. Every evening, Daniel and his 5-year-old autistic daughter, Emma, share a special moment to talk about their day. Tonight, they sit at Emma's bedside table and launch the AACESSTALK app on a tablet with a set of turn pass button in front of them. The AACESSTALK displays three topic cards on the main screen (Figure 3-1): (1) What to do today? (Plan)-sharing the day's schedule to reduce the child's anxiety about unexpected events [60], (2) What happened today? (Recall)-discussing the day's experiences to support the parent and child in processing and reflecting on what happened [70], and (3) Emma's favorite things (Interest)-talking about a topic the child enjoys to increase their motivation to participate in the conversation [114]. Daniel is curious about Emma's experience during the job exploration field trip at kindergarten. So, among the three conversation topics on the main screen, he selects the \"What happened today\" topic.\nThe AACESSTALK then transitions to the parent turn screen (Figure 3-2). When the parent's turn begins, recording starts automatically to transcribe Daniel's speech, with an animated recording indicator appearing in the top left corner. In the center of the screen, three conversation guides generated by LLMs are presented as cards to help Daniel to start the discussion about today's event. Daniel skims through the options and picks one that starts with: \"Remind Emma of the important events from today. He pauses briefly, considering how to make it engaging for Emma. Then he taps on the guide, and an example phrase pops up. Inspired, Daniel says, \"Emma, did you see the firefighter you like at the job trip today?\" and then presses the turn pass button to signal the end of his turn.\nAACESSTALK now switches to Emma's turn (Figure 3-3). In the center of the screen, each of the three sections, labeled Topic, Action, and Emotion, displays four AAC cards related to firefighters. Emma carefully looks through the cards and taps on the Firetruck card. Then the card appears in the selected card area at the top of the screen, and the app voices, \"firetruck\" Emma then touches the refresh button in the bottom right corner to receive new card suggestions. She then selects Ride, Fire hose, and Happy. After a pause, she looks up at Daniel. Daniel says,"}]}