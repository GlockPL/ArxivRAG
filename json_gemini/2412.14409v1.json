{"title": "Multi-task Representation Learning for Mixed Integer Linear Programming", "authors": ["Junyang Cai", "Taoan Huang", "Bistra Dilkina"], "abstract": "Mixed Integer Linear Programs (MILPs) are highly flexible and powerful tools for modeling and solving complex real-world combinatorial optimization problems. Recently, machine learning (ML)-guided approaches have demonstrated significant potential in improving MILP-solving efficiency. However, these methods typically rely on separate offline data collection and training processes, which limits their scalability and adaptability. This paper introduces the first multi-task learning framework for ML-guided MILP solving. The proposed framework provides MILP embeddings helpful in guiding MILP solving across solvers (e.g., Gurobi and SCIP) and across tasks (e.g., Branching and Solver configuration). Through extensive experiments on three widely used MILP benchmarks, we demonstrate that our multi-task learning model performs similarly to specialized models within the same distribution. Moreover, it significantly outperforms them in generalization across problem sizes and tasks.", "sections": [{"title": "1 Introduction", "content": "Many real-world problem domains, such as path planning [46], scheduling [17], and network design [10,25], fall into the category of combinatorial optimization (CO) and are generally NP-hard to solve. Designing efficient algorithms for CO problems is both important and challenging. Mixed Integer Linear Programs (MILPS) provide a versatile framework for modeling and solving various CO problems. MILPs involve optimizing a linear objective function subject to linear constraints, with some variables restricted to integer values. Significant advancements in MILP solvers, such as Gurobi [20] and SCIP [5], have been achieved by leveraging techniques like Branch-and-Bound (BnB) [36], complemented by a suite of heuristics to enhance performance.\nRecent advancements in machine learning (ML) offer new avenues to improve MILP solvers. ML methods, by learning from complex historical distributions, can enhance both exact solvers like BnB and heuristic solvers. For exact solvers, ML techniques can predict tasks like which node to expand [49,35], which variable to branch on [30,19,7], which cut to apply [50,45], or how to"}, {"title": "2 Background", "content": "This section defines MILPs and provides background knowledge on our three tasks: CONFIGURATION, BACKDOOR, and PAS."}, {"title": "2.1 Mixed Integer Linear Programming", "content": "A Mixed Integer Linear Program (MILP) P = (A, b, c, I) is defined as:\nmin{cx | Ax < b, x \u2208 R\", xj \u2208 {0,1}\u2200j \u2208 I},\nwhere A \u2208 Rm\u00d7n, b\u2208Rm, c\u2208 R\", and I \u2286 {1, ..., n} is the set of indices for bi-nary variables. The objective is to minimize cx by finding a feasible assignment for x that satisfies the constraints. MILP solvers rely heavily on Branch-and-Bound (BnB) [36] that constructs a search tree to find feasible solutions with minimum costs. This process involves repeatedly solving LP relaxations of the MILP and branching on integer variables that are fractional in the LP solution, creating subproblems until all integrality constraints are met.\nA key aspect of MILP solvers is their vast configuration space, with param-eters spanning integer, continuous, and categorical values, influencing nearly every step of the BnB process. While the solvers' default settings aim for robust performance across heterogeneous MILP benchmarks, there is significant poten-tial to improve configuration settings for specific distributions of instances by selecting the solver parameters effectively (CONFIGURATION)."}, {"title": "2.2 Backdoors for MILP", "content": "Initially introduced for Constraint Satisfaction Problems [53], backdoors were later generalized to MILPs [11]. In the context of MILPs, strong backdoors are defined as subsets of integer variables such that branching exclusively on these variables yields an optimal integral solution. Research [16] has further demonstrated speedups in MILP solving times by prioritizing branching backdoor variables instead of branching exclusively on them.\nGiven a MILP instance P = (A, b, c, I), a pseudo-backdoor (BACKDOOR) of size K < |I| is a small subset B C I of binary variables, with |B| = K, whose variables are prioritized for branching to improve solver performance [15,7]. We guide the solver's decision-making process by assigning higher branching priority to the variables in B at the start of the tree search. This adjusted branching order influences the solver's primal heuristics and enhances the overall pruning efficiency in the BnB procedure."}, {"title": "2.3 Predict-and-Search", "content": "Predict-and-Search (PAS) [21] is a primal heuristic that leverages the prediction of the optimal solutions to guide the search process. Given a MILP instance, P = (A, b, c, I), let po(xi | P) denote the predicted probability for each binary variable xi \u2208 I. PAS identifies near-optimal solutions by exploring a neighborhood informed by these predictions. Specifically, it selects ko binary variables Xo with the smallest po(xi | P) and k\u2081 binary variables X1 with the largest po(xi | P), ensuring Xo and X1 are disjoint (ko + k1 \u2264 q). Variables in Xo are fixed to 0, and those in X\u2081 are fixed to 1 in a sub-MILP. However,"}, {"title": "3 Related Work", "content": "This section provides an overview of related work in learning techniques for MILP solving, focusing on learning to branch, solution prediction, and algorithm configuration. Additionally, it highlights research about generalization in the context of ML-guided solving."}, {"title": "3.1 Machine Learning for MILP Solving", "content": "There has been extensive research leveraging machine learning techniques to improve MILP solvers. Common approaches represent MILPs as bipartite graphs [19] and employ graph neural networks (GCN [19,12,45,32,52,27,24] and GAT [26,7]) to learn various MILP decisions. Learning methods are diverse, some commonly used are imitation learning [22,49,45], contrastive learning [26,7,27,39], and re-inforcement learning [50,48]. For a comprehensive survey on machine learning for MILP solving, we refer readers to [47]. Here, we focus on our selected three tasks.\nLearning to branch: Several studies [30,42,3,19,39] have explored learn-ing to branch by imitating strong branching heuristics and predicting scores or ranking variables. Still, these approaches require solver-specific implementations and multiple test-time inferences. In contrast, backdoor approaches [15,7] focus on predicting branching variables at the root node, treating the solver as a black box with a single inference. The first work to use ML-guided techniques for iden-tifying effective backdoors is [15], which employs a scorer model and a classifier model trained on data collected via biased sampling methods from [11]. Building on this, [7] utilizes a contrastive learning model to generate backdoors, leverag-ing a novel Monte Carlo tree search-based data collection approach introduced in [33].\nSolution prediction: The goal is to predict partial assignments of high-quality feasible solutions in a MILP to guide the search. [12] identifies variables that remain unchanged across near-optimal solutions and searches within their neighborhood. [43] and [32] propose fixing predicted variables and letting the MILP solver optimize the rest as a warm start. However, if predictions are in-accurate, fixing variables can lead to low-quality or infeasible solutions. [21] introduces PaS, which searches for solutions within a predefined neighborhood of the prediction, improving feasibility and quality. [27] extends PaS using con-trastive learning and novel optimization-based methods for handling low-quality or infeasible solutions."}, {"title": "3.2 ML-guided solving Generalization", "content": "Despite advancements in ML-guided solving, generalizing learned models across tasks and problem domains remains a key challenge. Most ML methods are tailored to specific problem classes, limiting their applicability in real-world sce-narios. Recently, some works have addressed this issue. [28] introduced Distribu-tional MIPLIB, the first multi-domain library for advancing ML-guided MILP methods and exploring cross-domain generalization. [38] proposed MILP-Evolve, leveraging large language models to generate diverse MILP classes, showing strong generalization when trained on a large dataset. [14] developed GOAL, a generalist model capable of solving various problems in CO like routing, schedul-ing, packing, and graph problems, and fine-tuning to new problem domains. Additionally, multi-task learning has been applied in other CS problems like computer vision [41] and natural language processing [8], but no one has applied it to the CO domain."}, {"title": "4 Multi-task Representation Learning", "content": "We aim to learn MILP embeddings that are effective across different learning tasks and instances within the same problem domain, and that can be easily fine-tuned for new tasks. We share the same network architecture for different tasks to enable multi-task training with task-specific layers attached. Training data from other tasks is processed alternately by batch in every epoch.\nHowever, this alternating training strategy often leads to competition between different tasks, causing significant oscillations in the loss curves and a strong bias in testing performance towards one of the tasks. To address this issue, we introduced a two-step training strategy. First, we train the shared net-work architecture while keeping the task-specific layers fixed at randomly initial-ized weights. We use three randomly initialized task-specific layers to enhance the robustness of each task. This ensures the shared network architecture learns a general MILP embedding that is not overly specialized to a single random initialization. Second, we fine-tune the task-specific layers for each task while"}, {"title": "4.1 Data collection and Data representation", "content": "Since we use contrastive loss, carefully collecting positive and negative samples for practical training is crucial. For BACKDOOR, we follow [7] and employ the"}, {"title": "4.2 Network architecture and Contrastive loss", "content": "Our network architecture is a Graph Attention Network (GAT) [6], which takes the bipartite graph P' as input and outputs the MILP embeddings (V2, C2). To enhance the modeling capacity and manage interactions between nodes, em-bedding layers are employed to adjust the sizes of the feature embeddings to V1 \u2208 Rn\u00d7L and C\u00b9 \u2208 Rm\u00d7L. Subsequently, the GAT performs two rounds of message passing. In the first round, each constraint node in C\u00b9 attends to its neighboring variable nodes via an attention mechanism with H attention heads, producing updated constraint embeddings C\u00b2. Similarly, each variable node in V\u00b9 attends to its neighboring constraint nodes in the second round, yielding updated variable embeddings V2 using a separate set of attention weights. The GAT is designed to learn a shared MILP embedding representation (V2, C2) that is generalizable across various tasks and instances. In the experiments, em-bedding vector size L and number of attention heads H are set to 64 and 8.\nThe task-specific layers vary depending on the task. For BACKDOOR and PAS tasks, only variable features are required during prediction. In these cases, the task-specific layers consist of a multi-layer perceptron with a sigmoid activation function, which outputs a score between 0 and 1 for each variable. For CONFIG-URATION, we have additional layers combining variable and constraint features, mapping the embedding size to the number of configuration parameters, and"}, {"title": "4.3 Applying learned network", "content": "During testing, given a MILP instance, we convert it to a bipartite graph and inference one-time with the network to output a score vector with one score for each variable/parameter.\nFor BACKDOOR, the binary variables with the highest scores are greedily selected as the predicted backdoors based on a user-defined backdoor size \u039a.\nFor PAS, Xo and X1 are selected greedily based on the predictions, and a constrained optimization problem is solved using the hyperparameters ko, k1, and A.\nFor CONFIGURATION, categorical parameters are set to the option with the highest score, while numerical parameters use the output score.\nFull details of bipartite graph features, GAT network architecture, and hyper-parameter settings are provided in the Appendix."}, {"title": "5 Experiments", "content": "This section introduces the setup for empirical evaluation and presents the re-sults. The code and Appendix are available at https://github.com/caidog1129/MILP_multitask."}, {"title": "5.1 Experiment Setup", "content": "Benchmark Problems and Instance Generation:\nWe evaluate our approach on three NP-hard benchmark problems widely used in existing studies [19,21]: combinatorial auction (CA), minimum vertex cover (MVC), and maximum independent set (MIS). Previous works [7,27] have demonstrated promising results in predicting backdoor variables and Pas assignments"}, {"title": "5.2 Results", "content": "Same-Task Performance: To evaluate the same-task performance of a multi-task model, we test it on the tasks on which it is trained. We evaluate Gurobi, Single-task, and Multi-task-BAPAS on BACKDOOR and PAS using both S and L instances from CA, MIS and MVC. The detailed results are shown in Table 2 and Figure 2. For 100 S instances, both Single-task and Multi-task-BAPAS outperform Gurobi consistently, demonstrating competitive performance. For BACKDOOR, Multi-task-BAPAS achieves a slightly better average runtime than Single-task, with improvements of 4.04%, 6.05%, and 1.56% in CA-S, MIS-S, and MVC-S, respectively. However, Single-task outperforms Multi-task-BAPAS in the number of instances, with 39 vs. 32 wins in MIS-S and 53 vs. 40 in MVC-S.\nFor PAS, while Single-task consistently achieves a better primal gap at the end of the time cutoff, Multi-task-BAPAS demonstrates slightly better performance in"}, {"title": "6 Conclusion", "content": "This paper introduced a multi-task learning framework for MILP, unifying di-verse tasks through shared representations and task-specific fine-tuning. Our approach demonstrated competitive performance with specialized models and significantly improved generalization across problem sizes and functions. Future work includes integrating tasks with dynamic features and extending the frame-work to different problem domains, advancing toward general foundation models for MILP optimization."}]}