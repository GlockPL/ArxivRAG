{"title": "Multi-Agent Norm Perception and Induction in Distributed Healthcare", "authors": ["Chao Li", "Olga Petruchik", "Elizaveta Grishanina", "Sergey Kovalchuk"], "abstract": "This paper presents a Multi-Agent Norm Perception and Induction Learning Model aimed at facilitating the integration of autonomous agent systems into distributed healthcare environments through dynamic interaction processes. The nature of the medical norm system and its sharing channels necessitates distinct approaches for Multi-Agent Systems to learn two types of norms. Building on this foundation, the model enables agents to simultaneously learn descriptive norms, which capture collective tendencies, and prescriptive norms, which dictate ideal behaviors. Through parameterized mixed probability density models and practice-enhanced Markov games, the multi-agent system perceives descriptive norms in dynamic interactions and captures emergent prescriptive norms. We conducted experiments using a dataset from a neurological medical center spanning from 2016 to 2020. In the model's descriptive norm-sharing experiment, within small-scale medical communities, each agent's Subjective Individual Norm Perception (SINP) achieved a stable KL divergence of below 0.1 with the Objective Collective Norm (OBJ) after participating in medical practice-sharing activities, indicating that the model can perceive the collective medical norms representing the current best clinical practices in the environment. In medium-scale medical communities, the relationship between the number of agents and the norm convergence times followed different types of heavy-tailed distributions. In large-scale medical communities, the system's convergence rate exhibited fluctuations; however, overall, it decreased linearly as the number of agents increased. The Practice Shannon Diversity Index of the medical community, consisting of 10 neurologists in the dataset, gradually converged over 5 years to a value that better aligns with the real diagnostic practices of the neurological medical center. This indicates that the model, through long-term learning and sharing processes, can progressively reflect the actual diagnostic trends and collective behavioral tendencies within the medical community. In the experiment where multiple agents infer prescriptive norms within a dynamic healthcare environment, the agents effectively learned the key clinical protocols N\u2081 and N2 within the norm space H, which also included 30 control norms, without developing high belief in invalid norms. Furthermore, the agents' belief update process was relatively smooth, avoiding any discontinuous stepwise updates.", "sections": [{"title": "1. Introduction", "content": "Although the majority of studies have focused on a head-to-head comparison of AI with humans [1], real-life medical practice is more likely to involve human-in-the-loop setups, where humans actively collaborate with AI systems and provide oversight [2, 3]. There are still open questions about exactly how AI assistance affects human performance [4]. Recent studies have begun to explore such collaborative setups between AI and humans from multiple perspectives [3, 5, 6, 7]. In a highly distributed and fragmented environment like healthcare [8, 4, 9], characterized by strong local autonomy and dynamism [10, 11, 12], the key to addressing collaboration between AI and humans lies in the ability of autonomous agents to understand and adhere to the norms among healthcare professionals (HCPs). The notion of norms is applied in various settings to describe the consistency of thought or behavior within a reference group, typically aiming to understand how these patterns influence the members of those groups [13, 14, 15, 16]. Ethicists and philosophers typically conceptualize norms as being strictly divided into descriptive norms and prescriptive norms [17, 18, 15]. Norms play a critical role in facilitating cooperation and collaboration within groups, communities, and societies. They serve as indispensable mechanisms that uphold collective action [19, 20, 21]. Prescriptive norms set forth how people ought to behave [22]. Prescriptive norms can be transmitted via messaging and reinforced by the constraints imposed by individuals' social roles or positions [23]. Descriptive norms capture the observed or communicated tendencies of behavior or thought within a group, which can be conveyed to others through observation or the transmission of informal or formal information [24, 22]. Most of the medical norms are for human doctors, and are written in natural language with weak formalization and references to doctors' expertise. Enabling autonomous agent systems to learn and perceive the norms among healthcare professionals is both intriguing and essential for their integration into real-world healthcare environments. Considering the general properties of norms and the inherent distributed nature of the healthcare environment, we propose a Multi-Agent Norm Perception and Induction Learning Model that enables autonomous agent systems to simultaneously learn both descriptive and prescriptive medical norms in real-world healthcare scenarios. Placing interaction at the core of descriptive norms conceptualizes them as processes of individual interactions rather than static end products [25, 26, 27]. This conceptualization serves as our general approach to modeling descriptive norms in distributed healthcare scenarios. We model descriptive norms as agents' subjective perceptions of collective norms, where these subjective perceptions represent a generalized abstraction of descriptive norms. This perception represents a form of Theory of Mind, involving the ability to infer others' mental states based on the information conveyed [28]. We model the perception of norms by individual agents towards the collective using a parameterized weighted sum of mixed probability density functions. The parameters are updated based on prior norm perceptions from the EHR dataset and the ongoing interactions among multiple agents. This parameterized probability density function model effectively represents the descriptive norms among doctors that agents gradually learn during their interactions. The modeling of prescriptive norms in healthcare has different characteristics. Federal and regional protocols are based on clinical recommendations derived from reliable evidence. These protocols specify the most effective interventions and treatments for specific groups of patients. However, the implementation of these protocols varies across hospitals, each with its unique real-world circumstances [8]. Therefore, we focus on the emergence and convergence of prescriptive norms within the healthcare environment under such dynamic conditions. Shared and distributed prescriptive norms are learned and sustained in a decentralized and emergent manner [29, 30]. Some models, based on the frameworks of joint intentionality in human cooperation [31] and shared agency [32], allow agents to consider the compliance of the norm while pursuing individual interests [33]. Agents infer and update their understanding of the norms that best explain collective behavior by analyzing apparent violations of self-interest. However, contrary to the strict requirements of the healthcare environment, the approximate rational Bayesian rule induction in these methods can lead agents to learn \"silly\" prescriptive norms within the norm space. To address this, we have refined the Bayesian approach used by agents to induce rules from noisy action data and introduced external regulation by allowing agents to practice and verify norms within the healthcare environment. Additionally, we have incorporated momentum-like mechanisms and adaptive learning rates into the agents' belief updating process [34, 35, 36]. The updated model prevents convergence to local optima caused by the internal complexity of the probabilistic model, while simultaneously smoothing the agents' norm update process, eliminating the discontinuous stepwise changes observed in belief updates. Building on the distributed nature of healthcare, we developed a model that enables autonomous agent systems to integrate into healthcare environments through dynamic interactions. This approach allows the agents to learn medical norms while taking into account the discrete nature, complexity, and distributed characteristics of the healthcare domain [8, 12, 37]. Statement of Significance is in the table below."}, {"title": "2. Medical Norm Perception and Induction", "content": "Modeling norm perception and induction in distributed healthcare environments involves abstracting the general properties of healthcare. Establishing a general definition of descriptive and prescriptive norms within healthcare is essential. With these foundational concepts, we can naturally extend the development of multi-agent models that effectively learn these norms through robust methods."}, {"title": "2.1. Descriptive Norms in Healthcare", "content": "We standardize the expression of descriptive norms in healthcare under the term 'Medical Tendencies' (MedT). Descriptive norms include both behavioral norms and perceptual norms. They refer to the tendency of people in their community and are less rule-like [38]. Behavioral norms capture the observed or communicated behavioral tendencies of a group [39, 14]. Perceptual norms, in turn, refer to the communicated perceptual tendencies of a group. They describe the reference group's perceptions or attitudes regarding behavior. We define 'tendencies' as the general characteristic of descriptive norms in healthcare. We generalize the behavioral and cognitive tendencies of all categories of healthcare professionals (HCPs) into MedT, encompassing all scenarios, including clinical diagnosis, emergency care, nursing, and medical academic activities. The perception of descriptive norms operates on both individual and collective levels [40]. Individuals develop a perception of collective norms based on the information they acquire from their environment. This individual perception may be prone to errors [41]. For example, a patient who survived acute coronary syndrome without undergoing percutaneous coronary intervention (PCI) may perceive PCI as ineffective or unnecessary, even though the reality might be quite the opposite. In studies on ACS treatment, clinical pathways that include timely and effective PCI represent the optimal treatment strategy and are most aligned with clinical recommendations [8]. Therefore, modeling medical descriptive norms involves both individual and collective levels. In a given healthcare environment or scenario, there exist N agents, which are divided into K groups. Each group has a mean Medical Tendency (MedT) : \\(\\mu_{group}\\) for a specific medical object. The agents within each group share the same standard deviation of MedT, denoted as \\(\\sigma_{group}\\). Based on the mean and standard deviation, a MedT value is sampled for each agent within the group. The objective collective norm (OBJ) for each group is formed by the initial objective weighted sum w\u2081 of these groups, creating an objective collective norm based on a mixture of Gaussian distributions [42, 43].\n$$\nOBJ(x|\\lambda) = \\sum_{i=1}^{K} w_i g(x|\\mu_{group}, \\sigma_{group})\n$$\nIn this context, \\(\\lambda = {w_i, \\mu_{group}, \\sigma_{group} }\\) represents the set of parameters, where i ranges from 1 to K, corresponding to the weight, mean, and standard deviation of each group within the model, respectively. Each agent's tendency (MedT) is modeled as a single Gaussian distribution based on the sampled MedT value from their respective group. Each agent j has a unique mean \\(\\mu_{MedT_j}\\) and a shared standard deviation \\(\\sigma_{indiv}\\) across all agents.\n$$\nMedT_j ~ N(\\mu_{MedT_j}, \\sigma_{indiv})\n$$\nEach agent's medical tendency, represented by its Gaussian distribution, is communicated to other agents within the healthcare scenario through medical or daily activities. This interaction is modeled as a fully connected network, where agents infer the collective norms based on the messages received from others. This subjective inference is continuously"}, {"title": "2.2. Perceptions of Medical Descriptive Norms", "content": "Individuals continuously infer collective norms through interactions, updating the subjective parameters \\(\\lambda_{SINP}\\). The convergence of an agent's SINP parameters with the OBJ parameters (\\(\\lambda_{SINP} \\rightarrow \\lambda_{OBJ}\\)) represents the outcome of the agent's perception (learning) of the collective objective norms. Before individuals in a group enter a healthcare environment for the first time, they naturally possess prior knowledge of norms due to social and educational influences [15, 18]. An individual can obtain only limited information through each interaction within the collective. We first derive the prior knowledge [44] of healthcare professionals (HCPs) regarding norms based on the EHR dataset, and then parameterize this knowledge as \\(\\Lambda_{SINP}\\). Next, we use Maximum Likelihood (ML) estimation to find the model parameters that maximize the likelihood of the Subjective Individual Norm Perception (SINP) given the training data, as shown in Figure 1. Our norm perception process is based on our proposed definition of descriptive medical norms, incorporating the characteristics of distributed healthcare environments, and has been adaptively modified from the standard Gaussian Mixture Model (GMM) and Expectation-Maximization (EM) algorithm."}, {"title": "2.3. Prescriptive Norms in Healthcare", "content": "In the context of prescriptive norms, they typically involve fundamental principles [24]. This is also true for medical prescriptive norms, which consist of medical rules, protocols, or guidelines [8]. Medical rules exist in the minds of"}, {"title": "2.4. Learning Medical Prescriptive Norms", "content": "In the field of healthcare modeling, discrete-event simulation [52, 53], system dynamics [54, 55], agent-based modeling [56], and queueing theory [57, 58] are popular approaches, each addressing different types of distributed problems in medical environments. Based on the various complex distributed problems in healthcare scenarios that are described and addressed by these popular approaches, we have found that enabling autonomous agents to continuously interact within medical environments, and using rational inductive logic models to derive prescriptive norms from sparse and noisy data in uncertain conditions, greatly facilitates the ability of autonomous agent systems to collaborate effectively with HCPs. Combining Markov games with a model of \"approximate\" rational Bayesian structured rule induction [59, 60, 61] has shown inaccuracies in general social norm learning experiments [33], where agent systems may learn nonfunctional or even irrational prescriptive norms. Based on the results observed in our rule (prescriptive norms) induction experiments on the medical dataset, we hypothesize that this phenomenon may be due to two factors. First, the probabilistic nature can lead to the emergence"}, {"title": "B. Norm Practice and Smooth Updates", "content": "Assumption 1 (Section 2.4) establishes the integration of the norm verification and adjustment process into agents' belief updating mechanisms. This process includes an external regulation mechanism that refines agents' beliefs based on the observed effectiveness of norms in the environment. After identifying the most relevant norms within the norm space H, agents adjust their beliefs b(nm) about each norm nm \u2208 H according to its observed efficacy in practice. This adjustment modifies the belief update rule, where the beliefs are reweighted by a regulation factor a \u2208 [0, 1], scaling the belief values based on the empirical success of the norm:\n$$\nb'(nm) = a\\cdot b_i(nm)\n$$\nThe adjustment factor a is determined through an external validation process that evaluates the effectiveness of norms in guiding appropriate actions. Once adjusted, beliefs are normalized to ensure they form a valid probability distribution:\n$$\nb(nm) = \\frac{b'(nm)}{\\sum_{nm\\in H}b'(nm)}\n$$\nThis external regulation mechanism ensures that agents do not converge to non-functional norms by continuously adapting their belief structures based on practical outcomes in the environment.\nIn addition to this external regulation through \"practice verification,\" adaptive learning rates and momentum mechanisms were introduced into the process of agents' concept updates. Specifically, a momentum mechanism was implemented to smooth gradient updates during the belief update process for prescriptive norms, mitigating the effects of noise and unstable gradients. The momentum update is defined as:\n$$\nm^{t+1}(nm) = \\beta_1\\cdot m^t(nm) + (1 - \\beta_1) \\cdot \\nabla L_i(nm)\n$$\nwhere \\(m^{t+1}(nm)\\) represents the momentum for norm nm at step t + 1, \\(\\nabla L_i(nm)\\) is the current gradient for the norm, and \\(\\beta_1\\) is the momentum coefficient. An adaptive learning rate was also introduced, dynamically adjusting the step size during updates to ensure stability in the learning process. The adaptive learning rate is defined as:\n$$\n\\alpha^{t+1}(nm) = \\frac{\\alpha}{\\sqrt{v^{t+1}(nm)} + \\epsilon}\n$$\nwhere \\(\\alpha^{t+1}(nm)\\) is the adaptive learning rate, \\(\\alpha\\) is the initial learning rate, \\(v^{t+1}(nm)\\) is the second moment estimate for norm nm, and \\(\\epsilon\\) is a small constant to prevent division by zero. To support this mechanism, the second moment estimate \\(v^{t+1}(nm)\\) was updated dynamically as:\n$$\nv^{t+1}(nm) = \\beta_2 \\cdot v^t(nm) + (1 - \\beta_2) \\cdot (\\nabla L_i(nm))^2\n$$\nwhere \\(v^{t+1}(nm)\\) represents the second moment estimate for norm nm at step t + 1, and \\(\\beta_2\\) is the RMSprop coefficient."}]}