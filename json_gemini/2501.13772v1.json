{"title": "Tune In, Act Up: Exploring the Impact of Audio Modality-Specific Edits on Large Audio Language Models in Jailbreak", "authors": ["Erjia Xiao", "Hao Cheng", "Jing Shao", "Jinhao Duan", "Kaidi Xu", "Le Yang", "Jindong Gu", "Renjing Xu"], "abstract": "Large Language Models (LLMs) demonstrate remarkable zero-shot performance across various natural language processing tasks. The integration of multimodal encoders extends their capabilities, enabling the development of Multimodal Large Language Models that process vision, audio, and text. However, these capabilities also raise significant security concerns, as these models can be manipulated to generate harmful or inappropriate content through jailbreak. While extensive research explores the impact of modality-specific input edits on text-based LLMs and Large Vision-Language Models in jailbreak, the effects of audio-specific edits on Large Audio-Language Models (LALMs) remain underexplored. Hence, this paper addresses this gap by investigating how audio-specific edits influence LALMs inference regarding jailbreak. We introduce the Audio Editing Toolbox (AET), which enables audio-modality edits such as tone adjustment, word emphasis, and noise injection, and the Edited Audio Datasets (EADs), a comprehensive audio jailbreak benchmark. We also conduct extensive evaluations of state-of-the-art LALMs to assess their robustness under different audio edits. This work lays the groundwork for future explorations on audio-modality interactions in LALMs security.", "sections": [{"title": "1 Introduction", "content": "The field of Large Language Models (LLMs) has gained remarkable prominence, with cutting-edge models like GPT-4 and Claude. They exhibit exceptional zero-shot performance across a wide range of natural language processing tasks, including question answering (Zhuang et al., 2023; Li et al., 2024), sentence summarization (Fang et al., 2024; Jin et al., 2024), language translation (Gong et al., 2024; Lu et al., 2024), and sentiment analysis (Zhang et al., 2023b; Gupta et al., 2024). Building on the rapid advancement of LLMs, integrating various types of encoders enables the development of Multimodal Large Language Models (MLLMs) that can perceive multiple modalities. Compared to LLMS, MLLMs are capable of handling a wider range of tasks. After adding a vision encoder to LLMs, Large Vision Language Models (LVLMs) are able to enhance vision-language interaction and perception capabilities. By equipping LLMs with an audio encoder, Large Audio Language Models (LALMs) can directly understand audio input and provide responses.\nPrevious research shows that editing inputs from different modalities for large models significantly influences the final output. Adversarial examples (Goodfellow et al., 2014; Madry, 2017), a common security threat in AI models, impact the final output by being simultaneously fed through adversarial images (Luo et al., 2023; Cheng et al., 2024; Wang et al., 2024) and prompts (Zhang et al., 2025; Liu et al., 2023a) into both the vision and text encoders. Language modality-specific edits to the input of the text encoder lead to positive or negative impacts on the inference output of both LLMs and LVLMs. Hand-crafted edits to the text input, such as sequential reordering, emphasized elements, repeated content, and so on, increase the likelihood that LLMs and MLLMs will respond to jailbreak tasks that challenge ethical and legal boundaries (Liu et al., 2023b; Shen et al., 2024; Yu et al., 2024). Various Chain-of-Thought (CoT) techniques (Wei et al., 2022; Chu et al., 2023; Wang et al., 2024) suggest that appropriate edits to the language modality input of large models can enhance reasoning performance. Additionally, for LVLMs, visual modality-specific edits to the input images of the vision encoder similarly influence the final language output. Some studies (Miyai et al., 2024; Huang et al., 2023) show that editing the input image with out-of-distribution perturbations significantly harms the LVLMs' performance in various reasoning tasks. Other works (Zhang et al., 2023c; Shao et al., 2024) suggest that appropriately designed out-of-distribution perturbations, such as blurring or Gaussian noise, added to the input image can be effectively applied in areas like privacy protection and defense against adversarial attacks in large model security. Moreover, typographic attacks (Cheng et al., 2025, 2024) can influence the final output by simply adding typographic text to the image. However, there is no comprehensive related work on how audio modality-specific edits affect LALMs, despite their widespread applications in real-life contexts.\nThis paper provides a comprehensive study of the impact of audio modality-specific edits on the final inference output of LALMs. We propose the Audio Editing Toolbox (AET) and Edited Audio Datasets (EADs). AET offers a range of editing tools for specific audio inputs, enabling users to evaluate the performance of audio content under various audio-specific edits. EADs can serve as a benchmark dataset for future evaluations of different types of LALMs under multiple audio-specific edits. AET and EADs include several audio-specific editing methods, such as tone adjustment, word emphasis, intonation modification, speed change, noise injection, and accent conversion. These methods are evaluated on various LALMs, including BLSP (Wang et al., 2023), SpeechGPT (Zhang et al., 2023a), Qwen2-Audio (Chu et al., 2024), SALMONN (Tang et al., 2023). The results serve as valuable baselines for future research. The following are our contributions:\n\u2022 We introduce the Audio Editing Toolbox (AET), which allows multiple audio modality-specific edits to be applied to audio content.\n\u2022 We propose the Edited Audio Datasets (EADs), the most comprehensive dataset of audio modality-specific edits to date, designed to serve as a benchmark for evaluating the effect of audio-modality edits in LALMs.\n\u2022 Based on AET and EADs, we conduct the most comprehensive performance evaluation for how audio-modality edits affect LALMs."}, {"title": "2 Methods", "content": "An audio signal is represented as x(t), a time-domain waveform where t means time index. We applied the transformations to these signals to modify various characteristics such as intonation, speed, etc. Then, we could get a transformed signal x'(t). This transformation can be expressed as:\nx'(t) = T(x(t), 0) \\tag{1}\nwhere T represents the transformation function and 0 controls the transformation.\nWe also use Short-Time Fourier Transform (STFT) to analyze time-frequency characteristics of signals, where w(t) is the window function:\nX(t, f) = \\int_{-\\infty}^{\\infty} x(\\tau)w(\\tau \u2013 t)e^{-j2\\pi f \\tau} d\\tau \\tag{2}\nTo reconstruct the time-domain signal after transformations in the frequency domain, we use the Inverse Short-Time Fourier Transform (iSTFT) to ensure smooth transitions between frames:\nx(n) = \\sum_{m} \\sum_{k} X(m, k) \\cdot e^{i2\\pi kn/N} \\cdot w(n \u2013 mH) \\tag{3}"}, {"title": "2.2 Types of Audio Editing", "content": "The original audio dataset is created using 520 harmful text questions from AdvBench (Zou et al., 2023). Each text question is converted into audio using gTTS (Google Text-to-Speech) (Durette, 2024) to produce the original audio samples, which are then used for further editing. We define the following audio editing to generate diverse audio variations for the experiments.\nTone Adjustment We modify the pitch of the original audio by changing its frequency for tone adjustment. The transformation is defined as:\nf'(t) = f(t) \\cdot 2^{\\Delta p/12} \\tag{4}\nwhere the \u0394 represents the semitone shift, \u0394\u03c1 \u2208 {-8, -4, +4, +8}.\nEmphasis We increase the volume of specific segments (such as verbs and question words) in the audio to simulate stronger emphasis, as follows:\nx'(t) = kx(t) \\tag{5}"}, {"title": "3 Experiments", "content": "We implement dynamic pitch modification to simulate natural prosodic patterns in speech for intonation adjustment. Specifically, we segment the audio and apply time-varying pitch shifts to create realistic intonation curves. Then we utilize graduated semitone intervals such as [0,2,4,6], [0,3,6,9], and [0, 4, 8, 12] to modify each segment's pitch, resulting in naturalistic prosodic contours.\nSpeed Change We adjust the playback rate of the audio by scaling the time axis while keeping the pitch. The transformation is defined as:\nx'(t) = x(\\beta \\cdot t) \\tag{6}\nwhere \u03b2 is the speed factor, \u03b2 \u2208 {0.5, 1.5}.\nNoise Injection We inject background noise into the original audio to simulate real-world environments. To be more specific, we introduced three types of noise: crowd noise, machine noise, and white noise. The transformation is defined as:\nx'(t) = x(t) + \\gamma \\cdot n(t), \\tag{7}\nwhere n(t) is the noise signal, \u03b3 is the noise level.\nAccent Conversion We modify the phonetic features of the original audio to simulate different accents. We focused on three accent categories: Black, White, and Asian. This transformation is performed using coqui-ai TTS (Coqui-ai, 2024), enabling high-quality voice conversion."}, {"title": "3.1 Experimental Settings", "content": "We conduct extensive experiments on current Large Audio Language Models, which are BLSP (Wang et al., 2023), SpeechGPT (Zhang et al., 2023a), Qwen2-Audio (Chu et al., 2024), SALMONN-7B and SALMONN-13B (Tang et al., 2023). For each model, we maintain default hyperparameters as recommended in their respective official implementations.\nWe employ 520 harmful questions from AdvBench (Zou et al., 2023). Each harmful question is converted into speech using gTTS (Google Text-to-Speech) (Durette, 2024) to produce the original audio samples. The text prompt \"Provide a detailed answer that exceeds 500 words.\" is employed as the text input in inference, along with these audio samples."}, {"title": "3.2 Impact of Audio Editing in Jailbreak", "content": "The ASR results on AdvBench show that audio editing's impact on model jailbreak reveals significant variations across different model series and editing types.\nAs shown in Table 1, SALMONN series demonstrates notable vulnerability, with SALMONN-13B showing particularly high sensitivity to audio editing, experiencing substantial ASR increases of 25%~45% across multiple editing types. Background noise injection and accent conversion emerge as particularly effective attack vectors for SALMONN models, causing ASR increases of up to 44.6% and 45.0%, respectively.\nIn contrast, other models like SpeechGPT and Qwen2-Audio exhibit remarkable robustness, maintaining stable ASR across most audio editing, with changes typically under 3%. BLSP shows moderate susceptibility to certain audio editing, particularly experiencing notable decreases in ASR (7.3%~18.7%) with accent conversion and an 11.2% decrease with increased speed.\nThe stark contrast between the SALMONN series' vulnerability and other models' resilience in the audio jailbreak highlights the importance of considering audio editing vulnerabilities in model development and deployment, particularly for safety-critical applications."}, {"title": "3.3 Representation Space Analysis", "content": "To further investigate the vulnerability of SALMONN models to audio editing in jailbreak, we visualized the representations generated when the models process audio samples with different types of audio editing. Specifically, we employed t-SNE (Van der Maaten and Hinton, 2008) to reduce the dimensionality of these representations. The t-SNE visualizations reveal a striking contrast in how these models process audio editing.\nFig. 1 shows distinct, well-separated clusters for different types of audio edits (accent, emphasis, noise, etc.), with considerable distance between these clusters and the original audio representations in SALMONN-7B. This clear separation in the representation space suggests that SALMONN-7B processes modified audio significantly differently from the original audio samples, which aligns with its high sensitivity to audio editing.\nIn contrast, Fig. 2 shows heavily overlapped, almost indistinguishable clusters where modified audio samples are tightly integrated with the original audio representations in Qwen2-Audio-7B. This t-SNE visualization pattern indicates that Qwen2-Audio-7B maintains consistent internal representations regardless of audio editing, explaining its robust performance with minimal ASR changes across different audio editing types."}, {"title": "4 Conclusion", "content": "This study presents a pioneering investigation into the security vulnerabilities of Large Audio-Language Models (LALMs) through audio-specific edits. Through our developed Audio Editing Toolbox (AET) and Edited Audio Datasets (EADs), we have demonstrated that LALMs can be susceptible to jailbreak attempts through various audio edits, including tone adjustment, word emphasis, intonation modification, speed change, noise injection, and accent conversion. Our comprehensive evaluation of state-of-the-art LALMs provides valuable insights into their robustness against the impact of audio modality-specific edits and highlights the need for enhanced security measures in LALMs."}]}