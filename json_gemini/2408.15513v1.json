{"title": "Continual-learning-based framework for structural damage recognition", "authors": ["Jiangpeng Shu", "Jiawei Zhang", "Reachsak Ly", "Fangzheng Lin", "Yuanfeng Duan"], "abstract": "Multi-damage is common non in reinforced concrete structures and leads to the requirement of large number of neural networks, parameters and data storage, if convolutional neural network (CNN) is used for damage recognition. In addition, conventional CNN experiences catastrophic forgetting and training inefficiency as the number of tasks increases during continual learning, leading to large accuracy decrease of previous learned tasks. To address these problems, this study proposes a continual-learning-based damage recognition model (CLDRM) which integrates the \u201clearning without forgetting\u201d continual learning method into the ResNet-34 architecture for the recognition of damages in RC structures as well as relevant structural components. Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework. In this way, it reduces both the prediction time and data storage by about 75% in four tasks of continuous learning. Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework. By gradual feature fusion, CLDRM outperformed other methods by managed to achieve high accuracy in the damage recognition and classification. As the number of recognition tasks increased, CLDRM also experienced smaller decrease of the previous learned tasks. Results indicate that the CLDRM framework successfully performs damage recognition and classification with reasonable accuracy and effectiveness.", "sections": [{"title": "1 INTRODUCTION", "content": "1.1 Background\nReinforced concrete (RC) civil structures gradually approach their design life expectancy, posing a risk to the safety structures and people (Liu et al. 2019). Therefore, it is necessary to effectively inspect damages of RC structures. Conventionally, different manual inspections methods were used. However, these methods have the disadvantages of unreliable inspection results and considerable time consumption (Cha et al. 2017). Owing to the rapid development of machine learning, which has shown excellent performance in image processing and computer vision in recent years, researchers and engineers are increasingly applying it for damage detection and structural assessment (DeVries et al., 2018, Spencer et al., 2019 & Chen et al., 2018). One of the well-known applications of deep learning in civil engineering is crack detection and recognition. For instance, Kim et al. (2019) used a convolutional neural network (CNN) to determine the existence and location of concrete cracks. Chen and Jahanshahi (2018) combined CNNs with naive Bayes data fusion to analyze individual video frames for crack detection.\nThe types of damage of RC structures are various. Thus, the demand for the recognition and classification of damage types is also on the rise. Moreover, it is becoming easier to retrieve more structural-damage-related information in the form of image data based on the technical development of deep learning and data acquisition. For this reason, numerous solutions have been explored. A region-based CNN (Faster-RCNN, Ren et al., 2017) was adopted to detect different damage types such as concrete cracks and steel corrosion with two levels (medium and high), including bolt corrosion"}, {"title": "1.2 Multitask Damage Recognition", "content": "It is worth noting that with the continuous development of deep learning, the number of recognition tasks in damage detection is increasing. One of the common problems among the abovementioned applications is the limitation of the number of recognition tasks for training. For example, ten different neural networks are required for ten different recognition tasks. Hence, the number of parameters increases exponentially with the number of damage recognition tasks, thereby making the training process time/resource consuming. Additionally, these training methods do not utilize the feature correlation between similar tasks such as crack detection and spalling detection. To address this issue, one neural network can be trained simultaneously for multiple recognition tasks. The trained model can identify similar features and characteristics with improved accuracy (Li and Hoiem, 2018). Nevertheless, the similar characteristics of certain recognition tasks present a few drawbacks. For instance, the image characteristics of spalling condition check and damage level evaluation are similar to a certain extent. If a model only outputs one prediction, then there is a problem. Therefore, to prevent this confusion in training methods, fully connected layer is separated to output the results of different tasks. The two most common methods for this are simple sequence training (Sutskever et al., 2014) and joint training (Caruana, 1997). Simple sequence training begins by training a model for the first task. Then, more neurons are subsequently added in the tail part of a fully connected layer to learn the feature of the next task. The common problem of this method is the highly likely catastrophic forgetting, where a network tends to forget the feature learned in the old task after the training for the new task is finished. This significantly reduces the recognition accuracy for the first task. Joint training (Caruana, 1997) can be applied for simultaneously training multiple recognition tasks. However, the datasets of all previous tasks are required for the training of any new recognition task. These training methods have the following limitations:\n1) Flaws appear when the number of training datasets between each task is extremely unbalanced; this causes poor recognition accuracy for the tasks with small samples. In the field of civil engineering, datasets are extremely expensive. There is a lack of particular types of images, which could result in poor performance for the corresponding recognition tasks. In addition, as the number of tasks increases, the recognition accuracy for each task becomes unpredictable or decreases.\n2) The total amount of data required for simultaneous training increases with the number of recognition tasks. Therefore, considerable computing resources are required to perform training; otherwise, the problem of memory overflow occurs in GPUs during training.\n3) Whenever a new task is added to a model, all data used in the training of the previous task are required again for retraining. These data are simultaneously used to retrain the model again. This not only causes the problem mentioned in 2) but also exponentially increases data storage and training time as the number of tasks increases. Furthermore, the assumption that the data from old tasks are always available at the time of training a new task is not always satisfied."}, {"title": "1.3 Continual Learning", "content": "Continual learning has been proposed as a revolutionary method (Parisi et al., 2019) for two purposes: (1) to perform multitask recognition using one CNN; (2) to maintain an optimal recognition accuracy for previously trained tasks with a low training cost. Continual learning is a generic method, which can be adopted in any CNN framework. Continual learning utilizes the features and knowledge learned from the recognition of previous tasks, facilitates training for next tasks, and maintains the features learned from previous tasks. This is achieved by limiting changes in parameters, i.e., adding a regularization term. For instance, Kirkpatrick et al.(2017) proposed elastic weight consolidation as a specific sequence training method that quantifies the importance of the weights of previous tasks, flexibly updates the parameters during the training of a new task, maintains the features learned in previous tasks, and prevents catastrophic forgetting. Zenke et al. (2017) introduced synaptic intelligence into artificial neural networks, where each synapse accumulates and exploits task-relevant information over time to rapidly store new knowledge without forgetting previous knowledge."}, {"title": "2 OVERVIEW OF THE PROPOSED METHOD", "content": "Figure 1 shows the flowchart of the proposed framework, training steps, and testing steps. A comprehensive dataset that includes typical damage categories is prepared for training. A labeled training dataset is the input. A separate test dataset is prepared to verify the model and to investigate its performance on four different recognition tasks, which are (1) three-class classification for damage level evaluation, (2) binary classification for spalling condition check, (3) three-class classification for component type determination, and (4) four-class classification for damage type determination. Each task is defined in detail in Section 3.1. This study utilizes a collected large dataset of damaged RC image including PEER Hub ImageNet dataset (Gao and Mosalam, 2018). Overall, 16,840 colorful images with a resolution of 224 \u00d7 224 are prepared, preprocessed, reclassified, and manually annotated for the aforementioned recognition tasks. The hierarchy tree in Figure 2 illustrates the structure of the dataset. To address the lack of valuable structural images, each image is labeled with multiple tags as multiple attributes according to the recognition tasks. The final ratio of the images used in each recognition task is illustrated in Figure .\nThe CLDRM adopts the continual-learning-based \"learning without forgetting (LwF)\" method (Li and Hoiem, 2018), which is a form of knowledge distillation (Hinton et al. 2015). Instead of using a previous image dataset for retraining, the knowledge learned from previous tasks is retained by learning the soft targets provided by the previous model, which is stored after training. In other words, the previous model can be saved and stored for subsequent training without any image datasets of a previous task. This significantly reduces memory requirement and training complexity. A new deep CNN training framework, namely, the CLDRM, which utilizes the LwF method with the residual network (ResNet) (He et al., 2016) architecture for the detection and classification of crack damage in RC structures, is developed."}, {"title": "3 RECOGNITION TASKS AND DATASET", "content": "3.1 Recognition Tasks\n3.1.1 Damage level evaluation\nOwing to limited datasets and engineering subjectivity on determining moderate versus heavy damage levels, previous researchers in this field have categorized the types of damage into three different levels, i.e., \"undamaged,\" \"minor damage,\" and \"moderate damage to heavy damage.\u201d To achieve a clearer boundary between the levels of damage, this study categorizes crack damage into three main categories, i.e., \u201cundamaged,\u201d \u201cminor damage,\" and \"heavy damage,\" which are defined as follows: Minor damage does not pose a risk and does not need to be repaired urgently. Heavy damage can pose a risk and must be repaired urgently.\n3.1.2 Spalling condition check\nSpalling is the breaking of a concrete surface, and it frequently extends to the top layer of reinforcing steel. The spalling of concrete affects a broad variety of structures, including framed buildings, multistory car parks, and bridges. Spalling can be caused by the corrosion of embedded reinforcing steel, fire exposure, freeze and thaw cycling, and so on. Spalling is considered as a separate damage type category owing to its distinguishable characteristics.\n3.1.3 Component type determination\nComponent type determination is a three-class classification task for \"columns,\" \"walls (or slabs),\" and \"beams\". Owing to the geometrical similarity between beams and columns, rotation is not implemented for data augmentation to prevent the occurrence of label inconsistency between beams and columns.\n3.1.4 Damage type determination\nFour typical crack damage types are selected based on the causes of cracks. All of them have evident characteristics, which are suitable for identification. The proportion of images for each crack type is shown in Figure 7."}, {"title": "4 NETWORK ARCHITECTURE AND MODEL", "content": "4.1 Network Architecture\n4.1.1 Network Architecture of ResNet\nResNet (He et al., 2016) is well known for its remarkable object detection and image classification capabilities. It has been demonstrated that residual mapping and shortcut connections facilitate the training process and lead to better results compared to very deep plain networks. Network depth is crucial for improving the network performance of CNNs; however, deeper networks are more difficult to train. He et al. (2016) reported that an increase in network depth leads to degradation problems, which cause accuracy to become saturated. To address this problem, they used [batch normalization (BN), rectified linear unit (ReLU), and a convolution layer] \u00d7 2 as a basic mapping backbone and subsequently added an extra skip connection, i.e., simple identity mapping, to form a complete residual block (Figure 5). This residual block learns the necessary residual mapping for a given task and improves the capability of training considerably deeper networks. This method reduces training time and improves convergence speed, resulting in more accurate prediction.\nThe ResNet architecture has shown impressive performance not only on image classification benchmarks, such as CIFAR (Krizhevsky et al., 2009) and ImageNet, but also on object detection benchmarks such as MS COCO (Lin et al. 2014). Researchers have implemented numerous improvements in the structure of residual units to facilitate the learning of the network. For instance, Inception-ResNet (L\u00e4ngkvist et al., 2014) has been introduced by combining residual learning and inception blocks. It has been shown that training with residual connections significantly accelerates the training of inception networks. Merge-and-run mappings in residual units have been implemented to improve network performance by facilitating information flow in networks\n4.1.2 Learning Without Forgetting\nThe LwF method was first developed by Li and Hoiem (2018), and has been adopted in the proposed CLDRM. There are three important notations in LwF, i.e., \\(\\theta_s\\), which denotes the parameters in the CNN shared across all tasks, \\(\\theta_o\\), which denotes the specific parameters learned from previous tasks, and \\(\\theta_n\\), which denotes the specific parameters that are learned in a new task.\nIn this study, ResNet-34 is utilized to implement multitask learning and \\(\\theta_s\\) (the parameters of layers before the tail of the fully connected layer) is initialized with the pretrained parameters of the 1000-class ImageNet dataset to accelerate the convergence of training. The features of images extracted from the first few layers of a CNN tend to be more generalized (Zeiler and Fergus, 2014), while the features extracted from the latter layers are more relevant to a specific dataset. Therefore, researchers tend to freeze the parameters of the first few layers after transferring the parameters trained on the dataset with richer features; only the parameters of the next few layers are fine-tuned (Yosinski et al., 2014). However, fine-tuning all parameters provides better performance in multitask learning. For this reason, \\(\\theta_s\\) is focused in the training process. In the tail part of the fully connected layer, fc-1000 in the original ResNet is replaced by a new linear layer with 512 input features and m output features, where m is the number of classes for the first task. Then, after the training process of the first task, n, which denotes the number of classes for the next new task, is appended to this fully connected layer. All newly appended to this fully connected layer. All newly appended parameters are initialized using Kaiming initialization (He et al., 2016)."}, {"title": "4.2 Comparative Evaluation", "content": "The performance of the proposed CLDRM framework is evaluated through experiments and compared to a conventional CNN model with four existing training methods, which are described below.\n4.2.1 Feature Extraction\nFeature extraction (Shin et al., 2016) is used to filter out the most critical and distinguishable information from redundant data. Extracted features are typically represented by feature vectors. In deep learning, the output of a certain layer (the last convolutional layer) can be extracted as the"}, {"title": "4.2.2 Fine-Tuning", "content": "To overcome the abovementioned problem of feature extraction, \\(\\theta_s\\) is fixed and a low learning rate is applied for training \\(\\theta_s\\) and \\(\\theta_n\\) (Yosinski et al., 2014). In this manner, the network learns the features related to a new task. However, it may forget the features learned in the first task. The training conditions of the CLDRM and fine-tuning are quite similar but considerably different from the training conditions of the two methods mentioned below. Therefore, the CLDRM is mainly compared with fine-tuning in the following experiments."}, {"title": "4.2.3 Duplicate and Fine-Tuning", "content": "During the training for a new task, the relatively important parameters for the identification of the first task are partially modified. This causes the network to forget the features learned in the previous task. For this reason, the duplicate and fine-tuning method is applied to the network for each new task. Moreover, each network must be individually fine-tuned. It is worth noting that even though each network learns specific features from the images corresponding to a task, the number of parameters still increases exponentially."}, {"title": "4.2.4 Joint Training", "content": "Joint training simultaneously trains all parameters (\\(\\theta_s\\), \\(\\theta_o\\), and \\(\\theta_n\\)) using all data from old and new tasks (Caruana, 1997). The network can extract and integrate the characteristics of each task. This may improve the accuracy for a few recognition tasks compared to the individual training of each task. However, storing all data is an issue and extremely expensive in terms of time and computation resources. In order words, whenever a new task is added, it must be trained again with the old tasks that have been previously trained on the network."}, {"title": "4.3 Model Training", "content": "This section describes the CLDRM training process, including the training and test sets, optimization methods, and hardware configuration. All tasks are performed on a workstation with the Intel(R) Xeon(R) E5-2678 v3 2.50 GHz CPU, 64.0 GB RAM, and the NVIDIA RTX2080TI-11G GPU."}, {"title": "4.3.1 Train and test set", "content": "The number of training and test sets used in the experiments for different recognition tasks are listed in Table 2. In the data preprocessing part, data augmentation (horizontal flip, vertical flip, rotation, color jitter, etc.) is implemented with a batch size of 64. However, a small proportion of the datasets in the structure component part contain useful environmental background information. Therefore, in most cases, at a certain angle of rotation of images, inclined beams may look like vertical columns and vice versa. Therefore, to prevent this, images are not rotated in the component type determination task."}, {"title": "4.3.2 Optimization", "content": "The results of the initial experiments for the training of continual learning tasks show that the Adam optimizer (Kingma and Ba, 2015) is relatively unstable and ineffective, which results in poor model performance. The recognition accuracy for an old task decreases significantly during the training of a new task. Thus, the Adam optimizer is not selected as the training method for the CLDRM. SGD (Nesterov, 1983) with momentum provides considerably better performance, and it is employed as the optimizer for the CLDRM. The learning rate of the SGD optimizer is 1 \u00d7 10-3, the momentum is 0.9, and the weight decay rate is 4\u00d710-5. These parameter settings are adopted to pretrain \\(\\theta_n\\), and the model is trained for 40 epochs. When \\(\\theta_s\\), \\(\\theta_o\\), and \\(\\theta_n\\) are simultaneously trained, the learning rate is reduced to 1 \u00d7 10-4 and the number of training epochs is increased to 60."}, {"title": "5 EXPERIMENTS AND RESULTS", "content": "The feasibility of the CLDRM is experimentally verified for four different recognition tasks, i.e., damage level evaluation, spalling condition check, component type determination, and damage type determination. The objective is to achieve accurate multitask damage recognition through a single neural network. However, typically, the recognition accuracy for a previous task decreases when new tasks are input to the neural network. The target is to minimize the decrease in the recognition accuracy for previous tasks so that the total accuracy is high. The influence of the following parameters on the model is examined: a) effects of different distillation temperature settings on the four proposed continuous-learning-based"}, {"title": "5.1 Initial Study", "content": "The initial experiment compares the accuracy of different recognition tasks using different training methods for model. Table 3 compares the accuracy of different recognition tasks and training methods. \u201cInitial\" refers to the best test accuracy for a task that is trained for the first time. \"Final\" refers to the test accuracy for this specific task when the training of all tasks is finished. The difference between \"Initial\" and \"Final\" for a task shows the decline in the recognition accuracy for that task during the entire training process. It is worth noting that the values of \"Initial\" and \"Final\" are the same for damage type determination because it is the last task to be trained. \\(\\Theta_s\\) and are constant in feature extraction. Therefore, the values of \u201cInitial\" and \"Final\" are the same for all tasks in the case of this training method. In addition, there is no concept of \u201cInitial\u201d and \"Final\" in the duplicate and fine-tuning method and joint training method. However, for the convenience of comparison, \u201cFinal\u201d is considered as equal to \"Initial\u201d for these methods.\nAs shown in Table 3, when the number of trained tasks increases, the decrease in the recognition accuracy for previous tasks is less in the case of the CLDRM compared to the fine-tuning and feature extraction methods. Moreover, compared to the other three methods, the CLDRM achieves the highest recognition accuracy (93.60%) for the final trained task (damage type determination). The Average of \"Final\" for the CLDRM is also relatively high.\nThe CLDRM achieves high accuracy primarily because it is capable of retaining the useful and similar characteristic features of the previous three tasks, which are beneficial for the damage type determination task. Hence, damage types are classified more accurately with less direct training data. Similarly, the characteristics of the cracks caused by the ASR are quite similar to a certain type of spalling. Thus, the training of the spalling condition check task is beneficial for the ASR damage detection task. In the future, this notion can be implemented to improve the accuracy for recognition tasks where direct training alone cannot improve the accuracy.\nIn Table 3, the \"Average of Final\" indicator is used to measure the overall accuracy of different training methods. It is the average of the value of \u201cFinal\u201d for each recognition task. The Average of \"Final\" for the CLDRM is 1.36% higher than the fine-tuning method. This difference increases with the number of tasks. The duplicate and fine-tuning method and joint training method have the highest Average of Final; this indicates that these methods perform the best. However, as mentioned in Section 4.2, the high accuracy of these methods comes at the high cost of a large number of parameters and data storage required during training.\nThe confusion matrices of the test prediction by the CLDRM in the four recognition tasks are shown in Figure 11. As shown in Figure 11 a), when the damage level is categorized into three classes (\u201cundamaged,\u201d \u201cminor damage,\" and \"heavy damage\"), the model successfully distinguishes between \"heavy damage\" and \"minor damage\" with high accuracy. However, in the same recognition task, \u201cminor damage\" is misclassified by the model as the \"undamaged\" in most cases. The main reason behind this might be that the characteristics of the damage in the \"minor damage\" dataset is not obvious and similar to that in the \u201cundamaged\" dataset. Furthermore, the damage in the dataset used for training the other recognition tasks is quite similar. For this reason, the characteristics used to distinguish between \u201cminor damage\" and \"undamaged\" might not be important for training the next recognition task and might not be considered in continual learning. This also"}, {"title": "5.2 Further Experiments", "content": "5.2.1 Distillation temperature\nAs mentioned in Section 4.1.2, when the new model distills the knowledge of old tasks from the old model, most detailed information is lost if the softmax output of the old model is relatively similar to one-hot encoding. Thus, Hinton et al. (2015) introduced the distillation temperature, T, to distill the characteristic information of low probability targets. The output of the old model is divided by T before reaching the softmax layer. Therefore, a larger T leads to a more uniform probability distribution, which implies that the information carried by a small probability target is amplified. In this study, T is used to mitigate catastrophic forgetting in the CLDRM, i.e., to reduce the decrease in the recognition accuracy for old tasks while learning new tasks.\nThis section describes the effects of different temperature settings on the recognition accuracy for the first task. Component type determination is set as the first task, and spalling condition check is set as the second task with T set to be 1, 2, 5, and 10. These tasks are selected owing to their distinct characteristics, which tend to provide better generalization compared to other tasks. The purpose of this experiment is to find the optimal value of the distillation temperature by observing the variations in the recognition accuracy for the first task during the training of the second task. A smaller decrease in the recognition accuracy for the first task implies a more suitable value of the distillation temperature. The first task is trained using is a typical process with no distillation operation. Therefore, the accuracies of the models trained for the first task at different temperatures are almost the same. The main variation in accuracy occurs during the training of the second task. As illustrated in Figure 12, the accuracy for the first task is obtained over 120 epochs of training, where the first 60 (0\u2013 59) and last 60 epochs represent the training of the first and second tasks, respectively. It is worth mentioning that there are only minor changes in accuracy during the training of the second task at different temperatures. This implies that the variations in the temperature have a negligible effect on the learning of the new task. Nonetheless, the temperature significantly impacts the knowledge distillation from the first task. As clearly shown in Figure 12, when T = 1, it is ineffective to use the normal SoftMax output from the old and new models to calculate the loss for retaining the recognition accuracy for the first task. However, accuracy increases at T = 2. The maximum accuracy is obtained at T = 5, and it is approximately 3-4% higher than the accuracy at T = 1. However, as T continues to increase more, accuracy tends to gradually decrease. For instance, the accuracy at T = 10 is less than that at T = 1. These results show that the appropriate distillation temperature improves the effect of knowledge distillation from old tasks. T is set as 5 in the subsequent experiments to obtain the best accuracy.\n5.2.2 Tasks with correlated Characteristics\nThis section describes the impact of the feature correlation between learning tasks on the performance of continual learning. When different tasks share numerous similar or same feature extractors, fine-tuning tends to perform better"}, {"title": "The modified probabilities of \\(y_o\\) and \\(\\hat{y}_o\\) are given by Equation (2).", "content": "\\(y_o^{(i,j)} = \\frac{(y_o^{'(i,j)})^{1/T}}{\\Sigma_j (y_o^{'(i,j)})^{1/T}}\\) \n\\(\\hat{y}_o^{'(i,j)} = \\frac{(\\hat{y}_o^{(i,j)})^{1/T}}{\\Sigma_j (\\hat{y}_o^{(i,j)})^{1/T}}\\)\n(2)"}, {"title": "5.2.3 Learning Order", "content": "This section describes the effect of the learning order of different tasks on the recognition accuracy of the CLDRM by mixing the feature-related and feature-unrelated tasks. The purpose of this experiment is to find whether the learning order of these four tasks has a significant impact on the final accuracy for a particular task. Owing to the advantage of feature fusion from different tasks in continuous multitask learning, this experiment will examine\nwhether it is possible for its the recognition accuracy to be higher than the one that was individually trained using fine- tuning method. In other words, we examine whether the knowledge of the spalling condition check and component type determination tasks helps improve the accuracy of the damage type determination task. The damage type determination task is selected as the last task to be trained, and the learning order of the other three tasks is arbitrarily changed. The damage level evaluation, spalling condition check, component type determination, and damage type determination tasks are denoted by numbers 1, 2, 3, and 4, respectively. For instance, the learning order of the damage level evaluation, spalling condition check, component type determination, and damage type determination tasks is denoted as 1-2-3-4.\nTable 4 shows the recognition accuracy of the CLDRM for all tasks for different learning orders. The CLDRM shows excellent performance in maintaining the knowledge of old tasks. The decrease in the recognition accuracy for old tasks during the training of new tasks is less than 6%. Additionally, the learning order of 3-1-2-4 shows the highest performance"}, {"title": "The loss (\\(L_{new}\\)) during the learning of a new task can be defined as the cross entropy between \\(y_n\\) and \\(\\hat{y}_n\\), as expressed in Equation (1).", "content": "\\(L_{new} = -y_nlog\\hat{y}_n\\) \n(1)"}, {"title": "Step 5: The total loss \\(L_{total} = L_{new} + \\lambda L_{old}\\) is", "content": "The total loss \\(L_{total} = L_{new} + \\lambda L_{old}\\) is calculated with the ground truth \\(y_n\\) and the outcome of the Step 3, namely, \\(\\hat{y}_n\\), \\(y_o^{(i,j)}\\), \\(\\hat{y}_o^{'(i,j)}\\). \\(\\lambda\\) is a hyperparameter that balances the learning tendency between the new task and the old tasks. In this study, \\(\\lambda\\) is set to 1."}, {"title": "Step 6: \\(\\theta_s\\), \\(\\theta_o\\), and \\(\\theta_n\\) are simultaneously updated to", "content": "Step 6: \\(\\theta_s\\), \\(\\theta_o\\), and \\(\\theta_n\\) are simultaneously updated to minimize the total loss."}, {"title": "The loss (\\(L_{old}\\)) for an old task can be expressed as Equation (3).", "content": "\\(L_{old} = -\\Sigma_{i=1}^k\\Sigma_j (y_o^{'(i,j)} log\\hat{y}_o^{'(i,j)} \\)\n(3)"}, {"title": "6. CONCLUSION AND FUTURE WORKS", "content": "In order to meet the requirement of multi-damage recognition in engineering practice, this study proposed a new deep CNN framework for the damage detection of RC structures, namely, the CLDRM, by combining the state-of- the-art LwF with the ResNet 34 architecture. The newly proposed approach not only possesses high prediction accuracy, but also have the advantage of computational economy. Deep CNN networks with traditional training methods, i.e., feature extraction, fine-tuning, duplicate and fine-tuning, as well as joint training were also investigated and compared with the new method. Three different experiments for four recognition tasks, including damage level, spalling check, component type and damage type determination were designed based on this training method to explore the optimal model parameters and applicable scenarios in damage recognition. The conclusions are as follows:\n\u2022\nCompared to conventional neural network models, the CLDRM can continuously train a model for multiple recognition tasks, without losing the prediction accuracy of old tasks. Additionally, the CLDRM provides robust performance with higher recognition accuracy and faster prediction for old and new tasks. It is achieved by optimized the model with less parameters and data storage. To be more specific, it will need just a quarter of the parameters needed for duplicate and fine-tuning method in most cases.\n\u2022\nIn practical applications, the appropriate distillation temperature depends on the characteristics of a trained dataset. An appropriate distillation temperature can improve the recognition accuracy of the CLDRM. However, recognition accuracy decreases when the temperature is extremely high.\n\u2022\nThe CLDRM is more suitable for feature-related multitask learning. The recognition accuracy for old tasks decreases negligibly when learning new tasks. Conversely, there might be a significant decrease in the accuracy for old tasks in feature-unrelated multitask learning. However, the CLRDM still maintains an accuracy of more than 80%."}, {"title": "Step 2: When a new task is added, a new model will be created and it inherits the \\(\\theta_s\\) and \\(\\theta_o\\) from the old model.", "content": "Step 2: When a new task is added, a new model will be created and it inherits the \\(\\theta_s\\) and \\(\\theta_o\\) from the old model. The newly appended parameters \\(\\theta_n\\) will be initialized."}, {"title": "Step 3: \\(\\theta_s\\) and \\(\\theta_o\\) are frozen, and \\(\\theta_n\\) is pretrained in the", "content": "Step 3: \\(\\theta_s\\) and \\(\\theta_o\\) are frozen, and \\(\\theta_n\\) is pretrained in the dataset of new task to convergence (warm up)."}, {"title": "Step 4: \\(\\theta_s\\) and \\(\\theta_o\\) are unfrozen, \\(\\hat{y}_n\\) and \\(y_o^{(i,j)}\\) are", "content": "Step 4: \\(\\theta_s\\) and \\(\\theta_o\\) are unfrozen, \\(\\hat{y}_n\\) and \\(y_o^{(i,j)}\\) are output from the new model, and \\(y_o^{'(i,j)}\\) is input from the old model using the same batch images of new task."}, {"title": "The learning order influences the CLDRM. It is", "content": "The learning order influences the CLDRM. It is important to determine the appropriate learning order of tasks and select when to end the learning process for achieving better performance. To improve the recognition accuracy of the CLDRM for a particular task after fine-tuning", "follows": "n\u2022\nIn terms of parameter updates during model training, certain restrictions can be placed on the weight updates of the neurons that are relatively beneficial for maintaining damage characteristics to prevent catastrophic forgetting(Kirkpatrick et al., 2017).\n\u2022\nA GAN (Generative Adversarial Network) model (Goodfellow et al., 2014) can be simultaneously trained with a particular task to maintain the memory of the dataset used in this training. Thus, when new tasks are added in the future, the past data collected by the GAN model can be directly used for training. This is equivalent to improving the training efficiency of joint training.\n\u2022\nCombining long-term memory and short-term memory, such as LSTM (Long Short Term Memory) (Hochreiter et al. 1997), for model training can be further explored to alleviate the adverse effects of the gradual forgetting problem of continual learning (Gepperth and Karaoguz, 2016). In this manner, the model can preserve the recognition accuracy for a previously learned task and simultaneously improve the accuracy for a new recognition task because it is extremely capable of retaining information about the characteristics of previous learning tasks.\nThe CLDRM has the potential to be used for portable devices owing to its small number of parameters and ability to rapidly and accurately learn new tasks. Once the model achieves stable performance with acceptable recognition accuracy, its algorithms can be programmed into portable hardware or as mobile software"}]}