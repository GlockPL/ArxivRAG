{"title": "Continual-learning-based framework for structural damage recognition", "authors": ["Jiangpeng Shu", "Jiawei Zhang", "Reachsak Ly", "Fangzheng Lin", "Yuanfeng Duan"], "abstract": "Multi-damage is common non in reinforced\nconcrete structures and leads to the requirement of large\nnumber of neural networks, parameters and data storage, if\nconvolutional neural network (CNN) is used for damage\nrecognition. In addition, conventional CNN experiences\ncatastrophic forgetting and training inefficiency as the\nnumber of tasks increases during continual learning, leading\nto large accuracy decrease of previous learned tasks. To\naddress these problems, this study proposes a continual-\nlearning-based damage recognition model (CLDRM) which\nintegrates the \u201clearning without forgetting\u201d continual\nlearning method into the ResNet-34 architecture for the\nrecognition of damages in RC structures as well as relevant\nstructural components. Three experiments for four\nrecognition tasks were designed to validate the feasibility\nand effectiveness of the CLDRM framework. In this way, it\nreduces both the prediction time and data storage by about\n75% in four tasks of continuous learning. Three experiments\nfor four recognition tasks were designed to validate the\nfeasibility and effectiveness of the CLDRM framework. By\ngradual feature fusion, CLDRM outperformed other methods\nby managed to achieve high accuracy in the damage\nrecognition and classification. As the number of recognition\ntasks increased, CLDRM also experienced smaller decrease\nof the previous learned tasks. Results indicate that the\nCLDRM framework successfully performs damage\nrecognition and classification with reasonable accuracy and\neffectiveness.\nKeywords: Damage recognition and classification,\nConcrete Structures, Continual-learning-based damage\nrecognition model (CLDRM), ResNet, Learning without\nforgetting.", "sections": [{"title": "1 INTRODUCTION", "content": "Reinforced concrete (RC) civil structures gradually\napproach their design life expectancy, posing a risk to the\nsafety structures and people (Liu et al. 2019). Therefore, it is\nnecessary to effectively inspect damages of RC structures.\nConventionally, different manual inspections methods were\nused. However, these methods have the disadvantages of\nunreliable inspection results and considerable time\nconsumption (Cha et al. 2017). Owing to the rapid\ndevelopment of machine learning, which has shown\nexcellent performance in image processing and computer\nvision in recent years, researchers and engineers are\nincreasingly applying it for damage detection and structural\nassessment (DeVries et al., 2018, Spencer et al., 2019 &\nChen et al., 2018). One of the well-known applications of\ndeep learning in civil engineering is crack detection and\nrecognition. For instance, Kim et al. (2019) used a\nconvolutional neural network (CNN) to determine the\nexistence and location of concrete cracks. Chen and\nJahanshahi (2018) combined CNNs with naive Bayes data\nfusion to analyze individual video frames for crack detection.\nThe types of damage of RC structures are various. Thus,\nthe demand for the recognition and classification of damage\ntypes is also on the rise. Moreover, it is becoming easier to\nretrieve more structural-damage-related information in the\nform of image data based on the technical development of\ndeep learning and data acquisition. For this reason, numerous\nsolutions have been explored. A region-based CNN (Faster-\nRCNN, Ren et al., 2017) was adopted to detect different\ndamage types such as concrete cracks and steel corrosion\nwith two levels (medium and high), including bolt corrosion"}, {"title": "1.2 Multitask Damage Recognition", "content": "It is worth noting that with the continuous development of\ndeep learning, the number of recognition tasks in damage\ndetection is increasing. One of the common problems among\nthe abovementioned applications is the limitation of the\nnumber of recognition tasks for training. For example, ten\ndifferent neural networks are required for ten different\nrecognition tasks. Hence, the number of parameters increases\nexponentially with the number of damage recognition tasks,\nthereby making the training process time/resource\nconsuming. Additionally, these training methods do not\nutilize the feature correlation between similar tasks such as\ncrack detection and spalling detection. To address this issue,\none neural network can be trained simultaneously for\nmultiple recognition tasks. The trained model can identify\nsimilar features and characteristics with improved accuracy\n(Li and Hoiem, 2018). Nevertheless, the similar\ncharacteristics of certain recognition tasks present a few\ndrawbacks. For instance, the image characteristics of\nspalling condition check and damage level evaluation are\nsimilar to a certain extent. If a model only outputs one\nprediction, then there is a problem. Therefore, to prevent this\nconfusion in training methods, fully connected layer is\nseparated to output the results of different tasks. The two\nmost common methods for this are simple sequence training\n(Sutskever et al., 2014) and joint training (Caruana, 1997).\nSimple sequence training begins by training a model for the\nfirst task. Then, more neurons are subsequently added in the\ntail part of a fully connected layer to learn the feature of the\nnext task. The common problem of this method is the highly\nlikely catastrophic forgetting, where a network tends to"}, {"title": "1.3 Continual Learning", "content": "Continual learning has been proposed as a revolutionary\nmethod (Parisi et al., 2019) for two purposes: (1) to perform\nmultitask recognition using one CNN; (2) to maintain an\noptimal recognition accuracy for previously trained tasks\nwith a low training cost. Continual learning is a generic\nmethod, which can be adopted in any CNN framework.\nContinual learning utilizes the features and knowledge\nlearned from the recognition of previous tasks, facilitates\ntraining for next tasks, and maintains the features learned\nfrom previous tasks. This is achieved by limiting changes in\nparameters, i.e., adding a regularization term. For instance,\nKirkpatrick et al.(2017) proposed elastic weight\nconsolidation as a specific sequence training method that\nquantifies the importance of the weights of previous tasks,\nflexibly updates the parameters during the training of a new\ntask, maintains the features learned in previous tasks, and\nprevents catastrophic forgetting. Zenke et al. (2017)\nintroduced synaptic intelligence into artificial neural\nnetworks, where each synapse accumulates and exploits task-\nrelevant information over time to rapidly store new\nknowledge without forgetting previous knowledge."}, {"title": "2 OVERVIEW OF THE PROPOSED METHOD", "content": "Figure 1 shows the flowchart of the proposed framework,\ntraining steps, and testing steps. A comprehensive dataset that\nincludes typical damage categories is prepared for training. A\nlabeled training dataset is the input. A separate test dataset is\nprepared to verify the model and to investigate its performance\non four different recognition tasks, which are (1) three-\nclass classification for damage level evaluation, (2)\nbinary classification for spalling condition check, (3)\nthree-class classification for component type\ndetermination, and (4) four-class classification for\ndamage type determination. Each task is defined in detail\nin Section 3.1. This study utilizes a collected large dataset\nof damaged RC image including PEER Hub ImageNet\ndataset (Gao and Mosalam, 2018). Overall, 16,840\ncolorful images with a resolution of 224 \u00d7 224 are\nprepared, preprocessed, reclassified, and manually\nannotated for the aforementioned recognition tasks. The\nhierarchy tree in Figure 2 illustrates the structure of the\ndataset. To address the lack of valuable structural images,\neach image is labeled with multiple tags as multiple\nattributes according to the recognition tasks. The final\nratio of the images used in each recognition task is\nillustrated in Figure .\nThe CLDRM adopts the continual-learning-based\n\"learning without forgetting (LwF)\" method (Li and\nHoiem, 2018), which is a form of knowledge distillation\n(Hinton et al. 2015). Instead of using a previous image\ndataset for retraining, the knowledge learned from\nprevious tasks is retained by learning the soft targets\nprovided by the previous model, which is stored after\ntraining. In other words, the previous model can be saved\nand stored for subsequent training without any image\ndatasets of a previous task. This significantly reduces\nmemory requirement and training complexity. A new\ndeep CNN training framework, namely, the CLDRM,\nwhich utilizes the LwF method with the residual network\n(ResNet) (He et al., 2016) architecture for the detection\nand classification of crack damage in RC structures, is\ndeveloped."}, {"title": "3 RECOGNITION TASKS AND DATASET", "content": "The effect of different parameters, such as distillation\ntemperatures, correlation of features as well as learning\norders, on the results of recognition based on proposed\nCLDRM, is investigated. This research's content is\ndescribed as follows. Section 2 presents the synopsis of the\nproposed method. Section 3 provides the details of the four\nrecognition tasks and their corresponding datasets. Section\n4 explains the overall architecture of the networks and the\nproposed continual learning-based model training\nmethodologies as well as the hyperparameters, dataset and\nsettings used to train the model. Section 5 demonstrates\nhow the framework evaluates test images from the\nproposed experiments and includes discussions regarding\nthe method's performance and potential. Section 6\nconcludes this article and overviews some future possible\nstudies to be conducted in this research area."}, {"title": "3.1 Recognition Tasks", "content": ""}, {"title": "3.1.1 Damage level evaluation", "content": "Owing to limited datasets and engineering subjectivity\non determining moderate versus heavy damage levels,\nprevious researchers in this field have categorized the\ntypes of damage into three different levels, i.e.,\n\"undamaged,\" \"minor damage,\" and \"moderate damage to\nheavy damage.\u201d To achieve a clearer boundary between\nthe levels of damage, this study categorizes crack damage\ninto three main categories, i.e., \u201cundamaged,\u201d \u201cminor\ndamage,\" and\n\"heavy damage,\" which are defined as follows: Minor\ndamage does not pose a risk and does not need to be repaired\nurgently. Heavy damage can pose a risk and must be repaired\nurgently. The samples of the images used in training for\ndamage level evaluation are shown in Figure 4."}, {"title": "3.1.2 Spalling condition check", "content": "Spalling is the breaking of a concrete surface, and it\nfrequently extends to the top layer of reinforcing steel. The\nspalling of concrete affects a broad variety of structures,\nincluding framed buildings, multistory car parks, and bridges.\nSpalling can be caused by the corrosion of embedded\nreinforcing steel, fire exposure, freeze and thaw cycling, and\nso on. Spalling is considered as a separate damage type\ncategory owing to its distinguishable characteristics (Figure)."}, {"title": "3.1.3 Component type determination", "content": "Component type determination is a three-class\nclassification task for \"columns,\" \"walls (or slabs),\" and\n\"beams\" (Figure). Owing to the geometrical similarity\nbetween beams and columns, rotation is not implemented for\ndata augmentation to prevent the occurrence of label\ninconsistency between beams and columns."}, {"title": "3.1.4 Damage type determination", "content": "Four typical crack damage types are selected based on the\ncauses of cracks. All of them have evident characteristics,\nwhich are suitable for identification. The proportion of\nimages for each crack type is shown in Figure 7."}, {"title": "4 NETWORK ARCHITECTURE AND MODEL", "content": ""}, {"title": "4.1 Network Architecture", "content": ""}, {"title": "4.1.1 Network Architecture of ResNet", "content": "ResNet (He et al., 2016) is well known for its remarkable\nobject detection and image classification capabilities. It has\nbeen demonstrated that residual mapping and shortcut\nconnections facilitate the training process and lead to better\nresults compared to very deep plain networks. Network depth\nis crucial for improving the network performance of CNNs;\nhowever, deeper networks are more difficult to train. He et\nal. (2016) reported that an increase in network depth leads to\ndegradation problems, which cause accuracy to become\nsaturated. To address this problem, they used [batch\nnormalization (BN), rectified linear unit (ReLU), and a"}, {"title": "4.1.2 Learning Without Forgetting", "content": "The LwF method was first developed by Li and Hoiem\n(2018), and has been adopted in the proposed CLDRM.\nThere are three important notations in LwF, i.e., $\\theta_s$, which\ndenotes the parameters in the CNN shared across all tasks,\n$\\theta_o$, which denotes the specific parameters learned from\nprevious tasks, and $\\theta_n$, which denotes the specific\nparameters that are learned in a new task.\nIn this study, ResNet-34 is utilized to implement multitask\nlearning and $\\theta_s$ (the parameters of layers before the tail of"}, {"title": "4.2 Comparative Evaluation", "content": "The performance of the proposed CLDRM framework is\nevaluated through experiments and compared to a\nconventional CNN model with four existing training\nmethods, which are described below."}, {"title": "4.2.1 Feature Extraction", "content": "Feature extraction (Shin et al., 2016) is used to filter out the\nmost critical and distinguishable information from redundant\ndata. Extracted features are typically represented by feature\nvectors. In deep learning, the output of a certain layer (the\nlast convolutional layer) can be extracted as the"}, {"title": "4.2.2 Fine-Tuning", "content": "To overcome the abovementioned problem of feature\nextraction, $\\theta_o$ is fixed and a low learning rate is applied for\ntraining $\\theta_s$ and $\\theta_n$ (Yosinski et al., 2014). In this manner, the\nnetwork learns the features related to a new task. However,\nit may forget the features learned in the first task. The\ntraining conditions of the CLDRM and fine-tuning are quite\nsimilar but considerably different from the training\nconditions of the two methods mentioned below. Therefore,\nthe CLDRM is mainly compared with fine-tuning in the\nfollowing experiments."}, {"title": "4.2.3 Duplicate and Fine-Tuning", "content": "During the training for a new task, the relatively important\nparameters for the identification of the first task are partially\nmodified. This causes the network to forget the features\nlearned in the previous task. For this reason, the duplicate\nand fine-tuning method is applied to the network for each\nnew task. Moreover, each network must be individually fine-\ntuned. It is worth noting that even though each network\nlearns specific features from the images corresponding to a\ntask, the number of parameters still increases exponentially."}, {"title": "4.2.4 Joint Training", "content": "Joint training simultaneously trains all parameters ($\\theta_s$,\n$\\theta_o$, and $\\theta_n$) using all data from old and new tasks (Caruana,\n1997). The network can extract and integrate the\ncharacteristics of each task. This may improve the accuracy\nfor a few recognition tasks compared to the individual\ntraining of each task. However, storing all data is an issue\nand extremely expensive in terms of time and computation\nresources. In order words, whenever a new task is added, it\nmust be trained again with the old tasks that have been\npreviously trained on the network."}, {"title": "4.3 Model Training", "content": "This section describes the CLDRM training process,\nincluding the training and test sets, optimization methods,\nand hardware configuration. All tasks are performed on a\nworkstation with the Intel(R) Xeon(R) E5-2678 v3 2.50 GHz\nCPU, 64.0 GB RAM, and the NVIDIA RTX2080TI-11G\nGPU."}, {"title": "4.3.1 Train and test set", "content": "The number of training and test sets used in the\nexperiments for different recognition tasks are listed in Table\n2. In the data preprocessing part, data augmentation\n(horizontal flip, vertical flip, rotation, color jitter, etc.) is\nimplemented with a batch size of 64. However, a small\nproportion of the datasets in the structure component part\ncontain useful environmental background information.\nTherefore, in most cases, at a certain angle of rotation of\nimages, inclined beams may look like vertical columns and\nvice versa. Therefore, to prevent this, images are not rotated\nin the component type determination task."}, {"title": "4.3.2 Optimization", "content": "The results of the initial experiments for the training of\ncontinual learning tasks show that the Adam optimizer\n(Kingma and Ba, 2015) is relatively unstable and ineffective,\nwhich results in poor model performance. The recognition\naccuracy for an old task decreases significantly during the\ntraining of a new task. Thus, the Adam optimizer is not\nselected as the training method for the CLDRM. SGD\n(Nesterov, 1983) with momentum provides considerably\nbetter performance, and it is employed as the optimizer for\nthe CLDRM. The learning rate of the SGD optimizer is 1 \u00d7\n$10^{-3}$, the momentum is 0.9, and the weight decay rate is 4\u00d7$10^{-5}$.\nThese parameter settings are adopted to pretrain $\\theta_n$, and\nthe model is trained for 40 epochs. When $\\theta_s$, $\\theta_o$, and $\\theta_n$ are\nsimultaneously trained, the learning rate is reduced to 1 \u00d7\n$10^{-4}$ and the number of training epochs is increased to 60."}, {"title": "5 EXPERIMENTS AND RESULTS", "content": "The feasibility of the CLDRM is experimentally verified\nfor four different recognition tasks, i.e., damage level\nevaluation, spalling condition check, component type\ndetermination, and damage type determination. The\nobjective is to achieve accurate multitask damage\nrecognition through a single neural network. However,\ntypically, the recognition accuracy for a previous task\ndecreases when new tasks are input to the neural network.\nThe target is to minimize the decrease in the recognition\naccuracy for previous tasks so that the total accuracy is high.\nThe influence of the following parameters on the model is\nexamined: a) effects of different distillation temperature\nsettings on the four proposed continuous-learning-based"}, {"title": "5.1 Initial Study", "content": "The initial experiment compares the accuracy of different\nrecognition tasks using different training methods for model.\nTable 3 compares the accuracy of different recognition tasks\nand training methods. \u201cInitial\" refers to the best test accuracy\nfor a task that is trained for the first time. \"Final\" refers to the\ntest accuracy for this specific task when the training of all\ntasks is finished. The difference between \"Initial\" and \"Final\"\nfor a task shows the decline in the recognition accuracy for\nthat task during the entire training process. It is worth noting\nthat the values of \"Initial\" and \"Final\" are the same for\ndamage type determination because it is the last task to be\ntrained. Os and are constant in feature extraction.\nTherefore, the values of \u201cInitial\" and \"Final\" are the same for\nall tasks in the case of this training method. In addition, there\nis no concept of \u201cInitial\u201d and \u201cFinal\u201d in the duplicate and\nfine-tuning method and joint training method. However, for\nthe convenience of comparison, \u201cFinal\u201d is considered as\nequal to \"Initial\u201d for these methods.\nAs shown in Table 3, when the number of trained tasks\nincreases, the decrease in the recognition accuracy for\nprevious tasks is less in the case of the CLDRM compared to\nthe fine-tuning and feature extraction methods. Moreover,\ncompared to the other three methods, the CLDRM achieves\nthe highest recognition accuracy (93.60%) for the final\ntrained task (damage type determination). The Average of\n\"Final\" for the CLDRM is also relatively high.\nThe CLDRM achieves high accuracy primarily because it\nis capable of retaining the useful and similar characteristic\nfeatures of the previous three tasks, which are beneficial for\nthe damage type determination task. Hence, damage types\nare classified more accurately with less direct training data.\nSimilarly, the characteristics of the cracks caused by the ASR\nare quite similar to a certain type of spalling. Thus, the\ntraining of the spalling condition check task is beneficial for\nthe ASR damage detection task. In the future, this notion can\nbe implemented to improve the accuracy for recognition\ntasks where direct training alone cannot improve the\naccuracy.\nIn Table 3, the \"Average of Final\" indicator is used to\nmeasure the overall accuracy of different training methods.\nIt is the average of the value of \u201cFinal\u201d for each recognition\ntask. The Average of \"Final\" for the CLDRM is 1.36%\nhigher than the fine-tuning method. This difference increases\nwith the number of tasks. The duplicate and fine-tuning\nmethod and joint training method have the highest Average\nof Final; this indicates that these methods perform the best.\nHowever, as mentioned in Section 4.2, the high accuracy of\nthese methods comes at the high cost of a large number of\nparameters and data storage required during training.\nThe confusion matrices of the test prediction by the CLDRM\nin the four recognition tasks are shown in Figure 11. As\nshown in Figure 11 a), when the damage level is categorized\ninto three classes (\u201cundamaged,\u201d \u201cminor damage,\" and\n\"heavy damage", "heavy damage": "nd", "damage": "ith high\naccuracy. However, in the same recognition task, \u201cminor\ndamage", "undamaged": "nin most cases. The main reason behind this might be that the\ncharacteristics of the damage in the"}, {"damage": "ataset\nis not obvious and similar to that in the \u201cundamaged", "minor damage\"\nand \"undamaged\" might not be important for training the\nnext recognition task and might not be considered in\ncontinual learning. This also\"\n    },\n    {\n      \"title\"": "5.2 Further Experiments", "content": ""}, {"title": "5.2.1 Distillation temperature", "content": "As mentioned in Section 4.1.2, when the new model\ndistills the knowledge of old tasks from the old model, most\ndetailed information is lost if the softmax output of the old\nmodel is relatively similar to one-hot encoding. Thus, Hinton\net al. (2015) introduced the distillation temperature, T, to\ndistill the characteristic information of low probability\ntargets. The output of the old model is divided by T before\nreaching the softmax layer. Therefore, a larger T leads to a\nmore uniform probability distribution, which implies that the\ninformation carried by a small probability target is amplified.\nIn this study, T is used to mitigate catastrophic forgetting in\nthe CLDRM, i.e., to reduce the decrease in the recognition\naccuracy for old tasks while learning new tasks.\nThis section describes the effects of different temperature\nsettings on the recognition accuracy for the first task.\nComponent type determination is set as the first task, and\nspalling condition check is set as the second task with T set\nto be 1, 2, 5, and 10. These tasks are selected owing to their\ndistinct characteristics, which tend to provide better\ngeneralization compared to other tasks. The purpose of this\nexperiment is to find the optimal value of the distillation\ntemperature by observing the variations in the recognition\naccuracy for the first task during the training of the second\ntask. A smaller decrease in the recognition accuracy for the\nfirst task implies a more suitable value of the distillation\ntemperature. The first task is trained using is a typical\nprocess with no distillation operation. Therefore, the\naccuracies of the models trained for the first task at different\ntemperatures are almost the same. The main variation in"}, {"title": "5.2.2 Tasks with correlated Characteristics", "content": "This section describes the impact of the feature correlation\nbetween learning tasks on the performance of continual\nlearning. When different tasks share numerous similar or\nsame feature extractors, fine-tuning tends to perform better"}, {"title": "5.2.3 Learning Order", "content": "This section describes the effect of the learning order of\ndifferent tasks on the recognition accuracy of the CLDRM\nby mixing the feature-related and feature-unrelated tasks.\nThe purpose of this experiment is to find whether the learning\norder of these four tasks has a significant impact on the final\naccuracy for a particular task. Owing to the advantage of\nfeature fusion from different tasks in continuous multitask\nlearning, this experiment will examine\nwhether it is possible for its the recognition accuracy to be\nhigher than the one that was individually trained using fine-\ntuning method. In other words, we examine whether the\nknowledge of the spalling condition check and component\ntype determination tasks helps improve the accuracy of the\ndamage type determination task. The damage type\ndetermination task is selected as the last task to be trained,\nand the learning order of the other three tasks is arbitrarily\nchanged. The damage level evaluation, spalling condition\ncheck, component type determination, and damage type\ndetermination tasks are denoted by numbers 1, 2, 3, and 4,\nrespectively. For instance, the learning order of the damage\nlevel evaluation, spalling condition check, component type\ndetermination, and damage type determination tasks is\ndenoted as 1-2-3-4."}, {"title": "5.3 Model Evaluation", "content": "The performance of each training method is evaluated on\nthe test set using the indicators listed in Table 6. The feature\nextraction method requires the least training time but\nprovides mediocre performance for new tasks. The duplicate\nand fine-tuning method provide good performance on old\nand new tasks; however; the prediction time of the\ncorresponding model is quite high. The joint training method\nprovides superior performance for old and new tasks but\nrequires a large amount of data storage while training. On the\ncontrary, the CLDRM not only provides high recognition\naccuracy and speed for old and new tasks but also requires\nless data storage and parameters during training. The results\nprovided in the table are for a generalized evaluation purpose\nonly. These results are not only affected by whether tasks are\nrelated but also by specific datasets and application scenarios.\nIn addition, one of the main challenges is the amount of data\nstorage or computing power required for"}, {"title": "6. CONCLUSION AND FUTURE WORKS", "content": "In order to meet the requirement of multi-damage\nrecognition in engineering practice, this study proposed a\nnew deep CNN framework for the damage detection of RC\nstructures, namely, the CLDRM, by combining the state-of-\nthe-art LwF with the ResNet 34 architecture. The newly\nproposed approach not only possesses high prediction\naccuracy, but also have the advantage of computational\neconomy. Deep CNN networks with traditional training\nmethods, i.e., feature extraction, fine-tuning, duplicate and\nfine-tuning, as well as joint training were also investigated\nand compared with the new method. Three different\nexperiments for four recognition tasks, including damage\nlevel, spalling check, component type and damage type\ndetermination were designed based on this training method\nto explore the optimal model parameters and applicable\nscenarios in damage recognition. The conclusions are as\nfollows:\n\u2022\nCompared to conventional neural network models, the\nCLDRM can continuously train a model for multiple\nrecognition tasks, without losing the prediction\naccuracy of old tasks. Additionally, the CLDRM\nprovides robust performance with higher recognition\naccuracy and faster prediction for old and new tasks. It\nis achieved by optimized the model with less\nparameters and data storage. To be more specific, it will\nneed just a quarter of the parameters needed for\nduplicate and fine-tuning method in most cases.\n\u2022\nIn practical applications, the appropriate distillation\ntemperature depends on the characteristics of a trained\ndataset. An appropriate distillation temperature can\nimprove the recognition accuracy of the CLDRM.\nHowever, recognition accuracy decreases when the\ntemperature is extremely high.\n\u2022\nThe CLDRM is more suitable for feature-related\nmultitask learning. The recognition accuracy for old\ntasks decreases negligibly when learning new tasks.\nConversely, there might be a significant decrease in the\naccuracy for old tasks in feature-unrelated multitask\nlearning. However, the CLRDM still maintains an\naccuracy of more than 80%."}, {"title": "ACKNOWLEDGMENTS", "content": "The authors would like to gratefully acknowledge the\nsupport from the National Key R&D Program of China\n(2018YFE0125400) and the National Natural Science\nFoundation of China (U1709216), which made the research\npossible. The project was also funded by Centre for Balance\nArchitecture, Zhejiang University. In addition, the authors\nalso need to acknowledge that the first author and the second\nauthor have equivalent contribution to the paper."}]}