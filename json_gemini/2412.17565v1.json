{"title": "Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction.", "authors": ["Theodoros Tsiolakis", "Nikolaos Pavlidis", "Vasileios Perifanis", "Pavlos Efraimidis"], "abstract": "Cellular traffic forecasting is a critical task that enables network operators to efficiently allocate resources\nand address anomalies in rapidly evolving environments. The exponential growth of data collected from\nbase stations poses significant challenges to processing and analysis. While machine learning (ML)\nalgorithms have emerged as powerful tools for handling these large datasets and providing accurate\npredictions, their environmental impact, particularly in terms of energy consumption, is often overlooked\nin favor of their predictive capabilities.\nThis study investigates the potential of two bio-inspired models: Spiking Neural Networks (SNNs) and\nReservoir Computing through Echo State Networks (ESNs) for cellular traffic forecasting. The evalua-\ntion focuses on both their predictive performance and energy efficiency. These models are implemented\nin both centralized and federated settings to analyze their effectiveness and energy consumption in de-\ncentralized systems. Additionally, we compare bio-inspired models with traditional architectures, such\nas Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs), to provide a compre-\nhensive evaluation. Using data collected from three diverse locations in Barcelona, Spain, we examine\nthe trade-offs between predictive accuracy and energy demands across these approaches.\nThe results indicate that bio-inspired models, such as SNNs and ESNs, can achieve significant energy\nsavings while maintaining predictive accuracy comparable to traditional architectures. Furthermore,\nfederated implementations were tested to evaluate their energy efficiency in decentralized settings com-\npared to centralized systems, particularly in combination with bio-inspired models. These findings offer\nvaluable insights into the potential of bio-inspired models for sustainable and privacy-preserving cellular\ntraffic forecasting.", "sections": [{"title": "1. Introduction", "content": "Accurately predicting network traffic and load is\nessential for improving network management and\nensuring efficient operation for telecommunication\nproviders. Reliable forecasting enables proactive re-\nsource allocation, effective capacity planning, and\nimproved service quality, especially in high-demand\nscenarios. The primary challenge lies in maintaining\nrobust connectivity for all devices while avoiding un-\nnecessary resource wastage. Machine learning (ML)\nalgorithms have become indispensable tools for ad-\ndressing this challenge, offering capabilities such as\nreal-time decision-making, anomaly detection, fail-\nure prediction, and dynamic spectrum management.\nThese features make ML a critical component for\ncreating smarter, more sustainable telecommunica-\ntion networks. 1,2\nThis study is motivated by the rapid growth of\ndata generated by telecommunication systems, which\nis driven by the increasing use of connected devices.\nThe large amounts of data involved require sophisti-\ncated predictive models that need significant compu-\ntational resources to process. As a result, the training\nof these models often consumes substantial amounts\nof energy, time, and storage, creating challenges for\nboth efficiency and sustainability.\nOne major concern is the environmental im-\npact of training such resource-intensive models. As\ndemand for data-driven solutions grows, the energy\nconsumption and carbon emissions from these pro-\ncesses increase. This highlights the need for ap-\nproaches that can balance strong predictive perfor-\nmance with lower energy consumption.\nA source of inspiration for this work is the ef-\nficiency of the human brain, which processes infor-\nmation using far less energy than modern machine\nlearning systems. For example, training a model like\nGPT-3 is estimated to consume around 190,000 kWh\nof energy, whereas the human brain operates on just\n12-20 W.4 By mimicking the brain's processes, bioin-\nspired models like Spiking Neural Networks (SNNs)\noffer a promising way to make machine learning more\nenergy-efficient.\nIn this study, we explore the use of bioinspired\nSNNs and Reservoir Computing (RC) with Echo\nState Networks (ESNs) for cellular traffic forecast-\ning. We examine several types of Leaky Integrate-\nand-Fire (LIF) neurons in SNNs, including Lapicque,\nLeaky, RLeaky, Synaptic, and Alpha neurons, as\nwell as ESNs.5 These models are compared with tra-\nditional machine learning methods, such as Multi-\nLayer Perceptrons (MLPs) and Convolutional Neu-\nral Networks (CNNs). Both centralized and feder-\nated learning settings are used in the evaluation\nto account for modern distributed computation ap-\nproaches. Federated learning, in particular, reduces\nthe need for centralized data storage, offering a more\nenergy-efficient way to train models.\nThis study evaluates the trade-offs between pre-\ndictive accuracy and energy efficiency. While energy-\nefficient models often show reduced prediction per-\nformance, this work aims to explore ways to strike\na balance between sustainability and accuracy. To\nachieve this, we use a Sustainability Index that com-\nbines key metrics like power consumption, prediction\nerror, and dataset size to provide a comprehensive\nevaluation of model efficiency.\nTo the best of our knowledge, this is the first\nstudy to compare the energy consumption of bio-\ninspired and traditional models for cellular traffic\nforecasting, evaluated across both centralized and\nfederated learning settings.\nWe further explore the power efficiency of fed-\nerated learning, which was initially introduced to\nenhance privacy in machine learning. Recent stud-\nies indicate that federated learning can also reduce\npower consumption, offering a dual benefit of im-\nproved privacy and energy efficiency. This makes it\na promising framework for sustainable and privacy-\npreserving machine learning.\nThe results aim to guide researchers and prac-\ntitioners toward developing machine learning mod-\nels that balance high performance with lower energy\nuse. The rest of the paper is structured as follows:\nSection 2 re/views related work on Spiking Neural\nNetworks (SNNs), Reservoir Computing (RC), and\nFederated Learning. Section 3 describes the dataset\nand research problem, along with the models and\nevaluation methods. Section 4 explains the experi-\nmental setup and methodology. Section 5 presents\nthe results and analysis. Section 6 discusses the find-\nings, challenges, and future directions. Finally, Sec-\ntion 7 concludes by summarizing the key outcomes\nand contributions of the study."}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Traffic Prediction", "content": "Recent advancements in cellular traffic forecast-\ning have demonstrated the effectiveness of machine\nlearning and federated learning approaches in man-\naging 5G base stations. Perifanis et al. (2023)8 in-\ntroduced a federated learning framework for traf-\nfic prediction in 5G base stations, highlighting the\nmodel's ability to preserve data privacy while en-\nabling distributed training across multiple stations.\nTheir work emphasized the importance of efficient\ntime-series forecasting to optimize resource alloca-\ntion and reduce energy consumption in large-scale\ncellular networks.\nBuilding on this foundation, Pavlidis et al.\n(2024)9 extended the concept by applying federated\nmodels to predict traffic across a larger number of\nbase stations, while also investigating the impact of\nfine tuning several experimental parameters. They\ndemonstrated how federated learning could improve\nforecasting accuracy and reduce unnecessary com-\nmunication overheads.\nZhao et al. (2023) proposed the FL-DeepAR\nframework, which uses deep autoregressive net-\nworks for federated traffic prediction. This ap-\nproach addressed statistical heterogeneity and incor-\nporated advanced gradient-based aggregation tech-\nniques, achieving superior prediction performance on\nreal-world datasets.10\nSimilarly, Guesmi et al. (2024) 11 proposed ad-\nvanced predictive modeling techniques to enhance\ntraffic forecasting in emerging cellular networks.\nTheir research leveraged a combination of deep learn-\ning and federated learning algorithms to address the\nchallenges of time-series forecasting in dynamic and\nheterogeneous environments, further reinforcing the\npotential of distributed machine learning in telecom-\nmunications.\nLee et al. (2024) 12 explored federated learning\napplications beyond traffic forecasting, focusing on\ncomprehensive mobile network management. Their\nstudy emphasized the integration of federated mod-\nels into resource allocation and small-cell base sta-\ntion management, showcasing the broader impact of\nthis technology on network efficiency.\nGao et al. (2024) developed FedCE, a\ncommunication-efficient federated learning frame-\nwork that reduced communication overhead while\nimproving prediction accuracy using gradient com-\npression and adaptive aggregation strategies. The re-\nsults highlighted significant improvements in predic-\ntion accuracy with optimized resource utilization. 13\nAdditionally, Lee et al. (2024) proposed a per-\nsonalized federated learning approach for mobile\ntraffic prediction, which utilized layer-wise aggre-\ngation and adaptive layer freezing to improve pre-\ndiction accuracy and communication efficiency. This\nmethod demonstrated its potential for reducing over-\nhead and ensuring scalability in dynamic network en-\nvironments.14\nLastly, Kalam et al. (2023) introduced a fed-\nerated learning approach for 5G traffic forecasting,\ndemonstrating significant improvements in accuracy"}, {"title": "2.2. SNN in Traffic Prediction", "content": "Recent advancements in spiking neural networks\n(SNNs) demonstrate their potential for efficient and\naccurate network traffic prediction, particularly in\nenergy-constrained environments. In our previous\nwork 3 we explored SNNs in the context of cellular\ntraffic forecasting, emphasizing their ability to re-\nduce power consumption compared to conventional\nmachine learning models. By leveraging the bio-\ninspired architecture of SNNs, the study addressed\nthe growing demand for environmentally sustainable\nmachine learning solutions in telecommunications.\nWe highlighted how SNNs effectively capture tem-\nporal dynamics in network traffic patterns, enabling\nprecise predictions with significantly reduced energy\nfootprints.\nSimilarly, Kang et al. (2024) 16 investigated the\nuse of SNNs in neuromorphic systems for traffic\nhotspot prediction in network-on-chip (NoC) archi-\ntectures. Their study focused on utilizing liquid state\nmachines (LSMs) a specific form of reservoir com-\nputing based on spiking dynamics to predict and\nmitigate traffic congestion hotspots in NoC environ-\nments. The findings showcased how SNN-based ap-\nproaches not only improve computational efficiency\nbut also enhance routing strategies, contributing to\na more energy-efficient processing pipeline.\nTogether, these studies underscore the transfor-\nmative potential of SNNs in network traffic predic-\ntion, providing scalable, low-power solutions for real-\ntime applications while maintaining high predictive\naccuracy."}, {"title": "2.3. RC in Traffic Prediction", "content": "Reservoir computing has emerged as a promising\nframework for cellular traffic forecasting due to its\nability to process complex temporal data efficiently\nwhile minimizing computational power consumption.\nLi et al. (2021) 17 introduced a deep multi-reservoir\nregression learning network tailored for cellular traf-\nfic prediction in multi-access edge computing envi-\nronments. This innovative approach leverages the\nstrengths of reservoir computing to provide real-time\nand accurate predictions, demonstrating its scalabil-\nity and efficiency in handling dynamic traffic pat-\nterns while maintaining low energy overheads.\nFurther advancing the field, Zhang and Vargas\n(2023) applied reservoir computing in the con-\ntext of 5G and beyond networks. Their study empha-\nsized how reservoir computing architectures enhance\nforecasting accuracy while addressing sustainability\nchallenges in mobile networks. By leveraging inno-\nvative learning techniques, their work provides ac-\ntionable insights for integrating reservoir computing\nframeworks into modern telecommunications infras-\ntructures, ensuring both predictive performance and\nenergy efficiency.\nCollectively, these studies underline reservoir\ncomputing's transformative potential for cellular\ntraffic forecasting, particularly in energy-constrained\nand dynamic environments like 5G networks. Its abil-\nity to balance computational efficiency with predic-\ntion accuracy makes it a critical tool for future net-\nwork management and optimization."}, {"title": "2.4. Federated Bio Inspired in Traffic Prediction", "content": "Federated Learning (FL) addresses privacy concerns\nin mobile networks but faces challenges like high\nenergy consumption, communication overhead, and\nconvergence issues. Aouedi et al. (2023)19 introduced\nHFedSNN, a Hierarchical Federated Learning (HFL)\nmodel using Spiking Neural Networks (SNNs) to\novercome these issues. HFedSNN reduces energy con-\nsumption by 4.3x, communication overhead by 26x,\nand improves accuracy by 4.48% compared to FL\nwith ANNs (FedANN), making it highly efficient for\nnon-IID data scenarios.\nSimilarly, Bacciu et al. (2021)20 introduced Fed-\nerated Reservoir Computing (FRC) that leverages\nbio-inspired models like Echo State Networks (ESNs)\nfor low-power, distributed temporal data process-\ning. ESNs excel in handling time-series data while\nminimizing energy use, offering scalable, privacy-\npreserving solutions.\nTogether, HFL with SNNs and FRC provide a"}, {"title": "3. System Model", "content": "This section outlines the framework used to evaluate\nthe performance and energy efficiency of the differ-\nent models and settings. This includes details about\nthe dataset, the problem formulation, and the model\narchitectures implemented in both centralized and\nfederated learning setups."}, {"title": "3.1. Dataset", "content": "In our analysis, we utilized a real-world dataset\nwith LTE traffic measurements that was gathered\nfrom three different areas in Barcelona, Spain. The\ndataset was collected under SUPERCOM initiative, a\nfrom Downlink Control Information (DCI) messages,\nwhich are transmitted through the PDCCH every\nTransmission Time Interval (TTI). Then, the raw\ndata are aggregated into two minutes intervals. Each\nmeasurement contains eleven features regarding net-\nwork traffic (see Table 1) and the downstream task is\nto predict the five of them, i.e. RNTI Count, UpLink,\nDownLink, RB Up and RB Down, using historical\nmeasurements for the next timestep.\nSpecifically, the measurements are gathered in\nthe following locations:\n\u2022 LesCorts: A residential area near Camp\nNou Football Stadium. Measurements at\nthis location comprise 12 days (2019-01-12\nto 2019-01-24).\n\u2022 PobleSec: A residential and touristic area\nnear the historic center, the exhibition cen-\ntre and the port. Measurements at this loca-\ntion comprise 28 days (2018-02-05 to 2018-\n03-05).\n\u2022 ElBorn: A touristic area in the downtown\nof the city. It is characterized by having a\nlot of shops and nightlife. Measurements at\nthis location comprise 7 days (2018-03-28 to\n2018-04-04).\nAs showed in, the dataset presents non Inde-\npendent and Identically Distributed (non-IID) dis-\ntibution, with the presence of three different skews,\ni.e. quantity, quality and temporality. This differen-\ntiation among respective BS is depicted in Fig. 2,\nindicating a challenging ML task."}, {"title": "3.2. Problem Statement", "content": "We formulate the problem in the context of time-\nseries forecasting. Consider a dataset $X \\in \\mathbb{R}^{N \\times d}$,"}, {"title": "3.3. ML Models", "content": "We evaluate the performance of several model archi-\ntectures within our framework. Specifically, we first\nemploy two traditional baseline learning models, i.e.,\nMLP and CNN as benchmarks. To facilitate a com-\nprehensive comparative analysis, we then selected\nseveral distinct Leaky-and-Integrate Fire (LIF) spik-\ning neuron types: the Lapicque's original Neuron, as\nwell as its streamlined counterpart, the Leaky Model,\nalongside the Recurrent Leaky Neuron, the Synaptic\nConductance-Based LIF Neuron Model, and the Al-\npha Neuron Model and a Reservoir Computing (RC),\nEcho State model. Specifically, we utilize the follow-\ning model architectures:\n\u2022 Multi-Layer Perceptron (MLP): A\nMLP belongs to the class of feed-forward\nartificial neural networks (ANNs). MLP\ncan not operate directly on matrix rep-\nresentations, thus requiring time-series to\nbe flattened to one-dimensional vectors.\nIn our case, we transform the $(S,d)$ two-\ndimensional array used as input into an one-\ndimensional vector to $(S \\times d)$. In our archi-\ntecture, we utilize a single hidden layer with\n128 neurons.\n\u2022 Convolutional Neural Network\n(CNN): CNNs are a type of deep neural\nnetworks, highly effective in analyzing data\nwith a grid-like topology. In multivariate\ntime-series, convolution operations can ef-\nfectively utilize structural covariance. The\nimplemented CNN takes a two-dimensional\nmatrix of size $(S, d)$ as input and feeds it\nto four two-dimensional convolutional lay-\ners. The output is then propagated to a\ntwo-dimensional average pooling layer and\nfinally to a fully connected layer. For the fi-\nnal layer, similar to MLP, we utilize a single\nhidden layer with 128 units.\n\u2022 Lapicque Neuron (Original LIF Neu-\nron): The Lapicque neuron implements the\nfundamental circuit approach, originating\nfrom biology. Ion channels of a physical neu-\nron's membrane are modeled with a resis-\ntor and the membrane itself is modeled with\na capacitor. We check the potential (U) in\nthe capacitor, and if this potential reaches"}, {"title": "3.4. Evaluation Metrics", "content": "The primary metric used to quantify prediction error\nfor the time-series forecasting task is the normalized\nroot mean squared error (NRMSE), defined as:"}, {"title": "4. Experimental Setup", "content": "To ensure the integrity and validity of our compar-\native analysis, we maintained consistency across all\nexperimental settings. The architecture of the SNN\nmodels was standardized to include a single hidden\nlayer with 128 neurons and five output neurons cor-\nresponding to the target variables.\nIn our SNN models, both the input and output\nlayers utilize the Subtract-Reset Mechanism. This\nmeans that when a neuron's membrane potential ex-\nceeds the threshold, a spike is emitted, and the mem-\nbrane potential is reduced by the threshold value\n($V_{mem}$ = $V_{mem}$ - threshold).\nIn the output layer, however, neurons lack a re-\nset mechanism-a deliberate design choice to bet-\nter address the requirements of the time-series fore-\ncasting task. This configuration ensures that the pre-\ndicted output corresponds directly to the membrane\npotential, avoiding distortions caused by resets.\nAdditionally, input spikes are encoded directly\nfrom the input data at specific timesteps, enabling\nthe network to effectively convert non-spiking data\ninto a format compatible with spiking mechanisms.\nThis approach enhances the model's ability to pro-\ncess time-series data within the spiking neural net-\nwork framework.\nThe size of the dataset used for training the\nmodel is also a crucial factor. Training on a smaller\ndataset inevitably results in lower power consump-\ntion compared to a larger one. This relationship is\ncaptured by the Sustainability Index (S), which in-\ncludes dataset size as a parameter. To ensure consis-\ntency, we used the same dataset and size across all\nexperiments.\nFor implementation, we utilized the PyTorch li-\nbrary25 for traditional models such as MLPs and\nCNNs. The SNN models were implemented using\nthe snnTorch library, which is tailored for gradient-\nbased learning and provides pre-designed spiking\nneuron models that seamlessly integrate as recur-\nrent activation units. Energy consumption during the\ntraining process was measured using the Carbon-\nTracker Python module. 26 CatbonTracker is a tool\ndesigned to estimate and monitor the carbon emis-\nsions associated with computational processes, help-\ning organizations and researchers assess and reduce\ntheir environmental impact.\nCentralized training was conducted over 150\nepochs with a batch size of 128. In the federated\nlearning experiments, we used 10 federated steps\nwith 3 local epochs per client with a central server,\nsimulating the setup to maintain consistency.\nThe experiments were conducted on a Windows"}, {"title": "5. Experimental Evaluation", "content": ""}, {"title": "5.1. Predictive Performance", "content": ""}, {"title": "5.1.1. Modeling of Input Data", "content": "Selecting the correct number of spiking timesteps is\ncrucial for effectively encoding input data in SNN\nmodels. The number of timesteps determines how\nthe input data is represented as spikes, influencing\nthe network's ability to process and learn from the\nencoded information. Using too few timesteps may\nresult in a loss of critical details during the encod-\ning process, leading to poor model performance. On\nthe other hand, an excessive number of timesteps\ncan overcomplicate the encoding, increasing compu-\ntational costs and energy consumption without im-\nproving the predictive capacity of the model. This\nchallenge highlights the importance of fine-tuning\nthe timestep configuration to achieve an efficient and\naccurate representation of the input data.\nIn our experiments, we investigated how vary-\ning the number of timesteps used to encode input\ndata impacts the predictive performance of the mod-\nels. Specifically, we tested configurations with 1, 7,\n10, 50, 70, and 100 timesteps to identify the optimal\nsetup for maximizing accuracy.\nAs shown in Figure 3, the results indicate sig-\nnificant variations in performance depending on the\nchosen timestep length. Optimal performance was\nachieved at 10 timesteps for some models and 7\ntimesteps for others. Beyond these values, increasing\nthe number of timesteps did not improve accuracy\nand, in some cases, resulted in performance degra-\ndation. These findings highlight the importance of\nselecting an appropriate timestep configuration to\nbalance information completeness, computational ef-\nficiency, and predictive accuracy."}, {"title": "5.1.2. Centralized Learning", "content": "The evaluation of model performance and sustain-\nability across centralized configurations reveals criti-\ncal insights into the trade-offs between predictive ac-\ncuracy, energy efficiency, and overall sustainability.\nFigures 4 and 5 present the performance of various\nmodels using metrics such as NRMSE, MSE, RMSE,\nand MAE. The results show that model performance\nvaries significantly depending on the selected metric.\nTo ensure consistency and comparability, NRMSE\nwas chosen as the primary metric, as it normalizes\nerrors relative to the data scale, providing a more\nrealistic and interpretable estimation.\nFrom the data in Tables 2 and 3, as well as the\nreferenced figures, we analyzed the performance of\nthe models for 7 and 10 timesteps. The findings re-\nveal that the Leaky architecture is the only model\nthat performs better with 7 timesteps. In contrast,\nall other models achieve superior performance and\nlower error rates with 10 timesteps, highlighting the\nimportance of selecting an optimal timestep config-\nuration for each model to balance computational ef-\nficiency and predictive accuracy.\nAt first glance, the Sustainability Index used\nto evaluate the models does not reveal a straight-"}]}