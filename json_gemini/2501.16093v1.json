{"title": "STAR: Stepwise Task Augmentation and Relation Learning for Aspect Sentiment Quad Prediction", "authors": ["Wenna Lai", "Haoran Xie", "Guandong Xu", "Qing Li"], "abstract": "Aspect-based sentiment analysis (ABSA) aims to identify four sentiment elements, including aspect term, aspect category, opinion term, and sentiment polarity. These elements construct the complete picture of sentiments. The most challenging task, aspect sentiment quad prediction (ASQP), predicts these elements simultaneously, hindered by difficulties in accurately coupling different sentiment elements. A key challenge is insufficient annotated data that limits the capability of models in semantic understanding and reasoning about quad prediction. To address this, we propose stepwise task augmentation and relation learning (STAR), a strategy inspired by human reasoning. STAR constructs auxiliary data to learn quadruple relationships incrementally by augmenting with pairwise and overall relation tasks derived from training data. By encouraging the model to infer causal relationships among sentiment elements without requiring additional annotations, STAR effectively enhances quad prediction. Extensive experiments demonstrate the proposed STAR exhibits superior performance on four benchmark datasets.", "sections": [{"title": "Introduction", "content": "Aspect-based sentiment analysis (ABSA) has emerged as a prominent research area in natural language processing, focusing on the fine-grained analysis of sentiment at the aspect level. Over the past decade, ABSA has garnered significant attention due to its potential applications in areas such as opinion mining and customer feedback analysis [1], [2], [3]. The core of ABSA research revolves around identifying four key sentiment elements: aspect term, aspect category, opinion term, and sentiment polarity [4]. For instance, in the sentence \"The pizza is delicious\", the sentiment polarity is \"positive\" towards the aspect category \"food quality\u201d, according to the opinion term \"delicious\" describing the aspect term \"pizza\". The aspect sentiment quad prediction (ASQP) task involves predicting these elements simultaneously in a structured quadruple form, such as (food, food quality, delicious, positive). This task is inherently challenging, as it requires not only the accurate identification of each sentiment element but also an understanding of the relationships among them.\nRecent research has highlighted that the performance of existing ASQP methods is often limited due to two primary challenges: insufficient annotated data [5], [6] and constrained adaptation capacity to unseen targets [7]. To address these challenges, existing studies have explored data augmentation techniques. Given the demonstrated adaptability of generative methods with pre-trained language models, many studies have approached ASQP as a generation task, solving it in an end-to-end manner. For instance, Zhang et al. [4] proposed the PARAPHRASE approach, which transforms quadruples into natural language using a single template, predicting the quadruple as a target sequence generation. However, the scarcity of labeled data remains a significant hurdle, prompting further innovations in data augmentation. Gou et al. [5] investigated multi-view prompting (MVP) to augment training data by considering diverse element orders. To further enhance the effectiveness of data augmentation, Zhang et al. [6] developed a pseudo-label scorer trained on self-constructed comparison datasets to aid"}, {"title": "Contributions", "content": "1) We introduce STAR, a stepwise task augmentation and relation learning framework for ASQP tasks, inspired by human reasoning through a divide-and-conquer strategy.\n2) We augment the relation tasks and auxiliary data by compositing element markers progressively with a balanced contribution loss to capture higher-order relationships without requiring extensive human annotation.\n3) Experiments conducted on four benchmark datasets demonstrate the effectiveness of our framework in learning relationships among sentiment elements and improving quad prediction performance."}, {"title": "Related Work", "content": "ASQP is considered the most challenging task in ABSA, as it aims to accurately predict four sentiment elements simultaneously [1]. Earlier approaches attempted to address ASQP using a pipeline method, where preceding sentiment elements were extracted separately and then classified for sentiment polarities [9]. However, this approach failed to deliver satisfactory performance. With the advent of pre-trained language models, which have shown significant potential in natural language understanding and generation, the predominant research has shifted towards using generative methods for ASQP [4], [5], [6], [7].\nFor example, Zhang et al. [4] reformulated quad prediction as a natural language generation task by mapping the elements into a single sentence. While this approach enhances semantic representation learning, it is constrained by the limited availability of annotated data. Gou et al. [5] introduced data augmentation through element-order-based templates, achieving notable performance improvements. However, this method may not effectively capture the relationships among sentiment elements through mere order permutations. Another study [7] proposed a more balanced dataset and considered all existing templates by employing soft-prompting to jointly learn the most relevant templates. This approach requires significant human effort and is unsustainable for domain adaptation by relying on data sources. Even large language models (LLMs), trained on vast amounts of data, show limited performance in handling structured prediction tasks [10]. To address these challenges, we emphasize the importance of reasoning ability to study and infer sentiment relationships step-by-step through a divide-and-conquer strategy. Our approach augments stepwise data without additional data sources and conducts relation learning through multi-tasking with balanced contribution loss, ensuring the significance of each step during training."}, {"title": "Methodology", "content": "Figure 1 illustrates the proposed STAR framework compared to PARAPHRASE [4] and MVP [5] methods. The PARAPHRASE approach maintains a fixed order of elements, transforming quadruples into semantic expressions using a single template. In contrast, the MVP method explores various element orders to facilitate model learning from multiple perspectives. Our framework underscores the importance of learning relationships among sentiment elements. This involves not only considering different element orders but also incorporating higher-order relationships. We achieve this by progressively augmenting pairwise and overall relational targets through a divide-and-conquer strategy. Further details are provided in the subsequent sections."}, {"title": "Task formulation", "content": "Our focus is on the ASQP task, which aims to predict four sentiment elements: aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Given an input sentence x, the objective is to accurately predict all quads $Q = \\{(a, c, o, s)\\}$. Following the methodology outlined in [4], we map sentiment elements into semantic expressions. For instance, the sentiment polarity \"positive\u201d is expressed as \"great\" in the target sequence, while the \"NULL\" label is represented as \"it\". Consequently, the prediction target becomes $Q = \\{(m_a, m_c, m_o, m_s)\\}$, where m denotes the mapping function. During inference, the target $(m_a, m_c, m_o, m_s)$ is converted back to the original elements a, c, o, s for performance evaluation."}, {"title": "Stepwise Task Augmentation", "content": "Quad Prediction. The primary objective is to predict all quads correctly given an input sentence. To enrich the annotated data from the perspective of element orders, we follow the MVP [5] method to control different prediction orders by adjusting the positions of element markers in the prompts. Specifically, we assign distinct markers to each sentiment element: [A], [C], [O], [S] for $m_a$, $m_c$, $m_o$, $m_s$, respectively. These markers serve as tags indicating the prediction order, which are appended to the input sentence. Each sentiment element is then concatenated with its corresponding marker to form the prediction target. We use the task prefix \"Quad Prection\" to differentiate with other auxiliary data. to distinguish this task from other auxiliary data. For example, given an input sentence x, the input and"}, {"title": "Pairwise Relation", "content": "To progressively achieve comprehensive relation learning, we introduce pairwise relation targets by combining different element markers with causal relationships. We use the task prefix \"Pairwise Relation\" in this phrase to predict the target sequence in natural language expression. Considering human expression habits and causal order, there are 4 combination orders for pairwise relations: [AO], [CS], [AS], [CO]. We further develop higher-order pairwise relationships by composing different pairwise orders (e.g., [AO][CS], [CS][AO]) and augmenting them with permutations, resulting in 12 candidates. The input and output for higher-order pairwise relations are structured as follows:"}, {"title": "Overall Relation", "content": "While the PARAPHRASE method rewrites quadruples in natural language expressions with a fixed order, it represents the causal relationships among different sentiment elements. We revisit it as an overall relation, serving as the final relation learning target. This approach encourages the model to capture semantic meanings and analytical modes in a divide-and-conquer manner, supported by the preceding tasks. The input and output forms for overall relation are as follows:"}, {"title": "Relation Learning", "content": "Training. In the training phase, we conduct multi-task learning for relation learning. We select top-k orders for quad prediction using corresponding order templates. However, the augmented pairwise and overall relation targets have varying numbers of instances, which may lead to imbalanced loss learning during training. To address this, we first examine the impact of instance numbers by comparing results from using all permutations in pairwise relations with results from maintaining a top k instance count equal to that in the quad prediction phase. This is achieved by pairwise permutation sampling (PPS), where we randomly select the top k * 4 higher-order permutations with 4 lower-order pairwise targets. Given that the overall relation task consists of only one instance, we introduce a balanced contribution loss (BCL) to emphasize the significant contribution of each step:\n$L= - \\frac{1}{K} \\sum_{i=1}^{K} log p(y | x_{quad}) - \\frac{1}{M} \\sum_{i=1}^{M} log p(y | x_{pairwise}) - \\frac{1}{N} log p(y | x_{overall})$ (2)\nwhere K, N, M represent the instance counts for the quad prediction, pairwise relation, and overall relation tasks, respectively. We minimize this loss function instead of simply summing all instance losses equally.\nInference. During inference, we employ schema-based constrained decoding, as illustrated in Table 1, to ensure that the generated targets are valid within the predefined vocabulary set. To evaluate quad prediction performance, we derive inference results using the top-k selected prediction order templates $T_p$ and aggregate the results $P$ through majority voting, which also fulfills the requirement that votes is greater than a defined threshold $\\tau$:\n$P = \\{q \\mid q \\in \\bigcup_{i=1}^{k} T_{p_i} \\text{and} \\ vote(q) > \\tau\\}$ (3)"}, {"title": "Experiments", "content": "Datasets and Metrics. We evaluate our approach using four publicly available ASQP datasets. These datasets are derived from the SemEval Challenges [11], [12] and the Amazon platform. [4] completed REST15 and REST16 in the restaurant domain for ASQP tasks. [9] proposed RESTAURANT and LAPTOP datasets for aspect-category-opinion-sentiment (ACOS) quadruple extraction, which contains a greater number of implicit aspects and opinions in expressions. Table 2 presents detailed statistics of these datasets. In the evaluation process, a predicted sentiment tuple is deemed correct only if all its elements match exactly with those of the gold standard tuple. we use precision (Pre), recall (Rec), and F1 score as evaluation metrics. The reported results in Table 3 are averaged over five runs using different random seeds.\nImplementation Details. We utilize the T5-base model [13] in encoder-decoder architecture from the Huggingface Transformers library \u00b9 as our primary pre-trained model to compare with baseline methods. Additionally, we evaluate the T5-Large model to examine the model size effect. During training, we set the number of epochs to 20, with a batch size of 64 and a learning rate of 1e 4, using AdamW as the optimizer. The voting threshold $\\tau$ is set to k/2 during inference. Consistent hyperparameters are applied across all tasks and datasets. For the top-k order in the quad prediction phase, we use k = 15 for all tasks and datasets in the main results. In the default setting, all samples from the augmented pairwise and overall relations are utilized for training.\nBaselines. We compare our methods against several state-of-the-art approaches. The EXTRACT-CLASSIFY method [9] employs a pipeline of extraction followed by classification. Other leading methods address the ASQP task using generative approaches: GAS [14] was the first to model the ABSA task as a text generation problem. PARAPHRASE [4] transforms structured quads into natural language sequences. SEQ2PATH [15] generates tuples as paths of a tree. DLO/ILO [16] identifies the most suitable element orders and combines multiple templates for data augmentation. GENDA [17] generates augmented parallel data for enhancement. CHATGPT (few-shot) [18] evaluates the few-shot capabilities of CHATGPT using specified templates. MUL [16] controls token-level generation by considering model uncertainties. In addition to these, LEGO-ABSA [19] employs unified prompt-based methods for multi-task learning, while MVP [5] augments with element order templates and conducts multi-task learning. For the T5-large model evaluation, we also compare with the Scorer & RERANK (AI) [6] method, which trains a pseudo-label scorer using an additional comparison dataset for prediction label selection."}, {"title": "Experimental Results", "content": "Main Results. The main results compared with baseline methods are presented in Table 3. The STAR framework consistently outperforms all baselines across four datasets and all evaluation metrics, highlighting its effectiveness in learning relationships among sentiment elements. With the balanced contribution loss (BCL), STAR can fully leverage the augmented data and enhance relation learning even with a base-size model. It is important to note that while LEGO-ABSA [19] and MVP [5] employ multi-task learning to enhance performance, with MVP further augmenting this approach through element-order-based templates, these methods primarily focus on task similarity and are trained in parallel with other subtasks in ABSA, such as triplet prediction or pair extraction. In contrast, our approach emphasizes relational learning by constructing auxiliary tasks that focus on stepwise relationships through a divide-and-conquer strategy.\nAblation Study. We also present the ablation study in the main results, as shown in Table 3. STAR achieves state-of-the-art results supported by stepwise task augmentation and BCL, which ensures equal contribution from instances of each step task. Since we use k = 15 orders in quad prediction, the pairwise permutation sampling (PPS) shows little difference compared to the default setting utilizing all pairwise permutations. However, PPS still contributes to a slight enhancement by maintaining the balance of instance count, as shown in the ASQP-REST16 and ACOS-REST datasets.\nEven without BCL, PPS can improve performance in most cases. However, there is a noticeable performance drop across all datasets and evaluation metrics when without BCL. This indicates that while PPS can help alleviate issues caused by imbalanced instances, BCL effectively handles both balanced and imbalanced scenarios.\nModel Size Effect. We evaluate the T5-large model across four datasets to study the effect of model size on relation learning. As shown in Table 4, both GAS + Scorer & RERANK (AI) and MUL + Scorer & RERANK (AI), proposed by ZHANG et al. [6], trained a pseudo-label scorer using the self-curated comparison datasets with human or Al assistance and applied the scorer to generative methods. However, GAS [14] and MUL [16] are independent generative methods trained using the T5-base model. In particular, MUL employed uncertainty-aware unlikelihood learning to control generation, resulting in greater improvements across four datasets when combined with the scorer. In comparison, our method only fine-tunes a single model without additional annotation data sources or human assistance. STAR demonstrates superior performance in most cases. Since T5-large exhibits a stronger capacity to handle stepwise tasks and different targets compared to T5-base, it achieves second-best or even best results in ASQP-REST15 and ACOS-REST without BCL.\nTop-K Orders. To explore the selection of top-k orders and the effect of instance count across different tasks, we compare k = 10 with k = 15. It can be seen in Figure 2 that with the assistance of BCL, performance increases the number of orders (K) increases. In contrast, in ASQP-REST16 and ACOS-"}, {"title": "Discussion", "content": "We propose a stepwise task augmentation and relation learning framework, STAR, for ASQP tasks. STAR employs stepwise element markers to manage pairwise and higher-order relationships for effective relation learning. With larger model sizes, STAR demonstrates enhanced performance in capturing quad relationships and accurately predicting quadruples. However, our approach uses constrained decoding to control the generation vocabulary set, which may limit its performance when transferring to entirely unrelated domains. Exploring alternative decoding strategies, such as beam search with dynamic vocabulary adaptation or contrastive decoding, could be promising for application in more general scenarios.\nAdditionally, we adopt a divide-and-conquer strategy to learn the overall relationships among sentiment elements, using a balanced contribution loss to regulate the stepwise contributions. This approach could be further enhanced by introducing a consistency loss to ensure the model learns consistently across different tasks. Given its unique capability to derive pairwise and overall relationships from quad prediction tasks that predict all elements simultaneously, the introduction of consistency loss may improve the alignment between intermediate predictions and the final quadruple output, ensuring that the model maintains coherence across tasks and generalizes better to unseen data."}, {"title": "Conclusion", "content": "We address complex ASQP tasks by implementing stepwise task augmentation and relation learning (STAR), utilizing a divide-and-conquer strategy. Unlike existing methods that rely on additional annotated data to mitigate data scarcity, our approach emphasizes the importance of reasoning about relationships among sentiment elements. We construct auxiliary data that indicate higher-order relationships by systematically composing element markers within prompts and target sequences, eliminating the need for additional data sources or human annotation costs. This method effectively compels the model to capture stepwise relationships, ultimately facilitating comprehensive relation learning for more accurate quadruple predictions. Furthermore, we introduce a balanced contribution loss and permutation sampling technique to better manage the imbalance of instances at each step. Extensive experiments conducted on four public datasets demonstrate that STAR significantly enhances quad prediction and achieves competitive performance, surpassing baseline methods. Future work could also explore adaptive weighting mechanisms for the consistency loss to dynamically balance its influence during training, further enhancing the model's robustness and adaptability."}]}