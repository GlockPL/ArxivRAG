{"title": "User Intent to Use DeekSeep for Healthcare\nPurposes and their Trust in the Large\nLanguage Model: Multinational Survey Study", "authors": ["Avishek Choudhury", "Yeganeh Shahsavar", "Hamid Shamszare"], "abstract": "Large language models (LLMs) increasingly\nserve as interactive healthcare resources, yet user\nacceptance remains underexplored. This study examines\nhow ease of use, perceived usefulness, trust, and risk\nperception interact to shape intentions to adopt DeepSeek,\nan emerging LLM-based platform, for healthcare purposes. A\ncross-sectional survey of 556 participants from India, the\nUnited Kingdom, and the United States was conducted to\nmeasure perceptions and usage patterns. Structural\nequation modeling assessed both direct and indirect effects,\nincluding potential quadratic relationships. Results revealed\nthat trust plays a pivotal mediating role: ease of use exerts a\nsignificant indirect effect on usage intentions through trust,\nwhile perceived usefulness contributes to both trust\ndevelopment and direct adoption. By contrast, risk\nperception negatively affects usage intent, emphasizing the\nimportance of robust data governance and transparency.\nNotably, significant non-linear paths were observed for ease\nof use and risk, indicating threshold or plateau effects. The\nmeasurement model demonstrated strong reliability and\nvalidity, supported by high composite reliabilities, average\nvariance extracted, and discriminant validity measures.\nThese findings extend technology acceptance and health\ninformatics research by illuminating the multifaceted nature\nof user adoption in sensitive domains. Stakeholders should\ninvest in trust-building strategies, user-centric design, and\nrisk mitigation measures to encourage sustained and safe\nuptake of LLMs in healthcare. Future work can employ\nlongitudinal designs or examine culture-specific variables to\nfurther clarify how user perceptions evolve over time and\nacross different regulatory environments. Such insights are\ncritical for harnessing Al to enhance outcomes.", "sections": [{"title": "I. INTRODUCTION", "content": "DeepSeek, an open-source large language model (LLM)\ndeveloped in 2023, has gained attention for its cost-\neffectiveness and comparable performance to GPT-4. In\nJanuary 2025, it released a free chatbot application based on\nDeepSeek-R1, which quickly surpassed ChatGPT as the\nmost-downloaded free app on the U.S. iOS App Store. Its\nrapid rise and potential to outperform other LLMs can\ninfluence public perception and trust. Users may experience\na halo effect, assuming DeepSeek's competence in all\ndomains due to its coherent and contextually relevant\nanswers. This over-reliance can lead to the abandonment of\njudgment and cross-checking processes when an AI system\nseems superior [1]. The fluid and human-like nature of\nDeepSeek's responses further reinforces the illusion of\ngenuine understanding, blurring the lines between machine\noutput and expert advice. Consequently, users may\nimplicitly trust DeepSeek's answers, even in critical areas\nlike healthcare, without considering potential errors or\nbiases [2, 3].\nAccording to the media equation theory, suggests that\npeople often treat mediated interactions (including those\nwith computers and other digital systems) similarly to real-\nlife interpersonal encounters. According to this view, users\nmight ascribe social qualities to Al systems, causing them to\nbehave as though they are conversing with a trustworthy\nindividual rather than a machine [4]. This tendency is further\namplified by an LLM's (like DeepSeek) ability to produce\nfluid, contextually aware dialogue, leading users to feel\ncomfortable disclosing personal details as they would with\na trusted confidant. Its widespread availability in user-\nfriendly formats, like smartphone apps, lowers friction and\nleads to uncritical acceptance of outputs, increasing privacy\nrisks [5]. Corporate servers store and analyze every query\nand response, potentially creating a vast repository of\npersonal information. While anonymization measures exist,\ndata breaches and unauthorized re-identification remain\nconcerns, especially without transparent data governance [6,\n7].\nThe AI arms race further complicates data security.\nDeepSeek must navigate evolving privacy legislation across\nmultiple jurisdictions. Malicious entities may exploit LLMs'\nauthority by designing targeted phishing attacks disguised as\nofficial DeepSeek responses. The social credibility of\nDeepSeek makes it an ideal vehicle for sophisticated fraud\nif safeguards are lacking [8]. Even without malicious intent,\ntechnical limitations like hallucinations can confuse users\nand propagate misinformation if the system is trusted\nunconditionally [9, 10].\nDeepSeek's or comparable LLM's potential for biased\noutputs highlights another concern [11]. Despite cost-\neffective training on extensive corpora, LLMs reflect biases\nin their training data. Users may accept DeepSeek's\nstatements as objective truths, leading to unchallenged\ncultural or social biases. Transparent disclosures about data\nsources, training methodologies, and error margins are\ncrucial to help users understand when DeepSeek might give\nskewed answers.\nAddressing these issues requires a multidisciplinary effort\n[12]. While DeepSeek's achievements are groundbreaking,\nsustaining public trust requires understanding how people\nperceive and intend to use this technology. Collective\nawareness and responsibility are essential to harness its\nbenefits without compromising privacy, security, or\ninformation integrity."}, {"title": "II. RESEARCH OBJECTIVE AND HYPOTHESES", "content": "The objective of this study is to examine how perceptions\nof ease of use, risk, and perceived usefulness interact with trust\nto ultimately shape users' intentions to employ DeepSeek in\nhealth-related contexts. In doing so, the research extends\nestablished technology acceptance and trust theories by\nincorporating both direct and indirect paths, as well as by\nexploring potential non-linear (quadratic) effects [13, 14].\nA key focus centers on the\nrole of ease of use a construct traditionally linked to\ntechnology acceptance. Specifically, the study posits that ease\nof use will significantly foster trust in DeepSeek and\nsimultaneously increase users' intent to adopt it for health\npurposes. This expectation aligns with the view that a user-\nfriendly interface reduces cognitive strain, thereby instilling an\nimpression of competence and reliability [15]. Moreover,\nstraightforward navigation of an Al system in a clinical or\npersonal health setting can lower barriers to initial adoption,\nprompting individuals to incorporate the technology more\nreadily into their decision-making. At the same time, our study\nacknowledges the possibility of non-linear relationships [16].\nThat is, once perceived ease of use surpasses a certain threshold,\nfurther enhancements may yield diminishing effects on trust or\nusage intent hence the inclusion of quadratic testing.\nAnother central component is trust, which is widely\nrecognized as a pivotal determinant of individuals' willingness\nto delegate sensitive tasks to Al systems [17]. Here, trust is\nposited to positively influence intent to use DeepSeek,\nreflecting the premise that users must believe in the system's\ncredibility and accuracy before relying on its outputs for\npersonally significant choices, such as interpreting medical\ndocuments. In parallel, the model predicts that perceived\nusefulness-the degree to which users believe DeepSeek\neffectively aids in accomplishing tasks will both feed into\ntrust and directly motivate the decision to adopt [18]. If\nDeepSeek demonstrably improves efficiency, offers relevant\ninformation, or yields better outcomes, individuals are more\nlikely to view the technology not only as beneficial but also as\ndeserving of confidence, thus reinforcing their intention to use.\nIn contrast, risk perception is anticipated to exert a negative\nimpact on intent to use [17]. Particularly in health-related\nscenarios, concerns over data privacy, the possibility of\nincorrect diagnoses, or broader ethical dilemmas can act as\ninhibitors to adoption. Users who sense a high level of risk may\nhesitate to rely on an Al system, even if they recognize certain\nadvantages [19]. The non-linear aspect of this path allows for\nthe possibility that moderate levels of risk perception might\nexert disproportionately strong effects-potentially deterring\nadoption more acutely than either very low or very high-risk\nperceptions.\nAdditionally, the framework addresses mediation\npathways, where trust operates as an intermediary in two\ndistinct relationships. First, the study investigates whether trust\nmediates the link between ease of use and intent to use, positing\nthat user-friendly design can bolster trust, thereby reinforcing\nthe inclination to adopt DeepSeek. Second, perceived\nusefulness is hypothesized to enhance trust, which in turn\nincreases intent to use, reflecting the theory that tangible\nbenefits establish an underlying belief in the system's\nreliability. Both mediating paths also incorporate the possibility\nthat their effects may plateau or intensify under certain\nconditions-further underscoring the need to examine\nquadratic relationships. We explore the following eight\nhypotheses (H):\n\u2022\nH1: Ease of Use positively influences Trust in DeepSeek.\n\u2022\nH2: Ease of Use positively influences Intent to Use\nDeepSeek for Health-Related Purposes.\n\u2022\nH3: Trust in DeepSeek positively influences Intent to Use\nDeepSeek for Health-Related Purposes.\n\u2022\nH4: Risk Perception negatively influences Intent to Use\nDeepSeek for Health-Related Purposes.\n\u2022\nH5: Perceived Usefulness positively influences Trust in\nDeepSeek.\n\u2022\nH6: Perceived Usefulness positively influences Intent to\nUse DeepSeek for Health-Related Purposes.\n\u2022\nH7: Trust in DeepSeek mediates the relationship between\nEase of Use and Intent to Use DeepSeek.\n\u2022\nH8: Trust in DeepSeek mediates the relationship between\nPerceived Usefulness and Intent to Use DeepSeek."}, {"title": "III. METHODS", "content": "The study, bearing the Institutional Review Board protocol\nnumber 2302725983 and classified as a flex protocol type,\nreceived approval from West Virginia University."}, {"title": "A. Survey Instrument", "content": "The survey items were adapted from established\nmeasurement scales commonly used in technology acceptance\nand human-computer interaction research [20-22]. A\npreliminary literature review identified key constructs (e.g.,\nease of use, trust, risk perception, perceived usefulness, and\nusage intentions) pertinent to AI-driven applications,\nparticularly in the healthcare domain [17, 23]. Existing,\nvalidated items were then modified linguistically to reflect\nDeepSeek's functionality. For instance, several questions\nincluded references to reliability and accuracy, adapted from\ntrust in automation scales, while risk perception measures were\nframed to address data privacy and potential adverse outcomes\nin health-related tasks [24-26].\nThe resultant questionnaire comprised 12 primary items,\neach measured on a four-point forced Likert scale. Questions were grouped to form latent construct and validated.\nThe instrument also had questions about participant\ndemographics. Additionally, the survey incorporated a\nchecking question to verify that respondents thoroughly read all\nquestions before providing their answers, further ensuring data\nquality."}, {"title": "B. Pilot Testing and Sampling", "content": "Before launching the main data collection, the survey was\npilot tested with a small convenience sample (n = 20) who met\nthe criterion of having used DeepSeek at least once in the\nprevious two weeks. Pilot participants were asked to provide\nopen-ended feedback on item clarity, redundancy, and overall\nlength. Minor revisions were made, including refining the\nwording of risk-related items and adjusting the Likert anchors\nfor consistency.\nFollowing pilot testing, an online version of the final\nquestionnaire was administered via a paid audience paneling\nservice. The survey was distributed to India, United Kingdom\n(UK), and United States of America (USA). Participant\nrecruitment targeted adult users (18 years or older) who\nreported having used DeepSeek at least once in the preceding\ntwo weeks. Exclusion criteria included individuals with no prior\nexposure to DeepSeek, as the survey required firsthand\nexperience to accurately assess perceptions of trust, usability,\nand risk. The questionnaire's introduction reiterated the\nvoluntary nature of participation, guaranteed anonymity, and\nprovided contact details for the principal investigator."}, {"title": "C. Data Collection Procedure", "content": "Data collection took place over a two-week period. Each\nparticipant received an individualized survey link, which led to\na landing page containing an informed consent statement. After\nconsenting, participants proceeded to the main survey. The\nsurvey platform automatically recorded session details,\nincluding session ID, IP address (to prevent deduplication\nonly). All identifying information was removed prior to data\nanalysis. Participants could terminate the survey at any point\nwithout penalty."}, {"title": "D. Statistical Analyses", "content": "First, descriptive statistics were calculated for all survey\nquestions to provide an overview of the responses' central\ntendency, dispersion, and distribution. These statistics offered\ninitial insights into the participants' attitudes and perceptions\nregarding the constructs under investigation. Following the\ndescriptive analysis, the research team employed Partial Least\nSquared Structural Equation Modeling (PLS SEM) to examine\nthe relationships between the latent constructs. PLS-SEM is a\nmultivariate technique that allows estimation of complex cause-\neffect relationships between latent constructs and their\nindicators [27]. This method was chosen for its ability to handle\nsmall to medium-sized samples and suitability for exploratory\nresearch [28].\nThe PLS-SEM analysis in our study was conducted in two\nstages: the assessment of the measurement model and the\nevaluation of the structural model. We assessed the\nmeasurement model for reliability and validity by focusing on\nfour aspects: indicator reliability, internal consistency\nreliability, convergent validity, and discriminant validity.\nIndicator reliability was examined by analyzing the factor\nloadings of each indicator, with loadings greater than 0.5\nconsidered satisfactory. We evaluated internal consistency\nreliability using composite reliability (rhoC) [29]. Convergent\nvalidity was assessed by examining the average variance\nextracted (AVE), and values above 0.5 indicated an adequate\nconvergent validity [29, 30]. In addition to these assessments,\nwe also evaluated the reliability of the constructs in our research\nmodel using the average inter-item correlation (rho_c). A value\nof 0.7 or higher for rhoC is generally considered to indicate\nsatisfactory reliability.\nAfter confirming the measurement model's adequacy, we\nevaluated the structural model to test our hypotheses. We\nperformed a bootstrap resampling procedure with 10,000\niterations to obtain the parameter estimates and compute\nconfidence intervals."}, {"title": "E. Sample Size Justification", "content": "Structural equation modeling commonly benefits from\nrelatively large sample sizes to ensure robust parameter\nestimation and adequate statistical power. Guidelines in the\nSEM literature vary, but several rules of thumb have been\nproposed where some recommends a minimum of 200\nparticipants for most SEM applications, while others suggest\nhaving at least five to ten respondents per estimated parameter\nin the model [31-33].\nIn our study, the final instrument contained 12 key items\nspanning multiple latent constructs (e.g., ease of use, trust, risk\nperception, perceived usefulness, and intent to use).\nConsequently, typical rules of thumb would indicate a desired\nsample size in the range of 300-500 participants to comfortably\nmeet assumptions of stable parameter estimation."}, {"title": "III. RESULTS", "content": "A total of 556 complete responses were collected.\nGeographically, 184 individuals were based in India, 185 in the\nUK, and 187 in the United States, reflecting an almost even split\nacross these three locales. Of the 556 participants in this study,\n33% used it \"once a month,\" 28% used it \"once a week,\" 25%\nused it \"more than once per week,\" and 14% used it \"almost\nevery day.\" Regarding education, most respondents (38%) held\na bachelor's degree, followed by master's degree holders\n(28%), high school graduates (26%), those with some high\nschool (4%), and doctoral-level degrees (4%). The sex\ndistribution was nearly balanced, with 49% identifying as male\nand 51% as female. In terms of age, the largest proportion of\nrespondents fell in the 26-35-year range (25%), while 14%\nwere aged 18-25, 19% were 36-45, another 19% were 46\u201355,\n15% were 56\u201365, and 7% were 66 or older."}, {"title": "A. Measurement Model and Survey Validation", "content": "indicate a robust measurement model with strong\nevidence of convergent and discriminant validity across all\nlatent constructs. Convergent validity is supported by high AVE\nvalues: each construct exceeds the commonly accepted 0.50\nthreshold (ranging from 0.650 to 0.820), indicating that the\nitems explain a substantial portion of their respective\nconstructs. Likewise, rho_c and Cronbach's alpha values are\nmostly well above the 0.70 benchmark confirming internal\nconsistency among indicators.\nDiscriminant validity is supported by the Heterotrait-\nMonotrait (HTMT) ratios, nearly all of which fall below the\ncritical value of 0.90 or 1.00. In addition, the R2 values of 0.532\n(adjusted 0.525) for Intent to Use DeepSeek for Health\nPurposes and 0.592 (adjusted 0.589) for Trust in DeepSeek\nindicate that the explanatory power of the proposed paths is\nmoderate to strong. The significant T-statistics and p-values\nacross the key relationships further verify that the\nconceptualized constructs have been measured accurately, with\nonly a few non-significant quadratic paths. These findings\nvalidate the measurement instrument and confirm that the\ntheorized latent variables-Ease of Using DeepSeek, Perceived\nUsefulness, Trust in DeepSeek, Risk Perception, and Intent to\nUse DeepSeek for Health Purposes exhibit sufficient\nreliability and validity to warrant confidence in subsequent\nstructural analyses.\nIn addition to the overall validity of the measurement model,\nthe findings also support the validity of the individual survey\nquestions that served as indicators for each latent construct.\nFirst, the high factor loadings (as implied by the satisfactory\nAVE values) suggest that each item meaningfully contributes\nto measuring its intended factor-i.e., users' responses to\nquestions about ease of use, trust, perceived usefulness, risk, or\nintent to use strongly correlate with the respective latent\nconstructs they were designed to represent. Second, the internal\nconsistency indices (Cronbach's alpha and composite\nreliability) confirm that groups of questions intended to\nmeasure the same construct hang together well, indicating the\nsurvey items reliably capture the same underlying concept.\nFinally, the discriminant validity checks (heterotrait monotrait\nratios) confirm that sets of questions targeting one construct do\nnot overlap excessively with those measuring other constructs;\nthis indicates that the items' wording and content domains\neffectively capture distinct dimensions of user perceptions\ntoward DeepSeek. Taken together, these indicators demonstrate\nthat the survey questions and not just the overarching\nconstructs exhibit satisfactory validity."}, {"title": "B. Structural Equation Model (Direct, Indirect, and Total\nEffects)", "content": "As shown , the path coefficients and mediation\nanalyses provide strong evidence for most of the hypothesized\nrelationships, though one notable exception emerged regarding\nrisk perception.\nEase of Use (H1) exhibits a significantly positive direct effect\non Trust in DeepSeek, indicating that when users perceive\nDeepSeek to be more intuitive and less effortful to operate, their\ntrust in the system increases correspondingly.\nHowever, the direct relationship from Ease of Use to Intent\nto Use DeepSeek for health-related purposes (H2) is not\nstatistically significant. Despite this, a significant total effect\nand a strong indirect path through Trust confirm that trust fully\nmediates the impact of ease of use on user intentions. Hence,\nwhile there is no direct link from ease of use to intent, ease of\nuse indirectly drives intent via trust, satisfying H2's broader\npremise when mediation is considered."}, {"title": "B. Structural Equation Model (Quadratic Effects)", "content": "The model also explored potential quadratic (QE) non-linear\nrelationships among the key constructs. The results indicate that\nthe quadratic effect of Ease of Use on Intent to Use DeepSeek\nfor Health Purposes is significant ($\\beta$ = 0.072, p = 0.011),\nsuggesting that beyond a certain point, the influence of ease of\nuse on user intentions may intensify or plateau rather than\nprogressing linearly. In contrast, the quadratic term of Ease of\nUse on Trust in DeepSeek was not significant ($\\beta$= 0.038, p =\n0.102), indicating that trust levels respond to ease of use in a\nlinear fashion.\nThe quadratic effect of Risk Perception on Intent to Use\nDeepSeek for Health Purposes emerged as significant ($\\beta$ = -\n0.119, p = 0.002), implying that moderate risk perceptions\nmight not affect adoption the same way extremely low or very\nhigh-risk perceptions do\u2014potentially reflecting a threshold.\nPerceived Usefulness exhibited a negative but significant\nquadratic relationship with Intent to Use ($\\beta$ = \u22120.074, p =\n0.045), suggesting that at very high levels of perceived\nusefulness, additional increases might yield diminishing or\neven marginally negative returns on user intentions. By\ncontrast, no significant quadratic effect of Perceived Usefulness\nwas detected on Trust in DeepSeek ($\\beta$ = 0.022, p = 0.439),\nindicating that trust is likely more directly related to usefulness\nwithout an apparent non-linear inflection point.\nCollectively, these results demonstrate that while ease of use,\nrisk perception, and perceived usefulness can shape user\nintentions in curvilinear ways, not all relationships in the model\nexhibit non-linear patterns. For constructs like trust, effects\nappear to follow a more straightforward linear trajectory. These\nfindings underscore the importance of accounting for potential\nthreshold or plateau effects in user adoption research,\nparticularly in health-oriented applications where attitudes and\nbehaviors can shift dramatically once certain levels of risk or\nperceived benefits are reached. summarizes the overall\nfindings."}, {"title": "IV. DISCUSSION", "content": "This study makes a significant contribution to the field of\ninformatics by systematically examining user interactions with\nDeepSeek, a novel Al platform, through the lens of data\ngovernance, privacy, and security. The structured measurement\nmodel employed in this study provides valuable insights into\nhow users perceive and respond to DeepSeek's capabilities. By\ncapturing and analyzing users' perceptions of risk, trust, and\nease of use, the study addresses critical informatics issues such\nas clinical decision support and system design. In addition to its\nfocus on informatics, this work adopts a human factors and\ntechnology acceptance perspective. While previous research\nhas explored these constructs in the context of other large\nlanguage models (e.g., ChatGPT), this study is among the first\nto empirically validate a comprehensive measurement model\nspecifically tailored for DeepSeek. This model integrates both\ndirect and non-linear effects, demonstrating that user\nperceptions of system utility and trustworthiness are paramount\nin health-oriented AI contexts. The interplay between ease of\nuse, perceived usefulness, trust, and risk perception provides a\ncomprehensive framework for understanding user intentions to\nadopt DeepSeek. This highlights the importance of developers\nprioritizing these factors to enhance user acceptance.\nThe most notable contribution of this study lies in its\ncomprehensive examination of how ease of use, perceived\nusefulness, trust, and risk perception influence users' intentions\nto adopt DeepSeek for health-related purposes. By drawing on\na large sample of 556 participants-fairly evenly distributed\nacross India, the UK, and the United States this research\ndemonstrates that trust is a primary determinant of users'\nadoption intentions, mediating the relationships from both ease\nof use and perceived usefulness to intent. This aligns with\nexisting literature that emphasizes the critical role of trust in the\nacceptance of AI technologies in healthcare settings. For\ninstance, a highlights that lack of trust in Al systems is a\nsignificant barrier to their adoption in medical care, indicating\nthat enhancing user confidence is essential for successful\nimplementation [34].\nWhile ease of use does not directly predict intent to use (H2),\nit indirectly exerts a strong effect via trust (H7)-highlighting\nthat enhancing usability alone is insufficient unless it also\nfosters greater confidence in the system. This notion is echoed\nin the work of Schnall et al., who argue that both perceived\nusefulness and ease of use are critical for the successful\nadoption of mobile health technologies [35].\nFurthermore, perceived usefulness drives both trust and\nintent, highlighting the central role of benefit-driven\nevaluations in motivating user behavior (H5, H6, H8). These\nresults extend existing technology acceptance theories by\nshowing that user perceptions of system utility and\ntrustworthiness take precedence in health-oriented AI contexts.\nIt also aligns with the findings reported in a meta-analysis\ndemonstrating that perceived benefits significantly influence\nhealth-related behaviors [36]. In the context of AI in healthcare,\na study found that stakeholders prioritize the utility of AI tools,\nwhich supports our assertion regarding the importance of\nperceived usefulness in driving adoption intentions [37].\nAdditionally, the negative direct relationship from risk\nperception to intent to use (H4) supports longstanding\nexpectations that higher apprehension can discourage adoption.\nIn line with our findings a study acknowledged risk perception\nas a key predictor of preventive behavioral intentions among\nhealthcare workers, reinforcing the notion that risk perceptions\nplay a crucial role in shaping user intentions [38]. However, our\nfindings also suggest that this relationship may manifest non-\nlinearly under certain conditions, which is a nuanced\nperspective that warrants further exploration in future research.\nAlthough most hypothesized paths proved significant, ease\nof use did not directly correlate with intent to use (H2),\nhighlighting that simpler interfaces alone might not\nautomatically drive adoption for sensitive applications like\nhealth inquiries. Furthermore, the quadratic terms for several\nrelationships were non-significant, suggesting a primarily\nlinear dynamic between these constructs. Such null findings can\nbe instructive: they indicate that, in certain relationships, user\nattitudes do not exhibit threshold or plateau effects and are\ninstead driven by more consistent incremental changes (e.g.,\neach increase in usefulness incrementally raising trust without\na significant non-linear inflection).\nPolicymakers focused on regulating AI in healthcare can\ndraw from these results by encouraging transparency initiatives\nthat bolster user trust for instance, mandating disclosures\nabout how Al systems generate medical suggestions or interpret\nuser data. For healthcare providers, the evidence that ease of\nuse indirectly shapes intent via trust means that training\nprograms and user onboarding should emphasize not only user-\nfriendly design but also trust-building strategies (e.g.,\nillustrating system accuracy, addressing privacy concerns).\nGiven that perceived usefulness directly drives adoption,\ndevelopers should prioritize demonstrating tangible benefits\n(e.g., better medical outcomes, efficient data processing) to\nfoster acceptance. Lastly, the significant quadratic effects for\nrisk perception and ease of use highlight the need to monitor\nuser attitudes for potential tipping points beyond which\nadditional enhancements in usability or risk mitigation have\ndisproportionate impacts on willingness to adopt.\nFew constraints must be acknowledged when interpreting\nthese findings. First, this cross-sectional study cannot establish\ncausal direction definitively, although the robust model fit and\ntheoretical grounding strengthen causal inferences. Second,\nalthough the sample size was large and relatively balanced\nacross three regions, the results may not generalize to other\ncultural or regulatory contexts where attitudes toward AI-driven\nhealth tools differ. Third, the study relied on self-reported\nmeasures, which may be subject to social desirability bias or\ninaccuracies in recalling frequency and manner of use. Finally,\nwhile the model covered central factors in technology\nacceptance (ease of use, usefulness, trust, risk), there may be\nother contextual variables such as domain expertise, quality\nof healthcare infrastructure, or cultural norms-that also shape\nAI adoption in health contexts. Future studies could integrate\nlongitudinal or experimental designs to verify these\nrelationships over time and examine how usage behaviors\nevolve with extended Al exposure in real clinical or personal\nhealth settings."}]}