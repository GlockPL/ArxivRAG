{"title": "SUPER-INTELLIGENCE OR SUPERSTITION? EXPLORING PSYCHOLOGICAL FACTORS UNDERLYING UNWARRANTED BELIEF IN \u0391\u0399 PREDICTIONS", "authors": ["Eunhae Lee", "Judith Amores", "Pat Pataranutaporn", "Pattie Maes"], "abstract": "This study investigates psychological factors influencing belief in AI predictions about personal behavior, comparing it to belief in astrology and personality-based predictions. Through an experiment with 238 participants, we examined how cognitive style, paranormal beliefs, AI attitudes, personality traits, and other factors affect perceived validity, reliability, usefulness, and personalization of predictions from different sources. Our findings reveal that belief in AI predictions is positively correlated with belief in predictions based on astrology and personality psychology. Notably, paranormal beliefs and positive AI attitudes significantly increased perceived validity, reliability, usefulness, and personalization of AI predictions. Conscientiousness was negatively correlated with belief in predictions across all sources, and interest in the prediction topic increased believability across predictions. Surprisingly, cognitive style did not significantly influence belief in predictions. These results highlight the \"rational superstition\" phenomenon in AI, where belief is driven more by mental heuristics and intuition than critical evaluation. We discuss implications for designing AI systems and communication strategies that foster appropriate trust and skepticism. This research contributes to our understanding of the psychology of human-AI interaction and offers insights for the design and deployment of AI systems.", "sections": [{"title": "1 Introduction", "content": "Technology is often associated with scientific advancement and frequently viewed in opposition to superstition. However, the recent rapid advancements in artificial intelligence (AI) have given rise to quasi-religious perspectives among some leaders in the tech industry [1]. In fact, as generative AI and large language models (LLMs) continue to evolve, a contemporary critique posits that the narrative surrounding their development bears striking resemblances to religious discourse [2]. Promoting concepts such as superintelligence and sentience, prominent figures in the tech industry have been observed making prophetic claims regarding AI's potential to either salvage or obliterate humanity [3, 4]. These claims are often based on personal speculation and subjective views rather than rigorous scientific research. Nonetheless, empirical research has demonstrated that these popular narratives are mirrored in public perceptions of AI, frequently manifesting as exaggerated utopian or dystopian visions [5, 6]. This intersection of technological advancement and quasi-religious perspective presents a complex landscape for scholars to navigate, as it blurs the boundaries between scientific progress and speculation."}, {"title": "Super-intelligence of Superstition?", "content": "While AI has been developed through predictive algorithms and statistical pattern recognition, exemplifying advance- ments in mathematical and rational thinking, public perception of AI may draw unexpected parallels with astrology [7, 8, 9]. Despite astrology representing an opposing epistemology based on pseudoscientific methodologies antithetical to empirical reasoning, both AI and astrology function as prediction-generating mechanisms helping people make sense of the uncertainty in the world [7, 8]. Anthropologist Christophe Lazaro suggests that AI, powered by data, has become a new mode of speculative thinking, with algorithms taking on the role of oracles in contemporary societies, framing AI as \"artificial divination\" [8, p. 128].\nOn the other hand, AI, unlike astrology, presents an aura of scientific legitimacy, backed by a vast body of scientific research in computer science, mathematics, cognitive science, and more. This foundation contributes to the belief that AI systems are rational and objective. However, studies have shown that algorithms could produce unpredictable outcomes, biased results, and inherit implicit societal biases [10, 11, 12]. Moreover, despite ongoing efforts to increase transparency, much of the inner workings of AI systems remain \"black boxes\" [13, 14, 15, 16]. Such misconceptions regarding AI may engender a form of naive technological optimism and irrational trust in the system, which Wilson refers to as \"rational superstition\" [17]. Scholars have investigated the concept of algorithmic appreciation-the propensity to rely on algorithms for decision-making processes\u2014which may lead to an overreliance on AI in critical decision-making contexts [18, 19].\nPopular narratives that over-inflate the promises of AI and its capabilities is particularly alarming when considering the impact it has on mental models and perception of AI systems [6]. According to the dual process theory in psychology, people engage in two types of thinking-fast and intuitive (System 1) and slow and reflective (System 2) [20, 21]. Incomplete or incorrect mental models shaped by speculative claims about AI rather than scientific evidence can become a mental heuristic that triggers people's System 1 thinking rather than engaging their System 2 thinking, blurring the lines between speculation and informed reasoning [22]. This, in turn, can lead to miscalibration of trust and over-reliance on AI, which drives ineffective use of AI [18, 19, 23].\nFor instance, consider an AI system that claims to give you personalized product recommendations based on your social media usage and purchase history. A user with an incorrect mental model of the system's capabilities and limitations may hastily rely on its recommendations without considering other options. On the flip side, a user who has developed an overly skeptical mental model of AI may reject helpful recommendations and miss critical opportunities. Therefore, without ongoing effort to establish appropriate mental models, users can become more prone to manipulation and potential negative outcomes.\nWhile belief in AI supremacy is growing despite its demonstrated limitations and biases, our study presents the first empirical investigation into the phenomenon of \"rational superstition\" [17] in AI. To do so, we examine how people's perception and trust in AI predictions may correlate with other irrational behaviors, such as belief in astrology. This research question is particularly timely and relevant given the recent surge in popularity of astrology, especially among Millennials and Gen Z [24, 25], despite the lack of empirical evidence supporting its validity [26, 27]. A recent consumer survey of over 2000 people in the US revealed that about a third of Millennials and a quarter of Gen Z have made financial decisions based on their horoscope [28].\nTo address this research question, we conducted an experiment involving 238 participants who were presented with fictitious predictions from three sources (AI, astrology, and personality psychology) and rated their perceived validity, reliability, usefulness, and personalization. To create a reasonable basis for the predictions, participants answered questionnaires about astrology and personality and engaged in a simulated investment game that appeared to analyze their interactions and predict their future investment behavior. Participants were randomly assigned to either positive (N = 119) or negative (N = 119) prediction groups, receiving forecasts about their future investment behavior and outcomes accordingly.\nOur study also explores how cognitive style, paranormal beliefs, gullibility, trust in AI, and personality traits may influence belief in predictions based on AI, astrology, and personality psychology. This investigation builds upon previous work examining how user characteristics such as personality traits influence the perception of AI-generated advice [29] and trust in AI [30]. Additionally, we consider the relationship between cognitive style and paranormal beliefs, including astrology [31, 32, 33, 34, 35], as well as how cognitive reflection affects social media usage and the sharing of (mis)information and conspiracy theories [36, 37].\nFurthermore, we explore how demographic factors such as age, gender, and education level, as well as prior experience in AI, astrology, and personality psychology, and the level of interest in the topic influence belief in the predictions. By examining these various factors, our research aims to provide a comprehensive understanding of the \"rational superstition\" phenomenon in AI and its implications for decision-making in an increasingly AI-driven world.\nBased on our research questions, we tested the following hypotheses:"}, {"title": "2 Results", "content": ""}, {"title": "2.1 People who are more likely to believe in astrology and personality-based predictions are more likely to believe in AI predictions.", "content": "To test the first hypothesis (H1), a multiple linear regression model was applied to the data in wide format, with believability score for AI predictions as the outcome variable and believability scores for astrology- and personality- based predictions as predictor variables, along with control variables (cognitive style, paranormal beliefs, gullibility, AI attitude/trust in AI, big five personality, familiarity with the prediction sources (AI, astrology, personality), interest in topic of prediction, age, gender, education level). The scores across the four subscales (perceived validity, reliability, usefulness, and personalization) were averaged as overall \"believability\" scores to provide a straightforward test of the hypothesis.\nThe multiple linear regression analysis explained a significant proportion of the variance in the AI overall score (R2 = 0.7606, Adjusted R2 = 0.7337, F(24, 213) = 28.2, p < 0.001). Significant predictors included the zodiac overall score (Estimate = 0.3119, p < 0.001) and the personality overall score (Estimate = 0.4585, p < 0.001), supporting the hypothesis that belief in astrology and personality-based predictions is positively associated with belief in AI predictions."}, {"title": "2.2 People generally find fictitious AI predictions about their personal behavior convincing.", "content": "To examine the influence of moderating factors including cognitive style (H2), paranormal beliefs, trust in AI, personality traits, demographic factors, etc. (H3), a mixed-effects model was fitted to the data in a nested long format, with"}, {"title": "2.3 There is no evidence of correlation between belief in predictions and cognitive style.", "content": "Based on our hypothesis (H2), we expected to see either a significant positive association between cognitive style and belief in AI predictions, significant negative interactions between cognitive style and other prediction sources (astrology, personality), or both. However, our results showed that the composite cognitive score, as measured as the composite of the performance-based Cognitive Reflection Test (CRT-2) [38] and the preference-based Need for Cognition (NFC-6) [39], did not significantly increase the perceived validity of AI predictions. The estimated increase in perceived validity was 0.13 points with one point increase in the composite cognitive score, but this effect was not statistically significant (95% CI [-0.01, 0.26], p = 0.065). The composite cognitive score ranged from -4.29 to 2.61 (Mean = 0.0, SD = 1.44).\nHowever, we found some significant negative interactions between cognitive score and the subscales. Compared to perceived validity, higher composite cognitive score was associated with a decrease in perceived reliability (-0.11, 95% CI [-0.20, -0.02], p = 0.021) and perceived usefulness (-0.12, 95% CI [-0.20, -0.04], p = 0.004), making the main effect less positive. The interaction with perceived personalization was not statistically significant (-0.05, 95% CI [-0.11, 0.01], p = 0.092).\nThe interactions between cognitive style and prediction sources showed that while there was some negative interaction for astrology (-0.10, 95% CI [-0.21, 0.01], p = 0.079) and personality (-0.07, 95% CI [-0.18, 0.03], p = 0.170), the effects were not statistically significant. This suggests a lack of evidence that cognitive style is an influential factor in how people perceive predictions based on AI, astrology, and personality. Three-way interactions between subscales, prophecy source, and composite cognitive score did not lead to significant results."}, {"title": "2.4 Higher paranormal beliefs increases perceived validity, reliability, usefulness, and personalization of AI predictions.", "content": "One of the most interesting findings was that having paranormal beliefs was positively associated with belief in AI predictions. The results from the mixed effects model showed that the paranormal beliefs score, as measured by a shortened version of the Revised Paranormal Belief Scale (R-PBS) [40], significantly increased perceived validity of AI predictions. With each point increase in the paranormal beliefs scale, perceived validity of AI predictions increased by an average of 0.02 points (95% CI [0.01, 0.03], p = 0.001) on a 7-point scale. The paranormal score, which was centered for the analysis, originally ranged from 15 to 95 (Mean = 45.6, SD = 20.08).\nThe interaction between paranormal beliefs and subscales showed that the effect was stronger for perceived reliability (0.01, 95% CI [0.00, 0.01], p = 0.020) and perceived usefulness (0.01, 95% CI [0.01, 0.02], p < 0.001), both being statistically significant. There was no significant interaction effect for perceived personalization (0.00, 95% CI [-0.00, 0.01], p = 0.427), suggesting that the effect did not differ significantly from perceived validity.\nParanormal beliefs score was an even stronger predictor for belief in astrology-based predictions, perhaps less sur- prisingly given that the scale includes questions around astrology (see Section 7.3). Each standard deviation increase in paranormal beliefs led to an additional 0.01 point increase in perceived validity (95% CI [0.01, 0.02], p = 0.001) compared to the AI baseline. Differences for personality-based predictions were not significant compared to the AI prediction baseline (-0.00, 95% CI [-0.01, 0.00], p = 0.274). No significant interactions were observed between the subscales, prophecy source, and paranormal score."}, {"title": "2.5 Positive AI attitudes increases belief in AI predictions, especially perceived reliability.", "content": "Individuals with more positive attitudes towards AI found predictions based on AI more believable. One point increase in AIAS score [41] led to an increase of perceived validity of AI predictions by 0.04 points (95% CI [0.01, 0.06], p = 0.001) on a 7-point scale. The AIAS score ranged from 4 to 40 (Mean = 25.79, SD = 8.68).\nThe main effect was augmented by an additional 0.03 points for perceived reliability (95% CI [0.02, 0.05], p < 0.001), while the interactions were not significant for perceived personalization (-0.00, 95% CI [-0.01, 0.01], p = 0.941) and usefulness (0.01, 95% CI [-0.00, 0.03], p = 0.071). This suggests that positive attitudes toward AI/trust in Al is more closely related to perceived reliability among all subscales, which is aligned with the findings of studies that explore the relationship between trust/attitude and reliance in AI [42, 43, 44, 45, 46].\nThe interaction between AI attitude (AIAS) and prediction source showed that the positive impact of positive AI attitudes on perceived validity was mostly reversed for astrology-based predictions (-0.24, 95% CI [-0.41, -0.08], p = 0.004), while the effect did not differ significantly for personality-based predictions (0.04, 95% CI [-0.11, 0.19], p = 0.590). The interaction effects between subscales, prophecy source, and AI attitude score were not statistically significant."}, {"title": "2.6 People with high conscientiousness are less likely to believe in predictions about personal behavior.", "content": "Out of the big five personality traits (Extraversion, Openness, Agreeableness, Conscientiousness, Emotional stability), conscientiousness was negatively associated with perceived validity of predictions across all sources. With each point increase in the conscientiousness score (Mean = 5.29, SD = 1.32, Range = [1.0, 7.0], perceived validity was estimated to decrease by an average of 0.15 points (95% CI [-0.30, -0.01], p = 0.032) on a 7-point scale. There were no significant interaction effects with subscales observed, suggesting the main effect was consistent across the four subscales.\nWhile the other domains of the five-factor model were not found to have significant influence, there were some variation in interaction terms. Extraversion was associated with a 0.06 point increase in perceived usefulness (95% CI [0.02, 0.10], p = 0.004), while Openness was associated with a 0.06 decrease in perceived personalization (95% CI [-0.10, -0.01], p = 0.012)."}, {"title": "2.7 Level of interest in the prediction topic increases perceived validity, reliability, usefulness, and personalization.", "content": "While often overlooked in the context of studying trust in AI predictions, individuals' interest in the topic of prediction (in our case, personal investing behavior) was an influential factor in perceived validity, personalization, reliabiliity, and usefulness of predictions. With each point increase in the level of interest in the topic, perceived validity significantly increased on average by 0.27 points (95% CI [0.11, 0.43], p = 0.001) on a 7-point scale. The interest in behavior scale ranged from 1 to 5 (Mean = 3.18, SD = 1.09).\nThe positive association was observed across other subscales. Compared to perceived validity, perceived personalization increased slightly less, reduced by 0.06 points (95% CI [-0.11, -0.01], p = 0.018), while interaction was not statistically significant for perceived reliabilty (-0.07, 95% CI [-0.14, 0.01], p = 0.068) and perceived usefulness (0.02, 95% CI [-0.04, 0.09], p = 0.475), suggesting that the effects were comparable to perceived validity. The results suggest that when all else is held constant, the more people are interested in the topic, the more likely they will perceive fictitious predictions to be valid, reliable, useful, and personalized."}, {"title": "2.8 There is no evidence that the level of familiarity with the prediction sources influences belief in predictions.", "content": "On the other hand, familiarity with the prediction sources (AI, astrology, personality psychology), which measures the level of self-reported familiarity/prior knowledge in each source, did not have a significant effect on perceived validity (-0.02, 95% CI [-0.11, 0.07], p = 0.650) across all sources. The familiarity scale ranged from 1 to 5 (Mean = 2.96, SD = 1.05).\nThe interaction between familiarity and subscales shows that perceived personalization increases slightly but significantly by 0.05 points (95% CI [0.00, 0.11], p = 0.035), while differences were not statistically significant for perceived reliability (0.02, 95% CI [-0.06, 0.10], p = 0.685) and perceived usefulness (0.01, 95% CI [-0.06, 0.08], p = 0.781).\nUnlike what the literature suggests about the familiarity effect, a cognitive phenomenon where people tend to prefer things they are familiar with [47], our results showed inconclusive evidence that familiarity in the prediction sources (AI, astrology, and personality) neither increased nor decreased belief in the respective predictions."}, {"title": "2.9 Other results", "content": "Gullibility was not found to be a significant predictor of perceived validity of AI predictions (-0.02, 95% CI [-0.04, 0.01], p = 0.128). While the interaction between gullibility and Personalization subscale was significant (0.01, 95% CI [0.00, 0.02], p = 0.021), the results were inconclusive when compared to the main effects. Interactions between gullibility and prophecy source were not significant (Astrology: -0.00, 95% CI [-0.02, 0.02], p = 0.977, Personality: -0.02, 95% CI [-0.04, 0.00], p = 0.096), suggesting the effects were similarly insignificant across different prophecy sources. Gullibility scale ranged from 6 to 39 (Mean = 14.68, SD = 7.69).\nWe found that older age was associated with a decrease in belief in predictions across all sources. One year increase in age (Mean = 41.04, SD = 12.38, Range = [19, 75]) was associated with a decrease of perceived validity of AI predictions by 0.02 points (95% CI [-0.03, -0.00], p = 0.014). Interactions between age and subscales were not significant, nor were interactions between age and prophecy source. The non-significant interaction terms suggested that the effect was consistent across subscale and prophecy source.\nFor gender, we did not find significant main effects relative to the Female reference level. While male participants were associated with lower perceived validity scores for AI predictions than female participants, it was not statistically significant (-0.31, 95% CI [-0.69, 0.06], p = 0.103). However, they tend to perceive them as more reliable than female participants (0.41, 95% CI [0.14, 0.68], p = 0.003). Interactions with other subscales were not significant, suggesting they were similar to the perceived validity baseline. Interactions between gender and prophecy source were not significant.\nThere were no significant main effects for level of education compared to the Bachelor reference level. Interactions between education level and subscale showed some significant effects between High school and Personalization (-0.23, 95% CI [-0.40, -0.06], p = 0.009), and Less than high school and Reliability (-0.89, 95% CI [-1.56, -0.22], p = 0.009), but these results did not lead to conclusive results."}, {"title": "3 Discussion", "content": "Belief is subjective and context-dependent; it is also socially constructed through external stimuli such as media narratives, contextual factors, and internal disposition [48, 49]. When looking at belief, trust, and reliance in AI predictions, it is important to consider not just the features of the AI system, but also the characteristics of the users and the broader context. The results from our study show that people who are more likely to believe in astrology- and personality-based predictions were more likely to believe in AI predictions. Moreover, we found that belief in AI predictions on personal behavior can be influenced by various psychological, cognitive, and contextual factors that also drive belief in astrology- or personality-based predictions. By breaking down the concept of believability into four subscales (perceived validity, reliability, usefulness, and personalization), which we further elaborate in Section 7.3.1, we were able to observe interesting patterns and interactions with different subscales.\nCognitive style. While prior literature seemed to suggest that an analytic cognitive style would lead to more skepticism in predictions based on astrology and possibly personality [31, 33, 35], our results did not show significant evidence to support these claims. Moreover, cognitive style was not a significant predictor in belief in AI predictions. Thus, our hypothesis (H2) that people with more analytic cognitive style would be more likely to believe in AI predictions than predictions based on astrology and personality was not supported by our findings. This suggests that analytic cognitive style may not necessarily lead to rational skepticism of fictitious predictions, and perhaps there may be a missing link or mechanism between cognitive style and belief/trust in AI predictions, which could be a topic of future study.\nParanormal beliefs. Paranormal beliefs were found to be an influential predictor of belief in predictions across all sources, including AI predictions. While the association may seem unlikely at first, it can be interpreted within the context of the influence of popular AI narratives. The popular portrayal of AI as rational and objective creates the impression that people would also treat AI in a rational way, and thus more scientifically-inclined people would find AI predictions more believable. However, our results show that belief in AI predictions is more closely associated with paranormal beliefs than one's cognitive style. This result points to the existence of the phenomenon of \"rational superstition\" in AI that was described in the introduction. Moreover, while the effect of paranormal beliefs on belief in AI predictions was significant across all subscales, the effect was larger for perceived usefulness and reliability. Social science research suggests that the rise in belief in astrology is an indicator of rising uncertainties and anxieties as a result of disintegration of community in the modern era [50]. As such, people turn to pseudo-scientific approaches such as astrology for insights to help them navigate their lives. Our findings suggest that people may perceive AI predictions in a way that is similar to the way they perceive astrology-based predictions, which could help explain the results.\nAI Attitude/Trust in AI. Our results showed that people with positive attitudes towards AI found AI predictions more valid, reliable, useful, and personalized. Among the subscales, perceived reliability was found to be most closely related to attitude towards AI. This supports findings from prior literature that positive attitudes toward AI lead to higher reliance in AI predictions [51, 46]."}, {"title": "Super-intelligence of Superstition?", "content": "Personality. Our findings using the Big Five personality traits [52] show that conscientiousness had a negative influence on perception of validity, personalization, reliability, and usefulness, while other traits did not have significant effects. This contrasts previous findings by Riedl [30], who found that agreeableness, openness, and extraversion positively influenced trust and high neuroticism negatively impacted trust, while results on conscientious were mixed.\nConscientiousness is defined as \"socially prescribed impulse control that facilitates task- and goal-directed behavior, such as thinking before acting, delaying gratification, following norms and rules and planning, organizing, and prioritizing tasks\u201d [53, p. 120]. Prior studies have found a positive relationship between conscientiousness and cognitive ability [54, 55]. Contrary to our expectations that these two traits may mirror each other in direction, it was not the case-cognitive style did not have significant effect on believability in our study, while conscientiousness had a significant negative influence on perception of validity, personalization, reliability, and usefulness.\nInterest in the topic of prediction. Our findings show that people's interest in the topic of prediction is a strong predictor when it comes to their belief in predictions, regardless of the source. While our results do not confirm any causal relationship, it could suggest that the more interested one is in a topic, the more exposure they may have to information about it, and the more likely they may be susceptible to cognitive biases that could influence their belief. Some biases that could explain this tendency are confirmation bias and belief bias. Confirmation bias is when individuals seek out and remember information that confirm their existing beliefs [56]. Belief bias occurs when individuals judge the strength of an argument based on the believability of its conclusion rather than the logical structure of the argument itself [57, 58].\nThis has implications in the context of AI-assisted decision-making in different fields; e.g. in marketing, companies may take advantage of people's interest in a certain topic and expose them to more targeted information (e.g. advertisements) that may create an impression of hyper-personalization and lead to more positive attitudes toward the brand [59]. Moreover, in the medical field, an individual may be more prone to believing AI-based predictions about their health if it confirms their prior beliefs.\nFamiliarity/Prior knowledge. Familiarity with the prediction source was not found to be a significant predictor of belief in predictions. Earlier, we discussed how people's positive AI attitudes and interest in the topic of the prediction were positively correlated with belief in the predictions, which may be explained by its likelihood to fuel certain cognitive biases such as belief bias. On the other hand, an individual's level of familiarity in AI, astrology, and personality psychology may not be necessarily indicative of their attitude towards the field. For instance, someone who is not acquainted with the details of latest AI developments may have either a utopian or dystopian view of AI's impact on society, as mentioned in the introduction. Similarly, just because an individual is very familiar with astrology does not inherently mean they are more likely to believe or adopt the predictions, as that may depend on other personal and contextual factors. This suggests two things: 1) simply knowing more about the prediction source does not predict whether one finds a prediction more or less believable, and 2) it does not make one better at calibrating one's trust, providing implications for the design of trustworthy AI systems.\nGullibility. While prior literature suggested a positive relationship between gullibility and paranormal beliefs [31, 34], our findings showed inconclusive results on whether self-reported gullibility had a positive or negative effect on the belief of fictitious predictions based on AI, astrology, and personality. There may be a few potential explanations for this. One is that the order of the study potentially biased participants' answers. The survey was completed after participants had seen and evaluated the predictions, at which point their perception of the believability of the predictions may shadow their self-perception of gullibility\u2014in other words, they did not want to contradict their decisions so quickly by admitting that they are more prone to being fooled. Another possible explanation is the limitation of a self-report nature of the gullibility scale. Some people may be hesitant to admit that they are gullible for different reasons. As such, future studies can further explore the relationship between gullibility and belief in AI predictions.\nDemographic factors. Our results found that older people are more skeptical of predictions about personal behavior, across AI, astrology, and personality sources. This is aligned with prior literature that seems to suggest that older age is associated with lower trust in AI [60], due to many reasons including bias, lack of learning avenues, and concerns about privacy [61]. For gender, while the main effects were insignificant, interactions revealed that male participants were more likely to perceive AI predictions as reliable than female participants. This is supported by a prior study that found that being male with higher education and with a Western background were predictors of trust in AI among the general population [62]. Moreover, while prior work suggested a positive association between level of education and belief in AI [60], we did not find significant main effects for level of education, and the interaction terms did not lead to conclusive results."}, {"title": "4 General Discussion", "content": "Our results highlight the irrational side of how humans perceive and believe in AI predictions, by providing a side-by- side comparison of the perception of fictitious predictions based on AI, astrology, and personality. Our analysis showed that belief in AI prediction about personal behavior may be more related to paranormal beliefs than cognitive style, and that positive attitudes toward AI and interest in the topic of prediction, but not familiarity with the sources, can enhance that belief.\nThese findings suggest that highly accurate and reliable performance is not a prerequisite for people to put high trust in predictions; models do not need to be completely trustworthy for users to put trust in them. The disentanglement between perception and actual performance leads to a few important discussions regarding how people perceive and engage with AI systems:\n1) Incorrect mental models of AI can override perception of validity.\nBelief in AI predictions is based on people's mental model of AI systems, rather than the actual model performance. Hoff and Bashir presented a comprehensive three-layer framework of trust in automation, including dispositional, situational, and learned trust, among which system performance is part of learned trust that comes with active engagement with the system [63]. In our study, we observed that even without any validation of system performance, people found fictitious AI predictions highly valid, reliable, useful, and personalized. Other researchers have studied this placebo effect of AI systems, with just priming with descriptions of AI leading to people perceiving and behaving differently [64, 65, 66, 67].\nThis highlights the importance of the role of mental models in how people perceive and trust AI [23, 68, 69, 70, 71, 72]. Mental models are the collection of beliefs and expectations around AI systems and interactions with them, and can be shaped by prior beliefs as well as ongoing interactions with AI systems [23, 68]. By framing the scenario in a certain way, including the task domain and the information provided about the AI system, we observed that people could perceive fictitious AI predictions to be highly accurate, personalized, and trustworthy [23].\nMoreover, the results revealed that people might perceive AI predictions similarly to how they believe in astrology predictions, given a reasonable context. This supports the observation of \"rational superstition\" in AI and automation [17]. We argue that this phenomenon is fueled by an idealized portrayal of AI systems as enchanted yet rational and deterministic [73], which may shape people's prior beliefs about AI and bias their interactions.\nThe dual process theory in psychology provides insight on how larger narratives could bias people's perceptions of AI systems. The theory states people engage in two types of thinking\u2014fast and intuitive (System 1) and slow and reflective (System 2) [20, 21]. Mental models may be shaped by evolving public narratives around AI [6], and may become a mental heuristic that triggers people's System 1 thinking rather than engaging their System 2 thinking, blurring the lines between speculation and informed reasoning [22]. Incomplete or incorrect mental models shaped by speculative claims about AI rather than scientific evidence can lead to over-reliance or miscalibration of trust [18, 19], driving ineffective use of AI [23, 43].\nThis points to the importance of de-divinizing AI in popular narratives and increasing awareness of both the capabilities and limitations of AI systems to help users form more accurate mental models. Even with technological advancements, people's mental models should evolve along with an appropriate level of skepticism to avoid becoming overreliant or overly skeptical.\n2) Mental models can influence and be influenced by cognitive biases.\nCognitive biases can provide some insight into how people might believe in AI in an irrational manner. Specifically, belief bias occurs when individuals evaluate a statement based on its plausibility according to their prior beliefs rather than its logical validity [57, 58]. When situated within the dual process theory, belief bias is known to be largely attributed to System 1 thinking (especially under time pressure [74]), but it can also be intervened by System 2 thinking to construct mental models around existing beliefs in a way that can be biased, leading to overriding of logic [75, 21]. Known as the selective processing model [76], this theory explains why people may engage logic when a statement contradicts their beliefs, but fail to engage logical thinking when a statement aligns with what they believe, especially when it comes to beliefs about themselves.\nAnother cognitive bias that may explain our findings is the Barnum effect, which refers to when individuals believe vague and general statements to be highly accurate for them personally. Also known as the Forer effect or personal validation fallacy, this cognitive bias has been studied in contexts such as astrology and personality tests [77, 78]). Based on the findings from our study, we argue that the Barnum effect can also explain how people engage with AI predictions about oneself, where people perceive general AI-generated statements as personalized and valid. Cognitive biases such as belief bias and the Barnum effect can influence how mental models are formed and how users rely on AI"}, {"title": "Super-intelligence of Superstition?", "content": "systems [69"}]}