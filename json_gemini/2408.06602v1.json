{"title": "SUPER-INTELLIGENCE OR SUPERSTITION? EXPLORING\nPSYCHOLOGICAL FACTORS UNDERLYING UNWARRANTED\nBELIEF IN \u0391\u0399 PREDICTIONS", "authors": ["Eunhae Lee", "Judith Amores", "Pat Pataranutaporn", "Pattie Maes"], "abstract": "This study investigates psychological factors influencing belief in AI predictions about personal be-\nhavior, comparing it to belief in astrology and personality-based predictions. Through an experiment\nwith 238 participants, we examined how cognitive style, paranormal beliefs, AI attitudes, personality\ntraits, and other factors affect perceived validity, reliability, usefulness, and personalization of predic-\ntions from different sources. Our findings reveal that belief in AI predictions is positively correlated\nwith belief in predictions based on astrology and personality psychology. Notably, paranormal\nbeliefs and positive AI attitudes significantly increased perceived validity, reliability, usefulness,\nand personalization of AI predictions. Conscientiousness was negatively correlated with belief in\npredictions across all sources, and interest in the prediction topic increased believability across\npredictions. Surprisingly, cognitive style did not significantly influence belief in predictions. These\nresults highlight the \"rational superstition\" phenomenon in AI, where belief is driven more by mental\nheuristics and intuition than critical evaluation. We discuss implications for designing AI systems\nand communication strategies that foster appropriate trust and skepticism. This research contributes\nto our understanding of the psychology of human-AI interaction and offers insights for the design\nand deployment of AI systems.", "sections": [{"title": "1 Introduction", "content": "Technology is often associated with scientific advancement and frequently viewed in opposition to superstition. However,\nthe recent rapid advancements in artificial intelligence (AI) have given rise to quasi-religious perspectives among some\nleaders in the tech industry [1]. In fact, as generative AI and large language models (LLMs) continue to evolve, a\ncontemporary critique posits that the narrative surrounding their development bears striking resemblances to religious\ndiscourse [2]. Promoting concepts such as superintelligence and sentience, prominent figures in the tech industry have\nbeen observed making prophetic claims regarding AI's potential to either salvage or obliterate humanity [3, 4]. These\nclaims are often based on personal speculation and subjective views rather than rigorous scientific research. Nonetheless,\nempirical research has demonstrated that these popular narratives are mirrored in public perceptions of AI, frequently\nmanifesting as exaggerated utopian or dystopian visions [5, 6]. This intersection of technological advancement and\nquasi-religious perspective presents a complex landscape for scholars to navigate, as it blurs the boundaries between\nscientific progress and speculation."}, {"title": "2 Results", "content": "To test the first hypothesis (H1), a multiple linear regression model was applied to the data in wide format, with\nbelievability score for AI predictions as the outcome variable and believability scores for astrology- and personality-\nbased predictions as predictor variables, along with control variables (cognitive style, paranormal beliefs, gullibility, AI\nattitude/trust in AI, big five personality, familiarity with the prediction sources (AI, astrology, personality), interest in\ntopic of prediction, age, gender, education level). The scores across the four subscales (perceived validity, reliability,\nusefulness, and personalization) were averaged as overall \"believability\" scores to provide a straightforward test of the\nhypothesis.\nThe multiple linear regression analysis explained a significant proportion of the variance in the AI overall score\n(R2 = 0.7606, Adjusted R2 = 0.7337, F(24, 213) = 28.2, p < 0.001). Significant predictors included the zodiac\noverall score (Estimate = 0.3119, p < 0.001) and the personality overall score (Estimate = 0.4585, p < 0.001),\nsupporting the hypothesis that belief in astrology and personality-based predictions is positively associated with belief\nin AI predictions. This association can be visually observed in the scatterplots in Figure 1."}, {"title": "2.2 People generally find fictitious AI predictions about their personal behavior convincing.", "content": "To examine the influence of moderating factors including cognitive style (H2), paranormal beliefs, trust in AI, personality\ntraits, demographic factors, etc. (H3), a mixed-effects model was fitted to the data in a nested long format, with"}, {"title": "2.3 There is no evidence of correlation between belief in predictions and cognitive style.", "content": "Based on our hypothesis (H2), we expected to see either a significant positive association between cognitive style and\nbelief in AI predictions, significant negative interactions between cognitive style and other prediction sources (astrology,\npersonality), or both. However, our results showed that the composite cognitive score, as measured as the composite of\nthe performance-based Cognitive Reflection Test (CRT-2) [38] and the preference-based Need for Cognition (NFC-6)\n[39], did not significantly increase the perceived validity of AI predictions. The estimated increase in perceived validity\nwas 0.13 points with one point increase in the composite cognitive score, but this effect was not statistically significant\n(95% CI [-0.01, 0.26], p = 0.065). The composite cognitive score ranged from -4.29 to 2.61 (Mean = 0.0, SD = 1.44).\nHowever, we found some significant negative interactions between cognitive score and the subscales. Compared to\nperceived validity, higher composite cognitive score was associated with a decrease in perceived reliability (-0.11, 95%\nCI [-0.20, -0.02], p = 0.021) and perceived usefulness (-0.12, 95% CI [-0.20, -0.04], p = 0.004), making the main effect\nless positive. The interaction with perceived personalization was not statistically significant (-0.05, 95% CI [-0.11,\n0.01], p = 0.092).\nThe interactions between cognitive style and prediction sources showed that while there was some negative interaction\nfor astrology (-0.10, 95% CI [-0.21, 0.01], p = 0.079) and personality (-0.07, 95% CI [-0.18, 0.03], p = 0.170), the\neffects were not statistically significant. This suggests a lack of evidence that cognitive style is an influential factor in\nhow people perceive predictions based on AI, astrology, and personality. Three-way interactions between subscales,\nprophecy source, and composite cognitive score did not lead to significant results."}, {"title": "2.4 Higher paranormal beliefs increases perceived validity, reliability, usefulness, and\npersonalization of AI predictions.", "content": "One of the most interesting findings was that having paranormal beliefs was positively associated with belief in AI\npredictions. The results from the mixed effects model showed that the paranormal beliefs score, as measured by a\nshortened version of the Revised Paranormal Belief Scale (R-PBS) [40], significantly increased perceived validity of AI\npredictions. With each point increase in the paranormal beliefs scale, perceived validity of AI predictions increased\nby an average of 0.02 points (95% CI [0.01, 0.03], p = 0.001) on a 7-point scale. The paranormal score, which was\ncentered for the analysis, originally ranged from 15 to 95 (Mean = 45.6, SD = 20.08).\nThe interaction between paranormal beliefs and subscales showed that the effect was stronger for perceived reliability\n(0.01, 95% CI [0.00, 0.01], p = 0.020) and perceived usefulness (0.01, 95% CI [0.01, 0.02], p < 0.001), both being\nstatistically significant. There was no significant interaction effect for perceived personalization (0.00, 95% CI [-0.00,\n0.01], p = 0.427), suggesting that the effect did not differ significantly from perceived validity.\nParanormal beliefs score was an even stronger predictor for belief in astrology-based predictions, perhaps less sur-\nprisingly given that the scale includes questions around astrology (see Section 7.3). Each standard deviation increase\nin paranormal beliefs led to an additional 0.01 point increase in perceived validity (95% CI [0.01, 0.02], p = 0.001)\ncompared to the AI baseline. Differences for personality-based predictions were not significant compared to the AI\nprediction baseline (-0.00, 95% CI [-0.01, 0.00], p = 0.274). No significant interactions were observed between the\nsubscales, prophecy source, and paranormal score."}, {"title": "2.5 Positive AI attitudes increases belief in AI predictions, especially perceived reliability.", "content": "Individuals with more positive attitudes towards AI found predictions based on AI more believable. One point increase\nin AIAS score [41] led to an increase of perceived validity of AI predictions by 0.04 points (95% CI [0.01, 0.06], p =\n0.001) on a 7-point scale. The AIAS score ranged from 4 to 40 (Mean = 25.79, SD = 8.68).\nThe main effect was augmented by an additional 0.03 points for perceived reliability (95% CI [0.02, 0.05], p < 0.001),\nwhile the interactions were not significant for perceived personalization (-0.00, 95% CI [-0.01, 0.01], p = 0.941) and\nusefulness (0.01, 95% CI [-0.00, 0.03], p = 0.071). This suggests that positive attitudes toward AI/trust in Al is more"}, {"title": "2.6 People with high conscientiousness are less likely to believe in predictions about personal\nbehavior.", "content": "Out of the big five personality traits (Extraversion, Openness, Agreeableness, Conscientiousness, Emotional stability),\nconscientiousness was negatively associated with perceived validity of predictions across all sources. With each point\nincrease in the conscientiousness score (Mean = 5.29, SD = 1.32, Range = [1.0, 7.0], perceived validity was estimated\nto decrease by an average of 0.15 points (95% CI [-0.30, -0.01], p = 0.032) on a 7-point scale. There were no significant\ninteraction effects with subscales observed, suggesting the main effect was consistent across the four subscales.\nWhile the other domains of the five-factor model were not found to have significant influence, there were some variation\nin interaction terms. Extraversion was associated with a 0.06 point increase in perceived usefulness (95% CI [0.02,\n0.10], p = 0.004), while Openness was associated with a 0.06 decrease in perceived personalization (95% CI [-0.10,\n-0.01], p = 0.012)."}, {"title": "2.7 Level of interest in the prediction topic increases perceived validity, reliability,\nusefulness, and personalization.", "content": "While often overlooked in the context of studying trust in AI predictions, individuals' interest in the topic of prediction\n(in our case, personal investing behavior) was an influential factor in perceived validity, personalization, reliabiliity, and\nusefulness of predictions. With each point increase in the level of interest in the topic, perceived validity significantly\nincreased on average by 0.27 points (95% CI [0.11, 0.43], p = 0.001) on a 7-point scale. The interest in behavior scale\nranged from 1 to 5 (Mean = 3.18, SD = 1.09).\nThe positive association was observed across other subscales. Compared to perceived validity, perceived personalization\nincreased slightly less, reduced by 0.06 points (95% CI [-0.11, -0.01], p = 0.018), while interaction was not statistically\nsignificant for perceived reliabilty (-0.07, 95% CI [-0.14, 0.01], p = 0.068) and perceived usefulness (0.02, 95% CI\n[-0.04, 0.09], p = 0.475), suggesting that the effects were comparable to perceived validity. The results suggest that\nwhen all else is held constant, the more people are interested in the topic, the more likely they will perceive fictitious\npredictions to be valid, reliable, useful, and personalized."}, {"title": "2.8 There is no evidence that the level of familiarity with the prediction sources influences\nbelief in predictions.", "content": "On the other hand, familiarity with the prediction sources (AI, astrology, personality psychology), which measures the\nlevel of self-reported familiarity/prior knowledge in each source, did not have a significant effect on perceived validity\n(-0.02, 95% CI [-0.11, 0.07], p = 0.650) across all sources. The familiarity scale ranged from 1 to 5 (Mean = 2.96, SD =\n1.05).\nThe interaction between familiarity and subscales shows that perceived personalization increases slightly but significantly\nby 0.05 points (95% CI [0.00, 0.11], p = 0.035), while differences were not statistically significant for perceived reliability\n(0.02, 95% CI [-0.06, 0.10], p = 0.685) and perceived usefulness (0.01, 95% CI [-0.06, 0.08], p = 0.781).\nUnlike what the literature suggests about the familiarity effect, a cognitive phenomenon where people tend to prefer\nthings they are familiar with [47], our results showed inconclusive evidence that familiarity in the prediction sources\n(AI, astrology, and personality) neither increased nor decreased belief in the respective predictions."}, {"title": "2.9 Other results", "content": "Gullibility was not found to be a significant predictor of perceived validity of AI predictions (-0.02, 95% CI [-0.04,\n0.01], p = 0.128). While the interaction between gullibility and Personalization subscale was significant (0.01, 95%"}, {"title": "3 Discussion", "content": "Belief is subjective and context-dependent; it is also socially constructed through external stimuli such as media\nnarratives, contextual factors, and internal disposition [48, 49]. When looking at belief, trust, and reliance in AI\npredictions, it is important to consider not just the features of the AI system, but also the characteristics of the users\nand the broader context. The results from our study show that people who are more likely to believe in astrology-\nand personality-based predictions were more likely to believe in AI predictions. Moreover, we found that belief in AI\npredictions on personal behavior can be influenced by various psychological, cognitive, and contextual factors that\nalso drive belief in astrology- or personality-based predictions. By breaking down the concept of believability into four\nsubscales (perceived validity, reliability, usefulness, and personalization), which we further elaborate in Section 7.3.1,\nwe were able to observe interesting patterns and interactions with different subscales.\nWhile prior literature seemed to suggest that an analytic cognitive style would lead to more skepticism\nin predictions based on astrology and possibly personality [31, 33, 35], our results did not show significant evidence to\nsupport these claims. Moreover, cognitive style was not a significant predictor in belief in AI predictions. Thus, our\nhypothesis (H2) that people with more analytic cognitive style would be more likely to believe in AI predictions than\npredictions based on astrology and personality was not supported by our findings. This suggests that analytic cognitive\nstyle may not necessarily lead to rational skepticism of fictitious predictions, and perhaps there may be a missing link or\nmechanism between cognitive style and belief/trust in AI predictions, which could be a topic of future study.\nParanormal beliefs. Paranormal beliefs were found to be an influential predictor of belief in predictions across all\nsources, including AI predictions. While the association may seem unlikely at first, it can be interpreted within the\ncontext of the influence of popular AI narratives. The popular portrayal of AI as rational and objective creates the\nimpression that people would also treat AI in a rational way, and thus more scientifically-inclined people would find\nAI predictions more believable. However, our results show that belief in AI predictions is more closely associated\nwith paranormal beliefs than one's cognitive style. This result points to the existence of the phenomenon of \"rational\nsuperstition\" in AI that was described in the introduction. Moreover, while the effect of paranormal beliefs on belief in\nAI predictions was significant across all subscales, the effect was larger for perceived usefulness and reliability. Social\nscience research suggests that the rise in belief in astrology is an indicator of rising uncertainties and anxieties as a\nresult of disintegration of community in the modern era [50]. As such, people turn to pseudo-scientific approaches such\nas astrology for insights to help them navigate their lives. Our findings suggest that people may perceive AI predictions\nin a way that is similar to the way they perceive astrology-based predictions, which could help explain the results."}, {"title": "4 General Discussion", "content": "Our results highlight the irrational side of how humans perceive and believe in AI predictions, by providing a side-by-\nside comparison of the perception of fictitious predictions based on AI, astrology, and personality. Our analysis showed\nthat belief in AI prediction about personal behavior may be more related to paranormal beliefs than cognitive style, and\nthat positive attitudes toward AI and interest in the topic of prediction, but not familiarity with the sources, can enhance\nthat belief.\nThese findings suggest that highly accurate and reliable performance is not a prerequisite for people to put high trust\nin predictions; models do not need to be completely trustworthy for users to put trust in them. The disentanglement\nbetween perception and actual performance leads to a few important discussions regarding how people perceive and\nengage with AI systems:\nBelief in AI predictions is based on people's mental model of AI systems, rather than the actual model performance. Hoff\nand Bashir presented a comprehensive three-layer framework of trust in automation, including dispositional, situational,\nand learned trust, among which system performance is part of learned trust that comes with active engagement with\nthe system [63]. In our study, we observed that even without any validation of system performance, people found\nfictitious AI predictions highly valid, reliable, useful, and personalized. Other researchers have studied this placebo\neffect of AI systems, with just priming with descriptions of AI leading to people perceiving and behaving differently\n[64, 65, 66, 67].\nThis highlights the importance of the role of mental models in how people perceive and trust AI [23, 68, 69, 70, 71, 72].\nMental models are the collection of beliefs and expectations around AI systems and interactions with them, and can be\nshaped by prior beliefs as well as ongoing interactions with AI systems [23, 68]. By framing the scenario in a certain\nway, including the task domain and the information provided about the AI system, we observed that people could\nperceive fictitious AI predictions to be highly accurate, personalized, and trustworthy [23].\nMoreover, the results revealed that people might perceive AI predictions similarly to how they believe in astrology\npredictions, given a reasonable context. This supports the observation of \"rational superstition\" in AI and automation\n[17]. We argue that this phenomenon is fueled by an idealized portrayal of AI systems as enchanted yet rational and\ndeterministic [73], which may shape people's prior beliefs about AI and bias their interactions.\nThis points to the importance of de-divinizing AI in popular narratives and increasing awareness of both the capabilities\nand limitations of AI systems to help users form more accurate mental models. Even with technological advancements,\npeople's mental models should evolve along with an appropriate level of skepticism to avoid becoming overreliant or\noverly skeptical."}, {"title": "3) Design of AI systems must take cognitive biases and mental models into account to support appropriate level\nof trust.", "content": "Awareness of the potential impact of cognitive biases on human-AI interaction is crucial to reduce the risk of negatively\nexploiting these human tendencies. For instance, AI systems that simply validate users' prior beliefs may be more\nlikely to be favored and accepted, but this may not support better decision-making or well-being, such as in areas of\npersonal finance or health. Thus, we could think about how to design systems that are not only agreeable, but can\npresent information in a way that helps people think critically.\nMoreover, establishing correct mental models about AI systems is important. For example, in the context of mental\nhealth chatbots, users with incorrect mental models may have unrealistic expectations about what the AI can do, thus\nleading to greater disappointments. AI systems should include mechanisms that help users develop an appropriate level\nof trust in these systems to avoid over or under reliance [46]. Fortunately, mental models are dynamic and can evolve\nwith more interactions [23, 79]."}, {"title": "4) Our understanding of human-AI interaction needs to include psychological and contextual factors.", "content": "How people believe, trust, and rely on AI predictions for their decision-making should be seen in a larger context [46].\nContextual factors, including individual differences, task domain, information provided, media discourse, organizational\nand social environment, and more are all factors that could influence user perceptions and behavior in AI-assisted\ndecision-making [11, 23].\nGoing beyond system performance, our findings highlight the importance of user-related factors in the evaluation\nof human-AI interaction. Importantly, our study underscores the role of psychological factors that may influence\nperception and belief in AI predictions. We found that factors including prior attitude towards AI, tendency to believe\nin paranormal phenomena, certain personality traits, and the level of interest in the topic influence people's perceptions\nof AI predictions. We discuss the findings in the context of broader societal narratives around AI, mental models, and\ncognitive biases."}, {"title": "5 Limitations and Future Work", "content": "While our study has presented valuable insights into the phenomenon of \"irrational superstition\" in AI predictions and\ncognitive biases, there are several important limitations that can be addressed in future work. First, our experiment\nwas specifically designed to provide predictions on personal behavior. There are some limitations to the extent to\nwhich our results can be generalized to the general use of AI. Therefore, future studies could look at how people\nperceive AI predictions in different contexts and prediction topics, while also exploring the relationship with underlying\npsychological and cognitive factors at play. For instance, the effect can be tested within the context of AI-assisted\ndecision-making in personal health or well-being, or in educational settings using an AI tutor. We believe that our study\nopens up more questions about understanding the intricate ways in which humans perceive, trust, and interact with AI\nsystems.\nSecond, like most survey designs, our survey-based approach to measuring psychological and cognitive traits may be\naffected by social desirability bias (the tendency to respond in a way that seems socially favorable) [84], as well as\ncommon method biases [85], and reliance on self-reported data. Therefore, we hope future studies can validate our\nfindings using different methods and approaches."}, {"title": "6 Conclusion", "content": "Our study empirically investigated the phenomenon of \u201crational superstition\" in AI by providing a side-by-side\ncomparison of people's perceptions of fictitious predictions based on AI, astrology, and personality. Even without any\nvalidation of system performance, people perceived fictitious AI predictions as highly believable, and their perceptions\nwere positively associated with their perception of astrology- and personality-based predictions. Our findings showed\nthat people's belief in AI predictions was positively associated with paranormal beliefs, positive attitude towards\nAI, interest in the topic of prediction, and negatively associated with conscientiousness and age. We also explored\ninteractions with other prediction sources and the subscales including perceived validity, reliability, usefulness, and\npersonalization. In our discussion, we highlighted the role of mental models and cognitive biases in shaping people's\nperceptions of AI predictions, and the importance of including psychological and contextual factors in studying\nhuman-AI interaction."}, {"title": "7 Methods", "content": "Data were initially collected from a survey administered to 300 participants recruited through Prolific. After excluding\n62 participants due to incomplete responses or failed attention checks, the final analysis was conducted with data\nfrom the remaining 238 participants. These individuals were adults aged 18 and above from diverse socioeconomic\nbackgrounds (see Table 1 for an overview of participants' demographic information)."}, {"title": "7.2 Experiment Protocol", "content": "Participants were asked to complete a short zodiac-related questionnaire (date, hour, and location of birth), a short\npersonality test (adaptation of Myers-Briggs Type Indicator (MBTI) [86], and a simulated investment game. In\nthe instructions, participants were told that they will receive personalized predictions about their future investment\nbehavior generated from three distinct sources (astrology, personality, and AI) based on their game interactions and\nthe information they provided. What they were not told in the beginning was that these predictions were generic,\npre-determined statements that were not based on their responses, which was revealed to them after completion."}, {"title": "Recommendations:", "content": "The simulated investment game was designed to elicit interactions comparable to that of modern robo-advising\nplatforms [87], but in a simplified way. Participants were provided with virtual currency of $10,000 to invest across\nthree investment categories (high risk/return, medium risk/return, low risk/return) over ten rounds (representing years).\nAt each round, they could allocate up to 100% of their assets across the three categories, with the goal of maximizing\ntheir total portfolio value."}, {"title": "7.3 Measures", "content": "This section includes the detailed questionnaires that we used for the study."}, {"title": "7.3.1 Perceived validity, reliability, usefulness, and personalization", "content": "To measure the believability of the predictions, we presented a short questionnaire that assess perceived validity,\nreliabiliy, usefulness, and personalization of given predictions. These factors were chosen based on existing literature\non the different qualities of a statement that contribute to persuasion, user adoption of an information technology, and\npositive attitudes."}, {"title": "7.3.2 Cognitive Reflection (CRT-2) and Need for Cognition (NCS-6)", "content": "Cognitive reflection, or the tendency to suppress an intuitive but incorrect response in favor of a more reflective and\ncorrect one, was chosen as a moderating factor for belief in predictions to explore how it influences the acceptance and\ntrust in predictions about personal behavior. This approach aims to determine if higher cognitive abilities correlate with\nmore critical evaluation and discernment of AI predictions, as well as predictions based on astrology and personality."}, {"title": "7.3.3 Paranormal beliefs (R-PBS)", "content": "Paranormal beliefs refer to the conviction in phenomena beyond scientific explanation, such as supernatural events,\nastrology, and mystical experiences. Paranormal beliefs were chosen as a moderating factor for belief in AI, astrology,\nand personality predictions to investigate how these unconventional beliefs influence the acceptance of various predictive\nstatements."}, {"title": "7.3.4 AI Attitude/Trust in AI (AIAS-4)", "content": "A 4-item, 1-factor AI attitude scale (AIAS-4) [41] (10-point Likert scale, 1=Not at all, 10=Completely agree) was used\nto measure participants' attitude towards AI."}, {"title": "7.3.5 Gullibility", "content": "A shortened version of the originally 12-item, 2-factor scale by Teunisse et al. (2020) [90] (7-point Likert scale,\n1=Strongly disagree, 7=Strongly agree) was used to measure self-reported gullibility."}, {"title": "7.3.6 Big Five Personality", "content": "Based on the Five Factor personality model, the 10-item Big Five Personality Inventory (TIPI) [91] (7-point Likert\nscale, 1=Strongly disagree, 7=Strongly agree) was used to measure participants' personality."}, {"title": "7.3.7 Familiarity/Level of expertise", "content": "How would you rate your level of familiarity with the following (5-point Likert scale, 1=Not at all, 5=Extremely\nfamiliar)"}, {"title": "7.3.8 Interest in topic of prediction", "content": "How would you rate your level of interest in understanding your future investment behavior? (5-point Likert scale,\n1=Not interested, 5=Extremely interested)"}, {"title": "7.4 Approvals", "content": "This research was reviewed and approved by the MIT Committee on the Use of Humans as Experimental Subjects,\nprotocol number E-5768."}, {"title": "7.5 Analysis", "content": "The dependent variable (Y) was the subscale scores for perceived validity, personalization, reliability, and usefulness\n(7-point Likert scale, 1=Strongly disagree, 7=Strongly agree).\nThe analysis included a range of predictor variables (X) to examine their effects on the subscale scores. The predictor\nand control variables were:"}, {"title": "7.5.2 Multiple linear regression", "content": "To test the hypothesis that individuals who are more likely to believe in astrology and personality-based predictions are\nalso more likely to believe in AI predictions (H1), a multiple linear regression model was first applied to the data in\nwide format. The dependent variable was $ai\\_overall\\_score$, and the main predictors were $zodiac\\_overall\\_score$ and\n$personality\\_overall\\_score$, with the rest of the variables mentioned in Section 7.5.1 included as control variables. The\nmodel was fitted using the lm function in R."}, {"title": "7.5.3 Mixed effects model", "content": "To examine the main effects and moderating effects of psychological and cognitive factors (H2, H3), the data was\ntransformed to a long format, creating a three-level hierarchical structure. Each subject engaged in three types\nof conditions ($prophecy\\_source$) and evaluated across four subscales ($subscale$). The outcome variable was the\n$subscale\\_score$.\nThe mixed effects model was specified as follows. The fixed effects were defined as:"}]}