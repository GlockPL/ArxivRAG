{"title": "DispFormer: Pretrained Transformer for Flexible Dispersion Curve Inversion from Global Synthesis to Regional Applications", "authors": ["Feng Liu", "Bao Deng", "Rui Su", "Lei Bai", "Wanli Ouyang"], "abstract": "Surface wave dispersion curve inversion is essential for estimating subsurface Shear-wave velocity (vs), yet traditional methods often struggle to balance computational efficiency with inversion accuracy. While deep learning approaches show promise, previous studies typically require large amounts of labeled data and struggle with real-world datasets that have vary-ing period ranges, missing data, and low signal-to-noise ratios. This study proposes DispFormer, a transformer-based neural net-work for inverting the vs profile from Rayleigh-wave phase and group dispersion curves. DispFormer processes dispersion data at each period independently, thereby allowing it to handle data of varying lengths without requiring network modifications or alignment between training and testing data. The performance is demonstrated by pre-training it on a global synthetic dataset and testing it on two regional synthetic datasets using zero-shot and few-shot strategies. Results indicate that zero-shot DispFormer, even without any labeled data, produces inversion profiles that match well with the ground truth, providing a deployable initial model generator to assist traditional methods. When labeled data is available, few-shot DispFormer outperforms traditional methods with only a small number of labels. Furthermore, real-world tests indicate that DispFormer effectively handles varying length data, and yields lower data residuals than reference models. These findings demonstrate that DispFormer provides a robust foundation model for dispersion curve inversion and is a promising approach for broader applications.", "sections": [{"title": "I. INTRODUCTION", "content": "SURFACE wave tomography, which utilizes the cross-correlation functions of long-term seismic ambient noise [1]\u2013[4] or surface waves generated by regional and global earthquakes [5]\u2013[10], has proven to be a powerful method for investigating the interior of the Earth. This technique is widely used for high-resolution imaging of the crust and lower mantle [11]\u2013[13], and is increasingly applied in near-surface exploration [14], [15]. A commonly used approach in surface wave tomography involves a two-step inversion process. In the first step, group and/or phase velocity maps are constructed across multiple periods. These maps are then employed to generate dispersion curves for each grid cell, which are subsequently inverted to obtain one-dimensional (1-D) shear wave velocity (vs) profiles [16].\nThe inversion process that maps surface wave dispersion curves to a 1-D depth profile of vs is inherently nonlinear and underdetermined [17], [18]. Conventional methods include linearized inversion techniques [19], which iteratively refine an assumed initial velocity model using gradient descent, and global search algorithms such as Monte Carlo [20], [21] and particle swarm optimization (PSO) [22], which explore a broad parameter space to identify optimal solutions. As the number of deployed seismic arrays and shared databases increases, the limitations of both approaches become more pronounced. Linearized inversion encounters difficulties in yielding ac-curate results without a good initial model, while global search algorithms face significant computational challenges [23], [24].\nDeep learning has emerged as a promising alternative to traditional methods, offering a balance between efficiency and accuracy in various inversion applications, including gravity inversion [25], [26], electromagnetic inversion [27], [28], and seismic inversion [29], [30]. In the context of surface wave dispersion curve inversion, early studies used fully connected neural networks (FCNNs) to estimate surface wave velocities and layer thicknesses [31]\u2013[33], paving the way for more advanced deep learning approaches. For example, Hu et al. [34] utilized convolutional neural networks (CNNs) to improve inversion results on two regional datasets from continental China and southern California. Earp et al. [35] and Yang et al. [36] employed mixture density networks to derive vs structures while quantifying inversion uncertainty. Aleardi and Stucchi [37], along with Gan et al. [38], used residual networks (ResNets) to directly map the full dispersion spectrum to vs models. Additionally, Luo et al. [39] trained a deep FCNN on a global synthetic dataset and validated its performance on regional datasets. Cai et al. [40] proposed a semi-supervised Cycle-GAN to enhance generalization in poorly constrained regions.\nDespite these advancements, most existing network ar-chitectures are limited by the requirement for fixed-length dispersion data, which restricts their applicability to real-world scenarios where dispersion curves often face challenges such as inconsistent data ranges, missing data, and low signal-to-noise ratios [14], [41], [42]. Moreover, these models typically exhibit limited generalization capabilities, performing well on training datasets but underperforming on unseen or diverse datasets [34], [38]. In practice, applying these models often requires large labeled datasets for case-specific training and the alignment of training and observed data through methods such as cropping, interpolation, or padding. However, large labeled datasets and length-aligned observations are rarely available in surface wave dispersion curve inversion studies. These challenges underscore the need for more robust and adaptable methods that can accommodate varying lengths and deliver reliable results across a broad range of datasets.\nTo address these challenges, this study introduces three primary contributions: 1) DispFormer, a transformer-based net-work for varying-length dispersion data. The model encodes dispersion data using linear layers and position embeddings, extracts period-related features through multiple transformer blocks, and finally projects the results into a 1-D velocity pro-file. 2) Pre-training and zero-shot testing: DispFormer is pre-trained on a global synthetic dataset to embed prior knowledge of surface wave dispersion. Tests on regional datasets demon-strate that the pre-trained model effectively handles varying-length dispersion data and generalizes well to unseen datasets. Using this prior knowledge, zero-shot DispFormer provides a plug-and-play solution for generating reliable initial models in traditional inversion workflows. 3) Few-shot testing: When a small amount of labeled data is available, fine-tuning the pre-trained DispFormer significantly improves performance. Both synthetic and real-world tests show that the fine-tuned model produces inversion results that are comparable to, or even exceed, those of traditional global search methods."}, {"title": "II. METHODOLOGY", "content": "For a horizontally layered Earth model, the forward model-ing of the Rayleigh wave dispersion curves can be expressed as [43], [44]:\n$d(\\tau) = G(v_p, v_s, \\rho, h), \\qquad(1)$\nwhere G is the forward operator that takes the layered earth model as input, including P-wave velocity ($v_p$), S-wave velocity ($v_s$), density ($\\rho$), and layer thickness (h) for each layer. The output of this operation, d($\\tau$), corresponds to the dispersion data at a given period $\\tau$, which includes both phase and group velocities.\nInversion aims to estimate the underlying Earth model parameters based on observed dispersion data. Traditional inversion methods can be broadly categorized into linearized and global approaches. Linearized inversion iteratively refines an initial model, typically using gradient-based optimization to minimize the discrepancy between observed and modeled data [17], [19]. However, its effectiveness heavily depends on the quality of the initial model; a well-chosen starting model increases the likelihood of convergence to the global minimum, while a poor choice raises the risk of being trapped in a local minimum [45]. Global search algorithms, in contrast, explore the parameter space more comprehensively to identify the optimal model. These methods are less dependent on initial guesses and are generally more robust but come with substantial computational costs, which limits their practicality for large-scale applications.\nTo achieve a balance between efficiency and accuracy in inversion, deep learning techniques have been increasingly employed to learn the nonlinear mappings between dispersion curves and S-wave velocity [38], [46], which can be mathe-matically expressed as:\n$m = f(d; \\theta) \\qquad(2)$\nwhere f denotes the neural network, parameterized by $\\theta$. The input to the neural network, d, consists of phase and/or group velocity dispersion data. The output, m = [$v_p$, $v_s$, $\\rho$, h], represents the predicted subsurface velocity model. In practice, empirical relationships are often used to estimate $v_p$ and $\\rho$ due to their relatively low sensitivity to Rayleigh wave dispersion data [17]. Additionally, the layers can be divided into thin layers of equal thickness to standardize the output of the network [34], [40], [47]. These simplifications allow the inversion process to focus on $v_s$, the primary variable of interest for surface wave tomography.\nSupervised learning techniques are then used to train the neural network by minimizing the discrepancy between the predicted and true velocity models. This process is achieved through the following misfit functions:\n$J(d, m; \\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L(f(d_i; \\theta), m_i) \\qquad(3)$\nwhere J denotes the misfit function, N represents the number of samples, f($d_i$;$\\theta$) is the predicted velocity model for the i-th input dispersion data $d_i$, and $m_i$ is the corresponding true velocity model. The function L(\u00b7,\u00b7) quantifies the difference between the predicted and true velocity models, typically using metrics such as mean squared error (MSE) or mean absolute error (MAE). Once trained, the neural network can efficiently conduct inversion mapping without requiring iterative opti-mization or extensive random sampling, which are common in traditional methods."}, {"title": "B. DispFormer for Arbitrary-length Dispersion Data", "content": "Previous studies have successfully applied various neural networks, such as FNNs, CNNs, and ResNets, to learn the inversion mapping between dispersion curves and S-wave velocity profile. However, the intrinsic characteristics of the dispersion data present challenges for training a universal neural network that can adapt to diverse real-world scenarios. A critical factor is the varying period ranges, which are directly related to the depth of the inversion, as longer periods typi-cally provide information about deeper structures [14], [48]. Notably, period ranges can vary significantly across different study areas, and even within a single dataset, the dispersion curves may exhibit distinct effective ranges. Additionally, some dispersion curves may have a lower signal-to-noise ratios, while others may contain missing data due to limitations in the data acquisition and picking processes. As shown in Fig. 1, observed dispersion curves often feature varying ranges, missing data, and low signal-to-noise ratio. Consequently, neural network architectures that rely on fixed-length input data may struggle to accommodate these variations.\nIn this study, we propose DispFormer, a transformer-based architecture designed to handle dispersion data of arbitrary length. Fig. 2 illustrates the workflow of DispFormer, where the dispersion curves are used as input and the corresponding S-wave velocity at each depth is generated as output. Initially, dense layers separately encode the period, phase velocity, and group velocity for each period. To preserve the relative distances between periods, additional position embeddings are incorporated. Transformer blocks are then employed to capture the relationships between different periods of the surface wave dispersion curves, which are essential for modeling the depth-dependent velocity structure. Finally, a dense layer maps the extracted features to the S-wave velocity. The flexibility of DispFormer in handling data of arbitrary length is achieved through two strategies: encoding each period of data inde-pendently and leveraging the transformer architecture, which supports inputs of varying lengths."}, {"title": "C. Workflow for Pre-training and Fine-tuning DispFormer", "content": "The capability of DispFormer to accommodate dispersion data of arbitrary length facilitates the implementation of a pre-training and fine-tuning strategy, significantly enhances its generalization ability. In this study, a global synthetic dataset was created for pre-training. This dataset, with spatial resolution of approximately 1\u00b0 and period ranges spanning from 1 to 100 seconds, is designed to capture crust and upper mantle structures down to depths of about 200 km (Fig. 3a). The resulting pre-trained model provides a robust foundation for subsequent applications.\nIn regional studies with higher spatial resolutions (e.g., < 0.25\u00b0) and varying period ranges (e.g., 10-60 s, 8-80 s), the pre-trained DispFormer can be directly applied to map observed dispersion curves to S-wave velocity, even in the absence of labeled data. This \"zero-shot\" strategy (Fig. 3b) eliminates the need for region-specific training, offering an efficient solution for generating initial models. While the in-version results may not always outperform those of traditional global search methods due to the domain gap between pre-training dataset and regional observation datasets, the velocity models generated by the pre-trained DispFormer remain highly valuable. They can serve as practical initial models or provide meaningful constraints for subsequent inversion processes. In this way, DispFormer functions as a plug-and-play tool to support and enhance traditional inversion techniques.\nWhen labeled data, such as well logs or results from global searches, are available, the pre-trained model can be fine-tuned to better align with the regional data distribution. This \"few-shot\u201d strategy (Fig. 3c) requires only a small subset of labeled data, yet it significantly enhances inversion accuracy. Remarkably, fine-tuned DispFormer achieves inversion results that are comparable to, or even surpass, those of traditional global search methods."}, {"title": "D. Training and Testing Process", "content": "During the training process, DispFormer iteratively mini-mizes the misfit function, J, by adjusting the model parame-ters, \u03b8. Since the velocity varies with depth, the misfit function is defined as the normalized mean squared error (NMSE), which accounts for variations in the relative velocity scale. The NMSE is expressed as [49]:\n$L(f(d; \\theta), m) = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{(f(d_i; \\theta) - m_i)^2}{m_i} \\qquad(4)$\nwhere N denotes the number of samples in the training dataset, and $m_i$ and f($d$; $\\theta$) represent the true and predicted velocity models for the i-th sample, respectively.\nFor optimization, the adaptive moment estimation (Adam) optimizer [50] is employed, with an initial learning rate of 1 \u00d7 10\u22124 during pre-training, and subsequently reduced to 5 \u00d7 10\u22125 during fine-tuning. A step-based learning rate decay scheduler (StepLR) is incorporated to automatically adjust the learning rate as training progresses, thereby improving convergence and stability.\nTo evaluate the predictive performance, the mean absolute error (MAE) is defined as:\n$MAE = \\frac{1}{N} \\sum_{i=1}^{N} |f(d_i; \\theta) - m_i|. \\qquad(5)$"}, {"title": "III. DATA: SYNTHETIC AND REAL", "content": "The pre-training datasets used in this study are entirely synthetic, constructed from an extensive collection of 1-D velocity profiles. To capture diverse and realistic features, a paired global velocity-dispersion dataset is first created based on the updated Earth crust and lithosphere model (LITHO1.0) [51]. The fundamental mode Rayleigh-wave phase and group velocity are computed from these extracted velocity profiles, and the construction process is outlined as follows:\n1) Initially, 40,962 1-D S-wave velocity profiles, extending to a depth of 200 km, are extracted from the LITHO1.0 database. Any water layers in the profiles are removed, and each profile is then converted into an isothermal layer model with a uniform layer thickness of 0.5 km, using linear interpolation.\n2) Given the relatively low sensitivity of Rayleigh wave phase and group velocities to $v_p$ and $\\rho$, $v_p$ for depths above 120 km is computed from $v_s$ using the empirical relationships established by Brocher [52], with a fixed $v_p$/$v_s$ ratio of 1.79 for depths between 120 and 200 km [53]. Additionally, $p$ is derived from $v_p$ using Brocher's empirical relationship [52].\n3) Theoretical Rayleigh wave phase and group velocity dispersion curves for periods ranging from 1 to 100 seconds are generated using the Computer Programs in Seismology (CPS) software package [19]. To ensure comprehensive coverage of real-world scenarios, periods are drawn not only uniformly at integer period positions but also logarithmically and randomly within the period domain [47].\n4) During the pre-training phase, the complete dataset is used to train the model, and the best optimized model is selected as the base model. To improve the gener-alization and stability of the base model, several data augmentation strategies are introduced, including: a) adding random Gaussian noise (approximately 5%), b) zeroing out random segments of the data (approximately 10%), and c) randomly removing either phase velocity or group velocity.\n5) Considering that dispersion curves with varying period ranges are sensitive to different depth ranges, a dynamic calculation approach is adopted to determine the approx-imate depth range based on the wavelengths of observed dispersion curves. The calculation can be formulated as:\n$z_{min} = min(C_1\\lambda_p, C_2\\lambda_g), \\qquad(6)$\n$z_{max} = C_3 max(\\lambda_p, \\lambda_g), \\qquad(7)$\nwhere $z_{min}$ and $z_{max}$ represent the minimum and maximum sensitive depths, respectively. The phase and group wavelengths for each period $T_i$ are given by $\\lambda_p$ = $v_{phase}$ \u00d7 $T_i$ and $\\lambda_g$ = $v_{group}$ \u00d7 $T_i$, where $v_{phase}$ and $v_{group}$ are the phase and group velocities. The constants $C_1$, $C_2$, and $C_3$ are empirical scaling factors, with values of $C_1$ = 1/3, $C_2$ = 1/2, and $C_3$ = 1.1 used in this study."}, {"title": "B. Regional Synthetic Data for Model Validation", "content": "To evaluate the stability and performance of DispFormer, two regional synthetic datasets are generated based on the S-wave velocity profiles from Shen et al. [54] and Shen et al. [55]. The dataset from Shen et al. [54] consists of 6,803 1-D S-wave velocity profiles derived from a tomographic model of the central and western United States, while Shen et al. [55] provides 4,527 profiles from continental China. These datasets are herein referred to as the Central and Western US Dataset (CWD) and the Continental China Dataset (CCD), respectively. The thickness, P-wave velocity and density for both datasets are calculated using the same parametrization strategy as that employed for the pre-training dataset. The dispersion periods are sampled at 1-second intervals, spanning 10 to 60 s for the CWD and 5 to 80 s for the CCD, providing distinct period ranges compared to the pre-training data.\nWhen testing DispFormer on these synthetic datasets, the zero-shot strategy allows direct evaluation without requiring any training data. In contrast, the few-shot strategy involves selecting a small subset (less than 2%) of the regional dataset for fine-tuning, done through a hierarchical selection process. The distribution of the global and regional synthetic datasets is illustrated in Fig. 4."}, {"title": "C. Field Data for Model Testing", "content": "Xiao et al. [56] propose a high-resolution China Seis-mological Reference Model (CSRM) by integrating various seismic data, with extensive surface wave dispersion data being used to derive the S-wave velocity. The dispersion data, spanning periods from 8 to 70 seconds, are extracted from three-component waveforms of 9,361 teleseismic events recorded at 4,193 seismic stations across mainland China. These observations are mapped onto a regular grid, with finer resolution of 0.2 \u00b0 x 0.2 \u00b0for the North-South Seismic Belt and the trans-North China orogen regions, and coarser resolution of 0.4 \u00b0x 0.4 \u00b0for the remainder of the continent.\nFor this study, 12,705 observed dispersion curves are ex-tracted from the original CSRM database and directly used to construct the test dataset. Fig. 1 presents examples of the observed dataset, which exhibit issues such as varying period ranges, missing data, and low signal-to-noise ratios. Additionally, the corresponding reference velocity profiles are interpolated into 0.5 km thick layers, with a maximum depth of 120 km."}, {"title": "IV. APPLICATION AND VERIFICATION", "content": "This section conducts zero-shot tests on two regional syn-thetic datasets using the pre-trained DispFormer. Since Disp-Former is designed to process dispersion data of arbitrary length, the model directly ingests dispersion curves from the CWD and CCD datasets, with period ranges of 10 to 60 s for CWD and 5 to 80 s for CCD, to obtain the corresponding inverted S-wave velocity profiles.\nFig. 5 shows slices of the true and inverted S-wave velocity models at depths of 20, 40, 50, and 90 km, derived from the CWD dataset. The first column (Figs. 5a, e, i, and m) displays the target velocity model, while the second column shows the interpolated model obtained from the LITHO1.0 database, which is also used for pre-training the DispFormer model. The third column presents the inversion results from the pre-trained DispFormer with zero-shot strategy. The final column illustrates the error distributions between the target model and both the interpolated LITHO1.0 model and the zero-shot DispFormer's results. This highlights that the error distribution for the zero-shot DispFormer is much more tightly centered around zero, with fewer large error samples compared to the interpolated model.\nFurthermore, the Continental China dataset, with its broader period range, enables the inversion of S-wave velocities at greater depths. Fig. 6 shows the true and inverted results at depths of 30, 55, 100, and 170 km based on this dataset. The results clearly demonstrate that the zero-shot DispFormer more accurately captures the lower-velocity anomalies in the Tibetan Plateau area.\nTherefore, the zero-shot DispFormer provides a robust, plug-and-play alternative for generating initial models in traditional inversion frameworks."}, {"title": "B. Few-shot DispFormer for Improved Results", "content": "The adaptability of a pre-trained DispFormer model to local datasets can be further enhanced through fine-tuning when labeled data is accessible. To evaluate the effectiveness of few-shot learning, experiments are carried out on two regional datasets. The inversion results obtained by fine-tuning with limited labeled data are contrasted with those from a global search algorithm. For the global search baseline, a particle swarm optimization (PSO) algorithm is implemented [57], with a search range of \u00b1 0.6 km around the true velocity model and an iteration limit of 2000.\nFig. 7 compares the inverted S-wave velocity models ob-tained from the PSO and few-shot DispFormer at depths of 20, 40, 50, and 90 km using the CWD dataset. The first column shows the true S-wave velocity model, while the second column presents the inversion results using the PSO method. The third and fourth columns display the inverted results from the few-shot DispFormer, fine-tuned with 10 and 108 labeled samples, respectively. Similarly, Fig. 8 provides a comparison using the CCD dataset, with fine-tuning performed using 36 and 180 labeled samples.\nThese findings highlight the potential of few-shot DispFormer to efficiently generate high-quality inversion models, even with limited labeled data, rendering it highly valuable for practical applications where labeled data is scarce."}, {"title": "C. Field Case", "content": "The use of real-world dispersion data presents several challenges, including varying period ranges, missing data, and low signal-to-noise ratios (fig. 1). Traditional deep learning-based inversion frameworks usually require alignment between observation and training datasets, which hinders the applica-tion of models trained on one dataset to others. In contrast, DispFormer is specifically designed to handle data of arbitrary length, making it adaptable to datasets with varying period ranges. Furthermore, DispFormer improves its generalization capability by integrating pre-training, fine-tuning, and data augmentation techniques. These features make DispFormer particularly suitable for real-world data applications.\nTo evaluate the performance of DispFromer, the pre-trained model was tested via both zero-shot and few-shot approaches on the CSRM dataset. The slices of the reference model and inverted results at depths of 10, 40, 60, and 100 km are shown in Fig. 9. The first column displays the reference model from Xiao et al. [56], while the second column shows the inversion results using zero-shot DispFormer. The third and fourth columns present the results after fine-tuning with 38 and 114 labeled samples, respectively. It should be noted that the velocity profiles used for fine-tuning were randomly selected from the reference model, and the corresponding dispersion curves were synthesized using the CPS program. The MAE between the inversion results and the reference model are shown in the lower left of each sub-figure. The results demon-strate that zero-shot DispFormer can accurately replicate the reference model, capturing large-scale anomalies such as the low-velocity zone of the Tibetan Plateau. Furthermore, fine-tuning with as little as 1% labeled data significantly enhances accuracy, particularly in resolving finer structural details.\nIn real data applications, since there is no true model available for direct comparison, the accuracy of inversion results is typically assessed by calculating the data residuals between synthetic dispersion curves derived from the inversion results and the actual observed dispersion curves. To this end, Fig. 10 compares the data residual distributions for the CSRM reference model, zero-shot DispFormer, and Few-shot Disp-Former (fine-tuned with 114 labeled samples). The comparison reveals that the inversion results from zero-shot DispFormer closely match the data domain of the CSRM reference model, while Few-shot DispFormer shows even greater alignment with the observed data. This ability to handle the complexities of real-world datasets highlights the potential of DispFormer as a robust and adaptable tool for large-scale geophysical inversions in diverse applications."}, {"title": "V. DISCUSSION", "content": "The depth alignment strategy employed during training dynamically aligns the period ranges of the dispersion curves with their corresponding sensitivity depths, thereby signifi-cantly improving the zero-shot performance of DispFormer. This strategy relies on empirical formulas for $z_{min}$ and $z_{max}$ to compute the inversion depth range, allowing the model to capture depth-specific features which is consistent with the physical sensitivity of the observed dispersion data. In traditional deep learning methods, fixed inversion depths are commonly utilized. However, these may not align effectively with the specific depths sensitive to the observed data. As a consequence, this can potentially hinder the model's per-formance when applied to regional datasets. In contrast, by dynamically calculating the range of inversion depths, this strategy narrows the solution space and allows the model to learn more relevant features. As shown in Table III, a comparison of the MAE between zero-shot DispFormer mod-els trained with and without depth alignment demonstrates that the alignment strategy consistently results in lower MAE across two regional synthetic datasets. By embedding physical constraints into the training process, this strategy not only improves the generalization ability of the network, but also highlights the importance of physics-informed preprocessing in data-driven inversion frameworks."}, {"title": "VI. CONCLUSION", "content": "This study introduces DispFormer, a transformer-based neu-ral network designed to invert $v_s$ models from Rayleigh-wave phase and/or group dispersion curves. DispFormer processes the dispersion data for each period independently, extract-ing period-related features via transformer blocks and subse-quently mapping these features to $v_s$ profile. The specially designed architecture supports dispersion data of arbitrary length, making it directly applicable to real-world datasets with varying lengths, without requiring adjustments to the network structure or alignment of training and test data.\nTo evaluate its performance, DispFormer is first pre-trained on the global synthetic LITHO1.0 dataset and then applied to two regional synthetic datasets in both zero-shot and few-shot modes. The synthetic tests demonstrate that the performance of zero-shot DispFormer is very close to that of traditional global search methods, making it a reliable tool for generat-ing high-quality initial models. Furthermore, when fine-tuned with limited labeled data, DispFormer achieved even better performance. Both synthetic and real data tests show that the few-shot mode of DispFormer outperforms traditional global search methods, delivering comparable or superior results with limited labeled data. Additionally, the real case study further highlights the versatility and high generalizability of DispFormer, which can be easily applied to complex datasets with varying period ranges, missing data, and low signal-to-noise ratios.\nIn summary, DispFormer, with its zero-shot capability for generating improved initial models and few-shot fine-tuning for superior inversion results, presents a promising approach for broader applications in surface wave tomography."}]}