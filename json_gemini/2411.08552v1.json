{"title": "Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with Variational Quantum Circuits", "authors": ["Jun Qi", "Chao-Han Yang", "Samuel Yen-Chi Chen", "Pin-Yu Chen", "Hector Zenil", "Jesper Tegner"], "abstract": "Quantum Machine Learning (QML) offers tremendous potential but is currently limited by the availability of qubits. We introduce an innovative approach that utilizes pre-trained neural networks to enhance Variational Quantum Circuits (VQC). This technique effectively separates approximation error from qubit count and removes the need for restrictive conditions, making QML more viable for real-world applications. Our method significantly improves parameter optimization for VQC while delivering notable gains in representation and generalization capabilities, as evidenced by rigorous theoretical analysis and extensive empirical testing on quantum dot classification tasks. Moreover, our results extend to applications such as human genome analysis, demonstrating the broad applicability of our approach. By addressing the constraints of current quantum hardware, our work paves the way for a new era of advanced QML applications, unlocking the full potential of quantum computing in fields such as machine learning, materials science, medicine, mimetics, and various interdisciplinary areas.", "sections": [{"title": "1. Introduction", "content": "Quantum machine learning (QML) is an emerging interdisciplinary field that integrates the principles of quantum computing and machine learning [1-6]. With the rapid development of quantum computing hardware, we are in the noisy intermediate-scale quantum (NISQ) era that admits only a few hundred physical qubits to implement QML algorithms on NISQ devices in the presence of high levels of quantum noise [7-9]. Variational quantum circuit (VQC) is a promising building block for a QML architecture for processing data and making predictions [10-12]. The VQC block is composed of parameterized quantum circuits that can be optimized by employing a stochastic gradient descent (SGD) algorithm to minimize a loss function in a black-propagation manner [13-16]. The VQC's resilience against quantum noise errors admits it to be applicable in many QML applications [17-26].\nHowever, the number of available qubits constrains the VQC's representation power, and the amount of training data limits its generalization power [27-29]. Based on pre-trained neural networks, our theoretical findings introduce new bounds that allow the representation power independent of the number of qubits. We enhance the generalization power by requiring only a smaller target dataset. Notably, this target dataset pertains to quantum data that is significantly different from the source data used to train a classical neural network. Thus, this work focuses on both theoretical and empirical advancements in using pre-trained neural networks for VQC, including:\n(i) Demonstrating that pre-trained neural networks can enhance the representation and generalization powers of VQC blocks.\n(ii) Validating our theoretical insights with experimental results from semiconductor quantum dot classification and human genome transcription factor binding site (TFBS) prediction.\nUnlike the end-to-end learning approach in hybrid quantum-classical architectures, we keep the pre-trained neural network's parameters fixed without further tuning. This shows that this can enhance the VQC's representation and generalization capabilities. This strategy allows us to utilize large pre-trained neural networks, including cutting- edge large language models with frozen parameters, to scale up QML using VQC blocks. More importantly, we are the first to establish the theoretical benefits of using pre- trained neural networks for VQC and to pioneer their application in quantum data scenarios.\nA classical neural network $X$ is pre-trained with another neural network $Y$ following an end-to-end learning pipeline on a generic dataset $D_A$ for a generic task $T_A$. The well-trained neural network Pre-$X$ is then transferred to a hybrid quantum-classical model comprised of classical module Pre-$X$ and a quantum component VQC. In the fine-tuning stage, only the VQC's parameters need further update on a target dataset $D_B$ given a target task $T_B$. Besides, the pre-trained neural network is closely related to the state-of-the-art foundation model of generative artificial intelligence, e.g., large language models like Generative Pre-trained Transformers (GPT) [30, 31], which can generate context-enriched features before going through the VQC block.\nRecent studies have shown that hybrid quantum-classical models have achieved remarkable empirical results in numerous machine-learning applications. These models were developed using an end-to-end learning approach, where the parameters of both classical and quantum models are jointly optimized with the training data. However, in our work, we keep the parameters of the classical neural network fixed and only allow"}, {"title": "2. Results", "content": "2.1. Preliminaries\nBefore delving into our theoretical and empirical results, we first introduce the VQC architecture representing the QML model. As shown in component (b) of Figure 2,\nthe VQC block consists of three components: (a) Tensor Product Encoding (TPE), (b) Parametric Quantum Circuit (PQC), and (c) Measurement.\nGiven $U$ qubits, we employ $U$ Pauli-Y gates $R_y(\\cdot)$ to constitute a TPE operation, which transforms a classical input vector $x = [x_1,x_2, ..., x_U]^\\top$ into their corresponding quantum state $|x\\rangle = [|x_1\\rangle, |x_2\\rangle, ...,|x_U\\rangle]^\\top$ through adopting a one-to-one mapping as:\n$\\langle x| = \\bigotimes_{i=1}^{U} R_y(\\phi(x_i)) |0\\rangle^{\\otimes U} = \\bigotimes_{i=1}^{U} \\begin{bmatrix} \\cos(\\frac{\\phi(x_i)}{2}) \\\\  \\sin(\\frac{\\phi(x_i)}{2})\\end{bmatrix}| = \\bigotimes \\begin{bmatrix} \\cos(\\frac{\\phi(x_U)}{2}) \\\\  \\sin(\\frac{\\phi(x_U)}{2})\\end{bmatrix}|$,\nwhere $\\phi(\\cdot)$ is a non-linear function like a sigmoid function $\\sigma(x_i) = \\frac{1}{1+\\exp(-x_i)}$ such that $\\sigma(x_i)$ is restricted to the domain of [0,1] and we can establish a one-to-one mapping between $x$ and $|x\\rangle$.\nIn the PQC framework, we first implement quantum entanglement through a series of two-qubit controlled-not (CNOT) gates and then leverage single-qubit Pauli rotation gates $R_x(\\alpha_i)$, $R_y(\\beta_i)$ and $R_z(\\gamma_i)$ with trainable parameters of qubit rotation angles $\\alpha_i$, $\\beta_i$, $\\gamma_i$. The PQC model in the green dashed square is repeatedly copied to build up a deep PQC architecture, which outputs $U$ quantum states $|o_1\\rangle$, $|o_2\\rangle$, ..., $|o_U\\rangle$. The quantum measurement returns the expected values $\\langle \\sigma_i^{(z)} \\rangle = \\langle o_i | \\sigma_i^{(z)} | o_i \\rangle$ associated with the Pauli-Z operators $\\sigma_i^{(z)}$ for the $i^{th}$ quantum channel. The expected values $\\langle \\sigma_i^{(z)} \\rangle = \\langle o_i | \\sigma_i^{(z)} | o_i \\rangle$ can be approximated by using an arithmetic average of $M$ times' quantum measurement. The resulting values $\\langle \\sigma_i^{(z)} \\rangle$ are connected to a softmax operation with a cross-entropy loss to calculate gradients for the update of VQC's parameters.\n2.2. Theoretical results\nFigure 2 illustrates Pre-$X$+VQC with a hybrid quantum-classical architecture that consists of a pre-trained classical neural network and a VQC block, which are separately shown in components (a) and (b). The pre-trained classical neural network transforms D-dimensional input vectors $x = [x_1, x_2,..., x_D]$ into context-enriched features $f_x(x)$. The features $f_x(x)$ are then turned into quantum states $R_y(\\phi(f_x (x_i)))|0\\rangle$ through the TPE operation in the VQC block. The VQC block transforms the quantum states into their corresponding classical outputs $\\langle \\sigma_i^{(z)} \\rangle$ that are connected to a softmax operation with the cross-entropy loss. The VQC's parameters are adjustable using the SGD algorithm to adapt to the input training data. In contrast, the pre-trained neural network's parameters are frozen without participating in the VQC fine-tuning process.\nNext, we characterize the Pre-$X$ +VQC's representation and generalization powers. Mathematically, given a functional class of neural networks $F_X$ and a VQC functional class $F_V$, we define a hybrid quantum-classical model as $f_{X+V} = f_V \\circ f_X$, where a pre-trained neural network $f_X \\in F_X$ and $f_V \\in F_V$. Additionally, we separately use the symbols $f$, $\\hat{f}$, and $f^*$ to represent the empirical risk minimizer, actual algorithm- returned hypothesis, and optimal hypothesis. Given an underlying distribution $D$, for a smooth target operator $h_D$ and a loss function $l$ to measure the distance between $h_D$ and an operator $f$, we define an expected loss as:\n$L_D(f) := E_{x\\sim D} [l(h_D(x)), f(x)]$.\nWe further assume that the training dataset $S$ contains the samples ${X_1, X_2, ..., X_{|S|}}$,\nthe expected loss $L_D(f)$ can be approximated by an empirical loss $L_S(f)$ as:\n$L_S(f) := \\frac{1}{|S|} \\sum_{n=1}^{|S|} l(h_D (x_n), f(x_n))$.\nThen, we conduct an error performance analysis by decomposing the expected loss into the sum of approximation error, estimation error, and optimization error, which is\n$L_D(f_{X+V}) = \\mathcal{L_D}(f_{X+V}) + \\mathcal{L_D}(\\hat{f}_{X+V}) - \\mathcal{L_D}(f_{X+V}) + \\mathcal{L_D}(f_{X+V}) - \\mathcal{L_D}(\\hat{f}_{X+V})$\n$= \\mathcal{E}_{app} + \\mathcal{E}_{est} + \\mathcal{C}_{opt}$,\nwhere the Pre-$X$ +VQC's optimal hypothesis $f_{X+V}^* = arg \\min_{f_V\\in F_V} L_D(f_V \\circ f_X)$ and its empirical risk minimizer $\\hat{f}_{X+V} = arg \\min_{f_V\\in F_V} L_S (f_V\\circ f_X)$, and the symbols $\\mathcal{E}_{app}$, $\\mathcal{E}_{est}$ and $\\mathcal{C}_{opt}$ denote approximation error, estimation error, and optimization error, respectively.\nWe first upper bound the approximation error associated with its representation power as presented in Theorem 1, and then we derive the upper bounds on the estimation error and the optimization error as shown in Theorem 2 and 3 that jointly correspond to the generalization power.\nTheorem 1 Given a smooth target operator $h_D$ and $U$ quantum channels for the VQC model, for a pre-trained neural network $f_X \\in F_X$ conducted on a source training dataset $D_A$, we can find a VQC model $f_V \\in F_V$ such that for a cross-entropy loss function"}, {"title": "3. Discussion", "content": "This work demonstrates the theoretical and experimental benefits of pre-trained neural networks for the VQC block, showcasing improved representation and generalization powers. We first leverage the theoretical error performance analysis to derive upper bounds on the approximation error, estimation error, and optimization error for the Pre-$X$+VQC. Our theoretical results suggest that the approximation error does not rely on the number of qubits. Instead, it corresponds to the model complexity of pre- trained neural networks and the number of source training data, which can be scaled to attain a lower approximation error. Besides, the estimation and optimization errors are jointly related to the generalization power, mainly determined by the VQC's model complexity, which is associated with the number of qubits and target data. In particular, our QML approach can lead to an exponential convergence rate in the VQC's training process, making the training of VQC easier without the PL condition.\nWe conduct two binary classification tasks with target quantum data to corroborate our theoretical results. Regarding charge stability diagrams in semiconductor quantum dots, we highlight that pre-trained ResNet models can lead to better VQC representation and generalization powers, even achieving better empirical performance than their classical counterparts. As for the TFBS prediction experiments, we demonstrate that a pre-trained TTN model brings empirical performance gain in the generalization capability. The two experimental tasks corroborate our theoretical understanding of our QML approach. Although the performance gain becomes relatively marginal compared to its classical counterpart, the pre-trained classical neural networks can significantly improve the VQC's empirical performance.\nPrior works, such as a theoretical analysis of the pre-trained neural networks for VQC and its comprehensive experiments with quantum data, have yet to be delivered. Our theoretical understanding of the proposed QML approach lays a solid foundation for quantum machine learning use cases, particularly in the era of generative artificial intelligence, where pre-trained deep learning models, like large language models, are widely utilized as foundation models. Furthermore, we discuss the following issues in detail to highlight the significance of this work.\n3.1. Which error component is dominant?\nOur previous theoretical work [32] of the VQC's error performance analysis shows that a large target dataset leads to an arbitrarily small estimation error, making the approximation and optimization errors dominate the error components.\nIn this work, as for the upper bound on the approximation error, we demonstrate that the pre-trained neural networks for VQC can replace the reliance on the number of qubits with a term related to the pre-trained neural network's complexity and the amount of source training data. By scaling the amount of source training data and the pre-trained neural network's complexity, we can reduce the approximation error to a small value.\nOn the other hand, regarding the optimization error, we alleviate the PL condition for the VQC setup by providing an upper bound on the assumptions of approximation linearity and gradient bound. We also achieve exponential convergence rates in the training stage by controlling the constant constraints and delicately setting the learning rates."}, {"title": "4. Methods", "content": "This section supports the theoretical results in the main text, including the pre-trained ResNet models, TTN, cross-entropy loss, and PCA. In the Appendix, we provide a sketch of proofs for theorems.\n4.1. Pre-trained ResNet models\nResNet stands for Residual Neural Network, a robust convolutional neural network architecture [44] employed in deep learning, particularly for computer vision tasks. In particular, ResNet18 and ResNet50 are two pre-trained ResNet architectures that differ in size and complexity. ResNet18 is a smaller and faster model with around 11 million parameters, which is a good choice when computational resources are limited or when an efficient model for inference is needed. ResNet50 is a more complex model with around 25 million parameters, which can be generalized to diverse data scenarios but requires more computational power and training time.\n4.2. Tensor-train network\nTensor-train network (TTN) [42], also known as matrix product state [45], is a type of tensor network architecture used in various scientific fields, particularly machine learning and quantum physics. They excel at representing high-dimensional tensors in a compressed and efficient manner. The TTN factorizes a high-dimensional tensor into a product of lower-dimensional tensors, typically matrices or three-index tensors, arranged in a specific chain-like structure.\n4.3. Cross-entropy loss function\nThe cross-entropy loss function [46] is a popular tool used in machine learning for classification problems. It helps us measure a classification model's performance by indicating the difference between the predicted probabilities and the actual labels. The"}, {"title": "8. COMPETING INTERESTS", "content": "The authors declare no Competing Financial or Non-Financial Interests."}, {"title": "9. ADDITIONAL INFORMATION", "content": "The views expressed in this article are those of the authors and do not represent the views of Wells Fargo. This article is for informational purposes only. Nothing contained in this article should be construed as investment advice. Wells Fargo makes no express or implied warranties and disclaims all legal, tax, and accounting implications related to this article. Correspondence and requests for materials should be addressed to Dr. Jun Qi and Prof. Jesper Tegner."}, {"title": "Appendix", "content": "Sketch of the proof of the main theorems\nProof of Theorem 1. Given a target function $h_D$, we define a pre-trained classical neural network $f_X$ and an optimal VQC operator $f^*_V$, the expected loss $L_D(f_{X+V}) = f_V \\circ f_X$ is denoted as:\n$\\epsilon_{app} = L_D(f_{X+V}) = E_{x\\sim D} [l (f^*_V\\circ f_X(x), h_D(x))]$.\nThe above equation can be further decomposed into the sum of two terms:\n$\\epsilon_{app} = E_{x\\sim D} [l (f^*_V\\circ f_X(x), f^*_V \\circ \\hat{f}_X(x))] + (E_{x\\sim D} [l (f^*_V\\circ f_X(x), h_D(x))] \u2013 E_{x\\sim D} [l (f^*_V\\circ f_X(x), f^*_V \\circ \\hat{f}_X(x))]).$\nwhere we take the cross-entropy as the loss function $l$ in Term 1 and Term 2, then we can further derive that\nTerm 1 = $E_{x\\sim D} [l (f^*_V\\circ f_X(x), f^*_V \\circ \\hat{f}_X(x))] = E_{x\\sim D}[ -f^*_V \\circ f_X(x)log(\\frac{f^*_V \\circ \\hat{f}_X(x)}{1})] \\leq E_{x\\sim D} (-f^*_V \\circ f_X(x)) ((\\frac{f^*_V \\circ \\hat{f}_X(x)}{1}) -1) =  E_{x\\sim D}|f^*_V \\circ f_X(x) - f^*_V \\circ \\hat{f}_X(x)| \\leq E_{x\\sim D} sup_{f_X\\in F_X} |f^*_V \\circ f_X(x) - f^*_V \\circ \\hat{f}_X(x)|$.\nThe last term can be further upper bounded with an empirical Rademacher complexity $R_S(X)$, which is related to the upper bound as $O(\\sqrt{\\frac{C(F_X)}{|D_A|}})$, where $C(F_X)$ represents a measurement of the intrinsic complexity of the functional class $F_X$, and $D_A$ refers to the source dataset. Thus, we can attain the upper bound as:\nTerm 1 = $E_{x\\sim D} [l (f^*_V\\circ f_X(x), f^*_V \\circ \\hat{f}_X(x))] = \\Tilde{O}(\\sqrt{\\frac{C(F_X)}{|D_A|}})$.\nOn the other hand,\nTerm 2 = $E_{x\\sim D} [l (f^*_V\\circ f_X(x), h_D(x))] \u2013 E_{x\\sim D} [l (f^*_V\\circ f_X(x), f^*_V \\circ \\hat{f}_X(x))] = E_{x\\sim D}[ -f^*_V \\circ f_X(x)log(\\frac{h_D(x)}{1}) + f^*_V \\circ f_X(x)log(\\frac{f^*_V \\circ \\hat{f}_X(x)}{1})] \\leq E_{x\\sim D}|f^*_V \\circ f_X(x) (log (f^*_V \\circ \\hat{f}_X(x)) - log(h_D(x)))|$.\nSince the quantum circuit $f^*_V$ can be expressed as an exponential form, based on the universal approximation theory of quantum neural networks, we can further derive that\n$|log(f^*_V \\circ \\hat{f}_X(x)) \u2013 log(h_D(x))| \\leq \\frac{1}{\\sqrt{M}}$.\nThen, we finally derive that\nTerm 2 $\\leq E_{x\\sim D}|f^*_V \\circ f_X(x) (log (f^*_V \\circ \\hat{f}_X(x)) - log(h_D(x)))| = O(\\frac{1}{\\sqrt{M}})$.\nProof of Theorem 2. Given the target dataset $D_B$ for the VQC's training, the estimation error $\\epsilon_{est}$ is only related to the VQC's model complexity because we aim to update the VQC's model parameters and freeze the pre-trained model's parameters. Then, we can directly derive that\n$\\epsilon_{est} = \\Tilde{O}(\\sqrt{\\frac{C(F_V)}{|D_B|}})$.\nProof of Theorem 3. Please assume that the VQC's parameters are represented as $\\theta$; we denote $\\theta_t$ as the VQC's parameters at the epoch $t$ during its training stage, which iteratively approximates the optimal parameters $\\theta^*$. Given the target dataset $D_B$ and a learning rate $\\eta$, we use the empirical loss $L_S(\\cdot)$ to approximate the expected loss $L_D(\\cdot)$ such that an SGD algorithm returns\n$r^2_{t+1} = ||\\theta_{t+1} - \\theta^* ||^2_2 \\leq ||\\theta_t \u2013 \\eta\\nabla L_S(\\theta_t) \u2013 \\theta^* ||^2_2 = r^2_{t} + 2\\eta <\\nabla L_S(\\theta_t), \\theta^* \u2013 \\theta_t> + \\eta^2 ||\\nabla L_S(\\theta_t)||^2_2$.\nTo further upper bound $r^2_{t+1}$, given the constants $\\beta, R, L$ defined in Assumptions 1 and 2, we employ Assumptions 1 and 2 to separately upper bound $<\\nabla L_S(\\theta_t), \\theta^* \u2013 \\theta_t>$ and $||\\nabla L_S(\\theta_t)||^2_2$ as:\n(i) To upper bound the term $<\\nabla L_S(\\theta_t), \\theta^* \u2013 \\theta_t>$, based on Assumption 1 regarding the approximate convexity theory for the VQC's parameters, we have\n$<\\nabla L_S(\\theta_t), \\theta^* \u2013 \\theta_t> \\leq L_S(\\theta^*) \u2013 L_S(\\theta_t) + 4\\beta R^2$.\n(ii) To upper bound the term $||\\nabla L_S(\\theta_t)||^2_2$, based on Assumption 2 about the gradient bound on the VQC's parameters, we have\n$||\\nabla L_S(\\theta_t)||^2_2 \\leq L^2 + \\beta^2 R^2$.\nTherefore, at the epoch $t + 1$ of total iterations $T_{sgd}$, we derive that\nr^2_{t+1} $\\leq r^2_t + 2\\eta (L_S(\\theta^*) \u2013 L_S(\\theta_t) + 4\\beta R^2) + \\eta^2 (L^2 + \\beta^2 R^2) \\leq r^2_0 + 2\\eta (\\sum_{t=0}^{T_{sgd} - 1} L_S(\\theta^*) \u2013 L_S(\\theta_t)) + 8 \\eta T_{sgd}\\beta R^2 + \\eta^2 T_{sgd}(L^2 + \\beta^2 R^2)$.\nBy rearranging the last inequality, we have\n$\\frac{r^2_0 - r^2_{T_{sgd}}}{2\\eta T_{sgd}} + 4\\beta R^2 + \\frac{\\eta}{2} (L^2 + \\beta^2 R^2) \\geq \\frac{1}{T_{sgd}} \\sum_{t=0}^{T_{sgd} - 1} L_S(\\theta^*) \u2013 L_S(\\theta_t) \\geq min_{t=0,...,T_{sgd} - 1} L_S(\\theta^*) \u2013 L_S(\\theta_t)$.\nNow, using the step size $\\eta = \\frac{1}{\\sqrt{T_{sgd}}}(\\frac{R}{\\sqrt{L^2 + \\beta^2 R^2}})$, we observe that\n$\\frac{r^2_0 - r^2_{T_{sgd}}}{2\\eta T_{sgd}} + \\frac{\\eta}{2} (L^2 + \\beta^2 R^2) \\leq \\frac{R^2}{2\\eta T_{sgd}} \\sqrt{\\frac{L^2 + \\beta^2 R^2}{R^2}} \\leq \\frac{1}{T_{sgd}} (L^2 + \\beta^2 R^2) = R(\\frac{\\sqrt{L^2 + \\beta^2 R^2}}{T_{sgd}})$.\nfrom which the upper bound for the optimization error in Theorem 3 follows, where\n$\\epsilon_{opt} \\leq \\beta R^2 + R(\\frac{\\sqrt{L^2 + \\beta^2 R^2}}{T_{sgd}})."}]}