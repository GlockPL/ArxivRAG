{"title": "Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with Test-time Refinement", "authors": ["Shengyu Chen", "Peyman Givi", "Can Zheng", "Xiaowei Jia"], "abstract": "The precise simulation of turbulent flows holds immense significance across various scientific and engineering domains, including climate science, freshwater science, and energy-efficient manufacturing. Within the realm of simulating turbulent flows, large eddy simulation (LES) has emerged as a prevalent alternative to direct numerical simulation (DNS), offering computational efficiency. However, LES cannot accurately capture the full spectrum of turbulent transport scales and is present only at a lower spatial resolution. Reconstructing high-fidelity DNS data from the lower-resolution LES data is essential for numerous applications, but it poses significant challenges to existing super-resolution techniques, primarily due to the complex spatio-temporal nature of turbulent flows. This paper proposes a novel flow reconstruction approach that leverages physical knowledge to model flow dynamics. Different from traditional super-resolution techniques, the proposed approach uses LES data only in the testing phase through a degradation-based refinement approach to enforce physical constraints and mitigate cumulative reconstruction errors over time. Furthermore, a feature sampling strategy is developed to enable flow data reconstruction across different resolutions. The results on two distinct sets of turbulent flow data indicate the effectiveness of the proposed method in reconstructing high-resolution DNS data, preserving the inherent physical attributes of flow transport, and achieving DNS reconstruction at different resolutions.", "sections": [{"title": "1 Introduction", "content": "Advances in computational fluid dynamics (CFD) have significantly impacted many scientific and engineering domains. In the clean energy sector, CFD is crucial for enhancing power generation and distribution, which includes designing high-efficiency wind turbines and strategically placing turbines to maximize energy harvest. CFD is also important for developing safer and more efficient cooling systems used in thermal and nuclear power plants. In the aerospace industry, CFD is used to analyze aerodynamic forces and thermal effects on aircraft, rockets, and spacecraft. It plays a vital role in simulating and optimizing airflow around wings, fuselages, and engine components. The optimization helps improve fuel efficiency, reduce drag, enhance maneuverability, and increase safety. Additionally, CFD is critically needed in many environmental science problems, e.g., predicting pollution patterns, refining emission controls, and assessing the environmental impact of infrastructure. It is especially important for studying ocean currents and their impact on climate change. By simulating complex ocean dynamics, including factors such as temperature and salinity and their interactions with atmospheric conditions, CFD helps scientists understand and predict changes in major oceanic systems, such as the Gulf Stream [1] or the El Ni\u00f1o phenomenon [2]. These simulations are vital for predicting climate change effects, assessing impacts on marine ecosystems, and informing policy decisions related to climate change mitigation and adaptation [3].\nIn particular, turbulent flows often need to be simulated at high spatial resolutions and over long periods in many CFD tasks (e.g., simulating fine-level cloud behaviors for climate models [4]). Direct Numerical Simulation (DNS) has been widely considered as the method with the highest fidelity in creating turbulence simulations, but it is computationally intensive and thus limited in producing long-term simulations at fine spatial scales [5]. As an alternative with reduced computational cost, large eddy simulation (LES) has gained popularity. LES focuses on the larger scale energy-containing eddies while filtering out the smaller scales of transport [6]. Consequently, LES can be performed on coarser grids compared to DNS, but at the expense of reduced fidelity [7].\nMachine learning methods, including super-resolution (SR) techniques [8], have been advocated as a solution for reconstructing highly detailed DNS from LES data. These approaches have demonstrated remarkable success in enhancing high-resolution data across various commercial applications. Most contemporary SR models utilize convolutional network layers (CNNs) [9] to extract meaningful spatial features, which are then used to recover high-resolution images through non-linear transformation. From the initial end-to-end convolutional SRCNN model [10], numerous researchers have incorporated additional structural elements, including skip-connections [11, 12, 13, 14], channel attention [15], adversarial training objectives [16, 17, 18, 19, 20, 21, 22], implicit neural representation [23, 24, 25, 26], and more recently, Transformer-based SR structures [27, 28, 29, 30, 31, 32].\nGiven their prominence in the field of computer vision, SR techniques are gaining popularity for reconstructing high-resolution turbulence data (e.g., DNS) from low-resolution turbulence data (e.g., LES) of lower fidelity [33, 34, 35, 36, 37, 38]. However, these techniques remain limited in recovering fine-level flow patterns due to the absence of physical information (i.e., small-scale flow transport) in the input low-resolution data. In an effort to preserve fine-scale physical patterns and capture the temporal dependencies in simulating turbulence data, an alternative sequential prediction method has been explored to simulate high-resolution flow data from historical high-resolution data without referring to low-resolution data. These approaches utilize temporal modeling structures to capture underlying dynamics expressed by governing partial differential equations (PDEs) i.e., the Navier-Stokes equation, through the utilization of neural operators [39, 40, 25], or through the recurrent unit that directly encodes the Navier-Stokes equation [41]. Although these methods can better preserve fine-level physical patterns from input high-resolution data, they still rely on data-driven learning structures to simulate complex temporal dynamics and can be susceptible to cumulative errors over time. Furthermore, existing SR and sequential methods for turbulent flows often assume a predefined grid structure and lack the ability to simulate flow variables at arbitrary positions and at different scales. These models need to be re-trained to accommodate a target grid structure or spatial resolution that differs from the historical data.\nTo address these challenges, a novel physics-guided neural network named \"Super-Resolution through Test-time Refinement\" (SR-TR) has been developed. The SR-TR method is composed of two main components: the degradation-based refinement and the continuous spatial transition unit (CSTU). Unlike conventional SR techniques that directly reconstruct high-resolution data from low-resolution data, SR-TR adopts the sequential prediction approach to better preserve fine-level patterns in predicting the high-resolution data while utilizing the low-resolution flow data to reduce the accumulated errors in the testing phase. In particular, SR-TR automatically adjusts the reconstructed high-resolution data in the testing phase by preserving the consistency with the available low-resolution data and known physical constraints. The CSTU structure is further designed to better capture the continuous spatial and temporal dynamics of turbulent flows during the sequential prediction process. The CSTU structure captures the fluid dynamics by using the physics-guided recurrent unit (PRU) [41], which is well-suited for modeling the behavior of turbulent flows driven by complex PDEs. Additionally, CSTU facilitates the reconstruction of flow data at arbitrary locations and scales by integrating the implicit neural representation (INR) method. This method enables the CSTU to operate effectively across different resolutions, adding versatility to the SR-TR method.\nComprehensive evaluations of the SR-TR method have been conducted on two distinct turbulent flow datasets: (1) the forced isotropic turbulent (FIT) flow [42], and (2) the Taylor-Green vortex (TGV) flow [43]. The results of the consistency assessments demonstrate the capability of the SR-TR capability in terms of reconstruction performance over time and across different resolutions. Furthermore, the effectiveness of each component of the methodology is demonstrated both qualitatively and quantitatively. Our implementation is publicly available\u00b9."}, {"title": "2 Problem Definition and Preliminaries", "content": "This study focuses on simulating the transport of unsteady, three-dimensional turbulent flows. In all cases, the flow is considered to be Newtonian and incompressible, with a constant density. In this formulation, the spatial coordinates are represented by the vector x = x,y,z, and time is denoted as t. The velocity field is denoted by Q(x,t), with its three components u(x, t), v(x, t), w(x, t) along the three flow directions x, y, z, respectively. The pressure, density, and dynamic viscosity are represented by p(x,t), \\rho(x,t), and \\nu, respectively. During the training process, the provided DNS data are available at a regular time interval d, denoted as Qd = {Qd(t)}, where t belongs to the time range {to, to + d,...,to + Kd}. The objective is to predict high-resolution DNS data following the provided historical data, specifically at time instances {to+(K+1)d,..., to+Md}. We also have access to low-resolution LES data, Q' = {Q'(t)} for t \u2208 [to, to + MS]. As the LES data can be generated at a lower computational cost, they are available for both the training and testing periods and are often generated at a higher frequency. In addition to the LES and DNS data, we assume the access to a small number of DNS data samples at an even higher resolution than Qd, denoted as Q = {Qh(t)}. These data samples are optional, and they are used only for enhancing the performance of turbulence reconstruction at resolutions higher than Qd. Here we consider such higher-resolution DNS (HR-DNS) is available only for a shorter period, within the time range {to, to+d, . . ., to +0.5Kd} during the training period due to the high cost of generating such data. The available data are illustrated in Fig. 1."}, {"title": "2.1 Physics-guided Recurrent Unit (PRU)", "content": "The physics-guided recurrent unit (PRU) method [41] is built upon the Runge-Kutta (RK) discretization method [44]. The central idea is to utilize the continuous physical relationship represented by the underlying PDE in order to connect the discrete data samples with the continuous flow dynamics. This approach is adaptable to various dynamical systems governed by deterministic PDEs. The PDE for the target variables Q can be formulated as: Qt = f(t, Q; \\theta), where Qt denotes the temporal derivative of Q, and f(t, Q; \\theta) is a non-linear function parameterized by the coefficient \\theta, which summarizes the current value of Q and its spatial variations. The turbulent data adhere to the Navier-Stokes equation for an incompressible flow:\n$$f(Q) = -\\frac{1}{\\rho} \\nabla p + \\nu \\Delta Q - (Q \\cdot \\nabla) Q,$$\nwhere \\nabla represents the gradient operator, and \\Delta = \\nabla.\\nabla applies to each of the velocity components. Figure 2 illustrates the PRU structure, involving a series of intermediate states {Q(t, 0), Q(t, 1), Q(t, 2), . . ., Q(t, N)}. The temporal gradients are estimated at these states as {Qt,0, Qt,1, Qt,2,..., Qt,N}. Beginning with Q(t, 0) = Q(t) (where Q(t) corresponds to Qu(t)), the PRU method approximates the temporal gradient as Qt,0 and then adjusts Q(t) in the direction of the gradient to generate the subsequent intermediate state Q(t, 1). This process repeats for N intermediate states. For the fourth-order Runge-Kutta method utilized in this work, N = 3. Finally, PRU combines all the intermediate temporal derivatives into a composite gradient to calculate the final prediction of the next step flow data QPRU(t + d), as QPRU(t + d) = Q(t) + \\sum_{n=0}^{N} wn Qt,n, where {wn}=1 are the trainable model parameters.\nIn more detail, the PRU method estimates temporal derivatives using the function f(\u00b7). According to Eq. (2.1), evaluating f(.) requires the explicit estimation of first-order and second-order spatial derivatives. The most common approaches for estimating spatial derivatives involve finite difference methods (FDMs) [45] or convolutional neural network layers (CNNs) [41]. After estimating the first-order and second-order spatial derivatives, they are incorporated into Eq.(2.1) to derive the temporal derivative Qt,n"}, {"title": "3 Proposed Method", "content": "The proposed SR-TR method comprises two primary components: the degradation-based refinement and the continuous spatial transition unit (CSTU). The objective of the degradation-based refinement is to reduce the accumulated errors made by the sequential prediction by aligning the reconstructed data with low-resolution LES data while ensuring the adherence to physical constraints. In addition, the CSTU is constructed to capture the spatial and temporal dynamics of turbulent flows and facilitate the reconstruction of flow data at different resolutions."}, {"title": "3.1 Degradation-based Refinement", "content": "The proposed SR-TR method uses the CSTU to conduct sequential prediction from the data at time t to predict Q(t + d) (more details will be described later). With the true DNS data Qd(t + d) available in the training set, the reconstruction loss Crecon is defined using the mean squared error (MSE) loss, as\n$$L_{recon} = \\sum MSE(Q(t + d), Q^{d}(t + d)).$$\nAfter that, the degradation-based refinement is introduced during the testing phase. The refinement\u2019s objective is to alleviate the accumulated errors and structural distortions that arise during long-term predictions by enforcing physical consistency. The refinement process involves the direct downsampling of reconstructed DNS data Q to the corresponding low-resolution LES data Q'. The degradation loss Ldeg between Q and real LES data Q' is described as:\n$$L_{deg} = MSE(Q', \\hat{Q}).$$\nAnother reason for utilizing LES data in degradation loss Ldeg is the unavailability of DNS data during the testing phase. Hence, it is not feasible to directly minimize the difference between true DNS Qd and the reconstructed Q.\nAdditionally, two physical constraints are introduced to ensure the consistency of (i) the mean velocity field, and (ii) the kinetic energy of turbulence. For (i), as mean values from the true DNS data cannot be accessed, the mean values from the LES data are employed as an approximation. The equal-mean loss Lmean is defined as the difference between the mean value of reconstructed flow data Q and that of the true LES data, as follows:\n$$L_{mean} = |\\bar{Q} - \\bar{Q'}|.$$\nFor (ii), the kinetic energy is defined using three components of Q as K = 1/2(u\u00b2 + v\u00b2 + w\u00b2). Similarly, the exact kinetic energy of the flow data is not available during the testing period. However, the value of kinetic energy for incompressible flows often follows simple patterns, e.g., constant or linearly decayed, and thus can be approximated from the DNS data in the training period, denoted by K. Therefore, the loss function Lkinetic is defined as follows:\n$$L_{kinetic} = |K(Q) - \\hat{K}|.$$\nThe final refinement loss function combines the degradation loss and physical consistency, as follows:\n$$L_{refine} = a_{0}L_{deg} + a_{1}L_{mean} + a_{2}L_{kinetic},$$\nwhere a0, a1, and a2 represent the hyperparameters to control the balance amongst the three constituents. In this study, the loss Lrefine is used to directly adjust the parameters of the last layer of the model at each test-time step. This adjustment preserves the flow structure using LES data, and ensures the consistency with two physics constraints. Due to the auto-regressive nature of the sequential prediction method, the output of the adjusted model can affect the prediction for the following time steps.\nThe SR-TR method is different from traditional SR methods in that the low-resolution LES data are only employed in the test-time refinement and are not used in the training. However, it is worth mentioning that LES data could also be incorporated as additional inputs to improve flow reconstruction within the CSTU structure, which will be described later."}, {"title": "3.2 Continuous Spatial Representation", "content": "To facilitate flow reconstruction at desired resolutions, the implicit neural representation method [24] is integrated into the CSTU structure, as depicted in Fig. 3. Before predicting the DNS output Q d(t+d) at the target resolution for time t + d from the input DNS data, the input Qd(t) is initially encoded and interpolated to the target resolution of the flow data denoted as Q (t). This process is described as:\n$$\\hat{Q}(t) = g(t, Q^{d}(t); \\Phi),$$\nwhere g(\u00b7) contains three components. First, it uses CNN layers to learn a spatial implicit neural representation. The CNN layers convert discrete encoded feature map of each flow data slice to a continuous 2D feature space, where any 2D position can be represented by its corresponding feature vector r. Ideally, the CNN layers need to be trained such that the feature vectors encoded by the CNN layers are uniformly distributed across the 2D space.\nSecond, given any query point xs, we select the feature vector r of the grid point xz that is closest to the queried spatial coordinate xs. This selected vector r is then concatenated with its positional information \\Deltaxs relative to the query point's coordinate xs. Finally, this combined input goes through a parameterized interpolation function gs(\u00b7) to generate the continuous feature hs at xs. This process is described as:\n$$h_s = g_s(r, x_s - x_z).$$\nNext, we use a decoder to convert the continuous feature hs to the flow values in Q. By employing this approach, the CSTU structure can effectively resample the DNS data Qd to the DNS data Q in the desired resolution.\nAdditionally, to enhance the capacity of g(\u00b7) in capturing the feature mapping and improving flow reconstruction across different resolutions, the SR-TR model can be fine-tuned using a small number of DNS samples in the target resolution collected from the training period. The loss function Lfinetune between the true HR-DNS data Qh and the resampled DNS data Q can be formulated as:\n$$L_{finetune} = MSE(Q^{\\ddagger}, \\hat{Q}).$$\nOnce obtaining Q , CSTU utilizes the temporal PRU structure to conduct sequential prediction over time. Different from the original PRU that uses CNNs to approximate the spatial derivatives, CSTU enables estimating spatial derivatives using FDM, as it can interpolate the data at close points to reduce the errors of FDM.\nIt is also possible to use the LES data as additional inputs to enhance the intermediate state Q(t,n) in PRU and improve flow reconstruction within the CSTU structure. Same as the PRU architecture shown in Fig. 2, the initial data point Q(t) = Q(t) can be replaced by combining DNS and LES data using an augmentation mechanism: Q(t) = W\u24d2Q\u00b0(t) + W'Q'(t), where W\u24d2 and W\u00b9 are trainable model parameters. The data Q'(t) represents the up-sampled LES data with the same resolution as DNS, generated using the g(.) method. Following this, the CSTU estimates the initial temporal gradient Q(t, 0) = f(Q(t)) using the Navier-Stokes equation and calculates the next intermediate state variable Q(t, 1) by advancing the flow data Q(t) in the direction of temporal derivatives. With frequent LES data, the intermediate states Q(t,n) are further augmented by incorporating LES data Q'(t,n), given as Q(t,n) = WQ(t,n) + WQ(t,n). For the 4-th order Runga-Kutta method, LES data Q'(t,n) are selected based on the position of intermediate temporal derivatives computed in the Runga-Kutta method, as Q'(t, 1) = Q'(t + d/2), Q'(t,2) = Q'(t + d/2), and Q'(t,3) = Q'(t + d). Then CSTU follows a similar process with PRU by moving Q(t) along the estimated gradient Qt,n to compute the subsequent intermediate state Q(t, n + 1)."}, {"title": "4 Experiment", "content": "4.1 Experimental Settings\n4.1.1 Dataset To evaluate the performance of the proposed methodology, the data sets pertaining to two turbulent flows are considered: a forced isotropic turbulent flow (FIT) [42] and the Taylor-Green vortex (TGV) [43] flow. In both scenarios, the mean velocity is zero, Q(t) = 0, and the Reynolds number is sufficiently high to induce turbulent characteristics in the flow.\nThe FIT dataset comprises the original DNS records of forced isotropic turbulence, representing an incompressible flow. The flow is subjected to energy injection at low wave numbers as part of the forcing mechanism. The DNS data consists of 5,024 time steps, with each step separated by a time interval of 0.002s, encompassing both velocity and pressure fields. For this study, the original DNS data is generated to three different grids: 128 x 64 x 64, 128 \u00d7 128 \u00d7 128, and 128 \u00d7 256 \u00d7 256. Simultaneously, the LES data is generated on grids of size 128 x 32 x 32. Both DNS and LES data are collected along the 128 equally spaced grid points along the z axis.\nThe Taylor-Green vortex (TGV) represents another incompressible flow. The evolution of the TGV involves the elongation of vorticity, resulting in the generation of small-scale, dissipating eddies. A box flow scenario is examined within a cubic periodic domain spanning [-\u03c0,\u03c0] in all three directions. The initial conditions are defined as:\n(A.1)\n$$\nu(x,y,z,0)=sin(x)cos(y)cos(z),$$\n$$\\nu(x,y,z,0)=cos(x)sin(y)cos(z),$$\n$$\\nu(x,y,z,0)=0.$$\nThe DNS and LES resolutions are 128 \u00d7 128 \u00d7 65 and 32 \u00d7 32 \u00d7 65, respectively. Both DNS and LES data are produced along the 65 equally-spaced grid points along the z axis."}, {"title": "4.1.2 SR-TR method and baselines", "content": "The performance of the SR-TR method is evaluated and compared with several existing methods for super-resolution (SR) and turbulent flow downscaling. Specifically, we implement two SR-TR-based methods: ST-TRFDM and ST-TRCNN, which use FDM and CNN to approximate spatial gradients. Additionally, four popular SR methods SR-CNN [10], RCAN [15], HDRN [14], and SRGAN [16], two well-known dynamic fluid downscaling methods: DCS/MS [33] and FSR [37], and the Fourier neural operator (FNO) [39], are used as baselines.\nTo better assess the effectiveness of the model components, three additional baseline models are introduced: the Convolutional Transition Network (CTN), CSTUFDM, and CSTUCNN [41]. The CTN is a combination of SRCNN and LSTM [46]. CSTUFDM and CSTUCNN are similar to ST-TRFDM and ST-TRCNN but do not use degradation-based refinement. The goal of comparing CTN with CSTU-based methods is to highlight the advantages of CSTU in spatio-temporal DNS reconstruction. Comparing CSTU-based methods with SR-TR-based methods shows the benefits of the refinement process. Additionally, we explore the improvement in flow data reconstruction with extra LES input by implementing a variant of the proposed method."}, {"title": "4.1.3 Experimental designs", "content": "The proposed methods and the baselines are evaluated using both the FIT and TGV datasets. The models are trained using the FIT data over a continuous one-second period with a time interval of d = 0.02s and a total of 50 time steps. Subsequently, the trained models are applied to the following 0.4 second period (equivalent to 20 time steps) for performance assessment. For the TGV dataset, the models are trained on a consecutive 40-second period with a time interval of d = 2s, and the subsequent 40 seconds of data (equivalent to 20 time steps) are used for testing.\nAdditionally, given that the FIT dataset contains DNS data of different resolutions, it is important to note that all of the methods and baselines were trained using data with a resolution of 64 \u00d7 64 and were subsequently tested at the same resolution. The higher-resolution DNS data (HR-DNS) are exclusively used for testing the reconstruction of flows at different resolutions and for conducting the ablation study that explores the benefits of utilizing LES data. Additionally, we use the periodic data augmentation [41] to address boundary conditions.\nThe assessment of DNS reconstruction performance employs two metrics: the Structural Similarity Index Measure (SSIM) [47] and dissipation difference [48]. SSIM measures the similarity between reconstructed and target DNS data in terms of luminance, contrast, and overall structure. Higher SSIM values indicate better reconstruction. Dissipation evaluates the model's gradient capturing ability, considering dissipation for each velocity vector component (u, v, and w). The dissipation operator is defined by \\chi(Q) = \\nabla Q \\cdot \\nabla Q =. The dissipation is used to measure the difference in flow gradient between the true DNS and generated data. This is represented by \\chi(Qd) - \\chi(Qd), and the smaller difference indicates better performance."}, {"title": "4.2 Reconstruction Performance", "content": "4.2.1 Quantitative results Table 1 and Table 2 provide a summary of the average performance across the initial 10 time steps during the testing phase, tested on both the FIT and TGV datasets. When compared to the baselines, the SR-TR-based methods generally present superior performance in both assessments, exhibiting the highest SSIM value and the lowest dissipation difference. Several highlights also emerge: (1) When contrasting SR-TR-based methods with SR baselines, DCS/MS, FSR, and FNO models, it becomes evident that these baseline methods struggle to accurately recover the overall flow, resulting in diminished performance concerning SSIM and dissipation difference. (2) A comparison between CSTU-based methods and SR-TR-based methods shows the substantial enhancements derived from the incorporation of the degradation-based refinement."}, {"title": "4.2.2 Temporal analysis and visualization", "content": "For the FIT dataset, the performance for reconstructing DNS is measured for each step during a 0.4s period (20 time steps) in the testing phase. The performance change using dissipation difference is shown in Fig. 11. Several observations are highlighted: (1) With larger time intervals between training and prediction data, the performance becomes worse. In general, SR-TR-based methods exhibit greater stability over long-term prediction, indicating superior performance compared to other methods. (2) SR-TR-based methods outperform CSTU-based methods, illustrating the effectiveness of degradation-based refinement in mitigating prediction bias over long-term predictions. (3) Both CSTUFDM and CSTUCNN demonstrate similar performance. A parallel observation arises when comparing the two variants of SR-TR-based methods, demonstrating that either approach for estimating the spatial derivative within the CSTU can obtain similar performance. The same conclusion can be drawn from the temporal analysis of the TGV data, shown in appendix."}, {"title": "4.2.3 Validation via physical metrics", "content": "The performance is also evaluated through the long-term prediction of turbulent kinetic energy. Figure 7 illustrates the energies corresponding to the target DNS, along with the reconstructed flow data from both the baselines. The dissipation is used to measure the difference in flow gradient between the true DNS and generated data. This is represented by x(Qd) - x(Qd), and the smaller difference indicates better performance."}, {"title": "4.2.4 Reconstruction performance in different resolutions", "content": "We compare the performance of SR-TRFDM, SR-TRFDM, and FNO on the FIT dataset. All models are trained at a resolution of 64 x 64, tested at different resolutions: 64x64, 128x128, and 256 x 256. Notably, FNO and SR-TRFDM are purely zero-shot super-resolution [49] methods, without using higher resolution DNS data for model fine-tuning before prediction. While SR-TRFDM utilizes 15 time steps' higher resolution DNS data for model fine-tuning before prediction. Figure 8 displays the performance of three methods, highlighting some observations: (1) All methods face more difficulty recovering higher-resolution flow data. This is due to the increased complexity of flow details in higher-resolution data. (2) When comparing the performance between SR-TRFDM and SR-TRFDM, it is obvious that fine-tuning the model before prediction can lead to significant improvements in flow reconstruction across different higher resolutions. (3) SR-TRFDM method can achieve ideal reconstruction performance and demonstrate zero-shot super-resolution capabilities based on SSIM and dissipation difference. In contrast, FNO struggles to make accurate predictions at the same resolution and also faces challenges in generalizing to unseen resolutions. These observations highlight the effectiveness of SR-TRFDM in long-term reconstruction and zero-shot super-resolution."}, {"title": "4.2.5 Ablation study for utilization of LES data", "content": "The objective of this study is to investigate techniques for integrating LES data into the SR-TR approach. The performance of these techniques is shown in Fig. 9, generally demonstrating their effectiveness in utilizing LES data for reconstructing flow data across different resolutions. Several observations can be highlighted: (1) When comparing CSTUFDM with SR-TRFDM or SR-TRFDM, a significant improvement in reconstruction performance, as indicated by both SSIM and dissipation difference, can be observed. This demonstrates that introducing LES data can lead to improvements regardless of the specific LES data utilization strategy employed. (2) Compared with SR-TRFDM, SR-TREDM method demonstrates slightly better performance in reconstructing flow data at the same resolution. However, its performance is worse than that of SR-TRFDM when aiming to reconstruct higher-resolution flow data. This discrepancy comes from the significant dissimilarity between low-resolution LES data and high-resolution DNS data, which not only hinders the reconstruction process but can also lead to performance degradation, particularly for higher resolutions. Based on these observations, we conclude that using the low-resolution LES data as input does not bring significant benefit when the degradation-based refinement process is adopted."}, {"title": "5 Conclusion", "content": "A new physics-guided neural network, called \"super-resolution through test time refinement\" (SR-TR), has been developed to reconstruct high-resolution flow data at various resolutions and time intervals. SR-TR is designed for unsteady, incompressible, Newtonian turbulent flow in spatially homogeneous conditions. The key component, the Continuous Spatial Transition Unit (CSTU), leverages physical insights from the Navier-Stokes equation to capture spatial and temporal flow dynamics. CSTU also enables reconstruction across different resolutions. To enhance the precision of the reconstructed data over time, a degradation-based refinement method is introduced, ensuring the data remains true to physical constraints. The model's performance is tested on two turbulent flow scenarios, using both visual and statistical analysis, showing SR-TR's superior spatio-temporal reconstruction ability. Notably, the constituents of the model, CSTU and the degradation-based refinement, can easily serve as fundamental building blocks for enhancing existing deep learning models."}, {"title": "A Experimental Settings", "content": "A.1 Dataset To evaluate the performance of the proposed methodology, the data sets pertaining to two turbulent flows are considered: a forced isotropic turbulent flow (FIT) [42] and the Taylor-Green vortex (TGV) [43] flow. In both scenarios, the mean velocity is zero, Q(t) = 0, and the Reynolds number is sufficiently high to induce turbulent characteristics in the flow.\nThe FIT dataset comprises the original DNS records of forced isotropic turbulence, representing an incompressible flow. The flow is subjected to energy injection at low wave numbers as part of the forcing mechanism. The DNS data consists of 5024 time steps, with each step separated by a time interval of 0.002s, encompassing both velocity and pressure fields. For this study, the original DNS data is generated to three different grids: 128 x 64 x 64, 128 \u00d7 128 \u00d7 128, and 128 \u00d7 256 \u00d7 256. Simultaneously, the LES data is generated on grids of size 128 x 32 x 32. Both DNS and LES data are collected along the 128 equally spaced grid points along the z axis.\nThe Taylor-Green vortex (TGV) represents another incompressible flow. The evolution of the TGV involves the elongation of vorticity, resulting in the generation of small-scale, dissipating eddies. A box flow scenario is examined within a cubic periodic domain spanning [-\u03c0, \u03c0] in all three directions. The initial conditions are defined as:\n(A.1)\n$$u(x, y, z, 0) = sin(x) cos(y) cos(z),$$\n$$v(x, y, z, 0) = cos(x) sin(y) cos(z),$$\n$$w(x, y, z, 0) = 0.$$\nThe DNS and LES resolutions are 128 \u00d7 128 \u00d7 65 and 32 \u00d7 32 \u00d7 65, respectively. Both DNS and LES data are produced along the 65 equally-spaced grid points along the z axis."}, {"title": "A.2 SR-TR method and baselines", "content": "The performance of the SR-TR method is evaluated and compared with multiple existing methods for SR and turbulent flow downscaling. Specifically, we implement the SR-TR-based methods: ST-TRFDM and ST-TRCNN using FDM and CNN to approximate spatial gradients, respectively. Additionally, four popular SR methods SR-CNN [10], RCAN [15], HDRN [14], and SRGAN [16], two well-known dynamic fluid downscaling methods: DCS/MS [33] and FSR [37], and the Fourier neural operator (FNO) [39], are used as baselines.\nTo better verify the effectiveness of each of the model's components, three additional baselines are also introduced: convolutional transition network (CTN), CSTUFDM, and CSTUCNN [41]. The CTN is created by combining SRCNN and LSTM [46]. CSTUFDM and CSTUCNN are similar to ST-TRFDM and ST-TRCNN, but they are created without using the degradation-based refinement. The objective of comparing the CTN with CSTU-based methods is to demonstrate the advantages of CSTU in spatio-temporal DNS reconstruction. The advantages of the refinement process are demonstrated by comparing CSTU-based and SR-TR-based methods. Furthermore, to present additional evidence regarding the potential enhancement of flow data reconstruction through additional LES input, we implement a variant of the proposed method ST-TREDM, which utilizes LES data as additional input."}, {"title": "A.3 Implementation details", "content": "The proposed SR-TR method is implemented via Tensorflow 2 with an A100 GPU. The model is first trained in 500 epochs with ADAM optimizer [50] from an initial learning rate of 0.0001. In the refinement step, the learning rate is lowered to 0.00005, and the training rate is iterated by 10 epochs. All the hidden variables and gating variables are in 32 dimensions. The values of \u03b10, \u03b11, and a2 are set as 1000, 1, and 1, respectively."}, {"title": "A.4 Evaluation Metrics", "content": "The assessment of DNS reconstruction performance employs two metrics: the Structural Similarity Index Measure (SSIM) [47] and dissipation difference [48]. SSIM measures the similarity between reconstructed and target DNS data in terms of luminance, contrast, and overall structure. Higher SSIM values indicate better reconstruction. Dissipation evaluates the model's gradient capturing ability, considering dissipation for each velocity vector component (u, v, and w). The dissipation operator is defined by:\n(A.2) x(Q) = \\nabla Q \u2022 \\nabla Q =."}, {"title": "B Reconstruction Performance", "content": "B.1 Temporal analysis For"}]}