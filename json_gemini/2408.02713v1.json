{"title": "A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality", "authors": ["Zheng Han", "Qi Dou"], "abstract": "Augmented Reality (AR) holds the potential to revolutionize surgical procedures by allowing surgeons to visualize critical structures within the patient's body. This is achieved through superimposing preoperative organ models onto the actual anatomy. Challenges arise from dynamic deformations of organs during surgery, making pre-operative models inadequate for faithfully representing intraoperative anatomy. To enable reliable navigation in augmented surgery, modeling of intraoperative deformation to obtain an accurate alignment of the preoperative organ model with the intraoperative anatomy is indispensable. Despite the existence of various methods proposed to model intraoperative organ deformation, there are still few literature reviews that systematically categorize and summarize these approaches. This review aims to fill this gap by providing a comprehensive and technical-oriented overview of modeling methods for intraoperative organ deformation in augmented reality in surgery. Through a systematic search and screening process, 112 closely relevant papers were included in this review. By presenting the current status of organ deformation modeling methods and their clinical applications, this review seeks to enhance the understanding of organ deformation modeling in AR-guided surgery, and discuss the potential topics for future advancements.", "sections": [{"title": "1. Introduction", "content": "Recent advancements in optical see-through displays have introduced augmented reality (AR) as a promising tool for surgical navigation [1]. In AR-guided surgery, 3D digital organ models can be overlaid onto real anatomical structures [2]. These organ models are generated from patient-specific data obtained through preoperative computed tomography (CT) or magnetic resonance imaging (MRI) images. They encompass information that presents organ shapes, surfaces, blood vessels, and tumors. The alignment of these digital models with patient anatomy helps surgeons to form an intuitive understanding of the spatial relationships among various anatomical structures concealed beneath the organ surfaces (see Figure 1). The improved spatial awareness alleviates the burden for surgeons in localizing the safety-critical structures. This facilitates the execution of surgical plans with a higher level of precision and more informed decisions that could contribute to improved surgical outcomes [3,4].\nDespite the potentials of AR-guided surgery, its reliability can be compromised by organ deformations caused by factors such as patient positioning, respiratory motion, extrinsic compression by pneumothorax, hematoma, or the device [6,7]. These deformations lead to misalignment between the preoperative digital organ models and the intraoperative anatomy, affecting the accuracy of localizing tumors and vessels [8]. To make reliable surgical navigation, organ deformation modeling technique is an indispensable component in the AR-guided surgery system. This modeling process involves continuously adjusting preoperative 3D organ models to adapt to the dynamic deformations occurring during surgical procedures [9]. Organ deformations can be observed through various modalities, including the locations of anatomical landmarks [8,10], tissue structure silhouettes [11], or 3D digitized organ surfaces [12,13]. Organ deformation modeling, at its core, involves extrapolating organ deformation fields based on these intraoperative observations to adjust preoperative digital organ models.\nWhile organ deformation modeling plays a pivotal role in AR-guided surgery, achieving consistency between digital models and real organs remains a persistent challenge due to technical constraints. Firstly, organ surfaces often lack distinct features suitable for use as fiducials in deformation modeling, and the limited color and texture contrast in intraoperative imaging modalities further exacerbate this issue [14,15]. Secondly, the intraoperative observations available for deformation modeling are relatively limited, typically allowing only partial views of organs to be acquired [16]. Extrapolating deformations spread across the entire organ from such limited information poses a significant challenge, especially given the considerable deformation that soft tissues within organs may experience during surgical procedures [17]. Thirdly, different surgical specialties present unique challenges. For instance, organs such as livers and kidneys exhibit viscoelastic deformation behavior during surgery [18-20], while spinal structures deform due to their inherent flexibility [21]. In these regards, specialized deformation modeling methods should be tailored for each surgical specialty to effectively address the corresponding organ deformations.\nTo inspire potential solutions for addressing these challenges in the computer-assisted surgery research field, this literature review commences by providing a comprehensive and technical-oriented summary of current deformation modeling techniques (cf. Sec. 3). Subsequently, it delves into various surgical specialties, offering detailed insights into the particular challenges faced by each specialty and presenting existing solutions (cf. Sec. 4). Finally, drawing on existing research, this review discusses future research possibilities (cf. Sec. 5)."}, {"title": "2. Literature Search and Screening Process", "content": "The literature search and screening process were conducted according to the guideline of Preferred reporting items for systematic review and meta-analysis (PRISMA) [22].\nFigure 2 shows the overview of our literature processing workflow."}, {"title": "2.1. Literature search", "content": "The literature search was initially conducted in May 2023, across five scientific databases: Scopus, Web of Science, IEEE Xplore, ScienceDirect, and PubMed. An updated search on Google Scholar for 2023 and 2024 articles was subsequently performed on in March 2024 in order to add more literature including ArXiv papers. To make a comprehensive investigation, a number of search terms was identified, comprising keywords including \"intraoperative\", \u201cnon-rigid\", \"deformation\", \"registration\", \"modeling\u201d, and \u201cAR\u201d. Logical operators (AND/OR) were utilized to combine the keywords, facilitating a thorough and proper retrieval of relevant articles from each database. A detailed list of these search terms can be found in Appendix Table A.1."}, {"title": "2.2. Selection process", "content": "The literature search yielded a total of 3119 records, and after removing duplicates, 2671 unique studies underwent screening. During the screening phase, titles and abstracts were reviewed to preliminarily exclude irrelevant publications. The exclusion criteria comprised the following items: (1) studies containing similar content from the same authors, (2) non-original research such as reviews or book chapters, (3) studies not focusing on modeling organ deformation, (4) studies not proposing new methods (e.g., comparative studies evaluating existing methods), and (5) studies not validated in scenarios related to clinical settings (e.g., focused solely on medical simulations or virtual surgical scenarios). Based on these criteria, 2354 records were excluded.\nSubsequently, a more time-consuming full-text assessment was conducted to determine the eligibility of the remaining 317 studies for inclusion to this survey. Full-text articles had to satisfy the following inclusion criteria: (1) updating preoperative reconstructed 3D organ models based on information extracted from an intraoperative acquisition, (2) providing a comprehensive description of the proposed method's implementation details, and (3) demonstrating clear applicability to AR-guided surgery in certain clinical scenarios. After applying these criteria, a final set of 112 studies were included in this review paper. In this way, we hope that the screened compact set of references can present the most closely-related literature and highly-informative summary, so that readers can find a focused survey on the specific topic of organ deformation modeling approaches in AI-guided surgery."}, {"title": "2.3. Related review papers", "content": "To ensure new knowledge provided by this review, we also examine existing survey papers on related topics identified during the literature search and screening process. Min et al. [23] (2023) review registration approaches for aligning preoperative organ models with intraoperative anatomy. However, their focus is solely on orthopedic surgery and thus does not cover the deformation of soft tissues. Similarly, Gsaxner et al. [24] (2023) summarize methods for rigidly aligning digital and physical coordinates to realize surgical navigation in augmented reality space, but compensation for soft tissue deformation is still lacking. Schneider et al. [25] (2021) provide a comprehensive comparison of current surgical navigation systems with augmented reality support, regarding accuracy performance in laparoscopic liver surgery. While they discuss the issue of soft tissue deformation, a technical overview of how to model organ deformation is not provided. The most pertinent review on organ deformation modeling techniques is by Bernhardt et al. [1] (2017), who summarize non-rigid registration methods to account for soft tissue deformation. However, this review was published a while ago, therefore a newer survey is needed to update the latest literature especially learning-based and data-driven techniques."}, {"title": "3. Organ Deformation Modeling Approaches", "content": "Organ deformation modeling involves predicting a deformation field as output to update a pre-surgery reconstructed 3D organ model based on the input intraoperative observations [9]. These observations can be anatomical point coordinates, or partial organ surface reconstructed from stereoscopic images, as illustrated in Figure 3. By incorporating these observations, the modeling process ensures the fidelity of preoperative organ models to intraoperative anatomical changes, thus accommodating tissue deformations during AR-guided surgery. With the potential to enhance the surgical precision, this field has attracted widespread attention, leading to the flourishing of various modeling algorithms."}, {"title": "3.1. Categorization of organ deformation modeling methods", "content": "Existing algorithms for modeling organ deformations can be broadly categorized into model-based, data-driven, and hybrid methods. Table 1 and Table 2 provide a categorical summary of these existing methods for organ deformation modeling."}, {"title": "3.1.1. Model-based methods", "content": "In the field of organ deformation modeling, the majority of research efforts were initially directed towards model-based algorithms. These early research endeavors centered around understanding the tracking and modeling of tumor movement within organs during respiratory motion patterns. Clinical trials conducted by Schweikard et al. [27] confirmed the hypothesis that a correlation exists between internal and external motion. This discovery laid the foundation for the development of correlation models, which could predict the intraoperative motion of internal tumors based on changes in externally trackable signals, often referred to as surrogates. Correlation models found practical application in cases such as radiofrequency ablation therapy [13], where small tumors could be treated as rigid targets. However, when dealing with the deformation of soft tissues, correlation modeling proved to have limitations in its fitting capacity, presenting challenges [28].\nTo achieve the goal of modeling soft tissue deformations, further exploration ensued. Existing model-based algorithms can be categorized into four subcategories based on their underlying principles: (1) biomechanical models, (2) physics-based modeling methods, (3) geometry-based alignment methods, and (4) statistical models.\nBiomechanical models (n = 44) account for soft tissue deformations by numerically solving partial differential equations associated with constitutive models [29]. Finite element (FE) methods are commonly used in the numerical solving process due to their effectiveness in handling partial differential equations (PDEs). In biomechanical modeling, the problem of inferring organ deformation is framed as solving a boundary value problem, where the boundary conditions (input data) are derived from intraoperative observations [16]. Boundary conditions (BCs) on an FE model can be expressed as either displacements or forces. When specifying a displacement BC, a node is compelled to move to a given position. Conversely, when a force BC is specified, it ensures that the internal stress is in equilibrium with the applied stress. With specified BCs, biomechanical models have demonstrated promising capabilities in simulating the viscoelastic behavior of soft tissues within various organs, such as the liver, prostate, kidney, and brain [18\u201320,30]. However, their application in a real surgical setting encounters difficulties. Firstly, acquiring BCs during surgery remains challenging. Obtaining displacement BCs requires known surface correspondences, while obtaining force BCs necessitates precise measurement of forces applied by surgical tools on the organ [31]. Secondly, directly solving FE-based biomechanical models presents logistical limitations, such as the lengthy computational time [32]. These challenges limit the practical utility of biomechanical models in clinical scenarios. To address the issues, Yang et al. [33] recently proposed a boundary constraint-free biomechanical model, eliminating the need for predefined zero-displacements and force locations in BCs. Min et al. [34] explored the use of physics-informed neural networks to solve PDEs, offering potential solutions to computational efficiency challenges.\nPhysics-based modeling (n = 6) presents an alternative approach to soft tissue deformation modeling. The fundamental concept behind these methods is to depict organ deformation in a physically interpretable manner. For instance, in the work by Suwelack et al. [35], the non-rigid deformation problem is likened to an electrostatic-elastic scenario, where an elastic representation of the preoperative liver model behaves akin to an electrically charged object interacting with the oppositely charged rigid intraoperative liver surface. The preoperative liver in its undeformed state and the intraoperative liver surface, captured through stereo endoscopic imaging, serve as inputs for the registration process. Electrostatic forces facilitated the alignment of the preoperative liver with the intraoperative surface, with elastic forces providing regularization. Another approach, demonstrated by Dagon et al. [36], involved modeling hepatic vein deformations using a mass-spring skeleton aligned with vessel centerlines. During surgery, the actual vessel positions were inferred from image segmentation provided by a tracked 2D ultrasound system. These intraoperative measurements were then translated into 3D points, serving as input data. Elastic deformation of the skeleton to align with these 3D points was achieved by applying virtual forces until it conformed to the measurements. Currently, research in physics-based modeling remains relatively limited, and there is a need to explore additional physical constraints to enhance the realism of deformation modeling [37].\nGeometry-based alignment methods (n = 21) handle 3D organ models in the form of point clouds. These methods deform the preoperative 3D organ model by manipulating its geometric coordinates, specifically the 3D points that compose the organ surface [38]. They aim to find a rigid transformation while simultaneously deforming the preoperative 3D model (output) to align it with the intraoperative organ surface point clouds (input data). This is achieved by employing non-rigid point cloud registration algorithms, such as multi-stage iterative closest point (ICP), coherent point drift (CPD), or thin-plate spline (TPS) registration [12,39,40]. These algorithms estimate point correspondences and transformation functions between preoperative and intraoperative surfaces, aiming to maximize the alignment of visible regions between preoperative and intraoperative surfaces [41]. However, rather than FE-based or physics-based approaches, geometry-based alignment methods often lack strain energy regularization [42] in the deformation modeling process. This regularization, described by the material properties and geometric features of organs, ensures that the deformation results adhere to organs' elastic properties and mechanical behavior. The absence of this regularization in geometry-based alignment methods can diminish the accuracy and reliability of the predicted deformations in invisible surface regions. Moreover, geometry-based alignment methods face challenges in effectively propagating external organ surface deformation to internal structures such as vessels and tumors. In a preliminary study conducted by Maris and Fiorini [40], a direct application of the non-rigid TPS function obtained from the surface registration to each of the points x of the target tumor was tested, resulting in an evaluation error of around 5mm on the centroid of the tumor volume.\nStatistical models (n = 9) describe the patterns of organ shape variations or motion from a statistical perspective, corresponding to statistical shape models and statistical motion models. In the shape model, variations among shapes from different individuals are accounted for, while the motion model captures the temporal changes in shape relative to a reference, such as those caused by respiratory motion [43]. Constructing statistical models depends on having patient ground truth data, ideally offering high-resolution 3D spatial representations of organs. Particularly in the case of building statistical motion models, it is also crucial to have a sufficiently high temporal frame rate, capturing several volumes per second. To address the challenge of balancing image quality and acquisition speed, a learning-based technique was introduced by von Siebenthal et al. [44] to obtain 4D-MRI data. With the 4D-MRI data, a population-based statistical model can be built from the non-rigid registration of the MRI images [45,46]. The constructed statistical models can be employed to estimate present shape changes based on intraoperative observations. For instance, if online ultrasound images depict parts of the changing shape of interest, the full changing shape can be estimated form the previously observed shape changes, which have been encapsulated in the statistical motion model.\nIn general, model-based methods employ explicit mathematical models to characterize organ deformation. Among these, biomechanical models demonstrate good simulation effectiveness for deformations induced by external forces, such as instrument interactions and pneumoperitoneum pressure. For deformations arising from regular motion patterns, such as those caused by respiratory motion, statistical models are more suitable. Physics-based modeling endeavors to transfer existing physical models to directly simulate the viscoelastic behavior of soft tissues. Geometry-based alignment methods, on the other hand, tend to utilize non-rigid registration techniques from general computer vision to simultaneously address organ rigid registration and deformation modeling. However, this approach often lacks strain energy regularization, thereby failing to ensure that the predicted results adhere to organs' elastic properties and mechanical behavior."}, {"title": "3.1.2. Data-driven methods", "content": "Data-driven methods were initially employed to address the limitations of directly applying biomechanical models in surgical procedures. Specifically, early data-driven methods sought to reduce intraoperative computation of biomechanical models by constructing a patient-specific atlas generated by FE-based simulation [32]. Recently, there has been a growing trend in adopting machine learning approaches as implicit representations of the underlying biomechanical model mechanism. The advantage of this adoption lies in the ability of machine learning approaches to predict the complex behavior of elastic organ structures in real-time without relying on preassigned boundary conditions [10]. This is particularly beneficial for clinical applicability, as boundary conditions are often challenging to obtain in clinical settings. The following provides an overview of the utilization of (1) atlas-based modeling approaches and (2) machine learning approaches in deformation modeling.\nThe atlas-based method (n = 5) entails the construction of a pre-operatively computed collection of solutions, referred to as an atlas. This atlas is then used to align the data acquired during surgery with the solutions within the atlas, enabling the prediction and correction of the intraoperative organ deformation [53]. The process of atlas construction begins with the generation of a patient-specific finite element organ model. This model is derived from the surface description provided by a segmentation of the pre-operatively obtained image volumes. Boundary conditions, patient orientations (e.g., gravity directions), and material properties are selected based on a priori knowledge of surgical loading conditions [54]. The preoperative FE organ model is then run for each combination of conditions to create the atlas of organ deformation solutions. During surgery, a set of weight parameters (output) is determined to linearly combine the pre-operatively computed collection of solutions within the atlas [55]. This allows the organ model generated from atlas to match with the intraoperative observations, such as 3D digitized surfaces of the organ (input). These weight parameters can be iteratively solved using various algorithms, such as the iterative closest atlas algorithm [32] or the Levenberg-Marquardt nonlinear optimization method [56].\nMachine learning approaches (n = 10) were initially harnessed to expedite biomechanical modeling [57]. These models learn a function that maps inputs, such as external forces, to outputs, such as nodal displacements, by training on organ deformation datasets [58]. Typically, these datasets consist of synthetic data generated from simulating the biomechanical behavior of organs using FE methods [59]. Training the network using synthetic datasets rather than real patient data is a trade-off. Collecting ground truth deformation patterns of the same patient's organs would require multiple CT scans, which is impractical in clinical practice. Notably, studies such as [29,31,60-62] have shown that even when trained solely on synthetic data, machine learning models still have the potential to accurately predict the physical deformation behaviors of organs. After training, the machine learning model serves as an implicit representation of the underlying biomechanical model mechanism, eliminating the need for explicit mathematical formulations during inference. Further, machine learning approaches can be categorized into two main branches: traditional machine learning (TML) and deep learning (DL) techniques. Specifically, traditional machine learning techniques, such as support vector machines and random forests, have demonstrated their potential to simulate tissue behavior in real-time, including organs such as breasts [63] and livers [64,65]. However, these methods face limitations when applied in actual surgical settings. Traditional machine learning models rely on FE-based conditions, specifically stress and displacement conditions [66], as input variables. Acquiring these variables in a real surgical environment is challenging, since, for instance, measuring forces requires additional devices, and estimating surface displacements necessitates knowledge of surface correspondences [31]. Currently, the most widely adopted solution for obtaining input variables involves simplified boundary conditions, which assume fixed subsets of nodes while leaving others free [67-69]. However, manually assigning these boundary conditions can lead to instability if incorrect values are chosen, thereby impeding prediction accuracy. Deep learning, on the other hand, has been recognized as a powerful approach for predicting organ deformation behaviors, offering enhanced clinical applicability due to its ability to operate in real-time and independence from preassigned boundary conditions. These algorithms function by taking preoperative organ models, along with intraoperative observations such as 3D reconstructed organ surfaces (input), and predicting a displacement field (output) that warps the preoperative models to align with these intraoperative observations. For instance, Nakao et al. [70] introduced a deep learning-based framework for modeling the deformation of abdominal soft organs. This framework offers an end-to-end solution for real-time 2D/3D deformable registration by integrating an image-based generative network [71] and a graph convolutional network (GCN) [72]. The generative network learns the transformation from the 2D projection image to a displacement map, while the GCN translates this transformation into the final nodal displacements of the organ model. Moreover, Pfeiffer et al. [31] harnessed a fully 3D convolutional architecture to recover the displacement field directly from the intraoperative digitized organ surface, which was reconstructed from the laparoscopic video. This estimated displacement field can subsequently be utilized to deduce the nodal displacements spanning the entire organ, encompassing organ surface, vessels, and tumors. Table 4 summarizes publicly available datasets that can be used for neural network training and quantitatively evaluating accuracy.\nIn general, data-driven models, by learning a vast number of deformation patterns, can serve as implicit representations of the underlying biomechanical mechanism. Thanks to parallel computing, the inference process of data-driven methods can be significantly accelerated [48]. Additionally, both atlas-based methods and deep learning approaches can directly infer deformation fields from intraoperative observations, greatly enhancing clinical applicability [29,31,62]. In contrast, traditional machine learning methods still rely on manually assigning boundary conditions, which can lead to instability and affect accuracy if incorrect values are chosen."}, {"title": "3.1.3. Hybrid methods", "content": "Hybrid methods represent the fusion of model-based and data-driven approaches, offering notable flexibility in their implementation.\nOne approach to implementing hybrid methods involves leveraging network-driven biomechanical models (n = 4). This approach utilizes neural networks to estimate essential prerequisites, such as boundary conditions or deformation parameters, to drive biomechanical organ models. These prerequisites are typically challenging to directly measure during actual surgical procedures. An example to better illustrate this concept is the work of Tagliabue et al. [73], who employed a BANet [74] to continuously estimate boundary conditions from raw intraoperative point cloud data of the deforming anatomy, captured by a vision sensor. The estimated boundary conditions from BANet guide preoperative biomechanical organ models to deform, ensuring an accurate representation of intraoperative organ deformations. Another example comes from the work of Labrunie et al. [49], where neural networks predict pose (R, T) and deformation parameters (\u03b2) defining the intraoperative state of the organ. Initially, a ResNet-50 network [75] extracts organ boundary features from mini-invasive images. These extracted features, along with the temporary pose (R, T), and deformation parameters (\u03b2), serve as inputs to a regression network [76]. This network iteratively updates the pose (R, T) and deformation parameters (\u03b2), which are subsequently employed to drive the preoperative biomechanical organ model for an accurate representation of organ deformations.\nAnother method for implementing hybrid approaches involves multi-stage deformation modeling (n = 10), which breaks down the deformation modeling process into multiple stages and selecting appropriate methods for each. For example, Shi et al. [10] decomposed organ deformation modeling into organ surface and internal structure deformation modeling stages. Initially, an external-internal correlation model [77] is used to estimate organ surface deformation by tracking the displacement of external markers attached to the skin. Subsequently, neural networks propagate the surface deformation to internal structures, such as vessels and tumors. Meanwhile, Jia and Kyan [17] achieved deformation modeling by first recovering organ shape and then performing non-rigid registration. They utilized a point cloud occupancy network [78] to infer the complete organ shape from partial organ surfaces. Then, a correction algorithm utilizing the Levenberg-Marquardt nonlinear optimization method [79] is applied for non-rigid registration based on the organ shape inferred from the network.\nImplementing hybrid methods through physics-guided deep learning (n = 3) presents another viable solution. This approach incorporates established physical principles, equations, and laws into the training and inference process of deep learning models to ensure that the models' predictions align with physical phenomena [80]. Pioneering work in this field was introduced by Min et al. [34], who employed a novel deep learning approach integrating physics-informed neural networks (PINNs) with PointNet for non-rigid medical image registration. The key physical principle integrated into the deep learning model is a loss function term based on biomechanical constraints, which ensures that the estimated spatial transformation is biophysically plausible. This method represents prostate point displacements using PointNet[81], while PINNs impose elastic constraints on the estimated displacements. Comparison experiments have illustrated that incorporating these physics-guided constraints significantly reduces target registration error, especially for patients with large deformations, thereby demonstrating superior performance and generalizability to new subjects.\nIn general, hybrid methods effectively leverage the strengths of both data-driven and model-based approaches. They can improve data-driven predictions to better approximate the viscoelastic characteristics observed in actual organs, or expedite model-based methods in acquiring the necessary prerequisites for controlling organ models. The flexibility in implementing hybrid methods can also expand their applicability in real clinical settings."}, {"title": "3.2. Comparison of different deformation modeling methods", "content": "We would like to compare different deformation modeling methods based on their accuracy, computational efficiency, and ease of implementation, categorizing their performance as \"high\", \"medium\", or \"low\" for each criterion. The \u201caccuracy\" criterion evaluates the method's ability to accurately predict the deformation behavior of soft tissues; \"computational efficiency\" indicates its suitability for real-time applications; and \"ease of implementation\" reflects the method's practical applicability in clinical settings, considering factors such as the ease of model construction, and the accessibility of required intraoperative observations (input data) during clinical practice."}, {"title": "3.2.1. Accuracy comparative analysis", "content": "In terms of accuracy, methods utilized biomechanical FE-models best explain the deformation behavior induced by external forces. This is primarily due to the fact that this method is grounded in continuum mechanics theory [61]. Additionally, this method can leverage prior knowledge about the mechanical load applied to organs to reduce the complexity of the problem space. This prior knowledge can be integrated into constraints within the adjoint optimization scheme [82], or decomposed into a set of localized point forces distributed over the active contact surfaces of the organ to control deformation responses [83]. Conversely, methods that solely rely on surface correspondence and lack mechanical constraints, such as geometry-based alignment methods in model-based approaches, and data-driven methods, often lack strain energy regularization within the objective function, leading to limited control over deformation field irregularities. Additionally, deep learning approaches in data-driven methods may exhibit voxelization artifacts, associated with data discretization procedures at convolutional layers [51]. However, incorporating physics-guided loss functions for optimizing the parameters of the deep learning model has the potential to enhance accuracy in unseen deformation scenarios [84]. For deformations arising from regular motion patterns, such as those caused by respiratory motion, statistical models perform better. This is because statistical models are directly constructed from patient ground truth data. These models estimate evolving shapes based on previously observed shape changes encapsulated within the statistical motion model."}, {"title": "3.2.2. Computational efficiency comparative analysis", "content": "Implementing parallel processing is key to ensuring computational efficiency. However, achieving this in FE-based methods poses challenges due to the memory access arrangement required for concurrent updates of matrix entries describing the physical state [85]. To overcome this obstacle, machine learning approaches have been effectively leveraged, benefiting from the parallelization capabilities of modern GPUs, to accelerate FE models [84]. By training on datasets generated from FE simulations, the machine learning model serves as an implicit representation of the underlying biomechanical model mechanism, eliminating the need for explicit mathematical formulations during inference. Similarly, deep learning models take advantage of parallelizing well on modern GPUs to extract complex patterns efficiently. As for other model-based methods, including statistical models, geometry-based alignment methods, and physics-based modeling, the algorithms themselves are not inherently complex and can be parallelized for computation. However, geometry-based alignment methods typically require an iterative optimization framework, which needs serial implementation, consequently diminishing some of their computational efficiency."}, {"title": "3.2.3. Ease of implementation comparative analysis", "content": "The ease of model construction and the clinical accessibility of input data will both impact the applicability of methods in real clinical settings. Ideally, algorithms that do not require additional equipment for acquiring input data will have higher clinical applicability. Altas-based modeling and deep learning methods in data-driven approaches, as well as physics-based modeling and geometry-based alignment methods in model-based approaches, can directly utilize organ surface information reconstructed from stereo 3D laparoscopy to predict organ deformations. Statistical models can also predict deformation behavior directly from 3D reconstructed organ surfaces; however, the construction of statistical models requires acquiring patient ground truth data at different respiration stages [43], thereby increasing the difficulty of the model construction phase. Moreover, biomechanical models require stress or displacement boundary conditions as input, which can be challenging to obtain in clinical practice. Acquiring stress boundary conditions necessitates measuring forces applied by surgical tools on the organ [31]. Displacement boundary conditions can be obtained by measuring the displacement of interacting instruments [29], but this also requires additional equipment for spatial tracking of the instruments. Consequently, acquiring input data for biomechanical models is more demanding compared to other methods. Utilizing neural networks to estimate boundary conditions for driving biomechanical organ models holds promise for expanding their utility in clinical settings [73]."}, {"title": "3.3. Analysis of annual distribution of relevant methods", "content": "We further analyze the annual distribution of organ deformation modeling methods to understand their evolution over time. Figure 5 presents charts showing the annual distribution of articles focusing on these algorithms, revealing trends and patterns within the research landscape.\nBetween 2004 and 2018, research efforts primarily focused on model-based algorithms, underscoring their significance. Afterwards, starting in 2019, there was a noticeable increase in studies using neural networks to directly infer organ deformations from intraoperative observations, without manual parameter assignments. This shift led to the emergence of hybrid algorithms, combining both model-based and data-driven approaches. Notably, in 2020, there was a surge in articles on hybrid algorithms, reaching a comparable level with those on model-based algorithms. This rise reflects growing recognition of the benefits of integrating both approaches. Through a synergistic combination of model-based and data-driven methodologies, it is possible to refine data-driven results to better emulate the viscoelastic characteristics of real organs, or accelerate model-based methods in obtaining essential prerequisites for deforming organ models. As the field evolves, ongoing development of hybrid algorithms holds great promise for advancing the accuracy and efficacy of deformation modeling in clinical applications."}, {"title": "4. Clinical Applications of Deformation Modeling for AR-guided Surgery", "content": "Organ deformation modeling has been explored across different surgical specialties to mitigate disparities between preoperative and intraoperative anatomical states, aiming to enhance the precision of surgical procedures. Figure 6 illustrates the distribution of research publications across these surgical specialties. Each specialty presents its own challenges, demanding tailored solutions and implementations for addressing them. The subsequent section will delve into the implementation of organ deformation modeling methods in each surgical specialty, including hepatobiliary surgery, brain surgery, breast surgery, spine surgery, vascular surgery, and renal surgery."}, {"title": "4.1. Hepatobiliary surgery", "content": "Organ deformation modeling finds applicability in hepatobiliary surgery procedures, including percutaneous tumor ablation and liver resection.\nIn the context of percutaneous tumor ablation, the internal tumor position can be predicted in real-time from the external signals, such as the motion of trackable markers attached to the skin [86]. This is achieved by establishing the correlation between the internal tumor position and external signals via regression or statistical tumor motion models [87]. Furthermore, recent advancements [10,88] have shown that even the deformation of healthy tissue near tumors, such as blood vessels, can also be predicted from external signals using neural networks. This empowers surgeons to effectively plan optimal puncture trajectories and perform tumor destruction while minimizing damage to adjacent healthy tissues. To date, in animal experiments applying liver deformation modeling, the exemplar achieved puncture accuracy is 3.52mm (pig) [89] and 2.50mm (dog) [10] in terms of targeting tumors, meeting the precision surgical safety requirement of an error less than 5mm [90].\nIn the context of liver resection, challenges arise when dealing with soft-tissue deformation modeling. Firstly, the traction exerted by surgical instruments induces large viscoelastic deformation in the liver organ, particularly in laparoscopic surgery, where pneumoperitoneum introduction further amplifies liver deformation [3]. This deformation can greatly alter the spatial relationships among the liver's internal tissues [6]. Secondly, in liver resection procedures, available intraoperative information for liver deformation modeling is relatively limited. Typically, only a partial surface of the liver can be observed, often through laparoscopic cameras or specialized depth sensors designed for liver surface digitization [91]. Inferring the deformation of the entire liver from this partial surface, especially given the lack of detailed texture information, presents a significant challenge [14,62]. To address these issues, Pfeiffer et al. [31] attempted to predict the displacement field of the entire liver directly from the deformed partial liver surface, reconstructed from intraoperative laparoscopic video streams. The predicted displacement field can then drive the deformation of the entire preoperative liver model, including the liver surface, vessels, and tumors. Results from in silico experiments indicate a strong correlation between the accuracy of liver deformation modeling and the degree of liver deformation as well as the visibility ratio of the liver surface. Labrunie et al. [49] pursued a similar approach to predict the liver's displacement field from laparoscopic video. However, instead of reconstructing the liver surface, they employed a ResNet-50 encoder [75] to extract the liver's 2D slihouettes, thereby imposing further constraints on liver deformation modeling (as shown in Figure 7). Accuracy experiments conducted in retrospective patient cases revealed a liver surface registration error of 8.5mm in low deformation cases and 16.4mm in cases involving large deformation."}, {"title": "4.2. Brain surgery", "content": "The primary approach for treating brain tumors is surgical resection, with the extent of resection being highly correlated to patient survival rates [92", "93,94": ".", "96": ".", "95": "or by directly employing neural networks to extract them from microscopic images [97,98"}, {"95": "or as constraints for aligning preoperative models with intraoperative anatomy. In addition, some studies opt for an optimization approach to iteratively update the preoperative brain model, minimizing its displacement from the intraoperative 3D brain surface [53,54,94", "30": "or directly acquired using a laser range scanner [99", "97": "reported impressive accuracy, achieving a target registration error below 1.93mm within the cortical level and immediate sub-cortical structures (depth < 15mm) during in-silico evaluations. The brain shift compensation demonstrated effectiveness of up to 68.2%, with a minimum compensation of 24.6% even in the most challenging configurations ["}]}