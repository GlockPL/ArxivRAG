{"title": "A Review on Organ Deformation Modeling Approaches for Reliable\nSurgical Navigation using Augmented Reality", "authors": ["Zheng Han", "Qi Dou"], "abstract": "Augmented Reality (AR) holds the potential to revolutionize surgical procedures\nby allowing surgeons to visualize critical structures within the patient's body. This is\nachieved through superimposing preoperative organ models onto the actual anatomy.\nChallenges arise from dynamic deformations of organs during surgery, making pre-\noperative models inadequate for faithfully representing intraoperative anatomy. To\nenable reliable navigation in augmented surgery, modeling of intraoperative defor-\nmation to obtain an accurate alignment of the preoperative organ model with the\nintraoperative anatomy is indispensable. Despite the existence of various methods\nproposed to model intraoperative organ deformation, there are still few literature\nreviews that systematically categorize and summarize these approaches. This review\naims to fill this gap by providing a comprehensive and technical-oriented overview\nof modeling methods for intraoperative organ deformation in augmented reality in\nsurgery. Through a systematic search and screening process, 112 closely relevant\npapers were included in this review. By presenting the current status of organ de-\nformation modeling methods and their clinical applications, this review seeks to\nenhance the understanding of organ deformation modeling in AR-guided surgery,\nand discuss the potential topics for future advancements.", "sections": [{"title": "1. Introduction", "content": "Recent advancements in optical see-through displays have introduced augmented re-\nality (AR) as a promising tool for surgical navigation [1]. In AR-guided surgery, 3D\ndigital organ models can be overlaid onto real anatomical structures [2]. These organ\nmodels are generated from patient-specific data obtained through preoperative com-\nputed tomography (CT) or magnetic resonance imaging (MRI) images. They encom-\npass information that presents organ shapes, surfaces, blood vessels, and tumors. The\nalignment of these digital models with patient anatomy helps surgeons to form an in-\ntuitive understanding of the spatial relationships among various anatomical structures\nconcealed beneath the organ surfaces (see Figure 1). The improved spatial awareness\nalleviates the burden for surgeons in localizing the safety-critical structures. This facil-\nitates the execution of surgical plans with a higher level of precision and more informed\ndecisions that could contribute to improved surgical outcomes [3,4].\nDespite the potentials of AR-guided surgery, its reliability can be compromised by\norgan deformations caused by factors such as patient positioning, respiratory motion,\nextrinsic compression by pneumothorax, hematoma, or the device [6,7]. These defor-\nmations lead to misalignment between the preoperative digital organ models and the\nintraoperative anatomy, affecting the accuracy of localizing tumors and vessels [8]. \u03a4\u03bf\nmake reliable surgical navigation, organ deformation modeling technique is an indis-\npensable component in the AR-guided surgery system. This modeling process involves\ncontinuously adjusting preoperative 3D organ models to adapt to the dynamic defor-\nmations occurring during surgical procedures [9]. Organ deformations can be observed\nthrough various modalities, including the locations of anatomical landmarks [8,10],\ntissue structure silhouettes [11], or 3D digitized organ surfaces [12,13]. Organ defor-\nmation modeling, at its core, involves extrapolating organ deformation fields based on\nthese intraoperative observations to adjust preoperative digital organ models.\nWhile organ deformation modeling plays a pivotal role in AR-guided surgery, achiev-\ning consistency between digital models and real organs remains a persistent challenge\ndue to technical constraints. Firstly, organ surfaces often lack distinct features suit-\nable for use as fiducials in deformation modeling, and the limited color and texture\ncontrast in intraoperative imaging modalities further exacerbate this issue [14,15]. Sec-\nondly, the intraoperative observations available for deformation modeling are relatively\nlimited, typically allowing only partial views of organs to be acquired [16]. Extrap-\nolating deformations spread across the entire organ from such limited information\nposes a significant challenge, especially given the considerable deformation that soft\ntissues within organs may experience during surgical procedures [17]. Thirdly, differ-\nent surgical specialties present unique challenges. For instance, organs such as livers\nand kidneys exhibit viscoelastic deformation behavior during surgery [18-20], while\nspinal structures deform due to their inherent flexibility [21]. In these regards, special-\nized deformation modeling methods should be tailored for each surgical specialty to\neffectively address the corresponding organ deformations.\nTo inspire potential solutions for addressing these challenges in the computer-"}, {"title": "2. Literature Search and Screening Process", "content": "The literature search and screening process were conducted according to the guideline\nof Preferred reporting items for systematic review and meta-analysis (PRISMA) [22].\nFigure 2 shows the overview of our literature processing workflow."}, {"title": "2.1. Literature search", "content": "The literature search was initially conducted in May 2023, across five scientific\ndatabases: Scopus, Web of Science, IEEE Xplore, ScienceDirect, and PubMed. An\nupdated search on Google Scholar for 2023 and 2024 articles was subsequently per-\nformed on in March 2024 in order to add more literature including ArXiv papers. To\nmake a comprehensive investigation, a number of search terms was identified, compris-\ning keywords including \"intraoperative\u201d, \u201cnon-rigid\", \"deformation\", \"registration\",\n\"modeling\u201d, and \u201cAR\u201d. Logical operators (AND/OR) were utilized to combine the\nkeywords, facilitating a thorough and proper retrieval of relevant articles from each\ndatabase. A detailed list of these search terms can be found in Appendix Table A.1."}, {"title": "2.2. Selection process", "content": "The literature search yielded a total of 3119 records, and after removing duplicates,\n2671 unique studies underwent screening. During the screening phase, titles and ab-\nstracts were reviewed to preliminarily exclude irrelevant publications. The exclusion\ncriteria comprised the following items: (1) studies containing similar content from the\nsame authors, (2) non-original research such as reviews or book chapters, (3) studies\nnot focusing on modeling organ deformation, (4) studies not proposing new methods\n(e.g., comparative studies evaluating existing methods), and (5) studies not validated\nin scenarios related to clinical settings (e.g., focused solely on medical simulations or\nvirtual surgical scenarios). Based on these criteria, 2354 records were excluded.\nSubsequently, a more time-consuming full-text assessment was conducted to deter-\nmine the eligibility of the remaining 317 studies for inclusion to this survey. Full-text\narticles had to satisfy the following inclusion criteria: (1) updating preoperative re-\nconstructed 3D organ models based on information extracted from an intraoperative\nacquisition, (2) providing a comprehensive description of the proposed method's im-\nplementation details, and (3) demonstrating clear applicability to AR-guided surgery\nin certain clinical scenarios. After applying these criteria, a final set of 112 studies\nwere included in this review paper. In this way, we hope that the screened compact\nset of references can present the most closely-related literature and highly-informative\nsummary, so that readers can find a focused survey on the specific topic of organ\ndeformation modeling approaches in AI-guided surgery."}, {"title": "2.3. Related review papers", "content": "To ensure new knowledge provided by this review, we also examine existing survey\npapers on related topics identified during the literature search and screening process.\nMin et al. [23] (2023) review registration approaches for aligning preoperative or-\ngan models with intraoperative anatomy. However, their focus is solely on orthopedic\nsurgery and thus does not cover the deformation of soft tissues. Similarly, Gsaxner\net al. [24] (2023) summarize methods for rigidly aligning digital and physical coor-\ndinates to realize surgical navigation in augmented reality space, but compensation\nfor soft tissue deformation is still lacking. Schneider et al. [25] (2021) provide a com-\nprehensive comparison of current surgical navigation systems with augmented reality\nsupport, regarding accuracy performance in laparoscopic liver surgery. While they dis-\ncuss the issue of soft tissue deformation, a technical overview of how to model organ\ndeformation is not provided. The most pertinent review on organ deformation model-\ning techniques is by Bernhardt et al. [1] (2017), who summarize non-rigid registration"}, {"title": "3. Organ Deformation Modeling Approaches", "content": "Organ deformation modeling involves predicting a deformation field as output to up-\ndate a pre-surgery reconstructed 3D organ model based on the input intraoperative\nobservations [9]. These observations can be anatomical point coordinates, or partial\norgan surface reconstructed from stereoscopic images, as illustrated in Figure 3. By\nincorporating these observations, the modeling process ensures the fidelity of preoper-\native organ models to intraoperative anatomical changes, thus accommodating tissue\ndeformations during AR-guided surgery. With the potential to enhance the surgical\nprecision, this field has attracted widespread attention, leading to the flourishing of\nvarious modeling algorithms."}, {"title": "3.1. Categorization of organ deformation modeling methods", "content": "Existing algorithms for modeling organ deformations can be broadly categorized into\nmodel-based, data-driven, and hybrid methods. Table 1 and Table 2 provide a cate-"}, {"title": "3.1.1. Model-based methods", "content": "In the field of organ deformation modeling, the majority of research efforts were ini-\ntially directed towards model-based algorithms. These early research endeavors cen-\ntered around understanding the tracking and modeling of tumor movement within\norgans during respiratory motion patterns. Clinical trials conducted by Schweikard\net al. [27] confirmed the hypothesis that a correlation exists between internal and ex-\nternal motion. This discovery laid the foundation for the development of correlation\nmodels, which could predict the intraoperative motion of internal tumors based on\nchanges in externally trackable signals, often referred to as surrogates. Correlation\nmodels found practical application in cases such as radiofrequency ablation therapy\n[13], where small tumors could be treated as rigid targets. However, when dealing with\nthe deformation of soft tissues, correlation modeling proved to have limitations in its\nfitting capacity, presenting challenges [28].\nTo achieve the goal of modeling soft tissue deformations, further exploration ensued.\nExisting model-based algorithms can be categorized into four subcategories based\non their underlying principles: (1) biomechanical models, (2) physics-based modeling\nmethods, (3) geometry-based alignment methods, and (4) statistical models.\nBiomechanical models (n = 44) account for soft tissue deformations by numeri-\ncally solving partial differential equations associated with constitutive models [29].\nFinite element (FE) methods are commonly used in the numerical solving process\ndue to their effectiveness in handling partial differential equations (PDEs). In biome-\nchanical modeling, the problem of inferring organ deformation is framed as solving\na boundary value problem, where the boundary conditions (input data) are derived\nfrom intraoperative observations [16]. Boundary conditions (BCs) on an FE model can\nbe expressed as either displacements or forces. When specifying a displacement BC, a\nnode is compelled to move to a given position. Conversely, when a force BC is speci-\nfied, it ensures that the internal stress is in equilibrium with the applied stress. With\nspecified BCs, biomechanical models have demonstrated promising capabilities in sim-\nulating the viscoelastic behavior of soft tissues within various organs, such as the liver,\nprostate, kidney, and brain [18\u201320,30]. However, their application in a real surgical set-\nting encounters difficulties. Firstly, acquiring BCs during surgery remains challenging.\nObtaining displacement BCs requires known surface correspondences, while obtaining\nforce BCs necessitates precise measurement of forces applied by surgical tools on the\norgan [31]. Secondly, directly solving FE-based biomechanical models presents logisti-\ncal limitations, such as the lengthy computational time [32]. These challenges limit the\npractical utility of biomechanical models in clinical scenarios. To address the issues,\nYang et al. [33] recently proposed a boundary constraint-free biomechanical model,\neliminating the need for predefined zero-displacements and force locations in BCs.\nMin et al. [34] explored the use of physics-informed neural networks to solve PDEs,\noffering potential solutions to computational efficiency challenges.\nPhysics-based modeling (n = 6) presents an alternative approach to soft tissue\ndeformation modeling. The fundamental concept behind these methods is to depict\norgan deformation in a physically interpretable manner. For instance, in the work by\nSuwelack et al. [35], the non-rigid deformation problem is likened to an electrostatic-\nelastic scenario, where an elastic representation of the preoperative liver model be-\nhaves akin to an electrically charged object interacting with the oppositely charged\nrigid intraoperative liver surface. The preoperative liver in its undeformed state and"}, {"title": "3.1.2. Data-driven methods", "content": "Data-driven methods were initially employed to address the limitations of directly\napplying biomechanical models in surgical procedures. Specifically, early data-driven\nmethods sought to reduce intraoperative computation of biomechanical models by\nconstructing a patient-specific atlas generated by FE-based simulation [32]. Recently,\nthere has been a growing trend in adopting machine learning approaches as implicit\nrepresentations of the underlying biomechanical model mechanism. The advantage of\nthis adoption lies in the ability of machine learning approaches to predict the com-\nplex behavior of elastic organ structures in real-time without relying on preassigned\nboundary conditions [10]. This is particularly beneficial for clinical applicability, as\nboundary conditions are often challenging to obtain in clinical settings. The following\nprovides an overview of the utilization of (1) atlas-based modeling approaches and (2)\nmachine learning approaches in deformation modeling.\nThe atlas-based method (n = 5) entails the construction of a pre-operatively com-\nputed collection of solutions, referred to as an atlas. This atlas is then used to align\nthe data acquired during surgery with the solutions within the atlas, enabling the\nprediction and correction of the intraoperative organ deformation [53]. The process of\natlas construction begins with the generation of a patient-specific finite element organ\nmodel. This model is derived from the surface description provided by a segmentation\nof the pre-operatively obtained image volumes. Boundary conditions, patient orienta-\ntions (e.g., gravity directions), and material properties are selected based on a priori\nknowledge of surgical loading conditions [54]. The preoperative FE organ model is\nthen run for each combination of conditions to create the atlas of organ deformation\nsolutions. During surgery, a set of weight parameters (output) is determined to linearly\ncombine the pre-operatively computed collection of solutions within the atlas [55]. This\nallows the organ model generated from atlas to match with the intraoperative obser-\nvations, such as 3D digitized surfaces of the organ (input). These weight parameters\ncan be iteratively solved using various algorithms, such as the iterative closest atlas\nalgorithm [32] or the Levenberg-Marquardt nonlinear optimization method [56].\nMachine learning approaches (n = 10) were initially harnessed to expedite biome-\nchanical modeling [57]. These models learn a function that maps inputs, such as ex-\nternal forces, to outputs, such as nodal displacements, by training on organ deforma-\ntion datasets [58]. Typically, these datasets consist of synthetic data generated from\nsimulating the biomechanical behavior of organs using FE methods [59]. Training the\nnetwork using synthetic datasets rather than real patient data is a trade-off. Collecting\nground truth deformation patterns of the same patient's organs would require multiple\nCT scans, which is impractical in clinical practice. Notably, studies such as [29,31,60-\n62] have shown that even when trained solely on synthetic data, machine learning mod-\nels still have the potential to accurately predict the physical deformation behaviors of\norgans. After training, the machine learning model serves as an implicit representation\nof the underlying biomechanical model mechanism, eliminating the need for explicit\nmathematical formulations during inference. Further, machine learning approaches can\nbe categorized into two main branches: traditional machine learning (TML) and deep\nlearning (DL) techniques. Specifically, traditional machine learning techniques, such\nas support vector machines and random forests, have demonstrated their potential to\nsimulate tissue behavior in real-time, including organs such as breasts [63] and livers\n[64,65]. However, these methods face limitations when applied in actual surgical set-\ntings. Traditional machine learning models rely on FE-based conditions, specifically\nstress and displacement conditions [66], as input variables. Acquiring these variables"}, {"title": "3.1.3. Hybrid methods", "content": "Hybrid methods represent the fusion of model-based and data-driven approaches, of-\nfering notable flexibility in their implementation.\nOne approach to implementing hybrid methods involves leveraging network-driven\nbiomechanical models (n = 4). This approach utilizes neural networks to estimate es-\nsential prerequisites, such as boundary conditions or deformation parameters, to drive\nbiomechanical organ models. These prerequisites are typically challenging to directly\nmeasure during actual surgical procedures. An example to better illustrate this concept\nis the work of Tagliabue et al. [73], who employed a BANet [74] to continuously esti-\nmate boundary conditions from raw intraoperative point cloud data of the deforming\nanatomy, captured by a vision sensor. The estimated boundary conditions from BANet\nguide preoperative biomechanical organ models to deform, ensuring an accurate repre-\nsentation of intraoperative organ deformations. Another example comes from the work\nof Labrunie et al. [49], where neural networks predict pose (R, T) and deformation"}, {"title": "3.2. Comparison of different deformation modeling methods", "content": "We would like to compare different deformation modeling methods based on their ac-\ncuracy, computational efficiency, and ease of implementation, categorizing their per-\nformance as \"high\", \"medium\", or \"low\" for each criterion. The \u201caccuracy\" criterion\nevaluates the method's ability to accurately predict the deformation behavior of soft\ntissues; \"computational efficiency\" indicates its suitability for real-time applications;"}, {"title": "3.2.1. Accuracy comparative analysis", "content": "In terms of accuracy, methods utilized biomechanical FE-models best explain the\ndeformation behavior induced by external forces. This is primarily due to the fact\nthat this method is grounded in continuum mechanics theory [61]. Additionally, this\nmethod can leverage prior knowledge about the mechanical load applied to organs\nto reduce the complexity of the problem space. This prior knowledge can be inte-\ngrated into constraints within the adjoint optimization scheme [82], or decomposed\ninto a set of localized point forces distributed over the active contact surfaces of the\norgan to control deformation responses [83]. Conversely, methods that solely rely on\nsurface correspondence and lack mechanical constraints, such as geometry-based align-\nment methods in model-based approaches, and data-driven methods, often lack strain\nenergy regularization within the objective function, leading to limited control over\ndeformation field irregularities. Additionally, deep learning approaches in data-driven\nmethods may exhibit voxelization artifacts, associated with data discretization proce-\ndures at convolutional layers [51]. However, incorporating physics-guided loss functions\nfor optimizing the parameters of the deep learning model has the potential to enhance\naccuracy in unseen deformation scenarios [84]. For deformations arising from regu-\nlar motion patterns, such as those caused by respiratory motion, statistical models\nperform better. This is because statistical models are directly constructed from pa-\ntient ground truth data. These models estimate evolving shapes based on previously\nobserved shape changes encapsulated within the statistical motion model."}, {"title": "3.2.2. Computational efficiency comparative analysis", "content": "Implementing parallel processing is key to ensuring computational efficiency. How-\never, achieving this in FE-based methods poses challenges due to the memory access\narrangement required for concurrent updates of matrix entries describing the physical\nstate [85]. To overcome this obstacle, machine learning approaches have been effec-\ntively leveraged, benefiting from the parallelization capabilities of modern GPUs, to\naccelerate FE models [84]. By training on datasets generated from FE simulations, the\nmachine learning model serves as an implicit representation of the underlying biome-\nchanical model mechanism, eliminating the need for explicit mathematical formula-\ntions during inference. Similarly, deep learning models take advantage of parallelizing\nwell on modern GPUs to extract complex patterns efficiently. As for other model-\nbased methods, including statistical models, geometry-based alignment methods, and\nphysics-based modeling, the algorithms themselves are not inherently complex and can\nbe parallelized for computation. However, geometry-based alignment methods typi-\ncally require an iterative optimization framework, which needs serial implementation,\nconsequently diminishing some of their computational efficiency."}, {"title": "3.2.3. Ease of implementation comparative analysis", "content": "The ease of model construction and the clinical accessibility of input data will both\nimpact the applicability of methods in real clinical settings. Ideally, algorithms that\ndo not require additional equipment for acquiring input data will have higher clini-\ncal applicability. Altas-based modeling and deep learning methods in data-driven ap-"}, {"title": "3.3. Analysis of annual distribution of relevant methods", "content": "We further analyze the annual distribution of organ deformation modeling methods\nto understand their evolution over time. Figure 5 presents charts showing the annual\ndistribution of articles focusing on these algorithms, revealing trends and patterns\nwithin the research landscape.\nBetween 2004 and 2018, research efforts primarily focused on model-based algo-\nrithms, underscoring their significance. Afterwards, starting in 2019, there was a no-\nticeable increase in studies using neural networks to directly infer organ deformations\nfrom intraoperative observations, without manual parameter assignments. This shift\nled to the emergence of hybrid algorithms, combining both model-based and data-\ndriven approaches. Notably, in 2020, there was a surge in articles on hybrid algo-\nrithms, reaching a comparable level with those on model-based algorithms. This rise\nreflects growing recognition of the benefits of integrating both approaches. Through a\nsynergistic combination of model-based and data-driven methodologies, it is possible\nto refine data-driven results to better emulate the viscoelastic characteristics of real\norgans, or accelerate model-based methods in obtaining essential prerequisites for de-"}, {"title": "4. Clinical Applications of Deformation Modeling for AR-guided Surgery", "content": "Organ deformation modeling has been explored across different surgical specialties to\nmitigate disparities between preoperative and intraoperative anatomical states, aiming\nto enhance the precision of surgical procedures. Figure 6 illustrates the distribution of\nresearch publications across these surgical specialties. Each specialty presents its own\nchallenges, demanding tailored solutions and implementations for addressing them.\nThe subsequent section will delve into the implementation of organ deformation mod-\neling methods in each surgical specialty, including hepatobiliary surgery, brain surgery,\nbreast surgery, spine surgery, vascular surgery, and renal surgery."}, {"title": "4.1. Hepatobiliary surgery", "content": "Organ deformation modeling finds applicability in hepatobiliary surgery procedures,\nincluding percutaneous tumor ablation and liver resection.\nIn the context of percutaneous tumor ablation, the internal tumor position can be\npredicted in real-time from the external signals, such as the motion of trackable mark-\ners attached to the skin [86]. This is achieved by establishing the correlation between\nthe internal tumor position and external signals via regression or statistical tumor mo-\ntion models [87]. Furthermore, recent advancements [10,88] have shown that even the\ndeformation of healthy tissue near tumors, such as blood vessels, can also be predicted\nfrom external signals using neural networks. This empowers surgeons to effectively\nplan optimal puncture trajectories and perform tumor destruction while minimizing\ndamage to adjacent healthy tissues. To date, in animal experiments applying liver"}, {"title": "4.2. Brain surgery", "content": "The primary approach for treating brain tumors is surgical resection, with the extent\nof resection being highly correlated to patient survival rates [92]. However, the phe-\nnomenon of brain shift, characterized by non-rigid tissue displacement attributed to\nfactors such as cerebrospinal fluid drainage, tissue swelling, and gravitational effects,\nintroduces misalignment between preoperative imaging and real-time intraoperative\nconditions. The misalignment may considerably affect the surgical outcome since neu-\nrosurgical procedures are often based on pre-operative planning where brain shift is\nnot considered [93,94]."}, {"title": "4.3. Breast surgery", "content": "Diagnosis of breast cancer relies on mammography and preoperative MRI, during\nwhich the patient is positioned either standing or lying prone with pendant breasts.\nHowever, when performing breast conserving surgery, the patient is typically in a\nsupine or semi-vertical position for ultrasound (US) guided interventions [100]. These\nshifts in patient positioning invariably result in breast deformation between the diag-\nnostic and biopsy phases under the influence of gravity. Additionally, the compression\nforces from the US probe can cause significant deformation and repositioning of breast\nanatomy [101]. The cumulative effect of these factors presents challenges to surgeons in\naccurately correlating tumor locations between medical images and the surgical field."}, {"title": "4.4. Spine surgery", "content": "Spinal deformations occur during surgery due to the patient's respiration and surgical\ninterventions, resulting in a disparity between preoperative CT scans of the spine and\nintraoperative conditions. Conventional intraoperative image-guided modalities, such\nas X-ray imaging, pose risks of ionizing radiation exposure for both patients and sur-\ngeons due to the need for multiple scans [103]. Addressing intraoperative deformations\nand radiation exposure are common challenges encountered in spinal surgery [104]."}, {"title": "4.5. Vascular surgery", "content": "Intraoperative interventions in vascular surgery encounter intricate vessel anatomy and\ndemand real-time visualization. Currently, these interventions are primarily guided\nby intraoperative digital substraction angiography (DSA) images [106]. However, the\nlack of critical 3D information within these images poses challenges for interventional\nradiologists in accurately identifying vessel branches, catheter tips, and the precise\nlocations of narrowed coronary arteries [107]. Furthermore, the introduction of rigid\nendovascular devices exacerbates this challenge by inducing deformations that misalign\nintended treatments with actual interventions, potentially affecting treatment success\nand patient outcomes [108]."}, {"title": "4.6. Renal surgery", "content": "Modeling organ deformation for surgical navigation is crucial in renal surgery, partic-\nularly in the context of minimally invasive procedures [112]. However, research ded-\nicated specifically to organ deformation modeling in renal surgery remains relatively\nlimited. To some extent, the methods for modeling renal deformation can draw insights\nfrom those employed in liver deformation modeling. This is because the challenges in\nmodeling deformation in renal surgery and hepatobiliary surgery exhibit similarities.\nFor instance, both renal and hepatic surfaces lack distinct texture features, and both\norgans undergo viscoelastic deformations [113].\nA study by Zhang et al. [114] introduced a coarse-to-fine registration framework\naimed at applying the coherent point drift algorithm to rectify kidney deformations in\nlaparoscopic partial nephrectomy navigation. Subsequent optimization in their study\n[12] improved the accuracy and robustness of this framework against substantial defor-\nmations, supported by quantitative evaluations. The average root-mean-square error\nof volume deformation measured at 0.84mm, and the mean navigation TRE from\nphantom experiments stood at 1.69mm."}, {"title": "4.7. Summary of deformation modeling in surgical specialties", "content": "In summary, the application of deformation modeling methods across various surgical\nspecialties presents a diverse landscape with varying levels of research activity and\nimplementation.\nHepatobiliary surgery takes a prominent position, with a large number of studies\n(n = 44, p = 41%) focusing on liver resection and tumor ablation scenarios. While\nthe radiofrequency ablation has achieved noteworthy precision (TRE less than 5mm)\nin animal experiments [10,13,89], studies concerning liver resection are still in the in-\nsilico validation stage. Further exploration is needed to establish standardized clinical\nevaluation protocols and develop modeling algorithms capable of accurately predicting\nthe complex behavior of soft tissues when subjected to large deformation [62].\nIn brain surgery (n = 17, p = 16%), the contours of cortical vessels, exposed on\nthe brain parenchyma surface, offer distinct features that are instrumental in achiev-\ning high-precise deformation modeling. Deformation modeling has demonstrated no-\ntable accuracy in mitigating disparities resulting from brain shift in-silico settings.\nApproaches involving non-rigid registration and the incorporation of biomechanical\nconstraints have shown promising levels of accuracy, particularly in cortical and sub-\ncortical structures, achieving an impressive TRE below 1.93mm [97]. Future endeavors\nshould focus on further improving the accuracy of deeper brain regions and addressing\nreal clinical situations characterized by pronounced degrees of deformation.\nBreast surgery (n = 6, p = 5%), spine surgery (n = 6, p = 5%), vascular surgery (n\n= 11, p = 10%), and renal surgery (n = 4, p = 3%) have also witnessed the application"}, {"title": "5. Discussion on Current Status and Future Works", "content": "Organ deformation modeling serves as a dependable foundation for maintaining the\nconsistency of preoperative organ models with the complex and dynamic intraoperative\nenvironment during AR-guided surgery. Overall, the current research field is still at a\nrelatively preliminary stage, with remaining technical challenges to be tackled before\npossibility of wide adoption in clinical applications.\nExisting algorithms for modeling organ deformations can be broadly classified into\nmodel-based, data-driven, and hybrid methods. Among these, biomechanical FE-\nmodels in model-based methods best explain the organ deformation behavior, and have\nbeen successfully applied to simulate the viscoelastic behavior of soft tissues. However,\nimplementing these models directly in real surgical settings presents challenges due to\nthe prolonged computational time required. Specifically, numerical methods for solv-\ning the partial differential equations associated with biomechanical FE-models result\nin solving a system of linear equations. These linear systems are large, sparse, and\noften ill-conditioned, making traditional numerical solvers inefficient. To address this,\nleveraging learning-based approaches to obtain high-performing preconditioners offers\na promising solution. The preconditioner should transform the original system into an\nequivalent one with more favorable properties for numerical solving, thereby making\nthe system easier and faster to solve.\nWe consider exploring the integration of human guidance into the deformation mod-\neling process shows promise for the next step. Currently, deformation modeling meth-\nods typically rely on pre-established surface correspondences. These methods estimate\nthe movement of visible surfaces (those with established correspondences) with biome-\nchanical constraints to propagate local motions for inferring the movement of non-\nvisible surfaces. Therefore, establishing accurate correspondences is crucial for precise\norgan deformation estimation. However, organ surfaces often exhibit highly similar\ngeometric features, such as the left and right lobes of the liver, leading algorithms to\nconverge to incorrect correspondences and affecting the accuracy of subsequent defor-\nmation modeling. Existing algorithms struggle to handle such mismatches, especially\nfor textureless surfaces. Incorporating human prior knowledge with carefully designed\ninteraction and user interface in AR has the potential to address this challenge. The\nkey to implementing this approach lies in finding the suitable interactive methods\nand efficiently leveraging the local reliable correspondence information in practice.\nMoreover, exploring methods to extend single-frame human annotations into sequen-\ntial multi-frame data is an intriguing topic. Once humans provide reliable local surface\ncorrespondences for a specific deformation state, it is important to continuously utilize\nsuch information for subsequent deformations to reduce geometric feature ambiguity.\nFurthermore, we also think that improving the accuracy performance of data-driven\nalgorithms with limited data is a topic that warrants collective discussion in this field.\nThe limited availability of data stems from the necessity of performing CT scans on\npatients during surgery to obtain ground-truth deformation of patient organs, thereby\nincreasing the risk of radiation exposure for patients [31]. Although there are currently\npublicly available datasets (cf. Table 4) providing 3D organ models of patients in\nboth preoperative undeformed and intraoperative deformed states, the dataset size is\nlimited. Existing works mainly utilize the valuable data for quantitative evaluation in\nexperiments rather than for training neural networks. There is a strong desire in this\nfield to collect and release more data for research use. Synthetic data with ground\ntruth deformation field are equally appreciated and popular at current status. Data\nefficient machine learning methods, such as transfer learning, self-supervised learning,\nfoundation models, test-time adaptation have potentials for alleviating the problem.\nLast but not least, ensuring patient safety through rigorous validation and testing\nprotocols is essential. Currently, the accuracy of organ deformation modeling is pri-\nmarily validated using phantoms or animal studies. Risk factors would be incresingly\nconsidered and more frequently discussed along with the advancement of pre-clinical\nvalidation of the AR navigation systems. Moreover, bias is a commonly reported issue\nin data-driven methods, potentially leading to unfair treatment and predicted out-\ncomes. In organ deformation modeling, bias may arise from differences in patient's\norgan morphology, severity of diseases, surgeon's subjectiveness and incomplete un-\nderstanding of deformation patterns. The reason behind this is also associated with\nthe afore-mentioned issue of data scarcity. Finally, in relation to the ethical stan-\ndards of intelligent navigation systems, if that are to be applied, building trust in"}, {"title": "6. Conclusion", "content": "This literature review presents a systematic and focused overview of methods for\nmodeling organ deformation within the context of AR-guided surgery. We adopt a\ntechnology-driven narrative to trace the development and evolution of these model-\ning techniques. Furthermore, we extend our exploration to encompass various surgical\nspecialties, shedding light on the current state of clinical applications for organ defor-\nmation modeling methods while identifying potential barriers to widespread clinical\nadoption. Building upon existing research, our aim is to provide insights into the fu-\nture works of organ deformation modeling technology, with an emphasis on unresolved\nissues that require attention to enhance its applicability. Through this review, we hope\nto provide readers with an up-to-date understanding of the organ deformation model-\ning techniques which is fundamental for AR-guided surgery, while also raising interest\nof future investigations and contributions on this topic."}]}