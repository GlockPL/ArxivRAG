{"title": "Enhancing ID-based Recommendation with Large Language Models", "authors": ["LEI CHEN", "CHEN GAO", "XIAOYI DU", "HENGLIANG LUO", "DEPENG JIN", "YONG LI", "MENG WANG"], "abstract": "Large Language Models (LLMs) have recently garnered significant attention in various domains, including recommendation systems. Recent research leverages the capabilities of LLMs to improve the performance and user modeling aspects of recommender systems. These studies primarily focus on utilizing LLMs to interpret textual data in recommendation tasks. However, it's worth noting that in ID-based recommendations, textual data is absent, and only ID data is available. The untapped potential of LLMs for ID data within the ID-based recommendation paradigm remains relatively unexplored. To this end, we introduce a pioneering approach called \"LLM for ID-based Recommendation\" (LLM4IDRec). This innovative approach integrates the capabilities of LLMs while exclusively relying on ID data, thus diverging from the previous reliance on textual data. The basic idea of LLM4IDRec is that by employing LLM to augment ID data, if augmented ID data can improve recommendation performance, it demonstrates the ability of LLM to interpret ID data effectively, exploring an innovative way for the integration of LLM in ID-based recommendation. Specifically, we first define a prompt template to enhance LLM's ability to comprehend ID data and the ID-based recommendation task. Next, during the process of generating training data using this prompt template, we develop two efficient methods to capture both the local and global structure of ID data. We feed this generated training data into the LLM and employ LoRA for fine-tuning LLM. Following the fine-tuning phase, we utilize the fine-tuned LLM to generate ID data that aligns with users' preferences. We design two filtering strategies to eliminate invalid generated data. Thirdly, we can merge the original ID data with the generated ID data, creating augmented data. Finally, we input this augmented data into the existing ID-based recommendation models without any modifications to the recommendation model itself. We evaluate the effectiveness of our LLM4IDRec approach using three widely-used datasets. Our results demonstrate a notable improvement in recommendation performance, with our approach consistently outperforming existing methods in ID-based recommendation by solely augmenting input data.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommender systems play a central role and have emerged as indispensable tools in online services [7, 11, 15, 21, 77]. They serve the critical function of offering personalized recommendations in the face of information overload, effectively aligning with user preferences across a range of tasks [9, 86]. While various recommendation tasks exist [11, 39, 69], including top-N recommendation, next-item recommendation, and rating prediction, the common approach involves learning user representations to model their preferences and intentions. These learned representations are subsequently employed to generate decisions regarding recommended items for users. In recent years, Large Language Models (LLMs) have exhibited remarkable proficiency in approximating human intentions and excelling in a wide array of tasks, including reasoning and decision-making [4, 30, 84]. Inspired by the great success of Large Language Models (LLMs) [5, 10, 62], exploring the potential of LLMs in recommendation is attracting attention [1, 12, 13, 18, 34, 81, 85], especially driven by innate reasoning capabilities and approximating human intentions of LLMs. With the exploration of LLM-based recommendation [17, 28, 43], this direction has emerged as a promising approach for the next-generation recommendation systems [44, 64, 80].\nIn the context of recommender systems, accurately capturing patterns in user interaction data (ID data) is crucial for generating relevant recommendations. The core goal of recommendation algorithms is to predict the items a user is likely to engage with based on their interaction history. Over the years, various methods have been developed to improve recommendation performance, including Markov Chains [23, 56], RNN/CNN models [23, 56], self-attentive models [31, 35, 83], and more recently, graph convolutional network (GCN)-based models [8, 65, 76]. These advancements stem from increasingly sophisticated architectures designed to better capture the complex relationships in interaction data. GCN-based models, for example, excel at capturing intricate relationships between users and items compared to"}, {"title": "2 RELATED WORK", "content": "Our work is closely related to several other lines of research. First, we discuss ID-based recommendation models, and then we explore the integration of LLM with the recommendation model."}, {"title": "2.1 ID-based Recommendation", "content": "In recommendation scenarios, the prevalent practice is to employ unique identifiers (IDs) to represent users and items, and then the user behavior (such as click and purchase behavior) is represented as an interaction matrix between user IDs and item IDs. Thus, modern recommendation models [32, 55, 78] have placed a significant emphasis on ID data and have, in fact, constructed numerous models tailored specifically to the handling of user and item IDs. The developmental trajectory of recommendation models has evolved from the traditional collaborative filtering [42], shallow factorization models [32, 53] to the more deep neural network models [25, 26].\nThe interaction behavior between user IDs and item IDs constructs the interaction matrix. This matrix can be categorized into two types based on the temporal information associated with these behaviors: one involves user interaction behavior without temporal relationships, and the other pertains to the sequential recommendation, where a clear sequential relationship between behaviors exists. For the first interaction data type, existing research methods mainly rely on recommendation models based on Graph Convolutional Networks (GCNs) [8, 24] which have become mainstream methods. For example, NCL [41] and other models have consistently achieved significant results. More recently, as contrastive learning has gained prominence, some recommendation models have integrated it into GCN-based models [75, 76]. Examples include SimGCL [76] and XsimGCL [75], which excel at capturing the correlations within ID data. For sequential recommendation data, existing recommendation models focus on modeling the structure of sequential behaviors to better understand the temporal order between them [31, 70]. Models like SASRec [31] and BERT4REC [59] leverage attention mechanisms to effectively utilize sequence behavior data. It's worth mentioning that recent studies have introduced contrastive learning into the sequential recommendation, leading to models like CL4SRec [70]. These models enhance the performance of sequence recommendation by incorporating contrastive learning and improving the understanding of user behavior sequences. In summary, various ID-based recommendation models have been developed in the research field for the interaction data with only user IDs and item IDs. Based on these models, we use LLM for data augmentation to improve the performance of existing ID-based recommendation models, thereby providing feasible solutions for exploring ID-based recommendation tasks in the current development of LLM."}, {"title": "2.2 LLM with the recommended model", "content": "For the adaption of language models in recommendations, specifically concerning the modeling paradigm, existing research can be broadly categorized into the following two main groups: LLM as RS and LLM + RS."}, {"title": "2.2.1 LLM as RS", "content": "LLM as RS is to leverage LLM as a powerful recommendation model [14, 28, 61]. Typically, the input sequence consists of textual descriptions, user behavior prompts, and instructions for the recommendation task. Then the \"LLM as RS\" generates the desired output, which may include predictions of target item scores and the ranking of the candidate item list. Some recent works explore the utilization of LLMs as RS. Dai et al. [14] proposes to enhance ChatGPT's recommendation capabilities by aligning it with ranking capabilities. This approach leverages item titles as descriptors within the prompt, followed by conducting a preliminary evaluation using generated prompts. Sun et al. [61] explore the two instructional strategies for LLMs in ranking tasks, they evaluate the capabilities of LLMs on three passage"}, {"title": "3 PRELIMINARY", "content": "In this section, we present the ID-based recommendation model and reveal the large language model in modeling ID information. The core data of a recommendation model is to represent users and items and their interaction data. Denote U (of number |U|) and V (of number |V|) as the set of users and items, respectively. For each user $u \\in U$, we can represent it by its unique ID. Similarly, for each item $v \\in V$, we can represent it by its unique ID. Users and items are only represented by ID and do not contain modality information. The interaction data are represented by a binary matrix $R = r_{uv}$, where $r_{uv} \\in {0, 1}$ indicates whether user u has interacted with item v.\nIn the ID-based recommendation model, users and items are represented by an embedding matrix $E \\in R^{(|U|+|V|) \\times d}$. According to the interaction data R, the ID-based recommendation model retrieves the embedding of users/items and then feeds it to the recommendation network. During training, the ID-based recommendation model typically designs and optimizes a loss function L, where L can be a pairwise BPR loss or other widely-used loss. In a word, various ID-based recommendation models are input as interaction data R, and these models are optimized through a loss function to make the predicted candidate items close to the real interaction data R.\nLLM and ID-based recommendation. Within the domain of language models, specifically LLM, the objective usually is to project the probability distribution of the probability word in a given textual context, denoted as:\n$p(word | context)$.\nIn LLM, input data is typically represented as tokens. Therefore, the above formula is essentially predicting the next most likely token given a series of tokens, denoted as:\n$p(next | tokens)$."}, {"title": "4 METHOD", "content": "As shown in Figure 2, the LLM4IDRec framework aims to enhance the alignment of LLMs with ID-based recom- mendation systems. We employ LLMs for data augmentation within ID-based models, leveraging the advantages of LLMs in modeling and inference capabilities. This collaboration with ID-based models allows us to effectively capture collaborative information, thereby improving the overall performance of recommendations. The proposed LLM4IDRec adopts a two-stage paradigm. The first stage is the LLM-based Data Generation. The LLM-based Data Generation feeds the historical interaction data into an LLM and then infers potential interaction data. Combining the generated potential interaction data with the original historical interaction data creates augmented interaction data."}, {"title": "4.1 The LLM-based Data Generation", "content": "In the interaction data R, given a user u with interacted item sequence $S_u = \\{v_1, v_2, ..., v_{|S_u|}\\}$, we want to predict n items $\\hat{S}_u = \\{v_{t+1}, ..., v_{t+n}\\}$ that user u may like. For almost large language model recommender systems (LLMRec), each item i is associated with a textual description d(i), such as a book title. These LLMRec models initially process each item's description d(i) by tokenizing the text and formulate a prompt $f_{prompt}(*)$ which serves to convert the interacted item sequence $S_u$ into a contextual sequence $f(d(S_u)) = f_{prompt}(d(v_1), d(v_2), ..., d(v_{|S_u|}))$. Subsequently, LLMRec feeds this contextual sequence, $f_{prompt}(d(S_u))$, into a comprehensive language model to generate recommendations tailored to the preferences of user u.\nIt's important to underscore that existing LLMRec models rely exclusively on textual descriptions and are primarily concerned with text-based data. However, the challenge that arises is that in ID-based recommendation tasks, there is no textual description associated with the items. Consequently, our proposed approach grapples with two key questions: firstly, how can ID-based data be appropriately represented within the LMRec framework? secondly, can a large language model effectively capture and model ID data?"}, {"title": "4.2 Prompt Template", "content": "We first present the process of constructing prompt templates. These templates serve the purpose of converting ID-based data into textual data for each instance. A proper prompt should contain the interaction data about the user and the item and also provide a clear task description. The following steps are undertaken to create a proper prompt:\n1) Establishing context and defining goal: Begin by providing context regarding the user and the recommendation task. It necessitates the clear articulation of the task's objectives, explicitly stating that the LLM model is tasked with offering recommended items.\n2) List the interacted items: A fundamental component of the prompt template is the enumeration of items that the user has previously interacted with or clicked. This enumeration ensures that the LLM model is equipped with the historical data requisite for generating relevant recommendations.\n3) In the process of fine-tuning the LLM model, an additional requirement is introduced wherein labeled data with user interactions and desired recommendations is provided. This labeled data can guide the optimization of the LLM model and improve performance based on real-world data.\nFor this purpose, we define the prompt template.\nDefinition 4.1. For user u and interaction item sequence $S_u = \\{v_1, v_2, ..., v_{|S_u|}\\}$, We first use the ID mapping function $f_{ID}(*)$ to obtain the unique ID corresponding to the user u and item sequence $S_u$. Then we design the following template to construct the prompts:\n* Input: Given the user($f_{ID}(u)$)'s clicked list items: $f_{ID}(v_1), ..., f_{ID}(v_{i-1}), f_{ID}(v_{i+1}), ..., f_{ID}(v_{|S_u|})$ predict what are items to recommend to the user($f_{ID}(u)$). Please only answer the items.\n* Output:$f_{ID}(v_i)$\nPlease note that the item $v_i \\in S_u$ in the output is any one item in item sequence $S_u$. In this prompt template, the prompts are tailored to what the pretrained LLM can understand, aiming to trigger its reasoning ability based on encoded knowledge. For instance, consider the relational phrase \"the user($f_{ID}(u)$)'s clicked list items $f_{ID}(v_1), ..., f_{ID}(v_{i-1u}), f_{ID}(v_{i+1u}),$"}, {"title": "4.3 Generating Training Data by Prompt Template", "content": "According to the prompt template, the construction of training data for finetuning the LLM requires the combination of user interaction data. Within the prompt template, specific item IDs must be inserted into the input section, designated as \"clicked list items: Item ID, Item ID, ..., Item ID\". It is worth noting that the number of interactive items may vary among different users, resulting in different quantities of item IDs to be filled in. We propose two implementation methods to better utilize clicked list items, Su, with varying lengths.\nWe designed two methods to integrate item IDs from Ru into the prompt template: 1. Fully generating training data: In this approach, we insert the complete item IDs from Ru directly into the prompt template. The training data generated using this method emphasizes the user's overall behavior, enabling LLM to infer which items the user might prefer based on their comprehensive behavior data. 2. Randomly generating training data: Alternatively, we employ a random sampling technique to select fixed-length item IDs from Su and incorporate them into the prompt template. The training data generated through this method concentrates on the user's local behavior, enabling the LLM to analyze the user's specific, localized behavior data to make inferences about the items that might interest the user. These two"}, {"title": "4.4 Fine-tuning for Data Adaption and Inference for Data Generation", "content": "Utilizing the provided prompt template and interaction data R, we have the capability to construct ID-based textual data. This constructed data can be effectively employed for training an LLM to model ID-based information. It is worth noting that directly fine-tuning the LLM is a computationally intensive and time-consuming process. To address these challenges, we propose the adoption of an efficient fine-tuning strategy aimed at significantly reducing the number of trainable parameters. One such approach is LoRA, which excels in parameter efficiency. LoRA not only reduces the storage requirements for adapting LLMs to specific tasks but also demonstrates superior performance compared to several other methods. Consequently, we employ LoRA as an efficient means to model ID-based information while"}, {"title": "4.5 Injecting the Fine-tuned LLM into the ID-based Recommendation Model", "content": "Let's denote the set of interactions generated through the fine-tuned LLM as $R_{LLM}$. Then, we combine the original interaction data R and the generated interaction data $R_{LLM}$ to create the augmented interaction data $R_{aug} = \\{R, R_{LLM}\\}$. The augmented data $R_{aug}$ relies on fine-tuned LLM to understand ID-based data and generate interaction data, which means that the quality of the augmented data directly reflects the generalization performance of LLM on recommendation tasks and its ability to understand ID-based data.\nTo measure the quality of the augmented data $R_{aug}$, we employ a straightforward approach. We input the augmented data $R_{aug}$ into an ID-based recommendation model without making any alterations to the recommendation model itself. If the augmented data $R_{aug}$ allows us to train a more accurate ID-based recommendation model, it demonstrates the effectiveness of our data augmentation process. This suggests that finetuning LLM can understand the ID-based data within the recommendation task and output results that align with the task's requirements."}, {"title": "4.6 Model Discussion", "content": "4.6.1 Model Analysis. The primary concern of using LLM in specific domains is how to enable LLM to understand specific domain knowledge and concepts [20, 33, 51, 58]. For instance, LLMs lack access to external knowledge sources, thereby constraining their efficacy in applications within chemistry [3]. Similarly, when we employ LLM for ID-based recommendation, a pertinent concern is how to make LLM understand the meaning of ID data in recommendation scenarios, rather than interpreting them as mere individual numbers.\nOur proposed LLM4Rec is designed to facilitate the organization of ID data, interaction data, and variables in a manner that aligns with user preferences, with the ultimate aim of fine-turning LLM for an enhanced understanding of ID data. Specifically, we are designing different structures for ID relationships in interaction data. For an item list Ru of"}, {"title": "5 EXPERIMENTS", "content": "In this section, we conduct experiments to evaluate our proposed method to answer the following research questions:\nQ1: Can our proposed LLM4IDRec improve the performance of existing ID-based recommendation models, such as the collaborative filtering model and the sequential recommendation model? If only data augmentation by LLM4IDRec is done, it can improve the performance of existing models (the collaborative filtering model and the sequential recommendation model), which indicates the effectiveness of LLM4IDRec.\nQ2: What is the composition of the data generated by our proposed LLM4IDRec? Does LLM4IDRec generate data similar to the test/real data, or does LLM4IDRec generate data that matches user preferences but is different from the test/real data? The latter situation better illustrates that LLM4IDRec provides more information to assist in ID-based recommendation, providing a new solution for applying LLM to ID-based recommendation."}, {"title": "5.1 Experimental Settings", "content": "Datasets. In our study, we conducted experiments utilizing three publicly available datasets, namely Yelp, Amazon- kindle, and Amazon-beauty. The characteristics of these datasets are outlined in Table 1. Yelp dataset has been sourced from the 2018 edition of the Yelp challenge. Additionally, the Amazon-kindle and Amazon-beauty datasets have been sourced from Amazon reviews, with a focus on selecting Kindle and beauty from the available collection. During the data preprocessing phase, a common step involves the exclusion of users and items that possess fewer than 10 interaction records. There is no sequential relationship between the ID data in the Yelp and Amazon-kindle datasets. Amazon-beauty is used for sequential recommendation, and there is a sequential relationship between the ID data. In Amazon-beauty, we adopted a leave-one-out strategy, splitting the data by the last two interactions to create validation and test sets."}, {"title": "5.2 Performance Comparison (Q1)", "content": "Table 2, 4 and 3 present the overall performance comparisons. According to the results, we have the following observa- tions:\n* LLM4IDRec can generally improve performance across all metrics and baselines. Our proposed LLM4IDRec improves the performance of all ID-based recommendation models by leveraging the power of LLM to augment input data. To illustrate this, let's consider the BPR model as an example. When considering the BPR model, its input is represented as R, while the input of the BPR+LLM4IDRec model is represented as Raug. The only difference between BPR and BPR+LLM4IDRec lies in the input data. Compared with the BPR model, the BPR+LLM4IDRec model achieved better performance with an average performance improvement of 3%. LLM4IDRec also achieved better performance on all baselines. These observations indicate that LLM is capable of generating and satisfying data for recommendation tasks, thereby having a positive impact on overall recommendation results. It is essential for LLM to possess an understanding of ID-based data and recommendation tasks to generate data that aligns with the recommendation task's goals and effectively improves recommendation performance. Otherwise, either"}, {"title": "5.3 Analysis of Augmented Data $R_{aug}$ Composition (Q2)", "content": "Our proposed LLM4IDRec generates additional data $R_{LLM}$ to augment the original dataset R. These additional data $R_{LLM}$ are generated by finetuning the LLM based on user interaction behavior and the description of recommendation tasks. We not only compare the overall recommendation performance to evaluate the effectiveness of generated data and the performance of LLM4IDRec, but we also need to do an in-depth analysis of the generated data, as this is crucial for evaluating the performance of LLM4IDRec. In this section, we investigate in detail the data generated on different datasets to further understand their composition.\n* From Figures 4 and 5, it can be observed that the proportion of generated data $R_{LLM}$ to augmented data $R_{aug}$ is 0.88% on the Yelp dataset and 0.48% on the Amazon-kindle dataset, respectively. The purpose of generated data is to improve recommendation performance. By combining the results from Table 2 and Table 3, it can be illustrated that there is a significant performance improvement when the data volume is added by less than 1%. This phenomenon shows that the data generated by our model on the Yelp and Amazon-kindle datasets is closely related to actual user preferences and the recommendation task, ensuring that the generated data is valuable for modeling user preferences and improving performance.\n* The generated data in Figures 4 and 5 only have approximately 20% overlap with the test data, while 80% of the generated data is independent of the test data. This phenomenon can be analyzed and explained in depth from two perspectives. Firstly, considering the low overlap between the generated data and the test data, there is still 20% of the data that matches. This indicates that LLM4IDRec can learn some patterns and features from the user's historical data (training data R), thereby generating content consistent with the test data. This further confirms that LLM4IDRec has a certain ability to understand user historical behavior and can generate relevant data according to the requirements of recommendation tasks. This can be seen as evidence that LLM4IDRec accurately infers user interests to a certain extent. Secondly, although most of the generated data is unrelated to the test data, it is still important. These generated data are used to synthesize augmented data $R_{aug}$, significantly improving recommendation performance on datasets such as Yelp and Amazon-kindle datasets. This indicates"}, {"title": "5.4 Comparing User Groups of Different Sparsity Levels (Q3)", "content": "The data sparsity issue has always been a significant concern in recommendation systems. In practical applications, most users tend to interact with only a few items, while a large portion of items receive minimal user engagement. Consequently, this results in sparse user-item interaction data R, making it challenging to model user preferences accurately. Our proposed solution, LLM4IDRec, can address the sparsity issue through the utilization of LLM-based data augmentation.\nTo provide a clearer explanation, we categorize user groups based on their sparsity levels. This categorization allows us to gain the performance of different user groups. Sparsity levels are determined by the number of interactions per user. Based on these sparsity levels, we divided the users in the training set into four groups, each containing an equal number of users. Using the Yelp dataset as an example, these user groups exhibited interaction frequencies of less than 20, 27, 45, and more than 45, respectively. It's worth noting that while we have chosen to present the results of LLM4IDRec using the Yelp dataset to reinforce our points, we achieved similar outcomes with other datasets as well. Due to similar trends, we omit the details related to those datasets.\nIn Figures 8, 9, and 10, we show the results for different user groups across various K values (K=10, 20, 50). These results reveal several critical observations:"}, {"title": "5.5 Replacing LLMs with existing ID-based recommendation models", "content": "To better illustrate the effectiveness of our proposed LLM4IDRec in augmented data, we also compared it with simple merging strategies involving existing ID-based recommendation models like SASRec and BPR. The \"?+SASRec\" represents utilizing SASRec as data augmentation, integrating different ID-based recommendation models. Taking the BERT4Rec+SASRec model as an example, we use SASRec to augment the interaction data, then train BERT4Rec on the augmented data and generate recommended items. Please note that this process is the same as BERT4Rec+LLM4IDRec.\nIn Table 5, 6 and 7, the experimental results demonstrated that when used for data augmentation, LLM4IDRec outperformed SASRec and BPR, resulting in a better performance improvement. Conversely, using SASRec or BPR for data augmentation led to a decrease in recommendation performance. This discrepancy can be attributed to the different approaches employed by SASRec/BPR and LLM4IDRec in handling feature space expansion. Large language models like LLM4IDRec can effectively explore a broad feature space during data augmentation, enabling the ID-based model to better learn user preferences from enhanced data. In contrast, SASRec's or BPR's data augmentation method, constrained by a smaller model, may overly memorize specific patterns in the training data, resulting in reduced generalization ability on the test set and a decline in performance for the ID-based model after incorporating this data."}, {"title": "6 CONCLUSION", "content": "In this paper, we have introduced an innovative approach called LLM4IDRec that leverages LLM in recommendation systems, particularly in scenarios where only ID data is available. Our objective was to explore the potential of LLMs in ID-based recommendations, diverging from the reliance on textual data that has been the focus of previous studies. The key idea behind LLM4IDRec was to employ LLMs to augment ID data and assess whether this augmentation could"}]}