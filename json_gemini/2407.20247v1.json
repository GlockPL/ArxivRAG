{"title": "How Homogenizing the Channel-wise Magnitude\nCan Enhance EEG Classification Model?", "authors": ["Huyen Ngo", "Khoi Do", "Duong Nguyen", "Viet Dung Nguyen", "Lan Dang"], "abstract": "A significant challenge in the electroencephalogram EEG lies\nin the fact that current data representations involve multiple electrode\nsignals, resulting in data redundancy and dominant lead information.\nHowever extensive research conducted on EEG classification focuses on\ndesigning model architectures without tackling the underlying issues.\nOtherwise, there has been a notable gap in addressing data preprocess-\ning for EEG, leading to considerable computational overhead in Deep\nLearning (DL) processes. In light of these issues, we propose a simple yet\neffective approach for EEG data pre-processing. Our method first trans-\nforms the EEG data into an encoded image by an Inverted Channel-wise\nMagnitude Homogenization (ICWMH) to mitigate inter-channel biases.\nNext, we apply the edge detection technique on the EEG-encoded image\ncombined with skip connection to emphasize the most significant transi-\ntions in the data while preserving structural and invariant information.\nBy doing so, we can improve the EEG learning process efficiently with-\nout using a huge DL network. Our experimental evaluations reveal that\nwe can significantly improve (i.e., from 2% to 5%) over current baselines.", "sections": [{"title": "1 Introduction", "content": "Electroencephalograms (EEGs) hold great potential for medical advancements,\nincluding identifying neurological disorders and enabling mind-computer inter-\nfaces [2], [5], [25]. Nonetheless, decoding the complex patterns embedded in EEG\ndata necessitates the utilization of artificial intelligence (AI). AI models can learn\nfrom and interpret vast datasets, unlocking secrets within brain waves. However,\napplying a deep learning model to EEG classification presents unique challenges\ndue to the temporal and non-linear nature of EEG signals, which can lead to\noverfitting and unreliable results.\nResearchers are working on refining model architecture and enhancing feature\nextraction to fully exploit the combined temporal and spatial nature of multi-\nchannel EEG data. Recurrent neural networks (RNNs) [26], [20] and LSTMS\n[24,28,27] and [9] excel in capturing the temporal evolution of brain activity\nacross channels, but they can overlook the crucial spatial aspect, which can lead\nto overfitting. Convolutional neural networks (CNNs) [7], [15], EEG-based ar-\nchitectures [14], [21] are better at extracting spatial features from multi-channel"}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Preliminary and Notations", "content": "We consider a dataset comprising N training samples {(x\u00b2, y\u00b2)}, with x\u00b2 \u2208 Rdx\nand y\u00b2 \u2208 Rdy denotes the ith EEG sampled signal and the corresponding ground\ntruth. Each image x\u00b2 comprises H \u00d7 W pixels denoted by x\u00b2 = {x\u00b2(a, b)}, with a\nand b as pixel indices.The dataset encompasses M ~ p(M) classes, where p(M)\ndenotes the categories' probability distribution. For a sample belonging to class\nm we have (xm, ym), where m \u2208 [1,..., \u039c]. To achieve EEG classification, we\nemploy a model parameterized by a weight matrix W = [w\u2081,...,wm]. The ob-\njective is to optimize this model by minimizing the Cross-Entropy Loss function\n(Equation 2), which effectively measures the discrepancy between the predicted\nclass probabilities and the true class labels. The specific problem tackled in this\nwork can be formally described by Equation (1).\nminC(W) = \\frac{1}{NM}\\sum_{i=1}^{N}\\sum_{m=1}^{M} [F(x^{i},y^{m}|W)]\nWERdXM\n(1)"}, {"title": "2.2 Overall Architecture", "content": "The proposed methodology (Figure 1) for EEG signal classification uses a two-\nstep preprocessing approach to improve signal quality and feature extraction.\nThis approach tackles the inherent variability in power distribution observed\nacross EEG channels. First, the Inverted Channel-wise Magnitude Homogeniza-\ntion (ICWMH) technique is used to normalize signal amplitude, ensuring a bal-\nanced input for subsequent processing stages. This transformation encodes each\nEEG signal sample denoted as x\u00b2 into an EEG-encoded image suitable for the\nCNN model. The encoded image is then enriched using a Feature Enrichment\nvia Skip Connection (FEvSC) approach, which uses edge detection to capture\nvariant information from the image. This information is then integrated back\ninto the encoded image using the Hadamard sum, providing a more comprehen-\nsive representation of the CNN model. The enriched image, incorporating both\noriginal data and edge-derived features, is stacked into a three-layer structure,\nwhich is fed into the convolution operator of the CNN for classification, resulting\nin improved classification performance."}, {"title": "2.3 Inverted Channel-wise Magnitude Homogenization (ICWMH)", "content": "The input data x\u00b2 \u2208 RC\u00d7L (refer to Figure 1) is a composition of multiple\nstochastic random processes x(t), where C, L is the number of channels and\nchannel signal length, respectively. The overall problem is maximizing the log-\nlikelihood between the distribution of channel-wise signal p(y\u00b2x,...,x) and\nthe estimated class distribution p(x\u00b2y\u00b2) (refer to Equation 3). Figure 1 illus-\ntrates the differences in power P, or signal strength, across channels owing to\nthe underlying neuronal activity and the amplitude of measured neural currents.\nFurthermore, the variance distribution of these signals (p\u2260p \u2200 h\u2260k) high-\nlights how the dominant frequencies differ across brain regions. Consequently,\nthe gradients across channels \u2207wF(x) are dominated by the overwhelming one.\nF(x^{i}, y^{i}) = \u2212 \\sum_{m=0}^{M-1} log (p(y_{m}|x_{0},...,x_{c}) p(x^{i}_{m}))\n(3)\nTo address the issue of dominant magnitude across channels, ICWMH (see\nFigure 1) aims to equalize signal magnitudes before training. This ensures each\nchannel contributes equally, mitigating the dominance of specific channels by"}, {"title": "2.4 Variant Feature Extractor", "content": "In the EEG-encoded image, the salient features come from the change between\nimage regions. Thus, by applying edge detection on the image (Figure 2), we"}, {"title": "2.5 Feature Enrichment via Skip Connection (FEvSC)", "content": "The Feature Enrichment via Skip Connection (FEvSC) approach is proposed to\nimprove the classification performance of an EEG model. It uses the strengths\nof the first proposed technique, ICWMH, and edge detection methods to enrich\nthe feature space of EEG data. The approach as described in Equation 7 aims to\nmitigate redundancy while preserving essential structural and variant features\ninherent in EEG signals, enhancing predictive accuracy.\nx\u00b2 = ICWMH(x\u00b2) + I(x\u00b2)\n(7)\nIn this equation, I represents an affine transformation influenced by general\nedge detection principles. Edge detection in EEG signal analysis helps isolate\nsignificant boundaries and transitions, indicating critical neural activities and\naccentuating high-frequency components associated with subtle brain activities.\nThis enhances contrast and clarity of signal features, highlighting areas of neu-\nral activity crucial for accurate classification. The FEVSC approach uses skip\nconnections in its neural network architecture, allowing direct access to both\nraw and processed EEG signals. These enriched features provide refined input,\naiding in learning complex patterns for accurate EEG classification. Combining\nedge detection and skip connections offers a promising direction for improving\nEEG classification system performance."}, {"title": "3 Experiment", "content": "Datasets) Perceive Lab [24], [21]. The Perceive Lab dataset contains EEG\nresponses from 6 subjects who viewed 2,000 unique objects (40 classes from Im-\nageNet [6]) during 10 seconds to achieve 11,964 EEG segments. Each sample has\n128 channels and 500 time-step data. The dataset is sampled in 50Hz with notch\nfiltering, channel-wise z-score normalized, and bandpass filtered across three fre-\nquency ranges. High-gamma-dataset (HGD) [23]. The High-Gamma Dataset\nis a 128-electrodes dataset from 14 healthy subjects, consisting of 1000 four-\nsecond trials of executed movements divided into 13 runs per subject. The four\nclasses of movements were left, right, feet, and rest. The datasets are each divided\ninto training (80%), validation (10%), and test (10%) sets.\nModels) We reimplemented and evaluate LSTM networks, stacked bidi-\nrectional LSTMs [24,28,27,9], EEGNet [14] and EEGChannelNet [21] model,\nSiamese networks [21], 2D EGG-encoded grayscale heatmaps [19]. We trained\nthese models under identical conditions with the learning rate of 9e 04, the\nbatch size is 64, and the optimizer is Adam under 100 epochs. This compre-\nhensive exploration provided valuable insights into the effectiveness of different\nEEG classification approaches.\nProblems) This study presents a two-step preprocessing method for enhanc-\ning feature representation. First, data is normalized using Inverted Channel-Wise\nMagnitude Homogenization (ICWMH). Second, the variant feature is extracted\nthrough edge detection, using Gaussian blur to reduce noise and employing\nAdaptive Edge and Canny Edge Detection techniques.\nHyperparamter Tuning) In particular, the training configuration for Per-\nceive Lab dataset employs Canny edge detection with thresholds (50, 120) in\nbilinear interpolation mode, along with a Gaussian blur kernel size of (3, 3).\nFor the HGD dataset, the baseline configuration utilizes adaptive edge detection\nwith mean thresholding in bilinear interpolation mode and the same Gaussian\nblur kernel size."}, {"title": "3.1 Comparison to State-of-the-art methods", "content": "ICWMH with Edge Detection shown in Table 1, achieves an accuracy of approxi-\nmately 66% on a dataset of 40-class images from the Perceive Lab challenge. This\nsurpasses previous approaches, such as GIE (Grayscale Image Encoded), which\nachieved 64% accuracy. The key improvement lies in its additional edge detection\nstep, which extracts critical features within the EEG data, boosting accuracy\nto 65.78%. This approach outperforms standard and specialized architectures\nlike LSTMs and EEGNet by a large margin and surpasses EEChannelNet by\nnearly 20%. ICWMH+ED's ability to extract richer information from EEG data\npaves the way for advancements in brain-computer interfaces and neurological\ndisease diagnosis. When applied to the HGD dataset, ICWMH+ED achieves an\naccuracy of 57.18%, double the accuracy of the grayscale-encoded image method\nwithout edge detection. This demonstrates the promise of ICWMH+ED in EEG"}, {"title": "3.2 Ablation Study", "content": "Interpolation Method) The study examines the impact of different interpo-\nlation methods on EEG classification performance (refer to Table 2), focusing\non 'bilinear' and 'nearest' techniques. The 'bilinear' method [18] achieves base-\nline accuracy for both datasets, while the 'nearest' method [22] results in lower\naccuracy, especially in the HGD dataset, where the accuracy drops significantly\nto half of the baseline. The choice of interpolation significantly impacts the clas-\nsification model's effectiveness.\nEdge Threshold) The study investigates different threshold values [1], [3]\nin EEG data. The threshold of (50, 120) set Perceive Lab dataset achieves the\nhighest accuracy (65.78%). Lower threshold settings show a slight decrease in\naccuracy (64.74%), while higher threshold settings result in a significant drop\nin accuracy (51.75%), potentially omitting crucial information and leading to\nunderfitting. The HGD dataset performs best with a threshold of (40, 120),\nachieving 56.81% accuracy. A stricter threshold setting leads to lower accuracy,\nespecially with an increased upper threshold, causing underfitting and a signifi-\ncant drop in accuracy.\nGaussian Blur Kernel) The paper explores the impact of different Gaus-\nsian blur kernel sizes [17] on EEG classification accuracy. The baseline kernel size\nof (3,3) achieves the highest accuracy at 65.78% for Perceive Lab and 57.18% for\nthe HGD dataset. However, as kernel size increases to (5,5) and (7,7), accuracies\ndecrease, possibly due to excessive smoothing, which can lead to a loss of critical\nsignal detail. This highlights the importance of selecting an appropriate level of\nGaussian blurring for EEG image preprocessing."}, {"title": "Edge Threshold)", "content": "The experiment also investigates the effectiveness of\nadaptive thresholding methods [16] for edge detection. Adaptive Mean Thresh-\nolding achieves an accuracy of 62.98% for Perceive Lab and baseline accuracy for\nthe HGD dataset, effectively balancing local variations in illumination in EEG\nimaging. Adaptive Gaussian Thresholding, however, achieves lower accuracy for\nboth datasets, suggesting a more localized approach to thresholding."}, {"title": "4 Conclusion", "content": "This paper presents a groundbreaking EEG classification method using Inverted\nChannel-wise Magnitude Homogenization (ICWMH) and Edge Detection. The\nmethod achieves approximately 66% accuracy rate in 40 classes of classifica-\ntion tasks, highlighting the importance of improved feature representation and\nbalanced channel input. The process converts EEG signals into expanded di-\nmensional representations and integrates long-range dependencies, extracting a\nbroader set of features. The study emphasizes the need for careful hyperparame-\nter calibration and the delicate interplay between noise suppression and feature\nretention in EEG signal classification success. The methodology could serve as\na new benchmark in the field."}, {"title": "A Related Works", "content": "Model Architecture Design Within the domain of EEG classification, sig-\nnificant research efforts have centered on optimizing established models like Re-\ncurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs)\nfor enhanced performance [11]. [24] explored the potential of Long Short-Term\nMemory (LSTM) networks and their stacked variants, while [28] focused specif-\nically on LSTMS-B with Swish activation and bagging ensembles. Further inves-\ntigations by [9] and [27] extended to BiLSTMs and attention-based models for\nvisual object classification based on EEG signals. While RNNs excel at captur-\ning temporal dynamics, concerns regarding potential overfitting due to limited\nspatial information extraction remain. This contrasts with CNNs, which demon-\nstrate strong efficacy in EEG classification by effectively extracting relevant\nbrain activity features. [14] solidified the value of CNNs in this domain through\ntheir compact EEGNet architecture specifically designed for EEG-based brain-\ncomputer interfaces. Further emphasizing the versatility of CNNs for EEG data,\n[21] proposed EEGChannelNet, employing 1D CNNs for robust feature extrac-\ntion. These advancements reflect the ongoing pursuit of improved performance\nand adaptability in EEG classification through continued model optimization\nand innovation.\nFeature Enhancement Prior research has significantly improved EEG feature\ndata for better classification accuracy. [21] and [24], [10] pioneered the use of\na Siamese network architecture to learn a joint embedding between EEG sig-\nnals and images. This approach maximizes the similarity between embeddings\nfrom both modalities, thereby enhancing the model's representational power\nfor EEG-based visual classification tasks. Further advancing EEG data utiliza-\ntion, [19] introduced an innovative approach to transforming EEG signals into\ngrayscale heatmap representations. This conversion from 1D signals to a 2D im-\nage format leverages the strengths of Convolutional Neural Networks (CNNs) by\nmaking relevant features more readily extractable for classification tasks. These\nadvancements demonstrate the ongoing focus on enriching EEG feature data to\nunlock its full potential for accurate and reliable brain-computer interaction."}]}