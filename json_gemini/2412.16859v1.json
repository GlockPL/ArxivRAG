{"title": "Adversarial Diffusion Model for Unsupervised Domain-Adaptive Semantic Segmentation", "authors": ["Jongmin Yu", "Zhongtian Sun", "Shan Luo"], "abstract": "Semantic segmentation requires labour-intensive labelling tasks to obtain the supervision signals, and because of this issue, it is encouraged that using domain adaptation, which transfers information from the existing labelled source domains to unlabelled or weakly labelled target domains, is essential. However, it is intractable to find a well-generalised representation which can describe two domains due to probabilistic or geometric difference between the two domains. This paper presents a novel method, the Conditional and Inter-coder Connected Latent Diffusion (CI-CLD) based Semantic Segmentation Model, to advance unsupervised domain adaptation (UDA) for semantic segmentation tasks. Leveraging the strengths of latent diffusion models and adversarial learning, our method effectively bridges the gap between synthetic and real-world imagery. CICLD incorporates a conditioning mechanism to improve contextual understanding during segmentation and an inter-coder connection to preserve fine-grained details and spatial hierarchies. Additionally, adversarial learning aligns latent feature distributions across source, mixed, and target domains, further enhancing generalisation. Extensive experiments are conducted across three benchmark datasets-GTA5, Synthia, and Cityscape-shows that CICLD outperforms state-of-the-art UDA methods. Notably, the proposed method achieves a mean Intersection over Union (mIoU) of 74.4 for the GTA5 to Cityscape UDA setting and 67.2 mIoU for the Synthia to Cityscape UDA setting. This project is publicly available on https://github.com/andreYoo/CICLD.", "sections": [{"title": "1. Introduction", "content": "Semantic segmentation, a fundamental task in computer vision, involves assigning labels to each pixel in an input image with high granularity. Over the past decade, significant efforts have been dedicated to advancing this field, leading to notable improvements through deep representation learning techniques [1, 2]. Competitions on major open benchmark datasets [3, 4, 5] have spurred the development of increasingly robust models; however, despite achieving new heights in benchmark performance, these models frequently face difficulties in real-world applications such as autonomous driving, which demand consistently high performance from the perception module. This discrepancy arises because benchmark datasets are typically biased towards specific environments, whereas real-world testing scenarios can present substantial domain variations due to factors like geographic location, lighting, camera differences, and weather conditions. Consequently, even highly advanced models can experience significant performance degradation in these situations, an issue that cannot be easily resolved by merely enhancing model complexity.\nThe most straightforward practical approach to enhancing a network's generalisation capability is to gather and annotate data from a wider range of scenes. Nonetheless, densely annotating images is an arduous and labour-consuming process. For instance, in the Cityscapes dataset, [5], each image requires approximately 90 minutes to annotate. To address this limitation, researchers have developed methods to produce densely annotated images from rendered scenes efficiently, exemplified by the Synthia Dataset [4] and the Grand Theft Auto V (GTA5) Dataset [3]. However, the substantial visual disparity between simulated and real domains can markedly diminish the performance of models trained on synthetic data.\nDue to these limitations, various domain adaptation methods have been developed to improve performance by exchanging information between data containing from diverse sources. Depending on the existence of labels in the domain for which performance is to be improved, domain adaptation can be classified as supervised [6, 7], semi-supervised [8, 9, 10, 11, 12, 13, 14], self-supervised [15], and unsupervised domain adaptation [16, 17, 18]. The purpose is to transfer information extracted from one domain to another domain. In this process, to improve the generalisation performance of the neural network itself, networks with various structures such as transformers [19] or spatial and channel attention mechanism [20] were used, and learning methods such as teacher-student learning were used [19, 15].\nWe tackle the intricate problem of unsupervised domain adaptation (UDA) in"}, {"title": "2.1. Semantic segmentation", "content": "Semantic segmentation is a fundamental task in computer vision that involves classifying each pixel in an image into a predefined category. This fine-grained classification is essential for various applications, including autonomous driving [24], medical imaging [25, 26], and scene understanding [27]. Recent advancements in this field have been significantly influenced by the development of deep learning, particularly convolutional neural networks (CNNs) [28]. However, recently, the landscape of semantic segmentation has evolved with the introduction of novel approaches such as transformers [27, 24, 26, 29, 22], self-supervised learning [30, 31], and diffusion models [32, 33, 22]. Each of these methods brings unique advantages and challenges, contributing to the rich diversity of the current state-of-the-art in semantic segmentation."}, {"title": "2.2. Unsupervised domain adaptation", "content": "Unsupervised Domain Adaptation (UDA) entails training a model to transfer knowledge from a domain with available labels to a domain without annotations [19]. Recently, UDA techniques for semantic segmentation have seen significant advancements through the use of data augmentations [38, 39], feature alignments [40, 22], and self-supervised learning [19, 20]. Traditionally, these methods have leveraged synthetic datasets like GTA5 [3] or Synthia [4] as the labelled source domain, transferring knowledge to real-world datasets such as Cityscapes in the unlabelled target domain. These conventional benchmarks are reasonable because making a synthetic segmentation dataset is way easier than labelling real images. However, it is obvious that context information, such as texture and object variations of synthetic images and real images, are very different. This context information gap makes learning highly generalised representations from synthetic images very important.\nIt is widely recognised that the generalised representational power of a segmentation model often does not translate effectively across domains, leading to inferior cross-domain performance. Consequently, domain adaptation for semantic segmentation has become a highly active area of research. Various adaptation methods have been introduced, including adversarial training at the input image level [39], feature level [16, 39], and network output level [17]. For instance, Hoffman et al. [39] seek to mitigate the domain gap by first converting source images to the target style using a cycle consistency loss, followed by aligning cross-domain feature distributions through adversarial training. Additionally, Saito et al. [40] propose a method to identify non-discriminative samples near decision boundaries using a critic network, enabling the generator to produce more discriminative features by deceiving the critic network with adversarial training. Zhang et al. [41] introduced a curriculum adaptation method to regularise the predicted label distributions in the target domain, ensuring they align with the label distributions in the source domain.\nTo improve the semantic segmentation model's representation performance and consequently the unsupervised domain adaptation's result, we have designed a diffusion model-based semantic segmentation model and formulated an adversarial learning-based unsupervised domain adaptation. Our diffusion-based method can learn more generalised and outstanding representations from synthetic images and convey representational information for the target domain via adversarial learning."}, {"title": "3. The proposed method", "content": ""}, {"title": "3.1. Preliminaries", "content": "The goal of diffusion models [23] is to find the parameterised data distribution $P_{\\theta} \\approx p(x_0)$ using a given data $x_0 \\sim q(x_0)$. To do this, when a data $x_0$ is given, the training of diffusion models conducts a forward process (a.k.a. diffusion process) $q(x_t|x_{t-1})$, which adds Gaussian noise to the data and a reverse process (a.k.a. denoising process) $p_{\\theta}(x_{t-1}|x_t)$, which denoises the given noised data by subtracting predicted noise.\nThe forward process $q(x_t|x_{t-1})$ is a task to add Gaussian noise to data at a certain time step $t < T$. The Gaussian noise is generated by a Gaussian probability $\\mathcal{N}(\\cdot)$ with scheduled variance: $\\beta_1, ..., \\beta_T$. The entire forward process to generate completely noised sample $x_T$ is represented by\n$\\begin{aligned}\nq(x_{1:T}|x_0) := \\prod_{t=1}^{T} q(x_t|x_{t-1}),\\\\\nq(x_t|x_{t-1}) := \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t I).\\nonumber\n\\end{aligned}$\n\nThe reverse process $p_{\\theta}(x_{t-1}|x_t)$ can be considered as a denoising task. For each time step $t$, a diffusion model predicts a noise and subtracts it from the noised data. This task is represented by Markov Chain so that it can be represented by"}, {"title": "3.2. Methodology overview", "content": "Fig. 1 provides our proposed approach's structural details and loss functions. For unsupervised domain adaptation, the input to our model is a source image $x^s$ and a target image $x^t$ sampled from the source and target distributions, respectively. We subsequently create a mixed image $x^{s+t}$, where the source and target images are mixed using the approach in ClassMix [42]. Here, source pixels belonging to randomly sampled classes are overlayed on the target image, and pixel-level augmentations are applied to the resulting mixed image. The same module is applied in the labels as well; however, the UDA task operates under the assumption"}, {"title": "3.3. Architectural details of CICLD", "content": "Several studies have been presented that apply diffusion models for semantic segmentation [34, 35, 36, 37]. However, those approaches still face challenges"}, {"title": "3.4. Training objectives", "content": "Conditional LDM loss: We reformulate the diffusion loss function in the DDPM [23] to apply the diffusion process to the latent feature space. The loss function is used to optimise the Unet $f_{unet}$ only by minimising given noise $\\epsilon$ and the predicted noise by the Unet $\\bar{\\epsilon}$. The loss function for the diffusion process is formulated as"}, {"title": "3.5. Training and Inference", "content": "We conduct pre-training and fine-tuning to optimise the CICLD for unsupervised domain adaptive semantic segmentation. The pre-training is essential for diffusion-based segmentation, which is very slow to optimise the model. Also,"}, {"title": "5. Ablation study", "content": ""}, {"title": "5.1. Effectiveness of the conditioning", "content": "We built the conditioning module to improve the contextual property when a given latent feature is being denoised and transferred for semantic segmentation, and it is one of the key differences between our method and other diffusion-based segmentation methods [34, 35, 36, 37, 43].\nTo demonstrate the effectiveness of the conditioning module for semantic segmentation using the diffusion model, we conduct ablation studies by comparing the segmentation performances depending on the usage of the conditioning module."}, {"title": "5.2. Effectiveness of the inter-coder connection", "content": "The inter-coder connection is built to bring the wide range of latent features available from the encoder's feature extraction process to the decoder. The inter-coder connection is motivated by the skip connection on the UNet [56] and ResNet [2] so we expected to improve the feature representation performance by concatenating the low-level and high-level latent features from the encoder to improve the"}, {"title": "5.3. Effectiveness of LAdv", "content": "We formulate adversarial learning using cross-entropy and KL-divergence to explicitly align the latent feature distributions for the source and target domains. Unlike other UDA methods using adversarial learning, which apply the adversarial learning strategy for the source and target domain only, our adversarial learning takes three domains i.e., the source, mixed, and target domains, so that, rather than computing the cross-entropy loss with the fake labels about the target domains for updating the encoder, our adversarial learning tries to minimise the KL-divergence between the classification likelihood and the uniform distribution.\nWe conducted ablation studies to demonstrate the effectiveness of adversarial learning. Table 2 shows the segmentation performances depending on the loss function settings. We not only compare the segmentation performance depending on the usage of adversarial learning but also compare the segmentation performance with other adversarial and contrastive learning-based UDA methods [49, 15, 50]. The experimental results demonstrate the effectiveness of adversarial learning. The models trained with objective functions with the proposed adversarial loss always perform better than those trained with the loss functions, considering the two classes of adversarial loss. The best performance was achieved by the model"}, {"title": "6. Comparison with existing UDA methods", "content": "We begin by comparing the proposed approach with existing UDA methods [17, 18, 51, 52, 53, 54, 19, 55]. We show that our method achieves better performance than the current state-of-the-art methods by a margin of +0.6 mIoU in GTA5 \u2192 Cityscapes and +1.4 mIoU in Synthia \u2192 Cityscapes in Table 3. Class-wise improvements can be seen in 11 of the 19 classes in GTA5 \u2192 Cityscapes, where major improvements can be seen in difficult classes like Wall, Rider, Fence, etc., and 12 of the 16 classes in Synthia \u2192 Cityscapes, as also supported quantitatively in Table 3.\nThe proposed method achieves 74.4 mIoU for the GTA5 \u2192 Cityscapes UDA setting and 67.2 mIoU for the Synthia \u2192 Cityscapes UDA setting. Overall, the proposed method outperforms the other methods. However, the HRDA [55] performs better in the GTA5 \u2192 Cityscapes UDA settings in some particular classes. The HRDA [55] achieves better performances for the sidewalk (S.Walk), building (Build), pole, vegetation (Veget), person, bus, train, and bike. In the Synthia \u2192 Cityscapes UDA results, BAPA [53] and HRAD [55] show better performance for some particular classes. The BAPA [53] produces 86.8 IoU for the Veget class, and the HRDA achieves 60.9 IoU and 89.0 IoU for the traffic sign (T. Sign) and car, respectively. However, the performance gap between those methods and our method is usually less than 0.2, suggesting that the proposed method also achieves very competitive performance for the above classes.\nWe not only compare the quantitative results but also the qualitative results. Fig. 5 shows the segmentation results of the proposed method and some methods achieving comparable performance with ours. HRDA [55] and DAFormer [19] are selected because those methods produce 2nd and 3th ranked performances based on mIoU. We also show the visualisation results of the UDA segmentation results using BAPA [53] since it produces the best performance for the Veget clase on the Synthia \u2192 Cityscape UDA setting (86.8 IoU, see Table. 3). The visualisation results show that the proposed method produces less noisy segmentation results for both UDA settings, which can interpreted as our method can have a more generalised representation from a source domain."}, {"title": "7. Conclusion", "content": "In this paper, we propose a Conditional and Inter-coder Connected Latent Diffusion (CICLD) for unsupervised domain adaptive semantic segmentation. The CICLD, leverages latent diffusion models (LDMs) and adversarial learning to enhance the generalisation capability of semantic segmentation models across different domains. The key contributions include the conditioning module, which enhances generalisation by modelling gradual transitions between domains and improving segmentation accuracy through a conditioning mechanism for segmentation masks. The Inter-coder Connection is a structural innovation that preserves fine-grained details and spatial hierarchies, crucial for precise semantic segmentation. The adversarial learning component explicitly aligns latent feature distributions from source, mixed, and target domains, enhancing the model's ability to generalise across different domains with a novel three-class adversarial loss. Experimental results demonstrate that CICLD significantly outperforms state-of-the-art UDA methods on benchmarks such as GTA5 to Cityscapes and Synthia to Cityscapes, with notable improvements in mean Intersection over Union (mIoU) scores, particularly in challenging classes like walls, riders, and fences. The model achieved 74.4 mIoU for the GTA5 to Cityscapes UDA setting and 67.2 mIoU for the Synthia to Cityscapes UDA setting, surpassing existing methods. Overall, CICLD presents a robust and innovative solution for unsupervised domain adaptation in semantic segmentation, showing considerable potential for real-world applications by effectively handling domain variations and improving segmentation model performance in diverse environments.\nHowever, even though the proposed method shows outstanding performance compared with the existing state-of-the-art methods, there is a critical drawback which has to be resolved in the future. The huge, time-consuming diffusion process is it. Our method contains the noising and denoising process for the diffusion model, and, this process is very time-consuming. Additionally, the performance, depending on the number of sampling steps, is a critical issue. This issue is a common problem in all studies leveraging diffusion models. In conclusion, our method has shown promising results, but there is room for improvement in computational complexity and processing speed. Our future research will focus on optimising the algorithm and exploring more efficient techniques to develop a more robust and scalable solution for UDA tasks."}]}