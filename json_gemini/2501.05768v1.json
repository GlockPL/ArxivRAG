{"title": "Halal or Not: Knowledge Graph Completion for Predicting Cultural\nAppropriateness of Daily Products", "authors": ["Van Thuy Hoang", "Tien-Bach-Thanh Do", "Jinho Seo", "Seung Charlie Kim", "Luong Vuong\nNguyen", "Duong Nguyen Minh Huy", "Hyeon-Ju Jeon", "O-Joun Lee"], "abstract": "The growing demand for halal cosmetic products has exposed\nsignificant challenges, especially in Muslim-majority coun-\ntries. Recently, various machine learning-based strategies,\ne.g., image-based methods, have shown remarkable success\nin predicting the halal status of cosmetics. However, these\nmethods mainly focus on analyzing the discrete and specific\ningredients within separate cosmetics, which ignore the high-\norder and complex relations between cosmetics and ingredi-\nents. To address this problem, we propose a halal cosmetic\nrecommendation framework, namely HaCKG, that leverages\na knowledge graph of cosmetics and their ingredients to ex-\\plicitly model and capture the relationships between cosmet-\nics and their components. By representing cosmetics and in-\ngredients as entities within the knowledge graph, HaCKG ef-\nfectively learns the high-order and complex relations between\nentities, offering a robust method for predicting halal status.\nSpecifically, we first construct a cosmetic knowledge graph\nrepresenting the relations between various cosmetics, ingre-\ndients, and their properties. We then propose a pre-trained\nrelational graph attention network model with residual con-\nnections to learn the structural relation between entities in the\nknowledge graph. The pre-trained model is then fine-tuned\non downstream cosmetic data to predict halal status. Exten-\nsive experiments on the cosmetic dataset over halal prediction\ntasks demonstrate the superiority of our model over state-of-\nthe-art baselines.", "sections": [{"title": "Introduction", "content": "The cosmetic industry includes various products and in-\ngredients, ranging from skincare and perfumes to other\nitems designed for beauty enhancement and personal care\n(Rauda Ramdania et al. 2022). These cosmetic products of-\nten feature a variety of natural, synthetic, and innovative in-\ngredients designed to cater to consumers' evolving needs\nand preferences. However, awareness of cosmetics' ingredi-\nents does not always align with consumer consumption pat-\nterns, particularly when it comes to distinguishing between\nhalal and haram cosmetics. For instance, most consumers\noften neglect to check labels or review the detailed compo-\nsition of beauty products. This oversight may lead to the on-\ngoing use of products without fully understanding their in-\ngredients or possible effects (Rauda Ramdania et al. 2022;\nKim et al. 2011). Furthermore, although awareness of halal\nstandards and ingredients in cosmetic products is growing\namong consumers, identifying halal versus non-halal prod-\nucts remains challenging. These challenges arise due to the\ndiverse range of brands, each offering products with dif-\nferent ingredient compositions and chemical formulations\n(Park et al. 2007).\nHalal ingredients are necessary for Muslims to comply\nwith dietary laws outlined in Islamic principles. For exam-\nple, the ingredients within products should not include pro-\nhibited things like pork, alcohol, or any animal, according to\nIslamic guidelines (Rauda Ramdania et al. 2022). With the\ngrowing demand for halal products globally, many indus-\ntries, from food to drugs, are working to ensure their prod-\nucts comply with halal standards. The growing demand for\nhalal products has led to the establishment of numerous halal\ncertification institutes worldwide. Currently, there are more\nthan 500 halal certification institutions worldwide (Tieman\nand Williams 2019). However, no international board man-\nages a centralized database to unify halal certification data\nacross institutions (Rakhmawati et al. 2021). Consequently,\na single product may carry multiple halal certificates from\nvarious organizations since each institution has its own stan-\ndards and regulations.\nRecently, machine learning-based methods have been ap-\nplied to identify halal ingredients in cosmetic products\n(Karimah and Darwanto 2021; Cetin and Dincer 2016).\nThe adoption of machine learning-based methods for ha-\nlal certification introduces both opportunities and challenges\nthat have significant ethical and societal implications. These\nmethods offer transformative potential in addressing the\nchallenges of halal certification and making halal certifica-\ntion more accessible, especially for small organizations that\nstruggle to meet traditional methods' cost or time require-\nments.\nInspired by the success of the image processing methods\nin computer vision, the halal status of products can poten-"}, {"title": "Related work", "content": "We now discuss several machine learning-based strategies\nto identify the status of cosmetic products compared to our\nstrategy. The recent strategies can be categorized into three\nmain approaches: text-based strategies, image processing-\nbased strategies, and graph-based strategies.\nText-based strategies focus on analyzing ingredient lists\nor product descriptions to determine compliance using a\nlarge text corpus. For example, DIETHUB (Petkovi\u0107 et al.\n2021) is a tool designed to predict and recommend prod-\nuct recipes based on a hierarchy, describing food entity re-\nlations from Hansard's corpus (Mollin 2007) with various\nfood entity annotations and recipes. The large number of\nproduct entities in the corpus enables various ingredients and\nrecipes, catering to different dietary preferences and restric-\ntions, including halal. They then use a language model, e.g.,\ndoc2vec, to learn the hierarchy relations between ingredi-\nents, products, and their labels (R Rehurek and Sojka 2010).\nIspirova et al. (Ispirova, Eftimov, and Korou\u0161i\u0107 Seljak 2020)\nuse a set of products representing various items from Slove-\nnian food consumption data. They then combine word em-\nbedding and graph learning to cluster products into separate\ncategories.\nFor image processing-based strategies, several methods\nadopt convolutional neural networks (CNNs) to recognize\nhalal products and their components. For example, Ramda-\nnia (Rauda Ramdania et al. 2022) introduced a convolutional\nneural network to recognize letters or characters in the in-\ngredients. Other strategies utilize CNNs and OCR tools to\nextract text from images and recognize the ingredient let-\nters from images. CNNs can be used with OCR tools, e.g.,\nTesseract (Smith 2007), to extract text from images, which\ncan be integrated to convert image data into text. However,\nonly checking the presence of ingredients can be insuffi-\ncient to decide whether the products are halal or non-halal.\nThis is because alternatively sourced ingredients may still\nbe allowed to be part of a halal cosmetic product. For exam-\nple, cosmetic products may contain ethanol as long as it is\nsourced from natural aerobic fermentation (e.g., natural fer-\nmentation process in the presence of oxygen) or synthetic\nsources (i.e., prepared from ethylene oxide, acetaldehyde,\nacetylene) and not from the liquor industry. Moreover, by\nconsidering individual products, the existing methods fail to\nlearn the complex relations between many entities, such as\ningredients and products. That is, these methods could ig-"}, {"title": "Methodology", "content": "In this section, we first explain how the cosmetic knowl-\nedge graph can be constructed from cosmetics, ingredients,\nand their properties. Then, we present the model architec-\nture, including fusion layers and attentive propagation with\nresidual connection. Lastly, we introduce our strategy for the\npre-training phase without using any label information about\ncosmetic status, followed by the fine-tuning phase.\nshows an overview architecture of HaCKG."}, {"title": "Cosmetic Knowledge Graph Construction", "content": "We now represent our strategy to construct a cosmetic\nknowledge graph from cosmetic product records. A knowl-\nedge graph (KG) is a semantic framework that models het-\nerogeneous data by connecting entities and their relation-\nships, effectively mirroring real-world relationships (Bordes\net al. 2013; Lin et al. 2015). Formally, a KG is a set of triples\nwhere each triple is formed of $(h,r,t)$, where h, r, and t\nrefer to the head, relation, and tail, respectively (Dai et al.\n2020). That is, each triplet $(h_j, r_j, t_j)$ contains pairs of en-"}, {"title": "Fusing Attributes and Entities Features", "content": "As mentioned earlier, several ingredient properties, e.g., tox-\nicity or allergy, could contain numeric information, which\ndelivers the state of the ingredient. Therefore, we first de-\nsign a fusion layer that contains a gate function to transform\ndifferent types of attributes and entities into unified repre-\nsentations as initial inputs for our model. That is, numeri-\ncal attributes, such as ingredient properties, are normalized\nand transformed directly into feature vectors (Kristiadi et al."}, {"title": "Learning Relational Attention", "content": "To account for the diverse types of relationships between\nnodes in our cosmetic knowledge graph, we propose em-\nploying a relational Graph Attention Network (r-GAT) with"}, {"title": "Model Optimization", "content": "We now introduce our pre-training strategy for HaCKG,\nwhich aims to preserve the co-coefficients across all triplets\nthrough a scoring function without using any label informa-\ntion. That is, the model will learn entity representations to\npreserve the graph structure and relations between entities.\nTo preserve the entity relations, we aim to maximize all the\npositive triplets from our Cosmetic Knowledge Graph and"}, {"title": "Experiments", "content": "In this section, we perform a series of comprehensive experi-\nments to assess the effectiveness of our proposed model and\ncompare it with existing state-of-the-art baselines. We first\nevaluate the model's performance on link prediction tasks.\nThen, we conduct ablation studies to investigate the impact\nof various relation types and the residual connections on the\nmodel's overall performance."}, {"title": "Experimental Settings", "content": "Evaluation Metrics Since our task is a binary classifica-\ntion problem, we utilized several evaluation metrics, includ-\ning accuracy (Acc), precision (P), recall (R), and $F_1$ to eval-\nuate the performance of our proposed model. The evaluation\nmetrics are defined as follows:"}, {"title": "Results on Link Prediction", "content": "Table 3 shows the performance of our proposed model and\nbaselines in terms of accuracy, recall, precision, and $F_1$. We\nhave the following observations: (1) Our proposed model\nwith pre-training outperformed baselines in all the evalua-\ntion metrics, showing the model's superiority compared to\nbaselines. For example, our proposed model reached the\nhighest value at 0.9794 regarding precision metric. This in-\ndicates that our model could learn the numerical informa-\ntion of entities well to maximize the relations between en-\ntities and capture complex entities' relations via the atten-\ntion mechanism. (2) Translation-based models, i.e., TransE\nand TransR, showed low performance in predicting halal or\nharam status. We argue that these models only capture the lo-\ncal relations independently, e.g., cosmetics and ingredients\nrelations or ingredients and their properties, which could\noverlook high-order relations between entities, resulting in\npoor performance. (3) Several recent GNN-based models,\ni.e., KGAT and LiteralKG, have shown competitive perfor-\nmance compared to our model. This indicates that learning\nrelational information between entities is an essential factor\nthat could contribute to the overall performance. The supe-\nrior performance of the model verifies that our model can\ncapture well structural relations between cosmetics and in-\ngredients and can help improve cosmetic representations."}, {"title": "Model Analysis", "content": "Our model implementation is based on the PyTorch li-\nbrary, which is available in the following open source repos-\nitory2. All experiments were conducted on two GPU servers,\neach equipped with four NVIDIA RTX A5000 GPUs (24GB\nRAM per GPU). The Adam optimizer (Kingma and Ba\n2015) was utilized during both the pre-training and fine-\ntuning phases. We used Leaky ReLU as the activation\nfunction. We employ early stopping and optimize the hy-\nperparameters using grid search. The learning rate was\nselected from the range {0.0001, 0.00005, 0.00001}. The\nhidden dimensions of the GNN layers were chosen from\n{16, 32, 64, 128}, while the number of GNN layers was var-\nied among {1,2, 3, 4, 5}. For a fair comparison with base-\nline methods, we tuned the hyper-parameters within similar\nranges, including learning rate, hidden dimensions, and the\nnumber of layers."}, {"title": "Performance According to the Number of Layers", "content": "We further analyze the impact of the number of layers in our\nproposed model on different metrics, as shown in Figure 4.\nWe observed that: (1) The model's performance improved as\nl increased, reaching its peak at l = 2 and 1 = 3. This is be-\ncause each entity aggregates information from its neighbors\nand those neighbors' neighbors (2-hop). That is, the pro-\nposed model captured sufficient local structures, enabling\nthe model to learn robust representations for each entity. (2)\nWhen the number of layers increased, e.g., 1 > 3, the model\nperformance was decreased as entities could receive redun-\ndant and overly smoothed information from distant nodes.\nWe argue that this could be the over-smoothing problem,\nwhich limits the model's ability to distinguish between dif-\nferent graph structures, reducing model accuracy."}, {"title": "Effect of Pre-training, Numerical Properties, and Resid-\nual Connection", "content": "To verify the impact of pre-training\nstrategies, the use of numerical properties, and the resid-\nual connection, we conduct an ablation study by consider-\ning four variants of our proposed model, as shown in Table\n4. Specifically, for the first variant, i.e., w/o pre-training, we\ndisable the pre-training step and directly train the model by\nusing the loss function for prediction. For the second vari-\nant, i.e., w/o numerical properties, we remove the numerical\nfeatures of ingredient properties and replace them with ran-\ndom attributes. Last, we disable the residual connection in\nour model to test the model performance. We observed that:\n(1) Removing the pre-training process and residual connec-\ntion degrades the model performance. Without pre-training,\nthe proposed model consistently underperforms the over-"}, {"title": "Conclusion and future work", "content": "In this work, we propose HaCKG, a pre-trained relational\ngraph attention network model, to learn the halal status of\ncosmetic products. We first construct a cosmetic knowledge\ngraph that represents the natural relations between prod-\nucts, ingredients, and their properties. The model is then\npre-trained to learn the structural similarity between triplets\nin the cosmetic knowledge graph, followed by a predic-\ntion task. By doing so, the model could learn the knowl-\nedge graph structures and relations between entities in the\nknowledge graph, which aligns with the nature of the knowl-\nedge graph. Our extensive experiments demonstrate that the\nproposed model consistently outperforms existing baselines.\nWhile the current pre-training strategy focuses on learning\nstructural similarities between triplets, there are several fu-\nture directions for further exploration. For example, explor-"}]}