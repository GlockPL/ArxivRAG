{"title": "A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce", "authors": ["Chunyuan Yuan", "Ming Pang", "Zheng Fang", "Xue Jiang", "Changping Peng", "Zhangang Lin"], "abstract": "Query intent classification is an essential module for customers\nto find desired products on the e-commerce application quickly.\nMost existing query intent classification methods rely on the users'\nclick behavior as a supervised signal to construct training samples.\nHowever, these methods based entirely on posterior labels may lead\nto serious category imbalance problems because of the Matthew\neffect in click samples. Compared with popular categories, it is\ndifficult for products under long-tail categories to obtain traffic and\nuser clicks, which makes the models unable to detect users' intent\nfor products under long-tail categories. This in turn aggravates the\nproblem that long-tail categories cannot obtain traffic, forming a\nvicious circle. In addition, due to the randomness of the user's click,\nthe posterior label is unstable for the query with similar semantics,\nwhich makes the model very sensitive to the input, leading to an\nunstable and incomplete recall of categories.\nIn this paper, we propose a novel Semi-supervised Multi-channel\nGraph Convolutional Network (SMGCN) to address the above prob-\nlems from the perspective of label association and semi-supervised\nlearning. SMGCN extends category information and enhances the\nposterior label by utilizing the similarity score between the query\nand categories. Furthermore, it leverages the co-occurrence and\nsemantic similarity graph of categories to strengthen the relations\namong labels and weaken the influence of posterior label instability.\nWe conduct extensive offline and online A/B experiments, and the\nexperimental results show that SMGCN significantly outperforms\nthe strong baselines, which shows its effectiveness and practicality.", "sections": [{"title": "1 INTRODUCTION", "content": "Online shopping has evolved into a fundamental aspect of our\nlives, significantly reshaping our daily routines over the past few\nyears. An increasing number of e-commerce platforms such as\nAmazon, Taobao, and JD offer customers hundreds of millions of\nvibrant and colorful products. These massive products are organized\nin the form of categories to facilitate customers to retrieve them\nquickly. To cover as many kinds of commodities as possible, the\ncategory taxonomy involves nearly ten thousand leaf categories\nin e-commerce applications. Due to the diversity of user needs\nand plenty of categories, accurately capturing the user's intention\nto purchase the category of products is a crucial part of the e-\ncommerce platform.\nQuery intent classification has gained significant attention from\nboth academia and industry. Early research uses click graphs [9] or\ncontext information [2] to solve the short and ambiguous problems\nof query faced by the general Web search. In recent years, query\nintent classification has usually been regarded as a multi-label\ntext classification problem in academia. With the wide application\nof deep learning technology, some deep learning-based models,\nsuch as XML-CNN [10], KRF [12], HiAGM [27], LSAN [19] have\nbeen proposed to learn the contextual information of documents\nto enhance the representation learning of queries. Furthermore,\nsome recently proposed query intent classification models, such\nas PHC [23], DPHA [26], and MMAN [22] also explore utilizing\nthe correlation between query intent classification and semantic\ntextual similarity or multi-task to facilitate models to learn external\ninformation beyond query information.\nMost previous methods assume an abundance of authentic la-\nbeled data is available to train a model. However, manual annotation\nis expensive and time-consuming, especially for the thousands of\nproduct categories. As a result, the industry often utilizes users'\nclick behavior as an implicit feedback signal to generate training\nsamples, but this approach has its challenges. One major issue is\nthe category imbalance in the training data, where long-tail cate-\ngories struggle to obtain user clicks and traffic, making it difficult\nfor models to identify them. This exacerbates the problem of low\ntraffic to long-tail categories, creating a vicious cycle. This problem\nbecomes more serious for newly built categories because of busi-\nness development. Figure 1 illustrates the distribution of query rank\nversus search count. According to Zipf's law, most queries show\nlong-tail phenomena, which makes these models hard to generalize\ndue to a lack of training data.\nFurthermore, the posterior label of queries with similar seman-\ntics is unstable due to the randomness of user clicks. For example,\nwhen the user searches for \"earphones\", they may click on labels\nsuch as \"Headset\" and \"Second-hand headset\". However, if another\nuser inputs a similar search query, such as \"white earphones\", the\nclicked labels may change to \"Bluetooth earphones\" or \"Gaming\nearphones\". Even though the categories of \"Headset\" and \"Second-hand headset\" also offer white earphones, they are not clicked by\ncustomers, thus not presented at the labels of the query \"white\nearphone\". This instability makes the model very sensitive to input,\nleading to an unstable and incomplete recall of categories. Since\ndownstream product retrieval relies on category outcomes, an in-\ncomplete category recall cascades into relevant products not being\nretrieved, thereby impacting the user's purchase experience and\nbusiness revenue.\nTo address the aforementioned challenges simultaneously, we\nproposed a semi-supervised multi-channel graph convolutional\nnetwork. To begin, we obtain the co-occurrence relations between\ncategories by counting the frequency of category pairs in the train-\ning samples and obtain the similarity relations between categories\nthrough the semantic relevance between categories. Despite the\nlimited number of training samples for tail categories, tail cate-\ngories are easily connected to their relevant popular categories by\nthe co-occurrence or semantic similarity relations. These relations\nfacilitate the transfer of gradients from samples with popular cate-\ngories to tail categories, resulting in more effective representation\ntraining for long-tail categories and compensating for the draw-\nbacks of posterior labels. Subsequently, we use a multi-channel\nGCN to model both relations, which enables the model to learn\nsimilar representations for the categories with higher relevance."}, {"title": "2 RELATED WORK", "content": "Conventional multi-label classification methods can be broadly\ncategorized into two main types: problem transformation and al-\ngorithm adaptation methods. Problem transformation methods are\nmulti-label techniques that transform the multi-label problem into\nmultiple single-label problems [16, 17], while algorithm adaptation\nmethods [14, 25] focus on adapting existing algorithms to tackle\nthe multi-label challenges.\nIn recent years, deep learning methods, such as RCNN [8], and\nXML-CNN [10], have been applied to capture contextual infor-\nmation of the document for multi-label text classification. Some\nseq2seq-based techniques [3, 19, 21], like MLC2Seq [13] and SGM [20]\nhave used an RNN to encode the text and an attention-based RNN\ndecoder to generate predicted labels sequentially to learn the depen-\ndency of different labels. Additionally, LSAN [19], and LEAM [18],\nhave explored label-specific attention mechanisms to capture the in-\nteractions between words and labels to learn better representations\nfor labels and measure the compatibility of word-label pairs.\nWhile these methodologies have demonstrated auspicious out-\ncomes in various benchmark assessments, their applicability within\nindustrial domains encounters distinct challenges. Industrial train-\ning datasets frequently exhibit class imbalance, and the stability\nof data labels remains precarious because of the randomness of\nuser behavior. Consequently, their efficacy may be significantly\nundermined if they were to be employed directly in the context of\nonline E-commerce applications."}, {"title": "2.2 Query Intent Classification", "content": "Early query intent classification mainly focuses on mining the\nclick graphs [9] or click-through logs [1] to improve the accuracy"}, {"title": "3 MODEL", "content": "In this section, we first formally define the query intent classifica-\ntion task. Then, we describe different modules of SMGCN in detail\nand analyze the influence of the model during the training and\npredicting process."}, {"title": "3.1 Problem Statement", "content": "Suppose the query inputted by users on the E-commerce applica-tions, has \\(q = [x_1, x_2, ..., x_{L_q}]\\) characters. Each category \\(n_i\\) has a\ncategory name and a series of product words, and \\(|C|\\) denotes the\ntotal amount of leaf categories. The products belong to one of the\nleaf categories. The query classification task requires models to\nassign a subset \\(y\\) of categories from all leaf categories to \\(q\\). Our\ntarget is to learn a classification model \\(f(\u00b7, \u00b7)\\). For any input query\n\\(q\\), the model \\(f(q, [n_1, .., n_c])\\) can select relevant categories from\nthe label set. For a clear definition, throughout the rest of this paper,\nbold lowercase letters represent vectors."}, {"title": "3.2 Overview", "content": "Figure 2 illustrates the components of the SMGCN model, which\nis mainly composed of three modules: (1) query and category rep-\nresentation learning module, (2) semi-supervised label generation\nmodule, and (3) multi-channel graph learning module. Specifically,\nthe query and category representation learning module describes\nthe mapping of query or category sequence from word embedding\ninto the same semantic space; the semi-supervised label generation\nmodule illustrates why the model needs semi-supervised labels\nand how to utilize the pseudo-label to facilitate model training; the\nmulti-channel graph learning module defines two kinds of relations\nof categories and introduces how to fuse both kinds of relations\nto learn better category embeddings. Finally, query and category\nembeddings are fed to a classifier to predict the user's intent."}, {"title": "3.3 Learning query and category representation", "content": "Query and categories are the basic input of the model. To learn\ngood semantic representations of them, we project the query and"}, {"title": "3.4 Semi-supervised label generation", "content": "Most existing methods rely on user click behavior to generate train-ing samples, but long-tail categories struggle to obtain traffic and\nuser clicks compared to popular categories. Additionally, user click\nbehavior tends to be random and unstable for queries with simi-lar semantics due to individual preferences and varying demands.\nAs a result, the posterior labels are highly imbalanced and unsta-ble, leading to inadequate performance for long-tail categories and\nincomplete category recall.\nTo compensate for the drawbacks of the posterior label, we\ncalculate the similarity score between the query and categories to\ntreat it as a semi-supervised label. Then, we fuse it with the label\nclicked by the user to calculate loss as the final label. Specifically,\n\\(s_i = stop\\_grad(\\frac{Q_i C^T}{||Q_i|| ||C||})\\),\n\\(S_{ij}^{semi} = \\begin{cases}\ns_{ij} & \\text{if } s_{ij} \\ge \\tau' \\\\\n0 & \\text{if } s_{ij} < \\tau'\\end{cases}\\),\nwhere \\(s_i \\in \\mathbb{R}^{1 \\times |C|}\\), is the relevance scores between query \\(q_i\\) and\nall categories. \\(t\\) is the threshold to filter the categories with low\nscores. \\(y^{semi}\\) is the semi-supervised label. For example, referring to\nFigure 2, although the new category \"Bone conduction headphones\"\ndid not have click records below query \"earphone\", they are seman-tically highly related and should be recalled. This connection can\nbe expressed by the \\(y^{semi}\\) and influences model training.\nBoth query and label encoders use the same text encoder, but\ntheir word distribution is different. If the gradient of the semi-supervised signal is fed to the semi-supervised label generation\nmodule, a circular dependency may arise, which could ultimately\nresult in the model collapse. To avoid this issue, we disable the\ngradient feedback of this branch and solely rely on the gradient\nof semi-supervised labels to guide the training of the query intent\nclassification module."}, {"title": "3.5 Multi-channel graph learning", "content": "Subsequently, we will introduce how the model leverages the rela-tions among categories as prior information to compensate for the\ndrawbacks of the posterior labels."}, {"title": "3.5.1 Graph construction", "content": "Firstly, we obtain the co-occurrence re-lations between categories by counting the co-occurrence times of\ncategories in the training samples. Then, we compute the condi-tional probability of two categories and obtain the adjacency matrix\n\\(A^{coo}\\).\n\\(A_{ij}^{coo} = \\frac{N(c_i, c_j)}{N(c_i)}\\),\nwhere \\(N(c_i, c_j)\\) is co-occurrence times of category \\(c_i\\) and \\(c_j\\) and\n\\(N(c_i)\\) denotes the number of occurrences of category \\(c_i\\).\nAdditionally, we obtain the semantic similarity relations between\ncategories by computing the cosine similarity of every pair of cate-gories:\n\\(a_{ij} = \\frac{C_i C_j}{\\|C_i\\| \\|C_j\\|}\\),\n\\(A_{ij}^{sim} = \\begin{cases}\na_{ij} & \\text{if } a_{ij} \\ge \\alpha \\\\\n0 & \\text{if } a_{ij} < \\alpha\\end{cases}\\),\nwhere \\(\\alpha\\) is the threshold to filter the edges with low relevance\nscores.\nThe two correlation matrices obtained from different scales can-not be merged directly, so it is necessary to normalize \\(A^{coo}\\) and\n\\(A^{sim}\\) respectively. The normalization method [7] is formalized as\nfollows:\n\\(\\hat{A} = D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}},\\),\nwhere \\(D\\) is a diagonal degree matrix with entries \\(D_{ii} = \\sum_j A_{ij}\\).\nNext, we merge the two correlation matrices after normalization:\n\\(A = [A^{coo}; A^{sim}]\\),\nwhere \\(A \\in \\mathbb{R}^{2 \\times |C| \\times |C|}\\)."}, {"title": "3.5.2 Graph learning", "content": "GCN is applied to generate nodes' represen-tation by aggregating neighborhood information. The layer-wise\npropagation rule of a multi-layer GCN is as follows:\n\\(H^{l+1} = LeakyReLU (A H^l W^l)\\),\nwhere \\(H^l \\in \\mathbb{R}^{|C| \\times d}\\) is in the \\(l\\)th layer (where \\(|C|\\) denotes the number\nof nodes, \\(d\\) is the dimensionality of node features) and \\(H^{l+1}\\) is the\nenhanced node features. \\(W^l \\in \\mathbb{R}^{d \\times d'}\\) is a transformation matrix to\nbe learned.\nDespite the limited number of training samples for tail cate-gories, tail categories are easily connected to their relevant hot\ncategories by the co-occurrence or semantic similarity relations.\nThese relations facilitate the transfer of gradients from samples\nwith hot categories to tail categories, resulting in more effective\nrepresentation training for long-tail categories and compensating\nfor the drawbacks of posterior labels."}, {"title": "3.6 Training and inference", "content": "Finally, we obtain query representation \\(q_i \\in \\mathbb{R}^{1 \\times d}\\) and the final\nrepresentations of categories \\(H \\in \\mathbb{R}^{|C| \\times d}\\). Specifically, we introduce\nthe nonlinear transformation layer which is defined as:\n\\(\\hat{y}_i = sigmoid(q_i H^T + b)\\),\nwhere \\(b \\in \\mathbb{R}^{1 \\times |C|}\\) is the bias, and \\(\\hat{y}_i \\in \\mathbb{R}^{1 \\times |C|}\\) is the predicted labels\nof query \\(q_i\\).\nTo optimize the model and use the posterior and semi-supervised\nlabels, we fuse them as follows:\n\\(y_i = y^{click} + y^{semi}\\),\n\\(Y_i = \\begin{cases}\ny_i & \\text{if } y_i \\le 1.0 \\\\\n1.0 & \\text{else}\\end{cases}\\),\nwhere \\(y^{click}\\) is the one-hot encoding of clicked labels of query \\(q_i\\),\nand the value range of \\(y_i\\) is \\(y_i \\in [0, 1]\\).\nIn this paper, we use the binary cross-entropy loss as the objec-tive to train the model :\n\\(L = - \\sum_{j=1}^N \\sum_{i=1}^C y_i log (\\hat{y}_i) + (1 - y_i) log (1 - \\hat{y}_i)\\),\nwhere \\(N\\) is number of samples, \\(L\\) is the final loss function."}, {"title": "4 EXPERIMENT", "content": "In this section, we will discuss the offline and online experiments\nin detail. We first introduce the datasets and the evaluation metrics\nused in this paper. Then, we analyze the experiment results by\nseveral fair comparisons with strong baselines. After that, we deeply\ninvestigate the effect of different modules of the SMGCN model.\nSubsequently, we present the online performance of the model on\nthe JD search engine and further analyze the influence of different\nmodules. Finally, we explore the influence of hyper-parameters."}, {"title": "4.1 Dataset", "content": "To evaluate the effectiveness and generality of the proposed model,\nwe conducted a series of experiments on two large-scale real-world\ndatasets collected from users' click logs on the JD application. The\nstatistics of the datasets are listed in Table 1. Specifically,\nCategory Data: We randomly sample queries and corre-sponding clicked products from search logs over one month.\nThe clicked products' category are treated as the query's intent. The clicked frequency of the product is treated as\nthe frequency of the category. To filter unreliable categories,\nwe normalize the frequency of the category and compute\nthe cumulative distribution function (CDF) of the category's\nprobability. When CDF > 0.95, the rest of the categories\nwith low probabilities are removed.\nIntent Data: The e-commerce platform defines a hierarchi-cal intent architecture that contains more than 1000 intents\nof users by many experts. The categories of the query are\nmapped into intent domains, which form the Intent data.\nThe training data is also mined with identical rules as the\ncategory data from user historical click logs. Different from\nit, the test dataset is annotated by the experts in each domain."}, {"title": "4.2 Baseline Models", "content": "We compare SMGCN with several strong baseline models, including\nwidely-used multi-label classification methods, such as XML-CNN,\nand LSAN, and query intent classification models, such as PHC,\nDPHA, and MMAN. The detailed introductions are listed as follows:\n(1) Multi-label text classification baselines:\nRCNN [8]: It captures contextual information with the re-current and convolutional structure for text classification.\nXML-CNN [10]: It is a CNN-based model, which combines\nthe strengths of CNN models and goes beyond the multi-label\nco-occurrence patterns.\nLEAM [18]: It is a label-embedding attentive model, which\nembeds the words and labels in the same space, and measures\nthe compatibility of word-label pairs.\nLSAN [19]: It is a label-specific attention network that uses\ndocument and label text to learn the label-specific docu-ment representation with the self- and label-attention mech-anisms.\n(2) Query intent classification baselines:\nCNN [4]: It proposes a convolutional neural network (CNN)\nto extract query vector representations as the features for\nthe query classification.\nPHC [23]: It investigates the correlation between query in-tent classification and textual similarity and proposes a multi-task framework to optimize both tasks.\nBERT [5]: We use the pre-trained BERT-base 1 delivered\nby google, and fine-tune it on the training set to predict the\nuser's intent.\nDPHA [26]: It contains a label graph-based neural network\nand soft training with correlation-based label representation."}, {"title": "4.3 Evaluation Metrics", "content": "Query intent classification is essentially a multi-label text classifi-cation task. Thus, following the settings of previous work [22, 24],\nwe report the micro and macro precision, recall, and F1-score of the\nmodels as the metrics to evaluate their performance. The definitions\nof these metrics are listed as follows:\nMicro-Precision / Recall / F1: The calculation of the micro average metric requires aggregating the contributions of all labels to compute the average micro score. The categories with more samples have an advantage over other categories.\nMacro-Precision / Recall / F1: The macro average metric computes the score independently for each label and then takes the average as the final score. Thus, each category has a similar contribution to the overall score."}, {"title": "4.4 Experiment Settings", "content": "We implement the models based on the Pytorch framework. The\ndimensionality of the embedding of BERT is 768. We use a 2-layer\nGCN to learn the category embeddings of two graphs, and the\ndimensionality of embedding is 768. We use Adam algorithm [6]\nwith a learning rate of 1e-4. The max length of the query is set to\n16. The threshold of labels is set to 0.5. The threshold t is set to 0.8\nand a is set to 0.65 according to the result of the grid search. The\nmodel training should use a warm start strategy and the threshold\nt is gradually decreased to 0.8 as the training.\nTo overcome the overfitting, we use the dropout strategy with a\ndropout rate of 0.5. The maximum training epoch is set to 20, and\nthe batch size of the training set is set to 1024. We select the best\nparameter configuration based on the performance of the validation\nset and evaluate the configuration on the test set."}, {"title": "4.5 Offline Evaluation", "content": "The experimental results are shown\nin Table 2. Overall, the experimental results indicate that SMGCN\nsignificantly outperforms all baselines on two large-scale real-world\ndatasets. Specifically, we have the following observations:\n(1) For the multi-label text classification baselines (i.e., RCNN,\nXML-CNN, LEAM, and LSAN), it is obvious that SMGCN outper-forms them by a significant margin on two large-scale datasets.\nThese methods mainly focus on learning better query and label\nrepresentations but ignore the complexity of real industrial appli-cations. Industrial training datasets frequently exhibit class imbal-ance, data distribution is often dominated by popular categories\nand the stability of data labels remains precarious because of the\nrandomness of user behavior. Consequently, their efficacy may be\nsignificantly undermined if they were to be employed directly in\nthe context of online E-commerce applications.\n(2) Compared with recently proposed query intent classifica-tion methods (i.e., CNN, PHC, DPHA, and MMAN), SMGCN also\nachieves better performance on both datasets. As the results are\nshown in the table, the recall of relevant categories obtains nearly"}, {"title": "4.5.2 Ablation study", "content": "To further figure out the relative importance\nof each module in the proposed model, we perform a series of\nablation studies over the different components of SMGCN. Three\nvariants of SMGCN are listed below:\nw/o simi. graph: Removing the graph constructed through\nthe semantic similar relations between category pairs. Only\nuse the co-occurrence graph and semi-supervised strategy\nfor query intent prediction.\nw/o coo. graph: Removing the graph constructed through\nthe co-occurrence relations between category pairs and us-ing the similarity graph with the semi-supervised strategy\nfor query intent prediction.\nw/o graph: Removing both co-occurrence and similarity\ngraphs only uses the semi-supervised strategy with BERT\nfor intent prediction.\nBERT: Removing all modules and only remaining BERT as\ntext encoder for query intent classification.\nThe experiment results are shown in Table 3. We can observe\nthat:\n(1) When removing the similarity graph, the performance consis-tently has a little drop compared with SMGCN on both datasets. A\nsimilar phenomenon can be seen when removing the co-occurrence\ngraph, indicating that the similarity or co-occurrence graph does\ncontain extra information that is neglected in the posterior data.\n(2) When we eliminate both similarity and co-occurrence graphs,\nthe performance degrades more than 5% compared with the com-plete SMGCN. The results indicate that both graphs play different\nroles in category representation learning.\n(3) After removing these three modules, we can see that the micro\nand macro F1 decay about 8% compared with the complete SMGCN.\nThis result further demonstrates that all of these components in\nSMGCN provide complementary information to each other, and\nare requisite for query intent classification."}, {"title": "4.6 Online Evaluation", "content": "To reduce the response latency of online\ndeployment, the text encoder of the SMGCN is distilled from the"}, {"title": "4.7 Parameter Sensitivity", "content": "Four major hyper-parameters may influence the performance: (1) The maximum length of query and category; (2) the threshold t and \\(\\alpha\\). We conduct some sensitivity analysis experiments to study how different choices of hyper-parameters influence the performance of the SMGCN. The results are shown in Figure 4. Due to space limitations, we only show the results on the category dataset.\nImpact of the maximum length. Figure 4 (a) and (b) illustrate the performance with different query and category lengths. The length has a significant influence on the prediction per-formance. When the tweet is too short, it cannot provide enough information for classification. Therefore, the perfor-mance improves as the growth of length. We observed that the best max length of the query is about 16 and the best max length of the category input is about 20.\nImpact of threshold. Figure 4 (c) and (d) illustrate the perfor-mance of SMGCN with different \\(\\tau\\) and \\(\\alpha\\). \\(\\tau\\) determines how many soft labels would add to loss and \\(\\alpha\\) decides how many\nsemantic similar edges of categories would be remained. As shown, a low threshold \\(\\tau\\) or a significantly influences the performance of the model because it brings too much noise. Moreover, a high threshold will filter too many useful con-nections of categories and also influence the performance of the model. We can observe that SMGCN achieves the best performance when t = 0.8 and \\(\\alpha\\) = 0.6."}, {"title": "5 CONCLUSION AND FUTURE WORK", "content": "This paper proposes a semi-supervised multi-channel graph convo-lutional network to address the challenges of category imbalance\nand incomplete recall of categories. SMGCN extends category infor-mation and enhances the posterior label by utilizing the similarity\nscore between the query and categories. Additionally, it leverages\nthe co-occurrence and semantic similarity relations among cat-egories to strengthen the relations between labels and weaken\nthe influence of posterior label instability. Offline and online A/B\nexperiments demonstrate significant improvements over the state-of-the-art methods. Moreover, the proposed approach has been\ndeployed in real-world applications and has brought great commer-\ncial value, confirming its practicality and robustness for large-scale\nquery intent classification services.\nIn future work, we aim to investigate the use of external knowl-edge, such as the taxonomic hierarchy of categories and product\ninformation, to comprehensively model category representations\nand further enhance the model's performance."}]}