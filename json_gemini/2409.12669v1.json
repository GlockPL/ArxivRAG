{"title": "ENHANCING CONSTRUCTION SITE SAFETY: A LIGHTWEIGHT CONVOLUTIONAL NETWORK FOR EFFECTIVE HELMET DETECTION", "authors": ["Mujadded Al Rabbani Alif"], "abstract": "In the realm of construction safety, the detection of personal protective equipment, such as helmets, plays a critical role in preventing workplace injuries. This paper details the development and evaluation of convolutional neural networks (CNNs) designed for the accurate classification of helmet presence on construction sites. Initially, a simple CNN model comprising one convolutional block and one fully connected layer was developed, yielding modest results. To enhance its performance, the model was progressively refined, first by extending the architecture to include an additional convolutional block and a fully connected layer. Subsequently, batch normalization and dropout techniques were integrated, aiming to mitigate overfitting and improve the model's generalization capabilities. The performance of these models is methodically analyzed, revealing a peak F1-score of 84%, precision of 82%, and recall of 86% with the most advanced configuration of the first study phase. Despite these improvements, the accuracy remained suboptimal, thus setting the stage for further architectural and operational enhancements. This work lays a foundational framework for ongoing adjustments and optimization in automated helmet detection technology, with future enhancements expected to address the limitations identified during these initial experiments.", "sections": [{"title": "1 Introduction", "content": "The construction industry is notoriously fraught with hazards, characterized by high-risk activities and environments that substantially increase the likelihood of worker exposure to dangerous situations. Recent statistical data reveals a distressing global trend of rising fatalities within this sector. Specifically, the U.S. Bureau of Labor Statistics reported that the year 2021 saw a total of 5,190 fatal work injuries, which represents an 8.9% increase from the preceding year [1]. This upward trajectory is mirrored in China, where the Ministry of Emergency Management noted a 7.8% increase in construction-related accidents and a 1.4% rise in fatalities during the first half of 2018. Contrary to the decreasing accident and fatality rates observed in most other industries, the construction sector has experienced a consistent increase in such incidents since 2016 [2]. Furthermore, the UK Health and Safety Executive (HSE) highlights a particularly alarming statistic: 79% of all fatal injuries in the construction industry from 2017/18 to 2021/22 were confined to just five types of accidents, as illustrated in Figure-1. Within the most recent year of the study (2021/22), falls from height alone were responsible for 29 fatalities, constituting 24% of all construction worker deaths for that year [3]. These figures underscore a critical need for targeted interventions to address specific high-risk activities within the construction environment. The persistent elevation in fatality rates, despite technological and regulatory advancements, calls for innovative approaches to enhance safety measures and compliance. This paper explores the potential of leveraging advanced machine learning techniques and computer vision to improve safety equipment compliance and reduce the occurrence of fatal accidents in the construction industry."}, {"title": "2 Literature Review", "content": "Machine learning-based object detection technologies have become increasingly prevalent across various domains due to their robust capabilities in detecting and classifying objects [16]. In a seminal work by Rubaiyat et al. [17], an automatic detection method was introduced that effectively identifies both construction workers and safety helmets. This method utilizes a combination of frequency domain analysis, Histogram of Oriented Gradients (HOG), and Circle Hough Transform (CHT) in a sequential approach to enhance the accuracy of detecting workers equipped with helmets. Despite the successes, these machine learning-driven approaches encounter challenges, particularly in distinguishing safety helmets from other headgear, such as hats with similar colors and shapes. Moreover, the detection accuracy falters in scenarios where the workers' faces are partially obscured, complicating the simultaneous recognition of faces and helmets.\nHistorically, research in this field has been oriented toward binary classification models that simply ascertain the presence or absence of safety helmets. Such models often overlook the presence of other forms of headwear like caps or headscarves, leading to potential misclassifications in diverse working environments [18]. Addressing these limitations, Cheng et al. [19] developed a more nuanced model that classifies headgear into four categories: helmet, cap, no-wear, and safety cap. This model, an enhanced version of YOLOv3-Tiny named SAS-YOLOv3-Tiny, integrates sandglass-residual structures and Spatial Pyramid Pooling (SPP) modules to strike a balance between detection accuracy and processing speed. Trained on a dataset comprising 7,656 images, their model demonstrated commendable performance metrics, achieving precision, recall, mean Average Precision (mAP), and F1-score of 71.6%, 80.9%, 80.3%, and 75.2% respectively.\nBuilding upon the development of object detection models, a recent study by Z. Xiang et al. [20] evaluated the effectiveness of various configurations of the YOLOv5 model for safety helmet detection. Modifications to the YOLOv5 models included adjustments to the size of the BottleneckCSP module, which is integral to the model's architecture. Among the variants, YOLOv5s demonstrated superior processing speed, achieving 110 frames per second despite similar mean Average Precision (mAP) values among the models. The addition of pre-training weights further enhanced the YOLOv5 models, improving mAP values by approximately 0.9 to 1.3 points. Another advancement in the YOLOv5 architecture was made by J. Doe et al. [21], who incorporated a multi-scale detection approach and the DIOU-NMS technique to refine the accuracy of bounding box predictions, especially for smaller targets. This modified YOLOv5 model recorded an impressive mAP of 95.7% while maintaining a processing speed of 98 FPS.\nThe use of pre-trained convolutional neural networks (CNNs) such as VGG [22], Inception_V3 [23], and ResNet50 [24] has been prevalent in general image classification tasks, owing to their robust performance metrics established through training on large datasets like ImageNet [25]. Inspired by these successes, K. Zdenek et al. [26] adapted the VGG-16 model for a specialized task of guardrail detection. By retraining VGG-16 on a dataset of 4,000 augmented images, they effectively transferred learned image feature knowledge to a new domain. The features extracted were subsequently processed using an MLP model, culminating in a detection accuracy of 96.5%, which notably exceeded the performance of a traditional support vector machine (SVM) approach.\nMoreover, addressing the challenges posed by low-resolution objects in diverse scenarios, another pivotal study [27] utilized the Faster R-CNN framework [28], employing the VGG-16 architecture as the backbone for its classifica-tion network. This approach proved highly effective for monitoring hard hat usage in far-field surveillance videos, demonstrating consistently high precision and recall rates above 90% across varying weather conditions and worker poses.\nIn summary, convolutional neural networks (CNNs) have become the predominant technology for helmet detection in image classification tasks, outperforming traditional detection methods. Research has extensively demonstrated the efficacy of CNN architectures such as VGG-16 and Faster R-CNN in identifying safety helmets within complex construction environments. These networks excel due to their robust ability to process low-resolution images and adapt effectively to diverse conditions, making them ideally suited for the challenging scenarios often encountered in safety compliance monitoring. Furthermore, these methodologies have consistently delivered high precision and recall rates, maintaining robust performance amidst varying environmental factors and worker movements. Consequently, the application of CNNs in helmet detection not only enhances the reliability and accuracy of results but also underscores their superiority in managing complex and variable visual data, thereby affirming their vital role in advancing object detection and classification technologies in safety-critical applications."}, {"title": "3 Methodology", "content": null}, {"title": "3.1 Dataset", "content": "A comprehensive dataset forms the foundation of our research on automated helmet detection. To ensure a robust and representative sample, we compiled images from two distinct sources: the publicly accessible \"Safety Helmet Detection\" dataset available on Kaggle [29] and direct image acquisitions from various operational construction sites. This dual-source approach allows for a diverse collection of images that encompasses both staged digital representations and dynamic real-life scenarios.\nThe ethical integrity of our research was maintained by adhering strictly to relevant data collection protocols and privacy regulations. Explicit consent was obtained from all individuals involved, including workers and, where applicable, their legal guardians. This consent process ensures the protection of participants' privacy and compliance with ethical standards.\nThe dataset consists of 500 high-quality images carefully selected to represent diverse conditions typical of construction sites. These images are categorized into two primary classes based on the presence or absence of safety helmets. The distribution of these classes is balanced to prevent any model bias during the training process."}, {"title": "3.2 Dataset Visualization and Partitioning", "content": "Figure 2 provides a visual representation of the dataset, showcasing examples of workers both with and without helmets. This visual comparison is integral for discerning the unique features that differentiate the two classes. Key attributes such as the presence, shape, color, and position of the helmet were meticulously analyzed to aid the development of an effective image classification model."}, {"title": "3.3 Data Augmentation", "content": "To mitigate the risks posed by overfitting and to enhance the model's generalization capabilities, several data augmen-tation techniques were applied to the original dataset. Each technique was specifically chosen to introduce realistic variability into the training process that mirrors actual conditions on construction sites."}, {"title": "3.3.1 Crop Augmentation", "content": "Crop augmentation was implemented to vary image composition and emphasize critical regions within the frame. Figure 3 showcases the application of a 35% crop, which focuses on different positions and scales of the helmets. Such augmentation aids the model in recognizing helmets across varied perspectives and distances."}, {"title": "3.3.2 Rotation Augmentation", "content": "To address the challenges of skewed helmet positions due to worker movement or varied camera angles, rotation augmentation was utilized. Figures 4 and 5 depict rotations of 30\u00b0 and 20\u00b0, respectively. This method trains the model to identify helmets in tilted or skewed states, enhancing its robustness."}, {"title": "3.3.3 Brightness Augmentation", "content": "To ensure that the model performs well under various lighting conditions, brightness augmentation was employed. Figures 6 and 7 illustrate adjustments of 35% and 28% in brightness levels, respectively. This adjustment enables the model to maintain accuracy even under significant lighting variations.\nPost augmentation, the dataset expanded to a total of 2886 images. The augmented data was then divided into training, testing, and validation subsets, maintaining the original distribution ratio to ensure a consistent and fair evaluation process."}, {"title": "3.4 Proposed Architecture", "content": "Initially, our architecture comprised a single convolutional block and one fully connected layer, with the convolutional block outputting 11 channels and the fully connected layer having 40 neurons. This initial design did not perform satisfactorily on both the original and augmented datasets, prompting further iterations to refine the model."}, {"title": "3.4.1 Final Model Architecture", "content": "The final architecture that we propose is a lightweight model composed of three convolutional blocks followed by three fully connected layers optimized for efficient helmet detection. The layers are arranged as follows: - The first convolutional block filters the input image into 11 output channels, - The second block increases the complexity with 22 output channels, - The third block doubles the capacity to 44 output channels.\nEach convolutional layer includes a 3x3 convolution, optional batch normalization, ReLU activation, and max-pooling. Dropout regularization is strategically placed after the second and third blocks to prevent overfitting. The fully connected layers progressively decrease in size, featuring 200, 100, and 50 neurons, with the final layer culminating in a 2-neuron output for binary classification as can be seen in figure 8."}, {"title": "4 Experimental Results", "content": null}, {"title": "4.1 Hyperparameter Tuning", "content": "In our initial experiment, we meticulously tuned the hyperparameters to enhance the model's training dynamics and performance. The settings selected are summarized in Table 5."}, {"title": "4.2 Initial Architecture Performance with Original Dataset", "content": "The initial model architecture was assessed using the original, un-augmented dataset. This dataset, comprising 500 images split evenly across the two classes, presented a substantial challenge in terms of model generalization. The performance metrics are summarized in Table 6. During the training phase, the model achieved a peak training accuracy of 100% but demonstrated a validation accuracy that fluctuated significantly, peaking at around 65% in the early epochs and then stabilizing closer to 56.6% by the 60th epoch. This variation and the notable gap between training"}, {"title": "4.3 Initial Architecture Performance with Augmented Dataset", "content": "Upon testing with the augmented dataset, the initial architecture demonstrated improved performance metrics, achieving a precision of 79%, recall of 83%, and both F1-score and accuracy of 81% as detailed in Table 7. Despite these promising results, it should be noted that the same model only achieved 65% accuracy with the original dataset, highlighting its susceptibility to overfitting\u2014an issue quantified at 19%. The validation accuracy of the model with the augmented data started at a high level and quickly stabilized, maintaining an average accuracy of approximately 81.8% throughout the training process. This steady performance contrasts with the more variable accuracy observed with the original dataset, underscoring the benefits of data augmentation in enhancing model stability and generalization."}, {"title": "4.4 Modified Architecture Performance with Augmented Dataset", "content": "The revised model structure, featuring two convolutional blocks and two fully connected layers, exhibited a slightly different performance profile. The results are summarized in Table 8, with the model achieving an F1-score and accuracy of 79% and 80%, respectively. The model's training accuracy quickly reached 100% and remained consistent throughout the training process, while the validation accuracy demonstrated a rapid increase to around 80.76% in the early epochs before stabilizing. This pattern suggests a slight increase in overfitting by 1% over the initial model, as the high training accuracy was not fully mirrored in the validation performance."}, {"title": "4.5 Batch Normalization", "content": "The implementation of batch normalization in the modified model significantly enhanced its performance. This approach resulted in notable improvements across all metrics as summarized in Table 9. The model achieved a precision of 82%, recall of 88%, F1-score of 85%, and an overall accuracy of 85%. These results underscore the model's ability to deliver accurate and reliable predictions. The training accuracy of the model swiftly reached and maintained 100%, while the validation accuracy, after an initial steep rise, stabilized at approximately 85.27% throughout the majority of the epochs. This demonstrates a more consistent model behavior compared to previous iterations, with a reduced degree of overfitting now marked at only 15%."}, {"title": "4.6 Dropouts", "content": "To further refine the model's performance, different dropout rates were tested, ranging from 10% to 50%. Table 10 compares these configurations, showing minor fluctuations in performance metrics, with dropout proving to moderately influence model behavior. The precision varied between 81% and 83%, and recall between 85% and 89%. The F1-score remained consistently around 84%, while training and validation accuracy exhibited variations correlated with the dropout rates."}, {"title": "4.7 Batch Normalization and Dropout", "content": "The integration of batch normalization alongside varying dropout rates was systematically evaluated to assess performance enhancements and overfitting characteristics. Table 11 details the results, with the best performance observed at a 10% dropout rate, which achieved a precision of 81%, a recall of 90%, and an F1-score of 85%. This configuration also recorded the lowest degree of overfitting at 15%, with the highest validation accuracy of 85%. Other dropout rates-15%, 25%, and 50%-yielded slightly lower metrics, each with a consistent overfitting degree of 16% and similar validation accuracy."}, {"title": "5 Discussion", "content": "This study methodically evaluated the performance of two CNN architectures developed to classify helmet images within construction settings. The first model tested, an elementary architecture comprising one convolutional block and one fully connected layer, exhibited modest capabilities. On the original dataset, this initial model achieved a 55% F1-score and a 65% accuracy rate, underscoring substantial issues with overfitting, evident from a high overfitting rate of 35%.\nTo rectify the observed shortcomings of the initial model, the architecture was enhanced by introducing an additional convolutional block and a second fully connected layer. This modified model was then augmented with batch normalization and varying dropout rates, aimed at boosting its effectiveness and minimizing overfitting. The performance metrics for the initial and modified models, detailed in Table 12, reveal the improvements achieved across various experimental setups, particularly when augmented data was employed."}, {"title": "6 Conclusion", "content": "This paper has methodically explored the initial development and incremental improvement of convolutional neural networks (CNNs) for helmet detection in construction environments. We began with a basic CNN model consisting of one convolutional block and one fully connected layer. Subsequent enhancements, including the addition of another convolutional block and a second fully connected layer, along with the integration of batch normalization and dropout techniques, have significantly bolstered the model's performance.\nThrough these modifications, the models showed improved capability to classify helmet images accurately. The modified architecture, incorporating advanced regularization techniques, achieved notable enhancements in precision, recall, and F1-score, effectively addressing the initial model's limitations of underfitting and excessive overfitting [31]."}, {"title": "7 Future Work", "content": "While this study has laid a solid foundation for helmet detection using CNNs, further advancements are necessary to optimize and expand the current model's capabilities:\n\u2022 Real-Time Deployment: Future work should aim at optimizing the model for real-time application, ensuring it can operate effectively in dynamic construction site along with other environments such as renewable energy [32].\n\u2022 Integration with IoT Devices: Integrating the CNN model with IoT devices could lead to the development of comprehensive safety monitoring systems, enhancing proactive safety measures on construction sites [33].\n\u2022 Expansion to Other PPE Detection: Extending the model's capabilities to detect other personal protective equipment, such as safety vests and goggles, could provide a more holistic approach to site safety.\n\u2022 Robustness to Environmental Variabilities: Enhancing the model to maintain high accuracy across diverse environmental conditions, including different lighting and weather conditions, remains a priority.\n\u2022 Data Augmentation: Enriching the training dataset with a wider variety of images, including those from different geographic locations and varied construction settings, would help improve the model's robustness and generalizability.\n\u2022 Exploration of Advanced Architectures: Investigating more sophisticated neural network architectures and further refining dropout and normalization strategies could enhance the model's efficiency and effectiveness. Explorations in lightweight CNN architectures for digital applications and child emotion recognition present exciting avenues [34].\nBy addressing these areas, future research can significantly advance the state of automated safety monitoring in construction and similar industrial sectors, paving the way for safer working conditions through enhanced technological integration."}]}