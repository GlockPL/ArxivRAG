{"title": "GReDP: A More Robust Approach for Differential Privacy Training with Gradient-Preserving Noise Reduction", "authors": ["Haodi Wang", "Tangyu Jiang", "Yu Guo", "Xiaohua Jia", "Chengjun Cai"], "abstract": "Deep learning models have been extensively adopted in various regions due to their ability to represent hierarchical features, which highly rely on the training set and proce-dures. Thus, protecting the training process and deep learning algorithms is paramount in privacy preservation. Although Differential Privacy (DP) as a powerful cryptographic primitive has achieved satisfying results in deep learning training, the existing schemes still fall short in preserving model utility, i.e., they either invoke a high noise scale or inevitably harm the original gradients. To address the above issues, in this paper, we present a more robust approach for DP training called GReDP. Specifically, we compute the model gradients in the frequency domain and adopt a new approach to reduce the noise level. Unlike the previous work, our GReDP only requires half of the noise scale compared to DPSGD [1] while keeping all the gradient information intact. We present a detailed analysis of our method both theoretically and empirically. The experimental results show that our GReDP works consistently better than the baselines on all models and training settings.", "sections": [{"title": "1. Introduction", "content": "Deep learning has been widely adopted in various appli-cations due to its ability to represent hierarchical features. The performance of the deep learning models relies highly on the training data, which usually contain sensitive infor-mation. Quantities of works have proven that an adversary can extract or infer the training data via the model parame-ters and training procedures [12], [43], [44]. Thus, protecting deep learning algorithms is paramount in preserving data privacy.\nMeanwhile, Differential Privacy (DP), as one of the fun-damental cryptographic tools, offers a robust mechanism to safeguard sensitive information while extracting meaningful insights. By injecting carefully calibrated noise into the data, DP ensures that statistical queries about a dataset remain indistinguishable whether any single data point is included or excluded. In the context of deep learning, implementing DP on models benefits by mitigating the risks of leaking information about individual data points. This approach not only enhances the security and ethical considerations of deep learning applications but also fosters greater trust and compliance with privacy regulations in an increasingly data-driven world.\nHowever, directly adopting DP to the well-trained model parameters would devastate the model utility. Due to the vulnerability of the deep learning models, a slight change in the model might cause a divergent output [16], which ne-cessitates more sophisticated approaches to privacy preser-vation. In 2016, Abadi et al. [1] proposed DPSGD, which modifies the standard training procedure by incorporating DP into the gradient computation process. Instead of adding noise directly to the model parameters, DPSGD gradually introduces noise to the gradients during training. There are quantities of subsequent work established on DPSGD to enhance its performance [22], [38], [42]. Though effective, these works still suffer from the high utility loss of the deep learning models.\nTo address the above issue, in 2023, Feng et al. pro-posed an alternative to DPSGD called Spectral-DP [11]. The authors point out that the utility loss in DPSGD and the variants derive from the direct gradient clipping and noise addition to the model. Thus, Spectral-DP designs a novel method to perform the low-bandwidth noise addition on the model gradients in the Fourier domain. Since the weight vectors have a more sparse distribution in the fre-quency domain, Spectral-DP realizes a noise reduction via a filtering operation. However, the filtering ratio inevitably results in the loss of the original gradients and unstable noise levels. Thus, the performance of Spectral-DP can be further enhanced.\nGenerally speaking, the model utility under different DP methods is determined by two primary factors: (i) how much noise is added to the model gradients, and (ii) how much original gradient is retained. The existing schemes either invoke a high noise scale or might cause information loss during the algorithm, thus leading to an unsatisfying model accuracy.\nOur objectives. The objective of this paper is to shed some light on the differential private deep learning train-ing. Our proposed algorithm should retain all the gradient information and add less noise than the current schemes, thus achieving better model utility than the baseline methods with a more comprehensive theoretical analysis.\nOur contributions. To this end, we propose a novel and more robust DP approach for the training procedure of the deep learning models called GReDP. Enlightened by Spectral-DP, we compute the model gradients in the fre-quency domain by adopting the Fast Fourier Transformation (FFT) to the model parameters and feature maps. We then adopt the Gaussian noise mechanism to the gradients. Since the model weights are more sparse after adopting FFT, it is viable for us to perform the noise reduction. Unlike the previous work that filters the noised gradients in the frequency domain, we instead process them in the time domain by deleting the imaginary parts. We theoretically prove that our GReDP requires only half of the noise level than DPSGD under the same privacy budget. Compared to Spectral-DP, our approach invokes lower and more stable noise levels without deleting any gradient information. We fully implement our GReDP and design comprehensive experiments to evaluate its performance. We adopt five universally used architectures to show the performance gain under two popular training settings. The experimental results demonstrate that GReDP achieves consistently better model utility than the existing baselines under the same privacy requirements. In all, the concrete contributions of this paper are as follows."}, {"title": "2. Preliminaries", "content": "We first present the essential definitions that are closely related to this paper. We denote \\( \\mathbb{N} \\) the field of natural number. We use bold letters to denote vectors and matrices, respectively. For instance, A is a vector with entry \\( a_i \\). We adopt \\([1, N]\\) to represent \\( \\{1,2,\\ldots, N\\} \\).\nDP provides mathematical privacy guarantees for spe-cific algorithms by computing statistics about the inputs or algorithms. The goal of the original DP is to protect the membership information of each individual's data. Specifi-cally, by observing the output, an adversary cannot distin-guish whether a particular data is included in the dataset or not. As a critical primitive for privacy preservation, DP provides an essential measure to quantify privacy for various tasks. Formally speaking, for two collections of records \\( \\mathbf{x}, \\mathbf{y} \\in \\mathbb{N}^x \\) from a universe \\( \\mathcal{X} \\), the distance between \\( \\mathbf{x} \\) and \\( \\mathbf{y} \\) is defined such that"}, {"title": "2.1. Differential Privacy", "content": "Definition 1. (Distance Between Databases). The distance between two databases x and y is the \\(l_1\\) distance between these two databases \\(||x - y||_1\\), where the \\(l_1\\) norm is defined as\n\\[\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^N |x_i|\\]\nNote that \\( \\|x - y\\|_1 \\) evaluates the amount of records that differ between x and y. Based on this definition, DP is defined as below.\nDefinition 2. (Differential Privacy) A randomized algorithm \\( \\mathcal{M} \\) with domain \\( \\mathbb{N}^{|\\mathcal{X}|} \\) is said to be \\((\\epsilon, \\delta)\\)-differential private if for all \\( S \\subseteq Range(\\mathcal{M}) \\) and for all \\( x, y \\in \\mathbb{N}^{|\\mathcal{X}|} \\) such that \\( \\|x - y\\|_1 \\le 1 \\):\n\\[Pr[\\mathcal{M}(x) \\in S] \\le exp(\\epsilon) Pr[\\mathcal{M}(y) \\in S] + \\delta\\]\nwhere the probability space is over the coin flips of the mechanism \\( \\mathcal{M} \\).\nNote that if \\( \\delta = 0 \\), \\( \\mathcal{M} \\) is said to be \\( \\epsilon \\)-differential private. Generally speaking, \\( (\\epsilon, \\delta)\\)-DP ensures that for all adjacent x and y, the absolute value of the privacy loss will be bounded by \\( \\epsilon \\) with probability at least \\( 1 - \\delta \\).\nIn order to create algorithms that satisfy the definition of \\( (\\epsilon, \\delta)\\)-DP, one can exert the Gaussian mechanism to the target database. The noise level is determined by the Gaussian noise added to the database, which is controlled by a parameter \\( \\sigma \\). In particular, to approximate a deterministic function \\( f: \\mathcal{M} \\rightarrow \\mathbb{R} \\) with the \\( (\\epsilon, \\delta)\\)-DP is to add the Gaussian noise defined as\n\\[\\mathcal{M}(x) = f(x) + \\mathcal{N}(0, S^2 \\cdot \\sigma^2)\\]\nwhere \\( \\mathcal{N}(0, S^2 \\cdot \\sigma^2) \\) is the Gaussian distribution with a mean value of O and standard deviation as \\( S^2 \\cdot \\sigma^2 \\). S denotes the sensitivity of function f. Based on the analysis of [9], for any \\( \\epsilon, \\delta \\in (0, 1) \\), the Gaussian mechanism satisfies \\( (\\epsilon, \\delta)\\)-DP if the following equation holds,\n\\[\\sigma = \\frac{\\sqrt{2 \\log(1.25/\\delta)}}{\\epsilon}\\]"}, {"title": "2.2. Deep Learning and Gradient Descent", "content": "Deep learning models are extensively researched due to their ability in hierarchical learning. A typical deep learning structure consists of two main procedures, i.e., training and inference, as shown in Fig. 1. For a specific task, the model owner uses its private dataset as the input of the deep learning model. The model parameters are initialized by randomness (i.e., training from scratch) or pre-trained model parameters (i.e., transfer learning or fine-tuning). In each iteration of the training procedure, the deep learning model updates its current parameters via backpropagation, which uses gradient descent algorithms to calculate the errors between the prediction results and data labels. Then the algorithm adjusts the weights and biases of each layer. The model parameters are fixed once the training procedure is completed, which is adopted by the inference phase using the testing dataset.\nAmong all the gradient descent algorithms, the Stochas-tic Gradient Descent (SGD) algorithm is widely adopted due to its efficiency in finding the optimal parameters. Specifically, suppose the deep learning model adopts \\( L(\\theta) \\) as the loss function with parameters \\( \\theta \\). In the backpropa-gation, the loss function over a batch of training samples \\( \\{x_1,x_2, ..., x_B\\} \\) is \\( L(\\theta) = \\sum_i L(\\theta, x_i) \\), where B is the batch size. The optimizing goal is to minimize \\( L(\\theta) \\) consistently. To this end, the model calculates the partial derivative \\( \\nabla_{\\theta}L(\\theta) := \\frac{\\partial}{\\partial \\theta}L(\\theta) \\) and update the model parameters such that\n\\[\\theta_{i+1} = \\theta_{i} - \\eta \\times \\nabla_{\\theta}L(\\theta)\\]\nwhere i indicates the training iteration, \\( \\eta \\) is the learning rate."}, {"title": "2.3. Differential Privacy for Deep Learning", "content": "There are different types of DP for deep learning models based on various privacy-preserving goals. In this paper, we adopt DP to the training process of the models. Con-sequently, the training procedure as well as the trainable parameters, will not leak the information of the training datasets. In particular, we require the algorithm that opti-mizes the deep learning model to satisfy \\( (\\epsilon, \\delta)\\)-DP w.r.t. the training data. To this end, the Gaussian noise is added to the clipped gradients in each iteration. The overall privacy-preserving level is determined by the privacy accountant mechanism introduced in [28].\nSpecifically, we follow the definitions of Renyi Differ-ential Privacy (RDP) [28] as used in the previous work [1], [11], such that"}, {"title": "Definition 3. (Renyi Differential Privacy)", "content": "Suppose \\( \\mathcal{M} \\) is a randomized algorithm with domain \\( \\mathcal{D} \\), and \\( \\mathcal{R} = Range(\\mathcal{M}) \\) is the range of \\( \\mathcal{M} \\). \\( \\mathcal{M} \\) is said to be \\( (\\epsilon, \\delta)\\)-RDP if for any two adjacent sets \\( d, d' \\in \\mathcal{D} \\), the following holds\n\\[D_{\\alpha}(\\mathcal{M}(d) \\|\\| \\mathcal{M}(d')) \\le \\epsilon\\]\nwhere \\( D_{\\alpha}(\\|\\) is the Renyi divergence between two proba-bility distributions.\nThe RDP mechanism can be converted to a DP mecha-nism, which is described in the following proposition."}, {"title": "Proposition 1.", "content": "If f is an \\( (a,\\epsilon)\\)-RDP mechanism, it equiv-alently satisfies \\( (\\epsilon + \\frac{\\log{1/\\delta}}{\\alpha-1}, \\delta)\\)-DP for any \\( \\delta \\in (0,1) \\)."}, {"title": "2.4. DPSGD and Spectral-DP", "content": "Among all the previous proposed methods, DPSGD and Spectral-DP are the most relative ones to our GReDP. We recall their conceptual foundations first to better demonstrate the design and difference of our scheme.\nDPSGD [1]. DPSGD, proposed in 2016 by Abadi et al., is the first work that proposed to craft the synergy of DP into the region of gradient descent algorithms. In contrast to directly adding noise to the well-trained model parameters, the algorithm in [1] can preserve a better model utility under more relaxed security assumptions. The method of DPSGD is relatively straightforward. Specifically, in each iteration of the training, the algorithm clips the gradient and adds the Gaussian noise to the gradients, such that\n\\[\\frac{1}{B} \\sum_i g(x_i) + \\mathcal{N}(0, \\sigma^2S^2)\\]\nwhere B is the batch size and g is the weight gradients. It can be demonstrated that the noise is added to the gradients directly in each iteration in the time domain. DPSGD is proven to maintain the model utility to a certain extent efficiently.\nSpectral-DP [11]. Feng et al. propose that the loss in model accuracy is due to the direct gradient clipping and noise addition. Hench the authors design an alternative of DPSGD called Spectral-DP [11]. In particular, Spectral-DP first pads the weight matrix and the convolutional kernels to the same size and performs the Hadamard product between these two matrices in the Fourier domain. The clipping and Gaussian noise adding are applied accordingly afterward. At the core of Spectral-DP lies a filtering operation, which sets a ratio of the gradients to zeros before converting the noised gradients back to the time domain. Compared to DPSGD, Spectral-DP achieves a lower noise scale. However, it relies on the filtering ratio and would inevitably delete the original gradients. We will further analyze this in Section 3.2."}, {"title": "3. Method", "content": "In this section, we present the detailed designs of GReDP. We first describe our proposed approach in general and give detailed designs to adapt our method to the deep learning models. We then analyze the theoretical results of our GReDP, including why it is effective and how the performance of our approach in theory. We also elaborate on the advantage of GReDP over the existing baseline methods [1], [11]. Finally, we illustrate the training algorithm of our method."}, {"title": "3.1. Our Approach", "content": "3.1.1. Overview. The framework of GReDP is shown in Figure 2. There are in total four steps contained in GReDP, i.e., the Gradients Computation, Clipping and Noise Ad-dition, Inverse Transformation, and Real Part Selection. In each round of the backpropagation, the gradients of each layer go through the entire procedure with noise added.\nGradients Computation. The first step is to convert the gradient computation into the frequency domain. To this end, we adopt the Fourier transformation to the inputs and ker-nels respectively, and obtain their spectral representations. Without loss of generality, the operations in the time domain are then equivalent to an element-wise multiplication. We denote \\( G := \\{g_1,g_2,\\ldots,g_n\\} \\) the gradients computed in the frequency domain, such that\n\\[G = \\Psi(\\mathcal{F}(X), \\mathcal{F}(W))\\]\nwhere X is the input matrix, W is the kernel, and \\( \\Psi \\) denotes the concrete operation determined by the layer type. \\( \\mathcal{F} \\) is the function of Fourier transformation such that\n\\[\\mathcal{F}(Y): \\hat{y_i} = \\frac{1}{\\sqrt{N}} \\sum_{n=0}^{N-1} Y_n e^{-jin}\\]\nwhere \\( \\hat{y_i} \\) is the i-th term of \\( \\mathcal{F}(Y) \\in \\mathbb{C}^N \\), and j is referred to as the iota of the complex number. We will defer the concrete implementation of \\( \\Psi(\\cdot,\\cdot) \\) for various layers in the deep learning models in the next subsection.\nClipping and Noise Addition. The second step of GReDP is to clip the gradients and add noise due to the privacy-preserving requirement. We follow the previous set-tings [1], [11] to inject noise layer-wise with the training procedure for better model utility. More concretely, we clip the \\( l_2 \\) norm of the gradients by a clipping parameter c such that\n\\[g_i = \\frac{g_i}{\\max\\{1, \\|G\\|_2\\}} c\\]\nwhere \\( i \\in [1, N] \\) and \\( \\|\\cdot\\|_2 \\) is the \\( l_2 \\) normalization. The gradient clipping benefits our GReDP to control the noise sensitivity considering the scale of the noise to be added is proportional to the \\( l_2 \\) norm of the data sequence. Then we inject the noise into the clipped noise which can be formalized as\n\\[\\hat{g_i} = g_i + \\tau_i\\]\nwhere \\( \\tau_i \\), \\( i \\in [1, N] \\) is the noise drawn from \\( \\mathcal{N}(0, \\frac{\\sigma^2}{2}) \\) independently.\nInverse Transformation. The next step is to convert the noised gradients in the frequency domain back into the time domain. To this end, we adopt the inverse Fast Fourier Transformation (IFFT) \\( \\mathcal{F}^{-1}(\\cdot) \\) to the noised gradients G, which is the inverse procedure of \\( \\mathcal{F}(\\cdot) \\). More concretely, \\( \\mathcal{F}^{-1}(\\cdot) \\) calculates the input sequence in the frequency do-main such that\n\\[\\mathcal{F}^{-1}(\\hat{Y}) : Y_n = \\frac{1}{\\sqrt{N}} \\sum_{i=0}^{N-1} \\hat{y_i} e^{jin}\\]\nWe denote \\( \\bar{G} \\) as the output of this step.\nReal Part Selection. Finally, we proceed with the converted gradients in the time domain by deleting the imaginary part of the values and only retaining the real part. This procedure is the key operation of GReDP, and also is the primary difference between our method and previous works. Specif-ically, since we add the noise in the frequency domain, the original real values (i.e., the weights and inputs in the time domain) might become complex numbers with imaginary parts. Thus, the results of IFFT also contain imaginary parts."}, {"title": "3.1.2. GReDP in Deep Learning", "content": "Having the conceptual procedure of GReDP, we can construct concrete ways to adapt our approach in the deep learning models. The key question is how to compute the model gradients in the frequency domain. To answer this, we construct the methods of GReDP for the convolutional layers and fully-connected layers, respectively.\nConvolutional Layers. The convolutional operations are the most fundamental computations in deep learning. To adopt GReDP to the convolutions, we first construct the method for the two-dimensional convolutions. More concretely, sup-pose the input of the convolutional layer is \\( X \\in \\mathbb{R}^{h \\times w \\times C_{in}} \\), and the kernel matrix is denoted as \\( W \\in \\mathbb{R}^{C_{in} \\times C_{out} \\times d \\times d} \\) where h, w are the input size, d is the kernel size, and \\( C_{in} \\) (resp. \\( C_{out} \\)) is the input (resp. output) channel of the current layer. Then the computation of the 2D convolution is\n\\[o_i = \\sum_j X_j \\circledast W_{ij}\\]\nwhere \\( o_i \\in \\mathbb{R}^{h_{out} \\times w_{out}} \\) is the feature map generated in the i-th channel of the convolution, \\( X_j \\) denotes the j-th channel of the input, \\( W_{ij} \\) is the (i,j)-th kernel, and \\( \\circledast \\) is the convolutional operation. The backpropagation of the 2D convolution in the time domain is equivalent to the Hadarmard multiplication between the input matrix X and convolutional kernels W, such that\n\\[\\frac{\\partial \\mathcal{L}}{\\partial W_{ij}} = \\frac{\\partial \\mathcal{L}}{\\partial o_i} \\frac{\\partial o_i}{\\partial W_{i,j}} = \\mathcal{F}^{-1}(\\mathcal{F}(\\frac{\\partial \\mathcal{L}}{\\partial o_i}) \\odot \\mathcal{F}(X))\\]\nwhere \\( \\circledast \\) is the convolutional operation in the time domain and \\( \\odot \\) denotes the element-wise multiplication. \\( \\frac{\\partial \\mathcal{L}}{\\partial W_{ij}} \\) is the gradient of the loss function over the model weights, \\( \\frac{\\partial \\mathcal{L}}{\\partial o_i} \\) is the gradient of the loss function over the feature map, and \\( \\frac{\\partial o_i}{\\partial W_{ij}} \\) is the gradient of the feature map w.r.t. the kernel weight matrix. Thus, GReDP can be adapted to the 2D-convolutions such that\n\\[\\mathcal{F}Re(G_{conv}) = \\mathcal{F}Re(\\mathcal{F}(\\frac{\\partial \\mathcal{L}}{\\partial o_i}) \\odot \\mathcal{F}(X))\\]\nFully-Connected Layers. Compared to the convolutional layers, applying GReDP to the fully-connected layers in the deep learning model is less straightforward. The primary reason is that there is no direct Fourier transformation for the fully-connected operations. To alleviate this issue, we adopt the technique of circular weight matrix [7], [11], [23] and convert the weights in the fully connected layers to a circular shifted matrix. We briefly present the details for comprehensiveness.\nSpecifically, for a block-circulant matrix \\( W \\in \\mathbb{R}^{m \\times n} \\), which consist of circulant square sub-matrices \\( W_{ij} \\in \\mathbb{R}^{d \\times d} \\), the forward propagation is given as follows."}, {"title": "where", "content": "\\[\\begin{aligned} O = WX &= \\begin{bmatrix} \\sum_{j=1}^{2} W_{1,j}X \\\\ \\sum_{j=1}^{2} W_{2,j}X \\\\ \\ldots \\\\ \\sum_{j=1}^{2} W_{p,j}X \\end{bmatrix} \\end{aligned}\\]\n\\( p = m \\div d \\), \\( q = n \\div d \\) and each subsequent row of \\( W_{i,j} \\) is a one-position circular shift of the previous one, such that\n\\[\\begin{aligned} W_{i,j} = \\begin{bmatrix} w_{0} & w_{1} & \\ldots & w_{d-1} \\\\ w_{d-1} & w_{0} & \\ldots & w_{d-2} \\\\ \\ldots \\\\ w_{1} & w_{2} & \\ldots & w_{0} \\end{bmatrix} \\end{aligned}\\]\nAccording to the circulant convolution theorem [4], [30], \\( W_{i,j}X \\) can be further equivalently represented as \\( \\mathcal{F}^{-1}(\\mathcal{F}(w_{i,j}) \\odot \\mathcal{F}(X)) \\), where \\( w_{i,j} \\) is the first row vector of \\( W_{i,j} \\). Then using the chain rule, the backpropagation of the fully connected layers can be derived such that\n\\[\\begin{aligned} \\frac{\\partial \\mathcal{L}}{\\partial w_{ij}} = \\sum_{l=1}^{N} \\frac{\\partial o_i}{\\partial w_{i,j}} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial o_i} \\\\ = \\mathcal{F}^{-1}(\\mathcal{F}(\\frac{\\partial \\mathcal{L}}{\\partial o_i}) \\odot \\mathcal{F}(\\frac{\\partial o_i}{\\partial w_{i,j}})) \\end{aligned}\\]\nwhere \\( \\frac{\\partial o_i}{\\partial w_{ij}} \\) is block-circulant matrix. Thus, the GReDP can be adopted to the fully connected layers with a block-circulant matrix such that\n\\[\\mathcal{F}Re(G_{fc}) = \\mathcal{F}Re(\\mathcal{F}(\\frac{\\partial \\mathcal{L}}{\\partial o_i}) \\odot \\mathcal{F}(\\frac{\\partial o_i}{\\partial w_{i,j}}))\\]"}, {"title": "3.2. Theoretical Analysis", "content": "In this subsection", "11": "since they all utilize the FFT technique to the model gradients and complete the Gaussian mechanism in the frequency domain. The primary differences between GReDP and Spectral-DP consist two points: 1) we first perform IFFT to the noised gradients and then \"filter\" the gradients in the time domain", "satisfies": "n\\[\\mathcal{F"}, "Re(\\mathcal{F}(V)) = \\mathcal{R}(\\mathcal{F}^{-1}(\\mathcal{F}(V) + \\mathcal{T})) \\sim V + \\mathcal{N}(0, \\frac{1}{2} S^2 \\sigma^2)\\"], "satisfies": "mathcal{T}_x \\sim \\mathcal{N}(0, a^2 \\frac{S^2\\sigma^2}{2}) \\) and \\( \\mathcal{T}_y \\sim \\mathcal{N}(0, b^2 \\frac{S^2\\sigma^2}{2}) \\), where \\( \\sqrt{a^2 + b^2} = 1 \\). Then the results in Theorem 1 still hold.\nProof. Let the vector as \\( V = (V_1,\\ldots, V_N) \\), and \\( \\mathcal{T} = \\mathcal{F}(V) \\), such that \\( \\mathcal{T}_i = \\frac{1}{\\sqrt{N}} \\sum_{k=1}^{N} V_k \\exp(-jki\\frac{2\\pi}{N}) \\). Then the noise addition as described in Section 3.1 is \\( \\mathcal{T} = \\mathcal{T} + \\tau \\). Thus, performing the IFFT on the noised vector in the frequency domain can be represented as\n\\[\\mathcal{F}^{-1}(\\mathcal{T}) = \\mathcal{F}^{-1}(\\mathcal{T}) + \\mathcal{F}^{-1}(\\tau) = V + \\mathcal{F}^{-1}(\\tau)\\]\nwhere\n\\[[\\mathcal{F}^{-1}(\\tau)]_i = \\frac{1}{\\sqrt{N}} \\sum_{k=1}^{N} \\mathcal{T}_k \\exp(jki\\frac{2\\pi}{N})\\]\nThen we have\n\\[\\begin{aligned} &\\mathcal{R}([\\mathcal{F}^{-1}(\\mathcal{T})]_i) \\\\ &= \\frac{1}{\\sqrt{N}} \\mathcal{R}( \\sum_{k=1}^{N} \\mathcal{T}_k (cos(k\\frac{2\\pi}{N}j) + i sin(k\\frac{2\\pi}{N}j)) \\\\ &= \\frac{1}{\\sqrt{N}} ( \\sum_{k=1}^{N} \\mathcal{T}_x cos(k\\frac{2\\pi}{N}j) + \\mathcal{T}_y sin(k\\frac{2\\pi}{N}j) ) \\\\ &\\sim \\mathcal{N}(0, \\frac{S^2\\sigma^2}{N} (a^2 \\sum_{k=1}^{N} cos^2(\\frac{2\\pi}{N}kj) + b^2 \\sum_{k=1}^{N} sin^2(\\frac{2\\pi}{N}kj))) \\\\ &= \\mathcal{N}(0, \\frac{S^2\\sigma^2}{2} (a^2 + b^2)) \\\\"}