{"title": "Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images", "authors": ["Arianna Bunnell", "Thomas Wolfgruber", "Brandon Quon", "Kailee Hung", "Brenda Hernandez", "Peter Sadowski", "John A Shepherd"], "abstract": "Mammographic breast density, as defined by the American College of Radiology's Breast Imaging Reporting & Data System (BI-RADS), is one of the strongest risk factors for breast cancer, but is derived from mammographic images, limiting the utility of risk evaluation to women participating in screening mammography. Breast ultrasound (BUS) is an alternative breast cancer screening modality, particularly useful for early detection in low-resource, rural contexts with no access to mammography. To date, BUS has not been used to inform risk models that need breast density. We asked if BUS can accurately quantify breast density calibrated to mammography density for use directly in risk models. The purpose of this study was to explore an artificial intelligence (AI) model to predict BI-RADS mammographic breast density category from clinical, handheld BUS imaging.\nAll data are sourced from the Hawai\u02bbi and Pacific Islands Mammography Registry, which collects breast health information and imaging from all women undergoing screening or diagnostic breast imaging (2009-onwards) at three clinical partner sites. We compared deep learning methods for predicting mammographic breast density directly from BUS imaging, as well as machine learning models trained to make predictions from image statistics alone. The use of AI-derived BUS breast density as a risk factor for breast cancer was then compared to clinical BI-RADS breast density while adjusting for age. The BUS data were split by individual into 70/20/10% groups for training, validation for hyperparameter tuning, and held-out testing for reporting results.\n405,120 clinical BUS images from 14,066 women were selected for inclusion in this study, resulting in 9,846 women for training (302,574 images), 2,813 for validation (11,223 images), and 1,406 testing (4,042 images). On the held-out testing set, the strongest Al model achieves AUROC 0.854 predicting BI-RADS mammographic breast density from BUS imaging and outperforms all shallow machine learning methods based on image statistics. In cancer risk prediction, age-adjusted AI BUS breast density predicted 5-year breast cancer risk with 0.633 AUROC, as compared to 0.637 AUROC from age-adjusted clinical breast density.\nBI-RADS mammographic breast density can be estimated from BUS imaging with high accuracy using a deep learning model. The AI model provided superior estimates to other machine learning approaches. Furthermore, we demonstrate that AI-derived BUS breast density is predictive of 5-year breast cancer risk in our population.", "sections": [{"title": "INTRODUCTION", "content": "Other than age, mammographic breast density is one of the strongest risk factors for breast cancer.\nBreast density has been extensively studied over the past 30 years and is included in many breast cancer risk models (3-5). A recent meta-analysis showed that having extremely dense breasts increased lifetime breast cancer risk by 2.11 times over women with scattered dense breast tissue (BI-RADS density B), even when adjusted for BMI and age (6). Furthermore, high breast density lowers the sensitivity of mammography leading to a federal mandate to report breast density to all women undergoing screening mammography (7). Thus, many women have direct knowledge of the breast density and can apply it to readily available risk models. Women at high risk of developing breast cancer have multiple options for lowering their risk including lifestyle choices (8), and chemoprevention (9-11). However, there are many parts of the world that are either too resource-limited or too remote to have access to screening mammography programs. Without mammography, clinical breast density has not been available for comprehensive breast cancer risk assessment.\nBreast ultrasound (BUS) is a sensitive method for detecting breast cancer and is broadly used around the world as primary screening in lower resource settings (12-14), secondary screening for women with dense breast tissue (15-17), and follow-up adjuvant imaging (18, 19). However, mammography is preferred, when available, due to is lower false-positive rate (20). Ideally, breast density would be available from accessible breast imaging technologies, like BUS, with a calibration equivalent to mammographic density."}, {"title": null, "content": "Image contrast in B-mode BUS is based on the boundaries where density changes. \nThese boundary features have been investigated in the past to derive density-like measures. Jud et al. (21) used linear regression of variable defined by the grey-level values normalized into 16 bins. Their model was able to estimate percent mammographic density with an accuracy of R2 = 0.67 but suffered from calibration issues in external datasets (22).\nIn the past decade, there has been a revolution in machine learning and convolutional neural deep learning networks with substantial literature on predicting mammographic breast density from mammograms using artificial intelligence (AI) (23-25) and deriving breast cancer risk from mammograms directly (26-29). The purpose of this study is to explore the use of AI to estimate breast density from BUS images. We further explore"}, {"title": null, "content": "the use of our AI-derived BUS breast density in place of mammographic density in a simple risk model."}, {"title": "METHODS", "content": "Using BUS images without cancer temporally linked to a mammogram visit and to future cancer outcomes, we constructed a deep learning model to predict BI-RADS mammographic density. We compared our deep learning model to a previously-derived machine learning method using grey-level image histograms. We then compare the predictive ability of clinical, AI-derived and image grey-level histogram-based BUS estimates of breast density in estimating 5-year breast cancer risk."}, {"title": "Study sample", "content": "All women included in this study participated in either screening or diagnostic BUS imaging in the Hawai\u02bbi and Pacific Islands Mammography Registry (HIPIMR; see Supplement). Women were selected for inclusion if they met all the following criteria: (a) had at least one negative screening 2D mammography visit; (b) had a negative, benign, or probably benign BUS visit within one year of their mammograms; (c) had a clinical BI-RADS breast density; (d) had the standard four views captured at their screening mammogram; and (e) had no history of breast cancer prior to screening mammogram (See Supplement for complete inclusion/exclusion criteria). From these, cases were defined as women diagnosed with invasive breast cancer at least 6 months and no more than 5 years from their extracted BUS exam. Controls were selected from women who did not develop cancer. \nImaging data preparation\nClinical BUS data are highly noisy data, with many artifacts such as Color Doppler blood flow highlighting, sonographer text annotations, and lesion caliper markers which can interfere with AI"}, {"title": null, "content": "model learning. We implement a cleaning pipeline developed in-house called BUSClean (30) to remove these artifacts and standardize BUS images converted from DICOM to PNG."}, {"title": "Data splitting", "content": "The development dataset was split by woman, stratified by clinical BI-RADS breast density category, with 80% assigned to the training data set and 20% assigned to the validation split for hyperparameter tuning and early stopping determination. The case-control matched testing set was reserved for performance evaluation. Each woman and her images are only present in a single data split. We duplicated the validation dataset to create curated and uncurated validation sets. In brief, the curated validation set has extensive preprocessing applied to remove clinical artifacts, while the uncurated validation set had only invalid scans removed and scans with multiple views split."}, {"title": "Deep learning model", "content": "Three deep learning models were trained in PyTorch (31) using three distinct ImageNet-pretrained architectures: DenseNet121 (32), ViT-B/32 (33), and ResNet50 (34), selected to represent a diverse range of deep learning architecture designs. Hyperparameters for each were optimized over 25 trials using the TPESampler in Optuna (35). \nThe best-performing model and hyperparameters on the curated validation set was selected as the final architecture and retrained (see Supplement for training configuration). The final deep learning architecture was selected based on performance on the curated validation set."}, {"title": "Image histogram models", "content": "Prior work in estimating percentage mammographic breast density from B-mode BUS imaging from Jud et al. makes use of gray-level image histograms with equally-sized intervals in a linear regression model (21). We implement a version of their method adapted for the categorical BI-RADS breast density measure (see Supplement). Logistic regression, random forest, and multi-layer perceptron (MLP) models were constructed using the gray-level image histogram intervals as features to predict BI-RADS categorical breast density."}, {"title": "Statistical analysis", "content": "Statistical analysis was undertaken in two steps. The first step demonstrates Al model accuracy in predicting breast density category from BUS. The second step demonstrates utility of predicted BUS BI-RADS breast density category in breast cancer risk modelling.  To assess Al model performance in predicting breast density from BUS, all models are evaluated by their micro-averaged AUROC over all density categories with 95% confidence intervals estimated using DeLong's method (1, 2) on the testing set. We use micro-averaged AUROC for increased stability under class imbalance. We present AUROC on the overall testing set as well by BUS machine manufacturer, binned patient age at BUS exam, cancer status, and BUS exam BI-RADS category. We additionally compute Kendall's t-b (36) between clinical density and predicted density from BUS to compare agreement. As a comparator, we computed mammographic density using (23) on all included women and computed Kendall's t-b between these predictions and clinical density. We use interpretation ranges from (37). \u03a4\u03bf demonstrate utility in cancer risk prediction, we constructed logistic regression models of breast cancer risk from age at BUS exam and mammographic breast density. Effect of breast density"}, {"title": null, "content": "category and standardized age was compared via computation of odds ratios with 95% Wald confidence intervals."}, {"title": "RESULTS", "content": "Study sample characteristics\nThe characteristics of all 14,066 women (15,632 identified for inclusion from the HIPIMR) included in the study (mean age at BUS exam \u00b1 standard deviation, 53 \u00b1 12 years) are described"}, {"title": "Deep learning model", "content": "Based on superior performance in the curated validation set, DenseNet121 was chosen as the final deep learning model architecture \n Performance with confidence interval estimates on the complete testing set, as well as subgroups of interest, are reported. DenseNet121 identified patients with BI-RADS breast density category A, B, C, and D from all other categories with AUROC 0.84, 0.79, 0.72, and 0.88 respectively on the unseen test set.  In comparison of performance on subgroups non-"}, {"title": "Image histogram models", "content": "Performance results for the baseline random forest and logistic regression models (see \n Logistic regression from the gray-level image histograms identified patients in the held-out testing set with BI-RADS breast density A, B, C, and D from all other categories with AUROC 0.642, 0.654, 0.621, and 0.668, respectively. The image histogram random forest model identified patients in the held-out testing set with BI-RADS breast density A, B, C, and D from all other categories with AUROC 0.698, 0.639, 0.575, and 0.727, respectively. 95% confidence"}, {"title": null, "content": "intervals for performance overlap between linear (logistic regression) and nonlinear (random forest) modelling from the gray-level image histograms in every BI-RADS breast density category."}, {"title": "Agreement to Clinical Density", "content": "Kendall's t-b between predicted BUS density and clinical density was found to be 0.47 (moderate agreement). Predicted BUS density was calculated per-patient by taking an arithmetic mean over the predicted class with the largest probability from each image and rounding to the nearest integer. Kendall's t-b between mammographic density from (23) and clinical density was found to be 0.60 (moderate agreement). Predicted mammographic density from (23) was defined as the predicted class with the largest probability."}, {"title": "Cancer Risk Modeling", "content": "The benchmark for age-adjusted AI-derived BI-RADS breast density performance was performance of age-adjusted clinical BI-RADS breast density scores, assigned by the examining radiologist at the time of each woman's matched mammogram. We additionally computed the predictive power of age alone. The age-adjusted, clinical, BI-RADS breast density category predicted cancer occurrence with 0.637 AUROC (95% confidence interval (0.594, 0.679)). The BUS AI density model BI-RADS category predicted cancer occurrence with AUROC 0.633 (0.590, 0.676). Standardized age alone predicted cancer occurrence with AUROC 0.628 (0.585, 0.671). Odds ratios (ORs) for the individual explanatory variables are presented in Supplemental Table 3. The ORs with 95% confidence intervals for the extremely dense/D (class B/scattered as reference) clinical and BUS AI density were 1.54 (1.31, 1.81) and 1.50 (1.28, 1.76), respectively.\nAdditional experiments modeling cancer risk from clinical mammographic breast density in an age-matched cohort resulted in an AUROC of 0.546 (0.478, 0.614), supporting the observed result"}, {"title": null, "content": "in the non-age-matched cohort that clinical breast density did not provide additional predictive power. Cases in the age-matched cohort were the same cases included in the previously-defined testing set. Controls were re-matched and selected from the previously-defined validation and testing set. BUS density was not computed for this group."}, {"title": "DISCUSSION", "content": "We found that BI-RADS breast density can be estimated through machine learning methods from BUS images and that our deep learning model outperformed other approaches. We also found that that the top performing BUS breast density estimate had comparable performance or at least was not inferior to clinical BI-RADS breast density for predicting 5-year breast cancer risk in an unseen test set. Furthermore, agreement to clinical density is shown to be similar to an open-source method for predicting density from the mammogram directly (23). We found that the deep learning model had similar performance in subgroups of BUS machine make and model, patient age, cancer status, diagnostic BI-RADS status. Given this robustness, breast density derived from our deep learning model should be broadly applicable to clinical situations globally, particularly in remote- and low-resource areas.\nLimited prior work has investigated the prediction of mammographic breast density from ultrasound. Tissue speed-of-sound (SoS) using a dedicated non-diagnostic probe has been proposed for measuring mammographic breast density (40). It was found that non-dense (BI-RADS classes A & B) could be predicted from dense (BI-RADS C & D) breasts with AUROC = 0.887. However, the application of a dedicated BUS device for breast density has limited clinical applications or benefit over being able to get BUS from a clinical hand-held system. Our method can identify patients with extremely dense breasts (class D) with similar performance of AUROC"}, {"title": null, "content": "0.879. When dichotomized, our method identified dense (BI-RADS C & D) from non-dense (BI-RADS A & B) women with AUROC 0.823 (0.797, 0.848). Mammographic percent density has also been measured using SoS on a SoftVue (Delphinus Medical Technologies; MI, USA) ultrasound tomosynthesis system with an accuracy of R2 =0.96 (41-43). Ultrasound tomosynthesis systems are highly specialized equipment with high installation and maintenance costs which may not be appropriate for low-resource and rural areas. Handheld BUS is most directly applicable to rural and resource-limited scenarios due to portability and low cost. Additional non-mammographic methods of measuring breast density have also been explored, including microwave breast imaging (44), dual X-ray absorptiometry (45, 46), optical spectroscopy (46), and bioimpedance (47, 48). These methods, no matter their performance, are less desirable than integrating breast density into clinical BUS since they do not provide cancer detection in addition to density assessment the way clinical BUS does. If used in breast cancer screening, these alternative methods would need to be coupled with BUS or mammography to provide both detection and risk assessment.\nAlternative BUS imaging-based biomarkers of breast cancer risk have been explored other than breast density. Breast parenchymal pattern from ultrasound measures the distribution of fat and ductal tissue in the breast. It can be classified by a breast radiologist into four categories: ductal, heterogeneous, mixed, and fibrous and has been found to be associated with breast cancer risk in the Chinese population (49, 50). Another biomarker of breast cancer risk identified from breast ultrasound imaging is glandular tissue component. Glandular tissue component is also a four-category classification which measures the degree of lobular involution observed in screening BUS (51). High glandular tissue component is associated with increased risk of breast cancer in women with extremely dense (BI-RADS D) breasts (51, 52). It may be that these measures have"}, {"title": null, "content": "complementary risk information to breast density but this has yet to be explored. We pursued breast density since it may be integrated into existing breast cancer risk models such as the BCSC, Tyer-Cuzick and others. Background echotexture, as defined by the ACR, is a three-category classification which has been found to be associated with both mammographic density and parity, known risk factors for breast cancer (53). AI combined with automated breast ultrasound (ABUS) performed with AUROC 0.979 for identifying background echotexture categories (54), however ABUS may be prohibitively costly for remote and low-resource rural areas.\nThe performance of the derived breast risk model using age alone was not significantly different from models with either clinical or BUS-derived density, limiting the insights we can draw about the added value of our measure in clinical breast cancer risk models. The typical effect has been found to be 2.1 to 2.3 times the relative risk for women with extremely dense (BI-RADS D) breasts over women with scattered density (BI-RADS B) (55, 56). The lack of observed effect of BI-RADS breast density in our study may be attributed to the imaging being from diagnostic visits. BUS is not a primary screening modality in Hawai\u02bbi, and all exams included in this study are diagnostic exams requested after an initial mammogram. The characteristics of the diagnostic BUS population are likely different that a screening mammography population, on which most breast cancer risk evaluation is based. Future validation is needed in a population screened with BUS to verify our findings and confirm clinical utility of BUS-derived breast density in traditional breast cancer risk models.\nAlthough our findings are promising, there are limitations to consider. First, there were relatively few women present in the lowest density category A (4%). This imbalance may be due to the ethnic breakdown of the population of the HIPIMR, with an estimated 60% of women in Hawai\u02bbi identifying as Asian (alone or in combination with another race) in 2023 (57). Asian women have"}, {"title": null, "content": "been found to have denser breasts than women of other races (58, 59). Future work will explore sample enrichment with category A women. Another limitation of this work is that our risk model only consisted of age and breast density. Inclusion of other breast cancer risk factors may provide a more comprehensive assessment and validation of our method.\nWe conclude that estimation of categorical, BI-RADS breast density is possible from BUS imaging with acceptable accuracy for use in breast cancer risk assessment models. In cancer risk models, the performance of our measure of breast density indicates an association to cancer risk on par with clinical density in our dataset."}, {"title": "EVIDENCE BEFORE THIS STUDY", "content": "Age-adjusted mammographic breast density is one of the strongest risk factors for breast cancer and several artificial intelligence (AI) approaches exist for automatic breast density estimation from digital mammography imaging. When using breast ultrasound for primary screening, such as in low-resource medical contexts, breast density is not available. Lack of mammographic breast density limits the breast cancer risk evaluation which can be done. Prior work has shown that breast density can be estimated from modalities other than mammography, with varying levels of success. In ultrasound, speed-of-sound using specialized hardware or methods using automated/3D ultrasound have been the most successful. These methods have limited applicability in low-resource contexts (for ABUS) or require specialized hardware (speed of sound)."}, {"title": "ADDED VALUE OF THIS STUDY", "content": "Our study proposes an Al method for estimation of BI-RADS mammographic breast density category from handheld breast ultrasound imaging and demonstrates the efficacy of breast density estimation from ultrasound in cancer risk assessment. This method could be used to provide more"}, {"title": null, "content": "complete breast cancer risk evaluation in rural and low-resource areas where mammography is not available, or in any context where women are primarily being screened with breast ultrasound."}, {"title": "IMPLICATIONS OF ALL THE AVAILABLE EVIDENCE", "content": "Breast ultrasound imaging contains information about mammographic breast density. Our study shows that BI-RADS mammographic breast density can be accurately estimated from clinical breast ultrasound data using artificial intelligence. Estimated breast density may be useful in performing breast cancer risk assessment in rural and low-resource areas, where mammography may not be available."}, {"title": "LIST OF ABBREVIATIONS", "content": "BUS = breast ultrasound\nAUROC = area under the receiver operating characteristic curve\nAI = artificial intelligence\nBI-RADS = breast imaging-reporting and data system\nABUS = automated breast ultrasound\nHIPIMR = Hawai\u02bbi and Pacific Islands Mammography Registry"}, {"title": "DECLARATIONS", "content": "Ethics approval and consent to participate. This study was approved by the WCG IRB (Study Number 1264170).\nConsent for publication. Not applicable."}]}