{"title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs", "authors": ["Ameya Prabhu", "Tawsif Ahmed", "Andreas Hochlehnert", "Huu Nguyen", "Ludwig Schmidt", "Robert Kaczmarczyk", "S\u00f6ren Auer", "Jenia Jitsev", "Nick Akinci Heidrich", "Matthias Bethge"], "abstract": "Paywalls, licenses and copyright rules often restrict the broad dissemination and reuse of scientific knowledge. We take the position that it is both legally and technically feasible to extract the scientific knowledge in scholarly texts. Current methods, like text embeddings, fail to reliably preserve factual content, and simple paraphrasing may not be legally sound. We urge the community to adopt a new idea: convert scholarly documents into Knowledge Units using LLMs. These units use structured data capturing entities, attributes and relationships without stylistic content. We provide evidence that Knowledge Units (1) form a legally defensible framework for sharing knowledge from copyrighted research texts, based on legal analyses of German copyright law and U.S. Fair Use doctrine, and (2) preserve most (~95%) factual knowledge from original text, measured by MCQ performance on facts from the original copyrighted text across four research domains. Freeing scientific knowledge from copyright promises transformative benefits for scientific research and education by allowing language models to reuse important facts from copyrighted text. To support this, we share open-source tools for converting research documents into Knowledge Units. Overall, our work posits the feasibility of democratizing access to scientific knowledge while respecting copyright.", "sections": [{"title": "1. Introduction", "content": "Scientific publishing has grown tremendously in recent decades (White, 2019), but many researchers still lack access to crucial papers (Suber, 2012). This access gap exists even in the wealthiest academic libraries in the world and is much worse for Researchers in developing countries, small independent labs or for independent scholars and educators. In 2008, Harvard had 98,900 subscriptions, Yale 73,900 and the best-funded research library in India only 10,600 (Suber, 2012). This disparity, coupled with the unsustainable surge in academic journal subscription costs, has been a pivotal driving force behind the Open Access (OA) movement. Although OA has become more common, this scholarly communication crisis still remains an issue today. In July 2018 up to 200 German institutions lost access to journals of Elsevier (Else, 2018) for five years after unsuccessful negotiations. While the negotiations since succeeded this temporary cut from new publications had a measurable effect on publishing behavior (Fraser et al., 2023). Furthermore, in 2019 major US universities canceled their subscriptions to certain journals stating unreasonable price surges as the reason (Gaind, 2019). This barrier slows scientific progress and as such \"copyright laws work counter to prevailing scientific norms\" (Stodden, 2009).\nWhy this position paper? Recent advances in language models (LLMs), like GPT-4 (OpenAI, 2023), Llama (Touvron et al., 2023), and recently Deepseek R1 (Guo et al., 2025) allow us to democratize access to scholarly knowledge, such as answering questions based on existing scientific research. The core issue lies in scholarly texts containing both information and artistic elements such as wording, style, and unique phrasing - of which the latter is protected by copyright. With LLMs, for the first time, we can extract knowledge at scale and free scientific content while respecting authors' rights to copyright.\nContribution. In this paper, we take the position that separating the factual information in scholarly works from the copyrighted creative expression is technically and legally feasible. We advocate for a Project Alexandria, to realize this vision by creating Knowledge Units using LLMs, which systematically separate reusable information from the artistic expressions inherent in scholarly writings. Knowledge"}, {"title": "2. Knowledge Units", "content": "To extract knowledge from a document, its text is segmented into manageable sections or paragraphs. Each paragraph is subsequently processed by an LM to identify entities, along with their attributes and relationships, resulting in a structured output referred to as a Knowledge Unit (Table 1).\nKnowledge Unit (KU): A set of entities, attributes, and relationships, capturing a short original text excerpt.\nEach Knowledge Unit captures:\nEntities: the core concepts or objects in the paragraph, with relevant attributes.\nRelationships: statements that connect or link entities, such as causal or definitional relationships.\nAttributes: statements that describe entities according to the excerpt.\nContext summary: A few sentences summarizing the previous knowledge units.\nSentence MinHash: A list of MinHashes of the source sentences used to generate this KU.\nMotivation for Paragraph-Level Granularity Using paragraph-sized segments avoids two extremes. If segments are too short (such as single sentences), the knowledge becomes scattered. If segments are too long (such as entire papers), the language model's question-answering performance deteriorates, as it struggles to effectively extract all relevant facts from such large chunks of text in a single step. Paragraph-level chunks represent an optimal granularity that allows the language model to focus effectively on extracting and processing all the facts contained within the text segment.\nComparison to Knowledge Graphs Knowledge Units share similarities with knowledge graphs (Hogan et al., 2021); however, they are generated locally, on a per-paragraph basis, rather than globally. Unlike conventional knowledge graph tools such as REBEL (Huguet Cabot & Navigli, 2021), which decompose text into concise triples (subject, relation, object), Knowledge Units maintain the contextual richness and nuances of the original paragraph, ensuring that relationships and entities remain closely aligned with the source text. However, KUs lack more logic-based knowledge representation such as OWL-based knowledge graphs, and entities in KUs are not equipped with worldwide unique identifiers (URI/IRIs). While these are significant disadvantages for general-purpose knowledge representation, it is not required for our prime use case of knowledge and context provision for downstream AI applications.\nConstructing Knowledge Units with LLMS We create each Knowledge Unit using large language models guided by a few-shot prompt. We split each scholarly text into paragraphs that have roughly 200 to 500 tokens. The language model then extracts a structured set of entities, relationships, and attributes from each paragraph. We instruct the model to avoid copying the original wording. Instead, it stores key facts in a simple data structure, omitting stylistic language. If we process a longer document, we include the previous 10 KUs in the prompt so that the model remains consistent in naming entities across paragraphs."}, {"title": "3. Legal Considerations for Fair Knowledge Extraction", "content": "We start our legal considerations under the broader legal framework of the Universal Declaration of Human Rights (UDHR), Article 27(a) which states \"[e]veryone has the right freely to participate in the cultural life of the community, to enjoy the arts and to share in scientific advancement and its benefits.\u201d However, it also specifies the need to support and respect the rights of authors in their \"moral and material interests resulting from any scientific, literary or artistic production of which (s)he is the author\u201d as also stated under the UDHR 27(b). These rights of authors must co-exist with everyone's rights to scientific knowledge, and indeed freeing such knowledge from copyright burdens will allow scholars to participate in the marketplace of ideas - to continue new research. From this starting point, we analyzed in detail the legal implications of extracting knowledge from copyrighted text under two legal frameworks: German and U.S. copyright law, presented below."}, {"title": "3.1. German Copyright Law", "content": "Under German law, Urheberrecht (copyright) serves to protect creative expressions, ensuring that authors maintain exclusive rights over their original works (Wandtke, 2010; Geller, 2009). Therefore, only the aesthetic design of a text is protected, but not the content itself. An important exception exists for complex narratives that stem from an author's imagination, which may receive copyright protection. In contrast, mere facts and scientific discoveries remain unprotected.\nFor a work to qualify for copyright protection, it must satisfy the Sch\u00f6pfungsh\u00f6he (original creative threshold) (Wandtke, 2010; Hoffmann et al., 2011), and only human authors excluding AI systems can hold authorship rights (Gr\u00e4tz, 2021; Legner, 2019). The extraction of information from copyrighted texts does not infringe upon the original rights holder's exclusive privileges (Federal Ministry of Eductaion and Research & German Library Association, 2020), provided three specific conditions are met: no protected text is copied, the extracted text is fact-centric, and data mining exemptions are adhered to.\nAccessing Original Text: According to Sections 44b and 60d of the Urheberrechtsgesetz (UrhG), or the German Copyright Act, there is explicit permission to temporarily store copyrighted works for the purpose of extracting insights such as patterns, trends, or correlations, particularly in the context of scientific research (Text and Data Mining) (Akinci, 2023). Both provisions are exceptions to the principle that works protected by copyright may only be reproduced with the permission of the author or rights holder. Organizations operating as non-profits in the scientific research sector that engage in large-scale text analysis are offered robust support under \u00a744b and \u00a760d UrhG, being authorized to perform such activities, provided they systematically delete the underlying works once the factual extraction process is complete.\nProtected Text is Not Extracted: The process of abstracting or summarizing the main ideas from a work can be permissible under German copyright law, provided the summary does not replicate the original's creative form (Akinci, 2023). Knowledge Units aim to comply to this principle by avoiding the storage of even summary phrases. Instead, it focuses solely on maintaining relationships, domain-specific concepts, or numeric attributes. If Knowledge Units do not reveal the text's distinctive arrangement or style, they cannot"}, {"title": "Publication and Use of the Extracted Knowledge Units:", "content": "Under $15 UrhG, authors retain control over the reproduction and public communication of their works. However, when it comes to the publication of extracted Knowledge Units, if what is being disseminated is non-protected factual content and the creative aspects of the original work are not reproduced in this process, they would be exempt. We highlight that any new textual or data-based work that arises solely from factual extraction is inherently authored by those who develop the new structure. Such works may be considered unprotected if they are exclusively machine-generated without any human creative input, aligning with the legal framework that restricts authorship rights to human creators (Akinci, 2023). As a result, it is viable to publish these Knowledge Units without infringing upon the original author's rights.\nOverall, the processes of accessing original texts, extracting Knowledge Units, and publishing these extracted units can be conducted in a manner that neither reproduces nor stores the original phrasing, sentence structures, or distinctive literary qualities of the source material. This allows that there is no unfreie Bearbeitung (unfree adaptation) involved, thereby avoiding any breach of German copyright laws. By explicitly prompting, we seek to adhere to the stipulated conditions - avoiding the copying of protected text, focusing on fact-centric extraction, and following data mining exemptions - allowing the extracted Knowledge Units to be published while complying with the legal protections afforded to original creative works under German law."}, {"title": "3.2. The Idea-Expression Dichotomy and US Fair Use Doctrine in Copyright", "content": "In the United States, the legal framework regarding copyright differs slightly from Germany but leads to similar conclusions as other jurisdictions. U.S. copyright law does not protect facts or ideas, only the expressions of those facts, an axiom that courts have repeatedly affirmed. Notably, the Fair Use doctrine (17 U.S.C. \u00a7107) also allows provides a flexible framework that accommodates new and transformative uses such as text and data mining (TDM) (Cox, 2015; Reichman & Okediji, 2012). The basis for using the knowledge downstream is the idea-expression dichotomy (Yen, 1989) codified in 17 U.S.C. \u00a7102 (b):\nIn no case does copyright protection for an original work of authorship extend to any idea, procedure, process, system, method of operation, concept, principle, or discovery, regardless of the form in which it is described, explained, illustrated, or embodied in such work.\nTitle 17, Section 107 of the U.S. Code also enumerates four factors to evaluate fair use. For TDM, the first factor, Purpose/Character, demands for output text (in our case, Knowledge Units) to be typically \"highly transformative,\" especially if the copying is for nonprofit research or distinct from the original text's use. The second factor, Nature of work, although many TDM cases involve creative works, courts have often downplayed or treated this factor as neutral if the use remains transformative. The third factor, Amount/Substantiality, permits copying the entire text to achieve meaningful analysis, with courts finding that the \"all or nothing\" nature of TDM demands full copying (Cox, 2015). Lastly, the fourth factor, Effect on market, is generally favorable for TDM because it does not serve as a substitute for reading or consuming the original work, thereby rarely damaging the market for the original.\nWhen these factors are weighed collectively, courts usually find that TDM constitutes fair use-particularly in academic or research settings (Cox, 2015; hat, 2012). Knowledge Units aim to operate in accordance with the best practice recommendations from \"The Code of Best Practices in Fair Use for Academic and Research Libraries,\" which explicitly endorses the creation of TDM databases, provided that full-text or near-verbatim distributions are not made publicly available (Cox, 2015). Our pipeline aims to adheres to these recommendations by ensuring that no substantial original expression is published; Knowledge Units contain only factual statements, short style descriptors, and minimal numeric references. Additionally, there is no end-user access to entire works, as the original copyrighted text is neither exposed nor distributed. Instead, it is either deleted after analysis or stored for ephemeral TDM tasks within the scope of allowable research usage. Furthermore, we focus on non-consumptive research, providing derived knowledge for advanced AI, searching, and research purposes, rather than for reading or substituting the original content.\nPast Relevant Case Law illustrates the application of these principles. In Authors Guild v. HathiTrust, the court emphasized that scanning entire works to facilitate full-text search and enable computational analysis was \u201cquintessentially transformative", "transformed the book text into data for the purpose of substantive research": "Ax, 2015).\nOverall, our approach likely aligns with past cases and could gain broad acceptance under U.S. fair use precedents, as it fosters public-interest scholarship with measures taken to avoid threatening authors' legitimate markets or moral rights to their expression. In the U.S. context, such re-purposing contributes distinct value and fosters new lines of inquiry, such as large-scale pattern identification. Moreover, it does not replace the original text as reading material, minimizing risk of market harm."}, {"title": "4. Evaluating Knowledge Unit Effectiveness", "content": "One major question is whether removing creative expression still preserves enough factual information to be useful. We designed multiple experiments to study these issues."}, {"title": "4.1. Experimental Setup and Design", "content": "Design Principles. Our evaluation requires scalable benchmarks that adapt across different research domains. To achieve this, we adopt a multiple-choice question (MCQ) design with questions, correct answers and distractors generated by a frontier LM. We chose MCQs for three key reasons: (1) They confirm with users querying knowledge contained in specified original text, providing clearer insights than retrieval metrics; (2) Not requiring manual generation allows for easy customization across various disciplines; (3) Repeating benchmark generation and retesting helps capture broader variance and reduces the risk of overfitting.\nKey Idea. We tested how well multiple-choice question (MCQ) performance is preserved when we convert the original text into Knowledge Units data. We created MCQs for each text excerpt, asked language models to answer them with no context (lower bound), then asked them again with the original text (upper bound) for sanity check since they are automatically generated. Finally, we tested them with only the Knowledge Units (our method).\nDatasets. We used:\n1. Abstract-level analysis: 1,000 abstracts each from Biology, Mathematics, and Physics of the peS2o dataset (Soldaini & Lo, 2023) as well as 1,000 abstracts from Computer Science from ArXiv (Clement et al., 2019). For each abstract, we generate three MCQs (Appendix, Table 6, 7, 8, 9) and one KU.\n2. Full-paper analysis: 200 longer papers (100 Medical, 100 Physics) (Cohan et al., 2018). We chunked each paper into segments of 200 words and generated Knowledge Units for each chunk, referencing the previous 10 units for context continuity. For each paper we generate 10 MCQs (Appendix, Table 10 and 11).\nProcedure: The Gemini Pro 1.5 002 model was utilized to generate all MCQs based on the original text, as well as to provide annotations for the correct answer. The questions are designed to assess specific, verifiable elements, such as factual claims, numerical data, definitions, or relational knowledge, to minimize ambiguity. The accuracy of the answers is verified through cloze evaluation, as is standard in the LM-Harness."}, {"title": "4.2. Results: Information Retention", "content": "We evaluate the effectiveness of Knowledge Units (KUs) in preserving information from original text by addressing two key questions:\nQ1: Does conversion retain information from the original text chunks (Abstract-Level Analysis)? To answer this, we compared multiple-choice question (MCQ) performance using Knowledge Units against performance using the original text. We tested several small language models, first asking them to answer MCQs based on full original passages, then repeating the test with only Knowledge Units. Table 2 presents the results.\nFindings. As expected, models answering without any context (lower bound) performed significantly worse than those given the full original text (upper bound), confirming that context is crucial for correctly answering the MCQs. While language models could occasionally eliminate incorrect answer choices using prior knowledge, their accuracy remained low without context. When provided with Knowledge Units instead of the original text, model performance closely matched the upper bound in nearly all cases. This suggests that Knowledge Units preserve the majority of relevant information needed for answering questions. The pattern held across different models and research domains. Additionally, the variance in performance across different question sets remained between 3-5%, indicating a statistically significant but relatively small difference between using the original text and using Knowledge Units.\nQ2: Can conversion preserve information in long documents (full paper analysis)? To examine this, we assessed model performance on long-document MCQs, where each document was segmented into multiple Knowledge Units. We used models with larger context windows, both to generate the Knowledge Units and to answer the questions. Table 3 summarizes the results.\nFindings. Consistent with Q1, the gap between the lower and upper bounds remained large, reaffirming the validity of our MCQ evaluation approach. However, we observed a slight decline in the upper bound performance, suggesting that longer documents introduced additional complexity, making some questions harder to answer even with access to the full text. Knowledge Units performed slightly worse in long-document scenarios compared to short text segments. This suggests that aggregating multiple Knowledge Units across long contexts introduces some challenges in reasoning. However, performance remained much closer to the upper bound than the lower bound, confirming that Knowledge Units still retained most of the critical information. As with Q1, variance across different question sets remained within 3-5%, reinforcing the reliability of these findings.\nConclusion. Knowledge Units effectively preserve information across multiple domains. While performance degradation is observed in long-document scenarios, the majority of factual content remains intact. These results are consistent across different model families and scientific disciplines, demonstrating the robustness of Knowledge Units as a structured knowledge representation format."}, {"title": "4.3. Results: Assessing Content Overlap", "content": "We have established that key information is preserved in the generated Knowledge Units (KUs). As a next step, we perform empirical checks to detect potential text reuse. In legal contexts, consistent high n-gram overlap across large spans of text is a commonly used measure to prove textual reuse, though not a definitive measure by any means. Here, we compute n-gram overlaps between the original abstracts and our generated KUs on an abstract-level dataset, with results shown in Table 4 for the two best models.\nQ1: Is there a significant overlap? The top portion of Table 4 reports 5-gram, 7-gram, and 11-gram Jaccard similarities for the entire dataset, as well as for the top 5% of the most similar original text-KU pairs. The Gemini-1.5 Flash model consistently exhibits very low overlap (<3% in the most conservative 5-gram scenario), even in the top 5% subset. The Qwen-2.5 model shows slightly higher scores but remains below 7% in the same scenario. Overall, these findings indicate negligible direct textual reuse.\nQ2: Does a plagiarism check show different trends? We additionally use an open-source plagiarism detector (Pike & Loki), which attempts to detect more subtle forms of reuse (e.g., paraphrasing, synonym substitutions). Scores below 20% are typically dismissed as negligible threshold and are not even displayed, according to official documentation. We apply this check instead of the n-gram metric, keeping everything else constant. Table 4 reports averages of 3\u20135% for the entire dataset, rising to 15-23% in the top 5% of most similar pairs. These numbers remain below or close to even automatic dismissal thresholds, let alone a conservative actionable plagiarism check. This reinforces the findings from n-gram scores, indicating no direct text reuse.\nQ3: Does reconstructing text increase overlaps? We next tried our best prompting a strong LM (Gemini-1.5 Pro) to regenerate the original abstract from a knowledge graph, using few-shot examples from the same domain. While Qwen-2.5 shows a substantial increase in n-gram overlap in the top 5% subset, overlaps for both models, especially Gemini-1.5 Flash, remain extremely low in an absolute sense. Sherlock scores also remain unchanged in all but overall the Qwen-2.5 case. Manual inspection of the highest-overlap (11-gram) passages, with examples provided in Appendix C, suggests that most identical segments are filler phrases common in scientific writing, rather than substantive stylistic overlap.\nConclusion. Across both n-gram overlap measures and a dedicated plagiarism detector, evidence of direct text copying remains minimal. Even when models are explicitly prompted to reconstruct the source text, stylistic carryover is surprisingly low. While neither n-gram overlap nor plagiarism checks are legal standards for copyright, they provide preliminary empirical reassurance that the original text is not being substantially reproduced."}, {"title": "5. Alternative Positions", "content": "Extracting valuable scientific knowledge from scholarly texts is debated from two main perspectives. One view argues that existing methods like LM embeddings already separate factual content from expressive elements, making a new format like Knowledge Units unnecessary (see Section 5.1). Conversely, critics question whether scientific knowledge can ever be freed from copyright constraints, citing the complexity of legal challenges, limitations of automated extraction methods, and the potential for large-scale harm (see Subsection 5.2)."}, {"title": "5.1. Limitations of Embeddings", "content": "While text embeddings are commonly used to store and share even copyrighted content, we demonstrate they inadequately preserve scientific knowledge even state-of-the-art models on MTEB Leaderboard (Muennighoff et al., 2023)like BGE-M3 (Chen et al., 2024). Embeddings primarily capture coarse semantic similarity but fail to encode precise factual statements, causal relationships, or numeric details.\nExperimental Setup: We embedded abstracts from prior analysis using BGE-M3 and evaluated knowledge retention via cosine similarity.\nSanity Checks: Baselines included (1) gibberish vs. original (lower bound), (2) original vs. itself (upper bound), (3) unrelated domain-matched abstracts, and (4) scrambled abstracts (randomized word order).\nResult. Table 5 summarizes the results. We see that heavily scrambled text often showed high similarity to the original, revealing that surface-level spurious patterns drive much of the model's similarity score. Cosine similarity, the most popular method for using embeddings, cannot separate whether the extracted facts (e.g., relationships, causal statements, numerical data) actually match the source.\nConclusion. Embeddings often fail to capture precise factual details, making them unreliable technically for preserving scientific knowledge. Similarly, simple paraphrasing may still resemble the original text's structure and style too closely, raising potential legality concerns."}, {"title": "5.2. Addressing Common Criticisms", "content": "We address a few common criticisms to our position below:\n1. Credit Attribution: Critics contend that open-access extraction of research findings into structured databases risks diluting traditional citation metrics (e.g., impact factors), as users may cite the database over original papers.\nRebuttal: Traceable attribution systems (e.g., DOIs embedded in extracted facts) and enhanced accessibility can amplify citation reach while preserving credit to authors.\n2. Oversimplification of Nuance in Research: Knowledge Units may not effectively capture intricate procedures such as mathematical proofs or biochemical assays. In general, information that is best presented through tables, diagrams, or proofs does not easily convert into Knowledge Units.\nRebuttal: We agree, this is a critical limitation of KUs. However, mathematical proofs, assay descriptions, tables of results and similar long-form structured texts are largely not even eligible for copyright. However, we need to accurately identify and release such text information as-is.\n3. Legal Risks: Transformative-use defenses under fair use law are context-dependent, requiring costly case-by-case litigation, creating deterrence through legal uncertainty.\nRebuttal: We agree. We try to mitigate this by careful design, using structured extraction frameworks converting text into non-expressive factual units.\n4. Hallucination Propagation: Automated extraction risks embedding inaccuracies, particularly in high-stakes domains, without scalable human validation.\nRebuttal: We agree, and believe a critical next step is designing hybrid systems integrating cross-referencing algorithms, confidence scoring, and targeted human oversight for critical assertions to balance scalability with rigor. Moreover, we believe that upcoming more capable models, like recently developed reasoning models, will provide further way to automate and scale verification of extracted knowledge content, requiring human assistance only in few manageable cases.\n5. Irreversible Harm. Once Knowledge Units is released, any flaws discovered later affects all released content, making the copyright harm irreversible."}, {"title": "6. Impact: Why Free Scientific Knowledge?", "content": "Historically, making knowledge widely available has driven transformative progress. Gutenberg's printing press broke medieval monopolies on information, increasing literacy and contributing to the Renaissance and Scientific Revolution. In today's world, open source projects such as GNU/Linux and Wikipedia show that freely accessible and modifiable knowledge fosters innovation while ensuring creators are credited through copyleft licenses. These examples highlight a key idea: access to essential knowledge supports overall advancement.\nThis aligns with the arguments made by Prabhakaran et al. (Prabhakaran et al., 2022), who specifically highlight the human right to participate in scientific advancement as enshrined in the Universal Declaration of Human Rights. They emphasize that this right underscores the importance of equal access to the benefits of scientific progress for all, a principle directly supported by our proposal for Knowledge Units. The UN Special Rapporteur on Cultural Rights further reinforces this, advocating for the expansion of copyright exceptions to broaden access to scientific knowledge as a crucial component of the right to science and culture (of the High Commissioner for Human Rights, 2015).\nHowever, current intellectual property regimes often create \"patently unfair\" barriers to this knowledge, preventing innovation and access, especially in areas critical to human rights, as Hale compellingly argues (Hale, 2022). Finding a solution requires carefully balancing the imperative of open access with the legitimate rights of authors. As Austin and Ginsburg remind us, authors' rights are also human rights, necessitating robust protection (Austin & Ginsburg, 2022). Shareable knowledge entities like Knowledge Units offer a potential mechanism to achieve this delicate balance in the scientific domain, enabling wider dissemination of research findings while respecting authors' fundamental rights."}, {"title": "6.1. Impact Across Sectors", "content": "Researchers: Collaboration across different fields becomes easier when knowledge is shared openly. For instance, combining machine learning with biology or applying quantum principles to cryptography can lead to important breakthroughs. Removing copyright restrictions allows researchers to freely use data and methods, speeding up discoveries while respecting original contributions.\nPractitioners: Professionals, especially in healthcare, benefit from immediate access to the latest research. Quick access to newer insights on the effectiveness of drugs, and alternative treatments speeds up adoption and awareness, potentially saving lives. Additionally, open knowledge helps developing countries gain access to health innovations.\nEducation: Education becomes more accessible when teachers use the latest research to create up-to-date curricula without prohibitive costs. Students can access high-quality research materials and use LM assistance to better understand complex topics, enhancing their learning experience and making high-quality education more accessible.\nPublic Trust: When information is transparent and accessible, the public can better understand and trust decision-making processes. Open access to government policies and industry practices allows people to review and verify information, helping to reduce misinformation. This transparency encourages critical thinking and builds trust in scientific and governmental institutions.\nOverall, making scientific knowledge accessible supports global fairness. By viewing knowledge as a common resource rather than a product to be sold, we can speed up innovation, encourage critical thinking, and empower communities to address important challenges."}, {"title": "7. Open Problems", "content": "Moving forward, we identify key research directions to further exploit the potential of converting original texts into shareable knowledge entities such as demonstrated by the conversion into Knowledge Units in this work:\n1. Enhancing Factual Accuracy and Reliability: Refining KUs through cross-referencing with source texts and incorporating community-driven correction mechanisms, similar to Wikipedia, can minimize hallucinations and ensure the long-term accuracy of knowledge-based datasets at scale.\n2. Developing Applications for Education and Research: Using KU-based conversion for datasets to be employed in practical tools, such as search interfaces and learning platforms, can ensure rapid dissemination of any new knowledge into shareable downstream resources, significantly improving the accessibility, spread, and impact of KUs.\n3. Establishing Standards for Knowledge Interoperability and Reuse: Future research should focus on defining standardized formats for entities like KU and knowledge graph layouts (Lenat et al., 1990). These standards are essential to unlock seamless interoperability, facilitate reuse across diverse platforms, and foster a vibrant ecosystem of open scientific knowledge.\n4. Interconnecting Shareable Knowledge for Scientific Workflow Assistance and Automation: There might be further potential in constructing a semantic web that interconnects publicly shared knowledge, together with mechanisms that continually update and validate all shareable knowledge units. This can be starting point for a platform that uses all collected knowledge to assist scientific workflows, for instance by feeding such a semantic web into recently developed reasoning models equipped with retrieval augmented generation. Such assistance could assemble knowledge across multiple scientific papers, guiding scientists more efficiently through vast research landscapes. Given further progress in model capabilities, validation, self-repair and evolving new knowledge from already existing vast collection in the semantic web can lead to automation of scientific discovery, assuming that knowledge data in the semantic web can be freely shared.\nWe open-source our code and encourage collaboration to improve extraction pipelines, enhance Knowledge Unit capabilities, and expand coverage to additional fields."}, {"title": "8. Conclusion", "content": "In this paper, we highlight the potential of systematically separating factual scientific knowledge from protected artistic or stylistic expression. By representing scientific insights as structured facts and relationships, prototypes like Knowledge Units (KUs) offer a pathway to broaden access to scientific knowledge without infringing copyright, aligning with legal principles like German \u00a724(1) UrhG and U.S. fair use standards. Extensive testing across a range of domains and models shows evidence that Knowledge Units (KUs) can feasibly retain core information. These findings offer a promising way forward for openly disseminating scientific information while respecting copyright constraints."}, {"title": "A. Appendix", "content": "A.1. Example Knowledge Unit\nThe following shows the first of six KUs of \"Sparsity-certifying Graph Decompositions\" (Streinu & Theran", "2009b)\nTitle": "Sparsity-certifying Graph Decompositions\nAuthors: Ileana Streinu; Louis Theran\nGenre: Academic Journal", "Science\nStyle": "The writing style is formal and highly technical", "Streinu'": {"n'relations'": {"n'authored'": "Sparsity-certifying Graph Decompositions", "n'affiliated_with'": "Smith College", "n'email'": "streinu@cs.smith.edu", "n},\n'attributes'": {"n'department'": "Computer Science", "Theran'": {"n'relations'": {"n'authored'": "Sparsity-certifying Graph Decompositions", "n'affiliated_with'": "University of Massachusetts Amherst", "n'email'": "theran@cs.umass.edu", "n},\n'attributes'": {"n'department'": "Computer Science", "Decompositions'": {"n'relations'": {"n'authors'": ["Ileana Streinu", "Louis Theran"], "n'introduces'": "(k, \\$\\lambda\\$)-pebble game with colors", "n'characterizes'": "(k, \\$\\lambda\\$)-sparse graphs", "n'provides_solutions_for'": "Tree decompositions of graphs", "n'extends_work_of'": ["Lee and Streinu", "Gabow", "Gabow and Westermann", "Hendrickson \u2192"], "n'proves'": "Tutte-Nash-Williams characterization of arboricity", "n},\n'attributes'": {"n'type'": "Academic Journal, Mathematics, Computer Science", "n'topic'": "Graph decompositions", "n'focus'": "(k, \\$\\lambda\\$)-sparse graphs", "colors'": {"n'relations'": {"n'introduced_in'": "Sparsity-certifying Graph Decompositions", "n'generalizes'": "Previous results of Lee and Streinu", "n},\n'attributes'": {"n'type'": "Algorithm", "graphs'": {"n'relations'": {"n'characterized_by'": " (k, \\$\\lambda\\$)-pebble game with colors", "n'definition'": "No subset of n vertices spans more than \\$k n \\$\\lambda\\$ edges", "n},\n'attributes'": {"n'range'": "\\$k \\geq \\lambda \\geq 2k-1\\$ (upper range)", "graphs'": {"n'relations'": {"n'are_a_type_of'": "(k, \\$\\lambda\\$)-sparse graphs", "n},\n'attributes'": {"n'edge_count'": "\\$k n $\\lambda$\\$"}, "graphs'": {"n'relations'": {"n'addressed_by'": "Sparsity-certifying Graph Decompositions", "n},\n'attributes'": {"n'relevance'": "Rigidity theory", "arboricity'": {"n'relations'": {"n'proven_by'": "Sparsity-certifying Graph Decompositions", "n},\n'attributes'": {"n'type'": "Theorem"}}}}}}}}}}}}}}}}}}}}}}}}]}