{"title": "SiMilarity-Enhanced Homophily for Multi-View Heterophilous Graph Clustering", "authors": ["Jianpeng Chen", "Yawen Ling", "Yazhou Ren", "Zichen Wen", "Tianyi Wu", "Shufei Zhang", "Lifang He"], "abstract": "With the increasing prevalence of graph-structured data, multi-view graph clustering has become a fundamental technique in various applications. While existing methods often employ a unified message passing mechanism to enhance clustering performance, this approach is less effective in heterophilous scenarios, where nodes with dissimilar features are connected. Our experiments demonstrate this by showing the degraded clustering performance as the heterophilous ratio increases. To address this limitation, a natural method is to conduct specific graph filters for graphs with specific homophilous ratio. However, this is inappropriate for unsupervised tasks due to the unavailable labels and homophilous ratios. Alternatively, we start from an observation showing that the implicit homophilous information may exist in similarity matrices even when the graph is heterophilous. Based on this observation, we explore a strategy that does not require prior knowledge of the homophilous or heterophilous, proposing a novel data-centric unsupervised learning framework, namely SiMilarity-enhanced Homophily for Multi-view Heterophilous Graph Clustering (SMHGC). By analyzing the relationship between similarity and graph homophily, we propose to enhance the homophily by introducing three similarity terms, i.e., neighbor pattern similarity, node feature similarity, and multi-view global similarity, in a label-free manner. Then, a consensus-based inter- and intra-view fusion paradigm is proposed to fuse the improved homophilous graph from different views and utilize them for clustering. The state-of-the-art experimental results on both multi-view heterophilous and homophilous datasets highlight the effectiveness of using similarity for unsupervised multi-view graph learning, even in heterophilous settings. Furthermore, the consistent performance across semi-synthetic datasets with varying levels of homophily serves as further evidence of SMHGC's resilience to heterophily.", "sections": [{"title": "1 Introduction", "content": "Graph neural networks (GNNs) that can handle graph data by considering both node features and neighbor relations show impressive performance in various domains, such as social networks, recommendation systems and molecules. However, labeling the growing explosion of graph-structured data is often intricate and expensive. Deep multi-view graph clustering (MVGC) has recently been explored to address this problem under unsupervised settings by leveraging the complementary and consistent information of different graph views. For example, O2MAC captures the shared feature representation by designing a One2Multi GNN-based graph autoencoder. MVGC explores the cluster structure by training a graph convolutional encoder to learn the self-expression coefficient matrix. MCGC learns a consensus graph to exploit both attribute content and graph structure information simultaneously.\nDespite much progress made in this area, these methods based on GNNs typically rely on an implicit homophily assumption, i.e., connected nodes often belong to the same class. With this assumption, the message passing mechanism in GNNs can effectively aggregate the node information from the same class while disregarding the scrambled information, enabling the model to obtain class-distinguishable embedding for downstream tasks as substantiated by extensive empirical evidence. Unfortunately, the graphs collected in reality often fail to fully satisfy the homophily assumption, which significantly limits the applicability of GNN-based MVGC methods. In fact, a more common graph is moderately or even mildly homophilous rather than a fully homophilous graph due to the general presence of non-homophilous (heterophilous) information in graphs. When it comes to such heterophilous graphs, the message passing mechanism aggregates the node information from different classes, hindering access to class discriminative embeddings. The empirical results shown in Fig. 1(a) demonstrate the challenge of heterophilous in the context of unsupervised clustering task, i.e., the steady degrades of clustering performance with the increase of heterophilous ratio. Unlike supervised tasks with ground truth labels where the homophilous ratio could be estimated and then improved by the observation of training data, it is more difficult to design frameworks for unsupervised clustering on homophilous ratio agnostic graphs. Therefore, one key point for MVGC is how to learn class discriminative embeddings on unsupervised tasks with unknown homophilous ratio, which termed as multi-view heterophilous graph clustering (MVHGC).\nRecently, several works have tried to address the heterophilous issue for MVGC. These works, generally, focus on two aspects. One is to utilize the pseudo labels predicted by multiple views to gradually improve the aggregated graphs, for example, DuaLGR proposes a dual pseudo label guided framework. Another type tries to adaptively extract useful information by utilizing elaborate graph filters. For example, MCGC and AHGFC propose hybrid graph filters for learning node embedding. However, the first type relies on the robustness of pseudo labels, the bad quality of pseudo labels may lead to local optimums. The second type is limited due to the difficulty in determining which graph filter should be used for which specific graph, because of the unaccessible homophilous ratio.\nUnlike these model-centric methods, we address this issue from a data-centric view, which could skip the limitations of previous works that rely on pseudo labels or GNN models (graph filters). Our observations on the benchmark data demonstrate the homophilous ratio of a graph could be potentially improved. As shown in Fig. 1(b), the homophilous ratio could essentially be improved by the proposed neighbor pattern similarity and feature similarity. This suggests that homophilous information can exist even in heterophilous graphs, a factor that has been overlooked by previous work.\nBased on the observation, we propose our solution from a significantly effective yet generally underestimated perspective - Similarity. To avoid the limitations of GNNs on heterophilous graphs for clustering tasks, as described in Fig. 1 and Section 2.2, we propose three similarities, i.e., neighbor pattern similarity, node feature similarity, and multi-view global similarity, to effectively improve the homophily of graph. Building on this concept, we propose a SiMilarity-enhanced homophily Multi-view Heterophilous Graph Clustering framework (SMHGC). In this framework, a robust similarity-enhanced homophilous graph can be obtained"}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Notations and Definitions", "content": "Let \\(G = (V,E)\\) be an undirected graph, where \\(V = {x_i}_{i=0}^N\\) is the node set with node numbers \\(N = |V|\\), and \\(E = {e_{i,j}|0 < i, j < N}\\) is the edge set with self-loop. \\(X \\in \\mathbb{R}^{N \\times d}\\) denotes the feature matrix of the nodes, where \\(x_i\\) is the \\(d\\)-dimensional feature vector of node \\(i\\). \\(A \\in \\mathbb{R}^{N \\times N}\\) is the symmetric adjacency matrix of \\(G\\),\nwhere \\(a_{ij} = 1\\) if there exists an edge between node \\(i\\) and node \\(j\\), otherwise \\(a_{ij} = 0\\). Let diagonal matrix \\(D\\) represent the degree matrix of \\(A\\), i.e., \\(D_{ii} = \\sum_j A_{ij}\\). Here we consider the normalized adjacency matrix \\(A\\) to be normailzed as \\(\\bar{A} = D^{-1}A\\). In the setting of MVGC, nodes and the relations among them can be seen from multiple views. Specifically, given \\(V\\) different views with graphs \\({G^v}_{v=1}^V\\) and features \\({X^v}_{v=1}^V\\), the goal of MVGC is to partition the nodes into different classes.\nHomophily and heterophily. Different from homogeneity/ heterogeneity which describes the types of nodes and edges in a graph, homophily/ heterophily is a concept that describes the nature of edges in a graph. To make the distinction easier, we formally define them again as follows.\nDefinition 1 (Homophily and heterophily). Let \\(Y\\) be the set of node labels, where \\(y_i\\) denotes the label of node \\(i\\). Let \\(e_{i,j}\\) be an arbitrary edge connecting node \\(i\\) and node \\(j\\) in \\(V\\). Homophily describes \\(y_i = y_j\\) for the edge \\(e_{i,j}\\), and, conversely, it is termed heterophily.\nFor a graph, it consists of only homophilous and non-homophilous edges (heterophilous edges). Based on this, we can define the homophilous information in a graph with the help of generalized edge as follows:\nDefinition 2 (Generalized edge). The generalized edge set \\(\\bar{E}\\) is defined by transforming the inputs \\(X\\) and \\(A\\) through any transformation operation \\(T_f(\\cdot)\\) (e.g., initial inputs or multi-order aggregation): \\(E = T_f(X, A) : \\mathbb{R}^{N \\times d}, \\mathbb{R}^{N \\times N} \\rightarrow \\mathbb{R}^{N \\times N}\\). Each element \\(\\bar{e}_{ij}\\) in \\(E\\) is a generalized edge that connects nodes \\(i\\) and \\(j\\).\nDefinition 3 (Homophilous information). For an arbitrary generalized edge \\(\\bar{e}_{i,j} \\in E\\), it exhibits homophily if and only if \\(y_i = y_j\\), i.e., nodes \\(i\\) and \\(j\\) connected by it belong to the same cluster. The homophilous information is defined as the set of homophilous generalized edges.\nIn recent works, the ratio of homophilous edges, named homophily ratio, is used to measure the homophily of a given graph. The graph becomes strongly homophilous when this ratio closes to 1, and conversely, the graph is with strong heterophily (i.e., weak homophily) when the ratio closes to 0. However, it is notable that this metric can only be used for evaluation but cannot contribute to the learning of models in unsupervised scenarios since this process relies on labels that are agnostic.\nWith the aforementioned notations, the problem of MVHGC can be formalized as follows.\nProblem 1 (Multi-view heterophilous graph clustering).\nInput: Graphs \\({G^v}_{v=1}^V\\) encompassing both homophilous and heterophilous information and corresponding node feature matrices \\({X^v}_{v=1}^V\\) from \\(V\\) views.\noutput: The clustered node labels for the total \\(N\\) nodes."}, {"title": "2.2 Limitation of GNNs for Clustering on Heterophilous Graph", "content": "Generally, contemporary GNNs rely on a message passing mechanism in which each node updates itself by aggregating the embedding of its neighboring nodes and combining it with its own embedding. Specifically, the embedding update process of node \\(i\\) at the \\(l\\)-th GNN layer can be expressed as:\n\\begin{equation}\nm_i^l = AGGREGATE^l({h_u^{l-1}|u \\in \\mathcal{N}(i)}); h_i^l = UPDATE^l(h_i^{l-1}; m_i^l),\n\\end{equation}\nwhere \\(h_i^l\\) denotes the embedding of node \\(i\\) at the \\(l\\)-th layer, \\(\\mathcal{N}(i)\\) represents the neighborhood of node \\(i\\) and \\(m_i^l\\) represents the messages aggregated from the neighborhood of node \\(i\\). \\(AGGREGATE(\\cdot)\\) and \\(UPDATE(\\cdot;\\cdot)\\) are defined as aggregation and update operations in the forward process. From Eq. (1), it can be seen that messages from neighborhood aggregation play a crucial role in the update of node \\(i\\'s\\) embedding. In homophilous neighborhoods, messages are clear and come from pure neighbors of the same class. While in heterophilous neighborhoods, mixed-class information weakens embedding distinguishability. We claim that this distinguishability also exists in unsupervised clustering task. Fig. 1(a) demonstrates this by performing a basic two-order nonparametric message passing on two single-view datasets (Cora and Citeseer) respectively, showing that performance is greatly affected by heterophilous information. Therefore, directly aggregating messages from neighbors through a heterophilous graph may not be an effective choice."}, {"title": "3 Proposed Framework", "content": ""}, {"title": "3.1 Overview of SMHGC", "content": "In this section, we present the SMHGC framework, focusing on three key similarities. Fig. 2 illustrates an overview of SMHGC. \\(V\\) feature matrices (\\({X^v}_{v=1}^V\\)) and corresponding \\(V\\) graphs (\\({A^v}_{v=1}^V\\)) are input. Then, in the homophilous information extraction module, the feature matrices and adjacent matrices are transformed into two similarity subspaces \\(Z_a\\) and \\(Z_x\\) respectively to construct two similarities, i.e., neighbor pattern similarity (\\(A_a\\)) and node feature similarity (\\(A_x\\)) (Section 3.2). After that, in the intra-view fusion module, the global similarity matrix \\(HH^T\\) which implies multi-view consistency similarity information is introduced to measure and weight the aforementioned two similarities, so that the graph \\(S^v\\) obtained from the three similarities is able to absorb not only the homophilous information from neighbor pattern and node feature but also the multi-view consistency similarity information from different views. This extracted homophilous structure is then aggregated with node features to get intra-view embeddings (Section 3.3). Finally, multiple view-specific embeddings are fused under the guidance of consensus information to produce a better global embedding, \\(H\\). Iteratively, the updated \\(H\\) further aids in the generation and optimization of view-specific similarity graph \\(S^v\\) (Section 3.4). Finally, the optimized global embedding is fed into traditional clustering methods (e.g., K-means) to obtain clustering results.\nOverall, SMHGC utilizes similarity to extract and enhance the homophilous information that is implied in features and heterophilous graphs, and then they are weighted and fused under the guidance of the multi-view global similarity. Therefore, a similarity graph \\(S^v\\) with comprehensive homophilous information can be"}, {"title": "3.2 Couple Similarity Enhanced Homophily", "content": "Neighbor pattern similarity for homophilous information extraction. For a graph, it consists of only homophilous and heterophilous information. Instead of directly using this graph to aggregate neighbor messages, our motivation is to extract the implied homophilous information from this graph, so the negative effect of heterophilous information can be effectively avoided. A natural question is what is the homophilous information in a heterophilous graph?\nTo answer the question, we investigate various prior studies. For example, He et al. (2023) demonstrated that neighbor patterns are the key factor for GNNs to improve performance. Moreover, some research suggests that 'good heterophily', where the nodes with the same label sharing similar neighbor patterns, can be exploited to achieve good performance. These research provides us a support and possible solution to find homophilous information implied in heterophilous graphs. Following these previous works, we summarize their observation in the following Proposition 1:\nProposition 1 (Good heterophily ). In heterophilous graphs, if the neighborhood distribution of nodes with the same label is (approximately) sampled from a similar distribution and different labels have distinguishable distributions, then this heterophilous graph indicates good heteropihly.\nRegrettably, this notion of 'good heterophily', as inferred from the label information, is unsuitable for unsupervised MVHGC task. To generalize this proposition to unsupervised setting, we propose the hypothesis:\nHypothesis 1. In node clustering tasks, the higher the similarity between two nodes in an ideal subspace, the greater the likelihood that they belong to the same cluster.\nWith Hypothesis 1, the labels mentioned in Proposition 1 can be generalized to similarity, which implies that the nodes with similar neighbor patterns in the ideal subspace are homophilous nodes, so that to be used in the clustering task. More importantly, the target of learning homophilous information from a good heterophilous graph can be naturally changed to the target of learning a better projection that can project the input nodes to the ideal subspace. Therefore, it becomes achievable to find the homophilous information implied in good heterophilous graphs by considering the neighbor pattern similarity:\nDefinition 4 (Neighbor pattern similarity). Given adjacency matrix \\(A\\), each row in \\(A\\) describes the neighbor pattern of the node. Therefore, we define \\(AA^T\\) as neighbor pattern similarity.\nFor an intuitive understanding, from the neighborhood aggregation perspective, neighbor pattern similarity implies 2-hop structural information, which provides a possibility to receive more homophilous edges compared to the initial heterophilous adjacency matrix. The experimental results shown in Fig. 3 also demonstrate that the neighbor pattern similarity may capture homophilous information implied in heterophilous graph.\nFollowing the analysis, for acquiring homophilous information, we employ deep encoders to initially conduct subspace learning for node neighbors. This process is then refined through multi-view consensus, facilitated by a regularization term in Eq. (5) that captures neighbor pattern similarity. Specifically, each row of the given graph \\(A\\) implies a neighbor pattern of a node, so \\(A\\) is fed into an encoder \\(f_a\\) instantiated with a multi-layer perception (MLP) with learnable parameters \\(\\theta_a\\), and then outputs a low-dimensional representation:\n\\begin{equation}\nZ_a = f_a(A; \\theta_a),\n\\end{equation}\nwhere \\(Z_a\\) aims to represent the potential neighbor pattern in ideal subspace.\nSubsequently, we propose the neighbor pattern similarity regularization term \\(\\mathcal{L}_{sim_a}\\) to encourage the encoder \\(f_a\\) to focus on learning neighbor pattern similarity information of the input graph:\n\\begin{equation}\n\\mathcal{L}_{sim_a} = l_s(Z_aZ_a^T; AA^T),\n\\end{equation}\nwhere \\(l_s(\\cdot;\\cdot)\\) is loss calculation function, instantiated here as the Mean Squared Error (MSE) loss. In this similarity loss, \\(AA^T\\) is the neighbor pattern similarity information of the input graph. Consequently, by"}, {"title": "How the couple similarity enhances clustering performance.", "content": "The neighbor pattern similarity defined in Definition 4 enables the extraction of both homophilous information and 'good heterophily' from the input graph in a label-free manner. On the one hand, it involves a 2-hop aggregation of the adjacency matrix, allowing for the comprehensive mining of homophilous information within it. On the other hand, through similarity computation, similar neighboring patterns can be efficiently explored, facilitating the identification of 'good heterophily'. In addition, feature similarity extracts homophilous information from feature space."}, {"title": "3.3 Global Similarity Guided Intra-View Homophily Fusion and Aggregation", "content": "In unsupervised tasks, the inaccessibility of labels and homophily may lead to a lack of robustness when extracting homophilous information. Therefore, in this section, we address the challenge that how to obtain more robust homophilous information, and seek the guidance of consensus from different views.\nHow to fuse node feature and neighbor pattern similarities. The node features and neighbor patterns in each view's graph \\(G^v\\) may imply different homophilous information, which contributes differently to the downstream task. To generate a robust homophilous graph, we design a global similarity guided intra-view homophily fusion strategy, aiming to assign weights to the extracted homophilous information based on their relevance to the final task and multi-view global similarity. Without labels, it is difficult to directly determine the contribution of information to the final task. An alternative approach is inspired by clustering algorithms like K-means (MacQueen, 1967), where the distance between samples and their cluster centroids dictates their final assignments. In other words, the distance between samples plays a basis role for final assignments. Similarly, the fused embedding from all views (denoted as \\(H\\)), which is used for final assignments, captures the basis that is most aligned with the downstream tasks.\nTherefore, it is natural to use the global similarity matrix obtained from \\(H\\) to evaluate the homophilous information of node features and neighbor patterns. Specifically, let the homophilous information from node features and neighbor patterns be denoted as \\(A_x = Z_xZ_x^T\\) and \\(A_a = Z_aZ_a^T\\), respectively. Their contribution to the task objective can be assessed by evaluating their similarity to \\(H\\):\n\\begin{equation}\n(\\omega_x, \\omega_a) = norm(sim(A_x; HH^T), sim(A_a; HH^T)),\n\\end{equation}\nwhere \\(norm(\\cdot)\\) denotes normalization operation, \\(sim(\\cdot;\\cdot)\\) denotes the similarity calculation function, which is instantiated as cosine similarity in this work, and \\(HH^T\\) is the global similarity matrix. Based on this, \\(A_x^v\\) and \\(A_a^v\\) in \\(v\\)-th view can be properly fused to generate a homophilous graph as follows:\n\\begin{equation}\nS^v = \\omega_x A_x^v + \\omega_a A_a^v.\n\\end{equation}\nTo accommodate the discrete nature of graph, we discretize the dense \\(S^v\\). Specifically, let \\(\\mathcal{U}^v\\) be the set of the top \\(k\\) largest elements in \\(S^v\\), where \\(k\\) is a hyperparameter, thus \\(S^v\\) can be discretized as:\n\\begin{equation}\nS_{ij}^v = \\begin{cases}\n1, & \\text{if } s_{ij}^v \\in \\mathcal{U}^v, \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\end{equation}\nAggregate node feature and extracted graph via GNN. Compared to the neighbor relations in a graph composed of solely homophilous and heterophilous edges, the node features encompass a variety of information that can be leveraged for obtaining distinguishable embeddings. Therefore, the node features are required to be compressed in a latent space. In this work, autoencoders are employed to compress the inherent distinguishability of these node features. Let \\(f_{\\phi^v}\\) and \\(g_{\\xi^v}\\) be the encoder and decoder with"}, {"title": "3.4 Global Consensus Based Inter-View Fusion", "content": "In multi-view tasks, each view can contribute different information to the downstream task to varying degrees. To fully exploit the complementarity of the individual views, it is natural to fuse the embeddings from all views. However, the quality of information may vary across views, necessitating the assignment of appropriate weights to each view during fusion. Given the absence of label information, an alternative approach is to use inter-view consensus for evaluation. Specifically, we utilize the fused embedding \\(H\\) from the current iteration to evaluate and score the embedding \\(H^v\\) obtained from each view. Based on this, we determine the weight of each view for fusion. Ultimately, the weighted fused embedding is updated:\n\\begin{equation}\nH = \\sum_{v=1}^V \\omega_v H^v, \\omega_v = \\frac{score(v)^p}{\\max(score(1), score(2),..., score(V))},\n\\end{equation}\nwhere \\(score^v\\) can be obtained from the evaluation function, \\(score^v = metric(H^v; H)\\) and \\(metric(\\cdot;\\cdot)\\) is instantiated as cosine similarity function in this work. The hyperparameter \\(p\\) is applied to adjust the smoothing or sharpening of the view weights. Notably, the update of \\(H\\) will in turn aid the generation of view-specific similarity graph \\(S^v\\) as the iteration proceeds. With \\(H\\), sample clustering algorithms, such as K-means, can be implemented to obtain the final assignment."}, {"title": "3.5 Objective Function", "content": "Overall, the objective function of SMHGC comprises three parts: similarity regularization loss term of \\(V\\) views \\(\\sum_v \\mathcal{L}_{sim}^v\\) (Eq. (5)), reconstruction loss of \\(V\\) views \\(\\sum_v L_r^v\\) (Eq. (9)), and Kullback-Leibler (KL) divergence loss \\(\\mathcal{L}_{kl}\\):\n\\begin{equation}\n\\mathcal{L} = \\gamma_{sim} \\sum_v \\mathcal{L}_{sim}^v + \\gamma_r \\sum_v L_r^v + \\mathcal{L}_{kl},\n\\end{equation}\nwhere \\(\\gamma_{sim}\\) and \\(\\gamma_r\\) are trade-off parameters. The KL divergence loss (\\(\\mathcal{L}_{kl}\\)) is a commonly used clustering loss applied to facilitate the model to obtain consensus embedding following the previous work . Specifically, let \\(q_i^v \\in Q^v\\) be the soft cluster assignment that describes the possibility of node \\(i\\) belonging to cluster centroid \\(j\\) in \\(v\\)-th view and \\(P\\) be the sharpen target distribution, the loss can be expressed as:\n\\begin{equation}\n\\mathcal{L}_{kl} = KL(P||Q) + \\sum_{v=1}^V KL(P||Q^v),\n\\end{equation}"}, {"title": "3.6 Generalization Analysis", "content": "To assess the robustness and generalizability of the proposed similarity terms, we conduct a generalization analysis. As a way to infer the generalization bound of the similarity, we introduce the hypothesis function \\(h_a: A \\rightarrow \\mathbb{R}^{d_a}\\) and \\(h_x: X \\rightarrow \\mathbb{R}^{d_x}\\) to map the neighbor pattern and node feature into the embedding points, where \\(A\\) and \\(X\\) represent the neighbor pattern and node feature space respectively. Then the embedding points from the neighbor pattern and node feature can be obtained by \\(z_{a_i} := h_a(a_i)\\) and \\(z_{x_i} := h_x(x_i)\\). Suppose \\(H\\) represents the family of \\(h\\). On the basis of this, the similarity loss can be expressed as:\n\\begin{equation}\n\\mathcal{L}_{sim_a} = ||Z_aZ_a^T - AA^T||_F^2 = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N ||h_a(a_i)h_a(a_j)^T - a_ia_j^T||^2,\n\\end{equation}\n\\begin{equation}\n\\mathcal{L}_{sim_x} = ||Z_xZ_x^T - XX^T||_F^2 = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N ||h_a(x_i)h_a(x_j)^T - x_ix_j^T||^2.\n\\end{equation}\nFor the similarity loss from neighbor patterns \\(\\mathcal{L}_{sim_a}\\), the empirical risk can be defined as:\n\\begin{equation}\n\\hat{\\mathcal{L}}_a(h) = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N ||h_a(a_i)h_a(a_j)^T - a_ia_j^T||^2.\n\\end{equation}\nTheorem 1. Let \\(\\mathcal{L}(h)\\) be the expectation of \\(\\hat{\\mathcal{L}}(h)\\). Suppose that for any \\(a \\in A\\) and \\(h \\in H\\), there exists \\(M < \\infty\\) such that \\(||a_ia_j^T||, ||h_a(a_i)h_a(a_j)^T|| \\in [0, M]\\) hold. Then with probability \\(1 - \\tau\\) for any \\(h \\in H\\) the inequality holds:\n\\begin{equation}\n\\mathcal{L}(h) \\leq \\hat{\\mathcal{L}}(h) + 2\\sqrt{2}M^2\\sqrt{\\frac{4 + 3ln\\frac{1}{\\tau}}{N}}.\n\\end{equation}\nUsing Theorem 1, it can be easily found that the expected risk of the similarity is bounded by the empirical risk on input neighbor patterns and node features and the complexity term that depends on \\(M\\) and \\(N\\). The proof and model complexity analysis are presented in the Appendix."}, {"title": "4 EXPERIMENTS", "content": ""}, {"title": "4.1 Experimental Settings", "content": "Datasets. To evaluate the effect of SMHGC, we conduct extensive experiments on ten datasets, including two real-world homophilous graph datasets (ACM and DBLP), two real-world heterophilous graph datasets (Texas and Chameleon ) and six semi-synthetic graph datasets generated from ACM. More details about the datasets and implementation details can be found in the Appendix. The implementation of SMHGC will be published.\nComparison methods. The following baselines are considered: VGAE is a single-view method. O2MAC, MvAGC, MCGC, MVGC , DuaLGR and BTGF are six deep MVGC methods. The results from VGAE and O2MAC on ACM and DBLP are obtained from the best in the literature, the others are conducted five times and the average results with standard deviations are reported in Table 1. For MVGC (Xia et al., 2022b), we use the original version without feature augmentation technique for fair comparison."}, {"title": "4.2 Overall Performance", "content": "Table 1 presents the clustering performance of all compared methods on four real-world graph datasets. Notably, SMHGC demonstrates competitive ability with the baselines on homophilous datasets, including ACM and DBLP. Specifically, our method outperforms the best baseline DuaLGR on ACM, with NMI, ARI, ACC, and F1 improving by 12.6%, 6.7%, 2.0%, and 2.0%, respectively. On two heterophilous datasets, i.e., Texas and Chameleon, our method exhibits excellent results compared to other traditional methods that rely on the homophily assumption. For instance, considering Texas, whose homophilous ratio hr is only 0.09, the best result from VAGE achieves only 55.3% accuracy, while SMHGC achieves significantly higher accuracy, reaching up to 71.3%. This underscores the outstanding performance of SMHGC on heterophilous graphs, leveraging similarity. It also highlights the limitations of existing traditional methods when confronted with heterophilous graphs. Additionally, Fig. 4(a) and Fig. 4(b) illustrate the partial clustering performance of SMHGC and other baselines on the six semi-synthetic ACM datasets with varying heterophilous ratios ranging from 0.5 to 1.0. The performance of these baselines deteriorates as the heterophilous ratio increases,"}, {"title": "4.3 Ablation Study", "content": "Effect of each loss. As depicted in Table 2, the performance of SMHGC experiences a significant drop in the absence of \\(\\mathcal{L}_{sim}\\). This not only validates Proposition 1 empirically but also underscores the feasibility and effectiveness of exploring homophilous information in node features and neighbor patterns through the proposed similarity loss. Additionally, \\(L_r\\) represents the reconstruction loss of the node features, aiming to retain as much key information as possible. Its absence leads to a degradation in the model's performance across all metrics. On the other hand, \\(L_{k\\iota}\\) contributes to obtaining distinguishable embeddings, although its impact appears to be subtle.\nEffect of couple similarities. As observed in the third and fourth rows of Table 2, the absence of either \\(A_x\\) or \\(A_a\\) results in a certain degree of performance degradation. This indicates that both node features and neighbor patterns contain certain complementary homophilous information. Consequently, it underscores the necessity of mining homophilous information from node features and neighbor patterns, respectively.\nEffect of global similarity. The absence of \\(\\omega_x\\) and \\(\\omega_a\\) have a negligible effect on the model's performance on ACM and a relatively strong effect on Texas. This discrepancy may arise from the varying relevance of node features and neighbor patterns to the downstream task across different datasets."}, {"title": "4.4 Parameter Sensitive Analysis", "content": "SMHGC primarily relies on two key hyperparameters: \\(k\\) and \\(order\\), which determine the number of edges in \\(S^v\\) and the aggregation order of \\(S^v\\), respectively. To explore their specific effects on the model, we conduct a parameter sensitivity analysis of these two hyperparameters on ACM and Texas datasets. Part of the results is depicted in Fig. 4(c). As illustrated, our SMHGC has better performance when \\(k\\) is in different ranges depending on the datasets. This observation suggests that the model aggregates an optimal amount of homophilous messages from the neighborhood when \\(k\\) is appropriately chosen. Empirically, selecting \\(k\\) within 8% to 12% of the number of nodes appears to yield better results. Additionally, as \\(order\\) increases, SMHGC exhibits a trend of initially rising and then stabilizing, with the peak performance observed within the range of 2 to 10. Furthermore, Fig. 4(d) illustrates the effect of different values of \\(\\gamma_{sim}\\) and \\(\\gamma_r\\) on the final results. Overall, the varying weights of \\(\\mathcal{L}_{sim}\\) and \\(L_r\\) have a relatively moderate impact on the model"}, {"title": "5 Conclusion", "content": "In this study, we analyzed the observation about homophily and similarity, and introduce an effective solution for multi-view heterophilous graph clustering, called SiMilarity-enhanced homophily for Multi-view Heterophilous Graph Clustering (SMHGC). Confronted with the challenges posed by heterophilous graphs, we empirically demonstrated the robust power of similarity for unsupervised clustering tasks. Our analysis explores how the similarity could enhance homophilious and clustering performance. Constructed on this foundation, we propose two regularization losses, i.e., neighbor pattern similarity and node feature similarity, to enhance graph homophily under the guidance of introduced multi-view global similarity. Further, we propose a paradigm for fusing inter- and intra-view information, enabling the integration of homophilous information from different sources and levels through the utilization of global similarity and multi-view consensus. Extensive experiments demonstrate the strong robustness of SMHGC for multi-view heterophilous graph clustering, validating the feasibility and effectiveness of our proposed solution."}, {"title": "A RELATED WORKS", "content": ""}, {"title": "A.1 Multi-View Graph Clustering", "content": "With the advancement of GNNs, researchers are eager to explore the graph structural information for multi-view clustering. In recent years, an abundance of methods for MVGC have emerged. O2MAC pioneered the application of GNNs in MVGC. Their approach is to encode multi-"}]}