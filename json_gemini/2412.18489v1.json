{"title": "An Overview and Discussion of the Suitability of Existing Speech Datasets to Train Machine Learning Models for Collective Problem Solving", "authors": ["Gnaneswar Villuri", "Alex Doboli"], "abstract": "This report characterized the suitability of existing datasets for devising new Machine Learning models, decision making methods, and analysis algorithms to improve Collaborative Problem Solving and then enumerated requirements for future datasets to be devised. Problem solving was assumed to be performed in teams of about three, four members, which talked to each other. A dataset consists of the speech recordings of such teams. The characterization methodology was based on metrics that capture cognitive, social, and emotional activities and situations. The report presented the analysis of a large group of datasets developed for Spoken Language Understanding, a research area with some similarity to Collaborative Problem Solving.", "sections": [{"title": "I. INTRODUCTION", "content": "Our goal has been to study the process of problem solving by individuals, e.g., Individual Problem Solving (IPS), and teams, i.e., Collaborative Problem Solving (CPS) [1], [2]. A main feature of our work has been studying team dynamics during CPS, as it is expressed by speech dialog during problem solving. In addition to studying Machine Learning (ML) and decision-making algorithms that use data collected from experimental settings [2], our work considered agent-based simulation models that mimic lab experiments [3]\u2013[5], modeling of the behavior of research teams [6], [7], and applications beyond problem solving, such as therapy [8]. This previous work has highlighted the importance of having access to datasets that comprehensively represent the characteristics of IPS and CPS, so that the datasets can be used in ML training, for model construction, and analysis.\nThe CPS process can be analyzed along four different perspectives: (i) As a complex process that involves cognitive, social, and emotional aspects interrelated in many ways [9], [10], [12], [13], (ii) As a process decided by the features of the tackled problems, which can pertain to three categories: well-defined, ill-defined, and open-ended problems [15]\u2013[17], in which problems descriptions and CPS processes might incorporate constraints and requirements, like timing constraints, cost, robustness, ethical aspects, and so on [18], [19], (iii) As a process that creates besides a solution also other outcomes, like learning new knowledge [14] or new team behavior, i.e. how to effectively work in a team [20], [21], and (iv) As a context-dependent process, in which the environment in which the process is performed is essential, such as organization, community, and society [22], [23]. Our research has focused mainly on understanding the interplay between cognitive, social, and emotional aspects during CPS.\nUsing our research experience as a starting point, the goal of this report was to discuss the dataset requirements as well as the characteristics of the existing datasets in devising and training modern ML models, decision making methods, and analysis algorithms, so that they can improve the CPS process. This work assumed that CPS was conducted in small teams of around four members, which talk to each other while solving a problem together. A dataset represents the speech recordings of such teams. It is accepted that the quality of datasets is critical for ML training, e.g., the training and re-training of deep neu-ral networks, like transformers and Large Language Models (LLMs). The characterization methodology is based on the cognitive, social, and emotional activities of problem solving, which the report argues should be captured and characterized to understand any CPS process. The report enumerates these activities and summarizes the CPS process. Then, the report presentation refers to Spoken Language Understanding (SLU), a research domain in which spoken language datasets were devised to automatically model individual and team activities. We felt that SLU tasks resemble CPS activities to some level. A set of CPS-based metrics were proposed and used to characterize the main SLU datasets. Then, the report discusses the needs related to dataset development to devise new ML methods to improve the CPS process.\nThe report uses the term utterance to denote a unit of speech or text that represents a complete expression, such as a sentence, phrase, or command. It is typically defined by natural boundaries, such as pauses or shifts in conversational turns.\nThe report has the following structure. Section II offers an overview of individual and collective problem solving. Sec-tion III summarizes SLU and compares it to CPS. Section IV"}, {"title": "II. OVERVIEW OF INDIVIDUAL AND COLLECTIVE PROBLEM SOLVING", "content": "A. Problem Solving: Cognitive Dimension\nProblem-solving activities belong to the following cate-gories [10]-[12]:\n1) Problem Framing (PF): PF requires collecting the requirements and constraints that define a problem to produce a description of the problem-solving goals [24], [25]. Goals can refer to functionality (e.g., the nature of the input processing) and performance (i.e. the pro-cessing speed). Descriptions might include ambiguities, unknowns, and can be only partially defined. Multiple problem framings are possible for a problem, especially for ill-defined and open-ended problems [25]. Reframing might be needed if the current description is incorrect or does not lead towards a solution [26], [27].\n2) Problem Understanding (PU): PU is the activity of associating meaning to a problem description [28]. It involves identifying the inputs and outputs of the prob-lem, their attributes (features), the connections between inputs and outputs, the variables involved in process-ing and their characteristics, the relationships between different input, output and variable connections, and the nature of the ambiguities and unknowns of a description.\n3) Information Recollection (IR): IR involves retrieving from the memory the knowledge related to solving a problem [31]. It involves information cueing from the memory and remembering similar problems, which were previously solved, and which can serve me modified or as analogies to solving the new problem [32], [33]. More complex situations involve knowledge restructuring and sudden insight [34].\n4) Identifying the Solving Approach (ISA): ISA repre-sents the activity of devising the general strategy for solving a problem [35], [36]. It produces a description, which while cannot be executed as it is not detailed enough, it serves as a starting point for solution elabo-ration, so that the general strategy can be converted into an executable solution. The description describes the broad operations (processing steps) required to realize the problem description.\n5) Problem Decomposition (Divide and Conquer) (DC): DC (segmentation) decomposes a problem into its sub-problems and assigns subgoals to each subproblem [37]. The solution to the subproblems must be combined into the overall solution.\n6) Solution Elaboration (SE): SE details a solution de-scription deemed to be still unexecutable by adding"}, {"title": "B. Problem Solving: Social Dimension", "content": "CPS includes the following social activities that are not part of SLU:\n1) Social Understanding (SU): SU indicates the degree to which a team member creates an image of the other team members [50]. This image includes cognitive, social, and emotional aspects, and is used during problem solving.\n2) Bridging Knowledge Gaps (BKG): BKG is the process of addressing the knowledge gaps between the members of a team. This involves aspects, like the psychological safety [20] to feel comfortable asking questions and giving feedback, degree of participation in the process, and providing answers to posed questions.\n3) Team Agreement (TA): TA presents the knowledge on which all team members agree on [51], [52].\n4) Team Synchronization (TS): TS represents the degree to which team members participate and identify social interaction procedures that support effective team coordination to solve a problem [51].\n5) Individual Learning (IL): IL describes the amount of an individual's learning by participating to CPS, includ-ing new knowledge learned as well as SU [53]. While KLR is in a solitary situation, IL refers to individual learning in a social context. Traditionally, IL includes goal adjustment, new knowledge retainment, creating new associations [54], belief change, insight [34], pres-sure management, and developing team management skills.\n6) Team Learning (TL): While BKG, TA, TS are some-times considered part of TL, this work associates ac-tivities to TL, like goal sharing, role distribution, self-construal orientation, and conflict resolution [20], [55]."}, {"title": "C. Problem Solving: Emotional Dimension", "content": "IPS and CPS includes the following aspects related to emotions, and which are not part of SLU:\n1) Individual Emotional Behavior (IEB): IEB refers to emotion, motivation, self-efficacy, pressure manage-ment, evaluation apprehension, and cultural characteris-tics [56]-[58].\n2) Team Emotional Behavior (TEB): TEM refers to psychological safety [20]."}, {"title": "III. RELATED RESEARCH AREAS", "content": "A. Activities during Spoken Language Understanding\nSLU systems perform the following main activities, each of which contributes to robust language understanding:\n1) Speech-to-Text Understanding (STU): STU converts spoken input into text, which is then processed for downstream tasks [59].\n2) Domain Classification (DC): DC assigns utterances to predefined categories depending on the application domain, like weather, music, or travel [60].\n3) Intent Recognition(IR): IR determines the purpose or action implied by an utterance [61]. For example, in the sentence \"Set a timer for 10 minutes,\" the communicated intent is SetTimer.\n4) Named Entity Recognition (NER): NER identifies and classifies entities, such as dates, locations, or product names [62].\n5) Slot Filling (SF): SF extracts specific parameters re-quired to fulfill the identified intent [63]. In the above example, the value 10 minutes is extracted as the slot value for the parameter duration.\n6) Dialogue State Tracking (DST): DST maintains the conversational context by storing user goals, preferences, and prior interactions [64]."}, {"title": "B. Discussions of the Computational Activities to Support IPS and CPS", "content": "The following differences distinguish IPS and CPS activities from the SLU activities:\n1) Multi-modal tracking: The data used in IPS and CPS is multi-modal, not only speech data converted into text but also outcomes of the solving process, like designs, code, etc., physiological signals (e.g., heart rate, sweat, etc.), eye gaze, body posture, and so on [68], [69]. Multi-data collection, integration, and fusion into a coherent representation are required for team tracking and characterization.\n2) Semantic parsing and understanding: IPS and CPS require the identification of ten different types of activ-ities, i.e. activities (2)-(11) in Section II.C, while SLU includes mainly two activities, IR and SF. In contrast to SLU, IPS and CPS must bridge between different description styles, e.g., using sequences of conditions on data features, sequences of processing steps, or function compositions [2], [70], [71]. Connecting related entities at different abstraction levels is difficult as the connections might not be always reducible to the expressed features. A representation is created as part of understanding and then used in solving. Descriptions are of different complexities (e.g., mixtures of description styles) and sizes, and at different levels of abstraction, and can include ambiguities, unknowns, and partial solutions. Semantic parsing must address these issues.\n3) Specific activities: IPS and CPS involve specific activ-ities, which arguably are not present in SLU, like PF and PU. Both activities can produce different represen-tations of the problem requirements, e.g., the priorities associated to the requirements. CPS needs reaching a consensus about the different representations. Moreover, handling ambiguities, unknowns, and incomplete prob-lem descriptions.\n4) Solution elaboration: The problem solving process involves the elaboration of the description in contrast to SLU activities in Section III.A, which do not re-quire elaboration. Elaboration requires insertion of new parameterized structures and connecting the parameters through associations and causality relations. Moreover, problem solving repeatedly performs DC, SA, SMC, and SR, which are less important in dialog systems, in which"}, {"title": "IV. TAXONOMY OF SLU DATASETS", "content": "Figure 1 presents a taxonomy of Spoken Language Understanding (SLU) datasets organized by their primary purpose. The datasets are grouped into four major cate-gories based on their application areas: Task-Oriented Di-alogue, Multi-Speaker Interaction, Text Understanding, and Speech Recognition. Each category is further divided into subcategories, highlighting the specific use cases of the datasets, with examples provided under each subcategory.\n\u2022Task-Oriented Dialogue\nThese datasets are designed to evaluate the performance of Spoken Language Understanding (SLU) algorithms, focusing on tasks such as intent detection, slot filling, and dialogue state tracking. They are typically used in task-specific scenarios, such as air ticket reservations [72],\n\u2022Multi-Speaker Interaction\nThese datasets focus on conversations involving multiple participants, often in collaborative settings. For exam-ple, the AMI Meeting Corpus [93] contains recordings of business meetings annotated for actions, dialogue acts, and participant roles. Unlike task-oriented dialogue datasets, these focus on analyzing group dynamics, inter-actions, and the roles of speakers in conversations.\n\u2022Text Understanding\nThese datasets aim to improve understanding of spoken or written queries, including tasks like entity extraction and question answering. Multi-Domain SLU datasets such as SLURP [89] focus on understanding spoken language across diverse domains, emphasizing the challenge of generalization. Question Answering datasets like Spo-kenSQUAD [84] adapt the popular SQUAD dataset to spoken input, focusing on processing natural spoken queries. Named Entity Recognition (NER) datasets, such as CONLL 2003 [80] and OntoNotes [81], specialize in identifying entities like names of people, organizations, and locations within text, offering precision-focused eval-uation for NER models.\n\u2022Speech Recognition\nThese datasets support tasks like automatic speech recog-nition (ASR), speaker identification, and command recog-nition. General ASR datasets, such as CommonVoice [83] and LibriSpeech [82], provide diverse data across lan-guages and accents to ensure generalizability. Specialized Audio datasets, such as VoxPopuli [91], VoxCeleb [87], and TED-LIUM [92], cater to specific applications like speaker verification or lecture-style speech transcription. Command and Control datasets, such as SpeechCom-mands [90] and Fluent Speech Commands [86], focus on specific spoken commands used in smart devices, emphasizing clarity and conciseness."}, {"title": "A. How Do Existing Data Sets Address SLU Activities", "content": "Existing datasets have played a main role in advancing SLU research by providing annotated examples that mirror real-world interactions. We discussed next how the datasets have contributed to the study of the various SLU tasks:\n1) Intent Recognition (IR) and Slot Filling (SF): IR and SF are two key components in SLU, where the system must understand the user's intention and extract relevant information [94]. Datasets, like ATIS [72] and Snips [73], have been particularly popular in this regard.\nThe ATIS dataset, focused on the travel domain, provides utterances that are labeled with intents such as Flight Search, and slots like origin_city and destination_city. These annotations enable systems to identify the user's intent (e.g., booking a flight) and extract useful details from their input, making it easier to handle travel-related tasks.\nThe Snips dataset spans a broader range of domains, such as music, weather, and smart home control. It includes both intent labels and slot annotations, helping systems learn to recognize a wide variety of intents and extract information in different contexts.\nBy providing these domain-specific examples, both datasets allow models to generalize across different areas, thus sup-porting the development of versatile SLU systems.\n2) Domain Classification (DC): DC is essential for SLU systems to manage different topics or services within a con-versation [95]. Datasets like Google Dialogflow [78] and SGD [79] provide valuable resources for training models to handle multi-domain conversations.\nThe Google Dialogflow dataset, for example, includes utter-ances annotated with domain tags that cover a diverse range of topics, from entertainment to healthcare. This helps systems identify which domain the user's query belongs to, ensuring that the correct response or action is taken.\nSimilarly, SGD (Spoken Language Understanding Dataset) offers a collection of dialogues with domain annotations, en-abling systems to switch seamlessly between different topics.\nThese multi-domain datasets are particularly useful for building virtual assistants and multi-functional chatbots that need to interpret and respond to a wide array of requests in a single conversation.\n3) Dialogue State Tracking (DST): DST is a critical task in multi-turn dialogues, where the system must keep track of the evolving conversation state [96]. Datasets like Mul-tiWOZ [76] and DSTC [75] are designed to support this task by providing annotations that capture the dialogue state across several turns.\nMultiWOZ, for instance, is a large-scale dataset that covers domains such as hotel bookings, restaurant reservations, and public transportation. It annotates each dialogue with infor-mation about user intents, requested slots (e.g., hotel_name, check_in_date), and system actions, helping systems man-age the state of the conversation over multiple interactions.\nLikewise, DSTC (Dialogue State Tracking Challenges) in-cludes datasets that focus on tracking the dialogue state, such as user goals and system responses, which are crucial for en-suring that the system remains contextually aware throughout the conversation.\nThese datasets help SLU models develop the capability to manage long, complex dialogues and ensure that responses are contextually appropriate.\n4) Named Entity Recognition (NER): NER is an essential SLU task that involves identifying and classifying named entities (such as names, locations, and dates) in a given text [97]. Datasets like CoNLL-2003 [80] and OntoNotes [81] serve as benchmarks for general-purpose NER tasks.\nCONLL-2003 provides entity annotations for a wide variety of documents, while OntoNotes offers a more comprehensive dataset that spans multiple text genres, including news articles and conversational speech."}, {"title": "V. QUANTITATIVE CHARACTERIZATION OF THE DATASETS", "content": "The following metrics were used to characterize the compu-tational activities (Section III.B) of IPS and CPS. The datasets used to compute the metrics were enumerated in the Appendix.\nA. Multi-modal tracking\nThe following metrics were used to characterize the multi-ple modalities captured by a dataset: (i) number and kinds of modalities (e.g., text, images, sound, physiological sig-nals, etc.), (ii) expected accuracy in processing a modality, (iii) amount of knowledge communicated through each modal-ity, (iv) relationships between modalities, including the amount of overlaps, knowledge connections, overlaps, complementar-ities, and redundancies, and (iv) difficulty in using the knowl-edge from a modality to form the problem representation.\nDiscussion\n1) Task-Oriented Dialogue: This category relies on both text and sound. Text has high accuracy (90-95%), while"}, {"title": "B. Semantic parsing and understanding:", "content": "The related metrics refer to the following elements: (i) the size of the descriptions (ii) number of abstraction levels, (ii) mixture of description styles, such as describing properties, operations for processing, structure, and expected goal [?], (iii) the connections between entities, like sentences, and the distances of the connections, (iv) the connections between entities at different levels of abstraction, (v) the presence and amount of ambiguities and unknowns, (vi) the characteristics of the context needed in understanding, and (vii) the informa-tion extracted during understanding to build the representation used in solving."}, {"title": "VI. DISCUSSION", "content": "The dataset analysis revealed insight into how different categories of SLU tasks address the various aspects of problem solving. These datasets cover a broad range of metrics related to multi-modal tracking, semantic parsing, solution elabora-tion, reactivity to unexpected situations, and social-emotional dynamics. While the datasets provide a useful foundation for studying problem-solving processes, they also highlight areas where additional data collection is necessary to address specific gaps.\nThe datasets analyzed demonstrate distinct strengths across the following categories:\n\u2022Task-Oriented Dialogue: This category excels in struc-tured workflows and systematic goal tracking. It is well-suited to study intent-based processing, slot filling, and iterative solution refinement. However, its limited adapt-ability to highly dynamic situations may restrict its ap-plicability to more flexible or open-ended problems.\n\u2022Multi-Speaker Interaction: The high adaptability, ex-tensive use of abstraction levels, and focus on discourse structures make this dataset appropriate to study CPS, ambiguity resolution, and social-emotional dynamics. Its complexity, however, requires sophisticated tools for speaker tracking and ambiguity handling, which may pose challenges in modeling and automation.\n\u2022Text Understanding: The structured and straightforward nature of the datasets in this category supports studies of semantic parsing, entity recognition, and syntactic analysis. Its primary limitation lies in the lack of multi-"}, {"title": "VII. CONCLUSIONS", "content": "This report discussed the suitability of existing datasets used to train Machine Learning (ML) models on speech data to build novel ML methods, decision making techniques, and analysis algorithms to address challenges in Collaborative Problem Solving (CPS). A dataset includes the speech record-ings of teams with about four members that talked to each other during CPS. The proposed characterization methodology uses metrics that express cognitive, social, and emotional activities and situations. The presented work analyzed a group of popular datasets developed for Spoken Language Under-standing (SLU), a research area with some similarity to CPS.\nThe analysis of the SLU datasets suggested that new datasets should be created with the following features: they include multi-modal data that capture diverse team interac-tions, offer longitudinal data to help tracking team dynamics over time, incorporate short, ambiguous, and ill-defined speech utterances, and include situations of sudden disruptions and conflicts."}]}