{"title": "PDDLFuse: A Tool for Generating Diverse Planning Domains", "authors": ["Vedant Khandelwal", "Amit Sheth", "Forest Agostinelli"], "abstract": "The variety of real-world challenges requires planning algorithms that can adapt to a broad range of domains. Traditionally, the creation of planning domains has relied heavily on human implementation, which limits the scale and diversity of available domains. While recent advancements have leveraged generative AI technologies such as large language models (LLMs) for domain creation, these efforts have predominantly focused on translating existing domains from natural language descriptions rather than generating novel ones. In contrast, the concept of domain randomization, which has been highly effective in reinforcement learning, enhances performance and generalizability by training on a diverse array of randomized new domains. Inspired by this success, our tool, PDDLFuse, aims to bridge this gap in Planning Domain Definition Language (PDDL). PDDLFuse is designed to generate new, diverse planning domains that can be used to validate new planners or test foundational planning models. We have developed methods to adjust the domain generator's parameters to modulate the difficulty of the domains it generates. This adaptability is crucial as existing domain-independent planners often struggle with more complex problems. Initial tests indicate that PDDLFuse efficiently creates intricate and varied domains, representing a significant advancement over traditional domain generation methods and making a contribution towards planning research.", "sections": [{"title": "Introduction", "content": "Automated planning systems are critical in applications ranging from robotics to software management. These systems depend on well-defined planning domains and problems that describe the environment and define the tasks (Ghallab, Nau, and Traverso 2004). Traditionally, planning domains have been manually created, which restricts the diversity and complexity of the problems these systems can tackle. This limitation affects the robustness and generalizability of planning algorithms when they encounter new or unforeseen domains (Chen, Thi\u00e9baux, and Trevizan 2024). Recent advancements in generative AI, particularly large language models (LLMs), have been used for automating the creation of planning domains. While these technologies have the potential to scale domain creation beyond traditional methods, most applications of LLMs in this area have been limited to translating existing domains from natural language descriptions rather than generating novel and varied domains (Oswald et al. 2024). This replication restricts the ability of planning systems to generalize effectively across a broad set of domains.\nDomain randomization, is proven to enhance performance and generalization in reinforcement learning, involves training agents in varied domains. Successfully applied in fields such as robotic control and locomotion, this method demonstrates that training in diverse settings can significantly improve an agent's ability to adapt to new, unseen domains (Mehta et al. 2020; Ajani, Hur, and Mallipeddi 2023). Inspired by the success of domain randomization in reinforcement learning, which has shown improved adaptability and robustness, we propose applying similar principles within the Planning Domain Definition Language (PDDL).\nPDDLFuse is a tool designed to generate new planning domains by fusing existing ones, rather than merely creating existing domains through translation from natural language descriptions (Oswald et al. 2024; Mahdavi et al. 2024). This approach enhances the diversity of domains available for planning research and supports the development of more adaptable and generalizable planning algorithms. By significantly expanding the range of test domains, PDDLFuse facilitates comprehensive testing and development of planning algorithms, validation of new planners, testing foundational planning models, and exploring previously uncharted domains. Preliminary tests indicate that PDDLFuse efficiently generates complex and diverse domains, representing an advancement over traditional methods and contributing to the field of planning research.\nThe following sections will discuss the background of planning domains, and review related works, describe the methodologies employed, and present experimental results."}, {"title": "Background and Related Works", "content": "This section covers the essentials of planning domains, domain-independent planners, and the role of generative AI in domain reconstruction. We highlight the limitations of current methods. We also explore domain randomization, an approach from reinforcement learning that improves algorithm robustness by training with diverse domains, offering potential benefits for planning systems. Detailed discussion in Supplementary Material."}, {"title": "Planning Domains and Problems", "content": "In the context of automated planning, a planning domain is a structured description of an environment consisting of objects, predicates, and actions that an agent can perform. Formally, a planning domain D is defined by a tuple (O, P, A), where:\n\u2022 O is a finite set of objects that exist within the domain.\n\u2022 P is a finite set of predicates, where each predicate represents a property or relationship among objects (e.g., At (location, package)).\n\u2022 A is a finite set of actions, where each action $a \\in A$ is defined by a pair (pre(a), eff(a)):\n- pre(a), the preconditions of action a, is a set of predicates that must hold true for a to be executed.\n- eff(a), the effects of action a, is a set of predicates that describe the changes in the domain after a is executed.\nA planning problem specifies a particular task within a domain by defining both an initial and a goal state. Formally, a planning problem P is defined by the tuple (D, $s_0$, $s_g$), where:\n\u2022 D is the domain in which the problem is defined.\n\u2022 $s_0$ is the initial state, a set of grounded predicates representing the domain file's state before planning begins.\n\u2022 $s_g$ is the goal state, a set of grounded predicates specifying the desired conditions that define the successful completion of the task."}, {"title": "Domain Reconstruction", "content": "Automating domain creation through translation from natural language has seen progress, though it still faces limitations in fostering diversity and novelty. Oswald et al. (2024) employed LLMs to replicate planning domains from textual descriptions, closely aligning with existing PDDL specifications, but requiring a reference domain for validation restricts its scope to known domains. Similarly, Mahdavi et al. (2024) used an iterative refinement approach with environment feedback to enhance LLM-generated domains, reducing manual effort but focusing primarily on refining rather than creating new domains, limiting scalability. The \"Translate-Infer-Compile\u201d (TIC) tool by Agarwal and Sreepathy (2024) and \u201cAUTOPLANBENCH\" by Steina et al. (2024) advance the translation of natural language into structured PDDL, enhancing accuracy through logic reasoning and LLM interaction, yet they remain confined to reconstructing established domains, rather than diversifying the domain pool essential for generalization in planning."}, {"title": "Generalization in Planning", "content": "Generalization in automated planning is limited by the lack of diverse training domains, as exemplified by those in the International Planning Competition (IPC), leading to weaker inductive biases and models prone to overfitting. Recent approaches using Graph Neural Networks (GNNs) and Large Language Models (LLMs) aim to address this but remain restricted by their narrow domain scope. For instance, the graph representations by Chen, Thi\u00e9baux, and Trevizan (2024) and the GOOSE tool by Chen, Thi\u00e9baux, and Trevizan (2023) show promise in learning domain-independent heuristics, yet face scalability issues and reliance on IPC domains. Similarly, Toyer et al. (2018) employs GNNs to improve plan quality but depends on accessible solvers, limiting real-world applicability. LLMs, even with advanced prompting techniques (Hu et al. 2023; Yao et al. 2023), are constrained by a lack of domain diversity, reducing their effectiveness in novel contexts. Multimodal and code-based models, such as those by Lu et al. (2023); Pallagani et al. (2023); Khandelwal, Sheth, and Agostinelli (2024); Agostinelli, Panta, and Khandelwal (2024), perform well in known distributions but struggle with out-of-distribution domains, highlighting the need for more diverse domains to achieve robust generalization."}, {"title": "Domain Randomization and Generalization in Reinforcement Learning", "content": "Domain randomization is a key technique in reinforcement learning (RL) that is used to improve robustness and generalizability by exposing agents to diverse training domains, thereby improving generalization to unfamiliar domains. Mehta et al. (2020) introduced Active Domain Randomization (ADR), which strategically manipulates challenging environmental parameters to improve policy robustness, particularly in robotic control. Similarly, Ajani, Hur, and Mallipeddi (2023) showed that varying physical properties like surface friction can significantly boost an RL agent's generalization ability. Kang, Chang, and Choi (2024) further refined this with Balanced Domain Randomization (BDR), which focuses training on rare and complex domains to enhance performance under demanding conditions. In non-physical tasks, Koo, Yu, and Lee (2019) applied adversarial domain adaptation to align feature representations across domains, thereby enhancing policy generalization in complex tasks like dialogue systems. These studies demonstrate the power of domain randomization in building resilient AI, aligning with PDDLFuse's goal to generate diverse planning domains to improve generalization in automated planning."}, {"title": "Domain Independent Planners", "content": "Domain-independent planners such as Fast Downward (FD)(Helmert 2006) and LPG (Gerevini and Serina 2002) play a crucial role in the advancement of automated planning technologies. These systems are designed to function across a wide range of problem domains by utilizing heuristics that do not rely on specific domain knowledge. FD converts PDDL tasks into a more manageable internal format and employs powerful heuristics like the Fast-Forward (FF) (Hoffmann and Nebel 2001), which simplifies planning by focusing only on positive action effects, and the landmark-cut (lmcut) (Helmert and Domshlak 2009), which identifies essential milestones within a plan to optimize the search process. LPG, on the other hand, leverages stochastic local search strategies that incrementally refine plans through action-graph and plan-graph techniques, proving highly effective in both propositional and numerical planning contexts (Gerevini and Serina 2002). The use of these planners in research is driven by their ability to efficiently generate solutions in diverse domains, thereby facilitating the development of more robust and adaptable planning systems."}, {"title": "Methods", "content": "This section details the procedures and algorithms developed to fuse existing domains and manipulate domain characteristics to generate new and diverse domains. More details in Supplementary Material."}, {"title": "Domain Generation", "content": "In PDDLFuse, the generation of new planning domains D = (O, P, A) starts by selecting two existing domains and their problem files as bases. An initial step ensures no overlapping predicates or action names exist between the two domains, by systematically renaming the predicates and actions to maintain uniqueness.\nThe actions within the domains are then enhanced using a set of hyperparameters that control modifications to preconditions and effects. These parameters include:\n\u2022 Probability of adding a new predicate to the preconditions (prob_add_pre).\n\u2022 Probability of adding a new effect to the actions (prob_add_eff).\n\u2022 Probability of removing a predicate from the preconditions (prob_rem_pre).\n\u2022 Probability of removing a predicate from the effects (prob_rem_eff).\nThe inclusion of negations through prob_neg, ensuring predicate reversibility revflag and the control over object counts via num_objs provide further flexibility. This process allows for the generation of complex and diverse planning domains, essential for developing robust planning algorithms."}, {"title": "Problem File Generation", "content": "Problem file generation starts with setting the initial state based on num_objs. A sequence of random actions from the generated domain is executed to transition the initial state into a new state, where a subset of true predicates forms the goal state. This process ensures the generated problems are solvable within the domain.\nThis section outlined the systematic approach employed by PDDLFuse to generate new and diverse planning domains, with an emphasis on parametric controls that enables customization. The subsequent sections will discuss the experimental setup for evaluating the effectiveness and utility of these generated domains in planning research."}, {"title": "Results", "content": "This section presents the outcomes of experiments conducted to evaluate PDDLFuse's ability to generate novel planning domains and assess the solvability of these domains by domain-independent planners. We explore the performance of FD and LPG planners across various domain generation parameters, providing insights into their limitations and the complexity of the generated domains. All planners ran with a time limit of 200 seconds per problem instance."}, {"title": "Algorithm 1: Domain & Problem Generation", "content": "Require: Two base domains $D_1 = (O_1, P_1, A_1)$ and $D_2 = (O_2, P_2, A_2)$\nEnsure: No overlapping predicates or actions between $D_1$ and $D_2$\n1: $O \\leftarrow O_1 \\cup O_2$ {Union of objects from both domains}\n2: $P \\leftarrow P_1 \\cup P_2$ {Union of predicates from both domains}\n3: $A \\leftarrow {}$\n4: for each action $a$ in $A_1 \\cup A_2$ do\n5:  Define pre(a) and eff(a) for new A\n6:  if random() < prob_add_pre then\n7:   Add new predicates to pre(a) {Expanding precond}\n8:  end if\n9:  if random() < prob_add_eff then\n10:   Add new effects to eff(a) {Expanding effects}\n11:  end if\n12:  if random() < prob_rem_pre then\n13:   Remove predicates from pre(a) {Simplifying precond}\n14:  end if\n15:  if random() < prob_rem_eff then\n16:   Remove predicates from eff(a) {Simplifying effects}\n17:  end if\n18:  Apply prob_neg to negate added predicates\n19:  $A \\leftarrow A \\cup {a}$ {Incorporating modified action into new domain}\n20: end for\n21: Generate problem P using modified $D_{new} = (O, P, A)$ and num_objs\n22: Execute actions to derive the goal state from the initial state\n23: return $D_{new}, P$ {Output new planning domain and problem}"}, {"title": "Planners and Heuristics Evaluation", "content": "In our planning experiments, we utilized two domain-independent planners: Fast Downward (FD) with FF and lm-cut heuristics, and LPG."}, {"title": "Experimental Setup and Parameters", "content": "For these experiments, we introduced variation within the generated domains using the following parameters:\n\u2022 Prob_add_precond = 0.5\n\u2022 Prob_add_effect = 0.5\n\u2022 Prob_remove_effect = 0.3\n\u2022 Prob_negation_predicate = 0.5\nUsing these parameters, we generated ten domains per depth level. Starting from Gripper and Blocks World as base for depth level 1, subsequent levels used the previous depth's generated domains as base. This setup systematically assessed planner performance across increasing domain complexities. These generated domains are used to evaluate planner solvability across increasing domain depths. We measured the planners' success rates, and path costs. These metrics provided a comprehensive view of planner efficiency and adaptability as domain complexity increased.\nAs shown in Table 1, both FD(FF) and LPG maintain high solvability at lower depth levels, but their performance declines as depth increases. LPG shows robustness across depths, though its effectiveness drops as depth increases, while FD(FF) maintains consistent performance in more complex domains. The recorded path costs further demon-"}, {"title": "Solvability Across Parameter Variations", "content": "We used five base domains-Blocks-World, Gripper, Depot, Grid, and Satellite-to conduct experiments focusing on depth level 1 with 15 objects. Other parameters were systematically varied to examine planner performance under different domain configurations. The parameter pairs used were:\n\u2022 Prob_add_precond and Prob_remove_precond: (0.3, 0.7), (0.5, 0.5), (0.7, 0.3)\n\u2022 Prob_add_effect and Prob_remove_effect: (0.3, 0.7), (0.5, 0.5), (0.7, 0.3)\nAdditionally, we varied the negation probability with values of 0.3, 0.5, and 0.7, enabling predicate reversibility throughout the experiments."}, {"title": "System Configuraiton", "content": "Experiments were conducted on CPU-only nodes, equipped with Intel Xeon Platinum 8480CL processors, featuring two sockets with 56 cores each, totaling 112 cores per node. Each node was allocated 500GB of RAM. For each experiment, 14 cores were utilized, providing approximately 608MB of RAM per experiment with a random seed of 42."}, {"title": "Conclusion and Future Work", "content": "In this work, we presented PDDLFuse, a tool designed to generate diverse and complex planning domains that can be used to train more robust planning foundation models. The generated domains serve as a valuable resource for testing and benchmarking new planning algorithms, pushing the boundaries of current domain-independent planners like Fast Downward and LPG-td. Our experiments demonstrated the tool's ability to generate a wide variety of domains, with results showing that increased domain complexity significantly challenges existing planning systems. This analysis highlights the impact of varied parameter settings on planner performance, underscoring the potential of PDDLFuse to generate complex domains.\nFuture work involves integrating feedback mechanisms to adjust parameters based on planner performance dynamically, which could further refine domain complexity, advance the development of more resilient and adaptable AI planning systems, and further develop a comprehensive, adaptive tool that generates planning domains by adjusting a predefined set of parameters, complexity levels, and target characteristics. This enhanced system would create diverse domains and replicate existing ones by precisely tuning parameters, thereby broadening its applicability. Additionally, it would provide interpretative insights into each domain's structure, improving usability."}, {"title": "Handling Overlapping Predicate and Action Names", "content": "Handling overlapping predicates and action names is crucial for maintaining the integrity and uniqueness of domain definitions when combining two existing domains. Overlapping elements can cause logical conflicts and inaccuracies in domain behavior during planning tasks. This algorithm identifies overlaps and systematically renames the conflicting elements in one domain to prevent ambiguity."}, {"title": "Algorithm 2: Handling Overlapping Names", "content": "Require: Two domains $D_1$ and $D_2$ with potential overlapping predicates and actions.\nEnsure: Unique predicates and actions across $D_1$ and $D_2$.\n1: Initialize set $O_1$ for unique objects from $D_1$.\n2: Initialize set $O_2$ for unique objects from $D_2$.\n3: for each predicate or action in $D_1$ and $D_2$ do\n4:  if exists in both $D_1$ and $D_2$ then\n5:   Rename in $D_2$.\n6:  end if\n7: end for\n8: return Updated $D_1$ and $D_2$ with unique names."}, {"title": "Action Generator Process", "content": "The Action Generator is designed to dynamically produce a sequence of actions based on the specifications of a given domain's initial state. It simulates random actions from the domain's action set, transforming the initial state into a new state that can potentially serve as a goal state for planning problems. The goal state is determined by selecting a subset of predicates active in the reached state, ensuring that there exists a sequence of actions that leads to this state."}, {"title": "Algorithm 3: Action Generator Process", "content": "Require: Generated domain $D = (O, P, A)$, Initial state $S_0$\n1: Initialize current_state $\\leftarrow S_0$\n2: Initialize action_sequence $\\leftarrow[]$\n3: for i = 1 to N do\n4:  Select $a \\in A$ randomly such that preconditions of $a$ are satisfied in current_state\n5:  Apply a to current_state\n6:  Append a to action_sequence\n7:  Update current_state based on the effects of a\n8: end for\n9: Define goal state $S_g$ as a subset of predicates true in current_state\n10: return action_sequence, $S_g$"}, {"title": "Validator Process", "content": "The Validator ensures that the generated domains and problems conform to PDDL 3.1 standards, utilizing a parser to validate the structural and logical correctness of the domain and problem definitions. It checks for consistency in the domain's actions and the feasibility of achieving the problem's goal state from its initial state based on the defined actions."}, {"title": "Algorithm 4: Validation Process", "content": "Require: Domain $D = (O, P, A)$, Problem $P = (D, S_0, S_g)$\n1: Parse $D$ and $P$ using a PDDL 3.1 parser\n2: Check for syntactical correctness of $D$ and $P$\n3: Verify logical consistency: all actions in $A$ must correctly transform predicates from $S_0$ to achieve $S_g$\n4: if all checks pass then\n5:  Return \"Validation Successful\"\n6: else\n7:  Return \"Validation Failed\"\n8: end if"}, {"title": "Results", "content": "In this section, we present the outcomes of our experiments, evaluating the PDDLFuse tool's efficacy in generating complex planning domains and the performance of domain-independent planners across various configurations. We assess the robustness of our validator, analyze planner solvability under different parameter variations, and examine planner performance across increasing domain depths. These results underscore the versatility and challenge of the generated domains, demonstrating the value of PDDLFuse for advancing research in automated planning. Detailed findings are discussed below."}, {"title": "Evaluating the Validator", "content": "To assess the robustness and accuracy of our validator, we conducted evaluations across eight diverse domains, each with 20 problem instances. The problem data was sourced from the study by Chen, Thi\u00e9baux, and Trevizan (2023), which used the Scorpion planner to generate optimal plans for each domain and problem file. This evaluation focused on two primary aspects: (1) verifying that the validator could correctly interpret and check the syntax of both the domain and problem files, and (2) ensuring that it could execute each optimal plan step-by-step to reach the specified goal state."}]}