{"title": "Anatomical Foundation Models for Brain MRIs", "authors": ["Carlo Alberto Barbano", "Matteo Brunello", "Benoit Dufumier", "Marco Grangetto"], "abstract": "Deep Learning (DL) in neuroimaging has become increasingly relevant for de- tecting neurological conditions and neurodegenerative disorders. One of the most predominant biomarkers in neuroimaging is represented by brain age, which has been shown to be a good indicator for different conditions, such as Alzheimer's Disease. Using brain age for pretraining DL models in transfer learning settings has also recently shown promising results, especially when dealing with data scarcity of different conditions. On the other hand, anatomical information of brain MRIs (e.g. cortical thickness) can provide important information for learning good representations that can be transferred to many downstream tasks. In this work, we propose AnatCL, an anatomical foundation model for brain MRIs that i.) leverages anatomical information with a weakly contrastive learning approach and ii.) achieves state-of-the-art performances in many different downstream tasks. To validate our approach we consider 12 different downstream tasks for diagnosis classification, and prediction of 10 different clinical assessment scores.", "sections": [{"title": "1 Introduction", "content": "Magnetic Resonance Imaging (MRI) is the foundation of neuroimaging, providing detailed views of brain structure and function that are crucial for diagnosing and understanding various neurological conditions. However, the complexity and high dimensionality of MRI data present significant challenges for automated analysis. Traditional machine learning methods often require extensive manual annotation, which is both time-consuming and expensive. Recently, contrastive deep learning techniques have emerged as powerful tools for extracting meaningful information from complex data, showing promise in improving the automated analysis of neuroimaging datasets.\nContrastive learning methods, particularly those leveraging supervised contrastive loss functions, have been effective in creating models that learn robust representation spaces. These methods typically utilize metadata, such as patient age, to guide the learning process, with the aim of aligning similar data points (i.e. similar age) and distinguishing dissimilar ones in the representation space. While this approach has yielded promising results, it may fall short of fully capturing the multifaceted information inherent in MRI data and the anatomical complexity of the brain.\nFor this reason, in this paper, we extend the capabilities of existing contrastive learning approaches by incorporating additional anatomical measures into the loss formulation. We propose AnatCL, a contrastive learning framework that builds upon previous works that leverages patient age as proxy metadata [12, 1] to also include information derived from anatomical measures (such as cortical thickness), computed on region of interests (ROIs) of common atlas such as the Desikan-Killiany parcellation [7] Specifically, we propose a modified contrastive learning loss function that integrates patient age with a targeted selection of three anatomical features: Mean Cortical Thickness, Gray"}, {"title": "2 Related Works", "content": "Machine learning on structural brain imaging. Current literature has been mainly devoted to segmentation tasks for brain anatomical data, such as brain tumor segmentation [2] or tissue segmentation [10], in a supervised setting requiring annotated maps. The deep neural network U-Net [25] and its extension nnU-Net [18] were very successful at such tasks. Another body of literature tackled phenotype and clinical prediction tasks from structural imaging, such as age prediction [14], Alzheimer's disease detection [31], cognitive impairment detection, or psychiatric conditions prediction [22, 4]. Current approaches mostly involve traditional machine learning models such as SVM or penalized linear models trained in a supervised fashion to predict the targeted phenotypes. Since most studies only include a few hundred subjects in their datasets, larger models introducing more parameters (such as neural networks) do not necessarily translate into better performance [11, 26, 16], probably because of over-fitting.\nSelf-supervised learning on brain imaging. Self-supervised learning has been popularized by its impressive performance in Natural Language Processing (NLP) using auto-regressive models trained on web-scale text corpus and mainly deployed on generation tasks [8, 3]. Since it does not require a supervised signal for training, it is particularly appealing when large-scale data are available, and the annotation cost is prohibitive. Its applicability on neuroimage data is still unclear and very few studies have tackled this problem so far [17]. [12] demonstrated that contrastive learning integrating subjects meta-data can improve the classification of patients with psychiatric conditions. [29] demonstrated that learning frameworks from NLP, such as sequence-to-sequence autoencoding, causal language modeling, and masked language modeling, can improve mental state decoding from brain activity recorded with functional MRI.\nContrastive Learning on brain imaging Recently, interests in contrastive learning approaches for brain age prediction has risen. Among different works we can identify y-Aware [12] and"}, {"title": "3 Materials and Methods", "content": "3.1 Experimental data\nWe use a collection of T1-weighted MRI scans comprising 7,908 different individuals, for a total of 21,155 images. The experimental data is gathered from different publicly available datasets, and we target 5 different neurological conditions: healthy samples (OpenBHB [13]), Alzheimer's Disease (ADNI [23] and OASIS-3 [20]), schizophrenia (SchizConnect [30]) and Autism Spectrum Disorder (ABIDE I [9]). The overall composition of the cohorts used in this study is presented in Fig. 1B. Tab. 1 provides an overview of all the downstream tasks that we explore in this work.\nOpenBHB OpenBHB is a recently released dataset that aggregates healthy control (HC) samples from many public cohorts (ABIDE 1, ABIDE 2, CoRR, GSP, IXI, Localizer, MPI-Leipzig, NAR, NPC, RBP). Every scan comes from a different subject. We use OpenBHB as pretraining dataset for our method. Besides the structural scans and patients information, OpenBHB also provides 7 anatomical measures according to the Desikan-Kiliani parcellation [7] (cortical thickness mean and std, gray matter volume, surface area, integrated mean, gaussian curvature index and intrinsic curvature index [13]).\nADNI and OASIS-3 We include all phases ADNI-1, ADNI-2, ADNI-GO and ADNI-3 in our study, amounting to 633 HC, 712 MCI and 409 AD patients. For OASIS3 we include 685 patients respectively, containing 88 AD cases.\nSchizConnect We include anatomical MRIs for a total of 383 patients, divided in 180 HC, 102 with schizophrenia (broad), 74 with schizophrenia (strict), 11 schizoaffective patients and 9 with bipolar disorder.\nABIDE I We include anatomical MRIs for a total of 1102 patients, divided in 556 HC, 339 patients with autism, 93 patients with Asperger's Syndrome, and 7 with pervasive developmental disorder not otherwise specified (PDD-NOS).\nClinical assessment scores In addition to predict the above diagnosis, we also consider some relevant clinical assessment included in the data, as reported in Tab. 1. For SchizConnect, we consider the Abormal Involuntary Movement Scale (AIMS) evaluated in three assessments (overall, uppder body, lower body), a Depression score based on the Calgary Scale, Handedness information, and GAIT measuremens with the Simpson-Angus-Scale (SAS). For ABIDE, we consider also handedness and three IQ scores, namely Full Scale IQ (FIQ), Visual IQ (VIQ) and Performance IQ (FIQ) measured with the Wechsler Abbreviated Scale (WASI).\n3.1.1 Data preparation and preprocessing\nAll the images underwent the same standard VBM preprocessing, using CAT12 [15], which includes non-linear registration to the MNI template and gray matter (GM) extraction. The final spatial resolution is 1.5mm isotropic and the images are of size 121 x 145 x 121. The preprocessing is performed using the brainprep package. After preprocessing, we consider in this work modulated gray matter (GM) images, as in [13].\n3.2 Background\nContrastive learning (CL) (either self-supervised as in SimCLR [5] or supervised as in SupCon [19]) leverages discrete labels (i.e., categories) to define positive and negative samples. Starting from a"}, {"title": "3.3 Weakly contrastive learning", "content": "To tackle the issue of continuous labels, weakly contrastive approaches employ the notion of a degree of \"positiveness\u201d between samples. This degree is usually defined by a kernel function $w_i = K(y - y_i)$, where $0 \\leq w_i \\leq 1$ is computed by a Gaussian or a Radial Basis Function (RBF) kernel and $y, y_i$ are the continuous attributes of interest. The goal of weakly contrastive learning is thus to learn a parametric function $f : X \\rightarrow S^d$ that maps samples with a high degree of positiveness ($w_i \\sim 1$) close in the latent space and samples with a low degree ($w_i \\sim 0$) far away from each other. y-Aware [12] proposes to do so by aligning positive samples with a strength proportional to the degree, i.e.:\n$L^{y-aware} = \\sum_{i}\\sum_{j} w_i \\log(\\frac{\\exp(sim(f(x), f(x_i)))}{\\sum_{t=1}^{N} \\exp(sim(f(x), f(x_t)))})$ (1)\nwhere sim is a similarity function (e.g. cosine). A similar approach is also adopted by ExpW [1]. A limitation of this class of approaches is the reliance on one single attribute (age) to determine the alignment strength. They are thus not suited to leverage multiple attributes (e.g. anatomical measurements of the brain). Our proposed approach aims to solve this issue by extending the weakly contrastive formulation to include multiple attributes."}, {"title": "3.4 Proposed method", "content": "In this section, we will discuss our approach to include multiple attributes in a weakly contrastive paradigm."}, {"title": "3.4.1 Anatomical Contrastive Learning with anatomical measures", "content": "We propose a novel formulation for weakly contrastive learning to employ multiple anatomical attributes derived from the MRI scan, that we call AnatCL. The features we consider are derived from the standard Desikan-Kiliany parcellation [7], based on the information available in the OpenBHB dataset (see Sec. 3.1). Among the anatomical measurements, we consider cortical thickness (CT), gray matter volume (GMV), and surface area (SA) [13]. To include these measurements inside AnatCL, we propose two different formulation, global and local, based on how the similarity across two brain scans is computed.\nLocal Descriptor For each of the 68 regions, we obtain a local anatomical descriptor $k \\in \\mathbb{R}^3$ where $k \\in \\{1,..., 68\\}$ composed by the three anatomical measurements considered for that specific region. In order to compute the degree of positiveness $w_i$ across two samples $x$ and $x_i$, given their corresponding anatomical descriptors $\\Psi = \\{\\psi_1, ... \\psi_{68}\\}$ and $\\Psi_i = \\{\\psi_1^i, ... \\psi_{68}^i\\}$ we compute the average cross-region similarity (which we call local descriptor) as:\n$w_i = \\frac{1}{68} \\sum_{k=1}^{68} K(\\gamma(\\psi_k), \\gamma(\\psi_k^i))$ (2)\nwhere K can either be a similarity function or a kernel as in [12], and $\\gamma(x)$ is a normalization that normalizes each component of x to a standard range [0, 1]. In this work, for simplicity, we choose to employ cosine similarity as K.\nGlobal Descriptor Taking a complementary approach, we now consider global anatomy descriptors $w_k \\in \\mathbb{R}^{68}$ for the entire brain with $k \\in \\{1,2,3\\}$, that contain the values across all 68 regions for each anatomical measurement. Similarly to above, in order to compute the degree of positiveness $w_i$ between two samples $x$ and $x_i$ given their global anatomical descriptors $\\Omega = \\{w^1, . . ., w^3\\}$ and $\\Omega_i = \\{\\omega_1^1, . . ., \\omega_i^3\\}$ we compute the cross-measurement similarity (global descriptor) as:\n$w_i = \\frac{1}{3} \\sum_{k=1}^{3} K(\\omega^k, \\omega_i^k)$ (3)\nThis time we do not need to standardize $\\omega^k$ and $\\omega_i^k$ as K is evaluated between features of the same type, so the scale of the value is comparable. Also in this case, for the sake of simplicity, we employ a cosine similarity function for K.\nOur proposed AnatCL loss function is based on y-Aware [12] and integrates the computed $w_i$ (either local or global) as in Eq. 1."}, {"title": "3.4.2 Final objective function", "content": "For training, we also consider the available age information, thus our final loss formulation becomes:\n$L = \\lambda_1 L_{age} + \\lambda_2 L_{AnatCL}$ (4)\nwhere $L_{age}$ is defined as in Eq. 1 and $L_{AnatCL}$ is defined as in Sec. 3.4.1. It is worth noting that the considered anatomical features in AnatCL can be computed directly from the 3D MRI with standard tools such as FreeSurfer, and thus our method does not require any additional label in the dataset."}, {"title": "4 Results", "content": "In this section, we present the results of our proposed method in comparison to existing state-of-the-art approaches in several downstream task."}, {"title": "4.1 Experimental setup", "content": "Our experiments involved pretraining a model using the proposed AnatCL loss on the OpenBHB dataset, followed by testing the resulting model on various downstream tasks across different datasets. The experimental settings for the two loss formulations, local (AnatCL-G3) and global (AnatCL-L3), are identical. We pretrain two ResNet-18 3D models using VBM-preprocessed images and their corresponding Desikan measures with the proposed formulations. The training process employs the Adam optimizer with a learning rate of 0.0001, and a decay rate of 0.9 applied after every 10 epochs. The models are trained with a batch size of 32 for a total of 300 epochs. As values of $\\lambda_1$ and $\\lambda_2$, for simplicity, we use 1. As standard practice in CL approaches [5, 19], the contrastive loss is computed on a fully-connected projection head following the encoder, composed of two layers. To ensure robust evaluation, we perform cross-validation using 5 folds. The results are computed in terms of mean and standard deviation across the 5 folds.\nAfter the pre-training step we evaluate the models by testing their performance with a transfer learning approach: we extract the latent representations generated by the model using only the encoder of the model (i.e., discarding the fully connected head). For each downstream task, we train different linear classifiers on the extracted representations to assess the model's ability to learn meaningful and generalizable features.\nFor comparison with standard approaches, we also implement four different baselines: SimCLR [5] (completely self-supervised) and three supervised baselines: a standard model trained with the L1 loss, y-Aware [12] and ExpW [1] which has shown state-of-the-art results on the OpenBHB challenge [13]. For all these methods, we follow the same experimental setup described above.\nTo run our experiments, we employ a cluster of 4 NVIDIA V100 GPUs, with a single training taking around 10h."}, {"title": "4.2 Brain age prediction", "content": "Preliminary results in terms of brain age prediction and sex classification are evaluated on the OpenBHB dateset. The results are reported in Tab. 2. From the results we conclude that AnatCL is able to match and slightly surpass state-of-the-art performance on brain age prediction. It is worth noting that we do not employ any bias-correction method as in [6, 21]. For sex classification, we do not match ExpW [1], but we improve over the SimCLR and L1 baselines."}, {"title": "4.3 Alzheimer's desease and cognitive impariments", "content": "In Tab. 3 we report results for Alzheimer's Disease (AD) detection on ADNI and OASIS-3. While we do not reach the best results overall, AnatCL can usually improve over the self-supervised baseline (SimCLR) and sometimes over either L1, y-Aware or ExpW."}, {"title": "4.4 Schizophrenia and ASD", "content": "We evaluate downstream performance on SchizConnect for detecting schizophrenia (broad and strict), schizoaffective and bipolar patients. Results are reported in Tab. 4. With AnatCL we achieve state-of-the-art performance on three out of four tasks, denoting that taking anatomical information into account can prove useful for these psychiatric conditions. We also assess detection performance for"}, {"title": "4.5 Cognitive score / assessments", "content": "As final experiments, we turn our attention to predicting clinical assessments score from brain MRIs. To the best of our knowledge, this has not been explored in other works, and it could provide useful insights on the relation between brain anatomy and behavioral phenotypes. The 10 phenotypes considered can be distinguished based on the prediction task: AIMS, depression, handedness and GAIT are classification tasks, while IQ scores (FIQ, VIQ and PIQ) are regression tasks. For handendess, we predict right-handed vs other (left-handed or ambi), for depression we classify between absent vs mild and above, for AIMS we classify between none and minimal vs mild and above, for GAIT between normal vs everything else. For more detailed explanation of the possible value in the considered phenotypes we refer to the official documentation.\nThe results are reported in Tab. 5. While we cannot conclude that any of the analysed method can accurately predict all clinical assessments from MRI scans, AnatCL overall achieves the best results three out of ten times, which is more than any other baseline. Interestingly, AnatCL can better predict the overall AIMS score and patients' handedness, hinting that brain anatomy may be linked with these phenotypes."}, {"title": "5 Limitations, impact and ethical considerations", "content": "We believe that foundation models for neuroimaging may have a considerable impact on accurately diagnosing neurological and psyhicatric diseases. With AnatCL we aim at laying the foundations for this path. Currently, AnatCL is limited towards using a single data modality (structural MRI), considering limited anatomical features (only CT, GMV, and SA) and to a relatively small backbone (ResNet-18). Future research should focus on improving these issues, in order to obtain even more accurate predictions. Altough, deep learning techniques can be used in a variety of contexts, we do not believe that AnatCL inherently poses any ethical issue. Furthermore, all the data employed in this work is publicly available for researchers."}, {"title": "6 Conclusions", "content": "We propose AnatCL, a foundation model based on brain anatomy and trained with a weakly contrastive learning approach. With thorough validation on 10 different downstream tasks, we show that incorporating anatomy information during training can results in more accurate predictions of different neurological and psychiatry conditions, and also partially clinical assessment scores and phenotypes. We release the weights of the trained model for public use at omittedlink, empowering researchers and practitioners worldwide to leverage AnatCL in many different applications."}]}