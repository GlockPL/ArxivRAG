{"title": "GPT as ghostwriter at the White House", "authors": ["Jacques Savoy"], "abstract": "Recently several large language models (LLMs) have demonstrated their capability to generate\na message in response to a user request. Such scientific breakthroughs promote new perspectives\nbut also some fears. The main focus of this study is to analyze the written style of one LLM\ncalled ChatGPT 3.5 by comparing its generated messages with those of the recent US presidents.\nTo achieve this objective, we compare the State of the Union addresses written by Reagan to\nObama with those automatically produced by ChatGPT. We found that ChatGPT tends to\noveruse the lemma \u201cwe\u201d as well as nouns and commas. On the other hand, the generated\nspeeches employ less verbs and include, in mean, longer sentences. Even when imposing a given\nstyle to ChatGPT, the resulting speech remains distinct from messages written by the target\nauthor. Moreover, ChatGPT opts for a neutral tone with mainly positive emotional expressions\nand symbolic terms (e.g., freedom, nation). Finally, we show that the GPT's style exposes\ndistinct features compared to real presidential addresses.", "sections": [{"title": "Introduction", "content": "Based on large language models (LLMs) (Zhoa et al., 2023), the computer is able to provide an\nexplanation to users' queries. These LLMs (e.g., OpenAI's GPT, Meta's Llama, Google's Bard,\nGemini, PaLM or T5) can maintain a dialogue, for example, to help the user in identifying or\nresolving a problem. To generate such text, LLMs have been trained with massive web-text\ndata, newspapers\u00b9 and books corpora. Of course, the value of the generated message depends\non the quantity and quality of those sources as well as various intern choices (neural network\narchitecture, parameters, optimization algorithm, etc.).\nEven if authoring short texts corresponds to the primary LLM application, the solution of other\nproblems have been put forward such as automatic translation (Jiao et al., 2023), solving"}, {"title": "State of the Art", "content": "The domain and applications of stylometry cover a relatively large field from authorship attrib-\nution and profiling (Savoy, 2020), to the detection of plagiarism and fake documents as, for\nexample, in criminology (Olsson, 2018), or even the dating of a document (Kreuz, 2023). In this\ncontext, the main objective of this study is to analyze and compare the style and rhetoric of\npolitical speeches automatically generated by ChatGPT (publicly available since Nov. 2022).\nThe latter is mainly the user interface for dialog with the user while GPT is the underlying engine\nemployed to generate the corresponding reports\u00b2.\nThe LLM technology is grounded on a deep learning architecture (Goodfellow et al., 2016) based\non a sequence of transformers with an attention mechanism (Vaswami et al. 2017). The most\nimportant notion to understand LLM is the following: Given a short sequence of tokens (e.g.,\nwords or punctuation symbols), the computer is able to automatically provide the next one. More\nprecisely, knowing four tokens, the model must first determine the list of possible next tokens to\ncomplete the given sequence (Wolfram, 2023). For example, after the chain \u201cthe president of\nthe\", the computer, based on the training documents, can define a list of the next occurring token\nas {United, Philippines, Senate, US, firm, UK, republic, Ukraine, ...}."}, {"title": "Corpus Overview", "content": "To compare the written style of recent US presidents with speeches generated by machine, we\nasked ChatGPT to generate the State of the Union (SOTU) address for four presidents, namely\nReagan, Clinton, Bush, and Obama. For each US leader, only the SOTU addresses have been\ntaken into consideration. As the proper style of an author cannot be precisely defined per se,\nthis study compares similar texts (SOTU) having the same genre, written in a same time period,\nand discussing similar topics for the same audience.\nTo help the freely available version 3.5 of GPT in its generative process, we provide for each\npresident some written examples but not from any SOTU. Those instances have been extracted\nfrom the Miller website (millercenter.org/president/) containing a selection of the"}, {"title": "Stylometric Analysis", "content": "According to previous studies, the written style could be characterized by certain numbers such\nas the mean word length with higher the mean, higher complexity. As a second measurement,\none can take account of the vocabulary richness measured by the type-token ratio (TTR) (Hart,\n1984). As other values, one can consider the hapax proportion (percentage of words occurring\nonce), the lexical density (Biber et al., 2002) or the percentage of big words (BW) defined as\nwords composed of six letters or more (at least for the English language). For example, one can\nobserve that some terms are easier to understand than others as, for example, between \u201cads\u201d and\n\"advertisings\u201d or \u201cdesks\u201d and \u201cfurniture\u201d. Such a relationship between complexity and word\nlength is clearly established:\n\"One finding of cognitive science is that words have the most powerful effect on our\nminds when they are simple. The technical term is basic level. Basic-level words tend\nto be short. Basic-level words are easily remembered; those messages will be best\nrecalled that use basic-level language.\" (Lakoff & Wehling, 2012, p. 41)\nFor example, L. B. Johnson (presidency: 1963\u20131969) recognized the fear of having a too\ncomplex style by specifying to his ghostwriters: \u201cI want four-letter words, and I want four\nsentences to the paragraph.\u201d (Sherrill, 1967).\nFinally, to reflect the stylistic aspect related to the syntax, one can consider the mean sentence\nlength (MSL), with a higher mean signaling a more detailed argumentation and usually less easy\nto follow."}, {"title": "Characteristic Vocabulary", "content": "As all presidents are speaking with similar terms, the differentiation between them resides in\ntheir frequencies. To detect those differences, one can take account of the characteristic vocab-\nulary belonging to each author. To determine the terms overused (or under-used) by a writer,\nMuller (1992) suggests analyzing the number of term occurrences between a specific author\ncompared to the whole corpus.\nMainly, the underlying idea is the following. For a given term $t_i$, we compute its occurrence\nfrequency both in the set $P_0$ (value denoted $tf_{i,0}$) and in the second part $P_1$ (denoted $tf_{i,1}$). The set\n$P_0$ would be the sample written by the target author, while $P_1$ the rest of the corpus. Thus, for\nthe entire corpus the occurrence frequency of the term $t_i$ becomes $tf_{i,0} + tf_{i,1}$. The total number\nof word tokens in part $P_0$ (or its size) is denoted $n_0$ similarly with $P_1$ and $n_1$. Thus, the size of the\nentire corpus is defined by $n = n_0 + n_1$. For any given term $t_i$ the distribution is assumed to be\nbinomial, with parameters $n_0$ and $p(t_i)$ representing the probability of the term $t_i$ being randomly\nselected from the entire corpus. Based on the maximum likelihood principle, this probability\nwould be estimated as follows:\n$p(t_i) = \\frac{tf_{i,0}+tf_{i,1}}{n}$ (1)\nThrough repeating this drawing $n_0$ times we are able to estimate the expected number of occur-\nrences of term $t_i$ in part $P_0$ using the expression $n_0 \\cdot p(t_i)$. We can then compare this expected\nnumber to the observed number (namely $tf_{i,0}$), where any large differences between these two\nvalues indicate a deviation from the expected behaviour. To obtain a more precise definition of\nlarge we account for variance in the underlying binomial process (defined as $n_0 \\cdot p(t_i) \\cdot (1-p(t_i))$).\nEquation 2 defines the final standardized Z score (or standard normal distribution N(0,1)) for\nterm $t_i$, using the partition $P_0$ and $P_1$:\n$Z score(t_{i,o}) = \\frac{tf_{i,o}-n_0p(t_i)}{\\sqrt{n_0 \\cdot p(t_i) \\cdot (1-p(t_i))}}$ (2)\nFor each selected term, we apply this procedure to weight its specificity according to the under-\nlying text excerpt $P_0$. Based on the Z score value, we then verify whether this term is used"}, {"title": "Rhetorical and Topical Analysis", "content": "As leaders tend to reuse the same words, we can hypothesize that some presidents will talk more\non some topics, or using some rhetorical forms, more often than others. To analyze such regular\nusage of some expressions, one can regroup related semantical words under a given tag. For\nexample, in this study, the category Symbolism (Hart et al., 2013) contains terms related to the\ncountry (e.g., nation, America), ideology (e.g., democracy, freedom, peace), or generally, polit-\nical concepts and institutions (e.g., law, government). Under Tenacity (e.g., was, is, will, etc.),\none can study the absolute confidence of the author's declaration or claim (Hart, 1984) while the\nBlame category includes terms such as angry, deceptive, incompetent, etc. In this study, words\nbelonging to the Achieve tag (e.g., first, plan, win, ...) form another dedicated category.\nGrounded on such wordlists, Hart (1984) portrays the rhetorical and stylistic differences between\nthe US presidents from Truman to Reagan. In a second study, Hart et al. (2013) exposed the\nstylistic changes from G.W. Bush to Obama as well as some features associated with Trump's\npresidency (Hart, 2020). Recently, Hart (2023) exposed the change in style and eloquence of\nUS presidents and politicians during the last century.\nAs an alternative, one can adopt the LIWC (Linguistic Inquiry & Word Count) system (Tausczik\n& Pennebaker, 2010) organizing expressions under syntactical, emotional or psychological cat-\negories. These classes may match grammatical categories (e.g., first person singular denoted by\nSelf, see Table 3), broader ones (e.g., verbs) as well as specific ones (verbs in the past tense,\nauxiliary verbs). On the semantics level, the LIWC system defines positive emotions (Posemo)\n(e.g., happy, hope, peace), negative ones (Negemo) (e.g., fear, blam*8), or terms related to Hu-\nmans (e.g., family, woman, child*)."}, {"title": "Intertextual Distance", "content": "To evaluate the similarity between a pair of texts, Labb\u00e9 (2007) proposed an intertextual distance\nbased on the entire vocabulary. The computation of this measure between Text A and Text B is\ndefined according to Equation 3 where $n_A$ indicates the length of Text A (in number of words),\nand $tf_{i, A}$ denotes the absolute frequency of the ith term (for i = 1, 2, ..., m). The value m represents\nthe vocabulary length. Usually both texts do not have the same length, so let us assume that Text\nB is the longer. To reduce the longer text to the size of the smaller, each of the term frequencies\n(in our case $tf_{i,B}$) is multiplied by the ratio of the two text lengths, as indicated in the second part\nof Equation 3.\n$D(A, B) = \\sum_{i=1}^{m} |tf_{i,A} - tf_{i,B}| / (2 \\cdot n_A)$ with $tf_{u,B} = tf_{i,B} n_A/n_B$ (3)\nThis formulation returns a value between 0 and 1 depending on the lexical overlap between two\ntexts. When two documents are identical, the distance is 0. The largest distance of 1 would\nappear when the two speeches have nothing in common (e.g., one written in Chinese and the\nother in English). Between these two limits, the distance value depends on the number of terms\nappearing in both speeches, and their occurrence frequencies. Even if this computation can take\naccount for different text lengths, it is reasonable to limit the difference to eight times the\nsmallest.\nBased on this measure, one can compute the intertextual distance between the six US presidents\nand messages written by GPT. For four presidents, we subdivide their speeches according to\ntheir two terms in office. For example, Obama's speeches are subdivided into \u201cObamaA\u201d (his\nfirst term in the White House) and \u201cObamaB\u201d (last four years). In addition, the GPT speeches\nhave also been split according to the two terms."}, {"title": "Conclusion", "content": "The various experiments performed in this study demonstrate that GPT can generate political\nspeeches sharing similarities with real State of the Union addresses. For example, based on\nTable 2, the top ten most frequent words are the same between GPT versions and true speeches.\nMoreover, this generative system recognizes the importance of the pronoun \u201cwe\u201d (see Table 2)\nalso occurring with a high frequency under many leaders in power. This stylistic facet could\nalso be viewed as a clear sign of possible close similarity with presidents (or prime ministers).\nHowever, when analyzing the mean sentence length (MSL), GPT opts for longer constructions\n(MSL: 22.62) than the US presidents (e.g., 19.71) (see Table 4). GPT's language complexity is\ntherefore higher and this aspect is increased by considering both the presence of longer words\n(mean word length of 4.9 vs. 4.39 for the mean presidential addresses) and a higher percentage\nof big words (BW: 37.4% compared to 27.7%).\nTo provide a better explanation, Table 5 highlights the POS distribution difference between texts\nwritten by a computer and those authored by humans. One can observe that GPT favors noun-\nphrases (nouns, articles, prepositions) and does not anchor its argumentation in space, time or\nwith many names. In addition, Table 7 indicates that GPT's tone is clearly positive avoiding\nnegative expressions. Moreover, GPT includes many references to political institutions and\nsymbols (mainly with the term \u201cnation\u201d or \u201cAmerica\u201d).\nAs a result, the overall GPT writing style can be characterized by a didactic and neutral tone.\nOne can add that the global impression is that of reading a report without real pitch. Many\npersonal pronouns are missing (you, s/he, they) (see Table 3) and the presentation inclines to\nstay at a descriptive level, without taking any divisive position (see Table 6). Moreover, GPT\navoids specific examples and never employs an argument that could cause clear disagreements\nbetween people.\nUsing an intertextual distance measure computed according to the whole vocabulary, a overall\npicture indicates that GPT addresses differ from the real ones (see Figure 1). True ghostwriters\nemployed more distinct stylistic and rhetorical modus operandi than GPT. On the other hand,\nwhen asking GPT to write according to the style of a given president, the computer is able to\nproduce allocutions that differ from one leader to the next (see Figure 1).\nFinally, we need to mention that GPT is not the sole LLM system or a final product. Such models\nwill evolve over time. Thus, with improvements allowing the system to include more personal\npronouns of the second or third person, together with the inclusion of more names, or geograph-\nical anchors, GPT will generate speeches closer to real presidential addresses."}]}