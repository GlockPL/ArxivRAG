{"title": "Here's Charlie! Realising the Semantic Web vision of Agents in the age of LLMs", "authors": ["Wright, Jesse"], "abstract": "This paper presents our research towards a near-term future in which legal entities, such as individuals and organisations can entrust semi-autonomous AI-driven agents to carry out online interactions on their behalf. The author's research concerns the development of semi-autonomous Web agents, which consult users if and only if the system does not have sufficient context or confidence to proceed working autonomously. This creates a user-agent dialogue that allows the user to teach the agent about the information sources they trust, their data-sharing preferences, and their decision-making preferences. Ultimately, this enables the user to maximise control over their data and decisions while retaining the convenience of using agents, including those driven by LLMs.\nIn view of developing near-term solutions, the research seeks to answer the question: \"How do we build a trustworthy and reliable network of semi-autonomous agents which represent individuals and organisations on the Web?\". After identifying key requirements, the paper presents a demo for a sample use case of a generic personal assistant. This is implemented using (Notation3) rules to enforce safety guarantees around belief, data sharing and data usage and LLMs to allow natural language interaction with users and serendipitous dialogues between software agents.", "sections": [{"title": "1. Introduction", "content": "There exists a substantial body of research on communication protocols for multi-agent systems, and it is reflected in the vision of the Semantic Web itself [1, 2, 3] as shown by Charlie, the \"AI that works for you\u201d. Yet, the 2006 lamentation that \u201c[b]ecause we haven't yet delivered large-scale,\nagent-based mediation, some commentators argue that the Semantic Web has failed\" [4] still rings true today. The growing use of LLMs raises a key challenge in building Trustworthy and Reliable Web Agents [5, 6]. This is heightened by growing interest among LLM researchers in building dialogues between multiple LLMs [7, 8]. Moreover, recent research indicates the strong potential of the Semantic Web to complement emerging LLM technologies [9]. For example, the use of Retrieval Augmented Generation (RAG) with Knowledge Graphs has shown to be effective in grounding LLM queries [10]. The universal semantics and proof mechanisms of the Semantic Web stack are therefore pertinent to the successful development of semi-autonomous Web agents using LLMs."}, {"title": "2. Design Requirements", "content": "We identify the following non-functional requirements for an agent communication protocol.\nIt must be possible for semi-autonomous agents to:\n1. Identify legal entities, such as individuals or organisations, on the Web [11] so they can be referenced.\n2. Deterministically discover other agents representing an entity from their Web identity [11]. This does not require all agents to be publicly advertised; some may be discovered from links to protected documents.\n3. Describe, and agree to, any usage controls [12, 13, 14] associated with data they exchange. This allows sharing of protected data while articulating the recipient's legal or moral obligations [15].\n4. Describe the origin and provenance of data they exchange. In an open world of agents that can \"say anything about anything,\u201d systems can identify which external claims to believe for a given task, based on the agent's internal trust model.\n5. Unambiguously describe ground truths they send, and agreements they make, using a formal representation. Consider the case where an individual's agent purchases a flight from an airline's agent. Structured ground truths eliminate an LLM's risk of hallucination or misinterpretation of key information, such as the flight time (\u201c10 o'clock\u201d could be 22:00 or 10:00). As agents represent entities in binding agreements, this approach also reduces the risk of legal disputes by limiting the subjectivity of agreed terms and thus the ability to reinterpret or rescind them [16]. Furthermore, agents can implement rule-based internal safeguards, such as user-defined daily spending limits. Truly generic agents may generate and communicate structured ontologies when encountering new tasks. In many cases we expect LLM-supported ontology construction [17] to facilitate generation; however, research is required to understand how (1) agents can align on conceptual models for use and (2) how human oversight can be maintained without disrupting user experience.\n6. Contextualise a task which may be ambiguous or poorly defined, such that interacting agents can introduce new solution spaces or negotiating actors in a serendipitous manner."}, {"title": "3. Sample Use-Case and Implementation", "content": "We implemented the following flow where agents act as personal assistants for individual users:\n1. Jun types into a chat \"Schedule a meeting with Nigel next week\";\n2. Jun's agent identifies data to be shared with Nigel and requests relevant sharing permissions from Jun (where not already obtained);\n3. Nigel's agent receives a request from Jun;\n4. Nigel is prompted to confirm that he believes Jun is an authoritative source of truth for her calendar (where not already obtained);\n5. Nigels agent proposes a meeting time to Nigel; and\n6. the meeting is proposed to Jun's agent and automatically confirmed."}, {"title": "4. Conclusion and Future Research", "content": "We have implemented a generic personal assistant that communicates using a protocol satisfying the requirements of Section 2. Future work will make the design requirements more rigorous by (1) gathering requirements for personal agents through user studies, and (2) engaging with industry to develop specialised agents, including product sales agents. Concurrently, we shall formalise the vocabularies for exchanging provenance and terms of use between agents and modelling trust and data policies within agents, extending those vocabularies discussed in Section 3. Once these vocabularies mature, we will develop reasoning specifications to mediate between the internal representations and exchanged metadata. This enables agents to negotiate to obtain sufficient provenance to believe claims, and find agreeable data terms of use between agents - whilst concurrently updating their internal models via user interaction."}]}