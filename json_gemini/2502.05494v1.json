{"title": "Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection", "authors": ["Ya Zhou", "Yujie Yang", "Jianhuang Gan", "Xiangjie Li", "Jing Yuan", "Wei Zhao"], "abstract": "Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing cardiovascular conditions, yet anomaly detection in ECG signals remains challenging due to their inherent complexity and variability. We propose Multi-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel end-to-end framework that effectively captures both global and local dependencies in ECG data. Unlike state-of-the-art methods that rely on heartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for such pre-processing steps, enhancing its suitability for clinical deployment. MMAE-ECG partitions ECG signals into non-overlapping segments, with each segment assigned learnable positional embeddings. A novel multi-scale masking strategy and multi-scale attention mechanism, along with distinct positional embeddings, enable a lightweight Transformer encoder to effectively capture both local and global dependencies. The masked segments are then reconstructed using a single-layer Transformer block, with an aggregation strategy employed during inference to refine the outputs. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art approaches while significantly reducing computational complexity-approximately 1/78 of the floating-point operations (FLOPs) required for inference. Ablation studies further validate the effectiveness of each component, highlighting the potential of multi-scale masked autoencoders for anomaly detection.", "sections": [{"title": "Introduction", "content": "Electrocardiograms (ECG) are widely used in clinical practice as an affordable and non-invasive tool for diagnosing cardiovascular conditions (Somani et al., 2021). Early detection of anomalies in ECG signals plays a crucial role in identifying cardiovascular diseases. Traditional automatic ECG analysis algorithms, based on supervised learning, typically require large, labeled datasets for training (Ribeiro et al., 2020). While recent advances in self-supervised learning have alleviated the need for extensive labeled data, these methods still require labeled datasets for fine-tuning (Zhou et al., 2023). Given the diversity and rarity of cardiac diseases (Jiang et al., 2024), such approaches may struggle to detect new abnormal conditions that were not present in the training data. In contrast, anomaly detection, which relies solely on normal healthy data for training, has the potential to identify previously unseen anomalies and mitigate the risk of missing rare cardiac conditions.\nAnomaly detection has been widely applied to time-series data analysis, particularly in domains such as economics, manufacturing, and healthcare (Zamanzadeh Darban et al., 2024). However, its application to ECG signal analysis remains relatively underexplored (Jiang et al., 2023). ECG anomaly detection poses unique challenges due to inter-individual variability and inter-sample variability, as well as the complex nature of anomalies, which can manifest in both global rhythm patterns and localized morphological features, further complicating accurate detection and generalization (Liu et al., 2022; Jiang et al., 2023). To address these challenges, existing methods such as BeatGAN (Liu et al., 2022), a generative adversarial network designed for heartbeat reconstruction, have demonstrated promise in capturing local morphological features of ECG signals. Similarly, a recently proposed multi-scale approach has achieved state-of-the-art performance on the PTB-XL detection and localization benchmark (Jiang et al., 2023), highlighting its ability to model both global and local features. Despite these advancements, most current methods rely on R-peak detection or heartbeat segmentation, which introduces additional complexity and makes them highly sensitive to noise and irregularities in the data. This reliance limits their applicability in real-world clinical settings, where reliable R-peak identification may not always be feasible, particularly in noisy or pathological ECG recordings. Consequently, there is a critical need for a new model that can effectively capture both global and local features of ECG signals without depending on R-peak detection, ensuring greater robustness and practicality in clinical applications.\nMasked Autoencoders (MAE, He et al., 2022) have emerged as a powerful self-supervised representation learning technique, excelling in tasks such as image and time-series analysis (He et al., 2022; Zhou et al., 2023). While traditional autoencoders are widely regarded as effective for anomaly detection, prior research indicates that MAE may underperform in unsupervised anomaly detection tasks (Reiss et al., 2022). The self-attention mechanism in MAE enables it to focus on important input regions, making it adept at capturing global patterns (Vaswani et al., 2017). However, anomaly detection tasks, particularly for ECG signals, require not only capturing global patterns but also identifying subtle, localized features essential for accurate diagnosis. These limitations underscore the necessity of adapting MAE to effectively extract both global and local features simultaneously, enabling it to address the specific requirements of ECG anomaly detection.\nTo overcome these challenges, we propose a novel multi-scale MAE framework for ECG anomaly detection, referred to as MMAE-ECG, which eliminates the need for R-peak detection or heartbeat segmentation. Our approach leverages a Transformer-based encoder-decoder"}, {"title": "Related work", "content": "Anomaly detection in time series data has attracted significant attention in recent years due to its diverse applications in domains such as economics, manufacturing, and healthcare (Zamanzadeh Darban et al., 2024). Existing approaches can be broadly classified into traditional machine learning-based methods (Salem et al., 2014; Boniol et al., 2021; Yaacob et al., 2010) and deep learning-based methods (Hundman et al., 2018; Zong et al., 2018; Su et al., 2019; Tuli et al., 2022; Xu et al., 2022; Zheng et al., 2022; Liu et al., 2022). Deep learning-based methods have demonstrated significant advantages over traditional approaches, achieving superior performance in a variety of real-world time series anomaly detection tasks (Zamanzadeh Darban et al., 2024). These methods leverage the ability of neural networks to model complex temporal dependencies and capture non-linear patterns inherent in time series data. In this work, we focus on deep learning-based methods."}, {"title": "ECG Anomaly Detection", "content": "The diversity and rarity of cardiac diseases, coupled with the high cost of collecting diverse ECG abnormalities, present significant challenges to conventional multi-label classification methods. In contrast, anomaly detection methods, which rely exclusively on normal data for training, offer the potential to identify previously unseen anomalies and reduce the risk of missing rare cardiac conditions. However, ECG anomaly detection remains particularly challenging due to substantial inter-individual and inter-sample variability, as well as the intricate nature of anomalies, which can manifest as both global rhythm disturbances and localized morphological irregularities (Liu et al., 2022; Jiang et al., 2023). To address these issues, generative adversarial network (GAN)-based methods have been explored, such as BeatGAN (Liu et al., 2022), which demonstrates strong capabilities in capturing local morphological features. Similarly, approaches like Qin et al. (2023) and Wang et al. (2023b) leverage GANs to process ECG signals. For jointly modeling local and global ECG patterns, Jiang et al. (2023) proposed a multi-scale framework that achieved state-of-the-art results on the PTB-XL detection and localization benchmark (Wagner et al., 2020; Jiang et al., 2023). More recently, Bui et al. (2024) proposed a model that integrates both time-series and time-frequency representations of ECG signals while significantly reducing trainable parameters compared to previous methods. Despite these advancements, most approaches rely on R-peak detection or heartbeat segmentation, which introduces additional complexity and renders them highly sensitive to noise and irregularities, limiting their practicality in real-world clinical settings. To overcome these limitations, our proposed method eliminates the dependence on R-peak detection and heartbeat segmentation. Furthermore, it is lightweight, requiring fewer trainable parameters than current state-of-the-art algorithms, offering significant advantages in efficiency and inference speed."}, {"title": "Masked Autoencoders", "content": "In recent years, the focus of deep learning research has shifted from developing increasingly complex models to addressing the challenges of data scarcity (Zhang et al., 2023). Masked Autoencoders (MAE, He et al., 2022) have emerged as a powerful self-supervised representation learning framework, demonstrating remarkable success in various visual tasks and gaining significant attention. Recently, efforts have been made to adapt MAE for ECG classification (Zhang et al., 2022; Yang et al., 2022; Sawano et al., 2022; Wang et al., 2023a; Zhou et al., 2023). Among these, Zhou et al. (2023) proposed an MAE-based multi-label ECG classification approach, achieving notable performance improvements. However, the application of MAE to anomaly detection remains limited. For instance, Reiss et al. (2022) observed that MAE may underperform in unsupervised anomaly detection tasks for images. While the self-attention mechanism inherent in MAE enables it to capture global patterns effectively (Vaswani et al., 2017), anomaly detection tasks, particularly for ECG signals, require not only modeling global features but also detecting subtle and localized anomalies critical for accurate diagnosis. To address these challenges, we propose a novel multi-scale MAE-based framework specifically designed for ECG anomaly detection."}, {"title": "Methodology", "content": "Our proposed framework consists of four key components: (1) multi-scale masking, (2) multi-scale cross-attention encoding, (3) multi-scale reconstruction, and (4) anomaly score aggregation. An overview of the framework is illustrated in Figure 1. In the following, we provide a detailed explanation of each component."}, {"title": "Multi-scale Masking", "content": "Let a multi-lead ECG signal be denoted as $X# = (X_{k,q}) \\in R^{K\\times Q}$, where K represents the number of leads, and Q is the length of the ECG signal. Following Zhou et al. (2023), we partition the ECG signal X along the time dimension into a sequence of non-overlapping segments as follows:\n$U := {X_1,\\ldots,\\ldots, X_T}$,\nwhere T is the total number of segments. Each segment $X_t = (X_{k,q}^t) \\in R^{K\\times (Q/T)}$ represents a subset of the original signal, with $X_{k,q}^t = X_{k,{(t-1)\\cdot Q/T+q}}$ for $t = 1,...,T, k = 1, ...,K, and q = 1, ..., Q/T$.\nNext, we select multiple consecutive segments from U to construct a sequence of local regions $\\nu_{w_1},\\ldots,\\nu_{w_\\upsilon}$, where each local region is defined as:\n$\\nu_w := {X_{w+1},\\cdots, X_{w+\\delta}}$,\nfor w = w1,..., w, and $0 \\leq w_1 < w_2 < ... < w_\\upsilon < T - \\delta$, where \u03b4 is the predefined length of the local region."}, {"title": "Multi-scale Cross-attention Encoding", "content": "During training, for each batch, we randomly select w $\\in$ {$w_1$,..., $w_\\upsilon$ } and separately apply masking to the elements in U and $\\nu^w$. Specifically, given a masking ratio \u03b8, we uniformly sample S := min{max{$[T\\theta]$,1},T \u2212 1} segments from U, and R := min{max{$[\\delta\\theta]$, 1}, \u03b4 \u2212 1} segments from $V^w$, which are then masked. For notational simplicity, we denote the masked segments as:\n$U_{mask} = {X_{j_1},\\ldots, X_{j_{S'}}}$\nand\n$\\nu^w_{mask} = {X_{j_{w,1}},\\ldots,X_{j_{w,R'}} }$,\nwhere $j_{s,s} = 1,...,S'$ and $j_{w,r,r} = 1,..., R'$ are randomly chosen from the index sets {1,...,T} and {w + 1, . . ., w + \u03b4}, respectively.\nSimilarly, the unmasked segments are denoted as:\n$U_{unmask} = {X_{i_1},\\ldots,X_{i_S}}$\nand\n$\\nu^w_{unmask} = {X_{i_{w,1}},\\ldots, X_{i_{w,R}}}$,\nwhere $i_{s, s} = 1,..., S$ and $i_{w,r, r} = 1, ..., R$ represent the indices of the unmasked segments. Using these notations, we can express the total set of segments as:\n$U = U_{unmask} \\cup U_{mask}$, with $U_{unmask} \\cap U_{mask} = \\emptyset$,\nand\n$\\nu^w = \\nu^w_{unmask} \\cup \\nu^w_{mask}$, with $\\nu^w_{unmask} \\cap \\nu^w_{mask} = \\emptyset$.\nHere, $U_{unmask}$ and $\\nu^w_{unmask}$ are fed into the encoder to achieve multi-scale cross-attention, while $U_{mask}$ and $\\nu^w_{mask}$ serve as the reconstruction targets.\nWe introduce a self-attention mechanism to model the relationships between global and local features. To achieve this, we first concatenate the unmasked elements from $U_{unmask}$ and $\\nu^w_{unmask}$. To preserve sequence order information, we adopt the approach in Zhou et al. (2023), using learnable positional embeddings. However, applying standard positional embeddings without distinguishing between local and global features could lead to the model overlooking their positional differences. To address this, we introduce distinct positional embeddings for local and global features, enabling the model to better capture and differentiate the unique characteristics of each feature set.\nWe now describe the encoding module in detail. Denote the layer normalization (Ba et al., 2016), multi-headed self-attention, and multi-layer perceptron (MLP) blocks, as introduced in Dosovitskiy et al. (2020), by LN(\u00b7), MSA(\u00b7), and MLP(\u00b7), respectively. For simplicity, let $x_{i_s}^T$ and $x_{i_{w,r}}^T \\in R^{KQ/T}$ represent the vectorized forms of $X_{i_s}$ for $s = 1,..., S$ and $X_{i_{w,r}}$ for $r = 1,..., R$. Let D denote the latent vector size. Define the linear projection matrix E$\\in R^{(KQ/T)\\times D}$, the auxiliary token $x_{aux} \\in R^D$, and the learnable positional embedding vector $e_{pos} = (e_0, e_1,\\ldots, e_T, e_{T+1},\\ldots, e_{T+\\delta})^T \\in R^{D(T+\\delta+1)}$. Here, $e_t \\in R^D$, t = 0,1,..., T are used to preserve the sequential order information for global features, while $e_{T+t} \\in R^D$, t = 1,..., \u03b4 are employed to encode local features."}, {"title": "Multi-Scale Reconstruction", "content": "Only the unmasked segments from U and $V^w$ are passed through the model. The input representation is defined as:\n$Z_0 = [x_{aux}; x_{i_1} E; \u00b7\u00b7\u00b7 ; x_{i_S} E; x_{i_{w,1}}E; \u00b7\u00b7\u00b7 ; x_{i_{w.R}}E] + [e_0; e_{i_1};\u00b7\u00b7\u00b7 ; e_{i_S}; e_{T+i_{w,1}}; \u00b7\u00b7\u00b7 ; e_{T+i_{w,R}}]$,\nwhere $x_{i_s} E$ and $e_{i_s}$ denote the projections of the unmasked global segments and their corresponding positional embeddings, and $x_{i_{w,r}}E$ and $e_{T+i_{w,r}}$ represent the projections of the unmasked local segments along with their respective embeddings.\nThe encoding process consists of multiple layers of self-attention and MLP blocks:\n$z_l = MSA(LN(z_{l-1})) + z_{l-1}, l = 1, ..., L,$\n$Z_l = MLP(LN(z'_l)) + z'_l, l = 1, ..., L,$\nwhere L denotes the number of transformer blocks.\nFinally, the output of the encoder is given by:\n$Z_L = [z_L^a; z_{i_1}^L;\\ldots; z_{i_S}^L; z_{i_{w,1}}^L;\\ldots; z_{i_{w,R}}^L]$\nwhere $z_L^a) \\in R^D$ represents the encoded auxiliary token, $z_{i_s}^L \\in R^D$ are the encoded unmasked global segments, and $z_{i_{w,r}}^L \\in R^D$ are the encoded unmasked local segments. These encoded representations are subsequently used to reconstruct the global and local features, respectively.\nIn this section, we present the multi-scale reconstruction strategy that employs a Transformer-based decoder. This decoder helps encourage the encoder to learn meaningful wave shape features. Specifically, we adopt a one-layer Transformer decoder. Let D' denote the latent vector size. We define the learnable components as follows: $E' \\in R^{D\\times D'}, E_0 \\in R^{D'\\times (KQ/T)}, e_m \\in R^{D'}$, and the positional embeddings $e'_{pos} = (e_1,\\ldots, e_T, e_{T+1}, e_{T+\\delta}) \\in R^{(T+\\delta)D'}$. Here, $e'_t \\in R^{D'}$ for t = 1,...,T corresponds to the positional embeddings for global features, and $e'_{T+t} \\in R^{D'}$ for t = 1,..., \u03b4 serves as the positional embeddings for local features. Additionally, $e_m$ represents the embeddings for the masked segments.\nThe decoder can be formulated as follows:\n$\\tilde{Z}_0 = [z_{i_1}^L E';\\ldots; z_{i_S}^L E'; z_{i_{w,1}}^L E';\\ldots; z_{i_{w,R}}^L E'; e_m;\\ldots; e_m]$\n$\\tilde{Z}_1 = MSA(LN(\\tilde{Z}_0)) + \\tilde{Z}_0,$\n$\\tilde{Z}_1 = MLP(LN(\\tilde{Z}_1)) + \\tilde{Z}_1$.\nHere, $\\tilde{Z}_1$ is given by\n$\\tilde{Z}_1 = [\\tilde{z}_{i_1};\\ldots; \\tilde{z}_{i_S};\\tilde{z}_{i_{w,1}};\\ldots; \\tilde{z}_{i_{w,R}};\\tilde{z}_{j_1};\\ldots; \\tilde{z}_{j_S};\\tilde{z}_{j_{w,1}};\\ldots; \\tilde{z}_{j_{w,R}}]$\nwhere each $(\\tilde{z}_{i_s})^T, (\\tilde{z}_{i_{s'}})^T, (\\tilde{z}_{i_{w,r}})^T, (\\tilde{z}_{i_{w,r'}})^T \\in R^{D'}$ for s = 1,..., S, s' = 1,...,S', r = 1,..., R, and r' = 1,..., R'. The segments $\\tilde{z}_{i_s}$ and $\\tilde{z}_{i_{w,r}}$ are used to reconstruct the global and local masked segments, respectively."}, {"title": "Anomaly Score Aggregation", "content": "The decoder outputs are obtained by:\n$\\hat{x}_{j_s} = \\tilde{z}_{j_s}E_0, s' = 1, ..., S',$\nand\n$\\hat{x}_{j_{w,r}} = \\tilde{z}_{j_{w,r}}E_0, r' = 1,..., R'$.\nDuring training, the objective is to reconstruct the normalized values of the masked global and local segments. We define the reconstruction loss for the global and local features as:\n$I_{global} = \\sum_{s'=1}^{S'} ||\\hat{x}_{j_s} - f(x_{j_s}) ||_2^2,$\nand\n$I_{local} = \\sum_{r'=1}^{R'} ||\\hat{x}_{j_{w,r}} - f(x_{j_{w,r}}) ||_2^2,$\nwhere $\\hat{x}_{j_s}$ and $\\hat{x}_{j_{w,r}} \\in R^{QW/T}$ are the vectorized forms of the global and local segments $X_{j_s}$ and $X_{j_{w,r}}$, and f: $R^{QW/T} \\rightarrow R^{QW/T}$ is a predefined per-segment normalization function as specified in Zhou et al. (2023). The final loss function is then the sum of the global and local reconstruction losses:\n$\\mathcal{L} = I_{global} + I_{local}^\\omega$.\nIn the anomaly detection framework, each test sample $X#$ undergoes a sequence of forward passes, where the masking segments are determined randomly in each pass. To ensure that segments within the local region are reconstructed with high probability, we evaluate the test sample through H independent forward passes. Here, H is a predefined constant, which ensures that a segment is masked with the probability:\n$1 - (1-\\theta)^R$,\nwhere R represents the number of masked segments and d is the total number of segments.\nTo further improve reconstruction accuracy, we leverage multi-scale cross-attention to cover all local regions, including $\\nu^{w_1},\\ldots ,\\nu^{w_\\upsilon}$. For each local region $\\nu^{w_i}$ and each forward pass h, we denote the corresponding reconstruction loss as $I_{wish}^{local}$ for i = 1,..., \u03c5 and h = 1,...,H. Additionally, since the global features may also vary across different passes and regions, we use $I_{wish}^{global}$ to denote the loss associated with the global features for the same i and h.\nThe anomaly score for the test sample $X#$ is then defined as the average of the losses across all local regions and forward passes:\n$A(X#) := \\frac{1}{H\\upsilon} \\sum_{h=1}^H \\sum_{i=1}^{\\upsilon} (I_{wish}^{global} + I_{wish}^{local}).$       (1)\nFor localization of anomalies, the anomaly score for a specific signal point, denoted as $X_{k,q}^$, corresponds to the part of the anomaly score in (1) that is related to that signal point."}, {"title": "Experiments", "content": "This section presents an evaluation of the proposed method using the PTB-XL anomaly detection and localization benchmark (Jiang et al., 2023), which offers a comprehensive tool for ECG-based anomaly detection tasks. The dataset contains 10,327 12-lead ECG recordings, sampled at 500 Hz over 10 seconds. The training set consists of 8,167 normal recordings, while the test set includes 912 normal and 1,248 abnormal recordings, covering a wide range of cardiovascular conditions (Wagner et al., 2020). For anomaly localization, the dataset provides point-level annotations for 400 ECG recordings across 22 abnormality types, labeled by cardiologists for accuracy."}, {"title": "Implementation Details", "content": "In our experiments, we use a segment size of 125, resulting in a sequence length of T = 40. We set d = 4 and define the local regions at the points 1, 5, 9, 13, 17, 21, 25, 29, 33, excluding the segments at the beginning and end of the sequence, similar to Jiang et al. (2023). The masking ratio is set to 0 = 25%, and the encoder consists of L = 3 layers with 16 self-attention heads and a latent dimension of D = 64. The decoder has a latent dimension of D' = 64 with 2 self-attention heads. Training uses the AdamW optimizer with a cosine annealing learning rate schedule and a batch size of 256, running for 300 epochs with a warm-up of 40 epochs. For inference, we select H = 4 to ensure that each segment in the local regions is masked with at least 99% probability. Performance is evaluated using the Area Under the Receiver Operating Characteristic Curve (AUC), following Jiang et al. (2023) and Bui et al. (2024)."}, {"title": "Comparisons with State-of-the-Arts", "content": "We compare our proposed method with several state-of-the-art time-series anomaly detection approaches, including TranAD (Tuli et al., 2022), AnoTran (Xu et al., 2022), TSL (Zheng et al., 2022), BeatGAN (Liu et al., 2022), MCF (Jiang et al., 2023) and TSRNet (Bui et al., 2024). The results of TranAD, AnoTran, TSL and MCF are excerpted from Jiang et al. (2023), while that of TSRNet is excerpted from Bui et al. (2024). As shown in Table 1, both MCF and our method significantly outperform baseline models in anomaly detection and localization, with our method achieving comparable detection performance and slightly better localization accuracy. This demonstrates our method's ability to effectively capture both global and local features of ECG signals, offering improved robustness and precision over existing solutions.\nTable 2 further highlights the computational efficiency of our method. Unlike MCF, which requires R-peak detection during preprocessing, our method eliminates this step, simplifying"}, {"title": "Visualization for Anomaly Localization", "content": "To further demonstrate the effectiveness of MMAE-ECG in anomaly localization, we present visualization results on representative samples from the PTB-XL benchmark, as shown in Figure 2. These examples cover a diverse range of ECG abnormalities, as annotated by experienced cardiologists (Jiang et al., 2023), with detailed descriptions provided in Appendix A.1. As illustrated in Figure 2, the proposed method effectively identifies diverse anomaly"}, {"title": "Ablation Study", "content": "We conduct ablation studies to systematically evaluate the contribution of each design choice in our model, using the PTB-XL anomaly detection benchmark, which includes patients with diverse characteristics. Specifically, we investigate the following key aspects:\na. The impact of multi-scale region utilization.\nb. The effectiveness of the local positional embedding.\nc. The influence of the multi-scale masking strategy.\nd. The necessity of the masked segment-based loss function.\ne. The effect of varying masking ratios.\nf. The influence of different aggregation strategies during inference."}, {"title": "Discussion", "content": "This paper proposes a novel multi-scale masked autoencoder (MAE) framework for anomaly detection in ECG time-series data, achieving state-of-the-art performance on both anomaly detection and localization tasks using the recently released PTB-XL benchmarks (Jiang et al., 2023). The proposed method models both global and local features within a single, end-to-end Transformer-based architecture. Unlike previous approaches (Jiang et al., 2023; Bui"}, {"title": "Conclusion", "content": "This paper introduces a novel multi-scale masked autoencoder framework for ECG anomaly detection and localization. By eliminating the reliance on R-peak detection and heartbeat segmentation, our approach enhances robustness for real-world clinical ECG recordings. The method employs a novel multi-scale masking strategy with multi-scale attention to capture both global and local dependencies, significantly improving performance while reducing computational complexity to 1/78 of the current state-of-the-art method. Experimental results on the PTB-XL benchmark validate its superior performance and highlight its potential for clinical deployment, particularly in resource-constrained settings. Future work will explore extending this approach to other ECG-related tasks, such as arrhythmia classification and heart disease detection, to further demonstrate its clinical utility."}, {"title": "Data Availability", "content": "The PTB-XL detection and localization benchmark dataset is publicly available at https://github.com/MediaBrain-SJTU/ECGAD."}, {"title": "Appendix", "content": ""}, {"title": "Details of Visualization Examples", "content": "Figure 2 illustrates a portion of ECG signals from different leads of examples in the PTB-XL localization benchmark (Jiang et al., 2023). In particular, it shows the AVR lead from the 212rd sample (A), the V1 lead from the 225th sample (B), the V4 lead from the 230th sample (C), the V1 lead from the 234th sample (D), the V2 lead from the 376th sample (E), and the V2 lead from the 389th sample (F). By mapping these samples to the SCP-ECG statements in the PTB-XL dataset (Wagner et al., 2020), we identify the corresponding clinical annotations: the 212rd, 225th, 230th, 234th, 376th and 389th samples are labeled with [complete left bundle branch block, first degree AV block, premature ventricular contractions], [complete right bundle branch block, left posterior fascicular block, first degree AV block, right ventricular hypertrophy], [left ventricular hypertrophy, non-specific ischemic, incomplete right bundle branch block, first degree AV block], [inferolateral myocardial infarction, anteroseptal myocardial infarction], [anteroseptal myocardial infarction, left ventricular hypertrophy, non-specific ischemic, non-specific intraventricular conduction disturbance (block), left atrial overload/enlargement], and [ischemic in anterolateral leads, ischemic in inferior leads, premature ventricular contractions], respectively."}]}