{"title": "Federated GNNs for EEG-Based Stroke Assessment", "authors": ["Andrea Protani", "Lorenzo Giusti", "Albert Sund Aillet", "Simona Sacco", "Paolo Manganotti", "Lucio Marinelli", "Diogo Reis Santos", "Pierpaolo Brutti", "Pietro Caliandro", "Luigi Serio"], "abstract": "Machine learning (ML) has the potential to become an essential tool in supporting clinical decision-making processes, offering enhanced diagnostic capabilities and personalized treatment plans. However, outsourcing medical records to train ML models using patient data raises legal, privacy, and security concerns. Federated learning has emerged as a promising paradigm for collaborative ML, meeting healthcare institutions' requirements for robust models without sharing sensitive data and compromising patient privacy. This study proposes a novel method that combines federated learning (FL) and Graph Neural Networks (GNNs) to predict stroke severity using electroencephalography (EEG) signals across multiple medical institutions. Our approach enables multiple hospitals to jointly train a shared GNN model on their local EEG data without exchanging patient information. Specifically, we address a regression problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a key indicator of stroke severity. The proposed model leverages a masked self-attention mechanism to capture salient brain connectivity patterns and employs EdgeSHAP to provide post-hoc explanations of the neurological states after a stroke. We evaluated our method on EEG recordings from four institutions, achieving a mean absolute error (MAE) of 3.23 in predicting NIHSS, close to the average error made by human experts (MAE \u2248 3.0). This demonstrates the method's effectiveness in providing accurate and explainable predictions while maintaining data privacy.", "sections": [{"title": "1 Introduction", "content": "Neurological evaluation involving brain signals is the primary tool in assessing and managing stroke patients [1, 2, 3]. These evaluations provide insights into the functional state of biological neural networks affected by stroke, which are essential for guiding clinical decisions and rehabilitation strategies [4, 5, 6]. However, the susceptible nature of such data poses significant challenges, particularly regarding privacy and security [7]. These challenges often hinder data sharing across institutions, limiting the collaborative potential for advancements in clinical neuroscience research and the development of robust predictive models [8, 9]."}, {"title": "2 Background and Related Works", "content": "This section reviews the concepts of GNNs and FL and discusses previous studies related to EEG-based stroke assessment."}, {"title": "2.1 Graph Neural Networks", "content": "GNNs operate on graph-structured data, where a graph G = (V, E) consists of nodes v \u2208 V and edges (u, v) \u2208 E. Each node v is associated with a feature vector x, \u2208 Rd. GNNs can be formally defined as functions of the form GNNw: (G, {X}v\u2208V, w) \u2192 yg, where w represents a set of trainable parameters. The core idea behind GNNs is to learn node or graph-level representations by iteratively updating node features through message passing:\n $$h_v^{l+1} = com\\Big(h_v^l, agg_{u \\in N(v)}(M(h_v^l, h_u^l, h_{uv}))\\Big),$$(1)\nwhere h represents the hidden feature vector of v at layer l, and h = x, while N(v) is the set of neighbors of v. For the edge between u and v, huv represents its hidden feature vector. The function com updates the hidden feature vector with messages received from u \u2208 N(v), agg is a permutation-invariant aggregation function and M is a message function.\nGraph Attention Networks GATv2 [31] introduces a self-attention mechanism to account for the varying importance of neighboring nodes during message passing. For a node v and its neighbor u \u2208 N(v), the attention score sw(xv, xu) is computed as sw (xv, Xu) = a (W [x || xu]), where W is a learnable weight matrix, a is a learnable vector of attention coefficients, o is the LeakyReLU activation function and || denotes concatenation. The attention scores are then normalized via av,u = softmaxu\u2208N(v) (Sw(Xv, Xu))."}, {"title": "2.2 Multi-layer Brain Networks", "content": "To represent brain connectivity across different frequency bands, a multi-layer graph approach has been proposed [28]. The multi-layer graph G, illustrated in Fig. 3, is defined as G = {Ga1, G2, G\u03b2\u2081}, where each G\u2081 = (V, Ei) represents a graph for a specific frequency band, sharing the same vertices"}, {"title": "Rewiring Brain Networks", "content": "To address the issue of over-smoothing [32, 33] in fully connected graphs when using GNNs, a rewiring strategy has been developed [28]. This process transforms the graph G\u2081 = (V, E\u2081) of each brain network layer into a sparse graph G\u2081 = (V, E) through structural and functional rewiring.\n(a) Structural Rewiring: a spatial proximity function 4 : V \u00d7 V \u2192 R+ is defined based on Euclidean distance between Brodmann areas. For each node v \u2208 V, the k = 3 spatially closest nodes are selected.\n(b) Functional Rewiring: a function \u03c8\u03b9 : \u0395\u2081 \u2192 R is defined, mapping each edge to its LLC value in layer l. Edges above the 99th percentile of LLC values are retained. The final set of edges in the rewired graph for each layer is E = EU E\u03c8 \u222a {(v, v) : v \u2208 V}, where E represents structural connections, Ef represents functional connections, and self-loops are included.\nThis rewiring strategy reduces edge density (retaining only \u2248 5% of the initial number of edges) while preserving critical functional and structural information, enhancing the GNN's ability to learn from the underlying brain network topology.\nThe proposed GNN architecture, combined with the multi-layer graph representation and rewiring strategy, allows effective learning from the complex, sparse brain networks derived from EEG data."}, {"title": "2.3 Federated Learning", "content": "FL is a paradigm that enables collaborative model training across a federation of multiple insti-tutions [10, 34]. This approach has gathered interest in domains like digital healthcare, where regulations and ethical considerations often restrict data sharing [8]. Formally, let Dc\u2081 represent the local dataset on client ci and W denote the global model parameters. Each client c\u2081 updates the global model by minimizing a local loss function Lc\u2081 (W; Dc\u2081). The global objective can be expressed as:\n$$\\min_{W} \\sum_{i=1}^{N} \\frac{n_i}{n} L_{ci} (W; D_{ci})$$(2)\nwhere ni is the number of samples on device ci and n = $\\sum_{i=1}^{N}$ ni is the total number of samples across all devices.\nFederated Averaging (FedAvg) is one of the most popular algorithm for FL aggregation [10]. FedAvg aims to address the challenges of statistical heterogeneity among participants in federated systems. The algorithm operates as follows: the server initializes the global model parameters WO. Then, for each round r = 1, . . ., R, the server samples a subset of clients Sr according to a probability distribution P and sends the current global model Wr-\u00b9 to each of the clients in the sampled subset. Each client ci \u2208 Sr updates the model locally using their dataset Dci by computing W = OPT(Wr-1,Dci), where OPT is the local optimization algorithm (e.g., SGD,"}, {"title": "2.4 Edge Shapley Values for Model Explainability", "content": "While the model in [28] effectively predicts stroke severity from EEG data, its interpretability is limited to the noise introduced by random initialization of the attention coefficients a. In particular,"}, {"title": "2.5 Related Works", "content": "The impact of acute stroke on the topology of cortical networks has been extensively investigated through EEG analysis, revealing significant, frequency-dependent alterations in network properties. Specifically, stroke leads to decreased small-worldness in the 8 and 0 bands and increased small-worldness in the 2 band across both hemispheres, regardless of lesion location [1]. Distinct modifications in functional cortical connectivity due to acute cerebellar and middle cerebral artery strokes have been highlighted, showing different impacts on network architecture and small-world characteristics across various EEG frequency bands, independent of ischemic lesion size [4, 19].\nAdditionally, research has shown that acute cerebellar and middle cerebral artery strokes distinctly affect functional cortical connectivity, with significant differences in EEG-based network remod-eling across \u03b4, \u03b22, and \u03b3 frequency bands, highlighting the unique impact of stroke location on brain network dynamics [19]. The prognostic role of hemispherical differences in brain network connectivity in acute stroke patients has been explored using EEG-based graph theory and coher-ence analysis. Findings indicate that stroke-induced alterations in network architecture can predict functional recovery outcomes, providing a basis for tailored rehabilitation strategies [24, 23].\nThe relevance of brain network analysis for stroke rehabilitation has been studied, highlighting the potential of network-based approaches to inform and guide therapeutic interventions in stroke recovery [38]. Dynamic functional reorganization of brain networks post-stroke has been emphasized, providing critical insights into the brain's adaptive mechanisms following a stroke and supporting network analysis to understand structural and functional reorganization [3]. Finally, changes in the contralesional hemisphere following stroke and the implications of the stroke connectome for cognitive and behavioral outcomes have been explored, enhancing our understanding of the complex network dynamics involved in stroke pathology and recovery [2, 39, 20]"}, {"title": "3 Experimental setup", "content": "We designed two distinct federated learning setups to investigate how data distribution affects model performance. The first configuration mimics real-world conditions by treating individual hospitals"}, {"title": "4 Experimental result", "content": "The performances across different learning setups are summarized in Tab. 1. Results reflect the mean absolute error (MAE) and standard deviation across five initializations. The statistics are also computed across clients in isolated learning setups, while federated and centralized setups leverage collaborative training.\nThe Isolated Learning approach, where models are trained independently for each client, shows weaker performance compared to collaborative methods. In the realistic isolated learning setup, a MAE of 3.68\u00b10.26 was obtained, while the idealized isolated setup, though more controlled, resulted in a higher MAE of 3.92 \u00b1 0.87. The high variance in the idealized setting suggests that the data distribution across clients introduces inconsistencies in model performance, even when the data covers the full value range. This reflects the challenge of achieving stable results when training independently without data sharing.\nFL consistently outperformed isolated learning. In the realistic FL setup, FedAvg achieved a MAE of 3.23 \u00b1 0.06, and SCAFFOLD slightly improved with an MAE of 3.22 \u00b1 0.05. This indicates the robustness of federated learning in harnessing distributed data while maintaining privacy. The marginal improvement of SCAFFOLD over FedAvg in the realistic scenario suggests that SCAFFOLD's correction of client drift is particularly beneficial when client data distributions closely resemble real-world conditions.\nPerformance was slightly lower in the Idealized Federated Learning setup, which uses a more balanced and mixed data distribution across clients. FedAvg reported MAE of 3.34 \u00b1 0.08, while SCAFFOLD had an MAE of 3.44\u00b10.07. Although more evenly distributed, the idealized setup may obscure the natural variations in client data in realistic conditions. This could explain why models trained in the idealized setup generalize less effectively to the test set, which likely follows a more realistic data distribution. Thus, the realistic setup mirrors client-specific data patterns, enhancing predictive accuracy.\nThe Centralized Learning setup, where all client data is pooled into a single model, achieved a MAE of 3.22 \u00b1 0.12, which is identical to the performance of the Realistic Federated Learning setup using the SCAFFOLD algorithm. This highlights that federated learning, when properly configured, can achieve the same level of accuracy as centralized learning without requiring data sharing. Given the privacy constraints in medical settings, federated learning presents a substantial"}, {"title": "Explainable Insights", "content": "Integrating EdgeSHAPer values into our framework enables us to assign a Shapely value to each edge, which offers several key advantages:\n(a) Quantitative Edge Importance: Shapley values provide a theoretically robust measure of each edge's significance, enabling us to rank physiological connections based on their contributions to the model's predictions. This quantitative assessment ensures a fair and consistent evaluation of edge importance across brain networks.\n(b) Interpretable Visualizations: We visualize the brain network by coloring edges based on their corresponding Shapley values and sizing nodes according to their weighted degree centrality derived from those values (see Fig. 5). This dual representation effectively highlights critical brain regions and their interconnections, making the network dynamics more comprehensible.\n(c) Actionable Insights: Identifying the most significant edges allows clinicians to understand which neural pathways were most affected by the stroke. This understanding informs the development of targeted therapeutic interventions, enabling personalized treatment plans that address the specific neural disruptions identified by our model.\nWe used a similarity metric based on the normalized Euclidean distance to assess the similarity between different model variants. This metric was applied to compare sets of weight vectors derived from the various experiments. Our analysis revealed an average similarity of 0.76, indicating high coherence among the weight vectors. Notably, the idealized subgroup exhibited an average similarity of 0.75, while the realistic subgroup achieved a higher similarity of 0.78. The similarity matrix demonstrated consistently high values across all vector pairs, ranging from 0.73 to 0.78. This approach provides insights into the convergence patterns and consistency of diverse federated learning strategies and setups. Furthermore, these results align with our observations regarding the best MAE, suggesting a strong correlation between higher performance metrics and more cohesive latent representations. Fig. 5 illustrates these findings, depicting the Edge Shapley Values for our federated learning setups and highlighting the relative contributions of different nodes and edges to the model's predictions."}, {"title": "5 Conclusions", "content": "Broader Impact The proposed federated learning framework for stroke assessment can assist clinical neuroscientists' evaluations by enabling collaborative research and model development across multiple institutions while maintaining strict data privacy. By allowing hospitals to unify insights without sharing raw patient data, this approach addresses privacy concerns and broadens the scope of multi-healthcare collaborations. The model's ability to predict stroke severity with an error rate close to human performance and interpretability modules can help clinicians better understand brain network changes post-stroke, leading to more personalized treatment plans.\nLimitations While the proposed federated learning framework offers significant privacy advantages and demonstrates solid predictive performance, some limitations must be acknowledged. First, the relatively small sample size of 72 patients restricts the model's generalizability to more extensive and diverse clinical populations. Additionally, scalability to broader multi-institutional settings may face challenges due to variations in data quality, preprocessing protocols, and hardware capabilities across institutions.\nConclusion This study introduces a novel federated learning framework using GNNs for neurolog-ical assessments, demonstrating its ability to predict stroke severity from EEG data across multiple institutions. We show the effectiveness of collaborative model training while preserving data privacy. Incorporating explainability through EdgeSHAPer further enhances the model's potential clinical relevance by providing insights into the neural connections driving predictions. Future work will focus on expanding the dataset and addressing the technical challenges of scaling the system to larger, more diverse populations."}]}