{"title": "Extracting PAC Decision Trees from Black Box Binary Classifiers:\nThe Gender Bias Study Case on BERT-based Language Models", "authors": ["Ana Ozaki", "Roberto Confalonieri", "Ricardo Guimar\u00e3es", "Anders Imenes"], "abstract": "Decision trees are a popular machine learning method, known for their inherent explainability. In Explainable AI, decision trees can be used as surrogate models for complex black box AI models or as approximations of parts of such models. A key challenge of this approach is determining how accurately the extracted decision tree represents the original model and to what extent it can be trusted as an approximation of their behavior. In this work, we investigate the use of the Probably Approximately Correct (PAC) framework to provide a theoretical guarantee of fidelity for decision trees extracted from AI models. Based on theoretical results from the PAC framework, we adapt a decision tree algorithm to ensure a PAC guarantee under certain conditions. We focus on binary classification and conduct experiments where we extract decision trees from BERT-based language models with PAC guarantees. Our results indicate occupational gender bias in these models.", "sections": [{"title": "Introduction", "content": "Decision trees are known to be easy to explain because, given an input, one can directly trace the decisions which led to the output. However, this method lacks the generalizability of architectures based on neural networks that have hidden layers. Although there has been some progress in increasing the generalizability of decision trees [Frosst and Hinton, 2017] and even translating trained neural networks into decision trees [Aytekin, 2022], there appears to be a trade-off between generalizability and interpretability that is not easy to balance.\nTo enjoy the best of both worlds, the AI research community has been exploring the idea of extracting decision trees from trained neural networks. The extracted trees can then serve as an explainable approximation of these black-box models [Confalonieri et al., 2020, Krishnan et al., 1999, Vasilev et al., 2020, Boz, 2002, Bologna and Hayashi, 2018, Schmitz et al., 1999, Dancey et al., 2004, Burkhardt et al., 2021, Setiono and Liu, 1995, Nanfack et al., 2021, Craven and Shavlik, 1995, II et al., 2011, Awudu and Zhou, 2015] (see also [Chorowski and Zurada, 2011, Shih et al., 2019] for works extracting decision diagrams from trained neural networks). Previous works in this direction indicate that, in practice, decision trees are indeed useful for understanding patterns in the data, which cannot be understood from black-box models. This approach has been applied to various domains such as medicine [Dancey et al., 2010], traffic signal control [Zhu et al., 2023], risk credit evaluation [Baesens et al., 2003], water resource management [Wei et al., 2012], multimedia [Fanta et al., 2019], among others. The decision tree in this case functions as a surrogate for the original model. The advantage of surrogate models is their ability to abstract the original model, focusing on specific inputs or aspects of interest.\nIn this paper, we apply this approach to unveil occupational gender bias in BERT-based language models. By extracting rules that approximate parts of the model of interest, we can avoid the challenges associated with approximating the whole language model, which could be computationally infeasible or inefficient. Moreover, the approach of extracting decision trees can be applied to black-box models regardless of their internal architectures, which are constantly evolving as the field of artificial intelligence tackles increasingly complex tasks.\nThe main challenge with such approximations lies in determining how accurately the extracted decision tree represents the relevant parts of the original black box model. To the best of our knowledge, current practical approaches for extracting decision trees from trained neural networks do not provide theoretical guarantees regarding the fidelity of the decision trees with respect to the original model. What guarantees would be appropriate? How could such guarantees be given?\nIn Computational Learning Theory, the most well studied framework which gives correctness guarantees is known as the Probably Approximately Correct (PAC) framework [Valiant, 1984]. In the original framework, a learner receives examples classified according to some target function. The classification is binary and the classified examples come according to a probability distribution that is fixed but arbitrary and unknown. The learner then creates a hypothesis consistent with the information received. In a nutshell, the theoretical correctness guarantee is that, provided with enough data, with high probability, the difference between any hypothesis created by the learner that is consistent with the data and the target function is minimal. This \u201cdifference\u201d is quantified by the probability of misclassification, known as the true error [Shalev-Shwartz and Ben-David, 2014]. The sample complexity quantifies the amount of data that is enough for such a guarantee [Vapnik and Chervonenkis, 1971].\nIn this work, we study the PAC framework and explore its potential to provide a theoretical correctness guarantee for decision trees extracted from black-box models. We provide formal definitions for the relevant notions we use. In particular, we relate the notion of fidelity in the literature on decision trees with the PAC guarantee (Section 2). We focus on binary classification, as this is the most studied setting within the PAC framework. On the theoretical side, we provide a bound on the sample size needed for PAC learning when the training error is bounded by $k||S|$, where $|S|$ is the size of the training set and $k \\in N$ (Theorem 8). This bound is used in a decision tree algorithm (Section 3). On the practical side (Section 4), we perform experiments based on a recent gender bias study case [Blum et al., 2023], where we extract decision trees using BERT-based models [Devlin et al., 2019, Liu et al., 2019]. We conclude in Section 5."}, {"title": "The PAC Framework", "content": "Here we introduce the relevant notation for decision trees and PAC learning (Section 2.1). We then show in Section 2.2 our theoretical bound on the number of examples when the hypothesis is inconsistent with the training set."}, {"title": "Basic Definitions", "content": "We now formalise the PAC learning framework. We follow the notation for the definition of PAC learning adopted in the literature [Shalev-Shwartz and Ben-David, 2014, Konev et al., 2017, Ozaki, 2020, Kearns and Mansour, 1999].\nDefinition 1. A concept class $C$ is a triple $(E, H, \\mu)$ where $H$ is a set of concept representations, called hypothesis space; $E$ is a set of examples; and $\\mu$ is a function that maps each element of $H$ to a subset of $E$.\nEach element of $H$ is called a hypothesis. The target representation (here simply called target) is a fixed but arbitrary element of $H$, representing the kind of knowledge that is aimed to be learned. Given a target $t \\in H$, we say that the examples in $\\mu(t)$ are positive examples, otherwise, they are called negative examples. A classified example w.r.t. the target $t$ is a pair $(e, c(e))$, where $c(e) = 1$ (positive) if $e \\in \\mu(t)$ and $c(e) = 0$ (negative) otherwise. A training set is a set of classified examples (we may omit that this is w.r.t. $t$). Given a training set $S$, we denote by $S_e$ the examples in $S$. In other words, $S_e$ is the result of removing the labels in $S$.\nDefinition 2 (Induced Probability Distribution). Let $m$ be a positive integer and let $D$ be a probability distribution over a set of examples $E$. The probability distribution $D$ induces the probability distribution $D^m$ over the set of all"}, {"title": "Training Error Tolerance and Fidelity", "content": "A common assumption in PAC learning is the realizability assumption, which basically says that the target belongs to the hypothesis space. When the target belongs to the hypothesis space, in theory we know there is a hypothesis that is consistent with the training data, that is, the training error is 0. This is a rather strong assumption in practice because the hypothesis is usually not fully consistent with the training set [Mohri et al., 2018, Section 2.3]. On the other extreme, the notion of agnostic PAC learning completely removes the realizability assumption but comes with other challenges. Here we keep the realizability assumption but allow the hypothesis to be inconsistent with the training set. We prove in Theorem 8 that one can allow the hypothesis to misclassify $k$ examples in a training set and give a bound on the minimal number of examples needed for PAC learnability based on $k$. Given a sample $S$, let $h'_S$ be a fixed but arbitrary element of $H$ such that $e \\in \\mu(t)$ iff $e \\in \\mu(h'_S)$ does not hold for at most $k$ elements $e$ in $S$.\nTheorem 8 (PAC learnability with Training Error). Let $H$ be a finite hypothesis class. Let $\\delta \\in (0, 1)$ and $\\epsilon > 0$ and let $m$ be an integer that satisfies\n$m \\geq \\frac{ln((\\|H\\|\\cdot (k + 1))/(\u03b4\\cdot\\epsilon))}{E} + k$."}, {"title": "PAC Decision Trees", "content": "We first provide basic notions for formally defining decision trees (Section 3.1). Then, we present a version of a decision tree algorithm, called TopDown, introduced by Kearns and Mansour (1999) (Section 3.2) and the TREPAC algorithm (Section 3.3) for building decision trees with PAC guarantees."}, {"title": "Decision Trees", "content": "We provide formal definitions for candidate splits, constraints, trees and decision trees.\nDefinition 11 (Candidate Split & Constraint). Let $F$ be a set of features. Each feature $f$ is associated with a set $values(f)$ of possible values. A candidate split is an expression of the form $f \\copyright v$ where $f \\in F$, $\\copyright \\in {=, <, \\leq, >, \\geq}$, and $v \\in values(f)$. We define constraints by induction. Every candidate split is a constraint. If $\\phi$ and $\\psi$ are constraints then $(\\phi \\vee \\psi)$ and $(\\phi \\wedge \\psi)$ are constraints. Moreover, if $\\phi$ is a constraint then $\\lnot(\\phi)$ is also a constraint. We may write $\\bar{\\phi}$ as a short hand for $\\lnot(\\phi)$. When dealing with constraints, we may treat sets and the conjunction of its elements interchangeably (e.g. a$\\wedge$b as {a,b} and vice-versa). Moreover, we use 0 as an abbreviation for a contradiction $\\psi \\wedge \\lnot(\\psi)$, with $\\psi$ being a candidate split, and we write 1 for the negation of 0.\nDefinition 12 (Tree). A (binary) tree is a set $T$ containing $\\emptyset$ and finite binary sequences closed under prefix (i.e., if e.g. $110 \\in T$ then $11 \\in T$ and $1 \\in T$). The elements of $T$ are called nodes and the node $\\emptyset$ is called the root of $T$. The parent of a (non-root) node $n \\in T$ is the result of removing the last element of $n$. E.g., 11 is the parent of 110.\nDefinition 13 (Decision Tree). A (binary) decision tree is a relation that maps each node in a tree $T$ to a (possibly empty) set of constraints. We refer to this relation as a set of pairs $(n, \\psi)$ where $n$ is a node in $T$ and $\\psi$ is a constraint. The class of a node $n$, denoted $class(n)$, is the last bit of the sequence $n$. E.g., if $n = 110$ then $class(n) = 0$.\nWhenever we speak of the nodes of a decision tree we mean the domain of the relation. The nodes of a decision tree can be internal nodes or leaf nodes. The former are nodes which are parents of other nodes, while the latter are the remaining nodes, that is, those without children. We denote by $size\\_of(T)$ the number of internal nodes of a decision tree $T$. Also, we write $leaves(T)$ for the set of leaf nodes in $T$. We write $T(l, \\psi)$ for the tree that results of transforming a leaf $l$ in a tree $T$ into an internal node (with two children) and associating the constraint $\\psi$ with this internal node. In other words, $T(l, \\psi) := (T \\setminus {(l, \\emptyset)}) \\cup {{(l, \\psi), (l0, \\emptyset), (l1, \\emptyset)}}$.\nGiven a node $n$ in a decision tree $T$, we write $constr_T(n)$ for the set of constraints associated with $n$ in $T$ (that is {$n | (n, \\psi) \\in T$}). Also, we define a function constr that maps each node to all constraints needed to be satisfied to reach the node. We define such function inductively as follows. First we set $constr(\\emptyset) := \\emptyset$. Now, we set $constr(n0) := constr_T(n) \\cup constr(n)$ and $constr(n1) := constr_T(n) \\cup constr{\\lnot}\\phi(n)$.\nDefinition 14 (Tabular Examples & Constraint Satisfaction). A tabular example for a set of features $F$ is a tuple $(v_1,..., v_n)$ with each $v_i \\in values(f_i)$ being a value for a feature $f_i \\in F$ (assume a fixed but arbitrary order for the features in $F$). Then, $(v_1, ..., v_n)$ satisfies\n*   a candidate split $f_i \\copyright v$ if $v_i \\copyright v$, with $\\copyright \\in {=, <, \\leq, >, \\geq}$;\n*   a constraint$\\lnot(\\psi)$ if it does not satisfy the constraint $\\psi$;\n*   a constraint $(\\phi \\wedge \\psi)$ if it satisfies $\\phi$ and $\\psi$;\n*   a constraint $(\\phi \\vee \\psi)$ if it satisfies $\\phi$ or $\\psi$.\nGiven a tabular example $x$ and a constraint $\\psi$, we may write $x \\models \\psi$ to express that $x$ satisfies $\\psi$. Moreover, we say that a decision tree $T$ classifies a tabular example $x$ as positive, written $T(x) = 1$, if there is a leaf node $n_l$ such that $x \\models constraints(n_l)$. Otherwise, $T$ classifies the tabular example $x$ as negative."}, {"title": "The TopDown Decision Tree Algorithm", "content": "We define the concept class of (binary) decision trees.\nDefinition 15. The concept class of (binary) decision trees $CDT$ is a triple $(E, HDT, \\mu)$ where $E$ is a set of tabular examples (according to Definition 14), $HDT$ is a set of (binary) decision trees, and $\\mu$ is a function that maps each element $T$ of $HDT$ to $\\bigcup_{n1\\in leaves(T)}\\{x \\in E | x \\models constr(n1)\\}$.\nLet $T$ be a decision tree (Definition 13). For each $l \\in leaves(T)$, $D({x \\in E|x \\models constr(l)})$ is the probability that an example $x \\in E$ (drawn according to $D$) reaches $l$ in $T$. The error of a leaf $l$ is given by the probability that $l$ wrongly classifies $x$. The error of a decision tree $T$ is the sum of the error of all the leaves in $T$. We write $T'$ for the target decision tree that represents the black box binary classifier we attempt to approximate.\nProposition 16. The true error $error(T, T', D)$ of a decision tree $T$ is\n$\\sum_{n0Eleaves(T)} D(\\{x|x \\models constr+(n0)\\} \\cap \\mu(T')) + \\sum_{n1 Eleaves(T)}D(\\{x|x \\not\\models constr(n1)\\} \\cap \\overline{\\mu(T)})$.\nThe TopDown algorithm (Algorithm 1) starts with a root node and builds a decision tree by creating new leaf nodes at each iteration of the 'while loop'. These leaves may become parents at the next iteration, and so on. The 'for loop' iterates over the space of possible leaves and constraints. The idea is to find a leaf and constraint in a way that the splitting minimizes the error of the tree.\nAlgorithm 1 is only useful for theoretical purposes since in practice we do not have access to the function $error(.)$ and, furthermore, it would be computationally expensive to make an exhaustive search on the constraints, as done in Line 4. So in the next section we adapt a decision tree algorithm to use the PAC framework."}, {"title": "The TREPAC Algorithm", "content": "TREPAC is a tree induction algorithm that extracts decision trees from binary classifiers, seen as oracles. The original motivation behind the development of TREPAC is to approximate a neural network by means of a symbolic structure that is more interpretable than a neural network classification model while giving PAC guarantees. This approach has also its roots in the context of a wider interest in knowledge extraction from neural networks (see our discussion in the Introduction). TREPAC differs from conventional inductive learning algorithms such as CART and C4.5 because it uses the PAC framework to estimate the amount of training data and internal nodes in the resulting decision tree. It uses a membership oracle to classify examples used for training. Here we consider the binary entropy as the splitting criterion, that is, $G(q) = -qlog(q) \u2013 (1 \u2013 q) log(1 \u2013 q)$ and $q \\in [0,1]$. The best (binary) split, denoted best\\_split, is the candidate split with the lowest entropy w.r.t a set of samples $S$.\nThe pseudo-code for TREPAC is shown in Algorithm 2. In more details, the TREPAC algorithm works as follows. It takes 5 inputs, namely, an oracle $MQC,T,$ for creating the sample, the maximal number of internal nodes (called size\\_limit), an upper bound $k$ on the number of misclassified examples, a set of candidate splits $\\Phi$, and the size of the training set (called training\\_size). At the beginning, the algorithm creates an empty node and pushes it to the queue (Line 3). The queue is used to decide which nodes should be evaluated (Line 7). The algorithm calls the oracle $MQC,T,$ to create a training set (Line 4). TREPAC stops the tree extraction process when one of three criteria is met: no more nodes need to be further expanded (the queue is empty), a predefined limit of the tree size is reached, or the training error is below a predefined bound (Line 6). In Line 11, by the \u201cmisclassification of a node $n_i$\u201d we mean the number of classified examples in $S$ that reach $n$, but whose class differs from $i$.\nCorollary 17. Let $MQC,T,$ be the membership oracle for the concept class $C$ and the target $T'$, and let $I$ be the set of candidate splits induced by $C$. Let $T$ be the output of a run of TREPAC ($MQC,T,,$ size\\_limit, $k, \\Phi,$ training\\_size) and let $\\epsilon, \\delta \\in (0,1)$. With probability greater than 1 \u2013 $\\delta$, we have that $error(T, T', D)$ is smaller than $\\epsilon$, where $D$ is the probability distribution used to generate the examples given as input to the membership oracle $MQC,T,$ if (i) training\\_size is as in Theorem 8 and the number of misclassified examples of $T$ w.r.t. the training set is bounded by $k$; or (ii) size\\_limit (the number of internal nodes) and training\\_size are as in Theorem 1 by Kearns and Mansour [1999] and $k = 0$.\nProof. This result is a consequence of Theorem 8 and in Theorem 1 by Kearns and Mansour (1999))."}, {"title": "Experiments", "content": "We now describe our experiments using TREPAC. In order to showcase the performance of TREPAC as a tool for explaining the behaviour black box models, we consider the recent study case presented by Blum et al. [2023], where the authors extract rules indicating occupational gender biases in BERT-based language models. In the mentioned reference, the authors use an adaptation of Angluin's Horn algorithm to extract rules. The authors do not provide PAC guarantees for their results (although this could have been obtained in their work by running the algorithm without limiting the number of simulated equivalence queries). Here we extract decision trees and analyse the results in light of the PAC framework. Although BERT-based models [Devlin et al., 2019, Liu et al., 2019] are not binary classifiers, the study case focuses on pronoun prediction (\u2018she' or 'he'). In the following, we provide more details on the study case by Blum et al. [2023] (Section 4.1) and also our experimental results (Section 4.2)."}, {"title": "The Occupational Gender Bias Study Case", "content": "In the study case by Blum et al. [2023], the authors consider 4 language models: BERT-base-cased, BERT-large-cased [Devlin et al., 2019], RoBERTa-base, and RoBERTa-large [Liu et al., 2019]. These language models are trained to fill up a blank part (called 'mask') of a sentence with a token. The authors of the study case use the following kinds of features to create sentences\u00b3:\n*   birth period: before 1875, between 1875 and 1925, between 1925 and 1951, between 1951 and 1970, after 1970;\n*   location: North America, Africa, Europe, Asia, South America, Oceania, Eurasia, Americas, Australia;\n*   occupation: nurse, fashion designer, dancer, footballer, industrialist, boxer, singer, violinist.\nIn total, this gives 22 features which can be used to create sentences with one value for each kind of feature. The sentences are of the form:  was born [birth period] in [location] and is a/an [occupation], where the task of a"}, {"title": "Results", "content": "We now present and discuss our experimental results. The idea behind our experiments is to (i) check the feasibility of the study case [Blum et al., 2023] in our setting which gives PAC guarantees, (ii) check whether we obtain results that are consistent with their results, and also (iii) check whether decision trees format provide additional useful information. All experiments were run on a MacBook Pro M2 16GB. Each experiment was run 10 times. and we present average values.\nFeasibility We ran several experiments to check the practical feasibility of the approach using the PAC framework. The binary data representation is suitable for the case of learning surrogate decision trees from the BERT-based language models. We use Theorem 8 to calculate m considering the hypothesis space to be the set of all decision trees with n internal nodes. The size of the hypothesis space was constrained to the number of all decision trees with n internal nodes, in particular $|n||F|$, where $|F|$ is number of features which in our case is 22. The corresponding sample sizes (m) for values of k = [0, 5, 10, 15] and n = [3,6,10,18] are shown in Table 1. The range values for k and n were chosen so that the number of training examples is low in comparison with the total number of examples. When the number of accepted errors k is larger, the number of hypotheses which can be used increases. This also raises the chance of selecting a bad hypothesis. To compensate for this, a larger number of consistent examples is required. For each language model we extracted 16 decision trees varying n and k according to Table 1. For each decision tree we measured the training error (Figure 1), as well as the number of misclassified training examples (Figure 2).\nAs expected, both the training error and the number of misclassified training examples decreases when the size of the tree increases. Figure 1 shows the training error of the BERT-based language models. For all models, this error is less than the upper bound $\\epsilon = 0.2$, chosen for determining the number of examples needed for PAC learnability based on k. This result is consistent with our Theorem 8. Figure 2 shows the sensitivity of the results w.r.t. the number of accepted errors k. The numbers of samples m calculated in Table 1 ensure that the number of misclassified training examples is at most k = 0 when the tree size is at least n = 18 for all models. For other values k = [5, 10, 15], m ensures that the number of misclassified training examples is at most k when an appropriate tree size is chosen. To have at most k = 5 misclassified examples, the tree size has to be at least n = 10. For higher values of k, trees with fewer nodes suffice. This result demonstrates the practical applicability of Theorem 8. We provide additional supporting information regarding the error in Section 8. Crucially, the time for running the algorithm is negligible. The time for generating training sets using BERT-based models varied from approximately 85 to 510 seconds (more in Section 9).\nConsistency and Format Our results are consistent with those obtained by Blum et al. [2023], indicating also in our case occupational gender bias in these models (see Fig. 3 and also Fig. 6 in Section 10). Regarding the format, the decision trees depict in a quantified manner which features are the most relevant for pronoun prediction, with the occupations being the most relevant ones. We report the frequency of common rules in Table 2."}, {"title": "Conclusion and Future Work", "content": "We motivate and study the PAC guarantees for decision trees extracted from black box binary classifiers. Since the training error is rarely zero, we provide a non-trivial proof for estimating the sample size for finite hypothesis when the training error is not zero. Our proof is applicable to any concept class with finite hypothesis space. We then formalize the relevant definitions for decision trees. Finally, we perform experimental results with decision trees on BERT-based models and analyse the results in light of the PAC framework. In future work, it would be interesting to study a sampling strategy that satisfies the constraints of the leaves, as in Trepan [Craven and Shavlik, 1995], within the PAC framework. This seems promising from a practical point of view. However, the analysis would be complex because randomly selecting examples that satisfy the leaves would change the sample space, necessitating an investigation into how the PAC framework could be adapted for this scenario."}, {"title": "Lookup Table", "content": "Table 3 contains the mapping between features and vector positions, as defined by the authors of the occupational gender bias study case [Blum et al., 2023]."}, {"title": "True Error and Misclassified Examples", "content": "The true error is usually impossible to calculate since it requires knowledge about the classification of all examples."}]}