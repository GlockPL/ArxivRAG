{"title": "Optimization of Retrieval-Augmented Generation Context with Outlier Detection", "authors": ["Vitaly Bulgakov"], "abstract": "In this paper, we focus on methods to reduce the size and improve the quality of the prompt context required for question-answering systems. Attempts to increase the number of retrieved chunked documents and thereby enlarge the context related to the query can significantly com- plicate the processing and decrease the performance of a Large Language Model (LLM) when generating responses to queries. It is well known that a large set of documents retrieved from a database in response to a query may contain irrelevant information, which often leads to hallucinations in the resulting answers. Our goal is to select the most semantically relevant documents, treating the discarded ones as outliers. We propose and evaluate several methods for identifying outliers by creating features that utilize the distances of embedding vectors, re- trieved from the vector database, to both the centroid and the query vectors. The methods were evaluated by comparing the similarities of the retrieved LLM responses to ground-truth an- swers obtained using the OpenAI GPT-40 model. It was found that the greatest improvements were achieved with increasing complexity of the questions and answers.", "sections": [{"title": "1. Introduction", "content": "Improving context retrieval in question-answering systems has garnered considerable attention over the past few years. For instance, [1] presents a comprehensive survey on the Retrieval- Augmented Generation (RAG) framework, detailing the involved retrievers and generators. It explores various enhancement methods for RAG, evaluates benchmark frameworks, and addresses current limitations and future directions, providing a solid foundation for understanding RAG tech- niques and their applications. In another study, [2] introduces xRAG, a method for extreme con- text compression that reinterprets document embeddings used in dense retrieval as features for language models. This approach aims to maintain the semantic coherence of retrieved documents while minimizing memory overhead and computational expense. xRAG employs techniques such"}, {"title": "", "content": "as self-distillation and instruction tuning to enhance the use of contextual information. Also, [3] presents a novel in-context retrieval approach for RAG systems that avoids the traditional chunk- ing process. It uses encoded hidden states of documents for retrieval, improving the fidelity and accuracy of the evidence text used for generating responses. This method ensures that relevant and precise context is maintained without disrupting the semantic coherence of the documents. [4] discusses the concept of re-ranking, where a re-ranking agent re-orders retrieved documents based on additional factors such as user behavior, document popularity, or deeper semantic analysis, en- suring the most useful and relevant documents appear at the top of search results. In [5] we explore the benefits of reducing vector database dimensions with Fast Fourier Transform, with a focus on computational efficiency in processing context documents.\nIn the described approach, we propose a mechanism to improve the quality and reduce the size of the context based on retrieved documents for a given query. This mechanism identifies outliers that are far from or irrelevant to the query and focuses on the portion of the context most related to the query. Distances are calculated for each retrieved document, represented as an embedding vector by a sentence transformer model. We utilize distances to the vectors' centroid and the query vector. These distances form features based on the following methods: concatenation, weighted sum, interaction, and polynomial, which will be described later. The constructed features provide a rich representation of the distances between embedding vectors, the centroid, and the query vector, capturing various aspects of the relationship between the vectors and helping distinguish typical vectors from outliers. Outliers are determined with help of a Gaussian Mixture Model (GMM) and Log-Likelihood approach with selected percentile, [6] and [7].\nWe experimented with three categories of questions of increasing complexity and demonstrated that the approach provides the most significant advantage with the most complex questions."}, {"title": "2. Theory and Methods", "content": "Our approach aims to identify outliers among a set of embedding vectors used in a context for Retrieval-Augmented Generation (RAG). The outliers are detected based on distances from a query vector and a centroid vector. Below is a detailed explanation of the methods implemented, along with the corresponding formulas.\nDistance Calculation For each embedding vector in the set, the distances to a given query vector and a centroid vector are calculated:\nDistance to Centroid : $d_{centroid}$ = ||Vi - c||\nDistance to Query Vector : $d_{query}$ = ||Vi - q||\nWhere:\n\u2022 vi is the i-th embedding vector,\n\u2022 c is the centroid vector,\n\u2022 q is the query vector,"}, {"title": "", "content": "\u2022 || || denotes the Euclidean norm.\nWe use a weighting factor 0 \u2264 a \u2264 1 to balance these distances:\ndistance to centroid (weighted) = $d_{centroid}$ \u00d7 (1 \u2212 a)\ndistance to query (weighted) = $d_{query}$ \u00d7 a\nFeature Creation Methods We used multiple methods to combine these distances into features (see, e.g. [8] - [9]) for further analysis:\nConcatenate : $f\u2081 = [d_{centroid}, d_{query}]$\nWeighted Sum : $f\u2081 = ad_{query} + (1 \u2212 a)d_{centroid}$\nInteraction: $f\u2081 = [\\frac{d_{centroid}}{d_{centroid} + \\epsilon}, d_{query}, d_{centroid} \u00d7 d_{query}, \\frac{d_{query}}{d_{query} + \\epsilon}]$\nWhere epsilon is a small value to avoid division by zero.\nPolynomial : $f\u2081$ = PolynomialFeatures ($d_{centroid}, d_{query}$)\nThis expands the distance features to include polynomial combinations up to the specified degree.\nStandardization Standardization is applied to the feature vectors to ensure they have zero mean and unit variance:\n$f_{normalized} = \\frac{f_i - \\mu}{\\sigma}$\nWhere \u03bc is the mean and o is the standard deviation of the features.\nDimensionality Reduction If the number of features is more than two, we apply Principal Com- ponent Analysis (PCA) to reduce the features to two dimensions for visualization. We also use various PCA dimensions for outliers detection which will be explained further:\n$f_{PCA} = PCA(f_{normalized})$\nOutlier Detection Outliers are identified based on a log-likelihood threshold. Points with a log- likelihood below the threshold are considered outliers.\n1. Fit a Gaussian Mixture Model (GMM): The feature vectors are modeled using a GMM, which assumes that the data is generated from a mixture of several Gaussian distributions. The GMM is parameterized by the mean vectors \u03bc\u03ba, covariance matrices \u03a3\u03ba, and mixture weights \u03c0\u03ba for each component k."}, {"title": "", "content": "2. Calculate Log-Likelihood: For each feature vector f\u00bf, compute the log-likelihood under the GMM:\n$log p(f_i) = log \\left( \\sum_{k=1}^K \\pi_k N(f_i | \\mu_k, \\Sigma_k) \\right)$\nwhere N(fi|\u03bc\u03ba, \u03a3\u03ba) is the probability density function of the Gaussian distribution with mean \u03bc\u03b5 and covariance \u03a3\u03ba.\n3. Determine Outliers: Identify the outliers as those points whose log-likelihood is below a certain threshold. This threshold can be defined as a certain percentile of the log-likelihood values. For example, consider the bottom 10\nthreshold = percentile({logp(fi)}=1,10)\nwhere N is the total number of feature vectors.\n4. Outlier Identification: Points with log-likelihood values less than the threshold are marked as outliers:\noutliers = {f; | log p(fi) < threshold}\nGMM provides a probability distribution over clusters for each data point. This means each point can belong to multiple clusters with different probabilities. The choice of K (number of components) is crucial. It can be selected based on prior knowledge, or determined using model selection criteria like the Bayesian Information Criterion (BIC) or the Akaike Infor- mation Criterion (AIC), which balance model fit and complexity. Another approach would be by varying a combinations of GMM components and PCA dimensions one can control and optimize outliers selection."}, {"title": "3. Numerical study", "content": "The purpose of the numerical study was to determine if better responses could be obtained for a query using a filtered context (excluding outlier documents) compared to using the context based solely on a set of documents retrieved from the retrieval language model. Our base text-to-text model was 'TinyLlama/TinyLlama-1.1B-Chat-v1.0,' which, although rather small, proved to be a good choice for research and allowed us to conduct extensive experiments on a regular laptop. We also tested the proposed method with the 'mistralai/Mistral-7B-Instruct-v0.2' model and obtained very similar results but at a much higher cost.\nAs a document retriever, we used a popular sentence transformer model, \u2018sentence-transformers/all- mpnet-base-v2,' which can be used as a text to dense vectors converter. With this model we con- verted all chunked documents and stored them in a FAISS vector database developed by Facebook Research [10]. All models we used are publicly available in Hugging Face hub [11].\nFor testing, we used various datasets. The results of this study are obtained with SQuAD2.0 - The Stanford Question Answering Dataset, which includes a mixture of 35 topics covering political aspects, geography, mathematics, chemistry, religion, etc., ranging from \u201cAmazon Rainforest\u201d to \"Yuan Dynasty,\u201d from \u201cPharmacy\u201d to \u201cPrime Numbers.\u201d To generate questions and corresponding"}, {"title": "", "content": "answers for a benchmark, we leveraged the extensive knowledge and capabilities of the OpenAI GPT-40 model with the uploaded dataset text. The following three categories of questions and corresponding answers were generated:\n\"Simple\"\nQuestions that allow for a short simple answer, such as:\n\u2022 When did the 1973 oil crisis begin?\n\u2022 What did Nixon request from Congress on October 19, 1973?\n\"Broader\"\nQuestions that require to provide detail and insight, such as:\n\u2022 What allowed the tropical rainforest to spread out across the continent after the Creta- ceous-Paleogene extinction event?\n\u2022 How did the construction of highways in the Amazon lead to deforestation?\n\"Double\"\nTwo questions of \u201cbroader\u201d type combined in one, such as:\n\u2022 What caused the recurrence of plague outbreaks in Europe until the 19th century and how did the rise of the Andes Mountains create the Solim\u00f5es Basin?\n\u2022 What led to the creation of the National Energy Act of 1978 and what caused the Amazon rainforest to be considered unsustainable by 2100?\nWhen splitting text documents into chunks we tried to select a max chunk size so that the number of tokens from 20 \u2013 25 chunks, considered as documents, does not exceed the sequence length of the model, which in case of TinyLlama-1.1B-Chat-v1.0 model is 2048.\nIn Outlier Detection section we described the method of selecting outliers from a given set of feature vectors. This selection depends on the number of GMM components (clusters). For example in case of \"interaction\u201d method the size of the feature vector f\u00bf is 4. This is because the feature vector is composed of four components:\n1. $d_{centroid}$\n2. $d_{query}$\n3. $d_{centroid} \u00d7 d_{query}$\n4. $\\frac{d_{centroid}}{d_{query} +\u20ac}$"}, {"title": "", "content": "Each of these components represents a different feature derived from the distances $d_{centroid}$ and $d_{query}$. Then, by projecting these 4 features to principal components using PCA and selecting 2, 3, or 4 components, another leverage for controlling the clustering mechanism is introduced. We will use the following notation in selecting outliers:\n\u2022 Number of clusters: [4, 5, 6]\n\u2022 PCA dimensions: [2, 3]\nBy running the double loop over the number of clusters and PCA dimensions we will be getting different sets of outlier documents and some of them will be common. The final set of outliers will be those that are common or those that that are common at least at certain given number of occurrences. We will call it \"min outlier frequency\u201d denoted by \"freq\".\nWe will use the following experiment setup:\n\u2022 Text-to-text model: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\nMax Sequence Length: 2048\n\u2022 Retrieval Model: \u2018sentence-transformers/all-mpnet-base-v2'\n\u2022\nmax_seq_length: 384\nsentence_embedding_dimension: 768\nmax_new_tokens: 1500\n\u2022 Number of Docs: 20\n\u2022 Threshold Percentile: 15%\n\u2022 Number of clusters: [4, 5, 6]\n\u2022 PCA dimensions: [2, 3]\nWe use the following simple template to form a query prompt to the model that includes a short instruction, context and the query itself:\nformatted_prompt\n=\nf'''\nYou are a friendly chatbot who responds to the user's question by\nlooking into context.</s>\nContext:\n{context}\n</s>\nQuestion: {question}</s>\n'''"}, {"title": "", "content": "Context consists of documents retrieved on a query from the vector database. We call it a \"fil- tered prompt\" when all outliers are removed from the context. The response to a filtered prompt is compared with the ground-truth response. The same is done with the \"original prompt,\u201d where the context consists of the same number of first documents retrieved from the database. For compari- son, we use two types of similarity metrics: cosine (dense vector) similarity and TFIDF similarity based on tokens. Our purpose is to determine the improvement received when using \"filtered prompts\" over \"original prompts\u201d with respect to these similarities. For query Qi, let Rg; be the ground truth response, Rf\u00bf be the filtered response, and Ro\u00bf be the original response. The improve- ment in similarity can be expressed as the difference in similarities of Rf; to Rg, and Ro; to Rg divided by the similarity of Roz to Rgi:\nImprovement; =\n$\\frac{Similarity (Rf\u2081, Rg\u2081) \u2013 Similarity (Roi, Rg\u2081)}{Similarity (Ro\u2082, Rgi)}$\nWhere:\n\u2022 Similarity(Rf\u00bf, Rg\u00bf) is the similarity between the filtered response and the ground truth re- sponse.\n\u2022 Similarity (Ro\u2082, Rg\u2081) is the similarity between the original response and the ground truth response.\nThe average improvement over N questions can be calculated as follows:\nAverage Improvement =\n$\\frac{1}{N} \\sum_{i=1}^N Improvement_i$\nWhere:\n\u2022 N is the total number of questions.\n\u2022 Improvement; is the improvement for question Qi."}, {"title": "4. Conclusion", "content": "In conclusion, this study demonstrates the efficacy of filtering outlier documents to improve the quality of responses in question-answering systems using retrieval-augmented generation (RAG). By removing documents that are semantically irrelevant or far from the query, we have shown that the context can be significantly refined, leading to more accurate and relevant answers. Besides, a reduced context length is beneficial it terms of computational cost required to produce the response by the model.\nOur experiments with different text-to-text models, including 'TinyLlama/TinyLlama-1.1B- Chat-v1.0' and 'mistralai/Mistral-7B-Instruct-v0.2,' revealed that even smaller models benefit from this approach, making it feasible to conduct extensive research on standard hardware. The use of a sentence transformer model, 'sentence-transformers/all-mpnet-base-v2,' for document retrieval further reinforced the robustness of our method across diverse datasets, including the SQuAD2.0 dataset.\nThe key observations from our experiments indicated that: 1. The \"interaction\u201d method pro- vided the most significant improvement in similarity metrics. 2. Higher \"min outlier frequency\" led to better similarity improvements, albeit at the cost of increased computational demands. 3. The balance parameter a played a certain role in enhancing the feature representation for out- lier detection. 4. The complexity of questions had a profound impact on the effectiveness of the filtering mechanism, with more complex queries benefiting the most from the refined context.\nOverall, this study highlights the potential for enhanced context retrieval methods to address challenges in RAG systems, particularly when dealing with complex queries. Future work will focus on further optimizing the outlier detection mechanisms and exploring their applicability to other datasets and use cases."}]}