{"title": "A GEN AI Framework for Medical Note Generation", "authors": ["Hui Yi, Leong", "Yi Fan, Gao", "Shuai, Ji", "Bora Kalaycioglu", "Uktu Pamuksuz"], "abstract": "The increasing administrative burden of medical documentation, particularly through Electronic Health Records (EHR), significantly reduces the time available for direct patient care and contributes to physician burnout. To address this issue, we propose MediNotes, an advanced generative Al framework designed to automate the creation of SOAP (Subjective, Objective, Assessment, Plan) notes from medical conversations. MediNotes integrates Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech Recognition (ASR) to capture and process both text and voice inputs in real time or from recorded audio, generating structured and contextually accurate medical notes. The framework also incorporates advanced techniques like Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning (PEFT) for efficient model fine- tuning in resource-constrained environments. Additionally, MediNotes offers a query-based retrieval system, allowing healthcare providers and patients to access relevant medical information quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate that MediNotes significantly improves the accuracy, efficiency, and usability of automated medical documentation, offering a robust solution to reduce the administrative burden on healthcare professionals while improving the quality of clinical workflows.", "sections": [{"title": "I. INTRODUCTION", "content": "Despite the widespread adoption of Electronic Health Records (EHRs), clinicians are increasingly overwhelmed by the management of vast amounts of medical data. This overload can lead to errors and negatively impact the quality of healthcare delivery, especially when the data is incorrect, incomplete, or irrelevant. Physicians are particularly burdened by administrative tasks, with documentation consuming between 25% and 50% of their time [1]. The extensive effort required for collecting, processing, and documenting dialogue data significantly reduces the time available for patient care, education, and clinical research [2].\nArtificial Intelligence (AI), particularly Large Language Models (LLMs), is progressively transforming medical practice by offering innovative solutions to these challenges. LLMs have been utilized in healthcare for applications such as clinical decision support, medical writing, and patient interaction assistance [3]. However, their application in medical dialogue summarization remains underexplored. Given their capacity to process large volumes of unstructured data and generate coherent text, LLMs hold significant potential for tasks like summarizing patient information and assisting with medical documentation [3].\nIn this research, we continue previous study of fine-tuned model automated medical documentation [4], we introduce MediNotes, a generative AI framework designed to alleviate the documentation burden on healthcare providers. from what we the first framework Leveraging advanced speech recognition technologies and LLMs, MediNotes aims to generate SOAP (Subjective, Objective, Assessment, and Plan) notes from medical conversations in real time. The framework employs ambient listening to record interactions and automatically transcribes them into structured medical notes, thereby significantly reducing the time physicians spend on documentation. To ensure high-quality outputs, state-of-the-art Natural Language Processing (NLP) techniques are integrated to enhance accuracy and relevance.\nFurthermore, MediNotes incorporates a user-friendly chatbot that enables patients and healthcare professionals to access relevant medical information quickly and efficiently. Utilizing a vector database and Retrieval-Augmented Generation (RAG), the system performs contextual searches to provide precise and appropriate information. By streamlining these processes, the framework aims to improve patient care and enhance the overall efficiency of healthcare delivery."}, {"title": "II. RELATED WORK", "content": "The administrative burden on physicians is a critical issue in healthcare, with documentation tasks consuming up to 50% of their time [1]. This significant allocation detracts from patient care and contributes to physician burnout. Consequently, there is a pressing need for automation in clinical documentation to alleviate this workload.\nEarly attempts to automate this process involved statistical machine translation systems designed to convert patient-doctor interactions into written records. While innovative, these systems often failed to capture the complexity and nuances of medical discourse, leading to unreliable documentation [5]. The introduction of transformer-based models marked a significant advancement in natural language processing (NLP); however, their high computational requirements posed challenges for clinical settings.\nTo address these challenges, recent research has explored methods to reduce computational demands without compromising performance. Leong et al. [4] proposed the use of Low-Rank Adaptation (LoRA), Parameter-Efficient Fine- Tuning (PEFT), and instruction fine-tuning techniques to efficiently fine-tune Large Language Models (LLMs) for automated medical documentation in resource-constrained environments. While this approach enhances computational efficiency, limitations remain. The accuracy of the generated documentation can still be improved, and these LLMs convert notes but lack the ability to memorize or update with the latest information. Additionally, they process text input exclusively and cannot interpret voice data, restricting their utility in real- time clinical settings. Therefore, incorporating additional functionalities is necessary to enhance the documentation process.\nBeyond physician workload, patient recall of medical information is a significant concern. Studies have shown that patients forget 40\u201380% of the medical information provided by healthcare practitioners immediately after consultations [6]. This lapse negatively impacts patient outcomes and adherence to treatment plans. To assist patients in retrieving medical information, LLMs need to access external sources. Retrieval- Augmented Generation (RAG) has emerged as a promising technique in this context. RAG often combine pre-trained sequence-to-sequence models which is LLM with dense vector indexes of external databases, accessed through neural retrievers [7]. Thus, it enhances the accuracy and factuality by retrieving relevant data during text generation, thereby aiding both patients and healthcare providers\nEven with advancements in automation and retrieval, challenges persist. The process of generating and retrieving information still requires manual input; users need to type queries into LLMs to generate responses. This requirement is particularly burdensome given the sheer volume of clinical notes.\nData indicates that physicians generated 104 million notes for 1.9 million unique patients, totaling approximately 33 billion words in 6 years [8]. To alleviate some of this burden, the medical industry has increasingly turned to ambient listening and Automatic Speech Recognition (ASR) technology. ASR facilitates the automatic transcription of spoken language into text, enabling real-time documentation of patient-doctor interactions without manual input [9]. However, integrating ASR with LLMs to create a seamless, voice-activated documentation system remains an area requiring further exploration.\nIn addition to the prior works, other relevant research on automation for medical note generation and retrieval has made notable contributions, such as [10] and [11]. MedKnowts integrates a note-taking editor into Electronic Health Records (EHR) systems with information retrieval functionalities, streamlining clinical documentation and reducing the cognitive load associated with accessing patient data. However, despite its advantages, MedKnowts still requires significant manual input, relying on users to interact with the note-taking editor, which limits its efficiency in high-volume clinical settings that demand real-time documentation [10]. Similarly, [11] proposes natural language processing (NLP) models for aligning clinical dialogue with notes and summarizing patient visits. While this approach demonstrates potential for improving documentation, it primarily focuses on sentence alignment, restricting its adaptability to complex and dynamic medical conversations. Furthermore, it lacks real-time interaction capabilities, limiting its practical application in fast-paced clinical environments.\nIn contrast, our proposed solution\u2014MediNotes-from what we understand the first framework study offers a more advanced Al-driven approach by integrating Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech Recognition (ASR) technologies for medical note generation. By leveraging ambient listening, real-time voice transcription, and context-aware retrieval of medical information, MediNotes addresses the limitations of manual input and static summarization seen in previous works. This comprehensive AI solution not only reduces the administrative burden on physicians but also enhances the accuracy and efficiency of medical note generation by operating in real-time, thereby providing more advanced support in high-stakes healthcare environments."}, {"title": "III. METHODOLOGY", "content": "The proposed MediNotes framework integrates Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech Recognition (ASR) technologies to streamline medical note generation. The framework is designed to handle two main scenarios: generating SOAP (Subjective, Objective, Assessment, Plan) notes from medical conversations in real-time and retrieving relevant medical information based on user queries. The overall architecture of MediNotes is depicted in Figure 1, which demonstrates the flow from voice or text input to the generation and retrieval of structured medical documentation.\nIn Scenario 1, MediNotes operates in real-time, capturing both text and voice inputs during medical consultations. Using its integrated ASR system, the framework passively listens to conversations between physicians and patients, automatically transcribing spoken dialogue into structured SOAP (Subjective, Objective, Assessment, Plan) notes. The transcription is processed through an audio encoder, followed by fine-tuned LLM models, which refine and organize the content into detailed medical notes. This process significantly reduces the manual effort required for documentation, allowing physicians to focus more on patient care. The generated SOAP notes are stored in a vector database, enabling future retrieval for reference or further medical use.\nIn Scenario 2, MediNotes serves as a query-based retrieval system where both healthcare providers and patients can access medical information. Users can input their queries either through text or voice. The query is processed by an text encoder and sent to a Retrieval-Augmented Generation (RAG) model. The system searches the vector database for relevant content based on the user's query, retrieves contextual information, and formulates an appropriate response through the LLM. This scenario provides users with quick, accurate, and context-aware medical information, streamlining clinical workflows and improving the accessibility of essential data."}, {"title": "A. Audio Encoder", "content": "The MediNotes framework incorporates an audio encoder coupled with a robust Automatic Speech Recognition (ASR) system to facilitate both real-time and non-real-time transcription of medical conversations. During interactions, the ASR system can capture voice inputs either in real-time as conversations occur or from pre-recorded audio files. This flexibility allows the system to handle both live clinical consultations and retrospective transcription of recorded sessions, providing physicians with a versatile solution for medical note generation.\nAt the core of the ASR system is the Whisper-base model, which ensures high-fidelity speech-to-text conversion. Additionally, the integration of Pyannote-segmentation-3.0 for speaker diarization enables the framework to accurately identify and differentiate between the voices of multiple participants (e.g., physician and patient). The audio encoder captures and processes the input, whether in real-time through the user interface or from recorded audio, before the transcription is tokenized and passed through the LLM for further processing."}, {"title": "B. Dataset and Data Preprocessing", "content": "To train and fine-tune the MediNotes model, we utilized the ACI-BENCH dataset [1], which contains 207 doctor-patient role-play dialogues, each averaging 1,302 tokens, with corresponding SOAP notes averaging 490 tokens. The dataset was split into three subsets: 67 dialogues for training, 20 for validation, and 120 for testing, further divided into three test sets. This dataset was selected for being the largest publicly available corpus of medical notes, encompassing outpatient scenarios, thereby improving the model's capacity to generalize across routine medical consultations.\nThe preprocessing phase involved several key steps:\n\u2022 Data Cleaning: filling in missing values, removing outliers, and smoothing noisy data.\n\u2022 Text Normalization: Removal of irrelevant characters and standardization of medical terms.\n\u2022 Tokenization: Both dialogues and SOAP notes were tokenized using a SentencePiece tokenizer pre-trained on medical texts."}, {"title": "C. Generator Model", "content": "Given the need for an advanced model capable of maintaining context in lengthy and complex medical dialogues, we selected LLaMA3-8B for its optimal balance between performance and resource efficiency. This model is specifically designed to handle long-range dependencies, making it well- suited for clinical dialogue summarization tasks. Additionally, GEMMA-7B and Mistral-7B were included for ablation studies to compare different model architectures and their effectiveness. These models excel in accuracy and adaptability, while also being highly efficient for fine-tuning using advanced techniques such as QLoRA and PEFT, ensuring they scale well in real- world healthcare applications."}, {"title": "dff", "content": "To ensure that the LLM remains both accurate and computationally efficient, we employed two advanced fine- tuning techniques tailored for resource-constrained environments:\na) Parameter-Efficient Fine-Tuning (PEFT) [12]: PEFT fine-tunes only a small subset of critical model parameters, significantly reducing computational requirements. We set r = 16 and targeted key modules (q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj) responsible for attention and feed-forward operations. The lora_alpha was set to 16 to optimize scaling of the low-rank matrices, ensuring efficient training while maintaining high accuracy.\nb) Quantized Low-Rank Adaptation (QLORA) [13]: QLoRA reduces memory consumption by quantizing model parameters to 4 bits, allowing for efficient fine-tuning without compromising performance. This approach is ideal for healthcare settings where computational resources are limited, enabling the model to perform high-precision tasks, such as medical documentation, on standard hardware.\nc) Instruction Tuning: This method ensures that the model generates coherent and structured SOAP notes by training it with specific task instructions. It improves the model's ability to organize conversations into distinct sections (Subjective, Objective, Assessment, and Plan).\nAdditionally, SOAP notes generated by the system are encoded into PDF format and sent to both the chatbot and the RAG pipeline for storage in the vector database. This ensures that the notes are readily accessible for future retrieval, enhancing the system's capability to provide quick, accurate information when queried."}, {"title": "D. Retriever", "content": "The MediNotes framework utilizes Retrieval-Augmented Generation (RAG) to efficiently manage both medical note generation and information retrieval. This approach enhances the system's ability to handle text inputs from various sources, including user queries and converted voice conversations. The process begins by splitting the input text into smaller, manageable chunks using the RecursiveCharacterTextSplitter, which facilitates more efficient processing and retrieval.\nOnce the input text is segmented, the system transforms these text chunks into numerical representations, or embeddings, using open-source embedding models provided by Langchain. These embeddings capture the semantic meaning of the text, allowing the system to understand and retrieve relevant information based on context. The embeddings are stored in a vector database via the PGVector extension in an open-source PostgreSQL database. This vector store serves as the memory of the language model, allowing efficient retrieval of previously documented notes or other relevant content through vector similarity searches.\nWhen a user submits a query either via text input or through voice converted to text-the query is also converted into an embedding. This embedding is then used to search the vector store for related chunks of information. The relevant chunks retrieved from the vector database are combined with a predefined system prompt, and this augmented prompt is processed by the LLM to generate an accurate and contextually relevant response."}, {"title": "IV. RESULTS AND DISCUSSION", "content": "We employed a combination of quantitative metrics- ROUGE, BERTScore, and BLEURT for evaluating the MediNotes model along with qualitative assessments to evaluate the performance of the MediNotes framework. The quantitative metrics measured the accuracy, relevance, and coherence of the generated medical reports, while the qualitative assessments involved expert reviews by medical professionals. Our fine-tuned model, MediNotes LLM, based on LLaMA3-8B, was evaluated using the ACI-BENCH dataset across three test sets to ensure consistent and reliable results across diverse doctor- patient dialogues."}, {"title": "B. Framework Evaluation Results", "content": "A clinical evaluation was conducted in collaboration with the University of Chicago Medical Center to assess the performance of the MediNotes framework. Medical professionals reviewed the generated notes and data retrieval responses, evaluating them for accuracy, completeness, satisfaction, and usefulness. The study involved 10 doctors and 10 patients, each participating in 8 recorded conversations facilitated by the chatbot, as well as testing the chatbot with 8 query-based interactions.\n\u2022 Accuracy: The percentage of correct information provided by the system compared to a gold standard.\n\u2022 Completeness: The degree to which the system captures all necessary information.\n\u2022 Satisfaction: User satisfaction levels based on feedback surveys.\n\u2022 Usefulness: The perceived utility of the system in aiding users' tasks."}, {"title": "C. Ablation Studies", "content": "To better understand the impact of different model architectures and fine-tuning methods, an ablation study was performed to compare the performance of several models, including LLaMA3-8B, Mistral-7B, Gemma-7B, and Phi-3- mini-4k-instruct. This comparison aimed to isolate the effects of both model architecture and fine-tuning approaches, such as QLoRA and PEFT, on the overall performance of medical note generation tasks."}, {"title": "A. Limitations", "content": "The dataset used to train the MediNotes model faces significant limitations due to the sensitive nature of medical information and strict privacy regulations, such as HIPAA in the U.S. Acquiring real clinical data, especially recordings of patient-doctor conversations, is difficult because sharing such data risks compromising patient confidentiality. As a result, the dataset is relatively small and may rely on synthetic or anonymized data. Although this allows for the development of a functional model for clinical dialogue and note generation, it may not fully capture the diversity and complexity of real-world medical encounters, potentially affecting the model's generalization performance.\nAdditionally, the diversity of clinical language is a critical factor. While the dataset includes some variety in dialogue styles, expressions, and medical terminology from different healthcare providers and patients, it may lack the comprehensive scope required to train the model for a broad range of interactions. If the dataset is not sufficiently diverse, the model's ability to accurately understand and generate notes for varying dialogue patterns and medical language may be constrained. Therefore, to improve the model's adaptability and performance across diverse clinical environments, it is vital to incorporate a more representative and diverse dataset in future development efforts."}, {"title": "B. Application", "content": "To MediNotes could be integrated into hospital Electronic Health Record (EHR) systems to automate the real-time generation of medical notes from patient-doctor conversations. By capturing spoken consultations via Automatic Speech Recognition (ASR), it can generate structured notes like SOAP (Subjective, Objective, Assessment, Plan) that are instantly stored in the EHR. This reduces the time physicians spend on documentation, allowing them to focus more on patient care. In addition to generating notes, MediNotes can assist physicians by providing real-time access to critical patient data, such as previous lab results or diagnoses, supporting clinical decision- making. In telehealth settings, MediNotes can ensure efficient documentation and streamline the sharing of notes with other healthcare providers or patients.\nPatients could also benefit from MediNotes by having access to their own medical records through the EHR system, enabling them to review their health information or treatment plans. However, the implementation of MediNotes comes with challenges. Ensuring data privacy and security in compliance with regulations like HIPAA is crucial, while addressing interoperability issues with different EHR systems will require tailored APIs and middleware. Additionally, adoption by healthcare staff may be slow without adequate training, making it necessary to demonstrate the efficiency and accuracy gains of the system to encourage widespread use."}, {"title": "C. Ethical considerations", "content": "Ethical considerations surrounding the integration of AI in healthcare, particularly regarding privacy and model bias, are critical. The sensitive nature of medical data necessitates stringent privacy protections, ensuring that patient information remains confidential and secure. Moreover, Al system like MediNotes must be rigorously tested to prevent biases that could lead to unequal treatment or inaccuracies in medical documentation. Transparency in how these models function and make decisions is essential to building trust among both healthcare providers and patients. Accountability is also key, with physicians maintaining oversight to validate AI-generated notes, ensuring that AI supports rather than replaces clinical judgment, thus safeguarding the quality of care."}, {"title": "VI. CONCLUSION", "content": "In conclusion, MediNotes presents a promising solution to alleviate the administrative burden on healthcare professionals by automating medical note generation through advanced Al techniques. By integrating large language models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech Recognition (ASR), it enables real-time documentation that improves the efficiency of clinical workflows. The framework has demonstrated superior performance in producing accurate, structured, and contextually relevant medical notes. However, while MediNotes has shown considerable potential, there is room for future improvements. Expanding the diversity of training datasets to better capture the range of clinical interactions and medical terminology will enhance the model's adaptability. Further advancements in data privacy, security, and model bias mitigation are essential to ensure ethical and safe integration into healthcare systems. Additionally, incorporating more sophisticated retrieval techniques and expanding interoperability with various EHR platforms could further boost its functionality, making MediNotes an even more effective tool in modern medical environments."}]}