{"title": "Quantifying Behavioural Distance Between Mathematical Expressions", "authors": ["Sebastian Me\u017enar", "Sa\u0161o D\u017eeroski", "Ljup\u010do Todorovski"], "abstract": "Existing symbolic regression methods organize the space of candidate mathematical expressions primarily based on their syntactic, structural similarity. However, this approach overlooks crucial equivalences between expressions that arise from mathematical symmetries, such as commutativity, associativity, and distribution laws for arithmetic operations. Consequently, expressions with similar errors on a given data set are apart from each other in the search space. This leads to a rough error landscape in the search space that efficient local, gradient-based methods cannot explore. This paper proposes and implements a measure of a behavioral distance, BED, that clusters together expressions with similar errors. The experimental results show that the stochastic method for calculating BED achieves consistency with a modest number of sampled values for evaluating the expressions. This leads to computational efficiency comparable to the tree-based syntactic distance. Our findings also reveal that BED significantly improves the smoothness of the error landscape in the search space for symbolic regression.", "sections": [{"title": "1. Introduction", "content": "Mathematical modeling of an observed phenomenon is omnipresent in many scientific and engineering fields. Addressing the task requires human experts to follow tedious and time-consuming trial-and-error endeavors, which include a combination of reasoning from basic principles and parameter fitting. Equation discovery, also referred to as symbolic regression, addresses the task of finding mathematical equations that fit a given data set well and allows for the automation of these endeavors. The significant advantage of equations over other models obtained from data by using machine learning methods is their ability to provide a concise, human-readable, and interpretable way to represent complex relationships between the observed variables.\nSymbolic regression methods typically employ combinatorial search through the space of candidate mathematical expressions, i.e., model structures, together with numerical optimization for fitting the values of the model parameters to data. Methods mainly differ in how the space of equations is ordered and searched. However, most symbolic regression methods, if not all, assume a search space where syntactically similar expressions are close to each other. The prevailing paradigm, evolutionary optimization (Schmidt & Lipson, 2009) use genetic operators of crossover and mutation, which apply a sequence of edits to the expression trees to generate new expression from existing ones. The structure of the search space of symbolic regression methods thus follow the Levenshtein distance (Levenshtein, 1965), which calculates the number of edits required to transform one expression into another. However, syntactically similar expressions can significantly differ when their behavior, i.e., evaluations, are considered. For example, expressions $c + x$ and $cx$, where $c$ and $x$ denote a constant parameter and an observed variable, respectively, are syntactically similar (note that the Levenhstein distance between them is minimal, i.e., equals 1), but their evaluations for given values of $c$ and $x$ differ significantly. This also means that the error of similar expressions on a given data set will vary substantially, which renders simple, local search methods, like gradient descent, inappropriate for searching the space of equations (Tanevski et al., 2020).\nIn this paper, we propose a distance measure between mathematical expressions that captures the nuances of their behavior. The proposed measure should cluster expressions"}, {"title": "2. Related work", "content": "The distance between mathematical expressions is often measured by the Levenshtein distance (Levenshtein, 1965) between the corresponding string representations of the expressions in the in-fix notation. Alternatively, the distance between expression trees can be measured by using tree-edit distance (Zhang & Shasha, 1989). Both measures calculate the distance as the minimal number of elementary edit operations (add, remove, or edit a sequence symbol or a tree node) needed to transform one expression into another. These distances operate on the symbolic representations of the mathematical expressions as sequences or trees. In the more general context of code similarity (Walenstein et al., 2007), they are considered instances of the prevailing paradigm of representational or syntactic similarity.\nIn contrast, semantic or behavioral similarity aims to assess the similarity of the functions that the compared programs implement. Computational methods for aspects of semantics that can be captured by specific program representations, such as control-flow graphs (Nair et al., 2020). Another relevant aspect of code similarity, not related to program representation, is measuring the fraction of inputs for which two programs produce the same output (Walenstein et al., 2007). While this is considered an important aspect of code similarity when identifying code clones (Juergens et al., 2010), it would also be very relevant for comparing mathematical expressions. To this end, to the best of our knowledge, there are no readily available computational methods for assessing it.\nDespite the variety of techniques for searching through the space of mathematical expressions used in symbolic regression, the search space itself is commonly structured around the syntactic similarity between expressions. Take, for example, the prevailing approach in symbolic regression, i.e, genetic programming (Koza, 1994; Schmidt & Lipson, 2009; Cranmer, 2023). It represents mathematical expressions as expression trees and performs simple operations on the latter to transform the expressions from the current population into new expressions. The operations, such as crossover and mutation, are, in fact, sequences of elementary edits of the expression trees and, therefore, closely align with the concept of the syntactic tree-edit distance. Similarly, grammar-based methods search through the space of parse trees, where the most straightforward parse tree is considered first, and more complex parse trees are generated systematically by simple revisions of the existing ones based on the grammar rules (Todorovski & Dzeroski, 1997). Consequently, parse trees close to each other in the search space correspond to syntactically similar expressions. Similarly, process-based modeling (Bridewell et al., 2008) systematically explores the space of candidate models by exhaustively enumerating all expressions with simple edit operations of adding or changing a process.\nIn recent years, a growing body of research has explored the use of generative neural networks to embed expressions into a latent space where expressions with similar syntactic structures occupy close proximity (Kusner et al., 2017; G\u00f3mez-Bombarelli et al., 2018; Me\u017enar et al., 2023). These approaches then employ optimization algorithms to navigate this latent space and generate new expressions with similar syntactic properties. While these approaches do not explicitly use edit distance or tree-edit distance metrics during training, the underlying structure of the latent space aligns with these measures, effectively clustering syntactically similar expressions together. DSO (Petersen et al., 2021) further extends this concept by incorporating reinforcement learning and evolutionary algorithms to guide the search for new expressions. However, this approach's spatial relationships between expressions still largely mirror the neighborhoods defined by edit and tree-edit distance metrics. Finally, Symbolic-Numeric Integrated Pre-training, SNIP (Meidani et al., 2023) diverges from this trend by employing two transformer-based encoders, one for symbolic and one for numeric data. Note, however that SNIP requires a subsequent fine-tuning stage that utilizes syntactic similarity measures."}, {"title": "3. Behavioural distance between expressions", "content": "In the first part of this section, we introduce the challenges associated with the quantification of behavioural distance. In the second part, we present our solution to these challenges by defining the behaviour-aware expression distance, BED."}, {"title": "3.1. Challenges with behavioural distance", "content": "Mathematical expressions are often used as a discrete representation of a curve in continuous space. We can think of expressions in two ways, depending on what we want to do with them. On the one hand, we can represent them as a sequence of symbols in infix notation, which is a concise and precise way to write them down. This representation is convenient for evaluating expressions with specific values and conveying their general characteristics. On the other hand, we can visualize mathematical expressions as curves on a graph. This visualization helps us understand how an expression behaves and how similar it is to another expression. In this paper, we try to quantify this behavioural distance between two expressions in order to ease exploration of the space of expressions.\nBehavioural distance between expressions has several aspects. The first is the presence of constants with unknown values within expressions. Two expressions with identical structure can exhibit distinct behavior if their constants differ in value. Consider the expression $c \\cdot x^2$, where $c$ represents a constant. The behavior of this expression varies considerably depending on the value of $c$. For instance, when $c = 1$, the expression represents a simple parabola, while when $c = -1$, it becomes a downward-facing parabola. This poses a significant challenge for the metric in the context of symbolic regression, where generating expressions with known values of the constants is more difficult and produces worse results than generating the structure of an expression and subsequently replacing placeholder constant symbols with specific values through numeric optimization. Consequently, symbolic regression models generate expressions with unknown constants between which it is hard to define a distance.\nAnother aspect is the domain of the expression variables. Two expressions might exhibit similar behaviour over one domain, but diverge significantly when observed over another domain. For example, the expressions $x$ and $sin x$ exhibit similar behaviour over the domain $[-0.5, 0.5]$ but diverge significantly over the domain $[-100, 100]$. This fact makes us believe that behavioural distance between expressions must be data driven, as different domains drive expression closer or further apart.\nBuilding on these insights, we introduce the behavior-aware expression distance (BED), an unsupervised yet data-driven metric for quantifying the distance between mathematical expressions."}, {"title": "3.2. Behaviour-aware expression distance", "content": "Consider a specific input value of the expression variable(s) $x$. An expression $u$ without constants evaluates to a single output value $y = u(x)$. However, expressions involving constants with unknown values can be evaluated multiple times with different values of the constants, resulting in a set $Y = u(x)$ of output values. This set, along with the frequency of each output value, represents a probability distribution over the possible expression evaluations for a given $x$. This distribution captures the uncertainty associated with the expression's output caused by varying the values of the constants. In other words, we can model the output value of the expression $u$ at $x$ as a random variable $U(x)$ with the cumulative distribution function $F_{U(x)} (y)$.\nBy treating expressions' evaluations (outputs) at a specific input value as random variables and probability distributions, we can employ distance metrics from probability theory to quantify their dissimilarity. One possible choice is the p-Wasserstein distance, also known as Earth Mover's Distance, EMD (Villani, 2009). The Wasserstein distance measures the minimum amount of work required to transform one distribution into another. This option is particularly well-suited for our problem because it considers the relative importance of different output values rather than simply comparing their means or variances. Additionally, it has been shown to effectively capture human perception of similarity (Rubner et al., 2000). The p-Wasserstein distance is defined by the Eq. (1), where $\\Gamma(F, G)$ represents the set of all couplings between random variables $E$ and $G$, i.e., pairs of random variables $(D, H)$, such that $D$ and $H$ have the same distributions as $E$ and $G$, respectively.\n$W_p(E, G) = \\inf_{\\pi \\in \\Gamma(E,G)} \\left( \\int_{\\mathbb{R} \\times \\mathbb{R}} ||D - H||^P d\\pi \\right)^{\\frac{1}{P}}$   (1)\nIf we assume that the expressions evaluate to real numbers, we can simplify the calculation of the p-Wasserstein distance using the quantile function (inverse cumulative distribution function) of the corresponding random variable, denoted by $Q_{U(x)} (q) = F_{U(x)}^{-1}(y)$. Specifically, we use Eq. (2) (Ramdas et al., 2017), which directly relates the distance between distributions to their quantile functions. This approach offers computational advantages as it allows us to focus on a single coupling, rather than evaluating all possible couplings and selecting the one with the minimum value. The simplified equation also provides a more intuitive interpretation of the distance, as it directly relates to the differences in the quantile functions of the distributions.\n$W_p(E,G) = \\left(\\int_{0}^{1} |Q_E(q) - Q_G(q)|^P dq \\right)^{\\frac{1}{P}}$  (2)\nWe can now employ Eq. (2) to quantify the distance between two expressions $u$ and $v$ at a specific value of their variables $x$. However, to comprehensively assess their overall resemblance, we need to consider their behavior across the entire input domain X. To achieve this, we integrate the p-Wasserstein distance over the entire domain and normalize the result by the volume of the domain. Eq. (3) embodies this approach, where $Vol(X)$ represents the volume of the domain $X$, and $F_{U(x)}$ the cumulative distribution of the output for expression $u$ at input $x$.\n$BED_p(u, v) = \\frac{1}{Vol(X)} \\int_X W_p(F_{U(x)}, F_{V(x)}) dx$  (3)\nTo overcome the computational intractability of directly evaluating Eq. (3), we follow an approximation strategy outlined here. We first restrict the domain of the expressions' constants to a finite interval $[a, b]$, which encapsulates domain knowledge or biases regarding the acceptable range of the constants. For each expression, we employ Latin Hypercube Sampling, LHS (McKay et al., 1979) to generate a predefined number of distinct sets of constants' values $C_i$ from the given interval. LHS ensures that the selected constants are more representative of the entire range of possible values, compared to random sampling. We similarly sample points $x$ from a predefined domain $X$ using LHS.\nWe approximate the 1-Wasserstein distance using Eq. (4). In the equation, $Y_{u,x} = u(x)$ represents the set of output values we obtain by evaluating expression $u$ at $x$ using constant values $C_i$, $Y_x = Y_{u,x} \\cup Y_{v,x}$, $y_k$ is the $k$-th smallest value in the set $Y$, and $d_k = y_{k+1} - y_k$. The approximation of the cumulative distribution function $F_U$ is defined by using Eq. (5).\n$W_1(u,v,x) = \\sum_{k=1}^{|Y_x|-1} d_k |F_{U(x)} (y_k) - F_{V(x)} (y_k)|$  (4)\n$F_U(x) (y) = \\begin{cases} 0; & y < y_1 \\\\ \\frac{k}{|Y_u|}; & y_k \\leq y < y_{k+1} \\\\ 1; & otherwise \\end{cases}$   (5)\nSince we do not have guarantees that the sets $Y_{u,x}$ and $Y_{v,x}$ are non-empty (due to failures of expression evaluation for given values of the variables and constants), two border cases can occur. In the first case, when both sets are empty, we can assume the distance between them is 0. In the other border case, when only one of the two sets is empty, we set the distance between $u$ and $v$ at a point $x$ to a predefined high value of, e.g., $10^{20}$.\nFinally, we calculate the approximation of Eq. (3) using Eq. (6). Practically, we evaluate the distance between the two expressions as the average 1-Wasserstein distance at the sampled points from the domain $X$.\n$BED (u, v) = \\frac{1}{|X|} \\sum_{x \\in X} W_1 (u, v, x)$  (6)"}, {"title": "4. Evaluation", "content": "In this section, we report on the results of assessing the proposed metric's validity and effectiveness. In the first part, we demonstrate the metric's ability to produce consistent results, ensuring repeated evaluations yield similar rankings of expressions. The second part focuses on the smoothness of the error landscape, demonstrating that expressions close together in terms of our metric also exhibit similar fit to a given data set, validating the metric's ability to capture meaningful relationships between expressions.\nWe generate the expressions that are used in all experiments with the probabilistic grammar (Brence et al., 2021):\n$E \\rightarrow E + F [0.2004] | E - F [0.1108] | F [0.6888]$\n$F \\rightarrow FT [0.3349] | \\frac{F}{T} [0.1098] | T [0.5553]$\n$T \\rightarrow c, [0.1174] | R [0.0.1746] | x [0.708]$\n$R \\rightarrow (E) [0.6841] | E^P [0.0036] | sin(E) [0.028] |$\n$cos(E) [0.049] | \\sqrt{E} [0.0936]; | exp(E) [0.0878] |$\n$log(E) [0.539]$\n$P \\rightarrow 2 [0.65] | 3 [0.35]$\nIn the grammar, $c$ represents a constant, and $x$ is a generic variable. In the final expressions, $x$ is replaced by a randomly sampled specific variable from a set of variables in the observed data set. The grammar is also derived from the standard context-free definition of general mathematical expressions, including most frequently employed operators and functions. We set the grammar rule probabilities by maximizing the likelihood of the mathematical expressions in a corpus extracted from Wikipedia (Guimer\u00e0 et al., 2020; Chaushevska et al., 2022).\nThe code for the calculation of our metric and reproducing results can be found at the following link: (removed during the review process)"}, {"title": "4.1. Metric consistency", "content": "Consistency is a crucial aspect of a metric. Non-stochastic metrics inherently exhibit consistency as they consistently produce the same value. However, our proposed metric incorporates stochasticity. This necessitates demonstrating that the metric's outputs remain relatively consistent when the distance between a pair of expressions is calculated multiple times. Due to the varying magnitudes of distance values, simply presenting the consistency of the metric as the average standard deviation across different runs might be misleading. To address this, we recognize that the actual value of the distance metric itself is not of primary interest (it doesn't matter if the distance is 1 or 1000). Instead, we focus on the rankings of expressions produced by these distances. Accordingly, we assess the consistency of our metric by calculating the average Spearman's rank correlation coefficient (Spearman, 1904) between rankings across multiple experiments.\nTo assess the consistency of our metric across different parameter settings, we examine its performance on a set of 100 expressions with at most two variables. For additional experiments for expressions with at most 1, 4, 6, 8, and 10 variables, check Appendix A. For a given parameter configuration, we evaluate consistency as follows. First, we calculate the distance between each pair of expressions 100 times and store the distances in 100 distance matrices. For each distance matrix, we sample different values of the variables (x) and constants in the expressions. Next, we rank the expressions within each row (i) of the matrices based on their distance to the i-th expression. Then, we calculate the Spearman's rank correlation coefficient between each pair of rankings corresponding to the same row index across different matrices. Finally, we represent the consistency of our metric for a particular parameter set as the average of the computed Spearman's rank correlation coefficients.\nFigure 2 depicts the results of these experiments as a heatmap. As expected, our metric exhibits higher consistency when more points and constants are sampled. Furthermore, we observe that our metric achieves a strong correlation between rankings across different runs for most parameter configurations. This suggests that our metric exhibits considerable consistency, as random assignment of scores yields a correlation of approximately 0.02.\nBased on these results, we set the number of sampled variable values at 64 and the number of sampled constant values at 16 in further experiments. The graphs in Figure 2 and Appendix A show that for these settings, we can achieve a good trade-off between consistency and the amount of computational resources needed."}, {"title": "4.2. Smoothness of the error landscape", "content": "The central claim of this paper is that BED will increase the smoothness of the error landscape of the symbolic regression search space. Neighboring expressions in the restructured search space should have similar errors on a given data set. To test the validity of this conjecture, we perform experiments with 20,000 randomly generated expressions and eleven data sets from the Feynman symbolic regression benchmark (Udrescu & Tegmark, 2020) that include two variables. We compare BED against three other distance metrics: the edit distance, the tree-edit distance, and the optimal distance. We chose these metrics for their distinctive characteristics and relevance to specific groups of symbolic regression approaches.\nThe edit distance relates to methods that directly or indirectly manipulate the string representation of an expression to generate new expressions. These methods often employ deep learning techniques, such as CVAE (G\u00f3mez-Bombarelli et al., 2018) or GVAE (Kusner et al., 2017), which utilize cross-entropy to indirectly define the neighborhood of an expression. Cross-entropy closely mirrors the edit distance, as the model is penalized for incorrectly predicting the symbols of the expression.\nThe tree-edit distance, aligns with methods that directly or indirectly modify expression trees to generate new expressions. These include genetic programming (Cranmer, 2023), DSO (Petersen et al., 2021), and EDHiE (Me\u017enar et al., 2023), which produce new expressions by modifying the expression trees. The tree-edit distance measures the distance with the structural changes required to transform one expression tree into another.\nThe third metric, which we refer to as optimal, establishes a reference point for the smoothness of the error landscape. We calculate it as follows. First, we fit the unknown values of the expression constants to a given data set. Then, each expression $u$ is evaluated on the data set to obtain a vector of output values $Y_u$. Lastly, the distance between expressions $u$ and $v$ is calculated as the root mean squared error, RMSE, between $Y_u$ and $Y_v$. By design, this metric represents the ideal error landscape smoothness since the search space structure faithfully follows the error on a given data set. However, this metric relies on unrealistic assumptions that we know the error of the expressions on the given data set and that the generated expressions include the optimal values of the constants fitted to the given data set. Because of these assumptions, the metric serves as a lower bound for the smoothness of the error landscape of the search space for equation discovery. The closer the smoothness of the error landscape of a metric to this lower bound, the better.\nIn contrast to the three metrics, which have no parameters, BED has four parameters: domain of variables, domain of constants, number of variable values sampled, and number of constant values sampled. For our experiments, we set the domain of all variables to the interval [1, 5], the domain of constant values to [0.2, 5], and the number of sampled variables' and constants' values to 64 and 16, respectively. To account for the stochasticity of BED, we ran each experiment five times and report (plot) the mean and the variance.\nFigure 3 depicts the outline of the simulation study we performed to evaluate the impact of a distance metric on the error landscape smoothness. We first generate a set of $M = 20,000$ expressions and evaluate them on various data sets by fitting the unknown values of the constants and calculating the RMSE $l$ between the expression outputs and the ground truth. Next, we compute the pairwise distances between the $M$ expressions using the selected distance metric. For each expression $e_i$, we order the expressions in ascending order based on their distance to $e_i$ and select the first $N \\leq M$ closest expressions (in our case, $N = 200$). We create a matrix $A \\in \\mathbb{R}^{M \\times N}$ with rows corresponding to the $M$ expressions, columns to their $N$ closest neighbors, and elements $A_{i,j} = |l_i - l_j|$. Finally, we aggregate the elements of $A$ to obtain a vector representing the difference between the errors of the expressions and the errors of their closest neighbors, both on a given data set.\nWe perform the aggregation of the elements of the matrix $A$ in two stages. First, we use the first aggregation function $aggr_1$ to transform each row into cumulative statistics (one of maximum, mean, or median) of its elements, i.e., $B_{i,j} = aggr_1(\\left\\{A_{i,1}, A_{i,2},..., A_{i,j}\\right\\})$, which results in a new matrix $B \\in \\mathbb{R}^{M \\times N}$. In the second stage, we aggregated (using mean or median) the values of each column of $B$ into a single element of the vector $c \\in \\mathbb{R}^N$, i.e., $C_i = aggr_2(\\left\\{B_{1,i}, B_{2,i}, ..., B_{M,i}\\right\\})$. The small error differences aggregates in $c$ indicate a smooth error landscape, where similar expressions have comparable errors $l$ on a given data set, i.e., the error differences $A_{i,j}$ are small.\nFigure 4 reports on comparing the smoothness of the error landscapes corresponding to the four distance matrices. The results show that BED leads to a smooth error landscape for all data sets. This BED smoothness is very close to the smoothness of the error landscape obtained with the optimal metric, i.e., to the lower bound, for eight out of eleven data sets. In these eight cases, BED significantly improves the smoothness of the error corresponding to the two syntactic distance measures. Note that the figure depicts results obtained with the aggregation functions $aggr_1 = max$ and $aggr_2 = mean$. For results of additional experiments using alternative aggregation functions, check Appendix B."}, {"title": "5. Discussion and conclusions", "content": "This paper introduces a novel metric for quantifying the distance between mathematical expressions based on their evaluation behavior. By treating expressions as probability distributions of their output evaluations, we leverage established metrics from probability theory, specifically adapting the 1-Wasserstein distance to the domain of expressions while addressing potential border cases. We demonstrate in Section 4.1 that, despite the stochasticity of the metric, it consistently assigns similar distances to expression pairs. In Section 4.2, we provide empirical evidence that our metric closely approximates the optimal achievable distance and consistently outperforms conventional metrics like edit distance and tree-edit distance, widely used in symbolic regression. Moreover, we emphasize the significance of the sampling domain and find that our metric exhibits comparable or lower computational cost than the tree-edit distance.\nThe metric allows for structuring the search space of candidate expressions, explored by symbolic regression methods, so that neighboring expressions have similar errors on a given data set. This would enable the use of efficient local, e.g., gradient-based methods for exploring the space of candidate expressions. In further work, we want to explore the benefits of integrating the proposed behavioral-aware distance metric into symbolic regression methods. To this end, we plan to extend current methods based on generative models for mathematical expressions (Me\u017enar et al., 2023) with regularization based on the newly proposed distance metric. The latter is expected to guide the generative models, where the close points in the latent space correspond to expressions with similar behavior. This will open the possibility for exploring the candidate expressions' (latent) space with local, gradient-based search methods.\nAnother avenue for further research is the improvement of the proposed metric. First, the amount of computational resources this metric needs can be reduced by investigating the sampling procedures, reusing calculations that only need to be done once, and avoiding as much boilerplate code as possible. Second, one can further study the border case where one expression evaluates to an empty set of known output values and the other to a non-empty set: normalizing the values of the distance metrics on the interval [0, 1] would provide a simple way to address this issue. Another possibility would be to correlate the error of this border case to the values in the non-empty set in some way. Lastly, further study can consider alternative aggregations of Wasserstein scores to improve the metric robustness to outliers."}, {"title": "A. Metric consistency for different number of variables", "content": "In Section 4.1, we explore the consistency of our metric when expressions contain at most 2 variables. However, we want to highlight that our metric achieves consistency even on expressions that contain more/of fewer variables. Figure 6 shows results on expressions with different number of maximum variables (1, 2, 4, 6, 8, and 10) that are obtained using the same methodology as for Figure 2. We can see that consistency of our metric does not change significantly with the number of maximum variables."}, {"title": "B. Error landscape smoothness with additional aggregations", "content": "In Section 4.2 we present the smoothness of the error landscape using max as aggr\u2081 and mean as aggr2. As the choice of these aggregation functions is arbitrary, we present the results using different aggregation functions in this section.\nFigure 7 presents the difference in error between expressions in the close neighborhood when both aggregation functions (aggr\u2081 and aggr\u2082) are set to median. This aggregation strategy results in a slightly higher difference in error for our proposed metric, consistently exceeding the optimal metric on most datasets. However, it still exhibits a significant performance drop (higher error curve relative to the optimal metric) on data sets I.26.2 and II.11.28, where the data domain in the dataset deviates considerably from the sampling domain. Notably, we sample points from the interval [1,5], while the domain of the first variable in I.26.2 and both variables in II.11.28 is restricted to [0,1].\nFigure 8 illustrates the difference in error between expressions in the close neighborhood when the aggregation functions are set to max (aggr\u2081) and median (aggr\u2082). As observed, our metric closely aligns with the optimal metric on most datasets. The only exception is data set II.11.28, where the error difference for our metric deviates significantly from the optimal metric. On this dataset, our metric performs similarly to the edit distance."}]}