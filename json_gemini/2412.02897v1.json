{"title": "MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions", "authors": ["Jinming Zhang", "Yunfei Long"], "abstract": "Narrative understanding and story generation are critical challenges in natural language processing (NLP), with much of the existing research focused on summarization and question-answering tasks. While previous studies have explored predicting plot endings and generating extended narratives, they often neglect the logical coherence within stories, leaving a significant gap in the field. To address this issue, we introduce the Missing Logic Detector by Emotion and Action (MLD-EA) model, which leverages large language models (LLMs) to identify narrative gaps and generate coherent sentences that integrate seamlessly with the story's emotional and logical flow. The experimental results demonstrate that the MLD-EA model enhances narrative understanding and story generation, highlighting LLMs' potential as effective logic checkers in story writing with logical coherence and emotional consistency. This work fills a gap in NLP research and advances border goals of creating more sophisticated and reliable story-generation systems.", "sections": [{"title": "1 Introduction", "content": "Narrative understanding and story generation have been a compelling challenge in Natural Language Processing (NLP) for a long. They evolved from early rule-based systems with limited creativity to sophisticated models that generate rich, engaging narratives (Mooney and DeJong, 1985; Fan et al., 2018). Introducing Transformer (Vaswani, 2017) models like BART (Lewis et al., 2020) and large language models (LLMs) like ChatGPT (OpenAI, 2022) revolutionized this task by utilizing advanced architectures to capture in-detailed dependencies.\nMany previous studies have focused on tasks like summarizing (Awasthi et al., 2021; Jin et al., 2024), sentiment analysis (Lu et al., 2023; Zhao et al., 2025; Lu et al., 2025) and question-answering (QA) (Zhuang et al., 2024; Huang et al., 2024a). While previous story generation research often centered on predicting plot endings or crafting long narratives (Guan et al., 2020; Li et al., 2022). However, in general, story writing frequently needs to pay more attention to maintaining logical coherence (Oatley, 2002; Currie and Jureidini, 2004).\nNot surprisingly, some recent works lead LLMs to maintain narrative coherence in different ways with effective results (Zhao et al., 2023; Wang et al., 2023). However, most of those works focus on continuously writing coherency stories by LLMs (Guan et al., 2021). There is still a gap in detecting the logical coherence in the narratives.\nTo address this gap, our approach focuses on the observable actions of characters rather than delving into their deeper motivations. This choice stems from the understanding that actual actions have a more immediate and direct impact on emotions, and conversely, emotions are often the driving force behind tangible actions (Zhu and Thagard, 2002; D\u00f6ring, 2003). The James-Lange theory of emotion in psychology posits that physiological responses to a situation\u2014such as a racing heart or clenched fists-occur first and then lead to the subjective experience of emotion (Cannon, 1927). This suggests that an observable action (like a person slamming a door) can directly trigger an emotional response (such as anger or frustration). Similarly, the cognitive-behavioral theory emphasizes that behaviors (actions) and emotions are closely linked, where a behavior change can directly influence emotional states, and vice versa (Maslow, 1943; Eisenberg, 2014; Leahy et al., 2022).\nBy prioritizing the direct interplay between observable actions and emotions, we aim to capture the essence of narrative logic in a way that reflects these well-documented psychological principles (Carver et al., 2000). This approach is supported by extensive psychological studies that emphasize the strong correlation between actions and emotional responses, such as how consistent patterns of behavior can shape long-term emotional states, as seen in theories of learned helplessness or social learning (Bandura, 1977).\nIn this study, we introduce the Missing Logic Detector by Emotion and Action (MLD-EA), a LLM-based model designed to identify gaps in narrative logic and generate missing plot elements that are coherent both logically and emotionally. By incorporating the relationship between actions and emotions, MLD-EA aims to enhance the logical structure of narratives. Experimental results demonstrate that our models can produce more believable and emotionally coherent stories by aligning narrative generation with these psychological insights. Our model improves narrative understanding and story generation, underscoring the potential of LLMs as story generators and powerful logic checkers in the creative process.\nThe main contributions of our work can be briefly summarized as follows: 1), We propose a novel task of narrative logic detection. 2), By grounding our model in cognitive-behavioral theories, we highlight how emotions directly interact with actions, leading to better narrative understanding and generation. 3), Experiments have shown that our MLD-EA model has achieved superior results in most aspects, including narrative logic checking with involved characters' emotions and actions and missing plot completeness. Also, we demonstrate the importance of behavior and emotion in story logic detection and generation.\nLeveraging this interaction between actions and emotions to assess and generate story logic more efficiently and accurately mirrors the natural cause-and-effect relationships in human behavior."}, {"title": "2 Related Works", "content": "Several innovative approaches have been developed to enhance AI-generated narratives' logical coherence, emotional depth in narrative understanding, and story generation within NLP. Paul and Frank (2021) framework introduces a recursive inference strategy that dynamically generates contextualized rules to guide narrative completion, focusing on maintaining coherence and logical flow throughout the story. Similarly, the CHAE model (Wang et al., 2022) offers fine-grained control over narrative elements, creating customized stories with specific characters, actions, and emotions, enhancing the personalization and richness of the narratives. Similarly, the COMMA (Xie et al., 2022) explores the relationships among motivations, emotions, and actions, providing a cognitive framework that deepens the understanding of narrative construction by modeling these interrelated factors. However, these traditional models often struggle to consistently integrate actions and emotions to maintain logical coherence throughout the entire narrative, leading to disjointed or emotionally inconsistent storylines when handling more complex plots (Kambhampati et al., 2024). Additionally, they may lack the flexibility to dynamically understand nuanced shifts in a character's behavior or emotional progression.\nExploring LLMs, cognitive frameworks, and hybrid planning strategies has paved the way for more engaging and human-like stories. Alvarez (2023) used ChatGPT in interpreting narrative structures, which further extends the potential for generating stories based on predefined structures, offering new methods for narrative development. Notably, approaches such as iterative prompting-based planning for suspenseful story generation (Xie and Riedl, 2024), the combination of symbolic planning with neural models (Farrell and Ware, 2024), and the SWAG method (Patel et al., 2024), which utilizes action guidance in storytelling, have significantly improved the quality and engagement of AI-generated narratives. Additionally, comprehensive evaluations like \"The Next Chapter\" (Xie et al., 2023) and knowledge-enhanced pre-training models (Guan et al., 2020) have shown that LLMs can produce stories of high quality, sometimes approaching the level of human authors. LLMs often struggle to maintain consistent plots on generation, but they cannot check their generated stories by themselves (Huang et al., 2024b). In our approach, MLD-EA is able to find such logical loopholes by introducing the interaction between emotions and actions to keep stories coherent."}, {"title": "3 Problem Definition", "content": "The primary goal of MLD-EA is to identify whether the input story is logically completed, as Figure 1 shows. We divided the model into four main sub-tasks: 1), abstracting characters' actions. 2), classifying their emotions for each sentence. 3), then locate the logical loopholes of the narrative in which the missing part should be inserted. 4), we complete the tale consistently by predicting the characters' actions and emotions. Thereby preserving the narrative's overall coherence and logical structure. The tasks are defined as follows:\nFor any input $n$ sentences story $S = {s_1,..., s_n}$ with $m$ characters appeared in this story $(C = C_1,\uff65\uff65\uff65, C_m)$, MLD-EA abstract characters' actions $a$ and classify their emotions $e$ for each sentence, denoted as $\\{(c, s) \\rightarrow (a(c, s), e(c, s)) | c \\in C, s \\in S\\}$, where $a(c, s)$ represents the action of character $c$ in sentence $s$ and $e(c, s)$ represents the emotion of character $c$ in sentence $s$.\nSequently, given the story and characters' actions and emotions, MLD-EA will use the provided information to review the story and find inconsistencies. Notably, our task is to find the logic gap in the inner story. We suppose the start and end of the story are always complete. The process involves identifying points where the characters' actions or emotions exhibit abrupt changes that the preceding context cannot logically explain. After that, MLD-EA outputs the index $k$ which the missing part should be inserted before it:\n$k = \\begin{cases} 1 < k < n & \\text{if there is a missing sentence} \\\\ -1 & \\text{otherwise}. \\end{cases}$\nFormally, if MLD-EA identifies a logic gap before a specific place $k$ in the story, it proceeds by predicting the most likely actions $\\hat{a}(c, s_k)$ and emotions $\\hat{e}(c, s_k)$ by using the sequence of preceding $(\\{a(c, s_{k-1}), e(c, s_{k-1})\\})$ and succeeding actions and emotions $(\\{a(c, s_{k}), e(C, s_{k})\\})$. Then MLD-EA estimates the most coherent missing sentence $s_k$ according to $\\hat{a}(c, s_k)$ and $\\hat{e}(c, s_k)$."}, {"title": "4 Methodology", "content": "In this section, we will provide a detailed methodology for each module within our MLD-EA model. The model architecture is shown in Figure 2.\n4.1 Action Abstraction\nThe action abstraction module is designed to extract and abstract actions performed by characters in a given sentence, playing a crucial role in analyzing narrative structures and identifying logic gaps. The process begins with the model receiving a sentence $s$, a list of characters $C = \\{C_1, C_2, ..., C_m\\}$, and the story's context $S$ for reference.\nGuided by prompt engineering (details in Appendix E), MLD-EA processes each sentence to identify and represent the actions performed by the characters as flowing:\nFor each character $c$ in the characters list $C$, the model outputs an action in the following format: <c>Action(Target, Object)</c>, where $c$ represents the character acting; Action denotes the action the character performs; Target is the target of the action (who or what the action is directed towards); Object specifies any object associated with the action (if applicable). If a character $c$ does not perform any action in the sentence $s$, the model needs to output: <c>None</c>.\n4.2 Emotion Classification\nThe emotion classification module in the MLD-EA categorizes characters' emotions based on given sentences. This classification is based on eight basic emotion types from Plutchik's model (Plutchik, 2001) -joy, trust, fear, surprise, sadness, disgust, anger, and anticipation\u2014plus an additional \"none\" category for cases where no emotion is detected.\nBefore classifying emotions, the model first checks whether each character $c$ in the list $C = \\{C_1, C_2,..., C_m\\}$ is affected by the events described in each sentence $s$. If the model determines that a character $c$ is not affected, the emotion for that character is classified as none. In addition to the emotion classification, the model also outputs whether or not each character is affected by the sentence.\nThe model's output for each character $c$ includes the result of the 'affected' and the emotion classification in <c>(Affected, e(c, s))</c>, where Affected is a boolean value indicating whether the character $c$ is affected by any event in the sentence $s$ and $e(c, s)$ represents the emotion associated with the character in sentence $s$, where $e \\in \\{joy, trust, fear, surprise, sadness, disgust, anger, anticipation, none\\}.\n4.3 Narrative Logic Checker By Characters' Emotion and Action\nThe narrative logic checker component focuses on detecting potential gaps in the narrative by analyzing the relationship between characters' actions and emotions. This process is grounded in the outputs from the previous modules: action abstraction and emotion classification. The prediction is based on detecting disruptions or inconsistencies in each character's expected flow of actions and emotions. Several key principles in behavior research (Cannon, 1927; Zhu and Thagard, 2002) guide this process: 1), emotions often drive actions. 2), actions can influence subsequent emotions. 3), and some actions directly reflect the character's current emotional state, and vice versa.\nMLD-EA then predicts the missing sentence index $k$, which is determined by evaluating the continuity and logical consistency of the sequences with the interaction of characters' actions and emotions:\n$(E, A) = \\sum_{s \\in S, c \\in C} [e(c, s), a(c, s)],$\n$k =InfIndex [(S \\oplus (E, A)), C],$ where InfIndex represent the model inference of missing sentence index prediction. A significant deviation from expected values suggests a missing sentence, and $k$ identifies the position where this sentence should be inserted.\n4.4 Action/Emotion prediction and sentence generation\nFollowing the identification of the missing sentence index by analyzing characters' actions and emotions, the next crucial step in the MLD-EA framework is to predict the actions and emotions of the missing sentence and subsequently generate the sentence. This process is essential to ensure the narrative remains coherent and logically consistent. The focus here is on the immediate context surrounding the predicted index. By examining the sequences of preceding actions and emotions and succeeding actions and emotions, the model estimates the most coherent actions $\\hat{a}(c, s_k)$ and emotions $\\hat{e}(c, s_k)$ for the missing sentence $s_k$:\n$[\\hat{a}, \\hat{e}] = Infeap [(\\hat{a}(c, s_{k-1}), e(C, s_{k-1})), (a(c, s_{k}), e(c, s_{k}))],$\nwhere Infeap means the model inference of emotion and action prediction for the missing sentence. Once these predictions are made, the model generates a sentence to fill the identified gap:\n$s_k = Infgen (S, C, k, (\\hat{a}, \\hat{e})),$ where Infgen is a zero-shot inferring. This generated sentence encapsulates the character's possible emotion and action, thereby maintaining the story's coherence and flow and completing the narrative."}, {"title": "5 Experiment", "content": "5.1 Data\nWe use the Story Commonsense dataset for our task, which contains 4853 five-sentence stories with labeled emotions and motivation for characters (Rashkin et al., 2018). We only take the stories with labeled emotion because the labeled motivations are based on Maslow's needs (Maslow, 1943) and Reiss' motives (Reiss, 2004) theory, which are focused on the deeper motivation, not actual actions. By excluding motivations, which are more abstract and theoretical in nature, the analysis remains more grounded in observable narrative events, avoiding complexities that may not directly influence the characters' visible actions. This also ensures that the model can better focus on the emotional states that drive the characters' responses, making it easier to align predictions with surface-level events in the story. We then divided the data into 8:1:1 for training, validation, and testing.\nTo follow the task of emotion classification in section 4.2 and the task of narrative logic checker in section 4.3, we consolidate the characters' emotions into a single tag by selecting the one with the highest confidence, as determined by three annotators in the original dataset. The details of choosing the missing sentence are in Appendix A.\n5.2 Selected Baselines\nWe compare MLD-EA with the following baselines trained by different strategies and datasets:\nLlama3-8B-Instruct (AI@Meta, 2024): Meta's Llama3-8B-Instruct model is a cutting-edge LLM renowned for its exceptional ability to follow instructions meticulously. It is adept at crafting stories that are not only imaginative but also adhere to logical structures and factual integrity.\nGemma2-2B-it (Team, 2024): Gemma2-2B-it is a nimble and efficient model that packs a punch regarding text generation capabilities from Google. Despite its smaller size than some of its peers, it demonstrates remarkable skill in spinning engaging stories that captivate audiences.\nGemma2-9B-it (Team, 2024): Gemma2-9B-it is a larger version of Gemma2-2B-it. With a more vast dataset and bigger model size, it generates intricate and vivid stories rich in detail and depth.\nWe selected these particular models as baselines for several key reasons: 1) To the best of our knowledge, no prior research has focused on identifying logical gaps or inconsistencies at the sentence level within stories. This novel focus makes it difficult to directly compare our approach to existing studies. 2) While previous works on story generation have primarily relied on pre-trained models such as BERT and GPT-2 (Wang et al., 2022; Paul and Frank, 2021), our study specifically aims to evaluate the capabilities of newer LLMs. The baselines we selected models are all modern LLMs known for their advanced narrative understanding abilities. These models are particularly well-suited for complex tasks related to narrative. 3) We intentionally included models of different sizes and architectures to provide a comprehensive evaluation. This range allows us to compare varying complex models to understand how size and dataset diversity impact logical story generation.\n5.3 Implement Setups\nMLD-EA is built based on Llama3-8B-Instruct (AI@Meta, 2024) using the Huggingface's libraries\u00b9 (Wolf, 2019) and use Llama-Factory (Zheng et al., 2024) for supervised fine-tuning (Gunel et al., 2020). We use LoRA (Hu et al., 2021) to fine-tune our model. Please see Appendix B for hyper-parameters details and Appendix E for prompts technics we used and prompt templates.\nWe compute the micro-averaged result of all baselines by the same zero-shot (Wei et al., 2021), one-shot, and few-shot (Brown, 2020) prompts with original input labels from the dataset. All experiments run on two RTX 4090 24GB GPUs.\n5.4 Evaluation Metrics\nWe use the following metrics to evaluate MLD-EA performance on the different sub-tasks:\n(1) Both BLEU-1,2 (Papineni et al., 2002) and ROUGE-L (Lin, 2004) are used for evaluating the action abstraction task.\n(2) We compute the micro-average Precision, Recall, and F1 score for each tag to show the accuracy of emotion classification.\n(3) The micro-average Precision, Recall, and F1 score are also applied to evaluate the accuracy of the narrative logic checker on each candidate place.\n(4) For final generation task based on predicted emotions and actions, we use BLEU-1,2,4, ROUGE-1,2,L and BERTScore\u00b2 (Zhang et al.,"}, {"title": "6 Results and Analysis", "content": "6.1 Action Abstraction and Emotion Classification\nThe action abstraction has summarized the key concept from the original sentence as open-text, so we evaluate it by creating a simple process called 'Text to Action to Text (T2Act2T)'. T2Act2T takes the abstracted actions at first, and then it generates a new sentence only based on the abstracted actions. In the end, we compare the original sentence with the generated sentence to see how much information remained during the MLD-EA's action abstraction module. shows the result between original sentence and new sentence, which illustrates the degree of information kept by our method.\nWe give results for emotion classification in Table 2. Our model performs best compared to Llama3-8B-Instruct baseline and a developed NPN model (Bosselut et al., 2017) in ROCStories dataset (Rashkin et al., 2018). After fine-tuning, the model archives a significant improvement in emotion classification. Also, when incorporating the 'affected' feature to detect whether any emotion influences a character, our model attains an impressive F1 score of 88.51 on evaluating the accuracy of 'affected', respectively. Our findings suggest that including features that account for emotional impact can dramatically improve classification performance, which has implications for various applications in natural language processing.\nFurthermore, the partition relationship between the number of labels and their classified accuracy is in Figure 3. Classes with fewer instances show lower accuracy, indicating a need for better representation or enhanced feature engineering to improve performance across less frequent emotions.\n6.2 Narrative Logic Checker\nTable 3 presents the results of the narrative logic checker on predicting the index of missing part, which evaluates our model against various baselines both with and without incorporating actions and emotions\u00b3. MLD-EA model consistently outperforms all baselines across different sentence insertion points. Notably, including actions and emotions significantly improves the micro-averaged F1 scores for all baseline models. Specifically, when the story is complete (k = -1), there is a marked improvement in F1 scores for each baseline model, underscoring the critical role that action and emotion play in maintaining story logic.\nThe superior performance of our MLD-EA model highlights its advanced capability to accurately predict the missing sentence in a narrative. This suggests that the model's ability to consider emotional and action-related cues is essential for enhancing the logical coherence of stories. These findings emphasize the importance of incorporating nuanced narrative elements, such as emotions and actions, in developing more sophisticated and reliable models for story generation.\n6.3 Sentence Generation\nWe also compare our model with the baselines for the Generation task, which considers the different situations. Also, we add the influence of action-emotion prediction on generation task. The results, as shown in Table 4, demonstrate that our MLD-EA model, particularly when incorporating predicted actions and emotions, achieves competitive performance across multiple metrics. Notably, our model with the action-emotion prediction achieves the highest scores in several key areas: BLEU-1, BLEU-2, and all ROUGE. Moreover, we notice that BLEU-4 rises dramatically after involving emotions and actions for the Gemma2-2B-it model. This means this method may be more suitable for small-size LLMs on generation tasks with consistency and coherency. We also compare this with previous studies in story plot generation, which are done by pre-training models. Obviously, the LLMs-based results achieve impressive improvement in generation tasks.\nIncorporating actions and emotions into the generation process significantly enhances the model's performance, as evidenced by the notable improvement in BLEU and ROUGE scores across all baselines. However, the difference in BERTScore is slight. Overall, the baselines involved in emotion and action while adding action-emotion prediction still outperform the fundamental baselines.\nWe also use VAD to measure the deviation from the original sentence with model generation."}, {"title": "6.4 Ablation Study", "content": "MLD-EA's primary task is to find the logic gap by providing characters' emotions and actions. So, we focus on how actions and emotions affect the model's performance in ablation studies. As shown in Table 6\u2074, after we remove actions (w/o a) and emotions (w/o e), the accuracy of prediction drops out a lot, which decreases by more than 10 on micro-average F1 score. Surprisingly, we notice if we do not add actions and emotions as input (w/o ae), the prediction result is not bad. It may be because the default considering features is unrelated to characters' behaviors; it may be more related to the inherent connection between sentences."}, {"title": "6.5 Case study", "content": "Table 7 shows the result of models in finding the missing one's index and generating the sentence before and after the introduction of action and emotion. Without actions and emotions, most models incorrectly predicted the missing location, generating sentences that did not align with the emotional progression. For example, Llama3-8B-Instruct suggested inserting a sentence before 82 that did not logically lead to Gary's later frustration.\nWhen actions and emotions were included, model performance improved significantly. Both Llama3-8B-Instruct and Gemma2-9B-it accurately identified the correct index and generated sentences that better reflected the emotional shift from joy to anger, such as \"Gary was frustrated with the slow performance and poor battery life of his new laptop.\". The example of \"However, the Mac Air proved to be much slower than he had anticipated.\" even reflects the previous emotion status, making the sentence more connective to the story's consistent emotions and actions. This case study highlights the importance of action-emotion modeling in enhancing the accuracy and coherence of narrative generation, leading to more logically consistent and emotionally resonant outputs."}, {"title": "7 Conclusion", "content": "In this work, we introduced the MLD-EA model, a novel approach that leads LLMs to address gaps in narrative logic by integrating actions and emotions. MLD-EA extracts the actions and emotions of the characters in the input story and guides LLMs to find logical loopholes in the narrative by following the rules of interaction between actions and emotions. After getting the position where the missing part should be inserted, it combines the character behaviors and emotions in the context of the missing position to predict the possible character actions and emotions and complete the missing plot. The experimental results demonstrate that MLD-EA significantly improves narrative coherence and emotional alignment compared to existing models, highlighting its effectiveness in story logic detection and generation. By focusing on the interplay between actions and emotions, we have shown that maintaining logical consistency is crucial for producing believable and emotionally resonant narratives. This work advances the field of checking story logic and showcases the potential of LLMs as powerful tools for ensuring narrative cohesion.\nLimitations\nFirst, the model has only been tested on short, five-sentence stories and has yet to be evaluated on longer, more complex narratives. This may limit its generalizability to extended storytelling contexts. Second, the model's performance heavily relies on the quality of the original emotion labels and action abstractions. Any inaccuracies in these inputs could negatively affect the model's ability to generate coherent and logically consistent narratives. Future work should address these limitations by testing the model on longer stories and improving the robustness of emotion and action extraction."}]}