{"title": "Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model", "authors": ["Runqing Wu", "Fei Ye", "Qihe Liu", "Guoxi Huang", "Jinyu Guo", "Rongyao Hu"], "abstract": "Continual Learning seeks to develop a model capable of incrementally assimilating new information while retaining prior knowledge. However, current research predominantly addresses a straightforward learning context, wherein all data samples originate from a singular data domain. This paper shifts focus to a more complex and realistic learning environment, characterized by data samples sourced from multiple distinct domains. We tackle this intricate learning challenge by introducing a novel methodology, termed the Multi-Source Dynamic Expansion Model (MSDEM), which leverages various pre-trained models as backbones and progressively establishes new experts based on them to adapt to emerging tasks. Additionally, we propose an innovative dynamic expandable attention mechanism designed to selectively harness knowledge from multiple backbones, thereby accelerating the new task learning. Moreover, we introduce a dynamic graph weight router that strategically reuses all previously acquired parameters and representations for new task learning, maximizing the positive knowledge transfer effect, which further improves generalization performance. We conduct a comprehensive series of experiments, and the empirical findings indicate that our proposed approach achieves state-of-the-art performance.", "sections": [{"title": "1 Introduction", "content": "Continual Learning (CL), often referred to as lifelong learning, seeks to develop a model that can consistently acquire new concepts while retaining previously learned information [35]. Nevertheless, contemporary deep learning models frequently experience considerable performance decline in the context of continual learning, primarily due to catastrophic forgetting [35]. This issue arises because these models lack the necessary mechanisms to safeguard against information loss when adapting to new tasks. Given its advantageous characteristics, continual learning holds significant practical applications across various fields, including autonomous driving, robotic navigation, and medical diagnostics.\nContinual learning research has led to the development of various technologies aimed at addressing the issue of network forgetting. These can be categorized into three main approaches: first, rehearsal-based methods, which focus on optimizing a compact memory buffer to retain numerous essential examples [7, 3]; second, dynamic expansion frameworks that facilitate the automatic construction and integration of new hidden layers and nodes into an existing backbone to capture new information [8, 19]; and third, regularization-based methods that incorporate an additional regularization term into the primary objective function to mitigate significant changes to many previous and crucial network parameters [24, 31].\nAmong these technologies, utilizing a memory buffer to retain numerous critical examples stands out as the most prevalent approach in continual learning; however, it struggles to accommodate an increasing number of tasks. Conversely, dynamic expansion models excel in this demanding continual learning paradigm by adaptively generating a new sub-model to tackle each new task [8, 19]. Furthermore, recent research has suggested leveraging a pre-trained Vision Transformer (ViT) [12] as a foundational backbone, allowing for the rapid construction of a new expert with minimal parameters to swiftly adapt to new tasks [50]. Nonetheless, these methodologies typically concentrate on a singular data domain and depend on a single pre-trained backbone [50], which limits their ability to generalize effectively across a sequence of diverse data domains where both the domain and class may shift unpredictably.\nIn this paper, we introduce an innovative dynamic expansion framework, referred to as the Multi-Source Dynamic Expansion Model (MSDEM), designed to tackle the challenges of class and domain shifts in multi-domain continual learning. The core concept of our proposed methodology is to integrate knowledge retained by various backbones trained on distinct data sources into a cohesive optimization framework, with the objective of delivering robust generalization representations for the experts. Specifically, we present a novel Dynamic Expandable Attention Mechanism (DEAM) that regulates representations from multiple backbones through an attention mechanism. In contrast"}, {"title": "2 Related Work", "content": "Rehearsal-based techniques represent a fundamental and widely adopted strategy to mitigate network forgetting in continuous learning, as highlighted in the recent literature [4]. This approach focuses on retaining a substantial number of essential past instances and reintroducing them during the learning of new tasks [4, 6, 16, 17, 36, 39, 40, 44, 20]. Consequently, the selection of samples is pivotal in ensuring optimal performance of rehearsal-based methods. Additionally, the integration of a memory buffer system can be effectively aligned with regularization-based techniques, with the objective of further enhancing the model's efficacy [11, 31, 7, 30, 10, 42, 46, 34, 2, 9, 21]. Another approach to implement the memory system is to train a deep generative model such as Variational Autoencoders (VAEs) [26] or Generative Adversarial Networks (GANs) [14] for preserving and producing past examples to relieve network forgetting [1, 37, 43, 51, 25]. These methods can avoid the data privacy issues caused by the memory buffer system.\nKnowledge distillation techniques focus on transferring the knowledge preserved by a static teacher module to a small-sized student module [15, 18]. The Knowledge Distillation (KD) approach can also be applied to continual learning for addressing network forgetting. Specifically, the KD approach in continual learning treats the previously and currently learned model as a teacher and a student module, respectively. Minimizing the distance between the teacher and student outputs can relieve network forgetting [29]. Furthermore, the KD methodology can be integrated with rehearsal-based methods into a cohesive optimization framework, which can further enhance model performance, as demonstrated in [38], namely Incremental Classifier and Representation Learning (iCaRL). Specifically, iCaRL employs a novel nearest-mean-of-exemplars classification approach that bolsters the classifier's resilience to variations in data representations. In addition, another studies introduce a new self-KD technology, aiming to preserve previously acquired features and representations, which can address network forgetting [6].\nDynamic network architecture. Although rehearsal and knowledge distillation (KD) technologies have achieved significant performance in continual learning, they can only perform well on a small number of tasks and can not address the more complex learning environment. Recent studies have developed a dynamic expandable framework to deal with a long sequence of tasks. Specifically, this framework automatically creates and adds new sub-models and hidden layers into a unified backbone when learning a new task, in which all previously learned parameters are frozen to preserve all prior knowledge [8, 19, 36, 41, 48, 52, 23, 45]. As a result, the dynamic expandable framework can maintain good performance on all previous tasks without forgetting and are able to learn a new task effectively through a dynamic expansion process [41]. Furthermore, the recent popular backbone, called Vision Transformers (ViT) [12], has also been explored as a sub-network into a dynamic expansion framework, which can achieve better performance than the CNN based dynamic expansion framework [49, 13]."}, {"title": "3 Methodology", "content": null}, {"title": "3.1 Problem Statement", "content": "In continual learning, a model is assumed to be trained in a dynamically changed learning environment. Specifically, the model can only access the training samples from the current task learning while all previous tasks are unavailable. Let $D^i = \\{(x_j^i, y_j^i)\\}_{j=1}^{n^i}$ and $D_t^i = \\{(x_j^i, y_j^i)\\}_{j=1}^{n_t^i}$ be the i-th training and testing dataset, respectively, where $n^i$ and $n_t^i$ denote the total number of samples in the training set $D^i$ and the testing set $D_t^i$, respectively. $x \\in X$ and $y \\in Y$ denote the j-th testing sample and its corresponding class label, respectively. $X \\in R^{d_x}$ and $Y \\in R^{d_y}$ are the data and label space with the dimension $d_x$ and $d_y$, respectively. In a class-incremental learning paradigm, a training dataset $D_i$ is usually divided into $C_i$ parts $\\{D_i^{(1)}, \\dots, D_i^{(C_i)}\\}$, where each subset $D_i^{(j)}$ contains data samples from a single or several adjacent categories. Let $\\{T_1, \\cdots, T_{C_t}\\}$ be a set of tasks, where each task $T_j$ is associated with the training dataset $D_i^{(j)}$. At a certain task learning $(T_j)$, we can only access the samples from $D_i^{(j)}$ while all previous datasets $\\{D_i^{(1)}, \\dots, D_i^{(j-1)}\\}$ are unavailable. Most existing continual learning studies only consider to incrementally learn new categories within a single data domain. However, in a more realistic learning environment, new data samples can be drawn from entirely different data domains. Let $\\{D_1, \\dots, D_t\\}$ be a set of t different datasets/domains, where each dataset $D_i$ can be divided into $C_i$ parts. A data stream S can be formed using the following process :\n$S = \\{D_1^{(1)}, \\dots, D_1^{(C_1)}, \\cdots, D_t^{(C_t)}\\}$.\nLearning the data stream S remains a considerable challenge since it involves shifts in both the class and domain. When the total number of tasks is finished, we evaluate the model's performance on all testing datasets."}, {"title": "3.2 Framework Overview", "content": "Existing research typically proposes the introduction of a new independent expert within a mixture system or the utilization of a single pre-trained Vision Transformer (ViT) as a foundational backbone to initialize an expert with minimal parameters for learning a new task. However, many of these approaches focus solely on a single pre-trained backbone that encompasses semantically rich knowledge from one or a few data domains, which limits their applicability to unknown and entirely distinct data domains. In this paper, we introduce an innovative dynamic expansion framework that incorporates multiple pre-trained ViT backbones trained on samples from diverse sources, referred to as the Multi-Source Dynamic Expansion Model (MSDEM). This model demonstrates robust generalization capabilities across various data domains. \nThe multi-source backbones. Utilizing multiple backbones that are trained on diverse datasets and data distributions can yield semantically rich and robust representations, thereby enhancing the model's generalization capabilities in continual learning. Let $\\{f_{\\theta_1}, \\cdots, f_{\\theta_{t'}}\\}$ represent a collection of t' distinct backbones, each trained on varying data domains and datasets. Each backbone $f_{\\theta_j} : X \\rightarrow Z$ is constructed using the pre-trained Vision Transformer (ViT) [12], which takes an image $x \\in X$ as input and produces a feature vector $z \\in Z$, where $Z \\in R^{d_z}$ denotes the feature space with dimension $d_z$, and $\\theta_j$ signifies the parameter set of the j-th backbone. Given the substantial output dimension of each pre-trained ViT backbone, we utilize only the class token to minimize feature dimensions and computational expenses. For any input x, we can leverage all pre-trained backbones to extract a potent representation by :\n$z_f = z^1 \\otimes z^2, \\cdots, \\otimes z^{t'}$,\nwhere $z^j$ is given by the j-th backbone $f_{\\theta_j}$, and $\\otimes$ denotes to combine two feature vectors into a single one. $z_f$ is an augmented feature vector over the feature space $Z_f \\in R^{d_z \\times t'}$.\nThe expert module. While the pre-trained backbone is capable of delivering robust representations, it cannot directly leverage these features for predictive tasks. In this study, we introduce a method to dynamically construct and integrate a new expert module within the proposed dynamic expansion framework to address the challenges of learning new tasks. Specifically, for a designated new task $T_j$, we develop a new expert module $E_j$, which comprises an adaptive module $f_{\\varepsilon_j} : Z_f \\rightarrow Z_e$ designed to acquire a task-specific representation, alongside a linear classifier $f_{w_j} : Z_e \\rightarrow Y$ intended to discern a decision-making pattern. The adaptive module $f_{\\varepsilon_j}$ of the j-th expert $E_j$ takes an augmented feature $z_f$ as input and produces a feature vector $z$ within the feature space $Z_f \\in R^{d_e}$, where $d_e$ denotes the dimensionality of the features. The prediction process for a given input x utilizing the j-th expert is articulated as follows:\n$y' = \\arg \\max(\\text{Softmax}(W_w^T z))$,\nwhere $W_{w_j}$ denotes the weight matrix of the classifier $f_{w_j}$ and $\\text{Softmax}(\\cdot)$ represents a Softmax function. $W_{w_j}^T$ represents the matrix transpose."}, {"title": "3.3 Dynamic Expandable Attention Mechanism", "content": "In the process of acquiring the knowledge from a new task, certain pre-trained backbones may encompass semantically relevant representations that facilitate the learning of the new task, thereby enhancing their contribution to this learning process. Merely aggregating representations from various backbones, as outlined in Eq. (2), fails to effectively leverage prior knowledge for the new task acquisition. To tackle this challenge, we introduce an innovative dynamic expandable attention mechanism that autonomously assesses the significance of each pre-trained ViT backbone. Specifically, our proposed method can automatically generate and incorporate a new attention module upon the creation of a new expert, enabling the development of an expert-specific attention behaviour.\nWe assume that the proposed framework has already learnt (t - 1) experts $\\{E_1, \\cdots, E_{t-1}\\}$. When learning a new task $(T_t)$, we dynamically create three trainable weight matrices $K_t, Q_t$ and $V_t$, to regulate all previously learned representations during the new task learning. For a given input x, we can get a combined representation $z_f$ using Eq. (2) and employ the attention mechanism to process $z_f$ :\n$Q_t = Q_t z_f, K_t = K_t z_f,$\n$V_t = V_t z_f$.\nThe resulting weight matrices $Q_t$, $K_t$ and $V_t$ are used to calculate the attention map by :\n$Z_{\\text{att}} = \\text{Softmax}(Q_t (K_t / \\sqrt{d_k})) V_t,$"}, {"title": "3.4 Dynamic Graph Weight Router", "content": "Most current studies in continual learning primarily concentrate on examining the active model parameters to acquire new tasks, which limits their ability to capture comprehensive statistical information. In this paper, we propose leveraging numerous essential previously acquired network parameters and representations to bolster the learning capacity for future tasks. Furthermore, given that each expert assimilates knowledge from distinct data domains, employing all previously learned network parameters may not be advantageous for new task acquisition. We tackle this challenge by introducing an innovative dynamic adaptive weight generation method that dynamically constructs and develops weight routers to selectively identify several key experts for new task learning. We assume that the proposed dynamic expansion framework has already established (t - 1) experts $\\{E_1, \\cdots, E_{t-1}\\}$ during the (t \u2212 1)-th task learning phase. We conceptualize each expert as a node within a graph structure and present a graph relation matrix $C \\in R^{(t-1)*(t-1)}$ to characterize the interrelations among experts, where $C(i,j)$ signifies the relationship from the j-th expert to the i-th expert. Upon encountering a new task $(T_t)$, we first establish a new expert module $E_t$ and extend the relation matrix to $C \\in R^{(t,t)}$. Subsequently, we extract the relation vector $M^t = \\{M^t[1], \\cdots, M^t[t]\\}$ from $C(t)$, which represents all elements of the t-th row of C, corresponding to the expert $(E_t)$. To effectively select experts for new task learning, we propose utilizing the Gumbel-Softmax distribution to generate the weight router, expressed as:\n$M^t[k] = \\frac{\\exp ((\\log(M^t[k] + \\epsilon_n) + \\epsilon_u)/T)}{\\sum_{j=1}^t \\exp ((\\log(M^t[j] + \\epsilon_n) + \\epsilon_u)/T)},$\nwhere $\\epsilon_n \\sim N(0, \\sigma^2 I)$ is sampled from a normal noise distribution to enhance the robustness of weight optimization while encouraging the model to explore different expert combinations more extensively during the early stages of training. $\\epsilon_u = -\\log(-\\log(U))$ and $U \\sim Uniform(0, 1)$. T is a temperature parameter, controlling the smoothness of the sampling distribution.  Compared to a rigid Top-k selection scheme, adjusting the temperature parameter of the Gumbel-Softmax allows for tuning between hard and soft selection. In practice, the number of selected experts is determined by the results of the optimization process. By using Eq. (6), we can get the selection weights $\\{M^t[1], \\cdots, M^t[t]\\}$, which can be used to regulate the representations extracted by all previously learned experts.\nThen we combine all normalized representations and the feature extracted from the adaptive module $f_{\\varepsilon_t}$ into a compact representation, expressed as :\n$Z^t = \\sum_{i=1}^t (M^t[i] * z_f^i)$.\nWe employ the attention mechanism to further regulate the"}, {"title": "3.5 Algorithm Implementation", "content": "In this section, we provide the learning procedure of the proposed framework in fig. 1 while the pseudocode is provided in Algorithm 1, which can be summarized into three stages, described in the following.\nStep 1 (The construction process). When learning a new task $T_t$, we dynamically create a new expert module $E_t = \\{f_{\\varepsilon_t}, f_{w_t} \\}$ based on the pre-trained backbones and $K, Q, V$ of graph block.\nStep 2 (The dynamic expandable attention mechanism). We first create the attention parameters $\\{K_t, Q_t, V_t\\}$, which can be used to regulate the augmented feature $z_f$ using Eq. (4), resulting in $\\{K_t, Q_t, V_t\\}$.\nStep 3 (The dynamic graph weight router). We expand the relation matrix C and create the router $\\{M^t[1], \\cdots, M^t[t]\\}$ for the task Tt using Eq. (6). Then, we can obtain the final representation $Z^t$ using Eq. (9).\nStep 4 (The parameter update). To optimize the proposed framework, we introduce to employ the cross-entropy loss, defined as:\n$L_{CE} = - \\sum_{c=1}^K y[c] \\log \\{ \\text{Softmax}(W_w^T Z_f)[c]\\},$"}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Experimental setting", "content": "Datasets: We evaluate the model performance in a continual learning setting across multiple domains, using the TinyImageNet [28], CIFAR-100 [27], CIFAR-10 [27], and Birds 525 Species datasets.\nMetrics: To assess and compare the model performance across multi-domain settings, we use two metrics: \"Average\" and \"Last.\" The \"Average\" metric measures the model's mean accuracy across tasks in a specific scenario, while \"Last\" indicates the accuracy on the final task. We calculate the average accuracy on all testing samples.\nImplementation: We use three different ViT models as backbones: ViT-B/16 pretrained on ImageNet-21K, ViT-B/16 pretrained on ImageNet-21K and fine-tuned on ImageNet-1K, and pretrained ViT-L/14. All three models are frozen during training and inference to retain domain-specific prior knowledge. For the classifier, router, and all attention layers, we consider to employ three different Adam optimizers with tailored learning rates and scheduler parameters, aiming to achieve optimal performance."}, {"title": "4.2 Comparison with SOTA", "content": "SOTA Categorization. In this section, we present a comparative analysis of our method against various SOTA approaches in continual learning. Specifically, we consider the experience replay-based methods such as DER [5], along with its enhanced variants DER++ [5] and DER+++refresh [47]. We also consider to compare our approach with the dynamic expansion model such as the MoE adapter-based models utilizing a mixture of experts framework where we distinguish between a lower-bound configuration (MoE-2E/1R, comprising 2 experts and 1 router) and an upper-bound configuration (MoE-22E/10R, with 22 experts and 10 routers) [50]. Additionally, we also consider employing the prompt-based learning models as the baseline such as the StarPrompt [33], which maintains a balance between new and previous tasks through prompt injection and generated replay. Finally, we compare methods based on another type of continual learning methods, including Random Packing (RanPac) [32], which employs a random grouping mechanism, and Data Augmentation Prompt (Dap) [22], which incorporates data augmentation to enhance the retention of prior knowledge in continual learning scenarios. All models employing memory replay strategies (DER, DER++, DER+++refresh) use the same backbone. To maintain consistency in our experimental setup, we configure them with a dual-ViT model, unfreezing the last two blocks of each ViT to provide a fine-tuning parameter space. The memory replay buffer size is uniformly set to the Maximum 5120.\nMulti-domain Task Incremental Learning. In this experiment setting, we consider employing six two-domain scenarios, two three-domain scenarios, and one four-domain scenario, with evaluations based on two performance metrics: \"Average\" and \"Last\". Specifically, in the two-domain scenarios, we explore various domain order combinations to assess the generalization performance of various models under different domain configurations. Additionally, we examine both dual-ViT and triple-ViT model strategies to evaluate whether more pre-trained backbones can improve the model's generalization performance. It is noteworthy that the prompt-based StarPrompt, along with its generative replay mechanism, reuses the training samples from the current task 2-4 times during training to strengthen resistance to forgetting. Therefore, we also include the results achieved by the proposed approach using 3 training epochs for a fair comparison.\nThe results. The empirical results clearly illustrate that our method (denoted as \"Ours\") achieves superior average performance under the dual ViT model setup across nearly all task configurations. Notably, memory replay-based methods such as DER and mixture-of-experts models like MoE exhibit relatively poor performance in these multi-domain task scenarios. Although they achieve relatively high \"Last\" scores, indicating strong performance on the current task, they show limited resistance to forgetting.\nIn the dual-domain configuration, our method shows a 16.98% improvement in the Average metric and 15.95% in the Last metric over StarPrompt, the baseline performance ceiling. In the three-domain and four-domain configurations, the improvements are 15.06% and 6.2%, respectively. All comparisons are based on training for 3 epochs, where our model achieves great performance gains as the number of domains increases. Even with training limited to a single epoch, Our method consistently outperforms all SOTAS except StarPrompt on the Average metric across all task configurations, with results closely matching StarPrompt-1st and StarPrompt-2nd in the Cifar100-Birds and Birds-Cifar100 tasks.\nWhen considering to use a single training epoch, our method outperforms RanPac by 67.49% in the average metric and 70.44% in the last metric in the dual-domain configuration. In the three-domain and four-domain scenarios, these improvements are 62.28% and 78.88%, respectively."}, {"title": "4.3 Ablation Study", "content": "We provide the additional ablation results in Appendix-C from SM.\nComputational Cost. We compare the computational costs of our method with other baselines in terms of the computational costs and the number of parameters. A comparative analysis across various models is provided in table 3, which reports the training parameters (M), peak and average GPU memory usage (MiB), and runtime efficiency (it/s). The proposed framework, which utilizes a dual-backbone strategy, shows a clear advantage over all current SOTA methods. Compared with a prominent SOTA method, StarPrompt-2nd, our approach reduces training parameters by 70.36%, GPU memory usage by 85.83%, and training time by 89.35%. This underscores its capacity to enhance continual learning in ViT-based models while significantly alleviating computational demands during training. Although our method shows a modest 3.43% increase in RAM usage compared to StarPrompt-2nd, it remains within the typical range observed across other SOTA methods such as DER++refresh and RanPac.\nAnalysis of Router. The router mechanism is introduced to balance the extent of knowledge transfer from previous tasks during the training of the current task, as knowledge dependencies vary across domains. nearly all permutation schemes indicate that domain2's dependency on domain1 shifts with their training order, suggesting that knowledge dependency between domains is asymmetric. Notably, when two domains are relatively close, such as TinyImageNet and Birds, their dependencies tend to be reciprocal."}]}