{"title": "Regularized Multi-Decoder Ensemble for an\nError-Aware Scene Representation Network", "authors": ["Tianyu Xiong", "Skylar W. Wurster", "Hanqi Guo", "Tom Peterka", "Han-Wei Shen"], "abstract": "Feature grid Scene Representation Networks (SRNs) have been applied to scientific data as compact functional surrogates\nfor analysis and visualization. As SRNs are black-box lossy data representations, assessing the prediction quality is critical for scientific\nvisualization applications to ensure that scientists can trust the information being visualized. Currently, existing architectures do not\nsupport inference time reconstruction quality assessment, as coordinate-level errors cannot be evaluated in the absence of ground truth\ndata. By employing the uncertain neural network architecture in feature grid SRNs, we obtain prediction variances during inference\ntime to facilitate confidence-aware data reconstruction. Specifically, we propose a parameter-efficient multi-decoder SRN (MDSRN)\narchitecture consisting of a shared feature grid with multiple lightweight multi-layer perceptron decoders. MDSRN can generate a set of\nplausible predictions for a given input coordinate to compute the mean as the prediction of the multi-decoder ensemble and the variance\nas a confidence score. The coordinate-level variance can be rendered along with the data to inform the reconstruction quality, or be\nintegrated into uncertainty-aware volume visualization algorithms. To prevent the misalignment between the quantified variance and the\nprediction quality, we propose a novel variance regularization loss for ensemble learning that promotes the Regularized multi-decoder\nSRN (RMDSRN) to obtain a more reliable variance that correlates closely to the true model error. We comprehensively evaluate the\nquality of variance quantification and data reconstruction of Monte Carlo Dropout (MCD), Mean Field Variational Inference (MFVI),\nDeep Ensemble (DE), and Predicting Variance (PV) in comparison with our proposed MDSRN and RMDSRN applied to state-of-the-art\nfeature grid SRNs across diverse scalar field datasets. We demonstrate that RMDSRN attains the most accurate data reconstruction\nand competitive variance-error correlation among uncertain SRNs under the same neural network parameter budgets. Furthermore,\nwe present an adaptation of uncertainty-aware volume rendering and shed light on the potential of incorporating uncertain predictions\nin improving the quality of volume rendering for uncertain SRNs. Through ablation studies on the regularization strength and decoder\ncount, we show that MDSRN and RMDSRN are expected to perform sufficiently well with a default configuration without requiring\ncustomized hyperparameter settings for different datasets.", "sections": [{"title": "1 INTRODUCTION", "content": "Continuous functional representations of scientific datasets have gained\nattention as proxies for visualization and analysis thanks to their advan-\ntages in compactness, competitive modeling accuracy, and the ability\nto evaluate values and gradients at random locations without decod-\ning the full volume. A Scene Representation Network (SRN) is a\nneural functional representation trained with volume data to learn a\ncoordinate-value mapping to attain the aforementioned benefits. For\nthe past several years, the scientific visualization (SciVis) community\nhas improved SRN for volumetric data modeling in its compressive-\nness [12, 16, 23, 43], computational efficiency [43, 48, 52], and adaptivity\nto data [53].\nDespite the remarkable advancements in these areas, as a lossy\napproximation of the data, SRN lacks the ability to depict its prediction\nquality. Since each value prediction made by SRN exhibits a certain\nlevel of error compared to the ground truth, and the most inaccurate\npredictions are often present in regions with scientific features that\ninvolve complex spatial patterns, it is desirable to aid the process with\na quantifiable metric that reflects how accurately the SRN reconstructs\nthe data. However, it is non-trivial to obtain such a measurement of the\ncoordinate-wise prediction quality at inference time because evaluating\ncoordinate-wise prediction errors requires the ground truth data, which\nare often discarded after training. Alternatively, precomputing the error\nfield and writing it to the disk would incur considerable storage costs\nequivalent to the data size and hence defeats the purpose of using an\nSRN as a compact surrogate.\nIn this paper, we propose a method to indicate the prediction quality\nfor SRNs at inference time, which is storage-free and can be evaluated\nat arbitrary locations. We explore the application of uncertain neural net-\nwork architectures for computing prediction variances or uncertainties\nto indicate the confidence level of the model for its predictions. These\narchitectures, including Bayesian and ensemble methods [3, 9, 20], can\nbe used to make multiple plausible predictions for an input such that the\nvariance and mean prediction amounts to a more accurate prediction\nwith the error quantified. In addition to meeting the desired attributes\nfor a proper prediction quality metric, the computed coordinate-level\nvariance along with the mean can be conveniently granted a probabilis-\ntic interpretation and integrated into uncertainty-aware visualizations\nsuch as probabilistic marching cubes [32] and uncertain volume render-\ning [33], such that the uncertain predictions can be directly integrated\nto visualizations as an alternative to visualizing the mean predictions.\nTo empower SRNs with variance estimation for confidence-aware\npredictions, we introduce a feature grid SRN architecture with an en-\nsemble of decoders, dubbed multi-decoder SRN (MDSRN), that can\nseamlessly extend existing feature grid SRNs to produce different plau-\nsible predictions for any given input coordinate. Common ensemble\nmethods for variance quantification such as Deep Ensemble (DE) [20]\nrequire independent neural networks trained as members, thus result-\ning in a linear scaling of parameter counts to the number of members.\nThis might not be best suited for volumetric representations in SciVis\nwhere the compactness of the model is of great significance. To better\nadapt ensembling to feature grid SRNs with improved parameter effi-\nciency than DE, we propose a multi-decoder approach, and adapting\nour MDSRN to an existing feature grid SRN architecture simply re-\nquires training multiple MLP decoders along with a shared feature grid\nencoder. Feature grid SRNs usually have the majority of parameters\nconcentrated on the grid encoder, hence training additional lightweight\nMLPs only brings a negligible increase in the model size. Comparable\napproaches that can be applied to SRNs to generate uncertain predic-\ntions include the Bayesian neural network [3, 9] or directly predicting a\nvariance. However, they can suffer from inferior data reconstruction\naccuracy, and we show the proposed MDSRN architecture achieves\nhigher reconstruction accuracy with equivalent network size in Sec. 5.1.\nProvided that the variance of predictions for each voxel serves as a"}, {"title": "2 RELATED WORK", "content": "Our work targets adding error awareness to the predictions and visual-\nizations of scene representation networks (SRNs) with uncertain neural\nnetwork architectures, and we first review the fast-paced advancements\nof SRNs for scientific visualization, followed by related methods for\nuncertainty-aware neural networks.\n2.1 Scene Representation Network for Scientific Visualiza-\ntion\nOriginally proposed as continuous representations of 3D shapes or\nscenes [24, 28, 39], scene representation networks (SRNs), or equiv-\nalently implicit neural representations (INRs), are applied to SciVis\nas continuous and compact surrogates that go beyond the discretized\nscientific data formats and support decoding the value at any arbi-\ntrary coordinate without full volume reconstruction. A fully implicit\napproach of SRN that comprises multi-layer perceptrons (MLPs) for\nscientific data representation was first investigated by Lu et al. [23],\nand they proposed neurcomp that extends the MLP with sinusoidal\nactivation functions known as SIREN [38] with skip connections to\nachieve a high compression ratio for scalar field data in combination\nwith parameter quantization. SIREN-based SRNs were improved in\nvarious aspects following neurcomp. Han and Wang [14] showed the\nversatility of SRN in learning diverse tasks at both data and image levels\nfor spatial-temporal datasets. To increase the computational efficiency\nof SIREN SRNS, Tang and Wang [43] introduced ECNR that extends\nthe lightweight MLPs organized in a Laplacian pyramid proposed in\nMINER [34] to work on 4D scientific datasets with deep compres-\nsion strategies for a high compression rate. Targeting the compression\nof volume visualization images for spatial-temporal datasets, Gu et\nal. [12] proposed NeRVI that employs SIREN with skip connections\nand a CNN upscaling module for faster inference.\nAs the computational efficiency of MLP-based SRN can be concern-\ning, a hybrid SRN architecture that connects an explicit feature grid\nwith a lightweight MLP, namely feature grid SRN, attracted an interest\nin SciVis for fast SRNs. Weiss et al. [48] proposed fV-SRN with a\ncomposite encoder concatenating features from a dense feature grid and\nFourier feature encoding [24, 42] followed by an MLP with SnakeAlt\nactivation, and they further exploited GPU tensor cores for faster in-\nference. Wu et al. [52] achieved interactive training and visualization\nof hash grid SRN, known as NGP [26], with an optimized training\nand rendering routine with out-of-core sampling and sample streaming\nfor large-scale datasets. Bender et al. [16] explored the effectiveness\nof multi-grid and multi-decoder SRN in compressing meteorological\nensembles. We note the motivation for our multi-decoder ensemble\nSRN differs from the network by Bender et al. as they use the different\ndecoders to learn different volumes in an ensemble simulation dataset,\nwhereas our method applies to a single scalar field for variance quan-\ntification as a realization of ensemble neural network. Farokhmanesh\net al. [6] modeled bivariate correlations in ensemble datasets with a bi-\npartite hash grid SRN dubbed NDF. For better generalization to unseen\ninputs, Wu et al. [51] presented HyperINR with a hypernetwork on hash\ngrids trained with knowledge distillation. As scientific data can exhibit\ncertain degrees of sparsity, Wurster et al. [53] proposed APMGSRN to\nconcentrate SRN parameters to regions potentially containing scientific\nfeatures with high errors through learned transformations for multiple\nfeature grids.\n2.2 Uncertain Neural Network Architecture for Prediciton\nVariance Quantification\nThe critical necessity of understanding the trustworthiness of neural\nnetwork predictions spurred a rich set of research on uncertainty-aware\nneural network architectures [10]. These methods can be applied\nto neural networks such that an uncertain prediction with variance\nquantification can be obtained for regression tasks. Ensemble and\nBayesian Neural Network (BNN) are two prominent methods for this\npurpose. Monte Carlo Dropout (MCD) [9] and Mean Field Varia-\ntional Inference (MFVI) [3] are two practical realizations of BNN.\nAs for the ensemble approach, Deep Ensemble (DE) [20] advocated"}, {"title": "3 BACKGROUND", "content": "As we propose to equip feature grid SRNs with prediction variance\nquantification to indicate the quality of the prediction, we briefly review\nSRNs with feature grid encoders to which our method in Sec. 4 is\napplied as well as the related variance quantification approaches for\nneural networks that are compared in Sec. 5.1.\n3.1 Feature Grid Scene Representation Networks\nExtending the general discussion of SRNs for SciVis in Sec. 2.1, we\nformally define SRNs and highlight important properties of its feature\ngrid variants. A scene representation network (SRN) is a neural network\nthat predicts scalar or vector values from input coordinates, and its\narchitecture can be conceptually divided into two components, an\nencoder $E$ that transforms an input coordinate to a feature and a decoder\n$D$ that predicts the value given the feature. Formally, let $f$ be an SRN\nand $(x,y)$ be a coordinate-value mapping, the task of an SRN is to\nreconstruct $y$ given $x$: $f(x) = D(E(x)) = y$.\nAn initial application of SRNs to scientific data was explored by Lu\net al. [23]. They proposed neurcomp that uses multi-layer perceptrons\n(MLPs) for both the encoder and the decoder. Despite the high com-\npressiveness achieved by neurcomp, it is slow to evaluate as it consists\nof many wide fully connected layers. To improve the computational\nefficiency of SRNs, Weiss et al. [48] proposed fV-SRN that substitutes\nthe MLP encoder with a feature grid. A feature grid has learnable\nfeatures defined on each voxel, and an input coordinate can be encoded\nwith a trilinear-interpolated feature from neighboring voxels. The grid\nencoder can be evaluated more efficiently than an MLP which requires\na chain of matrix multiplications. Furthermore, the decoder can also\nbe made with fewer layers and neurons. As a result, the feature grid\nSRN can achieve considerable inference speedups. Following this\nconceptual model of grid encoders with lightweight decoders, more\nadvanced feature grid SRNs are proposed to further improve the ef-\nficiency and accuracy for large-scale scientific data, such as Neural\nGraphics Primitives (NGP) [26, 52] and the Adaptively Placed Multi-\nGrid SRN (APGMSRN) [53]. In Sec. 4, we introduce our approach that\ncan add to feature grid SRNs the ability of reliable prediction variance\nquantification with a modification to the given network architecture\nalong with a novel loss function, and our methods integrate well with\nstate-of-the-art models like fV-SRN, NGP, and APMPSRN.\n3.2 Prediction Variance Quantification for Neural Networks\nIn addition to our work that proposes a customized strategy to modify\nthe feature grid SRN architecture for variance quantification, there are\nalternative methods that can also be applied to achieve similar goals.\nSpecifically, we briefly review Monte Carlo Dropout (MCD) [9], Mean\nField Variational Inference (MFVI) [3], Deep Ensemble (DE) [20], and\nPredicting Variance (PV) [27] before evaluating them in Sec. 5.1.\nSimilar to our methods, MCD, MFVI, and DE enable the network to\nproduce multiple predictions to an input, from which a variance can be\ncomputed. Although dropout is initially proposed to reduce overfitting\nby randomly turning off neurons according to some probability [40],\nGal and Ghahramani [9] proposed to keep dropout at inference time\nsuch that different predictions can be acquired with multiple sets of\nnetwork weights after dropout trails, and this MCD method bears a\nBayesian neural network interpretation. MFVI [3] is another Bayesian\nmethod, and it requires the network to learn a posterior Gaussian distri-\nbution for every weight, such that the network weight distributions can\nbe sampled. Different samples of the network will in turn predict differ-\nently. DE [20] is a closely related method to ours as both approaches\nbelong to the ensemble technique for uncertainty quantification. In-\nstead of training one network, DE independently trains an ensemble of\nnetworks, such that the variance of the predictions from each member\nnetwork can be calculated as uncertainty.\nPV has a different realization of variance quantification compared to\nthe abovementioned methods in that the network directly predicts the\nvariance, and it was applied to SRNs, specifically neural radiance fields\n(NeRFs), by Pan et al. [27]. A PV network outputs both a mean and a\nvariance prediction, effectively predicting a Gaussian distribution, and\nit is optimized with the negative log-likelihood (NLL) loss from the\npredicted Gaussian and the ground truth."}, {"title": "4 REGULARIZED ENSEMBLE SCENE REPRESENTATION NET-\nWORK", "content": "Feature grid scene representation networks (SRNs) have received mul-\ntitudes of improvements in computational efficiency and accuracy as\nsurrogates for large-scale scientific data, yet there remains the question\nof where in the domain predictions can be trusted to be accurate such\nthat the volume visualization will be in high quality with respect to the\nground truth.\nWe explore extending feature grid SRNs with a network architecture\nthat produces multiple predictions for every input to acquire prediction"}, {"title": "4.1 Multi-Decoder Ensemble SRN Architecture", "content": "Deep Ensemble (DE) [20] provides high-quality variance quantification\nand predictive performance to neural networks by training an ensemble\nof member networks to acquire diverse predictions. Despite the attrac-\ntive performance of DE, an ensemble of independent member networks\ncan be parameter-intensive with a linear scaling factor to the number\nof members, which can lead to less optimal performance under a con-\nstrained parameter budget as in SRN tasks. To address the poor scaling\nof parameters of DE, we propose a parameter-efficient ensembling\nstrategy for feature grid SRNs, dubbed multi-decoder SRN (MDSRN),\nthat shares parameters between member networks. When construct-\ning an ensemble of feature grid SRNs, all members of an MDSRN\nmodel share the feature grid so that none of them learn separate grids.\nConsequently, the one shared feature grid can use higher resolutions\nand larger feature sizes that all members can benefit from. Apart from\nthe shared grid encoder, we do not share any layers in the multi-layer\nperceptron (MLP) decoder and instead use completely separate MLPs\nfor different members. This is to prevent an excessive level of similarity\nbetween member networks, which can lead to a spatially homogenous\nvariance that fails to distinguish regions that are challenging versus\neasy to learn.\nWe formally introduce the proposed MDSRN architecture that adds\nvariance quantification to feature grid SRNs. As illustrated in Fig. 1, to\nincorporate our multi-decoder strategy to a feature grid SRN, while the\nencoder in part (B) requires no modification, an ensemble of decoders\nin part (C) needs to be trained to output multiple predictions such\nthat a mean and a variance can be computed in part (D) for quality-\ninformed reconstruction and visualization. Following the notations in\nSec. 3.1, for an MDSRN containing $M$ member predictors that share\nthe same encoder with different decoders, denoted $f_i(x) = D_i(E(x))$\nwhere $i = 1,2,.., M$, the mean prediction and the variance are computed\nas follows:\n$$\\mu(x) = \\frac{\\sum_{i=1}^{M} f_i(x)}{M}$$\n$$\\sigma^2(x) = \\frac{\\sum_{i} (f_i(x) - \\mu(x))^2}{M-1}$$\n(1)\nThe design is inspired by the observation that the bottleneck lim-\niting the accuracy of an ensemble of SRNs is usually the capacity of\nthe member networks. For example, for the same number of total pa-\nrameters, an ensemble of 3 large independent SRNs often has a more\naccurate mean prediction than an ensemble of 5 smaller independent\nSRNs. This reveals a key to increasing the accuracy of an ensemble\nin a fixed compression level is to increase the capacity of member\nSRNs, and MDSRN achieves this through parameter-sharing. The\nmulti-decoder method can be applied easily to state-of-the-art feature\ngrid SRNs for scientific data including APMGSRN [53], NGP [26, 52],\nand fV-SRN [48] for post-training prediction confidence evaluation as\nMDSRN simply requires an ensemble of decoders of their specified\narchitectures, such as MLP with ReLU activation for APMGSRN or\nSnakeAlt activation [48] for fV-SRN, despite that as a limitation of the\nensemble method, training time can scale with the decoder members as\nshown in Sec. 5.1.\nTo optimize an MDSRN under the ensemble learning scheme simi-\nlarly to DE networks, each member is supervised with the ground truth\ndata to ensure they can make sufficiently plausible predictions. Let $x$\nand $y$ be a coordinate-value pair and $B$ denote the number of pairs in a\ntraining batch, the per-member loss function $L_{member}$ to train MDSRN\nin part (E) of Fig. 1 is defined as a sum of mean squared errors between\neach member's prediction and the ground truth:\n$$L_{MDSRN} = L_{member} = \\sum_{i=1}^{M} \\sum_{b=1}^{B} (f_i(x_b) - y_b)^2$$\n(2)"}, {"title": "4.2 Variance Regularization Loss Function", "content": "Although MDSRN provides improved parameter efficiency for better\ndata reconstruction accuracy than the conventional network ensemble\napproach at the same compression level, we found the spatial pattern of\nvariance does not always align with that of error, as illustrated in Fig. 2,\nand this can be problematic when the variance is utilized to evaluate the\nprediction quality. To mitigate the issue, our idea is to regularize the\nmodel with an additional loss function so that the regularized MDSRN\n(RMDSRN) learns to promote higher similarity between the variance\nand error. In addition, the adjustments to variance should be ideally\nbased on its own scale to avoid equating two different quantities with\npotentially disparate value ranges.\nWe propose to minimize the dissimilarity of the variance and error\nin the context of probability distributions to achieve scale-invariant\nmatching. By normalizing the variance and error fields such that both\nquantities integrate to one over the spatial domain, we can obtain\nvalid probability density functions (PDFs) in 3D. Furthermore, since\nthe density of a value at a location indicates the relative magnitude\nof the value compared with others over the domain, locations with\noverconfident variance can be naturally identified by those with lower\nvariance densities than the error densities. Consequently, minimizing\nthe difference between the two density functions effectively adjusts the\nvariance in a scale-invariant way.\nTo acquire proper densities for the variance and error, we can scale\neach of the values by their total aggregates in the volume. Formally,\nlet $X$ denote all coordinates encompassed by the volume extent and\n$v(x) = y$ be a function that returns the ground truth value at a location,\nthe variance density function $f_{\\sigma^2}$ and the error density function $f_{s}$ are\ndefined as:\n$$f_{\\sigma^2}(x) = \\frac{\\sigma^2(x)}{\\int_{x} \\sigma^2(x_j) dx_j}$$\n$$f_{s}(x) = \\frac{(\\mu(x) - v(x))^2}{\\int_{x} (\\mu(x_j) - v(x_j))^2 dx_j}$$\n(3)\nDespite Eq. (3) describes the density functions in the continuous\nspace over the volume for SRNs as continuous representations, only\nrandom voxel samples are available in a training batch from an opti-\nmization step. To compute the densities during training, we normalize\nthe variances and errors of the sampled points in a batch by their respec-\ntive sums, which is equivalent to replacing the integrals in Eq. (3) by\na summation over voxels in a batch, such that the densities constitute\ndiscrete approximations of Eq. (3). The batch-wise densities are fast to\ncompute and can update the model parameters for every optimization\nstep to work with the member reconstruction loss, and results in Tab. 1\nshow this approach can effectively align the variance of RMDSRN\nwith the error across the volume without increasing the training time\nsignificantly compared to MDSRN.\nAfter density functions are defined, we minimize their difference\nwith Kullback-Leibler (KL) divergence as a measure of dissimilarity\nbetween probability distributions, and Eq. (4) shows the variance reg-\nularization $L_{var}$ used during training. KL divergence especially helps\nRMDSRN prioritize matching the variance for high-error regions that\ncan greatly affect the accuracy of visualizations, and it is accomplished\nby weighing the log-space density difference by the error density, hence\npoints with high errors contribute more to the loss. We note that gra-\ndients incurred in the computation of error densities are not recorded,\nbecause we would like member models to minimize KL divergence\nsolely by steering the variance of their predictions toward similar pat-\nterns to error, so gradients should only flow from the loss function to\nthe variance densities.\n$$L_{var} = \\frac{1}{B} \\sum_{j=1}^{B} f_s(x_j)log(\\frac{f_s(x_j)}{f_{\\sigma^2}(x_j)})$$\n(4)\nBy adapting our multi-decoder design and the variance-regularized\ntraining as Fig. 1 presents, feature grid SRN can achieve reliable vari-\nance quantification. The loss function of the final Regularized MDSRN\n(RMDSRN) becomes a weighted sum of the member loss and the\nvariance regularization: $L_{RMDSRN} = L_{member} + \\lambda L_{var}$."}, {"title": "4.3 Training Regularized MDSRN with Exponential Growth\nWeight Scheduler", "content": "Compound loss functions usually benefit from appropriate weights on\neach term for the best results, such as in image generation networks like\nInSituNet [15] and FoVolNet [2]. The quality of a trained RMDSRN\nmodel is also dependent on a proper regularization strength $\\lambda$. We use\na $\\lambda$ scheduler to provide more robust training without requiring a hyper-\nparameter search as the detailed ablation study in Sec. 5.3 demonstrates.\nThe RMDSRN trained with the scheduler exhibits improved overall\nperformance than the unregularized MDSRN for a wide range as\nwell as the default recommendation.\nThe scheduler defined in Eq. (5) gradually increases $\\lambda$ from a min-\nimal value to a maximum at an exponential rate during training. The\nprinciple behind our $\\lambda$ scheduling is to silence the regularization in\nearly iterations and scale it up as the model approaches convergence\nin the member loss. The motivation is that since model predictions\nand hence errors will change after each optimization step, distribution\nmatching becomes a moving target. On the other hand, the true targets\nthat the variance should learn to correlate are the errors in later training\niterations, as they do not vary significantly and are more consistent\nrepresentations of the final RMDSRN error at inference time. With this\nprinciple, our scheduler starts $\\lambda$ with a small value ideally close to zero\nand keeps it small in the early iterations of training to allow a faster\nprogression of the model accuracy. Following exponential growth rates,\nin later stages of training, the scheduler can quickly raise $\\lambda$ to allow a\nsatisfactory fit to the final error pattern. The weight on training step $t$ is\ndefined as:\n$$\\lambda(t) = \\lambda_{min} + (\\lambda_{max} - \\lambda_{min}) \\frac{r^{\\frac{t}{t_{max}}}-1}{r-1}$$\n(5)\nAt step 1, the weight is the minimum value $\\lambda_{min}$ and it increases at\nan exponential rate to $\\lambda_{max}$ at the last training step $t_{max}$. Here $\\lambda_{max}$ is a\nhyperparameter to be tuned for the best result of variance regularization,\nwhile for $\\lambda_{min}$ a default of zero works generally. The parameter $r \\in$\n$(1,\\infty]$ controls the growth rate of the scheduler. Rates close to 1 result\nin linear-like growths and the higher the rate, the steeper the growth\nwill be in later iterations and the less weight for early iterations.\nAs the strength scheduler is applied jointly with learning rate decay,\nthe actual weight on the regularization is $\\lambda(t)$ in Eq. (5) multiplied by\nthe current learning rate. We visualize in Fig. 3 the combined strength\nthroughout training with a cosine annealing learning rate scheduler [22]\nused in Sec. 5.1 with an initial learning rate of 5.0e-3. For all $\\lambda_{max}$\nshown, $\\lambda_{min}$ and $r$ are set to 0 and 500. The combined strength grows\nslowly in early training and progresses quickly to a maximum before\n3/4 of training, followed by decreasing values until the end of training.\nThis follows our motivation to scale $\\lambda$ up in later training stages, and\nthe shrinking $\\lambda$ towards the end helps the regularization converge.\nIn summary, $\\lambda_{max}$ of the scheduler can be tuned for the best results\nfrom variance regularization. For $\\lambda_{min}$, setting it to zero should fit\nmost training scenarios. Regarding the growth rate $r$, we recommend a\ndefault $r$ of 500 so the weight does not grow significantly until around\n1/4 of the total training steps as visualized in Fig. 3. A detailed ablation"}, {"title": "5 EXPERIMENTS", "content": "To study the performance of uncertain neural network architectures on\nfeature grid SRNs for scientific data, we evaluate MDSRN, RMDSRN,\nDeep Ensemble (DE) [20], Monte Carlo Dropout (MCD) [9], Mean\nField Variational Inference (MFVI) [3], and Predicting Variance (PV)\nin reconstruction accuracy and variance quality with evaluation met-\nrics designed for volume visualization along with qualitative results in\nSec. 5.1. Related methods are reviewed in Sec. 3.2. We then study an\nadaptation of uncertainty-aware volume rendering [33] for uncertain\nSRNs in Sec. 5.2. Finally, we conduct ablation studies of the regular-\nization strength on RMDSRN as well as the ensemble member count\nfor both MDSRN and RMDSRN on Sec. 5.3 and Sec. 5.4.\n5.1\nUncertain Neural Network Architecture Evalaution\nWe quantitatively and qualitatively evaluate our methods, MDSRN and\nRMDSRN, against Deep Ensemble (DE), Monte Carlo Dropout (MCD),\nMean Field Variational Inference (MFVI), and Predicting Variance (PV)\nreviewed in Sec. 3.2. The uncertain architectures are adapted to three\nstate-of-the-art feature grid SRNs for five scalar field datasets with\ndifferent feature patterns and sparsity. We first detail the experiment\nsettings, and then introduce the evaluation methods and results for the\ndata reconstruction and variance quality tests.\nEvaluation datasets and base SRNs. The evaluated datasets include\nPlume, Nyx, Supernova, Asteroid, and Isotropic. The dimensions of the"}, {"title": "5.2 Uncertainty-Aware Volume Rendering with Uncertain\nSRNS", "content": "With uncertain SRNs outputting multiple predictions for any coordi-\nnate input, in addition to visualizing the variance as one presented\napproach for quality-informed visualization, the architectures open the\nopportunity for the application of probabilistic volume visualization\nalgorithms that work on uncertain data to produce uncertainty-aware\nvisualization [1, 8, 30\u201333].\nWe present our adaptations and results of the uncertainty-aware vol-\nume rendering technique proposed by Sakhaee et al. [33] for uncertain\nSRNs to directly incorporate the multiple predictions for every sampled\nlocation into the final rendered image, beyond rendering only the mean\nfield. In the statistical direct volume rendering (DVR) framework from\nSakhaee et al. [33], the uncertainty in the data values is integrated into\ntransfer function (TF) classification. For uncertain data with the value\nin each spatial location conforming to some probability distribution,\nthey propose to compute the expected color in a sampled location by\napplying the TF to all possible values and accumulating the colors as\nwell as opacities weighted by the probabilities of the values. To adapt\nthe statistical DVR framework for uncertain SRNs, we compute the\nexpected color by the sum of colors of each predicted value weighted\nby the probability of the prediction under the Gaussian distribution\nparameterized by the mean value and variance. The weights need to\nbe normalized by the total probabilities of all samples to ensure they\nsum to one before multiplying by the color and opacity. With this\nformulation, predictions closer to the mean are given higher weights\nthan others. This behavior can be justified by the observation that\nthe mean prediction is often more accurate than the samples for both\nensemble and BNN methods evaluated, hence samples more similar to\nthe mean are also expected to be higher-quality predictions, and they\nshould contribute more to the expected color and opacity.\nWe render fV-SRN-based uncertain SRNs for Isotropic with the\ndescribed adaptation of the uncertainty-aware TF classification method\nin comparison with the mean prediction renderings in Fig. 7. The\nmodels are from the experiments for Sec. 5.1. We observe the uncer-"}, {"title": "5.3 Ablation Study: Regularization Strength and Scheduler", "content": "The variance regularization endows RMDSRN with a reliable vari-\nance closely correlated to the error down to detailed spatial patterns\ncompared to other approaches, and this performance is tightly coupled\nwith an appropriate regularization strength. We study the behavior of\nRMDSRN under different $\\lambda_{max}$ in Fig. 8 with $\\lambda_{min}$ = 0 and r = 500 as\nthe settings of the $\\lambda$ scheduler, compared with an MDSRN baseline.\nWe test on Supernova, Nyx, and Asteroid with network configurations\nfor each dataset the same as in Sec. 5.1. In addition, we test RMDSRN\nwith constant $\\lambda$ throughout training without the proposed scheduler,\nand the results are labeled with a suffix of \"const $\\lambda$\".\nBefore we compare the performance of RMDSRN with a con-\nstant versus scheduled $\\lambda$, we first focus on discussing the results for\nRMDSRN with the scheduler plotted in red, yellow, and purple lines\nin Fig. 8. The right subplot shows stronger regularization monotoni-\ncally increases the variance-error correlation as shown in all datasets,\nwhereas the reconstruction accuracy can degrade after some threshold."}, {"title": "5.4 Ablation Study: Decoder Count", "content": "The number of decoder members can affect the performance of en-\nsemble networks, and we study the performance of our MDSRN and\nRMDSRN with different numbers of member decoders while keeping\nthe total model size constant. We test on Supernova with APGMSRN.\nAs Fig. 9 reveals, MDSRN does not exhibit an additional advantage\nin reconstruction accuracy with more decoders under a constant pa-\nrameter budget. This adheres to our empirical observation reported in\nSec. 4.1 that the most important factor affecting the ensemble accuracy\nis the capacity of member models. Nevertheless, the variance quality\nkeeps improving from 3 to 15 decoders. Following the results, a de-\ncoder of 5 for MDSRN can be a proper choice balancing both accuracy\nand variance quality. For RMDSRN, the reconstruction PSNR shows\na monotonic decrease for both $\\lambda_{max}$ of 5 and 10. Although RMDSRN\nwith $\\lambda_{max}$ = 30 shows increased performance from 3 to 5, the lower\nperformance of 3 decoders is likely a result of excessive regularization\nstrength, as the accuracy is substantially lower than MDSRN. As for\ntheir variance quality, decoder count is less impactful as the regular-\nization strength and the correlation change in response to different\nnumbers of decoders is minimal. Concluding from the observations,\n3"}]}