{"title": "MULTI-LABEL SCENE CLASSIFICATION IN REMOTE SENSING BENEFITS FROM\nIMAGE SUPER-RESOLUTION", "authors": ["Ashitha Mudraje", "Brian B. Moser", "Stanislav Frolov", "Andreas Dengel"], "abstract": "Satellite imagery is a cornerstone for numerous Remote Sensing (RS) applications; however, limited spatial resolution frequently hinders the precision of such systems, especially in multi-label scene classification tasks as it requires a higher level of detail and feature differentiation. In this study, we explore the efficacy of image Super-Resolution (SR) as a pre-processing step to enhance the quality of satellite images and thus improve downstream classification performance. We investigate four SR models - SRResNet, HAT, SeeSR, and RealESRGAN - and evaluate their impact on multi-label scene classification across various CNN architectures, including ResNet-50, ResNet-101, ResNet-152, and Inception-v4. Our results show that applying SR significantly improves downstream classification performance across various metrics, demonstrating its ability to preserve spatial details critical for multi-label tasks. Overall, this work offers valuable insights into the selection of SR techniques for multi-label prediction in remote sensing and presents an easy-to-integrate framework to improve existing RS systems.", "sections": [{"title": "1. INTRODUCTION", "content": "Remote Sensing (RS) is vital for monitoring and analyzing the Earth's surface [1]. However, despite the increasing demand for High-Resolution (HR) imagery in this domain, limited sensor capabilities often constrain fine-grained classification, detection, or mapping tasks [2, 3]. To alleviate these constraints - without relying solely on costly HR sensors or upgrades - image Super-Resolution (SR) offers a cost-efficient alternative by generating HR images from Lower-Resolution (LR) inputs [4]. While SR has been explored for various classification tasks [5, 6, 7], its influence on multi-label scene prediction in RS remains underexplored.\nIn RS, multi-label scene classification typically involves detecting multiple land cover types, urban structures, vegetation, or water bodies within a single satellite image, necessitating the capture of fine spatial details across diverse scales [8, 9]. Yet, with LR images, classical approaches often fail to capture subtle boundaries or small objects, ultimately leading to diminished precision [3]. By applying SR as pre-processing step, shown in Figure 1, models can leverage these finer features, leading to improved multi-label recognition [5].\nThis paper investigates the potential of SR to enhance multi-label scene classification in RS. We selected a range of pre-trained SR techniques - including diffusion-based, GAN-based, and CNN approaches and compare their performance on SR-enhanced and original LR images [10, 11, 12, 13]. Our findings highlight that using image SR excels at reconstructing spatial details critical for classification. As a result, the added details lead to improved identification of multiple labels within a single image. In summary, we shed light on the benefits and limitations of SR in improving downstream prediction accuracy."}, {"title": "2. RELATED WORK", "content": ""}, {"title": "2.1. Remote Sensing", "content": "Singh et al. [14] explore the application of satellite imagery for monitoring environmental changes. The authors leverage various machine learning and deep learning models such as ResNet[15], VGG[16], Inception[17], and so on to classify satellite images based on atmospheric conditions and land use. By employing multi-label classification, the authors captured the intricate relationships between different environmental factors.\nSimilar in spirit, Liu et al. [18] presents a simplified"}, {"title": "2.2. Image Super-Resolution", "content": "A trained SR model $M_{\\theta}: \\mathbb{R}^{H \\times W \\times C} \\rightarrow \\mathbb{R}^{sH \\times sW \\times C}$ should inverse the degradation relationship between a LR image $x \\in \\mathbb{R}^{H \\times W \\times C}$ and the HR image $y \\in \\mathbb{R}^{sH \\times sW \\times C}$, where s denotes the scaling. The optimization of $\\theta$ is based on a dataset $D_{SR} = \\{(x_i, y_i)\\}_{i=1}^{N}$ of N LR-HR pairs with the goal\n$\\theta^* = \\arg \\min_{\\theta} \\mathbb{E}_{(x,y) \\in D_{SR}}||M_{\\theta}(x_i) - y_i||^2$. (1)\nUsing SR have found use across diverse domains, ranging from medical imaging, where sharper images can critically affect patient outcomes, to satellite imagery, enabling more precise geographic analysis of the Earth's surface [20, 21]. This work investigates the influence of using existing and pre-trained SR methods as a pre-processing stage to RS downstream tasks."}, {"title": "3. METHODOLOGY", "content": "Our goal is to apply SR models of the form $M_{\\theta} : \\mathbb{R}^{H \\times W \\times C} \\rightarrow \\mathbb{R}^{sH \\times sW \\times C}$ prior to training a multi-label classifier to improve the precision of RS downstream tasks. Since the amount and quality of generally available images outnumber high-quality satellite images, we refer to pre-trained SR models with fixed parameters $\\theta$ rather than training a new model $M_{\\theta}$ from scratch."}, {"title": "3.1. SR Models", "content": "For SR methods, two primary factors drive performance: the model architecture $M_{\\theta}$ and the training objectives to optimize $\\theta$ [22]. For the latter, SR models can be categorized into two groups: regression-based models, which typically employ a regression loss, and generative SR models (GANs and diffusion models) [23].\nConsequently, we analyze representatives of each category. For regression-based models, we employ the ResNet-based model SRResNet [10, 24] and the vision transformer HAT [25, 11]. For generative SR, we analyze SeeSR [12] as a diffusion-based representative and RealESRGAN [13] as a representative for GANs. As image SR models are usually trained for 2x, 3x, or 4x, we will use 4\u00d7 pre-trained models to allow for maximum flexibility for the multi-label scene classifier."}, {"title": "3.2. Multi-Label Classifier", "content": "We adopt four commonly used models for multi-label scene classification, namely ResNet-50, ResNet-101, ResNet-152, and Inception-v4. We train each model under two configurations:\nBaseline (No SR): The network is trained directly on the original LR images (120 \u00d7 120).\nWith SR Pre-processing (SR): The network is trained on images super-resolved by one of the four SR models described in the previous Section (i.e., SRResNet, HAT, SeeSR, or RealESRGAN). We first apply the respective SR model (4\u00d7 i.e. 480 \u00d7 480 resolution) and then feed the enhanced images to the multi-label classifier."}, {"title": "3.3. Impact Assessment", "content": "To evaluate the impact of image SR models on the classifier under different aspects, we employ the following evaluation metrics:\nSample Accuracy (ACC): Measures the proportion of correctly predicted labels among all labels. Giving equal importance to each sample of the test set.\nHamming Loss (HL): Quantifies the fraction of misclassified labels, capturing the multi-label misalignment [26]. Lower HL indicates fewer label-wise errors.\nOne-Error (OE): Checks whether the top prediction (the label with the highest probability) is present in the true label set. A lower OE implies the model's highest-confidence prediction is more likely correct.\nPrecision (P), Recall (R), and F1-Score: Standard measures assessing the balance between correctly predicted labels (Precision) and the coverage of positive instances (Recall). F1 is their harmonic mean. All metrics are calculated based on the sample (test) data.\nMacro F2 Score: An extension of F1 that places additional emphasis on Recall. Useful when missing labels is costlier than having false positives."}, {"title": "4. EXPERIMENTS", "content": "We utilized a standard dataset for multi-label prediction in remote sensing for our experiments: BigEarth-Net [27, 28], containing 519,284 non-overlapping image patches, where CORINE Land Cover (CLC)[29] database provides one or more land cover class labels (multi-labels) for each image[30]. Each patch is a segment of 120 x 120 pixels for bands of 10m. These 10m band patches stacked to make RGB images(LR images)."}, {"title": "4.1. Quantitative Results", "content": "Table 1 shows the quantitative results. In short, training on SR-enhanced images outperforms the baseline across all classifier backbones, confirming the value of SR in recovering details beneficial for multi-label prediction. Notably, SRResNet achieves the highest accuracy on ResNet-50 and ResNet-101, demonstrating its strong performance in moderately deep networks. Meanwhile, HAT attains the best Hamming Loss on ResNet-101 and ResNet-152, indicating more precise label-wise predictions when paired with deeper architectures.\nRegarding One-Error, SRResNet provides the largest reduction on ResNet-50 (0.231 vs. 0.323 baseline). However, with deeper models such as ResNet-152, HAT outperforms SRResNet (0.241 vs. 0.295). This finding suggests that while SRResNet excels in shallower configurations, HAT's attention mechanisms align better with higher-capacity networks. Similarly, SRResNet consistently yields high F1 scores on ResNet-50, partly due to a robust balance of Precision and Recall. In contrast, HAT demonstrates stronger Precision and F1 in deeper setups (ResNet-152, Inception-v4).\nOverall, these three perspectives (ACC/HL, OE, and P/R/F1) show consistent performance trends yet emphasize different quality aspects. Despite their complementary perspectives, they collectively indicate that attention-based SR (i.e., HAT) delivers the strongest gains when paired with deeper networks. In contrast, SRResNet provides the best quality for smaller architectures. While all tested SR methods generally enhance multi-label prediction, generative approaches (i.e., SeeSR and RealESRGAN) hallucinate details, which explains their reduced positive impact, as exemplified in Figure 2.\nBy examining the class-level results via Macro F2 (see Table 2), we observe that SR notably boosts performance for certain land-cover types, particularly those defined by clear boundaries and texture (e.g., Marine and Inland Waters). Yet, while a SR method improves certain classes, it does not consistently improve predictions across all labels. These variations suggest that SR's effectiveness can be class-specific and should be factored into pre-processing decisions for multi-label RS tasks."}, {"title": "4.2. Qualitative Results", "content": "To gain deeper insight into how SR pre-processing influences network behavior, we employ Grad-CAM [31] to visualize class activation maps in the final convolutional layer of ResNet architectures. The results are shown in Figure 3. Overall, SR-enhanced images exhibit more pronounced and varied activations (highlighted by dark red or blue regions), indicating that the classifier focuses more strongly on distinct features. Interestingly, the strongest performance gains often coincide with broadly distributed positive CAM responses: for ResNet-50, SRResNet yields widespread high-intensity activations, whereas for ResNet-152, HAT demonstrates similarly extensive coverage. These observations align with the quantitative results, suggesting that spatially richer activations under SR pre-processing directly contribute to improved multi-label classification.\nOne plausible explanation for the observed performance gains and heightened activation variance is that higher resolution inputs better align with the receptive field that increases with deeper networks, allowing the classifier to extract richer, more discriminative features at each convolutional layer. Consequently, the classifier can more effectively utilize these cues when predicting multiple labels, leading to a broader and more varied activation map in the Grad-CAM visualizations and ultimately improving overall classification performance."}, {"title": "5. CONCLUSION & FUTURE WORK", "content": "In this study, we have investigated the potential of image SR as a pre-processing step for improving multi-label scene classification in RS. Our findings reveal that across diverse SR architectures (e.g., SRResNet, HAT, SeeSR, RealESRGAN) and classification backbones (ResNet-50, ResNet-101, ResNet-152, Inception-v4), SR-based enhancements can yield notable gains in multiple evaluation metrics, including accuracy, Hamming Loss, One-Error, F1-Score, and Macro F2 Score. Notably, SRResNet consistently boosted performance in shallower models (ResNet-50, ResNet-101), whereas the attention-based HAT approach aligned more effectively with deeper architectures (ResNet-152, Inception-v4). In conclusion, this study bridges the gap between SR and multi-label classification in satellite imagery, offering a robust framework for improving remote sensing applications.\nFuture work should also analyze the effect of using SR models trained on satellite images for multi-label scene classification."}]}