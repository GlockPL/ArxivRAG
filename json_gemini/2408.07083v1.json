{"title": "Masked EEG Modeling for Driving Intention Prediction", "authors": ["Jinzhao Zhou", "Justin Sia", "Yiqun Duan", "Yu-Cheng Chang", "Yu-Kai Wang", "Chin-Teng Lin"], "abstract": "Driving under drowsy conditions significantly escalates the risk of vehicular accidents. Although recent efforts have focused on using electroencephalography (EEG) to detect drowsiness, helping prevent accidents caused by driving in such states, seamless human-machine interaction in driving scenarios requires a more versatile EEG-based system. This system should be capable of understanding a driver's intention while demonstrating resilience to artifacts induced by sudden movements. This paper pioneers a novel research direction in BCI-assisted driving, studying the neural patterns related to driving intentions and presenting a novel method for driving intention prediction (DIP). In particular, our preliminary analysis of the EEG signal using independent component analysis (ICA) suggests a close relation between the intention of driving maneuvers and the neural activities in central-frontal and parietal areas. Power spectral density analysis at a group level also reveals a notable distinction among various driving intentions in the frequency domain. To exploit these brain dynamics, we propose a novel Masked EEG Modeling (MEM) framework for predicting human driving intentions, including the intention for left turning, right turning, and straight proceeding. Extensive experiments, encompassing comprehensive quantitative and qualitative assessments on a publicly available driving dataset, demonstrate the proposed MEM method is proficient in predicting driving intentions across various vigilance states. Specifically, our model attains an accuracy of 85.19% when predicting driving intentions for drowsy subjects, which shows its promising potential for mitigating traffic accidents related to drowsy driving. Ablation also demonstrates that our method significantly enhances the flexibility in handling missing channels. Notably, our method maintains over 75% accuracy when more than half of the channels are missing or corrupted, underscoring its adaptability in real-life driving scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Drowsy driving poses a substantial and increasing risk to transportation safety. In a drowsy cognitive state, a driver experiences impairment in both physical and mental faculties, leading to substantial delays in critical responses necessary to prevent accidents [1], [2]. To ensure safe driving, Brain-Computer Interface (BCI) technology has emerged as a precaution through real-time monitoring of the driver's cognitive state [3]. However, in the middle of long-distance driving, understanding and interpreting a driver's intentions in moments preceding potential danger can provide dynamic and nuanced safeguards that are aligned with the driver's objectives. Furthermore, understanding the driver's intentions could mark a pivotal stride in the evolution of BCI-assisted driving and the integration of human intention into the realm of human-machine interactions research.\nIn recent years, significant progress has been made in the decoding of tele-command [4], motor imagery (MI) [5], [6], and language [7] from non-invasive electroencephalography (EEG) signals. These studies have the potential to help people restore motor functionalities, control external devices, and reestablish communication with the outside world [8]\u2013[10]. Nonetheless, extracting a driver's intention from neural signals before the action is a considerable challenge. On the one hand, action planning and decision-making often involve complex cognitive processes. On the other hand, dissimilar to tasks such as MI, which typically allows two or more seconds for distinctive brain patterns to emerge from a tranquility state [11], predicting the driver's intention necessitates working with a brief EEG signal duration, potentially limiting the clarity of discerning underlying neural patterns associated with driving intentions [12]\u2013[14]. Last but not least, the proposed driving scenario is different from the controlled settings common in most EEG studies due to the dynamic driving environment, inherently posing challenges of sudden movements and potential electrode connectivity loss. Regrettably, current EEG decoding methods often falter when faced with heavily noisy signals or compromised electrodes, as highlighted in existing literature [15], [16].\nIn this paper, we study the brain activities associated with driving intentions by comprehensive analysis of decomposed EEG components, elucidating the relevant EEG channels and frequency bands associated with driving decisions. This analysis not only enhances the understanding of the neuro mechanisms involved but also provides insights for channel and frequency selection to remove inference from unrelated brain activities. For the challenge of modeling and predicting intention from EEG signals, we introduce a mask modeling approach called Masked EEG Modeling (MEM), aiming to improve the semantic level of EEG representation through a masked reconstructive training objective. To bolster the model's resilience against corrupted information or missing channels, two specialized masking strategies are incorporated in the frequency dimension and the channel dimension respectively. For the prediction of the driver's intention, we build a"}, {"title": "II. RELATED WORKS", "content": "Current BCI-based approaches related to our works are the EEG-based wheelchair control system [17], [18]. However, most approaches rely on the steady-state visual evoked potential (SSVEP) or MI methods which are not ideal to be applied in driving scenarios [19]. For instance, the visual stimuli for the SSVEP approach could pose significant dangers as additional distractions to the driver while the MI approach limits users to envisioning limb movements that are unnatural during driving.\nOn the other hand, existing research associating the human brain with driving mainly focused on estimating the driver's vigilance state [20], [21], fatigue [22] or mental workload [23]. To the best of our knowledge, no prior studies have investigated brain activities for the prediction of driving maneuver intentions.\nTo decode driving intentions efficiently, various deep learning models have been proposed for effective representations learning from EEG signals. Widely recognized networks such as EEGNet [24] and TCNet [25] leverage temporal and spatial features through convolutional neural networks (CNNs). Diverging from pure CNN architectures, Long Short-Term Memory (LSTM) models have been employed to enhance recognition performance on extended EEG signals [26]. Generalized architectures, such as Transformers [27], [28], have been implemented to enhance the model's capability for representation learning. Despite their proficiency in capturing temporal and spatial information, these models lack flexibility in handling missing or corrupted channels. Leveraging the efficacy of the recent masked modeling approach in diverse tasks [29], our work extends this strategy into the EEG domain. We introduce tailored masking strategies that enable effective EEG representation learning while accommodating missing information or channels."}, {"title": "III. METHOD", "content": "In this section, we delve into the details of the proposed MEM method for driving intention prediction. We begin with a concise overview of the DIP task in Section III-A. and subsequently, introduce the MEM method in Section III-B."}, {"title": "A. Task Setting for Driving Intention Prediction", "content": "The driving scenario for the DIP task is depicted in Figure 1. During driving, the car may deviate from the lane, requiring the driver to take corrective action. For real-time applicability and the reliability of neural patterns for driving intention, we extract EEG signals of duration $T = 0.5$ seconds before the action onset as sample data for left or right turning intentions. Similarly, EEG signals for straight proceeding intention are obtained $T + t_\\triangle$ seconds after the completion of the driving action, where $t_\\triangle$ is a 0.1-second offset. Conversely, the period of straight proceeding before deviation onset serves as the reference signal for mitigating inter-subject variations.\nGiven an EEG interface with a sampling rate of $f_s$, we are provided with a segment of multi-channel EEG signal $e$ consisting of $L = T \\times f_s$ timesteps and $N$ channels. The objective of the DIP task is to forecast the driving intention, denoted by $\\hat{c}$ solely based on $e$. Hence, the objective is to maximize the probability of the predicted driver intention $p(\\hat{c}|e)$."}, {"title": "B. Masked EEG Modeling", "content": "We introduce the MEM method, which leverages the masked autoencoder (MAE) [30] as the foundational model for effective representation learning in DIP. The integration of MAE is mainly used to address the challenges inherent in learning high-quality EEG representations. Remarkably, the encoder-decoder architecture and the self-attention building blocks enable flexible exploitation of spatial or temporal dependencies from the EEG signal, which is crucial for acquiring robust EEG filters and latent representations. Notably, the reconstructive self-supervised learning scheme compels the"}, {"title": "a) Preprocessing", "content": "Utilizing the raw EEG signal $e \\in \\mathbb{R}^{N \\times L}$, we employ Welch's method [31] to derive the estimated Power Spectral Density (PSD), transforming the raw EEG waves into the frequency domain. This process involves dividing the EEG signal into overlapping subsections, each subjected to windowing using a Hann window to mitigate edge effects. Following this, a Fast Fourier Transform (FFT) is applied to each subsection, producing a set of frequency"}, {"title": "b) Channel masking", "content": "For the channel masking strategy, we divide the frequency spectrogram $w$ into non-overlapping channels {$w_i$}$_{i=1,\\dots,N}$,$w_i \\in \\mathbb{R}^{d}$. Then we use a convolutional layer to process the frequency components from each channel into 1D EEG tokens of size $s$. Here, the convolutional layer works as a learnable filter in the frequency domain. Then we uniformly sample a number of channels to be masked out. This creates a self-supervised learning task for the encoder to infer complete global information from the partial observation of the EEG signal as well as learning the channel-wise spatial dependencies inherent in the EEG signal. More importantly, the EEG encoder can learn to handle different numbers of EEG channels, granting the model with flexibility to handle missing channels in real-life driving applications."}, {"title": "c) Frequency Masking", "content": "Diverging from the channel masking strategy, the frequency masking approach involves extracting and masking tokens along the frequency dimension by splitting $w$ into non-overlapping frequency bands across all channels {$w_{\\cdot j}$}$_{j=1,\\dots,d}$, $w_{\\cdot j} \\in \\mathbb{R}^{N}$. We also employ a convolutional layer to transform each EEG patch into EEG tokens of size $s$. Unlike the channel masking strategy, the convolutional layer mainly functions as a spatial filter adept at learning patterns specific to a given frequency band across all channels. The self-supervised learning task introduced by the frequency masking strategy differs markedly from that associated with the channel masking strategy, as it cannot be easily resolved"}, {"title": "d) EEG Encoder and Decoder", "content": "The MEM architecture utilizes 2 transformer blocks with the same hidden embedding size $s$ as the EEG token for both the encoder and decoder. We use $s = 512$ in our model. Each transformer block is configured with 4 attention heads. To ensure consistency in input length, mask tokens are incorporated into the latent representations $z \\in \\mathbb{R}^{N \\times s}$ by the encoder, aligning the input to the decoder with the original EEG tokens' length before masking. Additionally, positional embeddings are added to the input EEG tokens before masking and the full-size latent representation before being fed to the decoder."}, {"title": "e) Classifier", "content": "To utilize the representation learned by the encoder from each EEG token and handle a different number of output tokens, we use an adaptive pooling layer to aggregate information from all EEG representations and add a fully connected layer as a classifier to classify $z$ into driving intention $\\hat{c}$."}, {"title": "f) Training MEM with Scheduled Masking Ratio", "content": "The training process commences with a scheduled masking strategy that systematically increases the masking ratio of EEG tokens over time. This incremental elevation of the masking ratio serves the purpose of dynamically challenging the model with varying degrees of information loss, thereby presenting a more diverse and progressively demanding training set. In our experimental setup, the MEM is initially trained with a masking ratio of 0.05 for 200 epochs. Subsequently, we iteratively raise the masking ratio in increments of 0.1, reaching up to 0.9, every 200 training epoch.\nWe simultaneously optimize both the classification and reconstruction objectives for training MEM. The classification objective is a cross-entropy loss function as written in Eq. 1.\n$L_{cls} = - \\frac{1}{M} \\sum_{i=1}^M c_i \\log(p(c_i|w_i))$ (1)\nwhere M denotes the number of training samples, $c_i$ and $\\hat{c_i}$ denote the grounth-truth and predicted intention label of the $i^{th}$ sample respectively. The MEM employs a mean square error (MSE) reconstructive objective (Eq. 2), measuring the difference between the input EEG signal before masking and the reconstructed EEG signal as written below:\n$L_{mse} = \\frac{1}{Md} \\sum_{i=1}^M ||w_i - \\hat{w_i}||_2^2$ (2)\nThe composite training loss function is expressed as follows:\n$L = L_{cls} + \\alpha \\cdot L_{mse}$ (3)\nwhere represents, and $\\alpha$ is the coefficient for the reconstructive term. In our experiments, we set $\\alpha = 0.1$. This training strategy enables MEM to jointly optimize both classification"}, {"title": "IV. EXPERIMENT", "content": "Our study utilizes the publicly available Sustained Attention Driving (SAD) dataset [32] for analyzing brain activities related to driving intentions as well as evaluation of the proposed MEM model. This dataset encompasses EEG recordings from a total of 27 participants undertaking a 90-minute driving task in a virtual reality (VR) environment. Participants were instructed to maintain a straight course throughout the study. However, lane-departure events will be randomly initiated, causing the car to drift away from its designated lane. Participants were required to steer the car back to the original lane. The EEG signals were collected at a sampling rate of $f_s = 500$Hz using a wired EEG cap with 30 EEG channels and 2 reference channels. In our experiment, a total number of 16 subjects (5, 11, 22, 35, 40, 41, 42, 43, 44, 45, 48, 50, 52, 53, 54, 55) were selected for DIP evaluation due to the relatively consistent brain patterns exhibited by these subjects throughout their experiment.\nA trial in this experiment consists of straight proceeding, lane deviation, steering (response), and eventually back to straight proceeding. Deviation onset will be recorded for each drifting event; response onset and response offset will be recorded at the start and the end of the steering respectively. The driving intention was labeled based on the direction of the steering, and the response onset according to the description in Section III-A. To label the vigilance state of the participant,\nWe follow the settings from the well-established drowsiness detection research [33], [34], [34], [35] and assign each driving epoch into three levels of vigilance states including drowsy, transition, and alert according to the local reaction time (local-RT), which represents the interval between deviation onset and the subject's response onset. An individualized baseline, alert-RT, was established by calculating the 5th percentile of a subject's local-RTs. A trial was labeled as 'alert' if the local-RT was less than 1.5 times the alert-RT and 'drowsy' if it exceeded 2.5 times the alert-RT. A transition state encompassed trials falling within the two preceding states. This method effectively distinguishes the three vigilance levels of each subject. Finally, we split each vigilance state's data into non-overlapping train, validation, and test (80%, 10%, 10%). The complete statistics of the dataset are shown in Table I. We use the training set for training our model, and the validation set for model selection.\nWe report DIP performance evaluated on the test set in the experiment sections."}, {"title": "B. Analysis of Driver's neural activities for driving intentions", "content": "To identify highly activated brain sources corresponding to driving intentions, Independent Component Analysis (ICA) is utilized to analyze brain dynamics associated with driving intentions across different vigilance states. We isolate ICs with above 70% probability of representing brain activities for further analysis. Subsequently, we calculate the PSD for"}, {"title": "C. Evaluation on Driving Intention Prediction", "content": "We first implemented a few baseline methods trained on the SAD dataset's training split. Then we evaluated the baseline methods with our proposed mask modeling framework in Section III on various settings."}, {"title": "a) Baselines", "content": "ViT A Transformer-based baseline comprises a stack of Transformer blocks [39], each consisting of self-attention mechanisms and feedforward neural networks. We maintain the Vit structure to be similar to the proposed MEM encoder using 2 transformer blocks with 4 attention head and the hidden size of 512"}, {"title": "b) Evaluation mectrics", "content": "In our experiment, the performance of the proposed MEM method and the baseline methods are comprehensively evaluated using both the micro accuracy and the marco metrics including precision, recall, and F1-"}, {"title": "c) Main Results on DIP", "content": "We first conduct experiments using only the alert state data and then we evaluate the alert (AS), transition (TS), and drowsy (DS) states in a within-subject setting. This is because alert state data is easiest to collect in real-life scenarios. Then we expand the training dataset by adding the other vigilance states (AS+TS+DS), with a hypothesis that models should be able to benefit from the expansion of the training data and the increase of data diversity. Results in Table II show the performance of baseline models and our model on predicting driving intentions.\nCompared to training solely on the alert state driving data, the proposed model is able to benefit from the increase of training samples and vigilance states diversity, exemplified by the significant increase of testing accuracy for the prediction in the transition state (TS) from 38.48% to 72.04%. On the other hand, we find that our model's prediction performance in a drowsy state (Accuracy: 85.19%) surpasses the performance in an alert state (Accuracy: 74.48%) by over 10%. We consider the major reason to be due to the additional cognitive load and motor planning in the preparation of a turning maneuver when the driver is forced to respond to deviation events from a drowsy mental state. Thus eliciting stronger and more identical neural activities whereas during an alert state, the brain only exhibits a baseline level of activity necessary for maintaining attention and responsiveness to the change of environment. Figure 5 shows the confusion matrix of the frequency mask model in different vigilance states. For the transition and drowsy vigilance state, the proposed model performs very well in the separation of the straight proceeding state as compared to the right or left turning intention with only a handful of straight samples classified as turning intention. This is especially important for a safety system since undesired turning on the highway could be dangerous. On the other hand, during an alert state, our model excels in classifying between left and right turning intentions, which demonstrates the superior representation learning capacity to exploit spatial and temporal dependencies."}, {"title": "D. Evaluation results on different masking strategies", "content": "Table III illustrates the comparison between two proposed mask modeling strategies for mask EEG modeling. From the results, we could observe that when only trained on alert state data, the MEM model with frequency masking strategy performs better on the seen vigilance states during training (awake) than unseen vigilance states (drowsy and transition), this is exemplified by the observation that the frequency masking model performs better on the awake vigilance state (accuracy on AS: 50.85%) while underperformed by the channel masking model on all other vigilance states.\nHowever, when presented with a more diverse vigilance condition during the training phase, the frequency masking strategy results in more comprehension and discrimination of driving intentions across all vigilance states when compared to the channel masking strategy. On the other hand, although the channel masking strategy did not outperform the frequency"}, {"title": "E. Ablation Study", "content": "In this section, we conduct an ablation study on the proposed MEM method, specifically evaluating the impact of the scheduled masking strategy as well as the impact brought by the reconstruction term. We compare three variants of the MEM model including the MEM trained by the scheduled masking ratio (red), MEN trained by a fixed masking ratio (blue), and MEM without reconstructive objective and with a fixed masking ratio (green). We evaluate these models'"}, {"title": "V. CONCLUSION", "content": "This paper presents a pioneering advancement in BCI technology tailored for assisted driving scenarios, with a primary focus on decoding a driver's intentions from EEG signals through the proposed DIP task. The envisioned integration of our task into existing automatic driving systems holds the potential to enable automatic driving systems to align their actions seamlessly with the human's goals or intentions. Our work unveils activation patterns within central-frontal and parietal components, as decomposed by ICA, offering valuable insights into neural dynamics during the intention stage of driving actions. To effectively predict the driver's intention, this paper proposed the MEM framework for learning EEG representations via a masked reconstruction approach. Extensive experiments were conducted on a publicly available dataset, results show that our MEM method achieved 85.19% accuracy on drowsy states and maintained robust performance even with missing or corrupted channels. Emphasizing MEM's adaptability to artifacts and potential applications in real-world scenarios. However, there is room for performance improvement compared to the state-of-the-art speech recognition systems. In the future, we will extend our focus to real-time and continuous decoding of driver intentions without necessitating the pre-segmentation of action intention EEG signals, further enhancing human-machine interaction for safe driving."}]}