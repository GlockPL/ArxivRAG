{"title": "Masked EEG Modeling for Driving Intention Prediction", "authors": ["Jinzhao Zhou", "Justin Sia", "Yiqun Duan", "Yu-Cheng Chang", "Yu-Kai Wang", "Chin-Teng Lin"], "abstract": "Driving under drowsy conditions significantly escalates the risk of vehicular accidents. Although recent efforts have focused on using electroencephalography (EEG) to detect drowsiness, helping prevent accidents caused by driving in such states, seamless human-machine interaction in driving scenarios requires a more versatile EEG-based system. This system should be capable of understanding a driver's intention while demonstrating resilience to artifacts induced by sudden movements. This paper pioneers a novel research direction in BCI-assisted driving, studying the neural patterns related to driving intentions and presenting a novel method for driving intention prediction (DIP). In particular, our preliminary analysis of the EEG signal using independent component analysis (ICA) suggests a close relation between the intention of driving maneuvers and the neural activities in central-frontal and parietal areas. Power spectral density analysis at a group level also reveals a notable distinction among various driving intentions in the frequency domain. To exploit these brain dynamics, we propose a novel Masked EEG Modeling (MEM) framework for predicting human driving intentions, including the intention for left turning, right turning, and straight proceeding. Extensive experiments, encompassing comprehensive quantitative and qualitative assessments on a publicly available driving dataset, demonstrate the proposed MEM method is proficient in predicting driving intentions across various vigilance states. Specifically, our model attains an accuracy of 85.19% when predicting driving intentions for drowsy subjects, which shows its promising potential for mitigating traffic accidents related to drowsy driving. Ablation also demonstrates that our method significantly enhances the flexibility in handling missing channels. Notably, our method maintains over 75% accuracy when more than half of the channels are missing or corrupted, underscoring its adaptability in real-life driving scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Drowsy driving poses a substantial and increasing risk to transportation safety. In a drowsy cognitive state, a driver experiences impairment in both physical and mental faculties, leading to substantial delays in critical responses necessary to prevent accidents [1], [2]. To ensure safe driving, Brain-Computer Interface (BCI) technology has emerged as a precaution through real-time monitoring of the driver's cognitive state [3]. However, in the middle of long-distance driving, understanding and interpreting a driver's intentions in moments preceding potential danger can provide dynamic and nuanced safeguards that are aligned with the driver's objectives. Furthermore, understanding the driver's intentions could mark a pivotal stride in the evolution of BCI-assisted driving and the integration of human intention into the realm of human-machine interactions research.\nIn recent years, significant progress has been made in the decoding of tele-command [4], motor imagery (MI) [5], [6], and language [7] from non-invasive electroencephalography (EEG) signals. These studies have the potential to help people restore motor functionalities, control external devices, and reestablish communication with the outside world [8]\u2013[10]. Nonetheless, extracting a driver's intention from neural signals before the action is a considerable challenge. On the one hand, action planning and decision-making often involve complex cognitive processes. On the other hand, dissimilar to tasks such as MI, which typically allows two or more seconds for distinctive brain patterns to emerge from a tranquility state [11], predicting the driver's intention necessitates working with a brief EEG signal duration, potentially limiting the clarity of discerning underlying neural patterns associated with driving intentions [12]\u2013[14]. Last but not least, the proposed driving scenario is different from the controlled settings common in most EEG studies due to the dynamic driving environment, inherently posing challenges of sudden movements and potential electrode connectivity loss. Regrettably, current EEG decoding methods often falter when faced with heavily noisy signals or compromised electrodes, as highlighted in existing literature [15], [16].\nIn this paper, we study the brain activities associated with driving intentions by comprehensive analysis of decomposed EEG components, elucidating the relevant EEG channels and frequency bands associated with driving decisions. This analysis not only enhances the understanding of the neuro mechanisms involved but also provides insights for channel and frequency selection to remove inference from unrelated brain activities. For the challenge of modeling and predicting intention from EEG signals, we introduce a mask modeling approach called Masked EEG Modeling (MEM), aiming to improve the semantic level of EEG representation through a masked reconstructive training objective. To bolster the model's resilience against corrupted information or missing channels, two specialized masking strategies are incorporated in the frequency dimension and the channel dimension respectively. For the prediction of the driver's intention, we build a"}, {"title": "II. RELATED WORKS", "content": "Current BCI-based approaches related to our works are the EEG-based wheelchair control system [17], [18]. However, most approaches rely on the steady-state visual evoked potential (SSVEP) or MI methods which are not ideal to be applied in driving scenarios [19]. For instance, the visual stimuli for the SSVEP approach could pose significant dangers as additional distractions to the driver while the MI approach limits users to envisioning limb movements that are unnatural during driving.\nOn the other hand, existing research associating the human brain with driving mainly focused on estimating the driver's vigilance state [20], [21], fatigue [22] or mental workload [23]. To the best of our knowledge, no prior studies have investigated brain activities for the prediction of driving maneuver intentions.\nTo decode driving intentions efficiently, various deep learning models have been proposed for effective representations learning from EEG signals. Widely recognized networks such as EEGNet [24] and TCNet [25] leverage temporal and spatial features through convolutional neural networks (CNNs). Diverging from pure CNN architectures, Long Short-Term Memory (LSTM) models have been employed to enhance recognition performance on extended EEG signals [26]. Generalized architectures, such as Transformers [27], [28], have been implemented to enhance the model's capability for representation learning. Despite their proficiency in capturing temporal and spatial information, these models lack flexibility in handling missing or corrupted channels. Leveraging the efficacy of the recent masked modeling approach in diverse tasks [29], our work extends this strategy into the EEG domain. We introduce tailored masking strategies that enable effective EEG representation learning while accommodating missing information or channels."}, {"title": "III. METHOD", "content": "In this section, we delve into the details of the proposed MEM method for driving intention prediction. We begin with a concise overview of the DIP task in Section III-A. and subsequently, introduce the MEM method in Section III-B.\nThe driving scenario for the DIP task is depicted in Figure 1. During driving, the car may deviate from the lane, requiring the driver to take corrective action. For real-time applicability and the reliability of neural patterns for driving intention, we extract EEG signals of duration T = 0.5 seconds before the action onset as sample data for left or right turning intentions. Similarly, EEG signals for straight proceeding intention are obtained T + t\u25b3 seconds after the completion of the driving action, where t\u25b3 is a 0.1-second offset. Conversely, the period of straight proceeding before deviation onset serves as the reference signal for mitigating inter-subject variations.\nGiven an EEG interface with a sampling rate of fs, we are provided with a segment of multi-channel EEG signal e consisting of L = T \u00d7 fs timesteps and N channels. The objective of the DIP task is to forecast the driving intention, denoted by \u0109 solely based on e. Hence, the objective is to maximize the probability of the predicted driver intention p(\u0109|e).\nWe introduce the MEM method, which leverages the masked autoencoder (MAE) [30] as the foundational model for effective representation learning in DIP. The integration of MAE is mainly used to address the challenges inherent in learning high-quality EEG representations. Remarkably, the encoder-decoder architecture and the self-attention building blocks enable flexible exploitation of spatial or temporal dependencies from the EEG signal, which is crucial for acquiring robust EEG filters and latent representations. Notably, the reconstructive self-supervised learning scheme compels the"}, {"title": "III. METHOD", "content": "After frequency domain conversion, our MEM method transforms the EEG spectrogram into EEG tokens by the patchifying operation. Subsequently, a masking strategy is applied to shuffle and mask out a portion of the unmasked EEG tokens. A lightweight transformer encoder is then utilized to process the unmasked tokens into latent EEG representations. Afterward, we use mask tokens that contain no information to represent missing tokens and fill the latent representation to the full length of the unmasked EEG tokens. Finally, another transformer decoder that shares the same structure as the encoder is used to reconstruct the original EEG signal from the latent EEG representation and the mask tokens.\nCompared to images, EEG signals differ significantly in terms of how their information is organized. While information from images is typically conveyed by patches that capture spatial patterns for visual clues, neural activities from EEG signals are mainly organized by channels and frequency bands. Therefore, patchifying and masking methods specific to EEG modeling are needed to learn effective representation learning. Moreover, to cope with the driving scenario, where drastic physical movements or faulty electrodes often introduce noise or cause channel disconnection, we present two specifically designed masking strategies in Section III-B0b and III-B0c.\nUtilizing the raw EEG signal e \u2208 RN\u00d7L, we employ Welch's method [31] to derive the estimated Power Spectral Density (PSD), transforming the raw EEG waves into the frequency domain. This process involves dividing the EEG signal into overlapping subsections, each subjected to windowing using a Hann window to mitigate edge effects. Following this, a Fast Fourier Transform (FFT) is applied to each subsection, producing a set of frequency components for each segment. The power spectrum for each segment is then computed by squaring the magnitude of the Fourier coefficients. Finally, Welch's PSD estimation w\u2208 RN\u00d7d is a frequency spectrogram derived from the averaged power spectra of various segments, where d represents the number of selected frequency components used to represent e in the frequency domain. This preprocessing step allowed us to estimate the PSD of each frequency component, capturing the energy distribution of the EEG signals at specific frequencies.\nFor the channel masking strategy, we divide the frequency spectrogram w into non-overlapping channels {wi}i=1,\u2026,N,Wi. \u2208 Rd. Then we use a convolutional layer to process the frequency components from each channel into 1D EEG tokens of size s. Here, the convolutional layer works as a learnable filter in the frequency domain. Then we uniformly sample a number of channels to be masked out. This creates a self-supervised learning task for the encoder to infer complete global information from the partial observation of the EEG signal as well as learning the channel-wise spatial dependencies inherent in the EEG signal. More importantly, the EEG encoder can learn to handle different numbers of EEG channels, granting the model with flexibility to handle missing channels in real-life driving applications.\nDiverging from the channel masking strategy, the frequency masking approach involves extracting and masking tokens along the frequency dimension by splitting w into non-overlapping frequency bands across all channels {w.j}j=1,\u2026,d, W.j\u2208RN. We also employ a convolutional layer to transform each EEG patch into EEG tokens of size s. Unlike the channel masking strategy, the convolutional layer mainly functions as a spatial filter adept at learning patterns specific to a given frequency band across all channels. The self-supervised learning task introduced by the frequency masking strategy differs markedly from that associated with the channel masking strategy, as it cannot be easily resolved"}, {"title": "III. METHOD", "content": "through interpolation from unmasked channels. Hence, the encoder needs to make use of redundant or complementary information from the remaining frequency bands to mitigate the impact of the missing information or learn to dynamically adjust its sensitivity to other frequency bands when the most informative ones are masked out.\nThe MEM architecture utilizes 2 transformer blocks with the same hidden embedding size s as the EEG token for both the encoder and decoder. We use s = 512 in our model. Each transformer block is configured with 4 attention heads. To ensure consistency in input length, mask tokens are incorporated into the latent representations z \u2208 RN\u00d7s by the encoder, aligning the input to the decoder with the original EEG tokens' length before masking. Additionally, positional embeddings are added to the input EEG tokens before masking and the full-size latent representation before being fed to the decoder.\nTo utilize the representation learned by the encoder from each EEG token and handle a different number of output tokens, we use an adaptive pooling layer to aggregate information from all EEG representations and add a fully connected layer as a classifier to classify z into driving intention \u00ea.\nThe training process commences with a scheduled masking strategy that systematically increases the masking ratio of EEG tokens over time. This incremental elevation of the masking ratio serves the purpose of dynamically challenging the model with varying degrees of information loss, thereby presenting a more diverse and progressively demanding training set. In our experimental setup, the MEM is initially trained with a masking ratio of 0.05 for 200 epochs. Subsequently, we iteratively raise the masking ratio in increments of 0.1, reaching up to 0.9, every 200 training epoch.\nWe simultaneously optimize both the classification and reconstruction objectives for training MEM. The classification objective is a cross-entropy loss function as written in Eq. 1.\n$$L_{cls} = - \\frac{1}{M} \\sum_{i=1}^{M} c_i log(p(c_i|w_i))$$\nwhere M denotes the number of training samples, ci and \u0109i denote the grounth-truth and predicted intention label of the ith sample respectively. The MEM employs a mean square error (MSE) reconstructive objective (Eq. 2), measuring the difference between the input EEG signal before masking and the reconstructed EEG signal as written below:\n$$L_{mse} = \\frac{1}{M} \\sum_{i=1}^{M} \\lVert w_i - \\hat{w_i} \\rVert_2^2$$\nThe composite training loss function is expressed as follows:\n$$L = L_{cls} + \\alpha \\cdot L_{mse}$$\nwhere represents, and a is the coefficient for the reconstructive term. In our experiments, we set a = 0.1. This training strategy enables MEM to jointly optimize both classification"}, {"title": "IV. EXPERIMENT", "content": "Our study utilizes the publicly available Sustained Attention Driving (SAD) dataset [32] for analyzing brain activities related to driving intentions as well as evaluation of the proposed MEM model. This dataset encompasses EEG recordings from a total of 27 participants undertaking a 90-minute driving task in a virtual reality (VR) environment. Participants were instructed to maintain a straight course throughout the study. However, lane-departure events will be randomly initiated, causing the car to drift away from its designated lane. Participants were required to steer the car back to the original lane. The EEG signals were collected at a sampling rate of fs = 500Hz using a wired EEG cap with 30 EEG channels and 2 reference channels. In our experiment, a total number of 16 subjects (5, 11, 22, 35, 40, 41, 42, 43, 44, 45, 48, 50, 52, 53, 54, 55) were selected for DIP evaluation due to the relatively consistent brain patterns exhibited by these subjects throughout their experiment.\nA trial in this experiment consists of straight proceeding, lane deviation, steering (response), and eventually back to straight proceeding. Deviation onset will be recorded for each drifting event; response onset and response offset will be recorded at the start and the end of the steering respectively. The driving intention was labeled based on the direction of the steering, and the response onset according to the description in Section III-A. To label the vigilance state of the participant, We follow the settings from the well-established drowsiness detection research [33], [34], [34], [35] and assign each driving epoch into three levels of vigilance states including drowsy, transition, and alert according to the local reaction time (local- RT), which represents the interval between deviation onset and the subject's response onset. An individualized baseline, alert-RT, was established by calculating the 5th percentile of a subject's local-RTs. A trial was labeled as 'alert' if the local-RT was less than 1.5 times the alert-RT and 'drowsy' if it exceeded 2.5 times the alert-RT. A transition state encompassed trials falling within the two preceding states. This method effectively distinguishes the three vigilance levels of each subject. Finally, we split each vigilance state's data into non-overlapping train, validation, and test (80%, 10%, 10%). The complete statistics of the dataset are shown in Table I. We use the training set for training our model, and the validation set for model selection. We report DIP performance evaluated on the test set in the experiment sections.\nTo identify highly activated brain sources corresponding to driving intentions, Independent Component Analysis (ICA) is utilized to analyze brain dynamics associated with driving intentions across different vigilance states. We isolate ICs with above 70% probability of representing brain activities for further analysis. Subsequently, we calculate the PSD for"}, {"title": "IV. EXPERIMENT", "content": "each identified brain component to characterize the frequency content of the identified brain sources. Figure 3 presents PSD plots for driving intentions during different vigilance states, focusing on the central-frontal (Figure 3(a)) and parietal (Figure 3(b)) components for brevity. From a general perspective, ICA decomposition results show that drivers exhibit strong activities originating in the central-frontal and parietal areas, which suggests the involvement of these areas in sensorimotor coordination, cognitive control, and decision-making before steering. This finding is aligned with the neural functionality of the central-frontal and parietal areas [36].\nFor comparison in the central-frontal area (Figure.3(a)), we could observe that there is a significant spectral difference between left (blue) and right (red) steering intention in the frequency bins from 5 to 10Hz during the three driving intentions. Similarly, a significant difference between straight proceeding intention (green) and turning intention (red and blue) could be observed in the parietal areas (Figure 3(b)). These findings suggest that the driver's driving intention could be discriminated through the brain dynamics. However, the parietal area is frequently less vulnerable to artifacts compared to the frontal area, which enjoys a crucial advantage in the context of driving scenarios where artifacts are prevalent [37]. Furthermore, the parietal region play a more significant role in visuospatial processing, aiding in navigation and responding to changes in the traffic environment. With joint consideration of the neurodynamics and the functionality of the components, we selected 12 relevant channels as input (N = 12) to the MEM model, including C3, CZ, C4, CP3, CPZ, CP4, P3, PZ, P4, 01, OZ, O2 covering mainly the parietal area.\nWhile the ICA decomposition reveals clear patterns in EEG signals, its direct application in a real-time decoding system is hindered by computational complexity and limited control over its components. To gain deeper insights into the frequency domain characteristics of brain activity related to driving intentions, we opted for a more lightweight analysis based on the"}, {"title": "IV. EXPERIMENT", "content": "raw EEG waves using Welch's method [31]. After converting each EEG sample into Welch's frequency domain, we removed reference frequency from the Welch PSD for each subject and aggregated the PSD frequency bands across subjects during left, right, and straight proceeding intentions, we conducted a comprehensive examination. The visual representation of our findings is depicted in Figure 4. Notably, across all vigilance states, a substantial difference in the 6 to 14Hz frequency bin is observed. This discrepancy is most pronounced in the drowsy state, while it becomes less significant during the transition state. From a neuroscience perspective, this frequency range is commonly associated with the alpha band, known for its involvement in visual processing, attention, and motor planning [38]. We consider the cause for this discrepancy to be the heightened demands on visual and spatial processing contribute to distinct neural oscillatory patterns within the alpha band especially turning. The deviation from driving straight introduces additional cognitive and motor planning components, further influencing the observed differences in EEG signals. Based on the observation of this analysis result and the consideration for increasing adaptability, we select the frequency component from 3 to 20Hz as input to the MEM model for learning effective EEG representations.\nWe first implemented a few baseline methods trained on the SAD dataset's training split. Then we evaluated the baseline methods with our proposed mask modeling framework in Section III on various settings.\n A CNN-based baseline with three convolutional blocks, including the temporal convolutional block, the depthwise convolutional, and the separable convolution block [24]. Additionally, it uses a multi-layer perception (MLP) network for classification. The temporal convolutional block employs a series of one-dimensional convolutional layers for capturing both short-term and long-term patterns in the EEG data while the depthwise convolution applies a separate convolutional operation to each input channel, capturing spatial information within individual channels. To cope with the input shape of our frequency domain EEG data w, we set the kernel size of the temporal and separable convolutional block to 5. The number of filters is set to 16 and the depth multiplier is set to 2.\n A Transformer-based baseline comprises a stack of Transformer blocks [39], each consisting of self-attention mechanisms and feedforward neural networks. We maintain the Vit structure to be similar to the proposed MEM encoder using 2 transformer blocks with 4 attention head and the hidden size of 512\nIn our experiment, the performance of the proposed MEM method and the baseline methods are comprehensively evaluated using both the micro accuracy and the marco metrics including precision, recall, and F1-"}, {"title": "IV. EXPERIMENT", "content": "score to provide more balanced measurements of the model's performance across all classes.\nWe first conduct experiments using only the alert state data and then we evaluate the alert (AS), transition (TS), and drowsy (DS) states in a within- subject setting. This is because alert state data is easiest to collect in real-life scenarios. Then we expand the training dataset by adding the other vigilance states (AS+TS+DS), with a hypothesis that models should be able to benefit from the expansion of the training data and the increase of data diversity. Results in Table II show the performance of baseline models and our model on predicting driving intentions. Compared to training solely on the alert state driving data, the proposed model is able to benefit from the increase of training samples and vigilance states diversity, exemplified by the significant increase of testing accuracy for the prediction in the transition state (TS) from 38.48% to 72.04%. On the other hand, we find that our model's prediction performance in a drowsy state (Accuracy: 85.19%) surpasses the performance in an alert state (Accuracy: 74.48%) by over 10%. We consider the major reason to be due to the additional cognitive load and motor planning in the preparation of a turning maneuver when the driver is forced to respond to deviation events from a drowsy mental state. Thus eliciting stronger and more identical neural activities whereas during an alert state, the brain only exhibits a baseline level of activity necessary for maintaining attention and responsiveness to the change of environment. Figure 5 shows the confusion matrix of the frequency mask model in different vigilance states. For the transition and drowsy vigilance state, the proposed model performs very well in the separation of the straight proceeding state as compared to the right or left turning intention with only a handful of straight samples classified as turning intention. This is especially important for a safety system since undesired turning on the highway could be dangerous. On the other hand, during an alert state, our model excels in classifying between left and right turning intentions, which demonstrates the superior representation learning capacity to exploit spatial and temporal dependencies.\nWhen compared with other models, our model performs similarly to the EEGNet model when only alert state data is used during training. However, given more data (AS+DS+TS), our model significantly outperforms the EEGNet by a large margin. We mainly contribute to the improvement of the"}, {"title": "IV. EXPERIMENT", "content": "transformer architecture of the proposed method where the transformer building block could be a better memory sponge that could benefit from more diverse training data and could effectively learn to exploit the spatial dependencies of the frequency domain EEG data while the EEGNet is more suitable for learning temporal and spatial filters from raw EEG waves and could not perform as well for the frequency domain signal.\nCompared with transformer-based models (ViT), we observed that the introduction of masking for the input EEG tokens, e.g., MEM and MEM w/o reconstruction, has a positive impact on the prediction performance compared to ViT which is trained on complete EEG information. This is because the masking mechanism introduces additional variations to the input and creates more diverse training conditions for the model. This could help to prevent overfitting to a certain extent, contributing to the improvement of performance in our experiment. On the other hand, thanks to the reconstructive objective during the MEM training, our model is able to learn EEG representations that contain comprehensive information of the original input EEG signal, therefore it has a better understanding of the EEG signal which explains why it achieves the best performance.\nTable III illustrates the comparison between two proposed mask modeling strategies for mask EEG modeling. From the results, we could observe that when only trained on alert state data, the MEM model with frequency masking strategy performs better on the seen vigilance states during training (awake) than unseen vigilance states (drowsy and transition), this is exemplified by the observation that the frequency masking model performs better on the awake vigilance state (accuracy on AS: 50.85%) while underperformed by the channel masking model on all other vigilance states.\nHowever, when presented with a more diverse vigilance condition during the training phase, the frequency masking strategy results in more comprehension and discrimination of driving intentions across all vigilance states when compared to the channel masking strategy. On the other hand, although the channel masking strategy did not outperform the frequency"}, {"title": "IV. EXPERIMENT", "content": "masking strategy in terms of evaluation metrics, it holds enormous practical value as it grants greater flexibility to the working channel number and is robust against broken or missing channels. We consider that it remains a trade- off between better flexibility in real-life applications and the pursuit of better performance. We visualize the reconstructed channels from the channel masking MEM model in different masking ratios to evaluate the model's understanding of the EEG signal in Figure 6. As observed from the reconstruction of the unseen EEG signal, the channel MAE could provide a close reconstruction of the masked input channel even if the mask ratio is as high as 0.9 where 11 out of 12 input channels are missing. This indicates the model learns to understand the spatial dependencies of the input EEG channels.\nIn this section, we conduct an ablation study on the proposed MEM method, specifically evaluating the impact of the scheduled masking strategy as well as the impact brought by the reconstruction term. We compare three variants of the MEM model including the MEM trained by the scheduled masking ratio (red), MEN trained by a fixed masking ratio (blue), and MEM without reconstructive objective and with a fixed masking ratio (green). We evaluate these models'"}, {"title": "V. CONCLUSION", "content": "This paper presents a pioneering advancement in BCI technology tailored for assisted driving scenarios, with a primary focus on decoding a driver's intentions from EEG signals through the proposed DIP task. The envisioned integration of our task into existing automatic driving systems holds the potential to enable automatic driving systems to align their actions seamlessly with the human's goals or intentions. Our work unveils activation patterns within central-frontal and parietal components, as decomposed by ICA, offering valuable insights into neural dynamics during the intention stage of driving actions. To effectively predict the driver's intention, this paper proposed the MEM framework for learning EEG representations via a masked reconstruction approach. Extensive experiments were conducted on a publicly available dataset, results show that our MEM method achieved 85.19% accuracy on drowsy states and maintained robust performance even with missing or corrupted channels. Emphasizing MEM's adaptability to artifacts and potential applications in real- world scenarios. However, there is room for performance improvement compared to the state-of-the-art speech recognition systems. In the future, we will extend our focus to real- time and continuous decoding of driver intentions without necessitating the pre-segmentation of action intention EEG signals, further enhancing human-machine interaction for safe driving."}]}