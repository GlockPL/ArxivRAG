{"title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study", "authors": ["Keyu Wang", "Guilin Qi", "Jiaqi Li", "Songlin Zhai"], "abstract": "Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs' capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not yet known whether LLMs can understand Description Logic (DL) ontologies. In this work, we empirically analyze the LLMs' capability of understanding DL-Lite ontologies covering 6 representative tasks from syntactic and semantic aspects. With extensive experiments, we demonstrate both the effectiveness and limitations of LLMs in understanding DL-Lite ontologies. We find that LLMs can understand formal syntax and model-theoretic semantics of concepts and roles. However, LLMs struggle with understanding TBox NI transitivity and handling ontologies with large ABoxes. We hope that our experiments and analyses provide more insights into LLMs and inspire to build more faithful knowledge engineering solutions.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) (Brown et al., 2020a; OpenAI, 2023; Touvron et al., 2023) have showcased remarkable proficiency in understanding textual data and revolutionized the field of natural language processing. Recent studies suggest that LLMs possess adaptability to store, retrieve and infer with symbolic knowledge such as knowledge graphs (KGs) (Mruthyunjaya et al., 2023; Feng et al., 2023), sparking interest in their potential for understanding structured information. However, LLMs' capacity in understanding more complex symbolic knowledge, Description Logic (DL) ontologies, remains unexplored.\nCompared with KGs, DL ontologies have more fined-grained knowledge representation with formal syntax and model-theoretic semantics. For syntax, while most KGs generally only support atomic entities like PhdStudent, DL ontologies can support various constructors and compound concepts such as PhdStudent Has StudentID. For semantics, DL ontologies have model-theoretic semantics. For example, the above complex concept can be interpreted as the set of individuals who are not PhD students but do have a student ID. Further, DL ontologies efficiently support logical reasoning such as $R_1 \\subseteq R_2$, $C \\subseteq \\neg\\exists R_2 \\rightarrow \\exists R_1 \\subseteq \\neg C$. Understanding a DL ontology goes beyond just the capabilities of storage, retrieval, and inference, but involves a deeper comprehension of its formal syntax and semantic interpretations.\nWhile the necessity for more detailed investigations for LLMs' capacity in understanding DL ontologies is clear, a comprehensively evaluation presents a challenge. Most related works focus on LLMs' capacity to capturing patterns in KGs (Mruthyunjaya et al., 2023; Feng et al., 2023), far away from indicating that LLMs possess the ability to understand DL ontologies. Even though many"}, {"title": "2 Related Work", "content": "With the arrival of LLMs, some works focus on using LLMs to translate natural language into formal language to reduce labor in real-world applications. For example, Fill et al. (2023) use ChatGPT to generate entity relation (ER) diagrams for conceptual modeling and Yang et al. (2023) present a fine-tuned LLaMA-7B model to translate natural language into first-order logic (FOL). Mateiu and Groza (2023) convert natural language sentences into OWL Functional Syntax, showing LLMs' prospect of ontology engineering. However, there is a significant difference in syntax between DL and other formal languages like ER, FOL and OWL, and few works study whether LLMs can understand DL syntax."}, {"title": "2.2 LLMs for Semantics Understanding", "content": "Some studies, like (Mruthyunjaya et al., 2023; Feng et al., 2023), focus on LLMs' capacity of matching up to knowledge that presents in KGs, but such kind of factual knowledge is not the main focus of DL ontology. Shani et al. (2023) analyze how well LLMs capture concepts and their structures, showing evidence that LLMs can understand conceptual knowledge, but DL ontologies support more automated reasoning than just conceptual taxonomies. Further, recent works conduct evaluations on how effectively LLMs can capture logic and perform logical reasoning (Wang et al., 2024b; Bao et al., 2024; Luo et al., 2023; Pan et al., 2023; Chen et al., 2023). However, none of them study LLMs' capacity in understanding DL semantics. Focusing on representation and reasoning with structured, formal ontology, DL provides formal semantics based on model theory and strikes a balance between expressiveness and computational tractability, making differences with other logics.\nAdditionally, some works study LLMs acting as knowledge bases (Heinzerling and Inui, 2021), which focus on LLMs' capacity for storing and retrieving knowledge. In contrast, we conduct an"}, {"title": "3 Preliminaries", "content": "In this section, we briefly recall some basic notions about DL-Lite ontology (Calvanese et al., 2007, 2009). Particularly, we focus on DL-Litecore, DL-Litef and DL-Liter, three members in DL-Lite family, while our evaluation framework can be applied to any other description logics (DLs) such as DL-Lite A, ALC and EL.\nWe start from DL-Litecore concepts and roles, which are defined as follows:\n$B ::= A | \\exists R | \\exists R^-\\$\n$R ::= P | P^-$\n$C ::= B | \\neg B | C_1 \\cap C_2$\n$E ::= R | \\neg R$\nwhere A denotes an atomic concept, P denotes an atomic role, and $P^-$ denotes the inverse of the atomic role P and $\\neg R$ denote the negation of R. We call B, R, C, E a basic concept, a basic role, a general concept and a general role respectively.\nA DL-Litecore ontology $O = \\langle T, A\\rangle$ consists of a TBox T and an ABox A. T is formed by a finite set of concept inclusion assertions of the form $B \\subseteq C$. A is formed by a finite set of membership assertions on atomic concepts and on atomic roles, of the form A(a) and P(a,b), where a and b are constants. DL-Liter extends DL-Litecore with role inclusion assertions of the form $R \\subseteq E$ and DL-Litef extends DL-Litecore with functionality on roles or on their inverses of the form (funct R).\nThe semantics of DL-Lite is given in a model-theoretic way via interpretations over a fixed infinite domain $\\Delta$. Given an interpretation $I$ and an assertion $a$, $I \\models a$ means that $I$ is a model of a. An interpretation is a model of a DL-Lite ontology O, if and only if it is a model for each assertion in O. An ontology O is satisfiable if it has at least one model. O logically implies an assertion a, written $O \\models a$, if all models of O are also models of a.\nDesigned for knowledge representation and efficient reasoning, DL-Lite ontology supports several DL reasoning services (Calvanese et al., 2007):\n- Ontology satisfiability checking: given an ontology O, verify whether O admits at least one model;"}, {"title": "4 Unveiling LLMs' Capabilities in Understanding DL-Lite Ontology", "content": "In this section, we comprehensively investigate how effectively LLMs can understand DL-Lite ontologies, especially, grasp the formal representations (syntax) and interpretations of elements in ontologies (semantics). We conduct a series of tasks, including syntax checking, subsumption of concepts or roles, instance checking, query answering, ontology satisfiability checking and property characteristics probing."}, {"title": "4.1 Can LLMs Understand the Syntax of DL-Lite Ontologies?", "content": "An important aspect of how effectively LLMs can understand DL-Lite ontologies is their capacity to comprehend the syntax. In this section, we conduct syntax checking to evaluate LLMs' comprehension of structural rules and the construction of valid statements and expressions in DL-Lite ontologies.\nDatasets. We select several commonly used DL ontologies, including Gene Ontology (GO) (Consortium, 2004), Foundational Model of Anatomy (FMA) (Rosse and Mejino Jr, 2008), Ontology for Biomedical Investigations (OBI) (Bandrowski et al., 2016), MarineTLO (Tzitzikas et al., 2016) and the Music Ontology (Raimond and Sandler, 2012). For each DL ontology, we randomly collect 30 DL-Lite axioms. For each collected axiom, we insert random one type of syntax error, such as invalid quantifier (eg. TeachesTo \u2192 $\\exists\\exists$TeachesTo) and invalid conjunction (eg. Professor \\u001f\u25a1\u2203TeachesTo \u2192 Professor \u2203TeachesTo). We summarize typ-"}, {"title": "4.2 Can LLMs Understand the Semantics of DL-Lite ontologies?", "content": "Another aspect of whether LLMs can understand ontologies is their capacity to comprehend the semantics. Semantics goes beyond the syntactic structure and explores the interpretation and significance of the elements like concepts and roles of the ontology. In this section, we explore the capability of LLMs to understand the semantics of the components within ontology (i.e., concepts and roles) considering instance checking and subsumption of concepts or roles. Additionally, we probe some property characteristics (i.e., inverse roles and functional roles) in DL-Lite ontologies. Further, we conduct query answering and ontology satisfiability checking to explore LLMs' capacity to understand the semantics of the whole ontologies."}, {"title": "4.2.1 Semantics of Concepts and Roles", "content": "We evaluate the capacity of LLMs to understand the semantics of concepts and roles from two aspects: extension and intension (Bouaud et al., 1995; Woods, 1975; Formica, 2006; Wang et al., 2024a). The extension of a concept or role refers to the set of individuals or objects that fall under that concept or role (Bouaud et al., 1995; Formica, 2006). For example, the extension of the concept \u201cPresident of the U.S.\u201d would be the set of all individuals considered as U.S. presidents such as \u201cBarack Obama\u201d and \u201cJoe Biden\u201d. The intension of a concept or role refers to the characteristics, properties, or conditions that determine whether an individual belongs to that concept or role (Formica, 2006). For example, \u201cPresident of the U.S.\u201d is a \u201cPolitician\u201d and \u201csomeone who plays a role in federal legislation\u201d.\nWe use instance checking for the former, since it involves determining whether a particular individual belongs to a specified concept within a given ontology. Subsumption of concepts or roles is for the latter, which involves determining whether one concept or role is subsumed by another more general concept or role, reflecting the attributes, characteristics, constraints, and conditions encompassed by the inherent intension."}, {"title": "4.2.2 Property Characteristics Probing", "content": "Property characteristics, such as symmetric property, transitive property, functional property and inverse functional property, play a significant role in a DL ontology. Some studies have shown evidence that the LLMs have limited knowledge of some property characteristics without external knowledge or instructions such as inverse role property (called \"reversal curse\" in (Berglund et al., 2023)) and property inheritance (Shani et al., 2023). In this work, especially, we focus on two important property characteristics in DL-Lite, inverse role property and (inverse) functional role property. We set property characteristics probing tasks:\n- inverse role probing: Given an ontology O, a role R, its inverse role P = $R^-$, and two constants a and b which satisfy $O \\models R(a, b)$, verify whether $O \\models P(b,a)$.\n- (inverse) functional role probing: Given an ontology O, a functional role (funct R) (an inverse functional role (funct $R^-$)), and three constants a, b and c which satisfies $O \\models R(a,b)$ and $O \\models R(a, c)$ (resp. $O \\models R(b,a)$ and $O \\models R(c, a)$), verify whether b = c."}, {"title": "4.2.3 Query Answering", "content": "Query answering over an ontology involves retrieving information that satisfies a given query based on this ontology (Calvanese et al., 2007).\nDatasets. We use the Lehigh University Benchmark (LUBM) (Guo et al., 2005) with the given TBox, ABox example and 14 test queries.\nExperimental setup. We use GPT4o for evaluation. Similar to prompt-NI in instance checking, the prompt includes task description (T), input ontology (O) and the query (Q). Because LLMs can't handle large-scale ABox at one time as shown in Section 4.2.1, we cut the ontology into 10 parts and input them in turn.\nResults analysis. Test results show that GPT4o fails to give a totally correct answer for each query. For Q3, Q8, Q12, Q13 and Q14, GPT4o can only answer a very small part of all the expected answers. For other queries, GPT4o has hallucinations and answer incorrect answers. LLMs can't memorize and understand large scale factual knowledge and fail to perform query answering well practically."}, {"title": "4.2.4 Ontology Satisfiability Checking", "content": "Ontology satisfiability checking is to verify the logical consistency of an ontology by ensuring the existence of at least one model that satisfies its"}, {"title": "5 Conclusion", "content": "We have empirically investigated whether LLMs can understand DL-Lite ontologies. Extensive experimental results demonstrated the effectiveness and limitations of LLMs in understanding the syntax and semantics of DL-Lite ontologies. For instance, LLMs possess the ability to understand formal syntax and semantics of concepts, roles and property characteristics. However, LLMs still struggle with understanding TBox NI transitivity rules and handling ontologies with large scale ABoxes.\nAs future works, we will consider exploring the ability of LLMs to understand ontologies in other lightweight ontology languages, such as EL, and to understand ontologies in intractable ontology languages, such as ALC and SHOIQ."}, {"title": "Limitations", "content": "This work is an empirical study on LLMs' capacity of understanding DL-Lite ontologies, and it has several limitations. Firstly, the size and diversity are limited due to the data sources and costs of LLMs. Secondly, there are various kinds of DLs and we just choose DL-Lite for evaluation. We thus encourage future work to conduct investigations for more DLs. Finally, it still remains unexplored how to improve LLMs' understanding capacity for TBox NI transitivity and large-scale ABox."}]}