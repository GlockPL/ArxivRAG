{"title": "Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease", "authors": ["Rosemary He", "Gabriella Ang", "Daniel Tward"], "abstract": "Neurodegeneration as measured through magnetic resonance imaging (MRI) is recognized as a potential biomarker for diagnosing Alzheimer's disease (AD), but is generally considered less specific than amyloid or tau based biomarkers. Due to a large amount of variability in brain anatomy between different individuals, we hypothesize that leveraging MRI time series can help improve specificity, by treating each patient as their own baseline. Here we turn to conditional variational autoencoders to generate individualized MRI predictions given the subject's age, disease status and one previous scan. Using serial imaging data from the Alzheimer's Disease Neuroimaging Initiative*, we train a novel architecture to build a latent space distribution which can be sampled from to generate future predictions of changing anatomy. This enables us to extrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated the model on a held-out set from ADNI and an independent dataset (from Open Access Series of Imaging Studies). By comparing to several alternatives, we show that our model produces more individualized images with higher resolution. Further, if an individual already has a follow-up MRI, we demonstrate a usage of our model to compute a likelihood ratio classifier for disease status. In practice, the model may be able to assist in early diagnosis of AD and provide a counterfactual baseline trajectory for treatment effect estimation. Furthermore, it generates a synthetic dataset that can potentially be used for downstream tasks such as anomaly detection and classification.", "sections": [{"title": "1 Introduction", "content": "Neurodegeneration as observed in magnetic resonance imaging (MRI) is recognized as a potential biomarker for diagnosing Alzheimer's disease (AD)[13]. While MRI has the advantage of being noninvasive, it is generally considered not specific enough, unlike biomarkers of amyloid or tau[14]. The potential for using machine learning approaches (\u201cdata-driven statistical approaches in which many different brain regions are evaluated simultaneously\" [2]) has been recognized. However, an important challenge in making diagnoses from brain images is the large amount of interpersonal variability, compared to minor structural changes in the earliest stages of the disease such as the transentorhinal stage (Braak stage I and II) [5]. We hypothesize that this issue can be overcome by carefully modeling timeseries of imaging data, allowing each person to be compared to their own baseline, rather than to a population average."}, {"title": "1.2 Related work", "content": "One strategy for timeseries analysis in brain imaging is to quantify structural changes using the diffeomorphism group [4]. After defining an appropriate metric, geodesics can be computed to study changes over time [27,7,29]. More recently, deep learning has been applied to model disease progression via changing pixel values, with models including deep structural causal models[1], variational autoencoders (VAE) [33,24], generative adversarial networks (GAN)[31,21], and diffusion models[32,19]. Among these works, we highlight two that train on time-series MRIs to predict the aging brain, conditioned on age and diagnosis. The first [24] combines a variational autoencoder with a mixed-effect model imposed on the latent space to simulate the aging process. By explicitly modeling age in the latent space, this model synthesizes images across 30+ years with atrophy patterns consistent with expectation. However, the model focuses on providing a population trajectory and is not specific enough for individual predictions, and images produced tend to be lower resolution as is typical of VAEs. In the second, 4D-DANI-Net, a GAN model with specified loss functions and a weight profile function, is proposed to simulate the aging process both globally and locally[22]. Additional techniques are used to synthesize images that are high resolution, more individualized, and consistent with atrophy patterns associated to AD. Unlike VAEs which typically impose a Gaussian distribution on the latent space through their encoder, GAN models typically offer a uniform distribution where no point is more likely than any other, and cannot be directly used for statistical modeling to classify trajectories as normal or abnormal."}, {"title": "1.3 Our Contribution", "content": "In this work, we aim to develop an approach that combines the complementary strengths of the two highlighted previous methods. We maintain an interpretable"}, {"title": "2 Method", "content": "We obtain our dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu), led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI is to measure the progression of mild cognitive impairment (MCI) and early Alzheimer's disease. We include subjects from ADNI 1, 2 and 3 studies as of July 11, 2023, by searching for all MPRAGE scans. Here, we introduce a novel data preparation strategy to solve two problems we face in medical imaging datasets: data scarcity and computational limits. We structure our dataset so that each sample contains two images from the same patient, age and disease status when the first image was taken, and the time difference between the two images. For subjects with only one image, a pair of the same image is included, and the time difference is 0. For subjects with more than 2 images, we include all combinations of pairs both forward (positive time difference) and backward (negative time difference) in time. Including a negative time difference may or may not have direct clinical"}, {"title": "2.2 Autoencoders, VAE and CVAE", "content": "First, we give an overview of autoencoder models and their extensions. Autoencoders are a class of neural network methods that learn a low-dimensional representation of high-dimensional structured data[8]. They consist of two parts: an encoder that projects high dimensional data into a latent space with lower dimensions, and a decoder that learns to map a point in the latent space back to its high dimensional representation. The latent distribution of an autoencoder is unknown, making inference difficult and prompting the need for VAEs[16]."}, {"title": "2.3 Our Double Encoder CVAE", "content": "We present our novel model architecture, inspired by CVAE [26], to generate 3D MR images. While previous methods have conditioned on a learned representation of an image, our architecture allows for a direct conditional image input. In our model, the encoder and decoder are not \"symmetric\", but rather the encoder takes the form of a standard CNN with two image inputs, and the decoder takes the form of a U-net [23]. The latter allows the prior MR image and conditional variables, as well as the latent space representation to be used for decoding. A point in the latent space does not represent an image, but a transformation between images, linking VAE modeling and classical work with diffeomorphisms."}, {"title": "Training procedure", "content": "We used the Adam optimizer [15] with learning rate 1e-5 and batch size of 4. We trained our model for 1000 epochs with early stopping on a single NVIDIA GeForce RTX 4090 GPU with a training time of 5 days."}, {"title": "2.4 Comparison to alternative methods", "content": "We attempted a comparison of our method to those described in section 1.2, but were unable to produce satisfactory results using publicly available code and documentation. We omit the comparisons, rather than casting these methods in a negative light. We suggest that a challenge style comparison, where authors can optimize parameter selection for their own methods and have them run automatically on a hidden test set, would be more appropriate for head to head comparisons. In this work we compare to several simpler models to put our method into context and understand typical values of our figures of merit. Our goal is to provide insight into the challenge of longitudinal image prediction by developing a new approach, not claim superiority or inferiority. For a simple baseline, we use the conditional image as a prediction of the future image, and the other methods we compare to are described below.\nLow rank linear prediction For N individuals, we take the first and last images in their trajectories and form two matrices X and Y, both of size 803 (number of pixels) by N. We include demographic variables by appending additional rows to X for age, status, elapsed time and 1 (for mean). We perform singular value decomposition: X = USVT, and take the first 10 (the same dimension as our CVAE latent space) or 100 (for better results) singular vectors as the latent space representation. To estimate the future MRI Y for individual i, we use the first few singular values (indicated by :) and calculate as: $Y_i = YV S^{-1}U^T X_i$\nVAE with linear mixed effect estimation We train an autoencoder using the architecture described in [24], and fit a linear mixed effects (LME) model in the latent space using the statsmodels package in python [25]. While other authors [33] have noted that this approach should be improved upon, it provides a simple model based on standard VAEs for comparison. Images are predicted using the following procedure. First a baseline image is passed through the encoder. Second, its latent space representation is shifted based on our LME model parameters, in a manner depending on time difference and disease status. Third, the resulting vector is passed through the decoder."}, {"title": "3 Results", "content": "First, we compare results for trajectory reconstruction in the held-out test set. In Fig. 2, we visualize sample reconstructions for randomly selected healthy and"}, {"title": "3.2 Latent space disease status probability estimation", "content": "In addition to trajectory estimation, we propose a practical use of the latent space to estimate a posterior probability of a subject's disease status given a pair of images. For subjects in the test set, we set the disease status to both normal and AD to obtain two sets of latent space representations. Let $p_{i,j}$ be the jth dimension of the encoder output when disease status is i (0 for healthy and 5 for AD), and define $f_i = \\Pi_{j=1}^{10} (2\\pi)^{-1/2} \\exp(-p_{i,j}^2/2)$ (taking a product over the 10 dimensional outputs, reflecting our standard normal latent space distribution). Our posterior probability of disease status 0 is defined as $p_0 = f_0/(f_0 + f_5)$. We show two examples of disease classification analysis in Fig. 5, one healthy and one AD (same subjects as Fig. 2), where the posterior probability significantly favors the hypothesis corresponding to their true disease status."}, {"title": "4 Discussion", "content": "In this work, we present our double encoder CVAE, a novel architecture that predicts 3D MRI at an arbitrary time given a conditional prior image, age, disease status, and the future time. We compared our model on two datasets against other simpler methods, and showed our model is better at tracking both global and local changes during the aging process associated with AD. Our goal is to design a predictive model that operates on images and demographics only. While ADNI provides other biomarker information such as amyloid and tau pathology, we do not include them in this work but will consider in the future. One strength of our work is that our model learns aging patterns from populations without losing specificity when making individualized predictions. Given a baseline image, it could be used to understand potential trajectories of healthy aging or disease. Another strength is that our model produces a latent space for downstream inference, as demonstrated by our likelihood ratio classifier example. Our model has characteristics similar to \"image translation\" like the popular pix2pix model[12]. However, pix2pix is deterministic [20], whereas our model allows users to explore uncertainty in future trajectories. Lastly, model predictions could be used for downstream analysis, including treatment effect comparison (where our model predicts the trajectory with no intervention).\nOne limitation of this work is that we were unable to perform head-to-head comparisons with state-of-the-art methods, and we suggest this could be addressed in the future in a challenge framework, where each author can run their own code. Another is that it is not straightforward to incorporate more than one previous scan when making predictions, unlike in [24]. Future work will incorporate serial conditional images to increase predictive performance. Lastly, our test set size was relatively small due to a smaller cohort size compared to some computer vision datasets. With potential treatments for AD now approved, early diagnosis has become critical. Our model can generate synthetic datasets that can potentially be used for downstream tasks such as anomaly detection and classification. This work, which seeks to improve measures of neurodegeneration as a biomarker of AD by leveraging timeseries analysis, has the potential to impact treatment decisions."}]}