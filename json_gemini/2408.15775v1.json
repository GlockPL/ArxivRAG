{"title": "Easy, Interpretable, Effective: openSMILE for voice deepfake detection", "authors": ["Octavian Pascu", "Dan Onea\u021b\u0103", "Horia Cucu", "Nicolas M\u00fcller"], "abstract": "In this paper, we demonstrate that attacks in the latest ASVspoof5 dataset - a de facto standard in the field of voice authenticity and deepfake detection - can be identified with surprising accuracy using a small subset of very simplistic features. These are derived from the openSMILE library, and are scalar-valued, easy to compute, and human interpretable. For example, attack A10's unvoiced segments have a mean length of 0.09\u00b10.02, while bona fide instances have a mean length of 0.18\u00b10.07. Using this feature alone, a threshold classifier achieves an Equal Error Rate (EER) of 10.3% for attack A10. Similarly, across all attacks, we achieve up to 0.8% EER, with an overall EER of 15.7\u00b16.0%. We explore the generalization capabilities of these features and find that some of them transfer effectively between attacks, primarily when the attacks originate from similar Text-to-Speech (TTS) architectures. This finding may indicate that voice anti-spoofing is, in part, a problem of identifying and remembering signatures or fingerprints of individual TTS systems. This allows to better understand anti-spoofing models and their challenges in real-world application.", "sections": [{"title": "I. INTRODUCTION", "content": "Text-to-speech (TTS) technology has advanced significantly in recent years, offering various beneficial applications, such as the restoration of voice capabilities for speech-impaired individuals [1]. Despite these positive developments, TTS also presents potential risks such as the compromise of voice biometric systems and the creation of deepfakes, which enable fraud, slander and misinformation. A key initiative in combating these threats is the ASVspoof Challenge [2]. Since its inception in 2015, this biennial event has released datasets crucial for the design of anti-spoofing systems. Notably, since the forth iteration of ASVspoof in 2021 [3], [4], the challenge has included a separate track specifically for detecting audio deepfakes. The latest iteration of the ASVspoof challenge dataset is called 'ASVspoof 5', and is set to succeed the ASVspoof 2021 dataset, the de-facto standard in evaluating of voice authenticity systems.\nWhile related work reports high performance on the ASVspoof datasets [5]\u2013[7], achieving true generalization that applies effectively in real-world scenarios remains a challenge. Existing studies suggest that anti-spoofing efforts often rely on shortcut artifacts, such as the length of silences [8] or bitrate information [9], and struggle with cross-dataset generalization [10]. Large self-supervised representations improve the generalization to some degree [11], but this approach comes at the cost of explainability, which remains an important desideratum given the decision-critical nature of deepfake detection. In this work, we propose to use openSMILE [12], a software tool for the automatic extraction of audio features. This tool allows the computation of interpretable features, based on fundamental properties such as the length of voiced and unvoiced segments, spectral flux (a measure of how quickly the power spectrum of a signal is changing), or energy within specific frequency ranges. Our findings demonstrate that for the ASVspoof5 dataset, even single, scalar-valued openSMILE features allow for surprisingly accurate classification of attacks (i.e. voice deepfakes from a specific TTS system). For example, the 'MeanUnvoiceSegmentLength' feature allows for reliable identification"}, {"title": "II. METHODOLOGY", "content": "We utilize the two currently available, labeled partitions of the ASVspoof5 [13] dataset: 'train' and 'dev'. Each partition a set of bona fide instances, denoted as BT and BD (bona fide 'train' and bona fide 'dev', respectively). Additionally, each partition includes spoofed audio files, categorized by the TTS system used to generate them, referred to as 'attacks'. The 'train' partition comprises attacks A01 through A08, while the 'dev' partition includes attacks A09 through A16; the types of attacks are listed in Table II. For our experiments, we divided BT and BD, along with each attack, into an 80% training pool and a 20% evaluation pool, c.f. Figure 2.\nOur objective is to ascertain whether attacks in ASVspoof5 can be detected using a single, scalar-valued feature from openSMILE. We aim to evaluate the performance of this method in both in-domain (ID) and out-of-domain (OOD) scenarios. ID scenarios"}, {"title": "III. EXPERIMENTS", "content": "In this initial experiment, we evaluate the effectiveness of 'eGeMAPSv2' in an in-domain (ID) setting, where the training and testing data originate from the same distribution.\nFirst, we select the front-end: as outlined in Section II-B, we identify the two most predictive features per attack. Second, we train the back-end on each feature individually: A linear classification model $f(x) = wx + b \\in \\mathbb{R}$ where $x, w, b \\in \\mathbb{R}$. This model is trained on the 'train' portion of the attack data along with the bona fide training data (i.e. BDtrain, BTtrain and Ajtrain, c.f. Figure 2). We then compute the EER on the corresponding evaluation data, i.e. BDeval, BTeval and Ajeval."}, {"title": "V. DISCUSSION AND CONCLUSION", "content": "In this work, we analyze the efficacy of openSMILE as a front-end for voice anti-spoofing, specifically on the ASVspoof5 dataset. We find that for all attacks, there exist scalar-valued, human interpretable features which allow for good in-domain detection performance. How-ever, the application of these characteristics in out-of-domain settings remains limited, particularly across different TTS architectures.\nWe argue that TTS models display unique characteristics, akin to a fingerprint, which can be readily identified once encountered but can have limited use for generalization across different models. Judging by the good transferability between attacks originating from similar TTS architectures, c.f. Table II and Table III, these characteristics appear to include information about the underlying TTS architecture. Conversely, generalization across architecture boundaries is challenging. Success in the field of source tracing [39], [45], which involves assigning instances to their generating models, further demonstrates that individual models exhibit individual characteristics.\nThus, voice anti-spoofing may, in part, involve the challenge of identifying the unique signatures or fingerprints of individual TTS systems. While these distinctive characteristics can enable good identification of an attack, they require that the TTS model has been encountered during training. This may in part explain challenges in real-world application [10]."}]}