{"title": "Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy", "authors": ["Sahana Yadnakudige Subramanya", "Ko Watanabe", "Andreas Dengel", "Shoya Ishimaru"], "abstract": "Human-in-the-loop (HITL) frameworks are increasingly recognized for their potential to improve annotation accuracy in emotion estimation systems by combining machine predictions with human expertise. This study focuses on integrating a high-performing image-based emotion model into a HITL annotation framework to evaluate human-machine interaction's collaborative potential and uncover the psychological and practical factors critical to successful collaboration. Specifically, we investigate how varying model reliability and cognitive framing influence human trust, cognitive load, and annotation behavior in HITL systems. We show that model reliability and psychological framing significantly impact annotators' trust, engagement, and consistency, offering insights into optimizing HITL frameworks. Through three experimental scenarios with 29 participants-baseline model reliability (S1), fabricated errors (S2), and cognitive bias introduced by negative framing-we analyzed behavioral and qualitative data (S3). Reliable predictions (S1) yielded high trust and annotation consistency, while unreliable outputs (S2) induced critical evaluations but increased frustration and response variability. Negative framing (S3) revealed how cognitive bias influenced participants to rate the model as relatable and accurate despite misinformation about its reliability. These findings highlight the importance of reliable machine outputs and psychological factors in shaping effective human-machine collaboration. By leveraging the strengths of both human oversight and automated systems, this study establishes a scalable HITL framework for emotion annotation and sets the stage for broader applications in adaptive learning and human-computer interaction.", "sections": [{"title": "1 Introduction", "content": "Emotion recognition, a key area of artificial intelligence (AI), aims to interpret human emotions using data such as facial expressions [40, 39, 8], body"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Emotion Recognition and Engagement Estimation", "content": "Technical Foundations of Emotion Recognition Emotion recognition relies on artificial intelligence (AI) systems to analyze multimodal data and classify"}, {"title": "2.2 Human-in-the-Loop (HITL) Systems", "content": ""}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 Dataset Description", "content": "This study utilizes the DAiSEE dataset [15], a publicly available resource for emotion recognition in e-learning contexts, capturing natural affective states - engagement, boredom, confusion, and frustration - in real-world settings. This makes it valuable for developing models tailored to educational technology ap-plications.\nThe dataset includes 9,068 ten-second video snippets from 112 participants, mostly university students aged 18-30, recorded in natural environments like dormitories and libraries. Its varied settings and lighting conditions enhance ecological validity, supporting models that generalize across user environments.\nEach video is annotated with four affective states on a four-point scale, capturing subtle emotional variations critical for adaptive systems.\nThe videos are high-resolution webcam recordings (1920x1080 at 30 fps) that capture facial expressions, body language, and non-verbal cues essential for emo-tion recognition. Participants viewed educational and recreational content, elic-iting authentic emotional responses representative of real-world e-learning sce-narios."}, {"title": "3.2 Video-Based Emotion Detection", "content": "The MobileNet V2 architecture was chosen as the base model due to its bal-ance between computational efficiency and high performance. It is particularly suitable for video-based data where the sequential nature of frames imposes significant computational demands. Its lightweight structure enables real-time processing, critical for emotion detection in dynamic environments.\nA Long Short-Term Memory (LSTM) layer was integrated with MobileNet V2 to extend the model's capability to handle temporal patterns. While MobileNet V2 effectively extracts spatial features from individual frames, the LSTM layer cap-tures temporal dependencies, enabling the recognition of evolving emotional expressions over time. This hybrid architecture, combining MobileNetV2 and LSTM (Figure 1), allows for dynamic emotion recognition, capturing subtle vari-ations that static models may overlook.\nThe MobileNetV2 + LSTM architecture was evaluated on its ability to detect multiple emotional states-engagement, boredom, confusion, and frustration. Among these, engagement consistently outperformed other emotions, achieving the highest accuracy, precision, and recall. Notably, participant feedback corrob-orated these findings, with engagement predictions perceived as the most reliable and trustworthy, underscoring the alignment between quantitative performance and subjective interpretation.\nTraining and Optimization The training process for the MobileNetV2 + LSTM architecture was carefully designed to ensure consistent performance across varied conditions. The dataset was split into training, validation, and test sets using stratified sampling to ensure a balanced representation of all emotional states. This approach minimized bias and improved the model's generalization ability. The model was trained using a binary cross-entropy loss function, treat-ing each emotional state as an independent binary classification task to support multi-label learning. The Adam optimizer was employed for its adaptive learn-ing rate, facilitating faster convergence and training stability. The learning rate was fine-tuned to 1 \u00d7 10-4 based on validation performance, and early stopping"}, {"title": "Evaluation and Results", "content": "The proposed architecture integrates MobileNetV2 for spatial feature extraction and an LSTM layer for temporal sequence model-ing. The Time Distributed Wrapper applied to MobileNetV2 ensures frame-wise"}, {"title": "3.3 Data Collection", "content": "The data collection phase utilized a structured Human-in-the-Loop (HITL) framework to refine emotion detection models through real-time participant feed-back. Three distinct scenarios-Scenario 1 (S1), Scenario 2 (S2), and Scenario 3 (S3) were designed to examine human interactions with model predictions"}, {"title": "4 Results and Analysis", "content": ""}, {"title": "4.1 Scenario Based Analysis", "content": "The scenario-based analysis examines participant interactions with the model's engagement predictions under varying conditions, providing insights into trust, corrective behaviors, and the influence of cognitive framing.\nScatter Plots: Alignments and Deviations The scatter plot illustrates the relationship between the predicted and adjusted engagement percentages across the three scenarios. In S1 (Figure 3a), the points are mostly clustered near the diagonal, showing a strong agreement between the model's predictions and participant adjustments. In S2 (Figure 3b), we see a significant shift away from the diagonal, as participants actively corrected the flawed predictions, high-lighting their engagement and willingness to intervene. The larger adjustments reflect their efforts to correct manipulated predictions. For S3 (Figure 3c), the scatter points show a moderate deviation, reflecting how the negative framing of the model's reliability led to increased skepticism and adjustments, even though the predictions were accurate. These plots clearly show how trust, accuracy, and cognitive framing influenced participant behavior across the scenarios.\nDensity Plots: Distribution Trends - The density plot provides insight into predicted and adjusted engagement percentage distribution. In S1 (Figure 4a), the high overlap between predicted and adjusted distributions emphasizes the model's reliability. Participants made minimal adjustments, reinforcing trust in the predictions. In S2 (Figure 4b), the density of adjusted percentages shifts sig-nificantly, diverging from the manipulated predictions, as participants actively corrected perceived inaccuracies. This divergence underscores their ability to"}, {"title": "Bar Charts: Agreement and Skepticism", "content": "The bar chart illustrates feed-back agreement proportions across scenarios, shedding light on participants' trust in the model's predictions. In S1 (Figure 5a), the high proportion of agree-ment reflects strong trust in unaltered predictions and minimal cognitive strain. In S2 (Figure 5b), the dominant level of disagreement reveals participants' rejec-tion of manipulated predictions and their active correction efforts. S3 (Figure 5c) presents a more balanced distribution of agreement and disagreement, influenced by cognitive framing. While participants remained skeptical due to the negative framing, they still aligned with accurate predictions in some cases, reflecting the interplay between skepticism and trust."}, {"title": "Box Plots: Variability in Adjustments", "content": "The box plot highlights the vari-ability in engagement adjustments across scenarios. In S1 (Figure 6a), narrow"}, {"title": "4.2 Statistical Analysis", "content": "To evaluate the impact of model reliability on participant feedback, statistical tests were conducted to analyze differences across the three scenarios. Key results are summarized in Table 2."}, {"title": "4.3 Qualitative Feedback Analysis", "content": "The open-ended feedback from participants across the three scenarios provides valuable insights into how model reliability and framing influenced their engage-ment, perceptions, and emotional responses.\nS1: Described as intuitive and straightforward, fostering trust in the model's outputs and minimizing cognitive strain.\nS2: Elicited critical thinking but also frustration due to fabricated inaccura-cies, highlighting the cognitive demands of correcting errors.\nS3: Balanced skepticism and curiosity, with participants describing the task as engaging and reflective despite the negative framing."}, {"title": "5 Discussion", "content": ""}, {"title": "5.1 Interpretation of Results", "content": "The study reveals the complex interplay between model reliability, participant engagement, and annotation behavior in Human-in-the-Loop (HITL) systems for emotion estimation. The three experimental scenarios provide key insights into human-machine interaction, informing the design of HITL frameworks.\nS1 emphasized the role of reliable model predictions in fostering trust and reducing cognitive load. Participants agreed with unaltered predictions, making minimal adjustments and demonstrating alignment between the model's outputs and human judgment. This reliability enabled annotators to focus on refinement rather than questioning validity, highlighting the importance of consistent pre-dictions for maintaining user confidence.\nS2, with intentionally flawed predictions, revealed challenges posed by un-reliable models. Participants identified and corrected errors, reflecting critical engagement but at the cost of increased cognitive effort and adjustment vari-ability. For some, this led to frustration, showing that while critical thinking is essential, overly unreliable predictions risk disengagement and reduced trust.\nS3 examined cognitive bias by framing the model as historically unreliable despite unaltered predictions. Negative framing led participants to engage more skeptically, balancing doubt with objective evaluation. This reflective engage-ment highlighted the influence of cognitive framing on participant trust and behavior, even when prediction quality remained unchanged.\nThe cross-scenario analysis underscores the importance of balancing reliabil-ity, cognitive demands, and framing in HITL systems. S1 highlighted the value of reliable predictions, S2 demonstrated the trade-offs of engaging with flawed out-puts, and S3 revealed the subtle impact of psychological framing. Together, these findings offer a comprehensive understanding of factors shaping human-machine collaboration.\nIn conclusion, the study highlights the need for HITL systems that prioritize reliable predictions, manage cognitive demands, and account for framing effects to optimize user trust and engagement. These insights provide a foundation for designing emotion-aware technologies that support diverse user behaviors while ensuring efficiency and collaboration."}, {"title": "5.2 Post Survey Analysis", "content": "The post-survey examined relabeling behavior, cognitive traits, and the impact of cognitive framing on annotation decisions in HITL systems. By analyzing rela-beling patterns, demographics, and self-reported cognitive abilities, it identified factors influencing engagement and trust across scenarios."}, {"title": "5.3 Limitations", "content": "This study provides valuable insights into HITL systems for emotion estimation and highlights areas for improvement. While capturing diverse perspectives (33 participants in S1 and 29 in Scenarios 2 and 3), the sample size could be expanded to improve generalizability and uncover subtle patterns in larger populations.\nThe controlled experimental design ensured consistency but may not fully reflect real-world variability. Structured conditions or perceived expectations may have influenced participants' feedback. Future research in naturalistic settings could offer complementary insights into user interactions with HITL systems in less controlled environments.\nS3 demonstrated how explicit information about model reliability affects trust, but real-world applications involve implicit and explicit cues. Longitudinal studies could explore how trust and engagement evolve, providing deeper insights into trust-building mechanisms. Insights from S2's intentional errors"}, {"title": "6 Future Work", "content": "Future research should prioritize scaling HITL systems, expanding emotional metrics, and refining annotation frameworks. Scaling to larger datasets and par-ticipant pools while optimizing workflows for diverse conditions is critical. Tech-niques like active learning and uncertainty sampling can minimize human inter-vention by targeting uncertain or error-prone predictions. Expanding emotional metrics to include frustration, boredom, and confusion could enhance system ver-satility and provide deeper insights into reliability and cognitive framing effects across emotions.\nMultimodal integration\u2014incorporating speech, physiological signals, and text could improve annotation accuracy. Developing hybrid models that combine su-pervised, semi-supervised, and reinforcement learning could refine predictions. Collaborative annotation platforms may improve consistency and leverage shared expertise among annotators. Further exploration of cognitive framing's impact on trust, as observed in S3, could guide the design of transparent and interactive feedback mechanisms. Longitudinal studies could investigate how annotator be-havior evolves with varying model transparency, while real-time visualizations of corrections' impact on model accuracy could enhance collaboration.\nAdapting HITL principles to domain-specific systems like medical diagnostics and autonomous technologies will ensure scalability and effectiveness. Addressing ethical concerns, including data privacy, annotator fatigue, and bias mitigation, is essential to developing fair and inclusive systems.\nIn summary, advancing HITL systems requires a focus on scalability, diverse emotional metrics, hybrid frameworks, domain-specific challenges, and ethical considerations. These efforts will strengthen human-machine collaboration and drive the development of emotion-aware technologies."}, {"title": "7 Conclusion", "content": "This study provides key insights into designing Human-in-the-Loop (HITL) frameworks for emotion estimation, focusing on model reliability, cognitive fram-ing, and human behavior. It demonstrates how reliable predictions build trust (S1), unreliable outputs encourage critical engagement but add strain (S2), and"}, {"title": "Class Weights: Calculated using:", "content": "wi = Nkni\nwhere wi is the weight for class i, N is the total number of samples, k is the number of classes, and ni is the number of samples for class i."}]}