{"title": "Reducing Barriers to the Use of Marginalised Music Genres in AI", "authors": ["Nick Bryan-Kinns", "Zijin Li"], "abstract": "AI systems for high quality music generation typically rely on extremely large musical datasets to train the AI models. This creates barriers to generating music beyond the genres represented in dominant datasets such as Western Classical music or pop music. We undertook a 4 month international research project summarised in this paper to explore the eXplainable AI (XAI) challenges and opportunities associated with reducing barriers to using marginalised genres of music with AI models. XAI opportunities identified included topics of improving transparency and control of AI models, explaining the ethics and bias of AI models, fine tuning large models with small datasets to reduce bias, and explaining style-transfer opportunities with AI models. Participants in the research emphasised that whilst it is hard to work with small datasets such as marginalised music and AI, such approaches strengthen cultural representation of underrepresented cultures and contribute to addressing issues of bias of deep learning models. We are now building on this project to bring together a global International Responsible AI Music community and invite people to join our network.", "sections": [{"title": "1 INTRODUCTION", "content": "Music is a fundamental form of human activity and artistic endeavour. The impact of AI is increasingly felt across music making from creation and production, protection, distribution, to consumption. AI systems for high quality music generation and production exist in research labs and online, e.g. Magenta ${ }^{1}$ powered by Tensorflow (Google) and Suno $\\mathrm{AI}^{2}$. However, these systems typically rely on extremely large musical datasets to train the AI models which biases the models to genres captured in large datasets and creates barriers to generating music beyond the dominant musical genre datasets such as Western Classical music or pop music [2, 3]. For example, it is not possible to train these models on many minority culture genres such as Qin genre in China nor contemporary subcultures such as glitch or algorithmic music as the datasets are simply too small or non-existent. Whilst recent advances in AI research have started to explore low-resource AI approaches $[5,6]$ which have the potential to make small datasets usable in deep learning generative models they are currently difficult for musicians understand and use. The combination of these factors means that the rapid increase in the use of AI within the music ecosystem not only creates barriers to using small datasets and marginalised genres with AI but also that AI increasingly marginalises genres of music that are already underrepresented or not represented at all in large datasets of music. To begin to address this gap this paper reports on a four month international research project ${ }^{3}$ which explored eXplainable AI (XAI) [4] and broader Human-Centred AI (HCAI) [7] and Responsible AI (RAI) challenges and opportunities of using small datasets with AI music generation. We take a broad view of XAI and include explanations of AI bias, trust, training, datasets, control, and transparency. In doing so the project asked how we make AI models for music more ethical, less biased, and more understandable and usable by people - musicians in our research. The project focused on AI and music in the UK and China as the Creative Industries and Intangible Cultural Heritages of the UK and China provide a rich ecosystem of AI research along with substantial cultural heritage beyond the dominant forms typically used in current music AI research. Our research question is: What are the eXplainable AI challenges and opportunities for using small datasets of music with AI?"}, {"title": "2 DATA COLLECTION", "content": "To understand the XAI challenges of using small datatsets with AI music models we undertook interviews with seven international experts. We then held a hybrid workshop between the UK and China hosted at the Institute of Data and Intelligent Innovation Design, Academy of Arts and Design, Tsinghua University, Beijing, China, in Jan 2024 (Fig 1). Thirty-seven participants were brought together to build a community to share knowledge, experience, and practice around using AI with marginalised music. The workshop included brainstorming about challenges and opportunities, and case study sharing. We also commissioned a new piece of music ${ }^{4}$ composed using the Chinese Musical Instrument Database and RAVE $\\mathrm{AI}^{5}$ to foreground the practical challenges of undertaking such creative endeavours."}, {"title": "3 RESULTS", "content": "The interviews and workshop discussions were video recorded and transcribed and then analysed using Thematic Analysis [1] to identify challenges and opportunities for UK-China collaboration in this area. Four themes were identified as outlined below followed by the identified challenges and opportunities. Theme 1: Access to AI-enabled Music Exploration. Barriers that hinder the widespread utilization of AI in music exploration with marginalised music genres included: Ethical \\& economic constraints such as ethical data use and the cost of music collection and analysis. Here the XAI question is how to explain where the data came from and limitations on its ethical use. Knowledge and skills barriers The need for an in-depth set of multidisciplinary skills and knowledge to balance music domain knowledge with AI skills were highlighted as a critical barrier. This raises XAI questions of how to understand and control AI models. For example, AI music scholars face challenges in fully harnessing AI's potential due to the need for specialized musical knowledge and technical expertise which is particularly evident when attempting to engage with non-mainstream or regional music genres. Technical barriers such as the need for high-quality and large datasets for effective AI model training, and the high computational demands for AI training. This raises XAI questions about explaining and understanding training of low-resource models with smaller datasets to reduce the dependency on deep learning models. Theme 2: Stakeholder dynamics. How musicians want to interact and engage with AI models was seen as critical to their success and use from a HCAI [7] perspective - AI's capacity to extend and enrich musicians' creative vision requires technologists to focus on understanding and addressing musicians' needs. In doing so we can use XAI to better explain to musicians how the AI models work, and to design user interfaces to allow for more meaningful control of AI by musicians. Participants highlighted how experimentation and critical reflection by musicians can potentially inform explanation of AI music models to make AI music generation and exploration more accessible and inclusive. Theme 3: Technology innovation. Innovative uses of AI along with innovative AI techniques offer new opportunities for using AI with marginalised music. For example, participants noted that AI can offer novel and innovative opportunities for co-creation and co-creativity development. This will require careful XAI design to ensure that the interaction is intuitive and understandable for musicians. To address the practical challenges of training AI on limited resources, participants suggested fine-tuning large models with small datasets to reduce bias, augmenting small datasets using synthesised data, compressing datasets to extract the most salient musical features, or using transfer-learning to transfer learning to use features of large models with small datasets. In addition it was suggested that more experimentation with AI model selection would benefit music generation with small datasets rather than relying on deep learning approaches. The requires more explanations of small AI models and their potential use. Theme 4: Sustainable and Actionable Development in AI Music Ecosystems. A number of strategies for creating a supportive environment for AI music research and development were highlighted by participants. These primarily focused on XAI aspects of academic and scholarly support as well as community and stakeholder engagement and support which itself relies on XAI to help understand the positive potential of AI music making. For example, using research outcomes as an XAI voice to advocate for ethical musical influence on culture and humanities."}, {"title": "4 DISCUSSION AND CONCLUSIONS", "content": "Regardless of the nature of the marginalised music genre, they all suffer from increased marginalisation by deep learning AI. In addition to the lack of existing large datasets of marginalised music genres there many features of these genres which are simply difficult to encode into forms of representation that might be used in deep learning model training such as MIDI. Moreover, many of these genres are shared, learnt, and passed from generation to generation through oral tradition rather than being written down which again makes them less amenable to use with AI models than music genres which are well described and documented by conventional musical notations and encoding. The Key Take Away from our analysis is that one AI model or architecture will not be able to handle the wide variety of music styles, genres, heritage, cultural contexts, and forms of notation and documentation. This challenges the dominant contemporary discourse on the wide application and general use of deep learning models such as large language models and catalyses opportunities for collaboration. From the analysis of workshops and interviews we identified opportunities for collaboration between the UK and China on reducing barriers to the use of marginalised music with AI including: 1) New techniques for dataset building which relies on XAI to understand the training constraints of AI models; 2) New approaches to AI model training requiring XAI to explain how the training works; 3) Sharing examples of small dataset use which needs XAI to explain how the AI model is trained and used; 4) Interdisciplinary collaborations; 5) Community and stakeholder engagement. To bring together XAI resources for the use of marginalised music with AI we suggest building an online repository to include: - Descriptions of a variety of musical genres including rich descriptions of the genre, the associated musical traditions, musical notations (if any), musical practices and conventions, and the cultural context of the genres. - Musical content and corpora for the music genres. For example, in the style the Dunya project ${ }^{6}$ which includes audio recordings and descriptions of the recordings and cultural context as well as related software tools. - XAI descriptions of the suitability of AI architectures, models, and settings for the genres in the repository. - Explanations of AI fine-tuning and style transfer opportunities between pre-trained deep AI models and the AI models and genres in the repository. The key XAI value add of the repository will be the explanations of interconnections between the parts of the repository. For example, XAI mapping between musical content, suitable AI models, and fine-tuning and style transfer opportunities. Finally, participants in this project emphasised that whilst it is hard to work with marginalised music and AI, such approaches strengthen cultural representation of underrepresented cultures and contribute to addressing issues of bias of deep learning models. We believe that taking an XAI approach to developing low-resource models and training mechanisms will offer more opportunities for musicians to engage with and use AI in their music making practices with small datasets of marginalised music. We hope that this would help to increase representation of underrepresented genres in the AI music ecosystem. We are now building on this project to bring together a global International Responsible AI Music community ${ }^{7}$ and invite people to join our network."}]}