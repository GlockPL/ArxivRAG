{"title": "MatterChat: A Multi-Modal LLM for Material Science", "authors": ["Yingheng Tang", "Wenbin Xu", "Jie Cao", "Jianzhu Ma", "Weilu Gao", "Steve Farrell", "Benjamin Erichson", "Michael W. Mahoney", "Andy Nonaka", "Zhi Yao"], "abstract": "Understanding and predicting the properties of inorganic materials is crucial for accelerating advancements in materials science and driving applications in energy, electronics, and beyond. Integrating material structure data with language-based information through multi-modal large language models (LLMs) offers great potential to support these efforts by enhancing human-AI interaction. However, a key challenge lies in integrating atomic structures at full resolution into LLMs. In this work, we introduce MatterChat, a versatile structure-aware multi-modal LLM that unifies material structural data and textual inputs into a single cohesive model. MatterChat employs a bridging module to effectively align a pretrained machine learning interatomic potential with a pretrained LLM, reducing training costs and enhancing flexibility. Our results demonstrate that Matter Chat significantly improves performance in material property prediction and human-AI interaction, surpassing general-purpose LLMs such as GPT-4. We also demonstrate its usefulness in applications such as more advanced scientific reasoning and step-by-step material synthesis.", "sections": [{"title": "1 Introduction", "content": "In-silico material discovery and design have traditionally relied on high-fidelity first-principles methods such as density functional theory (DFT) [1] and ab-initio molecular dynamics (AIMD) [2] to accurately model atomic interactions and predict material properties. Despite their effectiveness, these methods face significant challenges due to their prohibitive computational cost, limiting their scalability for high-throughput screening across vast chemical spaces and for simulations over large length and time scales. Moreover, many advanced materials remain beyond the reach of widespread predictive theories due to a fundamental lack of mechanistic understanding. These challenges stem from the inherent complexity of their chemical composition, phase stability, and the intricate interplay of multiple order parameters, compounded by the lack of self-consistent integration between theoretical models and multi-modal experimental findings. As a result, breakthroughs in functional materials, such as new classes of correlated oxides, nitrides, and low-dimensional quantum materials, have largely been serendipitous or guided by phenomenological intuition rather than systematic, theory-driven design. Attempts to predict new materials and functionalities have often led to mixed results, with theoretically proposed systems failing to exhibit the desired properties when synthesized and tested. Achieving reliable, scalable, and predictive design of materials requires a paradigm shift.\nWith the rise of artificial intelligence (AI) in materials science, there has been a surge of methods aiming to overcome these limitations, ranging from machine learning (ML) surrogate models [3, 4], ML interatomic potentials (MLIPs) [5-7], and generative models [8, 9]. These models enable rapid predictions, accelerate large-scale simulations, and facilitate the generation of novel materials. As a result, they have significantly advanced fields such as energy storage [10], electronics [11], catalysis [12], and biomedical applications [13]. Among these promising ML approaches, graph-based models in material science have become increasingly popular due to their versatile graph representation of atomistic systems, where each atom is represented as a node, and chemical bonds to neighboring atoms are represented as edges. Although these graph-based methods have shown success in accurately predicting material properties, they typically lack the capacity to handle tasks that require understanding scientific context, literature-based insights, and domain-specific language [14]. In particular, these models do not support human-AI interaction through user prompts or textual descriptions, making it difficult to incorporate expert domain knowledge and user-specified requests to close the feedback loop.\nThis bottleneck has inspired a wave of exploration into how natural language processing (NLP), and particularly large language models (LLMs), might be leveraged to fill the gap. LLMs like BERT [15], GPT [16], and newer open-source LLMs such as Mistral [17], Llama [18] and DeepSeek [19] have shown substantial promise across different domains by interpreting and generating language. Trained on extensive datasets, these models can support some scientific tasks that require interpretive language capabilities, such as question-answering (QA) [20] and retrieving information from unstructured text sources [21]. In recent years, there has been several efforts incorporating LLM to solve material related problems [22, 23], either by leveraging pretrained LLMs or multi-modal LLMs. Unfortunately, these approaches rely on text-based representations, such as chemical formula [22], Simplified Molecular Input Line Entry System (SMILES) strings [23, 24], textual descriptions [25], or Crystallographic Information File (CIF) [26], which lose the full resolution of atomic structures. Consequently, they exhibit inferior performance compared to pure graph-based models for predicting material properties [25], and they also potentially hinder other downstream tasks where structural information is crucial. Thanks to the steady development of MLIPs [5-7], particularly in their universal form (uMLIPs) [7], these models can now serve as atomistic pre-trained models capable of supporting a wide range of applications. The locality assumption underlying uMLIPs ensures that they effectively represent the local environment of each atom. Therefore, it is feasible to extract structural information from atom embeddings in a pretrained uMLIP.\nIn this work, we present MatterChat, a multi-modal large language model designed for materials science. MatterChat integrates material structure data with textual user queries, combining insights from materials science and NLP. It enhances the capabilities of large language models by overcoming their traditional limitations in quantitative predictions and improving the handling of scientific material-related tasks, as demonstrated through comparisons with other LLMs. MatterChat also maintains robust human-AI interaction capabilities, offering an intuitive interface for complex queries, compared to physical ML models. Furthermore, by leveraging deep, embedded knowledge from state-of-the-art pretrained LLMs, MatterChat enables advanced scientific reasoning and synthesis process guidance. The embedding visualization analysis indicates that MatterChat effectively preserves structure and property information.\nThis has guided the adoption of a multi-modal Retrieval-Augmented Generation (RAG) approach that can enhance Matter Chat's robustness during material task inference."}, {"title": "2 Results", "content": ""}, {"title": "2.1 Overview of Matter Chat", "content": "Figure 1(a) presents the architecture of MatterChat, designed to process both material structures and user requests as inputs to generate text-based outputs for tasks such as material property prediction, structural analysis, and descriptive language generation. MatterChat consists of three core components: the Material Processing Branch, the Language Processing Branch, and the Bridge Model. The Material Processing Branch extracts atomic-level embeddings from material structures represented as graphs. These embeddings are then processed by the Bridge Model, which employs trainable queries to produce language model-compatible embeddings. Finally, the Language Processing Branch processes the user's text-based prompt (e.g., \"What is the formation energy of the material?\") into language embeddings. These embeddings are then combined with the query embeddings generated by the Bridge Model and fed into the LLM to produce the final output in text format. Below, we provide the details of each component.\nMaterial Structure Branch. The Material Structure Branch encodes material structures as graphs that capture the atomic local environment. To process these graphs, we use CHGNet [27], a state-of-the-art graph-based uMLIP model designed for crystal structures, to process these graphs. CHGNet is pretrained on a diverse dataset of materials, encompassing a wide range of symmetries, compositions, and bonding types, enabling it to effectively model complex atomic interactions and structural details. By capturing essential compositional features, such as atomic types and chemical bonds, along with spatial features like bond angles, CHGNet generates high-quality atom embeddings that are both physically meaningful and well-suited for downstream tasks.\nLanguage Branch. The language branch is used to process user's text-based prompts, such as requests for property predictions, chemical formulas, space group information, or other material characteristics. We use the Mistral 7B LLM [17], one of the latest open-source LLMs, chosen for its exceptional performance across a wide range of scientific and non-scientific tasks. This branch processes each prompt, transforming it into dense embeddings that capture the semantic content of the inquiry. These embeddings are then combined with the query embeddings processed by the bridge model using a structured fusion approach, allowing the model to effectively incorporate both textual and material information. This integration enables the LLM to generate precise and contextually relevant responses tailored to the user's specific material-related prompts.\nBridge Model. To facilitate the integration between atom embeddings and the language branch, we developed a bridge model inspired by the BLIP2 architecture [28], based on a multi-layer transformer framework. This bridge model includes 32 trainable query vectors that interact with atom embeddings using an alternating attention mechanism. Cross-attention in even-numbered layers extracts key features from the atom embeddings, while self-attention in odd-numbered layers enhances representational depth. This approach refines the atom embeddings into query embeddings that are most connected to text, as shown in Figure la. Finally, these refined representations are mapped to LLM-compatible embeddings via a linear projection layer.\nFigure 1(b)-(c) provide an overview of the dataset of crystalline structures used in our training set. Figure 1(b) visualizes the material distribution on the periodic table, highlighting that the dataset evenly spans a diverse range of elements up to Plutonium. Figure 1(c) depicts the distribution of crystalline structures by space group across the dataset. The dataset was curated from the Materials Project [29] and contains 142,899 material structures. For each structure, we generated a corresponding text-based dataset encompassing 12 tasks: 3 descriptive tasks (chemical formula, space group, and crystal system) and 9 property prediction tasks. These property prediction tasks include metallicity, direct bandgap, stability, experimental observation (Exp Ob), magnetic status (Is Magnetic), magnetic order, formation energy, energy above the hull, and bandgap, as summarized in Figure 1(a). Further details regarding the training scheme, hyper-parameters, and dataset curation are provided in the Methods section."}, {"title": "2.2 Multi-modal Material task interactions with Matter Chat", "content": "Figure 2 illustrates the human-AI interaction examples with MatterChat, across a diverse range of material property prediction and analysis tasks. The figure shows Matter Chat's ability to effectively address a broad spectrum of user prompts ranging from fundamental material attributes (e.g., chemical formulas, space groups and crystal system) to complex material properties (e.g., thermal stability, bandgaps, formation energies and energy above the hull). The top panels in Figure 2 shows three interactive examples of material property prompts from randomly selected materials from the Material Project Dataset. The top left panel presents a human-AI query interface with MatterChat for the material identified by ID \"mp-1001021\". It provides a detailed profile including the chemical formula Y2Zn4 Se2, its crystalline structure denoted by the space group Fd-3m, and electronic properties such as a bandgap of 0.21350 eV. The interface also addresses the material's lack of thermal stability. The top mid panel shows the interaction example with the material with mp ID of \"mp-1028281\". It provides a comprehensive breakdown of the material's composition attributes, including its chemical formula (Mg14V4Sb) and its space group (Amm2). The interaction further predicts that the material is both magnetic and metallic, and its formation energy is estimated at 0.05912 eV/atom. The top right panel provides an interaction example with MatterChat of the material with Materials Project ID of \"mp-10198\". This panel informs user's query about the chemical composition Mn3PdN and its cubic crystal structure, with the space group classified as Pm-3m. Additionally, it estimated that the material possesses an indirect bandgap, which is an important characteristic for applications in electronics. MatterChat also accurately predicts the ferro-magnetic (FM) magnetic behaviors that the material exhibits, and it mentions its energy above hull value at 0.03571 eV. In the bottom panel, we present a comparative evaluation of Matter Chat's performance on formation energy evaluation tasks for newly discovered materials from GNOME [30]. The model was compared against commercial LLMs, Gemini [31], GPT-40 [32] and DeepSeek [19]. The results show MatterChat's superior accuracy in estimating formation energies, consistently delivering predictions closer to the ground truths. For example, Matter Chat's formation energy predictions for \"mp-3202380\" and \"mp-3206774\" show a remarkable alignment with the ground truth values. These results demonstrate Matter Chat's ability to integrate structural and textual data seamlessly for a wide range of material property tasks."}, {"title": "3 Discussion", "content": "In this study, we present MatterChat, a multi-modal framework that demonstrates superior performance in material property prediction and scientific reasoning tasks compared to traditional models. This performance can be attributed to its ability to integrate structural material data with language-based information, creating a more comprehensive representation of materials. Traditional approaches often rely on text-based representations, such as Crystallographic Information Files (.cif), to encode atomic structures. While .cif files effectively capture detailed structural information, their static format may limit the model's capacity to learn complex structure-property relationships when used directly as input. In contrast, MatterChat's multi-modal approach processes structural embeddings derived from atomic graphs alongside textual data, enabling dynamic interactions between atomic configurations and contextual scientific knowledge. This integration enhances the model's generalization ability across diverse material tasks, as evidenced by its improved accuracy in classification and numerical property prediction tasks.\nWhile Matter Chat demonstrates advancements in material property prediction and analysis, several limitations provide avenues for future improvement and exploration.\n1. Alignment Limitation: One key limitation lies in the current level of alignment between the graph-based material(atom) embeddings and the language representations. Although the framework achieves superior performance on trained material property tasks, this behavior-based alignment does not necessarily imply full representation alignment between the two modalities. Representation level alignment remains an area requiring further investigation [42].\n2. Data Limitations: The curated dataset used in this study, while effective for benchmarking, has certain constraints that may impact model generalization ablility. Specifically, the text data for material property tasks consists of a fixed number of paraphrased queries, which could limit the diversity of the language representations. Expanding the dataset to include more comprehensive and diverse textual description scheme, as well as incorporating a broader range of material properties, could address this issue.\n3. Frozen LLM: Using frozen LLMs may limit the framework's effectiveness in material-related tasks, as they are primarily trained on broad, general-purpose text rather than domain-specific material science literature. Incorporating specialized LLMs trained on material science datasets could potentially enhance performance by improving domain-specific contextual understanding and reasoning.\nTo address these limitations, future work could focus on:\n1. Improving Alignment: Leveraging advanced techniques to improve representation-level alignment between modalities during end-to-end instructive fine-tuning, such as incorporating contrastive loss at the fine-tuning stage in addition to pretraining to further reinforce structural-textual consistency.\n2. Dataset Expansion: Building a more comprehensive dataset with diverse textual queries and a broader range of material properties to ensure the framework's applicability to real-world scenarios.\n3. Material Generation Capabilities: Developing a graph generative module to enable the framework to tackle new material design and discovery tasks.\n4. Optimizing LLM Integration: Investigating finetuning strategies for LLMs, such as whether multi-modal LoRA finetuning offers advantages over independent LLM finetuning before integration, to improve downstream task performance."}, {"title": "4 Method", "content": ""}, {"title": "4.1 Dataset curation", "content": "In this work, we curated a comprehensive dataset from the Materials Project Trajectory (MPtrj) dataset [36], focusing specifically on relaxed samples. By selecting these stable configurations, rather than complete trajectory data, we ensure that the dataset captures the equilibrium states of materials, which are more relevant for downstream tasks such as material property prediction. The final dataset consists of 142,899 high-quality samples, offering a rich and diverse representation of inorganic materials.\nTo facilitate effective model training and evaluation, we partitioned the dataset into training and testing subsets using a 9:1 split ratio. This ensures that a substantial portion of the data is available for learning, while maintaining a dedicated portion for rigorous performance validation, allowing us to assess the generalization capabilities of the model."}, {"title": "4.2 Training Detail", "content": "Matter Chat employs a bootstrapping strategy commonly used in multi-modal learning for vision-language tasks, adapted here for material science applications. The training process consists of two main stages: pretraining to align material structures with descriptive text; and finetuning for both descriptive and property prediction tasks with the LLM module integrated (see Figure S2 in the Supplementary Material). The pretraining phase aims to establish a foundational alignment between material structures and descriptive text. In this stage, the model connects a frozen graph encoder with pairs of graph data and corresponding textual descriptions, without attaching the LLM module. Here, the bridge model acts as a text generator, learning to extract descriptive graph representations that effectively capture structural information relevant to the text data.\nThis stage consists of three core optimizing targets, each with distinct interaction mechanisms between graph embeddings and text, while maintaining a consistent input format:\n1. Graph-Text Correlation Learning (Contrastive Loss).\nThis task aligns graph and text representations by maximizing the similarity between matched graph-text pairs and minimizing it for mismatched pairs. A contrastive loss is employed:\n$L_{correlation} = - \\sum_{i=1}^{N} log \\frac{exp(sim(q_i, t_i) / T)}{\\sum_{j=1}^{N} exp(sim(q_i, t_j) / T)},$ (1)\nwhere qi and ti represent the graph and text embeddings, respectively, and is the temperature parameter controlling the distribution's sharpness.\n2. Graph-Driven Text Prediction (Conditional Language Modeling Loss).\nThe bridge model generates descriptive text based on graph data, conditioned through attention mechanisms. The loss function is defined as:\n$L_{prediction} = - \\sum_{t=1}^{T} log P(y_t | Y_{<t}, Q),$ (2)\nwhereQ represents graph query features, and yt is the token at position t in the output sequence.\n3. Graph-Text Association (Binary Cross-Entropy Loss).\nThis task predicts whether each graph-text pair is correctly matched. A binary cross-entropy loss with hard negative sampling is applied:\n$L_{association} = - \\sum_{i=1}^{N} (Y_i log(s_i) + (1 - y_i) log(1 - s_i)),$ (3)\nwhere si is the model's prediction score, and yi indicates whether the pair is matched (1) or not (0).\nThe total pretraining loss is the sum of the individual task losses:\n$L_{total} = L_{correlation} + L_{prediction} + L_{association}.$ (4)\nAfter pretraining, the model undergoes instructive finetuning to optimize its performance on both descriptive and property prediction tasks. In this stage, the pretrained bridge model is integrated with the LLM to enhance multi-modal learning. A fully connected layer is introduced between the bridge model's output and the LLM's input. The finetuning phase includes 12 multi-modal subtasks, including 3 material description tasks and 9 property prediction tasks. Description tasks refine the model's ability to link structural features with detailed textual explanations, while property prediction tasks focus on improving quantitative accuracy in material property estimation. Finetuning is guided by a supervised cross-entropy loss defined as:\n$L_{finetune} = - \\sum_{i=1}^{N} \\sum_{j=1}^{T} Y_{i,j} log P(Y_{i,j} | x_i),$ (5)\nwhere Yi,j represents the ground truth token for the j-th position of the i-th sample, and $P(y_{i,j} | x_i)$ is the model's predicted probability of the correct token given the multi-modal input xi.\nIn the pretraining stage, the model is trained using the AdamW optimizer with a learning rate of 2\u00d710-4, with cosine decay scheduler and linear warmup starting from 1 \u00d7 10-6. A weight decay of 0.05 is applied to regularize the model, with a batch size of 32 and gradient accumulation over 5 steps to manage computational efficiency. Mixed-precision training is enabled to improve performance and reduce memory usage. The model is trained for ~ 25 epochs, with checkpoints saved every 2000 iterations. During the finetuning stage, the AdamW optimizer is again used with a learning rate of 2\u00d710-4, featuring a warmup phase to 1 \u00d7 10-4 followed by decay to 1 \u00d7 10-5. The batch size is set to 8, with gradient accumulation over 16 batches to effectively increase the batch size. Finetuning runs for 50 epochs, with checkpoints saved every 300 steps and at the end of each epoch. Additionally, distributed training is implemented using 4 GPUs per node across 8 nodes, leveraging the Distributed Data Parallel (DDP) strategy to enhance training efficiency and scalability."}, {"title": "4.3 Embedding Visualization", "content": "The visualization leverages UMAP to reveal chemical insights encoded in the material embeddings that are extracted from the bridge model in a lower-dimensional space. To prepare the data, each high-dimensional embedding, originally structured as (32, 4096), is first flattened into a single vector, capturing the essential features of the material. UMAP is then applied to this set of vectors with number of components equals 2, reducing the data to two dimensions to enable visual interpretation, with random state is set to 1 to ensure consistency in the layout across runs.\nStructural similarity scores are computed using the Smooth Overlap of Atomic Positions (SOAP) descriptor [43], combined with the Regularized Entropy Match Kernel (REMatch) [44, 45] to capture the structural characteristics within material embeddings. SOAP is a local atomic environment descriptor that encodes atomic geometries by expanding a Gaussian-smeared atomic density locally, using orthonormal functions derived from spherical harmonics and radial basis functions. From local descriptors to structure matching, we use REMatch kernel on top of SOAP descriptor. The REMatch kernel considers the best matching of local environments and employs an averaging strategy to enhance structural comparison. For SOAP construction, we consider periodic boundary conditions. The cutoff radius for the local region (rcut), the number of radial basis functions (nmax), and the maximum degree of spherical harmonics (lmax) are set to 6 \u00c5, 8 \u00c5, and 6 \u00c5, respectively. For the REMatch kernel, the entropic penalty (a) is set to 1, and the convergence threshold is set to (1 \u00d7 10\u22126). A linear pairwise metric is used for the local similarity calculation."}]}