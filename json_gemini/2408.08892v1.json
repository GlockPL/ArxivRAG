{"title": "Leveraging Large Language Models for Enhanced Process Model Comprehension", "authors": ["Humam Kourani", "Alessandro Berti", "Jasmin Hennrich", "Wolfgang Kratsch", "Robin Weidlich", "Chiao-Yun Li", "Ahmad Arslan", "Wil M. P. van der Aalst", "Daniel Schuster"], "abstract": "In Business Process Management (BPM), effectively comprehending process models is crucial yet poses significant challenges, particularly as organizations scale and processes become more complex. This paper introduces a novel framework utilizing the advanced capabilities of Large Language Models (LLMs) to enhance the interpretability of complex process models. We present different methods for abstracting business process models into a format accessible to LLMs, and we implement advanced prompting strategies specifically designed to optimize LLM performance within our framework. Additionally, we present a tool, AIPA, that implements our proposed framework and allows for conversational process querying. We evaluate our framework and tool by i) an automatic evaluation comparing different LLMs, model abstractions, and prompting strategies and ii) a user study designed to assess AIPA's effectiveness comprehensively. Results demonstrate our framework's ability to improve the accessibility and interpretability of process models, pioneering new pathways for integrating AI technologies into the BPM field.", "sections": [{"title": "1. Introduction", "content": "Business Process Management (BPM) represents a management approach focusing on aligning an organization's processes with its strategic objectives. This includes process documentation, automation, integration, and continuous process improvement. Using BPM allows organizations to optimize performance, manage change, and achieve operational excellence [1].\nIn the context of BPM, process models serve as the primary artifact for depicting the flow of activities, data, events, and organizational units in a process. Process models facilitate the analysis, simulation, optimization, and automation of business processes. In today's competitive market, high-quality process models are pivotal for enterprises seeking to enhance their operational efficiency and the quality of their products and services. However, the inherent complexity of real-world business processes often results in intricate models that can be difficult to understand and manage. This complexity can lead to higher costs and more errors during the maintenance and improvement of the processes.\nThe Business Process Model and Notation (BPMN) [2] has become the de facto standard for modeling business processes and is widely used in industry. While BPMN offers a diverse range of elements and constructs, typical usage in industry centers around a limited, commonly used subset [3, 4]. However, the availability of additional, more advanced elements allows for the modeling of specialized or complex scenarios. This capability enhances BPMN's versatility but also complicate model comprehension, increasing the risk of cognitive overload for users [5, 6]. This complexity acts as a barrier, hindering users from fully comprehending BPMN models.\nIn addressing the challenge of comprehending complex process models, leveraging new technologies in AI holds promise. Among these technologies, Large Language Models (LLMs) stand out for their advanced capabilities in natural language processing and pattern recognition. Advanced LLMs, such as gpt-4 [7], are trained on vast amounts of text data, enabling them to generate human-like text and engage in natural language conversations [8]. Due to their comprehensive training data, LLMs contain a wealth of process-related domain knowledge that can facilitate process model comprehension [9]. Moreover, LLMs possess reasoning capabilities, allowing them to recognize, analyze, and make inferences from textual data in various contexts [10]. These reasoning capabilities might enable LLMs to comprehend process models, identify relationships between elements, and interpret process structures accurately.\nIn this paper, we present a novel framework that leverages the capabilities of LLMs to enhance the interpretability and accessibility of complex BPMN models. By abstracting process models into different formats and employing advanced prompt engineering techniques, we guide LLMs to comprehend the different process structures and relationships. Our framework enables users to interact with the LLMs, gaining deep insights into complex processes without requiring technical expertise in modeling languages. Furthermore, we present our tool, AIPA (AI-Powered Process Analyst), which integrates our framework with state-of-the-art LLMs. Our research"}, {"title": "2. Related Work", "content": "The complexity of comprehending business process models has been extensively explored. In [11], the authors conducted a comprehensive review of metrics for assessing business process complexity, identifying different dimensions of complexity. In [12], the authors empirically evaluated the cognitive difficulty associated with comprehending process models, focusing on specific process constructs. Their findings revealed that repetition and exclusive choices impose a higher cognitive load compared to concurrent and sequential tasks. The study [13] assessed the comprehension of BPMN models by healthcare associates, highlighting the challenges they face in understanding complex BPMN models. These studies underscore the need for new methods to enhance the interpretability and accessibility of process models.\nProcess model querying methods [14] play a crucial role in enhancing the accessibility and usability of business process models. These methods can be categorized into two main categories: model-specific querying [15, 16, 17, 18] and models repository querying [19, 20] (i.e., finding the models in a repository satisfying some given constraint). All the proposed approaches allow for a large number of queries. However, the model-specific approaches are limited by i) lack of domain knowledge on"}, {"title": "3. LLM-Based Process Model Comprehension Framework", "content": "This section introduces our framework for LLM-based process model comprehension. We outline the high-level architecture of the framework, and we propose several methods for abstracting process models and various prompting strategies aimed at optimizing LLM performance."}, {"title": "3.1. Architecture", "content": "Figure 1 illustrates the architecture of our LLM-based process model comprehension framework. The process initiates with a user uploading a BPMN model, which is automatically abstracted into an input format that an LLM can process"}, {"title": "3.2. \u0392\u03a1\u039cN Abstraction", "content": "The abstraction of BPMN models is a crucial component of our framework, enabling their transformation into formats that can be effectively processed by LLMs.\nThis section details the four abstraction formats supported by our framework: XML, simplified XML, JSON, and image.\nXML. BPMN Models of the 2.0 standard are typically stored in an XML format [2]. This comprehensive format encapsulates all visual and structural aspects of the process, including tasks, events, gateways, and detailed attributes such as positions, styles, and additional metadata. The Full XML abstraction retains all these details, conforming with BPMN 2.0 standard. Listing 1 shows the full XML abstraction of an example BPMN model.\nSimplified XML (SXML). We designed this abstraction format to reduce the complexity of the standard XML format by deliberately omitting non-essential elements such as layout information, styling, and metadata. These elements are considered irrelevant to the core logical structure of the BPMN model. SXML retains the original XML's hierarchical structure but includes only the fundamental components such as swimlanes, tasks, gateways, and connections. This abstraction provides a concise representation that highlights the operational aspects of the BPMN model without the additional complexity of visual details. Listing 2 shows the simplified XML abstraction of the same BPMN model from Listing 1.\nJSON. We designed the JSON abstraction to restructure the BPMN data into an attribute-based representation. Unlike the hierarchical structure of XML, the JSON format organizes BPMN elements into a flat list, where each element is associated with a set of attributes that encapsulate all necessary information. Similarly to the Simplified XML abstraction, the JSON abstraction retains only the essential components and excludes non-essential attributes like styling and layout information. By doing so, it enables LLMs to process the structural and operational aspects of the process model efficiently, focusing on the attributes that are most relevant for analysis. Listing 3 shows the JSON abstraction of the same BPMN model from Listing 1.\nImage (PNG). Recent advancements in LLMs have extended their capabilities beyond text processing to include support for image inputs. This enhancement allows for the processing and analysis of non-textual data, offering a broader range of applications. We leverage these capabilities through the image abstraction of BPMN models. This abstraction involves transforming the graphical BPMN models into PNG images. This format captures the visual layout of the model, preserving the spatial arrangement of the different BPMN elements. By feeding the generated image into an advanced model, its image processing capabilities are used to interpret the BPMN model's content and structure."}, {"title": "3.3. Prompt Engineering Techniques", "content": "Prompt engineering refers to the techniques used to instruct LLMs and guide them towards desired outputs. This includes providing additional information in the prompt to better inform the LLM about the requirements of the task and the domain knowledge required to perform it. The goal is to optimize the LLM's performance and improve the relevance and quality of its outputs.\nIn our framework, we support several prompting techniques that can be combined to optimize the understanding of BPMN models by LLMs. This section outlines these techniques, and the full prompts are available at https://zenodo.org/records/\n12800002.\nRole Prompting\nOne problem of LLMs is their laziness, which was empirically studied in [28]. Laziness should be interpreted as the tendency to reduce the effort to accomplish a"}, {"title": "4. Tool Support", "content": "In this section, we present our tool AIPA (AI-Powered Process Analyst) which integrates our LLM-based process model comprehension framework, as detailed in Section 3, with OpenAI's LLMs. This integration is flexible, allowing users to configure the tool to use any OpenAI model. The tool can be downloaded from https://zenodo.org/records/12800002 and used following the instructions contained in the README.md file.\nAIPA uses JSON as the default textual abstraction format to represent BPMN models. This choice was informed by our evaluation experiments in Section 5, which show that the JSON and Simplified XML formats provided a clearer and more effective simplification compared to the other abstraction formats we proposed in Section 3.2. The prompting strategies proposed in Section 3.3 are all implemented in AIPA and enabled by default.\nFigure 2 shows a screenshot of AIPA. The user can upload a BPMN model and start a chat about the uploaded model with an AI assistant. When users select specific elements within a BPMN model, the tool generates a JSON representation containing only those selected elements. This focused abstraction ensures that the LLM processes only the relevant parts of the model, enhancing both the efficiency and relevance in the analysis. Additionally, our tool supports voice interactions, allowing users to input their questions and receive responses audibly. The dynamic nature of the tool facilitates an interactive dialogue between the user and the LLM. Users can pose follow-up questions, maintaining the conversation history. Users can reset the conversation at any time to start a new chat.\nNote that before starting the conversation with the AI assistant, the user needs to configure the OpenAI connection by selecting an LLM and entering the corresponding OpenAI API key."}, {"title": "5. Evaluation", "content": "In this section, we comprehensively evaluate our framework by addressing the first three research questions we defined in Section 1:"}, {"title": "5.1. Setup", "content": "This section describes the experimental setup. First, we detail the dataset comprising diverse BPMN models and user queries in Section 5.1.1. Then, we outline our scoring mechanism used to evaluate LLM outputs in Section 5.1.2."}, {"title": "5.1.1. Dataset", "content": "We use three BPMN models in our experiment. First, we use a publicly available BPMN model (Healthcare Process) [38]. This model represents a standard medical process and is publicly available with a textual description. It provides a baseline for comparison but is limited to simple workflow elements.\nTo ensure an unbiased evaluation and to address the possibility that the healthcare model and its description might have been included in the training data of the LLMs, we designed two additional BPMN models specifically for this study. These models incorporate a broader range of BPMN elements such as events, data objects, and complex gateways, ensuring a comprehensive assessment of the LLMs' capabilities across various BPMN facets.\nThe following list gives an overview of the two additional BPMN models we designed for our evaluation together with the help of BPMN experts from our research team:"}, {"title": "5.1.2. Outputs Scoring", "content": "In [39], evaluation criteria for LLMs' outputs on process mining tasks are proposed. These criteria include human evaluation, where a human evaluates the text provided by the LLM; automatic evaluation, which is only applicable to quantitative questions; and self-evaluation, where LLMs evaluate LLM outputs. Particularly, self-reflection methods, where the output of one session is provided to another LLM or another session of the same LLM to score the quality of the output, can be employed for self-evaluation [40].\nFor the evaluation of our framework, we decided to employ LLM self-evaluation due to the large size of the experiments. We incorporate a direct comparison of LLM outputs to ground truth answers. We utilize gpt-40 to perform a self-evaluation, assigning quality scores to LLM responses based on their alignment with the ground truth answers. To assess the robustness of our evaluation, we conducted a detailed review involving human experts; specifically, we assigned this role to the team who designed the models and the ground truth answers. We selected a sample encompassing two questions from each process, with four different LLM-generated answers for each question. Our experts were also provided with the rationale used by gpt-40 for scoring these answers, to assess both the quality and fairness of the evaluation process.\nThe feedback we received on the LLM self-evaluation has been positive in general, affirming that the quality of the evaluation is high and the reasoning behind the scores is both transparent and well articulated. Although there is an inherent level"}, {"title": "5.2. Results", "content": "The automatic evaluation is reproducible by downloading the code from https://zenodo.org/records/12800002 and executing the scripts contained in the offline_tests/questions_auto_eval.py folder. In particular, answer_questions.py is used to execute the questions and evaluate_questions.py can be used to evaluate their results. Each script can be modified with the LLM's connection parameters (API URL, name of the model, and API key) and allows the configuration of the abstraction, prompting strategies, the BPMN model, the list of questions, and the ground truth answers. The BPMN models are stored in the folder offline_tests/bpmn_models, and the questions with their ground truth answers are stored in offline_tests/data. We also collect in aipa_auto_evaluation_results.zip the evaluation results of all the experiments. For each dataset, we include the different experiments (abstractions, prompting strategies, choice of the LLM) in different folders."}, {"title": "5.2.1. Evaluating Abstraction Formats", "content": "In this section, we perform a comparative evaluation of the different abstraction formats defined in Section 3.2. We configure our framework to use gpt-40-2024-05-13, and we only enable simple prompting strategies (S1, S2, S3, and S4) that are efficient in terms of token usage, allowing us to focus on the impact of the abstraction format itself on the comprehension of BPMN models. The results of evaluating the effect of the abstraction formats on LLM comprehension are detailed in Table 5, where we report the average quality scores across various question categories, the overall average quality score, and the number of tokens required for each format.\nOur findings indicate that JSON, simplified XML (SXML), and XML generally produce similar comprehension scores, with PNG lagging behind overall. This difference becomes especially apparent for the healthcare process, where the PNG format scored very low compared to the other formats. However, PNG showed better performance in answering data-related and role-perspective questions, likely due to its visual nature, which makes artifacts and swimlanes more recognizable."}, {"title": "5.2.2. Evaluating Prompting Strategies", "content": "In this subsection, we explore the impact of the prompting strategies we defined in Section 3.3 on LLMs' comprehension of BPMN models. We employing both the JSON and simplified XML abstraction formats for each BPMN model, and we configure our framework to use gpt-40-2024-05-13. Each prompting strategy is assessed individually to determine its specific effect; however, for practical applications, combining these strategies is recommended to achieve optimal results. The average quality scores and standard deviation values for each strategy are reported in Table 6.\nThe results show that strategies S3 (non-technical restriction), S6 (few-shot learning), and S7 (negative prompting) stand out with particularly strong positive impacts across the different models and abstraction formats. For S3, restricting LLMs to use only natural language significantly enhances model comprehension, likely due to improved readability and accessibility of the information. Strategies S6 and S7 also align with expectations, showing a positive effect and confirming the usefulness of both positive and negative example-based learning for enhancing LLM comprehension.\nConversely, strategies S1 and S2, which involve role prompting, demonstrate minimal impact on the comprehension capabilities of LLMs. This outcome suggests that simple identity-based prompts do not significantly influence LLM performance in this context. Similarly, the chain-of-thoughts approach (S4) and the knowledge injection strategy (S5) show limited effects. For S4, the tendency to generate unnecessarily lengthy outputs might overwhelm the user with information that does not directly aid in model comprehension. For S5, the lack of observed improvement might be attributed to the extensive availability of information on the BPMN 2.0 standard online, which the LLM could have already encountered during its training. Future work could explore more targeted knowledge injection strategies, focusing specifically on the complex elements of the given BPMN model rather than providing general knowledge."}, {"title": "5.2.3. Evaluating State-Of-The-Art LLMs", "content": "In this section, we evaluate the performance of state-of-the-art LLMs on our framework. We configure our framework to use the Simplified XML (SXML) abstraction, and we enable the first four prompting strategies (S1, S2, S3, and S4). We have selected four LLMs for this analysis:\n\u2022 GPT-40-2024-05-13: The latest iteration of OpenAI's language models\u00b9, known for its broad and extensive training on a diverse dataset which may enhance its capability in domain-specific questions. The context window of this LLM is 128K. It also supports visual prompts.\n\u2022 GPT-4-Turbo-2024-04-09: A variant of GPT-4 optimized for speed and efficiency, potentially sacrificing some depth in exchange for faster response times. The context window of this LLM is 128K. It also supports visual prompts. On a note, this LLM is outperformed in most known benchmarks by GPT-40 in both response time and quality.\n\u2022 Microsoft WizardLM-2-8x22B 2: An open-source high-capacity model from Microsoft, designed to excel in deep contextual understanding and complex reasoning tasks. The context window of this LLM is 64K, still allowing for the full provision of our considered textual prompts.\n\u2022 Mixtral-8x22B-Instruct v0.1 3: An open-source instructive model geared towards following explicit user instructions with high precision, using fewer tokens for outputs which might affect the depth of generated content. The context window of this LLM is 64K, still allowing for the full provision of our considered textual prompts.\nWe also considered smaller LLMs (Mixtral-8x7B-Instruct v0.14, Codestral5, Mistral 7B6) in our initial experiments, but in light of significantly worse results, we discarded them. Some other LLMs were discarded for their limited context window (Llama3-70B7, Nemotron-4-340B-Instruct\u00ae)."}, {"title": "6. User Study", "content": "In this section, we present a user study designed to assess the usability and effectiveness of our LLM-based framework for process model comprehension in real-world contexts. The study specifically addresses RQ4 (cf. Section 1), exploring how industry experts in the field of business process management perceive and interact with BPMN models using our tool, AIPA. It is important to note that the version of AIPA used in this study did not include the voice support functionalities, as these features were added subsequently. The user study was conducted by configuring AIPA to use gpt-4-1106-preview."}, {"title": "6.1. Setup", "content": "We conducted a total of six interviews, each lasting between 45 minutes and one hour. The interview partners were contacted via email and selected for their extensive experience with BPMN modeling in professional contexts and their background knowledge of how LLMs work. The experts were identified through the professional networks of the authors, who are well-connected within the BPM research and industry community. The selected experts represent a diverse range of professional experiences, from 0-5 years to 15-20 years in the field. All invited experts agreed to participate in the user study. Table 8 provides an overview of the interview partners.\nThe user study comprised six semi-structured interviews guided by a 16-question interview guide. Conducting semi-structured expert interviews allowed us to focus on the research topic while gathering in-depth information [41]."}, {"title": "6.2. Results", "content": "This section provides a comprehensive summary of the interview results, offering insights and key findings derived from the discussions.\nUser-Friendliness. The user-friendliness aspect of the tool is highly praised as it is clear and concise, making it easy for users to interact with the system (Experts 1, 4). Users appreciate that the BPMN model is visible and can be reset, but they suggest further improvements such as displaying multiple process models at the same time to be able to simultaneously analyze several business processes that are connected with each other and improving visual elements, such as adapting the size of the window that contains the model (Expert 3). The ability to drag elements of the BPMN model directly on the user interface is highlighted as positive (Expert 5). It is suggested to further integrate the possibility of enlarging the model view to allow better interaction (Experts 5, 6) and possibly implement a function that highlights in color which part of the model the AI assistant's response refers to (Expert 6).\nSoundness (C1). Regarding the question of soundness, the explanations provided by the AI assistant were generally effective and answered most questions well, although sometimes the answers could have been more precise (Experts 1, 3, 4). The AI assistant explained elements such as message flow accurately, although its impact on the workflow engine was somewhat unclear (Expert 3). It performed well in explaining the exclusive gateway and notations (Expert 3). Overall, more than 80% of the information was correct (Expert 5). However, some issues were also uncovered, such as the AI assistant confusing signals and messages, indicating the need for careful use of correct terminology where a message should be consistently referred to as a message and not a signal (Expert 4). In addition, the AI assistant initially omitted an activity when describing the minimum process and only correctly identified the \u201cdraft invoice\u201d activity after repeated requests.\nCompleteness (C2). In response to the question regarding the completeness of the answers, the feedback shows that the explanations are well-generalized and applicable to different elements of BPMN (Experts 1 - 6). The answers are effective for common processes such as the widely used ordering process and can be appropriately applied to similar scenarios. However, for unique or less typical processes, more scrutiny seems required to ensure the accuracy and applicability of the explanations (Expert 1). The AI assistant's ability to provide relevant, overarching explanations suggests that it has an appropriate level of generalizability for practical use in BPMN modeling.\nContextfullness (C3). For the question on contextual fulfillment, the AI assistant received mixed reviews with scores ranging from 3 to 5. While the AI assistant provided detailed and comprehensive answers that improved users' understanding of BPMN processes, concerns were raised that the AI assistant could mislead those unfamiliar with BPMN by relying too much on the AI assistant's explanations (Experts 1, 3). Users appreciated the insights relevant to process optimization, although Expert 5 perceived some responses as confusing, indicating the need for clearer and more precise contextual understanding. There would be further potential for improvement if the AI assistant could access a broader database for more specific analysis (Expert 5).\nInteractiveness (C4). Regarding the question on interactivity, the performance of the tool was rated highly and predominantly scored between 4 and 5. It responded effectively to critical suggestions and responded appropriately to follow-up questions. Users appreciated that the AI assistant could recall previous interactions (Expert 3). Although the AI assistant sometimes needed several attempts to give the correct"}, {"title": "7. Discussion and Future Directions", "content": "Our approach has demonstrated promising results in using LLMs to enhance the comprehension of process models, yet it also has limitations. This section outlines potential ideas for further research and development.\nAim for more concise outputs: The experts involved in the user study highlighted a tendency of gpt-4 to produce long textual outputs. A more focused output is preferable to speed up the analytical reasoning. This could be addressed by changing the"}, {"title": "8. Conclusion", "content": "In this paper, we introduced a novel framework that utilizes the advanced natural language processing capabilities of Large Language Models (LLMs) to enhance the comprehension of complex process models. We transform intricate Business Process Model and Notation (BPMN) diagrams into various abstraction formats suitable for LLM interpretation, and we explore various prompting strategies to optimize LLM performance. Furthermore, we presented AIPA (AI-Powered Process Analyst), a tool developed to integrate our framework with OpenAI' LLMs. AIPA supports dynamic interactions with process models, enabling users to query BPMN models and receive explanations seamlessly.\nWe extensively evaluated our framework with different BPMN abstractions and prompting strategies. Our evaluation results indicate that the right combination of model abstraction and prompting strategies significantly improves the model's comprehensibility without compromising detail or accuracy. We conducted a user study to assess the ease of comprehension, accuracy of interpretation, and user satisfaction when interacting with BPMN models through AIPA. Results demonstrate a marked improvement in understanding complex models with our LLM-based framework, confirming its effectiveness and user-friendliness. This paper not only underscores the potential of LLMs to make BPMN models more accessible but also provides empirical evidence, highlighting the transformative potential of leveraging AI technologies for BPM and process mining tasks."}]}