{"title": "Compact Rule-Based Classifier Learning via Gradient Descent", "authors": ["Javier Fumanal-Idocin", "Raquel Fernandez-Peralta", "Javier Andreu-Perez"], "abstract": "Rule-based models play a crucial role in scenarios that require transparency and accountable decision-making. However, they primarily consist of discrete parameters and structures, which presents challenges for scalability and optimization. In this work, we introduce a new rule-based classifier trained using gradient descent, in which the user can control the maximum number and length of the rules. For numerical partitions, the user can also control the partitions used with fuzzy sets, which also helps keep the number of partitions small. We perform a series of exhaustive experiments on 40 datasets to show how this classifier performs in terms of accuracy and rule base size. Then, we compare our results with a genetic search that fits an equivalent classifier and with other explainable and non-explainable state-of-the-art classifiers. Our results show how our method can obtain compact rule bases that use significantly fewer patterns than other rule-based methods and perform better than other explainable classifiers.", "sections": [{"title": "Introduction", "content": "Deep neural networks (DNNs) have been used to solve complex problems in machine learning where non-structured data is available in large volumes, such as image and video [LeCun et al., 2015]. However, the use of these models is not always possible in cases where human liability is still relevant in the decision-making process, like medicine and finance [Arrieta et al., 2020]. Rule-based algorithms are considered one of the most trustworthy for the users, as they explicitly tell the users the patterns found and their relevance in each decision. They are also considered more faithful than other post hoc explainable artificial"}, {"title": "Related Work", "content": "Rule-based models and decision trees have been mostly trained using heuristic procedures due to their discrete and non-differentiable nature [Wei et al., 2019]. However, these algorithms may not find the best solution and are not guaranteed to find a close one [Rudolph, 1994]. Search algorithms can also be used, but they are expensive to compute, making them unfeasible in large datasets. Most existing rule-based methods mine a series of frequent patterns, which may not be ideal in all situations and do not achieve the same performance as other complex methods such as gradient boosting or random forest [Yuan, 2017]. However, such complex models are harder to interpret, and it is necessary to use tools such as Shapley values to do so [Lundberg et al., 2020]. Fuzzy rules offer good interpretability, but they are computationally intensive to train [Mendel, 2023] and might require hundreds of rules to achieve good performance.\nRule-based methods have been used as well for explainable symbolic reasoning when the antecedents are known concepts, and their relationships can be exploited to solve tasks such as classification. Logic structures can be fixed, and then the right concepts are to be found [Petersen et al., 2022, Barbiero et al., 2023]. Finding the optimal connections among the concepts studied [Vemuri et al., 2024] is also possible. However, the interpretability of the system is compromised by the quality of the concept detection, which is hard to assess. It is also possible to distil black-box models into rule-based ones with good results Li et al. [2024], at the expense of having to train both models."}, {"title": "Gradient-based training for rule-based and discrete models", "content": "Due to the good scalability of gradient-based optimization, gradient-based methodologies have been developed for many systems that are not directly differentiable. The most popular is the Straight-Through Estimator (STE) [Bengio et al., 2013]. Gumbel-Softmax estimator is also very used in architectures that need to sample a categorical distribution in a differentiable model [Jang et al., 2016], such as variational autoencoders. Gradient-based optimization for discrete models is also closely related to the quantization of a DNN. For example, one of the pioneering works in using binary weights was aimed at reducing the computing expenses of a DNN model [Courbariaux et al., 2015].\nThe most common approaches to gradient-based rule learning involve the joint use of discrete and continuous models so that continuous models generate a good gradient flow [Wang et al., 2024, Zhang et al., 2023]. The problem in that case is to make sure that the discrete and continuous models behave similarly, which is particularly complex for large models. These models also tend to create large numbers of additive rules, so the reasoning mechanism is very difficult for a human being to understand properly. For the case of fuzzy rule-based inference, it is possible to optimize fuzzy sets using gradient descent"}, {"title": "Gradient-based Rule Inference", "content": null}, {"title": "General scheme", "content": "Let D = {(X1,Y1), . . ., (XN, YN)} denote a data set with N instances and M\nfeatures, where Xi is the observed feature vector of the i-th instance with j-th"}, {"title": "Fuzzification layer", "content": "Existing rule-based gradient methods rely on dense binarization of real-valued variables to generate partitions, which are then used as potential antecedents for rule construction. In contrast, the FRR model uses fuzzy logic and fuzzy sets to define partitions that are both significantly simpler and more interpretable for end users.\nFuzzy logic extends classical binary logic by allowing truth values to take any real number within the range [0, 1] H\u00e1jek [2013]. Traditional Boolean operators are then replaced with their real-valued counterparts. For example, conjunction (the logical \"and\") is modelled using T-norms, such as the product or minimum operator, whereas disjunction (the logical \u201cor\") is modelled using T-conorms, such as the maximum operator.\nThe process of fuzzification involves mapping values from the original domain to degrees of membership in fuzzy sets, which collectively form a fuzzy partition. This partitioning divides the universe of discourse into overlapping fuzzy sets, enabling a more nuanced representation of information. Fuzzy partitions are designed to align with linguistic terms such as \"low,\" \"medium,\" or \"high\" Zadeh [1975]. This linguistic representation allows for a more compact set of partitions in real-valued features. Additionally, linguistic concepts provide greater interpretability for end users, as they correspond more naturally to human reasoning than arbitrary numerical thresholds.\nThe first layer of the FRR model is a fuzzification block that transforms input observations into degrees of truth according to predefined fuzzy partitions. All numerical features are represented as fuzzy linguistic variables with at most V linguistic labels. Formally, the i-th instance, feature j, and linguistic label v, the degree of truth is denoted by $\\mu_{j,v}(X_{i,j})$. So, the output of the fuzzification layer is given by $u_{j+v}^{(1)} = \\mu_{j,v}(X_{i,j})$.\nCategorical variables are represented using one-hot encoding, which can be interpreted as a degenerate form of fuzzy partitioning, where truth values are restricted to 0 or 1. Consequently, categorical variables can be seamlessly incorporated into the model without additional considerations, as each category is modelled using a degenerated fuzzy set."}, {"title": "Logic inference layers", "content": "We first consider the Mamdani inference expression to compute the truth value of a fuzzy ruler in an inference system\n$r(X) = w_r \\prod_{a\\in A_r} \\mu_a(X),$\nbeing $w_r$ the rule weight, $A_r$ the set of antecedents of the rule and $\\mu_a(X)$ the truth degree of the corresponding fuzzy set.\nIn order to replicate this, we propose to separate the logic inference into two steps, which correspond to two different layers in the hierarchical model. The first step is to choose which space partitions are forwarded into the rule for each feature. With that aim, layer 2 uses a weight matrix $W^{(2)}$ of size $M \\times V$, i.e., the number of features per number of linguistic labels, which measures the significance of each linguistic label in the logic inference. Then, we only forward the linguistic label with the highest weight value per each feature. In accordance, the output of the second layer is\n$u_j^{(2)} = \\sum_{v=1}^{V} f(W_{j,v}^{(2)}) W_{j,v}^{(2)}  u_{j+v}^{(1)} $\n$=  \\sum_{v=1}^{V} (f(W_{j,v}^{(2)}) W_{j,v}^{(2)}  \\mu_{j,v}(X_{i,j})),$\nwhere f is an indicator function that, given an instance Mij of the i-row of a certain matrix M, returns 1 if that instance has the highest value in the row, i.e.,\n$f(M_{i,j}) = \\begin{cases}\n1 & \\text{if } j = arg \\underset{k}{max} M_{i,k},\n\\\\0 & \\text{otherwise}.\n\\end{cases}$\nThe second step for performing the logic inference is to choose which features are selected as part of the antecedents of the rule. In order to set the number of antecedents per rule to a fixed size A, in the third layer, we use a weight matrix $W^{(3)}$ of size A $\\times$ M, which quantifies the relevance of each feature per antecedent in the rule. The contribution of the k-th antecedent is given by the following equation:\n$A_k = f((\\sum_{j=1}^{M} W_{kj}^{(3)}  u_j^{(2)})W_{k,j}^{(3)}) u_j^{(2)},$\nwhere f is the function defined in Eq. (3). Consecutively, the degree of truth of each rule is computed as the product of all antecedent's contributions and is the output of the third layer\n$u_j^{(3)} = \\prod_{k=1}^{A} A_k =  \\prod_{k=1}^{A}(\\sum_{j=1}^{M} (f(W_{k,j}^{(3)} ) W_{k,j}^{(3)}  u_j^{(2)}).$"}, {"title": "Making the model parsimonious", "content": "The procedure in Section 3.3 sets the number of antecedents per rule to a fixed value. This number represents the highest possible count of antecedents, but ideally, we aim to keep the number of antecedents limited to ensure rule interpretability and reduce the risk of overfitting. In many cases, concise rules not only enhance performance but also ensure that the model remains easily understandable for human users.\nTo reduce the number of antecedents in each rule, we make them \"compete\"\nwith a null element that will make the system ignore the antecedent value if it is not useful. To do so, we can consider the convex combination between 1 and the contribution of each antecedent of the rule\n$\\tilde{A}_k = \\alpha_k A_k + (1 - \\alpha_k),$"}, {"title": "Final decision layer", "content": "This module computes the predictions of the FRR given the truth degrees of the rules. In this layer, we consider the matrix $W^{(4)}$ of size $R \\times C$ where R is the number of rules and C the number of classes of the target variable. Then, each weight $W_{rs}^{(4)}$ corresponds to the score that rule r gives to class c. Taking into account the truth degrees of each rule provided by the previous layer, we can compute the final outcome, denoted in general by $u^{(4)}$, using sufficient or additive rules.\n\u2022 Sufficient rules: for a fixed class c we consider the set of rules whose maximum score is assigned to c and then we consider the value of the highest score per truth degree as output\n$FRR(X_i)^{(4)}=  \\underset{s\\in\\{1,...,R\\}}{max} f(W_{r,s}^{(4)}W_{rs}^{(4)}\\gamma_s(Xi).$\nTo select which rules have c as the class with maximum score we use again the function in Eq. (3).\n\u2022 Additive rules: in this case we just perform the standard matrix multiplication between the rules truth degrees and the score matrix\n$FRR(X)_c^{(4)} = \\sum_{s=1}^{R} r_s(X_i).$\nAgain, we need to apply the softmax function in Eq. (6) to maintain the weights between [0,1]. In this manner, since fuzzy truth degrees are already numbers in [0, 1], we can directly apply the cross-entropy loss L without further modifications.\nNotice that Eqs. (2), (5), (9) and (10) are not differentiable with respect to the weights because of the presence of the argmax function in the definition of f in Eq. (3). We show how to overcome this problem and others related to gradient-based optimization of the FRR in Section 4."}, {"title": "Extracting the rules from the model", "content": "Once trained, we can recover the rules obtained by the system by following \"the paths\" in the FRR. For each rule, we select the features that have the biggest weights according to $W^{(3)}$ that were not cancelled in Eq. (9). Then, for each feature we select the linguistic label according to $W^{(2)}$ and finally, in the decision layer, we choose the consequent according to $W^{(4)}$ and depending on if we are working with sufficient or additive rules, considering Eq. (10) or (11), respectively."}, {"title": "Gradient-based optimization of the FRR", "content": null}, {"title": "Component derivation in the FRR", "content": "To optimize the cross-entropy loss we consider gradient-based optimization, so the parameters are going to be updated according to\n$W_{i,j}^{(1)} |_{t+1}= W_{i,j}^{(1)} |_t -\\eta_t \\frac{\\partial \\mathscr{L}}{\\partial u^{(4)}}  \\frac{\\partial u^{(4)}}{\\partial W_{i,j}^{(1)}},$\nwhere nt is the learning rate. Then, to ensure an effective update of the model's parameters, let us analyse the derivative of each node with respect to its directly connected weights and nodes.\nFirst of all, since all the weights are normalized using the softmax function (see Eq. (6)), the derivative of each node according to the weights is multiplied by the derivative of the softmax, i.e,\n$\\frac{\\partial u_{i}^{(1)}}{\\partial W_{i,j}^{(1)}} = \\frac{\\partial u_{i}^{(1)}}{\\partial \\tilde{W}_{i,j}^{(1)}}  \\frac{\\partial \\tilde{W}_{i,j}^{(1)}}{\\partial W_{i,j}^{(1)}}$", "subsections": [{"title": null, "content": "where\n$\\frac{\\partial \\tilde{W}_{i,j}^{(1)}}{\\partial W_{i,m}^{(1)}} = \\frac{1}{\\alpha} (\\delta_{j,m} - \\tilde{W}_{i,m}^{(1)}),$\nand $\u03b4_{j,m}$ is the Kronecker delta. Then, we can compute the derivative of Eqs. (2) and (5) with respect to the normalized weights directly.\n$\\frac{\\partial u_j^{(2)}}{\\partial \\tilde{W}_{j,v}^{(2)}} =  (\\frac{\\partial f}{\\partial \\tilde{W}_{j,v}^{(2)}} + f(W_{j,v}^{(2)})) u_{j+v}^{(1)}$\n$\\frac{\\partial u_{j}^{(3)}}{\\partial W_{k,j}^{(3)}} = f((\\sum_{2})).$"}]}, {"title": "Gradient estimation", "content": "To compute the derivative of function f, present in numerous equations in the FRR, we have considered gradient estimators, which substitute the derivative of the non-differentiable function by an approximation. This approximation is typically the derivative of the identity function (STE) or another smooth function which behaves similarly to the original Yin et al. [2019]. In the case of the FRR, we replace the derivative of f in Eqs. (14) and (16) by 0 or the identity.\nAlthough other approximators could be considered as gradient estimators, there is no guarantee of better results with respect to the use of the identity function Schoenbauer et al. [2024].\nApart from STE, we have also considered \"gradient grafting\" Wang et al. [2024], which consists of training simultaneously a discrete model in the forward pass and a continuous one in the backward pass."}, {"title": "Restricted additive contributions", "content": "The FRR mimics the behaviour of fuzzy logic inference because of the different indicator functions used during the inference process. However, these functions present some problems. First, they are not differentiable, and we need to use a STE. Secondly, even with the STE, the indicator functions reduce the flow of information to only one of the possible paths. In order to speed up training, we propose a relaxed version of the indicator function during training time that will also keep the standard behaviour of the model in inference mode. Let M be a matrix of size n x m, we define:\n$f_\u00df(M_{i,j}) = \\begin{cases}\n\\frac{1}{1+\\beta(m-1)} & \\text{if } j = arg \\underset{k}{max} M_{i,k},\n\\\\ \\frac{\\beta}{1+\\beta(m-1)} & \\text{otherwise,}\n\\end{cases}$\nwhere \u03b2\u2208 [0,1] is a hyperparameter of the model. In this way, when \u1e9e > 0, the additive nature of the summations is restricted but not completely ignored. When \u03b2 = 0, Eq. (18) is equivalent to a hard indicator function. Since $\\sum_{m=1}^n f_\u03b2(M_{i,j}) = 1$ always holds regardless of the value of \u1e9e, the output will not change the scale of the input values.\nTo set the value \u1e9e during training, we start with a maximum value (usually 1) and gradually decrease it to a minimum value (usually 0). This allows the model to explore freely with larger gradient flows initially and resemble final inference behavior in later epochs."}, {"title": "Projection functions", "content": "The FRR might find problems of vanishing gradient because the truth degree of a rule is computed using the product of values in the [0, 1] range, which might result in values very close to 0 in Eq. (17). A feasible solution is to use custom functions to slow down the speed of approaching to zero. In Wang et al. [2024] the authors came across a very similar problem, and they propose to use the following function:\n$P(x) = \\frac{1}{1-\\log(x)}$\nHowever, there are many other functions, like $P(x) = \\sqrt{x}$, that would serve the same purpose.\nIn the case of the FRR, this function can be applied when computing the rule truth degree in Eq. (5)\n$\\tilde{u}^{(3)} = \\prod_{k=1}^{A} P(A_k + \\epsilon),$\nwith e a positive small constant."}, {"title": "Residual connections", "content": "We also incorporate a residual connection to tackle the problem with the vanishing gradient in Eq. (5). We consider another connection between the rules output and their antecedent values, similar to residual connections [He et al., 2016]:\n$\\tilde{u}^{(3)} = u^{(3)} + \\gamma \\sum_{k=1}^{A} A_k.$\nThe multiplying constant y of this expression starts at 0.1 and decreases linearly with the number of epochs passed in the training process, reaching 0 at the end and in the inference process."}, {"title": "Experiments", "content": null}, {"title": "Experimental settings", "content": "We took 40 datasets of different sizes, all of which are very common in studying classification performance. They range from 80 to 19020 samples and from 2 to 85 for different numbers of features. Please take a look at Appendix D to see their specific details and citations. As a performance metric, we use the standard accuracy metric. We use a 5-fold evaluation to obtain more reliable results than a traditional 80/20 split. When evaluating tree and rule-based models, we also measure the number of rules and antecedents they use to solve the problems.\nFor the fuzzification of real-valued variables, we use 3 linguistic labels, which are translated to the concepts of \"low\", \"medium\" and \"high\". The parameters for each of them are computed based on the quantile distribution. See more details about this in the Appendix A."}, {"title": "Comparison with an equivalent classifier optimized with genetic fine-tuning", "content": "We fitted different fuzzy rule-based classifiers using genetic optimization, which is the current state-of-the-art for such systems. We fit classifiers with different number of rules and antecedents, and we found that the best classifiers with this technique were obtained using smaller models (detailed results are shown in Appendix E).\nThen, we trained an FRR using the equivalent maximum number of rules, antecedents, and the same linguistic variables to find the best genetic one. The results for both are in Table 1 under the \"FRR\" and the \"FGA\" columns. We can see there that the FRR obtained a significant improvement in terms of accuracy over the FGA, backed by a t-test with p < 0.01. The number of rules was also bigger, but if we consider both the number of rules and antecedents, we see that the FRR resulted in less complex classifiers (Figure 2)."}, {"title": "Scaling the size of the FRR", "content": "Although the ideal FRR should be as compact as possible, we also believe that it is good to be able to scale the model to more complexity if the trade-off of performance is considered worth it by the user.\nJust as with genetic optimization, we found problems in scaling the FRR to larger numbers of rules. However, we also found that using additive rules instead of sufficient rules allowed the system to scale better in terms of performance, as can be seen in Figure 2 and Table 1 under the label of AdFRR."}, {"title": "Classification performance and comparison with other explainable and standard classifiers", "content": "Table 1 shows the results for all the datasets and all the classifiers tested. The interpretable methods chosen were: an equivalent Fuzzy Rule Based classifier using genetic fine tuning Fumanal-Idocin and Andreu-Perez [2024] (FGA), Rule-based Representation Learning (RRL), which is another method to obtain gradient optimized rules [Wang et al., 2021], classification trees constructed using Classification and Regression Trees (CART) methodology [Timofeev, 2004], C4.5 Quinlan [1993] and a Linear Regression (LR). We also show results for four models considered \"complex\u201d: a Support Vector Machine (SVM), a Multilayer Perceptron (MLP) [Hackeling, 2017], Random Forest (RF) [Ho, 1995] and Gradient Boosting (GB) [Friedman, 2001], being the latter two ensemble models.\nIn terms of accuracy, the best explainable classifier obtained was the RRL, with an average accuracy of 82.33. It did so, however, but using the largest num-ber of additive rules and antecedents per rule, which makes it hardly interpretable in practice.\nIn terms of the number of rules, the FRR was only surpassed by the Genetic fine-tuning of the fuzzy rule inference, which performed significantly worse than the FRR in terms of accuracy. The most direct competitor of the FFR, the RRL, obtained more accuracy at the expense of using more than 7 times the number of rules, which are also additive and less interpretable than the FRR sufficient rules. The AdFRR obtained better results than the FRR and the C4.5.\nWe believe that all the classifiers that used fuzzy sets were limited in perfor-mance by the fuzzification method used, which prioritized explainability over performance. It is also worth pointing out that the performance of any of the"}, {"title": "Ablation study", "content": "To show the effect of the gradient estimation methods in the training process, we also run the FRR with different configurations:\n\u2022 For the indicator in training: we use the standard indicator, the restricted additions and no indicator.\n\u2022 With and without residual connections.\n\u2022 For gradient estimation: STEo, approximating the gradient of the indicator with 0, STE\u2081 likewise with the identity function, and using gradient grafting in substitution of the STE method [Wang et al., 2021].\nThe results are shown in Table 2, which shows that the residual connec-tions were instrumental in achieving good results. Restricted additions were particularly effective when combined with gradient grafting. For results of more combinations of parameters, we refer the reader to Appendix G."}, {"title": "Conclusions and future work", "content": "We introduced a new explainable classifier, named Rule-based Fuzzy Reasoner (FRR), that can automatically learn rules for data representation and classifica-tion using gradient-based optimization. The FRR comes with a big advantage over other rule-based methods: the user can set the number maximum number of rules and their length, which avoids common problems in real-life applications like having an excessive number of rules and antecedents and overly complex par-titions of the space. The FRR presented a series of problems in non-differentiable functions and vanishing gradients, which we studied and mitigated. As tested in the experimentation, the FRR can obtain good performance results both for"}, {"title": "Using the FRR with other conjunctions", "content": "In fuzzy logic, T-norms are considered to be the extension of the boolean conjunction and are defined as binary functions T : [0, 1]2 \u2192 [0, 1] which are commutative, associative, increasing in both variables, and 1 is its neutral element (i.e., T(x, 1) = x for all x \u2208 [0,1]). Since the properties imposed in this definition are not very restrictive, there exists a lot of functions that can be used to model fuzzy conjunctions. However, in practice, the minimum $T_M(x,y) = min\\{x,y\\}$ and the product $T_P(x,y) = xy$ are the preferred choice because they are easy to implement and have a simple n-ary form:\n$T_M(x_1,...,x_n) = min\\{x_1,...,x_n\\}, T_P(x_1,...,x_n) = \\prod x_i.$\nIn general, since all T-norms are associative, the order of the inputs does not change the output, and any t-norm defines an n-ary function which is equivalent to the iterative evaluation of each instance.\n$T(x_1,T(x_2,...T(x_{n-1},x_n))) = T(x_1,...,x_n) = \\underset{i}{\\prod} x_i.$\nHowever, no T-norm has an easy closed expression of its n-ary form, and that is one of the reasons why the minimum and the product are mostly used. Nonetheless, continuous Archimedean T-norms are a special type that can be constructed via a unary continuous, strictly decreasing function t : [0,1] \u2192 [0, +\u221e) with t(1) = 0 called generator and they have a closed n-ary expression that allows a more efficient implementation Giannini et al. [2023]:\n$T(x_1,...,x_n) = t^{-1}(min {(0*),(\\sum t(x_i))}).$"}, {"title": "Datasets used and Code availability", "content": "The list of datasets used, alongside the number of features, samples, and classes, is in Table 3. They were collected from the UCI datasets Kelly et al. and the Keel website [Triguero et al., 2017]. The code will be publicly available on Github.\nFuzzy rule experiments using genetic optimization were carried out using the exFuzzy library [Fumanal-Idocin and Andreu-Perez, 2024], available at https://github.com/Fuminides/ex-fuzzy. RRL implementation is provided by the authors at https://github.com/12wang3/rrl. C4.5 classifier has been implemented by ourselves in Python. For the rest of the classifiers, we used the implementation available in Scikit-learn library Pedregosa et al. [2011]."}, {"title": "Hyperparameter choosing and detailed performance for each method", "content": "We tried different configurations of hyperparameters for all the classifiers tested. The ones reported in the main text are the ones that achieved the best accuracy results for each of them.\n\u2022 Random forest: we tried 100 and 200 trees with maximum depth of 3 and 5 in both cases.\n\u2022 Gradient boosting: same as for random forest.\n\u2022 SVM: we used two kernels, a radial basis function and a linear kernel. We also used a regularization parameter set up as 1.0 or 0.1.\n\u2022 CART: we tried trees with three different cost complexity pruning parame-ters. The higher this parameter, the smaller the final tree shall be. We tried: 0.0, 0.001 and 0.003.\n\u2022 RRL: for the RRL, we used the configurations that the authors recommend in Wang et al. [2021]. However, we obtained very similar results in all cases.\n\u2022 MLP: we used three different MLPs with one, two and three hidden layers in each case. The size of the hidden layer was 100 neurons in all cases. Same for the Fuzzy MLP.\n\u2022 C4.5: we tried a maximum depth of 5 and 10.\nFor the fuzzy classifiers trained with a genetic algorithm, we tried a different number of antecedents, rules per class and linguistic variables."}, {"title": "Reducing the size of the FRR", "content": "Even though we can set up a maximum number of rules and antecedents, there are sometimes cases where the FRR can find good solutions that are considerably smaller than these specifications. In our experimentation, we found some modifications in the loss function that helped reduce the size of the rules and their number.\nThe strategy to shorten the rules is to add a Laplacian term in the loss function that penalizes the weights in the cancellation process that affect the antecedent truth value:\n$L_r = - \\sum_{r=1}^{R} \\sum_{k=1}^{A} \\alpha_{k,1},$\nwhich is then added to the cross-entropy loss with a multiplier, which in our experimentation was set to 0.01.\nTo reduce the number of rules, we use an expression taken from the Gradient boosting algorithm. The reasoning why it reduces the number of rules is not direct, but it had a clear impact on the results obtained nevertheless.\nFor each rule, except for the first one, we compute the residuals of the system prediction up to that rule. Then, we multiply those losses by a small factor and add it to the final loss. This works differently for sufficient and additive rules, as the final prediction is computed differently in both cases.\n\u2022 For the case of sufficient rules, the loss for each rule is computed as:\n$L_r = \\frac{1}{N}  \\sum_{i=1}^{N} (1 - \\underset{s\u20ac\\{1,...,r-1\\}}{max} f(W_{rs}^{(4)}W_{rs}^{(4)}\\gamma_s(Xi)).$\n\u2022 For additive rules, we do the following:\n$L_r = \\frac{1}{N}  \\sum_{i=1}^{N}( \\sum_{S=1}^{r-1} W(Xi)).$\nThen, we can obtain the final expression as:\n$L_2 = \\sum_{r=2}^{R} L_r,$\nwhich can be added to the global loss as a Laplacian term."}, {"title": "Additional configurations tested", "content": "For the sake of brevity, some of the results regarding the different gradient techniques have been cut from the main part of the manuscript, as they were not needed to draw the relevant conclusions from the experiments. However, we have included here the rest of the configurations tested in case the reader is interested in the result of a particular configuration. We show Table 6 for the ablation study in the FRR and Table 7 those for the AdFRR. Those configurations where the \"K upper\" and \"K lower\" numbers are equal to 0.0 refers to a strict indicator (k was always 0 during training in Eq. (18)). When they are both 1.0, it corresponds to the continuous indicator: k = 1 in Eq. (18) during the whole training."}, {"title": "Computational resources employed", "content": "For the experiments using gradient-based optimization, we used the CERES cluster from the University of Essex. CERES has 1096 processing cores (2192 with hyperthreading) provided by servers with a mix of Intel E5-2698, Intel Gold 5115, 6152 and 6238L processors, and between 500Gb and 6Tb RAM each. There are also 24 NVidia GTX and RTX Series GPU cards (16 x GTX1080Ti and 8 x RTX2080)."}]}