{"title": "Adapting Job Recommendations to User Preference Drift with Behavioral-Semantic Fusion Learning", "authors": ["Xiao Han", "Chen Zhu", "Xiao Hu", "Chuan Qin", "Xiangyu Zhao", "Hengshu Zhu"], "abstract": "Job recommender systems are crucial for aligning job opportunities with job-seekers in online job-seeking. However, users tend to adjust their job preferences to secure employment opportunities continually, which limits the performance of job recommendations. The inherent frequency of preference drift poses a challenge to promptly and precisely capture user preferences. To address this issue, we propose a novel session-based framework, BISTRO, to timely model user preference through fusion learning of semantic and behavioral information. Specifically, BISTRO is composed of three stages: 1) coarse-grained semantic clustering, 2) fine-grained job preference extraction, and 3) personalized top-k job recommendation. Initially, BISTRO segments the user interaction sequence into sessions and leverages session-based semantic clustering to achieve broad identification of person-job matching. Subsequently, we design a hypergraph wavelet learning method to capture the nuanced job preference drift. To mitigate the effect of noise in interactions caused by frequent preference drift, we innovatively propose an adaptive wavelet filtering technique to remove noisy interaction. Finally, a recurrent neural network is utilized to analyze session-based interaction for inferring personalized preferences. Extensive experiments on three real-world offline recruitment datasets demonstrate the significant performances of our framework. Significantly, BISTRO also excels in online experiments, affirming its effectiveness in live recruitment settings. This dual success underscores the robustness and adaptability of BISTRO.", "sections": [{"title": "1 INTRODUCTION", "content": "In recent years, a clear trend has emerged where online recruitment platforms are undergoing rapid development and surpassing local job markets as the primary recruitment channel. According to the market research report [16], the global online recruitment market size, which was valued at USD 29.29 billion in 2021, is projected to expand to USD 58.16 billion by 2030, with a compound annual growth rate of 7.1% from 2023 to 2030. Consequently, the job recommender system, a primary method in online recruitment, has also underscored its significance.\nHowever, unlike conventional recommendation settings, recruitment is inherently a bidirectional selection process [27, 45]. This dynamic necessitates that not only should the jobs align with the expectations of the job-seekers, but the job-seekers must also satisfy the requirements set by the employers. As a toy example illustrated in Figure 1(a), active users refine job preferences in order to secure employment opportunities, reflected in the user-job interactions and the resume revision. Initially, the individual seeks employment as a data engineer but encounters setbacks due to the shortage of data pipeline and architecture design capabilities. This experience led to the realization that his skills may be more aligned with data analyst positions, which shows the preference drift. Motivated by this insight, the job-seeker refines his resume to better match data analyst positions, culminating in the successful acquisition of an offer. Furthermore, Figure 1(b) provides some statistical insights about resume update behaviors collected from a prominent online recruitment platform in China over a six-month period to imply the prevalence of this phenomenon. It highlights that, on average, job-seekers tend to revise their resumes every 7.28 days when they do not secure employment and those who update their resumes frequently are at least 44% more successful in receiving job offers than the rest of those who are not proactive, underscoring the effectiveness of consistently optimizing resumes during the job-seeking process. Another interesting insight is over three-quarters of individuals would change their job-seeking objectives when refining their resumes, indicating a strong correlation between preference drift and resume refinement.\nThe inherent propensity for frequent preference drift implies the necessity of nuanced and timely modeling of user preference in job recommendation, which limits the effectiveness of both content and behavior-based recommendation algorithms. On the one hand, content-based job recommender systems [26, 56, 57] strive to precisely profile job-seeker capabilities for better aligning their qualifications with recommendation results. However, they fall short in capturing job-seeker nuanced job preferences. On the other hand, although behavior-based recommendation, especially session-aware recommendation [33, 35, 61], provides a solution to timely track job-seeker preferences by short-term interactions, their performance is limited by the length of session-based interactions and thus is vulnerable to noise, which is common in practical job recommender systems.\nTo address the above issues, we propose a novel session-based framework in this paper, namely BISTRO (Behavioral-SemanTic fusion for job Recommendation). Specifically, the framework contains three modules: 1) A coarse-grained semantic clustering module. It groups users or jobs based on semantics to facilitate the broad identification of person-job matching. 2) A fine-grained job"}, {"title": "2 RELATED WORK", "content": "2.1 Job Recommender System\nIn job recommender systems, various studies have been proposed to match job seekers with recruiters. As highlighted by [13, 23, 24, 30, 37, 38, 49, 52, 62, 63, 65], while traditional recommender systems are adept at predicting job seekers' preferences, a key to augmenting the system's overall effectiveness lies in addressing the issue of preference drift. Conventionally, this challenge has been approached through feature engineering in a certain degree, utilizing content data to capture evolving preferences [12, 21, 66]. Efforts have also been made [15, 19, 29] to integrate clustering into recommender systems, tackling this problem at the model level by grouping similar users or jobs based on minimal user/job contents. Although the user and job representations could be enhanced by these refined features, they heavily rely on the results of semantic analysis of fixed content. To overcome these limitations, we introduce a behavioral-semantic fusion framework that merges content-driven and interaction-based methodologies, offering a more comprehensive and adaptive solution to the challenge of preference drift.\n2.2 Recommendation with Graphs\nGraph neural networks are increasingly utilized to capture the complexity of entities and their intricate interrelations. Recent research has leveraged the graph-structured information propagation paradigm to enhance user and item embeddings, employing a variety of neighborhood aggregation techniques [14, 18, 44, 60]. For instance,"}, {"title": "3 PRELIMINARIES", "content": "In this paper, we adopt the BISTRO framework to solve user preference drift during the job-seeking process in top-k job recommendations for users. Specifically, as shown in the above statistics, we believe a user \\(u \\in U\\) would continue to refine her/his resume along with her/his job preference drift. Thus, we first segment the user interaction sequence based on the timestamps of resume refinement under the assumption that the job preferences of users remain relatively stable within a given session.\nDEFINITION 1. Job Preference Drift. It refers to the phenomenon in which users change their job preferences, which could be predominantly observed through whether the user modifies the resume rather than modeling the short-term job-seeking behaviors where user interests tend to remain stable.\nDEFINITION 2. Interaction Noise. It stands for job-seeking behaviors that are inconsistent with user preferences, i.e., accidental clicks while a user browses jobs.\nDEFINITION 3. Session-based User-Job Interactions. For every user u, we need to segment the sequence of the job interactions into multiple sessions \\(S_u = \\{s_1, s_2, \\ldots\\}\\) based on whether the resume of the user has been changed, in order to obtain more accurate job preference in a specific period.\nBased on the definition above, we formulate the problem of the session-based job recommendation as follows:\nPROBLEM 1. Given the historical user resumes \\(D_u\\), job requirements \\(D_j\\) and interaction sessions \\(S_u\\), the objective of the job recommender system is to identify and rank a list of the top-k job vacancies that would likely appeal to a user u during a session \\(s_u\\)."}, {"title": "4 METHODOLOGY", "content": "In this section, we detail the architecture of the proposed framework, BISTRO, illustrated in Figure 2. The framework comprises three primary modules: 1) a coarse-grained semantic clustering module, 2) a fine-grained job preference extraction module, and 3) a personalized top-k recommendation module.\nInitially, the coarse-grained semantic clustering module incorporates a feature clustering approach with a probabilistic latent semantic analysis method, which facilitates the identification of broad user or job categories. The probabilistic latent semantic analysis method could efficiently summarize topics of the resume content and job requirements, and those topics could guide clustering directions. Subsequent to this, the fine-grained job preference extraction module constructs a multi-granular interaction hypergraph to deal with the data drift issue and then designs an adaptive wavelet learning algorithm for noise-robust preference extraction. In the hypergraph, we define two types of hyperedges, reflecting the intra-session and inter-session relationships, to introduce more information to the graph. Moreover, the wavelet filter in hypergraph wavelet learning is designed to detect noise in the spectral domain and further adaptively mitigate the effects of data noise. The final stage combines a recurrent neural network to discern personalized job preferences from short-term sequential interactions to generate top-k job recommendation results."}, {"title": "4.1 Coarse-grained Semantic Clustering", "content": "The coarse-grained semantic clustering serves as the foundational component of our framework, setting the stage for nuanced preference feature extraction. By tackling the challenge of aligning diverse and dynamic job preferences with suitable opportunities, this module highlights the core motivation behind the intricate process of facilitating effective employment matching. It utilizes semantic insights from resumes and job descriptions to broadly match job seekers with appropriate vacancies, identifying potential fits based on semantic themes related to job preference and recruitment requirements.\nIn our model, the conditional probability between the document content \\(d \\in D\\) and words \\(w \\in d\\) is captured through a latent embedding \\(z\\) (\\(z = \\text{Linear}(w)\\) or \\(\\text{Linear}(d)\\)), representing a class or topic. The model parameters, \\(P(w|z)\\) and \\(P(z|d)\\), allow for the possibility that words may associate with multiple classes and documents that may cover various topics. We assume that the distribution of words given a class, \\(P(w|z)\\) is conditionally independent of the document, implying \\(P(w|z, d) = P(w|z)\\). Thus, the joint probability of a document d and a word w is represented as:\n\\[P(w,d) = P(d) \\sum_z P(w/z)P(z|d).\\]\nTo estimate the parameters \\(P(w|z)\\) and \\(P(z|d)\\), the Expectation-Maximization (EM) algorithm iteratively maximizes the log-likelihood function L over a training corpus D:\n\\[L = \\sum_{d \\in D} \\sum_{w \\in d} f(d, w) \\log P(d, w),\\]\nwhere \\(f(d, w)\\) is the frequency of word w in document d. The EM process alternates between 1) the E-step, estimating the probability \\(P(z|w, d)\\) as:\n\\[P(z|w, d) = \\frac{P(w/z)P(z|d)}{\\sum_{z'} P(w/z')P(z'|d)},\\]\nand 2) the M-step, recalculating \\(P(w|z)\\) and \\(P(z|d)\\) to maximize L:\n\\[P(w/z) = \\frac{\\sum_{d} f(d, w)P(z|w, d)}{\\sum_{z'} \\sum_{d} f(d,w')P(z|w', d)}.\\]"}, {"title": "4.2 Fine-grained Job Preference Extraction", "content": "Short-term interactions at a session level always encompass issues of user preference drift and noisy interactions, with each influencing the other. To tackle the dual challenges above, the fine-grained job preference extraction module utilizes a novel adaptive hypergraph wavelet learning method in a unified approach.\nInitially, employing a standard graph structure to map user-job interactions often results in a proliferation of isolated vertices and edges, adversely impacting the efficacy of graph learning-based job preference extraction. In response, this paper introduces a hypergraph structure, denoted as \\(G_{C_u} = (V_{C_u}, E_{C_u})\\), which utilizes two specialized types of hyperedges to enhance the data with additional insights. The hypergraph for each user group \\(C_u\\) encompasses n job group nodes, alongside corresponding features (graph signals) \\(X_u\\). The hyperedge, defined as \\(e = \\text{link}(v_a, v_b, ...) \\in E^*\\), constitutes a subset of the vertex set \\(V\\), capturing complex, high-order relationships within the graph. For illustration, consider two sessions: \\(s_{C_u} = \\{v_1, v_2, v_3, v_4\\}, s'_u = \\{v_5, v_2, v_6, v_7, v_2, v_8\\}\\). The introduction of two distinct hyperedge types significantly augments the data connectivity within the user-job graph, as depicted in Figure 3.\nSession Hyperedges \\(E^s\\). The intra-session relationship is demonstrated as one of the critical factors to session-based recommendation [11]. For each user group, we link all jobs in each session to enhance the connectivity of these jobs. As for the job \\(v_2\\) in Figure 3(a), we connect the session jobs \\(\\{v_1, v_3, v_4\\}\\) and \\(\\{v_5, v_6, v_7, v_8\\}\\) that include it with a hyperedge, respectively. It reveals the high-order correlation of jobs facilitating the interaction on \\(v_2\\).\nTransition Hyperedges \\(E^v\\). Since the first type of hyperedges cannot model the chronological order of user-job interactions, we utilize job transition hyperedges to address this issue. For example, we connect the outcoming jobs \\(\\{v_3, v_6, v_8\\}\\) for job \\(v_2\\) as a hyperedge in Figure 3(b), which also implies the inter-session relationship"}, {"title": "4.3 Personalized Top-k Job Recommendation", "content": "Adapting job recommendations to reflect the job preference of the current user is the final key challenge faced by job recommendation systems, which could directly affect the recommendation"}, {"title": "5 EXPERIMENTS", "content": "In this section, we first describe the datasets used in this paper. Then, we introduce the experimental settings and compare BISTRO with representative baselines. We further present some case studies on job recommendations (Appendix C.3). The experiments are mainly designed to answer the research questions as follows:\n\u2022 RQ1: Can our BISTRO recommend suitable jobs for users?\n\u2022 RQ2: Does the clustering module effectively accommodate new jobs or users who have just revised their resumes?\n\u2022 RQ3: How does the specially designed hypergraph wavelet learning method deal with preference drift and noise issues?\n\u2022 RQ4: How do different settings influence the model performance?"}, {"title": "5.1 Dataset", "content": "The datasets come from the real-world online recruitment markets of multiple cities (Shenzhen, Shanghai, and Beijing). We utilize the user-job interaction (browse, click, chat, and so on) logs, user resumes, and job requirements data on this platform from July 1, 2023 to January 31, 2024 (215 days in total). To protect the privacy of users and platform operators, all sensitive information related to users is hashed or removed, and we only keep those data in the information technology industry. The detailed statistical information of our datasets is summarized in Table 1."}, {"title": "5.2 Experimental Settings", "content": "Baselines We compare BISTRO with baselines from different types of recommendation methods, including conventional methods: BasicMF [20], ItemKNN [46], PureSVD [7], and SLIM [34], DAE [53], MultVAE [25], EASE [41]; Graph neural networks-based methods: SLRec [59] and SGL [51], P3a [6], RP3b [36], NGCF [48], LightGCN [10], GCCF [5], NCL [28], DirectAU [44], HG-GNN [35], A-PGNN [61], AdaGCL [18], and MvDGAE [64]; Sequential recommendation methods: STAMP [31], GRU4Rec [11], BERT4Rec [42], CL4Rec [55], CoScRec [32], and TiCoSeRec [9]. More details about these baselines are shown in Appendix C.1. For ablation studies, we compare the variants of BISTRO to verify the effectiveness of each component.\nEvaluation metrics In this paper, two metrics commonly used in recommendation algorithms are used as evaluation metrics: hit ratio and mean reciprocal rank, and the definitions of these metrics are demonstrated as follows:\n\u2022 Hit Ratio (HR): It measures the proportion of successful recommended jobs out of all the recommendations made. Later, we use H@k to denote the value of HR when the model makes top-k recommendations.\n\u2022 Mean Reciprocal Rank (MRR): It is a statistical measure that focuses explicitly on the rank of the first relevant item in the list of recommendations to show the effectiveness of a recommendation method, and in this paper we use the symbol M@k to present this metric for simplicity.\nImplementation Details We experiment with a Spark cluster for preprocessing the data and A800 GPU servers to train and infer the proposed model. It has three parts: coarse-grained semantic clustering, fine-grained job preference extraction, and personalized top-k job recommendation. 1) Coarse-grained semantic clustering: we set the ratio of the number of groups to the number of users to about 1:1000 and the ratio of the number of groups to the number of job numbers to about 1:500. User professional skills and their inherent characteristics, such as work experience, are used as user clustering characteristics. Similarly, we extract job requirements as clustering features for jobs. 2) Fine-grained job preference extraction: the sparse matrix is used to represent the structure of hypergraphs efficiently. In addition, the order of Chebyshev approximation is p = 3, the total degree of interpolants is n = 50, and the number of hypergraph convolutional layers is L = 1. We set the number of hidden dimensions of this network to d\u2081 = 128. 4) Personalized top-k job recommendation: the number of hidden dimensions of the recurrent neural network is set to be the same as the one in hypergraph convolutional layers: drnn = 128. We set k = 10 for baseline experiments, and more experimental results under different settings of k can be found in Appendix C.2. As for each dataset, we split the training and validation data at a ratio"}, {"title": "5.3 Overall Performance (RQ1)", "content": "The performance of all the baselines in three datasets is shown in Table 2, in terms of the two metrics, i.e., H@10 and M@10. The performance of all methods is the average of the last 100 epochs in a total of 1000 epochs. It can be observed:\n\u2022 We can see that most conventional methods have poor performance, i.e., BasicMF, ItemKNN, SLIM, DAE, and EASE. SLIM deploys only a linear function to model user-job interactions, which limits the ability to generalize the model. BasicMF, ItemKNN, DAE, and EASE cannot provide fine-grained modeling for user/job features. PureSVD and MultVAE offer significant enhancements in performance over other techniques, yet they require extensive computational resources. Despite their advantages, they fall short of accurately capturing the dynamics of drifted interactions.\n\u2022 Compared to GNN-based methods, BISTRO allows for the extraction of fine-grained user representations from user resumes and their use in preference analysis. Among these baselines, MvDGAE achieves the best performance. This is because it also uses noise reduction representation learning based on multiview graphs. However, it lacks content modeling of user resumes and job requirements, resulting in lower results than our framework.\n\u2022 Sequential models can effectively learn the relationship among user-job interactions over time, but such interactions can easily be negatively impacted by spontaneous user preference drift, which would be directly reflected in interaction records. Thus, the sequence-only models do not apply to the job recommendation scenario, and their performance is justifiably worse than that of our framework.\nFurthermore, we extended our evaluation by deploying our model from the offline experiments to an online recruitment platform for a half-week online experiment, as shown in Table 3. In online experiments, the performance is measured on a daily basis, and we randomly select a unique 1% of active users and push the results for each model directly at the re-rank stage. It demonstrates our proposed method's superior performance and exceptional robustness compared to other baseline models."}, {"title": "5.4 Ablation Study (RQ2, RQ3)", "content": "The influence of clustering As mentioned previously, the clustering module can effectively achieve semantic matching at a coarse-grained level. Therefore, we partition the dataset into four subsets that do not overlap each other to train the model to achieve the following four tasks: 1) existing jobs for existing users, 2) existing jobs for users who have just revised resumes, 3) new jobs for existing users, and 4) new jobs for users who have just revised resumes. The comparison results are shown in Table 4."}, {"title": "5.5 Parametric Study (RQ4)", "content": "The size of user (job) groups The size of user and job groups are two hyperparameters that need to be predefined. Therefore, we choose 500:1, 1000:1, and 2000:1 as the ratios of the total number of users and the number of user groups \\(\\xi_u\\), and 100:1, 500:1, 1000:1 as the ratios of the total number of jobs and the number of job groups \\(\\xi_j\\) for our experiments respectively, as shown in Figure 6(a) and 6(b). We can easily observe that our model achieves best when \\(\\xi_u\\) =1000:1 and \\(\\xi_j\\) =500:1."}, {"title": "6 CONCLUSION", "content": "This study introduces BISTRO, an innovative framework designed to navigate the challenges of job preference drift and the subsequent data noise. The framework is structured around three modules: a coarse-grained semantic clustering module, a fine-grained job preference extraction module, and a personalized top-k job recommendation module. Specifically, a hypergraph is constructed to deal with the preference drift issue and a novel hypergraph wavelet learning method is proposed to filter the noise in interactions when extracting job preferences. The effectiveness and clarity of BISTRO are validated through experiments conducted with both offline and online environments. Looking ahead, we aim to continue refining BISTRO to enhance its applicability in broader contexts, particularly in scenarios characterized by anomalous data."}]}