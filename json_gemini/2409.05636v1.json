{"title": "3D-SAR Tomography and Machine Learning for\nHigh-Resolution Tree Height Estimation", "authors": ["Grace Colverd", "Jumpei Takami", "Laura Schade", "Karol Bot", "Joseph A. Gallego-Mejia"], "abstract": "Accurately estimating forest biomass is crucial for global carbon cycle modelling\nand climate change mitigation. Tree height, a key factor in biomass calculations,\ncan be measured using Synthetic Aperture Radar (SAR) technology. This study\napplies machine learning to extract forest height data from two SAR products:\nSingle Look Complex (SLC) images and tomographic cubes, in preparation for\nthe ESA Biomass Satellite mission. We use the TomoSense dataset, containing\nSAR and LiDAR data from Germany's Eifel National Park, to develop and evaluate\nheight estimation models. Our approach includes classical methods, deep learning\nwith a 3D U-Net, and Bayesian-optimized techniques. By testing various SAR\nfrequencies and polarimetries, we establish a baseline for future height and biomass\nmodelling. Best-performing models predict forest height to be within 2.82m mean\nabsolute error for canopies around 30m, advancing our ability to measure global\ncarbon stocks and support climate action.", "sections": [{"title": "Introduction and Methodology", "content": "We present work modelling forest height from three-dimensional tomographic SAR (TomoSAR) data,\ndeveloping a robust method for estimating tree heights. The primary objective of this research is to\nextend our understanding of the benefits of tomography (multiple image acquisition) within SAR\nresearch, given the incoming launch of a tomographic SAR satellite (Biomass Satellite mission ESA\n[1]). TomoSAR captures three-dimensional representations of forest structures, requiring multiple\nSLC images captured from different incidence angles and applied geometric processing including\nperforming a Fourier transformation to create a three-dimensional representation (Ferro-Famil [2]).\nThis results in a volumetric scattering distribution that provides detailed information about the vertical\nstructure of the forest, beyond traditional SLC images. TomoSAR datasets are inherently designed\nfor tomographic applications, significantly reducing preprocessing time and complexity, and enabling\nmore immediate and detailed forest structure analysis. We first present details of our models and the\ndifferent experiments. We provide further background information and discussion of related works in\nAppendix A.1."}, {"title": "1.1 Tabular models", "content": "Our classical machine learning pipeline uses a (1m x 1m x height) patch as the feature, with LiDAR\npoint clouds as the ground truth. We test three spatial splitting methods for data to quantify how\nthese can impact the model performance. The three methods (swath, square, and quadrant) are shown\nin Figure 1. Ratios of training/testing data are 80/20 for square/swathe and 75/25 for quadrant. We\nflatten the 3D TomoSAR intensity data, converting the cube into tabular data with a separate feature\nfor each height slice, i.e. for a given band B and polarization p, x, y, z \u2192 X, Y, Z1, \u2026, Zn where\nn = len(z). We match the input features with the LiDAR ground truth using a merge on (x, y).\nThe 1-pixel architecture enables us to use a simple model where each pixel is treated independently\nand benefits from needing less training data than deep learning approaches. We test including or\nexcluding the azimuth and range coordinates (x,y) as model inputs\nFor the tabular data we employed AutoGluon (Erickson et al. [5]), an AutoML tool, to streamline the\nprocess of evaluating and selecting the best machine-learning models for tree height estimation for\ntabular data. AutoGluon simplifies the machine-learning pipeline by automatically tuning hyperpa-\nrameters, selecting features, and optimizing models for well structured tabular data. AutoGluon uses\nbayesian optimisation to improve hyperparameter search, and automatically selects validation data.\nWe held out test data until final model selection."}, {"title": "1.2 CNN models", "content": "Our deep learning pipeline processes the TomoSAR data in its native 3D form and uses a 3D\nconvolution neural network architecture. We test three different model architectures adapted for three-"}, {"title": "2 Results and Discussion", "content": ""}, {"title": "2.1 Geo-Split Comparisons", "content": "The test MAE results for the P-band models is given in Table 1. Including the azimuth and range\ncoordinates (XY) as inputs in the tabular models reduced the MAE across all tabular models, by\nan average 15%, 29% and 49% across polarisations respectively for square, swath and quadrant\ngeo-splits, emphasizing the risks of spatial autocorrelation. The increasing impact of geo-location\ninclusion correlates with the degree of integration between test and training data (refer back to 1).\nThe difference in performance across the different geographic splits is notable, particularly for square\nand swathe vs. quadrant. A 47% drop reduction in quadrant MAE to the average of square and\nswath MAE to quadrant MAE, and an average change of 35% change when comparing the relative\nperformance of each of square/swathe/quadrant. The quadrant tabular models overfit the training\ndata and struggle to generalise to the unseen quadrant, even within a relatively homogeneous patch\nof forest. These findings highlight the critical nature of test data selection and cross-validation in\ngeospatial modelling, with the potential for a 35% performance swing based solely on test data\nlocation choices.\nHowever, it is prudent to interpret these results cautiously. The performance differences across splits\nmay be artificially inflated due to the small dataset size ((321, 665) pixels), potentially exaggerating\nthe impact of spatial dependencies. These observations underscore the need for rigorous validation\nstrategies in geospatial machine learning, particularly when working with limited datasets. Future\nwork should explore the stability of these findings with larger, more diverse TomoSAR datasets.\nThe superior performance of the CNN model even with less training data suggests that architectures\ncapable of capturing spatial relationships implicitly may offer more robust solutions for this type of\ngeospatial prediction task, and subsequent results all use this pipeline."}, {"title": "2.2 Height Estimation", "content": "The height prediction results for the union of all polarisation channels are given in Table 2. Due to the\ndifferent vertical resolutions of the bands, we also report Test MAE normalised by the relative vertical"}, {"title": "3 Conclusions", "content": "Our study revealed several significant findings. We quantified the impact on model performance of\nchoice of geographic test selection, with an average effect of 35% on MAE for classical models. This\nserves as a reminder of the potential for metric manipulation and we suggest the need for robust\nand transparent data selection procedures, and the use of cross-validation. Geocoding model inputs\naccounted for an average improvement in performance of 31% for classical models. The relative\nperformance of the square geo-split in classical modelling suggests the benefit to smaller localised\npaches of ground truth for improving model performance."}, {"title": "A Appendix", "content": ""}, {"title": "A.1 Scope of the work", "content": "Tree height estimation is a critical component of forest management, serving as a key indicator\nof forest structure, biomass, and overall ecosystem health. Precise tree height data enables forest\nmanagers to make informed decisions about timber yield, carbon sequestration potential, and habitat\nsuitability for various species, among other applications. Traditional methods, such as manual\nmeasurements and LiDAR surveys, while accurate, often face limitations in cost, time efficiency, and\naccessibility. The increasing demand for up-to-date and large-scale forest inventory data necessitates\nmore efficient and scalable solutions. Synthetic Aperture Radar (SAR) technology has emerged as a\npromising alternative, offering the ability to penetrate cloud cover and operate in various weather\nconditions, making it particularly suitable for monitoring forests in regions with frequent cloud cover,\nlike Northern Europe.\nTomographic SAR (TomoSAR) advances these capabilities by capturing three-dimensional repre-\nsentations of forest structures. TomoSAR requires multiple SLC images captured from different\nincidence angles and applied geometric processing including performing a Fourier transformation\nto create a three-dimensional representation. This results in a volumetric scattering distribution\nthat provides detailed information about the vertical structure of the forest, beyond traditional SLC\nimages."}, {"title": "A.2 Related work", "content": "Estimating tree height using physical models, which often rely on allometric relationships between\ntree diameter and height, is essential for accurate biomass estimation and ecological modeling (Phalla\net al. [8]). These models, such as the height-diameter relationship model, typically use parameters\nlike diameter at breast height (DBH) to predict tree height (Kershaw et al. [9] De Petris et al. [10]).\nHowever, several roadblocks hinder the effectiveness of purely physical models. Data collection\nchallenges arise in dense forests, particularly tropical ones, where closed canopies and the time and\ncost of obtaining accurate measurements can lead to tree height being overlooked, increasing bias\nin biomass estimations. Additionally, these models may not adequately account for environmental\nand spatial variability, which significantly affects tree growth patterns. Traditional methods, like\nclinometers or hypsometers, introduce measurement errors due to reliance on angle and distance\nmeasurements, especially in uneven terrain or when the tree top is obscured (Kershaw et al. [9]).\nFurthermore, while remote sensing technologies like LiDAR provide detailed canopy height models,\nthey often measure the apex rather than the prevailing dendrometric height, leading to discrepancies in\nactual tree height measurements. These limitations underscore the need for integrating other methods,\nsuch as remote sensing and statistical models, to improve the accuracy of tree height estimation\n(Kearsley et al. [11]).\nSatellite and aerial data have become essential tools for estimating tree height in conjunction with\nmachine learning, offering several advantages over traditional ground-based methods. Techniques\nsuch as LiDAR, SAR, and optical imagery are commonly used to derive tree height information\n(Tolan et al. [12]). LiDAR provides high-resolution data by measuring the time it takes for laser\npulses to return after hitting the canopy, resulting in accurate digital surface models (DSMs) and\ndigital terrain models (DTMs) (Ganz et al. [13], Lee and Lee [14]).\nRemote sensing methods are advantageous due to their ability to cover large areas quickly and cost-\neffectively, and they can be enhanced by integrating data from multiple platforms to improve accuracy\nLee and Lee [14], Xuan et al. [15]. However, challenges remain, such as the need for high-quality\ncalibration data and the potential for errors in complex terrains or dense canopies, which can affect\nthe precision of height estimations (Ganz et al. [13], Lee and Lee [14]). Despite these challenges,\nadvancements in remote sensing technologies continue to improve the reliability and resolution of\ntree height data, making it a valuable resource for ecological research and forest management.\nCommons machine learning methods for predicting tree height include random forests (Wang and Lu\n[16]), Gradient Boosting Decision Trees (GBDT) and Support Vector Machines (SVM) have been\nexplored for forest height estimation, with GBDT showing higher precision in certain scenarios (Bao\net al. [17]) and deep Convolutional Neural Networks (CNNS) (Puliti et al. [18]). These machine-"}, {"title": "A.3 Experiment details", "content": "In this study, the data is split geographically into training, testing, and validation sets to ensure\nthat the models generalize well to unseen areas. This approach minimizes the likelihood of spatial\nautocorrelation, which could lead to overly optimistic results if data from similar regions are used\nacross these splits. The geographic split involves segmenting the intensity image and the canopy\nheight map into different regions such as swaths, squares, and quadrants, which are then processed\nindependently."}, {"title": "A.3.1 Data", "content": "The TomoSense SAR bands and frequencies are given in Table 3.\nThe frequencies within the SAR bands refer to the orientation of the electromagnetic waves transmitted\nand receive by the emitting device. HH (Horizontal-Horizontal): Both transmitted and received waves\nare horizontally polarized. HV (Horizontal-Vertical): Transmitted wave is horizontal, but received\nwave is vertical. VV (Vertical-Vertical): Both transmitted and received waves are vertically polarized.\nThis is particularly sensitive to vertical structures and can penetrate vegetation canopies better than\nHH."}, {"title": "A.3.2 CNN architecture", "content": "Details of the three models tested are given in Table 4. The diagram for the architecture of the two\nsuccessful models is given in Figure 5."}, {"title": "A.3.3 Training software and hardware", "content": "All models are coded in PyTorch. We test different architecture configurations using the parameters\nmentioned (model backbone, collapse method, patch size, polarization) for each band as well as\ntraditional hyperparameter tuning on batch size (BS), number of epochs and learning rate (LR). Early\nstopping based on validation MAE was implemented. Sweeps are run using WandB, with Bayesian\nsearch. All models are trained using MSE as the loss function, with ADAM optimiser. Models are\ntrained on Google Cloud using a Tesla GPU T4 with 16gb memory. Due to the small size of the\ndataset, training was quick on the order of 5-30 minutes and we ran extensive hyperparameter sweeps,\nwith at least 300 runs for each band/polarisation option."}]}