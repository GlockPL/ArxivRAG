{"title": "Al-in-the-loop: The future of biomedical visual analytics applications in the era of Al", "authors": ["Katja B\u00fchler", "Thomas H\u00f6llt", "Thomas Schultz", "Pere-Pau V\u00e1zquez"], "abstract": "Al is the workhorse of modern data analytics and omnipresent across many sectors. Large Language Models and multi-modal foundation models are today capable of generating code, charts, visualizations, etc. How will these massive developments of Al in data analytics shape future data visualizations and visual analytics workflows? What is the potential of Al to reshape methodology and design of future visual analytics applications? What will be our role as visualization researchers in the future? What are opportunities, open challenges and threats in the context of an increasingly powerful Al? This Visualization Viewpoint discusses these questions in the special context of biomedical data analytics as an example of a domain in which critical decisions are taken based on complex and sensitive data, with high requirements on transparency, efficiency, and reliability. We map recent trends and developments in Al on the elements of interactive visualization and visual analytics workflows and highlight the potential of Al to transform biomedical visualization as a research field. Given that agency and responsibility have to remain with human experts, we argue that it is helpful to keep the focus on human-centered workflows, and to use visual analytics as a tool for integrating \u201cAl-in-the-loop\u201d. This is in contrast to the more traditional term \u201chuman-in-the-loop\u201d, which focuses on incorporating human expertise into Al-based systems.", "sections": [{"title": "Visual Analytics Workflows: present and future", "content": "We focus on the potential effects of Al, and particularly,\nDL and generative systems in the workflow of the\ndevelopment of Visual Analytics tools. The different\nsteps of such workflows are depicted in Figure 1. They\ninclude the data acquisition and processing, together\nwith the elements that transform such data into visual\nanalytics tools. Overly simplified, these consist of the\ncreation of the different visualization components, the\nconfiguration of such components, and the creation of\nthe final Visual Analytics interactive tool.\nFrom those steps, only the first one, data acquisi-\ntion and processing, has already been established as\na stage where Machine Learning (ML) and DL tech-\nniques play a crucial role. Tasks such as noise removal,\nimage segmentation, feature extraction, to name a few,\nare commonly designed with the help of these tools\nincluding related methods to enhance transparency\nand explainability of machine made decisions to end\nusers. The remaining components of the pipeline are\nalso undergoing alterations under the influence of Al,\nalthough these are still largely superficial in nature.\nCurrently, the emergence of LLMs is changing com-\npletely the way we develop software. As a result, we\nenvision a future VA tool development pipeline that\nwill be enhanced by generative Al. Those technologies\nwill assist the visualization developer in many of such\nsteps. Not only the design and development will be\ncarried out in collaboration with Al tools, but it will\nalso influence the way how users will interact with\nthese tools, for example, by enabling natural language\ncommands or supporting analytical workflows through\nintent predictions."}, {"title": "The future of VA workflows", "content": "While the idea of automating the creation of visu-\nalizations is not new, most previous systems were\nconstrained to rigid rules, and had limited capabilities.\nOnly recently, with the advent of more advanced nat-\nural language technologies and generative models, a\ngreater flexibility has been gained, and this creation\nprocess is getting closer to a conversational and intu-\nitive procedure where an Al assistant helps in gener-\nating code and solving problems and doubts. On the\nother hand, there are plenty of examples of language-\npowered queries to extract information from data. What\nis new in this area, is the extraction of higher level\ninsights, opposed to concrete queries (e.g., what is the\nmaximum value of a certain variable) directly from the\ndata or the visualization itself. Therefore, tasks such\nas storytelling, or labelling visualizations are becoming\nfeasible. Our vision is illustrated in Figure 2.\nWe classify the contribution of Al into three different\ncategories, that differ a lot in their nature, but that can\nbe supported in different manners by Al and generative\nsystems, as shown in Figure 2: (1) data acquisition\nand processing, (2) components that can aid in the\nVA tool creation, and (3) the components devoted to\nassisting interaction with such a tool.\nThe first category includes a set of well-known and\nestablished ML methods that are continuously devel-\noping to tackle new datasets modalities and increased\naccuracy. We call those tasks Data2Data\nRegarding VA tool creation, tasks include:\n\u2022\nData2Code: Generation of code for visualiza-\ntion components.\n\u2022\nData2Image: Extraction of visual depictions\nfrom the data.\n\u2022\nData2Viscomponent: Besides individual charts\nor images, other elements such as filters,\nmenus, etc., need to be defined to create a\nVA tool. These basic components could also be\ncreated by generative models, since they do not\ndiffer much from other code required to build\ncharts.\n\u2022\nTask2VisConfig: All the components in a VA\ntool require configuration. These include chang-\ning size, colors, palettes, etc.\n\u2022\nViscomponent2Tool: The creation of a VA tool\ninvolves linking many visualization components,\nand laying them out in a dashboard.\nAll tool creation tasks have in common that they are not\nmere transformations of input data. On the contrary,\nthey require generative capabilities. Even though some\napplications such as Lida [6] can already generate\npieces of code to visualize simple datasets, they are\nrestricted to very basic charts. Thus, they do not\ngeneralize to the complex input medical or biological\npipelines require. As LLMs evolve and specialize, direct\ngeneration of custom visualization code adapted to the\ncurrent dataset will be feasible. These code snippets\nrely on the use of visualization libraries to handle the\nfinal visualization.\nData2Image is a more sophisticated version of\nData2Code. In this case, the Al component will be\nable to transform data directly into an image. When\ntransforming data into visualization code, no care is\ntaken on the final aspect of the visualization. The\nconfiguration of the visual variables is commonly left\nto the library itself, which often has default parameters\nthat work for a wide range of situations. Selection and\nfine-tuning of the aesthetics of the final visualization is\na task that is currently only done by humans, but could\nbe taken over by large complex systems if enough data\n(and maybe guidelines) to train them were available.\nEach visualization component needs to be adapted\nto the VA tool: from modifying its size to changing\npalettes, many aspects can be fine-tuned. Currently,\nthis is carried out by the designers, but, like in previous\ncases, in the future they may end up being tasks that\ncan be triggered by the designers, and performed by\nAl-supported tools.\nLike in the previous case, we believe that the pro-\ncess of creating a tool by mixing and linking different\nvisualization components (Viscomponent2Tool) will\nbe achievable in the near future with the support of\ngenerative systems.\nConcerning interaction, we anticipate that the\npipeline will benefit from the advances in Natural Lan-\nguage Processing, notably LLMs. Furthermore, they\nwill also integrate other DL techniques to include both\nmore classical tasks, such as querying directly the\ndata, and more high-level procedures such as Al guid-\nance for the interaction with the visualizations using\nnatural language. These tasks consist of:\n\u2022 Task2Query: Execution of queries about data\n(e.g., find values) or visualization insights (e.g.,\ndetermine insights, correlations, etc.) using nat-\nural language. Here, Al techniques will improve\n\u2022 Task2Interact: Interaction with the tool using\nnatural language, such as for filtering, selection,\nor getting values. Again, Al can help either by\nfacilitating the interaction (e.g., predicting the\nusers' movements) or by hinting at potential\ntasks of interest."}, {"title": "Challenges in Biomedical Data Analytics", "content": "Independent from any Visual Analytics applications,\ndeep learning is already an established method in\nbiomedical informatics. Applications range from small\nsub-tasks like image registration, data filtering or data\nclassification tasks up to powerful models providing\nfor example medical doctors with end-to-end diagnos-\ntics or life scientists with fully automated pipelines\nfor protein discovery [4]. But even if the visions of\na super-human generalist Al like described by Mor-\nris et al. [3] or generalist medical Al by Moor et\nal. [8] seem to indicate at first sight that interactive\ndata exploration and analytics with Visual Analytics is\nbecoming obsolete and data-driven decision-making\nmight be fully automatized in its extreme case, this\ncan be questioned due to several reasons. (1) Data\nin the biomedical field are highly dynamic as\ndata acquisition is, especially in the life sciences,\nundergoing constant technical evolution and inno-\nvation. Novel imaging technologies are for instance\ndeveloped not only in terms of increased scales, imag-\ning quality and speed, but also e.g., in terms of novel\nmarkers highlighting specific biological function at the\nmolecular level or technology capturing transcriptomics\nand metabolomics in spatial samples. This dynamic\nis making data analytics very demanding, as com-\npletely novel types of before potentially impossible\nobservations exhibiting novel features would have to\nbe handled reliably by an AGI (or lower-level existing\nAl solutions). (2) Data in the biomedical field often\nlacks standardization, missing or uncertain data is\ncommon. Thus, automated processing based on orig-\ninal raw data becomes challenging, requiring expert\nand potentially also insider knowledge not previously\nexposed to any AGI. (3) Data complexity and di-\nmensionality is constantly increasing and together\nwith it the complexity of questions to the data\nand related analytical tasks. Beyond standardized\ndiagnostic tasks, this is a highly dynamic field driven\nby the dynamics in data acquisition technologies (see\n(1)) and (4) Entirely new situations may arise where\nwe are confronted with unprecedented data, such\nas during the Covid 19 pandemic.\nCoping with these challenges autonomously re-\nquires a broad set of highly specialized \u201cemerging\"\u00b9\nskills that will hardly be reached by any AGI in the\nnear future. Furthermore, by definition the idea of a\ngeneralist Al pushes humans into a more passive role\nin which the Al delivers the results, which the human\nfinally only approves or rejects. Such an end-to-end\nscenario could easily fail in complex data environments\nas described above, in which the learnt skills of an\nAGI are not necessarily sufficient to arrive at reliable\nresults. It also contradicts the concept of human cen-\ntered Al being a central element of current ethical and\nregulatory frameworks (see section below).\nThe combination of Al-driven data analysis with\nvisual analytics as an interface between the user and\nthe Al establishes a different concept of cooperation\nbetween humans and Al. It comes with the oppor-\ntunity to create an environment that can react more\nflexibly to dynamic, complex data environments and\ntasks and supports users in drawing their data-based\nconclusions as discussed above, by bringing the Al-\nin-the-loop. Therefore, we envision the emergence of\nAl companions that can create end-to-end VA tools\nbased on simple prompts. However, just like for the\nuse of Al, the biomedical domain poses significant\nchallenges for the the development of such Al-in-the-\nloop VA tools. Extending on the challenges laid out\nabove, we observe that (5) VA researchers frequently\nencounter a scarcity of biomedical training data,\nwhich presents a significant challenge in devel-\noping unbiased and stable Al systems. The high\nvariability, complexity and volatility of data (see (1), (2),\nand (3)), as well as complete lack of data e.g. in case\nof rare or new diseases (4) requires the modification of\nboth, data processing algorithms and the inclusion of\nnew analyses and interpretations into an VA system.\nHowever, data covering this knowledge is not or only\nsparsely available to (re-)train any assistive systems.\n(6) There is only a limited availability of VA code for\ntraining or tuning Al models. The majority of VA tools\nare proprietary, and their code private. Therefore, it\ncannot be used to train new Al systems. This limits the\npotential of generative tools to build specific biomedical\nVA applications. (7) Complex interactions with com-\nplex biological or medical models in exploratory\nanalysis tools are difficult to mimic. Biomedical\nexperts are highly specialized, and the interactions\nare data-specific and highly variable between experts.\nAs such, user behavior is difficult to train and predict\nand generated interactions are hard to validate. This\nbecomes even more challenging when designing for\ninclusivity to support heterogeneous user groups,\nfrom bioinformaticians and medical experts to non-\nspecialized medical personnel. (8) In compliance with\nthe diverse legal frameworks on the use of Al,\nhigh-risk systems must be transparent and should\nnot replace human sovereignty over a decision.\nMoreover, these decisions should be explainable. This\nneeds to be considered through the whole VA system\ndesign ensuring that every Al-generated subtask that is\nsubstituting human actions must be law-compliant, re-\nliable, and the underlying reasoning can be monitored\nand validated.\""}, {"title": "Dangers, Ethical, and Legal Considerations", "content": "The tight integration of Al into visual data analysis\npipelines and applications for biomedical purposes in\nprofessional environments requires careful considera-\ntion of ethical and safety issues. Moreover, the use of\nAl technologies is not free from dangers [9]. Errors,\nmistakes, or inaccuracies in the development and use\nof Al could have serious implications for the quality and\nreliability of results, with potential legal and/or financial\nconsequences, e.g., if a patient is misclassified for a\ndisease or if inaccurate or incorrect predictions slow\ndown the process of discovering new drugs. However,\nthe black box nature and unreliability of powerful LLMs\nand multi-modal foundation models trained on massive\nsets of data, often lack the necessary detail in model\nand data documentation [9], making it difficult to ensure\nthe implementation of high ethical and safety standards\nin downstream applications.\nRecently, several policy papers and resolutions\nhave been published worldwide to provide a regula-\ntory and ethical framework for the use of Al such as\nthe UNESCO Ethics of Al, the OECD Principles for\ntrustworthy Al which are partially reflected in national\nregulatory frameworks like the US Executive Order\non the Safe, Secure, and Trustworthy Development\nand Use of Artificial Intelligence, the Chinese Inter-\nnet Information Service Algorithmic Recommendation\nManagement Provisions, or the EU AI Act. A worldwide\noverview on Al legislation which is regularly updated\nis provided e.g. by The International Association of\nPrivacy Professionals (IAPP).\nOne of the key statements in most declarations is\nthe need for human oversight and fairness. While the\nuse of Al in research is often not as strictly regulated,\nvisualization researchers should be aware of these\nframeworks when designing Al-supported applications.\nConsidering reliability, legal and ethical issues through-\nout the project has the potential to increase adoption\nby domain experts and/or industry and to enhance the\nimpact of the research results. One framework is pro-\nvided by the Ethics by Design approach, which covers\nthe design, development, deployment, and use of Al-\nbased solutions. Ethics by Design considers the need\nfor human agency; privacy, personal data protection\nand data governance; fairness; individual, social and\nenvironmental well-being; transparency; accountability\nand oversight.\nResearch thrives on pushing the boundaries, but\nnot all what is technically possible might be finally\naccessible and usable. The knowledge on potential\nregulations of foundation models is a prerequisite to\ncreate sustainable and usable results. For instance\nMetas' llama3 model is currently (June 2024) not avail-\nable in Europe due to regulatory reasons 2."}, {"title": "The future role of visual analytics in biomedical applications", "content": "In the following discussion on the future of VA in\nbiomedical applications, we focus on scenarios with\ncomplex data and analytical tasks. Therefore, we skip\nsimple cases related to narrow, supportive Al for accel-\nerating non-critical tasks, like optimized data loading,\nfiltering, etc.\nThe quality of the result of a decision making pro-\ncess is the ultimate criterion for a performant human-\nAl teaming, in particular in critical environments like\nmedicine or life science research. Here, very much\nfollowing Keim et al. [5], agency has to fully remain with\na human expert, who takes responsibility for diagnostic\nand treatment decision-making in the medical domain,\nor for the scientific integrity of the overall reasoning and\nconclusions in a research context. Consequently, the\nhuman must have an opportunity to audit all algorith-\nmic results and decisions. During this process Visual\nAnalytics remains to play an inevitable role: It provides\ntools for comparative analysis (e.g., to explore the Al-\nbased classification results of a cancerous patient in\ncontext of multi-modal data of a related patient cohort),\nfor understanding why an Al-based assistant or second\nreader made a specific suggestion (e.g. by translating\npotential explanations of an Al into a more human\ninterpretable form by providing a visual representation\nof context), or for assessing uncertainty in algorithmic\nresults, in particular, when real-world datasets differ\nfrom those that the system was trained on (by visu-\nalizing domain shift or uncertainty of decisions)."}, {"title": "Conclusion -or- Do robots dream of Al-generated sheep?", "content": "We anticipate that the specific challenges of biomedi-\ncal applications, which include heterogeneity and lim-\nited availability of data and code examples for training,\nthe complexity and specialized nature of the required\ndomain knowledge, the complexity and dynamics of\nanalytical tasks, the permanent proliferation of new\nacquisition devices and data types, combined with\nhigh standards for reliability and trustworthiness, is still\nslowing down the practical adaptation of Al-based so-\nlutions compared to other domains with lower stakes,\nsuch as generating content for recreational purposes.\nHowever, we believe that, despite these challenges,\nAl will ultimately lead to profound transformations also\nin the biomedical domain, and we advocate shap-\ning these changes according to an \"Al-in-the-loop\"\nparadigm, in which visualization plays an important\nrole. In contrast to the frequently used term \"human-\nin-the-loop\", which considers humans as a source of\ninformation within an Al-based system, the term \"Al-in-\nthe-loop\" emphasizes that the ultimate focus, respon-\nsibility, and control should remain with human experts\nwho use Al-based systems to make faster or better\ninformed clinical decisions, or as a powerful new tool\nfor scientific research.\nAccording to recent estimates, even though the\nFood and Drug Administration has approved more\nthan 200 commercial radiology Al products, the cor-\nresponding U.S. market penetration is still only around\n2% [11]. We expect that our proposed \"Al-in-the-loop\"\napproach, which is centered on supporting specific\nbiomedical workflows by a suitable integration of vi-\nsualization and Al, will more effectively close this gap\nthan \"human-in-the-loop\" approaches, which are cen-\ntered on solving specific Al tasks by accounting for\nhuman feedback. While Al assistants should make im-\nplementation and prototyping of future visual analytics\nsystems substantially easier and more efficient, im-\nplementing the \"Al-in-the-loop\" approach still involves\nclassical stages of visualization design, such as data\nand task abstraction, that are unlikely to be fully au-\ntomated in the foreseeable future. Consequently, we\nexpect that, as long as it actively tracks progress in\nartificial intelligence, and makes use of the opportu-\nnities it presents to domain experts as well as tool\nbuilders in the spirit of the proposed \"Al-in-the-loop\"\napproach, biomedical visual analytics will continue to\nplay a central role in the future.\nThe inclusion of Al assistants in the development\nof VA tools will fundamentally change how we work\nas researchers. Code development implementing tra-\nditional, well-known procedures (reading models, cre-\nating Uls...) will be increasingly taken over by assistive\nsystems. But this only works for tasks that have been\npart of the training set of the generative models. Re-\nsearchers will still need to develop new algorithms that\ndeal with new tasks or new modalities of data, design\ninterfaces to deal with new kinds of information or im-\nplement new tasks, creation of new tools for overseeing\nthe performance of Al models, development of new\ntools for monitoring and validating the new VA software.\nHowever, the availability of public, labelled datasets of\nVA tools (or procedures) will be scarce due to multiple\nreasons, such as the proprietary nature of most of\nthe software, its complexity, etc. Therefore, creation of\nAl assistive software for Biomedical VA tools will be\nmuch slower as compared to other domains, such as\ngenerative systems for image creation.\nThe pipeline we have proposed in Figure 2 is plau-\nsible, and likely will be part of our work environments\nin a few years, as we move further to more and\nmore capable generative Als (Figure 3). However, the\npossibilities of generative tools go beyond that. And\nthe prospect of Al companions that help us in our work\nis very feasible. In the future, these will be pervasive,\nand the development of VA tools will be fundamentally\nchanged by them."}, {"title": "Research Opportunities", "content": "Analysis of cognitive and psychological needs\nand consequences of Al-in-the loop both on\nhuman users and the workflows.\nEnhancing and leveraging the \"expertise\" of\nmulti-modal Al models towards an artificial\nvisualization expert.\nIntegration of Visualization knowledge into Al\nmodels.\nBroadening the theory on coupling human\ncreativity and expert knowledge with Al ca-\npabilities."}, {"title": "Al for VA Tool Development", "content": "Low to no-code VA tool development, with a\nfocus on security, reliability, transparency, and\nethics.\nIntegration of different interaction modalities\nwith Al to build and support VA tools.\nCreation of VA tools from scarce data or code\nexamples (few-shot VA tool generation)."}, {"title": "Al Integration in the VA Workflow", "content": "Al-enhanced workflows, adapting to different\nuser profiles (skills, knowledge) and previous\nand current interaction with the system.\nShifting towards multi-modal interaction with\nthe Al (and the data) to jointly complete a\ndata-driven task.\nDesigning new Al-in-the-loop interfaces at all\nlevels.\nVisual Al-to-human communication methods\nthat provide sufficient explanations to support\naccurate and reliable decision making.\nQuality assessment of Al-in-the loop."}]}