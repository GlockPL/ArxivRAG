{"title": "PSM-SQL: Progressive Schema Learning with Multi-granularity Semantics for Text-to-SQL", "authors": ["Zhuopan Yang", "Yuanzhen Xie", "Ruichao Zhong", "Yunzhi Tan", "Enjie Liu", "Zhenguo Yang", "Mochi Gao", "Bo Hu", "Zang Li"], "abstract": "It is challenging to convert natural language (NL) questions into executable structured query language (SQL) queries for Text-to-SQL tasks due to the vast number of database schemas with redundancy, which interferes with semantic learning, and the domain shift between NL and SQL. In this paper, we propose a progressive schema linking with multi-granularity semantics (PSM-SQL) framework to reduce the redundant database schemas for Text-to-SQL. Using the multi-granularity schema linking (MSL) module, PSM-SQL learns the schema semantics at the column, table, and database levels. More specifically, a triplet loss is used at the column level to learn embeddings, while fine-tuning the LLM is employed at the database level for schema reasoning. MSL employs classifier and similarity scores to model interactions for schema linking at the table level. In particular, PSM-SQL adopts a chain loop strategy, sacrificing the upper limit of algorithm accuracy to reduce the task difficulty of schema linking by continuously decreasing the number of schemas. Experiments conducted on Text-to SQL datasets show the outperformance of the proposed PSM-SQL.", "sections": [{"title": "Introduction", "content": "Text-to-SQL (Qin et al., 2022; Deng et al., 2022; Gao et al., 2024; Pourreza and Rafiei, 2024) has attracted increasing attention in recent years, with the goal of covert natural language (NL) questions into executable structured query language (SQL) queries, thereby making it easier for users to access data in a relational database. However, the growing complexity database schemas (e.g., tables, columns, values, etc.) and domain gap between NL and SQL make it difficult to generate executable and accuracy SQL queries. By leveraging the powerful understanding and generation capabilities of large language models (LLMs), Text-to-SQL including schema linking and SQL generation tasks has made significant progress to address the problems.\nThe works on Text-to-SQL based on LLMs can be divided into two categories: prompting-based methods and fine-tuning-based methods. They often use domain-specific knowledge to construct prompts or fine-tune LLMs, enabling LLMs to learn the patterns for reasoning and generating SQL queries. For instance, C3 (Dong et al., 2023), DIN-SQL (Pourreza and Rafiei, 2023), MAC-SQL (Wang et al., 2024) decompose the Text-to-SQL into multiple sub-problems through chains of thought (CoT) (Wei et al., 2022). DAIL-SQL (Gao et al., 2024), DTS-SQL (Pourreza and Rafiei, 2024), CODES (Li et al., 2024) employ supervised fine-tuning strategy to fine-tune the open-source LLMs for Text-to-SQL. However, they focus on activating and enhancing the understanding and generation capability of LLMs for Text-to-SQL task, especially for SQL generation, while neglecting the optimizations of the task itself, such as schema linking. As shown in Fig. 1, our PSM-SQL pays attention on optimizing the task itself to continuously decrease the difficulty of Text-to-SQL. On one hand, PSM-SQL learns the semantics of"}, {"title": "", "content": "schemas at the table, column, and database levels to link related schemas for generation. On the other hand, PSM-SQL iteratively performs schema linking that is chained task, with the goal of maintaining a high lookup accuracy while allowing a high degree of redundancy, thereby continuously reducing the difficulty of Text-to-SQL.\nIn this paper, we propose PSM-SQL for Text-to-SQL by reducing the redundant database schemas. More specifically, PSM-SQL exploit MSL module to capture the semantics of schemas at multi-granularity levels. At column level, PSM-SQL uses triplet loss to fine-tune embedding models, which rewards the correct schemas while punishes the incorrect schemas. PSM-SQL fine-tunes the LLM to reason database schemas that are related to SQL generation at database level. At the table level, PSM-SQL designs classifier and similarity scores to model schema interactions in embedding space for schema linking. In particular, a chain loop strategy is applied to continuously decrease the difficulty of tasks by reducing redundant schemas.\nThe contributions of this work are summarized below:\n\u2022 We propose a progressive schema linking with multi-granularity semantics (PSM-SQL) framework for Text-to-SQL, which effectively reduce the redundant database schemas to enhance semantics learning of schemas and eliminate the domain shift between NL and SQL.\n\u2022 We devise a MSL module to learn multi-semantics of schemas at table, column, and database levels, and adopt a chain loop strategy to decrease the difficulty of schema linking continuously.\n\u2022 We conduct extensive experiments on Text-to-SQL datasets including Spider and Bird, manifesting the effectiveness of PSM-SQL against the state-of-the-art Text-to-SQL works.\nThe rest of the paper is organized as follows. Section 2 reviews the related works. Section 3 presents the details of the proposed PSM-SQL. Experiments are conducted in Section 4, followed by conclusions in Section 5."}, {"title": "Related Work", "content": "Text-to-SQL aims to convert natural language (NL) questions into executable structured query language (SQL) queries. In the early stage, Text-to-SQL employed encoder-decoder architectures to encode the question and database schema representations and decode the SQL queries. For example, RESDSQL (Li et al., 2023a) proposed a ranking-enhanced encoder to select the relevant schemas and a skeleton-aware decoder to implicitly guide the SQL parsing by the skeleton. SADGA (Cai et al., 2021) and LGESQL (Cao et al., 2021) introduced graph neural networks to learn the relationships between questions and database schemas. Graphix-T5 (Li et al., 2023b) designed specially-designed graph-aware layers to encode a mixture of semantic and structural information, boosting the capability of structural encoding of T5 while keeping the contextual encoding ability of the pretrained T5. However, they are suboptimal to generate SQL queries due to their limited generative capabilities caused by the small number of parameters in the model.\nRecently, researcher introduced large language models (LLMs) to understand database schemas and generate SQL queries for Text-to-SQL, which can be roughly grouped into two categories: prompting-based methods and fine-tuning-based methods. More specifically, prompting-based methods designed specific prompts with contextual learning to enhance the reasoning ability of LLMs in Text-to-SQL domain. DAIL-SQL (Gao et al., 2024) selected examples based on their skeleton similarities and removed cross domain knowledge from examples for token efficiency. DIN-SQL (Pourreza and Rafiei, 2023) broke down the generation problem into sub-problems and fed the solutions of those sub-problems as prompts into LLMs to generate SQL queries. MAC-SQL (Wang et al., 2024) employed a core decomposer agent for Text-to-SQL generation with few-shot chain-of-thought reasoning and adopt two auxiliary agents to refine erroneous SQL queries by utilizing external tools. TA-SQL (Qu et al., 2024) proposed Task Alignment (TA) strategy to mitigate hallucinations at each stage in Text-to-SQL, reducing the burden of SQL generation. Fine-tuning-based methods used data with domain-specific knowledge to fine-tune LLMs, encouraging LLMs to learn knowledge for Text-to-SQL. DTS-SQL (Pourreza and Rafiei, 2024) introduced a two-stage fine-tuning approach to decompose Text-to-SQL tasks into two simpler tasks for protecting data privacy, enabling small open-source models to rival larger ones. CODES (Li et al., 2024) proposed a comprehensive database prompt construction strategy and a bi-directional data augmentation method to fine-tune a series"}, {"title": "Problem Definition", "content": "In this section, we formalize the notations of Text-to-SQL, which aims to convert the NL questions to SQL queries. Without loss of generality, Text-to-SQL can be divided into two subtasks: schema linking and SQL generation.\nGiven the questions $Q = \\{q_i\\}_{i=1}^{n}$, evidence as external knowledge $K = \\{k_i\\}_{i=1}^{n}$, and the relational database $D = \\{(\\{t_j,c_j\\}_{j=1}^{|T|})\\}_{i=1}^{n}$, Text-to-SQL processes schema linking to predict the related schemas that are used for SQL generation from the original database as follows,\n$D_f = Filter(Q, K, D)$                                                (1)\nwhere $Filter(\\cdot)$ denotes the function of schema linking, $D_f$ denotes the filtered database that consists of the predicted schemas, n denotes the number of Text-to-SQL samples, $|T|$ represents the number of tables in the relational database, $|C_j|$ is the number of columns in the j-th table, $t_j$ and $c_j$ is the table name and column information in the j-th table respectively.\nFurthermore, Text-to-SQL generates the SQL queries S to answer the questions as follows,\n$S = Parse(Q, K, D_f)$                                             (2)\nwhere $Parse(\\cdot)$ denotes the function of SQL generation."}, {"title": "Methodology", "content": "Given the question with evidence and database schemas, we propose a progressive schema linking with multi-granularity semantics network (denoted as PSM-SQL) as shown in Fig. 2, which consists of a chain loop strategy and multi-granularity schema linking (MSL) module. PSM-SQL employes chain loop strategy to reducing the number of redundant schemas continuously and adopts MSL to learn the schema semantics at the column, table, and database levels. More specifically, a triplet loss is used to learn embeddings at the column level, while fine-tuned LLM is employed to reason the related schemas at the database level. At the table level, MSL adopts classifier and similarity loss to model schema interactions at the table level."}, {"title": "Schema Linking", "content": "Given the question $q \\in Q$, evidence as external knowledge $k \\in K$, and the relational database $d = \\{(\\{t_j,c_j\\}_{j=1}^{|T|})\\}_{i=1}^{n} \\in D$, multi-granularity schema linking (MSL) module learns the semantics of schemas at the column, table, and database levels for schema linking, capturing the multi-granularity patterns of schemas.\nColumn level. At the column level, we construct triples $(a, c^+, c^-)$, where $a = Cat(k, q)$ to fine tune a pre-trained embedding model (e.g., BGE-large-en (Xiao et al., 2024), etc.), ranking the scores for schemas to attain the filtered database $d_f$ that consist of the schemas which scores exceeding 0.5"}, {"title": "", "content": "as follows,\n$d_f = BGE(a, c^+, c^-)$                             (3)\nwhere $BGE(\\cdot)$ and $Cat(\\cdot)$ denote the BGE operation and the concatenation operation respectively, a is the anchor, $c^+ \\in d_{gt}$ and $c^- \\notin d_{gt}$ represent the schemas from the j-th table that are relevant and irrelevant to generating SQL queries, and $d_{gt} = \\{(\\{t_j,c_j\\}_{j=1}^{|T|})\\}_{i=1}^{n} \\in D_{gt}$ represents the ground-truth database schemas related to SQL generation.\nThe loss function at the column level can be denoted as follows,\n$L_c = max(\\phi(a, c^-) - \\phi(a, c^+) + \\beta, 0)$  (4)\nwhere $\\phi(\\cdot)$ is the distance function (e.g., cosine distance, etc.), $\\beta$ is the constant slack margin between the positive and negative pairs.\nTable level. As shown in Fig. 3, a cross encoder is implemented to model the interaction of schemas in the embedding and classifier spaces. Given the question with evidence $a = Cat(k, q)$, and the table schemas $\\{t_j,c_j\\}_{j=1}^{|C_j|} = d$, we employ the pre-trained ROBERTA model (Liu et al., 2019) to obtain the sequence embeddings, and then attain fusion embeddings of question, table and columns by long short-term memory (LSTM) network respectively as follows,\n$e_q, e_t, \\{e^{(c)}_{ck}\\}_{k=1}^{|C|} = EMB(a, t_j, \\{c_1^{(c)}, ..., c_{|C|}^{(c)}\\})$                                                                                                       (5)\nwhere $EMB(\\cdot) = LSTM(ROBERTA(\\cdot))$ is the function that encodes the feature embeddings, $ROBERTA(\\cdot)$ and $LSTM(\\cdot)$ is the ROBEARTA and LSTM operation, $e_q$ and $e_t$ denote the question and table embeddings, $\\{e^{(c)}_{ck}\\}_{k=1}^{|C|}$ represent the column embeddings.\nIn particular, we adopt a disentangled network (DN) that is a fully connected layer with dropout operation to filter the unrelated semantics of question embeddings from redundant tokens (e.g., \u201cthe\u201d, \u201cwas\u201d, etc.) as follows,\n$[e_n, e_s] = ReLU (DN (e_q))$                                                                                                         (6)\nwhere $ReLU(\\cdot)$ is the ReLU activation function, $e_n$ and $e_s$ denote the question embeddings that are semantically unrelated and semantically related to SQL generation respectively."}, {"title": "", "content": "To attain column-enhanced table embeddings $e^f_t$, a multi-head scaled dot-product attention layer, and a feature fusion layer are exploited to fuse the semantics of columns into table embeddings as follows,\n$e_q = MultiHeadAttn (e_t, \\{e^{(c)}_{ck}\\}_{k=1}^{|C|}, \\{e^{(c)}_{ck}\\}_{k=1}^{|C|},h)$ (7)\n$e^f_t = Norm(e_t, e_q)$ (8)\nwhere $MultiHeadAttn(\\cdot)$ represents the multi-head attention function, h is number of heads, and $Norm(\\cdot)$ is a row-wise L_2 normalization function.\nFurthermore, we use distance function $\\varphi(\\cdot)$ (e.g., cosine distance, etc.) and classifier $Classifier(\\cdot)$ to obtain the scores of schemas which represents the probability belong to ground-truth schemas from model as follows,\n$score_{cos} = 1 - \\varphi (e_q, \\{e^{(c)}_{ck}\\}_{k=1}^{|C|})$   (9)\n$score_{cl} = Classifier (e_q, \\{e^{(c)}_{ck}\\}_{k=1}^{|C|})$ (10)\nwhere $score_{cos}$ and $score_{cl}$ are the scores of schemas obtained by cosine similarity distance and classifier respectively.\nFinally, we retain database schemas with scores exceeding 0.5 as the predicted database schemas $d^{pred}_{cos}$ and $d^{pred}_{cl}$ from $score_{cos}$ and $score_{cl}$ respectively. For the inference, the predicted schemas of cross encoder are $d_f = d^{pred}_{cos} \\cup d^{pred}_{cl}$. Thus, we use cross entropy loss $CrossEntropy(\\cdot)$ to train"}, {"title": "", "content": "the cross encoder from the perspectives of cosine similarity distance and classifier as follows,\n$L_{cos} = CrossEntropy (d^{pred}_{cos}, d_{gt})$ (11)\n$L_{cl} = CrossEntropy (d^{pred}_{cl}, d_{gt})$   (12)\nwhere $d_{gt} \\in D_{gt}$ is the ground-truth database schemas.\nThe loss function at the table level can be denoted as follows,\n$L_t = L_{cos} + L_{cl}$ (13)\nDatabase level. Given the question $q \\in Q$, evidence as external knowledge $k \\in K$, and the relational database $d \\in D$, we construct an instruction to fine tune pre-trained LLMs (e.g., Llama3-8B, etc.) using Lora (Hu et al., 2022), reasoning the predicted schemas related to SQL queries for schema linking at the database level as follows,\n$d^*_f = LLM(inst, d, k, q)$ (14)\nwhere $inst$ is the instruction, $LLM(\\cdot)$ denotes the LLM operation, and $d^*_f$ represents the filtered database schemas at the database level.\nThe loss function at the database level can be denoted as follows,\n$L_d = \\frac{1}{n} \\sum_{i=1}^{n} p (d^{gt}_i | d_i, k_i, q_i)$  (15)\nwhere n is the number of Text-to-SQL instances, $d_i, k_i, q_i$ are the relational database, the evidence and the question of the i-th instance, $d^{gt}_i$ denotes the i-th target database schemas related to SQL generation.\nFinally, we attain the filtered database schemas $d_f = d^*_f \\cup d^{pred}_{cl} \\cup d^{pred}_{cos}$, which serves as the input database for schema linking of the next cycle. In particular, we follow the chain loop strategy to process schema linking using MSL continuously, reducing the task difficulty of schema linking by continuously decreasing the number of redundant schemas."}, {"title": "SQL Generation", "content": "Given the predicted database schemas $d_f = d^*_f \\cup d^{pred}_{cl} \\cup d^{pred}_{cos}$ from MSL, we construct an instruction to fine tune pre-trained LLMs using Lora to generate SQL query for the inference as follows,\n$s = LLM(inst, d_f, k, q)$ (16)\nwhere s is the predicted SQL query.\nThe loss function of SQL generation can be denoted as follows,\n$L_{SQL} = \\frac{1}{n} \\sum_{i=1}^{n} \\rho(\\hat{s}_i | d'_f, k_i, q_i)$ (17)\nwhere n is the number of Text-to-SQL instances, $\\hat{s}_i$ is the i-th target ground-truth SQL query."}, {"title": "Experiments", "content": "We conduct evaluations on two widely used Text-to-SQL datasets including Spider (Yu et al., 2018) and Bird (Li et al., 2023c).\n1) Spider (Yu et al., 2018). It contains 200 database schemas, of which 160 database chemas are used for training and validation, and 40 database schemas are used for testing. The training set comprises 8,659 samples, including 7,000 manually annotated samples and 1,659 samples sourced from six previous Text-to-SQL datasets (e.g., Restaurants (Popescu et al., 2003; Tang and Mooney, 2001), GeoQuery (Zelle and Mooney, 1996), etc.) for supplement, while the development set contains 1,034 samples, and the test set is hidden. Each instance is consisted of a NL question on specific database schemas and a corresponding SQL query.\n2) Bird (Li et al., 2023c). It covers 95 large databases consisting of 69, 11, and 15 databases for training, development, and testing respectively. This dataset with a combined size of 33.4 GB covers 37 professional domains, including blockchain, sports, health care, etc. The training set has 9,428 samples, while the development set includes 1,543 samples, and the test set is hidden. Each sample consists of a NL question with an evidence as external knowledge, a specific database and a corresponding SQL query."}, {"title": "Evaluation Metrics", "content": "To make a complete comparison, we evaluate the performances on schema linking and SQL generation for Text-to-SQL.\n1) Schema Linking. In terms of evaluations on schema linking, we adopt matching accuracy (MA), Including accuracy (IA), and redundancy (RE) to report the performances.\nMatching Accuracy: The MA metric is used to evaluate whether the predicted schemas are the"}, {"title": "", "content": "same as the ground-truth schemas.\n$MA = \\frac{\\sum_{i=1}^{n} 1 \\text{ if match }(s_i, Y_i) = \\text{True else } 0}{n}$ (18)\nwhere n denotes the number of samples, $s_i$ and $Y_i$ represent the i-th predicted and ground-truth schemas respectively, match(\u00b7) denotes the function that is used to determine if the two schemas are the same.\nIncluding Accuracy: The IA metric is employed to evaluate whether the predicted schemas contain the ground-truth schemas.\n$IA = \\frac{\\sum_{i=1}^{n} 1 \\text{ if } s_i \\supseteq Y_i \\text{ else } 0}{n}$   (19)\nRedundancy: The RE metric evaluates the redundancy in the predicted schemas.\n$RE = \\frac{\\sum_{i=1}^{n} \\sum_{j=1}^{m} 0 \\text{ if } s \\in Y_i \\text{ else } 1}{n \\times m}$ (20)\nwhere m denotes the number of schemas in the i-th predicted schemas and $s$ represents the j-th schema in the i-th predicted schemas."}, {"title": "SQL Generation", "content": "For Spider dataset, we use execution accuracy (EX) and exact match accuracy (EM) to evaluate the performances. In terms of the evaluations on Bird dataset, we employ execution accuracy (EX) and valid efficiency score (VES) as the evaluation metrics.\nExecution Accuracy: The EX metric evaluates whether the predicted and ground-truth SQL queries yield the same execution results on the database.\n$EX = \\frac{\\sum_{i=1}^{n} 1 \\text{ if match } (ex (SQL_{pred}^i), ex (SQL_{gt}^i)) = \\text{True else } 0}{n}$ (21)\nwhere ex (.) is the function that is used to execute the SQL queries in the database and return the results, $(SQL_{pred}^i)$ and $(SQL_{gt}^i)$ denote the i-th predicted and ground-truth SQL queries respectively.\nValid Efficiency Score: The VES metric evaluates the execution efficiency of accurately generated SQL queries.\n$VES = \\frac{EX \\times \\frac{\\text{time}(ex(SQL_{gt}^i))}{n}}{\\frac{\\text{time}(ex(SQL_{pred}^i))}{n}}$  (22)\nwhere time (.) denotes the execution time."}, {"title": "Baselines", "content": "We include a number of 9 Text-to-SQL approaches as baselines in two categories including prompting-based methods and fine-tuning-based methods. The details are as follows.\n1) Prompting-based methods: C3 (Dong et al., 2023) proposed three key components including clear prompting, calibration with hints, and consistent output to improve the Text-to-SQL performance from the perspectives of model input, model bias, and model output. DIN-SQL (Pourreza and"}, {"title": "Implementation Details", "content": "In terms of the column level of MSL module, a pre-trained BGE-large-en-v1.5 model is adopted as the embedding model for fine-tuning, and we take 0.5 as the threshold to predict the schemas during inference stage. Regarding the table level of MSL module, we design a cross-encoder model based on ROBERTA to model the interactions between schemas in the embedding and classifier spaces. Specifically, the part of the input tokens that exceeds 512 are truncated due to the ROBERTA, which interferes with the semantic learning. To"}, {"title": "Performance of the Tested Approaches", "content": "Table 1 and Table 2 summarize the performance of the approaches on the Bird and Spider datasets in terms of SQL generation, from which we have some observations. 1) As prompting-based methods, MAC-SQL with our predicted schemas achieves better performance than the original MC-SQL on the EX and VES metrics. The reason is that the predicted schemas by ours contain less redundant schemas and a smaller input token, causing less interference with the SQL generation of LLMs. 2) As fine-tune-based methods using DeepSeek-7B, PSM-SQL+DeepSeek-7B achieves better performance over DTS-SQL+DeepSeek-7B on the EX and VES metrics. The reason is that the predicted schemas with less redundant information can benefit LLMs to learn to generate the correct SQL queries. 3) PSM-SQL+Llama3-70B achieve the best performance on Bird dataset. The reason is that for predicted schemas with less redundant information, larger models can better demonstrate their semantic accuracy, thereby achieving more accurate generation of SQL queries.\nTable 3 summarizes the performance of the approaches on the Bird and Spider datasets in terms of schema linking, from which we can observe that PSM-SQL+Llama3-8B achieves the best performance on the MA and RE metrics at the table and column levels at the cost of reducing a bit of score of the IA metric. The reason is that PSM-SQL adopts MSL to learn multi-granularity semantics of schemas and exploits a chain loop strategy to reduce the redundant schemas continuously, benefiting to recognize the related schemas and discard the redundant schemas for schema linking."}, {"title": "Ablation Study", "content": "PSM-SQL mainly consists of a chain loop strategy and a MSL module at the column, table, and database levels. In order to verify their effectiveness, we evaluate the variations of PSM-SQL, including PSM-SQL processes one or two rounds of schema linking (denoted as Cycle_1 and Cycle_2, respectively), PSM-SQL adopt MSL process schema linking at the column, table, and database level (denoted as Emb_LLM, Cross_encoder, and Gen_LLM, respectively). The performance of the variations is summarized in Table 4 and Table 5, from which we have some observations. 1) Cycle_2 achieves better performance than Cycle_1 on SQL generation and schema linking tasks. The reason is that the chain loop strategy can continuously reduce the task difficulty which benefits the model to learn to discard the redundant schemas. 2) MSL achieves better performance than Cross_encoder, Emb_LLM, and Gen_LLM, and performs the best on the IA metric. The reason is that MSL learns the multi-granularity patterns of schemas at the column, table, and database levels, which is comprehensive than a single level. 3) In terms of the performance on SQL generation for inference, Cross_encoder+Gen_LLM performs better than MSL. The reason is that Emb_LLM pays attention on the semantics of columns that is difficult to distinguish, resulting in the retention of a large number of redundant schemas."}, {"title": "Conclusion", "content": "In this paper, we propose a progressive schema linking with multi-granularity semantics framework with a multi-granularity schema linking module and a chain loop strategy, to link the gold schemas for generating SQL queries from NL questions. More specifically, PSM-SQL employs MSL to capture multi-granularity semantics at column, table, and database levels and uses a chain loop strategy to cyclically reduce the number of schemas, thereby effectively improving the accuracy of schema linking. The experimental results conducted on Spider and Bird demonstrate the effectiveness of the proposed PSM-SQL."}, {"title": "Limitations", "content": "There are two limitations of our work. Firstly, we did not extensively engineer the prompts to process schema linking and SQL generation, which may not be optimal. Secondly, the chain loop strategy for schema linking inevitably reduces the upper limit of the model while lowering the task difficulty, as it may discard some correct schemas related to SQL generation during cycles, which is a trade-off issue."}]}