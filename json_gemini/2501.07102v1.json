{"title": "AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR", "authors": ["The Chuong Chu", "Vu Tuan Dat Pham", "Trung Kien Dao", "Ngoc Hoang Nguyen", "Steven Truong"], "abstract": "Intra-sentential code-switching (CS) refers to the alternation between languages that happens within a single utterance and is a significant challenge for Automatic Speech Recognition (ASR) systems. For example, when a Vietnamese speaker uses foreign proper names or specialized terms within their speech, ASR systems often struggle to accurately transcribe intra-sentential CS due to their training on monolingual data and the unpredictable nature of CS. This issue is even more pronounced for low-resource languages, where limited data availability hinders the development of robust models. In this study, we propose AdaCS, a normalization model integrates an adaptive bias attention module (BAM) into encoder-decoder network. This novel approach provides a robust solution to CS ASR in unseen domains, thereby significantly enhancing our contribution to the field. By utilizing BAM to both identify and normalize CS phrases, AdaCS enhances its adaptive capabilities with a biased list of words provided during inference. Our method demonstrates impressive performance and the ability to handle unseen CS phrases across various domains. Experiments show that AdaCS outperforms previous state-of-the-art method on Vietnamese CS ASR normalization by considerable WER reduction of 56.2% and 36.8% on the two proposed test sets.", "sections": [{"title": "I. INTRODUCTION", "content": "Automatic Speech Recognition (ASR) systems have made great progress in monolingual speech but struggle with intra-sentential code-switching (CS), where speakers alternate between languages within an utterance. This issue is prevalent these days, especially when the speaker mentions foreign-named entities or terminologies in different domains when they do not have a corresponding word in the native language.\nThe challenge of CS speech recognition primarily stems from the limited data available, which is insufficient to cover all speech variations, especially terms not present in the training data. This issue is even more complex for low-resource languages such as Vietnamese, particularly in the context of Vietnamese medical conversations. These conversations frequently utilize CS due to a majority of international standard medical terms not being translated into Vietnamese.\nIt's evident that training an End-to-End (E2E) ASR model, which can transcribe CS utterances directly from acoustic signals to written text, necessitates a comprehensive collection of CS speech data. Prior works have aimed to tackle the issue of intra-sentential CS by incorporating language information to take advantage of the available large scale of text data mainly including two approaches. The first is integrating a language model into the decoding scheme of the E2E ASR system [1]-[5]. The second approach [6]-[10] proposes the use of correction modules on top of the ASR system to standardize the its output.\nOf the methods above, \u201cplug-in\" modules added to the ASR system demonstrate significant promise in terms of quality and do not require much data or resources for training. Notably, [8], [9], [11] proposes models that can adapt to new domains during inference by introducing a contextual biasing mechanism through a predefined list of biased words. In this approach, a tagger module is used to identify CS phrases before normalization. However, [11] shows inefficiency due to decoding latency, which depends on the number of words in the bias list, and [8], [9] encounters issues with degraded performance with long contextual biasing because of the inadaptability of the tagger module when the bias list changes.\nTo address this gap, we proposed a novel model called AdaCS, which has the ability to adapt according to a pre-defined bias list in both CS phrase identification and normalization. This is achieved by utilizing the bias attention module in both phases. To demonstrate the performance and adaptive capability of our proposed model, we constructed a dataset for intra-sentential CS for Vietnamese (a low-resource language) with a total of 50,000 general-domain examples for the development set and 4,000 examples for the evaluation set including general and medical domains.\nIn summary, our contributions are as follows: (1) A novel model, AdaCS, that can adaptively and effectively address the intra-sentential CS normalization problem. (2) A high quality dataset, including a training and test set, to promote related research and serve as a benchmark for normalizing intra-sentential CS for Vietnamese."}, {"title": "II. RELATED WORK", "content": "The study of CS in ASR has been a significant focus for scholars. Encoder-decoder attention-based ASR has been transformative in the field, providing impressive results in multilingual ASR systems such as Whisper [13], XLS-R [14], USM [15]. However, these systems require significant data for training and their ability to manage CS is not fully clear.\nSome researchers have enriched models with language information by training a language identification module [16]-[21]. Others have modified the architecture of ASR [2], [22], [23] by adding a context encoder that incorporates contextual information into ASR systems. Some have incorporated an external contextual language model [1]-[4] into the ASR decoding framework to adjust the recognition results toward a context phrase list. However, these methods can slow the system or modify the ASR model's behavior.\nAn alternative approach is designing normalization modules on top of the ASR system to correct its output. These models, trained with text inputs and outputs, can be obtained on a large scale. Some use a tagger [9]-[12] to detect CS phrases that need normalization. In [9], the Tagger module functions solely as a classifier, lacking adaptability, making its performance dependent on consistency with the CS bias list. Conversely, [24] uses an adaptive tagger only for replacement, relying entirely on the tagger for normalization and skipping it in cases of conflict."}, {"title": "III. METHOD", "content": "In this section, we propose a novel model Adaptive Code Switching (AdaCS). AdaCS comprises a bias attention module, an encoder, and a decoder. Both the encoder and decoder blocks in AdaCS are integrated with the bias attention module to aid in the accurate and efficient identification and normalization of CS phrases, respectively. An overview of our proposed model is illustrated in Fig. 1.\n\nThe Bias Attention Module (BAM) takes in the hidden representation $s \\in \\mathbb{R}^{d_{model}}$ of a token and enhances its information about the bias list. BAM consists of: Bias Encoder, Rank & Selection, and Attention submodules.\n\nThe Bias Encoder processes a predefined list of biases, denoted as $\\{B_i\\}_{i=1}^L$, where L is the total number of entries. Each $B_i$ represents either a single word or a phrase, with $b_i$ denoting the number of tokens. A dummy entry $B_0$ is added to handle cases without bias information. For each $B_i$, the encoder computes a token-level representation matrix $E_i = [e_1, e_2, ..., e_{b_i}] \\in \\mathbb{R}^{b_i \\times d_{model}}$, and a pooled vector representation $P_i \\in \\mathbb{R}^{d_{model}}$. Given that both the bias list of CS phrases and the ASR hypothesis are text-based, it is logical to share parameters between the bias encoder and text encoder.\nThe similarity score of the tokens and the bias phrases is calculated by an inner product operation:\n$score = s^\\top P$\nwhere $P \\in \\mathbb{R}^{(L+1)*d_{model}}$ is the bias pooling matrices.\nThe bias phrase corresponding to the token, which is used to add the information to it, is retrieved by:\n$bias\\_index = argmax(scores)$\nNext, the bias mechanism is applied by using an attention layer with the query being s and the keys and values being $E_{bias\\_index}$ to compute a combined feature c. This feature is then summed with the original representation s to form an information-augmented output o:\n$o = s + MultiHeadAttention(s, E_{bias\\_index})$\n\n\nGiven a input sequence $x_0, ..., x_n$, the encoder compute the contextual features $H = [h_0, ..., h_n] \\in \\mathbb{R}^{n*d_{model}}$. Before being fed into the classification layer to determine the corresponding tag $\\hat{t_i}$ for each token in the input sequence, the features H is information-augmented with the bias list information through our BAM. The tag labels for each input token consists of B, I, O where B indicates that the token is the start of a tagged region, I if the token stands within a tagged region and O otherwise.\n$h' = BAM(h_i)$\n$\\hat{t_i} = argmax(W_{tagger}h'), W_{tagger} \\in \\mathbb{R}^{3*d_{model}}$\n\n\nWe adopted a decoder that mirrors the successful implementation proposed in [9]. After the tagger module identifies them text regions requiring normalization, the corresponding region embeddings $H_{i:j} \\in [0, m)$ are fed into the decoder to generate the corresponding normalized phrase $Y_i$. The decoder take the previous output token $y_0, \\ldots, y_{t-1}$ and does the cross attention with $H_{i:j}$ to produce a temporary output feature $z_t \\in \\mathbb{R}^{d_{model}}$. Here, BAM is also applied to help this temporary output feature to convey information about the bias list and the information-augmented output is used for decoder prediction:\n$z'_t = BAM(z_t)$\n$Y_t = W_{ffn}(z'_t), W_{ffn}\\in \\mathbb{R}^{V*d_{model}}$\n\nThe loss function $L$ used for training is a sum of four components: The tagger $L_{tagger}$, encoder biasing ranking $L_{enc\\_rank}$, decoder biasing ranking $L_{dec\\_rank}$ and the classifier of next predicted token $L_{gen}$.\n$L_{tagger} = \\frac{1}{n}\\sum_{i=0}^nCE(score_i, label_{enc\\_ranki})$\n$L_{enc\\_rank} = \\frac{1}{n}\\sum_{i=0}^nCE(score_i, label_{dec\\_ranki})$\n$L_{dec\\_rank} = \\frac{1}{m*T}\\sum_{j=0}^m\\sum_{t=0}^TCE(\\hat{y_{j,t}}, y^*_{j,t})$\n$L_{gen} = \\frac{1}{m*T}\\sum_{j=0}^m\\sum_{t=0}^TCE(\\hat{y_{j,t}}, y^*_{j,t})$\n$L = \\alpha L_{tagger} + \\beta L_{enc\\_rank} + \\gamma L_{dec\\_rank} + \\delta L_{gen}$"}, {"title": "IV. EXPERIMENT", "content": "First, we collected text data from diverse domains, segmented it into sentences, and preprocessed it to construct the corpus of original sentences. We then identified and selected sentences with CS phrases. Subsequently, we manually labeled the Vietnamese pronunciation of these CS phrases and replaced them in the original sentences, resulting in the spoken-reference pair\nFor the training process, we filtered and selected a total of 50,000 general-domain spoken-reference pairs. With a total count of approximately 1M text tokens, of which CS phrases constitute 7.5%. For evaluation, we designed the test sets according to the following criteria: (1) The test sets include two distinct domains, namely test-general for the general domain and test-medical for the medical domain. (2) Both test-general and test-medical have at least 90% of CS phrases that are not presented in the training set. (3) Test sets include \"easy\" examples where CS phrases are mixed with Vietnamese words and \"hard\" examples where CS phrases occur consecutively, common when listing proper names or medications. These criteria allow us to comprehensively evaluate the model's adaptation ability in both in-domain and cross-domain scenarios compared to the training set. After careful curation, we created test sets comprising 2,000 general-domain and 2,000 medical-domain spoken-reference pairs.\nTo evaluate our proposed model, we compared AdaCS with traditional Transformer model [25] as the baseline and other models including GPT-40 [26] and AdapITN [9].\nWe propose the following experimental settings. In the first experiment, no bias list is used to test the native normalization ability of the models. The second experiment uses a random bias list with a predetermined size of 1000 CS words, drawn from the list of English words in the entire corresponding test set, combining English words from current sentences to perform normalization. In the third experiment, we aim to reflect real-world conversations, where English phrases consisting of words often used to indicate a concept. We follow a similar approach to the second experiment, but our bias list includes both phrases and words instead of just words. In the final experiment, we evaluate the models' performance as the size of the bias list increases, intending to assess efficiency in a production environment."}, {"title": "V. CONCLUSION", "content": "AdaCS model demonstrates significant advancements in normalization intra-sentential CS. We believe our proposal emphasizes the importance of leveraging contextual information and tailored biasing strategies to improve CS speech recognition performance. The dataset, checkpoint, and experimental results are available at: https://github.com/adacs-project/adacs-project.github.io/."}]}