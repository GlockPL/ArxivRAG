{"title": "Spatial-Temporal Cross-View Contrastive Pre-training for Check-in Sequence Representation Learning", "authors": ["Letian Gong", "Huaiyu Wan", "Shengnan Guo", "Xiucheng Li", "Yan Lin", "Erwen Zheng", "Tianyi Wang", "Zeyu Zhou", "Youfang Lin"], "abstract": "The rapid growth of location-based services (LBS) has yielded massive amounts of data on human mobility. Effectively extracting meaningful representations for user-generated check-in sequences is pivotal for facilitating various downstream services. However, the user-generated check-in data are simultaneously influenced by the surrounding objective circumstances and the user's subjective intention. Specifically, the temporal uncertainty and spatial diversity exhibited in check-in data make it difficult to capture the macroscopic spatial-temporal patterns of users and to understand the semantics of user mobility activities. Furthermore, the distinct characteristics of the temporal and spatial information in check-in sequences call for an effective fusion method to incorporate these two types of information. In this paper, we propose a novel Spatial-Temporal Cross-view Contrastive Representation (STCCR) framework for check-in sequence representation learning. Specifically, STCCR addresses the above challenges by employing self-supervision from \"spatial topic\" and \"temporal intention\" views, facilitating effective fusion of spatial and temporal information at the semantic level. Besides, STCCR leverages contrastive clustering to uncover users' shared spatial topics from diverse mobility activities, while employing angular momentum contrast to mitigate the impact of temporal uncertainty and noise. We extensively evaluate STCCR on three real-world datasets and demonstrate its superior performance across three downstream tasks.", "sections": [{"title": "INTRODUCTION", "content": "LOCATION-BASED services (LBS), such as Gowalla, Weeplace, and Yelp, have experienced significant development over the past decade. These platforms enable users to share and discover location information and surrounding services, resulting in the accumulation of extensive data on human mobility behavior, e.g. check-in sequences at points of interest (POIs). This offers prospects for analyzing and comprehending human mobility patterns for various practical applications, such as predicting the next check-in location or time for personalized recommendations, linking trajectories to users, and detecting abnormal trajectories for safety control purposes etc.\nLearning accurate and universal representations for check-in sequences is a crucial task in human mobility data mining. However, the existing excellent end-to-end models for check-in sequences modeling, such as those designed for location prediction [1], [2], [3], time prediction [4], and trajectory user link [5], [6], [7], often struggle to learn generalized representations for check-in sequences and fail to comprehensively describe the spatial-temporal patterns of human mobility, since the supervision signals of these models usually rely on limited single-type labels. Therefore, the learned representations are task-specific and poorly generalized. To facilitate the generalization ability for the check-in sequence's representa-tions, pre-training check-in sequence representation via self-supervised learning has been widely studied and proven to be an effective way to fully exploit massive unlabeled check-in data to boost the performance of the downstream tasks.\nRepresentation learning is always one of the hot research topics in deep learning. And recently, contrastive pre-training with self-supervised signals [8] has emerged as the most effective approach for sequence modeling. In particular, some representative works [9], [10], [11] in the spatial-temporal data mining (STDM) domain have proven their effectiveness in learning the representations of check-in sequences. However, the unique spatial and temporal characteristics of check-in sequences raise challenges for these contrastive pre-training based models, meanwhile weakening their ability to capture the macroscopic spatial-temporal mobility patterns and to understand the high-level semantics of user mobility activities. Specifically, we identify three key challenges:\n(1) Temporal uncertainty: Understanding the temporal intention of users' ability from the check-in sequence with uncertain temporal information is challenging. As shown in Fig. 1, based on the user's historical sequence and the user's historical spatial-temporal behavior patterns, the user is most likely to go for dinner next, with the strongest temporal intention being at 17:00. However, the exact time of arrival is simultaneously influenced by his/her subjective decisions such as the today's choice of restaurant, and the surrounding objective factors such as traffic and weather. This leads to the temporal uncertainty, i.e., the user may arrive at the restaurant for dinner around 16:45 to 17:15, rather than the precise time of 17:00. Besides, unexpected bugs on service platforms may also bring noise to the recorded check-in time. The uncertainty and noise make it difficult to extract the user's temporal intention from the raw temporal context of the check-in sequences. Most existing check-in sequence representation learning methods capture the temporal patterns by embedding the precise time of check-ins, overlooking the inherent uncertainty presented in the temporal dimension of check-in sequences. Therefore, it is difficult for these methods to explore the periodic patterns and to understand the temporal intention of the users' mobility relying on noisy time.\n(2) Spatial diversity: Users' mobility has a high degree of diversity over POIs. Fig. 2 shows the check-in sequences of a user on consecutive working days and weekends. It can be seen that there are obvious differences between the user's spatial topic of working days and weekends. Specifically, the mobility on working days is mainly centered around office-related POIs, while that on weekends is mainly centered around leisure and entertainment POIs. Meanwhile, although the semantics reflected by check-in sequences on the two working days (or the two weekends) are similar, the specific POIs on the two working days (or the two weekends) may be diverse and rarely repeated. We term this phenomenon spatial diversity, which prevents us from effectively capturing the shared mobility patterns between check-in sequences with similar semantics but different POIs. Existing prevalent check-in sequence representation learning methods often adopt the most straightforward word embedding strategy borrowed from the natural lan-guage processing (NLP) domain to represent the POIs, i.e., learning embeddings for POIs and retrieving them using indices. That is, these methods treat each POI individually and fail to capture the shared semantics reflected by the POI sequences, resulting in the inability of these models to capture the high-level spatial-temporal semantics of users' mobility.\n(3) As discussed above, the raw check-in sequence is discretized and diverse w.r.t. the spatial information, but continuous and uncertain in w.r.t. the temporal information. Consequently, the distinct properties of spatial and temporal information make it challenging to effectively fuse them together. Some existing models adopt a \"fuse prior to modeling\" approach to model the temporal and spatial information of check-in sequences. However, these models encounter difficulties in simultaneously capturing spatial and temporal semantics within a unified encoder, since they ignore the difference between temporal and spatial information. Furthermore, raw data are at a fine-grained level and barely contain worthwhile semantic information. Besides, there are some disturbances in the raw data, such as temporal noise and spatial diversity. Therefore, combining the fine-grained level properties of temporal and spatial at an early phase would disrupt the performance of the model in relation to each other [12]. Other models explore using separate encoders to learn temporal and spatial representations before fusion. However, the learned temporal and spatial representations reside in separate spaces and lack alignment [13]. They usually use direct collocation or gating mechanisms, ignoring the relevance between spatial topic and temporal intention.\nTo overcome the aforementioned limitations, we propose the Spatial-Temporal Cross-view Contrastive Representation (STCCR), a pre-training framework for learning the representations of check-in sequences. Our method aims to achieve an effective fusion manner that preserves potential spatial-temporal cross-view correlations at the macroscopic semantic level. By treating one view as the reference, our cross-view contrastive strategy fa-cilitates spatial-temporal information interaction, generating numerous high-quality self-supervisions. Additionally, STCCR learns spatial topics from all check-in sequences using contrastive clustering, capturing topics by exploring the shared mobility pattern from diverse human behavior. In the temporal intention view, we employ an angular margin manner. This leverages angular margin self-supervised signals to mitigate the effects of temporal uncertainty and noise on the angular margin. In summary, our contributions are as follows:\n\u2022 We propose a novel spatial-temporal cross-view con-trastive framework for check-in sequence representation learning from the spatial topic and temporal intention views. To the best of our knowledge, this is the first study to leverage a cross-view contrastive manner to explore the spatial-temporal correlation of human mobility at the macroscopic semantic level.\n\u2022 We propose an angular margin contrast-based method to exploit the inherent uncertainty of the time information in check-ins. By adding a soft in-terval to the contrast learning training, the temporal noise information can be filtered so that the model can effectively capture the user's temporal intention.\n\u2022 We perform contrastive clustering in the spatial dimension. To address the diversity of POIs, we explore shared spatial topics by clustering high-level semantic information from check-in sequences.\n\u2022 We evaluate STCCR on three real-world datasets for three downstream tasks. The experimental results prove the superiority and versatility of our model."}, {"title": "RELATED WORK", "content": "Location-based services have given rise to a new and promising research topic known as mobility data mining, which has led to the emergence of three significant tasks that contribute to enhancing the quality of services: next location prediction (LP), next time prediction (TP), and trajectory user link (TUL). Recent studies have confirmed that deep learning techniques, specifically recurrent neural networks (RNNs) and attention mechanisms, are highly effective in capturing sequential and periodic patterns of human mo-bility. By combining deep learning techniques, researchers have made significant advancements in capturing both the sequential and periodic patterns of human mobility. The core of these models is the modeling of check-in sequences, which leads to improved accuracy in location prediction and trajectory analysis.\nLP aims to anticipate a user's future location based on their historical movement. Several notable models have emerged as prominent approaches in LP. DeepMove [1] leverages RNNs and attention mechanisms to capture the spatial-temporal intentions in users' location data and predict their next destination. STAN [14] introduces a spatial-temporal attention network that incorporates spatial and temporal contexts for accurate prediction. LSTPM [2] focuses on long and short-term patterns in user trajectory us-ing an attention-based LSTM [15] model. SERM [3] utilizes an encoder-decoder architecture with a spatial-temporal residual network to capture user preferences and predict future locations. PLSPL [16] trains two LSTM models for location and category based sequence to capture the user's preference. LightMove [17] designs neural ordinary differential equations to enhance robustness against sparse or incorrect inputs. HMT-GRN [18] alleviates the data sparsity problem by learning different User-Region matrices of lower sparsities in a multitask setting. Graph-Flashback [19] constructs a spatial-temporal knowledge graph to enhance the representation of POIs. GETNext [20] introduces a user-agnostic global trajectory flow map as a means to leverage the abundant collaborative signals.\nTUL is a significant task that focuses on establishing connections between different trajectories, facilitating the analysis of user movement patterns, and uncovering valu-able insights about their behavior. Notable models have been specifically developed to address the challenge of predicting trajectory links. TULER [6] takes advantage of advanced algorithms to establish links between trajecto-ries, allowing for a comprehensive understanding of user movement patterns. DeepTUL [5] utilizes deep learning techniques to extract representations from trajectory data and facilitate the prediction of trajectory links. S2TUL [21] utilizes graph convolutional networks and sequential neu-ral networks to capture trajectory relationships and intra-trajectory information. GNNTUL [22] employs graph neural networks for human mobility and associates the traces with users on social networks.\nTP focuses on estimating the time at which a user is likely to visit their next location. To accomplish this, it is common practice to use intensity functions to represent the rate or density of event occurrences, various models have been developed to model the intensity function and make accurate time predictions effectively. Modeling the intensity function using RNNs or attention mechanisms is a common approach for predicting the occurrence of events. RMTPP [23] utilizes RNNs to model the intensity function. SAHP [24] combines the Hawkes process with self-attention mechanisms to capture the temporal dependencies and spatial influences in event sequences. THP [25] combines the Hawkes process with transformer-based ar-chitectures to capture temporal dependencies in event se-quences. NSTPP [26] utilizes neural ODEs to model discrete events in continuous time and space, enabling the learning of complex distributions in spatial and temporal domains. IMTPP [27] models the generative processes of observed and missing events and utilizes unsupervised modeling and inference methods for time prediction. DSTPP [28] purposes a novel parameterization framework that uses diffusion models to learn complex joint distributions.\nIt is important to note that these end-to-end supervised methods designed for specific tasks are not universal. These models do not have a good grasp of the macroscopic se-mantics of check-in sequences. Thus, learning the universal representation of check-in sequences to improve the model's ability and understand high-level semantics is critical."}, {"title": "Pretraining and Contrastive Learning", "content": "The essence of mobility mining tasks lies in learning the representation of check-in sequences. Numerous studies have demonstrated the effectiveness of employing the pre-training paradigm to achieve check-in sequence representa-tion learning. For instance, TULVAE [7] and MoveSim [29] utilize Variational Auto-Encoder and Generative Adversar-ial Network, respectively, to capture the movement patterns of check-in sequences through pre-training. TALE [30] pro-poses a pre-training representation scheme for trajectory point location embedding that incorporates temporal se-mantics, which effectively improves the performance of next location prediction and location traffic prediction. CTLE [31] proposes a location pre-training representation model that incorporates domain features, which dynamically generates feature representations of the domain environment of the target location so that the model can better capture the macroscopic higher-order semantic information in the lat-itude and longitude.\nAs a kind of advanced SSL technology, contrastive learning-based pre-training techniques have demonstrated great potential in the field of Natural Language Process-ing (NLP). It utilizes self-supervised training by compar-ing positive and negative pairs generated through data augmentation., contrastive pre-training models employ a variety of data augmentation strategies. For example, Sim-CSE [32] utilizes dropout operations for data augmentation. ConSERT [33] disrupts, slices, and deletes representations in the hidden space. VaSCL [34] enhances the discrimina-tive power by introducing challenging negative samples. CLAPS [35] introduces adversarial perturbations to gener-ate indistinguishable augmented samples, thus significantly improving the robustness and discrimination ability.\nIn the domain of mobility mining, the first model to adopt contrastive learning is SML [10], which applies commonly used data augmentation strategies such as cropping or replacement to check-in sequences. ReMVC [9] learns distinct region embeddings and constraints embedding param-eters while transferring knowledge across multiple views. DRAN [36] exploits disentangled representations to capture distinct aspects and corresponding influences for a more precise representation of POIs. CACSR [11] proposes a con-trastive pre-training model for learning check-in sequence representations with adversarial perturbations. However, these models are not designed separately for spatial and temporal properties and do not specifically consider spatial-temporal information fusion.\nIn summary, learning about check-in sequence represen-tation is crucial for mobility mining tasks. Pre-training meth-ods, especially contrastive learning, have demonstrated ef-fectiveness in capturing underlying patterns. It is essential to develop tailored techniques that can effectively extract human spatial-temporal patterns of check-in sequences to improve the performance of contrastive pre-training models in this domain."}, {"title": "PRELIMINARIES", "content": "Definitions\nDefinition 1. POI Visiting Record. In location-based ser-vices datasets, a user's visit to a certain place is repre-sented by a POI visiting record $r = (u,l,t)$, where $u$ represents the user, $l$ indicates the visited location, and $t$ denotes the timestamp of the visit. The location $l$ is represented by $(l_{id}, lon, lat, c)$, comprising $l_{id}$ as a POI index or a grid index, and accurate longitude $lon$ and latitude $lat$. $c$ denotes the category of the visited location (e.g., hospital or restaurant).\nDefinition 2. Check-in Sequence. The movement of a user during a specific period can be represented by a list of sequential POI visiting records, which we refer to as a check-in sequence. We denote a check-in sequence as $T = <r_1, r_2, ... ,r_s>$, where the POI visit records are ordered by their visited time, and s is the length of the sequence."}, {"title": "Problem Statement", "content": "Pre-training Representation for check-in Sequence. The goal of this paper is to pre-train a parameterized encoder $G$ capable of generating a contextual representation for a given check-in sequence $T$, denoted as $G(T)$. Specifically, the encoder $G$ is first trained within a spatial-temporal cross-view frame-work using a contrastive manner, without task-specific ob-jectives. Then, it can be applied to various downstream tasks, such as next Location Prediction (LP), Trajectory User Link (TUL), and Time Prediction (TP), among others. We expect that the parameterized encoder $G$ can be widely used to enhance the performance of these downstream tasks."}, {"title": "SPATIAL-TEMPORAL CROSS-VIEW CONTRASTIVE FRAMEWORK", "content": "As illustrated in Fig. 3, we propose a Spatial Temporal Cross-view Contrastive Representation (STCCR) model that leverages self-supervision to capture high-level semantics, i.e., the spatial topic and temporal intention of check-in sequences separately and then fuse them at a macroscopic level. To extract the shared spatial topic of the check-in sequence, we introduce the Spatial Topic Module (STM). This module employs contrastive clustering to encode the spatial information of check-in sequences, forcing check-in sequences with similar spatial topics to have similar representations. Additionally, we combine time and user information in the Temporal Intention Module (TIM) dur-ing pre-training to extract the temporal intention of users. Specifically, we adopt a contrastive learning scheme with an angular margin to model noisy temporal information. Finally, the ST Cross-View Contrastive Module aligns the high-level spatial and temporal semantics into a unified semantic space using project heads, facilitating the integration of spatial-temporal information at the macroscopic semantic level. Next, we provide a detailed explanation of our proposed model in the following sections."}, {"title": "Spatial Topic Module", "content": "The Spatial Topic Module comprises a geohash layer, a transformer layer, and a spatial cluster contrastive block. The geohash layer and transformer layer work together to embed geographical location information into the embed-ding space. The contrastive spatial cluster block leverages contrastive clustering to capture spatial topics of users' mobility."}, {"title": "Geographical Location Information Encoding", "content": "The key advantage of Geohash 1 encoding is its ability to convert geographic coordinates into a string of characters, enabling efficient storage, retrieval, and analysis of location-based data. Geohash represents latitude and longitude infor-mation in the following three steps. First, the latitude and longitude are converted into two binary sequences, $e_{lat}$ and $e_{lon}$. These sequences are obtained by recursively dividing the latitude and longitude ranges. For the latitude value, the range (-90\u00b0, 90\u00b0) is divided into two sub-ranges: (-90\u00b0, 0) and (0,90\u00b0). If the latitude falls within the lower sub-range, a '0' is appended to $e_{lat}$, otherwise a '1' is appended. The same process is applied to $e_{lon}$ using the initial range (-180\u00b0, 180\u00b0). Next, the even bits of $e_{geo}$ are set to $e_{lat}$ and the odd bits are set to $e_{lon}$ to create the concatenated binary sequence $e_{geo}$, where i = {0, 1, 2, \u2026\u2026\u2026, 15}.\n$e_{(geo,2i)} = e_{(lat,i)}$\n$e_{(geo,2i+1)} = e_{(lon,i)}$\nFinally, $e_{geo}$ is converted to Base32 encoding to produce the geohash representation."}, {"title": "POI Category representation", "content": "To represent the category description of a POI, we treat the description as words and directly utilize a public pre-trained BERT model\u00b2 for sequence representation. We use a variant of BERT in which the final output of the [CLS] token is selected as the representation of the description. The representation of a POI description is denoted as $e_{cat}$."}, {"title": "Spatial Cluster Contrastive Block", "content": "To gain a more comprehensive understanding of user mobility patterns, we propose a spatial cluster contrastive block to capture the underlying shared spatial topics of users' mobility. As discussed in Section 1, we can find a great deal of diversity among the POIs of check-in sequences. Thus, treating each individual check-in sequence separately without considering their common mobility patterns makes it hard to share statistical strength across sequences. We find that users tend to exhibit movement patterns centered on specific spatial topics during different periods. For example, users tend to move around work areas, dining areas, and residential areas during the working days, while focusing on leisure activities such as travel areas, shopping centers, and dining areas during the weekends. Therefore, extracting spatial topics from diverse check-in sequences is crucial to effectively learning the shared mobility patterns of users' movement.\nThat is, spatial topics refer to the check-in sequences that are generated over different locations but have similar, relative, and shared patterns in terms of spatial movement. To explore the shared spatial topics among sequences, we introduce the \"clustering consistency\" and \"reweighted con-trastive\" strategies into our model. To represent different shared spatial topics, we define a prototype $C$ which is a set of $k$ cluster centers $C = {c_1,...,c_k}$. Meanwhile, we assume that check-in sequences with the same spatial topics fall into a similar semantic space. We use a Bi-GRU as the spatial encoder to encode the spatial information of check-in sequences combined by $e_{geo}$ and $e_{cat}$. Given a representation of the check-in sequence through the spatial encoder $z_s$ as the anchor, we use the dropout augmentation manner as SimCSE [32] to obtain its augmentation $z_s^m$. We calculate each prototype assignment $q_i$ by assessing the similarity of the representation to the prototype as follows:\n$q_i^{(k)} = \\frac{exp(\\frac{z_s^T c_k}{T})}{\\sum_{k'\\neq k} exp(\\frac{z_s^T c_{k'}}{T})}= [q_i^{(1)}, q_i^{(2)},..., q_i^{(k)},..., q_i^{(K)}], i = {1,2,......., N}$ N is the total number of check-in sequences, $\\tau$ is a temperature parameter. To ensure the consistency of class attribution between the anchor and augmented sample, we define the clustering consistency loss function as:\n$L_c(z_s, z_s^m) = l(z_s^n, q_n) + l(z_s^m, q_m)$,\nwhere $l(z_s, q)$ measures the fit between representation $z_s$ and assignment $q$. We compare the representations $z_s^n$ and $z_s^m$ using their prototype assignments $q_n$ and $q_m$. Each term in Eq. 3 represents the cross-entropy loss between $q$ and the probability obtained by taking a softmax of the dot products of $z_s$, and all columns in $C$, i.e.,\n$l(z_s, q_n) = - \\sum_k q_n^{(k)} log q_k^{(n)}$,\nConsistency loss makes the anchor and its corresponding sample belong to a similar assignment as much as possible. But this may lead to a plain solution (i.e., the model assigns all samples inside one cluster). To avoid this, we propose a reweighting strategy that assigns larger weights to meaning-ful negative samples with a moderate prototype distance to the anchor, and smaller weights to negative samples that are easily distinguished. This assigns the samples in the batch and queue to the K classes according to $q$ while satisfying the inter-cluster balance constraint. This makes samples that have similar prototype assignments grouped together as much as possible and avoids the plain-solution problem. We define the reweighting strategy denoted $L_R$ as:\n$L_R = - \\sum_{n=1}^N log \\frac{\\phi (n,m)}{\\phi (n,m) + M_n \\sum_{j\\epsilon S} w_{nj}\\phi(n, j)}$,\nwhere $\\phi (n, m) = exp(\\frac{z_s^n z_s^m}{T}), w_{nj}$ is the weight of negative pairs $(z_s^n, z_s^j). M_n = \\frac{2\\beta}{(\\sum_{j\\epsilon S} w_{nj})}$ is the normalization factor, $\\beta$ is the number of the set $S$. $S = {j|c^n \\neq c^m}$, where $c^n$ and $c^m$ are the most probable prototypes of the check-in sequence $z_s^n$ and $z_s^j$, respectively.\nWe utilize the cosine distance to measure the distance between two assignments $q_n$ and $q_j$ as: $D(q_n, q_j) = 1 - \\frac{(q_n.q_j)}{(\\Vert q_n \\Vert_2 \\Vert q_j \\Vert_2)}$. Then, we define the weight based on the above assignment distance with the format of the Gaussian function as:\n$w_{nj} = exp \\{-\\frac{[D(q_n, q_j) - \\mu_n]^2}{2\\sigma_n^2}\\}$,\nwhere $\\mu_n$ and $\\sigma_n$ are the mean and standard deviation of $D(q_n, q_j)$ for anchor $z_s^n$, respectively. In this way, selected negative samples can enjoy desirable semantic differences from the anchor, and those similar ones are \"masked\" out in the objective.\nSince different clusters represent distinct underlying semantics, such a sampling strategy can ensure a distin-guishable semantic difference between the anchor and its negatives. The final training objective is the combination of $L_R$ and $L_c$ to jointly optimise the spatial topic, formulated as:\n$L_{Spatial} = \\eta L_C + L_R$\nwhere the constant $\\eta$ balances the clustering consistency loss $L_c$ and the reweighted contrastive loss $L_R$. This loss function is jointly minimized concerning the prototype $C$ and the parameters $\\Theta$ of the spatial encoder used to produce the spatial representation $z_s$."}, {"title": "Temporal Intention Module", "content": "The Temporal Intention Module aims at analyzing users' temporal intentions. It includes a timestamp angular con-trastive block and a social aware block. They leverage the angular margin to mitigate the effects of temporal uncer-tainty and noise."}, {"title": "Timestamp Embedding", "content": "The timestamp embedding layers convert the original tem-poral features into dense vectors. Specifically, we first dis-cretize each timestamp $t$ into hourly intervals and then represent it as a $T$-dimensional one-hot vector $(T = 48)$. To distinguish weekends from weekdays, we treat weekends as an additional 24 hours. Then we learn the embedding for each time interval, denoted by $E_t \\epsilon R^{T*d_t}$."}, {"title": "Temporal Angular Contrastive Block", "content": "This block leverages the angular margin scheme to enable contrastive learning to mitigate the effects of temporal noise and extract users' temporal intention. To model the positive and negative pairwise relations between sequences, we first generate sequence representations and group them into positive and negative pairs. We then use these pairs as input to a training objective for optimization.\nTo generate temporal representations from check-in se-quences in the temporal dimension, we employ two Bi-GRU encoders, denoted as $M_t$ and $M_t'$. Similarly to the approach in ESimCSE [37], we use momentum contrast as the data augmentation method. In particular, we use the momentum-updated encoder to encode the enqueued sequence representation. Formally, denoting the parameters of the encoder $M_t$ as $\\Theta_t$ and those of the momentum-updated encoder $M_t'$ as $\\Theta_t'$, we update of in the following way:\n$\\Theta_t' \\leftarrow \\eta\\Theta_t' + (1 - \\eta)\\Theta_t$,\nwhere $\\eta \\epsilon [0,1)$ is a momentum coefficient parameter. Note that only the parameters $\\Theta_t$ are updated by back-propagation. To generate temporal representations, we introduce a new set of parameters denoted as $\\Theta$, which are updated using momentum to ensure a smoother evolution than $\\Theta_t$. We obtain two different temporal representations, denoted as the anchor $z_t$ and the augmentation $z_t^m$, by passing it through the models $M_t$ and $M_t'$, respectively. These representations share the same semantics and form a positive pair, while negative pairs are obtained by com-paring representations from different samples in the same batch. The most widely adopted training objective is the NT-Xent loss, which is formulated as follows:\n$L_{NT-Xent} = -log \\frac{e^{sim(z_t, z_t^m)/\\tau}}{\\sum_{j \\neq n} e^{sim(z_t, z_j)/\\tau}}$,"}, {"title": "Social Aware Block", "content": "To capture the intrinsic spatial-temporal movement patterns of different users more effectively, we propose the Social Aware Block, which generates a unique representation for each user. Specifically, we utilize Graph Attention Networks (GATs) to aggregate the neighbor features of each user and employ an adaptive adjacency matrix to aggregate higher-order neighbor features.\nGiven the social network $G = {U,E}$, where $U$ and $E$ denote the user and link sets respectively, the i-th user is denoted as $u_i$. We denote the matrix $E_u \\epsilon R^{\\Vert U\\Vert *d_u}$ as the lookup table of user embedding. Then we leverage GAT to aggregate neighbors' representations and update its embedding for each user, the new embedding is computed as:\n$h_i^{(l)} = \\sigma(\\sum_j a_{ij}^{(l)}W h_j^{(l-1)})$, where $sim(z_t, z_t^m)$ is the cosine similarity $\\frac{z_t z_t^m}{\\Vert z_t \\Vert * \\Vert z_t^m \\Vert}$,$\\\\tau$ is a temperature hyper-parameter and n is the number of sequences within a batch.\nAlthough the training objective tries to pull represen-tations with similar semantics closer and push dissimilar ones away from each other, these representations may still not be sufficiently discriminative and not be very robust to temporal noise. To demonstrate this, let us first denote angular $\\Theta_{n,m}$ as follows:\n$\\Theta_{n,m} = arccos(\\frac{z_t z_t^m}{\\Vert z_t \\Vert * \\Vert z_t^m \\Vert})$\nThe angular margin for $z_t$ in NT-Xent is $\\Theta_{n,m} = \\Theta_{n,j}$, as show in Fig. 5. Due to the lack of a decision margin, a tiny time perturbation around the angular margin may lead to an incorrect decision. To overcome this problem, we propose a new training objective for temporal representation learning by adding an additive angular margin $\\sigma$ between positive pairs $z_t$ and $z_t^m$. This means that we want to keep some interval between the positive samples and do not force them exactly the same. We named it Time Angular Margin contrastive loss (TAM Loss), which can be formulated as follows:\n$L_{TAM} = -log \\frac{e^{cos(\\Theta_{n,m}+\\sigma)/\\tau}}{e^{cos(\\Theta_{n,m}+\\sigma)/\\tau} + \\sum_{j\\neq n} e^{cos(\\Theta_{n,j})/\\tau}}$\nThe TAM loss introduces a angular margin for $z_t$ that is defined as $\\Theta_{n,m} + \\sigma = \\Theta_{n,j}$, as shown in Fig. 5. Compared to the NT-Xent loss, the TAM loss further encourages $z_t$ to move towards the region where $\\Theta_{n,m}$ is smaller and $\\Theta_{n,j}$ is larger. It increases the similarity of temporal representa-tions with similar semantics and enlarges the discrepancy between different semantic representations. This enhances the alignment and uniformity properties, which are the two key measurements of representation quality related to contrastive learning [32]. Moreover, the angular margin provides an extra margin $\\sigma$ to $\\Theta_{n,m} = \\Theta_{n,j}$, which is often utilized during inference, making the loss more tolerant to temporal noise and better at capturing the underlying semantic intentions of the user. Overall, these properties make the TAM loss a more effective training objective than traditional alternatives for extracting users' temporal intentions."}, {"title": "ST Cross-View Contrastive Module", "content": "The temporal intention and the spatial topic are strongly correlated with users and highly susceptible to each other's impacts. This gives rise to a wealth of high-quality self-supervised signals. For example", "follows": "n$P_{m \\rightarrow pont"}, {"as": "n$P_{m \\rightarrow pont"}, {"y$": "n$L_{ST} = \\frac{1}{2}E_{(z_s, z_t) \\sim D}[H(y"}]}