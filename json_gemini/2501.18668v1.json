{"title": "Simulation Streams: A Programming Paradigm for Controlling Large Language Models and Building Complex Systems with Generative AI.", "authors": ["Peter Sunehag", "Joel Z. Leibo"], "abstract": "We introduce Simulation Streams, a programming paradigm designed to efficiently control and leverage Large Language Models (LLMs) for complex, dynamic simulations and agentic workflows. Our primary goal is to create a minimally interfering framework that harnesses the agentic abilities of LLMs while addressing their limitations in maintaining consistency, selectively ignoring/including information, and enforcing strict world rules. Simulation Streams achieves this through a state-based approach where variables are modified in sequential steps by \u201coperators,\u201d producing output on a recurring format and adhering to consistent rules for state variables. This approach focus the LLMs on defined tasks, while aiming to have the context stream remain \u201cin-distribution\u201d. The approach incorporates an Entity-Component-System (ECS) architecture to write programs in a more intuitive manner, facilitating reuse of workflows across different components and entities. This ECS approach enhances the modularity of the output stream, allowing for complex, multi-entity simulations while maintaining format consistency, information control, and rule enforcement. It is supported by a custom editor that aids in creating, running, and analyzing simulations. We demonstrate the versatility of simulation streams through an illustrative example of an ongoing market economy simulation, a social simulation of three characters playing a game of catch in a park and a suite of classical reinforcement learning benchmark tasks. These examples showcase Simulation Streams' ability to handle complex, evolving scenarios over 100s-1000s of iterations, facilitate comparisons between different agent workflows and models, and maintain consistency and continued interesting developments in LLM-driven simulations.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating complex simulations (Chen et al., 2023; Park et al., 2023; Wu et al., 2023). Most straightforwardly, simulations can be produced just by prompting an LLM chatbot with instructions to simulate, and to do so using a specific format as this helps specify what is expected from the simulation and if more detailed even \"programs\" it. The format bears upon what the explicit state of the simulation contains, e.g. time and the location and activities of a number of characters, and the format can help track the state as well as guide attention to preceding entries. In this way, one can obtain sophisticated, emergent narratives which benefit from the LLM's vast knowledge base. Further, LLM simulations can enable new possibilities - for instance, in a situation like in Fig. 1, humans could inquire about an agent's progress or agents could request human assistance.\nHowever, this approach to LLM-based simulations faces the following limitations:\n1. Maintaining a consistent format over extended iterations cannot be guaranteed and the chatbot can become \"lazy\" and sum up instead, e.g. by \"and so they continued for iterations 5-10 and then everyone went home and would always remember that day\".\n2. It's difficult to selectively hide/include information from the LLM, since they are sampled autoregressively and all previous context is typically available for each generation step.\n3. Enforcing strict world rules is challenging, as"}, {"title": null, "content": "the LLM may violate established constraints or introduce inconsistencies, e.g. an agent hallucinating that it achieved its objective.\n4. The LLM can fail to properly track the state of the simulation, e.g. what is in an inventory.\n5. For a very long simulation, all the above can lead to compounding inconsistencies and the simulation going far off track.\nWhile alternative approaches to simulation exist, they face their own significant challenges. Traditional agent-based platforms like NetLogo (Wilensky, 1999) and artificial life simulators like Avida (Ofria and Wilke, 2004) require explicit rule specification through cellular automata or genetic algorithms, making them brittle when faced with novel scenarios. Physics-based simulation engines like MuJoCo (Todorov et al., 2012) excel at physical dynamics but struggle with high-level decision making. Reinforcement Learning (RL) (Brockman et al., 2016) including Multi-Agent RL Du et al. (2023). can learn policies through environment interaction, but require substantial training data and often fail to capture the nuanced reasoning that LLMs handle naturally. FLAME (Chopra et al., 2023) implements differentiable agent-based models with GPU acceleration, enabling gradient-based parameter calibration of parameterized rules.\nRecent work has explored various approaches to multi-agent LLM simulations. Park et al. (2023) introduced generative agents that maintain memory and plan actions, while Wu et al. (2023) developed structured conversational flows between specialized agents. Chen et al. (2023) focused on role-playing scenarios with defined social protocols, and Qian et al. (2024) demonstrated specialized agents collaborating in software development. Each of these frameworks implements specific patterns for managing agent interactions.\nThis paper introduces Simulation Streams\u00b9, a programming paradigm designed to leverage the agentic abilities of LLMs while addressing their core limitations in maintaining consistency and enforcing constraints. Importantly, Simulation"}, {"title": null, "content": "Streams provides a foundational language that can express many mechanisms of existing multi-agent LLM frameworks while requiring minimal interference with the model's capabilities.\nSimulation Streams takes a state-based approach where variables are modified in sequential steps, each defined by what we term an \u201coperator,\u201d producing a structured output stream that adheres to consistent rules. The following example in Figure 1 demonstrates how Simulation Streams generates a consistent output format across multiple iterations, with different operators contributing to various parts of the stream:"}, {"title": "Simulation Streams", "content": "Simulation Streams is maintaining \"in-distribution\" generation, which largely means generating a context where everything is reasonably probably according to the LLM. We want the trajectory to be something it could have generated by itself, while we are forcing it to be within the subset of trajectories it could have generated that follows our rules. In the context of LLMs, remaining in-distribution refers to generating content that aligns closely with the patterns and structures the model has learnt in training. To achieve this, Simulation Streams organizes its output into substreams\u2014sequences of related entries that follow consistent, well-defined formats. Each substream maintains its own specific structure, providing a clear pattern of manageable complexity for the LLM to work with, like the example in Figure 1. When generating new content, the LLM is tasked with producing the next line in the relevant substream, following the established format.\nOne of the key advantages of the substream approach is its ability to keep the repeating format and its events sufficiently simple and compact. This simplicity allows the LLM to model the pattern more effectively, enabling it to attend more appropriately to relevant preceding entries. By breaking the simulation into substreams, we create a modular design that is easier to manage and modify, while also improving the LLM's ability to generate coherent and contextually relevant content. As simulations grow in complexity, the substream approach allows for the addition of new elements without disrupting existing patterns, enhancing scalability.\nPrograms in Simulation Streams are essentially lists of operators, defining formats and rules while allowing easy switching between human design and LLM generation based on provided conditions. The simulation maintains a state composed of variables that can be modified at each step and influence the output. Each step in the simulation is defined by an operator, which includes an unique identifier, a formula (expressed in Python) that describes how variables change, conditions for when the LLM should generate or modify the formula, a query that determines which substreams form the context for the operator, and a \"next\" field that determines the subsequent operator. Many of these fields are provided automatically most of the time."}, {"title": null, "content": "Formulas within operators can be either human-written or generated by LLMs, allowing for both precise control and dynamic adaptability in the simulation. This flexibility is crucial for creating complex, evolving scenarios that can adapt to unexpected situations or novel inputs. The simulation progresses by evaluating operators sequentially, with each step potentially influencing which operator is executed next. Each step appears as a row in the stream, showing the variable being assigned and the right-hand side that determines its new value. This provides a traceable record of the LLM's behavior and outputs, facilitating debugging and analysis of the simulation's progress. Each operator's execution results in a contribution to the output stream, either through direct state updates or LLM-generated content. This structured approach allows Simulation Streams to maintain format consistency over thousands of iterations if needed, selectively control the LLM's access to information, and strictly enforce simulation rules - addressing the key limitations of purely LLM-driven simulations.\nTo further enhance the usability, Simulation Streams incorporates an Entity-Component-System (ECS) architecture (Bilas, 2002; Fabian, 2009) for producing lists of operators, which form the programs. This approach allows for modular, reusable components in building complex LLM-driven simulations. The ECS architecture is supported by a custom editor that has been developed to facilitate the creation of operator lists, run simulations, inspect metrics, and allow querying of the generated simulation stream. This ECS approach enhances the modularity of the output stream, allowing for complex, multi-entity simulations while maintaining the core benefits of format consistency, information control, and rule enforcement.\nTo demonstrate the versatility and power of Simulation Streams, we provide an illustrative example of simulating a market economy with consumers, producers of various goods, a market maker, and common resources. This simulation runs indefinitely, generating ongoing interesting and relevant developments. Additionally,"}, {"title": null, "content": "we create a suite of classical reinforcement learning benchmark tasks, including grid world tasks and continuous control problems like mountain car, where agent workflows and different models can be compared."}, {"title": "Simulation Streams", "content": "Simulation Streams is a novel programming paradigm designed for constructing and executing complex, dynamic simulations with integrated Large Language Model (LLM) capabilities. Formally, we define a Simulation Stream as follows:\nA Simulation Stream S is a tuple (X, O, L, T) where:\n\u2022 X is the state space,\n\u2022 O is a set of operators,\n\u2022 L is an LLM sampling function\n\u2022 T is a set of termination conditions.\nAdditionally, an output stream R is maintained, consisting of text rows representing assignment formulas derived from operator executions. Key characteristics that distinguish Simulation Streams include:\n1. State-based representation of the simulation environment\n2. Operator-driven state transitions\n3. LLM integration\n4. Output stream generation for context\n5. Substream-based context management"}, {"title": "State Space", "content": "The state space X in a Simulation Stream represents all possible configurations of the simulation at any given time. We define it as follows:\nThe state space X is a set of all possible states x, where each state x = (v\u2081, v\u2082, ..., vn) is a tuple of state variables vi \u2208 Vi, and Vi is the domain of the i-th state variable. State variables can be of various types:\n\u2022 Numerical: vi \u2208 R or vi \u2208 Z (e.g., real-valued coordinates or integer counters)\n\u2022 Categorical: v\u00a1 \u2208 {c\u2081, c\u2082, ..., ck} (e.g., boolean values where vi \u2208 {True, False}, or multi-class labels)\n\u2022 Text: \u03bd\u1f31 \u03b5 \u03a3*, where \u2211 is a finite alphabet (e.g. ASCII characters)\nThe state transition function F: X\u00d7O\u00d7L \u2192 X defines how the state evolves over time:\nXt+1 = F(xt, Ot, lt) (1)\nwhere xt is the state at time t, ot \u2208 O is the operator applied at time t, and lt is the LLM-generated content at time t. The selection of the next operator to apply is determined by the next operator selection function n : 0 \u2192 0, which is a component of each operator.\nOt+1 = n(ot). (2)\nEach state transition produces an output in the form of a text row in the output stream R. This row comprises an assignment formula where the left-hand side (LHS) coincides with the variable being modified, and the right-hand side (RHS) is the result of evaluating the formula field in the corresponding operator."}, {"title": "Operators", "content": "Operators are the mechanism for state transitions in Simulation Streams. An operator is defined as follows:\nAn operator \u03bf \u2208 O is defined by the following components:\n\u2022 id: a unique identifier,\n\u2022 f : X \u2192 X: a state transition formula that assigns a new value to one variable,\n\u2022 c : X \u2192 {0,1}: an LLM invocation condition,\n\u2022 q : X \u2192 P(X): a context query function,\n\u2022 n : X \u2192 O: a next operator selection function,\n\u2022 A: X \u2192 X: a set of additional variable assignments, which can include definitions for sub-stream belongings (tags)."}, {"title": null, "content": "The LLM invocation condition c determines when the LLM should be used to generate or modify the formula. It's a boolean function of the current state:\nc(x) = { True if LLM should be invoked False otherwise (4)\nOutput Stream and Query Function\nThe output stream O = (o\u2081, o\u2082, ..., ot) is a sequence where each oi represents the output at time step i, typically in the form of a text string, e.g. 'move_x = 1\\n'\nThe context query function q operates on this output stream, selecting relevant rows based on"}, {"title": null, "content": "specified conditions that relate to the state variables. It is defined as follows:\nA query function q : C \u00d7 S \u00d7 0 \u2192 P(0) takes a condition c \u2208 C, the current state s \u2208 S, and the current output stream O, and returns a subset of output rows where the condition is true based on the state:\nq(c, s, 0) = {o \u2208 O : c(s, o) is true} (5)\nwhere C is the set of all possible conditions and S is the state space.\nThe query function operates on the output stream, which contains the textual representation of state changes. This allows for context selection based on both the current state and the history of state transitions as recorded in the output stream. For example, a query might select all output rows where a movement was generated.\nq(movement=True, s, O) = {ot \u2208 0 : st(movement) = True} (6)\nThis allows the system to provide relevant historical context for LLM queries by selecting spe-"}, {"title": null, "content": "cific outputs from the simulation history. In practice, this might look like the following output from executing four operators (and a 'blank' for empty line) where movement=True, in two iterations and we are just about to sample the last of those (for y-movement):\ntime = 0\nplan = \"Move right and down.\"\nmove_x = 1\nmove_y = -1\ntime = 1\nplan = \"Move down\"\nmove_x = 0\nHere, 'movement' is a state variable that has been set as an additional field in some operators and otherwise to a default (False) when not explicitly specified in the operator."}, {"title": "Entity-Component-System (ECS)", "content": "Simulation Streams can be organized using an Entity-Component-System (ECS) architecture, which provides a modular and hierarchical structure for complex simulations. In the context of Simulation Streams, we define ECS as follows:\nAn ECS architecture in Simulation Streams is a pair (E, C) where:\n\u2022 E is an ordered set of entities, each associated with an ordered list of component identifiers,\n\u2022 C is a set of components, where each component initializes state variables and provides a list of operators.\nEntities represent distinct objects or actors in the simulation. Formally:\nE = (e\u2081, e\u2082, ..., en) (7)\nwhere each entity e\u00a1 is associated with an ordered list of components:\nli \u2192 [Ci1, Ci2, ..., Ciki] where cij \u2208 C (8)\nwhere each entity e\u00a1 is associated with an ordered list of components:"}, {"title": null, "content": "Components are defined as tuples that include both initial state variables and associated operators:\nC = {c1, c2, ..., cm} where c\u2081 = (Vi, O\u2081) (9)\nHere, Vi is a set of initial values of some state variables, and O\u2081 is a list of operators associated with the component.\nThe state initialization for an entity ej is defined by its ordered components:\nkij\nxo (ej) = v; where ci is the i-th component of ej (10)\ni=1\nThe complete list of operators for the simulation is formed by concatenating the operators from all components of all entities, respecting the order of entities and the order of components within each entity:\nO = [O11, O12, ..., O1k\u2081, O21, ..., Onkn] (11)\nwhere Oij is the list of operators from the j-th component of the i-th entity.\nThe state transition function remains similar to the original definition, but now operates on this hierarchically defined set of operators:\nXt+1 = F(xt, Ot, lt) (12)\nwhere or is selected from the ordered list O.\nThis ECS structure in Simulation Streams allows for a modular and hierarchical organization of state variables and operators. It provides a flexible framework for defining complex, multi-entity simulations while maintaining the core principles of Simulation Streams. The ordered nature of components within entities ensures a well-defined execution flow."}, {"title": "Experiments", "content": "The purpose of introducing Simulation Streams is to introduce a direct and effective of running long streams of consistent LLM streams that takes the general form of simulations, even if nothing prevent an operator from being based on interaction with an external environment. This experimental section is showing a few examples including for what simulations could be, and we display how it can be used to compare different models. The most complex example is our long-running market economy simulation where you provide an example of how it can run indefinitely and how novel situations and behaviours keep appearing while adhering to reasonable market behaviours, most clearly seen in the economic cycles that is a ubiquitous pattern.\nA conclusion regarding the performance of the models, is that the recent Gemini-2.0-Flash-Exp model and its thinking version, are eminently suited for the simulation streams framework as it is consistently understanding exactly what they need to produce next. This makes the simulations fast, economical and easy to work with, e.g. Gemini-2.0-Flash shows perfect simulation consistency for the social simulation across 10 runs, even if the much larger Gemini-1.5-pro-002 slightly outperforms it on the RL suite. Simulation Streams is based on the belief that improving models is increasingly capable of running agentic simulations without interference, and then benefits from being used in a minimally interfering manner."}, {"title": "Results and Analysis", "content": "We used our approach to compare different models on six benchmark tasks inspired by the classical reinforcement learning literature (Sutton and Barto, 2018). The tasks include: (1) Windy Gridworld, where an agent must navigate towards a goal while affected by directional wind forces, (2) Key-Chest, where the agent must find and collect a key before accessing a chest, (3) Maze navigation, (4) Mountain Car, where an under-powered car must escape a valley by building momentum, (5) Temperature Control involving maintaining a target temperature within constraints, and (6) Robot Cleaning, where a robot must efficiently clean dirty spots while avoiding obstacles.\nThe format employed includes multiple fields: a summary, a high-level strategic plan subject to selective revision, a detailed implementation plan, action determination and consequent state updates. The initial block before LLM invocation serves as an exemplar, establishing foundational patterns that guide subsequent iterations. These initial examples and their default structures significantly impact the system's trajectory. Maintaining consistency across the initial example fields is essential, and the initial iteration demonstrates how to refer to previously revealed information. The high-level plan functions as the agent's primary agenda, and the initial plan can incorporate various task-relevant strategies. This is exemplified in the mountain car scenario, where the initial plan may include the recognition that alternating backward and forward movements are necessary to generate sufficient momentum before reaching the uphill goal region.\nWe conducted 10 independent runs of 25 steps each across the 6 benchmark tasks. For each task, we collect performance metrics over these runs. The results are presented in Figure 2, where we show both the mean performance (solid lines) and the standard deviation (shaded regions) across all 10 runs. We leave out the standard deviation for the Key Chest tasks as performance variability is here highly related to varying key positions.\nAmong the compared models, Gemini-1.5-Pro-002 consistently outperforms Gemini-1.5-Flash-002 across all six tasks, while Gemini-1.5-Flash-002 demonstrates superior performance over Gemini-1.0-Pro in five out of six benchmark tasks. While Gemini-2.0-Flash-Exp consistently loses to Gemini-1.5-Pro-002, the margin is often narrow. Gemini-2.0-Flash-Exp outperforms Gemini-1.5-Flash-002 in 4 out of 6 tasks, primarily underperforming in tasks where progress must often remain stalled (Key-Chest, where no key might be found for many steps, and Windy Grid World, where after getting somewhat nearer to the target it becomes a battle to avoid being blown further"}, {"title": null, "content": "away again). Finally, Gemini-2.0-Flash-Thinking-Exp-01-21 is improving upon that by also handling windy gridworld well while being the only model performing truly well on the temperature control task. However, also the thinking version of 2.0-Flash is underperforming on the Key-Chest exploration-oriented task. The task stands out as providing no signal for progress or change until the key is found, while maze has a smell of chess indicating nearness and the windy grid world features the distance to target. While the tasks were defined before the arrival of Gemini-1.5, and used to empirically nail down the agent workflow, they are now nearer to saturation with the later models where both 2.0-Flash-Exp-Thinking and Gemini-1.5-pro largely solves 5 out of 6."}, {"title": "Social Simulation", "content": "We implemented a multi-agent social simulation involving three characters (Alice, Bob, and Charlie) engaged in a game of catch, with an additional world entity introducing environmental events. Each character is controlled in its own stream, determining the character's actions and dialogue while maintaining consistency with the game state but without directly controlling other characters' behaviors. The world entity introduces contextual elements such as ice cream trucks and squirrels, enriching the environment without directly interfering with the core game mechanics. The characters observes a summary of the total story from their perspective, produced from the stream seeing all contributions, while the characters contribution is produced only seeing the own stream with the characters observation (worldview) contribution, action and update to the ball state.\nThe simulation runs for 25 time steps, with character responses evaluated against the current game state. Characters can perform actions such as throwing or catching the ball, accompanied by natural language dialogue. Each character starts with a consistency score of 5. When a character's contribution is inconsistent with the game state (e.g., attempting to throw a ball they don't possess), they receive one opportunity to revise their response. If the revised response remains inconsistent, a penalty is applied by decrementing their consistency score by one.\nWe conducted 10 independent runs with the same range of models as above to assess their ability to produce a consistent simulation stream within the simulation streams framework. Figure 3 presents the consistency for each character across these runs, tracking when their responses required correction or incurred penalties.\nGemini-2.0-Flash-Exp maintains complete consistency across each character's 250 decisions, and Gemini-2.0-Flash-Thinking-Exp makes only a handful of mistakes. Gemini-1.5-Pro-002 and Gemini-1.0-Pro show some occasional inconsistency, while Gemini-1.5-Flash-002 exhibits substantially more. Across all simulations, Gemini-2.0-Flash-Exp also demonstrates perfect adherence to generating exactly one additional simulation row in the correct format, resulting in substantially greater speed and economy due to fewer excess tokens and reduced need for resampling, which the framework requires when the generated response doesn't conform to the format."}, {"title": "Market Simulation", "content": "Our simulated economy consists of eight key markets: housing, houses, bread, wood, grain, milk, fish, and labor. The producing entities and the consumers each have their own experience stream, but where the current value of relevant variables such as price and inventories is being"}, {"title": "State Initialization", "content": "The program begins with initialization of the state variables:\ninitial_state = {\n'time': 0,\n'location_x': 0,\n'location_y': 0,\n'move_x': 0,\n'move_y': 0,\n'previous': [],\n'cheese_found': False,\n'planning': False,\n'movement': False\n}\nDefining Operators\nThe core of a Simulation Stream program is a list of operators. Each operator specifies how variables change and when to involve the language model. Here is an example operator list showing part of the cheese-finding program referenced earlier:\noperators = [\n{\n'id': 'Time',\n'formula': 'time = time + 1',\n'use_lm': False,\n'query': {},\n'planning': True,\n'movement': True,\n'summary': True,\n'next': 'Objective'\n},\n{\n'id': 'Summary',\n'formula': 'summary = ...',\n'use_lm': 'time > 1',\n'query': {'summary': True},\n'planning': True,\n'movement': False,\n'summary': True,\n'next': 'Time'\n}\n]"}, {"title": null, "content": "where\nin the summary operator should be a string that shows a useful summary of the first step in that simulation, a step where everything has been determined by initialization and not yet including the large language model that starts generating choices in the second block.\nEach operator in the list contains several key fields:\n\u2022 id: A unique identifier for the operator\n\u2022 formula: The formula that assigns a value to a variable\n\u2022 use_lm: A boolean or condition specifying when to use the language model\n\u2022 query: A dictionary specifying which flags to match when selecting context\n\u2022 planning, movement: Boolean flags indicating the operator's categories\n\u2022 next: The identifier of the operator to execute next\nWhen executed, these operators generate the output stream shown in Figure 2, where some rows are language model-generated while others come from deterministic formulas. The flags (planning, movement) are used to mark rows in the output stream, enabling subsequent operators to selectively query relevant context through their query dictionaries.\nFor example, when the Summary operator executes, it will only receive context from previous"}, {"title": null, "content": "rows where summary=True, ensuring it has access to relevant information without being overwhelmed by unrelated details.\nThe program's execution follows the sequence defined by the next fields, with each operator either executing its formula directly or invoking the language model based on its use_lm condition. This produces a structured output stream that maintains format consistency while leveraging language model capabilities where appropriate."}, {"title": "Entity-Component Organization", "content": "The same program can be organized using the Entity-Component-System (ECS) approach, which provides better scalability and reuse. For our cheese-finding example:\nentities = {\n'world': [\n'heading'\n],\n'agent': [\n'planning',\n'movement',\n'summary'\n]\n}\nvariables = {\n'heading': {\n'time': 0,\n'objective': None\n},\n'movement': {\n'location_x': 0,\n'location_y': 0,\n'move_x': 0,\n'move_y': 0\n},\n'planning': {\n'high_level_plan': None,\n'movement_plan': None\n},\n'summary': {\n'previous': [],\n'cheese_found': False,\n'first_summary': \"...\"\n}\n}\nThis organization splits our previous operator list into components, each associated with specific entities:\n1. The world entity only has a simple heading component 2. The agent entity manages planning, movement, and summary generation\nEach component's operators maintain their original functionality while being organized in a more modular way. This approach makes it easier to add new entities (like additional agents) or components (like communication between agents) to the simulation."}, {"title": "Implementation Details", "content": "The implementation\u00b2 consists of a modular Python codebase that implements an Entity-Component-System (ECS) architecture for simulation management.\nCore Architecture\nThe codebase is structured around a Flask-based web application that provides an interactive web interface for simulation management as well as a command line option. The server handles HTTP requests that drive UI updates and simulation state changes through JavaScript code injection. The main components are:\nA Flask application server (app.py)\nAn ECS editor backend (editor.py)\nSimulation utilities (simulation_utils.py)\nAn expression evaluator (expressions.py)\nA web interface (templates/index.html)\nA configs directory with simulation configuration files\nA venv setup file (setup.sh)\nKey Components\nFlask Application Server\nThe application server handles:\n\u2022 Entity-Component management endpoints\n\u2022 Simulation control and execution\n\u2022 Continuous metric tracking and visualization\nThe server uses route decorators to define endpoints that interface with the ECS editor:\nECS Editor\nThe ECSEditor class serves as the core backend component, managing:\n\u2022 Entity-Component definitions\n\u2022 Variable and operator management\n\u2022 Simulation state\n\u2022 GUI state synchronization\n{\n'entities': {},\n'variables': {},\n'systems_definitions\u2019: {}\n}\nExpression Evaluator\nThe expressions module provides a secure evaluator for executing simulation expressions, incorporating:\n\u2022 Mathematical functions from math\n\u2022 Built-in Python functions\n\u2022 String manipulation methods\n\u2022 Statistics functions\n\u2022 Custom extensions\nThe evaluator uses the SimpleEval library.\nSimulation Utilities\nThe utilities module provides core simulation functionality including for:\n\u2022 The simulation stream generator\n\u2022 State transitions and output stream generation\n\u2022 Querying history for sub-stream generation\nCommand line options\nThe system supports various configuration options through command-line arguments:\necs_file (optional) Path to the ECS configuration file\n-web Flag to launch the web interface Default: False\n-steps Number of simulation steps Default: 10\n-metrics Metrics tracking file path Default: None"}]}