{"title": "Bridging Neural Networks and Wireless Systems with MIMO-OFDM Semantic Communications", "authors": ["Hanju Yoo", "Dongha Choi", "Yonghwi Kim", "Yoontae Kim", "Songkuk Kim", "Chan-Byoung Chae", "Robert W. Heath, Jr."], "abstract": "Semantic communications aim to enhance transmission efficiency by jointly optimizing source coding, channel coding, and modulation. While prior research has demonstrated promising performance in simulations, real-world implementations often face significant challenges, including noise variability and nonlinear distortions, leading to performance gaps. This article investigates these challenges in a multiple-input multiple-output (MIMO) and orthogonal frequency division multiplexing (OFDM)-based semantic communication system, focusing on the practical impacts of power amplifier (PA) nonlinearity and peak-to-average power ratio (PAPR) variations. Our analysis identifies frequency selectivity of the actual channel as a critical factor in performance degradation and demonstrates that targeted mitigation strategies can enable semantic systems to approach theoretical performance. By addressing key limitations in existing designs, we provide actionable insights for advancing semantic communications in practical wireless environments. This work establishes a foundation for bridging the gap between theoretical models and real-world deployment, highlighting essential considerations for system design and optimization.", "sections": [{"title": "I. INTRODUCTION", "content": "As next-generation wireless networks push toward more efficient and intelligent data delivery, conventional digital communication paradigms\u2014based on separate source coding, channel coding, and modulation-begin to show their limitations. While classic information-theoretic results [1] support this modular structure, real-world conditions often deviate from the ideal assumptions of large block lengths, stationary channels, and additive white Gaussian noise (AWGN) channel. As a result, practical systems struggle to fully realize the theoretical gains promised by such layered approaches [2].\nSemantic communications have emerged as a promising alternative, integrating source and channel coding within a single, end-to-end learning framework [3], [4]. Rather than focusing solely on symbol-level accuracy, semantic systems directly map application-relevant information such as key visual features [5], [6] or essential text components [4], [7] into symbols. This approach has demonstrated notable improvements over traditional methods in simulations, achieving better performance across metrics ranging from mean squared error to perceptual similarity [4]\u2013[7]. However, their end-to-end design, which bypasses traditional bit-based processing and directly operates on symbols, inherently increases their susceptibility to channel noise and variability. This raises a critical question: Can the theoretical and simulated gains of semantic communications be reliably achieved in real-world wireless scenarios?\nIn this paper, we provide new insights into how realistic communication components and settings limit semantic communications, and suggest approaches for overcoming these limitations. To understand the feasibility, we anchor the discussion around the lessons learned from implementing a MIMO-OFDM prototype. We address challenges commonly overlooked in simulations, such as power amplifier (PA) nonlinearity and varying noise levels across subcarriers and data streams. Our measurements reveal how these factors degrade performance and explain previously observed gaps between simulated and experimental results, offering insights into the feasibility of semantic communications in practical systems and providing key considerations for system design. To the best of our knowledge, this is the first work to validate the performance of semantic communications in MIMO-OFDM environments. Our contributions are as follows:\n\u2022\tWe examine challenges encountered in real wireless environments, such as error variations across subcarriers and data streams, to identify the causes of performance deviations between simulations and prototype results.\n\u2022\tWe demonstrate that semantic communications can achieve near-theoretical performance in real systems when channel variations are properly addressed.\n\u2022\tWe validate that peak-to-average-power ratio (PAPR) mitigation techniques, which typically degrade performance in statistical channel-based simulations without PA nonlinearity, can enhance system performance in practical systems within the nonlinear power region.\n\u2022\tWe make our source code and hardware setup publicly available\u00b9 to provide a foundation for developing semantic communications systems in real-world conditions."}, {"title": "II. AN OVERVIEW OF SEMANTIC COMMUNICATIONS", "content": "In this section, we introduce the typical architecture of semantic communications systems and compare it to conventional communications systems. Fig. 1 illustrates the basic building blocks of conventional and semantic communications system models.\nIn traditional communication systems, transforming input data into in-phase and quadrature-phase (I/Q) symbols involves multiple stages, including source coding (e.g., JPEG), channel coding (e.g., LDPC), and modulation (e.g., QAM). The output of the source and channel coding blocks is in the form of bits, which are then converted into complex values during the modulation stage.\nIn contrast, semantic communications systems bypass this bit-based processing by directly mapping input data (e.g., images) to wireless symbols. This method eliminates the need for separate source coding, channel coding, and modulation stages. By jointly optimizing these components with an end-to-end training approach, semantic communications systems enhance efficiency and performance. They consist of an encoder that reduces the dimensionality of the input and a decoder that generates the desired output from the encoded data, typically constructed using deep neural networks.\nThe primary objective of the encoder neural networks in semantic communications systems is to produce complex symbols suitable for wireless transmission. To achieve this, the encoder processes the input data to generate features significantly smaller than the original input, effectively compressing the data. These real-valued features are then paired to form complex-valued symbols. A channel layer is incorporated to mimic the physical wireless channel. As the channel layer should be differentiable for training, it typically consists of simple statistical channel models such as AWGN or Rayleigh fading channels. The impaired symbols are then unpacked into corrupted, real-valued features and passed to the decoder.\nThe decoder's role is to effectively achieve predefined goals using the corrupted features. These goals can vary, ranging from accurate reconstruction (e.g., image or text reconstruction) to analysis tasks (e.g., object detection or image classification) based on the input data. The extent of achievement is measured using a loss function, which could be a perceptual metric, mean squared error (for reconstruction tasks), or classification accuracy, depending on the system's configuration. As the encoder and decoder jointly learn to achieve these goals despite channel-corrupted symbols, the encoder is trained to generate noise-robust wireless symbols, while the decoder is optimized to efficiently realize the objectives from the encoder-produced symbols.\nThis end-to-end training process of the semantic communications system, as demonstrated in prior work [5]-[8], has shown improvements in transmission efficiency compared to traditional systems. Transforming features into wireless symbols, however, requires conscientious handling, mainly when those neural network-generated symbols are transmitted over actual wireless channels. We investigate the procedures of symbol transmission and identify the associated challenges in the following sections."}, {"title": "B. Prior Work", "content": "There have been few implementations of wireless semantic communications prototypes. The first effort to implement and validate semantic communications in a wireless environment is documented in [9], [10]. Using the NI USRP software-defined radio (SDR) device, this work revealed discrepancies between simulated results and real-world measurements in decoded image quality. [11], [12] also validated the performance of semantic communications using the USRP, implementing an OFDM-based wireless transmission system. However, they reported significant performance gaps in the lower transmit power region [11] and did not compare favorably to simulated results [12]. Furthermore, all these implementations are based on single-input single-output (SISO) systems, unlike modern communication systems that use multiple transceiver chains.\nThere have also been prior work addressing practical challenges in implementing semantic communication systems, such as PAPR issues and channel quality adaptation. To address the high PAPR problem in semantic communication systems, [13] proposed PAPR reduction methods. They demonstrated a performance-PAPR tradeoff in the semantic communications model, as PAPR reduction limits the representation power of the symbol. However, they only showed degraded performance with PAPR-restricted models and did not demonstrate actual improvement in the nonlinear power region, as their evaluation was solely based on AWGN simulations.\nSome prior work has explored adaptive encoding and decoding techniques based on given signal-to-noise ratio (SNR) values [12], [14]. These studies focus on training a single neural network to handle various SNRs, in contrast to typical semantic communications models which train separate neural networks for different target SNR values. These approaches, however, still assume a uniform SNR level for all symbols and do not account for varying SNRs for individual symbols.\nOther approaches have trained neural networks using statistical fading channel models, such as Rayleigh fading [5], [10], to account for scenarios where each symbol experiences different channel qualities. These models, however, were not truly channel-adaptive; instead, they relied on the encoder and decoder to implicitly learn channel statistics from channel-equalized symbols. Additionally, none of this work validated their system performance with prototypes in practical scenarios. Our article highlights the need for channel-adaptive semantic communications models through prototype measurements, complementing these previous studies."}, {"title": "III. CHALLENGES AND APPLIED SOLUTIONS", "content": "Transmitting I/Q symbols from neural networks via wireless channels involves various challenges, primarily due to hardware constraints related to analog-to-digital converters (ADCs), digital-to-analog converters (DACs), and PAs. This section explores the challenges associated with neural network-based symbol generation and specifically how we address them in our prototype implementations."}, {"title": "A. Fixed Point Representations", "content": "Neural networks typically use 32-bit floating-point numbers in graphics processing units (GPUs). In wireless transmission, however, converting these digital symbols into voltages suitable for an antenna requires a fixed-point format. This is because the ADC and DAC of the transceiver internally use a fixed-point format, which limits the signal's dynamic range and resolution.\nFor instance, the ADC and DAC in the NI USRP-2953R SDR device support peak-to-peak voltage values (Vpp) of 1, restricting signal amplitudes to the range [-1,1]. If the neural network generates symbols exceeding this range, signal clipping may occur. To address this issue in our prototype implementations, we apply a normalization factor $N$ to scale the generated symbols, ensuring they remain within the allowable amplitude limits. The normalization process involves scaling the symbol by the constant $N$ and then applying a clipping function to restrict the values to the range [-1,1]. The resulting normalized and clipped symbol is then ready for transmission.\nFixed-point representations in transceiver hardware also typically offer lower resolutions (commonly 14 or 16 bits) than floating-point formats, potentially leading to quantization errors. However, we conclude that the effects of symbol quantization due to fixed-point representations may be negligible for common ADC/DAC resolutions, as we observe no performance difference across a range of quantization levels. This is because the quantization noise level is significantly lower than the typical noise level in wireless channels. For instance, with a 14-bit fixed-point representation, the signal-to-quantization-noise ratio (SQNR) is approximately 22 dB when the signal uses only a quarter of the available range (e.g., [-0.25, 0.25]). Since typical SNR in communication systems ranges from 0 to 20 dB, we do not apply additional methods to mitigate quantization effects."}, {"title": "B. Varying SNR Across Frequencies and Streams", "content": "In practical OFDM systems, channel gain and noise vary across frequencies due to frequency-selective fading and hardware imperfections. In MIMO systems, different spatial streams can experience varying SNR levels due to antenna patterns, MIMO equalization, and other factors. As a result, symbols transmitted over different subcarriers and streams can experience different SNRs, leading to non-uniform and possibly multimodal symbol error distributions.\nFig. 3 shows the error of a signal across the subcarrier index and MIMO data streams transmitted in our wireless prototype (blue) and the error with shuffled symbols before transmission (red). These error variations result in varying SNR conditions for symbols that are simultaneously fed into the semantic encoder. We hypothesize that these SNR variations cause the inconsistencies between simulation results and real-world data reported in prior work.\nTo support this hypothesis, inspired by the results in Fig. 3, we mitigate this variance by shuffling the symbol sequence before mapping the symbols to resource blocks, similar to interleaving in conventional communication systems. This ensures that every adjacent symbol experiences the same average level of channel and noise, bringing the practical system closer to the AWGN assumption. By doing this, we conclude that the performance gap between simulations and prototype results reported in previous works [10], [14] is mainly due to these phenomena. We also show that near-AWGN performance can be achieved if those channel variations are conscientiously addressed."}, {"title": "C. PAPR and PA Nonlinearity", "content": "In actual wireless transmission systems, significant variations in symbol power levels can cause high PAPR and nonlinear signal distortion. This distortion occurs because the gain of a PA varies with the amplitude of the input signal. This issue is exacerbated in semantic communications systems, where typical 95th percentile PAPR values are around 9.8 dB, compared to 8.5 dB for 16-QAM in 72-subcarrier OFDM environments.\nTo mitigate this issue, as in prior work [13], [15], we used a loss-based method to control the PAPR of the symbols. We introduced a PAPR penalty term in addition to the original mean squared error (MSE) loss, with a multiplier $\\lambda_{PAPR}$ for the PAPR term.\nFig. 4 illustrates the effect of PAPR reduction on the symbol constellation and the PA's nonlinear behavior. In Fig. 4, three constellation diagrams are shown for different PAPR constraints: baseline (no PAPR constraint), weak PAPR regulation, and strong PAPR regulation. We used $\\lambda$ values for the PAPR loss of 0, 32768, and 4096, respectively. The baseline model displays widely dispersed symbols with a high PAPR of approximately 7.6 dB, increasing susceptibility to distortion. Introducing weak PAPR regulation tightens the symbol clustering, reducing PAPR to around 6.6 dB and slightly improving the PSNR. Strong PAPR regulation further confines the symbols near the origin, lowering PAPR to about 4.3 dB and achieving the highest PSNR, albeit with reduced symbol representation power. Due to this reduced representation power, in simulated channels without PA nonlinearity, this additional loss results in performance degradation due to the reduced representation power of the encoded symbols [13].\nIn a real wireless setup with PA nonlinearity, however, the model with reduced PAPR can outperform the baseline model despite the performance degradation from the PAPR reduction. Higher PAPR symbols from the baseline model extend into the PA's nonlinear region, causing significant distortion. In contrast, PAPR-reduced models remain within the linear operating range of the PA, minimizing distortion and enhancing signal quality."}, {"title": "IV. PROTOTYPE IMPLEMENTATIONS", "content": "We implemented a wireless semantic communications prototype targeting image reconstruction, comprising neural network processing and wireless transmission. The neural network runs on a GPU server equipped with an Nvidia RTX 2080 Ti, while the wireless transmission is managed by an NI USRP-2953R SDR device. Fig. 2 depicts the MIMO-OFDM system setup.\nOur neural network integrates convolutional neural networks with the Transformer architecture, following [10]. The encoder converts a 32 \u00d7 32 \u00d7 3 color image into 512 complex symbols, normalized with a constant $N = 3$.\nThese symbols are modulated to baseband signals using OFDM with an FFT size of 128 and 72 subcarriers, following LTE standards for a 1.4 MHz bandwidth. We excluded DC frequencies to avoid distortions from RF hardware bias. Each subcarrier spacing is 15 kHz with a symbol duration of 66.67 \u03bcs. For synchronization, Zadoff-Chu sequences are employed due to their excellent autocorrelation properties.\nPilot signals, consisting of 4-QAM modulated predefined bit sequences, are inserted in the first symbol of every 7-symbol block for MIMO channel estimation. Specifically, pilots are placed on alternating subcarriers for each transmit antenna (e.g., odd subcarriers for antenna 0 and even for antenna 1). We adopted open-loop spatial multiplexing with zero-forcing (ZF) receivers in a 2x2 MIMO configuration, but the system can be simply extendable to any MIMO configuration. All antennas were positioned in a line-of-sight (LoS) environment with limited scattering, as shown in Fig. 2.\nEncoded baseband samples are transmitted via the NI USRP SDR device at a center frequency of 2 GHz, connected to the GPU server through a 1 Gbps Ethernet link using the USRP Hardware Driver (UHD). We used Python for baseband and neural network signal processing. Transmitter and receiver gains range from 0 to 31.5 dB.\nFor power amplification, we utilized the Mini-Circuits ZVA-183W-S+, offering a 28.6 dB gain at a 15 V input. In PAPR-related experiments, the PA operated at 15 V to induce nonlinearity; otherwise, the PA was bypassed to maintain linearity.\nUpon reception, signals are forwarded to the GPU server for decoding. Channel estimation employs linear interpolation in the time domain and nearest neighbor interpolation in the subcarrier domain. Using the estimated channels, ZF combining is applied, and the decoder neural network reconstructs the final image from the decoded symbols.\nWe opted for open-loop spatial multiplexing without MIMO precoding due to negligible performance gains in our 2x2 setup and the added complexity and instability from feedback mechanisms required for precoding. Nonetheless, our open-source code includes partial implementations of MIMO precoding for future exploration."}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "We assessed reconstructed image quality using peak signal-to-noise ratio (PSNR), calculated for a 256 \u00d7 256 image composed of 64 independent 32 \u00d7 32 CIFAR-10 test images unless stated otherwise.\nAs a baseline, we used LDPC codes combined with the BPG image format\u00b2 and QAM modulation, representing state-of-the-art error correction and image compression techniques. The BPG format, based on the HEVC standard, is highly efficient among non-neural image codecs. For PSNR evaluation, we employed 4:4:4 chroma subsampling. Notably, BPG processes the entire 256 \u00d7 256 image, unlike our semantic system's block-wise 32 \u00d7 32 approach, which may offer PSNR advantages.\nFor the semantic communications system, models were trained under AWGN channels at SNRs of {0,5, 10, 15, 20} dB using the CIFAR-10 dataset and the Adam optimizer with a learning rate of 1e-4. Unless otherwise specified, we selected the model that best matched the SNR value observed in the wireless prototype. The bandwidth ratio, defined as the ratio of the number of complex symbols to the number of pixels, was set to 1/6, equating to 512 symbols per image. Processing a 256 \u00d7 256 image involved encoding 64 32 \u00d7 32 images, resulting in 64 x 512 = 32, 768 symbols.\nOur system directly generates I/Q symbols without traditional modulation schemes like QAM, enabling exploration of end-to-end optimization benefits without modulation constraints. This differentiates our setup from existing testbeds [12], which rely on quantization and conventional modulation, potentially introducing non-Gaussian noise characteristics.\nFor the BPG+LDPC+QAM configuration, we explored various combinations of LDPC code rates and modulation methods. Specifically, we selected channel code rates from the set {(3072, 6144), (3072, 4608), (1536, 4608)}, corresponding to code rates of 1/2, 2/3, and 1/3, respectively. We considered QAM modulation with orders of {4, 16, 64, 256} and report"}, {"title": "B. Transmission Performance in the Linear Power Region", "content": "To assess the system's performance, we plot the decoded image quality (PSNR) against the receiver SNR (Rx SNR), defined as the power ratio between the transmitted symbol and the errors arising from sources such as channel noise, imperfect channel estimation, and PA nonlinearity. Here, the Rx SNR is computed using the error vector magnitude (EVM). Since the errors are not perfectly Gaussian distributed, the actual performance of the prototype would be equal to or less than the simulated AWGN channel at the same Rx SNR. Thus, the gap between the simulated and prototype results at the same Rx SNR reflects the non-Gaussian nature of the symbol error.\nAs shown in Fig. 5a, the semantic communications systems outperform conventional BPG+LDPC+QAM systems across all regions in both simulated and prototype results, demonstrating their effectiveness in real-world scenarios. Moreover, as we hypothesized in the previous sections, the prototype results with symbol shuffling closely align with those from the simulated AWGN channel, while a gap that expands with decreasing Rx SNR is observed without shuffling. This finding aligns with previous studies [10], [11], indicating that the gap identified in earlier research is primarily due to noise level variations between subcarriers and streams.\nNotably, we observe no performance difference between BPG+LDPC+QAM results with and without shuffling. Note that LDPC performs interleaving within its block size, but this interleaving is equivalent to or less effective than shuffling since the block size spans only one or two images. The likely reason for no difference is that the conventional BPG+LDPC+QAM system relies on quantized modulations and error correction, providing some safety margins against noise level variations. However, in semantic communication systems, where the received symbols are directly fed into the decoder, these error distributions directly impact system performance. Therefore, it is more crucial to handle these effects appropriately in semantic communication systems than in conventional systems.\nThese prototype results provide insight into how channel variations and resource allocations affect the performance of semantic communications systems in real environments, a topic not extensively covered in existing literature. They also validate the need for channel-adaptive semantic communications models, which provide actual channel information along with the symbols to the neural network for adaptive decoding. This approach is analogous to traditional communication systems, where modulation and coding scheme (MCS) information for each subcarrier or stream is necessary for optimal performance."}, {"title": "C. Transmission Performance Based on PAPR Values in the Nonlinear Power Region", "content": "To assess the reduction in nonlinearity due to decreased PAPR, we transmitted symbols from both the baseline and the low PAPR model, trained at 20 dB SNR, through a highly nonlinear PA region. We did not apply random shuffling of symbols in these experiments, as it affected symbol PAPR values.\nAs shown in Fig. 5b, both PSNR and Rx SNR increase with input power up to 0 dBm, then decline due to the distortion caused by PA nonlinearity. In this high-power, nonlinear region, models that incorporate PAPR reduction techniques exhibit approximately a 1 dB improvement in Rx SNR. This enhancement is attributed to the reduced PAPR, which minimizes the distortions introduced by the PA's nonlinear operation, thereby maintaining higher signal quality despite the increased input power.\nInterestingly, while the weak PAPR reduction model outperforms the baseline in terms of PSNR in the 2.5 dBm or higher power region, the strong PAPR reduction model does not. This is due to the performance-PAPR tradeoff (see Fig. 4); excessive PAPR restriction leads to a performance drop that outweighs the benefits of reduced PAPR, resulting in overall lower PSNR despite similar Rx SNR levels. This indicates that PAPR reduction should be balanced to avoid diminishing returns."}, {"title": "VI. OPEN ISSUES", "content": "Signal Processing Techniques for MIMO-OFDM Semantic Communications: We demonstrated that symbol mapping to resource blocks or streams affects system performance. While we employed basic symbol shuffling and ZF-based channel equalization, advanced techniques like MIMO precoding or optimized resource allocation could further enhance performance. Although MIMO precoding offers limited benefits in our 2x2 setup due to few antennas and feedback complexity, it may be advantageous in larger MIMO configurations.\nReal Channel-based Training of Semantic Communications Models: Training semantic communication models with actual channel measurements can enhance reliability by capturing site-specific characteristics such as obstructions and interference patterns. However, this may lead to overfitting and reduce generalizability. Therefore, balancing adaptation to real channels with robustness across diverse scenarios is essential.\nAdaptation to Modern Communication Systems: For integration into future wireless technologies, semantic communications must be validated with advanced techniques like massive MIMO and full-duplex (FD) systems. Additionally, testing in challenging scenarios such as high mobility or urban environments and dynamically adapting to varying channels is crucial [14].\nEfficient and Adaptive Semantic Communications Systems: Semantic communications often utilize complex neural networks that introduce high latency, hindering real-time functionality. Developing lightweight architectures and applying model compression and quantization techniques can significantly reduce latency and computational demands, making systems more practical for real-time applications."}, {"title": "VII. CONCLUSION", "content": "We developed a MIMO-OFDM-based wireless semantic communications system to investigate the impact of channel variations and resource allocations on real-world performance. Our findings indicate that the performance gap between simulations and prototypes is primarily due to varying SNR levels across symbols. By implementing techniques such as symbol shuffling, our prototype achieved performance comparable to simulations, highlighting the need for channel-adaptive semantic communication models. Additionally, we demonstrated that PAPR reduction techniques can enhance performance by mitigating power amplifier nonlinearity effects, despite the tradeoff between PSNR and PAPR. Our source code and hardware setup are publicly available for further validation.\nWhile this study focused on reconstruction-based semantic communication, the methods and insights can be extended to other tasks like classification and detection. We believe these findings will drive future innovations and promote the broader adoption of semantic communication systems in practical applications."}]}