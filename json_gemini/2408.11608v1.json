{"title": "Don't Kill the Baby!\nThe Case For AI in Arbitration", "authors": ["Michael J. Broyde", "Yiyang Mei"], "abstract": "Since the introduction of Generative AI (GenAI) in 2022, its ability to simulate human intelligence\nand generate content has sparked both enthusiasm and concern. While much of the criticism focuses\non Al's potential to perpetuate bias, create emotional dissonance, displace jobs, and raise ethical\nquestions, these concerns often overlook the practical benefits of AI, particularly in legal contexts.\nThis article examines the integration of AI into arbitration, arguing that the Federal Arbitration Act\n(FAA) allows parties to contractually choose AI-driven arbitration, despite traditional reservations.\n\nThe article makes three key contributions: (1) It shifts the focus from debates over AI's personhood\nto the practical aspects of incorporating AI into arbitration, asserting that AI can effectively serve as\nan arbitrator if both parties agree; (2) It positions arbitration as an ideal starting point for broader AI\nadoption in the legal field, given its flexibility and the autonomy it grants parties to define their\nstandards of fairness; and (3) It outlines future research directions, emphasizing the importance of\nempirically comparing AI and human arbitration, which could lead to the development of distinct\nsystems.\n\nBy advocating for the use of AI in arbitration, this article underscores the importance of respecting\ncontractual autonomy and creating an environment that allows AI's potential to be fully realized.\nDrawing on the insights of Judge Richard Posner, the article argues that the ethical obligations of AI\nin arbitration should be understood within the context of its technological strengths and the voluntary\nnature of arbitration agreements. Ultimately, it calls for a balanced, open-minded approach to AI in\narbitration, recognizing its potential to enhance the efficiency, fairness, and flexibility of dispute\nresolution.", "sections": [{"title": "Introduction", "content": "Since the introduction of Generative AI (GenAI) in 2022, extensive discussions have highlighted its\nimpressive capabilities in simulating human intelligence and generating novel content. Despite these\nremarkable functionalities, there is consensus that, if not carefully managed and fine-tuned, GenAI\u2014\nespecially when applied through Large Language Models (LLMs)\u2014can be fundamentally harmful and\ndiscriminatory toward marginalized groups. In the workplace, Artificial Intelligence (AI) systems used\nfor hiring, promotions, and other Human Resources (HR) tasks may perpetuate biases by learning\nfrom historical data. Additionally, AI chatbots and virtual assistants, though capable of mimicking\nhuman interactions, lack genuine empathy and human connection. This can lead to emotional\ndissonance, where users feel temporarily understood without receiving the deeper emotional support\nthat real human relationships provide. Furthermore, AI's efficiency in automating tasks could result\nin significant job displacement, and its proficiency in analyzing large datasets might enable the\ncreation of personalized content, raising critical ethical questions about consent, manipulation, privacy,\nand the potential impact on democracy and personal autonomy.\n\nWhile criticisms of GenAI are valid and well-founded, they often overlook the technology's efficiency\nand cost-effectiveness. GenAI excels in processing and analyzing data at speeds unattainable by\nhumans, reducing overall costs, accelerating decision-making processes, and enhancing accuracy in\nvarious applications. Moreover, GenAI supports remote work, education, and medical\nconsultations, reducing the need for physical travel, especially when time is constrained. It makes\nhealthcare more accessible -- in regions with scarce health resources, GenAI provides on-demand,\naccessible care by offering diagnostic assistance, managing patient data, and facilitating remote\nmonitoring and consultations. More importantly, it demystifies medical jargon for laypeople who\nlack access to primary physicians for explanations, bridging the service gap for underserved\npopulations.\n\nGiven these observations, there is a notable disparity between the concerns highlighted in harm-\nfocused academic literature and the actual applications of GenAI in real-life settings. The essential\nquestion is not merely about how GenAI falls short of expectations or fails to meet people's needs,\nnor solely about the harms GenAI might inflict on society. Instead, the discussion should focus on\nexploring the tangible benefits and challenges of deploying AI in everyday contexts. When the\nadvantages substantially outweigh the disadvantages, how should AI's integration be managed within\nexisting legal frameworks? What modifications or reforms are necessary to ensure that AI deployment\nleads to more universally accessible resources and improved lifestyle choices?\n\nThis article addresses these questions within the context of arbitration. It explores whether AI should\nbe integrated into arbitration processes where decisions need to be made swiftly and cheaply and\nwhether such integration aligns with the current legal framework. It argues that the Federal Arbitration\nAct (FAA) almost uniquely among Federal laws allows such unconventional adjudication methods,\nprovided both disputants agree by contract to use AI as their preferred method for resolving disputes.\nFurthermore, this article contends that arbitration is the ideal starting point for integrating AI in the\nlegal space, as it operates with a lower threshold for fairness compared to traditional court systems.\n\nThis article makes several contributions:\n\n1. Focus on Practical Integration: It dismisses concerns about whether AI qualifies as a person\nand instead focuses on the practical issues of integrating AI into the arbitration process. It\nasserts that AI can serve as an arbitrator, regardless of its liability and entity status, as long as\nboth disputants agree by contract. The authors acknowledge that the current scholarship in\nComputer Science, Human-Computer Interaction, and (Bio)Informatics discourages the use\nof AI to replace humans, advocating instead for AI to augment human decision-making. However, we argue that in the context of arbitration, parties have the freedom to choose their\npreferred method. When informed, reasonable, and sensible adults make such a choice, third\nparties have no grounds to paternalistically forbid the practice based on a perceived lack of\nempathy or potential for discrimination.\n\n2. Arbitration as a Starting Point: We propose that arbitration is the starting point for an AI\nrevolution in the legal domain. In arbitration, parties seek a system that aligns with their\nstandards of fairness, which may differ from the objective standards upheld in conventional\nlitigation. These early practices can serve as a basis for experimentation and provide data for\nlater empirical analysis.\n\n3. Future Scholarship Directions: We discuss that future scholarship should focus on studying\nand investigating the differences between AI arbitration and human arbitration, specifically in\ndetermining the contexts in which AI is more suitable and the circumstances where humans\nare more appropriate. Rather than spending extensive efforts to make GenAI more like\nhumans and preventing over-reliance on machines, it is possible that there could be two\ndistinct systems for arbitration in the future: one traditional, involving only humans, and\nanother combining humans and AI, with all the disadvantages and drawbacks currently\ndiscussed.\n\nThe first part establishes that using GenAI in arbitration is consistent with the principles of the FAA,\nemphasizing that disputants have the discretionary power to shape their arbitration processes. The\nsecond part addresses resistance to AI's introduction in the legal sphere, challenging critics' arguments\nby highlighting that biases and errors often originate from humans rather than being inherent flaws of\nAI. It advocates for creating a conducive environment to positively influence AI's acceptance and\neffectiveness. The third part concludes the article and proposes future directions."}, {"title": "Part I. AI and the Federal Arbitration Act", "content": "This part argues that substituting AI as the arbitrator is consistent with the FAA. It includes three\nsections:\n\n1. Defining AI as an Arbitrator:\n\nThe first section proposes a new definition of AI as an intelligent and autonomous system based on\nmachine learning algorithms, capable of delivering results satisfactory to the parties. This definition\nemphasizes AI's ability to analyze data, learn from it, and make decisions autonomously, ensuring that\nthe arbitration process remains efficient and unbiased.\n\n2. Aligning AI with the FAA:\n\nThe second section argues that using AI as the arbitrator aligns with the FAA. It explains that the\nFAA's framework allows for flexibility in the arbitration process, enabling the use of innovative\ntechnologies like AI. As long as both parties consent to AI arbitration through their contractual\nagreement, the FAA supports such unconventional methods of dispute resolution.\n\n3. Benefits of AI in Arbitration:\n\nThe third section discusses the benefits of integrating AI in arbitration. It suggests that using AI as\nthe arbitrator is cost-effective, reducing expenses associated with human arbitrators and lengthy\nprocedures. Additionally, AI can meet the parties' personal, subjective standards of fairness by\nproviding consistent and unbiased decisions. Furthermore, deploying AI in arbitration is a strategic\nstarting point for an AI revolution in the legal system. As arbitration has gradually become more\njudicialized over time, incorporating AI can streamline processes and set a precedent for broader AI\nintegration in legal practices."}, {"title": "1. What is AI", "content": "AI is extensively used across various domains. In finance, for example, AI facilitates know-your-\ncustomer (KYC) checks and anti-money laundering (AML) monitoring. In tenant screening, AI\nconducts background checks, automating the retrieval and analysis of a candidate's financial history,\ncriminal records, and previous rental agreements. Using natural language processing (NLP), AI can\nanalyze a tenant's online interactions to gauge their reliability and character. In drug discovery, AI\nrevolutionizes nearly every stage of the process, from target identification and molecular simulations\nto prediction of drug properties, de novo drug design, and synthesis pathway generation. In content\ngeneration, AI has been used to write books in hours that win national competitions and help artists\nwin awards for paintings. Regardless of the users' identity\u2014be it painter, musician, or writer\u2014AI\nenhances the artistic journey through inspiration, idea generation, and visual exploration. Since the\ndebut of ChatGPT, AI has proliferated across various fields.\n\nThe proliferation of AI applications requires clear definitions, as \u201cAI\u201d is an umbrella term\nencompassing a wide range of computing approaches and algorithms, including deep learning,\nrobotics, expert systems, and NLP. Generally, there are three types of definitions: capability-based,\nprocess-based, and goal-oriented. Capability-based definitions focus on what AI can do, such as\nunderstanding natural language, recognizing patterns, solving problems, and learning. Process-based\ndefinitions emphasize how AI systems operate. Goal-oriented definitions center on the expected\noutcomes of AI, such as augmenting human capabilities or automating decision-making processes.\nDifferent organizations use these definitions interchangeably. For instance, IBM focuses on AI's\nfunctional and solution-oriented aspects, while McKinsey emphasizes its human-like capabilities.\n\nThese varying definitions create confusion about which AI is being discussed. They also affect people's\nperceptions of algorithmic decision-making systems, their evaluations of systems in application\ncontexts, and the replicability of research findings. For example, terms such as \u201ccomputers\u201d or\n\"robots\" are more likely to be perceived as tangible compared to \u201calgorithms\u201d or \u201cartificial\nintelligence.\u201d \u201cComputer programs\u201d might be perceived as less complex compared to \u201cartificial\nintelligence,\u201d and \u201ccomputer\u201d might be associated with an entity more controllable than a \u201crobot.\u201d\nThese different terms affect people's perceptions and treatment of the entity.\n\nTo avoid confusion, computer scientists and researchers in Human-Centered Computing use specific\nand well-defined terms such as \u201clanguage models\u201d or \u201cmachine learning algorithms.\u201d Although both\ncount as \u201cAI,\u201d they refer to vastly different things. Language models, used in NLP, focus on\nunderstanding and generating human language, replicating human communication. Machine-\nlearning algorithms are decision-making tools that analyze data and provide solutions or\nrecommendations based on training data. The former mimics human interaction; the latter prioritizes\nanalytical efficiency. Conflating them misses important details. To effectively evaluate the role of AI\nas an arbitrator in alternative dispute resolution, it's crucial to define precisely what AI means in this\ncontext.\n\nIt's important to note, however, defining AI merely by its technological features, focusing solely on\nalgorithms and computational abilities, risks overemphasizing its decision-making capacity while\nneglecting the normative frameworks essential to arbitration. Alternatively, viewing AI as a quasi-\narbitrator that mimics human behavior could mistakenly attribute human qualities like consciousness\nand independent thought to these systems. Therefore, we should define AI as an intelligent and\nautonomous system, driven by machine learning, capable of reaching conclusions satisfactory to all\nparties involved in arbitration. This definition should clarify key concepts: \u201cintelligence,\u201d\n\u201cautonomous systems,\u201d \u201cmachine learning,\u201d and the system's ability to satisfactorily resolve disputes."}, {"title": "a. Definition of AI in arbitration", "content": null}, {"title": "Intelligence", "content": "Intelligence, derived from the Latin \"intelligentsia,\u201d means \u201cunderstanding, knowledge, power of\ndiscerning; art, skill, and taste.\u201d Cognitive scientists define it as the ability to learn from experience\nand to adapt to, shape, and select environments.\u201d In AI arbitration, an intelligent system is one that\nis capable of learning from training data, discovering hidden patterns, transforming embedded\ncharacteristics, processing user prompts, and adjusting content based on instructions. Here, \u201clearning\"\ndoesn't mean the acquisition of information based on previous conscious experience; similarly,\n\u201cintelligence\u201d doesn't imply that the system can consciously understand natural language or reflect on\nsemantic meaning. The system's lack of conscious understanding shouldn't matter as long as it\ngenerates reasonable decisions that make sense to the disputants.\n\nFor example, consider John Searle's Chinese Room argument: a person in a room receives Chinese\ncharacters and manipulates them according to a set of rules, despite not understanding Chinese. To\nan external observer, it might appear as though the person understands and communicates fluently in\nChinese. However, the individual is merely following syntactic rules, without genuine\ncomprehension. In AI arbitration, the person in the room represents the algorithm, and the people\noutside are the disputants seeking a resolution. It does not matter whether the algorithm truly\nunderstands the language, as long as it facilitates an intelligent conversation and reaches a decision\nthat makes sense to the disputants.\n\nRequiring conscious understanding and reflection for AI may be overly demanding and an inadequate\ndefense. Sometimes, people learn simply by imitation. As Nicholson Baker advises writers, \u201ccopy out\nthe things that you really love... Put quotation marks around them... You'll absorb the prose more\ndeeply because the act of copying makes you notice elements you would miss by merely reading.\u201d\nDirect copying doesn't involve conscious understanding, yet it serves a purpose for later development.\nSimilarly, in arbitration, conscious understanding isn't always necessary for successful mediation or\ndispute resolution."}, {"title": "Autonomous Systems", "content": "\"Autonomy,\u201d derived from \u201cautonomos,\u201d means \u201cindependent, living by one's own laws.\u201d\n\"Autonomous systems,\u201d in this context, refer to systems that function by their own rules, without\nexternal interference.\n\nIn AI arbitration, the system's capability for being autonomous means that it is capable of\nindependently navigate the latent space\u2014a complex multidimensional space embedded with learned\npatterns and relationships within data\u2014based on human input such as prompts. An autonomous\nsystem doesn't act with subjective personal strivings. After receiving a user's prompt, which acts as a\ncreative guide, the AI system explores this latent space, applying its training to meld learned elements\ninto something novel. The user, rather than being passive, participates as an originator and evaluator\nof the final output. The machine's autonomy is thus collaborative and exercised within a social\nstructure influenced and validated by humans."}, {"title": "Machine Learning", "content": "Machine learning refers to the algorithms used in generating decisions. It is a field of study that gives\ncomputers the ability to learn without being explicitly programmed. Different learning models\ninclude supervised learning, unsupervised learning, and transfer learning."}, {"title": "Supervised Learning:", "content": "Supervised learning uses labeled datasets to train algorithms, which learn to predict outcomes and\nrecognize patterns based on provided data. For instance, consider the following process: imagine\nteaching a student artist to paint. In this analogy, the student represents the algorithm; the samples of\nartwork are like the dataset; the student's final work is the outcome. The student follows detailed\ninstructions that explain the techniques and rationale behind each brushstroke and color choice. By\nrepeatedly practicing these techniques, the student learns to create new artworks in similar styles. In\nsupervised learning, the algorithms undergo a similar repetitive training process as it learns from\nexamples to produce results based on the data they have been trained on."}, {"title": "Unsupervised Learning:", "content": "Unsupervised learning is another form of machine learning where algorithms learn without any labeled\ndata or explicit instructions. In this approach, the model must independently discern its own rules\nand structure the information by identifying similarities, differences, and patterns within the data on\nits own.\n\nUsing a similar example as above: imagine an artist tasked with organizing a vast collection of various\nartworks they've never seen before, without any guidelines or categories provided. As the artist\nnavigates this collection, they must examine each piece, noting styles, themes, and techniques, and\ndecide on a method to categorize and organize the entire collection based on their observations. No\none is there to teach them. The artist, as the algorithms in unsupervised learning, explores the data,\nidentifies patterns, and makes sense of it without prior knowledge or guidance, according to their own\nsystem of organization and understanding. Through this process, unsupervised learning produces\noutcomes."}, {"title": "Transfer Learning:", "content": "Transfer learning involves using a pre-trained model as the starting point for a new, similar task. It\nleverages knowledge from the initial training to improve performance on a new task. For example,\nimagine an artist who has already mastered painting pets and is now moving on to paint wild animals.\nThe artist doesn't start from scratch; instead, they \"transfer\u201d the skills and understanding of animal\nforms, textures, and behaviors from their previous experience with pets to more quickly master the\ndepiction of wild animals. The skills such as handling the brush and mixing colors are reused and\nadapted to this new subject matter, making the transition to a new task smoother and more efficient.\n\nEach of these machine learning methods can be applied to AI arbitration to reduce costs and improve\naccuracy in dispute resolution. Supervised learning would be particularly useful for making predictions\nbased on past data with known outcomes. For example, consider an algorithm analyzing a series of\nemployment disputes involving breaches of contracts. The system could assess the factors leading to\nfavorable outcomes in the labeled dataset and predict outcomes for new cases requiring arbitration."}, {"title": null, "content": "Additionally, because the algorithm can reference the styles of past awards, it can assist in drafting,\nreviewing, and suggesting modifications to legal documents. This capability ensures that the language\nand formatting of awards and dispute resolution documents are consistent, thereby enhancing the\nreliability and professionalism of legal documents in arbitration.\n\nUnsupervised learning, as it excels at discovering hidden patterns and relationships with large datasets,\ncan be used to cluster similar disputes and identify underlying themes or issues that might not be\nimmediately apparent to human arbitrators. For example, when the algorithm is fed thousands of\ncontractual disputes, it could find common factors that result in successful mediation; human\narbitrators can utilize such information to issue more informed arbitration awards in the sense that\nones that historically other parties in similar situations agreed to.\n\nAnd last, transfer learning, when applied in arbitration, can leverage insights gained from one area of\nlaw to enhance decision-making in another similar area. As an example an algorithm trained\nextensively in commercial litigation might be able to apply its learned legal interpretations to disputes\nin employment law; it may also be able to apply rules learned from tort cases to address liability issues\nin medical decision-making. This adaptability reduces the need for extensive retraining and enables\nmore speedy responses to various disputes.\n\nWhen used effectively, all three methods contribute to a more streamlined and efficient arbitration\nprocess, processing vast amounts of information and providing insights at speeds far surpassing\nhuman capabilities."}, {"title": "Reaching Results Satisfactory to the Parties", "content": "Machine learning algorithms can reach decisions satisfactory to disputants by \u201cthinking and acting\nhumanely,\u201d a term borrowed from Stuart Russel and Peter Norvig's definition of AI in Artificial\nIntelligence: A Modern Approach. They proposed four dimensions for considering AI: thinking and\nacting humanly, and thinking and acting rationally. The first category of dimension relates to the\nmachine's ability to perform tasks typically associated with human cognition, such as decision-making\nand problem-solving. The second category of dimension refers to logical thinking processes that are\npresumed to govern mental operations. All dimensions work together to enable AI to deliver results\nthat are acceptable \u2013 perhaps even more acceptable than an arbitration, when cost is factored in to\nthe disputants.\n\nIn the context of AI arbitration, it is important for AI to behave humanly, as it helps them demonstrate\nintelligent and responsive behavior. Alan Turing introduced this concept in the 1950s with the Turing\nTest, which provides a practical operational definition of intelligence. According to the test, if a\nhuman interrogator cannot tell whether responses to their written questions are coming from a person\nor a computer, the machine is deemed intelligent. Key abilities for this task include knowledge\nrepresentation (to store and retrieve information), automated reasoning (to use the information for\nanswering questions and drawing new conclusions), and machine learning (to adapt to new situations\nand identify patterns).\n\nBy acting humanly and rationally, AI builds trust with users, offering immediate, accessible support.\nUsers often attach significant emotional importance to interactions with LLM-based chatbots, turning\nimpersonal exchanges into meaningful relationships. For instance, some users perceive chatbots as\nemotional supports. In a study by Ma et al., users expressed that interacting with chatbots feels like\nhaving someone who enjoys talking to them, responds immediately, and seems to care, even though\nthey recognize it's a computer. This sense of connection persists despite knowing they are interacting\nwith a non-human entity. As the same interviewees elaborated, \u201cIt feels like a more personal\nconversation, even though we both know it's not with another human. For those of us who don't\nhave many people to talk to, it's a comforting space.\u201d\n\nThinking humanly and logically means that AI is more likely to provide rational and comprehensive\nexplanations for its decisions in terms that are understandable and adequate to humans. This process\ninvolves understanding the human mind through introspection, psychological experiments, and brain\nimaging, and then simulating this input-output behavior to mirror human actions.\n\nIn conclusion, the deployment of AI across domains underscores the importance of clearly defining\nand understanding AI\u2014not just by its computational capabilities, but also within its practical and\nethical operational contexts. By conceptualizing AI as an intelligent and autonomous system capable\nof providing conclusions acceptable to the parties involved, this definition aligns AI's capabilities with\nits intended roles, enhancing both functionality and user trust in arbitration."}, {"title": "b. Before and After GenAI: Transforming Legal Decision-Making", "content": "This section examines the evolution of AI in legal decision-making, divided into periods before and\nafter the introduction of GenAI. Historically, users have leveraged the latest technology to expedite\nand enhance decision-making processes. However, the capabilities and reliability of the technology\nhave determined the extent of its adoption. Before GenAI, AI systems generated inflexible and limited\ncontent, with algorithms struggling to automate decisions due to issues with explicability,\ncomprehensibility, and adaptability. Post-GenAI, advancements in AI have enabled more accurate and\nflexible human-AI interactions, significantly reshaping dispute resolution in the legal profession."}, {"title": "Before GenAI", "content": "AI's application in the legal field is not a recent development. Prior to GenAI, various algorithms were\nalready in use across different aspects of legal work, including legal research, document management,\npredictive analytics, expert systems, and compliance and risk management. For instance, LexisNexis\nand Westlaw, equipped with sophisticated search algorithms, have transformed legal research by\nautomating the process of locating precedents and relevant legal documents since their introduction\nin the 1970s. E-discovery software such as Relativity has also employed data mining and text analysis\nto manage large datasets of electronic documents. Lex Machina, a legal analytics tool, utilizes NLP\nand technology-assisted human review to deliver case resolutions, damages, remedies, findings, and\nother party data.\n\nBefore GenAI, these search engines and chatbots primarily rely on expert systems and decision\nsupport systems to generate responses. Their architecture primarily consists of 3 approaches: rule-\nbased, retrieval-based, and a combination of both. Rule-based models operate on predefined rules,\nlinking users inputs to specific responses; retrieval-based chatbots used machine learning algorithms\nto choose responses from an existing database according to user input. However, these models are\nlimited by the need for extensive data, significant computational power, and the challenge of\nmaintaining context in long conversations. Additionally, they are heavily influenced by a variety of\npreset factors, which has resulted in their applications and decision-making capabilities failing to\ngenerate much enthusiasm from the public. Despite Chief Justice Roberts' warning during a school\nlecture to high school students to \"beware the robots,\" skepticism persists about whether AI,\nparticularly algorithmic prediction tools, can be effectively applied to real-life scenarios.\n\nDue to the inflexibility and the system's reliance on machine learning methods anchored to fixed\ndatasets, one major concern with AI adjudication is its incomprehensibility. The system may operate\nin ways that are difficult for people to understand as these systems may not adapt well to constantly\nchanging situations. Additionally, deep learning techniques lack the explicit logical reasoning based\non precedents, which is characteristic of traditional human judicial decision-making. This could\nerode trust in the judicial process and undermine equitable justice. While human judges are undeniably\nalso susceptible to biases and errors, and their decisions can be influenced by external factors, at least\nthey provide reasons for their rulings, although these reasons may not always reflect their true motives.\nIn contrast, AI systems, with their opaque nature, exacerbate these issues by failing to provide any\nexplanation for their decisions. Legal reasoning, even when not reflecting the true motives of judges\nmight very well be something litigants want rather than \u2018black box' decisions. Furthermore, it's a fact\nthat people generally trust humans more than machines. This anthropocentric belief highlights a\nsignificant barrier to the acceptance of AI in judicial roles.\n\nThe third concern for deploying AI to automate decision making is the datafication of and alienation\nfrom the legal system when all legal information is transformed into data and fed into algorithms for\ntraining. When cases, opinions, and statutes become objective data, and legal systems adapt to\nincorporate and utilize this information, it could negatively impact legal operations. This focus on\ndata might compromise due process norms, devalue hearings due to lack of proper notice, and\nundermine participatory rulemaking.\" When code, rather than human-made judicial rules, determines\ndispute outcomes, programmers may inadvertently alter social and judicial values while preparing\ndatasets and selecting analytics methods. Since courts cannot actually review these mechanisms, this\nnew form of data could lead to an accountability deficit. As these deficits accumulate, they might\ncause people to lose interest in participating in the operations of the judicial system.\""}, {"title": "After GenAI", "content": "GenAI has demonstrated significant potential to transform the legal domain. According to the\nBrookings Institute, AI is poised to \u201cfundamentally reshape the practice of law.\u201d Law firms that\neffectively leverage GenAI will offer services at lower costs, higher efficiency, and better litigation\noutcomes. In contrast, firms failing to capitalize on AI's power risk losing clients and struggling to\nattract and retain talent. For individual clients and lawyers, LLMs could streamline document review,\nfacilitate case file management, and provide accessible explanations and summaries of cases. For\nexample, computer scientists have developed an LLM with 7 billion parameters, trained on an English\nlegal corpus of over 30 billion tokens to understand and process legal documents.\n\nGenAI models promise to deliver more natural, context-aware, and flexible conversations. Because\nof their extensive datasets and probabilistic word sequences, they can generate diverse and more\nappropriate as well as more adequate and comprehensive responses that are attuned to the\nconversational contexts and subtleties. Such improvements are achieved through techniques like\nReinforcement Learning from Human Feedback (RLHF), wherein the models iteratively learn from\ninteractions curated by human reviewers to refine their understanding and outputs. For instance,\nwhen applied in customer service scenarios, if a customer expresses frustration over a delayed order,\nLLM such as Llama 2 can discern the emotional tone and context of the complaint, thereby responding\nin an appropriate tone while providing practical solutions to the customers such as an updated delivery\ntimelines or a discount for future purchases. The ability to appropriately address both the content and\nemotional nuances of human interactions signifies a substantial advancement over earlier pre-GenAI\nsystems.\n\nGenAI can also be fine-tuned for specialization in tasks or domains, reducing the need for manual\nconstruction of knowledge bases and rule tables. In financial operations, for example, GenAI\nenhances fraud detection capabilities by autonomously scanning vast datasets to identify patterns and\nanomalies indicative of fraud, without manual adjustments. This adaptability makes fraud detection\nmore dynamic and responsive to new tactics, reducing the burden on human analysts and enhancing\nsecurity and efficiency."}, {"title": null, "content": "Another application is using GenAI to predict political orientation based on face scans. Machine\nlearning algorithms can analyze facial features, expressions, and micro-expressions from images\nsourced from public profiles where individuals have disclosed their political affiliations. This analysis\ncan identify facial patterns among individuals with similar political beliefs, potentially useful in\nmonitoring electoral outcomes, understanding regional political trends, or tailoring political\ncampaigns.\n\nIn arbitration, GenAI can master the intricacies of legalese, understand complex legal documents, and\napply rules depicted in agreements to make informed decisions. These models can operate\nindependently or assist human arbitrators by expediting the review of extensive legal documents,\nidentifying relevant case precedents, and formulating awards based on agreement stipulations. For\ninstance, in a contractual arbitration over contract terms, AI, even without individuals' engagement in\nthe loop, can analyze the contract language, relevant legal standards, and precedents, calculate damages\nbased on past cases, and suggest equitable remedies aligned with cultural norms and legal\nexpectations.\n\nIndeed, AI, when used to make decisions, is more accurate than humans. Using AI as an arbitrator in\nclaim disputes could lead to more precise outcomes in less time, enhancing cost-effectiveness and\nsaving considerable effort. For example, in a study on deceptive review detection by the University\nof Colorado, researchers conducted large-scale, randomized experiments involving human subjects to\nexamine whether model-driven tutorials could boost human performance in identifying fake\nreviews. Despite recruiting 480 participants via Amazon Mechanical Turk and finding that tutorials\ndid improve human accuracy, the increase was slight. The accuracy rates were 86.3% for AI alone,\n54.6% for humans alone, and 74% for a combined human-AI team, indicating that AI outperforms\nteams comprising only humans. This finding aligns with other research. In a separate study by\nYunfeng Zhang and colleagues, the effectiveness of AI confidence scores and explanations in AI-\nassisted decision-making was assessed in high-stakes situations requiring both automation and human\njudgment. The results showed that AI alone achieved a 75% accuracy rate, humans alone reached\n65%, and the combined human-AI team attained 73% accuracy.\n\nIn addition to AI making the decisions by itself, in scenarios where there must be a human-in-the-\nloop, the effectiveness of human-AI teams can be enhanced by considering individual characteristics\nand the specific nature of the task at hand. For instance, research in medical settings indicates that\nexperts with less domain experience tend to trust AI more than their more experienced counterparts.\nAdditionally, among all expert participants, there are variations in reliance on AI assistance; some\nconsistently over-rely on it while others do not, and they each utilize AI support in different ways.\nThis implies that less experienced arbitrators might depend more heavily on AI than their more\nseasoned peers. Recognizing these behavioral patterns could enable arbitration associations to provide\nmore precise and useful guidance.\n\nThere are also decisions that need to be made under time pressure. In such cases, presenting AI-\ngenerated decisions to individuals before they make their own choices has proven to accelerate the\ndecision-making process. Particularly in contexts where the promptness of a decision is prioritized\nover its absolute accuracy, providing arbitrators with AI-generated recommendations beforehand\nappears to be a promising approach.\n\nIn conclusion, the deployment of algorithms in legal domains, especially with the introduction of\nGenAI, marks a significant transformation in legal decision-making and dispute resolution. While\nearlier technologies facilitated efficient data processing and basic responses, GenAI offers a new level\nof dynamism and adaptability, enhancing the legal profession's efficiency and accuracy."}, {"title": "2. Designating AI as an Arbitrator is Consistent with FAA", "content": "Arbitration is fundamentally contractual", "comment": "short of\nauthorizing trial by battle or ordeal or, more doubtfully, by a panel of three monkeys, parties can\nstipulate whatever procedures they want to govern the arbitration of their disputes.\u201d Some notable\nchoices include desk arbitrations, bracketed arbitration, and baseball arbitration. Remote\nprocedures, such as phone or videoconference hearings, became prevalent during COVID-19 and\ncontinue post-pandemic.\n\nUnder the FAA, disputants can be confident that their arbitration agreements, including terms related\nto incorporating AI, will be enforced as written. The FAA was established to end judicial hostility\ntowards arbitration, ensuring agreements are honored without alteration. Section 2 of the Act\ndeclares that agreements to settle disputes through arbitration are valid, irrevocable, and enforceable.\nSections 3 and 4 support this by requiring courts to stay litigation and compel arbitration according to\nthe agreement's terms, provided there is no dispute over the agreement's validity. Unless overridden\nby clear Congressional intent, these arbitration agreements\u2014including those mandating AI\u2014are to\nbe upheld.\n\nThe FAA's mandate to enforce arbitration agreements according to their terms was affirmed in AT&T\nMobility LLC v. Concepcion. The justices held that the FAA mandates individual, rather than class\nproceedings, when the arbitration agreement prohibits class action. The Court reasoned that\ninvalidating class arbitration waivers violated the FAA's primary objective of \u201censuring the\nenforcement of arbitration agreements according to their terms to facilitate streamlined\nproceedings.\u201d\n\nDisputants who choose to incorporate AI into their arbitration need not fear preemption by state law.\nThe FAA overrides any state law that specifically discriminates against arbitration provisions. This\nprinciple was affirmed in Perry v. Thomas"}]}