{"title": "Don't Kill the Baby!\nThe Case For AI in Arbitration", "authors": ["Michael J. Broyde", "Yiyang Mei"], "abstract": "Since the introduction of Generative AI (GenAI) in 2022, its ability to simulate human intelligence and generate content has sparked both enthusiasm and concern. While much of the criticism focuses on AI\u2019s potential to perpetuate bias, create emotional dissonance, displace jobs, and raise ethical questions, these concerns often overlook the practical benefits of AI, particularly in legal contexts. This article examines the integration of AI into arbitration, arguing that the Federal Arbitration Act (FAA) allows parties to contractually choose AI-driven arbitration, despite traditional reservations.\n\nThe article makes three key contributions: (1) It shifts the focus from debates over AI\u2019s personhood to the practical aspects of incorporating AI into arbitration, asserting that AI can effectively serve as an arbitrator if both parties agree; (2) It positions arbitration as an ideal starting point for broader AI adoption in the legal field, given its flexibility and the autonomy it grants parties to define their standards of fairness; and (3) It outlines future research directions, emphasizing the importance of empirically comparing AI and human arbitration, which could lead to the development of distinct systems.\n\nBy advocating for the use of AI in arbitration, this article underscores the importance of respecting contractual autonomy and creating an environment that allows AI\u2019s potential to be fully realized. Drawing on the insights of Judge Richard Posner, the article argues that the ethical obligations of AI in arbitration should be understood within the context of its technological strengths and the voluntary nature of arbitration agreements. Ultimately, it calls for a balanced, open-minded approach to AI in arbitration, recognizing its potential to enhance the efficiency, fairness, and flexibility of dispute resolution.", "sections": [{"title": "Introduction", "content": "Since the introduction of Generative AI (GenAI) in 2022, extensive discussions have highlighted its\nimpressive capabilities in simulating human intelligence and generating novel content. Despite these\nremarkable functionalities, there is consensus that, if not carefully managed and fine-tuned, GenAI\u2014\nespecially when applied through Large Language Models (LLMs)\u2014can be fundamentally harmful and\ndiscriminatory toward marginalized groups. In the workplace, Artificial Intelligence (AI) systems used\nfor hiring, promotions, and other Human Resources (HR) tasks may perpetuate biases by learning\nfrom historical data. Additionally, AI chatbots and virtual assistants, though capable of mimicking\nhuman interactions, lack genuine empathy and human connection. This can lead to emotional\ndissonance, where users feel temporarily understood without receiving the deeper emotional support\nthat real human relationships provide. Furthermore, AI\u2019s efficiency in automating tasks could result\nin significant job displacement, and its proficiency in analyzing large datasets might enable the\ncreation of personalized content, raising critical ethical questions about consent, manipulation, privacy,\nand the potential impact on democracy and personal autonomy.\nWhile criticisms of GenAI are valid and well-founded, they often overlook the technology\u2019s efficiency\nand cost-effectiveness. GenAI excels in processing and analyzing data at speeds unattainable by\nhumans, reducing overall costs, accelerating decision-making processes, and enhancing accuracy in"}, {"title": "1. What is AI", "content": "AI is extensively used across various domains. In finance, for example, AI facilitates know-your-\ncustomer (KYC) checks and anti-money laundering (AML) monitoring. In tenant screening, AI\nconducts background checks, automating the retrieval and analysis of a candidate\u2019s financial history,\ncriminal records, and previous rental agreements. Using natural language processing (NLP), AI can\nanalyze a tenant\u2019s online interactions to gauge their reliability and character. In drug discovery, AI\nrevolutionizes nearly every stage of the process, from target identification and molecular simulations\nto prediction of drug properties, de novo drug design, and synthesis pathway generation. In content\ngeneration, AI has been used to write books in hours that win national competitions and help artists\nwin awards for paintings. Regardless of the users\u2019 identity\u2014be it painter, musician, or writer\u2014AI\nenhances the artistic journey through inspiration, idea generation, and visual exploration. Since the\ndebut of ChatGPT, AI has proliferated across various fields.\nThe proliferation of AI applications requires clear definitions, as \u201cAI\u201d is an umbrella term\nencompassing a wide range of computing approaches and algorithms, including deep learning,"}, {"title": "a. Definition of AI in arbitration", "content": "robotics, expert systems, and NLP. Generally, there are three types of definitions: capability-based,\nprocess-based, and goal-oriented. Capability-based definitions focus on what AI can do, such as\nunderstanding natural language, recognizing patterns, solving problems, and learning. Process-based\ndefinitions emphasize how AI systems operate. Goal-oriented definitions center on the expected\noutcomes of AI, such as augmenting human capabilities or automating decision-making processes.\nDifferent organizations use these definitions interchangeably. For instance, IBM focuses on AI\u2019s\nfunctional and solution-oriented aspects, while McKinsey emphasizes its human-like capabilities.\nThese varying definitions create confusion about which AI is being discussed. They also affect people\u2019s\nperceptions of algorithmic decision-making systems, their evaluations of systems in application\ncontexts, and the replicability of research findings. For example, terms such as \u201ccomputers\u201d or\n\"robots\" are more likely to be perceived as tangible compared to \u201calgorithms\u201d or \u201cartificial\nintelligence.\u201d \u201cComputer programs\u201d might be perceived as less complex compared to \u201cartificial\nintelligence,\u201d and \u201ccomputer\u201d might be associated with an entity more controllable than a \u201crobot.\u201d\nThese different terms affect people\u2019s perceptions and treatment of the entity.\nTo avoid confusion, computer scientists and researchers in Human-Centered Computing use specific\nand well-defined terms such as \u201clanguage models\u201d or \u201cmachine learning algorithms.\u201d Although both\ncount as \u201cAI,\u201d they refer to vastly different things. Language models, used in NLP, focus on\nunderstanding and generating human language, replicating human communication. Machine-\nlearning algorithms are decision-making tools that analyze data and provide solutions or\nrecommendations based on training data. The former mimics human interaction; the latter prioritizes\nanalytical efficiency. Conflating them misses important details. To effectively evaluate the role of AI\nas an arbitrator in alternative dispute resolution, it's crucial to define precisely what AI means in this\ncontext.\nIt's important to note, however, defining AI merely by its technological features, focusing solely on\nalgorithms and computational abilities, risks overemphasizing its decision-making capacity while\nneglecting the normative frameworks essential to arbitration. Alternatively, viewing AI as a quasi-\narbitrator that mimics human behavior could mistakenly attribute human qualities like consciousness\nand independent thought to these systems. Therefore, we should define AI as an intelligent and\nautonomous system, driven by machine learning, capable of reaching conclusions satisfactory to all\nparties involved in arbitration. This definition should clarify key concepts: \u201cintelligence,\u201d\n\u201cautonomous systems,\u201d \u201cmachine learning,\u201d and the system's ability to satisfactorily resolve disputes."}, {"title": "Intelligence", "content": "Intelligence, derived from the Latin \"intelligentsia,\u201d means \u201cunderstanding, knowledge, power of\ndiscerning; art, skill, and taste.\u201d Cognitive scientists define it as the ability to learn from experience\nand to adapt to, shape, and select environments.\u201d In AI arbitration, an intelligent system is one that\nis capable of learning from training data, discovering hidden patterns, transforming embedded\ncharacteristics, processing user prompts, and adjusting content based on instructions. Here, \u201clearning\"\ndoesn't mean the acquisition of information based on previous conscious experience; similarly,\n\u201cintelligence\u201d doesn't imply that the system can consciously understand natural language or reflect on\nsemantic meaning. The system's lack of conscious understanding shouldn't matter as long as it\ngenerates reasonable decisions that make sense to the disputants.\nFor example, consider John Searle's Chinese Room argument: a person in a room receives Chinese\ncharacters and manipulates them according to a set of rules, despite not understanding Chinese. To\nan external observer, it might appear as though the person understands and communicates fluently in\nChinese. However, the individual is merely following syntactic rules, without genuine\ncomprehension. In AI arbitration, the person in the room represents the algorithm, and the people\noutside are the disputants seeking a resolution. It does not matter whether the algorithm truly\nunderstands the language, as long as it facilitates an intelligent conversation and reaches a decision\nthat makes sense to the disputants.\nRequiring conscious understanding and reflection for AI may be overly demanding and an inadequate\ndefense. Sometimes, people learn simply by imitation. As Nicholson Baker advises writers, \u201ccopy out\nthe things that you really love... Put quotation marks around them... You'll absorb the prose more\ndeeply because the act of copying makes you notice elements you would miss by merely reading.\u201d Direct copying doesn't involve conscious understanding, yet it serves a purpose for later development.\nSimilarly, in arbitration, conscious understanding isn't always necessary for successful mediation or\ndispute resolution."}, {"title": "Autonomous Systems", "content": "\"Autonomy,\u201d derived from \u201cautonomos,\u201d means \u201cindependent, living by one's own laws.\u201d\n\"Autonomous systems,\u201d in this context, refer to systems that function by their own rules, without\nexternal interference.\nIn AI arbitration, the system's capability for being autonomous means that it is capable of\nindependently navigate the latent space\u2014a complex multidimensional space embedded with learned\npatterns and relationships within data\u2014based on human input such as prompts. An autonomous\nsystem doesn't act with subjective personal strivings. After receiving a user's prompt, which acts as a\ncreative guide, the AI system explores this latent space, applying its training to meld learned elements\ninto something novel. The user, rather than being passive, participates as an originator and evaluator\nof the final output. The machine's autonomy is thus collaborative and exercised within a social\nstructure influenced and validated by humans."}, {"title": "Machine Learning", "content": "Machine learning refers to the algorithms used in generating decisions. It is a field of study that gives\ncomputers the ability to learn without being explicitly programmed. Different learning models\ninclude supervised learning, unsupervised learning, and transfer learning."}, {"title": "Supervised Learning:", "content": "Supervised learning uses labeled datasets to train algorithms, which learn to predict outcomes and\nrecognize patterns based on provided data. For instance, consider the following process: imagine\nteaching a student artist to paint. In this analogy, the student represents the algorithm; the samples of\nartwork are like the dataset; the student's final work is the outcome. The student follows detailed\ninstructions that explain the techniques and rationale behind each brushstroke and color choice. By\nrepeatedly practicing these techniques, the student learns to create new artworks in similar styles. In\nsupervised learning, the algorithms undergo a similar repetitive training process as it learns from\nexamples to produce results based on the data they have been trained on."}, {"title": "Unsupervised Learning:", "content": "Unsupervised learning is another form of machine learning where algorithms learn without any labeled\ndata or explicit instructions. In this approach, the model must independently discern its own rules\nand structure the information by identifying similarities, differences, and patterns within the data on\nits own.\nUsing a similar example as above: imagine an artist tasked with organizing a vast collection of various\nartworks they've never seen before, without any guidelines or categories provided. As the artist\nnavigates this collection, they must examine each piece, noting styles, themes, and techniques, and\ndecide on a method to categorize and organize the entire collection based on their observations. No\none is there to teach them. The artist, as the algorithms in unsupervised learning, explores the data,\nidentifies patterns, and makes sense of it without prior knowledge or guidance, according to their own\nsystem of organization and understanding. Through this process, unsupervised learning produces\noutcomes."}, {"title": "Transfer Learning:", "content": "Transfer learning involves using a pre-trained model as the starting point for a new, similar task. It\nleverages knowledge from the initial training to improve performance on a new task. For example,\nimagine an artist who has already mastered painting pets and is now moving on to paint wild animals.\nThe artist doesn't start from scratch; instead, they \"transfer\u201d the skills and understanding of animal\nforms, textures, and behaviors from their previous experience with pets to more quickly master the\ndepiction of wild animals. The skills such as handling the brush and mixing colors are reused and\nadapted to this new subject matter, making the transition to a new task smoother and more efficient.\nEach of these machine learning methods can be applied to AI arbitration to reduce costs and improve\naccuracy in dispute resolution. Supervised learning would be particularly useful for making predictions\nbased on past data with known outcomes. For example, consider an algorithm analyzing a series of\nemployment disputes involving breaches of contracts. The system could assess the factors leading to\nfavorable outcomes in the labeled dataset and predict outcomes for new cases requiring arbitration."}, {"title": "Reaching Results Satisfactory to the Parties", "content": "Machine learning algorithms can reach decisions satisfactory to disputants by \u201cthinking and acting\nhumanely,\u201d a term borrowed from Stuart Russel and Peter Norvig's definition of AI in Artificial\nIntelligence: A Modern Approach. They proposed four dimensions for considering AI: thinking and\nacting humanly, and thinking and acting rationally. The first category of dimension relates to the\nmachine's ability to perform tasks typically associated with human cognition, such as decision-making\nand problem-solving. The second category of dimension refers to logical thinking processes that are\npresumed to govern mental operations. All dimensions work together to enable AI to deliver results\nthat are acceptable \u2013 perhaps even more acceptable than an arbitration, when cost is factored in to\nthe disputants.\nIn the context of AI arbitration, it is important for AI to behave humanly, as it helps them demonstrate\nintelligent and responsive behavior. Alan Turing introduced this concept in the 1950s with the Turing\nTest, which provides a practical operational definition of intelligence. According to the test, if a\nhuman interrogator cannot tell whether responses to their written questions are coming from a person\nor a computer, the machine is deemed intelligent. Key abilities for this task include knowledge\nrepresentation (to store and retrieve information), automated reasoning (to use the information for\nanswering questions and drawing new conclusions), and machine learning (to adapt to new situations\nand identify patterns).\nBy acting humanly and rationally, AI builds trust with users, offering immediate, accessible support.\nUsers often attach significant emotional importance to interactions with LLM-based chatbots, turning\nimpersonal exchanges into meaningful relationships. For instance, some users perceive chatbots as\nemotional supports. In a study by Ma et al., users expressed that interacting with chatbots feels like\nhaving someone who enjoys talking to them, responds immediately, and seems to care, even though\nthey recognize it's a computer. This sense of connection persists despite knowing they are interacting\nwith a non-human entity. As the same interviewees elaborated, \u201cIt feels like a more personal\nconversation, even though we both know it's not with another human. For those of us who don't\nhave many people to talk to, it's a comforting space.\u201d\nThinking humanly and logically means that AI is more likely to provide rational and comprehensive\nexplanations for its decisions in terms that are understandable and adequate to humans. This process\ninvolves understanding the human mind through introspection, psychological experiments, and brain\nimaging, and then simulating this input-output behavior to mirror human actions.\nIn conclusion, the deployment of AI across domains underscores the importance of clearly defining\nand understanding AI\u2014not just by its computational capabilities, but also within its practical and\nethical operational contexts. By conceptualizing AI as an intelligent and autonomous system capable\nof providing conclusions acceptable to the parties involved, this definition aligns AI's capabilities with\nits intended roles, enhancing both functionality and user trust in arbitration."}, {"title": "b. Before and After GenAI: Transforming Legal Decision-Making", "content": "This section examines the evolution of AI in legal decision-making, divided into periods before and\nafter the introduction of GenAI. Historically, users have leveraged the latest technology to expedite\nand enhance decision-making processes. However, the capabilities and reliability of the technology\nhave determined the extent of its adoption. Before GenAI, AI systems generated inflexible and limited\ncontent, with algorithms struggling to automate decisions due to issues with explicability,\ncomprehensibility, and adaptability. Post-GenAI, advancements in AI have enabled more accurate and\nflexible human-AI interactions, significantly reshaping dispute resolution in the legal profession."}, {"title": "Before GenAI", "content": "AI's application in the legal field is not a recent development. Prior to GenAI, various algorithms were\nalready in use across different aspects of legal work, including legal research, document management,\npredictive analytics, expert systems, and compliance and risk management. For instance, LexisNexis\nand Westlaw, equipped with sophisticated search algorithms, have transformed legal research by\nautomating the process of locating precedents and relevant legal documents since their introduction\nin the 1970s. E-discovery software such as Relativity has also employed data mining and text analysis\nto manage large datasets of electronic documents. Lex Machina, a legal analytics tool, utilizes NLP\nand technology-assisted human review to deliver case resolutions, damages, remedies, findings, and\nother party data.\nBefore GenAI, these search engines and chatbots primarily rely on expert systems and decision\nsupport systems to generate responses. Their architecture primarily consists of 3 approaches: rule-\nbased, retrieval-based, and a combination of both. Rule-based models operate on predefined rules,\nlinking users inputs to specific responses; retrieval-based chatbots used machine learning algorithms\nto choose responses from an existing database according to user input. However, these models are\nlimited by the need for extensive data, significant computational power, and the challenge of\nmaintaining context in long conversations. Additionally, they are heavily influenced by a variety of\npreset factors, which has resulted in their applications and decision-making capabilities failing to\ngenerate much enthusiasm from the public. Despite Chief Justice Roberts' warning during a school\nlecture to high school students to \"beware the robots,\" skepticism persists about whether AI,\nparticularly algorithmic prediction tools, can be effectively applied to real-life scenarios.\nDue to the inflexibility and the system's reliance on machine learning methods anchored to fixed\ndatasets, one major concern with AI adjudication is its incomprehensibility. The system may operate\nin ways that are difficult for people to understand as these systems may not adapt well to constantly\nchanging situations. Additionally, deep learning techniques lack the explicit logical reasoning based\non precedents, which is characteristic of traditional human judicial decision-making. This could\nerode trust in the judicial process and undermine equitable justice. While human judges are undeniably\nalso susceptible to biases and errors, and their decisions can be influenced by external factors, at least\nthey provide reasons for their rulings, although these reasons may not always reflect their true motives.\nIn contrast, AI systems, with their opaque nature, exacerbate these issues by failing to provide any\nexplanation for their decisions. Legal reasoning, even when not reflecting the true motives of judges\nmight very well be something litigants want rather than \u2018black box' decisions. Furthermore, it's a fact\nthat people generally trust humans more than machines. This anthropocentric belief highlights a\nsignificant barrier to the acceptance of AI in judicial roles.\nThe third concern for deploying AI to automate decision making is the datafication of and alienation\nfrom the legal system when all legal information is transformed into data and fed into algorithms for\ntraining. When cases, opinions, and statutes become objective data, and legal systems adapt to\nincorporate and utilize this information, it could negatively impact legal operations. This focus on\ndata might compromise due process norms, devalue hearings due to lack of proper notice, and\nundermine participatory rulemaking. When code, rather than human-made judicial rules, determines\ndispute outcomes, programmers may inadvertently alter social and judicial values while preparing\ndatasets and selecting analytics methods. Since courts cannot actually review these mechanisms, this\nnew form of data could lead to an accountability deficit. As these deficits accumulate, they might\ncause people to lose interest in participating in the operations of the judicial system."}, {"title": "After GenAI", "content": "GenAI has demonstrated significant potential to transform the legal domain. According to the\nBrookings Institute, AI is poised to \u201cfundamentally reshape the practice of law.\u201d Law firms that\neffectively leverage GenAI will offer services at lower costs, higher efficiency, and better litigation\noutcomes. In contrast, firms failing to capitalize on AI's power risk losing clients and struggling to\nattract and retain talent. For individual clients and lawyers, LLMs could streamline document review,\nfacilitate case file management, and provide accessible explanations and summaries of cases. For\nexample, computer scientists have developed an LLM with 7 billion parameters, trained on an English\nlegal corpus of over 30 billion tokens to understand and process legal documents.\nGenAI models promise to deliver more natural, context-aware, and flexible conversations. Because\nof their extensive datasets and probabilistic word sequences, they can generate diverse and more\nappropriate as well as more adequate and comprehensive responses that are attuned to the\nconversational contexts and subtleties. Such improvements are achieved through techniques like\nReinforcement Learning from Human Feedback (RLHF), wherein the models iteratively learn from\ninteractions curated by human reviewers to refine their understanding and outputs. For instance,\nwhen applied in customer service scenarios, if a customer expresses frustration over a delayed order,\nLLM such as Llama 2 can discern the emotional tone and context of the complaint, thereby responding\nin an appropriate tone while providing practical solutions to the customers such as an updated delivery\ntimelines or a discount for future purchases. The ability to appropriately address both the content and\nemotional nuances of human interactions signifies a substantial advancement over earlier pre-GenAI\nsystems.\nGenAI can also be fine-tuned for specialization in tasks or domains, reducing the need for manual\nconstruction of knowledge bases and rule tables. In financial operations, for example, GenAI\nenhances fraud detection capabilities by autonomously scanning vast datasets to identify patterns and\nanomalies indicative of fraud, without manual adjustments. This adaptability makes fraud detection\nmore dynamic and responsive to new tactics, reducing the burden on human analysts and enhancing\nsecurity and efficiency."}, {"title": "2. Designating AI as an Arbitrator is Consistent with FAA", "content": "Arbitration is fundamentally contractual, rooted in private agreements and decisions. Alan Rau\nemphasizes that arbitration should be viewed as a form of private governance and self-determination,\napproached through the lens of voluntary agreement rather than traditional adjudication. The\npurpose of granting parties discretion in designing the arbitration process is to allow for efficient,\nstreamlined procedures tailored to the type of dispute. Parties can choose a decision-maker who is\na specialist in the field or ensure proceedings remain confidential to protect trade secrets or privacy\nrights. This self-chosen adjudication process fosters informality, reducing costs and increasing the\nspeed of dispute resolution. Consequently, if both parties agree, AI can be designated as an arbitrator\nin their dispute resolution.\nUnconventional procedures in arbitration are generally tolerated and encouraged. Incorporating AI in\narbitration\u2014whether as the primary arbitrator or as an enhancement to the decision-making\nprocess\u2014is permitted. Judges frequently enforce arbitration clauses and awards, allowing parties to\ninnovate and experiment freely. This spirit is encapsulated in Judge Posner's comment: \"short of\nauthorizing trial by battle or ordeal or, more doubtfully, by a panel of three monkeys, parties can\nstipulate whatever procedures they want to govern the arbitration of their disputes.\u201d Some notable\nchoices include desk arbitrations, bracketed arbitration, and baseball arbitration. Remote\nprocedures, such as phone or videoconference hearings, became prevalent during COVID-19 and\ncontinue post-pandemic.\nUnder the FAA, disputants can be confident that their arbitration agreements, including terms related\nto incorporating AI, will be enforced as written. The FAA was established to end judicial hostility\ntowards arbitration, ensuring agreements are honored without alteration. Section 2 of the Act\ndeclares that agreements to settle disputes through arbitration are valid, irrevocable, and enforceable. Sections 3 and 4 support this by requiring courts to stay litigation and compel arbitration according to\nthe agreement's terms, provided there is no dispute over the agreement's validity. Unless overridden\nby clear Congressional intent, these arbitration agreements\u2014including those mandating AI\u2014are to\nbe upheld.\nThe FAA's mandate to enforce arbitration agreements according to their terms was affirmed in ATOT\nMobility LLC v. Concepcion. The justices held that the FAA mandates individual, rather than class\nproceedings, when the arbitration agreement prohibits class action. The Court reasoned that\ninvalidating class arbitration waivers violated the FAA's primary objective of \u201censuring the\nenforcement of arbitration agreements according to their terms to facilitate streamlined\nproceedings.\"\nDisputants who choose to incorporate AI into their arbitration need not fear preemption by state law.\nThe FAA overrides any state law that specifically discriminates against arbitration provisions. This\nprinciple was affirmed in Perry v. Thomas, where the Supreme Court ruled that Section 2 of the FAA\nsuperseded a conflicting California statute invalidating arbitration clauses in wage disputes. The\nFAA derives its authority from the Supremacy Clause of the U.S. Constitution. Allowing state laws to\noverride FAA provisions would undermine the uniformity and effectiveness of federal arbitration\npolicy. This principle was reiterated in Marmet Health Care Ctr., Inc. v. Brown, where the Supreme Court\nheld that arbitration agreements under the FAA must be enforced as written unless legal or equitable\ngrounds exist that would invalidate any contract. Judges are barred from using contract law's public\npolicy defense to exempt claims from arbitration.\nBy opting for arbitration and incorporating AI, disputants are not choosing an inferior form of\nlitigation or waiving substantive rights under the law. They are selecting an alternative method for\nresolving disputes. This principle was central in Mitsubishi Motors Corp. v. Soler Chrysler-Plymouth, Inc.,\nwhich examined whether U.S. antitrust law claims could be subjected to compulsory arbitration\ninternationally. The Court held that claims under the Sherman Antitrust Act could be arbitrated\ninternationally, reasoning that a party does not forfeit substantive rights by choosing arbitration but\nresolves these rights in an arbitral forum. A supporting decision in Epic System Corp v. Lewis further\nemphasizes this interpretation. The Court declared its duty to interpret Congressional statutes as a\ncoherent whole, upholding decisions made according to arbitration agreements.\nFairness is not a valid reason to reject AI's deployment in arbitration. Incorporating AI into arbitration\naligns with the FAA's fairness standards, which are less stringent than those in other judicial contexts.\nUnlike litigation courts, there is no specific requirement for a live hearing in arbitration. For instance,\nin Federal Deposit Insurance v. Air Florida System, Inc., the Ninth Circuit ruled that the absence of an oral\nhearing could not be considered misconduct prejudicing the FDIC's rights, as long as the evidence\ndid not require oral presentation. As long as arbitrators are not corrupt or fail to hear evidence\nappropriately, they are authorized to decide on pre-hearing motions to dismiss and summary judgment\nmotions. If parties agree to incorporate AI, such a decision should be upheld and enforced according\nto the arbitrators' rulings.\nCourts are generally reluctant to dismiss the methods disputants choose for managing their claims.\nInstead of dismissing claims due to a lack of due process, courts may vacate an award only in cases of\nmisconduct, such as when arbitrators unjustifiably refuse to postpone hearings, decline to\nconsider relevant evidence, or engage in behavior that prejudices any party's rights. Since an AI\narbitrator is incapable of such misconduct, its integration maintains the integrity of the arbitration\nprocess. Additionally, arbitration is deemed fair if the losing party received sufficient notice and had\nan opportunity to participate aspects unaffected by AI integration. Lastly, the FAA, serving as a"}, {"title": "3. Practical and Strategic Benefits of Using AI in Arbitration", "content": "Deploying AI in arbitration is a practical and strategic choice. It not only reduces the costs associated\nwith arbitration processes but also aligns with the fairness standards set by the parties themselves.\nMoreover, due to the increasing judicialization of arbitration\u2014which is seeing arbitration adopt more\nformal judicial processes\u2014this field serves as an ideal testing ground for integrating AI into the\nbroader judicial system."}, {"title": "a. Integrating AI in Arbitration Reduces Costs, Making Services More Accessible", "content": "Integrating AI in arbitration makes the process cost-effective. According to the Consumer Arbitration\nRules of the American Arbitration Association (AAA), the costs of arbitration are structured around\nfour key components to ensure fairness for all parties involved:\n(1) Filing Fees: These vary depending on whether the case is filed by an individual or a business. For\nindividuals, the standard filing fee for a single consumer case is $225. Businesses are required to pay\n$375 for arbitration involving a single arbitrator or $500 if three arbitrators are involved.\n(2) Case Management Fees: Both individuals and businesses must pay case management fees, set\nat $1,400 for a single arbitrator and $1,775 for three arbitrators.\n(3) Hearing Fees: Businesses are responsible for a hearing fee of $500, which is refundable if the\nhearing is canceled with at least two business days' notice.\n(4) Arbitrator Compensation: Arbitrators in desk or documents-only arbitration cases are\ncompensated at a rate of $1,500 per case, with an additional rate of $300 per hour if the document\nreview exceeds 100 pages or seven hours. For more involved procedures, such as in-person, virtual,\nor telephonic hearings, arbitrators are paid $2,500 per day.\nAdditional costs may arise depending on the specifics of the case, including abeyance fees for inactive\ncases and expenses related to the arbitrator's travel and other logistical requirements, typically borne\nby the business.\nFor a single consumer case involving a single arbitrator, case management, and a virtual hearing, using\nAI for dispute resolution could save the individual approximately $4,625, roughly equivalent to the\naverage American's earnings in Q4 of 2023. By reducing these costs, integrating AI makes\narbitration services more accessible and streamlines proceedings, lowering both financial and time\nexpenditures."}, {"title": "b. Deploying AI Levels the Playing Field and Enhances Subjective Fairness", "content": "AI in arbitration, with its advanced language processing capabilities, can help level the playing field\nfor individuals lacking legal expertise or strong writing skills. It assists pro se litigants by enabling\nthem to present their arguments clearly and effectively in paper hearings for small claims disputes.\nCommercial arbitration forums like AAA and JAMS offer streamlined processes for small claims,\nallowing parties to submit claims and defenses in writing, with decisions based solely on these\ndocuments."}, {"title": "c. Arbitration as a Testing Ground for AI Integration in the Judicial System", "content": "Deploying AI in arbitration offers a strategic starting point for integrating this technology within the\nbroader judicial system. Arbitration has increasingly mirrored traditional court proceedings, with\narbitrators determining their jurisdiction similarly to judges and the process involving extensive\ndiscovery phases much like those in litigation. If AI can be successfully integrated into arbitration,\nit may set a precedent for its eventual adoption in the wider judicial context.\nCurrently, there's much debate about whether AI should be integrated in the judicial system. While\nAI can potentially improve access to justice by increasing the percentage of adequately represented\nlitigants and reducing legal fees, critics argue that algorithmic tools lack transparency,\naccountability, and fairness. In addition, there are concerns that AI's capability to handle complex\nlegal reasoning is not yet sophisticated enough to navigate the nuances of law that human judges and\nlawyers can manage. AI systems, particularly those trained on past legal decisions, may not\nadequately adapt to new legal standards or understand the context of human emotions and ethical\nconsiderations that are often crucial in legal judgments. This could result in decisions that are legally\ncorrect but morally or ethically questionable, potentially undermining public trust in the judicial system.\nMoreover, the use of AI could lead to a homogenization of legal outcomes. As AI tools tend to\ngenerate solutions based on the most common interpretations of law, non-standard cases might not\nreceive the individualized consideration they require. This could stifle the development of law, as\nprecedents set by unique cases often lead to, or are reflections of significant legal reforms and social\nmovements.\nAs the number of trials declines, the rise of private arbitration offers an ideal testing ground for\nintegrating AI. From 1962 to 2002, the percentage of federal civil cases resolved by trial decreased by\n84%, with similar declines in state courts. This shift may be due to concerns about litigation costs,\ndelays, risks, and impacts on relationships. Lawsuits often strain personal and professional\nrelationships, causing emotional distress and psychological consequences for plaintiffs and\ndefendants. The frequent adjournments, delays, and financial strain associated with litigation lead to\nmany adverse emotional outcomes such as stress and sleepless nights.\nThe decrease in civil litigation has spurred the growth of arbitration, offering advantages like cost\nsavings, shorter resolution times, expert decision-makers, privacy, and relative finality. Arbitration's\nincreasing judicialization, with arbitrators determining jurisdiction and pre-hearing procedures\nmirroring litigation, makes it a suitable environment to test AI integration."}, {"title": "Part II. The Critics are Killing the Baby", "content": "Despite the growing resistance to AI adoption in the legal domain, criticisms such as claims of AI\nbeing biased, discriminatory, lacking transparency, and accountability are insufficient grounds for\noutright rejection. The origins of discrimination and bias often lie within the human-provided data,\nnot the AI mechanisms themselves. Given AI's early developmental stage and significant potential,\nmaintaining an open environment that encourages its growth is essential. Adopting an overly\nmoralistic tone could be counterproductive. The current regulatory frameworks, which typically\ninvolve supervising the system or focusing more carefully on human roles, may not be necessary for\narbitration. As long as both parties agree by contract to this method of adjudication, it should be\npermitted."}, {"title": "1. Resistance Against AI Does Not Offer Conclusive Reasons for Outright\nRejection", "content": "Criticizing AI has become trendy. Since the introduction of ChatGPT in December 2022, critics have\nproliferated in the literature. They argue that Al is biased and unfair, shaped by the initial data it\nreceives. When the underlying data is biased, the resulting algorithms can perpetuate discrimination\nand inequality. For instance, AI can exhibit sexist behavior-defaulting to male doctors and female\nnurses in stories\u2014because these patterns are reflected in the data it was trained on. Critics also\nargue that AI displaces jobs, with the World Economic Forum estimating that AI could replace 85\nmillion jobs by 2025 and more over time. Concerns extend to privacy, as AI can predict\npsychological characteristics from digital footprints, infringing on individual privacy. Additionally,\nAI's lack of transparency is another major concern, as leading companies do not share enough\ninformation about their foundation models' development and use. Furthermore, Al's ever-\nincreasing capabilities raise geopolitical concerns.\nLegal scholarship focusing on AI in arbitration echoes these criticisms. Many legal academics strongly\ndiscourage deploying AI in arbitration. Professor David Horton contends that AI procedures do\nnot qualify as \u201carbitration\u201d under the FAA, which is predicated on human arbitrators. Similarly,\nProfessor Derick Lindquist and Ylli Dautaj argue that AI lacks human qualities like empathy, emotion,\nand life experience, which are crucial for justice and fairness. Professor Lee-Ford Tritt notes that"}, {"title": "2. Let AI Grow Under Favorable Conditions: Avoiding Overly Moralistic Views", "content": "Social, cultural, and environmental"}]}