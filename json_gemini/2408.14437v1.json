{"title": "Sparsity-Aware Hardware-Software Co-Design of Spiking Neural Networks: An Overview", "authors": ["Ilkin Aliyev", "Kama Svoboda", "Tosiron Adegbija", "Jean-Marc Fellous"], "abstract": "Spiking Neural Networks (SNNs) are inspired by the sparse and event-driven nature of biological neural processing, and offer the potential for ultra-low-power artificial intelligence. However, realizing their efficiency benefits requires specialized hardware and a co-design approach that effectively leverages sparsity. We explore the hardware-software co-design of sparse SNNs, examining how sparsity representation, hardware architectures, and training techniques influence hardware efficiency. We analyze the impact of static and dynamic sparsity, discuss the implications of different neuron models and encoding schemes, and investigate the need for adaptability in hardware designs. Our work aims to illuminate the path towards embedded neuromorphic systems that fully exploit the computational advantages of sparse SNNS.", "sections": [{"title": "I. INTRODUCTION", "content": "Energy-efficient and high-performance computing architectures have become more essential than ever in the era of pervasive machine learning (ML) and artificial intelligence (AI). Spiking Neural Networks (SNNs), which mimic the event-driven communication of biological neurons, hold the promise of surpassing the energy efficiency of conventional Artificial Neural Networks (ANNs) [1]. An important reason for the potential efficiency of SNNs is that they exploit the inherent sparsity observed in biological neural systems, characterized by sparse coding [2], [3] and sparse connectivity [4], [5], and computation using partial synchrony instead of firing rate [6]. This sparsity translates directly into potential computational savings in hardware implementations, especially if the sparsity is explicitly exploited [7], [8].\nIn sparse coding, only a fraction of neurons are activated at a time. As a result, hardware designs that explicitly exploit sparse coding in SNN models can conserve energy by powering down inactive neurons, thus only consuming power for processing active signals on demand. This selective activation aligns well with event-driven processing, where computations are performed only when events (spikes) occur, reducing the overall energy consumption. Moreover, sparse connectivity implies that each neuron is connected to only a subset of other neurons, rather than a fully connected network. This reduces the complexity of the inter-neuronal communication infrastructure required. For an SNN hardware accelerator, this translates to fewer necessary connections and routing paths, which can simplify the accelerator's physical layout and reduce the energy costs associated with data transfer and storage. Furthermore, the high reliability of digital hardware (compared to biological neurons) makes it possible to increase the sparsity of the computations beyond what is observed in the brain to potentially achieve even more energy efficiency.\nHowever, translating this theoretical efficiency into tangible gains on real-world hardware remains a critical challenge. Specialized hardware platforms that explicitly exploit the characteristics of SNN workloads are necessary to reap the full benefits of sparse SNN computations [7], [8]. As such, the co-design of hardware and software holds the key to unlocking the energy-saving potential of SNNs. Algorithms and models must be tailored to work in synergy with hardware architectures optimized to handle the unique computational characteristics of sparse SNNs.\nKey considerations in this co-design process involve how sparsity is represented and how it interacts with the underlying hardware. Sparse operations in SNN computations often require different approaches for hardware acceleration than dense operations. Additionally, model configurations, such as the synaptic connectivity patterns, neuron models, encoding schemes, and the balance between different kinds of sparsity, including static and dynamic sparsity, can have profound impacts on hardware efficiency. For example, static sparsity, which refers to a fixed pattern of zero-valued weights in the SNN model, allows for predetermined optimizations like memory compression and skipping of computations with zero weights. On the other hand, dynamic sparsity, referring to the temporal event-based neuron activations, offers potential for further efficiency, but requires flexible hardware to handle variable, irregular, and unpredictable computational loads.\nThis paper provides an overview of the multifaceted field of hardware-software co-design for sparse SNNs, emphasizing the critical role of sparsity in achieving energy-efficient neuromorphic computing. We investigate the dynamic nature of sparsity, exploring its dependency on various factors such as training hyperparameters, neuron models, and input encoding methods. Through empirical analysis and detailed exploration, we quantify the impact of these factors on sparsity, offering valuable insights for optimizing SNNs for hardware implementation. We also address the challenges"}, {"title": "II. BACKGROUND ON SPIKING NEURAL NETWORKS", "content": "While both SNNs and ANNs ultimately map input patterns to outputs, their computational models differ significantly. ANNs rely on continuous-valued activation functions, whereas SNNs utilize discrete binary spikes within the temporal domain to represent information [9]. As depicted in Figure 1, using the integrate-and-fire neuron model [10] as an example, SNN neurons accumulate incoming spikes, integrating their weighted influence over time. A neuron fires an output spike only when its membrane potential surpasses a defined threshold. In this section, we present a brief overview of SNNs underpinned by the importance of sparsity as a core feature.\n1) Neuron models: At the heart of an SNN lies the individual neuron model and its synapses which determine the network's learning dynamics. Simple neuron models like the Leaky Integrate-and-Fire (LIF) [11] mimic the thresholding behavior of neurons, i.e., spikes are generated when their membrane potential exceeds a threshold. More complex models, such as the Hodgkin-Huxley [12], do not have an explicit threshold but detail the dynamics of membrane ion channels for greater biological realism and introduce computational overhead. The choice of neuron model profoundly impacts the efficiency obtained from network sparsity, learning dynamics, and the suitability for different hardware implementations.\n2) Spatiotemporal dynamics: SNNs fundamentally differ from traditional ANNs in their approach to information processing. While both utilize the activation patterns of neurons to encode information, SNNs introduce the precise timing of neuronal spikes as an additional dimension [13]. This timing allows neurons to convey information through single spikes, bursts, or complex temporal patterns. Learning mechanisms like Spike Timing Dependent Plasticity (STDP) [14], which modify synaptic strengths based on the relative timing between pre- and post-synaptic spikes, enable SNNs to learn both spatial and temporal patterns. This unique capability positions SNNs for applications in sequence recognition, temporal prediction, and adaptive behavior within dynamic environments. Furthermore, the inherent temporal sparsity of SNNs, where neurons only fire when necessary, contributes significantly to their energy efficiency [15].\n3) Learning in SNNs: Although backpropagation [16] has become a workhorse for effectively training ANNs in practice, training SNNs presents unique challenges due to the non-differentiability of spike-based signals. Several training methods address this, including ANN-to-SNN conversion [17], where a conventional ANN is trained and then converted to an SNN, potentially sacrificing accuracy and efficiency gains. Unsupervised methods utilize STDP [14], but often suffer from slow convergence, high sensitivity to noise and high sensitivity to parameter setting. More recently, supervised learning with surrogate gradients [18] has shown promise by using differentiable surrogate functions during backpropagation-like training, allowing optimization of SNNs for both accuracy and hardware efficiency.\n4) Input encoding: Input encoding in SNNs, the translation of real-world data into spikes, significantly affects information representation, network sparsity, robustness to noise, and hardware efficiency. Different encoding methods offer distinct trade-offs. For example, rate coding [19] encodes information in the average firing rate over time, offering high performance in deep networks (e.g., VGG9, VGG11) [20], but often at the cost of reduced sparsity due to the high spike rate. Temporal coding [21], conversely, focuses on the precise timing of spikes or patterns of spikes within short time frames [22]. While generally sparser than rate coding, it can sometimes lead to lower accuracy, though methods like time-to-first-spike (TTFS) have achieved high accuracy in certain applications [23], [24]. Delta encoding [25] strikes a balance by using the temporal change of input features to generate spikes, offering a compromise between sparsity and accuracy. Radix encoding [26] aims for ultra-short spike trains, achieving high accuracy with few time steps, but may require specialized hardware. Direct coding [27] bypasses explicit input encoding, allowing the training algorithm to learn the optimal mapping of input data to spiking patterns. The choice of encoding scheme depends on various factors, including input data characteristics, neuron models, and the target application.\n5) Applications: SNNs are well-suited for tasks where temporal dynamics and efficient processing are vital (e.g., machine learning implementations on resource-constrained devices). They are particularly well-suited for processing data from event-based sensors (such as neuromorphic vision sensors or dynamic audio sensors) [28], where the sensor output aligns naturally with the sparse, spike-based communication in SNNs. This enables low-power, real-time processing in resource-constrained edge computing systems. SNNs also show promise in embedded pattern recognition tasks [29] where stringent power constraints must be adhered to. Their ability to learn temporal patterns makes them applicable to tasks such as gesture recognition [30], anomaly detection in time-series data [31], or adaptive control systems [32]."}, {"title": "III. NEUROBIOLOGICAL FOUNDATIONS OF SPARSITY", "content": "Neuroscience research reveals that sparsity may be fundamental to the brain's organization and function, influencing storage [2], energy consumption [33], robustness to noise [34], and processing efficiency [35]. This sparsity manifests in various ways:\n1) Sparse neural coding: The brain employs a sparse distributed coding scheme, where only a small subset of neurons are active in response to specific stimuli or tasks, enhancing energy efficiency and robustness to noise [36], [37].\n2) Structural sparsity: The brain exhibits a high degree of sparse connectivity\u2014i.e., neurons form connections with only a fraction of other neurons [5]. This minimizes metabolic wiring costs and promotes modular and specialized subnetworks for efficient processing.\n3) Sparsity, plasticity, and learning: Sparsity interacts dynamically with learning mechanisms such as STDP [38], allowing for flexible synaptic modifications and synaptic pruning, which refines network representation during development and learning [39].\n4) Computational models of sparsity: Theoretical models suggest that sparsity enhances brain computing power by reducing redundancy and facilitating pattern separation [40], aiding in classification tasks [41].\nUnderstanding the biological basis of sparsity is crucial for developing neuromorphic computing systems that aim to mimic the brain's efficiency and low power consumption. Insights from biological sparsity can inspire the design of algorithms, hardware optimizations, and plasticity mechanisms for more efficient AI in resource-constrained systems."}, {"title": "IV. UNDERSTANDING THE DYNAMICS OF SPARSITY IN PRACTICAL SNNS", "content": "The inherent sparsity of SNNs is key to their energy efficiency. Sparsity is a dynamic property influenced by various factors like the network's training algorithms, neuron models, input encoding methods, and dataset characteristics. This section explores the impact of neuron models, their hyperparameters, and encoding methods on sparsity."}, {"title": "A. Sparsity in the LIF and Lapicque neuron models", "content": "To examine the sparsity characteristics of neuron models, we consider two simple models: Lapicque [42] and leaky integrate-and-fire (LIF) [11]. The Lapicque model, introduced in 1907, represents a neuron as a single point with a membrane potential that evolves in response to incoming inputs (I(t)). If the membrane potential (uj(t)) exceeds a threshold (\u03b8), the neuron fires a spike and resets to its resting value (Urest):\n\n$\\frac{du_j(t)}{dt} = \\begin{cases} I(t) & \\text{if } u_j(t) < \\theta \\\\  U_{\\text{rest}} & \\text{if } u_j(t) \\geq \\theta  \\end{cases}$ (1)\n\nDue to its simplicity, sparsity emerges naturally in the Lapicque model. If the input is insufficient to push the membrane potential above the threshold, the neuron remains silent. Sparsity in this model is primarily determined by the distribution of input weights and the chosen threshold value. However, its lack of temporal dynamics limits the complexity of sparsity patterns it can exhibit.\nThe LIF model extends the Lapicque model by introducing a \u201cleak\u201d term, simulating the gradual decay of the membrane potential towards its resting state. The interplay between input strength, the membrane potential\u2019s leak term, and the firing threshold governs the neuron\u2019s spiking behavior. The leak\u2019s time constant influences how quickly the neuron \u201cforgets\u201d previous inputs, impacting sparsity. A shorter time constant leads to a more rapid decay of the membrane potential in the absence of new inputs and effectively increases the amount of input current required to reach the firing threshold, thereby leading to sparser activity. The LIF neuron\u2019s characteristics can be expressed as:\n\n$u_j[t + 1] = \\beta \\cdot u_j[t] + \\sum_i W_{ij} \\cdot S_i[t] - S_j[t] \\cdot \\theta$ (2)\n\n$S_j[t] = \\begin{cases} 1, & \\text{if } u_j[t] > \\theta \\\\ 0, & \\text{otherwise} \\end{cases}$ (3)\n\nwhere \u03b2 (decay factor) controls the membrane potential decay rate, and impacts how the previous potential uj[t] affects the current potential uj[t+1]. \u03b8 represents the firing threshold to produce a spike sj[t]. A higher \u03b2 and \u03b8 can lead to sparser firing. More complex neuron models can similarly be analyzed based on their configurable parameters."}, {"title": "B. Practical impacts of model hyperparameters on sparsity", "content": "Model hyperparameters can significantly influence SNN sparsity and hardware efficiency. For example, a previous study [43] showed that using the fast sigmoid surrogate gradient function instead of arctan increased sparsity and improved frames per second/watt (FPS/W) by 11%. Fine-tuning neuronal parameters like decay rate and threshold further reduced latency by 48% with minimal accuracy loss.\nTo further examine the LIF and Lapicque neuron models, we performed experiments to explore the impacts of their different hyperparameters on sparsity. These experiments underscore the importance of sparsity-aware hardware-software co-design in the development of SNNs, illustrating the need for carefully balancing the trade-offs between accuracy and sparsity.\nWe used snnTorch [44] to build spiking neuron models and PyTorch to train a convolutional SNN (CSNN) on the Street View House Numbers (SVHN) dataset. We used a VGG-9-based [45] CSNN architecture with the structure: 64C3-P1-112C3-P1-192C3-P1-216C3-P1-480C3-P1-504C3-P1-560C3-P1-1064FC-P1-5000FC-P1-Dropout, where xCy denotes convolutional layers with x filters of size y \u00d7 \u0443. Depending on the neuron model employed, P1 represents either the LIF or Lapicque layer. xFC is a fully connected layer containing x neurons. Training was performed for"}, {"title": "V. CHALLENGES OF HARDWARE-SOFTWARE CO-DESIGN OF SNNS", "content": "While the potential benefits of SNNs are substantial, realizing these advantages in the real world necessitates careful co-design of the algorithms and the specialized hardware that supports them. In this section, we identify several key challenges that must be addressed to enable successful co-design for SNNs.\n1) Mapping algorithms to hardware: The complexity of the chosen neuron model has profound implications for hardware design. Complex models (e.g., Hodgkin-Huxley) might demand a large number of computations per timestep [46], straining embedded neuromorphic devices. Implementing on-chip learning rules, especially those beyond simple STDP, adds complexity in terms of memory technologies, update mechanisms, and potential trade-offs between flexibility and power consumption. Input encoding also plays a crucial role on the challenge of mapping SNN algorithms to hardware. For example, rate-based encoding can lead to dense activity, reducing the benefits of hardware-level sparsity support [47], while temporal encoding might necessitate specialized hardware for spike-time processing [48].\n2) Scalability and network architectures: Building large-scale SNNs necessitates the efficient routing of the potentially massive number of spike events, requiring specialized routing fabrics or memory-centric architectures that reduce communication overhead [49]. Implementing diverse SNN topologies introduces unique challenges at both the software and hardware levels. For example, deep convolutional SNNS need efficient distribution of convolutional kernels and management of spike-based data [8]. Replicating the connectivity of large-scale brain regions onto resource-constrained neuromorphic platforms might demand simplifying assumptions or distributed implementation strategies. Furthermore, real-time systems require optimized hardware-software mappings for real-time performance and sparsity [50].\n3) Accuracy vs. efficiency trade-offs: SNN optimizations for efficiency, like reducing the bit precision of weights and activations (i.e., quantization) [51], can significantly increase sparsity. However, such optimizations for efficiency might also carry the risk of severe accuracy degradation. Finding hardware-aware, optimal quantization strategies is important. Similarly, although pruning away weights creates sparsity, different SNN architectures might exhibit varying degrees of sensitivity to pruning. In addition, changes to the SNN architecture can create new trade-off considerations for different workloads. For instance, expanding an integrate-and-fire neuron model to a more bio-realistic leaky mechanism might increase the area overhead [47], leading to important workload-specific trade-off considerations regarding the efficiency impacts of the more realistic neuron model.\n4) Neuromorphic hardware heterogeneity: Analog neuromorphic chips [52], [53] might offer superior energy efficiency but can suffer from device mismatch and noise, impacting accuracy. Digital platforms offer flexibility but could demand more complex circuitry to achieve equivalent sparsity benefits.\nThe diversity of hardware also means navigating specialized programming tools and abstractions, potentially creating vendor lock-in and hindering the portability of SNN solutions.\n5) Lack of standardized tools and benchmarks: Comparing the performance of SNNs fairly across different algorithms and hardware platforms is hindered by a lack of standardization. Several current benchmarks focus on simple datasets (e.g., MNIST, FashionMNIST) [54], which do not fully capture the strengths of SNNs in handling temporal or spiking sensor data (e.g., neuromorphic vision sensors, audio). While there is a growing body of work focused on developing neuromorphic datasets (e.g., [55]) the development of SNNs would benefit from more comprehensive benchmarks that include tasks like dynamic object recognition, spatiotemporal pattern analysis, and processing event-based sensor data, reflecting real-world scenarios where SNNs could excel. Additionally, software frameworks for SNNs [44] currently lack the maturity of debugging, profiling, and hardware mapping tools available for ANNs, potentially slowing down the research and deployment cycle of SNNs."}, {"title": "VI. SURVEY OF SPARSITY-AWARE HARDWARE ARCHITECTURES FOR SNNS", "content": "Addressing the challenges in hardware-software co-design for sparsity-aware SNNs demands specialized hardware that can seamlessly handle the unique computational demands of these networks. The potential for extreme energy efficiency hinges on architectures explicitly designed to exploit irregular sparsity patterns and event-driven communication. Table II summarizes several innovative designs and approaches that have emerged. This section surveys some of the recent advances in this field, providing a representative overview of the strategies being explored to unlock the power of sparsity-aware SNN hardware.\nOne notable sparsity-aware implementation is Cerebron, a reconfigurable architecture that effectively handles both spatial and temporal sparsity in SNNs [56]. It utilizes an online channel-wise workload scheduling strategy to maximize data reuse and reduce computation time. This leads to significant reductions in prediction energy and faster processing, highlighting the importance of exploiting sparsity for neuromorphic computing.\nLiu et al. [57] introduced the MISS (Memory-based Irregular Sparsity Support) framework to tackle irregular sparsity with a combination of software and hardware optimizations. The framework applies unstructured pruning to synaptic weights for increased efficiency. The hardware utilizes a sparsity-stationary data flow to optimize memory usage and minimize processing overheads associated with sparsity, improving energy efficiency and speed. The MISS framework achieved an average of 36% improvement in energy efficiency and 23% speedup over baseline SNN accelerators by exploiting irregular sparsity in both input spikes and synaptic weights. Kuang et al. [58] presented an accelerator called ESSA (Efficient Sparse SNN Accelerator) that targets both temporal sparsity (in spike events) and spatial sparsity (in weights) for enhanced SNN inference throughput. Key design features include adaptive spike compression for efficient handling of sparse spike patterns and a flexible fan-in/fan-out trade-off to work within neuromorphic system constraints. Results showed that ESSA achieved a performance equivalent of 253.1 GSOP/s and an energy efficiency of 32.1 GSOP/W for 75% weight sparsity on a Xilinx Kintex Ultrascale FPGA, showing significant improvements in throughput and energy savings compared to other neuromorphic processors.\nUnlike the prior works, which focused on inference, Yin et al. [7] proposed a sparsity-aware accelerator for training called SATA. SATA (Sparsity-Aware Training Accelerator for SNNs) focuses on making SNN training more efficient using backpropagation through time (BPTT). Its systolic-based accelerator architecture exploits various forms of sparsity (in spikes, firing function gradients, and membrane potentials) to improve training energy efficiency. SATA's analysis demonstrates that SNN training can be less energy-intensive than traditional ANN training. The analysis showed that although SNN training consumed approximately 1.27 times more total energy than ANNs when considering sparsity, it improved"}, {"title": "VII. CONCLUSION", "content": "We provided an overview of the hardware-software co-design of sparse SNNs, emphasizing the critical role of sparsity in achieving energy-efficient neuromorphic computing. Key takeaways include the understanding that sparsity is a dynamic property, influenced by various factors such as network architecture, training algorithms, neuron models, and input encoding methods. The exploration of different sparsity-aware hardware architectures reveals the potential for significant performance and energy efficiency gains through specialized designs that exploit irregular sparsity patterns and event-driven communications. The insights presented in this paper pave the way for future research in developing neuromorphic systems that fully exploit the computational advantages of sparse SNNs, enabling highly energy-efficient artificial intelligence in resource-constrained systems."}]}