{"title": "Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare", "authors": ["Tianqi Shang, MS", "Weiqing He, MS", "Tianlong Chen, PhD", "Ying Ding", "Huanmei Wu", "Kaixiong Zhou, PhD", "Li Shen, PhD"], "abstract": "Social determinants of health (SDoH) play a crucial role in patient health outcomes, yet their integration into biomedical knowledge graphs remains underexplored. This study addresses this gap by constructing an SDoH-enriched knowledge graph using the MIMIC-III dataset and PrimeKG. We introduce a novel fairness formulation for graph embeddings, focusing on invariance with respect to sensitive SDoH information. Via employing a heterogeneous-GCN model for drug-disease link prediction, we detect biases related to various SDoH factors. To mitigate these biases, we propose a post-processing method that strategically reweights edges connected to SDoHs, balancing their influence on graph representations. This approach represents one of the first comprehensive investigations into fairness issues within biomedical knowledge graphs incorporating SDoH. Our work not only highlights the importance of considering SDoH in medical informatics but also provides a concrete method for reducing SDoH-related biases in link prediction tasks, paving the way for more equitable healthcare recommendations. Our code is available at https://github.com/hwq0726/SDoH-KG.", "sections": [{"title": "Introduction", "content": "Knowledge graph is widely used to organize real-world entities and their relationships in a graph structure. It is comprised of nodes and edges, where nodes can represent entities like objects, events, concepts, and so on, while edges define the relationships between them. Knowledge graphs have emerged as powerful tools in biomedical research, enabling the representation of complex relationships between various biomedical entities such as drugs, diseases, and genes. For example, PrimeKG, a multimodal knowledge graph for precision medicine analyses; Monarch, an analytic platform integrating phenotypes, genes, and diseases across species; DRKG, a comprehensive biological knowledge graph designed for Covid-19 drug repurposing. By structurally storing the vast amounts of biomedical knowledge triplets, these graphs have facilitated the advancements in drug discovery, disease prediction, personalized medicine, and so on.\nRecently, machine learning (ML) models have been developed to capture the complex structure of knowledge graphs, with a focus on tasks such as link prediction, node classification, and graph completion. The existing effective knowledge graph approaches can be roughly divided into two groups: traditional embedding and deep neural networks. First, the traditional knowledge graph embedding models like TransE, TransR, and RotatE, map the entities and relations within a knowledge graph into low-dimension vectors in a continuous embedding space, making it easier to perform downstream tasks. Second, Graph Neural Networks (GNNs) have been explored to process graph-structured data and encode entity features. GNNs work by iteratively aggregating information from a node's neighbors to learn node representations. Popular variants include Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), and Relational GCNs (R-GCNs). Besides the modeling advancements, the quality of graph data itself play a crucial role for the accuracy and trustworthiness of many downstream healthcare tasks, e.g., discovering potential drug-disease associations or predicting treatment outcomes. The edge connections among the biomedical entities will significantly influence the aggregation learning, node embeddings, and thus decision outcomes. Although GNNS widely deliver prediction efficacy in healthcare applications, they notoriously tend to capture structural bias and lead to biased predictions. There exists a research gap in how to bridge GNNs and healthcare knowledge graph construction."}, {"title": "", "content": "Social Determinants of Health (SDoH), including the conditions in which people are born, grow, live, work, and age, as well as the broader forces and systems that shape daily life, are non-medical factors that impact health outcomes. The impact of SDoH on health disparities has been a growing area of focus, with substantial research dedicated to understanding and addressing their influence. While incorporating SDoH data into predictive models can enhance accuracy, fairness issues may arise when certain groups based on socioeconomic status, education, race, or other factors are underrepresented or misrepresented in the data. In biomedical applications, such biases can disproportionately affect marginalized populations, exacerbating health disparities. For instance, insurance companies might use algorithms informed by SDoH data to assess risk and determine coverage. Individuals from areas with high rates of unemployment might be considered at higher risk due to potential gaps in health coverage or inconsistent medical care, which could affect the premiums they pay or their eligibility for certain plans. The inclusion of SDoH factors in knowledge graphs, while essential for understanding the broader context of health outcomes, also introduces the risk that machine learning models trained on these graphs may propagate or even amplify existing inequities in healthcare delivery and treatment. As machine learning continues to drive decision-making in healthcare, ensuring fairness in models trained on knowledge graphs is becoming increasingly critical. Addressing bias in these systems is essential not only for the accuracy of predictions but also for their ethical deployment in medical practice. However, while the fairness of ML models has been studied extensively in various fields, little research has been conducted on the fairness implications of SDoH in knowledge graphs. This brings us to the core focus of this work: investigating how SDoH data in biomedical knowledge graphs affects link prediction results, and proposing methodologies to detect and mitigate bias, ultimately advancing fairness in healthcare AI.\nIn this work, we collect patients' disease, drug, and SDoH information from the MIMIC-III dataset and phenotype information from PrimeKG to construct an SDoH knowledge graph. Based on this constructed graph, we employ the idea of demographic parity to develop a novel formulation of fairness within the context of link prediction, focusing on the invariance with respect to sensitive SDoHs. Specifically, we train a heterogeneous-GCN model to perform link prediction between drugs and diseases, and use this fairness notion to detect bias related to different types of SDoH information. For example, we explore whether the economics or education information can affect the medication recommendations between certain drug and disease. We also proposed a post-processing method to eliminate this bias. The key idea behind our de-biasing method is the strategic re-weighting of edges connected to SDoHs. This re-weighting aims to balance the influence of different sensitive SDoH factors, reducing the risk of unfair disparities in the graph's representation and subsequent predictions. To the best of our knowledge, this study represents one of the first comprehensive investigations into SDoH fairness issues within biomedical knowledge graphs."}, {"title": "Preliminaries", "content": "In this section, we sequentially introduce the concepts of Heterogeneous Graphs, Graph Convolutional Networks (GCNs), and link prediction, providing foundational context for the subsequent discussions."}, {"title": "Heterogeneous Graph", "content": "A heterogeneous knowledge graph is a type of graph that contains multiple types of nodes and/or multiple types of edges. This is in contrast to a homogeneous graph, where all nodes and edges are of the same type. In a heterogeneous graph, the different node types and edge types capture more complex relationships and interactions between various entities. We consider a heterogeneous graph G = (V, E), which consists of a set of directed edge triples e = (u, r, v) \u2208 \u0395, where u, v \u2208 V are nodes and r\u2208 R is a relation type. We further assume that each node is of a particular type, TC V, and that relations may have constraints regarding the types of nodes that they can connect. For example, in a heterogeneous biomedical knowledge graph, nodes include different entities like drugs, diseases, and genes, while edges represent different types of relationships, such as \"treats,\" \"causes,\" or \"is associated with.\""}, {"title": "Graph Convolutional Networks", "content": "Graph Convolutional Networks (GCNs) is a type of neural network designed to operate directly on graph-structured data. It extends the concept of convolution from grid-like data (such as images) to arbitrary graphs, allowing node features to be aggregated from their neighbors, thus capturing the local structure of the graph. In a GCN, each node's representation is updated by aggregating feature information from its neighbors, weighted by the graph structure. The transformation at each layer can be expressed as:\n$h_i^{(l+1)} = \\sigma(\\sum_{j \\in N(i)} C_{ji}h_j^{(l)}W^{(l)} + b^{(l)})$"}, {"title": "", "content": "where N(i) is the set of neighbors of node i, cji is the product of the square root of node degrees (i.e., $C_{ji} = \\sqrt{|N(j)|}\\sqrt{\\N(i)|}$), $b^{(l)}$ is a bias term added to adjust the output, and o is an activation function (e.g., ReLU). This formulation enables the GCN to learn node representations by leveraging both node features and the graph's structure. Mathematically, GCN maps each node v \u2208 V to a fixed size vector zv, and z can be used for downstream tasks like node classification, link prediction, and graph classification."}, {"title": "Link Prediction", "content": "Link prediction is a task in graph analysis aimed at predicting the likelihood of potential or missing connections between nodes in a graph. The link prediction task on graph G can be defined as follows. Let $E_{train} \u2282 E$ denotes a set of observed training edges and let \u00ca = {(vi, r, vj) : vi, vj \u2208 V,r \u2208 R}\\E denotes the set of negative edges that are not present in the true graph G. Given $E_{train}$ and a scoring function \u03c6, an ideal model should assign higher scores to positive (true) edges than to any negative (false) edges. Specifically, if we focus at the link prediction of relationship r*, using GCN as the embedding model and dot product as the scoring function, then we expect:\n$(Z_u, Z_v) > (Z_{u'}, Z_{v'}), \u2200(u, r*, v) \u2208 E, (u', r*, v') \u2208 \u00ca$"}, {"title": "", "content": "In the training phase, for each positive nodes pair (edge) (u, v), in the target relationship r*, we sample K arbitrary nodes pairs {(u, vi) i}K. According to equation 2, we encourage the score between node u and v to be higher than the score between node u and a sampled node vi, and use margin loss as the loss function to train a model for link prediction task,\n$L = \\sum_{i=1,...,K} max (0,1 \u2013 \u03c6(u, r*, v) + \u03c6(u, r*, vi))$"}, {"title": "", "content": "The training process is end-to-end, where the embedding model, such as a GCN, is trained to generate node represen-tations that minimize the margin loss."}, {"title": "Research Design and Methods", "content": "In this section, we begin by explaining the construction of the SDoH knowledge graph, detailing the types of nodes and the relationships captured in the graph. Next, we motivate and argue in favor of a particular form of \"fairness\" within the context of graph link prediction. Following this, we outline our de-biasing method which involves a re-weighting strategy on the edges. Figure 1 presents our workflow."}, {"title": "Dataset Construction", "content": "MIMIC-SBDH is a data set containing 7,025 discharge summary notes randomly selected from the MIMIC III dataset. The notes are annotated for the patient's status of the following Social and Behavioral Determinants of Health (SBDHs): Community, Education, Economics, Environment, Alcohol Use, Tobacco Use, and Drug Use, which we consider as Social Determinants of Health (SDoH) in this study.\nFor each discharge summary in MIMIC-SBDH, we identify its corresponding patient in the MIMIC III dataset accord-ing to its note ID. This allows us to obtain the patient's diagnosis and prescription data, capturing the disease and drug information of the patient. By linking these three entity types\u2014disease, drug, and SDoH\u2014we established relation-ships that provide a comprehensive view of each patient's health profile. To further extend this data, we incorporated phenotype information from PrimeKG. PrimeKG provides a more holistic representation, as it directly connects phe-notypes with both drugs and diseases. Since phenotypes are more likely to be influenced by SDoH factors than genetic information alone, incorporating phenotype data allowed us to enhance the dataset's representation of the social and biological determinants of health."}, {"title": "Fairness Notion and Bias Detection", "content": "In the section, we discuss the definition of our fairness notion and the way we detect the bias. We consider a simple, intuitive formulation of fairness within the context of link prediction. Using economic level as an example of a sensitive SDoH and drug re-purposing as an example relation prediction task, our approach is guided by the following question: What potential new therapeutic uses might be identified for an existing drug if we disregard the economic information associated with it? In other words, the discovery would be the same regardless of the economics information. Formally, given a drug u and a disease v, for the edge between u and v, the score (probability) should be independent with sensitive SDoH information T*,\n$\\Phi(Z_u, r, Z_v) \\perp \\mathbb{1}_{(u,w)}, \\forall r \\in \\mathbb{R}', w \\in T^*$\nwhere $1_{(u,w)}$ is the indicator function, equals to 1 if there is an edge between u and w, and 0 otherwise, and R' denotes the set of all possible relations between drugs and disease. For simplicity, we consider only one possible relation from drug to disease (i.e., |R'| = 1), and we can abbreviate \u03c6(zu, r, zv) as \u03c6(zu, zv). Additionally, we assume that the set T* contains only two nodes*, denoted as w0 and w1. With this in mind, we define the bias with sensitive SDOH factor T* as:\n$D_{T^*} = |E[(Z_u, Z_v) | \\mathbb{1}_{(u,w_0)} = 1] \u2013 E[(Z_u, Z_v) | \\mathbb{1}_{(u,w_1)} = 1]|$"}, {"title": "", "content": "$D_{T^*}$ evaluates the disparity in the score of an edge between drug u and disease v when u associates with different sensitive SDoH information. It is worth mentioning that our fairness notion is similar to traditional demographic parity, as both are independent of the true label (i.e., they do not consider whether the edge actually exists). However, in traditional fairness problems in knowledge graphs, sensitive information is typically encoded as node attributes with varying values. In contrast, in our approach, we treat sensitive information as separate nodes and examine bias based on different connection patterns.\nNext we apply this notion to detect the bias with respect to different potential sensitive SDoH factors. We begin with the definition of Ti-free drug nodes. As mentioned before, we have eight categories of SDoHs and we consider Community Present/Absent, Education, Economics, and Environment as the potential sensitive SDoHs, denoted as {Ti}1. We then define Ti-free drug nodes as the drug nodes which are not connected with any nodes in Ti. For example, drug 481(*IND* Pexelizumab/Placebo) is not connected with either 'Environment: True' or 'En-vironment: False', then it is considered an Environment-free drug node. In other words, the Ti-free drug nodes contain no information of Ti.\nTo detect the bias with respect to sensitive SDoH Ti = {wo, w1}, we first collect Ti-free drug nodes and for each of these nodes choose one drug-disease edge to build the test edge set C. Then we mask all the edges in C to generated a training graph. Using this training graph to create two testing graphs: Go by connecting Ti-free drug nodes to wo and masking the edges in the test edge set, and G1 by connecting Ti-free drug nodes to w1 and similarly masking the test edges. We then train a GCN model on the training graph, use the trained model to perform inference on Go and G1 respectively. Employing dot product as the scoring function, we compute the scores s0 and s1 for the test edges on each respective graph. Finally, we get the bias DT by calculating the mean absolute difference between the scores so and s1. Figure 3 illustrates this detection process."}, {"title": "De-bias Method", "content": "In this work, our fairness-aware method aims at removing bias from the graph structure itself by re-weighting the edges between drug and SDoHs. As mentioned in the Preliminaries, the weight of each edge in the graph is all considered equally, in other words, the graph's adjacency matrix only contains 0 and 1. By assigning equal weight to all edges during aggregation, the model can unintentionally amplify biases in the data. In a knowledge graph containing mul-tiple types of SDoHs, this equal treatment assumes that all edges\u2014representing relationships like economic level or alcohol use-contribute equally to the predictions. However, sensitive SDoH like economics may have disproportion-ate influence on medical outcomes, leading to biased predictions. For instance, individuals from lower economic levels may face different healthcare challenges, which could skew the predictions if those edges are not properly weighted."}, {"title": "", "content": "By treating every edge equally, the model risks over-representing or under-representing certain SDoH factors, leading to unfair and biased link predictions between drugs and diseases. To address this inherent bias in traditional GCNs, we proposed a re-weighting strategy on the edges between SDoHs and drugs. We begin with adding weighting parameter to each layer of GCN, the weighted transformation at each layer is expressed as:\n$h_i^{(l+1)} = \\sigma(\\sum_{j \\in N(i)} \\frac{e_{ji}}{C_{ji}}h_j^{(l)}W^{(l)})$"}, {"title": "", "content": "where eji is the scalar weight on the edge from node j to node i and other parameters remain consistent with those defined in the Preliminaries. The involvement of the weighting parameter enables the model to assign different im-portance to each edge and allows for a more nuanced representation of relationships by controlling the contribution of sensitive SDoHs, such as economic level, in the prediction process. During the training process, we aim to learn the weighting parameter that minimizes bias with respect to sensitive SDoH factors. To detect and remove the bias with respect to sensitive SDoH T\u2081 = {wo, w\u2081}, we follow the steps in Bias Detection but collect a different test edge set C' to generate two training graphs for de-biasing: G, G\u00ba. For the pre-trained GCN model, we freeze all the learnable parameters except for the initialized weighting parameter \u00ea (i.e., in equation 6, we freeze b(1) and W(1)). Using the weighted-GCN, we perform inference on Go and G. With the dot product as the scoring function, we compute the scores of test edge set C' on both graphs, denoted as sa, so. The loss function is then defined as the mean squared difference between these two scores:\n$L_{fair} = \\frac{1}{n}\\sum_{i=1}^{n} (s^d_{0,i} - s^d_{1,i})^2$"}, {"title": "", "content": "where n is the length of the vectors (the number of elements in s and s1), and so,i, s1i are the i-th elements of the vectors s0 and s1 respectively. In the training process, only the weighting parameter \u00e9 is learnable, and with back-propagation \u00ea can be updated to minimize the loss. Figure 4 presents the training process of the de-biasing method."}, {"title": "Results", "content": "As mentioned in the previous section, we limit our fairness analysis to the following categories: Education, Eco-nomics, Environment, and Community Present/Absent. Alcohol, tobacco, and drug use are not considered as sensitive factors in this context since fairness evaluations on these categories would not provide meaningful insights. Sensitive attributes in fairness evaluations are typically those that are associated with systemic inequalities or discrimination, such as race, gender, socioeconomic status, or education level. These attributes are protected under various ethical and legal frameworks (e.g., anti-discrimination laws like the U.S. Civil Rights Act or the European Union's General Data Protection Regulation), which aim to prevent models from disproportionately impacting specific demographic groups. In contrast, alcohol, tobacco, and drug use are considered behavioral factors that do not inherently align with these protected categories. While these behaviors may influence health outcomes, they are generally viewed as personal lifestyle choices rather than attributes that represent underlying social inequalities. Furthermore, individuals may engage in or abstain from these behaviors for a variety of reasons\u2014such as personal preference, medical advice, or cultural norms\u2014which complicates their classification as sensitive attributes. For the selected five SDoH cate-gories, we applied the bias detection and de-biasing method as outlined in the Research Design and Methods section to measure and mitigate bias.\nAs shown in Table 2, our de-biasing method significantly reduced the bias across all five SDoH categories. The bias values in the table represent the disparity in prediction scores associated with different SDoH factors, as defined by our fairness notion. The \"Initial Bias\" column indicates the extent of bias before applying our de-biasing method, while the \"Current Bias\" shows the reduced bias after applying our re-weighting strategy on the edges between SDoHs and drugs. The reduction in all five SDoH categories proves that our method is both effective and comprehensive. In addition to measuring bias reduction, we evaluated the impact of our de-biasing method on the predictive performance of the model, as indicated by the Mean Reciprocal Rank (MRR) which evaluates the mean reciprocal rank of the positive edge score among the arbitrary edge scores (in our experiment, we samlpe 20 arbitrary nodes pairs for each positive nodes pair.). The original MRR was 0.36064, and after de-biasing, the MRR values for each category were marginally different, ranging between 0.36066 and 0.36071. These slight variations indicate that the de-biasing process did not significantly alter the model's predictive accuracy. The minimal change in MRR demonstrates that our de-bias method strikes a crucial balance between fairness and accuracy. Achieving fairness often comes at the cost of reduced model performance, but in our case, the model retained its high accuracy while also becoming significantly fairer across multiple sensitive attributes. This indicates that our de-biasing method is both efficient and practical for real-world biomedical applications, where fairness and accuracy are equally important."}, {"title": "Discussion and Implications", "content": "Contributions This study makes several significant contributions to the field of biomedical informatics and fairness in machine learning. Firstly, we have successfully constructed a comprehensive knowledge graph that integrates Social Determinants of Health (SDoH) with traditional biomedical data, providing a more holistic representation of patient health factors. Secondly, we have introduced a novel fairness notion specifically tailored for graph embeddings, along with an innovative method to detect biases related to sensitive SDoH within the link prediction task. This advancement allows for a more nuanced understanding of how social factors may influence medical predictions and recommendations. Lastly, we have developed and presented a post-processing technique that effectively reduces SDoH-related biases while maintaining model accuracy, ensuring fairer and more equitable predictions in real-world biomedical applications, where fairness and accuracy are equally important."}, {"title": "Limitations and Future Work", "content": "Despite the significant strides made in this study, several limitations warrant consid-eration and point towards directions for future research. The primary limitation lies in the dataset used, which, while comprehensive, may not fully represent the diversity of global populations and healthcare systems. Future work should focus on validating our approach across more diverse datasets to ensure generalizability. Additionally, while our bias detection and mitigation methods show promise, they currently focus on a limited set of SDoH factors. Expanding this to include a broader range of social determinants could provide even more comprehensive insights into healthcare disparities. Another avenue for future research involves the exploration of more sophisticated graph neural network architectures, where the re-weighting strategy may need to be refined or adapted to suit the increased complexity of the model. Lastly, investigating the real-world impact of our fairness-enhanced predictions on clinical decision-making processes could provide valuable insights into the practical applications of this work."}, {"title": "Conclusion", "content": "In conclusion, this study represents a significant step forward in addressing fairness issues within biomed-ical knowledge graphs, particularly concerning the integration and impact of Social Determinants of Health. By con-structing an SDoH-enriched knowledge graph, defining novel fairness metrics for graph link prediction task, and de-veloping methods to detect and mitigate bias, we have laid the groundwork for more equitable medical predictions and recommendations. As healthcare system continues to move towards more personalized and data-driven approaches, the methods and insights presented in this study will be useful in ensuring that these advancements benefit all individ-uals equally, regardless of their social circumstances. This work opens up new possibilities for fair and comprehensive medication analytics, paving the way for more equitable and effective healthcare systems."}]}