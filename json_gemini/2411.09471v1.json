{"title": "Renal Cell Carcinoma subtyping: learning from multi-resolution localization", "authors": ["Mohamad Mohamad", "Francesco Ponzio", "Santa Di Cataldo", "Damien Ambrosetti", "Xavier Descombes"], "abstract": "Renal Cell Carcinoma is typically asymptomatic at the early stages for many patients. This leads to a late diagnosis of the tumor, where the curability likelihood is lower, and makes the mortality rate of Renal Cell Carcinoma high, with respect to its incidence rate. To increase the survival chance, a fast and correct categorization of the tumor subtype is paramount. Nowadays, computerized methods, based on artificial intelligence, represent an interesting opportunity to improve the productivity and the objectivity of the microscopy-based Renal Cell Carcinoma diagnosis. Nonetheless, much of their exploitation is hampered by the paucity of annotated dataset, essential for a proficient training of supervised machine learning technologies. This study sets out to investigate a novel self supervised training strategy for machine learning diagnostic tools, based on the multi-resolution nature of the histological samples. We aim at reducing the need of annotated dataset, without significantly reducing the accuracy of the tool. We demonstrate the classification capability of our tool on a whole slide imaging dataset for Renal Cancer subtyping, and we compare our solution with several state-of-the-art classification counterparts.", "sections": [{"title": "1. Introduction", "content": "Renal Cell Carcinoma (RCC) is a highly malignant tumor and the most widespread type of kidney cancer, accounting for 90% of the overall entities."}, {"title": "2. Background", "content": "2.1. RCC subtyping\nMuch of the studies on RCC subtyping come from the exploitation of the TCGA database [4, 5, 13], without furnishing results at the WSI level [4, 5] or at the patient-level [4, 5, 13]. Furthemore, much of the current literature considers only two [14, 15] (or three [4, 5, 13, 16]) RCC main malignant tumor subtypes: ccRCC and pRCC (and chRCC). This is mainly due to the fact that, being dedicated to malignant tumors, TCGA data portal excludes renal oncocytoma cases."}, {"title": "2.2. Self-supervised learning in histology", "content": "Self-supervision was introduced as a solution for annotation-hungry models in their application domains. SSL exploits labels obtained from the data itself, through a semi-automatic process, to delineate a supervised pretext task capable of learning an effective representation of the original data. Although the pretext task conducts the learning by means of a supervised loss function, the performance of the model on the pretext is peripheral, being"}, {"title": "3. Materials and methods", "content": "3.1. Patients cohorts and dataset\nIn our database, we collected tissue samples from 91 consecutive patients, who encountered nephrectomy in the Nice Hospital Urology Department, di- agnosed with ccRCC (n=56), papRCC (n=22), chrRCC (n=6) or ONCO (n=7). As defined by the 2022 WHO criteria, the diagnosis was based on pathology and cytogenetic analysis. H&E stained WSI (scanned using a Le- ica AT2 Digital Slide Scanner, Leica Microsystems CMS GmbH, Wetzlar,"}, {"title": "3.2. Formulation", "content": "Suppose a WSI has N magnification levels, where 0 is the base level, featuring the lowest resolution, and N is the maximum, providing the highest- resolution images of smaller areas of the tissue (see Figure 1).\nWe can denote as $p_t$ a generic patch, taken from the WSI at level t, with size $(W_t, H_t)$. At a higher magnification level t + 1, $p_t$ is represented by a higher magnification patch having size $(W_{t+1} = 2 \\times W_t, H_{t+1} = 2 \\times H_t)$, being the zoom factor between two consecutive levels $\\times2$. Thus, as shown in Figure 1, $p_t$ can be represented as 4 non-overlapping patches in level t + 1, each one having the same dimensions as $p_t$. The formulation of our SSL task specifically relies on such relation between patches in different WSI levels, as detailed in the following.\nConsider two resolution levels x and y $\\in$ [0... N], such that y < x, and let $p_y$ be a patch extracted from level y (see Figure 2(a)). We can term $C_{x|y}$ the set in x containing all the non-overlapping patches that jointly describe $p_y$.\nLastly, let $p_x \\in C_{x|y}$ be a patch belonging to level x, randomly extracted from $C_{x|y}$. The objective in our pre-text task is the prediction of the location of $p_x$ inside $p_y$.\nWe formalize our task as a classification problem by randomly sampling a patch from set $C_{x|y}$, which consists of $4^{n}$ patches, being n = y - x the"}, {"title": "3.3. Implementation details", "content": "In this section, we give the implementation details of the proposed architecture."}, {"title": "3.4. The pretext", "content": "We split the 91 patients between training and test set, with a split ratio not fixed among the different classes to ensure proper representation of all"}, {"title": "3.5. RCC subtype classification", "content": "We start by dividing the ROIs into 1024x1024 patches at the maximal resolution, filtering out the white background and resizing the rest to 112x112 pixels. We balance and split the resulting data into a training (85%) and a validation subset (15%). For the test set, we follow the same pipeline, except"}, {"title": "3.6. Counterpart models", "content": "In our study, we compare the proposed architecture with three counter- part solutions, representing a picture of the different state-of-the-art training paradigms for machine learning models adopted in the classification of his- tological WSI:\ni) the SSL methodology, proposed by Ding et al [26];\nii) a canonical CNN pre-trained on the ImageNet dataset and fine-tuned on the RCC classification task\niii) a fully supervised solution, proved to be the top performing one in this classification scenario in a recent study [7]."}, {"title": "3.6.1. SSL methodology", "content": "As previously mentioned, the solution by Ding et al. [26] consists of a model which learns a powerful data representation by understanding if a magnified patch lies inside or outside of a zoomed-out one. To put into effect such method, we started from our SSL task dataset and we generated the data by taking a tuple of samples and switching their high-resolution patch with a probability of 0.5. If the patches were switched, both samples became negative samples, and if they were not switched, the samples were considered positive. We used the same fusion scheme and hyper-parameters they used in their experiment and trained until the performance plateau at around 50 epochs."}, {"title": "3.6.2. Imagenet-based", "content": "To define a solid transfer learning based counterpart, we refer to our previ- ous work, where we individuated the VGG16 CNN pre-trained on ImageNet"}, {"title": "3.6.3. Fully supervised solution: the ExpertDT", "content": "As fully supervised counterpart, we select ExpertDT, a classification model which leverages a combination of supervised deep learning models (specifi- cally CNNs) and pathologist's expertise to substantially improve the accuracy in the RCC subtyping task [7].\nAll the counterparts frameworks are trained using Adam optimizer and a weight decay of 10-5. The best-performing models in terms of validation accuracy is always selected and all of them use a linear classifier for the downstream task."}, {"title": "4. Results", "content": "A competent SSL framework should ideally have two main characteristics. First, it should be accurate in a way that is not too far from fully supervised solutions. On the other hand, it should be robust and capable of scaling well with the reduction of available dataset, used in the downstream supervised learning task. Thus, we designed two peculiar experiments to test them. Figure 3 shows the outcome of the first set of experiments, reporting the confu- sion matrices obtained on the RCC subtyping task of our solution (top-left), Ding et al.'s counterpart [26] (top-right), ImageNet-based (bottom-left), and the fully supervised solution ExpertDT [7] (bottom-right). Such confusion matrices report the absolute number of patients correctly categorized (see the main diagonal) and incorrectly assigned (other positions of the grid) for each of the four classes of interest. We were the second-best solution in terms of mean accuracy between classes, following only the supervised one (76.5% ours versus 87% ExpertDT). Furthermore, we outperformed the counterpart SSL methodology by around 12% (76.5% ours versus 64.3% Ding et al.), as well as the ImageNet-based one by more than 6% of mean accuracy (76.5% ours versus 69.8% ImageNet).\nIn absolute terms, our solution misclassified 11 patients, the SSL counter- part 13, the Imagenet-based 13 as well, while ExpertDT only 10 (all rounded up). By running this set of experiments five times, we were able to also as- sess the robustness of the solutions tested among different execution of the learning. This aspect is embodied in the standard deviation of the number"}, {"title": "5. Discussion", "content": "In this study, we proposed a frontier SSL approach based on the concept of inter-level connectivity of WSI, which mimics the reasoning and the pro- cedure of a pathologist, diagnosing RCC lesions. The comparison between our solution and different baselines reveled a number of interesting aspects.\nFirst, despite being substantially less accurate with respect to a fully su- pervised solution, our method outperforms the recent SSL procedure pro- posed by Ding et al [26], as well as a common baseline made up of an ImageNet-pretrained CNN, fine tuned on the final classification task.\nOur solution seems also to be quite robust among different runs of the learning procedure, showing relatively low variations of the classes assigned to the different collected subjects. This can be evinced from both the standard deviations reported in Figure 3, and the error bars of Figure 4.\nAdditionally, the proposed methodology shows a good robustness in pres- ence of a progressively reduced size of the annotated training set. This aspect is paramount, as it is the main reason of researching learning solutions able to minimize the needing of annotations, which are costly, especially in the pathology domain. Our method still performs with a mean accuracy above 80% with only 33% of employed training set. This suggests superior robust- ness with respect to the two SSL counterparts, although, as expected, both of them mitigate the performance degradation, caused by the reduction of the employed training set, especially when compared to the supervised method- ology. Indeed, with only 33% of the training set employed for the learning, the supervised solution classifies with a mean accuracy below 75%, which is more than 8% lower than our SSL methodology. This largely assess the good- ness of the proposed pre-text task, which significantly reduces the amount of required annotated samples, with respect to a canonical supervised learning.\nAs future directions, we intend to expand our dataset with other RCC cancers, including rare subtypes and classes. Moreover, we intend to investi- gate the performance of the proposed solutions in other histological domain, to assess the portability of the system in other cancer subtyping tasks."}]}