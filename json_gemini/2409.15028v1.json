{"title": "REGION MIXUP", "authors": ["Saptarshi Saha", "Utpal Garain"], "abstract": "This paper introduces a simple extension of mixup (Zhang et al., 2018) data aug- mentation to enhance generalization in visual recognition tasks. Unlike the vanilla mixup method, which blends entire images, our approach focuses on combining regions from multiple images.", "sections": [{"title": "INTRODUCTION", "content": "Mixup (Zhang et al., 2018) is a data augmentation method that trains models on weighted averages of randomly paired training points. The averaging weights are typically sampled from a beta distribution with parameter a, where a ensures that the generated training set remains close to the original dataset. Mixup-generated perturbations may adhere only to the direction towards any arbitrary data point, potentially resulting in suboptimal regularization (Guo et al., 2019). To this end, we propose Region Mixup, an approach emphasizing the integration of regions from multiple images. While various mixup variants (Verma et al., 2018; Kim et al., 2021; Liu et al., 2021) have been proposed to address suboptimal regularization, including those considering convex combinations of more than two points, yet none explicitly strive to interpolate at the level of regions. Closest to our work is CutMix (Yun et al., 2019). However, CutMix does not interpolate regions; instead, it cuts and pastes patches between training images."}, {"title": "REGION MIXUP", "content": "Let $x \\in \\mathbb{R}^{W\\times H \\times C}$ and $y$ represent a training image and its corresponding label, respectively. The objective of region mixup is to create a new training sample $(\\tilde{x}, \\tilde{y})$ by combining regions from multi- ple training samples $(x_A, y_A), (x_{B_1}, y_{B_1}), (x_{B_2}, y_{B_2}), \\cdot \\cdot \\cdot, (x_{B_{k2}}, y_{B_{k2}})$. The combining operation is defined as follows:\n\\begin{equation}\n\\tilde{x} = \\sum_{j=1}^{k_2} \\lambda_j M_j \\odot x_A + (1 - \\lambda_j) M_j \\odot x_{B_j}, and \\quad \\tilde{y} = \\sum_{j=1}^{k_2} \\lambda_j y_A + (1 - \\lambda_j) y_{B_j}, \\quad (1)\n\\end{equation}\nwhere $M_j \\in \\{0, 1\\}^{W \\times H}$ denotes a binary mask representing the region to be mixed up from two images $x_A$ and $x_{B_j}$, and $\\sum_{j=1}^{k2} M_j = 1$. The operation $\\odot$ denotes element-wise multiplication. If $k = 1$, we recover standard mixup regularization."}, {"title": "Algorithm 1 Region Mixup at t-th training iteration", "content": "Input: Mini-batch (x, y), classifier f with parameters 0t\u22121, and model optimizer SGD\n1: Sample mixup parameters A1, A2, ..., Ak2 ~ Beta(a, a)\n2: (x, y) = (x, y); (xB\u2081, yB\u2084) = RandomPermute(x, y) for j = 1 to k2\n3: Compute (x, y) using equation 1\n4: \n$L = CE(f(x_A), y_A) + CE(f(\\tilde{x}), \\tilde{y})$\n\u25b7 CE is cross-entorpy loss.\n5: \u03b8t = SGD(0-1,$\\frac{\\partial L}{\\partial 0_{t-1}}$)\nOutput: Updated parameters Ot"}, {"title": "EXPERIMENTS", "content": "We perform image classification experiments on the CIFAR-10, CIFAR-100, and Tiny ImageNet datasets to assess the generalization capabilities of region mixup. In particular, we evaluate Mixup (Zhang et al., 2018), CutMix (Yun et al., 2019), and Region mixup for the PreAct ResNet-18 (He et al., 2016). All models undergo training on a single Nvidia RTX A5000 using PyTorch Lightning (Falcon & The PyTorch Lightning team, 2019) for 400 epochs on the training set, employing 128 examples per minibatch. Evaluation is carried out on the test set. The training utilizes SGD with momentum, a weight decay of 0.0005, and a step-wise learning rate decay. The learning rates commence at 0.1 and undergo division by 10 after 100 and 150 epochs during the training process. We do not use dropout in these experiments. For all three dataset, each image is zero-padded with two pixels on each side. Subsequently, for CIFAR-10 and CIFAR-100, the resulting image is cropped randomly to generate a new 32 \u00d7 32 image. For Tiny ImageNet, the random cropping process generates a new 64 \u00d7 64 image. Next, we flip the image horizontally with a probability of 50%. We summarize our results in Table 1 and Table 3 (in Appendix). The results are averaged over 3 runs."}, {"title": "DISCUSSION", "content": "We have introduced region mixup, a simple extension of the mixup data augmentation principle. Integrating region mixup into existing mixup training pipelines requires just a few lines of code and adds minimal to no computational overhead. Through empirical findings, we observe the ef- fectiveness of region mixup in visual recognition. We anticipate that Region Mixup will receive extensive investigation and further extensions, potentially becoming a valuable regularization tool for practitioners in deep learning."}, {"title": "APPENDIX", "content": null}, {"title": "ABLATION STUDY", "content": null}, {"title": "ADVERSARIAL ROBUSTNESS", "content": "We assess the robustness of the trained models against adversarial samples. Adversarial examples are generated (in one single step) using the Fast Gradient Sign Method (FGSM) (Goodfellow et al., 2015), with the assumption that the adversary possesses complete information about the models, thereby conducting a white-box attack. Following Zhang et al. (2018), we constrain our experiment to basic FGSM attacks as the strength of iterative PGD attacks diminishes the practical relevance of any observed performance enhancements. For the black-box attack setting, we consider $l_\\infty$-square attack (Andriushchenko et al., 2020) with a constraint on the query budget limited to 100 queries. We use torchattack (Kim, 2020) to launch these attacks. We report test accuracies after the attack in Table 3 and Table 4."}, {"title": "CLASS ACTIVATION MAPPINGS", "content": "We qualitatively compare Mixup, CutMix, and Region Mixup using class activation mappings (CAM) generated by Grad-CAM++ (Chattopadhay et al., 2018) on Tiny ImageNet dataset. We use the final residual block (layer4) of PreAct ResNet as the target layer to compute CAM."}]}