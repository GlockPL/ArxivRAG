{"title": "SOP-AGENT: EMPOWER GENERAL PURPOSE AI AGENT WITH DOMAIN-SPECIFIC SOPS", "authors": ["Anbang Ye", "Qianran Ma", "Jia Chen", "Muqi Li", "Tong Li", "Fujiao Liu", "Siqi Mai", "Meichen Lu", "Haitao Bao", "Yang You"], "abstract": "Despite significant advancements in general-purpose AI agents, several challenges still hinder their practical application in real-world scenarios. First, the limited planning capabilities of Large Language Models (LLM) restrict AI agents from effectively solving complex tasks that require long-horizon planning (Liu et al., 2023). Second, general-purpose AI agents struggle to efficiently utilize domain-specific knowledge and human expertise. In this paper, we introduce the Standard Operational Procedure-guided Agent (SOP-agent), a novel framework for constructing domain-specific agents through pseudocode-style Standard Operational Procedures (SOPs) written in natural language. Formally, we represent a SOP as a decision graph, which is traversed to guide the agent in completing tasks specified by the SOP. We conduct extensive experiments across tasks in multiple domains, including decision-making, search and reasoning, code generation, data cleaning, and grounded customer service. The SOP-agent demonstrates excellent versatility, achieving performance superior to general-purpose agent frameworks and comparable to domain-specific agent systems. Additionally, we introduce the Grounded Customer Service Benchmark, the first benchmark designed to evaluate the grounded decision-making capabilities of AI agents in customer service scenarios based on SOPs.", "sections": [{"title": "INTRODUCTION", "content": "Autonomous general purpose agents, built on the capabilities of Large Language Models (LLMs), have shown remarkable potential in performing a wide range of tasks. Existing general purpose agent systems (Wu et al. (2024), Yang et al. (2023a), Yao et al. (2023b), Li et al. (2023), Zhang et al. (2024c), Chen et al. (2024), Mei et al. (2024), Chase & contributors (2024), Nakajima (2023), Team (2023)) made significant process in fields such as planning (Yao et al. (2023b), Shinn et al. (2023),"}, {"title": "BACKGROUND AND RELATED WORK", "content": "Use of Human SOP in Domain-specific Agents Many domain-specific AI agent systems use human-designed SOP to optimize specific tasks. In code generation, most existing programming agents (Huang et al. (2024a), Qian et al. (2024), Hong et al. (2023), Wang et al. (2024), Zhang et al. (2024b), Yang et al. (2024)) use predefined debugging loop for self-debugging (Chen et al., 2023). Besides, MetaGPT introduced by Hong et al. (2023) hardcodes a software development SOP that involves cascaded action execution of different agents (e.g., product manager, engineer...), the SOP also controls communication between agents. In the CodeAgent (Zhang et al., 2024b), a set of rules is applied to establish the proper sequence for tool usage, ensuring that thorough research, including web searches and document reading, is conducted before coding. In other domains, Gao et al. (2024) proposed an Al system capable of automatically conducting biological research. This system utilizes a \"self-driving lab\u201d, where actions, including hypothesis generation, experiment design, conducting experiments, and analyzing experiment results, are performed in cycles. In another task of building a web crawler for web content understanding, Huang et al. (2024b) developed AutoCrawler, which implements a human SOP to recursively search for relevant information through a two-stage process that traverses the webpage's DOM tree.\nRule-based Expert System Rule-based expert system (ES), one of the earliest attempts made in AI, was first introduced by Lindsay et al. (1993) to solve a scientific hypothesis formation problem with a knowledge-driven approach. Later, Shortliffe (1977) proposed the IF-THEN heuristic rule, which later became a paradigm in Rule-based ES design. Our SOP-agent resembles the Mycin system as we adopt its IF-THEN formula and power it with LLM's reasoning ability.\nGrounded Agents and Language Models Few existing works ground AI agents on predefined workflows. We found AutoGPT+P (Birr et al. (2024)), which combines an affordance-based scene representation with a symbolic planner designed specifically for embodied robotic tasks. Similar to our work, Roy et al. (2024) introduces a Flow-Adhering Planning algorithm (FLAP), in which a set of predefined plans are provided to the agent in textual format to provide domain-specific knowl-edge. Each plan is a sequence of actions (flow) that needs to be executed sequentially. Additionally, Qiao et al. (2024) proposes to use a world-knowledge model, trained on the action trajectories col-lected from the simulation environment to affect the agent's behavior. In the research direction of grounded LLM, Xie et al. (2023) uses LLM to translate plans written in natural language to exe-cutable Planning Domain Definition Language (PDDL). Later researchers (Liu et al. (2023), Yang et al. (2023b), Dagan et al. (2023)) further use symbolic planners or simulators to execute LLM-translated symbolic plans or simulation scripts and ground LLM with the simulation results. Zhang et al. (2024a) use learned heuristics to guide the logical graph search to select the next action from a set of admissible actions. Although existing works (Roy et al. (2024), Birr et al. (2024), Liu et al. (2023), Yang et al. (2023b), Dagan et al. (2023)), has explored how to ground agent/LLM's output on predefined workflows, there still lacks a method that can handle complex workflow management, such as branching and looping, without simulation environments or planners."}, {"title": "\u041c\u0415\u0422\u041dOD", "content": "We propose to track the state of the agent in workflows and dynamically adapt a plan based on observation through selective depth-first-search (DFS) traversal of the decision graph. The overall design, as depicted in Figure 1, can provide SOP guidance to existing agents, such as Act and ReAct, to make the agent follow the workflow. For clarity, in the rest of this paper, we define two key concepts: (1) Action: A semantic representation of a task or behavior, such as \"read a book.\" (2) Function call: An executable program that acts, often parameterized, such as read(obj=\"book\")."}, {"title": "STANDARD OPERATING PROCEDURE (SOP)", "content": "We represent the SOPs as decision graphs, where each node signifies a candidate action at the current step. These actions can influence the environment, allowing the system to actively gather additional evidence for future decision-making on demand. Each edge corresponds to a IF condition or an unconditional ALWAYS condition. The textitALWAYS condition implies that the subsequent action"}, {"title": "SOP GUIDANCE", "content": "Our approach to guiding agent's behavior through SOPs consists of two components. First, the con-ditions and actions of subnodes are formatted into structural prompts to guide the agent's behavior. Second, we provide the agent with a filtered set of valid function callings (see Figure 1). These function callings are restricted to those associated with subnodes, which effectively limits the action space and improves decision-making robustness."}, {"title": "BRANCHING AND TRAVERSING ON THE DECISION GRAPH", "content": "Branching To selectively traverse the decision graph, a common approach is to first determine whether the condition for each node is met. If the condition is met, the corresponding func-tion (if any) will be executed with parameters generated by separate LLM calls, resulting in $1 + |branches\\_with\\_function\\_calls queries. However, this approach can be optimized in cer-tain scenarios where the function callings of each node are different. In this case, the function calling that the agent made help determine which conditions are met, allowing for more efficient branching. We use OpenAI's GPT-4, which provides a tool call interface that supports generating all the necessary function calls in a single query. We explore each subbranch based on the selected function call in DFS fashion as shown in Figure 1. This approach reduces the number of required queries to one per traversal. For more details on the cost analysis, refer to Appendix A. There are two scenarios in which actions cannot be distinguished: (1) when a node has at least two sub-nodes that perform the same function calling, and (2) when a node has at least two sub-nodes that do not perform any function calling. In these cases, we have to use the naive approach as described at the beginning of this paragraph. We prompt the LLM to call all applicable functions from predefined \"dummy\" function calls like \"explore_subtree_A\" and \"explore_subtree_B\". Afterward, the LLM generates the actual actions during the second phase of traversal. See Appendix B for more details.\nDFS-based Selective Traversing We employ DFS to traverse the decision graph selectively. On each step, we use the branching mechanism as stated above to select branches whose preconditions are met based on observation. Then, we recursively perform DFS on selected sub-branches."}, {"title": "EXPERIMENTS", "content": "We evaluate SOP-Agent across four domains to assess its versatility: (1) decision making, (2) multi-hop question answering via interactive searching, and (3) code generation, and (4) data cleaning."}, {"title": "DECISION MAKING", "content": "Experimental setup ALFWorld (Shridhar et al., 2020) is a virtual, text-based game built on the ALFRED benchmark dataset (Shridhar et al., 2019). ALFWorld provides a simulator that simulates six types of household-related tasks, including (1) put sth. in/on sth./spl., (2) find sth., heat it then put it in/on sth./spl., (3) find sth., cool it then put it in/on sth./spl., (4) find sth., clean it then put it in/on sth./spl., (5) examine sth. under a desklamp, (6) take and put sth. in/on sth./spl. twice. In our experiments, we use the existing ALFWorld simulator, which provides eight admissible actions: go to, take, put, heat, cool, open, clean, and use. Since the ALFWorld environment contains more than 50 possible locations, efficient exploration requires a targeted search strategy. For example, to search for an object, start with the location where the object is most likely to appear, then iteratively explore other locations. We manually write an SOP using human-designed optimal strategies for all six tasks. The SOP can be found in Appendix F. For the base agent, we choose to use a ReAct agent because the action trajectory contains useful information in the ALFWorld task.\nBaselines For comparison, we evaluate the performance of the SOP-guided agent against Auto-GPT (Yang et al., 2023a) and the original ReAct Agent. The experimental results for AutoGPT are based on the data reported in the original AutoGPT paper. To ensure a fair comparison, all agents were evaluated using GPT-4 on the same set of 134 unseen tests with a low-temperature setting to minimize randomness in responses (SOP-Agent: 0.0, AutoGPT: 0.01, ReAct: 0.0). For the two experiments that use few-shot prompting, we use identical few-shot prompts generated by the official evaluation script of ReAct. For the SOP-agent and ReAct experiments, we limit the number of GPT calls to 50. Furthermore, AutoGPT also reports the performance of a variant that incorporates an imitation learning (IL) model, trained using expert demonstrations.\nEvaluation Metrics For evaluation metrics, we use the success rate, $success\\_rate = \\frac{number-of-success-trial}{number-total-trial}$. The trial is successful if the ALFWorld game simulator returns a success signal before the agent terminates, crashes, or reaches the maximum GPT call limit."}, {"title": "MULTI-HOP QUESTION ANSWERING VIA INTERACTIVE SEARCHING", "content": "EXPERIMENTAL SETUP We utilize HotpotQA (Yang et al., 2018) to evaluate the agents' abil-ity to perform interactive searching and multi-hop reasoning. HotpotQA is a task designed for multihop question answering, where an agent iteratively searches Wikipedia passages to gather information and answer questions. Each question requires information from at least two dis-tinct Wikipedia passages. The agent interacts with a search engine through three actions: (1) search[entity]: This action searches for an exactly matched entity and retrieves the correspond-ing passage from the Wikipedia database. If no exact match is found, it returns a list of similar entities. (2) lookup[keyword]: This action returns the next sentence that contains the specified key-word from the current passage. (3) finish[answer]: This action is used to submit the final answer to the question. Similar to the ALFWorld experiment, we adapt the ReAct agent by incorporating a Standard Operating Procedure (SOP), which provides step-by-step instructions on how to navigate the multi-hop searching and reasoning process. The manually crafted SOP for this task is detailed in Appendix F.\nBaselines We compare the performance of the SOP-agent with that of the original ReAct agent. Both agents are evaluated under the same few-shot setting, with identical prompts. The experiments are conducted on the same set of 200 questions using GPT-4 with a temperature setting of 0.0.\nEvaluation Metrics Following the ReAct paper, we use two metrics: (1) EM: the ratio of questions where the agent's response exactly matches the ground truth answer. (2) F-1 score: the F-1 score, which measures the average similarity between the agent's response with the ground-truth answer. We also analyze the difference in agents' behavior through an abla-tion study on several action patterns that we think can reflect agents' exploration abilities: (1) total_searches: total number of search attempts, (2) total_lookups: total number of lookup at-tempts, (3) consecutive_search_same_keywords: the total number of search attempts using the same entity as the previous consecutive search attempt. (4) consecutive_search_same_keywords: the total number of lookup attempts using the same keyword as the previous consecutive lookup attempt. (5)-(14) lookup_same_keyword_level_N: The total number of consecutive lookups using the same keyword at depth N, where N represents the length of the consecutive lookup sequence. For example, the second lookup in lookup[Taylor Swift] >> lookup[Taylor Swift] counts as a lookup at depth 2."}, {"title": "CODE GENERATION", "content": "Experimental Setup We use two widely adopted code generation benchmarks, HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021) to evaluate the code generation ability of the SOP-agent. To adapt to the code generation task, in both benchmarks, we guide a single Act agent with SOP that empowers the Act agent with debugging and self-reflection (Shinn et al., 2023) ability. Additionally, we incorporate a persistent, read-replace-only long-term memory. This allows the agent to see previously generated code, observations, and thoughts in the prompt for debugging and self-reflexion. For the HumanEval benchmark, we use the existing HumanEval evaluation harness that provides a testing environment for 164 coding tasks. For the MBPP dataset, we adopt the same evaluation setting as AgentCoder (Huang et al., 2024a) and use the test split of the sanitized subset of the MBPP dataset (257 data points) based on whether all provided unit test cases can pass. In both experiments, we use a temperature of 0.0. The SOPs used in both experiments can be found in Appendix G.\nBaselines For the HumanEval benchmark, we include baselines across different methodologies: large language models: (1) GPT-4 (0-shot), OctorCoder (GPT-4 with fine-tuned on coding tasks), coding systems: (1) Parsel (Zelikman et al., 2023), ANPL (Huang et al., 2023), agent systems: MetaGPT (Hong et al., 2023), L2MAC (Holt et al., 2024), MapCoder (Islam et al., 2024), Agent-Coder (Huang et al., 2024a). Among those baselines, MetaGPT, L2MAC, MapCoder, and Agent-Coder are multi-agent frameworks designed specifically for code generation tasks. For the MBPP benchmark, we compare our method with large language models: (1) GPT-4 (0-shot), (2) GPT-4 (few-shot), and agent system: (1) MapCoder (Islam et al., 2024), MetaGPT (Hong et al., 2023), AgentCoder (Huang et al., 2024a). For a fair comparison, all baselines use GPT-4 as the base LLM.\nEvaluation Metrics For both HumanEval and MBPP benchmark, we compare the Pass@1 score: $(Pass@1 = \\frac{number-passed-tasks}{number-total-tasks})$ of different methods."}, {"title": "DATA CLEANING", "content": "Experimental Setup To demonstrate that our proposed SOP agent can handle complex real-world problems in fields that requires specialized expertise with the help of external knowledge injected via SOPs, we test our agent framework in the scenario of data cleaning on 4 Kaggle challenge datasets. There include: (1) CO2 Emission by Vehicles (Podder, 2022), (2) Laptop Price Prediction using specifications (Chaki, 2023), (3) Used Car Price Prediction (Hinglaspure, 2024), and (4) Effects of Alcohol on Student Performance (Naude, 2024). Those datasets are selected based on three criteria: First, the dataset is publicly available dataset in CSV format that does not exceed 200KB in size and can be used for regression tasks. Second, the dataset contains issues that require cleaning. Third, the dataset has a usability rating of 10 on Kaggle, indicating its high value. Additional details regarding those datasets and corresponding cleaning challenges are provided in Appendix C.\nTo quantitatively measure agents' data cleaning ability and to guarantee evaluation fairness, we add constraints to the data cleaning task. The data cleaning task contains four subtasks designed based on the DC-RM procedure by Corrales et al. (2018) to evaluate agents' ability in data-driven programming, data analysis, reasoning, and instruction following. The subtasks are as follows:\n\u2022 Data Conversion: The agent is tasked with converting all non-numerical columns to nu-merical form. Specifically, the agent must analyze the dataset and convert columns that contain numerical information but are stored as non-numerical data to numbers (e.g., \"1.24 kg\" to 1.24). In addition, Label (ordinal) encoding is used to convert all remaining categor-ical columns into numerical values.\n\u2022 Missing value imputation: The agent is required to fill missing values (NaNs) using the Random Forest Imputation technique.\n\u2022 Outlier Detection and Removal: The agent must identify and remove outliers using the Local Outlier Factor (LOF) method.\n\u2022 Duplicate Removal: The agent must detect and remove duplicated rows in the dataset.\nThe task, along with detailed instructions for each subtask, is presented to agents either through a textual task description (for baseline agents) or via a SOP (for the SOP agents). For each method and dataset, we run the agent 10 times and report the average score. For the SOP-agent, we use an Act agent and the provided SOP can be found in Appendix H."}, {"title": "SOP ENGINEERING", "content": "Techniques to improve prompting and tool calling performance have been widely discussed, includ-ing providing clear tool definitions and using few-shot examples. We further explore how to improve the stability of an SOP-based agent by engineering and rephrasing the SOP based on our empirical findings, refer to Appendix E for more details.\nWe find that with proper SOP setup, the SOP-agent can achieve extremely high performance in tasks that require intensive decision-making. We support our findings with the first SOP-grounded AI agent benchmark in custom service. This section will cover the benchmark data generation process, evaluation metrics, and final performance of SOP-agent."}, {"title": "GROUNDED CUSTOMER SERVICE BENCHMARK", "content": "The Task In industry, customer service providers need to provide assistance to customers accord-ing to a set of SOPs made by the company. They need to gather information from a variety of sources"}, {"title": "EXPERIMENTAL SETUP", "content": "For baselines, we use LangChain's (Chase & contributors, 2024) zero-shot ReAct agent. For both SOP-agent and the ReAct agent, we report the metrics based on 100 runs for each use case. To test the grounded task performance, we provide the SOP to the SOP-agent and a formatted textual SOP in bullet-point format to the baseline. All experiments use GPT-4 as the base model. As our dataset creation process inherently introduces biases if we attempt to use benchmarks on performance com-parison, we include baselines in this experiment solely to identify any gaps that may need to be addressed to align existing agent systems with the complex, real-world challenges of grounding in customer service tasks."}, {"title": "RESULTS AND OBSERVATIONS", "content": "As shown in Table 5, in our Grounded Customer Service Benchmark, the SOP-agent achieves ex-tremely high scores in all categories, the overall accuracy is 99.8%. Meanwhile, the scores from the ReAct baseline suggest that the benchmark is still challenging for general-purpose AI agents."}, {"title": "CONCLUSION", "content": "In this work, we introduced SOP-agent, a novel autonomous agent system guided by pseudocode-style SOPs written in natural language to build task-specific agents. The SOP-agent addresses"}, {"title": "ANALYSIS ON THEORETICAL LLM USAGE", "content": "There are three cases we need to consider, as shown in the figure below."}, {"title": "DETAILS ON USING DUMMY FUNCTIONS TO DO BRANCHING", "content": "For cases where the function calls cannot distinguish which branch to explore. We use dummy functions to do branching as described in the Algorithm 0."}, {"title": "SUPPLEMENTARY DETAILS ABOUT THE DATA CLEANING TASK", "content": "Data Cleaning Challenges in Datasets We select datasets that require different cleanups as listed in the table below."}, {"title": "SUPPLEMENTARY DETAILS ABOUT THE GROUNDED CUSTOMER SERVICE BENCHMARK", "content": ""}, {"title": "ADDITIONAL RESULTS ON THE GROUNDED CUSTOMER SERVICE BENCHMARK", "content": "Error Analysis We manually analyze the log of 9 failed cases from 5000 runs. Among failed cases, 3 runs failed because the LLM hallucinated a function-calling that doesn't exist. 6 of them are due to errors in reasoning, namely, the LLM chose a branch that should not be explored based on observation.\nSOP Refinement To ensure all the data samples in our constructed dataset is logically coherent and can be understood by GPT4, we adopt the following data refinement procedure (see Algorithm 2) to progressively fix the SOP through SOP engineering."}, {"title": "ADDITIONAL STUDY ON SOP ENGINEERING", "content": "Additional Study on SOP Engineering SOP engineering plays a crucial role in streamlining process optimization and enhancing workflow management efficiency. However, since those are out of the scope of this paper, we will concentrate instead on how SOP engineering helps the SOP-agent system to improve its robustness. We found that carefully designed SOPs can help to improve the robustness of our proposed SOP-agent system by a large margin. The process involves checking the logical completeness of every logical chain in the SOP, using easy-to-understanding logic to avoid compound logic with \"or\" or \"and\", and matching function calling descriptions with action instructions in the SOP definition.\nWe demonstrate the process through a case study, in which we manually modify an SOP generated by the LLM to improve the SOP-agent's robustness. The crude SOP (see Listing 1), while used to guide the SOP-agent, achieves 84% in path accuracy based on 100 runs. We manually refine it to get the refined SOP (see Listing 2) and improve the path accuracy to 98%, which leads to a 16.7% im-provement. The changed lines are presented in red in the refined SOP and the corresponding lines in the original crude SOP are in blue. The reason for making these modifications is to ensure the com-pleteness of the logical chain. In the first modification, the precondition (\"if the line is operational\") cannot related to the previous function calling description (\"Check the customer's, connection sta-tus\") directly, which may introduce confusion and lead to sub-optimal performance. Similarly, in the second modification, the precondition (else if an interruption has been detected), although the pre-vious function returns \"connection_status':'interruption_detected\", since the precondition didn't specify the scope of where it needs to find evidence regarding whether if an interruption has been detected, the LLM main attend to previous observation returned from the \"check_area_outages\" function call, which checks for any known outages in the customer's area and returns semantical similar responses (\"outage_status': 'outage reported\" and \"outage_status': 'outage none\")."}, {"title": "THE SOP USED IN THE ALFWORLD BENCHMARK", "content": "# zero-shot sops\nall in one:\ncondition_type: always\nAPI: {\"name\": \"AllInOne\", \"description\": \"Perform all tasks in\n\u2192the environment.\"}\nDescription: Perform all tasks in the environment.\nInstructions:\nif the task is to put an object in/on somewhere, execute the\n\u2192plan 'pickup and place':\nAPI: pick_and_place"}, {"title": "APPENDIX B: THE SOP USED IN THE HOTPOTQA BENCHMARK", "content": "multihop-question-answering-react:\ncondition_type: always\nAPI: {\"name\": \"MultiHopQA\", \"description\": \"Generate code given\n\u2190\nthe description.\"}\nDescription: Multi-hop QA SOP\nInstructions:\nthink about what to do next based on the provided question\n\u2192 and answer and obtained information. log your thought to\n\u2192 memory with key 'thought':\nAPI: log_thought\nlabel: think\ncondition_type: always\nInstructions:\nEvaluate the change for the key information to appear in\n\u2192 the article whose first paragraph is the last\n\u2192 observation, if the change is high, lookup for\n\u2192 keywords in the article with the lookup tool,\n\u2192 otherwise search for a different entity with the\n\u2192 search tool:\nAPI: action_selection\nlabel: action_selection\ncondition_type: always\nInstructions:\nif search is the next action to perform, search the\n\u2192 Wikipedia for an entity (name of person/object) to\n\u2192 obtain a new article related to the entity, you\n\u2192 should avoid searching for the same entity multiple\n\u2190\ntimes:\nAPI: search_new_article\nlabel: search\ncondition_type: if\nInstructions:\nalways, log the key information in the result, if\n\u2192the search cannot find the entity, log the\nsimilar entities:\nAPI: log_result\ncondition_type: always\nInstructions:"}, {"title": "SOP USED IN CODE GENERATION", "content": "simple_code_generation:\ncondition_type: always\nAPI: {\"name\": \"CodeGen\", \"description\": \"Generate code given\n\u2192 the description.\"}\nDescription: Code generation SOP\nInstructions:\nThink about the problem and try to understand the\n\u2192 requirements. Generate a plan to solve the problem. Also,\n\u2192 explain at least one test cases step by step. add an\n\u2192 entry to the memory with key 'thought' to log your\n\u2192 thought with key.:\nAPI: log_to_memory"}, {"title": "SOP USED IN DATA CLEANING", "content": "regression_data_cleaning:\ncondition_type: always\nAPI: {\"name\": \"DataCleaning\", \"description\": \"Data cleaning SOP\n.\"\nDescription: Data cleaning SOP\nInstructions:\nwrite code to 1. read data from data.csv, 2. check the data\n\u2192types of all columns, print the result:\nAPI: python"}]}