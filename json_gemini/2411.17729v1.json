{"title": "FAST CONVOLUTION ALGORITHM FOR STATE SPACE MODELS.", "authors": ["GREGORY BEYLKIN"], "abstract": "We present a fast, robust algorithm for applying a matrix transfer function of a linear time invariant\nsystem (LTI) in time domain. Computing L states of a multiple-input multiple-output (MIMO) LTI appears to\nrequire L matrix-vector multiplications. We demonstrate that, for any finite user-selected accuracy, the number\nof matrix-vector multiplications can be reduced to $O(log^2 L)$ (within an $O(L)$ algorithm). The algorithm uses\nan approximation of the rational transfer function in the z-domain by a matrix polynomial of degree $2^{N+1} \u2013 1$,\nwhere N is chosen to achieve any user-selected accuracy. Importantly, using a cascade implementation in time\ndomain, applying the transfer function requires only N+1 matrix-vector multiplications. We note that LTI\nsystems are used in state space models (SSMs) for modeling long range dependencies where L is large. In\napplications where the state matrix of LTI system is approximated by a structured matrix, the computational\ncost is further reduced. We briefly describe several structured approximations of matrices that can be used for\nsuch purpose.", "sections": [{"title": "1. INTRODUCTION", "content": "In [1, 2, 3] authors describe an efficient approach to sequence modeling using state space models (SSMs)\nto address long-range dependencies. While their approach yields an efficient algorithm, we propose a new\nfast, robust algorithm for the same purpose.\nThe setup of SSM uses a linear multiple-input multiple-output (MIMO) time invariant system (LTI),\n(1.1)\n$\\begin{cases}\nx'(t) = Ax(t)+Bu(t)\\\\\ny(t) = Cx(t)+Du(t),\n\\end{cases}$\nwhere A is an $m \\times m$ state matrix, B, C and D are $m \\times p$, $q \\times m$ and $q \\times p$ matrices with $1 < p,q \\le m$. Here\nx, u and y are vector functions of dimension m, p and q. Typically p and q are significantly smaller than m,\ne.g. in [1] p = q = 1. A discretization of the ordinary differential equation in (1.1) yields a system of the\nform\n(1.2)\n$\\begin{cases}\nx_n = \\overline{A}x_{n-1}+\\overline{B}u_n\\\\\ny_n = Cx_n+Du_n,\n\\end{cases}$\nwhere, using for example the trapezoidal rule with step size \u2206, we have $\\overline{A} = (I\u2212 \\frac{\\Delta}{2}A)^{-1}(I+\\frac{\\Delta}{2}A)$ and\n$\\overline{B} = \\Delta (I-\\frac{\\Delta}{2}A)^{-1}B$. Alternative discretization schemes for the ordinary differential equation in (1.1) can\nbe used with step size \u2206 playing the role of time scale in SSM schemes (see [1, 3, 2]). We assume that the\nmagnitude of the eigenvalues of the matrix A is less than 1.\nGiven the input sequence $u_n$, a computational goal is to obtain the output sequence $y_n$ using the recurrence\n(1.2). While the recurrence can be used directly, it is prohibitively expensive if the goal is to account for long\nrange dependencies. Alternatively, solving the recurrence, results in a convolution with a transfer function\nwhich maps the sequence {$u_n$}$_{n=0}$ to the sequence {$y_n$}$_{n=0}$ directly. Using the z-transform (described below\nfor completeness), the transfer function between these two sequences is obtained as\n(1.3)\n$H(z) = C(I_m - z^{-1}\\overline{A})^{-1}\\overline{B}+D,$\nwhere $I_m$ is the $m \\times m$ identity matrix. The question is how to apply efficiently the operator H as a convolu-\ntion in time domain.\nAs reported in [1], using an example of the so-called HiPPO matrix, diagonalization of the matrix A leads\nto numerical difficulties (i.e. ill-conditioned eigenvectors). As a way to avoid computational issues, the"}, {"title": "2. FAST CASCADE ALGORITHM", "content": "In [6, 7] we introduced a novel method of accurate approximation of causal and anti-causal IIR filters\nby a cascade of FIR filters leading to automatic design of efficient digital filters. Many properties, such as\nfilters with exact linear phase or symmetric filters satisfying the perfect reconstruction condition, can only\nbe obtained using non-causal IIR filters. Our method of approximating causal and anti-causal IIR filters\nproduces FIR filters that, within any user-selected accuracy, inherit properties of IIR filters. The resulting\ncascades of FIR filters have a straightforward parallel implementation. A simple technical tool underpinning\nthese results leads to a fast algorithm for applying the operator H in time domain. For completeness, we\npresent a detailed derivation.\nUsing the z-transforms\n$X(z) = \\sum_{n=0}^{\\infty} x_nz^{-n}$, $U(z) = \\sum_{n=0}^{\\infty} u_nz^{-n}$ and $Y(z) = \\sum_{n=0}^{\\infty} y_nz^{-n}$,\nwe obtain from (1.2) (with $x_{-1}$ = 0)\n$\\begin{cases}\nX(z) = z^{-1}\\overline{A}X(z) + \\overline{B}U(z)\\\\\nY(z) = CX(z) + DU(z)\n\\end{cases}$\nyielding $X(z) = (I_m - z^{-1}\\overline{A})^{-1}\\overline{B}U(z)$ and\n$Y(z) = H(z)U(z)$,\nwhere H is given in (1.3).\nSince the magnitude of all eigenvalues of A is less than 1, Lemma 1 below implies\n$(I_m - z^{-1}\\overline{A})^{-1} = \\prod_{n=0}^{\\infty} [I_m + (z^{-1}\\overline{A})^{2^n}],$\nwhere |z| = 1 and\n(2.1)\n$H(z) = C\\prod_{n=0}^{\\infty} [I_m + (z^{-1}\\overline{A})^{2^n}] \\overline{B}+ D.$\nApproximating H by a product with N + 1 terms, we define\n(2.2)\n$H_N(z) = C\\prod_{n=0}^{N} [I_m + (z^{-1}\\overline{A})^{2^n}] \\overline{B}+ D.$\nEffectively, we are approximating a rational matrix function $(I_m - z^{-1}\\overline{A})^{-1}$ by a matrix polynomial. If\nthe magnitude of some eigenvalues of the matrix A is close to 1, then the degree $2^{N+1} \u2013 1$ of the matrix\npolynomial $H_N$ can be large. However, the cost of applying the convolution operator as a cascade in time\ndomain using this matrix polynomial requires only N + 1 matrix-vector multiplications. We have\nLemma 1. Let $\\gamma < 1$ be largest singular value of A and N a positive integer. Since $\\gamma \\ge |\\lambda_j|$, $j = 1,...,m$,\nwe estimate\n$|| (I_m - z^{-1}\\overline{A})^{-1} - \\prod_{n=0}^{N} [I_m + (z^{-1}\\overline{A})^{2^n}]|| \\le \\frac{||\\overline{A}||^{2^{N+1}}}{1-|z||} \\le \\frac{\\gamma^{2^{N+1}}}{1-\\gamma}$"}, {"title": "3. APPLYING CONVOLUTION VIA A CASCADE", "content": "In time domain, given an input sequence {$u_l$}$_{l=0}^{L-1}$, the representation of the matrix polynomial in (2.3)\nyields a fast cascade algorithm for applying convolution to obtain the sequence {$y_l$}$_{l=0}^{L-1}$. Computing the\nsequence $y_l$ using (1.2) and setting $x_{\u22121}$ = 0 yields\n(3.1)\n$y_l = \\sum_{k=0}^{l} \\overline{A}^{l-k} \\overline{B}u_k + Du_l$.\nLemma 1 allows us to reuse intermediate matrix-vector products by the matrix $\\overline{A}$ and, as a result, we need\nto apply only the powers $\\overline{A}^{2^n}$, n = 0, . . . , N \u2013 1. Note that the powers of $z^{\u22122^n}$ in (2.3) correspond to a shift by\n$2^n$ in time domain.\nWe start with\n$v_l^{(0)} = \\overline{B}u_l, l = 0,1,..., L \u2212 1$\nand form an m \u00d7 L matrix\n$V^{(0)} = [v_0^{(0)},v_1^{(0)},...,v_{L-1}^{(0)}]$.\nNext we update columns of $V^{(0)}$ starting from column l = 1 according to\n(3.2)\n$\\begin{cases}\nv_l^{(1)} = \\overline{A}v_{l-2^0}^{(0)} + v_l^{(0)} 1 \\le l < L \u2212 1\\\\\nv_0^{(1)} = v_0^{(0)}\n\\end{cases}$\nand, for convenience of notation, rename the matrix as $V^{(1)}$. We then update columns of $V^{(1)}$ starting from\nl = 2,\n(3.3)\n$\\begin{cases}\nv_l^{(2)} = \\overline{A}^{2^1}v_{l-2^1}^{(1)} + v_l^{(1)} 2 \\le l < L \u2212 1\\\\\nv_l^{(2)} = v_l^{(1)} 0 \\le l < 1\n\\end{cases}$\nand rename the result as $V^{(2)}$. Next we update columns of $V^{(2)}$ starting from l = 4,\n(3.4)\n$\\begin{cases}\nv_l^{(3)} = \\overline{A}^{2^2}v_{l-2^2}^{(2)} + v_l^{(2)} 4 \\le l < L \u2212 1\\\\\nv_l^{(3)} = v_l^{(2)} 0 \\le l \\le 3\n\\end{cases}$\nand so on. At each step l = 0,2, . . . L \u2013 1 we update columns of $V^{(n-1)}$ in the range $2^{n\u22121} < l < L \u22121$ to yield\n$V^{(n)}$,\n$\\begin{cases}\nv_l^{(n)} = \\overline{A}^{2^{n-1}}v_{l-2^{n-1}}^{(n-1)} + v_l^{(n-1)} 2^{n\u22121} \\le l < L \u2212 1\\\\\nv_l^{(n)} = v_l^{(n-1)} 0 \\le l < 2^{n-1} \u2013 1\n\\end{cases}$"}, {"title": "4. AN EXAMPLE OF HIPPO MATRIX", "content": "The following triangular $m \\times m$ matrix is used in [1, 8, 2, 4],\n(4.1)\n$A = \\begin{cases}\n\\frac{\\sqrt{2n+1}\\sqrt{2k+1}}{n-k} n>k\\\\\n-<n+1 n=k\\\\\n0 n<k,\n\\end{cases}$\nwhere 1 < n,k < m. This is a so-called HiPPO (high-order polynomial projection operators) matrix [9].\nUsing it as an example and setting m = 100, we compute\n(4.2)\n$\\overline{A} =(I-\\frac{\\Delta}{2}A)^{-1} (I+\\frac{\\Delta}{2}A)$,\nwith \u2206 = $10^{\u22121}$. The diagonal elements of the resulting triangular matrix, i.e. its eigenvalues, range from\n$d_1$ = 0.9512195121951224 to $d_{100}$ = 0.9990103908955988. Since $d_{100}^{2^{15}} \\approx 8.12714*10^{-15}$, the matrix $\\overline{A}^{2^{15}}$\ncan be neglected and, as a result, 15 matrix-vector multiplications allow us to apply the matrix polynomial\n$H_{14}$ of degree 32767. Using double precision arithmetic in MathematicaTM, the powers of $\\overline{A}$ are computed\nwith accuracy \u2248 $10^{\u201312}$. We note that the powers of the matrix $\\overline{A}$ can always be computed with a large\nnumber of accurate digits and used with as many digits as the application requires."}, {"title": "5. STRUCTURED REPRESENTATION OF MATRICES", "content": "If a structured approximation of $m \\times m$ matrix A is available, then the cost of matrix-vector multiplications\nusing powers of this matrix can be significantly reduced. For example, by changing basis, the matrix A is\nmodified to be diagonal-plus-low-rank in [1].\nWe observe that there are other structured approximations that can be used to change complexity of\nmatrix-vector multiplication from $O(m^2)$ to O (m) or O(mlogm).\nFor example, the matrix in (4.2) admits the so-called partitioned low rank representation (PLR) (see e.g.\n[10]), where the rank of the off-diagonal blocks is equal to 1. The cost of applying the $m \\times m$ matrix (4.2)\nand its powers in PLR representation does not exceed O (mlogm).\nOther structured approximations include a wavelet representation of the matrices A or $\\overline{A}$, where an approx-\nimation via the so-called non-standard form [11] yields an O (m) algorithm for matrix-vector multiplication.\nIt is possible to use multiwavelets for the same purpose, see [12].\nThe choice of a structured representation also depends on the selected discretization of the LTI system in\n(1.1). For example, for the HiPPO matrix, if one selects $\\overline{A}$ = exp(\u2206A) and $\\overline{B} = (\\Delta A)^{-1} [exp (\\Delta A) \u2013 I] \\Delta A$,\nthen a wavelet representation of exp (\u2206A) is more efficient than that for $\\overline{A} = (I-\\frac{\\Delta}{2}A)^{-1} (I+\\frac{\\Delta}{2}A)$."}]}