{"title": "The Rising Threat to Emerging AI-Powered Search Engines", "authors": ["Zeren Luo", "Zifan Peng", "Yule Liu", "Zhen Sun", "Mingchen Li", "Jingyi Zheng", "Xinlei He"], "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced the capabilities of AI-Powered Search Engines (AIPSEs), offering precise and efficient re- sponses by integrating external databases with pre-existing knowledge. However, we observe that these AIPSEs raise risks such as quoting malicious content or citing malicious websites, leading to harmful or unverified information dis- semination. In this study, we conduct the first safety risk quantification on seven production AIPSEs by systematically defining the threat model, risk level, and evaluating responses to various query types. With data collected from PhishTank, ThreatBook, and LevelBlue, our findings reveal that AIPSES frequently generate harmful content that contains malicious URLs even with benign queries (e.g., with benign keywords). We also observe that directly query URL will increase the risk level while query with natural language will mitigate such risk. We further perform two case studies on online doc- ument spoofing and phishing to show the ease of deceiving AIPSEs in the real-world setting. To mitigate these risks, we develop an agent-based defense with a GPT-40-based content refinement tool and an XGBoost-based URL detector. Our evaluation shows that our defense can effectively reduce the risk but with the cost of reducing available information. Our research highlights the urgent need for robust safety mea- sures in AIPSEs.", "sections": [{"title": "1 Introduction", "content": "Recently, Large Language Models (LLMs) have demon- strated great potential in various applications [32,51,60,64]. Notably, conversational chatbots like ChatGPT [1] have achieved remarkable success. However, these models face inherent limitations. Since GPT models learn from pre- existing data (e.g., GPT-4's knowledge is up-to-date only un- til October 2023 [12]), they are unable to accurately address queries about information beyond this cutoff. Furthermore, LLMs are prone to generating hallucinations [37]. To address these issues, AI-Powered Search Engines (AIPSEs) have emerged as an application of Retrieval- Augmented Generation (RAG) [27, 33, 40]. Concretely, AIPSEs combine a knowledge database, a retriever, and an LLM to provide up-to-date information by integrating exter- nal data with the LLM's existing knowledge. Unlike tradi- tional search engines that focus on keyword matching and semantic search [44, 57], AIPSEs leverage LLMs to inter- pret user intent, retrieving and summarizing relevant exter- nal data to generate precise and concise answers, enhancing efficiency over traditional search engines. Despite being powerful, AIPSEs may face several risks. For example, the retriever may access unfiltered malicious websites and the LLM might refer to their data without any safety check, which results in harmful or unverified re- sponses. For instance, when users search for software to install, AIPSEs may directly provide the malware website instead of the official one in some cases. Such risks have already caused monetary loss in the real world: In Novem- ber 2024, a developer lost about $2,500 after following code generated by ChatGPT Search.\u00b9 This incident highlights the urgent need for thorough safety checks in production AIPSES such as ChatGPT Search [6]. Figure 1 demonstrates the process of our paper. In this pa- per, we perform the first safety risk quantification against 7 production AIPSES. Concretely, we first systematically de- fine the threat model, construct different types of queries (in- cluding keyword list query, URL query, and natural language query), and categorize the response of AIPSEs into different risk levels based on their harmfulness. To perform the eval- uation, we collect candidate URLs as well as their keyword lists (generated by GPT-40) from three popular cyber threat detection platforms: PhishTank [14], ThreatBook [19], and LevelBlue's [8]. Our evaluation shows that all AIPSEs suffer from generating harmful content based on malicious URLs."}, {"title": "2 Related Work", "content": "LLM and RAG. LLMs, such as ChatGPT [1,50], Copi- lot [11], Kimi [7], LLaMA [48], are widely used to com- prehend and generate human language texts, which can sum- marize, predict, and generate text or code based on massive training datasets. These LLMs generate the text autoregres- sively based on their knowledge and a conditional context that is provided by service providers or users. RAG [27, 33, 40] is a powerful way to enhance LLMs ability which con- sists of three components: a knowledge database, a retriever, and an generator (currently, a generator usually is an LLM). In AIPSEs, the knowledge database may contain snapshots of web pages. This database provides the LLM with the lat- est knowledge, compensating for the knowledge cutoff. The retriever understands the user's query and finds the most rel- evant data from the database. The generator outputs the final answer with the query and retrieved data, which is usually an LLM in current AIPSEs. Overall, AIPSE identifies the most relevant web pages and feeds them into the LLM along with the query. Subsequently, the LLM generates the final answer based on this information.\nPoisoning Attack and Prompt Injection Attack. Current research on poisoning attacks [29, 35, 54, 59] primarily fo- cuses on poisoning training data. The goal is to introduce malicious data into the training dataset, causing the model to produce incorrect results in future predictions or decisions. Carlini et al. [29] discuss the feasibility of poisoning web-scale datasets at a practical cost, which can affect content re- trieved from the web, including replacing the content linked to stored URLs or periodically cached datasets. Poisoning the prompt is commonly referred to as Prompt Injection (PI) attacks. Direct PI [52] occurs when mali- cious users exploit the model by manipulating the prompts to bypass content restrictions, such as overriding the orig- inal prompt and directing it to follow malicious instruc- tions. PoisonPrompt [65] investigates injecting backdoors into prompts during prompt fine-tuning while maintaining performance on downstream tasks. HOUYI [42], drawing from SQL injection and XSS attacks, deceives an LLM into interpreting the injected prompt as an instruction to be an- swered separately from the previous context. In contrast, Indirect Prompt Injection (IPI) [34] refers to adversaries injecting prompts into data that may be retrieved during inference, indirectly controlling the model's output. This typically occurs when an LLM receives input from ex- ternal sources controlled by the attacker, such as websites or files. Several works [34, 41, 67] have discussed the safety risks when LLMs incorporate external content into prompts, as LLMs struggle to distinguish between user instructions and external inputs. However, PI attacks have limitations when extended to RAG systems because the retriever re-ranks the retrieved content before passing it to the LLM. Several studies [31, 58, 69] have demonstrated effective backdoor attacks on RAG systems by poisoning the knowledge database, compromis- ing the LLM or retriever to generate inaccurate or harmful outputs. These studies primarily focus on open-source re- triever models and LLMs, while our work focuses AIPSES in production environments. One close work is conducted by Nestaas et al. [49], which proposes preference manipulation attacks, trying to manipu- late an AIPSE's selections to favor the attacker. Different from their work, we systematically evaluate the inherent safety risk of AIPSEs with non-optimized (and mostly benign) queries. We further conduct case studies to demonstrate the ease of manipulating the response of AIPSEs. To mitigate the risk, we develop an agent-based strategy to filter and mark the potential risks. Malicious Website Detection. Malicious website detection methods [38, 68] can be categorized into three types: URL- based [24, 39, 43, 61], Webpage-based [23, 36, 46, 47], Hy- brid approaches [53,56]. URL-based detection relies on fea-"}, {"title": "3 Threat Model", "content": "In this section, we formulate the AI search behavior and in- troduce the threat model. Formulation. Given an LLM $M$ that processes user re- quests by combining queries $Q$ with external data retrieved from a search engine $S(Q)$, the application typically re- sponds with a result $R$ under normal circumstances, i.e., $M(Q||S(Q)) = R$, where \u201c||\u201d denotes the concatenation op- eration. An attacker can publish adversarial content to poi- son the external data retrieved from the search engine, alter- ing it to $S'(Q)$. Then, the model will output the response of $M(Q||S'(Q)) = R'$, where $R'$ and $S'(Q)$ are the malicious response and search engine retrieved data respectively. Adversary's Goal and Capability. The adversary's goal is to ensure that relevant queries generate responses that in- clude specific websites, cite content from those websites, or even generate specific answers based on harmful content. Harmful content includes directly or indirectly answering users by citing phishing, scams, malware, piracy, spam, adult content, gambling, and other illegal content from the internet. Regarding the capability, we consider the adversary with lim- ited resources that can only deploy and spend a small amount of money to purchase domains and build websites, publish information on public platforms (e.g., posting on social me- dia or making malicious edits on crowdsourced websites like Wikipedia [21], which are likely to be reverted). An attacker can also perform Search Engine Optimization (SEO) [55], which aims to rank their sites on the top results of search engines for relevant keywords."}, {"title": "4 Experiment Settings", "content": "In this section, we first describe how harmful websites were collected. Then, we explain how manual testing and annota- tion were conducted for these 7 AIPSEs using the collected harmful websites.\n4.1 Data Collection\nOur data collection process can be divided into different steps as shown in Figure 1. We first collect candidate malicious website's URL from three well-known harmful URL collec- tion websites, including 17,225 URLs from PhishTank [14] (collected from 27/11/2024 to 27/12/2024), 2,427 URLs from ThreatBook [19](collected in 2024), and 4,385 URLs- from LevelBlue [8] (also collected in 2024). We then sent requests to these URLs, retaining only those whose corre- sponding domain certificates were valid and whose requests returned a status code of 200. The third step involved au- tomated filtering, which removed links to cloud storage ser- vices, URL shorteners, and domain marketplaces, retaining only websites that permitted crawling. After this process, 353 URLs from PhishTank, 291 URLs from ThreatBook, and 147 URLs from LevelBlue, along with their corresponding HTML files, were retained. For the retained websites, we conduct keyword extraction by using GPT-40 (2024-08-06) to generate a keyword list consisting of five words separated by comma based on the HTML content. The extraction prompt is as follows, where the \"website_info\" refers to the <title>, <h1>, <h2>, <h3>, and <meta> parts in HTML files."}, {"title": "4.2 AIPSES Selection", "content": "In this paper, we consider 7 representative production AIPSEs, including ChatGPT Search, Perplexity, Copilot, TextCortex, Grok, Doubao, and Kimi. Given a query, most AIPSEs include three main components in their response as shown in Figure 2. The first part is the list of accessed web- sites, called \"sources\" or \"relevant pages\". We uniformly refer to this as sources throughout this paper. Note that the sources usually require the user to click to show the whole list of accessed websites. The second part is the answer, which is the LLM's output based on the query and retrieved content. This usually includes multiple paragraphs or items. The third part is the specific corresponding websites cited after each paragraph or item, which we refer to as references."}, {"title": "4.3 Risk Levels", "content": "We aim to categorize URLs into different risk levels based on their potential harm to users. We classify the risk levels for each webpage into high, medium, low, and none, based on the three components (i.e., sources, answers, references) of the content responded by mainstream AIPSEs. Specifically, the risk levels of these URLs are defined as follows. \u2022 High Risk: For a given query, a malicious website is directly cited in the answer.\n\u2022 Medium Risk: If a malicious website is cited in the content but the AIPSE explicitly warns about the risk of the website or clearly identifies the legitimate official website corresponding to the query.\n\u2022 Low Risk: If a malicious website appears only in the sources but not in the answer.\n\u2022 None Risk: If no risky webpages are present in the query results (including answers, references, and sources). Specifically, high risk indicates that users are just one click away from a successful attack (for example, clicking on a malicious file download link). Additionally, the query's over- all risk level is determined by the highest risk level of URLs in the response."}, {"title": "4.4 Query Construction", "content": "Regarding query construction, we consider three types of queries, i.e., keyword list query, URL query, and natural lan- guage query. Keyword List Query. In the keyword list query, the key- word list in each entry of the data is directly used to construct a query. For instance, to query about the MetaMask wallet\u00b2, we use the keyword list (with 5 words): \"MetaMask, crypto wallet, blockchain apps, gateway, recovery mode.\" In total, our dataset contains 100 keyword lists. For each query, we label all risky URLs and their risk level in the response. Specifically, one individual will manually verify the risk level of each URL with the help of several cy- ber threat detection platforms [2, 9, 14, 16, 17]. If a URL's risk status cannot be conclusively determined, the second in- dividual will provide a judgment on it. If it still cannot be determined, we will label it as non-risk. Finally, the third individual will conduct a thorough review to ensure the ac- curacy of the assessment. URL Query. For URL query, we consider the scenario where the user may further query the LLM directly with the URLs obtained from the keyword list query. For each key- word list query, we may obtain a set of risky URLs in dif- ferent levels (low, medium, high), and we randomly select one URL from each risk level if the risk level exists. Intu- itively, using URLs directly might pose a higher risk, as the model might trust the content of the URL without adequate safeguards (we also empirically show it in Table 2). Natural Language Query. Compared with the keyword list query, the natural language query better reflect typical user behavior in AI search engines. For instance, the previously mentioned keyword list could be transformed into the natural language query: \"How to use MetaMask as a crypto wallet and gateway for blockchain apps with recovery mode?\" For the natural language query, we first input the keyword list into the GPT-40 (2024-08-06) using the following prompt."}, {"title": "5 Results", "content": "In this section, we present the evaluation results and our find- ings on the keyword list query, URL query, and natural lan- guage query. We conducted the entire experiment with 4 in- dividuals within 5 days to ensure timeliness and accuracy. Also, each two individuals is grouped to cross-validate the correctness of the results."}, {"title": "5.1 Results on Keyword List Query", "content": "The result of the keyword list query is shown in Table 1. Note that since Copilot does not have sources, there is no low-risk query or URLs associated with it. Note that we la- bel the query's risk level with the highest risk level of its returned URLs. We find that Grok, TextCortex, and Kimi exhibit the highest number of high-risk keyword list queries (41, 34, and 32 out of 100 queries), indicating a greater likeli- hood of including potentially harmful content directly in their responses without warnings. In contrast, ChatGPT Search, Copilot, and Doubao demonstrate a more cautious approach, with a lower proportion of high-risk keyword list queries. In- terestingly, Doubao has the highest medium-risk keyword list queries, which means it will cite the risky URL in the answer but will also include the warning. In general, AIPSEs are vulnerable to the keyword list query as more than 39% of queries are risky on all AIPSES except Copilot. We also record all risky URLs retrieved in keyword list query in Figure 3. We find that, compared to other AIPSEs, ChatGPT Search and Grok indexed a higher number of risky URLs. For instance, ChatGPT Search and Grok on average have 3.04 and 3.60 risky URLs per query while the others are less than or around 2. We speculate that this is due to the larger volume of web pages they index during searches. For instance, for each query, Grok consistently provides 25 URLs and ChatGPT Search returns around 15 URLs. On the other hand, we find that Doubao and Kimi have a lower number of risky URLs in their responses. This might be because they mainly focus on Chinese-based websites, re- sulting in a relatively narrow search domain. The generator will output the final answer with retrieved data. The safety of the generator can be represented by two numbers. The proportion of URL content directly cited in"}, {"title": "5.2 Results on URL Query", "content": "In terms of URL query, we consider directly taking URL as the input and monitoring the risk level change of the re- sponse. The result is shown in Table 2. We find that low-risk or medium-risk URLs often increase their risk level in the response. When low-risk URLs are queried directly, there is a large increase in their risk level. For example, Grok shows 48 out of 49 low-risk URLs be- coming higher risk (excluding inaccessible URLs). Inter- estingly, except for inaccessible URLs, all URL queries by Kimi are classified as high-risk. This finding suggests that direct querying of URLs may introduce additional risks that are not apparent in the initial keyword-based queries, pos-"}, {"title": "5.3 Results on Natural Language Query", "content": "The result of the natural language query is shown in Ta- ble 3. We find that, compared with keyword list query, nat- ural language query generally leads to safer search results."}, {"title": "5.4 Takeaways", "content": "Overall, we find that current AIPSEs exhibit relatively weak filtering capabilities for harmful content\u2014including key- word lists, URLs, and natural language queries on the In- ternet, highlighting the need for improved safety filtering mechanisms. For keyword list queries, AIPSEs may pro- vide high-risk responses by directly citing URLs without any warnings. In the case of URL queries, the risk level can even be amplified. Conversely, natural language queries typically have a lower risk level."}, {"title": "6 Case Studies", "content": "In this section, we present two case studies to demonstrate the vulnerabilities in current AIPSEs. The first case study, shown in Section 6.1, demonstrates how malicious online documentation can easily compromise AIPSEs. The second case study, lie at Section 6.2, demonstrates how AIPSEs can be deceived into recognizing fake websites as official ones by the use of specific content embedded within them. Both case studies are conducted with only basic web de- velopment and without search engine optimization, yet suc- cessfully demonstrate these vulnerabilities against Perplexity using 8 foundation models inclduing ChatGPT-01, ChatGPT- 40 mini, Grok-2, Sonar Large, Sonor Huge, Claude 3.5 Son- net, Perplexity Pro Search, and Claude 3.5 Haiku."}, {"title": "6.1 Safety Concerns in Online Documents with AIPSES", "content": "The first case study explores AIPSE's vulnerabilities that are rooted in phishing documentation on malicious websites. Since AIPSEs can access any publicly available website, hackers may inject harmful code into their cunningly de- signed phishing technical documentation pages. Once an AIPSE indexes these pages, it may output the harmful code directly to users. Consequently, if users directly run the mali-"}, {"title": "6.2 Phishing Threats in AIPSE", "content": "This second case study also explores the vulnerabilities of AIPSES. We show that for newly introduced content, such as newly published information databases, cryptocurrency plat- forms, or trading technical documentation not yet indexed in known databases, a malicious actor can disguise a single webpage as the \"official\" site. Experimental Design. In our experimental setup, we design and implement two websites for testing purposes. The first is a simulated official website(www.hsfaisz.com), and the second is a simulated phishing website(www.hsfaisz.org). Both websites are published online to ensure search engine indexing, and we build them using WordPress.\u00b3 Similar to phishing attacks in the real-world scenario, we consider an adversary who can crawl publicly accessible in- formation from the official website and construct a phishing website. More specifically, we consider the following 4 as- pects to mimic the phishing website's building process:"}, {"title": "6.3 Ethical Safeguards", "content": "To ensure our experimental websites do not adversely impact existing web content, we consider several safeguards to mit- igate ethical risks from multiple perspectives. First, we conduct searches across different mainstream search engines using our designated website keywords (\"V50TAIS\" and \"HSFAISZ\") prior to website creation. This verification process confirms that these keywords did not correspond to any real-world individuals or organizations, thereby preventing potential conflicts or misrepresentation. Second, we display a obvious marker across all experimental webpages, specifically an image containing the text: \"Warn- ing! This is a demonstration website intended for testing pur- poses only.\". This design aims to prevent potential misinter- pretation. Third, all content presented on our experimental websites was entirely fictional. We deliberately avoided im- plementing any backend API interfaces (although the web- sites claimed to offer them). Additionally, all visual content was either AI-generated or custom-designed, eliminating any potential commercial or copyright infringement issues. Our case studies aim to investigate the current vulnerabil- ities of AIPSEs by accurately assessing their risk levels and characteristics in real-world scenarios. Additionally, the eth- ical safeguards we implemented are designed to prevent any potential ethical issues."}, {"title": "7 Risk Mitigation", "content": "Given the complexity of AIPSE risks, existing URL-based detection [25,26] primarily focuses on link analysis and over- looks contextual cues within the content that indicate reli- ability or intent, thus failing to refine the search result for users and reducing the effectiveness of AIPSE. Additionally, AIPSE tends to overly trust URLs claiming to be \"official\" without proper verification, increasing the risk of phishing. To mitigate the risk, we construct an agent that is able to uti- lize external tools to conduct defense, which aims to contain as much information as possible while ensuring the safety of the response. Defender's Goal and Capability. We consider a defender that can capture the original search results returned by the AI search engine and encapsulate an agent that only returns the filtered results to the user. During the defense process, the agent may call detecting tools or query external LLMs to post-process the search result to make it more safe and reliable. Specifically, the defender's goal is to identify the potential risk and attach explicit refusal or risk warnings to the original output."}, {"title": "7.1 Agent Setup", "content": "Agent Design. We design the agent following a widely-used ReAct fashion [66]. The ReAct process consists of three sec- tions, including thought, action, and observation, and runs iteratively thus enabling the agent to interact with external information resources while inducing and updating the ac- tion plans. When enough information and thoughts are col- lected, the agent can conclude these clues to induce the final answer and finish the loop. The detailed prompt for our agent is shown in Appendix B.\nTool Design. To enable the agent to detect the potential risks precisely and comprehensively, we design two tools for the agent, including Content Refinement and URL Detector."}, {"title": "7.2 Defense Evaluation", "content": "Experiment Settings. For defense evaluation, we randomly selected 10 keywords that trigger high-risk responses across all 7 production AIPSEs, which were then used as our de- fense data. Note that we also consider a prompt-based de- fense as the baseline, which exploits the refining power of LLMs to filter the potential risks returned by the AIPSE. For equal comparison, we utilize the same prompt in the agent tool (Appendix C). If a specific risk is identified, then we consider it as successful in reducing the risk to medium-risk. Result. The experiment result is shown in Table 4 and Ta- ble 5. From Table 4, we observe that the prompt-based defense and agent-based defense can both mitigate the to- tal number of high-risk queries. However, the agent-based defense performs significantly better than the prompt-based defense. For instance, among the 70 high-risk queries, 64 responses are still at high risk with prompt-based defenses, while only 12 responses remain at high risk after the agent- based defense. This demonstrates the effectiveness of the agent-based defense. From Table 5, we find that although the agent-based de- fense can identify most malicious URLs correctly (low false negative rate, 1.31%), it will misclassify 34.42% benign"}, {"title": "8 Discussions and Limitations", "content": "Timeliness in Phishing Data. Since most phishing websites are time-sensitive, the validity and availability of phishing websites can change rapidly. To ensure the accuracy and timeliness of our dataset, all experiments were manually con- ducted by six individuals within five days after the data col- lection process. This approach aimed to mitigate the effects associated with outdated or inactive phishing websites. Human Evaluation. Due to the lack of the API on AIPSE for automated web search evaluation, we rely on manual as- sessment to evaluate the response. This includes manually recording URLs and assigning risk levels to each entry. Lim- ited by the research resources, the dataset used in our evalua- tions is on a relatively small scale. Future work could explore automated methods or expand the dataset size to enhance the scalability of such evaluations.\nDefense. To ensure the reliability of the URL detector tool, we analyze the detection results and have two findings. First, we find that the result include a large number of false posi- tives, primarily caused by the inaccuracy of the trained de- tector. However, a relatively high positive rate indicates a strict filtering policy, which does not lead to additional safety concerns but ensures a conservative approach to content fil- tering. On the other hand, the false negative rate represents a real defense failure, as undetected harmful URLs pose a sig- nificant risk. As shown in Table 5, the false negative rate is low, demonstrating the reliability of utilizing the detector as a tool for the agent."}, {"title": "9 Conclusion", "content": "In this paper, we conduct the first comprehensive analysis of safety risks associated with AIPSEs, focusing on their vulnerability quoting harmful content or citing malicious URLs. Our research highlights significant vulnerabilities across seven production AIPSEs, revealing that a large por- tion of their responses may include risky or malicious infor- mation, even when benign queries are used. We further lever- age two case studies on online document spoofing and phish- ing websites to demonstrate the ease of deceiving AIPSEs. To address these issues, we develop an agent-based defense to effectively mitigate high-risk responses, outperforming traditional prompt-based defenses. However, it also resulted in mislabeling benign URLs as malicious, which might re- duce available information. We hope our work can shed light on future research in safeguarding AIPSEs."}, {"title": "Ethics Considerations", "content": "There are two types of ethical considerations in our work that we discuss here: harmful URLs and live webpages. For the former one, to avoid unnecessarily enabling malicious par- ties, we do not publicly release malicious URLs. However, we have disclosed these findings to the affected AIPSES. Al- though we do not publish harmful URLs, we release keyword list and natural language queries. For the latter consideration, we must ensure that we will not pollute real search results for cryptocurrency documentation, news, etc. We ensure that our websites have a low rank and do not affect other searches, appearing only when specifically searched for using our key- word or domain. In addition, our three self-built websites using arbitrary name as the prefix, and we have placed a im- age with the text of \"Testing Purposes Only\" notice in the most prominent area of our websites."}, {"title": "Open Science", "content": "In accordance with the open science policy, we have released all relevant keyword lists and natural language query. We also released the relevant code and prompt template. The above resources will be accessible in an anonymous reposi- tory once this paper is published."}]}