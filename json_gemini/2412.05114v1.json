{"title": "A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs", "authors": ["Patrick Betz", "Nathanael Stelzner", "Christian Meilicke", "Heiner Stuckenschmidt", "Christian Bartelt"], "abstract": "In this technical report, we investigate the predictive performance differences of a rule-based approach and the GNN architectures NBFNet and A*Net with respect to knowledge graph completion. For the two most common benchmarks, we find that a substantial fraction of the performance difference can be explained by one unique negative pattern on each dataset that is hidden from the rule-based approach. Our findings add a unique perspective on the performance difference of different model classes for knowledge graph completion: Models can achieve a predictive performance advantage by penalizing scores of incorrect facts opposed to providing high scores for correct facts.", "sections": [{"title": "Introduction", "content": "A knowledge graph (KG) is a structured representation of a certain real world domain in form of (subject, relation, object) triples. The problem of knowledge graph completion (KGC) aims to infer new triples from a given and incomplete KG. Models need to learn patterns from a given KG and use them to make new fact predictions. One model class for performing KGC is given by rule-based approaches [13,9]. They learn symbolic patterns on the KG and are fully explainable as fact predictions originate from human-understandable rules. Moreover, they are frequently shown to be highly competitive in regard to predictive performance [18,13]. Recently, however, a novel graph neural network (GNN) architecture was introduced that reports significant evaluation improvements. The Neural Bellman Ford Network (NBFNet) [24] and its successor A*Net [23] use a fact scoring mechanism based on calculating path representations of a source and a candidate entity during message passing. Previous work finds that the GNNs express and learn certain positive rules by this procedure [24,17].\nIn this technical report, we investigate the GNNs behaviour on the KG benchmarks FB15K-237 [20] and WN18RR [8] and compare it with a rule-based approach [13,14]. Our findings suggest that approximately half of the performance differences of the model classes can be explained by one simple negative pattern on each dataset, which is hidden from the rule-based approach. On WN18RR, the exploitation of an exclusion rule, derived from the particular structure of 1-to-N relations, significantly boosts the performance. For FB15K-237, the particular benchmark construction induced a structural bias disallowing connections"}, {"title": "Background", "content": ""}, {"title": "Knowledge Graph Completion", "content": "We define a KG G as a collection of p(s, o) facts or triples where p is a relation also termed predicate, s is a head entity, and o is a tail entity. The set of entities is denoted by E and the set of relations is denoted by P. An existing fact t \u2208 Gis assumed to be a correct statement about the respective domain, such as profession(obama, politician). However, most of the existing real-world KGs are incomplete. A fact which is not existing in the KG is not necessarily false. The field of KGC is concerned with deriving new facts from the KG that are true but were previously unknown. We focus on the standard setting in this report where a model is trained on a training split of a KG and evaluated on a test split of the KG. No additional external data is used, i.e., a model has to learn given patterns from within the training graph and apply them to queries formed from the test graph.\nThe common evaluation protocols are ranking-based. First, the initial KG is split into training, validation and testing subsets. A model is trained on the training set while using guidance from the validation set. Subsequently, it is evaluated on the test KG. For every fact p(s, o) from the test set, two queries are formed. A head query p(?, o) with correct answers and a tail query p(s, ?) with correct answer o. We focus on the tail direction in the following. The explanations are the same for the head direction. A model has to propose confidence scores to candidate answers c\u2208 E by scoring facts p(s, c). We call s the source entity and c the candidate entity. From the scores of different candidates, a sorted ranking is created and the ranking position of the true answer o is used for evaluation. We use filtered metrics over all experiments. True answers except of the current true answer are filtered out to not penalize models erroneously. Often models calculate directed fact scores, i.e., for some fact p(e1, e2) there can be a head score (based on a head query) and a distinct tail score (based on a tail query). We will focus on the common evaluation metrics Mean Reciprocal Rank (MRR) and Hits@X. Further details can be found, for instance, in [18,19]."}, {"title": "Approaches for KGC", "content": ""}, {"title": "Rule-based KGC.", "content": "Rule-based approaches for KGC first mine symbolic Datalog rules on the training KG such as:\nlivesIn(X, london) \u2192 speaks(X, english)\nbornIn(X, A), cityOf(A,Y) \u2192 citizenOf(X,Y)\nAll the variables are universally quantified and london and english are entities of the KG. The comma in the body of the rule denotes the logical AND. Rule-based approaches are inherently interpretable as every prediction made can be traced back to a rule which is human readable. However, often a prediction is made simultaneously by multiple rules which requires to define or learn an aggregation function that calculates a final confidence score for the prediction [9,2,15].\nIn this report, we focus on approaches that learn aggregation functions on the training graph [4,14]. In particular, we use a simple linear aggregation function as proposed in Ott et al. [14]. Rules are represented as binary features assigned with learnable weights. Using rules as binary features is also proposed in [10].\nLet ti be some target fact and x\u00bf\u00a1 \u2208 {0,1}K be a feature vector that represents a learned set of K rules where xij = 0 if rule j predicts ti and 0 otherwise. The scoring function is based on a simple logistic regression formulation:\n$p(t_i|x_i) = \\sigma \\Big( \\sum_{j=1}^{K} w_j x_{ij} + w_o \\Big)$"}, {"title": "Graph Neural Networks.", "content": "The introduction of NBFNet and A*Net demonstrated the effectiveness of GNNs for KGC. Compared to the rule-based approach that is used in this work, they achieve an MRR that is roughly 5 percentage points higher on the WN18RR [8] and FB15K-237 [20] test sets in the standard setting. Interestingly, the performance is on par when considering the YAGO3-10 [12] benchmark [23]. NBFNet and its successor A*Net are message passing GNNs that rely on learning a path representation between a source entity of a query and a candidate entity. In contrast to previous GNN formulations, the message passing is performed in dependence to a current query. By using a boundary condition in the initial round of message passing, all entity representations are initialized with a zero vector except for the source entity of the query. Subsequently, the representations of all connected entities are populated by message passing that originates from the representation of the source entity. The approach learns global relation embeddings but no entity embeddings as their representations are calculated with respect to the current target query. Further details are provided in the original publications. For all our experiments, we use the implementations provided in [23] for NBFNet and A*Net."}, {"title": "Synthetic Datasets", "content": "In this section, we will present two artificial KGs, the zoo dataset (Section 3.1) and the uni dataset (Section 3.2). They will help us to identify structural differences between the different model classes. Later in Sections 4 and 5, we will investigate how the model behaviour on the zoo dataset can also be observed on the WN18RR KG benchmark [8] and the behaviour on the uni dataset is strongly connected to the particular construction of the FB15K-237 KG [20]."}, {"title": "The Zoo Dataset", "content": "Figure 1 shows the zoo KG which only contains two relations and describes students who visit the zoo. They walk in a chain-like structure such that each student has one follower and follows one other student. The dataset that we use in the synthetic experiments described below is exactly as shown in the figure with the exception that we use 100 students nodes and the last student in the chain follows the first student in the chain. Each student visits the zoo (dashed relation) such that message passing over the whole graph is possible. The fact follows(bobby, anna) is removed and taken as an evaluation fact, creating a visual gap in the graph. After the training phase on the KG, a model has to propose candidate answers to a head and a tail query formed from the evaluation fact. We will exclusively discuss the head direction within this section for simplicity. Due to the symmetry of the dataset, the same explanations hold for the tail direction for which we also report results for completeness."}, {"title": "Negative Pattern.", "content": "The previous discussion shows that there does not exist positive evidence in the graph (in form of facts) that helps to score bobby with a higher likelihood than the other student nodes. However, the behaviour of the GNNs is quite significant suggesting they learned a non-random regularity. To find an explanation, we have to consider which facts are not present in the graph. For example, sandy does not follow bobby, anna, or any of the other nodes but she follows lisa. From this we can formulate a negative pattern: If a node follows someone already, it does not follow someone else. There is not one case in the data that violates this statement. We will formalize this in Section 4."}, {"title": "The Uni Dataset", "content": "Figure 2 shows the uni KG where students ask a question to a professor and the professor answers to some of the students. All students (including anna and bernd) and the professor are member of the university which is expressed with dashed arrows where some of them are excluded in the figure to prevent occlusion. We duplicate the pattern shown in the figure 3 times, such that there are 3 groups of students and a professor (including 3 versions of anna and bernd) but all of them are member of the global uni node.\nThe fact answered(professor, anna) is removed from the graph and used as an evaluation fact. For simplicity, we will focus on the tail direction in the following. From the evaluation fact, the models have to answer the query answered(professor,?). The only two relevant candidates are bernd and the correct answer anna. The remaining studenti nodes are already known to have received answers from the professor in the training data (they are filtered out by the protocol). When looking at the data, it becomes apparent that anna is the only reasonable choice as there exists a clear positive pattern which can be described by a cyclical rule asked(X,Y) \u2192 answered(X, Y) that exhibits support from the studenti nodes. It says that everyone who asked a person also received an answer from that person. While anna asked a question to the professor, nothing is known about bernd. Therefore, the data provides clear evidence that anna should be ranked above bernd. Conversely, there is no reason why bernd should be ranked above anna."}, {"title": "Remove-One-Hop (ROH).", "content": "The last two rows of Table 2 show the results for the GNNs when the ROH hyperparameter is turned on. The parameter only affects the training process of the GNNs. During training, for a given training"}, {"title": "Negative Patterns on WN18RR", "content": "The WN18RR KG was intrudoced by Dettmers et al. [8] to have a more challenging version of the WN18 KG [6]. On the WN18RR test set, the GNNs achieve a joint MRR that is approximately five percentage points higher compared to the rule-based approach (Table 3). We have identified a structural difference between the model classes already in Section 3.1. The GNNs are able to rank bobby on top for the test query follows(?, anna) by penalizing all remaining student"}, {"title": "Only-One-Tail Rule.", "content": "The hypernym relation describes a semantic supertype relationship between a specific and a more generic term, such as hypernym (red, color) and hypernym(blue, color). A closer inspection of the WN18RR training set reveals that the relation is of type N-to-1, that is, each head entity can only be associated with exactly one tail entity. While the structural composition of such a relation type can not be explicitly used by the model classes, it can be reformulated to a computational rule, which we express using logic syntax in the following.\nLet x, y, z be variables and p be a relation. The Only-One-Tail (OOT) rule w.r.t. p is given by:\n$\\forall x,y: \\exists z \\; p(x,z) \\rightarrow \\neg p(x,y)$"}, {"title": "Perturbation Experiments", "content": "We will investigate in the following if the GNNs exploited the OOT rule on the WN18RR dataset for the hypernym relation. We make use of perturbation experiments in the context of adversarial attacks against KGC models [3,16]. An already trained GNN performs message passing over the training graph for answering test queries at inference times. This allows to query the GNNs based on small perturbations of the training graph. Our experiments are based on the idea that removing or adding a fact that activates or deactivates the OOT rule should be reflected by significant score changes if the rule is indeed exploited by the model. In fact, if the rule is activated, the score of a test fact should decrease while it should increase if the rule is deactivated."}, {"title": "Rule-based Experiments", "content": "For the rule-based experiments, we use a re-implementation of the logistic regression used by Ott et al. [14] as described in Section 2.2. We discussed already that this approach cannot express the OOT rule for the hypernym relation as the rule cannot be expressed in the language bias. Learning negative rules from the data, on the other hand, is challenging and we are opting here for a simple approach to test our base hypothesis. In fact, we augment equation 1 by existence features with respect to a current target fact. Let t = p(s, o) be a target fact. We define a binary feature z(t) \u2208 {0,1} that evaluates to one, if entity s already exists in the head slot in the KG in some other fact with relation p. That is, the feature is one if \u2203e \u2208 E : p(s, e) \u2208 G and it is zero otherwise. First, we create this feature only for the hypernym relation and assign it a learnable weight \u00df. We then augment the sum in equation 1 by one term:\n$p(t_i|x_i) = \\sigma \\Big( \\sum_{j=1}^{K} w_j x_{ij} + w_o + \\beta z \\Big)$"}, {"title": "Negative Pattern on FB15K-237", "content": "We will now turn to the FB15K-237 KG which is frequently used in the KGC community and was introduced in [20]. The rule-based approach reaches an MRR that is more than 5 percentage points lower compared to the GNNs on the FB15K-237 test set (see Table 8). We observed in Section 3.2 for the uni dataset that a direct connection between a source entity (professor) and a candidate entity (anna) leads to a score decrease for a respective fact when the GNNs are trained under the ROH hyperparameter. In contrast, such a behaviour is not shown by the rule-based approach. In fact, positive rules with only one body atom are important for the overall performance. We will now introduce the Only-One-Link rule:"}, {"title": "Perturbation Experiments", "content": "In the original configuration files of the GNNs the ROH parameter is turned off for WN18RR and turned on for FB15K-237. We employ perturbation results similar to Section 4.1 to investigate if the model specifications for FB15K-237 exploit the OOL rule. We re-train the models with the code provided by the original publication [23] and use the evaluation code from the PyClause library [1]. We also train and evaluate the models with ROH turned off (Table 7). The perturbation experiments are based on the facts of the test set. The definitions from Section 4.1 apply, e.g., we term a fact that activates the negative rule an influential fact and the score analysis is based on a base fact."}, {"title": "Post-hoc Experiments", "content": "We discussed previously that the OOL rule is not reflected within the training set of FB15K-237. Therefore, we are not able to learn weights for existence features on the dataset. While it is possible to add artificial negative facts to the training procedure, we choose the most pragmatic approach that does not involve manipulating the training data. If external knowledge is given about the structure of the OOL rule, we can simply remove all candidate proposals at inference time that already have a connection to the current source entity. By this procedure, we strictly enforce the pattern. For the rule-based approach, we use our re-implementation of the linear model from Ott et al. [14] as described in Section 4.2 while using their set of rules and hyperparameter configurations. For the post-hoc filter, we choose the following approach exemplified with the"}, {"title": "Discussion and Conclusion", "content": "In this report, we compared a rule-based approach [14] with the GNNs NBFNet [24] and A*Net [23] with respect to their predictive performance on the benchmarks WN18RR and FB15K-237. We provided empirical evidence that the GNNs are able to exploit certain negative patterns that are hidden from the rule-based approach. Our synthetic experiments also suggest that for these cases, a simple embedding model like ComplEx [21] aligns with the behaviour of the rule-based approach.\nFor WN18RR, our results clearly suggest a higher expressivity of the GNNs compared to the employed rule-based approach. Nevertheless, we showed that simply adding existence features to the rule-based approach leads to a significant performance improvement. The results for FB15K-237 are more ambiguous. It is quite remarkable that the ROH parameter seems to activate the discussed behaviour. It leads to a score penalty for candidates that have already a connection to the source entity of a query. However, the underlying OOL rule is a structural bias introduced by the benchmark construction, opposed to being a natural regularity. It is unclear for a potential user if the models should be trained with the ROH hyperparameter turned on. In general, future work is required to better understand the internal model processes regarding the hyperparameter.\nEstimating how much of the overall improvement on the real benchmarks can be explained by the negative patterns is not straightforward. A conservative approach is to base the estimate on the improvement of the rule-based approach under the proposed augmentation strategies. That is, using existence features for WN18RR as in Section 4.2 and using the post-hoc filter for FB15K-237 as in Section 5.2. By doing so, we can be certain that nothing except of the exploitation of the negative patterns is reflected in the improved performance. Therefore, we estimate that approximately half of the improvement of the GNNs over the rule-based approach can be explained by the defined negative patterns.\nFinally, it is likely that the patterns that are learned by the GNNs (positive or negative) might overlap. A fact could, for instance, simultaneously activate some positive pattern while also activating some other negative pattern. Indeed, our experiments expectedly suggest tendencies of model behaviour opposed to a hard execution of the negative patterns. In general, we only discussed one particular negative pattern (OOT rule) for one particular relation for WN18RR and one negative pattern regarding all relations for FB15K-237 (OOL rule). It is plausible that the GNNs have learned different negative rules and also more general formulations consisting of distinct relations or even multi-hop patterns. Future work should perform a more fine-grained analysis regarding different pattern types. Moreover, investigating the aggregation of overlapping patterns into a final score is an interesting direction."}, {"title": "Appendix", "content": ""}, {"title": "Existence Feature Types for WN18RR", "content": ""}]}