{"title": "FineRec: Exploring Fine-grained Sequential Recommendation", "authors": ["Xiaokun Zhang", "Bo Xu", "Youlin Wu", "Yuan Zhong", "Hongfei Lin", "Fenglong Ma"], "abstract": "Sequential recommendation is dedicated to offering items of interest for users based on their history behaviors. The attribute-opinion pairs, expressed by users in their reviews for items, provide the potentials to capture user preferences and item characteristics at a fine-grained level. To this end, we propose a novel framework FineRec that explores the attribute-opinion pairs of reviews to finely handle sequential recommendation. Specifically, we utilize a large language model to extract attribute-opinion pairs from reviews. For each attribute, a unique attribute-specific user-opinion-item graph is created, where corresponding opinions serve as the edges linking heterogeneous user and item nodes. To tackle the diversity of opinions, we devise a diversity-aware convolution operation to aggregate information within the graphs, enabling attribute-specific user and item representation learning. Ultimately, we present an interaction-driven fusion mechanism to integrate attribute-specific user/item representations across all attributes for generating recommendations. Extensive experiments conducted on several real-world datasets demonstrate the superiority of our FineRec over existing state-of-the-art methods. Further analysis also verifies the effectiveness of our fine-grained manner in handling the task.", "sections": [{"title": "1 INTRODUCTION", "content": "Sequential Recommendation (SR) aims to provide items of interest for users based on their history behaviors [12, 16]. SR concentrates on addressing the inherent feature of user behaviors, i.e., chronologically evolving preferences. This focus equips SR with the ability to grasp users' shifting interests, deliver personalized services timely, and adapt to the fast-paced trends of the modern information age. Owing to such merits, SR has received widespread attention from both academia and industry in recent years [10, 20, 36, 40].\nExisting methods typically rely on neural networks to obtain item and user embeddings, basing recommendations on the similarity between these embeddings. Most efforts attend to model implicit activities of users, like clicks, to infer their preferences, employing various neural architectures including Recurrent Neural Networks (RNN) [12, 19], attention mechanism [16, 34] and Graph Neural Networks (GNN) [35, 37]. As shown in Figure 1 (a), unfortunately, a significant drawback of this implicit approach is that implicit actions, like accidental clicks, can sometimes misrepresent user interests, thereby introducing noise into the models [37, 45]. Another line of research [9, 18, 32] utilizes user-item reviews to explicitly capture user preferences. However, they all coarsely treat a review as a whole, overlooking the fact that users may have distinct opinions about different attributes within a single review. As presented in Figure 1 (b), this failure to discern such fine-grained distinctions limits the effectiveness of these methods.\nActually, in a review, a user expresses her specific feelings for an item in the form of attribute-opinion pairs. These pairs provide an opportunity to capture user preferences and item characteristics at an explicit and fine-grained manner, offering a new perspective"}, {"title": "", "content": "to improve recommendation. As depicted in Figure 1 (c), this manner facilitates satisfactory recommendations, such as suggesting loose clothing to a user who previously expressed a dislike for tight fits, and the new item is favorably described as loose by other users. Despite holding encouraging prospects, effectively implementing the fine-grained manner in SR faces several obstacles:\nFirstly, it is difficult to extract informative attribute-opinion pairs from reviews. Users often express their opinions using informal and implicit language, which complicates the extraction. For instance, consider the review, \"I was robbed by this thing!\"-neither the attribute (Price) nor opinion (Expensive) is delivered in a straightforward way. Lacking rich language knowledge, current methods, either based on hand-craft rules [15] or well-designed models [3] tailored for certain fields, can not accurately extract informative attribute-opinion pairs from such reviews.\nSecondly, a major challenge lies in finely representing users and items under each attribute with diverse opinions. On one hand, users and items exhibit unique preferences and characteristics under different attributes. However, current methods typically represent them in a overall way, overlooking the distinctions across attributes. On the other hand, even in a certain attribute, the opinion diversity impedes the learning of fine-grained user and item representations. For users, their attitudes would be changing along with distinct items on an attribute. For example, a user may prefer televisions with large size for enhanced viewing, while favoring small-sized phones due to portability. As to items, they may receive various ratings from different users under an attribute. It is common that some users favor brightly colored clothes, while others may hate them. Thus, it is imperative to consider opinion diversity to achieve fine-grained user and item representations at attribute-level.\nThirdly, it remains a problem to generate recommendations in the fine-grained manner. User behaviors are determined by user preferences and item characteristics in various attributes jointly. For instance, a loyal fan may buy an item of her favored brand despite disliking its high price. Unfortunately, we can only observe the overall user-item interactions, while there are no explicit indicators to show how each attribute affects user decisions. This makes it challenging to infer user actions in the fine-grained manner.\nTo tackle these issues, we propose a novel framework to incorporate attribute-opinion pairs for Finely handling sequential Recommendation (FineRec). Firstly, trained on massive text data, the Large Language Model (LLM) encapsulates a wealth of language knowledge [1, 11, 28]. In light of this, we utilize LLM to extract attribute-opinion pairs from reviews. To relieve hallucinations of LLMs in tackling complex tasks, we obtain attributes based on their importance on websites and subsequently extract corresponding opinions via LLM. Secondly, to represent users/items under distinct attributes, we create a unique attribute-specific user-opinion-item graph for each attribute. Within the graph, heterogeneous user and item nodes are connected by opinion edges which represent the specific opinions users have expressed about items under the attribute. Afterwards, a diversity-aware convolution operation is devised to achieve fine-grained user and item representation on the graphs, with an emphasis on opinion diversity during the information aggregation. Lastly, we present an interaction-driven fusion mechanism that leverages user-item interaction information to guide the fusion of attribute-specific item/user representations,"}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Sequential Recommendation", "content": "With the powerful ability in representing users and items, neural networks have come to dominate the field of sequential recommendation [10, 27]. Various neural structures are employed to model user behavior sequences like RNN [12, 19], attention mechanism [16, 38, 39], Transformers [34, 45, 47], GNN [35, 37], MLP [21, 22] and contrastive learning [5, 30]. Some recent methods incorporate extra item information to mine user preferences from multiple views including categories [2, 4, 26], brands [10, 33], price [41, 43], text [13, 20, 28] as well as images [14, 42]. However, all of them focus on modeling user implicit behaviors which can not represent genuine intents of users in some cases. Thus, this limitation significantly hampers their effectiveness."}, {"title": "2.2 Review-driven Recommendation", "content": "Reviews, posted by users to explicitly convey their opinions on items, are utilized by recent works to improve recommendation task [9, 18, 32]. These works typically employ reviews to build user and item embeddings, and then rely on certain neural structures to offer suggestions like attention mechanism [9, 25] and GNN [32]. RNS [18] is a representative work incorporating reviews into sequential recommendation, where review contents are utilized to obtain users' long-term and short-term preferences. However, these efforts ignore the significant differences in a user review regarding different attributes, and instead coarsely model a review as a whole. Moreover, some methods attempt to capture user distinct interest on varying aspects [6, 7, 31, 44]. Unfortunately, they only focus on discerning various aspects while do not capture specific user opinions towards these aspects. Such paradigms fall short of finely disclosing user preferences or item characteristics either."}, {"title": "3 PROBLEM STATEMENT", "content": "Let $\\mathcal{U}$ and $\\mathcal{X}$ denote the unique user and item set, respectively. The $\\mathcal{R}$ is a review set consisting of all reviews posted by users on items. Each user $u_i \\in \\mathcal{U}$ has interacted with a sequence of items chronologically, producing a behavior sequence denoted as: $\\mathcal{S}u_i =$"}, {"title": "4 THE PROPOSED APPROACH", "content": ""}, {"title": "4.1 Overview of the FineRec", "content": "As illustrated in Figure 2, the proposed FineRec mainly consists of the following interconnected components: (1) LLM-based attribute-opinion extraction identifies informative attributes based on their importance and subsequently extracts the attribute-opinion pairs from reviews via LLM; (2) Fine-grained representation learning obtains fine-grained user and item embeddings via exploring attribute-opinion pairs, where an attribute-specific user-opinion-item graph is created under each attribute, with a diversity-aware convolution operation conducting information aggregating; (3) Interaction-driven fusion mechanism leverages user-item interaction information to guide the fusion of attribute-specific item/user representations; and (4) Prediction provides recommendations in the fine-grained manner."}, {"title": "4.2 LLM-based Attribute-opinion Extraction", "content": "Large Language Models (LLMs), benefiting from their training on massive text corpora, have become reservoirs of vast language knowledge. This foundation empowers LLMs with remarkable proficiency in various tasks of Natural Language Processing (NLP) [1, 11, 28]. Leveraging this capability, we utilize LLMs for"}, {"title": "", "content": "extracting attribute-opinion pairs from reviews. In the context of recommendation, the item attributes that users care about are heavily overlapping, that is, a small number of important attributes significantly influence user choice like item price [43]. Besides, LLMs can sometimes suffer from \"hallucinations\" where they perform unsatisfactorily in addressing complex issues [29]. In light of these facts, we present to obtain informative attributes based on their importance, and subsequently extract corresponding opinions via LLMs. Such a paradigm enables FineRec to focus on important attributes and greatly simplifies the extraction task.\nSpecifically, we gather item attributes directly from E-commerce websites, with an assumption that the displayed attributes are important. Adhering to the Pareto principle, we focus on the most prevalent attributes, selecting the top N attributes based on their frequency of occurrence to build the attribute set $\\mathcal{A} = \\{a_1, a_2, \\ldots, a_n\\}$, where N is the number of extracted attributes. Note that, each $a_i$ represents an informative attribute like 'Price', 'Color' and so on.\nA well-crafted prompt is the key to unleash the potential of LLMs. Building upon the extracted attributes, thus, we develop a specialized prompt template to facilitate the LLM in extracting attribute-opinion pairs from reviews as follows,\nwhere $a_n \\in \\mathcal{A}$ and \"review contents\" denotes a specific review. For a review $r_{ij}$, the LLM outputs a sentence that captures the opinion of a user ($u_i$) about an item ($x_j$) under the attribute ($a_n$), denoted as $o \\in \\mathcal{O}$, where $\\mathcal{O}$ is opinion set. If the review does not mention any attribute in $\\mathcal{A}$, the result is disregarded. Note that, we apply LLM to conduct the extraction across all reviews for every attribute,"}, {"title": "4.3 Fine-grained Representation Learning", "content": ""}, {"title": "4.3.1 Attribute-specific user-opinion-item graph", "content": "Generally, a/an user/item holds distinct preferences/characteristics under different attributes. Therefore, we create an attribute-specific user-opinion-item graph to finely-grained encode users/items under each attribute. Specifically, for an attribute $a_n$, a unique user-opinion-item graph $\\mathcal{G}^{n} = (\\mathcal{U}^{n} \\cup \\mathcal{X}^{n}, \\mathcal{O}^{n})$ is built. In this graph, $\\mathcal{U}^{n} \\cup \\mathcal{X}^{n}$ is the node set consisting of users and items, where $\\mathcal{U}^{n} \\subseteq \\mathcal{U}$ and $\\mathcal{X}^{n} \\subseteq \\mathcal{X}$. The $\\mathcal{O}^{n} \\subseteq \\mathcal{O}$ is the edge set encapsulating opinions expressed by users about items regarding the specific attribute. As shown in Figure 2, within the graph $\\mathcal{G}^{n}$ of the attribute $a_n$, a user $u_i \\in \\mathcal{U}^{n}$ and an item $x_j \\in \\mathcal{X}^{n}$ are connected by an opinion edge $o_n \\in \\mathcal{O}^{n}$ if the user expressed her opinion $o_n$ to the item in relation to the attribute. Note that, the $\\mathcal{G}^{n}$ will not record the user and item if there is not an opinion between them under the attribute. Moreover, the attribute-specific user-opinion-item graph captures interaction and opinion information between users and items, providing the potentials to discern fine-grained user preferences and item characteristics specific to each attribute.\nTo represent various user/item preferences/characteristics under different attributes, we employ distinct embeddings to represent users/items in each attribute. To elaborate, a user $u_i$ is separately represented by N unique embeddings as $\\{u^{1}_{i}, u^{2}_{i}, \\ldots, u^{N}_{i}\\}$, where $u^{n}_{i} \\in \\mathbb{R}^{d}$ indicates the user preferences about attribute $a_n \\in \\mathcal{A}$. The same applies to items, i.e., each item $x_j$ is represented as $\\{x^{1}_{j}, x^{2}_{j}, \\ldots, x^{N}_{j}\\}$, where $x^{n}_{j} \\in \\mathbb{R}^{d}$ denotes the item characteristics in attribute $a_n$. Besides, we employ pre-trained BERT [8] to represent an attribute $a_n$ as $a_n \\in \\mathbb{R}^{d}$ and an opinion text $o_n$ as $o_{n_j} \\in \\mathbb{R}^{d}$."}, {"title": "4.3.2 Diversity-aware convolution operation", "content": "The extensive diversity of opinions impedes fine-grained user and item representation learning through attribute-opinion manner. Specifically, for a given attribute, a user may have varying opinions about different items, and similarly, an item might receive a range of opinions from different users. To address this diversity, we devise a diversity-aware convolution operation to conduct information aggregating on each attribute-specific user-opinion-item graph. Formally, we update a user's embedding $u_i^n$ on the $\\mathcal{G}^n$ of attribute $a^n$ via,\n$\\begin{equation} u_i^n = u_i^n + \\alpha_i \\sum_{x_j \\in \\mathcal{X}_{u_i}^n} (x_j^n + o_{n_j}) \\end{equation}$\nwhere $\\mathcal{X}_{u_i}^n$ consists of items adjacent with the user in the graph $\\mathcal{G}^n$, while $o_{n_j}$ is embedding of corresponding opinion. It's important to highlight that our method updates user embeddings by jointly considering both the item and its associated opinion (instantiated with an additive operation). This approach allows our FineRec to capture the diversity of a user's opinions towards different items. The importance of different item-opinion pairs is"}, {"title": "determined by,", "content": "$\\begin{equation} \\alpha_j = \\frac{\\text{sim}(u_i^n, (a_n + x_j^n))}{\\sum_{x \\in \\mathcal{X}_{u_i}^n} \\text{sim}(u_i^n, (a_n + x^n))} \\end{equation}$\nwhere the sim() is cosine similarity. To highlight the attribute's influence on user behaviors, we employ the attribute embedding $a_n$ to calculate the importance. Similarly, we update an item embedding $x_j^n$ on the attribute-specific graph $\\mathcal{G}^n$ as follows,\n$\\begin{equation} x_j^n = x_j^n + \\beta_j \\sum_{u_i \\in \\mathcal{U}_{x_j}^n} (u_i^n + o_{n_i}) \\end{equation}$\n$\\begin{equation} \\beta_i = \\frac{\\text{sim}(x_j^n, (a_n + u_i^n))}{\\sum_{u \\in \\mathcal{U}_{x_j}^n} \\text{sim}(x_j^n, (a_n + u^n))} \\end{equation}$\nwhere $\\mathcal{U}_{x_j}^n \\subseteq \\mathcal{U}^n$ contains users expressing opinions on the item under the attribute $a_n$."}, {"title": "4.4 Interaction-driven Fusion Mechanism", "content": "The future actions of users are jointly influenced by their preferences and items' characteristics across various attributes. However, capturing the intricate patterns of the influence is challenging, primarily because there are no explicit signals indicating how each attribute impacts user decisions. Fortunately, the user-item interactions provide insights into these complex influencing patterns. For example, when a user selects certain items from a vast choices, it reflects a match between her overall preferences and the characteristics of those items. In fact, these interactions hint at the similarity at the embedding level, considering neural models operate based on the similarity of representations. Thus, we propose to employ the similarity implied in the user-item interactions to integrate attribute-specific item/user representations.\nTo intuitively illustrate user-item interaction relations, we present a global user-item interaction graph in the upper right part of Figure 2. As shown in the figure, user-item interactions manifest three types of similarities: (1) user-item similarity, indicating the commonality between a user and her interacted items; (2) user-user similarity, where users buying the same item can be considered similar; (3) item-item similarity, where items interacted with the same user are deemed similar. We start by concatenating attribute-specific item and user embeddings as,\n$\\begin{equation} \\hat{u}_i = [u^{1}_{i}; u^{2}_{i}; \\dots ;u^{N}_{i}] \\end{equation}$\n$\\begin{equation} \\hat{x}_j = [x^{1}_{j}; x^{2}_{j}; \\dots ;x^{N}_{j}] \\end{equation}$\nwhere [;] denotes concatenation operation, and $\\hat{u}_i, \\hat{x}_j \\in \\mathbb{R}^{Nd}$.\nWe find that, interestingly, three types of similarity can be conceptualized as adjacent relationships within the global user-item graph. Specifically, the user-item similarity represents direct, one-hop connections in the graph, while user-user and item-item similarities correspond to two-hop relationships. In light of aggregating algorithms in GNN, we integrate various preferences of the user ($u_i$) on different attributes as,\n$\\begin{equation} u_i = \\hat{u}_i + \\frac{1}{\\left|\\mathcal{X}_{u_i}\\right|} \\sum_{x_j \\in \\mathcal{X}_{u_i}} \\mathbf{W}_1\\hat{x}_j + \\frac{1}{\\left|\\mathcal{U}_{u_i}\\right|} \\sum_{u_k \\in \\mathcal{U}_{u_i}} \\mathbf{W}_2\\hat{u}_k \\end{equation}$\nwhere $\\mathbf{W}_1, \\mathbf{W}_2 \\in \\mathbb{R}^{Nd \\times Nd}$ are trainable matrices enabling attribute-specific embeddings to interact with each other, $\\mathcal{X}_{u_i}$ are items"}, {"title": "", "content": "interacted by the user $u_i$, $\\mathcal{U}_{u_i}$ contains users buying the same items as the user $u_i$, and $u_i$ is the final user representation. Note that, $\\mathcal{X}_{u_i}$ indicates user-item similarity, while $\\mathcal{U}_{u_i}$ denotes user-user similarity. In Eq.(7), for a user, we inject the information of its similar items and users into its embedding. This method highlights the similarities revealed through user-item interactions, urging similar users and items closer in the embedding space. By doing so, it guides the fusion for representations from various attributes. Similarly, we conduct the fusion for an item ($x_j$) as,\n$\\begin{equation} x_j = \\hat{x}_j + \\frac{1}{\\left|\\mathcal{U}_{x_j}\\right|} \\sum_{u_i \\in \\mathcal{U}_{x_j}} \\mathbf{W}_3\\hat{u}_i + \\frac{1}{\\left|\\mathcal{X}_{x_j}\\right|} \\sum_{x_k \\in \\mathcal{X}_{x_j}} \\mathbf{W}_4\\hat{x}_k \\end{equation}$\nwhere $\\mathcal{U}_{x_j}$ denotes users interacting with the item $x_j$, $\\mathcal{X}_{x_j}$ consists of items co-interacted by users with item $x_j$, and $x_j$ is the final item representation. Besides, $\\mathcal{U}_{x_j}$ indicates user-item similarity, while $\\mathcal{X}_{x_j}$ denotes item-item similarity."}, {"title": "4.5 Prediction", "content": "Recent actions of a user can reflect her recent interest. Following [18, 35, 38], thus, we represent a user's recent interest $\\overline{u}_i$ by conducting average-pooling on her last $l$ interacted items as,\n$\\begin{equation} \\overline{u}_i = \\frac{1}{l} \\sum_{k=0}^{l-1} x_{m-k}. \\end{equation}$\nBased on user embedding $u_i$, her recent interest $\\overline{u}_i$ and item embedding $x_j$, we can forecast next behavior of the user as,\n$\\begin{equation} \\hat{y}_j = (u_i + \\overline{u}_i)^T x_j, \\end{equation}$\nwhere $\\hat{y}_j$ is the interacted score predicted for a candidate item $x_j$. To ensure a fair comparison, we follow the training paradigm of full ranking on the entail item set as in [46, 47]. Formally, the FineRec is trained via cross-entropy loss as follows,\n$\\begin{equation} \\mathcal{L}(p, y) = - \\sum_{j=1}^{X} p_j \\log(y_j) + (1 - p_j) \\log(1 - y_j) \\end{equation}$\nwhere $p_j$ is the ground truth indicating whether the user purchases item $x_j$."}, {"title": "5 EXPERIMENTAL SETUP", "content": ""}, {"title": "5.1 Research Questions", "content": "We conduct extensive experiments on several real-world datasets to evaluate the proposed FineRec and all baselines, with the focus on answering the following research questions:\nRQ1: How does our FineRec perform compared with existing state-of-the-art methods? (ref. Section 6.1)"}, {"title": "", "content": "RQ2: What is the effect of the fine-grained attribute-opinion manner in handling the task? (ref. Section 6.2)\nRQ3: Does each proposed technique contribute positively to FineRec's performance? (ref. Section 6.3-6.4)\nRQ4: What is the influence of the key hyper-parameters on FineRec? (ref. Section 6.5)\nRQ5: How well dose the proposed FineRec work in the real-world instance? (ref. Section 6.6)"}, {"title": "5.2 Datasets and Preprocessing", "content": "To scrutinize the effectiveness of our FineRec, we employ the following four popular public datasets in our experiments:\nCellphones, Beauty and Sports are three datasets covering different domains in Amazon. As widely used benchmarks for the sequential recommendation [7, 18], these datasets contain users' purchasing behavior sequences and corresponding user-item reviews.\nYelp containing users' reviews for restaurants is a popular dataset used in the task [7, 23]. As in [23, 24], we retain the transaction records of the year 2019 in this dataset.\nFollowing [13, 16, 18, 30], we apply the 5-core method to preprocess these datasets, where items and users with less than 5 interactions are filtered out. Besides, to fairly examine the impact of finely-grained modeling, we eliminate reviews that fail to mention the attributes included in the attribute list $\\mathcal{A}$. In line with common practices [17, 47], leave-one-out operation is used to split these datasets, where the last item in a sequence is used for testing, the penultimate item for validation, and the remaining for training. We present the statistical details of all four datasets in Table 1."}, {"title": "5.3 Evaluation Metrics", "content": "Following existing works [10, 18, 30, 47], we evaluate the performance of all methods with following two metrics:\nPrec@k: Precision measures the proportion of cases where the ground-truth item is within the recommendation list.\nNDCG@k: Normalized Discounted Cumulative Gain considers the rank of the ground truth item among the recommendation list.\nIt is worth noting that the Prec@k metric does not take into account the ranking of an item, as long as it appears within the top-k recommendations. Conversely, NDCG@k emphasizes the item rank, which is crucial in scenarios where the order of recommendations matters. In this study, we report the results with k = 10 and 20."}, {"title": "6 RESULTS AND ANALYSIS", "content": ""}, {"title": "6.1 Overall Performance (RQ1)", "content": "The performance of all baselines and FineRec on four datasets is detailed in Table 3, where we can obtain the following insights:\nFirstly, the performance of baselines varies greatly across different datasets. Taking the ACTSR as an example, it shows best results among all baselines in Prec metric on Cellphones, while obtaining inferior performance in other contexts. Similarly, SASRec excels on Beauty dataset but performs poorly on others. These facts signify the complexity and difficulty of the sequential recommendation task, which requires capturing users' evolving interests from their historical behaviors. Moreover, most existing methods handle the task in an implicit way, primarily focusing on users' implicit clicking behaviors. Such a manner, unfortunately, often"}, {"title": "", "content": "fails to grasp user genuine intents, thereby significantly limiting their effectiveness.\nSecondly, RNS, as a representative work incorporating reviews into SR, exhibits competitive performance in certain scenarios, i.e., with the NDCG metric in Cellphones and Sports. Instead of modeling implicit user actions, RNS explicitly mines user interests from their reviews, enhancing its grasp of user intents. Nevertheless, its performance is less satisfactory on the Beauty and Yelp datasets. The primary drawback of RNS lies in its coarse paradigm for modeling a review as a whole. Indiscriminately blending distinct attitudes towards various attributes within a single review, RNS struggles to capture a user's specific preferences for each attribute. This leads to its inconsistent performance across different datasets.\nThirdly, the most recent approaches, namely MCLRec and ACTSR, generally outperform other baselines. Their impressive performance could be largely attributed to their utilization of cutting-edge techniques. Specifically, MCLRec leverages meta-optimized contrastive learning to enrich user behavior data. As to ACTSR, it calibrates attention weights within Transformer architectures to better adapt to the task. However, despite equipping with advanced techniques, these methods are unable to obtain consistent performance across various contexts. This once again suggests the limitations of implicit manner for modeling user behaviors in the task of sequential recommendation.\nFinally, the proposed FineRec achieves consistent improvements over all baselines in terms of all metrics on all datasets, which demonstrates its effectiveness for sequential recommendation. In particular, FineRec outperforms the best baselines in Prec@20 and NDCG@20 by 34.50% and 25.33% on Cellphones, 16.65% and 34.64% on Beauty, 22.75% and 40.24% on Sports, and 15.37% and 22.19% on Yelp. We believe that the consistent superiority of FineRec over current start-of-the-art methods comes from its fine-grained manner in handling the task. Benefiting from finely representing users and items via attribute-opinions, FineRec can identify fine-grained user preferences and item characteristics on various attributes. This manner enhances the prediction accuracy, significantly contributing to the overall effectiveness of the proposed FineRec."}, {"title": "6.2 The effect of fine-grained manner for handling SR (RQ2)", "content": "The key innovation of our FineRec lies in its fine-grained manner in handling SR, achieved via exploring attribute-opinions from user-item reviews. In order to validate the effectiveness of this novel paradigm, the following variants of FineRec are designed: \"FineReccoa\" builds a single user-review-item graph based on the entire user-item interactions. In this graph, users and items form the nodes, and their reviews serve as the edges. That is, FineReccoa coarsely models a review as a whole, without distinguishing users' various opinions on different attributes. Besides, \"FineRec-opin\" creates an attribute-specific user-item graph for each attribute, without considering the related opinions between users and items. It relies on the conventional GCN to update user and item embeddings under each attribute.\nFrom Figure 3, we can obtain the following key points: (1) FineRec-opin achieves better performance than FineReccoa. It underscores the rationality of building distinct attribute-specific subgraphs for various attributes. This distinction aligns with the fact that users exhibit varied preferences and items display different characteristics across various attributes. By recognizing these differences, FineRec-opin obtains improvements over FineReccoa; (2) FineRec-opin is defeated by FineRec with a large margin, which highlights the significance of jointly exploring attributes and opinions. For an attribute, users may express completely different attitudes. Thus, only considering attributes while ignoring corresponding opinions, FineRec-opin fails to make accurate predictions; and (3) The FineRec surpasses both its variants in all cases, validating the efficacy of our fine-grained manner in handling the task. By delving into the attribute-opinions within reviews, FineRec is able to uncover user preferences and item characteristics, significantly improving the recommendation performance."}, {"title": "6.3 The effect of diversity-aware convolution operation (RQ3)", "content": "To tackle the opinion diversity issue in fine-grained user and item representation learning, we introduce a diversity-aware convolution operation. The variant \"w/o diver\" discards the diversity-aware convolution operation. Instead, it employs a straightforward approach by summing all adjacent opinion embeddings and item/user embeddings to update the user/item embeddings. That is, it omits the diversity of opinions. Additionally, we include the results of the best-performing baselines for each metric to provide a comprehensive comparison.\nTable 4 clearly shows that FineRec consistently outperforms the \"w/o diver\" variant in all scenarios. It demonstrates the effectiveness of our specially devised diversity-aware convolution operation. By focusing on the diversity of opinions in user/item representation learning, this operation achieves two critical objectives: (1) grasping user varying opinions on distinct items, and (2) providing comprehensive portrayal of item characteristics based on various user opinions. Consequently, this operation enables FineRec to obtain robust user/item representations under each attribute. In addition, the underperformance of the best baselines compared to the \"w/o diver\" variant further indicates the efficiency of our fine-grained manner in tackling sequential recommendation."}, {"title": "6.4 The effect of interaction-driven fusion mechanism (RQ3)", "content": "To comprehensively understand user behaviors, we present an interaction-driven fusion mechanism that integrates user/item representations across all attributes. This mechanism employs informative user-item interactions to guide the fusion of attribute-specific user/item embeddings. In contrast, the FineReccat variant employs a conventional approach for the fusion. It concatenates the embeddings from different attributes and then merges them using a Multi-Layer Perception (MLP), bypassing our specialized fusion mechanism.\nAs can be observed from Figure 4, FineRec achieves better performance over FineReccat. It validates the effectiveness of our interaction-driven fusion mechanism in integrating attribute-specific embeddings. We believe that the user-item interactions reflect the relationships, notably the similarity at the embedding-level, between users and items. By harnessing these similarities, the designed fusion mechanism gains a deeper understanding of how various attributes influence user behaviors. Therefore, the proposed mechanism facilitates an effective fusion process, thereby establishing the superiority of FineRec over FineReccat."}, {"title": "6.5 Hyper-parameter Study (RQ4)", "content": "In this section, we investigate the influence of the main hyper-parameter $d$ on FineRec's performance. Parameter $d$ denotes the dimension of attribute embeddings, opinion embeddings, as well as attribute-specific user/item embeddings. The performance trends of FineRec across various $d$ values, evaluated using Prec@20 and NDCG@20 metrics on all datasets, are illustrated in Figure 5. The"}, {"title": "", "content": "performance curve reveals that as $d$ increases, FineRec initially shows improvements but eventually experiences a decline. This pattern suggests that while a larger $d$ enhances representation capability, leading to better performance, an excessively high $d$ might cause overfitting, thereby degrading performance. Interestingly, we find that a relatively small $d$ value suffices for optimal performance in FineRec, with $d$ set to 8 for Sports, and 16 for Cellphones, Beauty, as well as Yelp datasets. Our FineRec aims to capture specific user/item preferences/characteristics on each attribute, instead of indiscriminately modeling them as a whole like existing methods. Benefiting from such a fine-grained manner, FineRec can accurately represent users or items under each attribute at a low cost (i.e., a small number of embedding dimension). It is both efficient and effective. We believe that this merit of FineRec significantly enhances its practical applicability."}, {"title": "6.6 Case Study (RQ5)", "content": "In order to intuitively scrutinize the effects of FineRec in generating recommendations, we randomly select an instance from the dataset Sports. This real-world case is presented in Figure 6, where we detail a user's historically interacted items, reviews he posted for each item, the attribute-opinion pairs extracted using LLM, and the ground truth item. Additionally, we display recommended items from FineRec at the low part of the figure. For these recommended items, we include three reviews written by other users, along with their respective attribute-opinion pairs. Due to space constraints, we present the top-3 recommended items of FineRec."}, {"title": "", "content": "The following"}]}