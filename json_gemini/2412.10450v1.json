{"title": "Regional Weather Variable Predictions by Machine Learning with Near-Surface Observational and Atmospheric Numerical Data*", "authors": ["Yihe Zhang", "Bryce Turney", "Purushottam Sigdel", "Xu Yuan", "Eric Rappin", "Adrian L. Lago", "Sytske Kimball", "Li Chen", "Paul Darby", "Lu Peng", "Sercan Aygun", "Yazhou Tu", "M. Hassan Najafi", "Nian-Feng Tzeng"], "abstract": "Accurate and timely regional weather prediction is vital for sectors dependent on weather-related decisions. Traditional prediction methods, based on atmospheric equations, often struggle with coarse temporal resolutions and inaccuracies. This paper presents a novel machine learning (ML) model, called MiMa (short for Micro-Macro), that integrates both near-surface observational data from Kentucky Mesonet stations (collected every five minutes, known as Micro data) and hourly atmospheric numerical outputs (termed as Macro data) for fine-resolution weather forecasting. The MiMa model employs an encoder-decoder transformer structure, with two encoders for processing multivariate data from both datasets and a decoder for forecasting weather variables over short time horizons. Each instance of the MiMa model, called a modelet, predicts the values of a specific weather parameter at an individual Mesonet station. The approach is extended with Re-MiMa modelets, which are designed to predict weather variables at ungauged locations by training on multivariate data from a few representative stations in a region, tagged with their elevations. Re-MiMa (short for Regional-MiMa) can provide highly accurate predictions across an entire region, even in areas without observational stations. Experimental results show that MiMa significantly outperforms current models, with Re-MiMa offering precise short-term forecasts for ungauged locations, marking a significant advancement in weather forecasting accuracy and applicability.", "sections": [{"title": "I. INTRODUCTION", "content": "Accurate short-term weather predictions with fine temporal resolutions are crucial for sectors that depend on real-time weather-related decision-making, such as transportation, emergency response, solar farm operations, etc. However, current forecasting models, such as the Weather Research and Forecasting (WRF) model with High-Resolution Rapid Refresh (HRRR) [2], fall short of meeting these demands due to their coarse hourly outputs and high computational complexity. These models generate around 148 weather parameter values (i.e., variables) per hour over large geo-grids (e.g., 3 km \u00d7 3 km), with coarse temporal granularity (hourly forecasts) often deemed insufficient for applications requiring predictions in the interval of 5 or 15 minutes [3]. Additionally, a lack of near-surface observational data at tactical locations limits their accuracy.\nOn the other hand, regional Mesonet networks, such as the Kentucky Mesonet [4], provide real-time, location-specific weather data with fine temporal granularity (e.g., every five minutes). These networks operate under the U.S. National Mesonet Program [5] and consist of strategically located observational stations. The Kentucky Mesonet, for example, comprises over 70 stations for collecting values of some 22 weather parameters, including temperature, humidity, wind speed, pressure, and precipitation. This high-resolution dataset provides valuable micro-level data that can be leveraged to improve prediction accuracy (see Fig. 1 for station distribution).\nRecent advances in machine learning (ML) technology have propelled weather forecasting into a new era. Numerous studies have explored ML-centric techniques for weather forecasting, yielding promising results. These techniques include the deep neural networks (DNN), convolutional neural networks (CNN), long short-term memory networks (LSTM) [6], generative adversarial networks (GAN) [7], among others, for predicting values of such parameters as wind speed and direction [8], [9], [10], [11], solar radiation [12], [13], precipitation [14], [15], [16], [17], [18], air quality [19], weather changes [20], [21], [22], [23], etc. However, existing ML forecasting models have not yet achieved accurate predictions of weather variables at fine temporal resolutions (as seen with recent transformer-variant forecasters like [24], [25], [26], [27]). This shortcoming is largely due to the lack of geolocation-aligned ground observational data, which is essential for enhancing model training and prediction accuracy. Many models rely solely on satellite or radar images [28], limiting their precision. Additionally, most neural network-based models are designed to predict values of specific parameters, lacking a generalizable framework that can be readily adapted to forecast all parameters of interest.\nTo address these shortcomings, this paper introduces the MiMa model, a novel ML-based approach that integrates fine-grained observational data (Micro data) from regional Mesonet stations with larger-scale numerical outputs (macro data) from the WRF-HRRR model [3]. This integration enables accurate weather predictions over short time horizons (in minutes) for a region of interest. The MiMa model employs an encoder-decoder transformer architecture, where two encoders process multivariate sequences from the micro and the macro datasets, and a decoder forecasts the values of multiple weather parameters across a sequence of time points from t+1 to t+L (see Fig. 2).\nEach instance of the MiMa model is referred to as a modelet, dedicated to predicting a specific weather variable for an individual Mesonet station. To further enhance its utility, the MiMa model is extended to become Regional MiMa (Re-MiMa) modelets, which can predict weather variables at ungauged locations (where no observational stations exist). By using data from several representative stations in a region of interest, typically 3 or 4, tagged with their elevations, Re-MiMa modelets can generalize predictions across an entire region, providing accurate forecasts at both gauged and ungauged locations. This extension addresses a long-standing challenge in meteorological forecasting: accurate predictions at locations without direct observational data.\nWe conducted experiments on weather forecasting at various Kentucky Mesonet stations, focusing on four key weather parameters: air temperature, relative humidity, wind speed, and atmospheric pressure, across eleven stations (Figure 1).\nThe MiMa modelets consistently outperform all comparative techniques, achieving the lowest RMSE (Root Mean Squared Error) values in 39 out of 44 forecasting instances (Table VI. Additionally, Re-MiMa modelets, trained using data from three representative stations in eastern Kentucky (BMTN, FARM, and DANV), were tested at eight ungauged stations. The results show that Re-MiMa modelets predicted weather variables with accuracy comparable to, or better than, location-specific MiMa modelets, with 22 out of 32 parameters at those ungauged locations predicted more accurately (see Table X). This demonstrates the effectiveness of Re-MiMa in avoiding the need for multiple modelets for predicting a given variable while maintaining high accuracy across the entire region.\nIn summary, the MiMa model integrates micro and macro data to deliver precise weather predictions at fine temporal resolutions. The Re-MiMa extension further enhances its regional forecasting capability, making it a versatile tool for applications that require high-accuracy predictions in real-time. The MiMa model code, documentation, and datasets are made publicly available at [29] for further research and applications to other regions.\nThis paper makes several key contributions:\n\u2022 Novel Weather Prediction Model (MiMa). We introduce the MiMa model, a machine learning framework designed to predict weather parameters at fine temporal resolutions accurately. The model integrates high-frequency observational data (Micro data) with geo-aligned atmospheric numerical outputs (macro data) to provide accurate short-term weather forecasts.\n\u2022 Adaptable Prediction for Arbitrary Lead Times. The MiMa model employs an encoder-decoder architecture with LSTM units, allowing it to handle arbitrary lead times and forecast weather variables with fine temporal granularity, such as 5- or 15-minute intervals, meeting real-world demands for high-resolution weather forecasts."}, {"title": "Regional MiMa (Re-MiMa)", "content": "We extend the MiMa model by introducing Re-MiMa modelets, which enable accurate weather forecasting at ungauged locations (where no observational stations exist). Re-MiMa uses observational data from a small number of representative stations, avoiding the need for location-specific models while maintaining high prediction accuracy across a region."}, {"title": "Reduction in Modelet Count", "content": "By utilizing transfer learning and data from representative stations, Re-MiMa reduces the number of required modelets, achieving accurate regional forecasts using one single modelet per weather variable, compared to traditional approaches requiring individual modelets for each location."}, {"title": "Comprehensive Evaluation", "content": "Our experimental evaluation across multiple Kentucky Mesonet stations demonstrates that MiMa and Re-MiMa significantly outperform their counterparts in forecasting accuracy for multiple weather parameters, including temperature, humidity, wind speed, and pressure. Re-MiMa models achieve high accuracy at ungauged locations, further validating their effectiveness and boosting their usability."}, {"title": "Data and Code Availability", "content": "To facilitate further research and reproducibility, we have made the MiMa model code, documentation, and datasets available at [29], enabling other researchers to apply our approach to different regions and weather forecasting tasks."}, {"title": "II. RELATED WORK", "content": "Abundant applications of ML techniques for weather forecasting exist. This section reviews the recent advances in such applications, which mostly follow three lines of work."}, {"title": "A. Neural Networks for Simulating Atmospheric Systems", "content": "The first line aims to explore whether NNs can simulate the physical principles of atmosphere systems. In particular, a Global NN and a Local NN are employed in [30] to simulate the dynamics of a simple global atmosphere model at 500 hPa geopotential. The results conclude that prediction outcomes by the NN models can be better than those of the coarse-resolution atmosphere models over a short duration with the 1-hour time scale. Scher [31] applied the CNN structure with an AutoEncoder to learn the simplified general circulation models (GCMs), which can predict the weather variables for up to 14 days. The CNN incorporating LSTM components was leveraged in [32] to achieve 14-day lead time forecasting as well. Vlachas et al. [33] employed the LSTM model to reduce the order space of a chaotic system. However, known solutions along this line of work all focused on developing prediction models for simulated or simplified climate environments, without taking into account real-world conditions like observed weather parameters at a region of interest. Their applicability and effectiveness in real environments are questionable, given the complex real-world conditions in practice. For example, the actual measurements from Mesonet stations are highly dependent on local conditions. In addition, their solutions cannot make accurate fine-grained forecasts (e.g., in the 5- or 15-minute resolution) over short horizons (for one or two hours) flexibly."}, {"title": "B. Neural Networks for Real-World Weather Prediction", "content": "The second line of work pursues new NN models for the real-world weather parameters prediction. For example, the LSTM and fully connected NNs are leveraged in [11] to predict the wind speed at an offshore site, by capturing its rapidly changing features. Grover et al. [20] combined the discriminatively trained predictive models with a DNN (Deep NN) to predict the atmospheric pressure, temperature, wind speed, and dew point. A convolutional LSTM model was adopted in [14] to predict precipitation, whereas the CNN with a stack of delicately selected frames was employed in [16] for precipitation forecasting. In addition, a model with the AutoEncoder structure was proposed to predict rain-fall [15]. Forecasting the hurricane trajectories via a Recurrent NN structure was considered in [10]. The LSTM structures were employed in [12] and [13] to predict solar radiation and photovoltaic energy, respectively. [19] proposed a deep fusion network to predict air quality. [34] crafted a storm event imagery dataset while leveraging the VGG16 model to analyze storm events. U-net models [35] were considered in [36], [37] for fine-grained radar nowcasting. A deep CNN model was developed over a cubed sphere [21] for predicting several basic atmospheric variables on a global grid. In [38], the DeepMC model with attention mechanisms was proposed to predict micro climate. A near real-time hurricane rainfall forecasting model was proposed in [17], where a basic CNN model inputted with the integrated IMERG dataset was leveraged. In [23], basic machine learning and data mining algorithms were developed for forecasting the reservoir release. Recently, a lightweight model inputted with satellite and radar images for real-world storm prediction has been treated [39]. Meanwhile, a nonlinear nowcasting model under a neural network framework has been proposed for precipitation forecasting based on composite radar observations to exhibit more accurate and instructive outcomes than other deep-learning methods [40]."}, {"title": "C. Transformer-based Models for Long-term Weather Forecasting", "content": "As the third line of work, various transformer-based solutions have been developed for long time-series predictions, including weather forecasting but in coarse resolutions. Specifically, Autoformer [24] performs weather forecasting in the daily resolution, whereas FEDformer [25] evaluates the predictions of weather time-series data for the hourly resolution. Likewise, the Corrformer model [26] forecasts weather conditions over a large number of stations in coarse granularity temporally, FourCastNet [27] considers weather predictions at the temporal resolution of 6 hours, and the iTransformer model [41] makes long-term weather forecasting in the range of 96 hours to 720 hours at the hourly resolution.\nLately, general circulation models for weather and climate by combining atmospheric physics with machine learning have aimed at the daily (or longer) resolution coarsely over medium range (1-14 days) time horizons [42], which are also the target of the recently published global weather forecasting benchmark [43]. All aforementioned solutions are not meant to predict weather parameters accurately in fine temporal granularity (in minutes) over flexible time horizons and lead times, hence calling for accurate weather forecasting with fine-grained temporal resolutions."}, {"title": "D. Station Forecasting", "content": "The fourth line of work explores weather forecasting with several thousand weather stations as input to a forecasting model. Specifically, the Weather-5k dataset [44] presents a reliable and robust collection of over 5000 individual weather stations for evaluating multiple crucial weather elements. In addition to datasets like Weather-5k, recent advances focus on improving the accuracy of weather predictions at specific station locations through advanced downscaling techniques. A notable contribution in this area is the introduction of station-scale downscaling [45], which directly derives accurate meteorological states at station locations from coarse-resolution meteorological fields. Moreover, an innovative hybrid approach, DeepPhysiNet [46], integrates physical laws into deep learning models to enhance weather prediction accuracy. The aforementioned pursuits, however, lack predictions at fine-grained temporal resolutions, made possible only by employing near-surface parameter readings gathered with high temporal resolutions via weather stations plus geo-aligned numerical WRF-HRRR outputs."}, {"title": "E. MiMa and Re-MiMa: Fine-Grained Weather Prediction", "content": "With encoder-decoder transformer-variant structures, our MiMa and Re-MiMa modelets, for the first time, achieve accurate predictions with short time horizons in fine temporal resolutions on all weather variables at locations in a target region, realized by (1) tailoring a modelet for one variable prediction per location (or per region) under MiMa (or Re-MiMa), and (2) taking both near-surface observational and atmospheric numerical multi-variate data as their inputs, and (3) letting modelets' encoders input suitable data (including predicted outcomes) for encoding adaptively."}, {"title": "III. PERTINENT BACKGROUND", "content": "This section first explains near-surface observations conducted by Mesonet stations [4], followed by describing the WRF-HRRR (Weather Research and Forecasting with High-Resolution Rapid Refresh) computational model [47]. The limitations of applying such datasets for weather forecasting are then stated."}, {"title": "Kentucky Mesonet", "content": "Under the U.S. National Mesonet Program, this Mesonet comprises a set of automated weather stations (towers) located at specific locations in the State of Kentucky, as marked by yellow circles in Fig. 1. Its towers aim to gather real-time meteorological and soil measurements relevant to local weather phenomena, involving tens of meteorological measurements, such as air temperature, relative humidity, wind speed, atmospheric pressure, and precipitation, among others, periodically [4]. Meteorological measurements are gathered once in five minutes, whereas soil measurements are taken once in 15 or 30 minutes."}, {"title": "WRF with HRRR modeling", "content": "The WRF model takes actual atmospheric conditions (mainly from satellite, ground radar imagery, METAR, SYNOP, Sonde, etc) as the input of atmosphere physical equations to calculate numerical outputs that serve a wide range of meteorological applications across the nation. The WRF-HRRR model is the ARW core [48] simulation results of the WRF model [49] initialized by the HRRR assimilating system [47]. It takes multiple sources as inputs, including radar reflectivity and observations [50] related to rawinsonde, boundary layer, cloud, precipitation processes, etc. It computes up to 148 weather parameters over the 18-hour time horizon in hourly increments with the spatial resolution of 3-km and across 50 vertical levels. In this work, we take the HRRR assimilated results archived in the University of Utah for public use, and those results cover the whole United States continent with a total of 1059 \u00d7 1799 geo-grids sized 3km \u00d7 3km [2]. On July 12, 2018, the HRRR implementation Version 2 was upgraded to Version 3, with some changes to parameters; please refer to [51] for more details. Every parameter selected for our evaluation exists in both versions. To obtain the WRF-HRRR data that are geo-aligned with ground observational stations (in a mesonet) for MiMa modelet training, each involved hourly WRF-HRRR data file (sized 120MB) has to be preprocessed, given that those hourly parameter values of all geo-grids over the US continent are compressed to one single file for efficient transfer and storage. Preprocessing an hourly data file takes about 2 minutes by one Dell server in our lab and modelet training needs WRF-HRRR computed parameters held in thousands of such files, deemed a rather time-consuming task, as detailed under \"WRF-HRRR Data Preprocessing\" in Section V-A."}, {"title": "Limitations", "content": "Both Mesonet and WRF-HRRR datasets have their respective limitations. Specifically, the mesonet dataset contains near-surface weather measurements gathered continuously by stations with various sensors and devices in minutes. However, it does not provide forecasting results and involves only tens of observation parameters. It can serve as the ground truth for ML model training but is unable to reveal future weather parameter values by itself. The WRF-HRRR numerical outputs cover the whole US at hourly granularity, but they usually suffer from considerable inaccuracy at geo-grids of interest. Besides, its hourly prediction scale limits its suitability for meteorological applications that require high temporal resolutions (in minutes) in support of real-time decision-making. With affluent weather parameters (i.e., 148 or 192), the WRF-HRRR data can be inputted into our prediction modelets for complementing Mesonet observational data.\nOur developed prediction modelets take multivariate time series systematically chosen from both datasets as their inputs to complement each other for accurate prediction in fine temporal resolutions. As such, WRF-HRRR can provide affluent weather condition information while Mesonet stations gather accurate ground observations. Utilizing both of them (in our developed modelets) properly enables precise weather forecasting in fine-grained temporal resolutions."}, {"title": "IV. ML-BASED MODELS FOR WEATHER FORECASTING", "content": "The MiMa meteorological model utilizes Meteo modelets to accurately and concurrently predict weather variables with fine temporal resolution. These modelets are fed with minute-level near-surface observational data (the micro dataset) and hourly atmospheric numerical outputs from WRF-HRRR modeling (the macro dataset). Each Meteo modelet is specifically designed to predict a single weather parameter at a location where observational data is available. For each predicted parameter, two subsets of input parameters are selected: one from the micro dataset and the other from the macro dataset. These subsets are chosen based on their relevance levels with respect to the weather parameter being predicted, as detailed in Section V-A. The primary objective of the modelet design is to extract temporal variation features from relevant sequences of previous measurements to accurately predict weather parameter values at multiple consecutive future time points (say, in T minutes, 2T minutes, 3T minutes, etc.). This is achieved by leveraging advanced ML techniques to learn temporal sequence patterns from both datasets, capturing weather-situational variations essential for predicting specific parameters. The Meteo modelets deliver precise weather forecasts for a target region at desirable temporal resolutions. Before detailing the configuration of the MiMa modelets, we first describe a micro model that relies solely on the micro dataset for its predictions, as below."}, {"title": "A. Micro Model", "content": "Most atmospheric data exhibit noticeable temporal sequences and periodic patterns, with weather conditions continuously changing over time. To capture these patterns for forecasting in consecutive future time points, an Encoder-Decoder structure with the Long Short-Term Memory (LSTM) network [6] as its building block to capture the temporal and periodic patterns, as depicted in Fig. 3. Although the encoder-decoder LSTM model has been widely applied to sequence tasks such as language translation and question answering, the physical meaning of each element in the input vectors is not well-explored. Hence, the encoder's LSTM is detailed next, enabling it to keep rich element-wise features when encoding all features into a dense vector."}, {"title": "Micro Encoder", "content": "The Micro Encoder consists of an LSTM unit designed to encode appropriate multivariate time series of data over a specific period into a single dense vector, representing their temporal feature variations. The input to this encoder, $X_{micro}$, is a matrix of the most relevant parameter values at each timestamp, defined as follows:\n$X_{micro} = \\begin{bmatrix}\nP_1^1 & P_1^2 & ... & P_1^{\\alpha} \\\\\nP_2^1 & P_2^2 & ... & P_2^{\\alpha} \\\\\n... & ... & ... & ... \\\\\nP_n^1 & P_n^2 & ... & P_n^{\\alpha}\\end{bmatrix}$,\nwhere the ith row, for 1 < i < n, represents those \u03b1 most relevant parameters chosen from the micro dataset at the ith timestep of the multivariate time series data observed at a station to train the model for the station's location. These n time steps constitute the lookback window for predicting the results of future time points over a horizon, where the time gap between the lookback window and the prediction horizon is known as the lead time. The past T \u00d7 n-minute surface observational data points from the a time series gathered by the station are taken as a data frame ($X_{micro}$) representing an observed weather snapshot as the model input. In the ablation study (Section V-D), results under different lookback windows are provided and discussed. After inputting the data of $X_{micro}$ to the Micro Encoder, a hidden state vector of size n \u00d7 128 is obtained. During the training, the exact hidden state vector size is 128 x 128, under the mini-batch size of 64. Concatenation of the hidden and cell states lead to the resulting hidden state vector size of 128 x 128. The LSTM unit learns key features and updates its associated hidden state vector. This vector, along with the next data frame, is input to the same LSTM unit to update the hidden state vector $H_t$, expressed by:\n$H_t = \\sigma(X_{micro}W_{xo} + H_{t-1}W_{ho} + b_o) \u00d7 tanh (C_t)$, (1)\nwhere $W_{xo}$ are the output weights for the input $X_{micro}$, $H_{t-1}$ is the hidden state vector from the previous timestamp, $W_{ho}$ are the output weights for the hidden state, $b_o$ is the bias for the output, $C_t$ is the cell state of the LSTM unit, and \u03c3 denotes the sigmoid activation function and tanh is the hyperbolic tangent [6]. Initially, the hidden state vector without a prior state, is initialized randomly. The final dense vector $H_t$ aggregates temporal pattern variations from the inputs $X_{micro}$'s of n timestamps."}, {"title": "Decoder", "content": "The Decoder predicts specific weather parameter values for consecutive time points over the given horizon after a lead time, if any. Including an LSTM nuit, the Decoder, initialized by the dense vector $H_t$, also takes the starting value of the sequence, $Y_o$, as its input to generate the output vector $O_{t+1}$, denoted as:\n$O_{t+1} = \\sigma(Y_oW_{xo} + H_t W_{ho} + b_o)$, (2)\nwhere the weight and bias variables are similar to those given in Eq. (1). This output vector is passed to a fully connected network to obtain the forecast value of $Y_{t+1}$, expressed by:\n$Y_{t+1} = \\sigma(O_{t+1} W_{out} + b_{out})$, (3)\nwhere $W_{out}$ are the weights of the fully connected network, and $b_{out}$ is the bias.\nDuring training, multivariate data sequences from a station are inputted in batches, with each training pass learned from appropriate sequences of n values (e.g., 12 values for 1 hour of data at 5-minute intervals). For temperature prediction, as an instance, the modelet is inputted with the last hour's worth of most relevant parameter data in batches to predict the temperature 5 minutes immediately after, when the lead time is nil. During inference, the model generates a sequence of n values by the decoder, one at a time iteratively. For improved accuracy, the encoder inputs suitable data (including predicted values) for encoding before n iterations end."}, {"title": "B. MiMa Model", "content": "Given that the number of weather parameters observed by Mesonet stations is limited and primarily indicates current near-surface readings without forward-looking information, forecasting based solely on the micro dataset is insufficient. The WRF-HRRR computed outputs (the Macro dataset) include atmospheric indicators at higher altitudes (e.g., 700/925 hPa geopotential height, low cloud cover, 3000m storm-relative helicity, etc.), as listed in Table V. They are useful for inferring future weather conditions near the surface. Thus, incorporating appropriately selected WRF-HRRR outputs into the model training process significantly enhances prediction accuracy, arriving at the MiMa model. Our proposed MiMa model takes the macro dataset as a complementary input to improve forecasting.\nThe macro dataset is generated on an hourly basis [47], whereas surface observational data are collected every five minutes by Kentucky Mesonet stations. The MiMa model is obtained by adding a Macro Encoder to the Micro model (depicted in Fig. 3) to integrate these two data sources with different temporal scales. Comprising a single LSTM unit, the Macro Encoder takes as its input, the geo-aligned WRF-HRRR data which are most relevant to the weather parameter under prediction (e.g., air temperature, relative humidity, etc.; see Table II). \nThe subset of WRF-HRRR data chosen for a predicted weather parameter is based on parameter relevance degrees, as detailed in Section V-A. Since the Macro dataset and the Micro dataset are on different time scales, inputs to the Macro Encoder must be temporally downscaled from one hour to T-minutes (being the Mesonet station data sampling interval). Each hour is divided into 60/T time frames, using the hourly output from the Macro dataset to represent the first time frame's value. Values for the remaining time frames are computed using a polynomial function fitted to the last l output parameter data points, with l = 3. The polynomial a*x\u00b2+bx+c is used, fitting the immediate last three hourly WRF-HRRR computed values to find the best coefficients a, b, and c for extrapolating the future 60/T - 1 values at T-minutes intervals. This process is applied to every computed parameter listed in Table V, with their respective time frame populated according to the polynomial function.\nThe most relevant parameters from the Micro dataset (or the Macro dataset) for each predicted parameter are listed in Table III (or Table IV). In addition to the Micro encoder input $X_{micro}$, the Macro encoder input $X_{macro}$ is given by \n$X_{macro} = \\begin{bmatrix}\nP_1^{\\beta_1} & P_1^{\\beta_2} & ... & P_1^{\\beta_n} \\\\\nP_2^{\\beta_1} & P_2^{\\beta_2} & ... & P_2^{\\beta_n} \\\\\n... & ... & ... & ... \\\\\nP_n^{\\beta_1} & P_n^{\\beta_2} & ... & P_n^{\\beta_n}\\end{bmatrix}$,\nwhere the ith row, for 1 < i < n, denotes those \u03b2 most relevant parameters from the WRF-HRRR dataset, for the lookback window of n steps and the prediction horizon of T\u00d7 n minutes when the time step equals T minutes. Comprising an LSTM unit, the Macro Encoder takes its input $X_{macro}$ along with the hidden state vector from the previous time frame, to update its hidden state vector. It outputs a dense vector, $H_{t, macro}$, which is concatenated with the dense vector outputted from the Micro Encoder, $H_{t,micro}$, (as shown in Fig. 4) to produce the vector of $H_{t, merged}$:\n$H_{t,merged} = concat(H_{t,micro}, H_{t,macro})$. (4)\nThe decoder in the MiMa model functions similarly to that in the Micro model, and its output is expressed by Eq. (2), with $H_t$ replaced by $H_{t,merged}$. It is initialized by the concatenated dense vector $H_{t, merged}$ to start forecasting for consecutive time points sequentially. During both training and prediction phases, the MiMa model utilizes the WRF-HRRR numerical data from the geo-grid where the observational station resides (known as spatial alignment) over the same time duration (known as temporal alignments). Note that while our MiMa model is encoder-decoder structured, its encoders are made to consider prediction outcomes adaptively, based on prediction errors observed at model validation immediately after training. This way allows the MiMa modelets to encode input data frames over the look-back window more frequently to lower their prediction error during inference, at the expense of longer inference times (in a few seconds, rather than tens of us with just the decoder involved in predictions).\nNote that our proposed MiMa model, built on the LSTM-based encoder-decoder architecture, exhibits very high accuracy in predicting weather variables over the short time horizons of our interest (up to a few hours, as demonstrated in the next section). Its high accuracy results mainly from inputting geo-aligned Micro and Macro data at the same time. When the prediction horizons are long (say, tens of hours), different model structures, like transformers with attention [52], may be called for. A model built on the transformer with attention, however, typically requires a large amount of data for model training to have quality models with high prediction accuracy. For our weather forecasting, we employ small datasets (over two years), making it unsuitable to adopt any transformer-based model with attention."}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "This section provides evaluation specifics, performance results and discussion, ensemble predictions, ablation studies, and extreme weather forecasting. Evaluation specifics include dataset details, parameter-relevant degree calculation, WRF-HRRR data preprocessing, and experiment setup details. Performance results are shown (1) for different prediction methods under prediction horizons of 1 hour and 24 hours and (2) for MiMa modelets with the prediction lead times of 1 hour and 4 hours for the 3-hour horizon."}, {"title": "A. Evaluation Specifics", "content": "Dataset Details. Two types of datasets are inputted to the Meteo Modelets we developed for performance evaluation, including the near-surface observational data gathered by Kentucky Mesonet [4] and the WRF-HRRR [3] atmospheric numerical values, called respectively Micro and Macro datasets because the former (or latter) data are available in 5-minute (hourly) temporal granularity. The Micro data comprise a set of weather parameters gathered by Mesonet stations for monitoring real-time meteorological phenomena, as shown in Fig. 1, where stations are signified by yellow circles. The monitored weather parameters include the readings of air temperature, relative humidity, wind speed, and atmospheric pressure, among others, at various heights, recorded once every 5 minutes, as opposed to the WRF-HRRR computed atmospheric values available hourly. Eleven Kentucky Mesonet stations are selected for evaluating MiMa models, with their geographical locations denoted in Fig. 1 by red line segments. Four meteorological parameters of interest considered at each Mesonet station for model performance evaluation are listed, with their respective measuring heights and reading ranges included. The parameters of WSPD and PRES are measured respectively at 10m and 1.0m, whereas the remaining two are measured at 2.0m. In the case of the individually trained MiMa modelets, there are 44 (= 4 \u00d7 11) MiMa modelets involved. Each modelet is trained by inputting both the ground observational data gathered during, and WRF-HRRR atmospheric data computed for, Years 2018 and 2019, while tested via the data of Year 2020. The WRF-HRRR macro data employed are those corresponding to the 3-km by 3-km geo-grids of the eleven Kentucky Mesonet stations. There are 148 WRF-HRRR parameters computed for each geo-grid per hour, but only a few of them are relevant enough to a given parameter under prediction (say, TEMP) for consideration in its dedicated MiMa modelet. Similarly, each mesonet station gathers some 22 weather parameters periodically (mostly once per five minutes), with a few of them strongly relevant to the predicted parameter. The following describes a systematic way for identifying the relevant degrees of all parameters with respect to a predicted parameter under one dataset so that such identified relevant degrees permit each MiMa modelet to include a suitable set of strongly relevant parameters for superior prediction performance after training."}, {"title": "Parameter Relevance", "content": "Weather parameter prediction by ML belongs to high-dimensional multivariate data analytics, with its performance dictated by involved dimensional features (i.e., parameters in the weather prediction context). Although selecting a proper set of parameters is challenging, it is an essential step in data preprocessing for removing irrelevant and redundant data to reduce time complexity and improve learning accuracy for the ML model at hand. In essence, this step involves identifying relevant degrees of all parameters with respect to a given parameter, so that the model takes into account only those parameters with high enough relevant degrees when predicting its target parameter. Typically, each parameter under prediction involves a different subset of parameters with high enough relevant degrees under a given dataset (be the near-surface gathered or the WRF-HRRR computed one), as listed in Tables III and IV. The subset of relevant parameters chosen for consideration in predicting a given parameter, however, is found to be identical at all geo-grids across a regional area. Hence, only one subset of relevant parameters is chosen systematically for each predicted parameter under the given dataset, irrespective of geo-grids where mesonet stations reside. A description of relevant WRF-HRRR parameters considered by prediction models is given in Table V.\nGenerally, two systematic approaches for choosing appropriate subsets of relevant parameters are wrapper and filter solutions. The former exhaustively searches all possible subsets of the parameters (i.e., dimensional features) to optimize the solution for a specific ML model. Such an exhaustive search-based method is known to be NP-hard, involving infeasibly high time complexity when the problem size is large (like the WRF-HRRR dataset with 148 parameters). In contrast, the latter usually applies a statistical method to determine a suboptimal solution with a feasible time, avoiding exhaustive search. An early filter solution based on the statistical method is realized by computing correlation coefficients among parameters"}]}