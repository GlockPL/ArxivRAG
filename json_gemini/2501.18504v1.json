{"title": "CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction", "authors": ["Peter J. Bentley", "Soo Ling Lim", "Fuyuki Ishikawa"], "abstract": "Large Language Model (LLM) image recognition is a powerful tool for extracting data from images, but accuracy depends on providing sufficient cues in the prompt requiring a domain expert for specialized tasks. We introduce Cue Learning using Evolution for Accurate Recognition (CLEAR), which uses a combination of LLMs and evolutionary computation to generate and optimize cues such that recognition of specialized features in images is improved. It achieves this by auto-generating a novel domain-specific representation and then using it to optimize suitable textual cues with a genetic algorithm. We apply CLEAR to the real-world task of identifying sustainability data from interior and exterior images of buildings. We investigate the effects of using a variable-length representation compared to fixed-length and show how LLM consistency can be improved by refactoring from categorical to real-valued estimates. We show that CLEAR enables higher accuracy compared to expert human recognition and human-authored prompts in every task with error rates improved by up to two orders of magnitude and an ablation study evincing solution concision.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) are the leading approach today for image interpretation [1]. With appropriate prompts, LLMs trained on images and text can generate detailed textual descriptions of new images. This enables a new type of application: using LLMs to extract meaningful data from images. In e-commerce applications this might be to extract implicit attributes from a product image to improve search and user experience [2]. In medical applications this might be to describe the type of skin lesion an in attempt to identify melanoma early [3]. Here we focus on a new real-world application: the identification of sustainability data from images of buildings.\nAs the world becomes increasingly aware of the challenges presented by global warming, there is an urgent need to understand our existing buildings so that we can upgrade them to be more sustainable [4]. This is the challenge posed by our industrial partner, TheSqua.re Group a global accommodation marketplace specializing in medium-term rentals all over the world. They have five data items of interest: building age, lighting, heating, windows, energy. Determining building age is often helpful to estimate likely construction methods and details such as insulation [5]. They must find structures that have inefficient lighting and heating so that they can be upgraded. They need to identify buildings with inefficient single glazed windows so that the latest thermally efficient double or triple glazing can be installed [6]. An overall estimation of energy kWh/m\u00b2 enables the calculation of likely CO2 emissions - often requested by corporate customers when booking accommodation.\nIn some European countries, modern buildings might have such information readily available for some, but not all properties [7]. For much of the world there is simply no available data at all about buildings [7]. However, while precise sustainability or energy related data may be sparse or non-existent, photographs and satellite imagery are plentiful. In the rental industry, it is the norm to take regular photographs not just to list the properties, but also to act as evidence against inventory loss or damages. Our industrial partner holds thousands of such images.\nDespite having image data available, the task of prompting an LLM to extract the required data from images is non-trivial [8]. One cannot simply prompt the LLM to list architectural features relating to energy usage the answer is too generic and non-specific to be of value. Equally one cannot prompt the LLM to describe the type of heating or lighting from images we receive non-specific and generic estimates as results. For this application we need the LLM to behave as a detective. It must collate several distinct features and use them to make a judgement. For example, an older building in Europe could be estimated if one considers cues such as ceiling height, coving, fireplaces, construction material visible as brickwork and size of windows. But these cues would be very different for images in other regions of the world that do not share such architectural traditions and practices.\nSo how best to determine the cues required in prompts? Our industrial partner needs an approach that does not depend on expert domain knowledge for each country, for this is not scalable and may not be available. All necessary information must be derived from the building images or general knowledge within an LLM. This paper proposes the solution: Cue Learning using Evolution for Accurate Recognition (CLEAR), see Figure 1. CLEAR uses a combination of LLMs and evolutionary computation to generate and optimize cues such that recognition of specialized features in images is improved.\nThis work makes the following contributions:\n\u2022 Invention of the concept of prompt cues for LLMs.\n\u2022 Introduction of CLEAR: a novel approach for improving the performance of LLMs by optimizing cues.\n\u2022 Novel approach in EC that enables dynamic generation of representation for a genetic algorithm using LLMs.\n\u2022 Application of CLEAR to a challenging real-world task.\n\u2022 Demonstration of the effectiveness of CLEAR by comparison of our method with human-authored prompts and expert human evaluation.\n\u2022 In-depth analysis of the algorithm, providing evidence that variable length operators and non-categorical encoding provide the best results.\n\u2022 Demonstration that evolved solutions are coherent and concise through textual analysis and ablation studies.\nThe rest of the paper is organized as follows. We provide a background in the next section and give the method in Section 3. We describe empirical experiments in Section 4 and conclude in Section 5."}, {"title": "2 Background", "content": "The task of enhancing prompts is an area of extensive research, as generative systems are highly sensitive to exact wording, necessitating careful prompt engineering [9]. Techniques of improving prompts through text modifiers [10] or involving a human in the loop [11] are being developed.\nEvolutionary approaches have been used with LLMs in various areas, such as game level generation [12] and neural architecture search [13]. Previous research has demonstrated how an LLM can optimize an objective function through prompt optimization [14], and how LLMs can be used for crossover operations [15]. Researchers have also demonstrated the use of LLMs as a means of initialization, crossover and mutation to evolve prompts that are then used to generate architectural images [16].\nIn the area of vision models, there is increasing use of vision models to understand and extract data, e.g., using LLMs for chart understanding by converting data-filled visuals into textual summaries [17] and previous work using LLMs to extract data from images of buildings [8], which demonstrated that the performance of LLMs in such scenarios are sensitive to the exact prompt used, hence justifying the approach in this paper.\nThe combination of EC with LLMs is becoming more common. Pluhacek et al. used LLMs to enhance the Self-Organizing Migrating Algorithm (SOMA), demonstrating that LLMs can be used to create distinctive and effective algorithmic strategies [18]. Morris et al. introduced the concept of \"Guided Evolution\" (GE), which is a novel framework that uses LLMs for a supervised evolutionary process, guiding mutations and crossovers [19], using the LLM to help maintain genetic diversity and augment decision-making in model evolution. Nasir et al. proposed merging the code-generating abilities of LLMs with the diversity and robustness of Quality-Diversity (QD) solutions [20] to create diverse and high-performing networks. Liu et al. proposed an LLM-driven EA (LMEA), where each generation of the evolutionary search, LMEA instructs the LLM to select parent solutions from current population and perform crossover and mutation to generate offspring solutions [21]. EAs have also been used to explore the prompt space of LLMs, e.g., Saletta and Ferretti's grammar-based evolutionary approach [22] and Guo et al.'s EvoPrompt, which combines LLMs with EAs to automatically improve prompts [23]."}, {"title": "3 Method", "content": "In this work we define a prompt cue to mean: a signal or piece of information used to aid in the interpretation of an input by an LLM. An example of a cue might be \"window height\", typically used within a prompt for the LLM in the form, \"pay specific attention to window height.\"\nCLEAR evolves cues in order to achieve accurate recognition of features by LLMs. It iteratively optimizes the behavior of an LLM by optimizing sets of textual cues. It makes use of a genetic algorithm with a dynamic LLM-generated representation, where each individual in the population is represented by a set $i$ of $n$ chromosomes, where $n$ is determined by an LLM:\n$i = \\{ch_1, ch_2, ch_3, ..., ch_n\\}$\nand each chromosome $ch_x$ comprises a list of up to $m_x$ cues, where the allowable cues are also determined by an LLM:\n$ch_x: [cue_1, cue_2, ..., cue_{mx}]$\nThus, each chromosome is a group of cues (grouped in terms of semantic or application-specific similarity), with its exact composition optimized by the GA. For example, the chromosome representing the set of \"internal architectural features\" might contain the cues \"high ceilings\" and \"ceiling rose\", with the prompt instructing the LLM to focus on the presence or absence of the cues high ceilings and ceiling rose.\nWe choose a genetic algorithm because LLM image interpretation is inconsistent with extremely noisy results something GAs are particularly well-suited to handle.\nWhile this work focusses on the real-world application of extracting sustainability data from images of buildings, CLEAR is a general technique that could be used to improve any prompt for LLM interpretation of an input. Figure 1 illustrates the technique."}, {"title": "3.3 Automated Representation", "content": "Before the GA can evolve cues, we must first generate the chromosomes and their associated allowable cues, i.e., we must create a representation for the GA to evolve. Traditionally this is crafted by hand. Here we introduce an automated approach using an LLM (gpt-40). We do this to reduce bias caused by limited knowledge of a single expert and enable scalability."}, {"title": "3.4 Genetic Algorithms", "content": "We use two genetic algorithms: CLEAR* (fixed length), and CLEAR (variable length), the latter having more complex crossover and mutation operators. This enables us to investigate whether CLEAR benefits from the ability to add more cues to the same category or even remove entire categories.\nOur genetic algorithms manipulate cues (genes). Once the representation has been auto-generated, for every individual, for every chromosome, we initialize with a single random cue chosen from the corresponding LLM-generated cluster of possible cues. To evaluate individual $i$, each $ch_x$ is extracted as a list of textual cues: $cue\\_list$ and concatenated. These are then passed to the image interpretation LLM (gpt-4o) using the task-specific prompt (e.g., see Table 2). Chain-of-thought reasoning is encouraged by prompting the LLM to consider each cue in turn and give explanations before estimating. This is applied to each image. The interpreted result from the LLM is then cleaned (its textual output can be variable in formatting despite the prompt) and compared with the ground truth for each image to produce a fitness score (application-specific details in Section 4.2).\nOur GAs permit elites. Should any individual in the population already have a fitness score, it is re-evaluated and the worst score is used for the individual. We also cache all past solutions and their fitnesses in a run; if a previously-seen combination of cues is recreated then it is also re-evaluated and the worst score amongst the cached copy and new score is used. This method, first used in evolutionary robotics [24], encourages solutions to be more consistent (robust against noise). Once all members of the population have been evaluated, we copy the best two into the next generation as elites. We then choose parents from the best s% of the population and generate the remainder of the next generation using crossover and mutation operators.\nCrossover for the GA with fixed-length representation allocates a randomly chosen cue from either parent for each chromosome (uniform crossover). Mutation in a chromosome switches the cue with another randomly chosen from the same category. Thus, there is always the same number of chromosomes, each with $m_x=1$ cue.\nOur crossover for the GA with variable-length representation operates as follows. Given parents Parent1 and Parent2, we build each chromosome in turn for the child solution. Cues are iteratively randomly chosen from Parent1's chromosome or Parent2's chromosome until we reach the maximum number of cues of both parents. Should one parent have more cues in a chromosome, then the child has a probability of 0.5 of inheriting each additional cue in turn. Once complete, duplicate, or overspecified [25] cues are removed from the child. (If both parents share identical cues in a chromosome but in different orders then the child can be built with duplicates.) For example, if Parent1 = { ch\u2081:[brick, concrete, wood] } and Parent2 = { ch1: [laminate, brick] } then one child could become Child1 = { ch1:[brick, brick] }, corrected to Child1 = { ch\u2081: [brick] } while another could become Child2 = { ch\u2081: [laminate, concrete, wood] }\nMutation for the variable-length representation can perform three operations, randomly chosen: swap, delete or add. First a random chromosome is chosen within the child solution. When swapping, mutation picks a random cue of that chromosome and swaps it with another allowable cue. If there is no cue in the chromosome, a new cue is added instead. When deleting, if a random cue can be chosen, it is deleted. When adding, another allowable cue is added to the chromosome. After mutation, duplicates are removed. For example, if both Child1 and Child2 were mutated they could become: Child1 = { ch\u2081:[brick, steel] } and Child2 = { ch\u2081:[laminate, concrete] }\nUsing these operators we permit the GA with variable-length representation to explore any possible combination of cues for each chromosome from zero to the full allowable set. Once the new population has been created, we re-evaluate and continue until the termination criteria is met (either a perfect fitness achieved, or the maximum number of generations has been reached), see Figure 1."}, {"title": "4 Experiments", "content": "Our experiments focus on the following four research questions:\nR1. Validity of approach: Can cues be evolved from an LLM-generated representation that improve the accuracy of image interpretation?\nR2. Assessment of algorithm: How does a GA with fixed-length representation compare with a GA using variable-length representation?\nR3. Assessment of encoding: Can results be improved if categorical encoding is replaced with real encoding?\nR4. Validity of solutions: Do the evolved sets of cues represent coherent, concise sets?\nWe first describe data preparation and application-specific details of fitness evaluation."}, {"title": "4.1 Data", "content": "This work is performed in collaboration with the global accommodation marketplace TheSqua.re. With their support we prepared a ground truth dataset of 47 apartments each with confirmed data (accurate sustainability data is rare). Our first step was the preparation of this dataset. For each of the 47 properties there were between 8 and 50 images provided. From these, four image subsets were chosen representing:\n1. Building images: photographs of the exterior of the building if available, also wide-angle photographs showing as much of the interior as possible. (Used for Building Age and Energy data items)\n2. Heating images: photographs that include objects that could be used for heating such as radiators, boilers or vents.\n3. Window images: photographs that include windows, ideally showing features of frames, handles or other design characteristics.\n4. Lighting images: photographs that include lights, including ceiling or wall mounted and free-standing, ideally showing details of bulbs.\nWhile these were chosen manually in this work, the image selection stage could be automated by an LLM in future work. Our ground truth dataset also contains the true features contained by that apartment (laboriously collated from construction, owner, and surveyor documentation):\n[D1] Building age, which may comprise: an exact year, e.g., 2014, a range, e.g., 2007-2011, or text depicting a time period, e.g., 19th century => cleaned to \u20181801-1900', before 1900 => cleaned to '1000-1899'.\n[D2] Lighting, which comprises the percentage of lighting rated as low energy, e.g. 20% or 86%.\n[D3] Heating, which comprises one of: underfloor heating, warm air, water radiators, electric panels or electric storage heaters.\n[D4] Windows, comprising single glazed, double glazed, or high efficiency (triple glazed or high efficiency double glazing).\n[D5] Energy kWh/m\u00b2: an integer typically between 35 and 450.\nThis dataset was split 60:40 for training and test respectively, ensuring that the distribution of data remained similar (in some cases there are very few samples, e.g. of very old buildings, so we ensure both training and test contain at least one)."}, {"title": "4.2 Evaluation", "content": "For each of our five data items of interest: Building age, Lighting, Heating, Windows and Energy kWh/m\u00b2 we have a corresponding evaluation function to compare the image interpretation LLM output with the ground truth. Supplemental material provides all prompts used; here we give an example of the prompts for Windows (Table 2). For Building age, the LLM returns a range. Eqn (1) is used to calculate error if there is an exact ground truth value for the age, while Eqn (2) is used if there is a range. For Lighting, the fitness score per building is simply the difference between estimated percentage of low energy and actual percentage Table 3 and Table 4 describe error calculations for Heating and Lighting respectively. For Energy the fitness is the absolute difference between estimated kWh/m\u00b2 from the LLM and actual kWh/m\u00b2 of the building. If the LLM estimates a range, Eqns (1) and (2) is used. Final fitness scores comprise the sum of errors per building in the dataset.\n$Error (startA, emdA, pointB) =\\begin{cases}0, if (startA \\leq pointB \\leq endA)\\\\\\\\\\\\\\\\min (\\mid pointB -startA\\mid), otherwise\\end{cases}$\n$Error (startA, endA, startB, endB) = \\begin{cases}(startB - endA), if (endA < startB)\\\\\\\\\\\\\\\\(startA - endB), if (endB < startA)\\\\\\\\\\\\\\\\0, otherwise\\end{cases}$"}, {"title": "4.3 Experimental Setup", "content": "We perform four experiments to investigate our research questions:\nE1. Validity of approach. We test all five data items of interest: Building age, Lighting, Heating, Windows and Energy kwh/m\u00b2 and compare the result from CLEAR with the result from using the same image recognition LLM using a prompt written by a domain expert, and with the result of using another human domain expert to perform the recognition task manually on the same images.\nE2. Assessment of operators. We test both versions of the GA: fixed length and variable length.\nE3. Assessment of encoding. We compare the performance of CLEAR using categorical vs real encodings."}, {"title": "4.4 Results", "content": "Table 5 and Figure 2 provide our results. Overall, for all experiments, CLEAR outperforms or equals the performance of the other methods in both training and testing. CLEAR* can sometimes match the performance of direct human interpretation or expert-written prompts; in only one case it performs best (training dataset for Heating, but not for the test dataset). We revisit the research questions to understand the results in more detail."}, {"title": "4.4.1 Validity of approach (R1)", "content": "CLEAR (variable-length GA) successfully improves fitness scores over time. In several cases (Age, Lighting, Energy) its results are substantially better than direct human image interpretation and expert-written prompts (Table 5). It shows a clear pattern of changing the number of cues in chromosomes over time, occasionally removing all cues from some. Its approach varies according to the data item of interest. Runs where CLEAR strongly outperforms other methods often show an evolution towards higher numbers of cues after an initial drop (Figure 2, bottom row). This may indicate initial pruning away of harmful or unneeded cues (and entire categories of cues) before adding new useful cues to the other chromosomes. This can be seen in the final solutions, which reveal that some chromosomes have zero cues while others have multiple (Figure 3). Results where CLEAR merely equals the performance of other methods show a reduction in cues, perhaps indictive of the noise and difficulty inherent in the problems: for some problems it may be easier to remove distractions that cause LLM variability than find useful new cues that improve accuracy."}, {"title": "4.4.2. Assessment of operators (R2)", "content": "While CLEAR successfully evolved high quality solutions, results for CLEAR* show far less coherence, see Table 5 and Figure 2. For most runs there is still evolutionary progression towards better accuracy, but (apart from Heating, training) final solutions are always worse compared to using a GA with variable-length representation. Final solutions still appear to contain cues that have limited utility. For this problem there appears to be a substantial advantage in having the ability to alter the number of cues."}, {"title": "4.4.3 Assessment of encoding (R3)", "content": "CLEAR works effectively for all data items of interest. However, it seems that it is more difficult to evolve cues for some data items compared to others. Heating and Windows show less improvement over time, with Windows showing a trend towards fewer cues over time, but some of the cues remaining still questionable, e.g. \"Compliance with Fire-rated Standards\" and \"Visible Brand or Certification Labels\" (none are visible). While CLEAR equals or outperforms the other approaches, there remains a question: why is it easier to evolve cues for some data items compared to others?\nProblem difficulty is likely an important factor, and only solvable with improved data and better LLMs. But another reason may be noise. The use of nondeterministic LLMs for image interpretation, combined with the difficult identification task, results in inconsistent results from the LLM for the same set of cues. The level of noise may also be correlated with the precise cues presented to the LLM. To understand this better we presented the LLM with the same single cue ten times for the same image. For cue \"Evidence of Recent Installation\" the mean difference in output for categories was 0.4 (40% were reported as a different type out of the three options) with coefficient of variation (CV) of 1.29. This is perhaps a relatively good cue, but inconsistently good - there is high variation. In contrast the same LLM with cue \"Historical Building Integration\" had difference of output 0.9, CV 0.35 an example of a much worse cue, but less variation: it is more consistently worse."}, {"title": "4.4.4 Validity of Evolved Solutions (R4)", "content": "When we examine the evolved solutions from CLEAR"}, {"content": "it is apparent that the evolved cues appear relevant and tailored to the data item in question. Taking Energy kWh/m\u00b2 as an example of an evolved solution: this data item is extremely difficult to estimate from photographs alone, even for domain experts. CLEAR performed better than the other approaches for both training and test datasets (Table 5) and showed a clear improvement over time (Figure 2) with the number of cues first falling as low as 5 or 6 and then increasing to around 10. Figure 3 (bottom right) shows the cues of the best individual from the final generation, which provides a useful set relating to energy efficiency, building design, energy-hungry appliances, modernity and quality of d\u00e9cor and presence of central heating. One category was discarded: \"Heating and Ventilation\" which contained seemingly useful cues such as \"High-efficiency boiler\", \"Radiant floor heating\", \"Smart radiator valves\", and \"Underfloor heating controls\". But such features are not visible in our dataset of images so they were unlikely to be useful for the LLM.\nRelevance does not mean optimality, however. If CLEAR suffered from bloat then it is possible that our final solutions may contain many superfluous or unnecessary cues or even cues that harm accuracy. To test for this, we performed ablation studies, removing each cue in turn from the five best solutions shown in Figure 3 and testing the new prompt with the image interpretation LLM to see if there is any change in error. Table 5 (far right) shows the results: in every case a removal of an evolved cue resulted in worse performance by the LLM when interpreting the images. It would appear that CLEAR evolves high quality and concise sets of cues."}, {"title": "5 Conclusions", "content": "The use of LLMs to derive useful data from photographs could be transformational as we strive to understand existing building stock to improve long-term sustainability. But an LLM must be given highly specific prompts in order to achieve accurate interpretation. With building styles and practices varied around the world, this makes the application of LLMs time-consuming and costly - local domain experts would need to engineer new prompts for every new region. Our task, set by the industrial partner, was to solve this accuracy and scalability problem.\nWe introduced an automated approach for specialized LLM image-to-data applications. Cue Learning using Evolution for Accurate Recognition (CLEAR) generates and optimizes textual cues such that the accuracy of deriving specific data (such as building age, heating type, energy kWh/m\u00b2), for a given set of input data, is improved. LLMs optimized by CLEAR outperform human-authored prompts and expert human recognition by up to two orders of magnitude difference in error. Best results are achieved by using variable-length chromosomes to enable the number of cues to be changed over time. Real-valued estimates and corresponding fitness functions reduce noise and further improve accuracy compared to categorical estimates and stepped functions. An ablation study of final solutions provides evidence of concision, with the removal of any cue detrimental to accuracy.\nThis work has used image data of buildings in the UK. Future work will investigate the use of CLEAR for data from other regions. We also anticipate that CLEAR would be valuable for optimizing agentic LLM tasks and for other application domains."}]}