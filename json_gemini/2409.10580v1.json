{"title": "Veridical Data Science for Medical Foundation Models", "authors": ["Ahmed Alaa", "Bin Yu"], "abstract": "The advent of foundation models (FMs) such as large language models (LLMs) has\nled to a cultural shift in data science, both in medicine and beyond. This shift involves\nmoving away from specialized predictive models trained for specific, well-defined domain\nquestions to generalist FMs pre-trained on vast amounts of unstructured data, which\ncan then be adapted to various clinical tasks and questions. As a result, the standard\ndata science workflow in medicine has been fundamentally altered; the foundation\nmodel lifecycle (FMLC) now includes distinct upstream and downstream processes, in\nwhich computational resources, model and data access, and decision-making power\nare distributed among multiple stakeholders. At their core, FMs are fundamentally\nstatistical models, and this new workflow challenges the principles of \"Veridical Data\nScience\" (VDS) [1, 2], hindering the rigorous statistical analysis expected in transparent\nand scientifically reproducible data science practices. We critically examine the medical\nFMLC in light of the core principles of VDS: predictability, computability, and stability\n(PCS), and explain how it deviates from the standard data science workflow. Finally,\nwe propose recommendations for a reimagined medical FMLC that expands and refines\nthe PCS principles for VDS including considering the computational and accessibility\nconstraints inherent to FMs.", "sections": [{"title": "", "content": "Clinical data science combines statistics, computing, and algorithms with domain expertise to\nextract medical knowledge from data. The traditional data science life cycle (DSLC) typically\nbegins with a clearly defined domain question\u2014such as a specific prediction task related to\na particular clinical outcome in a defined patient cohort\u2014and follows a structured sequence\nof steps, including data collection, processing, modeling, and interpretation (although there\nare in practice many loops within and between the steps). However, recent foundation\nmodels (FMs) have caused a shift in clinical data science. Unlike the DSLC, the foundation\nmodel life cycle (FMLC) does not start with a specific domain question, but aims at training\ngeneral-purpose models. It uses broad, unstructured hospital and other non-domain data\nfor model pretraining, with the upstream process often inaccessible by the downstream\nprocess and users. This paradigm shift marks a transition from specialist to generalist\nmodels, from predefined tasks to emergent capabilities, from curated domain-specific\ndatasets to unstructured electronic health records (EHRs), and from purely predictive to\ngenerative modeling. Examples of medical FMs include clinical large language models\n(LLMs) and conversational vision-language models, which users can apply to or fine-tune\nfor specialized problems that differ from the data or tasks on which they were initially\npre-trained [3].\n\nThe shift from the DSLC to the FMLC brings an expanded scale and scope of underlying\noperations-it involves distinct upstream and downstream processes with distributed data\nassets, computational resources, and varying degrees of access among stakeholders. The\nresulting FM is often deployed as a proprietary \u201csoftware\u201d that is continuously updated\nover time (Figure 1), providing users with limited API access without transparency into"}, {"title": "", "content": "internal parameters, data used for pretraining and data pre-processing steps. As a result,\nthe FMLC includes numerous (reasonable) human judgment calls that are not transparently\ndocumented or communicated across stakeholders. Any variations in these decisions can\nnaturally induce often unacceptable variability in model outputs as shown in recent papers\nfrom social science and ecology. These additional uncertainty sources from human judgment\ncalls in the FMLC are not accounted for in standard statistical confidence intervals or\nhypothesis testing methods, raising serious concerns about the suitability of FMs for inductive\ninference in scientific and medical applications, where the ultimate goal is to derive reliable,\nreproducible, and transparent knowledge from data.\n\nA systematic way to consider the statistical implications of the medical FMLC is through the\npredictability, computability, and stability (PCS) framework and documentation for veridical\ndata science (VDS), introduced by Bin Yu and Karl Kumbier in 2020 for the traditional DSLC\n[1, 2]. Integrating the \u201ctwo cultures\" of Breiman (2001) into one [4], the PCS framework\n(including documentation) was originally proposed as a systematic approach to evaluate\nthe impact of human judgment calls on the reliability, reproducibility, and transparency of\nmodeling in the conventional DSLC. It is grounded in three core scientific principles that\ncombine statistics and ML in traditional data science practices: Predictability is the main\nobjective of supervised learning in standard clinical predictive models, providing a \"reality\ncheck\"-a model can be rejected or revised if it fails to predict new observations in held-out\ntest data. In the 2024 VDS book by Yu and Barter [2], Predictability has been expanded\nto be a stand-in for general reality-check including unsupervised learning. Computability\nconcerns computational aspects of the DSLC and includes efficient computing and data-\ninspired simulations. Stability expands traditional statistical uncertainty considerations\n(e.g. cross-validation, bootstrapping) to include variability from judgment calls across the\nDSLC, including those in data-cleaning and algorithm choices. Previous applications of the\nPCS framework in data science have demonstrated that, in various biomedical contexts,\nvariations induced by perturbing human judgment calls in the DSLC may be comparable to\nthose from bootstrapping a cleaned copy of the (training or test) data. The PCS framework\noffers a structured approach to address aspects of the FMLC that hinder transparency,\nreproducibility, and rigor in FM-based data science. Next, we discuss the challenges and\nrecommendations along the three pillars of predictability, computability and stability for\nFM development to be PCS-compliant during processes of the opaque upstream (e.g. data\nselection/curation, pretraining) and downstream (e.g. prompting and fine-tuning)."}, {"title": "", "content": "The concept of \"predictability\" as a reality check for FMs raises important questions. Tradi-\ntional predictive models are developed to solve a well-defined prediction problem, where\nstandard prediction performance measures (including accuracy, sensitivity, and specificity,\nand for subgroups) on held-out test data may suffice as a \"reality-check\". However, FMs are\noften used in diverse and non-traditional tasks, such as clinical text summarization. In these"}, {"title": "", "content": "contexts, defining a suitable reality check can be nuanced and requires an in-depth under-\nstanding of clinical workflows [5]. Despite the availability of public medical benchmarks for\npredictive tasks, more comprehensive benchmarks are needed to cover both upstream and\ndownstream processes, reflect the dynamic nature of clinical practice, as well as evaluate\nFM utility in non-traditional tasks such as medical text summarization, automatic clinical\nnote generation or conversational models. For the upstream, basic FDA-like disclosures are\nrecommended on the data, algorithms, prompt-design, their documentation, and release\ncriteria used for FM developers to ensure some essential trust from the downstream process\nand users, even for their economic gains down the line when paid FMs become common.\nFor both the upstream and downstream, it is recommended that FM developers stress-test\npretrained and fine-tuned FMs for high-stakes medical tasks by developing and improving\ncontinuously a collection of corner cases (e.g. using medical vignettes) and that they engage\nappropriate academic and citizen researchers to red-team new FMs for PCS-compliance\nbefore release and continuously monitor them over time.\n\n\"Computability\" is another dimension where FMLC differs remarkably from the DSLC.\nUpstream stakeholders (e.g. tech companies) typically have access to far greater GPU\nresources than downstream users (e.g. data scientists at hospitals). Retraining models to\nimplement statistical tests by perturbing judgment calls can be prohibitively expensive for\ndownstream users. Initiatives such as the National AI Research Resource pilot program\nlaunched by NSF may help bridge the computational gap between upstream and downstream\nstakeholders in health systems. However, further efforts (e.g. efficient compute advances in\nalgorithms and hardware) are needed to guarantee adequate availability of HIPAA-compliant\ncomputational resources to downstream users, ensuring a systematic evaluation process\nfor new releases of FMs. Data-inspired and well-vetted medical simulation models fall\nalso under \"Computability\" and can provide surrogates for reality-check for FMs in certain\nclinical settings.\n\nPredictability and computability are intertwined with the third pillar: stability. FMLC's\nstability can be assessed by upstream stakeholders through systematically perturbing and\ndocumenting each human judgment call and its impact on performance metrics within com-\nputational constraints. This ability to evaluate a model's stability is essential for conducting\nformal statistical tests on the \u201cscientific null hypothesis\u201d of an FM-that the FM does not\nsignificantly improve patient outcomes or inform clinical decisions. Pretraining FMs involves\nnumerous upstream engineering decisions that can greatly affect model performance, while\ndownstream users often customize \"prompts\" for specific outputs. Moving forward, it is\ncrucial for upstream stakeholders to document and communicate their judgment calls to\ndownstream users, including details on the data used for pretraining, data preprocessing,\noptimization algorithms, and hyperparameter tuning. Downstream users should also con-\nsider and report the impact of prompt engineering on output variability. Failing to comply\nwith such PCS guidelines may lead to poor scientific reproducibility and compromise the\nvalidity of findings based on FMs."}]}