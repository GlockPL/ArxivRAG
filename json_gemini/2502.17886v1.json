{"title": "A graph neural network-based multispectral-view learning model for diabetic macular ischemia\ndetection from color fundus photographs", "authors": ["Qinghua He", "Hongyang Jiang", "Danqi Fang", "Dawei Yang", "Truong X. Nguyen", "Anran Ran", "Clement C. Tham", "Simon K. H. Szeto", "Sobha Sivaprasad", "Carol Y. Cheung"], "abstract": "Diabetic macular ischemia (DMI), marked by the loss of retinal capillaries in the macular area,\ncontributes to vision impairment in patients with diabetes. Although color fundus photographs (CFPs),\ncombined with artificial intelligence (AI), have been extensively applied in detecting various eye\ndiseases, including diabetic retinopathy (DR), their applications in the detection of DMI remain\nunexplored, partly due to the skepticism among ophthalmologists regarding its feasibility. In this study,\nwe propose a graph neural network-based multispectral-view learning (GNN-MSVL) model designed\nto detect DMI from CFPs. The model leverages higher spectral resolution to capture subtle changes in\nfundus reflectance caused by the ischemic tissue, thereby enhancing sensitivity to DMI-related features.\nThe proposed approach begins with computational multispectral imaging (CMI) to reconstruct\n24-wavelength multispectral fundus images from CFPs. ResNeXt101 is then employed as the backbone\nfor multi-view learning to extract features from the reconstructed images. Additionally, a GNN with a\ncustomized jumper connection strategy is designed to enhance cross-spectral relationships, facilitating\ncomprehensive and efficient multispectral-view learning. The study included a total of 1,078\nmacula-centered CFPs from 1,078 eyes of 592 patients with diabetes, of which 530 CFPs from 530\neyes of 300 patients were diagnosed with DMI. The model achieved an accuracy of 84.7% and an area\nunder the receiver operating characteristic curve (AUROC) of 0.900 [95% CI: 0.852-0.937] on\neye-level, outperforming both the baseline model trained from CFPs and human experts (p-values\n<0.01). These findings suggest that AI-based CFPs analysis holds promise for detecting DMI, which\nmay contribute to its early and low-cost screening.", "sections": [{"title": "Introduction", "content": "DMI is a condition marked by a loss of retinal capillaries in the macular area and the enlargement and\nirregularity of the foveal avascular zone (FAZ) in patients with diabetes mellitus (DM)1,2. DMI is\nrecognized as a risk factor for the progression of DR and worsening vision, so it has been gradually\nconsidered as a possible new therapeutic target to halt DR progression and visual deterioration3-6.\nMultiple factors in DM contribute to the impairment of retinal capillaries, manifesting as capillary\ndropout, precapillary arteriolar narrowing and occlusion, thereby reducing downstream perfusion7-11.\nThe ensuing ischemic condition stimulates the retina and retinal pigment epithelium (RPE) to secrete\nsubstantial amounts of vascular endothelial growth factor (VEGF), leading to the disruption of the\nblood-retinal barrier and the proliferation of neovascularization, exacerbating the disease and resulting\nin irreversible worsening vision12. Early detection of DMI and effective management are crucial for\nslowing disease progression and preserving vision5,6,13. However, given that DMI predominantly occur\nwithin the capillaries, the detection of DMI demands the utilization of microangiography imaging\nmodalities including fluorescein fundus angiography (FFA) and optical coherence tomography\nangiography (\u041e\u0421\u0422\u0410).\nFFA, a time-honored technique for evaluating the retinal vascular system, is often considered the\ngolden standard for diagnosing DMI14-16. This method involves the intravenous administration of\nfluorescein dye followed by a sequence of fundus photographs that reveal the structure and blood flow\nof the retinal vessels, identifying microaneurysms, areas of non-perfusion, and neovascularization17-20.\nDespite its diagnostic accuracy, FFA is an invasive procedure that carries the risk of allergic reactions,\nwhich limits its use for early screening21,22. OCTA is an emerging, non-invasive imaging technology\nthat can capture the retinal capillary network and provide quantitative assessment23-25. It is highly\nsensitive in detecting DMI-related microvascular changes such as the enlargement of the FAZ,\nreduction in capillary density, and presence of non-perfusion zones26-28. However, OCTA requires\nexpensive equipment that is not widely available, making it less feasible for screening DMI23,29.\nCFPs, in contrast to the aforementioned imaging modalities, are more ubiquitous and accessible in\nhealthcare facilities at various settings, with a relatively simple operational procedure30,31. As a\nnon-invasive examination, CFPs inflict no direct ocular trauma on patients and avoid the use of\ncontrast agents that could elicit adverse reactions. Besides, the lower cost of CFPs translates to more\naffordable assessments, making it a more viable option for screening ocular diseases32-35. However, in\nclinical practice, CFPs are not currently regarded as a viable detection tool for DMI. This is likely\nbecause CFPs are thought to have limitations in rationales, including the insufficient resolution to\nsubtle retinal microvasculature changes.\nMultispectral imaging (MSI), in contrast to the color imaging technique employed in CFPs, provides\nsuperior spectral resolution. While primary color imaging captures images in three colors (red, green,\nand blue), MSI operates by collecting data across more wavelengths within a specific spectral range. In\nother words, it can distinguish between finer details in the spectral characteristics. Pigment molecules\nsuch as hemoglobin, melanin, and macular pigments present in fundus have unique spectral signatures.\nMSI is capable of detecting slight variations in their reflection patterns as a result of changes in the\ntissue's physiological state36-39. Having said that, MSI has not been used for studying DMI. The main\nhurdles could be the high cost and limited availability of fundus MSI devices. Previously, to address\nthe accessibility issue of MSI, we developed computational multispectral imaging (CMI) methods to\nreconstruct multispectral data from color images, without the need for additional hardware or\nmodifications, which provides a possible solution to reconstruct multispectral fundus images from\nCFPs40-42.\nAfter CMI, DMI detection from reconstructed multispectral fundus images entails further image\nprocessing steps. Considering the rich diversity of pigment molecules within the fundus tissue, this\nprocess inherently constitutes a multivariate analysis task. In our prior study, we had adopted the\nBeer-Lambert Law to delineate tissue-optical interactions and thereby formulated multivariate\nequations for a semi-qualitative analysis40,42,43. Nevertheless, when applied to tasks demanding a higher\nlevel of precision, such as disease detection, this methodology encounters some significant challenges.\nFirstly, the previous method was founded upon simplified tissue models which often prove insufficient\nin fully accounting for the complexity of variables present in real-world human tissue. Besides, errors\nthat occur during CMI can be amplified within the simplified linear multivariate equation system,\nnegatively impacting the detection performance. Hence, there is an urgent need to develop a new data\nprocessing method that can robustly exploit the reconstructed multispectral fundus images to generate\nprecise predictions for disease detection.\nIn this study, we developed the GNN-MSVL model with a jumper-connection mechanism to detect\nDMI from CFPs, adhering to several fundamental principles (Fig.1). First, leveraging the hypothesis\nthat MSI can more accurately capture microvascular abnormalities in DMI, we employed CMI to\nreconstruct multispectral fundus images from CFPs and utilized ResNeXt101 as an encoder to extract\nfeatures from multispectral views. Second, drawing on the rationale of multispectral joint analysis, we\nd designed a GNN to analyze features from multispectral views. Additionally, we designed a\njumper-connection strategy to create a cross-spectral graph structure to balance learning efficiency and\ncomprehensiveness. In a dataset comprising 1,078 eyes of 592 patients with DM, including 530\nDMI-affected eyes, our proposed method demonstrated a significant enhancement compared to the\nbaseline model and human experts, making itself a useful tool for identifying DMI in an accessible and\ncost-efficient approach."}, {"title": "Results", "content": "Computational multispectral fundus imaging\nEmploying the derived transformation matrix, we transformed CFPs into multispectral fundus images,\nspanning 24 discrete wavelengths ranging from 450 to 680 nm with a spectral resolution of 10nm (Fig.\n2b). Our observations indicated that as the wavelength increased from shorter to longer, there was a\ncorresponding increase in fundus reflectance, attributed to the reduction in tissue absorbance and\nscattering. Furthermore, the choroidal blood vessels became increasingly discernible in the images at\nlonger wavelengths, a phenomenon attributed to the enhanced penetration depth of light at these\nwavelengths.\nModel performance in DMI detection\nTable 1 details the characteristics of the training, validation, and test datasets, while Table 2 shows the\nperformance metrics of AI models and ophthalmologists. In the test dataset, the baseline ResNeXt101\nmodel trained on CFPs had an accuracy of 61.6%, sensitivity and specificity of 66.0% and 57.3%\nrespectively, and an AUROC of 0.632. The ResNeXt101 models trained on multispectral fundus\nimages exhibited average performance metrics of 72.4% accuracy, 67.2% sensitivity, 77.4% specificity,\nand an AUROC of 0.758. Among all wavelengths, the model trained from 560nm images achieved the\nbest performance, with an accuracy of 82.9%, sensitivity of 71.7%, specificity of 93.6%, and an\nAUROC of 0.867. The ROC curves of dections mades by all Al models were presented in Fig.3.\nSupplementary Table S2 provides a detailed analysis of the performance indices for models trained on\nimages at various wavelengths. Generally, models trained from images in the 500-600nm wavelength\nrange performed better, likely due to the relatively higher hemoglobin absorbance in this range\n[Supplementary Figure S1].\nWe also evaluated GNN-MSVL models with different connection designs: full connection, ring\nconnection, and jumper connection with step widths from 2 to 6. The GNN-MSVL model with ring\nconnection had performance metrics of 82.4% accuracy, 80.2% sensitivity, 84.5% specificity, and an\nAUROC of 0.859. The full connection GNN-MSVL model achieved similar performance metrics:\n82.4% accuracy, 77.4% sensitivity, 87.3% specificity, and an AUROC of 0.880. In contrast,\nGNN-MSVL models with jumper connections showed enhanced performance, with AUROC ranging\nfrom 0.854 to 0.900. Notably, the GNN-MSVL model with a jumper connection and a step width of 2\nhad the optimal performance, reaching 84.7% accuracy, 88.7% sensitivity, 80.9% specificity, and an\nAUROC of 0.900.\nBesides the predictions of deep-learning models, a human grading experiment was conducted to\ncomprehensively evaluate and compare different diagnostic metrics among ophthalmologists and\ndeveloped Al models. Three ophthalmologists, possessing 4, 6, and 10 years of experience respectively,\nachieved accuracy rates of 75.0%, 71.3%, and 73.1%, sensitivities of 49.1%, 41.5%, and 45.3%, while\nmaintaining a specificity of 100%. It's worth noting that in standard clinical settings, DMI is often\nbelieved to be undetectable from CFPs, which may account for the relatively low sensitivity in this\nstudy. Overall, this experiment provides a significant reference, emphasizing the improved\nperformance of our GNN-MSVL model."}, {"title": "Discussion", "content": "In this study, we developed a novel GNN-MSVL model to accurately detect DMI from CFPs. To the\nbest of our knowledge, this represents the first deep-learning model capable of achieving this specific\ntask solely using CFPs. Our model integrates CMI to augment the spectral resolution of CFPs,\nenabling the capture of minute variations in reflectance induced by ischemic fundus microvascular\ntissue. By employing ResNeXt101 as the backbone for multi-view learning, it effectively extracts\ndiscriminative features from the reconstructed multispectral fundus images. Moreover, the designed\nGNN with a jumper connection strategy optimizes cross-spectral relationships, facilitating\ncomprehensive and efficient multispectral-view learning. We speculate that jumper connection is\nsuperior to other connections as it reduces overfitting by having fewer connections compared to full\nconnection and offers more flexible information integration than ring connection. A jumper step of 2\nleads to the best performance may because it captures local spectral details crucial for detecting fine\ngrained changes in DMI detection without being overly complex or missing key information44.\nCFPs have emerged as preferred tools for screening ocular diseases due to the cost-effectiveness,\nwidespread availability, and ease of operation. For instance, it can clearly depict characteristics\nassociated with vision-threatening diseases like DR45,46, glaucoma 47,48, age-related macular\ndegeneration49,50 and papilledema51-53. Recent studies have demonstrated that the integration of CFPs\nwith deep-learning can be applied in detecting a variety of eye diseases54-57. Particularly, CFPs have\nbeen extensively researched and applied in the screening of DR among patients with DM. However,\nDMI, another retinal microvascular complication caused by DM, has been historically believed to be\nchallenging to detect from CFPs. The major reason is that the ischemic signals in DMI start from the\ncapillary network, resulting in relatively weak and early manifestations that are not readily observable\nin CFPs. Our proposed model focuses on this unmet gap by enhancing the capability to assess the\ncondition of pigment molecules, particularly hemoglobin in this study, through multispectral\nreconstruction and analysis. Simultaneously, through the utilization of multi-view learning and GNN,\nthe model robustly and precisely correlates relevant information present in multispectral fundus images\nwith DMI predictions. This strategy not only provides a potential solution for early screening of DMI\nbut also offers an explorative path for detecting other diseases and symptoms related to subtle fundus\nanomalies through CFPs.\nIn terms of method design, our research benefits from a novel strategy termed knowledge-informed\nAI58. This paradigm differs from most of the prevailing data-driven models, which often lack a deep\ncorrelation between model design and the intrinsic semantics of the data, thereby impeding targeted\noptimization of deep learning models. Knowledge-informed AI leverages prior knowledge,\nencompassing artificial comprehension of data, the principles governing the physical world, and expert\nexperience, to craft the model structure with certain purposes59,60. In our study, the conception and\nintegration of CMI, MSVL, and GNN with jumper connections are all executed in accordance with the\ninteraction principle of tissue optics and pathological knowledge. This informed development strategy\nhas yielded a model that outperforms traditional data-driven models significantly, underscoring the\npotential of knowledge-informed AI in specific applications.\nOur study has some limitations. Initially, during the CMI phase, the absence of clinical fundus MSI\nequipment necessitated that our spectral reconstruction verification be conducted on non-human tissue\nsamples. Despite the inclusion of 14 representative pseudo-skin tissue samples in our dataset, potential\nstructural disparities between these samples and actual fundus tissue may cause domain shift issues in\nthe multispectral reconstruction, potentially introducing errors in the multispectral fundus image\nreconstruction process. Secondly, we opted for a spectral reconstruction band ranging from 450 to 680\nnm, segmented into 24 channels with a spectral resolution of 10 nm. The selection of this spectral range\nwas primarily aligned with the sensitivity bands of RGB cameras, while the determination of spectral\nresolution and channel number was somewhat arbitrary. Owing to the computational constraints\nassociated with training and testing, we did not fine-tune the spectral resolution and the number of\nspectral channels, which may have precluded us from identifying the optimal spectral combination for\nachieving superior detection performance. Lastly, while our GNN-MSVL model with jumper\nconnections demonstrated significantly enhanced detection performance compared to the baseline\nmodel, there remains room for further optimization of the connection strategy, attention mechanism,\nand classifier module. It is plausible that a more comprehensive optimization process could reveal a\nmodel structure that offers an even more accurate detection. These considerations highlight areas for\nfuture research and potential refinements to enhance the model's efficacy in detecting DMI from CFPs.\nIn light of the aforementioned limitations, our future work will be directed towards several key areas of\nimprovement. Initially, we aim to optimize the spectral resolution, the number of channels in the\nmultispectral views, the connectivity patterns, the attention mechanisms, and the classifiers module, to\nachieve superior detection performance for DMI. Additionally, we plan to leverage the full application\npotential of our method by extending our research to encompass the detection of a broader spectrum of\neye diseases that involve vascular and tissue pigment anomalies. Furthermore, we will explore more\ninnovative strategies, such as developing new knowledge representations at feature engineering stages\nand adding physical residuals into loss functions, for integrating a more comprehensive array of prior\nknowledge and information into the development of deep learning algorithms. This will not only\nenhance the capabilities of our models but also contribute to the evolution of knowledge-informed AI\nmethodologies within the field of ophthalmology.\nIn conclusion, this study proposes an GNN-MSVL model for DMI detection from CFPs. By integrating\nCMI to enhance spectral resolution, devising MSVL for multispectral joint analysis, and creating a ring\nGNN architecture with jumper connections, the model achieves high-accuracy performance in DMI\ndetection. This achievement validates the viability and reliability of AI-based CFPs analysis in DMI\ndetection, overcoming the long-standing skepticism in the field regarding the use of CFPs for this\npurpose. The successful application of this model will not only offer a more accessible and\ncost-effective method for DMI screening but also have far-reaching implications for early detection and\nintervention of eye diseases, potentially improving patient outcomes."}, {"title": "Methods", "content": "Study design\nIn this study, a deep learning model was developed for DMI detection. The macula-centered CFPs were\nretrospectively collected from a well-defined cohort consisting of 530 eyes diagnosed with DMI and\n548 disease-free eyes. All the participants were subjected to OCTA via a swept-source optical\ncoherence tomography (DRI OCT Triton; Topcon). A 3\u00d73-mm volumetric scan centered at the fovea\nwas carried out. The ground truth was labeled on the OCTA images solely by referring to the Early\nTreatment Diabetic Retinopathy Study protocol which is based on dye-based angiography. Specifically,\nthe presence of DMI was identified when the images showed a disrupted FAZ, either with or without\nadditional regions of capillary nonperfusion in the macula. In contrast, the absence of DMI was defined\nas images presenting an intact FAZ outline and a normal distribution of vasculature.\nThe CFPs were performed using a fundus camera (TRC 50DX; Topcon) which was calibrated\nfollowing standardized procedures. Each CFP had a 45-degree field of view. The patients in the cohort\nwere characterized in terms of age, gender, and relevant clinical variables61,62. The study was\nmeticulously executed at the CUHK Eye Centre and adhered to strict ethical guidelines. It received\napproval from the Joint Chinese University of Hong Kong-New Territories East Cluster Clinical\nResearch Ethics Committee in the Hong Kong Special Administrative Region of China, as well as the\nlocal research ethics committees of each participating center. Informed consent was obtained from each\nparticipant or their legal guardian. The consent process involved providing detailed information and\nobtaining signatures or electronic confirmations. The STARD guideline was scrupulously implemented\nfor the reporting of this study, ensuring the highest level of methodological rigor, transparency, and\nreproducibility in the presented research findings.\nModel development\nThe proposed deep-learning model consists of three notable innovative parts: (1) CMI to reconstruct\nmultispectral fundus images from CFP, (2) MSVL to jointly analyze multispectral images, and (3)\nGNN with a jumper connection to achieve an efficient MSVL.\nCMI: The detailed methodology of CMI is elaborated in our previous study40,42. Herein, we briefly\noutline the operation steps for applying CMI in CFP. First, we selected a classic color chart (X-rite\nColorChecker Classic, X-rite Inc) as the standard color chart to calibrate the fundus camera.\nSpecifically, we captured images of 24 color blocks present on the color chart under darkroom\nconditions, illuminated exclusively by the built-in flash of the fundus camera. Following the acquisition\nof the camera responses, we deployed the Wiener estimation algorithm to compute the transformation\nmatrix, which facilitates the conversion of RGB values into a 24-channel reflectance spectrum. This\nmatrix was rigorously tested against all 24 classic color blocks and the 72 non-classic color blocks on\nanother color chart (X-rite ColorChecker Digital SG, X-rite Inc) to ascertain its accuracy. The validated\ntransformation matrix was subsequently applied to reconstruct macula-centered CFP images into\nmultispectral images and utilized for further analysis.\nMSVL: CMI facilitates high-spectral-resolution representations of the fundus tissue, which is\ndetermined by the content and distribution of various pigments, including hemoglobin, melanin,\nmacular pigment, and beyond 63. Theoretically, DMI presents as ischemia in the macular region,\ncharacterized by an abnormal deficiency in hemoglobin content. Viewing tissue pigments as the\nindependent variable set, the detection of alterations in specific independent variables necessitates the\npresence of a corresponding dependent variable set to accomplish multivariate joint analysis. In our\nresearch, multispectral fundus images provide the dependent variable set, serving as the foundation for\njoint analysis. Multi-view learning is conventionally employed to select distinct features, modalities, or\nperspectives of data, forming various views that reflect partial characteristics of the object, which are\nthen integrated to obtain a comprehensive representation64. In this case, multispectral fundus images\ncan be considered as views of the fundus within the spectra space, capturing the optical characteristics\nof fundus tissue across varying wavelengths65. Based on this rationale, we chose to design an MSVL\nframework to jointly process the spectral domain information to detect DMI.\nGNN-MSVL: There are multiple ways of view fusion in multi-view learning. Among them, GNN can\nnaturally construct multi-view data into a graph structure, regarding each view as a node and defining\nthe relationships between views as edges, thus accurately capturing the complex topological structures\nand node associations66. Therefore, we employed GNN as the basic structure for view fusion to jointly\nanalyze multispectral images. Furthermore, referring to the solution process of regular multivariate\nanalysis, we also require sufficient differences among multispectral data to avoid multicollinearity.\nBased on the above requirements, we designed a dual-layer GNN with jumper connections for\nmultispectral view fusion and analysis. Specifically, from multispectral views, we used ResNeXt101 as\nthe backbone encoder to extract view features, which, after passing through the attention module, form\nthe nodes of GNN layer 1. To ensure spectral differences, jumper connections are adopted between\nnodes, that is, there are adjustable step lengths between two connected nodes. During the learning\nprocess, nodes aggregate multivariate information from neighboring nodes (different view data) and\nupdate their own representations, so that the fused features possess both the characteristics of each\nview and collaborative information. A GATconv module with a four-head attention mechanism\naggregates all fused features in layer 1 and passed to layer 2. After processing the representations of all\nnodes, a binary classifier made a prediction on whether the input belongs to DMI eyes or not.\nStatistical analysis\nRMSE was used to evaluate the errors between the reconstructed spectra and the reference spectra. To\nassess the performance of different models for DMI detection, the precision, sensitivity, specificity, F1\nscore, and AUROC were calculated and compared. Additionally, we calculated the P-value of AUROC\nto evaluate the significance level. A P-value less than 0.01 was considered to indicate a highly\nstatistically significant difference. We calculated Yoden's index to find the optimal cutoff point to\nclassify test data into binary categories.\nData and code availability\nThe data used for model development of this study are not publicly available by hospital regulations to\nprotect patient privacy. Limited data access is obtainable upon reasonable request by contacting the\ncorresponding author. The framework is implemented in PyTorch framework 2.0.0 on an NVIDIA\nA100 GPU. Code and model weights are obtainable upon reasonable request by contacting the\ncorresponding author."}]}