{"title": "Dynamic Entity-Masked Graph Diffusion Model for histopathological image Representation Learning", "authors": ["Zhenfeng Zhuang", "Min Cen", "Yanfeng Li", "Fangyu Zhou", "Lequan Yu", "Baptiste Magnier", "Liansheng Wang"], "abstract": "Significant disparities between the features of natural images and those inherent to histopathological images make it challenging to directly apply and transfer pre-trained models from natural images to histopathology tasks. Moreover, the frequent lack of annotations in histopathology patch images has driven researchers to explore self-supervised learning methods like mask reconstruction for learning representations from large amounts of unlabeled data. Crucially, previous mask-based efforts in self-supervised learning have often overlooked the spatial interactions among entities, which are essential for constructing accurate representations of pathological entities. To address these challenges, constructing graphs of entities is a promising approach. In addition, the diffusion reconstruction strategy has recently shown superior performance through its random intensity noise addition technique to enhance the robust learned representation. Therefore, we introduce H-MGDM, a novel self-supervised Histopathology image representation learning method through the Dynamic Entity-Masked Graph Diffusion Model. Specifically, we propose to use complementary subgraphs as latent diffusion conditions and self-supervised targets respectively during pre-training. We note that the graph can embed entities' topological relationships and enhance representation. Dynamic conditions and targets can improve pathological fine reconstruction. Our model has conducted pretraining experiments on three large histopathological datasets. The advanced predictive performance and interpretability of H-MGDM are clearly evaluated on comprehensive downstream tasks such as classification and survival analysis on six datasets. Our code will be publicly available at https://github.com/centurion-crawler/H-MGDM.", "sections": [{"title": "Introduction", "content": "Achieving concise and informative histopathology patch image representation is the cornerstone for solving many tasks in the field of computational histopathology analysis, such as cancer diagnosis, grading, segmentation, and prognosis tasks within whole Slide Image (WSI) (Panayides et al. 2020). There are many extensive investigations on pre-training features for pathology images, which can help alleviate the time-consuming and tedious task of manual slide inspection by pathologists (Song et al. 2023). Today, the representation of pathology image patches relies heavily on transfer learning methods (Dosovitskiy et al. 2020; Sharmay et al. 2021; Li et al. 2022) and the supervised pathology classification models such as KimiaNet (Riasatian et al. 2021). The above approaches exist problems like the domain gap and category bias (Guan and Liu 2021), and scarce and high-cost annotations limit retraining. Therefore, unlabeled self-supervised learning (SSL) has emerged as a solution to alleviate these limitations by learning salient representations without using labels.\nPrevious SSL methods like MAE (He et al. 2022) have shown that using masks and reconstruction tasks in SSL effectively enables models to learn from unlabeled pathological data. In the context of pathological images, the topological connections among pathological tissues, including cellular interactions and their surrounding environment, are crucial for various tasks. Recent approaches have underscored the importance of structure function relationships by linking the spatial organization of cells within tissues through cell graphs. These methods enable the extraction of biomarker-based pathological features (Jaume et al. 2021b,a), capturing complex semantic associations that extend beyond pixel-level data to encompass tissues and cells. These approaches align more closely with pathological diagnostic procedures. Entity-based topological analysis provides enhanced control over tissue modeling and facilitates the integration of pathological priors into task-specific histopathological entity representations. This indicates that it is crucial to recognize the interactions among \u201cImage-to-Graph\u201d based pathological tissue entities. However, when SSL is applied to pathological images, recent studies often focus on using pathological grid tiles in patches as masks, while neglecting the impact of entities (e.g., cellular or tissue regions) mask strategy on the overall semantic representation. Therefore, we introduce a new method to convert images into graphics to capture the structure of pathological entities, such as tissues, in self-supervised learning.\nOn the other hand, diffusion strategies have recently improved robust learning representations as conditions through their technique of adding noise with varying intensities (Purma et al. 2023; Wei et al. 2023; Yang and Wang 2023). We propose using an entity-masked graph as the input for the diffusion process, with encoded features from different layers of the graph serving as conditions to maintain strong performance. This approach captures powerful and complex entity information, thereby enhancing the representation of pathological images.\nIn summary, the motivation of our paper is to better learn the knowledge of entity graphs under self-supervised reconstruction progress. We propose a novel approach that converts histopathological images into entity graphs with dynamic mask and noise for diffusion pre-training to obtain better pathological image representations in the pathology inspection process (see Fig.1). Our contributions are:\n\u2022 We propose a novel framework the H-MGDM, a novel self-supervised histopathological image representation learning method through Dynamic Entity-Masked Graph Diffusion Model. A strategy for partially visible entities as conditioning to prompt masked noisy entities to graph diffusion. Random masks and dynamic intensity noises can enhance representations in histopathological images.\n\u2022 In H-MGDM, we convert pathology images into entity graphs of latent space to incorporate structural information of pathological entities. This allows for more comprehensive spatial and semantic priors.\n\u2022 We conducted pretraining experiments on three large histopathological datasets. The advanced predictive performance and interpretability of H-MGDM are clearly evaluated on comprehensive downstream tasks on six datasets. All performance across several downstream tasks is averagely improved by 5.18%. This demonstrates the effectiveness of the H-MGDM framework for pre-training in histopathological image analysis."}, {"title": "Related Works", "content": "Graph Representation for Digital Pathology\nRecently, graph neural networks (GNN) have been employed to represent patches as graphs for pathology tasks. CGC-Net (Zhou et al. 2019) introduces a cell-graph convolutional neural network that converts large histology images into graphs, where vertices represent nuclei and edges denote cellular interactions based on vertex similarity. HACT (Pati et al. 2022) develops a hierarchical cell-to-tissue graph representation to jointly model both low-level and high-level graphs, incorporating intra- and inter-level coupling based on the topological distributions and interactions among entities. SHGNN (Hou et al. 2022a) proposes a novel spatial hierarchical GNN framework, equipped with a dynamic structure learning module, to capture entity location attributes and semantic representations, thereby extracting the characteristics of different entities in images. However, these methods focus supervision on global representation. Our proposed method introduces entities subgraph self-supervised targets. This enables entities to capture the contextual implications of local information.\nDenoising Diffusion Models\nDiffusion models (Rombach et al. 2022; Ho, Jain, and Abbeel 2020) are known for their ability to generate sophisticated images under conditional control. Diffusion models also exhibit variable masking capabilities and have also been used to enhance representation learning in the self-supervised learning domain, in learning paradigms such as DiffAE (Preechakul et al. 2022). Also, GenSelfDiff-HIS (Purma et al. 2023) proposes a diffusion-based generative pre-training process for self-supervision to learn efficient histopathological image representations. DiffMAE (Wei et al. 2023) integrates diffusion's nuanced detail reconstruction capabilities with MAE's comprehensive semantic representation capability, symbolizing a convergence of methodologies in pursuit of enhanced representation.\nMask for Self-Supervised Representation\nSince the introduction of BERT (Devlin et al. 2018) in language models, masking prediction has reattracted attention. Lots of self-supervised masking methods have been"}, {"title": "Methodology", "content": "Figure 2 illustrates the framework of H-MGDM. First, the histopathological entity graph is constructed using the superpixel algorithm SLIC (Achanta et al. 2012) to extract the topological relations among tissues in the image and compress entities to latent space. Then, the GNN encoder is used to encode the visible subgraph as a condition. The latent graph diffusion model is introduced to reconstruct the dynamic self-supervised target of the masked subgraph to obtain robust representations of patches.\nPathological Entity Graph Construction\nTo strengthen the concept of entity within limited structural constraints, we utilize priori pathological tissue superpixels as tissue entities when constructing the graph. First, a pathological image $I \\in \\mathbb{N}^{h_1 \\times w_1 \\times 3}$ with the height $h_1$ and the width $w_1$ is partitioned via SLIC algorithms (Achanta et al. 2012) resulting in a set of superpixels. For each superpixel, s, a window of size $a \\times a$ centered at s is considered as a vertex $v$ of the pathological entity graph P in pixel space. Pixels in the window that do not belong to s are assigned the background color. Subsequently, edges will be established between every two vertices with adjacent boundaries, considering the local interactions between adjacent vertices more. The edge e originates from the region after the expansion operation along the boundary between $s^i$ and another neighboring superpixel $s^j$. Thus, the image I is transformed into a pathological entity graph P(VP, Ep, A, D), where $VP = {s_i}_{i \\in [0,N_v)}, Ep = {e_j}_{j \\in [0,N_E)}$ are sets of vertices and edges, respectively. And the adjacency matrix is A and the degree matrix of A is D. $N_v$ and $N_E$ are the numbers of vertices and edges, respectively.\nEntity Compression into Latent Space\nOur compression model, based on previous work (Kingma and Welling 2013; Esser, Rombach, and Ommer 2021), utilizes an auto-encoder in stage 1. Given a pathological entity graph P, the encoder Ep transforms each entity $x \\in (X_V \\cup X_E) \\subset \\mathbb{N}^{a \\times a \\times 3}$ in P into a latent representation $z = E_p(x)$, where $z \\in \\mathbb{R}^{l \\times 1 \\times c}$. The encoder learns an approximate posterior distriution $q(z|x) = \\mathcal{N}(z; \\mu(x), \\sigma^2(x)I)$, with $\\mu(x)$ and $\\sigma(x)$ being learned mean and standard deviation of x. And the decoder Dp then reconstructs the image from this latent space, $y = D_p(z) = D_p(E_p(x))$. The downsampling factor of the image is $f = a/l$ and we ex-"}, {"title": "Latent Graph Diffusion Model", "content": "plore various downsampling factors f. After the first stage of training is completed, we infer Ep to encode all entities into the latent space, resulting in sets $V_G$ and $E_G$. Those compose the latent space entity graph $G(V_G, E_G, A, D)$.\nLatent Graph Diffusion Model\nThe forward process of the latent diffusion model can add noise to the graph entities, describing the degraded sequence caused by Gaussian noise on the latent space, which does not contain much semantics. Given a well-defined latent diffusion diffusion (Ho, Jain, and Abbeel 2020) forward process $q_L : {G_d(t)}_{[0,T]}$ with variance time dependence, and a noise schedule ${\\beta(t)}_{[0,1]}$ where the integer time $t \\in [0, T]$, based on Markov chain and diffusion characteristics(Huang et al. 2023; Wei et al. 2023), we have:\n$q_L (G_d(t)|G_d(t-1)) = \\mathcal{N}(G_d(t)|\\sqrt{1 - \\beta(t)}G_d(t - 1), \\beta(t)I)$\n$\\boxed{$q_L (G_d(t)|G_d(0)) = \\mathcal{N}(G_d(t)|\\sqrt{\\bar{\\alpha}(t)}G_d(0), (1 - \\bar{\\alpha}(t))I)$}\n(1)\n$G_d(t)$ is reparameterized as $G_d(t) = \\sqrt{\\bar{\\alpha}(t)}G_d(0) + \\sqrt{1 -\\bar{\\alpha}(t)}\\epsilon$, noise follows a normal distribution: $\\epsilon \\sim \\mathcal{N}(0, I)$, where $\\alpha(t) = 1 - f(t), \\bar{\\alpha}(t) = \\prod_{i=1}^{t} \\alpha(i)$, signal-to-noise ratio ${\\beta(t)}_{[0,1] \\in [0,T]}$ are chosen to noise gradually that $q_L(G_d(T)) \\approx \\mathcal{N}(0, I)$. The conditional diffusion reverse above by modeling the reverse distribution $p_L$ which implies masked part conditioned on visible graph $G_e$ from encoder:\n$p_L(G_d(t-1)|G_d(t), \\hat{G}_e) \\sim \\mathcal{N}(0, I).$\n(2)\nThen, a reverse diffusion network $D_L$ with graph conditioning on ${\\beta(t)}_{[0,1]}$ is introduced. Considering the graph structure, we can apply the continuous diffusion process to $V_d(t)$ and $E_d(t)$ respectively to facilitate the restoration of noisy latent within subgraph pathological entities.\nDynamic Diffusion on Masked Graph Model\nIn stage 2 illustrated in Fig. 2, an asymmetric auto-encoder mode is employed, utilizing GNN layers (Kipf and Welling 2016) as the encoder and ViT variants (Dosovitskiy et al. 2020) as the decoder. From the LDM perspective, the encoder also provides encoding conditions for the decoder's denoising process. For a graph input G, is dynamically randomly divided into two complementary subgraphs $G_e(V_e, E_e, A_e, D_e)$ for encoder and $G_d(V_d, E_d, A_d, D_d)$ for decoder according to the given masking ratio $r_m = \\frac{N_{V_d}}{N_v} = \\frac{N_{E_d}}{N_E}$. The noise-added $G_d(t)$ serves as the initial input to the decoder. Furthermore, the topological information $A_* D_* (* = e, d)$ is maintained during training.\nTissue GNN Encoder The latent encoder $E_L$ employs GNN that integrates tissue vertices and edges for L layers. In our pathological graph-based construction, the latent domains of graph vertices and edges are identical. Therefore, the vertex-based message passing can be used to forward edge latent for $\\hat{G}_e (V_e^{(1)}, E_e^{(1)}, A_e, D_e)$ in the l-th layer:\n$\\epsilon_l (V_e^{(l+1)}) = \\sigma(\\tilde{A} V_e^{(l)} W_v)$\n(3)\n$\\epsilon_l (E_e^{(l+1)}) = \\sigma(\\tilde{A}* E_e^{(l)} W_e)$"}, {"title": "Dynamic Diffusion Decoder", "content": "where $\\tilde{A} = D^{-1/2} A D^{-1/2}$. $\\tilde{A}$ and $\\tilde{A}*$ are the normalized symmetric adjacency matrices of the graph $G_e$ and the dual graph $G_d$, respectively. $V_e^{(l)}, E_e^{(l)}$ are inputs to the l-th layer, $W_v, W_e$ are the vertices and edges weight matrices of graph convolution $\\epsilon_l$, and $\\sigma(\\cdot)$ is a non-linear activation.\nDynamic Diffusion Decoder The decoder $D_L$ utilizes the conditional latent graph diffusion model. The noise level t serves as the forward sampling time during pre-training to generate $G_d(t)$. Similar to the Transformer architecture (Vaswani et al. 2017), in the l-thdecode block, cross-attention $CA(\u00b7,\u00b7)$ utilizes the visible latent $G_e^{(l)}$ from the l-th encoder layers as the conditional control after adding the time embedding $t(t)$: $G_e^{(l)} = G_e^{(l)} + t(t)$, aiding in denoising $G_d(t)$ during decoding. And the graph convolution of decoder $C$ is to perform the message passing of the fused latent according to $A_d$ next. The Feed Forward $FF(\u00b7)$ with layer normalized residual block is employed as the final layer within the Decoder Block to induce feature activation, resulting in $G_d^{(l-1)}(t)$. Then, it proceeds to the subsequent blocks to predict $\\hat{G}_d^{(0)}(t)$:\n$\\hat{G}_d^{(l-1)}(t) = FF(C_{d^{(l)}}(CA(G_d^{(l)}(t), \\hat{G}_e^{(l)}), A_d))$\n(4)\n$\\boxed{$G_d^{(0)}(t) = D_L(G_d(t), t, {\\hat{G}_e^{(l)}}_{l \\in [0,L)})$} \nThe skip connection from $\\hat{G}_e^{(l)}$ forms a U-shaped configuration, typically advantageous for graph representation across different levels and noisy latent restoration.\nTraining Strategy\nObjectives The optimization of the model in pre-taining has two stages: In order to avoid high-variance latent space in the first stage, the auto-encoder is optimized by a combination of a reconstruction loss and KL Divergence $D_{KL}$ like VAE (Kingma and Welling 2013). The pixel-space reconstruction constraint $\\mathcal{L}_{rec}$ enforces local realism avoids blurriness and ensures that the reconstructions are confined to the image manifold. Here we use the MSE form:\n$\\mathcal{L}_{rec} = E_{q(z/x)} ||x - \\hat{x}||^2,  \\mathcal{L}_{VAE} = \\mathcal{L}_{rec} + \\lambda D_{KL},$\n(5)\nwhere $E_{q(z\\x)}$ represents the expectation of the distribution of the latent variable z, $\\lambda$ is the loss weight. And $q(z|x)$ is the posterior distribution of the latent z given x.\nThe second stage is guided by minimizing the following objective function to optimize parameters $\\Theta$ of the model. Notably, xo-mode is used dynamic denoising on graph masking of vertices and edges:\n$\\mathcal{L}_{Simple} = E_{t,\\Theta, \\epsilon}[||V_d^{(0)} - \\hat{V}_d^{(0)}(t)|| + ||E_d^{(0)} - \\hat{E}_d^{(0)}(t)||].$\n(6)\nHere, $\\epsilon$ represents sampled noise. Leveraging variational inference, the well-known Mean Square Error (MSE) objective, derived from the evidence lower bound, is utilized to predict the denoised $V_d^{(0)}$ and $\\hat{E}_d^{(0)}$ as reconstruction targets."}, {"title": "Training Strategy", "content": "Objectives The optimization of the model in pre-taining has two stages: In order to avoid high-variance latent space in the first stage, the auto-encoder is optimized by a combination of a reconstruction loss and KL Divergence $D_{KL}$ like VAE (Kingma and Welling 2013). The pixel-space reconstruction constraint $\\mathcal{L}_{rec}$ enforces local realism avoids blurriness and ensures that the reconstructions are confined to the image manifold. Here we use the MSE form:\n$\\mathcal{L}_{rec} = E_{q(z/x)} ||x - \\hat{x}||^2,  \\mathcal{L}_{VAE} = \\mathcal{L}_{rec} + \\lambda D_{KL},$\n(5)\nwhere $E_{q(z\\x)}$ represents the expectation of the distribution of the latent variable z, $\\lambda$ is the loss weight. And $q(z|x)$ is the posterior distribution of the latent z given x.\nThe second stage is guided by minimizing the following objective function to optimize parameters $\\Theta$ of the model. Notably, xo-mode is used dynamic denoising on graph masking of vertices and edges:\n$\\mathcal{L}_{Simple} = E_{t,\\Theta, \\epsilon}[||V_d^{(0)} - \\hat{V}_d^{(0)}(t)|| + ||E_d^{(0)} - \\hat{E}_d^{(0)}(t)||].$\n(6)\nHere, $\\epsilon$ represents sampled noise. Leveraging variational inference, the well-known Mean Square Error (MSE) objective, derived from the evidence lower bound, is utilized to predict the denoised $V_d^{(0)}$ and $\\hat{E}_d^{(0)}$ as reconstruction targets."}, {"title": "Downstream Tasks", "content": "For downstream tasks, we deploy two stages' encoders $E_p E_L$ to inference to obtain the global graph representation $O_G$ by readout $r_g$:\n$\\boxed{$G_O = \\hat{G}_e^{(L)} = E_L (E_p(G_P)), O_G = r_g(G_O).$}\n(7)\n\u2022 Classification. For the downstream tuning, the cross-entropy loss $L_{CE}$ is adopted for patch classification tasks. The model is optimized through the classification layer MLP to obtain the predicted $Y$ by global representation $O_G$ as probabilities of the classes and to supervise it with the classification labels Y.\n\u2022 Regression. We introduce the Cox proportional hazards model, a semi-parametric regression model. Using survival events and survival time as labels. Here, pathological image features are used to predict risks and analyze the impact on survival. Considering a problem involving two explanatory variables as predictors of survival time $t_i$ and $t_j$ of patients i, j, $\u03b4$ represents the termination event (1: death, recurrence, 0: not occurred) $R(t_i)$ represents the condition $t_j > t_i$, for neg log partial likelihood loss:\n$\\mathcal{L}_{Cox} = - \\sum_{i: \\delta_i=1} \\left[h_i - \\log \\sum_{j \\in R(t_i)} e^{h_j} \\right],$\n(8)\nwhere we use $MLP_h$ linear map the graph representation $O_G$ to the final hazards prediction $h_i."}, {"title": "Experiments", "content": "Experimental Settings\nDatasets The proposed framework underwent pretraining and classification using three large extensive histopathological datasets: Komura et al. (Komura et al. 2022) (1.6M images, 32 cancer types), Prostate ANnotation Data Archive (PANDA) dataset (Bulten et al. 2022) (11,000 digitized H&E-stained WSIs, obtaining 12.5M images with 6 level Gleason region annotations), our in-house colorectal cancer data IBD (23M images, with 360K patches annotated into 9 common tissue types). For the survival analysis task, we compare the performances on two public cohorts: TCGA-KIRC (512 cases) and TCGA-ESCA (155 cases) and one privately collected primary-metastatic pathology colorectal cancer dataset CRC-PM (388 cases). We use different methods pre-trained on the pancancer dataset Komura et al. as feature extractors for patches in WSI 1."}, {"title": "Training Strategy", "content": "Objectives The optimization of the model in pre-taining has two stages: In order to avoid high-variance latent space in the first stage, the auto-encoder is optimized by a combination of a reconstruction loss and KL Divergence $D_{KL}$ like VAE (Kingma and Welling 2013). The pixel-space reconstruction constraint $\\mathcal{L}_{rec}$ enforces local realism avoids blurriness and ensures that the reconstructions are confined to the image manifold. Here we use the MSE form:\n$\\mathcal{L}_{rec} = E_{q(z/x)} ||x - \\hat{x}||^2,  \\mathcal{L}_{VAE} = \\mathcal{L}_{rec} + \\lambda D_{KL},$\n(5)\nwhere $E_{q(z\\x)}$ represents the expectation of the distribution of the latent variable z, $\\lambda$ is the loss weight. And $q(z|x)$ is the posterior distribution of the latent z given x.\nThe second stage is guided by minimizing the following objective function to optimize parameters $\\Theta$ of the model. Notably, xo-mode is used dynamic denoising on graph masking of vertices and edges:\n$\\mathcal{L}_{Simple} = E_{t,\\Theta, \\epsilon}[||V_d^{(0)} - \\hat{V}_d^{(0)}(t)|| + ||E_d^{(0)} - \\hat{E}_d^{(0)}(t)||].$\n(6)\nHere, $\\epsilon$ represents sampled noise. Leveraging variational inference, the well-known Mean Square Error (MSE) objective, derived from the evidence lower bound, is utilized to predict the denoised $V_d^{(0)}$ and $\\hat{E}_d^{(0)}$ as reconstruction targets."}, {"title": "Evaluation Metric", "content": "The F1-Score is the harmonic mean of Precision and Recall", "Recall}$\n(26)\nwhere": "n$\\bullet$ Precision = $ \\frac{TP"}, {"TP+FP}$": "The proportion of correctly predicted positive instances out of all predicted positive instances.\n$\\bullet$ Recall = $ \\frac{TP"}, {"TP+FN}$": "The proportion of correctly predicted positive instances out of all actual positive instances.\nRMSE The Root Mean Square Error is a commonly used metric for evaluating the reconstruction prediction error of a model. The formula for calculating RMSE is as follow:\n$RMSE = \\sqrt{\\frac{1"}, {"1": "death", "0": "not occurred). It is defined as the ratio of correctly ordered(concordant) pairs to comparable pairs.\n$C-index = \\frac{\\sum_{i", "j": "T_i"}]}