{"title": "Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator", "authors": ["Thinh Nguyen", "Khoa D Doan", "Binh T. Nguyen", "Danh Le-Phuoc", "Kok-Seng Wong"], "abstract": "Federated Class-Incremental Learning (FCIL) increasingly becomes important in the decentralized setting, where it enables multiple participants to collaboratively train a global model to perform well on a sequence of tasks without sharing their private data. In FCIL, conventional Federated Learning algorithms such as FedAVG often suffer from catastrophic forgetting, resulting in significant performance declines on earlier tasks. Recent works, based on generative models, produce synthetic images to help mitigate this issue across all classes, but these approaches' testing accuracy on previous classes is still much lower than recent classes, i.e., having better plasticity than stability. To overcome these issues, this paper presents Federated Global Twin Generator (FedGTG), an FCIL framework that exploits privacy-preserving generative-model training on the global side without accessing client data. Specifically, the server trains a data generator and a feature generator to create two types of information from all seen classes, and then it sends the synthetic data to the client side. The clients then use feature-direction-controlling losses to make the local models retain knowledge and learn new tasks well. We extensively analyze the robustness of FedGTG on natural images, as well as its ability to converge to flat minima and achieve better-predicting confidence (calibration). Experimental results on CIFAR-10, CIFAR-100, and tiny-ImageNet demonstrate the improvements in accuracy and forgetting measures of FedGTG compared to previous frameworks.", "sections": [{"title": "1 Introduction", "content": "Federated Learning (FL) [1, 2] is a Machine Learning setting that facilitates collaborative learning while maintaining privacy. Despite its significant achievements on various domains [3-6], FL observes several critical challenges, including resource limitation and data heterogeneity. Moreover, the client's local data distribution is assumed to remain unchanged, but the real-world scenarios [7] can be totally different, where the client's task, data, and domain can be changed, as shown in Figure 1. To overcome such challenges, Federated Class-Incremental Learning (FCIL) [8, 9] is an innovative approach that combines the principles of FL and Class-Incremental Learning (CIL) [10] to enable models to learn continuously from decentralized data sources while adapting to new information over time without forgetting previous knowledge [11]. This approach addresses data privacy challenges and ensures the model can evolve as new data types or tasks emerge without needing to access historical data. In CIL, exemplar-based approaches [10, 12, 13] preserve a limited number of samples from previous tasks to prevent forgetting, whereas exemplar-free approaches [14\u201316] do not retain any samples from prior tasks.\nDue to privacy concerns in many FL systems (e.g., hospitals and research areas), users cannot store any historical data, so the exemplar-free category is of particular interest. Recent works [17\u201319] in this field tend to generate synthetic data and combine with distilling regularizers [20, 15] to balance the trade-off between retaining knowledge and learning new tasks. However, experimental results have shown that these works still witness catastrophic forgetting, i.e., bias towards recent classes; see Figure 2a and 2b.\nTo address this problem, we propose Federated Global Twin Generator (FedGTG), an FCIL framework that does not store any data from clients. After completing one task, the server trains two generative models and shares them with clients on subsequent tasks to create synthetic examples and features of previous classes. On the client side, we propose a synthetic logit distillation using generated features for retaining knowledge, as well as a fine-tuning loss using both real and generated data to balance the ability to predict all classes. However, using only these two objectives still hinders the model's ability to obtain new knowledge, see Figure 2c. We argue that this issue happened as the feature directions were not constrained. Therefore, we add a feature-direction-controlling loss, which helps the model to have more plasticity in learning new tasks. As a result, FedGTG achieved extensive performance in terms of accuracy and forgetting measures compared to previous methods, as shown in Section 4.2.\nWe summarize our contributions below:\n\u2022 We propose an FCIL framework ensuring clients' privacy by training a data generator and a feature generator on the server side. These generators are distributed to the clients to mitigate catastrophic forgetting.\n\u2022 On the client side, we propose direction-controlling objectives to help the model have a better stability-plasticity trade-off.\n\u2022 We demonstrate the effectiveness of our method in popular benchmarks, including CIFAR-10, CIFAR-100, and tiny-ImageNet, with a 4% increase in accuracy and a 10% decrease in forgetting.\n\u2022 We analyze the robustness of FedGTG compared with recent FCIL algorithms on natural images, as well as test its abilities to converge to flat minima and achieve better predicting confidence."}, {"title": "2 Related work and preliminaries", "content": "Catastrophic forgetting [11] is a major issue in machine learning where training a model on new data makes it forget its previously learned knowledge. This issue is central to the field of CL, whose primary objective is to build models to acquire new knowledge while retaining information from older tasks. Numerous strategies have been explored to mitigate this problem, including the implementation of regularization terms [21-23], the isolation of architectural parameters [24-26], the use of experience"}, {"title": "2.1 Continual Learning", "content": "Catastrophic forgetting [11] is a major issue in machine learning where training a model on new data makes it forget its previously learned knowledge. This issue is central to the field of CL, whose primary objective is to build models to acquire new knowledge while retaining information from older tasks. Numerous strategies have been explored to mitigate this problem, including the implementation of regularization terms [21-23], the isolation of architectural parameters [24-26], the use of experience replay through data storage [10, 12, 13], and studies of data generation [14\u201316]. In CL, replay-based methods observe significant performance in terms of accuracy and forgetting measures. However, due to privacy concerns in FCIL, privacy concerns prevent data storage, making these methods inapplicable. An extensive alternative to address this issue is generative-based approaches.\nThere are three main types of learning in CL: Task-Incremental Learning (Task-IL), Domain-Incremental Learning (Domain-IL), and Class-Incremental Learning (Class-IL) [27]. In Task-IL, each task is distinct and comes with its own distribution during training and testing. In Domain-IL, the learning task does not change, while different domains or distributions of data sequentially arrive during training. In Class-IL, each new task adds new classes to what the model has to learn, which continually expands the amount of information the model needs to handle."}, {"title": "2.2 Federated Class-Incremental Learning", "content": "The goal of FCIL is to train a model to learn new classes over time without forgetting previously learned classes while also ensuring that data privacy is maintained across multiple decentralized devices. Several approaches exploit Knowledge Distillation [20] to mitigate forgetting by appointing the global model's weight of the most recent task as a teacher. Continual Federated Learning with Distillation (CFeD) [28] constructs server and client-side knowledge distillation using a surrogate dataset, but this costs time and financial resources to collect enough data for this surrogate dataset. Global-Local Forgetting Compensation (GLFC) [8] relaxes this problem by training a proxy server globally to ease the imbalance issue between classes.\nThe above approaches yield extensive performance in past knowledge retention but lack the abil- ity to learn well on new tasks. To alleviate this issue, Federated Class-Incremental Learning (FedCIL) [18] trains generators at both client-side and server-side, as well as utilizing knowledge distillation to balance the stability-plasticity trade-off. However, this approach can raise a privacy risk since information about client-side generative models is shared with the server. Federated Class- Continual Learning via Exemplar-Free Distillation (TARGET) [17] and Mimicking Federated Continual Learning (MFCL) [19] ensures clients' privacy and limited storage by training a data generator on the global-side and adding distilling regularizers to the client-side training to enhance overall performance. However, as we show in Figure 2, these methods still have bad performance on old classes, leaving catastrophic forgetting mitigation a still desirable goal."}, {"title": "2.3 Preliminaries", "content": "There are c clients, denoted as {C1, C2, . . ., Cc } and a central server, denoted as S. We consider the Synchronous Federated Continual Learning setting [29] where all clients share the same task sequence T = {T1, T2, ..., Tn}. Specifically, at task T\u2081, each client C\u2081 has a private dataset D = {X, Yt}.\nDuring the first task, the global model \u03b8 is obtained after aggregating local models {\u03b81, \u03b82,...,\u03b8} using conventional Deep Learning methods, where s\u2081 is a number of selected clients among all. From"}, {"title": "3 Metholodgy", "content": "Several approaches [10, 12, 13] in the conventional CL achieve significant predicting performance across all classes by storing a small subset of samples from previous tasks in episodic memory. However, this approach is not viable in the FL setting due to privacy concerns (e.g., local hospitals cannot share data with the central server). One initial approach to address this challenge is using generative models, which can generate synthetic data for subsequent training, as demonstrated in earlier studies [17, 19]. However, as illustrated in Figure 2, only generating synthetic examples still causes catastrophic forgetting in previously learned classes. Therefore, we propose a Federated Global Twin Generator (FedGTG), which can balance the stability-plasticity trade-off and clients' privacy. This method has two main stages: (1) At the end of each task, the server trains a data generator and a feature generator to capture the information of all seen classes; (2) Clients receive generators from the server to create synthetic information, as well as obtaining global weights as initialization, which helps retain knowledge from previous tasks and learn the new task efficiently. In the following section, we will explain these two stages of FedGTG (Figure 3)."}, {"title": "3.1 Overview", "content": "Several approaches [10, 12, 13] in the conventional CL achieve significant predicting performance across all classes by storing a small subset of samples from previous tasks in episodic memory. However, this approach is not viable in the FL setting due to privacy concerns (e.g., local hospitals cannot share data with the central server). One initial approach to address this challenge is using generative models, which can generate synthetic data for subsequent training, as demonstrated in earlier studies [17, 19]. However, as illustrated in Figure 2, only generating synthetic examples still causes catastrophic forgetting in previously learned classes. Therefore, we propose a Federated Global Twin Generator (FedGTG), which can balance the stability-plasticity trade-off and clients' privacy. This method has two main stages: (1) At the end of each task, the server trains a data generator and a feature generator to capture the information of all seen classes; (2) Clients receive generators from the server to create synthetic information, as well as obtaining global weights as initialization, which helps retain knowledge from previous tasks and learn the new task efficiently. In the following section, we will explain these two stages of FedGTG (Figure 3)."}, {"title": "3.2 Server-side", "content": "Since the server only has access to the global model's weights, we can only train the data generator using data-free methods, such as DeepInversion. Specifically, we have a generative model that takes a noise z ~ N (0, 1) as input and produces a synthetic example \u017e mirroring the dimensions of the original training input. This synthetic data should observe the following objectives."}, {"title": "3.2.1 Data Generator", "content": "Since the server only has access to the global model's weights, we can only train the data generator using data-free methods, such as DeepInversion. Specifically, we have a generative model that takes a noise z ~ N (0, 1) as input and produces a synthetic example \u017e mirroring the dimensions of the original training input. This synthetic data should observe the following objectives.\nAfter training task T\u2081, the synthetic data should be classified correctly by the global model \u03b8, and they should not be biased to any classes. With this aim, we employ a temperature cross entropy classification loss between its assigned label z and the prediction of it on G\u03b8(z) as\n$\\text{LCE} = \\text{CE}\\text{last} \\left(\\text{argmax} (z [:, q]), \\theta_G (x)\\right) + A_{\\text{current}} \\text{CE}_{\\text{current}} \\left(\\text{argmax} (z [:, q]), \\theta_G (x)\\right),$ (1)"}, {"title": "3.2.2 Feature Generator", "content": "As mentioned in Section 3.1, only synthetic images can exacerbate the catastrophic forgetting problem. To address this, we train a feature generator that synthesizes features, capturing the knowledge within the feature space. Like the data generator, this generative model is trained only on the server side. The feature generator takes noise input z ~ N (0, 1) and produces synthetic features \u0192 that match the dimensions of the original features. These synthetic features must meet the following objectives:\nAfter training task Tt, the generative feature should be classi- fied correctly by the classifier H\u03b8 of the global model. Additionally, the synthetic features should not be biased to any classes. With this aim, we employ a temperature cross entropy classification loss between its assigned label z and the prediction of H\u03b8 on G\u03b8(z) as\n$\\text{L}_{\\text{FCE}} = \\text{CE}_{\\text{last}} \\left(\\text{argmax} (z [:, q]), H_\\theta^G (f)\\right) + A_{\\text{current}} \\text{CE}_{\\text{current}} \\left(\\text{argmax} (\\text{argmax} (z [:, q]), H_\\theta^G (f)\\right),$ (6)"}, {"title": "3.3 Client-side", "content": "From task Tt>2, on the client side, we have to solve the trade-off between learning the current task quickly (plasticity) and retaining knowledge from previous tasks efficiently (stability). To this end, we divide the learning objectives into two parts.\nTo learn new tasks well, the model needs to learn the new information in a way that is separate from the old classes. To do this, we compute the Cross-Entropy Loss by using only the new classes' linear heads. Formally, we minimize:\n$\\text{LCE} = \\text{CE} \\left(\\theta^t (x | T_t), y\\right),$ (9)\nTo mitigate forgetting, previous approaches leverage knowledge distillation [33, 17]. However, this can cause information loss in probability space due to squashing functions [34]. Therefore, motivated by Buzzega et al. [13], we propose Synthetic Logits Distillation Loss, which matches the logits of the old and current linear heads. These classifiers take synthetic features as input instead of synthetic data since the feature stores more previous information. Formally, we optimize:\n$\\text{L}_{\\text{logits}} = \\left\\|\\theta_G^{t-1} (\\hat{F}) - \\theta^t (\\hat{F})\\right\\|,$ (10)\nAs shown in [13], when there is a sudden shift in the distribution of the input of the task sequence, biased features on previous tasks can output biased logits, hindering the ability to obtain new knowledge. To mitigate this shortcoming, from task Tt, we leverage synthetic data by training it alongside with real data. However, the distribution of synthetic data may vary from that of real data, making it essential to ensure the model does not distinguish between old and new data solely based on these differences. To address this problem, we only use the extracted features of the data. To tackle this issue, we utilize only the extracted features of the data, i.e., clients freeze the feature extraction layers and update only the linear head (represented by Ht) for both real (x) and synthetic (x) images. This Fine-tuning loss is formulated as\n$\\text{L}_{\\text{FT}} = \\text{CE} \\left(H^t ([f, \\hat{f}]), [y, \\hat{y}]\\right),$ (11)\nFigure 2c shows that the combination of the above objectives reduces the model's performance across all classes. We contend that this happens because the feature directions are unconstrained, resulting in the total loss failing to converge. We then further add additional loss to balance this problem, named Empirical Feature Matrix Loss [16], which constrains directions in feature space most important for previous tasks, while it allows more plasticity in other directions when learning new tasks. In this work, we re-utilize the synthetic features to calculate the Empirical Feature Matrix Et-1 from the previous task Tt\u22121. We have,\n$\\text{L}_{\\text{EFM}} = (F_t (x) - F_{\\theta^{t-1}}^G (x))^T (\\lambda E_{t-1} + \\eta I) (F_t (x) - F_{\\theta^{t-1}}^G (x)),$ (12)\nIn summary, the final objective on the client side as\n$\\min_{ \\theta_t} \\text{LCE} + A_{\\text{logits}}\\text{L}_{\\text{logits}} + A_{\\text{FT}}\\text{L}_{\\text{FT}} + A_{\\text{EFM}}\\text{L}_{\\text{EFM}}.$ (13)"}, {"title": "Plasticity", "content": "To learn new tasks well, the model needs to learn the new information in a way that is separate from the old classes. To do this, we compute the Cross-Entropy Loss by using only the new classes' linear heads. Formally, we minimize:\n$\\text{LCE} = \\text{CE} \\left(\\theta^t (x | T_t), y\\right),$ (9)\nwhere \u03b8t (x | Tt) is model's output and masking old classes before task T\u2081's linear heads."}, {"title": "Stability", "content": "To mitigate forgetting, previous approaches leverage knowledge distillation [33, 17]. However, this can cause information loss in probability space due to squashing functions [34]. Therefore, motivated by Buzzega et al. [13], we propose Synthetic Logits Distillation Loss, which matches the logits of the old and current linear heads. These classifiers take synthetic features as input instead of synthetic data since the feature stores more previous information. Formally, we optimize:\n$\\text{L}_{\\text{logits}} = \\left\\|\\theta_G^{t-1} (\\hat{F}) - \\theta^t (\\hat{F})\\right\\|,$ (10)\nwhere is the global model trained up to task Tt\u22121.\nAs shown in [13], when there is a sudden shift in the distribution of the input of the task sequence, biased features on previous tasks can output biased logits, hindering the ability to obtain new knowledge. To mitigate this shortcoming, from task Tt, we leverage synthetic data by training it alongside with real data. However, the distribution of synthetic data may vary from that of real data, making it essential to ensure the model does not distinguish between old and new data solely based on these differences. To address this problem, we only use the extracted features of the data. To tackle this issue, we utilize only the extracted features of the data, i.e., clients freeze the feature extraction layers and update only the linear head (represented by Ht) for both real (x) and synthetic (x) images. This Fine-tuning loss is formulated as\n$\\text{L}_{\\text{FT}} = \\text{CE} \\left(H^t ([f, \\hat{f}]), [y, \\hat{y}]\\right),$ (11)\nEnhancing stability-plasticity Figure 2c shows that the combination of the above objectives reduces the model's performance across all classes. We contend that this happens because the feature directions are unconstrained, resulting in the total loss failing to converge. We then further add additional loss to balance this problem, named Empirical Feature Matrix Loss [16], which constrains directions in feature space most important for previous tasks, while it allows more plasticity in other directions when learning new tasks. In this work, we re-utilize the synthetic features to calculate the Empirical Feature Matrix Et-1 from the previous task Tt\u22121. We have,\n$\\text{L}_{\\text{EFM}} = (F_t (x) - F_{\\theta^{t-1}}^G (x))^T (\\lambda E_{t-1} + \\eta I) (F_t (x) - F_{\\theta^{t-1}}^G (x)),$ (12)\nwhere Ft and F\u03b8\u00b9 respectively are the feature extractor of the current model and the previous global model, \u03b7 is the damping term to constrain features to stay in a specific region.\nIn summary, the final objective on the client side as\n$\\min_{ \\theta_t} \\text{LCE} + A_{\\text{logits}}\\text{L}_{\\text{logits}} + A_{\\text{FT}}\\text{L}_{\\text{FT}} + A_{\\text{EFM}}\\text{L}_{\\text{EFM}}.$ (13)"}, {"title": "4 Experimental results", "content": "In this section, we provide our experimental setup, including the datasets used, FCIL baselines, and implementation details."}, {"title": "4.1 Experimental Setup", "content": "In this section, we provide our experimental setup, including the datasets used, FCIL baselines, and implementation details.\nWe perform our experiments on three widely-used benchmark datasets in FCIL [8, 17, 19], which are the protocol versions in the FCIL setting of CIFAR-10 [35], CIFAR-100 [35], tiny- ImageNet [36], and we name it respectively are Sequential F-CIFAR-10, Sequential F-CIFAR-100 and Sequential F-tiny-ImageNet. The data preparation is explained later in Appendix B. We use Latent Dirichlet Allocation (LDA) [37] with \u03b1 = 1 to distribute the data of each task among clients.\nIn addition to our FedGTG, we also include one regularization-based method, FLWF-2T [33], and two generative-based methods, TARGET [17] and MFCL [19]. The detailed description of these algorithms can be seen in Appendix B.\nIn all experiments, we train a ResNet-18 [38] backbone using the SGD optimizer [39]. We train the model for 100 epochs per task on every dataset. Additional implementation details and hyper-parameter configurations are then provided in the Appendix B.\nWe report the performance of the methods using two metrics: Average Incremental Accuracy and Average Forgetting. Average Incremental Accuracy (AIA) measures the average accuracy of the global model on all tasks after the training finishes. Forgetting (ft) of task Tt is the difference between the model's best performance on task Tt and its accuracy after completed training. Consequently, Average Forgetting (AF) is the average of all ft, from task T\u2081 to task Tn\u22121, at the end of task Tn. We report the averaged result over three different random initializations."}, {"title": "Datasets", "content": "We perform our experiments on three widely-used benchmark datasets, including the FCIL version of CIFAR-10 [35], CIFAR-100 [35] and tiny-ImageNet [36]:\n\u2022 Sequential F-CIFAR-10. The CIFAR-10 dataset [35] consists of 60,000 32 \u00d7 32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. We split the training set into five disjoint subsets corresponding to 5 tasks.\n\u2022 Sequential F-CIFAR-100. Sequential F-CIFAR-100 is constructed by dividing the original CIFAR- 100 dataset [35], which contains 50,000 images belonging to 100 classes, into ten disjoint subsets corresponding to 10 tasks. In this way, each task has 5,000 images from 10 distinct categories, and each class has 500 images.\n\u2022 Sequential F-tiny-ImageNet. Tiny-ImageNet [36] is a subset of ImageNet, containing 100,000 images of 200 real objects. We follow settings in [19] to form the Sequential F-tiny-ImageNet. In particular, we split the original dataset into ten non-overlapping subsets. We consider each subset as a task whose images are labeled by 20 different classes, and each class has 500 samples."}, {"title": "FCIL Baselines", "content": "In addition to our FedGTG, we also include one regularization-based method, FLWF-2T [33], and two generative-based methods, TARGET [17] and MFCL [19]. FLWF-2T utilize knowledge distillation both on the server side and client side to ease the catastrophic forgetting issue. TARGET utilizes a global model to transfer knowledge from past tasks to the current task while also training a generator to generate synthetic data, mimicking the overall data distribution across clients. MFCL employs a generative model to create samples from previous distributions, which are then combined with training data to prevent catastrophic forgetting. Both of these algorithms ensure privacy by training the generative model on the server using data-free techniques after each task without client data retrieval."}, {"title": "Implementation Details", "content": "Table 2 shows our settings and the hyper-parameter tuning for each dataset."}, {"title": "4.2 Performance Results", "content": "We present the performance of FedGTG and the baselines. Figure 4 shows the Average Accuracy of the model at each task in the training process. It can be seen that FedGTG achieves state-of-the-art performance in all settings. Specifically, our method observes better Average Accuracy on all later tasks. Table 1 reports both AIA results (higher is better) and AF results (lower is better).\nAs expected, FedAvg and FedProx suffer the highest forgetting since they are not designed for FCIL. When compared to FLwF-2T, the performance gap between it and our FedGTG is significant, indicating that regularization towards previous parameter sets is insufficient to avoid forgetting. Compared to the generative-replay methods, TARGET and MFCL, our FedGTG achieves the least AF and the best AIA, showing that FedGTG can both retain knowledge and learn new tasks effectively."}, {"title": "4.3 Model Analysis", "content": "The majority of FCIL research concentrates on testing experiments on ideal benchmarks [8, 17, 19], such as CIFAR [35] and ImageNet [40]. This results in a lack of analysis concerning real-world scenarios, such as the decision-making ability required in hospitals or the model's generalization to diverse environments. Therefore, in this section, we conducted experiments to analyze the robustness of FedGTG and three FCIL algorithms mentioned above on corrupted environments, as well as the qualities of generalization [41-43] and achieve calibrated networks [44, 45]."}, {"title": "Robustness to natural corruptions", "content": "In the real world, autonomous cars must operate effectively in various environments, including diverse weather conditions. Therefore, it is essential for FCIL algorithms to be robust to naturally corrupted data distributions. We then evaluate our method and the recent FCIL methods on the CIFAR-100-C dataset. This dataset includes 18 augmentations of the original CIFAR-100, inspired by CIFAR-10-C [46]. Models are trained using standard CIFAR-100 with the same setting in Section 4.1 and tested on CIFAR-100-C. Figure 5 shows robustness to 09 different corruptions averaged over three different runs, the results of the rest augmentations are shown in the Appendix D. Specifically, our approach achieves higher test accuracy on various corruptions, with an average improvement of 5% over MFCL and 8% over TARGET. Evidently, our method offers noticeable advantages in robustness against natural corruption."}, {"title": "Converging to flatter minima", "content": "Extensive CL algorithms [47\u201349] explore how well their methods generalize by examining their ability to converge to flat minima. If a model obtains this quality, the loss function values LCE increase only slightly, suggesting stable model predictions and demonstrating good train-test generalization. In this part, we compare the flatness of the training minima of FLwF- 2T, TARGET, and MFCL with our approach. As done in [50], we consider the model at the end of training and add independent Gaussian noise with growing variance to each parameter. This allows us to evaluate its effect on the average loss -1 LTE across all training examples. As shown in Figures 6a and 6b, MFCL, especially FLwF-2T and TARGET, reveal higher sensitivity to perturbations than FedGTG. This result concludes that FedGTG can achieve better generalization compared to previous methods."}, {"title": "Converging to a more calibrated network", "content": "Calibration measures how well a learner's prediction confidence matches its accuracy, with ideal outcomes reflecting true probabilities of correctness. In real-world applications, including weather forecasting [51] and econometric analysis [52], the calibrating ability of an FCIL algorithm should be investigated. Figures 6c and 6d show the value of the Expected Calibration Error (ECE) [53] across various FCIL methods after completing each task. It can be seen that FedGTG achieves a lower ECE than the others. This indicates that models trained with FedGTG are less over-confident and, consequently, easier to interpret."}, {"title": "Robustness to different client sizes", "content": "We validate the effectiveness of FedGTG compared to other FCIL algorithms across different client sizes on the tiny-ImageNet dataset. We run experiments by varying the number of total clients (maintaining a consistent participation rate of 0.1 per round), ranging from 50 to 200, and compare the results. Figures 6e and 6f demonstrate that our method still outperforms other approaches, achieving an accuracy 4% higher and a forgetting rate 6% lower compared to the next best method, MFCL."}, {"title": "4.4 Limitations", "content": "In our work, clients require generative models, the global model's weight from the most previous task, and the current global model, which raises storage burdens between the server and clients. However, there are more benefits than storing actual data. First, the memory required for the generative models does not depend on the class size: as the number of classes increases, clients may need to either delete some stored examples to make space for new ones or expand their memory capacity. In contrast, the size of the generative models remains constant. Moreover, clients can remove the generative models when inactive during a specific round and retrieve them later when rejoining, whereas removing data samples leads to a permanent loss of information."}, {"title": "5 Conclusion", "content": "This study introduces an FCIL framework that tackles the constraints of limited resources and privacy concerns. We utilize data and feature generative models that have been trained by the server, eliminating the requirement for costly on-device memory for clients. Our experiments provide evidence that our strategy is successful in reducing catastrophic forgetting and surpasses the current state-of-the-art methods. This paper also analyzes the robustness of FCIL algorithms on natural images, as well as testing the qualities of converging to flat minima and calibrated networks."}, {"title": "A FedGTG algorithm", "content": "Recall that there are n tasks T1, T2, . . ., Tn. At task T\u2081, the system is trained using the conventional FedAVG algorithm for aggregating the weight from the clients in R communication rounds. At the end of every task, the server trains a data generator and a feature generator without using any information from the clients. From task T2, these two generators are sent to the clients, which combine with modified objectives to both retain knowledge and learn new tasks well. We formalize our approach in Algorithm 1 in detail. The code is available at https://github.com/lucaznguyen/FedGTG."}, {"title": "B Experimental Setup", "content": "In this section, we detail the settings used in our experiments, including datasets, FCIL algorithms, and experimental setups."}, {"title": "C Generative model setup", "content": "Figure 7 presents the architecture of the data generative models used for the Sequential F-CIFAR-10, Sequential F-CIFAR-100, and Sequential F-tiny- ImageNet dataset. In all experiments, the global model is based on the ResNet-18 backbone."}, {"title": "Data Generative Model Architecture", "content": "Figure 7 presents the architecture of the data generative models used for the Sequential F-CIFAR-10, Sequential F-CIFAR-100, and Sequential F-tiny- ImageNet dataset. In all experiments, the global model is based on the ResNet-18 backbone."}, {"title": "Feature Generative Model Architecture", "content": "The architecure of the feature generative models is illustrated in Figure 8, which employed for the Sequential F-CIFAR-10, Sequential F-CIFAR-100, and Sequential F-tiny-ImageNet datasets. As the outputs are feature vectors, only fully connected layers are needed."}, {"title": "Information generation", "content": "To create synthetic data, clients sample i.i.d. noise, which is used to determine the classes through the application of the argmax function to the first q elements, where q represents the total number of classes observed. Since the noise is sampled i.i.d., each class has an equal probability of for sample generation."}, {"title": "D Additional results", "content": "In this section, we show additional results about the robustness of testing on natural images across our method and other FCIL methods. Figure 5 shows the last 09 augmentations of the CIFAR-100 dataset averaged over three different runs. Our approach still outperforms MFCL and TARGET in terms of test accuracy."}, {"title": "E Ablation Study", "content": "In this section, we highlight the significance of each loss within our proposed framework, analyzing both server and client contributions by sequentially removing components to observe their effects. Table 3 shows our results, where each row corresponds to the removal of a specific loss component, and the columns display the corresponding Average Accuracy (At), for 1 \u2264 t \u2264 10, Average Incremental Accuracy (A), and Average Forgetting (F) from our proposed method. Specifically, we can see that the performance of the model is influenced by generative models, as poorly trained ones result in low AIA and high AF compared to others. Nevertheless, the Fine-tuning Loss has the lowest AF among all just because it did not learn tasks well (lowest AIA). The final two rows illustrate how the feature-constraining losses (Llogits and LEFM) impact the performance of the global model, where the decrease in accuracy demonstrates the importance of these two losses."}]}