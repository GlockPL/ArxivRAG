{"title": "Overcoming Catastrophic Forgetting in\nFederated Class-Incremental Learning via\nFederated Global Twin Generator", "authors": ["Thinh Nguyen", "Khoa D Doan", "Binh T. Nguyen", "Danh Le-Phuoc", "Kok-Seng Wong"], "abstract": "Federated Class-Incremental Learning (FCIL) increasingly becomes important in\nthe decentralized setting, where it enables multiple participants to collaboratively\ntrain a global model to perform well on a sequence of tasks without sharing their\nprivate data. In FCIL, conventional Federated Learning algorithms such as FedAVG\noften suffer from catastrophic forgetting, resulting in significant performance\ndeclines on earlier tasks. Recent works, based on generative models, produce\nsynthetic images to help mitigate this issue across all classes, but these approaches'\ntesting accuracy on previous classes is still much lower than recent classes, i.e.,\nhaving better plasticity than stability. To overcome these issues, this paper presents\nFederated Global Twin Generator (FedGTG), an FCIL framework that exploits\nprivacy-preserving generative-model training on the global side without accessing\nclient data. Specifically, the server trains a data generator and a feature generator\nto create two types of information from all seen classes, and then it sends the\nsynthetic data to the client side. The clients then use feature-direction-controlling\nlosses to make the local models retain knowledge and learn new tasks well. We\nextensively analyze the robustness of FedGTG on natural images, as well as its\nability to converge to flat local minima and achieve better-predicting confidence\n(calibration). Experimental results on CIFAR-10, CIFAR-100, and tiny-ImageNet\ndemonstrate the improvements in accuracy and forgetting measures of FedGTG\ncompared to previous frameworks.", "sections": [{"title": "1 Introduction", "content": "Federated Learning (FL) [1, 2] is a Machine Learning setting that facilitates collaborative learning\nwhile maintaining privacy. Despite its significant achievements on various domains [3-6], FL\nobserves several critical challenges, including resource limitation and data heterogeneity. Moreover,\nthe client's local data distribution is assumed to remain unchanged, but the real-world scenarios [7]\ncan be totally different, where the client's task, data, and domain can be changed, as shown in Figure 1.\nTo overcome such challenges, Federated Class-Incremental Learning (FCIL) [8, 9] is an innovative\napproach that combines the principles of FL and Class-Incremental Learning (CIL) [10] to enable\nmodels to learn continuously from decentralized data sources while adapting to new information over\ntime without forgetting previous knowledge [11]. This approach addresses data privacy challenges\nand ensures the model can evolve as new data types or tasks emerge without needing to access\nhistorical data. In CIL, exemplar-based approaches [10, 12, 13] preserve a limited number of samples\nfrom previous tasks to prevent forgetting, whereas exemplar-free approaches [14\u201316] do not retain\nany samples from prior tasks.\nDue to privacy concerns in many FL systems (e.g., hospitals and research areas), users cannot store\nany historical data, so the exemplar-free category is of particular interest. Recent works [17\u201319] in\nthis field tend to generate synthetic data and combine with distilling regularizers [20, 15] to balance\nthe trade-off between retaining knowledge and learning new tasks. However, experimental results\nhave shown that these works still witness catastrophic forgetting, i.e., bias towards recent classes; see\nFigure 2a and 2b.\nTo address this problem, we propose Federated Global Twin Generator (FedGTG), an FCIL\nframework that does not store any data from clients. After completing one task, the server trains two\ngenerative models and shares them with clients on subsequent tasks to create synthetic examples\nand features of previous classes. On the client side, we propose a synthetic logit distillation using\ngenerated features for retaining knowledge, as well as a fine-tuning loss using both real and generated\ndata to balance the ability to predict all classes. However, using only these two objectives still hinders\nthe model's ability to obtain new knowledge, see Figure 2c. We argue that this issue happened as\nthe feature directions were not constrained. Therefore, we add a feature-direction-controlling loss,\nwhich helps the model to have more plasticity in learning new tasks. As a result, FedGTG achieved\nextensive performance in terms of accuracy and forgetting measures compared to previous methods,\nas shown in Section 4.2.\nWe summarize our contributions below:\n\u2022 We propose an FCIL framework ensuring clients' privacy by training a data generator and a feature\ngenerator on the server side. These generators are distributed to the clients to mitigate catastrophic\nforgetting.\n\u2022 On the client side, we propose direction-controlling objectives to help the model have a better\nstability-plasticity trade-off.\n\u2022 We demonstrate the effectiveness of our method in popular benchmarks, including CIFAR-10,\nCIFAR-100, and tiny-ImageNet, with a 4% increase in accuracy and a 10% decrease in forgetting.\n\u2022 We analyze the robustness of FedGTG compared with recent FCIL algorithms on natural images,\nas well as test its abilities to converge to flat minima and achieve better predicting confidence."}, {"title": "2 Related work and preliminaries", "content": "2.1 Continual Learning\nCatastrophic forgetting [11] is a major issue in machine learning where training a model on new data\nmakes it forget its previously learned knowledge. This issue is central to the field of CL, whose primary\nobjective is to build models to acquire new knowledge while retaining information from older tasks.\nNumerous strategies have been explored to mitigate this problem, including the implementation of\nregularization terms [21-23], the isolation of architectural parameters [24-26], the use of experience"}, {"title": "2.2 Federated Class-Incremental Learning", "content": "The goal of FCIL is to train a model to learn new classes over time without forgetting previously\nlearned classes while also ensuring that data privacy is maintained across multiple decentralized\ndevices. Several approaches exploit Knowledge Distillation [20] to mitigate forgetting by appointing\nthe global model's weight of the most recent task as a teacher. Continual Federated Learning with\nDistillation (CFeD) [28] constructs server and client-side knowledge distillation using a surrogate\ndataset, but this costs time and financial resources to collect enough data for this surrogate dataset.\nGlobal-Local Forgetting Compensation (GLFC) [8] relaxes this problem by training a proxy server\nglobally to ease the imbalance issue between classes.\nThe above approaches yield extensive performance in past knowledge retention but lack the abil-\nity to learn well on new tasks. To alleviate this issue, Federated Class-Incremental Learning\n(FedCIL) [18] trains generators at both client-side and server-side, as well as utilizing knowledge\ndistillation to balance the stability-plasticity trade-off. However, this approach can raise a privacy risk\nsince information about client-side generative models is shared with the server. Federated Class-\nContinual Learning via Exemplar-Free Distillation (TARGET) [17] and Mimicking Federated\nContinual Learning (MFCL) [19] ensures clients' privacy and limited storage by training a data\ngenerator on the global-side and adding distilling regularizers to the client-side training to enhance\noverall performance. However, as we show in Figure 2, these methods still have bad performance on\nold classes, leaving catastrophic forgetting mitigation a still desirable goal."}, {"title": "2.3 Preliminaries", "content": "There are c clients, denoted as {C1, C2, . . ., Cc } and a central server, denoted as S. We consider the\nSynchronous Federated Continual Learning setting [29] where all clients share the same task sequence\nT = {T1, T2, ..., Tn}. Specifically, at task T\u2081, each client C\u2081 has a private dataset D = {X, Yt}.\nDuring the first task, the global model \u03b8 is obtained after aggregating local models {\u03b81, \u03b82,...,\u03b8}\nusing conventional Deep Learning methods, where s\u2081 is a number of selected clients among all. From"}, {"title": "3 Metholodgy", "content": "3.1 Overview\nSeveral approaches [10, 12, 13] in the conventional CL achieve significant predicting performance\nacross all classes by storing a small subset of samples from previous tasks in episodic memory.\nHowever, this approach is not viable in the FL setting due to privacy concerns (e.g., local hospitals\ncannot share data with the central server). One initial approach to address this challenge is using\ngenerative models, which can generate synthetic data for subsequent training, as demonstrated in\nearlier studies [17, 19]. However, as illustrated in Figure 2, only generating synthetic examples\nstill causes catastrophic forgetting in previously learned classes. Therefore, we propose a Federated\nGlobal Twin Generator (FedGTG), which can balance the stability-plasticity trade-off and clients'\nprivacy. This method has two main stages: (1) At the end of each task, the server trains a data\ngenerator and a feature generator to capture the information of all seen classes; (2) Clients receive\ngenerators from the server to create synthetic information, as well as obtaining global weights as\ninitialization, which helps retain knowledge from previous tasks and learn the new task efficiently. In\nthe following section, we will explain these two stages of FedGTG (Figure 3).\n3.2 Server-side"}, {"title": "3.2.1 Data Generator", "content": "Since the server only has access to the global model's weights, we can only train the data generator\nusing data-free methods, such as DeepInversion. Specifically, we have a generative model that takes\na noise z ~ N (0, 1) as input and produces a synthetic example \u017e mirroring the dimensions of the\noriginal training input. This synthetic data should observe the following objectives.\nAfter training task T\u2081, the synthetic data should be classified correctly by the global model 0, and\nthey should not be biased to any classes. With this aim, we employ a temperature cross entropy\nclassification loss between its assigned label z and the prediction of 0 (z) as\n$$L_{CE} = CE_{last} (argmax (z [:, q]), \\theta (\\tilde{x})) + \\lambda_{current}CE_{current} (argmax (z [:, q]), \\theta (\\tilde{x})),$$\nwhere x is the output of Gh (z), CElast and CEcurrent respectively are the Cross-Entropy Loss using\nthe truncated outputs of 0 (x) corresponding with last classes from task T\u2081, i < t, and current\nlearned classes on task Tt, and Acurrent is the temperature hyper-parameter.\nGenerating synthetic examples can easily be biased to a subset of classes. To maintain the diversity\nbetween classes, we utilize the Information Entropy (IE) Loss [30] as follows:\n$$L_{IE} = -H_{info} \\left(\\frac{1}{bs}\\sum_{i=1}^{bs} \\theta (X_{i})\\right),$$ bs: batch size,\nThis loss measures the IE for samples of a batch. By maximizing this value, we can promote a more\nuniform and balanced output distribution from the generator across all classes.\nIn order to further improve the stability of generator training, we use Batch Normalization Loss [31]\nto make all Batch Normalization layers have the same statistics on synthetic images, as follows:\n$$L_{batch} = \\sum_{j=1}^{L}KL \\left(N (\\tilde{\\mu}_{j}, \\tilde{\\sigma}_{j}) || N (\\mu_{j},{\\sigma}_{j})\\right),$$\nwhere L is the total number of Batch Normalization layers in the architecture of the global model. \u03bcj\nand \u03c3j are the mean and variance stored in Batch Normalization layer j of the global model, \u0169j and\n\u00d5j are measured statistics of Batch Normalization layer j for the synthetic data.\nAdjacent pixels in real images typically have values that are near to one another. One typical method\nto promote similar patterns in the synthetic images is to add Image Prior Loss [32]. We can create the\nsmoothed (blurred) version of an image by applying a Gaussian kernel and minimizing the distance\nof the original and Smooth (x) as\n$$L_{smooth} = ||\\tilde{x} - Smooth (\\tilde{x})||^{2}$$.\nIn summary, we can write the training objective of GD as follows:\n$$\\min_{GD} L_{CE} + \\lambda_{IE} L_{IE} + \\lambda_{batch} L_{batch} + \\lambda_{smooth} L_{smooth},$$\nwhere \u03bb\u0399\u0395, Abatch, and Asmooth are hyper-parameters of specific loss functions."}, {"title": "3.2.2 Feature Generator", "content": "As mentioned in Section 3.1, only synthetic images can exacerbate the catastrophic forgetting problem.\nTo address this, we train a feature generator that synthesizes features, capturing the knowledge within\nthe feature space. Like the data generator, this generative model is trained only on the server side.\nThe feature generator takes noise input z ~ N (0, 1) and produces synthetic features \u0192 that match\nthe dimensions of the original features. These synthetic features must meet the following objectives:\nTemperatured Cross Entropy Loss After training task Tt, the generative feature should be classi-\nfied correctly by the classifier H& of the global model. Additionally, the synthetic features should\nnot be biased to any classes. With this aim, we employ a temperature cross entropy classification loss\nbetween its assigned label z and the prediction of He on GF (z) as\n$$L_{FCE} = CE_{last} (argmax (z [:, q]), H_{\\theta} (\\tilde{f})) + \\lambda_{current} CE_{current} (argmax (argmax (z [:, q]), H_{\\theta} (\\tilde{f})),$$\nwhere f is the output of GF (z), CElast and CEcurrent respectively are the Cross Entropy Loss using\nthe truncated outputs of H& (f)\ncorresponding with last classes from task Ti, i < t, and current\nlearned classes on task Tt, and Acurrent is the temperature hyper-parameter.\nFeature Information Entropy Loss The generated features should also not be biased to any subset\nof classes. Therefore, we adjust the IE Loss (Equation 2) and propose the Feature Information\nEntropy Loss to make the synthetic feature have this quality, which is\n$$L_{FIE} = - H_{info} \\left(\\frac{1}{bs} \\sum_{i=1}^{bs} H_{\\theta} (\\tilde{F_{i}})\\right),$$ bs: batch size,"}, {"title": "3.3 Client-side", "content": "From task Tt>2, on the client side, we have to solve the trade-off between learning the current task\nquickly (plasticity) and retaining knowledge from previous tasks efficiently (stability). To this end,\nwe divide the learning objectives into two parts.\nPlasticity To learn new tasks well, the model needs to learn the new information in a way that is\nseparate from the old classes. To do this, we compute the Cross-Entropy Loss by using only the new\nclasses' linear heads. Formally, we minimize:\n$$L_{CE} = CE (\\theta^{+}(x | T_{t}),y),$$\nwhere 0t (x | Tt) is model's output and masking old classes before task T\u2081's linear heads.\nStability To mitigate forgetting, previous approaches leverage knowledge distillation [33, 17].\nHowever, this can cause information loss in probability space due to squashing functions [34].\nTherefore, motivated by Buzzega et al. [13], we propose Synthetic Logits Distillation Loss, which\nmatches the logits of the old and current linear heads. These classifiers take synthetic features as input\ninstead of synthetic data since the feature stores more previous information. Formally, we optimize:\n$$L_{logits} = ||\\theta_{G}^{t-1} (\\tilde{f}) - \\theta^{t} (\\tilde{f}) ||,$$\nwhere is the global model trained up to task Tt\u22121\u00b7\nAs shown in [13], when there is a sudden shift in the distribution of the input of the task sequence,\nbiased features on previous tasks can output biased logits, hindering the ability to obtain new\nknowledge. To mitigate this shortcoming, from task Tt, we leverage synthetic data by training it\nalongside with real data. However, the distribution of synthetic data may vary from that of real data,\nmaking it essential to ensure the model does not distinguish between old and new data solely based on\nthese differences. To address this problem, we only use the extracted features of the data. To tackle\nthis issue, we utilize only the extracted features of the data, i.e., clients freeze the feature extraction\nlayers and update only the linear head (represented by Ht) for both real (x) and synthetic (x) images.\nThis Fine-tuning loss is formulated as\n$$L_{FT} = CE (H^{t} ([f, \\tilde{f}]), [y,\\tilde{y}]),$$\nwhere f and f respectively are the extracted features of x and i after passing through the freezed\nfeature extractor Ft of the local model, y and \u1ef9 is the hard label of x and .\nEnhancing stability-plasticity Figure 2c shows that the combination of the above objectives\nreduces the model's performance across all classes. We contend that this happens because the feature\ndirections are unconstrained, resulting in the total loss failing to converge. We then further add\nadditional loss to balance this problem, named Empirical Feature Matrix Loss [16], which constrains\ndirections in feature space most important for previous tasks, while it allows more plasticity in other\ndirections when learning new tasks. In this work, we re-utilize the synthetic features to calculate the\nEmpirical Feature Matrix Et-1 from the previous task Tt\u22121. We have,\n$$L_{EFM} = (F^{t} (x) - F_{G}^{t-1} (x))^{T} (\\lambda E_{t-1} + \\eta I) (F^{t} (x) - F_{G}^{t-1} (x)),$$\nwhere Ft and F&\u00b9 respectively are the feature extractor of the current model and the previous global\nmodel, \u03b7 is the damping term to constrain features to stay in a specific region.\nIn summary, the final objective on the client side as\n$$\\min_{\\theta^{t}} L_{CE} + \\lambda_{logits}L_{logits} + \\lambda_{FT}L_{FT} + \\lambda_{EFM}L_{EFM}.$$"}, {"title": "4 Experimental results", "content": "4.1 Experimental Setup\nIn this section, we provide our experimental setup, including the datasets used, FCIL baselines, and\nimplementation details.\nDatasets We perform our experiments on three widely-used benchmark datasets in FCIL [8, 17, 19],\nwhich are the protocol versions in the FCIL setting of CIFAR-10 [35], CIFAR-100 [35], tiny-\nImageNet [36], and we name it respectively are Sequential F-CIFAR-10, Sequential F-CIFAR-100\nand Sequential F-tiny-ImageNet. The data preparation is explained later in Appendix B. We use\nLatent Dirichlet Allocation (LDA) [37] with \u03b1 = 1 to distribute the data of each task among clients.\nFCIL Baselines In addition to our FedGTG, we also include one regularization-based method,\nFLWF-2T [33], and two generative-based methods, TARGET [17] and MFCL [19]. The detailed\ndescription of these algorithms can be seen in Appendix B.\nModels and Implementation Details In all experiments, we train a ResNet-18 [38] backbone using\nthe SGD optimizer [39]. We train the model for 100 epochs per task on every dataset. Additional\nimplementation details and hyper-parameter configurations are then provided in the Appendix B.\nEvaluation Metrics We report the performance of the methods using two metrics: Average\nIncremental Accuracy and Average Forgetting. Average Incremental Accuracy (AIA) measures the\naverage accuracy of the global model on all tasks after the training finishes. Forgetting (ft) of task Tt\nis the difference between the model's best performance on task Tt and its accuracy after completed\ntraining. Consequently, Average Forgetting (AF) is the average of all ft, from task T\u2081 to task Tn\u22121,\nat the end of task Tn. We report the averaged result over three different random initializations."}, {"title": "4.2 Performance Results", "content": "We present the performance of FedGTG and the baselines. Figure 4 shows the Average Accuracy of\nthe model at each task in the training process. It can be seen that FedGTG achieves state-of-the-art"}, {"title": "4.3 Model Analysis", "content": "The majority of FCIL research concentrates on testing experiments on ideal benchmarks [8, 17, 19],\nsuch as CIFAR [35] and ImageNet [40]. This results in a lack of analysis concerning real-world\nscenarios, such as the decision-making ability required in hospitals or the model's generalization to\ndiverse environments. Therefore, in this section, we conducted experiments to analyze the robustness\nof FedGTG and three FCIL algorithms mentioned above on corrupted environments, as well as the\nqualities of generalization [41-43] and achieve calibrated networks [44, 45].\nRobustness to natural corruptions In the real world, autonomous cars must operate effectively\nin various environments, including diverse weather conditions. Therefore, it is essential for FCIL\nalgorithms to be robust to naturally corrupted data distributions. We then evaluate our method and the\nrecent FCIL methods on the CIFAR-100-C dataset. This dataset includes 18 augmentations of the\noriginal CIFAR-100, inspired by CIFAR-10-C [46]. Models are trained using standard CIFAR-100\nwith the same setting in Section 4.1 and tested on CIFAR-100-C. Figure 5 shows robustness to\n09 different corruptions averaged over three different runs, the results of the rest augmentations\nare shown in the Appendix D. Specifically, our approach achieves higher test accuracy on various\ncorruptions, with an average improvement of 5% over MFCL and 8% over TARGET. Evidently, our\nmethod offers noticeable advantages in robustness against natural corruption.\nConverging to flatter minima Extensive CL algorithms [47\u201349] explore how well their methods\ngeneralize by examining their ability to converge to flat minima. If a model obtains this quality, the\nloss function values LCE increase only slightly, suggesting stable model predictions and demonstrating\ngood train-test generalization. In this part, we compare the flatness of the training minima of FLwF-\n2T, TARGET, and MFCL with our approach. As done in [50], we consider the model at the end\nof training and add independent Gaussian noise with growing variance to each parameter. This\nallows us to evaluate its effect on the average loss -1 LTE across all training examples. As\nshown in Figures 6a and 6b, MFCL, especially FLwF-2T and TARGET, reveal higher sensitivity to\nperturbations than FedGTG. This result concludes that FedGTG can achieve better generalization\ncompared to previous methods.\nConverging to a more calibrated network Calibration measures how well a learner's prediction\nconfidence matches its accuracy, with ideal outcomes reflecting true probabilities of correctness.\nIn real-world applications, including weather forecasting [51] and econometric analysis [52], the"}, {"title": "4.4 Limitations", "content": "In our work, clients require generative models, the global model's weight from the most previous task,\nand the current global model, which raises storage burdens between the server and clients. However,\nthere are more benefits than storing actual data. First, the memory required for the generative models\ndoes not depend on the class size: as the number of classes increases, clients may need to either delete\nsome stored examples to make space for new ones or expand their memory capacity. In contrast, the\nsize of the generative models remains constant. Moreover, clients can remove the generative models\nwhen inactive during a specific round and retrieve them later when rejoining, whereas removing data\nsamples leads to a permanent loss of information."}, {"title": "5 Conclusion", "content": "This study introduces an FCIL framework that tackles the constraints of limited resources and\nprivacy concerns. We utilize data and feature generative models that have been trained by the server,\neliminating the requirement for costly on-device memory for clients. Our experiments provide\nevidence that our strategy is successful in reducing catastrophic forgetting and surpasses the current\nstate-of-the-art methods. This paper also analyzes the robustness of FCIL algorithms on natural\nimages, as well as testing the qualities of converging to flat minima and calibrated networks."}, {"title": "A FedGTG algorithm", "content": "Recall that there are n tasks T1, T2, . . ., Tn. At task T\u2081, the system is trained using the conventional\nFedAVG algorithm for aggregating the weight from the clients in R communication rounds. At the end\nof every task, the server trains a data generator and a feature generator without using any information\nfrom the clients. From task T2, these two generators are sent to the clients, which combine with\nmodified objectives to both retain knowledge and learn new tasks well. We formalize our approach in\nAlgorithm 1 in detail. The code is available at https://github.com/lucaznguyen/FedGTG.\nAlgorithm 1 Federated Global Twin Generator\n1: Input:\n2:n tasks with n datasets {D1, D2, . . ., Dn}.\n3: c clients with c local models 0, R communication rounds.\n4: A global model G, a data generator GD and a feature generator GF.\n5: Procedure:\n6: fort=1 to T do\n7:\nfor r = 1 to R do\nEach task is learned on several communication rounds\n8:\nSelect k clients for training.\n9:\nif r 1 ort > 1 then\n10:\nThe server sends the global model's weight to selected clients.\n11:\nif t > 1 then\n12:\nThe server sends the two generators, the global model's weight from the previous\ntask and the Empirical Feature Matrix to selected clients.\n13:\nend if\n14:\nend if\n15:\nift = 1 then\n16:\nTrain local models (tr) conventionally.\n17:\nelse\n1\u2264 j \u2264 k\n18:\nTrain local models (tr) using Algorithm 2.\n19:\nend if\n20:\nAggregate local model updates to the server.\n21:\nend for\n22:\nTrain the data generator and the feature generator.\n23:\nCalculate Empirical Feature Matrix Et using synthetic features.\n24:\nend for\nAlgorithm 2 Client-side: Continual Learning\n1: Input:\n2: Task Tt, t\u2265 2 with the dataset Dt in round r has B batches.\n(t,r)\n3: The global model \u03b8'1), a data generator G\u0127\u00b9, a feature generator GF1.\n4: The freezed global weight\n0-1) and the Empirical Feature Matrix Et-1.\n5: Procedure:\n6: Calculate the Current Cross-Entropy Loss LCE using Dt and Equation 9.\n7: Generate synthetic data Ds and synthetic features Fs having B batches each.\n8: Calculate the Fine-tunig Loss LFT using Dt, Ds and Equation 11.\n9: Calculate the Synthetic Logits Distillation Loss Llogits using Fs and Equation 10.\n10: Calculate the EFM LOSS LEFM using Fs and Equation 12.\n11: Optimize Equation 13."}, {"title": "B Experimental Setup", "content": "In this section, we detail the settings used in our experiments, including datasets, FCIL algorithms,\nand experimental setups."}, {"title": "C Generative model setup", "content": "Data Generative Model Architecture Figure 7 presents the architecture of the data generative\nmodels used for the Sequential F-CIFAR-10, Sequential F-CIFAR-100, and Sequential F-tiny-\nImageNet dataset. In all experiments, the global model is based on the ResNet-18 backbone.\nFeature Generative Model Architecture The architecure of the feature generative models is\nillustrated in Figure 8, which employed for the Sequential F-CIFAR-10, Sequential F-CIFAR-100,\nInformation generation To create synthetic data, clients sample i.i.d. noise, which is used to\ndetermine the classes through the application of the argmax function to the first q elements, where q\nrepresents the total number of classes observed. Since the noise is sampled i.i.d., each class has an\nequal probability of for sample generation."}, {"title": "D Additional results", "content": "In this section, we show additional results about the robustness of testing on natural images across\nour method and other FCIL methods. Figure 5 shows the last 09 augmentations of the CIFAR-100\ndataset averaged over three different runs. Our approach still outperforms MFCL and TARGET in\nterms of test accuracy."}, {"title": "E Ablation Study", "content": "In this section, we highlight the significance of each loss within our proposed framework, analyzing\nboth server and client contributions by sequentially removing components to observe their effects.\nTable 3 shows our results, where each row corresponds to the removal of a specific loss component,\nand the columns display the corresponding Average Accuracy (At), for 1 \u2264 t \u2264 10, Average\nIncremental Accuracy (A), and Average Forgetting (F) from our proposed method. Specifically, we\ncan see that the performance of the model is influenced by generative models, as poorly trained ones\nresult in low AIA and high AF compared to others. Nevertheless, the Fine-tuning Loss has the lowest\nAF among all just because it did not learn tasks well (lowest AIA). The final two rows illustrate how\nthe feature-constraining losses (Llogits and LEFM) impact the performance of the global model, where\nthe decrease in accuracy demonstrates the importance of these two losses."}]}