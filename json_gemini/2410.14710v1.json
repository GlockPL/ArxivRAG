{"title": "G2D2: GRADIENT-GUIDED DISCRETE DIFFUSION\nFOR IMAGE INVERSE PROBLEM SOLVING", "authors": ["Naoki Murata", "Chieh-Hsin Lai", "Yuhta Takida", "Toshimitsu Uesaka", "Bac Nguyen", "Stefano Ermon", "Yuki Mitsufuji"], "abstract": "Recent literature has effectively leveraged diffusion models trained on continu-\nous variables as priors for solving inverse problems. Notably, discrete diffusion\nmodels with discrete latent codes have shown strong performance, particularly\nin modalities suited for discrete compressed representations, such as image and\nmotion generation. However, their discrete and non-differentiable nature has lim-\nited their application to inverse problems formulated in continuous spaces. This\npaper presents a novel method for addressing linear inverse problems by leverag-\ning image-generation models based on discrete diffusion as priors. We overcome\nthese limitations by approximating the true posterior distribution with a variational\ndistribution constructed from categorical distributions and continuous relaxation\ntechniques. Furthermore, we employ a star-shaped noise process to mitigate the\ndrawbacks of traditional discrete diffusion models with absorbing states, demon-\nstrating that our method performs comparably to continuous diffusion techniques.\nTo the best of our knowledge, this is the first approach to use discrete diffusion\nmodel-based priors for solving image inverse problems.", "sections": [{"title": "1 INTRODUCTION", "content": "Diffusion models have gained significant attention as deep generative models, achieving remarkable\nsuccess in image (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021; Dhariwal & Nichol,\n2021; Esser et al., 2024), audio (Liu et al., 2023; Chen et al., 2024a), and video generation (Ho\net al., 2022b;a). These models operate by iteratively corrupting data then learning to reverse this\ncorruption process, ultimately generating high-quality samples from noise. In parallel with contin-\nuous diffusion models, discrete diffusion models have emerged as a compelling alternative. These\nmodels have gained traction by demonstrating notable results not only in image (Gu et al., 2022),\naudio (Yang et al., 2023), and text generation (Austin et al., 2021; Lou et al., 2023a) but also in more\nspecialized areas such as motion data (Lou et al., 2023b; Pinyoanuntapong et al., 2024), protein\nsynthesis (Gruver et al., 2024), and graph generation (Vignac et al., 2023).\nBuilding on these advancements, researchers have made significant progress in expanding the ap-\nplication of diffusion models. They have explored using diffusion models, trained either directly on\npixel space or on latent representations derived from variational autoencoders (VAEs), to address\ninverse problems (Kawar et al., 2022; Chung et al., 2023; Wang et al., 2023) and carry out vari-\nous conditional-generation tasks (Yu et al., 2023; Bansal et al., 2024; He et al., 2024) without the\nneed for additional training. These efforts aim to use the powerful generative capabilities of diffu-\nsion models to tackle intricate problems and generate conditional outputs, all while preserving the\nmodels' original trained parameters.\nThis line of work has been primarily restricted to diffusion models trained in continuous spaces, and\nmethods using trained discrete diffusion models as priors remain limited Gruver et al. (2024); Chen\net al. (2024b); Li et al. (2024). The inherent nature of the generation process in discrete diffusion\nmodels involves non-differentiable operations, posing a challenge for their application to inverse\nproblems formulated in continuous spaces. Therefore, controlling discrete diffusion models often\nnecessitates an additional trained network (Gruver et al., 2024; Nisonoff et al., 2024; Klarner et al.,"}, {"title": "2 PRELIMINARIES", "content": "We first provide a brief overview of VQ-Diffusion (Gu et al., 2022; Tang et al., 2022), an image-\ngeneration model based on discrete diffusion processes. VQ-Diffusion generates images in a two-\nstep process. It first produces discrete latent representations zo using a discrete diffusion model\ntrained on representations obtained from a pre-trained VQ-VAE model (Van Den Oord et al., 2017).\nIt then transforms these representations into the continuous image space using a decoder. Each\nelement of zo \u2208 {1,...,K}dz corresponds to one of the embedding vectors from the codebook,\ndenoted as B := {b\u2081,...,bK},bk \u2208 Rdb. During decoding, a variable Z \u2208 Bdz is constructed\nthrough codebook assignment, where (Z); = bzo, and 20,i denotes the i-th element of zo. This\nvariable is then fed into a continuous decoder D : Rdbxdz \u2192 Rdxo to obtain the final image:\nX0 = D(Z).\nIn discrete diffusion models, a forward Markov process gradually corrupts the discrete latent rep-\nresentation zo, and a reverse process is learned to invert this process. A single step of the forward\nprocess of the Markov chain zo \u2192 \u2026 \u2192 Z\u0165 \u2192 \u2026\u2026 \u2192 z\u012b can be represented as,\nq(2t,iZt-1) = VT (Zt,i)Qtv (zt\u22121,i),\n(1)\nwhere v(zt,i) denotes a one-hot encoded vector representing the token at time step t, and Qt rep-\nresents the transition matrix, which determines the probabilities of transitions between tokens. VQ-\nDiffusion uses a mask-absorbing-type forward process, which introduces a special masked token\ndenoted as [MASK] in addition to the K states from the VQ-VAE. The transition matrix is defined\nas\nQt=\n \n(2)\nwhere the transition probabilities are determined by three parameters: at, \u00dft, and Yt. Specifically, at\nrepresents the probability of a token remaining unchanged, Bt denotes the probability of transitioning\nto a different unmasked token, and Yt indicates the probability of the token being replaced with the\n[MASK] token. The probability \u1e9et between unmasked tokens is generally set to a very small value.\nDuring inference, the latent variable zo corresponding to the clean image is obtained by executing\nthe following reverse process:\n(3)\nwhere q(Zt-1|Zt, zo) represents the posterior distribution determined by the forward process, and pe\ndenotes the denoising network that predicts the denoised token distribution at t. The output of pe\nis generally modeled as independent categorical distributions for each dimension in zo. In text-to-\nimage models such as VQ-Diffusion, pe is trained with text conditioning. While the true distribution\nq(zo) is not dimensionally independent, the whole Markov reverse process in (3) produces a distri-\nbution over categorical variables with correlations across dimensions. We distinguish between the"}, {"title": "2.1 DISCRETE DIFFUSION MODELS FOR IMAGE GENERATION", "content": "We first provide a brief overview of VQ-Diffusion (Gu et al., 2022; Tang et al., 2022), an image-\ngeneration model based on discrete diffusion processes. VQ-Diffusion generates images in a two-\nstep process. It first produces discrete latent representations zo using a discrete diffusion model\ntrained on representations obtained from a pre-trained VQ-VAE model (Van Den Oord et al., 2017).\nIt then transforms these representations into the continuous image space using a decoder. Each\nelement of zo \u2208 {1,...,K}dz corresponds to one of the embedding vectors from the codebook,\ndenoted as B := {b\u2081,...,bK},bk \u2208 Rdb. During decoding, a variable Z \u2208 Bdz is constructed\nthrough codebook assignment, where (Z); = bzo, and 20,i denotes the i-th element of zo. This\nvariable is then fed into a continuous decoder D : Rdbxdz \u2192 Rdxo to obtain the final image:\nX0 = D(Z).\nIn discrete diffusion models, a forward Markov process gradually corrupts the discrete latent rep-\nresentation zo, and a reverse process is learned to invert this process. A single step of the forward\nprocess of the Markov chain zo \u2192 \u2026 \u2192 Z\u0165 \u2192 \u2026\u2026 \u2192 z\u012b can be represented as,\nq(2t,iZt-1) = VT (Zt,i)Qtv (zt\u22121,i),\nwhere v(zt,i) denotes a one-hot encoded vector representing the token at time step t, and Qt rep-\nresents the transition matrix, which determines the probabilities of transitions between tokens. VQ-\nDiffusion uses a mask-absorbing-type forward process, which introduces a special masked token\ndenoted as [MASK] in addition to the K states from the VQ-VAE. The transition matrix is defined\nas\nQt=\n \nwhere the transition probabilities are determined by three parameters: at, \u00dft, and Yt. Specifically, at\nrepresents the probability of a token remaining unchanged, Bt denotes the probability of transitioning\nto a different unmasked token, and Yt indicates the probability of the token being replaced with the\n[MASK] token. The probability \u1e9et between unmasked tokens is generally set to a very small value.\nDuring inference, the latent variable zo corresponding to the clean image is obtained by executing\nthe following reverse process:\n(3)\nwhere q(Zt-1|Zt, zo) represents the posterior distribution determined by the forward process, and pe\ndenotes the denoising network that predicts the denoised token distribution at t. The output of pe\nis generally modeled as independent categorical distributions for each dimension in zo. In text-to-\nimage models such as VQ-Diffusion, pe is trained with text conditioning. While the true distribution\nq(zo) is not dimensionally independent, the whole Markov reverse process in (3) produces a distri-\nbution over categorical variables with correlations across dimensions. We distinguish between the"}, {"title": "2.2 LINEAR-INVERSE-PROBLEM SETTINGS", "content": "Inverse problems involve estimating unknown data from measurement data. We specifically focus\non linear inverse problems in the image domain. The relationship between the measurement image\ny \u2208 Rdy and unknown ground-truth image x0 \u2208 Rdxo can be represented as\ny \u0391\u03c7\u03bf + \u03b7,\n(4)\nwhere A \u2208 RdyXdxo_is referred to as the forward linear operator, which describes the process by\nwhich the measurement data y are obtained from data x0. We assume this operator is known. The\nterm \u03b7 represents measurement noise, which we assume follows an isotropic Gaussian distribution\nwith a known variance on. Consequently, the likelihood function q(y|x0) can be described as\n\u039d(y; \u0391\u03c7\u03bf, \u03c3\u03b7\u0399).\nOne of the primary challenges in inverse problems is their ill-posed nature. This means that for any\ngiven measurement y, multiple candidate solutions may exist. To address this issue and determine\nx0, a common approach is to assume a prior distribution for xo, such as a Laplace distribution.\nDiffusion models have been utilized as more powerful and expressive priors, offering enhanced\ncapabilities in solving these inverse problems (Kawar et al., 2022; Chung et al., 2023; Wang et al.,\n2023; Rout et al., 2023). These methods are able to produce images that not only fit the measurement\ndata but also exhibit high likelihood for the prior model. Given a prior q(x0), the objective in the\ninverse problem is to sample from the posterior distribution q(xoy), which, according to Bayes'\ntheorem, is proportional to q(y|xo)q(x0).\nThese methods can be categorized based on how they incorporate the information from the mea-\nsurement data y into the generation trajectory of diffusion models. Methods such as denoising\ndiffusion restoration models (DDRM) (Kawar et al., 2022) and denoising diffusion null-space mod-\nels (DDNM) (Wang et al., 2023) leverage the assumption of linear operators, using singular value\ndecomposition of the forward process to control the generative process. In contrast, methods such\nas diffusion posterior sampling (DPS) (Chung et al., 2023) and posterior sampling with latent dif-\nfusion (PSLD) (Rout et al., 2023) operate by propagating the gradient of a loss term through the\ngenerative process. This loss term is designed to maximize the measurement likelihood, specifically\nby minimizing the term ||y \u2013 Axo||2.\nHowever, the application of these methods to generative models that use discrete diffusion models\nas priors is not straightforward. This limitation stems from two primary factors. First, with the\nformer methods, diffusion models are assumed trained in the pixel domain. Second, while the\nlatter methods can be extended to latent diffusion-type models, they encounter difficulties when\nhandling discrete diffusion models, in which the generative process is inherently discrete. The core\nchallenge lies in the lack of a direct mechanism to propagate gradients of the loss function through\nthe generative process in discrete diffusion models. In such models, after generating discrete data,\na non-differentiable operation (i.e., codebook assignment) is followed by a decoding operation into\ncontinuous space, which prevents the application of conventional gradient-based guidance."}, {"title": "3 GRADIENT-GUIDED DISCRETE DIFFUSION, G2D2", "content": "Besides the lack of a straightforward mechanism to propagate gradients of the loss function through\nthe generative process, a preliminary study reveals another main issue of directly applying the graph-\nical model of a general mask-absorbing discrete diffusion model to sampling in an inverse-problem\ncontext. Figure 2 shows images decoded from zo, which are sampled from the denoising model\nPo (Zo zt) conditioned on the intermediate noisy discrete latent Z90 or z80, along with the generated\nimage from the full reverse process. These images are generated using a pre-trained VQ-Diffusion\nmodel (Gu et al., 2022) with the prompt \"A face of monkey\" (where T = 100). The results indicate\nthat the majority of the image structure is determined within the initial approximately 10% of the\nsteps."}, {"title": "3.1 STAR-SHAPED NOISE PROCESS FOR INVERSE PROBLEM SOLVING", "content": "Inspired by Okhotin et al. (2024) and Zhang\net al. (2024), G2D2 employs the star-shaped\nnoise process. Figure 3 illustrates the differ-\nences between the Markov forward noise pro-\ncess (upper), which is used in general dis-\ncrete diffusion models, and the star-shaped\nnoise process (lower), both incorporating the\nrelationship with the measurement y. In the\nstar-shaped noise process, the noisy discrete\nlatents Z1,..., zT are conditionally indepen-\ndent given zo. We assume that the distri-\nbution q(zt zo) adopts the same form as the\noriginal forward_Markov process, specifically\nq(zt,izo) = v(zt,i)Qtv(20,i), with Qt =Q1.\nWe aim to sample from the posterior q(zoly)\ngiven the measurement y based on this graphi-\ncal model. Given that the transformation from\nZo to xo is nearly deterministic in general decoders, we omit the random variable x0 in the subse-\nquent discussion for simplicity.\nTo discuss the implementation of the sampling method based on the graphical model, we first intro-\nduce the conditional joint distribution qsampling (Zo:Ty) = q(Z\u0442\u0443) \u041f-19(Zt-1|Zt, y). This condi-\ntional joint distribution has several properties:\n1. A single step of qsampling inherently enables the \u201cre-masking\u201d operation. In the star-shaped\nnoise process, the positions of mask tokens in zt-1 and zt are mutually independent and uncorre-\nlated. Consequently, the conditional distribution q(Zt-1|zt, y) enables a \u201cre-masking\" operation,\nwherein unmasked tokens present in zt can become masked tokens in zt. This property suggests"}, {"title": "3.2 G2D2 BASED ON STAR-SHAPED NOISE PROCESS", "content": "Based on the discussion in the previous section, we aim to implement qsampling on the graphical model\nof the star-shaped noise process, which inherently incorporates a re-masking process. Specifically,\nwe introduce a variational distribution pa (Zo:T|y) to approximate qsampling (Z0:T|y), with the ultimate\ngoal of ensuring that the marginal distribution pa (zoly) approximates the true posterior q(zo|y).\nThe distribution pa is decomposed as\nPa(Zt-1/Zt, y) = \u2211 q(Zt-1|Zo)Pa (ZoZt, y),\n(5)\nwhere pa (ZoZt, y) is a categorical distribution parameterized by a \u2208 RT\u00d7dz\u00d7K, defined as\nPa(20,izt, y) = Cat (20,i; at,i,.), i.e., Pa(zo,i = k|zt, y) = At,i,k. This decomposition stems from\nthe fact that the distribution q(zt\u22121|zt, y) can be expressed as \u2211zo q(Zt-1|Zo)q(Zo|zt, y) based on\nthe conditional independence. Note that both q(zt-1|Zo) and pa(Zo|zt, y) have a mean field struc-\nture with independent categorical distributions across dimensions. Consequently, Pa (Zt-1|Zt, y),\nobtained by marginalizing over zo, inherits this mean field property. For notational convenience, we\ndenote the slice of distribution parameter a at time step tas at \u2208 Rdz\u00d7K.\nIn G2D2, the variational distribution pa is obtained by optimizing an objective function derived\nfrom the following theorem:\nTheorem 3.1. Let pa be a distribution with the parameterization given by the decomposition in (5).\nThen, for any measurement y, the following inequality holds for the Kullback-Leibler (KL) diver-\ngence between the marginal distributions:\nDKL (Pa(Zoy)||q(Zoy)) \u2264 Ezt Pa (zely) [DKL (Pa(Zo|Zt, y)||q(Zo|Zt, y))] . (6)\nThe full definitions of the terms are provided in the Appendix."}, {"title": "3.3 IMPLEMENTATION CONSIDERATIONS", "content": "We use the Gumbel-Softmax trick (Jang et al., 2016; Maddi-\nson et al., 2016) to make the computation of the second term in (7) differentiable. At time step\nt, this process begins by generating Gumbel-Softmax samples using parameters of pa as follows:\n20,i,k softmax ((log at,i,k + gi,k)/T), where gi,k represents samples drawn from the Gumbel\ndistribution, and T is the temperature parameter. This procedure generates a \"soft\" categorical\nsample for each dimension in zo, indicating the proportional selection of each codebook element.\nAs these proportions correspond to the contribution rate of each codebook element, we construct\nZGumbel \u2208 Rdzxdb as their weighted sum: (ZGumbel)i = \u03a3\u03ba=120,i,kbk. Finally, we pass ZGumbel\nthrough the decoder to obtain the image x0 = D(ZGumbel). By substituting this image into the\nlikelihood function q(y|x0), we have the differentiable objective with respect to the variational pa-\nrameter at, enabling continuous optimization. For linear inverse problems, the objective function\nwill include the term ||y - Axo(at)||2, excluding the constant term derived from measurement\nnoise.\nAt time step t, we are required to optimize the variational\nparameter at. To expedite this process, we can leverage the optimized values from the previous time\nstep as the initialization for the optimization process, effectively reducing the number of required\noptimization steps. To achieve this, we introduce a forgetting coefficient y and initialize at through"}, {"title": "3.4 APPLICATION OF G2D2 TO MASKED GENERATIVE MODELS", "content": "As discussed in (Zheng et al., 2024), mask-absorbing discrete diffusion models and masked genera-\ntive models, such as MaskGIT (Chang et al., 2022), share a similar framework. Except for temporal\nconditioning, these models are nearly identical and are trained to approximate q(zo|zt). Therefore,\nG2D2 can be straightforwardly applied to masked generative models. We give an example of solving\ninverse problems using a masked generative model as a prior model for motion data in the following\nsection."}, {"title": "4 EXPERIMENTS", "content": "We evaluate G2D2 on inverse problems in image processing and compare it with other diffusion\nmodel-based inverse-problem-solving methods. We also demonstrate gradient-based guidance on a\ndiscrete-latent variable-based motion-domain generative model without additional training, showing\nthe applicability of G2D2 to other domains."}, {"title": "4.1 EXPERIMENTAL SETUP", "content": "We evaluate G2D2 on inverse problems in image processing and compare it with other diffusion\nmodel-based inverse-problem-solving methods. We also demonstrate gradient-based guidance on a\ndiscrete-latent variable-based motion-domain generative model without additional training, showing\nthe applicability of G2D2 to other domains."}, {"title": "Image inverse problems and evaluation metrics", "content": "We conduct experiments on two tasks: (1)\nsuper-resolution (SR) and (2) Gaussian deblurring. For the SR task, the linear forward operator\ndownscales the image by a factor of 4 using a bicubic resizer. For the Gaussian-deblurring task, we\nset the kernel size to 61 \u00d7 61 with a Gaussian kernel standard deviation of 3.0. The measurements\nare obtained by applying the forward operator to the ground truth images normalized to the range\n[-1,1], followed by the addition of Gaussian noise with a standard deviation of 0.05. As metrics,\nwe use the learned perceptual image patch similarity (LPIPS) (Zhang et al., 2018) score to measure\nperceptual proximity to the original image, and the peak signal-to-noise ratio (PSNR) to measure\nthe closeness of the signal."}, {"title": "4.2 IMAGE INVERSE PROBLEM SOLVING ON IMAGENET AND FFHQ", "content": "Figure 5 shows the qualitative results of image inverse problem solving, and Tables 1 and 2 list\nthe quantitative results. G2D2 performs comparably to the other methods using diffusion models\ntrained in the continuous domain. Note that the pre-trained models used for each method are dif-\nferent, which particularly contributes to the superiority of pixel-domain methods on FFHQ. With\nDDRM, it is assumed that the amount of measurement noise is known and require the singular value\ndecomposition of the linear operator. We also show images in the intermediate phase of the G2D2\nalgorithm in Figure 4."}, {"title": "4.3 ABLATION STUDY ON GRAPHICAL MODELS", "content": "It is possible to derive a similar algorithm to G2D2 that uses a Markov noise process as the graphical\nmodel. However, as discussed at the beginning of Section 3, this graphical model does not allow"}, {"title": "4.4 MOTION INVERSE PROBLEM SOLVING", "content": "As discussed in Section 3.4, our method can also be applied to\nMasked generative models. We conduct experiments to manipulate\nGenerative Masked Motion Model (MMM) Pinyoanuntapong et al.\n(2024), a generative model for motion data, using gradient guid-\nance. Specifically, we perform a path following task where gen-\neration is conditioned on the position information of the hip joint.\nSince joint position information can be calculated from motion data,\nthis can also be treated within the framework of inverse problems.\nWhile there have been examples of achieving path following in mo-\ntion generation models with continuous latent spaces (Song et al.,\n2023b; Uchida et al., 2024), we are the first to accomplish this us-\ning a motion generation model with discrete latent variables in a\ntraining-free manner. Appendix C.9 provides additional samples\nand detailed experimental information."}, {"title": "5 CONCLUSION", "content": "We proposed G2D2 for solving inverse problems using discrete diffusion models as priors. We\ndemonstrated that G2D2 effectively addresses the limitation of discrete diffusion in inverse problem-\nsolving by using a continuous relaxation technique and star-shaped noise process. Specifically,\nG2D2 approximates the posterior in inverse problems by optimizing the parameters of a variational\ndistribution, composed of parameterized categorical distributions, at each time step of the diffusion\nprocess. Our experiments show that G2D2 performs comparable to its continuous counterparts,\nopening up possibilities for training-free applications of discrete diffusion models across a wide\nrange of tasks."}, {"title": "Limitations and future works", "content": "G2D2 does not significantly surpass its continuous counterparts in\nterms of computational speed or performance. We anticipate that these limitations can be mitigated\nthrough the optimization of efficiency and the enhancement of prior models. The application to\nmore complex problem settings, including nonlinear inverse problems, as well as to other domains\nsuch as audio and video, constitutes future work."}, {"title": "Ethics statement", "content": "Our G2D2 method, which uses discrete diffusion models as priors for solving\ninverse problems, carries potential risks similar to those of previously proposed techniques in this\nfield. We acknowledge that these methods, including ours, may inadvertently perpetuate biases\npresent in training data or be misused for generating misleading or harmful content. We are com-\nmitted to addressing these ethical concerns and promoting responsible use of our technology. We\nurge users of our method to exercise caution and consider the ethical implications of its applications."}, {"title": "Reproducibility statement", "content": "We will provide as detailed a description as possible regarding the\nreproduction of experiments in the Appendix, and we plan to release our code when this paper is\npublished."}, {"title": "A RELATED WORK", "content": "In this section, we review the relevant prior works."}, {"title": "A.1 LEVERAGING DIFFUSION MODELS AS PRIOR MODELS FOR INVERSE PROBLEMS", "content": "Several methods have been proposed that\nutilize pixel-domain diffusion models for solving inverse problems. DDRM and DDNM (Kawar\net al., 2022; Wang et al., 2023) assume linear operators and known noise levels, leveraging the\nsingular value decomposition (SVD) of these operators. IGDM (Song et al., 2023a) can handle\ncertain classes of non-linear operators, such as low dynamic range, where a pseudo-inverse operator\ncan be defined. Notably, IGDM does not require SVD or gradient computations for such a case.\nDPS (Chung et al., 2023) broadens the applicability to cases where operator gradients can be com-\nputed, enabling it to handle both linear and non-linear operators like phase retrieval and non-linear\nblur. Other notable methods in this category include RePaint (Lugmayr et al., 2022) and RED-\nDiff (Mardani et al., 2024)."}, {"title": "A.2 CONDITIONAL GENERATION USING DISCRETE DIFFUSION MODELS AS PRIORS", "content": "While our work focuses on inverse problems, it is important to consider related approaches in con-\nditional generation tasks using discrete diffusion models as priors. These methods, primarily devel-\noped in the context of graph generation and protein design, introduce new conditioning to pre-trained\nmodels rather than directly addressing inverse problems."}, {"title": "C DETAILS ON EXPERIMENTS", "content": "In our image inverse problem\nexperiments, the definition and implementation of the forward operator are based on the DPS imple-\nmentation\u00b2. To ensure a diverse representation of ImageNet classes without genre bias, we select a\nsubset consisting of 100 images from classes 0, 10, . . ., 990 using the imagenet_val_1k.txt\nprovided by Pan et al. (2021)3. For our experiments with the FFHQ dataset, we use images\n0,1,..., 99 from the validation set."}, {"title": "C.1 IMAGE INVERSE PROBLEMS", "content": "In our image inverse problem\nexperiments, the definition and implementation of the forward operator are based on the DPS imple-\nmentation\u00b2. To ensure a diverse representation of ImageNet classes without genre bias, we select a\nsubset consisting of 100 images from classes 0, 10, . . ., 990 using the imagenet_val_1k.txt\nprovided by Pan et al. (2021)3. For our experiments with the FFHQ dataset, we use images\n0,1,..., 99 from the validation set."}, {"title": "C.2 IMPLEMENTATION DETAILS OF G2D2 IN INVERSE PROBLEM SETTINGS", "content": "The implementation of G2D2 is based on the VQ-Diffusion model from the diffusers library 4.\nFor the prior model, we use the pre-trained model available at https://huggingface.co/\nmicrosoft/vq-diffusion-ithq. In our experiments, the number of time steps T for sam-\npling is set to 100.\nIn G2D2, the star-shaped noise process follows\nthe same cumulative transition probability q(zt|zo) as the original Markov noise process. For the\nMarkov noise forward process where q(zt|zt\u22121) is defined using Qt as in Equation 2, the cumulative\ntransition probability is computed as q(zt,i|zo) = v(zt,i)Qtv(zo,i), where Qt = Qt\u2026 Q1. Here,\nQ can be computed in closed form as:"}, {"title": "Parameterization of Star-Shaped Noise Process", "content": "In G2D2, the star-shaped noise process follows\nthe same cumulative transition probability q(zt|zo) as the original Markov noise process. For the\nMarkov noise forward process where q(zt|zt\u22121) is defined using Qt as in Equation 2, the cumulative\ntransition probability is computed as q(zt,i|zo) = v(zt,i)Qtv(zo,i), where Qt = Qt\u2026 Q1. Here,\nQ can be computed in closed form as:"}, {"title": "C.3 G2D2 WITH MARKOV NOISE PROCESS", "content": "As discussed in Section 4.3, a variant of G2D2 can be derived by introducing the original Markov\nnoise process in the graphical model. In that case, the algorithm is shown in Algorithm 2. The\nkey point here is that the qMarkov(Zt-1|Zo, zt) part is identical to that of the original Markov noise\nprocess, which is expressed as"}, {"title": "C.4 SETTINGS FOR COMPARISON METHODS", "content": "In this subsection, we detail the experimental settings for the comparison method."}, {"title": "C.5 GPU MEMORY USAGE AND COMPUTATIONAL SPEED", "content": "We analyze the GPU memory consumption and computational speed of our proposed method,\nG2D2, in comparison with other methods. Table 4 presents a overview of these metrics for vari-\nous methods. The measurement are conducted using a single NVIDIA A6000 GPU for the Gaussian\ndeblurring task on ImageNet. G2D2 has the lowest memory usage among all methods and the fastest\ncomputational speed among gradient-based methods."}, {"title": "C.6 IMPACT OF THE FORGET COEFFICIENT", "content": "Figure 7 shows the reduction in the loss function and the final results for the Gaussian deblurring\ntask on ImageNet when the forget coefficient is set to 0.3 and 1.0. The case with a forget coefficient\nof 1.0 corresponds to not using the optimization results from the previous step at all. Introducing the\nforget coefficient allows for a faster reduction in the loss function and achieves higher performance\nwith the same computational resources."}, {"title": "C.7 ADDITIONAL QUALITATIVE RESULTS OF G2D2 AND COMPARISON METHODS.", "content": "We present additional qualitative results of G2D2 and comparison methods. Figures 8 through 11\nshowcase the results for super-resolution (SR) and Gaussian blur (GB) tasks on ImageNet and FFHQ\ndatasets."}, {"title": "C.8 ADDITIONAL QUALITATIVE RESULTS OF G2D2 WITH MARKOV NOISE PROCESS", "content": "To compare G2D2 and G2D2 with Markov noise process, we present their respective qualitative\nresults in Figures 12 and 13. The latter approach does not include re-masking operations in its\nsampling process, which means that once a token becomes unmasked, it cannot be modified in"}, {"title": "C.9 INVERSE PROBLEMS ON MOTION DATA", "content": "We develop G2D2 based on the official implementation of MMM (Pinyoanuntapong et al., 2024) 12.\nThis method learns a masked generative model on the discrete latent space obtained by a motion\ntokenizer trained on the VQVAE framework (Van Den Oord et al., 2017). G2D2 uses the provided\npre-trained model as a prior distribution.\nWe conduct experiments on the path following task (Song et al., 2023b; Uchida et al., 2024). The\nobjective is to generate motion data mo \u2208 Rdm\u00d7L that follows a given path ypath \u2208 R3\u00d7L. Here,\nypath represents the coordinates of the hip joint at each time frame, L denotes the number of frames\nin the motion data, and dm is the dimensionality of each motion data point.\nThe likelihood loss used in the optimization process of G2D2 measures how closely the generated\nmotion follows the target path. It is defined as"}]}