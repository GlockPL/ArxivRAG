{"title": "Multi-Lingual Cyber Threat Detection in Tweets/X Using ML, DL, and LLM: A Comparative Analysis", "authors": ["Saydul Akbar Murad", "Ashim Dahal", "Nick Rahimi"], "abstract": "Cyber threat detection has become an important area of focus in the digital age of today due to the growing spread of fake information and harmful content on social media platforms such as Twitter (now 'X'). These cyber threats, often disguised within tweets, pose significant risks to individuals, communities, and even nations, emphasizing the need for effective detection systems. While previous research has explored tweet-based threats, much of the work is limited to specific languages, domains, or locations or relies on single-model approaches, reducing their applicability to diverse real-world scenarios. To address these gaps, our study focuses on multi-lingual tweet cyber threat detection using a variety of advanced models. The research was conducted in three stages: (1) We collected and labeled tweet datasets in four languages-English, Chinese, Russian, and Arabic-employing both manual and polarity-based labeling methods to ensure high-quality annotations. (2) Each dataset was analyzed individually using ML and DL models to assess their performance on distinct languages. (3) Finally, we combined all four datasets into a single multi-lingual dataset and applied DL and LLM architectures to evaluate their efficacy in identifying cyber threats across various languages. Our results show that among machine learning models, Random Forest (RF) attained the highest performance; however the Bi-LSTM architecture consistently surpassed other DL and LLMs architecture across all datasets. These findings underline the effectiveness of Bi-LSTM in multilingual cyber threat detection. The code of this paper can be found in this link: https://github.com/Mmurrad/Tweet-Data-Classification.git", "sections": [{"title": "I. INTRODUCTION", "content": "Social networks have emerged as a global focal point, functioning as platforms for the dissemination of opinions, ideas, marketing, and several other activities [13]. These platforms offer customers rapid, complimentary, and readily available tools to fulfill their varied requirements. Social networks efficiently fulfill user needs, resulting in a continuing rise in account registrations. Users continuously express their opinions on subjects of interest, rendering social networks a vibrant arena for communication and engagement. Twitter, now renamed as 'X,' is recognized as one of the most prominent and impactful social networks. Tweets have emerged as a significant data source for many users, including manufacturers, celebrities, healthcare experts, politicians, and researchers [15]. The extensive information dissemination on Twitter makes it a significant asset for activities such as cyber threat identification, sentiment analysis, and predictive modeling, underscoring the influence of social networks in contemporary society.\nWith the increase of social media, cyber threats have become an increasing concern, affecting both individuals and organizations in different ways [29]. threats come in various forms, such as online harassment, phishing scams, misinformation, and direct threats, using anonymity and etc. [30]. Some threats are sent privately through messages that target specific people, while others are made public. The goal is spreading fear among people or manipulating public opinion [22]. These types of cyberbullying can affect human life, leading to emotional distress, misinformation can create chaos or ruin reputations, and phishing scams can cause financial losses [26]. As social media increasingly embedded in our daily lives, so we need an effective systems to identify and mitigate these threats, ensuring a safer and more secure digital platform for everyone.\nIn recent years, cyber threats based on tweets have become a growing concern, especially through the exploitation of public tweets [22]. Such threats can result in serious consequences, often leading to public unrest or even community violence [23]. Fake or misleading tweets can sometimes incite mobs, creating panic and chaos in society [26]. On a broader level, such tweets can exacerbate group differences, inciting hostility along cultural, religious, or ideological lines [27]. In many instances, aggressive or misleading tweets have instigated diplomatic conflicts between nations, thereby straining international relations [28]. The rapid dissemination of harmful content on platforms such as Twitter underlines the urgent necessity to address these challenges and protect societal and global stability.\nMany researchers are actively working on detecting cyber threats in tweets, using advanced AI techniques such as ML [18], DL [19], and other novel approaches. Although significant progress has been made, there are still several limitations in the current body of research. One major issue is that most of the research concentrates on a single language [21]. But everyday tweets are coming in different languages. This language-specific focus limits the scalability and applicability of the models in addressing threats in different linguistic contexts. Some researchers worked on multi-lingual tweet datasets, but mostly their approaches involve devloping separate models for each language [11]. This approach may be effective for small-scale investigations, but it becomes wasteful and impracticable when used for big datasets comprising multiple languages. To address the diversity of cyber threats on social media, it's important to develop a generalized model capable of"}, {"title": "II. LITERATURE REVIEW", "content": "This section reviews the current state-of-the-art (SOTA) research on multi-lingual threat detection on Twitter/X. Although ML, DL, and LLMs have widely reached the depths of multiple disciplines and achieved commendable results, multi-lingual threat detection ceases to remain one of them. This gap is particularly concerning given the current rising prevalence of cross-country cyber threats and social media based cyber attacks.\nRehan et al. [1] claimed to be one of the first to offer multi-lingual threatening text detection on Twitter with LLMs. They achieved this by first translating English text into their Urdu corpus and then working on the Urdu language with their AI implementation. The authors fine-tuned RoBERTa with 1,313 English and 2,400 Urdu samples. The sample of English threats is highly skewed with only 128 non-threat messages out of the given 1,313 samples. The authors also chose standard ML algorithms like Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), Convolutional Neural Networks (CNN), Bi-directional Long Short-Term Memory (Bi-LSTM) with RoBERTa and Word2Vec approaches to test their approach. Although they have shown exceptional results with over 91.89% accuracy, the definition of multi-lingual classification for the papers includes just English and Urdu. Our paper overcomes this shortcoming by providing a more quantifiable and diverse approach that can work in English, Arabic, Russian, and Chinese; all of which, according to the CIA's The World Factbook [2], are in the top 10 most-spoken first languages around the world. This limitation in detecting multiple language to detect cyber threat can lead to catastrophic cyber attack vectors where the exploiters simply make use of the standing language and its essence barriers.\nApart from this, there exists very little literature on multi-language threat detection on Twitter tweets specifically. However, there are some related research works in the field which indirectly address the theme of this paper. Tundis et al. [3] provide a multi-language approach towards identification of suspicious users on social network platforms. Although their approach also relies on using platforms like Google Translate, Yandex, and Bing Translate, the authors deduce a similarity score. The authors don't mention a general formula to calculate the similarity score, but we can deduce it to the following from their examples.\n$SN_{max} = maxSimilarity(\\sum_{i=1}^{n}(R_{1i} \\times S_{1i}); \\sum_{i=1}^{n}(R_{2i} \\times S_{2i}); \\sum_{i=1}^{n}(R_{3i} \\times S_{3i}))$ (1)"}, {"title": "III. IMPLEMENTATION DETAILS", "content": "In this section, we briefly discuss the working procedure of this research. We started by discussing the data, including its source and the process of labeling it. Next, we explained how we processed the data, which included steps such as data cleaning, removing stopwords, and tokenization. After processing, we encoded the tokenized data and applied various techniques to the dataset. Finally, we concluded the section by describing the different parameters considered to measure the performance of the models. Figure 1 provides a visual representation of our working procedure."}, {"title": "A. Data Collection and Labeling", "content": "For this research, we collected our dataset from tweets posted by individuals across different languages. The dataset comprises tweets in four languages: English, Arabic, Russian, and Chinese. Initially, the collected data was unlabeled, and the objective was to classify the tweets into three categories: threat, neutral, and non-threat. We have made the dataset publicly available, and it's included with the source of this paper.\nWe employed two labeling approaches to annotate the dataset. The first approach was manual annotation, where four students, each proficient in one of the four languages, assisted in classifying the tweets into the predefined categories. This ensured linguistic nuances were considered during the labeling process.\nThe second approach is polarity-based classification. Polarity (P) measures the sentiment of a tweet and was calculated as follows:\n$P(T) = \\frac{\\sum_{i=1}^{n} s(w_i)}{n}$ (2)\nWhere P(T) is the polarity of the tweet. s (wi) represents the sentiment score of the i-th word in the tweet. This score is positive for positive words, negative for negative words, and zero for neutral words. n is the total number of words in the tweet.\nTo classify tweets based on their polarity:\n*   Threat: P(T) \u2264 \u22120.5\n*   Neutral: -0.5 < P(T) < 0.5\n*   Non-threat: P(T) \u2265 0.5\nThe polarity-based labeling approach yielded results that were largely consistent with the manual labeling. However, in certain instances, discrepancies were observed between the two methods. In such cases, we prioritized the manual"}, {"title": "B. Data Pre-processing", "content": "In the data preprocessing stage, we began by cleaning unnecessary data to enhance the quality of the dataset and improve the performance of the classification models. Following this, we removed stopwords from the tweets in all four languages (English, Arabic, Russian, and Chinese). Additionally, stemming was performed to reduce words to their root forms, ensuring consistency and further simplifying the data. Finally, the cleaned text data was tokenized, breaking the tweets into individual words or subwords, and padding was applied to standardize the input length. These steps prepared the data for model training, ensuring compatibility and optimal input representation for the subsequent stages of analysis.\n1) Data Cleaning: After labeling the datasets, our first objective was to clean the data to ensure it was suitable for analysis. Many tweets contained sentences that lacked meaningful context, so we removed such sentences. Additionally, we eliminated URLs, mentions, hashtags, punctuation, and special characters using Regular Expressions (Regex).\nWe denote the labeled dataset as:\n$X^1 = \\{(t_1, y_1), (t_2, y_2),..., (t_n, y_n)\\}$ (3)\nwhere ti represents the i-th tweet. yi is the corresponding label for ti, where yi \u2208 { Threat, Neutral, Non-threat }.\nThe cleaning process transforms each tweet ti into a cleaned version t'i by applying the following operations: 1. Removal of irrelevant or nonsensical sentences. 2. Removal of URLs, mentions, hashtags, punctuation, and special characters via Regex.\nThe cleaned dataset is represented as:\n$X^{clean} = \\{(t'_1, y_1), (t'_2, y_2), ..., (t'_n, y_n)\\}$ (4)\nWhere t'i is the cleaned version of ti. This ensures that the dataset X retains the labels yi while improving the quality and relevance of the tweets th.\nclean\n2) Remove Stopwords and Stemming: After completing the data cleaning process, we proceeded to remove stopwords from the tweets in all four languages. Stopwords, which are common words that do not significantly contribute to the semantic meaning of the text. These were eliminated to reduce noise and enhance the quality of the dataset. This step can be expressed mathematically as:\n$t'_i = RemoveStopwords (t'_i)$\nWhere t'i is the cleaned tweet from the previous stage. t''i is the tweet after removing stopwords. RemoveStopwords represents the stopword removal function applied to the cleaned tweet.\nAfter removing stopwords, stemming was applied to reduce words to their root or base forms, further standardizing the text. This transformation is represented as:"}, {"title": "C. Text Encoding", "content": "After preprocessing, the next step was encoding the text data into numerical vector representations using Word2Vec. Word2Vec transforms words into dense, continuous vector spaces where semantically similar words have closer repre-sentations.\nFor training Word2Vec, we utilized different pre-trained word embedding models specific to each language:\nEach word w in a tweet t''' was mapped to a vector w in a d-dimensional space, where d is the embedding size (300 in this case). Mathematically, for a tweet t''' = {w1,w2,..., wk}, the Word2Vec embeddings create a sequence of word vectors:\n$E_i = \\{w_1, w_2, . . .,w_k\\}, w_i \\in R^d$ (9)\na) Aggregating Word Embeddings: As ML models typically require fixed-length inputs, the sequence of word embeddings for a tweet Ei was aggregated into a single vector. Common aggregation techniques include:\nMean Pooling: Taking the average of all word vectors:\n$\\vec{T_i} = \\frac{1}{k} \\sum_{j=1}^{k} \\vec{w_j}$ (10)\nMax Pooling: Taking the maximum value across each dimension of the word vectors:\n$\\vec{T_i} = max(\\vec{w_1}, \\vec{w_2}, ..., \\vec{w_k})$\nHere, $\\vec{T_i} \\in R^d$ represents the encoded tweet as a fixed-length vector.\nb) Passing Encoded Data to the Model: Once encoded, the tweet representations $\\vec{T_i}$ were used as input to the classification model. The final dataset after encoding is represented as:\n$X_{encoded} = \\{(\\vec{T_1}, y_1), (\\vec{T_2}, y_2), ..., (\\vec{T_n}, y_n)\\}$\nWhere $\\vec{T_i}$ is the vector representation of the i-th tweet, Yi is the corresponding label.\nThese embeddings preserve semantic information and ensure that the text data is represented in a numerical format"}, {"title": "E. Classifier", "content": "To analyze the dataset, we employed three distinct types of models: ML, DL, and LLMs. For the ML approach, we utilized three robust algorithms: Logistic Regression (LR), Decision Tree (DT), and Random Forest (RF), known for their effectiveness in classification tasks. In the DL category, we designed architectures combining advanced recurrent neural networks, including LSTM, and GRU, to take advantage of their sequential data processing capabilities. These models provided a comprehensive framework for evaluating and classifying the dataset.\n1) Language-Specific Classification: In the experiment, we used ML and DL models for each language English, Chinese, Russian, and Arabic. The primary goal was to evaluate the performance of those models when trained and tested exclusively on data from a single language. To achieve this, we employed three ML models and three DL architectures, and we compared the results between the models.\na) ML Classifier: For training the ML models, we utilized 80% of the dataset, while the remaining 20% was reserved for testing. Each algorithm was carefully configured with hyperparameters optimized for the classification task. In the following, we detail the three ML algorithms employed:\nLogistic Regression (LR): The LR model maps the input features Ti to probabilities using a sigmoid function. The predicted probability of a label yi is given by:\n$P(y = 1/\\vec{T_i}) = \\frac{1}{1+ e^{-(\\vec{W}T_i+b)}}$ (11)\nWhere, w is the weight vector, b is the bias term.\nWe trained the LR model with a maximum of 1000 iterations (max_iterations = 1000) to ensure convergence.\nDecision Tree (DT): The Decision Tree algorithm partitions the feature space T into regions by recursively splitting the data based on features that maximize information gain or minimize Gini impurity. The decision rule at each node can be expressed as:\n$f(\\vec{T_i})$ =  \\begin{cases} 1 if $T_{ij}$ \u2264 threshold\\\\ 0 otherwise\\end{cases}  (12)\nWhere Tij is the j-th feature of T\u2081 and threshold is the splitting value determined during training.\nRandom Forest (RF): Random Forest is an ensemble algorithm that builds multiple Decision Trees (DT1, DT2,..., DTM) on random subsets of the data and features. The final prediction is obtained by majority voting:\n$f(T) = mode (DT_1(T), DT_2(T), ..., DT_M(T))$ (13)\nWhere M is the number of trees in the forest, and DTm(Ti)"}, {"title": "B. DL Classifier", "content": "We employed three distinct DL ar-chitectures Bi-RNN, Bi-LSTM, and Bi-GRU to analyze the dataset. Each architecture was designed and tested independently to evaluate its performance and identify the most effective model. Additionally, we meticulously tuned the hyperparameters of each architecture to achieve optimal results. A brief overview of these models and their configurations, as used in our experiments, is presented in Figure 2. Below, we provide detailed descriptions of the models and configurations used in our experiments.\nBiDirectional Recurrent Neural Framework (Bi-RNF) The top architecture in Figure 2 defines the RNF models, which begin with a word embedding layer common to all other architectures. The word embedding layer transforms the input tokens into dense vectors of dimension d = 300, with a maximum sequence length of 100. The embedding layer is initialized with pre-trained embeddings.\nThe first layer after embedding is a Bi-RNN with different units like 32, 64, 128, configured to return sequences. This layer captures temporal dependencies in both forward and backward directions. Mathematically, the output of this layer is:\n$H_{BIRNN} = BIRNN(E)$\nwhere E is the embedding matrix for a sequence, and HBIRNN represents the bidirectional output.\nFollowing the Bi-RNN layer, the output is passed through a dense layer with different neurons and a ReLU activation function:\n$D_1 = ReLU(W_{Dense1} H_{BiRNN} + b_{Dense1})$\nwhere WDensel and bpensel are the weights and biases of the dense layer.\nTo prevent overfitting, a dropout layer with a rate of 0.4 is applied:\n$D^{drop}_1 = Dropout(D_1, 0.4)$\nThis process is repeated for subsequent layers, including a Bidirectional GRU (Bi-GRU) and a Bidirectional LSTM (Bi-LSTM), interspersed with dense layers (with varying neuron counts such as 32, 64, or 128) and dropout layers. Each bidirectional layer captures sequential patterns, and the dense layers act as feature transformation layers, enhancing the learning capacity.\nThe output from the final dense layer is passed to another dense layer with num_classes neurons and a softmax activation function, producing a probability distribution for multi-class classification:\n$P(y|T) = Softmax(W_{output} H_{Dense} + b_{output})$ (14)\nHere, Woutput and boutput are the weights and biases of the final dense layer, HDense is the output from the last dense layer, and P(yT) represents the predicted probabilities."}, {"title": "2) Multi-class Classifier", "content": "Before implementing the multi-class classification models, we combined datasets from all four languages-English, Chinese, Russian, and Arabic-into a single unified dataset. Each dataset was processed independently up to the embedding stage, ensuring that the word embeddings were created separately for each language while maintaining a consistent embedding dimension across all datasets. After generating embeddings, we merged the four embedded datasets into one.\nIt is worth noting that the datasets for English, Chinese, and Russian contained three class labels (Threat, Neutral, Non-threat), while the Arabic dataset included only two labels (Threat and Non-threat). Despite this difference, we preserved the same embedding dimension across all datasets to ensure uniformity and compatibility during the model training process. This unified, multi-lingual dataset provided the foundation for training and evaluating the multi-class classification models, including the LLM-based classifiers.\na) DL Classifier: For the multi-class classification task, we utilized two distinct DL architectures: LSTM and GRU. The architecture of those models is same that we already"}, {"title": "V. CONCLUSIONS AND FUTURE WORK", "content": "This work presents a novel multilingual dataset, providing as a significant resource for research on cyber tweet threat identification. We performed an extensive examination of these datasets, both separately and in a unified multilingual configuration. We utilized three different model architectures-ML, DL, and LLM-to assess the performance of various techniques. Among the ML models, the RF algorithm exhibited superior performance, showcasing its efficacy in managing structured Twitter data. The Bi-LSTM architecture for DL models attained the best accuracy, surpassing all ML and DL models. Significantly, Bi-LSTM surpassed LLMs in performance on the integrated dataset, demonstrating its proficiency in capturing sequential patterns and contextual information adeptly. Although we utilized the LLM architecture (XLM-ROBERTa) for the integrated dataset, its performance was inferior to that of Bi-LSTM, indicating the necessity for additional optimization and fine-tuning of LLMs to fully realize their capabilities in multilingual cyber tweet identification.\nIn the future, our efforts will concentrate on improving model performance on integrated datasets by investigating more sophisticated LLM designs and utilizing fine-tuning techniques specifically designed for multilingual data. Furthermore, we intend to implement transfer learning techniques to modify models pre-trained on extensive datasets, enhancing their capacity to generalize to smaller and more heterogeneous datasets. Additionally, we intend to broaden our research to encompass other languages and domain-specific twitter datasets, facilitating a more thorough assessment of the suggested techniques' robustness and flexibility."}]}