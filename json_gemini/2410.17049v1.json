{"title": "A Comparison of Baseline Models and a Transformer Network for SOC Prediction in Lithium-Ion Batteries", "authors": ["Hadeel Aboueidah", "Abdulrahman Altahhan"], "abstract": "Accurately predicting the state of charge of Lithium-ion batteries is essential to the performance of battery management systems of electric vehicles. One of the main reasons for the slow global adoption of electric cars is driving range anxiety. The ability of a battery management system to accurately estimate the state of charge can help alleviate this problem. In this paper, a comparison between data-driven state-of-charge estimation methods is conducted. The paper compares various neural network-based models and common regression models for SOC estimation. These models include several ablated transformer networks, a neural network, a lasso regression model, a linear regression model and a decision tree. Results of various experiments conducted on data obtained from natural driving cycles of the BMW i3 battery show that the decision tree outperformed all other models including the more complex transformer network with self-attention and positional encoding. The decision tree model scored perfect values of performance metrics (MSE=0, R2=1, RMSE=0, MAE=0). This paper could be helpful for researchers to select appropriate data-driven methods for SOC estimation of lithium-ion batteries in real driving cycles.", "sections": [{"title": "Introduction and Background Research", "content": "With the growing concern about climate change and global warming, the use of electric vehicles (EVs) has emerged as a sustainable solution and an environmentally friendly alternative to petrol-fueled vehicles. Zero-emissions vehicles have become an essential part of every country's futuristic and sustainable vision. Rechargeable lithium-ion batteries are widely used for EVs and are considered the best available option, offering suitable battery energy density and cycle life [1]. Moreover, the development of (Li-ion) batteries over the next years will lead to more complex battery dynamics as well as higher energy density. Therefore, advancement in battery management systems (BMS) that can optimize and monitor battery behaviour will be required in parallel with the development of Li-ion batteries and the overall electrification system [2].\nThe state of charge (SOC) is one of the most important parameters in a battery management system (BMS). It is a metric that provides information about the battery's remaining capacity under current working conditions. Unlike the fuel gauge in a petrol-fueled vehicle, SOC cannot be directly measured in EVs. Therefore, it needs to be estimated in practical applications which can be a challenging task [3] The equation of a battery's SOC is defined as follows :\n$SOC = \\frac{C_{curr}}{C_{full}} \\times 100%$, (1)\nwhere $C_{curr}$ is the capacity of the battery in its current state and $C_{full}$ is the the capacity of the battery when it is fully charged.\nThe conventional SOC estimation methods include open-circuit voltage, impedance-based estimation, fuzzy logic, Kalman filter, and model-based estimation. The model-based methods have an advantage over the other methods as they can be used for online applications. Moreover, physics-based models (PBMs) are an advancement of model-based methods. The pseudo-two-dimensional (P2D) is the most studied PBM model in the literature. This model provides us with a better understanding of the battery's internal dynamics such as the concentration of lithium-ion in the electrodes and electrolytes. However, it is less practical for online applications due to its complex governing equations that require higher computational costs. Additionally, traditional PBMs do not consider the material properties within the battery, which are essential for understanding the battery's degradation behaviour and its SOC. The main battery models used today for real-time SOC estimation in BMSs are equivalent circuit models (ECMs). These models are widely used because of their low computational cost; however, one drawback is that their accuracy is limited when predicting battery characteristics across a range of varying operating conditions [4][5]."}, {"title": "Methodology", "content": "To compare the performance of these different regression models, 736,983 records were obtained from 72 real driving trips with a BMW i3 (60 Ah). The numerical features were standardized using the StandardScaler function, and 24 features were selected from a total of 51. Additionally, the confusion matrix obtained during the exploratory data analysis (EDA) highlighted the non-linear relationship between the input features and the target. The correlation with the target and the variance of each selected feature across the dataset were considered during the feature selection process. Moreover, 78,657 outliers were removed from the dataset after calculating the z-score and setting a threshold of 3 to identify outliers. The cleaned dataset was then used for further analysis. The original dataset can be accessed via this link: https://ieee-dataport.org/open-access/battery-and-heating-data-real-driving-cycles [16].\nThe three evaluation metrics used to evaluate the models' performance in this SOC prediction task are: Mean Squared Error (MSE), Root Mean Square Error (RMSE), R2, and Mean Absolute Error (MAE). The equations for these evaluation metrics are illustrated below:\n$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y_i} - y_i)^2$ (2)\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}$ (3)"}, {"title": "Baseline approaches", "content": "In this paper, various machine learning and neural network-based models were tested to predict the state of charge of lithium-ion batteries from historical natural driving cycles. These models included several scikit-learn models, such as linear regression, lasso regression, and decision tree, as well as neural network-based models from Keras, such as neural network regression and the transformer network. These models are listed and illustrated below:\nThe first baseline regression model used to predict the lithium battery SOC is linear regression from scikit-learn. In linear regression, a set of input features is represented by the variable X and matched with its corresponding continuous output values y. The linear regression model is performed through a straight-line approximation of the outputs [17]. Its equation is given below:\n$\\Upsilon_{i} = \\beta_{0} + \\beta_{1}X_{i} + \\epsilon_{i}$ (6)\n, where Y is the dependent variable, X is the independent variable, $B_{0}$ is the intercept of the line, $B_{1}$ is the linear regression coefficient (slope of the line), and e is the random error term.\nIn lasso regression, which stands for least absolute shrinkage and selection operator, linear regression is performed, but with a reduced number of features. This is achieved using L1 regularization, where a penalty term is added to the cost function to encourage the model to select only the most important attributes and set the coefficients of less important attributes to zero. [18]. The lasso regression equation can be given as follows:\n$\\hat{\\beta}^{lasso} = \\underset{\\beta}{argmin} \\{ \\frac{1}{2n} \\sum_{i=1}^{n} (y_{i} - \\beta_{0} - \\sum_{j=1}^{p} \\beta_{j} x_{ij})^2 + \\lambda \\sum_{j=1}^{p}|\\beta_{j}| \\}$ (7)\n, where $\\hat{\\beta}^{lasso}$ represents the estimated regression coefficients for Lasso regression, n and p represent the number of observations and predictor variables, respectively. $B_{0}$ is the intercept term, $y_{i}$ is the ith observation of the target variable and $x_{ij}$ is the ijth observation of the jth predictor variable."}, {"title": "The Transformer Network and its ablated versions", "content": "The potential of using a transformer network to predict the state of charge of lithium-ion batteries was explored. The transformer network was ablated with some of its main parts removed each time to assess the necessity of these parts and determine if a less complex architecture could outperform the original model in this regression task. The two diagrams of the ablated versions of the transformer network are demonstrated in fig.2.\nAs shown in fig.2, the self-attention and positional encoding are ablated each time to create less complex networks. The significance of these two layers will be further investigated by evaluating the performance of the ablated transformer networks in the following sections."}, {"title": "Experiment Results and Discussions", "content": "The baseline models and transformer networks were trained on the dataset, and their performances were compared.\nThe predicted vs actual SOC values for the LR model are demonstrated in Fig. 3a. In the case of perfect prediction, the predicted graph would coincide with the actual graph. However, as seen in Fig. 3a, the predicted SOC graph deviates from the actual one, resulting in high MSE and R2 values. Fig. 3b highlights the lasso regression model's relatively poor performance on the validation set, also indicated by its high MSE and R2 values. In contrast, Fig. 3c demonstrates that for the DT model, the predicted SOC graph closely matches the actual SOC graph, which is reflected in the near-perfect MSE and R2 values. Fig.3d shows that the neural network achieved a good MSE value of 0.07 and an RMSE value of 0.27.\nMoving on to transformer networks, Fig.3e depicts the performance of the transformer network with only an attention layer. The figure shows that the predicted SOC values for the transformer network with self-attention only slightly deviate across different data instances, with an MSE value of 1.08 and a perfect R2 value of 1. Fig.3f presents the results for the transformer network with positional encoding only. This network scored an MSE of 2.91, an RMSE of 1.71, and an almost perfect R2 value of 0.99. Eventually, Fig.3g illustrates the performance of the conventional transformer network. As shown, this model performed competently, achieving an MSE of 0.12, an RMSE of 0.35, an MAE of 0.77, and a perfect R2 value of 1. The predicted vs. actual SOC values for each model are demonstrated in fig.3.\nOverall performance After experimenting with all the baseline models and transformer-ablated architectures, the performance metrics indicate that the decision tree model outperformed not only all other baseline models but also the transformer networks tested in this prediction task. The decision tree achieved perfect performance metrics (MSE = 0, R2 = 1, RMSE = 0, MAE = 0). This outstanding performance prompts us to explore the advantages the decision tree model over other architectures when predicting the real-life SOC values of lithium-ion batteries. First, decision trees (DTs) are simple and fast learners capable of capturing non-linear relationships between input variables (such as voltage, current, etc.) and the target variable (SOC) [21] [22]. Second, DTs are computationally efficient, making them ideal for real-time SOC prediction in battery management systems [22]. They are also robust to missing and noisy real-world data, which further explains their outstanding performance in this prediction task [23]. Furthermore, the baseline decision tree model used in this task outperformed the proposed bagging random forest model in [10], which was trained and tested on a smaller dataset of only 32,067 instances with four time-dependent attributes. To ensure a fair comparison between the proposed model and the models used in our task, a sample of equal dimensions was extracted from our dataset and fed into the models investigated in this study. Fig. 3h presents the graph of the predicted vs. actual SOC values for the decision tree model, which was tested on a subset of the data that is equal in size to the input data used in [10]. The baseline decision tree achieved an RMSE value of 0.4, along with perfect MSE and MAE values of 0, and an R2 value of 1. This model relatively outperformed the proposed bagging random forest in [10], which recorded an MAE of 0.280 and an RMSE of 0.519. The decision tree maintained its superior performance, while other models, including linear models (LR and lasso) and neural network-based models, performed poorly in comparison to the model proposed in [10]. The second-best performing model was the neural network. Only three hidden layers were added to the feed-forward neural network, as this configuration provided good performance with an acceptable training time. Adding more layers increased both training time and the risk of overfitting, while yielding only minimal performance improvement. Therefore, a trade-off between achieving good performance metrics and minimizing training time was considered. Moreover, the neural network's competent performance can be attributed to its ability to capture non-linear relationships between input features and manage high-dimensional input. However, one potential drawback of feed-forward networks is their interpretability. While decision trees are easily interpretable, neural networks are more challenging to understand due to their complex architecture. They are also computationally expensive to train, particularly when dealing with large datasets. [24]. The third-best performing model, which achieved desirable MSE, RMSE, and R2 values, was the transformer model with self-attention and positional encoding. The self-attention mechanism allows the model to focus on the most relevant parts of the input (such as the readings of current and voltage over time) in our battery SOC prediction task. Furthermore, the positional encoding layer enables the model to capture temporal relationships between data points, which aids in analyzing the battery's behaviour over time and detecting any trends that may be present [20].\nFurthermore, the ablated transformer networks performed relatively poorly on this prediction task. This result emphasizes the essential need for having both the self-attention and positional encoding layers in the network. Their ability to capture relevant parts of the input and the temporal relationships between data points is essential for achieving competent performance in this SOC regression task. In addition, the performance of the linear and lasso regression models was unsatisfactory, as these models are primarily effective at capturing linear relationships between input variables and the target. The exploratory data analysis (EDA) performed on the dataset indicated that the relationships between the input features and the target are highly nonlinear. Consequently, the linear regression (LR) model was unable to capture these nonlinear relationships effectively, which was reflected in the poor performance metrics. Moreover, the nonlinear behaviour exhibited by the battery, particularly at high and low SOC levels, makes linear and lasso regression less effective. For instance, at these SOC levels, the battery's voltage does not change linearly with SOC, and similar nonlinear behavior is observed when the battery experiences significant temperature changes [25]. Therefore, more complex models like decision trees and neural networks are better suited for addressing such a problem."}, {"title": "Conclusion", "content": "The use of data-driven approaches to predict the state of charge of lithium-ion batteries has great potential and can be used to replace conventional SOC estimation methods. In this project, several machine-learning approaches were implemented to predict the SOC of lithium-ion batteries in real driving cycles, and their overall performance was compared. The obtained results showed that the baseline decision tree model outperformed all other baseline models, as indicated by its relatively low MSE, RMSE, and MAE values, alongside a high R2 value. This prominent performance of the decision tree model can be attributed to its robustness in handling real-world noisy data and its ability to capture non-linear relationships between input features and the target variable. The model was also able to outperform the bagging random forest proposed in [10] which was experimented on the same data scrutinized in this project. The second-best performing model was the neural network, which efficiently captured the nonlinear relationships between the input variables and the dependent variable. The more complex transformer model with self-attention and positional encoding ranked third in performance. The rest of the ablated transformer networks as well as the linear and lasso regression models performed relatively poorly in this regression task.\nModel complexity: Is attention really all we need? Exploring various machine learning models for predicting the state of charge in lithium-ion batteries highlights the importance of starting with baseline models before progressing to more complex architectures, such as transformer networks. While transformers and neural networks have gained popularity for SOC regression tasks, they can lead to temporal information loss in datasets with time-dependent data due to the permutation-invariant nature of self-attention, even when positional encoding is applied [31]. Therefore, simpler models should be considered initially before advancing to more complex architectures. The results in this paper emphasize the importance of this approach.\nFor future work, it would be interesting to investigate whether the methods and results obtained in this task can be generalized to other real-world charging and discharging data, as well as to different electric vehicles. Most machine learning models today offer black-box predictions that cannot be easily generalized to other battery chemistries [4]. Hence, incorporating domain knowledge is essential to achieve comprehensible and reliable predictions. Moreover, high-throughput experimentation should be conducted to generate high-quality, real-world datasets. Reducing the reliance on large data storage devices will also be crucial for advancing data-driven methods for real-time battery modelling."}]}