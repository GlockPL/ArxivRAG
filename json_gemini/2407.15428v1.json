{"title": "DECODING BACNET PACKETS: A LARGE LANGUAGE MODEL APPROACH FOR PACKET INTERPRETATION", "authors": ["Rashi Sharma", "Tatsumi Oba", "Naoto Yanai", "Hiroyuki Okada", "Karthikk Subramanian", "Sugiri Pranata"], "abstract": "The Industrial Control System (ICS) environment encompasses a wide range of intricate communication protocols, posing substantial challenges for Security Operations Center (SOC) analysts tasked with monitoring, interpreting, and addressing network activities and security incidents. Conventional monitoring tools and techniques often struggle to provide a clear understanding of the nature and intent of ICS-specific communications. To enhance comprehension, we propose a software solution powered by a Large Language Model (LLM). This solution currently focused on BACnet protocol, processes a packet file data and extracts context by using a mapping database, and contemporary context retrieval methods for Retrieval Augmented Generation (RAG). The processed packet information, combined with the extracted context, serves as input to the LLM, which generates a concise packet file summary for the user. The software delivers a clear, coherent, and easily understandable summary of network activities, enabling SOC analysts to better assess the current state of the control system.", "sections": [{"title": "1 Introduction", "content": "In industrial control systems (ICS), packets are vital for communication and control. Various protocols, such as Modbus, PROFINET, and BACnet, define how packets are structured and handled in ICS. These protocols ensure that devices from different manufacturers can work together. However, the diversity and complexity of these communication protocols present significant challenges for Security Operations Center (SOC) analysts. They struggle to monitor, understand, and respond to network activities and security incidents effectively. Traditional monitoring tools and methods make it hard to grasp the nature and intent of ICS-specific communications. This can lead to issues like difficulty understanding the current state of the control system from communication logs, which can result in failure to identify threats and respond promptly. Additionally, providing clear explanations to non-technical stakeholders can be challenging, potentially delaying decision-making. In this paper, we present a Large Language Model (LLM) based solution to improve the understanding of packet data.\nLarge Language Models (LLMs) are advanced AI systems designed to understand, generate, and interact with human language in a meaningful and contextually appropriate manner [Naveeda et al., 2024]. These models are trained on vast amounts of text data using advanced machine learning techniques, such as semi-supervised and self-supervised learning."}, {"title": "2 Background", "content": "Large language models (LLMs) have recently shown remarkable performance in various natural language processing (NLP) tasks. These models are trained on vast amounts of text data and can generate human-like text, answer questions, translate languages, and even write code. Models such as BERT [Devlin et al., 2018], GPT-2 [Radford et al., 2019], and T5 [Raffel et al., 2019] have demonstrated the ability to capture complex linguistic patterns, enabling them to generate human-like text and perform tasks such as machine translation, question answering, and sentiment analysis with high accuracy."}, {"title": "2.1 Large Language Models", "content": "Large language models (LLMs) have recently shown remarkable performance in various natural language processing (NLP) tasks. These models are trained on vast amounts of text data and can generate human-like text, answer questions, translate languages, and even write code. Models such as BERT [Devlin et al., 2018], GPT-2 [Radford et al., 2019], and T5 [Raffel et al., 2019] have demonstrated the ability to capture complex linguistic patterns, enabling them to generate human-like text and perform tasks such as machine translation, question answering, and sentiment analysis with high accuracy."}, {"title": "2.2 RAG (Retrieval-Augmented Generation)", "content": "RAG (Retrieval-Augmented Generation) is an approach in natural language processing (NLP) that combines the strengths of retrieval-based systems and generative models [Gao et al., 2024]. The core idea behind RAG is to enhance the generative model's responses by retrieving relevant information from a large corpus of documents. This approach helps in producing more accurate and informative answers, especially when dealing with complex queries or topics where the generative model alone might lack specific knowledge.\nRAG based system involves the following process:\n\u2022 Query Encoding: The input query is encoded into a dense vector representation using a pre-trained encoder, such as BERT or another transformer-based model.\n\u2022 Retrieval: The encoded query is used to retrieve relevant documents or passages from a large corpus. This retrieval is often performed using similarity search techniques, such as FAISS (Facebook AI Similarity Search) [Jegou et al., 2017], which quickly finds the most relevant documents based on vector similarity.\n\u2022 Document Encoding: The retrieved documents are also encoded into dense vector representations.\n\u2022 Generation: The encoded query and the retrieved document representations are fed into a generative model, such as a sequence-to-sequence transformer (e.g., T5 or GPT-3). The generative model uses this information to produce a more informed and contextually relevant response."}, {"title": "3 Related Work", "content": "Research papers highlight the growing interest in leveraging LLMs for various cybersecurity tasks. A recent study [Xu et al., 2024] explores the potential of LLMs in tasks like:\n\u2022 Vulnerability Detection: LLMs can analyze vast amounts of code to identify patterns indicative of vulnerabilities.\n\u2022 Malware Analysis: By understanding the language used in malware code and associated documentation, LLMs can aid in classification and analysis.\n\u2022 Network Intrusion Detection: LLMs can analyze network traffic data to detect anomalies and potential intrusions.\n\u2022 Phishing Detection: The ability to understand natural language allows LLMs to identify suspicious emails with higher accuracy.\nAnother application of LLMs, more related to the problem addressed in this paper, is generating comprehensive and understandable reports based on network packet analysis. LLMs can learn the characteristics of malicious traffic data, detect anomalies in user-initiated behaviors, and describe the intent behind intrusions and abnormal behaviors. For instance, Fayyazi and Yang [Fayyazi and Yang, 2023] explored the use of LLMs to predict and differentiate between ATT&CK tactics. Ali and Kostakos [Ali and Kostakos, 2023] implemented HuntGPT, an intrusion detection dashboard that combines a Random Forest classifier, XAI frameworks like SHAP and Lime, and GPT 3.5 Turbo to deliver threats in an easily understandable format. Furthermore, LLMs can provide security recommendations and response strategies for identified attack types [Chen et al., 2023].\nLLMs are also employed in Cyber Threat Intelligence (CTI) reporting. SecureBERT, a cybersecurity language model developed by [Aghaei et al., 2022], is designed to understand the subtleties of cybersecurity text, enabling it to automate several critical cybersecurity tasks. [Moskal et al., 2023] discussed how LLMs can understand threats, generate information about cybersecurity tools, and automate cyber campaigns."}, {"title": "4 Problem Statement", "content": "The Security Operations Center (SOC) analysts employ Intrusion Detection Systems (IDS) to scrutinize network traffic or system activity for indications of malicious activity or policy breaches. IDS alerts are generated when the system detects suspicious or anomalous activity that could signify a security threat, and these alerts are associated with specific packets. Analysts must comprehend why particular packets triggered an alert for efficient incident response. To gain this understanding, analysts need to be familiar with the specifications and protocols of control systems, which involves reading extensive technical documents and protocol specifications. Consequently, the training process is lengthy, and it takes time for new analysts to become proficient or for monitoring new environments to commence.\nNot much literature exists on explanation of individual packets for packet analysis. With the emergence of large language models (LLMs), generating packet explanations and summarizations has become more feasible."}, {"title": "5 Proposed Solution", "content": "The overall architecture of our solution is illustrated in Figure 2. The packet file is first pre-processed to extract useful information. This information is used to extract device information from the database. The packet information is also used for context retrieval using service database and RAG based context retrieval. Formatted packet information combined with context and device information is then inputted to the LLM which generates a packet file summary. Details of each stage are provided below:"}, {"title": "5.1 Packet Data Preprocessing", "content": "Our solution leverages the structure of network packets to generate summaries. Although the structure of packets may vary depending on the protocol used, each packet typically consists of two primary parts: the header and the payload (or data). In the case of BACnet, a typical packet includes the following layers:"}, {"title": "5.2 Mapping of Device Information", "content": "We possess information about the devices communicating via the BACnet protocol for buildings monitored by our security services. We provide this information to the LLM for a better understanding of communicating devices in a packet file. This information is only used if available. We map this device information to packet file data as part of preprocessing. Figure 3 shows the breakdown of packet file into consistent packets and extraction of device information per packet. Adding this information to packet data provides insights to both LLM and SOC operators about which devices are affected by a particular packet."}, {"title": "5.3 Context Extraction", "content": "Context is extracted using two sources: service database and RAG based context retrieval. Figure 4 shows how information retrieval is carried out for a packet file with 2 packets. The details of context retrieval for each of the extraction method is in the following sections."}, {"title": "5.3.1 Service Database Context Extraction", "content": "The APDU of a packet contains information about BACnet services. To ensure that LLM always receives service information as context for a given packet, we created a service database. This database contains summarizations of"}, {"title": "5.3.2 RAG-based Context Extraction", "content": "To provide LLM with additional context beyond the operation performed by the packet, we created a RAG database for the remaining data. The data is divided into chunks using Llamaparse\u00b2 and customized document-specific chunking. The chunks are stored using FAISS, a library for efficient similarity search and clustering of dense vectors. For each packet, the APDU data is used as a query to extract the top 3 similar chunks from the RAG database. Keyword matching is performed between the APDU data and the extracted chunks to improve the accuracy of the extraction. The chunk with the most matching keywords and the highest rank is used as context in the LLM input."}, {"title": "5.4 Summary Generation", "content": "The context extracted using the FAISS and service databases for each packet in the packet file is combined, with redundancies removed, and provided as context in the prompt. The processed packet data is included as part of the query to the LLM. Using this information, the LLM model generates a summary for the entire packet file."}, {"title": "6 Experiments and Results", "content": "For embedding model, for RAG context retrieval, we used all-MiniLM-L12-v2 model. The LLM model used in our experiments was Mixtral 8X7B LLM model 3 installed on our local machine. To improve speed and reduce hardware requirements we made use of the 4-bit quantized version of the model.\nFor context we use the BACnet standard book: ASHRAE BACnet, A Data Communication Protocol for Building Automation and Control Networks4.\nWe performed the following experiments for comparison purposes:"}, {"title": "6.1 Evaluation", "content": "The task dealt in this paper is a controlled task, limited to summary generation for BACnet packets. So, we do not possess a standard reference dataset for evaluation. For evaluation purposes we make use of 19 BACnet packets with IDS alerts(which can be used in future evaluations when IDS information is incorporated in summary).\nFor tasks like extractive summarization, where full source sentences are selected to appear in the summaries, simple n-gram overlap metrics against the \"gold\" summaries like ROUGE[Lin, 2004] or BLEU [Papineni et al., 2002] tend to work well as the correct answer space is limited [Shen et al., 2023]. In our task multiple summaries might be equally good so instead of creating \"gold\" summaries for our evaluation we proceed with human evaluation. Specifically we involve people with knowledge about BACnet protocol to evaluate the summaries based on two criteria: (1) Control Accuracy (CA) [He et al., 2022]: whether the summary contains accurate information about the intent of the packet and does not contain information which might mislead the analyst. (2) Control Informativeness(CI): the extent to which the summary can provide useful information about the packet. Results of evaluation are shown in Table 1."}, {"title": "6.2 Result Analysis", "content": "From Table 1 it can be gleaned that the proposed solution outperforms the other 3 methods in terms of informativeness while maintaining a high accuracy in the information provided.\nIn method 1 where the LLM is not provided any context information, the method performs poorly, for the CI metric, compared to other methods reasonably. In absence of any context the model hallucinates or provide any wrong information due to irrelevant context, rarely, resulting in a good accuracy of summary generated. In comparison to the proposed method(method 4), method 1 obviously lags in terms of informativeness and slight difference in accuracy due to absence of relevant contextual information.\nIn method 2 the context is retrieved entirely using the SOTA context retrieval methods. However, the context extracted is not always pertinent to the packet data leading to a poor accuracy of the method compared to others. The main downside observed in this method was irrelevant context extraction resulting in misleading information in the summary."}, {"title": "7 Conclusion", "content": "In this paper, we discussed methods for generating packet data summaries to extract relevant information from network packets. We proposed a Retrieval-Augmented Generation (RAG) approach that combines existing context retrieval techniques with mapping-based context retrieval to produce comprehensive summaries. This solution can assist SOC operators in quickly understanding packet data, help train new analysts, and provide clear explanations to non-technical stakeholders.\nThe proposed solution however suffers from the drawback of extracting large amount of context, if a packet file has lot of packets, which can result in the LLM running out of context window. In the future, we aim to address current limitations, such as handling packet files with a large number of packets and extracting more focused context for our summaries. We also plan to expand our solution beyond BACnet packets to other ICS networks, incorporate additional information, such as Intrusion Detection System (IDS) alerts and improve our evaluation data accordingly."}, {"title": "A Output Examples", "content": "In this section, we show examples of a few summaries generated by our proposed solution. For privacy reasons some information has been omitted."}]}