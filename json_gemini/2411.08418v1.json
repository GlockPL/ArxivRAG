{"title": "Enhanced Classroom Dialogue Sequences Analysis with a Hybrid AI Agent: Merging Expert Rule-Base with Large Language Models", "authors": ["Yun Long", "Yu Zhang"], "abstract": "Classroom dialogue plays a crucial role in fostering student engagement and deeper learning. However, analysing dialogue sequences has traditionally relied on either theoretical frameworks or empirical descriptions of practice, with limited integration between the two. This study addresses this gap by developing a comprehensive rule base of dialogue sequences and an Artificial Intelligence (AI) agent that combines expert-informed rule-based systems with a large language model (LLM). The agent applies expert knowledge while adapting to the complexities of natural language, enabling accurate and flexible categorisation of classroom dialogue sequences. By synthesising findings from over 30 studies, we established a comprehensive framework for dialogue analysis. The agent was validated against human expert coding, achieving high levels of precision and reliability. The results demonstrate that the agent provides theory-grounded and adaptive functions, tremendously enhancing the efficiency and scalability of classroom dialogue analysis, offering significant potential in improving classroom teaching practices and supporting teacher professional development.", "sections": [{"title": "1. Introduction", "content": "Classroom dialogue plays a crucial role in fostering student engagement, knowledge construction, and critical thinking (Alexander, 2008; Mercer & Dawes, 2014). High- quality dialogue enables students to articulate their thoughts, reason through problems, and collaboratively build on each other's ideas-key processes for deep learning (Howe & Abedin, 2013). Analysing classroom dialogue is therefore essential for assessing dialogue quality and providing educators with insights to refine their teaching practices. Through structured analysis, researchers and practitioners can evaluate how well classroom interactions align with theoretical models of effective dialogue, ultimately bridging the gap between theory and practice to improve learning outcomes.\nDespite its importance, the current landscape of classroom dialogue analysis remains fragmented. Most studies fall into two primary domains: theoretical analysis and empirical investigation. Theoretical analyses focus on identifying ideal dialogue sequences that align with pedagogical goals, such as fostering exploratory talk or critical inquiry (Mercer & Wegerif, 1999; Howe et al., 2019). These studies provide normative models that define what classroom dialogue should look like. Conversely, empirical research emphasises describing actual dialogue patterns observed in real classrooms, often revealing significant deviations from theoretical ideals (Nystrand et al., 2003). However, these data-driven studies tend to prioritise empirical accuracy"}, {"title": "2. Literature Review", "content": ""}, {"title": "2.1 Classical approaches of classroom dialogue sequences analysis", "content": "The study of classroom dialogue sequences has long focused on two fundamental questions: (1) What are the ideal dialogue sequences that support different teaching goals, and (2) How do real-world classroom dialogue sequences compare to these ideal sequences? These two approaches have shaped much of the classical research on dialogue sequence analysis.\nThe first approach, theory-driven or deductive, examines ideal dialogue structures designed to achieve specific pedagogical goals. These studies often draw on well- established frameworks, such as Bloom's Taxonomy (Bloom, 1956) and the Cambridge Dialogue Analysis Scheme (CDAS) (Howe et al., 2019), to propose sequences that optimise learning. Examples include exploratory talk, which fosters critical engagement and deep learning (Mercer & Wegerif, 1999), and cumulative talk, where students build uncritically on each other's ideas to enhance mutual understanding (Mercer, 1995). Other notable types include Socratic dialogue, which uses systematic questioning to deepen understanding (Dillon, 1988), and accountable talk, emphasising rigorous thinking and coherence (Michaels et al., 2008). These frameworks identify ideal sequences, such as reasoning and elaboration chains, to promote higher-order thinking and collaborative knowledge construction, providing a theoretical blueprint for effective classroom interactions.\nThe second approach, data-driven or inductive, focuses on analysing real-world classroom dialogue sequences to determine how closely they align with the ideal patterns proposed by theory. Researchers in this domain collect and analyse dialogue data, seeking to understand whether actual classroom interactions meet the theoretical expectations for effective learning. Studies have revealed that real-world classroom dialogues often diverge from these ideal patterns, with teachers frequently controlling the flow of dialogue and students having limited opportunities for extended reasoning or questioning (Nystrand et al., 2003). This inductive analysis often highlights the gap between theory and practice in classroom discourse, underscoring the challenges of implementing idealised dialogue sequences in diverse educational contexts.\nTo perform such analyses, researchers frequently employ common sequence analysis methods such as Lag Sequential Analysis (LSA), Markov Chains, Process Mining, and Epistemic Network Analysis (ENA). Lag Sequential Analysis (LSA) has been widely used to identify temporal patterns in classroom interactions by examining the conditional probabilities of one event following another (Bakeman & Quera, 2011). This method is particularly valuable for understanding the structure of classroom dialogue by identifying recurring sequences of events, such as teacher questions followed by student responses. Markov Chains are often used to model the probabilistic transitions between different states in a dialogue sequence. By mapping"}, {"title": "2.2 AI-facilitated classroom dialogue analysis", "content": "Recent years have seen growing interest from leading scholars in the use of automated annotation technology in classroom research. Automated annotation refers to the use of machine learning algorithms to code transcribed classroom dialogues based on predefined codes, offering significant advantages in accuracy, speed, and scalability compared to traditional observation and statistical methods (Song, 2022). The process typically involves three stages: dataset creation, model training (a key part of machine learning), and automated coding. Among these, model training is pivotal, primarily relying on neural network algorithms (LeCun et al., 2015).\nThe common algorithms used for automated annotation include convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and recurrent neural networks (RNNs), each excelling in different aspects of language processing. CNNs, for example, excel at capturing local semantic information, while LSTMs, as a more complex type of RNN, are designed to better handle long sequences of information. These technical advances not only improve the efficiency of dialogue analysis but also enable deeper insights into the underlying patterns of instructional practices. By analysing large-scale data, these algorithms can validate or refine existing pedagogical theories and uncover previously unrecognised dialogue features, contributing to the development of new theoretical frameworks.\nOnce the dialogue data is annotated, data mining techniques come into play to extract valuable patterns and relationships. Methods such as sequence pattern discovery, classification, clustering, and association rule mining are commonly applied (Wang et al., 2024). Sequence mining, in particular, holds unique advantages in identifying the temporal order of behaviours and speech, helping to uncover insights into how classroom discussions unfold over time (Santangelo, 2009). This type of analysis allows researchers to go beyond surface-level interactions such as question and response frequency, to investigate the deeper, cognitive processes that are influenced by dialogue sequences.\nThe first orientation is structure-based, focusing on identifying and categorising dialogue sequences using predefined theoretical frameworks. This approach often employs quantitative methods, such as Lag Sequential Analysis or Markov Chains, to capture the structural dynamics of dialogue patterns. Unlike previous studies that primarily use descriptive methods or rely on surface-level interaction features, these techniques delve deeper into the temporal and probabilistic relationships between dialogue moves. For instance, Lag Sequential Analysis examines the likelihood of specific dialogue moves following one another, while Markov Chains model the probabilistic transitions between states, offering a more systematic and predictive understanding of dialogue structure. This distinguishes them from more inductive, data-driven methods that lack a firm theoretical grounding. In contrast, the second orientation is function-based, where the focus is on the qualitative aspects of dialogue and its ability to foster thinking and reasoning. Recent efforts, like the CDAS (Howe et al., 2010) and the Teacher Scheme for Educational Dialogue Analysis (T-SEDA, Vrikki et al., 2018), emphasize dialogue features such as elaboration, reasoning, challenging and reflection. Other studies have applied NLP techniques to analyse group discussions, revealing patterns that enhance collaboration and knowledge construction (Wu et al., 2018; Song, 2022; Cukurova et al., 2018). Data mining and evidence-based methods have been employed to identify high-quality classroom behaviours, such as asking thought-provoking questions, but they often rely on post"}, {"title": "3. Research design and methods", "content": "To address the limitations of existing dialogue analysis approaches and bridge the gap between theoretical frameworks and empirical data, this study adopts a hybrid methodology. By combining expert-informed rule-based systems with the flexibility of LLMs, we aim to create an Al agent capable of accurately categorising and analysing classroom dialogue sequences in real time. This section outlines the research design, including the consolidation of existing dialogue types, the development of expert rules, and the implementation of the hybrid Al agent. The overall process is illustrated in Figure 1, which provides a visual representation of the study's methodological framework."}, {"title": "3.1 Consolidation of Existing Classroom Dialogue Types", "content": "The initial step in our research design involves a thorough categorisation of existing dialogue types based on a comprehensive review of the literature on classroom dialogues (as shown in Figure 1). This review encompasses seminal works and recent studies that have identified various types of teacher-student and student-student interactions. From these studies, we synthesised the characteristics and patterns of effective classroom dialogues to form a consolidated categorisation. This categorisation serves as the foundational taxonomy necessary for defining new dialogue categories and their corresponding characteristics.\nThen we define new dialogue categories and describe their unique characteristics. These definitions are based on the synthesised literature. We then employed the adapted coding scheme based on the Cambridge Dialogue Analysis Scheme (CDAS, Howe et al., 2019) to represent these newly defined categories. The adapted coding scheme includes categories such as Elaboration Invitation (ELI), Reasoning Invitation (REI), Elaboration (EL), Reasoning (RE), Coordination Invitation (CI), Simple"}, {"title": "3.2 Articulating Dialogic Sequences and Rules Development", "content": "The primary objective of this stage is to establish an expert rule base for dialogue sequences, which will serve as the foundation for subsequent analyses. This involves synthesising dialogue types and sequences from a comprehensive literature review, classifying them based on their pedagogical goals, and identifying gaps in the existing framework to ensure a robust and inclusive rule base.\nTo build the expert rule base, we conducted a systematic review of 30 peer-reviewed studies focused on classroom dialogue. These studies span various instructional contexts, covering key pedagogical frameworks such as exploratory talk (Mercer &\nWegerif, 1999), dialogic teaching (Alexander, 2008), accountable talk (Michaels et al., 2008), and Socratic dialogue (Dillon, 1988). Each study was analysed to extract its core teaching goals and associated dialogue sequences. Table A1 (see Appendix) summarises the reviewed studies, their core teaching goals, and the dialogue sequences they propose.\nThe extracted sequences were then classified into broader categories based on their pedagogical functions. This process involved grouping sequences that shared similar instructional objectives, such as fostering critical thinking, promoting collaboration, or encouraging metacognitive reflection. For instance, sequences like \u201cReasoning Invitation \u2192 Reasoning\u201d and \u201cElaboration Invitation \u2192 Elaboration\u201d were classified under the broader category of Critical Inquiry, as they both aim to deepen students' reasoning and analytical skills. Similarly, sequences promoting collaborative construction of knowledge, such as \u201cSimple Co-ordination \u2192 Agreement\u201d and \u201cReasoned Co-ordination \u2192 Elaboration,\u201d were grouped under Collaborative Learning.\nThis classification process was iterative, involving multiple rounds of discussion and refinement to ensure consistency and coherence. An initial draft of the categorisation was independently reviewed by two domain experts, and discrepancies were resolved through consensus.\nDuring the review, we identified gaps where certain pedagogical goals, such as fostering student agency or addressing socio-emotional aspects of learning, were underrepresented. For example, few studies provided explicit sequences for dialogues aimed at promoting self-regulation or emotional engagement. To address these gaps, we proposed new sequence categories based on theoretical frameworks, such as Zimmerman's model of self-regulated learning (Zimmerman, 2002), and extended"}, {"title": "Validation of the Rule Base Development Process", "content": "To validate the effectiveness of this process, we employed two strategies. First, a panel of five educational researchers reviewed the refined rule base to evaluate its comprehensiveness and theoretical alignment. Their feedback on the clarity and appropriateness of the categories informed further revisions. Second, we conducted an inter-rater reliability test, where two independent coders applied the expert rule base to a subset of classroom dialogue data. The Cohen's Kappa values for each category were above 0.85, indicating high consistency. While this demonstrates the clarity and usability of the rule definitions, it only indirectly supports the validity of the categorisation itself.\nThis rigorous validation process ensures that the expert rule base not only captures the complexity of classroom dialogue but also aligns closely with established pedagogical theories."}, {"title": "3.3 Automated Annotation Agent Development and Validation", "content": "To automate the annotation process, we developed an LLM-based agent that recognises sequences in classroom dialogues using the expert rules defined in the rule base. This section outlines the methods used for validating the agent's performance, focusing on inter-coder reliability and time cost efficiency."}, {"title": "Inter-Coder Reliability Evaluation", "content": "To assess the consistency of the automated tool in applying expert-defined rules, we employed Cohen's Kappa, a widely recognised metric for inter-coder reliability. This metric measures the level of agreement between two coders, with values ranging from 0 to 1. Kappa values above 0.75 indicate strong agreement. In this study, Cohen's Kappa was used to compare the automated tool's categorisation of dialogue sequences with those of human coders across multiple dialogue categories."}, {"title": "Time Cost and Efficacy Assessment", "content": "We evaluated the efficiency of the automated tool by comparing its coding speed with that of manual annotation. For this purpose, human coders and the automated tool were tasked with coding the same dataset, which comprised 1,084 dialogue turns. The time taken by each method to complete the annotation was recorded to assess the potential time savings offered by the automated tool. This evaluation also considered the tool's scalability and cost-effectiveness for large-scale educational research."}, {"title": "4. Results", "content": ""}, {"title": "4.1 Consolidating Classroom Dialogue Types Based on Previous Research", "content": "To address the first research objective, we synthesised various types of classroom dialogues identified in the 30 reviewed studies to develop a comprehensive framework that captures the diversity and complexity of classroom interactions. This framework is grounded in both the pedagogical goals and the dialogue sequences extracted from the literature. The consolidation process involved categorising these sequences into four primary dialogue types based on their instructional purposes: Critical Inquiry, Collaborative Construction of Knowledge, Instructional and Supportive Dialogue, and Reflective and Metacognitive Dialogue. These categories are summarised in Table 2, which lists the corresponding teaching goals and key sequences associated with each type."}, {"title": "4.2 Developing rules for the expert rule-based Al agent", "content": "To categorise classroom dialogues effectively, we developed an expert rule base that consolidates theoretical and empirical insights into four key dialogue categories:\nCritical Inquiry, Collaborative Construction of Knowledge, Instructional and Supportive Dialogue, and Reflective and Metacognitive Dialogue. Each category is defined by a meta-rule that guides its identification, key features that characterise its structure, and illustrative examples demonstrating its practical application. These elements ensure the framework's applicability across diverse educational settings."}, {"title": "4.3 Developing Expert Rule-Based AI Agent for Sequence Analysis and Validation", "content": ""}, {"title": "The developing process of the expert rule-based AI agent", "content": "The expert rule-based AI agent for sequence analysis was developed by building upon the automatic dialogue analysis agent proposed by authors (2024). Expert rules were systematically fed into the previous agent, enabling it to recognise specific dialogue sequences across various categories. The development process focused on ensuring that the agent accurately applied these rules to categorise classroom dialogues effectively."}, {"title": "Data collection and evaluation framework", "content": "The sample for this study consisted of classroom dialogue data from a middle school in China, comprising 12 classes, including both Chinese and mathematics lessons. A total of 1,084 dialogue turns were recorded and analysed. To validate the performance of the expert rule-based AI agent, human coders manually annotated the same dataset for comparison.\nThe evaluation framework centred on several key metrics: accuracy, consistency, time cost, scalability, and cost-effectiveness. Accuracy and consistency were measured using precision with comparisons made between the agent's outputs and human coders' annotations. Cohen's Kappa was employed to assess inter-coder reliability. Performance in terms of speed and consistency was evaluated by comparing the agent's processing time with that of human coders, while scalability and efficacy were gauged through the agent's ability to handle large datasets efficiently. Finally, cost-"}, {"title": "Accuracy and consistency", "content": ""}, {"title": "Precision Comparison with Human Coders", "content": "The coding performance of the coding tool was compared with human coders using common evaluation metrics, mainly including precision, to assess its accuracy in applying the coding scheme to classroom dialogues.\nPrecision measures the proportion of the tool correctly identifies and categorises dialogue sequences that match human annotations. In this case, the tool demonstrated high precision across several categories. For instance, the tool achieved a precision of 97.3% for coding critical inquiry dialogues, meaning that when the tool coded a dialogue as constructively challenging interlocutors, it matched human coders 97.3%\nof cases. Additionally, the tool achieved a precision of 95.6% for coding collaborative construction of knowledge dialogues. This indicates that when the tool identified a dialogue as promoting shared understanding or knowledge co-construction, it agreed with human coders 95.6% of the time. For instructional and supportive dialogue, the tool demonstrated a high precision of 98.1%, meaning that it correctly matched human annotations 98.1% of the time when identifying dialogues that provided instruction or support. Lastly, the tool achieved a precision of 96.5% for coding reflective and metacognitive dialogues, showing a 96.5% agreement with human coders when categorising dialogues focused on reflection or metacognition."}, {"title": "Inter-Coder Reliability", "content": "The automated agent demonstrated substantial agreement with human coders across various dialogue categories, achieving a Cohen's Kappa score of 0.952 in categorising\ncritical inquiry dialogues. This exceptionally high score reflects the agent's strong ability to reliably classify complex dialogue interactions, closely matching human annotations. Additionally, the tool achieved a Cohen's Kappa of 0.871 for collaborative construction of knowledge dialogues, indicating robust agreement with human coders in identifying shared understanding or co-construction of knowledge. For instructional and supportive dialogue, the agent reached a Kappa score of 0.914, further demonstrating its consistency in coding dialogues that offer instructional guidance or support. Lastly, the tool achieved a Cohen's Kappa of 0.895 for reflective and metacognitive dialogues, showing that it closely aligned with human annotations in recognising reflective and metacognitive interactions.\nThe high Kappa scores across multiple dialogue types, including elaboration invitations and reasoning sequences, underscore the robustness of the expert rule base. These results indicate that the tool consistently applies the coding framework in a\nwide range of classroom contexts, reducing variability and ensuring reliable performance regardless of the complexity of the dialogues being analysed."}, {"title": "Performance in Speed and Consistency", "content": "The automated tool consistently outperformed manual coding in both speed and consistency, particularly in handling complex dialogue sequences. For example, in coding intricate patterns like elaboration followed by reasoning (dialogues include ELI \u2192 EL \u2192 RE sequence), the tool applied the coding rules with an accuracy of\n95%, whereas human coders often showed variability, especially in borderline cases where distinctions between elaboration and reasoning were subtle.\nAdditionally, the tool reduced inconsistencies that often arise from human subjectivity, particularly in dialogue types that require nuanced interpretations, such as reflective dialogue and instructional talk. Human coders may differ in their interpretation of these subtle distinctions, but the automated agent applied the coding rules consistently, ensuring that the same criteria were used across all dialogues. This\nconsistency enhances the reliability of the analysis, leading to more robust and reproducible research outcomes."}, {"title": "Time cost and efficacy", "content": ""}, {"title": "Comparison of Time Taken", "content": "The automated tool provides significant time savings compared to manual coding. On average, manually coding a classroom session with 100 dialogue turns took a human coder approximately 3.5 to 4 hours, while the automated tool processed the same data\nin just 8 to 10 minutes, representing a 96% reduction in coding time. This drastic improvement in efficiency allows for faster data processing and analysis, freeing up\nvaluable research time and resources."}, {"title": "Scalability and Efficacy", "content": "The introduction of automation in dialogue coding significantly enhances the scalability of research, allowing researchers to handle much larger datasets than was feasible with manual methods. With the automation of coding, researchers can now analyse dialogue data from hundreds of classrooms in a fraction of the time, making\nlarge-scale, longitudinal studies both practical and achievable. This scalability enables the collection and analysis of data from diverse educational settings, providing a more comprehensive understanding of classroom interactions.\nIn addition, the tool's ability to process large datasets improves the generalizability of research findings. Traditional manual coding often limits studies to smaller sample\nsizes due to the significant time and effort required. With automation, however, researchers are no longer constrained by these limitations and can analyse data from large, varied samples, resulting in findings that are more widely applicable across\ndifferent contexts. This scalability not only enhances the robustness of research but also provides deeper insights into classroom dialogue patterns, leading to more reliable and actionable conclusions for educators and policymakers."}, {"title": "5. Conclusion & Discussion", "content": ""}, {"title": "5.1 Summary of results", "content": "This study achieved two significant outcomes. First, we developed a comprehensive expert knowledge base specifically designed for classroom dialogue sequence analysis. To the best of our knowledge, this knowledge base synthesises and\ncategorises a large body of research, drawing from more than 30 published studies. It provides an extensive classification of dialogue categories, offering a detailed and\nexhaustive analysis of the various types of interactions observed in classroom settings. The thoroughness of this classification ensures that the knowledge base can accommodate a broad range of dialogue sequences, making it an invaluable resource for future studies on classroom discourse.\nSecond, we successfully developed an LLM-based agent that integrates the advantages of rule-based systems and general AI. By combining precise, expert- informed rules with the adaptability and pattern-recognition capabilities of general AI,\nthe agent is capable of accurately identifying and categorising dialogue sequences"}, {"title": "5.2 Signification of the study", "content": "The significance of this research is twofold. First, this study represents a significant advancement in applying rule-based AI systems to the analysis of classroom dialogue\nsequences. While rule-based AI has been applied in other domains, its introduction into classroom interaction research is relatively novel. The combination of an expert- informed rule-based system with advanced LLMs enables a more structured and theoretically grounded analysis of dialogue patterns. This approach can deepen our\nunderstanding of classroom dynamics by ensuring that the agent's categorisations are aligned with established educational theories, offering more accurate and reliable insights compared to methods driven purely by data patterns.\nSecond, although the current expert knowledge base is comprehensive, it remains adaptable and open to future refinement. The structure of this knowledge base allows\nfor continual improvement as more data becomes available and new insights emerge. Researchers have the opportunity to collaboratively expand the knowledge base, incorporating a greater variety of dialogue sequences and creating more nuanced\nsubcategories within existing categories. This ongoing expansion enhances the diversity of the sequences covered and improves the robustness of the dialogue categorisation process. In this way, the expert knowledge base can evolve to meet the\ngrowing complexity of classroom dialogue analysis.\nIn summary, in terms of theoretical value, this research introduces a new methodology for analysing classroom dialogue, providing a scalable and systematic approach that is deeply rooted in educational theory. Practically, the development of this agent has\nsignificant implications for educators, as it enables real-time feedback on classroom interactions. By offering immediate insights into the quality of dialogue, the agent allows teachers to adjust their instructional strategies dynamically, thereby improving\nstudent outcomes. Additionally, the foundation laid by this study opens the door for future research aimed at refining and expanding the expert rule base, further enhancing the accuracy and applicability of classroom dialogue analysis in various\neducational contexts."}, {"title": "5.3 Future Directions", "content": "Looking towards the future, several avenues for further research and development emerge from this study. One promising direction is the continual expansion and\nrefinement of the expert knowledge base. As more data from diverse classroom settings becomes available, researchers can collaboratively work to refine the categories and subcategories within the knowledge base. This will allow for a more\nnuanced and comprehensive understanding of dialogue sequences, especially as educational contexts continue to evolve and diversify. By building a richer knowledge base, future research can address increasingly complex classroom interactions,\naccommodating a wider range of teaching styles and learning environments.\nThe agent's ability to categorise and analyse large volumes of classroom dialogue opens the possibility of aggregating these results into a comprehensive quantitative\ndatabase. This approach enables the integration of qualitative insights with quantitative methods, allowing for large-sample statistical analyses that can uncover\npatterns and correlations across diverse educational settings. By bridging qualitative depth with quantitative breadth, such a database could support meta-analyses, trend\nidentification, and the validation of pedagogical theories on an unprecedented scale. These findings would provide actionable insights for both researchers and educators,\nenhancing evidence-based teaching practices. Furthermore, as the agent evolves, it could be integrated into teacher training programs to offer low-stakes, formative\nfeedback for early-career educators. This feedback would help teachers refine their instructional strategies and foster deeper student engagement, leveraging real-time insights without the pressure of high-stakes evaluations. Together, these capabilities\nposition the agent as a powerful tool for advancing both research and practice in education.\nIn conclusion, the expert rule-based agent and knowledge base developed in this study lay the groundwork for future theoretical advancements and practical applications in\nclassroom dialogue analysis. By continuing to refine and expand the agent, researchers and educators alike can benefit from a more sophisticated understanding\nof classroom interactions, ultimately improving teaching quality and student learning experiences."}, {"title": "CRediT authorship contribution statement", "content": "Yun Long: Writing \u2013 original draft, Methodology, Formal analysis,\nConceptualization. Yu Zhang: Writing \u2013 review & editing, Methodology, Conceptualization, Supervision."}, {"title": "Data availability", "content": "Data will be made available on request."}]}