{"title": "Quantitative Assessment of Intersectional Empathic Bias and Understanding", "authors": ["Vojt\u011bch Form\u00e1nek", "Ond\u0159ej Sotol\u00e1\u0159"], "abstract": "A growing amount of literature critiques the current operationalizations of empathy based on loose definitions of the construct. Such definitions negatively affect dataset quality, model robustness, and evaluation reliability. We propose an empathy evaluation framework that operationalizes empathy close to its psychological origins. The framework measures the variance in responses of LLMs to prompts using existing metrics for empathy and emotional valence. The variance is introduced through the controlled generation of the prompts by varying social biases affecting context understanding, thus impacting empathetic understanding. The control over generation ensures high theoretical validity of the constructs in the prompt dataset. Also, it makes high-quality translation, especially into languages that currently have little-to-no way of evaluating empathy or bias, such as the Slavonic family, more manageable. Using chosen LLMs and various prompt types, we demonstrate the empathy evaluation with the framework, including multiple-choice answers and free generation. The variance in our initial evaluation sample is small and we were unable to measure convincing differences between the empathetic understanding in contexts given by different social groups. However, the results are promising because the models showed significant alterations their reasoning chains needed to capture the relatively subtle changes in the prompts. This provides the basis for future research into the construction of the evaluation sample and statistical methods for measuring the results.", "sections": [{"title": "1 Introduction", "content": "While there has been a vast amount of literature on empathy, it has come under increased scrutiny due to the unclear way of operationalizing empathy [13, 12]. Loosely defining empathy as the ability to understand another person's feelings and respond appropriately [12] was shown to cause problems across different tasks, such as dataset creation [5], training [30], evaluation [12]. This ambiguity led to a narrow focus on emotion recognition and prediction. We argue, alongside previous work, that this effort misunderstands empathy's psychological origins."}, {"title": "2", "content": "To improve upon the current operationalizations of empathy, we propose a framework with (i) a disambiguation of empathy, (ii) measurement operationalization specifically for computational models and (iii) an evaluatory procedure.\nSome of the problems stem from the disagreement on the definition of empathy within psychology itself [4]. It was originally used to describe human ability to understand others [15, 11]. Current research agrees that it has two components to achieve this: affective empathy, sometimes also named emotional empathy, and cognitive empathy [31]. Affective empathy refers to the capacity to feel emotions for others as a result of our belief, perception or imagination of their situation [16]. Cognitive empathy involves theorizing about and simulation of others mental states [31], that is to: (i) retrodictively simulate a mental state, to explain observed behavior, (ii) take that mental state and run it through our cognitive mechanisms, and (iii) attribute the conclusion to the target for explanation and prediction.\nSince cognitive empathy is dependent on one's cognitive mechanisms, it is also dependent on experience. Because of that, a person can have different levels of understanding based on the similarity of his experience and the state he is observing and feel different levels of empathy toward different social groups [37]. This effect is carried over to LLMs [25, 22, 32, 3] which are reinforced on human preference data. Observing if models exhibit this type of bias toward some of the groups thus can be leveraged to indirectly study empathy.\nWe propose an empathy evaluation framework for conversational agents, such as LLMs, which focuses on empathetic understanding. The framework uses masked templates to generate an evaluation dataset of prompts designed for the agents to respond to. The templates include masked sections into which different information is inserted. The information is biased towards different social groups; the selection of the type of information, the values, and social groups are inspired by current research such as reviewed in Gallegos et al. [8].\nFilling the masked section with varying values results in the evaluation sample. This enables measuring the variance in responses across a single template, which assumes the invariance in empathetic understanding, affect, and responding both inside and at the intersection of different social groups. This invariance also means that within the framework, bias manifests as a deviation from a given social group's central tendency.\nThis might or might not be preferable; thus, we give fine-grained tools for interpreting the scores within a given intersectional group individually. Taking into account Blodgett et al.'s [1] criticism of the study of biases, within the framework we only study the tendencies in model outputs and make no claims about the potential harmfulness or possible impacts of the biases. We make all of the data and code publicly available\u00b3."}, {"title": "2 Related Work", "content": "Several metrics have been proposed for evaluating bias in generated outputs [8]. They are either based on a difference in the distribution of tokens in the generated outputs between distinct groups [23], a classifier, typically used to detect toxicity [28, 29], or a lexicon [6]. The datasets used for evaluating bias deal with various social groups and issues (see Table 4. in [8] for an overview) and are sometimes created from existing datasets. Sample construction involves replacing the relevant social group identifiers (gender, race, etc.) with a mask, thus creating masked samples. When evaluating, the masks are substituted with examples from the same group. The shift in the responses is measured [19, 35], assuming that the output should be invariant of the social group. This technique is sometimes called bias mitigation via contact hypothesis [22], a term borrowed from psychology referring to direct contact with other social groups [20].\nDatasets used to train empathetic agents are typically single or multi-turn, with emotional labels [2, 24]. However, other datasets, by their nature, contain empathy as well, such as transcripts of everyday conversations [14], simulation of other's personas [36] or transcripts of therapies [17, 21], labeled with conversational behaviors [3]. Retroactively categorizing existing empathy metrics into the two dimensions is difficult, especially since they likely overlap.\nSince cognitive empathy involves understanding, the accuracy of emotion prediction can be considered a case of it, but a broader understanding has also been measured. Zhu et al. [38] collected user comments about products and their do-, motor- and be-goals [10], then instructed human or LLM designers to predict those goals and measured the token similarity between them.\nThe problems with measuring affective empathy are caused mainly by its dependence on an inner state. Lee et al. [13] uses metrics based on the model responses, thus might include mechanisms outside empathy. However, since the metrics measure the qualities indirectly, we mention them here. Representative of this group is specificity, which is based on a normalized variant of inverse document frequency (NIDF) [26] and measures the similarity in the vocabularies of the model and user. They also introduce valence, arousal, and dominance based on the NRC Emotion Intensity Lexicon [18]. With the focus on the similarity of the input and output texts, closer results are preferred. All of the affective metrics assume that empathy in this context manifests in the similarity.\nLee et al.'s metrics also fall into the category of empathetic responding, which is the focus of many currently existing measures. EPITOME is a ROBERTa-based model that predicts three dimensions on a scale (0-2; none, weak, strong): Empathetic Responses (ER), Explanations (EX) and Interpretations (IP) [27]. Chiu et al. [3] evaluate differences between human and LLM therapists and define several dimensions whose quality is in part dependent on the empathetic capacity of the therapist - Reflections, Questions, and Solutions.\nAll of the metrics depend on the true state of the evaluated sample (for example, the emotion). This makes both dimensions of empathy dependent on this state, meaning that misunderstanding leads to an inaccurate effect. Thus, we cannot separate affective from cognitive empathy. For this reason, Coll et al. [4]"}, {"title": "3 JaEm-ST: Framework for the Quantitative Assessment of Empathetic Behavior of LLMs", "content": "We propose the evaluation framework, JaEm-ST, where empathy has two dimensions, Cognitive and Affective, which follow the definitions introduced in Section 1. However, we operationalize the measurement into three metrics. Cognitive empathy (CE), the degree to which the empathizer understood the observed state correctly. Affective empathy (AE), the degree to which the empathizer's state matches that of the understood state (inspired by Coll et al. [4]). Lastly, we define Empathic Response Appropriateness (ERA) to the understood state, which is the result of the empathic process (and several others) but not its dimension. In our context, we define \"state\" as a person's momentary mental and physical circumstances."}, {"title": "3.1 Theoretical Basis of the Framework", "content": "Dependence of cognitive empathy on experience means that different empathizers might come to different conclusions about an observed state, even when self-reporting [9]. This impacts the evaluation on two sides: (i) LM empathizers might interpret the situation differently, which does not mean that it is false, and (ii) the \"true states\" constructed by the creator might not even be reflective of their empathetic understanding. Thus, it is difficult, if not impossible, to determine whether a given interpretation is genuinely false, but it is nonetheless representative of a human interpretation grounded in experience. For this reason, AE and ERA depend on the model's understanding of the state, so it is possible to evaluate an output even when it does not interpret the context in the same way as the creator of that template. But if we concede that the interpretation of states is subjective, then we need another standard for the evaluation.\nIn our case we assume that empathetic understanding is invariant across similar situations; the implications of this assumption are discussed later. Which is why JaEm-ST focuses on finding systemic differences in model output when responding to similar situations and uses the similarity between the \"true state\" and the one predicted by the model as a guiding principle. Given that experience can lead to biases, we create the evaluation examples by inserting values sampled from the representatives of different social groups (such as specific gender, education etc.) into the masked templates (see Fig 1). Thus two examples created from the same template differ only in the specific intersectional groups that were inserted into them."}, {"title": "3.2\nEvaluation Sample", "content": "We create the evaluation sample dynamically from a small seed dataset of predefined templates. The templates simulate conversations between a human speaker"}, {"title": "3.3\nExperimental setup", "content": "For the evaluation, we constructed two causal tuples and templates, as shown in Figure 1. To produce the evaluation sample, the templates are dynamically filled with the context-dependent information resulting from the Cartesian product of all of the predefined replacement values of the studied social groups. Since the product would be too large given any non-minimal value vectors, for this experiment, we focus only on two of the dimensions: gender and pronoun. We take their Cartesian product four times, then randomly sample from the rest of the dimensions. We get 486 samples for generation or multi-choice, so each model is evaluated with 972 samples, that is 1944 inputs in total.\nBecause we aim to maintain an understandable, controllable, high quality dataset with high ecological validity, we keep the number of templates relatively low. This also means that it is relatively simple to translate the templates to other languages. This could be especially beneficial for low resource languages, that currently have little to no way of evaluating bias or empathy.\nThe samples are given as input to a model in a single-turn fashion, which is most typical for evaluating empathy. The sample is used as is, in the order: (i) promptCE, context, conversation, answers for CE multiple choice, (ii) context, conversation for AE and ERA. And we pass each to the model separately. Because of the small amount of templates, the variability of the input is"}, {"title": "4 Results", "content": "We measured the largest differences in all three dimensions: Cognitive Empathy (CE), Affective Empathy (AE) and Empathetic Response Appropriateness (ERA) accuracy of multiple-choice answers (CE), VAD (AE) and EPITOME scores (ERA) between the two models and the two templates, as shown in Table 1. The differences between the intersectional groups are relatively stable. Generally, zephyr-gemma performed much worse in CE. The results show that it\nwas easiest for both of the models to find the answer with the most understanding to the sample shown in Figure 1. The differences in AE scores between the models are smaller and Llama-3.1 achieves lower scores and smaller differences between the two samples, ERA scores are similar.\nThere are no obvious differences between the pronouns. We found outliers in the interaction of these groups, such as Lesbian/She, which has an Interpretations (IP) score significantly above the overall average (\u03c3 = 3.36), but were unable to find any significant differences in the generated output.\nBoth models followed the multi-choice prompt well. For the free generation, manual inspection of a small subset the outputs suggests that Llama-3.1 might follow role-playing better, zephyr-gemma tends respond from the third perspec-"}, {"title": "5 Conclusion", "content": "We provided a disambiguation of empathy for computational models to help future work define the construct closer to its psychological origins as opposed to the loose definitions that are currently widespread. As a main result, we proposed a new empathy evaluation framework for the responses generated by conversational agents that acknowledges the inherent subjectivity of empathetic understanding. The framework focuses on how it is influenced by intersectional bias. It provides methods to generate evaluation samples from templates by inserting the intersectional contexts into them. The framework uses a new three-dimensional measurement operationalization of empathy to measure the construct. We demonstrated the usage of the framework on a small synthetic sample. In all three framework dimensions, we measured significant differences between the Llama-3.1-8B and Zephyr-gemma-v.1 models. Lastly, we identified differences in empathetic understanding across the evaluated metrics in some intersectional groups. More importantly, we showed the framework's strength in providing the ability to stratify scores across a wide range of social contexts, giving a more fine-grained insight into model behavior and potential harms."}, {"title": "Limitations", "content": "We view the modest number of templates as a limitation. Even though we can produce many examples by substituting into the masks, most of their structure stays the same. Further, the contexts and conversations do not reflect the variation across multiple different groups; future work should also focus on increasing the diversity of the sample creators. The template structure itself, especially the inclusion of context as an explanation of the speaker's background, does hurt the naturalness and ecological validity of the framework. Since the models generate more than just the expected response, future works should explore different ways to insert the context into the model. Furthermore, while the number of empathy metrics in this work is limited, future works can use the outlined criteria to include other metrics."}]}