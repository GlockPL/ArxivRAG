{"title": "Lotus at SemEval-2025 Task 11: RoBERTa with Llama-3 Generated\nExplanations for Multi-Label Emotion Classification", "authors": ["Niloofar Ranjbar", "Hamed Baghbani"], "abstract": "This paper presents a novel approach for multi-\nlabel emotion detection, where Llama-3 is used\nto generate explanatory content that clarifies\nambiguous emotional expressions, thereby en-\nhancing ROBERTa's emotion classification per-\nformance. By incorporating explanatory con-\ntext, our method improves F1-scores, particu-\nlarly for emotions like fear, joy, and sadness,\nand outperforms text-only models. The addi-\ntion of explanatory content helps resolve am-\nbiguity, addresses challenges like overlapping\nemotional cues, and enhances multi-label clas-\nsification, marking a significant advancement\nin emotion detection tasks.", "sections": [{"title": "1 Introduction", "content": "Emotion classification plays a crucial role in natu-\nral language processing (NLP) for applications like\nsentiment analysis and emotion-aware dialogue sys-\ntems (Mohammad and Kiritchenko, 2018). The\nchallenge lies in accurately identifying emotions\nfrom text, which are often subtle, multi-faceted,\nand context-dependent. Furthermore, emotions can\nbe expressed simultaneously, making multi-label\nclassification essential (Belay et al., 2025).\nDespite advancements, emotion classification re-\nmains complex due to ambiguous emotional expres-\nsions and diverse contexts. Early keyword-based\nmethods struggled with generalizing across lan-\nguages and expressions (Wiebe et al., 2005), and\neven modern transformer models face challenges\nwith short or under-explained sentences, particu-\nlarly in multi-label tasks (Kusal et al., 2022; Mo-\nhammad and Kiritchenko, 2018).\nTo address these challenges, we propose a novel\napproach using Large Language Models (LLMs)\nto generate explanatory content, enhancing the un-\nderstanding of ambiguous emotions. We fine-tuned\na Llama-3 model to generate context-rich explana-\ntions for each sentence, improving emotion classi-\nfication, especially for multi-label settings. The ex-"}, {"title": "2 Background", "content": "This section provides an overview of the emotion\ndetection task, dataset, and related works, focus-\ning on the use of large language models (LLMs)\nand contextual information for improving emotion\nclassification."}, {"title": "2.1 Task and Dataset Details", "content": "We propose using Large Language Models (LLMs),\nspecifically Llama-3, to generate explanations for\nambiguous emotional expressions, which are then\nused to fine-tune ROBERTa for emotion classifica-\ntion. Our results show that the inclusion of explana-\ntory context improves performance compared to\nusing text alone. The emotion distribution across\nthe datasets, shown in Table 1, illustrates the chal-\nlenges of handling imbalanced classes in multi-\nlabel emotion detection."}, {"title": "2.2 Related Works", "content": "Recent advancements in emotion recognition have\nbeen driven by the use of Large Language Mod-\nels (LLMs), particularly transformer-based archi-\ntectures like ROBERTa. demonstrated that fine-\ntuning pre-trained models significantly improves\nemotion detection compared to traditional keyword-\nbased methods, which often struggle to general-\nize across languages and diverse emotional expres-\nsions. Transformer models, including RoBERTa,\nhave been successfully applied to fine-grained emo-\ntion classification tasks, as shown by Demszky et al.\n(2020) on the GoEmotions dataset, excelling in\nmulti-label classification.\nEfforts to further enhance LLMs for emotion\ndetection have included integrating additional con-\ntext or knowledge during fine-tuning. For exam-\nple, Suresh and Ong (2021) proposed augmenting\ntransformers with knowledge-embedded attention\nmechanisms using emotion lexicons, which im-\nproved the recognition of nuanced emotional ex-\npressions. Similarly, Xenos et al. (2024) showed\nthat incorporating common-sense reasoning sig-\nnificantly enhances performance, particularly in"}, {"title": "3 System Overview", "content": "The task of multi-label emotion detection in text\nis inherently complex, especially when emotions\nare expressed simultaneously in a single sentence.\nTo address this, our system employs a two-phase\npipeline: first, generating explanatory content to\nenhance the understanding of ambiguous emotional\nexpressions, followed by fine-tuning a RoBERTa\nmodel for multi-label classification."}, {"title": "3.1 Phase 1: Explanation Generation with\nLlama-3", "content": "The first stage of our system leverages Llama-3, a\nlarge language model fine-tuned to generate con-\ntextual explanations for textual data. We selected\nLlama-3 over other LLMs like EmoLLMs and Di-\nalogueLLM due to its superior ability to generate\ncoherent and contextually relevant explanations.\nWhile EmoLLMs focuses on affective analysis\nacross multiple tasks and DialogueLLM is fine-\ntuned for conversational contexts, Llama-3 excels\nin generating general explanations that provide rich\ncontextual information without explicitly stating"}, {"title": "3.2 Phase 2: RoBERTa Fine-Tuning for\nMulti-Label Emotion Classification", "content": "In the second stage, we utilized the RoBERTa\nmodel, a transformer-based architecture known for\nits high performance in text classification tasks.\nROBERTa was fine-tuned on the training data en-\nriched with the explanations generated by Llama-3.\nDuring this fine-tuning, both the original text and\nthe generated explanations were concatenated with\na space between them and then fed into RoBERTa.\nThis approach allowed the model to learn the in-\ntricate relationships between emotions and their\ncontextual expressions in the text.\nROBERTa was fine-tuned with binary labels (0 or\n1) for each emotion in the dataset: anger, fear, joy,\nsadness, and surprise. These binary labels indicate\nthe presence (1) or absence (0) of each emotion.\nThe task is a multi-label classification, meaning\nmultiple emotions can be predicted for a given text.\nThis was crucial for handling complex emotional\nexpressions where more than one emotion could be\nconveyed simultaneously."}, {"title": "3.3 Challenges and Solutions", "content": "Our system addressed three main challenges:\n\u2022 Ambiguous Emotional Expressions: Emo-\ntion detection is challenging due to the subtle\nand complex nature of emotions in text. To re-\nsolve ambiguity, we used Llama-3 to generate\nadditional explanatory context, providing the\nmodel with clearer, more explicit information\nthat aids in correctly interpreting emotions, es-\npecially when they are not overtly expressed.\n\u2022 Multi-label Classification: Emotions often\noverlap in natural language, and multiple emo-\ntions can be expressed simultaneously. Our\nsystem's multi-label classification approach\nenables it to predict multiple emotions for\neach input sentence, which is crucial for cap-\nturing real-world emotional expressions. This\nmulti-label classification is essential for ad-\ndressing the intricate and overlapping emo-\ntional cues that occur in natural language.\n\u2022 Imbalanced Dataset: Emotion detection\ntasks often face class imbalance, where some\nemotions are more prevalent than others.\nWhile our system did not explicitly address\nthis issue through over-sampling or under-\nsampling techniques, the explanatory context\ngenerated by Llama-3 helped mitigate this im-\nbalance. By providing richer, more contextu-\nally informed inputs, Llama-3's explanations\noffered a way to enhance the recognition of\nless frequent emotions. This context made\nthe model more sensitive to underrepresented\nemotions by providing additional clarifying\ninformation that could compensate for their\nlesser frequency in the dataset."}, {"title": "3.4 Code and Resources Used", "content": "The code for fine-tuning Llama-3 is available in the\nUnslothai GitHub repository. This repository con-\ntains the necessary scripts for fine-tuning Llama-3."}, {"title": "4 Experimental Setup", "content": "We evaluated our multi-label emotion detection\napproach, using RoBERTa fine-tuned with ex-\nplanatory content generated by Llama-3, on the\nBRIGHTER dataset.\nText preprocessing and tokenization were per-\nformed with the Roberta Tokenizer from Hug-\nging Face. In the first phase, Llama-3 generated"}, {"title": "5 Results", "content": "In this section, we present the performance of our\nsystem, Lotus, on the competition task. Using\nthe Text + Explanation (RoBERTa) method, Lotus\nscored 0.7319, outperforming the SemEval Base-\nline (0.7083) but falling short of the top score of\n0.823. Ranked 44th, it performed competitively,\nthough there is room for improvement to reach the\nhighest positions."}, {"title": "5.1 Performance Comparison for Individual\nEmotions", "content": "In Table 2, the performance of Lotus was com-\npared across individual emotions using three meth-\nods: Text + Explanation (RoBERTa), Text Only\n(ROBERTa), and Text Only (Llama-3), focusing on\nprecision, recall, and F1-score.\nFor Anger, Text Only (Llama-3) achieved the\nhighest precision (0.7337), but Text + Explana-\ntion (ROBERTa) outperformed in recall (0.6304)\nand F1-score (0.6479), demonstrating better overall\nperformance. Text Only (RoBERTa) had a lower re-\ncall (0.5116) and F1-score (0.5871), while Llama-3"}, {"title": "5.2 Overall Performance Comparison Across\nDifferent Models", "content": "Table 3 compares the performance of three meth-\nods: Text + Explanation (RoBERTa), Text Only\n(RoBERTa), and Text Only (Llama-3) across macro\nand micro precision, recall, and F1 scores.\nText + Explanation (RoBERTa) outperformed\nthe other models in both Macro Recall (0.7433)\nand Macro F1 (0.7396), as well as in Micro Recall\n(0.7809) and Micro F1 (0.7678), showing its ef-\nfectiveness in capturing a wide range of emotions.\nHowever, Text Only (RoBERTa) achieved the high-\nest Macro Precision (0.7477) and Micro Precision\n(0.7650), indicating better selectivity in predictions.\nLlama-3 consistently performed worse across all\nmetrics, particularly in recall and F1 scores.\nLotus performed well overall, with Text + Ex-\nplanation (ROBERTa) excelling in emotions like\nFear (F1: 0.8343), Joy (F1: 0.7581), and Sadness\n(F1: 0.7423), reflecting a strong ability to balance\nprecision and recall. Even in Anger, where limited\ndata affected recall, Text + Explanation (RoBERTa)\noutperformed other models with an F1-score of\n0.6479. While Llama-3 performed reasonably well\nfor Joy, it consistently lagged behind RoBERTa-\nbased models in both precision and recall, partic-\nlarly for more nuanced emotions. These results\nemphasize the power of combining Llama-3's gen-\nerative explanations with RoBERTa's established\nstrength in emotion detection. The additional layer\nof explanation enhances RoBERTa's ability to cap-\nture subtle emotional nuances, improving overall\nperformance.\nIn our third experiment, we fine-tuned Llama-\n3 for the task and compared its performance to\nusing Llama-3's generated explanations in conjunc-\ntion with ROBERTa. Interestingly, when we used\nLlama-3's explanations as input to RoBERTa, the\nperformance exceeded that of fine-tuning Llama-3\nalone. This demonstrates that combining Llama-\n3's ability to generate contextual explanations with\nROBERTa's emotion detection capabilities creates a\nmore effective approach for emotion classification\ntasks.\nFuture improvements could focus on better han-\ndling underrepresented emotions like Anger and\nrefining the process of generating and leveraging\nexplanations. By combining Llama-3's explanatory\npower with RoBERTa's emotion detection, we can\ndevelop a more robust and accurate solution for\nemotion classification tasks.\nSince Anger and Surprise were the most chal-\nlenging emotions for all methods, we performed\nerror analysis for these two emotions, and the re-\nsults can be found in the Appendix B."}, {"title": "6 Conclusion and Future Work", "content": "We proposed a novel approach for multi-label\nemotion detection, using Llama-3 to generate ex-\nplanatory context, which was then combined with\nROBERTa for emotion classification. Our method\nsignificantly improves model performance, particu-\nlarly in handling ambiguous emotional expressions\nand multi-label tasks, outperforming text-only mod-\nels in key metrics like F1-scores for fear, joy, and\nsadness.\nFuture work will focus on improving the detec-\ntion of underrepresented emotions like anger and\nrefining the explanation generation process to cap-\nture subtler emotional cues. Additionally, explor-\ning techniques for handling imbalanced datasets\nand expanding the approach to different languages\nand emotional contexts will enhance the model's\ngeneralizability and robustness across diverse ap-\nplications."}, {"title": "A Examples of input texts", "content": "Table 4 shows input sentences from the dataset,\nalong with the predicted emotions and the gener-\nated explanations for each sentence. These explana-\ntions provide additional context, helping to clarify\nthe emotional intent behind the text and improving\nthe model's ability to correctly classify emotions."}, {"title": "B Error Analysis", "content": "B.1 Misclassification of Anger\nAnger is often misclassified due to subtle emotional\ncues or when it overlaps with related emotions like\nfrustration or anxiety. For example:\n\u2022 Text: \"Man, I can't believe it.\" Explanation:\n\"The speaker expresses surprise or frustra-\ntion.\" Predicted: Anger = 0, Actual = 1.\n\u2022 Text: \"I could not summon up the courage\nto get up.\" Explanation: \"The speaker con-\nveys vulnerability or exhaustion.\" Predicted:\nAnger = 0, Actual = 1."}, {"title": "B.2 Misclassification of Surprise", "content": "Surprise is often misclassified due to subtle or am-\nbiguous emotional cues in the text. For example:\n\u2022 Text: \"The lock was a dial-lock.\" Explana-\ntion: \"The speaker describes a specific detail,\nfocusing on the nature of the lock.\" Predicted:\nSurprise = 1, Actual = 0.\n\u2022 Text: \"I immediately started getting nervous\nand panic intensified.\" Explanation: \"The\nspeaker describes anxiety, which may be con-\nfused with surprise.\" Predicted: Surprise = 1,\nActual = 0.\nThese examples show that Surprise is sometimes\nmisclassified as confusion or anxiety, especially\nwhen the emotional reaction is subtle or combined\nwith other emotions.\nAdditionally, Surprise is occasionally misclassi-\nfied as fear or anger, particularly when unexpected\nevents are associated with discomfort or frustra-\ntion:\n\u2022 Text: \"She was growling, barking, snarling,\nfoaming.\" Explanation: \"The speaker de-\nscribes an intense emotional state, possibly\nfear or anger.\" Predicted: Surprise = 1, Ac-\ntual = 0.\n\u2022 Text: \"I almost got my hands on the door\nhandle, when...\" Explanation: \"The speaker\ndescribes a moment of frustration or missed\nopportunity.\" Predicted: Surprise = 1, Actual\n= 0."}]}