{"title": "CLOFAI: A Dataset of Real And Fake Image Classification Tasks for Continual Learning", "authors": ["William Doherty", "Anton Lee", "Heitor Murilo Gomes"], "abstract": "The rapid advancement of generative AI models capable of creating realistic media has led to a need for classifiers that can accurately distinguish between genuine and artificially-generated images. A significant challenge for these classifiers emerges when they encounter images from generative models that are not represented in their training data, usually resulting in diminished performance. A typical approach is to periodically update the classifier's training data with images from the new generative models then retrain the classifier on the updated dataset. However, in some real-life scenarios, storage, computational, or privacy constraints render this approach impractical. Additionally, models used in security applications may be required to rapidly adapt. In these circumstances, continual learning provides a promising alternative, as the classifier can be updated without retraining on the entire dataset. In this paper, we introduce a new dataset called CLOFAI (Continual Learning On Fake and Authentic Images), which takes the form of a domain-incremental image classification problem. Moreover, we showcase the applicability of this dataset as a benchmark for evaluat-ing continual learning methodologies. In doing this, we set a baseline on our novel dataset using three foundational continual learning methods EWC, GEM, and Experience Replay and find that EWC performs poorly, while GEM and Experience Replay show promise, performing significantly better than a Naive baseline. The dataset and code to run the experiments can be accessed from the following GitHub repository:\nhttps://github.com/Will-Doherty/CLOFAI.", "sections": [{"title": "Introduction", "content": "Continual learning aims to solve the problem of catastrophic forgetting [1], enabling neural networks to learn new information while preserving existing knowledge. The primary challenge in continual learning is achieving an optimal balance between the ability to learn new information (plasticity) and the ability to maintain previously learned information (stability), known as the stability-plasticity dilemma [2].\nContinual learning involves training a model on a sequence of distinct tasks, one after another. Formally, we define the data for task t as D\u2081 = (Xt, Yt), where\nXt is the set of input data and Yt is the set of corresponding output labels for\ntask t, with t \u2208 T = {1, ..., k} for k tasks. To be a continual learning problem,\neach task Dt must be distinct from other tasks in either input Xt or output Yt\n(or both). Continual learning aims to optimizes model performance across all\ntasks while only training on one task at a time. Various strategies for continual\nlearning exist, such as regularization and replay. Regularization methods, like\nthose proposed by [3, 4, 5], add explicit terms to the learning process to balance\nperformance between old and new tasks. Replay methods, as described by [6], use\nsamples from previous tasks to supplement the training data for the current task.\nIn this paper, we present a novel contribution to the field of continual learning\nby introducing CLOFAI (Continual Learning on Fake and Authentic Images),\na unique dataset designed to address the challenge of detecting fake versus real\nimages. CLOFAI is structured as a domain-incremental image classification prob-\nlem, offering a diverse array of images spanning various categories and complex-\nities. We highlight the significance of CLOFAI as a benchmark for assessing the\nefficacy of continual learning methodologies in the context of image classification\ntasks. By leveraging this dataset, researchers and practitioners can evaluate the\nrobustness and adaptability of their continual learning algorithms in a challeng-\ning domain-incremental setting.\nTo establish a foundation for comparison, we employ three fundamental con-\ntinual learning methods, setting a baseline performance on CLOFAI. Through\nthis comparative analysis, we provide insights into the strengths and limitations\nof existing approaches, while discussing characteristics of the CLOFAI dataset."}, {"title": "Related Work", "content": "In this section, we turn to the literature on continual learning, followed by a\ndiscussion of real versus fake image classification in non-continual-learning sce-\nnarios."}, {"title": "Continual Learning", "content": "Regularization approaches are popular strategies to cope with forgetting,\nwhere network parameters are regularized selectively. Elastic Weight Consolida-\ntion (EWC) [3] leverages the Fisher Information Matrix (FIM), the diagonals\nof which provide a parameter importance measure, to protect critical param-\neters during the learning of new tasks. This is done via a regularization term\nin the loss function that penalizes changes to parameters in proportion to their\nimportance:\n$L_{EWC}(\\theta) = L_{batch} (\\theta) + \\frac{\\lambda}{2} \\sum_j F_{jj} (\\theta_j - \\theta_j^{old})^2$\nHere, 0; represents the value of parameter j after the most recent training\nbatch; 0j,old is previous value of parameter j; Fjj is the entry at row and column\nj in the FIM; Lbatch (0) is the loss on the most recent training batch; A is a\nhyperparameter controlling the strength of the regularization. The loss is higher\nwhen changes to important parameters (as measured by Fisher information) are\ngreater.\nLike EWC, Synaptic Intelligence (SI) [4] uses an importance measure to con-\nstrain parameter updates, although the specific implementation is different; for\nSynaptic Intelligence, parameter importance is calculated based on its contribu-\ntion to the change in the loss function during training. Memory Aware Synapses\n(MAS) [5] also calculates an importance measure, although it is based on the\nsensitivity of the predictions to parameter changes, rather than the sensitivity\nof the loss function.\nThe most basic replay method is Experience Replay, where a selection\nof training samples are stored in a memory buffer, then interspersed amongst\nthe training data for subsequent tasks. The primary challenge when applying\nExperience Replay is deciding which samples to store in the buffer; these sam-\nples should encode maximal information about the previous tasks. For example,\nMean-of-Feature sampling selects the instances that are closest to the feature\nmean of each class [7], while Maximally Interfered Retrieval [8] prioritizes the\ninclusion of the training samples for which the model's predictions are most\nadversely impacted by parameter updates. Gradient Episodic Memory (GEM)\n[6] is another replay approach. For a new task t, GEM calculates the gradient\n\u25bdLt(0) with respect to the current model parameters 0, where L represents the\nloss function. It then retrieves the stored samples from previous tasks to compute\nthe gradients for each past task. GEM aims to find a parameter update direction\nthat minimizes the new task's loss without increasing the loss on any previous\ntask, formalized as solving a constrained optimization problem in equation 2.\nNote that L1:t-1(new) \u2264 L1:t-1 (old) means the loss on each task from 1 to\nt-1 when using the new model parameters must be lower than the loss on the\nsame task using the old model parameters.\nmin Lt (0) s.t. L1:t-1 (Onew) \u2264 L1:t-1 (0old)"}, {"title": "Real Versus Fake Image Classification", "content": "Several papers investigate fake face classification [9, 10, 11], showing that CNNs\nperform strongly in this domain. Other papers have examined real versus fake\nimage classification more generally. In one example, a CNN is used to classify the\nGAN-generated images [12] in a dataset created by the authors. In another [13],\nLatent Diffusion Models [14] are used to recreate the images from the CIFAR-10\ndataset [15] and a CNN is subsequently used to classify them.\nIt is also possible to not only classify images as real or fake, but also de-\ntermine the generative model that created them. One method [16] is to use a\nmulti-level approach, where a CNN (ResNet [17]) is first used to classify the\nimage as real or fake, then a second ResNet is trained to determine whether the\nfake images were generated by a GAN or by Diffusion. Two more ResNets are\nthen employed: one to differentiate between the different types of GANs, and\none to differentiate between the different types of Diffusion models.\nAs indicated by the aforementioned papers, CNNs are highly suited to most\nreal versus fake classification tasks. However, the recent emergence of Diffusion\nmodels has notably improved the quality of fake images, which are now highly\nrealistic. As a result, binary classification using a CNN is becoming less effective\n[18]. There have been two recent attempts to develop non-CNN fake image de-\ntectors that can be applied to images generated by Diffusion models. The first of\nthese is Diffusion Reconstruction Error [18], which involves measuring the error\nbetween an input image and its reconstruction (the reconstruction is performed\nby a Diffusion model). The authors find that Diffusion-generated images can be\nreconstructed, while real images cannot, allowing them to differentiate between\nthe two. The second approach, Diffusion Noise Feature [19], is similar. It uses\nan ensemble representation to estimate the noise generated during the inverse\nDiffusion process. A classifier can then be trained on the result.\nWhile the aforementioned papers provide valuable insights into real versus\nfake image classification, they do not adequately address the challenges posed\nby the continual emergence of new generative models. To bridge this gap, we\nintroduce the CLOFAI dataset and provide the results of several benchmark\ncontinual learning methods."}, {"title": "CLOFAI benchmark", "content": "Figure 1 provides an overview of the problem setup for the CLOFAI dataset.\nDuring each task, the Classifier is trained to differentiate between real and fake\nimages, simulating a practical scenario where a fake image detector is updated as\nnew generative models emerge. This setup is domain-incremental [20], meaning\nthe target labels are the same across tasks (in this case, the target labels are real\nand fake) while the input distribution changes (as different generative models\nare used to create the fake images for each task).\nCLOFAI is split into five distinct tasks. For each task, there are 5000 real\nimages, taken from the CIFAR-10 dataset [15], as well as 5000 fake images, cre-\nated by a generative model that has been trained to reproduce the images from\nCIFAR-10. A different set of real images are used for each task, preventing the\nmodel from simply memorising the real images. The training and test split is\n80/20, meaning there are 8000 images in the training dataset and 2000 images\nin the test dataset for each task. The pixel values of the images are normalised\nto have mean (0,0,0) and standard deviation of (1,1,1), as normalisation typ-\nically improves classification performance [21]. The three elements of the tuple\ncorrespond to the three image channels - red, green, and blue.\nThe generative models used for each task are listed below. An exemplar image\nfrom each of the models is shown in Figure 2.\nTask 1 - Variational Autoencoder (VAE) [22] trained for this specific appli-\ncation.\nTask 2 A model that combines a Variational Autoencoder and an Energy-\nbased Model [23]\nTask 3 - Generative Adversarial Network (GAN) [24] trained for this specific\napplication.\nTask 4 - Flow-Based Model [25].\nTask 5 - Denoising Diffusion Implicit Model from the HuggingFace diffusers\nlibrary [26].\nThe task order was chosen to reflect real-world circumstances where fake im-\nages become more realistic and harder to classify over time. To achieve this, we\ntested the Classifier's performance on each task in isolation and then ordered"}, {"title": "Experimental Setup", "content": "The Classifier used in our experiments is EfficientNet_b0 [27], with two modi-\nfications. The first modification is to add an additional linear layer which maps\nto a single node. The second modification is to include the sigmoid activation\nfunction after the final layer. Together, these two modifications make the model\nsuitable for binary classification. EfficientNet_b0 was chosen because it has been\nshown to have good performance on image classification benchmarks, in addi-\ntion to having a relatively short training time compared to models that attain\nsimilar performance [27]. In all experiments we used the weights provided in the\nPyTorch implementation of EfficientNet_b0 [28], which were derived by pre-\ntraining on ImageNet [29].\nSince the classes in CLOFAI are balanced, we have used classification ac-\ncuracy as the performance metric throughout the Experiments section. The\ncontinual learning methods used in the experiments are listed below:\nBaseline: Represents optimal performance, where the network is trained\ncollectively on data from all encountered tasks. Note that this is not a valid\ncontinual learning approach, as continual learning, by definition, is applied\nin situations where not all training data is available. Instead, the baseline\nrepresents an expected upper bound on the performance of continual learning\nmethods.\nNaive: The model is sequentially fine-tuned on each new task without strate-\ngies to prevent catastrophic forgetting, serving as a lower-bound benchmark.\nElastic Weight Consolidation (EWC) [3]: Assigns an importance score\nto each network weight, reflecting its impact on the network's performance on\npast tasks. Updates to weights are penalized according to their importance,\nwith more important weights being more resistant to change. EWC serves\nas a representative regularization method."}, {"title": "Results", "content": "In all experiments, the Classifier was trained on each task for 3 epochs with a\nbatch size of 128. When the classifier is trained using more epochs it begins to\noverfit a particular task. The Adam optimizer [31] was used, with a learning rate\nof 0.0001 and no regularization. The loss function was binary cross-entropy. All\nstochastic parameters had seed set to 123."}, {"title": "Baseline Results", "content": "Table 2 shows the Classifier's accuracy on the test dataset of each task. Each\nrow in the table represents the accuracy after being trained on a particular task.\nEach column represents the accuracy when the Classifier is tested on a particular\ntask. For example, the accuracy in the fourth row and second column represents\nthe accuracy on the second task after training on the fourth task. The accuracy\nis coloured blue if the Classifier has already seen the task and red otherwise.\nWe also tested the Classifier with random parameter initialization, i.e. no\npre-training. The results, shown in Table 3, are far worse than the results in\nTable 2, indicating that pre-training provides significant benefits for classifica-\ntion accuracy. The primary reason that pre-training dramatically improves the\nClassifier's performance is due to the small number of instances in the CLOFAI\ntraining data (8,000 per task)."}, {"title": "Naive Results", "content": "The Naive continual learning strategy refers to a scenario where the Classifier is\nsequentially fine-tuned on each new task without any method to prevent catas-\ntrophic forgetting. Table 4 shows that, after training on the first task, accuracy\non the test dataset is almost perfect, while accuracy on unseen tasks is no better\nthan random guessing. After training on Task 2, accuracy on the first task falls,\nbut accuracy on the unseen tasks starts to improve, indicating that Task 2 is\nsufficiently similar to Task 3 and 4 that the Classifier can generalize across these\ntasks to a small degree.\nAnother interesting finding is that, after training on Task 4, the accuracy on\nTask 1 falls to 37.45%. One explanation is that there are shared image features\nacross Tasks 1 and 4, but those features are labelled differently. For example, a\nspecific pattern might be an indicator of a fake image in Task 4, while the same\npattern is associated with real images in Task 1.\nFinally, we can see that the model is using somewhat similar features to clas-\nsify real and fake images in both Task 5 and Task 1, given that the accuracy\non Task 1 increases after the model has been trained on Task 5. However, it is\ninteresting that the opposite is not true; after training on Task 1 there is no im-\nprovement in accuracy in Task 5. This probably reflects the relative difficultly of\nthe two tasks, since Task 1 does not require the model to learn complex features.\nConsequently, the features learnt by the model are not sufficiently complex to\nallow it to classify instances from Task 5."}, {"title": "EWC Results", "content": "Elastic Weight Consolidation (EWC) is a regularization method with a hyper-\nparameter, A, that controls the strength of the regularization. A higher A means\na stronger regularizing effect, meaning we would expect performance on pre-\nvious tasks to degrade less, at the cost of performance on the current task.\nIn other words, a higher A prioritises stability over plasticity in terms of the\nstability-plasticity trade-off. Table 5 shows the accuracy matrix of EWC when\n\u03bb = 100,000. Here, EWC performs similarly to the Naive model, indicating that\nthe regularization is failing to mitigate catastrophic forgetting.\nThe natural response is to increase the value of A, thereby increasing the\nstrength of the regularization. However, it turns out that, irrespective of the\nvalue of A, EWC cannot achieve good performance. Once A gets sufficiently\nhigh, the Classifier starts failing to learn new tasks. To illustrate this, Table 6\nshows the result when A is scaled all the way to 100 million. By looking along\nthe diagonal, it is clear that the Classifier's performance on the most recent task\nis weaker (relative to Table 5), despite not achieving higher accuracy on prior\ntasks.\nTo understand the reasons behind EWC's suboptimal performance, it is use-\nful to understand its dependence on the parameter importance measure, calcu-\nlated using Fisher Information. This metric assesses how changes in parameters\naffect the model's output distribution, thereby indicating the relative importance\nof parameters for accuracy on prior tasks. During the learning of new tasks, the\nimportance measures act as constraints on the modification of weights, preserv-\ning the knowledge acquired from previous tasks. One potential explanation for\nEWC's poor performance is that the same parameters are highly important\nacross all tasks. This would explain why EWC does not perform much better\nthan the Naive method when A is relatively low the important parameters\nare being updated to improve accuracy on the next task, thereby diminishing\naccuracy on previous tasks. It would also explain why the Classifier struggles to\nlearn when A is high \u2013 critical parameters are not being adjusted due to intense\nregularization, while the remaining parameters fail to compensate.\nTo investigate this hypothesis, after the Classifier was trained on Task 1 we\nidentified the ten most important parameters using Fisher Information values.\nWe then compared their magnitudes to those observed after the Classifier was\ntrained on Task 2. The percentage changes are shown in Table 7 (parameter 1 is\nthe most important). Clearly, some of the important parameters are undergoing\nlarge changes, as indicated by the red highlight, giving credence to the hypothesis\nthat the same parameters are highly important across tasks."}, {"title": "Experience Replay Results", "content": "Table 8 shows the accuracy of Experience Replay with 100 samples replayed\nfrom each previously-seen task.\nTable 9 shows the accuracy of Experience Replay with 500 samples replayed\nfrom each previously-seen task. Classifier accuracy with 500 samples is slightly\nbetter than accuracy with 100 samples, although the differences are small. This\ncarries some notable implications, as a primary motivation for using continual\nlearning is for scenarios where not all training data can be used. Particularly as\nthe number of tasks increases, it is useful for the number of replayed samples to\nbe minimised, assuming accuracy remains approximately constant."}, {"title": "GEM Results", "content": "Table 10 shows the results when 100 samples are replayed (from each task) and\nTable 11 shows the results when 500 samples are replayed. Unlike Experience\nReplay, the GEM results when 500 samples are replayed are significantly bet-\nter, with the Classifier less prone to catastrophic forgetting. One caveat is that\naccuracy is lower on the task that has most recently been trained on when 500\nsamples are used. This can be seen by looking down the diagonal; for example,\nperformance on Task 5 after training on Task 5 is better when 100 samples are\nused. This is not unexpected, as the model is less constrained in updating its\nweights when 100 samples are used, allowing it to achieve better performance\non the most recent task.\nThe disparity in performance gains between GEM and Experience Replay\nwhen the number of replayed samples is increased from 100 to 500 can be un-\nderstood through the dynamics by which the two methods operate. Experience\nReplay enhances learning by mixing replayed samples from previous tasks with\ncurrent task data, effectively adding a term to the loss function that represents\nthe error on the replayed samples. In this case, it appears that adding more\nsamples simply increases the quantity of data without fundamentally changing\nthe model's approach to balancing new learning and knowledge retention. In\ncontrast, GEM directly constrains the optimization process by ensuring that\nupdates to the model do not increase the loss on instances in a memory buffer.\nWith 500 samples, GEM has a more comprehensive and varied set of constraints,\nderived from a wider array of past learning experiences. Evidently, this allows\nfor a more precisely-guided optimization process."}, {"title": "Conclusion", "content": "We introduced a new dataset, CLOFAI, specifically designed for real and fake\nimage classification in a domain-incremental continual learning scenario. To es-\ntablish an initial benchmark for CLOFAI, we evaluated its performance using\nthree continual learning methods: Experience Replay, GEM, and EWC. Our\nfindings indicate that Experience Replay and GEM demonstrated strong per-\nformance, while EWC performed poorly. Additionally, we observed a significant\nimprovement in classifier performance with pre-training.\nThe continual learning approach for real and fake image classification dis-\ncussed in this paper enables classifiers to efficiently adapt by training on new\nimages without losing previously acquired knowledge. This strategy is promising\nfor keeping pace with the rapid advancements in image generation technology.\nFurthermore, the CLOFAI dataset provides researchers with a valuable tool to\nevaluate and enhance the quality of their continual learning methods in this\ncritical domain.\nA potential direction for future research is to explore the integration of ad-\nvanced generative models, such as those based on transformer architectures, into\nthe CLOFAI dataset. Investigating how these models impact the performance\nand adaptability of continual learning methods could provide deeper insights\nand further improve classifier robustness."}]}