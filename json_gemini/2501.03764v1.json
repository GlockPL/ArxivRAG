{"title": "SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment", "authors": ["Siyuan Zhao", "Chenyu Liu", "Yi Ding", "Xinliang Zhou"], "abstract": "In practical sleep stage classification, a key challenge is the variability of EEG data across different subjects and environments. Differences in physiology, age, health status, and recording conditions can lead to domain shifts between data. These domain shifts often result in decreased model accuracy and reliability, particularly when the model is applied to new data with characteristics different from those it was originally trained on, which is a typical manifestation of negative transfer. To address this, we propose SelectiveFinetuning in this paper. Our method utilizes a pre-trained Multi-Resolution Convolutional Neural Network (MRCNN) to extract EEG features, capturing the distinctive characteristics of different sleep stages. To mitigate the effect of domain shifts, we introduce a domain aligning mechanism that employs Earth Mover's Distance (EMD) to evaluate and select source domain data closely matching the target domain. By finetuning the model with selective source data, our SelectiveFinetuning enhances the model's performance on target domain that exhibits domain shifts compared to the data used for training. Experimental results show that our method outperforms existing baselines, offering greater robustness and adaptability in practical scenarios where data distributions are often unpredictable.", "sections": [{"title": "I. INTRODUCTION", "content": "Sleep staging is crucial for assessing sleep quality and diagnosing disorders, typically involving the use of biometric signals to categorize sleep stages (N1, N2, N3, and REM). Sleep experts rely on polysomnography (PSG) data for judg- ments, including EEG and other physiological signals, but manual evaluation is costly and prone to errors [1], [2]. As a result, automated sleep staging methods have been extensively studied.\nDeep learning has been widely applied to automatic sleep stage classification, showing great performance in improving the accuracy and efficiency of sleep studies [3]\u2013[7]. However, in practical sleep staging, there are often situations where judg- ments need to be made directly on small groups of individuals, and specifically training a model for these data is not cost- effective. For instance, some sleep studies may involve only a small cohort of ten to twenty subjects, making it impractical to invest significant resources in developing a model tailored exclusively to such limited data [8]-[12]. Additionally, the process of training with large datasets is labor-intensive and resource-intensive, involving complex steps from data pre- processing to model training and validation. Thus, reducing training efforts while maintaining the model's accuracy on new samples is important.\nTransfer learning offers a solution, where a model is initially trained on a large source domain dataset and then be finetuned with a small target domain dataset [13], [14]. However, when knowledge from the source domain negatively impacts target domain learning, it results in negative transfer, reducing model performance [15], [16].\nObtaining sufficient labeled data in the target domain is challenging due to the high costs involved, even though labeled data is generally available in the source and target domain [17]. Furthermore, even if enough target domain data is collected, domain shifts often occur due to variations in EEG signals caused by factors such as physiology, age, and health [18], rendering models trained on the source domain less applicable. To mitigate this issue, we adopt an unsupervised approach that uses only labeled source data, carefully selecting source data that closely aligns with the target domain. This approach reduces domain mismatch, minimizes the risk of negative transfer, and enhances the applicability of knowledge transferred from the source domain to the target domain.\nIn this paper, we propose an domain aligning approach for sleep staging to maintain model performance on new data by mitigating negative transfer. Our Domain Aligner selects high- quality source data for transfer learning, making batch-based decisions to improve efficiency. We use specific metrics to identify similar source data and update the pre-trained model's parameters. Our contributions include:\n\u2022 We introduce a Domain Aligner designed to identify the most suitable source data, thereby helping the model mitigate the effects of negative transfer.\n\u2022 Rather than generating new features and selecting data on a case-by-case basis, our approach directly utilizes the source domain data and processes it in batches, improving the model's training efficiency.\n\u2022 Experimental results demonstrate that our Domain Aligner enhances the performance of the transfer learning model in sleep staging. Moreover, our model achieves state-of-the-art (SOTA) performance on sleep staging tasks."}, {"title": "II. RELATED WORK", "content": "Currently, deep learning-based sleep staging networks typi- cally consist of feature extraction and sequential signal classi-"}, {"title": "III. METHOD", "content": "The architecture of our algorithm framework is illustrated in Fig. 1. Our framework is designed with the primary goal of addressing the issue of negative transfer in transfer learning. We summarize three key ideas:\n1) Employ a pre-trained model that effectively extracts EEG signal features to provide a strong foundation for transfer learning.\n2) Design a feature extraction method that maps both source and target domain data into a common feature space.\n3) Develop a domain aligning mechanism that specifically aims to minimize negative transfer by carefully selecting source domain data."}, {"title": "A. Pre-trained Model", "content": "Different sleep stages are associated with specific EEG sig- nal frequencies, making it important to capture these varying bands for accurate classification. To achieve this, we apply a Multi-Resolution CNN model [34]. This model includes two convolutional branches: a wide kernel branch for lower frequencies like the delta (\u03b4) band and a narrow kernel branch for higher frequencies such as the alpha (\u03b1) and theta (\u03b8) bands. This part is indicated in the yellow part of Fig. 1.\nThe model extracts features using two convolutional branches: one with a wide 400 kernel for lower frequencies,"}, {"title": "B. Feature Extraction", "content": "Because MRCNN effectively extracts distinct features for each sleep stage from EEG signals, we choose to utilize a pre-trained MRCNN as the feature extractor, mapping both source and target domain data into a common feature space, which is indicated in the purple part of Fig. 1.\nThe specific steps are as follows:\n\u2022 We extract the output features from a specific convo- lutional layer (denoted by \u03c3) for both the source and target domain data, processing them in batches. This ensures uniformity in the feature extraction process across domains:\n$F_s^{(l)} = \u03c3 (W_s^{(l)}F_s^{(l-1)}+b_s^{(l)})$\n$F_t^{(l)} = \u03c3 (W_t^{(l)}F_t^{(l-1)}+b_t^{(l)})$\n\u2022 The final feature representations for the source and tar- get domains are derived from the specific convolutional layer's outputs. By maintaining the same network and layer, we ensure a unified feature space:\n$F_s = F_s^{(l)}, F_t = F_t^{(l)}$\nThis shared feature extraction strategy ensures consistency across domains, which can support subsequent alignment process."}, {"title": "C. Domain Aligner", "content": "To mitigate negative transfer, our Domain Aligner evaluates and selects source domain data that closely matches the target domain. This targeted selection ensures that the data used to selectively finetune the pre-trained model is most relevant.\nThe aligner (indicated in the green part of Fig. 1) operates as follows:\n\u2022 Policy Function and Reward Calculation:\nLet \u03c6 denote the function that extracts features $F_s$ and $F_t$ from the source and target domains using the shared feature extraction method:\n$F_s = \u03c6(X_s), F_t = \u03c6(X_t)$\n\u2022 The policy function calculates the similarity between the domains using Earth Mover's Distance (EMD).\n$EMD(F_s, F_t) = min_{\\{f_{ij}\\}} \\sum_{i=1}^m \\sum_{j=1}^n f_{ij} \\cdot d(f_s^i, f_t^j)$\nsubject to:\n$\\sum_{j=1}^n f_{ij} = w_s^i, \\sum_{i=1}^m f_{ij} = w_t^j, f_{ij} \u2265 0$\nHere, $d(f_s^i, f_t^j)$ denotes the distance between feature vectors $f_s^i$ and $f_t^j$, while $f_{ij}$ denotes the optimal transport needed to map the source domain features $F_s$ to the target domain features $F_t$.\nA reward R is assigned to each source domain sam- ple, inversely proportional to the EMD, prioritizing samples more similar to the target domain:\n$R = \\frac{1}{EMD(F_s, F_t)}$\n\u2022 Data Selection and Selectively Finetune:\nSource domain data with reward values R below a certain threshold T are selected:\n$Selected\\_source\\_data = \\{F_s | R > T\\}$\nThe selected samples are used to finetune the pre- trained model."}, {"title": "IV. EXPERIMENTS", "content": "We perform an evaluation of our algorithm method in comparison with baseline models on the SleepEDF and SHHS datasets."}, {"title": "A. Dataset and Preprocessing", "content": "The SleepEDF dataset [11] contains 153 sleep recordings from 78 healthy individuals aged 25 to 101 years, with most subjects having two full-day polysomnography (PSG) recordings. These are segmented into 30-second epochs, and labeled according to sleep stages, following AASM guidelines, where stages N3 and N4 are merged and Movement/Unknown stages are excluded, resulting in the final set {W, N1, N2, N3, REM}. EEG are taken from the FPZ-CZ channel. Similarly, the SHHS dataset [35] includes PSG recordings from 329 participants, selected based on their Apnea-Hypopnea Index (AHI), using the C4-A1 EEG channel, with data processed similarly to SleepEDF.\nFor the experimental evaluation, a cross-dataset transfer learning setup is used. The model is trained on one dataset as the source domain and evaluated on the other as the target domain. To account for different sampling frequencies across channels, resampling is applied to standardize all data to 100 Hz."}, {"title": "B. Baseline Methods", "content": "We compare our method with the following six baseline methods:\nNo Adapt: A baseline where the model is pre-trained on source data and then tested on target domain data without any adaptation.\nMSTGCN: Combines multi-view spatiotemporal informa- tion to enhance the generalization in sleep stage classification [36]."}, {"title": "C. Experiment Results", "content": "SEN-DAL: Utilizes multi-modal signals and domain adver- sarial learning to improve accuracy and generalization in sleep staging [37].\nTENT:Achieves test-time adaptation through entropy mini- mization, improving model performance in new environments [38].\nEATA: Dynamically adjusts the model at test time through closed-loop inference to enhance performance [39].\nSAR: Adapts to changes in dynamic environments with a stable test-time adaptation method [40].\nMUDA: The method uses domain-specific and domain- invariant branches with an adaptive mixing strategy to address domain shifts [41].\nTTACS: An OTTA framework with a teacher-student net- work to learn domain-invariant features [42].\nMSTGCN and SEN-DAL improve generalization but face complexity issues, while TENT, EATA, and SAR enhance test-time adaptation with risks of forgetting and resource demands. MUDA struggles with domain shifts, and TTACS relies on batch-level data, making both less robust against imbalanced class distributions in sleep staging.\nAmong the compared methods, MSTGCN and TENT show moderate improvements, with TENT benefiting from entropy minimization. SAR demonstrates strong stability, achieving high F1-scores due to sharpness-aware optimization, while MUDA performs better overall but falls short of the highest accuracy and F1-scores achieved by our method. The key advantage of our method is its ability to minimize domain shifts by selectively finetuning on relevant source data (as shown in Fig. 2), which enhances the model's adaptation to new datasets and reduces the risk of negative transfer. Consequently, our method outperforms others, achieving the highest accuracy and F1-scores in both the SHHS \u2192 78 and SHHS \u2192 20 tasks."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a method to mitigate negative transfer in sleep stage classification by strategically selecting source domain data that closely resembles the target domain. Our approach begins with a pre-trained MRCNN to extract EEG features and map them into a common feature space. We then employ a domain alignment mechanism that uses EMD to assess the distributional differences between source and target domain data. Based on this evaluation, source domain data that best matches the target domain is selected and used to finetune the pre-trained model. Our Domain Aligner allows the model to adapt more effectively to the target domain, reducing the impact of domain shifts and improving performance, particularly in scenarios with limited or small sample data. By addressing domain shifts in this way, our approach enhances the robustness, accuracy, and adaptability of sleep stage classification, thus making it a valuable tool for practical applications."}]}