{"title": "SURVIVAL ANALYSIS REVISITED: UNDERSTANDING AND\nUNIFYING POISSON, EXPONENTIAL, AND COX MODELS IN\nFALL RISK ANALYSIS", "authors": ["Tianhua Chen"], "abstract": "This paper explores foundational and applied aspects of survival analysis, using fall risk assessment\nas a case study. It revisits key time-related probability distributions and statistical methods, including\nlogistic regression, Poisson regression, Exponential regression, and the Cox Proportional Hazards\nmodel, offering a unified perspective on their relationships within the survival analysis framework.\nA contribution of this work is the step-by-step derivation and clarification of the relationships among\nthese models, particularly demonstrating that Poisson regression in the survival context is a specific\ncase of the Cox model. These insights address gaps in understanding and reinforce the simplicity\nand interpretability of survival models. The paper also emphasizes the practical utility of survival\nanalysis by connecting theoretical insights with real-world applications. In the context of fall de-\ntection, it demonstrates how these models can simultaneously predict fall risk, analyze contributing\nfactors, and estimate time-to-event outcomes within a single streamlined framework. In contrast,\nadvanced deep learning methods often require complex post-hoc interpretation and separate training\nfor different tasks particularly when working with structured numerical data. This highlights the en-\nduring relevance of classical statistical frameworks and makes survival models especially valuable\nin healthcare settings, where explainability and robustness are critical. By unifying foundational\nconcepts and offering a cohesive perspective on time-to-event analysis, this work serves as an acces-\nsible resource for understanding survival models and applying them effectively to diverse analytical\nchallenges.", "sections": [{"title": "1 Introduction", "content": "Time-to-event analysis, often referred to as survival analysis [1, 2], plays a crucial role in healthcare research, par-\nticularly in addressing the challenges posed by an aging population. As life expectancies increase, the prevalence of\nage-related health issues such as falls, chronic illnesses, cardiovascular conditions, and neurodegenerative diseases\ncontinues to rise. These conditions demand accurate modeling and prediction of event timing to design effective pre-\nventive strategies and improve patient outcomes. Survival analysis provides a robust framework for understanding\nand forecasting events like disease progression, survival times after diagnosis, and recovery durations. For example,\nfalls among the elderly population are often precursors to more severe conditions [3, 4]. Leveraging survival analysis\nto understand fall likelihood, timing, and associated risk factors enables early detection and intervention [5, 6, 7],\nsignificantly enhancing patient care, especially for vulnerable elderly individuals.\nThe growing popularity of survival analysis in healthcare stems from its ability to model time-to-event outcomes in di-\nverse real-world scenarios. At the same time, advances in deep learning, such as Recurrent Neural Networks (RNNs)\nand Variants (e.g., Long Short-Term Memory Networks (LSTMs), Gated recurrent units (GRUs)) [8], have introduced\npowerful data-driven tools for predictive modeling. However, despite their potential, these advanced methods often\nrequire substantial training data and computational resources and lack the interpretability and simplicity offered by tra-\nditional statistical approaches [9, 10]. In contexts like healthcare, where explainability and robustness are paramount,\ntraditional methods retain critical advantages. Another key advantage of statistical models lies in their ability to ad-\ndress multiple questions within a single framework. For example, a survival model can simultaneously predict fall\nrisks at various time points, analyse the impact of covariates, and estimate the expected time until the next event.\nIn contrast, deep learning approaches often require additional post-hoc methods for result interpretation, a process\nthat can become even more complex when dealing exclusively with structured numerical data [11]. Moreover, such\nmodels often require separate training for different tasks\u2014for instance, one model to predict risk at specific time inter-\nvals and another to estimate the time to the next event, particularly when working with structured numerical clinical\ndata, where the lack of inherent context or sequential relationships necessitates more tailored model architectures and\ntraining objectives [12], further increasing complexity and computational demands.\nThis paper is thus motivated by the need to revisit and unify foundational statistical methods in survival analysis,\nensuring their continued relevance in the evolving analytical landscape. By providing a review and integration of\nwidely used survival analysis techniques, the paper aims to clarify the connections between these models, address\ngaps in understanding their relationships, and offer a cohesive perspective for time-to-event analysis.\nThe discussion begins with logistic regression, a foundational method for binary classification. While effective for\npredicting outcomes at fixed time intervals, its limitations in modeling time-to-event data are evident. To address these\nshortcomings, the paper introduces Poisson and Exponential distributions, which incorporate time into predictive\nframeworks. The Generalized Linear Models are then explored as a bridge to enable the integration of covariates\nthat are then adapted in survival analysis framework. Finally, the paper presents a comparative analysis of the Cox\nProportional Hazards model, highlighting its strengths and its relationship with Poisson regression in the context of\nsurvival analysis.\nIn addition to theoretical insights, this paper emphasizes the practical applications of survival analysis methods. Using\nfall detection as a case study, it applies these models to achieve three main objectives: predicting the risk of an event\n(e.g., a fall) at specific intervals such as 3, 6, or 12 months, interpreting the influence of covariates on event risk, and\nestimating the expected time until the next event for an individual. These applications highlight the value of survival\nmodels in healthcare, providing actionable insights that support clinical decision-making and resource allocation."}, {"title": "2 Predicting the Probability of an Event at a Fixed, Preselected Time Interval", "content": "One of the fundamental questions in time-to-event prediction is estimating the probability of an event occurring within\na specific, fixed time interval. For example, in the context of fall prediction, healthcare providers may ask: What is\nthe probability of an elderly patient falling at Month 6 after a baseline assessment? This is a natural and practical\nquestion that aligns with preventative care and resource allocation strategies.\nGiven a dataset of n observations, let $X \\in \\mathbb{R}^P$ represent the vector of p predictor variables for an individual, and let\n$Y \\in \\{0,1\\}$ denote the binary outcome indicating whether the event of interest occurs within the fixed time interval.\nThe goal is to model the conditional probability:\n$P(Y = 1 | X) = f(X)$,\nwhere f(X) maps the predictors to a probability value in the range [0, 1].\nLogistic regression [13, 14] is a common approach to estimate f(X), which models the log-odds of the outcome as a\nlinear function of the predictors:\n$\\log\\left(\\frac{P(Y = 1 | X)}{1-P(Y= 1 | X)}\\right) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2+\\ldots+ \\beta_pX_p$.\nThe Odds $= \\frac{P}{1-P}$ or the logarithm of the odds Log-odds = $\\log\\left(\\frac{P}{1-P}\\right)$, is modelled linearly in logistic regression,\nwhere each coefficient $\u03b2_k$ is simple to interpret that represents the change in the log-odds for a one-unit increase\nin the factor $X_k$, holding other predictors constant. The corresponding change in odds is: $exp(\u03b2_k)$, indicating the\nmultiplicative change in the odds for a one-unit increase in $X_k$.\nThis can be rearranged to express the probability of the event as:\n$P(Y = 1 | X) = \\frac{1}{1 + exp (-(\u03b2_0 + \u03b2_1X_1 + \u03b2_2X_2 + \\ldots + \u03b2_pX_p))}$."}, {"title": "3 Modelling Time Element with Probability Distributions", "content": "Essentially a binary outcome without accounting for when the event occurs, the primary drawback of logistic regres-\nsion lies in its inability to incorporate time in the model. To address this limitation in time-related events, it is natural\nto consider probability distributions that explicitly model time. Two commonly used distributions in this context are\nthe Exponential distribution and the Poisson distribution [16].\nPoisson distribution: The Poisson distribution models the number k of events ($N_t$) occurring in a time interval t,\ngiven a constant event rate \u03bb:\n$P(N_t = k) = \\frac{(\\lambda t)^k \\exp(-\\lambda t)}{k!}$        $k = 0, 1, 2, ...$\nExponential distribution: The Exponential distribution models the time (T) between consecutive events, given a\nconstant hazard rate \u03bb. Its probability density function (PDF) and cumulative distribution function (CDF) are:\n$f(T) = \\lambda \\exp(-\\lambda T)$,                 $T \\geq 0$,\n$F(T) = P(T < t) = 1 - \\exp(-\\lambda t)$.\nIt is natural to align the choice of distribution with specific research questions related to fall prediction. Below are two\npossible key questions of interest:\n\u2022 Q1: What is the probability that a fall occurs within t months?\n\u2022 Q2: What is the probability that no falls occur until at least t months later?\nThese questions highlight different perspectives on modeling time-to-event data, with an analysis as follows.\nQ1: What is the probability of a fall occurring within t months?\nTo address this question, we consider the probability of one or more falls occurring within a fixed time interval t.\nCase 1-1: Exactly One Fall\nThe Poisson distribution models the number of events occurring in a fixed time interval t, with rate parameter \u03bb. The\nprobability of observing exactly one fall within t units of time (such as months) is:\n$P(N_t = 1) = \\frac{(\\lambda t)^1 \\exp(-\\lambda t)}{1!} = t\\lambda \\exp(-\\lambda t)$.\nThis assumes that falls follow a Poisson process, where events occur independently, and the rate A is constant.\nCase 1-2: One or More Falls\nThe probability of one or more falls within t months is the complement of the probability of no falls ($N_t = 0$):\n$P(N_t \\geq 1) = 1 - P(N_t = 0)$.\nFrom the Poisson distribution:\n$P(N_t = 0) = \\frac{(\\lambda t)^0 \\exp(-\\lambda t)}{0!} = \\exp(-\\lambda t)$.\nThus, the probability of one or more falls is:\n$P(N_t \\geq 1) = 1 - \\exp(-\\lambda t)$.\nFrom the Perspective of Exponential Distribution\nThe exponential distribution, which models the time between events, can also answer this question. The cumulative\ndistribution function (CDF) of the exponential distribution is:\n$P(T < t) = 1 - \\exp(-\\lambda t)$,\nwhere T is the time to the first event (e.g., a fall). This result is consistent with the Poisson-derived probability of one\nor more events occurring within t months:\n$P(N_t \\geq 1) = P(T < t) = 1 - \\exp(-\\lambda t)$.\nThe equivalence $P(T < t) = P(N_t > 1)$ arises from the relationship between the exponential and Poisson dis-\ntributions in a Poisson process. While mathematically identical, their interpretations differ. $P(T < t)$ models the\nprobability of the first event occurring within time t, focusing exclusively on the timing of that first event, regardless\nof what happens afterward, leaving subsequent events unmodeled. This distinction becomes explicit in the Poisson\ndistribution, where probabilities for specific event counts, such as $P(N_t = 1)$ or $P(N_t = 2)$, are directly modeled.\nHowever, when using the exponential distribution, the focus is inherently on the first event or the interval between con-\nsecutive events, aligning it with time-focused questions rather than event-count-focused scenarios. For applications\nrequiring explicit event counts, such as determining the probability of exactly one event occurring within t, the Poisson\ndistribution provides the necessary framework. The equivalence $1 - e^{-\\lambda t}$ thus serves different purposes depending\non the context: it can represent the probability of the first event occurring or the probability of at least one event, but\ncaution is needed to ensure correct interpretation based on the specific problem at hand.\nQ2: What is the probability that no falls occur until t months later?\nThe second question shifts the focus to the survival probability $S(t)$, a key concept in survival or risk analysis [2],\nwhich quantifies the likelihood of not experiencing an event, such as a fall, by time t.\nCase 2-1: Based on the Poisson Distribution\nThe probability of no falls occurring within t months is equivalent to $P(N_t = 0)$, calculated earlier:\n$S(t) = P(T \\geq t) = P(N_t = 0) = \\exp(-\\lambda t)$.\nCase 2-2: Based on the Exponential Distribution\nThe exponential distribution, particularly the cumulative form of the exponential distributions, answers\n$P(T < t) = 1 - P(T \\geq t) = 1 - \\exp(-\\lambda t) = 1 - S(t)$"}, {"title": "4 Poisson Regression in Survival Analysis Framework", "content": "Now that we can model the time of interest using probability distributions such as the Poisson and Exponential dis-\ntributions, which inherently account for time; however, they do not directly incorporate the influence of covariates.\nTo address this limitation, we utilise Generalized Linear Models (GLMs) [17, 18], which enable the modeling of the\nlinear relationship between the risk of time-to-event and associated covariates.\nThe Exponential Family and Its Role in GLMs\nA prerequisite to understanding GLMs is the exponential family of distributions, a versatile class of probability distri-\nbutions expressed in the form:\n$f(y; \\eta) = b(y) \\exp (\\eta T(y) \u2013 a(\\eta))$,\nwhere:\n\u2022\n\u03b7: the natural (canonical) parameter, often derived by rewriting the original parameters of the distribution,\n\u2022 T(y): the sufficient statistic, summarizing all relevant information about y (commonly T(y) = y),\n\u2022 a(n): the log-partition function, ensuring normalization,\n\u2022 b(y): the base measure, independent of n.\nRewriting a distribution into this form typically involves taking the logarithm of the probability density function (PDF)\nor probability mass function (PMF) and identifying the components corresponding to \u03b7, T(y), and a(n). The following\nare examples of common distributions in exponential family form, which provide the foundation for deriving flexible\nlinear models, where the response variable may follow alternative distributions depending on its nature.\n\u2022 Bernoulli: $f(y; p) = p^{y}(1 \u2013 p)^{1-y}$,                                 $y \\in \\{0,1\\}$, $0 < p < 1$\n$f(y; \\eta) = \\exp (y\\eta \u2013 \\ln(1+ e^{\\eta})), where $\\eta = \\ln\\left(\\frac{p}{1-p}\\right)$,         $a(\\eta) = \\ln(1 + e^{\\eta}), b(y) = 1$.\n\u2022 Exponential: $f(y; \\lambda) = \\lambda e^{-\\lambda y}$,                       $y \\geq 0$, $\\lambda > 0$\n$f (y; \\eta) = \\exp (\\eta y \u2013 \\ln(-\\eta)), where $\\eta = \u2013\\lambda, a(\\eta) = \\ln(-\\eta), b(y) = 1$.\n\u2022 Poisson: $f(y; \\lambda) = \\frac{\\lambda^{y} e^{-\\lambda}}{y!}$,                                 $y \\in \\{0,1,2, . . . \\}$, $\\lambda > 0$.\n$f(y; \\eta) = \\exp (\\eta y \u2013 e^{\\eta} \u2013 \\ln(y!)), where $\\eta = \\ln(\\lambda), a(\\eta) = e^{\\eta}, b(y) = \\frac{1}{y!}$\nGLMs: Associating Covariates with Risks\nGLMs extend linear regression to allow the response variable Y to follow distributions from the exponential family.\nTo derive GLMs, three core principles are followed:\n1. Response Variable Belongs to the Exponential Family: The response variable Y must follow an exponential\nfamily distribution: $f (y; \\eta) = b(y) \\exp (\\eta T(y) \u2013 a(\\eta))$."}, {"title": "5 Cox Proportional Hazard Model", "content": "The previous section discussed how to utilize common probability distributions and Generalized Linear Models\n(GLMs) to derive Poisson regression for time-to-event analysis within the framework of survival analysis. Before\na comparative analysis, this section introduces a widely used approach for analyzing time-to-event data: the Cox Pro-\nportional Hazards Model (Cox PH Model) [19]. It models key concepts, including the hazard rate, cumulative hazard\nfunction, and survival function, while seamlessly incorporating covariates to account for individual differences."}, {"title": "Basic Concepts", "content": "The hazard rate represents the instantaneous risk h(t) of the event occurring at time t, given survival up to that time:\n$h(t) = \\lim_{\\Delta t \\to 0} \\frac{P(t < T < t + \\Delta t | T > t)}{\\Delta t}$\nIt's worth noting that the hazard rate is not a probability but a rate (e.g., events per unit time).\nThe cumulative hazard function H(t) measures the total accumulated risk of experiencing the event up to time t.\n$H(t) = \\int_{0}^{t} h(u) du$.\nThe survival function S(t) gives the probability of surviving (not experiencing the event) beyond time t:\n$S(t) = P(T \\geq t)$.\nFrom the definition of the hazard function, the probability of surviving a small time interval [t, t + \u2206t), given survival\nup to t, is approximately:\n$P(T > t + \\Delta t | T > t) = 1 \u2013 h(t)\\Delta t$.\nTaking the product over all infinitesimal intervals up to t, the survival probability becomes:\n$S(t) = \\prod_{u=0}^{t} (1 \u2013 h(u)\\Delta u)$.\nUsing the approximation ln(1 \u2013 x) \u2248 -x for small x, and taking the logarithm:\n$\\ln(S(t)) \\approx \\sum_{u=0}^{t} -h(u)\\Delta u = \\int_{0}^{t} h(u) du.$\nExponentiating both sides:\n$S(t) = \\exp(- H(t))$.\nWhile H(t) captures the total accumulated risk of the event up to time t, and exp(-H(t)) translates this cumulative\nrisk into the probability of not experiencing the event. Since H(t) \u2265 0, $S(t) = \\exp(-H(t))$ ensures 0 \u2264 S(t) \u2264 1,\nsatisfying the requirements of a probability. Survival over t is the product of surviving each infinitesimal time interval,\nand exp(-H(t)) reflects this multiplicative accumulation."}, {"title": "Incorporating Covariates: Proportional Hazards Assumption", "content": "The Cox PH model relates the hazard rate to a set of covariates as:\n$h(t | X) = h_0(t) \\exp(\\beta^T X)$,\nwhere $h_0(t)$ is the baseline hazard function and $\\exp(\\beta^T X)$ is the relative risk associated with the covariates X. This\ndecomposition separates the hazard function into two distinct components: the baseline hazard $h_0(t)$, which depends\nsolely on time t and captures the risk for an individual when all covariates X = 0; and the relative risk $\\exp(\\beta^TX)$,\nwhich adjusts the baseline hazard based on the covariates and remains constant over time.\nThe use of $\\exp(\\beta^TX)$ appears identical to that of Poisson that is derived from GLMs, but in the context of Cox model,\nthe use of $\\exp(\\beta^TX)$ is more of a design choice to ensure non-negative hazards, interpretable coefficients, and realistic\nmultiplicative effects.\n1. Ensuring Non-Negativity of the Hazard: The hazard rate $h(t | X)$ represents a risk or rate and must always\nbe non-negative. The exponential function $\\exp(\u00b7)$ naturally satisfies this requirement, as exp(z) > 0 for all z.\nThis is a crucial advantage over direct linear formulations such as:\n$h(t\\vert X) = h_0(t) + \\beta^\u2122 X$,\nwhich can result in invalid negative hazard rates when $\\beta^T X$ dominates $h_0(t)$."}, {"title": "6 Comparison of Poisson Regression and Cox PH Model", "content": "Both Poisson regression applied in a survival analysis context and the Cox model aim to model time-to-event data.\nWhile their formulas are structurally similar, they differ in how the hazard rate and survival function are defined. This\nsection reviews and compares these approaches.\n1. Poisson Regression in a Survival Context\nHazard Rate: In Poisson regression, the rate of events (\u03bb) is modeled as:\n$\\lambda = \\exp(\\beta^T X)$,\nwhere $\u03b2^T X$ is the log-linear combination of covariates.\nSurvival Function: For a constant event rate ($\\lambda = \\exp(\\beta^T X)$), the survival function is:\n$S(t\\vert X) = \\exp(-t\\lambda) = \\exp(-t \\exp(\\beta^T X))$.\nThis survival function is derived from the Poisson process based assumption for inter-event times.\n2. Cox Proportional Hazards Model with Constant Baseline Hazard\nHazard Rate: The Cox PH model specifies the hazard function as:\n$h(u|X) = h_0(u) \\exp(\\beta^T X)$."}, {"title": "7 Learning and Applying Cox Proportional Hazard Model", "content": "Given the broader applicability of the Cox Proportional Hazards model compared to Poisson regression in survival\nanalysis, this section introduces the fundamentals of learning the Cox model and demonstrates its application in sce-\nnarios such as fall detection through adding three key applications: 1) Predicting the risk of an event at specific time\nintervals, 2) Analysing the influence of factors on event risk, and 3) Estimating the expected time until the next event.\n7.1 Learning a Survival Model\nTo learn a survival model like the Cox PH model, the key is to estimate the relationships between covariates and\nsurvival time (via the hazard function), while simultaneously capturing the underlying baseline hazard and survival\nprobabilities. Below are core computations involved:\nStep 1: Estimate the Regression Coefficients (\u03b2)\nThe first task is to learn how the covariates X influence the hazard via the relative risk:\n$h(t|X) = h_0(t) \\exp(\\beta^T X)$.\nThe coefficients \u03b2 are estimated using partial likelihood, which focuses on the ordering of event times rather than their\nexact values. Maximizing partial likelihood gives estimates for B, capturing the effect of covariates on the hazard ratio.\n$L(\\beta) = \\prod_{i=1}^{n} \\frac{\\exp(\\beta^TX_i)}{\\sum_{j \\in R(t_i)} \\exp(\\beta^TX_j)}$,\nwhere: $t_i$ is the time of the event for individual i, and R($t_i$) is the set of individuals still at risk just before $t_i$. Using\npartial likelihood makes it unnecessary to compute the baseline hazard $h_0(t)$, as it cancels out in the partial likelihood."}, {"title": "8 Conclusion", "content": "This paper underscores the critical role of survival analysis in tackling healthcare challenges, with a specific focus\non fall detection and prevention. By revisiting foundational statistical methods and distributions, it offers a unified\nperspective on widely used survival analysis techniques, including logistic regression, Poisson and Exponential distri-\nbutions, Generalized Linear Models (GLMs), and the Cox Proportional Hazards model.\nA contribution of this work is the clarification of the relationships among these models, particularly demonstrating that\nPoisson regression in the survival context is a specific case of the Cox model. These insights bridge gaps in understand-\ning and reinforces the simplicity, interpretability, and versatility of survival models. Unlike advanced deep learning\nmethods-which often require complex post-hoc interpretation and separate training for different tasks especially\nwhen dealing with pure numerical data\u2014survival models offer a streamlined framework capable of simultaneously\npredicting event risks at specific time intervals, interpreting covariate effects, and estimating time to the next event.\nThese attributes are particularly valuable in healthcare, where explainability and robustness are paramount, making the\napplications are not limited to fall detection alone, but to broader domains such as disease progression, highlighting\nthe versatility of survival analysis techniques.\nBy connecting theoretical insights with real-world applications, the paper emphasises the enduring relevance of classi-\ncal statistical survivla frameworks in guiding intervention strategies and navigating the evolving landscape of analytical\nmethods. By detailing the derivation and application of survival models, the paper provides an accessible resource for\nunderstanding these techniques, making it a valuable entry point for researchers and practitioners alike. For further\nexploration of survival analysis and the Cox model, readers may refer to a series of tutorial papers on survival analysis\n[21, 22, 23, 24] and review papers on the Cox model [25, 26]."}]}