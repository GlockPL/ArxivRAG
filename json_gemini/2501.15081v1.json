{"title": "CAN LARGE LANGUAGE MODELS BE TRUSTED AS BLACK-BOX\nEVOLUTIONARY OPTIMIZERS FOR COMBINATORIAL PROBLEMS?", "authors": ["Jie Zhao", "Kang Hao Cheong", "Tao Wen"], "abstract": "Evolutionary computation excels in complex optimization but demands deep domain knowledge,\nrestricting its accessibility. Large Language Models (LLMs) offer a game-changing solution with\ntheir extensive knowledge and could democratize the optimization paradigm. Although LLMs pos-\nsess significant capabilities, they may not be universally effective, particularly since evolutionary\noptimization encompasses multiple stages. It is therefore imperative to evaluate the suitability of\nLLMs as evolutionary optimizer (EVO). Thus, we establish a series of rigid standards to thoroughly\nexamine the fidelity of LLM-based EVO output in different stages of evolutionary optimization and\nthen introduce a robust error-correction mechanism to mitigate the output uncertainty. Furthermore,\nwe explore a cost-efficient method that directly operates on entire populations with excellent effec-\ntiveness in contrast to individual-level optimization. Through extensive experiments, we rigorously\nvalidate the performance of LLMs as operators targeted for combinatorial problems. Our findings\nprovide critical insights and valuable observations, advancing the understanding and application of\nLLM-based optimization.", "sections": [{"title": "Introduction", "content": "The advancement of computing technology, especially large language models (LLMs) [1, 2], has made it possible\nto revolutionize traditional programming methodologies [3, 4, 5] and reduce human labor. This vision is already\nmaterializing in the field of optimization [6], where optimization of combinatorial problems is achieved not through\nmathematical analysis or traditional programming but via prompt engineering only. Evolutionary optimization has\nproven to be an exceptionally powerful technique for tackling complex problems due to its simplicity and effectiveness\n[7, 8]. Despite their benefits, implementing evolutionary optimization is labor-intensive and demands deep domain\nexpertise for precise execution [9]. This challenge intensifies with constrained problems or when tailoring methods\nfor specific needs. Such difficulty is especially pronounced for non-technical users, presenting a major barrier to\naccessibility and effective application. Therefore, we ask the critical question of whether LLMs can directly serve as\nevolutionary optimizer (EVO).\nTo date, some preliminary studies have explored the use of LLMs as crossover operators [10], mutation operators [11],\nand in combination [12]. Despite these advancements [13, 14], LLMs have shown variable performance across different\ndomains; they excel in some areas [15, 16, 17] but not in tasks requiring precise arithmetic and logical reasoning\n[18, 19]. For most researchers, it is challenging to train a large model from scratch targeted to a specific problem or\neven fine-tune it due to the huge computational demands. Thus, when deploying these models for specific tasks, it is\nimperative to conduct a thorough analysis to ascertain whether LLMs are genuinely suitable for the task at hand.\nWhile these efforts have opened up LLMs as the black-box EVO, there is still a lack of comprehensive investigation\nto evaluate the effectiveness and reliability of LLMs as EVO, and to identify the factors affecting their performance.\nHuang et al. [20] conducted an investigation on LLMs as normal optimizers on different problems, but it is only\ntargeted at one-shot optimization, and some important aspects such as reliability, scalability, and computational cost\nremain underexplored. Thus, our work here aims to serve as a thorough assessment of the performance of LLMs as\noperators in all stages of evolutionary optimization, some of which, like LLM-based initialization and selection, still\nremain underexplored in the existing literature. We aim to provide insights into the suitability of LLMs, clarifying\ntheir capabilities and limitations. Our evaluations compare LLM-based approaches with software-based evolutionary\ncomputation to assess the accuracy of LLMs in meeting expected outcomes and their effectiveness in fulfilling\ncustomized requirements.\nAs evolution optimization is an iterative process, an error in any step will yield a cascading effect, leading to a failure of\noptimization. Recognizing the inherently probabilistic nature of LLMs outputs [21, 22, 23] and the high requirements on\nthe quality of the generated solutions during evolutionary optimization, we develop different stringent sets of standards\nfor LLMs outputs in various levels to rigorously measure solutions in terms of their format, diversity, and conformity to\nproblem constraints. We also introduce a set of corresponding error repair mechanisms with precisely tailored prompts\nto enhance the reliability of the LLM-based EVO.\nIn addition, we explore a cost-effective method that utilises the entire population as optimization unit for the LLM-based\nreproduction operator and compare this method with another common approach that implements optimization on\nindividual-by-individual. We specifically analyze the quality of generated solutions by these two distinct ways as well\nas their computational overhead. Some of our findings in this work are summarized as follows:\n\u2022 LLMs can perform the selection, crossover, and mutation operations well. Their performance is relatively independent\nof dataset size and type, being more influenced by hyperparameters such as population size and solution size instead.\n\u2022 LLMs may not be suitable for tasks involving intensive computation, such as initialization, and their performance\ntends to degrade greatly as the dataset size increases.\n\u2022 The performance of LLMs relies on the amount of input data, and LLMs may encounter various issues during the\nevolutionary optimization process, making correction mechanisms indispensable for successful optimization."}, {"title": "LLM-based evolutionary optimizer", "content": "As in the combinatorial problem within the evolutionary optimization framework, the solution representation is generally\ndefined as\n$[X_1, X_2, ..., X_n]$,\nwhere X depends on the specific task and n is the solution size [24, 25]. In this work, we choose a node selection\nproblem [26, 27] as the illustrative example. The problem is defined as: Given a graph G = (V, E), where V represents\nthe set of nodes and E represents the set of edges, the objective is to find a subset of nodes S\u2286 V that maximizes the\ninfluence across the network. As for network-related problems, the solution representation can simply be\n$[Node_1, Node_2, ..., Node_n]$.\nNote that our focus is not on solving any specific network-related problem but on evaluating the performance of\nLLMs as operators for combinatorial problems. The reason for selecting this problem is that it is general enough to\nprovide insights and observations for LLMs as EVO due to the representation similarity on combinatorial problems.\nTo enhance generality, \u2018element' will replace 'node', and 'dataset' will replace 'graph' in the rest discussion. This\ngenerality is also reflected in our prompt engineering where little network domain knowledge is needed (please refer to\nthe Appendix). For the selection, the inputs to LLMs is\n$\\{([X_1^{(1)}, ..., X_n^{(1)}], f_1), ..., ([X_1^{(k)}, ..., X_n^{(k)}], f_k)\\}$,\nwhere k is the population size and $X_i^{(j)}$ refers to the i-th element in the j-th solution in the population. It can be\nsimplified as\n$\\{(S_1, f_1), ..., (S_k, f_k)\\}$,\nwhere $S_i$ is the index of solution $[X_1^{(1)}, ..., X_n^{(i)}]$ and $f_i$ is its fitness value.\nLet F be combination of LLM-based evolutionary operators, i.e.,\n$F = \\{F_I, F_S, F_C, F_M\\}$,\nwhere $F_I, F_S, F_C$ and $F_M$ indicate LLM-based initialization, selection, crossover, and mutation, respectively.\nThe first phase, Initialization is defined as $P_0 = F_I(G)$, where $P_0$ refers to the initialized population and G refers to\nthe input data. A strategic reduction in search space can effectively speed up convergence and improve effectiveness"}, {"title": "Computational cost of population- and individual-level LLM-based EVO", "content": "As we aim to assess the fidelity of LLM-based EVO, the benchmark is based on precise coding methods. It is not\napplicable to compare their computational costs and efficiency since LLMs rely on online resources (e.g., token count)\nwhile code-based methods depend on local hardware. Then, we will discuss the difference between population- and\nindividual-level optimization regarding computational cost.\nCrossover: Let V be the token cost of LLMs, and V(P) and V(S) refer to the token of the entire population and\nindividual solution, respectively. The input to LLMs consists of prompt $T_E$ ($T_E$) and a pair of solutions (population),\nwhere $V(T_E) \u2248 V(T_E)$. Note that $V(T_E)$ is slightly higher than V($T_E$) because there will be an additional text\nlike \"Please randomly select pairs of solutions and continue applying the crossover operation until the number of\nnewly created solutions matches the population size.\" in the population-level method, in which the token cost is\n$V(T_E) + V(P)$. In contrast, the individual-level method requires LLMs to implement crossover operation on pair by\npair, which costs $(V(T_E) + 2 * V(S)) * \\frac{N_p}{2}$ where $N_p$ refers to the population size. AsV(P) = V(S) * Np, the cost\ndifference between individual- and population-level crossover is $V(T_E * \\frac{N_p}{2}) \u2013 V(T_E) \u2248 \\frac{N_p^2}{2} * V(T_E)$.\nMutation: As for individual-level mutation, it will run $F_M$ for Np times since it will mutate the solution individual by\nindividual. Thus, its cost difference with population-level mutation is $V(T_M * N_p) \u2013 V(T_M) \u2248 (N_p \u2212 1) * V(T_M)$.\nClearly, the proposed population-level method can save roughly $\\frac{NP-2}{2} * V(T_E) + (N_p \u2013 1) * V(T_M)$ in each round as\ncompared to individual-level method, and this advantage in cost will be further amplified when population size and\nevolution round are set to a high number.\nNotably, there are several restrictions that must be followed during reproduction: (1) The new solution should not\ncontain duplicate/invalid elements; (2) The new solution should maintain the same size as the previous solution; and (3)\nThe population size should remain the same as the previous population (only applicable to the population-level EVO)."}, {"title": "Error repair", "content": "The probabilistic nature of LLMs can lead to occasional undesirable results. As evolutionary optimization is an iterative\nprocess, an error early in the process can 'blow up' in subsequent cycles, creating a cascading effect to ruin the\noptimization process. We therefore investigate the possible errors and set rigid standards to validate the LLM outputs in\ndifferent phases. These errors are categorized as format errors and quality errors, with the latter further divided into\ncritical errors and moderate errors. Specifically,\n\u2022 Format Error refers to generated solutions that fail to adhere to required structures.\n\u2022 Critical Error refers to solutions that, while structurally correct, may cause system failures, demanding\nimmediate resolution to prevent extensive damages.\n\u2022 Moderate Error refers to solutions that can cause minor disruptions but generally will not lead to complete\nfailure of optimization.\nThe details of the different types of errors are listed in Table 1 (Please refer to the Appendix for more explanation)\nand an example of possible errors encountered in the population-level crossover is given in Figure 1(C). The outputs\ngenerated in different phases will undergo different validations due to the varying requirements for each phase. In\naddition, the output requirements are different when the input is an individual solution (denoted as S) and the entire\npopulation (denoted as P). The detail is shown in Table 2.\nDuring optimization, particularly in environments with numerous constraints, managing invalid solutions is critical in\nensuring successful optimization. To this end, we introduce a robust repair mechanism that maintains solution feasibility\nand ensures that each iteration contributes positively toward finding an optimal solution. Let O be the output from\n{FI, FS, FC, FM }, the refined output is defined as\n$O_{FR}(O, E_x, R_x)$,\nwhere FR refers to the LLM-based repair operator. Ex and Rx denote the error message and targeted repair prompt.\nDuring the optimization, each output undergoes the three aforementioned examinations. If any error is detected, the\nrepair mechanism is triggered. We will check and repair each type of error individually. Format errors and critical errors\nare particularly detrimental. The former interrupts the entire optimization process, and the latter can heavily corrupt the\npopulation, diverting the optimization from its optimal path. We will avoid repairing these two types of errors due to the\ncomplexity involved. Instead, a new generation is directly requested to obtain a valid solution. Due to their destructive\nimpact, solutions failing these checks cannot be used and the previous phase's solution will be used for the next phase.\nIn contrast, solutions with moderate errors that are not successfully repaired are allowed to enter into the next phase.\nThis approach is adopted because (1) the error can always be mitigated after repair; and (2) moderate errors do not yield\ncascading effects on the entire optimization, and there will still be an opportunity to repair them in the next phases."}, {"title": "Solution evaluation", "content": "After the output undergoes the check and, if necessary, repair process, we categorize it into the following cases:\n\u2022 Approved (Qapp): The solution meets all requirements and standards perfectly, with no errors or deficiencies.\nIt is ready for implementation without any modifications.\n\u2022 Repaired (Qrep): The solution had minor issues that did not meet the necessary standards, but these have been\naddressed, and it now meets the required criteria.\n\u2022 Acceptable (Qacc): The solution contains flaws that fail to be completely corrected, but it still functions\nadequately and meets the minimum necessary criteria for use, albeit not optimally.\n\u2022 Rejected (Qrej): The solution has format or critical error even though after an attempt of repair, rendering it\ncompletely unusable.\nFor the format and critical errors, the acceptable case Qacc is not applicable due to their destructive impact on the\npopulation. If a solution encounters these errors and cannot be repaired, it must be rejected. In this case, the output with\nmoderate error from last check will pass through to the next phase if repair fails."}, {"title": "Experimental studies", "content": "The fidelity and reliability of LLM-based EVO of different stages are validated on various datasets in different settings.\nThe population size and the evolution round are set to 30. The number of tests for candidate selection is 100, and the\nresults of evolutionary optimization are averaged from 10 independent simulations. The structural information of the\ntested dataset is listed in Table 3. More details of the parameters are given in the Appendix."}, {"title": "Optimization validation of LLM-based EVO", "content": "Table 4 shows the results of pass ratio of format and critical check in the candidate selection, consisting of ranking and\nfiltering. As seen, LLMs effective on small datasets fail to generate valid outputs for large datasets. For example, on\nDolphins, LLMs achieve 100.0% Qacc on both checks. We compare it with larger networks and observe an obvious\ndecrease in pass ratios; particularly, the critical check pass drops to about 40%. Thus, it can be seen that LLMs'\nperformance in calculation tasks, like candidate selection, will decline as the amount of input data increases.\nThe LLM-based initialization shows superior fitness at the starting point and during the optimization compared to\nrandom initialization, as shown in Figure 2. This result shows that LLMs can effectively handle population initialization,\nreducing human effort for networks of hundreds of nodes."}, {"title": "Selection:", "content": "Figure 3 compares the selection performance of LLM-based selection with other selection strategies. The LLM-based\nselection demonstrates the highest fitness across the entire optimization generation, with only the tournament strategy\nachieving comparable performance. It can be deduced that LLMs is effective in decision-making tasks such as in the\nselection phase."}, {"title": "Reproduction:", "content": "For fairness, we enhanced the baseline code-based EVO shown in Figure 4 by ensuring it does not violate constraints.\nAs observed, the LLM-based EVO can achieve nearly the same performance as software-based evolutionary\noptimizers, reflected by their similar fitness. Additionally, the choice of model significantly impacts performance, as\nevidenced by the poor results of the population-level LLM-based EVO by GPT-3.5."}, {"title": "Reliability analysis", "content": "Table 5 shows that the ratio of Qapp regarding format error is consistently above 95% in all phases. Meeting the\nrequirement of critical errors is more challenging as more criteria are involved. GPT-4.0 performs exceptionally well,\nachieving a Qrej below 1%. Even when issues are occasionally detected, they can be repaired, as seen in the initialization\ncase. In contrast, LLM-based EVO enhanced by GPT-3.5 has a relatively low Qacc and has nearly 10% Qrej in critical\nerror during the population-level crossover. Figure 5 also exhibits the similar result as format and critical check. The\nratio of Qacc in moderate error of GPT-4.0 is higher than that obtained by GPT-3.5. It can be concluded that the quality\nof LLMs output is promising but strongly dependent on model capability. In phases that demand processing large\ndata amount, such as population-level crossover and mutation, the LLM-based operator only achieves a maximum\naccuracy (Qacc) of 92.3%. However, in phases requiring less data processing, it can maintain a minimum accuracy\nof 95%. There are also fewer errors for individual-level EVO than population-level EVO. We can conclude that the\nreliability of LLMs is mainly affected by the scale of the processed data."}, {"title": "Scalability analysis", "content": "The scalability of LLM-based operators is subjected to the input data, which varies across different stages.\nInitialization: As illustrated in Table 4, the effectiveness of candidate selection is significantly influenced by the size of\nthe dataset. The input scale for LLMs during initialization (both candidate selection and sampling) increases\nlinearly with the dataset size. For example, given a network of 10,000 nodes, we must input all their IDs with any\nspecific metrics to LLMs for ranking, filtering, and sampling. It is not practical to input such large amounts of numerical\ndata into LLMS and have them do such complex operations, not to mention the huge token overhead, meaning that\nLLMs may not be suitable for this data-intensive task.\nPrevious experiments indicate that LLMs are highly sensitive to the amount of input data. However, apart from\nthe initialization phase, the input to LLMs is not the dataset itself but the population. Thus, the performance of\nLLM-based selection and reproduction relies more on hyperparameters than on the scale or type of dataset."}, {"title": "Selection:", "content": "No matter what the dataset is, the input to LLM is always \\{(S1, f1), ..., (Sk, fk)\\}. Thus, the relevant factor\nto LLM-based selection is the population size. A larger population size increases the amount of data LLMs need to\nprocess, but the common setting of this parameter is manageable to LLMs [29, 24]. Therefore, LLM-based selection\nhas great applicability in this decision-making task given the promising result in Figure 3.\nCrossover and Mutation: For these two phases, the input to LLMs is either [X1, X2, ..., Xn] (individual-level) or\n\\{\\[X1^((1)), ..., Xn^((1))\\],..., [X1^((k)), ..., Xn^((k))]\\} (population-level). As such, the input data amount, the main factor affect-\ning LLMs' performance, is dependent on the solution size and population size (only applicable to population-level\noptimization). The population size and solution size are empirical and will unnecessarily increase with the increase in\nthe scale of datasets. Thus, we can conclude that the dataset scale and the LLM's performance are not directly related,\nwhich is demonstrated in Table 6 where the reliability of LLM-based EVO in the large dataset Astro is comparable to\nthat in the two smaller networks.\nEvidence of LLMs sensitivity to hyperparameters can be found in Table 7, where the population size is set to P1 = 30\nand P2 = 10, and the solution size is set to S1 = 10 and S2 = 5. Reducing either the population size or the size of a\nsingle solution helps to minimize errors, a trend consistent for both crossover and mutation phases.\nOne potential factor affecting performance as dataset size increases is the representation of element IDs in the solution.\nFor example, given two datasets with element counts of up to 103 and 104, the maximum number of digits required to\nrepresent element IDs is 4 and 5, respectively. It means that the growth in element ID digits increases logarithmically\nrather than proportionally with dataset size. Therefore, we can conclude the scalability of LLM-based EVO in the\nreproduction phase is excellent, which is also demonstrated in Table 6, where there is no obvious difference between\nAstro and other smaller datasets regarding three types of check."}, {"title": "Ablation study", "content": "Figure 6 presents the ablation results of implementing a repair mechanism on the population-level LLM-based EVO\nacross three datasets. We only test the moderate error as format error and critical error are so severe that the optimization\ncannot proceed as normal, and lead to consistently poor outcomes. For both datasets, the inclusion of a repair\nmechanism consistently outperforms the absence of one, as indicated by the higher average fitness achieved across\ngenerations. The observed stagnation in the scenarios without a repair mechanism indicates the impact of errors on\noptimization and suggests the importance of repair procedures."}, {"title": "Computational overhead analysis", "content": "Figure 7 compares the token costs between individual- and population-level LLM-based EVO in Netscience. Initial cost\nrefers to the tokens required for a single operation, while total cost includes the additional tokens for repairs. The results\nshow that population-level EVO incurs much lower costs than the individual-level EVO for both crossover and\nmutation in the entire process, no matter what LLM is used. It can be seen that the repair costs for the population-level\napproach are higher than those for the individual-based method. Nevertheless, both theoretically and practically, the\ntotal costs of the population-level method are lower. As LLMs continue to advance, the accuracy of LLM-based EVO\nwill improve, leading to reduced repair costs, which further show the superiority of population-level optimization."}, {"title": "Conclusion", "content": "To facilitate evolutionary optimization by LLMs, we have conducted a comprehensive evaluation of LLM-based EVO\nby establishing a set of criteria. Our assessment offers insights and analysis on the strengths and limitations of using"}, {"title": "Related works", "content": "Wu et al. classified existing works regarding the synergy of LLMs and evolutionary computation into two main branches\n[9]: LLM-based black-box search operators [30, 14] and LLM-based optimization algorithm automation [31, 32].\nLLMs can potentially automate and optimize the design of evolutionary operators as indicated in [33], thereby reducing\nthe need for manual tuning and domain-specific adjustments such as [34, 35]. Yang et al. proposed to use LLMs as\noptimizer named Optimization by PROmpting (OPRO) to solve traveling salesman problem [6], in which the previously\ngenerated solution and its evaluation value are used as part of the prompt for next generation. In the study by Meyerson\n[10], LLMs are employed as crossover operators to derive new solutions from parental inputs. Brownlee [11] also\npresented LLMs effectively functioning as mutation operators that enhance the search process. Liu et al. introduced\na novel framework known as LLM-driven EA (LMEA) [12], which utilizes LLMs for both crossover and mutation\noperations. This approach highlights the adaptability of LLMs, where search behaviors can be easily modified by\nadjusting the LLM temperatures. Furthermore, LLM-based search operators can also be adapted for multi-objective\nscenarios by segmenting traditional optimization tasks into sub-problems [13].\nLLMs have shown significant potential in automated evolutionary optimization, autonomously optimizing, creating,\nand improving algorithms to effectively tackle optimization challenges. As demonstrated in [16], heuristic searched\nby LLMs achieves excellent performance in different complex combinatorial problems. In [36], Liu et al. proposed\na new method called Algorithm Evolution using the Large Language Model (AEL) that directly considers algorithms as\nindividuals for evolution. AEL was then further extended to the design of guided local search algorithms [37], showing\nthe strength of the LLM-based method over human-designed algorithms. After that, they extended AEL to an advanced\nmodel called Evolution of Heuristics (EoH) by exploring various prompts to solve different combinatorial tasks. LLMs\nanalyze swarm intelligence algorithms to obtain a hybrid algorithm that combines various strengths of existing methods\n[38]. Mao et al. explored LLM-enhanced algorithm automation for identifying critical nodes [39]. In this approach,\nvarious heuristics are initialized as populations and then evolve with the assistance of LLMs.\nFurthermore, LLMs can also assist in algorithm selection, as demonstrated in [40], through analyzing the code to\ngrasp both its structural and semantic elements, along with the contextual understanding. An emerging direction worth\nnoting involves using evolutionary optimization to search for the optimal prompt, enabling LLMs to achieve excellent\nperformance. Notable examples of this approach can be found in the work of [41, 42, 43].\nOur work is targeted to the first category, aiming to assess the suitability of LLMs as black-box operators. We\ninvestigate a new population-level optimization and establish repair mechanisms to reduce LLM uncertainty and\nenhance optimization."}, {"title": "More detail of possible errors of LLMs output", "content": "The following describes how each error type can negatively affect the optimization process with detailed examples."}, {"title": "Format Error", "content": "The format error refers to those that can directly interrupt the running of a program. Since format errors are rare and\ndifficult to fix, it is usually more efficient to request a new generation.\n\u2022 E1: The output is not in the required format.\nExample: When we ask LLMs to generate a list in Python, we expect only that list without any\nexplanation and text for further operations. However, LLMs sometimes add extra text, like \"You are doing\na crossover, and the result is ...\".\nImpact: This error can disrupt the evolutionary process because algorithms depend on a specific data\nstructure.\n\u2022 E2: The output contains non-integer elements.\nExample: The combinatorial problems require discrete integer values while LLMs sometimes output a\nsolution containing non-integer numbers such as [3, 5.9, 2.1, 8].\nImpact: Non-integer outputs can lead to invalid candidate solutions that cannot be evaluated, thus this\nerror will also interrupt the process as E1."}, {"title": "Critical Error", "content": "Most critical errors undermine diversity, which is essential for successful optimization. Note that once diversity is\nseverely damaged, then it is very difficult to repair as only mutation contributes to exploration in the entire evolutionary\noptimization. Therefore, this kind of error is not allowed in the optimization. In a manner consistent with addressing\nformat errors, a new output will be requested instead of attempting to correct an unacceptable one.\n\u2022 E3: The selected candidates significantly deviate from the ground truth.\nExample: We input all possible elements, each with a specific metric, and seek the top 50% (for example).\nHowever, LLMs outputs may only minimally overlap with the ground truth, indicating that most of their\nsuggestions are not suitable candidates.\nImpact: This case will reduce the quality of the initialized population, further impacting subsequent\noptimization.\n\u2022 E4: The size of candidates falls significantly short of meeting the requirements.\nExample: We input all possible elements, each with a specific metric, and seek the top 50%. However,\nLLMs may output only 10% elements.\nImpact: Such a number is insufficient to guarantee the diversity of the population as the solutions in the\ninitialized population will be very similar.\n\u2022 E5: The size of the population falls significantly short of meeting the requirements.\nExample: We input the entire population consisting of 30 solutions into LLMs but only receive 10\nsolutions as output.\nImpact: The drastic reduction in population size will severely affect the diversity of the population. The\npopulation size may be restored to the predefined number but the diversity remains poor as there will be a\nlot of repetitive solutions.\n\u2022 E6: The selected population contains one solution too many times.\nExample: We input a set of solution IDs and wish to filter those low-fitness solutions. However, LLMs\nmay occasionally produce repetitive IDs for numerous identical high-fitness solutions.\nImpact: Although the low-fitness solutions are filtered, over-selecting a single solution damages the\ndiversity of the population.\n\u2022 E7: Any solution appears in the population where all elements are the same.\nExample: LLMs sometimes return several solutions like [A1, A1, A1, A1] but the constraint is that no\nrepetitive element is allowed within the same solution.\nImpact: When this kind of error occurs, we discovered that the number of erroneous solutions in the\npopulation is not a few but a lot. After several rounds of crossover, all solutions of the entire population\nwill be polluted, resulting in poor diversity.\n\u2022 E8: The number of different elements in the population changes significantly.\nExample: When we input a population containing 50 different elements, LLMs sometimes will output a\npopulation containing only 20 elements.\nImpact: The drastic reduction in the number of different elements will severely affect the diversity of the\npopulation.\n\u2022 E9: The number of different solutions in the population changes significantly.\nExample: This error is similar to E6 that occurs during selection, whereas this error occurs during\nreproduction. When we input a population consisting of 30 various solutions to LLMs, the output LLMs\nmay also contain 30 solutions but most of which may be identical.\nImpact: The drastic reduction in the number of different solutions will severely affect the diversity of the\npopulation."}, {"title": "Moderate Error", "content": "The moderate errors have a high chance of being repaired during the optimization thus they will not yield severe impact.\n\u2022 E10: The size of some solutions fails to meet the requirement.\nExample: When we input a solution consisting of 10 elements to LLMs for reproduction, the output may\nhave 9 or 11 elements.\n\u2022 E11: The solution (population) after the operation remains the same as before.\nExample: When we input a solution (population) to LLMs for reproduction, the output remains un-\nchanged. For example, the solution [A1, A2, A3, A4] is still [A1, A2, A3, A4] after mutation.\n\u2022 E12: The size of the population fails to meet the requirement.\nExample: When we input a population consisting of 30 solutions for reproduction, LLMs may output a\npopulation containing 28, 29, 31, or 32 solutions.\n\u2022 E13: The new solution contains duplicated elements.\nExample: The issue resembles E7, but is less severe and involves only 2 or 3 identical elements in the\noutput solution.\n\u2022 E14: The new solution contains invalid elements not found in candidate nodes.\nExample: Suppose we have 100 elements and filter the 50 as candidates, the LLMs sometimes output a\nsolution containing the element in the other 50. We found that LLMs did not produce elements outside\nthese 100, thus we categorize this error as moderate.\n\u2022 E15: The selected population contains those with very low fitness.\nExample: This error is like E11 but this is for selection. When we input a list of solutions to LLMs for\nselection, their output will be the same as what we input before."}, {"title": "Optimization problem formulation", "content": "The broad utility of evolutionary optimization for tackling discrete, non-linear problems has led to their extensive\nadoption in combinatorial challenges [44, 45]. In this study, we use the problem of influence maximization that is\nextensively explored by the evolutionary computation community as illustration [46, 47, 48] due to its generalization in\nsolution representation.\nGiven a graph G = (V, E), where V represents the set of nodes and E represents the set of edges, the objective is to find\na subset of nodes S\u2286 V that maximizes the influence across the network. Let \\{C1, C2,..., Ck\\} be the communities\npartition. For each community Ci, we can evaluate the influence of seed node set S by calculating the intersection of\ntheir influenced nodes I(S) with the nodes in Ci as follows:\n$I_i(S) = |I(S) \\cap C_i|$,\nwhere I(S) refers to the function that simulates the spread of influence from the initial set S.\nThe weight of each community wi is proportional to its size relative to the network. The fitness function F(S) is then\ncalculated as the weighted sum of the influences within each community, i.e.,\n$f(S) = \\sum_{i=1}^{k} \\frac{|C_i|}{|V|} |I(S) \\cap C_i|,$"}, {"title": "More details of LLM-based EVO", "content": "The four components, initialization, selection, crossover, and mutation are all achieved by LLMs in this work. The\npseudocode of population- and individual-level LLM-based EVO is shown in Algorithms 1 and 2 respectively. The key\ndifference is in line 7 of Algorithm 2, where solutions from the population are iteratively selected for reproduction,\nunlike in population-level optimization, which does not require this step.\nFor the process of validation and repair, please refer to Algorithm 3. In each stage, the output of LLMs will undergo the\ncorresponding check and repair (if any). For the checklist of each stage, please refer to Table 2 of the main text."}, {"title": "Experimental settings and dataset", "content": "We investigated using the population as the fundamental optimization unit, where all solutions undergo crossover and\nmutation. To fairly compare the population and individual-level optimization by LLM, we thus set the crossover and\nmutation rate to 1.0 for individual-level optimization. The ablation study employs GPT-40, with initialization and"}, {"title": "Prompt engineering of LLM-based EVO", "content": "The prompt has four parts. To generalize it for other combinatorial problems, we can replace 'node' in the prompt with\nxx, where xx depends on the"}]}