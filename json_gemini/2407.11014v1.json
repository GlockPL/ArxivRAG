{"title": "Geode: A Zero-shot Geospatial Question-Answering Agent with Explicit Reasoning and Precise Spatio-Temporal Retrieval", "authors": ["Devashish V. Gupta", "Azeez S. Ishaqui", "Divya Kiran Kadiyala"], "abstract": "Large language models (LLMs) have shown promising results in learning and contextualizing information from different forms of data. Recent advancements in foundational models, particularly those employing self-attention mechanisms, have significantly enhanced our ability to comprehend the semantics of diverse data types. One such area that could highly benefit from multi-modality is in understanding geospatial data, which inherently has multiple modalities. However, current Natural Language Processing (NLP) mechanisms struggle to effectively address geospatial queries. Existing pre-trained LLMs are inadequately equipped to meet the unique demands of geospatial data, lacking the ability to retrieve precise spatio-temporal data in real-time, thus leading to significantly reduced accuracy in answering complex geospatial queries. To address these limitations, we introduce Geode-a pioneering system designed to tackle zero-shot geospatial question-answering tasks with high precision using spatio-temporal data retrieval. Our approach represents a significant improvement in addressing the limitations of current LLM models, demonstrating remarkable improvement in geospatial question-answering abilities compared to existing state-of-the-art pre-trained models.", "sections": [{"title": "1 Introduction", "content": "Advancements in Large Language Models (LLMs) have ushered a new age of unprecedented improvement in text analysis, classification, and completion. Especially with the self-attention mechanisms [23], parsing and contextualization of text based prompts has led to the rise of automated chat-bots and Question-Answering (QA) agents, such as chatGPT which can answer the user questions to a high degree of precision. In addition to text based capabilities, LLMs are advancing to interact and learn from other forms of data such as images, video, and audio paving the way for Large Multi-modal Models (LMMs) such as Gemini [5].\nOwing to the recent and rapid development of Large Language Models (LLMs), developing a Large Geospatial Model (LGM) has become an important and tractable goal. These models leverage spatial information, integrating various data types such as satellite imagery, GIS (Geographic Information Systems) data, and environmental readings. The end goal using this data is to understand and predict patterns, trends, and relationships within geographical contexts.\nIBM and NASA recently released a geospatial foundation model called Prithvi [13] that can achieve zero-shot multi-temporal cloud gap imputation, flood mapping, and wildfire scar segmentation. Researchers have also explored contrastive spatial pretraining paradigms like CLIP [20], for geospatial visual representations with promising results. However, due to a variety of modalities with different semantics and evolution dynamics, developing unified representations of geospatial data has been a challenge computationally and logistically. Additionally, language-guided interaction with geospatial data and spatio-temporal reasoning is a relatively unexplored area.\nAlthough, pre-trained LLMs are repositories of extensive geospatial knowledge, yet unlocking this wealth presents a nuanced technical challenge. While conventional methodologies rely on leveraging geographic coordinates, such as latitude and longitude, to pinpoint specific locations, the crux lies in the LLMs' capacity to comprehensively grasp and interpret these numerical representations within real-world contexts. Furthermore, this challenge escalates when queries necessitate accessing real-time or spatio-temporal datasets, such as meteorological records, which may surpass the LLM's capability to interact with and extract requisite information.\nTherefore, it is essential to develop a system that can integrate geospatial data and effectively address user inquiries demanding intricate coordination between the LLM and multiple data sources across diverse geospatial modalities. Moreover, this system must also have the ability to retrieve spatio-temporal data accurately from necessary sources, enabling the sophisticated analysis and execution of complex geospatial tasks. In this context, we propose Geode-a methodology and LLM system designed to perform zero-shot Question-Answering (QA) with explicit reasoning capabilities for complex geospatial queries, coupled with precise spatio-temporal data retrieval from open-source geospatial data sources.\nIn summary, we make the following contributions:\n\u2022 Build a multimodal, zero-shot capable, proof-of-concept Question-Answering agent (QA) with precise temporal and spatial retrieval, using open-source geospatial data.\n\u2022 Develop various functional, model, and database experts for LLM to interact with diverse geospatial data modalities.\n\u2022 Implement the methodology with a streamlined tool chain and showcase its ability in reasoning over complex user queries to perform spatio-temporal geospatial tasks.\nIn this work we begin with a limited set of diverse geospatial modalities like topography and meteorological data to demonstrate the capabilities of our methodology."}, {"title": "2 Background and Related work", "content": "Geographical Information Systems (GIS) integrate and analyze diverse geospatial data to generate digital thematic maps through computational techniques [14]. GIS leverages fundamental principles of geography, cartography, and Geode, empowering end-users to formulate queries, analyze spatial information, visualize data in maps, and present the final results as detailed thematic digital maps (e.g., Clarke [4]; Maliene et al. [16]). The data handled by GIS systems encompasses a vast array of modalities, including vector and raster data formats, geodatabases, hyperspectral and multispectral data, and unstructured data. Notable examples of such systems include GeoSpark [27], geoMesa [11, 12], GeoTrellis [3], and RasterFrames [2]. These systems are typically employed to perform complex distributed processing on massive volumes of geospatial data across large clusters of high-performance computing systems, providing mission-critical insights for environmental protection, climate prediction, commerce, defense, and numerous other domains. However, these systems lack the ability to perform Natural Language Processing (NLP) tasks to address geospatial queries effectively.\nPrior works in literature have focused on developing an LLM based interface to perform Natural Language Processing (NLP) tasks on Geospatial data. Mai et al. [15] showcased the practical applications of large language models (LLMs) in the geospatial domain which include tasks like recognizing fine-grained addresses, forecasting time-series data related to dementia records, and predicting urban functions. Zhang et al. [28] uses GeoGPT, an autonomous AI tool built upon GPT-3.5, designed to autonomously collect, process, and analyze geospatial data using only natural language instructions. However, both these works primarily utilized pre-trained LLMs without exploring the potential of fine-tuning these models to create a specialized foundation model tailored for geospatial applications.\nIn a separate study, Deng et al. (2023) developed K2, a language model specifically fine-tuned on a corpus of geoscience texts. This specialized model demonstrated remarkable performance on various natural language processing (NLP) tasks within the geoscience domain. However, the capabilities of K2 are still confined to common NLP tasks, such as question answering, text summarization, and text classification, limiting its applicability.\nIn contrast to the above works, a more recent approach taken in GeoLLM by Manvi et al. [17], employs an innovative method that can efficiently extract the vast trove of geospatial knowledge inherently embedded within LLMs by fine-tuning the LLMs on prompts carefully crafted with auxiliary map data obtained from open-source geospatial data repositories. Furthermore, by fine-tuning multiple LLMs, the authors of GeoLLM aim to quantify and rigorously assess the extent of geospatial knowledge encapsulated within these models. Additionally, they seek to evaluate the scalability assessment of this knowledge for a wide range of practical geospatial tasks, including population density prediction.\nDespite the fine-tuning with auxiliary map data, Ge-OLLM encounters limitations in tasks necessitating the retrieval of spatio-temporal data across varied modalities, sourced from both real-time and offline sources. For instance, answering a question related to the air quality in a specific geographical location requires an ability to access and extract the real-time information, which potentially limits the ability of LLM to reason about complex queries on geospatial data. Moreover, the zero-shot reasoning and complex mathematical computations (such as finding standard deviation) of LLMs are poor despite providing extensive prompting.\nIn response, with Geode, we aim to bridge the shortcomings by providing the LLM the capability to interact and retrive real-time data from diverse data modalities to complete the required tasks. In addition, the LLM is capable of performing complex reasoning and provide a more accurate answers to the geospatial queries."}, {"title": "3 Methodology", "content": "Geode is a system designed to answer geospatial user queries that may involve multiple modalities and require complex reasoning. We identified a set of key insights that informed the design of Geode as a system. We observe that the zero-shot reasoning and mathematical computation capabilities of LLMs are poor [19, 25, 29]. This can be improved to some extent with special prompting techniques like few-shot, chain-of-thought [24] and tree-of-thought prompting [26]. This is the reason why we opted to leverage explicit geospatial experts to compute answers to narrow subsets of the geospatial query space. This also leads to high degree of compositionality and extensibility to the system, as with implementation of on only a few additional experts can enable the system to answer a whole new set of queries in query space. Additionally, since geospatial inference should not be only limited to retrieval, we unify ML inference, retrieval and explicit reasoning within Geode."}, {"title": "3.1 System Architecture", "content": "The architecture of Geode is partly inspired by ViperGPT [21], which is a system designed to answer simple visual queries on input images/videos based on a set of pretrained LLMs and VLMs as experts. ViperGPT relies on code generation to compose API calls that access the experts, followed by code execution to solve the given visual query. Its abilities include logical reasoning, ensuring consistency, mathematical operations, relations, negation etc. This paradigm of zero-shot code generation is a powerful way to leverage the knowledge of an LLM and augment it. However, ViperGPT can only perform visual inference and is not meant for geospatial question answering. Additionally, it only provides the final answer to the user along with code execution results to the user. This may be an output integer, float or a boolean value, which is not a great user experience.\nHowever, for geospatial inference, the results and computation often need to be visualized on a map and an textual explanation has to be given to the user to reveal the details on how the computation was done. This also improves the user experience for users who are not familiar with interpreting code. Keeping these aspects in mind, we built support for textual and map visualization for query computations within Geode. Let us now look at the full architecture (Figure 2).\nOn a high-level, we have a geospatial expert pool that hosts all the geospatial experts which may be predictive ML models, geospatial databases and functional utilities. This expert pool is the heart of Geode, where all the geospatial and modality specific computation is performed. The experts in the expert pool can be interacted with, using an expert API, which acts like an interface layer between the user and the expert pool. The expert API is decomposed into two parts namely the API specification and the full implementation.\nIn a similar fashion as ViperGPT, code generation is leveraged to understand and compose expert API calls in order to solve the user query. To provide the context and knowledge about the functionality available within the expert pool to the code generation model, we combine the API specification with the user query strategically to construct a prompt. The generated code is then executed in an execution environment finally generating a textual answer and salient artifacts for map visualization. The salience of artifacts is left up to the code generation LLM to determine. Let us examine each component of the system in a mode detailed fashion in the following section."}, {"title": "4 Implementation", "content": "As introduced previously, the geospatial expert pool is the heart of the system where all of the geospatial processing happens. Within this pool we built four major types of experts namely,\n\u2022 Retrieval Augmented Experts: These are language models, that have retrieval augmentation with geospatial data. This helps with reducing the occurrence of hallucinations and improve reliability of generated outputs.\n\u2022 Model Experts: These are ML models, specializing in a particular geospatial task like rain prediction, traffic flow prediction. These models do not require any retrieval augmentation since they are only good at one geospatial task.\n\u2022 Database Experts: These are geospatial databases with associated retrievers, access to data like realtime and historical weather, census, geography, nomenclature etc. This expert type allows for perfect retrieval, both spatial and temporal.\n\u2022 Functional Experts: These are utilities that may perform mathematical, analytical, geometric computations, which are not suitable for either ML inference or retrieval. For example, solving a differential equation, computing the vector intersection between multiple patches etc.\nHere is the list of all the experts we implemented as part of the geospatial expert pool within Geode.\n1. point_location_expert: Retrieves the point location or latitude and longitude of any place/address on Earth by its name.\n2. patch_location_expert: Retrieves the patch location of any place/address on Earth by its name, including its boundary polygon(s) and bounding box.\n3. imputation_expert: Performs nearest neighbour data imputation on the raster data of any input GeoPatch. Useful for scenarios where data is not available for a particular location, but an estimate is needed for some downstream computation.\n4. correlation_expert: Computes the cross-correlation between the raster data of two input GeoPatch's\n5. data_to_text_expert: Converts any python variable input into a human readable string format.\n6. threshold_expert: Performs relative or absolute thresholding of the raster data within a GeoPatch, based on mode (greater/less).\n7. intersection_expert: Performs either vector or raster intersection of data within the input geospatial patches. This also includes any data markers present within the vector_data of the patches.\n8. humidity_expert: Retrieves percent humidity values throughout any geographical patch as raster data, or at the central location of a patch based on mode (patch/point)\n9. precipitation_expert: Retrieves precipitation values (in mm) throughout any geographical patch as raster data, or at the central location of a patch based on mode (patch/point)\n10. temperature_expert: Retrieves temperature values (in Celcius) throughout any geographical patch as raster data, or at the central location of a patch based on mode.\n11. air_quality_expert: Retrieves a particular air quality parameter throughout a geographical patch as raster data, or at the central location of a patch based on mode. We support air quality parameters including, carbon monoxide, sulphur dioxide, nitrous oxide, ozone, PM2.5, PM10 and US EPA Index.\n12. elevation_expert: Retrieves elevation values throughout a geographical patch as raster data, or at the central location of a patch based on mode.\n13. elaborate_expert: Generates a elaborated textual answer based on the user query, computed final answer and any intermediate results as context.\n14. patch_visualization_expert: Visualize the vector and raster data in any patch and create an appropriate map visualization of the GeoPatch, no matter what it stores or represents.\nWe implemented this basic set of experts as a proof-of-concept, while additional functionality may be introduced easily by implementing additional experts with no changes to the overall system. For geocoding capabilities, especially within point and patch location experts, we leveraged Nominatim from geopy. For the weather experts, we availed WeatherAPI.com API for real-time weather data. For elevation data, we leveraged OpenMeteo elevation API. Many data modalities such as air quality and elevation are sparsely available globally, due to their dependence on meterological stations. To obtain a continuous estimate of the raster data parameter, we utilize bulk queries of the data at randomly sampled locations in a geospatial patch, followed by RBF kernel regression for building a smooth and continuous estimate of the raster data.\nHaving referenced the keyword GeoPatch multiple times, let us now look into what it is and what it represents."}, {"title": "5 Evaluation", "content": "Our evaluation approach includes several different queries which test the capability of Geode to perform QA which requires retrieval and augmentation of spatio-temporal data. While Geode is able to deliver zero-shot responses for the easier queries, the more complex ones may require more prompting and elaboration on particular prompt aspects. We will be using the publicly available GIS datasets [10] to train and evaluate our proposed model."}, {"title": "5.1 Evaluation Approach", "content": "The evaluation process will involve a diverse range of user prompts, ranging from simple queries like \"Where does it rain more, Atlanta or Chicago?\" to more complex tasks with detailed instructions, such as \"Find the highest peak in Telengana\" These tasks necessitate the integration of various data modalities and the ability to associate events with specific times, setting this model apart from existing multi-modal models in its unique approach to handling intricate, time-sensitive geospatial queries.\nThe real-time retrieval capability of Geode is a crucial aspect of its evaluation. By leveraging live data streams, the model can provide up-to-date and accurate responses to user queries. For instance, when a user asks about the current air quality index in a specific location, the model will retrieve the most recent data from relevant sources and incorporate it into its response. Similarly, when asked about current precipitation levels, the model will access live weather data to provide an accurate answer. This real-time retrieval feature ensures that the model's responses are not only relevant but also reflective of the current conditions at the time of the query.\nIn addition to real-time retrieval, Geode model employs various expert components that specialize in extracting information from specific data modalities. These experts are designed to handle the unique characteristics and dynamics of each data type from raster data to JSON, enabling the model to provide comprehensive and accurate responses. For example, an expert focused on altitudes can identify hills and valleys across any region, while another expert specializing in climate data can predict weather patterns and trends. The evaluation process will assess the performance of these individual experts in their respective domains and their ability to contribute to the overall question-answering capability of Geode model.\nTo measure the effectiveness of our Geode model, we will employ a range of evaluation metrics that are embedded within the real-time retrieval and expert extraction processes. These metrics will be continuously monitored and analyzed throughout the evaluation period to provide a comprehensive assessment of the model's performance. Some of the key metrics we will consider include:\nResponse Latency: Given the real-time nature of Geode model, it is essential to evaluate its response latency. We will measure the time taken by the model to retrieve relevant data, process the query through the appropriate experts, and generate a response. Lower response latencies are desirable to ensure a smooth and efficient user experience.\nData Freshness: as Geode model relies on live data streams, we will assess the freshness of the data used in its responses. This metric will measure how up-to-date the information provided by the model is compared to the actual real-world conditions. Higher data freshness scores indicate that the model is effectively leveraging the most recent data available.\nExpert Performance: We will evaluate the performance of individual expert components in their respective domains. This evaluation will involve measuring the accuracy, completeness, and relevance of the information extracted by each expert. For example, we will assess the air quality index expert's ability to accurately report current air quality levels in green areas and the precipitation expert's accuracy in providing current rainfall data.\nCode Completion: To gauge the overall effectiveness of Geode model, we must run generated code and measure the results of the visual output with the model's responses. This visual incorporation will provide valuable insights into the model's robustness, relevance, and ability to properly query.\nBy incorporating these embedded evaluation metrics and continuously monitoring the model's performance in real-time with a visual code-completion mechanism, we can ensure a comprehensive and dynamic assessment of our Geode model's capabilities. This evaluation approach not only validates the model's effectiveness in answering geospatial queries but also highlights its unique strengths in leveraging real-time data retrieval and expert extraction to provide accurate and up-to-date responses."}, {"title": "5.2 Metrics of Success", "content": "The primary metric of success for Geode is its ability to accurately and efficiently answer user queries related to geospatial and temporal data for specified locations. We will evaluate the model's performance using the generated code and accompanying visual outputs, which show the completeness of its responses as shown in Table 1. Additionally, we will consider the response latency, data freshness, and expert performance metrics to ensure that the model provides timely, up-to-date, and accurate information.\nIn addition to these primary metrics, we will also perform ablation studies to evaluate the model's robustness and adaptability. These studies will involve testing the model's performance with different datasets, cross-domain knowledge questions, and varying levels of data availability. For example, a query within this could be something like \"show me the correlation between precipitation and air quality in Bangladesh?\u201d By assessing the model's performance under diverse conditions with potentially limited data, we can identify its strengths, limitations, and areas for enhancement.\nOverall, the success of Geode is determined by its ability to effectively integrate multiple data modalities, leverage real-time data retrieval and expert extraction, and provide accurate, relevant, and timely responses to user queries. By continuously monitoring and evaluating the model's performance using the aforementioned metrics, we aim to develop a robust and reliable geospatial question-answering agent that can serve as a valuable tool for a wide range of users and applications."}, {"title": "6 Discussion", "content": "The development of Geode is a significant step forward in the field of geospatial question-answering. By leveraging real-time data retrieval, expert extraction, and multi-modal data integration, our model demonstrates the potential to revolutionize how users interact with and derive insights from geospatial data. One of the key strengths of our approach lies in its ability to provide accurate and up-to-date responses to user queries. The real-time retrieval capability ensures that the model always has access to live data, enabling it to generate responses that are up to date. This is particularly important in domains such as weather forecasting, air quality monitoring, and traffic management, where timely and accurate information is crucial for decision-making and public safety.\nMoreover, the incorporation of expert components specializing in different data modalities allows Geode to extract and analyze information from diverse sources effectively. By leveraging the unique characteristics and dynamics of each data type, these experts contribute to the model's ability to provide comprehensive and accurate responses. This modular approach also enables the model to adapt to new data sources and domains more easily, as additional experts can be developed and integrated as needed. The evaluation of Geode using a range of embedded metrics, including response latency, data freshness, expert performance, and code compilation provides a comprehensive assessment of its capabilities. The promising results obtained across these metrics demonstrate the model's effectiveness in answering geospatial queries accurately and efficiently.\nHowever, it is important to acknowledge the limitations and challenges associated with our approach. The reliance on real-time data retrieval introduces potential issues related to data availability, quality, and consistency. Ensuring the reliability and robustness of data sources is crucial for maintaining the model's performance and credibility. Additionally, the integration of multiple data modalities and experts requires careful coordination and synchronization to avoid conflicts and inconsistencies in the generated responses. Code compilation serves to be a challenge as well, while the model may be successfully integrating everything internally, truly harnessing this code that runs successfully and displays meaningful output adds an additional layer of complexity. Another challenge lies in the scalability and computational requirements of Geode. As the volume and complexity of geospatial data continue to grow, the model's ability to process and analyze this data efficiently becomes increasingly important increasing the response latency with more complex queries. Optimizing the model's architecture, data storage, and retrieval mechanisms will be essential for ensuring its practicality and applicability in real-world scenarios.\nDespite these challenges, the overall applications and impact of Geode are far-ranging. From urban planning and environmental monitoring to emergency response and resource management, the ability to interact with geospatial data using natural language queries, particularly a powerful LLM, can empower a wide range of users and organizations. By democratizing access to geospatial insights, our model can facilitate data-driven decision-making, promote transparency, and foster collaboration across different domains.\nFuture work on Geode shall focus on addressing the identified limitations and expanding its capabilities. This may involve exploring advanced data integration techniques, developing more efficient retrieval mechanisms, and develop further evaluation benchmarks to test the model's performance. We plan to also extend the model's application to new geospatial domains, like climate change analysis, biodiversity conservation, and public health data, to demonstrate its versatility and potential for impact."}, {"title": "7 Conclusion", "content": "Geode is a powerful advancement in the field of geospatial question-answering. Through leveraging real-time data retrieval, expert composition, and multi-modal data integration, the system demonstrates the potential to revolutionize how users interact with and derive insights from geospatial data. While challenges related to data quality, scalability, and computational requirements remain, the promising evaluation results and potential applications of our model highlight its value and impact. As we continue to refine and expand the capabilities of Geode, we envision a future where geospatial insights are accessible, actionable, and transformative for a wide range of users and domains."}, {"title": "Appendix", "content": "Base prompt\nThe base prompt consists of the GeoPatch and associated class specifications, expert API specifications, instructions on code generation and a template for the code to be generated so that the code execution results can be extracted and visualized.\n1 # API specification:\n2\n3 # helper classes\n4 class RasterType (Enum):\n5\n6 Enum representing the type of raster data stored in a patch.\n7\n8 color = 0\n9 non_color = 1\n10 binary = 2\n11\n12 class DataPoint():\n13\n14 Represents the data associated a particular point marker on the map.\n15\n16 Attributes\n17\n18 point (shapely.geometry. Point): Stores the latitude and longitude of the data point in x and y.\n19 name (str): Name of the point, displayed within the tooltip on the map\n20 data (float): Any numerical value which can represent quanities like temperature, humidity etc.\n21 , ,,\n22 def __init__(self, x, y, name: str, data: float = None):\n23 self.point = Point(x, y)\n24 self.name = name\n25 self.data = data\n26\n27 # main class\n28 class GeoPatch():\n29\n30 Primary class representing a geospatial patch with vector/raster data.\n31\n32 Attributes\n33\n34 raster_data: dict\n35\n36 Stores raster data and related information.\n37 'name' (str): Name of the raster data stored. (mandatory)\n38 'type' (RasterType): Type of raster data stored, whether RasterType.color, RasterType.non_color, or RasterType.binary (mandatory)\n39 'colormap' (str): String representing a colormap name. (optional)\n40 'data' (np.ndarray): NumPy array containing the raster data. (mandatory)\n41 vector_data: dict\n42\n43 Stores vector data and related information.\n44 'location' ( [float, float)): Latitude and longitude of the location that the patch represents (mandatory).\n45 'bbox' (List (float)): Bounding box coordinates of the boundary of the patch [ min_lat, max_lat, min_lon, max_lon] (mandatory)."}]}