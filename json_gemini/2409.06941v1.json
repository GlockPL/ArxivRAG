{"title": "FreeRide: Harvesting Bubbles in Pipeline Parallelism", "authors": ["Jiashu Zhang", "Zihan Pan", "Molly (Yiming) Xu", "Khuzaima Daudjee", "Sihang Liu"], "abstract": "The occurrence of bubbles in pipeline parallelism is an inherent limitation that can account for more than 40% of the large language model (LLM) training time and is one of the main reasons for the underutilization of GPU resources in LLM training. Harvesting these bubbles for GPU side tasks can increase resource utilization and reduce training costs but comes with challenges. First, because bubbles are discontinuous with various shapes, programming side tasks becomes difficult while requiring excessive engineering effort. Second, a side task can compete with pipeline training for GPU resources and incur significant overhead. To address these challenges, we propose FreeRide, a system designed to harvest bubbles in pipeline parallelism for side tasks. FreeRide provides programmers with interfaces to implement side tasks easily, manages bubbles and side tasks during pipeline training, and controls access to GPU resources by side tasks to reduce overhead. We demonstrate that FreeRide achieves 7.8% average cost savings with a negligible overhead of about 1% in training LLMs while serving model training, graph analytics, and image processing side tasks.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) are usually trained on GPUs. As these models continue to increase in size, their GPU memory requirements can easily outstrip the capacity of a single GPU [57, 65]. Consequently, to accommodate this increase in size and to boost the performance of pipeline training, it is a common practice to parallelize the training of LLMs across multiple GPUs distributed over several servers.\nPipeline parallelism is a prevalent training paradigm for LLMs using multiple GPUs. In this paradigm, the model is divided into multiple stages, each consisting of several consecutive layers. These stages are distributed across different GPUs. During each training epoch, a batch of input data is split into multiple micro-batches. Each micro-batch undergoes a forward propagation (FP) and a backward propagation (BP). The FP and BP operations on different micro-batches are carried out in parallel by the pipeline training system at each stage. The pipeline training system schedules these operations in each epoch to train LLMs [10, 12, 18, 21, 26, 31, 35, 36, 48]."}, {"title": "Background and Motivation", "content": "In this section, we provide an overview of pipeline parallelism for training LLMs, bubbles in the pipeline, and motivation for utilizing the bubbles to execute generic workloads."}, {"title": "Pipeline Parallelism and Bubbles", "content": "Pipeline parallelism is a widely used paradigm for distributed training of LLMs that far exceed the memory capacity of a single GPU [48, 52, 65]. In pipeline parallelism, the model is divided into multiple stages, where each stage executes several consecutive layers of the model. These stages are deployed across different GPUs to form a pipeline. To parallelize the computation at each stage and reduce GPU memory consumption, one batch of input data is split into micro-batches during each training epoch. Each micro-batch undergoes forward propagation (FP) and backward propagation (BP). In both FP and BP operations, after a stage finishes processing one micro-batch of data, it passes its output to the next stage and immediately moves on to the next micro-batch. The FP and BP operations constitute the epochs in pipeline training systems [10, 12, 18, 21, 26, 31, 35, 36, 48]. A myriad of frameworks have been developed to support pipeline training. For example, DeepSpeed [48] and Megatron [51] are extensively used to train various LLMs such as OPT [65], Turing-NLG [49], and MT-NLG [52].\nThere are periods in pipeline training when the estimated GPU streaming multiprocessor (SM) occupancy is low, as depicted by the green curves in Figure 1(a). We refer to these periods as bubbles in the pipeline, marked as shaded areas. Bubbles inherently exist in pipeline parallelism and occur repetitively throughout training, as they are fundamentally caused by unsatisfied dependencies between FP and BP operations [26, 31]. In the example of Figure 1, Stage 1 must wait for input from Stage 0 before it can execute its first FP operation, creating a bubble in Stage 1 that starts from t + 0."}, {"title": "Bubble Characterization", "content": "To study bubbles in pipeline parallelism, we train a 3.6B-parameter LLM adapted from previous work [6, 20] using DeepSpeed [48] on a 4-GPU server (detailed setup in Section 6.1). The training is deployed as a 4-stage pipeline, and each stage takes one GPU as shown in Figure 1. Overall, we observe that bubbles exhibit different characteristics across all 4 stages. Next, we take a closer look at each type of bubble."}, {"title": "Bubble Categorization", "content": "We categorize the bubbles into 3 types based on their positions in the training pipeline and their causes.\n\u2022 Type-A bubbles appear at the start and end of each epoch in all stages except for the first stage. They are due to cascading dependencies between operations at the start and end of an epoch. When an epoch starts, the FP operations start at Stage 0, while all other stages wait for input data from their preceding stages to start their first FP operation. Likewise, at the end of an epoch, the last BP operation starts at Stage 3 and all other stages wait for their succeeding stages to start their last BP operation.\n\u2022 Type-B bubbles occur in the middle of each epoch on all stages except the last one. They are caused by dependencies between interleaved FP and BP operations. Once the first FP operation reaches the last stage, all previous stages must wait for the corresponding BP operation before they can proceed with other operations, which causes Type-B bubbles.\n\u2022 Type-C bubbles also occur in the middle of each epoch. Since BP operations typically take longer than FP operations [69], interleaved yet unaligned FP and BP operations create bubbles in each stage except the last. For instance, in Figure 1(a), when Stage 2 finishes its third BP operation, it must wait for input to its fourth BP operation, which is still being processed in Stage 3, causing a type-C bubble. Duration. In our training setup, the duration of a bubble ranges from 0.22 to 1.04 seconds, depending on its type and stage. The duration increases for Type-A bubbles but decreases for Type-B bubbles from Stage 0 to Stage 3. This is because of the cascading dependency from Stage 3 to Stage 0 for Type-A bubbles and from Stage 0 to Stage 3 for Type-B bubbles. For example, a Type-B bubble at Stage 2 is due to an unfinished BP operation at Stage 3, with the same bubble at Stage 1 caused by Stage 2. The accumulated time to satisfy dependencies elongates Type-A or Type-B bubbles at later stages. However, Type-C bubbles are caused by unaligned FP and BP operations. Therefore, they have a short duration and do not exhibit the same stage-dependent variations. Available GPU Memory. Determined by the stage, the available GPU memory of a bubble ranges from less than 3 GB to more than 20 GB in our setup. As shown by Figure 1(b), within a stage, the GPU memory consumption of pipeline training remains the same. Thus, the bubbles within the same stage have the same amount of available GPU memory. Because the later stages consume less GPU memory to store"}, {"title": "Bubble Rate", "content": "Besides the bubble shape, we evaluate the overall bubble rate, i.e., the total bubble time over pipeline training time. When the model size increases from 1.2B to 6B parameters, as shown in Figure 2(b), both the per-epoch time in pipeline training and the total per-stage bubble time decrease. Therefore, the bubble rate drops only slightly from 42.4% to 40.4%. We also evaluate a larger micro-batch number, i.e., an increase from 4 (used in Figures 1 and 2) to 8. The bubble rate drops to 26.2% as each epoch takes longer.\nPrior work has focused on reducing bubbles in pipeline parallelism. One approach is designing different ways of"}, {"title": "Utilizing Bubbles", "content": "The difficulties in mitigating bubbles in pipeline parallelism motivate an alternative approach \u2013 acknowledging their existence and leveraging their resources by allocating additional GPU workloads to them. Prior work has utilized bubbles to run procedures that enhance pipeline training. For example, Bamboo uses bubbles to perform redundant computation for successive layers to improve the reliability of pipeline training on spot instances [56]; PipeFisher computes second-order optimization based on the Fisher information matrix to speed up convergence [42]. However, they tightly couple the pipeline training system with the specialized procedures. Implementing the specialized procedures is complicated, especially since such customization should consider various bubble shapes with durations ranging from 0.22 to 1.04 seconds, and available GPU memory from less than 3 GB to more than 20 GB on each GPU (Section 2.2).\nGPUs used for training are generally compute-rich, with sufficient GPU memory available during the bubbles to accommodate other GPU workloads. Therefore, bubbles can be used to run workloads that otherwise require dedicated GPUs. For instance, training a ResNet18 model with batch size 64 takes only 2.63 GB of GPU memory with each iteration taking only 30.4 ms on our platform \u2013 small enough to fit into most of the bubbles in Figure 1(a). By doing so, the resources available in bubbles present prime opportunities for serving GPU workloads, which can amortize the expensive cost of LLM training with effective GPU workload execution. We refer to these GPU workloads served during bubbles as side tasks. Prior solutions that target specialized co-running procedures [42, 56] do not apply to generic workloads.\nIn this work, we aim to make bubble resources available to generic workloads, allowing for a programmable and efficient use of bubbles."}, {"title": "Challenges", "content": "To execute generic GPU side tasks during bubbles, we identify two major challenges."}, {"title": "FreeRide Design Overview", "content": "FreeRide is our system that addresses the aforementioned challenges in utilizing bubbles in pipeline training to serve generic GPU side tasks. FreeRide minimizes the performance impact of side tasks on pipeline training. In this section, we present the design and high-level ideas of FreeRide."}, {"title": "Side Task Programming Interface", "content": "Given the high cost and priority of the main pipeline training workload, the side task should not overlap with this main task so as to avoid competing for GPU resources. This requirement is challenging from a programmer's perspective as it is difficult to tailor every workload to different bubble shapes. We observe that GPU workloads are not monolithic, rather, they can be often divided into small, repeated steps with largely predictable per-step duration. For example, epochs in model training, iterations in graph analytical workloads [23, 43, 61], and steps to process each image in image-processing workloads [37] all follow this pattern. On the other hand, bubbles also demonstrate repeating and predictable patterns, as discussed in Section 2.2.\nWith these observations in mind, our idea is to provide an iterative programming interface that supports the step-by-step execution of side tasks to fit bubble patterns - the side tasks can be naturally divided into smaller steps to fit into bubbles of different shapes. This interface employs a state machine abstraction for the life cycle of a side task composed"}, {"title": "Profiling-guided Side Task Management", "content": "As bubbles have different shapes, when a side task is newly added to FreeRide, it should be assigned to a stage whose bubbles have enough GPU memory available. When a side task is served during bubbles, there should be mechanisms that make sure the side task does not consume more resources than available by the bubbles to minimize the overhead of FreeRide, e.g., excessively allocating GPU memory or not pausing when a bubble ends.\nTo judiciously manage side tasks on bubbles, FreeRide leverages offline profiling to understand the shapes of bubbles. Then, when a side task is newly submitted to FreeRide, as shown in Figure 3, FreeRide's automated side task profiler tracks its GPU memory consumption and per-step duration. During execution time, FreeRide employs one side task manager and multiple side task workers, one for each GPU. The side task manager assigns the newly submitted side task to one of the side task workers which will create the side task process, based on the resulting profile. We instrument DeepSpeed to report the start timestamps and duration of bubbles to the side task manager that will initiate state transitions of each side task through remote procedure calls (RPCs) at the start and end of each bubble.\nFreeRide minimizes performance overhead on the main pipeline training workload by limiting the GPU resource consumed by side tasks (Section 4.5). For GPU memory, the side task worker of FreeRide leverages CUDA MPS [39] to impose a limit on GPU memory consumed by a side task process. For GPU execution time, FreeRide uses a twofold mechanism a program-directed mechanism through the programming interface, and a framework-enforced mechanism based on the side task manager and workers. In addition, the side task worker can deploy side task processes in Docker containers [4] for isolation."}, {"title": "FreeRide Workflow", "content": "Putting the aforementioned ideas together, we present the workflow of FreeRide in Figure 3. First, programmers adapt"}, {"title": "Implementation of FreeRide", "content": "In this section, we first introduce how FreeRide supports side tasks through its framework and interfaces. Then, we present details of FreeRide's profiling-guided side task management. Finally, we discuss FreeRide's GPU resource limit mechanisms including the implementation details."}, {"title": "Programming Framework of FreeRide", "content": "Figure 4(a) describes the programming framework of a side task. The framework's core is a state machine with five states and six state transitions. These five states capture the life"}, {"title": "Interface for Side Task Implementation", "content": "Given the FreeRide programming framework, the next step is to implement side tasks, which have two requirements. First, the programmer should be able to implement the side task in a way that can pause at the end of a bubble and resume at the start of the next bubble. Second, the side task should be able to communicate with the side task manager to receive state transition RPCs (Section 4.6) for pausing and resuming. To lift programming burdens, FreeRide provides two programming interfaces supported in C++ and Python. Once implemented using either interface, FreeRide will handle the side tasks and their state transitions transparently at runtime. We discuss both interfaces next.\nIterative programming interface. This is the preferred interface for side tasks in FreeRide. It periodically checks whether the side task manager has initiated any state transitions. If so, it executes the state transition functions in Figure 4(a) and updates the state of the side task. Then, if the side task is currently in the RUNNING state, it executes RunNextStep(). The programmer only has to override these transition functions to implement the side task. Pausing and resuming the side task, the transition of states, and communication with the FreeRide side task manager are all handled by the interface itself. GPU workloads that are naturally step-wise, e.g., model training, can be easily adapted to the iterative interface. We will discuss the adaption to the iterative interface in Section 5 using an example.\nImperative programming interface. Not all side tasks can be explicitly implemented step-wise. Therefore, FreeRide provides the imperative interface as a fallback solution. The core is the function RunGpuWorkload() that allows the programmer to implement generic GPU side tasks without breaking them into steps. When the side task manager transits the state of the side task to RUNNING for the first time, the interface calls the RunGpuWorkload() function to execute the side task. The interface implements the pausing and resuming through signals (SIGTSTP and SIGCONT [14]) and calls StartSideTask() and PauseSideTask() inside the handlers of the two signals. The imperative interface offers better versatility at the cost of higher performance overhead (discussed in Section 5 and evaluated in Section 6.2)."}, {"title": "Profiling Bubbles and Side Tasks", "content": "Bubbles. To know the shapes of bubbles, FreeRide runs DeepSpeed, monitors its estimated SM occupancy and GPU memory consumption through the PyTorch profiler [46], and automatically measures each bubble's duration and available"}, {"title": "Side Task Management", "content": "FreeRide's side task management has two main roles. First, upon receiving a new side task, the side task manager assigns it to a suitable side task worker. Second, when the pipeline training system adds bubbles to the side task manager, the side task manager initiates the state transitions of side tasks (Figure 4(a)) through RPCs. This way, the side tasks are only served during bubbles and do not compete for GPU resources with the main pipeline training workload.\nTo keep track of side tasks and workers, the side task manager maintains the following fields for each worker, used by Algorithms 1 and 2 for side task management:\n\u2022 GPUMem: the available GPU memory size.\n\u2022 TaskQueue: the queue of side tasks ordered by submission timestamps.\n\u2022 CurrentTask: the side task that is currently served.\n\u2022 CurrentBubble: the bubble that is currently valid.\nAlgorithm 1 describes how the side task manager assigns side tasks to workers. When the side task manager receives a new side task together with its GPU memory requirement (through profiling, Section 4.3), it first filters out all workers"}, {"title": "GPU Resource Limit", "content": "In this section, we introduce the mechanisms in FreeRide that reduce the impact of side tasks on the main pipeline training workload through side task resource control for both GPU memory and GPU execution time.\nGPU Memory. FreeRide leverages MPS to impose GPU memory limit on side tasks, i.e., when a worker creates a side task, it sets GPU memory limits using MPS. The side task process triggers an out-of-memory (OOM) error when its memory consumption exceeds the limit, but other processes remain unaffected. However, FreeRide is also compatible with other mechanisms for limiting GPU memory, e.g.,"}, {"title": "Implementation", "content": "We use DeepSpeed 0.12.2 [9] as the framework for pipeline training. We modify DeepSpeed in three places with 55 lines of code: (1) before the start and at the end of an epoch for Type-A bubbles, (2) after all FP operations preceding the first BP operation for Type-B bubbles, and (3) after the first BP operation following the last FP operation for Type-C bubbles. The instrumented code reports bubbles to the side task manager in FreeRide, as shown in step of Figure 3. The modifications are done once as the framework can be used for training different models.\nTo isolate the side task processes from the pipeline training process, FreeRide deploys workers (and side tasks of these workers) inside Docker containers, as illustrated in Figure 5. FreeRide implements the side task manager and each side task worker in separate processes. Communication among the pipeline training system, side tasks, and FreeRide components is facilitated through RPCs utilizing gRPC [16]."}, {"title": "Use of Side Tasks Interface", "content": "This section describes FreeRide's iterative interface and imperative interface in detail.\nIterative programming interface. Figure 6 is an example of implementing a side task to train ResNet18 using the iterative interface of FreeRide in Python. Less important"}, {"title": "Evaluation", "content": "In this section, we evaluate the benefits and overhead of using FreeRide to serve side tasks."}, {"title": "Methodology", "content": "We describe the experimental setup of our evaluation."}, {"title": "Server setup", "content": "We use a main server (Server-I) with four RTX 6000 Ada GPUs each with 48 GB of GPU memory to evaluate all pipeline training workloads and side tasks. We use a second server (Server-II) with an RTX 3080 GPU with 10 GB of memory to run side tasks separately. Due to the global shortage of cloud GPUs, we quote prices from a community cloud vendor [50] that has GPUs available. The prices of the two servers are $P_{Server-I} = $3.96/hour and $P_{Server-II} = $0.18/hour, respectively (as of June, 2024). The price differences between higher- and lower-tier GPUs in major cloud GPU platforms are similar [1, 2, 24]. We deploy both pipeline training and side tasks in Docker 26.1.2 [4]."}, {"title": "Comparison points", "content": "We evaluate FreeRide for side tasks developed with both the iterative and imperative interfaces. For comparison, we evaluate MPS [39], where we set pipeline training with the highest priority and side tasks with a lower priority. We also evaluate a naive co-location"}, {"title": "Pipeline training setup", "content": "We train nanoGPT [6, 20] with model sizes 1.2B, 3.6B, and 6B with DeepSpeed 0.12.2 [9] in a 4-stage pipeline on Server-II (stages 0-3 in Figure 1). We always maximize the micro-batch size (until just before OOM) to make full use of GPU memory during training."}, {"title": "Side task workloads", "content": "We implement 3 types of side tasks: model training, graph analytics, and image processing using both iterative and imperative interfaces of FreeRide. Model training side tasks include ResNet18, ResNet50, and VGG19. We use the out-of-the-box models from PyTorch [45] and implement the training procedure ourselves. Graph analytics side tasks are adapted from Gardenia [61]. It includes PageRank (PR) which is based on the PageRank algorithm [43] and Graph SGD (SGD) which uses stochastic gradient descent to solve matrix factorization [23], both using the Orkut dataset [62]. The image processing (Image) side task resizes an input image and adds a watermark, which we adapt from Nvidia's example [37]."}, {"title": "Metrics", "content": "We use the time increase $\\Delta T$ and cost savings $S$ in Dollars due to side tasks as metrics. Time increase describes the performance overhead of co-locating side tasks with the main pipeline training workload. It is defined as $\\Delta T = (T_{withSideTasks} - T_{noSideTask})/T_{noSideTask}$, the ratio of extra time of pipeline training with side tasks, compared with the original DeepSpeed without any side tasks.\nCost savings describe the benefits of running side tasks. Since we cannot directly compare the throughput of different side tasks and the main pipeline training workload, we use their cost (dollars spent on GPUs) as a proxy. First, we define the cost of pipeline training without side tasks as\n$C_{noSideTask} = P_{Server-I} \\times T_{noSideTask}$\nand the extra cost of pipeline training due to side tasks as\n$C_{extra} = \\Delta T \\times C_{noSideTask}$.\nThen, we compute the cost of side tasks as if each of them were executed on a dedicated lower-tier GPU as\n$C_{sideTasks} = \\sum_{Each\\, sideTask} P_{Server-II} \\times \\frac{W_{sideTask, Server-I}}{T_{h sideTask, Server-II}}$\nwhere $W_{sideTask, Server-I}$ is the work done by a side task on Server-I, e.g., the number of epochs for model training side tasks, the number of iterations for graph analytics side tasks, and the number of images for the image processing side task. $T_{h sideTask, Server-II}$ is the throughput of running the same side task on Server-II, which we measure by running side tasks individually on Server-II. Finally, we define cost savings $S$ below, where the higher the S value, the greater the benefit:\n$S = \\frac{C_{sideTasks} - C_{extra}}{C_{noSideTask}}$"}, {"title": "Performance Evaluation", "content": "We run DeepSpeed to train a 3.6B model for 128 epochs with side tasks from Section 6.1.4 and compare the performance overhead, i.e., time increase ($\\Delta T$) and cost savings ($S$) of using FreeRide with the two interfaces and the two comparative methods (as mentioned in Section 6.1.2). For model training side tasks, we set the batch size to 64. We run the same side task in all workers if they have enough GPU memory. We also run a mixed workload with 4 side tasks: PageRank, ResNet18, Image, and VGG19, each in one worker corresponding to the GPU of stages 0-3 in Section 6.1.3, respectively.\nThe results are summarized in Table 1. FreeRide consistently exhibits lower overhead than the comparative methods, showing only a 1.1% average time increase while achieving 7.8% average cost savings through side tasks using the iterative interface. The imperative interface achieves comparable cost savings but with a higher overhead as it relies on the less efficient framework-enforced mechanism to limit the side task's execution time (Section 4.5). In comparison, the average time increase and cost savings for MPS are 48.7% and -4.5%, and for Naive are 54.7% and -29.2%. Their negative cost savings indicate that these approaches can increase the total cost. Notably, the time increase of Graph SGD with MPS is as high as 231.0%. This anomaly is due to Graph SGD's high compute intensity. We conclude that FreeRide effectively utilizes bubbles in pipeline training for serving side tasks. While the comparative methods can utilize bubbles, unlike FreeRide, they are not designed for this purpose. Thus, they are inefficient in using bubbles, leading to higher costs."}, {"title": "Sensitivity Study", "content": "We change the side task batch size, DeepSpeed model size, and DeepSpeed micro-batch numbers of different side tasks, and study the time increase and cost savings of FreeRide with the iterative interface.\n(1) Varying batch sizes. Figure 7(a) includes model training side tasks under variable batch sizes. Other side tasks are not included as they do not run with batch sizes. OOM means that the GPU in Server-II does not have enough GPU memory for the configuration, so the cost savings cannot be calculated. FreeRide has low performance overheads, with around 1% increase in execution time, and cost savings of 3.4% \u2013 7.5%.\n(2) Varying model sizes. In Figure 7(b), the performance overheads of FreeRide range from -0.7% to 1.9%, and cost savings range from 1.8% to 22.2%. The main reason is the shorter bubble durations when training larger models as the main workload, which was also shown in Figure 2.\n(3) Varying micro-batch numbers. In Figure 7(c), the performance overhead of FreeRide increases from -0.4% to 1.5%, and cost savings reduces from 2.1% to 11.8%. When the micro-batch number increases, because of the lower bubble rate (Section 2.2), the cost savings decrease."}, {"title": "Effectiveness of GPU Resource Limit", "content": "We use training ResNet18 as an example to demonstrate the GPU resource limit mechanism in FreeRide.\nSide task execution time limit. Figure 8(a) demonstrates a case where the side task does not pause after the bubble that ends at t + 2. With GPU resource limit, as shown by the"}, {"title": "Bubble Time Breakdown", "content": "In Figure 9, we present a breakdown of bubble utilization in FreeRide under the iterative interface. No side task: OOM means that some bubbles are unused due to their limited available GPU memory. For instance, the GPU memory consumption of VGG19 or the Image side task is larger than the GPU memory of bubbles in stages 0 and 1, so they cannot use half of the bubble time. No side task: insufficient time refers to idle time because the remaining time of a bubble is not enough for the next step of the side task. FreeRide runtime is the time consumed by running FreeRide, including the interface code and the side task manager. Most of the bubble time with enough available GPU memory size is used by side tasks. For side tasks with shorter per-step durations, e.g., PageRank, the ratio of FreeRide runtime is higher because more iterations of the iterative interface are executed. In contrast, side tasks with longer per-step durations have lower bubble utilization because of insufficient time."}, {"title": "Related Work", "content": "Pipeline parallelism and bubbles. Prior research has aimed to improve the schedule of pipeline training to reduce bubbles [10, 12, 18, 21, 26, 31, 35, 36, 47, 48, 55], and to leverage bubbles in pipeline parallelism by assigning specialized procedures coupled with pipeline training to gain benefits [42, 56], as discussed in Section 2. In contrast, FreeRide does not require any changes to, or coupling with, pipeline training to serve generic GPU side tasks.\nGPU sharing. Previous work has enhanced GPU sharing through optimized GPU primitives [64], better scheduling of containers or VMs [58, 68], and tailored applications like training frameworks or model compilers [3, 17, 27, 30, 59, 60, 66]. Orion supports GPU sharing by intercepting and scheduling the CUDA kernel calls made by PyTorch[54]. However, Orion is agnostic of the bubbles in pipeline parallelism and"}, {"title": "Discussion", "content": "Security. Prior GPU sharing solutions tend to prioritize efficiency and assume a safe environment [17, 27, 59, 64, 66]. E.g., Orion assumes that the co-located GPU workloads are in the same trust domain [54]. FreeRide provides the same security and isolation guarantees as the lower-level system it is built upon. It uses MPS to limit GPU memory which provides separate GPU address spaces [40] for pipeline training and side tasks, and Docker for environment isolation [11, 63].\nOrthogonally, security for co-located GPU workloads is an active research area [22, 29, 33, 34, 44, 67]. We expect future work to co-design security with efficient GPU sharing.\nSide task management. By implementing different strategies in its side task manager, FreeRide can incorporate more complicated management, e.g., co-locating multiple side tasks with various performance characteristics to improve the utilization of bubbles [30] or serving side tasks with fairness or performance guarantees [5, 13].\nScalability. FreeRide can be extended for better scalability. As FreeRide implements the communications among its components using RPCs, it can be easily extended to distributed settings with side tasks on multiple servers. FreeRide can also be extended for multi-GPU side tasks, e.g., distributed training and big data processing [8, 28], by launching workers with access to multiple GPUs.\nOther ML accelerators. This work targets GPUs due to their widespread accessibility. FreeRide's mitigation for bubbles fundamentally applies to other ML accelerators [19, 32], provided that the platform has isolation and resource limit options for each process. We anticipate future work to incorporate the approach of FreeRide with other ML platforms."}, {"title": "Conclusion", "content": "We propose FreeRide, a system to harvest the bubbles in pipeline parallelism to serve generic GPU side tasks. It provides programming interfaces that abstract the life cycle of a side task as different states of a state machine and allows programmers to implement side tasks with little engineering effort. The side task manager and side task workers manage bubbles and side tasks and reduce the performance overhead of side tasks on pipeline training. Our evaluation shows that, on average, FreeRide achieves 7.8% cost savings for long-running, expensive, pipeline training with a negligible performance overhead of only about 1%."}]}