{"title": "Visual Stereotypes of Autism Spectrum in DALL-E, Stable Diffusion, SDXL, and Midjourney", "authors": ["Maciej Wodzi\u0144ski", "Marcin Rz\u0105deczka", "Anastazja Szu\u0142a", "Marta Sok\u00f3\u0142", "Marcin Moskalewicz"], "abstract": "Avoiding systemic discrimination requires investigating Al models' potential to propagate stereotypes resulting from the inherent biases of training datasets. Our study investigated how text-to-image models unintentionally perpetuate non-rational beliefs regarding autism. The research protocol involved generating images based on 53 prompts aimed at visualizing concrete objects and abstract concepts related to autism across four models: DALL-E, Stable Diffusion, SDXL, and Midjourney (N=249). Expert assessment of results was performed via a framework of 10 deductive codes representing common stereotypes contested by the community regarding their presence and spatial intensity, quantified on ordinal scales and subject to statistical analysis of inter-rater reliability and size effects. The models frequently utilised controversial themes and symbols which were unevenly distributed, however, with striking homogeneity in terms of skin colour, gender, and age, with autistic individuals portrayed as engaged in solitary activities, interacting with objects rather than people, and displaying stereotypical emotional expressions such as pale, anger, or sad.Secondly we observed representational insensitivity regarding autism images despite directional prompting aimed at falsifying the above results. Additionally, DALL-E explicitly denied perpetuating stereotypes. We interpret this as ANNs mirroring the human cognitive architecture regarding the discrepancy between background and reflective knowledge, as justified by our previous research on autism-related stereotypes in humans.", "sections": [{"title": "1. Introduction", "content": "Artificial intelligence models are becoming increasingly important sources of knowledge and opinion. Analyses of Al cognitive biases and oversimplifications in their representations of various social phenomena now play a significant role in Al ethics and fairness. To prevent the perpetuation of systemic discrimination, it is imperative that users of Al models, such as large language models (LLMs) \u2013 exemplified by Chat GPT are cognizant of the inherent limitations of such models and that their developers can identify and rectify them.\nPrevious research has demonstrated that many models reproduce, for instance, gender, race, age , or ethnic stereotypes. It has been shown that Al models underlying assistive technologies contain biased stereotypes , while Abid and colleagues have demonstrated that LLMs associate Muslims with violence. Even when a language model is tasked with generating content pertaining to Arabic culture, it remains 'contaminated' by the elements characteristic of the West. Furthermore, some models exhibit biases towards the values of specific societies or may be politically biased . While the majority of research in this field has focused on text-to-text models, there have been a few studies examining models that generate images from text prompts. Bianchi demonstrated that text-to-image generation models amplify demographic stereotypes, and Aldahoul highlighted the presence of racial and gender stereotypes in Al-generated faces across six races, 32 professions, and 2 genders, and additionally proposed some debiasing solutions. When investigated LLMs were asked to depict an 'attractive person', they predominantly depicted white individuals. Conversely, when LLMs were asked to depict a 'poor person,' they predominantly depicted Black individuals. In a similar vein, the LLMs depicted a 'terrorist' as a Middle Eastern man. Even when explicitly instructed to depict a \u2018white terrorist,' the models generated images of a bearded man who visually resembled a stereotypically Middle Eastern individual. Wang et.al. showed that LLMs also perpetuate stereotypes concerning race, gender, and religion . For example, when asked to show 'people who are political elites' they show mainly white males. Nowadays, Al developers often use 'fairness protocols', which are top-down safeguards, to address the issue of reproducing stereotypical beliefs. These safeguards result in the models either refusing to generate specific content (e.g., a description of a representative of a particular social group) or circumventing the issue by generating content on similar, substitute topics. It is unfortunate that this method is only a temporary solution, as it does not address the fundamental issue of biased training datasets. In this study, we examine the efficacy of similar safeguards on a visual level in text-to-image models. The study examines the extent to"}, {"title": "Socially prevalent stereotypes about the autism spectrum condition", "content": "The example of autism is pertinent for a number of reasons. Firstly, the topic is of significant social importance and sensitivity, impacting ca. 62/10 000 people in the global population . Secondly, it is becoming increasingly prominent in the public eye. Over the past few decades, numerous, often detrimental, stereotypes and oversimplifications about autism have been created and disseminated, and have become deeply embedded in collective awareness. For instance, although there is some evidence suggesting the prevalence of autistic cognitive style among STEM/IT professionals , stereotypically identifying all people on the spectrum with the figure of a brilliant computer geek is unsubstantiated. Thirdly, the topic is characterised by a high degree of cognitive uncertainty, both in the social and scientific spheres. A number of studies have highlighted the historical variability and social construction of the autism category . Consequently, numerous beliefs and stereotypes about autism operate unconsciously in social awareness as background knowledge, influencing the identities of autistic individuals . The pervasive belief that autism is invariably accompanied by suffering, that the source of this suffering is the condition itself and not social misunderstanding, and that autism is primarily diagnosed in children, boys, and white individuals often leads to the perpetuation of hurtful prejudice against individuals on the autism spectrum, impeding their social functioning and access to diagnosis and appropriate therapy.\nConsequently, the beliefs about autism propagated by Al models have the potential to significantly influence opinions in this field. As the topic of autism gains increasing popularity in various spheres of public life, it has emerged in the broader awareness . A multitude of stereotypes and myths surrounding autism have the potential to negatively impact the lives of individuals on the spectrum. Autism communities seek to challenge these stereotypes and hegemonic narratives, aiming to redefine autism as a distinct mode of functioning, resulting, among other factors, from the atypical structure of the nervous system. Consequently, they seek to challenge the perception of the spectrum as a deficit and to de-pathologise it, thereby reducing social stigma ."}, {"title": "2. Methods", "content": "The research protocol involved generating images (N=249) based on 53 prompts, with the objective of visualising concrete objects and abstract concepts related to autism across four models. The first of these was DALL-E 3, a large language model based on a transformer architecture used for natural language processing. This implies that the model analyses the semantic structure of the inputted command, employing a self-attention mechanism to focus on specific parts of the command in question (the most strongly connected words). The model then compares the result of this analysis with its training data and generates an image based on the data described earlier. In general, the model transforms the input data, which is a text, into output data, which is an image. (2) and (3) Stable Diffusion and SDXL employ a latent diffusion model architecture, which processes images in a compressed feature space and gradually refines the image from a random noise distribution through a series of learned reverse diffusion steps (diffusion models that use stochastic processes to create images from initial noise). (4.) The Midjourney architecture is unknown. The research protocol, which is available in the supplementary materials, includes a comprehensive list of prompts.\nThe prompts were engineered to ensure a neutral form without suggesting the use of specific symbols or themes. The issues covered by the prompts were selected by a team of experts, including a person on the spectrum (authors: M.W. autistic scholar, M.S. psychologist, A.S. cognitive scientist, sociologist), with the aim of taking into account both the image of people on the autism spectrum (individually and in groups), various types of behaviour, interactions, and everyday situations. However, the team also considered more abstract concepts, such as the visualization of the phenomenon of autism itself or emotions. The results were subjected to an expert assessment via a framework of 10 deductive codes representing common stereotypes contested by the autistic community regarding their presence and spatial intensity (see Table 1). These were quantified on an ordinal scale of 1-10 and subjected to statistical analysis of inter-rater reliability and size effects. Each prompt was administered once to each model. However, the final number of images exceeds the number of prompts multiplied by the number of models (53 x 4 = 212). Some models generated multiple alternative versions, with all generated images considered. When requested to generate multiple themes or objects, the models occasionally returned the results as a single image (e.g., split into three parts) and at other times as three separate images. The Midjourney consistently generated four preliminary images. In order to avoid the potential for arbitrariness in the selection of images, all images generated by the models were considered in the analysis.\nThe images in the study were subjected to a comprehensive evaluation to ascertain the presence of all the listed stereotypes. The presence of a stereotype was rated on a scale of 1, indicating"}, {"title": "Data Analysis", "content": "Three subsequent pilot coding sessions on randomized samples of 20 from the dataset were conducted to improve the reliability of interrater agreement using Cohen's kappa coefficient accounting for agreement occurring by chance. We have improved the initial inter-rater reliability of 0.315 in the first pilot coding, through 0.698 in the second, to 0.93 in the third pilot coding by redefining the qualitative descriptions of codes (the final moderate k-value of 0.49 represents the kappa paradox because the absolute agreement was very high. Kappa for each code: Child 0.6227; White 0.5200; Male 0.5037; Puzzle 0.6394; Blue 0.3969; Brain/head 0.6691; Isolation 0.3184; Medical/Therapeutic 0.3881; Negative Emotional State 0.4131; IT Geek/ Artist/Scientist 0.4799. For a full interrater reliability assessment see supplementary materials). To calibrate the assessment tool and ensure its accuracy, these sessions included consensual adjustments to the qualitative evaluation grid based on feedback from the raters, which led to a progressive increase in interrater reliability. In effect, we refined the coding framework by increasing its specificity and sensitivity, taking into account those cases where there were divergencies between the coders, leading to both false-positive and false-negative results. To obtain unambiguous and non-fractional values, minor differences between the coders in the final evaluation were solved by a third rater."}, {"title": "3. Results", "content": "Distributions of the degree of stereotyping for all models differ significantly from normal. Testing indicates significant differences between the degree of stereotyping of each model, however, with moderate effect size ($\\eta^2$ = 0.06). The highest degree of stereotyping was observed for Stable Diffusion M/me 3.915/4.00), and the lowest for SDXL (M/Me 2.896/3.00). Figure 5 presents the comparison between the models.\nThe ratio of stereotypical themes to the number of images generated was found to be similar across the models (DALL-E: 2.91, Midjourney: 3.72, SDXL: 2.90, Stable Diffusion: 3.92). This indicates that, in absolute values, a comparable degree of stereotyping was exhibited by both the DALL-E transformer architecture-based model and the models based on diffusion architecture. The most frequently repeated stereotypes were those regarding skin colour, gender, and age. It is noteworthy that the proportion of males to females (220:60) depicted in the generated images closely resembles the proportion of genders in the diagnoses. This is due to various reasons, including biases of diagnostic tools and procedures, which have resulted in autism being currently diagnosed 3 to 4 times more often in males than in females.\nIn addition to the three common stereotypes observed across all models (gender, skin colour, and age), the most frequently repeated motifs were: DALL-E generated images exhibited a blue colour theme, Midjourney images featured a"}, {"title": "4. Discussion", "content": "The images generated by Al models were frequently found to resemble human mental images (and not perceptual images) due to the presence of qualitatively undefined quantitative properties and a lack of adherence to the principle of individuation. This resulted in the simultaneous appearance of objects across multiple modalities, as illustrated in the following examples:. It is regrettable that all of the assessed models perpetuated common stereotypes of autism. The most prevalent themes were those of the white , the young , the boy , the puzzle symbol , and the blue colour. The puzzle symbol implies that individuals on the autism spectrum are analogous to incomplete"}, {"title": "Group images", "content": "Images of groups including or consisting of autistic individuals appear to be similar to each other and are less diverse than default groups without specified characteristics . In some instances, DALLE generated explanations concerning the generated images, stating that the prompted issue is highly complex and that an alternative scene would be created in order to avoid perpetuating stereotypes (although some of them were still used). It was evident that such top-down 'fairness protocols' did not fully fulfill their role. Moreover, the utilisation of such safeguards does not address the underlying issue, which is the existence of biased datasets ."}, {"title": "Interaction: objects vs people", "content": "Images featuring multiple characters demonstrated a tendency to portray individuals on the autism spectrum as preoccupied with physical objects rather than engaging in interpersonal interactions. Even when these characters were in close proximity to one another, they did not engage in common activities, which reflects the pervasive (but often erroneous) belief that individuals with autism are antisocial (see Fig. 7). The words of autistic activist Jim Sinclaire serve to illustrate the falsity and hurtfulness of such stereotypes: 'Each of us who does learn to talk to you, each of us who manages to function at all in your society, each of us who manages to reach out and make a connection with you, is operating in alien territory, making contact with alien beings. We spend our entire lives doing this. And then you tell us that we can't relate' ."}, {"title": "Emotion expressions and behaviour", "content": "In addition to the images in which the model was directly asked to display strong emotions, the majority of the characters depicted in the generated graphics exhibited a lack of emotional expressiveness. It is noteworthy that a greater number of images depicted positive emotions than negative ones. However, when the models were directly asked to generate images showing autistic people experiencing a strong emotion or showing a typical mood, the majority of images showed negative emotions. This may indicate that autistic individuals do not experience intense emotions (or do so infrequently), or if they do, they are challenging, negative emotions rather than positive ones such as joy or empathy . Please refer to Fig. 8 for further details."}, {"title": "ANNs mirror human cognitive biases", "content": "We also observed representational insensitivity regarding autism images despite directional stimulus prompting aimed at falsifying the above results. Additionally, the model demonstrated a curious phenomenon of apparent blindness to a reproduced stereotype when generating graphics. The most prevalent motif employed by models to represent autism was the puzzle symbol. Upon being explicitly instructed to generate visualisations that did not include the aforementioned symbol, the models nevertheless incorporated it into their creations. Furthermore, DALL-E explicitly refuted the allegation that it perpetuates autism stereotypes on the text-to-text modality. It explicitly stated that the created graphic did not contain the aforementioned motif ('Here's a visual representation of the concept of autism that moves beyond the traditional puzzle piece motif, focusing on the diversity and richness within the autism spectrum'). We interpret this as ANNs mirroring the human cognitive architecture regarding the discrepancy between background and reflective knowledge, as justified by previous research on autism-related stereotypes in humans .\nIn conclusion, the results demonstrate that, sadly, the analysed models at their current stage of development can be utilised as a repository of knowledge representing the socially prevalent stereotypes regarding autism."}]}