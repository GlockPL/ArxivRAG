{"title": "Artworks Reimagined: Exploring Human-Al Co-Creation through Body Prompting", "authors": ["Jonas Oppenlaender", "Johanna Silvennoinen", "Hannah Johnston", "Helena Barranha"], "abstract": "Image generation using generative artificial intelligence is a popular activity. However, it is almost exclusively performed in the privacy of an individual's home via typing on a keyboard. In this article, we explore body prompting as input for image generation. Body prompting extends interaction with generative AI beyond textual inputs to reconnect the creative act of image generation with the physical act of creating artworks. We implement this concept in an interactive art installation, Artworks Reimagined, designed to transform artworks via body prompting. We deployed the installation at an event with hundreds of visitors in a public and private setting. Our results from a sample of visitors (N = 79) show that body prompting was well-received and provides an engaging and fun experience. We identify three distinct patterns of embodied interaction with the generative AI and present insights into participants' experience of body prompting and AI co-creation. We provide valuable recommendations for practitioners seeking to design interactive generative Al experiences in museums, galleries, and other public cultural spaces.", "sections": [{"title": "1 Introduction", "content": "Image generation with artificial intelligence (AI) has gained popularity, with millions of practitioners exploring text-to-image generation systems for recreation and creative exploration [24, 36, 42, 59]. However, text-to-image generation is almost exclusively conducted in the privacy of an individual's home, and limited to typing on a computer keyboard. We argue the current focus of image generation on typing and discrete prompts by one solitary creator limits opportunities for engaging experiences, due to four key constraints of text-to-image generation: literacy, input control, social creativity, and the setting.\nLimited by literacy: Frequently regarded as an instrumentalist use of technology, text-to-image generation is a process in which Al is used as a tool to visually translate concepts or ideas [12]. For this translation to be effective, English literacy is required. Further, some image generators require the use of specific keywords to produce high-quality outputs [43], which demands expertise in \"prompt engineering\" [42-44, 46] and familiarity with art concepts, such as styles and media [43]. These language-based requirements exclude certain populations, such as the illiterate, young children, and all those who are not familiar with the English language.\nLimited input control and expressivity: The level of control over text-to-image generation is limited by language [35]. Prompt engineering is tedious and it is not possible to fully control text-to-image generation with discrete prompts [46], leaving much of the initial image generation to randomness [19]. In practice, the first generated image is often one step in a longer creative process that involves many tools, such as image editors, image-to-image generation, inpainting, and others [44, 49, 59]. ControlNet was a remarkable breakthrough technology [63], allowing fine-grained control over image generation via human poses and other input forms. A pose is a skeleton-like structure with key points that correspond to major joints and body parts. ControlNet gained widespread popularity among AI art practitioners. However, rarely do these poses originate from the practitioners' own bodies. Instead, poses are transferred from existing images, taken from openpose datasets, or created with tedious manual editing. In addition to questions about copyright [47, 57, 58], this \"raises issues of embodiment, materiality, and material agency that traditionally come into play when making a visual artwork\" [35].\nLimited collaboration and social creativity: Contemporary literature views creativity as a social activity [2, 15], with the concept of the lone creator being dispelled as a myth [32]. Yet, image production with generative AI is almost exclusively completed by a solitary creator. The social and performative aspects of art creation are lost due to the privacy of the image generation setting and the constrained text input modality. Collaborative websites, such as Artbreeder\u00b9, have demonstrated that collaborative image generation can be an engaging experience, with wide audience appeal.\nLimited suitability for public settings: Confined to the personal and narrow triangular interaction space between user, keyboard, and computer display, the practice of text-to-image generation does not lend itself well to public settings, such as Galleries, Libraries, Archives, and Museums (GLAM). For such public settings, input modalities should be dynamic and intuitive, offering glimpses of the generative process to the audience and building anticipation for the final image. Typing on a keyboard in front of a computer screen is not expressive, in this regard, and does not provide an engaging audience experience.\nAddressing these limitations could make image generation more inclusive and accessible to a wider audience [27]. Prior work aimed to break free from these four limitations by exploring audience participation in image generation in a museum context. Kun et al.'s interactive GenFrame allowed museum visitors to shape the image generation process via three knobs controlling different parameters"}, {"title": "2 Related Work", "content": "Image generation is predominantly performed via typing prompts on a keyboard in a private space. Therefore, in the vast majority of cases, prompting is \"an isolated and individual experience\" [33]. In this section, we focus on related work that sought to break free from this reigning interaction paradigm to develop new inputs and bring the activity of image generation into the public sphere. We first review research on interaction with public displays (Section 2.1), and then examine embodied experiences (Section 2.2) and generative Al in public installations (Section 2.4).\n2.1 Interaction with Public Displays\nPublic displays offer opportunities to study how users interact with technology. However, public displays bring unique challenges, such as display blindness [41], interaction blindness [22], and the first-click problem [29]. The latter arises when users are unsure how to initiate interaction with a public display. In this section, we focus on challenges related to the public setting of our study.\nPrivacy concerns require consideration. Brudy et al. identified 'shoulder surfing' \u2013 where unauthorized individuals may view sensitive information \u2013 as a pertinent risk associated with public displays [6]. Further exploring privacy issues, Memarovic examined how the public's concerns about photography in the vicinity of public displays influence user interaction [38]. Their study emphasized the importance of transparent policies regarding the storage and usage of photos taken in these contexts, highlighting a general need for clear communication about the handling of users' data. In a comparative study, Collier et al. addressed differences between private and public self-service technologies [13]. Their findings suggest that perceptions of control and convenience significantly vary depending on the setting, with public technologies often viewed as less controllable and convenient than their private counterparts [13]. This perception could influence user engagement and satisfaction with the public display in our study. Hosio et al. studied privacy in interactive public displays [1, 21]. They found that people are surprisingly willing to volunteer highly sensitive personal information in public settings.\nThese studies reveal a complex landscape of user behavior and expectations when interacting with displays in public spaces. Addressing these concerns is crucial for designing an interactive public installation.\n2.2 Interactive Experiences via Embodied Interaction\nEmbodied interaction can provide an engaging experience. This is particularly relevant in the context public cultural spaces, such as GLAM institutions. In museums, the contact with more traditional art forms, namely painting or sculpture, tends to occur passively through a cognitive engagement with the artworks. Digitally enriched museum experiences [8] open new opportunities to experience and interact with such artworks through embodied cognitive engagement via human-technology interaction. Gestures and posing are an engaging way of meaning making in the GLAM context [16, 60, 61]. In the remainder of this section, we review prior work on embodied interaction in the context of GLAM institutions and other public settings.\nTrajkova et al. explored engaging museum visitors with embodied interaction [62]. Their study was aimed at human-data interaction, enabling people to explore data sets and interactive visualizations with gestures and body movements.\nOppenlaender and Hosio presented a system for museum visitors to provide feedback for artworks, including selfie photos and selfie videos [45]. The latter was perceived as a surprising way of interacting with an artwork and its artist. Kozinets et al. also explored museum selfies [28], finding selfies to be a way to construct narratives about oneself. However, their study did not feature embodied interaction with dynamically generated artifacts in the museum context.\nPositive effects of interactive technological engagement with artworks have been reported. For example, aesthetic appreciation (including interest, intensity, pleasure, and learning) was higher in artworks with interactive elements compared to non-interactive physical objects [23]. In Coeckelbergh's framework, body prompting can be conceptualized as a performance-based approach to interaction and Al image generation [12]. Body prompting is a poietic performance within human-technology co-creation. The performance-based approach emphasizes the process of interaction in which novel artistic (quasi-)subjects and objects emerge and are produced in and by the processes instead of instruments and tools [12]."}, {"title": "3 Method", "content": "This section first provides background information on the public event that was the context for our study and our motivation and design goals for Artworks Reimagined. We then describe the study design and procedure, research materials, data collection and analysis, and technical implementation.\n3.1 Background and Design Goals\nThe European Researchers' Night is an annual event, which aims to interest the general public in research. It is one of the biggest science events in Finland, held at several universities nation-wide. The event gives the public the opportunity to discover the wonders of science in fun and inspiring ways. As a multidisciplinary event, Researchers' Night offers a wide range of activities from workshops to laboratories, presentations, and lectures. The event program caters to the general public, including visiting school groups and parents with children.\nOur study was born from our previous experience hosting an exhibit at the European Researchers' Night in 2022 [47, 48]. At the time, text-to-image generation was still a new phenomenon, and many visitors had not tried it before. The exhibition stand consisted of two laptops on which visitors could try out three text-to-image generation systems (Midjourney, Stable Diffusion, and DALL-E). One laptop was connected to a large public display. During this event, we observed that while interesting for the person writing the prompts, textual interaction with the image generation system was not very appealing for bystanders in a public audience, due to prompts being written in private. In the following year, we designed an interactive art installation to address this issue.\nThe design of our installation had three goals. First, we sought to overcome the limitations in engagement that we had observed in 2022 and provide a highly engaging experience for visitors of the local Researchers' Night event. Second, we aimed to allow visitors to reconfigure an existing artwork with an input modality other than typing. To this end, we selected posing (\"body prompting\") as input modality. Visitors would be able to reimagine an existing artwork by posing in front of a camera. Third, like a camera booth, the installation was designed to be easy to use and self-guiding, allowing its user to go through the steps necessary to take a selfie photo."}, {"title": "3.2 Artworks Reimagined", "content": "We created an interactive art installation, called Artworks Reimagined, that guides its users through four simple steps (depicted in Figure 1 and described in detail in Section 3.3). The physical setup of the installation is depicted in Figure 2. Divider walls were used to define four separate areas. The public posing stage allowed participants to select an artwork on the touch screen and pose in front of the camera. This setup was mirrored in the private camera booth which was cordoned off and protected from viewing with divider walls. Results from the public booth were viewed on a large screen controlled by a laptop, whereas results from the private booth were viewed in private on two laptops equipped with privacy screens.\nWe selected artwork images for the installation from two sources. The first source included paintings from the \"Golden Age of Finnish Art\" (circa 1880-1910). We identified artworks by visiting Wikipedia pages of prominent artists from that time period.\u00b2 The second source was a list of popular paintings on WikiArt.\u00b3 When selecting artworks, we avoided nudity and other depictions not appropriate for public viewing in the presence of children. This convenience sample of 60 artworks (29 from the Finnish Golden Age and 31 from WikiArt) represents a mix of well-known international masterpieces and artworks with a deep local context."}, {"title": "3.3 Study Design and Procedure", "content": "The aim of our study was to observe and understand how body prompting is used and experienced in the context of a public event. Therefore, the research was conducted \"in-the-wild\", focusing on observing participants in an environment outside of the controlled laboratory, without interference from researchers. The research was exploratory and participants were not given specific posing instructions.\nThe study procedure is summarized in Figure 1. Participants were invited to walk up to the public display. The first application screen consisted of a consent form informing the participants about the extent and use of the collected data. Participants were specifically informed that only an anonymous, stick figure-like pose would be collected, not the original photo. After providing consent by clicking a button, participants selected an artwork from the list by touching the screen. Next, participants were informed that a timer would count down from 10 seconds. After confirming this message, participants could see themselves on the screen and assume a pose while the timer counted down to zero. The posing was supported by showing the artwork for a brief moment before displaying the camera feed, and a small version of the artwork was additionally shown in the corner of the screen while posing. Participants were not given any instructions on what specific pose to assume and were completely free to deviate from the source artwork. Finally, participants were shown a short unique code from a curated list of Finnish and English words, generated with a language model, and informed to exit the booth in the final application screen. The short code was used to associate the subsequent interview data with the generated image.\nFollowing the interaction with the installation, one of five research assistants invited the participants to a semi-structured interview recorded using a mobile phone. The assistants showed the participant(s) the artwork and detected body prompt during the interview and recorded participant(s)' reactions and comments in response to seeing the generated artwork.\nThe study was conducted in accordance with the policies of the University of Jyv\u00e4skyl\u00e4's Institutional Review Board (IRB) and the Finnish National Board on Research Integrity (TENK). Children under the age of 18 were allowed to use the installation under the supervision of adults, but were excluded from the interviews. In this article, we only focus on the data collected from 79 adults who agreed to an interview."}, {"title": "3.4 Data Collection and Analysis", "content": "We developed an interview guide consisting of 12 questions. Besides basic demographics, the research assistants asked participants about their motivation for selecting the artwork, the body prompt, and the choice of private or public posing area. The interviewers also inquired how participants experienced body prompting and what they wanted to express with their body prompt. The structured questions were followed by open-ended follow-up questions (\"can you describe why?\"). A Likert-scale question captured how enjoyable the experience was for the participant (from 1 - Not At All Pleasant to 5 - Extremely Pleasant). The interview also included the ten-item questionnaire on key personality traits (commonly referred to as \"Big Five\u201d) [14].\nThe generated image was revealed on the screen at the end of the interview and participants were asked whether the image expressed their original intent, thus giving insights into co-creative aspects of body prompting, and any other thoughts about their body prompt and the generated image.\nThe interview data was transcribed using a text-to-speech service, translated from Finnish into English using Google Translate, and manually reviewed and corrected by three research assistants who listened to the recordings and manually corrected translation errors. The qualitative data was analyzed following a grounded theory approach [17]. Three authors (one Postdoc in Cognitive Science, one PostDoc in Computer Science, and one PhD student with professional experience in user experience design) discussed a preliminary coding scheme for each question as a starting point for inductive coding. The three authors then individually coded the responses of a sample of 30 participants. In a discussion following this individual coding session, the authors noticed that coding the data was straightforward in all cases [37]. That means, in all but a very few cases, it was easy to identify themes in the data, and in two other questionnaire items, the responses were too diverse to identify common themes. Therefore, it was decided that one author would inductively code the interview data.\nThe generated images and the body prompts (i.e., poses) were rated by the three authors along three criteria: a) dynamism of the source artwork (low/medium/high), b) dynamism of the participant's pose (low/medium/high), and c) a comparison of the source artwork and generated image in terms of whether a change in narrative took place. For a) and b), the authors collaboratively agreed on a codebook, as listed in Table 2 in Appendix A. With the metric of 'dynamism', we intend to capture the expressiveness of the artwork and body prompt. A static pose was rated to be of low expressiveness, whereas a highly dynamic pose was rated as being very expressive. For c), the authors agreed to code a change in narrative if a subject engaged in a different activity or had a different expression (e.g., static versus humorous), or if the model hallu-cinated artifacts that caused or strongly contributed to a change in narrative. After a first rating round, the ratings were discussed and each author revised their ratings for internal consistency.\nEmploying Fleiss' Kappa for inter-rater reliability assessment, our study found high agreement levels among the three raters across all three variables: source artwork dynamism (k = 0.96), pose dynamism (k = 0.86), and narrative change (k = 0.88). These results underscore the raters' cohesive interpretations and a consistent and robust evaluation process for the studied variables. After calculating inter-rater agreement, a majority vote between the three authors was used to produce the final set of ratings.\nIn addition, one author analyzed and coded the difference between the source artwork and the body prompt, characterizing the latter as either being an imitation (re-creation) of the source artwork or an attempt to 'reimagine' (reinterpret) the artwork with a body prompt that significantly differs from the source artwork. The latter equates to wanting to change the narrative between source artwork and generated artwork via the body prompt. It was further coded whether this narrative change in the resulting image originated from the generative model (e.g., by hallucinating artifacts or facial expressions) or the user (via the body prompt), with options 'model', 'user', 'both', and 'n/a' (meaning no major change in narrative took place)."}, {"title": "3.5 Technical Implementation", "content": "We developed a software architecture based on T2I-Adapter [40] with four different inputs (depicted in Figure 3):\n(1) Pose: The pose was detected from the body prompt photo and used to guide the image generation with openpose-based ControlNet [10, 63].\n(2) Artwork: Style information was extracted from the selected source artwork and used as an input for the T2I-Adapter.\n(3) Prompt: A textual prompt was generated from the selected source artwork using CLIP-Interrogator (version 0.6.0).\n(4) Negative prompt: A negative textual prompt was manually designed, based on best practices in text-to-image generation [43]. This negative prompt was used for all image generations to improve the quality of outputs and prevent unsafe generations [53].\nImages were generated with Stable Diffusion v1.5 [55] with 50 steps and cfg 8.0. The generated images were upscaled twice with Real-ESRGAN for viewing on the large public display. GFPGAN was used to enhance faces. The image generation architecture was packaged as a cog container and uploaded to Replicate.com where it is publicly available for inference via an API.\u2075\nTwo React-based web applications were developed, one for body prompting and one for viewing the results. Both applications were hosted in AWS S3 buckets, using an ssl-encrypted AWS Cloudfront to provide a secure connection.\nThe first application guided users through the process with a linear application flow (c.f. Figure 1). The application captured the photo from the webcam MediaStream using the MediaDevices API once the timer hit zero. An AWS Gateway was set up to proxy requests from the web application to Replicate's API. Results from the API were received with a webhook (AWS Lambda function) and stored in a JSON file hosted in an S3 bucket. The application was automatically reset after 60 seconds once the final application screen was reached. The main purpose of this timed reset was to reduce queuing for participants at the public viewing area \u2013 the bottleneck of our study design \u2013 and to give more time to the subsequent interview. The source artworks were shuffled after each image generation.\nThe second application enabled the research assistants to scroll through the generated images with keyboard arrow keys. The ap-plication used long-polling to fetch the list of generated images. A red square on the screen indicated the number of newly generated images available for viewing. The participants pose was shown in the corner of the screen. Generated images were viewed either on a public display or in private on two laptops with privacy screens, depending on which posing area was chosen by the participant."}, {"title": "4 Results", "content": "This section first provides information on the participants and then proceeds to answer our research questions.\n4.1 Participants\nInterviews were conducted with 79 participants after they used the installation. Participants were on average 37 years old (Median = 35, SD = 13.5, Max = 68) and included 46 women, 32 men, and one non-binary participant.\nParticipants' Big Five personality traits were Openness, Conscien-tiousness, Extraversion, Agreeableness, and Neuroticism were assessed on five-point Likert scales. Participants' above average openness scores (Mean = 3.56, SD = 0.83) suggest a general ten-dency towards creativity and openness to experience within the cohort. Conscientiousness followed closely (Mean = 3.51, SD = 0.72), indicating a high level of reliability and organization among participants. Extraversion and Agreeableness scores were slightly lower (Means = 3.20 and 3.19, respectively, SDs = 0.56 and 0.72), pointing to moderate levels of sociability and empathy. Neuroticism received the lowest average score (Mean = 2.93, SD = 0.76), suggesting a lower degree of emotional instability and stress sensitivity in the group. These findings offer a nuanced view of the personality"}, {"title": "4.2 RQ1: Generated Images", "content": "In total, 172 images were created during the six-hour event (112 images in public and 60 images in the private booth). Due to the diversity of source artworks, the body prompts are difficult to compare. In this section, we provide a brief descriptive overview of the 172 generated images and body prompts. This section mainly reports on general trends, while specific outstanding instances are highlighted in Section 4.6.1. A gallery of all generated images is available at https://artworksreimagined.com.\nOverall, the style of the source artwork was reproduced well, to a degree where it was clearly recognizable which source artwork was used as style reference (see Figure 4). However, the generated images captured the source artwork to varying degrees, leaving room for interpretation and surprise.\nThe body prompts had varying degrees of expressiveness. Some participants simply stood motionless in front of the camera in a neutral pose with arms dangling beside their hips. Other participants were more dynamic and expressive, raising limbs into the air. A few participants went to great lengths to produce their body prompts (as depicted in Figure 5, bottom center). The generative model's output would reflect the same number of posing subjects. Overall, there were no noticeable differences between the body prompts performed in public and private, with a few exception (described in Section 4.6.1).\nWe classified whether a change in narrative had taken place between source artwork and generated image. In almost half of the generated images (46.8%) a change originated from the participant's body prompt, which means the pose introduced significant modifications in the generated image. In another 29.1% of the generated images, no change in narrative took place and the new generated image appeared to be a reproduction of the source artwork's original idea, with some minor changes (e.g., number of subjects).\nAbout a quarter of the participants (24.1%) encountered surprising generative artifacts in the generated image. Co-creation with Al can involve surprising hallucinations by the generative model. With hallucinations, we specifically refer to artifacts introduced by the generative model that cannot be found in the source artwork or in the participant's body prompt, often resulting in a change in narrative between the source artwork and the generated image. In this study, hallucinatory artifacts included door frames, wooden sticks, fields with houses in the distances, animals, and more. However, these generated elements in the image did not necessarily deviate from the narrative portrayed in the source artwork.\nAbout 8% of the participants encountered surprising artifacts originating from the generative model that clearly changed the narrative. Another 16.2% of participants encountered images where the narrative change originated both from the model and the participant. These were often images where the participant's pose deviated from the source artwork, with the AI adding surprising el-ements, such as additional characters or changes to the subjects. In other instances, the model added minor hallucinatory elements that still resulted in a change of narrative. For instance, in the generated image in Figure 5, bottom right, the model appears to have added COVID face masks which are not present in the source artwork. In another funny example, the generative model seemingly changed the gender of a subject from a blonde woman to bald man (see Figure 5, middle row, center)."}, {"title": "4.3 RQ2: User Experience", "content": "4.3.1 Experiencing body prompting. Participants generally found the experience of body prompting highly pleasant (Mean = 4.58 on a Likert-scale from 1 to 5, SD = 0.62). Creating images via body prompting was deemed to be overall a great experience (Mean = 4.58, SD = 0.65). When asked to describe why, participants provided different explanations. The most common reasons were that participants found it fun, interesting, and easy. The ease of the interaction via body prompting was commented on often. The in-app instructions were easy to understand and follow, providing a \"fluent\" (A38, D70) and \"effortless\" (C43) user experience.\nIn regard to body prompting, the installation provided a novel experience with interesting results. \"Combining the own posture with an artwork\" (D49) was perceived as entertaining activity and made for an interesting combination (D75). The physical interaction with the generative AI was perceived as interesting:\n\"It's interesting to try what you can do with the AI\nand just actually physically do something and see it\ncoming out.\" (D76)\nBody prompting was perceived as fun and lighthearted, with \"not too much pressure participating\" (A35). Many participants called it a \"fun experiment\u201d (e.g., C28, G79) and some participants appreciated that \"you get to be creative and go crazy\" (C28). Many participants wanted to try the installation a second time and experiment with different body prompts, such as F62 who wanted to \"try a completely different pose than in the artwork\". Speaking about Hokusai's \"The Great Wave off Kanagawa\", H30 commented they \"wanted to see if Al transforms us into humans or will it convert us to waves as there were no humans in the original artwork\". As depicted in Figure 5 (top right), the AI indeed added two humans in this case, although in other cases, it did not.\nA small minority of participants voiced some discomfort and concerns about body prompting. Most of these comments, however, related to the study design and the technical limitations of the installation. For instance, three participants commented on the wait time which was a fixed part of the study design. Some participants commented on the countdown timer. On the one hand, F57 thought \"it was quite a long time to stand and look at your own picture\". On the other hand, some participants wanted to have more time to decide on their body prompt. G66, for instance, thought the picture was taken too quickly and \"there was no time to think\". Addressing another technical limitation, A24 thought it was a fun experience, but voiced disappointment about the facial expression not being captured by the body prompt. While privacy-by-design was explicitly appreciated by two participants (G61 and B65), a few other participants still voiced concerns about being photographed. This included comments from E18 and G78 who categorically do not like being photographed. G78 mentioned the picture-taking being \"a little bit distressing\". A2 thought it was daring to perform in public, and C43 voiced concerns about being watched: \"When I started to do my pose I started to think is there someone watching. Other than that it was fun to see what is coming up\".\nWe could observe that body prompting by a group of people generally tended to be more entertaining, both for the participants performing the body prompting and the audience. Groups of participants developed their own dynamics leading to playful interactions with the image generation system. Selecting the right source artwork often involved short discussions in which participants agreed on their body prompt. These group negotiations could, obviously, not be observed in single participants. However, some participants instead asked the audience on what body prompt to perform, turning the audience from passive spectators to active participants.\nOverall, the novelty of the experience was appreciated by the participants, as exemplified by D47 who said that \u201cthis was a Friday afternoon's fun thing, an experiment, and something new for me", "unclear what to expect\" which was \\\"a good thing for creativity\". Some participants further referred to the creative aspects of body prompting. B77 thought it was a creative experience, \u201cI would have needed help for making the piece of art [with traditional means]. I felt that there was room for creativity\". B77 mentioned body prompting required \\\"quick enough creativity\" in the sense that it \u201cdoes not have to be perfect\". F62 voiced an interest in exploring emotions with body prompting": "how artificial intelligence modifies and how a work of art can be modified according to one's own emotional scale. It would be interesting to use this to express feelings\u201d."}, {"title": "5 Discussion", "content": "We evaluated body prompting as a novel interaction mechanism for generative AI art installations in public spaces. Overall, body prompting is a viable way of interacting with generative AI in a public setting, providing a highly engaging and fun experience for both participants and the audience. Our study identified three body prompting strategies employed by participants, focused on imitating the source artwork, re-imagining, or body prompting by \"just being themselves\". Personality traits did not play an important role in the participants' decisions and body prompts and the installation provided a novel experience which was appreciated by both extraverts and introverts.\n5.1 Human-AI Co-Creation via Body Prompting\nGenerative Al has ushered in an era of human-AI co-creation [11, 26, 54]. The human agency in this co-creative process varies on a spectrum [50], from full human autonomy to full machine automa-tion. In our study, participants experienced human-AI co-creation along this spectrum. Depending on the chosen source artwork and body prompt, the generative model had varying levels of influence on the generated image. In combination with the participants' body prompting strategy, their experiences included either re-creation or reinterpretation, as discussed in Section 2.3. The participants pursued their strategy with varying levels of tenacity, but most in-teractions were casual, as participants picked a level of interaction suitable for their desired engagement [51, 52].\nWhile it can be argued whether the body-prompted images are art [12, 35], the poietic act of performing a body prompt changed the dynamic of the creative process of image generation, placing the human in the center of the co-creative process in a public setting. In Kun et al.'s GenFrame, participants turned knobs to control image generation parameters, but otherwise relegated the creative process fully to the machine [30]. In our co-creative study, the AI became \"more than just a machine\", with AI and humans being co-creators and co-performers [12]. This highlights the importance of interaction design in co-creative systems [54].\n5.2 Recommendations for the Design of Body Prompting Installations\nIn this section, we reflect on the few shortcomings in the design of our study and installation, and draw on this experience to pro-vide recommendations for practitioners interested in the design of installations and researchers conducting user studies involving interactive image generation in a GLAM context.\n5.2.1 Multi-display setup and user experience design. A first rec-ommendation concerns the setup with two separate displays, one for input and one for output. The main reason for this split was that we wanted to incorporate the interview procedure into the image generation process to bridge wait time. However, at times, the interviews became the bottleneck of the installation and par-ticipants started queuing to see the results. While this was not a significant issue at our event where visitors also had to queue at other exhibits, it should be avoided in future studies.\nDesign recommendation: Future installations should provide im-mediate feedback to participants without forced integration of a user study. Bottlenecks in the user flow should be avoided. We recommend to show generated images on the same screen as soon as they are available. If there is a choice between private and pub-lic body prompting, this needs to be explained at the event, for example with signage.\n5.2.2 Manage expectations. As mentioned in Section 4.6.2, some participants experienced frustration. This was particular pronounced with young children who were often disappointed and did not share their parents' appreciation for the AI-generated images. This raises a point related to managing expectations: an \"AI Camera Booth\u201d may raise expectations that the resulting images will resemble the body prompting person. Our study's purpose was slightly different from a \"camera booth\", and we carefully designed communication materials to avoid setting this expectation.\nDesign recommendation: Communication materials should be carefully designed to set the right expectations. The purpose of the installation should be made clear to its visitors. If what is being provided is advertised as a \"camera booth\", the technology should be able to reproduce the likeness of its users. If the focus is on reinterpreting existing artworks, the term camera booth should be avoided. Facial expressions and hand gestures should be included in the body prompt.\n5.2.3 Enable expressiveness. A body pose can only carry a limited amount of information. In our case, some participants reported that the generated image was more serious and sinister than expected. This could be alleviated by including the facial expression in the body prompt and providing more fine-grained control over the image generation."}, {"title": "5.2.4 Enhancing user experience with Al co-creativity", "content": "Hallucinations add a surprising and playful element to the co-creative expe-rience. Participants who encountered and noticed these hallucina-tions were entertained and intrigued. Uncontrollable AI [18", "39": ".", "recommendation": "Hallucinations and weird artifacts are part of the generative AI user experience and add an intriguing component. We recommend not seeking to eliminate hallucinations", "20": ".", "first-click problem\u201d \u2013 they did not real-ize the display was a touchscreen and used a mouse and keyboard that happened to be available. With the public installation, this was not an issue since participants could observe other people's use of the installation.\nDesign recommendation": "The first-click problem should be ad-dressed with instructions that are carefully designed to fit the study purpose and not bias participants.. While we addressed this prob-lem with a makeshift banner during the event, the private booth requires a slightly different design and instructions than the public posing area.\n5.2.6 Takeaways and souvenirs. Many participants liked the resulting images and inquired about ways of downloading them. These participants developed a sense of ownership of the generated im-ages. In our event, we strived for a minimal setup and could not facilitate the download of images. Instead, participants were told"}]}