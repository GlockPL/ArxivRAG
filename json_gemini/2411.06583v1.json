{"title": "Enhancing frozen histological section images using permanent-section-guided deep learning with nuclei attention", "authors": ["Elad Yoshai", "Gil Goldinger", "Miki Haifler", "Natan T. Shaked"], "abstract": "In histological pathology, frozen sections are often used for rapid diagnosis during surgeries, as they can be produced within minutes. However, they suffer from artifacts and often lack crucial diagnostic details, particularly within the cell nuclei region. Permanent sections, on the other hand, contain more diagnostic detail but require a time-intensive preparation process. Here, we present a generative deep learning approach to enhance frozen section images by leveraging guidance from permanent sections. Our method places a strong emphasis on the nuclei region, which contains critical information in both frozen and permanent sections. Importantly, our approach avoids generating artificial data in blank regions, ensuring that the network only enhances existing features without introducing potentially unreliable information. We achieve this through a segmented attention network, incorporating nuclei-segmented images during training and adding an additional loss function to refine the nuclei details in the generated permanent images. We validated our method across various tissues, including kidney, breast, and colon. This approach significantly improves histological efficiency and diagnostic accuracy, enhancing frozen section images within seconds, and seamlessly integrating into existing laboratory workflows.", "sections": [{"title": "Introduction", "content": "In histopathology, frozen sections are commonly used to obtain immediate diagnosis during surgeries or other procedures, as they are fast and inexpensive to process. However, frozen sections suffer from poor image quality and artifacts and might not provide enough information for a definitive diagnosis, as the tissue may not be fully preserved, and certain features might be difficult to identify [1-4]. On the other hand, permanent sections are typically of higher quality than frozen sections, with fewer artifacts and better preservation of tissue architecture. This can provide a more detailed analysis of the tissue, allowing for a more accurate diagnosis and potential identification of additional features. However, permanent sections require much more preparation time and typically cannot be processed during surgery, which may delay diagnosis and treatment. Therefore, developing a method to improve frozen section images is critical.The preparation of frozen sections involves rapidly freezing the tissue sample to preserve its structure and cellular details. This is typically done using a cryostat, which maintains the tissue at temperatures around -20 to -30\u00b0C. The tissue is embedded in a gel-like medium, which consists of polyethylene glycol and polyvinyl alcohol. This medium ensures that the tissue remains stable and can be sliced into thin sections using a microtome. The rapid freezing process helps prevent the formation of most ice crystals that could damage the tissue, but it may still result in some artifacts and lower image quality compared to permanent sections.\nIn contrast, the preparation of permanent sections involves a more elaborate chemical process. The tissue is first fixed in formalin to preserve its structure and prevent degradation. It is then dehydrated through a series of alcohol baths, cleared with a solvent-like xylene, and finally embedded in paraffin wax. Once the wax hardens, the tissue block is sliced into thin sections using a microtome. These sections are then mounted on slides and stained to highlight different cellular components. The formalin fixation and paraffin embedding process provide excellent preservation of tissue architecture and cellular details, resulting in high-quality images suitable for detailed analysis.\nSince frozen and permeant section chemical preparation processes are different, most available datasets include unpaired frozen and permanent section images, which makes the problem of learning and mapping between frozen to permanent section images challenging as there is no ground truth of a paired permanent section to compare to frozen sections often contain blank regions, it is crucial not to introduce artificial data into these areas, as this could mislead pathologists. An example of frozen and permanent section images can be found in Figure 1. As can be seen, the sub-nuclei features are lost in the frozen section image in comparison to the permanent section image. The nuclei texture is useful for cancer diagnosis, grading as well in prognosis prediction [5]. For example, the detailed analysis of nuclear morphometry and chromatin texture has been shown to provide critical insights into the diagnosis and prognosis of hepatocellular carcinoma [6], highlighting the importance of precise nuclear characteristics in enhancing the accuracy of pathological assessments. These analyses can be done with permanent sections and cannot be done with frozen sections."}, {"title": "Methods", "content": "Data collection and preprocessing\nThe data used to train our models contained breast, colon, and kidney cancer slide images, obtained from The Cancer Genome Atlas (TCGA), a publicly funded project initiated by the National Cancer Institute and the National Human Genome Research Institute. Overall, we used 46,912 pairs of frozen and permanent images for breast, 25,362 pairs for colon, and 13,691 pairs for kidney for training. These pairs were prepared for each cancer type, where each pair of frozen and permanent slides was acquired from the same patient to get the best correspondence as fully paired (same tissue slice), but exact frozen- permanent pairs were not available due to different preparation protocols. We used the images with the highest resolution and cropped each of them into patches of 256x256 pixels, while removing images with significant blank parts. Afterward, the data was shuffled.\nSegmented Attention Network (SAN) for frozen section image enhancement\nOur goal is to utilize permanent images in order to improve frozen section images, placing particular emphasis on the nuclei regions to capture critical details with high accuracy.\nThe image-to-image translation from frozen images into permanent images was performed by CycleGAN.\nWe denote f \u2208 F, where f is a frozen section image taken from the frozen section set F, and p\u2208 P, where p is a permanent section image taken from the permanent section set P. The CycleGAN consists of two generators, Gp and GF, and two discriminators, Dp and DF. The generator Gp learns to map Gp: F\u2192 P, and the generator GF learns to map GF : P \u2192 F. Each of the generators has the architecture of Attention U-Net [26,27], as it improves the model sensitivity with minimal computation overhead. The two CycleGAN discriminators, Dp and DF, learn to distinguish between the real and generated images in their respective domains of permanent and frozen section images subset, respectively. Each of the discriminators has the architecture of Resnet-18 [28]. Our loss function is:\n$L(G_F, G_P, D_F, D_P) = L_{gan}(G_P, D_P,F,P) + L_{gan}(G_F, D_F, P, F) + \\lambda L_{cyc}(G_P, G_F, F,P),$\nwhere $L_{gan}$ is the adversarial loss, $L_{cyc}$ is the cycle-consistency loss, and \u03bb is a regulation weight to control the relative importance of the two objectives.\nTo improve the generation of frozen to permanent images specifically on the nuclei regions, we introduce a new loss function:\n$L(G_F, G_P, D_F, D_P) = L_{GAn}(G_P, D_P, F, P, F_{seg}, P_{seg}) + L_{GAN} (G_F, D_F, P, F, P_{seg}, F_{seg}) + \\lambda L_{cyc} (G_P, G_F, F_{seg}, P_{seg}),$\nwhere $F_{seg}$ and $P_{seg}$ are the nuclei segmented images of the frozen and permanent images, respectively, which include only the nuclei contents in the image, as can be seen in Figure 2.\nFirst, nuclei segmentation is done on the permanent and frozen patches using the StarDist model [29], pre-trained on H&E nuclei segmentation. Next, we train the model in two steps. The first step is done on the original pairs of F and G, and the second step is done on the nuclei-segmented pairs of $F_{seg}$ and $P_{seg}$. See full algorithm flow on Table 1.\nApplying the procedure appearing in Table 1 ensures that the discriminator will learn how to distinguish between the cell nuclei in the frozen-section domain and in the permanent-section domain in hard-attention manner, while pushing the generator to improve the cell nuclei details in the enhanced frozen section image. A block-diagram of the network flow is shown in Figure 3."}, {"title": "Model configuration", "content": "We trained the models on ASUS TUF Dash F15 i7 PC, with NVIDIA GeForce RTX 3060 GPU. The model configuration including the hyper-parameters used for each method are presented in Table 2."}, {"title": "Results", "content": "Grad-cam evaluation\nOur method pushes the discriminator to distinguish better on the feature of interest, which in our case is the nuclei region, and therefore to make the generator generate more reliable content in this region of interest. We first used Grad-cam [30] to examine the influence of our method on the discriminator. Grad-cams are a visualization method that highlights the regions of an image that contribute the most to a neural network's output, helping explain why a particular decision was made by the network. We compared CycleGAN with Attention UNET & Resnet, and SAN both with discriminator architecture of Resnet-18. We generated Grad-cams on the discriminator Dp. Figure 4 visually demonstrates that our method, SAN, puts more attention on the nuclei region, which pushes the generator to generate better nuclei content.\nFID score evaluation\nTo evaluate the similarity of our generated permanent section images to the unpaired permanent section targets, we used Frechet Inception Distance (FID) [31], measuring the Wasserstein distance [32] between multivariate Gaussian distributions fitted to feature representations of the generated and real images, typically using features from an Inception v3 net trained on ImageNet. FID can be computed from the mean and covariance of Inception activations on the generated and real images. Lower FID indicates greater similarity between the generated and real image distributions, making it useful for evaluating improvements in image generation quality for GANs and other generative models. The FID score comparison between our method, the CycleGAN, and CycleGAN with Attention UNET & Resnet on the test data is presented in Table 3.\nVisual inspection\nFirst, to verify that our SAN model succeeds in generating both permanent section patches from frozen section patches and nuclei-segmented permanent section patches from nuclei-segmented frozen section patches using the same model, we visually inspected the full test data, with one example shown in Figure 5.\nFor a full comparison, we present visual comparisons of the generated permanent section images using the CycleGAN, CycleGAN with Attention UNET & Resnet, and SAN, focusing on the breast, colon, and kidney tissue samples. Examples of the generated permanent section images alongside their corresponding frozen section counterparts are provided in Figure 6. These examples illustrate the differences in image quality and detail preservation among the methods. CycleGAN tends to produce images with noticeable artifacts and a lack of fine details, particularly within the nuclei region. The CycleGAN with Attention UNET & Resnet shows a slight improvement in preserving details and avoiding artifacts, but still tends to inaccuracy in representing the structures within the tissue samples. In contrast, our proposed SAN method significantly enhances the frozen section, especially within the nuclei region, providing clearer and more diagnostically relevant images compared to the other methods.\nNuclei texture analysis\nTo evaluate the content of the enhanced nuclei regions, we quantitatively analyzed the texture of kidney tissue images by comparing the segmentation of nuclei across frozen sections, permanent sections, and the enhanced frozen sections produced using our SAN method and CycleGAN with Attention UNET & Resnet. The focus is on extracting Gray-Level Co-occurrence Matrix (GLCM) [33] features, which are crucial for evaluating texture patterns related to diagnostic markers in histopathology.\nFor this analysis, we segmented the nuclei regions in all test images (frozen, permanent, and generated sections) and computed GLCM features from 14\u00d714-pixel crops taken exclusively from within the nuclei. This ensured that our texture analysis focused on the most diagnostically relevant regions. We calculated GLCM features using distances of 1, 2, 3, 4, 5, and 6 pixels and angles of 0\u00b0, 45\u00b0, 90\u00b0, and 135\u00b0.\nThe features analyzed include contrast, correlation, energy, and homogeneity, which provide a comprehensive statistical description of the textures within the nuclei.\nThe lower JS divergence values for SAN indicate that the textures generated by our method are closer to the real permanent sections. In particular, SAN achieves the lowest divergence in the image contrast feature (0.1651), indicating that it better reproduces the sharpness and variability of textures in the nuclei compared to both frozen sections and CycleGAN with Attention UNET & Resnet. In addition, SAN shows minimal divergence in the correlation feature (0.0057), suggesting that it accurately preserves the relationships between pixel intensities within the nuclei. Moreover, SAN exhibits improvements in the energy and homogeneity features over the other methods but still shows room for refinement in capturing smoothness and uniformity in the nuclei textures. Thus, the JS divergence analysis and GLCM feature statistics demonstrate that the proposed SAN method consistently outperforms both the frozen sections and CycleGAN with Attention UNET & Resnet in replicating the textures of the real permanent sections in the nuclei area. The significant reduction in divergence for contrast and correlation highlights SAN ability to capture fine textural variations within the nuclei, which are crucial for accurate tissue diagnosis. In contrast, CycleGAN with Attention UNET & Resnet shows higher divergence across all features, particularly for contrast and homogeneity, suggesting that it struggles to maintain the necessary texture details within the nuclei regions. Frozen sections also show relatively high divergence, especially in the contrast feature, further illustrating the limitations of the direct use of frozen section images for diagnostic purposes without enhancement.\nTo further assess the performance of our SAN model in a clinical setting, we generated 826 patches from frozen kidney tissue sections obtained at Chaim Sheba Medical Center. For each frozen section patch, we used our SAN model to produce an enhanced version. An example of such a pair is shown in Figure 8. We then asked a qualified pathologist (G. G.) to evaluate the contribution of the generated patches compared to the original frozen sections.\nThe most significant improvement is in the details that can be seen inside the nuclei. Both the boundaries of the nucleus and the dispersion of the chromatin and the presence of nucleoli are visible in the generated images. This feature is important for tissue grading, but also for the accuracy of diagnosis in a variety of different tumors. For example, when diagnosing papillary thyroid cancer, the pathologist might look for grooving inside the nucleus, which is sometimes difficult to see because of the quality of the image, and improving the quality of the nucleus can be critical [5, 6]. In our case, tissue grading of kidney cancer is based on the ability to see nucleation at different magnifications [5]. In relation to the cytoplasm and the borders between the cells, Figure 8 demonstrates a significant improvement. Regarding the cell borders, there is clearing of the cytoplasm and relatively clear cell boundaries in a way reminiscent of the permanent sections, instead of a smear of pink color, which characterizes the frozen sections. It appears that the model performs better to produce a permanent-section-like patches in areas where there are fewer artifacts of the frozen section. As the image has fewer tears in the tissue and more hypercellular areas where the concentration of cells is higher, it is more likely that the generated permanent-section-like patch will be of higher quality.\nQuantitatively, according to the pathologist's analysis of the 826 kidney tissue patches: 74.9% of the generated section patches significantly improve the diagnosis-relevant nuclear details. 49.1% of the generated section patches produced clearing of the cytoplasm, and 59.7% produced clear cell borders as they should appear in the permanent section images."}, {"title": "Discussion and Conclusion", "content": "In this paper, we introduced a new approach, called SAN, designed to address image-to-image translation with guided attention to specific details, and applied it to the challenging task of enhancing frozen section images by utilizing permanent section image guidance with focus on the cell nuclei details. While frozen sections offer immediate diagnosis during surgeries, but often suffer from artifacts and poor image quality, making it challenging to provide an accurate diagnosis, permanent sections offer better image quality and preservation of tissue architecture, but are time-consuming to prepare. Our approach aimed to bridge this gap by integrating a unique attention mechanism, based on nuclei segmentation, into the CycleGAN model. This frozen-section image enhancement is done by pushing the model generator to provide detailed content within the nuclei regions. Our method introduced a two-step training procedure, incorporating both the original pair of images and the nuclei-segmented pairs. While the first step translates frozen section images into permanent section images, the second step acts as a hard-attention mechanism, transferring nuclei-segmented frozen images into nuclei-segmented permanent images, which leads to more accurate and detailed images that capture nuclei-level information. Our method was evaluated using data samples from breast, kidney, and colon tissues. The unique attention method based on nuclei-segmentation significantly improved the generator's ability to capture and produce nuclei-level details, which are critical for precise diagnosis.\nThe proposed SAN method builds upon the framework of CycleGAN but incorporates attention mechanisms to prioritize the fidelity of nuclei features in the translated images. To further highlight the effectiveness of our approach, we conducted a comparative analysis of our method, SAN, with CycleGAN, and CycleGAN with attention UNET & Resnet. Our approach demonstrated its advantage in enhancing frozen section images with richer content in the nuclei region. Moreover, we used Grad-cam maps to visualize the impact of our method. The Grad-cam maps illustrated that our approach pushed the discriminator to focus more on the nuclei region, which, in turn, encouraged the generator to generate more detailed content within this region, producing permanent section images more accurately in these challenging regions. In addition, we evaluated the clinical improvements based on pathologist examination. While our results demonstrate improvements in image quality and detail preservation, several important considerations merit discussion. First, it is crucial to acknowledge the inherent challenge of working with unpaired frozen and permanent section images. We have obtained image pairs from the same patient, but the frozen and permanent section images are not exactly paired due to different chemical preparation protocols. The lack of direct correspondence between the two types of sections poses a fundamental limitation. As a result, there is ambiguity regarding whether the model has learned features from cancerous or non-cancerous areas, as the presence or absence of cancerous tissue areas may vary within individual patients. Addressing this issue would require meticulous labeling by pathologists to confirm the characteristics of each image pair, a task that we intend to explore in future work. Second, ensuring the relevance of enhancement learned from permanent section patches to corresponding frozen section patches is essential for the effectiveness of our translation model. While we have attempted to mitigate this concern through careful data selection and training, it remains a challenge to guarantee the alignment of features between the two types of sections. To address this, incorporating pathologist labeling can be carried out to validate the suitability of each image pair for training, thereby enhancing the relevance and accuracy of our model learning process.\nThird, the discrepancy in morphological characteristics between frozen and permanent sections presents a significant obstacle in achieving fully paired data. While it is not feasible to eliminate this difference entirely, we recognize the importance of utilizing successive or closely positioned histological section paired data to refine our model further. By exploring different degrees of pairing and conducting additional model training on such data, it will be possible to optimize the performance of our approach and enhance its robustness in translating frozen images into permanent-like quality.\nIn conclusion, SAN represents a significant advancement in the field of histopathology image enhancement. By combining nuclei segmentation with CycleGAN, we have developed a general method, which specifically addresses the limitation of frozen section images and offers a fast and reliable solution for frozen section image enhancement. This approach has the potential to improve the accuracy and effectiveness of pathological diagnosis and can be extended to various applications where detailed attention to specific image regions is required."}, {"title": "Supporting information", "content": "Not applicable."}, {"title": "Conflict of interest", "content": "The authors declare no conflict of interest."}, {"title": "Code availability", "content": "The code is available upon request."}, {"title": "Data availability statement", "content": "The slide images we used to train and test our models were taken from the TCGA Research Network:\nhttps://www.cancer.gov/tcga\nIn the Clinical Analysis section, we used for evaluation 826 patches taken from 4 kidney tissues obtained at Chaim Sheba Medical Center."}, {"title": "Funding", "content": "Supported by the Israel Science Foundation (ISF)."}, {"title": "Keywords", "content": "deep learning, CycleGAN, attention, histopathology, frozen sections, permanent sections"}]}