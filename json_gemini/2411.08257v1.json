{"title": "GPTree: Towards Explainable Decision-Making via LLM-powered Decision Trees", "authors": ["Sichao Xiong", "Yigit Ihlamur", "Fuat Alican", "Aaron Ontoyin Yin"], "abstract": "Traditional decision tree algorithms are explainable but struggle with non-linear, high-dimensional data, limiting its applicability in complex decision-making. Neural networks excel at capturing complex patterns but sacrifice explainability in the process. In this work, we present GPTree, a novel framework combining explainability of decision trees with the advanced reasoning capabilities of LLMs. GPTree eliminates the need for feature engineering and prompt chaining, requiring only a task-specific prompt and leveraging a tree-based structure to dynamically split samples. We also introduce an expert-in-the-loop feedback mechanism to further enhance performance by enabling human intervention to refine and rebuild decision paths, emphasizing the harmony between human expertise and machine intelligence. Our decision tree achieved a 7.8% precision rate for identifying \"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with few-shot learning as well as the best human decision-makers (3.1% to 5.6%).", "sections": [{"title": "1. Introduction", "content": "Thanks to their explainability, decision trees are among the most intuitive and popular methods in machine learning (second only to linear regression). Their tree-like structure enables users to easily follow the decision-making process, with each split representing an interpretable rule based on the input data. This transparency is valuable in domains such as the Venture Capital (VC) industry where the stakes are high for each investment decision. In practice, however, decision trees often underperform when faced with non-linear, high-dimensional datasets and are inherently unsuitable for text-rich and multi-modal datasets. Thus, our work to extend decision trees is motivated by this fundamental question: how to incorporate LLMs?\nIn recent years, Large Language Models (LLMs) have emerged as powerful tools capable of capturing the intricacies of natural language: models such as gpt-4o and gpt-1o preview have showcased exceptional capabilities in advanced reasoning and multi-modal tasks. However, LLMs are often seen as \"black boxes\" due to their elusive architectures. In addition, prompt engineering techniques like chain-of-thought and tree-of-thought, combined with extensive prompt chaining, are frequently required to produce accurate and contextually relevant responses. Not only does this require considerable human intervention and expertise but is also prone to trial-and-error procedures in crafting prompts that provide meaningful outputs. Therefore, we address another question: how to design a robust and explain-able approach that minimizes human intervention while maintaining high performance?\nIn this paper, we present GPTree, a novel framework that combines the explainability of decision trees with the advanced reasoning capabilities of LLMs, also incorporating an efficient expert-in-the-loop feedback system.\nIn summary, our work makes the following contributions:\n\u2022 We introduce an LLM-powered decision tree model to dynamically split samples using a combination of LLM inference, code-based and clustering nodes, giving users the full explainability of traditional decision trees along with the flexibility of working with unstructured text and potentially multimodal datasets.\n\u2022 We eliminate the need for feature engineering and prompt chaining, instead replacing it with our expert-in-the-loop feedback mechanism. This further enhances performance by enabling a human expert to refine and rebuild decision paths post-training, leveraging the cooperation potential between human expertise and machine intelligence.\n\u2022 We conduct a comprehensive empirical evaluation of our approach within the VC landscape, where explainable decision-making is essential. Our experimental analysis demonstrates the effectiveness of our approach at identifying \u201cunicorn\" startups in comparison to human decision-makers within the industry, based on data collected from over 115K US-based companies founded more than 8 years ago."}, {"title": "2. Dataset", "content": "This dataset contains 9,892 founder profiles collected and enriched from publicly available data sources as well as paid data sources such as Crunchbase. These profiles have been drawn from companies that were founded between 2010 and 2016 and have raised between $100K and $4M in funding. A founder is classified as successful if his/her company achieves a valuation of more than $500M through an IPO (initial public offering), is acquired for more than $500M, or holds a large funding round of more than $500M. Of the 9,892 founders, 978 (9.9%) are categorized as successful, while 8,914 are considered unsuccessful."}, {"title": "3. GPTree", "content": "GPTree is an automated framework that combines the reasoning and generative capabilities of the latest foundation models (OpenAI, 2024) with the explainability and robustness of decision trees, delivering intelligent and adaptive decision-making.\nThe process consists of several key stages, as illustrated in Figure 2: Task Contextualization, Insight Generation, Question Candidate Generation, Decision Split Optimization, and Expert Refinement. While we currently use GPT-4o-mini as our backend to query, this approach can easily be adapted as more advanced models become available, ensuring scalability and improved accuracy over time.\nIn Figure 3 we illustrate sample output generated by our approach. We detail each stage in the ensuing sections."}, {"title": "3.1. Task Contextualization", "content": "GPTree starts by taking a task-specific string as user input to be used as context for the LLM. Task contextualization boosts performance as follows:\n\u2022 Enhanced Task Understanding: Parsing a task string allows the LLM to function as a human expert, allowing it to utilize appropriate context from its training corpus, leading to more meaningful and actionable insights.\n\u2022 Improving Focus: The LLM can prioritize specific information relevant to the task, reducing unnecessary output and improving the precision of its response.\n\u2022 Consistency: Task-specific prompts ensure that repeated queries on similar data or questions yield consistent outputs, which is crucial for high-stakes tasks like data analysis or decision-making.\nAs a concrete example, if our task is to distinguish successful founders, the following instruction might be used:\n\"Imagine you are a VC analyst. Analyze\nthe given data of successful founders\nand identify common features or success\npatterns. Provide a concise summary of\nthese common characteristics/traits.\""}, {"title": "3.2. Insight Generation", "content": "It is well known that LLMs can be inherently \"lazy\" (Tang et al., 2023), often opting for shortcuts when tasked to execute multiple steps simultaneously. We observed that performance declines significantly when they are asked to perform analysis on successful founders and generate appropriate question candidates in a single instance. This is especially pronounced when dealing with large datasets, as they often exceed the context window of the LLM, leading to superficial analysis and outcomes, which are not representative of the entire dataset.\nTo address this issue, we first generate advice for the LLM based on the input data in a systematic manner. By iterating through the samples with $batch_{size} = 250$ (depending on the size of the input data) and producing concise summaries of the common characteristics of the successful samples, we make sure that the model focuses on relevant features without being overwhelmed by the volume of data. Subsequently, another instance of the LLM synthesizes these"}, {"title": "3.3. Question Candidate Generation", "content": "Unlike traditional decision trees, which have a finite number of input values and therefore a finite set of candidate conditions to test, natural language inputs introduce an unbounded question space. To make the problem more tractable, we incorporate advice generated from the previous stage along with the task context and ask the LLM to generate 0-3 questions per input feature as candidate questions as follows:\n\"Your task is to distinguish successful\nfrom unsuccessful ones by generating\nprecise questions based on a given"}, {"title": "3.4. Decision Split Optimization", "content": "Given the list of question candidates, we compute the samples in the split and check whether or not they meet the minimum number of required samples. Then, for each valid split, we compute the individual Gini impurity and use a greedy strategy to select the question which minimizes the overall weighted Gini at that particular node.\nThis heuristic allows us to increase the homogeneity of the data splits and ensures that we have the best possible separation. The weighted Gini impurity formula is as follows\n$G_{weighted} = \\sum_{i=1}^{k} \\frac{N_i}{N} G_i$ (1)\nwhere k is the number of child nodes after the split (typically 2), $n_i$ is the number of samples in the i-th child node, N is the total number of samples across all child nodes (i.e., $N = \\sum_{i=1}^{k}n_i$), $G_i$ is the Gini impurity of the i-th child node.\n$G_i = 1 - \\sum_{j=1}^{C} p_{ij}^2$ (2)\nwhere C is the number of classes, $p_{ij}$ is the proportion of samples in the i-th child node that belongs to class j.\nThe tree is then constructed recursively, terminating when the condition of minimum samples per node is met, max depth is reached or a particular node becomes \u201cpure\u201d."}, {"title": "3.5. Expert Refinement", "content": "Post training, human experts can use their knowledge to fine-tune the model on a separate validation set by rebuilding and refining decision paths using the following implemented features:\n\u2022 Collapse a node\n\u2022 Rebuild subtree at a node\n\u2022 Q&A with the samples\n\u2022 Remove trivial nodes\nAs an example the following string could be used as advice to rebuild a specific subtree.\nConsider if the founder worked at\nbig tech companies such as Google,\nMicrosoft, Apple and Facebook/Meta.\nConsider if the founder worked at a\npublic tech company (NASDAQ). Consider\nif the founder has studied at a top\n20 ranked university based on QS World\nUniversity Ranking 2023....\n#total samples\nThe sensitivity hyperparameter classifies the leaf nodes as successful or unsuccessful based on the condition\nsensitivity > #success samples We optimize the model by\nselecting the sensitivity which maximizes the $F_{0.5}$ score.\nThe model is then run on the test set to obtain the final set\nof metrics."}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Evaluation Metrics and Baselines", "content": "Due to limited resources, we prioritize precision over recall, as ensuring that an invested company is successful is much more important than capturing all successful companies; therefore, we evaluate our models using $F_{0.5}$ score. In other contexts such as medical diagnosis, it may be more appropriate to consider $F_1$ or $F_2$. The following section illustrates the baselines that we used."}, {"title": "4.2. Industry benchmarks", "content": "The metrics in Table 1 show the precision of human decision-makers based on data collected from over 115K US-based companies founded between 2014 and 2016. All the companies considered have raised more than $100K with Indexing Strategy representing the proportion of founders who are classified as successful.\nNote that the metrics mentioned in the remainder of this section are based on the 9.9% founder success rate present in our dataset and thus should be scaled down 5.5\u00d7 to match the 1.9% outlier rate in the industry."}, {"title": "4.3. Vanilla gpt-40", "content": "As a baseline, we use the following prompt to generate vanilla predictions without any prompt engineering techniques or decision trees. This allows us to evaluate GPT-4's inherent ability to distinguish between successful and unsuccessful founders, relying solely on general knowledge and context embedded within its training corpus.\n\"You are an expert in venture capital\ntasked with distinguishing successful\nfounders from unsuccessful ones. All\nfounders under consideration are\nsourced from LinkedIn profiles of\ncompanies that have raised between\n$100K and $4M in funding. A successful\nfounder is defined as one whose company\nhas achieved either an exit or IPO\nvalued at over $500M or raised more\nthan $500M in funding.\"\nAs shown in Table 2, gpt-4o exhibits a 1.3 percentage point improvement in precision and, notably, has more than twice"}, {"title": "4.4. Few-shot prompting", "content": "Based on the few-shot prompting concept introduced by (Brown et al., 2020), we refine our previous vanilla prompt by providing four labelled founders: two successful and two unsuccessful. The goal is to help the model recognize similar contextual signals from the founders' profiles when making future predictions. We expect the model to generalize from a small number of examples, potentially improving performance over the vanilla baseline by aligning the task more closely with the desired outcome."}, {"title": "4.5. GPTree", "content": "In Table 4 we have the averaged results from the test set, with the individual fold results of the cross-validation along with the fine-tuning results displayed in Table 5. Overall, we significantly outperform all human decision-makers. Aside from the reported cross-validation values, the proprietary model at Vela (trained without cross-validation) achieves 10x the baseline and 2.29x the cross-validated GPTree with a precision of 17.9%, post-scaling and after normalizing that to the real world distribution. We utilized a different train-test split and dedicated a significant amount of effort to refine the tree based on advice from VCs at Vela Partners. For the purpose of academic studies, we have omitted that in this section given that there was no cross-validation performed on that model due to the intensive time required for fine-tuning."}, {"title": "5. Training details", "content": "This section describes the GPTree training strategy. We implement several parameters/features present in scikit-learn Decision Tree Classifier.\nInitialization and hyperparameters. To prevent overfitting, we train our decision trees using a maximum tree depth of 18 and a minimum of 31 (0.5%) samples per leaf node. These hyperparameters are chosen to ensure a balance between model complexity and generalization performance. We perform summarization with a batch size of 250 samples.\nCross-Validation. To demonstrate the robustness of our approach, we perform 5-fold cross validation, considering all ten possible combinations of three folds (i.e., $\\binom{10}{3}$) for training, with two different ways to assign validation and test folds. We generate 10 distinct trees, and report the averaged performance metrics over all 20 partitions. This reduces the variance and ensuring that the reported performance is not dependent on specific fold assignments. We cross-validate with a validation in order to perform expert-in-the-loop.\nOptimization. Similar to traditional decision trees, we use the Gini impurity to measure the quality of splits at each node. At each iteration, the optimizer selects the question candidate, which minimizes the weighted Gini impurity of the resulting child nodes. This ensures that each split creates the most homogeneous subtrees possible. Post training, we select the sensitivity on the validation set, which optimizes the $F_{0.5}$ score (favouring precision over recall).\nFine-tuning expert-in-the-loop. We fine-tuned the trained decision tree with expert in the loop on the validation set. It includes rebuilding subtrees at certain nodes and collapsing the tree at certain nodes. Then we test the fine-tuned tree on a held out test set.\nTraining time. A typical training of 6000 samples using gpt-4o-mini typically takes 10 hours on a single 8-core CPU costing about $30 in API usage. This also scales based on the number of input features that are present, which affects the number of question candidates at each stage. For comparison, gpt-4o is 40% faster for question answering but 33x more expensive. For the full cross-validation process, which involves training 10 distinct trees, the total training time is approximately four days followed by two days of work for the expert refinement. The main bottleneck lies in the speed of API calls. However, there is potential for further acceleration through the use of more CPU cores for parallel processing."}, {"title": "6. Conclusion", "content": "In this paper, we introduced GPTree, a novel LLM-powered decision tree model, with an efficient expert-in-the-loop mechanism, emphasizing the harmony between human expertise and machine intelligence. We presented empirical evidence demonstrating the efficacy of our approach, and highlighting its ability to enhance predictive accuracy and decision-making processes in the VC industry."}, {"title": "6.1. Future work", "content": "As foundation models continue to evolve, we expect that GPTree's performance will scale, making it applicable to other domains, such as explainable healthcare diagnosis. In the future, we expect that this work can be generalized to multi-modal application including images, video and audio."}, {"title": "6.2. Limitations", "content": "While our work presents promising advancements, we recognize that it has several limitations: 1) Unreliability of CODE execution nodes; 2) Non-deterministic LLM evaluations (i.e. different phrasings of similar questions can result in different results); 3) Hallucination when there is insufficient information to answer the questions.\nIt is important to note that the findings presented are inherently limited to the scope and characteristics of the dataset. They may reflect biases associated with the voluntary provision, or omission, of information by the founders. Additionally, due to the nature of data acquisition through scraping techniques, there may be data quality issues that could potentially lead to inaccurate conclusions. Readers should exercise caution and consider these limitations when interpreting the results.\nAlthough we demonstrate the effectiveness of our approach using a founder success dataset, this paper is not intended as financial advice, investment guidance, or a recommendation to engage in any financial activities. Some publicly available datasets utilized in this study have been augmented with paid data sources, which may restrict the wide distribution of the underlying enriched training dataset."}, {"title": "Impact Statement", "content": "The goal of the work presented in this paper is to advance the field of Machine Learning, emphasizing a harmonic relationship between humans and machines. All datasets have been processed in strict adherence to the relevant code of conduct."}]}