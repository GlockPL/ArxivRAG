{"title": "AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution", "authors": ["David S. Bhatti", "Yougin Choi", "Rahman SM Wahidur", "Maleeka Bakhtawar", "Sumin Kim", "Surin Lee", "Yongtae Lee", "Heung-No Lee"], "abstract": "Hyperspectral Imaging (HSI) is a cutting-edge technology that captures comprehensive spatial and spectral data, enabling the analysis of features invisible to conventional imaging systems. This capability supports in-depth investigations of object composition, condition, and transformation, making HSI a critical tool across a wide range of applications, including weather monitoring, food quality control, counterfeit detection, healthcare diagnostics, face anti-spoofing, and extending into fields such as defense, agriculture, and industrial automation. HSI has evolved significantly due to advancements in spectral resolution, device miniaturization, and computational methods, broadening its application scope. This study offers a comprehensive overview of HSI, detailing its fundamental principles, diverse applications, challenges in data fusion, and the pivotal role of deep learning models in HSI processing. We explore how the integration of multimodal HSI with advanced AI models, particularly deep learning frameworks, has substantially improved classification accuracy and operational efficiency. Furthermore, we discuss how deep learning has enhanced multiple aspects of HSI analysis, such as feature extraction and reduction, target and change detection, denoising, unmixing, spatial-spectral attention, dimensionality reduction, land cover mapping, data augmentation, domain adaptation, spectral reconstruction, compression, and super-resolution. An emerging area of focus is the innovative fusion of hyperspectral cameras with large language models (LLMs), referred to as the \"high-brain LLM.\" This integration enables advanced applications, including low-visibility crash detection and face anti-spoofing, while empowering LLMs to generate actionable human-oriented alerts and insights. Additionally, we highlight key players in the HSI industry, its Compound Annual Growth Rate (CAGR), and the rapid expansion and industrial significance of the technology. This work aims to serve both technical and non-technical audiences, offering valuable insights for multidisciplinary researchers and industry practitioners. By addressing open research challenges, emerging trends, and the integration of HSI with deep learning and LLMs, this study provides a thorough understanding of HSI's current landscape and promising future directions. Presented in a tutorial format, this study equips readers to apply these insights to their respective fields, while also providing information on HSI datasets and software libraries, allowing researchers to effectively engage with this domain.", "sections": [{"title": "I. INTRODUCTION", "content": "HSI captures detailed spatial and spectral data, enabling the analysis of features that traditional imaging systems cannot detect. This makes HSI invaluable across diverse fields such as weather monitoring, crop protection, food quality control, and counterterrorism. Stored as a three-dimensional hypercube, HSI combines spatial and spectral dimensions (height, width, wavelength), allowing in-depth analysis of materials, composition, and transformations. Since its inception in the 1960s, HSI has evolved from multispectral sensors in remote sensing to advanced applications across environmental monitoring, healthcare, defense, agriculture, and more. The term \"hyperspectral\" was first defined in 1983 as involving over 100 spectral bands, enabling material identification [1]. However, HSI still faces challenges such as spectral unmixing and data fusion, requiring sophisticated approaches. The integration of AI, Machine Learning (ML), and Deep Learning (DL) has transformed HSI analysis, significantly improving object detection and classification accuracy. The combination of multimodal HSI and advanced AI models is driving the development of more effective systems for defense, technology, and societal applications.\nOur analysis of the Web of Science (WOS) database reveals the continued growth of HSI research, reflecting its expanding application range from environmental monitoring to medical diagnostics.\nWe have observed that most surveys on HSI focus on specific areas and do not provide a comprehensive overview, leaving readers to search for multiple articles on the same topic. For example, Zhang et al. [2] only address image reconstruction from RGB (Red, Green, Blue) to HSI and its associated challenges. Sethi et al. [3] focus solely on HSI applications in agriculture, with little attention paid to the outdated discussion on HSI's Compound Annual Growth Rate (CAGR). Khan et al. [4] and Bhargava et al. [5] provide detailed reviews on HSI applications. Gu et al. [6] focus exclusively on multimodal data acquisition, processing, and challenges. Kumar et al. [7] provide an excellent survey on deep learning for HSI classification, critically discussing the pros and cons of various studies and the challenges of small data samples. However, this survey is limited to deep learning applications in HSI classification alone. Other reviews include [8], which highlights image restoration methods; [9], which reviews trends in HSI for medical imaging; [10], which explores HSI for nanoscale materials research; [11], which reviews attention-based HSI classification; and [12], which reviews methods for texture and wavelength feature selection. However, these studies cover only a small fraction of the overall HSI landscape and lack a tutorial format.\nOur study overlaps with Kumar et al. [7] but differs significantly in terms of the applications of deep learning in HSI. While Kumar et al. focus exclusively on classification, we provide insights into which deep learning models are suitable for various HSI tasks, such as feature extraction and reduction, target and change detection, denoising, unmixing, spatial-spectral attention, dimensionality reduction, land cover mapping, data augmentation, domain adaptation, spectral reconstruction, compression, and super-resolution. Our emphasis on HSI multimodality, DL-based fusion of HSI data, recent challenges, potential solutions, trends, CAGR, and a tutorial approach to image pre-processing, DL-based image reconstruction, feature extraction, and classification offers a more comprehensive perspective than Kumar et al. [7].\nBased on a thorough review of existing surveys and reviews, we are confident that this write-up is more comprehensive, well-composed, and presented in a tutorial format. It effectively serves both technical and non-technical readers, catering to multidisciplinary researchers and those keen to explore new research dimensions through the integration of HSI, deep learning, and LLMs."}, {"title": "A. Motivation", "content": "Our motivation for conducting this article is multifaceted:\n1) To analyze the role of HSI in detecting and analyzing objects not detectable by conventional imaging systems.\n2) To explore how deep learning can enhance HSI's capabilities, addressing its challenges more efficiently and with greater accuracy.\n3) To investigate the opportunities of merging LLMs with hyperspectral cameras for generating human-language-oriented prompts and alerts.\n4) To examine the growth of the HSI industry, including a study of the CAGR predicted by leading business analysis and statistics organizations.\n5) To complete a manuscript that may serve the purpose of learning for new researchers in DL-based HSI.\nThe manuscript is structured into the following sections:\nII-Research Methodology: This section details the research methodology followed by the researchers in this study.\nIII-Understanding HSI: This section provides a comprehensive background and understanding of HSI.\nIV-HSI Pre-Processing: Building on the previous section, this part discusses preprocessing techniques essential for computational analysis in HSI.\nV-Augmenting HSI with Deep Learning: Various deep learning models, including CNNs (Convolutional Neural Network), DBNs (Deep Belief Networks), RNNs (Recurrent Neural Networks), LSTMs (Long Short-Term Memory), GRUs (Gated Recurrent Units), GANs (GANs), transformers, autoencoders, and stacked autoencoders, are explored for their applications in HSI tasks such as feature extraction, dimensionality reduction, classification, object and change detection, data fusion, augmentation, denoising, and spectral unmixing.\nVI-Multimodal HSI, Fusion, and Challenges: This section introduces Multimodal HSI, data fusion challenges, and the role of LLMs in HSI applications, presenting new research dimensions.\nVII-CAGR: This section examines the annual growth rate of the HSI industry.\nVIII-Applications of HSI: A broad range of HSI applications in fields such as healthcare, environmental monitoring, defense, forensics, and microscopy are discussed.\nIX-Challenges and Recent Trends: Key challenges and their solutions in HSI and emerging trends shaping the field are highlighted.\nX-Conclusion and Future Work: The study concludes with a summary of findings and directions for future research in HSI."}, {"title": "II. RESEARCH METHODOLOGY", "content": "For writing this article, the guidelines laid down by PRISMA [13] were followed, with significant help from [14]. The PRISMA guidelines, set by medical and health science experts, are also applicable for systematic literature surveys, reviews, and tutorials in other domains. A summary of the key steps followed in this project is briefly discussed below.\nStep-1 Conception & Research Questions: Driven by AI growth and HSI's potential to address social, industrial, and technological challenges, the idea was conceived by the researchers working on HSI, AI and LLMs to explore and review true potential of AI-driven HSI. Then to effectively address it, following questions were formulated, which this study can address.\n1) What is HSI, HSI image, signature, HSI Pixel, and hypercube?\n2) How do single-modal and multimodal HSI systems differ in data acquisition, fusion, challenges, and AI tools for processing HSI images?\n3) What is the role of AI in enhancing HSI systems, particularly in learning, classification, and challenges?\n4) What is the CAGR of the HSI industry, and what factors contribute to its growth?\n5) What are the current challenges, open research issues, and emerging trends in HSI technology.\nStep-2 Research Team Formation: A team of researchers specializing in AI, HSI, and communication was formed.\nStep-3 Research Method (articles and journals selection): The team decided on a unified approach and specific criteria for selecting articles and journals. The keywords used in the search included HSI (Hyperspectral Imaging), HSI basics, signature, hypercube, spectral unmixing, acquisition methods, electromagnetic spectrum, preprocessing, multimodal HSI, data fusion, LLMs, AI, machine learning, deep learning, CNNs, DBNs, GANs, RNNs, transformers in HSI, HSI CAGR, key players, and trends in HSI. Only articles from 2015-2025 were considered, with a few exceptions. Journals from publishers like IEEE (Institute of Electrical and Electronics Engineers), ACM (Association for Computing Machinery), Springer, Elsevier, Wiley-Blackwell, and Taylor & Francis were included. Articles from databases like Web of Science, Scopus, and SpringerLink were also considered. Only articles with an impact factor greater than zero were included.\nStep-4 Documentation & Reporting: Selected articles were reviewed and their findings documented in paragraphs, images, graphs, and tables by the research team. Research gaps, challenges, and unaddressed issues were highlighted, and the CAGR of HSI in the international market was reported.\nStep-5 Repetitive Review, Updating, and Submission: This study was continuously reviewed through periodic meetings. The final report, after revisions, was submitted for publication."}, {"title": "III. UNDERSTANDING HYPERSPECTRAL IMAGING", "content": "HSI generates high-resolution, multi-spectral images by capturing a continuum of spectral lines across a wide range of wavelengths. Unlike multispectral sensors, which capture images in broad wavelength bands, hyperspectral sensors collect data across dozens to hundreds of narrow, contiguous spectral bands, enabling the extraction of a continuous spectrum for each pixel, as depicted in Figure 4.\nHyperspectral cameras capture contiguous wavelengths across visible, near-infrared (NIR), short-wave infrared (SWIR), and mid-wave infrared (MIR) spectra, achieving spectral resolutions as fine as a nanometer. Light interacting with the sensor is dispersed into numerous spectral bands, forming a hypercube, which is a three-dimensional dataset with two spatial and one spectral dimension, as shown in Figure 5 and Figure 4. This allows for the identification of materials based on their spectral signatures, such as vegetation, soil, and minerals. Slight variations in these signatures help differentiate plant species. After applying corrections for sensor characteristics, atmospheric conditions, and terrain effects, extracted spectra can be compared with field or laboratory data for material mapping. Hyperspectral imaging employs different acquisition methods: spatial scanners capture spectral data over time, while snapshot imagers use a focal plane array for instantaneous spectral fingerprints. Effective interpretation of HSI data requires an understanding of material properties and their spectral responses [4], [15]."}, {"title": "A. Electromagnetic Spectrum: Information in HSI Image", "content": "Electromagnetic waves travel through space via oscillating electric and magnetic fields and can propagate through air, solids, and vacuum. The electromagnetic spectrum spans from radio waves to gamma rays, with visible light being a small segment. Each wavelength has varying energy levels, affecting how materials absorb or reflect light [16]. In hyperspectral imaging, this principle is crucial. By analyzing different wavelengths, hyperspectral imaging identifies material properties and environmental conditions, allowing precise analysis. Understanding electromagnetic wave interactions helps interpret hyperspectral data, making it valuable for remote sensing, agriculture, and medical diagnostics. The electromagnetic spectrum and HSI data across its bands are shown in Figure 6 and Figure 7."}, {"title": "B. HSI Acquisition Methods", "content": "In HSI systems, various image acquisition methods offer distinct advantages and trade-offs. The whiskbroom method employs point scanning, providing high-resolution imaging over large areas. It is widely used in satellite imaging and environmental monitoring due to its precision, though its long acquisition time can be a drawback [17]. Similarly, the pushbroom method uses line scanning, offering large coverage with high resolution. It is commonly applied in remote sensing and agriculture, where continuous data collection is essential. However, like whiskbroom scanning, its acquisition time limits its usability in dynamic environments. In contrast to pushbroom, spectral filter based HS imaging uses spectral filters, like absorption or interference filters, to capture specific spectral bands [17]. The staring method relies on wavelength scanning, enabling high spatial resolution within a narrow range. This makes it particularly useful for applications like mineral mapping and surface analysis. Despite its efficiency, its lower spectral resolution and restricted working range may limit broader applications [18], [19]. The snapshot method stands out for its rapid acquisition time and compact size. It is ideal for real-time imaging applications such as medical diagnostics and rapid environmental assessments. However, this method sacrifices both spectral and spatial resolution, making it less suitable for high-detail analysis [17]. Each method balances resolution, speed, and coverage based on application needs. Figure 8 illustrates whiskbroom, pushbroom, starring and snapshot for better understanding."}, {"title": "C. HSI Hypercube", "content": "HSI hypercube is a three-dimensional dataset where two dimensions represent spatial information (height, width), and the third dimension represents spectral information (wavelength), shown in Figure 4 where x, y, \u03bb are representing height, width and wavelength. Spatial resolution defines the smallest ground area each pixel represents. Hyperspectral imaging has lower spatial resolution than multispectral or panchromatic imaging due to the need to capture many spectral bands. Satellite sensors typically range from 10 to 30 meters per pixel (e.g., A:National Aeronautics and Space Administration (NASA) Hyperion, 30m) and airborne sensors range from 1-20m (e.g., CASI:Compact Airborne Spectrographic Imager, AISA:Airborne Imaging Spectrometer for Applications). UAV (Unmanned Aerial Vehicle) sensors offer the highest resolutions (0.01-0.5m), such as Headwall Hyperspec. Despite lower spatial resolution, HSI's high spectral resolution enhances applications like vegetation monitoring, mineral analysis, and water quality assessment [5]. Spectral resolution measures a sensor's ability to distinguish wavelengths. Higher spectral resolution enables precise material identification. HSI captures many narrow bands across visible, near-infrared, and mid-infrared regions. NASA's Hyperion provides 10 nm resolution, ESA'S PROBA-CHRIS offers 34 nm (19 bands) and 17 nm (63 bands), while airborne sensors like AVIRIS (10 nm) and AISA (3.3 nm) offer finer detail. UAV sensors, like Headwall Hyperspec (2.5 nm), enhance spectral resolution [5]. Temporal resolution refers to how often a sensor captures data from the same location. High temporal resolution allows frequent revisits, while low resolution indicates longer intervals. This is crucial for weather patterns, environmental monitoring, and change detection [5]."}, {"title": "D. Hyperspectral Signature: HSI Pixel", "content": "Hyperspectral imaging signatures represent the unique spectral characteristics of materials or objects. HSI captures and processes data across the electromagnetic spectrum, providing spectral information for each pixel. Materials reflect, absorb, or emit electromagnetic radiation differently across wavelengths, creating distinct spectral \"fingerprints.\" These signatures enable the identification and analysis of materials based on their spectral properties. For example, vegetation, water, soil, and minerals each have distinct signatures, and subtle variations in plant species allow for differentiation [20]."}, {"title": "IV. HSI IMAGE PROCESSING AND PRE-PROCESSING", "content": "Hyperspectral imaging, also referred to as imaging spectroscopy, emerged from the integration of traditional spectroscopic techniques with modern imaging system technologies. Spectrometry captures specific spectral data that facilitates the identification and analysis of materials, providing insights into their composition and related properties. Spectroscopy, in essence, examines the interaction between light and matter to reveal the intrinsic characteristics of a substance. Conversely, imaging systems are designed to translate the visual representation of an object's internal structure into digital signals, which are subsequently processed by computational systems to generate a digital image. These systems typically encompass a camera, optical lens, and an illumination source. When combined, spectroscopy and advanced imaging technologies form the foundation of hyperspectral imaging, enabling the precise measurement of spectral content at each pixel of an image [21]."}, {"title": "A. Hyperspectral Band Selection", "content": "Hyperspectral imaging sensors offer exceptional spectral resolution by capturing responses across hundreds of narrow bands, essential for applications like environmental monitoring and target detection. However, the data generated by these sensors, such as NASA's Hyperspectral Infrared Imager, which produces 65 Mb/s data rate leading to 372 Gb per orbit and 5.2 Tb per day creating computational challenges [22]. This vast data volume increases processing demands and worsens the \"curse of dimensionality,\u201d where classification accuracy drops with additional spectral bands. To address this, hyperspectral band selection techniques reduce redundancy and computational costs while preserving essential information. Methods include ranking-based, searching-based, clustering-based, sparsity-based, embedding-learning-based, and hybrid approaches. Ranking-based methods select top K bands but ignore inter-band correlations [23]. Searching-based methods optimize a cost function but are computationally intensive [24]. Clustering-based methods, like K-means, ensure noise resilience but may converge on suboptimal selections [25]. Sparsity-based approaches reduce data complexity but add performance uncertainty [26]. Embedding-learning methods integrate selection with learning models like SVMs, offering efficiency but requiring complex design [27]. Hybrid methods combine strategies for effective band selection but require careful implementation [28]. The goal of band selection is to maximize information content, minimize redundancy, and enhance class separability, improving classification accuracy, as shown in Table I."}, {"title": "B. Classification", "content": "HSI can be categorized by factors such as data acquisition method, wavelength band, and the number of spectral bands, which determines resolution. Hyperspectral imaging is broadly classified based on the acquisition method, either spatial or spectral scanning, each with advantages in how data is captured and processed into a hyperspectral cube, as explained in section III-B. The measurement spectrum band is another key criterion for classifying hyperspectral cameras, which influences their application. Bands are categorized into UV (200-400 nm), VIS (400\u2013600 nm), NIR (700\u20131,100 nm), SWIR (1.1-2.5 \u00b5m), and MWIR (2.5\u20137 \u00b5m) [36], [37]. For example, UV-SWIR is used in biomedical fields, VIS-SWIR in atmospheric monitoring, and SWIR\u2013MWIR in defense. Hyperspectral imaging can also be classified by the number of spectral bands: systems with 10 or fewer bands are multispectral, those with 10 or more bands are hyperspectral, and systems with 1,000+ bands are ultra-hyperspectral. Typical spectral resolution for hyperspectral imaging is \u2206\u03bb/\u03bb \u2248 0.01. Lower resolution classifies as multispectral (${\\Delta}{\\lambda}/{\\lambda}$ \u2248 0.1), and higher as ultra-hyperspectral (${\\Delta}{\\lambda}/{\\lambda} > 0.001$). Applications vary by classification: multispectral is for macroscopic object classification, hyperspectral for chemical composition analysis in solids or liquids, and ultra-hyperspectral for gases [1]. A summarized view of this classification is given in Table II."}, {"title": "C. Compression and Transmission", "content": "HSI image compression and transmission differ from regular RGB or grayscale images due to the high dimensionality of data across spatial and spectral bands. Efficient compression is vital to preserve spectral and spatial information [38]. Spatial redundancy can be reduced using methods like wavelet compression, discrete cosine transform, and block compression [39]. Techniques such as principal component analysis (PCA), independent component analysis (ICA), or singular value decomposition can reduce hyperspectral data dimensionality [40]. Band selection or fusion can also merge similar bands [41]. After compression, entropy encoding (e.g., Huffman or arithmetic coding) reduces frequent values to fewer bits [42]."}, {"title": "D. Spectral Unmixing", "content": "HSI differentiates materials based on spectral fingerprints, but spectral mixing remains a challenge, where a single pixel captures multiple materials due to limited spatial resolution. This occurs in two forms: linear mixing, when materials are spatially separated within a pixel, and nonlinear mixing, arising from material interactions. Addressing these distinctions enhances HSI precision [43]. Factors such as sensor resolution, material heterogeneity, and surface interactions contribute to spectral mixing. In agriculture, soil, crops, and water create mixed signatures, while urban and forest environments involve additional complexities. Spectral unmixing techniques decompose mixed pixels into endmembers through endmember extraction and abundance map estimation. Methods like Pixel Purity Index (PPI), Fast Iterative Pixel Purity Index (FIPPI), and N-Finder (N-FINDR) identify endmembers. Abundance map estimation determines each endmember's proportion within a pixel, improving data interpretability \u00b9, as shown in Figure 9."}, {"title": "E. Sub-Pixel Classification", "content": "Sub-pixel classification in HSI identifies multiple materials within a single pixel, which is common due to limited spatial resolution. This occurs in remote sensing applications where features like vegetation, soil, or urban structures are mixed within one pixel. It addresses spectral mixing through unmixing techniques like the linear mixture model and least-squares linear unmixing, which decompose mixed pixels into endmembers and estimate abundance fractions. Unlike hard classification, sub-pixel classification uses soft classification to assign fractional class memberships, improving accuracy. This approach is applied in land cover analysis, precision agriculture, and mineral mapping, with deep learning methods also emerging [44], [45].\n1) Linear Mixture Model: In the linear mixture model, each pixel's spectral value in a HSI image is represented as a combination of the spectra of pure components (endmembers) within that pixel [43]. Mathematically, this model can be expressed as: $P_{i} = \\sum_{j=1}^{n} F_{j} \\cdot R_{ij} + E_{i}$. While expanding this equation across all spectral bands gives:\n$P=RF+E$ (1)\nthis represents an inversion problem, where we attempt to determine unknown causes based on observable data. In HSI unmixing, this means estimating the proportion of each material present in a pixel based on the combined light spectrum detected by the sensor. The observed spectrum is a mixture of the known spectra of pure materials (endmembers), and the challenge lies in determining the fractional abundance of each material within the pixel. In Equation 1, P is the observed spectrum, R contains the known spectra of the materials, F represents the unknown fractions of each material that we seek to determine, and E accounts for errors or noise. Solving this inversion problem involves estimating the values of F, which is modeled as a system of linear equations in Equation 2.\n$\\begin{bmatrix}P_{1}\\\\P_{2}\\\\:\\\\P_{m}\\end{bmatrix} = \\begin{bmatrix}R_{11} & R_{12} & ... & R_{1n}\\\\R_{21} & R_{22} & ... & R_{2n}\\\\: & : & & :\\\\R_{m1} & R_{m2} & ... & R_{mn}\\end{bmatrix} \\begin{bmatrix}F_{1}\\\\F_{2}\\\\:\\\\F_{m}\\end{bmatrix} + \\begin{bmatrix}E_{1}\\\\E_{2}\\\\:\\\\E_{m}\\end{bmatrix}$ (2)\nTo obtain a unique solution for the inversion problem, it is assumed that the number of spectral bands m is greater than the number of endmembers n in the pixel. Additionally, to ensure a physically realistic solution, two constraints are applied: (i) $\\sum_{j=1}^{n} F_{j} = 1$, which ensures that the sum of the fraction coefficients equals one, representing the entire pixel area; and (ii) $F_{j} \\geq 0$ for $j = 1, . . ., n$, which ensures that each fraction coefficient is non-negative to avoid negative areas. These constraints ensure that the model accurately reflects the contributions of each endmember to the observed pixel spectra. However, selecting an adequate number of endmembers remains a challenge, as insufficient endmembers can lead to inaccurate unmixing results [46].\n2) Least-Squares (LS) Linear Unmixing: In the least-squares approach to the inversion problem, the unmixing coefficients are found by minimizing the sum of the squares of the errors. When the constraints (i) and (ii) discussed above are ignored, it is equivalent to solving a set of equations of the following form: $\\frac{\\partial}{\\partial F_{i}} (\\sum_{i=1}^{m} (P_{i} - \\sum_{j=1}^{n} F_{i}R_{i})) = 0$. Expanding this equation results in the classical multiple linear regression matrix equation, and the least-squares fit estimation for the unmixing coefficients $F_{j}$ becomes $F = (R^{T}R)^{-1} R^{T} P$. Taking the difference between the observed and the calculated spectral reflectance results in the estimated error terms of the observations as $E = P - RF$. The variance of the error terms is a quantitative measure of how well the mixture modeling fits the data, which indicates the feasibility of the solution. The estimation of the variance is $\\sigma^{2} = \\frac{E^{T}E}{m-n}$. The least-squares solution can be modified to fulfill the requirements of constrained fits. For the first requirement, the estimated coefficients $F_{j}$ are modified by taking the linear constraints $AF = b$ into account:\n$F = (R^{T}R)^{-1} R^{T} P+ (R^{T}R)^{-1} A^{T} (A (R^{T}R)^{-1} A^{T})^{-1} (b-AF)$ (3)\nWhere A is a $1 x n$ matrix defined as: $A = [111...1], b = [1]$. No analytical solutions are known for the inversion problem when the coefficients are constrained by inequalities. The use of iterative approaches, such as the simplex method, is needed to implement those constraints [46]. Other mathematical methods used for unmixing include PCA, Supervised Classification Analysis (SCA), and Multivariate Curve Resolution (MCR)."}, {"title": "V. AUGMENTING HSI WITH DEEP LEARNING", "content": "Instead of just referring to HSI, it is now more appropriate to call it \"AI-driven HSI,\" where deep learning (DL) has revolutionized HSI and multimodal HSI by enhancing the processing and interpretation of high-dimensional data. HSI captures a wide spectrum of wavelengths, which presents challenges due to its complexity and large volume. Traditional machine learning methods struggle with such data, but DL models, particularly CNNs, excel by automatically learning representations from raw data, making them effective for tasks like material classification, anomaly detection, and environmental monitoring. In multimodal HSI, DL facilitates the fusion of data from sources like LiDAR (Light Detection and Ranging), thermal imaging, and SAR (synthetic aperture radar), enabling richer feature extraction and more accurate analyses [47]\u2013[54]. For example, combining hyperspectral and thermal data improves precision agriculture by detecting early signs of crop health issues [55]\u2013[58]. DL excels in modeling complex spatial-spectral correlations, with CNNS, transformers, and autoencoders effectively capturing patterns between spectral bands, improving classification and detection in HSI. This has advanced fields such as urban planning, environmental monitoring, and medical diagnostics [59], [60]. As DL evolves, its role in multimodal HSI will expand, enhancing data fusion for applications like remote sensing and industrial inspection. Moreover, advances in computational resources and open-source DL libraries like TensorFlow and PyTorch have lowered the barriers to deploying sophisticated models for HSI [61]."}, {"title": "A. State-of-the-art DL Models and Networks", "content": "Deep learning models such as Deep Neural Networks (DNNs), Multilayer Perceptrons (MLPs), and CNNs are essential in HSI and multimodal HSI tasks like classification, anomaly detection, and feature extraction. MLPs are effective in pixel-wise classification, leveraging high-dimensional spectral inputs to learn non-linear relationships, making them suitable for small datasets or hybrid approaches. CNNs, commonly used in environmental monitoring and object identification, capture spatial hierarchies through convolutional and pooling layers. For tasks involving temporal or sequential data, models like RNNs and their advanced variants, LSTM networks and GRUs, are key in multimodal HSI. Autoencoders assist in dimensionality reduction by compressing and reconstructing high-dimensional spectral data, while GANs generate new spectral data, augmenting datasets or reducing noise. Recent advancements like Vision Transformers (ViTs) and DBNs enhance feature representation and clustering in HSI. Hybrid models like CNN-LSTM combine spatial and spectral data for better classification and anomaly detection.\nIn multimodal HSI, DL models such as ResNet50, VGG16, InceptionV3, and DenseNet are crucial for data fusion tasks involving multiple sensors. These models enhance applications like urban planning, land-use mapping, and environmental monitoring by fusing hyperspectral data with LiDAR or thermal imaging. For real-time object detection in HSI, Faster R-CNN and YOLO provide fast, accurate analysis, crucial for autonomous aerial monitoring using hyperspectral drones [62]. In land use mapping or infrastructure monitoring, these models improve detection accuracy by integrating HSI data with additional inputs like LiDAR or RGB imagery."}, {"title": "B. Basic Understanding of HSI Image Reconstruction", "content": "HSI captures images across a wide spectrum, providing rich spectral information for each pixel. However, reconstructing HSI can be challenging due to noise and distortion. To address this, techniques like regularization methods (L1 and L2 regularization, Tikhonov regularization, and total variation regularization) [99], [100], optimization algorithms (gradient descent, Adam optimizer, proximal gradient methods, alternating least squares, and coordinate descent) [101], [102], and advanced deep learning-based methods have been developed. Deep learning, especially CNNs, excels at identifying patterns by leveraging neighboring wavelengths and intensities, enabling accurate reconstruction of spectra from limited measurements. During acquisition, intensity measurements are collected across spectral bands and represented as a 3D data cube. The observed intensity at wavelength \u03bb for pixel i can be expressed as:\n$I_{i}(\\lambda) = S_{i}(\\lambda) \\cdot x(\\lambda) + n_{i}(\\lambda)$ (4)\nwhere $S_{i}(\\lambda)$ is the spectral sensitivity, $x(\\lambda)$ is the target spectrum, and $n_{i}(\\lambda)$ is measurement noise. The measured intensities are arranged into feature vectors for each pixel:\n$I_{i} = [I_{i}(\\lambda_{1}), I_{i}(\\lambda_{2}), ..., I_{i}(\\lambda_{N})]^{T}$ (5)\nThese feature vectors serve as input to a deep learning model, commonly based on CNNs like U-Net, which effectively capture spatial and spectral features. The training process involves minimizing the difference between the reconstructed and ground truth spectra using a loss function, such as Root Mean Square Error (RMSE):\n$RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}||X_{recovered,i} - X_{GT,i}||_{2}^{2}}$ (6)\nAfter training, the model is evaluated on a test set, and performance is assessed using metrics like RMSE or Peak Signal-to-Noise Ratio (PSNR). For new intensity measurements, the reconstructed spectrum is given by:\n$X_{recovered,j} = DL(I_{j})$ (7)\nDeep learning offers advantages such as improved accuracy, robustness to noise, and flexibility for different applications."}, {"title": "C. Basic Understanding of HSI Image Feature Extraction", "content": "Understanding HSI feature extraction using deep learning is crucial. The goal is to extract both spectral and spatial information", "103": ".", "71": [104], "105": [107], "108": "Autoencoder [109", "110": ".", "47": ".", "x_{B}": "where B is the number of spectral bands [111", "111": "which can be expressed as:\n$y_{i"}, {"111": ".", "as": "n$Y_{i,j,b} = \\sum_{m=-k}^{k}\\sum_{n=-k}^{k}\\sum_{p=-k}^{k} W_{m,n,p}.X_{i+m,j+n,b+p}$\nHere, $Y_{i,j,b}$ is the output feature at spatial position (i, j) and spectral band b, with $W_{m,n,p}$ as the 3D convolutional kernel weights, capturing spatial and spectral dependencies. To address the high dimensionality of hyperspectral data, autoencoders are often used for dimensionality reduction by learning compressed data representations."}]}