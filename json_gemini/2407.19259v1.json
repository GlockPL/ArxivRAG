{"title": "Fine-Grained Scene Graph Generation via\nSample-Level Bias Prediction", "authors": ["Yansheng Li", "Tingzhu Wang", "Kang Wu", "Linlin Wang", "Xin Guo", "Wenbin Wang"], "abstract": "Scene Graph Generation (SGG) aims to explore the rela-\ntionships between objects in images and obtain scene summary graphs,\nthereby better serving downstream tasks. However, the long-tailed prob-\nlem has adversely affected the scene graph's quality. The predictions\nare dominated by coarse-grained relationships, lacking more informative\nfine-grained ones. The union region of one object pair (i.e., one sample)\ncontains rich and dedicated contextual information, enabling the pre-\ndiction of the sample-specific bias for refining the original relationship\nprediction. Therefore, we propose a novel Sample-Level Bias Prediction\n(SBP) method for fine-grained SGG (SBG). Firstly, we train a classic\nSGG model and construct a correction bias set by calculating the mar-\ngin between the ground truth label and the predicted label with one\nclassic SGG model. Then, we devise a Bias-Oriented Generative Adver-\nsarial Network (BGAN) that learns to predict the constructed correc-\ntion biases, which can be utilized to correct the original predictions from\ncoarse-grained relationships to fine-grained ones. The extensive experi-\nmental results on VG, GQA, and VG-1800 datasets demonstrate that our\nSBG outperforms the state-of-the-art methods in terms of Average@K\nacross three mainstream SGG models: Motif, VCtree, and Transformer.\nCompared to dataset-level correction methods on VG, SBG shows a sig-\nnificant average improvement of 5.6%, 3.9%, and 3.2% on Average@K\nfor tasks PredCls, SGCls, and SGDet, respectively. The code will be\navailable at https://github.com/Zhuzi24/SBG.", "sections": [{"title": "1 Introduction", "content": "In recent years, Scene Graph Generation (SGG) has emerged as a popular area\nof research. SGG aims to generate a structured summary graph from an im-"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Scene Graph Generation", "content": "SGG [26, 30, 47, 49] decodes images into structured semantic graphs, supporting\nvarious downstream tasks [10, 12, 33, 38, 54]. Early works were primarily dedi-\ncated to designing models to achieve the relationship predictions between the ob-\njects. [31] leveraged language priors from semantic word embeddings to finetune\nthe predicted relationships, [5] exploited the statistical dependencies between\nobjects and their relationships, and [27] designed a ranking objective function\nby enforcing the annotated relationships to have higher relevance scores. The\nmethod described above neglected the rich visual context information from im-\nages. To address this problem, some methods designed elaborate feature refine-\nment modules to encode the visual context information, such as message passing\nstrategies [23, 48], sequential LSTMs [43,53], graph neural networks [3, 29, 52],\nand self-attention networks [11,32,40]. In addition, there are now some datasets\nas well as methods [21,25] emerging in the remote sensing field.\nLater works focused on designing optimization frameworks to further im-\nprove the performance of SGG models. Many optimization frameworks were\nproposed to tackle the long-tailed problem of relationships. [42] used causal in-\nference for unbiased SGG, [41] proposed an energy-based constraint loss to learn\nrelationships in small numbers. [7,9] employed hierarchical or grouped strategies\nto gradually learn, thereby mitigating the impact of the long-tailed effect. [2,4]\ncorrected the relationship predictions to obtain the unbiased scene graph. [1]\nleveraged a within-triplet Bayesian network to eradicate the long-tailed effect.\n[20] proposed a compositional feature augmentation strategy to mitigate the bias\nfrom the perspective of increasing the diversity of triplet features. There were\nalso some methods using data augmentation strategies to improve the perfor-\nmance of SGG models, such as [8,13,55]. Optimization frameworks offer greater\nflexibility and improved malleability, so it is a promising research direction."}, {"title": "2.2 Long-Tailed Learning", "content": "Recently, several correction methods have emerged to address the long-tailed\nproblem in SGG. In Fig. 2, DLFE [4] and RTPB [2] employed different ways to\ncorrect the original predictions. DLFE estimated the per-class label frequency c\nand used it to correct the biased probabilities. By dividing the biased probabil-\nities by c, DLFE obtained unbiased probabilities. RTPB utilized the resistance\nbias b to enhance the model's focus towards tail relationships. RTPB adjusted\nthe relationship's classification logits by subtracting b, thereby correcting the\nbiased relationship predictions."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Problem Setting & Overview Framework", "content": "Problem Setting. The task of SGG is to generate a connected summary graph\nG from an input image I. The common SGG methods are the two-stage processes\ninvolving object detection followed by relationship prediction. In the first stage,\nwe detect all objects in the image I, denotes as O = {0;}. In the second stage,\nwe predict relationships R = {ri\u2192j} of object pairs (0\u017c, oj) and then generate\n(Oi,rij,oj) triplets. Therefore, the scene graph can be formulated as:\n$$G = \\{(0i, r_{ij}, O_j)|0_i, O_j \\in O, r_{i\\rightarrow j} \\in R\\}.$$ \nOverall Framework. Fig. 3 illustrates the overall structure of SBG, and the\nentire workflow follows the common two-stage SGG pipeline. Consistent with\nprevious methods [2, 42], we utilize Faster R-CNN [37] as the object detection\nnetwork. To address the long-tailed problem of relationships, we present a novel\nmethod SBP to realize the sample-level bias correction. More detailed analysis\ncan be seen in Sec. 3.2."}, {"title": "3.2 Sample-Level Bias Prediction", "content": "The unbiased relationship predictions can be recovered from the biased ones [4].\nIn an ideal scenario, training the SGG model on an unbiased dataset results in"}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Settings", "content": "Datasets. We conduct experiments on three datasets: VG, GQA, and VG-\n1800. In SGG, the most commonly used database is VG [19]. From the orig-"}, {"title": "4.2 Implementation Details", "content": "Object Detector. For VG and VG-1800, following [4], we employ a pre-trained\nFaster R-CNN [37] with ResNeXt-101-FPN [47] backbone. In the training stage,\nthe parameters of the detector are fixed to reduce the computation cost. For\nGQA, we train a Faster-RCNN with ResNeXt-101-FPN as the object detector,\nand then the detector reaches 26.0 (%) mAP on the test set.\nModel Settings. For the classic SGG model, we set the batch size to 16 and\nemploy a SGD optimizer [15] with an initial learning rate of 0.001. The training\nprocedure contains a total of 18,000 iterations. For SBP, BGAN is comprised\nof one-dimensional convolutions. The number of layers for G and D are 5 and\n3, respectively. Both of them employ an RMSProp optimizer [56] with initial\nlearning rates of 0.0001 and 0.0005. \u025b is set to 0.0001. The training process\ncontains a total of 4,000 iterations. All experiments are performed on NVIDIA\n24G GeForce RTX 3090 GPUs."}, {"title": "4.3 Experiments on VG", "content": "Comparison with the State-of-the-Art Two-Stage Methods on VG. We\ncompare our SBG with the state-of-the-art two-stage methods on three main-\nstream SGG models: Motif [53], VCtree [43], and Transformer [42], as illustrated"}, {"title": "5 Conclusion & Future Work", "content": "In this paper, to tackle the long-tailed problem, we propose one novel method\nSBP to conduct sample-level bias correction, and further generate the fine-\ngrained scene graph. Specifically, we design a BGAN to predict the sample-\nspecific bias. Extensive experiments on VG, GQA, and VG-1800 datasets val-\nidate the effectiveness and generalizability of our SBG. We believe that this\nwork contributes to the advancement of research in this field and offers insights\ninto tackling the long-tailed issue. Our future work aims to further enhance the\nperformance of the proposed method and extend its applicability to other tasks."}, {"title": "A Dataset Details", "content": "GQA [14] is a vision-and-language dataset, consisting of a total of 113k images.\nWe retain images only with the most frequent 160 object and 60 relationship cat-\negories for experiments. Then it contains 59,588 images, of which 41,773 (70%)\nimages are used for the training, and 17,815 (30%) images are used for the testing.\nWe follow [42] to sample a 5k validation set from the training set for parameter\ntuning. The detailed list of the most frequent 160 object and 60 relationship\ncategories is shown in Tab. 10.\nWe visualize the quantity distribution for each relationship as shown in Fig. 7,\nGQA exhibits a severe long-tailed effect, with a highly imbalanced distribution\nbetween head categories (e.g., \u201con\u201d, \u201cwearing", "of\u201d) and tail categories (e.g.,\n\u201ccontain\u201d, \u201cpulling\u201d, \u201cpulled by": "."}, {"title": "B Ablation Studies", "content": ""}, {"title": "iii) The Effect of Weight Factor \u03b1", "content": "To assess the impact of \u03b1 for SBG,\nwe conduct the PredCls task on Transformer model. We validate a range of\nvalues (0.050, 0.075, 0.100) for \u03b1. The performance is presented in Tab. 11.\nFrom the results, it can be observed that the A@50/100 metric achieves the\nhighest performance when \u03b1 is set to 0.075, indicating the optimal performance\nof SBG."}, {"title": "iV) The Effect of Training Mode", "content": "In Section 3.2, we employ a grad-\nual training mode, where the parameters of the classic SGG model are frozen\nafter the training, and subsequently, the training of BGAN is conducted. The\ncomparison between the gradual training and integrated training of SBG on the\nPredCls task of Transformer model is presented in Tab. 12. The results indicate\nthat the gradual training outperforms the integrated training. This is because\nSBG is trained based on the output of the classic SGG model. However, the\noutput of the classic SGG model using the integrated training is continuously\nvaried, thus leading to the unstable training for SBG."}, {"title": "V) The Superiority of BGAN for Sample-Level Bias Prediction", "content": "To demonstrate the sample-level bias's prediction capability of BGAN, which\nemploys the one-dimensional convolution network, we conduct a comparison in-\nvolving three networks: a conventional 5-layer fully connected network (denoted\nas FC5), a 5-layer one-dimensional convolutional network (denoted as 1D5), and\na fully connected BGAN (denoted as BGANFC), on the Predcls task of Trans-\nformer model. The results are presented in Tab. 13. It can be observed that in the\ncase of FC5 and 1D5 networks, the 1D5 network outperforms the FC5 network\nslightly, as the 1D5 network benefits from the translation invariance and strong"}, {"title": "Vi) The Analysis for Feature Mapping", "content": "In Section 3.2, when con-\nstructing the correction bias set, we utilize an encoder that includes a single\nlayer of transformer (denoted as Trans\u2081) to map high-dimensional features to\none-dimensional features. We compare this approach with a conventional fully\nconnected mapping (denoted as FC) and an encoder containing two layers of\ntransformer (denoted as Trans2), based on the Predcls task of Transformer\nmodel. The results are presented in Table Tab. 14. It is evident that using\nTrans\u0131 for feature mapping yields the best performance. Compared to FC,\nTrans\u0131 demonstrates superior performance by leveraging the strong interaction\ncapabilities of the transformer. Moreover, Trans2 is relatively complex and re-\nsults in a performance decline."}, {"title": "Vii) The Structure Analysis of BGAN", "content": "The generator G and discrim-\ninator D in BGAN consist of multiple layers of one-dimensional convolution\nnetworks. The performance of G and D directly impacts the performance of\nBGAN. To assess their impact, we conduct experiments using various combina-\ntions of one-dimensional convolution layers for G and D based on the Predcls\ntask of Transformer model. The results are presented in Tab. 15. Based on the\ncombination (5, 3) of G and D (last row in the table), we individually keep the\nnumber of layers fixed for G and D while modifying the number of layers for"}, {"title": "Viii) The Effect of Small Non-Zero Value \u03b5", "content": "In constructing the cor-\nrection bias set (Section 3.2), we utilize the \u025b which is set to 0.0001. In order to\nassess the impact of a for SBG, we conduct the Predcls task using the Trans-\nformer model. We test a range of values (0.001, 0.0001, 0.00001) for \u025b, and the\nperformance of our SBG is presented in Tab. 16. It can be observed that the\nM@50/100 metric achieves the highest performance when \u025b is set to 0.0001,\nindicating optimal comprehensive performance."}, {"title": "iX) The Improvements of Long-Tailed Classes", "content": "In Fig. 8, we present\nthe R@100 of each relationship for the PredCls task, comparing Transformer\nand our SBG. It shows that all tail classes are improved significantly."}, {"title": "X) The Rationale for Generative Model", "content": "The bias in our SBG is non-\nlinear and its continuity is very important for correction, so we compare gen-\nerative models with non-generative models for bias prediction in Fig. 9. GAN\nhas the dual optimisation that helps to predict the more non-linear bias, and\nthat G and D of GAN supervise each other and promote each other making\nthe bore predicted by GAN more closely approximate to the btru and capture\nthe continuity of the btru better. These are also reflected in HiFi-GAN [18] and\nVCA-GAN [17]."}, {"title": "C Visualization for Bias Correction", "content": "In order to specifically demonstrate the process of sample-level bias correction,\nwe illustrate the corrections of relationships for object pairs <man, boat> and\n<man, pole> as depicted in Fig. 10 (a) and Fig. 10 (b). The original predictions\nare the coarse-grained relationships of \"on\" and \"holding\". Utilizing the contex-\ntual information (from union region) of <man, boat> and <man, pole>, the\nrelationships' global bias, and the original predictions, the generator in BGAN\npredicts the sample-specific biases to refine the coarse-grained \u201con\u201d and \u201chold-\ning\" to the fine-grained \u201csitting on\u201d and \u201cusing\u201d."}]}