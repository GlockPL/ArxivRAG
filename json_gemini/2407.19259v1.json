{"title": "Fine-Grained Scene Graph Generation via Sample-Level Bias Prediction", "authors": ["Yansheng Li", "Tingzhu Wang", "Kang Wu", "Linlin Wang", "Xin Guo", "Wenbin Wang"], "abstract": "Scene Graph Generation (SGG) aims to explore the relationships between objects in images and obtain scene summary graphs, thereby better serving downstream tasks. However, the long-tailed problem has adversely affected the scene graph's quality. The predictions are dominated by coarse-grained relationships, lacking more informative fine-grained ones. The union region of one object pair (i.e., one sample) contains rich and dedicated contextual information, enabling the prediction of the sample-specific bias for refining the original relationship prediction. Therefore, we propose a novel Sample-Level Bias Prediction (SBP) method for fine-grained SGG (SBG). Firstly, we train a classic SGG model and construct a correction bias set by calculating the margin between the ground truth label and the predicted label with one classic SGG model. Then, we devise a Bias-Oriented Generative Adversarial Network (BGAN) that learns to predict the constructed correction biases, which can be utilized to correct the original predictions from coarse-grained relationships to fine-grained ones. The extensive experimental results on VG, GQA, and VG-1800 datasets demonstrate that our SBG outperforms the state-of-the-art methods in terms of Average@K across three mainstream SGG models: Motif, VCtree, and Transformer. Compared to dataset-level correction methods on VG, SBG shows a significant average improvement of 5.6%, 3.9%, and 3.2% on Average@K for tasks PredCls, SGCls, and SGDet, respectively.", "sections": [{"title": "1 Introduction", "content": "In recent years, Scene Graph Generation (SGG) has emerged as a popular area of research. SGG aims to generate a structured summary graph from an im-"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Scene Graph Generation", "content": "SGG [26, 30, 47, 49] decodes images into structured semantic graphs, supporting various downstream tasks [10, 12, 33, 38, 54]. Early works were primarily dedicated to designing models to achieve the relationship predictions between the objects. [31] leveraged language priors from semantic word embeddings to finetune the predicted relationships, [5] exploited the statistical dependencies between objects and their relationships, and [27] designed a ranking objective function by enforcing the annotated relationships to have higher relevance scores. The method described above neglected the rich visual context information from images. To address this problem, some methods designed elaborate feature refinement modules to encode the visual context information, such as message passing strategies [23, 48], sequential LSTMs [43,53], graph neural networks [3, 29, 52], and self-attention networks [11,32,40]. In addition, there are now some datasets as well as methods [21,25] emerging in the remote sensing field.\nLater works focused on designing optimization frameworks to further improve the performance of SGG models. Many optimization frameworks were proposed to tackle the long-tailed problem of relationships. [42] used causal inference for unbiased SGG, [41] proposed an energy-based constraint loss to learn relationships in small numbers. [7,9] employed hierarchical or grouped strategies to gradually learn, thereby mitigating the impact of the long-tailed effect. [2,4] corrected the relationship predictions to obtain the unbiased scene graph. [1] leveraged a within-triplet Bayesian network to eradicate the long-tailed effect. [20] proposed a compositional feature augmentation strategy to mitigate the bias from the perspective of increasing the diversity of triplet features. There were also some methods using data augmentation strategies to improve the performance of SGG models, such as [8,13,55]. Optimization frameworks offer greater flexibility and improved malleability, so it is a promising research direction."}, {"title": "2.2 Long-Tailed Learning", "content": "Recently, several correction methods have emerged to address the long-tailed problem in SGG. In Fig. 2, DLFE [4] and RTPB [2] employed different ways to correct the original predictions. DLFE estimated the per-class label frequency $c$ and used it to correct the biased probabilities. By dividing the biased probabilities by c, DLFE obtained unbiased probabilities. RTPB utilized the resistance bias b to enhance the model's focus towards tail relationships. RTPB adjusted the relationship's classification logits by subtracting b, thereby correcting the biased relationship predictions."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Problem Setting & Overview Framework", "content": "Problem Setting. The task of SGG is to generate a connected summary graph G from an input image I. The common SGG methods are the two-stage processes involving object detection followed by relationship prediction. In the first stage, we detect all objects in the image I, denotes as $O = {o_i}$. In the second stage, we predict relationships $R = {r_{i\u2192j}}$ of object pairs ($o_i$, $o_j$) and then generate $(o_i,r_{i\u2192j},o_j)$ triplets. Therefore, the scene graph can be formulated as:\n$G = \\{(o_i, r_{ij}, o_j)|o_i, o_j \u2208 O, r_{i\u2192j} \u2208 R\\}$.\nOverall Framework. Fig. 3 illustrates the overall structure of SBG, and the entire workflow follows the common two-stage SGG pipeline. Consistent with previous methods [2, 42], we utilize Faster R-CNN [37] as the object detection network. To address the long-tailed problem of relationships, we present a novel method SBP to realize the sample-level bias correction. More detailed analysis can be seen in Sec. 3.2."}, {"title": "3.2 Sample-Level Bias Prediction", "content": "The unbiased relationship predictions can be recovered from the biased ones [4]. In an ideal scenario, training the SGG model on an unbiased dataset results in"}, {"title": "5 Conclusion & Future Work", "content": "In this paper, to tackle the long-tailed problem, we propose one novel method SBP to conduct sample-level bias correction, and further generate the fine-grained scene graph. Specifically, we design a BGAN to predict the sample-specific bias. Extensive experiments on VG, GQA, and VG-1800 datasets validate the effectiveness and generalizability of our SBG. We believe that this work contributes to the advancement of research in this field and offers insights into tackling the long-tailed issue. Our future work aims to further enhance the performance of the proposed method and extend its applicability to other tasks."}, {"title": "A Dataset Details", "content": "GQA [14] is a vision-and-language dataset, consisting of a total of 113k images. We retain images only with the most frequent 160 object and 60 relationship categories for experiments. Then it contains 59,588 images, of which 41,773 (70%) images are used for the training, and 17,815 (30%) images are used for the testing. We follow [42] to sample a 5k validation set from the training set for parameter tuning. The detailed list of the most frequent 160 object and 60 relationship categories is shown in Tab. 10.\nWe visualize the quantity distribution for each relationship as shown in Fig. 7, GQA exhibits a severe long-tailed effect, with a highly imbalanced distribution between head categories (e.g., \u201con\u201d, \u201cwearing\u201d, \u201cof\u201d) and tail categories (e.g., \u201ccontain\u201d, \u201cpulling\u201d, \u201cpulled by\u201d)."}, {"title": "B Ablation Studies", "content": "iii) The Effect of Weight Factor \u03b1: To assess the impact of \u03b1 for SBG, we conduct the PredCls task on Transformer model. We validate a range of values (0.050, 0.075, 0.100) for \u03b1. The performance is presented in Tab. 11. From the results, it can be observed that the A@50/100 metric achieves the highest performance when \u03b1 is set to 0.075, indicating the optimal performance of SBG.\niV) The Effect of Training Mode: In Section 3.2, we employ a gradual training mode, where the parameters of the classic SGG model are frozen after the training, and subsequently, the training of BGAN is conducted. The comparison between the gradual training and integrated training of SBG on the PredCls task of Transformer model is presented in Tab. 12. The results indicate that the gradual training outperforms the integrated training. This is because SBG is trained based on the output of the classic SGG model. However, the output of the classic SGG model using the integrated training is continuously varied, thus leading to the unstable training for SBG.\nV) The Superiority of BGAN for Sample-Level Bias Prediction: To demonstrate the sample-level bias's prediction capability of BGAN, which employs the one-dimensional convolution network, we conduct a comparison involving three networks: a conventional 5-layer fully connected network (denoted as FC5), a 5-layer one-dimensional convolutional network (denoted as 1D5), and a fully connected BGAN (denoted as BGANFC), on the Predcls task of Transformer model. The results are presented in Tab. 13. It can be observed that in the case of FC5 and 1D5 networks, the 1D5 network outperforms the FC5 network slightly, as the 1D5 network benefits from the translation invariance and strong\nVi) The Analysis for Feature Mapping \u03c6: In Section 3.2, when constructing the correction bias set, we utilize an encoder that includes a single layer of transformer (denoted as Trans\u2081) to map high-dimensional features to one-dimensional features. We compare this approach with a conventional fully connected mapping (denoted as FC) and an encoder containing two layers of transformer (denoted as Trans2), based on the Predcls task of Transformer model. The results are presented in Table Tab. 14. It is evident that using Trans\u2081 for feature mapping yields the best performance. Compared to FC, Trans\u2081 demonstrates superior performance by leveraging the strong interaction capabilities of the transformer. Moreover, Trans2 is relatively complex and results in a performance decline.\nVii) The Structure Analysis of BGAN: The generator G and discriminator D in BGAN consist of multiple layers of one-dimensional convolution networks. The performance of G and D directly impacts the performance of BGAN. To assess their impact, we conduct experiments using various combinations of one-dimensional convolution layers for G and D based on the Predcls task of Transformer model. The results are presented in Tab. 15. Based on the combination (5, 3) of G and D (last row in the table), we individually keep the number of layers fixed for G and D while modifying the number of layers for\nViii) The Effect of Small Non-Zero Value \u03b5: In constructing the correction bias set (Section 3.2), we utilize the \u03b5 which is set to 0.0001. In order to assess the impact of \u03b5 for SBG, we conduct the Predcls task using the Transformer model. We test a range of values (0.001, 0.0001, 0.00001) for \u03b5, and the performance of our SBG is presented in Tab. 16. It can be observed that the M@50/100 metric achieves the highest performance when \u03b5 is set to 0.0001, indicating optimal comprehensive performance.\niX) The Improvements of Long-Tailed Classes: In Fig. 8, we present the R@100 of each relationship for the PredCls task, comparing Transformer and our SBG. It shows that all tail classes are improved significantly.\nX) The Rationale for Generative Model. The bias in our SBG is non-linear and its continuity is very important for correction, so we compare generative models with non-generative models for bias prediction in Fig. 9. GAN has the dual optimisation that helps to predict the more non-linear bias, and that G and D of GAN supervise each other and promote each other making the bpre predicted by GAN more closely approximate to the btru and capture the continuity of the btru better. These are also reflected in HiFi-GAN [18] and VCA-GAN [17]."}]}