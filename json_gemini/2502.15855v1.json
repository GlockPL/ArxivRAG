{"title": "Non-Linear Flow Matching for Full-Atom Peptide Design", "authors": ["Dengdeng Huang", "Shikui Tu"], "abstract": "Peptide design plays a pivotal role in therapeutic applications, yet existing AI-assisted methods often struggle to generate stable peptides with high affinity due to their inability to accurately simulate the dynamic docking process. To address this challenge, we propose NLFlow, a novel multi-manifold approach based on non-linear flow matching. Specifically, we design a polynomial-based conditional vector field to accelerate the convergence of the peptide's position towards the target pocket, effectively capturing the temporal inconsistencies across position, rotation, torsion, and amino acid type manifolds. This enables the model to better align with the true conformational changes observed in biological docking processes. Additionally, we incorporate interaction-related information, such as polarity, to enhance the understanding of peptide-protein binding. Extensive experiments demonstrate that NLFlow outperforms existing methods in generating peptides with superior stability, affinity, and diversity, offering a fast and efficient solution for peptide design and advancing the peptide-based therapeutic development.", "sections": [{"title": "1. Introduction", "content": "Therapeutic peptides are short, single-chain proteins composed of amino acids, and their design is essential for achieving precise and stable docking with target receptor proteins (Craik et al., 2013; Fosgerau & Hoffmann, 2015). Full-atom peptide design enables the creation of such peptides, offering a robust solution for advancing therapeutic development and treating protein-related diseases (Muttenthaler et al., 2021; Petsalaki & Russell, 2008; Lee et al., 2019a). To tackle the vast and complex chemical space, recent generative models integrate protein sequence and structure data to extract rich feature representations, facilitating the exploration of sequence-structure relationships (Charoenkwan et al., 2021; Lin et al., 2023). Particularly, diffusion and flow matching models simulate peptide movement through time-dependent random pathways or vector fields (Ciemny et al., 2018; Dauparas et al., 2022; Watson et al., 2023). These models account for modalities such as displacement, rotation, and other dynamics. By imposing constraints on the peptide's conformational degrees of freedom, they enable efficient exploration of conformational space and provide an accurate simulation of docking dynamics. Thus, they overcome the limitations of traditional experimental methods, such as high costs and long timelines (Henninot et al., 2018; Bhardwaj et al., 2016).\nHowever, existing diffusion models neglect temporal dependencies across different modalities in the docking process, leading to generated peptides that cannot stably bind to target proteins (Bennett et al., 2023). Although these methods model multi modalities to simulate peptide movement, they treat the evolution of all these modalities as fully synchronized in time (Corso et al., 2022; Li et al., 2024; Lin et al., 2024). In reality, peptides must first move towards the target pocket before specific residue interactions can trigger subsequent conformational changes, such as backbone rotation and side-chain torsion (London et al., 2013). This temporal inconsistency during inference results in inaccurate peptide movement predictions and impairs the biologically realistic simulation of peptide dynamics.\nTo resolve the temporal inconsistency across different manifolds, we propose NLFlow, a novel Non-Linear multi-manifold based Flow matching method. It accelerates the peptide's coordinate convergence towards the target in a non-uniform manner, prioritizing positional alignment over rotational and torsional adjustments. This closely mirrors the actual docking process, where the peptide first moves towards the protein pocket and then fine-tunes its posture. To realize this, the core idea is to leverage polynomial interpolation to define a time-varying gradient vector, decoupling the evolution of the position manifold from the other manifolds. Specifically, the gradient magnitude of the position manifold decreases over time, accelerating the initial phase of convergence, thereby reflecting the temporal inconsistency across different manifolds. Additionally, to prevent the model from focusing solely on conformational alignment while neglecting docking interactions, interaction-related information such as polarity, charge, and hydrophilicity is incorporated, ensuring stronger binding affinity to the target protein.\nThe NLFlow framework consists of two key components:"}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Peptide generation", "content": "Peptide generation is a complex task in drug discovery, aiming to design peptides with specific biological functions, such as binding to target proteins or modulating enzymatic activity. Generative models have significantly advanced peptide design by exploring large sequence and structural spaces with greater flexibility. For example, RFDiffusion (Watson et al., 2023), designed for protein design, inspired the application of similar diffusion techniques for peptide generation. AMP-diffusion (Chen et al., 2024) utilizes the capabilities of protein large language model ESM-2 (Beal, 2015) to regenerate functional antimicrobial peptides (AMPs). MMCD (Wang et al., 2024) employs multi-modal contrastive learning in diffusion, exploiting the integration of both sequence and structural information to produce peptides with high functional relevance.\nPeptide design is a subtask of peptide generation, involving several key components. One important aspect is backbone design, where methods like PepFlow (Li et al., 2024) and PPFlow (Lin et al., 2024) use flow matching to simulate dynamic conformational changes and optimize peptide properties. Another aspect is side-chain packing, with methods such as RED-PPI (Luo et al., 2023) focusing on protein-protein complexes and DiffPack (Zhang et al., 2024) targeting peptide-protein interactions."}, {"title": "2.2. Protein-ligand docking", "content": "Protein-ligand docking aims to predict the binding pose and affinity of a ligand to a target protein. Traditional docking methods often rely on rigid-body simulations and predefined scoring functions, which can struggle to handle flexible ligands and complex interactions (Kramer et al., 1999; Totrov & Abagyan, 1997). Recent years, deep learning (DL) approaches have significantly improved docking accuracy (Yang et al., 2022a). Models like AtomNet (Stafford et al., 2022) and OnionNet (Wang et al., 2021) use convolutional neural networks (CNNs) to capture complex molecular features, significantly enhancing binding affinity predictions. Further developments have incorporated graph-based models, such as GraphSite (Shi et al., 2022) and DGraphDTA (Yang et al., 2022b), which represent protein-ligand interactions as graphs to better model flexible docking. Additionally, advances in protein structure characterization, notably via AlphaFold (Evans et al., 2021), have enhanced understanding of protein flexibility, fueling the development of structure-based docking prediction methods (Wong et al., 2022; Johansson-\u00c5khe & Wallner, 2022). However, challenges still remain in fully capturing the dynamic and flexible nature of ligands, highlighting the need for further improvements in docking models."}, {"title": "3. Method", "content": ""}, {"title": "3.1. Preliminary", "content": "Conditional Flow Matching. Conditional Flow Matching (CFM) (Lipman et al., 2022) models the transformation between a prior distribution $p = p_0$ and a target data distribution $q = p_1$ on a manifold $\\mathcal{M}$ using ODEs. The transformation is described as:\n$$\n\\frac{d}{dt} p_t(x) = u_t(x),\n$$\nwhere $p_t(x)$ represents the data distribution at time $t$, and $u_t(x)$ is the gradient vector field driving the flow. Since the true gradient flow $u_t(x)$ is unknown, it is assumed based on a hypothesis form and a known target distribution $p_1$. Usually a neural network is used to approximate this flow by learning a vector field $v_t(x)$. The loss is defined to minimize the difference between $v_t(x)$ and $u_t(x|x_1)$:\n$$\n\\mathcal{L}_{CFM}(\\theta) = \\mathbb{E}_{t, p_t(x|x_1)}[||v_t(x) - u_t(x|x_1)||^2],\n$$\nIn most current methods, the distribution $p_t(x)$ is typically assumed to follow a simple linear interpolation between the initial distribution $p_0$ and target distribution $p_1$: $p_t(x) = t x_1 + (1 - t)x_0$, where $t \\in [0, 1]$. The corresponding gradient vector field is $u_t(x) = \\frac{d}{dt} p_t(x) = x_1 - x_0$. This form has been proven to correspond to the Optimal Transport (OT) solution, which provides an efficient and fast means of transforming distributions with a fixed direction and magnitude.\nProblem Statement. Peptide is a short sequence of amino acids, denoted by $a$, representing its type. Each amino acid is characterized by its backbone and side chain.\nThe backbone consists of four heavy atoms N, Ca, C, and O, with the position of Ca serving as the reference, denoted as X at the origin. Peptide's orientation is modeled in two parts: the overall rigid rotation, represented by the rotation matrix $R \\in SO(3)$, and the side-chain torsion, captures four torsion angles $T = (\\chi_1, \\chi_2, \\chi_3, \\chi_4)$ of the rotatable bonds.\nIn the docking process, the peptide acts as the ligand, represented as $Lig = \\{(X_i, R_i, T_i, a_i)\\}_{i=1}^n$, where n is the length of peptide, while the protein serves as the receptor, denoted as Rec. The task of designing the peptide Lig based on a spesific Rec can be formulated as learning the conditional distribution $p(Lig|Rec)$. Expanding the problem to the four modalities we have modeled, the problem can be empirically decomposed into the product of probabilities of the four components:\n$$\np(Lig|Rec) \\propto p(\\{X_i\\}_{i=1}^n|Rec) \\cdot p(\\{R_i\\}_{i=1}^n|Rec) \\cdot p(\\{T_i\\}_{i=1}^n|Rec) \\cdot p(\\{a_i\\}_{i=1}^n|Rec).\n$$"}, {"title": "3.2. Non-Linear Flow for Position", "content": "Position manifold refers to the coordinates of the C-alpha atoms of the peptide backbone in Euclidean space. We initialize the system using a standard Gaussian distribution $X^0 \\sim \\mathcal{N}(0, I)$ as the random initialization, with $X^1$ representing the target distribution. The task is to model the trajectory from $X^0$ to $X^1$.\nDespite being efficient and fast, the OT assumption applied across all modalities leads to synchronized evolution in time. To resolve this temporal inconsistency issue, we define a polynomial interpolation for position mainfold to explicitly decouples its evolution from other mainfolds. The interpolation is defined as:\n$$\nX_t = X^0 + (1 - (1 - t)^k) \\cdot X^1, \\quad t \\in [0, 1],\n$$\nwhere $k$ is a hyperparameters.\nTaking the derivative of this equation with respect to time t gives the corresponding gradient vector field:\n$$\nu^{pos}_t(X_t|X^0, X^1) = \\frac{dX}{dt} = k(1 - t)^{k-1}(X^1 - X^0).\n$$\nFrom this formulation, we can see that the gradient vector field $\\nu^{pos}_t$ is time-varying and decreases over time, while the direction remains consistent, always aligned with $X^1 - X^0$."}, {"title": "Non-Linear Flow and Diffusion Formulation.", "content": "The non-linear flow model is not introduced arbitrarily but is inspired by both flow matching and diffusion processes. In diffusion models, the distribution evolves over time via stochastic differential equations (SDEs), with the transformation given by\n$$\n\\mu_t(x) = \\sigma_{1-t} x_1 \\text{ and the noise term } \\sigma_t(x) = \\sqrt{1 - \\sigma_{1-t}},\n$$\nwhere $\\mu_t(x)$ represents the mean of the data distribution at time t and $x_1$ is the target distribution.\nIt has also been shown that flow matching, as defined by the vector field, can be derived into the form of $\\mu_t(x)$. The optimal transport (OT) assumption corresponds to a linear form: $\\mu_t(x) = t x_1$, representing uniform evolution from the initial to the target distribution.\nBuilding on this, our proposed non-linear flow corresponds to a time-varying interpolation: $\\mu_t(x) = (1 - (1 - t)^k)x_1$, which reduces to the linear flow when $k = 1$. For $k > 1$, the non-linear flow provides increased flexibility to simulate the varying convergence speed of the position manifold in docking tasks, accurately capturing the complex dynamics of peptide conformation changes."}, {"title": "Loss Function for Position Flow.", "content": "We use a trainable neural network $\\nu^{pos}_\\theta$ to approximate the time-varying gradient $\\nu^{pos}_t$. The loss function is designed to minimize the squared error between the predicted and target gradient vectors over all timesteps, ensuring that the model learns the correct temporal dynamics. It can be expressed as:\n$$\n\\mathcal{L}^{pos}_\\theta = \\mathbb{E}_{t, p_t(x|X^0, X^1)}[\\nu^{pos}_\\theta(x) - k(1 - t)^{k-1}(X^1 - X^0)||^2].\n$$"}, {"title": "Non-Uniform Time Sampling Strategy.", "content": "To address the bias of standard uniform sampling-where interpolated positions $X_t$ cluster near $X^1$ under polynomial-based interpolation-we redefine the time variable as $t = z^k$ ($z \\sim U(0, 1)$). This non-uniform sampling adjusts the temporal density, prioritizing the initial phase ($t \\rightarrow 0$) where rapid positional convergence occurs. By reshaping the probability distribution of $t$, the strategy ensures balanced coverage of the entire trajectory, preventing under-sampling of critical early dynamics. Simultaneously, it allocates more training samples to the information-sparse initial phase, enabling the model to robustly learn fast positional alignment governed by large initial gradients, while stabilizing gradient updates across all stages."}, {"title": "3.3. Linear Flow for Orientation and Amino Acid Type", "content": "In this section, we follow recent advances in flow-based methods (Lin et al., 2024; Li et al., 2024), modeling the flows of rotation, torsion, and amino acid types using the optimal transport assumption, which enables efficient transitions between states. As the peptide approaches the pocket, these manifolds adjust according to the pocket environment, ensuring temporal consistency. This adjustment allows us to treat these three modalities as time-synchronized linear flows. Together with the non-linear flow model discussed in the previous section, our approach decouples the evolution of the position manifold from the other manifolds, effectively capturing cross-modal temporal inconsistencies.\nRotation Matrices. A rotation matrix, $R_i$, is an element of the special orthogonal group $SO(3)$, which describes rigid body rotations. As a Lie group, $SO(3)$ enables its elements to be locally represented by its tangent space. It has been proven that the exponential map facilitates smooth interpolation in Lie groups. Therefore, we use the rotation matrices under the exponential map for linear interpolation, which can be expressed as:\n$$\nR_t = EXPR(t \\log_R(R_i)),\n$$\n$$\n\\nu^{rot}_t(R_t|R_i, R_0) = \\frac{\\log_R R_i}{1 - t}.\n$$\nThe loss function $\\mathcal{L}^{rot}_\\theta$ is defined as:\n$$\n\\mathcal{L}^{rot}_\\theta = \\mathbb{E}_{p(R_0), p(R_1)} [||\nu^{rot}_\\theta - \\frac{\\log_R R_i}{1 - t}||^2].\n$$"}, {"title": "Torsion Angles.", "content": "The torsion angle, $\\tau_i \\in [0, 2\\pi)$, refers to the angle of rotation between two planes formed by four consecutive atoms in the side-chain of a peptide. Unlike the rotation of a rigid body, torsion alters the internal structure without changing the overall properties. The torsion angle has a periodicity of 2$\\pi$, and its space is topologically a torus, with the angle smoothly wrapping around itself as it changes continuously. Therefore, we define T:\n$$\nT_t = (1 - t)\\tau_0 + t\\tau_i \\mod 2\\pi,\n$$\n$$\n\\nu^{toru}_t(\\tau_t|\\tau_i, \\tau_0) = \\tau_i - \\tau_0 \\mod 2\\pi,\n$$\nThe loss function $\\mathcal{L}^{toru}_\\theta$ is defined as:\n$$\n\\mathcal{L}^{toru}_\\theta = \\mathbb{E}_{p(\\tau_0), p(\\tau_i)} [||\nu^{toru}_\\theta - (\\tau_i - \\tau_0 \\mod 2\\pi)||^2].\n$$"}, {"title": "Amino Acid Types.", "content": "A peptide is composed of a sequence of amino acids, where the amino acid type at position $i$, $a_i \\in \\{1, 2, ..., 20\\}$, has 20 possible distinct values. Since $a_i$ is a discrete variable, we define the soft label $s_i$ as continuous logits in a 20-dimensional space to facilitate smooth linear interpolation of this manifold. The interpolation for soft label $s_i$ is defined as:\n$$\ns_t = ts_i + (1 - t)s_0,\n$$\n$$\n\\nu^{type}_t(s_t|s_i, s_0) = s_i - s_0,\n$$\nThe loss function $\\mathcal{L}^{type}_\\theta$ is defined as:\n$$\n\\mathcal{L}^{type}_\\theta = \\mathbb{E}_{p(s_0), p(s_i)} [||\nu^{type}_\\theta(s_t) - (s_i - s_0)||^2].\n$$"}, {"title": "3.4. Loss Balancing for Sequence-Structure Co-design", "content": "To balance sequence and structural alignment, we define the spatial loss $\\mathcal{L}^{spa}$ as the weighted sum of the position, rotation and torsion losses:\n$$\n\\mathcal{L}^{spa} = \\sum_{l \\in \\{pos, rot, tor\\}} \\alpha_l \\cdot \\mathcal{L}^{l}_\\theta,\n$$\nwhere $\\alpha_l$ are the corresponding hyperparameters.\nThe sequence loss weight, $\\alpha_{type}$, is dynamically adjusted based on the spatial loss:\n$$\n\\alpha_{type} = \\min(\\alpha^{max}_{type}, \\max(\\frac{20}{\\mathcal{L}^{spa}}, 1)),\n$$\nwhere $\\alpha^{max}_{type}$ is a hyperparameter that controls the upper bound. This ensures that when spatial loss is small, indicating structural alignment with the reference, the sequence is encouraged to match it; otherwise, the alignment requirement is relaxed. The total loss is then computed as:\n$$\n\\mathcal{L}^{total} = \\sum_{l \\in \\{pos, rot, tor, type\\}} \\alpha_l \\cdot \\mathcal{L}^{l}_\\theta.\n$$"}, {"title": "3.5. Sampling with ODE", "content": "We perform sampling with the pre-trained flow model by formulating peptide generation as an ODE, where the peptide Lig evolves according to $\\frac{d}{dt} Lig = \\nu_t(Lig)$, with derivatives computed for each of the four modalities. The equation is discretized into N steps, yielding the final peptide $Lig_1$.\nEach modality's update depends not only on its own state but also on the states of other modalities. This interdependence highlights the importance of accurately capturing the temporal relationships across modalities. By iteratively updating these states, our model effectively simulates the dynamic nature of peptide docking, while enabling flexible sampling strategies for different design tasks (fix sequence for re-docking and fix backbone for side-chain packing)."}, {"title": "3.6. Network Parametrization", "content": "Encode with Interaction-related Information. We use two multi-layer perceptrons (MLPs) to encode the features of amino acids and the relationships between residue pairs. The first MLP encodes the features of individual residues, processing the amino acid type, backbone dihedral angles, and local atomic coordinates. Position embeddings are integrated to identify the context of sequences. Additionally, properties such as polarity, charge, hydrophilicity, and sulfur presence (which is critical for stability) are encoded using one-hot vectors, serving as auxiliary interaction-related information. This allows the model to not only focus on structural alignment but also on the alignment of interaction forces, ultimately enhancing the affinity between the peptide and protein. The second MLP encodes the relationships between residue pairs, capturing their relative positions, distances between atoms, and dihedral angles.\nLearning Gradient Vector with IPA and Transformers. We use invariant point attention (IPA) (Lee et al., 2019b) and transformer to learn the gradient vector field $\\nu_t$. The model consists of multiple IPA blocks for spatial feature learning, followed by transformer encoders for sequence modeling. Each block includes layer normalization, transition layers, and backbone updates, iteratively refining peptide conformations. Residue identity, angular encoding, and time-step embedding are integrated to ensure smooth temporal updates."}, {"title": "4. Experiment", "content": ""}, {"title": "4.1. Set up", "content": "In this section, we evaluate NLFlow on four tasks: (i) sequence-structure co-design, (ii) re-docking, (iii) side-chain packing and (iv) one-step generation. Through these evaluations, we assess whether the correct temporal characterization leads to the generation of more stable, high-affinity peptides with accurate structural alignment and functional relevance.\nThe dataset, derived from the work of PepFlow (Li et al., 2024), was obtained from PepBDB (Wen et al., 2019) and Q-BioLip (Wei et al., 2024). To ensure high-quality data, duplicates were removed, a resolution threshold of less than 4 \u00c5was applied, and peptide lengths were restricted to be between 3 and 25 residues. This preprocessing resulted in a final dataset consisting of 10,348 complexes, with 166 complexes reserved for the test set, and the remaining data split for training and validation.\nDuring pre-training, we simply selected the hyperparameter k = 2 for the non-linear flow model discussed in section 3.2. We trained three variants of our model to evaluate different configurations: (i) NLFlow, the full model with all components. (ii) NLFlow w/o II, which excludes the interaction-force related information. (iii) NLFlow w/o II+LW, which further removes the sequence-structure balance weight. Each model variant was trained for a total of 65,000 iterations to ensure sufficient training and convergence. The experiments were conducted on a Tesla P40 GPU with a batch size of 12, using the Adam optimizer with a learning rate of 5 \u00d7 10\u20134 and a plateau learning rate scheduler with a factor of 0.8, patience of 10, and a minimum learning rate of 5 \u00d7 10-6."}, {"title": "4.2. Sequence-Structure Co-design", "content": "Sequence-structure co-design involves jointly generating the peptide sequence and conformation, resulting in a full-atom peptide docked onto the target protein. We evaluate three baseline models: DIFFPP, PPFLOW (Lin et al., 2024) and PEPFLOW (Li et al., 2024). DIFFPP is a diffusion model for protein backbone parametrization, using DDPM (Yang et al., 2023) and SO(3)-DPM (Leach et al., 2022) to model translation and rotation, along with multinomial diffusion for amino acid types. PEPFLOW and PPFLOW, which were proposed simultaneously, are the latest models based on the flow matching framework for peptide design. They represent peptide structures by modeling backbone frames on the SE(3) manifold and side-chain dynamics on high-dimensional tori, enabling the generation of full-atom peptides with a focus on structural accuracy and torsion angle optimization.\nMetrics. The evaluation of the generated peptides is based on five metrics. Energy is calculated using Rosetta (Rohl et al., 2004), with two primary measures: Affinity, which quantifies the binding energy, where lower values indicate stronger binding potential, and Stability, representing the overall energy of the peptide-protein complex, with lower values indicating a more stable complex. We report the percentages of designed peptides with higher affinity and stability than the reference ones. Diversity is evaluated using the TM-score (Zhang & Skolnick, 2005), defined as the average of 1 minus the pairwise TM-scores of generated peptides, with Novelty calculated as the percentage of TM-score less than 0.5. Seq Sim is quantified by the longest common subsequence ratio between peptide pairs, reflecting the consistency between sequence and conformation.\nResults: Achieves Superior Affinity and Stability. From the comparison in Table 1, it can be concluded that (i) NLFlow exhibits a significant advantage in energy metrics, achieving 6.99% higher stability and 4.62% higher affinity compared to baseline models. A key distinction from flow-based methods explains that this improvement is largely due to the effective handling of temporal inconsistencies. (ii) The inclusion of interaction-related information (II) results in the generation of 6.7% more peptides with lower binding affinity compared to the version w/o II, highlighting its contribution to improved peptide-protein interactions. (iii) Our method generates diverse and novel peptide conformations. In contrast, the stronger randomness of diffusion models enables broader exploration of the conformational space, while NLFlow focuses on finer adjustments near the pocket, leading to slightly lower diversity. (iv) The designed sequences also show corresponding differences, reflecting the consistency between sequence and structural in the co-design process."}, {"title": "4.3. Peptide Re-docking", "content": "The re-docking task evaluates the model's ability to reconstruct the conformation by fixing the reference peptide sequence during the sampling stage, without retraining the model, and generating a full-atom peptide-protein complex in the docked state. We evaluate two baseline models in re-docking task: PEPFLOW and HDOCK (Yan et al., 2020). HDOCK is a traditional docking method, which uses a combination of rigid-body docking followed by energy minimization to predict the binding mode of two interacting proteins.\nMetrics. The evaluation of the Peptide Re-docking task is based on five metrics: RMSD measures the structural deviation between the generated peptide's Ca atoms and the reference peptide, indicating conformation accuracy; SSR quantifies the similarity in secondary structure, assessing the preservation of secondary structural features; BSR calculates the overlap between the docking site of the generated and the reference peptide-protein complex, reflecting binding site accuracy; Success is defined as achieving a top-1 RMSD < 4 \u00c5, with BSR and SSR both greater than 0.8. The result reports the percentage of successful cases; and Diversity, same as the co-design task, calculated as 1 minus the average TM-score, measuring the variation in peptide conformations.\nResults: Lower RMSD in Reconstructing. Table 2 shows that (i) NLFlow achieves the lowest RMSD, performing superiorly in structural accuracy. This demonstrates that by addressing temporal inconsistencies between modalities, the correct docking process simulation provides the model with a strong ability to reconstruct conformations. As illustrated in Figure 4, NLFlow not only focuses on fine-grained atomic coordinates but also effectively restores the overall macrostructural features, reflecting the model's deep understanding of the docking task under correct temporal alignment. While PepFlow excels in binding site recognition (BSR), NLFlow achieves a better balance between structural alignment and conformational diversity. (ii) Compared to flow-based models, the traditional method HDOCK, which does not redesign the peptide structure, does not provide SSR or diversity results, limiting its ability to model peptide-protein interactions. (iii) Among our model variants, removing interaction force information (w/o II) increases the success rate, as it shifts the model's focus from balancing structural alignment and docking interactions to solely optimizing structural alignment."}, {"title": "4.4. Side-chain Packing", "content": "This task evaluates the model's ability to predict the correct torsional angles for the side chains, which are crucial for accurate protein-ligand docking and stability. Specifically, we calculate the mean squared error (MSE) of the four predicted side-chain torsional angles. We use energy-based methods: ROSETTAPACKER (Leman et al., 2020), SCWRL4 (Krivov et al., 2009), and Rotamer Density Estimator (RDE) (Luo et al., 2023) with Conditional Flow on TNrt: RDE-PP (Lin et al., 2024) as baselines.\nResults: Strong Performance in Lower-Order Torsions. As shown in Table 3, NLFlow demonstrates a clear advantage in predicting the $X_1$ and $X_2$ torsional angles, outperforming all other methods. This highlights the importance of adjusting torsion angles according to the pocket environment, reflecting NLFlow's ability to finely tune the conformation near the pocket. However, for the more challenging $X_3$ and $X_4$ angles, the performance of all models is comparable, with showing worse results compared to $X_1$ and $X_2$. This highlights that higher-order torsions remain a complex task, with no model consistently outperforming others across all angles."}, {"title": "4.5. One-step Generation", "content": "Most flow matching methods rely on the assumption that the direction of the gradient vector field remaining constant, which theoretically enables one-step generation. However, achieving this in practice is challenging in non-linear flow due to two key issues: first, path conflicts as identified by Rectified Flow (Liu et al., 2022) exist across all flow-based models; second, our non-linear assumptions hinder the ability of the initial time step to capture temporal inconsistencies across different modalities, limiting the effectiveness of one-step generation.\nIn this task, we set varying number of inference steps (N) in sampling stage for sequence-structure co-design task to evaluate how it impacts the model's ability and determine the minimum steps required to capture the temporal inconsistencies in multimodal data.\nResults: Rapid Improvement with Minimal Steps. As shown in Fig 4.5, at step = 1, the lack of temporal consistency across modalities leads to poor performance, particularly with stability (Stab = 0). However, by step = 2, the model rapidly improves, indicating that the difficulty of one-step generation primarily arises from the absence of temporal information, highlighting the importance of the non-linear assumption. After step > 10, further increasing the number of steps has minimal impact on the model's performance, suggesting that our model largely follows the straight-line assumption of flow, making it a fast and efficient generation model."}, {"title": "5. Conclusion", "content": "In this work, we present NLFlow, a non-linear flow matching framework designed to address the critical challenge of temporal inconsistency across modalities in full-atom peptide design. By introducing a polynomial-based interpolation scheme and its associated time-varying gradient vector field, NLFlow explicitly decouples the evolution of the positional manifold from rotational, torsional, and residue-type manifolds. This approach captures the biologically hierarchical nature of peptide docking, resulting in peptides with enhanced binding affinity and stability. The integration of interaction-related features further enables the model to balance structural alignment with functional optimization, providing a nuanced simulation of peptide-protein interactions.\nDespite these advancements, NLFlow remains limited by suboptimal accuracy in predicting higher-order torsions under complex conformational constraints, and its predefined polynomial interpolation, though effective for temporal decoupling, restricts flexibility in modeling dynamic temporal hierarchies. Future directions include developing adaptive flow architectures to learn temporal dynamics directly from data, and incorporating dynamic interaction force predictors for context-aware refinement."}]}