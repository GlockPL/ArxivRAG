{"title": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning", "authors": ["Rui Sun", "Zhipeng Wang", "Hengrui Zhang", "Ming Jiang", "Yizhe Wen", "Jiqun Zhang", "Jiahao Sun", "Shuoying Zhang", "Erwu Liu", "Kezhi Li"], "abstract": "One of the biggest challenges of building artificial intelligence (AI) model in healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausted, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America and Asia) while without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaption to make it meet with the privacy and safety requirements of healthcare data, meanwhile rewards honest participation and penalize malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy preserved. Its prediction accuracy is much better than the models trained from limited personal data and is similar to, and even slightly better than, the results from a centralized dataset. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.", "sections": [{"title": "I. INTRODUCTION", "content": "While data-driven machine learning techniques have catalyzed breakthroughs in other domains, [1], [2], their progress in healthcare has been more incremental. This disparity is largely attributed to the unique challenges associated with healthcare data [3]. Healthcare data is distinctively private, sensitive, and heterogeneous, presenting significant barriers not commonly encountered in other fields [4], [5]. Accumulating sufficient data for effective training and testing of artificial intelligence (AI) models is not only challenging but also costly. The process of data collection is fraught with obstacles, varying significantly across global regions. For example, in the study of chronic diseases, researchers must establish partnerships with hospitals, private companies, or public authorities\nto gather sufficient data. Each partner, however, treats their data as a proprietary resource, complicating the sharing process. Moreover, the approval process for data access is often complex and protracted due to regulations and country barriers [6]. These factors collectively hinder the application of AI in healthcare and are increasingly becoming critical bottlenecks in the development of AI-enabled healthcare systems.\nTo address the prevalent challenge of data privacy and access, we use a privacy-preserving framework for AI modeling that leverages federated learning and blockchain. We selected blood glucose prediction as a case study to illustrate the potential of this approach in healthcare applications. Approximately 422 million people globally suffer from diabetes, with 1.5 million deaths directly attributed to the disease annually [7]. An effective strategy for mitigating severe complications due to hyperglycemia or hypoglycemia involves early intervention to regulate blood glucose levels for individuals with type 1 diabetes (T1D). Usually the data obtained from clinical trials are typically scarce and costly to acquire [8]. Research indicates that universal models, trained on data pooled from groups of T1D patients, can significantly enhance glucose"}, {"title": "II. PROBLEM FORMULATION AND EXISTING WORKS", "content": "There are three components in the work, including blood glucose level prediction (BGLP), decentralized federated learning, and blockchain deployment. Here we provide definitions for each of the components."}, {"title": "A. BGLP", "content": "The goal of BGLP is to predict future glucose levels using current and historical data, including glucose levels (mg/dL) collected from continuous glucose monitors (CGMs), and optional recorded data such as meal intake (grams as carbohydrate), insulin injection (mg or units) and time of the day. Specifically,\nDefinition 1: BGLP: Given a time series X of historical glucose records $9_{1:L} = {9_1,...,g_L}$ and associated variables (such meal intake m, insulin i, and timestamp t) collected at regular time intervals $\\tau$ (e.g. $\\tau$ = 5 mins), BGLP aims to accurately predict future glucose level $g_{L+H}$ where H denotes the predictive horizon (e.g. H = 6 to predict the future glucose in 30 mins), and L can vary as a sliding window.\nGiven the substantial interpersonal and intrapersonal variability inherent in glucose data, training the BGLP model necessitates individual-specific datasets to develop tailored models that accurately reflect personal health metrics. However, the acquisition of individual data for machine learning applications can be both challenging and resource-intensive. An effective alternative involves the utilization of a population model, which leverages data from a broad demographic. Research indicates that population models, when trained with extensive datasets from numerous individuals, typically outperform personalized models, especially when personal data is scant and costly [9], [10]. To fully capitalize on the advantages offered by the population model, it is proposed that a global collaborative framework be established whereby individuals, organizations, and healthcare institutions contribute their data to a collective model training effort in a manner that ensures the privacy of the contributors' data."}, {"title": "B. BGLP Using Federated Learning (FL)", "content": "In this context, federated learning becomes a useful approach. It enables the decentralized training of machine learning models wherein each participant (e.g., a hospital or an individual) retains control over their own data. Only model updates, such as gradients or learned parameters, are shared centrally for aggregation, without transmitting any personal or sensitive data. FL promises a solution that enables numerous participants (e.g., hospitals and individual patients) to collaboratively train a global ML model while preserving local data privacy [11]. During FL training of BGLP, only participants' local model updates, such as gradients or learned parameters of BGLP models [12], are shared for knowledge aggregation without transmitting any personal or sensitive local data.\nDefinition 2: BGLP Using FL: Consider a federated system with K > 1 participants(hospitals in this paper), denoted by the set $\\mathcal{K}$ = 1, 2, ..., K. Let $D_k$ represent the local data stored by participant k, where $D_k \\cap D_l = \\emptyset$ for k \u2260 l and k,l \u2208 $\\mathcal{K}$. Each local dataset $D_k$ can be randomly split into a training set $D_{k}^{train}$, a validation set $D_{k}^{val}$, and a test set $D_{k}^{test}$, all of which remain private to participant k. The global model is denoted as $\\theta_g$, and each participant's local model is denoted as $\\theta_k$. The total number of global communication rounds is R, with each round consisting of a single global aggregation. The number of local model update epochs per communication round is denoted by E."}, {"title": "C. Blockchain-Enabled FL", "content": "The properties of decentralization and transparency of blockchain technology can further improve the decentralization and security of FL. In the following, we provide the definition of blockchain-enabled FL.\nDefinition 3: Blockchain-enabled FL: Blockchain-enabled FL (BCFL) represents an innovative paradigm of blockchain technology with FL, aiming to enhance security and trust in decentralized machine learning environments. In this paradigm, blockchain serves as an immutable ledger, recording transactions and models exchanged across the distributed nodes participating in the federated learning process. This integration addresses core challenges such as data privacy, security, and model integrity, by ensuring transparent and verifiable transactions while maintaining the confidentiality of the data. Blockchain's decentralized nature allows for a trustless system where no single entity has control over the entire dataset or the learning process, thereby mitigating risks associated with centralized data storage and processing. Moreover, the use of smart contracts automates the process of data sharing and model updates in FL. Additionally, blockchain's inherent incentive mechanisms reward honest participation and penalize malicious activities, enhancing further the security of FL systems. BCFL has garnered significant attention for its applicability in diverse fields, including the Internet of Things (IoT) [13], [14] and healthcare [15]\u2013[17]."}, {"title": "III. BLOCKCHAIN-ENABLED FEDERATED LEARNING GLUCOSE MODELLING", "content": "To model blockchain-enabled federated learning for glucose prediction, we designed the Multi-Continental Glucose Prediction (MCGP) Framework, shown in Fig 2. This framework leverages federated learning to enable different hospitals to collaboratively train a glucose prediction model while preserving patient data privacy. Blockchain technology is utilized to implement a reward and slashing mechanism, incentivizing honest participation and detecting malicious actors."}, {"title": "A. Glucose Prediction", "content": "Many approaches have been developed for glucose prediction. Here We formulate the BGLP problem as a multi-variant time series prediction problem as in [10]. A sliding window is utilized to crop historical data as input data. The future glucose value (e.g. in 30 mins) is used as the target output."}, {"title": "B. Federated Learning for Glucose Prediction", "content": "In privacy-sensitive fields such as glucose management, FL can break down data silos among hospitals. Each patient has unique characteristics; for instance, insulin levels can vary significantly in response to eating, drinking water, and insulin injections. Each hospital's prediction model needs to learn these personalized features to provide timely and accurate blood sugar predictions for new patients. FL enables hospitals to collaboratively enhance their models by sharing knowledge, leading to improved patient care without compromising data privacy. Our FL mechanism for glucose prediction follows the FedAvg [18] algorithm, allowing locally trained models to\nshare knowledge about patients' unique characteristics without transmitting any private data. In an FL training task for glucose prediction, each participating hospital collects relevant data glucose levels, insulin intake, meals, physical activity, and sleep patterns \u2013 from their T1D patients via devices like CGM and manually input data. This data is divided into training, validation, and test sets.\nInitially, all hospitals and the central server initialize a training model, denoted as $\\theta^{0}$. The local models at each hospital are aligned with the global model on the central server to ensure a consistent starting point. In the first training round (r = 1), each hospital uses its own training data to update its local model $\\theta_k^{0}$. After a predefined number of epochs (E), the updated local model weights and the number of data samples (nk) are sent to the central server. The central server aggregates the updated model weights from all hospitals using a weighted averaging approach:\n$\\theta^{r} = \\sum_{k=1}^{K} \\beta_k \\theta_k^{r}$\nHere, the weight $ \\beta_k $ is defined as $ \\frac{n_k}{N} $ where $ n_k = |D_{k}^{train}|$ is the number of local training data samples for each participant k, and $N = \\sum_{k=1}^{K}n_k$ is the total number of training data samples across all participants. The aggregated model weights are then broadcast back to the hospitals, allowing them to synchronize their local models with the updated global model. This iterative process continues, with hospitals using the latest model weights for subsequent rounds of local updates. These"}, {"title": "C. Blockchain for BCFL", "content": "1) Blockchain and Smart Contract: Blockchain is a decentralized and secure ledger technology that ensures data integrity and transparency across multiple nodes. Smart contracts are self-executing agreements coded directly onto the blockchain, automating processes and enforcing terms without intermediaries. In BCFL, blockchain and smart contracts can play a crucial role by providing a secure and transparent framework for decentralized machine learning. Blockchain can ensure the integrity and traceability of data and model updates, while smart contracts can automate the coordination and validation of contributions from different parties. For instance, smart contracts can be used to implement incentive mechanisms for participants in the blockchain-based FL.\n2) Blockchain Tokens: In our BCFL system, a blockchain token, named as $FML, serves as a quantitative measurement of assets, providing a reliable indicator of a participant's trustability within our system. By staking $FML tokens, participants demonstrate their commitment and reliability, as their participation is backed by a tangible, verifiable asset. Their tokens will be integrated into our incentive mechanism, which not only incentivizes honest behavior but also deters malicious activities, as participants risk losing their staked tokens if they act dishonestly. Similar to ERC20 tokens, the $FML tokens in our BCFL system are fungible and governed by smart contracts. We assume that all participants have acquired sufficient $FML tokens (e.g., by purchasing $FML from centralized or decentralized exchanges) before joining the BCFL system.\n3) On-Chain Incentive Mechanism: As shown in Figure 3, we follow the existing work [17] and adopt an incentive mechanism to reward honest behaviors and penalize malicious behaviors.\nAs shown in [17], the expected return for malicious participants is negative, ultimately resulting in their expulsion from the system. Different from the existing work [17], which utilizes smart contracts to perform on-chain aggregation of local model updates, our approach allows voters to execute the aggregation off-chain. This improvement can significantly reduce on-chain costs (e.g., gas fees), particularly when dealing with training models that have a large number of parameters."}, {"title": "IV. MULTI-CONTINENTAL GLUCOSE PREDICTION FRAMEWORK EXPERIMENTS", "content": "To expedite the simulations, all experiments were conducted on an NVIDIA RTX4090 GPU. The entire framework, including the complete workflow, was deployed and tested in a decentralized manner on four PCs and one server located in five cities across three continents: Toronto, Canada; Shanghai and Shandong, China; and Newcastle and London, UK. The CPUs used in these machines include Intel Xeon E5-2686, Intel Core i9-13900K, Intel i5-1135, AMD Ryzen 9 7950X, and Apple M3."}, {"title": "A. Experiment Setup", "content": "1) Participants need to stake a fixed amount (i.e., d) of $FML tokens into the smart contract to be eligible to participate in the FL training process.\n2) In each round, a participant will be randomly selected to act as either an FL training node or a voter by using a verifiable random function (VRF) [19].\n3) A training node is responsible for performing local training using its own data and uploading the local model updates to a public database (e.g., IPFS\").\n4) Voters aggregate all the local model updates for that round to obtain the global model update. They evaluate the global model by running it on their evaluation data to propose voting results, i.e., vote \u2208 {support,oppose}.\n5) Based on the majority of the voting result (i.e., $majorVote \\in$ {support,oppose}), participants in that round will either be rewarded or have their FML tokens slashed. Specifically, if a voter's choice, vote, differs from the majority result (i.e., $vote \\neq majorVote^*$), that voter will be penalized; otherwise, they will be rewarded. For all selected training nodes in this round, the majority voting result will determine whether they receive a reward or not.\n6) At the beginning of each round, we check the participants' remaining $FML token balances in the smart contract: if their balance is still larger than a predefined threshold (i.e., $ \\delta_0$), they will be eligible to continue the following round. Otherwise, they will be removed from the system.\n7) For each round r, the finalized aggregated global model update is determined by the majoriting voting result:\n$\\theta^r = {\\theta^{r-1}, majorVote = oppose \\\\  \\theta, majorVote = support$ \"https://ipfs.tech/"}, {"title": "B. Dataset", "content": "The dataset utilized to evaluate the proposed framework consists of in-silico data from 30 adult T1D subjects, generated using the UVA/Padova T1D simulator, a tool for glucose level simulation approved by the Food and Drug Administration (FDA) [22]. This simulator is a robust and validated method for creating simulated cases. In our study, we employed a modified version of the simulator capable of generating a cohort of T1D cases with configurable meal and insulin information, ensuring sufficient variation among the cases. We created a dataset of 30 unique adult cases, each containing 28 days of data. Each day the data are specifically formatted as a 4-channel matrix, which includes: Glucose (in mg/dL, collected by continuous glucose monitor, 288 samples per day); Meal (carbohydrate in grams, manually input by patients, normally 3-5 samples per day); Insulin (in unit, manually input by patients, normally 3-5 samples per day); Time of the day. The insulin entries can occur with a meal (administered simultaneously) or without a meal (correction bolus).\nIn a reward-based system, malicious clients are more likely to earn rewards through simple and crude means, such as generating random false data. To simulate this, we generate fake patients' data for a malicious hospital aiming to gain rewards with fabricated data. This malicious data is intentionally designed to be significantly outside normal physiological limits, ensuring it is highly unrealistic and disruptive to model training. Specifically, we use the following ranges: glucose values from -10 to 10, insulin values from -5 to 5, measure\nvalues from -3 to 3, and time values from -1 to 1. These ranges are selected based on the normal distribution of patient data but are extended far beyond typical values to maximize randomness and extremeness."}, {"title": "C. Evaluation Metrics", "content": "We use root mean square error (RMSE) and mean absolute relative difference (MARD) for BGLP, as they are most widely used metrics to measure glucose accuracy.\n$\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{k=1}^{N} (y_{g|k-PH} - y_{k})^2}$,\nwhere $9_{g|k-PH}$ denotes the prediction results provided the historical data and y denotes the reference glucose measurement, and N refers to the data size.\n$\\text{MARD} = \\frac{1}{N} \\sum_{k=1}^{N} \\frac{|y_{g|k-PH} - y_{k}|}{y_{k}}$\nThe RMSE and MARD provide an overall indication of the predictive performance."}, {"title": "D. Results", "content": "We produced the results presented in Table I, Table II, Figure 4, and Figure 5 by training two different models using various methods on different patients' data. We validated the effectiveness of our MCGP through cross-validation on known data distributions and demonstrated its generalization and zero-shot capabilities on unseen data.\n1) MCGP Achieves Advanced Model Performance by Breaking Data Silos: To demonstrate the performance of MCGP in breaking data silos by integrating the federated learning paradigm, we compared it with standalone single-node training (SNT) conducted by five other hospitals, labeled H1Single to H5Single. The RMSE and MARD losses for selected current patients are reported in Tables I and II. Our results consistently show that MCGP outperforms the other SNT methods, and even centralised training (TotalCentral), achieving the lowest RMSE and MARD losses both individually and on average. Besides, MCGP's ability to aggregate global features from all participants enables it to predict more accurately than models trained solely on local data. As illustrated in Figure 4, Participant23's data, which is part of the H5Single training dataset, does not perform as well as MCGP, particularly at the inflection points of the curve.\n2) MCGP Demonstrates Superior Generalization and Zero-Shot Capabilities: In addition to training a model that performs well on all seen patients' data, we also aim for the model to make accurate predictions on new data. To evaluate the generalization and zero-shot capabilities of MCGP, we focused on its performance with unseen patients (ID 26-30). The results, shown in both tables, highlight MCGP's ability to generalize well to new, previously unseen data.\nWhile MCGP can globally learn from all participants' knowledge, its advantage over TotalCentral diminishes in most tests on unseen patients from current patients, as indicated by\nAavg in Table I and Table II. This suggests that compared to decentralized training, centralized training allows the model to learn detailed characteristics of data from a transparent view. However, since healthcare data is privacy-sensitive and unlikely to be used in centralized training, MCGP maintains significant advantages over other SNT methods, as demonstrated by its more accurate predictions shown in Figure 5.\n3) MCGP can resist the impact of malicious participant: In a real decentralized Federated Learning (FL) scenario, maintaining the performance of the global model is crucial, especially for tasks sensitive to prediction accuracy, such as blood glucose prediction. Our experiments, which include malicious participants (indicated as w/ mal) and are summa-rized in Table I and Table II, demonstrate that models trained using our MCGP are largely unaffected by these malicious participants, maintaining performance comparable to scenarios without malicious participants. In contrast, the FedAvg method is significantly impacted by malicious clients, for example, with RMSE loss deteriorating to 111.263 compared to 9.354 for MCGP, and MARD loss worsening to 78.157 compared to 5.232 for MCGP, as illustrated in Tables I. Additionally, in centralized training, where data from malicious clients constitutes 1/6 of the total, the centralized approach (TotalCentral w/ mal) shows some resilience but still performs worse compared to pure centralized training (TotalCentral), particularly for the NNPG model, as shown in Table II."}, {"title": "E. Discussion", "content": "1) Beyond Expected Results: Federated Learning has demonstrated its efficiency in computer vision tasks [23], [24], but it continues to face challenges with distributed data optimization. Typically, models trained using FL achieve performance close to that of models trained on centralized data but rarely surpass them due to the optimization issues arising from data distribution silos [25]. However, in our research, we focus on time-series data, which is lower-dimensional compared to image data. As a result, the models are powerful enough to learn features effectively.\nOur study yielded surprisingly positive results, with the FL-trained models outperforming those trained on centralized data. This can be attributed to two main factors. First, the inherent simplicity of time-series data allows models to learn relevant features efficiently, making the differences between FL and centralized training negligible in this context. Second, more importantly, the glucose prediction task we tackled involves data with distinct personal characteristics. In centralized training, aggregating all individual features can obscure personal nuances, making it difficult for the model to differentiate between individual characteristics. Conversely, FL optimizes the model within smaller, localized datasets, allowing it to more clearly capture and distinguish personal features.\nThis personalized approach in FL not only reduces overfitting to generalized patterns but also enhances model's ability to generalize across different individuals. Consequently, FL-trained models exhibit superior performance in tasks requiring attention to individual variations, such as glucose prediction, compared to their centrally trained counterparts. This highlights the potential of FL in applications where personalized data characteristics are crucial for accurate predictions."}, {"title": "2) Decentralised System Orchestration Barriers", "content": "During the real deployment testing stage of our MCGP across five locations, we encountered a networking issue due to system environment heterogeneity among devices. Specifically, two participants ran our MCGP on different platforms: one used a VMWare Workstation\u00b2 virtual machine (VM), while the other utilized Microsoft Windows native WSL23 VM.\nSpecifically, for the VMWare VM, the network is virtualized and isolated from the local system, necessitating meticulous network configuration before running the MCGP. This added an extra layer of complexity, as users needed to ensure that all network settings were correctly configured, which required significant technical knowledge and effort. For the WSL2 VM, the participant was located in Mainland China, where the Great Firewall4 restricts access to the resources required by the MCGP. Consequently, the user needed to use a VPN to access these sites. However, configuring a VPN within the WSL2 VM proved to be particularly challenging due to compatibility issues and the additional overhead of managing VPN connections in this environment.\nThese challenges highlight common barriers in deploying an automated decentralized system orchestration. From a real engineering perspective, designing an adaptive mechanism to address such issues is crucial for ensuring smooth operation across diverse environments and enhancing the robustness of decentralized systems."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "In this work, we proposed a Multi-Continental Glucose Prediction (MCGP) framework using blockchain-enabled federated learning to address the challenges of data privacy and sharing in healthcare. Our experimental results demonstrated that the MCGP framework effectively preserves data privacy while significantly improving prediction accuracy compared to traditional methods. This approach facilitates global collaboration, allowing healthcare institutions to contribute to model training without sharing sensitive healthcare data directly. Future work will focus on extending the framework to other chronic diseases, enhancing privacy with differential privacy techniques, and improving computational efficiency."}]}