{"title": "Quantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning", "authors": ["Jun Qi", "Chao-Han Huck Yang", "Samuel Yen-Chi Chen", "Pin-Yu Chen"], "abstract": "Quantum machine learning (QML) is a rapidly growing field that combines quantum computing principles with traditional machine learning. It seeks to revolutionize machine learning by harnessing the unique capabilities of quantum mechanics and employs machine learning techniques to advance quantum computing research. This paper introduces quantum computing for the machine learning paradigm, where variational quantum circuits (VQC) are used to develop QML architectures on noisy intermediate-scale quantum (NISQ) devices. We discuss machine learning for the quantum computing paradigm, show-casing our recent theoretical and empirical findings. In particular, we delve into future directions for studying QML, exploring the potential industrial impacts of QML research.", "sections": [{"title": "I. INTRODUCTION", "content": "Despite their remarkable natural language processing [1] and computer vision [2] achievements, deep neural networks face computational bottlenecks for emerging applications like drug discovery [3] and materials science. The massive size of large language models further exacerbates this issue. As machine learning continues to advance, the limitations of classical computing are becoming more apparent, hindering progress in these fields. A promising solution on the horizon is quantum computing [4]. The advent of quantum computing holds great potential for revolutionizing or enhancing the com-putational efficiency of machine learning algorithms. Although the deployment of quantum computers is still in its early stage, cloud-based services provide accessible quantum computing environments, such as IBM Quantum Experience [5] and CUDA Quantum [6], enabling users to develop quantum algorithms for machine learning.\nQuantum machine learning (QML) is an interdisciplinary field that combines quantum mechanics and machine learn-ing [7]\u2013[9]. Leveraging QML theories and algorithms can enhance the computational efficiency of machine learning models [10]. The noisy intermediate-scale quantum (NISQ) era, with its limited number of qubits and high noise levels, presents challenges but also opportunities for exploring the potential of quantum computing for machine learning [11]\u2013[13]. In particular, variational quantum circuits (VQC) consti-tute a QML architecture [14], such as quantum convolutional neural networks [15] and quantum graph neural networks [16], for data processing and making predictions. The parametric quantum circuits (PQC) in VQC can be adjustable in the training process using optimization methods like stochastic gradient descent (SGD) to minimize the cost function in a back-propagation manner. The VQC has been demonstrated to be resilient to the quantum noise on NISQ devices [17], [18], highlighting the advantages of deploying VQC for im-plementing QML in many real-world applications.\nIn addition to quantum computing for the machine learning paradigm, we are exploring how classical machine learning can contribute to developing QML. Given the current limita-tions of quantum computers, hybrid quantum-classical neural networks, combining classical and quantum components, are commonly used in QML to use available resources best. These hybrid architectures harness the speed advantages of quantum computing for specific tasks while relying on classical com-puting for operations it performs more effectively. This paper also focuses on enhancing QML's capabilities through classical machine learning techniques, aiming to improve its ability to represent data, generalize to new examples, and expand its applicability to real-world challenges.\nIn the discussion session, we offer fresh perspectives beyond the existing QML paradigms and explore how to harness the potential of cutting-edge generative AI and emerging quantum computing technologies in real-world industry use cases."}, {"title": "II. QUANTUM COMPUTING FOR MACHINE LEARNING", "content": "Quantum computers with hundreds of logical qubits could significantly advance machine learning by offering dramati-cally faster performance than traditional methods. As illus-trated in Table I, quantum algorithms can accelerate various machine learning tasks. For instance, neural networks and Boltzmann machines benefit from quadratic speedups, while PCA and SVM could see exponential improvements. This ad-vantage stems from the unique capabilities of quantum circuits. While classical computers use simple gates like AND and OR, quantum logic gates are associated with unitary matrices and have much more representation capability than classical gates."}, {"title": "A. Variational Quantum Circuits", "content": "The Pauli rotation gates are usually utilized to create varia-tional quantum circuits (VQC). As shown in Figure 1, a typical VQC comprises angle encoding, parametric quantum circuits (PQC), and measurement.\nGiven U qubits, the angle encoding admits U Pauli ro-tation gates $R_y(\\cdot)$ with fixed angles to constitute a tensor product encoding operation. Given a classical input vector $x = [x_1,x_2, ..., x_U]^\\intercal$ into their corresponding quantum state $|X\\rangle = [|x_1\\rangle, |x_2\\rangle,...,|x_U\\rangle]^\\intercal$ through adopting a one-to-one mapping as:\n$\\ket{\\phi(x)} = \\bigotimes_{i=1}^{U} R_y(\\kappa(x_i)) \\ket{0}^{\\otimes U}$,\nwhere $\\kappa(\\cdot)$ refers to a non-linear function, e.g., $\\kappa(x_i) = \\frac{1}{1+\\exp(-x_i)}$ such that $\\kappa(x_i)$ is restricted to the domain of $[0, 1]$ and the non-linearity is introduced in the feature space.\nIn the PQC framework, we first implement quantum entan-glement through a series of CNOT gates and then leverage Pauli rotation gates $R_x (\\alpha_i)$, $R_y (\\beta_i)$ and $R_z(\\gamma_i)$ with ad-justable angles $\\alpha_i, \\beta_i, \\gamma_i$ to construct a parametric circuit"}, {"title": "B. Quantum Reinforcement Learning", "content": "A successful QML application based on the VQC structures in our work is quantum reinforcement learning (QRL) [19]\u2013[23]. As illustrated in Figure 2, the VQC model, as the reinforcement learning agent, is processed on a quantum computer or quantum simulator. The classical computer selects the optimization techniques and controls quantum-classical interactions.\nQuantum Q-learning stands for the main approach to QRL. Quantum Q-learning, using a VQC as the agent, learns the best possible action-value function without following a specific policy. It starts with a random initialized $Q^{\\pi}(s, a)$ for all states $s \\in S$ and actions $a \\in A$, and it uses the VQC to represent $Q^{\\pi}(s,a)$. The experience replay technique is employed to store past experiences as transition tuples $s_t, a_t, r_t, s_{t+1}$ in a CPU memory. After collecting sufficient experience information, the VQC agent randomly samples them to update the VQC to make it more stable. It also uses a separate target network to reduce the dependence on the current predictions.\nQuantum Q-learning is trained by minimizing an objective function like mean squared error (MSE), as shown in Eq. (2).\n$\\mathcal{L}(\\theta) = \\mathbb{E}\\big[ r_t + \\gamma \\max_{a' \\in A} Q(s_{t+1}, a'; \\theta^-) - Q(s_t, a_t; \\theta) \\big]^2$\nwhere $\\gamma$ is a constant factor less than one used to discount future rewards, and $r_t$ is an immediate reward at time t associated with the state $s_t$ and action $a_t$. Other loss functions can also be considered, e.g., Huber loss or mean absolute error (MAE) [24]. In our work, QRL can solve environments with discrete observations, such as the Frozen Lake and Cognitive-Radio, where target network and experience replay are deployed. We also attempt to use quantum Q-learning for more sophisticated efforts in continuous observation spaces like Cart-Pole."}, {"title": "C. Quantum Convolutional Neural Network", "content": "Quantum convolutional neural networks (QCNN) [15], [25] is a novel approach to neural networks that potentially lever-age quantum computing principles to outperform classical convolutional neural networks (CNN) in many tasks. In-stead of traditional convolution operations, QCNN employs quantum convolution, which involves applying the quantum gates to input qubits to extract features. This process can be more efficient than classical convolution, especially for high-dimensional data. Quantum convolution can extract more meaningful features from data due to quantum systems' inher-ent parallelism and entanglement.\nOne of our real-world applications of QCNN is speech signal feature extraction with QCNN [26]. As shown in Figure 3, we utilize the VQC structure to compose the quantum convolution that transforms the Mel-Spectrogram of speech signals into the corresponding QCNN encoded features. Figure 4 compares the signal signal features encoded by classical CNN and QCNN models. The QCNN exhibits a more discriminative representation of speech signals than the original Mel-Spectrogram and CNN encoded features, which results in even better speech recognition accuracy in our experiments of spoken language understanding."}, {"title": "III. MACHINE LEARNING FACILITATES QUANTUM MACHINE LEARNING", "content": "Our other research focuses on using machine learning tech-niques to facilitate QML development. Although the theoreti-cal understanding of classical machine learning is far behind the rapid growth of the state-of-the-art empirical studies of generative AI, we can leverage the classical machine learning theory to scale up the QML for more complicated tasks. For one thing, we exploit a hybrid quantum-classical neural network to improve quantum models' representation and gen-eralization powers. For another, we rely on the generative AI for quantum circuit architecture search."}, {"title": "A. Hybrid Quantum-Classical Neural Neworks", "content": "Hybrid quantum-classical neural networks combine the power of classical neural networks with the potential ad-vantages of quantum components. These networks aim to harness the strengths of both paradigms to tackle complex problems that are challenging for classical or quantum systems alone [27].\nOur previous work proposed an end-to-end quantum learn-ing paradigm, TTN-VQC [28], integrating a tensor-train net-work (TTN) [29]\u2013[31] with the VQC structure as shown in Figure 5. TTN is a classical simulation of quantum circuits and provides a powerful and efficient way to represent high-dimensional tensors. When TTN is used on top of the VQC structure, TTN implements input feature dimensionality re-duction while improving VQC's representation power [32]. In particular, given U qubits and M times' measurement, the approximation error associated with the representation power is upper bounded by $O(\\frac{U}{M})+O(\\frac{1}{M^2})$. However, the upper bound still relies upon the number of qubits, so the approximation error cannot be reduced to a small scale as we can access a small number of qubits.\nWe proposed a transfer learning-based approach to improve the VQC's representation power [33]\u2013[35]. In this method, the classical TTN model is pre-trained and then integrated into the VQC structure. The resulting Pre+TTN-VQC architecture benefits from the TTN's pre-existing knowledge, making it less reliant on qubit constraints. Our experimental results of handwritten digit classification and semiconductor quantum dots corroborate our theoretical analysis."}, {"title": "B. Quantum Circuit Architecture Search", "content": "Quantum circuit architecture search (QCAS) automatically designs optimal quantum circuits for specific tasks [37]. It involves exploring a vast space of possible circuit configura-tions to find one that best balances performance, efficiency, and resource requirements. The search space of quantum circuit architectures includes factors like the number of qubits, gate types, and connectivity. We consider search algorithms to explore the search space and identify promising circuit architectures.\nFigure 7 showcases a generative model approach to de-signing quantum circuit architectures. Generative models, e.g., diffusion models, generate potential quantum circuit structures tailored to specific tasks [38]. Rather than directly optimizing quantum circuits on a quantum processing unit (QPU), we refine the generative models to prioritize circuit designs that are more likely adequate for the given task. Generative models offer a potential solution to the optimization hurdles faced in VQC, allowing for exploring deeper quantum architectures. Reinforcement learning (RL) provides another avenue for exploring quantum circuit architectures [39]\u2013[42]. An RL agent, often a neural network, generates and evaluates potential quantum circuit designs. The specific task or problem to be addressed serves as the environment for the RL agent. By learning from the RL rewards, e.g., accuracy or other relevant metrics, the RL agent refines its approach to find the most practical quantum circuit design. Further development combines the RL and QAS into a single framework using differentiable programming to optimize the VQC parameters and their architecture parameters simultaneously [43], [44]."}, {"title": "IV. DISCUSSIONS", "content": "The intersection of machine learning and quantum com-puting is a rapidly evolving field with significant potential. We have explored novel QML approaches using quantum circuits to expedite specific machine-learning tasks. Besides, we applied classical machine learning principles to design innovative quantum algorithms, including hybrid quantum-classical neural networks and quantum circuit optimization techniques. During the NISQ era, classical machine learning methods, like pre-trained generative models and tensor net-works, can enhance the performance of QML models, such as VQC, used in our work. However, our research primarily relies on classical simulations, assuming the existence of quantum logic qubits. For more practical use cases of QML, our future study of QML should consider the QML algorithms on realistic quantum computers.\nQuantum noise, a significant challenge in quantum com-puting, arises from interactions between qubits and their environments. Machine learning offers promising solutions to mitigate these noise-induced errors [13]. In particular, we mainly consider the critical approaches as follows:\n1. Quantum Error Correction Code (QEC) Optimization\n\u2022 Neural Networks: Train neural networks to optimize QEC parameters, such as syndrome decoding rules, to minimize error rates.\n\u2022 Reinforcement Learning: Use RL agents to learn optimal error correction strategies, considering the quantum hard-ware's specific noise characteristics.\n2. Noise Characterization and Modeling\n\u2022 Generative Models: Employ generative models like vari-ational autoencoders or generative adversarial networks to learn the underlying distribution of noise patterns.\n\u2022 Anomaly Detection: Using machine learning techniques to identify anomalous noise events that deviate from expected patterns, enabling targeted mitigation strategies.\n3. Dynamic Noise Mitigation\n\u2022 Adaptive QEC: Implement adaptive QEC schemes that adjust the error correction strategy based on real-time noise measurements.\n\u2022 Machine Learning Based Gate Optimization: Using ma-chine learning to optimize gate sequences to minimize the impact of noise dynamically.\n4. Quantum Circuit Compilation\n\u2022 Noise-Aware Compilation: Developing machine learning algorithms that compile quantum circuits to minimize noise-induced errors while preserving circuit functional-ity.\n\u2022 Error-Aware Gate Synthesis: Using machine learning to synthesize quantum gates that are more robust to specific noise sources."}]}