{"title": "A Meta-Engine Framework for Interleaved Task and Motion Planning using Topological Refinements", "authors": ["Elisa Tosello", "Alessandro Valentini", "Andrea Micheli"], "abstract": "Task And Motion Planning (TAMP) is the problem of finding a solution to an automated planning problem that includes discrete actions executable by low-level continuous motions. This field is gaining increasing interest within the robotics community, as it significantly enhances robot's autonomy in real-world applications. Many solutions and formulations exist, but no clear standard representation has emerged. In this paper, we propose a general and open-source framework for modeling and benchmarking TAMP problems. Moreover, we introduce an innovative meta-technique to solve TAMP problems involving moving agents and multiple task-state-dependent obstacles. This approach enables using any off-the-shelf task planner and motion planner while leveraging a geometric analysis of the motion planner's search space to prune the task planner's exploration, enhancing its efficiency. We also show how to specialize this meta-engine for the case of an incremental SMT-based planner. We demonstrate the effectiveness of our approach across benchmark problems of increasing complexity, where robots must navigate environments with movable obstacles. Finally, we integrate state-of-the-art TAMP algorithms into our framework and compare their performance with our achievements.", "sections": [{"title": "1 Introduction", "content": "Task And Motion Planning (TAMP) is the problem of finding high-level plans to accomplish assigned tasks (task planning), as well as the motions needed to execute these plans (motion planning). Consider a warehouse robot collecting items and placing them in bins for shipment. At the task level, it determines the sequence of actions needed, such as collecting items and navigating. At the motion level, it plans the movements considering obstacles. Merely sequencing task and motion planning may lead to ineffective solutions, with the robot possibly moving directly toward the goal, ignoring obstacles. In contrast, integrating these components effectively allows the robot's plan to adapt dynamically. For instance, if a pallet blocks an aisle, the robot will try to move it before proceeding further.\nA wide range of proposed solutions and formulations exist, but no clear standard representation has emerged [17]. In this paper, we propose a formalization and implementation for modeling TAMP problems related to navigation tasks involving multiple movable objects, which remains independent of specific planners and languages. Additionally, we offer an open-source modeling tool, built within the open-source Unified Planning (UP) library\u00b9, that facilitates seamless integration of setups and planners for evaluation and comparison.\nAs evidence of our approach, we provide an exhaustive benchmarks suite aligned with existing TAMP evaluation criteria [17], such as handling infeasible task actions, managing large task spaces, and balancing the trade-off between task complexity and motion execution.\nFurthermore, we devise and integrate into our overall framework a planning technique tailored to this class of problems that allows to combine off-the-shelf automated planners with off-the-shelf motion planners. We exploit the Meta-Engine feature of the UP library to instantiate our framework with any task planner available through the library. Then, we use the Open Motion Planning Library (OMPL) [25] to plan motions (but any other solver could be exploited). Our approach fits into the category of interleaved TAMP [11, 5]: a Benders Decomposition [2] of the TAMP problem where the automated task planner decides a candidate plan disregarding the motion constraints. Then, the motion planner tries to refine the plan by adding the motion details. If it fails, it analyzes the reason for the failure and derives an explanation that the task planner can use to prune its search for new plans. In this sense, the core of our approach is what we call topological refinement: we approximate the area explored by the motion planner, derive the encountered obstacles, and exploit them to formulate new constraints that we add at the task level. This refinement allows us to prune entire symbolic space regions rather than just the immediate unrealizable action, as typically done in traditional TAMP approaches.\nOne drawback of using an off-the-shelf automated planner is the need to restart the task planning search every time the framework learns a new constraint. Hence, we also present a simple but effective algorithm, called TAMPEST (Task And Motion Planning by Encoding into Satisfiability Testing), for task planning based on the Satisfiability Modulo Theory (SMT) [1] framework that can avoid restarts by exploiting the incrementality feature of modern SMT solvers.\nFinally, we integrated PDDLSTREAM [10], a solver increasingly used in TAMP, into our framework, making it one of the solvers supported by the UP library. Given our TAMP formulation, which is accepted as input by any UP-supported solver, we automatically convert it to the format supported by PDDLStream, so it can be used to solve TAMP problems without the need for customization. This integration demonstrates our ability to completely separate problem formulation from the solving algorithm, empowering users to compare various solvers using identical problem formulations and input data.\nWe include a thorough experimental assessment, comparing various task planners, sampling-based motion planners, and benchmarking against PDDLSTREAM. We show TAMPEST's effectiveness and efficiency, particularly with topological refinements.\nThe paper is organized as follows. Section 2 formalizes our TAMP"}, {"title": "2 Problem Statement", "content": "In this Section, we formalize a TAMP problem with mobile agents moving within a workspace populated by task-dependent obstacles. As a motivating example, consider a robot tasked to navigate an office environment with multiple sliding doors controlled by button presses (see Figure 1). To reach its destination, the robot needs to find a sequence of actions to move and open doors. Simultaneously, it must physically execute these actions, which means finding motion primitives ensuring collision-free movement. Upon pressing the button, it must be aware of the change in door configuration so it can pass through and reach the assigned target. A formal definition of this class of problems follows.\nDefinition 1. A (ground) Task And Motion Planning problem is a tuple $\\psi = (R, W, C, U, V, I, A, G)$ such that:\n\u2022 R is a set of mobile agents, where each agent r is characterized by a certain geometric model.\n\u2022 W$\\subset$$\\mathbb{R}^N$ (N = 2 or N = 3) is the workspace, that is the physical volume of all end point positions reachable by the robots in R. We define $W_f$ as the subset of W free from fixed obstacles.\n\u2022 U is a map that assigns to each agent $r \\in R$ a motion model $U_r$, that is a mathematical representation of the kinematic and dynamic laws that allows the agent to evolve within W.\n\u2022 C is the configuration space, where $C_r \\subset C$ is that subset of C that represents the joint configurations that $r\\in R$ may assume given its motion model. In this context, $occ(r, q) \\subset W_f$ is the set of points in $W_f$ occupied by r when in configuration $q \\in C_r$.\n\u2022 V = {$f_1, .., f_k$} is a finite set of variables (or fluents) $f \\in V$, each with a finite or infinite domain $Dom(f)$.\n\u2022 I is the initial task state, which assigns a value $I(f) \\in Dom(f)$ to each $f \\in V$.\n\u2022 A is a set of actions a = (P, E, M) such that:\nP is a set of preconditions $pre \\in P$, with pre a Boolean combination of atoms $f = v$, with $f \\in V$ and $v \\in Dom(f)$.\nE is a set of effects $eff \\in E$ each of the form $f := v$ with $f \\in V and $v \\in Dom(f)$.\nM is a (possibly empty) set of motion constraints of the form $(r, q_s, q_G, O)$, where $r \\in R$ is the agent performing a, $q_s \\in C_r$ is its start configuration, $q_G \\in C_r$ is the target configuration, and $O \\subset 2^{RxC}$ is a function associating the other movable agents, which r must avoid, to the configurations they currently occupy.\n\u2022 G is the goal condition, represented as a Boolean combination of atoms of the form $f = v$, with $f \\in V and $v \\in Dom(f)$.\nFocusing on the semantics of the problem, a state S is a total assignment of values to the fluents such that $S(f) \\in Dom(f)$ for all $f\\in V$. An action is applicable in a state S if its preconditions are satisfied by substituting each fluent f appearing in the Boolean combination with S(f) and if all the motion constraints M are satisfiable.\nA motion constraint $(r, q_s, q_G, O)$ is satisfied if there exists a collision-free path $\\tau: [0,1] \\rightarrow C_r$ that moves r from $\\tau(0) = q_s$ to $\\tau(1) = q_G$. $\\tau$ must be compliant with the motion model $U_r$, must reside in $W_f$, i.e., $\\forall t \\in [0,1]. occ(r, \\tau(t)) \\subseteq W_f$, and"}, {"title": null, "content": "must be collision-free with the obstacles listed on O, i.e., $\\forall t \\in [0, 1]. \\forall(r', q') \\in O. occ(r, \\tau(t)) \\cap occ(r', q') = \\emptyset$.\nThe successor of S, once applied a = (P, E, M), is a(S) where:\n$\\begin{equation} a(S)(f) = \\begin{cases} v & \\text{if } (f := v) \\in E\\\\ S(f) & \\text{otherwise} \\end{cases} \\end{equation}$\nThe plan solving $\\psi$ is a sequence $(a_0,...,a_n)$ of actions such that $a_0$ is applicable in I, each action $a_i$ is applicable in $a_{i-1}(a_{i-2}((a_0(I))))$, and the final state satisfies G.\nIn our example, r moves in a deterministic and fully observable 2D map where fixed obstacles are the walls. Thus, $W_f$ encompasses all the points on the map not occupied by the walls. The robot moves according to a ReedsShepp-type motion model [20], i.e., its configuration has the form $(x, y, \\theta)$, where (x, y) are Cartesian coordinates and $\\theta$ is the orientation angle. A motion constraint $(r, q_s, q_G, O)$ is satisfied if we find a path that connects $q_s$ to $q_G$ while avoiding the doors in O, where a door is a movable object that changes its configuration from closed to open when pressing its open button.\nDefinition 1 is a ground formalization of the TAMP problem we tackle. For the sake of brevity, we only formalize the syntax and semantics of the ground representation. In practical modeling, we adopt a lifted representation, as is customary in the planning community. Our peculiarity is to consider movable agents and configurations of interest as objects of the problem, allowing fluents to have subsets of configurations as domains. This is useful for specifying goals for the agents and expressions evaluating movable agents or configurations. If $e_r$ is an expression evaluating a movable agent and $e_q$ is an expression evaluating a configuration, a motion constraint will have the form $(e_r, e_{qs}, e_{qg}, O_r)$, with $O_r$ a set of pairs of the form $(e_r, e_q)$. The semantics is given by grounding: we assess the expressions within the lifted motion constraint in the state where the action starts, and we obtain the ground motion constraint of Definition 1."}, {"title": "3 Meta-Engine Framework", "content": "To effectively and efficiently solve the TAMP problem $\\psi$, we developed a meta-engine framework that allows to interleave an off-the-shelf task planner $\\xi$ and an off-the-shelf motion planner $\\rho$, provided as inputs. The basic idea of the approach is to invoke the task planner on the planning problem obtained by disregarding all the motion constraints of every action to generate a candidate plan. The candidate plan is then checked to ensure all the motion constraints of the involved actions are realizable. If this is the case, then the plan is returned, otherwise we extract information from the search space of the motion planner for the motion constraint that is not realizable; this information is then used to refine the task problem and we restart the task planner to find a new candidate plan. In this section, we detail this general schema and we explain how the refinement is computed.\nAlgorithm 1 reports the pseudo-code of the meta-engine. The task planner $\\xi$ searches for a plan that is valid for the problem $\\psi$ while disregarding the motion constraints (line 5). By excluding the motion aspect, the problem is reduced to a traditional task-planning problem. If a valid plan is found, the function CHECKPLANMOTIONS checks all the motion constraints of all the actions involved in the plan (line 7). Since many motion planning algorithms are sample-based and do not guarantee termination if a path does not exist, we set a timeout $t_p$ to each invocation of the motion planner. The algorithm keeps a cache $\\gamma$ which stores each motion constraint successfully checked and its trajectory $\\tau$. If all the motion constraints of all the actions of $\\pi$ are found to be realizable by the motion planner, then"}, {"title": null, "content": "the constraint $(r, q_s, q_G, O)$ is infeasible, it means that the target $q_G$ cannot be reached either because it is blocked by fixed obstacles or by movable ones (or that we did not give enough time to the motion planner, but this is handled as discussed above). In the first case, there is simply no plan that solves the high-level task that was assigned to r. In the second case, some of the obstacles in O prevent r from reaching the target, hence some of them must be moved to find a valid plan. In our motivating example, this means that some closed door prevents the robotic agent from reaching its final destination.\nIf the constraint $(r, q_s, q_G, O)$ is invalid, we find the convex hull\n$\\begin{equation} H(q_s) = \\{\\sum_{j=1}^K x_j p_j | \\sum_{j=1}^K x_j = 0; \\sum_{j=1}^K = 1\\} \\end{equation}$\nof the points {$p_1,..., p_k$} sampled by the motion planner from $q_s$.\nLet X be the set {$q_1,..., q_m$} $\\subset C_r$ of interesting configurations that the agent may assume, i.e., the motion constraints' configurations involving r for the ground case or the objects of type Configuration for the lifted case. We check which configurations yield an occupancy that does not belong to $H(q_s)$. The idea is that $H(q_s)$ is an approximation of the positions that the agent can reach and we want to compute the set of interesting locations that are unreachable from the specified starting configuration $q_s$. We call the resulting set $\\sigma$ and we define it formally as {$q \\in X | occ(r, q) \\nsubseteq H(q_s)$}.\nThe second element of the explanation concerns the blocking movable obstacles. Not all the obstacles in O block the agent from reaching its goal, hence we isolate the obstacles that prevent the motion planner from computing a feasible path connecting $q_s$ to $\\sigma$. We call this set $\\omega \\subset O$. This set can be efficiently computed by keeping track of the collisions analyzed by the motion planner: if a collision happens in a point $p\\in occ(r', q')$ with $(r', q') \\in O$, we add the element $(r', q')$ to $\\omega$. The intuition is that obstacles we do not collide with do not hinder finding a valid plan, offering no useful information for pruning the task planner's search space. Hence, they can be omitted.\nCHECKPLANMOTIONS collects all the conflicts in $\\mu$ and uses this data to refine the problem (line 11). The idea is to prevent the task planner from using actions that are not feasible because of the explanations in $\\mu$. We present here two refinements, one for the grounded problem of Definition 1 and a more practical one for the lifted case.\nIn the grounded refinement, we remove any actions with motion constraints that conflict with explanations in $\\mu$, thereby refining the set of actions. Formally, given $\\psi = <R, W, C, U, V, I, A, G)$, we return $\\psi' = (R, W, C, U, V, I, A', G)$ with A' defined as:\n$\\begin{equation} \\{a = (P, E, M) \\in A | \\forall m = (r, q_s, q_G, O) \\in M.\\\\ \\forall (r, q_s,\\sigma,\\omega) \\in \\mu \\land (q_G \\in \\sigma \\lor \\omega \\subseteq O)\\} \\end{equation}$\nThis prevents the execution of actions with known unrealizable constraints (with the given timeout $t_p$)."}, {"title": "4 SMT-based Specialization", "content": "We tailored our framework to leverage the incremental solution capabilities of SMT-based solvers. Such solvers maintain a stack of constraints (called assertions), enabling efficient repeated satisfiability checks as constraints are pushed onto or popped from the constraint stack. This feature eliminates the need for restarting the planning routine upon failure to find a valid plan, enhancing overall scalability."}, {"title": null, "content": "Our approach is called TAMPEST and it iterates between task and motion planning while progressively increasing the search depth until finding a valid plan or reaching the maximum step horizon $h_{max}$.\nAs shown in Algorithm 3, the general schema is that of the meta-engine in Algorithm 1, with the outer while loop serving for the refinement of the motion planner timeout $t_p$, the learned explanations $\\mu$, and the horizon h. The inner loop is the focal point of the approach. We encode the task part of $\\psi$ as an SMT planning problem, analogously to many SATPlan-like approaches [16, 21], and we add to the assertions relative to the initial state, which hold at step 0 (line 6). At each step h$\\leq$ $h_{max}$, we generate and add the assertions f and l (lines 9-13). As in [5], f asserts that a selected action implies its preconditions and effects, the state remains the same unless changed by an action effect, and only one subset of non-mutex ac- tions is taken at time. Assertion l, instead, characterizes the goal. $\\zeta$ searches for a valid plan $\\pi$, that means finding a satisfying assignment for the asserted logical formulae (line 15). If a model exists, we check the motion feasibility of $\\pi$ via CHECKPLANMOTIONS, possibly exploiting the cached information (line 16). If all constraints are satisfied, we return the plan and the paths (line 18). Otherwise, we pop the solver and add the logical lemmas representing the topological refinements $\\mu'$. We use the same logical formulation used for the lifted refinement in the meta-engine encoding the preconditions as an SMT formula instantiated at all the symbolic times $i \\in \\{1, ..., h\\}$. Once this data is added, we push the solver, re-add the goal, and try to find a solution again (lines 20:25). Every time we enlarge the encoding bound, we permanently add the lemmas for all the explanations in $\\mu$ at h, ensuring their validity across all encoding steps (line 11).\nThe lifted case is similar, but requires the addition of preconditions to eliminate all the groundings that would conflict with the learned explanations. For each action a in the lifted TAMP problem, we add the following precondition for each lifted motion constraint $m$ $(e_r, e_{qs}, e_{qc}, O^l)$ of a and for each explanation $(r, q_s, \\sigma,\\omega) \\in \\mu$:\n$\\begin{equation} e_r \\neq r \\lor e_{qs} \\neq q_s \\lor \\bigvee_{q \\in \\sigma} e_{qG} \\neq q \\lor \\bigvee_{(r',c') \\in \\omega} (e_r \\neq r') \\lor (e_c \\neq c')) \\end{equation}$\nwhich informally means that m of a is consistent with the explanation if any of the following conditions are met: i) $e_r$ does not evaluate to r; ii) $e_{qs}$ does not evaluate to $q_s$; iii) the destination $e_{qG}$ does not evaluate to any element of $\\sigma$; iv) there exists an obstacle in $\\omega$ that has a different configuration or doesn't exist in this constraint.\nTheoretical Guarantees. Many motion planners exist and can be leveraged by our meta-engine. In our case, we exploit sampling-based motion planners, specifically the Rapidly exploring Random Tree (RRT) algorithm [18] and its Lazy version. Our proposal be- comes probabilistic complete assuming the task planner is complete, because the probability of finding a solution tends to 1 as the time $t_p$ given to the motion planner to compute a plan tends to infinity. We also assume that when a motion from $q_s$ to $q_G$ fails, $q_G \\in \\mu$ at line 7 of Algorithm 1 (the destination is always unreachable), preventing to enter an infinite loop as the interesting configuration set is finite."}, {"title": "5 Modeling and Benchmarking", "content": "Besides formulating the TAMP problem of Definition 1 and defining suitable TAMP solvers, we developed a comprehensive open-source framework for modeling and benchmarking these problems. An overview of the key components of this implementation follows, along with a description of the benchmark suite we designed.\nUP\u00b9 is an open-source, planner-agnostic planning library that collects planning tools and algorithms to model, manipulate, and solve classical, numerical, temporal, and other complex tasks, such as multi-agent assignments. To enable the modeling of TAMP problems, we extended the TAMP modeling of the UP adding obstacle avoidance. Besides preconditions and effects, motion actions include motion constraints of the form path(r, qs, [qG], {o : qo\u2200o\u2208 O}), i.e., there \u2203\u03c0 : [qs, [qG]] \u2192 Cr for r \u2208 R and {0 : q\u2200o\u2208 O}, as in Definition 1. Non-fixed objects are defined as Movable Objects with a geometric and motion model. Their configurations are Configuration Objects with a value in the form provided by the motion model of the agent (e.g., (x, y, yaw) in SE(2)). The workspace is an \u041e\u0441\u0441\u0438\u0440\u0430\u043f\u0441\u0443 \u041cap collecting all useful data for motion planning and collision avoidance with fixed obstacles, such as the 2D image or 3D mesh of the operating environment and its reference system. We allow fluents that accept as input a Movable Object and output its current Configuration Object within the Occupancy Map. As for all the tools of the UP library, this extension is independent of the planning language and planner available to define and solve this problem.\nWith this extension, we offer a set of benchmarks that task robotic agents with Navigating Among Movable Obstacles (NAMO) [24], i.e., moving through a workspace while removing or avoiding movable obstacles. As in [17], we assume the search space is i) geometric: motion planning focuses only on finding feasible object poses based on the geometric constraints of the world; ii) fully observable:"}, {"title": null, "content": "the initial state is completely known both geometrically and semantically; iii) deterministic: world state changes exclusively result from planned actions, and object motions precisely adhere to the motion planner's output. We consider the following evaluation criteria:\n\u2022 Infeasible task actions. Some task actions are impossible due to the lack of corresponding feasible motion plans caused by obstructing obstacles.\n\u2022 Large task spaces. The task planning problem requires substantial search effort.\n\u2022 Motion/Task Trade-off. The problem can be solved with fewer steps if the right obstacles are moved.\n\u2022 Non-monotonicity. Some objects need to be moved more than once for achieving the goal.\n\u2022 Non-geometric actions. Some actions, like perception, change the discrete state but not the robot configuration.\nThe description of our benchmarks follows. For each domain, we offer a comprehensive setup, ensuring faithful replication in both 2D and 3D environments. This approach guarantees reliable assessment of solver performance, even within complex search spaces. In 2D scenarios, movable objects are polygons and the robot navigates using a ReedsShepp path within a black-and-white map, where black represents areas occupied by fixed obstacles. In 3D, objects are 3D rigid bodies and move according to an SE(3) motion model. Due to limited space, we'll discuss only the benchmarks deemed paradigmatic according to the outlined evaluation criteria (see Table 1):\n\u2022 Doors. One robot needs to navigate through N initially closed doors to reach a final destination, using the {move, open} action set (see Figure 1). move enables the robot to navigate from a start to a goal location and incorporates a motion constraint that avoids collisions with movable and static obstacles (doors and walls). open allows the robot to open a door when positioned in front of it, like pushing a button. Once the button is pushed, the door configuration changes instantaneously from closed to open. M extra locations are randomly sampled in the free space. All locations are connected from a task planning perspective, but the additional ones don't aid in achieving the goal; they merely expand the task space. Thus, even if the problem is simple, the optimal plan contains 2N+1 steps while the worst-case scenario needs 2N+M+1"}, {"title": null, "content": "steps to take the robot from start to goal while opening all the doors and visiting all extra locations (large task space). Closed doors make some locations unreachable (infeasible task actions).\n\u2022 Maze. A robot must navigate out of a maze while visiting M points randomly distributed within it (see Figure 2(a)). N doors block various passages, not all leading to exit or target locations. Their motion model requires the motion planner to compute opening paths. Actions are {move, open}. Again, we are exploring a large task space equipped with infeasible task actions. Moreover, we should find a good motion/task trade-off to efficiently solve the problem: while opening all doors and reaching the assigned targets is valid, only opening necessary doors yields efficiency.\n\u2022 Delivery. Inspired by the delivery domain of IPC, Maze locations become parcels with no geometry and motion model. They are distinguished by colors and must be arranged into rows by color, each row delivered before the next (see Figure 2(b)). Actions are {move, open, load, unload}, where load involves collecting a parcel and placing it atop an agent. unload enables the agent to remove an item from its cargo and deposit it at a specified location (large task space). The robot has a fixed capacity (numerical problem), and can unload packages only when positioned in front of the unloading location, though some parcels are already at their stations. N doors block N passages, some of which are useful to reach the unloading area (unfeasible task actions). The layout of the unloading area and the presence of obstructing doors influence the motion/task trade-off. Parcels initially at unloading stations enable assessment of non-monotonicity: if a parcel blocks the unloading of other items, it must be temporally relocated.\n\u2022 Rovers. We reproduce the rover domain of IPC to demonstrate the generality of our approach (see Figure 2(c)). N rovers must collect rock and soil samples, separated from each robot by a door. Then, they must calibrate their cameras, photograph M objectives located around each sample without occlusions, and send the results back to a lander. Due to obstacles that limit the reachability of parts of the workspace, one rover must be utilized for each sample and the objectives around it. Actions are {move, open, calibrate, sample rock, sample soil, send analysis, drop, take image, send image}, and some of them change only the discrete state and not the configuration space (non-geometric actions)."}, {"title": "6 Related Work", "content": "Many planners exist that combine symbolic and geometric search. As an example, the aSyMov planner [3, 4] interleaves a FF-based task planner with lazily-expanded roadmaps. However, this approach is impractical when action plans are valid in the symbolic space"}, {"title": null, "content": "but infeasible in the geometric one. To address this issue, many approaches have been developed over the years. For instance, Dornhege et al. [7] add semantic attachments to the definition of the task, and they call the motion planner after each action to check both its geometric and semantic feasibility. Other strategies, as discussed in [15, 23, 9, 26, 8], are tailored to specific classes of manipulation problems, limiting their adaptability to new domains, such as those introduced in this paper, without significant engineering effort. They lack a modular, domain-agnostic problem description language with clear semantics. In this regard, PDDLStream integrates symbolic planners and black-box samplers by extending Planning Domain Definition Language (PDDL) [12] with streams: declarative specifications of sampling procedures that link in a black-box way the symbolic representation of constraints with their sample-based counterparts. In TAMP, they are used to map the existence of collision-free paths with the functions checking their validity. Our formulation is less general as it is tailored specifically towards TAMP problems. However, this targeted approach allows us to exploit the motion planner's output to prune large regions of the task search space, significantly reducing the computational overhead.\nIndeed, calling the motion planner after each symbolic call is time-consuming, particularly when dealing with geometrically unfeasible states. To enhance efficiency, the geometric search is typically limited to candidate symbolic plans. Srivastava et al. [23], for example, interface a task planner with an optimization-based motion planner and use a heuristic to remove occluding objects. Dantam et al.. [6] propose TMKit: an incremental SMT solver that incrementally generates symbolic plans and call the motion planner for validation. They all suffer from long processing time, solve problems consisting of a limited number of actions and, given their focus on manipulation tasks, handle a limited quantity of manipulable objects. Some approaches exist that tries to overcome these limitations. Similar to TMKit, our SMT specialization employs an incremental approach to generate a valid symbolic plan. Initially, it assumes the validity of all motion actions within the plan. Once a task plan is established, it invokes the motion planner to verify feasibility. For any unfeasible motion action, we generate topological refinements on the geometric space. These refinements are leveraged at the task level, enhancing efficiency and allowing for plans with many actions."}, {"title": "7 Experimental Evaluation", "content": "In this Section, we present experiments evaluating our meta-engine framework across various task and motion planners. We assess the effectiveness of its SMT-based specialization and quantify improvements from topological refinements. Moreover, we compare our"}, {"title": null, "content": "framework with PDDLSTREAM, highlighting our ability to integrate existing solvers and the superior performance of our proposal. Benchmarks and solvers are available in the supplementary material, to be released upon paper acceptance. Our test cases follows:\n\u2022 Doors. We feature $n_d \\in$ [1, 2, 4, ..., 10] closed doors that must all be open to reach the final destination. Additionally, either 0 ($n_c$ = [(0, 0)]) or 10 extra configurations are randomly distributed in the reachable space ($n_c$ = [(10,0)]), the initially unreachable space ($n_c$ = [(0, 10)]), or equally split between both ($n_c$ = [(5,5)]).\n\u2022 Maze. We increase the complexity of our domain by introducing $n_d \\in$ [1, 2, 3, ..., 10] closed doors within a maze setup, where not all doors block the final destination. The extra-configurations becomes $n_c \\in$ [0, 1, 2, 3, ..., 10] mandatory targets for inspection, randomly located within the maze.\n\u2022 Delivery. We sample $n_d \\in$ [1,2,4,..., 10] closed doors, not all obstructing the target, and $n_r + n_g \\in$ [0,1, 2, 3, ..., 8] red and green parcels. Colors are randomly sampled among available parcels. Parcels must be delivered in two rows, with at most 4 red parcels placed in the front and 4 green parcels in the back. $d_r \\leq 3$ red parcels and $d_g \\leq 3$ green parcels are already in their delivery spots, eventually blocking the reachability of the unloading locations behind them, that means $n_c$ = x = [(nr,ng, dr, dg)]. The robot's load capacity $n_i$ ranges from 1 to 4.\n\u2022 Rovers. We involve 2nd robots with $n_d \\in$ [1,2,3,4,5]. Each robot analyzes either one soil or one rock sample, each one situated one closed door away from the robot. We design nc E [0, 1, 2, 3, 4] objectives to be photographed around each sample.\nWe tested Maze and Rover domains in both 2D and 3D setups, while Doors and Delivery tests were limited to their 2D implementations. Indeed, these setups closely resemble those of the former domains.\nWe instantiate our Meta-Engine with FAST-DOWNWARD [14], the Expressive Numeric Heuristic Search Planner (ENHSP) [22], and TAMER [27], and evaluate their performance compared with TAMPEST (with $h_{max}$ = 100), where the last three can solve numerical problems such as our Delivery domain. We combine each solver with the RRT [18] and LAZYRRT motion planners (with $t_p$ = 3s). In 2D scenarios, we implement an ad-hoc collision checker that verifies the feasibility of a robot's pose by ensuring that its footprint doesn't intersect obstacles. In 3D, we exploit the Flexible Collision Library [19]. Finally, we study our refinement schema by disabling some of the explanations computed by CHECKPLANMOTIONS. We set the topological refinements $\\mu' = \\{(\\sigma, \\omega)\\}$ as follows. All-Refinements is the full algorithm as described in the previous sections. Only-Reachables assumes $\\omega = O$, disabling the analysis of the obstacles with which the agent collided, but retaining the analysis of the unreachable points. Only-Obstacles forces $\\sigma = \\{q_G\\}$, retaining the obstacles analysis but disabling the unreachable configurations one, to only remove the target location. No-Refinements forces $\\sigma = \\{q_G\\}$ and $\\omega = 0$, removing only the violated constraint.\nFocusing on PDDLSTREAM, we explore its incremental, focused, binding, and adaptive variants equipped with FAST-DOWNWARD [13], as provided by default. To enable them to solve our benchmarks, we convert the motion constraints into streams, mapped with functions that certificates the existence of paths. We employ the same motion planners and collision checkers as before.\nWe set a global timeout of 1800 s, a memory limit of 10 GB, and ran tests on an Intel Xeon CPU 6226R @2.9GHz.\nResults. In Figure 3, we show the impact of leveraging topological refinements across all instances of all domains. The x-axis denotes the number of solved instances, while the y-axis represents computa-"}, {"title": "8 Conclusion and Future Work", "content": "In this paper, we provided a detailed representation of a multi-agent TAMP scenario with one agent moving at a time and multiple task-dependent obstacles. Our contributions include a general problem formulation and semantic definition, supported by an open-source library for modeling and benchmarking. We also introduced a novel meta-engine framework for combining off-the-shelf task and motion planners to solve complex scenarios. We proposed using geometric context to generate topological refinements and prune the task planner's search space. Additionally, we demonstrated how this meta-engine can be"}]}