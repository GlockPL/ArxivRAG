{"title": "From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using Large Language Models", "authors": ["Kangrui Ruan", "Xinyang Wang", "Xuan Di"], "abstract": "Social media has become an important platform for people to express their opinions towards transportation services and infrastructure, which holds the potential for researchers to gain a deeper understanding of individuals' travel choices, for transportation operators to improve service quality, and for policymakers to regulate mobility services. A significant challenge, however, lies in the unstructured nature of social media data. In other words, textual data like social media is not labeled, and large-scale manual annotations are cost-prohibitive. In this study, we introduce a novel methodological framework utilizing Large Language Models (LLMs) to infer the mentioned travel modes from social media posts, and reason people's attitudes toward the associated travel mode, without the need for manual annotation. We compare different LLMs along with various prompting engineering methods in light of human assessment and LLM verification. We find that most social media posts manifest negative rather than positive sentiments. We thus identify the contributing factors to these negative posts and, accordingly, propose recommendations to traffic operators and policymakers.", "sections": [{"title": "I. INTRODUCTION", "content": "Social media significantly influences our daily lives, with approximately two-thirds of American adults visiting social networks regularly [1]. This widespread utilization positions social media as a vital source for the acquisition and dissemi-nation of current information, highlighting its growing appeal as a cost-effective alternative to traditional data collection methods [2]. As a result, social media has evolved from a simple platform for connecting individuals to an extensive and invaluable repository of data. This evolution facilitates the study of human interactions and behaviors across various fields, e.g., transportation [3], emergency management [4], and so on."}, {"title": "A. Related Work", "content": "Previously, numerous studies have utilized social media data for transportation research, including the classification of urban activity patterns [5], estimation of travel activity spaces [6], examination of longitudinal travel behavior [7], incidents detection [8], and so on. Specifically, the authors in [5] utilize Latent Dirichlet Allocation to classify individual activity patterns. [6] estimates the differences between weekday and weekend activity spaces through geo-tagged tweets from different users. Gu et al. [8] first manually annotate tweets relevant to the traffic incidents and develop a Semi-Naive-Bayes model to classify the results. Similarly, Chen et al. [9] also manually label a small amount of tweets and train two separate classifiers for different objectives. Ye et al. [10] explore Twitter data to understand attitude changes in travel behaviors during the COVID-19 pandemic.\nHowever, there are several potential challenges identified in the previous research: (1) Manual annotation of the large volume of unlabeled tweets is extremely expensive and time-intensive [11]. (2) When various objectives exist, e.g., in analyzing travel modes vs. sentiments, previous researchers might need to develop distinct models [9], [12], with the risk of cascading errors passed from travel mode classification to sentiment analysis. (3) The accessibility of geo-location information is frequently limited, as many users opt not to share their precise location coordinates [13]. Based on [14], [15], [16], such unobserved variables might pose substantial risks on learning processes.\nTo tackle these challenges, we propose a novel framework purely based on text, and leverage Large Language Models (LLMs), utilizing their exceptional performance [17]. LLMs are recently popular and have already been applied in various fields, e.g., computer vision [18], agriculture [19], voice assistants [20], [21] and so on. Without the need for manual annotation, the proposed framework can simultaneously predict travel modes, sentiments, and summarize the reasons. Therefore, this approach obviates the need for different classifiers designed for distinct objectives, streamlining the analytical process."}, {"title": "B. Contributions of this paper", "content": "The contributions of this paper can be summarized as follows: (1) We propose a novel pure-text-based framework based on Large Language Models (LLMs) to analyze social media data. This approach effectively infers the travel modes mentioned within the collected tweets and facilitates an in-depth understanding of public attitudes and concerns regarding various travel modes. (2) We conduct a comparative analysis for different LLMs and different prompting engineering methods to determine their efficacy in understanding travel modes and the corresponding sentiment. The proposed framework is validated through systematic human evaluations and LLM verifications. (3) Based on the identified travel modes and public attitudes, we delve into the underlying reasons for negative attitudes and offer several specific recommendations for potential policy adjustments.\nThe structure of the paper is organized as follows. Section II"}, {"title": "II. DATA COLLECTION", "content": "In this section, we discuss how the dataset is collected from Twitter. We systematically gather tweets related to different travel modes using a structured list of keywords. For instance, to collect potentially relevant tweets about subways, we utilize keywords such as \"subway\", \"metro\u201d, \"path\", \"MTA\u201d, \u201cLIRR\u201d, \u201ctrain\", \"light rail\", \"transit\" and so on. Similarly, for buses, the keywords include \u201cbus\" and \"public transport.\" Although these tweets are collected based on specific keywords, there is no guarantee that they pertain to any particular travel mode. For example, the keyword \"subway\" could refer to either the metro system or the restaurant. In other words, the collected tweets are unlabelled. Therefore, when there is not any specific mode mentioned, we designate the travel mode field as 'NA'.\nGenerally speaking, the collected data covers periods from 2020 to 2022, and is geographically mainly focused on New York City (NYC), because of its diverse travel modes. Additionally, the dataset consists of more than 250,000 tweets, each record containing the user ID, username, tweet ID, timestamp, the corresponding text, and so on. Due to privacy considerations, this study focuses mainly on the textual content of the tweets themselves rather than the demographic information of the users, such as gender or age."}, {"title": "III. METHODOLOGY", "content": "We employ a similar pre-processing procedure for the collected tweets, which is consistent with the prior research [22], [9]. The overall structure of the proposed framework is illustrated in Figure 1. There are two primary LLM agents: the reasoner and the verifier. For a given tweet, the reasoner predicts the corresponding travel mode, assesses the sentiment, and conducts a reasoning check. Subsequently, the verifier examines and confirms the validity of these predictions."}, {"title": "A. Large Language Models (LLMs)", "content": "The mainly chosen LLMs in this paper include GPT-3.5 [23], Llama2 [24], and Mistral [25]. All of them are advanced Transformer-based models with over billions of parameters and pre-trained on a vast corpus of text data. The considerable size of the model and diverse training dataset enable LLMs like GPT-3.5 to exhibit remarkable capabilities, e.g., zero-shot learning [17], and solving problems with step-by-step reasoning [26].\nThe fundamental building block of the Transformer archi-tecture is the attention mechanism [27], [28]. Specifically, with notations consistent with previous studies [27], [29], $L$ denotes the length of the input sequence of tokens. Attention projects the input into three different vectors: queries $Q$, keys $K$ and values $V$ [20]. For the bidirectional dot-product attention $Attn$, the outcome can be computed as follows:\n$Attn (Q, K, V) = D^{-1}AV$,\n$A = exp (QK^{T}/\\sqrt{d})$, $D = diag (A11)$\nwhere $exp(.)$ signifies the element-wise exponential function, $K^{T}$ represents the transpose of $K$. diag(.) extracts the diagonal elements of a matrix, and 11 denotes a vector full of ones. Another significant type is unidirectional $Att_{\\rightarrow}$:\n$Att_{\\rightarrow}(Q, K, V) = D^{-1}AV$, $D = diag (A11)$,\n$A = tril(A)$, $A = exp (QK^{T}/\\sqrt{d})$\nwhere $tril(.)$ returns the triangular part of the input matrix with the diagonal. Unidirectional dot-product attention is important for autoregressive generative modelling [11].\nThe primary difference between the bidirectional dot-product attention (Equation (1)) and unidirectional dot-product attention (Equation (2)) lies in the application of $tril(.)$. In unidirectional dot-product attention, each position in the sequence is only allowed to attend to the preceding positions and itself. The function $tril(.)$ helps to ensure that future positions are masked, and therefore, not attended to during the attention computation."}, {"title": "B. Prompting Engineering Methods", "content": "Briefly speaking, a prompt constitutes the input provided to LLMs [11]. The practice of designing language queries to guide the model's outputs towards specific goals is commonly known as prompt engineering [30]. The syntax and semantics of a prompt can significantly affect a model's response.\nSpecifically, we compare the following prompting methods: instruction-following [31], in-context learning [11], chain-of-thought [32], and analogical prompting [33]. To highlight their unique characteristics and differences, examples are provided in Figure 2.\nInstruction-following [31] involves direct commands that guide the response generation of the language model.\nIn-Context Learning (ICL) [11] is a paradigm where LLM acquire the capability to perform new tasks through inference alone, without the need for updating its parameters.\nChain-of-thought prompting [32] encourages the model to articulate intermediate steps towards the solution, fostering a more transparent reasoning process, e.g., \"Let's think step by step\".\nInspired from human beings utilizing past experiences to solve new problems, Analogical prompting [33] enables language models to self-generate relevant examples or knowledge within a specific context."}, {"title": "IV. RESULTS AND DISCUSSION", "content": "In this section, we first identify the optimal LLM and prompt engineering technique for the reasoner. Based on the chosen methodologies, we conduct a detailed analysis of the distribution patterns of travel modes, and the sentiments associated with each. Ultimately, we summarize the primary factors contributing to dissatisfaction and propose targeted strategic recommendations to ameliorate these concerns.\nOur evaluation integrates human assessment and LLM verification to gauge performance. Specifically, each LLM is provided with identical input prompts to generate responses. These output responses are then assessed for coherence and relevance by both human evaluators and LLMs. In particular, human evaluators are asked to score the responses based on specific criteria, e.g., the correctness of the travel mode or the sentiment. Similarly, inspired by [34], the LLM verifier also evaluates such aspects, utilizing GPT-4 [23]. Combining human assessment and LLM verification offers a more robust approach to evaluate language models. Scores are normalized on a scale from 0 to 1, where higher values indicate superior performance. For each LLM, the average score across the test dataset is computed to determine its performance efficacy."}, {"title": "A. Ablation Study on Different LLMs and Prompting Engineering Methods", "content": "In order to choose the optimal LLM for the reasoner, we conduct an ablation study. Specifically, we examine the following representative LLMs: GPT-3.5 [23], Llama2-7B [24], and Mistral-7B [25].\nThe results, detailed in Table I, show that GPT-3.5 consistently achieved the highest average scores across both human verification and LLM verification. Generally, human verification scores are generated based on hundreds of tweets, while LLM verification scores are generated based on thousands of tweets. Specifically, consider a real-world tweet \u201csorry to ask is being miserable a criteria to be employed by the mta? almost every mta employee is miserable and angry\u201d. The response for GPT-3.5 is: \u201cThe travel mode related to the tweet is likely Metro, because of MTA. The sentiment expressed in the tweet is negative, as the user is"}, {"title": "B. Travel Mode and Sentiment Analysis", "content": "To further validate the predictive accuracy of our frame-work, we examined the most frequent words in tweets associated with each travel mode predicted by the reasoner. Figure 3 visualizes the frequent words by a series of word cloud maps, providing insights into the linguistic patterns related to different modes of travel. Specifically, Figure 3(a) highlights terms like \u201cdriver\u201d, \u201cbest driver\u201d, \u201ctaxi", "cab": "reflecting common discussions related to taxi or Uber services. Figure 3(b) shows the word cloud for private vehicle. Figure 3(c) represents bus, logically encompassing words such as \u201cbus\u201d, \u201cterminal\u201d, \u201cport\u201d, and \u201cpublic\u201d. Figure 3(d) shows the word cloud for subway, including terms like \"train\", \"subway\", \"station\", \"mta\". Figure 3(e) shows the bike-related word cloud, including terms like \u201cbike\u201d, \u201clane", "path": "ride\" underscoring the relevance of these words to bike.\nFigure 4 illustrates the distribution of travel modes in NYC, based on the collected Twitter data. Remarkably, the sub-way/metro emerges as the predominant mode of transportation, which likely reflects the efficiency of NYC's extensive metro system and the flexibility it offers to commuters. Following the subway, bike ranks as the second most popular mode. This preference can be understood in the context of the city's congested traffic conditions, which often make cycling a faster and more convenient option.\n\"NA\" appears third in the ranking, indicating instances where the context of keywords such as \"subway\" could lead to ambiguous interpretations. For example, when collecting tweets using the keyword \"subway\", it may refer to the metro system or the restaurant. An illustrative tweet like \u201cI like the sandwich at Subway in NYC\" is actually not related to any travel mode, as the term \"subway\" in this context is highly likely to refer to the restaurant chain. Such ambiguity could contribute to the high incidence of 'NA' as a travel mode.\nSubsequently, private vehicles are the fourth most common mode, followed by buses and then taxis/Uber, which rank sixth. In urban cities, such as NYC, the metro system's extensive network and convenience make it extremely popular, and biking might be preferred due to faster navigation through congested streets. In contrast, private vehicles, buses, and taxis/Uber might be less preferred, as they face challenges like parking scarcity, congestion, and higher costs.\nFigure 5 shows the proportion of user attitudes (Neu-tral/Negative/Positive) towards different travel modes. The results indicate that most travel modes exhibit a higher proportion of negative responses compared to positive ones. This trend aligns with existing research [35], [36], suggesting that individuals with negative experiences are more likely to share their grievances on social media platforms. Notably, Taxi/Uber and bicycles demonstrate slightly higher levels of user satisfaction comparing to other modes of travel.\""}, {"title": "C. Major Reasons of Dissatisfaction", "content": "To elucidate the representative factors contributing to dissatisfaction among different travel modes, we conduct a comprehensive analysis. Figure 7, Figure 8, Figure 9, and Figure 10 illustrate the primary reasons for negative feedback specific to different modes. In these figures, the complaints are ranked from most to least frequent.\nTo comprehend the underlying factors contributing to the dissatisfaction of nearly 40% of subway users, we analyzed the data and identify the most prevalent complaints, as depicted in Figure 7. The analysis reveals that the primary complaint is delays and long waiting time. The second most common complaint was inadequate COVID-19 safety mea-sures, including improper mask usage and insufficient physical distancing. The third issue involves incidents on the subway, including racist and harassment incidents. Additionally, users reported problems with smoking, odors, homelessness, fare concerns, maintenance shortcomings, misinformation, noise, and litter. Based on our findings, we recommend enhancing timeliness and reliability, enforcing health protocols during the pandemic, improving security, and addressing environmental and operational concerns.\nFigure 8 presents the analysis for dissatisfaction for bus, highlighting some issues, e.g., bus incidents, pandemic-related concerns, long waiting time, problems of bus stops, and so on. To enhance service quality, we recommend enhancing bus drivers' training and professionalism, improving service reliability, ensuring strict adherence to health protocols, increasing maintenance frequency for better quality.\nFigure 9 depicts the major dissatisfaction factors for bike, including inadequate maintenance of bike lanes, lack of secure parking, safety issues while cycling, substandard conditions of shared bicycles, excessive speed by some cyclists, and unsafe scooter behaviors. To address these issues, we advocate for enhancing the quality of bike lanes, developing secure bicycle parking facilities, and improving the standards of shared bicycles.\nAs shown in Figure 10, we analyze dissatisfaction factors related to taxi/Uber and private vehicles together, due to shared vehicular concerns. The key issues identified include both vehicle-related problems, such as obstructions of cross-walks, violations of traffic signals including running red lights or stop signs, accidents, reckless driving, illegal parking; and user-related concerns, for example, the scarcity of parking"}, {"title": "V. CONCLUSION", "content": "In this work, we introduce a novel LLM-based framework to analyze and extract individuals' travel mode choices from Twitter data, without the need of manual annotations. Our framework consists of the 'reasoner' that predicts travel modes and sentiments, and the \u2018verifier' that validates these predic-tions. We evaluate various LLMs and prompting strategies, and find that GPT-3.5 surpasses Llama2-7B and Mistral-7B. Moreover, our results show that in-context learning is particularly effective for the reasoner. Given that the dataset is mainly collected in NYC, subway/metro emerged as the most frequent travel mode, followed by bikes, private vehicles, buses, and taxis/Uber. Furthermore, our analysis suggests that individuals with negative experiences are more likely to express their dissatisfaction on social media. Accordingly, we identify the major causes of discontent for different modes and propose several recommendations to address these issues."}]}