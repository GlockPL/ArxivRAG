{"title": "A Comprehensive Review of Machine Learning Advances on Data Change: A Cross-Field Perspective", "authors": ["Jeng-Lin Li", "Chih-Fan Hsu", "Ming-Ching Chang", "Wei-Chao Chen"], "abstract": "Recent artificial intelligence (AI) technologies show remarkable evolution in various academic fields and industries. However, in the real world, dynamic data lead to principal challenges for deploying Al models. An unexpected data change brings about severe performance degradation in Al models. We identify two major related research fields, domain shift and concept drift according to the setting of the data change. Although these two popular research fields aim to solve distribution shift and non-stationary data stream problems, the underlying properties remain similar which also encourages similar technical approaches. In this review, we regroup domain shift and concept drift into a single research problem, namely the data change problem, with a systematic overview of state-of-the-art methods in the two research fields. We propose a three-phase problem categorization scheme to link the key ideas in the two technical fields. We thus provide a novel scope for researchers to explore contemporary technical strategies, learn industrial applications, and identify future directions for addressing data change challenges.", "sections": [{"title": "INTRODUCTION", "content": "Data-centric Machine Learning (ML) paradigms have emerged into important technical approaches to address many challenges in various Artificial Intelligence (AI) application fields, including the automotive industry [1], internet-of-things (IoT) [2], and healthcare [3]. Data is pivotal in driving model learning, influencing performance, and serving as an infrastructure in real-world systems. However, data may change due to differences in the sources, unexpected sensor corruption, and seasonal variations. New data distributions might gradually deviate from the original distributions. As a result, the predictive capability of the learned model can degrade accordingly. In the literature, there are two scenarios widely investigated with respect to data changes: domain shift [4]\u2013[7] and concept drift [8]\u2013[13]. The frameworks for domain shift aim to handle data changes caused by the change of data sources with the unchanged model's predicted performance. In comparison, concept drift methods aim to handle data changes caused by time-varying phenomena leading to the obsolescence of existing models. Although the original problem definitions differ in the two scenarios, recent ML advancements in the two fields share commonalities and trends, due to the similar underlying properties of data change.\nDomain adaptation aims to bridge the gaps between the source and target domains [14]. The problem intricately encompasses distribution shifts in both data and labels, arising from changes in data quality, annotating criteria, and the targeted label classes. Substantial research endeavors have been dedicated to enhancing the generalization capability of models in various scenarios, leveraging the concept of distribution learning [15]\u2013[17]. A common strategy is to train a robust and general source model and then fine-tune it for downstream tasks.\nConcept drift arises from the need to monitor model performance throughout the lifecycle of a system. Unexpected drift often occurs in data streams in non-stationary environments, where data distributions evolve over time, potentially leading to catastrophic failures in real-world applications. A common strategy to address concept drift is estimating temporal changes by analyzing historical data and adapting the model to accommodate forthcoming changes.\nRegarding the underlying data change, concept drift represents a form of temporal distribution shift that requires timely adaptation. Therefore, it is natural to align with the concept of domain shift. Researchers have expanded and begun to explore similar approaches to handle the two problems. For example, continual learning, which is specifically designed to mitigate catastrophic forgetting, can help address domain shift problems towards universal model learning. Simultaneously, continual learning techniques were also developed to incrementally learn new knowledge without forgetting important historical knowledge from the data stream [18] in the context of concept drift. Similarly, regularization and ensemble learning techniques are frequently leveraged in both domains. Fast domain adaptation and sequential test-time training are two sub-fields within the domain shift methods that emphasize efficiency and temporal factors during learning. Interestingly, these factors align with the primary challenges addressed in concept drift. Although the original assumptions in the two fields have shaped distinct algorithmic framework developments, emerging topics have led to an intertwining of technical approaches across these fields.\nIn this paper, we propose a unified perspective to bridge the literature gap between domain shift and concept drift. We further provide insightful industrial perspectives on the challenges associated with this gap [19] for real-world model deployment applications. This paper aims to answer the following research questions (RQs):\n\u2022 (RQ1) What problem settings have been proposed to tackle and consolidate the complicated data change issues in the research fields?\n\u2022 (RQ2) What are the current state-of-the-art approaches that address the problems under these settings?\n\u2022 (RQ3) How best to contribute to the integration of research fields revolving around the data change problems in a unified categorization scheme?\n\u2022 (RQ4) What are the perspectives, challenges, and practical applications in industries associated with data change?\nBased on their underlying shared data change characteristics, we associate domain shift and concept drift with a new and unified three-phase scheme to make evident the advantages of techniques in the two fields, facilitating comparisons of framework design ideas across the fields. Specifically, Fig. 1 shows the three-phase scheme including problem detection, problem handling, and other related factors. These phases suggest the logic of the model deployment procedure starting from detecting the problem to adapting models and finally incorporating other factors to further relax usage constraints. Efficiency is an important factor in adaptation, as it helps prevent the burden of extensive model retraining. Continual learning for the forgetting effects has also been studied to achieve sustainable model deployment in concept drift. Fig. 1 lists detailed terms used in the fields of domain shift and concept drift. For instance, in the case of domain shift, data undergo changes in batches, whereas, in concept drift, data changes occur in streams. Consequently, in domain shift, the source and target domains represent the data before and after the change, whereas in concept drift, the current and next states are utilized to capture the evolving data dynamics.\nOverall, this paper shows a comprehensive overview of the global landscape, cutting-edge designs, and emerging trends of domain shift and concept drift. Specifically, we summarize the key research and surveys in both research fields and introduce a problem-oriented taxonomy to categorize the state-of-the-art studies. We examine the major difference and similarities between the methods and datasets, thereby identifying potential avenues for future research. Additionally, we highlight other important topics, such as model bias and fairness, as well as advances in the related communities that should be considered in addressing data change problems. We expect this overview paper can stimulate technical improvement to address the challenging data change problems and guide researchers and practitioners for future development.\nOur contributions are summarized in the following.\n\u2022 Our work bridges the gaps of key ideas for handling data change in modern deep learning that spans multiple research fields around domain shift and concept drift.\n\u2022 This study reviews the state-of-the-art methods and illustrates the characteristics of the two fields, thereby bringing researchers to the frontiers of cutting-edge advancements.\n\u2022 We introduce a three-phase scheme including problem identification, problem handling, and extended factors, to categorize the research topics and illuminate key developments and emerging topics in the two fields.\n\u2022 We propose future research directions regarding the challenges of model deployment in industrial applications.\nThe rest of the paper is organized as follows: \u00a72 summarizes the recent survey papers on domain shift and concept drift, and \u00a73 describes the notations used in this paper. \u00a74 and \u00a75 introduce the domain shift and the concept drift problems with a series of research topics using our proposed problem categorization scheme. \u00a76 discusses the shared and complementary techniques in the fields of domain shift and concept drift. \u00a77 provides an industrial perspectives for the state-of-the-art studies. Finally, \u00a78 concludes this data change study with the current status and future trends."}, {"title": "2 RELATED SURVEYS AND DATASETS", "content": "Table 1 lists the existing survey papers up to 2023 that are on domain shift and concept drift. We briefly introduce their key contributions and the featured topics to summarize the surveys in both fields. Table 2 and Table 3 summarize the commonly-used public datasets for the evaluation of domain shift and concept drift, respectively."}, {"title": "2.1 Domain Shift Survey Papers", "content": "Domain shift involves the transfer learning across domains in addressing the data distribution shift problems. With the identified source and target domains, the domain shift problem can easily be found when we need to deal with multiple datasets. Therefore, the techniques are extensively investigated in multiple prominent machine learning applications, such as vision, language, and speech. Table 1 lists the recent survey papers along with the key topics that shows the trend of domain adaptation development. The general focus on transfer learning has garnered significant attention, with notable contributions from four survey studies [4]\u2013[7]. Additionally, unsupervised domain adaptation has emerged as a widely discussed topic [20]\u2013[22]. Vision [22], [31], language [33]\u2013[35], and speech [37], [38] applications have also been organized to lighlight the technologies developed in the contexts, each with its own task and data properties. Review studies have also covered topic such as reinforcement learning [40], providing a comprehensive understanding of the research findings."}, {"title": "2.2 Domain Shift Datasets", "content": "We investigate the publicly available datasets commonly used in domain shift research. Existing datasets are organized into three setup types according to their covering domains, the use of synthetic data, and the data sources. First, to cover broad domain changes, samples were collected in-the-wide from multiple domains [67], [68]. Second, data change can be simulated by changing the color and viewing angle, or by adding noise or blurriness [42], [43], [54] and other data corruption [44]\u2013[46]. Third, a simple approach to prepare a cross-domain dataset is to combine two or more naturally different datasets collected from multiple sources or institutions [15], [69]\u2013[71].\nTable 2 provides an overview of datasets collected with domain shift data in different modalities. Sub-fields of domain shift such as out-of-domain detection (\u00a74.1) and domain generalization (\u00a74.2) are developed on large-scale benchmark datasets to include different types of data change. The commonly considered domains are style and environmental changes, such as clipart and infographic styles in Domain-Net [53], and speaker accents and acoustic environment in LibriAdapt [65]. Changes in language tasks naturally involve cross-lingual contents [63] and conversation topics [62]. These studies frequently use cross-institution setups while turning into the multi-domain setup as the scale of data collection grows. Fast adaptation (\u00a74.4) follows a similar data configuration, yet it selects the dataset altered with distinct label classes. Studies on label shift (\u00a74.3) and test-time training and adaptation (\u00a74.5) often utilize synthesized corrupted data (e.g., CIFAR100-C or ImageNet-C [44]) to represent the target domain with presumed change types."}, {"title": "2.3 Concept Drift Survey Papers", "content": "Numerous studies have investigated the issue of concept drift that occurs in various machine-learning applications. Common categories of algorithms include performance-based detection [39], distribution-based detection [41], hypothesis-based detection, and contextual-based detection [39]. The majority of previous review studies have identified similar taxonomies for categorizing typical concept drift approaches [8]\u2013[13]. Table 1 lists the topics highlighted in the review papers between 2018 and 2023. Unsupervised approaches are widely used due to their ability to effectively handle concept drift without relying on labeled data. Fast-growing machine learning techniques are then employed to address concept drift [27], [28]. Meta-learning has emerged as a promising direction for concept drift adaptation [27]. Algorithms tailored to specific usage scenarios, such as regression [30] and class imbalance [32] problems, are developed taking into account the properties of the respective problems. Furthermore, studies in deep learning as presented in [36], have focused on learning network parameters and architectures to address concept drift in the data stream."}, {"title": "2.4 Concept Drift Datasets", "content": "Current studies on concept drift have used both real and synthetic datasets, with a focus on continuous temporal data. Tabular and structured data are more commonly employed in these cases. Given the diverse conditions under which concept drift occurs in different data collection scenarios, we report commonly used real datasets in Table 3. In line with the trend of utilizing real-world data with an unbiased estimation of the drift, we exclude synthetic datasets and prioritize the frequently used datasets in the table. The selected datasets comprise the prediction targets that are influenced by various potential drift factors. For example, the weather observations exhibit varying frequencies of rainy days as a consequence of climate change [72]. Similarly, ecological changes impact forest coverage [74]. Video recordings often exhibit changes in lighting conditions and recording environments [75], [76]. Human behaviors and habits also exhibit temporal variations, which can be observed in internet usage patterns [77] and chess playing [77]. For research aiming at comprehensive studies across various applications, Souza et al. have presented additional benchmark datasets [78]."}, {"title": "3 NOTATIONS AND DEFINITIONS", "content": "We next introduce the notations used in this paper. We aim to establish consistent notations and definitions to describe the data change associated with domain shift and concept drift for all papers that are reviewed. A specific domain is characterized by a distribution $P(X)$, which represents a set of data samples $X = \\{X_1,X_2, ..., X_N \\}$. Here, $N$ denotes the number of samples in the collected dataset $D$. For a given machine learning task $T$, which involves a collections of labels $Y \\{Y_1, Y_2, ..., Y_N\\}$ in the dataset $D$, supervised learning can be conducted using the labeled samples $x_i, Y_i$ for $i \\in N$, $x_i \\in X$ and $y_i \\in Y$.\nWe generalize the notations in the context of domain shift to describe the data change for concept drift. Specifically, we define the mismatch between a source domain and a target domain for domain shift and further extend this definition to address concept drift. This allows the dynamic updating of the two domains to accommodate the data stream setting. Table 4 shows the unified definition for the various terms commonly used in the fields of domain shift and concept drift. The original data correspond to the source domain dataset $D_S$ and the changed data correspond to the target domain dataset $D_T$. Concept drift is usually defined on a particular time step $t$ and a time window $w$, to specify the data in the current state $D_t$ and the occurrence of drift data at $t + w$, denoted as $D_{t+w}$. Here, $D_t$ can be regarded as a special case of $D_S$, where the time stamp is specified, and thus $D_{t+w}$ can be represented by $D_T$.\nThe data change problem is formulated as the distribution shift between $P_S(X, Y)$ and $P_T(X, Y)$ which contains the special case of the concept drift problem. Table 5 provides an overview of the sub-field problems addressed in this paper. We highlight the differences in data and models between the source and target domains to illuminate the changes. As there might be multiple source or target domain datasets, we denote the dataset as $D_m$, where $m$ represents the index of the domain. The checklist showing the data change of the distribution is also presented in Table 5."}, {"title": "4 DOMAIN SHIFT", "content": "We categorize the research efforts addressing the distribution shift between the source domain distribution $P_S(X, Y)$ and target domain distribution $P_T(X,Y)$ in three phases of problem categorization, as shown in Fig. 1. The problem detection phase focuses on out-of-domain detection technologies (\u00a74.1). The problem handling phase encompasses domain adaptation and generalization approaches (\u00a74.2). Additional factors including label quality, adaptation speed, and temporal dynamics are considered in \u00a74.3, \u00a74.4, and \u00a74.5."}, {"title": "4.1 Out-of-domain Detection", "content": "Out-of-domain (OOD) detection is vital in real-world applications, as it can avoid data abnormality that deviates from the typical distribution. This topic was recently identified in 2017 [79] due to the limitations of common domain adaptation approaches in ensuring safe and robust deployment in rapidly changing environments. From the perspective of domain adaptation, the OOD detection problem aims to identify unknown data sample that differs from the source domain dataset $D_S$, which is typically unavailable during the test phase. $D_S$ is referred to as in-domain data and the unknown samples are OOD data. The goal is to identify samples that do not belong to the source distribution $P_S(X, Y)$. Therefore, the OOD problem can seen as an early-phase monitoring problem, as the target dataset $D_T$ is not accessible for retraining. The scope of OOD detection has expanded to include various related topics such as anomaly detection, novelty detection, open set recognition, out-of-distribution detection, and outlier detection [79]. This broader perspective considers not only changes in sample features but also unknown classes and noises within the domain shift context. Differentiating between relevant information and irrelevant noises is a complex task, as the definition of in-domain distribution must be unbiased. Overconfident predictions can undermine model trust.\nClassification-based methods are intuitive in thresholding the prediction score to distinguish in-domain and out-of-domain distributions. Advanced methods extend the scoring functions to the gradient space, offering better flexibility for observing abnormal patterns. The design of the scoring function, by estimating the probabilistic properties of true likelihood distribution, can keep sensitive scores for model performance [80]. State-of-the-art OOD detection approaches favor agnostic solutions that are applicable to any network structure. For instance, the Simple Activated Function designed for deep networks makes no assumptions on the model architectures [81]. Another effective approach is the non-parametric nearest-neighbor distance, which is distribution assumption-free, test data agnostic, and model agnostic properties [82]. The success of the distance measurement approach can be attributed to techniques like contrastive learning [83] and self-supervised learning [84], which come with enhanced generalization ability for in-domain training.\nOOD detection in visual applications aims to detect domain shift factors, such as spatial location accuracy, appearance diversity, image quality, and aspect distribution [85]. Speech and language applications may encounter challenges related to cross-language problems or content differences influenced by cultural or contextual factors [59], [86]. In a recent survey study [87], open source codes are released to facilitate comprehensive benchmarking of the generalized OOD detection frameworks. Other libraries are also available to accelerate the R&D in this area [88]. These OOD detection approaches have led to the development of corresponding strategies in machine learning systems in two directions: learning with rejection and domain adaptation. Rejecting prediction on unknown data maintains the quality of the services and engaging humans to rectify the data promotes effective collaboration between humans and machines for further model learning. The direction of adaptation described in \u00a74.2 aims for a more automatic process to adapt models as soon as OOD is identified."}, {"title": "4.2 From Domain Adaptation to Domain Generalization", "content": "Traditional domain adaptation methods assume that we have access to the target domain dataset $D_T$ to estimate the distribution $P_T(X, Y)$, which usually restricts real-world applications. Therefore, unsupervised domain adaptation has emerged, leaving to the promising field of domain generalization (DG). DG encompasses an ambitious goal to generalize learning without accessing to the target domain dataset $D_T$. It can be seen as a more generalized problem of domain adaptation, which aims to handle unseen domains without retraining models [29]. Both domain generalization and domain adaptation are designed in the problem-handling phase which has attracted abundant research. In contrast to the OOD problem, the DG problem focuses on detecting changes in data across different domain distributions and adapting models to maintain predictive ability even on unseen classes [89]."}, {"title": "4.2.1 Source Domain Settings", "content": "The source domain data for training yields in-depth impacts on the model generalization ability and transferability. Herein, we regard two source domain training data settings, including multiple-source and single-source settings. The typical DG studies use multiple training datasets for multiple sources and attempt to generalize the source domain distribution $P_S$ [29]. The single source DG is more difficult because there is less data variability for the source model. Some prior works deem the single source DG as an OOD generalization problem [90] to focus on the samples' learning once the OOD has been detected. The typical domain adaptation studies use the single source setting that assumes the availability of the target domain labels for adaptation.\nAside from the two data source settings for training, source-free domain adaptation prohibits the source data to be used for adaptation once the source model has been trained [91], [92]. The adaptation is only based on the trained model parameters without access to the source domain data $D_S$. Technically, clustering along with pseudo labels can help estimate the distribution shift [93]. Xie et al. propose contrastive category matching to exploit the relationship between pairs of targeted images [94]. Source-free domain generalization has been identified as a harsh problem. Although teacher-student learning [95] and using text prompts as a proxy can be possible solutions [96], there still remains substantial space for further research."}, {"title": "4.2.2 Transfer Learning Strategies", "content": "Research in both domain adaptation and domain generalization has grown with three branches of learning strategies to conquer the domain gap problem including domain fine-tuning, domain adversarial learning, and domain matching approaches. Their distinct underlying ideas shape the framework designs with more focus on model refining, distribution difference elimination, and distribution alignment techniques, respectively.\nDomain Finetuning: The domain finetuning is the most fundamental approach for domain adaptation which can then be introduced to domain generalization with additional algorithm adjustment. Researchers are meant to construct a large and robust source model for initialization and design fine-tuning techniques for downstream tasks. The knowledge distillation approaches extract the knowledge in the source domain network for further reuse in the target domain [69]. Teacher-student learning enhances the knowledge distillation approaches by keeping using the distilled teacher network to supervise the finetuning steps [97]. With the knowledge distillation technique, the frameworks can deal with source-free cases [95]. Self-supervised learning loss acts as a regularization term to map the same-class samples across domains close to each other [98].\nDomain Adversarial Learning: The domain adversarial learning is a mainstream technique that is renowned for Domain Adversarial Neural Network (DANN) introducing the reverse gradient with an additional discriminator to avoid one domain being differed from another [15]. This setting naturally results in an adversarial condition in which one branch learns to recognize the main task and the other branch disables the ability to discriminate different domains. The adversarial approaches further improve the convergence by using mixup to create continuous label space instead of hard domain labels [16]. Although adversarial learning is designed to learn domain invariant latent features, over-optimization on domain discriminator can degrade the recognition performance on the target domain. Accordingly, explicitly designing an interplay of the classifier and the domain discriminator attains better adversarial optimization [99]. Recent visual transformer (ViT) takes advantage of the attention module to re-weight image patches to boost transferability during the adversarial learning [100]. The adversarial learning can also be extended to domain generalization studies by seeking a common ground of multiple datasets in the domain discriminator [101].\nDomain Matching: The domain matching approaches minimize the domain discrepancy by optimizing feature consistency across domains. The focus of the research turns to the design of distribution measurement approaches, such as maximum mean discrepancy (MMD) [102], correlation alignment [103], contrastive domain discrepancy [104], and Wasserstein distance [105]. Other than the distribution measurement approaches, batch normalization can adaptively dissociate bias and variance of the datasets [106]. In the source-free scenario, measuring classifier discrepancy with pseudo-labeled samples facilitates self-training [68]."}, {"title": "4.3 Label Shift and Noisy Labels", "content": "Most machine learning models highly rely on labeled data for supervised learning. However, unreliable labels might be observed in situations of label shift and noisy labels. Label shift refers to the change of the underlying label distribution $P_S(Y) \\neq P_T(Y)$. Although noisy labels would also give rise to the difference between the label distribution. We differ the label shift and noisy labels with the corresponding learning strategies that mainly keep the target distribution or the source distribution characteristics, respectively.\nCurrent studies blindly estimate the label shift problem and performance drop as it occurs unexpectedly. For example, Lipton et al. have proposed a black box shift estimation on an invertible confusion matrix and the distribution ratio before and after label shift [107]. To generalize the estimation in the low target sample setting, an importance weighting approach with regularization to address three kinds of synthesized label shift [108]. These studies quantify the shift with mathematical forms and propose a statistical bound to guarantee the bound of generalization. However, the presumed labeled shift might be oversimplified. An advanced work proposes a model to jointly estimate sparse covariate shift and label shift [109]. Recently, online learning algorithms can be used to actively estimate the shift [110].\nOne of the situations of label shift is that the source domain is contaminated with noisy labels. Data annotation engages in the cognitive status and past experiences of the annotators which yields potential labeling errors when the task is complex or the annotators are biased. The noisy labels in the source domain impede the model's robustness to generalize across domains. These corrupted labels might occupy 8.0% to 38.5% in real-world datasets [111]. The label quality issues are amplified as crowd-sourced labeling solutions can reduce data annotation costs. Technically, learning with noisy labels aims to handle the problem by enhancing the robust source domain model learning [111], [112] including framework designs on architecture, regularization, loss design, and sample selection. Curriculum learning is a remedy to recover noisy data as clean data by the estimation of empirical risk [113]. One of the loss designs is the denoising MMD loss to estimate the target domain label distribution with noisy source data [17]. Sample selection by measuring the divergence of two classifiers for each sample can alleviate the adverse effect of noisy samples and perform partial alignment on the cross-domain distributions [114].\nA special case related to the learning from noisy labels is the source-free domain adaptation in that recent studies have generated pseudo labels as noisy labels for the target data using a pre-trained source model [115], [116]. Regularizing the source model to avoid overly adapting to the noisy target data provide a bound of effect from the noise [116]. Separating target domain samples into clean and noisy data also regularizes the learning in a self-supervised manner [115]. Considering the label shift as noise has opened up new avenues for robust learning across domains."}, {"title": "4.4 Fast Adaptation", "content": "Frequent change in real-world data poses challenges to the domain adaptation models with the need for data efficiency and convenience. This section includes algorithms resolving the issues with inconsistent label space and target domain tasks. Few-shot learning and zero-shot learning are notable solutions to deal with learning with limited access to new data. A well-trained source domain model is the key to generalizing without complicated operations on the target domain data. Sophisticated techniques are proposed to improve this source domain model training to derive the so-called foundation model. The idea is that the foundation model aggregating massive knowledge provides strong initialization for any tasks to transfer with minimal effort. To allow fast adaptation with limited testing data, the technical approaches are optimized on either pretraining or finetuning phases. The pretraining aims to learn a generic model with large-scale datasets and the finetuning requires several techniques to efficiently adapt model parameters."}, {"title": "4.4.1 Few-Shot Learning", "content": "Few-shot learning is a problem set upon a harsh condition that the target dataset $D_T$ contains only very few available labeled samples for adaptation. We formally define a task $T_S = \\{Y, P(Y|X)\\}$ with the label space $y$ and conditional distribution $P(Y|X)$. The common setup includes the source domain dataset $D_S$ for typical supervised training and validation. Then, a new $C$-way $K$-shot task $T'$ is set up in the situation that $T \\neq T'$. That is, there are $C$ unseen classes in the target domain, resulting in disjoint label space. However, only a very limited number of $K$ samples are available as the target domain support set $D_T^S$ for model training, and the final task is to predict on a query set $D_T^Q$. In the context of a typical pre-trained model utilizing dataset $D_S$, the occurrence of domain shift towards dataset $D_T$ poses a challenge known as cross-domain few-shot learning. This shift is characterized by the dissimilarity between the probability distributions $P_S(X)$ and $P_T(X)$.\nA prior survey has categorized few-shot learning research into meta-learning and non-meta-learning methods [117]. The task change naturally leads the few-shot learning algorithm to seek more tasks for pretraining. Meta-learning becomes a major approach, mimicking the prediction of new tasks with sampling strategies (e.g., MAML [118]). Data augmentation and prototypical networks are notable examples of non-meta-learning methods [119]. The design principle of these approaches is to expand the feature space with sufficient sample diversity, providing a robust semantic structure for the new task to finetune delicate information. The cross-domain few-shot learning problem is more challenging with the change of both the domain and task. Associating prototypical network and adversarial learning serves as a way to capture new task prototypes in the new domain [120]. Moreover, training with a contrastive loss enhances the semantic structure of the self-supervised prototypes [121]. Domain-Switching Learning embeds the knowledge from multiple domains to realize a fast switch to the target domain [122]. The setting is similar to domain generalization but allows a few data in the support set to tackle the task differences. Zero-shot learning is an extended field restricting the use of the support set while introducing semantic features (attributes) to bridge to the new tasks [123]."}, {"title": "4.4.2 Foundation Models", "content": "The progress of the pre-trained model with continuously enlarged source domain data size has achieved promising success in the natural language processing [124], vision [125], [126], and audio [127] domains for fast adaptation to various downstream tasks. The core idea of the foundation model is to aggregate as much knowledge as possible into a pre-trained model for generic use.\nPretrained Model: Large-scale self-supervised learning is a dominated source-domain model training approach with the idea that predicts the latent features of masked inputs with self-training. Contrastive learning can minimize the distance between positive pairs of samples and maximize negative pairs of samples while the non-contrastive approach only considers the positive pairs [128]. Intriguingly, the recent research indicates that the covariance regularization-based non-contrastive methods can be regarded as performing contrastive pairs on dimensions rather than samples [129]. The learning methods for pre-trained models might share similar optimization goals with different techniques. In addition, Data2vec demonstrates that the same self-supervised training approach can be applied to different modalities [130]. The foundation model can not only support multimodal tasks [125], [131], but also encompass huge information with even cross-domain samples. For example, cross-lingual acoustic and language models have been introduced by training with multiple source domain datasets [132], [133].\nFinetuning: With a pre-trained foundation model, parameter efficiency in finetuning becomes crutial that requires minimal effort for deployment in new tasks, which is also termed as \u201cdelta tuning"}, {"title": "4.5 Test-time Training and Adaptation", "content": "One of the emerging topics of unsupervised domain adaptation, test-time training (TTT) or test-time adaptation (TTA), has been consolidated recently that the generalization of learning in the testing phase can leverage unlabeled testing data as an indicator for updating the model on the new data distribution [140]. This setting breaks the traditional stationary assumption and indicates that the testing data distribution might change over time. In practice, we observe a small batch of testing data and update the model in an unsupervised manner. Then, we evaluate the performance on-the-fly with the adapted model. TTA can be thought of as an online domain adaptation problem combining the techniques from domain generalization and fast adaptation described in \u00a74.2 and \u00a74.4, respectively. During training, researchers design the learning of source domain models for generalization while during testing, self-training with the unlabeled test data at hand needs to adjust the model for a better fit. In this task, the adaptation at test time is usually conducted without access to the source domain data. This setting connects TTA with source-free DG described in \u00a74.2."}, {"title": "4.5.1 Online Learning", "content": "TTT depends on the powerful foundations of source domain training and the strategies of the target domain unsupervised adaptation. The designed loss function with self-supervised learning techniques dominates the success of TTT. In addition, meta-learning is another strategy to expand the source domain learning space for a generic model, and thus the model simultaneously exploits the learned knowledge from other tasks [141]. In the testing phase, computing the self-supervised learning loss on the unlabeled testing data can update the model to handle new data distribution. The distribution mismatch often causes failure of adaptation due to the missing link across domains. Therefore, selecting an appropriate loss and matching the samples located in a similar feature space are techniques to diminish the distribution shift. For example, Goyal et al. examine training losses' convex conjugate to facilitate to seek for the best TTA loss for a given source model and distribution shift [142]. Chen et al. refine online pseudo labels with soft voting among their nearest neighbors and learn to contrast positive and negative samples [143]. Liu et al. propose a feature alignment approach by computing statistics to represent the distribution characteristics [144]. Gandelsman et al. reframe the TTT problem as one-sample learning which aims to perfectly fit each testing sample point for tailored prediction [145]. Sequential test-time training (sTTT) is recently defined to strictly include only one-pass adaptation on the data stream [146]. That is, refining the model with the accumulated testing data is not allowed to minimize computational overhead. Even further, adjustment on the classifier completely avoids the back-propagation and minimizes the cost at inference time [147]."}, {"title": "4.5.2 Learning without Forgetting", "content": "The model updating over time raises the catastrophic forgetting issue which learns the pattern from the new data samples but loses the discriminative power on the old samples. The new pattern is usually attributed to the out-of-domain samples described in \u00a74.1. Continual learning, also known as lifelong learning, has been exploited as a remedy to consolidate the learned knowledge over time. For example, Niu et al. propose to actively select reliable samples with regularized updating to avoid dramatic network parameters change [148]. Qin et al. reduce the error accumulation by using weight-averaged and augmentation-averaged prediction and introducing stochastic restoring partial neurons during training iterations to avoid the forgetting effects [149]. The model updating efficiency is also emphasized in these studies because the frequent back-propagation during the testing phase leads to great burdens on computational consumption. Samples redundantly generating similar gradients can be discarded to ensure sample efficiency during adaptation [148]. The studies imply the data-efficient learning trend for data stream with minimal updating and maximal knowledge consolidation."}, {"title": "5 CONCEPT DRIFT", "content": "For the input of data streams, the ability for models to adapt on the fly is crucial when facing dynamic changes in data distribution. Typical machine learning models are ill-suited for dealing with non-stationary scenarios, which significantly impacts their reliable deployment across diverse application domains. In the studies [11", "39": "the term \"concept drift\u201d is defined as the occurrence of a change in the joint probability of variables X and Y at time t, within a"}]}