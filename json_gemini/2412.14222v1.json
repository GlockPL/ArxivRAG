{"title": "A Survey on Large Language Model-based Agents for Statistics and Data Science", "authors": ["Maojun Sun", "Ruijian Han", "Binyan Jiang", "Houduo Qi", "Defeng Sun", "Yancheng Yuan", "Jian Huang"], "abstract": "In recent years, data science agents powered by Large Language Models (LLMs), known as \"data agents,\" have shown significant potential to transform the traditional data analysis paradigm. This survey provides an overview of the evolution, capabilities, and applications of LLM-based data agents, highlighting their role in simplifying complex data tasks and lowering the entry barrier for users without related expertise. We explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention. Furthermore, we analyze several case studies to demonstrate the practical applications of various data agents in real-world scenarios. Finally, we identify key challenges and propose future research directions to advance the development of data agents into intelligent statistical analysis software.", "sections": [{"title": "1 Introduction", "content": "As nearly every aspect of society becomes digitized, data analysis has emerged as an indispensable tool across various industries (Inala et al., 2024). For instance, financial institutions leverage data analysis to make informed decisions about stock trends (Provost and Fawcett, 2013; Institute, 2011), hospitals utilize it to monitor patients' health conditions (Waller and Fawcett, 2016), and companies employ it to develop strategic plans (Chen et al., 2012). Despite its widespread utility, data analysis is often perceived as a challenging field with a significant \"entry barrier\" (Cao, 2017; Jordan and Mitchell, 2015), typically requiring knowledge in areas such as statistics, data science, and computer science (Kitchin, 2014). Since the release of SPSS (IBM, 1968) in 1968, followed by SAS (Inc., 1976), Matlab (MathWorks, 1984), Excel (Microsoft, 1985), Python (Foundation, 1991), R (for Statistical Computing, 1995), PowerBI (Microsoft, 2013), and other specialized data analysis tools and programming languages, these advancements have significantly aided professionals in conducting statistical experiments and data analysis. Moreover, they have made data analysis more accessible to a broader range of practitioners (Witten et al., 2016).\nThe general data analysis process typically involves several key steps. Initially, data is collected from studies or extracted from databases and imported into tools such as Excel. Next, software like Excel or programming languages such as Python and R are employed to clean and analyze the data, aiming to extract valuable insights. Subsequently, data visualization is performed to make these insights more accessible and understandable. For more complex tasks, such as statistical inference and predictive analysis, statistical and machine learning models are often necessary. This involves data processing, feature engineering, modeling, evaluation, and more. Upon completing the analysis, a final report is usually drafted to summarize the findings and insights. However, for individuals without expertise in statistics, data science, and programming, data analysis remains a high-barrier task.\nThe barriers to data analysis primarily exist in the following areas:\n\u2022 Lack of systematic statistical training: Individuals without a background in statistics may find it challenging to understand which types of analysis are feasible, even when data is presented to them. As data and models become increasingly complex, gaining a solid understanding of current statistical techniques typically requires at least a Master's level of statistical training.\n\u2022 Software limitation: Simple data analysis tools like Excel are inadequate for complex scenarios, such as predictive analysis or analyzing data from enterprise databases. Conversely, advanced programming languages for data analysis, such as Python and R, require prior programming knowledge, which can be a barrier for many users.\n\u2022 Challenges in domain-specific problems: In specialized fields like protein or genetic data analysis, general data scientists may find it difficult to perform effective analysis due to a lack of domain-specific knowledge.\n\u2022 Difficulty in integrating domain knowledge: Corresponding to the last point, domain experts often lack the data science and programming skills needed to quickly incorporate their expertise into data analysis tools. For example, PSAAM (Steffensen et al., 2016) is software designed for the curation and analysis of metabolic models, yet a biologist researching metabolism might find it challenging to integrate this analytical method into common data analysis tools like Excel or R.\nWith the rise of generative AI, new opportunities have emerged in data science and analysis. This technology is gradually addressing existing challenges while introducing a new paradigm for approaching data analysis tasks."}, {"title": "2 Opportunities Brought by Generative AI", "content": "The rise and potential of generative AI, particularly large language models (LLMs) or vision language models (VLMs) in the field of data science and analysis have gained increasing recognition in recent years. In addition to understand text, LLMs are also trained to understand tabular data, allowing them to effectively extract insights, identify patterns, and draw meaningful conclusions from tables (Dong and Wang, 2024). Consequently, LLMS have emerged as powerful tools capable of significantly enhancing and transforming a variety of data-driven applications and workflows (Nejjar et al., 2023; Tu et al., 2023; Cheng et al., 2023). Recent research has focused on designing LLM-based data science agents (data agents) to automatically address data science tasks through natural language, as demonstrated by tools like ChatGPT-Advanced Data Analysis (ChatGPT-ADA) (GLM, 2024) and ChatGLM-Data Analysis (ChatGLM-DA) (OpenAI, 2023).\nThe emergence of data agents offers a potential solution to the previously mentioned challenges, as they lower the entry barrier for users who lack programming or statistical knowledge. By providing an intuitive interface that harnesses the capabilities of LLMs, users can request analyses using natural language, and the data agents can interpret these"}, {"title": "3 LLM-based Data Science Agents", "content": "LLM-based data agents leverage the powerful natural language understanding and generation capabilities of large language models (LLMs) to autonomously tackle complex data analysis tasks.\nIn this framework, the LLM serves as the core of the entire system, driving its performance and reliability. As such, the capabilities of the LLM are critical to the system's effectiveness, with advanced models like GPT-4 often being used. Data analysis typically involves multiple steps, especially when addressing complex tasks. Techniques such as Planning, Reasoning, and Reflection help ensure that the LLM processes these tasks with greater logical coherence and makes optimal use of its knowledge.\nIn the architecture, the LLM generates the code for a given data analysis task, executes it, and retrieves the corresponding results. This requires an execution environment, represented by the Sandbox, which safely isolates the code execution process. The Sandbox allows users to run programs and access files without risking the underlying system or platform. It includes pre-installed programming environments and software, such as Python, R, Jupyter, and SQL Server.\nA user-friendly interface is also essential to improving usability. An intuitive interface not only attracts users but also enables them to quickly engage with and utilize the system effectively."}, {"title": "3.1 Overview", "content": "LLM-based data agents leverage the powerful natural language understanding and generation capabilities of large language models (LLMs) to autonomously tackle complex data analysis tasks.\nIn this framework, the LLM serves as the core of the entire system, driving its performance and reliability. As such, the capabilities of the LLM are critical to the system's effectiveness, with advanced models like GPT-4 often being used. Data analysis typically involves multiple steps, especially when addressing complex tasks. Techniques such as Planning, Reasoning, and Reflection help ensure that the LLM processes these tasks with greater logical coherence and makes optimal use of its knowledge.\nIn the architecture, the LLM generates the code for a given data analysis task, executes it, and retrieves the corresponding results. This requires an execution environment, represented by the Sandbox, which safely isolates the code execution process. The Sandbox allows users to run programs and access files without risking the underlying system or platform. It includes pre-installed programming environments and software, such as Python, R, Jupyter, and SQL Server.\nA user-friendly interface is also essential to improving usability. An intuitive interface not only attracts users but also enables them to quickly engage with and utilize the system effectively."}, {"title": "3.2 Evolution of Data Science Agent", "content": "Research on data agents began gaining momentum in 2023. Chandel et al. (2022) trained and evaluated a model within a Jupyter Notebook to predict code based on given commands and results. Soon after, it was discovered that LLMs, such as GPT, could generate accurate code for basic data analysis. With the rise of the LLM-based agent, researchers began designing special data agents for automating data science and analysis tasks by human language."}, {"title": "3.3 User Interface", "content": "The user interface is crucial for attracting users at first glance. Current research on user interface design can be broadly categorized into four types: Integrated Development Environment-based (IDE-based), Independent System, Command line-based (Command-based), and Operation System-based (OS-based).\nIDE-based Tools like Jupyter-AI, Chapyter, and MLCopilot integrate LLM-based agents within IDEs such as Jupyter Notebook. This IDE-based approach is highly intuitive and flexible for users who are familiar with the environment. Users can choose to activate the agent within a cell or write and run their own code. Typically, magic commands correspond to specific functions, such as configuring settings or activating the agent. For example, in Jupyter AI, users can initiate the agent by entering the magic command \"%%ai chatgpt generate a random matrix with 3 \u00d7 3\" in a cell. This triggers the agent, designates ChatGPT as the LLM for the current task, and prompts it to generate the code for a 3 \u00d7 3 random matrix. The generated code and its execution results are then displayed as output below the cell. This interface is particularly popular among users with programming experience, as it provides significant flexibility.\nIndependent System Some works have focused on developing independent systems equipped with user interfaces. For example, ChatGPT introduced a streamlined, intuitive conversational system a model of interaction that has been widely adopted in subsequent projects. In the context of data analysis tasks, beyond basic text-based input and output,"}, {"title": "3.4 Planning, Reasoning, and Reflection", "content": "Planning, Reasoning, and Reflection often play crucial roles in guiding the actions of data agents. Planning, in particular, focuses on generating a logically structured roadmap of actions or thought processes for solving specific problems (Huang et al., 2024; Hong et al., 2024). When a data agent receives a request, it typically needs to provide a response along with execution results. Complex tasks often require a step-by-step approach to ensure effective resolution, while simpler tasks can be handled without such detailed breakdowns.\nSome approaches focus on building conversational data agents (Zhang et al., 2023b,a; Sun et al., 2024), where users interact with the agent over multiple rounds to complete a task. In these cases, under human supervision, complex planning is not necessary, as guidance can simplify decision-making and adjust the workflow dynamically. Some of these works operate in a Basic I/O mode. On the other hand, End-to-end data agents (Guo et al., 2024; Qiao et al., 2023; Hong et al., 2024; Chi et al., 2024; Jiang et al., 2024; Li et al., 2024; Trirat et al., 2024; Grosnit et al., 2024) are designed to allow users to issue a single prompt that encompasses all requirements. In these cases, the agent employs planning, reasoning, and reflection to iteratively complete all tasks autonomously.\nRecent research in planning has introduced two main approaches: Linear Structure Planning (or Single Path Planning/Reasoning) and Hierarchical Structure Planning (or Multiple Path Planning/Reasoning).\nA task can be planned and broken down into sub-tasks, as demonstrated in methodologies like Chain-of-Thought (CoT) (Wei et al., 2022), ReAct (Yao et al., 2022), Tree-of-Thoughts (ToT) (Yao et al., 2024), and Graph-of-Thoughts (GoT) (Besta et al., 2024).\nLinear Structure Planning In linear structure planning, a task is decomposed into a sequential, step-by-step process. For example, DS-Agent (Guo et al., 2024) utilizes Case-Based Reasoning to retrieve and adapt relevant insights from a knowledge base of past successful Kaggle solutions. This enables the system to develop experiment plans, iteratively adjusting the plan based on execution feedback. This approach allows the agent to learn from previous experiences and continuously improve its performance. Similarly, the Planner agent in AutoKaggle (Li et al., 2024) is responsible for task decomposition and plan generation, using logical reasoning to determine the sequence of actions for other agents to execute. AutoML-Agent (Trirat et al., 2024) adopts a retrieval-augmented planning (RAP) strategy to generate diverse plans for AutoML tasks. By leveraging the knowledge embedded in LLMs, information retrieved from external APIs, and user requirements, RAP allows the agent to explore a wider range of potential solutions, leading to more optimal plans.\nHierarchical Structure Planning Simple linear planning is often insufficient for complex tasks. Such tasks may require hierarchical and dynamic, adaptable plans that can account for unexpected issues or errors in execution (Hong et al., 2024). For instance, Hong et al. (2024) utilizes a hierarchical graph modeling approach that breaks down intricate data science problems into manageable sub-problems, represented as nodes in a graph, with their dependencies as edges. This structured representation enables dynamic task management and allows for real-time adjustments to evolving data and requirements. Additionally, they further introduce \u201cProgrammable Node Generation,\u201d to automate the generation, refinement, and verification of nodes within the graph, ensuring accurate and robust code generation. AIDE (Jiang et al., 2024) employs Solution Space Tree Search to iteratively improve solutions through generation, evaluation, and selection components. Similarly, SELA (Chi et al., 2024) combines LLMs with Monte Carlo Tree Search (MCTS) to enhance AutoML performance. It starts by using LLMs to generate insights for various machine learning stages, creating a search space for solutions. MCTS then explores this space by iteratively selecting, simulating, and back-propagating feedback, enabling the discovery of optimal pipelines. Agent K v1.0 (Grosnit et al., 2024) employs a structured reasoning framework with memory modules, operating through multiple phases. The first phase, automation, handles data preparation and task setup, generating actions through structured reasoning. The second phase, optimization, involves solving tasks and enhancing performance using techniques such as Late-Fusion Model Generation and Bayesian optimization. The final phase, generalization, utilizes a memory-driven system for adaptive task selection.\nReflection Reflection enables an agent to evaluate past actions and decisions, adjust strategies, and improve future task performance. This process is essential for self-correction and debugging during task execution. For example, Wang et al. (2024b) employs trajectory filtering to train agents that can learn from interactions and enhance their self-debugging capabilities. This technique involves selecting trajectories in which the model initially makes errors but successfully corrects them through self-reflection in subsequent interactions. Similarly, Zhang et al. (2023b) and Sun et al. (2024) use self-reflection based on code execution feedback to address errors. If a compilation error occurs, the agents repeatedly attempt to revise the code until it runs successfully or a maximum retry limit is reached. This iterative process helps ensure code correctness and usability."}, {"title": "3.5 Multi-agent Collaboration", "content": "Multi-agent collaboration involves multiple agents working together to achieve common goals. In this setup, agents communicate, negotiate, and share information to optimize their collective performance (Xi et al., 2023). In the context of data agents, dividing complex tasks among agents with specialized expertise can enhance both the efficiency and performance (Sun et al., 2024). For example, LAMBDA operates with two distinct agents: the Programmer and the Inspector. The Programmer is responsible for generating code based on user instructions. Meanwhile, the Inspector plays a critical role in debugging the generated code as needed, ensuring both functionality and accuracy in the execution (Sun et al., 2024). AutoML-Agent (Trirat et al., 2024) involves multiple agents such as the Agent Manager, Prompt Agent, Operation Agent, Data Agent, and Model Agent-that together cover the entire pipeline, from data retrieval to model deployment. Similarly, AutoKaggle (Li et al., 2024) employs five specialized agents-Reader, Planner, Developer, Reviewer, and Summarizer\u2014to manage each phase of the process, ensuring comprehensive analysis, effective planning, coding, quality assurance, and detailed reporting. OpenAgents (Xie et al., 2023) also adopts a multi-agent approach, with agents such as the Data Agent, Plugins Agent, and Web Agent collaborating to solve a variety of tasks."}, {"title": "3.6 Knowledge Integration", "content": "Integrating domain-specific knowledge into data agents presents a challenge (Dash et al., 2022; Sun et al., 2024). For example, when a domain expert has specialized knowledge, such as specific protein analysis code, the agent system are expected able to incorporate and apply this knowledge effectively. One approach is tool-based, where the expert's analysis code is treated as a tool that is recognizable by the LLM (Xie et al., 2023). When the agent encounters a relevant problem, it can call upon the appropriate tool from its library to execute the specialized analysis. Another method involves the Retrieval-Augmented Generation (RAG) technique (Lewis et al., 2020), where relevant code is first retrieved and then embedded within the context to facilitate in-context learning. LLM-based agents can also access and interact with external knowledge sources, such as databases or knowledge graphs, to augment their reasoning capabilities (Wang et al., 2024b).\nSun et al. (2024) proposes a Knowledge Integration method that builds on this concept. In LAMBDA, analysis codes are parsed into two parts: descriptions and executable code. These are then stored in a knowledge base. When the agent receives a task, it retrieves the relevant knowledge based on the similarity between the task description and the descriptions stored in the knowledge base. The corresponding code is then used for in-context learning (ICL) or back-end execution, depending on the configuration. This approach enables agents to effectively leverage domain-specific knowledge in relevant scenarios."}, {"title": "3.7 System Design and Other Related Works", "content": "Recent advancements in interactive data science systems highlight a variety of approaches in system design, with LLMs and structured frameworks significantly enhancing the user experience across key areas such as data visualization, task specification, predictive modeling, and data exploration. Notable systems like VIDS (Hassan et al., 2023), Data-Copilot (Zhang et al., 2023b), InsightPilot (Ma et al., 2023), and JarviX (Liu et al., 2023) exemplify diverse design principles tailored to these specific functions. For instance, VIDS employs a four-stage dialogue model, featuring \u201cmicro-agents\u201d dedicated to tasks such as data visualization, task formulation, prediction engineering, and results summarization. This structure optimizes system responsiveness at each stage (Hassan et al., 2023). Data-Copilot adopts a code-centric approach, generating intermediate code to process data and subsequently transforming it into visual outputs, such as charts, tables, and summaries (Zhang et al., 2023b).\nOther frameworks emphasize workflow automation. InsightPilot integrates an \u201cinsight engine\" that guides data exploration, reducing LLM hallucinations and enhancing the accuracy of exploratory tasks (Ma et al., 2023). JarviX, in combination with MLCopilot (Zhang et al., 2023a), contributes to automated machine learning by merging LLM-driven insights with AutoML pipelines. JarviX, in particular, offers a no-code interface, democratizing complex data analysis and streamlining predictive modeling processes (Liu et al., 2023). Additionally, in the domain of database management, systems like LLMDB improve efficiency and reduce hallucinations and computational costs during tasks such as query rewriting, database diagnosis, and data analytics. This is achieved by embedding domain-specific knowledge, semantic search, caching, and multi-round inference techniques (Zhou et al., 2024).\nIn data visualization, MatPlotAgent (Yang et al., 2024) transforms raw data into clear, informative visualizations by leveraging both code-based and multimodal LLMs. Collectively, these systems demonstrate success in designing sub-modules and processes within the broader data analysis workflow.\nMoreover, Wang et al. (2024a) organizes user interactions into \"data threads\" to provide context and facilitate the exploration and revision of prior steps. A similar approach is seen in Xie et al. (2024), which transforms raw code into an interactive visual representation. This provides a step-by-step visualization of LLM-generated code in real-time, allowing users to understand, verify, and modify individual data operations. Such an interface empowers users to guide and refine the analysis process proactively, facilitating better monitoring and steering of data analysis performed by LLMs. SEED (Chen et al., 2024) combines LLMs with methods like code generation and small models to produce domain-specific data curation solutions. HuggingGPT (Shen et al., 2024), on the other hand, uses LLMS to coordinate a variety of expert models from platforms such as Hugging Face, solving a broader range of AI tasks across multiple modalities."}, {"title": "4 Data Analysis Through Natural Language Interac- tion: Case Studies", "content": "In this section, we present a series of case studies conducted by a diverse range of agents, each illustrating the new data analysis paradigm facilitated through natural language interaction. These case studies demonstrate how this approach enables users to engage with data more intuitively and effectively, breaking down traditional barriers to data accessibility and understanding. By leveraging natural language processing, these agents can interpret and respond to complex queries, providing insights that are both comprehensive and easily digestible. Through these examples, we aim to highlight the transformative potential of natural language interaction in data analysis."}, {"title": "4.1 Case study 1: Data Visualization and Machine Learning by Conversational Data Agents", "content": "In this case study, we utilized ChatGPT and LAMBDA to demonstrate data visualization and machine learning, respectively. Specifically, we first used ChatGPT to explore the effect of alcohol content on the quality of different types of wine, focusing on both red and white varieties. Then, we used LAMBDA for machine learning and automatically generate reports.\nWe utilized the Wine Quality dataset\u00b9 and employed ChatGPT-Advanced Data Analysis to conduct exploratory data analysis and visualize the influence of alcohol content on wine quality ratings. GPT-4 first analyzed the problems and then outlined a step-by-step plan to solve the tasks. The entire workflow proceeded smoothly, with the code running efficiently to load the data, check for missing values, and generate visualizations, with each step delivering accurate results. Its ability to interpret data and provide insights significantly streamlined the analytical process. Finally, it provided insights into the relationship between quality scores and alcohol content.\nHowever, for some commercial products, such as ChatGPT and ChatGLM, there may be restrictions when attempting to install additional packages. Due to the server's protection mechanisms, the sandbox environment does not have internet access, and the agent receives a notification stating, \"There is no internet access.\u201d Any attempt to install packages results in an error."}, {"title": "4.2 Case Study 2: Data Visualization and Machine Learning by End-to-End Data Agents", "content": "End-to-end data science agents are particularly convenient for users who wish to perform data-related tasks with a single prompt. In this case study, we demonstrate how an end- to-end data agent, the Data Interpreter, can handle both data visualization and machine learning tasks. Specifically, we prompt the Data Interpreter to visualize the average salary across different age groups using the Salary Data\u00b2. We pre-downloaded the data to disk due to errors that may occur during the download process. The Data Interpreter began by generating a path in the Planning phase, which consisted of three task nodes: (1) \u201cLoad the salary data from the CSV file,\u201d (2) \u201cAnalyze the average salary by different age groups,\" and (3) \u201cDraw a line chart to visualize the average salary by age groups.\" It then sequentially executed each task. After obtaining the results for each step, the interpreter checked whether the current task was successfully completed. If not, it re-executed the task. This reflection process ensures task completion and accuracy by allowing for iterative re-evaluation. Once all nodes are successfully completed, the overall task is considered finished.\nThen, we used the Data Interpreter to train a classifier for breast cancer prediction based on the Breast Cancer Wisconsin (Diagnostic) Dataset\u00b3. We prompted the Data Interpreter to compute the classification accuracy using 5-fold cross-validation. Similarly, the Data Interpreter planned the whole task in 3 sub-tasks: (1) \u201cLoad and preprocess the breast cancer dataset\u201d, (2) \u201cTrain a classifier using 5-fold cross-validation.\", and (3) \"Evaluate the model and print the final accuracy.\u201d. However, there was an error caused by the wrong column name when solving the first task. The Data Interpreter reflected the error and updated the task code. Eventually, it successfully finished all 3 sub-tasks and provided the final accuracy of 0.9649.\nHowever, if the user's prompt is relatively simple, such as tasks that could be completed in a single step, the end-to-end data agent may waste many tokens due to its multi-step decomposition process.\nFurthermore, because the entire process cannot be intervened by the user, if any step produces an undesired outcome, the entire workflow must be repeated during the next session. This will result in the waste of time and tokens. Additionally, users often overlook some details in their prompts. For example, in this case, we asked the agent to train a model but forgot to instruct it to save the model. As a result, the model was not saved, and the entire process needs to be repeated in the next session. Moreover, without setting a fixed random_state, it is likely that we cannot reproduce the same model, leading to further inconsistencies.\nTo tackle this, the Data Interpreter offers another conversational mode for human interaction by specifying --auto_run False. This hybrid approach, which supports both end-to-end and conversational modes, is likely to become a prevailing design trend in the future.\""}, {"title": "4.3 Case study 3: Explore Expandability in Data Agents", "content": "In many situations, we encounter tasks that cannot be handled effectively because the LLM lacks the necessary knowledge. In such cases, if the data agent is designed to be extensible, manual tool expansion or knowledge integration can address this limitation. In this case study, we demonstrate how both the Data Interpreter and LAMBDA leverage integration mechanisms to incorporate additional packages or domain-specific knowledge.\nCreating and Using Tools in Data Interpreter To integrate a tool in MetaGPT (the parent project of Data Interpreter), we need to create a function or class in the metagpt/tools/libs directory and annotate it with the @register_tool decorator. This registration makes the tool accessible to the Data Interpreter. Besides, functions and classes must also include Google-style docstrings to describe their purpose and usage. In this case, we used the web-scraping tool PlaywrightWrapper to gather deadlines for AI conferences from the website. In the prompt, we included the URL of the target site and specified that the scraped data should be saved in a .txt file. The tool analyzed the HTML structure of the page and extracted relevant information, such as conference names and submission deadlines.\nIn the case, the Data Interpreter began with an initial plan. For each sub-task, it recommended relevant tools with a score indicating their suitability. The system then decided whether to use the suggested tool. For instance, it used scrape_web_playwright for a web-scraping task. This iterative recommendation and tool selection process continued until all sub-tasks were completed, addressing limitations in LLMs' built-in abilities and knowledge.\nNext, we demonstrate the knowledge integration mechanism in LAMBDA through Fixed Point Non-Negative Neural Networks (FPNNNs). First, we copied the code for FPNN into LAMBDA's template, which automatically integrates the code into the knowledge base. Since the code was lengthy, we defined the mode as Core. We then delineated the Core function, which directly accepts parameters, and the Runnable function, which was defined and executed separately. LAMBDA first retrieved the relevant code from the knowledge base, and then its Core function was presented in the context. By modifying the core code, LAMBDA generated the correct code and completed the task successfully."}, {"title": "5 Challenges and Future Directions", "content": "Despite the recent advancements in data analysis introduced by various data science agents, many challenges remain. Here, we highlight some of these challenges and suggest future directions for the field."}, {"title": "5.1 Challenges in the Capabilities of LLMs", "content": "The LLMs serve as the \u201cbrain\u201d of a data agent, interpreting user intent and generating structured plans to execute data analysis tasks. For an ideal data agent, advanced knowledge in statistics, data science, and coding is essential to effectively support users throughout the analytical process.\nAdvanced Models and Planning Techniques Current state-of-the-art models like GPT-4 show strong performance on undergraduate-level mathematics and statistics problems, yet struggle with more advanced, graduate-level tasks (Frieder et al., 2023). Additionally, the success rate of fully automating complete data workflows with current agents remains low (Cao et al., 2024). This suggests that enhancements in domain-specific knowledge, particularly in statistics and data analysis, are still needed, along with specialized planning and reasoning skills for data agents. Furthermore, to accommodate user preferences, data agents must be capable of learning from past interactions, requiring advancements in memory storage and adaptive systems (Inala et al., 2024).\nMulti-Modality and Reasoning Current data agents also struggle with handling multi-modal data\u2014such as charts, tables, and code\u2014which are crucial for data analysis workflows (Inala et al., 2024). Future research might focus on utilizing multi-modality models, like VLMs, to enhance reasoning capabilities across diverse data formats, allowing for a deeper understanding of relationships within and between various data representations (Inala et al., 2024). For instance, if a user finds a well-designed chart online with specific aesthetics and wishes to recreate it, describing these details verbally may be challenging. A multi-modal data agent, however, could allow the user to upload the image and replicate the chart's design by generating the necessary code based on the visual input. This requires more advanced VLMs and planning techniques to achieve these goals. For instance, a color extractor could be utilized during the process to extract hex color codes from specific visual elements."}, {"title": "5.2 Challenges in Statistical Analysis", "content": "Intelligent Statistical Analysis Software Current statistical software, like SPSS, and programming languages such as R, are highly developed, but future data agents have the potential to evolve into a new paradigm of intelligent statistical analysis software. This vision presents several challenges. For instance, R possesses a vast community and extensive package ecosystem, enabling users to easily perform a wide range of tasks by package installation. For data agents to succeed as intelligent analysis tools, they must facilitate seamless package development and installation, foster a large community where domain experts can contribute, and stay updated with knowledge from various programming communities. This collaborative environment could accelerate the evolution and experimentation within intelligent statistical analysis software. Additionally, many statisticians and scientists may lack comprehensive knowledge of existing models and methods, so data agents that offer guidance and suggest relevant approaches could significantly enhance research efficiency and drive scientific innovation.\nIncorporating Other Large Models into Statistical Analysis Current statistical analysis may increasingly rely on large models' representations for research. For example, in predicting the tertiary structure of proteins, LLMs can utilize representations of primary and secondary structures. Traditional statistical software like Matlab and R currently lacks robust applications in these areas. If data agents can effectively leverage domain-specific knowledge models, they could significantly advance statistical and data science research, enabling more complex analyses and fostering deeper insights across scientific disciplines.\nOther challenges related to data infrastructure and the evaluation of data agents have been addressed in prior works (Inala et al., 2024) and will not be discussed further in this survey. Additionally, for web-based applications, issues such as handling high concurrent requests present notable challenges. Effectively managing resource allocation and scheduling across multiple sandbox environments is crucial to ensuring scalability and efficiency, making these topics important areas for future research and development."}, {"title": "6 Conclusion", "content": "This survey has explored the recent progress of LLM-based data science agents. These agents have shown great potential in making data analysis more accessible to a wider range of users, even those with limited technical skills. By leveraging the capabilities of LLMs, they are able to handle various data analysis tasks, from data visualization to machine learning, through natural language interaction.\nHowever, as discussed, they also face several challenges. In terms of model capabilities, improvements are needed in domain-specific knowledge and multi-modal handling. For intelligent statistical analysis software, seamless package management and community building are crucial. Additionally, effectively integrating other large models into statistical analysis and addressing data infrastructure and evaluation issues remain important areas for future development.\nOverall, while LLM-based data science agents have made significant strides, continuous research and innovation are required to overcome the existing challenges and fully realize their potential in revolutionizing the field of data analysis."}]}