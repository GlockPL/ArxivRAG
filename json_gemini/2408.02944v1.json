{"title": "LLM-Empowered Resource Allocation in Wireless Communications Systems", "authors": ["Woongsup Lee", "Jeonghun Park"], "abstract": "The recent success of large language models (LLMs) has spurred their application in various fields. In particular, there have been efforts to integrate LLMs into various aspects of wireless communication systems. The use of LLMs in wireless communication systems has the potential to realize artificial general intelligence (AGI)-enabled wireless networks. In this paper, we investigate an LLM-based resource allocation scheme for wireless communication systems. Specifically, we formulate a simple resource allocation problem involving two transmit pairs and develop an LLM-based resource allocation approach that aims to maximize either energy efficiency or spectral efficiency. Additionally, we consider the joint use of low-complexity resource allocation techniques to compensate for the reliability shortcomings of the LLM-based scheme. After confirming the applicability and feasibility of LLM-based resource allocation, we address several key technical challenges that remain in applying LLMs in practice.", "sections": [{"title": "I. INTRODUCTION", "content": "In wireless communication systems, the allocation of resources such as transmit power, bandwidth, or beamforming is of utmost importance because the openness nature of wireless medium causes interference to neighboring nodes [1]. Recently, the number of transmitting nodes has increased, while the required communication objectives have become more diverse and stringent. At the same time, more complicated system models and stringent constraints, such as extremely low computation time, are being considered. These factors complicate resource allocation, spurring extensive research in this field.\nSince finding the optimal resource allocation strategy is typically formulated as an optimization problem, analytical optimization frameworks such as convex optimization have been widely applied [2]. However, given that the Shannon capacity formula is nonconvex with respect to transmit power and many control variables, such as channel selection, are discrete, finding the optimal resource allocation is challenging.\nTo address these issues, novel mathematical approaches, such as game-theoretic frameworks or convex relaxation techniques, have been developed [2]. Despite these advances, most analytical approaches face limitations in efficiently managing large numbers of nodes at low computational times and struggle to adapt to dynamically changing wireless environments.\nThe deep learning (DL)-based resource allocation has received considerable attention to address the above-mentioned challenges [3], [4]. In DL-based schemes, the optimal resource"}, {"title": "II. BASIC PRINCIPLE OF LLM AND ITS APPLICATION IN RESOURCE ALLOCATION", "content": "In this section, we describe the basic principles of LLM. Then, we turn our attention to the feasibility and benefits of using LLMs for resource allocation."}, {"title": "A. Principle of LLM", "content": "A DNN, trained on extremely large amounts of unlabeled data using self-supervision techniques to adapt to a wide range of tasks, is referred to as a foundation model. The foundation model is designed to be highly generalizable and can be fine-tuned for specific applications, making it a versatile and powerful base for a wide range of tasks. Notably, the foundation models typically have deep architectures with many layers and a large number of parameters (e.g., 175 billion parameters for GPT-3), allowing them to capture complex relationships in data and perform complicated tasks that require logical reasoning and understanding of the data. The LLM is a representative example of a foundation model, trained on large amounts of text data. Accordingly, the LLM generates text and performs text-based tasks based on given prompts, which are natural language descriptions of the tasks.\nLLM is primarily based on the Transformer architecture, which has become the mainstream framework for modern language models. The Transformer contains two main innovations: the attention mechanism and positional encoding [6]. The attention mechanism computes the relevance of each word in a sentence relative to other words, allowing the model to capture dependencies between words regardless of their distance in the text. This mechanism is enhanced by multi-head attention, which enables the model to focus on different parts of the input sequence simultaneously, capturing different contextual aspects. In addition, positional encoding is added to the input embeddings to encode information about the position of each word in the sequence, ensuring that the order and relative positioning of words are taken into account.\nMost well-known LLMs are pre-trained on billions to trillions of tokens over millions of iterations. Consequently, fine-tuning with task-specific labeled datasets is often employed to further adapt the LLM to specific tasks [7]. However, given the enormous number of trainable parameters, the computational overhead for fine-tuning can be substantial and costly. Given the reasoning capabilities of the LLM, few-shot or zero-shot learning approaches, where only a few concrete examples of a task are provided, or no examples at all, can be effective. Despite the minimal input, the LLM's inductive reasoning capabilities allow it to produce reasonable results. For example, simply adding \"Let's think step by step\" to the prompt can guide the LLM to follow a human-like reasoning process, leading to better results [7]."}, {"title": "B. Conventional Resource Allocation Strategies", "content": "In resource allocation for wireless communication systems, parameters such as transmit power are adjusted to optimize network performance, such as maximizing SE, while satisfying constraints. Finding the optimal strategy is typically formulated as an optimization problem, which can be addressed by using either conventional optimization-based approaches or DL-based approaches as follows [9]:\n\u2022 Optimization-based approach : The formulated optimization problem is tackled analytically. In general, the optimization problem is often complicated and hard to solve, involving aspects such as integer-valued control parameters and non-convex functions. As a result, a variety of mathematical approaches are typically used to transform and simplify the problem, to make it more tractable. The optimal solution is then often obtained through iterative methods.\n\u2022 DL-based approach: The optimal resource allocation is approximated using the output of a specially designed DNN, which provides the resource allocation strategy based on the current wireless network conditions. To achieve this, the DNN must be trained, which can be done either through supervised learning exploiting optimal resource allocation as labeled data, or through unsupervised learning without such labeled data. Although training the DNN can take a considerable amount of time, inference from the trained DNN can typically be performed in the order of a few milliseconds.\nAlthough resource allocation has been extensively investigated in the literature, conventional methods face significant limitations, especially with respect to multimodality and flexibility. In particular, resource allocation in future wireless"}, {"title": "C. Resource Allocation Using LLM", "content": "LLM-based resource allocation presents a promising solution to overcome the drawbacks of conventional schemes. Notably, in this approach, resource allocation can be determined by the LLM on a few-shot learning basis, eliminating the need for retraining of the LLM for specific scenarios. In essence, the LLM acts as a general optimizer, addressing a wide range of resource allocation problems. The benefits of using LLMs in resource allocation can be summarized as follows:\n\u2022 Multimodality : LLM-based scheme can handle various multimodal data. By effectively using such multimodal data in wireless communication systems, more efficient and proactive radio resource allocation can be achieved.\n\u2022 Flexibility: Unlike DL-based schemes that require extensive training, LLMs can operate without task-specific training. Consequently, LLMs can easily adapt to a wide range of objectives and topologies.\nTo effectively use LLMs for resource allocation, it is necessary to validate that they can solve mathematical problems. There have been several attempts to use LLMs to solve linguistically described mathematical problems, such as the GSM8K dataset. Although LLMs are primarily designed for linguistic tasks and may not be well suited for rigorous mathematical computations, recent studies indicate that LLMs can indeed solve mathematical problems when properly prompted. For example, the authors of [10] showed that LLMs can accurately solve mathematical problems by formulating prompts, achieving an accuracy of 97.1% in a zero-shot setting. Moreover, in [11], it was confirmed that the mathematical capabilities of LLMs could be enhanced through sequential reasoning techniques such as Chain of Thoughts, Tree of Thoughts, and Graph of Thoughts. In [12], the use of external math solvers was explored to address the limitations of LLM in precise algebraic computation. In addition, the authors of [13] demonstrated that LLMs could be used to solve optimization problems, such as the linear regression and the traveling salesman problem, through iterative optimization processes. Despite these previous works, there have been no attempts to apply LLMs to resource allocation in wireless communication systems."}, {"title": "III. LLM-BASED RESOURCE ALLOCATION", "content": "In this section, we illustrate the feasibility of using LLMs for resource allocation. To this end, we first describe a simplified resource allocation problem. We then explain how LLMs can be utilized for the resource allocation and present a scheme"}, {"title": "A. System Model and Considered Resource Allocation", "content": "We consider a resource allocation strategy for two transmit pairs, which are randomly distributed. Specifically, we assume that two transmitters send data to their respective receivers over the same channel. Let $h_{i,j}$ denote the channel gain between transmitter $i$ and receiver $j$, where $i, j \\in \\{1,2\\}$, and $P_i$ denotes the transmit power of the transmitter $i$, where the transmit power for a transmitter must not exceed the maximum transmit power, $P_T$.\nWe consider two resource allocation strategies to maximize either total SE or EE by properly adjusting the transmit power. The achievable SE of the transmit pair $i$, denoted as $SE_i$, can be expressed as\n$log_2\\left(1+\\frac{h_{i,i}P_i}{N_0W+\\Sigma_{l\\in\\{1,2\\}\\{i\\}}h_{l,i}P_l}\\right)$,\nwhere $N_0$ and $W$ are noise power density and bandwidth, respectively. Then the objective for maximizing the total SE can be formulated as $\\Sigma_{i=1}^2 SE_i$. Conversely, the objective for maximizing total EE can be formulated as $\\Sigma_{i=1}^2 \\frac{SE_i}{P_i+P_c}$, where $P_c$ is the constant circuit power of the transmitter. Although we do not explicitly show it in the paper, the strategy for transmit power control behaves differently depending on whether the goal is to maximize SE or EE. In particular, binary transmit power control is generally optimal for maximizing SE, whereas a range of transmit power levels can be used to maximize EE. This distinction will later affect the performance of the LLM-based resource allocation."}, {"title": "B. Proposed Resource Allocation based on LLM", "content": "In the proposed LLM-based resource allocation strategy, the transmit power of each transmitter is determined based on the channel gain, $h_{i,j}$. In this approach, the channel gain serves as the input, and the transmit power is the output of the LLM, such that the channel gain is provided as a prompt, and the resource allocation can be derived from the text generated by the LLM. Unlike the conventional DNN-based approach, which requires a customized structure, a generic LLM can be used for resource allocation. The procedure of proposed LLM-based resource allocation is depicted in Fig. 2.\nIn our work, we adopt a few-shot learning-based approach, where the channel gains and the corresponding transmit power strategies are provided as references in the prompt of LLM. Notably, we do not provide a formal description of the optimization objective; instead, we simply provide the channel gain and its corresponding optimal strategy. As a result, our framework can be applied to other optimization problems as well. In the generation of prompts for the LLM, we normalize the channel gain to have zero mean and unit variance, then multiply it by 100. This value is subsequently rounded to an integer. Similarly, the transmit power is normalized by its maximum value, i.e., $P_T$, and multiplied by 100, and is rounded to an integer. This preprocessing of numerical values is crucial because the LLM recognizes numeric values as strings, making it important to simplify these values for efficiency. Specifically, the original channel gain is typically on the order of $10^{-9}$, which is inefficient to express in string format. Additionally, given that the number of inputs to the LLM (i.e., the number of tokens) is limited, it is desirable to reduce the number of characters used to express each numeric value. For example, the formulated prompt to maximize the total SE can be illustrated as follows:\n\"If A is -29, 30, 128, -26, then B is 0, 100. If A is -31, -31, -19, -31, then B is 100, 0... If A is 51, -32, -22, -19, then B is\"\nIn the illustrative example above, the channel gain is denoted as A in the order of $h_{1,1}, h_{1,2}, h_{2,1}, h_{2,2}$, where $h_{i,j}$ is the preprocessed channel gain $h_{i,j}$. On the other hand, the transmit power aimed at maximizing the total SE, is denoted as B in the order of $P_1, P_2$, where $P_i$ represents the preprocessed transmit power. In the considered few-shot learning approach, the training data includes the values of both A and B. However, for the channel gain in the last line, where we need to determine the transmit power, the value of B is omitted. Since the LLM is designed to generate text that"}, {"title": "C. Performance Evaluation", "content": "In the performance evaluation, we assumed that the transmitters and receivers were randomly distributed over an area of 30 m \u00d7 30 m. We used the following parameters by default: $W = 10$ MHz, $N_0 = -173$ dBm/Hz, $P_T = 20$ dBm, and $P_c = 30$ dBm. We considered a simplified path loss model with a path loss coefficient of 103.453 and a path loss exponent of 3.8. In addition, we used an independent and identically distributed circularly symmetric complex Gaussian random variable for multipath fading, with zero mean and unit variance.\nFor the LLM structure, we considered three different LLM models based on LLaMA, each fine-tuned on different datasets, namely CodeLLaMA-7B, LLaMA-2-7B-32K-Instruct, and LLaMA-2-7B. First, the CodeLLaMA-7B model, which we refer to as LLM 1 in our performance evaluation, is fine-tuned using source code, making it specialized for programming tasks and offering robust support for code generation and understanding. Second, the LLaMA-2-7B-32K-Instruct model, denoted as LLM 2 in our performance evaluation, is fine-tuned to follow complex instructions with a relatively long context length. This model is well-suited for tasks that require detailed execution of instructions. Third, the LLaMA-2-7B model, which we refer to as LLM 3, is the base LLaMA 2 model that has not been fine-tuned for specific tasks. All considered models have 7 billion parameters, which are quantized to 5 bits to reduce the model size.\nIn the performance evaluation, we considered two proposed schemes. First, we considered the purely LLM-based scheme, which we refer to as Prop. 1. This approach relies solely on LLM for resource allocation. Second, we evaluated a joint scheme that combines the LLM-based approach with binary transmit power control, which we refer to as Prop. 2. In this scheme, the LLM is used together with a simple binary"}, {"title": "IV. RESEARCH CHALLENGES", "content": "In the following, we discuss the research challenges associated with the future use of LLMs for resource allocation."}, {"title": "A. Latency and Computation Time", "content": "In general, the size of LLMs is extremely large due to their large number of parameters. GPT-4, for example, has 1.7 trillion parameters. As a result, running LLMs requires significant computation resources, often necessitating the use of cloud-based services, which can introduce long latency. In addition, due to the size of LLMs, the computation time required can be large. To address the issues of long latency and computation time, the development of small LLMs (sLLMs) tailored for resource allocation is essential. These sLLMs, combined with edge AI technology, can distribute the computational load across distributed nodes, thereby reducing latency and improving efficiency."}, {"title": "B. Optimized LLM Architecture", "content": "To achieve higher performance, it is necessary to optimize the LLM architecture, including the proper selection of a pre-trained LLM model, which requires extensive performance evaluation against different LLM models. Moreover, diverse multimodal input data, such as user mobility, can also be utilized. For example, proactive resource allocation can be achieved by predicting user activity. Additionally, the energy consumed during the execution of LLMs should be carefully considered, as they utilize substantial computing power to determine the resource allocation strategy."}, {"title": "C. Training Methodology", "content": "In our illustrative example, we employed a supervised learning-based approach, that utilizes multiple labeled resource allocations for different channel gains in a few-shot learning framework. However, the acquisition of such labeled data is often challenging in practice, highlighting the need for innovative resource allocation techniques capable of finding optimal strategies without relying on labeled data. This capability is also critical for ensuring the scalability of LLM-based scheme, as the number of tokens (i.e., the input size to the LLM) cannot be arbitrarily large. To develop more effective training methodologies, careful prompt engineering and fine-tuning of LLM should be considered."}, {"title": "D. Interpretability and Explainability", "content": "Similar to DL-based approaches, the output of LLMs can be unpredictable, potentially resulting in non-optimal performance. In particular, unlike DL-based methods that output numerical values, LLMs generate text-based outputs, which can be difficult to handle. Furthermore, the performance of resource allocation derived from LLMs cannot be guaranteed because the operation of LLMs is considered as a black box. In addition, the hallucination of LLM-based approach can make the output unreliable. To address these issues, it is necessary to incorporate Explainable AI (XAI) techniques into LLMs and appropriately integrate conventional resource allocation methods, as suggested in the previous section."}, {"title": "V. CONCLUSIONS", "content": "In this article, we discussed the application of LLM for resource allocation. Unlike conventional DL-based approaches, the LLM-based approach eliminates the need to build and train dedicated DNNs for specific tasks. We considered a simple resource allocation problem and demonstrated the ability of LLMs for the resource allocation strategy. To address the drawbacks of the LLM-based scheme, we also devised a joint consideration of conventional resource allocation strategies. Through performance evaluation, we confirmed that the LLM-based resource allocation can achieve near-optimal performance and investigated its characteristics. In addition, we outlined challenges associated with the application of LLMs for resource allocation."}]}