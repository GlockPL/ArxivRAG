{"title": "ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model", "authors": ["Xuanqing Yu", "Wangtao Sun", "Jingwei Li", "Kang Liu", "Chengbao Liu", "Jie Tan"], "abstract": "In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we introduce the Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by integrating dynamic causal rule mining (DCRM) and dual history augmented generation (DHAG). DCRM dynamically constructs causal rules from real-time data, allowing for swift adaptation to new causal relationships. In parallel, DHAG merges short-term and long-term historical contexts, leveraging a bi-branch approach to enrich event prediction. Our framework demonstrates notable performance enhancements across diverse datasets, with significant Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language models (LLMs) for event prediction without necessitating extensive retraining. The ONSEP framework not only advances the field of TKGF but also underscores the potential of neural-symbolic approaches in adapting to dynamic data environments.", "sections": [{"title": "1 Introduction", "content": "Event prediction is a widely researched topic (Zhao, 2021; Benzin and Rinderle-Ma, 2023) since accurate prediction of future events allows one to minimize losses associated with certain future events. To model large amounts of real-world event data that represent complex interactions between entities over time, the temporal knowledge graph (TKG) has been introduced (Ding et al., 2023; Yuan et al., 2023). TKG is used to represent structural relationships among entities through timestamped quadruples $(s, r, o, t)$, where s and o are entities, r is a binary relation between them, and t specifies the time when the event $(s, r, o)$ occurs. For example, the quadruple (Angela Merkel, visit, China, 2014/07/04) indicates that Angela Merkel visited China on July 4, 2014. In this task, temporal knowledge graph forecasting (TKGF) aims to predict future events of the graph by inferring missing entities in a quadruple for a future time. This involves generating predictions for either the object entity $(s, r, ?, t+k)$ or the subject entity $(?, r, o, t + k)$ by utilizing historical data from previous snapshots, where k represents the number of time steps or intervals into the future beyond the current time t. Existing research studies have provided theoretical methodologies for time-sensitive applications such as recommendation systems (Wang et al., 2022; Zhao et al., 2022), financial analysis (Li, 2023), and social crisis early warning systems (Gastinger et al., 2023).\nTraditional approaches (Jin et al., 2020; Zhu et al., 2021; Li et al., 2021; Han et al., 2020; Sun et al., 2021; Li et al., 2022) involve converting event data into TKGs and combining graph neural networks (GNNs) and recurrent neural networks (RNNs) capture evolving entity relationships through embeddings. However, these methods must perform model training on specific datasets, which is resource-intensive. With the proven understanding and generative capabilities of large language models (LLMs), recent studies have explored methods on LLMs (Tao et al., 2023; Lee et al., 2023; Shi et al., 2023b). The method proposed by (Lee et al., 2023) offers a more adaptable method for TKGF with in-context learning (ICL) on LLMs, allowing LLMs to adapt to TKGF by using examples in the context, without fine-tuning.\nNevertheless, due to limitations in the length of history of LLM inputs, this approach may not fully capture long-term trends among events and cannot effectively leverage past insights, such as causal relationships between events. Imagine a TKG scenario that relates to everyday life. An example quadruple could be: \u2018(Sarah, Consult, Dr. Smith, 2022/04/10)', indicating that Sarah consulted Dr. Smith on April 10, 2022. In this case, the ICL method may use static key values like 'Sarah' and \u2018(Sarah,Consult)' to extract historical events. However, this method may not account for Sarah's tendency to begin consultations with phone calls months before meeting in person, This is evident in events such as \u2018Discuss by telephone' being a preceding cause, for example, \u2018(Sarah, Discuss by telephone, Dr. Smith, 2022/01/08)'. This long-standing pattern of initiating consultations with a call is a crucial piece of historical context that short-term data analysis could miss. Without considering these longer-term causal interactions, the LLM-based method may not make accurate future predictions. Besides, in datasets like ICEWS (Boschee et al., 2015), the distribution of data containing entities and relations is dynamically changing. The emergence of new relations during test time poses challenges for traditional ICL methods, which rely on fixed keyword-key value matching and cannot adapt over time. This highlights the need for methods that can dynamically capture and apply updates in real-time, enhancing adaptability in event prediction.\nTo overcome these limitations, this paper proposes the Online Neural-Symbolic Event Prediction (ONSEP) framework. It enhances both accuracy and adaptability in event prediction by addressing inadequate long-term causal relationship capture and enabling real-time adaptability for self-improvement without fine-tuning. Figure 1 illustrates a comparison of the ONSEP and ICL approaches. By contrast, ONSEP mainly has two novel components: 1) Dynamic causal rule mining (DCRM): Utilizing LLMs' external knowledge, DCRM semantically detects cause-effect links and dynamically constructs causal rules. This enables ONSEP to quickly adapt to new data and causal relationships, facilitating real-time updates and leveraging past experiences without extensive retraining. 2) Dual History Augmented Generation (DHAG): DHAG employs the long short-term bi-branch retriever (LSBBR) and a hybrid model inference (HMI) strategy to merge short-term and long-term historical contexts. The latter benefits from causal rules derived during the DCRM phase, enabling a broader event to be captured within the limits of historical input length. Inspired by the multi-branch fusion inference technology described in (Shi et al., 2023a), the HMI strategy applies weighted fusion to balance the contributions from both dual historical contexts. These innovations address the limitations of context length constraints in LLMs and improve the retrieval of relevant historical events over extended periods.\nONSEP shows significant performance gains on various datasets using InternLM2-7B model, achieving Hit@1 improvements over ICL of 9.63%, 9.35%, and 16.28% at history length 100, and 8.14%, 8.64%, and 15.25% at 200, and achieved competitive performance of embedding-based models trained on specific datasets. To summarize, our main contributions include:\n\u2022 We introduce DCRM, an innovative real-time adaptive causal learning module for LLMs that automatically updates the rule base at the snapshot level during testing.\n\u2022 We develop the DHAG module, which uses LSBBR and HMI strategies, allowing LLMs to effectively use historical data from different time scales for causal analysis.\n\u2022 Our framework includes an adaptive RAG solution that improves historical event retrieval and achieves self-improvement.\n\u2022 We demonstrate ONSEP's effectiveness across various models and datasets, showcasing its ability to enhance black-box LLM inference without the need for fine-tuning or manual annotations, thereby providing a robust and adaptable solution for diverse event prediction tasks."}, {"title": "2 Preliminaries", "content": "A temporal knowledge graph (TKG) is structured as a time-sequenced series of multi-relational directed graphs. The TKG up to time t is represented as $TKG_t = {G_1, G_2,...,G_t}$, where each $G_t = (V, R, E_t)$ represents a snapshot of the graph at time t. Here, V denotes the set of entities, R the set of relations, and $E_t$ comprises timestamped facts as quadruples $(s, r, o, t)$, with $s, o \\in V$ and $r\\in R$. TKGF aims to predict future states of the graph by inferring missing entities in a quadruple for a future time. This involves generating predictions for either the object entity $(s,r,?,t + k)$ or the subject entity $(?, r, o,t + k)$ using historical data from previous snapshots $TKG_t$.\nICL enables LLMs to adjust to new tasks through contextual examples, without the need for fine-tuning. Specifically, in TKGF, ICL harnesses the adaptability of LLMs for forecasting by leveraging historical data. For a query of future event $q = (s_q, r_q,?,t_n)$, where $s_q$ is an entity and $r_q$ is a relation at timestamp $t_n$, this method employs static keys, such as entity $s_q$ or the pair $(s_q, r_q)$, to retrieve the historical event chain $H_n(q)$, a set of quadruples, from previous snapshots $TKG_{n\u22121} = G_{1:n-1}$. Then the method constructs a prompt $\\Theta_q$ based on $H_n(q)$. The prediction $y_q$ is generated by leveraging the LLM's probability distribution $Y_q \\sim P_{LLM}(y_q|\\Theta_q)$, employing ICL to generate forecasts without further training.\nTo effectively handle multi-word entity and relation names, a numeric mapping $M_{ent}$ and $M_{rel}$ assigns unique labels to entities and relations. For example, candidate entities like [South Africa, China, New England] are mapped to numerical values [0, 1, 2] to align the outputs from the LLM with these candidates. During in-context learning, LLMs perform a forward pass to produce logits s for next-token predictions. These logits are then transformed into a probability distribution D using the softmax function, representing the likelihood of each candidate being the target entity or relation."}, {"title": "2.3 Causal Rules in TKG", "content": "Causal rules\u00b9 in TKG capture cause-and-effect links between events, denoted as $CR(r_e,r_c)$: $(X,r_e, Y,T_2) \\leftarrow (X, r_c, Y,T_1)$, where X and Y represent anonymized entities, and $T_1$ and $T_2$ are timestamps, with $T_1 < T_2$ ensuring the correct temporal sequence from cause to effect.\nExtending this, we define a causal rule base (CRB) as a set of tuples, each comprising a causal rule (CR) and its confidence score (conf). The CRB for effect $r_e$ at timestamp $t_n$ is denoted as: $CRB^n(r_e) = {((X,r_e, Y,T_2) \\leftarrow (X, r_{c_i}, Y, T_1), conf) | 1 \\le i \\le m}$, where $r_{c_i}$ indicates the cause relation, $r_e$ denotes the resulting relation influenced by $r_c$, and $conf_i$ is the confidence score for the i-th causal rule at timestamp $t_n$, a real number within [0, 1]. Here, m represents the total number of causal rules considered in the rule base."}, {"title": "3 Method", "content": "The ONSEP framework (Figure 2) aims for event prediction via two key modules: (1) DCRM, which adaptively adjusts to changing data distributions during single-step prediction testing without requiring extensive training data, and (2) DHAG, which integrates patterns from short-term historical events with causality from long-term event developments. Detailed explanations are provided in the following sections."}, {"title": "3.1 Dynamic Causal Rule Mining", "content": "The dynamic causal rule mining (DCRM) phase is crucial for identifying causal relationships within temporal knowledge graph. This phase utilizes a semantic-driven rule learning algorithm to discover causal rules. It is followed by a dynamic update module that updates the causal rule base (CRB), which is closely followed by a mechanism for rule filtering and sorting by confidence."}, {"title": "3.1.1 Semantic-Driven Rule Learning", "content": "This module is designed for the reflective learning of causal rules, structured around three core steps: candidate causes filter, causality assessment, and causal rule construction. Initially, it retrieves historical context $H_n$ for all queries from $G_n$ and real-time feedback $O_y$, which is the verified outcome for a query obtained when the system receives new data, to filter potential reason events. In the causality assessment phase, these candidates are then evaluated using a LLM to determine the most plausible cause event $r_e$. Finally, the identified cause event, along with the query's effect event $r_e$ forms the basis for constructing a causal rule $CR(r_e, r_c)$. The algorithm of semantic-driven rule learning is outlined in Appendix A.\nIn the candidate event filtering phase, we utilize historical context and real-time feedback related to the query to filter potential causal events. Given a query $q = (S_q, R_e, ?, t_n)$ at time $t_n$, we define the context $H_n(S_q)$ as a historical sequence of events associated with subject $S_q$, expressed as $H_n = {(S_q, r, o, t) \\in G_n}$. We select candidates based on the criterion that the object o is the same as the target $O_y$, thereby forming a set of candidate reason events $H_c$, formalized as:\n$H_c(q) = {(S, r_c, \\hat{o}, t) \\in H_n(S_q) | \\hat{o} = O_y}$.\nHere, $r_c$ represents a potential causal relation, $\\hat{o}$ is the filtered object that matches the target $O_y$, and t is the timestamp associated with the event. This methodology aims to pinpoint potential causative relations corresponding to $r_e$ within the event sequence that links the query's subject S to the target entity.\nFor each distinct causative event $r_c$ within the candidates of reason events, we first extract the set of quadruples from $H_c$ that contain $r_c$, which we denote as $T_{r_c}$:\n$T_{r_c} = {(s, r, o, t) | r = r_c, (s, r, o, t) \\in H_c(q)}$.\nWe then compute the support number $supp(r_c)$ as the count of quadruples of this set: $supp(r_c) = |T_{r_c}|$. Subsequently, we calculate the coverage rate $cove(r_c)$ for each event $r_c$ using:\n$cove(r_c) = \\frac{supp(r_c)}{|H_c(q)|}  (1)$\nThis coverage rate aids in assessing the confidence level of causal rules and supports the review and selection of causal event candidates by the LLM."}, {"title": "LLM-based Causal Event Selection", "content": "In this step, the causal evaluation utilizes the powerful semantic understanding capabilities of the LLM to assess the degree of causal association between a set of potentially causal events. This evaluation aims to select the causal rules that are most relevant to the current query and feedback goals. A pivotal aspect of our methodology involves the formulation of a structured prompt $\\Theta_1$ (Table 1), designed to direct the LLM towards discerning the most pertinent causal link between a given result event ($r_e$) and potential causes within the candidate reason events set $H_c(q)$. The selection mechanism utilizes LLM to obtain the logits L for numerically mapped candidate reasons, as same as the way how to generate an output for each test query. These logits represent the preliminary evaluation of each candidate's likelihood to be the true causal event. To convert these logits into normalized probabilities, we apply the softmax function, yielding the probability $P_{rc_i}$ for each candidate reason $rc_i$, mapped to label $id_i$ using $M_{rel}$, reprented as $s = LLM(\\Theta_1(r_e, H_c(q)))$, where s are the logits produced by LLM, The probability of each candidate reason $rc_i$ is then computed by:\n$p(rc_i) = \\frac{e^{s[id_i]}}{\\sum_{j\\in M_{rel}} e^{s[id_j]}} (2)$\nBased on these probabilities, the top-k candidates are selected. The confidence $conf_t$ for each causal rule at timestamp t is determined by combining the probability $p(rc_i)$ with the coverage score $cove(rc)$, can obtained as:\n$conf_t(rc_i) = a\\cdot p(rc_i) + (1 - a) \\cdot cove(rc) (3)$\nwhere a is a tuning parameter that balances the contribution of the probability $p(rc_i)$ and the coverage score $cove(rc_i)$, integrating the causal assessment with historical occurrence insights."}, {"title": "Causal Rule Construction", "content": "Following the causality assessment step, a set of selected causal events ($r_c$) and their corresponding confidence scores at the current time step ($t_n$) are obtained. These causal rules are formalized in a structured format, with each rule at timestamp t represented as $CR_t(r_e, r_c) = (X,r_e, Y,T_2) \\leftarrow (X, r_c, Y, T_1)$, accompanied by a confidence value $conf_t(CR(r_e, r_c))$, can be obtained by $conf_t(r_c)$."}, {"title": "3.1.2 Dynamic Update", "content": "The dynamic update module for the causal rule base adds new rules directly and updates existing ones by adjusting their confidence levels. It assigns a confidence score $c_t$ to each causal rule CR, linking a pair of relations, and this score is dynamically updated at each time step t. This score merges the previous confidence $c_{t-1}$ with the current confidence $con f$ calculated at time t, effectively updating the confidence for each pair of relations within the causal rule.\nIt uses a smoothing factor ($\\theta$) to stabilize confidence adjustments, and a growth factor ($\\beta$) to incrementally evaluate the reliability of the circular verification rules, but the historical confidence can not exceed 1. The update formula of the existing rules is:\n$c_t = \\theta \\cdot f_g(c_{t-1}) + (1 - \\theta) \\cdot con f (4)$\n$f_g(c_{t-1}) = min(c_{t-1} \\cdot (1 + \\beta), 1) (5)$\nwhere $c_t$ is the updated confidence, $con f$ the current evaluated confidence of CR, and $c_{t-1}$ the previous confidence, $f_g$ represent the grow function with the growth factor $\\beta$.\nThis approach ensures continuous optimization of the rule base, allowing for adaptability in light of distribution changes over time."}, {"title": "3.1.3 Rule Filter and Sort by Confidence", "content": "In the final module of the DCRM, rules falling below a predefined confidence threshold, denoted as $con f_{min}$, are filtered out to ensure the usability of the causal rule base. Subsequently, the remaining rules are sorted based on their confidence levels, allowing rules with higher confidence to take precedence in the subsequent reasoning phase."}, {"title": "3.2 Dual History Augmented Generation", "content": "DHAG, an innovative RAG variant, introduces a long short-term bi-branch retriever (LSTBBR) coupled with a hybrid model inference (HMI) strategy."}, {"title": "3.2.1 Long Short-Term Bi-Branch Retriever", "content": "The long short-term bi-branch retriever (LSTBBR) within the DHAG framework incorporates a dual retrieval strategy to enhance the predictive model with a rich historical context, comprising both short-term and long-term historical events. For each prediction query $q = (S_q, R_e,?, t_{n+1})$, LSTBBR extracts two distinct historical contexts: $H_s$ representing the short-term history event chain and $H_i$ representing the long-term causal event chain. This dual approach ensures a comprehensive understanding of the immediate events as well as the underlying long-term causal influences. The short-term history event chain ($H_s$) focuses on capturing the most recent events that are temporally proximate to the prediction query, providing an immediate context that reflects the latest developments. To construct $H_s$, the system retrieves events from $H_n(S_q)$, sorting them by timestamp and truncating to include only the L most recent events. This truncated list of events forms $H_s$, which is directly associated with the query's subject $S_q$, thereby providing a snapshot of the most immediate historical backdrop relevant to the query.\nOn the other hand, the long-term causal event chain ($H_i$) is designed to uncover the broader causal dynamics that have shaped the subject S over a more extended period. This is achieved by initially retrieving cause rules from $CRB(r_e)$ using a RECALL mechanism, which employs a key-value approach where the effect relation $r_e$ is used as the key to efficiently extract associated causal rules.\nSubsequently, cause events are filtered to construct the long-term cause event chain $H_i$ from $H_n(S_q)$. The events in $H_i$ are determined by the criteria: $(S_q, R_{ci},o_i,t_i)$ where $CR(R_e, R_{ci}) \\in CRB(R_e)$ and $(S, R_{ci}, o_i,t_i) \\in H_n(S_q)$, with $t_i < t_{n+1}$. Similar to $H_s$, $H_i$ is truncated to include only the most recent L events since limited by the max length of model input."}, {"title": "3.2.2 Hybrid Model Inference", "content": "Before inference, a numerical label mapping technique preprocesses multi-word entities to prepare them for integration into the model, similar to the causality assessment in DCRM. The essence of the hybrid model inference (HMI) strategy involves merging the query q with the short-term history event chain $H_s$ and the long-term causal event chain $H_i$. This allows the LLM to produce distinct probabilities for each context, which are then combined using a weighted ensemble approach.\nFor the short-term context, the logits $s_1$ are obtained by $s_1 = p(y|q\\oplus H_s)$, where symbol$\n$\\oplus izes concatenation. The logits $s_1$ are then normalized using the softmax function to produce a probability distribution $D_1 = softmax(s_1)$. Similarly, for the long-term context, the logits $s_2$ are derived by $s_2 = p(y|q\\oplus H_i)$, and the corresponding probability distribution $D_2$ is obtained by applying the softmax function to $s_2$, resulting in $D_2 = softmax(s_2)$. The integration strategy involves a weighted ensemble of $D_1$ and $D_2$, formulated as:\n$D = D_1 \\cdot (1 - \\lambda) + D_2 \\cdot \\lambda.  (6)$\nHere, $\\lambda$ is a tuning parameter that balances the contributions of short-term and long-term contexts. This unified distribution D ranks candidate entities by their relevance to q, leveraging the nuanced insights from both $H_s$ and $H_i$. By doing so, the HMI strategy enhances the LLM's accuracy in entity predictions, grounded in a comprehensive understanding of dual historical contexts."}, {"title": "4 Experiments", "content": "Our experimental evaluation is carried out on a subset of the integrated crisis early warning system (ICEWS) dataset, which includes versions such as ICEWS14 (Garc\u00eda-Dur\u00e1n et al., 2018), ICEWS05-15 (Garc\u00eda-Dur\u00e1n et al., 2018), and ICEWS18 (Jin et al., 2020). These datasets are composed of timestamped records of political events, making them highly suitable for conducting temporal analysis. They are widely recognized as benchmark datasets on TKGF. Each event is represented as a tuple, such as (Barack Obama, visit, Malaysia, 2014/02/19), capturing diverse political activities across various time periods.\nTo evaluate our method's efficiency in ranking event candidates, we use link prediction metrics like Hit@k (where k = 1,3,10). This measures the precision of our model in forecasting future events within the top k predictions. Higher Hit@k values indicate more accurate rankings, which, in product recommendations, translate to better purchase predictions and greater economic benefits.\nWe primarily compare ONSEP with the ICL method. Additionally, we have selected several traditional supervised models based on embedding methods for performance comparison, including RE-NET (Jin et al., 2020), CyGNet (Zhu et al., 2021), RE-GCN (Li et al., 2021), xERTE (Han et al., 2020), and TITer (Sun et al., 2021) in TKG. We also compare our method with a variety of LLMs.\nFurther information about the datasets, evaluation metrics, LLMs used and implementation specifics can be found in the Appendix B."}, {"title": "4.2 Performance Comparison", "content": "To evaluate whether ONSEP surpasses the previous best event prediction method based on LLMs, ICL, we conduct experiments with historical inputs of 100 and 200, using InternLM2-7B for all methods. As Table 2 shows, our method outperforms ICL across all three datasets. Specifically, with a history length of 100, ONSEP achieves Hit@1 improvements of 9.63%, 9.35%, and 16.28%, and with 200, the gains are 8.14%, 8.64%, and 15.25%. These results confirm ONSEP's capability to exceed the performance of the previous ICL method. These results underscore ONSEP's superior performance over ICL, particularly in Hit@1 accuracy, indicating a notable enhancement in precision.\nWhile ONSEP trails behind some trained embedding models in Hit@10 due to the LLM's reliance on ranking candidate entities from the input history rather than all entities, it achieves top performance in Hit@1 for the ICEWS14 and ICEWS05-15 datasets. Additionally, it shows closely competitive results in other metrics. This highlights ONSEP's capability to significantly enhance accuracy. For a detailed exploration of ONSEP's operational dynamics and its real-world applicability, see the ICEWS14 case study in Appendix C."}, {"title": "4.3 Inductive Setting and the Effectiveness of DCRM", "content": "To assess the transferability of causal rules mined during test-time iterations, we conduct experiments where rules learned from ICEWS14 are applied to predictions on ICEWS18, with findings presented in Table 3. There are significant temporal spans and differences in data distribution between ICEWS14 and ICEWS18. For example, ICEWS18 includes entities such as Donald Trump, who served as the President of the United States from 2017 to 2021, which are not present in ICEWS14.\nWith only a 20.3% overlap (see Table 5) in entities between the two datasets, our inductive experimental setup demonstrates performance improvements. Comparing the ICL method without pre-loaded rules (i) to the approach using ICEWS14-derived rules (iv), we observe a significant performance boost in the latter, indicating that the DCRM-mined causal rules are generalizable across datasets with similar relational structures, thereby improving inference.\nFurther analysis on the DCRM module's impact shows that incorporating DCRM (iii) versus not incorporating it (iv) leads to enhanced performance across all metrics, including a notable 9.52% increase in Hit@1. This underscores DCRM's effectiveness in improving the accuracy and recall of inference.\nInterestingly, real-time rule mining with DCRM without pre-loaded rules (ii) is slightly higher than that of the inductive setting (iii) (i.e., with pre-loading the rules learned from $G_{test_1}$), suggesting that relying on potentially outdated rules may hinder adaptation to new data. Due to the smoothing setup in dynamic updates, the old rule set may introduce some interference, hindering rapid adaptation to the new test set. This emphasizes the need for dynamic rule updates to ensure model relevance and effectiveness across varying datasets with dynamically changing distributions."}, {"title": "4.4 Effectiveness of DHAG", "content": "To assess the DHAG module's impact, we explored how blending short-term and long-term history contexts affects performance on the ICEWS14 dataset, with similar findings observed on other datasets. We vary the Weighted Fusion Ratio from 0 to 1, as shown in Figure 3, with details in Appendix D.2.\nOur findings indicate a clear pattern: a $\\lambda$ value of 0, which effectively uses only short-term history chain akin to the baseline ICL method, leads to lower performance. Conversely, a $\\lambda$ of 1, relying solely on long-term reasoning, also underperforms compared to a balanced approach. The optimal performance at a fusion ratio of 0.1 indicates that the model primarily utilizes short-term dynamic history for reasoning, while also incorporating long-term causal knowledge acquired during test time to improve its effectiveness."}, {"title": "4.5 Performance Comparison of Different Model Scale and Series", "content": "Our analysis reveals that model performance improves with increased parameter scale, with the 20B models outperforming the 7B models, aligning with the scaling law. However, the performance gain from increasing the model size from 7B to 20B is less pronounced and comes with higher computational costs. The ONSEP method enhances performance across different model scales and series, demonstrating its adaptability and effectiveness. Detailed comparisons across model series indicate that ONSEP's improvements are consistent, with InternLM2-7b showing the most significant gains. Further in-depth analysis and discussions are provided in Appendix D.1."}, {"title": "4.6 Hyperparameter Sensitivity Analysis", "content": "Our hyperparameter sensitivity analysis highlights the critical role of selecting the right history length L, rule selection thresholds k, and fusion ratios a for causal rule confidence scores. Finding the right balance between the length of historical input and computational efficiency is essential for optimal model performance. Similarly, precise calibration of rule selection thresholds and fusion ratios is vital for the effective application and updating of causal rules, taking into account factors such as the smoothing factor @ and growth factor \u03b2. These parameters collectively influence the model's ability to adapt and perform accurately over time. A more detailed discussion on these findings and their implications is provided in the Appendix E."}, {"title": "5 Related Work", "content": "In TKGF, traditional embedding-based methods (Jin et al., 2020; Zhu et al., 2021; Li et al., 2021; Han et al., 2020; Sun et al., 2021; Li et al., 2022) learn representations of the quadruple, showing efficacy in supervised learning. Recent efforts explore LLMs for event prediction. For example, Xu et al. (Xu et al., 2023) use a masking strategy to make the forecasting task similar to predicting missing words. LAMP (Shi et al., 2023b) utilizes LLMs as a cause generator to reorder candidate outcomes, while ICL has been applied in TKGF (Lee et al., 2023), transforming forecasting into a sequence generation task. Besides, GenTKG (Liao et al., 2023) leverages few-shot parameter-efficient instruction tuning of LLMs using the training set to enhance inference capabilities. These approaches hold promise for improved generalization and contextual understanding. However, their effectiveness in dynamic real-world scenarios warrants further investigation.\nOn the other hand, rule-based approaches like Tlogic (Liu et al., 2022) focus on interpretability and generalization by learning symbolic rules from TKGs. Despite their strengths, these methods struggle with large search spaces, can't incorporate textual semantics of relations, and rely on static rule sets, limiting their adaptability."}, {"title": "5.2 Retrieve Augmented Generation", "content": "Retrieval-augmented generation (RAG) significantly enhances LLMs by integrating dynamic external knowledge retrieval (Lewis et al., 2020), mitigating common challenges like hallucinations and slow information updates. Advancements like REPLUG (Shi et al., 2023a) and AAR (Yu et al., 2023) further enhance RAG. REPLUG refines retrieval models with supervised feedback from language models. AAR, on the other hand, is a versatile plugin trained with a single source LLM but adaptable to various target LLMs. These adaptive mechanisms of RAG could be particularly beneficial in LLM-based TKGF, improving semantic alignment between queries and retrieved history context."}, {"title": "5.3 Self-Improving on LLMS", "content": "Researchers have recently proposed methods by using LLM's inherent knowledge as an external database to let LLMs self-improve without annotated datasets and parameter updates. Frameworks like ExpNote (Sun et al., 2023), HtT (Zhu et al., 2023), and MoT (Li and Qiu, 2023) facilitate learning from experience, rule induction, and high-confidence thought generation. However, their application to tasks with temporal dimensions remains to be explored. Following this idea, we proposed an ONSEP framework to enable the model to induce rules in real-time during the testing process and then use them for future predictions."}, {"title": "6 Conclusion", "content": "In this paper, we introduce a novel online neural-symbolic framework, ONSEP, that integrates LLMs with TKGs to achieve adaptive and precise event forecasting in a dynamic online environment. To overcome the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to new data, we propose a dynamic causal rule mining module and a dual history augmented generation module within the ONSEP framework. This design allows LLMs to access the most recent history to identify patterns, as well as causal relationships from a broader range of past events. Extensive experiments conducted on three benchmark datasets have proven the efficacy of ONSEP in TKGF, surpassing previous methods and demonstrating its broad applicability across diverse LLMs. Our framework shows great potential for future applications in financial forecasting, public sentiment monitoring, and recommendation systems."}, {"title": "Limitations", "content": "Our method requires multiple uses of large models, leading to increased inference time (see Appendix F) and higher computational costs compared to simpler models. The effectiveness of the model is influenced by the length of the input context; longer contexts are only useful for LLMs designed to handle them. The method also faces interpretability challenges due to unclear reasoning paths, which can be particularly evident in applications like campaign strategy analysis with the ICEWS dataset.\nAdditionally, the method's potential to improve performance is limited for data that lacks a rich semantic understanding or detailed relationships needed to extract comprehensive causal rules. Since there is an upper limit on the length"}]}