{"title": "Declarative Knowledge Distillation from Large Language Models for Visual Question Answering Datasets", "authors": ["Thomas Eiter", "Jan Hadl", "Nelson Higuera", "Johannes Oetsch"], "abstract": "Visual Question Answering (VQA) is the task of answering a question about an image and requires processing multimodal input and reasoning to obtain the answer. Modular solutions that use declarative representations within the reasoning component have a clear advantage over end-to-end trained systems regarding interpretability. The downside is that crafting the rules for such a component can be an additional burden on the developer. We address this challenge by presenting an approach for declarative knowledge distillation from Large Language Models (LLMs). Our method is to prompt an LLM to extend an initial theory on VQA reasoning, given as an answer-set program, to meet the requirements of the VQA task. Examples from the VQA dataset are used to guide the LLM, validate the results, and mend rules if they are not correct by using feedback from the ASP solver. We demonstrate that our approach works on the prominent CLEVR and GQA datasets. Our results confirm that distilling knowledge from LLMs is in fact a promising direction besides data-driven rule learning approaches.", "sections": [{"title": "Introduction", "content": "Visual question answering (VQA) (Antol et al. 2015; Goyal et al. 2017) is a challenging problem with valuable applications (Barra et al. 2021; Lin et al. 2023); it is the task of providing an accurate answer for a question about a visual scene. This requires not just a joint understanding of vision and text, but also the ability to follow complex chains of reasoning operations.\nNeurosymbolic approaches to VQA (Mao et al. 2019; Yi et al. 2018; Amizadeh et al. 2020; Eiter et al. 2022; Sur\u00eds, Menon, and Vondrick 2023; Johnston, Nogueira, and Swingler 2023, etc.) use deep learning for perception, produce a symbolic representation of the input image and question, and then perform reasoning on this representation in a purely symbolic way. These approaches are interpretable, transparent, and can be extended easily due to their compositional structure. A promising direction in this regard is to use logic-based formalisms for the reasoning component. We are in particular interested in using Answer-Set Programming (ASP) (Brewka, Eiter, and Truszczynski 2011; Lifschitz 2019), a prominent knowledge representation framework, for the reasoning module of such systems. Besides concise representations, advantages are that non-determinism allows for multiple answers if desired, ambiguity in the perception often can be resolved in the reasoning module (Eiter et al. 2022), and one can more easily add explanation capabilities (Eiter et al. 2023). Using ASP to augment VQA with reasoning capabilities is a topic that is indeed currently gaining traction and is used not only for VQA (Abraham, Alirezaie, and Raedt 2024; Eiter et al. 2023; Eiter et al. 2022; Basu, Shakerin, and Gupta 2020), but also for tasks such as segmentation of medical images (Bruno et al. 2021). The downside is that crafting the rules for such a component is not always easy and can be an additional burden on the developer.\nWe address this challenge by presenting an approach for declarative knowledge distillation from Large Language Models (LLMs) (Vaswani et al. 2017; Zhao et al. 2023) (see Fig. 1). The premise of this work is that we want to develop a modular solution for a VQA task for which we have, as is commonly the case, a dataset of questions, scenes, and answers at our disposal. Further, the reasoning component involves already an initial ASP theory that covers some but not all aspects of the VQA task. Our method is to prompt an LLM to extend this initial theory to meet the remaining requirements. Examples from a VQA dataset are used to guide the LLM, validate the results, and mend the generated rules if they are not correct using feedback from the ASP solver. More specifically, if we encounter an example from"}, {"title": "Related Work", "content": "Answer-Set Programming and LLMs. Recently, LLMs have been explored in the context of ASP. Ishay, Yang, and Lee (2023) observed that LLM reasoning capabilities are shallow, but they can serve as a highly effective semantic parser to transform input into ASP representations. These are then used to solve logical puzzles. We also recently proposed to use LLMs to parse the question into ASP facts in the context of VQA for images of graphs (Bauer et al. 2023). Rajasekharan et al. (2023) showed that the combination of LLMs with ASP in their STAR framework produces good results for natural language tasks that require qualitative reasoning, mathematical reasoning, and goal-directed conversation. Our work is different as we do not focus on semantic parsing but on the more challenging task of knowledge distillation, where we aim for a system that can produce sound logical rules capturing knowledge about a particular domain. Recent work by Zhu et al. (2023) explores the use of LLMs to learn rules from arithmetic and kinship relationships, yet the rules they learn do not contain variables and their semantics is informal.\nStatistical-relational learning. Similar to our approach, methods from statistical-relational learning (SRL) (Raedt and Kersting 2017), in particular from inductive logic programming (ILP) (Muggleton 1991; Muggleton and Raedt 1994; Cropper et al. 2022), aim at producing rules from example data and a background theory. SRL has seen great advances in terms of scalability by, e.g., applying gradient-based boosting (Gutmann and Kersting 2006), and systems like ILASP (Law, Russo, and Broda 2020) and FastLAS (Law et al. 2020) provide means for inductively learning expressive ASP programs.\nHowever, SRL takes a statistical and probabilistic learning perspective that is in essence data driven. Our method is orthogonal to that, as it does not aim at learning. On the surface, we also use a data set, but the role is very different as it guides a knowledge distillation process via conditioning an LLM. ILP uses a search-based approach where the solutions produced are correct and minimal under some criteria. A key aspect of many ILP systems are mode declarations that define the syntactic form of allowed rules to restrict the search space of possible programs. Mode declarations are in a formal language, and they tacitly assume an intuition about the form of the solution. For the distillation approach, we do not need that; we only elicit knowledge that is already present in the LLM, and the information in the prompt that instructs what rules we want is informal and in natural language. When prompting LLMs, rules are general by command-while optimality is not enforced, it may happen implicitly.\nModular neurosymbolic VQA. There are several VQA systems that feature a modular architecture which combines subsymbolic with symbolic components (Yi et al. 2018; Mao et al. 2019; Amizadeh et al. 2020; Eiter et al. 2022; Sur\u00eds, Menon, and Vondrick 2023; Johnston, Nogueira, and Swingler 2023). Specifically, Yi et al. (2018) used a pipeline to extract a scene graph (a list of all objects detected in the image with their attributes and positions) from the image. They then translated the provided question into a structured representation of the reasoning steps, called functional program, and executed this program on the structural scene representation to obtain an answer. The authors showed excellent results on the popular CLEVR dataset (Johnson et al. 2017). This approach has been advanced with logic-based reasoning processes, e.g., by Differentiable First-Order Logic (V-FOL) (Amizadeh et al. 2020), or by ASP (Eiter et al. 2022). These reasoning processes can consider not just the"}, {"title": "Background & VQA Methodology", "content": "In this section, we review the basics of the logic-based VQA approaches for the two datasets, GQA and CLEVR, that we are going to use for our evaluation. Both systems use ASP to derive answers from a symbolic scene representation. So we start by reviewing the basics of ASP next."}, {"title": "Answer-Set Programming", "content": "Answer-Set Programming (ASP) (Brewka, Eiter, and Truszczynski 2011; Lifschitz 2019) is a well-known approach to declarative problem solving, in which solutions to a problem are described by sets of logical rules. Efficient ASP solvers for evaluating the rules are readily available.\u00b9\nFor our concerns, an ASP program is a finite set P of rules r of the following form:\na:- b1,..., bn, not c1,..., not cn m, n \u2265 0\nwhere a, all bi, and all cj are atoms in a first-order predicate language, and not stands for negation as failure (aka. weak negation). We allow that a may be missing (viewed as falsity); then r acts as a constraint. Intuitively, the rule means that whenever all bi are true and none of the cj can be shown to be true, then a must be true. Some rules appear in Fig 2b.\nThe semantics of a ground (variable-free) ASP program is given in terms of answer sets, which are Herbrand models that satisfy a stability condition (Gelfond and Lifschitz 1988). A Herbrand interpretation of P is a set I of ground atoms in the language induced by P (intuitively, the atoms that are true). Such an I is a model of P if for each ruler in P either (i) a \u2208 I or (ii) {b1, ..., bn} \u00a3 I or (iii) I\u2229 {C1, . . ., Cn } \u2260 0; that is, I satisfies r viewed as implication in classical logic. An interpretation I is then an answer set of P, if I is a C-minimal model of the program Pl = {r \u2208 P | I satisfies neither (ii) nor (iii)}. Intuitively, I must result by applying the rules r whose bodies \"fire\" w.r.t. I starting from facts. The semantics of programs with variables is defined in terms of their groundings (uniform replacement of variables in rules with all possible ground terms).\nASP features further constructs such as choice rules (which allows to select among alternatives under cardinality bounds) and weak constraints (i.e., soft constraints expressing costs for an objective function that is minimised); notably, the latter allow for modeling numeric uncertainty and to single out the most likely from answer sets of a program or a range of most likely answer sets. For more details on ASP, we refer to (Brewka, Eiter, and Truszczynski 2011; Calimeri et al. 2020)."}, {"title": "Zero-Shot VQA for the GQA Dataset", "content": "Next, we explain our system for zero-shot VQA for the GQA dataset (Hudson and Manning 2019). It does not require any training, but relies on foundation models for processing the visual scene and ASP for deducing answers.\nThe GQA dataset. We use the state-of-the-art GQA dataset, which has been widely adopted in the recent literature (Amizadeh et al. 2020; Sur\u00eds, Menon, and Vondrick 2023; Liang et al. 2020; Li et al. 2023). It contains over 22M open and binary questions that are complex in structure, involve a wide variety of reasoning skills, and have a large number (1878) of possible answers. The questions cover more than 100 000 images from the Visual Genome dataset (Krishna et al. 2017) that present real-world scenes with a wide variety of object classes, attributes, and relations. GQA comes with two types of supplementary data that greatly aid in the development of our pipeline: First, each natural-language question from the test split comes with a functional representation of its required reasoning steps. Second, a Visual Genome scene graph is provided for every image in the test split of the dataset, which allows us to verify soundness of our ASP encoding under perfect visual information.\nSolving GQA. Our system for solving GQA, shown in Fig 2a, resembles other modular neurosymbolic models consisting of modules for language, vision, and reasoning. We next describe these modules, a performance evaluation is relegated to the appendix. As mentioned, one of the advantages of using GQA is that we already have a functional representation that we can use for every question. Neurosymbolic systems have already shown that even classic neural networks such as the LSTM (Hochreiter and Schmidhuber 1997) are able to properly translate natural language into these representations. Moreover, LLMs can now be used for the task of semantic parsing, which may generalise much better than trained neural networks for specific datasets. We assume that the representation is given, and thus we only implement a script that translates it to our ASP representation. An example of this is shown in Fig. 2b under \"Question Encoding\". The predicates are linked by the numbers in the first argument, which represent steps to compose questions.\nWe next discuss the reasoning module, which uses as a fixed logical program. In a later section, we show how to use LLMs to extend such a logical theory to add functionality.\nThe ASP theory. The GS-VQA pipeline constructs symbolic encodings of both the input question and the input image, which we call question encoding and scene encoding, respectively. Similarly to a related approach (Eiter et al. 2022), we use ASP as the symbolic formalism for these encodings. This provides us not only with a mature ecosystem of tooling and solvers, but more importantly, allows us to capture the uncertainty in the class, attribute, and relation predictions of the scene-processing component.\nThe ASP theory consists of a set of rules that\u2014in contrast to the question and scene encoding\u2014do not change from question to question and encode the semantics of the reasoning operations that can appear as part of the question encoding."}, {"title": "VQA for the CLEVR Dataset", "content": "The second dataset we consider is CLEVR (Johnson et al. 2017), which uses synthetic scenes but challenges VQA systems with more complex compositional questions. We use a VQA system for CLEVR (Eiter et al. 2022), that we have extended by an explanation component in recent work (Eiter et al. 2023). We revisit its basic functionality in the remainder of this section.\nThe CLEVR dataset. CLEVR was designed to test VQA system with compositional questions that involve making several reasoning steps to derive the correct answer. The dataset contains synthetically generated images with different objects in it. These objects vary in their shape (cube, cylinder, sphere), colour (brown, blue, cyan, gray, green, purple, red, yellow), size (big, small), and material (metal, rubber).\nCLEVR questions require, e.g., identifying objects, counting, filtering for attributes, comparing attributes, and spatial reasoning. They are formulated in natural language, but, as for GQA, a functional representation is also provided that"}, {"title": "Knowledge Distillation Method", "content": "Our VQA approaches use a hand-coded ASP theory that correctly computes the answer to any question in the dataset, given a correct representation of both the question and the image. The ASP encoding is constructed around a fixed dataset. If the dataset is extended, rules need to be modified or added to handle new examples. In general, these new rules must be crafted by a human; here, an LLM based system can come to aid and provide automated support. To this end, we aim for a reasoning module that manages the theory by being able to recognise which examples it can handle and which it cannot, and in the latter case, by adding rules in a way such that the example can be solved. We propose a method of declarative knowledge distillation, where the model we distil from is an LLM, and the knowledge that is distilled from it is represented in ASP rules."}, {"title": "Preprompt", "content": "We first present a preprompt that instructs the LLM to only return ASP rules that extend an initial theory Init. Theory Init is a partial encoding for the task at hand that we want to extend. Our preprompt consists of several components:\n1. Introduction: We present the setting of VQA and clarify that we have already parsed both scene and question into correct representations.\n2. Language Syntax: We describe the syntax of the language we use to represent questions and scenes, in our case ASP."}, {"title": "Rule Distillation Algorithm", "content": "With the task explained to the LLM by the preprompt, we can start to present examples from the dataset. For each question/scene/answer tuple p = (Q, S, A), we do the following steps (and repeat them for the same example at most r times if not successful):\n1. Prompting: We prompt the LLM with p as additional input, and we get as a response R.\n2. Solving: We concatenate R with the initial theory to get theory Res. Then, we run an ASP solver on theory Res alongside the instance pair (Q, S).\n(a) Syntax Check: If we get a syntax error, we pass the error message to the LLM and prompt it to revise R accordingly. We try this at most m times.\n(b) Semantic Check: We check whether the answer we get from the solver is correct, i.e., coincides with A. If not, we pass the actual answer and the expected answer to the LLM and task it to update R; we try this at most m times.\n3. Regression Testing: To avoid that adding rules to the theory renders past examples incorrect, we test Res on all previously seen examples. Only if all tests pass we keep Res, otherwise we disregard the extension R."}, {"title": "Knowledge Distillation Experiments", "content": "We conduct a series of experiments to evaluate our knowledge distillation method on GQA and CLEVR to answer the following research questions:\n(R1) Given an ASP-based VQA system and a VQA task, can our approach extend the ASP reasoning component to deal"}, {"title": "Discussion", "content": "We turn back to our research questions from the beginning of this section.\n(R1) Experiment 1 shows that LLMs are capable of completing an ASP program that has all rules for a single operation removed. This is the case when a dataset is extended with new examples that require reasoning operations that are not yet encoded.\n(R2) Regarding the suitability of different LLMs for declarative knowledge distillation, we conclude that only grand-scale LLMs, with GPT-4 currently the market leader, are able to tackle this problem effectively. Arguably, the LLMs that we used have more knowledge about mainstream programming languages such as Python than logical programming languages. It will be interesting so see whether small, self-hosted language models will eventually catch up in the future.\n(R3) When challenged with restoring increasingly large parts of an ASP theory, the current approach reaches its limits. Only the most powerful model we used is still able to produce sound ASP rules.\n(R4) Our experiments on batch processing and the ablation study helped to illuminate the trade off between performance and reducing the number LLM calls. In conclusion, better performance can be bought by using more prompts, which can be expensive if a subscription-based LLM is used."}, {"title": "Conclusion", "content": "We have presented an approach for declarative knowledge distillation using LLMs to find rules that extend the reasoning component of a VQA system to extend its capabilities. This process uses examples from a dataset as guidance and relies entirely on prompting without the need to train or fine-tune the used language models. We have demonstrated this approach on the prominent CLEVR (Johnson et al. 2017) and GQA (Hudson and Manning 2019) datasets. The benefit of using logic-based methods in combination with foundation models is that we obtain systems that behave in an interpretable and verifiable way to ensure correct reasoning. Logical rules are intuitive, and they can helpful in VQA architectures to create advanced reasoning capabilities, including explainability. Our knowledge distillation method shows promise for automating the process of ASP modelling for VQA, a complex scenario that requires understanding of intricate representations.\nFor future work, we want to study further VQA datasets, but we also want to explore other tasks than VQA that potentially benefit from distilling rules from LLMs. As using API-based LLMs can be expensive, we want to look into balancing performance of the distillation approach and the number of LLM calls. Enhancing the LLM approach with concepts from ILP and a possible combination would also be interesting to explore."}, {"title": "Appendix", "content": "We provide an evaluation of our logic-based VQA approach, which we call GS-VQA. We evaluated the GS-VQA pipeline"}]}