{"title": "TOWARDS A THEORETICAL UNDERSTANDING OF SYNTHETIC DATA IN LLM POST-TRAINING: A REVERSE-BOTTLENECK PERSPECTIVE", "authors": ["Zeyu Gan", "Yong Liu"], "abstract": "Synthetic data has become a pivotal resource in post-training tasks for large language models (LLMs) due to the scarcity of high-quality, specific data. While various methods have been developed to generate synthetic data, there remains a discernible gap between the practical effects of synthetic data and our theoretical comprehension. To address this challenge, we commence by presenting a detailed modeling of the prevalent synthetic data generation process. Building upon this modeling, we demonstrate that the generalization capability of the post-trained model is critically determined by the information gain derived from the generative model, as analyzed from a novel reverse-bottleneck perspective. Moreover, we introduce the concept of Generalization Gain via Mutual Information (GGMI) and elucidate the relationship between generalization gain and information gain. This analysis serves as a theoretical foundation for synthetic data generation and further highlights its connection with the generalization capability of post-trained models, offering an understanding about the design of synthetic data generation techniques and the optimization of the post-training process.", "sections": [{"title": "INTRODUCTION", "content": "The efficacy of large language models (LLMs) is extensively influenced by both the volume and quality of the training data, as established by the widely acknowledged scaling laws. Given the inherent sparsity of data available during the post-training phases of LLMs, synthetic data plays a critical role, particularly during fine-tuning and alignment processes. Over the past decades, the LLM community has increasingly employed synthetic data to augment training in scenarios where real data is scarce. As of September 2024, there are over 1,000 datasets labeled as \u201csynthetic\u201d on the Hugging Face platform. Several leading-edge large language models, including LLaMA , Falcon , Qwen , and GPT-4 , have also reported utilizing synthetic data during their post-training stages. These instances underscore the pivotal role of synthetic data in enhancing the post-training of LLMs.\nNumerous methodologies for synthetic data generation have been advanced, yet the most prevalent and efficacious approach within the community involves generating synthetic data through sampling from a proficiently trained generative model, often another LLM tailored for specific domain tasks. To delineate this process more precisely, Long et al. (2024) describe the generation of synthetic data as follows: a well-trained generative model M is utilized, and synthetic data $S_{gen}$ is produced by sampling from M, conditioned on a set of prompts p, just as illustrated in the lower part of Figure 1 (a)."}, {"title": "RELATED WORK", "content": "Generative models constitute a category of machine learning models that are specifically trained to create new data points mimicking the original data distribution. Various types of generative models have been developed, each suited to particular data types and model architectures. Notable among these are Variational Autoencoders (Kingma, 2013), Generative Adversarial Networks (Goodfellow"}, {"title": "PRELIMINARIES", "content": "Let $S_{anchor}$ represent the real data utilized for generation, and $S_{gen}$ denote the synthetically generated data. The LLM employed in the generation process is designated as M, with the input prompt labeled as p. The distribution of the post-training target task T is referred to as D, while the output distribution of the LLM is denoted by $D_M$. Additionally, the distribution corresponding to the synthetic data is represented as $D_{gen}$. The generalization error associated with the under-aligned LLM $\\pi$ on the synthetic data $S_{gen}$ is expressed as $Err(\\pi_{gen})$, and the generalization error related to the anchor data is indicated by $Err(\\pi_{S_{anchor}})$. We define H(\u00b7) as the entropy of a random variable, I(\u00b7, \u00b7) as the mutual information between two random variables, $D_{KL}$ as the Kullback-Leibler divergence, and $D_{TV}$ as the total variation distance.\nTo provide a more intuitive demonstration, we use an example in the Gaussian mixture model (GMM) setting during the explanation. In simple terms, we assume that the target of the post-training task contains K + J Gaussian distribution components, and set up a corresponding ground-truth GMM (gt-GMM, G) to represent the target of the post-training task. After that, we randomly sample from the first K components of the gt-GMM as anchor data. To simulate the generative model M, we added L random components to the gt-GMM, which may include extra distributions, making M a GMM with total K + J + L components. Finally, we randomly sampled data from M to obtain the simulated synthetic data."}, {"title": "MODELING SYNTHETIC DATA GENERATION", "content": "Long et al. (2024) provided a brief summary for the synthetic data generation, the overall process of synthetic data generation can be modeled as $S_{gen} \\leftarrow M_p(T, S_{anchor})$, where $S_{gen}$ is the generated synthetic data, M is the generation model (usually a well-trained LLM), p is the prompt for generation, T is the downstream task, and $S_{anchor}$ is the anchor data (real data). More specifically, the prompt p is derived from the generation task T and the anchor data $S_{anchor}$, and consists of three crucial elements: $p(T, S_{anchor}) \\leftarrow E(e_{task}, e_{condition}, e_{demo})$, where E is the prompt template, $e_{task}$ is the task element, $e_{condition}$ is the condition element, and $e_{demo}$ is the anchor data element. The conceptual framework of this modeling is straightforward. $S_{gen}$ essentially constitutes a modification of the output generated by M in response to the prompt p, where the prompt p is defined by the downstream task T and the anchor data $S_{anchor}$.\nWe enhance our understanding of synthetic data generation by reevaluating the distributional relationships among the anchor data $S_{anchor}$, the prompt p, and the synthetic data $S_{gen}$ produced. We postulate that the anchor data $S_{anchor}$ is sampled from distribution D associated with the downstream task, and the generation process is influenced by both the prompt p and the generative model M. Consequently, $S_{gen}$ represents a modification of M's output in response to the prompt p: $S_{gen} = M(p) + \\epsilon$, where $\\epsilon$ is a noise term for the measurement of revision, such as the data curation process.\nThe prompt p is intricately linked to the downstream task T and the anchor data $S_{anchor}$. We postulate that $S_{anchor}$ forms the core of the prompt p, upon which a task-specific transformation function $\\Phi_T$ is applied. Consequently, the prompt p can be mathematically modeled as $p = \\Phi_T(S_{anchor})$, where $\\Phi_T$"}, {"title": "BRIDGING THE GENERALIZATION CAPABILITY", "content": "Subsection 3.2 offers an exhaustive examination of the synthetic data generation process, which is pivotal for elucidating the generalization error associated with the under-aligned LLM $\\pi$ when applied to synthetic data $S_{gen}$. This subsection endeavors to correlate the generalization error of $\\pi$ on the synthetic data $S_{gen}$ with the synthetic data generation process as previously delineated.\nGiven the focus on the alignment task performance, and considering that $\\pi$ is a pre-trained LLM, then $\\pi_{S_{gen}}$ is subsequently trained on synthetic data sampled from $D_{gen}$, the generalization error of post-trained LLM $\\pi_{S_{gen}}$ is delineated as $Err(\\pi_{S_{gen}}) = R_D(\\pi_{S_{gen}}) \u2013 R_{S_{gen}}(\\pi_{S_{gen}})$, where D is the real distribution of the post-training task. $R_D(\\pi_{S_{gen}}) = E_{z \\sim D} [l(\\pi_{S_{gen}}, z)]$ denotes the true error of $\\pi_{S_{gen}}$ on the distribution D, and $R_{S_{gen}}(\\pi_{S_{gen}}) = E_{z \\sim S_{gen}} [l(\\pi_{S_{gen}}, z)]$ denotes the empirical error of $\\pi_{S_{gen}}$"}, {"title": "MAIN RESULT", "content": "In preceding sections, we established a comprehensive modeling for synthetic data generation and elucidated the connection between this process and the generalization error as delineated in Lemma 3.1. This section delves deeper into the implications of the synthetic data generation process on the generalization capabilities."}, {"title": "INFORMATION GAIN & REVERSE-BOTTLENECK", "content": "To enhance our understanding of the synthetic data generation process, we delineate a suite of concepts pertaining to the information-flow within this process. Initially, we introduce the notion of synthetic factors, which represent the fundamental elements that influence the formation of $S_{gen}$.\nFollowing this framework, we proceed to introduce the concept of information gain within the context of the synthetic data generation process."}, {"title": "INFORMATION-FLOW GENERALIZATION ERROR UPPER BOUND", "content": "In this subsection, we endeavor to derive the upper bounds of the generalization error from an information-flow perspective, employing the concepts previously defined. We initiate our analysis with a classical information upper bound applicable to deep neural networks, as elaborated in Lemma 4.4.\nFor a deep neural network with L hidden layers, input S, and parameters W. The loss function is $\\sigma$-sub-Gaussian with respect to (W, Z) given any w, if all L hidden layers are contraction layers, the expected generalization error can be bounded as follows,\n$E [R(W) - R_S(W)] \\leq exp\\left(\\frac{L}{2} log\\left(\\frac{2\\sigma^2}{n}\\right) - \\frac{1}{n}I(S, W)\\right)$.\nLemma 4.4 establishes a connection between the expected generalization error and the mutual information between training data S and learned model parameters W. Despite network depth L and instance volume n, the principal constraint is imposed by the mutual information term.\nAccordingly, in scenarios where post-training is with synthetic data, the generalization error is inherently constrained by the mutual information between the synthetic data $S_{gen}$ and LLM parameters after training, denoted as $I(S_{gen}, W)$. Characterizing this term presents a significant challenge due to the difficulty in measuring mutual information accurately. To address this, we introduce an analytical upper bound for $I(S_{gen}, W)$ in Lemma 4.5 to facilitate a more comprehensive understanding of the dynamics influencing model performance in post-training."}, {"title": "GENERALIZATION GAIN WITH SYNTHETIC DATA", "content": "Theorem 4.7 establishes a general upper bound for the generalization error of LLMs post-trained with synthetic data. In this section, our objective is to analyze the generalization gains achieved by using synthetic data compared to scenarios devoid of synthetic data.\nWe commence our analysis with the anchor data $S_{anchor}$. Analogous to the definition of $Err(\\pi_{S_{gen}})$, the generalization error of an LLM that has been post-trained on $S_{anchor}$ is defined as $Err(\\pi_{S_{anchor}}) = R_D(S_{anchor}) \u2013 R_{S_{anchor}}(\\pi_{S_{anchor}})|$. It is logically sound to assume that $S_{anchor}$ is sampled from the distribution D. Building upon Lemma 4.4 and assume that $S_{anchor}$ comprises m instances, we can derive the subsequent result in Lemma 4.8."}, {"title": "VERIFICATION WITH GMM SIMULATION", "content": "Building upon the simulation settings, we offer a straightforward validation of the theoretical results discussed above. Specifically, we first fit a GMM $\\pi$ comprising K+J+L components to both $S_{anchor}$ and $S_{gen}$, yielding $\\pi_{S_{anchor}}$ and $\\pi_{S_{gen}}$ respectively. We then introduce a metric termed KL Gap, defined as $D_{KL}(\\pi_{S_{anchor}} ||G) \u2013 D_{KL}(\\pi_{S_{gen}} ||G)$, which represents the difference of KL-divergence between the fitted GMMs ($\\pi_{S_{anchor}}$ and $\\pi_{S_{gen}}$) and the ground-truth GMM G. A larger KL Gap corresponds to a greater GGMI, indicating enhanced generalization benefits from synthetic data.\nTo control the variables outlined in Theorem 4.10, we adjust the number of components in the GMM M and the ground-truth GMM G. The result is illustrated in Figure 4. Generally, increasing J facilitates the scaling of \u0394\u0399, resulting in a larger upper bound for GGMI. In contrast, larger K amplifies the influence of anchor data within the post-training target distribution, thereby increasing the $H(S_{anchor}|W)$ term and tightening the upper bound of GGMI. Additionally, while an increase in L enhances $H(S_{gen}|W)$ due to the introduction of greater diversity, it concurrently leads to a reduction in \u0394\u0397. As a result, we observe a trade-off manifested as a decrease in the KL Gap in our simulation outcomes."}, {"title": "CONCLUSION", "content": "In this paper, we have conducted a detailed analysis of synthetic data utilization in post-training large language models (LLMs). We present a comprehensive modeling of the current synthetic data generation process, focusing on its distributional aspects, which further connects the generalization capabilities of post-trained models. We introduce a novel reverse-bottleneck framework, allowing us to derive a measurable upper bound on generalization errors. Our analysis reveals that the pivotal constraint on generalization ability is influenced by the information gain from the generative model M. Additionally, we present the Generalization Gain via Mutual Information (GGMI), showing that larger information gains enhance the generalization capability of post-trained models. We emphasize the importance of balancing faithfulness and diversity during post-training stages, providing a theoretical foundation for existing methodologies.\nUnfortunately, due to limitations in computational resources, we are unable to validate our findings within real-world LLM settings. Looking ahead, future research should focus on developing adaptive models that respond to the evolving characteristics of synthetic data. This includes enhancing generative models and fine-tuning parameters for specific learning scenarios, as well as exploring various generative models to better replicate real-world data complexities while improving model performance."}]}