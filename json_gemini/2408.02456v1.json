{"title": "Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach", "authors": ["Wanxu Wei", "Yitong Song", "Bin Yao"], "abstract": "Knowledge graphs (KGs) play a vital role in enhancing search results and recommendation systems. With the rapid increase in the size of the KGs, they are becoming inaccuracy and incomplete. This problem can be solved by the knowledge graph completion methods, of which graph attention network (GAT)-based methods stand out since their superior performance. However, existing GAT-based knowledge graph completion methods often suffer from overfitting issues when dealing with heterogeneous knowledge graphs, primarily due to the unbalanced number of samples. Additionally, these methods demonstrate poor performance in predicting the tail (head) entity that shares the same relation and head (tail) entity with others. To solve these problems, we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH incorporates two separate attention network modules that work synergistically to predict the missing entities. We also introduce novel encoding and feature transformation approaches, enabling the robust performance of GATH in scenarios with imbalanced samples. Comprehensive experiments are conducted to evaluate the GATH's performance. Compared with the existing SOTA GAT-based model on Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.", "sections": [{"title": "1 INTRODUCTION", "content": "Knowledge graphs (KGs) store entities and their relations as triplets. Each triplet, which is also called fact, can be denoted as (h, r, t), where h and t are the head and tail entities, and r is their relation (e.g., the head entity h is \"Kobe\", the relation r is \"Career\", and the tail entity t is \"Basketball Player\"). Brimming with vast amounts of facts, KGs are widely employed to enhance the search results [6, 9, 38] and refine the recommendation results [10, 32, 33]. However, as KGs expand rapidly in size, the facts it contains may become inaccurate and incomplete, hindering the ability to provide satisfactory search and recommendation results.\n The knowledge graph completion (KGC) technique is dedicated to completing incomplete triples in KGs. Currently, several studies on knowledge graph completion focus on link prediction, which predicts missing values in a possible triplet. Link prediction is usually defined as, given a query triplet (?, r, t) or (h, r, ?), where? represents the missing value that needs to be predicted. For instance, given the query (?, isMarriedTo, William), the goal of link prediction is to predict that the missing value is \"Kate\". In this paper, we also study the link prediction problem for knowledge graph completion.\nRecently, knowledge graph embedding models based on graph neural network (GNN) have emerged as a successful method for the link prediction task. These approaches offer a comprehensive and nuanced representation of the knowledge graph by capturing the semantics of individual triplets as well as the structural information of the whole KG. Among all GNN-based methods, GAT-based approaches (e.g., GAT [30], r-GAT [2], KAME [13], DisenKGAT [35]) exhibit superior performance. This is due to the fact that GAT-based approaches assign different weights or importance to each neighbor during the information aggregation process. This allows the model to prioritize learning from important neighbors while diminishing the influence of unimportant connections. While significant progress has been made with GAT-based methods, further improvements are still needed for heterogeneous KGs. Heterogeneous KGs consist of diverse types of entities and relations, which provide a better representation of complex and varied real-world data. However, it becomes more challenging to predict entities and relations in such graphs using GAT-based methods."}, {"title": "Challenge", "content": "Challenge 1: Existing GAT-based approaches overfit in sparse entity and relation predictions. In deep learning, overfitting is a fundamental problem characterized by a model that can match the training set with high accuracy but performs poorly when modeling other data. [39] mentions that when the number of model parameters exceeds the amount of information in the training set. the model tends to memorize the training data rather than learn the underlying patterns, resulting in overfitting. The distribution of information in the real world tends to be skewed, resulting in some entities and relations appearing infrequently. For example, in Fig. 1(a), only one triple contains node E6 and relation r3. We call these entities and relations with low frequency \"sparse entities\" and \"sparse relations\", respectively. Existing GAT-based models often have a large number of parameters, which can lead to overfitting when modeling sparse entities and relations due to the parameter quantity exceeding the number of data points. Therefore, existing GAT-based methods suffer from performance degradation due to the presence of sparse entities and relations. For example, in Fig. 1(a), only one triple contains r3. Given the head entity E3 and relation r3, the model is likely to predict the entity E4, whereas the other potential tail entities are masked or overlooked. This is because overfitting occurs when using a large number of parameters to model sparse relations r3 with less information. As another example, there only exists one triple containing E6, i.e., (E6, r2, E1). And E5 is also related to E1 by r2. Assuming r\u2082 as a Teammate_of relation, there exists a fact (E6, r2, E5) in the real world but not in the KG. In this case, existing models fail to predict the entity E5 when provided with the head entity E6 and relation r2. This failure is primarily due to insufficient embedded information for E6.\n Challenge 2: Existing GAT-based approaches demonstrate poor performance in predicting the tail (head) entity that shares the same relation and head (tail) entity with others. In heterogeneous KGs, it is quite common to encounter scenarios where different tail (head) entities share the same relation with a particular head (tail) entity, as depicted in Fig. 1(b). In such cases, existing GAT-based approaches assign weights to entities based on relations. This will directly lead to the following two limitation: 1) Some information about neighboring entities may be lost. Relations may prioritize specific information about entities while disregarding other information. For example, consider the example illustrated in Fig. 2, where the entity of a basketball player, Ming Yao, encompasses various aspects of information such as family information and occupation information. However, the relation Teammate_of primarily focuses on the occupation information while neglecting other aspects. 2) Another limitation lies in the inability to capture the varying emphasis that the head entity places on different tail entities within the same relation. Even through the same relation, the head entity will have different inclinations towards neighboring entities. For example, as shown in Fig. 2, Ming Yao may have varying inclinations towards different teammates because of information unrelated to occupation information, such as personality and family. This difference cannot be explained if we only consider the relation Teammate_of.\nIn this paper, we propose a novel end-to-end GAT-based method for heterogeneous knowledge graph completion, aiming to overcome the limitations of existing GAT-based methods. In response to challenge 1, that is, the model is overfitting on sparse entities and relations due to a large number of parameters, our proposed solution is to reduce model parameters. Specifically, we first use reducing features to reduce the number of parameters representing relations. Instead of using matrices, we represent relations using embedding vectors. Additionally, reducing parameters may limit the model's ability to model relations with rich information. To address this, we introduce weight sharing to enhance the feature extraction capabilities of relations. We use the same attention projection matrices for all relations, which have a global perspective of KG. By applying these two methods, we reduce the parameters"}, {"title": "Contributions", "content": "\nWe introduce GATH, a novel GAT-based method specifically designed for Heterogeneous knowledge graph completion. GATH comprises two key components: an entity-specific attention network module and an entity-relation joint attention network module. These components work together to predict the missing entities.\nTo address the issue of model overfitting on heterogeneous KGs, we propose a novel encoding and feature transformation method. This method enables the robust performance of GATH in scenarios with sparse samples by effectively reducing the number of model parameters.\nWe conduct a comprehensive evaluation of GATH on the FB15K-237 and WN18RR datasets. Results show that GATH has superior performance than other competitors on various evaluation metrics, including mean reciprocal ranking (MRR), mean ranking (MR), and Hits@n. Compared with the existing SOTA GAT-based model on Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively."}, {"title": "2 RELATED WORK", "content": "Knowledge graph completion methods can be divided into translation-based models, semantic matching-based models, GCN-based models, GAT-based models, and language model-based models, as described below.\n Translation-based models. TransE [1] is a pioneering work of translation-based model. Inspired by word2vec [17], TransE utilizes the translation invariance of word vectors. It maps the head entity, relation, and tail entity respectively to the dense vectors h, r, t in a low-dimensional space, and then adjusts h, r, t so that h + r \u2248 t. Subsequent models, such as TransH [34], TransR [15], TransD [12], etc., proposed novel methods of relational translation, increasing the complexity of models and improving their performance. These models are also known as translation models or additive models. However, translation-based models have limited consideration of semantic information and struggle to handle one-to-many or many-to-many connections effectively. Despite their ease of expansion, these models have inherent limitations in capturing complex relations.\nSemantic matching-based models. As opposed to translation-based models, semantic matching-based models evaluate the rationality of facts by matching the potential semantics in embedded entities and relations. These models utilize scoring functions to quantify the semantic similarity between entities. RESCAL [19] declares a matrix for each relation and uses the bilinear function to calculate the rationality of triples. DistMult [36] simplifies RESCAL by replacing the relation-specific matrix with a diagonal matrix. Complex [26] extends DistMult to the complex space and is the first model to introduce complex number embeddings for knowledge graphs. However, although semantic matching-based models overcome the limitations of translation models by effectively capturing the symmetry or asymmetry of relations, they often struggle to efficiently model complex relational patterns. These models typically require a large number of parameters, leading to potential memory inefficiencies.\nGCN-based models. GCN-based models enhance the vanilla GCN for knowledge graph embedding through the incorporation of 1) relation-specific linear transformations, 2) weighted aggregation, and 3) relation representation transformations. Among these, RGCN [21] is the first work that introduces GCN to knowledge graph embedding. RGCN aggregates neighbor information through a relation-specific matrix. After that, SACN [22] assigns static weights to each relation type. CompGCN [28] jointly embeds entities and relations and uses combination operators to model their interaction. However, GCN-based models often exhibit limited flexibility and require loading the entire knowledge graph into memory, leading to scalability issues and posing challenges when applied to large knowledge graphs.\nGAT-based models. GAT-based models achieve state-of-the-art performance in knowledge graph embedding by dynamically modeling the interactions between entities and relations. In contrast to GCN, GAT [30] introduces attention mechanisms to dynamically adjust node weights. Based on GAT, RGAT [2] utilizes self-attention to derive relation-related weights for relation features. It combines the inter-entity attention results from GAT to obtain the final outcome. DisenKGAT [35] assumes that entities consist of multiple independent factors and leverages attention mechanisms within each sub-representation space to aggregate neighbor information. HRAN [14] incorporates an entity-level encoder to generate neighborhood features for each relation type and a relation-level encoder to capture their relative importance. MRGAT [3] utilizes two matrices for each relation type, embedding the head and tail entities into the query and key vectors for attention calculation. However, these models often face challenges such as overfitting on sparse data and limited scalability when dealing with a large number of rapidly increasing relations.\nLanguage model-based models. Knowledge graph text has been successfully leveraged to pre-train embeddings in language model-based models. KG-BERT [37] is the first model to apply BERT [5], a pre-training language model widely used in various Natural Language Processing (NLP) tasks, to knowledge graph embedding. KG-BERT offers two variants for knowledge graph completion: KG-BERT (variant a) models triples using their textual descriptions, while KG-BERT (variant b) predicts relations using only the textual descriptions of the head and tail entities. On the other hand, LMKE [31] utilizes a language model to generate embeddings for both entities and relations in the knowledge graph. Both KG-BERT and LMKE can effectively use large amounts of text data to pre-train embeddings for knowledge graph entities and relations. However, it is essential to note that the reliance on text data limits the application scenarios of these models."}, {"title": "3 BACKGROUND", "content": "3.1 Knowledge graph\nKnowledge Graph. A knowledge graph (KG) can be denoted as G = (E, R, T), where & represents the set of entities, R represents the set of relations, TC E\u00d7R\u00d7 & represents the set of triplets.\nKnowledge Graph Embedding. A KG G can be embedded into a low-dimensional vector space. In other words, a knowledge graph embedding is defined as, KG& = {(h, r, t)|h, t \u2208 H, r \u2208 R}, where H and R represent the embedding sets of entities and relations which are ne x de and nr \u00d7 dr dimensions respectively. ne and ny represent the number of entities and relations respectively. de and dr represent the embedding dimensions of entities and relations respectively."}, {"title": "3.2 Attention mechanism", "content": "Self-Attention Mechanism. Transformer [29] introduces the self-attention mechanism, which has been widely adopted in various NLP tasks. Several language models, such as GPT [20] and BERT [5], are built upon the self-attention mechanism and have achieved state-of-the-art (SOTA) performance in semantic analysis, machine translation, and other NLP tasks. The self-attention mechanism is responsible for encoding an input sequence consisting of dh-dimensional vectors H = [h\u2081, ..., hN]T \u2208 RN\u00d7dh, and it can be formulated as follows,\nself_att(Q, K, V) = softmax(\\frac{OK^T}{\\sqrt{d_k}})V \\newline Q = HW_q, K = HW_k, V = HW_v\nwhere Wq, Wk \u2208 Rdh\u00d7dk, Wv \u2208 Rdh\u00d7do project the input sequence H to the query matrix Q, key matrix K and value matrix V respectively. Q and K are multiplied and divided by \u221adk, and the attention score can be obtained by performing softmax normalization. Finally, we can get the output of the self-attention function by multiplying the attention score and V.\nMulti-Head Attention. The self-attention mechanism is limited to capturing features within a single projection space of H, which makes it sensitive to initialization. To overcome this limitation and capture more diverse features, a multi-head attention mechanism is introduced, drawing inspiration from Convolutional Neural Networks (CNNs). The idea is to leverage multiple projection spaces to capture different aspects of the input. Specifically, if we aim to capture features from M projection spaces, the multi-head attention mechanism can be formulated as follows,\nMultihead(H) = [head1; ...; headm] Wo \\newline headm = self_att(Qm, Km, Vm) \\newline Qm = HW_q^m, Km = HW_k^m, Vm = HWM_v^m\nwhere Wo \u2208 RM*dhx dh' is the projection matrix used to convert the slices of multiple self-attention outputs to the original dimension. headm corresponds to the output sequence of the m-th self-attention function. W_q^m, Wm_k \u2208 Rdnx dk and Wm \u2208 Rdh\u00d7do respectively project H to the query matrix Qm, key matrix Km and value matrix Vm of the m-th attention head, while m \u20ac 1, ..., M"}, {"title": "4 METHOD", "content": "In this section, we will provide a detailed introduction to GATH. We first introduce the overall framework of GATH and then describe each module and its interconnections in detail. Finally, the loss function used in GATH is proposed."}, {"title": "4.1 Overall Framework", "content": "The architecture of GATH follows the Encoder-Decoder framework, as depicted in Fig. 3. The encoder is responsible for generating embeddings of entities by incorporating both the structural and neighborhood information from the KG. Specifically, the encoder consists of an attention module that calculates attention scores between the central entity and its neighbors, as well as an aggregation module that combines information from all neighboring entities into a single representation. To begin, the attention module computes attention scores via entity pair and relation type, respectively. Subsequently, the aggregation module utilizes these attention scores to aggregate relational and neighborhood information toward the central entity. Finally, the encoder feeds the generated entity embeddings into a decoder. The decoder can be any generic decoder (such as TransE or ConvE) for knowledge graph embedding models. In our case, we employ a decoder based on ConvE with certain enhancements to better capture diverse relational patterns in KGs. Next, we describe each component in detail."}, {"title": "4.2 Encoder", "content": "The encoder of GATH consists of two primary components: 1) the entity-specific attention network, and 2) the entity-relation joint attention network. These two parts calculate the attention scores of head and tail entities respectively from the entity feature space and the entity-relation joint feature space. They are described separately as follows.\n Entity-Specific Attention Network. To address the challenge of poor performance in predicting the tail (head) entities that share the same relation and head (tail) entities with others, we introduce an entity-specific attention network that is relation-agnostic. This module aims to capture the intrinsic interaction between a central entity and its neighbor entities, allowing GATH to assign different attention weights to neighbor entities based on their relevance to the central entity regardless of the specific relation involved. By doing so, GATH can efficiently handle the situation shown in Fig. 1(b)."}, {"title": "Attentions", "content": "We use H\u00ba as the initial entity embedding matrix, which is initialized by Gaussian distribution sampling. In l-th entity-specific attention network module, the input is H(1\u22121) \u2208 R\u2116\u00d7D-1), where Ne is the number of entities, I represents the number of layers of the encoder, D(1-1) represents the dimension of the input vector. We first project the head and tail embeddings into the query and key vectors respectively as follows,\nq_i^{(h)} = W_q^{(h)}h_i^{(l-1)} \\newline k_{j}^{(h)} = W_k^{(h)}h_j^{(l-1)}\nwhere h_i^{(l-1)} and h_j^{(l-1)} denote the embeddings of the i-th node vi and the j-th node vj of KG respectively and vj is in Ni, which is the set of neighbors of vi. W_q^{(h)} and W_k^{(h)} \u2208 RD^{(l-1)} xdk are relation-independent learnable projection matrices. dk is the dimension of the query vector and key vector.\nAfter obtaining the query and key vector, we use a shared attention mechanism when measuring the relation-independent entity importance as follows,\natt_{ij}^{(h)} = f(q_i^{(h)} \\odot k_j^{(h)})\nwhere \\odot means Hadamard product, f(.) represents a feed-forward network capable of capturing entity features with a parameter matrix of W \u2208 Rdk\u00d71, followed by a nonlinear function.\nFinally, softmax is used to make the importance smoother, i.e.,\n\\alpha_{ij}^{(h)} = softmax_j(att_{ij}^{(h)}) \\newline= \\frac{exp(att_{ij}^{(h)})}{\\sum_{v_k \\epsilon N_i}exp(att_{ik}^{(h)})}\nwhere a_{ij}^{(h)} represents the attention score of the central node vi to its neighbor vj when no additional relation information is considered.\n Entity-Relation Joint Attention Network. In heterogeneous KGs, entities and relations are embedded in different feature spaces, which poses a challenge to effectively capture the joint features of entities and relations. A general approach is to generate a query projection matrix WQ \u2208 RD\u00d7F and a key projection matrix WK \u2208 RD\u00d7F for each relation, project head, and tail entities as query and key vectors, respectively, and then obtain the attention score, where D represents the dimension of entity embedding and F represents the dimension of query vector and key vector. For a KG with n types of relations, the model needs 2 * n * D * F space to store relation features. Therefore, this calculation method requires too many parameters for handling numerous relations in large-scale KGs while risking overfitting on sparse relations. Moreover, it is difficult to extend this approach to handle KGs with many different relations due to its high space complexity. To simplify the parameters representing the relation, we use a D-dimensional embedding"}, {"title": "Joint features", "content": "vector to represent the relation. Furthermore, we make two shared attention projection matrices to map head (tail) entity embeddings transformed by relations to query (key) vectors.\nWe assume that each entity is represented by a combination of information in different scenarios. For example, as shown in Fig. 2, a person entity may be represented by a combination of information in various scenarios, such as occupation information and family information. Specifically, in the entity feature space, information in different dimensions corresponds to entity information in different scenarios. A relation is a concrete representation of a scene, so each relation focuses on information under the specific dimensions of the entity feature. We refer to entity features transformed by specific relations as entity-relation joint features. We will compute the attention score based on the entity-relation joint feature.\nIn practice, in the D-dimensional relation embedding that matches the entity embedding dimension, the value under each dimension indicates the degree of attention of the relation to the entity information under the corresponding dimension. In other words, a D-dimensional entity embedding can be represented as consisting of D subspaces of dimension 1. The relation-based entity feature transformation is that the relation enhances or weakens the characteristics of the entity information in each subspace. The following is a detailed demonstration of the calculation process.\nThe entity-relation joint attention network internally preserves relation features R(1) \u2208 RN,\u00d7D-1) and receives entity embeddings H(1\u22121), where N, represents the number of types of relations and D(1-1) denotes the dimensionality of each entity embedding. We then obtain the joint features of entities and relations through the following operations,\njoint_i^{(r)} = r_r^{(l)}h_i^{(l-1)}, joint_j^{(r)} = r_r^{(l)}h_j^{(l-1)}\nwhere r_r^{(l)} represents the embedding of the r-th relation, and (vi, rr, vj) is in Ni. joint_i^{(r)} represents the joint feature of the head entity and relation, and similarly, joint_j^{(r)} corresponds to the joint feature of the tail entity and relation.\nThe parameter matrices shared by all relations project the joint features to the query and key vectors. This process can make the information in each dimension of the joint features interact. The attention score will be calculated as follows,\nq_{i}^{(r)} = W_q^{(r)}joint_i^{(r)}, k_{j}^{(r)} = W_k^{(r)}joint_j^{(r)} \\newline att_{ij}^{(r)} = f(q_i^{(r)} \\odot k_j^{(r)}\nwhere W_q^{(r)}, W_k^{(r)} \u2208 RD^{(l-1)} xdk are learnable projection matrices shared by all relations. f(.) is a fully connected layer with an output dimension of 1.\nIn order to make the attention scores more comparable, a softmax operation will be performed,\n\\alpha_{ij}^{(r)} = softmax_j(att_{ij}^{(r)}) \\newline= \\frac{exp(att_{ij}^{(r)})}{\\sum_{(v_i, r_r, v_k) \\epsilon N_i}exp(att_{ik}^{(r)})}\nwhere a_{ij}^{(r)} represents the relation-specific head-to-tail attention score."}, {"title": "Aggregation", "content": "Aggregation. The aggregation module linearly combines the embeddings of the neighbors according to the attention scores calculated above, and then aggregates this information to generate a new embedding for the central node. For node vi, the formula for aggregating neighborhood information is as follows,\nh^{(l)}_{(h)i} = \\sum_{v_j \\epsilon N_i} \\alpha^{(h)}_{ij}h_j^{(l-1)} \\newline h^{(l)}_{(r)i} = \\sum_{(v_i,r_r,v_j) \\epsilon N_i} \\alpha^{(r)}_{ij}h_j^{(l-1)}"}, {"title": "Encoder & Coefficients", "content": "where W(1) \u2208 RD-1)xdo is a learnable transformation matrix that projects entity embedding to value vectors. de represents the dimension of the value vector. h(l)(h)i and h(l)(r)i denote the embeddings that aggregate the neighborhood from the entity-specific attention network module and the entity-relation joint attention network module, respectively.\nThe multi-head attention mechanism enables simultaneous focus on different feature spaces, allowing for the extraction of richer feature information. This has two main advantages. Firstly, it can accelerate model convergence by capturing diverse aspects of the input data. Secondly, it effectively mitigates the sensitivity of the attention mechanism to initialization, enhancing the stability and robustness of the model. Therefore, GATH adopts a multi-head attention mechanism instead of the single-head attention mechanism in order to learn different semantic features more effectively. Assuming there are M attention heads, we use the following formula to concatenate the output of M heads and project them into the entity feature space,\nh_i^{(l)} = CONCAT(h^{(l,1)}_{(h)i}, h^{(l,1)}_{(r)i},...,h^{(l,M)}_{(h)i},h^{(l,M)}_{(r)i})W^{(l)}\nwhere h^{(l),m}_{(h)i} and h^{(l),m}_{(r)i} denote the embeddings generated by the m-th entity-specific attention network module and entity-relation joint attention network module respectively. W (1) \u2208 R2MdxD transforms the multi-head attention output to the entity feature space. D) denotes the dimension of the output entity embedding of the aggregation module.\nUp to this point, the entities have gathered all the neighborhood information. It is worth noting that the information of the entities themselves is not propagated, which may lead to an over-smoothing of the graph, i.e., the entity embeddings tend to be the same. Inspired by ResNet[8], we introduce self-loops as residual connections and a learnable parameter \u03b2 for each entity to make information propagation more flexible. The updated formula for entity embedding propagation is as follows,\nh_i^{(l)} = \u03c3(W^{(l)}(h^{(l)} + \\beta h_i^{(l-1)}))\nwhere \u03c3(\u00b7) is a non-linear activation function. W(1) \u2208 RD-1)xD) is propagation matrix."}, {"title": "4.3 Decoder", "content": "GATH can adopt any knowledge graph embedding model's decoder, such as TransE or ConvE, etc. Our decoder is implemented based on ConvE, which uses 2D convolutions to model KGs and has better performance in predicting highly connected entities. In addition, inspired by semantic matching-based models, our decoder additionally introduces relation-based entity feature transformation to accurately evaluate the plausibility of triples.\nOur encoder generates entity embeddings H and feeds them into the decoder. The decoder defines the relation embedding matrix RER, initialized with Gaussian distribution sampling. The STACK operation, which will concatenate a sequence of vectors on the first dimension, is performed on the entity embeddings, relation embeddings, and their transformed features to obtain the input."}, {"title": "Predictions", "content": "Then, we feed this input into a convolutional neural network to make predictions as shown below,\ninput = STACK(h, r, hr) \\newline g(h, r, t) = \u03c3(vec((input * w))W)t\nwhere converts each Dh-dimensional vector into a matrix with dimensions dw and dh where Dh = dw \u00d7 dh.\nIn the feed-forward stage, firstly, each vector in the input is reshaped into a 2D matrix. They are then fed into a 2D convolutional layer with kernel w, which will produce a feature map tensor F \u2208 Rc\u00d7m\u00d7n. F contains c feature maps with dimensions m and n. Secondly, the vec() operation converts the feature map F into a vector v\u2081 \u2208 Remn. Then the vector v\u2081 is projected into the entity feature space by W \u2208 Rcmn\u00d7Dh. Thirdly, the nonlinear transformation will be performed to get v2 \u2208 RDh followed by computing the inner product of 02 and the tail entity embedding t as the score. Finally, the score is normalized to obtain predicted probabilities as shown,\np(h, r, t) = sigmoid(g(h, r, t))"}, {"title": "4.4 Loss function", "content": "If the input triple (h, r, t) is valid in KG, then we want the predicted probability p(h, r, t) to be 1. Otherwise, we want the predicted probability to be 0[3]. So the loss function is defined as follows,\nL(h,r,t) = -\\frac{1}{N} \\sum_{i=1}^{N} (y(h,r,t_i) \u00b7 log(p(h,r,t_i))+\n(1-y(h, r, t_i)) log(1 \u2013 p(h, r, t_i))) \\newline in which \\newline y(h, r, t_i) =\\begin{cases} 1 & \\text{if } (h, r, t_i) \\epsilon T \\\\0 & \\text{if } (h, r, t_i) \\notin T \\end{cases}\nwhere y(h, r, ti) indicates whether the triplet (h, r, ti) is a positive triplet, and its value is {0,1}. N represents the total number of tail nodes to be predicted. T represents the set of valid triples."}, {"title": "5 EXPERIMENT", "content": "5.1 Datasets\nMost of the knowledge graph embedding models and knowledge graph completion models [3, 7, 22, 27, 35, 37] are developed on the FB15K-237 and WN18RR datasets. Likewise, these two datasets will also be used to evaluate the performance of GATH. A short introduction to these two datasets is given below.\nFB15K-237. FB15K-237[25] is a dataset for link prediction with 14541 entities, 237 relations, and 310,116 triples. It is the subset of FB15K[1]. In FB15K, many triples are inverses that cause leakage from the training to testing and validation splits. And the inverse relations are removed in FB15K-237.\nWN18RR. WN18RR[4] is a subset of WN18[1]. The WN18 also suffers from test leakage, similar to FB15K. Therefore, WN18RR has revised WN18 and deletes the inverse relations. In all, WN18RR contains more than 40,000 entities, 11 relations, and more than 90,000 triples. Compared with FB15K-237, WN18RR has more entities, but the complex connections are reduced a lot."}, {"title": "5.2 Baselines", "content": "In order to demonstrate the superiority of GATH in knowledge graph completion, we mainly conduct comprehensive comparisons with the following 5 categories of knowledge graph embedding models: 1) translation-based models, 2) semantic matching-based"}, {"title": "Baselines & GATH", "content": "models, 3) GCN-based models, 4) GAT-based models and 5) decoder-only models. The calculation process related to the baselines is shown in Table 2.\n Translation-based models. Translation-based models use distance functions as scoring functions. We use TransE [1] and RotatE[24] as our baselines. This is because TransE is a pioneering work based on translation, while RotatE views relation as the rotation of entity in complex number space and significantly improves the performance of embedded models.\nSemantic matching-based models. Semantic matching-based models usually use similarity functions as scoring functions, such as DistMult [36] and Complex [26]. Similarly, DistMult and ComplEx measure the similarity of triples in real and complex number spaces, respectively. We choose DistMult because it can succinctly obtain high-quality entity embeddings, while ComplEx introduces complex entity embeddings making the model performance greatly improved.\nGCN-based models. GCN-based models use static relation attributes to aggregate neighbor information. Among them, we have chosen SACN [22] and NoGE [18] as baselines. SACN aggregates neighbor information by assigning static weights to relations, while NoGE aggregates neighbor information with the help of dual quaternion. Although SACN obtains the optimal result, NoGE introduces quaternion to improve the performance. Therefore, SACN and NoGE were chosen as the baselines.\nGAT-based models. GAT-based models combine graph neural networks and attention to dynamically aggregate neighbor information. We chose RGAT [2], DisenKGAT [35], and MRGAT [3] as baselines. RGAT extends the original GAT to take relation into account, while DisenKGAT assumes that entity information is composed of multiple sub-feature information and aggregates neighbor information in different subspaces. MRGAT transforms head and tail entities into attention components via relation-specific projection matrices. The reason we chose these three baselines is that RGAT expands the original GAT and considers the relations in KG, greatly improving the performance of the embedding models; DisenKGAT has a similar idea to ours, where entities are composed of features from multiple subspaces together; and MRGAT is currently the state-of-the-art model.\nDecoder-only models. Decoder-only models work on the initial embedding of entities, such as ConvE [4], Conv_TransE [22], InteractE [27], and CTKGC [7]. ConvE is similar to Conv_TransE. Specifically, ConvE reshapes the input while Conv_TransE does not perform additional processing on the input to maintain translation invariance. InteractE enhances the expressive power of models by increasing the possible interactions between embeddings. CTKGC relies on the fact that the multiplication of the head entity and relation is approximately equal to the tail entity. We choose these baselines for the following reasons. ConvE and InteractE respectively achieved their best performance at the time and were chosen as the baseline by us. ConvE was pioneering work in applying CNN as a decoder, while Conv_TransE is the decoder of SACN. As a decoder-only model, CTKGC has achieved excellent results in the current knowledge graph embedding models."}, {"title": "5.3 Experiment setup", "content": "The number of GATH's encoding layer is set to 2, and AdamW[16", "dropout[23": "and batch normalization [11"}]}