{"title": "BoostStep: Boosting mathematical capability of Large Language Models\nvia improved single-step reasoning", "authors": ["Beichen Zhang", "Yuhong Liu", "Xiaoyi Dong", "Yuhang Zang", "Pan Zhang", "Haodong Duan", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "abstract": "Cutting-edge large language models (LLMS)\ndemonstrate promising performance in solv-\ning complex math problems with a divide-\nand-conquer pipeline and the assistance of in-\ncontext learning (ICL) examples. However,\ntheir potential for improvement is limited by\ntwo critical problems within their ICL exam-\nples: granularity-mismatch and the ensuing\nnegative-effect noise problem. Specifically, the\nLLMs are capable of the dividing process yet\nmostly failed by inaccurate reasoning within\na few conquer steps, while the ICL examples\nretrieved in question-grained sometimes lack\nrelevant steps for a specific challenging reason-\ning step. Further, this disconnect may hinder\nthe correct reasoning due to its irrelevance. To\nthis end, we focus on improving the reason-\ning quality within each step and present Boost-\nStep. BoostStep aligns the granularity between\nthe retrieving and reasoning on step grained,\nand provides highly related ICL examples for\neach reasoning step with a novel 'first-try' strat-\negy. BoostStep provides more relevant exam-\nples than the coarse question-grained strategy,\nenhancing the model reasoning quality within\neach step steadily. BoostStep is a general\nand robust reasoning-enhancing method that\nnot only improves standalone reasoning per-\nformance but also integrates seamlessly with\nMonte Carlo Tree Search methods (MCTS) to\nrefine both candidate generation and decision-\nmaking. Quantitatively, it improves GPT-40\nand Qwen2.5-Math-72B by 3.6% and 2.0%\nrespectively on various mathematical bench-\nmarks, and 7.5% gain combined with MCTS.", "sections": [{"title": "1 Introduction", "content": "Mathematical reasoning is a crucial and challeng-\ning task in the development of artificial intelligence.\nIt serves as an indicator of a model's ability to\nperform complex reasoning and has a wide range\nof applications, such as problem solving, theorem\nproving and scientific discovery.\nWhen solving complex mathematical problems,\ntwo capabilities are necessary, which are divide\nand conquer. The former decomposes the complex\nproblem into several simpler steps to simplify the\ntask, while the latter guarantees the correctness of\nthe one-step reasoning.\nThrough the analysis of error cases, we found\nthat the current SOTA models have been relatively\nclear in the divide part, that is, the model can basi-\ncally know exactly what tasks should be completed\nin each step. However, there will still be a lot of\nmistakes in the conquer section, such as wrong for-\nmula use, wrong calculation, insufficient enumer-\nation, etc. To quantitatively substantiate this con-\nclusion, we provide GPT-40-mini with groundtruth\nreasoning process to determine whether the error"}, {"title": "2 Related Works", "content": "Mathematical Reasoning. Mathematical reason-ing has long been a highly challenging task in the\nfield of artificial intelligence. In the early days of\nartificial intelligence, constrained by a lack of gen-\neral capabilities, early methods primarily attempted to per-form simple mathematical reasoning through rule-based methods. With the advent of large language\nmodels with enhanced reasoning capabilities, con-temporary approaches typically focus on enhancing\nperformance during both the training and inference\nphases. The first category improves mathematical\ncapability by fine-tuning with more high-quality\nmathematical data. This strategy can fundamentally im-prove the base model's mathematical capabilities.\nHowever, it demands substantial high-quality math-ematical data and computational resources. Conse-quently, more efforts have been put in exploring var-ious techniques during inference to enhance mathe-matical reasoning performance. Some work involves prompt\nengineering to enable models to generate compre-hensive chains of thought. Other studies involve using self-refinement techniques to revise the\ninitial reasoning outputs.\nStepwise Mathematical Reasoning. Recently,\nto further enhance mathematical reasoning capa-bilities, many studies have shifted the granular-ity of mathematical reasoning from the problem\nlevel to the step level. This approach involves\naddressing each next step individually, complet-ing small segments of reasoning within the overall\ntask. These works often employ strategies such\nas Tree of Thoughts (ToT) or\nMonte Carlo Tree Search extending multiple steps to optimize step\nanswers and ultimately obtain the optimal solu-tion. Additionally, Process Supervision Models\n(PRMs) are frequently used to verify the correctness of new\ncandidate nodes in real-time and prune reasoning\npaths, thereby improving the accuracy of the fi-nal answer. This more detailed auxiliary strategy\ndemonstrates greater potential.\nIn-context Learning in Mathematical Reason-ing. In-context learning can provide low-cost guid-"}, {"title": "3 Step-Level In-Context Learning", "content": "3.1 Revisiting In-Context Learning from\nConditional Probability\nCurrent models often employ next-token predic-tion for training and inference, where the condi-tional probability is central to the model's gen-eration of the next token. Given a problem q,\na model's reasoning process can be represented\nby $r_{predict}$ = $arg \\max_{r} P_{model}(r | q)$, where we\ntrain the model to get a better conditional proba-bility $P_{model}$ so that $r_{predict}$ can be closer to the\ngroundtruth answer $r_{gt}$ = $arg \\max_{r} P_{gt}(r | q)$.\nIn-context learning provides the model with con-ditional probabilities similar to the groundtruth an-swer for imitation without changing the probability\nmodel $P_{model}$. Specifically, an example problem\nq' and its corresponding correct solution r' is pro-vided and it can be posited that the conditional prob-ability P(r' | q') is similar to the probability of the\ngrountruth answer of the target problem P($r_{gt}$ | q).\nConsequently, the model will imitate this simi-lar example and $r$ = $arg \\max_{r} P_{model}(r |$\nq, q', r') will be closer to $r_{gt}$ comparing to $r_{predict}$.\nHowever, given that the actual reasoning pro-\ncess r can be highly complex, the complete rea-soning process is often divided into multiple steps\n$s_1$, $s_2$,...Step-level reasoning iteratively guides\nthe model to generate the next step $s_{i+1}$ =\n$arg \\max_{s} P_{model} (s | q, s_1, s_2, ..., s_i)$.\nAt the step granularity, examples retrieved based\non the problem q are evidently insufficient for"}, {"title": "3.2 Step-Level Example Problem Bank", "content": "Due to the need for further improvement in mathe-matical capabilities, currently open-source mathe-matical data no longer consist solely of problems\nand their final answers to determine whether the fi-"}, {"title": "3.3 Step-Level ICL with First-try Strategy", "content": "The core challenge of in-context learning lies in\nhow to effectively retrieve relevant problems or\nsteps for effective guidance. This is contingent\nupon both the similarity between the problem\ndatabase and the target problem, as well as the\nspecific retrieval strategy employed. Traditional\nproblem-level in-context learning involves retriev-\ning similar problems based solely on the problem\nstatement. This approach is relatively straightfor-"}, {"title": "3.4 Step-Level Example Guidance in MCTS", "content": "The core aspect of our method is that our step-level in-context learning can significantly enhance"}, {"title": "4 Experiments", "content": "4.1 Experiment setting\nReasoning Model. Our primary reasoning model\nis GPT-40. To demonstrate the\ngenerality of our approach, we also conducted tests\non Qwen2.5-Math-72B-Instruct"}, {"title": "4.2 Comparing to Problem-Level ICL", "content": "We conduct a rigorous comparison of the proposed\nstep-level in-context learning approach and tradi-tional problem-level few-shot learning across mul-tiple benchmarks and base models. Specifically, for\ntraditional problem-level few-shot learning, we set\nthe shot num to 4, which is a common setting for\nevaluation. The results are presented in Tab. 1. Our\nstep-level In Context-Learning achieves improve-ments across various mathematical benchmarks,\nwith particularly notable enhancements observed\non the relatively more challenging AMC problems.\nSinece the sensitivity to example problem banks"}, {"title": "4.3 Construction of Example Problem Bank", "content": "To better align with the steps in reasoning, we pro-pose constructing a step-level question bank based\non the reasoning content rather than grammatical\ndivisions. To prove our assumption, we compare\nour approach with a commonly used strategy that\nconstructs steps based on grammatical segmenta-\ntion, using periods '.' as the delimiter, on the same\ndataset PRM800K and under identical conditions.\nResults are presented in tab. 4. Our method largely\noutperforms those using periods as delimiter."}, {"title": "4.4 Comparison of Retrieving Strategies", "content": "The key factor in determining the effectiveness of\nin-context learning lies in the relevance of the re-trieved examples. At the finer-grained step level,"}, {"title": "4.5 Example-guided Monte Carlo Tree Search", "content": "As discussed above, the reasoning capability of gen-erating model and the verifying capability of critic\nmodel are two core factors of Monte Carlo Tree\nSearch methods, and our strategy can enhance the\nreasoning quality of MCTS in both ways. On one\nhand, it can improve the accuracy of generating\ncandidate nodes using the previously mentioned\nfirst-try strategy when reasoning nodes are gener-"}, {"title": "4.6 Case Study", "content": "Here we demonstrate a specific example of how our\nstep-level in-context learning boosts step-level rea-soning. Given the question, we first let the model\nto have a first-try on step one. Unfortunately, be-cause the model is unfamiliar with trigonometric\nfunctions, it makes an error on tangent sum for-"}, {"title": "5 Conclusion", "content": "We propose step-level in-context learning, which\nprovides real-time, fine-grained guidance during\nthe reasoning process by searching for similar steps\naccording to the first-try reasoning attempt. This\napproach improves the model's reasoning capabili-ties and reduces the dependency on the similarity\nof example problem set, thereby increasing the gen-eralizability of in-context learning. Moreover, our\nmethod can also enhance the reasoning and evalua-tion capability of Monte Carlo Tree Search (MCTS)\nby introducing similar steps in reasoning and ver-ifying phases respectively, thereby improving the\noverall reasoning correctness.\nPotential Limitations. Currently, our example\nproblem bank is entirely sourced from PRM800k"}]}