{"title": "Leveraging Large Language Models for enhanced personalised user experience in Smart Homes", "authors": ["Jordan Rey-Jouanchicot", "Andr\u00e9 Bottaro", "Eric Campo", "Jean-L\u00e9on Bouraoui", "Nadine Vigouroux", "Fr\u00e9d\u00e9ric Vella"], "abstract": "Smart home automation systems aim to improve\nthe comfort and convenience of users in their liv-\ning environment. However, adapting automation\nto user needs remains a challenge. Indeed, many\nsystems still rely on hand-crafted routines for each\nsmart object.\nThis paper presents an original smart home archi-\ntecture leveraging Large Language Models (LLMs)\nand user preferences to push the boundaries of per-\nsonalisation and intuitiveness in the home environ-\nment. This article explores a human-centred ap-\nproach that uses the general knowledge provided\nby LLMs to learn and facilitate interactions with\nthe environment.\nThe advantages of the proposed model are demon-\nstrated on a set of scenarios, as well as a compar-\native analysis with various LLM implementations.\nSome metrics are assessed to determine the sys-\ntem's ability to maintain comfort, safety, and user\npreferences. The paper details the approach to real-\nworld implementation and evaluation.\nThe proposed approach of using preferences shows\nup to 52.3% increase in average grade, and with\nan average processing time reduced by 35.6% on\nStarling 7B Alpha LLM. In addition, performance\nis 26.4% better than the results of the larger models\nwithout preferences, with processing time almost\n20 times faster.", "sections": [{"title": "1 Introduction", "content": "Networks of devices are deployed to assist human beings in\ntheir daily activities, using notions of context and knowl-\nedge to decide on the best actions to take [Weiser, 1991]\n[Dey, 2001]. Indeed, many houses are covered by wireless\nand wired networks and equipped with electronic devices al-\nlowing the occupants to control their environment for com-\nfort, entertainment, security, energy management, and elderly\ncare.\nHowever, Smart Home Automation Systems are still miss-\ning the aim of autonomously taking the best action in every\nsituation. Aligning automation routines to meet every need\nfor every home configuration, every set of devices, available\nor not, functional or not, remains a challenge. In fact, most\nsystems today are configured for simple routines that occur\nfrequently. For instance, setting the home for wake-up or de-\nparture time by playing music, ringing a bell, acting on lights,\nshutters, heating, ventilation, and air conditioning. More pre-\ncise needs in less frequent situations are not covered. Further-\nmore, if some devices are missing from a routine, no decision\nis made to use alternative devices. While artificial intelli-\ngence can play a role in learning about situations and the asso-\nciated actions taken by users [Rashidi and Cook, 2009], it still\nrequires time to understand users' habits, and is never able to\ncover the wide range of situations encountered at home.\nOne of the main technical challenges of pervasive comput-\ning is the ability to set up a system knowing the wide variety\nof users' potential needs, and how it can adapt to the wide\nrange of functions of existing devices, with devices and lo-\ncations whose configuration can be very different. As their\nexecution environment is particularly dynamic, applications\nneed to be aware of their context and act appropriately.\nLarge language models [Radford et al., 2019] have the po-\ntential to give this general knowledge at once to applications\nsuch as smart home. In essence, these models have acquired\na vast amount of knowledge. They are trained on a diverse\nrange of textual sources, enabling them to cover a variety of\ntopics, facts, and concepts, here the expected actions of home\ndevices to meet user needs in a wide range of situations.\nRetrieval-Augmented Generation [Lewis et al., 2020] is\na technique that improves the accuracy of LLMs by giving\nthem access to more targeted and precise information. This\nis achieved by using a retrieval component that searches a\nspecific database and introduces it into the model, along with\nusers' query.\nThis paper proposes a software architecture integrating the\ngeneral LLM knowledge available today into a smart home\nautomation system. The LLM is placed at the center of the\nhome's decision-making system and participates in the re-\naction to every event to deduce the next best actions. This\npaper investigates the inclusion of preferences with a LLM\nfor smart home automation, The contribution also includes\na user-centred representation of smart home states and ac-\ntions in natural language. Finally, experiments are carried\nout using several LLMs with different prompting styles for\ndecision-making in the smart home."}, {"title": "2 Related works", "content": "This topic is recent and few papers have been published on\nLLMs for smart homes. The following papers are selected\nfor their approaches using the knowledge of user preferences\non decision-making in smart home automation systems. This\nsection cannot be exhaustive in this larger domain.\n[Oliveira et al., 2022] proposes a multi-agent environment\nwith a Belief-Desire-Intention cognitive model, to support\nadaptivity and preferences transparently in a smart home en-\nvironment. Any possible interaction could be modeled in\nsuch a way as to allow alternative proposals, but this requires\nconsiderable work in semantic representation to be fully com-\nplete.\nAnother paper takes advantage of general knowledge in-\nformation to improve system adaptivity to preferences. [Ruiz\net al., 2021] proposes an approach using three Knowledge-\nBased systems, one with general knowledge, one with skill\nknowledge, and one with contextual information such as de-\nvice location, and generating rule models for a middleware\nplatform based on all this information.\nThis approach requires really strict semantic modeling to\nhandle most scenarios, and cannot take advantage of some\ninformation that is implicitly given in context.\n[Shuvo, 2022] proposes an actor-to-critic (A2C)-based al-\ngorithm adapted to decision-making in smart homes for en-\nergy consumption. In this work, at each step, an A2C algo-\nrithm is applied to each device to select the best action, using\nas inputs the activity and price of electricity at that time.\nA key element is that the set of actions for each appliance\ndepends on the category associated with the appliance, adding\ninitial knowledge to the model to ensure action based on the\nimportance of the appliance. This system requires learning,\nand any change in device availability leading to different op-\ntimal decisions will require a large number of steps before\nadapting.\nIn addition, the larger the context, the more difficult it will\nbe to converge for each scenario to learn the best-suited de-\nvice state. The paper HESIDR, [Zhang et al., 2023] also pro-\nposes a system for energy consumption in smart homes, it\ncombines a set of control rules and reinforcement learning to\nreduce the adaptation time.\nThe study proposed by [Peng et al., 2020] describes an ap-\nproach for decision-making in home automation using deep\nreinforcement learning. It showed the ability to learn when to\nturn on a light but with a really limited context supported, so\nthe application is limited to learning when to turn on a light\nwith schedules of 15 minutes, which is a quite large period\nfor this application.\n[King et al., 2023a; King et al., 2023b] proposes the first\napproach to smart home automation, using a JSON data rep-\nresentation from a smart home middleware platform and ex-\nperimenting with an LLM to select an action based on a user\nrequest.\nThis approach is a first step towards the use of the gen-\neral knowledge provided by these models. However, it does\nnot support user preferences, and the idea is to select actions\nbased on an initial user request, rather than proactively. These\nworks have proposed ways of managing decision-making, but\nare limited by the contextual data supported. Works using\nsymbolic AI methods can show great adaptability, but at the\ncost of extensive semantic modeling and with requirements to\nmake them adaptable to future changes in preferences. A new\nmethod is proposed to support contextual data while adding\npreferences."}, {"title": "3 Proposed architecture", "content": "This study proposes a new architecture for decision-making\nin smart home automation systems. The system uses Large\nLanguage Models and proposes methods to add user prefer-\nences, in order to select an action according to context and\nusers. It aims to be a proactive system. At every event oc-\ncurring in the home, the system proposes actions on devices\nto align the home state with user needs and preferences. The\nsystem supports different types of data thanks to LLMs abil-\nity to process data while generating a textual representation\nof the home based on device states and the action list.\nThe proposed system aims to be able to adapt to changes in\nuser preferences over time. Indeed, LLMs avoid the need for\nretraining and handle appliance configuration changes, basic\nunavailability, or appliance failure.\nThis reason leads directly to the use of RAG or directly\ninjecting the knowledge into the prompts for retrieving up-\ndated preferences at every execution time of the AI, instead\nof fine-tuning. Indeed, fine-tuning over preferences would be\nimpractical, as it would require a new iteration each time user\npreferences change, which would be costly and computation-\nally expensive.\nA home simulator is implemented, it takes information on\nthe configurations of sensors and then generates a textual rep-\nresentation, it is also used to generate the list of actions from\nits data.\nThis section details the main components designed for the\nproposed system architecture. Figure 1 shows this architec-\nture, including the simulator."}, {"title": "Algorithm 1 Dynamic Devices: Action builder Algorithm", "content": "home and a list of actions, with control over connected de-\nvices. It filters the number of relevant actions that can be\ntaken in every situation. For example, it limits some actions\nthat may be prohibited to guarantee user safety. This list of\nactions is used by the model to select the optimal action.\nConcerning contextual data representation editing:\n\u2022 User positions are listed with their current activity and\nthe history of previous activities.\n\u2022 The history of previous actions performed in the house\nis supported.\n\u2022 All rooms, sensors, and actuators are presented using\ntheir names, which the user optionally gives.\n\u2022 Some sensors and actuators give more global data and\ncontrol, e.g., internal and external temperature sensors,\ngas sensors, humidity sensors, HVAC systems, etc.\nThe implementation supports some device categories with\na dedicated natural representation, to generate more natural\nsentences adapted to some types of data: lights, CO2 sen-\nsors, smart curtains, etc. It could also support any additional\ndata sensors with a generic representation template, using the\ndevice name in the smart home environment and data status.\nUsing meaningful naming added by the users helps the sys-\ntem to understand the usage of the device.\nThe action proposal algorithm 1 considerably reduces the\nset of possible actions. It assumes that only devices that are in\nthe room or global can be switched on, but that all switched-\non devices can be switched off. As far as the list of possible\nactions is concerned, the idea is to filter the actions supported\naccording to some conditions and device types. This ap-\nproach is made possible by LLM's native support for a change\nin the output action space, without requiring training.\nAlgorithm 1 Dynamic Devices: Action builder Algorithm\nRequire: userid, devices_list\n1: for all device_name, device_kind, device location,\ndevice_state in devices_list do\n2: if device_kind=\"actuator\" then\n3: if user_location[userid] = device_location or\ndevice_state = 1 then\n4: devices.append(device_name is device_state)\n5: action_vector.append(1)\n6: end if\n7: end if\n8: end for\n9: devices.append(\"Interact with user\")\n10: action_vector.append(2)\n11: devices.append(\"No action required\")\n12: action_vector.append(0)\n13: return (action_vector, devices)\nAny type of device can be easily supported: it simply has\nto be added to the representation and the LLM will ingest\nthe data thanks to its internal knowledge. This knowledge al-\nlows the LLM to get a natural human description of the home\nincluding biased contextual data unlike many conventional\nhome automation systems. The latter do not take advantages\nof information such as the names of lights or rooms. This data\nis transmitted to the LLM using one of the prompting styles,\nprompting being the way to call the LLM with contextual ar-\nguments. The different styles of prompts will be described in\nthe following section.\nA common aim for all the prompting styles is to take ad-\nvantage of the knowledge of the overall world provided by\nthis Large Language model, to handle changes or even new\ntypes of sensors added to the representation.\nThe user preferences and rules block represents a database\ncontaining information about the system's basic rules, gener-\nalities about human preferences and specific user preferences.\nA benchmark is established with predefined scenarios for\nevaluation purposes.\nRegarding LLMs, some off-the-shelf models are selected,\nwith a local inference engine backend."}, {"title": "4 Experimentation", "content": "Different objectives are defined for the experimentations.\n\u2022 Evaluate the improvements provided by adding user\npreferences, with various techniques of doing so.\n\u2022 Evaluate the improvements of natural language repre-\nsentation of a smart home automation state over a JSON\nrepresentation, as LLMs are trained on natural language\ncorpus. Even if they contain other kinds of data like\ncode.\nIn alignment with the objectives of experimentations, dif-\nferent metrics are used for these evaluations:\n\u2022 Grades: The grade obtained for each model, the prompt-\ning styles for each scenario, by execution., based on the\ngrade values defined in table 1\n\u2022 Processing time: Total runtime, including the construc-\ntion of the context data and action list representation, the\ninferences with the prompting styles, the use of RAG if\nthe prompting style uses it, and the processing of the for-\nmatted LLM response.\nEleven evaluation scenarios are defined as starting points,\nwith predefined accepted actions and their specific grade. Ta-\nble 1 presents the eleven scenarios by name and the associated\nreward values. A category is associated with each scenario,\nthe goal being to regroup the scenario with the name of the\nmain evaluated ability.\nThe database of preferences and rules is defined in a single\nfile for all scenarios. These data are naturally written sen-\ntences, and at the end of each one, information about the\nstyle is recorded: Rules, Preferences, Generality. The idea is\nto transmit to the LLM the importance of each data through\nkeywords. Generality is considered the least important, Pref-\nerences the second most important, and Rules the most im-\nportant. The database includes some preferences, generality\nand some rules. It is designed to handle some scenarios, help\nin some others but does not provide a solution for all scenar-\nios. The data are fed into a vector database so that RAG may\nbe used instead of prompts to convey them to the LLM."}, {"title": "5 Results", "content": "all prompting styles in addition to a \"reasoning\" and an \"ac-\ntion\" key, three optional keys are available: temperature, lu-\nminosity and explanation. It enables the model to respectively\nmodify the temperature of an HVAC system when executing\na related action, modify the luminosity by dimming a light or\ngive an explanation to transmit a sentence to the user.\nTwo ways of representing the state of the house data are\nimplemented, both using the same input data:\n\u2022 JSON: A JSON representation\n\u2022 Textual: A fully natural textual representation\nThe implementation of the system is evaluated using vari-\nous open-sources LLMs, including:\n\u2022 Starling Alpha 7B [Zhu et al., 2023]- 8bpw\n\u2022 Qwen 1.5 14B [Bai et al., 2023] - 5bpw\n\u2022 Qwen 1.5 72B [Bai et al., 2023] - 3.5bpw\nThe three models are selected for their performance and for\ncovering the three main open-source model sizes. They are\nused to evaluate the impact of proposed prompting methods\nand data representation.\nQwen 1.5 72B, with around 72 billion parameters, is\ncurrently one of the best models available open-source.\nStarling 7B Alpha, with around 7 billion parameters, is\nan excellent smaller model, and is based on Mistral 7B an\nefficient model for its size on various benchmarks. Qwen 1.5\n14B model, a smaller version of Qwen 1.5 72B, is selected to\nadd an intermediary model.\nAll these models are used with versions that are quan-\ntized, a technique used to reduce inference time and memory\nfootprint, the quantization chosen for each model is given in\nbits per weight (bpw). With their quantization, they require\naround 8GB, 12GB, and 44GB of memory respectively.\nEvery model is evaluated on local instances, served locally\nwith an engine-based API backend, using TabbyAPI based\non ExLLamaV2 multiple GPUs and without automatic split-\nting, using a workstation equipped with a Ryzen 9 7950x,\n96GB of DDR5 memory running at 5600mhz and 2 Nvidia\nRTX 4090, each with 24 GB dedicated memory, running\nUbuntu 23.10.\nExperiments are carried out beforehand on various uncon-\ntrolled scenarios to define LLM parameters. With the sole\naim of reducing non-determinism from one cycle to the next,\nthe final parameters modified from the default engine param-\n\u2022 max_tokens, maximum number of tokens in output: 300\n\u2022 min_p, minimum percentage value that a token must\nreach to be considered (Value is scaled based maximum\ntoken probability): 0.05\n\u2022 temperature, parameter that regulates the randomness:\n0.2\nThe RAG is implemented using Langchain[Topsakal and\nAkinci, 2023] with an inference engine from HuggingFace"}, {"title": "5.1 Data representation", "content": "The first analysis of the results focuses on the advantage of\nusing a natural representation versus a JSON representation.\nTable 2 shows an average difference between results us-\ning JSON representation, or the more natural representation.\nIt shows that the larger models are almost stable indepen-\ndently of the contextual representations, and on average even\nslightly better using JSON representation, by around 5.9%.\nHowever, on smaller models, the natural language representa-\ntion greatly improves performances, with a 14.6% increase in\naverage performance using Starling 7B, and a 57.1% increase\nusing Qwen 1.5 14B. In terms of processing time, results are\nquite similar on average for models with both representations.\nOn average, accross all models, it leads to an increase in per-\nformance of 21.9%, despite the results on the larger Qwen\nmodel, making the natural representation more efficient."}, {"title": "5.2 User preferences", "content": "Figure 3 depicts the average grades obtained by the 3 chosen\nmodels on their responses to scenarios with the 4 different\nprompting styles and the 2 distinct representation types.\nIt first shows that Qwen 72B model is much more sta-\nble than the other two and that the prompting style does not\nhave as much impact on response quality. Regarding the two\nsmaller models, larger inconsistency in results can be noted\nas varying with the chosen prompting styles, particularly with\nQwen 14B model.\nThe results of LLMs are compared with a baseline cor-\nresponding to the random choice of an action. The results\nremain on average behind any model without preferences\n(37.1% below the worst result with the \"direct\" prompting\nstyle). However, thanks to the algorithm reducing the set of\nactions and the fact that multiple responses are acceptable on\neach scenario, the random baseline obtains grades that are\nsometimes better than the ones of some experiments with\nLLMs.\nThe sequence of multiple questions requires the model to\nbe consistent and to respect the expected instruction format.\nFurthermore, given that only prompt engineering is used to\nensure the format, some prompting styles with multiple ques-\ntions may lead to invalid responses, forcing the model to take\na default action in the proposed setting. This default action is\nset to do nothing and to inform the user that it has failed to\nact. This reduces the performance of some models with some\nprompting styles. in figure 3 failure ratio measures the ratio\nof invalid responses. Qwen 14B results are especially below\nthis baseline because they failed to answer in a large number\nof scenarios"}, {"title": "6 Discussion", "content": "This section mainly discusses the results of the LLMs and\nprompting techniques chosen in order to make choices\nfor real experiments. The advantages of this study are\nhighlighted as well as the new challenges that are raised.\nAs seen previously", "directPref\" takes advantage\nof natural representation and achieves almost similar perfor-\nmances with much more complex prompting techniques. This\nmakes the approach of using Starling 7B Alpha with this\nprompting style a good choice for future work. It gives simi-\nlar performances concerning grades, and has a relatively low\ninference time (Average: 0.47s).\nIn addition, compared to Qwen 1.5 72B with natural\nrepresentation and no preferences, Starling 7B Alpha's\nperformance is 26.4% better using \"directPref\", with a\nprocessing time almost 20 times faster.\nThe results show the advantage of adhering to preferences.\nDrawbacks appear, however, with the additional average\ncomputation time for \"OpenQuestion\" and \"ThreeQuestion\"\n    },\n    {\n      ": "itle", "7 Conclusion": "content\": \"This paper presents a new architecture for a smart home au-\ntomation system, using LLMs with user preferences to en-\nhance personalised user experiences. This approach leverages\nthe general knowledge provided by LLMs and combines it\nwith naturally written rules and preferences to make contex-\ntually relevant decisions in line with user preferences. This\narchitecture is proactive, able to adapt to any change in the\nenvironment thanks to the robustness provided by LLMs.\nThe user-centred action list builder takes advantage of this\nability to reduce the set of actions at each step, as the repre-\nsentation of the environment also takes advantage of the name\ngiven to devices by the user to better support them.\nThe experimental results demonstrate the potential of this\narchitecture to improve alignment with user preferences\ncompared with an implementation without user preferences,\nshowing up to 52.2% performance increase.\nThe study showed that, particularly with small models, us-\ning a natural representation instead of a JSON representation\nleads to an increase in performance, with an average 21.9%\nincrease.\nAlthough the system shows promising results on a set of\ndefined scenarios, it also presents challenges due to stochastic\nbehaviour and a slower inference time compared to traditional\nmachine learning methods. These drawbacks are offset by the\nsystem's ability to adapt dynamically - without retraining - to\nchanges in preferences, appliances and home configuration.\nFuture work will focus on implementing the system\nin a real-world smart home middleware system such as\nOpenHAB[Portal\u00e9s et al., 2019] to evaluate its performance\nwith real users. Mechanisms will be proposed to allow users\nto naturally add and remove preferences, as well as to explore\nthe automatic evolution of these rules and preferences."}]}