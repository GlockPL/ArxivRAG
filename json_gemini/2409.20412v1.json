{"title": "CONFORMAL PREDICTION FOR DOSE-RESPONSE MODELS WITH CONTINUOUS TREATMENTS", "authors": ["Jarne Verhaeghe", "Jef Jonkers", "Sofie Van Hoecke"], "abstract": "Understanding the dose-response relation between a continuous treatment and the outcome for an individual can greatly drive decision-making, particularly in areas like personalized drug dosing and personalized healthcare interventions. Point estimates are often insufficient in these high-risk environments, highlighting the need for uncertainty quantification to support informed decisions. Conformal prediction, a distribution-free and model-agnostic method for uncertainty quantification, has seen limited application in continuous treatments or dose-response models. To address this gap, we propose a novel methodology that frames the causal dose-response problem as a covariate shift, leveraging weighted conformal prediction. By incorporating propensity estimation, conformal predictive systems, and likelihood ratios, we present a practical solution for generating prediction intervals for dose-response models. Additionally, our method approximates local coverage for every treatment value by applying kernel functions as weights in weighted conformal prediction. Finally, we use a new synthetic benchmark dataset to demonstrate the significance of covariate shift assumptions in achieving robust prediction intervals for dose-response models.", "sections": [{"title": "1 INTRODUCTION", "content": "How can we determine the optimal dose for a patient to ensure the best therapeutic outcome? What is the impact of discounts in an online store on sales? What impact does CO2 concentration have on local climates? At the core of each of these questions lies a shared causal idea: understanding the dose-response relation under continuous treatments to inform decision-making. In many cases, these decisions bear significant consequences, where relying solely on point estimates may be insufficient (Feuerriegel et al., 2024). Particularly in high-stakes situations, augmenting predictions with uncertainty quantification (UQ) can significantly improve decision-making processes (Feuerriegel et al., 2024). For instance, while the estimated causal effect of a continuous treatment may appear positive, prediction intervals could suggest a largely negative outcome for a specific individual. Such insights are crucial for deciding interventions. To tackle this, conformal prediction (CP) offers a robust solution for UQ, being both distribution-free and model-agnostic, with formal coverage guarantees (Vovk et al., 2022).\nIn this work, we seek to extend CP to UQ in dose-response models, aiming to aid decision-makers with more informed estimates to tackle such questions. We introduce a novel approach for deriving prediction intervals in the continuous treatment setting using weighted conformal prediction by combining propensity estimation with weighted conformal predictive systems. Furthermore, with the aid of a novel synthetic benchmark, we show how viewing the problem as a covariate shift approach provides coverage across all treatment values to help create more individualized dose-response curves."}, {"title": "2 BACKGROUND", "content": "In this paper we expand upon the potential outcomes framework introduced in Rubin (2005), otherwise known as the Rubin framework to accommodate continuous treatments. Consider a continuous treatment variable $T \\in [t_l,t_u]$ with a lower bound $t_l$ and upper bound $t_u$, observed covariates X, and potential outcomes $Y(t) \\in \\mathbb{R}$ representing the outcome that would be observed under treatment level t. The Conditional Average Dose-Response Function (CADRF) is defined as $v(x, t) = E[Y(t)|X = x]$, the expected value over the Individual Dose-Response Functions (IDRF) for all individuals with observed X. Similar to Conditional Average Treatment Effects (CATE), to estimate the CADRF we make the following standard assumptions (Rubin, 2005; Hirano & Imbens, 2004):\n\u2022 Unconfoundedness: $Y(t) \\perp T|X, \\forall t \\in T$. This assumption states that, conditional on the observed covariates, the treatment assignment is independent of the potential outcomes. In other words, there are no unobserved confounders that influence both the treatment assignment and the outcome.\n\u2022 Overlap or positivity: $0 < P(T = t|X = x) < 1, \\forall t \\in T$ with $x \\in \\mathcal{X}$. The overlap assumption ensures that for every covariate value x, there is a positive probability of receiving any treatment level. This is crucial for estimating treatment effects across the entire range of treatment levels.\n\u2022 Consistency: $Y = Y(t)$ with probability 1. This assumption links the observed outcomes to the potential outcomes, stating that the observed outcome is equal to the potential outcome corresponding to the treatment received.\nQuantifying the IDRF requires observing the Y(t) for all possible treatment values. These treatment values are all counterfactuals and thus impossible to observe as we only can observe Y for a single treatment value t at a time. Furthermore for estimating the CADRF, likewise with CATE estimation, the distribution of the treatment assignment can bias the estimation (Hirano & Imbens, 2004). This distribution of the treatment assignment is called the propensity distribution, which was initially defined for binary treatments. Hirano & Imbens (2004) introduced the generalized propensity score (GPS) for continuous treatments that aims to unbias the CATE estimation for continuous treatments. The GPS is defined as $\\pi(t_i|x) = f_{T|X}(T = t_i|X = x)$, which is the evaluation of $T = t_i$ on the conditional probability density function $f_{T|X}$ (Hirano & Imbens, 2004). If the treatment is independent of X, i.e. there are no confounders that influence treatment assignment, then $f_{T|X}$ is equal for all possible X. Furthermore, the treatment assignment is considered uniformly assigned between lower $t_l$ and upper $t_u$ possible treatment if $f_{T|X}$ represents the density function of the uniform distribution between $t_l$ and $t_u$. The GPS can then be used to mimic the randomly assigned treatment to estimate the unbiased CADRF (Wu et al., 2024).\nThe simplest method to estimate the CADRF is using an S-learner where a single learner is fit on both the covariates X and the treatment T to estimate Y. This approach provides a CADRF for each specific sample by keeping the covariates X constant and changing T to all different treatment values. However, if the treatment in the data is not uniformly assigned then the epistemic error can increase for specific treatment values $t_i$ and X = x in low overlap regions or where $\\pi(t_i|x)$ becomes very small. Consequently inferring T = $t_i$ in these regions would yield unreliable model estimates which should be communicated to ensure correct usage of a CADRF model.\nThe estimated IDRF can also be seen as follows: $IDRF = v(x,t)+\\epsilon_{a,IDRF}(x,t)+\\epsilon_{e,IDRF}(x,t)$. The aleatoric uncertainty is symbolized by $\\epsilon_{a, IDRF}(x, t)$ created by the inherent variability between individuals having the same covariates. $\\epsilon_{e,IDRF}(x, t)$ symbolises the epistemic uncertainty coming from model specification and finite samples. Estimating both uncertainties creates the opportunity to estimate the ranges of the IDRF:\nProblem Definition To accurately estimate the IDRF for all possible treatment values we require correctly estimating both uncertainties for all treatment values equally, or more formally; for a specific significance level $\\alpha$, lower treatment bound $t_l$, upper treatment bound $t_u$, and covariates X, we require prediction intervals $C(t, X)$ such that\n$P(Y(t) \\in C(X, t)) \\geq 1-\\alpha, \\forall t \\in [t_L, t_u]$        (1)\nThis requirement necessitates prediction intervals that guarantee coverage for each possible treatment value individually."}, {"title": "3 RELATED WORK", "content": "Our proposed solution combines three different domains: propensity score methods, conformal prediction, and treatment effect or dose-response modelling.\nPropensity score methods, introduced by Rosenbaum & Rubin (1983), have become widespread in causal inference, especially in observational studies. These methods aim to balance confounders across treatment groups, reducing bias in treatment effect estimates. Hirano & Imbens (2004) generalized this propensity score to continuous instead of binary treatments, introducing the generalized propensity score and building the foundation for causal inference with continuous exposures. Wu et al. (2024) used the generalized propensity score for matching continuous treatments to debias the treatment assignment and more accurately estimate the average dose-response curve for all treatment values. Other approaches adapt machine learning techniques to dose-response modelling. For instance, Athey et al. (2019) developed generalized random forests for heterogeneous treatment effect estimation, adaptable to continuous treatments.\nTo provide UQ, this work adapts conformal prediction. Conformal prediction is a model-agnostic method introduced by Vovk et al. (2022) that constructs prediction intervals with guaranteed finite-sample coverage under distribution-free assumptions. Conformal prediction uses conformity scores to assess uncertainty. Various improvements, such as the adaptive version by Romano et al. (2019), have increased the flexibility and applicability to even heteroscedastic settings. Additionally, Lei et al. (2018) and Papadopoulos et al. (2002) introduced split conformal prediction, significantly improving computational efficiency. For scenarios involving covariate or distribution shifts, Tibshirani et al. (2019) introduced weighted conformal prediction to ensure coverage under mismatched training and testing data distributions, with additional work by Gibbs & Candes (2021; 2024) and Barber et al. (2023). By reweighting the calibration samples similar to weighted conformal prediction, Guan (2023) introduced localized conformal prediction where the prediction intervals are determined by calibration samples localized around the test sample. Vovk et al. (2019) also introduced conformal predictive systems (CPS); an extension of full conformal prediction that allows extracting predictive distributions instead of prediction intervals. More recently, Jonkers et al. (2024a) combined previous concepts, introducing weighted conformal predictive systems to also account for covariate shifts.\nIn causal inference, conformal prediction has mainly been applied to binary treatments. For instance, Lei & Cand\u00e8s (2021) were among the first to apply conformal prediction to treatment effects estimation in randomized experiments and confounded or observational data. Jonkers et al. (2024b) and Alaa & Ahmad (2024) extended this approach to the potential outcomes framework, providing uncertainty to quantify individual treatment effects. However, the use of conformal prediction in continuous treatment settings remains largely unexplored. Schr\u00f6der et al. (2024) proposed a conformal prediction framework for prediction intervals of treatment effects for continuous treatment interventions. However, their approach mainly covers single-treatment interventions and is computationally intensive, requiring optimization per confidence level, treatment, and sample where they provide prediction intervals for a single treatment value. For a more in-depth analysis of Schr\u00f6der et al. (2024), see Appendix C.\nOur goal is to achieve predictive coverage across the entire range of the treatment variable in estimating the dose-response curve. To our knowledge, no existing UQ methods offer conformal prediction guarantees for dose-response models with continuous treatments. To address this gap, we propose a novel methodology that seeks to provide this coverage by integrating weighted conformal prediction with propensity score weighting thereby guaranteeing coverage for any treatment value in continuous treatment dose-response models."}, {"title": "4 METHOD", "content": ""}, {"title": "4.1 INTRODUCTION TO CONFORMAL PREDICTION", "content": "Before delving into our proposed method, we provide a formal introduction to conformal prediction (Jonkers et al., 2024a; Tibshirani et al., 2019). Conformal prediction offers a powerful method for constructing prediction intervals with guaranteed finite-sample coverage under distribution-free assumptions (Vovk et al., 2022). The key insight of conformal prediction lies in its use of a nonconformity measure to quantify the degree to which a new observation differs from previously observed data.\nLet us consider a regression problem with the training data being n independent and identically distributed (i.i.d.) data pairs $Z_1 = (X_1,Y_1),..., Z_n = (X_n,Y_n)$, where $X_i \\in \\mathbb{R}^d$ represents a vector of d features and $y_i \\in \\mathbb{R}$ the corresponding label. Consider $Z_{n+1} = (X_{n+1}, Y_{n+1})$ a new exchangeable point being the test observation to evaluate and provide prediction intervals. Conformal prediction aims to construct a prediction interval $\\hat{C}(X_{n+1})$ such that\n$P{y_{n+1} \\in \\hat{C}(X_{n+1})} \\geq 1 - \\alpha$         (2)\nfor a pre-specified significance level $\\alpha \\in (0, 1)$ where the probability is calculated over the points $Z_i, i = 1, ..., n$.\nTo achieve this, we first define a nonconformity measure $S((X, y), Z_{1:n})$ that quantifies how different the pair (X, y) is from a multiset $Z_{1:n} = {Z_1, ..., Z_n}$ of data points. The lower the nonconformity measure, the more the pair conforms to the multiset $Z_{1:n}$. The most commonly used nonconformity measure is the absolute error $S((X, y), Z_{1:n}) = |y - \\hat{\\mu}(X)|$ with $\\hat{\\mu}$ an estimator fitted on $Z_{1:n}$.\nNext, for each possible value $y \\in \\mathbb{R}$ that $Y_{n+1}$ could be, we compute the nonconformity scores:\n$R^i:= S((X_i, Y_i), {(X_1, Y_1), ..., (X_{i-1}, Y_{i-1}), (X_{i+1}, Y_{i+1}), ..., (X_n, Y_n), (X_{n+1},y)}), i = 1, ..., n$        (3)\n$R^{n+1}:= S((X_{n+1}, Y), {(X_1,Y_1), ..., (X_n, Y_n)})$        (4)\nFinally, we construct the prediction interval containing all y where (Jonkers et al., 2024a)\n$\\hat{C}(X_{n+1}) = {y \\in \\mathbb{R}: \\frac{\\# { i = 1...n+1; R^i \\geq R^{n+1}}}{n+1} > 1-\\alpha}$         (5)\nTibshirani et al. (2019) presented conformal prediction slightly differently by using quantile functions instead, which will be more convenient for weighted conformal prediction later on. Tibshirani et al. (2019) defines the 1 - $\\alpha$ quantile function as follows, where $F_R(y)$ represents the distribution of nonconformity scores R consisting of a sum of point masses $\\delta_\\alpha$ with mass at a where $R \\sim F_R(y)$ (Tibshirani et al., 2019). $F_R(y)$ can then be used to calculate probabilities:\n$Quantile (1-\\alpha; F_R(y)) = inf{R :P{R < R} \\geq 1 - \\alpha}$        (6)\n$F_R(y) = \\frac{1}{n+1}\\sum_{i=1}^n\\delta_{R^i}+ \\frac{1}{n+1}\\delta_y$        (7)\nFinally, we construct the prediction interval containing all y where\n$\\hat{C}(X_{n+1}) = {y \\in \\mathbb{R} : R^{n+1} \\leq Quantile (1 - \\alpha; F_R(y))}$        (8)\nThis procedure guarantees that $P(y_{n+1} \\in \\hat{C}(X_{n+1})) \\geq 1 - \\alpha$ for any exchangeable distribution of the data and any choice of nonconformity measure (Tibshirani et al., 2019)."}, {"title": "4.1.1 INDUCTIVE CONFORMAL PREDICTION", "content": "The previously mentioned conformal prediction approach is computationally heavy as it requires fitting $n \\cdot \\#{R} + 1$ estimators $\\hat{\\mu}$. Inductive or split conformal prediction (ICP), introduced by Papadopoulos et al. (2002), tackles this computation issue by splitting the training sequence $Z_{1:n} = {Z_1, ..., Z_n}$ into two sets: the proper training set $Z_{1:m} = {Z_1, ..., Z_m}$ and the calibration set $Z_{m+1:n} = {Z_{m+1}, ..., Z_n}$. A single regression model $\\hat{\\mu}$ is fit on the proper training set while the nonconformity scores (e.g., $R_i = |Y_i - \\hat{\\mu}(X_i)|, i = m + 1, ..., n$) are generated from the calibration set. These scores are sorted in descending order denoted as $R_{(1)}, ..., R_{(n-m)}$. Then, for a new sample with features $X_{n+1}$, a point prediction is made $\\hat{y}_{n+1} = \\hat{\\mu}(X_{n+1})$. Finally, given a target coverage of 1 - $\\alpha$, the prediction interval becomes\n$\\hat{C}(X_{n+1}) = [\\hat{y}_{n+1} - R_{(s)}, \\hat{y}_{n+1} + R_{(s)}]$        (9)\nwhere $s = [\\alpha(n - m + 1)]$ represents the 1 - $\\alpha$ quantile of the ordered nonconformity set with size n - m (Jonkers et al., 2024a)."}, {"title": "4.1.2 WEIGHTED CONFORMAL PREDICTION", "content": "Evaluating and requiring coverage guarantees for the dose-response model at all possible treatment values changes the test distribution compared to the training distribution. In the training data, all treatment values are sampled according to their (conditional) training distribution, which can be determined by other variables in the case of confounding. However, every treatment value is possible in testing, and thus, every treatment sample can be sampled. This mimics sampling a new test sample with the treatment value from a uniform distribution, which can be vastly different from the treatment distribution in the training data. Standard conformal prediction only guarantees coverage if the joint distribution of the new sample $Z_{n+1}$ and $Z_{1:n}$ remains the same under permutations, which is called the exchangeability assumption (Vovk et al., 2022; Tibshirani et al., 2019). This issue is called covariate shift; The features $X_{n+1}$ come from a different distribution compared to $X_{1:n}$, while the relation between X and y remains the same. More formally: $X_i \\sim P_X, i = 1, ..., n$ and $X_{n+1} \\sim P_\\tilde{X}$ where $P_X \\neq P_\\tilde{X}$ while $y_i \\sim P_{Y|X}, i = 1, ..., n$.\nWeighted conformal prediction provides a solution to tackle this issue (Tibshirani et al., 2019). However, their main assumption is that the likelihood ratio between the training $P_X$ and the test covariate distribution $P_\\tilde{X}$ is known, defined as\n$w(x) = \\frac{dP_\\tilde{X}(x)}{dP_X(x)}$        (10)\nThe rationale is that they reweight the distribution of nonconformity scores $F_R(y)$ to make the nonconformity scores more exchangeable with the test population by using the following weights in equation 7 (Tibshirani et al., 2019):\n$\\rho^n(X_{n+1}) = \\frac{w(X_i)}{\\sum_{i=1}^n w(X_i) + w(X_{n+1})}; \\quad \\rho^{n+1}(X_{n+1}) = \\frac{w(X_{n+1})}{\\sum_{i=1}^n w(X_i) + w(X_{n+1})}$        (11)\n$F_R(Y) = \\sum_{i=1}^n\\rho^n(X_{n+1}) + \\rho^{n+1}(X_{n+1})\\delta_y$        (12)\nConsequently, these weights adjust the distribution of nonconformity scores to give more weight to nonconformity scores that are more likely in the test set and vice versa while in standard conformal prediction, every $R_i$ has equal weight. Also, note that the weights $\\rho^n(x)$ are normalized, cancelling out any constant terms resulting in w(x) being proportional to $w(x) \\propto \\frac{dP_\\tilde{X}(x)}{dP_X(x)}$. An extension to split weighted conformal prediction can be done similarly as in section 4.1.1 (Tibshirani et al., 2019)."}, {"title": "4.1.3 CONFORMAL PREDICTIVE SYSTEMS", "content": "In some cases, providing a prediction interval often does not suffice and a complete predictive distribution is required. The extension proposed by Vovk et al. (2019) produces a predictive distribution by arranging p-values, created using specific conformity measures, into a probability distribution function. A requirement to create a Conformal Predictive System (CPS) is to use a specific type of conformity measures 1 which include monotonic measures. Then, given the training data $Z_{1:n}$ and observed test sample $X_{n+1}$, we define an example of this specific conformity measure S and conformity scores R similar as in equations 3 and 4:\n$S((X, y), Z_{1:n}) = y - \\hat{\\mu}(X)$        (13)\nWith $\\hat{\\mu}$ an estimator fitted on the training set $Z_{1:n}$. $R^i$ and $R^{n+1}$ are then similarly defined as in equation 3 for a CPS. Then, as defined in Vovk et al. (2022) we can define a predictive distribution Q for value y, using a distribution of nonconformity scores $F_R(y)$ of y to calculate P, similarly to the quantile function in equation 6 as follows:\n$Q_R(Y, \\phi) = \\phi P_{F_R(y)}{R^n < R^{n+1}} + \\phi \\cdot P_{F_R(y)}{R^n = R^{n+1}}$        (14)\nWhere $\\phi$ is a random number sampled from a uniform distribution between 0 and 1 to ensure a smooth predictive distribution. Using the same approach as section 4.1.2, these conformal predictive"}, {"title": "4.2 PROPOSED METHODOLOGY: PROPENSITY WEIGHTED CONFORMAL PREDICTION", "content": "Taking into account the background knowledge of conformal prediction, we first need to formally define the target distribution to tackle our problem definition. A CADRF model $\\hat{v}(X, T)$ is trained on triples (X, T, Y) with X d-dimensional observed covariates $X \\in \\mathbb{R}^d \\sim P_X$ and continuous treatment variables $T \\in [t_l,t_u] \\sim P_{T|X}$ to predict responses $Y \\in \\mathbb{R} \\sim P_{Y|T,X}$. $P_X$ represents the covariate distribution, $P_{T|X}$ represents the observational conditional treatment distribution given confounders X, and $P_{Y|T,X}$ represents the outcome distribution. $P_{T|X} = P_T$ if there are no confounders for T. A CADRF model will be used to query the dose-response for all $T \\in [t_l, t_u]$, creating an interventional distribution $P_I$. As every treatment value t is equally likely we can define $P_I = P_{I|X} = Uniform(t_L,t_u)$.\nTo attain marginal coverage across the interventional test set for a CADRF we can use weighted conformal prediction (Tibshirani et al., 2019). This requires defining the weights w for $X_i$ and treatment value t using equation 11, which we will call the global (g) propensity (p) weights $w_{g,p}$:\n$w_{g,p}(X_i, T_i) = \\frac{dP_{X,T}(X_i, T_i)}{dP_{I|X}(X_i, T_i)} = \\frac{dP_{T|X}(X_i, T_i)dP_X(X_i)}{dP_{I|X}(X_i, T_i)dP_X(X_i)} = \\frac{dP_{T|X}(X_i, T_i)}{dP_{I|X}(X_i, T_i)} \\frac{dP_{T|X}(X_i, T_i)}{dP_{I|X}(X_i, T_i)}$ (15)\n$\\frac{dP_{T|X}(X_i, T_i)}{dP_{I|X}(X_i, T_i)} = \\frac{f_{U(t_L, t_U)}(T_i)}{\\pi(T_i|X_i)} \\propto \\frac{1_{[t_L, t_U]}(T_i)}{\\pi(T_i|X_i)}$\nwith $1_{[t_L, t_U]}(T_i)$ the indicator function for $T_i \\in [t_L, t_u]$.\nWe assume that there is no distribution shift for X and thus $P_X(X_i) = P_\\tilde{X}(X_i)$. Additionally, $f_{U(t_L,t_U)}$ is the probability density function for the uniform distribution. We also define the propensity function $\\pi(T|X_i)$ as the probability density function for $P_{T|X}(T_i)$ as specified in Section 2. To generate the prediction intervals at treatment value t for a new sample $X_{n+1}$ the weights change to $w_{g,p}(X_{n+1},t) = \\frac{1}{\\pi(t|X_{n+1})}$. According to the weighted exchangeability defined in (Tibshirani et al., 2019), this guarantees marginal coverage over the interventional distribution, for all $T \\in [t_l, t_u]$, and $X \\sim P_X$.\nTibshirani et al. (2019) also suggested a method to attain local coverage around a predetermined target point $x_0$ using weighted conformal prediction. Consequently, this can provide varying prediction intervals for different values of $x_0$ providing another heteroscedastic approach. The proposed weights, which we call the local (l) weights $w_l$, utilize kernel functions with bandwidth parameter h:\n$w^l(X_i) \\propto K(\\frac{X_i - X_0}{h})$        (16)\nThese weights then guarantee\n$P_{X_0}{Y_{n+1} \\in \\hat{C}(X_{n+1}; x_0)} \\geq 1 - \\alpha$        (17)\nThis assures coverage around $x_0$, but $x_0$ must be determined beforehand. Additionally, if a new $x_0$ must be evaluated, a new calibration procedure must be performed which should be considered when applying it to general regression use cases. However, for this work, the target interventional treatment distribution is known in advance and can all be computed before deployment. Consequently, for a target treatment value t we can define $w_l(T_i) \\propto K(\\frac{T_i-t}{h})$ instead.\nThe local weights guarantee coverage where $\\frac{dP_\\tilde{T}(T_i)}{dP_T(T_i)} \\propto K(\\frac{T_i-t}{h})$. To adjust the local weights for a CADRF model we need to be aware of the covariate shift introduced by evaluating the interventional distribution and thus must combine $W_{g,p}$ with $w_{local}$ to achieve weighted exchangeability. These new weights are defined as $w_{l,p}$ for target treatment t:\n$w_{l,p} (X_i, T_i) \\propto \\frac{1_{[t_L, t_u]}(T_i)K (\\frac{T_i-t}{h})}{\\pi(T_i|X_i)}$         (18)\nTo generate the prediction intervals for target treatment t for a new sample $X_{n+1}$ the weights are then\n$\\frac{1_{[t_L, t_u]}(T_i)K((t-t/h))}{\\pi(X)}, which is equal to $w_{gp}(X_{n+1},t)$. By using\n$\\(T_i)(X_i)\nthese weights in a weighted conformal prediction framework, we provide a solution to the problem definition in Section 2."}, {"title": "5 EXPERIMENTS", "content": ""}, {"title": "5.1 SYNTHETIC DATA", "content": "We evaluate the proposed approach on synthetic data as evaluating the true individual dose-response curve requires knowing the counterfactuals which is not feasible in real-world data.\nWe used three experimental setups using synthetic data, each having different scenarios that change specific parameters. Setup 1 is inspired by Wu et al. (2024) and Setup 2 follows the experimental setup of Schr\u00f6der et al. (2024). Both Setup 1 and 2 are clarified in Appendix A. Setup 3 is novel, proposed by us, which mimics a situation where, for every scenario, two different possible dose-response functions are possible that each depends on the covariates, resulting in heavy confounding and thus limited overlap.\nFor each scenario (over the different setups), 5000 samples were generated using 50 different random seeds resulting in 50 datasets for each scenario. These datasets were split into 25% test (1250), 25% calibration (1250), and 50% training (2500) samples. For each scenario, two different $\\alpha$ (significance values) were evaluated (i.e., 0.1 and 0.05 for a confidence of 90% and 95% resp.). Each sample in the test set is evaluated using 40 treatment values to at equal intervals between the 2% and 98% training treatment value quantile to include varying treatment overlap regions and to mimic the uniform treatment sampling. In the results, the coverage of all treatment values and all samples in the test set are aggregated to a single mean coverage for each experiment, resulting in 50 mean coverage results for every method and scenario."}, {"title": "5.1.1 SETUP 3", "content": "Setup 3 is a new experimental setup proposed in this work to underline the importance of compensating for confounding in UQ for CADRF. The covariates are independently sampled from a normal distribution. The treatment T is confounded by two variables, determining the mean of the treatment assignment distribution:\n$X_1, X_2, X_3 \\sim Normal(0,5)$\n$T \\sim Normal (\\frac{X_2 + 0.1 \\cdot X_1}{4},4)$\nThe two scenarios have slightly different outcome distributions, as shown in Table 1. The idea is the same for both scenarios; The individual dose-response function is truly conditional and thus equal treatment values between different individuals or samples do not necessarily translate to each other. In total, there are four different possible dose-response functions depending on the covariates. Furthermore, there is heavy confounding resulting in limited samples where $T - X_2$ yields high values that in turn create large outcome values. This creates an opportunity for high epistemic uncertainty and limited overlap. For scenario two, the aleatoric uncertainty is also heteroscedastic based on $X_3$ forcing solutions to look beyond the treatment value to quantify uncertainty."}, {"title": "5.2 IMPLEMENTATION", "content": "In the case of synthetic data, the true propensity distribution, also known as the oracle distribution, is available. However, in real-world applications, the true propensity distribution is mostly unknown."}, {"title": "6 CONCLUSION", "content": "In this work, we have introduced a novel approach to weighted conformal prediction for UQ in dose-response models, utilizing propensity estimation and kernel functions as weights for the likelihood ratio. Alongside a newly proposed synthetic dataset, our approach highlights the necessity of compensating for the covariate shift in the treatment assignment when evaluating dose-response models across all possible treatment values. This is achieved by assuming uniform treatment sampling during testing, similar to methods used in discrete treatment effect estimation. Additionally, by leveraging conformal predictive systems to estimate propensity distributions, we offer a practical solution to implement UQ in continuous dose-response estimation for various practical use cases.\nOur contribution not only adds to the field of dose-response modelling but also facilitates delivering reliable, individualized dose-response functions. Our approach has the potential to aid decision-making for personalized dosing in fields such as marketing, policy-making, and healthcare. With this UQ for continuous treatments, we are one step closer to achieving truly personalized interventions that optimize outcomes for individuals."}, {"title": "A SYNTHETIC DATA", "content": ""}, {"title": "A.1 SETUP 1", "content": "For setup 1, inspired by Wu et al. (2024), six independent covariates are sampled from various distributions representing both continuous and discrete values:\n$X_1, X_2, X_3, X_4 \\sim Normal(0, 1)$\n$X_5 \\sim Uniform[-2, 2] (Integer)$\n$X_6 \\sim Uniform(-3, 3)$\nThe treatment value is confounded by all variables in this setup and thus determined by a treatment function $T_\\mu$. All scenarios share the same treatment function except for scenario 3, where a quadratic term was added. The treatment functions are shown in Table 2."}, {"title": "A.2 SETUP 2", "content": "Setup 2 tests the different treatment assignment distributions in the two different scenarios, which is the same experimental setup as proposed by Schr\u00f6der et al. (2024). The covariates are sampled"}, {"title": "B PROPENSITY DISTRIBUTION ESTIMATION", "content": "Algorithm 1 presents the propensity distribution estimation using Conformal Predictive Systems (CPS). This results in a propensity distribution array $T_{arr}$ with the calculated propensity density for each sample in $X_{cal}$. $exp$ is the exponential function and $len(X)$ denotes the length of the array X."}, {"title": "C COMPARISON TO SCHR\u00d6DER ET AL.", "content": "In comparison to the work of Schr\u00f6der et al. (2024), our approach differs in several key aspects. First, the aim of their work is different from ours. The aim of Schr\u00f6der et al. (2024) is to provide prediction intervals for the causal effect of treatment interventions where the treatment value is continuous. In our work, the goal is to provide prediction intervals for dose-response models instead of treatment interventions, answering a different causal question. However, adjusting our work to interventions is possible; In the case of soft interventions, the target distribution propensity changes and thus substituting the current uniform distribution in the weights w(x) with the new target propensity distribution covers the soft intervention case. For hard interventions, this is an evaluation for a single treatment value which is similar to the local propensity method, but for only that target treatment value. Secondly, their"}]}