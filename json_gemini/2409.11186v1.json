{"title": "Deep Learning tools to support deforestation monitoring in the Ivory Coast using SAR and Optical satellite imagery", "authors": ["Gabriele Sartora", "Matteo Salis", "Stefano Pinardi", "\u00d6zg\u00fcr Saracik", "Rosa Meo"], "abstract": "Deforestation is gaining an increasingly importance due to its strong influence on the sorrounding environment, especially in developing countries where population has a disadvantaged economic condition and agriculture is the main source of income. In Ivory Coast, for instance, where the cocoa production is the most remunerative activity, it is not rare to assist to the replacement of portion of ancient forests with new cocoa plantations. In order to monitor this type of deleterious activities, satellites can be employed to recognize the disappearance of the forest to prevent it from expand its area of interest. In this study, Forest-Non-Forest map (FNF) has been used as ground truth for models based on Sentinel images input. State-of-the-art models U-Net, Attention U-Net, Segnet and FCN32 are compared over different years combining Sentinel-1, Sentinel-2 and cloud probability to create forest/non-forest segmentation. Although Ivory Coast lacks of forest coverage datasets and is partially covered by Sentinel images, it is demonstrated the feasibility to create models classifying forest and non-forests pixels over the area using open datasets to predict where deforestation could have occurred. Although a significant portion of the deforestation research is carried out on visible bands, SAR acquisitions are employed to overcome the limits of RGB images over areas often covered by clouds. Finally, the most promising model is employed to estimate the hectares of forest has been cut between 2019 and 2020.", "sections": [{"title": "1. Introduction", "content": "Forests are an essential element in every ecosystem, covering 31% of the total Earth's land area [1] and hosting most of the planet's biodiversity [2]. Many species, including 80% of amphibians, 75% of birds, and 68% of mammals, inhabit and depend on forested areas. Forests also act as a carbon sequester [3] and as climate regulators, influencing temperature through evapotranspiration. Furthermore, thanks to their physical structure and chemistry, forests help mitigate extreme weather events by stabilizing rainfall patterns and limiting runoff and soil erosion [4, 5]. These ecosystem services underscore the critical role of forests in promoting sustainable development and conserving the natural ecosystem. However, the past few decades have witnessed a significant increase in deforestation, causing critical challenges across many biomes and exacerbating the climate change worldwide. [3, 6, 7, 8]. Deforestation exposes soil directly to solar radiation, making it more vulnerable to weather extremes and depleting its texture, nutrients and microbial content. If these forcing factors are not addressed, they could precipitate further degradation, including desertification [9, 10, 11].\nAmong continents, Africa had the largest annual rate of net forest loss from 2010 to 2020 (3.9 million ha lost), followed by South America with 2.6 million ha. Africa is the continent least equipped to cope with the negative impacts of climate change. Heatwaves, heavy rains, floods, tropical cyclones, and prolonged droughts are having devastating impacts on communities and economies [12, 13]. As of early 2020, over a third (36%) of all adaptation actions identified in the NDCs (Nationally Determined Contributions) of 52 African countries [14] were Ecosystem-based Adaptations (EbA) [15, 16, 17]. More than the 80% of these actions fall within the agriculture, land use/forestry, environment and water sectors [18]. Furthermore, while the rate of net forest loss has decreased in some countries, in Africa it has continued to increase over the three decades since 1990 [1]. Deforestation in Africa, especially in West Africa, has been frequently attributed to the agricultural activity of local farmers [19, 9, 10, 11]. Given the low industrial-"}, {"title": "2. Related Works", "content": "Over the years, satellite missions have gained increasing relevance in monitoring environmental phenomena, giving birth to the Earth Observation field. For this reason, most of the countries of the world joined international missions to obtain and/or share the collected data. Among the current most popular satellite constellations there are Sentinel [31], implemented by the European Space Agency, and the American constellation Landsat [32], which have been extensively used also thanks to their open access availability. Satellites have been employed to monitor several aspects of the environment, such as water scarcity [33], floods [34], wildfires [35], and others [36].\nWhile, initially, all these satellite data were analyzed with manual methods [37], machine learning techniques, such as Random Forest, have been increasingly adopted for classification and segmentation [38]. With the outbreaks of deep learning and computer vision models, a new plethora of instruments have come out. The convolutional-based architectures with their overwhelming performances have established themselves as the hard-to-beat competitor for the data-driven models.\nAmong targets of classification and segmentation, also deforestation gained an increasing relevance due to its impact on climate change. Most of the researches in this field focused on the Amazon forest [39, 40, 37], but studies were carried out all over the world, over Africa [41], Europe [42, 43] and Asia [44, 45].\nDeforestation has been studied both by training segmentation models on single images [39, 40, 46] and also by building models using a spatio-temporal approach that ingests multiple time steps [37, 47]. For instance, the first cited researches were based on an ad-hoc forest/non-forest dataset created for the Amazon forest with the support of an expert [48]. Consequently, these studies have been conducted only on visible images, which could be a limit to detect deforestation in areas with significant cloud coverage, which is particularly common during the summer. Then, using Landsat images, models have been trained on data with a spatial resolution of 30 meters per pixel. Instead, in [37] the authors worked on a ground truth with a ground truth dataset distinguishing non-deforested from deforested areas, starting from PRODES dataset and creating models updating the deforested area each year. In these case"}, {"title": "3. Datasets and Methods", "content": "This work aims to provide a methodology to develop deforestation detectors over rural areas scarcely covered by remote sensing open source data, such as the Ivory Coast. The pipeline performed in this work, and depicted in Figure 1, is the following:\n1. Data retrieval: selection of the region of interest (ROI), mosaic definition, crop raw data into tiles, per-tiles download of Sentinel-1 (2 bands), Sentinel-2 (4 bands and Cloud Probability), and FNF map;\n2. Preprocessing: ground truth processing, splitting of the dataset into train, validation and test sets, normalization and data augmentation;\n3. Modeling & Testing: models initialization, training, and testing using some performance metrics on test sets;\n4. Deforestation: Detect deforestation in a given period by looking at the changes in the forest classification map predictions.\nStep 1) was performed on Google Earth Engine, while the remaining steps were performed through Python using Cineca HPC resources 2. The following subsections provide more details about these steps."}, {"title": "3.1. Datasets", "content": "The raw data used in this work consists of Sentinel datasets and the Forest/Non-Forest (FNF) dataset, provided by the European Copernicus program and the Japanese ALOS program, respectively. The Sentinel data are used as input, while the FNF classification is the ground truth. To avoid ambiguity, in the rest of the paper, the created dataset made of instancies of Sentinel and FNF images is referred to as S2FNF."}, {"title": "3.1.1. Sentinel", "content": "Sentinel-1 and Sentinel-2 are two Earth Observation missions of the Copernicus program, managed by the European Commission. Sentinel-1 carries a C-band synthetic-aperture radar (SAR) instrument, while Sentinel-2 provides 13-bands multispectral images. These two missions offer complementary data: Sentinel-1 captures images in the non-visible electromagnetic spectrum which are not influenced by time of acquisition (day/night) and weather conditions. While, Sentinel-2 collects images primarily in the visible spectrum helpful for monitoring Earth's land and coastal waters. Sentinel images were chosen as the input of the proposed models because of their sub-monthly revisit time and spatial resolution of 10 meters per pixel (m/px) which make these data highly suitable for the segmentation task."}, {"title": "3.1.2. Forest-Non-Forest map (FNF)", "content": "The target for training our model is the Forest/Non-Forest map (FNF version 4) [29]. This map is produced by processing the Advanced Land Observing Satellite Phased Arrayed L-band Synthetic Aperture Radar (ALOS-PALSAR) data. The FNF map has a native resolution of 25m/px and classifies pixels into four categories: dense forest, non-dense forest, non-forest and water. To align the input and output dimensions of the models, we upsampled FNF images to match the Sentinel's resolution of 10m/px. Furthermore, following the Food and Agriculture Organization (FAO) forest definition\u00b3, we consolidated the original 4 categories into two: \"forest\" (made of dense and non-dense forest) and \"non-forest\" (made of non-forest and water). In this classification, \"forest\" is the positive label. Other maps classifying forests, such as ESA World Cover [49] and JRC Global Forest map [30]), have been released. However, the FNF map offers a broader temporal coverage (since 2007 up to the present) and is specifically tailored for forestry classifications."}, {"title": "3.1.3. S2FNF dataset", "content": "To reduce computational load, we focused on a representative region in the central part of the country, retrieving data from 2019. The region of interest (ROI) is defined by longitudes ranging from -6.0969 to -4.7731 and latitudes from 5.5697 to 7.1474 .Sentinel's mosaics have been composed by images for the period from May to October 2019. This period was chosen because the FNF map for this region is generated yearly by ALOS-PALSAR data from the same months. Thus, in this way, the input data should be the most representative of the target ground-truth map. Over the ROI only VV (single co-polarization, vertical transmit/vertical receive) and VH (dual-band cross-polarization, vertical transmit/horizontal receive) bands of Sentinel-1 in ascending orbit were available.\nFor Sentinel-2, four bands have been retrieved: B2, B3, B4 and B8, respectively, blue, green, red and NIR (i.e. visible and near-infrared, also known as RGBN). These bands have a resolution of 10m/px which is the finest resolution available among the Sentinel-2 bands4). Given that summer is the season presenting extensive cloud coverage in Ivory Coast, Sentinel-2 images has been filtered to include only those with at most 20% of cloud coverage. Even though this filtering prevents the use of almost completely cloud-covered images, many of the remaining Sentinel-2 images still suffer from cloud occlusion which makes the segmentation task particularly challenging using only Sentinel-2 optical data. For this reason, we decided to use also the Cloud Probability Map layer provided within the Sentinel-2 product, which represents the probability of each pixel being covered by clouds.\nThe ROI has been mosaiced into 4000 squared tiles, each covering an area approximately of 6,55 km\u00b2. The S2FNF has been composed then by 4000 instances, each made of Sentinel features and the respective FNF target mask. The S2FNF has been split into 70% training, 15% validation and 15% test sets. Finally, it is worth noting that the Ivory Coast is mostly covered by forests and, consequently, the dataset classification labels are significantly unbalanced towards this class. Specifically, around 75% of the labels are forest areas, while only 25% are non-forest. For this reason, during training, the loss is weighted in an inversely proportional way, weighting 0.7 the misclassification of a non-forest pixel and 0.3 the forest misclassification."}, {"title": "3.2. Preprocessing", "content": "Sentinel images have been normalized following the Equation 1 which is the classical min-max normalization but using instead the 1st and 99th percentile. This improves the representation of features in the normalized space in the presence of outliers, easing in this way the information extraction and improving the learning process of the models.\n$\\X = (p_{99} - X)/(p_{99} \u2013 p_{1}).$\nData augmentation is applied at training times. This process does not create a specific percentage of new samples, but it slightly modifies all the samples during training. Specifically, it applies random horizontal/vertical flips, shifts (from 0 to 10% of the width/height length), and rotations (from 0 to 180 degrees)."}, {"title": "3.3. Models", "content": "The experiments are carried out comparing four segmentation models: FCN32 [50] with a VGG16 [51] backbone, SegNet [52] with a ResNet50 [53] backbone, UNet [54], and the Attention UNet proposed by [55]. The term backbone is generally used when multiple architectures are employed for building a single final model. As the name suggests, the backbone is the architecture which characterizes the inner structure of a model (e.g. VGG) and works as a feature extractor, while other architectural structures could be used to define the shape of the final model (e.g. FCN). To develop specific forest classifiers, all the architectures have been trained from scratch without using transfer learning. While FCN, SegNet and UNet are state-of-the-art and very widespread models, Attention-UNet has been less adopted except in the medical field. In more detail, Attention-UNet is a classical UNet with the attention gates along with the skip connection of the UNet, these gates should help the network to focus only on salient features and suppress irrelevant regions of the feature maps. In [40] authors highlighted the performance of this architecture for classifying forests in South America, and for this reason, we have decided to add it to our comparison."}, {"title": "4. Results", "content": "Experiments have been carried out considering four input combination scenarios: S1) Sentinel-1, S2) Sentinel-2, S1-2) Sentinel-1 and Sentinel-2 combined, S1-2-CP) Sentinel-1, Sentinel-2, and Cloud Probability Map combined. All the models have been trained using the Adam optimizer with a binary cross-entropy loss for 50 epochs with a learning rate of 0.0001 and a batch size of 32. Two test sets have been defined to evaluate the generalization ability of the models, especially concerning cloud coverage. The first test set was defined in 2019, the same year as the training, in which the cloud"}, {"title": "4.1. Forest Segmentation", "content": "coverage over the ROI was about 10.9%; the second test set was defined in 2020, in which the cloud cover was about 6.8% over the ROI. If a model can generalize well and is resilient to adverse weather conditions, its performances should be maintained over the test set defined in the two consecutive years. Accuracy, precision, recall, f1-score, and AUC PR (AUC of PR curves) have been computed to evaluate the performance of the models."}, {"title": "4.1.1. Sentinel-1 (S-1)", "content": "In this scenario, models have been fed using only Sentinel-1 bands, thus the predictions should not be affected by cloud coverage. Among all the models, UNet and SegNet-ResNet50 have performed the best with quite similar performances . All the metrics for the two test sets are almost the same in consecutive years, suggesting that these models can generalize well and are not affected by cloud coverage as expected and explained in Section 3. The trade-off between precision and recall appears to be well balanced with an F1 score of around 0.9 for the best-performing models. In the S1 scenario, the recalls are generally and slightly higher than the precision values; this could be attributed to the dataset imbalance whose positive class (forest) is more frequent All the above considerations are equally valid either for the 2019 and 2020 test sets, demonstrating the resilience of using Sentinel-1 data in different circumstances."}, {"title": "4.1.2. Sentinel-2 (S2)", "content": "In this scenario, models have been trained using Sentinel-2 bands as input. The best-performing models remain U-Net and SegNet-ResNet50 respectively. Comparing precision and recall in the S2 scenario in the 2019 test, the precisions are slightly higher than recalls (more false negative than false positive, i.e. more false non-forest than false forest) for three models (U-Net, SegNet-ResNet50, FCN-VGG16) over four. However, in the 2020 test, among these three models, only SegNet-ResNet shows a precision higher than the recall. Considering that 2020 has a lower cloud coverage, and the detrimental effect of clouds on the information content of optical data, this might mean that U-Net and FCN-VGG16 in S2 scenario are prone to classify clouds as non-forest erroneously. Relating to the previous S1 scenario, performance metrics are worse both for the tests in 2019 and 2020. The difference in the AUC PR in the 2020 test between S1 and S2 highlights and states the limitation of developing models based only on optical Sentinel-2 data on a cloudy region. In this context, SAR data could be considered as input features to complete the noisy (partially cloud-occluded), or even missing (totally cloud-occluded), optical land satellite images."}, {"title": "4.1.3. Sentinel-1 & Sentinel-2 (S1-2)", "content": "Given the limitation of the S2 scenario in cloudy context, we have proposed a new scenario combining Sentinel-1 and Sentinel-2 data with the idea of exploiting the most useful information from both visible and non-visible sources. Indeed, as already stated, in case of highly cloud occluded regions, SAR data should be considered the main feature for the classification task. However, optical data are for sure the faster and easiest means by which performing forest and non forest segmentation in a cloud-free context. This scenario is named S1-2 and provides the concatenation of Sentinel-1 and Sentinel-2 bands (i.e., 6 bands, namely VV, VH, B2, B3, B4, B8) as the input of the models. On the 2019 test, models in the S1-2 scenario seems to perform slightly better than S1 in terms of accuracy and AUC PR . Accuracies and recalls are still well-balanced, with a F1 score around 0.9 for all the models. However, on 2020 test, models perform not better, and in some case worse, than in S1. This suggest that in S1-2 scenario models generalize less than in S1, probably because of the inability of models to understand on what sources to focus on depending on cloud coverage. This is demonstrated also by the higher AUC PR in the S1 scenario ."}, {"title": "4.1.4. Sentinel-1 & Sentinel-2 & Cloud Probability (S1-2-CP)", "content": "To facilitate the learning of how to use Sentinel-1 and Sentinel-2, we have proposed a new scenario (S1-2-CP) in which the Cloud Probability Map is provided as an additional input to the S1-2 features. Models' performances on the 2019 test do not reveal any significative improvement than the S1-2 scenario, and for some models and metrics even worse. This suggest that S1 scenario provides sufficient information for the classification task and the proposed integration of optical data sem to be unnecessary - even misleading in some occasions. The high cloud coverage represents for sure one of the major limiting factor for the usefulness of Sentinel-2 data. More complex models could be developed and tested to ease the automatic fusion of SAR and optical data, as discussed in Section 5."}, {"title": "4.2. Deforestation detection", "content": "Concerning the forest and non-forest segmentation task, U-Net has revealed the best-performing model. For this reason, we have decided to select U-Net in the S1 scenario as the reference for deforestation mapping. Our strategy to detect deforestation has been to look at changes in per-pixel classification in two time-subsequent segmentation maps: when a forest pixel becomes a non-forest pixel deforestation has occurred. The usefulness of Sentinel-1 SAR data is definitively demonstrated here. Indeed, both Sentinel-2 images in 2019 and 2020 are partially occluded by clouds, and understanding deforestation patterns is rather complicated. Instead, looking at radar data, it is clear the urban expansion and the consequent deforestation. It is relevant to stress that deforestation maps like  could be created for any tile and periods with any length, where the lower bound length is defined by the Sentinel-1 revisit time which is approximately two weeks. Looking for deforestation all over the ROI, we have estimated 462.52 km\u00b2 of deforested area between 2019 and 2020, which means deforestation of roughly 2% concerning 2019 forests."}, {"title": "5. Discussion", "content": "Focusing on the forest segmentation task, one of the major problems has been the difficulty of correctly classifying isolated non-forest pixels, as it is visible from and . This is a rather difficult goal, even in ideal conditions of high-quality data and well-performing models.\nTo the best of our knowledge, no previous works have been done applying deep learning models over the Ivory Coast for forest/non-forest segmentation, especially using FNF. However, other works on the same task presented models reaching about 95% of accuracy and F1-score [39, 40, 46]. Instead, although the models presented in this paper reached about 90% of accuracy, it is important noticing that our ground truth could be less precise. Indeed, in Ivory Coast, the conditions are far from ideal, especially because of the data availability and quality both for the target FNF map and for the Sentinel images. Indeed, FNF's documentation declares an accuracy of 91% for its forest classification over Africa. This means that the target used for training deep learning models might be erroneous in some circumstances, hardening the model training. Furthermore, FNF has an original spatial resolution of 25m/px, which is lower than the Sentinel images one. Consequently, models could have learned well how to classify forest and non-forest classes, but FNF could act as a bottleneck for models performances on this task. In other words, the metrics of  could be considered as lower bounds, being potentially higher in the case in which FNF map would increase its resolution up to 10m/px.\nThe major limitation of Sentinel-1 data is the lack of descending orbit images. Even if our S1 scenario has produced remarkable results, the availability of this additional Sentinel-1 data could enhance a lot the ability of models to classify forest and non-forest highlighting additional forest borders - which in turn would bring more accurate deforestation maps.\nNotwithstanding the limitations, we have provided an open-access framework to produce deforestation maps in Ivory Coast using only open data. As already pointed out, within our framework, deforestation maps could be created at a sub-annual rate, which is a temporal frequency higher than any other existing tool. Furthermore, by using Sentinel-1 data we have developed cloud-resilient remote sensing-based models, which is essential for countries in which clouds represent a limiting factor for optical satellite data.\nIn this case study the combination of both Sentinel-1 and Sentinel-2 has been of scarce utility. However, more complex models could be developed aiming at a better automatic information fusion in the S1-2 scenario. In detail, the so called \"neuro-symbolic\u201d or \u201cphysically-informed\" approach [56] could be used to force the network to learn autonomously where clouds are present and then, according to cloud occlusion intensity, what source between Sentinel-1 and 2 to use more. This improvement is left for future work.\nTo improve the proposed framework, a spatio-temporal approach could be tested. Instead of training models for forest segmentation, and subsequently, looking for per-pixel label changes in a deterministic way, it is possible to develop models that directly predict deforestation patterns. However, this approach would require feeding as input two satellite images, one at the beginning of the period to monitor, and one at the end. Furthermore, a true deforestation map should be available, i.e. a ground truth. Most of the studies retrieve this ground truth either from pre-existing datasets or by expert manual labelling, which is time and cost-intensive [37, 47]. West Africa, and in particular Ivory Coast, lacks such datasets and given the scarce resources we have preferred to produce a simpler and cheaper, but re-usable and still accurate, instrument by adopting the FNF and Sentinel data."}, {"title": "6. Conclusions", "content": "Despite the availability of remote sensing open data, this analysis highlights the difficulty of conducting a study on developing countries with scarce economic and technical resources. It is pivotal to provide cheap, or even free, instruments to these countries to comply with standards and international regulations on the environmental impact of goods. Our study has tried to furnish a free deep-learning model to detect deforestation patterns in the Ivory Coast, demonstrating the potential and the usefulness of radar acquisitions over forested areas. Even if some limitation exists and multiple improvements are applicable, our solution could be considered a first approach to support forest sub-annual monitoring and national forest management policies."}]}