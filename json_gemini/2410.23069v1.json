{"title": "LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education", "authors": ["Ahmed Kharrufa", "Sami Alghamdi", "Abeer Aziz", "Christopher Bull"], "abstract": "This work takes a pedagogical lens to explore the implications of generative AI (GenAI) models and tools, such as ChatGPT and GitHub Copilot, in a semester-long 2nd-year undergraduate Software Engineering Team Project. Qualitative findings from survey (39 students) and interviews (eight students) provide insights into the students' views on the impact of GenAI use on their coding experience, learning, and self-efficacy. Our results address a particular gap in understanding the role and implications of GenAI on teamwork, team-efficacy, and team dynamics. The analysis of the learning aspects is distinguished by the application of learning and pedagogy informed lenses to discuss the data. We propose a preliminary design space for GenAI-based programming learning tools highlighting the importance of considering the roles that GenAI can play during the learning process, the varying support-ability patterns that can be applied to each role, and the importance of supporting transparency in GenAI for team members and students in addition to educators.", "sections": [{"title": "1 INTRODUCTION", "content": "The implications of generative AI (GenAI) in education are currently a very active area of research. Some researchers are exploring this in the context of education in general (e.g. [11, 49]), while others are focusing on specific disciplines. What is special about GenAI and computing education is the development of models (such as Codex [57]) and tools such as GitHub Copilot that specifically support code generation. As such, this topic has gained an even greater research interest in computing education recently (e.g. [17, 18, 20, 29, 37, 44, 53]). Such research ranged from evaluating the quality of GenAI generated code and its impact on assessment (e.g. [19, 38, 41, 51]), to many that looked at educators or experienced developers' perspectives (e.g. [6, 11, 15, 31]). Accordingly, it is critical to understand how these tools can align with educational objectives set by educational organizations, aside from their capability to meet varied personal needs of students and educators. There is a growing consensus that prohibiting students from utilizing these tools is not practical nor is it beneficial for students learning. Instead, the focus may shift towards understanding, adopting, and adapting these tools to better serve fundamental educational objectives in the long run [11, 17, 27, 41].\nIn this work, we aim to add to the community's understanding of the potential role and implications of using GenAI tool in software engineering. To narrow the scope further, we are particularly interested in looking at the students' perspective based on practical use within team-based formal education and analyzing it through a pedagogical and technology design lens. As highlighted by French et al. [21], many of the papers reporting on students' perception of GenAI in computing education are not based on actual, or long-term, use and experiences where GenAI is integrated into their modules. This can be a natural consequence of the recentness of such technologies, the duration it takes to make and approve changes to taught modules at universities, and the eagerness to contribute to the discussion on the topic before students are given the opportunity to use them extensively in formal education.\nMoreover, the students' perspective of the role of GenAI on teamwork and its effect on team dynamics in computing (i.e., GenAI's use in computing teams beyond one student collaborating with AI) remains insufficiently studied, even though teamwork is a common practice in computing projects and in professional careers in computing. We also noticed that apart from a few exceptions, the results and findings of existing research are rarely explicitly discussed from a learning theories and pedagogy perspectives (e.g. [32, 37, 53]) or from a technology design perspective (e.g. [23, 26, 33]). Instead, more focus can be found in"}, {"title": "2 RELATED WORK", "content": "To situate our work, this section provides an overview of the rapidly evolving field of Generative Artificial Intelligence in education, particularly within computing.\n2.1 GenAl in Education and Computing Education\nGenAI is significantly impacting education, driving a transformative shift in teaching and learning practices. OpenAI's ChatGPT, as highlighted by Velibor Bo\u017ei\u0107 [8] and Michael Neumann [36], represents a significant advancement in GenAI technology with broad applications in education. Bo\u017ei\u0107 discusses ChatGPT's utility in language learning, writing assistance, automated grading, and personalized education. Similarly, Neumann's work emphasizes ChatGPT's transformative potential in education but also calling for its responsible use.\nAs discussed in the introduction, GenAI's specialized support for code makes the role of GenAI in computing science education of particular importance. Accordingly, the integration of GenAI in computing science education opens new opportunities for academic innovation, enhancing learning through programming assistance, content generation, and personalized instruction (e.g. [11, 15, 43]). The academic sector is keenly exploring the potential and challenges of GenAI, focusing on ethical issues, equitable access, maintaining academic integrity, and responsible use [12, 25, 36]. As GenAI technologies like code generators become more common, there's an emerging challenge in ensuring that students maintain a strong foundation in traditional programming skills. Research into GenAI's efficacy in aiding beginner programmers has revealed both their advantages and limitations. For instance, GPT 4 shows improvements over 3.5 which again shows improved accuracy over earlier models like Codex, yet issues in output formatting and language accuracy remain [41]. Future research aims at developing conversational techniques to better support students in troubleshooting and refining Large Language Models (LLMs) for more precise guidance, underscoring the need for balancing the benefits with responsible GenAI use in education. Moreover, integrating GenAI tools in computing education raises concerns about their impact on learning goals and teaching methods. As an example, a study involving 12 students and six instructors indicated GenAI tools' usefulness in programming and learning but highlighted risks of overreliance and plagiarism, stressing the importance of including practical usage training and AI literacy in the curriculum [52]. Further, Paul Denny and colleagues point out the limitations of using natural language for complex programming tasks, underscoring that proficiency in high-level programming languages is still a crucial skill for computing students [16]."}, {"title": "2.2 Students' Experience Using GenAl", "content": "Several recent studies have investigated the integration and impact of GenAI in education, focusing on student experiences across a range of academic disciplines. However, several of these studies rely on speculations, opinions, and survey-based data. For instance, a study from Hong Kong [12] involving 457 students and 180 teachers used surveys to collect both quantitative and qualitative data. The aim was to identify the necessary requirements and guidelines for developing Al policies applicable in university teaching and learning contexts. A similar study [40] highlighted concerns over GenAI misuse and proposed a GenAI Ecological Education Policy Framework for a future integration with GenAI, placing a strong emphasis on data privacy and security measures. Further, a study by Chan and Lee [13] utilized an online survey to assess how adapting GenAI to meet diverse learning preferences across generations could integrate traditional and AI-enhanced methods to promote critical thinking. This research reached out to potential participants via bulk emails, garnering responses from 399 students and 184 teachers, and offering valuable insights into attitudes towards GenAI and its potential effects on education. These mentioned works predominantly use survey- based methods to explore Al's role in educational contexts. The reported students' experiences from our research are based incorporating GenAI into a software engineering module for an entire semester. This method provides a deeper understanding of GenAI from the students' perspective through firsthand experience and application, rather than through speculative or supposed impacts.\nAdditionally, research conducted among students has included design experiments and the introduction of novel tool designs. Paul Denny and colleagues [16] evaluated Al-generated educational content against student contributions, highlighting Al's potential as an auxiliary educational tool. Hassan Khosravi and colleagues implemented RiPPLE [28], where students were tasked with creating code examples during a weekly lab session. Through blind evaluations focused on correctness and helpfulness, they discovered that AI-generated resources were comparable in quality to those produced by students, though differences in syntax and length were noted. Another investigation by Kazemitabaar et al. [26] assessed the effects of Al coding assistants like OpenAI Codex on the education of introductory programming students. This study involved 69 novice learners, aged 10-17, split into two groups-one using the AI code generator and the other did not. The group assisted by AI completed tasks more efficiently and with fewer errors, underscoring the utility of AI code generators in reducing stress and boosting engagement for beginners.\nThe \"Grounded Copilot\" study by Shraddha Barke and team [5] aimed to understand programmers' interactions with GitHub Copilot. Recruiting 20 participants, including 15 from academia and 5 from the industry, they conducted a programming task with Copilot for an hour, followed by interviews. The session recordings were used to inform a grounded theory analysis. The findings suggest directions for optimizing future Al programming assistants for better user engagement and efficiency.\nA similar studies [42] examined novice programming students' interactions with GitHub Copilot, involving 19 university students aged 18-11 enrolled in an introductory programming course. These students, observed in a controlled environment for 30 minutes, mirrored in-class coding conditions. This study shed light on the challenges faced by first-time users, particularly how unsolicited Copilot suggestions could be more obstructive than helpful. Thus, novices showed a preference for an interaction model offering help on demand. These insights highlight the need for AI coding tools tailored to novice programmers' specific needs. The results also offer insights for integrating these technologies into introductory programming education and enhancing their usability to better assist novices in overcoming programming obstacle [42].\nFurthermore, at London Metropolitan University [15], BSc Games Programming students engaged with GenAI through two models, focusing on current Al developments and games. The students utilized GenAI tools like ChatGPT in their assignments, reflecting on GenAI's role in enhancing creative and critical problem-solving skill. This inclusion of GenAI not only enhanced their ability to generate creative responses and infer context but also facilitated the development of critical problem-solving skills. Feedback mechanisms, supported by literature on the timing and specificity of formative feedback, played a crucial role in shaping their learning experience. The outcomes of this educational approach were reflected in the marks awarded, which ranged from 54 to 73 percent, demonstrating the students' ability to creatively tackle assignments and critically reflect on the use of GenAI tools in development processes, all while navigating the challenges set within the freedom of their academic environment [15].\nOur paper, in contrast, extends beyond the specific use cases and tools investigated in these studies, aiming to provide a comprehensive understanding of GenAI's implications in computing science education from an empirical perspective. We focus on enriching the understanding of student perspectives on GenAI's potential and implications based on actual use in a SE module. While the cited research contributes valuable insights into GenAI's role in educational content creation, programming assistance,"}, {"title": "2.3 Educators' Stance on Using GenAl in Computing", "content": "As various studies have highlighted, the integration of GenAI into computer science education is reshaping the educator's role. Al-Hossami's research looks into applying Socratic questioning alongside AI, specifically evaluating GPT-based models like GPT-4 and GPT-3.5 for debugging tasks [3]. This method promotes independent problem-solving among novice programmers through guided inquiry, showcasing both the strengths and limitations of these models compared to human expertise. Simultaneously, Sam and Guo's study [31], conducted through interviews with 20 programming instructors from nine countries, examines the broader impact of Al coding tools such as ChatGPT and GitHub Copilot on computing education. It explores instructors' perspectives on incorporating AI tools into curricula, raising issues related to bias, ethics, and the authenticity of AI-generated work [31].\nFurthermore, research by Smolensky et al., [47] involving 389 students and 36 educators in Australia and the US, reveals concerns about academic integrity and the need for assessment modifications to encourage critical thinking. While educators lean towards altering assessments to accept Al's growing presence, student reactions are mixed, with some worrying about the potential loss of creativity [47]. Similarly, another research by Petrovska et al [39] explored the feasibility of integrating GenAI thoughtfully into software engineering education through formative and summative assessments, addressing coding capabilities and argument construction.\nThese studies highlight the complex challenges of adopting GenAI in educational contexts, advocating for a balanced approach that combines traditional teaching methods with Al's innovative capabilities. This strategy, in turn, is expected to prepare students and educators for the continually evolving technological landscape."}, {"title": "2.4 Al in Teamwork", "content": "Exploration into the role of GenAI in enhancing teamwork is in its preliminary phases, with a nascent but expanding body of work just beginning to uncover its potential benefits and implications. Zhang et al. investigated communication strategies within human-Al teams, pinpointing the necessity of proactive and balanced communication for effective collaboration [54]. The deployment of ChatGPT-4 in engineering education emerges as a promising strategy to improve team feedback mechanisms, striving to foster a nurturing and growth-oriented team atmosphere [46]. Moreover, GitHub Copilot's integration into software development routines signifies a transformation, redefining coding as a collaborative, rather than an isolated activity [6]. Comparative studies on human-Al versus traditional human-human pair programming shed light on AI's ability to bolster human efforts in educational frameworks, emphasizing the critical need for flexible and ethical adoption strategies [34]. These insights, while enlightening, underscore the urgent need for more extensive research to thoroughly understand and harness Al's, particularly GenAI's, capacity for facilitating teamwork in various fields and contexts.\nIn the context of qualitative analyses collaboration, Gao et al. developed CoAlcoder [22], a tool specifically designed to enhance human collaboration in qualitative analyses of data. This was achieved by leveraging AI to provide real-time code suggestions. The study concludes that AI can be effectively integrated into the inductive coding process, thereby promoting collaborative interpretation.\nIn engineering and computing education, teamwork emerges as a pivotal skill, with students and educators alike navigating the complexities of collaborative learning environments. A study was conducted to improve teamwork in first-year engineering design teams by utilizing GenAI, specifically ChatGPT-4, for feedback synthesis. Their research acknowledges the instrumental role of teamwork, underscored by the traditional use of tools like CATME for team formation and peer feedback [31].\nHowever, most research in AI teamwork in computing education has focused on the interaction between humans and AI in pair programming settings. There is a need for more research looking at the role that GenAI can play as a member of a programming team. For instance, Barke [5] explored the Human-AI pair in the context of GitHub's Copilot and highlighted the shift in coding experience, emphasizing the growing importance of reviewing written code and discussing potential improvements in Al pair programming. Similarly, Ma et al. [34] investigated the dynamics of human-AI pair programming through literature, contrasting it with traditional human-human pair programming. The research suggests that while Al partners like GitHub Copilot can complement human programmers by managing tasks like code generation, there are unique challenges and opportunities in optimizing this collaboration for educational contexts and professional development. These studies, while insightful, underscore"}, {"title": "2.5 Pedagogical and Technology Design Perspectives in GenAl Research", "content": "Our review shows that only a few studies explicitly incorporated pedagogical or learning theory perspectives in examining the role of GenAI in computing science education. Interestingly, most studies that adopted these perspectives did so by developing their own tools to enhance existing GenAI technologies for educational purposes (e.g., [23, 26, 33]).\nA significant line of inquiry has focused on assessing the impact of GenAI tools on learning, especially regarding the potential for overreliance on these technologies. Kazemitabaar et al. [26] created a unique Integrated Development Environment (IDE) that leveraged the Codex LLM to aid novice programmers aged 10-17 in their learning processes. Their findings indicated that GenAI tools enabled newcomers to programming to code more efficiently and effectively, reducing frustration. Crucially, reliance on GenAI did not diminish the students' ability to modify code manually when GenAI support was absent. The study concluded with three key design implications for GenAI tools: 1) enhanced support for absolute beginners, stemming directly from the study's target demographic; 2) mechanisms to control overuse, preventing dependency that could hinder learning progress; and 3) improved support for constructing effective writing prompts.\nSimilarly, Liffiton et al. [33] developed CodeHelp, a GenAI-powered tool designed with 'guardrails' to offer on-demand assistance to programming students without directly providing solutions. These guardrails aim to curb students' over-reliance on GenAI, offering an innovative way to integrate GenAI tools into learning while enabling educators to monitor and analyze student engagement with the technology. The evaluation of CodeHelp was positive, with students appreciating its support in completing tasks successfully and enhancing their learning. Key themes from student feedback included error correction, support for independent learning, speed, and improved understanding. A noted concern was the tool sometimes presenting content not yet covered in the course. Although specific design implications were not detailed, the study suggests valuable design considerations like implementing guardrails, providing educators with dashboards for monitoring GenAI usage, and ensuring GenAI-generated content aligns with course material.\nAnother research focus is the pedagogical value of learning from worked examples, a widely studied approach in education, particularly in programming education [1, 11, 55]. Leinonen et al. [32] examined how code explanations by students compare with those generated by GenAI in terms of accuracy, length, and understandability. They found that while GenAI and student explanations were similar in length, GenAI-generated explanations were perceived as more accurate and easier to comprehend. This suggests GenAI's potential in producing resources for students, especially beneficial in early learning stages where example-based learning is common. Acknowledging the educational advantages of worked examples and the time required to create quality ones, Jury et al. [23] introduced 'WorkedGen' for generating interactive worked examples. Their study involving around 400 first-year Python programming students demonstrated that GenAI could create effective, high-quality examples that students found valuable, particularly due to the interactive possibilities offered by GenAI."}, {"title": "3 METHOD", "content": "3.1 Study Context\nThis study focused on students enrolled in a 2nd-year undergraduate Software Engineering Team Project module at a UK University, a compulsory course for all Computing majors. This module spans seven weeks and is the only module the students work on during this time. It emphasizes software engineering principles, involves extensive programming, and it is designed as a key team-based project coursework. Programming activities commence in the second week or earlier, allowing students to devise their projects around the United Nations Sustainable Development Goals\u00b9, typically leading to the creation of mobile or web applications based on a multi-tier architecture. While the module centers on software engineering, it also adopts a comprehensive approach by integrating Human-Computer Interaction (HCI) elements.\nAt the outset of the second week-following an initial week dedicated to team formation and the definition of project ideas and requirements the module leader informed the students about the availability of GenAI tools for their projects. This introduction covered a range of GenAI technologies, including ChatGPT, Google's Bard, and GitHub Copilot, emphasizing the students' freedom to explore and optionally utilize these tools in their project development. However, a significant condition was set: these tools were permitted exclusively for project creation and code development, not for composing the assessed textual design report. This distinction was crucial as the evaluation criteria focused on the application of software engineering principles over algorithmic quality. The students received repeated reminders about the use of these tools and the associated constraints throughout the module, ensuring clarity on the guidelines and mitigating potential issues such as plagiarism or other assessment discrepancies. This was particularly aimed at maintaining awareness among all students, including those potentially less engaged, who might overlook verbal and written announcements.\nEthical approval was sought from the host academic institution and awarded under reference #31848/2023.\n3.2 Data Collection and Analysis\nA mixed-method approach was adopted for this study to capture both comprehensive and detailed insights, utilizing a combination of a survey and follow-up in-depth semi-structured interviews. The survey was conducted initially to gather a general understanding of the students' perceptions regarding their use of GenAI tools in their projects. At the survey's conclusion, participants had the opportunity to provide their contact details if they were interested in further discussing their experiences through a semi-structured interview. This second phase was designed to go deeper into the survey findings, offering a platform for more detailed and nuanced insights.\nThirty-nine students consented to participate in the survey phase of our study. Within this cohort of survey participants, a demographic breakdown reveals a gender distribution wherein 77% identified as male, 18% as female, 2.5% as transgender, and 2.5% as non-binary. The cultural background of participants exhibited considerable diversity, with White British identified as the predominant category.\nFollowing the survey, eight students agreed to partake in the subsequent in-depth interviews, with seven identifying as male and one as female. Although a consistent interview guide was utilized across all sessions, the semi-structured nature of each discussion led to unique insights, because of the dynamic interaction between the interviewer and each participant. This method was particularly effective given the varied national and cultural backgrounds of the student body, enabling the collection of rich and diverse data that accurately reflected the personal contexts and experiences of the participants.\n3.2.1 Overview of survey and interview questions\nTo gain a well-rounded understanding of students' experiences with GenAI tools in their team projects, we developed surveys and interviews to complement each other. The survey questions (Table 1) aimed to gather wide insights into the integration of GenAI tools into coursework, their influence on programming skills, team dynamics, and the overall learning experience. Our survey combined multiple-choice options, Likert scales, and open-ended questions to gather qualitative data."}, {"title": "4 RESULTS", "content": "4.1 Quantitative Insights From Survey\nWe provide a summary of the survey results and some key insights, as the survey was used to inform the interview design. The full survey questions and results are provided in the supplementary materials.\nThe 39 respondents used a variety of GenAI tools (some using multiple tools), including: ChatGPT (33), GitHub Copilot (15), Google Bard (2), Microsoft Bing Chat (1), and 3 did not use any GenAI. When asked a related question about \"How often were you responsible for using AI in your team?\", we find a spectrum of usage (Figure 1) with most respondents occasionally using GenAI (44%).\nGenerally, the respondents had a slightly positive experience with GenAI (Q8, 3.64 average) and, in their view, its helpfulness was neutral in assisting writing code for their projects (Q9, 3.08 average) see Figure 2. However, the respondents were slightly more likely to recommend these GenAI tools to be considered for other courses.\nThe students were also asked to consider if the GenAI tools promoted critical thinking and problem solving (Q13), and whether the tools enabled them to complete the programming part of their work more efficiently (Q14) Figure 3. There is a clear spread of views, though in terms of critical thinking and problem-solving enhancement attributed to these AI tools, the majority, accounting for almost 53%, either agreed or strongly agreed. Although when asked if they agree or disagree that GenAI tools enabled them to \"complete the programming part more efficiently\", 77% of respondents either chose \"strongly agree\" or \"agree\"; 18% of the respondents perceived that these tools sometimes produce less than ideal code or do not yield comprehensive solutions, requiring subsequent edits."}, {"content": "4.2 Teamwork\nThe data highlights a generally positive impact of GenAI on team confidence, dynamics, and productivity. It also shed light on some of the difficulties that can result from using GenAI in a team setting.\n4.2.1 Bridging the skills gap and increasing the team's confidence.\nSome students viewed AI tools as enablers that bridged the skill gap between team members, thus allowing all team members to contribute effectively to the project (e.g. \"I think it made everyone seem to have an increased level of confidence, I think, in what level we could all complete the project...everybody has vastly different skill sets and it can sometimes be hard to manage that...But now that the AI is a thing, I feel like that gap [in experience in React] can now be bridged, because if you understand how to utilize the Al in an effective manner, it doesn't hinder you as much and you can still have a large contribution to the project...", "We were a little bit disheartened when we found out that one of our members wasn't going to do anything. But we were like, Oh, look, it's not that bad, especially with the Al tool now, we've got an idea of how to do this. So we don't really need them.": "I2). The overall effect was seen to bring a sense of calmness to teams believing that they can solve more challenging problems than before (\u201cI definitely noticed a difference as the project manager. People remained calm and knew that with ChatGPT, they could resolve errors or come up with new functions. It brought a sense of calmness, and they had confidence that ChatGPT could help solve any problem.\u201d, 13).\n4.2.2 Al as a team member\nOne mechanism in which GenAI contributed to such increased confidence and calmness is by playing the role of an additional team member whose contribution to the team can range from (1) doing tasks that other team members normally do, (2) to provide"}, {"title": "4.2.3 Improved the productivity of the team shifting its focus to the bigger picture, team skills, and testing", "content": "The different roles and levels of support that GenAI contributed to the team (as detailed in previous and upcoming sections) increased the teams' productivity giving them more space and capacity to focus on more the bigger picture behind the project (e.g., \"Now that Al was open to use, it helped us turn our small ideas into code. I could focus on the bigger ideas and didn't have to worry about the time-consuming little syntax and stuff. I could just focus on the big picture and start programming. I feel like it allowed our group to create a high-quality project compared to if we weren't allowed to use AI.\u201d, I3; and \u201cI think it was mainly used within the team to Build up... Boilerplate code... I think it just allowed us to focus more on the problems and developing features, things that you know, things that were important to us, and that we thought needed more development time", "They [the AI tools] have given us more time to focus on the development of documentation and team skills, which were core components of this module.": "S27), and design and testing (e.g. \"It has reduced the time needed for coding, allowing us to focus responsibility on other important issues such as design and testing.", "as the one managing everyone's code and branches, it was sometimes difficult to understand the code. People might have generated code with Al without fully comprehending it and treated it like a black box, saying, 'It's working, here it is.' So, I had to debug a lot of code that some people might not have understood or even created themselves, if that makes sense.": 13, "I found that often times the code provided by them [other team members] was not representing their skill set correctly and couldn't wrap my head around the mistakes in it, as I wasn't informed they're using AI. It slowed down our development and I don't think it helped anyone with their coding skills. I spent hours fixing code that was written by AI.\", S6; and \u201cOverall I believe they hindered my project, as many of my team members misunderstood how to utilize it properly. This resulted in subpar code that made no sense being present in the project that required amending later on\", S12).\"\n    },\n    {\n      \"title\": \"4.3 Supporting Learning\",\n      \"content\": \"\u201cI use Al a lot now every day, and I don't know how universities, schools, and the education system can continue as it is now. Almost every student, like 9 out of 10, is using AI and they can pass any exam and do anything with AI.": 13}, {"title": "4.3.1 Scaffolding", "content": "In addition to playing a role as a team member, GenAI played an educator role, providing scaffolding to support students in their learning and problem solving. This was a very popular theme with many examples of how Al supported the students allowing them to do things they could not have done by themselves without support - normally from teaching staff. One student gave an excellent example of how AI helped them stretch themselves within their Zone of Proximal Development (ZPD) without even knowing about this concept (\"Really have improved it as without the use of AI i wouldn't have stretched myself as far it allowed me to go beyond my normal comfort zones as i knew i had some help if i got stuck.", "I personally find AI tools very useful for programming, especially for software engineers. They can write programs for you, providing a steppingstone and a boost. For instance, they can help you grasp the basics, but beyond that, as things get more advanced, their assistance diminishes.\u201d, I7; and \u201cIt's like an assistant that can provide necessary help, and if used properly, they [students] can learn how to do it themselves, in the most efficient way, and won't need the AI tools anymore.\u201d, I2).\nThere are also many examples that talk about GenAI providing explanations and support in problem solving, frequently comparing it to human support. Below are just some of these examples": "n\"...when I didn't fully understand some of the logic schemas, we needed to design to explain our application's logic. The lecture presentation was okay, but I needed a bit of extra information. ChatGPT was helpful here... If I don't fully understand something, then I might use GPT to explain it to me or to provide me with ideas.", "else.": 13, "times.": "S12). This comment is interesting as the same student also commented that \"Whilst generative AI gave me a basic idea of how to achieve a certain task, it was often inconsistent with its answers. The answers were only useful a fraction of the time, and it gives wrong answers with full confidence."}, {"title": "4.3.2 Scaffolding: Learning from worked examples.", "content": "In our literature review, we looked at some work that explored the use of worked examples in programming education (e.g. [1, 55]) with [32] explicitly looking at GenAI's potential in this space. In examining our results, we identified repeated cases where the AI generated code is studied by the students as examples to learn from (e.g. \"It [Copilot] helps me improve my coding skills by providing better examples.", "I think if you take the time to try and understand the code that it's generating, and then even asking it to explain line by line what it's doing, you can develop a really strong understanding of exactly what is going on in each function and each file.": "I1; \u201cWhile you could simply copy and paste the code AI provides, to truly understand what it does and how to use it in future projects requires you to research the methods and classes it provides. Therefore, I think it is quite useful for learning... By asking AI to generate code, you need to understand it before you can implement it, which means learning new methods. This can solidify the knowledge in your mind.\u201d, I7; \u201cMakes learning easier by giving examples, and being able to describe what the code is doing", "Seeing the solutions and remembering what was suggested has taught me in the same way a teacher would.": "S16)."}, {"title": "4.3.3 Scaffolding: getting started", "content": "Another type of scaffolding mentioned by a few students, which builds on the previous two, is \u201chelp getting started\" (S4) on the project, or even a coding task. Depending on how this support is provided, this can fall under the 'partial-worked example' or 'completion examples' category, but in other cases it can be guidance or tips rather than code. Students repeatedly talked about GenAI providing help getting started and sometimes referring to its potential downsides (e.g. \"They give a place to start learning\""}, {"title": "4.3.4 Critical thinking and learning different ways of doing things.", "content": "In addition to scaffolding, another important potential support for learning is developing students critical thinking skills. Only one student explicitly commented on the support of GenAI for problem solving and analytical skills (\u201cProgramming generally builds up your problem-solving skills over time. If you're using AI properly, it's also going to build up your critical analysis skills. So, it's kind of a different skill that is being built up... If you're always thinking, 'What does this actually do?' when you look at code, and that's how Al is being taught in universities, then it could realistically enhance problem-solving skills", "point": "n\u201cIt can suggest different ways of doing things which you might not have thought of. Usually, it's not more efficient, but sometimes it is, and it can expand your knowledge through suggesting new syntaxes and new algorithms, etc., which might not have been in your comfort zone. It gives you the opportunity to expand and explore these hacks and codes and so on.", "problem.": "nd \u201cThey allowed me to find new approaches for completing tasks.", "function.": "S18).\n\"I learnt a lot about coding because often AI would suggest a more efficient way of writing code than the way I have wrote it by using new methods that I did not know."}]}