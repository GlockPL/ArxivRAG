{"title": "Pesti-Gen: Unleashing a Generative Molecule Approach\nfor Toxicity Aware Pesticide Design", "authors": ["Taehan Kim", "Wonduk Seo"], "abstract": "Global climate change has reduced crop resilience\nand pesticide efficacy, making reliance on syn-\nthetic pesticides inevitable, even though their\nwidespread use poses significant health and envi-\nronmental risks. While these pesticides remain a\nkey tool in pest management, previous machine-\nlearning applications in pesticide and agriculture\nhave focused on classification or regression, leav-\ning the fundamental challenge of generating new\nmolecular structures or designing novel candi-\ndates unaddressed. In this paper, we propose\nPesti-Gen, a novel generative model based on\nvariational auto-encoders, designed to create pes-\nticide candidates with optimized properties for\nthe first time. Specifically, Pesti-Gen leverages a\ntwo-stage learning process: an initial pre-training\nphase that captures a generalized chemical struc-\nture representation, followed by a fine-tuning\nstage that incorporates toxicity-specific informa-\ntion. The model simultaneously optimizes over\nmultiple toxicity metrics, such as (1) livestock\ntoxicity and (2) aqua toxicity to generate environ-\nmentally friendly pesticide candidates. Notably,\nPesti-Gen achieves approximately 68% structural\nvalidity in generating new molecular structures,\ndemonstrating the model's effectiveness in pro-\nducing optimized and feasible pesticide candi-\ndates, thereby providing a new way for safer and\nmore sustainable pest management solutions.", "sections": [{"title": "1. Introduction", "content": "Pesticides have been pivotal in global food security and\nagricultural productivity since their widespread adoption in\nthe mid-20th century. Their importance was underscored\nby Paul Hermann M\u00fcller's discovery of DDT's insecticidal\nproperties, a breakthrough that revolutionized pest control\n(M\u00fcller, 1948). Even today, pesticides remain a cornerstone\nin reducing crop losses. With estimates suggesting that, in\ntheir absence, key staple crops could experience up to a\n30% yield loss due to pests and pathogens, translating into\nhundreds of billions of dollars in global economic losses\n(Rizzo et al., 2021). Despite their undeniable benefits, the\nquest to develop safe and effective pesticides continues to\nface significant hurdles. Cross-resistance, toxicity, and un-\nintended ecological consequences persist as major concerns\n(Ara\u00fajo et al., 2023). These challenges are further high-\nlighted by regulatory bans such as those on imidacloprid\nand clothianidin between 2016 and 2018\u2014and by findings\nfrom the European Food Safety Authority (EFSA), which\nidentified neonicotinoids as posing substantial risks to pol-\nlinators, including both wild bees and honeybees (Ara\u00fajo\net al., 2023).\nIn addition to direct toxicity, the shifting landscape of global\nclimate change exacerbates the need for eco-friendly pes-\nticide solutions. Rising temperatures not only affect pest\nbehavior but also reduce the effectiveness and persistence\nof many pesticides (Hannigan et al., 2023; Iltis et al., 2022;\nRhodes & McCarl, 2020). Seminal studies demonstrate\nthat increased temperatures can diminish a chemical's resid-\nual activity, often necessitating more frequent reapplica-\ntion, thereby raising both economic and environmental\ncosts (Lichtenstein & Schulz, 1959; Walker & Eagle, 1983;\nNokes & Young, 1992; Garcia-Cazorla & Xirau-Vayreda,\n1994; Ahmad et al., 2003; Bailey, 2004). Although machine\nlearning has been widely used in pesticide and agricultural\nresearch-primarily for classification and regression tasks,\nsuch as predicting toxicity or categorizing pesticides (Anwar\n& Masood, 2023)\u2014these approaches have not yet tackled\nthe critical need to generate novel molecular structures or\ndesign new candidates.\nTo address the challenge of developing safer and more sus-\ntainable pesticides, we propose a novel generative frame-\nwork, Pesti-Gen. Specifically, our approach employs a two-\nstage learning process: first, pre-training on a large corpus of\ngeneral molecular structures to establish a comprehensive\nlatent space capturing broad chemical features; and sec-"}, {"title": "2. Related Work", "content": "Machine learning applications in agriculture have tradition-\nally focused on classification and detection tasks, particu-\nlarly in computer vision-driven research such as plant dis-\nsease identification or pest recognition (Anwar & Masood,\n2023). These approaches typically aim to enhance early de-\ntection and management strategies but often do not address\nthe inherent toxicity or environmental impact of pesticides.\nBeyond image-based tasks, other machine learning endeav-\nors center on pesticide classification and property prediction\nusing physicochemical or dissipation-related parameters.\nFor instance, Shen et al. (Shen et al., 2022) leveraged pre-\nviously reported pesticide data to perform classification\nbased on half-life, which is a vital measure influencing both\ntoxicity levels and recommended dosages. Similarly, Quan-\ntitative Structure-Activity Relationship (QSAR) techniques\n(Isarankura-Na-Ayudhya et al., 2009) and Structure Alerts\n(SA) models have been employed to predict toxicity, filter-\ning out chemically active structures likely to exhibit adverse\neffects. Ensemble-based methods have further improved\nthe accuracy and robustness of toxicity predictions (Kwon\net al., 2019). While these predictive and classification mod-\nels provide valuable tools for optimizing the use of existing\npesticides, they fall short in enabling the discovery of novel,\neco-friendly compounds.\nIn contrast, the drug discovery domain has seen signifi-\ncant advancements in methods for generating new small\nmolecules with desired properties, demonstrating the poten-"}, {"title": "3. Datasets", "content": "As no publicly available benchmarks or established small-\nmolecule datasets specifically designed for novel pesticide\ncandidate generation exist, we compiled a custom dataset\ntailored to this task. While datasets focusing on metrics\nsuch as half-life are available, our dataset uniquely incor-\nporates both livestock toxicity scores (based on LD50) and\naqua toxicity scores (based on LC50). This dataset includes\nthe molecular structures of relevant pesticides in SMILES\nformat alongside their corresponding toxicity scores, provid-\ning a resource for training and evaluating our model under\npractical constraints."}, {"title": "3.1. Limitation of Initial Half-Life Based Data", "content": "A common metrics used to evaluate the toxicity of pesti-\ncides and environmental risk indicators is half-life (the time\nrequired for a pesticide to degrade by half). Initially, the\ntraining dataset for Pesti-Gen was curated by focusing on\nhalf-life based on previous works, specifically by modify-\ning the dataset presented in the work of Shen et al. (Shen"}, {"title": "3.2. Custom Dataset Based on LD50 and LC50 Toxicity", "content": "As an alternative to resolve this variability, final training\npesticide dataset for Pesti-Gen was compiled based on\nLD50 and\nLC50, as these metrics introduce less variability\ncompared to environmental factors. LD50 (Lethal dose)\nrefers to the dose required to kill 50% of a population and\ncan be mathematically expressed as:\n$\\frac{LD_{50}}{W}= X $\nwhere LD50 is the lethal dose for 50% of the population,\nX is the amount of substance administered (in mg), and\nW is the body weight of the organism (in kg) (Damalas &\nEleftherohorinos, 2011). This LD50 metrics assesses risks\nto mammals and livestock. In addition to LD50, the dataset\nincorporates LC50 (Lethal Concentration 50), which mea-\nsures the concentration of a substance required to kill 50%\nof a test population in aquatic environments. It is expressed\nin units of mg/L over a specified exposure duration, typically\n48 hours:\n$LC_{50} = \\frac{M}{V}$\nwhere LC50 is the lethal concentration for 50% of the pop-\nulation, M is the mass of the pesticide (in mg), and V\nis the volume of the solution (in L). LC50 and Aquatic\nEcosystem Relevance: As outlined in the aqua ecotoxicity\nclassifications (RDA), the LC50 metric provides a critical\nunderstanding of how pesticides affect aquatic ecosystems."}, {"title": "3.3. Gyeonggi Province Pesticide Open Dataset", "content": "To curate a pesticide dataset that accurately accounts the\nLD50 metrics as toxicity measure, dataset from Gyeonggi\nProvince in Korea was referred\u00b9. The dataset was translated,\nand curated due to its valuable features. It provides detailed\nhuman/livestock toxicity and aqua ecotoxicity grades based\non LD50, with the human/livestock toxicity classifications\naligned with the WHO guidelines, ensuring reli-\nable and standardized risk assessments.\nAdditionally, the dataset provides geographic coordinates\n(latitude and longitude) for each entry, which are crucial\nfor agriculture-related studies where environmental fac-\ntors such as soil and temperature significantly influence\npesticide behavior. Moreover, the dataset also includes\nand offers a diverse pesticide formed in mixture form\n(e.g. Benzobicyclon+Pyrazosulfuron-ethyl+Pyriminobac-\nmethyl), including unique combinations, adding robustness\nand depth to the analysis. These attributes make it a highly\ncompatible for the purpose of our Pesti-Gen model, obtain-\ning stable metrics paired with diverse pesticide for training.\nIn detail, the curated custom dataset comprises 56, 360 data\npoints and 520 unique pesticides, significantly improving\nupon previous datasets, which included only 4513 data-"}, {"title": "3.4. Custom Dataset: \u2460 Livestock \u2461 Aqua Ecotoxicity", "content": "Relevant toxicity classification labels provided by the\nGyeonggi Province Pesticide Open Dataset were converted\nto numerical values for model training. Matching the guide-\nline range scale, the categorical classification metrics were\nmapped to numerical scales (e.g., 10 for livestock toxicity\nand 4 for aquatic toxicity) and subsequently normalized to\na scale of 0 to 1. For instance, pesticides classified as Class\nII for livestock toxicity were mapped to 100 and normalized\naccordingly, while aquatic toxicity classifications such as\nClass II and Class II S are mapped to the same number\nbecause Class II S is specific to the Korean ecosystem. The\nspecific mapping logic applied is as follows:\n\u2022 For livestock toxicity:\nHigh Toxicity (Class II): Mapped to 1000\nModerate Toxicity (Class III): Mapped to 100\nLow Toxicity (Class IV): Mapped to 10\nUnclassified: Mapped to 0\n\u2022 For aquatic toxicity:\nClass I: Mapped to 16 (highest risk to aquatic\necosystems)\nClass II and Class II S: Mapped to 4 (to account\nfor similar aquatic impact)\nClass III: Mapped to 1 (lowest risk)\nExempt: Mapped to 0\nAfter applying these mappings, the numerical values were\nnormalized using the formula:\n$Normalized \\: Value = \\frac{Value - Min \\: Value}{Max \\: Value - Min \\: Value}$\nThis process ensures that higher toxicity values remain pro-\nportional across both livestock and aquatic toxicity metrics,\nmaking them suitable for training a machine learning model.\nChemical names from the dataset were also mapped to their"}, {"title": "4. Methodology", "content": "In this section, we describe our two-stage training procedure\nfor Pesti-Gen, which aims to capture both general molecu-\nlar properties and specific pesticide toxicity measures. (1)\nDuring the first stage, the model learns a broad latent rep-\nresentation of SMILES structures; (2) in the second stage,\nthe learned representations are refined to explicitly incorpo-\nrate toxicity constraints. An overview of the framework is\nprovided in Figure 1."}, {"title": "4.1. Latent Space Training with VAE", "content": "Our Pesti-Gen model initially follows the architecture out-\nlined by G\u00f3mez et al. using a Variational Au-\ntoencoder (VAE) (Kingma, 2013)\ntrained on a large corpus of SMILES strings based on the\nZINC dataset. The dataset consists\nof 50,000 diverse molecular structures, all of which were\nspecifically utilized for training VAE model\u00b2. We trained\nthe model for 30 epochs with a learning rate of 5 \u00d7 10-5.\nThe primary objectives in this stage are: \u2460 SMILES Re-\nconstruction: Learning to accurately encode and decode\nmolecular representations; \u2461 Latent Space Structuring:\nCreating a continuous and meaningful latent embedding that\ncaptures key chemical features.\nThe training process simultaneously minimizes both the\nreconstruction loss and the KL divergence, as defined by the\nfollowing loss function:\n$Lpretrain = Eq$(z|x) [-log po (x | z)] + KL (qq(z | x) ||p(z)),\nwhere q(z | x) represents the encoder modeling the varia-\ntional posterior distribution, pe (x | z) is the decoder mod-\neling the reconstruction likelihood, and p(z) is the prior\ndistribution over latent variables, typically assumed to be\nN(0, 1).\nThe reconstruction loss encourages accurate decoding of\ninput SMILES from latent representations to ensure chem-\nical plausibility, while the KL divergence regularizes the\nlatent space by aligning it with the prior distribution, ensur-\ning smoothness and meaningful sampling. This combined\noptimization enables the VAE to proficiently tokenize and\nreconstruct SMILES while creating a structured latent space,\nlaying the foundation for fine-tuning on toxicity-based con-\nstraints."}, {"title": "4.2. Fine-Tuning on Target Properties", "content": "Building upon the general-purpose latent space developed in\nStage 1, we fine-tune the Pesti-Gen to align with pesticide-\nspecific toxicity metrics using dataset as described in Sec-\ntion 3.3. In particular, we incorporate both livestock and\naqua ecotoxicity levels. Collectively, these provide a quan-\ntitative indicator of the environmental risks posed by the\ngenerated molecules.\nPartial Freezing and Decoder Enhancement. To pre-\nserve the broad chemical representations learned previously,\nwe fix the encoder parameters, denoted by e. Concretely,\nlet\n$0 = arg min Lpretrain,$\nwhere Lpretrain is the original VAE objective (e.g., recon-\nstruction plus KL divergence) minimized during the first\ntraining stage. These parameters \u03b8 remain frozen, thereby\nretaining the learned latent space structure. We then fine-\ntune the decoder with updated parameters 0, introducing\nnew layers specifically handling the toxicity features:\n$\\theta'd arg min C_{recon} + \\alpha L_{toxicity}^{(livestock)} + \\beta L_{toxicity}^{(aqua)}.$"}, {"title": "Latent Noise Injection", "content": "To improve robustness and en-\ncourage smoother latent representations", "vector": "nz' = Z + \u20ac, \u03b5 ~ \u039d(0, \u03c3\u00b2\u0399),\nwhere o is the noise level and I is the identity matrix. Train-"}]}