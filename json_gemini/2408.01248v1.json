{"title": "Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system", "authors": ["Li Dong", "Feibo Jiang", "Minjie Wang", "Yubo Peng", "Xiaolong Li"], "abstract": "The intelligent reflection surface (IRS) and un- manned aerial vehicle (UAV)-assisted mobile edge computing (MEC) system is widely used in temporary and emergency scenarios. Our goal is to minimize the energy consumption of the MEC system by jointly optimizing UAV locations, IRS phase shift, task offloading, and resource allocation with a variable number of UAVs. To this end, we propose a Flexible REsource Scheduling (FRES) framework by employing a novel deep progressive reinforcement learning which includes the following innovations: Firstly, a novel multi-task agent is presented to deal with the mixed integer nonlinear programming (MINLP) problem. The multi-task agent has two output heads designed for different tasks, in which a classified head is employed to make offloading decisions with integer variables while a fitting head is applied to solve resource allocation with continuous variables. Secondly, a progressive scheduler is introduced to adapt the agent to the varying number of UAVs by progressively adjusting a part of neurons in the agent. This structure can naturally accumulate experiences and be immune to catastrophic forgetting. Finally, a light taboo search (LTS) is introduced to enhance the global search of the FRES. The numerical results demonstrate the superiority of the FRES framework which can make real-time and optimal resource scheduling even in dynamic MEC systems.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, computation-intensive applications such as virtual reality (VR) and augmented reality (AR) have grown rapidly, which makes the user equipment (UE) difficult to process these tasks locally. Mobile edge computing (MEC) addresses this issue by relocating computing and commu- nication services closer to users, enabling UEs to offload computation-intensive tasks to nearby MEC servers. This offloading alleviates the computational burden and reduces the energy consumption of UEs [1]. However, deploying fixed MEC servers in terrestrial areas may not be considered economically viable, especially in temporary situation [2]. Unmanned aerial vehicles (UAVs) are designed to be highly maneuverable, allowing them to navigate through tight spaces, fly at low altitudes, and perform precise aerial movements [3]. UAV-assisted MECs have been proposed to provide computation and communication services to ground UEs seamlessly and proficiently. Whereas the wireless chan- nels between UAVs and terrestrial UEs may be blocked by trees or high buildings. Recently, the intelligent reflecting surface (IRS) [4] has been proposed and received considerable attention. The quality of signal transmission can be improved by laying IRS on the surface of high buildings. Since each component in IRS can reflect the transmission signal, the transmission data rate can be greatly improved. In addition, the reflective elements of the IRS are generally passive, and the reflected signal does not require any signal processing capacities, which is more energy-efficient than the traditional transmission technologies. In UAV-assisted MEC systems, the IRS can be attached on the buildings or on the high places to enhance the channel between the UAV and UEs when the connections are blocked by buildings in temporary and emergency scenarios. Although IRS and UAV-assisted MEC is promising, some challenges should be addressed. First, with the increase of UEs, a single UAV may not be sufficient to support a large number of computing tasks, and multiple UAVs may require to be deployed. However, with the changing number of UAVs and UEs, the communication environment is expected to become increasingly complex. Second, in the wireless fading environ- ment, the wireless channel conditions which may change with time, can affect the resource scheduling of MEC systems [5], especially considering the IRS in the MEC system. Third, the offloading decision is generally an integer variable, and the resource allocation is the continues variable. It is an over- all mixed integer nonlinear programming (MINLP) problem, which is difficult to be addressed by traditional methods. To address the above challenges, in this paper, we consider the MEC system assisted by IRSs and UAVs in the dynamic environment. Our objective is to design a deep progressive reinforcement learning based Flexible REsource Scheduling (FRES) framework to minimize the energy consumption of the MEC system with a variable number of UAVs. This problem requires not only a transfer learning method without catas-"}, {"title": "II. RELATED WORK", "content": "In [6], the authors proposed the MEC system with multiple ground servers and an air server. In order to achieve the maximum calculation rate, the author optimized the trajectory of the UAV and the offloading of each user task. The work in [7] introduced a single UAV-assisted MEC system, in which the UAV was used to collect the data of users on the ground, and the energy consumed by the UAV was minimized by optimizing the trajectory of the UAV. The work in [8] con- sidered a framework in which UAVs were used to assist users in task processing. In order to make all users consume the lowest energy when processing tasks, the authors optimized the trajectory and allocated resources of the UAV. The work in [9] proposed a UAV-assisted MEC system based on DRL. The users offloaded the tasks that need to be processed in the UAV to improve the computing efficiency. This method realized the offloading decision and resource allocation under the time-varying channel. The work in [10] proposed a MEC system containing multiple UAVs and the number of UAVs was reduced as much as possible while meeting the constraints. In this work, the system energy consumption was minimized by optimizing the offloading decision and resource allocation of user tasks.\nIn [11], in order to improve the quality of the transmission channel, a low-altitude passive relay system was established using IRS-assisted UAV to convert the Rayleigh fading chan- nel into the Rician fading channel to improve the transmission performance. In [12], the author proposed a radio system in which the UAV's signal was reflected to the base station (BS) by IRSs, and the weighted sum rate of all IRSs was maximized by optimizing the trajectory of the UAV and the phase shift matrix of the IRSs. In [13], the author proposed a multi- IRS-assisted UAV system, which improved the user's received power by continuously adjusting the trajectory of the UAV and the beamforming of the IRS. In [14], with the help of the IRS component, the author improved the communication quality between the UAV and the users by adjusting the trajectory of the drone and the phase shift matrix of the IRS. An IRS- assisted UAV communication system was studied in [15]. In order to increase the average transmission rate of the system, the phase shift matrix of the IRS and the trajectory of the UAV were jointly optimized.\nAt present, there are many related works that formulated the resource scheduling in the MEC system as a MINLP problem, and adopted some traditional solutions to solve it. In [16], the author proposed a dynamic programming algorithm to allocate bandwidth and computing resources for mobile devices to minimize the energy consumption. In [7], the successive convex approximation (SCA) algorithm was used to optimize the resource allocation, and the energy efficiency of the UAV in the MEC system is maximized. In [17], the block coordinate descent method and the successive convex approximation algorithm were used to optimize the resource scheduling problem in the cellular connected UAV system. In [18], the author proposed a heuristic algorithm named GAWOA on the basis of genetic algorithm (GA) and whale op- timization algorithm (WOA) to solve the resource scheduling problem in the MEC system. In [19], a hierarchical GA and particle swarm optimization (PSO) based computing algorithm was designed to solve the resource scheduling problem in the MEC system.\nThere are also some related works that used deep learning to implement resource scheduling in the MEC system. In [20], a DRL-based resource scheduling method was proposed. The author reduced the state space of DRL by compressing channel quality information, and proposed adaptive iteration to improve the search efficiency in the DRL. In [21], a resource scheduling framework based on distributed network structure"}, {"title": "III. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "We consider the IRS and UAV-assisted MEC system, as shown in Fig. 1, which consists of N UEs, L IRSs, some UAVs and a central cloud. All UEs are randomly distributed and all IRSs are mounted on buildings. The set of UEs is denoted as N = {1,2,..., N}, the set of UAVs is denoted as M = {1,2,..., M} and the set of IRSs is denoted as L = {1,2,..., L}. The central cloud is utilized to gather all system information, encompassing channel state information, UAV information, IRS information, and task-related informa- tion from UEs. By deploying the DRL model on the central cloud, the task offloading and resource scheduling for the MEC system are executed.\nEach UE has the option to either offload its entire task to a single UAV or execute it locally. We employ the notation aio to indicate that a task is executed locally, and aij to signify that a task is offloaded to the jth UAV. Consequently, we can establish the following constraints:\n\\(a_{i0} = \\{0,1\\}, \\forall i \\in N\\) (1)\n\\(a_{ij} = \\{0,1\\}, \\forall i \\in N, \\forall j \\in M\\) (2)\nwhere a20 = 1 signifies that the ith UE chooses to execute the task locally. Otherwise, aio = 0. Similarly, aij = 1 implies that the ith UE wants to offload its task to the jth UAV, while aij = 0 indicates otherwise. Each UE can choose only one location for task execution, we are led to establish the following constraint:\n\\(a_{i0} + \\sum_{j \\in M} a_{ij} = 1, \\forall i \\in N\\). (3)\nWe assume that each UE has a computationally intensive task Ui which can be expressed as follows:\n\\(U_i = (R_i, F_i), \\forall i \\in N\\) (4)\nwhere Ri denotes the volume of data that is required to be transmitted to the UAV for task execution, while Fi signifies the cumulative number of required CPU cycles for task computation."}, {"title": "B. Communication Model", "content": "We assume that UEs are situated in a bustling urban center with numerous tall buildings. In such an environment, the direct link to the UAVs may be obstructed, leading to severe path loss. However, by deploying IRSs on these building surfaces, we can enhance the communication quality between UEs and UAVs. Each IRS is assumed to have multiple re- flecting elements, denoted as K = {1,2,..., K}, and only one IRS is utilized to assist each UE in communication. The ; and coordinates of the ith UE can be represented as (x, y, z);\nthose of the lth IRS can be represented as (x, y, z); and those of the jth UAV can be represented as (x, y, z). Therefore, we calculate the distance between the ith UE and the lth IRS as follows:\n\\(R_{i,l}^2 = \\sqrt{(x_i - x_l)^2 + (y_i - y_l)^2 + (z_i - z_l)^2}\\). (5)\nSimilarly, the distance between the lth IRS and jth UAV is expressed as\n\\(R_{lj}^V = \\sqrt{(x_l - x_j)^2 + (y_l - y_j)^2 + (z_l - z_j)^2}\\). (6)\nWe consider that the communication path between the ith UE and the jth UAV is divided into two segments: the UE- IRS link and the IRS-UAV link. We also assume that each UE only uses one IRS for signal transmission, so that the"}, {"title": "C. Computation Model", "content": "The energy consumption of the local computing can be expressed as follows:\n\\(E_i^L = \\nu_1 (f_{i0})^{\\tau_1 -1} F_i, \\forall i \\in N\\) (12)\nwhere fio is the local computation capacity of the ith UE. V1 \u2265 0 is the effective switched capacitance and T\u2081 \u2265 1 is the positive constant.\nThe computation capacity of the ith UE is constrained by:\n\\(a_{i0} f_{i0} \\leq F_{i,max}^L, \\forall i \\in N\\) (13)\nwhere \\(F_{i,max}^L\\) means the maximum local computation capacity of the ith UE.\nThe energy consumption in remote computing phase is\n\\(E_{ij}^R = \\nu_2 (f_{ij})^{\\tau_2 -1} F_i\\) (14)\nwhere fij means that the computing resource allocated by the jth UAV to the ith UE. V2 is the effective switched capacitance and T2 \u2265 1 is the positive constant.\nSince each UAV has a limited computation capacity, we can represent the constrained computation resource of the jth UAV as follows:\n\\(\\sum_{i \\in N} a_{ij} f_{ij} \\leq F_{j,max}^R, \\forall j \\in M\\) (15)\nwhere \\(F_{j,max}^R\\) is the total computation capacity of the jth UAV."}, {"title": "D. UAV Hover Model", "content": "When the jth UAV hovers to receive and perform offloaded tasks, the transmission time of the offloaded task can be expressed as:\n\\(T_{ij}^t = \\frac{R_i}{r_{ij}}, \\forall i \\in N, \\forall j \\in M\\) (16)\nThe execution time of the offloaded task can be expressed as:\n\\(T_{ij}^c = \\frac{F_i}{f_{ij}}, \\forall i \\in N, \\forall j \\in M\\) (17)\nHence, the energy consumption associated with UAV hov- ering is given by\n\\(E_j^h = P_h max\\{a_{ij} (T_{ij}^t + T_{ij}^c)\\}, j \\in M\\) (18)\nwhere Ph means the hover power of the jth UAV."}, {"title": "E. Problem Formulation", "content": "In this study, our objective is to minimize the energy consumption of the IRS and UAV-assisted MEC system. The optimization problem can be summarized as follows:\n\\(P0: \\min_{L,A,F,O} \\sum_{i \\in N} \\alpha a_{i0} E_i^L + \\sum_{j \\in M} a_{ij} E_{ij}^R + \\sum_{j \\in M} (E_j^t + E_j^h)\\) (19)\ns.t. (1), (2), (3), (13), (15)."}, {"title": "IV. THE FRES FRAMEWORK", "content": "Problem PO is a typical MINLP, where A are binary vari- ables, and L, F and are real positive variables. This makes the Problem PO non-smooth and non-differential. Moreover, there are still three challenges for solving Problem P0: (1) It is a large-scale optimization problem with many variables, the search is easy to trap into the local minimum. (2) In the system, the number of UAVs is varying, so the prior knowledge is hard to be reused to solve the problem in the dynamic environment. (3) It needs to design a real-time resource scheduling with low computational complexity for the wireless fading channel.\nTo this end, we propose a deep progressive reinforcement learning based FRES framework to address the above chal- lenges. First, we present a model free DRL-based resource scheduling structure, which can learn from the environment by the interaction between the agent and the MEC system without any prior information. After the agent of DRL is well trained, the agent can make real-time decision easily by doing some simple algebraic calculations instead of solving the original PO repeatedly. Second, we propose a multi-task agent with two-head structure to solve the MINLP directly. Third, we consider a progressive scheduler to adjust structure of the agent for adapting the varying number of UAVs, which can add or remove a part of neurons in the agent to trace the dynamic environment. This structure is resistant to catastrophic forget- ting. Finally, we introduce an action refinement to enhance the exploration, in which a LTS guided by channel gains is designed to jump out of the local minimum and accelerate the policy search in large action space.\nThe dataflow of the FRES framework can be described as follows: first, the central cloud collects the global environ- ment information as well as task information from the MEC system. Then, the central cloud executes the FRES algorithm, updates the locations of UAVs and the phase-shifted diagonal matrix of IRSs, and performs the online decisions of the user association and resource allocation for each UE. Finally, based on the decision received from the central cloud, each UE can offload the task to the suitable UAV, and then receive results accordingly."}, {"title": "A. Algorithm Overview", "content": "The details of the FRES framework are described in Algo- rithm 1. We first introduce a quantitative passive beamforming (QPB) method to solve Ot according to the positions of UAVs and UEs. Then, we design a model-free DRL to generate At and Ft of all UEs at tth timeslot. Next, we introduce the state, action, and reward of the DRL in the FRES framework as follows:"}, {"title": "B. QPB", "content": "We introduce the QPB method to optimize the phase shift matrix of IRSs [23]. Due to hardware facility restrictions, the IRS can only reflect signals with certain phase shifts. For simplicity, we consider discrete phase shift angles in this paper, the phase shift Ok,i,l,j of the IRS is chosen from the following set of phase shift values: \u03a8 = {\\( \\frac{2 \\pi}{N_p} i, i=0,1,...,N_p - 1\\)}, where Np denotes the number of the phase shift values that can be selected for every element. We optimize the phase shift Ok,i,l,j of the kth reflecting element in the lth IRS between the ith UE and the jth UAV with the following equation:\n\\(\\Theta_{k,i,l,j}^{RV} = argmin_{\\Theta_{ki} \\in \\Psi} | \\omega_{k,i,l}^{UR} - (\\theta_{k,i,l}^{UR} + \\theta_{l,k}^{RV}) |\\) (20)\nwhere \\(\\omega_{k,i,l}^{UR}\\)\u2208 [0,2\u03c0) denotes the phase shift of the kth reflecting element from the ith UE to the lth IRS, and \\(\\omega_{l,k}^{RV}\\)\u2208 [0,2\u03c0) denotes the phase shift of the kth reflecting element from the lth IRS to the jth UAV."}, {"title": "C. Multi-task Agent", "content": "Multi-task learning is a machine learning method that puts multiple related tasks together to learn [24]. In the learning process, these tasks share parameters of the shallow part of the deep neural network (DNN) to extract the common features and then adjust the independent parameters of the subsequent part of the DNN to learning the unique features of each task respectively. The whole multi-task agent includes four part: input layer, shared layer, standalone layer and output layer, which are shown in Fig. 3.\nAs depicted in Fig. 3, the multi-task agent consists of Q shared layers, and P standalone layers for each specific task. The output from the qth shared layer can be characterized as follows:\n\\(o_q = \\sigma(w_q o_{q-1} + b_q)\\) (21)\nwhere wq and bq represent the weights and biases of the qth shared layer, respectively. \u03c3(.) is the activation function.\nWe can express the output from the pth standalone layer of the jth task as follows:\n\\(o_{j,Q+p} = \\sigma (w_{j,Q+p} o_{j,Q+p-1} + b_{j,Q+p})\\). (22)"}, {"title": "D. Progressive Scheduler", "content": "Progressive learning was first proposed by Google Deep- Mind [25], which was a novel knowledge transfer method based on continual learning [26]. With the help of the previous knowledge of the old task, the new task can be trained relatively quickly, and the parameters of the old tasks will not be forgotten. When the old task needs to be carried out again, the new knowledge will be forgotten and the old model parameters can be directly recalled to process it without retraining over again.\nThe system model considered in this paper is a dynamic model with different number of UAVs when the environment varies. However, the structure of traditional neural network is stationary, when the number of UAVs changes, the structure of the neural network should be adjusted and the network should be retrained again for adapting the changes in the environment. We design a new progressive scheduler for the multi-task agent to address this challenge, in which we can adjust the structure of the neural network to trace the dynamic environment and we can add or remove a part of the neurons to adapt the change of UAV numbers. The process of dynamically adjusting the neurons using the progressive scheduler for different numbers of UAVs is illustrated in Fig. 4."}, {"title": "E. LTS", "content": "Since the action space of our DRL framework is large and dynamic, the DRL is hard to converge in the action space. Action refinement has proven to be an effective global search strategy when dealing with large-scale action spaces in DRL [27]. Based on taboo search [28], we propose an LTS algorithm to implement action refinement. The details of the LTS are described as follows:\n1) Solution representation: The solution in taboo search is encoded as a vector x = (A,F), where A represents the user association, and F denotes the resource allocation. The initial solution x = (Ao, Fo) is acquired from the multi-task agent.\n2) Evaluation function: We define the evaluation function of the taboo search as:\nmin f (x) : x \u2208 D (30)\nwhere f (\u00b7) is the minimum energy consumption function in the current scenario which can be expressed as Eq. (19), D is"}, {"title": "V. EXPERIMENTAL RESULTS", "content": "The simulation parameters of the FRES framework are chosen as follows: The number of UEs is set to 50, and the number of IRSs is also set to match the number of UEs. The initial multi-task agent consists of two shared layers with 64 and 128 neurons, respectively. Both the fitting head and classification head are configured with 32 neurons [2]. For progressive scheduler, we adjust each layer by adding or removing up to 16 neurons for each UAV. For the LTS, we set the taboo list length to 5 with a maximum iteration number capped at 10. Unless otherwise stated, all other parameters employed are summarized in Table II [2], [29], [30]. The simulations are executed in an environment powered by an Intel Xeon CPU, supplemented with 32GB RAM, and a Tesla T4 GPU with 15GB RAM."}, {"title": "VI. CONCLUSION", "content": "In this paper, we propose a deep progressive reinforcement learning based FRES framework to minimize the energy consumption of all the UEs by optimizing offloading decision and resource allocation in IRS and UAV-assisted MEC system. The FRES framework includes three important parts: 1) the multi-task agent is presented to solve the offloading decision task and the resource allocation task at the same time; 2) the progressive scheduler is used to achieve quick reaction for the dynamic environment with the changing number of UAVs; 3) the LTS is applied to enhance the exploration of the DRL. The simulation results show that the FRES framework can achieve the best performance in IRS and UAV-assisted MEC system with varying number of UAVs.\nDespite the contributions of the proposed method, there is also a downside that can serve as a basis for future research. When the number of UAVs increases, the number of parameters in the multi-task agent is also growing. This growth can be addressed by pruning, quantization and compression for the network structure of the agent during the learning process."}]}