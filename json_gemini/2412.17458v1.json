{"title": "Progressive Boundary Guided Anomaly Synthesis for Industrial Anomaly Detection", "authors": ["Qiyu Chen", "Huiyuan Luo", "Han Gao", "Chengkan Lv", "Zhengtao Zhang"], "abstract": "Unsupervised anomaly detection methods can identify surface defects in industrial images by leveraging only normal samples for training. Due to the risk of overfitting when learning from a single class, anomaly synthesis strategies are introduced to enhance detection capability by generating artificial anomalies. However, existing strategies heavily rely on anomalous textures from auxiliary datasets. Moreover, their limitations in the coverage and directionality of anomaly synthesis may result in a failure to capture useful information and lead to significant redundancy. To address these issues, we propose a novel Progressive Boundary-guided Anomaly Synthesis (PBAS) strategy, which can directionally synthesize crucial feature-level anomalies without auxiliary textures. It consists of three core components: Approximate Boundary Learning (ABL), Anomaly Feature Synthesis (AFS), and Refined Boundary Optimization (RBO). To make the distribution of normal samples more compact, ABL first learns an approximate decision boundary by center constraint, which improves the center initialization through feature alignment. AFS then directionally synthesizes anomalies with more flexible scales guided by the hypersphere distribution of normal features. Since the boundary is so loose that it may contain real anomalies, RBO refines the decision boundary through the binary classification of artificial anomalies and normal features. Experimental results show that our method achieves state-of-the-art performance and the fastest detection speed on three widely used industrial datasets, including MVTec AD, VisA, and MPDD. The code will be available at: https://github.com/cqylunlun/PBAS.", "sections": [{"title": "I. INTRODUCTION", "content": "ANOMALY detection aims to identify unseen data points that deviate from the normal data distribution. Recently, it has been widely applied in various domains, including industrial inspection [1]\u2013[3], medical diagnosis [4]\u2013[6], and video surveillance [7]\u2013[9]. In the field of industrial inspection, anomalies typically refer to various types of surface defects on products, such as scratches, cracks, and stains. However, it is challenging to collect all defect patterns in real-world applications for supervised learning. Additionally, the cost of precise pixel-level annotations for guiding anomaly localiza-tion is prohibitively high. Therefore, unsupervised anomaly detection (UAD) is crucial for identifying defective products in manufacturing processes."}, {"title": "II. RELATED WORK", "content": "In this section, we review the typical and SOTA methods for unsupervised anomaly detection. The existing methods can be divided into three categories. In brief, reconstruction-based methods aim to reconstruct the input data from the latent space, while embedding-based methods aim to learn the embedding space for the input data [24]. Based on these two frameworks, synthesis-based methods aim to synthesize artificial anomalies to assist in the training of models."}, {"title": "A. Reconstruction-based Methods", "content": "Reconstruction-based methods have been widely explored in anomaly detection. It is assumed that the model can properly reconstruct normal samples, while it fails to do so for anomalies. The key to these methods is to detect anomalies by analyzing the residual images before and after reconstruction. The Autoencoder (AE) [25] is a classic model widely used for image reconstruction tasks. Several studies [26]\u2013[28] employ feature reduction and sparse representation methods to compress the latent representations of AEs, achieving more stable reconstruction results. However, since AEs have never trained on real anomalies, the assumption that anomalous regions will not be accurately reconstructed does not always hold. To address this issue, several methods [10]\u2013[12] randomly remove some patches, and reconstruct the missing information through inpainting. Given the superior reconstruction capability of generative models, Generative Adversarial Networks (GANs) [29] and Variational Autoencoders (VAEs) [30] are commonly used frameworks for reconstruction-based models. Several works [31]\u2013[33] train GANs through adversarial learning, using the reconstruction error of the generator to detect anomalies. Similarly, several papers [34]\u2013[36] train VAEs to model the distribution of normal samples in latent space, using the reconstruction error of decoder to detect anomalies. However, these methods heavily rely on the quality of reconstructed images, which faces challenges in difference analysis."}, {"title": "B. Embedding-based Methods", "content": "Embedding-based methods have demonstrated outstanding performance in anomaly detection and localization, becoming increasingly prevalent in recent years. These methods utilize pretrained networks to extract features and compress normal features into a compact space. Consequently, anomaly features are distinctly segregated from normal clusters within the feature space. The key to these methods is to detect anomalies by calculating the distance between the representations of test images and normal clusters. First, Knowledge Distillation (KD) methods exploit the disparity in anomaly detection capability between teacher and student networks. To learn a more robust and generalizable representation, MKD [37] and GLCF [38] employ feature distillation at various layers from the teacher network to the student network. Since structurally similar teacher-student networks can hinder the diversity of anomalous representations, RD4AD [14] and ADPS [39] adopt an asymmetrical \u201creverse distillation\" paradigm. Specifically, ADPS concatenates spatial attention-weighted [40] teacher features with decoded student features to achieve more precise anomaly segmentation. To further enhance inference speed, EfficientAD [41] refines the architecture of teacher network with efficient feature extractor. Second, memory bank methods store representative normal features and detect anomalies through the distance between test samples and memorized samples. PaDiM [42] memorizes the multivariate Gaussian distributions of normal patch embeddings and calculates the anomaly score by Mahalanobis distance. However, PaDiM stores a specific distribution for each patch position. As Patch-Core [1] generally stores patches from all positions through the greedy coreset mechanism, it reduces reliance on image alignment. PNI [43] further integrates position and neighborhood information into the inference stage of PatchCore. Third, normalizing flow methods [44]\u2013[46] aim to transform the distribution of normal samples into a standard Gaussian distribution, resulting in anomalies exhibiting low likelihood. Finally, one-class classification methods constrain the implicit classification boundaries of normal features by designing loss functions. A primary paradigm of these methods is to construct decision boundaries that encompass typical normal samples and detect anomalies by measuring the distance between test samples and the normal center. SMCC [15] utilizes a Gaussian mixture model to obtain cluster centers. NoCoAD [47] improves the optimization objective by leveraging well-designed norm based on Deep Support Vector Data Description (Deep-SVDD) [48]. To address the singular training objective of Deep-SVDD, CFA [13] searches hard negative features from normal samples to perform contrastive supervision. Despite achieving superior performance, these models have only been exposed to normal samples.\""}, {"title": "C. Synthesis-based Methods", "content": "Synthesis-based methods treat anomaly synthesis as data augmentation for normal samples, integrating this strategy into reconstruction-based and embedding-based frameworks. Anomaly detection models trained solely on normal samples lack the ability to learn anomalous distribution. Leveraging the reconstruction-based framework, most methods synthesize anomalies at the image level to assist training in a self-supervised manner. Some works [16]\u2013[20], [49]\u2013[52] follow a common paradigm of synthesizing anomalies by creating binary masks using Perlin noise [53] and filling them onto normal images with various textures from auxiliary datasets. To avoid introducing auxiliary images, Yan et al. [54] directly adds random noise to the entire images to simulate anomalies. However, synthesizing anomalies at the image level requires manually predefining the visual properties of anomalies. Without the need for explicit visual guidance, DSR [55] and IGD [56] synthesize anomalies in feature space through vector replacement and vector weighting. Leveraging the embedding-based framework, several studies [57]\u2013[59] using image-level anomaly synthesis follow the same common paradigm described above. CutPaste [60] and Pull&Push [61] employ a direct approach by cutting normal regions and pasting them at random positions. To improve the unnaturalness of direct overlay, NSA [62] uses Poisson image editing to seamlessly blend various images. AnomalyDiffusion [63] and RealNet [64] utilize the diffusion model [65] to synthesize anomalies that are more realistic. Unlike the aforementioned image blending, CDO [66] and RD++ [67] add random noise within rectangular masks. Nevertheless, more realistic image-level anomaly synthesis requires significant computational resources, which greatly affects training speed. In contrast, feature-level anomaly synthesis is more efficient because it is straightforward and does not require repeated feature extraction. UniAD [21] and SimpleNet [22] synthesize feature-level anomalies by adding Gaussian noise to the normal features. To enhance the detection of weak anomalies, GLASS [68] further refines the noise distribution by adversarial learning. However, these methods only cover a fixed range of anomalies in random directions, which may fail to capture useful information and lead to significant redundancy. In contrast, our proposed method, PBAS, introduces a novel feature-level anomaly synthesis strategy that efficiently generates anomalies with directional guidance and self-adaptive lengths, offering more control and effectiveness than existing methods that rely on predefined textures or simple noise."}, {"title": "III. PROPOSED METHOD", "content": "The overall architecture of the proposed PBAS is shown in Fig. 3. During the training stage, PBAS consists of three core components: ABL, AFS, and RBO. The ABL module (Section III-C) employs a feature extractor $E_{\\varphi}$, a feature projector $P_{\\theta}$, and a center initializer $C_{\\varphi,0}$ to learn an approximate boundary of normal images. The backbone of $E_{\\varphi}$ (Section III-B) is pretrained on ImageNet and kept frozen. $P_{\\theta}$ within $C_{\\varphi,0}$ is only frozen at the initialization stage, while it becomes trainable afterward. The AFS module (Section III-D) takes the normal and center feature outputs from ABL as inputs and is designed to synthesize anomaly features self-adaptively, guided by the hypersphere distribution of normal features. The RBO module (Section III-E) takes the normal and anomaly feature outputs from AFS as inputs and utilizes a pair of discriminators $D_{\\psi}$ to refine the boundary. These two $D_{\\psi}$ are trainable and share the same weights. PBAS is trained in a multi-task learning manner with three loss functions from ABL and RBO. At the inference stage (Section III-F), only the feature extractor $E_{\\varphi}$ and the feature projector $P_{\\theta}$ from ABL, along with the discriminator $D_{\\psi}$ from RBO, are used."}, {"title": "B. Feature Extraction with Pretrained Model", "content": "The pretrained networks can be utilized to extract features from different scales and channels. In this paper, we employ the ResNet-like backbone $\\phi$ pretrained on ImageNet with frozen parameters. The training set $X_{train}$ for anomaly detection tasks only contains normal images. During the training phase, normal images $x_i$ are first fed into the backbone of the feature extractor $E_{\\phi}$ to obtain pretrained features $\\phi_{i,j} = E_{\\phi_j}(x_i) \\in \\mathbb{R}^{H_j \\times W_j \\times C_j}$ at different hierarchy levels $j$. The feature point at location $(h, w)$ is denoted by $\\phi_{i,j}^{h,w} \\in \\mathbb{R}^{C_j}$. The relationship of this vector to the feature map $\\phi_{i,j}$ is:\n$$\n\\phi_{i,j} = \\{ \\phi_{i,j}^{h,w} | h \\in [1,..., H_j], w \\in [1,..., W_j] \\}\n$$\nTo increase the receptive field size and robustness to small spatial deviations, pretrained features are then aggregated through adaptive pooling [1]. The location set of neighborhood vectors associated with $\\phi_{i,j}^{h,w}$ is:\n$$\nN_{h,w} = \\{ (a,b) | a \\in [h - \\frac{p}{2}, ...,h + \\frac{p}{2}], b \\in [w - \\frac{p}{2}, ..., w + \\frac{p}{2}] \\}\n$$\nwhere $p$ denotes the neighborhood size. Hence, the neighbor-hood aggregation vectors $\\mathcal{S}_{i,j}^{h,w}$ can be expressed as:\n$$\n\\mathcal{S}_{i,j}^{h,w} = f_{agg}(\\{\\phi_{i,j}^{(a, b)} | (a, b) \\in N_{h,w} \\})\n$$\nwhere $f_{agg}$ represents adaptive pooling that integrates the local feature patch into a single feature point.\nUsing multilevel concatenation $f_{concat}$ to capture low-level and high-level features, we obtain the dispersed feature:\n$$\nt_i = E_{\\varphi}(x_i) = f_{concat}(\\{f_{resize}(\\mathcal{S}_{i,j}) | j \\in J\\})\n$$\nwhere $J$ denotes the set of selected hierarchy levels. Each feature map $\\mathcal{S}_{i,j}$ is upsampled to the maximum resolution $(H_m, W_m)$ of the lowest hierarchy level using $f_{resize}$."}, {"title": "C. Approximate Boundary Learning by Center Constraint", "content": "The features obtained by the feature extractor $E_{\\varphi}$ already contain useful information for anomaly detection [69]. However, the distribution of these features is highly dispersed. Traditional SVDD methods using simple averaging for center estimation fail to capture intra-class variations. To capture intra-class diversity and establish a compact boundary, we propose a novel center constraint method called Approximate Boundary Learning (ABL), which improves the center initialization by iterative feature alignment, as shown in Fig. 3(a)."}, {"title": "D. Hypersphere-based Anomaly Feature Synthesis", "content": "Synthesizing anomalies in the feature space has proven to be an effective method for enhancing anomaly detection tasks [21], [22]. As shown in Fig. 5, these works generate feature-level anomalies by simply adding Gaussian noise without directional constraints, which may result in Gaussian anomalies still residing within the normal sample space. As the features become more concentrated during training, the constant variance of Gaussian noise further increases the likelihood of overlap between synthetic anomalies and the normal feature distribution. To generate more useful anomalies for boundary optimization, we design the Anomaly Feature Synthesis (AFS) method, which is based on the hypersphere distribution of normal features, as shown in Fig. 3(b).\nAFS generates near-in-distribution anomalies derived from the normal features of the original training set. As shown in Fig. 5, starting from the normal feature $u_i$, the anomaly feature $z_i$ is synthesized at a flexible length along the ray direction from the nearest center feature $\\check{c}$ to $u_i$. The ray direction ensures that the synthetic anomalies are reliably positioned outside the normal feature space by following the path that allows for the fastest departure from the distribution of normal features, thereby minimizing overlap and enabling the most efficient generation. The self-adaptive generation process is mathematically formulated as:\n$$\nz_i = u_i + \\alpha \\cdot L_c \\cdot \\frac{u_i - \\check{c}}{||u_i - \\check{c}||}\n$$\nwhere $\\alpha$ is a hyperparameter that controls the range of anomaly synthesis. As $\\alpha$ decreases, it becomes more difficult to distinguish the anomaly feature $z_i$ from the normal feature $u_i$, and vice versa.\nIn the self-adaptive generation described in Eq. 7, the flexible length $L_c$ plays a crucial role. The $L_c$ given by Eq. 6 represents the average distance from nearest center feature $\\check{c}$ to normal feature $u_i$. Since all $u_i$ in a batch share the same $L_c$, each anomaly feature $z_i$ maintains the same distance from $u_i$. This ensures that $z_i$ cannot get too close to $\\check{c}$, reducing overlap between normal and anomaly features. With the iterative training of boundary learning, $L_c$ gradually decreases. Consequently, $z_i$ is also compressed as the hypersphere shrinks. This ensures that $z_i$ cannot get too far from $u_i$, preventing the anomalies from becoming useless."}, {"title": "E. Refined Boundary Optimization by Discriminative Network", "content": "Through the boundary learning of ABL, normal features are constrained within the loose hypersphere boundary, with the majority of them being centrally clustered near the center feature. However, the distribution of normal features is more concentrated in specific directions emanating from the center feature, while it is more dispersed in other directions. To address the issue of real anomalies potentially occurring within the hypersphere, the Refined Boundary Optimization (RBO) is introduced to further optimize the boundary based on synthetic anomaly features and normal features, as shown in Fig. 3(c).\nInspired by [70], RBO employs a discriminator $D_{\\psi}$ to enlarge the score disparity between normal and anomaly features, where $D_{\\psi}$ is structured as a three-layer Multi-Layer Perceptron (MLP) with Sigmoid. The loss $L_n$ for normal features is given by the Binary Cross-Entropy (BCE) loss between the normal confidence and ground truth of 0:\n$$\nL_n = \\frac{1}{N \\cdot H_m \\cdot W_m} \\sum_{i=1}^{N} \\sum_{h,w} f_{bce}(D_{\\psi}(u_i^{h,w}), 0)\n$$\nThe loss $L_a$ for anomaly features is given by the BCE loss between the anomaly confidence and ground truth of 1:\n$$\nL_a = \\frac{1}{N \\cdot H_m \\cdot W_m} \\sum_{i=1}^{N} \\sum_{h,w} f_{bce}(D_{\\psi}(z_i^{h,w}), 1)\n$$\nThrough the discriminative learning of normal and anomaly features synthesized by AFS, the boundary obtained by RBO is more refined compared to the hypersphere boundary obtained by ABL, as depicted by the light pink region in Fig. 5. By leveraging the joint training with near-in-distribution anomalies, RBO effectively mitigates the risk of model collapse in ABL, where optimizing the feature projector $P_{\\theta}$ with a single center constraint loss could potentially map all normal features to one point. According to Eqs. 6, 8, and 9, the overall training objective of PBAS is:\n$$\n\\mathcal{J}(\\theta, \\psi) = \\min_{\\theta} (L_c + \\gamma ||\\theta||^2)\n+ \\min_{\\theta, \\psi} (L_n + L_a + \\delta(||\\theta||^2 + ||\\psi||^2))\n$$\nwhere $\\gamma$ and $\\delta$ represent the regularization coefficients for enhancing the generalization ability of ABL and RBO.\nDuring the iterative training of PBAS, normal features contract towards the center with the boundary evolving from approximate to refined. In summary, our proposed anomaly synthesis strategy is guided by the progressive boundary refinement to enhance anomaly detection."}, {"title": "F. Anomaly Scoring at Inference Stage", "content": "As depicted in Fig. 3, the inference stage is represented by the solid arrows without AFS. The test set $X_{test}$ contains both normal and abnormal images. Concretely, the test image $x_i$ is processed by the feature extractor $E_{\\varphi}$ and the feature projector $P_{\\theta}$ in ABL to obtain the test feature $u_i$. Then, the discriminator $D_{\\psi}$ in RBO directly outputs the confidence scores. Since the center feature provided by ABL is not required during inference, PBAS allows for a streamlined and efficient inference process.\nAnomaly Detection refers to the task of classifying test images as either normal or anomalous, essentially a classification task at the image level. The image-level anomaly score $S_{AD}$ of test image $x_i$ is calculated by the maximum value of all vectors in test feature $u_i$:\n$$\nS_{AD} = \\max_{u_i^{h,w} \\in u_i} D_{\\psi}(u_i^{h,w})\n$$\nwhere \u201cAD\u201d denotes Anomaly Detection.\nAnomaly Localization refers to the task of identifying the specific locations of anomalies within test images, essentially a segmentation task at the pixel level. First, bilinear interpolation is employed to upsample the confidence scores from feature dimensions $(H_m, W_m)$ to image dimensions $(H_o, W_o)$ using $f_{resize}$. Second, Gaussian smoothing is applied to reduce noise using $f_{smooth}$. Finally, the pixel-level anomaly score $S_{AL}$ of the test image $x_i$ is calculated by:\n$$\nS_{AL} = f_{smooth} \\big( f_{\\frac{H_o}{H_m}, \\frac{W_o}{W_m}}(D_{\\psi}(u_i)) \\big)\n$$\nwhere \u201cAL\u201d denotes Anomaly Localization."}, {"title": "IV. EXPERIMENT AND ANALYSIS", "content": "In the experiments, we use three publicly available real-world datasets renowned for their broad application in the field of industrial anomaly detection.\n1) MVTec AD: The MVTec Anomaly Detection [71] dataset is one of the most challenging datasets in the domain. This dataset contains 15 high-resolution industrial product categories divided into texture and object groups with 5354 images, including over 70 types of defects. The training set comprises 3629 normal samples, while the test set contains 467 normal samples and 1258 anomalous samples.\n2) VisA: The Visual Anomaly [72] dataset is one of the largest datasets for industrial anomaly detection, including 10821 images across 12 categories of colored industrial parts. The training set comprises 8659 normal samples, while the test set contains 962 normal samples and 1200 anomalous samples.\n3) MPDD: The Metal Parts Defect Detection [73] dataset contains 1346 images of metal parts under varied camera conditions across 6 categories. The training set comprises 888 normal samples, while the test set contains 176 normal samples and 282 anomalous samples."}, {"title": "B. Implementation Details", "content": "1) Experimental Settings: All experiments are conducted using an Intel\u00ae Xeon\u00ae Gold 6226R CPU @2.90GHz and an NVIDIA GeForce RTX 3090 GPU. During the training stage, input images for all methods are resized and center-cropped to the resolution of 256\u00d7256. The Adam optimizer is employed to train the feature projector $P_{\\theta}$ and the discriminator $D_{\\psi}$, with learning rates of $10^{-4}$ and $2 \\times 10^{-4}$, respectively. The training process consists of 400 epochs, with the batch size of 8. For example, training the \u201cCarpet\u201d class from the MVTec AD dataset takes approximately 2.5 hours, with each image requiring an average training time of 80 ms. Our proposed PBAS framework comprises three components. For ABL, we utilize the WideResnet50 [74] pretrained on ImageNet as the backbone for the feature extractor $E_{\\varphi}$. Then, we concatenate the features from hierarchy levels 2 and 3. The neighborhood patch size $p$ is set to 3, and the smoothing factor $\\beta$ for EMA is set to 0.1. For AFS, the anomaly degree $\\alpha$ is set to 0.3. For RBO, the regularization coefficients $\\gamma$ and $\\delta$ are set to $10^{-5}$ and $10^{-2}$, respectively.\n2) Evaluation Metrics: To effectively evaluate the discriminative capability of different models at both image and pixel levels, we employ the Area Under the Receiver Operating Characteristic Curve (AUROC) during the inference stage. Given its independence from predefined classification thresholds and its robustness against class imbalance, AUROC is a widely adopted evaluation metric in anomaly detection and localization. AUROC at the image and pixel levels are denoted as I-AUROC and P-AUROC, respectively. To evaluate the precision-recall balance in anomaly detection, this paper follows [39], [75] by using Average Precision (AP), which is more informative for imbalanced datasets than AUROC. AP at the image and pixel levels are denoted as I-AP and P-AP, respectively. For a more comprehensive assessment of the ability to localize anomalies, we additionally calculate the Per-Region Overlap (PRO) [76] at the pixel level. PRO is particularly sensitive to smaller-scale anomalies and avoids the risk of AUROC overestimating performance due to an increase in false positives. PRO at the pixel level is denoted as P-PRO."}, {"title": "C. Comparative Experiments", "content": "To evaluate our proposed PBAS, several typical and SOTA methods are employed in comparative experiments. NoCoAD [47], CFA [13], and RD4AD [14] employ an embedding-based framework without anomaly synthesis. In contrast, DRAEM [17], DSR [55], and DBPI [49] employ a reconstruction-based framework integrated with anomaly synthesis. Similarly, Pull&Push [61], CutPaste [60], DeSTSeg [58], RD++ [67], and SimpleNet [22] employ an embedding-based framework integrated with anomaly synthesis. Specifically, DSR and SimpleNet generate anomalies in the feature space, while the other synthesis-based methods generate anomalies in the image space.\n1) Results on MVTec AD: As shown in Table I, PBAS achieves a perfect I-AUROC of 100% on 9 categories of MVTec AD, establishing itself as the SOTA method for anomaly detection with an average I-AUROC of 99.8%. It is evident that PBAS excels particularly in the detection of texture categories. Given that methods using reconstruction-based framework are prone to generating false negatives in difference analysis, the average performance of most methods using embedding-based framework surpasses that of methods using reconstruction-based framework. Through the discriminative learning of synthetic anomalies, PBAS improves the I-AUROC by a margin of 0.3% compared to the second-best result achieved by SimpleNet (which leverages feature-level anomaly synthesis). As shown in Table II, PBAS achieves the best anomaly localization performance, with an average P-AUROC of 98.6% and P-PRO of 97.3%. Specifically, PBAS improves the P-AUROC and P-PRO by margins of 0.3% and 2.3% compared to the second-best result, respectively."}, {"title": "2) Results on VisA", "content": "As shown in Table III, PBAS achieves superior anomaly detection and localization performance on VisA, with an average I-AUROC of 97.7%, P-AUROC of 98.6%, and P-PRO of 93.3%. Specifically, PBAS improves the I-AUROC, I-AP, P-AP, and P-PRO by margins of 0.6%, 0.2%, 5.4%, and 1.1% compared to the second-best result, respectively. As illustrated in Fig. 8(a), PBAS effectively localizes anomalies on different categories within VisA. Due to the relatively small size of some anomalies in VisA (e.g., the \u201cCandle\u201d class), DBPI, RD++, and SimpleNet frequently exhibit incorrect localization. The results demonstrate that PBAS excels in detecting tiny anomalies. Given that P-AP is particularly sensitive to small-scale anomalies, PBAS outperforms other methods significantly on this metric. Similarly, the average I-AUROC and I-AP of embedding-based framework surpass those of reconstruction-based framework.\n3) Results on MPDD: As shown in Table IV, PBAS achieves competitive anomaly detection and localization performance on MPDD, with an average I-AUROC of 97.7%, P-AUROC of 98.8%, and P-PRO of 97.1%. Specifically, PBAS improves the P-AUROC and P-PRO by margins of 0.1% and 1.4% compared to the second-best result, respectively. As illustrated in Fig. 8(b), PBAS effectively localizes anomalies on different categories within MPDD. Due to the complex camera conditions in MPDD (e.g., the \u201cBracket black\" class), RD++ and SimpleNet are prone to over-detection, while DBPI fails to detect anomalies. The results demonstrate that PBAS excels in detecting anomalies across various shooting angles. Given that P-AUROC is insensitive to over-detection, PBAS shows only a slight improvement over others. Similarly, the average P-AUROC and P-PRO of embedding-based framework surpass those of reconstruction-based framework.\""}, {"title": "D. Ablation Study", "content": "To verify the effectiveness of different components in PBAS, we conduct ablation experiments on MVTec AD. PBAS consists of three core components: Approximate Boundary Learning (ABL), Anomaly Feature Synthesis (AFS), and Refined Boundary Optimization (RBO).\n1) Components in PBAS: As shown in Table V, PBAS achieves the best performance on three metrics when all three components are integrated. Specifically, we first divide the center initialization method in ABL into two types: the traditional average center method A and our proposed feature alignment method F. Since there is no discriminator when using ABL alone, we define the anomaly score by the Euclidean distance between the anomaly feature and its nearest center. Due to the intra-class variations, the performance of ABL using method F is significantly better than using method A, which will be detailed in the next section. Compared to ABL using method A, ABL using method F improves the I-AUROC, P-AUROC, and P-PRO by margins of 1.6%, 0.5%, and 1.0%, respectively.\nNext, we divide the anomaly synthesis strategy in AFS into two types: noisy anomaly synthesis N and our proposed self-adaptive generation method S. Similar to [22], method N synthesizes anomalies by adding Gaussian noise to normal features. Based on ABL using method F and integrated with the discriminative learning of RBO, the performance of AFS using method S is significantly better than using method N. Compared to AFS using method N, AFS using method S improves the I-AUROC, P-AUROC, and P-PRO by margins of 0.8%, 0.5%, and 5.4%, respectively. Due to the fixed variance and random directions of Gaussian noise, the anomalies generated by AFS using method N are scale-invariant and lack directionality. On the other hand, the anomalies generated by AFS using method S are located on the ray direction from the center to normal features. As the anomalies progressively contract with the increase of training epochs, they become more controllable and meaningful. Finally, through the discriminative learning of normal and anomaly feature in RBO, the decision boundary transitions from approximate to refined. Compared to using ABL alone, the introduction of AFS and RBO can further improve the anomaly detection performance.\n2) Visualized Feature Distribution: To more intuitively"}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a novel feature-level anomaly synthesis strategy guided by the progressive boundary for enhancing anomaly detection, termed PBAS. Our method addresses key limitations of existing approaches by eliminating the need for predefined anomaly properties and allowing for controllable anomaly synthesis. Leveraging the hypersphere boundary established by ABL and the artificial anomalies synthesized by AFS, RBO refines the boundary between normal and anomalous samples through binary classification. Consequently, PBAS significantly improves the performance of anomaly detection and localization. We evaluate our method on various industrial datasets and achieve state-of-the-art performance, demonstrating the effectiveness and efficiency of PBAS. Moreover, PBAS has the potential to detect subtle anomalies. Since PBAS is designed to capture and enhance distribution differences in the feature space through anomaly synthesis and boundary optimization, our main focus is localizing structural anomalies (e.g., surface stains) in industrial scenarios. However, logical anomalies (e.g., misassembled parts), which often require higher-level understanding such as scene interpretation, are beyond the current scope of PBAS. We have not yet thoroughly addressed these types of anomalies. In the future, we will explore the integration of semantic analysis for logical anomaly detection."}]}