{"title": "AUTOGEN STUDIO: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems", "authors": ["Victor Dibia", "Jingya Chen", "Gagan Bansal", "Suff Syed", "Adam Fourney", "Erkang Zhu", "Chi Wang", "Saleema Amershi"], "abstract": "Multi-agent systems, where multiple agents (generative Al models + tools) collaborate, are emerging as an effective pattern for solving long-running, complex tasks in numerous domains. However, specifying their parameters (such as models, tools, and orchestration mechanisms etc,.) and debugging them remains challenging for most developers. To address this challenge, we present AUTOGEN STUDIO, \u0430 no-code developer tool for rapidly prototyping, debugging, and evaluating multi-agent workflows built upon the AUTOGEN framework. AUTOGEN STUDIO offers a web interface and a Python API for representing LLM-enabled agents using a declarative (JSON-based) specification. It provides an intuitive drag-and-drop UI for agent workflow specification, interactive evaluation and debugging of workflows, and a gallery of reusable agent components. We highlight four design principles for no-code multi-agent developer tools and contribute an open-source implementation.", "sections": [{"title": "Introduction", "content": "When combined with the ability to act (e.g., using tools), Generative AI models function as agents, enabling complex problem-solving capabilities. Importantly, recent research has shown that transitioning from prescribed (fixed) agent pipelines to a multi-agent setup with autonomous capabilities can result in desirable behaviors such as improved factuality and reasoning (Du et al., 2023), as well as divergent thinking (Liang et al., 2023). These observations have driven the development of application frameworks such as AutoGen (Wu et al., 2023), CAMEL (Li et al., 2024), and TaskWeaver (Qiao et al., 2023), which simplify the process of crafting multi-agent applications expressed as Python code. However, while multi-agent applications advance our capacity to solve complex problems, they also introduce new challenges. For example, developers must now configure a large number of parameters for these systems including defining agents (e.g., the model to use, prompts, tools or skills available to the agent, number of action steps an agent can take, task termination conditions etc.), communication and orchestration mechanisms - i.e., the order or sequence in which agents act as they collaborate on a task. Additionally, developers need to debug and make sense of complex agent interactions to extract signals for system improvement. All of these factors can create significant barriers to entry and make the multi-agent design process tedious and error-prone. To address these challenges, we have developed AUTOGEN STUDIO, a tool for rapidly prototyping, debugging, and evaluating MULTI-AGENT workflows. Our contributions are highlighted as follows:\n\u2022 AUTOGEN STUDIO - a developer-focused tool (UI and backend Web and Python API) for declaratively specifying and debugging (human-in-the-loop and non-interactive) MULTI-AGENT workflows. AUTOGEN STUDIO provides a novel drag-and-drop experience (Figure 1) for rapidly authoring complex MULTI-AGENT agent workflows, tools for profiling/debugging agent sessions, and a gallery of reusable/shareable MULTI-AGENT components.\n\u2022 We introduce profiling capabilities with visualizations of messages/actions by agents and metrics (costs, tool invocations, and tool output status) for debugging MULTI-AGENT workflows.\n\u2022 Based on our experience building and supporting AUTOGEN STUDIO as an open-source tool with a significant user base (over 200K downloads within a 5-month period), we outline emerging design patterns for MULTI-AGENT developer tooling and future research directions.\nTo the best of our knowledge, AUTOGEN STUDIO is the first open-source project to explore a no-code interface for autonomous MULTI-AGENT application development, providing a suitable platform for research and practice in MULTI-AGENT developer tooling."}, {"title": "Related Work", "content": "Generative Al models face limitations, including hallucination generating content not grounded in fact and limited performance on reasoning tasks or novel out-of-distribution problems. To address these issues, practice has shifted towards agentic implementations where models are given access to tools to act and augment their performance (Mialon et al., 2023). Agentic implementations, such as React (Yao et al., 2022), explore a Reason and Act paradigm that uses LLMs to generate both reasoning traces and task-specific actions in an interleaved manner. As part of this process, developers have explored frameworks that build prescriptive pipelines interleaving models and tools (e.g., LIDA (Dibia, 2023), LangChain (Chase, 2022)). However, as tasks become more complex, requiring lengthy context and the ability to independently adapt to dynamic problem spaces, pre-defined pipelines demonstrate limited performance (Liu et al., 2024). This limitation has led to the exploration of more flexible and adaptive agent architectures."}, {"title": "MULTI-AGENT Frameworks", "content": "Several frameworks have been proposed to provide abstractions for creating such applications. AutoGen (Wu et al., 2023) is an open-source extensible framework that allows developers to build large MULTI-AGENT applications. CAMEL (Li et al., 2024) is designed to facilitate autonomous cooperation among communicative agents through role-playing, using inception prompting to guide chat agents toward task completion while aligning with human intentions. OS-Copilot (Wu et al., 2024) introduces a framework for building generalist agents capable of interfacing with comprehensive elements in an operating system, including the web, code terminals, files, multimedia, and various third-party applications. It explores the use of a dedicated planner module, a configurator, and an executor, as well as the concept of tools ( Python functions or calls to API endpoints) or skills (tools that can be learned and reused on the fly)."}, {"title": "System Design", "content": "AUTOGEN STUDIO is implemented across two high-level components: a frontend user interface (UI) and a backend API (web, python and command line). It can be installed via the PyPI package manager (listing 1).\nAUTOGEN STUDIO can be installed from PyPI (pip) and the UI launched from the command line."}, {"title": "User Interface", "content": "The frontend web interface in AUTOGEN STUDIO is built using React and implements three main views that support several key functionalities. The build view enables users to author (define-and-compose) multi-agent workflows. The playground view allows for interactive task execution and workflow debugging, with options to export and deploy. The gallery view facilitates the reuse and sharing of agent artifact templates."}, {"title": "Building Workflows", "content": "The build view in the UI (see Figure 1) offers a define-and-compose experience, allowing developers to declaratively define low-level components and iteratively compose them into a workflow. For instance, users can define configurations for models, skills/tools (represented as Python functions addressing specific tasks), or memory stores (e.g., documents organized in a vector database). Each entity is saved in a database for use across interface interactions. Subsequently, they can define an agent, attaching models, skills, and memory to it. Several agent default templates are provided following AUTOGEN abstractions a UserProxy agent (has a code execution tool by default), an AssistantAgent (has a generative AI model default), and a GroupChat agent (an abstraction container for defining a list of agents, and how they interact). Finally, workflows can be defined, with existing agents attached to these workflows. The default workflow patterns supported are autonomous chat (agents exchange messages and actions across conversation turns until a termination condition is met) and sequential chat (a sequence of agents defined, each agent processes its input in order and passes on a summary of their output to the next agent). The workflow composition process is further enhanced by supporting a drag-and-drop interaction e.g., skills/models can be dragged to agents and agents into workflows."}, {"title": "Testing and Debugging Workflows", "content": "Workflows can be tested in-situ in the build view, or more systematically explored within the playground view. The playground view allows users create sessions, attach workflows to the session, and run tasks (single shot or multi-turn). Sessions can be shared (to illustrate workflow performance) and multiple sessions can be compared. AUTOGEN STUDIO provides two features to support debugging. First, it provides an observe view where as tasks progress, messages and actions performed by agents are streamed to the interface, and all generated artifacts are displayed (e.g., files such as images, code, documents etc). Second a post-hoc profiler view is provided where a set of metrics are visualized for each task addressed by a workflow - total number of messages exchanged, costs (generative AI model tokens consumed and dollar costs), how often agents use tools and the status of tool use (success or failure), for each agent."}, {"title": "Deploying Workflows", "content": "AUTOGEN STUDIO enables users to export workflows as a JSON configuration file. An exported workflow can be seamlessly integrated into any Python application (listing 2), executed as an API endpoint using the AUTOGEN STUDIO command line interface (figure 2a), or wrapped in a Docker container for large-scale deployment on various platforms (Azure, GCP, Amazon, etc.)."}, {"title": "Template Gallery", "content": "The UI also features a gallery view a repository of components (skills, models, agents, workflows) that users can import, extend, and reuse in their own workflows. Since each component specification is declarative (JSON), users can also easily export, version and reshare them."}, {"title": "Backend API - Web, Python, and Command Line", "content": "The backend API comprises three main components: a web API, a Python API, and a command-line interface. The web API consists of REST endpoints built using the FastAPI library\u00b2, supporting HTTP GET, POST, and DELETE methods. These endpoints interact with several key classes: A DBManager performs CRUD (Create, Read, Update, Delete) operations on various entities such as skills, models, agents, memory, workflows, and sessions. The Workflow Manager class handles the ingestion of declarative agent workflows, converts them into AUTOGEN agent objects, and executes tasks (see listing 2). A Profiler class parses agent messages to compute metrics. When a user initiates a task within a session, the system retrieves the session history, instantiates agents based on their serialized representations from the database, executes the task, streams intermediate messages to the UI via websocket, and returns the final results. AUTOGEN STUDIO also provides a command-line"}, {"title": "Usage and Evaluation", "content": "In this project, we have adopted an in-situ, iterative evaluation approach. Since its release on GitHub (5 months), the AUTOGEN STUDIO package has been installed over 200K times and has been iteratively improved based on feedback from usage (> 135 GitHub issues). Issues highlighted several user pain points that were subsequently addressed including: (a) challenges in defining, persisting, and reusing components, resolved by implementing a database layer; (b) difficulties in authoring components, resolved by supporting automated tool generation from descriptions and integrating an IDE for editing tools; (c) frustrations caused by components failing during end-to-end tests, addressed by incorporating a test button for components (e.g.,models) and workflows in the build view. Finally, in Appendix A, we demonstrate how AUTOGEN STUDIO can effectively be used to support an engineer persona in rapidly prototyping, testing, and iteratively debugging a MULTI-AGENT workflow, and deploying it as an API endpoint to address a concrete task (generating books)."}, {"title": "Emerging Design Patterns and Research Directions", "content": "In the following section, we outline some of the high-level emerging patterns which we hope can help inform the design of no-code interfaces for building next-generation multi-agent applications."}, {"title": "Define-and-Compose Workflows", "content": "Allow users to author workflows by defining components and composing them (via drag-and-drop actions) into multi-agent workflows.\nA multi-agent system can have a wide array of parameters to configure. We have found that selecting the right visual presentation of the workflow to helping users understand what parameters to configure (discovery), and how to configure them. Specifically, we have found that a define-and-compose workflow, where entities are first defined and persisted independently, and then composed ultimately into multi-agent workflows, provides a good developer experience. This includes providing tools to support authoring entities e.g., the ability define and test models, an IDE for generating/editing tools (code), and a a canvas-based visual layout of workflows with drag-and-drop interaction for associating entities in the workflow."}, {"title": "Debugging and Sensemaking Tools", "content": "Provide robust tools to help users debug, interpret, and rationalize the behavior and outputs of multi-agent systems.\nMulti-agent workflows can be brittle and fail for multiple reasons, ranging from improperly configured models to poor instructions for agents, improper tool configuration for agents or termination conditions. A critical request has been for tools to help users debug and make sense of agent responses."}, {"title": "Export and Deployment", "content": "Enable seamless export and deployment of multi-agent workflows to various platforms and environments.\nWhile a no-code tool like AUTOGEN STUDIO enables rapid iteration and demonstration of workflows, the natural progression for most use cases is that developers want to replicate the same outcomes but integrated as parts of their core applications. This stage requires seamless export and deployment of multi-agent workflows to various platforms and environments."}, {"title": "Collaboration and Sharing", "content": "Facilitate user collaboration on multi-agent workflow development and allow easy sharing of creations within the community.\nCollaboration and sharing are key to accelerating innovation and improving multi-agent systems. By enabling users to collaborate on workflow development, share their creations, and build upon each other's work, a more dynamic and innovative development environment can be cultivated. Tools and features that support real-time collaboration, version control, and seamless sharing of workflows and components are essential to foster a community-driven approach. Additionally, offering a repository or gallery where users can publish and share their workflows, skills, and agents promotes communal learning and innovation."}, {"title": "Future Research Directions", "content": "While we have explored early implementations of the design requirements mentioned above, our efforts in building AUTOGEN STUDIO have also identified two important future research areas and associated research questions.\n\u2022 Offline Evaluation Tools: This encompasses questions such as how can we measure the performance, reliability, and reusability of agents across tasks? How can we better understand their strengths and limitations? How can we explore alternative scenarios and outcomes? And how can we compare different agent architectures and collaboration protocols?\n\u2022 Understanding and quantifying the impact of multi-agent system design decisions: These questions include determining the optimal number and composition of agents for a given problem, the best way to distribute responsibilities and coordinate actions among agents, and the trade-offs between centralized and decentralized control or between homogeneous and heterogeneous agents.\n\u2022 Optimizing of multi-agent systems: Research directions here include the dynamic generation of agents based on task requirements and available resources, tuning workflow configurations to achieve the best performance, and adapting agent teams to changing environments and user preferences. Furthermore, how can we leverage human oversight and feedback to improve agent reliability, task performance and safety?"}, {"title": "Conclusion", "content": "This paper introduced AUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging, and evaluating multi-agent workflows. Key features include a drag-and-drop interface for agent workflow composition, interactive debugging capabilities, and a gallery of reusable agent components. Through widespread adoption, we identified emerging design patterns for multi-agent developer tooling - a define and compose approach to authoring workflows, debugging tools to make sense of agent behaviors, tools to enable deployment and collaborative sharing features. AUTOGEN STUDIO lowers the barrier to entry for multi-agent application development, potentially accelerating innovation in the field. Finally we outline future research directions including developing offline evaluation tools, ablation studies to quantify the impact of MULTI-AGENT systems design decisions and methods for optimizing multi-agent systems."}, {"title": "Ethics Statement", "content": "AUTOGEN STUDIO is designed to provide a no-code environment for rapidly prototyping and testing multi-agent workflows. Our goal is to responsibly advance research and practice in solving problems with multiple agents and to develop tools that contribute to human well-being. Along with AUTOGEN, AUTOGEN STUDIO is committed to implementing features that promote safe and reliable outcomes. For example, AutoGen STUDIO offers profiling tools to make sense of agent actions and safeguards, such as support for Docker environments for code execution. This feature helps ensure that agents operate within controlled and secure environments, reducing the risk of unintended or harmful actions. For more information on our approach to responsible AI in AutoGen, please refer to transparency FAQS here. Finally, AUTOGEN STUDIO is not production ready i.e., it does not focus on implementing authentication and other security measures that are required for production ready deployments."}, {"title": "Jack the Software Engineer Persona Use Case", "content": "Jack is a junior software engineer who has recently joined SoftwareCon. As part of his tasks, he is required to create an application that can generate a variety of short books. The initial version should focus on generating children's books (age 5 -8 years old) based on a given query (e.g., create a book for kids on how the sun works) with the expectation of being generalized to support other generic tasks. Jack has heard about a MULTI-AGENT approach to building systems that can address a variety of tasks through autonomous collaboration between agents. To explore this approach, he begins by perusing the AUTOGEN STUDIO documentation, installs it, launches the UI, and performs the following steps:\nJack starts with the Build view, where he reviews the default skills that come with AUTOGEN STUDIO. He sees that there are two relevant skills generate_pdfs and generate_images. He verifies that he has the appropriate API keys for the generate_image skill. Next, he creates a GPT3.5 model and adds an API key.\nFollowing best practices, Jack knows that the basic agent team with AUTOGEN consists of a UserProxyAgent that can execute code and an AssistantAgent that can solve tasks as well as write code or call available tools/skills. He creates both of these agents; for his AssistantAgent, he ensures that he attaches the GPT4 model he created previously and also attaches both skills. Jack moves on to the workflow tab and creates a new autonomous chat workflow where he specifies the UserProxyAgent as the initiator and his AssistantAgent as the receiver.\nWithin the workflow tab, Jack tests the workflow immediately and quickly observes a few issues. Using the profiler tool and visualization of messages exchanged by the agents, he notices that there seem to be quality issues with the content of the book - namely, the AssistantAgent seems to generate very short messages and hence the book pages contains only 2 sentences per page whereas the requirements state that the kids are slightly older and can read much longer text.\nTo remedy these issues, Jack takes two actions. First, he attempts to extend the base instructions of his AssistantAgent, but still doesn't get pages with more than 3 sentences across interactive tests. He recalls that using more agents can help separate focus and improve task performance. He then switches to creating 4 agents: a UserProxy, a ContentAssistant with detailed instructions on generating the content for each page, a QualityAssuranceAssistant to verify the pages meet parameters, and an ImageGeneratorAssistant focused on generating images for the book. He then creates a GroupChat agent and adds his list of agents to it. Next, he creates a new workflow where the receiver is the GroupChat agent and tests the application across a few tries. Jack is satisfied with the results as full-page stories are now generated correctly. In addition, Jack is concerned about costs but can easily use the observe message button to explore duration, tokens used by agents, tool/skill use and LLM dollar costs for each task run.\nAt this point, Jack has two final tasks: he wants to share his work with colleagues for feedback and then provide an API they can prototype with. AUTOGEN STUDIO makes sharing easy; First, Jack can simply export and share a link to successful sessions. Second, he can also download his workflow and share it with colleagues, saving it in a version control system like Git. Third, he can spin up an API endpoint where the agents can respond to task requests using cli commands \u2018autogenstudio serve -port 8000'. He can also spin up a docker container using the AUTOGEN STUDIO serve command and scale it on any platform of his choice (Azure, AWS, GCP, Hugging Face)."}]}