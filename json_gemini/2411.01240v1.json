{"title": "Optimizing Federated Learning by Entropy-Based Client Selection", "authors": ["Andreas Lutz", "Gabriele Steidl", "Karsten M\u00fcller", "Wojciech Samek"], "abstract": "Deep learning is an emerging field revolutionizing various industries, including natural language processing, computer vision, and many more. These domains typically require an extensive amount of data for optimal performance, potentially utilizing huge centralized data repositories. However, such centralization could raise privacy issues concerning the storage of sensitive data. To address this issue, federated learning was developed. It is a newly distributed learning technique that enables to collaboratively train a deep learning model on decentralized devices, referred to as clients, without compromising their data privacy. Traditional federated learning methods often suffer from severe performance degradation when the data distribution among clients differs significantly. This becomes especially problematic in the case of label distribution skew, where the distribution of labels varies across clients. To address this, a novel method called FedEntOpt is proposed. FedEntOpt is designed to mitigate performance issues caused by label distribution skew by maximizing the entropy of the global label distribution of the selected client subset in each federated learning round. This ensures that the aggregated model parameters from the clients were exhibited to data from all available labels, which improves the accuracy of the global model. Extensive experiments on several benchmark datasets show that the proposed method outperforms several state-of-the-art algorithms by up to 6% in classification accuracy, demonstrating robust and superior performance, particularly under low participation rates. In addition, it offers the flexibility to be combined with them, enhancing their performance by over 40%.", "sections": [{"title": "I. INTRODUCTION", "content": "Nowadays, an extensive amount of data is continuously created from different sources, such as smartphones, desktop computers and other Internet of Things (IoT) devices. Approximately 328.77 million terabytes of data are produced daily, and the volume is expected to triple in the upcoming year compared to five years ago [1], [2]. Training deep learning models on such data would be highly beneficial since they typically require a large amount of data to achieve state-of-the-art performance [3]. Nevertheless, storing the data in a centralized location for training such models is not possible due to data privacy violations. Further restrictions, such as the General Data Protection Regulation (GDPR) [4] additionally impede this process. Consequently, more and more training data is stored in a fragmented manner across different databases and cannot be exchanged over country [5] or even organizational borders, degrading the performance of a deep learning model due to lack of data [6]. To address this issue, a novel decentralized machine learning technique, called federated learning (FL) was proposed. This method is able to leverage all the available data from different devices, referred to as clients, to collaboratively train a global deep learning model without ever disclosing the raw data [7]\u2013[9]. A typical realization of an FL system uses a server-client architecture, where a central server manages the global deep learning model, which is shared among all clients in order to train it on their respective local datasets. After training, the updated parameters are sent to the central server, which aggregates them to update the global model [9]. FL systems have been successfully applied in various real-world scenarios, including fraud detection in finance [10], next-word prediction in natural language processing [11], developing autonomous driving strategies for self-driving cars [12], and building movie recommendation systems [13]. However, the training of such systems remains challenging due to varying data distributions among clients. The largest impact on the degradation of the global model performance in this setting is caused by label distribution skew, where clients have different label distributions [14]. It has been shown that simply averaging updated model parameters under such conditions can significantly decrease the performance of the global model, suffering from up to 26% loss in classification accuracy compared to the case where the label distribution among clients is homogeneous [15]. Furthermore, label skew is often encountered in practice since individual clients acquire their data independently, resulting in an imbalanced distribution of labels. For instance, hospitals in urban areas may have more images of respiratory diseases because their patients are exposed to higher levels of air pollution compared to those patients in rural areas. Therefore, our research will focus on addressing label distribution skew to mitigate its negative effects on the performance of the global model while simultaneously improving it. Several methods were proposed in the literature to reduce the negative effect of label skew. One approach focuses on constraining local updates to keep local models close to the global model. This is achieved by modifying the loss functions of the clients [15]- [17], incorporating contrastive learning [18], [19], or introducing control variates [20]. Other works employ weighting schemes, which take the varying importance of locally ac-"}, {"title": "II. RELATED WORK", "content": "1) Federated Learning with Heterogeneous Data: Initially, federated averaging (FedAvg) was introduced, which averages transmitted model parameters weighted by the dataset size of participating clients [9]. Nevertheless, the training process suffers from slow convergence and compromised global model performance, since the aggregated model parameters were obtained from different data distributions [14], [32]. FedProx [33] improves on this by incorporating a proximal term in the local loss functions. This term regularizes the local updates, limiting their deviation from the global model. However, this approach does not take the difference among client models into account. SCAFFOLD [20] addresses this by introducing control variates to correct for the client drift at the cost of additional communication overhead. FedNova [22], on the other hand, deals with the data heterogeneity problem at the aggregation stage by averaging normalized client updates, effectively mitigating inconsistencies in parameter updates arising from the optimization of different local objectives.\n2) Federated Learning with Label Skew: Several methods were proposed to directly handle label skew in FL. FedRS [16] relies on a loss function that constrains the weight updates associated with missing labels during local training. FedLC [15] improves on this, by calibrating the logits according to the local label distribution. FedCRL [19] relies on shareable representations that, in combination with contrastive learning, help to align global and local models. Since the representations have to be updated, additional communication is required. FedConcat [24] concatenates model parameters to combine knowledge over a diverse set of clients. To control the model size, the concatenation is performed over clusters with similar label distributions. However, in the considered settings with highly imbalanced data, several clusters are needed, leading to increased computational and storage demands. All the aforementioned methods lack the consideration of the aggregated label distribution across all selected clients in each communication round, which can lead to sub-optimal performance, compared to our entropy-based selection method. Another work [34] addresses this utilizing label information transmitted by each client before the actual training. However, their optimization method consistently produces the same subset of clients, leading to overfitting. Additionally, forming the subset requires excluding large portions of data. These limitations lead to compromised model performance, as we will demonstrate in the experiment section.\n3) Federated Learning with Entropy: Several works have been proposed relying on an entropy-based approach to improve FL systems. Condori Bustincio et al. [28] leverage data entropy and model divergence to select a subset of clients and to decide, whether model updates should be transmitted. This approach reduces communication overhead at the cost of decreased global model performance comparable to FedAvg. Additionally, the method suffers from computational overhead at the client side, since local training might be executed, but model parameters are never exchanged. Orlandi et al. [29] propose to train only on specific portions of local data, which have lower entropy than the average data entropy of all clients. While this approach reduces overall training time, the performance of the global model cannot surpass the baseline FedAvg. The approach proposed by [30] utilizes a refined selection scheme, where clients after an initial random selection are re-selected for aggregation based on the information contained in their soft labels. This leads to additional local computation and communication overhead because the soft labels have to be computed by leveraging the entire local"}, {"title": "III. PROBLEM FORMULATION", "content": "FL is a distributed learning framework involving multiple clients to collaboratively train a global model without sharing their raw data. We consider $K$ clients, where each client $k$ has a local dataset $D^{(k)} = {(x_i^{(k)}, y_i^{(k)})}_{i=1}^{n_k}$ of size $n_k$, where $x_i^{(k)} \\in \\mathcal{X} \\subseteq \\mathbb{R}^d$ and $y_i^{(k)} \\in \\mathcal{Y} \\subseteq \\mathbb{R}^C$ represent the features and labels, respectively. The goal is to learn a global model for image classification $f_{\\theta} : \\mathcal{X} \\rightarrow \\mathcal{Y}$, which is a neural network with parameters $\\theta \\in \\mathbb{R}^P$, minimizing the following objective:\n$\\theta^* = \\underset{\\theta \\in \\mathbb{R}^P}{\\operatorname{argmin}} \\sum_{k=1}^K \\frac{n_k}{\\sum_{i=1}^K n_i} \\int_{\\mathcal{X} \\times \\mathcal{Y}} \\ell(f_{\\theta}(x), y) dP_{x^{(k)},y^{(k)}}$,\nwhere $\\ell : \\mathbb{R}^C \\times \\mathbb{R}^C \\rightarrow [0, \\infty)$ denotes the loss function and $P_{x^{(k)},y^{(k)}}$ the unknown joint probability distribution of each client. It can be expressed as\n$P_{x^{(k)},y^{(k)}}(x, y) = P_{x^{(k)}|Y^{(k)}=y}(x) P_{y^{(k)}}(y)$.\nThe label distribution skew is characterized by the condition that the marginal probability distribution $P_{y^{(k)}}$ varies among clients, while the conditional probability distribution $P_{x^{(k)}|Y^{(k)}}$ stays the same for all clients. Since these distributions are unknown, the solution of (1) is obtained through empirical risk minimization, where the optimization is carried out on a subset of clients $S \\subseteq \\mathcal{A} := {1, ..., K}$:\n$\\hat{\\theta} = \\underset{\\theta}{\\operatorname{argmin}} \\sum_{s \\in S} \\frac{n_s}{\\sum_{j \\in S} n_j} \\frac{1}{n_s} \\sum_{i=1}^{n_s} \\ell(f_{\\theta}(x_i^{(s)}), y_i^{(s)})$.\nAfter receiving the global model from the server, the selected clients update their local models with their data and send the updated model parameters $(\\theta^{(s)})$ back for aggregation. This procedure is iterated until convergence [9]. Optimally, the cohort of clients is chosen such that their aggregated local"}, {"title": "IV. PROPOSED METHOD", "content": "To leverage the information contained in the label distribution of the clients, FedEntOpt uses Shannon entropy. The goal is to ensure that the aggregated label distribution over the subset is close to uniform:\n$P_{\\mathcal{Y}}(y) = \\sum_{s \\in S} \\frac{n_s}{\\sum_{j \\in S} n_j} P_{\\mathcal{Y}^{(s)}}(y)$.\nSince the local conditionals $P_{x^{(k)}|Y^{(k)}}$ are assumed to be the same and the global joint distribution is a convex combination of the local ones, approximating the global label distribution effectively approximates the global joint distribution.\n$\\hat{P}_{x, y}(x, y) = \\sum_{s \\in S} \\frac{n_s}{\\sum_{j \\in S} n_j} \\hat{P}_{x^{(s)}, y^{(s)}}(x, y)$.\nThis in turn reduces the excess risk between the empirical and optimal global model [35].\nTo illustrate the proposed method for solving the classification problem in (1), let the label set be defined as $\\mathcal{L} := {1, ..., C}$. Each label $i \\in \\mathcal{L}$ is represented as a one-hot encoded vector $e_i \\in \\mathbb{R}^C$. For a client $k$, we count the number of occurrences of each label and store these counts as a vector $l^{(k)} \\in \\mathbb{R}^C$. Specifically, the $i$-th component $l_i^{(k)}$ is given by:\n$l_i^{(k)} = \\sum_{j=1}^{n_k} \\mathbb{1}_{{y_j^{(k)} = e_i}} \\quad \\forall i \\in \\mathcal{L} \\text{ and } \\forall k \\in \\mathcal{A}$,\nwhere $\\mathbb{1}_{{y_j^{(k)} = e_i}}$ is an indicator function defined as:\n$\\mathbb{1}_{{y_j^{(k)} = e_i}} = \\begin{cases} 1 & \\text{if } y_j^{(k)} = e_i, \\\\ 0 & \\text{otherwise}. \\end{cases}$\nEach client then sends its label count vector $l^{(k)}$ to the central server. This has to be done only once before training, resulting in minimal communication overhead compared to the exchange of model parameters during training. In order to keep track of the aggregated label distribution, the server relies on a vector $L = 0 \\in \\mathbb{R}^C$. After this preliminary step, the first client $i \\in \\mathcal{A}$ is sampled uniformly at random from all possible clients in $\\mathcal{A}$. Its label count vector is then added to"}, {"title": "V. EXPERIMENTS", "content": "To demonstrate the effectiveness of our approach, we implemented FedEntOpt and other baseline algorithms for comparison in PyTorch and ran the associated experiments on a GPU cluster with AMD EPYC 3.5 GHz CPUs, 512 GB RAM, and 4 NVIDIA Ampere A100 GPUs with 40 GB memory per GPU. Under the label skew setting, FedEntOpt consistently outperforms the other state-of-the-art algorithms in terms of classification accuracy.\nA. Experiment Setup\n1) Datasets: For the experimental evaluation, we adopt three benchmark datasets: CIFAR-10, CIFAR-100 [36] and CINIC-10 [37], which are widely used in the literature. CIFAR-10 contains 60,000 32x32 color images in 10 different classes, while CIFAR-100 has 100 classes, which are grouped into 20 super-classes. We use the superclass variant of CIFAR- 100 to double the classification problem size compared to CIFAR-10. Both datasets have 50,000 training samples, which we distributed among the clients for training, and 10,000 samples reserved for testing to evaluate the classification accuracy of the global model. CINIC-10 is an extension of CIFAR-10 with additional images from ImageNet with a training set containing 90,000 images. This dataset is used to run experiments with a larger cohort of clients compared to the other datasets. Similarly, the performance of the global model is evaluated using the provided test set, which also contains 90,000 samples. In all cases, the distribution of the test set is uniform, aligning well with the setting stated in the problem formulation.\n2) Simulation of Label Skew: To simulate label imbalances, we follow the partitioning strategy outlined in [14]. We consider two types of label imbalances. The first one is quantity- based, where each client owns samples of a fixed number of labels. We denote #C = j to indicate that a client has data for only j different labels. The second type concerns distribution- based label imbalances. In this scenario, $p_j \\sim Dir_K(\\beta)$ is sampled according to a Dirichlet distribution with parameter $\\beta$, where $p_j$ is a $K$-dimensional vector representing the proportions of instances of label $j$ allocated to each client. Specifically, we assign $p_{j,k}$ samples of class $j$ to the client $k$. For ease of notation, we use Dir($\\beta$) dropping the index $K$ and the vector $p_j$ of proportions to denote such a partitioning strategy.\n3) Model Architecture: Since our experiments are based on image classification, we employ a convolutional neural network suited for this task. Concretely, we use the LeNet- 5 [38] architecture for evaluation on all three considered datasets. The architecture consists of two convolutional layers with 5 \u00d7 5 kernels, where the size of the output channels is 6 and 16, respectively. After each convolution, 2 \u00d7 2 max pooling is applied. The output after the second convolution block is then flattened into a vector and fed into a series of three fully connected layers, where the hidden sizes are 120 and 84, respectively. ReLU activation functions are applied between each of these layers.\n4) Baseline Methods: We compare FedEntOpt with the following baseline methods, which can be divided into two categories: methods that select clients randomly and address label imbalance on the clients, and methods that address label imbalance directly on the server by additionally requiring label information transmitted by the clients. The first category includes FedAvg [9], FedProx [33], FedNova [22], SCAFFOLD [20], FedRS [16] and FedLC [15]. The other category contains FedConcat [24] and the method proposed by [39], where we compare the client selection module to our method. Since the authors provided no specific name for this method, we refer to it as KL, since they rely on the KL-Divergence to select a subset of clients for training.\n5) Hyperparameters: In all experiments, we perform local training for 5 epochs using the SGD optimizer with a learning rate of 0.01, momentum of 0.9 and a weight decay of 5\u00b710-4. We use a local batch size of 64 and use cross-entropy as the loss function, which is a typical choice for classification tasks. We train for a total of 500 communication rounds, where we evaluate the performance of the global model in terms of classification accuracy in each of them. The learning rate is decayed by a factor of 0.98 after each communication round. For CIFAR-10 and CIFAR-100 with 20 superclasses, we set the number of available clients to K = 100. For CINIC-10, we use K = 200 clients to simulate a larger cohort. For FedEntOpt, we use best performing buffer size $Q \\in {50\\%, 70\\%}$ of the available clients. For FedProx, we utilize the same strategy and tune the proximal parameter"}]}