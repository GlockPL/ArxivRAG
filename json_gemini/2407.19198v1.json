{"title": "Towards the Dynamics of a DNN Learning Symbolic Interactions", "authors": ["Qihan Ren", "Yang Xu", "Junpeng Zhang", "Yue Xin", "Dongrui Liu", "Quanshi Zhang"], "abstract": "This study proves the two-phase dynamics of a deep neural network (DNN) learning interactions. Despite the long disappointing view of the faithfulness of post-hoc explanation of a DNN, in recent years, a series of theorems have been proven [27] to show that given an input sample, a small number of interactions between input variables can be considered as primitive inference patterns, which can faithfully represent every detailed inference logic of the DNN on this sample. Particularly, it has been observed [42] that various DNNs all learn interactions of different complexities with two-phase dynamics, and this well explains how a DNN's generalization power changes from under-fitting to over-fitting. Therefore, in this study, we prove the dynamics of a DNN gradually encoding interactions of different complexities, which provides a theoretically grounded mechanism for the over-fitting of a DNN. Experiments show that our theory well predicts the real learning dynamics of various DNNs on different tasks.", "sections": [{"title": "Introduction", "content": "Background: mathematically guaranteeing that the inference score of a DNN can be faithfully explained as symbolic interactions. Explaining the detailed inference logic hidden behind the output score of a DNN is considered one of the core issues for the post-hoc explanation of a DNN. However, after a comprehensive survey of various explanation methods, many studies [28, 1, 12] have unanimously and empirically arrived at a disappointing view of the faithfulness of almost all post-hoc explanation methods. Fortunately, the recent progress [27] has mathematically proven that given a specific input sample $x = [x_1,\\cdots, x_n]^T$, a DNN2 usually satisfy the three conditions. for a classification task usually only encodes a specific small set of interactions between input variables in the sample. It is proven that these interactions act like primitive inference patterns and can accurately predict all network outputs, no matter how we randomly mask the input sample\u00b3. An interaction refers to a non-linear relationship encoded by the DNN between a set of input variables in S. For example, as Figure 1 shows, a DNN may encode a non-linear relationship between the three image patches in $S = {X1,X2,X3}$ to form a dog-snout pattern, which makes a numerical effect I(S) on the network output. The complexity (or order) of an interaction is defined as the number of input variables in the set S, i.e., $\\text{order}(S) \\stackrel{\\text{def}}{=} |S|$.\nOur task. This study is inspired by the finding of Zhou et al. [45] that high-order (complex) interactions usually have a much higher risk of over-fitting than low-order (simple) interactions. Thus, in this study, we hope to track the change in the complexity of interactions during training, so as to"}, {"title": "Related work", "content": "Long-standing disappointment on the faithfulness of existing post-hoc explanation of DNNs.\nMany studies [30, 40, 29, 2, 15] have explained the inference score of a DNN, but how to mathemati-\ncally formulate and guarantee the faithfulness of the explanation is still an open problem. For example,\nusing an interpretable surrogate model to approximate the output of a DNN [3, 11, 35, 34] is a classic\nexplanation technique. However, the good matching between the DNN's output and the surrogate\nmodel's output cannot fully guarantee that the two models use exactly the same inference patterns\nand/or use the same attention. Therefore, many studies [28, 12, 1] have unanimously and empirically\narrived at a disappointing view of the faithfulness of current explanation methods. Rudin [28] pointed\nout that inaccurate post-hoc explanations of DNNs would be harmful to high-stakes applications.\nGhassemi et al. [12] showed various failure cases of current explanation methods in the healthcare\nfield and argued that using these methods to aid medical decisions was a false hope.\nProving interactions act as faithful inference primitives encoded by the DNN. Despite the disap-\npointing view of post-hoc explanation methods, recent achievements in interactions provide a new\nperspective to formulate primitive inference patterns encoded by a DNN. It has been discovered[23]\nand proven [27] that the DNN's inference on a certain sample can be explained by only a small number\nof interactions. Furthermore, [21] discovered that salient interactions usually represented common\ninference patterns shared by different samples, and [4] proposed a method to extract generalizable\ninteractions shared by different DNNs. Furthermore, [25] defined and learned the optimal baseline\nvalue for the Shapley value based on interactions. [5, 6] used interactions of different complexities to\nexplain the encoding of different types of visual patterns in DNNs for image classification.\nExplaining the representation capacity of DNNs using interactions. The multi-order interac-\ntion has been used to explain the adversarial robustness [24], adversarial transferability [37], and\ngeneralization ability [41] of a DNN. In addition, [26] proved that compared to a standard DNN,"}, {"title": "Dynamics of interactions", "content": "3.1\nPreliminary: interactions\nLet us consider a DNN $v$ and an input sample $x = [x_1,\\ldots,x_n]^\\intercal$ with $n$ input variables indexed by\n$\\mathcal{N} = \\{1,..., n\\}$. In different tasks, one can define different input variables, e.g., each input variable\nmay represent an image patch for image classification or a word/token for text classification. Let\nus consider a scalar output of a DNN, denoted by $v(x) \\in \\mathbb{R}$. Previous studies [4, 44] show that the\noutput score $v(x)$ can be decomposed into the sum of AND interactions and OR interactions.\n$v(x) = v(x_\\emptyset) + \\sum_{ \\emptyset \\neq S \\subseteq \\mathcal{N} } \\mathcal{I}_{\\text{and}}(S | x) + \\sum_{ \\emptyset \\neq S \\subseteq \\mathcal{N} } \\mathcal{I}_{\\text{or}}(S | x),$ (1)\nwhere the computation of $\\mathcal{I}_{\\text{and}}(S | x)$ and $\\mathcal{I}_{\\text{or}}(S | x)$ will be introduced later in Eq. (2).\nWe can understand AND-OR interactions as follows. Suppose that we are given an input sample\n$x$. According to Theorem 2, a non-zero interaction effect $\\mathcal{I}_{\\text{and}}(S | x)$ indicates that the entire function\nof the DNN must equivalently encode an AND relationship between input variables in the set $S \\subset \\mathcal{N}$,\nalthough the DNN does not use an explicit neuron to model such an AND relationship. As Figure 1\nshows, when the image patchs in the set $S_2 = \\{x_\\text{1=nose}, x_\\text{2=tongue}, x_\\text{3=cheek}\\}$ are all present (i.e.,\nnot masked), the three regions form a dog-snout pattern, and make a numerical effect $\\mathcal{I}_{\\text{and}}(S_2 | x)$\nto push the output score $v(x)$ towards the dog category. Masking any image patch in $S_2$ will\ndeactivate the AND interaction and remove $\\mathcal{I}_{\\text{and}}(S_2 | x)$ from $v(x)$. This will be shown by Theorem 2.\nLikewise, $\\mathcal{I}_{\\text{or}}(S | x)$ can be considered as the numerical effect of the OR relationship encoded by\nthe DNN between input variables in the set $S$. As Figure 1 shows, when one of the patches in\n$S_1=\\{x_\\text{4=spotty region1}, x_\\text{5=spotty region2}\\}$ is present, a speckles pattern is used by the DNN to make\na numerical effect $\\mathcal{I}_{\\text{or}}(S_1 | x)$ on the network output $v(x)$.\nFor each set $S \\subseteq \\mathcal{N}, S \\neq \\emptyset$, interactions $\\mathcal{I}_{\\text{and}}(S | x)$ and $\\mathcal{I}_{\\text{or}}(S | x)$ can be computed as follows [4, 44].\n$\\mathcal{I}_{\\text{and}}(S | x) = \\sum_{T \\subseteq S} (-1)^{|S|-|T|} v_{\\text{and}}(x_T), \\quad \\mathcal{I}_{\\text{or}} (S | x) = - \\sum_{T \\subseteq S} (-1)^{|S|-|T|}v_{\\text{or}} (x_{\\mathcal{N}\\backslash T}),$ (2)\nwhere $x_T$ denotes the sample in which input variables in $\\mathcal{N} \\backslash T$ are masked4, while input variables in\n$T$ are unchanged. The network output on each masked sample $v(x_T), T \\subseteq \\mathcal{N}$, is decomposed into two\ncomponents: (1) the component $v_{\\text{and}}(x_T) = 0.5v(x_T)+\\gamma_T$ that exclusively contains AND interactions,\nand (2) the component $v_{\\text{or}} (x_T) = 0.5v(x_T) - \\gamma_T$ that exclusively contains OR interactions, subject to\n$v(x) = v_{\\text{and}}(x_T) + v_{\\text{or}}(x_T)$. Appendix E.1 shows that $v_{\\text{and}}(x_T) = v(x_\\emptyset) + \\sum_{\\emptyset \\neq S' \\subseteq T} \\mathcal{I}_{\\text{and}}(S' | x)$ and\n$v_{\\text{or}} (x_T) = \\sum_{S' \\subset \\mathcal{N}: S' \\cap T \\neq \\emptyset} \\mathcal{I}_{\\text{or}} (S' | x)$. The sparsest AND-OR interactions are extracted by minimizing\nthe following objective [20]: $\\min_{\\{\\gamma_T\\}} \\sum_{S \\subseteq \\mathcal{N}} |\\mathcal{I}_{\\text{and}}(S | x)| + |\\mathcal{I}_{\\text{or}}(S | x)|$. See Appendix C for details.\nTheorem 1 (Sparsity property, proven by [27], and discussed in Appendix B). Given a DNN $v$\nand an input sample $x$ with $n$ input variables, let $\\Omega \\stackrel{\\text{def}}{=} \\{S \\subseteq \\mathcal{N} : |\\mathcal{I}_{\\text{and}}(S | x)| > \\tau\\}$ denote the set\nof salient AND interactions whose absolute value exceeds a threshold $\\tau$. If the DNN can generate\nrelatively stable inference outputs $v(x_S)$ on masked samples5, then the size of the set $|\\Omega|$ has an upper"}, {"title": "Two-phase dynamics of learning interactions", "content": "Zhang et al. [42] have discovered the following two-phase dynamics of interaction complexity during\nthe training process. (1) As Figure 2 shows, before the training process, the DNN with randomly\ninitialized parameters mainly encodes interactions of medium orders. (2) In the first phase, the DNN\nremoves initial interactions of medium and high orders, and mainly encodes low-order interactions.\n(3) In the second phase, the DNN gradually learns interactions of increasing orders.\nTo better illustrate this phenomenon, we followed [42] to conduct experiments on different DNNs,\nincluding AlexNet [17], VGG [31], BERT [9], DGCNN [38], and on various datasets, including\nimage data (MNIST [19], CIFAR-10 [16], CUB-200-2011 [36], and Tiny-ImageNet [18]), natural\nlanguage data (SST-2 [32]), and point cloud data (ShapeNet [39]). For image data, we followed [42]"}, {"title": "Proof of the two-phase phenomenon", "content": "Analytic solution to interaction effects\nAs the foundation of proving the dynamics of the two phases, let us first derive the analytic solution\nto interaction effects during the training process. The proof of the dynamics of interactions is\nconducted under the assumption that the DNN has unavoidable weight noises. Despite the simplifying\nassumptions, later experiments show that our theory can well predict the true dynamics of all AND-OR\ninteractions during the learning of real DNNs.\nReformulating the inference as a linear regression based on interaction triggering strength.\nFor simplicity, let us only focus on the dynamics of AND interactions, because OR interactions\ncan also be represented as a specific kind of AND interactions6 (see Appendix D for details). In\nthis way, without loss of generality, let us just analyze the learning of AND interactions w.r.t.\n$v_{\\text{and}}(x) = v(x_\\emptyset) + \\sum_{\\emptyset \\neq S \\subseteq \\mathcal{N}} \\mathcal{I}(S | x)$, and simplify the notation as $v(x) = v(x_\\emptyset) + \\sum_{\\emptyset \\neq S \\subseteq \\mathcal{N}} \\mathcal{I}(S | x)$\nin the following proof. Our conclusions can also be extended to OR interactions, as mentioned above.\nGiven a DNN, we follow [26, 22] to reformulate the inference function of the network $v(x)$, which is\ninspired by the universal matching property of interactions in Theorem 2, i.e., given any arbitrarily\nmasked input samples w.r.t. a random subset $S \\subset \\mathcal{N}$, the network output can always be represented\nas a linear sum of different interaction effects $v(x = x_S) = \\sum_{T \\subseteq S} \\mathcal{I}(T | x = x)$. Thus, the following\nequation rewrites the inference function of the DNN $v(x = x_S)$ as the weighted sum of triggering\nstrength of interaction patterns (see Appendix E.2 for proof).\n$\\sqrt{S \\subseteq \\mathcal{N}, v(x=x_S) = f(x=x_S)}, \\text{ subject to } f(x) \\stackrel{\\text{def}}{=} \\sum_{T \\subseteq \\mathcal{N}} w_T \\mathcal{J}_T(x),$ (6)\nwhere the function $\\mathcal{J}_T(x)$ is a real-valued approximation of the binary indicator function\n$\\mathbb{1}(x_S \\text{ triggers the AND relation } T)$ in Eq. (3) and returns the triggering strength of the interaction\npattern $T$. In particular, we set $w_\\emptyset = v(x = x)$, $\\mathcal{J}_\\emptyset(x) = 1$. $\\mathcal{J}_T(x)$ is computed as a sum of\ncompositional terms in the Taylor expansion of $v(x)$.\n$\\mathcal{J}_T(x) = \\sum_{\\pi \\in \\Omega_T} \\prod_{i=1}^n \\frac{1}{\\pi_i!} \\frac{\\partial^{\\pi_1+\\ldots+\\pi_n}v}{\\partial x_1^{\\pi_1}\\ldots \\partial x_n^{\\pi_n}} \\Big|_{x=x_\\emptyset} (x_i - b_i)^{\\pi_i}/w_T,$ (7)\nwhere the scalar weight $w_T$ should be computed as $w_T = \\mathcal{I}(T | x=x)$ to satisfy the equality in Eq. (6),\nand $\\Omega_T = \\{\\[\\pi_1,\\ldots, \\pi_n\\]^\\intercal | \\forall i \\in T, \\pi_i \\in \\mathbb{N}^+; \\forall i \\notin T, \\pi_i = 0\\}$. See Appendix E.2 for proof.\nUnderstanding $\\mathcal{J}_T(x)$ and $w_T$. Let us consider a masked sample $x_S$ in which input variables in\n$\\mathcal{N}\\backslash S$ are masked. If $T \\subseteq S$, which means all input variables in $T$ are not masked in $x_S$, then\n$\\mathcal{J}_T(x_S) = 1$, indicating the interaction pattern is triggered; otherwise, $\\mathcal{J}_T(x_S) = 0$, indicating the\ninteraction pattern is not triggered. $w_T$ is a scalar weight. Particularly, let $\\mathcal{I}_f(T | x)$ denote the\ninteraction extracted from the function $f(x) = \\sum_{T \\subseteq \\mathcal{N}} w_T \\mathcal{J}_T(x)$, then we have $\\mathcal{I}_f(T | x) = w_T$.\nBased on Eq. (6), the learning of a DNN is reformulated as the learning of the scalar ef-\nfect/weight $w_T$ for each interaction triggering function $\\mathcal{J}_T(x)$. In this way, we analyze the training\nprocess of a DNN in the new setting of linear regression in Eq. (8). We can roughly consider the\nlearning problem as a regression to a set of potentially true interactions, because it has been discovered\nby [21, 4] that different DNNs for the same task usually encode similar sets of interactions. Therefore,\nthe learning of a DNN can be considered as training a model to fit a set of pre-defined interactions.\nIn spite of the above simplifying settings, subsequent experiments in Figure 4 still verify that our\ntheoretical results can well predict the learning dynamics of interactions in real DNNs.\nSpecifically, let the DNN be trained on a set of samples $\\mathcal{D} = \\{(x,y)\\}$. According to The-\norem 2, given each training sample $x$, output scores of the finally converged DNN on all $2^n$\nrandomly masked samples $\\{x_S : S \\subseteq \\mathcal{N}\\}$ can be written in the form of $y_S \\stackrel{\\text{def}}{=} y(x_S) = v(x_\\emptyset) +"}, {"title": "Conclusion", "content": "In this study, we have proven the two-phase dynamics of a DNN learning interactions of different\norders. Specifically, we have followed [26, 22] to reformulate the learning of interactions as a linear\nregression problem on a set of interaction triggering functions. In this way, we have successfully\nderived an analytic solution to interaction effects when the DNN was learned with unavoidable\nparameter noises. This analytic solution has successfully predicted a DNN's two-phase dynamics\nof learning interactions in real experiments. Considering a series of recent theoretical guarantees of\ntaking interactions as faithful primitive inference patterns encoded by the DNN [45, 27], our study\nhas first mathematically explained why and how the learning process gradually shifts attention from\ngeneralizable (low-order) inference patterns to probably over-fitted (high-order) inference patterns."}]}