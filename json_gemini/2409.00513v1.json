{"title": "PLANT DETECTION FROM ULTRA HIGH RESOLUTION REMOTE SENSING IMAGES: A SEMANTIC SEGMENTATION APPROACH BASED ON FUZZY LOSS", "authors": ["S. Pande", "B. Uzun", "F. Guiotte", "M.T. Pham", "T. Corpetti", "F. Delerue", "S. Lef\u00e8vre"], "abstract": "In this study, we tackle the challenge of identifying plant species from ultra high resolution (UHR) remote sensing images. Our approach involves introducing an RGB remote sensing dataset, characterized by millimeter-level spatial resolution, meticulously curated through several field expeditions across a mountainous region in France covering various landscapes. The task of plant species identification is framed as a semantic segmentation problem for its practical and efficient implementation across vast geographical areas. However, when dealing with segmentation masks, we confront instances where distinguishing boundaries between plant species and their background is challenging. We tackle this issue by introducing a fuzzy loss within the segmentation model. Instead of utilizing one-hot encoded ground truth (GT), our model incorporates Gaussian filter refined GT, introducing stochasticity during training. First experimental results obtained on both our UHR dataset and a public dataset are presented, showing the relevance of the proposed methodology, as well as the need for future improvement.", "sections": [{"title": "1. INTRODUCTION", "content": "Recent advancements in sensing technologies have significantly boosted research in the remote sensing community. With improved sensors, a vast amount of geospatial data from multiple sources and modalities is now available at ultra-high resolution (UHR). Land-cover mapping remains one of the most common yet challenging problems, and the challenges increase with UHR data due to high dimensionality, labeling costs, and large geographical areas [1, 2]. In this study, we address a similar problem of plant species identification, which is a primary objective of our project: Positive Plant-Plant interactions and spatial Patterns in Pyrenean Post-mine tailings"}, {"title": "2. METHODOLOGY", "content": "We discuss here the datasets used in our study, the data preprocessing aspects, and the creation of fuzzy labels leading to the implementation of the semantic segmentation model."}, {"title": "2.1. Dataset", "content": "Our SixP dataset: The data, acquired from UHR drone imagery and field surveys, includes visible (red, green, blue, i.e., RGB) and multispectral (RGB + near-infrared) photographs, but we only employ RGB data in this study. These images are orthorectified, mosaicked, and georeferenced, achieving 2-3 mm per pixel resolution. Data collection spanned eight zones in a complex study site in the Pyrenees, France. Field surveys provided reference data, with ecologists recording plant positions, identifications, and characteristics within quadrats of 1 to 25 m\u00b2. Multiple quadrats were sampled per site. Raw plant data include differential GPS (DGPS) positions, species information, diameters, and area identifiers, with some plants defined by polygons.\nThe Weed Dataset: Since our SixP dataset is not yet publicly available, we rely on a similar public dataset for weed detection [7]. This collection features diverse weed species from various environments, climates, and conditions, reflecting real-world detection challenges. Each high-resolution image is meticulously annotated to identify weed presence and location, aiding in training and assessing computer vision models. The dataset also includes metadata such as location, date, and plant information to provide additional contexts [7]."}, {"title": "2.1.1. Data preprocessing", "content": "For both datasets, the ground truths are provided in the form of circular or elliptical box annotations around the plant species. Hence, to formulate the segmentation problem, the rings are converted to the segmentation masks. In our case, we treat the plant identification problem as a binary segmentation task, where the plant species represent the foreground, while the rest of the image is considered as the background. We tackle the semantic segmentation task from two different perspectives. The first one is the conventional semantic segmentation problem, where the values inside each ring are homogeneously declared as the foreground. In the second approach, we use a Gaussian mask and convolve it over the image such that the values closer to the centre of the plant have a higher magnitude in the GT, while as we move away from the plant centre and towards the periphery, the certainty of a the pixel being denoted as plant decreases. After creation of the GT, the images were divided into smaller patches of 640 \u00d7 640 and 320 x 320 pixels, for SixP and Weed dataset, respectively."}, {"title": "2.2. Problem definition", "content": "After pre-processing the dataset, let us consider a set of UHR RGB images denoted as $X = {x^i}_{i=1}^n$ such that $X \\in \\mathbb{R}^{P\\times Q\\times B}$. Here, n is the number of samples, while P and Q are spatial dimensions, and B is the number of channels. The corresponding GT for the images is given as $Y = {y^i}_{i=1}^n$ such that $Y \\in \\mathbb{R}^{P\\times Q\\times C}$. Here, C represents the total number of classes. The entire problem is posed as a semantic segmentation task such that each pixel in X can be mapped to a corresponding class in Y."}, {"title": "2.3. Creation of fuzzy labels", "content": "To account for the spatial imprecision inherent in class delineation, we present a novel approach involving the modeling of spatial confidence within the reference data. Our method entails convolving the pixel membership to a class with a Gaussian kernel, leveraging its ability to represent the spatial probability of class membership based on the standard deviation of DGPS errors. The kernel is represented in Eq. (1), where $y_p$ and $y_q$ represent the spatial locations in the image, while $\\sigma_u$ is the standard deviation that is treated as a hyperparameter:\n$G_{2D}(y_p, y_q, \\sigma_u) = \\frac{1}{2\\pi \\sigma_u^2} exp(-\\frac{||y_p-y_q||^2}{2 \\sigma_u^2})$\nThe modified GT can be represented as $y_G = G_{2D}(y)$. The proposed implementation augments the cost functions with an initial step aiming at ensuring the integration of spatial confidence modeling. The efficiency of convolutions, particularly on GPUs, is harnessed for this purpose. Additionally, the 2D decomposition of Gaussian kernels proves advantageous, leading to significant acceleration in computational speed."}, {"title": "2.4. Model architecture", "content": "In this study, we exclusively used the U-Net network [8]. This choice was motivated by its versatility and significant presence in the state-of-the-art, but let us emphasize that our contributions can be implemented with other models as well. The network consists of an encoder E to downsample the original image to a bottleneck representation $E(x^i)$, and a decoder D to upsample the bottleneck representation to $D(E(x^i))$. The last layer of the decoder represents a softmax layer, that outputs the probabilities for the different pixels in the images to belong to the different classes. Since we are working with fuzzy labels, we present a modified fuzzy loss function that converts the classification aspect of the segmentation task to a regression based setting. For the training, we use different loss functions, such as binary cross-entropy (BCE), mean-squared error (MSE) and cosine similarity (CS) between the fuzzy GT and the calculated probabilities from the network (see Eq. 2, 3 and 4 for the respective losses), on which the model is trained.\n$\\text{loss}_{CE} = -y_G \\text{log} D(E(x^i))$\n$\\text{loss}_{MSE} = (y_G - D(E(x^i)))^2$\n$\\text{loss}_{CS} = 1 - \\frac{y_G .D(E(x^i))}{||y_G||||D(E(x^i))||}$\nIn the inference phase, the validation/test images are sent to the trained model and the corresponding class probabilities are obtained, from which is performed class assignment."}, {"title": "3. EXPERIMENTS AND PRELIMINARY RESULTS", "content": "In this section, we will discuss the experimental setup and the preliminary results of our investigation."}, {"title": "3.1. Training protocols and evaluation", "content": "The optimization is carried out using Adam optimizer with Nesterov momentum [9] with an initial learning rate of 0.0005 and a gradual learning rate decay. All the models are trained on a Nvidia A6000 GPU. For evaluation, we use overall accuracy, classwise accuracy, Cohen's kappa and F1-score, for the conventional segmentation case. In case of fuzzy loss based segmentation, we use regression based metrics such as mean squared error and cosine similarity."}, {"title": "3.2. Results and discussion", "content": "Table 1 illustrates the semantic segmentation outcomes in the conventional context for both datasets. The overall accuracy stands at 91.49% for the SixP dataset and 95.95% for the Weed dataset. However, despite these high accuracies, the and F1-scores are relatively diminished due to significant class imbalances. This imbalance is evident in the class-wise accuracy of the foreground (plants) for both datasets. Table 2 displays results employing a fuzzy loss-based approach, where the cosine loss yields optimal performance for the SixP dataset, while the cross-entropy loss proves most effective for the Weed dataset.\nFigs. 4 and 5 exhibit the visual outcomes of segmentation methods applied to the SixP and Weed datasets, respectively. These figures showcase segmentation and probability maps derived from logits, emphasizing the accuracy of predictions at the centers of plant species. Particularly in the Weed dataset (Fig. 5), the impact of the fuzzy label-based approach is evident, with the probability density map effectively discerning weeds, unlike the traditional model. This can be noticed by comparing the bottom part of Fig. 5 (b) and (e). However, such distinctions are less pronounced in the SixP dataset, possibly due to highly imbalanced classes and increased label noise, which pose challenges in segmentation. Notably, smaller plants are entirely overlooked, suggesting that Gaussian smoothing might suppress crucial details alongside label noise."}, {"title": "4. CONCLUSION", "content": "In this research, we have introduced a new RGB dataset (a.k.a. the SixP dataset) on UHR remote sensing images for the task of plant species identification on a large scale. We have formulated the plant species detection as a semantic segmentation problem for efficient and accurate identification. Simultaneously, to tackle the challenges of noisy and overlapping GT labels, we have introduced a fuzzy loss function, that morphs the hard-coded GT to a more stochastic representation using Gaussian kernel. We have showcased the performance of the models on two plant species detection datasets (our SixP dataset and the public Weed Image Detection dataset), while the strengths and weaknesses of both the approaches are identified. We conclude from these first experiments that, due to a high class imbalance and the severity of noisy labels in the SixP data, further research is required to ensure better identification of plant species in such a complex but realistic ultra-high resolution imaging scenario."}]}