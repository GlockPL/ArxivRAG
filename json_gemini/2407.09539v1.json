{"title": "Classification of Inkjet Printers based on Droplet Statistics", "authors": ["Patrick Takenaka", "Manuel Eberhardinger", "Daniel Grie\u00dfhaber", "Johannes Maucher"], "abstract": "Knowing the printer model used to print a given document may provide a crucial lead towards identifying counterfeits or conversely verifying the validity of a real document. Inkjet printers produce probabilistic droplet patterns that appear to be distinct for each printer model and as such we investigate the utilization of droplet characteristics including frequency domain features extracted from printed document scans for the classification of the underlying printer model. We collect and publish a dataset of high resolution document scans and show that our extracted features are informative enough to enable a neural network to distinguish not only the printer manufacturer, but also individual printer models.", "sections": [{"title": "I. INTRODUCTION", "content": "Printing text on paper has been the basis for communication and the dissemination of information for a long time. While nowadays many paper-driven processes are gradually digitized, they still play a crucial role in daily life. At the same time, new technologies make it easy for non-experts to use high-quality printing methods to forge or alter documents. These technologies include inexpensive printers and scanners, various image processing software and also tools supported by artificial intelligence [1]. The incentive for criminal activity is high, as the entry barrier for interested individuals is low and there are many different types of possible forgeries, such as concert tickets, travel tickets, banknotes, fake IDs or other kinds of personal documents. Additionally, it is hard for non-experts to decide if the presented documents are genuine or forged. These points make it difficult for law enforcement authorities and also for counterfeit detection in banks to keep up with the latest counterfeits [2]. Identifying the printer model that was used to produce a particular document is an important aspect for determining whether it is genuine or fake, as in many circumstances the printer model for genuine documents is known and thus can be compared with.\nFor laser printers, there is already a solution for recognizing which printer has created a document by decoding the machine identification code, which is displayed as yellow dots on the document and is not visible to the naked eye. For inkjet printers, however, there is still no general method applicable without the help of spectroscopy [3]\u2013[6]. In this work, we present a method that works only with digital image data from high-quality scans, without the need for the original document or additional specialized hardware, such as Raman Spectrom- eters. Machine learning, and especially deep learning, often requires large amounts of labeled data, which in the case of printer identification is challenging due to the logistical chal- lenges of gathering many high-resolution scans from various printers. To mitigate this problem, we introduce a carefully designed feature extraction from image data and show that this leads to significantly better classification performance than relying on image features alone. Our core assumption is that each printer model exhibits distinct droplet patterns, and by extracting features based on the frequencies in those patterns we can capture their identity. Based on insights from domain experts we continue by also adding features related to droplet shapes specifically, such as their areas and boundaries, and thus arrive at a feature vector that both captures the patterns and the visual aspects as well.\nWe further introduce a training and evaluation scheme that can handle the large amounts of data present in a high- resolution scan in an efficient manner and verify it empirically. An overview of the overall classification process is shown in Fig. 1.\nWe further collect and introduce a dataset for printer identification, which consists of 50 high-resolution scans of documents printed from 25 different printer models across multiple manufacturers. To the best of our knowledge there is no other dataset in this scale publicly accessible for printer identification. Our dataset and code is available at https: //github.com/P-Takenaka/ijcnn2024-inkjet-classification."}, {"title": "II. RELATED WORK", "content": "The task of identifying or distinguishing printers has long been of great interest [7]\u2013[11] and is usually done with spec- troscopy in combination with machine learning approaches [3]\u2013[6]. Another approach is using textual features based on the differences in the geometric distortion of printed fonts [12]\u2013[15]. Other work focuses on detecting if barcodes were printed from the same source [16]. In our work, however, we do not constrain the image regions\u2014to for instance barcodes\u2014 used for classification in order to allow better generalization across a wide variety of documents. A similar work based on feature engineering has been studied in [17], where a feature vector is computed over different quality assurance metrics such as color variations, but the study is limited to only four printers and four scanners. In [18], the discrete wavelet transform was used to extract features from printed documents to classify the source printer for Chinese characters. In [19], [20], several different feature extraction methods were studied and compared, focusing only on laser printers. Our work, in contrast, focuses on inkjet-printers.\nIn contrast to printer identification, there is also research aimed at anonymizing documents [21] or using Siamese neural networks to predict whether two documents were printed by the same printer [22].\nFrequency-based features are often used to reduce the difficulty of the problem for machine learning algorithms. The Fourier transform is used in the field of medical imaging to improve the performance of deep learning models [23]\u2013[25] or for fraud detection in manufacturing plants [26], [27]. Wavelet features are widely used across all domains, e.g. for medical purposes [28]\u2013[31], for high-resolution image reconstruction [32], for seismic data reconstruction [33] or the prediction of emissions into the atmosphere [34]."}, {"title": "III. BACKGROUND", "content": "Here we first describe the necessary background for fre- quency domain transformation, and\u2014in order to give a better picture of the intuition behind our feature extraction-continue by illustrating the general printing process prevalent in inkjet- printing.\nA. Frequency Domain Features\nIn the following we describe the theory of different established methods for transforming an-possibly multi- dimensional-input signal into the frequency domain.\nFourier Analysis: The Fourier transform converts an input signal from the temporal- or, in our case spatial domain into frequency domain by deconstructing the signal into a series of (possibly infinite) sine and cosine waves. For discrete, equally spaced signals the discrete Fourier transform (DFT) therefore is a Z-transform that converts the signal x(t) of length T into T complex coefficients so that\n$$X(k) = \\sum_{t=0}^{T-1} x(t)\u00b7e^{-it}$$\nwhere X(k) are polar coordinates defining the phase and amplitude of the sinusoidal component of the signal x(t) with frequency. The resulting coefficients of the Fourier transform therefore describe global frequency information of the input signal.\nWavelet Transform: While the DFT, and Fourier analysis in general, have the limitation to only capture global frequency information, wavelet transformations are able to preserve the temporal or spatial locality information while also capturing the spectral transformation of the signal. The discrete wavelet transformation (DWT) of a one-dimensional signal x(t) can be described as\n$$W(m, n) = \\sum_{t=0}^{T-1} \\psi_{m,n}(t) \u00b7 x(t)$$\nwhere $\\psi_{m,n}(t)$ is a mother-wavelet function that is scaled by m and translated by n, so that $W_{\\psi}(m,n)$ describes the"}, {"title": "B. Inkjet Printing", "content": "Inkjet printers construct an image by placing droplets of colored ink onto a medium. The droplets can be produced by different methods such as thermal expansion or mechanical stimulation using piezo electric devices [35, p. 58 ff.]. In the most common setting that is of interest here, the droplets are ejected onto a white paper medium, so that the density of droplets can be used to perform subtractive color mixing to create arbitrary colors by only using a few primary colors, most commonly magenta, cyan and yellow. For text and other black and white printouts, often there is an additional black ink to avoid the need to mix this common color. Due to the limited resolution of the human eye, areas of small dots, even if non- overlapping, will be perceived as a single color depending on the density of dots of each primary color.\nThe size of dots produced by inkjet printers typically varies between 10 100\u03bcm [35, p. 10]. To produce drops of this size with the required accuracy and frequency, basic physical properties of the used ink need to be considered such as surface tension and viscosity. Since typically printing is done in multiple lines, the ink nozzles and medium move relative to another, requiring planning of acceleration and timing of drop ejection. Due to this complexity, the position and size of the individual dots depends not only on physical factors such as the ejection method, nozzle size and mechanical tolerances but also on the algorithms implemented in the firmware of the printer."}, {"title": "IV. DATA", "content": "A dataset consisting of A4 scans of high resolution printed documents was collected with the help of various potential users of our system, leading to printing conditions that would occur in a real-world usage setting. In total, 25 unique printer models were used to print out a printing template (cf. Fig. 2) containing varied content, such as text areas or portrait images."}, {"title": "A. Feature Extraction", "content": "Inkjet printers produce droplet patterns of a probabilistic nature. Upon taking a closer look (cf. Fig. 3) these patterns appear to be highly dependent on the printer model used and it leads to the question of what are the distinct factors that make up an individual printer model.\nWe decided to focus on two main aspects contained in these patterns: (1) The frequencies present in the image in order to capture the overall, global pattern of droplets, and (2) the droplet shape in order to capture detailed, local information. However, using these features directly would not be suitable as the feature vector would be too large and likely result in overfitting. As such, we compress them further by calculating their general statistics (cf. Tab. I), which ideally removes"}, {"title": "V. EXPERIMENTS", "content": "A. Setup\nFor our classifier model we use a Multi-Layer Perceptron (MLP) with three hidden layers, each composed of 512 neu- rons and subsequent hyperbolic tangent activation functions. Among other classifier models we have found a neural network to be the most reliable (cf. Sec. V-D for ablations).\nThe training process minimizes the cross-entropy loss using the Adam Optimizer [36] with an initial learning rate of 1e-4"}, {"title": "VI. LIMITATIONS AND FUTURE WORK", "content": "While we have shown that manually extracted frequency- based features are better than relying on image features di- rectly, there is still room for further improvements. Especially in the area of forensics a high level of confidence and reliance is necessary in order to integrate such a system in the work- flow. One aspect that makes the whole endeavour challenging in general is the difficulty in obtaining large amounts of data that correspond to a wide variety of printing conditions, however our dataset can be a suitable basis in this regard to expand upon. For this reason and due to the large amount of different printer models in the real world, it is highly likely that a tested document is from a printer model not available in the dataset. As such, model extensions that can predict such outliers is a promising direction for future work that makes this more applicable.\nFurthermore, in this work we have analyzed image-based features and our manually extracted features separately. It might be even better to fuse both types of features in a single model to also let the model extract useful features on its own. These could then potentially replace the droplet-based features that we utilized. However at this time the limiting factor here seems to be the small amount of data available. As such, a clear future direction is the expansion of the dataset both in terms of document content variety and also new printer models. We reckon that, as in other areas, deep learning methods will gradually become more important the larger the data basis gets.\nAn interesting other direction for future work might be the identification of not only the printer model used, but also the printer instance. The hypothesis is that due to mechanical wear or slight manufacturing differences the droplet dispersion pattern varies even among same printer models. It would be interesting to pursue whether this can be detected from the features that we proposed as well. Similarly, the used scanner device might also be an important factor that should be taken into account. In our dataset we used only a single scanning device, in reality however this is difficult to enforce. There- fore analyzing the performance on documents scanned with different scanning devices might provide valuable insights."}, {"title": "VII. CONCLUSION", "content": "We introduced a novel dataset and corresponding training and evaluation scheme for printer model identification that works without specialized scanning hardware. We proposed a set of manually extracted features which lead to substantial performance improvements over relying on image features alone, and show that wavelet-based frequency features best capture the printer identities. In the future this work will be part of a system to be used by document forensics experts."}]}