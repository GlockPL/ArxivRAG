{"title": "Flow: A Modular Approach to Automated Agentic Workflow Generation", "authors": ["Boye Niu", "Yiliao Song", "Kai Lian", "Yifan Shen", "Yu Yao", "Kun Zhang", "Tongliang Liu"], "abstract": "Multi-agent frameworks powered by large language models (LLMs) have demonstrated great success in automated planning and task execution. However, the effective adjustment of Agentic workflows during execution has not been well-studied. A effective workflow adjustment is crucial, as in many real-world scenarios, the initial plan must adjust to unforeseen challenges and changing conditions in real-time to ensure the efficient execution of complex tasks. In this paper, we define workflows as an activity-on-vertex (AOV) graphs. We continuously refine the workflow by dynamically adjusting task allocations based on historical performance and previous AOV with LLM agents. To further enhance system performance, we emphasize modularity in workflow design based on measuring parallelism and dependence complexity. Our proposed multi-agent framework achieved efficient sub-task concurrent execution, goal achievement, and error tolerance. Empirical results across different practical tasks demonstrate dramatic improvements in the efficiency of multi-agent frameworks through dynamic workflow updating and modularization.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) [17, 26] show remarkable abilities to understand and generate human-like text. Recent advances have significantly enhanced their capability to emulate human reasoning [18], indicating a promising future for LLM-based reasoning. With the powerful ability to deal with a variety of natural language processing tasks, these models underpin a wide range of applications, from conversational agents [25] and content creation tools [24] to advanced analytics and decision-making systems [15, 20]. Building upon this foundation, a key advancement is the development of multi-agent systems empowered by LLMs [9, 8, 7, 23, 21, 4] where multiple LLM-based agents collaborate to address the same task, leveraging their collective reasoning and planning abilities to automate and optimize task execution processes.\nExisting LLMs-based multi-agent systems define LLM as an agent and agents are collaborated with each others via manually designed or LLM-generated prompts. Specifically, MetaGPT [7] focuses on programming tasks by leveraging Standardized Operating Procedures (SOPs) [22, 5, 2]. It predefined distinct roles such as product manager, project manager, and engineer. For each role, an LLM agent is initialized, and these agents follow a strict and sequential workflow to execute sub-tasks. CAMEL [8] is designed to complete a variety of tasks. It requires users to predefine two agents. These agents interact and execute tasks sequentially, with each agent taking on specific responsibilities. AutoGen [23] is also aimed at completing diverse tasks. Unlike CAMEL, AutoGen can automatically create an agent list with different roles based on the task requirements. These agents execute tasks sequentially following the order in the list.\nBuilding upon the strengths of current multi-agent systems, our work aims to further improve existing general-purpose multi-agent systems by enabling dynamically updating workflows during task execution and encouraging modularity in workflows when planning the workflows.\nSpecifically, dynamic updating workflow allows to adjust sub-task allocations and agent roles in real-time based on ongoing performance feedback and changing conditions. This capability ensures that the system remains responsive and efficient even when faced with unexpected obstacles. For instance, if an agent encounters a roadblock in data preprocessing, dynamic updating allows the system to reassign the sub-task to another agent or introduce a new sub-task to overcome the challenge. This adaptability is essential for maintaining robustness and ensuring the seamless execution of complex tasks.\nModularization in system design involves dividing a system into separate, independently operating modules, each responsible for specific functionalities [1]. A highly modularized system allows each module to be developed, managed, and executed in isolation, which simplifies system design and enhances adaptability. In our context, modularization refers to the decomposition of a complex task into smaller, interchangeable sub-task modules. A highly modularized workflow enables sub-tasks to execute concurrently, without bottlenecks from other parts of the workflow. It directly improves the operational efficiency of multi-agent frameworks. In addition, modularity dramatically enhances the ease of dynamic updating. When workflows are highly modularized, the dependency complexity between sub-tasks is small. Therefore, updating one sub-task does not necessitate changes in others, allowing for small adjustments. For instance, if an agent responsible for data preprocessing encounters an unexpected obstacle, the system can dynamically introduce a new sub-task to address the issue with little influence on the rest of the workflow.\nIn this paper, we have improved existing multi-agent systems by fulfilling modularity and"}, {"title": "3 Method", "content": "Our proposed framework enhances multi-agent frameworks powered by LLMs by introducing modularity and dynamic workflow updating. This section details how we achieve these features.\nFormulating a Workflow as an AOV Graph Activity on Vertex (AOV) graph is a type of directed acyclic graph (DAG) where vertices represent tasks and edges denote precedence relations [3]. AOV Graphs are crucial in project scheduling and management [11, 19], helping planners visualize dependencies and sequence tasks efficiently.\nInspired by that, we define Multi-Agent workflow as an AOV Graph where vertices represent sub-tasks, with its edges denoting dependencies between these sub-tasks. Let \\(G = (V, E, A)\\) denote the AOV Graph, where V is the set containing all sub-tasks (nodes), \\(E \\subset V \\times V\\) represents the set of directed edges indicating sub-task dependencies, and A represents a set of agents for all sub-tasks. Each agent \\(a_j \\in A\\) is associated with a role \\(s_j\\) and is responsible for executing a subset of tasks \\(T_j \\subset V\\). We also generate sub-tasks and each directed edge \\(e_{ij} = (V_i, V_j) \\in E\\) indicates that sub-task \\(v_i\\) must be completed before sub-task \\(v_j\\) can be started.\nNote that AutoGen [23] also automatically generates sub-tasks and agents. However, the sub-tasks are designed to be executed sequentially. For Flow, we allow for the generation of complementary sub-tasks that can run in parallel. This distinction enhances our system's ability to handle multiple tasks simultaneously, which reduces overall process time and increases efficiency.\nModularity in a Workflow Modularity in system design [1] involves dividing a system into separate, independently operating modules, each responsible for specific functionalities, allowing focus on individual components without affecting the entire system. In the context of workflows, we advocate for the creation of sub-tasks that can be executed independently. Modularity is essential for scalability and flexibility in workflows. By reducing dependency complexity, the system can more easily adapt to changes, such as the introduction of new tasks or the reassignment of existing ones, without requiring extensive restructuring. In below theorem, we show that introducing additional dependencies in a workflow reduces the expected success rate of subtasks.\nTheorem 3.1. Consider two topologically sorted workflows A and B each consisting of N subtasks according to their execution order. Suppose:\n1. (Random fail probability) Each subtask \\(t \\in T\\) fails with probability \\(p_f\\), where \\(0 < p_f < 1\\).\n2. (Additional dependency in Workflow B) There exists at least one subtask \\(t^* \\in T\\) and a subtask \\(a \\in T\\) such that the set of immediate predecessors (dependencies) of \\(t^*\\) in Workflow B is \\(D_B(t^*) = D_a(t^*) \\cup \\{a\\}\\), where \\(D_a(t^*)\\) is the set of immediate predecessors of \\(t^*\\) in Workflow A. For all other subtasks \\(t \\neq t^*\\) \\(D_a(t) \\subseteq D_B(t)\\).\nThen the expected number of successfully completed subtasks in Workflow A is strictly greater than in Workflow B: \\(E[S_A] > E[S_B]\\).\nTo encourage modularity in the generated AOV Graph, we define two quantitative measures that evaluate parallelism and dependency complexity, respectively. Parallelism measures the extent to which tasks can be executed concurrently. Let \\(S_t\\) represent the set of tasks executed at step t. Let T be the total number of steps (the maximum depth of The DAG). Given an AOV Graph"}, {"title": ""}]}