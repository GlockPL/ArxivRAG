[{"title": null, "authors": ["Yulong Wang", "Tianhao Shen", "Lifeng Liu", "Jian Xie"], "abstract": "Existing agents based on large language models (LLMs) demonstrate robust\nproblem-solving capabilities by integrating LLMs' inherent knowledge, strong in-\ncontext learning and zero-shot capabilities, and the use of tools combined with in-\ntricately designed LLM invocation workflows by humans. However, these agents\nstill exhibit shortcomings in long-term reasoning and under-use the potential of\nexisting tools, leading to noticeable deficiencies in complex real-world reasoning\nscenarios. To address these limitations, we introduce Sibyl, a simple yet power-\nful LLM-based agent framework designed to tackle complex reasoning tasks by\nefficiently leveraging a minimal set of tools. Drawing inspiration from Global\nWorkspace Theory, Sibyl incorporates a global workspace to enhance the manage-\nment and sharing of knowledge and conversation history throughout the system.\nFurthermore, guided by Society of Mind Theory, Sibyl implements a multi-agent\ndebate-based jury to self-refine the final answers, ensuring a comprehensive and\nbalanced approach. This approach aims to reduce system complexity while ex-\npanding the scope of problems solvable\u2014from matters typically resolved by hu-\nmans in minutes to those requiring hours or even days, thus facilitating a shift\nfrom System-1 to System-2 thinking. Sibyl has been designed with a focus on\nscalability and ease of debugging by incorporating the concept of reentrancy from\nfunctional programming from its inception, with the aim of seamless and low\neffort integration in other LLM applications to improve capabilities. Our experi-\nmental results on the GAIA benchmark test set reveal that the Sibyl agent instan-\ntiated with GPT-4 achieves state-of-the-art performance with an average score of\n34.55%, compared to other agents based on GPT-4. We hope that Sibyl can in-\nspire more reliable and reusable LLM-based agent solutions to address complex\nreal-world reasoning tasks.", "sections": [{"title": "INTRODUCTION", "content": "Large language models (LLMs) have transformed the landscape of human-computer interaction\n(HCI) by offering unprecedented capabilities in understanding and generating human-like text.\nLLM-based agents, which are systems designed to harness these models, effectively orchestrate\nLLM capabilities to address complex tasks (Xi et al., 2023; Wang et al., 2024). These agents lever-\nage human-designed frameworks that utilize the inherent knowledge within LLMs, often employing\nstructured workflows that maximize the potential of in-context learning and zero-shot capabilities.\nSuch strategies allow these agents to engage in sophisticated dialogues and problem-solving sce-\nnarios that mirror human cognitive processes (Sumers et al., 2023). By incorporating prior human\nknowledge into the workflow, LLM-based agents can process and utilize information with a level of\nproficiency that was previously unattainable.\nDespite their abilities, LLM-based agents are often limited by their inability to engage in complex\nquestions of reasoning in real-world scenarios, where the number of reasoning steps can be nu-\nmerous (Mialon et al., 2023). While LLMs excel in simpler, quick-answer scenarios, they struggle"}, {"title": "", "content": "significantly when tasks demand lengthy, complex reasoning chains, often resulting in error prop-\nagation and a steep decline in accuracy. To address these complex real-world problems, existing\nsystems are often intricately designed, leading to complexity that makes them difficult to evolve or\noptimize. This complexity not only impedes their practical deployment, but also restricts their adapt-\nability and scalability in various LLM applications, which underscores the need for an approach that\nhas simple design while improving the reasoning capabilities of LLM-based agents.\nFurthermore, long-context management also remains a significant hurdle in LLM applications. The\ncollection of abundant external information (e.g, computation output and error messages during\ncoding, or intricate web content) creates a high demand for managing long context sizes effectively\nwithin the LLM's processing capabilities. However, Hsieh et al. (2024) found that there exists a\nnotable gap between the claimed length (the designed maximum context size a model can handle)\nand the effective length (the maximum context size a model can effectively manage) that LLMs\ncan process. On the other hand, the challenge of long contexts is further compounded by the need\nto integrate information from various sources and data formats, often leading to \"context dilution\"\nproblem where valuable information is overwhelmed by the sheer volume of data (Xu et al., 2023;\nShi et al., 2024). Effective context management is crucial to ensure that LLMs can maintain focus\non relevant information without being sidetracked by less pertinent details. As such, addressing\nthis gap is not just about increasing the raw capacity of models to handle more data but also about\nimproving their ability to discern and prioritize information that is most critical for the task at hand.\nTo address the identified limitations in long-term reasoning and system complexity, we introduce\nSibyl, a simple yet powerful LLM-based agent framework. The system is compartmentalized into\nfour main modules: tool planner, external information acquisition channel, a jury based on multi-\nagent debate and a global workspace. Specifically, we introduce an external information acquisition\nchannel to receive and process external information from selected tools. To efficiently compress\nthe received information, we integrate the concept of dialogue states from task-oriented dialogue\nsystems (Budzianowski et al., 2018; Quan et al., 2020; Moradshahi et al., 2023) into the channel\nand design a representation language for the compressed information. This adaptation allows for\nthe selective compression of external information, focusing only on incremental details pertinent to\nsolving problems, which diverges from the traditional method of simply appending external infor-\nmation to the conversational history. By doing so, it not only elevates the quality and relevance of\nthe information processed by LLMs but also conserves context length, allowing for more extended\nsteps in reasoning. In addition, we design a global workspace inspired by the Global Workspace\nTheory (Baars, 1993; 2005) that facilitates seamless information sharing among the modules, and\na multi-agent debate-based jury under the guidance of Society of Mind Theory (Minsky, 1988) that\nencourages self-refinement before the final response.\nThe inner design of Sibyl is inspired by functional programming principles, emphasizing reusability\nand statelessness between operations. This is realized through the use of QA functions instead of\ndialogues in internal LLM inference requests, allowing for each LLM inference to operate inde-\npendently without the need to maintain a persistent state. By reducing inner dependency on LLM\nrequests and maintaining a simple structure, we hope that Sibyl can be easily reused to facilitate and\ninspire other LLM-based applications to improve their reasoning capabilities and achieve the shift\nfrom System-1 (rapid and intuitive) to System-2 (slow and delibrate) thinking.\nWe evaluated the Sibyl agent instantiated by GPT-40 API (text only) in the GAIA benchmark test\nset, which is carefully designed to probe the depth and robustness of reasoning through a diverse\nset of real-world questions (Mialon et al., 2023). Sibyl agent achieves an impressive average score\nof 34.55% on the GAIA test set, outperforming the previous state-of-the-art method based on Au-\ntoGen (Wu et al., 2023) and demonstrating its superior reasoning capabilities. In contrast, widely\nused systems like AutoGPT-4 (Gravitas, 2023) achieve only an 5% average score. Notably, Sibyl\nagent secures scores of 32.7% and 16.33% in the more challenging level 2 and level 3 scenarios of\nGAIA, respectively. These results represent significant relative improvements of 13% and 12% over\nthe prior state-of-the-art method, underscoring Sibyl's proficiency in managing intricate, long-term\nreasoning tasks.\nOur contributions are as follows:"}, {"title": "THE SIBYL FRAMEWORK", "content": "In this section, we provide a overview of the Sibyl framework, focusing on its design philosophy\nand fundamental modules. As shown in Figure 1, given a user query, Sibyl starts with the tool\nplanner which aims to select appropriate tools, functions, and parameters tailored to each specific\nsubtask. Then, we design an external information acquisition channel to call the tools and selectively\ncompress the external information returned by tool execution. Inspired by Society of Mind Theory,\nwe incorporate a multi-agent debate-based jury to achieve self-correction and a global workspace\nto seamlessly share information and enable effective collaboration across all modules. The prompts\nfor each module are described in Appendix C."}, {"title": "2.1 DESIGN PHILOSOPHY", "content": "The Sibyl framework is constructed around a core design philosophy that focuses on reducing com-\nplexity while enhancing the functional capabilities of LLM-based agents. This philosophy is imple-\nmented through several strategic approaches to restructure LLM operations.\nHuman-oriented Browser Interface Instead of Retrieval Augmented Generation In conven-\ntional LLM-based agent setups, Retrieval Augmented Generation (RAG) often leads to significant\ninformation loss due to the limitation of retrieval process, which can lose the sequential informa-\ntion and connection of chunks in long text and have to trade off between information precision and\nrecall. Retrieving information at a coarse level yields a wider range of data but with less preci-\nsion, while a fine-level retrieval approach ensures a more detailed dataset, albeit sacrificing speed.\nInspired by the success of WebGPT (Nakano et al., 2021), Sibyl addresses this by adopting a human-\noriented browser interface, shifting away from RAG's constraints towards a more intuitive, human-\nlike method of information retrieval. This form of information gathering is crucial as it retains the\nrelational dynamics of the text, preserving more context and depth in the data accessed by the agent.\nQuestion Answering Function Instead of Dialogues Recent agent frameworks such as AutoGen\n(Wu et al., 2023) utilize dialogue as the primary mode of communication between different modules.\nThis design is intended to mimic human conversational patterns, making the interaction more natural"}, {"title": "", "content": "and user-friendly. However, dialogues are stateful and can create complex dependencies among\nvarious LLM inference calls within a session, complicating the debugging and prompt engineering\nprocesses significantly. Sibyl replaces this with a stateless, reentrant QA function that decouples\nindividual LLM inference requests. This transformation significantly simplifies the architecture\nof the system, facilitating easier maintenance and modification while allowing each component to\noperate independently without legacy constraints from previous interactions.\nLess Universal Tools Instead of More Specialized Tools Sibyl centralizes its functionalities\naround two primary tools: the Web browser and Python environments. It aligns the browser's inter-\nface more closely with human interaction modes, such as using page navigation commands (page\ndown/up), click, and search shortcuts (ctrl+f, ctrl+g). This approach moves away from reliance\nsolely on web crawlers and full-page content parsing, aiming for a more selective and relevant data\ninteraction method that mimics human web usage patterns.\nFrom System-1 to System-2 Thinking The Sibyl framework places a strong emphasis on enhanc-\ning capabilities for long-term memory, planning, and error correction-elements vital for complex,\nlong-distance reasoning.\n\u2022 Shared Long-term Memory as First-class Citizen: Sibyl incorporates a global workspace\nthat all modules share, which is designed from the ground up and stores information with\nan incremental state-based representation language. This language selectively compresses\npast events, adding only information increments relevant to problem solving, rather than\nsimply appending all incoming data.\n\u2022 Planning and Self-correction: Sibyl summarizes the outcomes from its tools, and plans\nsubsequent steps based on the assessment of current progress. This involves strategic think-\ning about which pieces of information are necessary and how they should be processed\nmoving forward. In addition, Sibyl introduces a \u201cJury\u201d mechanism, which utilizes a multi-\nagent debate format for self-critique and correction. This process allows the model to\nutilize the information stored in the global workspace efficiently to refine responses and\nensure accurate problem solving.\nThrough these principles, Sibyl aims to advance the development of LLM-based agents, shifting to-\nwards a model that is not only more aligned with human cognitive processes but also more adaptable\nand capable of handling the complexities of real-world applications. This holistic approach is key\nto achieving a deeper, more nuanced interaction with information, leading to better-informed, more\nreliable decision-making for LLM-based agents."}, {"title": "2.2 TOOL PLANNER", "content": "The tool planner in Sibyl is a specialized module designed to select the most suitable (tool, function,\nparameters) triplets and parameters to address incoming queries step by step. Given the planning\nprompt, it assesses the given query and any associated step history to determine the most effective\ntools, functions, and parameters for execution. If the query can be resolved straightforwardly and\ndoes not require additional tools, the planner can also select \"None\", indicating that no additional\ntools are required for that particular step."}, {"title": "2.3 EXTERNAL INFORMATION AQUISITION CHANNEL", "content": "The external information acquisition channel plays a pivotal role in enhancing the agent's ability to\nprocess and utilize information effectively. It first obtains the output of the tool planner, which spec-\nifies the tool, function, and parameters to be used. Upon receiving these directives, the appropriate\ntools are activated to gather and return the needed information.\nThen, the channel performs analysis to extract and verify relevant information for the query. This\ninvolves:\n\u2022 Analyzing the tool results to extract relevant data that directly contributes to answering the\nquestion."}, {"title": "", "content": "\u2022 Verifying the extracted information against the original question to ensure its accuracy and\nrelevance.\n\u2022 Recording new facts only if they provide unique and necessary information that has not\nalready been captured in the step history.\n\u2022 Deciding if the tool result sufficiently answers the query or if further data gathering is\nnecessary.\nIf the information from the current step is insufficient, the channel plans a follow-up step to gather\nmore data, choosing the next tool and query that will efficiently lead to the ultimate goal. This\nplanning is detailed, focusing on minimizing unnecessary steps and emphasizing direct and efficient\nmethods to gather required information.\nConsidering that the information obtained is usually lengthy and noisy, we propose a representation\nlanguage to selectively compress the information inspired by Lee et al. (2024). Unlike simple data\nappending, selective compression involves integrating only those pieces of information that directly\ncontribute to resolving the query at hand. This is exactly in line with the goal of the dialogue state\ntracking module in task-oriented dialogue systems, which is designed to selectively compress past\ninformation related to accomplish tasks. This approach not only minimizes data redundancy but also\nenhances the relevance and quality of information maintained in the system's memory. Specifically,\nwe design a structured output in this step that includes sections for recording the incremental factual\ninformation compared to history, explanations of why choosing the next step and how it contributes\nto answering the question, and the detailed plan of the next step."}, {"title": "2.4 MULTI-AGENT DEBATE-BASED JURY", "content": "The Society of Mind Theory, proposed by Marvin Minsky, provides a fundamental underpinning\nfor the design of the jury system in the Sibyl framework. It posits that the mind is composed of a\nmultitude of semi-autonomous agents, each responsible for different aspects of intellectual opera-\ntion, making complex cognitive processes emerge from the interactions and negotiations between\nsimpler, specialized processes. These agents work in concert, albeit through a decentralized process\nof negotiation and cooperation, much like a society (Minsky, 1988). This inspired the multi-agent\ndebate-based jury mechanism in the Sibyl framework, where multiple agents can discuss and analyze\nproblems, mimicking the cooperative yet independent interaction of Minsky's mental agents.\nHere we instantiate the jury with a minimal implementation using AutoGen (Wu et al., 2023), where\ntwo primary roles are defined:\n\u2022 Actor: This agent attempts to answer the question, explain their thought process in detail,\nand consider feedback from others critically.\n\u2022 Critic: The role of this agent is to identify logical or intellectual errors in the actor's rea-\nsoning.\nThese roles allow for a structured yet flexible interaction and play a vital role in ensuring the logical\ncoherence and intellectual integrity of the responses provided. We leave the exploration of diverse\norganizational forms for LLM-based agents for future work, including collaborative models like\nadvisory councils.\nIn addition, the Sibyl framework employs a majority vote ensemble method to enhance the stability\nand quality of the output answers. This method aggregates decisions or suggestions from multi-\nple inferences, using their consensus to finalize the answer. This approach is particularly effective\nin mitigating individual errors in agent responses, leading to more reliable and accurate problem\nsolving."}, {"title": "2.5 GLOBAL WORKSPACE", "content": "The concept of the global workspace in Sibyl is deeply influenced by Global Workspace Theory\n(Baars, 1993; 2005), which suggests that the brain consists of many specialized processes or mod-\nules that operate simultaneously, with a significant portion functioning unconsciously. Attention\nserves as a spotlight that elevates some of these unconscious activities to conscious awareness within"}, {"title": "", "content": "the global workspace. This workspace acts as a crucial hub for the broadcasting and integration of\ninformation, allowing its distribution across various modules. This theoretical backdrop inspires\nthe design of the global workspace as an integrative platform for various modules within the Sibyl\nframework, facilitating seamless information sharing and a comprehensive understanding of com-\nplex problems.\nThe global workspace acts as a central hub where different modules can broadcast their outputs and\ninsights. This mechanism ensures that despite the modular nature of the system, there is a cohesive\nand unified approach to problem solving. In addition, information within the global workspace is\nwell-structured and denoised, which not only ensures that the data is easy to access and manipu-\nlate by LLMs but also simplifies the debugging and case-analysis processes for human developers.\nBy implementing this global workspace, the framework supports complex information handling and\nlong reasoning sequences, facilitating the evolution from rapid, reflexive responses (System-1 think-\ning) to more deliberate and structured problem solving (System-2 thinking)."}, {"title": "3 EXPERIMENTS", "content": "Datasets We conducted our evaluations on the GAIA dataset (Mialon et al., 2023), a benchmark\ntailored for general AI assistants. The GAIA dataset is designed to reflect tasks that align closely\nwith human perceptual capabilities, including visual, auditory, and textual modalities. This dataset\nchallenges general-purpose assistants with complex reasoning tasks that even require dozens of steps\nto solve, similar to those encountered by humans. Such a design significantly magnifies the impact of\nerror propagation, providing a robust evaluation of problem-solving and error-handling capabilities\nfor LLM-based agents."}, {"title": "3.1 SETTINGS", "content": "In our experimental setup for the Sibyl framework, we utilized two primary tools: a web browser and\na Python-based code interpreter. Details of these tools are described in the Appendix A. To balance\nbudget constraints and time cost, we only use the GPT-40 API within the text modal, and limit the\nmaximum number of reasoning steps of the model to 20."}, {"title": "3.2 BASELINES", "content": "We compared it against several established baselines on GAIA: 1) GPT-4 (Achiam et al., 2023)\nwith and without manually configured plugins, 2) AutoGPT-4 (Gravitas, 2023), which integrates\nAutoGPT with a GPT-4 backend, 3) An LLM-based agent implemented by AutoGen (Wu et al.,\n2023), a framework designed for automating complex multi-agent scenarios, and 4) FRIDAY (Wu\net al., 2024), an advanced agent utilizing OS-Copilot for automating a broad spectrum of computer\ntasks, capable of interfacing with various operating system elements including web browsers, code\nterminals, and multimedia."}, {"title": "3.3 MAIN RESULTS", "content": "We present the results of our experiments on both the test and validation sets of the GAIA dataset in\ntable 1 and 2, respectively. Our findings highlight that Sibyl outperforms other models in the GAIA"}, {"title": "3.4 ABLATION STUDIES", "content": "We further conduct the ablation studies on the validation set of GAIA to investigate the individual\ncontributions of specific components within the Sibyl framework. We mainly focus on two main\ncomponents: the multi-agent debate-based jury and the majority vote-based ensemble. As shown\nin 4, the removal of the multi-agent debate component resulted in a notable performance drop in\nthe Level 1, which indicates that this component significantly boosts the accuracy for basic question\ntypes. However, its removal did not markedly affect the performance in the more challenging Levels\n2 and 3. This suggests that while the multi-agent debate is crucial for resolving simpler queries\neffectively, it does not substantially influence the outcome of more complex reasoning tasks.\nTo evaluate the impact of the ensemble component, we report the average accuracy across three\nseparate runs to ensure a fair comparison against the ensemble configuration. The individual runs\nyielded overall accuracies of 40.61, 34.55, and 35.15, respectively, with an average of 36.77, com-\npared to the ensemble's overall performance of 40.00. While one run did slightly exceed the ensem-\nble result, the ensemble generally provided more stable and consistent outcomes. This demonstrates"}, {"title": "3.5 DISCUSSION", "content": "In this section, we will explore some insights gained from the development of Sibyl. We hope that\nthese insights can inspire future LLM-based agent work with more powerful reasoning capabilities.\nChallenges in Complex Reasoning Complex reasoning in real-world applications is inherently\nchallenging due to the high risk of error propagation. Even with an 80% accuracy rate at each\nstep, the probability of maintaining this accuracy consistently across 20 steps plummets to merely\naround 1%. This exponential increase in error risk highlights the critical nature of maintaining high\naccuracy at every step in reasoning. Furthermore, excessive errors can cause a series of retries which\nconsume significant portions of the context, submerge useful information and hamper the problem-\nsolving process.\nStrategic Approaches to Mitigating Errors The decomposition of complex reasoning into sim-\npler, manageable substeps is vital, as improving the success rate of each step can significantly mit-\nigate error propagation. Selective compression of historical information plays a key role here, as\nmost of the data accumulated during web navigation and previous interactions do not directly con-\ntribute to solving the problem at hand. This approach not only streamlines information processing,\nbut also focuses on maintaining only the most pertinent data, enhancing overall system efficiency.\nImportance of Debug-oriented Design A robust debug-oriented design is essential for reduc-\ning debugging costs and facilitating rapid system iteration. By limiting the introduction of state\nand striving for decoupling between components and even individual LLM inference requests, the\nsystem's maintainability and adaptability are significantly improved. Given that Sibyl follows the\ncombinator pattern, it can be seamlessly integrated as a low-cost enhancement into existing frame-\nworks, easily replacing the vanilla GPT-4 API. This design can make it more flexible in various\nLLM applications.\nOptimizing Tool Usage Considering the aforementioned error propagation in complex reasoning,\noptimizing existing tools is often more crucial than adding new ones. The potential of tools such as\nweb browsers is far from fully realized; current LLM agents do not yet match human capabilities\nin terms of content visibility and operational scope on web platforms. Enhancing these tools to\nfully exploit their capabilities can provide substantial improvements in performance and utility, thus\ndriving forward the sophistication and effectiveness of AI systems in complex environments."}, {"title": "4 RELATED WORK", "content": "The integration of LLMs into autonomous agents marks a significant advancement in the field of\nartificial intelligence. These agents, capable of sensing their environment, making decisions and\ntaking actions, are at the forefront of pushing AI towards Artificial General Intelligence (AGI) (Xi\net al., 2023; Wang et al., 2024). These agents, often referred to as LLM-based agents, are increas-\ningly prevalent across a variety of domains, demonstrating the potential of LLM applications in\ncomplex scenarios.\nMost LLM-based agents are designed for specific applications, highlighting their adaptability but\nalso suffering from a potential limitation in versatility. These applications include mathmatical\nproblem solving (Gou et al., 2023; Swan et al., 2023), coding (Yang et al., 2024; Zheng et al., 2024),\nrole-playing (Shao et al., 2023; Shen et al., 2023), and social simulation (Park et al., 2023; Gao et al.,\n2023). To take a step further towards general purpose LLM-based agents that are capable of various\ngeneral tasks, open-source communities have developed some LLM-based agent framework, such\nas Langchain (Chase, 2022), BabyAGI (Nakajima, 2023) and AutoGPT (Gravitas, 2023). Equipped\nwith tools and structured frameworks, these agents can competently handle relatively straightfor-\nward tasks with human-like capabilities. However, their proficiency in tackling complex real-world\nchallenges remains comparatively limited. This gap indicates the need for further enhancements in\ngeneral-purpose LLM-based agents to address more intricate problems effectively."}, {"title": "5 CONCLUSION", "content": "We introduce Sibyl, an agent framework designed to enhance the capabilities of LLMs in complex\nreasoning tasks. Through the integration of modular design and a global workspace for information\nsharing and collaboration, Sibyl aims to facilitate the transition of LLM-based agents from rapid and\nintuitive System-1 thinking to slow and delibrate System-2 thinking. Our experimental results on\nthe GAIA benchmark show that the Sibyl agent instantiated by GPT-4 outperforms existing state-of-\nthe-art solutions, demonstrating the effectiveness of our proposed framework. We hope that Sibyl\ncan contribute to the promotion of LLM applications to have better capabilities in handling complex\nreal-world tasks."}, {"title": "D LIMITATIONS AND FUTURE DIRECTIONS", "content": "Despite the advancements demonstrated by the Sibyl framework, there are inherent limitations that\nwait to addressed in the future."}, {"title": "D.1 LIMITATIONS", "content": "Lack of Vision Large Language Model Support Currently, Sibyl primarily operates on textual\ndata and use Optical Character Recognition (OCR) to convert visual information into text modal,\nthus lacking integration with vision large language models, which restricts its ability to process and\ninterpret visual content as humans do.\nBrowser Functionalities While Sibyl utilizes a browser tool, it is not yet equipped with a fully\nfunctional browser akin to those used by humans. This limitation affects the agent's ability to interact\nwith web content in a more natural and efficient manner.\nLearning Mechanisms The present system does not incorporate learning mechanisms to adapt\nand improve from real-world interactions on-the-fly. This may restrict its ability to evolve based on\nnew data or scenarios it encounters."}, {"title": "D.2 FUTURE DIRECTIONS", "content": "Integrating Vision Large Language Models Future versions of Sibyl will incorporate vision\nlarge language models to allow the system to handle multimedia content effectively, broadening\nits applicability across various domains where visual data plays a crucial role.\nEnhancing Browser Capabilities There is a pressing need to optimize the browser tool to provide\nfull functionality, mirroring the capabilities available to human users, thereby improving the agent's\ninteraction with web interfaces.\nDesigning Adaptive Learning Mechanisms In the future version of Sibyl, we plan to introduce\nadaptive learning mechanisms will enable the system to learn from its interactions and experiences,\nthereby progressively improving its problem-solving strategies and effectiveness.\nDeveloping LLMs tailored for Agents Future work will also focus on developing LLMs that\nare specifically optimized for general-purpose AI agents, aiming to enhance their efficiency and\neffectiveness in complex reasoning tasks. This includes gathering and utilizing data specific to long-\ndistance reasoning processes in real-world scenarios and improving the system's ability to build and\nreuse its tools autonomously."}, {"title": "A DETAILS OF TOOLS", "content": "In the development of Sibyl, we reuse the tools from the AutoGen (Wu et al., 2023). Below is\na detailed description of each tool and its functions, providing insights into how these tools are\nutilized within the framework to process and interact with web content efficiently.\nWeb Browser The web browser tool in Sibyl is designed to perform a variety of functions that\nfacilitate interaction with web pages. These functions are shown in table 5."}, {"title": "", "content": "Additionally, the web browser tool can convert the content of web pages into various formats for bet-\nter processing, including plain text, HTML, and formats specific to sites like Wikipedia, YouTube,\nas well as document formats like DOCX, XLSX, PPTX, and multimedia formats such as WAV, MP3\n(via ASR), and images (via OCR).\nComputer Terminal The computer terminal tool serves as a code interpreter within the Sibyl\nsystem. This tool allows the execution of Python code, facilitating dynamic computation and pro-\ncessing tasks which are crucial for complex problem solving and data manipulation within the AI\nframework.\nThese tools and their functionalities are important in enabling the Sibyl agent to navigate, inter-\npret, and interact with the digital world effectively, mirroring human-like web browsing and data\nprocessing capabilities."}, {"title": "BETHICS STATEMENT", "content": "By refining the ability to parse and process multifaceted information, Sibyl helps in delivering more\naccurate and reliable outputs during complex reasoning in real-world scenarios. This progression\nhelps improve the reliability of responses and reduce the occurrence of hallucinations in the outputs\nof these models. In addition, during the evaluation phase, we implemented rigorous monitoring of\nthe reasoning processes to identify and prevent any potentially harmful actions that could be exe-\ncuted by the Sibyl system. This precautionary measure is essential to ensure that while the system\nimproves in autonomy, it remains within the bounds of ethical operation. Due to the versatility of\ngeneral purpose LLM-based agents, we strongly recommend that users of Sibyl also remain vigilant\nregarding the outputs produced, recognizing the potential impacts that these could have if misap-\nplied. Users are urged to ensure that the deployment of Sibyl is aligned with ethical standards and\nnot used for malicious purposes."}, {"title": "CPROMPTS", "content": "You are a helpful AI assistant.\nI'll give you a question and a set of tools. Tell me which\nfunction you would use to solve the problem (or if you don't\nneed any tool).\n# Step History\n{steps"}, "n# Question\ntext\n{question}\n# Tools\n## Browser\nThe functions of the browser will share the same session, that\nmeans the viewport will persist between calls\nEvery function will return the text of the current viewport after\nthe action is performed. For long pages (longer than 1\n\u2192 viewport), you can use the page_up() and page_down()\n\u2192functions to scroll the viewport.\nSince the page has been converted from HTML to Markdown, you\ncannot submit information using a form, nor can you enter\n\u2192 information in any text boxes. If you want to use the form\ninside the page, try using the computer_terminal below to\nread the html content.\nWhen the page is very long, content truncation may occur due to\n\u2192 the limited display capacity of the viewport. You need to\n\u2192carefully consider whether additional page down is needed to\n\u2192ensure that you have obtained the complete information.\ninformational_web_search (query: str) -> str:\nPerform an INFORMATIONAL web search query and return the\nsearch results.\nnavigational_web_search (query: str) -> str:\nPerform a NAVIGATIONAL web search query and immediately\n\u2192 navigate to the top result. Useful, for example, to\n\u2192 navigate to a particular Wikipedia article or other\n\u2192known destination. Equivalent to Google's \"I'm Feeling\nLucky\" button.\nvisit_page(url: str) -> str:\nVisit a webpage at a given URL and return its text.\npage_up() -> str:\nScroll the viewport UP one page-length in the current webpage\n\u2192 and return the new viewport content.\npage_down() -> str:\nScroll the viewport DOWN one page-length in the current\n\u2192 webpage and return the new viewport content.\ndownload_file(url: str) -> str:\nDownload a file at a given URL and, if possible, return its\ntext. File types that will returned as text: .pdf,\n.docx, .xlsx, .pptx, .wav, .mp3, .jpg, .jpeg, .png (You\ncan read the text content of the file with these\n\u2192 extensions).\nWhen the page is too long to be fully displayed in one\n\u2192viewport, you can use this function to scroll the\n\u2192 viewport to the first occurrence of the search string.\nIf the viewport has already displayed the entire\n\u2192page (Showing page 1 of 1.), there is no need to use this\n\u2192function. This is equivalent to Ctrl+F. This search\nstring supports wildcards like '*'\nfind_next() -> str:\nScroll the viewport to the next occurrence of the search\n\u2192 string.\n## Computer Terminal\ncomputer_terminal (code: str) -> str\nYou can use this function to run Python code. Use print() to\noutput the result.\nBased on the question and the step history, tell me which function\nyou would use to solve the problem in next step.\nIf you don't need any function or the question is very easy to\nanswer, function \"None\" is also an option.\nDo not change the format and precision of the results (including\n\u2192rounding), as a dedicated person will handle the final\n\u2192 formatting of the results.\nUse JSON format to answer.\n{format_instructions}\nYour ultimate goal is to find the answer to the question below.\ntext\n{question}\n# Step History\ntext\n{steps}\nThe next step is running the following code:\npython\n{code}\nCheck this code and help me improve it.\nResponse in JSON format:\n{format_instructions}\n## Computer Terminal\ncomputer_terminal (code: str) -> str\nYou can use this tool to run Python code. Use print() to\noutput the result.\n# Step History\ntext\n{steps}\n# Current Step Tool Result\nTool: {tool}\nArgs```json\n{\n\"title\": \"SIBYL: SIMPLE YET EFFECTIVE AGENT FRAMEWORK\nFOR COMPLEX REAL-WORLD REASONING\",\n\"authors\": [\n\"Yulong Wang\",\n\"Tianhao Shen\",\n\"Lifeng Liu\",\n\"Jian Xie\"\n],\n\"abstract\":", "Existing agents based on large language models (LLMs) demonstrate robust\nproblem-solving capabilities by integrating LLMs' inherent knowledge, strong in-\ncontext learning and zero-shot capabilities, and the use of tools combined with in-\ntricately designed LLM invocation workflows by humans. However, these agents\nstill exhibit shortcomings in long-term reasoning and under-use the potential of\nexisting tools, leading to noticeable deficiencies in complex real-world reasoning\nscenarios. To address these limitations, we introduce Sibyl, a simple yet power-\nful LLM-based agent framework designed to tackle complex reasoning tasks by\nefficiently leveraging a minimal set of tools. Drawing inspiration from Global\nWorkspace Theory, Sibyl incorporates a global workspace to enhance the manage-\nment and sharing of knowledge and conversation history throughout the system.\nFurthermore, guided by Society of Mind Theory, Sibyl implements a multi-agent\ndebate-based jury to self-refine the final answers, ensuring a comprehensive and\nbalanced approach. This approach aims to reduce system complexity while ex-\npanding the scope of problems solvable\u2014from matters typically resolved by hu-\nmans in minutes to those requiring hours or even days, thus facilitating a shift\nfrom System-1 to System-2 thinking. Sibyl has been designed with a focus on\nscalability and ease of debugging by incorporating the concept of reentrancy from\nfunctional programming from its inception, with the aim of seamless and low\neffort integration in other LLM applications to improve capabilities. Our experi-\nmental results on the GAIA benchmark test set reveal that the Sibyl agent instan-\ntiated with GPT-4 achieves state-of-the-art performance with an average score of\n34.55%, compared to other agents based on GPT-4. We hope that Sibyl can in-\nspire more reliable and reusable LLM-based agent solutions to address complex\nreal-world reasoning tasks.", "sections\": [\n{\n\"title\": \"INTRODUCTION", "content\": \"Large language models (LLMs) have transformed the landscape of human-computer interaction\n(HCI) by offering unprecedented capabilities in understanding and generating human-like text.\nLLM-based agents, which are systems designed to harness these models, effectively orchestrate\nLLM capabilities to address complex tasks (Xi et al., 2023; Wang et al., 2024). These agents lever-\nage human-designed frameworks that utilize the inherent knowledge within LLMs, often employing\nstructured workflows that maximize the potential of in-context learning and zero-shot capabilities.\nSuch strategies allow these agents to engage in sophisticated dialogues and problem-solving sce-\nnarios that mirror human cognitive processes (Sumers et al., 2023). By incorporating prior human\nknowledge into the workflow, LLM-based agents can process and utilize information with a level of\nproficiency that was previously unattainable.\nDespite their abilities, LLM-based agents are often limited by their inability to engage in complex\nquestions of reasoning in real-world scenarios, where the number of reasoning steps can be nu-\nmerous (Mialon et al., 2023). While LLMs excel in simpler, quick-answer scenarios, they struggle"], "content": "significantly when tasks demand lengthy, complex reasoning chains, often resulting in error prop-\nagation and a steep decline in accuracy. To address these complex real-world problems, existing\nsystems are often intricately designed, leading to complexity that makes them difficult to evolve or\noptimize. This complexity not only impedes their practical deployment, but also restricts their adapt-\nability and scalability in various LLM applications, which underscores the need for an approach that\nhas simple design while improving the reasoning capabilities of LLM-based agents.\nFurthermore, long-context management also remains a significant hurdle in LLM applications. The\ncollection of abundant external information (e.g, computation output and error messages during\ncoding, or intricate web content) creates a high demand for managing long context sizes effectively\nwithin the LLM's processing capabilities. However, Hsieh et al. (2024) found that there exists a\nnotable gap between the claimed length (the designed maximum context size a model can handle)\nand the effective length (the maximum context size a model can effectively manage) that LLMs\ncan process. On the other hand, the challenge of long contexts is further compounded by the need\nto integrate information from various sources and data formats, often leading to \"context dilution\"\nproblem where valuable information is overwhelmed by the sheer volume of data (Xu et al., 2023;\nShi et al., 2024). Effective context management is crucial to ensure that LLMs can maintain focus\non relevant information without being sidetracked by less pertinent details. As such, addressing\nthis gap is not just about increasing the raw capacity of models to handle more data but also about\nimproving their ability to discern and prioritize information that is most critical for the task at hand.\nTo address the identified limitations in long-term reasoning and system complexity, we introduce\nSibyl, a simple yet powerful LLM-based agent framework. The system is compartmentalized into\nfour main modules: tool planner, external information acquisition channel, a jury based on multi-\nagent debate and a global workspace. Specifically, we introduce an external information acquisition\nchannel to receive and process external information from selected tools. To efficiently compress\nthe received information, we integrate the concept of dialogue states from task-oriented dialogue\nsystems (Budzianowski et al., 2018; Quan et al., 2020; Moradshahi et al., 2023) into the channel\nand design a representation language for the compressed information. This adaptation allows for\nthe selective compression of external information, focusing only on incremental details pertinent to\nsolving problems, which diverges from the traditional method of simply appending external infor-\nmation to the conversational history. By doing so, it not only elevates the quality and relevance of\nthe information processed by LLMs but also conserves context length, allowing for more extended\nsteps in reasoning. In addition, we design a global workspace inspired by the Global Workspace\nTheory (Baars, 1993; 2005) that facilitates seamless information sharing among the modules, and\na multi-agent debate-based jury under the guidance of Society of Mind Theory (Minsky, 1988) that\nencourages self-refinement before the final response.\nThe inner design of Sibyl is inspired by functional programming principles, emphasizing reusability\nand statelessness between operations. This is realized through the use of QA functions instead of\ndialogues in internal LLM inference requests, allowing for each LLM inference to operate inde-\npendently without the need to maintain a persistent state. By reducing inner dependency on LLM\nrequests and maintaining a simple structure, we hope that Sibyl can be easily reused to facilitate and\ninspire other LLM-based applications to improve their reasoning capabilities and achieve the shift\nfrom System-1 (rapid and intuitive) to System-2 (slow and delibrate) thinking.\nWe evaluated the Sibyl agent instantiated by GPT-40 API (text only) in the GAIA benchmark test\nset, which is carefully designed to probe the depth and robustness of reasoning through a diverse\nset of real-world questions (Mialon et al., 2023). Sibyl agent achieves an impressive average score\nof 34.55% on the GAIA test set, outperforming the previous state-of-the-art method based on Au-\ntoGen (Wu et al., 2023) and demonstrating its superior reasoning capabilities. In contrast, widely\nused systems like AutoGPT-4 (Gravitas, 2023) achieve only an 5% average score. Notably, Sibyl\nagent secures scores of 32.7% and 16.33% in the more challenging level 2 and level 3 scenarios of\nGAIA, respectively. These results represent significant relative improvements of 13% and 12% over\nthe prior state-of-the-art method, underscoring Sibyl's proficiency in managing intricate, long-term\nreasoning tasks.\nOur contributions are as follows:"}, {"title": "THE SIBYL FRAMEWORK", "content": "In this section, we provide a overview of the Sibyl framework, focusing on its design philosophy\nand fundamental modules. As shown in Figure 1, given a user query, Sibyl starts with the tool\nplanner which aims to select appropriate tools, functions, and parameters tailored to each specific\nsubtask. Then, we design an external information acquisition channel to call the tools and selectively\ncompress the external information returned by tool execution. Inspired by Society of Mind Theory,\nwe incorporate a multi-agent debate-based jury to achieve self-correction and a global workspace\nto seamlessly share information and enable effective collaboration across all modules. The prompts\nfor each module are described in Appendix C."}, {"title": "2.1 DESIGN PHILOSOPHY", "content": "The Sibyl framework is constructed around a core design philosophy that focuses on reducing com-\nplexity while enhancing the functional capabilities of LLM-based agents. This philosophy is imple-\nmented through several strategic approaches to restructure LLM operations.\nHuman-oriented Browser Interface Instead of Retrieval Augmented Generation In conven-\ntional LLM-based agent setups, Retrieval Augmented Generation (RAG) often leads to significant\ninformation loss due to the limitation of retrieval process, which can lose the sequential informa-\ntion and connection of chunks in long text and have to trade off between information precision and\nrecall. Retrieving information at a coarse level yields a wider range of data but with less preci-\nsion, while a fine-level retrieval approach ensures a more detailed dataset, albeit sacrificing speed.\nInspired by the success of WebGPT (Nakano et al., 2021), Sibyl addresses this by adopting a human-\noriented browser interface, shifting away from RAG's constraints towards a more intuitive, human-\nlike method of information retrieval. This form of information gathering is crucial as it retains the\nrelational dynamics of the text, preserving more context and depth in the data accessed by the agent.\nQuestion Answering Function Instead of Dialogues Recent agent frameworks such as AutoGen\n(Wu et al., 2023) utilize dialogue as the primary mode of communication between different modules.\nThis design is intended to mimic human conversational patterns, making the interaction more natural"}, {"title": null, "content": "and user-friendly. However, dialogues are stateful and can create complex dependencies among\nvarious LLM inference calls within a session, complicating the debugging and prompt engineering\nprocesses significantly. Sibyl replaces this with a stateless, reentrant QA function that decouples\nindividual LLM inference requests. This transformation significantly simplifies the architecture\nof the system, facilitating easier maintenance and modification while allowing each component to\noperate independently without legacy constraints from previous interactions.\nLess Universal Tools Instead of More Specialized Tools Sibyl centralizes its functionalities\naround two primary tools: the Web browser and Python environments. It aligns the browser's inter-\nface more closely with human interaction modes, such as using page navigation commands (page\ndown/up), click, and search shortcuts (ctrl+f, ctrl+g). This approach moves away from reliance\nsolely on web crawlers and full-page content parsing, aiming for a more selective and relevant data\ninteraction method that mimics human web usage patterns.\nFrom System-1 to System-2 Thinking The Sibyl framework places a strong emphasis on enhanc-\ning capabilities for long-term memory, planning, and error correction-elements vital for complex,\nlong-distance reasoning.\n\u2022 Shared Long-term Memory as First-class Citizen: Sibyl incorporates a global workspace\nthat all modules share, which is designed from the ground up and stores information with\nan incremental state-based representation language. This language selectively compresses\npast events, adding only information increments relevant to problem solving, rather than\nsimply appending all incoming data.\n\u2022 Planning and Self-correction: Sibyl summarizes the outcomes from its tools, and plans\nsubsequent steps based on the assessment of current progress. This involves strategic think-\ning about which pieces of information are necessary and how they should be processed\nmoving forward. In addition, Sibyl introduces a \u201cJury\u201d mechanism, which utilizes a multi-\nagent debate format for self-critique and correction. This process allows the model to\nutilize the information stored in the global workspace efficiently to refine responses and\nensure accurate problem solving.\nThrough these principles, Sibyl aims to advance the development of LLM-based agents, shifting to-\nwards a model that is not only more aligned with human cognitive processes but also more adaptable\nand capable of handling the complexities of real-world applications. This holistic approach is key\nto achieving a deeper, more nuanced interaction with information, leading to better-informed, more\nreliable decision-making for LLM-based agents."}, {"title": "2.2 TOOL PLANNER", "content": "The tool planner in Sibyl is a specialized module designed to select the most suitable (tool, function,\nparameters) triplets and parameters to address incoming queries step by step. Given the planning\nprompt, it assesses the given query and any associated step history to determine the most effective\ntools, functions, and parameters for execution. If the query can be resolved straightforwardly and\ndoes not require additional tools, the planner can also select \"None\", indicating that no additional\ntools are required for that particular step."}, {"title": "2.3 EXTERNAL INFORMATION AQUISITION CHANNEL", "content": "The external information acquisition channel plays a pivotal role in enhancing the agent's ability to\nprocess and utilize information effectively. It first obtains the output of the tool planner, which spec-\nifies the tool, function, and parameters to be used. Upon receiving these directives, the appropriate\ntools are activated to gather and return the needed information.\nThen, the channel performs analysis to extract and verify relevant information for the query. This\ninvolves:\n\u2022 Analyzing the tool results to extract relevant data that directly contributes to answering the\nquestion."}, {"title": null, "content": "\u2022 Verifying the extracted information against the original question to ensure its accuracy and\nrelevance.\n\u2022 Recording new facts only if they provide unique and necessary information that has not\nalready been captured in the step history.\n\u2022 Deciding if the tool result sufficiently answers the query or if further data gathering is\nnecessary.\nIf the information from the current step is insufficient, the channel plans a follow-up step to gather\nmore data, choosing the next tool and query that will efficiently lead to the ultimate goal. This\nplanning is detailed, focusing on minimizing unnecessary steps and emphasizing direct and efficient\nmethods to gather required information.\nConsidering that the information obtained is usually lengthy and noisy, we propose a representation\nlanguage to selectively compress the information inspired by Lee et al. (2024). Unlike simple data\nappending, selective compression involves integrating only those pieces of information that directly\ncontribute to resolving the query at hand. This is exactly in line with the goal of the dialogue state\ntracking module in task-oriented dialogue systems, which is designed to selectively compress past\ninformation related to accomplish tasks. This approach not only minimizes data redundancy but also\nenhances the relevance and quality of information maintained in the system's memory. Specifically,\nwe design a structured output in this step that includes sections for recording the incremental factual\ninformation compared to history, explanations of why choosing the next step and how it contributes\nto answering the question, and the detailed plan of the next step."}, {"title": "2.4 MULTI-AGENT DEBATE-BASED JURY", "content": "The Society of Mind Theory, proposed by Marvin Minsky, provides a fundamental underpinning\nfor the design of the jury system in the Sibyl framework. It posits that the mind is composed of a\nmultitude of semi-autonomous agents, each responsible for different aspects of intellectual opera-\ntion, making complex cognitive processes emerge from the interactions and negotiations between\nsimpler, specialized processes. These agents work in concert, albeit through a decentralized process\nof negotiation and cooperation, much like a society (Minsky, 1988). This inspired the multi-agent\ndebate-based jury mechanism in the Sibyl framework, where multiple agents can discuss and analyze\nproblems, mimicking the cooperative yet independent interaction of Minsky's mental agents.\nHere we instantiate the jury with a minimal implementation using AutoGen (Wu et al., 2023), where\ntwo primary roles are defined:\n\u2022 Actor: This agent attempts to answer the question, explain their thought process in detail,\nand consider feedback from others critically.\n\u2022 Critic: The role of this agent is to identify logical or intellectual errors in the actor's rea-\nsoning.\nThese roles allow for a structured yet flexible interaction and play a vital role in ensuring the logical\ncoherence and intellectual integrity of the responses provided. We leave the exploration of diverse\norganizational forms for LLM-based agents for future work, including collaborative models like\nadvisory councils.\nIn addition, the Sibyl framework employs a majority vote ensemble method to enhance the stability\nand quality of the output answers. This method aggregates decisions or suggestions from multi-\nple inferences, using their consensus to finalize the answer. This approach is particularly effective\nin mitigating individual errors in agent responses, leading to more reliable and accurate problem\nsolving."}, {"title": "2.5 GLOBAL WORKSPACE", "content": "The concept of the global workspace in Sibyl is deeply influenced by Global Workspace Theory\n(Baars, 1993; 2005), which suggests that the brain consists of many specialized processes or mod-\nules that operate simultaneously, with a significant portion functioning unconsciously. Attention\nserves as a spotlight that elevates some of these unconscious activities to conscious awareness within"}, {"title": null, "content": "the global workspace. This workspace acts as a crucial hub for the broadcasting and integration of\ninformation, allowing its distribution across various modules. This theoretical backdrop inspires\nthe design of the global workspace as an integrative platform for various modules within the Sibyl\nframework, facilitating seamless information sharing and a comprehensive understanding of com-\nplex problems.\nThe global workspace acts as a central hub where different modules can broadcast their outputs and\ninsights. This mechanism ensures that despite the modular nature of the system, there is a cohesive\nand unified approach to problem solving. In addition, information within the global workspace is\nwell-structured and denoised, which not only ensures that the data is easy to access and manipu-\nlate by LLMs but also simplifies the debugging and case-analysis processes for human developers.\nBy implementing this global workspace, the framework supports complex information handling and\nlong reasoning sequences, facilitating the evolution from rapid, reflexive responses (System-1 think-\ning) to more deliberate and structured problem solving (System-2 thinking)."}, {"title": "3 EXPERIMENTS", "content": "Datasets We conducted our evaluations on the GAIA dataset (Mialon et al., 2023), a benchmark\ntailored for general AI assistants. The GAIA dataset is designed to reflect tasks that align closely\nwith human perceptual capabilities, including visual, auditory, and textual modalities. This dataset\nchallenges general-purpose assistants with complex reasoning tasks that even require dozens of steps\nto solve, similar to those encountered by humans. Such a design significantly magnifies the impact of\nerror propagation, providing a robust evaluation of problem-solving and error-handling capabilities\nfor LLM-based agents."}, {"title": "3.1 SETTINGS", "content": "In our experimental setup for the Sibyl framework, we utilized two primary tools: a web browser and\na Python-based code interpreter. Details of these tools are described in the Appendix A. To balance\nbudget constraints and time cost, we only use the GPT-40 API within the text modal, and limit the\nmaximum number of reasoning steps of the model to 20."}, {"title": "3.2 BASELINES", "content": "We compared it against several established baselines on GAIA: 1) GPT-4 (Achiam et al., 2023)\nwith and without manually configured plugins, 2) AutoGPT-4 (Gravitas, 2023), which integrates\nAutoGPT with a GPT-4 backend, 3) An LLM-based agent implemented by AutoGen (Wu et al.,\n2023), a framework designed for automating complex multi-agent scenarios, and 4) FRIDAY (Wu\net al., 2024), an advanced agent utilizing OS-Copilot for automating a broad spectrum of computer\ntasks, capable of interfacing with various operating system elements including web browsers, code\nterminals, and multimedia."}, {"title": "3.3 MAIN RESULTS", "content": "We present the results of our experiments on both the test and validation sets of the GAIA dataset in\ntable 1 and 2, respectively. Our findings highlight that Sibyl outperforms other models in the GAIA"}, {"title": "3.4 ABLATION STUDIES", "content": "We further conduct the ablation studies on the validation set of GAIA to investigate the individual\ncontributions of specific components within the Sibyl framework. We mainly focus on two main\ncomponents: the multi-agent debate-based jury and the majority vote-based ensemble. As shown\nin 4, the removal of the multi-agent debate component resulted in a notable performance drop in\nthe Level 1, which indicates that this component significantly boosts the accuracy for basic question\ntypes. However, its removal did not markedly affect the performance in the more challenging Levels\n2 and 3. This suggests that while the multi-agent debate is crucial for resolving simpler queries\neffectively, it does not substantially influence the outcome of more complex reasoning tasks.\nTo evaluate the impact of the ensemble component, we report the average accuracy across three\nseparate runs to ensure a fair comparison against the ensemble configuration. The individual runs\nyielded overall accuracies of 40.61, 34.55, and 35.15, respectively, with an average of 36.77, com-\npared to the ensemble's overall performance of 40.00. While one run did slightly exceed the ensem-\nble result, the ensemble generally provided more stable and consistent outcomes. This demonstrates"}, {"title": "3.5 DISCUSSION", "content": "In this section, we will explore some insights gained from the development of Sibyl. We hope that\nthese insights can inspire future LLM-based agent work with more powerful reasoning capabilities.\nChallenges in Complex Reasoning Complex reasoning in real-world applications is inherently\nchallenging due to the high risk of error propagation. Even with an 80% accuracy rate at each\nstep, the probability of maintaining this accuracy consistently across 20 steps plummets to merely\naround 1%. This exponential increase in error risk highlights the critical nature of maintaining high\naccuracy at every step in reasoning. Furthermore, excessive errors can cause a series of retries which\nconsume significant portions of the context, submerge useful information and hamper the problem-\nsolving process.\nStrategic Approaches to Mitigating Errors The decomposition of complex reasoning into sim-\npler, manageable substeps is vital, as improving the success rate of each step can significantly mit-\nigate error propagation. Selective compression of historical information plays a key role here, as\nmost of the data accumulated during web navigation and previous interactions do not directly con-\ntribute to solving the problem at hand. This approach not only streamlines information processing,\nbut also focuses on maintaining only the most pertinent data, enhancing overall system efficiency.\nImportance of Debug-oriented Design A robust debug-oriented design is essential for reduc-\ning debugging costs and facilitating rapid system iteration. By limiting the introduction of state\nand striving for decoupling between components and even individual LLM inference requests, the\nsystem's maintainability and adaptability are significantly improved. Given that Sibyl follows the\ncombinator pattern, it can be seamlessly integrated as a low-cost enhancement into existing frame-\nworks, easily replacing the vanilla GPT-4 API. This design can make it more flexible in various\nLLM applications.\nOptimizing Tool Usage Considering the aforementioned error propagation in complex reasoning,\noptimizing existing tools is often more crucial than adding new ones. The potential of tools such as\nweb browsers is far from fully realized; current LLM agents do not yet match human capabilities\nin terms of content visibility and operational scope on web platforms. Enhancing these tools to\nfully exploit their capabilities can provide substantial improvements in performance and utility, thus\ndriving forward the sophistication and effectiveness of AI systems in complex environments."}, {"title": "4 RELATED WORK", "content": "The integration of LLMs into autonomous agents marks a significant advancement in the field of\nartificial intelligence. These agents, capable of sensing their environment, making decisions and\ntaking actions, are at the forefront of pushing AI towards Artificial General Intelligence (AGI) (Xi\net al., 2023; Wang et al., 2024). These agents, often referred to as LLM-based agents, are increas-\ningly prevalent across a variety of domains, demonstrating the potential of LLM applications in\ncomplex scenarios.\nMost LLM-based agents are designed for specific applications, highlighting their adaptability but\nalso suffering from a potential limitation in versatility. These applications include mathmatical\nproblem solving (Gou et al., 2023; Swan et al., 2023), coding (Yang et al., 2024; Zheng et al., 2024),\nrole-playing (Shao et al., 2023; Shen et al., 2023), and social simulation (Park et al., 2023; Gao et al.,\n2023). To take a step further towards general purpose LLM-based agents that are capable of various\ngeneral tasks, open-source communities have developed some LLM-based agent framework, such\nas Langchain (Chase, 2022), BabyAGI (Nakajima, 2023) and AutoGPT (Gravitas, 2023). Equipped\nwith tools and structured frameworks, these agents can competently handle relatively straightfor-\nward tasks with human-like capabilities. However, their proficiency in tackling complex real-world\nchallenges remains comparatively limited. This gap indicates the need for further enhancements in\ngeneral-purpose LLM-based agents to address more intricate problems effectively."}, {"title": "5 CONCLUSION", "content": "We introduce Sibyl, an agent framework designed to enhance the capabilities of LLMs in complex\nreasoning tasks. Through the integration of modular design and a global workspace for information\nsharing and collaboration, Sibyl aims to facilitate the transition of LLM-based agents from rapid and\nintuitive System-1 thinking to slow and delibrate System-2 thinking. Our experimental results on\nthe GAIA benchmark show that the Sibyl agent instantiated by GPT-4 outperforms existing state-of-\nthe-art solutions, demonstrating the effectiveness of our proposed framework. We hope that Sibyl\ncan contribute to the promotion of LLM applications to have better capabilities in handling complex\nreal-world tasks."}, {"title": "D LIMITATIONS AND FUTURE DIRECTIONS", "content": "Despite the advancements demonstrated by the Sibyl framework, there are inherent limitations that\nwait to addressed in the future."}, {"title": "D.1 LIMITATIONS", "content": "Lack of Vision Large Language Model Support Currently, Sibyl primarily operates on textual\ndata and use Optical Character Recognition (OCR) to convert visual information into text modal,\nthus lacking integration with vision large language models, which restricts its ability to process and\ninterpret visual content as humans do.\nBrowser Functionalities While Sibyl utilizes a browser tool, it is not yet equipped with a fully\nfunctional browser akin to those used by humans. This limitation affects the agent's ability to interact\nwith web content in a more natural and efficient manner.\nLearning Mechanisms The present system does not incorporate learning mechanisms to adapt\nand improve from real-world interactions on-the-fly. This may restrict its ability to evolve based on\nnew data or scenarios it encounters."}, {"title": "D.2 FUTURE DIRECTIONS", "content": "Integrating Vision Large Language Models Future versions of Sibyl will incorporate vision\nlarge language models to allow the system to handle multimedia content effectively, broadening\nits applicability across various domains where visual data plays a crucial role.\nEnhancing Browser Capabilities There is a pressing need to optimize the browser tool to provide\nfull functionality, mirroring the capabilities available to human users, thereby improving the agent's\ninteraction with web interfaces.\nDesigning Adaptive Learning Mechanisms In the future version of Sibyl, we plan to introduce\nadaptive learning mechanisms will enable the system to learn from its interactions and experiences,\nthereby progressively improving its problem-solving strategies and effectiveness.\nDeveloping LLMs tailored for Agents Future work will also focus on developing LLMs that\nare specifically optimized for general-purpose AI agents, aiming to enhance their efficiency and\neffectiveness in complex reasoning tasks. This includes gathering and utilizing data specific to long-\ndistance reasoning processes in real-world scenarios and improving the system's ability to build and\nreuse its tools autonomously."}, {"title": "A DETAILS OF TOOLS", "content": "In the development of Sibyl, we reuse the tools from the AutoGen (Wu et al., 2023). Below is\na detailed description of each tool and its functions, providing insights into how these tools are\nutilized within the framework to process and interact with web content efficiently.\nWeb Browser The web browser tool in Sibyl is designed to perform a variety of functions that\nfacilitate interaction with web pages. These functions are shown in table 5."}, {"title": null, "content": "Additionally, the web browser tool can convert the content of web pages into various formats for bet-\nter processing, including plain text, HTML, and formats specific to sites like Wikipedia, YouTube,\nas well as document formats like DOCX, XLSX, PPTX, and multimedia formats such as WAV, MP3\n(via ASR), and images (via OCR).\nComputer Terminal The computer terminal tool serves as a code interpreter within the Sibyl\nsystem. This tool allows the execution of Python code, facilitating dynamic computation and pro-\ncessing tasks which are crucial for complex problem solving and data manipulation within the AI\nframework.\nThese tools and their functionalities are important in enabling the Sibyl agent to navigate, inter-\npret, and interact with the digital world effectively, mirroring human-like web browsing and data\nprocessing capabilities."}, {"title": "BETHICS STATEMENT", "content": "By refining the ability to parse and process multifaceted information, Sibyl helps in delivering more\naccurate and reliable outputs during complex reasoning in real-world scenarios. This progression\nhelps improve the reliability of responses and reduce the occurrence of hallucinations in the outputs\nof these models. In addition, during the evaluation phase, we implemented rigorous monitoring of\nthe reasoning processes to identify and prevent any potentially harmful actions that could be exe-\ncuted by the Sibyl system. This precautionary measure is essential to ensure that while the system\nimproves in autonomy, it remains within the bounds of ethical operation. Due to the versatility of\ngeneral purpose LLM-based agents, we strongly recommend that users of Sibyl also remain vigilant\nregarding the outputs produced, recognizing the potential impacts that these could have if misap-\nplied. Users are urged to ensure that the deployment of Sibyl is aligned with ethical standards and\nnot used for malicious purposes."}, {"title": "CPROMPTS", "content": "You are a helpful AI assistant.\nI'll give you a question and a set of tools. Tell me which\nfunction you would use to solve the problem (or if you don't\nneed any tool).\n# Step History\n{steps}\n# Question\ntext\n{question}\n# Tools\n## Browser\nThe functions of the browser will share the same session, that\nmeans the viewport will persist between calls\nEvery function will return the text of the current viewport after\n\u2192 the action is performed. For long pages (longer than 1\n\u2192 viewport), you can use the page_up() and page_down()\n\u2192functions to scroll the viewport.\nSince the page has been converted from HTML to Markdown, you\ncannot submit information using a form, nor can you enter\n\u2192 information in any text boxes. If you want to use the form\ninside the page, try using the computer_terminal below to\nread the html content.\nWhen the page is very long, content truncation may occur due to\n\u2192 the limited display capacity of the viewport. You need to\n\u2192carefully consider whether additional page down is needed to\n\u2192ensure that you have obtained the complete information.\ninformational_web_search (query: str) -> str:\nPerform an INFORMATIONAL web search query and return the\nsearch results.\nnavigational_web_search (query: str) -> str:\nPerform a NAVIGATIONAL web search query and immediately\n\u2192 navigate to the top result. Useful, for example, to\n\u2192 navigate to a particular Wikipedia article or other\n\u2192known destination. Equivalent to Google's \"I'm Feeling\nLucky\" button.\nvisit_page(url: str) -> str:\nVisit a webpage at a given URL and return its text.\npage_up() -> str:\nScroll the viewport UP one page-length in the current webpage\n\u2192 and return the new viewport content.\npage_down() -> str:\nScroll the viewport DOWN one page-length in the current\n\u2192 webpage and return the new viewport content.\ndownload_file(url: str) -> str:\nDownload a file at a given URL and, if possible, return its\ntext. File types that will returned as text: .pdf,\n.docx, .xlsx, .pptx, .wav, .mp3, .jpg, .jpeg, .png (You\ncan read the text content of the file with these\n\u2192 extensions).\nfind_on_page_ctrl_f(search_string: str) -> str:\nWhen the page is too long to be fully displayed in one\n\u2192viewport, you can use this function to scroll the\n\u2192 viewport to the first occurrence of the search string.\nIf the viewport has already displayed the entire\n\u2192page (Showing page 1 of 1.), there is no need to use this\n\u2192function. This is equivalent to Ctrl+F. This search\nstring supports wildcards like '*'\nfind_next() -> str:\nScroll the viewport to the next occurrence of the search\n\u2192 string.\n## Computer Terminal\ncomputer_terminal (code: str) -> str\nYou can use this tool to run Python code. Use print() to\noutput the result.\nBased on the question and the step history, tell me which function\nyou would use to solve the problem in next step.\nIf you don't need any function or the question is very easy to\nanswer, function \"None\" is also an option.\nDo not change the format and precision of the results (including\n\u2192rounding), as a dedicated person will handle the final\n\u2192 formatting of the results.\nUse JSON format to answer.\n{format_instructions}\nYour ultimate goal is to find the answer to the question below.\ntext\n{question}\n# Step History\ntext\n{steps}\nThe next step is running the following code:\npython\n{code}\nCheck this code and help me improve it.\nResponse in JSON format:\n{format_instructions}\n## Computer Terminal\ncomputer_terminal (code: str) -> str\nYou can use this tool to run Python code. Use print() to\noutput the result.\n# Step History\ntext\n{steps}\n# Current Step Tool Result\nTool: {tool}\nArgs"}]