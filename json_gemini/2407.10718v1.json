{"title": "SIBYL: SIMPLE YET EFFECTIVE AGENT FRAMEWORK\nFOR COMPLEX REAL-WORLD REASONING", "authors": ["Yulong Wang", "Tianhao Shen", "Lifeng Liu", "Jian Xie"], "abstract": "Existing agents based on large language models (LLMs) demonstrate robust\nproblem-solving capabilities by integrating LLMs' inherent knowledge, strong in-\ncontext learning and zero-shot capabilities, and the use of tools combined with in-\ntricately designed LLM invocation workflows by humans. However, these agents\nstill exhibit shortcomings in long-term reasoning and under-use the potential of\nexisting tools, leading to noticeable deficiencies in complex real-world reasoning\nscenarios. To address these limitations, we introduce Sibyl, a simple yet power-\nful LLM-based agent framework designed to tackle complex reasoning tasks by\nefficiently leveraging a minimal set of tools. Drawing inspiration from Global\nWorkspace Theory, Sibyl incorporates a global workspace to enhance the manage-\nment and sharing of knowledge and conversation history throughout the system.\nFurthermore, guided by Society of Mind Theory, Sibyl implements a multi-agent\ndebate-based jury to self-refine the final answers, ensuring a comprehensive and\nbalanced approach. This approach aims to reduce system complexity while ex-\npanding the scope of problems solvable\u2014from matters typically resolved by hu-\nmans in minutes to those requiring hours or even days, thus facilitating a shift\nfrom System-1 to System-2 thinking. Sibyl has been designed with a focus on\nscalability and ease of debugging by incorporating the concept of reentrancy from\nfunctional programming from its inception, with the aim of seamless and low\neffort integration in other LLM applications to improve capabilities. Our experi-\nmental results on the GAIA benchmark test set reveal that the Sibyl agent instan-\ntiated with GPT-4 achieves state-of-the-art performance with an average score of\n34.55%, compared to other agents based on GPT-4. We hope that Sibyl can in-\nspire more reliable and reusable LLM-based agent solutions to address complex\nreal-world reasoning tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs) have transformed the landscape of human-computer interaction\n(HCI) by offering unprecedented capabilities in understanding and generating human-like text.\nLLM-based agents, which are systems designed to harness these models, effectively orchestrate\nLLM capabilities to address complex tasks (Xi et al., 2023; Wang et al., 2024). These agents lever-\nage human-designed frameworks that utilize the inherent knowledge within LLMs, often employing\nstructured workflows that maximize the potential of in-context learning and zero-shot capabilities.\nSuch strategies allow these agents to engage in sophisticated dialogues and problem-solving sce-\nnarios that mirror human cognitive processes (Sumers et al., 2023). By incorporating prior human\nknowledge into the workflow, LLM-based agents can process and utilize information with a level of\nproficiency that was previously unattainable.\nDespite their abilities, LLM-based agents are often limited by their inability to engage in complex\nquestions of reasoning in real-world scenarios, where the number of reasoning steps can be nu-\nmerous (Mialon et al., 2023). While LLMs excel in simpler, quick-answer scenarios, they struggle"}, {"title": "2 THE SIBYL FRAMEWORK", "content": "In this section, we provide a overview of the Sibyl framework, focusing on its design philosophy\nand fundamental modules. As shown in Figure 1, given a user query, Sibyl starts with the tool\nplanner which aims to select appropriate tools, functions, and parameters tailored to each specific\nsubtask. Then, we design an external information acquisition channel to call the tools and selectively\ncompress the external information returned by tool execution. Inspired by Society of Mind Theory,\nwe incorporate a multi-agent debate-based jury to achieve self-correction and a global workspace\nto seamlessly share information and enable effective collaboration across all modules. The prompts\nfor each module are described in Appendix C."}, {"title": "2.1 DESIGN PHILOSOPHY", "content": "The Sibyl framework is constructed around a core design philosophy that focuses on reducing com-\nplexity while enhancing the functional capabilities of LLM-based agents. This philosophy is imple-\nmented through several strategic approaches to restructure LLM operations.\nHuman-oriented Browser Interface Instead of Retrieval Augmented Generation In conven-\ntional LLM-based agent setups, Retrieval Augmented Generation (RAG) often leads to significant\ninformation loss due to the limitation of retrieval process, which can lose the sequential informa-\ntion and connection of chunks in long text and have to trade off between information precision and\nrecall. Retrieving information at a coarse level yields a wider range of data but with less preci-\nsion, while a fine-level retrieval approach ensures a more detailed dataset, albeit sacrificing speed.\nInspired by the success of WebGPT (Nakano et al., 2021), Sibyl addresses this by adopting a human-\noriented browser interface, shifting away from RAG's constraints towards a more intuitive, human-\nlike method of information retrieval. This form of information gathering is crucial as it retains the\nrelational dynamics of the text, preserving more context and depth in the data accessed by the agent.\nQuestion Answering Function Instead of Dialogues Recent agent frameworks such as AutoGen\n(Wu et al., 2023) utilize dialogue as the primary mode of communication between different modules.\nThis design is intended to mimic human conversational patterns, making the interaction more natural"}, {"title": "2.2 TOOL PLANNER", "content": "The tool planner in Sibyl is a specialized module designed to select the most suitable (tool, function,\nparameters) triplets and parameters to address incoming queries step by step. Given the planning\nprompt, it assesses the given query and any associated step history to determine the most effective\ntools, functions, and parameters for execution. If the query can be resolved straightforwardly and\ndoes not require additional tools, the planner can also select \"None\", indicating that no additional\ntools are required for that particular step."}, {"title": "2.3 EXTERNAL INFORMATION AQUISITION CHANNEL", "content": "The external information acquisition channel plays a pivotal role in enhancing the agent's ability to\nprocess and utilize information effectively. It first obtains the output of the tool planner, which spec-\n      ifies the tool, function, and parameters to be used. Upon receiving these directives, the appropriate\n      tools are activated to gather and return the needed information.\nThen, the channel performs analysis to extract and verify relevant information for the query. This\ninvolves:\n\u2022 Analyzing the tool results to extract relevant data that directly contributes to answering the\nquestion."}, {"title": "2.4 MULTI-AGENT DEBATE-BASED JURY", "content": "The Society of Mind Theory, proposed by Marvin Minsky, provides a fundamental underpinning\nfor the design of the jury system in the Sibyl framework. It posits that the mind is composed of a\nmultitude of semi-autonomous agents, each responsible for different aspects of intellectual opera-\ntion, making complex cognitive processes emerge from the interactions and negotiations between\nsimpler, specialized processes. These agents work in concert, albeit through a decentralized process\nof negotiation and cooperation, much like a society (Minsky, 1988). This inspired the multi-agent\ndebate-based jury mechanism in the Sibyl framework, where multiple agents can discuss and analyze\nproblems, mimicking the cooperative yet independent interaction of Minsky's mental agents.\nHere we instantiate the jury with a minimal implementation using AutoGen (Wu et al., 2023), where\ntwo primary roles are defined:\n\u2022 Actor: This agent attempts to answer the question, explain their thought process in detail,\nand consider feedback from others critically.\n\u2022 Critic: The role of this agent is to identify logical or intellectual errors in the actor's rea-\nsoning.\nThese roles allow for a structured yet flexible interaction and play a vital role in ensuring the logical\ncoherence and intellectual integrity of the responses provided. We leave the exploration of diverse\norganizational forms for LLM-based agents for future work, including collaborative models like\nadvisory councils.\nIn addition, the Sibyl framework employs a majority vote ensemble method to enhance the stability\nand quality of the output answers. This method aggregates decisions or suggestions from multi-\nple inferences, using their consensus to finalize the answer. This approach is particularly effective\nin mitigating individual errors in agent responses, leading to more reliable and accurate problem\nsolving."}, {"title": "2.5 GLOBAL WORKSPACE", "content": "The concept of the global workspace in Sibyl is deeply influenced by Global Workspace Theory\n(Baars, 1993; 2005), which suggests that the brain consists of many specialized processes or mod-\nules that operate simultaneously, with a significant portion functioning unconsciously. Attention\nserves as a spotlight that elevates some of these unconscious activities to conscious awareness within\nthe global workspace. This workspace acts as a crucial hub for the broadcasting and integration of\ninformation, allowing its distribution across various modules. This theoretical backdrop inspires\nthe design of the global workspace as an integrative platform for various modules within the Sibyl\nframework, facilitating seamless information sharing and a comprehensive understanding of com-\nplex problems.\nThe global workspace acts as a central hub where different modules can broadcast their outputs and\ninsights. This mechanism ensures that despite the modular nature of the system, there is a cohesive\nand unified approach to problem solving. In addition, information within the global workspace is\nwell-structured and denoised, which not only ensures that the data is easy to access and manip-\nlate by LLMs but also simplifies the debugging and case-analysis processes for human developers.\nBy implementing this global workspace, the framework supports complex information handling and\nlong reasoning sequences, facilitating the evolution from rapid, reflexive responses (System-1 think-\ning) to more deliberate and structured problem solving (System-2 thinking)."}, {"title": "3 EXPERIMENTS", "content": "Datasets We conducted our evaluations on the GAIA dataset (Mialon et al., 2023), a benchmark\ntailored for general AI assistants. The GAIA dataset is designed to reflect tasks that align closely\nwith human perceptual capabilities, including visual, auditory, and textual modalities. This dataset\nchallenges general-purpose assistants with complex reasoning tasks that even require dozens of steps\nto solve, similar to those encountered by humans. Such a design significantly magnifies the impact of\nerror propagation, providing a robust evaluation of problem-solving and error-handling capabilities\nfor LLM-based agents."}, {"title": "3.1 SETTINGS", "content": "In our experimental setup for the Sibyl framework, we utilized two primary tools: a web browser and\na Python-based code interpreter. Details of these tools are described in the Appendix A. To balance\nbudget constraints and time cost, we only use the GPT-40 API within the text modal, and limit the\nmaximum number of reasoning steps of the model to 20."}, {"title": "3.2 BASELINES", "content": "We compared it against several established baselines on GAIA: 1) GPT-4 (Achiam et al., 2023)\nwith and without manually configured plugins, 2) AutoGPT-4 (Gravitas, 2023), which integrates\nAutoGPT with a GPT-4 backend, 3) An LLM-based agent implemented by AutoGen (Wu et al.,\n2023), a framework designed for automating complex multi-agent scenarios, and 4) FRIDAY (Wu\net al., 2024), an advanced agent utilizing OS-Copilot for automating a broad spectrum of computer\ntasks, capable of interfacing with various operating system elements including web browsers, code\nterminals, and multimedia."}, {"title": "3.3 MAIN RESULTS", "content": "We present the results of our experiments on both the test and validation sets of the GAIA dataset in\ntable 1 and 2, respectively. Our findings highlight that Sibyl outperforms other models in the GAIA"}, {"title": "3.4 ABLATION STUDIES", "content": "We further conduct the ablation studies on the validation set of GAIA to investigate the individual\ncontributions of specific components within the Sibyl framework. We mainly focus on two main\ncomponents: the multi-agent debate-based jury and the majority vote-based ensemble. As shown\nin 4, the removal of the multi-agent debate component resulted in a notable performance drop in\nthe Level 1, which indicates that this component significantly boosts the accuracy for basic question\ntypes. However, its removal did not markedly affect the performance in the more challenging Levels\n2 and 3. This suggests that while the multi-agent debate is crucial for resolving simpler queries\neffectively, it does not substantially influence the outcome of more complex reasoning tasks.\nTo evaluate the impact of the ensemble component, we report the average accuracy across three\nseparate runs to ensure a fair comparison against the ensemble configuration. The individual runs\nyielded overall accuracies of 40.61, 34.55, and 35.15, respectively, with an average of 36.77, com-\npared to the ensemble's overall performance of 40.00. While one run did slightly exceed the ensem-\nble result, the ensemble generally provided more stable and consistent outcomes. This demonstrates"}, {"title": "3.5 DISCUSSION", "content": "In this section, we will explore some insights gained from the development of Sibyl. We hope that\nthese insights can inspire future LLM-based agent work with more powerful reasoning capabilities.\nChallenges in Complex Reasoning Complex reasoning in real-world applications is inherently\nchallenging due to the high risk of error propagation. Even with an 80% accuracy rate at each\nstep, the probability of maintaining this accuracy consistently across 20 steps plummets to merely\naround 1%. This exponential increase in error risk highlights the critical nature of maintaining high\naccuracy at every step in reasoning. Furthermore, excessive errors can cause a series of retries which\nconsume significant portions of the context, submerge useful information and hamper the problem-\nsolving process.\nStrategic Approaches to Mitigating Errors The decomposition of complex reasoning into sim-\npler, manageable substeps is vital, as improving the success rate of each step can significantly mit-\nigate error propagation. Selective compression of historical information plays a key role here, as\nmost of the data accumulated during web navigation and previous interactions do not directly con-\ntribute to solving the problem at hand. This approach not only streamlines information processing,\nbut also focuses on maintaining only the most pertinent data, enhancing overall system efficiency.\nImportance of Debug-oriented Design A robust debug-oriented design is essential for reduc-\ning debugging costs and facilitating rapid system iteration. By limiting the introduction of state\nand striving for decoupling between components and even individual LLM inference requests, the\nsystem's maintainability and adaptability are significantly improved. Given that Sibyl follows the\ncombinator pattern, it can be seamlessly integrated as a low-cost enhancement into existing frame-\nworks, easily replacing the vanilla GPT-4 API. This design can make it more flexible in various\nLLM applications.\nOptimizing Tool Usage Considering the aforementioned error propagation in complex reasoning,\noptimizing existing tools is often more crucial than adding new ones. The potential of tools such as\nweb browsers is far from fully realized; current LLM agents do not yet match human capabilities\nin terms of content visibility and operational scope on web platforms. Enhancing these tools to\nfully exploit their capabilities can provide substantial improvements in performance and utility, thus\ndriving forward the sophistication and effectiveness of AI systems in complex environments."}, {"title": "4 RELATED WORK", "content": "The integration of LLMs into autonomous agents marks a significant advancement in the field of\nartificial intelligence. These agents, capable of sensing their environment, making decisions and\ntaking actions, are at the forefront of pushing AI towards Artificial General Intelligence (AGI) (Xi\net al., 2023; Wang et al., 2024). These agents, often referred to as LLM-based agents, are increas-\ningly prevalent across a variety of domains, demonstrating the potential of LLM applications in\ncomplex scenarios.\nMost LLM-based agents are designed for specific applications, highlighting their adaptability but\nalso suffering from a potential limitation in versatility. These applications include mathmatical\nproblem solving (Gou et al., 2023; Swan et al., 2023), coding (Yang et al., 2024; Zheng et al., 2024),\nrole-playing (Shao et al., 2023; Shen et al., 2023), and social simulation (Park et al., 2023; Gao et al.,\n2023). To take a step further towards general purpose LLM-based agents that are capable of various\ngeneral tasks, open-source communities have developed some LLM-based agent framework, such\nas Langchain (Chase, 2022), BabyAGI (Nakajima, 2023) and AutoGPT (Gravitas, 2023). Equipped\nwith tools and structured frameworks, these agents can competently handle relatively straightfor-\nward tasks with human-like capabilities. However, their proficiency in tackling complex real-world\nchallenges remains comparatively limited. This gap indicates the need for further enhancements in\ngeneral-purpose LLM-based agents to address more intricate problems effectively."}, {"title": "5 CONCLUSION", "content": "We introduce Sibyl, an agent framework designed to enhance the capabilities of LLMs in complex\nreasoning tasks. Through the integration of modular design and a global workspace for information\nsharing and collaboration, Sibyl aims to facilitate the transition of LLM-based agents from rapid and\nintuitive System-1 thinking to slow and delibrate System-2 thinking. Our experimental results on\nthe GAIA benchmark show that the Sibyl agent instantiated by GPT-4 outperforms existing state-of-\nthe-art solutions, demonstrating the effectiveness of our proposed framework. We hope that Sibyl\ncan contribute to the promotion of LLM applications to have better capabilities in handling complex\nreal-world tasks."}, {"title": "A DETAILS OF TOOLS", "content": "In the development of Sibyl, we reuse the tools from the AutoGen (Wu et al., 2023). Below is\na detailed description of each tool and its functions, providing insights into how these tools are\nutilized within the framework to process and interact with web content efficiently.\nWeb Browser The web browser tool in Sibyl is designed to perform a variety of functions that\nfacilitate interaction with web pages. These functions are shown in table 5."}, {"title": "Computer Terminal", "content": "The computer terminal tool serves as a code interpreter within the Sibyl\nsystem. This tool allows the execution of Python code, facilitating dynamic computation and pro-\ncessing tasks which are crucial for complex problem solving and data manipulation within the AI\nframework.\nThese tools and their functionalities are important in enabling the Sibyl agent to navigate, inter-\npret, and interact with the digital world effectively, mirroring human-like web browsing and data\nprocessing capabilities."}, {"title": "BETHICS STATEMENT", "content": "By refining the ability to parse and process multifaceted information, Sibyl helps in delivering more\naccurate and reliable outputs during complex reasoning in real-world scenarios. This progression\nhelps improve the reliability of responses and reduce the occurrence of hallucinations in the outputs\nof these models. In addition, during the evaluation phase, we implemented rigorous monitoring of\nthe reasoning processes to identify and prevent any potentially harmful actions that could be exe-\ncuted by the Sibyl system. This precautionary measure is essential to ensure that while the system\nimproves in autonomy, it remains within the bounds of ethical operation. Due to the versatility of\ngeneral purpose LLM-based agents, we strongly recommend that users of Sibyl also remain vigilant\nregarding the outputs produced, recognizing the potential impacts that these could have if misap-\nplied. Users are urged to ensure that the deployment of Sibyl is aligned with ethical standards and\nnot used for malicious purposes."}, {"title": "D LIMITATIONS AND FUTURE DIRECTIONS", "content": "Despite the advancements demonstrated by the Sibyl framework, there are inherent limitations that\nwait to addressed in the future."}, {"title": "D.1 LIMITATIONS", "content": "Lack of Vision Large Language Model Support Currently, Sibyl primarily operates on textual\ndata and use Optical Character Recognition (OCR) to convert visual information into text modal,\nthus lacking integration with vision large language models, which restricts its ability to process and\ninterpret visual content as humans do.\nBrowser Functionalities While Sibyl utilizes a browser tool, it is not yet equipped with a fully\nfunctional browser akin to those used by humans. This limitation affects the agent's ability to interact\nwith web content in a more natural and efficient manner.\nLearning Mechanisms The present system does not incorporate learning mechanisms to adapt\nand improve from real-world interactions on-the-fly. This may restrict its ability to evolve based on\nnew data or scenarios it encounters."}, {"title": "D.2 FUTURE DIRECTIONS", "content": "Integrating Vision Large Language Models Future versions of Sibyl will incorporate vision\nlarge language models to allow the system to handle multimedia content effectively, broadening\nits applicability across various domains where visual data plays a crucial role.\nEnhancing Browser Capabilities There is a pressing need to optimize the browser tool to provide\nfull functionality, mirroring the capabilities available to human users, thereby improving the agent's\ninteraction with web interfaces.\nDesigning Adaptive Learning Mechanisms In the future version of Sibyl, we plan to introduce\nadaptive learning mechanisms will enable the system to learn from its interactions and experiences,\nthereby progressively improving its problem-solving strategies and effectiveness.\nDeveloping LLMs tailored for Agents Future work will also focus on developing LLMs that\nare specifically optimized for general-purpose AI agents, aiming to enhance their efficiency and\neffectiveness in complex reasoning tasks. This includes gathering and utilizing data specific to long-\ndistance reasoning processes in real-world scenarios and improving the system's ability to build and\nreuse its tools autonomously."}]}