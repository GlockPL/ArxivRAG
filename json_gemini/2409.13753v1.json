{"title": "Synergistic Simulations: Multi-Agent Problem Solving with Large Language Models", "authors": ["Asher Sprigler", "Alexander Drobek", "Keagan Weinstock", "Wendpanga Tapsoba", "Gavin Childress", "Andy Dao", "Lucas Gral"], "abstract": "Large Language Models (LLMs) have increasingly demonstrated the ability to facilitate the development of multi-agent systems that allow the interpretation of thoughts and actions generated by each individual. Promising advancements have also been made in LLM-based interaction with existing worlds, particularly in interacting with simulated environments. This paper aims to integrate both aforementioned topics (agents & world interaction) into a single simulation where multiple agents can work together to solve a problem, modeling how groups of humans can often solve problems better than individuals. By showing whether LLMs demonstrate the synergy of human collaboration, it could lead to advancements in the applications of LLMs. We implemented two simulations: a physical studio apartment with two roommates, and another where agents collaborate to complete a programming task. We provide a multi-agent framework, discuss the performance of the agents in each simulation, and discuss potential future additions.", "sections": [{"title": "1 Implementation", "content": ""}, {"title": "1.1 Overview", "content": "We aim to provide a general framework which can be applied to more specialized problems in various domains. Our framework utilizes the idea of an agent and introduces the idea of an environment. Agents are independent units of behavior which have a unique understanding of themselves and how they relate to other agents and the environment. An environment is any representation of a state that agents can interact with to reach a goal. All agents are given a goal related to the problem domain and a description of how they are expected to interact with the environment. With this information, agents are free to interact with the environment and each other in any way. In having many agents rather than a single unit of behavior (i.e., an LLM chat bot) convene on a single problem, our objective is to replicate how groups of humans can often solve problems better than individuals.\nAdditionally, we hope to show that LLM research does not require the use of large proprietary models like OpenAI's ChatGPT. [7] Instead, one can use open source LLMs which open many more possibilities for experimentation: highly customized fine tuning, the safe use of sensitive and/or proprietary data, independence from usage restrictions, no required proprietary model changes, and no usage rates or rate limits. In our case, we used Rosie, MSOE's supercomputer [8], with llama.cpp (a general-purpose LLM inference library) [5], and we experimented with Llama7b [3] and Mistral7b-instruct [4]. By using Rosie, we were able to gain the benefits of no usage rates or rate limits without sacrificing LLM inference performance or (to a lesser extent) output quality as would be the case if we only had consumer hardware."}, {"title": "1.2 Agents", "content": "Our approach is primarily inspired by prior work which simulates agents in a more static environment as opposed to a fully dynamic environment. [1] At the root of our implementation can be any LLM that has chatting capabilities. We briefly explored usage of Llama7B [3], but ultimately decided on using Mistral7B-instruct [4] which we qualitatively determined generates better results. To run our LLM, we are using llama.cpp. [5] All independent agents exist in parallel on top of a single LLM instance, differentiated by their unique histories. Agent histories are, at their simplest, a list of messages used as input for the LLM."}, {"title": "1.3 Environment & Interaction", "content": "To extend the simple muti-agent framework, we introduce the idea of an environment. The idea of an environment is more general; it can be any representation of objects on which the agents can interact in turns. In practice, we commonly implemented an environment as a list of associative arrays which map various objects' attribute names to values.\nTo facilitate interaction, agents take turns participating in an event loop which consists of these steps at the highest level:\n1) The environment is summarized to an agent including possible interactions and prompts.\n2) The agent will then decide an action to pursue.\n3) This action will then be applied to the environment. This is done by, for instance, having agents select a function from a given set of predefined functions (as is described in the apartment environment section).\n4) This is repeated for each agent during the event loop with environment changes persisting between event loops."}, {"title": "1.4 Observation", "content": "Many problems necessitate the use of more information than what can be included in the context window of an LLM. To solve this problem, we implemented a system of longer-term memory based on the concept of \u201cobservations\u201d seen in prior work. [1] Observations are short statements about the environment that agents generate after every action. Generated observations include a timestamp, and an importance-value. Before each action taken, relevant observations are injected into the agent's history. Additionally, the history is truncated to a predetermined length after every response, with the oldest messages being removed (except for the system prompt)."}, {"title": "2 Apartment Environment", "content": ""}, {"title": "2.1 Overview", "content": "One implementation of the agent framework involved placing two agents in an apartment environment as \u201croommates\u201d with a moderator LLM that assisted them in interacting with their environment and each other. They were given two situations to navigate: one where they had the broader goal of living in the apartment and had to coordinate the finer details amongst themselves, and another where they had the explicit goal of baking a cake in a kitchen with the moderator helping them explore their environment and discover necessary materials."}, {"title": "2.2 Event Loop", "content": "To start the event loop, we needed to create several different agents: two roommates and a moderator. We created a moderator that would keep the roommates' responses in check so that there was a better understanding. We did this by reducing the temperature on the moderator and increasing the temperature on the roommates. We then supplied various system prompts for these agents:\n\u2022 For the moderator: \u201cYou are a moderator that helps an agent interact with their environment.\"\n\u2022 For roommate 1: \u201cYou are an accountant living in a studio apartment in the city, you have a roommate. You can talk to your roommate, and interact with the environment, including speaking with your roommate.\"\n\u2022 For roommate 2: \u201cYou are an engineer living in a studio apartment in the city, you have a roommate. You can talk to your roommate, and interact with the environment, including speaking with your roommate.\u201d\nWe stored these agents in an array, and made a method called agent_interaction. The event loop is the means through which the agents interact with their environment."}, {"title": "2.3 Results", "content": "In the shared environment of their apartment, two roommates cohabit like any ordinary pair of individuals. Initially, they were curious about the room's temperature, ensuring it remains comfortable for both, a behavior typical of people cohabiting. The most intriguing task they accomplished was their coordination in managing apartment expenses. One roommate proposed the creation of a spreadsheet to meticulously track expenses and ensure timely payments. This initiative demonstrates remarkable thoughtfulness, especially when contrasted with the tendencies of many humans who occasionally overlook bill payments and fail to derive effective solutions to prevent recurrence. Then the other roommate, an engineer, took that idea and began to write python that would generate a viable spreadsheet for this purpose. This shows that when allowed to approach a broad problem with their own techniques, the LLMs can work together to solve it practically."}, {"title": "2.4 Drawbacks/Challenges", "content": "A setback that we had at the start of research was getting the agent to work in the pre-determined environment that we had set up for it. When we first introduced the world object, we had the moderator mention to the agent that it existed and ask it to interact within it. However, the agent was refusing to use it and instead developed its own world to interact in. This was unfortunate, as a great deal of effort had already been put in to ensure that the agent's temperature was high enough to adequately explore its environment and make unique choices. To fix this issue we decided to make the moderator \u201charsher\u201d to the agent. This included telling it how to respond to the moderator and what it was only allowed to do. We also decided to display the \u2018World' object to it and the methods it was allowed to use in this environment. This proved to be a great success because when tested on an individual agent it consistently stayed within the environment as well as choosing the methods it wanted to use in a way the moderator was better able to understand. The agents also proved they could develop their own methods in the correct format so the moderator could use them.\nAnother challenge we found was finding an efficient way for the moderator to expose the agents to only the functions that they might find relevant to their task. We developed a dictionary of all the functions that the agents would use to interact with the environment. The issue that came up was the moderator pulling all the functions out and turning them into strings so that the agents were able to read them. This created a large amount of text, most of which was irrelevant to the agents' current objective. To solve this problem, we changed the event loop's call method so that the moderator would grab only the functions it required, then it went into the dictionary and converted all the functions into a string format so that the agents were able to read and respond correctly.\nHowever, despite their ability to interact with the environment, we also had to provide a method for the agents to talk to one another through the moderator so we could have a social interaction between the two roommates. Initially, the agents had a hard time understanding that they were in the environment with another agent and that they could communicate with each other through the moderator. This required the creation of a separate programmatical approach where an agent could call a function through the usage of the moderator which allowed it to say something to the other roommate and receive an instant response. However, a roommate would have to wait until their turn to initiate a conversation."}, {"title": "2.5 Discussion", "content": "Collaboration in a simulated, physical, modifiable environment allowed for a powerful extrapolation of a vague problem to a more defined set of smaller problems, as seen in examples such as the accountant being faced with the management of an apartment, and then working logistically with his software engineering roommate to begin the creation of a script to help manage their finances. In situations where they could create their own sub-objective, they successfully worked through their problems. However, this environment did not provide strong evidence for the collaboration of large language models on specifically defined problems using programmatic methods, as the models used lacked the necessary context to explain or hold all necessary information about the environment to engage in a detailed task such as baking a cake. Overall, model collaboration in this environment shows promise for upper-level problem solving, and as open-source LLMs utilize techniques for greater context retention, these complex simulated problems may open to the effort of collaboration more easily."}, {"title": "3 Online Coding Environment", "content": ""}, {"title": "3.1 Overview", "content": "The coding environment tasks multiple agents with solving some coding problem collaboratively, allowing agents to interact with the code and each other through natural language. The agents will be able to modify and add to the code, as well as post messages to a \u201cchatroom\u201d that potentially allows the agents to interact with each other and explain changes/additions they make to the code. The goal of this is to see if agents can collaborate to create articulate pieces of code and allow errors to be caught by having more than one agent look at and work on the code. These agents were tested with a variety of easy and medium Leetcode tasks, such as \u201cRemove Nth Node From End of List\"."}, {"title": "3.2 Event Loop", "content": "An initial LLM is created as an \u201cexpert problem solver\u201d tasked with splitting the given prompt into a list of steps that may aid the agents in their task. The agents are then created and told about the prompt for the problem as well as how they will respond. Each agent gets a turn to add or modify the code and add a message to the \u201cchatroom\u201d, which is a list of strings that is relayed to the other agents. Then, once an agent thinks that the code is done, the loop finishes, and the code is printed out to a file. I manually evaluated their responses in the Leetcode website."}, {"title": "3.3 Results", "content": "The agents were not able to give correct solutions to a variety of easy and medium difficulty Leetcode problems presented to them. Additionally, the chatroom functionality was only used by the agents to explain their coding decisions and not for any social functions. With these results, it can be said that a single LLM would produce better results than agents working together in this environment."}, {"title": "3.4 Drawbacks/Challenges", "content": "The biggest piece of the event loop that is missing is having the code run, and then giving feedback from that to the agent. Currently, agents can finish the code and agree that it is finished, but the code suffers from runtime issues, most likely because it is not being checked in each step of the event loop. This was not implemented due to time concerns, especially because it would increase the run time of the event loop significantly. This would be one of the next things to implement into this environment."}, {"title": "3.5 Discussion", "content": "One reason for the complications in achieving the desired results could be using an LLM not specifically trained for coding purposes. To mitigate this problem, a specially trained model for writing code (such as Code Llama) could have been used in place, but time and constraints did not allow us to test this.\nAnother problem could be how the agents were allowed to interact with the environment. Their implementation was too unrestricted, allowing them too much freedom when editing the code. The LLMs would sometimes defy their prompts and produce outputs that were unworkable or would crash the event loop. A typical example of this type of problem was seen when the LLMs were asked to keep their alterations of the code to a maximum of five lines but would try to write the entire solution at once.\nA workaround for this could have been a different approach to how the agent was asked to generate code. The list of instructions generated by the moderator could have been used as a checklist which would then be utilized to generate the code step by step, having the agents and moderator validate their completion, instead of adding or changing wherever the agents saw fit."}, {"title": "4 Future Additions", "content": "There are many interesting directions in which we could continue our agent framework. These include the following ideas:\nUse multiple LLMs in parallel to speed up our simulations via higher agent inference throughput.\nExperimenting with other open source LLMs, including larger models, and different types of more specialized models such as Code Llama.\nExperimenting with fine-tuning our agent LLM to possibly reach agents that are better at collaborating.\nExpanding programmatic environment interaction, including the generation of action functions by the agents themselves, and by investigating the approach of having actions which depend on each other in the form of a directed graph.\nNon-turn-based agents which can act in parallel.\nMore sophisticated means of observation, such as reflective capabilities which combine multiple observations into a tree of experience. [1]"}]}