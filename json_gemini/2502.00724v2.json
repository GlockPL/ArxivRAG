{"title": "Learned Bayesian Cram\u00e9r-Rao Bound for Unknown Measurement Models Using Score Neural Networks", "authors": ["Hai Victor Habi", "Hagit Messer", "Life Fellow, IEEE", "Yoram Bresler", "Life Fellow, IEEE"], "abstract": "The Bayesian Cram\u00e9r-Rao bound (BCRB) is a crucial tool in signal processing for assessing the fundamental limitations of any estimation problem as well as benchmarking within a Bayesian frameworks. However, the BCRB cannot be computed without full knowledge of the prior and the measurement distributions. In this work, we propose a fully learned Bayesian Cram\u00e9r-Rao bound (LBCRB) that learns both the prior and the measurement distributions. Specifically, we suggest two approaches to obtain the LBCRB: the Posterior Approach and the Measurement-Prior Approach. The Posterior Approach provides a simple method to obtain the LBCRB, whereas the Measurement-Prior Approach enables us to incorporate domain knowledge to improve the sample complexity and interpretability. To achieve this, we introduce a Physics-encoded score neural network which enables us to easily incorporate such domain knowledge into a neural network. We study the learning errors of the two suggested approaches theoretically, and validate them numerically. We demonstrate the two approaches on several signal processing examples, including a linear measurement problem with unknown mixing and Gaussian noise covariance matrices, frequency estimation, and quantized measurement. In addition, we test our approach on a nonlinear signal processing problem of frequency estimation with real-world underwater ambient noise.", "sections": [{"title": "I. INTRODUCTION", "content": "The Bayesian Cram\u00e9r-Rao Bound (BCRB) [1] is a crucial tool in signal processing for assessing the fundamental limitations of any estimation problem within a Bayesian framework. For instance, the BCRB has been employed to elucidate various signal processing applications such as localization [2], [3] and MIMO systems [4], among others [5]\u2013[7]. Besides understanding the intrinsic limits of problems, the BCRB has also been used for system design, including waveform design [8]\u2013[11].\nHowever, to obtain the BCRB requires complete knowledge of both the prior and the measurement distributions. In addition, in some cases, even when both prior and measurement distributions are known, the BCRB cannot be computed, because the required integration over the parameter distribution does not have a close-form solution.\nVarious methods have been proposed to derive a bound from data, rather than analytically. Some leverage prior knowledge of the problem combined with a learnable component. For instance, [12] presents a non-Bayesian bound for single-channel speech separation. Another category of methods, as those described in [13], [14], proposes bounds based on f-divergences. However, these methods require access to a special dataset containing observations where for each parameter value there are also observations with a slightly perturbed parameter value. This condition is generally viable only when one can generate an observation vector for any desired value of the parameter vector that one aims to estimate.\nRecently, thanks to the success of generative models in modeling complex, high-dimensional data distributions [15], [16], a new approach has been introduced that suggested using a learned Generative Cram\u00e9r Rao bound [17] when the measurement distribution is completely unknown, but a dataset of independent and identically distributed (i.i.d) measurement-parameter pairs is available. The Generative Cram\u00e9r Rao bound [17] achieves this by first learning the measurement distribution using a generative model, and then utilizing it to obtain the learned Generative Cram\u00e9r Rao bound. The approach of using a generative model to learn a performance estimation bound from data has been extended to several other non-Bayesian bounds, such as the misspecified CRB [18] and the Barankin bound [19].\nThose approaches utilized normalizing flows [16], [20] which enable the computation of the probability density function of the measurements. This comes with a major limitation: that there exist an invertible mapping between the measurements and some base distribution that is analytically tractable (usually standard Gaussian). An example in which such mappings do not exist is when the measurements are quantized [21].\nIn the Bayesian setting, recent work [22] suggested to learn the prior distribution using score matching [23]. After learning the prior score ($\\nabla_\\theta \\log f_\\theta (\\theta)$), obtaining the BCRB using this method requires complete knowledge of the Fisher score function ($\\nabla_\\theta \\log f_{X|\\theta} (x|\\theta)$) and its computation. Given the known Fisher score function and the learned prior score function, the BCRB is then approximately calculated using empirical means. A limitation of this approach is the need"}, {"title": "II. NOTATION AND BACKGROUND", "content": "Upper case A indicates a random vector, lower case italics a and boldface a indicate a scalar and a vector, respectively, with $||\\mathbf{a}||_2$ denoting the $l_2$ norm. The i-th element of a vector a is indicated by $[\\mathbf{a}]_i$. Upper case boldface A indicates a matrix, with its trace, determinant, transpose, Frobenius norm, spectral norm (largest singular value), and condition number denoted by $\\text{Tr}(\\mathbf{A})$, $\\det \\mathbf{A}$, $\\mathbf{A}^T$, $|\\mathbf{A}||_F$, $||\\mathbf{A}||_2$, and $\\kappa(\\mathbf{A})$, respectively. An identity matrix of size $k \\times k$ is denoted by $\\mathbf{I}_k$. For symmetric matrix A the notation $\\mathbf{A} \\succeq 0$ (or $\\mathbf{A} \\succ 0$) means that A is positive-definite (or positive semidefinite). For symmetric A and B the inequality $\\mathbf{A} \\succeq \\mathbf{B}$ means that $\\mathbf{A} - \\mathbf{B} \\succeq 0$. The minimal and maximal eigenvalues of a symmetric matrix A are denoted by $\\lambda_{\\min}(\\mathbf{A})$ and $\\lambda_{\\max}(\\mathbf{A})$, respectively. Finally, the $d \\times d$ Jacobian matrix of a vector function $\\mathbf{s} (\\theta) : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ is denoted by $\\frac{d \\mathbf{s} (\\theta)}{d \\theta}$.\nLet $\\mathbf{X} \\in \\mathcal{Y} \\subseteq \\mathbb{R}^d$ be a random observation vector that depends on a random parameter vector $\\mathbf{\\Theta} \\in \\mathcal{T} \\subseteq \\mathbb{R}^{d_\\Theta}$, and let $f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta})$ be their joint probability density function (PDF).\u00b9 For convenience we model the parameter set $\\mathcal{T}$ as a closed set (in the Euclidean metric) with no isolated points. Assume the following conditions [40, pages 33-35], [41].\nAssumption II.1 (BCRB Regularity Conditions). $f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta})$ satisfies the following conditions:\nII.1.1 The gradient $\\nabla_\\theta \\log f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta})$ with respect to $\\theta$ exists and each of its elements is absolutely integrable w.r.t x and $\\theta$ on $\\mathcal{Y} \\times \\mathcal{T}$.\nII.1.2 The gradient $\\nabla_\\theta \\log f_{\\mathbf{\\Theta}}(\\mathbf{\\theta})$ with respect to $\\theta$ exists.\nII.1.3 The matrix\n$\\mathbb{E}_{\\mathbf{X},\\mathbf{\\Theta}} [\\nabla_\\theta \\log f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\Theta}) \\nabla_\\theta \\log f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\Theta})^T]$\nis positive-definite and finite.\nII.1.4 The limits $\\lim_{\\theta \\rightarrow \\partial \\mathcal{T}^+} f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta}) = 0$ hold, where $\\partial \\mathcal{T}^+$ is the boundary of the set $\\mathcal{T}$ augmented by the points of $\\mathcal{T}$ at infinity in case $\\mathcal{T}$ is unbounded.\nII.1.5 The conditional expectation of the score vanishes for all x, $\\mathbb{E}_{\\mathbf{\\Theta}|\\mathbf{X}} [\\nabla_\\theta \\log f_{\\mathbf{\\Theta},\\mathbf{X}} (\\mathbf{\\Theta}, \\mathbf{x})] = 0$.\nII.1.6 For all $\\theta \\in \\mathcal{T}$, the densities $f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta})$ have a common support {$\\mathbf{x}: f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta}) > 0$} $\\subseteq \\mathcal{Y}$ w.r.t. x that is independent of $\\theta$.\nRemark 1. Assumption II.1.3, although sometimes not stated explicitly (e.g., [40, pages 33-35]), is, in view of (2), a natural non-degeneracy assumption for the BCRB.\nRemark 2. When X is a discrete random variable, a slightly altered set of regularity conditions can be used [42].\nRemark 3. In situations where one or more of assumptions II.1.4 and II.1.5 is not satisfied, both can be substituted by the bias condition $\\lim_{\\theta \\rightarrow \\partial \\mathcal{T}^+} \\int_{\\mathcal{Y}} (\\hat{\\theta}(\\mathbf{x}) - \\theta) f_{\\mathbf{X},\\mathbf{\\Theta}}(\\mathbf{x}, \\mathbf{\\theta}) d\\mathbf{x} = 0$, where $\\hat{\\theta}(\\mathbf{x})$ is the estimator of $\\theta$ that is being considered.\nLet $\\hat{\\Theta} (\\mathbf{X})$ be an arbitrary estimator of $\\theta$ using a set of i.i.d observations $\\mathbf{X} \\triangleq {\\mathbf{X}_i}_{i=1}^{n_{iid}}$ of X, with estimator error $\\epsilon = \\theta - \\hat{\\Theta} (\\mathbf{X})$. Then, subject to Assumptions II.1, the following lower bound on the mean square error (MSE) matrix holds [40]:\n$\\text{MSE} (\\epsilon) \\triangleq \\mathbb{E}_{\\mathbf{X},\\mathbf{\\Theta}} [\\epsilon \\epsilon^T] \\succeq \\mathbf{V} \\triangleq \\mathbf{F}_{\\mathcal{B}}^{-1},$\nwhere $\\mathbf{V}$ is the Bayesian Cram\u00e9r Rao Bound (BCRB), and\n$\\mathbf{F}_{\\mathcal{B}} \\triangleq \\mathbb{E}_{\\mathbf{X},\\mathbf{\\Theta}} [\\nabla_\\theta \\log f_{\\mathbf{X},\\mathbf{\\Theta}} (\\mathbf{X}, \\mathbf{\\Theta}) \\nabla_\\theta \\log f_{\\mathbf{X},\\mathbf{\\Theta}} (\\mathbf{X}, \\mathbf{\\Theta})^T]$,\n$\\mathbf{F}_{\\mathcal{B}} = \\mathbb{E}_{\\mathbf{X},\\mathbf{\\Theta}} [\\nabla_\\theta \\log f_{\\mathbf{\\Theta}|\\mathbf{X}} (\\mathbf{\\Theta}|\\mathbf{X}) \\nabla_\\theta \\log f_{\\mathbf{\\Theta}|\\mathbf{X}} (\\mathbf{\\Theta}|\\mathbf{X})^T]$\nis the Bayesian Fisher Information Matrix (Bayesian FIM, or BFIM). The second line in (2) follows by the product rule of probability and the vanishing of $\\mathbb{E}_{\\mathbf{\\Theta}|\\mathbf{X}} [\\nabla_\\theta \\log f_{\\mathbf{\\X}}(\\mathbf{x})] = 0$. A different representation of the BFIM decomposes it [40] into the sum of two parts, the measurement FIM $\\mathbf{F}_\\mathcal{M}$ of a single observation vector X and the prior FIM $\\mathbf{F}_\\mathcal{P}$:\n$\\mathbf{F}_{\\mathcal{B}} = N_{iid} \\cdot \\mathbf{F}_\\mathcal{M} + \\mathbf{F}_\\mathcal{P} = N_{iid} \\cdot \\mathbb{E}_{\\mathbf{\\Theta}} [\\mathbf{F} (\\mathbf{\\Theta})] + \\mathbf{F}_\\mathcal{P},$\nwhere $\\mathbf{F} (\\mathbf{\\Theta})$ is the non Bayesian FIM (whose inverse is the non-Bayesian CRB) of a single observation vector X\n$\\mathbf{F} (\\mathbf{\\Theta}) \\triangleq \\mathbb{E}_{\\mathbf{X}|\\mathbf{\\Theta}} [\\nabla_\\theta \\log f_{\\mathbf{X}|\\mathbf{\\Theta}} (\\mathbf{X}|\\mathbf{\\Theta}) \\nabla_\\theta \\log f_{\\mathbf{X}|\\mathbf{\\Theta}} (\\mathbf{X}|\\mathbf{\\Theta})^T]$\nand\n$\\mathbf{F}_\\mathcal{P} \\triangleq \\mathbb{E}_{\\mathbf{\\Theta}} [\\nabla_\\theta \\log f_{\\mathbf{\\Theta}} (\\mathbf{\\Theta}) \\nabla_\\theta \\log f_{\\mathbf{X}|\\mathbf{\\Theta}} (\\mathbf{X}|\\mathbf{\\Theta})].$\nWe use the term Posterior Approach to describe the computation of the BFIM according to (2), and the term Measurement-Prior Approach to describe the computation according to (3)."}, {"title": "C. Overview of Score Matching", "content": "Score matching [23], [32], [43] is a well-known method for learning the score function of a data distribution when only having access to a set of i.i.d. samples. Various scores have been developed over the years. We begin with a brief introduction to classical score matching [23]. Specifically, the goal of score matching is to learn, using a dataset $\\mathcal{D}$ of $N_D$ i.i.d. samples, a model function (represented e.g., by a neural network) $\\mathbf{s} (\\theta; \\Omega) : \\mathbb{R}^{d_\\Theta} \\rightarrow \\mathbb{R}^{d_\\Theta}$ paramterized by vector $\\Omega$, such that $\\mathbf{s} (\\theta) = \\mathbf{s} (\\theta;\\Omega) \\approx \\nabla_\\theta \\log f_\\Theta (\\theta)$. The mismatch between the true score function and the model is formulated as the objective function\n$\\mathcal{L}^\\Omega (\\Omega) = \\mathbb{E}_{\\Theta} [|\\mathbf{s} (\\theta;\\Omega) - \\nabla_\\theta \\log f_\\Theta (\\theta) ||_2^2]$,\nwhere the expectation over $\\Theta$ can be replaced by an empirical mean over the samples in $\\mathcal{D}$.\nWe wish to minimize the score mismatch (6) w.r.t. $\\Omega$. Since we do not have direct access to the true score $\\nabla_\\theta \\log f_\\Theta (\\theta)$, only a set of i.i.d. samples $\\mathcal{D}$, we cannot directly minimize the objective (6). Instead, an equivalent objective function has"}, {"title": "III. LEARNED BAYESIAN CRAM\u00c9R RAO BOUND:OVERVIEW", "content": "We briefly overview the problem that the LBCRB address, and the methods to compute it. The overview in this section covers all the information that a practitioner would need to apply the proposed techniques. Detailed formulation, derivations and theoretical analysis are in later sections. Our goal is to determine the Bayesian Cram\u00e9r-Rao bound (1) in scenarios where the prior $f_{\\theta} (\\theta)$, the measurement $f_{x|\\theta} (x|\\theta)$, or both are either unknown or partially known. However, a data set\n$\\mathcal{D} = {(\\Theta_n, \\mathbf{X}_n = {\\mathbf{X}_{n,j}}_{j=1}^{M_{iid}})}_{n=1}^{N_D},$\nof $N_D$ parameter-measurement sets pairs is given, where $\\theta_n$ drawn from $f_{\\Theta} (\\Theta)$ and each $\\mathbf{x}_{n,j}$ drawn from $f_{x|\\theta} (x|\\theta_n)$. The measurement set in $\\mathcal{D}$ contains $M_{iid}$ i.i.d samples for the same value of $\\theta$. It is acceptable that $M_{iid} \\neq N_{iid}$, that is, $M_{iid}$ may differ from $N_{iid}$ defined earlier in the context of (3).\nWe propose two approaches to learn the LBCRB from $\\mathcal{D}$: the Posterior Approach; and the Measurement-Prior Approach."}, {"title": "A. Posterior Approach", "content": "In the Posterior Approach (Fig. 2a), we use the BFIM in (1), which only requires the posterior score $\\nabla_\\theta \\log f_{\\Theta|X} (\\theta|x)$, a conditional score of $\\theta$ given a measurement X. Then we use the learned conditional score to evaluate the LBCRB by replacing the expectation with an empirical mean.\n1) Score Learning: To learn $\\nabla_\\theta \\log f_{\\Theta|X} (\\theta|x)$, we suggest to use conditional score matching [15], [23], [44]. The goal is to to fit a model $\\mathbf{s}_B (\\theta|X;\\Omega)$ parameterized by $\\Omega$ (usually implemented as a neural network) to the true score function $\\nabla_\\theta \\log f_{\\Theta|X} (\\theta|x)$ by minimizing w.r.t. $\\Omega$ the discrepancy between the two expressed by the objective\n$\\mathcal{L}_B (\\Omega) = \\mathbb{E}_{\\Theta,X}||\\mathbf{s}_B (\\Theta|X; \\Omega) - \\nabla_\\theta \\log f_{\\Theta|X} (\\Theta|x) ||_2^2$\nSince we do not have direct access to $\\nabla_\\theta \\log f_{\\Theta|X} (\\Theta|x)$, only a set of i.i.d. samples $\\mathcal{D}$, we cannot directly minimize the objective (20). Similar to standard score matching, an equivalent objective function is used that does not require direct access to $\\nabla_\\theta \\log f_{\\Theta|X} (\\Theta|x)$:\n$\\mathcal{L}_B (\\Omega) = \\mathbb{E}_{\\Theta,X} [l_B (X, \\Theta; \\Omega)] = \\mathbb{E}_{\\Theta,X} [||\\mathbf{s}_B (\\Theta|X; \\Omega) ||_2^2 + 2 \\text{Tr} \\mathbb{E}_{X,\\Theta} [\\frac{d \\mathbf{s}_B (\\Theta|X; \\Omega)}{d \\Theta}]]$,\nObjective (21) is equivalent to (20) for the purpose of finding the minimizer $\\Omega^*$, in the sense that the two only differ by a constant C that is independent of $\\Omega$, i.e., $\\mathcal{L}_B (\\Omega) = \\mathcal{L}_B (\\Omega)+C$, provided that the following conditions hold. First, the boundary condition\n$\\lim_{\\theta \\rightarrow \\partial \\mathcal{T}^+} \\mathbf{s}_B (\\theta|x; \\Omega) f_{\\Theta|X} (\\theta|x) = 0, \\forall \\mathbf{x},$\nSecond, the following regularity conditions.\nAssumption IV.1.\nIV.1.1 The log-posterior $\\log f_{\\Theta|X} (\\theta|x)$ is differentiable w.r.t. $\\theta$ at all X and $\\theta \\in \\mathcal{T}$ where $f_{\\Theta,X} (\\theta,x) > 0$.\nIV.1.2 The expectation $\\mathbb{E}_{\\Theta,X} [||\\nabla \\log f_{\\Theta|X} (\\Theta)|X) ||^2]$ is finite.\nIV.1.3 The score neural network $\\mathbf{s}_B (\\theta|x; \\Omega)$ is differentiable w.r.t. $\\theta$.\nIV.1.4 The expectation $\\mathbb{E}_{\\Theta,X} [||\\mathbf{s}_B (\\Theta|X) ||^2]$ is finite.\nRemark 5. Assumptions IV.1.1 and IV.1.2 are implied by the regularity Assumptions II.1.1 and II.1.3 of the BCRB, respectively. On the other hand, Assumptions IV.1.3, IV.1.4 and the boundary condition (22) can be inherently satisfied by selecting an appropriate neural network architecture and non-linear activation function."}, {"title": "B. Measurement-Prior Approach", "content": "In this approach, illustrated in Fig. 2b, we employ the decomposition of the BFIM in (3) into two components: the prior Fisher Information Matrix (FIM), which requires only the score $\\nabla_\\theta \\log f_\\Theta (\\theta)$, and the measurement FIM, which relies on the Fisher score $\\nabla_\\theta \\log f_{X|\\Theta} (x|\\theta)$. To learn of the prior score we use the standard score matching presented in Section II, whereas for learning the measurement score, we derive a new Fisher Score Matching (FSM) objective.\nThe separation of the Bayesian score into two learned components provides several important advantages, which we highlight here, and discuss in detail later in this section.\nFirst, it enables to determine bounds for a measurement with an arbitrary number of independently and identically distributed i.i.d samples without requiring additional data or training.\nSecond, it enables to learn and use a model for the Fisher score for only a single measurement sample, reducing the complexity of the model and facilitating its training. Third, it enables to to incorporate domain knowledge about the"}, {"title": "IV. DERIVATION OF THE LBCRB", "content": "We turn now to a precise problem statement and derivation of the two proposed methods for the LBCRB.\nProblem Statement. Suppose that $f_{X} (x|\\theta)$ and $f_{\\theta} (\\theta)$ satisfy Assumptions II.1 and score matching As-sumptions IV.1 or IV.2 and II.2. Let V be the Bayesian Cram\u00e9r-Rao lower bound (BCRB) (1) on the estima-tion error of parameter $\\Theta \\in T$ from a measurement $\\mathbf{X} = {X_i}_{i=1}^{N_{iid}}$ containing $N_{iid}$ i.i.d. measurements $X_i \\sim f_{X|\\Theta} (X|\\Theta_n)$. Assume that $f_{X} (x|\\theta)$ and $f_{\\theta} (\\theta)$ are completely or partially unknown. Given a data set\n$\\mathcal{D} = {(\\Theta_n, \\mathbf{X}_n = {\\mathbf{X}_{n,j}}_{j=1}^{M_{iid}})}_{n=1}^{N_D},$\nof parameter-measurement samples that are inde-pendent and identically-distributed (i.i.d) as $\\mathbf{X}_{n,j} \\sim f_{x|\\theta} (X/\\Theta_n), \\Theta_n \\sim f_{\\theta} (\\Theta)$, obtain a learned ap-proximation LBCRB $\\mathbf{V}(\\mathcal{D})$ to V satisfying:\n$\\mathbf{V} (\\mathcal{D}) \\xrightarrow{N_D\\rightarrow\\infty} V \\quad a.s.$\nRemark 4. The data set in (9) represents an instance (re-alization) of the data set defined in Problem IV ((18)). For theoretical analysis concerning the stochastic nature of the LBCRB, we employ the random data set specified in (18).\nTo address Problem IV, we propose two approaches: (A) the Posterior Approach, which uses conditional score matching to learn the posterior score; and (B) the Measurement-Prior Approach, which learns two score functions one for the prior, and another for the measurement distribution. The Measurement-Prior Approach facilitates the incorporation of domain knowledge into the score neural network improving the representation and learning of the true score. Similar to previous works [17], [18], [22], both approaches comprise two stages of learning, and evaluation. However, as discussed"}, {"title": "V. THEORETICAL RESULTS", "content": "Here, we investigate the errors of the LBCRB due to learning error. Following the standard approach in learning theory [45, Chapter 5], we divide the learning error into two components: the approximation error and the empirical-mean error. We then examine each of these errors individually and their collective impact. In the last part, we demonstrate that the learned score neural network models are strongly consistent approximations of the true scores, and that LBCRB converges with probability 1 to the BCRB as the size of the training data set $\\mathcal{D}$ increases, providing conditions to achieve an accurate approximation.\nThe results in this section use the concept of intrinsic dimension of a matrix [46], [47] as a measure of its effective dimension:\nDefinition V.1 (Intrinsic Dimension of a Matrix). Let $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$ be a non-zero positive semi-definite square matrix. Then its intrinsic dimension is defined as:\n$\\text{intdim} (\\mathbf{A}) \\triangleq \\frac{\\text{Tr} (\\mathbf{A})}{\\|\\mathbf{A}\\|_2}$\nThe intrinsic dimension of a matrix can be understood as quantifying the number of dimensions by accounting for the spectral intensity over all dimensions. From the definition of intrinsic dimension and the inequality $1 \\leq \\text{intdim}(\\mathbf{A}) \\leq \\text{rank} (\\mathbf{A}) \\leq d$, we observe that $\\text{intdim} (\\mathbf{A}) = d$ when all eigenvalues are identical and nonzero, whereas $\\text{intdim} (\\mathbf{A}) = 1$ when A has rank one. In addition, the intrinsic dimension is more robust to small perturbations than the matrix rank [47]."}, {"title": "A. Approximation error", "content": "We evaluate the approximation error of both approaches, demonstrating that the score matching objective that expresses the score mismatch provides an upper bound on the learned Fisher Information Matrix (FIM) errors.\nTheorem V.1 (LBCRB Approximation Error: Posterior Ap-proach). Let $SREB \\triangleq \\frac{\\|\\mathbf{F}_B - \\mathbf{F}_B\\|_2}{\\|\\mathbf{F}_B\\|_2}$ be the relative approximation error of the Bayesian score and let $d_B = \\text{intdim} (\\mathbf{F}_B)$.\nSuppose that Assumptions II.1, IV.1 hold and $d_B \\cdot SREB^2 < 0.16$. Then:\n$\\text{RE} (\\mathbf{F}_B - \\mathbf{F}_B)\\|_2 \\leq 2.4 \\sqrt{d_B \\cdot SREB^2}.$\nTheorem V.2 (LBCRB Approximation Error: Measuremen-t-Prior Approach). Let $SREM \\triangleq \\frac{C}{\\text{Tr}(\\mathbf{F}_M)} \\|\\nabla \\log f_{\\theta|x} (\\theta|x)\\|_2$ and $SREP \\triangleq \\frac{C}{\\text{Tr}(\\mathbf{F}_P)} \\|\\nabla \\log f_{\\theta} (\\theta)\\|_2$ be the relative errors in learning the Fisher and prior scores, respectively and let $d_M = \\text{intdim} (\\mathbf{F}_M)$ and $d_P = \\text{intdim} (\\mathbf{F}_M)$. Suppose that Assumptions II.1, II.2, and IV.2 hold and $d_M SREM^2 < 0.16$, $d_P SREP^2 < 0.16$. Then:\n$\\text{RE} (\\mathbf{F}_{MP} - \\mathbf{F}_B)\\|_2\\leq 2.4 (\\frac{\\| N_{iid} \\mathbf{F}_M \\|_2}{\\| \\mathbf{F}_B \\|_2} \\sqrt{d_M} SREM + \\frac{\\| \\mathbf{F}_P \\|_2}{\\| \\mathbf{F}_B \\|_2} \\sqrt{d_P} SREP)$.\nTheorem V.1 and V.2 (proved in Appendix C) quantify the relationship between the score matching optimization objective, (or equivalently, the relative error in approximating the score vector), and the approximation error of the corresponding FIM. They show how a reduction in the objective (smaller score approximation error) translates to a smaller learning error for the FIM. Moreover, the tightest bound for a selected neural network architecture is achieved when $\\Omega = \\Omega^*$ the NN parameters that minimize the objective $\\mathcal{L}$. Finally, the assumptions $\\text{intdim} (\\mathbf{F}_B) \\cdot SREB^2 \\leq 0.16$, $\\text{intdim} (\\mathbf{F}_M) \\cdot SREM^2 \\leq 0.16$ and $\\text{intdim} (\\mathbf{F}_P) \\cdot SREP^2 \\leq 0.16$ introduced in Theorems V.1 and V.2 can be satisfied by minimizing the score objectives $\\mathcal{L}_B$, $\\mathcal{L}_F$, and $\\mathcal{L}_p$.\nComparing between the theoretical results on the ap-proximation error of the two approaches reveals that the Measurement-Prior Approach will have an advantage in cases where the measurement FIM is the dominant part, and some additional information can be used in the Fisher (Measure-ment) score model, e.g. the reuse of i.i.d. samples, or a model-informed score neural network."}, {"title": "B. Empirical Mean Error", "content": "In this section", "namely": "nAssumption V.1 (Score Function Bounds). For $\\Omega^*$", "that": "nV.1.1 $||s^*_B (\\theta|X)||_2 \\leq c_B$ $\\forall x_n", "Error": "Posterior Ap-proach). Suppose that Assumptions II.1", "u)$": "n$\\text{RE"}, "frac{\\| \\mathbf{F}_B - \\mathbf{F}_B \\|_2}{\\| \\mathbf{F}_B \\|_2} \\leq 1.5 \\sqrt{\\frac{K_B^{(e)}}{N_D}}$.\nFurthermore, define $K_B^{(s)} \\triangleq (\\frac{c_B}{\\|\\mathbf{F}_B\\|_2} + 1) (\\log (1 + 2d_B) + 0.52)$. Then for any $N_D > K_B^{(e)}$ the relative empirical mean error is bounded in expectation by\n$\\mathbb{E}_D \\text{RE} \\leq \\sqrt{\\frac{6+1.5\\sqrt{2 \\log (1 + 2d_B) + 0.52}}{\\sqrt{N_D}}}$.\nTheorem V.4 (LBCRB Empirical Mean Error: Measure-ment-Prior Approach). Suppose that Assumptions II.1, II.2, IV.2 and the bounded score conditions V.1.2 and V.1.3 hold. Let $d_{MP} = \\text{intdim} (\\mathbf{F}_{MP})$, and define $N^{(e)}_{MP} \\triangleq \\frac{4}{\\xi^2} (u + \\log (8d_{MP}))$. Define $K^{(e)}_{MP} \\triangleq \\frac{d_M + d_P}{\\frac{N_{iid}}{\\text{Tr}(\\mathbf{F}_M)} + \\frac{1}{\\text{Tr}(\\mathbf{F}_P)}} (\\frac{c_M + c_P}{\\sqrt{N_{iid}} \\|\\mathbf{F}_M\\|_2 + \\|\\mathbf{F}_P\\|_2} + 1)^2$. Then for any $u > 0$ and $N_D > N_{MP}^{(e)}$, the following bound holds with probability of at least $1 - \\exp (-u)$:\n$\\text{RE} \\leq 1.5 \\sqrt{\\frac{K_{MP}^{(e)}}{N_D}}$.\nFurthermore, define $K_{MP}^{(s)} \\triangleq \\frac{d_M + d_P}{\\frac{N_{iid}}{\\text{Tr}(\\mathbf{F}_M)} + \\frac{1}{\\text{Tr}(\\mathbf{F}_P)}} (\\log(1 + 2d_{MP}) + 0.52)$. Then for any $N_D > K_{MP}^{(e)}$ the relative empirical mean error is bounded in expectation by\n$\\mathbb{E}_D \\text{RE} \\leq \\sqrt{\\frac{6+1.5\\sqrt{2 \\log (1 + 2d"]}