{"title": "On Enhancing Network Throughput using Reinforcement Learning in Sliced Testbeds", "authors": ["Daniel Pereira Monteiro", "Lucas Nardelli de Freitas Botelho Saar", "Larissa Ferreira Rodrigues Moreira", "Rodrigo Moreira"], "abstract": "Novel applications demand high throughput, low latency, and high reliability connectivity and still pose significant challenges to slicing orchestration architectures. The literature explores network slicing techniques that employ canonical methods, artificial intelligence, and combinatorial optimization to address errors and ensure throughput for network slice data plane. This paper introduces the Enhanced Mobile Broadband (eMBB)-Agent as a new approach that uses Reinforcement Learning (RL) in a vertical application to enhance network slicing throughput to fit Service-Level Agreements (SLAs). The eMBB-Agent analyzes application transmission variables and proposes actions within a discrete space to adjust the reception window using a Deep Q-Network (DQN). This paper also presents experimental results that examine the impact of factors such as the channel error rate, DQN model layers, and learning rate on model convergence and achieved throughput, providing insights on embedding intelligence in network slicing.", "sections": [{"title": "1. Introduction", "content": "Disruptive applications, such as 8K video streaming, Virtual Reality (VR), and Augmented Reality (AR), had led to an increased demand for high network throughput [Khan et al. 2022]. Additionally, other application families, including remote surgery, smart factories, and autonomous vehicles, require low-latency and high-reliability connectivity [Aripin et al. 2023]. Ensuring the compatibility between these conflicting requirements within a physical network is a significant challenge for both management and resource orchestration [Khan et al. 2022]. To address this, various advances have been made in network slicing, virtualization, programmability, security, and Artificial Intelligence (AI), especially in mainstream mobile networks, such as beamforming and energy-aware solutions [Khan et al. 2022, Moreira et al. 2023, Brilhante et al. 2023].\n\nThe literature has explored approaches for performing network slicing that can handle errors in the underlying channel while ensuring throughput using canonical techniques such as artificial intelligence, and combinatorial optimization [Ojijo and Falowo 2020, Liu et al. 2023]. Some of these techniques involve intervention in the link [Moreira et al. 2021], while others involve intervention in the communicating entity, such as those based on Transmission Control Protocol (TCP) [Li et al. 2019b,"}, {"title": "2. Related Work", "content": "Recent efforts, such as [Zhang et al. 2019], have sought to improve the Multipath Transmission Control Protocol (MPTCP) protocol through reinforcement learning techniques. Using asynchronous training, this study allows parallel execution of packet scheduling, data collection, and neural network training. The goal was to optimize scheduling in real time by employing an asynchronous algorithm for neural training.\n\nThe work proposed by [Li et al. 2019a] aimed to improve network efficiency using the SmartCC algorithm. This algorithm employs reinforcement learning techniques to improve the congestion window management. SmartCC uses an asynchronous reinforcement learning mechanism to acquire a set of congestion rules. While [Tang et al. 2018] presented a traffic prediction algorithm based on deep learning. This algorithm aims to anticipate the workload and network congestion. After the prediction, partial channel allocation based on deep learning is performed to prevent possible congestion by assigning appropriate channels.\n\nThe study carried out by [Beig et al. 2018] examined mobile users using the MPTCP protocol, with the aim of optimizing congestion control in heterogeneous networks. This study proposes an algorithm based on Q-learning (QL) to improve throughput, with the aim of maximizing throughput. [Vieira and Garcez 2011] developed a mathematical expression to calculate the probability of data loss on the servers. This expression is used to condition the estimation of the probability of data loss in analog servers that have a finite buffer and receive time-dependent multifactor flows."}, {"title": "3. Evaluation Method", "content": "This study examines the influence of various factors, including the number of layers in the DQN model, percentage of channel error, and learning rate, on the convergence time and data transmission rate (throughput) between two applications. The study employs metrics such as congestion window size, packet size, total number of bytes sent, average, total number of recognized segments, and network throughput. The aim is to optimize the current throughput on a link generated by the NS3 simulator, focusing on the impact of the eMBB-Agent on the search space, as shown in Fig. 1.\n\nWe used Network Simulator 3 (NS3) to create a network topology and simulate the transmission of packets between two File Transfer Protocol (FTP) applications, as shown in Fig. 1. We set the bandwidth between the hots to 10 Mbps and 2 Mbps between the routers to induce congestion, as illustrated in Fig. 2. We used configurations NN-2 containing two hidden layers, NN-4 with four hidden layers, and NN-8 with eight hidden layers.\n\nThrough partial factorial combination, that is, we take combinations two-by-two and carry out experiments on the levels of variations to verify the influence of these variations. Each combination was run 10 times to generate a statistical sample. We measured the error rate in packets in scenarios of 0% and 20%, and varied the learning rate hyper-parameter to 0.01 and 0.001. The parameters of the combinations performed are listed in Table 2."}, {"title": "4. Results and Discussion", "content": "The central objective of the experiments was to analyze the behavior of the network in response to different configurations of Neural Networks (NNs) by using the DQN algorithm with the NS3-GYM [Gawlowicz and Zubow 2018] tool. With this technology, it has become possible to combine RL algorithms and interventions in the control mechanisms of communication networks by using NS3. In this study we considered NS3-GYM online.\n\nDuring the simulation, a progressive increase in the congestion window was observed, which was directly related to a significant increase in the rewards obtained by the eMBB-Agent. According to Fig. 3, advantageous network flow rates were identified with the implementation of the Neural Network (NN)-2 model containing two layers. In detail, Fig. 3a, 3b and 3c provide a visual representation of the algorithm over 200 steps.\n\nThus, it is possible to verify that the larger the size of the cwnd variable in a smaller number of epochs, the faster eMBB-Agent increases the communication throughput.\n\nThe NN configuration, shown in Fig. 3a, 3b and 3c exhibit a progressive increase in throughput with an increasing congestion window cwnd based on decisions and receiving rewards for correct choices. Three models (NN-2, NN-4, and NN-8) were analyzed, and NN-4 presented a lower average flow rate considering NN-2 and NN-8. Subsequently, NN-8 manifested the second-worst throughput. This behavior is attributed to the time required to train a DQN with more layers, given the time sensitivity in the experimental scenario.\n\nFig. 4a highlights the performance of the Q-Learning algorithm in three configurations: NN-2, NN-4 and NN-8, representing the average throughput of the network slice in an error-free and with error in slicing. NN-2, with an error-free demonstrates the best performance, followed by NN-4, while NN-8 displays lower performance, with a lower Average Network Throughput. We associate this with its complexity, which requires more computational resources owing to its deep neural network structure.\n\nFig. 4b shows the convergence times of the DQN algorithm for three different architectures: NN-2, NN-4, and NN-8. As can be seen, in an error-free channel, algorithm NN-4 exhibits the best performance, with a convergence time 20.09% lower than NN- 2 and 32.99% lower than NN-8, respectively.\n\nAlternatively, in a channel with 20% error induction, NN-2 reaches convergence, that is, fullness in the second variable faster. Thus, the convergence time for NN-2 was 10.34% less than that of NN-4 and 15.00% less than that of NN- 8. We associate this better performance of the simpler NN with better training time.\n\nFinally, we investigate the effect of the error rate, learning rate, and RL algorithm on network throughput through regression. Tables 3 and 4 present the variables considered, their estimated impacts, associated coefficients, standard errors, and T and P-values, providing information about the relationships between Algorithm DQN, error rate, learning rate, and network throughput."}, {"title": "5. Concluding Remark", "content": "The analysis of congestion algorithms with various combinations of artificial NN demonstrated an inverse correlation between the number of layers and the efficiency of optimizing the flow in communication networks, as indicated by the data from linear regression analysis. This suggests that an increase in network complexity leads to a decrease in network throughput. The study found that neither the network error rate nor the learning rate had a statistically significant effect on the network throughput.\n\nThis study struggled with some constraints, one of which was that the analysis was carried out in a simulated environment using Network Simulation Library 3 (NS3). To overcome this limitation, we suggest that future research explore the functionality of eMBB-Agent in a real-world setting, in which variables can be manipulated to assess its impact in more complex and dynamic situations. This provided a more accurate and comprehensive understanding of the practical implications of the findings across various operational scenarios. In addition, we suggest the optimization of additional parameters and evaluation of latency and reliability to further improve network performance."}]}