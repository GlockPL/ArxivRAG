{"title": "A Novel Framework For Text Detection From Natural Scene Images With\nComplex Background.", "authors": ["Basavaraj Kaladagi", "Dr. Jagadeesh Pujari"], "abstract": "Recognizing texts from camera images is a\nknown hard problem because of the difficulties in text\ndetection from the varied and complicated background. In\nthis paper we propose a novel and efficient method to\ndetect text region from images with complex background\nusing Wavelet Transforms. The framework uses Wavelet\nTransformation of the original image in its grayscale\nform followed by Sub-band filtering. Then Region\nclustering technique is applied using centroids of the\nregions, further Bounding box is fitted to each region thus\nidentifying the text regions.\nThis method is much sophisticated and efficient\nthan the previous methods as it doesn't stick to a\nparticular font size of the text thus, making it generalized.\nThe sample set used for experimental purpose consists of\n50 images with varying backgrounds. Images with edge\nprominence are considered. Furthermore, our method\ncan be easily customized for applications with different\nscopes.", "sections": [{"title": "1. Introduction", "content": "In recent years, we have created many still-\nimages and videos using digital cameras, digital\ncamcorders and cellular-phone cameras. Texts in these\nimages contain very important information about locations\nand road signs. If we could recognize these texts\naccurately in real time, we can design artificial vision\nsystems for assisting auto-navigation of vehicles and\nvision impaired, video indexing and retrieval systems, text\ntranslation systems, and spam-mail filtering systems, and\nso on.\nThe research on Text Detection from Natural Scene\nImages, towards a System for Visually Impaired Persons\n[1] proposing a system that reads the text encountered in\nnatural scenes with the aim to provide assistance to the\nvisually impaired persons. Methods are proposed which\npresent a novel image operator that seeks to find the value\nof stroke width for each image pixel, and demonstrate its\nuse on the task of text detection in natural images [2].\nDetection of text in color images of complex colored\nbackground is done through an efficient automatic text\ndetection method-fusing multi-feature [3]. A low\ncomplexity method for detection of text regions in natural\nimages which is designed for mobile applications (e.g.\nunmanned or hand-held devices) in which computational\nand energy resources are limited, it focuses on the\ndetection of text on signs and it relies on the properties of\nthe background of the text region, as opposed to the text\nitself [4]. Text detection from natural scene images can\nalso be done based on the intensity information of the\nimages. This method is composed of gray value stretching\nand binarization by an average intensity of the image. It is\nappropriate to extract texts from complex backgrounds\n[5]. A new method for text detection and recognition in\nnatural scene images is presented in which detection\nprocess, color, texture, and OCR statistic features are\ncombined in a coarse-to-fine framework to discriminate\ntexts from non-text patterns. In this approach, color\nfeature is used to group text pixels into candidate text\nlines. Texture feature is used to capture the \"dense\nintensity variance\" property of text pattern. Statistic\nfeatures from OCR (Optical Character Reader) results are\nemployed to further reduce detection false alarms\nempirically. After the detection process, a restoration\nprocess is used [6]. In one of the methods text detection is\ndone using multiscale texture segmentation and spatial\ncohesion constraints, then cleaned up and extracted using\na histogram-based binarisation algorithm [7]. A frame\nwork is proposed to detect text using text intensity and\nshape features, this framework uses the Niblack algorithm\nto threshold images and group components into regions\nwith commonly used geometry features. The intensity\nfilter considers the overlap between the intensity\nhistogram of a component and that of its adjoining area.\nFor non-text regions, it is found that this overlap is large,\nand hence can prune out components with large values of\nthis measure. The shape filter, on the other hand, deletes\nregions whose constituent components come from a same\nobject, as most words consist of different characters [8]."}, {"title": "2. Proposed Method", "content": "In this section, we present a method to extract\ntexts in natural scene images using Haar discrete wavelet\ntransform (Haar DWT). The edge detection is\naccomplished by using 2-D Haar DWT and some of the\nnon-text edges are removed using thresholding. Although\nthe color component may differ in a text region, the\ninformation about color does not help extracting texts\nfrom images. If the input is a gray-level image, the image\nis processed directly starting at discrete wavelet transform.\nIf the input is RGB image, it is converted to grayscale\nimage and processed.\nThe discrete wavelet transform is a very useful\ntool for signal analysis and image processing, especially in\nmulti-resolution representation. Two-dimensional discrete\nwavelet transform (2-D DWT) decomposes an input\nimage into four sub-bands, one average component (LL)\nand three detail components (LH, HL, HH) as shown in"}, {"title": "2.1 Proposed Method for Text Detection.", "content": "In this subsection, we use morphological\noperators and the logical AND operator to further\nremoves the non-text regions. In text regions, vertical\nedges, horizontal edges and diagonal edges are mingled\ntogether while they are distributed separately in non-text\nregions. Since text regions are composed of vertical\nedges, horizontal edges and diagonal edges, we can\ndetermine the text regions to be the regions where those\nthree kinds of edges are intermixed. Text edges are\ngenerally short and connected with each other in different\norientation. Thus we apply logical AND operator to\nhorizontal, vertical and diagonal sub-band image set to get\nthe region of interest (ROI). The figure 2.1.1 shown below\nshows horizontal, vertical and diagonal pixels and the text\nregion after applying AND operation to the sub-band\nimages.\nWhile applying haar wavelet transform, sigma\nvalue decides the amount of filtering done i.e. as the value\nincreases the amount of non-text but textured region\npresent in the image decreases thus pruning out the non-\ntext region."}, {"title": "2.1.1 A Proposed method for Filtering", "content": "Even after this much of filtering there is a\nprobability of getting non-text region which have textured\nfeatures appearing in the image. To filter such background\npixels a new method is proposed. Here we scan through\nthe image and record the rows containing white pixel\nconcentration above a particular threshold. These pixels\nform the part of text region after filtering."}, {"title": "2.2 Clustering and Region Growing", "content": "The co-ordinates of the pixels obtained after\nregion filtering are subjected to clustering. Here we use\nsubtractive clustering to extract cluster centers.\nThe subtractive clustering method assumes each\ndata point is a potential cluster center and calculates a\nmeasure of the likelihood that each data point would\ndefine the cluster center, based on the density of\nsurrounding data points. The algorithm does the\nfollowing:\n\u2022\nSelects the data point with the highest potential\nto be the first cluster center\n\u2022\nRemoves all data points in the vicinity of the first\ncluster center in order to determine the next data\ncluster and its center location\n\u2022\nIterates on this process until all of the data is\nwithin the vicinity of a cluster center\n\u2022\nThe subtractive clustering method is an extension\nof the mountain clustering method proposed by\nR. Yager."}, {"title": "2.2.1 Clustering Regions.", "content": "Once region are divided into clusters, the process\nof growing region is done using the cluster center of each\nregion, the algorithm is as follows:\nREGION_GROWING(Cluster_Centroids,\nNumber Of Clusters)\nFor every c \u2208 Cluster_Centroids\nPut a 2*2 Rectangle around c\nNew value=Calculate number of\npixels belonging to text\npercentIncrease=(NewValue-\nOldValue)*100/ NewValue;\nif percentIncrease< 5\nDraw a BoundingBox across\nthat region;\nbreak;\nReturn;\nelse\nOldValue=NewValue;\nEnd if\nEnd for"}, {"title": "2.3 Thresholding", "content": "Once the text region is extracted from the image\nusing the bounding box fitted to the text region, each\nregion is subjected to thresholding, thresholding is done\nusing Ostu's thresholding method which chooses the\nthreshold to minimize the intraclass variance of the black\nand white pixels."}, {"title": "3. Character Separation", "content": "Once the text region is threshold, the characters\nhave to be separated before sending them to OCR for\nrecognition, as there is a little gap between every character\non the text region, characters are separated using the\nsimple and efficient Connected Component algorithm.\nComponents are considered to be 4-connected. Connected\nComponent is implemented so as to find the connectivity\nbetween white pixels. This leads to a problem, if the\nimage supplied has black text with white background, to\novercome this a strategy is developed to check the\nbackground of image which is as follows:\n1. Put a 3 *3 rectangle at the corner of the image.\n2. If the background is white and the characters are\nin black then we have to change the background\ncolor to black. Now we can label the objects by\napplyingsimple connected-component algorithm.\n3. If the background is white, then complement of\nimage is taken which is then subjected to\nconnected- component algorithm.\n4. Now each connected-component represents a\ncharacter which is then supplied to OCR for\nrecognition."}, {"title": "4. Conclusion", "content": "In this paper we have presented a novel\nframework to detect text region from natural scene images\nwith complex background with a fixed font style.\nThe method uses discrete wavelet transform to get the\nsub-bands and region of interest detection is done using a\nProposed method, which is based on the concentration of\ntexture features, got by applying morphological AND\noperator. This method has a good efficiency for images\ncontaining objects with less texture properties."}]}