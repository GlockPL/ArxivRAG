{"title": "Generative AI and Empirical Software Engineering: A Paradigm Shift", "authors": ["Christoph Treude", "Margaret-Anne Storey"], "abstract": "The widespread adoption of generative AI in software engineering marks a paradigm shift, offering new opportunities to design and utilize software engineering tools while influencing both developers and the artifacts they create. Traditional empirical methods in software engineering, including quantitative, qualitative, and mixed-method approaches, are well established. However, this paradigm shift introduces novel data types and redefines many concepts in the software engineering process. The roles of developers, users, agents, and researchers increasingly overlap, blurring the distinctions between these social and technical actors within the field.\nThis paper examines how integrating AI into software engineering challenges traditional research paradigms. It focuses on the research phenomena that we investigate, the methods and theories that we employ, the data we analyze, and the threats to validity that emerge in this new context. Through this exploration, our goal is to understand how AI adoption disrupts established software development practices that creates new opportunities for empirical software engineering research.", "sections": [{"title": "I. INTRODUCTION", "content": "The software engineering academic and industry community is undergoing a significant transformation due to the rapid development and adoption of generative AI technologies. Many consider generative AI to be the most disruptive innovation in software engineering since the Internet [1], with the potential to fundamentally change the way software is developed, evolved, and used. Others take a more conservative stance, but still acknowledge that the adoption of generative Al is driving critical and substantive changes in software development practices [2]. These changes include cascading effects on delivery speed, software quality, and the developer experience.\nBeyond its impact on software engineering practices, generative AI is redefining the roles of developers, users, and researchers. The boundaries between these actors are becoming increasingly blurred, opening up opportunities for novel approaches to designing, building, and studying software systems. Consequently, in this paper, we explore how the integration of generative AI into the software development lifecycle reshapes and challenges the empirical methods traditionally employed in software engineering research. Quantitative, qualitative, and mixed method approaches must now account for new data sources, dynamic workflows, and redefined notions of the inputs to and the outputs from the software engineering process.\nIt is not just the empirical methods that are disrupted, but also the nature of the research questions posed are changing. Understanding the implications of technological advances on research is a well-established area of concern in media studies and digital anthropology [3]. For example, Marshall McLuhan [4] famously proposed four laws to analyze the impact of new technologies. Storey et al. [1] describe how these laws can be applied to generative AI in software engineering:\n\u2022 What does generative AI enhance or amplify? Gener-ative AI amplifies various software engineering tasks [5], such as automating the writing of low-level code, which previously required significant human effort.\n\u2022 What does the technology make obsolete? Traditional platforms such as Stack Overflow are seeing reduced use as generative AI provides instant coding assistance and solutions [6], potentially reducing the reliance on community-driven resources.\n\u2022 What does the technology retrieve that had been obsolesced earlier? Generative AI reintroduces the use of chat interfaces for technical assistance [7], which were not widely utilized by developers until the advent of conversational AI models.\n\u2022 What does the technology reverse or flip into when pushed to extremes? If reliance on generative AI continues to grow, foundational skills, such as learning programming from first principles, may be neglected or undervalued by new learners who overly depend on AI-generated solutions [8].\nThese laws provide a framework for understanding how generative AI disrupts traditional workflows while creating new opportunities for software engineering research. However, these disruptions also raise fundamental questions about how researchers should adapt their approaches to remain relevant and impactful. The data sources we use in our research are evolving and we must prepare for additional disruptive changes, including new phenomena, research methods, theories, and threats to validity.\nThis paper explores how the adoption of generative AI is reshaping empirical software engineering research. Specifi-"}, {"title": "II. THE RESEARCH PHENOMENONA WE STUDY AND THE QUESTIONS WE ASK", "content": "The adoption of generative AI is fundamentally transforming the landscape of software engineering research. Mustafa Suleyman, in his book \"The Coming Wave\", describes generative AI as a \u201cgeneral-purpose technology\u201d [10], comparable to foundational innovations such as fire, the wheel, and the computer. These technologies have historically triggered \u201cCambrian explosions\u201d of innovation, fundamentally reshaping how humans live, work, and play. Similarly, generative Al's capabilities, when combined with other disruptive technologies such as synthetic biology and augmented reality, hold the potential to drive unprecedented transformations.\nLatour's actor-network theory [9] emphasizes that innovation brings uncertain boundaries and fluctuating entities, making it critical for researchers to \"follow the actors\" and observe how they redefine collective existence. As generative AI becomes integrated into software engineering, traditional constructs such as \u201cdeveloper\u201d, \u201csource code\u201d, and \u201cartifact\" are becoming more fluid, requiring empirical research to adapt to these transformations.\nThe roles of developers, tools, and end users are particularly affected. Developers now use AI tools to generate code, shifting their focus from writing code to designing and refining solutions. End users, empowered by AI, are increasingly taking on development tasks, further blurring the boundary between the developer and the user. Generative AI tools also actively contribute to the creation of artifacts, such as commit messages, bug reports, and UML diagrams, challenging the traditional distinction between tools and collaborators.\nAs discussed in the introduction, McLuhan's four laws of media [4], as interpreted by Storey et al. [1], offer a valuable framework for analyzing these changes. The evolving definitions of \"developer\" and \"software\" further complicate these dynamics. Peter Naur's perspective [11] highlights that software is not merely code but theories in developers' minds about the problem being solved and how it evolves. Expanding interaction methods, such as natural language prompts, sketches [12], and gestures in virtual or augmented reality environments [13], challenge traditional notions of \"coding\" and \"software\".\nAs Latour underscores, when innovations proliferate, we must be ready to observe new actors and reconsider the constructs we use to conceptualize them. For empirical software engineering researchers, this means studying emergent phenomena such as the integration of AI tools into the inner development loop and their impact on team dynamics, the evolving relationship between developers and artifacts as AI increasingly mediates their creation, and the use of synthetic data generated by AI during interactions, which redefines our understanding of developer behavior.\nThe implications of these transformations extend beyond technical workflows. For example, as generative AI tools learn from the traces of their interactions, they may inadvertently introduce biases or amplify existing inequities. Researchers must remain vigilant in identifying and addressing these unintended consequences.\nThe adoption of generative AI is not merely an enhancement of existing practices but a fundamental reshaping of the phenomena we study. By asking the right questions and adapting our conceptual frameworks, we can ensure that empirical software engineering research remains relevant and impactful in this rapidly evolving landscape.\nTo address these evolving phenomena and guide future research, we recommend:\n\u2022 Continuously refine the definitions of key constructs such as \"developer\", \"artifact\", and \"coding\" to reflect their evolving roles in AI-mediated environments.\n\u2022 Focus on questions that explore the unique dynamics of human-AI collaboration, such as how AI tools influence creativity, collaboration, and knowledge transfer.\n\u2022 Conduct longitudinal research to understand how AI adoption shapes software engineering practices, team dynamics, and skill development over time.\n\u2022 Collaborate across disciplines and engage with diverse communities to uncover novel insights into the socio-technical impacts of generative AI."}, {"title": "III. RESEARCH METHODS AND THEORIES", "content": "The impact of generative AI presents challenges to the traditional methods and theories used in empirical software engineering research. Existing approaches must evolve to capture the new socio-technical dynamics introduced by AI while addressing the complexity and scale of emerging phenomena.\nEmpirical software engineering research has traditionally relied on a combination of quantitative, qualitative, and mixed-method approaches to analyze software-related artifacts and processes. While these methods remain foundational, generative AI introduces new challenges:\n\u2022 Quantitative Methods: The non-deterministic nature of AI output complicates traditional statistical analyses and causal inference. Researchers must account for variability in the results and the rapid evolution of AI models.\n\u2022 Qualitative Methods: The blurring of socio-technical boundaries makes it difficult to isolate human behavior from AI-mediated processes. Established methods for"}, {"title": "IV. THE DATA WE STUDY", "content": "Generative AI has transformed not only the processes and tools of software engineering but also the types of data available for empirical research. The important role of leveraging engineering data has been well recognized for several decades. In the 1996 editorial for the first issue of the Empirical Software Engineering journal, Harrison and Basili defined the discipline as \u201cthe study of software-related artifacts for the purpose of characterization, understanding, evaluation, prediction, control, management, or improvement through qualitative or quantitative analysis\u201d [20]. Almost 30 years later, this definition is fully realized. In 2022, Abou Khalil and Zacchiroli [21] conducted a meta-analysis of artifact mining in empirical software engineering, identifying over 3,000 papers that mined artifacts such as bug data, code reviews, commit metadata, forums, mail data, source code, test data, and UML diagrams. They noted common combinations of mined artifacts and purposes, including bug prediction and source code classification.\nRevisiting this list of data artifacts in the generative AI era, it is evident that AI now generates many of these artifacts:\n\u2022 Bug Reports: Tools such as Buglistener automatically generate bug reports from live chats [22].\n\u2022 Code Review Comments: LLaMA-Reviewer uses large language models to automate code review comments [23]."}, {"title": "V. RECONSIDERING THREATS TO VALIDITY", "content": "The adoption of generative AI in software engineering introduces new threats to validity that challenge established practices in empirical research. These threats stem from the dynamic, non-deterministic nature of AI systems, the evolving constructs we study, and the reliance on AI-generated data and tools in research processes.\nConstruct validity refers to the extent to which a study measures what it claims to measure. Generative AI disrupts traditional constructs in software engineering research. Concepts such as \u201cdeveloper\u201d, \u201csource code\u201d, and \u201cartifact\u201d are evolving as AI tools take on active roles in software development. For instance, when natural language prompts replace programming languages, the definition of \u201ccoding\u201d becomes ambiguous. As AI tools blur the boundaries between social and technical phenomena, traditional constructs may no longer capture the full complexity of the systems being studied. McLuhan's tetrad [4] provides a framework for understanding how these constructs evolve by analyzing what AI enhances, obsolesces, retrieves, and reverses.\nInternal validity refers to the degree to which a study can establish causal relationships. Generative AI complicates this process in several ways. The inherent variability in AI-generated output makes it difficult to replicate studies and establish causality. For example, the same prompt can yield different results across executions, even within the same model. Frequent updates to generative AI models further complicate longitudinal analyses, as studies conducted on older versions may lose relevance as the models evolve and their behavior changes.\nExternal validity refers to the generalizability of the study findings. The unique characteristics of generative AI introduce new challenges in this regard. Studies focusing on proprietary or closed-source models (e.g., OpenAI's GPT) may produce findings that are not applicable to other models or contexts. Similarly, research conducted in controlled settings may not capture the complexities of real-world scenarios, where AI tools interact with a diverse range of users and systems. The rapid adoption of generative AI underscores the need for studies that reflect the dynamic environments in which these tools are applied.\nGenerative Al models are trained on large datasets that reflect societal biases, which can distort empirical findings. Research has shown that generative AI can perpetuate gender and cultural biases [32], [33]. For example, AI-generated code reviews or documentation may inadvertently include biased language or assumptions. The use of biased AI-generated data in research raises ethical concerns, particularly when such data informs decision-making or trains future Al systems.\nThe use of generative AI in empirical research introduces additional threats. When AI is used to code qualitative data or simulate users, the biases inherent in the underlying models can influence the findings. Furthermore, many AI tools function as \"black boxes\", making it difficult to discern how their output was generated. This lack of transparency complicates the interpretation of the results and hinders the reproducibility of the studies. Researchers who rely heavily on AI tools may inadvertently overlook critical nuances or context that would have been evident in manual analyses.\nTo address these threats, researchers must adopt strategies that ensure rigor and reliability:\n\u2022 Whenever possible, researchers should prioritize open source models to enable greater transparency and control, reduce dependence on proprietary tools, and improve replicability.\n\u2022 Iterative and adaptive research designs can accommodate the rapid evolution of AI models and the dynamic nature of AI-generated outputs.\n\u2022 Researchers should regularly review and refine their constructs to ensure that they remain relevant in the context of evolving phenomena.\n\u2022 Mixed methods [14], [41] are particularly well suited to address the complex and emergent nature of AI-mediated phenomena and should be applied with care.\n\u2022 Researchers should critically evaluate assumptions and biases embedded in AI tools and transparently report their limitations.\nBy proactively addressing these threats, empirical software engineering researchers can maintain the validity and reliability of their findings in the era of generative AI."}, {"title": "VI. FINAL THOUGHTS", "content": "Generative Al is fundamentally reshaping empirical software engineering research, presenting both opportunities and challenges. Its integration into the software development lifecycle is not simply enhancing existing practices but driving radical transformations that require researchers to rethink their approaches to data, methods, and theoretical frameworks.\nThis paper has outlined how empirical software engineering must evolve to address these changes. Researchers must reassess the phenomena they study, redefining constructs such as \"developer\" and \"artifact\" in light of active participation of AI. Research methods must adapt to the dynamic nature of AI-mediated workflows, incorporating interdisciplinary perspectives, and utilizing mixed-method designs. New data sources, including AI-generated artifacts and synthetic datasets, should be embraced, but with attention to challenges such as bias and interpretability. In addition, adaptive study designs, open source tools, and critical assessments of AI limitations are essential to mitigate novel threats to validity.\nThe adoption of generative AI is accelerating, and its impact on software engineering research is likely to expand in complexity and scope. Although its immediate benefits, such as increased productivity and automation, are clear, the broader implications for the field demand careful consideration. Over-reliance on AI could undermine foundational skills, and biases in AI-generated data risk perpetuating inequities."}]}