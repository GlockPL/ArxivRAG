{"title": "ADVANCING ENTERPRISE SPATIO-TEMPORAL FORECASTING APPLICATIONS: DATA Mining MEETS INSTRUCTION TUNING OF LANGUAGE MODELS FOR MULTI-MODAL TIME SERIES ANALYSIS IN LOW-RESOURCE SETTINGS", "authors": ["Sagar Srinivas Sakhinana", "Geethan Sannidhi", "Chidaksh Ravuru", "Venkataramana Runkana"], "abstract": "Spatio-temporal forecasting is crucial in transportation, logistics, and supply chain management. However, current methods struggle with large, complex datasets. We propose a dynamic, multi-modal approach that integrates the strengths of traditional forecasting methods and instruction tuning of small language models for time series trend analysis. This approach utilizes a mixture of experts (MoE) architecture with parameter-efficient fine-tuning (PEFT) methods, tailored for consumer hardware to scale up AI solutions in low resource settings while balancing performance and latency tradeoffs. Additionally, our approach leverages related past experiences for similar input time series to efficiently handle both intra-series and inter-series dependencies of non-stationary data with a time-then-space modeling approach, using grouped-query attention, while mitigating the limitations of traditional forecasting techniques in handling distributional shifts. Our approach models predictive uncertainty to improve decision-making. Our framework enables on-premises customization with reduced computational and memory demands, while maintaining inference speed and data privacy/security. Extensive experiments on various real-world datasets demonstrate that our framework provides robust and accurate forecasts, significantly outperforming existing methods.", "sections": [{"title": "INTRODUCTION", "content": "Multivariate time series forecasting (MTSF) has many applications, but it faces challenges such as complex relationships between time series variables, non-linearity, sparsity, and non-stationarity. Spatio-temporal graph neural networks (STGNNs) improve forecast accuracy by modeling temporal dependencies within variables and interdependencies between variables. STGNNs utilize both explicit relationships based on predefined graphs provided by domain expert knowledge and implicit relationships derived from data-driven relational inference methods. While 'Human-in-the-loop' STGNNS Yu et al. (2017); Li et al. (2017); Guo et al. (2020) use prior knowledge in predefined graphs, they do not take into account latent variable relationships underlying the substantial data. On the other hand, 'Human-out-of-the-loop' STGNNs Deng & Hooi (2021); Wu et al. (2020); Kipf et al. (2018) jointly infer variable dependency graph structures and learn spatio-temporal dynamics from data, but they may underutilize expert-defined graphs, especially in noisy data scenarios, which can impact forecasting performance. However, existing methods rely on fixed historical window lengths that may not capture the diverse and complex time series patterns of varying lengths, and lack reliable uncertainty estimates. Transformers Vaswani et al. (2017), without a built-in bias towards pairwise variable dependencies, provide greater flexibility in modeling long-range dependencies beyond local spatial relationships, enabling the capture of global relationships. STGNNS introduce a stronger spatio-temporal inductive bias, while Transformers provide enhanced representational flexibility. Recent research indicates an opportunity to develop hybrid methods that combine explicit domain knowledge in priori-known graph structures with data-driven relational learning, overcome the limitations of fixed-length window sequences by enabling the forecasting methods to apply learned patterns across past observations, and provide probabilistic forecasts for more accurate and reliable MTSF. In recent years, proprietary and closed-source large language models (LLMs) such as GPT-4 OpenAI (2023) have revolutionized natural language processing by achieving remarkable performance through pretraining on diverse and massive datasets. However, their black-box nature hinders interpretability in applications. Open-source LLMs, such as Llama 2 Touvron et al. (2023), allow fine-tuning for domain-specific customization but require significant computational resources. In contrast, smaller open-source models, like BERT Devlin et al. (2018), are interpretable but may lack reasoning abilities compared to contemporary off-the-shelf LLMs. Furthermore, integrating foundational LLMs with traditional forecasting methods remains largely unexplored, yet it holds great promise for enhancing predictions. Adapting LLMs to generate natural language descriptions capturing time series trends and patterns, though unconventional, offers a clear possibility for providing unique insights that complement and guide traditional forecasting techniques. However, sharing sensitive data with external proprietary LLM API services raises concerns regarding data privacy, sovereignty, costs, and security and has limited ability to customize them for specific needs. In this work, we introduce MultiTs Net, an innovative dynamic, multi-modal approach that combines prompt-based time series representation learning with complementary instruction-tuning open-source language models for time series trend analysis, aiming to enhance accurate time series forecasting. The key design methods include: (a) utilizing a flexible retrieval-based prompt pool to integrate time series-specific knowledge and historical context relevant to the current data distribution into traditional forecasting methods. (b) Instruction tuning of small-scale language models for time series trend analysis to interpret and describe complex time series data. The prompt design involves creating a shared pool of prompts stored as distinct key-value pairs. These prompts are tailored to encode task-specific knowledge, such as trends or seasonality relevant to different time periods. The framework uses these prompts to recognize and apply learned patterns to guide its predictions for each time series instance through transfer learning. Our framework leverages related past experiences, where similar input time series instances retrieve the same group of prompts from the pool, enhancing efficiency and predictive performance. This approach is particularly suited for overcoming fixed-window size limitations by handling the typically nonstationary nature of real-world time series data with distributional shifts. The traditional representation learning method captures the full spectrum of both intra- and inter-series dependencies underlying the time series data by implementing a time-then-space modeling approachGao & Ribeiro (2022), focusing on temporal dynamics before learning spatial dependencies. We utilize a grouped-query attention mechanismAinslie et al. (2023) to learn long-range temporal dependencies. The spatial learning method includes: (i) Graph Chebyshev convolutions to leverage explicit prior knowledge of domain expert-based pairwise variable dependencies. (ii) Utilizing grouped-query attention with no graph spatial priors to learn all pairwise variable dependencies, enhancing the understanding of long-range spatial dependencies. We perform a convex combination through a gating mechanism to compute accurate latent representations of the complex non-linear spatial dynamics of the time series data, which improves forecasting accuracy. We utilize a large-scale open-source LLM, such as 'llama2 70B 4k,' to generate instruction-following data consisting of pairs of time-series data and the corresponding natural language descriptions that encapsulate insights into time-series trends and patterns. We employ the Mixture of Parameter-Efficient Experts (MoPEs) with Low-Rank Adaptation (LoRA) technique for on-premises instruction-tuning of small-scale decoder-only language models, such as 'llama2 7B 4k,' using this machine-generated data to customize them for time-series trend analysis for enterprise adoption to complement traditional forecasting methods. In addition, the framework models predictive uncertainty to assist decision-making. In summary, our proposed framework integrates open-source large and small-scale language models with traditional time series representation learning methods by dynamically adapting to the evolving nature of non-stationary time series data distributions to provide robust and accurate forecasts. It offers a secure and affordable solution to run on consumer-grade hardware within their infrastructure, enhancing data privacy and reducing costs, thereby enabling the realization of the benefits of language models for time series analysis while addressing key adoption barriers."}, {"title": "PROBLEM DEFINITION", "content": "Our study focuses on a dynamic system with N sensors collecting sequential data over T time intervals across F features, forming a spatio-temporal matrix \\(X \\in \\mathbb{R}^{N \\times T \\times F}\\). These features include traffic attributes, such as speed, flow, and density. We denote the historical data for each sensor as"}, {"title": "EXPERIMENTS AND RESULTS", "content": "The study focuses on evaluating two frameworks: MultiTs Net and its variant w/Unc-MultiTs Net, using large-scale spatial-temporal traffic datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7(M), PeMSD8) from the Caltrans Performance Measurement System (PeMS)Chen et al. (2001). PeMS provides critical real-time and historical traffic data for California's freeways, aiding in traffic management, monitoring, and analysis. Our study converts 30-second interval data into 5-minute averages, following previous research methodsChoi et al. (2022), and also uses additional traffic flow datasets (METR-LA and PEMS-BAY)Li et al. (2018) converted into the same format. This approach allows for a consistent data format, enhancing the study's ability to analyze and model complex spatial-temporal data, and demonstrate superior performance over existing methodologies."}, {"title": "EXPERIMENTAL SETUP", "content": "In our study, we divided traffic-related datasets (PEMS-BAY and METR-LA) into three parts: training (70%), validation (10%), and testing (20%). Other datasets followed a 60%/20%/20% split. Before training, we standardized all time-series variables to a zero mean and unit variance. The models were assessed using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE), calculated on the original scale of data. Key hyperparameters included: window size (W = 12), prompt pool size (M = 15), and embedding dimension (d = 64). The Grouped-query multi-head attention (GQ-MHA) parameters included the number of groups (g = 3), attention heads (H = 4), and key/value/query dimensions (dh = 16), balancing model accuracy and efficiency. Our MultiTs Net framework was trained over 30 epochs with a batch size of 48, employing early stopping based on Validation MAE to prevent overfitting. A learning rate scheduler and the Adam optimizer were used for efficient training, with the initial rate set at 1e-3. Training involved powerful NVIDIA Tesla V100 GPUs and multiple experimental runs, reporting ensemble averages for model performance evaluation. We minimized MAE loss for MultiTs Net and Gaussian negative log-likelihood loss for its variant w/Unc-MultiTs Net. For instruction-tuning the Llama2-7B model involved utilizing the MoPEs technique with key hyperparameters: rank (r = 16), controlling model capacity; alpha (a = 1, a fraction of the rank), determining parameter update magnitude; and a LoRA dropout rate (0.05) for generalization. Training settings included a batch size of 16 per GPU, 15 epochs, an initial learning rate of 2e-4, weight decay of 0.001, the AdamW optimizer, and 8-bit quantization via MoPEs for efficiency. The focus was on supervised training to minimize the cross-entropy loss aiming to minimize cross-entropy loss by correlating time series data with textual descriptions using Nvidia V100 GPUs and the PyTorch library."}, {"title": "MULTISTEP FORECASTING RESULTS", "content": "Tables 2 and 3 compare two models, MultiTs Net and w/Unc-MultiTs Net, against various baselines in the MTSF task. The baseline results are reported from earlier studiesChoi et al. (2022); Wu et al. (2020). In a standard benchmark setting, we utilize historical data to predict estimates in a popular 12-sequence-to-12-sequence forecasting task. It involves using 12 time steps of historical data to forecast the value at the 12th future time step and then computing the forecasting errors. Both the MultiTs Net and its variant with local uncertainty estimation, w/Unc-MultiTs Net, demonstrate superior performance over the baselines. They achieve lower forecast errors and effectively capture complex MTS data dynamics. However, w/Unc-MultiTs Net, despite providing uncertainty estimates, slightly underperforms compared to MultiTs Net. Our framework forecasts consistently outperform baselines, as seen across all prediction horizons"}, {"title": "ABLATION STUDY RESULTS", "content": "The MultiTs Net is a unified framework designed to improve the accuracy and reliability of forecasting in multi-time series (MTS) data. An ablation study was conducted to evaluate the importance of each component in the framework by testing various ablated variants (with specific components disabled) on multiple datasets. The ablated variants that exclude the language model processing, dynamic prompting mechanism, intra-series dependencies, inter-series dependencies, and multi-modal alignment method are labeled as proposed framework 'w/o LLMs', 'w/o DP', 'w/o IntraS', 'w/o InterS', and 'w/o MMA' respectively; 'w/o' stands for 'without'. The study found that removing components significantly reduced performance, highlighting their importance. In particular, the ablated variant lacking the multi-modal multi-head attention mechanism (MMA) exhibited the highest error rates, emphasizing its crucial role. The increase in error for the 'w/o MMA' ablated variant might be attributed to the oversimplified linear layer substituted to demonstrate MMA effectiveness. Variations in the performance of the ablated variants across different datasets suggest that the complexity of each dataset uniquely affects the effectiveness of each component."}, {"title": "CONCLUSION", "content": "We propose a dynamic, cost-effective, and privacy-conscious hybrid approach for multi-horizon forecasting, specifically designed for private enterprise adoption. This approach integrates time series trend analysis using instruction-tuning of smaller language models with prompt-augmented, time series representation learning. This combination enables accurate and reliable forecasts, even in the presence of complex inter-variable relationships and non-stationarity. The method leverages a blend of domain expert knowledge and data-driven insights to capture both explicit and implicit variable dependencies, as well as long-range temporal dynamics through a time-then-space modeling approach. It overcomes limitations of traditional forecasting methods, such as fixed historical window lengths, by adapting to the changing nature of time series data and being compatible with consumer-grade hardware. Experiments validate the effectiveness of the hybrid method in improving forecast accuracy and quantifying uncertainty."}, {"title": "TECHNICAL APPENDIX", "content": ""}, {"title": "PROPOSED METHOD", "content": ""}, {"title": "MIXTURE OF PARAMETER-EFFICIENT EXPERTS", "content": "Low-Rank Adaptation (LoRA) Hu et al. (2022) is a parameter-efficient fine-tuning method for pre-trained language models that does not increase inference latency. It enables efficient, task-specific customization by incorporating a set of additional, lightweight trainable parameters into the existing architecture, of pretrained models, without modifying the original pretrained weights. Freezing the original weights helps mitigate catastrophic forgetting by preserving the extensive knowledge acquired by the pretrained models while learning new information. LoRA introduces a pair of low-rank weight matrices, known as adapters, alongside the frozen pretrained weights to capture task-specific information. Specifically, LoRA approximates the weight update of a linear layer as follows:\nY = (Wo + AW)X = (Wo + \\alpha BA)X\nwhere \\(Y \\in \\mathbb{R}^{b \\times d_{out}}\\) and \\(X \\in \\mathbb{R}^{b \\times d_{in}}\\) are the output and input of a linear layer, respectively. \\(d_{in}\\), \\(d_{out}\\) are the input and output dimensions, respectively, and b is the batch size. \\(W_o \\in \\mathbb{R}^{d_{in} \\times d_{out}}\\) is the pretrained weight matrix, AW is the low-rank approximation of the weight update, and \\( \\alpha \\) is a scaling constant. \\(B \\in \\mathbb{R}^{d_{in} \\times r}\\), \\(A \\in \\mathbb{R}^{r \\times d_{out}}\\) are projection-down and projection-up weight matrices, respectively. For \\(d_{in} = d_{out} = d\\), the low-rank decomposition technique reduces the number of trainable parameters from \\(O(d^2)\\) to \\(O(2dr)\\), where r < d, thus yielding substantial memory savings. The rank r is a key hyperparameter for effective fine-tuning of large pretrained models using LORA Hu et al. (2022) for niche tasks, impacting computational complexity and adaptability to new tasks. However, LoRA suffers from high activation memory costs during task-specific adaptation, which are comparable to full-parameter fine-tuning due to the need to store large input activations (or intermediate outputs, like \\(X \\in \\mathbb{R}^{b \\times d_{in}}\\)) for the computation of gradients of low-rank matrices B and A during backpropagation. Current solutions include selective layer adaptation Hu et al. (2022) or activation recomputation Chen et al. (2016), but these methods may impact performance. In summary, vanilla LoRA enables efficient LLM adaptation through low-rank weight decomposition but faces challenges related to fine-tuning memory overhead. We further enhance the original LORA method by reducing the activation memory footprint further, without incurring extra computational costs. We achieve this by freezing the projection-down weight B, while redefining the projection-up weight A as the product of a pair of low-rank matrices, D and C, where \\(D \\in \\mathbb{R}^{r \\times \\zeta}\\) remains static, and \\(C \\in \\mathbb{R}^{\\zeta \\times d_{out}}\\) is updated during fine-tuning. This approach reduces trainable parameters and minimizes the size of input activations stored during fine-tuning, which are required for backward propagation during gradient computation, all without adding inference latency. In this approach, the input \\(X \\in \\mathbb{R}^{b \\times d_{in}}\\) is initially mapped through \\(B \\in \\mathbb{R}^{d_{in} \\times r}\\) and \\(D \\in \\mathbb{R}^{r \\times \\zeta}\\) to reduce its dimension to \\( \\zeta \\), before being projected back up through C. This approach significantly reduces the activation memory requirements by limiting the storage of input activation to the output of X transformed by matrix D, which is retained from the feed-forward pass to compute the gradient of C during backward propagation. We start with B and D initialized from a normal distribution, and C set to zero, while keeping the adaptation weight matrix \\(AW = BA = B(DC)\\) initially at zero. During fine-tuning, only C is updated, which limits weight updates to a reduced column rank space (\\( \\zeta \\)) defined by the output of D. In this work, we propose using a mixture of parameter-efficient experts (MoPEsZadouri et al. (2023)) to synergistically combine the advantages of applying a mixture of experts (MoEs) to parameter-efficient fine-tuning (PEFT) methods. This results in a parameter-efficient adaptation of the MoE approach. The LoRA variant achieves parameter efficiency and activation memory reduction, and the MoE architecture utilizes specialized experts (multiple LoRA variants) tailored for adapting to distinct aspects of the input data. With a mixture of experts, each targeting specific patterns in the input data, MoPEs enable more efficient fine-tuning of large pretrained models and enhance overall performance on complex tasks. MoPEs represent a family of neural network architectures that enable conditional computation through multiple experts (LoRA variants), activated based on a gating mechanism (router R). We denote the set of K experts as \\({C_0 = E(X;\\theta_0),...,C_K = E(X;\\theta_K)}\\), where \\(C_k\\) is the k-th expert weight"}, {"title": "FINE-TUNING SMALL-SCALE LMS", "content": "The Llama 2Touvron et al. (2023) is an advanced autoregressive, language-optimized transformer architecture, fine-tuned using supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human-centric values and preferences. It incorporates RMSNorm pre-normalization, PaLM-inspired SwiGLU activation functions, and rotary positional embeddings. Additionally, it utilizes a grouped-query attention mechanism, extending the input context length to 4096 tokens. The architecture consists of 32 layers and 32 attention heads, with a hidden size of 4096, and supports batch sizes of up to 32 for sequences up to 2048 tokens. We utilize zero-shot prompting of the Llama2-70B model to generate training data for time series trend analysis, enabling task-specific fine-tuning of smaller models. We perform instruction tuning on smaller models, such as Llama2-7B through the Quantized MoPEs technique, using the machine-generated data mentioned earlier, to efficiently customize them for niche time series trend analysis through transfer learning. This approach allows us to achieve both accuracy and efficiency comparable to that of the larger model. We have integrated MoPEs modules into each linear layer of the grouped-query attention layers in the Llama2-7B model architecture for efficient fine-tuning. Each layer typically captures different aspects of language, with lower layers often capturing basic syntactic information and higher layers capturing more complex semantic relationships, allowing for task-specific adaptation. Furthermore, the original weights of the Llama2-7B model hosted by Meta AI are in 16-bit format to reduce memory usage. We also apply 8-bit quantizationDettmers et al. (2023) to further compress the pretrained language model's parameters, significantly reducing memory and computational costs. We leverage paired input time series data and their corresponding Llama2-70B-generated textual summaries to instruct-tune a smaller Llama2-7B model and minimize standard cross-entropy loss to achieve similar performance with reduced resource consumption and increased interpretability. The Llama2-7B model compute expressive token embeddings to encapsulate both contextual information and semantic relationships between words or phrases. We freeze the fine-tuned Llama2-7B model and use a downstream, forecasting task-based, differentiable softmax attention pooling mechanism to derive text-level embeddings, represented as \\(H_{text} \\in \\mathbb{R}^{N \\times W \\times d}\\), across a historical time window to compliment traditional forecasting method. Our innovative method aims to demystify the 'black-box' nature of the Llama2-70B by generating instruction-following data, thereby enhancing the Llama2-7B's capabilities in interpreting and analyzing time series data with increased precision and explainability through task-specific customization."}, {"title": "DYNAMIC PROMPTING MECHANISM DESIGN", "content": "We present a dynamic prompting mechanism designed to enhance the adaptability and accuracy of traditional forecasting methods when dealing with complex time series data. The dynamic prompting mechanism consists of a predefined set of shared pools of prompts, stored as key-value pairs, with each prompt associated with specific time series characteristics, such as periodic trends, seasonality, cyclicality, and more. The prompting mechanism enables traditional methods to retrieve relevant prompts based on the evolving nature of time series data and apply learned patterns for forecasting tasks. This allows them to draw upon appropriate past knowledge and adapt to new, similar time series trends or patterns, ultimately leading to improved forecast accuracy. Traditional methods often struggle to adapt to dynamic, non-stationary data with distributional shifts. The ability to access and utilize the most relevant prompts from the shared pool to introduce appropriate time-series-specific prior knowledge significantly improves upon traditional methods. The shared pool of prompts encodes contextual information and insights learned from historical time series data stored as key-value pairs (km, Vm) described as follows:"}, {"title": "MODELING INTRA-SERIES DEPENDENCIES", "content": "We model the dependencies within each individual time series to enhance pointwise forecasts. We employ the Grouped-query multi-head attention (GQ-MHA) mechanism to capture non-linear, time-evolving dependencies. Our approach involves projecting the time series embedding \\(S_t \\in \\mathbb{R}^{N \\times W \\times d}\\) for each of the N sensors into shared keys (Kg), shared values (Vg), and unique queries (Qg,h) for each head(h) in the group(g), as follows:\n\\[\nK_g = S_tW_{Kg}, i = 1,..., N\n\\]\n\\[\nV_g = S_tW_{Vg}, i = 1, ..., N\n\\]\n\\[\nQ_{g,h} = S_tW_{Qg,h}, i = 1, ..., N.\n\\]\nwhere the weight matrices \\(W_{K_g}\\), \\(W_{V_g}\\), and \\(W_{Q_{g,h}}\\) have dimensions \\( \\mathbb{R}^{d \\times d}\\). Consequently, the dimensions of \\(K_g\\), \\(V_g\\), and \\(Q_{g,h}\\) for each sensor i are \\( \\mathbb{R}^{W \\times d}\\), respectively. The transformed time series embeddings are computed using the scaled dot-product attention mechanism, as follows:\n\\[\nAttention(Q, K, V) = softmax(\\frac{Q_{g,h}(K_{g})^T}{\\sqrt{d_k}})V_{g}\n\\]\nwhere \\(d_k = \\sqrt{d}\\) is a scaling factor, and H is the total number of heads. We then perform aggregation across heads and groups to synthesize a concise representation of the time series data for each sensor as follows:\n\\[\nS_t = \\frac{1}{G} \\sum_{g=1}^G (Concat(Attention_1, ..., Attention_H)W_o)\n\\]\nHere, \\(W_o \\in \\mathbb{R}^{Hd \\times d}\\). Understanding the internal dynamics of each time series can provide a strong foundation for later exploring inter-series dependencies."}, {"title": "MODELING INTER-SERIES DEPENDENCIES", "content": "In highly intricate multivariate systems with intertwined dynamics, a hybrid approach that iteratively learns both intra-series and inter-series dependencies might be the most effective way to adequately"}, {"title": "GRAPH CHEBYSHEV CONVOLUTION", "content": "Graph convolution is an effective method for processing graph-structured data, with spectral graph convolution Tanaka (2021) being notable but computationally intensive. To address this, Chebyshev Graph Convolution (CGC) Defferrard & Vandergheynst (2016) offers a more scalable alternative, leveraging Chebyshev polynomials to approximate spectral graph convolution, facilitating efficient convolutional filtering on graph-structured data using the Chebyshev polynomial approximation of the graph Laplacian. The Chebyshev polynomials are calculated based on the normalized Laplacian matrix of the predefined graph, denoted as \\( \\hat{L} = \\hat{D}^{-1/2} \\hat{A} \\hat{D}^{-1/2}\\), where \\( \\hat{A} \\) is the normalized adjacency matrix, and \\( \\hat{D} \\) is the diagonal degree matrix of the graph. The Chebyshev approximation of the graph Laplacian to any degree is obtained using Chebyshev polynomials Tk(L), where k represents the degree of the polynomial. The GCC operation can be defined as follows:\n\\[\n\\tilde{S_t} = \\sigma (\\sum_{k=0}^{K-1} T_k(\\hat{L}) \\Theta_k)\n\\]\nwhere \\( \\sigma(\\cdot) \\) is a non-linear activation function applied element-wise, \\( \\Theta_k \\in \\mathbb{R}^{d \\times d} \\) is the trainable weight matrix for the k-th order Chebyshev polynomial, and K denotes the maximum order of the Chebyshev polynomials, which influences the expressive power of the approximation. \\( \\tilde{S_t} \\) is the transformed time series embedding, which captures the spatial relationships within the graph. To regulate the information flow from \\( S_t \\) (refer Equation equation 1) and \\( \\tilde{S_t} \\) (refer Equation equation 2), we employ a gating mechanism that generates a weighted combination of these representations, denoted as \\( \\overline{S_t} \\). Our hybrid architecture combines explicit domain-expert knowledge with implicit knowledge, extending beyond pairwise dependencies to capture the full complexity of spatio-temporal dependencies. Our approach, by modeling both local and global relationships in spatio-temporal data, enables accurate forecasting"}, {"title": "OUTPUT LAYER", "content": "We employ the multi-head attention mechanism (MHA) Vaswani et al. (2017) to merge text-level and time series embeddings, thereby enhancing contextual understanding and alignment across different multi-domain embeddings. This integration improves the analysis and understanding of multi-time-"}, {"title": "UNCERTAINITY ESTIMATION", "content": "We present a variant and extension of our proposed framework, MultiTs Net for time series forecasting: w/Unc-MultiTs Net, with a focus on uncertainty estimation. The MultiTs utilizes a supervised learning approach to minimize the Mean Absolute Error (MAE) which quantifies the deviation between the framework's forecasts and actual data. The w/Unc-MultiTs Net extends this by assessing uncertainties in forecasts, with predictions modeled as a heteroscedastic Gaussian distribution, characterized by mean \\(\u00b5_\u03c6(S_t)\\) and variance \\(\u03c3_\u03c6^2(S_t)\\). These parameters are derived using \\(\u00b5_\u03c6(S_t), \u03c3_\u03c6^2(S_t) = f_\u0398(S_t)\\), from a linear layer function \\(f_\u0398\\) applied to the output of a multi-modal alignment output layer.\n\\[\nL_{GaussianNLLLoss} = \\sum_{t=1}^{T} \\frac{log \\sigma_{\\varphi(S_t)}^2}{2} + \\frac{(S_{t+1} - \\mu_{\\varphi(S_t)})^2}{2 \\sigma_{\\varphi(S_t)}^2}\n\\]\nThe framework minimizes the Gaussian negative log-likelihood loss, thereby enhancing the quantification of uncertainty. While the MultiTs Net focuses on minimizing MAE for accurate forecasting, the w/Unc-MultiTs Net emphasizes minimizing the Gaussian negative log-likelihood loss for effective uncertainty quantification in time series forecasting."}, {"title": "IRREGULAR TIME SERIES", "content": "We focus on evaluating the effectiveness of the MultiTs Net framework in handling missing data in large, complex sensor networks. The study simulates two types of missingness patterns: MCAR (Missing Completely At Random), representing random sensor failures, and block-missing, where data points are missing for a contiguous period. Block-missing patterns are defined by their length (the number of missing points) and frequency (how often they occur). These simulations help assess the framework's performance in 12-sequence-to-24-sequence forecasting tasks, with data missing-ness ranging from 10% to 50%. The results reveal that while the MultiTs Net performs well with lower missing data percentages, its accuracy declines as the level of missingness increases. However, its ability to condition forecasts on available observations without relying on imputed values demonstrates its resilience and effectiveness in capturing nonlinear spatio-temporal dependencies in sensor network data."}]}