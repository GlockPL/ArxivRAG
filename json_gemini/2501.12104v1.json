{"title": "Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection", "authors": ["ShiXuan Song", "Hao Chen", "Shu Hu", "Xin Wang", "Jinrong Hu", "Xi Wu"], "abstract": "Visual anomaly detection is a highly challenging task, often categorized as a one-class classification and segmentation problem. Recent studies have demonstrated that the student-teacher (S-T) framework effectively addresses this challenge. However, most S-T frameworks rely solely on pre-trained teacher networks to guide student networks in learning multi-scale similar features, overlooking the potential of the student networks to enhance learning through multi-scale feature fusion. In this study, we propose a novel model named PFADSeg, which integrates a pre-trained teacher network, a denoising student network with multi-scale feature fusion, and a guided anomaly segmentation network into a unified framework. By adopting a unique teacher-encoder and student-decoder denoising mode, the model improves the student network's ability to learn from teacher network features. Furthermore, an adaptive feature fusion mechanism is introduced to train a self-supervised segmentation network that synthesizes anomaly masks autonomously, significantly increasing detection performance. Evaluated on the MVTec AD dataset, PFADSeg achieves state-of-the-art results with an image-level AUC of 98.9%, a pixel-level mean precision of 76.4%, and an instance-level mean precision of 78.7%.", "sections": [{"title": "1 INTRODUCTION", "content": "The primary objective of anomaly detection is not only to identify anomalous images but also to precisely segment the anomalous pixel regions. It is critical in various computer vision applications, including industrial defect inspection [16, 26], medical image analysis [20], and video surveillance [12]. However, these tasks commonly face significant challenges, such as the scarcity of anomalous samples and the diversity of anomaly types. This variability makes it difficult to collect sufficient data or labels for the wide range of anomaly categories. Furthermore, the differences between normal and anomalous samples are frequently subtle, often masked by irrelevant noise, which complicates the task of simultaneously filtering out noise and accurately identifying anomalous pixel regions.\nGiven the scarcity of anomaly data and the difficulty of obtaining labels, anomaly detection tasks typically rely on unsupervised learning methods, where models are trained solely on normal data. Recently, the knowledge distillation mode [18], particularly the student-teacher (S-T) framework, has demonstrated its effectiveness in anomaly detection tasks [3, 7, 18, 21, 22]. In this framework, the teacher network is usually pre-trained on large-scale datasets (e.g., ImageNet [8]) and possesses well-established weights, while the student network, which shares the same architecture as the teacher network, is trained under the supervision of the teacher using anomaly detection datasets [2] containing only normal samples. The goal is for the student network to learn feature representations similar to those of the teacher network. Notably, knowledge distillation can also be applied across multiple levels of a feature pyramid [18, 21, 28], enabling the integration of multi-level feature differences and achieving superior performance. However, several issues remain unresolved. First, the lack of anomalous samples during student network training may lead to insufficient representation of feature differences between the teacher and student networks for anomalies in the S-T framework. Second, the student network in most S-T frameworks shares the same architecture as the teacher network, which may limit the student's ability to effectively learn features extracted by the teacher, particularly in large-scale anomaly detection datasets where training the student network becomes more complex.\nTo address the aforementioned challenges, we introduce a novel knowledge distillation (KD) approach, the denoising student-teacher distillation mode (Fig. 1), where paired normal and anomalous samples are fed into the teacher and student networks, respectively, with the student network adopting a different architecture from the teacher. Based on this mode, we propose a Parallel Feature Aggregation and Denoising for Anomaly Segmentation (PFADSeg, Fig. 2), which consists of a pre-trained teacher network, an improved denoising student network, and a segmentation network. Synthetic anomaly masks are added to normal images to generate inputs for the student network, while the teacher processes the corresponding unaltered normal images. This setup allows the student network to remove noise and learn features aligned with those of the teacher network, leveraging architectural differences to reduce sensitivity to irrelevant noise. The student network, based on ResNet18 [10], is further enhanced to better fuse features across multiple levels. Finally, a trainable segmentation network is introduced to process multi-level feature differences between the teacher and student networks, with synthetic anomaly masks providing supervision during training.\nWe evaluated the performance of our model using the unsupervised MVTec AD dataset [2]. Extensive experimental results demonstrate that our approach achieves significant improvements in anomaly detection tasks at the image level, pixel level, and instance level. Additionally, we conducted ablation studies to validate the effectiveness of our proposed model enhancements. Compared to previous work [28], our method introduces several improvements to the segmentation network and the denoising student network:\n\u2022 We enhance the segmentation network's ability to capture global contextual information by incorporating horizontal and vertical pooling. Additionally, we introduce a large-kernel strip convolution to create rectangular attention regions, which better highlight anomalous pixels.\n\u2022 We improve the denoising student network by modifying the residual block structure based on ResNet18 [10]. Specifically, we introduce an attention mechanism into the residual connections, enabling dynamic feature fusion and allowing the network to simultaneously focus on both globally distributed large objects and locally distributed small objects.\n\u2022 We propose a Parallel Convolutional Attention Recalibration Module to replace the second convolutional layer in the residual blocks, which further enhances feature extraction and anomaly detection performance."}, {"title": "2 RELATED WORKS", "content": "Anomaly detection and localization have been explored from various perspectives, with significant progress made in methods involving image reconstruction, parameter density estimation, and memory-based approaches.\nIn image reconstruction, researchers have used models such as autoencoders [4], variational autoencoders (VAE) [1], and generative adversarial networks (GANs) [19, 20]. These models are typically trained on normal data, assuming that anomalous images, unseen during training, will not be effectively reconstructed. The pixel-wise difference between the input image and the reconstructed image is used as an anomaly score. However, these methods face challenges such as overgeneralization, where anomalous regions may still be accurately reconstructed, thus reducing the effectiveness of the anomaly score [14]. Recent works have addressed this issue by incorporating techniques such as adversarial training or hybrid models, which combine reconstruction with discriminative learning to improve robustness against anomalies.\nFrom the perspective of parameter density estimation, this method assumes that features extracted from normal data follow a specific distribution, typically a multivariate Gaussian distribution [6, 11, 15]. The model estimates the parameters of this distribution using normal data, and during inference, outliers are identified as anomalies. To overcome the restrictive Gaussian assumption, recent advancements have leveraged normalization flow techniques [9, 25], which transform arbitrary feature distributions into Gaussian distributions. This flexible framework enables the estimation of complex data distributions and has shown significant improvements in detecting various anomalies.\nAnother line of research focuses on memory-based methods [16, 23], which involve constructing a memory bank of normal data during training. During inference, the model retrieves the most similar items from the memory bank based on a given query and calculates anomaly scores based on their similarity. These methods effectively capture fine-grained patterns in normal data and are particularly useful in scenarios where anomalies are subtle or context-dependent. Extensions of memory-based models, such as those incorporating attention mechanisms or dynamic memory updates, further enhance their applicability to real-world anomaly detection tasks.\nKnowledge distillation is a method that leverages a pre-trained teacher network and a trainable student network, and it is highly useful in anomaly detection. The student network is typically trained on a dataset consisting of only normal data, and its anomalous feature representations are expected to differ from those of the teacher network. This divergence provides a basis for distinguishing anomalies. Various strategies have been proposed to enhance the detection of different anomaly types. For example, Bergmann et al. [3] uses ensemble learning to train multiple student networks, exploiting irregularities in their feature representations to detect anomalies more effectively. Similarly, Salehi et al. [18] and Wang et al. [21] introduce methods for aligning multi-level feature representations, allowing the model to capture both low-level and high-level anomalies. These methods demonstrate the versatility and adaptability of knowledge distillation in addressing various challenges in anomaly detection. Additionally, to avoid the scenario where both the teacher and student networks have the same architecture and use the same input data, some works [7, 22] design the student network with a decoder architecture. Furthermore, Zhang et al. [28] further distinguishes the representations of anomalies between the teacher and student networks within the S-T framework.\nAnomaly Simulation. In the context of one-class classification for anomaly detection (AD), where anomalous data is unavailable for training, pseudo-anomalous data can be simulated for supervised training of AD models. Traditional anomaly simulation methods, such as rotation and cropping [20], are often ineffective at detecting fine-grained anomaly patterns [11]. Zhang et al. [28] adopted the idea proposed in, using two-dimensional Perlin noise to simulate more realistic anomalous images, and utilized the generated anomaly masks as ground truth for the segmentation network. However, this approach may cause the trained segmentation network to overlook the impact of irrelevant noise in normal images when segmenting real anomalous images. This can lead to misclassifying normal regions as anomalous during inference. The attention on irrelevant noise often shifts focus away from true anomalous regions, thus reducing the effectiveness of anomaly detection, especially in the MVTec AD dataset [2], where this issue is more pronounced in five texture categories."}, {"title": "3 METHOD", "content": "The proposed PFADSeg architecture consists of three main components: a teacher network pre-trained on the ImageNet [8] dataset, an improved denoising student network, and a segmentation network."}, {"title": "3.1 Teacher Encoder-Student Decoder Denoising Network", "content": "Our proposed method introduces a modified denoising student network that is fundamentally different from the teacher network. Specifically, both the teacher and student networks utilize paired normal and anomalous images as inputs, but the denoising student network adopts a different architecture from the teacher network. The teacher network we use is a ResNet18 [10] pre-trained on the ImageNet dataset, but only the first three convolutional blocks (i.e., conv1_x, conv2_x, conv3_x) are employed, denoted as T1, T2, and T3, respectively. For the denoising student network, the encoder part is based on an improved ResNet18, which we refer to as PA_ResNet18, where the residual blocks have been enhanced. This version of the student network uses four convolutional blocks, named PA_SE\u00b9, PA_SE2, PA_SE\u00b3, and PA_SE4. For the decoder part, we employ a reversed PA_ResNet18 (where all downsampling layers are replaced with bilinear upsampling). This decoder also utilizes four convolutional blocks, named PA_SD\u00b9, PA_SD2, PA_SD\u00b3, and PA_SD4.\nFeature fusion is a method of combining features from different layers or branches, often achieved through simple operations like summation or concatenation. However, these simple operations may not always be the best choice. To address this, we draw inspiration from the Attentional Feature Fusion (AFF) module proposed in [5]. Since anomaly detection is not merely a simple binary classification problem but more importantly involves anomaly region segmentation, we aim to handle feature fusion across different scenarios. We also introduce attention mechanisms and multi-scale context aggregation, allowing the model to aggregate contextual information from various receptive fields. This enables the network to adapt to objects of different scales, focusing on both large objects with global distribution and small objects with local distribution. This is particularly important for anomaly detection, especially when segmenting small anomalous regions.\nThe improved residual block in our PA_ResNet18 is shown in Fig. 3. We replace the simple summation-based feature fusion in the residual connection of the original Residual Block with the feature fusion method involving the AFF. Rather than simply summing the features, we employ AFF to dynamically fuse them. Additionally, the second 3 \u00d7 3 convolution layer in the original Residual Block is replaced by the Parallel Convolutional Attention Recalibration (PCAR) module we proposed, which will be elaborated in detail in Sec. 3.2. This modification enhances the model's ability to focus on relevant features and improves its performance in detecting and segmenting anomalies.\nWe minimize the cosine distance between the features Ti and PA_SD\u0130 (where i = 1, 2, 3). Let FT; \u2208 RC\u00a1\u00d7Hi\u00d7Wi be the features extracted by the teacher network, and Fs; \u2208 RCi\u00d7H\u00d7Wi be the features extracted by the decoder part of the student network. The cosine distance is calculated using the (2) and (3), where j and k represent the spatial coordinates on the feature map, with j = 1... Hi and k = 1... Wi. The total loss is calculated as the sum of the losses for three different feature pairs, as shown in (4). Where, Xi (j, k) is the cosine similarity between the features from the teacher and student network; Di (j, k) is the cosine distance, which is used to calculate the dissimilarity between the teacher and student features; Lcos represents the total loss over the three feature pairs, used to guide the training process.\n$X_{i}(j, k)=\\frac{F_{T_{i}}(j, k) \\cdot F_{S_{i}}(j, k)}{\\|F_{T_{i}}(j, k)\\|_{2} \\|F_{S_{i}}(j, k) \\|_{2}}$\n$D_{i}(j, k)=1-\\sum_{c=1}^{G_{i}} X_{i}(j, k)_{c}$\n$L_{\\cos }=\\sum_{i=1}^{3} \\frac{1}{H_{i}, W_{i}} \\sum_{j, k=1}^{H W} D_{i}(j, k)$"}, {"title": "3.2 Parallel Convolutional Attention Recalibration Module", "content": "In ResNet18, each of the four convolutional layers (i.e., conv2_x, conv3_x, conv4_x, conv5_x) consists of two residual blocks. We propose a novel Parallel Convolutional Attention Recalibration (PCAR) Module. By using parallel convolutions to extract multi-scale spatial information, the PCAR module can accurately localize and segment anomalous regions while effectively eliminating irrelevant noise present in the detection images. We specifically use the PCAR module to replace the second 3x3 convolution in the residual block of the original ResNet18 architecture. The overall architecture of the PCAR module is shown in Fig. 4.\nFirst, the PCAR module receives the output feature F \u2208 RH\u00d7W\u00d7C from the first 3 \u00d7 3 convolution layer of the Residual Block, where H, W, and C represent the height, width, and number of channels of the feature map, respectively. The input feature F is then passed through three parallel 3 \u00d7 3 convolutions, each of which independently extracts features from different perspectives, resulting in different feature maps Fi (where i = 1, 2, 3), thus enhancing the diversity of the features. The convolution operation is represented as:\n$F_{i}=\\text { Conv } 3 \\times 3(F)$\nNext, the output Fi from each convolution layer is processed through a Spatial Pyramid Recalibration (SPR) module [24], which is designed to reinforce the important information in the feature map Fi. This allows the model to focus more on the critical regions of the feature map while ignoring irrelevant noise, thereby improving the precision of anomaly region segmentation. The processed feature maps F are then concatenated together to form a new feature map F' \u2208 RH\u00d7W\u00d73C, as expressed by:\n$F^{\\prime}=\\text { Concat }\\left(F_{1}, F_{2}, F_{3}\\right)$\nThe concatenated feature map F' is passed through a Softmax layer to generate a weight map W \u2208 R1\u00d71\u00d73C, with the operation for obtaining W as follows:\n$W=\\operatorname{Softmax}\\left(F^{\\prime}\\right)$\nThe generated weight map W is then element-wise multiplied with the concatenated feature map F1, F2, F3 yielding the recalibrated feature map T \u2208 RH\u00d7W\u00d73C. This operation can be expressed as:\n$T=W \\otimes \\text { Concat }\\left(F_{1}, F_{2}, F_{3}\\right)$\nFinally, a channel sum operation is applied to T to convert it back to the original number of channels C, producing the output feature map Y \u2208 RH\u00d7W\u00d7C:\n$Y=\\text { channel_sum }(T)$\nIn experimental results on the MVTec AD anomaly detection dataset, the newly proposed PCAR module demonstrated significant performance advantages. Thanks to its innovative parallel convolution design, PCAR is able to capture image features from multiple perspectives simultaneously, which not only enhances the model's ability to detect subtle anomalies but also improves the accuracy of anomaly detection. The attention mechanism integrated within the PCAR module enables the model to adaptively focus on key areas of the image, ensuring accurate anomaly detection even in complex backgrounds, thus enhancing the model's robustness."}, {"title": "3.3 Segmentation Network", "content": "In the works of [18], anomaly scores are typically represented by directly summing the cosine distances of multi-layer features. However, if the discriminative abilities of the features across layers vary, this direct summation may result in suboptimal performance. To address this issue, we introduce a segmentation network that provides additional supervisory signals to guide the feature fusion process. Specifically, we freeze the weights of both the student and teacher networks to train the segmentation network. The synthetic anomalous images are passed as input to both the teacher-student network, while the corresponding binary anomaly masks are used as target labels during training.\nIn this process, we calculate the similarity between the feature maps (T\u2081, PA_SD\u00b9), (T2, PA_SD\u00b2), (T3, PA_SD\u00b3), as shown in Equation (2), and the results are upsampled to a quarter of the input image size, i.e., the size of X1. After upsampling, the resulting feature maps X1, X2, X3 are concatenated into X and passed to the segmentation network for further processing. The segmentation network mainly consists of two PA_Residual Blocks and a Rectangular Self-Calibration Module (RCM) [13]. In [28], the segmentation network employs the Atrous Spatial Pyramid Pooling (ASPP) module to increase the receptive field without introducing additional computational costs. However, the dilated convolutions used by ASPP tend to overlook small foreground objects in the image. This limitation is particularly problematic in industrial anomaly detection tasks, such as those involving datasets like MVTec AD [2], where most anomalies are small region anomalies. Consequently, the use of ASPP can lead to over-segmentation, where the detected anomaly regions include many non-anomalous parts, thereby reducing the model's ability to accurately localize anomalies. To address this issue, we replace the ASPP module with the RCM proposed in [13]. This adjustment allows the segmentation network to focus more on the foreground objects by adjusting the rectangular attention regions, improving the localization of foreground objects and precisely segmenting anomalous regions. This ensures that the anomaly regions are accurately delineated while reducing the segmentation of non-anomalous areas.\nTo optimize the segmentation network's training, we employ a combination strategy of focal loss and L1 loss. Since most pixels in the training dataset belong to the easily recognized normal background, while anomalous pixels constitute a small yet critical minority, focal loss is used to emphasize these minority and hard-to-distinguish samples, improving the model's ability to segment anomalies. L1 loss is further introduced to enhance output sparsity, ensuring clearer segmentation boundaries. The ground truth anomaly mask is downsampled to a quarter of the input image size to match the output dimensions (H1, W\u2081). Let Y denote the output probability map and K the downsampled anomaly mask; the focal loss is computed as follows:\n$L_{\\text {focal }}=\\frac{1}{H_{1}, W_{1}} \\sum_{i, j=1}^{H W}\\left(1-q_{i j}\\right)^{\\gamma} \\log \\left(q_{i j}\\right)$\nwhere qij = KijYij + (1 \u2212 Kij)(1 \u2013 Yij), and \u03b3 is the focusing parameter of the focal loss. The formula for L1 loss is:\n$L_{l 1}=\\frac{1}{H_{1}, W_{1}} \\sum_{i, j=1}^{H W}\\left|K_{i j}-Y_{i j}\\right|$\nwhere K is the ground truth mask.\nFinally, the total segmentation loss is the weighted sum of the focal loss and L1 loss:\n$L_{\\text {seg }}=L_{\\text {focal }}+L_{l 1}$"}, {"title": "4 EXPERIMENTS", "content": "We conducted a comprehensive evaluation of the proposed method using the MVTec AD [2] dataset. It is one of the most widely used benchmarks in the field of anomaly detection and localization, consisting of a total of 15 categories, including 10 object categories and 5 texture categories. The training set for each category contains several hundred normal images, while the test set consists of a mix of normal and anomalous images. Additionally, each anomalous image in the test set is provided with ground truth annotations for performance evaluation. The image resolutions range from 700\u00d7700 to 1024x1024 pixels. For the anomalous source image A as shown in Equation (1), we used images from the Describable Textures Dataset (DTD) [17]. Although [26] shows that other datasets, such as ImageNet, can achieve comparable performance, the DTD dataset is more compact, easier to use, and better suited for generating anomalies."}, {"title": "4.2 Evaluation Metrics", "content": "We used three levels of evaluation metrics for the examination of model's detection performance. For image-level evaluation, we adopt the area under the ROC curve (AUC), which is a common practice in the anomaly detection field. Rather than AUC, Average Precision (AP), as highlighted in [17], is reported for the pixel-level evaluation considering the significant class imbalance in the dataset. In practical applications, such as industrial defect detection and medical imaging lesion detection, users are more concerned with whether the model can locate the anomalous instances entirely or partially, instead of detecting every pixel precisely. In such case, the Region Overlap Ratio (PRO) metric proposed in [3] is used for the instance-level evaluation. It assigns equal weights to connected regions of different sizes in the ground truth annotations and calculates the overlap between the predicted and ground truth regions within a user-defined false positive rate (e.g., 30%). However, since instance recall is particularly important in real-world scenarios, we propose using Instance Average Precision (IAP) as a more intuitive evaluation metric. We define anomalous instances as the largest connected regions in the ground truth. In the predicted results, an anomalous instance is considered successfully detected if more than 50% of the pixels in the instance are correctly predicted as positive. By setting different thresholds, we can plot the curve of pixel-level precision versus instance-level recall, and the area under this curve represents the IAP. Furthermore, for applications requiring high recall, we also calculate the precision at a recall rate of k% and denote it as IAP@k. In the experiments, to simulate high-risk scenarios, we set k to 90."}, {"title": "4.3 Implementation Details", "content": "In the experiments, the teacher network is based on a ResNet18 [10] model pre-trained on ImageNet [8], with the weights of the teacher network remaining fixed throughout the training process. The encoder of the denoised student network adopts an architecture that improves the residual blocks of ResNet18, while the decoder uses a reversed architecture based on the ResNet18 residual blocks (replacing all downsampling with bilinear upsampling). Both the encoder and decoder are constructed by concatenating four residual blocks in an equal manner, with all weights randomly initialized and involved in training. The segmentation network consists of two improved residual blocks(PA_Residual Blocks), and a Rectangular Self-Calibration module (RCM), with all weights also randomly initialized and involved in the training process. Both the denoised student network and the segmentation network are trained using Stochastic Gradient Descent (SGD). The learning rate for the denoised student network is set to 0.5, the learning rate for the improved residual blocks in the segmentation network is set to 0.1, and the learning rate for the RCM module is set to 0.01, with a batch size of 16. During training, the denoised student network is first trained for 3000 iterations, after which its weights are fixed. Then, the segmentation network undergoes an additional 4000 iterations of training. All input images are resized to 256 \u00d7 256 during both training and testing."}, {"title": "4.4 Results", "content": "We primarily compared our method with current state-of-the-art approaches using the evaluation metrics mentioned in Sec. 4.2. Experimental results that were unavailable are marked as \"-\". Below, we will primarily focus on comparing our method with others in terms of image-level anomaly detection, pixel-level anomaly localization, and instance-level anomaly detection, while also presenting visual comparison results that are closest to our method.\nFor the image-Level anomaly detection, we present the AUC scores of our method and other methods in the image-level anomaly detection task in Tab. 1, with a focus on the average results across the 15 categories of the MVTec AD dataset. As observed, our method outperforms others, achieving an Image_AUC of 98.9%. In Tab. 2, we report the AUC and AP metrics for the pixel-level anomaly localization task. Our method achieves nearly identical AUC scores compared to PatchCore [16], while setting a new benchmark in terms of AP. Additionally, our approach demonstrates substantial improvements across most categories, with scores either at or near the highest, strongly suggesting that it performs robustly across a wide range of categories.\nFor the instance-level anomaly detection, the experimental results are shown in Tab. 3, where we report the IAP and IAP@90 metrics to comprehensively assess the model's performance. The results indicate that our method achieves state-of-the-art performance on both metrics, demonstrating its exceptional anomaly detection capabilities. Notably, our method reaches an average IAP@90 of 62.7%. This means that when the model successfully detects 90% of the anomalous instances, the pixel-level precision reaches 62.7%. In other words, this corresponds to only a 37.3% pixel-level false positive rate, which is relatively low and indicates a high level of robustness and reliability in many real-world applications. The high precision and low false positive rate of our method, especially in complex and high-risk industrial environments, provide a strong guarantee for practical applications. This makes it particularly valuable in industrial domains and other critical areas. In addition, we provide a visual comparison between our method and the DeSTSeg approach [28]. As shown in Fig. 5, the segmentation results from our method clearly outperform those of DeSTSeg in terms of visual quality. Notably, for the five texture categories on the right side, our approach excels in accurately focusing on the abnormal regions while effectively minimizing irrelevant noise."}, {"title": "4.5 Ablation Studies", "content": "In Tab. 4, we conducted ablation experiments to effectively evaluate the proposed three modules. Specifically, we adopted the network architecture from [28] as the baseline and performed a detailed analysis and comparative experiments to assess the independent effects of each module as well as their combined impact on network performance. The experimental results demonstrate that, by comparing Experiment 2 with 5 and Experiment 3 with 6, integrating the proposed PCAR module with either the RCM or AFF module significantly enhances the network's performance. Furthermore, the results of Experiment 7 further reveal that incorporating the PCAR, RCM, and AFF modules into the network architecture achieves optimal performance. This combination not only enables more accurate detection and localization but also substantially improves the overall network effectiveness, thereby validating the efficiency and superiority of our proposed approach."}, {"title": "5 CONCLUSION", "content": "In this paper, we propose a novel PCAR module and integrate it into our PFADSeg model. The PCAR module employs parallel convolution techniques to effectively capture multi-scale spatial information, enabling precise localization and segmentation of anomalous regions while suppressing irrelevant noise in detection images. The PFADSeg model further optimizes the feature extraction process between the student and teacher networks, using an improved strategy to enhance discriminative features in anomalous regions. Additionally, a segmentation network is integrated to adaptively fuse features from the student-teacher network, achieving more accurate anomaly segmentation. Experiments on the MVTec AD dataset demonstrate that our method outperforms state-of-the-art approaches. Specifically, in image-level anomaly detection, our method achieves an AUC of 98.9%, surpassing the current best by 0.4%. For pixel-level anomaly localization, it achieves an AP of 76.4%, exceeding the best by 0.6%, with AUC nearing the state-of-the-art. Notably, for instance-level anomaly detection, our method improves IAP@90 by 7.3% and IAP by 4.1%. These results validate the effectiveness and superiority of our approach."}]}