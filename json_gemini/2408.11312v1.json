{"title": "Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework", "authors": ["Xiao Han", "Chen Zhu", "Xiangyu Zhao", "Hengshu Zhu"], "abstract": "Visual geo-localization demands in-depth knowledge and advanced reasoning skills to associate images with real-world geographic locations precisely. In general, traditional methods based on data-matching are hindered by the impracticality of storing adequate visual records of global landmarks. Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability of geo-localization through Visual Question Answering (VQA), enabling a solution that does not require external geo-tagged image records. However, the performance of a single LVLM is still limited by its intrinsic knowledge and reasoning capabilities. Along this line, in this paper, we introduce a novel visual geo-localization framework called smileGeo that integrates the inherent knowledge of multiple LVLM agents via inter-agent communication to achieve effective geo-localization of images. Furthermore, our framework employs a dynamic learning strategy to optimize the communication patterns among agents, reducing unnecessary discussions among agents and improving the efficiency of the framework. To validate the effectiveness of the proposed framework, we construct GeoGlobe, a novel dataset for visual geo-localization tasks. Extensive testing on the dataset demonstrates that our approach significantly outperforms state-of-the-art methods.", "sections": [{"title": "1 Introduction", "content": "Visual geo-localization, referred to the task of estimating geographical identification for a given image, is vital in various fields such as human mobility analysis [1, 2, 3, 4, 5] and attraction recommendations [6, 7, 8, 9, 10, 11]. In general, accurate visual geo-localization without the help of any localization equipment (e.g., GPS sensors) is a complex task that requires abundant geospatial knowledge and strong reasoning capabilities. Traditional methods [12, 13, 14, 15] typically formulate it as an image retrieval problem where to geo-localize the given image by retrieving similar images with known geographical locations. Thus, their effectiveness is limited by the scope and quality of the geo-tagged image records.\nRecently, the success of Large Vision-Language Models (LVLMs) has enabled Visual Question Answering (VQA) to become a unified paradigm for multi-modal problems [16, 17], providing a novel solution for visual geo-localization without the need for external geo-tagged image records. However, the performance of a single LVLM on the geo-localization task is still limited by its inherent geospatial knowledge and reasoning capabilities. Along this line, in this paper, we introduce a novel multi-agent framework, named swarm intelligence Geo-localization (smileGeo), which aims to adaptively integrate the inherent knowledge and reasoning capabilities of multiple LVLMs to effectively and efficiently geo-localize images. Specifically, for a given image, the framework initially elects K suitable LVLM agents as answer agents for initial location analysis. Then, each answer agent chooses several review agents via an adaptive social network, which imitates the collaborative relationships between agents with a target on the visual geo-localization task, to discuss and share their knowledge for refining its location analysis. Finally, our framework conducts free discussion among all of the answer agents to reach a consensus. Besides, we also design a novel dynamic learning strategy to optimize the election mechanism along with the adaptive collaboration social network of agents. We hope that by the effectiveness of the election mechanism and the review mechanism, our framework can discover the mode of communication among agents, thereby enhancing geo-localization performance through multi-agent collaboration while minimizing unnecessary discussions. In summary, our contributions are demonstrated as follows:\n\u2022 A novel swarm intelligence geo-localization framework, smileGeo, is proposed to adaptively integrate the inherent knowledge and reasoning capability of multiple LVLMs through discussion for visual geo-localization tasks.\n\u2022 A dynamic learning strategy is introduced to discover the most appropriate discussion mode among LVLM agents for enhancing the effectiveness and efficiency of the framework.\n\u2022 A new visual geo-localization dataset named GeoGlobe is collected, containing a wide variety of images globally. The diversity and richness of GeoGlobe allow us to evaluate the performance of different models more accurately. Moreover, extensive experiments demonstrate our competitive performance compared to state-of-the-art methods.\nThe remainder of this paper is organized as follows: Section 2 discusses the related literature. In Section 3, the proposed framework is introduced. Section 4 provides the performance evaluation, and Section 5 concludes the paper."}, {"title": "2 Related Work", "content": "Visual Geo-localization. Recent research in visual geo-localization, commonly referred to as geo-tagging, primarily focuses on developing image retrieval systems to address this challenge [3, 18, 19, 20, 21, 22]. These systems utilize learned embeddings generated by a feature extraction backbone, which includes an aggregation or pooling mechanism [23, 24, 25, 26]. However, the applicability of these retrieval systems to globally geo-localize landmarks or natural attractions is often limited by the constraints of the available database knowledge and the restrictions imposed by national or regional geo-data protection laws. Alternatively, some studies treat visual geo-localization as a classification problem [27, 28, 29, 30]. These approaches posit that two images from the same geographical region, despite depicting different scenes, typically share common semantic features. Practically, these methods organize the geographical area into discrete cells and categorize the image database accordingly. This cell-based categorization facilitates scaling the problem globally, provided the number of categories remains manageable. However, while the number of countries globally remains relatively constant, accurately enumerating cities in real-time at a global scale is challenging due to frequent administrative changes, such as city reorganizations or mergers, which reflect shifts in national policies. Additionally, in the context of globalization, this strategy has inherent limitations. The recent advent of LVLMs offers promising compensatory mechanisms for the deficiencies observed in traditional geo-localization methodologies, making the exploration of LVLM-based approaches significantly relevant in current research.\nMulti-agent Framework for LLM/LVLMs. LLM/LVLM agents have demonstrated the potential to act like human [31, 32, 33], and a large number of studies have focused on developing robust architectures for collaborative LLM/LVLM agents [34, 35, 36, 37, 38]. These architectures enable each LLM/LVLM agent that endows with unique capabilities to engage in debates or discussions. For instance, [34] proposes an approach to aggregate multiple LLM/LVLM responses by generating candidate responses from various LLM/LVLM in a single round and employing pairwise ranking to synthesize the most effective response. While some studies [34] utilize a static architecture potentially limiting the performance and generalization of LLM/LVLM, others like [38] have implemented dynamic interaction architectures that adjust according to the query and incorporate user feedback. Recent advancements also demonstrate the augmentation of LLM/LVLM as autonomous agents"}, {"title": "3 Methodology", "content": "In this section, we first present the overall framework and then introduce each part of smileGeo in detail for geo-localization tasks."}, {"title": "3.1 Model Overview", "content": "In this paper, we denote the social network of LVLM agents by G, where G = {V, E}.V stands for the agent set and & presents the edge set. Each agent $v_i \\in V, i \\in [N]$ is an LVLM, which is pre-trained by massive vision-language data and can infer the possible location Y of a given image X. Besides, each edge $e_{ij} \\in E, i, j \\in [N]$ is the connection weighted by the improvement effect of agent vi to agent vj via discussion regarding the geo-localization performance.\nAs illustrated in Figure 1, smileGeo contains the process of the review mechanism in agent discussions along with a dynamic learning strategy of agent social networks:\nThe review mechanism in agent discussions is a 3-stage anonymous collaboration approach to allow LVLM agents to reach a consensus via discussion. In the first stage, for a given image X, our framework elects the most suitable K agents as answer agents by agent election probability Lst. In the second stage, these answer agents respectively select R review agents by the adaptive collaboration social network A to refine their answer via discussion. Finally, our framework facilitates consensus among all agents through open discussion to reach a final answer. Both Lst and A are analyzed from the given image X, allowing our framework to minimize unnecessary discussions, thereby significantly enhancing its efficiency while maintaining its accuracy. Moreover, the multi-stage discussion facilitates communication among agents, maximizing the integration of their knowledge and reasoning abilities to generate an accurate response Y.\nTo get Lst and A, we specifically design a dynamic learning module, which initially deploys the encoder component of a pre-trained image variational autoencoder (VAE) to extract features from the given image X. The extracted features, combined with agent embeddings Emb, are employed to determine the suitability of agents w.r.t. Lst for agent discussions and predict agent collaboration connections A in the geo-localization task."}, {"title": "3.2 Review Mechanism in Agent Discussions", "content": "LLM/LVLM have demonstrated remarkable capabilities in complicated tasks and some pioneering works have further proven that the performances can be further enhanced by ensembling multiple LLM/LVLM agents. Thus, to improve the geo-localization capability of LVLMs, we propose a cooperation framework to effectively integrate the diverse knowledge and reasoning abilities of multiple LVLMs. Inspired by the fact that community review mechanisms can improve the quality of manuscripts, an iterative 3-stage anonymous reviewing mechanism is proposed for helping agents share knowledge and reasoning capability with each other through their collaboration social network: i) answer agent election & answering, ii) review agent selection & reviewing, and iii) final answer conclusion.\nStage 1: Answer Agent Election & Answering\nInitially, we select K agents with the highest agent election probabilities Lst as answer agents and let them geo-localize independently as the preliminary step for further discussion. By initiating the discussion with a limited number of agents, we aim to reduce potential chaos and maintain the efficiency of our framework as the number of participating agents increases."}, {"title": "Stage 2: Review Agent Selection & Reviewing", "content": "In this stage, for each answer agent, we choose R review agents by performing a transfer-probability-based random walk on the agent collaboration social network G for answer reviewing. The transfer probability p(vi, vj) from node vi to node vj can be calculated as follows:\n$P(V_i, U_j) = \\begin{cases}\n\\frac{A_{ij}}{\\sum_{k \\in N(v_i)} A_{ik}}, & \\text{if } e_{ij} \\in E \\\\\n0, & \\text{otherwise}\n\\end{cases}$                                                                             (1)\nwhere N(vi) is the 1-hop neighbor node set of node vi.\nFor each selected review agent, it reviews the results as well as the explanations generated by the corresponding answer agent and gives its own comments. After that, each answer agent would summarize their preliminary analysis and the feedback from all of its review agents to get the final answer, which must include three parts as well: one location, one confidence, and an explain."}, {"title": "Stage 3: Final Answer Conclusion", "content": "In the previous stage, each answer agent produces a refined result based on feedback. When K > 1 in Stage 1, the proposed framework generates multiple independent results, which may not be consistent. However, we aim to provide a definitive answer rather than multiple options for people to choose from. To address this, we allow up to Z rounds of free discussion among those answer agents to reach a unified answer:\nFirst, we maintain a global dialog history list, diag, recording all replies agents respond. In addition, discussions are executed asynchronously, which means that any answer agent can always reply based on the latest diag, and replies would be added to the end of diag as soon as they are posted. Each answer agent is allowed to speak only once in each discussion round, and after Z rounds of free discussion, we determine the final result using a minority-majority approach, i.e., we choose the reply with the most agreement as the final conclusion. If all agents reach a consensus, we early stop this stage and adopt the consensus answer as the final answer. If none of any consensus is reached, we only select the reply of the first answer agent elected from Stage 1 as the final result."}, {"title": "3.3 Dynamic Learning Strategy of Agent Collaboration Social Networks", "content": "In our framework, choosing the appropriate answer agents and review agents for knowledge sharing and discussion is vital to its effectiveness and efficiency. Therefore, we propose a dynamic learning strategy to optimize them. Specifically, for each training sample, i.e., a geo-tagged image, we would first estimate the optimal answer agent election probability Lst and the optimal collaboration social network of agent G by its actual location. Then we train an attention-based graph neural network, which aims to predict Lst and G, by such estimated ground truth.\nTo estimate the optimal Lst and \u00c2 for agents to geo-localize image X, we first initialize the agent social network G(0) by a fully connected graph with the agent set V. Besides, we initialize the agent election probability Lst(0) = [0.5,0.5,\u2026\u2026], with all agents having 50% probability of being chose as answer agents.\nThen, we iteratively conduct our 3-stage discussion framework to get the prediction answer. Lst(1) and G(1) is updated at the end of each round l \u2208 L by comparing the answers Y from each answer agent with the ground truth Y.\nAfter L rounds of agent discussions, the updated agent election probability for an image X, Lst := Lst(L) (X) = [P(L), P(L), ..., P(L)], determines whether an agent vi gives the correct/wrong answers Y(L) by comparing it with the ground truth \u00dd. Here, the definition of P of agent vi at round l is as follows:\n$P_{v_i}^{(l)} := \\begin{cases}\n0, & \\text{if } D(Y, Y) > th \\\\\n1, & \\text{if } D(Y, Y) < th \\\\\n\\frac{1}{2}, & \\text{if } v_i \\text{ did not participate in the discussion}\n\\end{cases}$                                  (2)\nwhere th is a pre-defined threshold for determining whether the predicted location is close enough to the actual location. In the distance function D(\u00b7), we first deploy geocoding to convert natural language into location intervals in a Web Mercator coordinate system (WGS84) by utilizing OSM APIs, and then compute the shortest distance between two two location intervals.\nPlease note that, rather than electing the top-K answer agents in each round, we choose each agent with probability Pvi during the training period to ensure that every agent has the opportunity to participate in the discussion for more accurate estimation, as shown at the left part of the dynamic learning strategy module of agent collaboration social networks in Figure 1.\nIn addition, the agent collaboration social network would also be updated by comparing the actual location with the generated answer of each answer agent at the same time. For l-th round, we strengthen the link between the correctly answered agent and the corresponding review agents while weakening the link between the incorrectly answered agent and the corresponding review agents:\n$A_{ij} := A_{ij}^{(l)} (X) = \\begin{cases}\n\\frac{2^{tt}+1}{2^{tt}} A_{ij}^{(l-1)} (X), & \\text{if agent } v_i \\text{ answers correctly} \\\\\n\\frac{2^{tt}-1}{2^{tt}} A_{ij}^{(l-1)} (X), & \\text{if agent } v_i \\text{ answers incorrectly}\n\\end{cases}$  (3)"}, {"title": "4 Experiments", "content": "To evaluate the performance of our framework, we conducted experiments on the real-world dataset that was gathered from the Internet to answer the following research questions:\n\u2022 RQ1: Can smileGeo outperform state-of-the-art methods in open-ended geo-localization tasks?\n\u2022 RQ2: Are LVLM agents with diverse knowledge and reasoning abilities more suitable for building a collaboration social network of agents?\n\u2022 RQ3: How does the setting of hyperparameters affect the performance of smileGeo?"}, {"title": "4.1 Experiment Setup", "content": "Datasets. In this paper, we newly construct a geo-localization dataset named GeoGlobe. It contains a variety of man-made landmarks or natural attractions from nearly 150 countries with different cultural and regional styles. The diversity and richness of GeoGlobe allow us to evaluate the performance of different models more accurately. More details can be found in Appendix B.\nImplemention Details. We select both open-source and close-source LVLMs with different scales trained by different datasets as agents in the proposed framework. As for the open-source LVLMs, we utilize several open-source fine-tuned LVLMs: Infi-MM\u00b9, Qwen-VL 2, vip-llava\u20137b&13b3, llava-1.5-7b-base&mistral&vicuna\u2074, llava\u20131.6\u20137b&13b&34b-mistral&vicuna, CogVLM6. As for the closed-source LVLMs, we chose the models provided by three of the most famous companies in the world: Claude-3-opus7, GPT\u20134V8, and Gemini\u20131.5\u2013pro 9. Besides, 99% of images (about 290,000 samples) from the original dataset are randomly chosen as training samples. For the open-world geolocation problem, we construct the test dataset using approximately 4,000 samples, of which nearly 66.67% samples reflected different locations not present in the training dataset. More details about the deployment of smileGeo and the related parameter settings can be found in Appendix C.\nBaselines. In this work, we compare the proposed framework with three kinds of baselines: single LVLMS, LLM/LVLM-based multi-agent frameworks, and image retrieval approaches. Firstly, we use each LVLM alone as an agent directly for the geo-localization task and compute the performance of these single LVLMs under the same dataset. In addition, we experiment with multi-agent collaborative frameworks, including LLM-Blender [34], PHP [35], Reflexion [36], LLM Debate [37], and DyLAN [38]. Finally, several state-of-the-art image retrieval approaches, including NetVLAD [3], GeM [26], and CosPlace [46], are also used to be part of the baselines. We set the training dataset as the geo-tagged image database of each image retrieval system and use images in the test dataset for the retrieval system to generate answers.\nEvaluation Metrics. We use Accuracy (Acc) to evaluate the performance: Accuracy = $\\frac{N_{\\text{correct}}}{N_{\\text{total}}}$, where Ncorrect is the number of samples that the proposed framework correctly geo-localizes, and Ntotal refers to the total number of testing samples.\nIn this paper, we first geo-encode the answers with the ground truth, i.e., we transform the addresses described through natural language into latitude-longitude coordinates. Then, we calculate the distance between the two coordinates. When the distance between the two coordinates is less than th = 50km (city-level), we consider the answer of the framework to be correct."}, {"title": "4.2 Performance Comparison", "content": "We divide the baseline comparison experiment into three parts: i) comparison with single LVLMs, ii) comparison with LLM/LVLM-based agent frameworks, and iii) comparison with image retrieval systems."}, {"title": "4.3 Ablation Study", "content": "Number of Agents. We further demonstrate the relationships between the number of agents and the framework performance. We conduct experiments in two ways: i) by calling the same closed-source LVLM API (Here, we use Gemini-1.5-pro because it performs best without the help of the Internet) under different prompts (e.g., You are good at recognizing natural attractions; You're a traveler around Europe) to simulate different agents, and ii) by using different LVLM backbones to represent distinct agents. The results are shown in Figure 2."}, {"title": "5 Conclusion", "content": "This work introduces a novel LVLM agent framework, smileGeo, specifically designed for geo-localization tasks. Inspired by the review mechanism, it integrates various LVLMs to discuss anonymously and geo-localize images worldwide. Additionally, we have developed a dynamic learning strategy for agent collaboration social networks, electing appropriate agents to geo-localize each image with different characteristics. This enhancement reduces the computational burden associated with collaborative discussions among LVLM agents. Moreover, we have constructed a geo-localization dataset called GeoGlobe and will open-source it. Overall, smileGeo demonstrates significant improvements in geo-localization tasks, achieving superior performance with lower computational demands compared to contemporary state-of-the-art LLM/LVLM agent frameworks.\nLooking ahead, we aim to expand the capabilities of smileGeo to incorporate more powerful external tools beyond just web searching. Additionally, we plan to explore extending its application to complex scenarios, such as high-precision global positioning and navigation for robots, laying the cornerstone for exploring LVLM agent collaboration to handle different complex open-world tasks efficiently."}, {"title": "A Notations", "content": "We summarize all notations in this paper and list them in Table 4."}, {"title": "B Dataset Details", "content": "The images in this dataset are copyright-free images obtained from the Internet via a crawler. We divide the images into two main categories: man-made landmarks as well as natural attractions. Then, we filter out the data samples that could clearly identify the locations of the landmarks or attractions in the images. As a result, we filter out nearly three hundred thousand data samples, and please refer to Table 5 and Figure 4 for details. Due to the fact that a large number of natural attractions in different geographical regions with high similarity are cleaned, the magnitude of the data related to natural attractions in this dataset is smaller than that of man-made attractions."}, {"title": "C Implementation Details", "content": "In all experiments, we employ a variety of LVLMs, encompassing both open-source and closed-source models, to be agents in the proposed framework. Unless specified otherwise, zero-shot prompting is applied. Each open-source LVLM is deployed on a dedicated A800 (80G) GPU server with 200GB memory. As for each closed-source LVLM, we cost amounting to billions of tokens by calling APIs as specified by the official website. To avoid the context length issue that occurs in some LVLMs, we truncate the context before submitting it to the agent for questions based on the maximum number of"}, {"title": "D Additional Experiments", "content": "D.1 Parametric Analysis\nMaximum Number of Discussion Rounds. A limited number of discussion rounds may cause the framework to overly rely on the agent selection model, preventing it from fully leveraging the capabilities of the entire framework. Conversely, too many discussion rounds could reduce the efficiency of model execution and introduce redundant information. To address this, we conducted experiments varying the maximum number of discussions, with results presented in Table 6. As shown, increasing the maximum number of discussion rounds leads to an exponential decrease in the framework's efficiency. Based on these findings, we set the maximum number of rounds to 10 in our framework, which improves model accuracy by over 3% compared to relying solely on agent selection without any discussion.\nD.2 Case Study\nCase 1: In Figure 5, we illustrate the application of smileGeo in a visual geo-localization task. For this demonstration, we randomly select an image from the test dataset and employ five distinct LVLMS: LLaVA, GPT-40 mini, Claude-3, Gemini, and Qwen. The agent selection model selects two answer agents, as depicted in the top part of the figure. Subsequently, stages 1 through 3 detail the process of generating the accurate geo-location. Initially, only one answer agent provided the correct response. However, after several rounds of discussion, the agent that initially responded incorrectly revised the confidence level of its answer. During the final internal discussion, this agent aligned its response with the correct answer. This outcome validates the efficacy of our proposed framework, demonstrating its ability to integrate the knowledge and reasoning capabilities of different agents to enhance the overall performance of the proposed LVLM agent framework.\nCase 2: This case study illustrates the need to pinpoint the geographical location of a complete image based on only a portion of it, as demonstrated in 6(a). As illustrated in Figure 6(b), all agents recognized the Statue of Liberty in Figure 6(a), and some identified the presence of part of the Eiffel Tower at the edge of the picture. For instance, GPT-40 mini concluded that the buildings in these two locations appeared in the same image. However, as is known through the knowledge of other agents (Gemini), a scaled-down version of the Statue of Liberty has been erected on Swan Island, an artificial island in the Seine River in France. By marking both the Eiffel Tower and the island on the Open Street Map (OSM) manually, as shown in Figure 6(c), it is evident that they are merely 1.3 kilometers apart in a straight line. By utilizing the proposed framework, agents discuss and summarize the location depicted in the picture to be Paris, France, as shown in Figure 6(d). Thus, without human intervention, this framework demonstrates the effectiveness of doing geo-localization tasks."}]}