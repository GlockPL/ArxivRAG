{"title": "Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework", "authors": ["Xiao Han", "Chen Zhu", "Xiangyu Zhao", "Hengshu Zhu"], "abstract": "Visual geo-localization demands in-depth knowledge and advanced reasoning skills to associate images with real-world geographic locations precisely. In general, traditional methods based on data-matching are hindered by the impracticality of storing adequate visual records of global landmarks. Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability of geo-localization through Visual Question Answering (VQA), enabling a solution that does not require external geo-tagged image records. However, the performance of a single LVLM is still limited by its intrinsic knowledge and reasoning capabilities. Along this line, in this paper, we introduce a novel visual geo-localization framework called smileGeo that integrates the inherent knowledge of multiple LVLM agents via inter-agent communication to achieve effective geo-localization of images. Furthermore, our framework employs a dynamic learning strategy to optimize the communication patterns among agents, reducing unnecessary discussions among agents and improving the efficiency of the framework. To validate the effectiveness of the proposed framework, we construct GeoGlobe, a novel dataset for visual geo-localization tasks. Extensive testing on the dataset demonstrates that our approach significantly outperforms state-of-the-art methods.", "sections": [{"title": "Introduction", "content": "Visual geo-localization, referred to the task of estimating geographical identification for a given image, is vital in various fields such as human mobility analysis [1, 2, 3, 4, 5] and attraction recommendations [6, 7, 8, 9, 10, 11]. In general, accurate visual geo-localization without the help of any localization equipment (e.g., GPS sensors) is a complex task that requires abundant geospatial knowledge and strong reasoning capabilities. Traditional methods [12, 13, 14, 15] typically formulate it as an image retrieval problem where to geo-localize the given image by retrieving similar images with known geographical locations. Thus, their effectiveness is limited by the scope and quality of the geo-tagged image records.\nRecently, the success of Large Vision-Language Models (LVLMs) has enabled Visual Question Answering (VQA) to become a unified paradigm for multi-modal problems [16, 17], providing a novel solution for visual geo-localization without the need for external geo-tagged image records. However, the performance of a single LVLM on the geo-localization task is still limited by its inherent geospatial knowledge and reasoning capabilities. Along this line, in this paper, we introduce a novel multi-agent framework, named swarm intelligence Geo-localization (smileGeo), which aims to adaptively integrate the inherent knowledge and reasoning capabilities of multiple LVLMs to effectively and efficiently geo-localize images. Specifically, for a given image, the framework initially elects K suitable LVLM agents as answer agents for initial location analysis. Then, each answer agent chooses several review agents via an adaptive social network, which imitates the collaborative relationships between agents with a target on the visual geo-localization task, to discuss and share their knowledge for refining its location analysis. Finally, our framework conducts free discussion among all of the answer agents to reach a consensus. Besides, we also design a novel dynamic learning strategy to optimize the election mechanism along with the adaptive collaboration social network of agents. We hope that by the effectiveness of the election mechanism and the review mechanism, our framework can discover the mode of communication among agents, thereby enhancing geo-localization performance through multi-agent collaboration while minimizing unnecessary discussions. In summary, our contributions are demonstrated as follows:\n\u2022 A novel swarm intelligence geo-localization framework, smileGeo, is proposed to adaptively integrate the inherent knowledge and reasoning capability of multiple LVLMs through discussion for visual geo-localization tasks.\n\u2022 A dynamic learning strategy is introduced to discover the most appropriate discussion mode among LVLM agents for enhancing the effectiveness and efficiency of the framework.\n\u2022 A new visual geo-localization dataset named GeoGlobe is collected, containing a wide variety of images globally. The diversity and richness of GeoGlobe allow us to evaluate the performance of different models more accurately. Moreover, extensive experiments demonstrate our competitive performance compared to state-of-the-art methods.\nThe remainder of this paper is organized as follows: Section 2 discusses the related literature. In Section 3, the proposed framework is introduced. Section 4 provides the performance evaluation, and Section 5 concludes the paper."}, {"title": "Related Work", "content": "Visual Geo-localization. Recent research in visual geo-localization, commonly referred to as geo-tagging, primarily focuses on developing image retrieval systems to address this challenge [3, 18, 19, 20, 21, 22]. These systems utilize learned embeddings generated by a feature extraction backbone, which includes an aggregation or pooling mechanism [23, 24, 25, 26]. However, the applicability of these retrieval systems to globally geo-localize landmarks or natural attractions is often limited by the constraints of the available database knowledge and the restrictions imposed by national or regional geo-data protection laws. Alternatively, some studies treat visual geo-localization as a classification problem [27, 28, 29, 30]. These approaches posit that two images from the same geographical region, despite depicting different scenes, typically share common semantic features. Practically, these methods organize the geographical area into discrete cells and categorize the image database accordingly. This cell-based categorization facilitates scaling the problem globally, provided the number of categories remains manageable. However, while the number of countries globally remains relatively constant, accurately enumerating cities in real-time at a global scale is challenging due to frequent administrative changes, such as city reorganizations or mergers, which reflect shifts in national policies. Additionally, in the context of globalization, this strategy has inherent limitations. The recent advent of LVLMs offers promising compensatory mechanisms for the deficiencies observed in traditional geo-localization methodologies, making the exploration of LVLM-based approaches significantly relevant in current research.\nMulti-agent Framework for LLM/LVLMs. LLM/LVLM agents have demonstrated the potential to act like human [31, 32, 33], and a large number of studies have focused on developing robust architectures for collaborative LLM/LVLM agents [34, 35, 36, 37, 38]. These architectures enable each LLM/LVLM agent that endows with unique capabilities to engage in debates or discussions. For instance, [34] proposes an approach to aggregate multiple LLM/LVLM responses by generating candidate responses from various LLM/LVLM in a single round and employing pairwise ranking to synthesize the most effective response. While some studies [34] utilize a static architecture potentially limiting the performance and generalization of LLM/LVLM, others like [38] have implemented dynamic interaction architectures that adjust according to the query and incorporate user feedback. Recent advancements also demonstrate the augmentation of LLM/LVLM as autonomous agents"}, {"title": "Methodology", "content": "In this section, we first present the overall framework and then introduce each part of smileGeo in detail for geo-localization tasks.\n3.1 Model Overview\nIn this paper, we denote the social network of LVLM agents by G, where G = {V, E}.V stands for the agent set and & presents the edge set. Each agent \\(v_i \\in V\\), \\(i \\in [N]\\) is an LVLM, which is pre-trained by massive vision-language data and can infer the possible location Y of a given image X. Besides, each edge \\(e_{ij} \\in E, i, j \\in [N]\\) is the connection weighted by the improvement effect of agent \\(v_i\\) to agent \\(v_j\\) via discussion regarding the geo-localization performance.\nAs illustrated in Figure 1, smileGeo contains the process of the review mechanism in agent discussions along with a dynamic learning strategy of agent social networks:\nThe review mechanism in agent discussions is a 3-stage anonymous collaboration approach to allow LVLM agents to reach a consensus via discussion. In the first stage, for a given image X, our framework elects the most suitable K agents as answer agents by agent election probability Lst. In the second stage, these answer agents respectively select R review agents by the adaptive collaboration social network A to refine their answer via discussion. Finally, our framework facilitates consensus among all agents through open discussion to reach a final answer. Both Lst and A are analyzed from the given image X, allowing our framework to minimize unnecessary discussions, thereby significantly enhancing its efficiency while maintaining its accuracy. Moreover, the multi-stage discussion facilitates communication among agents, maximizing the integration of their knowledge and reasoning abilities to generate an accurate response Y.\nTo get Lst and A, we specifically design a dynamic learning module, which initially deploys the encoder component of a pre-trained image variational autoencoder (VAE) to extract features from the given image X. The extracted features, combined with agent embeddings Emb, are employed to determine the suitability of agents w.r.t. Lst for agent discussions and predict agent collaboration connections A in the geo-localization task.\n3.2 Review Mechanism in Agent Discussions\nLLM/LVLM have demonstrated remarkable capabilities in complicated tasks and some pioneering works have further proven that the performances can be further enhanced by ensembling multiple LLM/LVLM agents. Thus, to improve the geo-localization capability of LVLMs, we propose a cooperation framework to effectively integrate the diverse knowledge and reasoning abilities of multiple LVLMs. Inspired by the fact that community review mechanisms can improve the quality of manuscripts, an iterative 3-stage anonymous reviewing mechanism is proposed for helping agents share knowledge and reasoning capability with each other through their collaboration social network: i) answer agent election & answering, ii) review agent selection & reviewing, and iii) final answer conclusion.\nStage 1: Answer Agent Election & Answering\nInitially, we select K agents with the highest agent election probabilities Lst as answer agents and let them geo-localize independently as the preliminary step for further discussion. By initiating the discussion with a limited number of agents, we aim to reduce potential chaos and maintain the efficiency of our framework as the number of participating agents increases."}, {"title": "Dynamic Learning Strategy of Agent Collaboration Social Networks", "content": "In our framework, choosing the appropriate answer agents and review agents for knowledge sharing and discussion is vital to its effectiveness and efficiency. Therefore, we propose a dynamic learning strategy to optimize them. Specifically, for each training sample, i.e., a geo-tagged image, we would first estimate the optimal answer agent election probability Lst and the optimal collaboration social network of agent G by its actual location. Then we train an attention-based graph neural network, which aims to predict Lst and G, by such estimated ground truth.\nTo estimate the optimal Lst and \\(\\hat{A}\\) for agents to geo-localize image X, we first initialize the agent social network \\(G^{(0)}\\) by a fully connected graph with the agent set V. Besides, we initialize the agent election probability \\(Lst^{(0)} = [0.5,0.5,\u2026\u2026]\\), with all agents having 50% probability of being chose as answer agents.\nThen, we iteratively conduct our 3-stage discussion framework to get the prediction answer. \\(Lst^{(1)}\\) and \\(G^{(1)}\\) is updated at the end of each round \\(l \\in L\\) by comparing the answers \\(\\hat{Y}_{v_i}\\) from each answer agent with the ground truth Y.\nAfter L rounds of agent discussions, the updated agent election probability for an image X, Lst := \\(Lst^{(L)}(X) = [P_{v_1}^{(L)}, P_{v_2}^{(L)}, ..., P_{v_N}^{(L)}]\\), determines whether an agent \\(v_i\\) gives the correct/wrong answers \\(\\hat{Y}_{v_i}^{(L)}\\) by comparing it with the ground truth \\(\\hat{Y}\\). Here, the definition of \\(P_{v_i}^{(l)}\\) of agent \\(v_i\\) at round l is as follows:\n\\[P_{v_i}^{(l)} := \\begin{cases}\n0, & \\text{if } D(\\hat{Y}_{v_i}, \\hat{Y}) > th \\\\\n1, & \\text{if } D(\\hat{Y}_{v_i}, \\hat{Y}) < th \\\\\n\\frac{1}{2}, & \\text{if } v_i \\text{ did not participate in the discussion}\n\\end{cases}\\]\nwhere th is a pre-defined threshold for determining whether the predicted location is close enough to the actual location. In the distance function D(\u00b7), we first deploy geocoding to convert natural language into location intervals in a Web Mercator coordinate system (WGS84) by utilizing OSM APIs, and then compute the shortest distance between two two location intervals.\nPlease note that, rather than electing the top-K answer agents in each round, we choose each agent with probability \\(P_{v_i}\\) during the training period to ensure that every agent has the opportunity to participate in the discussion for more accurate estimation, as shown at the left part of the dynamic learning strategy module of agent collaboration social networks in Figure 1.\nIn addition, the agent collaboration social network would also be updated by comparing the actual location with the generated answer of each answer agent at the same time. For l-th round, we strengthen the link between the correctly answered agent and the corresponding review agents while weakening the link between the incorrectly answered agent and the corresponding review agents:\n\\[A_{ij}^{(l)} := A_{ij}^{(l-1)}(X) = \\begin{cases}\n\\frac{2tt+1}{2tt} A_{ij}^{(l-1)}(X), & \\text{if agent } v_i \\text{ answers correctly} \\\\\n\\frac{2tt-1}{2tt} A_{ij}^{(l-1)}(X), & \\text{if agent } v_i \\text{ answers incorrectly}\n\\end{cases}\\]\nwhere \\(A_{ij}^{(l-1)}(X)\\) is the weight of the connection between answer agent \\(v_i\\) and review agent \\(v_j\\) at round l \u2013 1 when geo-locating image X, \\(A_{ij}^{(0)}(X) = 1, i \\neq j, A_{ij}^{(0)}(X) = 0, i, j \\in [N]\\), tt is the number of consecutive times an agent has answered correctly, which is used to attenuate the connection weights when updating them, preventing the performance of an agent on a certain portion of the continuous dataset from interfering with the model's evaluation of the current agent's performance on the entire dataset.\nThen, we try to learn an attention-based graph neural network to predict the corresponding optimal agent election probability Lst = h(X,G|\u0398) and the optimal agent collaboration connections A = f(X,V|\u0398):\n\\[A = AttGNN (Fea, Fea, 1) = softmax(\\frac{Fea \\cdot Fea^T}{\\sqrt{d_k}}),\\\\\nLst = \\sigma' (Linear (Flatten (\\sigma (A \\cdot Fea \\cdot W)))),\\\\\nFea = Linear (Emb + VAEEnc(X)),\\]\nwhere W, Emb \\(\\in \\mathbb{R}\\) are two learnable parameters, \\(Emb := [Emb_{v_1}, Emb_{v_2},\u2026\u2026]^T\\) is the agent embedding and W is the weight matrix, \\(\\sigma(\\cdot)\\) is the LeakyReLU function, \\(\\sigma'(\\cdot)\\) is the Sigmoid function, VAEEnc() is the encoder of the image VAE that compresses and maps the image data into the latent space. It is used to align the image features with the agent embedding, and dk is the dimension of the Fea. Our learning target can be formalized as:\n\\[arg \\underset{\\Theta}{min} \\sum_{V_i}D(\\hat{Y}, Y_{v_i})1(v_i \\text{ gives an answer}) + MSE(Lst, Lst) + MSE(\\hat{A}, A),\\]\nwhere D(.) denotes the distance between the places an LVLM agent answered and the ground truth, 1(.) is the indicator function, \\(Y_{v_i} := Y_{v_i}^{(L)} = g_{v_i} (X, Y_{v_i}^{(l-1)})\\), \\(g_{v_i} (\\cdot)\\) represent the LVLM agent \\(v_i\\) with fixed parameters and \\(Y_{v_i}^{(0)} = g_{v_i} (X)\\) is the answer that LVLM agent \\(v_i\\) generates at the initial stage of discussion."}, {"title": "Experiments", "content": "To evaluate the performance of our framework, we conducted experiments on the real-world dataset that was gathered from the Internet to answer the following research questions:\n\u2022 RQ1: Can smileGeo outperform state-of-the-art methods in open-ended geo-localization tasks?\n\u2022 RQ2: Are LVLM agents with diverse knowledge and reasoning abilities more suitable for building a collaboration social network of agents?\n\u2022 RQ3: How does the setting of hyperparameters affect the performance of smileGeo?\n4.1 Experiment Setup\nDatasets. In this paper, we newly construct a geo-localization dataset named GeoGlobe. It contains a variety of man-made landmarks or natural attractions from nearly 150 countries with different cultural and regional styles. The diversity and richness of GeoGlobe allow us to evaluate the performance of different models more accurately. More details can be found in Appendix B.\nImplemention Details. We select both open-source and close-source LVLMs with different scales trained by different datasets as agents in the proposed framework. As for the open-source LVLMs, we utilize several open-source fine-tuned LVLMs: Infi-MM\u00b9, Qwen-VL \u00b2, vip-llava\u20137b&13b\u00b3, llava-"}, {"title": "Performance Comparison", "content": "We divide the baseline comparison experiment into three parts: i) comparison with single LVLMs, ii) comparison with LLM/LVLM-based agent frameworks, and iii) comparison with image retrieval systems."}, {"title": "Ablation Study", "content": "Number of Agents. We further demonstrate the relationships between the number of agents and the framework performance. We conduct experiments in two ways: i) by calling the same closed-source LVLM API (Here, we use Gemini-1.5-pro because it performs best without the help of the Internet) under different prompts (e.g., You are good at recognizing natural attractions; You're a traveler around"}, {"title": "Conclusion", "content": "This work introduces a novel LVLM agent framework, smileGeo, specifically designed for geo-localization tasks. Inspired by the review mechanism, it integrates various LVLMs to discuss anonymously and geo-localize images worldwide. Additionally, we have developed a dynamic learning strategy for agent collaboration social networks, electing appropriate agents to geo-localize each image with different characteristics. This enhancement reduces the computational burden associated with collaborative discussions among LVLM agents. Moreover, we have constructed a geo-localization dataset called GeoGlobe and will open-source it. Overall, smileGeo demonstrates significant improvements in geo-localization tasks, achieving superior performance with lower computational demands compared to contemporary state-of-the-art LLM/LVLM agent frameworks.\nLooking ahead, we aim to expand the capabilities of smileGeo to incorporate more powerful external tools beyond just web searching. Additionally, we plan to explore extending its application to complex scenarios, such as high-precision global positioning and navigation for robots, laying the cornerstone for exploring LVLM agent collaboration to handle different complex open-world tasks efficiently."}, {"title": "Notations", "content": "We summarize all notations in this paper and list them in Table 4."}, {"title": "Dataset Details", "content": "The images in this dataset are copyright-free images obtained from the Internet via a crawler. We divide the images into two main categories: man-made landmarks as well as natural attractions. Then, we filter out the data samples that could clearly identify the locations of the landmarks or attractions in the images. As a result, we filter out nearly three hundred thousand data samples, and please refer to Table 5 and Figure 4 for details. Due to the fact that a large number of natural attractions in different geographical regions with high similarity are cleaned, the magnitude of the data related to natural attractions in this dataset is smaller than that of man-made attractions.\nFor an open-world geo-localization task, the relationship between the training and test samples in the experiment could greatly affect the results. We label the training samples as Ztrain, and the test sample set as Ztest, and use two metrics, coverage as well as consistency, to portray this relationship:\n\\[coverage = \\frac{Z_{train} \\cap Z_{test}}{Z_{train}} \\times 100% \\\\\nconsistency = \\frac{Z_{train} \\cap Z_{test}}{Z_{test}} \\times 100%\\]\nAs for the samples in this paper, coverage \u2248 4.6564%, and consistency \u2248 33.2957%."}, {"title": "Implementation Details", "content": "In all experiments, we employ a variety of LVLMs, encompassing both open-source and closed-source models, to be agents in the proposed framework. Unless specified otherwise, zero-shot prompting is applied. Each open-source LVLM is deployed on a dedicated A800 (80G) GPU server with 200GB memory. As for each closed-source LVLM, we cost amounting to billions of tokens by calling APIs as specified by the official website. To avoid the context length issue that occurs in some LVLMs, we truncate the context before submitting it to the agent for questions based on the maximum number of"}, {"title": "The smileGeo framework", "content": "tokens that each agent supports. Besides, noting that images are token consuming, we only keep the freshest response for agent discussions.\nThe detailed algorithm of smileGeo is illustrated in Algorithm 1. In the initialization stage, we initialize or load the parameters of the agent social network learning model, as delineated in line 1. Next, we treat each LVLM agent as a node, establishing the LVLM agent collaboration social network and computing the adjacency relationships among LVLM agents as well as the probability that each agent is suited for responding to image X, as shown in line 2. Then, line 3 initializes the agent"}]}