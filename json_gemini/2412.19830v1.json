{"title": "A Unified Framework for Context-Aware IoT Management and State-of-the-Art IoT Traffic Anomaly Detection", "authors": ["Daniel Adu Worae", "Athar Sheikh", "Spyridon Mastorakis"], "abstract": "The rapid expansion of Internet of Things (IoT) ecosystems has introduced growing complexities in device management and network security. To address these challenges, we present a unified framework that combines context-driven large language models (LLMs) for IoT administrative tasks with a fine-tuned anomaly detection module for network traffic analysis. The framework streamlines administrative processes such as device management, troubleshooting, and security enforcement by harnessing contextual knowledge from IoT manuals and operational data. The anomaly detection model achieves state-of-the-art performance in identifying irregularities and threats within IoT traffic, leveraging fine-tuning to deliver exceptional accuracy. Evaluations demonstrate that incorporating relevant contextual information significantly enhances the precision and reliability of LLM-based responses for diverse IoT administrative tasks. Additionally, resource usage metrics-such as execution time, memory consumption, and response efficiency-demonstrate the framework's scalability and suitability for real-world IoT deployments.", "sections": [{"title": "I. INTRODUCTION", "content": "The Internet of Things (IoT) is projected to surpass 30 billion interconnected devices by 2030 [1], revolutionizing industries through automation and data-driven decision-making. Despite its transformative potential, this rapid growth has introduced significant administrative challenges. Managing the heterogeneity and interconnectivity of IoT devices requires administrators to address complex tasks such as configuring devices securely, troubleshooting, and maintaining network integrity. The increasing sophistication of cyber threats exacerbates these challenges, demanding intelligent solutions that ensure operational efficiency and robust security.\nLLMs, such as GPT-4, are promising tools for assisting IoT administrators by providing insights and answering queries across a wide range of tasks [2]. However, their application in IoT environments is hindered by critical limitations, particularly their tendency to hallucinate-generating plausible yet incorrect responses and reliance on potentially outdated training data. These shortcomings can lead to unreliable outcomes in administrative scenarios where precision is critical. For instance, an administrator might need immediate, precise answers to questions like, \u201cWhat are the recommended security configurations for a newly deployed IoT device?\u201d or \u201cHow can I identify and mitigate a coordinated cyberattack targeting multiple IoT endpoints without risking operational downtime?\u201d A hallucinated response in such cases could lead to severe misconfigurations or overlooked threats, with cascading consequences for network operations and security.\nRAG provides a promising solution to address these limitations by dynamically integrating external knowledge repositories. RAG grounds LLM outputs in reliable, domain-specific information [3]\u2013[7]. This approach significantly improves response accuracy and contextual relevance, equipping administrators with dependable insights for managing IoT devices and networks effectively. Figure 1 illustrates RAG's impact, showing significant performance gains across five IoT use cases with contextual augmentation, while its absence leads to poorer outcomes, emphasizing its critical role.\nAnomaly detection is another critical aspect of IoT management, particularly for identifying potential cyber threats or operational anomalies. This requires nuanced analysis to uncover subtle patterns in network traffic indicative of malicious activities or device malfunctions. Transformer-based models like BERT [8], renowned for their ability to understand contextual relationships, are particularly well-suited for this task. By finetuning BERT on IoT-specific datasets, administrators can achieve precise anomaly detection, enabling proactive responses to emerging security threats. This capability is essential for maintaining IoT ecosystem integrity.\nThis work introduces a first-of-its-kind IoT management framework that unifies RAG-enhanced LLMs for context-aware question answering with a fine-tuned BERT model for anomaly detection. To the best of our knowledge, this is the only framework explicitly designed to address the unique challenges of administrative management in IoT environments, providing actionable insights and precise anomaly detection tailored to the complexities of IoT ecosystems. By bridging these critical gaps, the framework offers a comprehensive solution for administrators managing IoT networks securely and efficiently.\nTo advance the understanding and effectiveness of the framework, we explore the following key research questions:\n\u2022 RQ1: How does integrating RAG with LLMs impact the accuracy and reliability of responses for IoT administrative tasks, including device management, security and privacy, troubleshooting, maintenance, and device setup?\n\u2022 RQ2: How effective is a fine-tuned BERT model in detecting nuanced anomalies within IoT traffic, and what critical insights can it provide to preempt cybersecurity threats and operational disruptions?\n\u2022 RQ3: How can a unified framework effectively integrate RAG-based contextual question answering with BERT-based anomaly detection to address the operational and security challenges IoT administrators face?\nTo answer these research questions, we make the following contributions:\n\u2022 We introduce a first-of-its-kind IoT management framework that integrates RAG with LLMs to provide accurate, context-aware responses for administrative tasks, including device setup, maintenance, security, and troubleshooting.\n\u2022 The framework incorporates a fine-tuned BERT model for nuanced anomaly detection in IoT traffic, achieving an accuracy of 99.87% on the Edge-IIoTset dataset."}, {"title": "II. SYSTEM DESIGN", "content": "This paper proposes a framework that integrates a context-aware generation module and a fine-tuned BERT-based anomaly detection module, as illustrated in Figures 2 and 3. The framework addresses two critical challenges in IoT ecosystems: providing accurate, domain-specific responses to administrative queries and ensuring real-time detection of cyber threats and anomalies in network traffic. The system achieves this through a modular design, where each component operates cohesively to enhance operational efficiency and security. This section outlines the architecture, interactions, and functionality of these components, forming a robust and scalable solution for modern IoT environments.\n\nA. Context-Aware Generation Module\nThis module operates in two phases: Indexing and Query Processing. During indexing, IoT manuals, documents, and other domain-specific resources are preprocessed, chunked, and stored as vector embeddings in a vector database. During query processing, an administrator's query is transformed into a vector representation, compared with the stored vectors, and augmented with the most relevant knowledge chunks before being passed to the LLM for final answer generation, as shown in Figure 4. This ensures that the LLM produces domain-specific and accurate responses."}, {"title": "1) IoT Knowledge Repository:", "content": "\u2022 Content Sources The IoT knowledge repository consists of device manuals, troubleshooting guides, FAQs, and other domain-specific resources. These documents form the backbone of the knowledge hub, ensuring that responses to administrator queries are grounded in accurate, specialized information.\n\u2022 Preprocessing: Documents are parsed and preprocessed to remove irrelevant content (e.g., metadata, unrelated sections). The cleaned documents are then divided into manageable chunks, ensuring each chunk contains semantically meaningful information.\n\u2022 Vectorization: Each chunk is passed through an embedding model (e.g., sentence transformers) to convert into a high-dimensional vector representation. These embeddings capture the semantic meaning of the text and are stored in the vector database.\n2) Vector Database (Knowledge Hub): The vector database stores embeddings of document chunks together with the chunks and enables efficient similarity search for relevant knowledge. In our implementation, we use Chroma to manage these embeddings, leveraging its ability to handle large-scale vectorized data while supporting persistence for future use.\nDuring indexing, IoT manuals are loaded from the data directory and processed using PyPDFDirectoryLoader. Documents are split into smaller, semantically meaningful chunks (800 characters with 80character overlap) using RecursiveCharacterTextSplitter. Each chunk is converted into an embedding using a custom embedding function, with metadata such as source file, page number, and a unique chunk ID assigned for precise identification.\nTo prevent duplication, the system compares chunk IDs with existing entries in the database. Only new chunks are added, and the database is persisted to ensure efficient future retrieval. This approach provides scalability and accuracy while maintaining a streamlined knowledge base for IoT-specific query processing.\n3) Query Processing Workflow:\n\u2022 Query Vectorization: When the IoT administrator submits a query (e.g., \"What steps should I follow to fix Amazon Echo when it cannot control smart locks?\"), the query text is passed through the same embedding model used during the indexing phase. This converts the query into a vector representation, ensuring consistency in how text is represented.\n\u2022 Similarity Search: The query embedding is compared to the embeddings in the vector database using a similarity metric (e.g., cosine similarity). This process identifies the chunks of knowledge most semantically similar to the query.\n\u2022 Knowledge Retrieval: The system retrieves the top-ranked chunks from the vector database. These chunks serve as the relevant context for the query, ensuring that the subsequent response generation is grounded in accurate domain-specific knowledge.\n\u2022 Context Augmentation: The retrieved knowledge chunks are concatenated with the user query to form an augmented input. This input is structured as a prompt for the LLM, ensuring the model generates answers based on the query and the retrieved domain-specific context.\n4) Large Language Model: The LLM (e.g., llama or similar model) processes the augmented input and generates a contextually relevant and precise response. By leveraging the retrieved knowledge, the model addresses out-of-date training data, avoids hallucination, and delivers answers tailored to IoT-specific queries. The response is then returned to the IoT administrator for actionable insights."}, {"title": "B. Transformer-Based Anomaly Detection Module", "content": "This module uses a fine-tuned BERT model to detect anomalies in IoT network traffic by identifying complex patterns and contextual relationships. It strengthens IoT security by addressing cyber threats and device malfunctions in real-time, enhancing system reliability.\n1) Dataset Utilization: Generating a dataset through real-life IoT traffic analysis is time-intensive and risks omitting critical attack scenarios. To address this, we prioritize the use of realistic and diverse datasets that represent genuine network conditions. The Edge-IIoTset dataset [9] provides a comprehensive cybersecurity resource designed specifically for IoT and IIoT applications. It includes fifteen attack types across five major threat categories: DoS/DDoS, Information Gathering, Man-in-the-Middle (MITM), Injection, and Malware. These attacks encompass techniques such as TCP SYN flood, port scanning, DNS spoofing, SQL injection, and ransomware, making the dataset highly representative of real-world IoT threats. Its diversity and focus on IoT connectivity protocols ensure its alignment with our research objectives for anomaly detection and classification.\n2) Feature Selection and Data Preprocessing: Network traffic logs in PCAP format are processed to extract features over a defined time window, resulting in structured data suitable for analysis. Each network flow is identified and analyzed to extract a predefined set of features stored in CSV format for efficient processing. The Edge-IIoTset dataset, after preprocessing to remove null features, provides 61 distinct attributes sourced from network traffic, system logs, resource usage, and alerts. However, not all features are suitable for effective modeling. Features with high cardinalities, such as \u201chttp.request.full_uri\u201d, or those prone to overfitting, like \"ip.src_host\" and \"ip.dst_host\", were excluded due to their limited generalizability across networks. Similarly, redundant features such as \u201carp.src.proto_ipv4\u201d and \u201cip.src_host, or features like \u201ctcp.payload\u201d containing raw data, may introduce noise or multicollinearity, reducing model stability. Removing such columns optimizes the dataset, ensuring computational efficiency while maintaining focus on relevant, generalizable patterns. This refined feature set forms a robust foundation for anomaly detection, tailored to IoT environments and capable of capturing diverse network behaviors effectively.\n3) Contextual Representation: The BERT module processes raw network data by converting it into structured, textual representations optimized for natural language processing. This transformation reformats the diverse and often semi-structured features of network traffic logs into a descriptive text format, enabling BERT to harness its advanced contextual understanding capabilities. By encapsulating each data row into a structured, natural-language-like text string, the module effectively captures underlying patterns, relationships, and contextual nuances within network traffic, facilitating more accurate and insightful analysis.\nIn this approach, every row in the dataset is converted into a single textual string made up of feature-value pairs. Each feature column is assigned a descriptive label, and its corresponding value is appended using a delimiter, such as a colon. For example, a feature representing source IP might appear as ip.src: 192.168.1.1. All feature-value pairs for a row are concatenated into a single text string, creating a comprehensive representation of the network flow.\nColumns such as labels or target variables are excluded during this transformation to ensure the focus remains on the input features. The resulting textual representations are stored in a structured format, such as a new column in the dataset, and are used as input for the BERT model. This structured approach allows BERT to analyze network data contextually, capturing meaningful patterns that enable effective anomaly detection and threat identification.\n4) Fine Tuning the BERT module: The BERT module customizes a pre-trained BERT model for IoT anomaly detection by training it on labeled network traffic data. This phase builds upon the structured textual representations prepared in the previous stages, aligning them with the model's requirements for effective learning.\nTokenization is performed using the BERT tokenizer, which converts each textual representation into input embeddings comprising token IDs, attention masks, and segment embeddings. Padding and truncation are applied to ensure uniform input length, enabling the model to process sequences efficiently without exceeding its maximum token limit. The labeled dataset is split into training and testing subsets to support supervised learning and performance evaluation.\nThe pretrained BERT model is configured for sequence classification by adding a classification head, with output dimensions corresponding to the number of unique attack categories. The model is fine-tuned using the training dataset, leveraging tailored learning parameters, such as batch size, learning rate, and evaluation strategies, to optimize performance. During training, metrics like accuracy, precision, recall, and F1-score are computed to monitor the model's ability to detect and classify anomalies.\nThis fine-tuning process equips the BERT model with the capacity to recognize and distinguish complex patterns in IoT network traffic, ensuring robust and scalable anomaly detection.\n5) Testing and Evaluation: After fine-tuning, the BERT module is evaluated to validate its performance in detecting and classifying IoT anomalies. The evaluation is conducted using the test dataset, which contains previously unseen network traffic instances to ensure unbiased assessment.\nKey metrics such as accuracy, precision, recall, and F1-score are computed to measure the model's effectiveness. Accuracy provides an overall measure of correctness, while precision and recall evaluate the model's ability to identify anomalies without false positives or missed detections. The F1 score balances these metrics, offering a comprehensive view of the model's classification capabilities across all attack categories.\nThe testing process also generates a detailed classification report outlining the model's performance for each class. This includes insights into attack-specific precision and recall, enabling a granular understanding of how well the model distinguishes among diverse IoT attack types. This thorough testing phase solidifies the model's role as a robust anomaly detection solution capable of addressing the dynamic and complex nature of IoT network security."}, {"title": "III. EXPERIMENTAL RESULTS AND ANALYSIS", "content": "This section evaluates our framework that encompasses RAG-augmented LLMs for context-aware question answering and a fine-tuned BERT model for anomaly detection. The RAG component is analyzed across five IoT use cases to measure the benefits of contextual augmentation. At the same time, the BERT module is tested for its accuracy and robustness in detecting diverse network anomalies, addressing critical challenges in IoT administration and security.\n\nA. Context-Aware Generation Module\nThis section evaluates the RAG with LLMs module in addressing IoT-specific queries across five critical use cases: device management, maintenance, security and privacy, troubleshooting, and device setup. To assess the framework's effectiveness, we prepared a dataset of 600 curated question-answer pairs for each use case, representing realistic IoT administrative scenarios derived from device manuals, FAQs, and operational documentation. This evaluation focuses on comparing the performance of LLMs operating in two settings: noncontextual (NC) and contextual (WC), where domain-specific knowledge is dynamically retrieved using the RAG framework.\nThe analysis, summarized in Table I, is based on four state-of-the-art LLMs-Gemma2, Llama 3.2, Mistral, and Llava-with performance quantified using metrics such as BLEU, ROUGE, METEOR, and BERTScore. These metrics evaluate syntactic accuracy, linguistic quality, and semantic alignment, providing a comprehensive understanding of the framework's impact on IoT administrative tasks.\n1) Evaluation Metrics"}, {"title": "2) Use Cases and Results", "content": "a) Device Management: This encompasses routine administrative tasks such as firmware updates, performance monitoring, and device health checks. Contextual augmentation yielded substantial improvements in these tasks. Gemma2 (WC) achieved a BLEU score of 70.2, compared to 0.59 (NC), reflecting significant gains in syntactic precision. Similarly, Mistral (WC) recorded a ROUGE-L score of 75.33%, up from 9.68 (NC), demonstrating enhanced response completeness. BERTScore (WC) for Gemma2 reached 95.8%, underscoring strong semantic alignment. Additionally, the METEOR score for Llava (WC) increased to 62.63%, highlighting improved linguistic richness and relevance.\nb) Maintenance: This involves diagnostic assessments, troubleshooting, and preventive actions to ensure IoT systems remain operational and secure. Contextual augmentation produced notable enhancements in these tasks. Gemma2 (WC) achieved a BLEU score of 71.59, a dramatic improvement over 0.41 (NC). The ROUGE-L score for Mistral (WC) rose to 72.36%, reflecting increased clarity and comprehensiveness in responses. Additionally, BERTScore (WC) for Mistral reached 93.59%, compared to 83.24% (NC), highlighting semantic improvements in diagnostic insights. Llava (WC) achieved a METEOR score of 57.55%, showcasing improved coherence and linguistic quality.\nc) Security and privacy: This addresses queries focused on resolving vulnerabilities, mitigating threats, and ensuring compliance with security protocols in IoT ecosystems. These use cases showed the most pronounced gains, underscoring the framework's value. Gemma2 (WC) achieved a BLEU score of 78.71, far exceeding 0.6 (NC). Mistral (WC) recorded a BERTScore of 95.32%, compared to 83.88% (NC), reflecting its ability to generate highly semantically aligned responses. Llava (WC) also delivered a METEOR score of 67.62%, highlighting its ability to produce linguistically rich and precise outputs for security-focused queries.\nd) Troubleshooting: These tasks require step-by-step reasoning and detailed explanations to resolve IoT issues efficiently. Contextual augmentation provided significant benefits in this use case. Gemma2 (WC) achieved a BLEU score of 76.11, compared to 0.61 (NC), demonstrating enhanced response fluency. Llama 3.2 (WC) recorded a ROUGE-L score of 68.88%, reflecting improved structural depth in solutions. Furthermore, Mistral (WC) achieved a BERTScore of 94.24%, up from 83.71% (NC), emphasizing its ability to generate coherent and contextually relevant troubleshooting steps."}, {"title": "3) System Performance and Token Metrics Analysis", "content": "This analysis evaluates execution time, memory usage, GPU utilization, and token metrics, with results averaged across multiple query runs for accuracy and reliability. The findings in Table II provide critical insights into resource efficiency and token utilization across withcontext (WC) and without-context (NC) scenarios.\n1) Execution Time: Context-aware processing significantly improved execution time across all LLMs, exemplified by Gemma2 reducing from 3.8876 seconds (NC) to 0.7095 seconds (WC), a reduction of approximately 81.7%. This improvement stems from supplying the LLMs with targeted context, which eliminates extra token generation and ensures computational focus on the most relevant information.\n2) Memory Usage: Memory usage slightly increased when context was added, reflecting the additional processing required for context integration. For example, Gemma2's memory usage rose from 0.0004 MB (NC) to 0.0295 MB (WC), and similar trends were observed for other models. Despite this increase, memory usage remains negligible for administrative systems, ensuring efficient operation even in resource-constrained environments.\n3) GPU Usage: GPU utilization remained minimal across all configurations, with the highest value recorded at only 0.0022% for Llama 3.2 (WC). This demonstrates the lightweight nature of the framework and its suitability for environments with limited GPU resources.\n4) Token Metrics: Token metrics, including the average number of tokens and response size, show significant reductions in the context-aware setup across all LLMs. Notably, Llama 3.2 processed an average of 440.81 tokens (NC), which dropped to 54.99 tokens (WC), with the corresponding response size decreasing from 2248.55 bytes to 284.99 bytes. These results demonstrate the efficiency of contextual augmentation in streamlining responses and reducing unnecessary generation."}, {"title": "B. Transformer-Based Anomaly Detection Module", "content": "In this section, we assess the performance of our finetuned BERT model, which delivers an exceptional accuracy of 99.87%. This unparalleled result highlights the model's capacity to accurately identify IoT attacks within complex and realistic network environments, setting a new benchmark for anomaly detection in IoT security.\n1) Experimental Results\nWe evaluated the model's performance using standard metrics, including Accuracy, Precision, Recall, and F1-Score. The Edge-IIoTset dataset [9] was split into 80% (126,240 data points) for training and 20% (31,560 data points) for evaluation, ensuring the model was tested on unseen data to validate its anomaly detection capabilities rigorously."}, {"title": "C. Discussion", "content": "The experimental findings confirm the efficacy of the framework in addressing IoT management and security challenges. The RAG with LLM module consistently enhanced response quality, achieving up to 82.95% improvements in BLEU, ROUGE, METEOR, and BERTScore metrics. These results underscore the effectiveness of contextual augmentation in grounding LLM outputs, reducing hallucinations, and delivering precise, task-relevant responses. Resource efficiency was evident, with notable reductions in execution time and token metrics in the WC scenario, demonstrating computational optimization without compromising response quality.\nThe fine-tuned BERT module achieved a recordbreaking accuracy of 99.87%, demonstrating exceptional precision and recall across diverse IoT attack types. Critical threats, including 'MITM' and 'DDoS_TCP,' were identified with near-perfect recall, affirming the model's robustness in detecting anomalies. Minor misclassifications were limited to closely related attack types, having negligible practical impact, further highlighting the model's reliability for real-world IoT environments. By integrating these complementary modules, our framework delivers an efficient, scalable, and highaccuracy solution for IoT ecosystem management, establishing a benchmark for addressing complex, real-world challenges in the domain."}, {"title": "IV. RELATED WORK", "content": "The integration of LLMs within IoT ecosystems has opened new avenues for addressing operational challenges and enhancing security. Existing research showcases significant advancements in task modeling, reasoning, and anomaly detection tailored to IoT environments.\n\nA. Task Reasoning and Modeling\nLLMs have extended their capabilities beyond traditional text-processing tasks to include reasoning about physical-world IoT systems. Research has shown that LLMs can process multi-modal IoT data, such as accelerometer signals, WiFi patterns, and heart rate measurements, enabling them to classify human activities, monitor environments, and analyze physical phenomena [19], [20]. These developments highlight LLMs' potential to interpret IoT sensor data and generate actionable insights by integrating embedded world knowledge.\nTo better adapt LLMs to IoT-specific tasks, researchers have introduced frameworks that incorporate sensor data preprocessing, knowledge retrieval, and advanced prompting strategies [21], [22]. These approaches enable LLMs to handle diverse IoT modalities, including human activity recognition, industrial monitoring, and indoor localization. Techniques such as multitasking adapter layers and structured prompting have been deployed to improve performance on complex, real-world tasks. Moreover, the creation of extensive multi-modal datasets has further enhanced LLMs' capabilities, ensuring scalability and adaptability across varied IoT applications [22].\nB. Security\nIn the realm of security, LLMs have shown remarkable promise in identifying and mitigating threats within IoT networks [23]. Transformer architectures have been utilized to detect advanced cybersecurity threats, such as denial-of-service attacks, reconnaissance activities, and command injection vulnerabilities [24], [25]. These models use techniques such as static taint analysis and chaining of large language models to improve accuracy and efficiency in identifying network attacks.\nBERT-based models have proven particularly effective in anomaly detection for structured environments. Early applications succeeded in detecting arbitration identifier anomalies in controller area networks and malware classification tasks [26]. Similarly, advancements in malware classification leveraged contextual relationships to identify malicious patterns in source code [27]. Recent advancements have expanded these capabilities to largescale IoT systems, treating logs and network data as sequential language-like inputs [28]. This has enabled the detection of advanced persistent threats and subtle vulnerabilities with high accuracy [29]-[31].\nHowever, despite these advancements, BERT's potential for real-time packet-level IoT traffic analysis remains underutilized [18]. Current efforts often emphasize privacy-preserving mechanisms or lightweight adaptations for resource-constrained devices, which restrict their effectiveness in accurately detecting nuanced anomalies in complex, dynamic IoT ecosystems [18], [32]. Unlocking BERT's full contextual understanding offers a compelling opportunity to enhance anomaly detection and ensure robust IoT network security.\nDespite advancements in applying LLMs to IoT environments, existing approaches are limited in scalability and adaptability to IoT ecosystems' diverse and dynamic nature. Additionally, no frameworks comprehensively address administrative functionalities\u2014such as device management, troubleshooting, device setup, maintenance, and security and privacy-by leveraging contextual knowledge from IoT manuals and related documentation while incorporating IoT traffic analysis for anomaly detection to support administrative purposes. This gap highlights the pressing need for an integrated solution that unifies operational management with robust anomaly detection and is designed to meet the complexities of IoT networks."}, {"title": "V. CONCLUSION", "content": "This paper proposes a framework that integrates a context-aware generation module and a fine-tuned BERT model, addressing critical challenges in IoT device management and network security. The RAG component bridges the gap between generic LLMs and IoT-specific demands, enabling precise, contextually grounded responses across five administrative use cases: device management, maintenance, security and privacy, troubleshooting, and device setup. Meanwhile, the fine-tuned BERT model excels in anomaly detection, achieving state-of-the-art accuracy in identifying diverse attack types and ensuring robust security for IoT ecosystems.\nOur experimental results demonstrate that contextual augmentation significantly enhances LLM performance, reducing hallucinations and increasing the reliability of responses, while the anomaly detection module ensures actionable insights for cybersecurity. By combining these strengths, our framework delivers a scalable, efficient, and practical solution to the growing complexity of IoT environments, empowering administrators to manage and secure devices with unprecedented accuracy. This work lays a solid foundation for advancing AI-driven IoT systems and offers a path forward for future research in intelligent, secure IoT ecosystem management."}]}