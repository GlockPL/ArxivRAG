{"title": "Permutation Picture of Graph Combinatorial\nOptimization Problems", "authors": ["Yimeng Min"], "abstract": "This paper proposes a framework that formulates a wide range of graph combi-\nnatorial optimization problems using permutation-based representations. These\nproblems include the travelling salesman problem, maximum independent set,\nmaximum cut, and various other related problems. This work potentially opens up\nnew avenues for algorithm design in neural combinatorial optimization, bridging\nthe gap between discrete and continuous optimization techniques.", "sections": [{"title": "1 Introduction", "content": "The advances in Deep Learning for vision and language tasks have inspired researchers to explore\nits application to different domains, such as Go [Silver et al., 2016] and protein folding [Jumper\net al., 2021]. It has also motivated researchers to apply learning-based methods to combinatorial\noptimization problems [Bengio et al., 2021]. This emerging field, often referred to as Machine\nLearning for Combinatorial Optimization (ML4CO), aims to leverage the power of machine learning\nto enhance or replace traditional optimization algorithms. Neural Networks (NNs) have emerged as\na particularly powerful tool in ML4CO, owing to their ability to capture and process the structural\ninformation inherent in many combinatorial optimization problems. NNs can learn representations of\nmany graph problems, making them well-suited for tasks that can be formulated as graph optimization\ntasks[Wilder et al., 2019, Khalil et al., 2017, Kool et al., 2018]. The application of NNs in tackling\ngraph-based optimization problems has been further exemplified in unsupervised learning fashion to\na range of graph combinatorial problems, such as Travelling Salesman Problem, Maximum Clique,\nand other related problems [Min et al., 2024, Karalias and Loukas, 2020]."}, {"title": "1.1 Supervised, Reinforcement and Unsupervised Learning", "content": "Since many graph combinatorial problems can be categorized as NP-hard, thus, direct application of\nSupervised Learning (SL) to these problems can be challenging due to the expense of annotation.\nReinforcement Learning (RL), while it doesn't require directly labelled training data, it also has its\nlimitations. These include sparse reward issues, where rewards can be rare, making it difficult for the\nagent to learn effectively, and large variance during training, which leads to unstable performance. A\npromising alternative approach is unsupervised learning (UL). In UL, a surrogate loss function (which\ncan be either convex or non-convex) is constructed to encode the graph combinatorial problem. This\nloss function serves as a proxy for the original optimization objective. After training on this surrogate\nloss, the model learns a representation of the problem space. Subsequently, a decoding algorithm is\napplied to this learned representation to extract the final solutions. This two-step learning followed\nby decoding allows for a more flexible and potentially more effective approach to tackling graph\ncombinatorial problems."}, {"title": "1.2 Building Surrogate Loss using Ising Formulation", "content": "However, building an effective surrogate loss for graph combinatorial problems is challenging. A\npopular choice for constructing such surrogate losses is to use the Ising model formulation derived\nfrom Quadratic Unconstrained Binary Optimization (QUBO). QUBO aligns with the binary nature\nof decision variables (True or False) in graph combinatorial problems. When using QUBO as\na surrogate loss, the goal of machine learning is then to minimize this energy function, which\ncorresponds to finding an optimal or near-optimal solution to the original problem [Lucas, 2014]."}, {"title": "1.3 Permutation", "content": "Permutations play a crucial role in representing and solving a wide range of graph combinatorial opti-\nmization problems, offering intuitive and efficient formulations that often align closely with problem\nstructures. In contrast, while we can use the Ising model formulations to build surrogate losses, the\nresulting quadratic function can have a large number of terms, leading to computational challenges.\nQUBO formulations essentially reduce variables to binary classifications, but the interactions between\nthese variables may not always capture the problem structure.\nIn this paper, we build surrogate losses using permutations. There is a key distinction arises between\nour permutation picture and QUBO: we are essentially learning orders, not binary classifications.\nThe concept of learning to order provides a more natural fit for problems where the objective is to\ndetermine a sequence or arrangement, as opposed to classification Cohen et al. [1997]. This idea of\nlearning orders has been effectively applied in other machine learning tasks, such as solving jigsaw\npuzzles or sorting Mena et al. [2018], Noroozi and Favaro [2016]. In the following sections, we\nwill delve deeper into how this ordering approach aligns with the structure of our problems and the\npotential advantages it offers over QUBO-based formulations.\nThe importance of formulating graph combinatorial problems as permutation operators is further em-\nphasized in various problems. In graph isomorphism, permutations represent the bijective mappings\nbetween vertices of two graphs that preserve edge relationships, defining what it means for graphs to\nbe isomorphic [Luks, 1982]. [Babai, 2016] exemplifies the power of this approach, leveraging the\ntheory of permutation groups to achieve a quasipolynomial time solution to the graph isomorphism\nproblem.\nThe lack of intuitiveness for QUBO is more evident in problems that inherently involve sequencing\nor ordering, such as the Travelling Salesman Problem (TSP). In these problems, a permutation\nrepresentation directly encodes the tour as a sequence of cities: $\\pi = (\\pi_1,\\pi_2, ..., \\pi_n)$, where $\\pi_i$\nrepresents the i-th city visited in the tour and $c_{ij}$ is the cost between city i and j. The objective\nfunction simply becomes:"}, {"title": "4 Formulating Graph Combinatorial Problems using Permutation", "content": ""}, {"title": "4.1 Travelling Salesman Problem", "content": "Let's first start from the famous TSP. TSP is a well-known NP-hard combinatorial optimization\nproblem that has been extensively studied in the fields of computer science, operations research, and"}, {"title": "4.2 Maximum Independent Set", "content": ""}, {"title": "4.2.1 Definition", "content": "The Maximum Independent Set (MIS) problem asks to find the largest subset of vertices in an\nundirected graph $G = (V, E)$, where V is the set of vertices and E is the set of edges, such that\nno two vertices in the subset are adjacent to each other. In other words, the objective is to find\nan independent set of vertices $S \\subseteq V$, where an independent set is a set of vertices in which no\ntwo vertices are connected by an edge in E. The problem aims to maximize the cardinality of the\nindependent set, denoted by |S|. Formally, the MIS problem can be stated as: $max_{S\\subseteq V} |S|$, subject\nto the constraint that for all pairs of vertices i, j \u2208 S, (i, j) \u2209 E."}, {"title": "4.2.2 Permutation-based objective function", "content": "We now formulate the MIS problem using a permutation-based approach similar to TSP, given a\ngraph of n vertices, the objective is:"}, {"title": "4.2.3 Proof", "content": "Consider the matrix product $PAP^T$. This product has the property that $(PAP^T)_{ij} = 1$ if and\nonly if vertices \u03c0(i) and \u03c0(j) are connected by an edge in the graph. Now consider the matrix\nproduct $PAP^TC(k)$, which correspond to the first k vertices in the permutation \u03c0. The trace of\na square matrix is the sum of its diagonal elements. Therefore, $Tr(PAP^TC(k))$ is the sum of the\ndiagonal elements of $PAP^TC(k)$, which correspond to the edges between the first k vertices in the\npermutation \u03c0. If $Tr(PAP^TC(k)) = 0$, then there are no edges between the first k vertices in the\npermutation \u03c0. This means that these k vertices form an independent set.\nThe objective function $f_{MIS}(P,k) = k$ maximizes the size of the independent set. Therefore, the\npermutation-based formulation correctly finds the MIS of the graph by maximizing k subject to the\nconstraint $Tr(PAP^TC(k)) = 0$, which ensures that the first k vertices in the permutation \u03c0 form an\nindependent set."}, {"title": "4.3 Maximum Cut", "content": ""}, {"title": "4.3.1 Definition", "content": "The Maximum Cut (MC) problem involves finding a partition of the vertices of an undirected graph\n$G = (V, E)$ into two disjoint subsets S and V \\ S, such that the number of edges between the two\nsubsets, known as the cut size, is maximized. Here, we assume every edge in E has the same unit\nweight. In other words, the objective is to find a cut (S, V \\ S) that maximizes the sum of the numbers\nof the edges crossing the cut, where the weight of an edge (i, j) \u2208 E is given by $e_{ij}$. The problem\ncan be formally stated as: $max_{S\\subseteq V} \\sum_{i\\in S, j \\in V\\setminus S} e_{ij}$"}, {"title": "4.3.2 Permutation-based objective function", "content": "Given a graph of n vertices, the objective of MC is:"}, {"title": "4.3.3 Proof", "content": "To prove that the function $f_{MC}(\\pi,k) = \\frac{1}{2} Tr(PAP^TC(k))$ correctly represents the MC problem. Let\n$\\pi$ be a permutation of the vertices, represented by the permutation matrix P, and k be a cut point\nwhere 1 \u2264 k < n. We define two sets: $S = {\\pi(1), ..., \\pi(k)}$ and $T = {\\pi(k + 1), ..., \\pi(n)}$. The\nmatrix $PAP^T$ represents the adjacency matrix of G with vertices reordered according to \u03c0, while\nC(k) is constructed such that $C(k)_{ij} = 1$ if and only if i \u2264 k < j or j \u2264 k < i.\nThe trace calculation $Tr(PAP^TC(k))$ can be expanded as the sum of two terms:\n$\\sum_{i=1}^{k} \\sum_{j=k+1}^{n} (PAP^T)_{ij}$ and $\\sum_{i=k+1}^{n} \\sum_{j=1}^{k} (PAP^T)_{ij}$. The first term counts edges from ver-\ntices in positions 1 to k to vertices in positions k + 1 to n, while the second term counts edges in the\nopposite direction. Together, these sums count each edge crossing the cut exactly twice. This double\ncounting aligns perfectly with the definition of a cut in graph theory: an edge (u, v) \u2208 E is in the cut\nif and only if (u \u2208 S and v \u2208 T) or (u \u2208 T and v \u2208 S).\nTo correct for this double counting, we multiply the trace by 1/2 in our objective function. Thus,\n$f_{MC}(\\pi,k) = \\frac{1}{2} Tr(PAP^TC(k))$ accurately counts the number of edges in the cut defined by permu-\ntation \u03c0 and cut point k. It follows that maximizing $f_{MC}(\\pi, k)$ over all permutations \u03c0 and cut points\nk is equivalent to finding the MCs in G. This is because every possible cut in G can be represented\nby some permutation \u03c0 and cut point k, and our function correctly counts the size of each such cut.\nTherefore, the maximum value of $f_{MC}(\\pi, k)$ must correspond to the size of the maximum cut in G,\ncompleting our proof and demonstrating the validity of our permutation-based formulation for the\nMax Cut problem."}, {"title": "4.4 Graph Coloring Problem", "content": ""}, {"title": "4.4.1 Definition", "content": "The goal of graph coloring problem is to assign colors to the vertices of an undirected graph\n$G = (V, E)$, such that no two adjacent vertices have the same color. The objective is to find a\nvalid coloring of the graph using the minimum number of colors possible, known as the chromatic\nnumber of the graph, denoted by x(G). Each vertex must be assigned exactly one color from the set\n1,2,..., k, where k is the number of available colors, and if two vertices i and j are connected by an\nedge (i, j) \u2208 E, then they must be assigned different colors."}, {"title": "4.4.2 Permutation-based objective function", "content": "The problem can be written as:"}, {"title": "4.4.3 Proof", "content": "The objective of the graph coloring problem is to minimize the number of colors used to assign a\ncolor to each vertex such that no two adjacent vertices share the same color. The objective function in\nEquation 14, ensures that we minimize the number of colors. The constraint in Equation 15 enforces\nthat no two adjacent vertices share the same color. Here, P is a permutation matrix, and A is the\nadjacency matrix that encodes the edges between vertices. The cost matrix C(k) assigns a value of\n1 if two vertices share the same color and 0 otherwise. Therefore, the product $PAP^TC(k)$ checks\nwhether any adjacent vertices are assigned the same color. If adjacent vertices share a color, the"}, {"title": "4.5 Minimum Vertex Cover", "content": ""}, {"title": "4.5.1 Definition", "content": "The goal of Minimum Vertex Cover (MVC) problem is to find the smallest subset of vertices in an\nundirected graph $G = (V, E)$, such that every edge in the graph is incident to at least one vertex in\nthe subset. In other words, the objective is to find a vertex cover of the graph, denoted by S\u2286 V,\nwhere a vertex cover is a set of vertices such that every edge in E has at least one of its endpoints in\nS. The problem aims to minimize the cardinality of the vertex cover, denoted by |S|. Formally, the\nMVC problem can be stated as: $min_{S\\subseteq V} |S|$, subject to the constraint that for all edges (i, j) \u2208 E,\neither i \u2208 S or j\u2208 S (or both)."}, {"title": "4.5.2 Permutation-based objective function", "content": "Given a graph of n vertices, the objective of MVC is:"}, {"title": "4.5.3 Proof", "content": "We prove that minimizing k subject to $Tr(PAP^TC(k)) = 0$ is equivalent to finding a MVC of G.\nConsider a permutation \u03c0 of V, represented by matrix P. The matrix C(k) is defined as $C(k)_{ij} = 1$\nif i > k and j > k, and 0 otherwise. Thus, $PAP^TC(k)$ represents the subgraph of the permuted\ngraph induced by vertices k + 1 to n. The condition $Tr(PAP^TC(k)) = 0$ means that there are no\nedges in the permuted graph where both endpoints are beyond the first k vertices. Equivalently, every\nedge in G has at least one endpoint among the first k vertices in the permutation \u03c0. Therefore, these\nk vertices form a vertex cover. By minimizing k, we find the smallest such cover. Conversely, any\nvertex cover of size k can be represented by a permutation \u03c0 where the cover vertices are the first k\nelements"}, {"title": "4.6 Minimum Dominating Set", "content": ""}, {"title": "4.6.1 Definition", "content": "A Minimum Dominating Set (MDS) in a graph $G = (V, E)$ is a subset S of V such that:\n1. Every vertex not in S is adjacent to at least one vertex in S.\n2. S is of minimum size among all dominating sets of G.\nIn other words, it's the smallest set of vertices in a graph such that every vertex in the graph is either\nin the set or adjacent to a vertex in the set."}, {"title": "4.6.2 Permutation-based objective function", "content": "We can formulate the MDS problem using the permutation-based approach:"}, {"title": "4.6.3 Proof", "content": "We prove that minimizing k subject to $P(A + I)P^T 1_k \\geq 1$ is equivalent to finding the MDS of G.\nConsider a permutation \u03c0 of V, represented by matrix P. The product $P(A + I)P^T1_k$ calculates,\nfor each vertex, the number of neighbors (including itself) that are in the set D, and the constraint\n$P(A + I)P^T1_k \\geq 1$ ensures that all vertices are included. Minimizing k corresponds to finding the\nsmallest such set, which is exactly the objective of the MDS problem. Therefore, the formulation is a\nvalid representation of the MDS problem."}, {"title": "4.7 Maximum Clique Problem", "content": ""}, {"title": "4.7.1 Definition", "content": "Let G = (V, E) be an undirected graph, a clique is a subset of vertices S \u2286 V such that every pair\nof vertices in S is connected by an edge in E. In other words, a clique is a complete subgraph of\nG where all possible edges between its vertices are present. The objective of the Maximum Clique\n(MClique) problem is to find a clique of maximum cardinality, denoted by w(G). Formally, the\nproblem can be stated as: maxscv |S|, subject to the constraint that for all pairs of vertices i, j \u2208 S,\n(i, j) \u2208 E."}, {"title": "4.7.2 Permutation-based objective function", "content": "we can formulate the MClique problem using the permutation-based approach:"}, {"title": "4.7.3 Proof", "content": "We prove that maximizing k subject to $Tr(P(J \u2013 A \u2013 I)P^TC(k)) = 0$ is equivalent to finding\na maximum clique in G. Consider a permutation of V, represented by matrix P. The matrix\nJ - A - I has entries of 1 where there are no edges in G (excluding self-loops), and 0 elsewhere.\nC(k) is a matrix with ones in the upper-left k \u00d7 k block and zeros elsewhere, effectively selecting the\nsubgraph induced by the first k vertices in the permutation. The product $P(J \u2013 A \u2013 I)P^T$ represents\nthe non-edge matrix of G after reordering vertices according to \u03c0. When multiplied element-wise\nwith C(k), it selects the non-edges within the first k vertices of this permutation. The condition\n$Tr(P(J \u2013 A \u2013 I)P^TC(k)) = 0$ implies there are no non-edges among the first k vertices in the\npermutation \u03c0, in other words, these k vertices form a clique.\nBy maximizing k subject to this constraint, we find the largest set of vertices that forms a clique,\nwhich is the definition of a maximum clique. Conversely, for any clique of size k in G, we can\nconstruct a permutation \u03c0 that places the clique vertices in the first k positions, satisfying Tr(P(J \u2013\nA \u2013 I)PTC(k)) = 0. Therefore, the optimal solution to this formulation corresponds to a MClique\nin G."}, {"title": "4.8 Graph Isomorphism", "content": ""}, {"title": "4.8.1 Definition", "content": "Given two graphs $G_1 (V_1, E_1)$ and $G_2(V_2, E_2)$ with $|V_1| = |V_2| = n$, we want to determine if there\nexists a bijection f : V\u2081 \u2192 V2 such that (u, v) \u2208 E\u2081 if and only if (f(u), f(v)) \u2208 E\u2082."}, {"title": "4.8.2 Permutation-based objective function", "content": "we can formulate the Graph Isomorphism (GI) Problem using the permutation-based approach:"}, {"title": "4.8.3 Proof", "content": "This formulation directly corresponds to the definition of graph isomorphism."}, {"title": "4.9 Boolean Satisfiability", "content": ""}, {"title": "4.9.1 Definition", "content": "The Boolean Satisfiability Problem (SAT) is a fundamental problem in computer science and math-\nematical logic that plays a central role in computational complexity theory. SAT asks whether a\ngiven Boolean formula, typically expressed in Conjunctive Normal Form (CNF), can be satisfied\nby assigning truth values (True or False) to its variables. A CNF formula consists of a conjunction\n(AND) of clauses, where each clause is a disjunction (OR) of literals (variables or their negations).\nLet $X = x_1,x_2, ..., x_n$ be a set of n Boolean variables. A SAT instance with m clauses can be\nrepresented as:\n$\\$\\phi = C_1 \\land C_2 \\land ... \\land C_m,$\nwhere each clause C\u2081 is a disjunction of literals:\n$C_i = (l_{i1} \\lor l_{i2} \\lor ... \\lor l_{ik_i})$.\nHere, each literal $l_{ij}$ is either a variable $x_k$ or its negation $\u00acx_k$, and $k_i$ is the number of literals in\nclause $C_i$. The SAT problem asks if there exists an assignment \u03b1 : X \u2192 {0, 1} such that:"}, {"title": "4.9.2 Permutation-based objective function", "content": "We now encode SAT as a graph problem and then apply a permutation-based approach. We first\ncreate a vertex for each literal (x and \u00acx for each variable x in X). For a SAT problem with n\nvariables and m clauses, our graph will have N = 2n + m vertices.\nOur objective is to find a permutation matrix P\u2208 R2n+m, subject to:\n$Tr (CPAP^TC) = 0,$\nwhich is the complementarity constraint which ensures that no two complementary literals are both\nassigned True by verifying that there are no conflicting edges.\n$TPAP^TC1_N \\geq 1_m.$"}, {"title": "4.9.3 Proof", "content": "We begin by considering a satisfying assignment \u03b1 : X \u2192 {0, 1}, where\nUnder this assignment \u03b1, all clauses $C_j$ evaluate to True. To represent this assignment in our\npermutation-based framework, we construct a permutation \u03c0 such that:\n1. The first n positions correspond to literals assigned True.\n2. The next n positions correspond to the remaining literals.\n3. The last m positions correspond to the clauses $C_j$.\nFormally, for each i = 1 to n, we define \u03c0(i) as follows:\n1. If \u03b1(xi) = 1, we place the literal xi at position i.\n2. If \u03b1(xi) = 0, we place the literal \u00acx\u00bf at position i.\nThe order of literals in positions n + 1 to 2n can be arbitrary, and the clauses are placed at positions\n2n + 1 to 2n + m.\nSince the assignment \u03b1 does not assign both a literal and its complement to True, there are no conflicts\namong the literals assigned True. Therefore, the complementarity constraint Tr (CPAPTC) = 0 is\nsatisfied.\nMoreover, each clause $C_j$ contains at least one literal that is assigned True under \u03b1. This implies\nthat in the permuted adjacency matrix $PAP^T$, there is at least one edge from an assigned literal (in"}, {"title": "5 Discussion", "content": "The key of constructing the permutation framework for many graph problems lies in reordering (or\nrelabelling) the vertices. Let's take the MIS problem in Section 4.2 as an illustrative example. Recall\nthat an independent set in a graph is a set of vertices where no two vertices are adjacent. The MIS is\nthe largest such set for a given graph.\nMoreover, this relabelling strategy extends to other graph problems, such as clique finding and vertex\ncover. By framing these problems in terms of permutations, we may open up new possibilities\nfor combining these representations with recent advancements in learning-to-sort or learning-to-\npermute models. These permutation-based formulations, when integrated with these learning-based\napproaches, creates a framework that can potentially enhance the efficiency of solving graph combi-\nnatorial problems using neural networks."}, {"title": "6 Conclusion", "content": "This paper presents a general framework for addressing a wide range of graph combinatorial optimiza-\ntion problems under permutation picture. We have demonstrated the versatility of this approach by\napplying it to many graph combinatorial problems. It should be emphasized that there are numerous\nproblems that can be formulated using permutation-based representations, and this paper discusses\nonly a select few examples to illustrate the framework's broad applicability. By formulating different\nproblems into a permutation-based structure, we provide a unified approach to tackling graph com-\nbinatorial optimization problems. For many problems, particularly those involving sequencing or\nordering, permutation-based formulations offer more intuitive and direct representations of problem\nstructures compared to traditional approaches like QUBO.\nFurthermore, our approach can be combined with recent advancements in differentiable sorting and\nranking techniques, opening up possibilities for applying gradient-based (differentiable) machine"}, {"title": "A Appendix", "content": ""}, {"title": "A.1 SAT Example", "content": ""}, {"title": "A.1.1 Variables and Literals", "content": "The SAT problem consists of 4 Boolean variables X1, X2, X3, X4 and 5 clauses in CNF:\nWe can encode the SAT problem using the permutation-based method. We first construct\na graph with vertices representing literals and clauses. There are 8 total literal vertices\n(X1,\u00acX1,X2,\u00acX2,X3,\u00acX3,X4,\u00acx4) and 5 clause vertices (C1, C2, C3, C4, C5). Total number of ver-\ntices N = 13.\nThe adjacency matrix A \u2208 R13\u00d713 is constructed as follows:"}, {"title": "A.2 Example of Satisfying Assignment and Permutation", "content": ""}, {"title": "A.2.1 Satisfying Assignment 1", "content": "We assign True to: X1, X2, X3, X4, the truth assignment is: X1 = True, X2 = True, X3 = True,\nX4 = True. The permutation is:\n\u03c0 = [1, 3, 5, 7, 2, 4, 6, 8, 9, 10, 11, 12, 13]."}]}