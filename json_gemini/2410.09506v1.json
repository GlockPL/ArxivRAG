{"title": "Distribution-Aware Mean Estimation under User-level Local Differential Privacy", "authors": ["Corentin Pla", "Hugo Richard", "Maxime Vono"], "abstract": "We consider the problem of mean estimation under user-level local differential privacy, where n users are contributing through their local pool of data samples. Previous work assume that the number of data samples is the same across users. In contrast, we consider a more general and realistic scenario where each user $u \\in [n]$ owns $m_u$ data samples drawn from some generative distribution $\\mu$; $m_u$ being unknown to the statistician but drawn from a known distribution $M$ over $\\mathbb{N}^*$. Based on a distribution-aware mean estimation algorithm, we establish an M-dependent upper bounds on the worst-case risk over $\\mu$ for the task of mean estimation. We then derive a lower bound. The two bounds are asymptotically matching up to logarithmic factors and reduce to known bounds when $M_u = m$ for any user $u$.", "sections": [{"title": "1 Introduction", "content": "In the current artificial intelligence era, machine learning (ML) techniques and algorithms have become common tools for data analysis and decision making. In most cases, their empirical success is based on the availability of large training datasets, which is for instance theoretically justified by data probabilistic modelling and the Bernstein-von Mises approximation asserting that under appropriate conditions, the more data can be processed, the more accurate the inference can be performed (Bardenet et al., 2017; Bottou et al., 2018; Cornish et al., 2019). However, in the meantime, growing user concerns and regulatory frameworks have emerged regarding how user personal data could be collected and processed by third-party entities. These data privacy issues hence have incentivised users of machine learning applications to ask for methods preserving data anonymity (Shokri and Shmatikov, 2015; Abadi et al., 2016; Zaeem and Barber, 2020).\nWhilst many privacy-preserving tools have been proposed (Garcelon et al., 2022; Knott et al., 2021; Ohrimenko et al., 2016; McMahan et al., 2017a; Vono et al., 2022), the workhorse framework in machine learning is differential privacy (DP). DP allows to formally protect user's privacy in a quantifiable manner while maintaining the statistical utility. It dates back at least to Warner (1965) but has received a renewed interest after the work of Dwork et al. (2014). As an example, DP has been implemented in real-world scenarii by large technology companies such as Meta, Apple, or LinkedIn (Erlingsson et al., 2014; Tang et al., 2017; Messing et al., 2020; Rogers et al., 2021); public bodies such as the United States Census Bureau (Abowd, 2018); or non-governmental organisations such as Wikimedia Foundation (Adeleye et al., 2023). The DP framework, which requires outputs of a differentially-private algorithm to be undistinguishable when a single contribution changes, has been formalised first in the so-called central model where data is aggregated before being privatised (Dwork et al., 2006; Hardt and Talwar, 2010). The main ingredient to ensure such guarantees is to randomise seminal algorithms by incorporating calibrated noise. To embrace more stringent privacy guarantees, DP has then evolved into a distributed setting, called local differential privacy (LDP), which privatises data before aggregation, alleviating the need to resort to a trusted aggregator (Hsu et al., 2012; John C. Duchi and Wainwright, 2018).\nIn contrast to the central setting, LDP comes with a degraded privacy/utility trade-off mainly due to noise involved in each local data contribution. Such fundamental limits have been established by a series of recent works, focusing on specific tasks and associated algorithms. For instance, the problem of finding optimal private protocols has already been addressed"}, {"title": "Distribution-Aware Mean Estimation under User-level LDP", "content": "for mean estimation (Duchi et al., 2018), density estimation (Butucea et al., 2019), and hypothesis testing (Berrett and Butucea, 2020).\nTraditionally, differentially-private models based on LDP assume that users are contributing with only one data sample (Duchi et al., 2018). Whilst this framework is sufficient for basic use-cases such as mean wage estimation of several individuals, it cannot be applied to a broader set of real-world applications where users may contribute via multiple data points. As seminal examples, users can contribute with a local database made of multiple item (e.g., product or movie) ratings in order to train recommendation systems (McSherry and Mironov, 2009); or can hold several sequences of words typed on their mobile device keyboards which are then used to train next-word prediction models (McMahan et al., 2017c). Such general applications nourished a research area focusing on user-level differential privacy, where each user holds more than one data sample and seeks to maintain the privacy of her entire collection. User-level DP has been considered under both central and local settings for statistical tasks already pointed out previously, that is mean estimation, empirical risk minimisation, and non-parametric density estimation (Girgis et al., 2022; Acharya et al., 2022b; Kent et al., 2024). Unfortunately, the user-level DP paradigm considered in aforementioned state-of-the-art research work lacks realism as it involves an unrealistic assumption of uniformity over the number of samples. More precisely, current work assume that the number of data samples provided by each user is the same, which does not hold in many real-world settings as outlined, for instance, by federated learning applications (McMahan et al., 2017b; Wang et al., 2021).\nThis paper aims at filling this gap. Among statistical tasks that have been tackled in the literature, univariate mean estimation stands for the primary and most interesting problem to consider as it is the basis to many other protocols. Indeed, associated results can be extended to multivariate mean estimation via specific data transformations involving Hadamard matrices (Chen et al., 2020), non-parametric density estimation via the trigonometric basis (Butucea et al., 2019), sparse mean estimation (Acharya et al., 2022b) or regression via stochastic convex optimisation (Bassily and Sun, 2023).\nAs such, we consider in this paper the problem of univariate mean estimation under user-level local differential privacy where each user $u \\in [n]$ locally holds a dataset of $m_u \\in \\mathbb{N}^*$ independent and identically distributed observations from an unknown probability distribution $\\mu$; $m_u$ being drawn from a known discrete probability distribution $M$. To the best of our knowledge, we are the first to investigate this general user-level local DP setting.\nContribution. Our contribution is three-folded.\nWe propose a novel and more realistic user-level LDP framework that allows users to contribute via local data sets of heterogeneous cardinality.\nWe instantiate this framework for the task of univariate mean estimation and propose an associated algorithm, coined distribution-aware mean estimation (DAME). The proposed algorithm works in two phases: (i) the localisation phase aims at finding a bin where the true mean parameter lies with high probability; (ii) the estimation phase projects data samples onto the bin to reduce the range. Compared to other variants proposed in previous work, the novelty of DAME lies in (i) the selection of users and the bin size, which are adapted to the data set size distribution M; (ii) the estimation phase where the mean is shrinked towards the center of the bin to include data contributions from all users even those having few samples.\nWe derive non-asymptotic guarantees on the worst-case risk over $\\mu$ for mean estimation. More precisely, we derive upper bounds via the proposed algorithm DAME, and also provide lower bounds on the same quantity. Based on the derived bounds, we show that DAME is optimal in many scenarii: (i) asymptotically in $n$ up to a log-factor; (ii) in the item-level ($m_u = 1$ for any $u \\in [n]$) LDP setting, up to constant factor; (iii) in the homogeneous ($m_u = m \\in \\mathbb{N}^*$ for any $u \\in [n]$) user-level LDP setting, up to a log factor; and (iv) in many regimes interpolating the item-level and user-level settings. The optimality of the derived bounds is verified numerically for several choices of the discrete distribution $M$.\nRelated Work. As outlined previously, private mean estimation under the DP paradigm has been investigated in both the central (Dwork et al., 2006; Hardt and Talwar, 2010) and local settings (Duchi et al., 2018). These seminal research works have focused on providing item-level (in contrast to user-level) privacy under the assumption that the number of samples is the same across all users. When the data samples are discrete, the more general problem of frequency estimation has also been well-studied under the same assumptions in both central (Dwork et al., 2006) and local DP models (Hsu et al., 2012; Erlingsson et al., 2014; Acharya et al., 2019). User heterogeneity in terms of number of data samples per user has already been considered in both different DP settings"}, {"title": "2 Problem Formulation", "content": "Notation. We set $[n] = \\{1, ..., n\\}, [n_1, n_2] = \\{n_1,...,n_2\\}$ and use the notation $z_{i:j} = (z_i, \\dots, z_j)^T$ and $Z_{(i:j)} = (Z_{(i)},..., Z_{(i)})^T$. We define $\\mathcal{B}([-1,1])$ as the Borel set over [-1,1] and let $\\mu^i$ denote the i-th product distribution. Through this paper, we will use the mathematical notation, $\\mathcal{O}(\\cdot)$, $\\Omega(\\cdot)$ and $\\Theta(\\cdot)$ to describe the complexities of the computation required by private mean estimation algorithms. We recall that $f(d) = \\mathcal{O}(g(d))$ (resp. $f(d) = \\Omega(g(d))$) if there exists $c > 0$ such that $f(d) \\leq cg(d)$ (resp. $f(d) \\geq cg(d)$). We use $f(d) = \\Theta(g(d))$ if there exist $c_1, c_2 > 0$ such that $c_1g(d) \\leq f(d) \\leq c_2g(d)$. We define $a \\wedge b = \\min(a, b)$ and $a \\vee b = \\max(a, b)$. Finally we denote $D_{TV}(\\cdot,\\cdot)$ the total variance distance and $D_{KL}(\\cdot,\\cdot)$ the Kullback-Leibler divergence.\nFramework. We study the setting of user-level local differential privacy, in which users do not trust the central data aggregator. We consider an environment involving $n \\in \\mathbb{N}^*$ users holding private local data sets $\\{X^{(u)} = \\{X_1^{(u)},..., X_{m_u}^{(u)}\\}\\}_{u\\in[n]}$ of different sizes $\\{m_u\\}_{u\\in[n]}$. For any $u \\in [n]$, $m_u$ is distributed according to a discrete distribution $M$ defined on $(\\mathbb{N}^*, 2^{\\mathbb{N}^*})$, and $X^{(u)}$ stands for a random variable distributed according to a probability distribution $\\mu$ defined on a measurable space $(\\mathcal{X},\\mathcal{X})$. For the sake of simplicity and similar to previous work, we assume, for any $u \\in [n]$ and $t \\in [m_u]$, that $X_t^{(u)} \\in [-1,1]$. Note that in constrast to item-level LDP where $m_u = 1$ for any $u \\in [n]$, the considered user-level LDP setting assumes that each user $u \\in [n]$ contributes $m_u \\in \\mathbb{N}^*$ samples to the global (artificial) dataset so that $\\mathcal{X} = \\bigcup_{u=1}^n [-1,1]^{m_u}$. As a result, each user local data set is sampled independently and identically according to the joint distribution $\\nu_\\mu$ described by the following generative model:\n$M_u \\sim M, \\; X^{(u)} \\vert m_u = i \\stackrel{i.i.d}{\\sim} \\mu^i.$\t(1)\nIn order to preserve their private local datasets, users do not directly reveal $X^{(u)}$ to the statistician but instead send to the latter an obfuscated view $Z^{(u)}$ of $X^{(u)}$, defined over $(\\mathcal{Z},\\mathcal{Z})$. More precisely, the random variables $\\{Z^{(u)}\\}_{u\\in [n]}$ stand for differentially-private versions of $\\{X^{(u)}\\}_{u\\in[n]}$. We assume that users sequentially reveal $\\{Z^{(u)}\\}_{u\\in[n]}$ to the statistician. This assumption means that for any user $u \\in [n]$, $Z^{(u)}$ and $\\{X^{(u')}\\}_{u'\\neq u}$ are independent given $X^{(u)}$ and $Z_{(1:u-1)}$. Such independence property implies that the conditional probability distribution $Q$ of $Z_{(1:n)}$ given $X_{(1:n)}$, referred to as mechanism, is fully characterised by $\\{Q_u\\}_{u\\in[n]}$ where, for any $u \\in [n]$, $Q_u$ is the local conditional probability distribution of $Z^{(u)}$ given $X^{(u)}, Z_{(1:u-1)}$, coined local channel.\nLocal Differential Privacy. For a given scalar privacy parameter $a > 0$ and any $u \\in [n]$, we say that the random variable $Z^{(u)}$ is an $a$-differentially locally private view of $X^{(u)}$ if, for any $\\tilde{z}_{1:u-1} \\in \\mathcal{Z}^{u-1}$ and $x,x' \\in \\mathcal{X}$, the conditional probability distribution $Q_u: \\mathcal{Z} \\times (\\mathcal{X} \\times \\mathcal{Z}^{u-1}) \\rightarrow [0,1]$ of $Z^{(u)}$ given $X^{(u)}, Z_{(1:u-1)}$ satisfies:\n$\\sup_{S \\in \\mathcal{Z}} \\frac{Q_u (S \\vert X, \\tilde{z}_{1:u-1})}{Q_u (S \\vert X', \\tilde{z}_{1:u-1})} \\leq \\exp(a).\t(2)\nNote that the previous definition does not constrain $Z^{(u)}$ to be a data release exclusively based on $X^{(u)}$: the local channel $Q_u$ may be interactive, that is differing based on previous data releases $Z_{(1:u-1)}$. When for any $u \\in [n]$, $Z_u$ is an $a$-differentially locally private view of $X_u$, we say that $Q = \\{Q_u\\}_{u\\in[n]}$ is an $a$-LDP mechanism. We refer to $\\mathcal{Q}_a$ as the set of $a$-LDP mechanisms.\nPrivate Mean Estimation. The objective of mean estimation under user-level LDP is to estimate $\\theta = \\mathbb{E}_{X\\sim\\mu}[X]$ by choosing (i) an $a$-LDP mechanism $Q$ that will generate data $Z_{(1)}, ..., Z_{(n)}$ from $X_{(1)},..., X_{(n)}$, and (ii) an estimator $\\hat{\\theta} : \\mathcal{Z}^n \\rightarrow [0,1]$. The difficulty of such estimation task is measured by a metric referred to as the worst-case risk over $\\mu$, and defined by:\n$R_{a,n,M} = \\inf_{\\mathcal{Q} \\in \\mathcal{Q}_a, \\, \\hat{\\theta}} \\sup_{\\theta \\in \\Theta} \\mathbb{E}_Z[\\lvert\\hat{\\theta}(Z_{(1:n)}) - \\theta\\rvert].\t(3)$"}, {"title": "3 Distribution-Aware Mean Estimation (DAME)", "content": "In this section, we present the proposed algorithm to perform private mean estimation under user-level LDP. We refer to the latter as distribution-aware mean estimation (DAME) algorithm, to emphasise that it works under user data set size heterogeneity.\nHigh-level Description. Similar to other interactive algorithms proposed in previous work (Berrett and Butucea, 2020; Acharya et al., 2022b,a; Kent et al., 2024; Berrett and Butucea, 2020), DAME proceeds in a two-phase procedure. In the first phase, coined the localisation phase, private data of the first half of users is discretised and privatised via a calibrated randomised response mechanism (Warner, 1965). This phase aims to identify a candidate bin where the true mean lies with high probability. In the second phase, coined the estimation phase, private data of remaining users is projected onto the candidate bin (slightly enlarged) and privatised via the Laplace mechanism (Dwork et al., 2014, Definition 3.3) where the added noise scales with the width of the enlarged candidate bin. The novelty of DAME is that it adapts the bin size to the data set size distribution M, and uses a novel biasing/debiasing procedure in the estimation phase to include data from all users even those that have few samples. The following paragraphs provide additional details regarding the two phases involved in DAME.\nAlgorithmic Details. More precisely, we assume an even number of users n, discarding one user if we need to, and use the first n/2 users for the localisation phase and the last n/2 for the estimation phase. The interval [-1,1] is partitioned into non-overlapping sub-intervals $I_j$ (also called bins) of width $2\\tau$, where $\\tau > 0$ is given by:\n$\\tau = \\sqrt{\\frac{2\\log(8(\\sqrt{m}na^2 \\vee 1))}{m}} ,\\qquad(4)$\nwith $m \\in \\mathbb{N}^*$ being the effective maximum data set size and standing as an hyper-parameter of the DAME. We denote by $l$ the bin index containing the true mean $\\theta$, that is $\\theta \\in I_l$.\n\u2460 In the localisation phase, each user $u \\in [n/2]$ such that her number of samples $m_u$ verifies $m_u \\geq m$ computes her sample mean $\\bar{X}_m^{(u)} = (1/m_u)\\sum_{t=1}^{m_u} X_t^{(u)}$, identifies in which sub-intervals $\\bar{X}_m^{(u)}$ falls into, and computes the indicator vector $V^{(u)} = (V_j^{(u)})_{j\\in [N]}$ defined, for any $j \\in [N]$, by\n$V_j^{(u)} = \\mathbb{1}_{\\{\\bar{X}_{m_u}^{(u)} \\in \\bigcup_{k\\in\\{j-1,j,j+1\\}} I_k \\}}.\t(5)$\nInformally, we say that user $u$ votes for the $j$-th bin if $V_j^{(u)} = 1$. A user therefore votes for the bins that either contain its empirical mean or are neighbors of the bin containing its empirical mean. This ensures that $I_l$, the interval containing the true mean $\\theta$, receives a vote with high probability even when $\\theta$ is close or equal to the border of the bin. The indicator vector of users $u \\in [n/2]$ with $m_u \\leq m$ is given by $V^{(u)} = 0$. In other words, users with low number of samples are not allowed to take part to the vote.\nThen, a privatised version $\\tilde{V}^{(u)}$ of $V^{(u)}$ is computed using the randomised response mechanism for binary vectors with three non-zero entries (Kent et al., 2024, Lemma 15). More precisely, for any $j \\in [N]$, $\\tilde{V}_j^{(u)}$ is defined as:\n$\\tilde{V}_j^{(u)} = \\begin{cases} V_j^{(u)} & \\text{with proba. } \\pi_{a/6} = \\frac{e^{a/6}}{1+e^{a/6}},\\\\ 1-V_j^{(u)} & \\text{otherwise}. \\end{cases}\\t(6)$\nThe candidate bin $I_j$ is the one that receives the highest number of votes, that is:\n$j = \\arg\\max_{j\\in[N]} \\sum_{u=1}^{n/2} \\tilde{V}_j^{(u)}.\t(7)$\n\u2461 In the estimation phase, each remaining user $u \\in [n/2+1, n]$ computes an estimate of her respective local empirical mean that is shrunk towards the mid-point $s_j$ of $I_j$, and defined as:\n$\\hat{X}_j^{(u)} = \\frac{\\sqrt{m_u} \\wedge \\sqrt{m}}{\\sqrt{m}} \\bar{X}_{m_u}^{(u)} + \\left( 1 - \\frac{\\sqrt{m_u} \\wedge \\sqrt{m}}{\\sqrt{m}} \\right) s_j.\t(8)$\nThen, $\\hat{X}_j^{(u)}$ is projected onto $[L_j, U_j]$, an enlarged copy of $I_j$ where $6\\tau$ are added to the left and right borders to ensure that shrunk estimates are not affected by the projection, with high probability. A Laplace noise scaling with the width of $[L_j, U_j]$ is then added to preserve privacy. For any $u \\in [n/2 + 1,n]$, the resulting local mean estimate for user $u$ writes:\n$\\tilde{X}_j^{(u)} = \\Pi_j \\left( \\hat{X}_j^{(u)} \\right) + \\frac{14\\tau}{a} \\ell_u,$\nwhere $\\Pi_j (\\cdot)$ is the projection onto $[L_j, U_j]$.\nLastly, the estimate of the true mean $\\theta$ is given by:\n$\\hat{\\theta} = \\frac{\\sum_{m=1}^n\\frac{\\sqrt{m}}{\\mathbb{E}_{m\\sim M}[\\sqrt{m} \\wedge m]} (\\sqrt{m_u} / \\sqrt{m} ) \\tilde{X}_j^{(u)}}{\\mathbb{E}_{m\\sim M}[\\frac{\\sqrt{m}}{\\sqrt{m} \\wedge m}]}.\t(9)$"}, {"title": "4 Theoretical Analysis", "content": "In this section, we present an upper bound, obtained via DAME detailed in Algorithm 1, on the worst-case risk $R_{a,n,M}$ defined in (3). Furthermore, we also derive a lower bound on $R_{a,n,M}$. These two non-asymptotic bounds allow us to discuss the asymptotic optimality of our results, while drawing connections with known results from the private mean estimation literature.\n4.  1 Lower and Upper Bounds on $R_{a,n,M}$\nAssumption. In order to derive our non-asymptotic theoretical results, we consider the following assumptions on the main parameters characterising the considered distribution-aware user-level LDP paradigm.\nH1 (Finite expectation M). The data set size distribution M is known and such that $\\mathbb{E}_{m \\sim M}[m] < \\infty$.\nH2 (Bounded support of $\\mu$). The common data distribution $\\mu$ admits a known support defined as [-1,1].\nH3 (High privacy regime for a). The LDP parameter $a > 0$ is set such that $a \\leq 2^{2/35}$.\nH1 is a rather weak assumption satisfied by most discrete distributions encountered in practice. H2 is a common assumption in local differential privacy made for instance in Duchi et al. (2018); Bassily (2019); B\u0142asiok et al. (2019). In the worst-case, the square dependency on the range cannot be avoided but for some distributions, better results can be obtained (Bun and Steinke, 2019). Lastly, the high privacy regime in H3 is a rather strong assumption that we make for the sake of simplicity. This assumption mainly allows to re-use results derived in Duchi et al. (2018), that also rely on H3. We believe our results could be extended to lower privacy regimes but leave this task to future work.\nLower bound. Theorem 1 below provides a lower bound on the worst-case risk $R_{a,n,M}$ defined in (3).\nTheorem 1 (Lower bound). Assume H1-3. Then, there exist $c_1, c_2 > 0$, independent of $a$, $n$ and $m$, such that the following lower bound holds:\n$R_{a,n,M} \\geq \\max_{a \\in \\mathbb{N}} \\frac{c_1 \\exp(-c_2na^2 \\mathbb{P}_{m \\sim M}(m > a)^2)}{na^2 \\mathbb{E}_{m \\sim M}[\\sqrt{m} \\mathbb{1}\\{m \\leq a\\}]^2 \\vee 1}.\t(10)$\nThe positive constants $c_1$ and $c_2$ are explicitly given in Appendix S1.\nProof sketch, see Appendix S1 for more details. Consider probability distributions $\\mu_0$ and $\\mu_1$ supported on $\\{-1,1\\}$ such that $\\mu_0(1) = (1 - \\delta/2)$ and $\\mu_1(1) = (1 + \\delta/2)$. Consider for $i \\in \\{0,1\\}$, $\\nu_{\\mu_i}$ where $\\nu_{\\mu}$ is described in eq. (1). From a sequential application of LeCam's bound, Bretagnolle-Huber (Yu (1997)) and (Duchi et al., 2014, Th 1), it holds that $R_{n,a,M} \\geq \\frac{a}{\\sqrt{4}} \\exp(-12na^2D_{TV} (\\nu_0, \\nu_1)^2)$. Then Lemma S1"}, {"title": "Distribution-Aware Mean Estimation under User-level LDP", "content": "gives $D_{TV} (\\nu_0, \\nu_1) \\leq \\mathbb{E}_{m\\sim M}[\\sqrt{D_{KL}(\\mu_0, \\mu_1)} \\wedge 1]$ and Lemma S2 gives $D_{KL}(\\mu_0, \\mu_1) \\leq 3\\delta^2$ for $\\delta \\in [0,1]$. Then choosing $\\delta^2 = \\frac{1}{4(na^2\\mathbb{E}_{m\\sim M}[\\sqrt{m} \\mathbb{1}\\{m\\leq a\\}]^2\\vee 1)}$ and optimising over $a$ gives the lower bound.\nThe lower bound in (10) means that there exists a universal constant $c_2$ such that given $M$, $a$, $n$, and for any user-level LDP algorithm returning an estimate $\\hat{\\theta}$ of $\\theta = \\mathbb{E}_{X\\sim\\mu}[X]$, there exists a choice of $\\mu$ such that for any $a \\in \\mathbb{N}$, it holds that\n$\\mathbb{E}[\\lvert\\hat{\\theta} - \\theta\\rvert^2] = \\Omega \\left( \\frac{\\exp(-c_2na^2\\mathbb{P}_{m \\sim M}(m > a)^2)}{na^2\\mathbb{E}_{m \\sim M}[\\sqrt{m} \\mathbb{1}\\{m < a\\}]^2 \\vee 1} \\right).$\nUpper bound. Our next result, provided in Theorem 2, analyses the performance of DAME and therefore provides an upper bound on the worst-case risk $R_{n,a,M}$ defined in (3).\nTheorem 2 (Upper bound). Assume H1-3. Let $c_3$, $c_4$, $c_5 > 0$ be universal constants, independent of $n$, $a$ and $M$. Consider the function $\\phi : a \\in \\mathbb{N}^* \\mapsto \\frac{c_5}{na^2}\\log[\\frac{c_4(ana^2 \\vee 1)}{\\log(c_4(ana^2 \\vee 1))}]$ and set $\\mathfrak{m} = \\arg\\max_{a\\in\\mathbb{N}^*} \\{\\mathbb{P}_{m \\sim M} (m \\geq a)^2 \\geq \\phi(a) \\wedge 1\\}$. Then, we have the following lower bound.\n$R_{a,n,M} \\leq \\frac{c_3 \\ln(c_4(\\sqrt{\\mathfrak{m}}na^2 \\vee 1))}{na^2(\\mathbb{E}_{m \\sim M}[\\sqrt{m} \\wedge \\mathfrak{m}])^2} \\wedge 4.\t(11)$\nThe positive constants $c_3$, $c_4$ and $c_5$ are explicitly given in Appendix S2.\nProof sketch, see Appendix S2 for more details. The upper bound is provided by DAME which is instantiated with $\\mathfrak{m}$ as specified in Theorem 2. The proof starts by a bias-variance decomposition of the objective and we first focus on the bias. Thanks to Hoeffding bounds (Hoeffding, 1963), each user can estimate $\\theta$ up to a precision scaling in approximately $1/\\sqrt{m_u}$. Since the bins size scales with $1/\\sqrt{\\mathfrak{m}}$, users with data set size higher than $\\mathfrak{m}$ will vote for $I_l$ or its neighboring bin with high probability. However, because of the privatisation, for each user (including those with low data set size), a bin could gain or lose a vote with probability $1 - \\pi_{a/6}$. Lemma S5 in the Appendix precisely upper bounds the probability that the localisation is not successful, i.e., $j$ is at distance at least 3 from the optimal bin $l$. If the localisation is not successful, the error is upper bounded by 4. If the localisation is successful, a user $u$ with a high number of samples ($m_u \\geq \\mathfrak{m}$) is likely to have its empirical mean $\\bar{X}_{m_u}$ in $[L_j, U_j]$ since this interval contains $\\theta$ and is of size $1/\\sqrt{\\mathfrak{m}}$ up to log factors (see Lemma S7). Users with low number of samples are unlikely to be in this interval and therefore their estimate $\\hat{X}_j^{(u)}$ of the mean is a linear combination"}, {"title": "Distribution-Aware Mean Estimation under User-level LDP", "content": "of their empirical mean and $s_j$ the middle point of bin $I_j$ where coefficients are chosen to guarantee that $\\hat{X}_j^{(u)}$ lies in $[L_j, U_j]$. This procedure adds a bias that can be computed explicitly and is removed when $\\hat{\\theta}$ is estimated (see eq. (9)) therefore ensuring that the error added by users with low number of samples is controlled (see Lemma S8 and Lemma S10). We then focus on the variance (see Lemma S11) which is given by $\\mathbb{V}ar(\\hat{X}_j^{(u)})/\\mathbb{E}_{m \\sim M}[\\sqrt{m} \\wedge \\mathfrak{m}]$ by definition of $\\hat{\\theta}$. The variance of $\\tilde{X}_j^{(u)}$ is the sum of the variance of the Laplace noise and the variance of the estimates, the latter being controlled by the projection. The precise formula for $\\mathfrak{m}$ trades-off the probability of finding the correct bin in the localisation phase and the error terms due to the variance.\nTo reach the upper bound presented in Theorem 2, $\\mathfrak{m}$ must be set as the solution of the optimisation problem\n$\\arg\\max_{\\alpha \\in \\mathbb{N}^*} \\{\\mathbb{P}_{m \\sim M} (m \\geq a)^2 - \\phi(a) \\wedge 1 > 0\\}.\t(12)$\nNotice that $\\phi$ is decreasing, $\\phi(1) > 0$ and $\\phi(\\exp(na^2)) \\leq 0$. It follows that $\\mathfrak{m}$ can be found via a binary search with less than $2[na^2]$ iterations.\nThe optimality of our bounds and comparison with previous work is discussed in Section 4.2.\n4.  2 Discussion\nIn this section, we demonstrate that our bounds are asymptotically optimal up to log-factors. In addition, we show that they reduce to known bounds in the item-level LDP setting or the homogeneous (i.e., $m_u = \\mathfrak{m} \\in \\mathbb{N}^*$) user-level LDP setting. Lastly, we illustrate numerically our theoretical insights by plotting upper and lower bounds for classical distributions and studying the empirical performance of DAME on synthetic data.\nAsymptotic Optimality. First, we claim that DAME is asymptotically optimal up to a log factor as the number of users $n$ grows towards infinity. Indeed, by taking $a \\rightarrow \\infty$ in Theorem 1, we get the following lower bound:\n$R_{a,n,M} = \\Omega\\left( \\frac{1}{na^2\\mathbb{E}_{m \\sim M}[\\sqrt{m}]^2} \\right).\t(13)$\nLooking at the upper bound in Theorem 2, since, for any $a \\in \\mathbb{N}$, $\\lim_{n\\rightarrow \\infty} \\phi(a) = 0$, we get that $\\mathfrak{m} \\rightarrow \\infty$. Furthermore, we have $\\lim_{n\\rightarrow \\infty}\\mathfrak{m}/(na^2) \\leq 1$. Indeed, $\\mathfrak{m} > na^2$ implies that, for any $x \\leq na^2$, $\\mathbb{P}(m \\geq x) \\geq \\sqrt{\\phi(x)} \\geq \\sqrt{\\frac{c}{na^2}}$, leading to $\\mathbb{E}_{m\\sim M}[m] > \\int_0^{na^2} \\mathbb{P}_{m \\sim M}(m > x)dx \\geq \\sqrt{na^2}$"}, {"title": "Corentin Pla, Hugo Richard, Maxime Vono", "content": "and therefore violate H1. Hence", "that": "n$\\lim_{n\\rightarrow \\infty} R_{a,n,M} \\frac{\\frac{\\log(na^2)}{na^2\\mathbb{E}_{m \\sim M}[\\"}]}