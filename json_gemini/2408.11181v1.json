{"title": "A Full DAG Score-Based Algorithm for Learning Causal Bayesian Networks with Latent Confounders", "authors": ["Christophe Gonzales", "Amir-Hosein Valizadeh"], "abstract": "Causal Bayesian networks (CBN) are popular graphical probabilistic models that encode causal relations among variables. Learning their graphical structure from observational data has received a lot of attention in the literature. When there exists no latent (unobserved) confounder, i.e., no unobserved direct common cause of some observed variables, learning algorithms can be divided essentially into two classes: constraint-based and score-based approaches. The latter are often thought to be more robust than the former and to produce better results. However, to the best of our knowledge, when variables are discrete, no score-based algorithm is capable of dealing with latent confounders. This paper introduces the first fully score-based structure learning algorithm searching the space of DAGs (directed acyclic graphs) that is capable of identifying the presence of some latent confounders. It is justified mathematically and experiments highlight its effectiveness.", "sections": [{"title": "1 Introduction", "content": "Causal networks, a.k.a. causal Bayesian networks (CBN) [15], are graphical probabilistic models that encode cause-and-effect relationships. Like Bayesian networks (BN), they are constituted by i) a directed acyclic graph (DAG) whose nodes represent random variables and whose edges encode their relationships; and ii) a set of conditional probability distributions of the nodes/random variables given their parents in the graph. However, unlike BNs, the semantics of the edges is not merely correlation but rather a causal relationship, that is, an arc from A to B states that A is a direct cause of B. CBNs are important for Artificial Intelligence because they enable to perform the same kind of reasoning as humans do, in particular counterfactual reasoning (if I had done this, what would have happened?).\nAlthough it is well-known that learning the structure of CBNS from only (observational) data is theoretically not always possible [15], many algorithms have been proposed in the literature for this purpose. When there exists no unmeasured confounder, i.e., no unobserved direct common cause of some measured variables, they can be essentially divided into two classes: constraint-based and score-based approaches. The former [20, 16, 4, 30] rely on statistical conditional independence tests to uncover the independence properties underlying the probability distribution that generated the data, thereby learning the graphical structure of the causal model. These methods are often not able to uncover the whole DAG of the CBN, so they provide weaker information in the form of a Completed Partially Directed Acyclic Graph (CPDAG). In such a graph, only the directed edges represent \"true\" causal relations, the undirected ones representing correlations, their causal direction remaining unknown. On the other hand, score-based approaches [3, 6, 26] identify the DAG of the CBN as the one maximizing some fitness criterion on the data. They rely on either approximate or exact optimization techniques to uncover the searched DAG. However the orientations of its arcs may not always have a causal meaning. So this DAG is mapped into the CPDAG of its Markov equivalence class, which is the best that can be extracted in terms of causality from the data. Score-based approaches are usually considered more robust than constraint-based approaches, notably because, in the latter, errors in statistical tests can chain and decrease significantly the quality of the resulting CPDAGs.\nHowever, in most practical situations, some variables play an important role in the causal mechanism and, yet, for different reasons, they are not or cannot be observed in the data. For instance, their measuring may be too expensive or it would require unethical processes. Constraint-based methods have been successfully extended to cope with such latent (unobserved) variables [5, 21, 31]. For score-based algorithms, it is somewhat different: it is commonly admitted that they are unable to cope with latent variables because they rely on searching for DAGs and DAGs are inadequate in the presence of latent variables. An extension of DAGs called Maximal Ancestral Graphs (MAG) [18] has been introduced precisely to fix this issue and score-based approaches have been adapted to learn MAGs [17, 13, 23]. Unfortunately, currently, they can only cope with scoring MAGs over continuous variables. Yet, this is restrictive because there exist situations in which variables are discrete by nature and cannot be meaningfully extended as continuous ones, e.g., non-ordinal variables such as colors, locations, types of devices, etc.\nIn this paper, we address problems in which all the random variables are discrete. In [22],it was shown that causal models with arbitrary latent variables can always be converted into semi-Markovian causal models (SMCM), i.e., models in which latent variables have no parent and only two children, while preserving the same independence relations between the observed variables. So, to deal with latent confounders, we focus on learning SMCMs. More precisely, we show that, without any prior knowledge about the latent confounders or their number, DAGs learnt from observational data by latent confounders-unaware score-based approaches encode sufficient information to recover many latent confounders and their locations. Exploiting this property, we provide and justify a structure learning algorithm that i) only relies on scores; ii) uses only DAGs; and iii) is capable of identifying some latent confounders and their locations.\nThe rest of the paper is organized as follows. Section 2 presents formally causal models and some algorithms for learning BN and/or CBN structures from observational data that can cope with latent confounders."}, {"title": "2 Causal Models and Structure Learning", "content": "In the paper, bold letters represent sets. X denotes a set discrete random variables. For a directed graph G, Ch\u00e7 (X) and Pag (X) denote the set of children and parents of node X respectively, i.e., the set of nodes Y such that there exists an arc from X to Y and from Y to X respectively. A causal model over X is defined as follows [15]:\nDefinition 1. A causal model is a pair (G, ) where G = (\u03a7, \u03b5) is a DAG\u00b9 and E is a set of arcs. To each Xi \u2208 X is assigned a random disturbance \u03be\u2081. \u0398 = {fi(Pag(Xi), \u00a7i)}x;\u2208x\u222a{P(fi)}x;\u2208x, where fi's are functions assigned to Xi's and P are probability distributions over disturbances \u03bei.\nIt is easy to see that a causal model can be represented equivalently by a Bayesian network \u2013 BN [14]:\nDefinition 2. A BN is a pair (G, \u2299) where G = (X,E) is a directed acyclic graph (DAG), X represents a set of random variables, E is a set of arcs, and \u2299 = {P(X|Pa\u04ab(X))}xex is the set of the conditional probability distributions (CPD) of the nodes / random variables X in G given their parents Pag (X) in G. The BN encodes the joint probability over X as P(X) = \u220fx\u2208x P(X|Pag(X)).\nCausal models impose that the arcs are oriented in the direction of causality, that is, an arc X \u2192 Y means that X is a direct cause of Y. In this case, the BN is called a CBN. In general, BNs do not impose this restriction since they only model probabilistic dependences. Hence a BN containing only Arc X \u2192 Y is equivalent to one containing Arc Y \u2192 X. More precisely, the independence model of a BN is specified by the d-separation criterion [14]:\nDefinition 3 (Trails and d-separation). Let G be a DAG. A trail C between nodes X and Y is a sequence of nodes (X\u2081 = X,..., Xk = Y) such that, for every i \u2208 {1, ..., k \u2212 1}, G contains either Arc Xi\nXi+1.\nXi+1 or Arc Xi\nLet Z be a set of nodes disjoint from {X, Y}. X and Y are said to be d-separated by Z, which is denoted by (X \u0130\u00e7 Y|Z), if, for every trail C between X and Y, there exists a node Xi \u2208 C, i \u00a3 {1, k}, such that one of the following two conditions holds:\n1. (Xi\u22121, Xi, Xi+1) is a collider, i.e., G contains Arcs Xi\u22121 \u2192 Xi and Xi\nXi+1. In addition, neither Xi nor its descendants in G belong to Z. The descendants of a node are defined recursively as the union of its children and the descendants of these children.\n2. (Xi\u22121, Xi, Xi+1) is not a collider and X\u2081 belongs to Z.\nSuch trails are called blocked, else they are active. Let U, V, Z be disjoint sets of nodes. Then U and V are d-separated by Z if and only if X and Y are d-separated by Z for all X \u2208 U and all Y\u2208 V.\nLet U, V, ZC X be disjoint sets and let P be a probability distribution over X. We denote by UpVZ the probabilistic conditional independence of U and V given Z. The independence model of BNs is the following:\n(U19 VIZ) \u21d2 UpV|Z.   (1)\nTwo BNs with the same set of d-separation properties therefore represent the same independence model. Any graphical model satisfying Eq. (1) is called an I-map (independence map). The d-separation criterion implies that two BNs represent the same independence model if and only if they have the same skeleton and the same set of v-structures [29]: the skeleton of a directed graph G is the undirected graph obtained by removing all the orientations from the arcs of G; v-structures are colliders (Xi-1, Xi, Xi+1) such that G does not contain any arc between Xi-1 and Xi+1. The directions of the arcs in v-structures are therefore identical for all BNs that represent the same sets of independences. When Eq. (1) is substituted by:\n(U19 VIZ) \u21d4 UpV|Z,   (2)\nthen the graphical model is called a P-map (perfect map).\nTo learn the structure of a BN from observational data, it is usually assumed that the distribution P that generated the data has a P-map (although there exist some papers that relax this assumption [16, 10, 11]). Then, it is sufficient to learn the independence model of the data (the set of conditional independences): each independence XPY Z necessarily implies the lack of an arc between X and Y in the BN. The (undirected) edges of the skeleton therefore correspond to all the pairs of nodes (X, Y) for which no conditional independence was found. The set of v-structures (X, Z, Y) is the set of triples (X, Z, Y) such that i) edges X \u2013 Z and Z - Y belong to the skeleton and ii) there exist sets Z Z {Z} such that XpY|Z. The edges of the skeleton corresponding to v-structures can be oriented accordingly. Now, to avoid creating additional spurious v-structures or directed cycles (which are forbidden in DAGs), some edges need necessarily be oriented in a given direction. These are identified using Meek's rules [12] and can be computed in polynomial time [2]. The graph resulting from all these orientations is called a CPDAG (Completed Partially Directed Acyclic Graph). To complete the learning of the BN's structure, there just remains to orient the remaining undirected edges. To do so, it is sufficient to sequentially apply the following two operations until there remains no undirected edge: i) orient in any direction one (arbitrary) edge; and ii) apply Meek's rules. This is precisely what constraint-based algorithms like PC [20], PC-stable [4], CPC [16], IC [29] or FCI [21] do, relying on statistical independence tests. MIIC [30] essentially performs the same operations but exploiting multivariate information instead.\nThere exist many other algorithms, based notably on learning Markov blankets [25] or on scoring DAGs [6, 8, 3, 26]. The key idea of score-based approaches is to assign to each DAG a score representing its fitness on the data. Under some assumptions, the one maximizing this criterion is the one that generated the data. In the rest of the paper, we exploit the BIC score [19]:\nS(XIZ) = \u2211x\u2208\u03a9\u03c7 \u2211z\u2208\u03a9z Nxzlog(Nxz\nNz) \u2212 1/2 log(|D|)dim(X|Z),\nwhere S(XIZ) denotes the score of node X given parent set Z; \u03a9\u03c7 and Oz represent the domains of X and Z repectively; Nxz is the number of records in Database D such that X = x and Z = z;\nNz = \u2211x\u2208\u03a9\u03c7 Nxz; and, finally, dim(X|Z) is the number of free parameters in the conditional probability distribution P(X|Z), i.e., dim(X|Z) = (|\u03a9\u03c7| \u2013 1) \u00d7 |\u03a9z|. The term log(|D|)dim(X|Z) is called the penalty of the score.\nIn the literature, v-structures are considered to represent causal relations, that is, the directions of their arcs have a causal meaning. This implies that, when there exist no latent confounder, CPDAGS are precisely the best that can be extracted in terms of causality from the data."}, {"title": "3 A New Full Score-based Causal Learning Algorithm", "content": "In the rest of the paper, X is divided into Xo and XH, which represent sets of observed and hidden (latent) variables respectively. We assume that there exists an underlying probability distribution P* over X = Xo UXH that generated a dataset D*. But, as the variables in XH are unobserved (they are the latent confounders), only the projection D of D* over Xo, i.e., the dataset resulting from the removal from D* of all the values of the variables of XH, is available for learning. In addition, we assume that P* is decomposable according to some DAG G*. The goal is to recover G*.\nThe key idea of our algorithm is summarized on Figure 1: the left side displays part of Graph G*, which contains a latent confounder L\u2208 XH and represents the structure of the causal network that generated the data; Graph G on the right should be the one learnt by a score-based algorithm. Indeed, in G*, there exists no set ZC Xo that d-separates A and B (because Trail (A, L, B) is active). Hence, provided G* is a P-map, A and B should be dependent and a structure with an arc between A and B should have a higher score than one without. Assume that this arc is A \u2192 B. For the same reason, a structure with an arc between A and C (resp. B and D) should have a higher score that one without. Now, given any Z {A}, node B is not d-separated from C in G* because Trail (C, A, L, B) is active. But it would be on Fig. 1.b if there were no arc between B and C. This is the reason why score-based algorithms tend to produce structures with such an arc and analyzing such triangles (A, B, C) in the learnt graph should provide some insight on the location of the latent confounders. This intuition is confirmed by the next proposition.\nProposition 1. Assume that there exists a perfect map G* = (\u03a7, \u03b5) for Distribution P* and that X H is the set of latent confounders, i.e., all the nodes of XH have no parent and exactly two children in G*, which both belong to Xo."}, {"title": "Algorithm 1: Learning with confounders", "content": "Input: Dataset D\nOutput: The CPDAG of the learnt CBN\n1 G \u2190 DAG learnt from D by a score-based algorithm\n2 T the triangles of G satisfying Rule 2\n// Get the latent triangles\n3 T1 \u2190 \u2205 // latent triangles of type 1\n4 T3 \u2190 \u2205 // latent triangles of type 3\n5 foreach triangle T = (A, B, C) in T do\nif T is of Type 1 and |Pag(B)| \u2265 3 then\nT1 \u2190 T1 \u222a T\nelse if T is of Type 3 and there exists\nD\u2208 (Pag(B)\\{A}) \u222a (Ch\u2081(B)\\{C}) such that there\nexists Z \u2286 Xo\\\\{C, D} such that A \u2208 Z and\nD\u22a5C|Z then\nT3 \u2190 T3 \u222a T\n// Recreate the latent variables\n10 foreach triangle T = (A, B, C) in T1 \u222a T3 do\n11 Add a new node L (confounder) to G\n12 Remove from G Arc A \u2192 B\n13 Remove from G the arc between B and C\n14 Add arcs L \u2192 A and L \u2192 B to G\n15 M the CPDAG of G\n16 return CPDAG M\nRule 2 and Algorithm 1 require the determination of some set Z Xo such that some pairs of nodes are conditionally independent given Z. Below, we suggest two algorithms for this purpose. The first algorithm to determine Set Z consists of exploiting the fact that, in I-maps, d-separation implies conditional independences. Hence, applying a d-separation analysis on G using, e.g., van der Zander and Li\u015bkiewicz [28]'s algorithm, it is possible to get some d-separating set Z and, consequently, a set inducing a conditional independence. The following proposition justifies that this approach can be used\u2074:\nProposition 4. Let D* be a dataset generated by some distribution P* over X for which there exists a perfect map G* = (X, E), and let D be the projection of D* over Xo. Then, as |D|\u2192 \u221e, every DAG G maximizing the BIC score over D is a minimal I-map.\nHowever, when the database is not \"too\" large and Graph G is not highly trustworthy, another option is to exploit Algorithm 2 which adds iteratively to Z the variable X that allows to reduce the most the dependence between the pair of nodes U, V until an independence between U and V is inferred or no independence can be proven. In essence, this is the approach followed by MIIC [30], except that MIIC estimates dependences through an information theoretic criterion whereas we exploit the BIC score:\nDefinition 4. For every pair of variables U, V and every set of variables Z, let fBIC (U, VIZ) be defined as:\nfBIC(U, VIZ) = 2 \u00d7 (S(UV,Z) \u2212 S(UZ) \u2212 S(VZ) + 1/2 log(|D|)\u03b4)  (5)\nwhere \u03b4 = (|\u03a9\u03c5| \u2212 1) \u00d7 (|\u03a9\u03bd| \u2212 1) \u00d7 |z| and \u03a9\u03c5 (resp. \u03a9\u03bd, \u03a9z) is the domain of variable U (resp. V, Z), and S(..) is the BIC score.\nThe following proposition justifies Algorithm 2:"}, {"title": "Algorithm 2: Finding a set Z s.t. UVZ", "content": "Input: nodes U, V, Dataset D, max size h of Z, risk level a, sets C and F of compulsory and forbidden variables, i.e., Z \u2287 C and Z\u2229F = \u2205\nOutput: A set Z s.t. U \u22a5 V | Z if such set is found, else False\n1 Z \u2190 C; F \u2190 F \u222a {U, V}\n2 \u03b4 \u2190 (\u03a9\u03c5| \u2212 1) \u00d7 (|\u03a9v| \u2212 1) \u220fx\u2208z \u03a9x\n3 if | Z| > h then return False;\n4 if fBIC(U, VIZ) < x\u00b2(a) then return Z;\n5 while | Z| < h do\n6 X = argmin{fBIC(U, V|ZU{Y}) : Y\u2208 Xo\\(ZUF)}\n7 Z\u2190 ZU {X}\n8 \u03b4 \u03b4 \u220fx\u2208 \u03a9x\n9 if fBIC(U, VIZ) < x\u00b2(a) then return Z;\n10 return False\nProposition 5. If U and V are independent given a set Z, the formula of Eq. (5) follows a \u03c7\u00b2 distribution of \u03b4 degrees of freedom. So, given a risk level \u03b1, U and V are judged independent if the value of Eq. (5) is lower than the critical value x\u00b2(\u03b1) of the \u03c7\u00b2 distribution.\nTo conclude this section, we provide below the time complexity of Algorithm 1, assuming (as we did in our experiments) that the algorithm used for determining the conditioning sets Z required in Rule 2 and Algorithm 1 is Algorithm 2:\nProposition 6. Assume that the existence of d-separating sets Z is checked with Algorithm 2 with h the maximal size allowed for Z and BIC defined as Eq. (5). Let n and m denote the number of nodes and arcs of G as defined on Line 1 respectively. Let k be the maximum number of parents and children of the nodes in G. Then the time complexity of Algorithm 1 over dataset D is O(n\u00b2k\u00b3h|D| + mlog n)."}, {"title": "4 Experiments", "content": "In this section, some experiments on classical benchmark CBNS (child (|XO| = 20), water (|XO| = 32), insurance (|XO| = 27), alarm (|XO| = 37), barley (|XO| = 48)) from the BNLearn Bayes net repository are performed to highlight the effectiveness of our algorithm to find latent confounders and to recover CBN structures.\nFor each experiment, a CBN is selected, and some new (latent) variables Li are added to it. To make them confounders of a semi-Markovian causal model, for each Li, two nodes of Xo are randomly chosen to become Li's children. To fit the propositions of the paper, Line 1 of Algorithm 1 is performed using the CPBayes exact score-based learning algorithm [26]. For this purpose, Datasets D need to be converted into so-called instances that are passed as input to CPBayes. These contain all the possible nodes' sets that CPBayes will consider as potential parent sets. So, to control the combinatorial explosion it has to face, CPBayes requires limiting the number of possible parents of the nodes. In the experiments, we set this limit to 4 because i) no node of Xo had more than 4 parents in the original CBN (the one without confounders); and ii) this enabled to control the amount of computations performed by CPBayes (see [26] for more details). As a consequence, since the score-based algorithm may add 2 additional parents (A and C) to some Li's children (B), as shown in Fig. 1.b, all the Li's children are selected randomly but with the constraint that they have 1 or 2 parents in Xo. This upper bound constraint is only due to our use of CPBayes, not to Algorithm 1. But the lower bound is due to Proposition 2.\nTo discover that some nodes A and B are children of some confounder Li, all the learning algorithms rely in some way or another on the fact that A and B are conditionnally dependent given any set Z. This imposes some restrictions on the way the conditional probability distributions (CPD) of Li and its children should be generated. Actually, assume that they are uniformly randomly generated. Then the cells of the joint distribution P of A, B and their parents is a sample generated from a uniform distribution. Testing the conditional (in)dependence of A and B given some sets Z strictly included in A and B's parents amounts to marginalize out some variables from P or, equivalently, to sum some values of P. The sum of 2 independent variables uniformly distributed follows a triangular distribution and, by the central limit theorem, the sum of more than 2 variables tends to a variable normally distributed. As such, the values of the marginals of P have much more chances to be located on the mode of the distribution than on the tails. In other words, the cells of the marginals of P tend to have more or less the same values, which makes A and B appear to be independent, and no learning algorithm can determine that they are the children of a confounder. This is the reason why the CPDs of A, B and Li need to be generated differently.\nIn our experiments, the CPD of Li is set to a uniform distribution in order to maximize the chances of A and B to be dependent. For A (resp. B), for each value of its parents, the CPD of A (resp. B) is set to a mixture of a Dirichlet distribution whose hyperparameters ai are all set to 4 and a Dirac distribution. The weight of the latter is selected randomly between 2/3 and 5/6. Such mixtures tend experimentally to limit the effect of the central limit theorem but, of course, do not discard it completely. So, to check whether A and B have some chance to be identified as dependent, we test whether the values of their mutual information and their conditional mutual information given their parents are higher than some thresholds (these are some extreme cases for the Z sets mentioned in the preceding paragraph). If this is the case, the CPDs of A and B are judged admissible for the experiments. To make them realistic, the thresholds are defined as the averages of the mutual information and condition mutual information respectively of all the pairs of nodes with a common parent in the original CBN. The use of these information-theoretic criteria has been made to favor algorithms like MIIC over our algorithm.\nFor each CBN with confounders created as defined above, a dataset D* is randomly generated using the pyAgrum 1.13.0 library [7] and Dataset D which is given as input of the learning algorithms is the projection of D* over Xo. Algorithm 2 is exploited for independence testing and its risk level \u03b1 and Size h are set to 0.05 and 7 respectively. In the experiments, we compare 3 learning algorithms: Algorithm 1, MIIC [30] and FCI [21]. For MIIC, we use the pyAgrum's implementation with the NML correction to be more accurate. For FCI, we use the python causal-learn 0.1.3.8 package [32]. All the tables below display averages of the results over 50 CBN/datasets. All the experiments are executed on an Intel Xeon Gold 5218 CPU with 128GB of RAM.\nIn Table 1, to every original CBN, 2 confounders have been added whose domain sizes are equal to 2. The table compares the performance of Algorithm 1, MIIC and FCI for different CBNs with different dataset sizes. Columns ok and -ok contain the number of correctly and wrongly identified confounders respectively. Column \"prec.\" displays the precision metrics, i.e., it is equal to ok / (ok +\n-ok). Column \"recall\" is the usual recall metrics, i.e., it is equal to ok / the number of confounders Li added to the original CBN. The F1 score is defined as 2 \u00d7 (precision \u00d7 recall)/(precision + recall). Column \"time\" reports the average computation times in seconds of Lines 2 to 16 of Algorithm 1 (finding the confounders). These lines increase only marginally the structure learning computation times.\nFCI finds most of the latent confounders. This is the reason why, in Table 1, it is the best in terms of recall. Unfortunately, it also misidentifies numerous variables as confounder's children. This is the reason why its precision and F1 score are, by far, never the best. Here, we should emphasize that we identify confounders with connections, that is, we do not take into account o labels since those express an uncertainty about the existence of arrow heads. Converting every o- into \u2192 results in adding numerous false positive, which would decrease significantly the quality of the solutions found by FCI. MIIC identifies fewer confounders but it also makes much fewer mistakes, which makes it better in terms of F1 score. Algo. 1 makes even fewer mistakes and this is the reason why its precision is almost always the best of all the algorithms. Yet, it is somewhat cautious and tends to miss some confounders, which explains why its recall is not the best. However, the larger the size of the dataset, the higher the number of confounders correctly identified by Algorithm 1. This can also be observed in terms of F1 score: for small datasets, MIIC outperforms Algorithm 1 but this is the converse when |D| increases. This phenomenon illustrates empirically Proposition 1.\nTable 2 reports how the CPDAGs learnt by Algorithm 1, MIIC and FCI compare with those of the CBNs (with their confounders) that were used to generate the datasets. Columns \"ok\" (resp. \"miss\") indicate the number of arcs and edges that were learnt correctly (resp. that existed in the generating CBN but for which no arc nor edge was learnt). As can be observed, Algorithm 1 and MIIC are the best for these metrics and their results are quite comparable. Of course, for these metrics, the larger the dataset, the better the quality of the learnt CPDAGS. Column \"rev.\" displays the number of arcs in the CPDAG of the generating CBN that were learnt in the opposite direction, i.e., the direction of the causality is incorrectly learnt. For this metrics, FCI always outperforms the other algorithms. Note, however, that the number of reversed arcs is always very small for all the CBNs and all dataset sizes. Column \"type\" refers to the number of arcs (resp. edges) that were learnt as edges (resp. arcs), i.e., their types (directed, undirected) are incorrect. For this metrics, Algorithm 1 and MIIC usually outperform FCI and, in general, when Algorithm 1 outperforms MIIC, the difference is bigger than when this is the converse. Finally, Column \"xs\" reports the number of arcs or edges that belong to the learnt CPDAG but whose extremal nodes are linked neither by an arc nor by an edge in the generating CBN. Here, Algorithm 1 significantly outperforms both MIIC and FCI. This means that Algo- rithm 1 is less prone to learn spurious direct causes. Overall, empirically, Algorithm 1 is very competitive and often produces CPDAGs closer to those of the original CBNs than the other two methods"}, {"title": "5 Conclusion and Perspectives", "content": "In this paper, we have introduced the first score-based CBN structure learning algorithm for discrete variables that searches only the space of DAGs, exploits only observational data and, yet, is capable of identifying some latent confounders. It has been justified mathematically, notably through Proposition 1. In addition, theoretically, it is asymptotically guaranteed to produce an I-map. Experiments highlighted it effectiveness, especially for large datasets. Notably, both in terms of the CPDAGs and the latent confounders found, the results of this algorithm may be judged as very competitive compared to those of its constraint-based competitors like MIIC or FCI.\nFor future works, to be more scalable, we plan to substitute the use of the CPBayes on Line 1 of Algorithm 1 by a faster approximate algorithm like greedy hill climbing (GHC). Usually, GHC-like methods make more mistakes in the directions of the causal arcs learned than CPBayes. So, to compensate for this issue, the rules used in Lines 6 and 8 may certainly have to be improved. Notably, in Algorithm 1, we did not take into account Type 2 triangles (see Figure 3.b) because, empirically, they were very seldom encountered in the experiments. However, with GHC-like algorithms, this may not be the case anymore and they should be taken into account.\nPerhaps a more immediate improvement could be made by observing that, whenever Type 3 triangles are found, their A \u2192 C connection is in the wrong direction (see Figure 3.b). Therefore, to produce better CPDAGs, Algorithm 1 should reverse this arc and relearn the neighborhood of node C. In addition, as shown in Propositions 2 and 3, some structures are indistinguishable from the observational data point of view and, among all the structures of Fig. 2, Algorithm 1 makes the decision to select only those of Fig. 2.c and 2.e. So, in the same spirit as PAGs, the output of Algorithm 1 could be improved to express the uncertainty about which of these structures should be selected. Note that, in this case, PAG's labels are not sufficient since the uncertainty not only concerns the location of arrow heads but also the very existence of some arcs (like C \u2192 B of Fig. 2.e) for which no independence test can detect that they can be dispensed with."}]}