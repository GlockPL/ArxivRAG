{"title": "Conditional Vendi Score: An Information-Theoretic Approach to Diversity Evaluation of Prompt-based Generative Models", "authors": ["Mohammad Jalali", "Azim Ospanov", "Amin Gohari", "Farzan Farnia"], "abstract": "Text-conditioned generation models are commonly evaluated based on the quality of the generated data and its alignment with the input text prompt. On the other hand, several applications of prompt-based generative models require sufficient diversity in the generated data to ensure the models' capability of generating image and video samples possessing a variety of features. However, most existing diversity metrics are designed for unconditional generative models, and thus cannot distinguish the diversity arising from variations in text prompts and that contributed by the generative model itself. In this work, our goal is to quantify the prompt-induced and model-induced diversity in samples generated by prompt-based models. We propose an information-theoretic approach for internal diversity quantification, where we decompose the kernel-based entropy $H(X)$ of the generated data $X$ into the sum of the conditional entropy $H(X|T)$, given text variable $T$, and the mutual information $I(X;T)$ between the text and data variables. We introduce the Conditional-Vendi score based on $H(X|T)$ to quantify the internal diversity of the model and the Information-Vendi score based on $I(X;T)$ to measure the statistical relevance between the generated data and text prompts. We provide theoretical results to statistically interpret these scores and relate them to the unconditional Vendi score. We conduct several numerical experiments to show the correlation between the Conditional-Vendi score and the internal diversity of text-conditioned generative models. The codebase is available at https://github.com/mjalali/conditional-vendi.", "sections": [{"title": "1 Introduction", "content": "Prompt-based generative models, including text-to-image and text-to-video generation schemes, are widely used in various artificial intelligence (AI) applications. In prompt-based generative AI, the sample creation process begins with a text input and produces a random output aligned with that text. The conditional nature of this sample generation distinguishes prompt-based generative models from standard unconditional generative models where the objective is to produce samples distributed similarly to real data without any guiding input prompt. Since most evaluation metrics for generative models had been developed for unconditional models in the previous decade, the recent literature has sought to create scores tailored specifically for text-conditioned generative models.\nThe existing evaluation metrics for prompt-based generative models typically focus on fidelity and relevance in sample generation, i.e., they assess the visual quality of the produced samples and their alignment with the input prompt. Relevance is often measured by calculating a similarity score between a shared embedding of the text and image samples, e.g. in ClipScore [1] which utilizes the CLIP embeddings of text and image data. Such shared embedding-based evaluation mechanisms have been further adapted to quantify the aesthetics, semantic consistency, and compositional accuracy of the generated data based on the input text prompt."}, {"title": "2 Related Work", "content": "Evaluation of deep generative models: The existing metrics for the evaluation of generative models can be divided into reference-dependent and reference-free categories, as discussed in [9]. As one type of reference-dependent metrics, a distance between generated and reference distributions is measured using metrics such as FID [10] and KID [11]. Other reference-based metrics such as the Inception Score [12], GAN-train/GAN-test [13], Precision/Recall [2,3], and Density/Coverage [4] are defined to quantify the diversity and quality of generated data in comparison to the samples in the real dataset. In addition, assessing memorization and novelty has been studied in several references, including the authenticity score [14] and Feature Likelihood Divergence [15] to assess generalizability, and the rarity score [16], KEN [17] and FINC [18] proposed to assess novelty. Note that the memorization metrics are inherently reference-based. In contrast, reference-free evaluations [19, 20] measure diversity [21] and quality based only based on the generated data. Specifically, the Vendi [5,6] and RKE scores [7] fall into this category.\nEvaluation of conditional generative models: The evaluation of prompt-based generative models, including text-to-image and text-to-video models, has been studied in several related works. Most of the"}, {"title": "3 Preliminaries", "content": "Throughout the work, we focus on a conditional generative model that produces a data vector $X \\in \\mathcal{X}$ given an input text prompt $T \\in \\mathcal{T}$ according to a conditional distribution $P_{X|T}$, i.e., for text prompt $T = t$ the model outputs a random sample following $P_{X|T=t}$. We consider $n$ sample pairs $(t_i, x_i) \\sim P_T \\times P_{X|T}$ where each text prompt $t_i$ is drawn independently from the distribution $P_T$ and then the generated sample $x_i$ is generated according to $P_{X|T=t_i}$. Our goal is to quantify the internal diversity of the prompt-based generative model, influencing the variety of data generated $x_1,...,x_n$ independently of the diversity of input texts $t_1,..., t_n$.\nIn this section, we first discuss existing entropy-based approaches to the diversity evaluation of unconditional generative models and then review the definition of matrix-based conditional entropy and mutual information in the literature."}, {"title": "3.1 Entropy-based diversity scores for unconditional generative models", "content": "Consider generated samples $x_1, ..., x_n \\in \\mathcal{X}$ following the distribution $P_X$ of an unconditional generative model. For a kernel function $k : \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$, the kernel similarity matrix $K \\in \\mathbb{R}^{n \\times n}$ is:\n$K = \\begin{bmatrix} k(x_1,x_1) & \\cdots & k(x_1,x_n) \\\\ : & & : \\\\ k(x_n, X_1) & \\cdots & k(X_n, X_n) \\end{bmatrix}$   (1)\nFollowing the standard definition, a kernel function $k$ satisfies the positive semidefinite property (PSD), which means that the above kernel matrix will be PSD for any arbitrary selection of data points $x_1,..., X_n \\in \\mathcal{X}$, i.e., all its eigenvalues are non-negative. A well-known example of kernel functions is the Gaussian (RBF) kernel, which for a bandwdith parameter $\\sigma$ is defined as:\n$k(x, x') = exp(-\\frac{||x - x'||^2}{2\\sigma^2})$   (2)\nAssuming that a kernel function $k$ is normalized, i.e. $k(x,x) = 1$ for every $x \\in \\mathbb{R}^d$, then the non-negative eigenvalues $\\lambda_1,...,\\lambda_n$ of $K$ will add up to 1, implying that they represent a probability model. In the"}, {"title": "3.2 Matrix-based Conditional Entropy and Mutual Information", "content": "In the previous subsection, we reviewed the standard definition of order-a matrix-based entropy for PSD matrices. Here, we discuss an extension proposed by [8] to define matrix-based conditional entropy and mutual information for two variables $X \\in \\mathcal{X}$ and $T\\in \\mathcal{T}$. For variables $X$ and $T$, we consider normalized kernel functions $k_X : \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$ and $k_T : \\mathcal{T} \\times \\mathcal{T} \\rightarrow \\mathbb{R}$, where the kernel functions satisfy $k_X(x,x) = 1$ and $k_T(t,t) = 1$ for every input $x$ and $t$. Given the two kernel functions, [8] define the order-a matrix-based joint entropy $H_a(X, T)$ as the order-a entropy of the PSD matrix $K_X \\odot K_T$, in which $K_X$ and $K_T$ are the kernel matrices of $X$ and $T$ samples and $\\odot$ denotes the entry-wise Hadamard product.\nNote that the Hadamard product $K_X \\odot K_T$ represents the kernel matrix of concatenated samples $[x_i, t_i]$, where we consider the kernel function $k_{X,T}([x, t], [x',t']) = k_X(x,x')k_T(t, t')$ to be the product of marginal kernel functions. This definition is sensible, since the joint similarity value, taking value over [0, 1] in Gaussian kernels, is considered to be the multiplication of the similarity scores for the text and output data vectors. Then, [8] propose defining conditional entropy $H_a(X|T)$ as the difference between the joint and marginal entropy values:\n$H_a(X|T) := H_a(X,T) - H_a(T) = H_a(K_X \\odot K_T) - H_a(K_T)$   (6)\nSpecifically, it is shown that the defined conditional entropy $H_a(X|T)$ is non-negative for every normalized kernel function $k_X$ and $k_T$. Furthermore, [8] define the matrix-based mutual information $I_a(X;T)$ as the difference between the defined conditional and marginal entropy which is shown to be non-negative given normalized kernel functions $k_X$ and $k_T$:\n$I_a(X;T) := H_a(X) - H_a(X|T) = H_a(K_X) + H_a(K_T) - H_a(K_X \\odot K_T)$   (7)"}, {"title": "4 An Information-theoretic Diversity Quantification for Prompt- based Generative Models", "content": "We aim to extend the entropy-based diversity scores for unconditional generative models to conditional text-based generative models. Note that if we only evaluate the entropy score of the generated samples"}, {"title": "5 Statistical Interpretation of the Entropy-based Scores", "content": "In this section, we statistically interpret the defined Conditional-Vendi and Information-Vendi scores. First, we derive the statistic estimated from empirical samples by the entropy-based scores. According to the Schur product theorem, the Hadamard product $K_X \\odot K_T$ of PSD kernel matrices $K_X, K_T$ will also be a PSD kernel matrix. We note that the kernel matrix corresponds to the following feature map $\\Phi_{X,T}: \\mathcal{X} \\times \\mathcal{T} \\rightarrow \\mathbb{R}^{d \\times d_t}$ where $\\otimes$ denotes the Kronecker product:\n$\\phi_{X,T}([x,t]) = \\phi_X(x) \\otimes \\phi_T(t)$\nThe above holds due to the identity $(\\phi_{X,T} ([x,t]), \\phi_{X,T}([x',t'])) = k_X(x,x') k_T(t, t')$. The following proposition formulates kernel-based conditional entropy and mutual information using $\\Phi_{X,T}$.\nProposition 1. Consider the kernel matrices $K_X$ for samples $x_1,...,x_n$ and $K_T$ for samples $t_1,...,t_n$. Then, $K_X \\odot K_T$ (used for defining joint entropy $H_a(X,T)$) share the same non-zero eigenvalues with the following kernel covariance matrix:\n$\\hat{C}_{X,T} := \\frac{1}{n} \\sum_{i=1}^{n} \\phi_{X,T}([x_i, t_i]) \\phi_{X,T}([x_i, t_i])^T = \\frac{1}{n} \\sum_{i=1}^{n} [\\phi_X(x_i) \\otimes \\phi_T(t_i)][\\phi_X(x_i) \\otimes \\phi_T(t_i)]^T$\nCorollary 1. Consider the composite feature map $\\phi_{X,T}$ and joint kernel covariance matrix $\\hat{C}_{X,T}$ defined above. Then, given marginal kernel covariance matrices $C_X = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_X(x_i) \\phi_X(x_i)^T$, $C_T = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_T(t_i) \\phi_T(t_i)^T$, the following holds for the defined conditional entropy and mutual information:\n$H_a(X|T) = H_a(\\hat{C}_{X,T}) - H_a(C_T), \\qquad I_a(X;T) = H_a(C_X) + H_a(C_T) - H_a(\\hat{C}_{X,T})$"}, {"title": "6 Numerical Results", "content": "We empirically evaluated the Conditional-Vendi and Information-Vendi scores for three types of conditional generative models: 1) text-to-image, 2) text-to-video generation, and 3) image-captioning models. For text-to-image models, we considered Flux [28], Stable Diffusion 2.1 [29], Stable Diffusion XL [30], GigaGAN [31], Kandinsky [32], and PixArt [33,34]. For text-to-video models, we tested VideoCrafter1 [35], Show-1 [36], and Open-Sora [37]. For image-captioning models, we evaluated BLIP [38], GIT [39], and GPT40-mini [40].\nEmbeddings used in the evaluation of generative models. Unlike standard embedding-based scores for text-to-image models such as CLIPScore [1], which require the same embedding model for the text and generated image, the definitions of Conditional-Vendi and Information-Vendi allow different feature extractors for text and generated sample. In our experiments, we followed [41,42], to use the DINOv2 [43] embedding for image data. For text data, we used Gemini [44] and CLIP [45], and for video samples, following the video evaluation literature [46-48], we used I3D [49]. To select the bandwidth parameter $\\sigma$, similar to [7], we chose the Gaussian kernel bandwidth for each type of data as the smallest $\\sigma$ that ensures a variance below 0.01 in the evaluated score over independent evaluations. We observed that for image data, $\\sigma \\in [20,30]$; for text data, $\\sigma \\in [0.1,0.8]$; and for video data, $\\sigma \\in [10,20]$ can satisfy this requirement.\nQuantifying model-induced diversity via Conditional-Vendi. To illustrate how Conditional-Vendi correlates with the model-induced diversity, we considered a toy experiment with 10 different dog breeds from the ImageNet dataset [50] as simulated outputs for a text-to-image model. We generated two sets of prompts using GPT40 [40]. In the first set, the breed of dog in the picture was not specified, while in the other one, the breed was explicitly mentioned. As shown in Figure 2, increasing the number of breeds sampled from the dataset led to the growth of the Vendi score, regardless of the text prompt. However, Conditional-Vendi only increased when the breed was not specified in the prompts, and in the second case where the breed had been included in the prompt, the score remained relatively constant, implying that the diversity in pictures mostly follows the text prompt. To repeat this observation for text-to-image models, we considered 10 types of animals generated by Stable Diffusion XL, as shown in Figure 3. Similar to the previous experiment, we found that Conditional-Vendi increased at a more rapid rate when the prompts did not specify the type of animal in the picture. In contrast, when the animal types were specified in the prompts, there was only a slight increase in the Conditional-Vendi value."}, {"title": "7 Conclusion", "content": "In this work, we proposed an evaluation score to measure the internal diversity of prompt-based generative models, isolating diversity that is not induced by variations in text prompts. The proposed method is based on a decomposition of unconditional matrix-based entropy scores, Vendi and RKE, into Conditional-Vendi and Information-Vendi components. From a theoretical perspective, we derived the kernel-based statistics estimated by these scores and demonstrated their connection to the expectation of unconditional entropy values given a fixed text prompt. In our experiments, we evaluated the proposed scores in multiple settings where the ground-truth ranking of model diversity and relevance was known, showing that the scores correlate well with the ground-truth rankings. A future direction is to apply the proposed scores to quantify biases in existing models regarding sample generation across different human ethnicities and genders. Additionally, using these scores as a regularization penalty to train more diverse prompt-based models is another interesting area for further exploration."}, {"title": "Appendix A Proofs", "content": null}, {"title": "A.1 Proof of Proposition 1", "content": "First, we observe that for every $x, x' \\in \\mathcal{X}$ and $t, t' \\in \\mathcal{T}$, the following holds:\n$\\begin{aligned} \\phi_{X,T}([x,t])^T \\phi_{X,T}([x',t']) &= (\\phi_X(x) \\otimes \\phi_T(t))^T (\\phi_X(x') \\otimes \\phi_T(t')) \\\\ &= (\\phi_X(x)^T \\phi_X(x')) (\\phi_T(t)^T \\phi_T(t')) \\\\ &= k_X(x,x') k_T(t, t') \\\\ &= k_X(x,x')k_T(t, t') \\end{aligned}$\nTherefore, the Hadamard product of kernel matrices $K_X \\odot K_T$ can be written as\n$K_X \\odot K_T = \\frac{1}{n} \\Phi_{X,T} \\Phi_{X,T}^T$\nin terms of the matrix of samples' feature maps $\\Phi_{X,T} \\in \\mathbb{R}^{n \\times d \\times d_t}$ with its $i$th row being $\\phi_{X,T}([x_i, t_i])$. We observe that the matrices $\\Phi_{X,T} \\Phi_{X,T}^T$ and $\\Phi_{X,T}^T \\Phi_{X,T}$ share the same non-zero eigenvalues, that are the square of the singular values of $\\Phi_{X,T}$. Therefore, $K_X \\odot K_T$ has the same non-zero eigenvalues as the following matrix\n$\\frac{1}{n} \\Phi_{X,T}^T \\Phi_{X,T} = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_{X,T}([x_i, t_i]) \\phi_{X,T}([x_i, t_i])^T$\nwhich is the defined matrix $\\hat{C}_{X,T}$. Therefore, the proof of the proposition is complete."}, {"title": "A.2 Proof of Corollary 1", "content": "As we showed in Proposition 1, the Hadarmard product $K_X \\odot K_T$ shares the same non-zero eigenvalues with $\\hat{C}_{X,T}$. Also, as noted by [7], $K_X$ and $K_T$ have the same non-zero eigenvalues as of $C_X$ and $C_T$, respectively. Since the order-a matrix-based entropy is only a function of the input matrix's non-zero eigenvalues (zero eigenvalues have no impact on the entropy value), we can conclude that\n$\\begin{aligned} H_a(X|T) := H_a(K_X \\odot K_T) - H_a(K_T) \\\\ = H_a(\\hat{C}_{X,T}) - H_a(C_T), \\end{aligned}$\nand also\n$\\begin{aligned} I_a(X;T) := H_a(K_X) + H_a(K_T) - H_a(K_X \\odot K_T) \\\\ = H_a(C_X) + H_a(C_T) - H_a(\\hat{C}_{X,T}). \\end{aligned}$"}, {"title": "A.3 Proof of Theorem 1", "content": "To prove Theorem 1, we begin by showing the following lemma.\nLemma 1. Suppose that the kernel function $k$ and variable $T$ satisfy the assumptions in Theorem 1. Then, the following Frobenius norm bound holds for $C_i = \\mathbb{E}[\\phi_X(x) \\phi_X(x)^T|G = i]$ where $G \\in \\{1,...,m\\}$ is the cluster random variable for text $T$:\n$||C_{X \\odot T} - \\sum_{i=1}^{m} w_i C_i \\otimes \\phi_T(\\mu_i) \\phi_T(\\mu_i)^T||_F^2 \\leq \\frac{2m \\omega^2 \\sigma^2}{\\sigma^2}$"}, {"title": "Appendix B Additional Numerical Results", "content": null}, {"title": "B.1 Correlation between prompts and generated output", "content": "To measure the correlation between text and image using Information-Vendi, we used MS-COCO captions to generate images with Stable Diffusion XL and Flux. We gradually substituted the generated images with random ones for the same prompts at different substitution rates. As the substitution rate increased, the correlation between the text and image pairs decreased. In Figure 8, we measured Information-Vendi at various substitution rates and observed that as the substitution rate increased, Information-Vendi decreased, demonstrating that our score can successfully measure the correlation between text and image. Unlike other correlation metrics, such as CLIPScore, which require the same embedding for both text and image, our method places no such restriction. This allows for the use of different embeddings for text and image. Furthermore, our approach can be easily generalized to other conditional models, such as text-to-text or text-to-video generation."}, {"title": "B.2 Measuring Conditional-Vendi across prompt types", "content": "In this section, we conducted additional experiments similar to those in Figure 5. We created 5,000 prompts across different categories using GPT40 and generated corresponding images with text-to-image models. We reported Conditional-Vendi for the top 3 groups in the text data on PixArt-a, Stable Diffusion XL text-to-image generative models.\nAs shown in Figure 9, Figure 10 and Figure 11, we observed the same behavior during these experiments: the Conditional-Vendi score for \"dog\" prompts was significantly higher than for the \"airplane\" and \"sofa\" categories. This observation suggests that the outputs of generative models are unbalanced when presented with different groups of text prompts."}]}