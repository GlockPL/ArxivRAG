{"title": "Variational Autoencoders for Efficient Simulation-Based Inference", "authors": ["Mayank Nautiyal", "Andrey Shternshis", "Andreas Hellander", "Prashant Singh"], "abstract": "We present a generative modeling approach based on the variational inference framework for likelihood-free simulation-based inference. The method leverages latent variables within variational autoencoders to efficiently estimate complex posterior distributions arising from stochastic simulations. We explore two variations of this approach distinguished by their treatment of the prior distribution. The first model adapts the prior based on observed data using a multivariate prior network, enhancing generalization across various posterior queries. In contrast, the second model utilizes a standard Gaussian prior, offering simplicity while still effectively capturing complex posterior distributions. We demonstrate the efficacy of these models on well-established benchmark problems, achieving results comparable to flow-based approaches while maintaining computational efficiency and scalability.", "sections": [{"title": "Introduction", "content": "The simulation-based inference (SBI) problem involves statistical inference of parameters of a stochastic simulation model \\(M(\\theta, \\xi)\\) containing random states \\(\\xi\\), from observed data y [Cranmer et al., 2020]. Once calibrated, the simulation model can be used to reason about, analyze and explain the observed data y in the context of the corresponding physical process [Lavin et al., 2021]. Several challenges arise in SBI owing to model stochasticity and potential multi-valuedness, where different sets of parameter values can produce similar observations, or similar parameters may lead to varied outputs. Consequently, the task is to infer the posterior distribution \\(p(\\theta \\mid y)\\) in a Bayesian setting.\nA user-defined prior distribution \\(p(\\theta)\\) encodes domain knowledge or assumptions about plausible parameter values. The likelihood function \\(p(y \\mid \\theta)\\) is however, often intractable due to intricate stochastic dynamics, high-dimensional integration, or latent variables making analytical computation impractical [Sisson et al., 2018]. Although a closed-form expression for the likelihood function \\(p(y \\mid \\theta)\\) is unavailable, samples from this distribution can be generated by evaluating the simulator M with varying \\(\\xi\\) for different \\(\\theta\\) drawn from the prior, effectively yielding samples from the joint distribution \\((\\theta, y) \\sim p(\\theta, y)\\).\nDeep learning based approaches that directly approximate the model likelihood, or the posterior distribution have gained increasing popularity in the SBI setting [Zammit-Mangion et al., 2024]. Several approaches involve flow-based models, which are potentially compute-intensive and also restrict the design space of neural networks to invertible functions with computationally efficient Jacobian calculations [Rezende and Mohamed, 2015]. This constraint can limit the flexibility of the model in handling more complex data structures. Alternative approaches like Generative Adversarial Training for SBI (GATSBI) [Ramesh et al., 2022] use an adversarial network, where a generator produces simulations that mimic observed data, and a discriminator distinguishes between real and simulated data. However, the adversarial approach can suffer from training instability, mode collapse, and difficulties in balancing the generator and discriminator networks [Arjovsky and Bottou, 2022, Arjovsky et al., 2017], complicating training and limiting robustness.\nContribution: We propose a variational inference approach for simulation-based inference, utilizing a Conditional Variational Autoencoder (C-VAE) architecture [Kingma and Welling, 2014, Sohn et al., 2015] that is simple, computational efficient, scalable, interpretable and robust. As VAEs are not constrained by the invertibility requirement, they allow seamless integration of various neural network architectures without significant modifications as opposed to flow-based models. VAEs also avoid the instability associated with GANs due to adversarial learning dynamics. As a result, C-VAEs can handle complex data structures and dependencies more effectively, making them suitable for a wider range of tasks without requiring external summary networks [Cranmer et al., 2020].\nThe paper is organized as follows. Section 2 outlines the related work. In Section 3, we provide a formal problem definition, followed by a detailed explanation"}, {"title": "Related Work", "content": "A vast majority of SBI approaches based on deep learning aim to either approximate the likelihood [Hermans et al., 2020], or focus on directly approximating the posterior [Papamakarios and Murray, 2016, Lueckmann et al., 2017, Greenberg et al., 2019]. Additionally, there exist methods that target both the likelihood and posterior simultaneously [Radev et al., 2023a, Gl\u00f6ckler et al., 2022, Wiqvist et al., 2021]\nNeural Posterior Estimation (NPE) [Papamakarios and Murray, 2016] was one of the earliest approaches towards one-step posterior estimation, introducing the use of conditional normalizing flows to approximate the posterior distribution. By incorporating techniques such as Neural Spline Flows (NSFs) and Mixture Density Networks (MDNs), NPE enhanced both the accuracy and scalability of simulation-based inference. In comparison to traditional approaches like Approximate Bayesian Computation (ABC) or Sequential Monte-Carlo (SMC)-ABC [Sisson et al., 2018] that rely on repeated simulations and rejection-based schemes, NPE and its derivatives such as Robust NPE [Ward et al., 2022] are more efficient and flexible.\nSequential Neural Posterior Estimation (SNPE) improves NPE's efficiency by employing sequential training, where initial parameters are sampled from the prior, and the model is iteratively refined by focusing on regions of the parameter space that are most relevant to the parameter inference task. This adaptive sampling allows for more efficient exploration of the posterior distribution. Early versions like SNPE-A [Papamakarios and Murray, 2016] and SNPE-B [Lueckmann et al., 2017] required correction steps to account for changes in the sampling distribution, adding complexity to the process. In contrast, Automatic Posterior Transformation (APT) or SNPE-C [Greenberg et al., 2019], eliminated this need, offering a more robust and streamlined approach by leveraging normalizing flows to refine the posterior iteratively. However, a limitation of sequential methods like APT is that they necessitate multiple rounds of training, extending the total training time.\nThe recently proposed Jointly Amortized Neural Approximation (JANA) framework [Radev et al., 2023a] addresses posterior and likelihood estimation through joint amortization. JANA employs conditional invertible neural networks (cINNs) for both the posterior and likelihood networks, allowing efficient transformations between the parameter space and latent variables. Additionally, JANA includes a trainable summary network sub-module optimized to extract maximally informative data representations in an end-to-end manner. Unlike previous approaches, JANA follows a fully amortized strategy, allowing the evaluation of normalized densities and generation of conditional random draws for parameter estimation and surrogate modeling. Simformer [Gloeckler et al.] is a recent approach that leverages a probabilistic diffusion model with transformer architectures to accurately learn complex, high-dimensional posteriors, making it highly flexible. However, the transformer-based architecture is relatively resource-intensive and involves careful optimization.\nWe compare our proposed approach with four popular SBI methods: JANA [Radev et al., 2023a], GATSBI [Ramesh et al., 2022], APT [Greenberg et al., 2019], and NPE [Papamakarios and Murray, 2016]. The motivation is to cover a variety of approaches (e.g., flow-based, adversarial, one-shot, sequential) while noting that our focus is on efficiency and scalability as opposed to solely the posterior approximation accuracy. We refer the reader to [Zammit-Mangion et al., 2024] and [Radev et al., 2023a] for further reading on deep learning methods for SBI."}, {"title": "Simulation Based Inference", "content": "In the Bayesian framework, the aim is to infer the posterior distribution \\(p(\\theta \\mid y)\\) over the model parameters \\(\\theta\\), given the observed data y. From Bayes' theorem, the posterior distribution can be expressed as:\n\\[p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)} \\qquad(1)\\]\nwhere \\(p(y) = \\int p(y \\mid \\theta) p(\\theta) d\\theta\\) is the marginal likelihood, acting as a normalizing constant to ensure that the posterior is a valid probability distribution. However, as p(y) does not depend upon \\(\\theta\\), it can be ignored in the computations involving the posterior.\nWe propose two models for amortized inference: a Conditional Prior VAE (CP-VAE) and an Unconditional Prior VAE (UP-VAE). Both models utilize latent variables to capture hidden structures in the data. The Conditional Prior VAE uses a multivariate prior network that conditions on observed data, enabling adaptive inference that improves generalization across posterior queries. The Unconditional Prior VAE, in contrast, employs a simpler Gaussian prior with unit variance, while still capturing complex posterior distributions. Leveraging the variational inference framework, both models achieve competitive performance"}, {"title": "Conditional Prior VAE (CP-VAE)", "content": "The Conditional Prior Variational Autoencoder (CP-VAE) is an extension of the standard Conditional Variational Autoencoder (CVAE) [Sohn et al., 2015, Ivanov et al., 2019] specifically designed for simulation-based inference. We begin by introducing an auxiliary latent variable z to capture complex structures and dependencies within the joint distribution \\(p(\\theta, y)\\) of parameters \\(\\theta\\) and simulated data y. The latent variable z serves as a learned, low-dimensional summary statistic, efficiently encoding the most salient features of high-dimensional data relevant to characterize the posterior distribution. We formulate a latent variable model \\(p(z \\mid y, \\theta)\\) and approximate it using a variational distribution \\(q_\\psi(z \\mid y, \\theta)\\), parameterized by \\(\\psi \\in \\Phi\\), where \\(\\Phi\\) represents a family of distributions. The goal is to minimize the Kullback-Leibler (KL) divergence between this variational distribution and the true conditional distribution [Jordan et al., 1999, Kingma and Welling, 2014]:\n\\[\\min_{\\Psi \\in \\Phi} D_{KL}(q_\\psi (z \\mid y, \\theta) || p(z \\mid y, \\theta)). \\qquad(2)\\]\nUsing Bayes' theorem and the chain rule of probability, the conditional distribution \\(p(z \\mid y, \\theta)\\) becomes:\n\\[p(z \\mid y, \\theta) = \\frac{p(\\theta \\mid z, y)p(z \\mid y)}{p(\\theta \\mid y)} \\qquad(3)\\]\nSubstituting (3) into (2), and denoting the KL divergence \\(D_{KL}(q_\\psi (z \\mid y, \\theta)||p(z \\mid y, \\theta))\\) as D, we obtain:\n\\[D = \\mathbb{E}_{z \\sim q_\\psi (z|y,\\theta)} [- log q_\\psi (z \\mid y, \\theta) - log p(z \\mid y) - log p(\\theta \\mid y, z) + log p(\\theta \\mid y)]. \\qquad(4)\\]\nRearranging the components of equation (4), we isolate log p(\\theta|y) to derive:\n\\[log p(\\theta \\mid y) \\geq - D_{KL}(q_\\psi(z \\mid y, \\theta) || p(z \\mid y)) + \\mathbb{E}_{z \\sim q_\\psi (z|y,\\theta)} [log p(\\theta \\mid y, z)].\\qquad (5)\\]\nThis inequality stems from the fundamental non-negativity property of the KL divergence, establishing a lower bound on the log-posterior p(\\theta | y). This bound forms the core of the optimization objective in the CP-VAE framework. Maximizing the log-posterior can be conveniently reformulated as minimizing its negative, which is a standard approach in optimization, leading to the following formulation:\n\\[\\mathcal{L}(\\theta, y; \\psi) = D_{KL}(q_\\psi(z \\mid y, \\theta) || p(z \\mid y)) - \\mathbb{E}_{z \\sim q_\\psi (z|y,\\theta)} [log p(\\theta \\mid y, z)]. \\qquad(6)\\]\nThe key advantage of this formulation lies in the prior distribution p(z | y) being conditioned on the observed data y, allowing the model to adaptively shape its latent representation based on observed data, a crucial feature for effective amortized inference. This adaptive prior serves as a powerful regularization mechanism, ensuring that the latent space accurately captures the relevant features from the joint distribution \\(p(\\theta,y)\\). As a result, this approach delivers more precise posterior approximations, especially when dealing with data that exhibit complex conditional dependencies, which a fixed prior cannot adequately capture. Such adaptability is crucial for models aiming to generalize across a wide range of queries, making the CP-VAE framework well-suited for real-world applications with intricate data dependencies [Sohn et al., 2015].\nThe loss function presented in (6) is generally intractable due to the complexity of computing both the KL divergence between the variational distribution"}, {"title": "Unconditional Prior VAE (UP-VAE)", "content": "A simpler alternative optimization scheme is also proposed, that employs an unconditional prior, in contrast to the earlier approach where the prior was conditioned on the observed data y. Conditioning the prior on y is beneficial for amortized inference, but adds additional complexity to the model as the prior now depends on the data, potentially increasing the computational burden and complicating inference. Moreover, a data-dependent prior can become overly tailored to the training data, reducing the model's ability to generalize to new observations. By utilizing an unconditional prior, we simplify the model architecture and promote better generalization by preventing overfitting to training data. To address this, we use Bayes' theorem to reformulate the conditional distribution p(z | \\theta,y) as:\n\\[p(z \\mid \\theta,y) = \\frac{p(\\theta, y \\mid z)p(z)}{p(\\theta, y)} \\qquad(7)\\]\nSubstituting (7) into the KL divergence formulation in (2), and denoting \\(D_{KL}(q_\\psi (z|y, \\theta)||p(z \\mid y, \\theta))\\) as D,\n\\[D = \\mathbb{E}_{z \\sim q_\\psi} [log q_\\psi (z \\mid \\theta, y) - log p(z)] - \\mathbb{E}_{z \\sim q_\\psi} [log p(\\theta, y \\mid z)  ] - log p(\\theta, y) \\qquad(8)\\]\nApplying the chain rule to the joint probability p(\\theta,y) = p(y) p(\\theta | y) and recognizing that log p(y) is a constant with respect to \\(\\theta\\), along with the non-negativity property of the KL divergence, we obtain:\n\\[log p(\\theta|y) > \\mathbb{E}_{z \\sim q_\\psi} [log p(\\theta \\mid y, z) + log p(y | z)] - D_{KL} (q_\\psi (z \\mid \\theta,y) || p(z) ) \\qquad(9)\\]\nSimilar to (5), minimizing the negative of the right-hand side of the derived inequality is equivalent to minimizing the negative log-posterior. This aligns with our primary objective and thus, the final optimization problem can be expressed as:\n\\[\\mathcal{L}(\\theta, y; \\psi) = D_{KL} (q_\\psi(z \\mid \\theta, y) || p(z)) - \\mathbb{E}_{z \\sim q_\\psi} [log p(\\theta \\mid y, z)] - \\mathbb{E}_{z \\sim q_\\psi} [log p(y | z)].\\qquad (10)\\]\nThis formulation employs two decoder networks: one for reconstructing the parameters \\(\\theta\\), and another for reconstructing the observed data y. The data decoder introduces an auxiliary loss, which complements the primary loss from the parameter decoder. This auxiliary objective helps the model capture latent space"}, {"title": "Experiments", "content": "We evaluate the proposed approach on ten benchmark problems from the sbibm suite [Lueckmann et al., 2021], each presenting unique challenges for simulation-based inference. The main text focuses on three test problems described in the following subsections. A deeper description of the problems, and additional results for the remaining benchmarks are presented in the Appendix.\nFor each test problem, the simulation budgets is varied in {10,000,20,000,30,000}. We then estimate the posterior distributions by generating 10,000 samples from fixed observed data across five independent runs. To evaluate the accuracy of the posterior approximations, we compare them against reference posteriors obtained via MCMC sampling, using the Maximum Mean Discrepancy (MMD) and the Classifier Two-Sample Test (C2ST) [Friedman, 2003] as evaluation metrics. For consistency and reproducibility, we utilized pre-generated observed data and reference posteriors from the sbibm library [Lueckmann et al., 2021]. Detailed hyperparameter settings for each method are provided in the Appendix. The C2ST metric computations follow Lueckmann et al. [2021] a C2ST score close to 0.5 indicates that the two distributions are indistinguishable, whereas a score significantly higher than 0.5 suggests notable differences. The MMD calculation were performed using the BayesFlow framework [Radev et al., 2023b]. All experiments were performed on a machine with 2 \u00d7 16 core Intel(R) Xeon(R) Gold 6226R CPU, 576GB RAM and a NVIDIA Tesla T4 GPU (16 GB RAM)."}, {"title": "The Two Moons Model", "content": "The Two Moons model is a popular benchmark commonly used to evaluate the ability of SBI algorithms to recover multimodal and unconventional posterior distributions [Greenberg et al., 2019, Lueckmann et al., 2021]. The challenge herein is to recover the bimodal nature of the posterior, and to capture its distinctive crescent shape. The parameter vector \\(\\theta \\sim U(-1,1)^2\\) governs the model, and the observed data x is generated as:\n\\[\\begin{aligned}\nx_0 &= r cos(\\alpha) + 0.25 + (\\theta_1 + \\theta_2)\\\\\nx_1 &= r sin(\\alpha) - 1.25\n\\end{aligned} \\qquad(11)\\]\nfor radius \\(r \\sim \\mathcal{N}(0.1, 0.01^2)\\) and angle \\(\\alpha \\sim U(-\\frac{\\pi}{2}, \\frac{\\pi}{2})\\)."}, {"title": "The Bernoulli Generalized Linear Model", "content": "The Bernoulli Generalized Linear Model (GLM) simulates neuronal spiking behavior in response to a time-varying stimulus, driven by a set of covariates [Gonzalves et al., 2020]. With a discrete time domain of T = 100 bins, the model produces observed data in the form y = [yi]T100i=1. Each component yi aggregates spiking activity across time intervals, capturing both overall spiking frequency and spatial patterns of neuronal activity. The model is parameterized by a vector \\(\\theta \\in \\mathbb{R}^{10}\\), consisting of a scalar bias term \\(\\beta\\) and an auxiliary vector f \u2208 R9:\n\\[\\begin{aligned}\n\\theta &= [\\beta, f],\\\\\n\\beta \\sim \\mathcal{N}(0.2), f \\sim \\mathcal{N} (0, (F^T F)^{-1}),\n\\end{aligned} \\qquad(12)\\]\nwhere the matrix F enforces smoothness by penalizing second-order differences in f, defined as:\n\\[F_{ij} = \\begin{cases}\n1, & j = i - 2, \\\\\n-2, & j = i - 1, \\\\\n1 + \\sqrt{\\frac{i-1}{9}}, & j = i, 1 \\leq i \\leq 9. \\\\\n0, & otherwise.\n\\end{cases} \\qquad(13)\\]\nFor each time bin i, the binary spiking variable zi is sampled from a Bernoulli distribution, where the spiking probability is modeled using a logistic function applied to the linear combination of covariates vi and the parameter vector, expressed as:\n\\[z_i \\sim Bernoulli (\\sigma(v_i^T f + \\beta)), \\sigma(t) = \\frac{1}{1 + e^{-t}}. \\qquad(14)\\]\nHere, vi \u2208 R9 represents white noise inputs (covariates) drawn from N(0, I). The design matrix V = [Vi]T1i=1 aggregates these inputs over time bins T. The model computes summary statistics y \u2208 R10, where the total number of spikes is represented by \\(y_1 = \\sum_{i=1}^T z_i\\), and the remaining components, y2,\u2026\u2026\u2026, y10, are spike-triggered averages of the covariates, normalized by y1, defined as y2:10 = y11Vz. The summary statistics provide a compact representation of the simulated spiking activity, capturing the overall frequency and the influence of covariates on the spiking process."}, {"title": "The SIR Model", "content": "The Susceptible-Infected-Recovered (SIR) model is a widely used mathematical framework in epidemiology for modeling the spread of infectious diseases within a population. This model tracks the evolution of the number of individuals in three distinct compartments: susceptible (S), infected (I), and recovered (R). The dynamics of disease spread are governed by a non-linear dynamical system characterized by two key parameters: the contact rate (\u03b2) and the recovery rate (\u03b3). The model is described by the following set of ordinary differential equations:\n\\[\\begin{aligned}\n\\frac{dS}{dt} &= -\\frac{\\beta SI}{N},\\\\\n\\frac{dI}{dt} &= \\frac{\\beta SI}{N} - \\gamma I,\\\\\n\\frac{dR}{dt} &= \\gamma I.\n\\end{aligned} \\qquad(15)\\]\nwhere N is the total population size. The parameters are sampled as: \\(\\beta \\sim LogNormal(log(0.4), 0.5)\\) and \\(\\gamma \\sim LogNormal(log(1/8), 0.2)\\)."}, {"title": "Discussion", "content": "The results are now evaluated with respect to the following important considerations in SBI.\nPosterior estimation accuracy: JANA and APT hold an advantage, as JANA is able to capture complex dependencies between parameters, owing to the autoregressive factorization of the joint posterior as a series of conditional distributions; while APT leverages sequential posterior refinement to enhance accuracy.\nComputational efficiency: Adversarial training presents well known challenges, which reflect in relatively high training times for GATSBI. The sequential nature of APT adds computational expense over NPE and CP/UP-VAE. Autoregressive models can be computationally expensive to train and evaluate as estimating each parameter depends on previously estimated parameters - however, JANA is able to closely match NPE's training times for chosen hyperparameters. CP-VAE and UP-VAE are inherently simple, and do not require external summary statistics, aiding scalability and efficient training (Table 3).\nRobustness/stability: GATSBI suffers from the instabilities associated with the adversarial setting (e.g., high MMD std. dev. in Table 2). JANA and APT proved to be very robust, with low std. dev. across test problems, followed by CP/UP-VAE and NPE.\nFlexibility/approximating complex posteriors: APT holds an advantage over NPE due to its iterative refinement. JANA is particularly suited for posteriors with dependencies between parameters. However, the flexibility of normalizing flow based approaches (NPE, APT, JANA) is hindered by the invertibility requirement. GATSBI is suitable for complex, high-dimensional problems where other approaches may struggle and learning the posterior implicitly becomes important. Both CP-VAE and UP-VAE are highly flexible and adaptable with respect to the architecture.\nCP-VAE v/s UP-VAE: CP-VAE's conditional prior p(z | y) adapts to observed data, allowing flexibility and control for improved posterior accuracy. This is of particular interest in high-dimensional problems. UP-VAE's simple Gaussian prior p(z) allows for efficient latent space sampling, easier regularization, and a consistent latent space, leading to more stable training, making it efficient and effective for simpler problems.\nThe proposed CP-VAE and UP-VAE models complement existing approaches by virtue of approximating the posterior distribution in a computation-efficient manner (as evidenced in Table 3). This makes the models well-suited for challenging problems where computational efficiency is of key consideration (e.g., large number of parameters to infer, rapid model exploration, etc.). While UP-VAE uses a simpler prior, its data decoder is computationally more expensive than the conditional prior in CP-VAE, which reflects in faster training times for CP-VAE for most problems (Table 3). While we note that the training times in Table 3) can be affected by several factors including implementation and hyperparameter optimization, the comparison provides an estimate of relative computational complexity on the same hardware for reference implementations (taken from the original papers)."}, {"title": "Conclusion", "content": "This paper introduces two latent variable models, CP-VAE and UP-VAE, for amortized inference in likelihood-free simulation-based inference, with a view on efficiency, scalability, interpretability and robust-"}, {"title": "Stabilizing the training process", "content": "In both CP-VAE and UP-VAE models, we approximate the loss using a multivariate distribution with both mean and variance. Unbounded variance where \\(\\sigma^2\\) becomes excessively small or large can lead to numerical instabilities, disrupting training. To improve stability, ? suggest the ExpLin parameterization, which combines"}, {"title": "CP-VAE", "content": "In this configuration, common parameters are applied uniformly across all problems, with specific architectures detailed in Table 2. Each network \\(q_\\psi(z \\mid y, \\theta)\\), p(z | y), and \\(p(\\theta \\mid y, z)\\) is designed to approximate a multivariate distribution, outputting both a mean and variance vector. Specifically, the last layer in \\(q_\\psi(z \\mid y, \\theta)\\) and p(z | y) outputs a vector of size 2 \u00d7 latent_dim, while the last layer in \\(p(\\theta \\mid y, z)\\) outputs a vector of size 2x theta_dim. Leaky ReLU activation functions with a negative slope of 0.1 are used throughout, with a learning rate of 5 \u00d7 10\u22124, except for the Lotka-Volterra model, which uses 10\u22124, and the AdamW optimizer [?]. Models are trained with a batch size of 32 (except SLCP, which uses 16, and Lotka-Volterra, which uses 128) for 1,000 epochs, with early stopping triggered if validation performance does not improve for 20 consecutive epochs. Both \\(\\theta\\) and the data are normalized using standard scaling, and gradient clipping is set to 3.0. The latent dimension is equal to the \\(\\theta\\) dimension, except for the Gaussian Linear and GLM raw models, which use 5, Lotka-Volterra uses 8, SLCP uses 4, SLCP with Distractors uses 8, and Gaussian Linear uses 5. Kaiming normal initialization is used for weights. For each simulation budget, 90% of the data is used for training, with the remaining 10% reserved for validation."}, {"title": "UP-VAE", "content": "Building on the CP-VAE model, the UP-VAE model retains several core hyperparameters while incorporating key enhancements. Shared parameters include a learning rate of 5 \u00d7 10\u22124, except for the Lotka-Volterra (LV) model, which uses 10\u22124, a batch size of 32 (except Two Moons, which uses 50, and LV, which uses 128), and 1,000 training epochs with early stopping after 20 epochs of no improvement. Standard scaling, gradient clipping (set to 3.0), Kaiming normal initialization, and a 90-10 train-validation split are consistently applied. In the UP-VAE model, the networks \\(q_\\psi(z \\mid y, \\theta)\\), \\(p(\\theta \\mid y, z)\\), and p(y | z) approximate multivariate distributions, producing both mean and variance vectors. The final layers of these networks consist of separate fully connected layers for the mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)), outputting vectors of size corresponding to the dimensions of z, \\(\\theta\\), and y, respectively. The loss function weights are adjusted, with data reconstruction set to 0.2, theta loss to 0.4, and KL divergence to 0.4, reflecting the model's primary focus on the theta decoder and constraining the latent space. Specific architectures for these components across different problems are detailed in Table 3."}, {"title": "JANA", "content": "We use the hyperparameters provided in the supplementary text of the original paper [Radev et al., 2023a]."}, {"title": "NPE", "content": "The original paper on Neural Posterior Estimation (NPE) does not test the method on all the SBI benchmarking problems. However, the sbibm paper has evaluated NPE on all 10 benchmarking problems [Lueckmann et al., 2021]. As reported in Appendix H of the sbibm paper, Neural Spline Flows (NSF) are generally a better choice of density estimator than Masked Autoregressive Flows (MAF), which was originally recommended in the NPE"}, {"title": "APT", "content": "The implementation of Automatic Posterior Transformation, or SNPE-C, is taken from the sbi package. As for NPE, we use a pre-configured NSF density estimator from the sbi package. The default NSF architecture consists of 5 Piecewise Rational Quadratic Coupling Transforms, each with 50 hidden features and 10 bins. The spline context network includes 1 hidden layer, and the residual network has 2 blocks. The tail bound for each spline is set to 3.0, with no dropout and batch normalization disabled. Since APT is a sequential method, the number of simulations per round is calculated by dividing the simulation budget with the total number of rounds. Similar to NPE we use a CNNEmbedding for SIR and LV problems."}, {"title": "GATSBI", "content": "The original paper [Ramesh et al., 2022] provides hyperparameters for two benchmarking problems (two moons and SLCP) from the SBI benchmarking tests. For other test problems, we select and optimize appropriate hyperparameters based on the structure and complexity of each problem. The generator and discriminator layers were selected to reflect the relative complexity, with simpler problems like Gaussian Linear assigned smaller network layers. Specifically, for complex problems like SIR, Lotka-Volterra, SLCP, and SLCP with Distractors, we selected larger network layers to adequately capture their intricacies. For instance, SLCP with Distractors and other high-dimensional problems were assigned generator and discriminator layers similar to SLCP but with additional layers to manage the complexity. The learning rate was consistently set at 0.0001, balancing convergence speed and stability. Noise injection layers were tailored to each problem to ensure sufficient variability in the generated data, enhancing robustness. As recommended in the original article, the batch size is defined as the smaller value between 10% of the simulation budget and 1000. Each epoch comprised 10 discriminator updates and 10 generator updates. For each simulation budget, 100 samples are used for validation. We used the Adam optimizer with a learning rate of 0.0001, \\(\\beta_1 = 0.9\\), and \\(\\beta_2 = 0.99\\). Noise injection details are provided in the table. Each discriminator has a single output feature in the last layer, followed by a sigmoid nonlinearity. Each layer (except the last) is followed by a leaky ReLU nonlinearity with a slope of 0.1. Note: We only consider the amortized GATSBI here and do not test on sequential GATSBI, which, as stated in the original paper, is computationally very expensive."}, {"title": "Additional results", "content": "We present herein the approximated posterior distributions for all test problems, corresponding to a maximum simulation budget of 30,000."}, {"title": "Two Moons", "content": "The challenge lies not only in accurately recovering the bimodal posterior distribution but also in capturing the distinct crescent shape inherent in the data."}, {"title": "SLCP", "content": "The posterior distribution corresponding to this model exhibits a diverse range of behaviors across the parameters. Specifically, \\(\\theta_1\\) resembles a uniform distribution, \\(\\theta_2\\) follows an approximately Gaussian distribution, while \\(\\theta_3\\) and \\(\\theta_4\\) are highly multimodal. Additionally, \\(\\theta_5\\) displays a skewed, unimodal distribution. These complex characteristics make the posterior challenging to approximate accurately."}, {"title": "Gaussian Mixture", "content": "In this test problem, the challenge lies in identifying the shared mean of two distinct Gaussian distributions. These distributions differ in their variance scales, with one exhibiting a significantly broader covariance than the other, making it essential to effectively model their interaction to achieve accurate posterior inference."}, {"title": "Gaussian Linear", "content": "In this test problem, both the prior and likelihood are Gaussian, resulting in a conjugate prior that ensures that the posterior is also Gaussian. The primary challenge lies in accurately inferring the posterior mean \\(\\theta\\), which tests the efficacy of SBI methods in capturing the true underlying distribution."}, {"title": "Gaussian Linear Uniform", "content": "The Gaussian Linear Uniform model utilizes a uniform prior, representing a non-informative approach in contrast to the Gaussian prior used in the standard Gaussian Linear model. This non-conjugate setting complicates the integration of the Gaussian likelihood with the uniform prior, potentially resulting in a more intricate posterior distribution. As a result, effectively inferring the parameter \\(\\theta\\) tests the robustness of SBI methods in handling uncertainty and variability inherent in the data."}, {"title": "SLCP with distractors", "content": "This task extends the SLCP test problem by incorporating uninformative dimensions, or distractors, into the observations. The challenge lies in effectively inferring the posterior distributions while navigating the increased dimensionality and noise introduced by these irrelevant features."}, {"title": "Bernoulli GLM Model", "content": "This model tests the effectiveness of SBI methods in estimating the posterior distribution of a 10-parameter generalized linear model with Bernoulli observations and a Gaussian prior."}, {"title": "Bernoulli GLM Raw", "content": "This task is an extension of Bernoulli Generalized Linear Model (GLM) where raw observations are used instead of sufficient statistics. This alteration introduces additional complexity, as the raw data must be effectively managed to infer the underlying parameters."}, {"title": "Lotka Volterra", "content": "The Lotka-Volterra model comprises a challenging test problem for posterior inference due to its non-linear dynamics and potential chaotic behavior in predator-prey interactions. Accurately estimating the underlying parameters from observed ecological time-series data requires robust SBI methods to navigate the model's stiffness and complexity."}]}