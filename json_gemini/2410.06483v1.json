{"title": "Deep Learning Ensemble for Predicting Diabetic Macular Edema Onset Using Ultra-Wide Field Color Fundus Image", "authors": ["Pengyao Qin", "Arun J. Thirunavukarasu", "Le Zhang"], "abstract": "Diabetic macular edema (DME) is a severe complication of diabetes, characterized by thickening of the central portion of the retina due to accumulation of fluid. DME is a significant and common cause of visual impairment in diabetic patients. Center-involved DME (ci-DME) is the highest risk form of disease as fluid extends close to the fovea which is responsible for sharp central vision. Earlier diagnosis or prediction of ci-DME may improve treatment outcomes. Here, we propose an ensemble method to predict ci-DME onset within a year using ultra-wide-field color fundus photography (UWF-CFP) images provided by the DIAMOND Challenge. We adopted a variety of baseline state-of-the-art classification networks including ResNet, DenseNet, Efficient Net, and VGG with the aim of enhancing model robustness. The best performing models were Densenet 121, Resnet 152 and EfficientNet b7, and these were assembled into a definitive predictive model. The final ensemble model demonstrates a strong performance with an Area Under Curve (AUC) of 0.7017, an F1 score of 0.6512, and an Expected Calibration Error (ECE) of 0.2057 when deployed on a synthetic dataset. The performance of this ensemble model is comparable to previous studies despite training and testing in a more realistic setting, indicating the potential of UWF-CFP combined with a deep learning classification system to facilitate earlier diagnosis, better treatment decisions, and improved prognostication in ci-DME.", "sections": [{"title": "Introduction", "content": "Diabetic macular edema (DME) is a leading cause of vision loss among diabetic patients worldwide [1]. It is characterized by the accumulation of fluid in the central portion of the retina (the macula), and can occur at any stage in the natural history of diabetic retinopathy (DR) [2]. DME leads to severe vision impairment, although a variety of interventions are now available to prevent and even reverse disease progression if detected and treated early [2]. Center-involved diabetic macular edema (ci-DME) is the highest-risk form of disease, as the central macula (the fovea) is responsible for central sharp vision. Clinically, DME is best characterised using optical coherene tomography (OCT), as high resolution cross-sectional images of the retina clearly reveal fluid accumulation and can be measured to assess response to treatment.\nEn-face fundus photography-2D colour imaging of the retina-is a cheaper and more widely available modality than OCT, and is already used in screening programmes to detect diabetic retinopathy [2], [3]. However, clinicians cannot reliably diagnose DME on fundus photographs, and instead rely on surrogate markers of fluid accumulation such as hard exudate formation [4]. These surro- gates are poor predictors of DME, and screening could therefore miss patients that would benefit from early treatment, while simultaneously resulting in many unnecessary referrals to ophthalmologists for further investigation [5]. Computational analysis of fundus photographs can improve on clinical assessment, and thereby improve the utility of fundus photography to screen for DME.\nUltra-wide field colour fundus photography (UWF-CFP) is an advanced form of fundus imaging which captures a wider portion of the retina. UWF-CFP can capture more features of DME than conventional photography, such as through higher resolution imaging of the macula or due to peripheral retinal consequences of mass effect exerted by fluid accumulation. The DIAMOND Challenge aims to leverage this potential through development of artificial intelligence models capable of predicting the onset of ci-DME within one year based on individual UWF-CFP images. By focusing on predictive modeling, the challenge seeks to shift the paradigm from reactive to proactive management of ci-DME, thereby reducing the incidence of vision loss in diabetic retinopathy [6]. The DIAMOND Challenge also introduces another methodological complexity: only code (rather than model weights) is submitted, which the organizing committee runs on a cloud-based cluster. This tasks participants with developing highly generalizable models with the necessary flexibility to perform in real-world situations where data heterogeneity, privacy, and logistical limitations are common.\nIn this work, we propose a deep learning ensemble-based approach to pre- dict the development of ci-DME using UWF-CFP images. We employed several state-of-the-art convolutional neural networks (CNNs), training them with data augmentation strategies to enhance model robustness. An ensemble method was utilised to combine predictions from the top-performing models, improving the overall accuracy and reliability of ci-DME prediction."}, {"title": "Method", "content": "The challenge utilised data sourced from 14 French hospitals as part of the EVIRED project, which aims to predict ci-DME development and anticipate the onset of DR complications. For evaluation, the DIAMOND Challenge incorporated independent datasets from Algeria alongside the French hospital data. This approach promoted universally applicable solutions, capable of serving diverse population groups and settings. During the coding period, a synthetic dataset"}, {"title": "Baseline Network", "content": "We adopted four CNN architectures to develop a generalisable and robust model: Resnet, Densenet, Efficient Net and VGG.\nResNets (Residual Networks) are renowned for high performance in classifi- cation tasks, particularly in medical image analysis. It employs a deep residual learning framework to address the vanishing gradient problem and the degra- dation of network performance as depth increases. This approach enables the training of very deep networks by introducing residual mapping, which allows gradients to propagate through the network more effectively, enhancing training efficiency and performance.\nDenseNet (Densely Connected Convolutional Networks) excels in efficient feature usage and parameter reduction. It introduces dense blocks where each layer connects to every other layer in a feed-forward manner, promoting feature reuse and mitigating the vanishing gradient problem. DenseNet is often preferred for its ability to achieve high performance with fewer parameters than with ResNets.\nEfficient Net scales network dimensions (depth, width, and resolution) uni- formly using a compound scaling method. This model achieves superior perfor- mance on ImageNet and transfers well to other datasets, offering a balance of high accuracy and computational efficiency. EfficientNet's ability to maintain small model sizes while ensuring fast computation speeds makes it suitable for local applications such as hospital-based retinal image classification.\nVGG (Visual Geometry Group Network) is an earlier convolutional neu- ral network (CNN) architecture which uses small convolutional filters and deep networks (16-19 layers) to attain strong performance on large-scale image recog- nition tasks like ImageNet. VGG is known for its large model size and lengthy computation times relative to newer architectures, but remains a useful baseline model for image classification tasks such as object recognition and medical image classification."}, {"title": "Model ensemble", "content": "Model ensembling combines the outputs produced by multiple models into a single prediction process, which can overcome shortcomings associated with in- dividual estimators such as high variance, noise, and bias. In this work, three ensemble strategies were used. The first was majority voting: where the class with the highest number of votes is used as the final prediction. The second was averaging: where the final outputted probability is the unweighted average of the"}, {"title": "Experiments", "content": "In all experiments, the images were resized to 224x224 pixels from their original size. Other image augmentation techniques were also employed, including random horizontal reflection, random vertical reflection, and random rotation (Figure 2).\nThroughout the training process, the adam op- timizer was used with a learning rate scheduler with exponential decay. Networks were trained using 200 epochs and the models with the best performance were saved. Performance was gauged with the metrics suggested by the DIAMOND Challenge: Area under the receiver operating characteristic curve (AUC), F1- score (F1) and Expected Calibration Error (ECE). The use of AUC aligns with the goal of achieving high sensitivity and specificity in predictions and was there- fore weighted highest during evaluation and ranking. F1 and ECE were consid- ered as secondary metrics (lowerr weighted) to further assess the relevance of computed probabilities. F1 helped ensures that binary predictions (when using"}, {"title": "Model evaluation", "content": "Here I present the results of different ensemble methods. Table. 2 shows the performances of the ensemble methods, evaluated on the internal testing dataset. For the individual evaluation, label fusion obtained the best performances (over- all score of 1.4343) comparing to the other models ensemble methods."}, {"title": "Discussion and Conclusion", "content": "In this study, we developed an ensemble-based deep learning model to predict the onset of ci-DME within 12 months using UWF-CFP images. Our model combined several CNN architectures and exhibited performance comparable to previous studies involving human experts and deep learning algorithms diagnos- ing existing DME on fundus photographs [5], [7]. While the ensemble model's overall performance was slightly lower than that of the best individual model (Densenet121), it offers improved generalizability across diverse datasets. This trade-off-sacrificing peak performance for better generalization-may help mit- igate overfitting, making the ensemble model more robust for real-world clinical applications. Though higher performance has been achieved for detecting exist- ing ci-DME from fundus photographs (rather than OCT, the clinical standard for diagnosis) [3], a predictive model like ours may provide greater clinical benefit by guiding preemptive decision-making and early treatment interventions.\nTimely intervention is associated with substantial improvement in patient outcomes, but fundus photography is insufficient to replace OCT in diagnosing ci-DME and regular OCT screening is associated with prohibitive costs and inac- cessibility, particularly in lower income countries [2], [3]. Predictive deep learning with UWF-CFP images may represent a cost-effective and scalable alternative, allowing more patients around the world to receive critical treatment as required [8]. This potential aligns well with the aims of the DIAMOND Challenge, which emphasized the value in generalisable models with potential to augment real- world clinical practice. Our approach aims to maintain sufficient flexibility to cope with training and deployment across conventional fundus photography as well as UWF-CFP, with differences in frame of view, image artifact, and resolu- tion that can confound classification (Figure 4).\nWith a 7 day time frame provided by the DIAMOND challenge, we plan to implement a streamlined training and evaluation workflow using a bash script.\nThis script is designed to automate the training of each component network separately on the available data. By using an ensemble method combined with model selection based on objective evaluation metrics such as AUC, F1, and ECE, we ensure that the final submission to the challenge is both robust and generalizable, potentially performing well even when applied to datasets derived from other imaging devices.\nIn conclusion, our ensemble model demonstrates the potential to significantly advance the early detection of ci-DME, which could facilitate proactive manage- ment and prompt treatment to improve patient outcomes. By integrating deep learning with UWF-CFP imaging, accurate and accessible screening could pro- mote timely intervention and ultimately better clinical outcomes for patients with DR."}]}