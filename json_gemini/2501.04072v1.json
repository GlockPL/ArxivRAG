{"title": "Multi-armed Bandit and Backbone boost Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problems", "authors": ["Long Wang", "Jiongzhi Zheng", "Zhengda Xiong", "Kun He"], "abstract": "The Lin-Kernighan-Helsguan (LKH) heuristic is a classic local search algorithm for the Traveling Salesman Problem (TSP). LKH introduces an a-value to replace the traditional distance metric for evaluating the edge quality, which leads to a significant improvement. However, we observe that the a-value does not make full use of the historical information during the search, and single guiding information often makes LKH hard to escape from some local optima. To address the above issues, we propose a novel way to extract backbone information during the TSP local search process, which is dynamic and can be updated once a local optimal solution is found. We further propose to combine backbone information, a-value, and distance to evaluate the edge quality so as to guide the search. Moreover, we abstract their different combinations to arms in a multi-armed bandit (MAB) and use an MAB model to help the algorithm select an appropriate evaluation metric dynamically. Both the backbone information and MAB can provide diverse guiding information and learn from the search history to suggest the best metric. We apply our methods to LKH and LKH-3, which is an extension version of LKH that can be used to solve about 40 variant problems of TSP and Vehicle Routing Problem (VRP). Extensive experiments show the excellent performance and generalization capability of our proposed method, significantly improving LKH for TSP and LKH-3 for two representative TSP and VRP variants, the Colored TSP (CTSP) and Capacitated VRP with Time Windows (CVRPTW).", "sections": [{"title": "1. Introduction", "content": "Given an undirected, complete graph, where each node represents a city, and the distance between any two cities is known, the Traveling Salesman Problem (TSP) [1] aims to find the shortest Hamiltonian circuit in the graph, which starts from a city, visiting each of the other cities exactly once and finally returns to the starting city. As the basic model of many routing problems [2, 3, 4, 5, 6], TSP is a classical NP-hard combinatorial optimization problem that has a wide range of real-world applications [7, 8].\nWith the increase in problem scales, the computation time for exactly solving the TSP instances grows sharply. To meet the requirements of algorithm efficiency in many real-world routing problems, heuristics are the most popular and practical methods. Heuristic methods for TSP mainly include local search [9] and genetic algorithms [10]. In this paper, we mainly focus on local search methods, which are more commonly used and more suitable for TSP instances with various scales, even for instances with over a million cities\u00b9.\nThe foremost local search algorithms are represented by two families, deriving from the Lin-Kernighan (LK) [11] method and the Stem-and-Cycle (S&C) method [12], respectively. The LK heuristic is based on the famous k-opt local search operator [13], which actually adjusts the solution by replacing its k edges with k new edges. LK uses the distance between the endpoints to evaluate the quality of the edges. S&C method proposes some particular rules based on a spanning subgraph consisting of a cycle attached to a path, which can change the solutions by moves that LK cannot generate [14].\nThis paper mainly focuses on the LK series algorithms, among which the Lin-Kernighan-Helsgaun (LKH) algorithm [9, 15] is a representative one, making many achievements in the field of TSP solving. LKH improves LK in many aspects, including using an a-value derived from the 1-tree structure [16, 17] (a variant of spanning tree) to replace the distance for evaluating the edges, generalizing k-opt that allows non-sequential moves, chain search, tour merging, etc. These improvements and smart designs make LKH one of the state-of-the-art local search algorithms for TSP.\nLKH considers that edges with smaller a-values are more likely to be in the optimal solution. For each city, LKH associates a candidate set consisting of other cities that have the smallest a-values on the connection edges. Edges in the candidate sets are also called candidate edges. During the k-opt process, only candidate edges can be used to replace edges in the current solution. Specifically, the k-opt operator first removes k edges from the current solution and reconnects them using the candidate edges, trying to improve the current solution. Obviously, the algorithm performance heavily depends on the evaluation metric used to select the candidate edges, i.e., evaluate the edge quality.\nIn this work, we observe that the a-value used in LKH to evaluate the edge quality is fixed during the search. The single and fixed guidance information might limit the algorithm's search flexibility, making the algorithm hard to escape from local optima in some cases. To this end, we propose two approaches with learning techniques and mechanisms to provide diverse and appropriate guiding information for the local search and boost the effective LKH algorithm.\nFirst, we propose to combine three metrics, the a-value, distance, and backbone information, for evaluating the edge quality and ordering candidate edges. Towards TSP, the backbone information is represented as the frequency of edge occurrence in optimal solutions, which are however blind to local search algorithms. To handle this issue, an intuitive idea is to extract pseudo backbone information from the high-quality local optimal solutions generated during the search process [18]. For convenience, we simply use \"backbone information\u201d to denote the pseudo one in the rest of this paper. The backbone information indicates that edges that appeared more frequently in those local optimal solutions are of higher quality.\nThe backbone information has been applied to solve TSP [18] and has also been taken into account by LKH [15]. However, it does not really take effect in LKH, which might be because it does not fully utilize the historical search information. In this work, we use the backbone information from a very different perspective. Specifically, once a local optimal solution is found, the backbone information will be updated accordingly to contain information represented by edges in historical local optimal solutions. With the accumulation of backbone information, i.e., the increase in the number of iterations, the backbone information becomes more accurate and valuable, and we increase its weight accordingly in the evaluation metric. Actually, the a-value, distance, and backbone information evaluate each edge mainly from global, local, and historical perspectives, respectively. Our method combines their advantages and makes use of their complementarity to provide diverse guidance for the algorithm.\nSecond, we propose to use a multi-armed bandit (MAB) to help the algorithm learn to select a reasonable combination of the three component metrics. MAB is a basic reinforcement learning model [19, 20, 21], where the agent needs to choose and pull an arm (i.e., take an action) at each decision step (i.e., state) and gains some rewards. The agent uses the rewards to update the evaluation values of the arms, which correspond to the benefit of pulling the arms and are used as a reference for selecting the arm to be pulled. MAB can be used to help heuristic algorithms select the best element among multiple candidates [22]. In our method, arms in the MAB correspond to different evaluation metrics on candidate edges, i.e., different combinations of the a-value, distance, and backbone information. The MAB is used to help the algorithm select a promising metric for evaluating the quality of candidate edges.\nWe apply our two approaches to LKH and denote the resulting algorithm as MABB-LKH (MAB and Backbone boost LKH). Both the dynamic backbone information and MAB can provide diverse guiding information for the search and learn from the search history, helping the algorithm select appropriate guiding information to escape from local optima and find better results. We further apply our methods to LKH-3 [23], an extension of LKH for solving constrained TSPs and Vehicle Routing Problems (VRPs). The resulting algorithm is called MABB-LKH-3. We select two representative TSP and VRP variant problems, the Colored TSP (CTSP) and Capacitated VRP with Time Windows (CVRPTW), to evaluate the performance of MABB-LKH-3. Extensive experiments show the excellent and generic performance of our proposed methods.\nThe main contributions of this work are as follows:\n\u2022 We propose a novel way to extract backbone information from TSP local search algorithms. The information considers all edges in historical local optimal solutions and can be updated and accumulated.\n\u2022 We propose to combine backbone information, a-value, and distance to form a new metric for evaluating the edge quality. The new metric contains global, local, and historical information, thus can improve the algorithm robustness for various instances.\n\u2022 We propose to use an MAB to help select an appropriate combination of backbone information, a-value, and distance. Both the MAB and backbone information can learn from the search history and provide dynamic and appropriate guiding information for the algorithm.\n\u2022 We incorporate the proposed methods into the effective LKH algorithm and its extension version, LKH-3. Extensive experiments show that both algorithms can be significantly improved, indicating the excellent performance and generalization capability of our approaches."}, {"title": "2. Problem Definition", "content": "In this section, we present the definition of the involved problems, including the Traveling Salesman Problem (TSP), the Colored TSP (CTSP), and the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW)."}, {"title": "2.1. Traveling Salesman Problem", "content": "Given an undirected complete graph $G = (V, E)$, $V$ is the set containing n cities and $E$ contains all pairwise edges between the cities. Each edge $(i, j) \\in E$ between cities $i$ and $j$ has a cost $d(i, j)$ representing the distance. TSP aims to find a Hamiltonian circuit represented by a permutation $(c_1, c_2, ..., c_n)$ of cities {1,2,..., n} that minimizes the total cost, i.e. $d(c_n, c_1) + \\sum_{i=1}^{n-1} d(c_i, c_{i+1})$."}, {"title": "2.2. Colored TSP", "content": "In the CTSP, the city set $V$ is divided into $m + 1$ disjoint sets: $m$ exclusive city sets $E_{c1}, E_{c2}, ..., E_{cm}$ and one shared city set $S_c$. The cities of each exclusive set $E_{ck} (k = 1,2,..., m)$ must be visited by salesman k and each city from the shared city set $S_c$ can be visited by any of the m salesmen. City 1 (the depot) belongs to the shared set $S_c$ and is visited by all salesmen. The CTSP needs to determine m routes on the graph $G = (V, E)$ for the m salesmen. Route k ($k \\in {1,2,..., m}$) can be represented by sequence $(c_1^k, c_2^k, ..., c_{l_k}^k, c_1^k)$, where $c_1^k = 1$ is the depot, $l_k$ is the number of the cities in route k. The m routes should satisfy the following constraints. First, each city except the depot can be visited exactly once. Second, the cities belonging to exclusive set $E_{ck}$ should be contained in sequence $(c_1^k, c_2^k, ..., c_{l_k}^k, c_1^k)$. The goal of the CTSP is to find m routes with the minimum total traveling distance (cost), i.e., $\\sum_{k=1}^{m} d(c_{l_k}^k, c_1^k)+ d(c_1^k, c_2^k) + ... + d(c_{l_k-1}^k, c_{l_k}^k)$."}, {"title": "2.3. Capacitated VRP with Time Windows", "content": "In the CVRPTW, every city (customer) i has its requirement $r_i$ and wishes to be served in an expected time window, i.e., $[t_i^a, t_i^b]$. The cities are visited by multiple vehicles, which depart from the depot, visit the cities, and finally return to the depot. Each city except the depot can be visited only once by only one vehicle. The vehicles have their capacity $C$, and the total requirement of the cities visited by each vehicle cannot exceed the capacity $C$. Moreover, a vehicle can wait at city i before its service begins at $t_i^a$. The CVRPTW aims to decide the number of vehicles used and the routes of the vehicles to minimize the total traveling distance (cost) of the vehicles while satisfying the time windows and capacity constraints."}, {"title": "3. Related Work", "content": "In related works, we first review some learning-based methods for TSP, including end-to-end methods with deep neural networks and the combinations of learning models and traditional algorithms, then review studies using backbone information, and finally revisits the LKH and LKH-3 algorithms."}, {"title": "3.1. Learning-based Methods for TSP", "content": "Many studies attempt to use learning-based methods to solve the typical combinatorial optimization problem of TSP, which can be divided into two main categories.\nThe first category uses deep learning models in an end-to-end manner to directly find a solution. Representative models include the graph neural network [24], the Pointer network [25] and its improved version of Pointerformer [26], and employed learning mechanisms include reinforcement learning [27, 28] and supervised learning [29]. Some studies propose to use deep learning models to learn to perform and guide the traditional local search operators, such as 2-opt [30] and k-opt [31]. Recently, Ye et al. [32] propose the GLOP method that combines non-auto-regressive neural heuristic methods for global problem segmentation and auto-regressive neural heuristic methods for local path construction. These studies investigate the potential of neural network models in directly solving TSP, which is a very difficult task. They can hardly be competitive with efficient heuristics such as LKH, especially for large-scale problems.\nThe second category combines learning models with traditional algorithms to boost performance, such as the NeuroLKH [33] and VSR-LKH [34] algorithms. NeuroLKH uses a Sparse Graph Network (SGN) with supervised learning to generate candidate edges for LKH, showing higher performance than LKH in instances with the same structure as its training instances. For instances with more than 6,000 cities, whose scales are significantly larger than the training ones, the performance of NeuroLKH will degrade obviously. VSR-LKH uses reinforcement learning to train a Q-value and replaces the a-value for evaluating the edge quality, showing higher performance than LKH. Similar to the a-value, the Q-value does not make full use of the historical information either."}, {"title": "3.2. Backbone Information for TSP", "content": "The backbone information was initially applied to (maximum) satisfiability problems [35, 36], and later on gradually extended to the TSP field [18], where the backbone information is a concept that extracted from some high-quality local optima. In detail, Zhang and Looks [18] run the algorithm with fewer iterations for 30 independent times and extract backbone information from these local optimal solutions so as to guide the subsequent search, which pays extra effort to obtain prior knowledge. LKH also takes into account the usage of backbone candidate edges [15], but the effect is not obvious. One reason is that it does not fully utilize the historical search information but only uses backbone information of local optimal solutions generated in the initial iterations to help select candidate edges.\nIn our method, the backbone information is dynamic and contains more comprehensive historical information, i.e., considering all edges that appeared in all local optimal solutions in history. Meanwhile, we extract backbone information in every iteration, updating and using them in real-time without preprocessing and extra calculation compared with the previous method [18]. Moreover, we combine backbone information with a-value and distance to form a combination metric and further use an MAB to help select a promising combination. Owing to the diversity and learning mechanism, our method exhibits excellent performance and robustness."}, {"title": "3.3. Revisiting the LKH and LKH-3 Algorithms", "content": "Both LKH [9] and LKH-3 [23] can be divided into two stages. In the first stage, the algorithms select high-quality candidate edges based on the a-value metric. The candidate edges and their ranking in the candidate sets play an important role in the algorithms because the new edges to adjust the current solution are selected sequentially from the candidate sets. In the second stage, the algorithm repeats generating an initial solution by a function called ChooseInitialTour() and using the search operators (i.e., k-opt) to improve the solution to a local optimum until the stopping criterion is reached. The procedure of improving the solution to a local optimum is encapsulated in a function called LinKernighan(), which outputs a local optimal solution that cannot be improved by the k-opt operator, and such a procedure is called a trial (i.e., iteration) in LKH and LKH-3.\nLKH-3 is an extension of LKH for various constraint TSPs and VRPs. LKH-3 solves these problems by transforming them into the constrained TSP [37, 38], and uses the k-opt method to explore the solution space. LKH-3 allows searching in the infeasible solution space and defines different violation functions for different problems to evaluate the violation extent of the given constraints. A solution is improved by k-opt in LKH-3 when the violation function is reduced or the violation function is unchanged while the optimization objective is reduced. A solution with zero violation values is feasible. In summary, techniques that can be used for LKH can be easily used for LKH-3.\nIn the following, we will introduce the key components in LKH and LKH-3, i.e., the a-value for selecting the candidate edges and the k-opt operator."}, {"title": "3.3.1. The a-value and Candidate Edges", "content": "LKH proposes the a-value for evaluating the edges and selecting the candidate edges. The a-value is calculated based on a 1-tree structure [16], a variant of the spanning tree. Given a graph $G = (V, E)$, for any vertex $v \\in V$, we can generate a 1-tree by first constructing a spanning tree on $V\\{v}$ and then combining it with two edges from E incident to v. The minimum 1-tree is the 1-tree with the minimum length, i.e., the total length of its edges. We denote $L(T)$ as the length of the minimum 1-tree, which is obviously a lower bound of the length of the shortest TSP tour. Moreover, we denote $L(T(i, j))$ as the length of the minimum 1-tree containing edge $(i, j)$. The a-value of edge $(i, j)$ is calculated as follows.\n$\\alpha(i, j) = L(T(i, j)) \u2013 L(T)$.\nTo further enhance the performance of a-values, LKH applies the method of adding penalties [39] to vertices to obtain a tighter lower bound. Given the final a-values of the edges, LKH and LKH-3 associate each city i with a candidate set, containing five (default value) other cities with the smallest a-values to city i (sorted in ascending order of the a-values.), and each edge between a city and its candidate city is a candidate edge."}, {"title": "3.3.2. The k-opt Operator", "content": "The k-opt operator in LKH and LKH-3 contains two categories, sequential and non-sequential moves,. The dashed line is the edge about to be disconnected. The sequential move starts from a starting point, e.g., $p_1$, alternatively selects the edges to be removed in the current solution (e.g., $(p_1, p_2)$, $(p_3, p_4)$ and $(p_5, p_6)$), and edges to be added sequentially from the candidate sets (e.g., $(p_2, p_3)$ and $(p_4, p_5)$), and guarantees that after selecting each edge to be removed, connecting its endpoint (e.g., $p_4$ and $p_6$) back to the starting point leads to a feasible TSP tour. Therefore, the sequential move can be stopped once an improvement is found, and the non-sequential move cannot."}, {"title": "4. MABB-LKH and MABB-LKH-3", "content": "The proposed MABB-LKH and MABB-LKH-3 algorithms improve LKH and LKH-3 from two aspects, i.e., combining backbone information, a-value, and distance to evaluate the edge quality and selecting an appropriate combination of them by using a multi-armed bandit (MAB). The MAB model can learn during the search and adjust the ranking of the candidate cities dynamically in each iteration. Note that MABB-LKH and MABB-LKH-3 share a similar framework, as LKH and LKH-3 do. Therefore, this section first introduces our proposed methods that are commonly used in MABB-LKH and MABB-LKH-3, including how we extract and update backbone information from the historical search information, how we design the new combination metric, and the proposed MAB model, and then introduce the framework of the MABB-LKH algorithm as a representative."}, {"title": "4.1. Extract and Update Backbone Information", "content": "In our method, the backbone information is represented by the edge frequency among the local optimal solutions, i.e., solutions outputted by the LinKernighan() function. The backbone information will be updated once a local optimal solution is generated in each iteration (i.e., the trial in LKH). We define $t$ as the number of trials of the local search algorithm, and $n_{ij}$ as the number of times that edge $(i, j)$ appears in all the local optimal solutions in the search history. Then, the backbone information corresponding to edge $(i, j)$ is defined as:\n$b_{ij} = n_{ij} / t$.\n$n_{ij}$ is divided by $t$ which standardizes backbone information based on trials t. We regard that edges that appear more frequently in historical local optimal solutions should have higher quality. Note that collecting the backbone information for all edges in graph $G = (V, E)$ needs an $O(|V|^2)$ memory space. In practice, we only need to collect information for promising edges with small a-values and lengths as LKH does, resulting in an $O(|V|)$ memory space."}, {"title": "4.2. New Combined Evaluation Metric", "content": "We define a new evaluation metric that combines the a-value, backbone information, and distance for evaluating the edge quality and ordering cities in each candidate set to fully use their advantages corresponding to global, historical, and local perspectives, respectively. Zhang and Looks [18] propose to combine backbone information with distance by multiplying the two metrics. In this work, we also multiply them and obtain a metric denoted as bd-value. The bd-value for an edge $(i, j)$ can be calculated as follows:\n$bd(i, j) = (1 \u2013 b_{ij})d(i, j)$,\nwhich indicates that an edge with a shorter length and appearing more frequently in historical local optimal solutions will have a higher quality, measured by a lower distance. Note that the backbone information in our bd-value can be updated without any prior knowledge and considers all appeared edges in local optimal solutions, which is quite different from the metric in [18].\nWe furthermore combine the a-value and bd-value by weighted sum with a weight factor $w$, resulting in the final new metric, abdw-value. The abdw-value of an edge $(i, j)$, denoted as $abd^w(i, j)$, can be calculated as follows:\n$abd(i, j) = w \\cdot a'(i, j) + (1 \u2013 w) \\cdot bd'(i, j)$,\nwhere $a'(i, j) = \\frac{a(i,j)-a_{min}}{a_{max}-a_{min}}$ and $bd'(i, j) = \\frac{bd(i,j)-bd_{min}}{bd_{max}-bd_{min}}$ are the a-value and bd-value of edge $(i, j)$ after normalization, respectively. Here $a_{max}$ (resp. $bd_{max}$) and $a_{min}$ (resp. $bd_{min}$) are the maximum and minimum a-values (resp. bd-values) of candidate edges, respectively. This operation makes two different metrics at the same level.\nSince the magnitudes of a-value and bd-value might be different, and we have no idea about the best weight assignments for them in an ideal evaluation metric, we first normalize them and then use a weight factor $w$ to control their importance in the linear combination. Because sometimes a-value is more important than bd-value, and sometimes the situation is the opposite. And different $w$ corresponds to different metrics. In MABB-LKH, we empirically set several values of $w$ following a uniform distribution in [0, 1] and use an MAB model to help the algorithm select the best one."}, {"title": "4.3. The MAB Model", "content": "The MAB model is used to select an appropriate weight factor for our proposed new combined evaluation metric in each trial of MABB-LKH. The metric is then used to order the candidate edges, which is quite important for the local search algorithm. Suppose the MAB has $m$ ($m > 1$) arms. We set the i-th arm ($i \\in {1, 2, \u2026, m}$) corresponding to a weight factor of $w_i = \\frac{i-1}{m-1}$, and also corresponding to a metric based on $abd^{w_i}$-value, where \u0393 is a discount value which will decrease with the increase of trials (see details in Section 4.4).\nIn the MAB model, each of the m arms has an expected return when picked, which is hard to calculate precisely since the background problem is too complicated. Therefore, we associate each arm i with an estimated value $V_i$ to approximate estimate the expected return of pulling it, which is initialized to be 0.\nIn the following, we first introduce the way of selecting an arm to be pulled in each step, and then introduce how to update the estimated values of the arms."}, {"title": "4.3.1. Select an Arm to be Pulled", "content": "The MAB model uses the widely-used Upper Confidence Bound (UCB) method [40, 22] to trade-off between exploration and exploitation and selects an arm to be pulled. We denote $n_i$ as the number of times that arm $i$ has been pulled in the history, and $N = \\sum_{i=1}^m n_i$ as the number of times calling the MAB model to pick an arm. The action (i.e., arm) selected at trial t by the UCB method is:\n$A = arg\\ max_{i} (V_i + c \\sqrt{\\frac{ln \\ N}{n_i + 1}})$,\nwhere $c$ is the exploration bias parameter, also called the confidence level in the UCB method, to trade the exploitation item $V_i$ and exploration item $\\sqrt{\\frac{ln \\ N}{n_i + 1}}$."}, {"title": "4.3.2. Update Estimated Values", "content": "We hope the corresponding metric selected by the MAB model can provide promising guiding information for the local search algorithm and help it find better solutions. Therefore, we use the improvement or degradation in the solution quality to calculate the reward of pulling an arm. Suppose i is the arm pulled at the beginning of the current trial t, R is the local optimal solution outputted by function LinKernighan() at trial t following the metric corresponding to arm i, and R* is the shortest solution found so far. We further define L(R) and L(R*) as the length of solutions R and R*, respectively. The reward of pulling arm i at trial t is designed as:\n$r_i = \\frac{L(R*) \u2013 L(R)}{L(R*) \u2013 L(T) + 1}$,\nwhere L(T) is the lower bound of the length of the optimal solution. The numerator L(R*) \u2013 L(R) in the reward makes the reward larger for a shorter R, and the denominator L(R*) \u2013 L(T) + 1 indicates that the closer to the optimum, the larger the reward, which is intuitive and reasonable. The extra added 1 is to avoid the situation where the denominator equals zero.\nFinally, the estimated value $V_i$ of arm $i$ pulled at trial t is updated incrementally as follows.\n$V_i^{t+1} = V_i^t + s \\cdot (r_i \u2013 V_i^t)$,"}, {"title": "4.4. The Framework of MABB-LKH", "content": "The main framework of our MABB-LKH algorithm is depicted in Algorithm 1. The algorithm first initializes the candidate sets and some important values, which will be updated during the subsequent search, including the length of the best solution L(R*), the number of times calling the MAB model N, as well as the estimated value $V_i$, the number of pulled times, and the initial weight factor $w_i$ of each arm i (lines 1-5). Then, the algorithm repeats to search for better solutions iteratively until reaching the maximum number of trials MaxTrials (lines 6-19).\nIn each trial, the algorithm first uses the ChooseInitialTour() function derived from LKH to generate an initial solution R (line 7), which is actually generated by adding some random perturbation based on the best solution R*. Then, if the current trial $t \\leq bs$, the algorithm does not use backbone information and the MAB model to adjust the candidate sets but follows the same search method of LKH and records it (lines 8-9). Actually, the first bs (100 by default) trials are only used to collect backbone information. When backbone information accumulates to a basic amount (i.e., t = bs), the algorithm starts to use the MAB model to select an arm to be pulled A, in trial t (line 12).\nWe argue that with the accumulation of backbone information, it will be more precise and valuable. Therefore, we use a weight discount factor \u03b3 (0.998 by default) to increase the weight of backbone information as the number of trials increases (line 14). Actually, when t is close to bs, a-value still plays a major role in the evaluating metric. The backbone information will be more and more important and dominate the evaluating metric with the increase of t. After the algorithm determines the weight factor w, the evaluation metric abdw-value corresponding to w is then used to resort the candidate edges (line 15) and lead the local search function LinKernighan() to find better solutions. Details about function LinKernighan() are referred to Section 3.3 and [9]."}, {"title": "5. Experimental Results", "content": "For experiments, we first present detailed comparison results of MABB-LKH\u00b2 and LKH (version 2.0.10) to evaluate the performance of our proposed new algorithm. We also compare MABB-LKH with the NeuroLKH algorithm [33], a representative learning-based algorithm for TSP. NeuroLKH combines deep learning models with LKH, using deep learning models to select candidate edges for the LKH algorithm. We furthermore compare MABB-LKH-3 with LKH-3 in solving CTSP and CVRPTW and finally perform ablation studies to evaluate the effectiveness of the backbone information and the MAB model in MABB-LKH."}, {"title": "5.1. Experimental Setup and Datasets", "content": "5.1.1. Experimental Setup\nMABB-LKH and MABB-LKH-3 were implemented in C Programming Language. The experiments were executed on a server with an AMD EPYC 7H12 CPU", "41": ".", "43": ".", "44": "and Homberger [45", "groups": "C1, C2, R1, R2, RC1, and RC2, each containing between 8 and 12 instances. The C1 and C2 classes have customers located in clusters, and in the R1 and R2 classes, the customers are at random positions. The RC1 and RC2 classes contain a mix of both random and clustered customers. The C2, R2, and RC2 classes have longer scheduling horizons and larger capacities than the C1, R1, and RC1 classes, meaning that each vehicle can service a larger number of customers in the former classes. For each CVRPTW instance, we also set the maximum number"}]}