{"title": "A Statistical Framework for Data-dependent Retrieval-Augmented Models", "authors": ["Soumya Basu", "Ankit Singh Rawat", "Manzil Zaheer"], "abstract": "Modern ML systems increasingly augment input instances with additional relevant information to\nenhance final prediction. Despite growing interest in such retrieval-augmented models, their fundamental\nproperties and training are not well understood. We propose a statistical framework to study such models\nwith two components: 1) a retriever to identify the relevant information out of a large corpus via a\ndata-dependent metric; and 2) a predictor that consumes the input instances along with the retrieved\ninformation to make the final predictions. We present a principled method for end-to-end training of both\ncomponents and draw connections with various training approaches in the literature. Furthermore, we\nestablish excess risk bounds for retrieval-augmented models while delineating the contributions of both\nretriever and predictor towards the model performance. We validate the utility of our proposed training\nmethods along with the key takeaways from our statistical analysis on open domain question answering\ntask where retrieval augmentation is important.", "sections": [{"title": "Introduction", "content": "Recent advancements in machine learning (ML) have not only led to breakthroughs on long-standing\nchallenging tasks across various fields, but they have also inspired a great deal of interest to develop ML\nmodels that can solve even harder tasks [Meinhardt et al., 2022, Lewkowycz et al., 2022, Cramer, 2021] or\nfocus on completely new fields [Austin et al., 2021, OpenAI, 2023, Singhal et al., 2023]. While scaling the\nsize of parametric ML models, such as neural networks, is becoming the predominant approach to meet\nsuch demands [Brown et al., 2020, Chowdhery et al., 2022, Touvron et al., 2023, Dosovitskiy et al., 2021,\nDehghani et al., 2023], the excellent performance realized by this approach is marred by drawbacks such as\nhigh computational cost, inefficient storage of world knowledge in parameters, lack of transparency in model\nbehavior, and reduced grounding/factuality of model predictions.\nRecognizing these shortcomings, retrieval-augmented models (RAMs) have emerged as a promising\nalternative. Such models typically employ two components, namely retriever and predictor, during inference\non a given input instance: The retriever first identifies instance-specific relevant information from a data-store,\nand then the predictor jointly processes the retrieved information and the input instance to make a final\nprediction. In practice, RAMs have enjoyed favorable performance vs. compute trade-off [Borgeaud et al.,\n2021, Das et al., 2021, Thai et al., 2023] as employing moderate-size parametric models as retriever and\npredictor in a RAM often matches or exceeds the performance of a much larger standalone ML model that\ndirectly maps input instances to predictions. Similarly, conditioning prediction on the retrieved information\nhas shown to exhibit improved grounding [Shuster et al., 2021, Lin et al., 2023, Asai et al., 2023]. Furthermore,\nhaving access to an external corpus can obviate the need to store task-specific world knowledge in model\nparameters and enable incorporating dynamically evolving knowledge [Izacard et al., 2022, Liska et al., 2022].\nDespite these desirable characteristics, training RAMs presents multiple challenges. The natural approach\nof independently training retriever and predictor can be sub-optimal [Izacard et al., 2022]. Moreover, it\nrequires collecting intermediate supervision on the instance-dependent relevant information to retrieve, which"}, {"title": "Problem setup", "content": "In this paper, we focus on developing a systematic understanding of RAMs with learned retrievers in a\nclassification setting where the model has access to a data-store. Towards this, we begin by formally defining\nthe problem setup and providing the necessary background along with the notations used.\nLet's first consider the standard classification setting which requires predicting a class in y for a given\ninstance x \u2208 X. Assume that Dxy captures the underlying data distribution and one has access to n training\nexamples Sn = {(xi, Yi)}i\u2208[n] that are independent and identically distributed (i.i.d.) according to DxY.\nGiven Sn, one hopes to learn a classifier f : X \u2192 R|| that minimizes the miss-classification error:\n$$R(f) = \\mathbb{P}_{(X,Y)\\sim \\mathcal{D}_{XY}} \\left[\\arg \\max_{y \\in \\mathcal{Y}} f_y (X) \\neq Y\\right],$$\nwhere fy(x) denotes the score that f assigns to the y-th class, given the input instance x. Since directly\noptimizing the miss-classification error or 0/1-loss poses computational challenges, one typically selects\nthe classifier that minimizes the empirical risk associated with a well behaved surrogate loss function"}, {"title": "Joint training and excess risk", "content": "Recall that training a RAM involves training both the retriever re: X\u00d7Z \u2192 R and the predictor h\u025b: X\u00d7I\u2192\nRII components of the model without access to intermediate supervision on retrieval, which is infeasible to\nobtain in most practical settings. Thus, it becomes critical to devise methods to jointly train re and he with\naccess to only labeled instances Sn = {(Xi, Yi)}i\u2208[n] \u2286 X \u00d7 Y with the predictor guiding the retriever training\nbased on how valuable the retriever-provided evidences are towards the correct final prediction.\nTowards this, we leverage the empirical risk from (8) along with the log-loss l(he(x, z), y) = \u2212 log p\u025b(y|x, z),\nwhere p\u025b(y|x, z) is defined in (7). In particular, this leads to the following joint end-to-end training objective:\n$$\\mathcal{L}_n(f,\\theta;\\mathcal{J}) = \\mathcal{R}_{\\text{log},\\mathcal{I},n}(\\xi, \\theta) = - \\frac{1}{n} \\sum_{i \\in [n]} \\sum_{z \\in \\mathcal{I}} P_{\\theta,\\mathcal{I}} (z|x_i) \\cdot \\log P_{\\xi} (Y_i|x_i, z).$$\nNote that the objective in (13) aims to improve the end-to-end performance of a RAM in deployment\nin the sense that the objective aims to minimize the expected loss given the selected evidences as per the\nretriever-induced distribution. One can use gradient-based methods to jointly minimize the objective in (13)\nwith respect to (\u03be, \u03b8); however, its efficient implementation is non-trivial due to the sum over entire data-store\nJ. In App. C.1, we discuss some approximate design choices. Lastly, please refer to Sec. 3.6 for connections\nbetween our proposed objective in (13) and some of the existing end-to-end training approaches for RAMs.\nNext, to study the generalization and expressive power of RAMs, we want to bound the excess risk\n\u2206\u03b5.(\u03be, \u03b8) as defined in (12). We consider X to be a compact subspace of Rd and, for simplicity, take"}, {"title": "Excess risk decomposition", "content": "Our excess risk relies on separating out the contribution coming from the retriever and the predictor during\nthe joint training. Moreover, the retriever and predictor errors can be each split into generalization and\napproximation error.\nThe population risk optimizer of our joint training over the space \u039e\u00d7 is defined as\n$$(\\xi_{\\text{joint}}, \\theta_{\\text{joint}}) = \\arg \\min_{(\\xi,\\theta) \\in \\Xi \\times \\Theta} \\mathbb{E}_{X} \\left[\\mathbb{E}_{Z \\sim P_{\\theta} (\\cdot|X)} \\mathbb{E}_{Y|X}l(h_{\\xi}(X, Z), Y)\\right].$$\nFor a predictor \u00a7, sample x \u2208 X and retrieved example z \u2208 I, let us denote the risk averaged over the\nlabels y as\n$$g_{\\xi} (x, z) = \\mathbb{E}_{Y|X = x} [l(h_{\\xi}(x, z), Y)].$$\nFor any fixed predictor \u00a7 (not necessarily in E) and fixed data-store I, the retriever that optimizes the joint\npopulation risk is given as p*,\u00a3(z|x) = 1arg min-1 \u00a31 94 (x,z')(z), where a tie is broken arbitrarily. Note that, for\neach sample x, the best retrieved evidence z may change. We define the optimal predictor within the class \u039e\nwith best possible retriever as\n$$\\xi^* = \\arg \\min_{\\xi \\in \\Xi} \\mathbb{E}_{X} \\left[\\min_{z \\in \\mathcal{I}} g_{\\xi} (X, z)\\right].$$\nThe optimal retriever within the class for a given predictor & is defined as\n$$\\theta(\\xi) = \\arg \\min_{\\theta \\in \\Theta} \\mathbb{E}_{X} \\left[\\mathbb{E}_{Z \\sim P_{\\theta} (\\cdot|X)}g_{\\xi}(X,Z)\\right].$$\nThe excess risk for the classes and can be bounded as\n$$\\Delta_{\\xi, \\Theta}(\\xi, \\theta) \\leq\\sum_{(\\theta, \\xi) \\in \\{(\\theta(\\xi), \\xi^*), (\\theta_{\\text{joint}}, \\xi_{\\text{joint}})\\}} \\left|\\mathcal{R}_{e,\\mathcal{I}}(\\xi, \\theta) - \\mathcal{R}_{e,\\mathcal{I},n} (\\xi, \\theta)\\right|$$"}, {"title": "Generalization error", "content": "We first bound the generalization error and relate it to the covering number of the retriever and predictor\nclass.\nAs our loss is bounded by lmax, through standard concentration bounds [Shalev-Shwartz and Ben-David,\n2014], we obtain that, for any d > 0, with probability at least (1 \u2013 \u03b4):\n$$|\\mathcal{R}_{e,\\mathcal{I}}(\\xi_{\\text{joint}}, \\theta_{\\text{joint}}) - \\mathcal{R}_{e,\\mathcal{I},n} (\\xi_{\\text{joint}}, \\theta_{\\text{joint}}) | \\leq 3l_{\\text{max}} \\sqrt{\\frac{\\log(1/\\delta)}{n}}.$$\nHowever, (\u03be, \u03b8) is learned from the data. A high probability generalization error requires taking union\nover the space of \u039e\u00d7 \u0398. We employ Rademacher complexity based generalization error bounds. Next, the\ncovering number of the space is used to bound the associated Rademacher complexity. See Shalev-Shwartz\nand Ben-David [2014] for details."}, {"title": "Approximation error", "content": "We next proceed to bound the retriever and predictor approximation errors. Towards this, we extensively use\nthe Sobolev functions spaces. A Sobolev space for a domain is characterized by two quantities, \u03ba the\nnumber of weak-derivatives a (real-valued) function within it possesses, and Lp(\u03a9) \u2013 the norm with respect\nto which these derivatives are integrable. Please see Appendix A for a complete definition."}, {"title": "Retriever error", "content": "The retriever error is given by how well the score function re(x, z) approximates the optimal retriever given\n\u00a7*. In order to do so we first need to impose some smoothness constraints on the function ge* : X \u00d7 Z \u2192 R.\nIn particular, we assume the following."}, {"title": "Final excess risk bound", "content": "We now combine the three components of the excess risk bounds under Assumptions 3.1 and 3.2 and discuss\nthe design tradeoffs. The following theorem captures our main theoretical result.\nTheorem 3.3 (Excess risk of joint training). Under Assumption 3.1 and 3.2, the excess risk for the retriever\nclass and predictor class = is bounded as\n$$\\Delta_{e,\\mathcal{I}}(\\xi, \\theta) \\leq 3l_{\\text{max}}(\\sqrt{\\frac{\\log(n)}{n}} + \\frac{\\log(|\\mathcal{I}|)}{\\tau^2}) + \\inf_{\\epsilon \\in [0, \\frac{l_{\\text{max}}}{2}]} 8\\epsilon + 24 \\sqrt{\\frac{\\epsilon}{n}} \\int_{0}^{\\frac{l_{\\text{max}}}{2}} f_\\mathcal{N}(v/2; \\Theta, \\Xi) + f_\\mathcal{N}(v/2; \\Xi, \\Theta)dv$$"}, {"title": "Illustrative example: MLPs", "content": "We instantiate both our retriever and predictor classes to be multi-layer perceptron (MLP) with depth Lret\n& width Wret = O(dx + dz) and depth Lpred & width Wpred = O(|Y|(dx + d\u2082)), respectively. The class\nMLP (Rd, Rk; L, W) is defined in Appendix A. The specialized excess risk bound for this setting is given as"}, {"title": "Connections with prior end-to-end training", "content": "We conclude our treatment of end-to-end training of RAMs by drawing parallels between our proposed\nmethod with some representative approaches from the literature.\nEMDR2 Sachan et al. [2021] minimize the following objective based on the negative log-likelihood:\n$$\\mathcal{L}^{\\text{EMDR}}_n(\\xi, \\theta; \\mathcal{I}) = - \\log p_{\\xi, \\theta,\\mathcal{I}} (y/x) = -\\frac{1}{n} \\sum_i \\log \\left(\\sum_{z \\in \\mathcal{I}} P_{\\theta,\\mathcal{I}} (z|x_i) \\cdot P_{\\xi} (Y_i|Xi, z)\\right).$$\nIt follows from the convexity of \u2013 log(\u00b7) and Jensen's inequality that our objective in (13) upper bounds the\nEMDR2 objective in (21); as a result, minimizing the former also minimizes the latter but not vice versa.\nPerplexity distillation (PDist) Another approach for joint training of RAMs in the literature involves\noptimizing two distinct objectives for training the predictor and retriever components. For example, Izacard"}, {"title": "Experiments", "content": "There have been numerous successful practical applications of RAMs in the literature (e.g., Sachan et al.\n[2021], Izacard et al. [2022]). Here, we present a brief empirical study for such models in order to corroborate\nthe benefits predicted by our theoretical results. In particular, we consider the task of open-domain question\nanswering and show that proposed objective is competitive to the objectives proposed in the literature and\nobserve the trade-offs in model capacity between retriever and predictor model.\nData Our evaluation is based on two benchmark datasets: NQOpen Kwiatkowski et al. [2019] and\nTriviaQA Joshi et al. [2017], which serve as sources for supervised examples (x, y), while chunked Wikipedia\n2018 is used as the data-store I following literature [Karpukhin et al., 2020a]. Consistent with established\npractices, we employ the exact match metric to assess the correspondence between the predicted answers and\nthe ground truth. Additionally, we introduce a recall metric to measure the frequency at which the answer\nstring appears within the retrieved documents.\nModels We implement the retriever component using GTR [Ni et al., 2022] and the predictor component\nusing T5 [Raffel et al., 2020]. We sweep across small, base, and large configurations for both retriever and\npredictor. The details regarding the model sizes, expressed in terms of the number of parameters, are provided\nin Table 6 (App. C)."}, {"title": "Discussion and related work", "content": "Several works have proposed some form of retrieval augmented models. Here, we provide a brief account\nof the evolution of RAMs and discuss how our proposed joint-learning objective and the framework for excess\nrisk analysis compare with existing end-to-end training methods.\nAugment with local neighborhood The first approaches dating back to 1970s employed just\naugmenting training instance in the local neighborhood of the input space [Stone, 1977, 1980]. Such approaches\ngained a lot of attention as parametric regression was not adequate in various practical applications of the time.\nThis line of work aims to fit a low-degree polynomial at each point in the data set based on a subset of data\npoints, which resulted in a rich literature on local polynomial regression in low dimensions [Katkovnik and\nKheisin, 1979, Cleveland, 1979, Pinsker, 1980, Donoho and Liu, 1988, Ruppert and Wand, 1994, Ibragimov\nand Has Minskii, 2013]. These classical ideas have found their application in many ML algorithms such as face\nrecognition [Jain and Learned-Miller, 2011], dimensionality reduction via local linear embeddings [Roweis and\nSaul, 2000], domain adaptation [Yang et al., 2021], test time training on neighboring points [Sun et al., 2020,\nGandelsman et al., 2022], etc. Recently, Basu et al. [2023] generalized this setup of augmenting with a local\nneighborhood of the input instance in the context of modern ML models like neural networks and proposed a\nstatistical framework to study such retrieval-based models. However, they do not consider a learned or a\nspecialized distance metric to find the augmenting set, which is critical for realizing good performance in\npractice [Schonberger et al., 2017, Karpukhin et al., 2020b] and studied in the present work.\nFixed retriever augmentation Next generation retrieval augmented models started to deploy either a\nhand crafted or a learned retriever. Zhang et al. [2006] employed SIFT [Lowe, 1999] based retrieval followed by\na SVM [Cortes and Vapnik, 1995] classifier to improve performance on multiple vision tasks. Chen et al. [2009]\nstudied generalization bounds for SVM-kNN methods one of the limited works in this domain with formal\nanalysis. For natural language understanding, methods like TF-IDF [Sparck Jones, 1972] were employed in\nthe tasks like case based reasoning [Leake et al., 1996] and open-domain question answering (ODQA; Voorhees\net al. 1999). Unlike many previous methods, one retrieves relevant text passages in ODQA settings as opposed\nto retrieving labelled training pairs. With introduction of transformers [Vaswani et al., 2017], both retriever\nand predictor models based on encoder and decoder, respectively, have become popular across various domains,\nincluding image classification [Long et al., 2022, Iscen et al., 2023], text classification [Wang et al., 2022,"}, {"title": "Conclusion", "content": "In this work, we initiate the development of a theoretical framework to study the statistical properties of\nRAMs with data-dependent retrieval. Our excess-risks analysis allows us to highlight how retriever and\npredictor components play complementary roles in reducing approximation error as we increase their respective\nfunction class complexity. We surface both theoretically and empirically a Pareto surface achieving the same\nperformance with different size predictors and retrievers. As future work, it would be interesting to study the\neffect of dynamically updatable data-store and multi-step retrievals for making predictions."}, {"title": "Preliminaries", "content": "Definition A.1 (Rademacher complexity). Given a sample Sn = {(Xi, Yi)}i\u2208[n] \u2282 X \u00d7 Y and a real-valued\nfunction class F : X \u00d7 Y \u2192 R, the empirical Rademacher complexity of F with respect to Sn is defined as\n$$\\mathcal{R}_{S_n} (\\mathcal{F}) = \\frac{1}{n} \\mathbb{E}_{\\sigma} \\left[\\sup_{f \\in \\mathcal{F}} \\sum_{i=1}^n \\sigma_i f(x_i, y_i) \\right]$$\nwhere \u03c3 = {\u03c3\u03af}i\u2208[n] is a collection of n i.i.d. Bernoulli random variables. For n \u2208 N, the Rademacher\ncomplexity Rn(F) and worst case Rademacher complexity Rn (F) are defined as follows.\n$$R_n (\\mathcal{F}) = \\mathbb{E}_{S_n \\sim D^n} [\\mathcal{R}_{S_n} (\\mathcal{F})], \\text{ and } R_n(\\mathcal{F}) = \\sup_{S_n \\sim (\\mathcal{X} \\times \\mathcal{Y})^n} \\mathcal{R}_{S_n} (\\mathcal{F}).$$\nDefinition A.2 (Covering nsumber). Let e > 0 and || . || be a norm defined over Rn. Given a function class\nF : X \u00d7 Y \u2192 R and a collection of points Sn = {(xi, Yi)}i\u2208[n] C X \u00d7 Y, we call a set of points {uj}j\u2208[m] CRn\nan (e, || ||)-cover of F with respect to S, if we have\n$$\\sup_{f \\in \\mathcal{F}} \\min_{j \\in [m]} || f(S_n) - u_j || \\leq \\epsilon,$$\nwhere f(Sn) = (f(x1,y1),..., f(xn, Yn)) \u2208 Rn. The || . ||-covering number N(F, \u20ac, || \u00b7. ||; Sn) denotes the\ncardinality of the minimal (e, || \u00b7 ||)-cover of F with respect to Sn. In particular, if || || is a lp norm (e.g.\n||2|| = (\u03a3=1|2j|P1/p for v \u2208 Rd), then we simply use N(F, 6, || \u00b7 ||Lp; Sn) to denote the corresponding\nlp-covering number.\nWhen Sn is unambiguous we may drop it, i.e., we use N(F, \u0454, ||\u00b7 ||L\u2082) to represent the covering number.\nDefinition A.3 (Multi-layer perceptron (MLP)). We consider for both retrieval and predictor, the class of\nmulti-layer-perceptron, aka fully connected Deep Neural Network, with Relu nonlinearity \u03c3(x) = max(x, 0).\nAn MLP is specified by the number of layers L, and the width W. We define with weight W\u2208 Rd2 \u00d7 Rd1\nand bias b \u2208 Rd2, an affine transform Aw,6(Rd1, Rd2) : x \u2192 Wx + b. Let \u03c3\u03bf Aw,6(Rd1, Rd2) define the\nelementwise application of the Relu non-linearity on the affine transform. The class of L layers and W width\nMLP is defined as\n$$\\text{MLP}(\\mathbb{R}^d, \\mathbb{R}^k; W, L) = \\{ A_{W_L,b_L} \\circ \\sigma \\circ A_{W_{L-1},b_{L-1}} \\circ ... \\circ \\sigma \\circ A_{W_0,b_0}\\},$$\nwhere WL \u2208 Rk\u00d7Wand b\u2081 \u2208 Rk; W\u00bf \u2208 RW\u00d7W_and b\u2081 \u2208 RW, for 1 \u2264 i \u2264 (L \u2212 1); and Wo \u2208 RW\u00d7d and\nbo \u2208 RW.\nas\nDefinition A.4 (Sobolev space). For p > 1, we denote the set of functions with finite Lp norm over \u03a9\nLp(\u03a9), i.e., for any f \u2208 Lp(N), ||f||L\u2084(\uc694) (Ssen f(s)Pds)1/p <\u221e. Note that for p = \u221e, we have\n|| f || L\u221e (2) = ess sups\u2208n|f(s)|. Let a \u2208 Nd denote a multi-index, and |a| = \u2211iedai be it's degree. We denote\nby Do the weak-derivative with respect to multi-index a for any function.\nFor an integer \u043a > 0, the Sobolev semi-norm WF (Lp(\u03a9)) for a function f that has weak-derivatives of\norder K is defined as"}, {"title": "Derivations of main result", "content": "As discussed in Section 2, the objective here is to study the excess risk in Eq. (12) which has three main\ncomponents, generalization error, retriever approximation error, and predictor approximation error (cf. (15)).\nIn this section, we structure our results somewhat differently than the main body to capture the general\nsetting of learning retriever with a fixed predictor, and vice versa. We first prove excess risk bounds for\nlearning the retriever, then excess risk bounds for learning the predictor. Finally, we combine the results to\nobtain the guarantees for jointly learning the retriever and the predictor presented in the paper. For the\nrest of the analysis we need to specify the space of retrieved examples to define the complexity of the gap\nfunction (cf. 3.1). We recall that our retrieved samples are embedded in a compact subspace of Rdz, and X is\na compact subspace of Rd. In particular, for simplicity, we assume that X \u2286 [-1,1]dx and Z \u2286 [-1,1]dz."}, {"title": "Learning the retriever", "content": "We first study learning the retriever over class when the predictor & is fixed. The task of learning the\nretriever corresponds to minimizing the following over \u03b8\u2208\u0398,\n$$\\mathbb{E}_{(X,Y) \\sim D} [\\mathbb{E}_{Z \\sim P_{\\theta} (\\cdot|X)}l(h_{\\xi}(X,Z), Y)] = \\mathbb{E}_{X} [\\mathbb{E}_{Z \\sim P_{\\theta} (\\cdot|X)} \\mathbb{E}_{Y|X}l(h_{\\xi}(X, Z), Y)|X]] = \\mathbb{E}_{X} [\\mathbb{E}_{Z \\sim P_{\\theta} (\\cdot|X)}g_{\\xi}(X,Z)],$$\nwhere g\u025b(X, Z) = Ex\\xl(h\u025b(X, Z), Y). We have a closed form for the optimal retriever when not restricted\nwithin a function class. The optimal retriever is p*,\u00a3(z|x) = 1arg min\u2082/\u22085 94 (x,z')(z), where a tie is broken\narbitrarily.\nFor the fixed predictor \u03be, let \u03b8(5) minimize the empirical risk given, and 0(5) minimize the population\nrisk over the class O, i.e.\n$$\\hat{\\theta}(\\xi) = \\arg \\min_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i \\in [n]} \\sum_{z \\in \\mathcal{I}} P_{\\theta} (z|x_i)l(h_{\\xi}(x_i, z), Y_i),$$\n$$\\theta(\\xi) = \\arg \\min_{\\theta \\in \\Theta} \\mathbb{E}_{X} \\left[\\mathbb{E}_{Z \\sim P_{\\theta} (\\cdot|X)}g_{\\xi}(X,Z)\\right].$$\nHere, the probability is defined using the softmax operator for a given \u03b8\u2208 as follows:\n$$P_{\\theta,\\xi} (z|x) = \\frac{\\exp (r_{\\theta}(x, z))}{\\sum_{z' \\in \\mathcal{I}} \\exp (r_{\\theta}(x, z'))}, \\forall z \\in \\mathcal{I}, x \\in \\mathcal{X}.$$\nHardness of retrieval: We recall the Sobolev space with a derivatives as defined in Section A. The\nfollowing is the restatement of Assumption 3.1 but for any \u03be\u2208 \u039e and not just the optimal one \u00a7*."}, {"title": "Joint learning of retriever and predictor", "content": "In this section, we consider the task of joint learning the predictor and retriever from the space and\nrespectively. The empirical optimizer pair (joint, Ojoint) and the population optimizer (joint, joint) for the"}, {"title": "More experiments", "content": "policy gradients suffer from high variance [Burda et al., 2015, Grathwohl et al., 2021] we use a constant\nbaseline [Williams, 1992] for variance reduction, i.e. our objective becomes\n$$\\nabla_{\\theta,\\xi}^{\\text{CRCE+PG}}(\\theta; \\xi, \\mathcal{I}) = -\\frac{1}{n} \\sum_{i \\in [n]} \\sum_{j \\in [K]} \\nabla_{\\theta} P_{\\theta,\\mathcal{I}} (z_j (x_i)|x_i) \\cdot \\left[\\log P_{\\xi}(Y_i|x_i, z_j (x_i)) - b\\right]$$\n$$\\mathcal{L}^{\\text{CRCE+PG}}(\\theta; \\xi, \\mathcal{I}) = -\\frac{1}{n} \\sum_{i \\in [n]} \\sum_{j \\in [K]} \\nabla_{\\theta} P_{\\theta,\\mathcal{I}} (z_j (x_i)|x_i) \\cdot \\left[\\log P_{\\xi}(Y_i|x_i, z_j (x_i)) - b\\right],$$\nwhere zj(xi) ~ po(|xi) are K i.i.d. samples from the retriever distribution. We use K = 64 and b = 5."}]}