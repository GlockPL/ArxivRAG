{"title": "FDLLM: A Text Fingerprint Detection Method for LLMs in Multi-Language, Multi-Domain Black-Box Environments", "authors": ["Zhiyuan Fu", "Junfan Chen", "Hongyu Sun", "Ting Yang", "Ruidong Li", "Yuqing Zhang"], "abstract": "Using large language models (LLMs) integration platforms without transparency about which LLM is being invoked can lead to potential security risks. Specifically, attackers may exploit this black-box scenario to deploy malicious models and embed viruses in the code provided to users. In this context, it is increasingly urgent for users to clearly identify the LLM they are interacting with, in order to avoid unknowingly becoming victims of malicious models. However, existing studies primarily focus on mixed classification of human and machine-generated text, with limited attention to classifying texts generated solely by different models. Current research also faces dual bottlenecks: poor quality of LLM-generated text (LLMGT) datasets and limited coverage of detectable LLMs, resulting in poor detection performance for various LLMGT in black-box scenarios. We propose the first LLMGT fingerprint detection model, FDLLM, based on Qwen2.5-7B and fine-tuned using LoRA to address these challenges. FDLLM can more efficiently handle detection tasks across multilingual and multi-domain scenarios. Furthermore, we constructed a dataset named FD-Datasets, consisting of 90,000 samples that span multiple languages and domains, covering 20 different LLMs. Experimental results demonstrate that FDLLM achieves a macro F1 score 16.7% higher than the best baseline method, LM-D.", "sections": [{"title": "Introduction", "content": "With the emergence of outstanding large language models (LLMs) such as ChatGPT 4, 40 [Achiam et al., 2023], Claude 3.5 [Anthropic, 2024], and Gemini1.5 [Gemini et al., 2024], the capabilities of LLM-generated text (LLMGT) have been further enhanced. Using meticulously crafted prompts, LLMs can now generate text that closely emulates human writing styles.\nMotivation. Earlier research primarily centered on distinguishing between human-written and machine-generated text [Russinovich and Salem, 2024; Xu et al., 2024; Yu et al., 2024; Abdali et al., 2024], driven largely by the need to address issues such as academic misconduct [Mozes et al., 2023]. However, with the continuous advancement of LLMs, it has become increasingly challenging to distinguish between outputs from different models in a manner that is intuitive and comprehensible to humans. Reviewing existing approaches in detecting LLM identities in black-box scenarios, we discovered a notable gap: no detection-oriented LLM has been explicitly designed for this purpose. Furthermore, including human-written text in current studies introduces additional complexity, thereby exacerbating the difficulty of accurate discrimination. Additionally, the limited diversity of detection models in existing research results in inadequate coverage of the wide range of LLMs currently in widespread use. This underscores the urgent need for more comprehensive and specialized approaches to LLM detection. In addition, when users access services from LLM providers such as Cloudflare [Cloudflare, 2024] and Volcengine [Volcengine, 2024], some providers encrypt model names, which poses security risks. Attackers could deploy malicious models on these platforms and attract users with phrases like \u201cfree\u201d or \u201cthe most powerful\", potentially leading to unpredictable consequences. In such scenarios, users are more concerned with explicitly knowing which LLM they use.\nChallenge. Current studies face the following challenges:\n(1) As a detection method for black-box scenarios, the texts to be detected are diverse in both content and language, making it impossible to exhaust all possibilities. Therefore, how to construct a dataset that covers multiple domains and captures the intrinsic features of LLMs, similar to a fingerprint database for humans.\n(2) Current LLMs are not specifically designed to distinguish outputs from various LLMGTs. Training new models from scratch or fully fine-tuning existing ones is costly and resource-intensive. Prompt-based methods, while effective, often depend on powerful commercial models, making them expensive and impractical for everyday use. This challenge calls for efficient approaches to identify and differentiate the unique fingerprints of different LLMGTs.\nSolutions. To address these challenges, we propose a targeted solution leveraging LLMs to learn complex relationships across diverse knowledge domains. Trained on vast, varied data, these models can detect subtle patterns and contextual cues that might otherwise remain hidden. As the cost of model inference continues to decline, acquiring LLMGT data at lower costs has become increasingly feasible. Capitalizing on this trend, we collected and preprocessed data from various publicly available Chinese and English corpora spanning a wide range of domains, such as social media, cultural values, finance, healthcare, and technology. From this data, we constructed a comprehensive Chinese-English raw vocabulary, which served as the foundational seed for creating a robust and diverse dataset, named FD-Datasets. This dataset includes 90,000 entries, covering multiple categories, various LLMs, and multiple languages, providing extensive coverage for analysis and detection. Building on the FD-Datasets, we fine-tuned the Qwen2.5-7B LLM to create a specialized fingerprint detection model, referred to as FDLLM. This model is explicitly designed for the task of detecting and distinguishing between outputs from different LLMs and categories. By leveraging the power of fine-tuning and a well-curated dataset, FDLLM achieves efficient and effective LLM fingerprint detection while mitigating the resource and deployment constraints associated with traditional approaches.\nBy tailoring feature extraction mechanisms to the text characteristics of LLMs and using advanced Qwen2.5 LLM as classifiers, our approach achieved superior accuracy and robustness in distinguishing multi-category generated text. It outperformed traditional methods across 20 LLMs while maintaining stable performance. Experimental results show that for each of the 20 model categories, collecting only 100 Chinese and English samples can achieve up to 100% prediction accuracy for individual models, with a macro F1 score of 91.1%.\nTo further evaluate the performance of FDLLM, we designed a multilevel testing scheme that includes domain-specific detection, cross-domain detection, and robustness testing. Our approach is entirely designed for black-box scenarios, with each step, from raw data collection to prompt construction, fine-tuning, and inference, being conducted randomly.\nThis further validates the effectiveness and practicality of our approach in real-world black-box scenarios, highlighting its broad application potential. It provides reliable technical support for tracing and detecting LLMGT. Our contributions are as follows:\n\u2022 We propose the first dedicated method for LLMGT fingerprint detection, leveraging LoRA fine-tuning on LLMs to learn implicit text features. Experiments show that our approach maintains robust detection performance even with a limited number of samples.\n\u2022 We introduce FD-Datasets, the first large-scale LLMGT fingerprint dataset containing 90,000 samples from 20 widely used LLMs, covering texts in two languages.\n\u2022 We have uploaded the related codes and experimental data of FDLLM to Supplementary Material, and we will open-source them after the paper's publication."}, {"title": "Related Work", "content": "In previous research, the academic community has primarily focused on the problem of Authorship Attribution (AA) [Uchendu et al., 2020; Abdali et al., 2024]. However, the study by Uchendu et al. [Uchendu et al., 2023] provides an in-depth analysis of the limitations of traditional AA research in the current context and shifts the focus to addressing Authorship Attribution for Neural Text Generators (NT-GAA). This work categorizes existing AA techniques into four approaches: Stylometric, Deep Learning, Statistical, and Hybrid. The authors conclude that deep learning-based methods achieve the best results for NTGAA tasks.\nHowever, specific data sets and generation strategies constrain existing deep learning methods, resulting in limited robustness. Moreover, the LLMs studied in current research are relatively narrow in scope. Presently, AA research for LLMs can be broadly divided into two approaches: one based on white-box scenarios involving modification of model parameters or outputs, and the other based on black-box scenarios that analyze only the text output.\nWhite-Box Techniques. In white-box scenarios, LLM identities are primarily detected using watermarking techniques, a form of linguistic steganography that embeds identity information in text through algorithmic word substitutions [Bahri et al., 2024]. Xu et al. [Xu et al., 2024] introduced a method using periodic signals for embedding and detecting watermarks. Google's SynthID-Text [Dathathri et al., 2024] employs a scalable approach that modifies only the sampling process, preserving high generation quality while enabling efficient detection. However, these methods have limitations: embedding watermarks often requires modifying model parameters, potentially degrading performance, while altering the sampling process can affect output quality, impacting user experience.\nBlack-Box Techniques. For detecting LLMs in black-box scenarios, existing research can be categorized into two main approaches: metric-based methods and model-based methods. Metric-based methods distinguish model outputs by designing specific statistical indicators or features. In contrast, model-based methods leverage machine learning or deep learning models to learn complex output characteristics from large-scale data, enabling the detection of sophisticated models. Below, we will detail these studies to elucidate the characteristics and applicable scenarios of different approaches.\nMetric-Based Methods. With the widespread adoption of deep learning models like BERT [Devlin, 2018] and GPT-2 [Radford et al., 2019] in text generation, early academic research primarily relied on mathematical metrics to distinguish the generated text. These studies typically focused on binary classification problems, aiming to differentiate between human-authored and machine-generated texts. For example, Gehrmann et al. [Gehrmann et al., 2019] introduced GLTR, which utilizes statistical features such as generation probabilities, word rankings, and entropy distributions to detect generation traces in text. Similarly, Solaiman et al. [Solaiman et al., 2019] proposed the Log-Likelihood method, which involves"}, {"title": "FDLLM Framework", "content": "According to Figure 1, the overview of the framework consists of three stages: Given an LLM, FDLLM operates through three steps: 1) Data Construction 2) Feature Extraction and 3) Inference\nConsidering that there is currently no dataset specifically collected for comparing responses of LLMs to the same question,"}, {"title": "Feature Extraction", "content": "In a black-box environment, LLMGT is the most critical data for analysis. For LLMs, the Temperature parameter (T) used during generation directly affects the randomness and diversity of the outputs.\n$p(x_i) = \\frac{exp(z_i/T)}{\\sum_j exp(z_j/T)}$\nHere, $z_i$ is the raw logits score calculated by the model for the token $x_i$. As the formula shows, when $T \u2192 0$, the model assigns higher weights to high-probability tokens, resulting in more deterministic and concentrated outputs. Conversely,\nTo address this, we leverage LoRA technology [Hu et al., 2021] for lightweight fine-tuning of the Qwen2.5-7B LLM (M). The fine-tuned model (M') can directly output predictions about the target model. In the LoRA method, the parameter update formula is:\n$LORA(W) = W + \u2206W,$\nwhere the update matrix AW is defined as:\n$AW = \\frac{AB}{r},$\nwith $A \u2208 R^{d\u00d7r}$ and $B \u2208 R^{r\u00d7k}$. It is evident that the choices of r and a are critical for model performance. A larger r provides a higher parameter capacity, allowing the capture of more complex features, while a controls the contribution strength of the low-rank update matrix AW. Therefore, by selecting appropriate values for r and a, we can achieve effective fine-tuning of the model while keeping hardware costs manageable, meeting the requirements for multicategory LLMGT detection."}, {"title": "Inference", "content": "During the inference stage of FDLLM, an input LLMGT is provided. By utilizing the LoRA weights fine-tuned in the earlier stage, FDLLM accurately detects the generating model under zero-shot conditions. This approach allows FDLLM to determine the source model of the text without needing additional samples or further training, significantly improving the flexibility and efficiency of model detection."}, {"title": "Experiment", "content": "Experimental Setup. For simplicity, we use Tt to represent the Temperature used during model data collection and Ti to represent the Temperature used during model inference. Both Chinese and English language environments were considered. Based on the data obtained in Section 3.1, we randomly selected 500 samples for each of 20 different models under Tt \u2208 {0, 0.5, 1}, resulting in a total of 60,000 samples. The data was then divided into a training set and a test set in a 4:1 ratio without creating a validation set.\nThe FDLLM parameters were set as follows: epoch = 3, batch size = 2, learning rate = 1 \u00d7 10\u22124, and dropout = 0.1."}, {"title": "RQ1: Performance Improvement", "content": "We conducted experiments with FDLLM and 10 other baseline methods on the same dataset. Based on Table 2, we have the following observations: Traditional methods (e.g., Entropy, Rank, and DetectGPT) performed poorly in classification tasks, with Macro F1 scores mostly below 4%. This indicates they cannot effectively distinguish samples. Intermediate-performance methods (e.g., GLTR and Log-Likelihood) showed slight improvements. However, their scores, around 7%, still fall short of practical requirements. Advanced baseline methods (e.g., ChatGPT-D and OpenAI-D) achieved significant improvements but still lagged behind FDLLM. This highlights FDLLM's superior capability in such tasks. FDLLM outperformed all other methods in every performance metric. Its Macro F1 score reached 91.1%, demonstrating its ability to achieve a good balance between generation stability and classification accuracy. In contrast, traditional methods (e.g., Entropy and Rank) and intermediate-performance methods (e.g., GLTR and Log-Likelihood) generally had much lower metric values and could not compete with FDLLM's performance."}, {"title": "RQ2: Impact of Training and Inference Parameters", "content": "Considering that collecting 400 training samples for each model to achieve high performance may hinder the practical application of this method, we explored the performance of models trained under different training set sizes. The results are shown in Table 3. We found that even if the training set size is reduced by half, the model still achieves excellent results. Surprisingly, the Macro F1 score was 2 percentage points higher than the model trained on the full dataset. When the training set size was further reduced to one-fourth of the original, the Macro F1 score decreased by about 4% points. Even with a training-to-testing ratio of 1:1, FDLLM"}, {"title": "RQ3: LoRA Parameter Configurations", "content": "We further investigated the impact of different LoRA parameters (r and a) on model performance. The test set consists of data with five different Ti values constructed in previous experiments. The experimental results, shown in Table 4, illustrate the influence of various LoRA parameter configurations on model performance. From the results, it can be observed that appropriate values for r (e.g., 256) and a (e.g.,) typically achieve a good balance between performance and computational efficiency. In contrast, excessively small r or a values limit the adaptability of the model, resulting in decreased performance. Thus, selecting suitable r and a configurations balances performance and efficiency.\nIn addition, a significant performance drop was observed when a was set to twice the value of r, increasing the influence of LoRA on model weights. This might be due to excessive intervention by LoRA, which disrupts the original knowledge of the model and adversely affects its performance. To visualize the prediction performance of FDLLM across different LLMs more intuitively, the confusion matrix, the confusion matrix is presented in Figure 4. The deep red cells on the diagonal represent correctly classified samples. The following conclusions can be drawn from the figure: FDLLM achieves a classification accuracy of over 95% for 50% of the models.\nFurthermore, FDLLM tends to confuse GLM4 and GLM4 Flash, likely due to their high similarity. A similar issue occurs between Qwen2.5 and Qwen Turbo. FDLLM still has room for improvement. For instance, when handling the Deepseek model, FDLLM frequently misclassifies it as other models, such as GPT4o and GLM4 Plus."}, {"title": "Conclusion and Future Research", "content": "This paper introduces and applies LoRA fine-tuning to the Qwen2.5 LLM for detecting LLMGT in a black-box setting. We employ advanced NLP techniques to process a large corpus, generating high-quality data to produce rich text seeds. These seeds are then used to sample outputs from the target LLM, creating a diverse dataset that spans various languages and domains. The fine-tuned FDLLM demonstrates outstanding performance in classification tasks involving LLMGT. In the future, we plan to explore additional methods to enhance the FDLLM's robustness against adversarial samples."}, {"title": "Ethical Statement", "content": "Despite dataset cleaning and optimization, some offensive or sensitive content may remain. The LLM in this paper lacks extensive verification, and its outputs may show biases, inaccuracies, or other issues. Users should not rely solely on this tool for final decisions and are encouraged to review results through multiple methods to ensure fairness, accuracy, and reliability."}]}