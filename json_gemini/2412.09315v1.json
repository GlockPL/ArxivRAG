{"title": "Beware of Metacognitive Laziness: Effects of Generative Artificial Intelligence on Learning Motivation, Processes, and Performance", "authors": ["Yizhou Fan", "Luzhen Tang", "Huixiao Le", "Kejie Shen", "Shufang Tan", "Yueying Zhao", "Yuan Shen", "Xinyu Li", "Dragan Gasevic"], "abstract": "With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human-AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human-AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self-regulated learning processes and learning performances on a writing task among different groups who had support from different agents, i.e., ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi-channel learning, performance and motivation data were collected and analysed. The results revealed that: 1) learners who received different learning support showed no difference in post-task intrinsic motivation; 2) there were significant differences in the frequency and sequences of the self-regulated learning processes among groups; 3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self-regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive \"laziness\u201d. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.", "sections": [{"title": "1 | INTRODUCTION", "content": "In the 21st century, marked by constant technological evolution, artificial intelligence (AI) has become a catalyst for industrial and societal transformation. Al can automate many processes, significantly impacting the workforce and labour markets (Rane, 2023). It becomes essential for everyone to learn how to cooperate with Al and to capitalise on the new opportunities (Zarifhonarvar, 2023). Consequently, the importance of lifelong learning with human-Al collaboration is increasingly emphasised, signifying that everyone needs to continually acquire, adjust, and transfer knowledge and skills (Parisi et al., 2019), and more importantly, integrate the strengths of both humans and Al in the learning process (J\u00e4rvel\u00e4 et al., 2023). Following this vision, the concept of hybrid intelligence was proposed and several hybrid human-Al learning and regulation models were constructed (Holstein et al., 2020; J\u00e4rvel\u00e4 et al., 2023; Molenaar, 2022b). Akata et al. (2020) defined hybrid intelligence as a \"combination of human and machine intelligence, augmenting human intellect and capabilities instead of replacing them and achieving goals that were unreachable by either humans or machines\" (Akata et al., 2020, p. 19). Hybrid Intelligence is viewed as an evolving approach that addresses the limitations of data-driven Al (J\u00e4rvel\u00e4 et al., 2023), which often lacks interpretable and actionable insights, risk due to biased data and faces constraints in real-world applications (Ahmad et al., 2024). However, research into hybrid intelligence is still at a nascent stage (Molenaar, 2022b), and particularly, this field notably lacks deep insights and understanding of the mechanisms and outcomes of hybrid human-Al learning based on strong empirical research.\nIn the context of lifelong learning and hybrid intelligence, learners' regulation plays a pivotal role, serving as a fundamental mechanism in an individual's ability to engage effectively in learning (Taranto and Buchanan, 2020) and human-Al collaboration (Molenaar, 2022b). Self-regulated learning (SRL), as defined by Zimmerman (2000), involves self-generated thoughts, feelings, and behaviours directed toward achieving personal goals. The SRL model consists of three phases: forethought (where learners analyse tasks, set goals, and plan approaches, driven by motivational beliefs), performance (where they execute tasks, monitor progress, and apply self-control strategies to maintain fo-cus and motivation), and self-reflection (where they assess performance, make attributions of success or failure, and adjust strategies for future tasks)(Zimmerman, 2000, 2002). Complementing SRL is metacognition, a term introduced by John Flavell in the 1970s, which refers to \"thinking about thinking\" or \"cognition about cognition\" (Flavell, 1979). Metacognitive strategies in SRL, such as goal setting, self-monitoring, and self-evaluation, are essential for effective"}, {"title": "2 | BACKGROUND", "content": "In this section, we initially provide a concise overview of research concerning learners engaging with diverse agents, along with the associated insights on motivation, processes, and performance dimensions. Subsequently, we introduce our research questions, designed to fill the existing research gap in this area."}, {"title": "2.1 | Motivation", "content": "Motivation, a pivotal element in SRL, is essential for initiating and sustaining educational endeavours (Panadero, 2017). Broadly defined, motivation encompasses the driving forces behind task completion, which range from intrinsic enjoyment to extrinsic rewards such as financial incentives (Lazowski and Hulleman, 2016). This concept extends to encompass diverse psychological elements such as needs, goals, and emotions, which are identified as crucial in ed-ucational psychology (Panadero, 2017). In this context, motivation plays a critical role in shaping learning processes and performance (Linnenbrink and Pintrich, 2002, 2003). It has significant impact on learner engagement and the maintenance of learning activities (Yu et al., 2023).\nLearning motivation can generally be divided into extrinsic and intrinsic motivations (Hennessey et al., 2015). Extrinsic motivation arises from external factors such as rewards and scores, thus it is rather sensitive to the context or setting of learning(Abuhamdeh and Csikszentmihalyi, 2009). For example, changing the way of assessment or rewards could easily manipulate learners' extrinsic motivation. Consequently, extrinsic-motivation-related effects of instruc-tional interventions often lack external validity and are not robust among varied contexts. On the other hand, intrinsic motivation, which arises within individuals, is more valued by researchers within learners' SRL (Borjigin et al., 2015; Panadero, 2017). When individuals are intrinsically motivated, they engage in activities because they enjoy and get personal satisfaction from doing them (Oudeyer et al., 2016). Intrinsic motivation plays a greater role in enhancing en-gagement and achievement than extrinsic motivation, as it emerges within individuals and is less sensitive to external environments. Moreover, from the perspective of individual development, learners' intrinsic motivation (e.g., inherent interest) has a more direct impact on the development of knowledge and skills (Fidan and Gencel, 2022). Based on the above considerations, our study mainly focuses on learners' intrinsic motivation.\nMany studies posit that Al can enhance learning motivation. For instance, in a quasi-experimental study (Al-Abdullatif et al., 2023), learners who interacted with the task-oriented chatbot integrated with WhatsApp, showed higher motivation levels compared to a control group not using Al. Similarly, Lee et al. (2022) employed a quasi-experimental design to assess the effects of an Al-based chatbot used for after-class review, finding that learners in the Al group outperformed their counterparts in the control group in terms of academic performance, self-efficacy, learning attitude, and motivation. Yin et al. (2021) also found that learners in the Al chatbot-based learning environ-"}, {"title": "2.2 | Self-regulated Learning Process", "content": "Analysing learners' SRL processes helps us better understand their SRL and metacognitive strategies (Gandomkar et al., 2016; Sonnenberg and Bannert, 2015), which are fundamental to driving behavioural change across various contexts (Frazier et al., 2021). In an era where learning environments are becoming increasingly diverse and complex, learners often interact with a range of agents, including human experts, Al, and different learning tools. Understanding how learners conceptualise, strive for, and accomplish their goals under different agent conditions is therefore essential.\nPrevious research has provided valuable insights into the impact of Al on SRL processes. Several studies have focused on understanding learners' perceptions, engagement, and SRL strategies when interacting with Al platforms. For example, Clark et al. (2024) focused on non-science majors' perceptions of a final exam facilitated by ChatGPT, underscored learners' enhanced self-reflection and the importance of analysing Al-generated work, suggesting the potential role of Al in modulating SRL processes. Hwang et al.'s (2022) study on the smart chatbot application, Smart UEnglish, which analysed quantitative and semi-quantitative variables related to learners' behaviours, revealed that Al significantly influenced learners' behaviours in authentic English learning contexts, particularly during 'free talk' and 'designed talk' activities, underscoring the role of Al in facilitating complex conversation practice and enhancing learner engagement. Chen and Chang (2024) identified statistically significant differences in behaviour sequences in different learning conditions, revealing that learners in a game-only setup relied on trial-and-error approaches, whereas learners using the game with Al aid exhibited more systematic problem-solving strategies, making active use of tools and revisiting necessary knowledge. Recently, scholars have increasingly focused on the dynamic analysis of sequences of learning behaviour with techniques such as process mining and epistemic network analysis to gain a deeper understanding of the SRL process (Li et al., 2023; Saint et al., 2022), which is essential for a comprehensive understanding of learning.\nWhile the existing studies offer valuable contributions, there is a gap in the literature regarding comparative anal-"}, {"title": "2.3 | Learning Performance", "content": "Learning performance is usually referred to as the intellectual outcomes (i.e. knowledge acquisition, content under-standing, skill attainment) and belongs to the cognitive domain in the field of education (Soderstrom and Bjork, 2015). The implementation of Al enables personalised guidance, and one-to-one tutoring, which provides expanding oppor-tunities for cognitive enhancement and better performance (Altarawneh, 2023; Chen et al., 2023). Hence, several studies have examined the potential of Al tools in enhancing learners' performance in educational contexts; for ex-ample, V\u00e1zquez-Cano et al. (2021) and Hakiki et al. (2023) conducted quasi-experiments in this line of research. Both studies showed that learners with chatbots or ChatGPT had higher scores in their final tests than those with con-ventional technology methodology (Hakiki et al., 2023; V\u00e1zquez-Cano et al., 2021). In other words, their participants utilising chatbots or ChatGPT could transfer what they learned better as evidenced by performance on other tests than the participants utilising conventional technology. In another study, Alneyadi and Wardat (2023, 2024) also found that learners with ChatGPT had significantly higher post-test scores (knowledge gain in the field of electronic magnetism) than those with human tutors. Their participants (non-native English speakers) considered ChatGPT a useful facilitator to overcome their language barriers as well as better understand complex concepts. Similarly, Song and Song (2023) recruited English as foreign language learners and used the International English Language Testing System (IELTS) test to examine whether learners' writing skills improved using ChatGPT as learning support. Their results showed that learners who interacted with ChatGPT had higher scores in aspects of writing such as organi-sation, coherence, grammar, and vocabulary. Additionally, a meta-analysis of 24 randomised studies demonstrated that Al chatbots played a significant role in promoting improved learning performance Wu and Yu (2024). The afore-mentioned studies elucidated the potential of Al-powered chatbots such as ChatGPT to improve learners' test scores, knowledge gain, and knowledge transfer.\nHowever, divergent findings have also been reported in the existing literature. Researchers reported that Al-powered tools offer no direct help in learners' performance, even though they create a more relaxing environment (Asare et al., 2023). For instance, Yin et al. (2021) compared pre-post scores of learners who used Al-powered chatbots to those of the learners who interacted with a human tutor. Their results showed no significant difference in the overall learning performance between the two groups. In other words, despite the fact that Al chatbots provided more flexible and enjoyable learning environments and experiences for learners, they had no advantage over traditional methods of teaching in improving learners' learning performance. Moreover, Asare et al. (2023) found a negative influence on learners' mathematics performance after the implementation of ChatGPT. Their participants pointed out that ChatGPT only helped learners come up with solutions for the problems, whereas neither analysis for the problems nor explanations for the solutions were provided by ChatGPT. In other words, utilising ChatGPT did not improve learners' understanding of what they studied.\nPrevious research has mainly been focused on learners' performance in two educational contexts (e.g. ChatGPT vs. human tutor, or ChatGPT vs. conventional technology environment) by means of comparing one dimension of their learning performance (e.g. knowledge gain, knowledge transfer, or test score). Therefore, we propose the following"}, {"title": "3 | METHODS", "content": null}, {"title": "3.1 | Experimental Design and Settings", "content": "Participants. A total of 117 university students (average age 22.61, SD=3.39, with 70% identifying as female and 55% undergraduates) participated in the experiment from July to September 2023. These participants came from a diverse array of disciplines. English was a second language for all the participants with the first language being [disclosed]. The participants were asked to complete a two-stage English reading and writing task as shown in Figure 1. The participants were randomly assigned to four experimental groups: one group did not have any support and finished the task by themselves (CN group, 30 participants); one group of learners were supported by ChatGPT 4.0 (Al group, 35 participants); one group of learners were supported by a human expert (HE group, 25 participants); and one group of learners had the support of the writing analytics toolkit named Checklist Tools (CL group, 27 participants).\nLab setting and research procedure. As shown in Figure 1, we conducted our experiment in the lab, where partic-ipants were required to complete the task following six steps: pre-task, stage 1 training, stage 1 reading and writing, stage 2 training, stage 2 revising, and post-task. In the lab, participants used a computer to complete pre-post-task questionnaires, watch training videos and complete the learning tasks. The first training video instructed the par-ticipants on how to use the learning tools in our learning environment. After watching the first training video, the participants began the 2-hour reading and writing task. The second training video introduced the participants to the support provided to them during the revision according to their experimental group assignment. After watching the second training video, the participants began the 1-hour revising task aiming to improve their essays. Once these tasks were completed, participants were asked to complete the post-test within one day.\nLearning task. The participants, as English as second language speakers, were required to complete an English writing and revising task. In this task, we provided participants with reading materials on three topics: Al, differentiated teaching, and scaffolding teaching. The participants were expected to read these materials and write an essay that envisions the future of education in 2035 while integrating the three topics. Alongside these materials, a rubric was"}, {"title": "3.2 | Four Learning Groups and Corresponding Learning Support", "content": "Table 1 shows the different conditions of the four groups. the CN group maintained the same learning environ-ment in both stage, without any additional support provided. the Al group received assistance from ChatGPT 4.0 (embedded in our platform user interfaces), which was trained and restricted to the content covered by our learning task (only conversations based on the learning task are allowed). The HE group received assistance from a proficient human expert who specialises in academic writing and academic writing education; participants could ask for help in polishing the content of the essay. The CL group had the support of writing analytics tools, which could provide feedback on (1) spelling and grammar, (2) academic style, (3) originality, and (4) rhetorical structure consistent with the genre the learners were asked to write in based on a GPT-based classifier of rhetorical categories designed in accor-dance with Author (2023) research, following Bloom's taxonomy of cognitive domains (Bloom et al., 1956; Krathwohl, 2002). Detailed information about the conditions of the four groups is in the Appendix."}, {"title": "3.3 | Data Collection and Data Analysis", "content": "To answer RQ1, learners' motivation was measured using the Intrinsic Motivation Inventory(IMI) McAuley et al. (1989); Torbergsen et al. (2023) in the post-task to compare the difference of four groups in terms of intrinsic motivation. IMI has been widely used in measuring intrinsic motivation in different learning tasks Heindl (2020); Predyasmara et al. (2022). The IMI consists of four dimensions to measure individuals' intrinsic motivation toward a task: inter-est/enjoyment, perceived competence, effort/importance, and pressure/tension. The interest/enjoyment dimension is considered a self-report measure of intrinsic motivation, while the other three dimensions measure the theoretically relevant predictors of intrinsic motivation. ANOVA followed by Tukey's HSD was used to compare the differences be-tween the four groups in terms of intrinsic motivation.\nTo answer RQ2, we collected the learning trace data of learners' behaviours during the study (both the first stage of reading and writing and the second stage of revising). The learning trace data included learners' navigational logs (i.e., page views), click streams, mouse movement and keyboard strokes. We followed the trace parser approach to parse the raw learning trace data into learning actions and processes (Fan et al., 2022a,b; Saint et al., 2021, 2020). For example, the trace data of a learner who opened the task instruction or rubric page and scrolled the mouse wheel up and down were labelled as instruction action based on the action library (see Appendix), and such actions were further labelled as orientation process based on the process library (see Appendix) because these actions indicated the learner was trying to understand the requirements of the task. For a non-parametric comparison of process frequency, we conducted the Kruskal-Wallis test followed by Mann-Whitney test for post hoc analysis to investigate the difference among learners when they interacted with different agents.\nAdditionally, we aim to understand not just the differences in frequency, but also how learners sequentially and temporally engage with various SRL processes throughout their learning. Therefore, we employed the process mining method (pMineR) utilising the first-order Markov Model (FOMM) which has been used extensively in previous research (Gatta et al., 2017; Saint et al., 2022, 2021), to assess the temporal characteristics and process models of learners' interactions and engagements with different agents across four groups. We utilised overlay on the process maps, provided by pMineR, to highlight the differences between groups, using red and green edges to highlight key variations (the difference in transition probabilities larger than 10%) in the SRL process models. In the present study, we aimed to identify potential metacognitive laziness by analysing learners' SRL process models. We collected and compared SRL processes across different experimental groups, focusing on key metacognitive activities such as orientation, planning, monitoring, and evaluation. By examining variations in these SRL processes (and their transitions with other processes such as reading and elaboration) between different groups, we aimed to identify patterns indicating a reduction in metacognitive engagement, thereby revealing the presence and impact of metacognitive laziness.\nTo answer RQ3, we evaluated learners' learning performance across three dimensions: 1) essay score improve-ment (difference in essay scores before and after revising), 2) knowledge gain (difference between pre- and post-test scores on the same knowledge test on Al in education), and 3) knowledge transfer (knowledge test score on Al in healthcare). Each learner's two versions of the essay before and after the revision were scored by researchers. Two researchers independently assessed 12 written essays using the same rubric provided to learners (see Appendix), based on the five predefined criteria. Inter-rater reliability, measured through the intraclass correlation coefficient (ICC) and absolute agreement, indicated a high level of consistency (all ICCs > 0.85). In light of this strong inter-rater reliability, the remaining essays were evaluated by a single researcher. The knowledge test on Al in education (10 items of single or multiple-choice questions) and the transfer test on Al in healthcare (10 items of single or multiple-choice questions) were developed and examined the reliability in previous studies (Authors, 2022, 2023). To analyse differences across four groups on the three performance dimensions, we employed a series of ANOVA tests based on"}, {"title": "4 | RESULTS", "content": null}, {"title": "4.1 | RQ1: Differences in Intrinsic Motivation of Four Groups", "content": "To address RQ1, learners' intrinsic motivation was measured using the IMI in the post-task to compare the dif-ferences of the four groups. An ANOVA, followed by Tukey's HSD, was used to compare the differences. The over-all Cronbach's alpha for the IMI was 0.82, with subscale alphas as follows: 0.94 for Interest/Enjoyment, 0.93 for Perceived Competence, 0.86 for Effort/Importance, and 0.91 for Pressure/Tension. Table 2 shows the descriptive statistic results of each dimension in IMI. No significant difference between the four groups was observed with re-gards to Interest/Enjoyment (F=1.087, p=0.358, $\\eta^2$=0.029), Perceived Competence (F=0.453, p=0.716,$\\eta^2$=0.012), Ef-fort/Importance (F=1.152, p=0.332, $\\eta^2$=0.030) and Pressure/Tension (F=0.546, p=0.652,$\\eta^2$=0.015). Although the insignificant were observed, we found two patterns based on the descriptive statistical results which might revealed some additional information. Firstly, the CN group reported lowest interest and enjoyment. Meanwhile, the CN group reported the highest pressure and tension, which is a negative predictor of intrinsic motivation. This indicates a po-tential tendency that learners with external learning support would have higher intrinsic motivation for the learning"}, {"title": "4.2 | RQ2: Differences in SRL processes of Four Groups", "content": null}, {"title": "4.2.1 | Frequency differences of SRL processes", "content": "To address RQ2, we collected the learning trace data of learners' behaviours. We followed the trace parser approach to parse the raw learning trace data into learning actions and processes (See section 3.3 and Appendix). Figure 3 shows the comparison results of frequencies of different SRL processes among four groups in learning stage 1 (upper half of the figure) and learning stage 2 (lower half of the figure). As shown in Figure 3, we found that in the first stage (without differentiated support), there is basically no significant difference in the frequency of the SRL processes between the three treatment groups and the control group (except that the orientation process of the CL group was slightly lower than that of the CN group). However, there are significant differences in the frequency of the SRL processes in the revising stage. For instance, during the revising, learners in the AI, HE and CL groups engaged more extensively in the processes of Elaboration and Organisation, which primarily involve writing activities, compared to those in the CN group. Conversely, learners in the Al and HE groups participated less in reading. This pattern emerged because learners in the Al and HE groups primarily revised their texts through interactions with ChatGPT or human experts, in contrast to those in the CN and CL groups who continued to engage extensively with reading materials. It is also worth noting that, the AI, HE and CL groups also demonstrated significantly more Orientation processes (but no differences in Monitoring and Planning processes) in the revising stage compared with CN group, which indicated that learning in the AI, HE and CL groups revisited the task instruction and rubric pages more extensively. Interestingly, the use of checklist tools led to a significant increase in Evaluation processes among learners in the CL group, an effect not observed in the Al and HE groups. This might be closely tied to the design of the checklist tools which guided the learners' using rubrics to evaluate and revise their own writing."}, {"title": "4.2.2 | Temporal model differences of SRL processes", "content": "Figure 4 shows two comparisons between groups (the upper part is the comparison between the Al group and CN group, and the lower part is the comparison between the Al group and HE group). The other pairwise comparisons are placed in the Appendix due to space limitations. The nodes in Figure 4 represent the seven SRL processes defined in this study, the connecting lines represent transitions between processes, and the numbers on the connecting lines represent transition probabilities. The Red lines indicate that the transition probability of the Al group at this transition was higher than that of the comparison group (e.g., CN or HE group), the green lines indicate the opposite, grey lines indicate the difference in transition probability was smaller than 10%, and the thickness of the lines indicates the differences in transition probabilities.\nAs illustrated in the upper half of Figure 4, a prominent distinction between the Al group and the CN group is the prevalence of red transitions pointing to the Other node, indicating that the Al group learners frequently returned to interact with ChatGPT after engaging in processes such as MC.O, HC.EO, MC.M, and MC.E. Notably, Figure 4 highlights a pronounced loop involving Other, HC.EO, and MC.E (with all transitions marked in red). This loop suggests that learners in the Al group predominantly relied on consulting ChatGPT during the revision stage to refine and assess their essays, thus making it their primary strategy. However, the stronger transitions of the CN group (marked in green), show interactions between HC.EO with processes such as LC.FR, MC.O, and MC.P. This indicates that"}, {"title": "4.3 | RQ3: Differences in Learning Performances of Four Groups", "content": null}, {"title": "4.3.1 | Dimension 1: essay score improvement", "content": "The ANOVA results indicated no significant differences in essay scores (F=1.275, p=0.286, $\\eta^2$=0.033) before revision, but significant differences in score improvements (F=4.549, p=0.005, $\\eta^2$=0.108) after revision. As detailed in Table 4.3.1, pairwise comparisons indicated that the score improvement in the Al group was significantly greater than in the other three groups. Specifically, the Al group showed a higher score improvement than the CN group (mean difference = 1.970, p-adjusted = 0.037), the HE group (mean difference = 2.120, p-adjusted = 0.025), and the CL group (mean difference = 2.200, p-adjusted = 0.012). These results suggest that the Al group had a statistically significant higher task performance compared to the other groups. The descriptive statistical results of the scores and the figures to visually display the distribution of scores across groups are presented in the Appendix, in which three metrics were included: scores after the writing task, scores after the revision task and essay score improvement."}, {"title": "4.3.2 | Dimension 2: knowledge gain", "content": "We compared learners' knowledge gain by means of ANOVA, and the descriptive results including the pre-test score, post-test score and score improvement are reported in Appendix (Table 2). The ANOVA results indicated no significant differences between the groups in terms of the pre-test score (F=1.294, p=0.281, $\\eta^2$=0.036) and post-test score (F=0.913, p=0.438, $\\eta^2$=0.030), which means no significant differences in knowledge gain."}, {"title": "4.3.3 Dimension 3: knowledge transfer", "content": "We compared the transfer test scores between the four groups, and ANOVA results showed that there were no significant differences between the four groups (F=0.019, p=0.996,$\\eta^2$=0.000). The descriptive statistics results of transfer test scores are shown in Table 3 in the Appendix."}, {"title": "5 | DISCUSSIONS", "content": null}, {"title": "5.1 | RQ1: Learners' Intrinsic Motivation While Interacting With Different Agents", "content": "Our study explored the impact of Al, human expert, checklist tools, and a control group on learners' intrinsic motivation (RQ1). Results showed no significant differences in intrinsic motivation among the four groups, although descriptive statistics revealed the control group (CN) had the lowest interest and enjoyment and the highest pressure and tension, supporting previous research on external learning support boosting motivation (Borjigin et al., 2015; Fidan and Gencel, 2022). The checklist group (CL) reported the highest scores for interest, enjoyment, perceived competence, and effort, with the lowest pressure and tension, indicating the highest intrinsic motivation. Checklist tools may enhance motivation by providing clear goals, accomplishment, and reduced anxiety (Yu et al., 2023).\nYu et al. (2023) argued that motivation plays a critical role in shaping learning processes and performance. For example, Caratiquit and Caratiquit (2023) found that ChatGPT improved academic performance by enhancing mo-tivation, suggesting Al tools can boost achievement. However, Deng and Yu (2023) conducted a meta-analysis and showed that chatbot technology did not significantly enhance learning motivation, which triggered the discussion on the role of motivation in high-intelligence tools (such as ChatGPT) assisted learning. In our study, we found no differences in intrinsic motivation between groups and extrinsic motivation was well controlled, however, significant differences were still found in learners' learning process and performance. In our context, ChatGPT or Checklist tools served as efficient tools which significantly affected the SRL processes and final essay score improvement, but the difference in intrinsic motivation was not significant. On the one hand, our research showed that the complex mech-anisms of hybrid intelligence in terms of motivation, process and performance require further research. Our research also raises concerns about whether Al-powered technologies such as ChatGPT really affect learners' long-term intrin-sic motivation while rapidly improving short-term performance."}, {"title": "5.2 | RQ2: Learners' SRL process and Potential Metacognition Laziness Issue", "content": "Our second research question (RQ2) focused on understanding the variations in SRL processes among learners inter-acting with different agents. Our results revealed significant differences during the revising stage, with the ChatGPT (Al), human expert (HE), and checklist (CL) groups engaging more extensively in elaboration, organization and orienta-tion processes. This finding aligns with previous studies suggesting that Al and human tutors can facilitate interactive and personalized revision processes, moving beyond traditional reading-intensive approaches (Chen and Chang, 2024; Wei, 2023). Interestingly, the CL group also demonstrated a significant increase in evaluation processes, which can be attributed to the writing analytics diagnostic design of the checklist tools. Previous research has emphasized the importance of dynamic analysis of behaviour sequences to gain a deeper understanding of the SRL process (Li et al., 2023; Saint et al., 2022), and our findings contribute to this understanding by highlighting the impact of different agents aimed at supporting learning.\nWhen comparing the Al group to other groups, frequency analysis and process mining revealed that the Al group"}, {"title": "5.3 | RQ3: Differences in learning performance of three dimensions", "content": "Our third research question compared the four groups on three dimensions of performance, and our findings showed that the Al group significantly improved the essay scores compared to other groups, but no significant differences were found among the groups in terms of knowledge gain or knowledge transfer. ChatGPT's ability to effectively improve learners' writing performance and productivity has been proven in many studies (Noy and Zhang, 2023; Song and Song, 2023). However, our research, for the first time, systematically compared four different conditions in a randomised trial, and to our surprise, ChatGPT improved writing performance even more than the condition that involved support provided by a very experienced human expert. This out-performance, based on previous studies, may relate to sev-eral advantages of ChatGPT, including providing additional learning resources, immediate feedback, helping learners comprehend challenging concepts, overcoming language barriers, bridging gaps for learners with different needs and"}, {"title": "6 | LIMITATIONS", "content": "This study is subject to several limitations that may affect the generalizability and robustness of the findings. The ob-served lack of significant differences between groups could be attributed to constraints related to task duration and sample size. Therefore, further research with larger sample sizes and exploration of long-term effects on motivation and performance is necessary. The study recruited 117 university students, of whom 70% were female. This gender imbalance may also limit the representativeness of the sample and, in turn, the external validity of the results. Given this limitation, there is a need for future research to expand the sample size and strive for a more balanced gender distribution to enhance the generalizability of the findings to broader contexts and diverse populations. Another lim-itation lies in the study's reliance on a single task involving reading and writing activities. Focusing exclusively on this"}, {"title": "7 | CONCLUSION", "content": "In conclusion, our study highlights the potential of ChatGPT in improving essay scores, significantly outperforming other groups, including those guided by human experts. However, there were no significant differences in knowledge gain or transfer, indicating that while ChatGPT can enhance short-term task performance, it may not boost intrinsic motivation or long-term learning outcomes. The study also raises concerns about metacognitive laziness, where learn-ers become overly reliant on Al, potentially hindering their ability to self-regulate and engage deeply in learning. This study contributes to the field of hybrid intelligence by revealing the potential and issues of learning with GenAl, and it calls for future research to deepen our understanding of how learners learn, regulate, collaborate, and evolve with Al."}]}