{"title": "Advanced POD-Based Performance Evaluation of Classifiers Applied to Human Driver Lane Changing Prediction", "authors": ["ZAHRA RASTIN", "DIRK S\u00d6FFKER"], "abstract": "Machine learning (ML) classifiers serve as essential tools facilitating classification and prediction across various domains. The performance of these algorithms should be known to ensure their reliable application. In certain fields, receiver operating characteristic and precision-recall curves are frequently employed to assess machine learning algorithms without accounting for the impact of process parameters. However, it may be essential to evaluate the performance of these algorithms in relation to such parameters.\nAs a performance evaluation metric capable of considering the effects of process parameters, this paper uses a modified probability of detection (POD) approach to assess the reliability of ML-based algorithms. As an example, the POD-based approach is employed to assess ML models used for predicting the lane changing behavior of a vehicle driver. The time remaining to the predicted (and therefore unknown) lane changing event is considered as process parameter. The hit/miss approach to POD is taken here and modified by considering the probability of lane changing derived from ML algorithms at each time step, and obtaining the final result of the analysis accordingly. This improves the reliability of results compared to the standard hit/miss approach, which considers the outcome of the classifiers as either 0 or 1, while also simplifying evaluation compared to the \u00e2 versus a approach. Performance evaluation results of the proposed approach are compared with those obtained with the standard hit/miss approach and a pre-developed \u00e2 versus a approach to validate the effectiveness of the proposed method. The comparison shows that this method provides an averaging conservative behavior with the advantage of enhancing the reliability of the hit/miss approach to POD while retaining its simplicity.", "sections": [{"title": "I. INTRODUCTION AND MOTIVATION", "content": "SUPERVISED classification is a machine learning (ML) approach that involves training a model using a dataset with known labels, aiming to predict the class or category of new data [1]. Machine learning classifiers are a fundamental part of a wide range of artificial intelligence applications. Object detection, fraud and fault detection, text classification, medical diagnosis, and structural damage detection are examples of tasks in which ML classifiers are extensively employed.\nIt is essential to evaluate the performance of ML classifiers as it ensures their reliability and applicability to specific tasks they have been designed for, guiding model selection and improvement. Various evaluation metrics have been used for this purpose. According to [2], accuracy, recall, F-score, and precision are the most commonly used ones in recent years [3], [4], [5], [6], [7]. Receiver operating characteristic (ROC) and precision-recall (PR) curves are other frequently employed evaluation tools [8], [9], [10]. The ROC curve is a graphical tool for illustrating a classifier's performance by plotting detection rate (DR) against false alarm rate (FAR) values at various classification thresholds. The area under the ROC curve serves as a summery measure of the model's performance which ranges from 0.5, representing a model with no discriminative power, to 1, denoting a flawless model. Receiver operating characteristic curves can be deceptive when dealing with unbalanced data, making the model's performance seem better than it actually is. To address this common issue in the field of ML, PR curves are often considered a suitable alternative [11], [12], [13]. On a PR curve, precision\nis plotted against recall (another name for DR) at various\nthresholds. Like with ROC curves, a summery measure of a\nclassifier's performance can be obtained by calculating the\narea under the PR curve which ranges from 0 to 1.\nClassification results are often affected by process parame-\nters that are not accounted for by classifiers. Process parame-\nters, which differ from training/model-specific hyperparame-\nters, are task-specific factors that impact recognizability of\nthe target and the final outcome. The size of damage in a\ndamage detection task or the resolution of images used for\ndisease diagnosis tasks are examples of process parameters.\nDespite their significance, these effects have not been directly\naccounted in any of the previously mentioned evaluation\nmetrics, therefore have not received sufficient attention in\nevaluating ML classifiers. To tackle this problem, the prob-\nability of detection (POD) approach can be utilized to assess\nclassifiers' performance [14].\nThe POD approach is frequently employed for evaluating\nthe efficiency of nondestructive testing (NDT) techniques,\nand finds applications in safety-critical domains such as\naerospace and military fields [15], [16], [17]. This approach\nis also attracting attention in other areas where it was less\ncommon before, such as structural health monitoring field\nand nuclear industry [18], [19]. Probability of detection-based\nevaluation results in a curve referred to as the POD curve.\nIn NDT field, the POD curve illustrates the probability of\ndetecting a flaw as a function of its size. This curve can\nbe generated using either binary data indicating whether the\ntarget is detected or not (hit/miss approach), or continuous\ndata providing quantitative assessment of the target (\u00e2 versus\na approach) [17], [20].\nAmeyaw et al. [21] employed the POD approach to assess\nand compare the performance of ML classifiers. As exam-\nples, artificial neural network (ANN), support vector machine\n(SVM), hidden Markov model (HMM), random forest (RF),\nand improved versions of these classifiers used for human\ndriver lane changing behavior (LCB) prediction were chosen\nfor performance assessment. As a common driving behavior,\nlane changing is one of the leading contributors to road\naccidents and its prediction is essential for autonomous ve-\nhicles and advanced driver-assistance systems [22]. Modern\nLCB prediction relies on ML algorithms; however, further\nimprovement in the performance of these algorithms is nec-\nsary to facilitate their widespread application in commer-\ncial products [23]. Ameyaw et al. [21] considered the time\nremaining to the lane changing event as the process parameter.\nThe \u00e2 versus a approach to POD was taken using DR values\ncalculated at each time step as the continuous data needed\nto generate the POD curve. This enabled the comparison and\nillustration of differences between traditional and enhanced\nclassifiers, in a manner distinct from conventional evaluation\nmetrics such as ROC, DR, and ACC.\nIn the previous study [24], a method for further improving\nthe performance of these algorithms was proposed. Multi-\nlevel features extracted from a deep autoencoder were utilized\nto train an ensemble of classifiers of one type whose hyper-"}, {"title": "II. THEORETICAL BACKGROUND", "content": "This section provides a concise overview of the hit/miss approach to POD and the ML classifiers considered in this paper. The hit/miss approach can be employed to conclude the relationship between detection probability and a considered process parameter using binary (hit/miss) response data. To reach this purpose, a linear model is required to describe the correlation between the continuous process parameter and the binary (0 or 1) data. Ordinary linear regression is not suitable for modeling such a correlation, since it assumes that the response data is continuous and has no bounds. Generalized linear models are used to tackle this problem [17]. A generalized linear model with a single process parameter can be written in the form of \n$$g(y) = b_0 + b_1a,$$\nwhere $b_0$ is the intercept, $b_1$ is the slope, $a$ is the process parameter, and $g(y)$ is a function of the binary response, $y$, that can be used to link $a$ to $y$ through the probability of positive response that continuously changes from 0 to 1 [17], [25]. The logistic function is often chosen as the link function, but using the probit function for this purpose is also common. These functions are defined as\n$$g(y) = \\log(\\frac{p}{1-p})$$\nand\n$$g(y) = \\Phi^{-1}(p)$$\nrespectively, where $\\Phi$ is the cumulative standard normal distribution function. Using these functions, the average POD for different process parameter values can be obtained as [26], [27]\n$$POD(a) = \\frac{exp(b_0 + b_1a)}{1 + exp(b_0 + b_1a)}$$\nor\n$$POD(a) = \\phi(b_0 + b_1a).$$\nDepending on the data being modeled, replacing $a$ with $log(a)$ in equations (1), (4), and (5) might be more beneficial (further explanations on choosing between $a$ and $log(a)$ are given in Section III). To take the uncertainties in estimating the parameters of the linear model into account, the likelihood ratio method is utilized to generate the 95 percentile POD curve under which 95% of the average POD curves would fall if the study was conducted many times. Process parameter values for 90% POD on average and with 95% confidence are referred to as $a_{90}$ and $a_{90/95}$ respectively. The $a_{90/95}$ value is frequently used in NDT field to evaluate the effectiveness of defect detection techniques. An example of an average POD curve, its 95 % lower confidence bound, and corresponding $a_{90}$ and $a_{90/95}$ values, together with the related hit/miss points, is shown in Fig. 1.\nAnalyzing hit/miss noise is part of the evaluation process that allows considering the false alarm probability (FAP). This probability with 50 % confidence can be calculated as\n$$FAP = {1 + \\frac{n-x}{x+1}}F(0.5, 2x+2, 2n - 2x)^{-1},$$\nwhere n denotes the number of opportunities for a false alarm, x the number of false alarms, and F(0.5,2x+2,2n-2x) the F- statistics with (2x + 2, 2n \u2013 2x) degrees of freedom and 50 % (0.5) confidence level [25].\nThe described POD approach is used here to evaluate ANN, SVM, HMM, and RF classifiers used for human driver LCB prediction as examples. In contrast to the widely known ANN and SVM models, HMMs are designed to identify dependencies among data points over time and are particularly suited for handling sequential data. Hidden Markov models are statistical frameworks that analyze a series of observable data (here: driving data) emitted by underlying hidden states (here: LCBs). The model subsequently employs inference algorithms to obtain the likelihood of each hidden state at every point along the series of observed data [28]."}, {"title": "III. MODIFIED HIT/MISS APPROACH TO POD", "content": "The methodology for modifying the hit/miss approach to POD to evaluate ML classifiers is explained in this section. This includes taking the probability of hit/miss data obtained from ML algorithms for different process parameter values into account for performance evaluation. The suggested methodology is illustrated in Fig. 2. First, test data corresponding to various process parameter values are fed into a pre-trained ML model. For instance, in the LCB prediction task, where the process parameter is the time remaining until the lane changing event, the trained classifier is provided with driving data recorded over time. It is assumed that the probability of the classifier detecting the target for a given process parameter value is determined based on the results of 10 separate experiments conducted with that specific process parameter value. The number of experiments that result in target detection (n) is calculated by multiplying this probability (P) by 10 and rounding the result\n$$n = round(10P).$$\nTherefore, considering each process parameter value, n experiments out of 10 lead to target detection (hit/1), and the rest fail to detect the target (miss/0)."}, {"title": "IV. MACHINE LEARNING CLASSIFIERS", "content": "Machine learning classifiers considered for performance evaluation in this study include ANNs, SVMs, HMMs, and RFs developed previously for human driver LCB prediction. The methodology for LCB prediction using these classifiers, and employing the \u00e2 versus a approach to POD to assess them is thoroughly described in [24] and is repeated here briefly.\nIn the first step of the proposed methodology, the features required as inputs to ML models were extracted using a deep autoencoder. Driving data regarding the status of the considered vehicle and its surrounding vehicles were used to train the autoencoder. After training, the encoder part of the network, including 4 hidden layers with 24, 16, 8, and 4 neurons, was utilized to extract multi-level features from the data, which were then fed to ML classifiers.\nThree classes of LCB were considered: lane changing to left (LCL), lane changing to right (LCR), and lane keeping. Features from each encoder layer were utilized to train two binary classifiers of each type, where each classifier regarded either LCL or LCR as the positive class and remaining two classes as negative. This process was done considering features from 4 encoder layers, 4 classifier types, and two binary classifiers of each type, resulting in a total of 32 trained models. The hyperparameters of all ML models were optimized"}, {"title": "V. APPLICATION AND RESULTS", "content": "The modified and standard hit/miss approaches to POD are used to evaluate the classifiers trained in [24]. Data obtained from the SCANER\u2122\u2122 studio driving simulator shown in Fig. 4 was utilized for this purpose. The simulator uses virtual sensors such as cameras, radar, and lasers to collect data, providing a comprehensive understanding of the vehicle's environment. The simulated driving environment consists of a highway with two lanes in each direction. Three drivers, aged 25 to 38 and holding valid driver's licenses, were re- recruited to collect the required data. Each participant drove for approximately 40 minutes to obtain the training dataset, with an additional 10 minutes of driving data recorded for the test phase. During the simulation, drivers were permitted to overtake slower vehicles and return to their original lane [29]. The vehicle's lane was determined by the position of its center point, and lane changes were identified by shifts in this position. A lane changing event began with the last significant steering wheel adjustment, and the period from this adjust- ment to the lane shift was defined as the lane changing interval [8]. The driving environment and lane changing/keeping behaviors are depicted in Fig. 5.\nTraining and test dataset samples, recorded every 0.05 s, comprised 26 variables including the velocity of the con- sidered ego vehicle and surrounding vehicles, distances to surrounding vehicles, time to collision, lane number, turn signal status, gear engaged, steering wheel angle, heading angle, accelerator position, and brake pressure of the ego vehicle [29]. The test dataset is utilized here for classifiers' performance evaluation. Categorical variables with no inherent order are one-hot-encoded. The data are then normalized between 0 and 1, and fed to the trained autoencoder [24] for multi-level feature extraction.\nFeatures from each encoder layer are input to the 8 related trained classifiers (2 binary ANNs, SVMs, HMMs, and RFs), and the probability that each data sample belongs to the positive class (LCL/LCR class) is extracted from the ML models. The time frames from 7 s before the lane change to the moment of the event are considered, and the average of the extracted probabilities at each time point within this 7-second span is computed. To apply the modified hit/miss approach, it is assumed that the average probability is the result of 10 separate experiments, as explained in Section III. The standard hit/miss approach can also be applied, defining a hit (1) as an average probability greater than 50%, and a miss (0) as an average probability of 50 % or less. Examples of POD curves obtained from the standard hit/miss approach for the ANN and the SVM trained on features from the first encoder layer to predict LCL using test data from the first driver are shown in Fig. 6. In this figure, $a_{90/95} = -1.89$ and $a_{90/95} = -0.692$ mean the algorithms can reliably predict LCBs 1.89 s and 0.692 s before the event respectively. Clearly, the earlier the algorithm predicts the LCB, the better its performance.\nThe $a_{90/95}$ values obtained using the standard and the modified hit/miss approaches to evaluate ANNs and SVMs trained on different encoder layers to predict LCL/LCR, when tested on data from each driver separately, are presented in Tables 1 and 2. The results from the \u00e2 versus a approach to POD from the previous study [24] are also included in the table, along with the differences between the $a_{90/95}$ values from the \u00e2 versus a approach and the two other approaches, to facilitate comparison between these methods. According to these tables, $a_{90/95}$ results from the modified hit/miss approach are generally smaller than those from the standard version. Additionally, they are closer to \u00e2 versus a approach results (exceptions are highlighted in red). This outcome is expected, as the \u00e2 versus a approach used probabilities of predicting LCBs at different time points as response values in its evaluation; by modifying the hit/miss approach to consider these probabilities instead of simple 0/1 values, the final result is anticipated to align more closely with the result from the \u00e2 versus a approach. Similar outcomes were obtained for HMMs and RFs, but they are not included here for the sake of brevity.\nLike in the previous study, the winner-take-all ensemble strategy is applied to performance evaluation results from ML models of the same type having the same task. The final results for each classifier type, when tested on data from each driver and evaluated using the three POD approaches, along with the corresponding encoder layers are detailed in Tables 3 and 4. False alarm probabilities calculated using equation 6, considering encoder layers related to the modified hit/miss approach, are also included in the tables. It can be seen that, in general, the best encoder layers according to the \u00e2 versus a approach are more similar to those identified by the modified hit/miss approach than to those identified by the standard hit/miss approach (18 out of 24 similar cases versus 9 out of 24). Therefore, the modified hit/miss approach is more reliable when deciding about the most suitable set of features for ML classifiers. Furthermore, the best $a_{90/95}$ values for each driver are shown in green in Tables 3 and 4. According to all three approaches, ANNs are the most reliable algorithms for LCB prediction.\nOverall, the results show that modifying the hit/miss approach brings its outcomes closer to those from the \u00e2 versus a approach. These results are more reliable than those based solely on 0/1 values when determining the suitable set of features for the considered ML classifiers and assessing the algorithms' reliability in predicting upcoming LCBs early enough. Therefore, this modification allows the hit/miss approach to be used for evaluating ML classifiers in a more reliable way, while remaining simpler than the \u00e2 versus a approach."}, {"title": "VI. CONCLUSION", "content": "This paper proposes POD-based performance evaluation of ML classifiers using a modified hit/miss approach. Unlike common performance evaluation metrics typically used for assessing ML algorithms, the POD-based approach considers the effects of process parameters in evaluation, offering new insights into the reliability of ML algorithms. The hit/miss approach to POD is modified here by incorporating the probability of target detection derived from ML algorithms for various process parameter values and obtaining the final result of the analysis accordingly. This enhances the reliability of the results compared to the standard hit/miss approach, which considers classifier outcomes as either 0 or 1, as in reality, these outcomes are probabilistic rather than absolute.\nAs an example, the POD-based approach is used to evaluate ML models trained on multi-level features from a deep autoencoder for predicting drivers' LCB using data from a driving simulator. The time until the predicted (and unknown) lane changing event is taken as the process parameter, and the classifiers' ability to predict the intended driver behavior is assessed relative to the time remaining before the event.\nPerformance evaluation results from the proposed modified hit/miss approach are compared to those from the standard hit/miss approach and the \u00e2 versus a approach to POD. Modifying the hit/miss approach makes its outcomes more similar to those from the \u00e2 versus a approach. These results are more reliable than those based solely on 0/1 values when selecting appropriate features and evaluating the algorithms' effectiveness in predicting upcoming LCBs early. The hit/miss approach is more straightforward than the \u00e2 versus a approach to POD; this modification enhances its reliability while maintaining its simplicity."}]}