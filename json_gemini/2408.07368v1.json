{"title": "The Complexity of Manipulation of k-Coalitional Games on Graphs", "authors": ["Hodaya Barr", "Yohai Trabelsi", "Sarit Kraus", "Liam Roditty", "Noam Hazon"], "abstract": "In many settings, there is an organizer who would like to divide a set of agents into k coalitions, and cares about the friendships within each coalition. Specifically, the organizer might want to maximize utilitarian social welfare, maximize egalitarian social welfare, or simply guarantee that every agent will have at least one friend within his coalition. However, in many situations, the organizer is not familiar with the friendship connections, and he needs to obtain them from the agents. In this setting, a manipulative agent may falsely report friendship connections in order to increase his utility. In this paper, we analyze the complexity of finding manipulation in such k-coalitional games on graphs. We also introduce a new type of manipulation, socially-aware manipulation, in which the manipulator would like to increase his utility without decreasing the social welfare. We then study the complexity of finding socially-aware manipulation in our setting. Finally, we examine the frequency of socially-aware manipulation and the running time of our algorithms via simulation results.", "sections": [{"title": "1 Introduction", "content": "In many situations, there is an organizer who would like to divide a group of agents into k non-empty coalitions. For example, consider a manager who would like to divide his employees into k teams in order to execute k tasks. The interpersonal friendship connections between potential team members play an important role in such a setting. Indeed, different managers may treat friendship differently. One manager may be interested in maximizing the number of friendship connections within all of the coalitions. Another manager may consider the welfare of an employee who is worse off than the others, and thus be interested in maximizing the minimum number of friendship connections that this employee has within his coalition. It is also possible that a manager would simply require that every employee have at least one friend within his coalition.\nThe organizer may be familiar with all of the friendships among the agents. However, in some real-world scenarios, the organizer is unfamiliar with the friendships and thus needs to elicit them from the agents. For example, when dividing students into classes, it is common practice to ask them about their social relationships [1]. In such situations, a manipulative agent, who is familiar with all the friendships among the agents, might have an incentive to misreport his friendship connections. Indeed, it is possible that such manipulation cannot be found efficiently.\nIn this paper, we analyze the complexity of finding manipulation in k-coalitional games 6, with fixed k. We assume that the agents' utilities depend on the friendship connections. Specifically, the friendship connections are represented by an unweighted graph, where the vertices are agents, and the edges represent the friendships among the agents. The utility of an agent is the number of friends he has within his coalition. There is an organizer who would like to divide the agents into exactly k coalitions, but he builds the graph from the agents' reports. We analyze the settings where one manipulative agent would like to misreport his friendship connections by hiding some or reporting fake connections.\nWe study the objective of maximizing the egalitarian social welfare (Max-Egal), and show that finding an optimal manipulation is computationally hard. Moreover, even deciding if a given report is beneficial for the manipulator is a hard problem. We then study a less demanding objective, in which the organizer requires that every agent has at least one friend within his coalition (At-Least-1). Indeed, finding an optimal manipulation or deciding if a given report is beneficial are still computationally hard problems. Arguably, the most natural organizer's objective is to maximize the utilitarian social welfare (Max-Util), and deciding if a given report is beneficial in this setting can be done efficiently. The complexity of finding an optimal manipulation with Max-Util remains open, but we provide an XP algorithm for this problem.\nIn addition, we introduce a new type of manipulation for coalitional games, socially-aware manipulation (SAM), in which the manipulator would like to increase his utility without decreasing the social welfare. This manipulation models social situations in which a manipulator interested in his own welfare will not want to harm the welfare of society. For example, consider an employee in a company or a player in a sports team. In these settings, the manipulator would like to maximize his utility without decreasing the social welfare, since it reduces the overall productivity or the teams' performance. Before analyzing the complexity of finding an SAM, we show that for every objective (Max-Util, Max-Egal, and At-Least-1), there are scenarios in which SAM is possible. We then show that finding an optimal SAM or deciding if a given report is an SAM are still compu-"}, {"title": "2 Preliminaries", "content": "Let $G = (A, E)$ be a directed graph representing a social network, where the vertex set $A$ represents a set of agents and the edge set $E$ represents friendship connections between the agents. The graph is directed since friendship connections are not necessarily symmetric, and an edge $(a, a') \\in E$ represents that $a$ considers $a'$ as his friend. We denote by $E(a)$ the set of edges from $a$, and the set of neighbors of $a \\in A$ by $N(a) = \\{a' \\in A|(a, a') \\in E(a)\\}$. For a subset $S \\subseteq A$, we denote the set of neighbors of $a$ from the subset $S$ by $N(a, S) = N(a) \\cap S$. In our setting, there is an organizer who would like to divide the agents into exactly $k$ coalitions. Formally, the organizer seeks a partition $P$ of $G$, which is a partition of the set $A$ into $k$ disjoint and non-empty sets $C_1, C_2,..., C_k$; we refer to these sets as coalitions. Since $k$ is small in many settings, we further assume that $k$ is fixed. Let $I_k$ be the set of all partitions of size $k$. We denote by $u(a, P)$ the number of friends that agent $a$ has within his coalition in partition $P$, i.e, if $a \\in C_i$ then $u(a, P)$ is $|N(a, C_i)|$. When the organizer partitions the agents into coalitions, he may want to maximize a certain objective. In this paper, we examine three types of objectives:\nDefinition 1 (Max-Egal). The organizer wants to find a partition $P^*$ that maximizes the minimum number of connections that an agent has within his coalition. That is, $P^* = \\arg \\max_{P\\in \\Pi_k} \\min_{a\\in A} u(a, P)$.\nDefinition 2 (At-Least-1). The organizer wants to find a partition $P^*$ such that every agent has at least one connection within his coalition. That is, $P^*$ such that $\\forall a\\in A \\quad u(a, P^*) > 0$.\nDefinition 3 (Max-Util). The organizer wants to find a partition $P^*$ that maximizes the total number of connections within the same coalition. That is, $P^* = \\arg \\max_{P\\in \\Pi_k} \\sum_{a\\in A} u(a, P)$.\nLet $O_{obj}(G)$ be the set of all partitions that sat- isfy the objective of the organizer. For $a \\in A$, let $LB_{obj}(G, a) = \\min_{P\\in O_{obj}(G)} u(a, P)$, and let $UB_{obj}(G, a) = \\max_{P\\in O_{obj}(G)} u(a, P)$. That is, $LB_{obj}(G, a)$ and $UB_{obj}(G, a)$ are lower and upper bounds (respectively) on the number of friends that an agent $a$ can have in a partition satisfying the objective obj.\nNote that when the objective of the organizer is At-Least-1 it is possible that there is no feasible partition in $G$, i.e., $O_{At-Least-1}(G) = \\emptyset$. In such a case, we define the utility of all the agents to be 0.\nEach agent $a \\in A$ reports to the organizer a set of friendship con- nections, $E_R(a)$, which is not necessarily equal to $E(a)$. That is, the organizer learns about the graph structure solely from the reports of the agents, and if all of the agents are truthful then this graph is equal to $G$. 7 A manipulator agent $m \\in A$ reports a set of friendship connections $E_R(m) \\neq E(m)$, so that the organizer will choose a partition that is better for $m$ than the partition that would have been chosen with $m$'s truthful report. In this case, we refer to $E_R(m)$ as the manipulation of $m$. We assume that there is a single manipulator,"}, {"title": "3 Background", "content": "Our setting, in which the utility of an agent is the number of neigh- bors that he has within his coalition to which he is assigned [22], is a special case of Additively Separable Hedonic Games (ASHGs), which have been extensively studied [8, 15, 2, 3]. However, very few papers consider the problem of manipulation in ASHGs. In- deed, Dimitrov and Sung [10] analyzed ASHGs where agents have both positive and negative edges, and provided a strategyproof algo- rithm for finding stable outcomes. Rodr\u00edguez-\u00c1lvarez [21] discussed strategyproof core stable solutions' properties. They proved that sin- gle lapping rules are necessary and sufficient for the existence of a unique core-stable partition. Aziz et al. [4] proved that, with appro- priate restrictions over the agents' preferences, the serial dictatorship mechanism is strategyproof. Flammini et al. [12] studied the utilitar- ian social welfare in ASHGs and fractional hedonic games, and they proposed strategyproof mechanisms at the cost of non-optimal social welfare. They extended their analysis to friends and enemies games in a subsequent work [13]. Wright and Vorobeychik [24] considered a model of ASHG that is very similar to ours, but they restricted the size of each coalition instead of restricting the number of coali- tions. In their work, they proposed a strategyproof mechanism that achieves good and fair experimental performance, but with no the- oretical guarantee. All of these works focused on developing strate- gyproof mechanisms, while we study the computational complexity of finding manipulation.\nThe work that is closest to ours is by Waxman et al. [23]. They provided an extensive set of results specifying for each objective whether or not it is susceptible to manipulation. Specifically, they show that Max-Egal is susceptible to SIM by removing edges (and thus, obviously, it is also susceptible to LBM, UBM, and WIM),"}, {"title": "4 The Complexity of the Manipulation and the Improvement Problems", "content": "We begin with the Max-Egal objective. Recall that manipulation is possible only by removing edges. Indeed, finding any type of optimal manipulation is computationally hard. Moreover, we show that even deciding whether a SIM exists for a given instance is computationally hard.\nTheorem 1. Given a graph G, and a manipulator $m^- \\in A$, de- ciding whether any type of manipulation exists when the objective is Max-Egal is co-NP-hard.\nThe reduction is from the complementary problem of the NP- complete 3-SAT problem.\nDefinition 12 (3-SAT problem). Let F be a Boolean CNF formula, such that each clause has three literals. We are asked whether there exists a truth assignment that satisfies F.\nOur gadget for the hardness proof is a ring graph, which represents a CNF Boolean formula, as was introduced by [7].\nTheorem 2. Given a graph G, a manipulator $m^- \\in A$, a manipulation type type, and a report $E_R(m)$, deciding whether $I_{type}(E_R(m)) > 0$, when the objective is Max-Egal is co-NP-hard.\nThe At-Least-1 objective is less demanding than the Max-Egal ob- jective. In addition, it is susceptible only to LBM by removing edges. However, finding an optimal LBM is computationally hard.\nTheorem 3. Unless P = NP, there is no polynomial time algorithm for finding an optimal LBM for a manipulator m when the objective is At-Least-1.\nThe reduction is from a variant of the 3-SAT problem, in which each variable appears in at most 3 clauses, each literal appears in at most 2 clauses, and each clause has 2 or 3 literals. The improvement problem is also computationally hard.\nTheorem 4. Given a graph G, a manipulator $m^- \\in A$, and a report $E_R(m)$, deciding whether $I_{LBM}(E_R(m)) > 0$ when the objective is At-Least-1 is NP-hard.\nThe reduction is from the same variant of 3-SAT that is used in the proof of Theorem 3.\nThe Max-Util objective is susceptible to all types of manipulations, with either $m^+$ or $m^-$. For the analysis of the Max-Util objective, we use the following definitions.\nGiven a directed graph $G = (A, E)$, we can naively convert G to a weighted undirected graph $G_U = (A, E_U)$ by creating an edge $(u, v)$ whenever either $(u, v)$ or $(v, u)$ exists in G. If both $(u, v)$ and $(v, u)$ exist in G, then the edge weight is set to 2. Otherwise, the edge weight is set to 1. Given an undirected graph $G_U = (A, E_U)$, a set of edges $Y\\subseteq E_U$ is a k-cut of $G_U$ if $G' = (A, E_U \\setminus Y)$ is a graph that contains at least k connected components. We refer to 2-cut simply as cut. A k-cut $Y^*$ is a min-k-cut if $\\sum_{y\\in Y^*} w(y)$ is minimal amongst all possible k-cuts of $G_U$. We denote $Y^*$ by min-k-cut(G). Note that any partition has a corresponding k-cut, and a Max-Util partition of G has a corresponding min-k-cut in $G_U$. For simplicity, we will refer to the cuts in $G_U$ as cuts of G.\nUnlike with the Max-Egal and At-Least-1 objectives, we show a polynomial time algorithm for solving the improvement problem with the Max-Util objective.\nTheorem 5. The improvement problem can be solved in polynomial time when the objective is Max-Util, with any type of manipulator, and any manipulation type.\nAs a consequence, given two reports, $E_f (m)$ and $E_r(m)$, we can decide whether $E_f(m)$ is better than $E_r(m)$ in polynomial time."}, {"title": "5 Socially-aware Manipulation", "content": "We now introduce a new type of manipulation, which we call Socially-aware Manipulation (SAM). In SAM, the manipulator m would like to increase his utility without decreasing the social wel- fare. That is, $O_{obj}(G(m)) \\subseteq O_{obj}(G)$, and thus SAM is necessarily an LBM.\nDefinition 15 (Socially-Aware Manipulation (SAM)). A manip- ulation $E_R(m)$ is SAM if $O_{obj}(G(m)) \\subseteq O_{obj}(G)$ and $LB_{obj}(G(m), m) > LB_{obj}(G, m)$.\nNote that term SAM may remind the concept of Pareto optimality. However, in SAM, the manipulator aims to increase his utility with- out decreasing the social welfare. That is, the manipulator would not want to harm the organizer's objective, but his manipulation may de- crease the utility of one of the agents, unlike the notion of Parteo optimality.\n5.1 The Existence of SAM\nBefore analyzing the complexity of finding an SAM, we establish the existence of SAM.\nTheorem 9. The susceptibility of SAM is equivalent to the suscepti- bility of LBM. Specifically, Max-Util is susceptible to SAM by adding or removing edges, but Max-Egal and At-Least-1 are susceptible to SAM only by removing edges.\nNote that the equivalence between the susceptibility of SAM and LBM (as shown in Theorem 9) means that any setting (i.e., objective and type of manipulator) that is susceptible to LBM is also suscepti- ble to SAM.\n5.2 The Complexity of the Manipulation and Improvement Problems for SAM\nWe begin with the Max-Egal objective. Similar to LBM, deciding whether an SAM exists (and thus also finding an optimal SAM) is computationally hard.\nTheorem 10. Given a graph G, and a manipulator $m^- \\in A$, decid- ing whether an SAM exists when the objective is Max-Egal is co-NP- hard.\nThe improvement problem is also hard.\nTheorem 11. Given a graph G, a manipulator $m^- \\in A$, and a report $E_R(m)$, deciding whether $I_{SAM}(E_R(m)) > 0$ when the ob- jective is Max-Egal is co-NP-hard.\nWith the At-Least-1 objective, we show that every LBM is also an SAM, and thus the manipulation and improvement problems for SAM are computationally hard.\nTheorem 12. For At-Least-1, every LBM by removing edges is also SAM by removing edges.\nTheorem 13. The improvement problem for SAM can be solved in polynomial time when the objective is Max-Util.\nInterestingly, the manipulation problem for SAM with the Max- Util objective can also be solved in polynomial time. Indeed, we only need to change line 1 in Algorithm 2, so that $P \\leftarrow Max-Util(G)$. To prove the correctness, we first show an essential property of every report that respects a Max-Util partition.\nLemma 14. If ER(m) is a report that respects $P\\in O_{Max-Util(G)}$ then $O_{Max-Util(G(m))} \\subseteq Max-Util(G)$.\nProof. Let $P\\in O_{Max-Util(G)}$, and let ER(m) be the report that re- spects P. Let Y be the min-k-cut that corresponds to P in G. Given $P' \\notin O_{Max-Util(G)}$ let Y' be its corresponding k-cut in G. Since Y is a min-k-cut and Y' is not a min-k-cut, we have that $|Y| < |Y'|$. Let $Y_1$ be the k-cut that corresponds to P in G(m) and $Y'_1$ be the k-cut that corresponds to P' in G(m).\nTheorem 16. Algorithm 2, in which line 1 is $P\\leftarrow O_{Max-Util(G)}$, solves the manipulation problem for SAM with the Max-Util objective in time $O(n^{2(2k-1)})$."}, {"title": "6 Experiments", "content": "In order to examine the frequency of SAM and the effectiveness of our XP algorithm with the Max-Util objective, we ran some simula- tions 8 on graphs that are based on the Twitter followers dataset [19]. Since it was too large, we sampled 150 subgraphs of the network. Specifically, we sampled subgraphs of sizes 5, 10, 15, 20, and 25. For each graph size, we first sampled at least 9 graphs: we randomly chose a vertex and ran BFS where in each iteration we added only 2 of the neighbors to the queue. The search was terminated when it reached the desired graph size. In order to vary the number of edges we repeated this process once when we added 4 neighbors to the queue, and then when we added 6 neighbors. If we did not reach the desired graph size, we sampled again an initial vertex (up to 100 times).\nWe set k = 2 and $m = m^+$. Note that we concentrated on manip- ulation by adding edges, since it was quite common; e.g., we found an LBM in around a third of the instances. In contrast, manipula- tion by removing edges was much less common (e.g., we found an LBM in 0.5% of the instances). We also concentrated on the Max- Util objective, since we do not have efficient algorithms for finding manipulations with Max-Egal and At-Least-1. For each graph, we considered every vertex that has the potential to be a manipulator. Specifically, we computed all the min-cuts, and considered only the vertices that have an edge in a min-cut as potential manipulators. Overall, we had 368 instances. For each instance, we ran our XP al- gorithm (that finds LBM, UBM, WIM, and SIM) and the algorithm that finds an SAM. We also ran a brute-force algorithm, which iter- ates over all subsets of edges that the manipulator can possibly add. We set a timeout of one hour and terminated each algorithm that did not finish till the timeout.\nFrequency of SAM. For each graph size, we compared the number of instances in which we found an LBM with the number of instances in which we found an SAM. Overall, our results indicate that SAM is quite frequent. Specifically, when the graph size was 5, 10, 15, 20, or 25, the percentage of instances in which there was an SAM out of the instances in which there was an LBM was 90%, 68%, 50%, 67%, and 64%, respectively.\nEffectiveness of the XP algorithm. As expected, the algorithm that finds SAM was very effective: in all of the instances, it finished in less than a second. With a graph size of 5, the XP and the brute force algorithms also finished in less than a second. The results with the other graph sizes are depicted in Figure 5. Note that we consid- ered only instances in which both algorithms finished their run till the timeout. The average running time of the brute force algorithm sig- nificantly increased as the graph size increased. On the other hand, the XP algorithm was very effective when we increased the graph size. Note that the average running time of the XP with a graph size of 25 was lower than with graph sizes of 20 or 15, due to the time- outs: with a graph size of 25, the brute force algorithm timed out in 86% of the instances, and thus there were fewer instances in which we tested the algorithms. Indeed, if we do not remove the instances in which the brute force algorithm timed out, the average running time of the XP algorithm becomes 176 seconds. Overall, the brute force algorithm timed out on 0%, 49%, and 86% of the instances with graph sizes of 15, 20, and 25, respectively. In comparison, the XP algorithm timeout on just 6%, 8%, and 20% of the instances with the corresponding graph sizes.\nAs the brute force timed out on 86% of the instances with graph sizes 25, we run only the XP algorithm on sampled subgraphs of size 30-100, that were sampled in same way as above. We observe an increasing trend in the frequency of timeouts, but in a relatively slow rate, see Figure 6."}, {"title": "7 Conclusions and Future Work", "content": "In this paper, we initiate the study on the complexity of finding ma- nipulation in k-coalitional games. We also introduce a new type of manipulation, the socially-aware manipulation. We showed that both the manipulation and improvement problems are computationally hard with Max-Egal and At-Least-1, even for SAM. With Max-Util, we provide a general algorithm that finds an optimal manipulation. The algorithm is XP for LBM, UBM, WIM, and SIM, and it runs in polynomial time for SAM. Our experiments show that SAM is quite frequent, and demonstrate the effectiveness of our algorithm.\nThe main problem that is still open is classifying the complexity of the manipulation problem for LBM, UBM, WIM, and SIM with Max-Util. In addition, we showed that the manipulation problem for SAM with Max-Util can be solved efficiently when k is fixed. If k is a parameter, our polynomial-time result becomes an XP-membership result, which naturally leads to the question of whether one can do better (i.e., provide an FPT result). Finally, it will be interesting to extend our model to the case of multiple manipulators."}, {"title": "A Omitted Proofs", "content": "A.1 Proof of Theorem 1\nReminder of Theorem 1. Given a graph G, and a manipulator $m\\in A$, deciding whether any type of manipulation exists when the objective is Max-Egal is co-NP-hard.\nAs mention in the paper, for the reduction, we use the complemen- tary problem of the NP-complete 3-SAT problem. And our gadget for the hardness proof is a ring graph, which represents a CNF Boolean formula. It was introduced by [7].\nProof. Given a formula $F$, we construct a graph $G = (A, E)$ with a manipulator $m^-$.\nThe construction of G: We start by adding a ring graph to G based on $F$, where $T$ represents the set of ring vertices. For each $t\\in T$, we add to G a clique of 9 vertices, denoted as $Q_t$. Each vertex $t \\in T$ has the following outgoing edges:\nIn addition to the previous construction, we add a vertex $c_i$ for each clause $C_i \\in F$, which we refer to as clause vertices. If $x_j \\in C_i$ we add an outgoing edge from $c_i$ to one of the occurrences of $x_j$ in the positive path between $s_j$ and $s_{j+1}$, and another edge to one vertex in the corresponding clique of $x_j$. If $\\overline{x}_j \\in C_i$, we add an outgoing edge from $c_i$ to one of the occurrences of $\\overline{x}_j$ in the negative path between $s_j$ and $s_{j+1}$ (see Figure 3b for an illustration). Note that each literal vertex on the ring has only one incoming edge from a clause vertex.\nWe also add an additional clique with 9 vertices, denoted as $Q_r$. Each vertex $c_i$ corresponding to clause $C_i$, has 6 outgoing edges to vertices of $Q_r$. Let $G'$ be the subgraph of $G$ containing all the ver- tices and edges defined up to this point. To complete the construction, we add to G a clique with 9 vertices, denoted as $Q_m$. Additionally, we add one more vertex, $m$, which is defined as the manipulator. $m$ has 7 outgoing edges to vertices of $Q_m$. We also connect $m$ to one vertex of $Q_r$ with an outgoing edge. See Figure 7 for illustration of the structure of $G$ for $F = (x_1 \\vee x_2) \\wedge (\\overline{x_1} \\vee \\overline{x_2})$.\nProperties of partitions of G'. First, we show that the graph G' has a partition to two coalitions, such that each vertex has at least 8 neighbors if F is satisfiable. Conversely, if F is not satisfiable then every partition of G' has at least one vertex that gets only 6 neighbors in his coalition.\nHence, if F is satisfiable it is possible to achieve a minimum degree of 8 or more in the partition of G', otherwise, F is not satisfiable and the maximum that can be achieved is 6 in any partition of G'.\nAdding it all together. Based on this, we will prove that if Fis satisfiable, then there is no manipulation. Conversely, if F is unsat- isfiable then there is manipulation.\nFirst, we show that if there is a satisfying truth assignment of F then there is no manipulation. This is because there exists a parti- tion of G where each vertex has at least 8 neighbors (the maximum possible since some vertices have exactly 8 friends), the manipulator has only 8 neighbors and hence in such a partition, it is necessary that m gets all of his neighbors in his coalition. The organizer can partition G into two coalitions using as follows: The first coalition includes all the vertices in the cycle that corresponds to $\\tau$ as well as all clauses vertices $c_i$. It also includes the clique $Q_m$ and the ma- nipulator. The second coalition includes all the vertices in the cycle\nIf there is a satisfying truth assignment of F then there is no manipulation... conversely, if F is not satisfiable then there is manipulation. we get that, LB(G($m^-$), $m^-$) = 8 > UB(G, $m^-$) = 7, hence, there is a SIM (which is also LBM, UBM, and WIM).\nA.2 Proof of Theorem 2\nReminder of Theorem 2. Given a graph G, a manipulator $m^- \\in A$, a manipulation type type, and a report $E_R(m^-)$, deciding whether $I_{type}(E_R(m^-)) > 0$ when the objective is Max-Egal is co-NP-hard.\nProof. The reduction is from the complementary problem of 3-SAT. Given a Boolean CNF formula F, we construct the same graph struc- ture as in the proof of Theorem 1. In addition, we set $E_R(m^-)$ to be the report in which $m^-$ removes two edges to vertices in $Q_m$. Fol- lowing the same claims as in the proof of Theorem 1, we get that F is unsatisfiable if and only if $I_{type}(E_R(m^-)) > 0$.\nA.3 Proof of Theorem 3\nReminder of Theorem 3. Unless P = NP, there is no polynomial time algorithm for finding an optimal LBM for a manipulator $m^-$ when the objective is At-Least-1.\nFor the proof, we need the following lemma:\nLemma 17. Each coalition C in an At-Least-1 partition contains at least one directed cycle. In addition, every vertex in C that is not part of a directed cycle in C, is part of a directed path that ends at a directed cycle in C.\nProof. Assume by contradiction that there is a coalition in an At- Least-1 partition without any directed cycle. Start with an arbitrary vertex, v, and consider the longest directed path, p, which is started in v. Denote by u the last vertex of p. u has no outgoing edge to a vertex in the coalition, but not in p. Otherwise, p is not the longest path. In addition, u cannot have an outgoing edge to a vertex in p. Otherwise, there would be a directed cycle in the coalition. Therefore, u has no neighbors in the coalition, in contradiction to the assumption that this is a coalition in an At-Least-1 partition.\nWe can now prove Theorem 3. As in the proof of Theorem 1, our gadget for the hardness proof is a ring graph [7], which represents a CNF Boolean formula.\nA.5 Equivalents to Lemma 7\nLemma 7 is proved for LBM by a manipulator $m^-$. Here we show equivalent lemmas, for LBM by $m^+$ and for WIM by $m^-$.\nB An Improved Algorithm for Manipulation By Removing Edges with Max-Util\nIn the paper we presented Algorithm 2, which is a general XP algo- rithm for finding any type of optimal manipulation, with any type of manipulator. Here we present Algorithm 3, which is suitable only for m, and it slightly improves the running time of Algorithm 2.\nThe correctness of the algorithm is straightforward, since m should remove only edges that are part of a k-cut that m wants that the organizer will choose. In addition m can remove edges only from the wanted k-cut in order to achieve a manipulation. Hence he should not remove more edges then he loses in the partition of G. For each such manipulation we check the improvement and return the opti- mal manipulation (if exist). As for the running time, note that the number of edges that m loss in the partition of G is bounded by the cost of the min-k-cut, hence in this case, it gets better complexity to check each possible manipulation. i.e., set of edges $E_R(m^-)$ of size at most $N(m^-) - LB(G, m^-) - 1$, for each such set it checks if E' is better than manip, and thus it needs to iterate over all the min-k-cuts of G(m^-). Computing all the min-k-cut takes at most O($n^{2k}$) [14]. Overall, the running time is O($n^{\\frac{1}{2} maxSize+2k}$)), and maxSize = 2mim-k-cut.\nC The Complexity of the Manipulation and the Improvement Problems in Undirected Graphs\nC.1 Definitions\nWhen the organizer decides to build an undirected graph, he needs to choose a policy of how to handle inconsistencies, i.e., if $(b, a) \\in E_R(b)$ but $(a, b) \\notin E_R(a)$. Clearly, there are two possible options:"}]}