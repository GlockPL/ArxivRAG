{"title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "authors": ["Mayur Amarnath Palavalli", "Mark Santolucito"], "abstract": "Code generation with Large Language Models (LLMs) has helped to increase software developer productivity in coding tasks, but has yet to have significant impact on the tasks of software developers that surround this code. In particular, the challenge of infrastructure management remains an open question. We investigate the ability of an LLM agent to construct infrastructure using the Infrastructure as Code (IaC) paradigm. We particularly investigate the use of a feedback loop that returns errors and warnings on the generated IaC to allow the LLM agent to improve the code. We find that, for each iteration of the loop, its effectiveness decreases exponentially until it plateaus at a certain point and becomes ineffective.", "sections": [{"title": "1 Introduction", "content": "Infrastructure as Code (IaC) has fundamentally transformed the way cloud infrastructure is managed. With IaC, developers can provision and maintain their infrastructure through code. This ensures automation and consistency in deploying infrastructure, allowing for more effective scaling of operations. IaC also allows teams to use version control on their infrastructure, making it easier to collaborate and track changes [13]. However, a major challenge with IaC is in the difficulty of writing correct code [10, 12, 15, 16, 18].\nAt the same time, Large Language Models (LLMs), as applied to code generation, are enabling developers to be more effective. Code generation benchmarks, such as HumanEval [11] and SWEBench [14], have shown that LLMs are capable of assisting developers with challenging programming tasks. It is then natural to seek to extend the application of LLMs for code generation to IaC."}, {"title": "2 Related Work", "content": "The application of LLMs in generating IaC has amassed significant attention in recent years. Using LLMs for IaC comes with certain challenges that make it inefficient in large systems. Srivatsa et al. evaluate the LLM performance on functional correctness by comparing with human-written code and deciding whether or not it is an exact match. They found that the GPT-3.5-turbo model had a success rate of between 50 and 60 percent, while the Codeparrot model never exceeded 10 percent accuracy [19]. They also discuss ethical and safety concerns of developing LLMs for more accurate IaC generation.\nA natural extension is the work of Ugare et al. who introduce Syn- Code [21], a framework that uses grammar rules to enhance LLM generation in formal coding languages. SynCode is able to reduce 96.07 percent of syntax errors in Python and Go. It particularly shines in generating JSON, where it is able to eliminate all syntax errors. This is achieved by utilizing context-free grammar rules based on discrete finite automation.\nAn important area of investigation related to LLM code gener- ation is constrained decoding [7, 17]. At a high level, grammar constrained decoding (GCD) helps language models (LLMs) in pro- ducing structured results without requiring additional fine tuning. GCD utilizes grammars to guarantee that the generated sequences follow a predefined structure. The technique greatly improves the"}, {"title": "3 Background", "content": "IaC is a diverse space with many existing languages and tools. The most widely adopted tools are Terraform [5] and Amazon Web Service's CloudFormation [9]. Both Terraform and CloudFormation files are specified as JSON (or YAML) documents, where the various fields define properties of the cloud resource to be deployed. These files are generally declarative - giving a specification of the desired cloud infrastructure state. This is in contrast to some other IaC languages, such as Pulumi, which allow users to write imperative programs that construct operations that should take place upon the user's infrastructure [1]. An example of a CloudFormation JSON is given in Fig. 1.\nIn this work, we focus solely on the LLM generation of AWS Cloud- Formation [9] in JSON. We additionally use the AWS CloudFor- mation linter cfn-lint [4]. cfn-lint allows us to validate Cloud- Formation JSON templates against the resource provider schemas provided by AWS as well as other best-practice IaC rules. A schemat- ically valid JSON template returns nothing when run through cfn-lint. In any other case, cfn-lint returns errors and/or warn- ings. The example error in Fig. 2 outlines the basic structure of an"}, {"title": "4 Methodology", "content": "To describe our system, we first describe the methodology we used for collecting a benchmark set, then we describe the feedback loop that we constructed with cfn-lint. We make all of our code and evaluation results available open-source: https://github.com/Mayur- Palavalli/LLM-IaC-generation."}, {"title": "4.1 Benchmark Set", "content": "To create a dataset of prompts, we took 33 descriptions of AWS CloudFormation problems from the official AWS CloudFormation Template Schema repository [2]. This repository converts exist- ing Resource Specifications files into a formatted JSON (or YAML) schema document which can be integrated in an IDE. An example prompt from this repository is displayed in Fig. 3"}, {"title": "4.2 Feeback Loop", "content": "We queried an LLM for a solution to this problem five times for each description, yielding a dataset of 165 implemented CloudFormation templates. We generated these templates in JSON format.\nThe tool cfn-lint is able to process a JSON CloudFormation tem- plate, and returns errors describing schema violations, invalid re- source properties, and best practices. After each generation, we run cfn-lint, and send the error message(s) and JSON template back to the LLM, instructing it to modify the template to fix the"}, {"title": "5 Results", "content": "The entire process of iterating each file ten times through the feed- back loop is repeated six times. Fig. 5 summarizes the results of all six sets of iterations in a bar graph by displaying the total number of errors and warnings in all 165 JSON files after each iteration. The graph's plateau beginning at approximately the fifth iteration indicates the point at which the feedback loop is no longer effective.\nThe plateau is caused by the feedback loop's inconsistency in fixing errors. The LLM is unable to correctly fix certain individual errors, which occasionally result in several new errors being produced from each old error between iterations. After approximately five iterations, this anomaly is enough to yield no significant net change in the number of errors across all 165 files. The slight peak in the number of errors at the eighth and ninth iterations indicates at least one of two things:\n(1) An unusually high number of files generated more errors than it had after the seventh iteration.\n(2) Certain files had an unusually high increase in the number of errors generated after the seventh iteration."}, {"title": "6 Discussion", "content": "Perfecting the use of LLMs in generating valid AWS CloudForma- tion could enable developers to more quickly build the infrastruc- ture they need for their systems. Automating the generation of CloudFormation templates could drastically increases the speed and efficiency of setting up complex cloud environments.\nWe do not use ChatGPT's structured output mode [8]. Structured output mode allows users to provide the desired schema of JSON output from ChatGPT in addition to the prompt. This mode guar- antees that the generated response matches the schema. However, for the purposes of CloudFormation generation this is not a viable option. Not only is the complete CloudFormation schema is over 200,000 lines long, it uses features of JSON schemas that are outside the scope of ChatGPT's structured output mode [8].\nWhile our feedback loop dramatically increases the chance of gen- erating valid IaC, we still do not have a formal guarantee that the generated code will be schematically valid. The remaining uncer- tainty is enough for LLM code generation of IaC to remain hard to use in large-scale development. There is a further question of se- mantic validity. Semantic validity captures the idea that not only is the CloudFormation deployable, but is also what the user wants (e.g. an empty file is always schematically valid, but not semantically valid). A schematically valid CloudFormation is not guaranteed to be semantically valid. We are left with the task of ensuring schemat- ically valid CloudFormation are also semantically valid before LLMs are safe to use at large scale. This, however, is a challenging prob- lem. Measuring semantic validity requires a way to determine how well the generated infrastructure adheres to the prompt. There is currently no simple tool like cfn-lint that does this."}, {"title": "6.1 Threats to Validity", "content": "One threat to the generalizability of our work is the question of the extent to which we would see the same pattern if using a different LLM. At the time of writing, OpenAI's gpt-40 is among the best LLMs capable of working with JSON. We believe that the use of a different LLM for our work would the rate of decrease in the number of errors, but not change the overall pattern. We hypothesize that the plateau on the graph in Fig. 5 is due to the LLM's inability to reconcile error messages with the high-level intent of the prompt. If this is true, we would need a structurally different LLM than OpenAI's gpt-40 model.\nAnother threat to generalizability is the extent to which the IaC provider impacts the pattern of our results. AWS CloudFormation is one of the most well-documented IaC services, and thus has large corpus of training data related to it, making it well-suited to generation with LLMs. Other well-documented IaC services, such as Terraform, would likely yield similar results due to similar com- patibility with LLMs. We hypothesize that using a less documented services would likely still produce a plateau, but would yield more slowly declining error bars due to a smaller training set of relevant data."}, {"title": "6.2 Future Work", "content": "We find that an LLM has a limited ability to respond to error mes- sages and correct code in the context of IaC configurations. A future task would be to customize error messages to a format that an LLM like ChatGPT more clearly understands so errors can be be fixed without creating new ones. The creation of a tool like cfn-lint to check for semantic validity would take IaC generation via LLMs to the next level, allowing for widespread commercial use.\nIn the context of IaC, Pulumi [1] is a an open-source IaC tool that allows developers to define, deploy, and manage cloud infrastruc- ture in familiar programming languages. All AWS services, includ- ing CloudFormation, are fully supported by Pulumi. An especially useful tool is Pulumi AI [6], an experimental feature that allows developers to generate IaC in familiar programming languages via natural-language prompts. As far as we know, the Pulumi AI tool does not incorporate any feedback during its generation from static analysis tools such as cfn-lint. A future task might be to use Pulumi Al to generate Pulumi code which maps to AWS CloudFor- mation, which is run through cfn-lint, and send the generated errors back to correct the Pulumi code."}, {"title": "7 Conclusion", "content": "Our investigation of the use of feedback loop for Infrastructure as Code generation demonstrates the potential of agentic LLM systems for real-world software development. Our results indicate that using LLMs to generate IaC provides a significant advantage, but not yet enough to be make it scale-able. The feedback loop offers a method to increase the rate of successful IaC generation from LLMs, as well as an opportunity for further research to fix the anomalies that cause the loop to become eventually ineffective.\nEven if OpenAI's structured output mode were to support large complex schema like that of AWS CloudFormation, there are still issues of semantic correctness that are not captured in the schema and only appear through checks with tools like cfn-lint."}]}