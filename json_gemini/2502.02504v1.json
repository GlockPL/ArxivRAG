{"title": "Unified Spatial-Temporal Edge-Enhanced Graph Networks for Pedestrian Trajectory Prediction", "authors": ["Ruochen Li", "Tanqiu Qiao", "Stamos Katsigiannis", "Zhanxing Zhu", "Hubert P. H. Shum"], "abstract": "Pedestrian trajectory prediction aims to forecast future movements based on historical paths. Spatial-temporal (ST) methods often separately model spatial interactions among pedestrians and temporal dependencies of individuals. They overlook the direct impacts of interactions among different pedestrians across various time steps (i.e., high-order cross-time interactions). This limits their ability to capture ST inter-dependencies and hinders prediction performance. To address these limitations, we propose UniEdge with three major designs. Firstly, we introduce a unified ST graph data structure that simplifies high-order cross-time interactions into first-order relationships, enabling the learning of ST inter-dependencies in a single step. This avoids the information loss caused by multi-step aggregation. Secondly, traditional GNNS focus on aggregating pedestrian node features, neglecting the propagation of implicit interaction patterns encoded in edge features. We propose the Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a novel dual-graph network that jointly models explicit N2N social interactions among pedestrians and implicit E2E influence propagation across these interaction patterns. Finally, to overcome the limited receptive fields and challenges in capturing long-range dependencies of auto-regressive architectures, we introduce a transformer encoder-based predictor that enables global modeling of temporal correlation. UniEdge outperforms state-of-the-arts on multiple datasets, including ETH, UCY, and SDD.", "sections": [{"title": "I. INTRODUCTION", "content": "The aim of pedestrian trajectory prediction is to forecast future paths based on observed movements (Fig. 1(a)). High-precision prediction systems are crucial for applications like self-driving vehicles [1], [2] and video surveillance [3]. Specifically, in intelligent surveillance systems, especially at accident-prone intersections, early detection of pedestrian crossing intentions within a few seconds enables timely warn-ings to approaching vehicles through Vehicle-to-Everything (V2X) communication between vehicles, infrastructure and pedestrians, providing sufficient time for vehicles to react and reduce accident risks [4].\nPredicting pedestrian trajectory is inherently challenging, primarily due to the complexity of interactions in which pedestrians continuously adjust their movements based on the evolving dynamics of others over multiple time steps. Spatial-temporal (ST) graph architectures (Fig. 1(b)) are widely used to analyze human motions [5], [6] and pedestrian trajectories [7]\u2013[14], capturing spatial interactions within each frame and temporal dependencies over time.\nThis challenge is particularly severe when modeling high-order cross-time interactions, i.e., complex interactions among pedestrians across multiple time steps. Traditional ST graph architectures require multiple steps to capture these in-teractions, where each node first aggregates spatial information at individual time steps and then addresses temporal dependen-cies through temporal networks. STGAT [10] combines graph attention [15] with Long Short-Term Memory (LSTM) [16] for sequential temporal modeling, while Social-STGCNN [11] and SGCN [7] advance to integrating Graph Convolutional Network (GCN) [17] with Temporal Convolutional Network (TCN) [18] for parallel processing. This paradigm has two key disadvantages: (1) when processing high-order interactions among pedestrians, this multi-step aggregation paradigm leads to potential under-reaching [19] due to increased effective re-sistance [20], where important interaction patterns are diluted and compressed with the increase of aggregation steps; and (2) the separation of spatial and temporal processing can disrupt the natural unified ST inter-dependencies observed in real-"}, {"title": "II. RELATED WORK", "content": "Spatial-temporal architecture is widely used in trajectory prediction which considers both spatial interactions and tem-poral dependencies. Pioneering methods such as Social-LSTM [33] and Social-GAN [34] propose pooling window mech-anisms to compute pedestrian spatial interactions and Long Short-Term Memory (LSTM) [16] for temporal aggregation. Due to the outstanding performance of graphs in representation learning, they are widely used to represent pedestrian interac-tions. STGAT [10] and Social-BiGAT [9] employ Graph Atten-tion Network (GAT) [15] to measure interactions strength and LSTM to capture temporal dependencies. Social-STGCNN [11] proposes to use a Graph Convolutional Network (GCN) [17] combined with the TCN [18] to model pedestrian trajec-tories. To simplify the complexity of the graph, sparse GCN-based approaches [7], [8], [13] further propose directed graphs to dynamically update graph topology during message passing, and TCN is used to learn temporal correlations. In recent years,\nAnother challenge lies in modeling the implicit influence propagation through edges in pedestrian social interactions. While Graph Neural Networks (GNNs) are widely adopted for modeling pedestrian interactions [10]\u2013[12], existing ap-proaches primarily focus on Node-to-Node (N2N) interactions (Fig. 2(a)) through GNNs, e.g., using inverse distance [11] or attention-based [7], [10] weighting. Recent works like GroupNet [23] and HEAT [24] advance to Edge-to-Node (E2N) interactions (Fig. 2(b)) by incorporating edge features into node representations, enhancing the relation reasoning ability of the system. However, both N2N and E2N focus on the training of node features, while neglecting the crucial Edge-to-Edge (E2E) patterns [25], [26]. This fundamental limitation restricts GNNs' ability to capture the full spectrum of interaction dynamics in pedestrian behaviors, particularly in complex ST scenarios where one pedestrian's behavior can implicitly influence others through cascade effects [25].\nIn this paper, we introduce the Unified Spatial-Temporal Edge-enhanced Graph Network (UniEdge) for pedestrian tra-jectory prediction. To address the first challenge, our uni-fied ST graph segments input trajectories into patch-based structures (Fig. 1 (c)), simplifying high-order cross-time in-teractions into first-order relationships. This approach reduces effective resistance [20] and mitigates the under-reaching prob-lem [19], preventing information dilution during propagation. By processing ST information jointly in a single step, each uni-fied patch maintains natural ST inter-dependencies, enabling immediate responses to dynamic changes while preserving multi-step interaction patterns.\nTo tackle the second challenge, we introduce Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a dual-graph network that jointly processes both node and edge patterns, as depicted in Fig. 2 (c). Dual-graph design provides a deeper understanding of graph topology in various domains [26], [27]. Our dual-graph architecture consists of two com-plementary graphs: a node-level graph that models explicit N2N social interactions among pedestrians, and an edge-level graph that captures the implicit E2E influence propagation"}, {"title": "III. METHODOLOGY", "content": "The goal of pedestrian trajectory prediction is to esti-mate the possible future trajectories of a pedestrian based on observed trajectories and nearby neighbors. Mathemat-ically, consider a multi-pedestrian scenario containing N pedestrians in Tobs time steps. The observed trajecto-ries of each pedestrian i\u2208 [1,...,N] can be repre-sented as X\u1d62 = {(x, y) | t \u2208 [-Tobs +1,...,0]} and its ground-truth future trajectories can be defined as Y\u1d62 = {(x, y) | t \u2208 [1,...,Tpred]}. For N pedestrians, the ob-served and ground-truth future trajectories are X = [X\u2081,X\u2082,..., X\u0274] \u2208 \u211d^(N\u00d7Tobs\u00d72) and Y = [Y\u2081, Y\u2082, ..., Y\u0274] \u2208 \u211d^(N\u00d7Tpred\u00d72) respectively, where 2 denotes the 2D coordinates. Our proposed UniEdge aims to learn a prediction function Fpred() that minimizes the differences between the predicted trajectories \u0176 = Fpred(X) and the ground-truth future trajec-tories Y. Instead of directly predicting absolute coordinates, we follow [7], [11]-[13] that predict relative coordinates of each pedestrian to ensure the robustness and generalization ability of the system across different scenarios.\nFor trajectory feature initialization, our model takes inputs consisting of pedestrian velocities v, velocity norms p = ||v||\u2082, and pedestrian movement angles \u03b8 = angle(v), where || ||\u2082 denotes the vector 2-norm and angle(\u00b7) is the function that computes the angle of the velocity vectors. We follow [48] that subtract each historical v\u209c, t \u2208 [-Tobs, 0] by the corresponding endpoint v\u1d1bpred as the pre-process step. These motion dynamic features are embedded and then concatenated to obtain the final geometric feature representation as follows:\nX = CONCAT(f(v, W\u1d65), f(p, Wnorm), f(\u03b8, Wangle)),\nwhere X \u2208 \u211d^(N\u00d7Tobs\u00d7D), N and Tobs represent the total number of pedestrians and time steps, respectively, and D de-notes the embedded feature dimension. Here, f(\u00b7, \u00b7) represents Multi-Layer Perceptron (MLP) for feature embedding, and W represents the corresponding weights.\nPrevious trajectory prediction methods often adopt a two-step approach, separately modeling pedestrian spatial inter-actions and individual temporal dependencies [7], [11], [33]. This approach is limited in capturing high-order cross-time"}, {"title": "A. Problem Formulation and Feature Initialization", "content": "Trajectory prediction has seen various architectural develop-ments. Early RNN-based approaches [3], [33], [34], [44]\u2013[46] process trajectories sequentially through hidden states. Among these methods, Social-LSTM [33] processes trajectories where hidden states are updated recursively to capture temporal patterns. Recent works like Social-VAE [44] and ATP-VAE [45] combine RNN with variational autoencoders to model the uncertainty in trajectory predictions, achieving promising results. Subsequently, TCN-based predictor [7], [8], [11], [43] emerged as an alternative approach. Social-STGCNN [11] combines graph convolutions with TCN to achieve efficient parallel processing through increased receptive fields. SGCN [7] further advances this design by introducing sparse at-tention mechanisms to adaptively aggregate temporal fea-tures. Recently, transformer-based methods [2], [41], [47]\nhave gained prominence in trajectory prediction, where self-attention mechanisms compute pairwise interactions between all time steps, enabling global temporal modeling without the constraints of sequential processing or fixed receptive fields. However, RNNs suffer from long-term dependencies due to their auto-regressive nature, and TCNs are limited by fixed receptive fields due to their convolutional structure, while full transformer models have high computational costs. To balance modeling capability and efficiency, we propose a Transformer encoder-based predictor that learns global dependencies within the sequence without high computational costs."}, {"title": "B. Unified ST Graph", "content": "interactions, which require multi-step aggregation. Such multi-step processing increases the effective resistance a mea-surement of graph connectivity that quantifies the efficiency of information flow between nodes [20], [49]. High effective resistance impedes graph message-passing, leading to under-reaching problem [19], where message flows from distant nodes are diluted and compressed.\nTo address these challenges, we propose a unified ST graph to simplify high-order cross-time interactions among pedestri-ans into first-order relationships, enabling direct learning of ST inter-dependencies, and preserving high-order interactions without information dilution. This design significantly reduces the effective resistance during message passing, improving information flow efficiency [20], [49] and alleviating the risk of under-reaching [19]. Fig. 4 illustrates the difference in effective R between the message-passing paradigms of traditional ST approach and our unified approach:\nR\u1d62\u2c7c = (e\u1d62 - e\u2c7c)\u1d40L\u207a(e\u1d62 - e\u2c7c)   (1)\nwhere L\u207a denotes the Moore-Penrose pseudoinverse of the graph Laplacian matrix representing the graph connectivity [50], and e\u1d62, e\u2c7c are standard basis vectors corresponding to nodes i and j. Lower R\u1d62\u2c7c values indicate better message propagation efficiency between nodes.\nTo reduce computational overhead in processing entire sequences and to better capture fine-grained pedestrian dynam-ics, we adopt a patch-based strategy akin to the local receptive fields used in convolution kernel for image processing. [51]. Specifically, to construct the unified ST graph depicted in Fig. 3 (a), the input features are segmented into K overlapping patches across the temporal dimension Tobs. These patches are defined by a length L and a stride S, yielding K = [\u1d40\u1d52\u1d47\u02e2-\u1d38/S]+1. For each patch k, ranging from 1 to K, a graph \ud835\udca2\u1d4f\u02b0\u1d52\u1d48\u1d49 = (\ud835\udcb5\u2096, \ud835\udc9c\u1d4f\u02b0\u1d52\u1d48\u1d49) is constructed. Here, \ud835\udcb5\u2096 \u2208 \u211d^(\ud835\udc41\u1d38\u00d7\ud835\udc37) represents the node features, and \ud835\udc9c\u1d4f\u02b0\u1d52\u1d48\u1d49 \u2208 \u211d^(\ud835\udc41\u1d38\u00d7\ud835\udc41\u1d38) denotes the node adjacency matrix, which encapsulates the node connections. This configuration further benefits subsequent trajectory prediction phases by reducing the number of input tokens from Tobs to K, which is crucial when using the transformer encoder model. It leads to a quadratic reduction in memory usage and computational complexity for the attention map, by a factor of (\u1d40\u1d52\u1d47\u02e2/S)\u00b2.\nWe then apply GAT [9], [10], [52] to initialize interactions strength for the kth graph \ud835\udca2\u1d4f as:\nH\u02b0\u1d52\u1d48\u1d49 = GAT(\ud835\udcb5\u2096, \ud835\udc9c\u1d4f\u02b0\u1d52\u1d48\u1d49), (2)\nwhere each node \ud835\udc3b\u02b0\u1d52\u1d48\u1d49,\u1d62 is embedded as:\n\ud835\udc3b\u1d50\u1d52\u1d48\u1d49,\u1d62 = \u03c3(\u2211\u2c7c\u2208\ud835\udca9(\u1d62)\u222a{\u1d62}\u03b1\u1d62\u2c7c\u0398\u1dbb[\ud835\udcb5\u02b0\u1d52\u1d48\u1d49,\u2c7c]), (3)"}, {"title": "C. E2E-N2N Graph Convolution (E2E-N2N-GCN)", "content": "Previous pedestrian trajectory models typically adopt node-centric approaches, such as N2N [7], [11]-[13], [53] and E2N [23], [24] paradigms to understand and capture node dependencies. However, these methods overlook crucial E2E patterns, limiting their ability to capture the full spectrum of interaction dynamics. This oversight may result in a partial understanding of pedestrian behaviors, especially in complex scenarios where interaction patterns influence each other.\nTo address this limitation, we propose a novel Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN) module (Fig. 3 (b)), a dual-graph architecture that leverages the first-order boundary operator to construct edge graphs. By jointly modeling both explicit N2N social interactions among pedestrians and implicit E2E influence propagation across interaction patterns, our approach enables more comprehensive modeling of complex pedestrian behaviors. This dual-graph design allows each unified ST graph to capture how interaction patterns evolve and influence each other through connected edges, leading to more accurate trajectory predictions.\nTo construct the edge graph, we apply the first-order bound-ary operator \u212c\u2081 to transform it into its corresponding undi-rected edge graph \ud835\udca2\u1d49\u1d48\u1d4d\u1d49 = (\u2130\u2096, \ud835\udc9c\u1d49\u1d48\u1d4d\u1d49), where \u2130\u2096 represents the node features in the edge graph, and \ud835\udc9c\u1d49\u1d48\u1d4d\u1d49 indicates the new adjacency relations. This operator reinterprets the connections between nodes (edges in the original graph) as nodes in the new graph, creating edges between these new nodes if they share a common node in the original graph. Fig. 5 illustrates this process, effectively showing how relationships are redefined to highlight deeper interaction dynamics.\nTo analyze and update the feature propagation of each edge graph, we employ the first-order Hodge Laplacian [25], [26] to analyze and learn the dynamics within these edge graphs:\n\u2112\u2081 = \u212c*\u212c\u2081 + \u212c\u2082\u212c\u2082*,  (5)\nwhere \u2112\u2081 represents first-order Hodge Laplacian operator, and \u212c captures and enhances edge relationships, focusing on direct interactions. \u212c\u2082 is typically relevant for higher-dimensional structures and not a primary focus here. We perform edge convolution by adapting the Hodge-Laplacian Laguerre Convolution (HLLConv) [25], [26] to obtain the high-level edge embedding \u210b\u1d49\u1d48\u1d4d\u1d49 for each edge graph k:\nH\u1d49\u1d48\u1d4d\u1d49 = HLLConv(\u2130\u2096, \ud835\udc9c\u1d49\u1d48\u1d4d\u1d49)\n= \u0127\u2081 \u2217 \u2130\u2096\n= \u2211\u2c7c=\u2080\u1d36\u207b\u00b9\u0398\u2c7c\u0393\u2c7c(\u2112\u2081) \u2130\u2096,   (6)\nwhere \u0127\u2081 is a spectral filter based on \u2112\u2081 applied to update edge features \u2130\u2096, with \u0398\u2c7c representing learnable parameters, and \u0393\u2c7c (\u00b7) indicates the Laguerre polynomial functions. Detailed explanations of spectral filter \u0127\u2081 are shown in Algorithm 1.\nFinally, after obtaining the embedded node features \ud835\udc3b\u02b0\u1d52\u1d48\u1d49 and edge features \u210b\u1d49\u1d48\u1d4d\u1d49 for the kth unified ST graph, we leverage a fusion GCN to integrate node and edge embeddings, enhancing the understanding of graph dynamics. Specifically, we incorporate normalized edge embedding as weights into the aggregation process of GCN:\nH\u1d4f = GCN (\ud835\udc3b\u02b0\u1d52\u1d48\u1d49, \u210b\u1d49\u1d48\u1d4d\u1d49, \ud835\udc9c\u02b0\u1d52\u1d48\u1d49), (7)\nand each node i in the graph is embedded as:\n\ud835\udc3b\u1d62\u1d4f= \u03c3(\u03a6(\ud835\udc3b\u02b0\u1d52\u1d48\u1d49,\u1d62) + \u2211\u2c7c\u2208\ud835\udca9(\u1d62)\u03a8(\u210b\u1d49\u1d48\u1d4d\u1d49,\u1d62,\u2c7c)(\ud835\udc3b\u1d50\u1d52\u1d48\u1d49,\u2c7c)), (8)\nwhere \u03a6(\u00b7) and \u03a8(\u00b7) are linear transformations for node and edge features [25], with \u03c3(\u00b7) as the activation function."}, {"title": "D. Transformer Encoder Predictor", "content": "Temporal dependency modeling in trajectory prediction has evolved through various architectures. RNNs [33], [34] and TCNs [7], [11] have been widely adopted, they suffer from limited receptive fields and struggle to capture long-range dependencies. Although Transformer encoder-decoder architectures [2], [29], [41] address the long-range dependency issue, it introduces extra computation costs.\nIn this work, we design a Transformer encoder-based predictor for trajectory prediction. As shown in Fig. 3 (c), by encoding future trajectories as learnable parameters and concatenating them with historical trajectories, our approach enables unified modeling of both past and future information, allowing the model to fully leverage global temporal depen-dencies [54] for more accurate predictions. We simply stack the graph embeddings Hk output by E2E-N2N-GCN across all patches to obtain the integrated feature representations H:\nH = STACK(H\u00b9, H\u00b2,\u2026\u2026,H\u1d37) \u2208 \u211d^(K\u00d7(NL)\u00d7D).  (9)\nWe perform temporal average pooling across the L channel, and the output H \u2208 \u211d^(N\u00d7K\u00d7D) is served as the historical input tokens. We then initialize a learnable placeholder to form the padded future tokens as F \u2208 \u211d^(N\u00d7Tpred\u00d7D). The temporal channel of these tokens, Tpred, is tailored to match our prediction horizon. This setup aligns with the requirements of the Transformer encoder architecture [29], [55], which necessitates uniform sequence lengths for both inputs and outputs to enable synchronous processing. This design allows our model to directly produce trajectories of the required length. Throughout the training process, these placeholders are incrementally refined to represent the predicted trajectories, thereby enhancing the prediction capabilities.\nFinally, the input tokens for the Transformer encoder are formed by concatenating the learned historical input tokens H and padded future tokens F, resulting in the concate-nated feature representation \u0124in \u2208 \u211d^(N\u00d7(K+Tpred)\u00d7D). We further enhance these tokens with a learnable additive position embedding P \u2208 \u211d^(N\u00d7(K+Tpred)\u00d7D) [29] that is applied to the entire concatenated sequence to preserve the temporal order information. The Transformer encoder then processes these augmented inputs to produce the predicted sequence representations \u0176 \u2208 \u211d^(\u00d1\u00d7(K+Tpred)\u00d7D).\nY = Encoder(Hin + P),\nHin = [H || F],(10)\nwhere [ | ] denotes the concatenation operation along the temporal dimension. Note that \u0176 represents the complete output of the encoder with length K+Tpred, only the last Tpred time steps are used as the predicted trajectory representations, corresponding to the padded future tokens F. The architecture of the Transformer encoder and the learning process are shown in Fig. 6. Similarly to [7], [8], [11], we employ the bi-variate Gaussian loss function \u2112prediction to optimize the trajectory prediction:\n\u2112prediction = \u2212 \u2211\u209c=\u2081\u1d40\u1d3e\u02b3\u1d49\u1d48 log P((x\u209c, y\u209c)|\u00fb\u209c, \u00f4\u209c, \u03c1\u209c), (11)\nwhere \u00fb and \u00f4 are the mean and variance of bi-variate Gaus-sian distribution, and \u03c1 represents the correlation coefficient."}, {"title": "E. Implementation Details", "content": "The UniEdge framework, developed using PyTorch, is trained end-to-end on an NVIDIA TITAN XP GPU. We use a consistent batch size of 128 across all datasets, with initial learning rates set at 0.001 for the ETH/UCY datasets and 0.01 for the SDD datasets. The learning rate is adjusted every 50 epochs by a factor of 0.5. The AdamW optimizer is employed to train the model. The architecture for learning graph employs single-layer GAT, HLLConv, and GCN components. Node and edge embedding dimensions are set to 128. The Transformer encoder-based predictor is configured with a hidden dimension of 256 with 4 attention heads."}, {"title": "IV. EXPERIMENTS", "content": "We evaluate the proposed UniEdge on multiple benchmark datasets, including ETH [30], UCY [31], and Stanford Drone Dataset (SDD) [32]. The ETH dataset contains two subsets (ETH and HOTEL) and the UCY dataset contains three subsets (UNIV, ZARA1, ZARA2), with the total number of pedestrians captured in these 5 subsets being 1,536. SDD is a benchmark dataset for pedestrian trajectories captured by a drone with a bird's eye viewing of university campus scenes and it contains 5,232 pedestrians across 8 different scenes.\nWe follow the experimental setup of [7], [33], [56], using 3.2 seconds (8 frames) of observation trajectories to predict the next 4.8 seconds (12 frames). For ETH and UCY datasets, we follow existing works [7], [11]\u2013[13], [34], [41] and use the leave-one-out strategy for training and evaluation. For SDD, we follow the existing train-test split [12]\u2013[14] to train and test our proposed method. During training, we employ data augmentation following [56] to diversify and enrich our training datasets. This strategy is pivotal in enhancing the model's generalization capabilities.\nDuring testing, we follow the standard protocol [33], [34] and sampling strategy [12] that generates 20 predictions from the predicted distributions; the best sample is used to compute"}, {"title": "A. Experimental Setup", "content": "1) Model Component Analysis: To verify the influence of each module incorporated in our UniEdge, we conduct ablation studies on the ETH and UCY datasets, which contain five different social scenarios. The results of these studies are detailed in Table III. In our experiments, variant (1) corresponds to the model excluding node-level embedding (NN), i.e., the model eliminates node-level GAT for capturing N2N interactions. variant (2) represents the model without edge-level embedding (EE), meaning that edge information is not integrated into the model's architecture, neglecting implicit edge feature propagation. Lastly, variant (3) describes the modeling process without learning edge graphs through Hodge-Laplacian Laguerre Convolution (HC). Specifically, node-level embedding provides an overall picture of pedestri-ans' interaction intentions to capture initial N2N interactions, the overall performance dropped 11.1% in ADE and 24.0% in FDE without N2N interactions. Variant (2) shows that without the modeling of implicit E2E influence propagation, the per-formance dropped 16.7% in ADE and 20.0% in FDE. Variant\nsignificant improvements of 10.0% in average ADE and 16.7% in average FDE. Although HighGraph introduces high-order interaction modeling, it operates only on individual time steps, rather than cross-time interactions, which limits its effective-ness in capturing dynamic changes over time. Contrasted to these graph-based methods, our UniEdge comprehensively models edge information flow and cross-time interactions, which can be the key to performance gain. Compared to DDL, which uses similar data pre-processing techniques, our UniEdge surpasses it by 10.0% in ADE and 35.9% in FDE, demonstrating enhanced prediction performance. While our UniEdge model demonstrates state-of-the-art (SOTA) perfor-mance on four subsets (HOTEL, UNIV, ZARA1, and ZARA2), particularly in environments with rich pedestrian interactions such as UNIV, it faces challenges similar to the graph-based SOTA method HighGraph on the ETH subset. This limitation of graph-based methods is mainly caused by the sparsity of the ETH subset, where fewer pedestrians and limited interactions constrain the expressive power of graph representations.\n2) SDD Dataset: Table II presents the quantitative compar-ison results of our model against various previous methods on SDD dataset. Unlike the ETH and UCY datasets, the SDD is a larger dataset featuring more complex pedestrian interactions. Compared to generative-based methods, UniEdge improves 8.6% in ADE compared to MSRL and 6.6% in FDE compared to LED. As a graph-based approach, our UniEdge outperforms the best graph-based HighGraph model by 5.9% in ADE and 4.6% in FDE. Compared to SOTA methods, UniEdge shows an improvement of 3.0% in ADE over TUTR. These results further highlight the effectiveness of our proposed UniEdge model in handling complex social scenarios."}, {"title": "E. Ablation Study and Model Analysis", "content": "4) Unified ST Graph Analysis: In this section, we analyze the effectiveness and impact of our proposed unified ST graph data structure while keeping other components fixed. The construction of this data structure is controlled by two key parameters: patch size L and stride size S. We conduct experiments on the ETH and UCY datasets to thoroughly analyze how these parameters affect the model's ability to capture ST inter-dependencies.\nAs shown in Fig. 9 (left), we evaluate how patch size affects unified ST graph construction. A patch size of 1 reduces our model to traditional two-stage ST approaches [7], [10], [11], [13], where cross-time interactions are not explicitly modeled. The model achieves optimal performance with a patch size of 3, effectively capturing local ST dependencies. Larger patch sizes, despite capturing more context information, may introduce redundant connections that degrade performance.\nSecond, we analyze the impact of stride size as shown in Fig. 9 (right). The stride size determines the number of unified ST graphs and the overlap between adjacent patches. A larger stride size reduces the overlap between patches during graph construction, which in turn decreases the total number of uni-fied ST graphs. A stride size of 1 yields the best performance in both ADE and FDE metrics, as it enables the capture of more fine-grained cross-time interactions through increased\nsituations and effectively meeting, where our predictions successfully capture their gradual convergence even in sparse environments. Scenario (b) shows pedestrians moving in parallel, where our approach achieves better alignment with ground-truth and avoids collisions compared to other methods. Scenario (c) presents two pedestrians meeting, where GP-Graph and EigenTrajectory fail to capture non-linear collision avoidance patterns. While Graph-TERN provides plausible predictions, our method better aligns with ground-truth by effectively modeling cross-time interactions. Scenario (d) presents a complex scenario in which several groups of pedestrians walk in opposing directions. In this case, GP-Graph and Eigen-Trajectory significantly suffer pedestrian collision issues. Our UniEdge demonstrates superior capability in capturing non-linear movements, showcasing enhanced predictive accuracy in dynamically complex pedestrian interactions compared to previous methods. Finally, scenario (e) features complex non-linear trajectories with abrupt changes, where our method bet-ter captures overall movement trends despite shared challenges with certain trajectories.\n2) Distribution Visualization Comparisons: In this section, we further compare the predicted distributions of UniEdge with GP-Graph [12], Graph-TERN [14] and EigenTrajectory [13] on the ETH and UCY datasets. As shown in Fig. 8, our method generates more accurate and plausible distributions. In scenario (a), while other methods' distributions cover the ground-truth, they fail to capture the pedestrian convergence trend that our method successfully predicts. In scenarios (b) and (c), GP-Graph and Graph-TERN generate either too narrow or broad distributions, failing to capture non-linear trajectories. EigenTrajectory covers ground-truth but produces overly broad, overlapping distributions that lead to collision issues. Our method achieves comprehensive coverage with fewer collision predictions. In scenario (d) with random walking patterns, our approach better captures both non-linear and linear trajectories."}, {"title": "D. Qualitative Comparison", "content": "3) demonstrate the effectiveness of the proposed edge-level reasoning, without Hodge-Laplacian Laguerre Convolutions, the overall performance dropped 16.7% in ADE and 16.0% in FDE, respectively. Notably, the UNIV subset, which contains the most pedestrians and the most complex interactions [63", "17": "exhibits limited performance due to its uniform neighborhood aggregation strategy. GraphSage [64"}]}