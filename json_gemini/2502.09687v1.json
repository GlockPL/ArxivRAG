{"title": "Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models", "authors": ["Wiktoria Mieleszczenko-Kowszewicz", "Beata Bajcar", "Jolanta Babiak", "Berenika Dyczek", "Jakub \u015awistak", "Przemys\u0142aw Biecek"], "abstract": "Be careful what you ask for, you just might get it. This saying fits with the way large language models (LLMs) are trained, which, instead of being rewarded for correctness, are increasingly rewarded for pleasing the recipient. So, they are increasingly effective at persuading us that their answers are valuable. But what tricks do they use in this persuasion? In this study, we examine what are the psycholinguistic features of the responses used by twelve different language models. By grouping response content according to rational or emotional prompts and exploring social influence principles employed by LLMs, we ask whether and how we can mitigate the risks of LLM-driven mass misinformation. We position this study within the broader discourse on human-centred AI, emphasizing the need for interdisciplinary approaches to mitigate cognitive and societal risks posed by persuasive AI responses.", "sections": [{"title": "Introduction", "content": "Social influence refers to the change in attitude or behavior that one individual or group causes in another [Kelman, 2017]. Studies investigate the effects of social influence in various social domains, such as organizational systems [Binyamin, 2020] marketing and information systems management [Baker et al., 2014], political marketing [Raftopoulou and Hogg, 2010], or human resource management [Ferris et al., 2002].\nPersuasion is a distinct form of social influence that involves communication designed to influence others by changing their beliefs, values, or attitudes [Simons, 1976]. Persuading others can take place in both face-to-face interaction [Rosselli et al., 1995] and computer-mediated communication (CMC) [Mazzotta et al., 2007; Fogg, 1998; Wilson, 2003]. The literature discusses different persuasion strategies that are considered effective in CMC, such as a reward strategy, a punishment strategy, a logical strategy, and an emotional strategy [Wilson, 2003], or emotional and rational argumentation that includes positive and negative statements [Mazzotta et al., 2007]. However, there is no agreement among authors on which persuasion approach is most effective. Possibly, it depends on the context in which persuasion takes place, such as advertising [Heath et al., 2006], political campaigns [Brader, 2005], or management [Fox and Amichai-Hamburger, 2001].\nThis paper focuses on computer-mediated persuasion, specifically persuasion that occurs when a person interacts with a system known as a Large Language Model (LLM). LLMs are highly sophisticated deep learning systems that have been trained to predict the next word in a sequence based on the given context, exhibiting human-like linguistic abilities. LLMs function as communication partners, acquiring knowledge through human feedback while presumably suppressing undesirable responses [Wei et al., 2022; Jin et al., 2023]. In contemporary society, people frequently interact with LLMs mainly because of the convenience with which many different requests can be handled by the models [Brown et al., 2020]. Given the wide range of contexts in which LLMs find application - including business, organizational, medical, or educational - it is imperative for users to interact with them reflexively and conscientiously. In light of the findings from prior studies that demonstrated the effectiveness of LLMs in persuading users [Wilczy\u0144ski et al., 2024], the goal of this study was to determine whether these models can similarly influence interlocutors through the use of rational and emotional persuasion.\nThe following research questions emerge from the objective of the study.\nRQ1: What are the differences in the LLMs' language patterns when they are prompted to use rational versus emotional persuasion?\nRQ2: Do LLMs differ in their tendency to use rational or emotional persuasion?\nRQ3: What social influence principles do LLMs use in emotional or rational persuasion?\nThe main contributions of our work are as follows:\nC1: We identified the key differences between emotional and rational persuasion in LLMs, highlighting how emotional prompting can enhance cognitive complexity.\nC2: We revealed the baseline setup's preference for rational persuasion, while also incorporating subtle emotional inclination, particularly negative emotions like anger and sadness.\nC3: We demonstrated that LLMs construct responses with reference to different social influence principles. Emotional and rational prompting evokes different responses by LLMs."}, {"title": "Related work", "content": "Some LLMs are more flexible and adapt their responses in line with the persuasion setup, while other models use similar principles of social influence regardless of the persuasion setup.", "sections": [{"title": "Persuasion by LLMs", "content": "The extensive utilization of LLMs in a multitude of tasks has rised significant concerns regarding their potential to generate detrimental outputs, including discrimination, exclusion, toxicity, information hazards, misinformation, malicious uses, and harm to human-computer interaction [Weidinger et al., 2021].\nRecent studies have identified manipulative content produced by LLMs as a function of detected personality of a person interacting with the model [Mieleszczenko-Kowszewicz et al., 2024]. Other studies [Goldstein et al., 2024; Karinshak et al., 2023] showed that LLMs can be as persuasive as humans, both in writing extensive articles or short texts.\nThe capabilities of LLMs are linked to both their knowledge-driven stylistic approach and their integration of moral-emotional language [Carrasco-Farre, 2024; Breum et al., 2024; Wilczy\u0144ski et al., 2024]."}, {"title": "Persuasion prompting", "content": "In previous studies some authors prompted the models with suggestions which persuasion tactic should be included in the output[Carrasco-Farre, 2024; Zeng et al., 2024; Pauli et al., 2024]. These approaches aimed at enhancing the effectiveness of generated content by incorporating rhetorical strategies such as emotional appeals, logical arguments, or credibility cues [Wilczy\u0144ski et al., 2024]. Other notable works encompassed categories of persuasion as rational or manipulative [Pauli et al., 2024] or focused on the characteristic of communication, e.g., static persuasion, interacting with LLMs, or interacting with humans [Jones and Bergen, 2024]. These studies mainly focused on complex persuasion techniques, neglecting basic tactics, such as emotional and rational persuasion, which have been well documented in the literature [Rosselli et al., 1995; Miceli et al., 2006]."}, {"title": "Principles of social influence", "content": "Widely recognized conception of social influence was proposed by Robert Cialdini, who argued that all influence attempts fall into one of six principles, i.e., commitment and consistency, reciprocity, scarcity, liking and sympathy, authority, and social proof [Cialdini, 2021]. The principle of commitment and consistency means that people can use their natural tendency to remain consistent in their decisions and behaviors. If an individual succeeds in forcing an initial commitment on someone, it will be much easier to persuade that person to meet subsequent demands. The principle of reciprocity states that one should always reciprocate for what one receives from someone. The ability to induce a sense of obligation for the future is a critical element in conducting successful transactions, socially beneficial exchanges, and establishing lasting relationships. The principle of scarcity states that when something is limited, we experience discomfort because of the reduced opportunities. This emotional response often leads people to make quick decisions. The principle of liking and sympathy suggests that people are more likely to help those they like or consider friends, even if the request is uncomfortable. In addition, we tend to be more sympathetic to those who share our beliefs or resemble us. The principle of authority explains that individuals are more likely to trust and accept the ideas of experts rather than forming independent opinions. This is why people often respect professionals such as doctors, lawyers, and military officers. The principle of social proof can be used to get someone to comply by showing that many other people (including widely admired and well-known individuals) have already agreed to the demand. Based on previous studies, it can be argued that each of the aforementioned principles of social influencing others contains the possibility of having a manipulative effect on those involved in the communication process."}]}, {"title": "Methods", "content": "", "sections": [{"title": "LLMS", "content": "In our investigation into how different LLMs use rational versus emotional persuasion, we selected models that differ in both size and licensing. Therefore, our research incorporated 12 LLMs from four separate model families.\n1. OpenAI [OpenAI, 2024]: GPT-3.5 Turbo, GPT-4, GPT-4 Turbo, GPT-40.\n2. Mixtral [MistralAI, 2024]: Mixtral 8x7B, Mixtral 8x22B.\n3. Meta [Dubey et al., 2024]: Llama 3 8B, Llama 3 70B.\n4. Anthropic [Anthropic, 2024b]: Claude 3 Sonnet, Claude 3 Haiku, Claude 3 Opus, Claude 3.5 Sonnet [Anthropic, 2024a]."}, {"title": "Prompting method", "content": "In our experiment, we compare the baseline output with responses generated by selected LLM models using a dataset referenced containing responses to a persuasion task [Mieleszczenko-Kowszewicz et al., 2024]. To ensure consistency across different models, the dataset includes responses generated from a standardized prompt template incorporating multiple variables, such as gender, persuasion style, level of a specific trait, initial belief, and controversial topics. The topics covered in this dataset are related to various controversial issues, such as the death penalty, abortion, illegal immigration, and climate change.\nFor current study, we developed a baseline prompt that emphasizes direct persuasive argumentation while omitting explicit references to demographic, psychological traits or persuasion type. This approach allowed us to evaluate the natural persuasive tendencies of the models. Each variant of this simplified prompt was administered 60 times per model, resulting in a data set that captured a range of generated outputs in response to the same directive.\nThe baseline prompt content is:"}, {"title": "Annotation technique", "content": "The independent judges rating method [O'Connor and Joffe, 2020; McDonald et al., 2019] was used to assess whether social influence techniques were present in rational and emotional prompt's setup. In this procedure, four researchers (i.e., researchers with expertise in psychology, sociology, and AI) were assigned as judges who annotated the LLM responses for the presence of social influence techniques (such as commitment and consistency, reciprocity, scarcity, liking and sympathy, authority, and social proof). A randomly drawn 10% subset of responses from specified types was annotated, both rational and emotional, to ensure a balanced evaluation of the response models. The dataset Claude Sonet did not produce any emotional responses; therefore, we had no data to annotate. Finally, 517 responses were included in the analysis, which were independently rated by the annotators. Each prompt was independently checked by judges who assigned them to one or more of the six principles of social influence [Cialdini, 2021]. They used codings of 1 - the principle is present in the response and 0 - the principle is not present in the response. A positive decision by at least three judges was the criterion for recognizing that a given principle is present in the LLM responses."}, {"title": "Linguistic analysis", "content": "All LLMs' answers from rational or emotional setup were analyzed with Linguistic Inquiry and Word Count [Tausczik and Pennebaker, 2010] a software that returns the percentage of words in the text from predefined psycholinguistics categories. Each category contains words referring to different psychological dimensions. Among the fourteen main categories available in LIWC, in our analysis we chose two main categories: cognition as the linguistic indicator of the rational persuasion and affect for the emotional persuasion (see Table 2). During analysis we use the latest version: LIWC-22 [Boyd et al., 2022]."}]}, {"title": "Results", "content": "The results were presented in two sections. The first subsection contains the results seeking answers to research questions 1 and 2, while the second subsection contains the results regarding research question 3.", "sections": [{"title": "Differences in linguistic patterns between emotional, rational, and baseline setups", "content": "The LIWC analyses demonstrated differences in emotional and rational responses compared to baseline (see Figure 2 and 3).\nEmotional setup The emotional setup consistently outperforms both rational and baseline setups across nearly every linguistic indicator of rational persuasion, see Figure 3. Notably, Claude 3 Haiku employs the most cognitively complex wording, suggesting that it generates the most elaborate arguments. The emotional setup also scores highest in all or none thinking style, indicating a tendency to use more polarized argumentation, omitting subtle nuances. Particularly, GPT-3.5 Turbo (1.04) and GPT-4 (1.2) score very high in this category. In terms of insight, the emotional setup surpasses all others except Claude 3 Haiku, suggesting that LLMs are more likely to provoke reflection and understanding in emotional setup. Claude 3 Opus (6.16), GPT-40 (5.17) and Mixtral 8x22B (5.28) generate the most insightful responses. Also, the emotional setup indicates the highest discrepancy processes, meaning emotional arguments are more likely to introduce dichotomies, probably due to the tendency to create emotional tensions, emphasize conflicts, and present dramatic opposites. Additionally, the frequent use of tentative words reflects elements of uncertainty and openness to different interpretations. This may be due to the tendency for personalization and subjecting of arguments. On the other hand, LLMs in emotional setup use the most certitude words, which means that emotional arguments are firmer and more confident. The reason for this is that the greater emphasis on emotional persuasion often requires strong self-confidence. Particularly, Claude 3 Haiku is the most confident model (0.84), which may exhibit the highest capacity for persuasion. There is a slight tendency across LLMs (besides GPT 3.5 Turbo, GPT-4 Turbo, Claude 3 Opus, Claude 3 Sonnet, Mixtral 8x7B, Meta Llama 3.1 8B) to employ differentiation mechanisms in the emotional setup. As a result, they may be more likely to highlight the differences between arguments, rather than unifying the position. What is more, the emotional setup consistently references memory, indicating a tendency to draw on past experiences, which adds a personal touch to the arguments.\nThe differences are also visible for emotional linguistic indicators. LLMs responding in emotional setup consistently generate more affect-laden content, with the highest values observed in Claude 3.5 Sonnet (11.02) and Mixtral 8x7B (10.20) (see Figure 2). This suggests that emotional persuasion leads to greater emotional intensity. There is a consistent trend for the emotional setup to produce both positive and negative tones in the text.. The positive tone is clearly higher than the negative in almost every model (a different tendency appears in Claude 3.5 Sonnet and Claude 3 Sonnet). Also, it is worth noting that Claude 3.5 Sonnet has the highest score in a negative tone. Furthermore, the emotional setup contains more emotion-related wording, resulting in enhancing emotionality in the generated text. The tendency is similar for positive and negative emotions. The emotional setup consistently exhibits the highest anxiety levels across all models. The highest mean values appear in two models, Claude 3.5 Sonnet (0.46) and GPT-40 (0.44), suggesting they may use anxiety-inducing content. The emotional setup increases the level of sadness, which means that emotional arguments are more likely to contain references to loss and grief. In addition, GPT 4o generates the highest proportion of sad responses (0.33), contrary to Meta Llama 3 70 \u0412 (0.10).\nRational setup All models have lowest scores in rational than in emotional setup in cognition indicators, meaning they frame statements in a more nuanced, non-extreme way. There is a distinction between models regarding causal relationships. Only Meta Llama 3 70B (3.26) and Meta LLama 3.1 8B use more causal reasoning in emotional setup, whereas all other models score higher in either rational or baseline setup. On the other hand, low scores in discrepancies process in rational setup may suggest a preference for coherence and less confrontational style, focusing on logical argument instead of opposing extreme viewpoints. The rational setup contains fewer tentative words, indicating arguments to be more firm and unambiguous, avoiding excessive assumptions.\nAnger is more intense in a rational setup than an emotional setup. This suggests that rational arguments are more often referring to frustration, dissatisfaction, and criticism. The lowest score for rational than emotional setup in both anxiety and sadness highlight the focus on logical persuasion than evoking emotional reaction (see Figure 2).\nBaseline setup Answers from the baseline setup contain the least cognition words (see Figure 3), suggesting that evoking any persuasion type improves the depth of reasoning or engagement. The baseline contains more negative tone in few models (GPT 3.5 Turbo, GPT-4, Claude 3 Sonnet, Claude 3.5 Sonnet, Claude 3 Haiku, Claude 3 Opus, Meta Llama 3 70B, Mixtral 8x22B). With this exception, the baseline is the most neutral and avoids emotional persuasion processing in any direction. The baseline generally shows lower values for all or none category compared to the emotional setup, suggesting less tendency for polarized argumentation. Lowest scores for both cognitive processing and insight suggest providing less insightful arguments. Baseline setup performed better than emotional persuasion but worst in rational in cause category. Only Claude 3 Haiku, Claude 3 Opus, Mixtral 8x22B, Mixtral8x7B and GPT-4 - baseline score higher in baseline setup than others. This suggests the natural preferences of models to show causal relationships. Scores similar to rational setup in discrepency implicates that baseline preferences are"}, {"title": "Social influence principles in emotional and/or rational setups used by LLMs", "content": "The most frequently applied principle of social influence in LLMs, irrespective of the model and persuasion setup, was the principle of social proof (appearing 59% out of 517 responses). Relatively often, LLMs used the principles of authority (45.6%), commitment and consistency (41.8%), and liking and sympathy (27.1%). Relatively rarely LLMs used the principle of scarcity (8.3%) and reciprocity (1.9%) (see Table 1A in Appendix). The chi-square test revealed that the differences in using social influence principles based on emotional and rational setups are statistically significant, except for reciprocity. Specifically, LLMs used the principles of commitment and consistency, liking and sympathy, social proof, as well as scarcity to a higher degree in the emotional than in the rational setup (see Figure 5).\nIn emotional setup, the GPT-3.5 model used solely the principle of commitment and consistency. The GPT-4, GPT-4 Turbo, GPT-40, Claude 3.5 Sonnet, Meta Llama 3 70B, and Meta Llama 3.1 8B models frequently utilized a combination of persuasive principles, including commitment and consistency, liking and sympathy, and social proof. The Claude 3 Opus and Claude 3 Haiku models primarily employed the principles of commitment and consistency and scarcity, while Claude 3 Opus also used the principle of authority. Most models relatively rarely used the principles of reciprocity, scarcity, and authority (see Figure 5).\nIn rational setup, most models employed the principles of authority and social proof. For example, the GPT-40 model applied both principles to a similar extent. The GPT-3.5, GPT-4 Turbo, and Mixtral 8x22B models employed the principle of social proof most frequently, with the principle of authority used to a lesser extent. The GPT-4, Claude 3.5 Sonnet, Claude 3 Haiku, Claude 3 Opus, Meta-Llama 3 70B, Meta-Llama 3.1 8B, and Mixtral 8x7B models primarily utilized the principle of authority and social proof to a lesser degree. The Claude 3 Sonnet model exclusively employed the principle of authority. Among all models, Claude 3 Haiku stands out as the only one that used the principle of commitment and consistency at a relatively high level. Overall, all models rarely utilized the principles of reciprocity, scarcity, or liking and sympathy (see Figure 5).\nDifferent families of large language models varied in applying the principles of social influence. OpenAI models (3.5 Turbo, 4, 4 Turbo, 40, 01) primarily used commitment and consistency in emotional setup, and social proof in rational setup. Meta-Llama models (70B and 8B) used the principle of social proof more frequently in emotional setup, whereas in rational setup, they used the principle of authority more frequently. Mixtral models (8x22B and 8x7B) employed social proof and authority across both types of setups, while commitment and consistency, as well as liking and sympathy, in emotional setup. Anthropic's models (3.5 Sonnet, 3 Haiku, and 3 Opus) varied in employing the principles of social influence, depending on the specific model and setup. In emotional setup, the principle of commitment and consistency was consistently employed at a relatively high level, along with the principle of scarcity by Anthropic's models. Scarcity was also the most frequently utilized principle in rational setup by Claude 3 Opus, which stands out for its use of authority in emotional setup. Across all Anthropic's models, the most commonly employed principles in rational setup were authority and social proof (see Figure 5)."}]}, {"title": "Conclusions", "content": "In response to RQ1, our analyses reveal a paradox: an emotional setup triggers rational linguistic indicators most strongly, suggesting that emotionally framed prompts can still generate complex and persuasive rational arguments. This suggests that emotional persuasion effectively integrates with rational persuasion. Emotional setup is responsible for more expressive language, which can be useful for narratives, storytelling or generating emotionally engaged content. On the other hand, a rational setup can create more factual, less insightful narratives, avoiding extreme viewpoints and ensuring logical argumentation.\nWith reference to RQ2, the baseline setup uses the rational setup more often than the emotional one. It avoids emotional appeals or highly polarized arguments, which could be seen as a strength in terms of objectivity and balance. The baseline produces less cognitive complexity and insightful answers compared to the rational setup but maintains a more cautious and tentative approach. This suggests a tendency to avoid overconfident or overly assertive responses. While this setup may lack the depth of rational persuasion or emotional engagement found in other setups, it demonstrates a preference for balanced responses that avoid emotional manipulation. Nevertheless, the baseline's setup is characterized by a subtle negative affect, particularly anger, and its lean towards sadness rather than pure rationality. That suggests that it still has an inclination to subtle emotional persuasion. Overall, the baseline setup appears to favor a restrained and neutral approach that avoids extremes but still carries emotional nuances in a subtle manner. Addressing RQ3, the findings indicate that LLMs use different social influence principles depending on whether the prompt was emotional or rational. Furthermore, LLMs are able to use each of social influence principles, but to different extents. For emotional prompts, LLMs predominantly used commitment and consistency, liking and sympathy, and social proof principles. It appears that emotional prompts trigger different mechanisms, such as those related to reinforcing the stability and validity of their perspective (commitment and consistency), reinforcing positivity and empathy to sustain interaction (liking and sympathy), and invoking social proof to provide reassurance about a decision (social proof). When prompted with rational persuasion, the models most often employed the principles of authority and social proof. It seems that when LLMs argumentation is based on rationality they rely on facts, research, and the authority of scientists or institutions. Moreover, upon rational prompt when LLMs used social proof most probably they referred to the normative aspect of the majority of social behavior. Different LLM families employed principles of social influence in different ways. This suggest that they may differ in their in how they apply specific persuasive strategies based on their training data and underlying architectural adjustments.\nSeveral limitations must be acknowledged. First, LLM responses vary in length, structure, and number of arguments, sometimes incorporating diverse perspectives that make it difficult to isolate specific persuasive elements and compare responses. Future studies could explore how different prompt designs affect the consistency, structure, and clarity of LLM-generated persuasive responses while maintaining argument diversity. Second, prompts containing preexisting values or implicit biases may have influenced model responses, subtly shaping their content toward certain ideological or normative perspectives rather than a fully neutral persuasive process. Future research could examine how different prompt types impact the ideological framing and neutrality of LLM-generated content. Finally, this study focused on a narrow subset of persuasive principles, limiting the generalizability of findings. Future research could explore a broader range of strategies, analyzing how LLMs dynamically combine multiple techniques in varied contexts. Additionally, further studies should address safeguards against unethical persuasive communication to ensure responsible LLM implementation in fields such as advertising, politics, management, and education."}]}