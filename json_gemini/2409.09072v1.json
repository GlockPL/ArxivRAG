{"title": "Joint Model Assignment and Resource Allocation for Cost-Effective Mobile Generative Services", "authors": ["Shuangwei Gao", "Peng Yang", "Yuxin Kong", "Feng Lyu", "Ning Zhang"], "abstract": "Artificial Intelligence Generated Content (AIGC) services can efficiently satisfy user-specified content creation demands, but the high computational requirements pose various challenges to supporting mobile users at scale. In this paper, we present our design of an edge-enabled AIGC service provisioning system to properly assign computing tasks of generative models to edge servers, thereby improving overall user experience and reducing content generation latency. Specifically, once the edge server receives user requested task prompts, it dynamically assigns appropriate models and allocates computing resources based on features of each category of prompts. The generated contents are then delivered to users. The key to this system is a proposed probabilistic model assignment approach, which estimates the quality score of generated contents for each prompt based on category labels. Next, we introduce a heuristic algorithm that enables adaptive configuration of both generation steps and resource allocation, according to the various task requests received by each generative model on the edge. Simulation results demonstrate that the designed system can effectively enhance the quality of generated content by up to 4.7% while reducing response delay by up to 39.1% compared to benchmarks.", "sections": [{"title": "I. INTRODUCTION", "content": "The Artificial Intelligence Generated Content (AIGC) tech- nique is undergoing rapid advancement, driven by sophisti- cated generative AI models that can produce various contents, including text, images, and videos [1]. Examples of these models include OpenAI's large multimodal model, ChatGPT4 [2], image-centric diffusion models, DALL-E3 [3] and Stable diffusion [4]. In terms of content generation and information visualization, the AIGC technique provides an efficient way to meet diverse user demands [5]. As AIGC pushes the boundary of customized content creation, it also faces significant chal- lenges. The complexity of the models leads to high training costs and resource demands, making it difficult for users with limited resources to obtain quality contents in a cost-effective manner [6], [7]. For instance, the latest video generation model, Sora [8], requires 324 GFLOPs of computing power for training an image of 1024*768 pixels. Therefore, the challenge of high computing demands has become a critical concern in AIGC service provisioning, especially as the demand for imaginary and creative contents grows.\nTo facilitate the availability of the AIGC services and mitigate the challenge of intensive computing requirements, deploying AIGC models on edge servers has become a promis- ing solution. Du et al. proposed the concept of AIGC-as-a- service, where AIGC service providers can deploy AI models on edge servers to provide instant services to users over wire- less networks, offering a more convenient and personalized experience [9]. Leveraging the resource advantages at the edge enhances the accessibility of AIGC services and fosters new venues for real-time and interactive applications. However, edge-assisted AIGC services also introduce new challenges, including optimizing resource allocation, minimizing latency, and ensuring high quality of generated contents [6].\nTo accommodate various user requirements, it is essen- tial to deploy multiple AIGC models at the edge server. While various AIGC models possess distinct capabilities, it is challenging to improve user's experience by only pursu- ing the high efficiency of small models or the high quality of generated contents by large models [10]. Therefore, it is crucial to efficiently assign AIGC models and allocate edge resources considering the following aspects [11]. First, model assignment can be intricate because user tasks have unique performance requirements, which in turn necessitates a dynamic, task-oriented approach to assign the appropriate models [12]-[14]. Second, given the limited computing re- sources available on edge devices, efficient resource allocation strategies should also be investigated. Effective management is essential to balance the competition for computing resources among models and ensure optimal generated quality without introducing long response delay [15]. Many existing studies have considered the deployment of large models for distributed processing at the edge. For instance, Li et al. harnessed the parallelism of multiple edges to improve the generation efficiency of high-resolution images according to the similarity of adjacent diffusion processes [16]. While current studies often emphasize training and deploying AIGC models on the edge [17], they tend to ignore the significant resource requirements and the need for effective resource allocation among these models, which is crucial for handling intense workloads and improving users service quality.\nIn this paper, we take the Text-to-Image generation task, one of the fundamental and popular AIGC services, as an example and propose an edge-enabled AIGC service system, consisting of a user prompt-based model assignment module and an adaptive resource allocation module, aiming to generate high-quality content with low latency. First, we demonstrate significant differences in score distribution across various"}, {"title": "II. MOTIVATION", "content": "In Text-to-Image generation tasks, the prompt refers to the textual description provided by users to generate images. Due to the differences in generation techniques and training datasets used by different AIGC models, the same prompt can generate diverse results under different AIGC models."}, {"title": "A. The Score Distribution of Prompts", "content": "categories of prompts. Based on such observation, a model assignment method is proposed to appropriately assign models to each task. Second, for the diffusion-based generation model, we conduct experiments to analyze how the performance of models and the corresponding denoising process impact both the content quality and time consumed to generate results. Third, an adaptive denoising step selection and computation resource allocation algorithm is designed to optimize the uti- lization of available resources at the edge, thereby effectively reducing time consumption and enhancing content quality. The main contributions of this paper can be summarized as follows.\n\u2022 We conduct experiments on a challenge category-based prompt dataset, revealing the approximate Gaussian dis- tribution of CLIPScore for different categories, as well as the key factors influencing generation quality and time overheads for different generative models.\n\u2022 We propose an edge-enabled AIGC service system that offloads AIGC task requests to the edge. By factoring in computational resource constraints, this system adap- tively assigns models and allocates resources for high- quality content generation in response to user prompts.\n\u2022 We design a probabilistic model assignment method and a simulated annealing-based resource allocation algorithm to solve the model assignment and computation resource optimization problem respectively, realizing the trade-off between the generation quality and the time consumption."}, {"title": "B. AIGC-as-a-Service on the Edge", "content": "To explore the feasibility of deploying AIGC models at the edge, we conduct a text-to-image experiment using the SD1.5 model on an RTX 3080Ti GPU. A total of 200 prompts are randomly selected from aforementioned P2 dataset. For the diffusion-based AIGC models, e.g., SD1.5, image generation involves a gradual denoising process starting from pure Gaus- sian noise. Moreover, the degree of image refinement is deter- mined by the number of denoising steps. Visually, increasing the number of denoising steps progressively enhances image quality, particularly in the details of the image. As shown in Fig. 2, the generation time increases linearly with the number of steps. While the quality significantly improves up to a certain score, the marginal gain of CLIPScore diminishes as the number of steps continues to increase.\nNote that, AIGC models are rapidly evolving, higher quality images often generated at the cost of higher computation resource requirements. Therefore, we conduct the same exper- iment on the upgraded SDXL model [19]. As shown in Fig."}, {"title": "III. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "Consider a scenario where a set of mobile user simul- taneously send requests to the same edge server for AIGC services. As shown in Fig. 3, a set of generative models are deployed to effectively meet the users' diverse requirements. After receiving the requests, the edge assigns the model for each prompt of the user. Then, with selected denoising steps, generation process is performed on the edge with allocation of computing resources for each model. Finally, the generated contents are returned to the mobile user. Considering the unknown content quality generated by the AIGC models and the prior knowledge of the score distribution from different categories of prompts, we adopt a probabilistic model assign- ment strategy to efficiently assign the most suitable model for each user. Then, we design an adaptive denoising step and computation resource allocation algorithm to efficiently utilize the computation resources on the edge server."}, {"title": "B. Score and Latency Model", "content": "The set of models deployed on edge, $\\mathcal{M} = \\{1, ..., m,..., M\\}$, is considered to have varying generation abilities. The users send prompt requests with category labels through the device, which is defined as the task set $\\mathcal{N} = \\{1,...,n,...,N\\}$. Without loss of generality, task requests arrive at the edge at the beginning of each time slot.\n1) Generated score model: As observed in Section II, the denoising steps, $s_m$, has a crucial impact on the quality of the generated image (i.e., CLIPScore). $C_m$ is denoted as the CLIPScore for the n-th task of processing $s_m$ steps by model m. We introduce a binary variable, $x_m$, to indicate whether model m is selected by the n-th task. Therefore, the CLIPScore for the n-th task can be represented as:\n$C_n = \\sum_{m=1}^M x_m C_m(s_m)$.\n2) Latency model: For an AIGC service request, the system delay includes prompt transmission delay, $d_1$, and AIGC model inference delay, $d_2(s_m, \\gamma_m)$, which is determined by the selected steps and the resources allocation. Specifically,\n$d_2(s_m, \\gamma_m) = \\alpha_m \\cdot d^*(s_m)$,\nwhere $\\alpha_m = \\frac{\\Gamma}{\\gamma_m}$ denotes the ratio of the total computation resource $\\Gamma$, compared to the resource allocated $\\gamma_m$ by the model in TFLOPS. $d^*(s_m)$ represents the relationship between the number of denoising steps and inference latency using available resources $\\Gamma$. The transmission time of the generated image from the model back to the user is denoted as $d_3$. Then, the overall delay of the n-th task can be formulated by:\n$D_m(s_m, \\gamma_m) = d_1 + d_2(s_m, \\gamma_m) + d_3$.\nAs the time consumption of AIGC model inference $d_2$ is significantly larger than the two transmission delays, $d_1$ and $d_3$ are thus ignored in our system."}, {"title": "C. Problem Formulation", "content": "In our edge-enabled AIGC service system, each prompt re- quested from the user needs to be assigned with a model m for content generation. Besides, at the beginning of each time slot, multiple models run simultaneously to take advantage of all available computation resources. Therefore, the computation resources $\\gamma$ and the appropriate number of denoising steps $s_m$ should be carefully determined for each model. In order to achieve a better trade-off between generation quality and time consumption for the tasks handled by each model, we"}, {"title": "D. Probabilistic Model Assignment", "content": "According to the analysis in Section II, even prompts within the same category exhibit differences in CLIPScore, and different models distinctly affect both the generation quality and time consumption. Therefore, we propose adopting specific model assignment methods to enhance the overall utility of the tasks. We take three models with different generation capabilities and computational costs as examples, named small, medium, and large model, where the larger model generates better results with longer delay. Then, we set two thresholds, dividing the CLIPScore into three intervals. Prompts that achieve different scores on the medium model are reclassified according to the score interval into three score levels. These are then processed separately on the small and large models, with the result presented in Fig. 4. We observe that prompts with low CLIPScore on the medium model can save time on the small model and do not cause the loss of average scores. Besides, prompts that score high on the medium model have a higher cost of time on the large model, but in turn get a significant CLIPScore gain.\nIn real-world applications, it is difficult to accurately profile the score level for prompts of different categories with each model, especially with those that require huge computation overhead. Therefore, given the distribution curves of prompt CLIPScore for different categories on the medium model, we consider using the expected score probability for the model as- signment of different categories. For example, when the score of a prompt is expected to be lower than 21 on the medium model, it is considered as a low score level prompt and will be assigned to the small model with greater probability. In other words, according to the defined score intervals, the probability of each prompt category being assigned to each model is calculated as the cumulative probability density of its score distribution on the medium model within each interval.\nSpecifically, consider the assignment strategy when there are three performance models m\u2208 [1,2,3]. The prior score distribution of four categories $A_{j \\in [1,2,3,4]}$ on the medium model 2 follows Gaussian distribution, and the mean $\u00b5_j$ and standard deviation of are known in advance. Therefore, the probability $P_m$, that category Aj is assigned to model m can be calculated according to:\n$P_m = \\int_{h_1}^{h_2} \\frac{1}{\\sqrt{2\\pi\\sigma_j^2}}e^{-\\frac{(x-\\mu_j)^2}{2\\sigma_j^2}}dx$,\nwhere $h_1$ and $h_2$ are defined on different models as:\n$h_1, h_2 = \\begin{cases} 0, X_1 & m = 1 \\\\ X_1, X_2 & m = 2 \\\\ X_2, \\infty & m = 3 \\end{cases}$"}, {"title": "E. Step Selection and Resource Allocation", "content": "Instead of selecting steps individually for each task, we consider allocating the same number of steps sm and compu- tational resources Ym to each model based on the difference in the number of tasks assigned to each model. In order to solve this problem, we propose a step selection and resource allo- cation algorithm based on simulated annealing (SA), aiming to efficiently search for sub-optimal solutions. As presented in Algorithm 1, it iteratively seeks better solutions by setting policies to modify the current solution, and accepts them only if they improve or meet the Metropolis criteria. The utility function in our algorithm is denoted as follows:\n$U = \\frac{1}{N} \\sum_{n=1}^N [C_m(s_m) - w \\cdot D_m (s_m, \\gamma_m)]$,\nwhere $C_m(s_m)$ is the estimated score function. Among them, $C_m(s_m)$ and $D_m(s_m,\\gamma_m)$ are different for different models. The temperature parameter gradually decreases until the termi- nation condition is reached, and the rate of decrease is related"}, {"title": "IV. PERFORMANCE EVALUATION", "content": "In this section, we evaluate the performance of our proposed system. The experimental settings and results are as follows."}, {"title": "A. Experimental Setting", "content": "In the experiment, we take the Text-to-Image generation task as example. Besides, the edge server is deployed with models featuring varying generation abilities. Specifically, three mod- els from the Stable Diffusion series are selected, i.e., SDXL- Turbo [21], SD1.5, and SDXL. While these models share similar structures, they exhibit different trade-offs between the quality and time required for generating results, primarily due to the variations in their training datasets and amount of parameters. We conduct experiments using P2 dataset, the details of which have been presented in Section II.\nMoreover, the AIGC model for receiving prompts and generating images is deployed on the NVIDIA GeForce RTX 3080 Ti GPU as the edge server. The utility function weight w is set to 0.2. The CLIPScore thresholds 21 and 22 are set to 29.5 and 33.8. The step set is {10, 14, 18, 22, 26, 30, 34, 38, 42}. In particular, since the small model SDXL-Turbo is capable of producing good results in 1-4 steps, we consider fixing its denoising step number to 1. We compare our system with the following strategies:\n\u2022 Direct-assignment: This method assigns prompts of the same category to a single model, regardless of score differences within that category.\n\u2022 Random-assignment: This method randomly assigns each prompt to one of three models, giving each category an equal chance of selection.\n\u2022 Equal-allocation: In this method, all the computation resources of the edge server are equally allocated to each model, and only the number of denoising steps is selected.\n\u2022 Optimal-step: The method selects the near-optimal step number for each model to guarantee the highest score, while only the computation resources are allocated."}, {"title": "B. Performance of Probabilistic Assignment", "content": "We compare the proposed Probabilistic-assignment with Direct-assignment and Random-assignment. The average CLIPScore generated on each model is shown in Fig. 5(a). Compared with two methods, our proposed method improves CLIPScore from 0.2 to 2.4, especially in SDXL model. In particular, although the Random-assignment assigns more high score level prompts to the small model, which increases the average score of the tasks handled by the small model, it also significantly decreases its overall score on the large model. Conversely, the Direct-assignment overlooks the variation in score levels within the same prompt category, thus limiting the scoring potential across different models, resulting in its score not being improved. Our method utilizes the scoring potential of each prompt itself, effectively assigning each prompt to the appropriate model based on the scoring probability of different categories. As shown in Fig. 5(b), our method demonstrates an improvement in overall utility, achieving up to a 2.5% increase compared with other methods at different time slots. It indicates that our method achieves a trade-off between score quality and time consumption. Apart from that, the task CLIP- Score CDF of the three methods is shown in Fig. 5(c). It can be seen that the proposed method improves the overall score level, which indicates that Probabilistic-assignment strategy is beneficial to obtain higher scores."}, {"title": "C. Performance of Step Selection and Resource Allocation", "content": "We then compare the time consumption and average CLIP- Score of our proposed step selection and resource allocation method with Equal-allocation and Optimal-step. As shown in Fig. 6, compared with the Optimal-step, the proposed method achieves less time consumption on each model, saving an average of 30.2% in time consumption. This is due to the fact that the Optimal-step method selects more denoising steps to achieve higher quality results at the cost of greater time overhead. In addition, the Equal-allocation shows lower time consumption for the small model. However, this is due to the lack of consideration given to the varying resource requirements of different models. As a result, the larger models experience significantly higher time consumption. Our method saves 39.1% time consumption compared to Equal-allocation. In terms of CLIPScore in Fig. 7, our proposed method approaches the Optimal-step while improving over the Equal- allocation on all models. Moreover, as shown in Fig. 8 the proposed method respectively improves the overall utility by 17.8% and 12.7% compared with the other two methods. The results demonstrate that the proposed method realizes reason- able adaptive allocation of steps and resources, and obtains a balance between generation quality and time consumption."}, {"title": "V. CONCLUSION", "content": "In this paper, we have proposed an edge-enabled AIGC service system that offloads intensive AIGC tasks to the edge for model assignment and resource allocation to provide users with efficient and personalized AIGC services. The system performs a probabilistic model assignment method to assign appropriate models to different categories of prompts. Then, it adaptively selects the number of denoising steps and allocates computation resources for models based on the task requests received by each AIGC model. Simulation results have demon- strated that the proposed system effectively optimizes resource allocation, achieving the trade-off between generation quality and time consumption across different performance models. For future work, we will explore the AIGC service system for multiple types of content generation applications."}]}