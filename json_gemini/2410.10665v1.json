{"title": "Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers", "authors": ["Aivin V. Solatorio", "Gabriel Stefanini Vicente", "Holly Krambeck", "Olivier Dupriez"], "abstract": "Artificial Intelligence (AI), particularly large language models (LLMs), holds the potential to bridge language and information gaps, which can benefit the economies of developing nations. However, our analysis of FLORES-200, FLORES+, Ethnologue, and World Development Indicators data reveals that these benefits largely favor English speakers. Speakers of languages in low-income and lower-middle-income countries face higher costs when using OpenAI's GPT models via APIs because of how the system processes the input-tokenization. Around 1.5 billion people, speaking languages primarily from lower-middle-income countries, could incur costs that are 4 to 6 times higher than those faced by English speakers. Disparities in LLM performance are significant, and tokenization in models priced per token amplifies inequalities in access, cost, and utility. Moreover, using the quality of translation tasks as a proxy measure, we show that LLMs perform poorly in low-resource languages, presenting a \"double jeopardy\" of higher costs and poor performance for these users. We also discuss the direct impact of fragmentation in tokenizing low-resource languages on climate. This underscores the need for fairer algorithm development to benefit all linguistic groups.", "sections": [{"title": "1 Introduction", "content": "Given their transformative impact on society, it is imperative to investigate the potential inequalities stemming from large language models. Like previous general-purpose technologies such as the steam engine, electricity, and the Internet, LLMs can significantly alter economies, cultures, and social frameworks [1]. However, they also have the capacity to intensify existing disparities or generate new ones. LLMs are trained on extensive corpora of Internet data that mirror the global digital footprint [2]. While these models compress vast textual information to form representations of the world, their dependence on such data subjects them to inherent biases, particularly those influenced by the digital divide [3]. As a result, discrepancies in Internet content coverage lead to LLMs having an uneven impact on different demographic groups.\nEnsuring equitable access to technology is essential. Yet, specific technical barriers, like the tokenizer an integral part of LLMs responsible for processing input texts\u2014 impede this objective. Tokenizers, much like LLMs, are trained on text corpora to learn the distribution of syntactic fragments or tokens. Customizing tokenizer training to particular corpora improves its application effectiveness by pre-learning syntactic characteristics and enhancing processing efficiency [4, 5]. However, prior research has demonstrated that tokenizers employed by services such as OpenAI create inequalities for non-English speakers [6].\nWhen processed by tokenizers, non-English languages often break down into more tokens than English this is referred to as fragmentation [6]. This issue underscores the lack of linguistic diversity in the datasets used to train these tokenizers. Since a single token is typically the unit of pricing for most paid LLM API services, languages that experience greater fragmentation will incur higher costs [7]. Thus, addressing linguistic diversity in algorithmic development is crucial to ensure equitable access to technology.\nThe socioeconomic effects of LLMs are still not well quantified. However, existing studies suggest that languages spoken primarily in countries with a lower Human Development Index (HDI) face more significant fragmentation [8]. This indicates that LLMs may impart uneven impacts influenced by geographical and socioeconomic factors since elevated fragmentation directly translates to increased usage cost.\nThe climate impact of LLMs has also been investigated [9\u201312]. As demand for more powerful AI systems increases, the corresponding emissions associated with training and the use of models are concerning [13, 14]. Although AI and LLM are promising, their impact on climate remains grim [15]. In addition, the discussion of how AI can impact water resources has also been studied [16]. Fortunately, large companies that conduct model training have net zero commitments and are taking steps to offset carbon emissions from these activities [17, 18].\nThis research adds to the growing body of evidence on the socioeconomic challenges posed by LLMs, emphasizing that languages spoken by economically disadvantaged populations face a \"double jeopardy\": higher costs for LLM usage and lower performance outcomes. Speakers of these languages are disproportionately affected by tokenization inefficiencies, which inflate the usage cost while delivering suboptimal results."}, {"title": "2 Data", "content": "This section offers a detailed overview of the different data sources utilized in our analysis."}, {"title": "2.1 FLORES-200 and FLORES+", "content": "We use the FLORES dataset, an extensive collection of concise excerpts drawn from Wikipedia articles on various topics. Each excerpt has been translated into all included languages, making this dataset particularly valuable for multilingual research and applications such as machine translation, natural language processing, and linguistic studies. We utilize a combination of the FLORES-200 dataset [19] and the FLORES+ dataset [20], both curated by the Open Language Data Initiative. The FLORES+ dataset includes 12 additional language variants compared to the original FLORES-200. Hereafter, we will refer to the combined dataset as FLORES-200P."}, {"title": "2.2 Ethnologue", "content": "We supplemented the FLORES-200P with data from the Ethnologue platform [21]. Ethnologue provides extensive information on global languages. We gathered data on the estimated number of speakers, the level of digital language support, and the language family. Additionally, we collected information on the countries where each language is spoken and the respective number of speakers. This enabled us to study the relationship between countries and their spoken languages. Overall, we have successfully gathered data for 194 out of the 200 languages in the FLORES-200P dataset."}, {"title": "2.3 World Bank World Development Indicators", "content": "We use data from the World Bank's World Development Indicators (WDI) to add socioeconomic insights [22]. For comparing economic performance and living standards across countries, we use the GDP per capita in current US$ indicator (NY.GDP.PCAP.CD). The annual population growth rate (SP.POP.GROW) helps standardize the number of speakers per language from Ethnologue. Additionally, we obtained the World Bank's country classification by income level through their Indicators API [23]."}, {"title": "3 Anatomy of Large Language Models", "content": "Prior to our analysis, this section provides a brief synopsis of the key elements of LLMs specifically, the transformer architecture. Additionally, we will explore the tokenization process and its role in perpetuating inequality within LLMs, especially affecting low-resource languages. This inequity poses notable challenges for non-English speakers, which will be thoroughly examined in this paper."}, {"title": "3.1 Transformer Architecture", "content": "The core of LLMs is the transformer architecture, which has revolutionized the processing and modeling of sequential data [24]. Unlike traditional recurrent neural network (RNN) models, transformers use a self-attention mechanism to assess relationships between all tokens in a sequence at once, rather than in order. This advancement helps in capturing long-range dependencies better, greatly improving performance across various natural language processing (NLP) tasks.\nLLMs, typically structured as decoder-only transformers like Generative Pre-trained Transformers (GPTs), are trained to predict the next token in a sequence [25]. These models consist of multiple transformer blocks with multi-head self-attention and position-wise feedforward networks. Self-attention assigns importance scores to each token, helping the model grasp context and meaning. Residual connections and layer normalization within each block ensure stable training. This design enhances computational efficiency through parallelization and achieves high accuracy and coherence in language modeling tasks.\nBy training on extensive text corpora, these models discern underlying language patterns and relationships, which enables them to generate coherent, contextually appropriate text. The transformer architecture has revolutionized natural language processing, fostering the creation of advanced language models that emulate human abilities in text comprehension and generation. Its proficiency in managing long-range dependencies and its suitability for parallel processing have greatly enhanced model performance and scalability, propelling progress in applications like conversational agents, automated summarization, and language translation."}, {"title": "3.1.1 Input Embeddings", "content": "A transformer model's input is usually a sequence of tokens from the tokenization process, with each token represented as a vector. Positional embedding is added to include token positions in the sequence, forming an effective initial input for the model. These token embeddings, learned during training, encapsulate the semantic and syntactic details of each token, aiding in text comprehension and processing. The embeddings then go through transformer blocks for transformations that capture their complex interrelationships."}, {"title": "3.1.2 Self-attention Mechanism", "content": "The self-attention mechanism allows the model to assess the importance of each token in a sequence relative to the others. It computes a weighted sum of the token representations, where the weights represent how relevant each token is to the others in the sequence. This enables the model to dynamically focus on different parts of the input, capturing long-range dependencies between tokens and improving its understanding of context."}, {"title": "3.1.3 Feedforward Neural Network Layers", "content": "The feedforward neural network layers refine the output from the self-attention mechanism by applying nonlinear transformations, enabling the model to capture more complex patterns in the data. Each transformer block includes residual connections and layer normalization, which enhance training stability and improve overall model performance by preserving important features and avoiding vanishing gradients."}, {"title": "3.2 Tokenization", "content": "Tokenization is crucial for transformer models to handle text data properly. It breaks down text into tokens, which are then turned into numerical representations. This process is vital for the model to interpret and produce text precisely, affecting the detail it can capture.\nTokenizers, specialized algorithms, split raw text into tokens that can be words, subwords, or characters [26]. Subword tokenization, commonly used in LLMs, strikes a balance between vocabulary size and the representation of rare words, enhancing the model's ability to handle out-of-vocabulary words and morphological variations. An example of this is Byte-Pair Encoding (BPE) [27]. Customized tokenizers for other LLM applications have also shown improved performance [28, 29].\nThe tokenizer splits the text based on predefined rules or learned patterns, creating structured input for the model. The text may undergo preprocessing like lowercasing, punctuation removal, and handling special characters to normalize it, though sometimes it is processed as-is. Each token receives a unique identifier mapped to an embedding vector, which acts as a dense numerical representation carrying its semantic information for the model's processing.\nTokenization can be particularly challenging for languages with complex structures or limited resources. Ineffective tokenization can harm model performance, so it is vital to optimize this process for better accuracy and efficiency in transformer models."}, {"title": "4 Methodology", "content": "This section details our methods for creating linguistic and socio-economic indicators to measure economic disparities in access to enterprise LLM technologies between non-English and English languages. We propose a metric for assessing tokenization fragmentation costs across languages and outline our approach for evaluating LLM performance in different languages. Combining these indicators, we highlight the challenges non-English speakers face in accessing and using LLMs."}, {"title": "4.1 Linguistic and Socio-economic Indicators", "content": "To measure the economic disparity in access to language technologies, we employ a range of linguistic and socio-economic indicators. First, we outline our strategy for normalizing the number of speakers per language. Subsequently, we detail our approach to developing a weighted wealth of linguistic indicators and associating languages with income levels, thereby establishing a connection between language and economic factors."}, {"title": "4.1.1 Number of Speakers for Each Language", "content": "Ethnologue is an extensive database offering in-depth details about languages spoken globally [21]. It notably includes data on the number of speakers per country for each language, although this information might come from various sources and different periods."}, {"title": "4.1.2 Estimate GDP per Capita for each Language", "content": "To incorporate an economic aspect into our study, we establish a measure to assess the wealth tied to each language. Using the harmonized speaker counts, $S_{i,j}$, calculated earlier in Eq. 1, we consider languages spoken in various countries.\nTo calculate a population-weighted GDP for each language, we use the per capita GDP in current USD (NY.GDP.PCAP.CD) for each country. This approach offers a detailed measure of the economic impact tied to each language, enabling accurate comparisons of economic contributions among languages. The indicator is calculated as follows:"}, {"title": "4.1.3 Classify Income Level for Each Language", "content": "Languages traverse boundaries, reaching from individual speakers to entire regions and countries. The World Bank Group categorizes the world's economies into four income levels: low, lower middle, upper middle, and high [30]. To proportionately reflect the income level of language speakers, we use this classification to define an indicator that represents the population-weighted average income level of the countries where the language is spoken, on a scale from 0 (low) to 1 (high). For example, a value of 1 would mean that all countries where a particular language is spoken are classified as high-income. The income level classification for each language is derived as follows:"}, {"title": "4.2 Quantifying Fragmentation Cost", "content": "Lastly, we describe the framework for assessing fragmentation cost in LLM systems and detail our approach for evaluating LLM performance across different languages, particularly in translation tasks."}, {"title": "4.2.1 Tokenization Premium per Language", "content": "We use the concept of premium from [6] to systematically assess how tokenizers process equivalent sentences in various languages. Consider sentence $S_A$ in language A and its translation $S_B$ in language B. The ratio\nThis indicator highlights differences in tokenization efficiency across languages and related costs compared to English. A higher premium means less efficient processing, leading to more fragmentation and potentially higher user costs, worsening socioeconomic disparities. By measuring this premium, we can identify which languages struggle with tokenization and evaluate its impact on LLM accessibility and performance, guiding efforts to improve tokenization strategies."}, {"title": "4.3 FLOPs as an Indicator of the Climate Impact of LLMs", "content": "FLOP count, or floating point operations, is one of several components used to estimate the carbon emissions associated with LLMs. Other key factors include the energy efficiency of the hardware, the cooling and infrastructure of the data centers, and the energy mix, whether the electricity that powers the computations comes from renewable or non-renewable sources [10, 12]. Among these, the FLOP count serves as a valuable proxy indicator for the computational requirements of LLMs, offering insights into their potential climate impact.\nAn indicator for estimating the inference cost of LLMs in terms of FLOP count has been presented in the seminal paper on the scaling laws of LLMs [31] as well as in the recent literature attempting to quantify a holistic computation of carbon emissions related to the technology [10]. It is approximated as follows:\nwhere $F_{IC}$ is the estimated FLOP count, $P$ represents the count of non-embedding parameters in the LLM, while $D$ is the number of tokens processed. The dense parameter count is used for LLMs implemented as a mixture of agents (MoE). In the accounting model presented in [10], the FLOP count is directly proportional to the total carbon emission. This accounting allows us to mathematically show that fragmentation directly contributes to the climate impact of LLMs since $D$ is the total number of tokens processed."}, {"title": "4.4 Translation Tasks as a Proxy for LLM Performance", "content": "The indicators discussed earlier aim to reveal the inequalities in LLMs due to tokenizer choices, leading to fragmentation. As LLM usage is priced per token, these differences cause disparities. This section examines another inequity: the model's ability to perform tasks effectively across various languages.\nWe use language translation to evaluate LLMs' performance across different languages, focusing on low-resource languages. Although past assessments have been done [32, 33], they rarely target our languages of interest. We designed an experiment to test the LLM's ability to translate low-resource languages into English, serving as a measure of its multilingual capabilities."}, {"title": "4.4.1 Translation Task", "content": "We select various languages from the FLORES-200P dataset to evaluate the translation performance of the LLM. Our selection focuses on languages primarily spoken in low- and lower-middle-income countries, as well as those widely spoken globally. This diverse array covers multiple linguistic families and regions, ensuring a thorough assessment of the LLM's translation capabilities.\nWe take sentences from the FLORES-200P dataset's selected source languages and have the LLM translate them into English. Translating at the sentence level maintains the independence of each translation. To keep the experiment consistent, we use a basic system prompt. While improved performance through prompt engineering is documented [34, 35], we choose simplicity to avoid any prompt influence on the LLM's performance. The system prompt is detailed in Listing 1."}, {"title": "4.4.2 Measuring Translation Quality", "content": "Once the sentences are translated, we have the LLM compare them to their original English counterparts. We first evaluate translation quality through a binary classification task, where the LLM identifies each translation as correct or incorrect. This assessment helps measure the LLM's effectiveness in translating from the source language to English.\nWe developed two different versions of this evaluation approach to ensure robustness. The initial version simply prompts the LLM to decide whether the translation is accurate or not a form of zero-shot prompting that relies heavily on the intrinsic reasoning capabilities of the LLM.\nThe second method includes a chain-of-thought component, where the LLM first explains its decision before delivering a verdict. This approach has been found to improve the quality of reasoning in LLM [36]."}, {"title": "4.5 Comparison of GPT-4 and GPT-40 in Tokenization and Translation", "content": "OpenAI recently introduced GPT-40, claiming enhanced multilingual capabilities. They state, \u201cGPT-40 has the best vision and performance across non-English languages of any of our models\" [39]. Furthermore, improvements in tokenization compression have been claimed [40]. We evaluated GPT-4o against GPT-4 in tokenization and translation tasks to verify these enhancements.\nWe use the same sentences for both LLM versions to ensure a fair comparison. The performance of GPT-4 and GPT-40 is evaluated using the previously described methodology. We compare the ratings given by the models to assess translation quality improvements and use their respective tokenizers to evaluate enhancements in tokenization."}, {"title": "5 Results", "content": "Our evaluation of the performance differences of LLMs across various languages, using English as a reference point, focuses on these main areas: (i) how fragmentation costs in tokenization premium relate to the economic well-being of speakers, (ii) the estimated number of people affected by the disparity, (iii) the variability in LLM performance across different languages, and (iv) assessing the progress made in LLMs."}, {"title": "5.1 \"Poor Languages\" Pay More", "content": "A key aim of the paper is to examine and measure the link between the tokenization premium described in Eq. 6 and the population-weighted average wealth across different languages formalized in Eq. 3. Gaining this understanding helps shed light on the economic inequalities in LLM access and the effect of tokenization on individuals from diverse socio-economic conditions."}, {"title": "5.2 A Lower-Middle Income Trap in LLMs?", "content": "With data on countries where specific languages are spoken, we can evaluate how the tokenization premium is distributed across different income levels and estimate the number of speakers impacted."}, {"title": "5.2.1 GPT-4 Tokenizer: The Population Impacted", "content": "The GPT-4 model tokenizer results show that high-income countries face much lower tokenization costs. In these regions, about 38.89% of people speak English, and 37.51% have premiums ranging from 1 to 2 times. A very small fraction (around 0.02%) faces premiums of 8 to 10 times, with an even smaller group incurring 10 to 16 times the cost."}, {"title": "5.2.2 GPT-40 Tokenizer: The Population Impacted", "content": "In contrast, the data using the GPT-40 tokenizer appear promising. In high-income groups, about 38.89% of the population faces a premium of 0 to 1 time the English tokenization cost, and approximately 59.83% fall within the 1 to 2 times range. Only 1.19% face premiums between 2 and 4 times, and less than 0.01% experience premiums between 4 and 16 times. This aligns with previous results from the GPT-4 tokenizer, showing that high-income countries consistently have lower tokenization premiums."}, {"title": "5.3 LLM Performance Across Languages", "content": "While we have explored the economic effects of LLMs due to varying tokenization costs among languages, it is equally vital to consider their performance across different languages. Paying higher costs could be justified if the model consistently delivers high-quality results in all languages. To explore this matter, we evaluate the performance of LLMs across a varied sample of languages to determine if there are performance gaps that may exacerbate the disadvantages for speakers of languages with higher costs. Identifying such disparities is essential, as poor model performance, along with increased tokenization expenses, would further increase the inequities experienced by these language communities.\nWe utilize the translation task as a proxy for assessing LLM performance, as outlined in Section 4.4. The selection of languages is based on the following criteria: (i) the top 3 languages with the highest premiums from low-income countries, (ii) the top 3 languages by total population with at least a 4x premium in low-income countries, (iii) the top 3 languages with the highest premiums from lower-middle-income countries, (iv) the top 3 languages by total population with at least a 4x premium in lower-middle-income countries, and (v) the top 5 languages by total global population. This selection process aims to identify languages that are particularly disadvantaged due to a combination of high tokenization costs, economic factors, and large speaker populations, ensuring that our focus is on the most affected groups."}, {"title": "5.4 Improvements in Premium Costs and Performance", "content": "Our analysis shows that tokenization premiums have decreased from GPT-4 to GPT-40 for most languages. Only Santali (sat) and Tamazight (tzm) see increases in tokenization premiums. The median reduction is 20.93%, with the average decrease being 30.13%. Santali's premium rose by 7.44%, while Tamazight's increased slightly by 1.06%. This indicates improved tokenization efficiency in GPT-40, lowering costs for non-English languages. Notably, languages with population-weighted wealth classified as lower-middle-income see a larger overall improvement in tokenization premium.\nThese results are promising, indicating progress in reducing tokenization cost disparities across languages. The overall decrease in premiums shows better tokenization efficiency, making LLMs more accessible and affordable for non-English speakers. Yet, the rise in premiums for some languages emphasizes the need for continued research to tackle their specific challenges.\nIt is also important to note that although GPT-40 shows promising improvements in tokenization premiums, its performance in low-resource languages is still lacking."}, {"title": "6 Discussion", "content": "The findings show that users of low-resource languages face a double jeopardy with LLMs. They not only bear higher tokenization costs, which disproportionately impact lower-middle and low-income groups, but also experience poor performance in translation and processing with these models, even with efficiency gains in GPT-40.\nThe data indicate that, although there have been some successes in lowering tokenization premiums, specifically with the GPT-40 model, these benefits are uneven. Lower-middle-income languages, in particular, bear the brunt of high tokenization costs, exacerbating their existing economic challenges.\nWhile lower tokenization premiums for some languages are a step forward, the high costs for low-resource languages underscore the need for more tailored solutions. For many speakers of these languages, high tokenization fees can be especially restrictive, limiting access to advanced language technologies like LLMs.\nThe problem extends beyond tokenization's economic impact. Even with reduced tokenization premiums, LLMs perform poorly on tasks such as translation in low-resource languages. This leads to higher computational costs and subpar model performance for these speakers. For instance, although the GPT-40 model offers lower tokenization costs, it still struggles with accurate translations in many low-resource languages, negating any cost savings due to its less reliable outputs.\nThis \"double jeopardy\"-higher tokenization costs combined with poorer model performance creates a significant barrier for low-resource language speakers, limiting their ability to benefit from advancements in LLMs. It highlights the inherent inequities in current LLM systems. While high-resource languages, particularly those spoken by high-income groups, enjoy both low costs and high model performance, low-resource language speakers face both economic and functional disadvantages.\nThis could further entrench existing divides, where only a select group of languages, typically tied to wealthier populations, reap the full benefits of cutting-edge AI technologies such as LLMs-echoing the disparities seen during the rise of digitalization.\nAddressing this dual challenge requires sustained research and development to improve the proficiency and effectiveness of LLMs across diverse languages, as well as a dedicated effort to gather high-quality data for under-resourced languages. Important strategies include enhancing the availability of training data, fine-tuning models for specific linguistic traits, and developing cost-efficient tokenization algorithms. Additionally, creating policies that involve marginalized communities in AI design and deployment is crucial for ensuring equitable distribution of LLM benefits."}, {"title": "6.2 Tokenization Inequities Increase the Climate Impact for Everyone", "content": "Inefficiencies in tokenization, particularly for languages with complex morphology or those lacking robust linguistic resources, present significant social and environmental challenges. Fragmentation during tokenization inflates token counts, increasing the computational burden as shown in Equation 7, especially for low-resource languages. These inefficiencies have tangible consequences, affecting the accessibility of language technologies and their broader environmental impact.\nAs discussed in Section 4.3, the number of tokens processed is directly proportional to the carbon footprint of a model. LLMs rely heavily on tokenization to segment input text. When tokenization leads to excessive fragmentation, it results in a proportionally increased computational cost, making LLM-based applications more resource-intensive and expensive. Moreover, this inefficiency heightens the environmental toll by requiring more energy to process longer token sequences.\nAddressing these inefficiencies requires innovations in tokenization algorithms that can better accommodate diverse linguistic structures. By reducing token fragmentation, we can lower the FLOP count and, consequently, the carbon emissions associated with LLMs. This would contribute to global efforts to mitigate the climate impact of AI technologies and promote linguistic equity by making language models more accessible and cost-effective for speakers of diverse languages.\nWhile the environmental impact of LLMs is influenced by various factors such as hardware energy efficiency and data center infrastructure the efficiency of the models themselves and their related components remains a key determinant. As LLMs continue to scale in size and usage, addressing tokenization inefficiencies becomes increasingly urgent. Improvements in this area would benefit everyone by reducing the global carbon emissions associated with LLMs. Therefore, one of the pathways toward creating more sustainable and equitable LLMs is through optimizing both the technical and linguistic aspects of tokenization. Continuous efforts to refine tokenization algorithms, aimed at reducing the total number of tokens these tokenizers produce across all languages, including English, can significantly mitigate the climate impact of AI technologies."}, {"title": "6.3 Delocalization of Cost to Access", "content": "Besides the LLM-intrinsic issues detailed in this paper, there are additional factors that exacerbate access challenges and inequalities in cloud-based AI services. A major concern is the delocalization of costs, where global service providers, relying on major currencies, create substantial barriers for users in low- and lower-middle-income countries.\nProviders such as OpenAI, AWS, Microsoft Azure, and Google Cloud Platform (GCP) typically charge in major currencies, primarily the US dollar (USD). While this simplifies global operations, it poses significant challenges for users whose local currencies fluctuate against the USD. Forex volatility can sharply increase cloud service costs for businesses and individuals in economically unstable regions.\nThis issue is particularly acute in low- and lower-middle-income countries, where currency instability is often higher. When local currencies depreciate against the USD, the costs of accessing LLM services through cloud platforms can rise dramatically. For instance, a company in such a country may find that weakening currency renders once-affordable services prohibitively expensive, further straining already-limited resources.\nThese rising costs widen the economic gap in accessing advanced technologies. Businesses and individuals in low- and lower-middle-income countries are already disadvantaged by higher tokenization premiums for less commonly spoken languages. The added impact and uncertainty of forex-driven cost hikes exacerbate this divide, presenting dual challenges: elevated premiums and unpredictable service costs.\nSuch financial pressures limit access and potential of businesses in these regions from innovating or competing globally. While wealthier nations enjoy stable, affordable cloud services, lower-income regions face cost inconsistencies that hinder their ability to engage with cutting-edge AI technologies.\nThe long-term effects of rising cloud service costs are substantial. Many businesses in low- and lower-middle-income countries may struggle to afford these services, hampering their ability to leverage LLMs and broader AI tools. This financial strain could discourage startups, schools, and local businesses from adopting AI, stifling innovation and fostering a \"brain drain\" as local talent turns away from costly AI projects, further hindering technological growth in these regions.\nAdditionally, businesses may be driven to seek out cheaper, lower-quality options, which could offer reduced performance and scalability. This would further impede these regions from fully participating in the global digital economy, reinforcing economic disparities.\nTo address the combined challenges of forex fluctuations and tokenization premiums, service providers and policymakers should explore solutions to make cloud services more affordable in low- and lower-middle-income countries. One potential strategy is pegging costs to local currencies, which could stabilize pricing and ensure more consistent service fees.\nGovernments could also play a role by offering subsidies or incentives to businesses that rely heavily on cloud services. Encouraging the growth of regional cloud providers that bill in local currencies and are less vulnerable to international currency fluctuations could provide a more stable and cost-effective solution for users in low- and lower-middle-income economies."}, {"title": "6.4 A Subtle Risk of Inaction", "content": "A substantial yet frequently unacknowledged risk of not improving LLM performance for low-resource languages is the potential contamination of the internet with subpar or incorrect content in these languages [41]. As LLMs continue generating text that appears to come from low-resource languages, but are trained on limited and unreliable data, the chances of producing flawed translations or erroneous outputs increase. This risk grows when models cannot accurately capture the nuances and complexities of these languages, leading to outputs that may seem correct but are often inaccurate or misleading. When these inaccuracies are disseminated online, they contribute to an expanding pool of low-quality linguistic data, which can further exacerbate the performance challenges of LLMs in future updates.\nThis concern is particularly pressing because LLMs rely heavily on internet-sourced data for training. If inaccurate or subpar content in low-resource languages proliferates online, it risks being incorporated into future training datasets, thereby perpetuating a cycle of substandard performance. As more flawed material is produced and shared, LLMs will find it increasingly difficult to generate accurate text in these languages, resulting in a self-perpetuating feedback loop."}, {"title": "7 Conclusion", "content": "The increasing capabilities and utility of Large Language Models (LLMs) present a unique opportunity to bridge global knowledge and access gaps. However, for speakers of low-resource languages, this potential remains largely unrealized, resulting in a double jeopardy: they face both elevated tokenization costs and inferior model performance. Although advancements like GPT-40 have minimized tokenization premiums to some extent, these gains are unevenly distributed, continuing to exclude speakers from lower-income and lower-middle-income nations. About 1.5 billion speakers in lower-middle-income countries face tokenization costs 4 to 6 times higher than those for English. This dual burden of cost and inefficiency exacerbates existing inequities, limiting access to advanced AI technologies for already marginalized groups.\nIn addition to these intrinsic challenges, external economic factors, such as currency fluctuations, further increase the cost of cloud-based AI services for businesses in economically unstable areas. This cost shift widens the global economic gap, limiting access to cutting-edge technologies and stifling innovation in lower-income economies, thus deepening the digital divide.\nMoreover, the environmental cost of inefficient tokenization, especially for low-resource languages, compounds the challenge. As LLMs scale, their energy consumption and carbon emissions grow, particularly when models process unnecessarily long token sequences due to inefficiencies. Reducing tokenization inefficiencies across all languages, including well-resourced ones like English, is critical to minimizing the climate impact of AI technologies. While long-context LLMs are gaining traction, there is an urgent need for more efficient tokenization algorithms that can process the same amount of information using shorter contexts. This shift could reduce computational demands, but ensuring LLM performance is maintained or enhanced will be crucial in this new tokenization paradigm. By addressing these inefficiencies, we can directly reduce the environmental footprint of AI, ensuring its development remains sustainable.\nIf LLMs for low-resource languages are not improved, we risk creating a feedback loop where poor model performance leads to degraded training data, further marginalizing these languages. Proactive steps are essential to ensure that speakers of low-resource languages can fully access and benefit from AI technologies. Both technological advancements and policy initiatives must be pursued to provide equitable access to AI systems. This requires addressing the economic and linguistic disparities."}]}