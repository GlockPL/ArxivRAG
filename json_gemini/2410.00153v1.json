{"title": "BEYOND SINGLE CONCEPT VECTOR: MODELING CONCEPT SUBSPACE IN LLMS WITH GAUSSIAN DISTRIBUTION", "authors": ["Haiyan Zhao", "Heng Zhao", "Bo Shen", "Ali Payani", "Fan Yang", "Mengnan Du"], "abstract": "Probing learned concepts in large language models (LLMs) is crucial for understanding how semantic knowledge is encoded internally. Training linear classifiers on probing tasks is a principle approach to denote the vector of a certain concept in the representation space. However, the single vector identified for a concept varies with both data and training, making it less robust and weakening its effectiveness in real-world applications. To address this challenge, we propose an approach to approximate the subspace representing a specific concept. Built on linear probing classifiers, we extend the concept vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's effectiveness through measuring its faithfulness and plausibility across multiple LLMs with different sizes and architectures. Additionally, we use representation intervention tasks to showcase its efficacy in real-world applications such as emotion steering. Experimental results indicate that GCS concept vectors have the potential to balance steering performance and maintaining the fluency in natural language generation tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs) such as GPT-4 (Achiam et al., 2023), LLaMA-3 (Touvron et al., 2023), and Claude-3 (Anthropic, March 4, 2024) have demonstrated remarkable capabilities across a wide range of natural language understanding and generation tasks (Brown et al., 2020; Wei et al., 2022). However, our understanding of how concepts are represented internally within these models remains limited. Current research in this area can be broadly categorized into two categories. The first involves studying model parameters through causal mediation analysis (Vig et al., 2020), which has found applications in downstream tasks such as knowledge editing (Meng et al., 2022; Wang et al., 2024a) and circuit identification (Conmy et al., 2023; Elhage et al., 2021). The second focuses on investigating the representation space and activations of models (Zou et al., 2023; Turner et al., 2023; Jorgensen et al., 2023; Rimsky et al., 2023), where representation vectors in hidden spaces are often interpreted as linear vectors of certain concepts, such as color (Patel & Pavlick, 2022), world models (Nanda et al., 2023; Li et al., 2023), and sentiment (Tigges et al., 2023).\nIn this work, we focus on the representation vector-based explanation paradigm. Among methods to derive representation vectors, linear concept vectors are most widely used. They are typically obtained by training linear probing classifiers, such as logistic regression, on datasets comprising positive and negative samples (Ousidhoum et al., 2021; Alain & Bengio, 2016). This approach has proven effective in identifying semantic knowledge encoded within LLMs and has recently been extensively applied in inference-time interventions to mitigate undesirable model behaviors (Li et al., 2024; Lee et al., 2024; Rimsky et al., 2023; Turner et al., 2023). However, concept vectors derived from this approach can vary significantly depending on the dataset used to train the classifier and the training process, making it challenging to obtain robust vectors. This substantial variation not only poses challenges in studying concept relations within the representation space but also negatively impacts effectiveness of concept vector's usage in intervention tasks.\nTo address these limitations, we explore the following research question: Instead of using a single vector to describe each underlying concept captured by LLMs, can we use a distribution to more"}, {"title": "2 PRELIMINARY", "content": "Hidden Representation. We focus on decoder-only LLMs (GPT-like models) (Ferrando et al., 2024), where each layer comprises multi-head attention blocks (MHA) and feed-forward networks (FFNs/MLPs). In this study, we utilize frozen pretrained language models. We index layers as $l \\in L$, where $L$ denotes the set of all model layers. Each layer begins and ends with a residual stream. The MHA first processes the residual stream and adds its output back to it. The updated vector is then passed through MLPs to generate the layer's output:\n$h_i^{l+1} = h_i^l + \\text{MLP}(h_i^l + \\text{Attn}^l(h_i^l)),$ (1)\nwhere $h_i^l$ represents the i-th token in the input token sequence at layer l. We concentrate on the output representation space of each layer, specifically the residual stream at the layer's end. Following Zou et al. (2023), we use the last token's representation to represent the entire input sequence, denoted as $h_l$, as it is generally believed to integrate information from all preceding tokens.\nLinear Probing. We adopt the classic linear concept probing approach to derive concept activation vectors (Kim et al., 2018). For each concept c, given a dataset $D_c = \\{(h_i^l, y_i) \\mid i = 1,\u2026\u2026,N\\}$ where $h \\in P \\cup N$, P is the set of concept-related positive samples, N is the set of concept-irrelevant negative samples, and $y_i \\in \\{0,1\\}$ indicates the sample class. These datasets generate layerwise hidden representations for downstream classifier training. We employ a logistic regression (LR) classifier as follows: $\\sigma(h_i^l) = \\frac{1}{1+\\text{exp}(-h_i^l w_c)}$, where $h_i^l \\in \\mathbb{R}^{N \\times d}$ specifies sample representations from a dataset at l-th layer, and d is the representation dimension. The normalized coefficients $w_c$ of each binary linear classifier are considered the concept vector. The loss function for logistic"}, {"title": "3 METHODOLOGY", "content": "To address the above-mentioned limitations, we explore the following research question: Instead of using a single vector to describe the concept captured by LLMs, can we use a distribution to more robustly describe the learned concept? We aim to approximate a subspace that better captures the semantics of specific concepts while providing vectors representing the concept with varying relevance. Building upon the linear probing approach described in Section 2, we introduce the Gaussian Concept Subspace (GCS) framework for estimating a multidimensional subspace of vectors for each concept. While linear probing identifies a single vector for a concept, GCS aims to capture a more comprehensive representation by estimating a Gaussian distribution of vectors."}, {"title": "3.1 THE PROPOSED GCS FRAMEWORK", "content": "To estimate the Gaussian distribution of concept vectors, we extend the linear probing method by deriving M independent concept vectors for a concept c. We first create a large dataset for a concept c and then randomly sample subsets of examples from this dataset to create M smaller datasets. Each dataset contributes to the same concept vector c, analogous to the single vector derived in Equation 2. For a model with target layer l, we obtain a concept vector $w_{c, m}^l$ for the m-th dataset at the l-th layer. This process generates a set of concept vectors for concept c:\n$W_c^l = \\{w_{c, m}^l \\mid m = 1,\u2026, M\\}.$ (3)\nWe use this set to estimate the concept subspace, represented as a Gaussian distribution of concept c at the l-th layer. The distribution is d-dimensional, where d is the dimension of the hidden representations, and is denoted as:\n$W_c^l \\sim \\mathcal{N}(\\mu_c, \\Sigma_c).$ (4)\nTo simplify the model, we assume independence between dimensions in the representation space. This assumption results in a diagonal covariance matrix, where diagonal elements represent the variance of each dimension:\n$\\mu_c^l = \\frac{1}{M} \\sum_{m=1}^M w_{c, m}^l, \\; \\; \\Sigma_c = \\text{diag}(\\sigma_1^2,\u2026\u2026, \\sigma_d^2)$ (5)"}, {"title": "3.2 EVALUATION OF GCS", "content": "We use faithfulness and plausibility two metrics to eveluate performance of GCS, which are two crucial dimensions for evaluating the performance of an interpretability approach (Zhao et al., 2024)."}, {"title": "3.2.1 FAITHFULNESS", "content": "To assess faithfulness, we compare the performance of sampled vectors $V_c^l$ (stage 3 of Algorithm 1) compared to that of observed vectors $W_c^l$ (stage 1 of Algorithm 1). Specifically, we employ two metrics: 1) similarity among observed vectors, sampled vectors and between the two sets; 2) accuracy of classifiers based on observed vectors and sampled vectors on our constructed datasets.\nSimilarity We evaluate the similarity between vectors within the observed concept vectors $W_c^l$ and within the sampled concept vectors $V_c^l$ using Equation 6. Additionally, we assess the similarity between vectors from the observed set and the sampled set using Equation 7.\n$S_{\\text{observed}} = 1/N * \\sum_{i,j} \\text{sim}(w_i, w_j), \\; w_i, w_j \\in W_c^l; S_{\\text{sampled}} = 1/N * \\sum_{i,j} \\text{sim}(v_i, v_j) \\; v_i, v_j \\in V_c^l$ (6)\n$S_{o-s} = 1/N * \\sum_{i,j} \\text{sim}(w_i, v_j), \\; w_i \\in W_c^l, v_j \\in V_c^l$ (7)\nThe average similarity score of observed vectors $S_{\\text{observed}}$ and sampled vectors $S_{\\text{sampled}}$ describes how similar the linear vectors are for a specific concept. If our sampled vectors accurately represent concept vectors, the similarity score of sampled vectors should be comparable to that of observed concept vectors. Moreover, the similarity between observed and sampled vectors, denoted as $S_{o-s}$, should also be approximately equal to the within-set similarities.\nAccuracy The observed concept vectors are derived from the weights of linear concept classifiers. To generate M linear concept vectors for a concept c, we randomly sample M datasets $\\{D_1,\u2026, D_M\\}$ from a large dataset D. For each dataset $D_i$, a linear classifier is trained using hidden representations from the l-th layer of a LLM. The weight vector of this classifier is identified as a concept vector for concept c at layer l. The average accuracy score of concept vectors for concept c at the l-th layer is defined as:\n$A = \\frac{\\sum_{i=1}^M \\text{acc}(w_i, D_{\\text{test}})}{M}, w_i \\in C, \\text{where } D_{\\text{test}} = \\begin{cases} D/D_i, & \\text{if } C \\subset W_c^l \\\\ D, & \\text{if } C \\subset V_c^l \\end{cases}$ (8)\nThe average accuracy score captures how effectively concept vectors represent the concept. A higher average accuracy score for observed concept vectors suggests that classifiers have learned more generalized concept vectors. Sampled concept vectors should achieve comparable or even higher accuracy scores if they genuinely represent related concept."}, {"title": "3.2.2 PLAUSIBILITY", "content": "Plausibility describes how well explanations align with human expectations. We measure the plausibility of GCS by studying whether models learn real-world hierarchies of concepts. To achieve this, we predefine a set of hierarchical concepts. We use average cosine similarity among concept vectors and principle component analysis (PCA) to demonstrate the consistence of GCS's plausibility.\nAverage Cosine Similarity To measure the similarity between two concepts $c_i$ and $c_j$ at the l-th layer, we utilized their respective sampled concept vectors $V_{c_i}^l$ and $V_{c_j}^l$. The concept similarity is represented by the average cosine similarity between two concept vector sets. The average cosine similarity between these two concepts at the l-th layer is computed as follows:\n$S_{c_i, c_j}^l = \\frac{\\sum_{m=1}^M \\sum_{n=1}^{M/2} \\text{sim}(v_m, v_n)}{M \\times M/2}, \\; v_m \\in V_{c_i}^l, v_n \\in V_{c_j}^l$ (9)"}, {"title": "4 EXPERIMENTS", "content": "In this section, we present experimental results that measure the performance of GCS and address the following three research questions (RQs):\nRQ1: How faithfully do GCS-sampled concept vectors represent the original concepts?\nRQ2: To what extent do explanations derived from GCS-sampled concept vectors align with human expectations about the hierarchies among model's learned knowledge?\nRQ3: Can the proposed GCS method effectively mitigate unwanted behaviors in LLMs?"}, {"title": "4.1 EXPERIMENTAL SETUP", "content": "We define a hierarchical concept structure comprising two levels, encompassing concepts from high-level to low-level. The high-level concepts include four categories: moive, sports event, populated place, and animal. Under each high-level concept category, there are 4 low-level concepts, as illustrated in Figure 1. To ensure consistency and high quality of input data across all experiments, we generate our experimental dataset using the OpenAI API, specifically leveraging GPT-40 model. For each low-level concept, we prompt GPT-4o to produce 5,000 positive samples and 5,000 negative samples. The specific prompts used for generating these samples are detailed in Appendix I. Our prompt design strategy varies based on the concept's specificity. For more inclusive concepts such as \"Town\", we utilize detailed prompt descriptions to guide GPT-40 in generating concept-related data. Conversely, for more specific concepts like \u201cMotor race\", simpler and more generic prompt descriptions are sufficient to produce appropriate samples."}, {"title": "4.1.2 MODELS", "content": "We study concept vectors across multiple LLMs, including Llama-2-7B chat model (Meta AI, 2023b), Gemma-7B (Google, 2024), and Llama-2-13B chat model (Meta AI, 2023a). This selection of models enables a comparative analysis of GCS across varying model architectures and sizes. By examining GCS's performance across these diverse models, we aim to provide insights into the method's generalizability and effectiveness across different LLM implementations."}, {"title": "4.1.3 IMPLEMENTION DETAILS", "content": "Evaluating GCS at the distribution level presents significant challenges. Gaussian distribution encompasses vectors representing concepts with varying degrees of relevance, potentially diminishing as the sampling distance from the mean increases. This variability, coupled with the infinite potential of sampled concept vectors, renders precise distribution-level evaluation impractical. To address these limitations, we simplify our assessment by randomly sampling 1,000 concept vectors within 1\u03c3 of the mean, which we consider representative of the concept.\nThe GCS pipeline comprises several key steps: generating data points using GPT-4o, extracting hidden representations of each sample from LLMs, training linear classifiers for each concept using these hidden representations, and constructing Gaussians distribution for concept vectors. Our study generated 10,000 descriptions per low-level concept (5,000 positive and 5,000 negative). To"}, {"title": "4.2 FAITHFULNESS OF GCS (RQ1)", "content": "We evaluate the faithfulness of GCS from two perspectives: similarity and accuracy. Similarity assessment involves comparing observed concept vectors with those sampled from the GCS. This comparison provides an effective measure of their relatedness in the representation space. Ideally, for any given concept, the sampled vectors should closely approximate the observed vectors. We also assess the accuracy of these vectors in concept-related tasks."}, {"title": "4.2.1 COSINE SIMILARITY AMONG CONCEPT VECTORS", "content": "For each concept, we analyze three types of cosine similarity: among observed concept vectors, among sampled concept vectors, and between these two sets, as defined in Equation 6 and 7. The cosine similarities among observed concept vectors indicate the potential size of the concept subspace, with higher similarities suggesting a more compact subspace. The cosine similarities among"}, {"title": "4.2.2 PREDICTION ACCURACY OF CONCEPT VECTORS", "content": "Despite the similarity between sampled and observed concept vectors in the representation space, it is crucial to verify that sampled vectors are as effective as observed concept vectors. We begin by measuring the accuracy of each observed linear vector on its test dataset, which comprises 8,000 additional concept descriptions. Then, we evaluate sampled concept vectors on the entire dataset of 10,000 samples, as these vectors are not trained on the dataset. The results are reported in Figure 3.\nTo evaluate the impact of proximity to the concept subspace center, we evaluate sampled concept vectors for all concepts at 1\u03c3, 2\u03c3, 3\u03c3, 4\u03c3, and 5\u03c3 across three LLM models. Our results demonstrate that sampled concept vectors usually achieve comparable and even better prediction accuracy compared to observed vectors, as illustrated in Figure 3. This improved performance is particularly evident for sampled concept vectors at 1\u03c3 and 2\u03c3. These findings are further corroborated by the accuracy of these vectors across all predefined concepts in the Gemma-7B model (Appendix F). Our analysis yields two key insights. First, it validates the effectiveness of sampled concept vectors in representing concepts. Second, it also suggests that vectors closer to the subspace center could be more representative of the concept."}, {"title": "4.3 PLAUSIBILITY OF GCS (RQ2)", "content": "In this section, we evaluate the plausibility of GCS using two methods: average cosine similarity among concepts and PCA visualization (see Section 3.2.2). Here, we utilize concept vectors sampled at 1\u03c3 to compute the average cosine similarity between concepts and to generate the PCA visualization. We assess the coherence of concept relationships in the high-dimensional space (through cosine similarities) and in a lower-dimensional projection (through PCA visualization)."}, {"title": "4.3.1 AVERAGE COSINE SIMILARITY AMONG CONCEPTS", "content": "We evaluate concept similarity using average cosine similarity. Instead of measuring the entire distribution, we assess 1,000 concept vectors sampled within 1\u03c3 for each concept. The cosine similarity is computed for all vector pairs between two concepts, with the mean value representing the overall similarity between these concepts. Figure 4 illustrates these results across various LLMs."}, {"title": "4.3.2 PCA VISUALIZATION", "content": "PCA visualization offers an intuitive method to reveal concept proximity by linearly reducing concept vectors into a two-dimensional space. We visualize all 16 concepts to explore their relationships in terms of sampled concept vectors. Figure 5 illustrates the results across various LLMs at the penultimate layer. Across all three models, we observe several patterns. First, in all three visualizations, concepts belonging to the same high-level category tend to cluster together, confirming"}, {"title": "4.4 APPLICATIONS OF GCS ON INFERENCE-TIME INTERVENTION (RQ3)", "content": "Recently, concept vectors has been extensively used to steer model outputs towards desirable behaviors during inference time. This approach is considered as more efficient than finetuning, without needing modify the model's parameters. These steering vectors are generally derived using various approaches, all based on pairs of desired and undesired data samples. Following Konen et al. (2024), we evaluate GCS on open-ended generation tasks, which are more flexible and challenging tasks for intervention compared to natural language understanding tasks such as multiple-choice questions. Specifically, we aim to steer Llama-2-7B chat model to generate more joyful movie reviews, a task we refer to as emotion steering. To measure the performance of GCS, we compare vectors derived from GCS with two conventional methods: mean difference and linear vector as defined in Appendix B. Moreover, we utilize vectors within \u03b7\u03c3,\u03b7 \u2208 {1,2,3,4,5} from GCS to explore the relation between steering performance and concept vector relevance.\nWe follow the experimental settings described in Section 4.1.3. We use GPT-4o to generate \"joyful\" and \"angry\" movie reviews, then derive concept vectors for the joyful concept. Throughtout our experiments, we utilize the representation of the last token as the input for downstream computation. The process involves tasking models to generate angry movie reviews using prompts detailed in Appendix H. We then apply concept vectors to the representation of the last token across all layers, excluding the first and the last, to shift the model's outputs. We attempt to incrementally adjust the strength of steering vectors to measure its influence on outputs as detailed in Appendix C. The generated sentences are rated with GPT-4o from two aspects: joyfulness and coherence. Joyfulness assesses how joyful the generated text become after steering, while coherence measures the fluency of generated text through repetitive or chaotic elements. The result is shown in Table 1.\nIt is crucial to maintain a balance between steering models to produce desired expressions and preserving the fluency of those expressions. For example, before intervention, Llama-2-7B chat model generates angry review: Awful, predictable, and cringeworthy. Our GCS 1\u03c3 sampled vector based intervention can push it to generate joyful review: Creative writing, beautiful acting, fun movie. Examples of best performance for each method are detailed in Appendix H.3. The results in Table 1 show that mean difference is less effective in steering, and more likely to generate less fluent text. Additionally, the vectors sampled within 2\u03c3, 3\u03c3, 4\u03c3, and 5\u03c3 of GCS are generally less effective in generating joyful content compared to 1\u03c3 sampled vectors and one linear vector. Although one linear vector can reach comparable effect as 1\u03c3, its robustness is not as good as vectors sampled within 1\u03c3 from GCS. It's worthnoting that one linear vector is trained on all data samples used to derive the set of concept vectors. As a result, it is possible that the one linear vector falls around the 1\u03c3 area, which makes it achieve the similar steering effect but lack of robustness. Consequently,"}, {"title": "5 RELATED WORK", "content": "Concept Vector. The concept vector represents a linear vector of a concept and is typically constructed using datasets containing both positive and negative samples. A range of methods have been implemented to derive the vector. One common approach is to train a linear classifier and the vector is the normalized weights of the learned classifier (Kim et al., 2018). Another branch of methods focus on mean difference involving different strategies. One popular way is to compute the difference between average activations of positive samples and negative samples. Another approach is to derive steering vectors by averaging the difference in residual stream activations between pairs of positive and negative samples at certain layers (Rimsky et al., 2023; Zou et al., 2023). While Mean-Centering takes the difference between the average activation of a target dataset and that of all training activations as the steering vector (Jorgensen et al., 2023). K-means is also proven feasible to compute vectors, where positive and negative clusters are clustered unsupervisedly and then their mean values are used (Tigges et al., 2023). Besides, Principle Component Analysis (PCA) is another popular way to produce concept vectors through identifying specific dimensions of representations (Liu et al., 2023; Lee et al., 2024).\nInference-time Intervention. The intervention on internal representations of LLMs during inference time has proven effective in steering model outputs (Burns et al., 2022; Zou et al., 2023). This approach utilizes steering vectors, also known as steering activations, which are believed to linearly represent concepts or features in the representation space (Park et al., 2023; Elhage et al., 2022). These vectors are added up to models representations during forward pass at the level of either attention head or layer. For example, some studies add scaled concept vectors to tokens, either all tokens or last token of a sequence, at certain layers to manipulate models output (Rimsky et al., 2023; Liu et al., 2023; Tigges et al., 2023; Turner et al., 2023; Zou et al., 2023). However, some work prefer intervening on a more delicate level, such as attention heads. They focuses on heads that are responsible for specific behaviors, then intervening selected heads to achieve comparable performance (Wang et al., 2024b; Li et al., 2024)."}, {"title": "6 CONCLUSIONS", "content": "In this paper, we introduce the Gaussian Concept Subspace (GCS), a new framework to estimate the subspace of specific concepts within LLMs. Our research demonstrates the faithfulness and plausibility of GCS in terms of its explanation. Explanations from GCS are similar to trained vectors in representation space and their prediction accuracy is comparable to, and in some cases surpasses, that of trained vectors. GCS also reveals the hierarchical concept structures that align with we human's understanding. Besides, we attempt to apply it in real-world inference-time intervention tasks. The performance of GCS demonstrates its potential for efficiently mitigating models' undesirable behaviors. In summary, GCS offers a concise yet powerful method for concept subspace estimation, showing promise in both theoretical explanations and practical applications."}, {"title": "H EMOTION STEERING", "content": "The experimental details of emotion steering are detailed as below."}, {"title": "H.1 PROMPTS FOR SAMPLE GENERATION", "content": "The prompts below are used to prompt GPT-4o to generate concept-related samples, which are necessary to derive concept vectors."}, {"title": "H.2 PROMPTS FOR LLM GENERATION", "content": "The prompt is designed to prompt the model that we steer to generate outputs with angry sentiment."}, {"title": "H.3 GENERATED REVIEWS UNDER INTERVENTION", "content": "The reviews below are generated by adding up layerwise intervention vectors and prompting Llama-2-7B Chat model to generate joyful reviews (even though prompts in H.2 are for generating angry reviews). The results are chosen from best performances of each method. These less robust methods usually generate expressions that are less fluent, with uncommon unicode characters, or less joyful."}, {"title": "H.4 PROMPTS FOR RATING GENERATED TEXT", "content": "The prompt instructs GPT-4o to evaluate the generated text on two criteria: joyfulness and coherence. For joyfulness, GPT-4o assesses the text's overall joyful emotional tone. For coherece, it rates the text's logical flow and structure, considering factors such as repetitiveness and disorganization."}, {"title": "I PROMPTS TO GENERATE CONCEPT-RELATED DATASET", "content": "We prompt GPT-4o to generate no more than 100 positive samples or negative samples each round to avoid failures of instruction following. For concepts in sports events, the simply phrased prompts are enough to generate samples that well represent the concepts. Because these concepts such as cycling competition are focused and specialized. However, the other much broader concepts demand more detailed prompts when generating positive samples."}, {"title": "I.1 SPORTS EVENT", "content": ""}, {"title": "I.1.1 CYCLING COMPETITION", "content": ""}, {"title": "I.1.2 FOOTBALL MATCH", "content": ""}, {"title": "1.1.3 TENNIS TOURNAMENT", "content": ""}, {"title": "1.1.4 MOTOR RACE", "content": ""}, {"title": "1.2 POPULATED PLACE", "content": ""}, {"title": "I.2.1 TOWN", "content": ""}, {"title": "1.2.2 ISLAND", "content": ""}, {"title": "1.2.3 CITY DISTRICT", "content": ""}, {"title": "I.2.4 VILLAGE", "content": ""}, {"title": "1.3 MOVIE", "content": ""}, {"title": "I.3.1 HORROR", "content": ""}, {"title": "1.3.2 ACTION", "content": ""}, {"title": "1.3.3 COMEDY", "content": ""}, {"title": "1.3.4 SCIENCE FICTION", "content": ""}, {"title": "1.4 ANIMAL", "content": ""}, {"title": "1.4.1 BIRD", "content": ""}, {"title": "1.4.2 FISH", "content": ""}, {"title": "1.4.3 INSECT", "content": ""}, {"title": "1.4.4 CAT", "content": ""}]}