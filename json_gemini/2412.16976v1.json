{"title": "On Fusing ChatGPT and Ensemble Learning in Discontinuous Named Entity Recognition in Health Corpora", "authors": ["Tzu-Chieh Chen", "Wen-Yang Lin"], "abstract": "Named Entity Recognition (NER) has traditionally been a key task in natural language processing (NLP), aiming to identify and extract important terms from unstructured text data. However, a notable challenge for contemporary deep-learning NER models has been identifying discontinuous entities, which are often fragmented within the text. To date, methods to address Discontinuous Named Entity Recognition (DNER) have not been explored using ensemble learning to the best of our knowledge. Furthermore, the rise of large language models (LLMs, such as ChatGPT) in recent years has shown significant effectiveness across many NLP tasks. Most existing approaches, however, have primarily utilized ChatGPT as a problem-solving tool rather than exploring its potential as an integrative element within ensemble learning algorithms. In this study, we investigated the integration of ChatGPT as an arbitrator within an ensemble method, aiming to enhance performance on DNER tasks. Our method combines five state-of-the-art (SOTA) NER models with ChatGPT using custom prompt engineering to assess the robustness and generalization capabilities of the ensemble algorithm. We conducted experiments on three benchmark medical datasets, comparing our method against the five SOTA models, individual applications of GPT-3.5 and GPT-4, and a voting ensemble method. The results indicate that our proposed fusion of ChatGPT with the ensemble learning algorithm outperforms the SOTA results in the CADEC, ShARe13, and ShARe14 datasets, achieving improvements in F1-score of approximately 1.13%, 0.54%, and 0.67%, respectively. Compared to the voting ensemble method, our approach achieved improvements of about 0.63%, 0.32%, and 0.09%. Furthermore, compared to GPT-3.5 and GPT-4, our average results were approximately 7.42%, 0.89%, and 0.54% higher. The results demonstrate the effectiveness of our proposed fusion method of ChatGPT and ensemble algorithms, showcasing its potential to enhance NLP applications in the healthcare domain.", "sections": [{"title": "1. Introduction", "content": "NER tasks have long been fundamental tasks in natural language processing, involving the identification and extraction of important terms from unstructured textual data. Early NER methods often relied on pre-defined syntactic or semantic rules and relied on annotated corpora, which required significant human resources and time costs for manual analysis [1]. Over the years, approaches that utilize machine learning and deep learning technologies have gained widespread popularity [2]. Most traditional NER models [3]-[6] transform the NER problem into a sequence labeling task [7],[8], where each token is labeled as \"B\", \"I\", or \"O\". Here, \"B\" indicates the start of an entity, \"I\" signifies that a token is inside an entity, and \"O\" marks a token as outside of any entity. As shown in Figure 1, the word \"aching\" is the beginning of the ADE entity \"aching in legs\", thus it is labeled as \"B\", and the words \"in\" and \"legs\" are in the inside of the entity, hence labeled as \"I\". However, this approach of assigning only one label per token can only handle continuous NER tasks and cannot address issues involving irregularly overlapping or discontinuous entities."}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Prompt Engineering", "content": "Prompt engineering refers to the deliberate design and adjustment of input prompts in generative AI systems, such as ChatGPT, to guide the model towards generating desired outputs, thereby enhancing per-formance on specific tasks [26]. In recent years, several studies have indicated that prompt engineering has a crucial impact on the performance of generative AI [27],[28]. Moreover, in the medical domain, researchers have explored prompt engineering for tasks like medical question answering [29] and medical NER [30] using ChatGPT. Effective prompt engineering maximizes the quality of model outputs, ensuring relevance and ac-curacy in generated content while minimizing irrelevant or biased results."}, {"title": "2.2. Baseline Deep Learning DNER Models", "content": "In our research approach, we combine ChatGPT with five deep learning models specialized in identifying discontinuous entities to enhance the model's ability to identify discontinuous entities effectively. Here is a brief introduction to these models to better understand how they address the problem of DNER:"}, {"title": "2.2.1. Transition-Based Model", "content": "The transformation-based approach proposed by Dai et al. [31] addresses the DNER problem by intro-ducing two finer-grained entities, thereby transforming it into a nested NER problem. As illustrated in Figure 3, the original ADE entity is divided into two more specific entities: \"Body Location\" and \"General Feeling,\" to solve the DNER problem."}, {"title": "2.2.2. Span-Based Model", "content": "The model proposed by Li et al. [32] is essentially a relationship extraction model. The model identifies entities by traversing all possible text spans, then performs relationship classification to determine whether the given entity pair belongs to the same named entity, two separate named entities, or entities with overlap-ping spans. As shown in Figure 4, this model consists of two main steps. First, it identifies entities \"mitral,\" \"leaflets,\" and \"thickened\" by traversing all possible text spans. Then, it performs relationship classification to determine that these three entities belong to the same named entity."}, {"title": "2.2.3. Maximal Clique Discovery-Based Model", "content": "The model proposed by Wang et al. [33] is a concept in graph theory. The model is divided into two main tasks, entity extraction and edge prediction, to form the nodes and edges of the entity graph. A node graph is established for each sentence, where each node represents an entity (formed by one or more words), and edges connect nodes within the same entity. As illustrated in Figure 5, the model first identifies words that could potentially be the beginning of an ADE entity, such as \"Sever joint\" and \"Sever\" are annotated as ADE-B, and words that could be inside the entity like \"pain\", \"should\", and \"upper body pain\", are then annotated as ADE-I. Then, the model establishes connections between entities within the same entity through edge prediction."}, {"title": "2.2.4. Word-Word Relation Classification Model", "content": "The W\u00b2NER model proposed by Li et al. [34] transforms the NER problem into predicting word-word relationships, and uses two custom labels to link entities together. This model effectively simulates relation-ships between entity words by predicting the Next-Neighboring Word (NNW) and Tail Head Word (THW) relationships. As shown in Figure 6, (a) illustrates examples of three NER scenarios: \"aching in legs\" (E1) is a contiguous entity, \"aching in shoulders\" (E2) is a discontinuous entity, and there is an overlapping entity \"aching in,\" while (b) demonstrates that the model converts these three NER scenarios into word-word rela-"}, {"title": "2.2.5. Tag-Oriented Enhancement Model (TOE)", "content": "The TOE (Tag-Oriented Enhancement) model proposed by Liu et al. [35] is an enhanced version of W\u00b2NER model, achieving higher performance by adding two additional custom labels. As shown in Figure 7, the red relationships represent the new labels \"PNW\" and \"HTW,\" which are used to enhance the W\u00b2NER Model that originally only had \"NNW\" and \"THW\" labels. The model not only proposes predicting Next-Neighboring-Word (NNW) and Tail-Head-Word (THW) relationships to capture discontinuous entities, but also introduces two new relationships: Previous-Neighboring-Word (PNW) and Head-Tail-Word (HTW). This requires the model to consider not only relationships between words but also interactions between labels and words, as well as between labels themselves."}, {"title": "3. Methodology", "content": "Figure 8 illustrates the overall framework of this study, aimed at leveraging the advantages of ensemble learning [36] and using ChatGPT to address the challenges of DNER in medical corpora. We employ ChatGPT as a mediator, utilizing custom prompts for ChatGPT to integrate five deep-learning models capable of han-dling DNER issues, thereby enhancing the model's ability to recognize discontinuous entities effectively. Ad-ditionally, for the reliability of this approach, we also explore a voting ensemble method to compare with the proposed approach of using ChatGPT as an arbitrator."}, {"title": "3.1. Data Preprocessing", "content": "First, following the approach of [31], we preprocessed the datasets suitable for use by the DNER models. Then, we fine-tuned the data according to the input formats of each model, enabling training with the respec-tive datasets. As shown in Figure 9, the transition-based model [31] only converts the original entity into two finer-grained entities, so only the entity position and category need to be used in the input format. The Span-based model [32] is essentially a relationship extraction model. It first predicts entities and then performs relationship classification for each entity. Therefore, \"ner\" needs to be used in the input format to represent entities and \"relations\" to represent the relationships of each entity. Maximal clique discovery-based model"}, {"title": "3.2. Data Post-processing", "content": "To enable the data for learning through ensemble methods, we needed to standardize the outputs of all models into a uniform format for further evaluation of the ensemble method. Figure 10 shows an example of the proposed uniform format corresponding to the example in Figure 9. The \"text\" field contains the original sentence, \"sentence\" represents the tokenized version of the original sentence, and \"entity list\" includes each entity's \"text\" and \"index\" positions within the sentence. When we use majority voting in the voting ensemble method, we only need to grab the entity positions predicted by each model. However, considering ChatGPT's capabilities as a generative AI that understands text, we did not simply use entity positions like in a voting ensemble method but also included the original sentence and each entity's text, allowing ChatGPT to have a deeper understanding of the sentence content."}, {"title": "3.3. Prompt Engineering", "content": "Due to the high uncertainty in ChatGPT's responses, we applied the following prompt engineering to stabilize and constrain its answering behavior, guiding the model to generate the desired outputs. We divided the prompts into two parts. The first part is the foundational prompts, as shown in Table 1, which contains task descriptions commonly used by people when interacting with generative AI models (for example, given what role it is and what tasks it wants to handle). Annotation description is essential in the NER task, so we must also describe the entity in detail. The last is the sample description, which tells ChatGPT the input and output formats."}, {"title": "4. Evaluation", "content": "All experiments were performed on a PC equipped with the following specifications: an Intel Core i5-12400 CPU, 32GB RAM, a 1TB SSD hard disk, and an NVIDIA GeForce RTX 3070-Ti with 8GB VRAM graphics card, running on Windows 10, and all software was implemented in Python."}, {"title": "4.1. Data Sets", "content": "To underscore the reliability of our proposed method, we applied preprocessing to three benchmark biomedical datasets of CADEC, ShARe13, and ShARe14, as previously done by Dai et al. [31].CADEC [23] is a richly annotated corpus containing medical forum posts where patients report adverse drug events. The texts in this corpus are mostly written in informal language and frequently diverge from standard English grammar and punctuation norms. Annotation quality is maintained through the use of guidelines, a multi-phase annotation process, inter-annotator agreement measurements, and final reviews by clinical ter-minologists. This corpus is valuable for research in extracting information from social media or text mining to detect potential adverse drug reactions directly from patient reports.ShaRe13 [24] and ShaRe14 [25] are datasets belonging to a shared task. In the ShaRe13, the laboratory includes three tasks: Task 1 involves disease identification and standardization (1a and 1b), and Task 2 involves standardizing medical term abbreviations and acronyms. Task 3 focuses on information retrieval. In this study, we used Task 1 to evaluate NER performance. The ShaRe14 also comprises three tasks: Task 1 focuses on interactive visualization and exploration of electronic health records, Task 2 involves information extraction from clinical texts, and Task 3 is dedicated to user-centered health information retrieval. Our ex-periments used the Task 2 dataset of ShaRe14 to assess NER performance.Table 3 presents the descriptive statistics of the datasets, including document counts, sentence counts, token counts, and entity counts. Here, Disc. E represents the number of discontinuous named entities com-prising approximately 10% of the total entities."}, {"title": "4.2. Performance Metrics", "content": "In NER tasks, Precision, Recall, and F1-Score are the standard metrics for evaluation. These metrics ef-fectively assess the performance of NER systems. Calculating accuracy is more difficult because it is challeng-ing to determine the exact True Negative (TN) value. This is because the main goal of NER is to identify entities in the text rather than performing binary classification (entity/non-entity) for each word. Therefore, we selected three metrics to evaluate our experiments: precision, recall, and F1-score, all defined by confusion matrices."}, {"title": "4.3. Results and Discussion", "content": "We compared our method with five deep learning-based methods, as well as GPT-3.5 and GPT-4. The test results are shown in Table 4, where highlighted in bold indicate the best results for each metric, and underlined values indicate the second-best results. The first five rows represent the five baseline models, the sixth and seventh rows represent the generative AI models GPT-3.5 and GPT-4, and the last two rows repre-sent ensemble learning methods: a simple majority voting ensemble method and an ensemble method using ChatGPT as an arbitrator.The results show that our ChatGPT-coordinated ensemble algorithm outperforms five baseline models, generative AI models, and voting ensemble methods in terms of F1 score. Moreover, across the three bench-mark datasets, out method elevates the state-of-the-art (SOTA), i.e., TOE [35] in the baseline models, results by approximately 1.13%, 0.54%, and 0.67%. Compared to voting ensemble methods, our approach showed"}, {"title": "5. Conclusions", "content": "Many research institutions have recently employed various deep-learning models to address the DNER problem. Nevertheless, we have not found relevant studies using ensemble learning to tackle DNER issues.We explored two ensemble learning methods to investigate whether they can enhance the performance of individual DNER models. One method is the majority voting ensemble approach, while the other is our novel method, using ChatGPT as an arbitrator to combine outputs from other deep learning models.We have conducted comprehensive experiments on three benchmark medical datasets. The results demonstrate that our proposed approach of ChatGPT-coordinated ensemble algorithm outperforms other individual deep learning models, ChatGPT itself, or the voting ensemble algorithm. In summary, our study demonstrated the potential of using ChatGPT as a coordinator to shape a better ensemble-based DNER model."}]}