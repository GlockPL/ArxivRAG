{"title": "NC2D: Novel Class Discovery for Node Classification", "authors": ["Yue Hou", "Xueyuan Chen", "He Zhu", "Ruomei Liu", "Bowen Shi", "Jiaheng Liu", "Junran Wu", "Ke Xu"], "abstract": "Novel Class Discovery (NCD) involves identifying new categories within unlabeled data by utilizing knowledge acquired from previously established categories. However, existing NCD methods often struggle to maintain a balance between the performance of old and new categories. Discovering unlabeled new categories in a class-incremental way is more practical but also more challenging, as it is frequently hindered by either catastrophic forgetting of old categories or an inability to learn new ones. Furthermore, the implementation of NCD on continuously scalable graph-structured data remains an under-explored area. In response to these challenges, we introduce for the first time a more practical NCD scenario for node classification (i.e., NC-NCD), and propose a novel self-training framework with prototype replay and distillation called SWORD, adopted to our NC-NCD setting. Our approach enables the model to cluster unlabeled new category nodes after learning labeled nodes while preserving performance on old categories without reliance on old category nodes. SWORD achieves this by employing a self-training strategy to learn new categories and preventing the forgetting of old categories through the joint use of feature prototypes and knowledge distillation. Extensive experiments on four common benchmarks demonstrate the superiority of SWORD over other state-of-the-art methods.", "sections": [{"title": "1 INTRODUCTION", "content": "Graph data is commonly used to reveal interactions between various entities, such as academic graphs, social networks, recommendation systems, etc [47\u201349, 65, 66]. In the last few years, node classification has received considerable attention [34, 43, 45, 50, 56] with the rise of significant advances in graph neural networks (GNNs) [22]. Most of the existing works on node classification primarily focus on a single task, where the model is tasked to classify unlabeled nodes into fixed classes [20, 22, 32, 68]. In practice, however, many graph data grow continuously, generating new classes as new nodes and edges emerge, for example, in a citation network, the appearance of new papers and their related citations, or even new interdisciplinary; the addition of new users leads to the emergence of new social groups. The categories of nodes are gradually expanding, usually accompanied by few labels due to their new emergence or lack of exploration. This requires new category discovery on graphs using GNNs, which currently has limited research on tasks regarding node classification.\nThe task of automatically discovering new classes in an unsupervised manner while utilizing previously acquired knowledge is called novel class discovery (NCD) [10, 15, 16, 62, 63]. NCD has recently received widespread attention for its ability to effectively"}, {"title": "2 RELATED WORK", "content": "As information grows, the task of discovering new categories from data and making accurate classification predictions has become a popular research direction [15, 16, 27, 38, 62, 67]. Here, we devote our attention to NCD for node classification, the most relevant topic of this work."}, {"title": "2.1 Graph Representation Learning", "content": "Graph representation learning aims to encode both the feature information from nodes and the topological structure of the incoming graph. Inspired by word2vec [31], several methods, such as DeepWalk [33] and node2vec [13], generate sequences of nodes by random walks, and apply skip-gram approach to map nodes within the same context to similar vector representations. Although these methods show success in various tasks like node classification and link prediction, they overemphasize proximity information at the expense of structural information and fail to incorporate node attributes."}, {"title": "2.2 Novel Class Discovery", "content": "NCD task is to migrate knowledge learned from labeled datasets to unlabelled ones to discover new classes, assuming that the classes in labeled and unlabelled sets are disjoint. The proposed NCD methods can be broadly divided into two categories. The first category of approach utilizes a joint training scheme, assuming the availability of both labeled and unlabeled data [44, 55, 57]. The other category employs a stage-wise isolated training scheme, where data from old and new classes cannot be used simultaneously. In this context, the labeled data of the base classes are used only during the supervised pre-training phase and not thereafter. Instead, an unsupervised clustering loss is employed to fine-tune unlabelled data during the phase of discovering unknown new classes [19, 54, 62].\nAccording to [27], NCD methods that rely on joint training always outperform methods with isolated training. However, it is not always practical to have access to labeled data after the pre-training phase due to concerns about data privacy or storage limitations. Therefore, training on the old and new classes jointly may not be a viable option in many cases. Moreover, earlier approaches based on isolated training schemes fail to adequately address the issue of catastrophic forgetting, which can result in models losing their ability to classify base classes. To tackle this problem, a novel task called Novel Class Discovery without Forgetting (NCDwF) is proposed in [21], which presents a more challenging domain derived from NCD. ResTune [27] and FROST [38] are the first isolated training methods to address NCDwF. ResTune incorporates the use of the Hungarian Assignment [24] that concatenates classifiers specific to the old and new classes. However, despite these efforts, ResTune still incorrectly evaluates performance due to confusion between the old and new classes.\nIn this work, since the implementation of NCD tasks on the graph is almost non-existent, we migrate NCD to the node classification task with GNN and propose a more reasonable NC-NCD setting. Specifically, the assumption of NC-NCD differs from that of the current NCD, primarily manifested in the inference phase of performance evaluation for classifications, employing a task-agnostic joint classifier."}, {"title": "2.3 Incremental Learning", "content": "In the past, incremental learning (i.e., continual learning or lifelong learning) has been explored in several areas such as computer vision [17, 46], and reinforcement learning [37]. Essentially, it aims to"}, {"title": "3 METHODOLOGY", "content": "In this section, SWORD are elaborated below. First, several preliminary definitions and notations are given."}, {"title": "3.1 Novel Class Discovery for Node Classification", "content": "Formally, a graph G = {V, 8}, where V is the set of N nodes and & is the edge set, can be alternatively represented by G = (A,X). Let A \u2208 $\\mathbb{R}^{N \\times N}$ be the adjacency matrix and X \u2208 $\\mathbb{R}^{N \\times d_0}$ denotes the node attribute matrix, where $d_0$ denotes the dimension of node attributes. To solve the NC-NCD problem, we split the dataset G into two folds with disjoint categories, G\u00b9 and Gu to represent data from the base and new classes respectively. G\u00b9 is randomly split into Gtrain, Gual and Glest for pre-training phase. Gu also has three splits of Gurain, Gual, Guest. To simplify the writing, we uniformly use G\u00b9, Gu, Ga to denote data from base, new and all classes.\nFor supervised task T\u00b9, given labeled G\u00b9 = {(A, x, y)} with N\u00b9 node samples, where x \u2208 X\u00b9 represents the feature of the current node and y \u2208 Y is||C|| dimensional one-hot labels. Once the task T\u00b9 is completed, G\u00b9 is discarded and we get n\u201c instances from the"}, {"title": "3.1.2 Evaluation Protocol", "content": "Previous NCD methods [10, 62] trained task-specific classification heads for the base and new classes respectively. To overcome the limitation of NCD being restricted to specified tasks, ResTune [27] introduced the use of Hungarian Assignment [24] to concatenate these two classification heads to achieve an evaluation of all classes during inference. However, the Hungarian Assignment which is a direct maximum match of the outputs from the two heads, lacks the ability to distinguish between old and new classes when they become completely confused.\nIn the present work, our NC-NCD setting uses a more reasonable evaluation protocol. Specifically, after learning the labeled nodes in base classes, since the unlabeled data in the NCD stage is used for isolated training, we employ a classification head for new classes to assign labels specifically and use pseudo-labels to train a single joint classifier that can classify both the base and new classes. When evaluating the model, the trained task-agnostic joint classifier is used directly without specifying the task-id, and the classification results are inferred on all seen class data, compared with the ground-truth labels of the samples. It is clear that our evaluation protocol is more reasonable, such as being able to discern when a new category is classified as one of the old categories is an error, which is a desirable behavior."}, {"title": "3.1.3 Overall Framework", "content": "Within NC-NCD setting, the function f consists of two major components: a GNN encoder g(\u00b7) to learn node representations and a linear classification head h(\u00b7) to output logits. Our proposed SWORD runs in two phases, a pre-training phase on the supervised task T\u00b9 and an NCD-training phase on the unsupervised task Tu.\nPre-training. In this stage, we utilize the labeled nodes from G\u00b9 to learn the mapping function fl = hl\u00b0g in a supervised manner, which identifies samples belonging to the category Cl. The feature extractor g and the classifier h\u00b9 are parameterized by $\u03b8_g$ and $\u03b8_{h_1}$, respectively. The latent features of the old category nodes are defined as z\u00b9 = g(G\u00b9). We aim to learn these two parameters {$\u03b8_g^l$, $\u03b8_{h_1}^l$} of model f\u00b9 by using supervised cross-entropy loss:\n$\\mathcal{L}_{ce} = -\\frac{1}{||C||} \\sum_{c=1}^{||c||} y_c \\log \\sigma_k(h^l(z^l)),$ (1)\nwhere the softmax function $\u03c3_k = \\frac{exp(l_k)}{\\sum_j exp(l_j)}$ represents the likelihood corresponding to the kth output from the model and c is the number of classes in the task T\u00b9. In addition, before the next"}, {"title": "3.2 Self-training with Prototype Replay and Distillation", "content": "We aim to learn a model that has a better capability of clustering unlabeled nodes after pre-training with labeled data while preserving the performance on previously seen categories without visiting nor storing previously labeled nodes. Our SWORD framework will achieve the above task requirements through self-training, prototype replay, and distillation, which are explained in detail below."}, {"title": "3.2.1 Pairwise Similarity and Pseudo Label", "content": "In the NCD-training phase, an essential step in learning new classes is to train fu = huog. On the one hand, we update the weights of GNN encoder g to maintain the feature extraction capability on new category nodes. On the other hand, we train the task-specific classifier hu, which is initialized and lacks the ability to discriminate the features on unlabeled nodes. We adopt the ideology from the NCD method AutoNovel [15] to infer pairwise similarity between features of a pair of unlabeled nodes and employ it in a weakly supervised form during NCD-training steps. Specifically, given a pair of node-featured pairs ($x_i,x_j$) taken from the unlabeled Gu, we use GNN encoder g to compute $z_i^u = g(G_i^u)$ and $z_j^u = g(G_j^u)$, respectively, to obtain the pair of node representations ($z_i^u, z_j^u$) on the graph. Then we multiply the node representation pair between the two samples with dot product and normalize it using a logistic function \u03c3(\u00b7). That is, we calculate the pairwise similarity using the following:\n$S_{ij} = \\sigma (h_u(z_i^u) \\odot h_u(z_j^u)).$ (2)\nSince the class of nodes in this stage is unknown, robust rank statistics are utilized to compare the node representation pairs. We consider that if the top-k dimensions of node representation pair ($z_i^u, z_j^u$) are the same, the two nodes corresponding to index i and j are considered to belong to the same class. In this way, another pairwise similarity of the two sample nodes is generated, referred to as a pairwise pseudo label to weakly supervise the training of classification head hu for new classes. The pairwise pseudo labels are formulated as:\n$\\hat{y}_{ij}^u = 1 \\{\\text{topk}(z_i^u) = \\text{topk}(z_j^u)\\},$ (3)\nwhere topk: $z_u \\rightarrow S \\{(1,...,k)\\} \\subset P \\{(1,...,||z_u||)\\}$. In particular, ranking the values by size in node representation vectors, if $z_i^u$ and $z_j^u$ are identical in the top-k most activated dimensions, then"}, {"title": "3.2.2 Self-training with Joint Head", "content": "To accommodate the NC-NCD setting, the inference step of our training framework should ideally not depend on task-id. We thus train the joint classifier ha by self-training with the help of pseudo labels computed from fu = hu \u043e \u0434. In summary, given the goal of the learning model f, we utilize the task-specific classification head hu to assign the pseudo label $\\hat{y}^u$ to the unlabeled nodes and use this pseudo label to supervise the training of the joint classification head ha, where the pseudo label $\\hat{y}^u$ of unlabeled nodes can be computed as:\n$\\hat{y}^u = ||C|| + \\underset{k\\in ||C_u||}{\\text{arg max}} h_u (z_i^u).$ (5)\nThe self-training loss is described as:\n$\\mathcal{L}_{Self} = - \\frac{1}{||C_u||} \\sum_{i=1}^{||C_u||} \\sum_{k=1}^{||C_a||} \\hat{y}_k \\log \\sigma_k(h^a(z_i^u)).$ (6)"}, {"title": "3.2.3 Encoder Output Perturbation", "content": "Since the pairwise pseudo labels obtained in Eq.(3) can be noisy, it will lead to poor supervised training of hu. Then it will affect the pseudo labels in Eq.(5), which adversely affects the training of the joint classifier ha. Therefore, to minimize the impact of the noise cascade propagation from hu, inspired by stochastic data augmentation, instead of changing the structural information of the graph itself, we add perturbations to encoder output features on node representation level [51] to perturb classifier hu. Specifically, we directly add the perturbation of random Gaussian noise to the node representation $z_i^u$ obtained with GNN encoder, described mathematically as,\n$z_i^{u'} = z_i^u + \\eta \\cdot \\Delta z_k; \\Delta z_k \\sim \\mathcal{N}(0,\u03c3^2),$ (7)\nwhere \u03b7 is the coefficient that scales the magnitude of the perturbation, and $\\Delta z_k$ is the perturbation term which samples from Gaussian distribution with zero mean and variance \u03c3\u00b2. The hu is reused for representation with perturbation $z_i^{u'}$ and original $z_i^u$, with a mean-squared error loss to further optimize the parameters {$\u03b8_g, \u03b8_{h_u}$}:\n$\\mathcal{L}_{Perturb} = \\frac{1}{||C_u||} \\sum_{k=1}^{||C_u||} \\sum_{k=1}^{||c_u||} [\\sigma_k (h^a(z_i^u)) - \\sigma_k (h^a(z_i^{u'}))]^2.$ (8)"}, {"title": "3.2.4 Prototype Replay and Distillation", "content": "Although the self-training described above helps the model f = h\u00ba og discover new categories, at the same time it loses the ability to predict old categories on task Tu. So, we propose feature-level prototype replay and distillation. In the NC-NCD setting, with labeled data G\u00b9 on task Tu that has been discarded, we use the node representation z\u00b9 at the end of"}, {"title": "4 EXPERIMENT", "content": "Dataset Settings. We evaluate the proposed SWORD on four representative datasets: Cora [29], Citeseer [12], Pubmed [39] and Wiki-CS [30], whose details are provided in Appendix A.2. We also provide statistics and splitting for the datasets in Table 6.\nBaselines. We choose representative GNNs as backbones including GCN [22], GAT [41] and GraphSAGE [14]. Additionally, we compare our SWORD with several SOTA baselines, including 4 traditional NCD methods (AutoNovel [15], ResTune [27], NCL [62] and DTC [16]), and 4 graph incremental learning methods in both task-IL and class-IL settings (GEM [28], ER-GNN [64], TWP [26] and CPCA [36]). Table 2 provides a further summary and comparison of these baseline methods with our SWORD. A more detailed analysis of these baseline methods is described in Appendix A.3. We also provide implementation details and parameter settings in Appendix A.4."}, {"title": "4.2 Comparison with SOTA Methods", "content": "Under our practical setting for node classification (i.e., NC-NCD), we compare SWORD with the NCD baseline methods and record the performance on the old, new and all categories after unified classification using the joint classifier ha on all unlabeled samples, as shown in Table 3. The best results are highlighted in bold, while the runner-ups are underlined. From the comprehensive views, we make the following observations and analyses."}, {"title": "4.2.1 Analysis of Performance Comparison", "content": "First, our SWORD stands out among the baseline methods as it effectively balances the classification of old and new categories. After learning old category nodes on task T\u00b9 and learning new category nodes on task Tu, SWORD successfully distinguishes between old and new categories using the joint classifier and performs better on the classification of all category nodes.\nIn contrast, most of the NCD baseline methods struggle to differentiate new nodes using task-agnostic joint classifiers, prioritizing the maintenance of performance on old classes. Although these NCD methods fail to classify new category nodes in the NC-NCD setting, they still achieve better overall performance by relying on the classification of old categories. We acknowledge that the performance on all categories is largely influenced by the classification"}, {"title": "4.2.2 Performance on Multiple Backbones", "content": "We implement SWORD with multiple backbones and evaluate the node classification accuracy for both old and new categories. Our results show that SWORD consistently outperforms other SOTA methods in achieving a balanced performance on old and new categories. Specifically, GraphSAGE and GCN exhibit similar performance on multiple datasets. GAT, with its attention mechanism, stands out in accurately classifying both old and new category nodes.\nWe also visualize the Cora dataset's original graph and the embedding of graphs learned by SWORD and other baseline methods via t-SNE in Appendix A.5.3."}, {"title": "4.3 Ablation Studies", "content": "In this section, we delve deeper into the effectiveness of the baselines on NCD tasks and analyze the effectiveness of different components within our framework."}, {"title": "4.3.1 Effectiveness of the Baselines on NCD tasks", "content": "As shown in Table 4, the baseline methods and our SWORD achieve commendable classification accuracy for both old and new category nodes, primarily attributed to the utilization of task-specific novel classification"}, {"title": "4.3.2 Effectiveness of Prototype Replay and Distillation", "content": "Table 5 shows that the removal of either $\\mathcal{L}_{Replay}$ or $\\mathcal{L}_{Distill}$ causes SWORD to completely forget the old categories. This outcome aligns with our expectations, as the feature extractor deviates from its original configuration after training on the new task Tu, thus leading the extracted node representations of the old classes to diverge from their prototypes.\nFurthermore, we observed that SWORD, when subjected to the ablation of prototype replay and distillation, exhibits superior performance in classifying new categories on the Citeseer dataset. This enhanced performance can be attributed to the relatively smaller number of novel node categories present in the dataset. Following the completion of task Tu, the model with the ablated prototype replay and distillation mechanisms tends to classify all categories as new categories."}, {"title": "4.3.3 Effectiveness of Self-training", "content": "As shown in the 4th row of Table 5, SWORD, when lacking self-training, faces challenges in"}, {"title": "4.4 Parameter Analysis", "content": "In this section, we present extensive experiments to analyze the sensitivity of our SWORD to the ramp-up function weights \u03b2\u2081 and \u03b2\u2082, noise perturbation \u03b7 and hyper-parameter \u03bb. The results are shown in Figure 3. In the AppendixA.5.4, we conduct further experiments to analyze the impact of the number of layers in the GNN backbones on classification performance."}, {"title": "4.4.1 Effect of the Weights of Ramp-up Functions", "content": "The coefficients \u1e9e1 and B2 are the weights adjusted by the ramp-up function, represented as $\u03b2_1 = \u03b1_1 \u00b7 rampup(epoch)$, where $\u03b1_1$ can be flexibly adjusted to the loss function at different training stages. \u1e9e2 is in the same vein. Therefore, we tuned adjustable coefficients a\u2081 and a2 to examine their impact on the model's performance in the NC-NCD task. Figure 3(a) demonstrates that as a\u2081 increases, the performance of SWORD gradually improves on the new categories, while the effect on the old and all categories diminishes. Conversely, a2 has a minor influence on the model's performance. Increasing the noise perturbation by raising a2 results in a slight improvement in the learning of new category nodes, while it has minimal effect on old categories."}, {"title": "4.4.2 Effect of Gaussian Noise Perturbation", "content": "The coefficient \u03b7 is used to measure the extent to which random Gaussian noise is added to the new class data in the joint training head. As shown in Figure 3(c), a small increase in the perturbation of Gaussian noise, for example, \u03b7 ranging from 0.05 to 0.2, can improve the"}, {"title": "4.4.3 Effect of Loss Balance Factor", "content": "The hyper-parameter \u03bb is an essential loss balance factor to weigh the learning ability of the model at the old and new category nodes, preventing SWORD from completely failing to learn the new categories or completely forgetting the old categories. As we found in Figure 3(d), when is small, the model's forgetting of the old categories is catastrophic, while when \u03bb is large enough the performance improvement on the old categories slows down and is replaced by a performance decrease on the new categories. This demonstrates the important role of a in balancing the performance of the old and new categories."}, {"title": "5 CONCLUSION", "content": "In this work, we propose a novel NC-NCD setting that distinguishes itself from previous NCD tasks. In real-world scenarios, existing NCD methods fail to adequately balance the learning performance between the old and new categories in a task-agnostic manner. To address this limitation, we introduce a new framework called SWORD to enhance the node classification task in the NC-NCD setting. SWORD employs a self-training strategy to train task-agnostic joint classifiers capable of classifying all previously seen categories, eliminating the need for explicit task indicators. Additionally, feature-level prototype replay as well as distillation are utilized to prevent forgetting. Comprehensive experiments demonstrate the potential and adaptability of the SWORD method for NC-NCD tasks compared to other SOTA methods. A practical future endeavor is to embark on developing a framework that does not necessitate prior knowledge of the number of novel classes and to extend the NC-NCD framework to multiple stages NCD. We will also discuss this within the generalized category discovery setting, where both unlabeled old and new category data are available which reflects real-world scenarios."}, {"title": "A.1 Overall Process of SWORD", "content": "The overall process of SWORD is shown in Algorithm 1 as follows."}, {"title": "A.2 Datasets", "content": "In this section, we describe more details on the datasets used for this paper.\n\u2022 Cora, Citeseer and Pubmed are citation networks following the standard train/validation/test split in line with [22].\n\u2022 Wiki-CS consists of nodes corresponding to Computer Science articles, with edges based on hyperlinks and 10 classes representing different branches of the field. We split this dataset according to [30].\nIn the novel NC-NCD, the pre-training phase employs labeled node features exclusively from the old categories, whereas the NCD-training phase involves unlabeled node features specific to the new categories. Therefore, the splitted datasets are further randomly divided into old and new classes according to node labels, with node-ids recorded to facilitate the reproduction and comparison of subsequent methods. To elaborate, distinct categories of node features are masked during different training phases driven by node-ids, thereby effectuating the division of graph data nodes for diverse tasks."}, {"title": "A.3 Baselines", "content": "Here are descriptions and implementation details of the baseline methods used in the experiments:\nNCD Methods:\n\u2022 AutoNovel [15] initiates a self-supervised pre-training phase using both labeled and unlabeled data to initialize the network, followed by supervised training exclusively with labeled data.\n\u2022 ResTune [27] partitions data features into two components: basic features, aimed at retaining information from labeled data, and residual features, dedicated to adjusting information derived from unlabeled data. The optimization of residual features is achieved through clustering objectives.\n\u2022 NCL [62] exploits local neighborhoods within the embedding space, empowering the model to assimilate knowledge from a broader set of positive samples, thereby elevating clustering accuracy.\n\u2022 DTC [16] employs the clustering algorithm to identify k-means centers for unlabeled data and subsequently estimates a potential target distribution to refine these centers.\ntask-IL Methods:\n\u2022 GEM [28] stores representative data in episodic memory. During the learning process, GEM modifies the gradients of the current task by incorporating the gradient calculated with the stored data, preventing an increase in the loss of previous tasks.\n\u2022 ER-GNN [64] represents a memory replay-based graph incremental learning method integrating memory replay into GNNs by preserving representative nodes selected from previous tasks.\n\u2022 TWP [26] is a regularization-based graph incremental learning method that introduces a penalty to preserve the topological information of previous graphs.\nclass-IL Methods:\n\u2022 CPCA [36] is a class-IL method on graphs, that employs class prototype augmentation, creating virtual classes through the combination of current prototypes to facilitate the learning of new category nodes.\nThese previous NCD methods are originally implemented on image data. Therefore, we replicate them based on GNN backbones in our NC-NCD setting. GEM [28] is a popular incremental learning method for Euclidean data, and is considered a baseline on graphs in many studies [26, 58, 64]. ER-GNN [64] and TWP [26] are both classical graph incremental learning methods, yet both rely on"}, {"title": "A.4 Implementation Details", "content": "For GNN backbones, we set their depth to be 2 layers, adopting the implementations from the PyTorch Geometric Library in all experiments. The hidden size is varied within the set {16, 32, 128} to accommodate different datasets. We utilize the Adam optimizer with the learning rate is set to 0.01, and weight decay is set to 5 \u00d7 10\u207b\u2074 In the pre-training phase, the training process will run for 200 epochs, and in the NCD-training phase, it will run for 600 epochs. Furthermore, early stopping is implemented to prevent model degeneration. The parameters of the above baseline methods are set as the suggested value in their papers or carefully tuned for fairness. We introduce an additional hyper-parameter A, which is set within the range of 0.4 to 1, to balance the performance of the model and avoid learning new categories too weakly or forgetting old categories too seriously. Other coefficients are adjusted for different datasets, including \u03b2\u2081 \u2208 [0.05, 0.1], \u03b2\u2082 \u20ac [4, 5] and \u03b7 \u2208 [0.2, 1]."}, {"title": "A.5 Additional Experiments and Analysis", "content": "We additionally employ average accuracy (AA) and average forgetting (AF) [58] to evaluate and compare the performance of all methods. These metrics serve to characterize the average performance of each model in the context of learning new classes and the resistance to forgetting, respectively. Considering n learning phases, let the comprehensive performance matrix be denoted as M\u2208 $\\mathbb{R}^{n \\times n}$. For phase i, the j-th (j \u2264 i) element in the i-th row of M corresponds to the accuracy of the current model on the learnt old classes in phase j. The AA for phase i is calculated through , while the AF is assessed by. Notably, as there is no forgetting for the initial task, its AF is inherently 0.\nAs shown in Table 7, our SWORD exhibits a comparatively high performance on AA, primarily attributed to its ability to effectively balance the classification performance of both new and old category nodes. The elevated performance in AF of SWORD indicates a reduced level of forgetting of old categories after learning new ones. While several NCD methods also demonstrate commendable performance on AF, our analysis from Table 3 reveals that this comes at the cost of the model's inability to effectively learn new categories, resulting in poor AA performance. It is noteworthy that, despite TWP, ER-GNN, and GEM achieving respectable AA performance on individual datasets (eg., Cora, Citeseer), their significant forgetting shown in AF is apparent, stemming from reliance on labeled data for old categories during the training stage. This underscores the importance of evaluating model performance in the NC-NCD"}]}