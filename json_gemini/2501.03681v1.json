{"title": "SLAM: Towards Efficient Multilingual Reasoning via Selective Language Alignment", "authors": ["Yuchun Fan", "Yongyu Mu", "Yilin Wang", "Lei Huang", "Junhao Ruan", "Bei Li", "Tong Xiao", "Shujian Huang", "Xiaocheng Feng", "Jingbo Zhu"], "abstract": "Despite the significant improvements achieved by large language models (LLMs) in English reasoning tasks, these models continue to struggle with multilingual reasoning. Recent studies leverage a full-parameter and two-stage training paradigm to teach models to first understand non-English questions and then reason. However, this method suffers from both substantial computational resource computing and catastrophic forgetting. The fundamental cause is that, with the primary goal of enhancing multilingual comprehension, an excessive number of irrelevant layers and parameters are tuned during the first stage. Given our findings that the representation learning of languages is merely conducted in lower-level layers, we propose an efficient multilingual reasoning alignment approach that precisely identifies and fine-tunes the layers responsible for handling multilingualism. Experimental results show that our method, SLAM, only tunes 6 layers' feed-forward sub-layers including 6.5-8% of all parameters within 7B and 13B LLMs, achieving superior average performance than all strong baselines across 10 languages. Meanwhile, SLAM only involves one training stage, reducing training time by 4.1 11.9x compared to the two-stage method\u00b9.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) (Touvron et al., 2023; OpenAI, 2023) have demonstrated significant advancements in reasoning abilities (Huang and Chang, 2023). However, these improvements are primarily focused on English, leading to inferior performance in non-English scenarios, especially in low-resource languages (Chen et al., 2023b). As the demand for deploying LLMs in multilingual environments increases (Qin et al., 2024), recent years have witnessed a growing interest in multilingual reasoning alignment, which aims to bridge the gap between the non-English reasoning abilities of LLMs and those in English (Chen et al., 2023b; Zhu et al., 2024; She et al., 2024).\nEarly work (Chen et al., 2023b) along this line of research directly fine-tunes models on multilingual mathematical question-answer pairs synthesized via machine translation. However, the reasoning answers are too complex for accurate translation, potentially compromising the performance of fine-tuned models. Building upon this, Zhu et al. (2024) introduce a two-stage learning strategy. It first teaches models to comprehend multilingual inputs by translating non-English questions into English counterparts and then trains them with English-only reasoning datasets to awaken their multilingual reasoning abilities.\nDespite its effectiveness, notable limitations persist with the two-stage framework. On the one hand, during its training process, all parameters of LLMs are tuned to facilitate multilingual reasoning alignment, which consumes substantial computational resources and hinders applying this method in resource-constrained scenarios. Moreover, conducting full-parameter training in the first training stage can lead to catastrophic forgetting, destroying the inherent reasoning abilities within LLMs. Thus this method depends on the second training stage to awaken the model's reasoning abilities, seeming necessary but inefficient.\nWhen considering multilingual models, one might think of capturing language-specific knowledge in certain parts of these models. Tang et al. (2024) has verified that only a small number of parameters in LLMs are language-dependent. In this work, we further confirm this viewpoint by examining neuron activations across different layers of LLMs. We find that lower-level layers are more involved in learning language-specific representations, which are then transformed into universal representations in higher-level layers. This suggests that it might be worth separating the learning of language-specific and universal representations in developing multilingual reasoning LLMs.\nThis work is motivated by a perspective of parameter-efficient fine-tuning. In response to our findings, we precisely identify and fine-tune the multilingualism-handling layers with translation-only data to achieve multilingual reasoning alignment in one stage. Our method, SLAM, first calculates the mean squared deviation (MSD) of the numbers of neurons activated by different languages and selects the layers with higher MSD scores. Next, recognizing that feed-forward networks (FFN) store most of the multilingual knowledge (Geva et al., 2021), SLAM achieves further efficiency by only training FFN sub-layers within the selected layers. Compared to the two-stage method, SLAM significantly improves the efficiency in terms of training data and computational resources. Moreover, SLAM merely trains models one time since freezing irrelevant parameters effectively prevents the inherent reasoning abilities from being destroyed, as illustrated by Figure 1.\nExperimental results on two multilingual mathematical reasoning benchmarks, MGSM (Shi et al., 2023) and MSVAMP (Chen et al., 2023b), show that SLAM outperforms strong baselines in both in-domain and out-of-domain settings, with only 8% and 6.5% of the parameters tuned in 7B and 13B models, respectively. Furthermore, SLAM reduces the training time by 4.1\u00d7 and 11.9\u00d7 compared to the two-stage method. Moreover, SLAM can also be generalized to multilingual common sense reasoning (Lin et al., 2021) and can leverage models with advanced reasoning abilities to consistently enhance multilingual reasoning performance."}, {"title": "Background", "content": "Point-wise feed-forward network. Multilingual reasoning requires LLMs to integrate both multilingual comprehension and reasoning abilities. Our approach builds on the findings that factual knowledge is stored in the model's FFN sub-layers (Dai et al., 2022; Meng et al., 2022). By directly injecting language-specific knowledge into these FFN sub-layers, we can enhance the multilingual comprehension abilities of LLMs. Typically, each layer of Transformer-based LLMs is predominantly composed of a multi-head self-attention (MHA) sub-layer followed by an FFN sub-layer. Concretely, let l denote the length of the input sentence. Given the output x\u00b2 \u2208 Rl\u00d7dmodel from the MHA sub-layer at the i-th layer, the computation within the FFN sub-layer can be formulated as follows:\nFFN(x\u00b2) = f(x\u00b2. Wap) Wa down, (1)\nup\nwhere Win \u2208 Rdmodel dinter, and Wrown E Rdinterdmodel are the mapping matrices. The dmodel denotes the input dimension, dinter refers to the intermediate hidden dimension, and f(\u00b7) represents a non-linear activation function.\nNeuron activation. Recent work (Dai et al., 2022; Mu et al., 2024) reveals that language-specific neurons in the FFN sub-layers significantly influence how LLMs process multilingual languages. As a new variant of the activation function, SwiGLU (Shazeer, 2020) is widely used in current LLMs (Touvron et al., 2023). Thus, Equation (1) can further be decomposed as follows:\nFFN(x\u00b2) = [f(Wate (x\u00b2)) Wap (x\u00b2)] Wdown,\nup\n(2)\nwhere Wi gate \u2208 Rdmodel dinter is the mapping metric introduced by SwiGLU. A neuron is defined as a single column in Wup, thereby an FFN sub-layer within one layer consists of dinter neurons. In our work, a neuron in the i-th FFN sub-layer is considered activated if the value of the element in f (Wate (x\u00b2)) exceeds zero (Tang et al., 2024)."}, {"title": "Methodology", "content": "In this section, we start with a preliminary study of examining neuron activations across different"}, {"title": "Preliminary Study", "content": "We examine neuron activations across different layers from two perspectives: (1) the number of neurons activated by different languages, and (2) the overlap ratio of activated neurons between non-English languages and English. We first sample n questions, each expressed in 10 different languages. Let lang denote the language of the input sentence. Subsequently, we calculate the count of activated neurons for all samples of a language lang in the i-th layer, as specified by the following equation:\nAlang = [[f(Wate(x\u00b2)) > 0], (3)\nwhere II is the indicator function. To provide a more intuitive understanding of neuronal activation, we normalize the count of activated neurons, as defined by the following equation:\nRiang = Alang/dinter(4)\nThen we compute the overlap ratio of activated neurons between non-English languages and English. The results presented in Figures 2, 3 show that while the number of activated neurons across all languages initially decreases and then stabilizes, the neurons activated by non-English languages and English progressively overlap and finally reach a stable level. This indicates the existence of language-specific layers, which are more involved in learning language-specific representations. The findings also align with the phenomenon found in Zhao et al. (2024). Specifically, we define all layers preceding the point at which the average overlap ratio among all non-languages reaches its maximum as language-specific layers, as shown in Figure 3. Full visualization results of all layers are presented in Figure 11 and Figure 12, respectively."}, {"title": "SLAM", "content": "In response to our findings, we formally introduce a training method to efficiently achieve multilingual reasoning alignment of LLMs in one stage. The method consists of two steps: (1) Selecting multilingualism-handling layers, and (2) Selectively supervised fine-tuning.\nSelecting multilingualism-handling layers. Directly fine-tuning the language-specific layers will inevitably impair the model's inherent reasoning abilities, since reasoning abilities also persist in these layers (Chen et al., 2023a). Therefore, we design a layer selection algorithm to identify layers that are more involved in multilingual comprehension, thereby effectively balancing understanding and reasoning abilities. Consequently, we introduce the mean squared deviation (MSD) to precisely measure the stabilization of neuron activation across different languages. For each layer i within the language-specific layers denoted by K, MSD is defined by the following equations:\n\u03bc\u03b5 =1/|L| \u03a3 Riang\nlangEL(5)\nMSD\u00b2 = 1/\u039a \u03a3 \u03a3 (Riang \u2013 \u03bc\u00b2) 2, (6)\niEK langEL\nwhere L denotes all languages and Riang is calculated using Equation (4). A higher MSD indicates the destabilization of neurons activated in different languages, suggesting that the layer is more actively engaged in multilingual comprehension. The average engagement in multilingual comprehension across language-specific layers is quantified by the following equation:\n\u03b8=1/\u039a \u03a3MSD\u00b2. (7)\nWe select the layers with MSD\u00b2 exceeding threshold \u03b8 for subsequent fine-tuning, as these layers contribute most to multilingual comprehension while minimally affecting reasoning abilities.\nSelectively supervised fine-tuning. Since the FFN sub-layers store the majority of the knowledge (Geva et al., 2021; Dai et al., 2022), we achieve further efficiency by only training the FFN sub-layers within the multilingualism-handling layers utilizing X-English translation data. Given non-English inputs Ilang and their English counterparts Ieng, the optimization objective can be formulated as:\narg min \u03a3 - log py(Ieng|Ilang), (8)\n\u03c6lang\u2208L\\{English}\nwhere denotes the FFN of the selected layers."}, {"title": "Experiment Settings", "content": "Baseline Models\nFor a fair comparison, we compare SLAM with the following strong baselines, all trained based on Llama 2 (Touvron et al., 2023). Detailed statistics of the training data for all baselines can be found in the Appendix A.\nMAmmoTH: Yue et al. (2024) collected diverse instruction datasets on MATH and directly fine-tuned the model on these datasets.\nWizardMath: Luo et al. (2023) leveraged reinforcement learning to train the model on two mathematical reasoning datasets GSM8K and MATH.\nMetaMath: Yu et al. (2023) first employed question bootstrapping to create high-quality English reasoning dataset METAMATHQA and then fine-tuned the model on the dataset.\nMathOctopus: Chen et al. (2023b) employed supervised fine-tuning using MSGM8KINSTRUCT, a multilingual reasoning dataset constructed by directly translating the data from GSM8K.\nLangBridge: Yoon et al. (2024) introduced an extra multilingual encoder and trained a linear layer connecting this encoder to the LLM using English data to enhance multilingual comprehension.\nQAlign: Zhu et al. (2024) employed a two-stage training strategy, where the model first learns to translate non-English questions into English and then unlocks multilingual reasoning abilities using the English reasoning data METAMATHQA."}, {"title": "Experimental Details", "content": "We constructed X-English translation data from MGSM8KINSTRUCT (Chen et al., 2023b) as training data. For MGSM (Shi et al., 2023) and MSVAMP (Chen et al., 2023b), we trained only the FFN within the first six layers of the model. Considering that QAlign and LangBridge are either trained on METAMATHQA or built upon MetaMath, we implemented SLAM on the MetaMath model to ensure a fair comparison. During inference, we adopted the settings from Yu et al. (2023). For more details, please refer to Appendix A."}, {"title": "Evaluation Datasets", "content": "We utilized MGSM and MSVAMP as in-domain and out-of-domain test sets to evaluate the multilingual mathematical reasoning abilities of LLMs. Data statistics are reported in Table 1."}, {"title": "Evaluation Metrics", "content": "Following Zhu et al. (2024), our evaluation primarily focuses on two key dimensions: Accuracy and Prediction Consistency Ratio.\nAccuracy. Following Yu et al. (2023), accuracy is calculated by comparing the last numerical value in the response to the gold answer. Higher accuracy indicates stronger reasoning ability.\nPrediction Consistency Ratio (PCR). Assuming M and N are sets of questions correctly answered in English and non-English languages respectively. PCR is calculated as: |MON|/|M|. Higher PCR denotes the model's non-English reasoning ability is closer to its English reasoning ability."}, {"title": "Experimental Results", "content": "Main Results\nSLAM effectively achieves multilingual reasoning alignment. We present the results on MGSM in Table 2, which demonstrates that SLAM outperforms all strong baselines in in-domain settings. Specifically, SLAM achieves comparable performance with QAlign in 7B models and surpasses all baselines in 13B models, with an average accuracy improvement of 2.1%. Notably, compared to MetaMath, SLAM exhibits substantial improvements, achieving increases of 29.2% and 32.8% in the 7B and 13B models, by selectively fine-tuning multilingualism-handling layers in MetaMath using translation data. Furthermore, as shown in Figure 7 (a), SLAM demonstrates higher answer consistency. This highlights that directly enhancing multilingual comprehension at specific lower-level layers can effectively improve the multilingual reasoning abilities of LLMs.\nSLAM shows significant out-of-domain generalization. To further validate the generalization ability of SLAM, we evaluate it on the out-of-domain test sets, MSVAMP. As shown in Table 4, SLAM demonstrates robust generalization compared with all baselines, exhibiting an average accuracy improvement of 5.8% and 0.2% in the 7B and 13B models, respectively. Notably, SLAM-7B shows substantial performance gains across all 10 languages. Moreover, as shown in Figure 7 (b), SLAM also enhances answer consistency across all non-English languages. This superior generalization is attributed to the modest number of trainable parameters in SLAM. Unlike the baselines, which undergo fine-tuning all parameters on the in-domain dataset and potentially suffer from overfitting, SLAM only fine-tunes partial parameters, significantly reducing the impact of domain shifts.\nSLAM demonstrates superior efficiency. Rather than fine-tuning all layers, SLAM selectively trains layers responsible for multilingual comprehension. As shown in Table 2 and Table 4, SLAM fine-tunes only 8% and 6.5% of the"}, {"title": "Ablation Study", "content": "Training different layers. To evaluate the necessity of the layer selection training strategy, we conduct ablation studies by training different layers. As shown in Figure 4, the layers selected by SLAM achieve the best performance both in-domain and out-of-domain performance. Selecting an insufficient number of layers may lead to inadequate multilingual comprehension, while excessive layer selection will impair the model's reasoning abilities. This suggests that while the ability to handle multilingualism is concentrated in lower-level layers, precisely selecting layers that are more actively engaged in multilingual comprehension is crucial for effective multilingual reasoning alignment.\nTraining different sub-layers. To explore the role of different sub-layers within the multilingualism-handling layers, we conduct ablation studies by training only the Attention sub-layers, and both the Attention and FFN sub-layers, utilizing X-English translation data. As shown in Figure 5, training only the FFN sub-layers results in the highest average accuracy for both in-domain and out-of-domain tests (For the results of MSVAMP, refer to Appendix B). Specifically, training only the FFN sub-layers leads to notable"}, {"title": "Analysis", "content": "Scalability of SLAM in Multilingual Common Sense Reasoning\nTo evaluate the scalability of SLAM, we extend our method to Multilingual Common Sense Reasoning (XCSQA) (Lin et al., 2021). More experimental details and results can be found in Appendix C. We observe that SLAM improves accuracy across all languages. Notably, as shown in Table 5, SLAM achieves significant improvements for low-resource languages such as Swahili, Hindi, and Arabic, with increases of 22.6%, 13.2%, and 14.5%, respectively. The results demonstrate that our method can be effectively adapted to other multilingual reasoning tasks. This also suggests that the multilingual reasoning process can be decomposed into comprehend-then-reason patterns across layers."}, {"title": "Extending SLAM to Other Strong Reasoning Models.", "content": "We extend our method to the RFT-MuggleMath models (Li et al., 2024), which possess stronger reasoning abilities. As shown in Table 6, SLAM achieves significant in-domain and out-of-domain improvements, with increases of 33.3% in the average accuracy for non-English languages in both the 7B and 13B models, while tuning only 6.7% and 5.4% of parameters, respectively. This suggests that when the models possess stronger English reasoning abilities, it provides an advantageous starting point for SLAM, which leads to significant improvements in multilingual reasoning alignment."}, {"title": "Comparison of Neuron Activation Before and After Training", "content": "To facilitate comparisons, we compute the average overlap ratio across all non-English languages to represent the overlap at that layer. As shown in Figure 6, the overlap ratio increases significantly after training (The comparison results of MetaMath-13B, refer to Appendix E). This demonstrates that enhancing the overlap of activated neurons between non-English languages and English at lower-level layers can improve the model's comprehension of multilingual questions, thereby achieving better"}, {"title": "Related Work", "content": "Multilingual Mathematical Reasoning\nSignificant performance discrepancies in LLM reasoning between high-resource and low-resource languages have spurred research aimed at aligning their multilingual reasoning abilities. Early efforts (Chen et al., 2023b; Lai and Nissim, 2024) directly fine-tune models on multilingual mathematical reasoning data generated via machine translation. Another line of research concentrates on leveraging additional components during training. These works either utilize a multilingual encoder (Yoon et al., 2024; Huang et al., 2024b) to facilitate cross-lingual transfer or employ an additional translation model to construct preference signals for preference optimization (She et al., 2024). Recent work (Zhu et al., 2024) proposes a two-stage approach where the model is first learned to translate non-English questions into English for multilingual comprehension and then trained on English reasoning data to enhance multilingual reasoning abilities. In contrast, our study particularly focuses on achieving efficient multilingual reasoning alignment, a perspective that remains under-explored. We precisely fine-tune lower-level layers that are responsible for learning language-specific representations and leverage the model's inherent reasoning ability to facilitate multilingual reasoning alignment. This ensures superior efficiency in one stage without the need for two-stage full parameters training or introducing additional components."}, {"title": "Mechanism of Multilingual Language Processing in LLMs", "content": "Recently, multilingual LLMs have garnered significant attention. Numerous studies attempt to explore the mechanism of LLMs in processing multiple languages. Recent research (Chen et al., 2023a; Zhao et al., 2024) reveals that both lower and upper layers of multilingual LLMs are language-dependent. The lower layers are designed to convert inputs from various languages into a high-resource language (e.g., English), while the upper layers perform the reverse function. Additionally, further studies (Tang et al., 2024; Mu et al., 2024) highlight that the proficiency of LLMs in comprehending a particular language is significantly influenced by a small subset of language-specific neurons. Despite their limited number, these neurons play a crucial role in bolstering the multilingual understanding abilities in LLMs. Aligning with this line of research, SLAM further reveals that specific layers are dedicated to handling multilingualism, as evidenced by neuron activation patterns. This advancement significantly deepens the understanding of the multilingual mechanisms in LLMs."}, {"title": "Conclusion", "content": "In this paper, we propose SLAM for efficiently achieving multilingual reasoning alignment in LLMs. Inspired by neuron activations in language abilities, we develop an approach to precisely identify the layers mostly engaging in multilingual comprehension during multilingual reasoning. After that, we fine-tune the FFN sub-layers within the selected layer to enhance the multilingual understanding abilities of LLMs. This enables achieving multilingual reasoning alignment in one stage without compromising LLMs' inherent reasoning abilities. The experimental results on multilingual mathematical reasoning demonstrate the effectiveness and superior efficiency of SLAM. Further analysis reveals that SLAM exhibits significant out-of-domain generalization and can be effectively adapted to other multilingual reasoning tasks."}, {"title": "Limitations", "content": "Our work presents several limitations worth noting. First, to ensure a fair comparison with baseline models, our method primarily conducts experiments using the Llama2 series models. Future work will involve extending our experiments to additional series models to more comprehensively evaluate the generalizability of our method across diverse baseline models. Second, while our method achieves substantial advantages in average accuracy on both in-domain and out-of-domain test sets, the degrees of alignment across different languages result in performance trade-offs. We hypothesize that this issue may be due to the imbalanced data among languages in the X-English translation dataset. In the future, we will conduct an in-depth analysis of this phenomenon."}]}