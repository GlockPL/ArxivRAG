{"title": "Semantic Enrichment of the Quantum Cascade Laser\nProperties in Text- A Knowledge Graph Generation\nApproach", "authors": ["Deperias Kerre", "Anne Laurent", "Kenneth Maussang", "Dickson Owuor"], "abstract": "A well structured collection of the various Quantum Cascade Laser (QCL)\ndesign and working properties data provides a platform to analyze and understand the\nrelationships between these properties. By analyzing these relationships, we can gain\ninsights into how different design features impact laser performance properties such\nas the working temperature. Most of these QCL properties are captured in scientific\ntext. There is therefore need for efficient methodologies that can be utilized to extract\nQCL properties from text and generate a semantically enriched and interlinked plat-\nform where the properties can be analyzed to uncover hidden relations. There is also\nthe need to maintain provenance and reference information on which these properties\nare based. Semantic Web technologies such as Ontologies and Knowledge Graphs have\nproven capability in providing interlinked data platforms for knowledge representation\nin various domains. In this paper, we propose an approach for generating a QCL prop-\nerties Knowledge Graph (KG) from text for semantic enrichment of the properties.\nThe approach is based on the QCL ontology and a Retrieval Augmented Genera-\ntion (RAG) enabled information extraction pipeline based on GPT 4-Turbo language\nmodel. The properties of interest include: working temperature, laser design type, las-\ning frequency, laser optical power and the heterostructure. The experimental results\ndemonstrate the feasibility and effectiveness of this approach for efficiently extracting\nQCL properties from unstructured text and generating a QCL properties Knowledge\nGraph, which has potential applications in semantic enrichment and analysis of QCL\ndata.", "sections": [{"title": "1 Introduction", "content": "Quantum Cascade Lasers (QCL) are semiconductor laser devices which consists of nano-\nmetric stack of different semiconductor materials and whose spectral emission is restricted\nto the frequency range from about 100GHz to 10THz. The stacks of different materials are\nreferred to as heterostructures. Interactions between the various layers of materials results to\nvarious emission behaviour of the QCL laser device [1]. The nature of the radiations emitted\nby these laser devices have enabled various applications ranging from analysis of chemicals,\nhigh-resolution spectroscopy in astronomy, detection of organic compounds in drugs etc [2-7]."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Information Extraction in Materials Science Domain", "content": "Extraction of materials properties from text has gained a lot of interest recently as occa-\nsioned by the need for accelerated materials discovery. The methodologies developed can be\nbroadly classified in to rule-based methods and machine learning based methods. Rule-based\nmethods constitutes rules, grammars and other expert-defined structures for identification\nof properties in specific domains. The machine learning based approaches entails training of\nlearning algorithms on labelled data to enable them to learn how to identify specific materials\nproperties in text.\nExamples of rule based toolkits adopted for properties extraction in materials science\ninclude chemDataExtractor [12], LeadMine [13], ChemicalTagger [14], tmChem [15] and\nChemSpot [16]. The chemDataExtractor toolkit has also been widely adopted for materi-\nals properties extraction in other specific use cases which includes: thermo-electric mate-\nrials [17], semiconductor bandgaps [18], refractive indices and dielectric constants [19], an\nauto-populated ontology of materials science [20], battery materials [21], transition temper-\natures of magnetic materials [22] and quantum cascade laser properties [9].\nMachine learning methods have also been adopted in the extraction of materials science\nproperties. Examples include generation of datasets of gold nano-particle synthesis proce-\ndures, morphologies and size entities [23], and materials synthesis recipes [24]. Another work\nis on the use of the combination of deep convolutional and recurrent neural networks for\nnamed entity recognition [25]. BERT(Bidirectional Encoder Representations from Transform-\ners) models have also been proposed for the analysis of optical materials [26] and extraction\nof battery materials from scientific text [27].\nThe emergence of generative large language models have also opened opportunities in the\nextraction of materials properties from text. The models have been harnessed for text parsing\nin solid-state synthesis internary chalcogenides [28] .The in-context learning method is also\napplied to assess the ability of LLMs in processing materials data [29] and extracting materials\ndata from research papers [30]. Lastly, LLMs have also been utilised in the construction of\nfunctional materials Knowledge Graph in multidisciplinary materials science [31]."}, {"title": "2.2 Knowledge Graphs in Materials Science Domain", "content": "Knowledge Graphs have been proposed in representing knowledge for properties in the mate-\nrials science domain. The KGs are based on several foundational and specific domain ontolo-\ngies developed for this domain. The motivation behind these KGs is to provide an accelerated\nanalysis of materials science properties for various reasons, including materials discovery. The\nproposed KGs ranges from specific materials such as nanocomposite materials [32] and a wide"}, {"title": "2.3 Summary", "content": "Despite the great advancements in Information Extraction in materials science domain, there\nare a couple of problems to be addressed: the rule-based approach developed for QCL prop-\nerty extraction from text is specific and is limited in cases where their is slight change in text\nstructure. The machine learning models need quality training data to effectively train and\nevaluate the models for this task. The LLM based methodologies gives a promising direction\nin the extraction of QCL properties from text. The proposed KGs in the materials science\ndomain do not capture the properties of interest in the QCL domain. They cannot therefore\nbe adopted for QCL properties representation and exploration.\nThere is therefore need for efficient methodologies for extracting QCL properties from\ntext to generate structured data and utilise this data to generate a Knowledge Graph for\nrepresenting QCL properties, relationships among them and the provenance information. To\nthe best of our knowledge, this work presents the initial steps for implementing the task of\nQCL properties extraction from text and KG generation for property exploration."}, {"title": "3 Methodology", "content": "The Knowledge Graph generation approach is composed of the following parts: Information\nExtraction pipeline and the KG modelling and data enrichment part. We describe these parts\nin the following subsections:"}, {"title": "3.1 Information Extraction Pipeline", "content": "In this module, we explore the use of large language models in developing the pipeline.\nWe approach this process as an open information extraction task as we are interested in\nliteral values for the properties i.e a value and a unit. We propose a RAG enabled pipeline\nbased on GPT-4 Turbo. This is owed to GPT-4 Turbo improved efficiency in generating\nresponses and the larger context window [39]. Our approach is based on advanced RAG [40].\nLarge language models such as GPT models are trained on general knowledge data and\ncannot be efficiently used on specific domain tasks without adaptation. We hypothesize that\nexposing the model to labelled data consisting of sample text describing QCL properties\nand the corresponding extracted properties improves the model's performance on this task\nof property extraction from text. This also aligns the model's output to the expected format\nand minimizes irrelevant responses. As illustrated in Figure 1, the module has three sections\ni.e Retrieval, Data Augmentation and Data Generation. The rest of this subsection describes\nthe pipeline modules.\nRetrieval: An input sentence (query) containing QCL property of interest and an instruc-\ntion to the large language model is submitted by the user to the retriever. This is then for-\nwarded by the retriever to the data augmentation module for retrieval of similar responses\nbased on the query."}, {"title": "3.2 Knowledge Graph Modelling and Data Enrichment", "content": "In this section, there are two processes that we carry out: first we define the KG model to\norganize the data and secondly we map the data to enrich it. We detail them in the following\nsubsections:\nThe Knowledge Graph Modelling: A Knowledge Graph represents a semantic network\nof interlinked entities. Entities refers to real world concepts or ideas that can be identified\nby a unique identifier on the web. A Knowledge Graph is defined in form of triples, that\nconsists of two entities and a relation (predicate) linking them. Formally, a Knowledge graph\nKG can be defined as KG = {t1, t2, t3...tn} and t refers to the various triples in the KG\nand n the number of triples in the KG. A triple t= {s,p,o} where s is the subject, p the\npredicate and o the object. s, p and o are denoted by Resource Identifiers inform of Uniform\nResource Identifiers (URIs) or Literals (e.g., strings, numbers, dates). The semantics of a KG\nare provided by ontologies or standard vocabularies.\nIn our case, the entities are the various QCL properties, the various relationships among\nthem and the provenance information for these properties. We define the KG schema whose\nsemantics are provided by the QCL ontology model\u00b2 [10] and other vocabularies such as\nBIBO\u00b3 and schema.org4. Figure 3 shows the KG schema used to organize the data and table\n1 shows the prefixes and URIs for the namespaces used in the KG schema.."}, {"title": "Data Mapping", "content": "In this phase, several steps are carried out in order to perform map-\nping of the data values generated in section 3.1 to the entities. This is implemented via the\ndata properties. All the object properties are also implemented. The the KG classes are also\ninstantiated. We also specify the data types for all the data instances. This is implemented\nusing the rdflib library 5. The units, design types and the relevant working modes are also en-\nriched with the relevant URIs. The redundant triples are also examined and eliminated from\nthe generated Knowledge Graph. The final RDF file is then serialized into the Turtle and\nthe RDF/XML formats in order to generate the Knowledge Graph for querying and explo-\nration. The generated Knowledge Graph contains a total of 3403 triples containing the QCL\nproperties and their associated provenance information. A visualization of a sample instance\nof a QCL heterostructure (capturing the design type and material combination information)\nand its provenance information is shown in Figure 4."}, {"title": "4 Experiments", "content": "In this section, we carry out experiments to evaluate the KG generation approach. This is\ndone is based on three strategies: the performance of the approach in QCL property extraction\nfrom text, the consistency and the correctness of the generated KG in terms conformance to\nthe QCL properties domain requirements i.e the ability to capture the intended knowledge\ncorrectly."}, {"title": "4.1 Property Extraction From Text", "content": "Evaluation Metrics: For the evaluation of the information extraction module, we adopt the\nexpert validation approach. This entails comparison of the model's output with the expert\nannotated ground truth label in the evaluation dataset. We use the precision and recall in\norder to evaluate the performance of the approach on QCL property extraction from text [85].\nPrecision is the fraction of correct (relevant) records among all extracted records and the\nrecall is the fraction of successfully extracted records among all correct (relevant) records in\nthe dataset. The metrics are determined as follows:\nPrecision=TPTP+FP (1)\nRecall =\u03a4\u03a1TP+FN (2)\nTP refers to the true positive count (the number of correct records extracted), FP is the\nfalse positive count (the number incorrect records extracted), and FN corresponds to the\nfalse negative count (the number of correct records that are not extracted). We define the\nterms correct and incorrect in our context as follows:\nDefinition 1: The word \"correct\" in this context implies that the property value extracted\ncan be validated by a human expert when reading the corresponding sentence containing the"}, {"title": "4.2 Knowledge Graph Evaluation", "content": "The generated Knowledge Graph is evaluated based on two metrics: the consistency in the\nKG triples and the correctness of the KG in capturing the intended knowledge in the QCL\ndomain properties. The consistency ensures the logical soundness of the defined triples in\nthe generated KG. The correctness of the KG in terms of the domain requirements aims to\nevaluate the generated KG's ability in capturing the domain knowledge of interest and being\nable to provide answers to questions regarding the avrious QCL properties.\nIn order to validate the ability of the KG to conform to the domain requirements, we\ndefine a set of 7 classes of competency questions (CQs) with the help of the QCL domain\nexperts. The competency questions capture the whole QCL properties of interest i.e the\ndesign, working properties, the laser working modes and the provenance information. The\ncompetency questions entails probable questions that the QCL experts could be interested to\nget answers to when trying to understand the implications of the laser design on the overall\nlaser performance. Some of the competency questions are adopted from the user requirements\nof the QCL ontology."}, {"title": "5 Results and Discussions", "content": "In this section, we present and discuss the results for the evaluation of the KG generation\napproach based on the property extraction from text and the ability of the generated KG to\nmeet the QCL domain requirements. We detail them in the following subsections:"}, {"title": "5.1 Property Extraction from Text", "content": "We present the results for QCL property extraction from text analyzed per QCL property as\nthe properties have a varying level of difficulty during the extraction process. The results are\nas shown in Table 4 for the laser power, Table 5 for working temperature, Table 6 for laser\nheterostructure materials, Table 7 for lasing frequency, Table 8 for the laser design type and\nTable 9 for the average performance of the models for all the properties.\nThe laser power, working temperature and frequency exhibit higher precision in the ex-\ntraction process in both simple query and the proposed approach. This is attributed to the\nfact that these properties are generally available in the general knowledge of the models.\nHowever, their is lower recall for the simple queries for these properties. This is in cases"}, {"title": "5.2 Knowledge Graph Evaluation", "content": "The Knowledge Graph consistency is validated by lack of inconsistencies/contradictions in\nthe generated triples. We the validate the KG consistency using the pellet reasoner [86].\nFor the Knowledge Graph correctness, We run a total of 20 queries in order to validate the\nsuitability of the generated KG in capturing the QCL properties, the relationships between\nthem and their provenance information. Table 10 shows the specific queries run for each class\nof queries specified in Table 3.\nThe queries range from simple to complex queries regarding the QCL properties and\ntheir provenance information. We present a scenario where a QCL expert is interested in the\nheterostructure materials composition of a QCL device with a certain working property, for\ninstance a frequency value greater than 1.5. Such a question can be captured by query 5.2 in\nTable 10. A corresponding SPARQL query and the retrieved results for query 5.2 are shown\nin Figure 5. All the queries are successfully answered by the generated KG and the complete\nresults are available in the GiHhub repository 6.\nThe ability of the generated KG in successfully answering the competency questions\nindicates its capability in capturing QCL properties information from the various textual\nsources. This provides a unified platform that allows exploration of QCL properties in a\nstructured manner to be able to derive insights on the relationship between the properties\nas opposed to manually exploring the textual documents for these properties. This is useful\nin scenarios where there is need for a quicker comparison of the various QCL properties\nfor instance, the working properties for a particular laser design. The ability to capture the\nprovenance information for the QCL properties also makes it possible to track the sources of\nthis information via permanent identifiers such as the DOI and the URL. With the generated\nKG, it is also possible to have a linked acess to the references for the various QCL properties"}, {"title": "6 Conclusions and Future Work", "content": "In this paper, we address the issue of semantic enrichment of QCL properties in text by\npresenting an approach for generating a Knowledge Graph for QCL properties from text.\nThis enables exploration of the properties in the various heterogenous textual sources while\nmaintaining provenance information. The approach is composed of two parts: an information\nextraction pipeline for extracting QCL properties from text based on an LLM enabled RAG\napproach and the data enrichment part where all the data is mapped and the relationships\ninterlinked. The semantics of the QCL properties KG are provided by the QCL ontology\nand other vocabularies. We evaluate the KG generation approach based on two strategies i.e\nthe performance in QCL property extraction from text and the correctness of the generated\nKnowledge Graph in modelling the knowledge in the QCL properties domain.\nThe proposed information extraction approach presents competitive results indicating the\nmodel's ability to learn how to identify domain specific properties with the help of curated"}]}