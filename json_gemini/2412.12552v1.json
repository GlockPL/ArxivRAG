{"title": "SA-MODIFIED: A FOUNDATION MODEL-BASED ZERO-SHOT APPROACH FOR\nREFINING NOISY LAND-USE LAND-COVER MAPS", "authors": ["Sparsh Pekhale", "Rakshith Sathish", "Sathisha Basavaraju", "Divya Sharma"], "abstract": "Land-use and land cover (LULC) analysis is critical in remote sensing, with wide-ranging applications across diverse fields such as agriculture, utilities, and urban planning. However, automating LULC map generation using machine learning is rendered challenging due to noisy labels. Typically, the ground truths (e.g. ESRI LULC, MapBioMass) have noisy labels that hamper the model's ability to learn to accurately classify the pixels. Further, these erroneous labels can significantly distort the performance metrics of a model, leading to misleading evaluations. Traditionally, the ambiguous labels are rectified using unsupervised algorithms. These algorithms struggle not only with scalability but also with generalization across different geographies. To overcome these challenges, we propose a zero-shot approach using the foundation model, Segment Anything Model (SAM), to automatically delineate different land parcels/regions and leverage them to relabel the unsure pixels by using the local label statistics within each detected region. We achieve a significant reduction in label noise and an improvement in the performance of the downstream segmentation model by \u2248 5% when trained with denoised labels.", "sections": [{"title": "1. INTRODUCTION", "content": "Accurate Land-Use Land Cover (LULC) mapping is essential for numerous remote sensing applications, including crop monitoring, urban infrastructure development, and environmental conservation. To generate LULC maps at scale, we often rely on supervised machine learning models. However, this automation faces significant hurdles, primarily stemming from the quality and consistency of ground truth annotations. In many widely used LULC datasets, such as ESRI LULC [1] and MapBioMass [2], the presence of noisy, incorrect, or ambiguous labels is a persistent issue. These inaccuracies not only degrade model performance but also undermine the reliability of subsequent analyses based on these maps.\n\nThe challenges associated with noisy labels in LULC datasets are multi-faceted. First, the complexity of landscapes and the subtle differences between land cover classes can lead to misclassification during the model-based annotation process. This is especially problematic in heterogeneous environments where distinct land covers may share similar spectral signatures, making it difficult for automated systems to distinguish between them. While these datasets are generated through sophisticated algorithms, the inherent limitations of these models, including biases in training data and algorithmic assumptions, contribute to the propagation of errors.\nPrior Arts: Traditional approaches to addressing label noise, such as unsupervised clustering algorithms [3, 4], attempt to"}, {"title": "2. METHOD", "content": "Stage 1: SAM-based Land Parcel Identification\nIn the first stage, we utilize the Segment Anything Model (SAM), a foundation model that combines deep convolutional neural networks (CNNs) and transformer architectures for state-of-the-art segmentation. Trained on a vast dataset, SAM excels in recognizing and delineating objects and regions across diverse and complex environments by generating a comprehensive feature map that captures both spatial details and contextual information. Unlike traditional models, SAM generalizes effectively without fine-tuning, making it ideal for segmenting input images into distinct land parcels.\nMathematically, let I represent the input image, and \\(F(I)\\) denote the feature map generated by SAM. For each pixel pj in the image, SAM predicts the segment si it belongs to based on the feature representation \\(F(p_j)\\). This can be expressed as:\n\\[si = \\arg \\max_{S} P(s | F(p_j))\\]\nwhere S is the set of all possible segments, and \\(P(s | F(p_j))\\) is the probability that pixel pj belongs to segment s given its feature representation \\(F(p_j)\\).\nStage 2: Majority Voting for Class Refinement\nOnce the land parcels have been identified in Stage 1, the second stage involves refining the noisy labels within each segment using a majority voting mechanism. For each segment si identified in Stage 1, we have a set of pixels P\u2081 = {p1,p2,..., pm;} and their corresponding noisy labels Li = {l1,l2,...,lm;}. The refined label L for each segment is determined by applying majority voting on the noisy labels within that segment:\n\\[L = mode(L_i) = \\arg \\max_l \\sum_{j=1}^{m_i}I(l_j = l)\\]"}, {"title": "3. EXPERIMENTS", "content": "Dataset: The experiments are conducted using the Map-Biomas LULC dataset for Brazil. This dataset provides annual LULC classifications in 30m spatial resolution across Brazil. For our study, we focus exclusively on the level 1 labels, which include Cropland, Forest, Barren/Built-up, Waterbody, and Pasture. Additionally, the dataset contains a class labelled \"mosaic of uses,\" representing pixels where the classification is uncertain, and the exact land cover type is ambiguous. Our objective is to denoise these uncertain labels by identifying the most probable class to which these pixels belong. We use Harmonized Landsat and Sentinel-2 (HLS) as the satellite image source. A multi-level stratified sampling strategy was applied across Brazil to identify 112, 092 AOIs of 235.93KM\u00b2 each for our experiments.\nBaseline 1 (BL1): K-means algorithm aims to minimize the variance within clusters by iteratively assigning data points to one of K clusters based on the nearest mean, or centroid, of the cluster. Mathematically, the objective of K-means is to minimize the following loss function:\n\\[J = \\sum_{k=1}^{K} \\sum_{i=1}^{n_k} ||x_i^{(k)} - \\mu_k||^2\\]\nwhere \u03bc\u03b5 is the centroid of the k-th cluster, \\(x_i^{(k)}\\) represents the i-th data point assigned to the k-th cluster, and nk is the number of data points in cluster k.\nBaseline 2 (BL2): Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clusters data based on density. It requires two parameters: \u20ac, the neighborhood radius, and Min Pts, the minimum number of points to form a cluster. Mathematically, a point p is a core point if:\n\\[|\\{q \\in D | dist(p,q) < \\epsilon\\}| \\geq MinPts\\]\nwhere D represents the dataset, and dist(p, q) is the distance between points p and q. Clusters are formed by expanding from core points, while points that don't meet the criteria are labeled as noise."}, {"title": "4. RESULTS AND DISCUSSION", "content": "The reliability of the model is evaluated on four fronts; (I) the Ability to reduce the noise present in the form of stray pixels, (ii) the ability to improve boundary/demarcation between classes hence reducing the mixing between classes, (iii) improvement in downstream segmentation task and (iv) and comparison with other unsupervised algorithms\nA. Impact on Stray Pixels\nB. Impact on Class Boundaries\nC. Impact on Downstream Segmentation Tasks"}, {"title": "5. CONCLUSION", "content": "In this paper, we presented a two-stage approach leveraging foundation models and zero-shot learning to mitigate label noise in LULC datasets. By using the Segment Anything Model (SAM) for precise land parcel segmentation and applying statistical relabeling, our method effectively reduces noise and improves the accuracy of LULC maps. Experimental results demonstrate that this approach surpasses traditional methods, enhancing both denoising and segmentation tasks. Future efforts will focus on extending this approach to utilise and develop EO foundation models."}]}