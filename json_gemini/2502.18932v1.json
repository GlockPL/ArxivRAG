{"title": "SLAM in the Dark: Self-Supervised Learning of Pose, Depth and Loop-Closure from Thermal Images", "authors": ["Yangfan Xu", "Qu Hao", "Lilian Zhang", "Jun Mao", "Xiaofeng He", "Wenqi Wu", "Changhao Chen"], "abstract": "Visual SLAM is essential for mobile robots, drone navigation, and VR/AR, but traditional RGB camera systems struggle in low-light conditions, driving interest in thermal SLAM, which excels in such environments. However, thermal imaging faces challenges like low contrast, high noise, and limited large-scale annotated datasets, restricting the use of deep learning in outdoor scenarios. We present DarkSLAM, a noval deep learning-based monocular thermal SLAM system designed for large-scale localization and reconstruction in complex lighting conditions.Our approach incorporates the Efficient Channel Attention (ECA) mechanism in visual odometry and the Selective Kernel Attention (SKA) mechanism in depth estimation to enhance pose accuracy and mitigate thermal depth degradation. Additionally, the system includes thermal depth-based loop closure detection and pose optimization, ensuring robust performance in low-texture thermal scenes. Extensive outdoor experiments demonstrate that DarkSLAM significantly outperforms existing methods like SC-Sfm-Learner and Shin et al., delivering precise localization and 3D dense mapping even in challenging nighttime environments.", "sections": [{"title": "I. INTRODUCTION", "content": "Simultaneous Localization and Mapping (SLAM) is crucial for intelligent systems from mobile robots, drones, to self-driving vehicles, enabling their real-time localization and mapping for autonomous navigation. Traditional visual SLAM systems, which rely on visible-light (RGB) cameras, struggle in challenging lighting conditions such as strong light, shadows, or nighttime, limiting their use in all-time scenarios. Thermal cameras, which detect heat radiation, offer a solution by functioning in darkness, smoke, and dust, complementing visible-light sensors. Recent improvements in thermal camera resolution and sensitivity have increased their reliability in autonomous systems.\nWhile thermal technology is well-established in areas such as object detection and identification, its application in SLAM remains limited due to the challenges of feature extraction, matching and reconstruction in thermal images. However, thermal SLAM offers significant advantages in low-light environments, where visible-light SLAM often fails. As a result, research on thermal SLAM is expanding, with efforts focused on adapting traditional SLAM frameworks to process thermal data. For example, Buemi et al. [3], and Li et al. [17] have developed methods to extract usable features from thermal imagery. Additionally, thermal sensors are increasingly integrated with LiDAR, RGB cameras, and inertial sensors to improve perception and localization in complex environments. Works such as those by Chen [6] and Choi [8] combine thermal data with LiDAR, while others [12] fuse thermal imagery with RGB and inertial data. Despite these advancements, monocular thermal SLAM remains challenging due to the limited visual information and high noise levels in thermal images, and a fully effective solution has yet to be developed.\nIn recent years, significant research efforts have focused on integrating deep learning into visual SLAM. In the context of RGB images, novel view synthesis combined with self-supervised learning has been widely applied to achieve visual odometry and depth estimation, showing remarkable effectiveness. Works such as Zhou [29], Godard [10], and Zhang [27] have demonstrated the utility of self-supervised learning in RGB-based visual SLAM. By reducing reliance on manual annotations and utilizing geometric consistency constraints to learn features directly from unlabelled data, self-supervised learning not only enhances model adaptability but also improves the accuracy of visual odometry and depth estimation.\nHowever, thermal images present unique challenges in visual SLAM due to difficulties in feature extraction, high noise levels, and loss of detail, making depth estimation and loop closure detection problematic. Deep learning, with its superior feature extraction and generalization capabilities, offers a potential solution to these challenges. Although monocular thermal visual odometry has seen some progress, such as in the work of Shin et al. [22, 21], the approach primarily relies on local histogram processing of initial ther- mal images followed by self-supervised learning to estimate thermal visual odometry. While this method validates the"}, {"title": "II. RELATED WORK", "content": "feasibility of self-supervised learning in thermal imagery, its applicability is limited to indoor or small-scale scenes. The complete monocular thermal SLAM problem in outdoor, long-range thermal scenarios remains unresolved.\nTo address the challenges of large-scale, low-light envi- ronments, we propose DarkSLAM, a novel learning based monocular thermal SLAM framework. As shown in Fig. 1, our system first preprocesses raw thermal images using linear transformation and low-pass filtering. Self-supervised learning [10, 28] is then employed to generate a heat consistency loss, reducing reliance on ground truth pose data and labeled datasets. In the learning model, the intro- duced Efficient Channel Attention (ECA) [24] mechanism dynamically adjusts channel weights for better pose feature extraction, while Selective Kernel Attention (SKA) [1] en- hances multi-scale depth feature fusion. We also integrate the Dino [5] model into DepthNet to improve training convergence and depth estimation. Extensive experiments in large-scale outdoor thermal environments show that Dark- SLAM siginificantly outperforms SC-SfM-Learner [29], Shin et al. [21], and V\u00f6disch [23] in both pose prediction and depth estimation. Notably, incorporating the ECA mecha- nism reduced PoseNet's Absolute Trajectory Error (ATE) by 38.5% compared to SC-SfM-Learner. Meanwhile, the SKA mechanism not only enhances depth prediction accuracy but also effectively mitigates common issues related to depth prediction degradation.The Siamese network-based loop de- tection framework further improved loop closure success, optimizing the pose graph and delivering a robust thermal SLAM solution for precise localization and 3D mapping in challenging thermal conditions.\nIn summary, our key contributions are as follows:\n\u2022\n\u2022 We propose DarkSLAM, a novel self-supervised SLAM framework capable of learning poses, depths, and loop closures directly from monocular thermal images, that achieves large-scale thermal localization and mapping in complex lighting conditions.\n\u2022 By integrating Efficient Channel Attention and Selec- tive Kernel Attention mechanisms into pose and depth estimation, we enhance the capability of pose and depth estimation while addressing common visual degradation issues in depth prediction.\n\u2022\n\u2022 We introduce a contrastive learning-based loop closure detection module, enabling efficient loop closure and pose graph optimization in the thermal SLAM backend.\n\u2022 We developed a thermal data collection platform our- selves and conducted extensive real-world experiments, demonstrating that DarkSLAM significantly outper- forms existing solutions."}, {"title": "A. Thermal SLAM", "content": "Traditional thermal SLAM methods, which often extend classical visual SLAM algorithms, face significant limitations due to the unique properties of thermal images, such as low feature extraction precision and error accumulation that can lead to system failures. To address these challenges, researchers have proposed three main categories of solutions. The first category involves integrating inertial sensors or radar with thermal SLAM [8]. While this approach improves localization, it requires precise sensor calibration and syn- chronization, and errors can still accumulate. The second cat- egory aims to improve thermal SLAM by enhancing image processing before feature extraction[12]. For instance, Wang et al[25]. proposed novel thermal image processing and feature extraction strategies tailored to the unique thermal characteristics, achieving effective localization in dynamic environments with visual degradation. The third category combines visual and thermal sensors for SLAM [7], leverag- ing the strengths of both sensor types under varying lighting conditions. However, this approach introduces complexities such as image registration and data fusion, especially in environments with drastic lighting changes."}, {"title": "B. Deep Learning based Visual SLAM", "content": "Self-supervised learning in RGB camera-based SLAM has gained popularity for depth and motion estimation from unlabeled image sequences, eliminating the need for costly ground-truth labels. A notable example is SC-Sfm-Learner [29], which estimates depth and pose through temporal image reconstruction by warping one image to match another. Kim et al. [14] proposed using spatial RGB stereo reconstruction to train single-view depth estimation by aligning thermal with RGB images. Lu et al. [19] introduced a cross-spectral reconstruction loss for single-view depth networks. Li et al. [18] extended this framework by integrating LoopNet and pose graphs, significantly improving robustness and accuracy in RGB-based SLAM through temporal consistency and loop closure. However, adapting these methods to thermal images is challenging due to high noise, low feature precision, and spectral differences, which hinder long-range pose prediction and depth estimation in large-scale thermal environments. Thus, while RGB-based SLAM methods show promise, applying them to thermal imaging remains a complex task."}, {"title": "III. DEEP LEARNING BASED THERMAL SLAM", "content": "In this section, we propose DarkSLAM, a novel deep learning-based thermal SLAM framework for large-scale localization and mapping using only monocular thermal im- ages. The inherent challenges of thermal imaging, including feature scarcity, low contrast, and high noise, make it difficult for deep neural networks to directly extract meaningful features during training. To overcome these challenges, we first apply a transformation to raw thermal images to enhance contrast and detail while preserving temperature consistency. Next, we introduce a self-supervised learning framework to learn poses and depths from thermal images. We incor- porate an Efficient Channel Attention (ECA) module [24] into PoseNet, which improves its sensitivity to differences between input image pairs and enhances pose feature ex- traction. For DepthNet, we use Dino-ResNet50 [5] as the backbone encoder and integrate a Selective Kernel Network (SKA) module [1] in the depth decoder, mitigating depth feature degradation. Additionally, we propose a loop closure detection network based on a Siamese architecture, enabling reliable loop closure detection and pose optimization for thermal SLAM in large-scale environments."}, {"title": "A. Thermal Image Enhancement", "content": "Thermal imaging uses color coding to represent temper- ature distributions, but often suffers from low resolution, poor contrast, and lack of detail. While these character- istics can highlight temperature anomalies, they obscure scene details, making feature extraction difficult. To enhance feature extraction, raw thermal data must be processed by adjusting brightness and contrast and applying linear stretching techniques. First, the brightness range is stretched to improve texture contrast across temperature regions. A linear transformation then limits brightness within specific bounds. To further enhance image details, a Gaussian filter decomposes the image into background and detail layers. The background is smoothed to reduce noise, while the detail layer is enhanced to highlight key features. This processing improves contrast and provides more effective supervision signals for self-supervised learning, as shown in Fig. 2."}, {"title": "B. Self-Supervised Pose and Depth Learning from Thermal Images", "content": "Our self-supervised framework, as shown in Fig. 3,DarK- SLAM, enables depth and pose estimation from thermal images using novel view synthesis as the primary supervision signal, eliminating the need for ground-truth pose data. To tackle the challenges of thermal imaging, we integrate Ef- ficient Channel Attention (ECA) into PoseNet for improved pose feature extraction and use Dino as DepthNet's back- bone for faster convergence. Additionally, we incorporate a Selective Kernel Network (SKA) module to reduce depth degradation during joint training with PoseNet."}, {"title": "1) Self-supervised Learning via Thermal Images Synthe- sis:", "content": "We select a target thermal image $I_t$ and an adjacent source view $I_s$ from a nearby time frame (e.g.,t-1 or t+1). DepthNet generates a per-pixel depth map $D_t$ from $I_t$, while PoseNet estimates the relative camera pose $T_{ts}$ using both $I_t$ and $I_s$. These outputs are used to inverse warp $I_s$ to align with $I_t$. A core component of our framework is a differ- entiable depth-based image renderer, which reconstructs the target view by sampling pixels from the source view $I_s$. This relies on $D_t$ and $T_{ts}$. The pixel transformation from target to source view is given by:\n$p_s \\sim K T_{ts}D_t(p_t)K^{-1}p_t$. (1)\nTo reconstruct $\\hat{I}_s(p_t)$, we use differentiable bilinear interpo- lation. This interpolates the values from the four neighboring pixels surrounding the projected pixel $p_s$. The formula is\n$\\hat{I}_s(p_t) = I_s(p_s) = \\sum w_{ij} I_s(p) (2)$\n$i\\in{t,b},j\\in{l,r}$\nwhere $w_{ij}$ are the interpolation weights. This interpolation is differentiable, ensuring smooth gradient propagation. This method allows for precise and stable image warping and supports end-to-end optimization, relying on projective ge- ometry instead of directly learning the warping."}, {"title": "2) Training Loss and Mask Generation:", "content": "The total loss function in the DarkSLAM framework is defined as:\n$L_{total} = L_{rec} + \\lambda_{gc}L_{gc} + \\lambda_{sm}L_{sm} (3)$\nThis combines photometric consistency loss ($L_{rec}$) [26], geo- metric consistency loss ($L_{gc}$) [2], and edge-aware smoothness loss ($L_{sm}$)[10] to train depth and pose estimation networks"}, {"title": "3) ECA Guided Pose Network:", "content": "In our DarkSLAM, the PoseNet employs a ResNet-based [11] encoder to extract image features from pairs of input images. These features are then fed into the PoseNet decoder to estimate the 6- DoF (Degrees of Freedom) pose. To better aggregate features from the two images, we incorporate the ECA (Efficient Channel Attention) module into the PoseNet decoder. Unlike traditional attention mechanisms, the ECA module does not require dimensionality reduction and upscaling operations, preserving the integrity of the original channel features. This allows the model to better exploit channel dependencies and enhance feature representation."}, {"title": "4) Dino and SKA Enhanced Depth Network:", "content": "The Depth- Net of our DarkSLAM is built on a ResUnet [9] architecture. However, due to the limited availability of thermal datasets and the low contrast and high noise in thermal images, train- ing DepthNet can be challenging, often leading to suboptimal performance. To address this issue, we incorporate the Dino (self-distillation with no labels) model [5] as the encoder for DepthNet. Dino, trained on a large volume of images, has demonstrated exceptional performance across various vision tasks, including depth estimation. When used as the encoder in DepthNet, Dino effectively extracts features from thermal images, which are then utilized by the decoder for accurate depth prediction.\nAdditionally, due to the lack of texture information and low contrast in thermal images, DepthNet is prone to severe overfitting during self-supervised training. This overfitting often leads to the abandonment of depth predictions in low-texture regions, resulting in large black spots in the predicted depth maps. To mitigate this visual degradation, we introduce an SKA (Selective Kernel Attention) module [1] in the upsampling feature fusion stage of DepthNet. The SKA module enables the network to better capture multi-scale features in complex thermal image spaces, preserving the network's ability to predict depth in weakly textured regions. Additionally, it enhances the network's perception and depth prediction capabilities for distant objects in thermal images."}, {"title": "C. Thermal Loop Closure Detection", "content": "In thermal imaging, scene boundaries and features often appear blurred compared to RGB images, making traditional loop closure detection methods less effective. Hand-crafted visual features or texture-based methods struggle with the high similarity and low contrast inherent in thermal im- ages. To overcome these challenges, we propose a Siamese network-based framework for loop closure detection using thermal images."}, {"title": "1) LoopNet Architecture:", "content": "Our core network is based on ResNet18, trained using a contrastive learning approach that maximizes similarity between images of the same scene and minimizes it between different scenes. This enhances the network's ability to distinguish between similar and dissimilar scenes, even under the low contrast and noise typical of thermal images.The training framework is shown in Fig. 4.\nWe integrate this with a global loop closure detection and pose graph optimization system, combining PoseNet with our thermal loop closure detection network. PoseNet provides the relative pose information by calculating the transformation between adjacent images. During deploy- ment, we construct a pose graph, incorporating both local and global connections, visual odometry (VO) estimation, and loop closure detection. Our loop closure module, a twin- network thermal detection system, converts each input frame into a feature vector, which is then compared to previous vectors using cosine similarity:\n$s_{incos} = cos(f_{current}, f_{previous}) (8)$\nWhen the cosine similarity exceeds a predefined threshold, PoseNet estimates the transformation between the corre- sponding images, updating the pose graph to ensure global trajectory accuracy and consistency."}, {"title": "2) Training Details:", "content": "In thermal loop detection, environ- mental temperature fluctuations and dynamic objects can cause significant variations in image brightness and contrast. To improve the model's accuracy and robustness, we applied image enhancement techniques during training. Specifically, we adjusted the brightness and contrast of positive sample pairs and randomly embedded patches from negative samples into the positive pairs, simulating real-world environmental changes. This strategy enhances the model's adaptability to varying imaging conditions. We also apply data augmen- tation (Fig. 4) to improve model robustness. Given input samples $X_1$ and $X_2$, and model $G_w$, the contrastive loss is computed as:\n$E_w = ||G_w(X_1) - G_w(X_2)||$ (9)\nThe loss function is defined as:\n$L(W, (Y, X_1, X_2)^i) = (1 - Y)L_G (E_w (X_1, X_2)^2) + YL_1 (E_w (X_1, X_2)^2) (10)$\nHere, Y indicates whether $X_1$ and $X_2$ are from the same category (Y = 0) or different categories (Y = 1). P is the total number of input data points, and i is the current data point index. $L_G$ and $L_1$ are the loss functions for matching and non-matching pairs, respectively."}, {"title": "D. Pose Graph Optimization", "content": "In our DarkSLAM system, the backend optimization pro- cess begins with the initialization of a pose graph [16], where nodes represent thermal images and their corresponding global poses, and edges represent the relative poses between nodes. When a new thermal image frame arrives, PoseNet predicts the relative pose between the current and previous frames. Using the previous frame's global pose and the predicted relative pose, the global pose of the current frame is calculated. This new global pose is then added as a node in the pose graph, with the corresponding relative pose added as an edge connecting it to the previous node. When LoopNet detects a loop closure, PoseNet computes the relative poses between the current image and the images at the loop closure node. These relative poses are added as loop closure edges in the pose graph. The pose graph is then optimized through iterative refinement using the nonlinear optimization Ceres Solver, improving the accuracy of pose estimation and ensuring global trajectory consistency in complex thermal environments."}, {"title": "IV. EXPERIMENT", "content": "per second, while memory usage decreased to approximately 3,061 MB. Depth estimation required about 6,614 MB of memory while maintaining a consistent prediction speed of 17 frames per second. These results demonstrate that DarkSLAM delivers real-time pose and depth processing, ensuring efficiency in practical applications."}, {"title": "B. Large-scale Thermal Localization and Mapping", "content": "1) Pose Estimation Evaluation: We evaluated pose pre- diction on five thermal urban road sections that were ex- cluded from the training set: trajectory1 (3,491 images), trajectory2 (6,473 images), trajectory3 (2,460 images), tra- jectory4 (4,751 images), and trajectory5 (3,320 images). We evaluated the trajectory performance of Shin et al. [21], SC-Sfm-Learner [29], ORB-SLAM3[4] and our Dark- SLAM framework, both with and without loop detection and pose optimization. Shin et al.'s PoseNet and DepthNet shared a ResNet50-based encoder, while SC-Sfm-Learner's PoseNet and DepthNet used the same encoders as Dark- SLAM, ResNet18 and ResNet50, respectively. To ensure a fair comparison, all methods were trained and tested on thermally enhanced images to address challenges like high noise, low contrast, and inconsistent brightness in the original thermal data. Additionally, ORB-SLAM3 was tested using RGB images collected from the RealSense D455 camera. The trajectory generation results are shown in Fig. 6.\n2) Loop-closure Detection Performance: To evaluate the performance of our thermal loop detection module, we com- pared it with the method proposed by V\u00f6disch [23]. Loop detection accuracy is highly sensitive to the feature similarity threshold. Raising the threshold typically increases both false positives and false negatives. Striking the right balance is critical, as a higher threshold may falsely identify loops, while a lower threshold may miss true loops. To address this, we implemented a dynamic threshold adjustment strategy, gradually tuning the threshold across different scenarios until false positives were minimized, thereby identifying the optimal threshold. Using this threshold, we compared the detection success rates and false negative rates of both methods across various routes. Key frames were extracted every 15 frames, and after detecting a loop, detection was suspended for the next 150 frames. The routes (trajectories 1, 2, 3, 4, and 5) contained 2, 1, 4, 1, and 3 loops, respectively. Our method successfully detected 2, 1, 3, 1, and 3 loops, while V\u00f6disch's method detected 1, 1, 2, 0, and 2 loops. Overall, our loop detection success rate improved by 66.6% compared to V\u00f6disch's method, as shown in Fig. 7. This highlights the effectiveness of our dynamic threshold adjustment and enhanced feature extraction, resulting in more reliable loop detection in challenging thermal environments."}, {"title": "C. Ablation Study", "content": "1) Thermal Scene Reconstruction Performance: During depth estimation, DepthNet experienced significant feature degradation over time due to the high similarity of thermal image features. This degradation resulted in numerous \"black spots\" in the predicted depth maps (Fig. 8), leading to incomplete depth maps and blank areas in the final dense 3D reconstructions, ultimately affecting mapping accuracy. The introduction of the Selective Kernel Attention (SKA) mechanism [20] allowed the network to capture multi-scale spatial features more effectively, greatly reducing the feature degradation issue. To validate this improvement, we selected two degraded thermal sections for depth prediction and dense mapping comparison experiments. We compared depth maps generated by SC-Sfm-Learner [29] with those produced by DarkSLAM, analyzing their impact on thermal 3D recon- struction. The estimated depth maps from DarkSLAM were input into the InfiniTAM-V3 [13] framework to generate dense thermal point clouds. The results, shown in Fig. 8, illustrate the differences in point clouds generated by various depth predictions and demonstrate the improvements in the final 3D reconstructions.\n2) Ablation Study on DepthNet: We enhance DepthNet by integrating Dino-ResNet50 for initialization and the Selective Kernel Attention (SKA) mechanism [20] to improve depth prediction performance and prevent depth degradation. Pre- training with Dino-ResNet50 enabled our network to ex- tract more robust features from noisy, low-contrast thermal images, thereby increasing depth prediction accuracy (see Fig.9). We evaluated three DepthNet variants: the original SC-SfMLearner DepthNet, DepthNet with Dino-ResNet50 (without SKA), and DepthNet with both Dino-ResNet50 and SKA. Using LiDAR data as depth ground-truth and evaluation metrics such as Absolute Relative Error, Squared Relative Error, RMSE, and depth accuracy thresholds, the results in Table II demonstrate that our proposed depth model integrating Dino-ResNet50 and SKA achieved superior depth accuracy and robustness over other settings, especially in low-feature and distant thermal scenes. These findings con- firm the effectiveness of the enhancements of Dino and SKA in challenging environments.\n3) Ablation Study into ECA Module: We specifically eval- uated the impact of the Efficient Channel Attention (ECA) [24] on pose prediction by comparing DarkSLAM's PoseNet with and without ECA. For a broader comparison, we also included PoseNets from Shin et al. [21] and SC-Sfm-Learner [29]. This allowed us to assess the effectiveness of ECA in improving thermal pose prediction. While Shin et al. used ResNet50, SC-Sfm-Learner employed ResNet50 for Depth- Net and ResNet18 for PoseNet, and DarkSLAM utilized Dino-ResNet50 [5] for DepthNet and ResNet18 for PoseNet. We tested on trajectories 1-5 from the Largescale Thermal Dataset, comparing Absolute Trajectory Error (ATE) and Relative Pose Error (RPE). ECA significantly improved pose prediction by enhancing the model's attention to relevant features in noisy thermal images. DarkSLAM with ECA reduced ATE by 38.5% and RPE by 2% which can show in Table I, outperforming SC-Sfm-Learner in both positional and rotational accuracy."}, {"title": "V. CONCLUSIONS", "content": "In this work, we present DarkSLAM, a deep learning-base monocular thermal SLAM system designed for large-scale, complex thermal environments. Leveraging self-supervised learning, DarkSLAM provides accurate pose estimation and depth mapping without the need for ground truth data. We incorporate attention mechanisms and the Dino model to ad- dress visual degradation in thermal images, while a siamese network-based contrastive learning framework enhances loop detection, significantly boosting overall performance.Future work will focus on improving loop detection in varying ther- mal conditions (e.g., day-to-night transitions) and enhancing dynamic object detection for more precise pose prediction. However, there are several limitations. The large number of parameters in PoseNet, DepthNet, and LoopNet makes real- time deployment on resource-constrained edge devices chal- lenging. Additionally, our loop optimization currently only refines the pose graph, not the depth predictions, limiting the generation of high-precision maps for applications like au- tonomous driving. While effective in static environments, the system struggles with dynamic objects, leading to degraded map accuracy when object density is high."}]}