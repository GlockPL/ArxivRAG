{"title": "Develop AI Agents for System Engineering in Factorio", "authors": ["Neel Kant"], "abstract": "Continuing advances in frontier model research are paving the way for widespread deployment of AI agents. Meanwhile, global interest in building large, complex systems in software, manufacturing, energy and logistics has never been greater. Although AI-driven system engineering holds tremendous promise, the static benchmarks dominating agent evaluations today fail to capture the crucial skills required for implementing dynamic systems, such as managing uncertain trade-offs and ensuring proactive adaptability. This position paper advocates for training and evaluating AI agents' system engineering abilities through automation-oriented sandbox games-particularly Factorio. By directing research efforts in this direction, we can equip AI agents with the specialized reasoning and long-horizon planning necessary to design, maintain, and optimize tomorrow's most demanding engineering projects.", "sections": [{"title": "1. Introduction", "content": "Since the release of ChatGPT in November 2022, the field of generative AI has experienced an explosive surge in both attention and investment. Early successes in large language models (LLMs) have demonstrated that tuning foundation models to follow instructions and optimize for human preferences can yield AI systems capable of a wide range of tasks often approaching or matching human-level proficiency in specific domains. This has led researchers and industry experts alike to speculate that we now possess the fundamental building blocks for artificial general intelligence (AGI).\n\nA logical progression beyond chatbots and prompt-based LLMs is the development of AI agents. Unlike conventional models that simply output text in response to queries, agentic AI systems combine language comprehension with memory, tools, and other interfaces, allowing them to interact with environments in near-human ways. This paradigm shift has ignited excitement about the possibility of autonomous, always-on AI \"workers\" that can undertake many tasks currently performed by humans-ranging from data analysis to coding, from supply-chain management to design optimization.\n\nYet, for all the excitement around AI agents, today's systems often remain limited in scope and capability. Part of this is due to a lack of robustness and a need for continued integration with real-world interfaces, but it is also due to limitations of static development environments for agents. We argue that these constraints can be overcome by explicitly training and evaluating agents in system engineering tasks, where scalability, adaptability, and long-term strategic thinking become paramount. By building, optimizing, and maintaining complex, real-world systems\u2014or close simulations thereof-agents can push well beyond static benchmarks toward generalized superhuman problem-solving.\n\nThis paper makes three main points:\n\n1.  System engineering is a uniquely high-leverage capability. Societies worldwide face challenges that demand new levels of coordination and innovation in designing and managing complex infrastructures and processes.\n\n2.  Sandbox-style simulation platforms are essential for training and evaluating AI agents on their capacity to handle real-world complexities. Such platforms can capture the interplay between adaptability, automation, and other dynamic trade-offs that static benchmarks fail to represent, thereby enabling more realistic and robust testing.\n\n3.  Factorio stands out as the ideal sandbox game for this purpose as its entire nature centers on designing and automating complex systems along with key technical advantages like robust support for modifying and augmenting game mechanics.\n\nWe explore each of these points in detail in subsequent sections individually, and provide an Appendix which visually illustrates Factorio for newcomers to gain intuition about its gameplay."}, {"title": "2. The Importance of System Engineering", "content": "In this section, we examine trends in complex system development and AI agents. We deduce that these will converge and we thus firmly establish the value proposition for developing system engineering capability in AI agents."}, {"title": "2.1. The Ubiquity of Systems", "content": "A system is defined as a collection of interacting components that together serve a function or purpose. Under this broad definition, the world as we know it is held together by complex systems. Key examples include:\n\n\u2022 Transportation and Logistics. Industries such as shipping, trucking, and ridesharing; public services like trains and buses; physical infrastructure projects including roads, bridges, and tunnels.\n\n\u2022 Energy Infrastructure. Raw material acquisition and refinement; large-scale energy generation in specialized facilities; storage and distribution networks required for load balancing.\n\n\u2022 Modern Agriculture. Encompassing land management (irrigation, fertilization, pest control), crop and livestock cycles, as well as packaging and distribution systems to bring products to market.\n\n\u2022 Advanced Manufacturing. The creation of parts from raw materials; international supply chain coordination; final assembly of complex products across sectors such as computing, biotechnology, and aerospace.\n\n\u2022 Digital Ecosystems. Physical networking infrastructure; internet hosting servers; cloud computing stacks; software frameworks, libraries, and algorithms.\n\nSystem engineering refers to the design, implementation, and management of such large-scale systems that integrate hardware, software, and human processes. Our understanding of systems has evolved significantly over time. Early industrial breakthroughs (e.g., standardized components, assembly lines, electrification) introduced new layers of complexity by increasing production volumes, lowering costs, and extending distribution chains. In aerospace and defense projects, where massive interdisciplinary teams had to be coordinated, formal system engineering practices emerged. Over the years, these yielded iterative and agile methods emphasizing continuous integration and rapid feedback-trends that are now mainstream in digital ecosystems.\n\nThe demand for building and scaling complex systems shows no signs of slowing down. Across the world, large projects are planned or underway to address unprecedented challenges in the form of energy needs, aging demographics, changing climate patterns, geopolitical tensions, and more. The competitive advancement of technology itself leads to self-reinforcing demand for systems, exemplified by staggering investments into AI-related infrastructure. Budget overruns and timeline delays are all too common in implementing large projects, showing that human planning and system engineering has its limitations. It thus appears nearly certain that advanced AI will be crucial in tackling these challenges and implementing the solutions."}, {"title": "2.2. The Rise of AI Agents", "content": "Simultaneously, AI agents are gaining traction as the most promising framework for applying human-aligned generative AI models. Significant advances in multimodal input processing and reasoning through inference-time compute use have exposed the possibilities of autonomous agents using complex interfaces to accomplish tasks over longer time horizons. These opportunities are rapidly being realized through virtual agents which are increasingly using web browsers, code interpreters and other digital tools to automate workflows and offload other labor from humans. Progress in physical agents is also picking up steam, leaning on advances in both general-purpose foundation models and maturing robotics technology.\n\nThe tasks assigned to AI agents today may be composites of several smaller sub-tasks, but ultimately tend to be self-contained workflows. As AI agents become more reliable at executing these tasks, it will become more enticing to involve them in more system-level challenges. Systems-level expertise is always more scarce since it demands deep knowledge of choices for components, interconnections and associated trade-offs for costs, implementation time, complexity, scalability, etc. Training data for reasoning about systems is also commensurately scarce and so it will naturally present a challenge for improving AI agents. As AI agents proliferate, the challenges and opportunities associated with multi-agent coordination will also become more relevant and influence the efficacy of AI-enhanced systems. Hence, this trajectory of elevating AI agents to effectively work on system engineering seems central for achieving the long-term goals of developing AGI."}, {"title": "2.3. Implications of Superhuman System Engineering", "content": "AI models and agents have shown superhuman ability in various domains. Historically, this is evidenced by their mastery of classically challenging board games and more complex real-time strategy video games"}, {"title": "3. Designing Evaluations for System Engineering", "content": "We highlight core trade-offs associated with building systems, namely efficiency, scalability and adaptability. We argue that system engineering training and evaluation environments must be dynamic and open-ended to adequately assess the dynamic equilibrium of these characteristics."}, {"title": "3.1. Real-World Intuition", "content": "In the design phase of a system engineering project, the focus is on delivering a proposal that meets various requirements and user preferences for features and costs. This requires deep domain expertise since many valid proposals can exist, yet vary in terms of up-front costs, maintenance costs, implementation time, complexity, regulatory compliance, scalability, and so on. Design capability is readily tested in the software industry with system design interviews that pose questions such as \"How would you design a real-time collaborative word processing application like Google Docs?\" or, more bluntly, \u201cDesign Google Docs.", "Design Uber.\u201d, \u201cDesign Twitter.": "etc. These questions are not meant to be answered in a single pass, but rather serve as a starting point for iteratively gathering requirements and proposing increasingly detailed solutions.\n\nAfter a real system is designed, the implementation phase begins and often never truly ends. Successful systems typically continue to expand in scope because increased outputs fuel greater demand. This pattern is evident in large software services, energy networks, and public transportation systems. Even if overall scale plateaus, there is an ongoing need for repair and maintenance-particularly in physical systems but also in software, which must periodically upgrade dependencies and refactor for performance. Consequently, the longevity and effectiveness of a system fundamentally depend on its capacity to assimilate feedback and adapt to inevitable changes.\n\nFeedback collection is facilitated through automated means like logging in software or more manually such as accepting verbal customer feedback. Adapting the system with this feedback is thus core to ensuring it meets expectations through key performance indicators. Some future scenarios are more serious and difficult to fully predict. Recent examples such as the COVID-19 pandemic required large-scale adaptations not seen since World War II, and the volatility of geopolitics-as highlighted by the conflict in Ukraine-continues to demand swift adjustments in global systems. Natural disasters like hurricanes and wildfires, technological breakthroughs such as the generative AI boom, major cybersecurity incidents, and new discoveries of key commodities further underscore the need for flexible system design."}, {"title": "3.2. Supporting Theory", "content": "Fortunately, the study of systems has long acknowledged the value of adaptability, leading to foundational frameworks that inform real-world solutions. One such lineage is cybernetics , which reveals how continuous feedback loops and robust communication channels allow systems to counter external disturbances. Ashby's law of requisite variety (LRV) stresses that systems must possess enough complexity (known as variety) internally to handle the complexity of potential external disruptions . If this condition is not met, it can lead to a loss of stability of the system, meaning that it will not be able to maintain desired indicators of success. The intuition is comparable to that of machine learning theory, where out-of-distribution inputs lead to poor model performance.\n\nThe law is typically presented in the static setting, meaning it applies to the (internal) response variety ($V_R$) and environmental variety ($V_E$) at any given time. However, it can be extended to apply over time, where the configuration of a system must be able to change in order to support the particular variety of the environment over time . Building on this, Beer's viable system model (VSM) emphasizes hierarchical structures for robust systems. The modularity of hierarchy allows different levels of a system to handle only the variety of inputs which the level is responsible for . For example, the lowest level (System 1) of viable systems are the autonomous operational units which act in the world, so they individually only need to support their distinct low-level functions. In this model, it is essential for systems to have a layer which plans proactive adaptation (System 4), enabling organizations and infrastructures to pivot swiftly under changing requirements.\n\nThe law of requisite variety (LRV) and the viable system model (VSM) highlight a central tension in robust system operation: efficiency and flexibility tend to come at the cost of each other. For instance, a mechanized assembly line can mass-produce a single product more rapidly than a human worker, yet the latter may be more versatile in producing a variety of items. In software, production-level code is often streamlined through rigid abstractions, whereas one-off scripts are less optimized but highly flexible. Even in the study of LLMs, the choice between prompt-engineering large models and finetuning smaller ones reflect this same trade-off. This principle is shown graphically in where system variety $V_R$ is expensive to maintain, and ultimately should be reduced when unneeded. Likewise, illustrates that System 3 and 4 directly embody this tension and it is up to System 5 to arbitrate and maintain cohesion. Scaling up and maintaining systems thus presents a persistent challenge of preserving dynamic equilibrium, in which the benefits of automation and scale do not compromise a system's capacity to adapt.\n\nFrom a machine learning perspective, adaptability has been explored under many paradigms, including domain adaptation , meta-learning for agents , continual learning , in-context learning , and out-of-distribution generalization . Central themes across these fields involve developing robust representations, ensuring sample-efficient training, and promoting safe exploration. By weaving AI-driven automation into systems, we now have the opportunity to significantly enhance both efficiency and adaptability-two objectives that have traditionally been at odds."}, {"title": "3.3. Evaluations for AI Agents", "content": "Recent advances in Al research have fueled efforts to build virtual agents capable of increasingly complex interactions with real-world interfaces. As these cognitive capabilities continue to mature, they provide a foundation for agents to meaningfully contribute to system engineering projects. Realizing this vision, however, requires a fundamental rethinking of how we both train and evaluate virtual AI agents.\n\nEvaluation methods for LLM-derived agents naturally began with classic NLP benchmarks, such as question answering in MMLU . They have since evolved to encompass multi-turn interaction , multimodality , and external tool use \u2014capabilities expected of advanced AI agents. SWE-bench (Jimenez et al., 2024) (and its multimodal extension ) is likely the most challenging agent benchmark in use today. It requires agents to resolve issues in codebases by modifying multiple files and subsequently passing unit tests. Though it involves reasoning and multi-step planning, it remains a static evaluation that does not measure the capacity to maintain dynamic equilibrium between VSM Systems 3 and 4 and deal with the uncertainty of dynamic environment variety as per the LRV. This would hold true even for an extension of the benchmark in which agents designed a system like Google Docs and implemented it, yet never had to respond to changing requirements or circumstances.\n\nBy contrast, non-LLM-based agents have often been evaluated in dynamic environments. This is the case for agents achieving superhuman performance in competitive games such as Go and StarCraft II , where the presence of an opponent forces rapid adaptations to both the agent's own actions and those of adversaries. For a time, increasingly complex games appeared to be a promising route to building general intelligence, culminating in work on Minecraft via Voyager and MineDojo. These agents achieved goals in a dynamic, open-ended environment, with effectively unconstrained objectives demanding resource gathering, multi-step planning, and adaptability to emergent challenges."}, {"title": "3.4. The Ideal Evaluation Environment for System Engineering", "content": "Interest in dynamic, open-ended environments waned somewhat after the advent of LLM-based generalist models. However, the rapid evolution of ChatGPT and its successors-featuring multimodality, tool-use capabilities, and ample test-time compute\u2014opens new possibilities for resurrecting this research agenda in a more advanced form.\n\nWe deduce from the ar, sandbox games which support automation as a mechanic are the ideal setting for evaluating system engineering. They let researchers specify high-level objectives and observe an agent's ability to break down tasks, weigh trade-offs, and implement solutions. Over time, the researcher can change these objectives or introduce disruptions, testing the agent's capacity to maintain a healthy dynamic equilibrium as per the viable system model. Greater open-endedness is also desirable as it allows for more comprehensive testing of an agent's ability to comply with the law of requisite variety. Simulated environments additionally have the benefits of being fundamentally safer than real-world testing and can manage the trade-off between world physics complexity and scalability.\n\nDrawing on Minecraft as inspiration, one can envision an \"ideal\" environment that focuses on abstractions relevant to system engineering while omitting excessively detailed physics. Full 3D simulations can be computationally expensive and often distract from the higher-level reasoning crucial for scaling and process orchestration. Accordingly, a game environment centered on resource flows, balancing trade-offs, and long-horizon planning is preferable. Core properties of such an environment include:\n\n\u2022 Automation. The agent's action space should permit automating processes and managing the associated trade-offs between efficiency and adaptability. This is key for testing System 3 and 4 capability as per the VSM.\n\n\u2022 Complex Evaluation Metrics. Long-horizon performance, resource usage, and resilience under partial failures become measurable, enabling richer assessments than single-turn tests. This is part of high environment variety in the LRV.\n\n\u2022 Multi-Agent Support. Collaboration with peers, hierarchical coordination, and competition with adversaries significantly increase complexity, further testing an agent's capacity to adapt. This is also key for testing System 3 and 4 capability in the VSM.\n\n\u2022 Modding Support. Allowing users and artificial agents to create modifications or extensions fosters adaptation to out-of-distribution scenarios. This an-other way to have high environment variety in the LRV.\n\n\u2022 Scalability. The environment mechanics should be at the right level of abstraction to facilitate systems reasoning, planning, and implementation without requiring excessive computational resources.\n\nThere are many candidate sandbox games-Cities: Skylines, The Sims, Stardew Valley, Kerbal Space Program, No Man's Sky, Satisfactory, among others\u2014that support a form of system engineering. Yet they each have limitations with respect"}, {"title": "4. Factorio as a System Engineering Testbed", "content": "We now argue that Factorio is an ideal environment to develop system engineering capability in AI agents. We describe the mechanics, features and extensible scope of the game and put forth a call for using Factorio as a platform for public research. Interested readers can find a more detailed walkthrough of the game in Appendix A"}, {"title": "4.1. Overview", "content": "Factorio is a 2D, top-down factory-building game that centers on automation, rendering it a uniquely rich environment for developing and evaluating AI agents with strong system engineering capabilities. Although it shares the open-sandbox approach of titles like Minecraft, Factorio is far better suited for this purpose as it emphasizes building systems with high throughput, efficiency, and resilience. Automating the production of goods from early hand-assembled items to complex industrial chains\u2014is not merely a side option but rather the heart of the gameplay. This emphasis on scaling and optimizing factories pushes agents to navigate challenges that mirror real-world engineering dilemmas: resource constraints, energy usage, logistical complexity, and even defensive measures against hostile forces.\n\nA key metric of success is science per minute (SPM), a community-standard indicator of a factory's overall efficiency in generating the science packs needed for technological progress. Because each successive tier of research unlocks new possibilities (e.g., improved assemblers, trains, robots) but also imposes heavier resource and energy demands, any small inefficiency can ripple into crippling bottlenecks. Consequently, an effective agent must maintain the appropriate degree of variety in its approach at all times, ensuring that its decision-making processes can handle the game's growing complexity and unexpected fluctuations. SPM makes for a great summary benchmark metric, with human novice bases at ~0-30 SPM, intermediate at ~30-200 SPM and advanced bases at ~200-1000+ SPM.\n\nFrom a VSM perspective, Factorio initially starts players at purely System 1 activities like manually extracting coal and iron to be placed in a hand-crafted furnace. The use of automated conveyer belts with splitting and load-balancing mechanisms combined with automated inserter arms elevates design to a System 2 level. A key gameplay entity is the assembler which can be programmed with a recipe to convert inputs to finished outputs using materials, power and space for operation. Scaling the automated production of intermediate goods setting up train cargo networks and selecting technology tree paths are all System 3, 4 and 5 functions. A pivotal late game technology is the use of automated construction robots which can be used to rapidly bring and place materials in accordance with large, complex player-made blueprints. This capability hence focuses gameplay purely on systems-level control problems, choosing the right smelting column, railway depot, solar array configuration, etc. to evolve the base as needed.\n\nThis versatility is further magnified by Factorio's robust modding support, which allows researchers and the broader community to introduce new mechanics, custom APIs, or entire rebalanced rule sets. In other words, the sandbox"}, {"title": "4.2. Challenges for Current AI Agents", "content": "While AI agents have made remarkable progress in reasoning and multimodal interaction, there remains a sizable gap between the capabilities of frontier agents and the level of sophistication needed to thrive in Factorio\u2014and, by extension, in complex real-world systems. For example, Factorio uses traditional a keyboard-and-mouse interface with numerous GUI windows and features detailed real-time visualization-where every item, belt, or robot is tracked on screen from a 2D view. This is coupled with the ability to view monitoring for practically all processes, placing it at the cutting edge of current AI capabilities for handling multimodal data bandwidth and human interface use.\n\nBases are commonly developed over several dozens if not hundreds of hours. There is a tremendous amount of temporal information involved in optimizing a base which would certainly test the long-context nature of frontier agents. Sophisticated memory and recall systems would undoubtedly be necessary for an LLM-based agent to succeed in an extended episode playing Factorio. Separately, planning for the future would certainly benefit from time spent reasoning, but this comes at a cost when acting in a real-time environment, hence aligning interplay of System 3 and 4 with a key compute usage trade-off.\n\nAddressing these technical barriers also highlights the importance of multi-agent collaboration: large-scale systems often require multiple agents or human-agent teams working in sync. This necessitates coordination frameworks that facilitate shared state and efficient task delegation. Moreover, real-world complexities like supply-chain delays or hardware breakdowns call for robust decision-making under uncertainty-agents must act swiftly and safely, even with incomplete information. Nevertheless, scaling compute FLOPs and refining AI architectures are likely to improve input-output flow management to the point where agents can handle advanced simulations like Factorio in real time (realistically the game only needs to be played at around 5 FPS), without relying on domain-specific observation and action spaces, as was common in earlier superhuman-agent research such as AlphaStar."}, {"title": "4.3. Modding, Market Interactions, and the Agent-Evaluator Framework", "content": "Factorio's modding ecosystem is unusually flexible, allowing Lua scripts to fundamentally alter or extend nearly every facet of the simulation. At one end, small \u201cQuality-of-Life\" mods streamline actions like inventory management or blueprint deployment an approach often mirrored in real-world industrial systems where specialized scripts automate repetitive tasks. At the other end, total conversion mods, such as Space Exploration or Industrial Revolution 3 introduce entirely new resources, tech trees, and production pipelines. This capacity for extensive re-parameterization means researchers can craft tailored scenarios focusing on, for example, large-scale chemical manufacturing or advanced energy grids. By doing so, Factorio can serve as a robust platform for evaluating AI agents under conditions that closely resemble real-world system engineering challenges.\n\nAn especially promising application of this modding framework involves designing market pricing and multi-agent interactions. Factorio already supports multiplayer, and community-created mods showcase how resource trading, diplomatic pacts and emergent economies can drive the game's complexity. In a research context, introducing dynamic markets would allow agents to buy and sell resources, negotiate prices, and even form alliances or contracts-key elements of real-world logistics and supply chains. Observing how AI agents adapt to fluctuating market forces and coordinate with others could yield insights into cooperative and competitive strategies, as well as negotiation tactics and resilient system designs.\n\nBeyond market dynamics, Factorio's modding API also lends itself to the concept of a Agent-Evaluator Framework. In this paradigm, a \u201cevaluator\" agent (human or AI) orchestrates scenario constraints, random events, or objectives while the \"agent\" attempts to build and maintain a functional factory. This setup is well-suited to self play-like reinforcement learning algorithms, where the evaluator can inject perturbations-ranging from supply shortages to power-grid failures-testing the agent's capacity for adaptive, long-horizon decision-making. The evaluator could also coordinate multiple agents with distinct roles or goals, enabling both collaboration and competition. Such arrangements bring Factorio closer to real-world engineering environments, where teams of engineers and managers must not only design but also continually refactor systems in response to shifting requirements and unforeseen disruptions.\n\nBy blending flexible modding, multi-agent mechanics, and the Agent-Evaluator approach, Factorio becomes more than just a factory-building game. It becomes a powerful sandbox for studying how AI agents might operate in large-"}, {"title": "4.4. Technical Advantages", "content": "Beyond the near-limitless opportunities provided by mods, Factorio offers a few key advantages that are worth highlighting. First, as a 2D game, it is far more resource efficient for the complexity of systems that can be built in it as it does not involve costly 3D graphics rendering as would be the case in other titles such as Satisfactory. Even despite this major difference, Factorio is well-known to be a very well-optimized game in terms of memory usage, as it has been continually refined by its dedicated team since its first public release in 2012. Furthermore, the game is platform-agnostic, running natively on Windows, Mac OS X and Linux, which is rare. It offers a free headless Linux server for supporting well-optimized multiplayer gameplay which would be crucial for human-AI and multi-AI agent experimentation. And as mentioned before, the game has exceptional support for modding, showcased by community mods which completely overhaul the tech tree, environmental mechanics and GUI systems. We believe it is quite feasible to build an API layer for control as an intermediate solution for AI usage similar to Mineflayer (PrismarineJS used in the Voyager project . In fact, that could even be a task for an AI agent to perform as part of its introduction to the game."}, {"title": "5. Alternative Views", "content": "Some critics argue that advancing AI system engineering is premature, given that core capabilities-like consistent reasoning, robust multimodality, and factual grounding-remain underdeveloped. They believe AI should first address these foundational weaknesses before tackling higher-level tasks. Yet proactive, orthogonal research can reveal new performance bottlenecks and drive innovation across modalities. Much as multimodality has progressed alongside unresolved text-based issues, tackling system engineering now can highlight what crucial gaps persist, helping to shape more integrated AI architectures.\n\nAnother concern is the risk of entrusting critical infrastructures to automated agents. Misaligned objectives or flawed reasoning could theoretically sabotage energy grids, supply chains, or other vital systems. While these dangers merit attention, the potential benefits-greater efficiency, cost savings, and creative solutions\u2014are substantial. Alignment sits at the core of system engineering, which is rooted in clear requirements, continuous feedback loops, and stakeholder validation. By maintaining transparency and accountability, AI-driven engineering can strike a balance between prudence and progress.\n\nSkeptics may also doubt whether games like Factorio adequately reflect real-world complexities, noting they often omit granular physical laws or regulatory constraints. Yet such \"unrealistic\" environments highlight the essence of system engineering-resource management, strategic planning, and iterative trade-offs in efficiency, adaptability, and cost-far better than static benchmarks and without the noise associated with realistic physics simulations. Skills developed in orchestrating large-scale virtual factories can be paired with domain-specific testing to produce a fuller assessment of AI's strengths. This integrated approach shows where AI excels (e.g., in macro-level design) and where further refinement is needed before applying these insights to physical-world applications."}, {"title": "6. Conclusion", "content": "AI agents stand on the verge of a new era where they can systematically design, optimize, and maintain complex systems in ways that rival or surpass human expertise. While LLMs have already showcased impressive capabilities for text generation, the true promise lies in the agentic paradigm-with integrated multimodal interfaces, memory, autonomy, and adaptive planning.\n\nWe have argued that system engineering represents a high-leverage domain for such agentic AI. Whether the task is orchestrating large-scale software infrastructures or managing logistical networks, adaptability and continuous learning map naturally onto the strengths of a well-trained AI agent. Yet, to properly develop and evaluate these systems, we must look beyond static benchmarks toward open-ended simulations that reflect real-time constraints, multi-agent collaboration, and shifting objectives.\n\nIn this regard, Factorio emerges as a compelling platform, providing a safe yet rich environment for refining agentic capabilities. Its emphasis on real-time resource management, multi-objective optimization, and large-scale factory layouts makes it a microcosm of industrial-scale challenge. Success in Factorio would signal that agents can handle real complexity, track multiple objectives, and adapt in realistic ways.\n\nIn conclusion, the evolution from LLM-based chatbots to versatile AI agent that can tackle system engineering marks a logical next step if we hope to solve the grand challenges of our era. By leveraging automation-oriented sandbox simulations like Factorio, we can accelerate progress toward AI systems that orchestrate research, design, and operations at scale-fundamentally reshaping how societies function and flourish in the coming decades."}]}