{"title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network", "authors": ["Jia-Hau Bai", "Chi-Ting Liu", "Yu Wang", "Fu-Chieh Chang", "Pei-Yuan Wu"], "abstract": "This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. (cf. Fig. 3 and Fig. 4). Furthermore, we additionally present the time complexity of our algorithm as O(W2NK), where W is the maximum width of the neural network, N is the number of neurons, and K is the size of the maxpool layer's kernel.", "sections": [{"title": "1 Introduction", "content": "In the past few years, convolution neural networks have reached unprecedented performance in various tasks such as face recognition (Hu et al., 2015; Mehdipour Ghazi & Kemal Ekenel, 2016) and self-driving cars (Rao & Frtunikj, 2018; Maqueda et al., 2018), to name a few. However, these networks are vulnerable to malicious modification of the pixels in input images, known as adversarial examples, such as FGSM (Goodfellow et al., 2015), PGD (Madry et al., 2018), One Pixel Attack (Su et al., 2019), Deepfool (Moosavi-Dezfooli et al., 2016), EAD (Chen et al., 2018), GAP (Poursaeed et al., 2018), MaF(Chaturvedi & Garain, 2020) and many others (Wong et al., 2019).\nIn view of the threat posed by adversarial examples, how to protect neural networks from being tricked by adversarial examples has become an emerging research topic. Previous studies of defense against adversarial examples are categorized as Removal of adversarial perturbation (Akhtar et al., 2018; Xie et al., 2019; Jia et al., 2019; Samangouei et al., 2018) and Adversarial training (Shafahi et al., 2019; Han et al., 2020; Tramer et al., 2020). Both defense mechanisms may protect the network from certain adversarial examples but there is only empirical evidence that they do so. The robustness of the network is not guaranteed. It is impossible to train or evaluate all possible adversarial examples so these methods are vulnerable to other adversarial examples that are not in the data sets that are used.\nThe need for guaranteed robustness assessments has led to the development of verification mechanisms for a neural network. These verify specific properties pertaining to neural networks, such as robustness against norm-bounded perturbation (Dvijotham et al., 2018; Singh et al., 2018), robustness against adversarial frequency or severity (Katz et al., 2017) and robustness against rotations (Singh et al., 2019a).\nDuring the early development of neural network verification, satisfiability modulo theories (SMT) solver (Katz et al., 2017) and semidefinite programming (SDP) methods (Raghunathan et al., 2018) were used. A SMT solver yields tight verification bounds but is not scalable to contemporary networks with sophisticated architecture. The SDP method requires less time but is limited to linear architectures. Recent studies have developed verification tools for more realistic scenarios, such as a fully connected neural network (FCNN) with an activation function and a convolution neural network (CNN). As indicated by Salman et al. (2020), the main methods for neural network verification can be categorized as either primal view or dual view.\nThe primal view method involves Abstract interpretation and Interval bound propagation. There are classic frameworks for abstract interpretation (e.g., AI2 (Gehr et al., 2018), DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a)). As a step further, RefineZono (Singh et al., 2019b) and RefinePoly (Singh et al., 2019b) use mixed integer linear programming (MILP) to improve the verification bounds for DeepZ and DeepPoly, respectively. However, the computation time that is required for verification is significantly increased. Another bounding technique for the primal view method is interval bound propagation, which uses interval arithmetic to obtain the bound for each individual neuron in each layer. Representative works include IBP (Gowal et al., 2018) and CROWN-IBP (Zhang et al., 2019). Dual-view methods (Wong & Kolter, 2018; Dvijotham et al., 2018; Wong et al., 2018; Bunel et al., 2020; Xu et al., 2020; Wang et al., 2021) formulate the verification problem as an optimization problem, so according to Lagrangian duality (Boyd et al., 2004), each dual feasible solution yields a lower bound to the primal problem and verification bounds are derived by solving the dual problem. Moreover, noteworthy among these methods is the state-of-the-art approach \u03b1,\u03b2-CROWN (Wang et al., 2021), which is grounded in the LiRPA framework (Xu et al., 2020)."}, {"title": "1.1 Verification of a CNN with maxpooling", "content": "The maxpool function is an integral part in most real-world neural network architectures, especially CNNs (e.g., LeNet (LeCun et al., 1998), AlexNet (Krizhevsky et al., 2012) and VGG (Simonyan & Zisserman, 2015)), which are widely used for image classification. However, past works have the following shortage in the verification of networks involving maxpool functions:\nNot applicable: IBP (Gowal et al., 2018) and others (Wong & Kolter, 2018; Wong et al., 2018) (Bunel et al., 2020; De Palma et al., 2021) verify a CNN but there is no theory to verify maxpool-based networks. Gowal et al. (2018) analyzed several monotonic activation functions (e.g., ReLU, tanh, sigmoid) in IBP but they did not consider non-monotonic functions (e.g., maxpool). Wong & Kolter (2018) discussed the verification of a ReLU-based FCNN and a later study (Wong et al., 2018) uses this for the verification of residual networks. However, besides referring to the work of Dvijotham et al. (2018), the study by Wong et al. (2018) does not address much about handling maxpool functions. Bunel et al. (2020); De Palma et al. (2021) analyzed networks with nonlinear activation functions, such as ReLU and sigmoid, but there is no analysis of the maxpool function.\nHas theory but lack of implementation evidence: These studies analyze the maxpool function but experiments only verifiy ReLU-based CNNs. Examples include AI2 (Gehr et al., 2018), DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a), RefineZono (Singh et al., 2019b), RefinePoly (Singh et al., 2019b) and LiRPA (Xu et al., 2020). Dvijotham et al. (2018) analyzed a large variety of activation functions, such as ReLU, tanh, sigmoid and maxpool, but they only demonstrated the experiment result on a small network consisting of one linear layer, followed by sigmoid and tanh. CROWN-IBP (Zhang et al., 2019) used the verification method of IBP (Gowal et al., 2018) and analyzed non-monotonic functions, including maxpool, but experiments only verify results for ReLU-based CNNs. In spite of providing functions corresponding to maxpool, LIRPA is currently unable to function properly on maxpool-based CNNs. The definitions of DenseNet and ResNeXt used in their experiments can be found in their GitHub repository, and it's noteworthy that these definitions do not include a maxpool layer.\nImprecise: These studies give an imprecise verification bound for maxpool-based CNN. DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a), and PRIMA (M\u00fcller et al., 2022) implement the verification of maxpool-based CNN but experimental results are nevertheless lacking. For comparison purposes, we implement these methods on 6 maxpool-based CNN benchmarks modified from (Mirman et al., 2018) (cf. Supplementary Material A.4). Our experiment indicates that DeepZ, DeepPoly, and PRIMA are imprecise in our benchmarks. For a norm-bounded perturbation \u2208 = 0.0024, the verified robustness for a convSmall CIFAR10 structure decreases to 1%, 25%, and 26%, respectively (cf. Fig. 3). Due to the implementation of the BaB (branch and bound) algorithm in \u03b1,\u03b2-CROWN (Wang et al., 2021) on maxpool-based CNNs, it results in excessive GPU memory requirements (more than 13GB) or prolonged execution times (more than 5 minutes per example). Consequently, we consider examples that trigger the BaB algorithm as not verified.\nComputational costly: These studies involve a significant computational cost to verify each input image in the maxpool-based CNN benchmarks (cf. Sec. 3.1). Our experiment shows that for \u2208 = 0.0006 on convBig CIFAR10 (cf. Fig. 4), PRIMA (M\u00fcller et al., 2022) requires 6.5 days and DeepPoly (Singh et al., 2019a) requires 3 days to verify 100 images. (See Sec. 3.1 for hardware spec)"}, {"title": "2 Method", "content": "This section illustrates the verification of a CNN classifier under the l\u221e norm-bounded perturbations. Sec. 2.1 defines the verification problem and Sec. 2.2 gives an overview of CAPM. More details for solving the verification problem for a maxpool-based CNN are in Supplementary Material A.1 and Supplementary Material A.2.\nSupplementary Material A.1 specifies the CNN architecture for this study; Supplementary Material A.2 describes the formulation of the the verification problem in terms of Lagranian dual problems, and simplifies the dual constraints to the form of a leaky ReLU dual network."}, {"title": "2.1 Definition of the verification problem", "content": "This study evaluates the robustness of a CNN to arbitrary adversarial examples within a bounded norm budget, to see whether or not the prediction result of the CNN will change under such adversarial perturbations. The verification problem is reformulated through convex relaxation as a convex optimization problem and the duality theorem states that any dual feasible solution can serve as a lower bound for the original verification problem.\nA neural network f consisting of k convolution layers with ReLU activation and maxpool functions, followed by flattening and t fully connected layers with ReLU activation is shown in Fig 1. If a clean image x is added with perturbation A, to which this study impose a l\u221e-norm constraint ||A||\u221e\u2264 \u03f5, the perturbed input z1 resides in an input adversarial polytope that is described as:\n\n\nz1 \u2264 x + \u03f5 and z1 \u2265 x - \u03f5.\n\n\n(1)\nThe perturbed input z\u2081 is taken as the input of the network f. Though at first glimpse the input adversarial polytope (cf. equation 1) is a hyper-cube which is convex, and that the ReLU function is itself a convex function, the intermediate adversarial polytope after passing the input adversarial polytope through the convolution and ReLU activation is in general not a convex set, as the set {(\u03be, ReLU(\u03be)) : \u03be\u2208R} is not a convex subset of R2. The verification problem deviates from a convex optimization framework due to"}, {"title": "2.2 CAPM overview", "content": "This section describes a toy example to illustrate the use of CAPM to solve the optimization problem in equation 2 using a Maxpool-based network. The dual problem is formulated using Lagrangian relaxation (Boyd et al., 2004) and convex relaxation (Wong & Kolter, 2018), so any dual feasible solution corresponds to a lower bound to the original problem in equation 2. Convex relaxation loosens the verification bound but Wong & Kolter (2018) showed that this lower bound can be calculated using a backpropagation-like dynamic programming process in a so called dual network. As the determination of upper and lower bounds for preceding layers constitutes a sub-problem within the dual network framework for subsequent layers, employing a dynamic programming algorithm becomes a viable approach to address this verification problem. This study extends the method of Wong & Kolter (2018) to a maxpool-based CNN and demonstrates that maxpool-based CNNs can also be verified efficiently and precisely using a dual network."}, {"title": "2.2.1 Toy example", "content": "CAPM verifies the robustness of a simple maxpool-based network under the l\u221e norm constraint in equation 1. The verification problem for this toy example is formulated as an optimization problem in equation 3. If the lower bound of equation 3 is positive for all possible target classes, then this network is not misled by any input perturbation, l\u221e-norm that is less than \u03f5. If not, then this network may not be safe for this input perturbation.\n\n\n\nmin y (ey - eytarg) Tz3 = dTy3\n\nz3\ns.t. z1 \u2264 x + \u03f5\nz1 \u2265 x-\u03f5\nz2 = W1z1 + b1\n\n\n\n\n\nz = max(z2, 0)\n\nR\nz2 \n\n\nmax(22,0) = max(22,0,22,1,22,2,22,3)\n\nz3 = W2z2 + b2\n\n\n(3)\nIn equation 3, the perturbed input z\u2081 is the input to a simple maxpool-based network. The feature map z2 is obtained by inputting z\u2081 into the linear operation in the fully-connected layer. ReLU and maxpool"}, {"title": "2.2.2 Determining the upper-lower bound", "content": "The node-wise upper-lower bounds are required for the convex relaxation of ReLU functions. To determine the upper-lower bounds, namely l2,j \u2264 z2,j \u2264 \u016b2,j, for the input nodes of the ReLU function, a verification problem is formulated that corresponds to the network up to the linear layer before the first ReLU. The node-wise bounds for z2,j are determined by evaluating the resulting (smaller) dual network with one-hot input vector ej (instead of d) (Wong & Kolter, 2018). In terms of the element-wise lower and upper bounds, namely l2,j \u2264 z2,j \u2264 \u016b2,j, that pertain to the maxpool functions, each maxpool function is decomposed into multiple ReLU activations (cf. equation 4). Thus computing these bounds layer-by-layer as in (Wong & Kolter, 2018) would be very costly. The values for l2,j and \u016b2,j can be calculated more efficiently as follows: For (cf. equation 5a)\n\n\nz2,j = yj - z2\n\nR2,j\n\n\n\n\nR\n\n\n\nR\n\n\n\n\nif the element-wise lower and upper bounds for z2,j and \u017e, namely\n\n\nl2,j \u2264 y \u2264 \u016b2,j and l \u2264 z \u2264 \u016b2,\n\nR\n\nR\n\n\nR\n\n\nthen are derived as\n\n\n\n\nthe element-wise lower and upper bounds and \u016b2,j for  are derived as\n\n\n\nlM = uR M and uM = uR-1.\n\nl2,j - u2 z\n\nR\nThe elementwise bounds lMj' and unj' on the pre-maxpool activations can be computed in a way similar to\nhow the elementwise bounds for pre-ReLU activations are computed in (Wong & Kolter, 2018). To compute\nlMj+1 and uMj+1, recall that\n\n\n\nM\nzR+1 = maxzj : j' \u2208 [0, j]} ."}, {"title": "3 Experiment", "content": "This section determines the verified robustness and the average verification time for CAPM, DeepZ, DeepPoly, PRIMA (M\u00fcller et al., 2022) and \u03b1,\u03b2-CROWN for a l\u221e norm-bounded perturbation of various budgets and for various attack schemes, such as FGSM and PGD. Sec. 3.1 details the experimental network architecture and the input dataset. Sec. 3.2 compares the results for this study with those of previous studies (DeepZ, DeepPoly, PRIMA and \u03b1,\u03b2-CROWN) in terms of the verified robustness and the average verification time, and Supplementary Material A.5 illustrates how we reproduced the state-of-the-art methods so that we can have a fair comparison with them. Experiments in Supplementary Materials A.3.2 also demonstrate that the neural network verification problem cannot be simply evaluated using a Monte-Carlo simulation. All experiments were conducted on a 2.6 GHz 14 core Intel(R) Xeon(R) CPU E5-2690 v4 with a 512 GB main memory."}, {"title": "3.1 Experiment setting", "content": "Robustness is calculated against adversarial examples on several networks that are trained using different methods:\nDataset: Models are trained using the MNIST and CIFAR10 datasets. Images are normalized using the default setting for DeepPoly (Singh et al., 2019a). For MNIST, the mean and standard deviation is 0.5 and 0.5, respectively. For CIFAR 10, the mean and standard deviation of the RGB channels is (0.485, 0.456, 0.406) and (0.229, 0.224, 0.225), respectively.\nArchitecture of neural networks: There are no empirical verificaion results on maxpool-based CNNs so maxpool layers are added to the common benchmark networks, convSmall, convMed and convBig in (Mirman et al., 2018). The parameter for striding and padding is adjusted to achieve a similar number of parameters to previous studies. Information about these 6 networks is shown in Table 1. The detail structures are shown in Supplementary Material A.4. Moreover, although the authors of \u03b1,\u03b2-CROWN didn't conduct experiments in maxpool-based CNNs before and they did make some additional assumptions on their maxpool layers, we would like to compare with them in maxpool-based CNNs. Hence, we also create the network benchmark convs, convm and conv for their settings.\nTraining methods: We compared the verification results of CNNs trained either normally (without adversarial training) or with adversarial examples such as Fast-Adversarial (Wong et al., 2020) and PGD (Madry et al., 2018).\nPerformance metrics: The performance of neural network verification is often evaluated through the following metrics (Singh et al., 2019a):\nVerified robustness: This is expressed as the number of images verified to be resilient to adversary example attack, divided by the total number of accurate images. This ratio represents the analysis precision of a verifier when a neural network is applied to a test image dataset that is subject to attack by an adversarial example.\nAverage verified time: This is the total time that is required by the verification algorithm to verify images, divided by the total number of images."}, {"title": "3.1.2 Robustness evaluation", "content": "For each test dataset, the settings for DeepPoly (Singh et al., 2019a) are used and the top 100 clean images are used as the evaluation test dataset. Adversarial examples are generated by adding to clean images with l\u221e norm-bounded perturbation for various budgets \u03f5 and various attack schemes, such as FGSM and PGD. The generated adversarial examples are then applied to the neural network to compare the accuracy of lower bounds that are evaluated using various verification methods. A better verification method must give a tighter (higher) accuracy for the lower bound and never exceeds that of existing attack schemes. The implementation details for DeepPoly, PRIMA and \u03b1,\u03b2-CROWN are described as follows:\n\u2022 DeepZono and DeepPoly: We follow the implementation as suggested by the default command in their GitHub (Eth-Sri).\n\u2022 PRIMA: We use exactly the same configuration mentioned in (M\u00fcller et al., 2022) for convSmall and convBig. Since PRIMA didn't report any results on convMed, and that convMed has the same number of layers as convSmall, we use the same configuration that PRIMA applied to convSmall on convMed as well.\n\u2022 \u03b1,\u03b2-CROWN: We used the default parameters and set the parameter conv mode to matrix in order to enable the operation of the BaB algorithm. The examples that would trigger the BaB algorithm were considered not verified. This adjustment was made because the implementation of the BaB algorithm on maxpool-based CNNs results in excessive GPU memory requirements (more than 13GB) and extended execution times (more than 5 minutes per example)."}, {"title": "3.2 Experimental results", "content": "The results for CAPM are compared with those of previous studies (DeepZ, DeepPoly, PRIMA) in terms of the verified robustness and average runtime metrics for various adversary budgets \u03f5 for six different networks, as shown in Fig. 3 and Fig. 4. The classification accuracy for a real-world PGD attack is also determined. A verification method must demonstrate verified robustness that is no greater than the accuracy of real-world attack schemes. Fig. 3 and Fig. 4 illustrate that CAPM achieves better verification robustness than all other schemes for all combination of the CIFAR10 dataset and has a much lower computational cost. The computational cost of CAPM is independent of \u03f5, because a different adversary budget corresponds to the same dual network architecture so computational costs are similar. However, the verification time that is required by PRIMA increases as \u03f5 increases, possibly because as \u03f5 increases, the intermediate adversarial polytope becomes more complicated and must be described by a more complex MILP optimization problem. This demonstrates the promising potential of CAPM towards verification of large scale CNNs and colour images. Due to the excessive GPU memory requirements of \u03b1,\u03b2-CROWN, we did not include \u03b1,\u03b2-CROWN in this set of experiments."}, {"title": "4 Conclusion", "content": "This study extends Wong & Kolter (2018)'s work to general purpose CNNs with maxpool, padding, and striding operations. The key idea for handing the maxpool function is to decompose it into multiple ReLU functions, while special care is taken to speed-up the computation of element-wise bounds required for the convex relaxation of intermediate ReLUs in maxpool layer. General purpose CNNs are expressed using a dual network, which allows efficient computation of verified bounds for CNNs.\nThe experimental results show that CAPM outperforms previous methods (DeepZ, DeepPoly, and PRIMA) in terms of verified robustness and computational cost for most adversary budget settings, and especially for large-scale CNNs for color images. For an adversary budget \u2208 = 0.0024, the verified robustness for DeepZ, DeepPoly and PRIMA for convSmall CIFAR10 decreases by to 1%, 25%, and 26%, respectively, but CAPM has a verified robustness of 87.5%; For an adversary budget \u2208 = 0.0006 for convBig CIFAR10, CAPM is 40-times and 20-times faster than PRIMA and DeepPoly, respectively, and gives a significantly higher verified robustness (see Fig. 3 and Fig. 4).\nThe proposed method gives comparable or better verification with significantly less runtime cost. Unlike many verification methods, for which runtime increases with the adversary budget \u03f5, CAPM has a constant runtime, regardless of the adversary budget, so it can be used for larger-scale CNNs which are usually computationally prohibitive for other verification methods. The proposed verification method is suited for use with large scale CNNs, which are an important element of machine learning services.\nThis study does provide a more precise and efficient verification for maxpool-based CNNs but the verified network is limited to a specific architecture that is defined in Supplementary Material A.1.1. Future study will involve the design of a verification framework that is applicable to neural networks with a more flexible architecture.\nAdditionally, the method of simplifying certain layers into multiple ReLU layers may likely be limited to maxpool layers only. Therefore, our preliminary future direction will focus on achieving greater flexibility in maxpool-based CNNs. Subsequently, we will continue exploring more flexible neural network architectures, such as residual connections."}, {"title": "A Appendix", "content": "As mentioned in section 2.1, the network f in consideration is a maxpool-based CNN, which consists of k convolution layers with ReLU activation and maxpool functions, followed by flattening and t fully connected layers with ReLU activation. In this manuscript we separate layers 1 - 1 and I with the linear operations. That is, the first layer simply contains a convolution operation; and from layer 2 to k \u2212 1, there are ReLU, maxpool, and convolution operations in order; while the k-th layer contains ReLU, maxpool, flatten, and linear (fully connected) operations. After the flatten operation is the fully-connected part of the network. Denote T = k+ t as the total number of layers in f, then within layers k+1 to T there are ReLU and linear (fully connected) operations in order, while the last layer is a pure output layer containing no operations. In the following derivation, we consider CNN with k\u2265 2 and t > 1. The explicit notations pertaining to all intermediate results during the calculation of f are specified in Sec. A.1.1 and Table 4."}, {"title": "A.1.1 Notation and data flow", "content": "We use the tuple (l, c, m, n) to indicate the pixel located at the m-th row and n-th column in the c-th channel of the corresponding l-th layer feature map. For instance, such a pixel in the feature map zi is indicated as zl,c,m,n.\nTo consider padding which is a common practice in convolutions, we extend the pixel region of the feature map zi, which is the input to the convolution operation, to S\u2081 = SINUSUDUSER as indicated in Table 5 and Fig. 6. Here SIN represents the index region of the feature map zi without padding, while SUD represents the padded index region located at the upper/down-sides of the feature map zi, and SLR represents the padded index region located at the left/right-sides of the feature map zi."}, {"title": "\u2022 Convolution kernel hi,c", "content": "As illustrated in Fig. 7, we use hi,e to represent the c-th convolution kernel in the 1-th layer, where l\u2208 [1, k \u2212 1] and c\u2208 [0,C1+1 \u2013 1]. In addition, each kernel contains ci channels with both height and width kiu, namely the index region of hi,c is [0, c\u0131 \u2013 1] \u00d7 [0, \u03ba\u03b5\u03c5 \u2212 1] \u00d7 [0, kv \u2212 1]. Here we use hi,c(\u00ea, m, n) to refer to the kernel value at the \u00ea-th channel, m-th row and n-th column, and define hi,c(\u00ea, m, n) = 0 for each index (\u00ea, m, n) that is out of the range [0, ci - 1] \u00d7 [0, kv \u2013 1] \u00d7 [0, kv \u2013 1]."}, {"title": "Flat kernel W", "content": "The flat kernel unfolds the feature map zk to the vector \u017ee in the flattening layer, namely\n\n\n\n\nzk,a = \u2211(Wc,m,n)azk,c,m,n, a \u2208 [0, ak \u2212 1],\n\n\n\n\n(c,m,n)\u2208SIN\nwhere (Wc,m,n)a = 1{a = CkNkNk + mNk + n} for (c, m, n) \u2208 SIN, and that ak= CkNkNk.\nBefore introducing the details of the math operations processing through network f, we first illustrate how to decompose the maxpool: Instead of considering the whole group of candidates as the input of maxpool, e.g., Yout = max(x1, x2,..., XN), we split the maxpool function into several lines of one-by-one comparisons, each considering only one additional input\n\n\ny1 = max(x1,0) = ReLU(x1 - 0) + 0,\ny2 = max(x2,y1) = ReLU(x2 - y1) + y1,\n:\nYNout = max(xN, YN-1) = ReLU(XN - YN-1) + YN-1.\n\n\n(7)\nNote that we assume all of the inputs x1,..., XN are non-negative, since they are drawn from the output of ReLU. The operations through network f is given as follows:\nStarting with feature map zi-1 (l\u2208 [2, k]) with index region SIN, to apply convolution with zero-padding, we first pad the four boundaries of zi-1 with 0, namely\n\n\n\n\nz1\u22121,c,m,n = 0, (c,m,n) \u2208 SUDUSER,\nLR\n\n\n(8)\n(\u00ea,m,n)ES1-1\n\n\nl-1,c+ \u2211 hi-1,c(c, m+pi_1-si-\u2081m',n+pi_1-si\u2081n')z\u0131\u22121,\u00ea,m,n, (c, m', n') \u2208 Q{N ~ l \u2208 [2, k].\n\n\n\nz1,c,m',n' = bl-1,c+\n(9)\nBy taking convolution between the convolution kernel hi\u22121,c and the padded zi-1, we compute\u017c as in equation 9. As such, zf is obtained by applying ReLU to 21 as follows:\n\n\n\n\nz1,c,m,n = max 21,c,m,n, 0}, (c,m,n) \u2208 Q{N.\n\n\n(10)"}, {"title": "Regarding the maxpool layer, as illustrated in Fig. 8, one has", "content": "\n\n\n\nzl,c,m,n = max\n\n\n1,c,sMm+i,sMn+j\n\n\ni\u2208[0,kM-1],\nj\u2208 [0,kM-1]\n\n\n10\n\n\n\n\n\n\n(11)\nwhere k\u00bfM and stu indicate the kernel size and stride, respectively. By applying the decomposition trick to maxpool as in equation 7, one may rewrite equation 11 as zl,c,m,n = (z,m,n)kk for (c,m,n) \u2208 SIN,\n\nM\nwhere we denote (zic,m,n)o = 0 and\n\nM\n\n\n\n\n\n\n\n\n1,c,sMm+i',sMn+j'\n\n(zi,c,m,n)ik+j = max{R\n\ni'\u2208 [0,k-1],\n: j'\u2208[0,k-1],\n\n\n\ni'k+j'<iki+j}\n\n\n\n\n\n\n\n\n\n\nZR\nmax{\n\n1,c,sMm+i,sMn+j\n\nM\n1,c,sMm+i,sMn+j}\n\nM\n(z1,c,m,n)ik+j} ;} =max{\n+ (z1,c,m,n)ik+j\n\n\n\n(12)\nfor i \u2208 [0, k\u00bfM \u2013 1] and j\u2208 [0, kM \u2013 1], which can be further decomposed as follows:\n\n\n\n\n{R 1,c,sMm+i, sun+j - (zi,c,m,n)ik+j\n,\nM\n\n\n(zi,c,m,n)ikM+j =\n\n\nmax {(Z1,c,m,n)ikM+j, 0}\n\n\nM\n\n\n,\n\n\n= (Zi,c,m,n)ik+j+ (zi,c,m,n)ik+j\n\n\n\n(13)\nOnce the convolution part of the neural network is completed, we get zk and convert it into a vector \u017ee by flat kernel W, namely,\n\n\n\nzka =\n\n\n\u2211(Wc,m,n)azk,c,m,n\n\n\n(c,m,n)\u2208SIN\n\n\n(14)\nfor all a \u2208 [0, ak \u2013 1]. Finally, \u017ee is fed into linear part, where the linear and ReLU operations can be written as:\n\n\n21+1 = W\u0131z\u0131 + b\u00ed, l \u2208 [k, k + t \u2212 1]\n\n\n\nM= max(21,0), l\u2208 [k + 1, k + t \u2212 1].\n\n\n(15a)\n(15b)"}, {"title": "A.1.2 Convex outer bound", "content": "In order to make the feasible solution set a convex set", "following": "n\n\n\nz1"}, {"title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network", "authors": ["Jia-Hau Bai", "Chi-Ting Liu", "Yu Wang", "Fu-Chieh Chang", "Pei-Yuan Wu"], "abstract": "This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. (cf. Fig. 3 and Fig. 4). Furthermore, we additionally present the time complexity of our algorithm as O(W2NK), where W is the maximum width of the neural network, N is the number of neurons, and K is the size of the maxpool layer's kernel.", "sections": [{"title": "1 Introduction", "content": "In the past few years, convolution neural networks have reached unprecedented performance in various tasks such as face recognition (Hu et al., 2015; Mehdipour Ghazi & Kemal Ekenel, 2016) and self-driving cars (Rao & Frtunikj, 2018; Maqueda et al., 2018), to name a few. However, these networks are vulnerable to malicious modification of the pixels in input images, known as adversarial examples, such as FGSM (Goodfellow et al., 2015), PGD (Madry et al., 2018), One Pixel Attack (Su et al., 2019), Deepfool (Moosavi-Dezfooli et al., 2016), EAD (Chen et al., 2018), GAP (Poursaeed et al., 2018), MaF(Chaturvedi & Garain, 2020) and many others (Wong et al., 2019).\nIn view of the threat posed by adversarial examples, how to protect neural networks from being tricked by adversarial examples has become an emerging research topic. Previous studies of defense against adversarial examples are categorized as Removal of adversarial perturbation (Akhtar et al., 2018; Xie et al., 2019; Jia et al., 2019; Samangouei et al., 2018) and Adversarial training (Shafahi et al., 2019; Han et al., 2020; Tramer et al., 2020). Both defense mechanisms may protect the network from certain adversarial examples but there is only empirical evidence that they do so. The robustness of the network is not guaranteed. It is impossible to train or evaluate all possible adversarial examples so these methods are vulnerable to other adversarial examples that are not in the data sets that are used.\nThe need for guaranteed robustness assessments has led to the development of verification mechanisms for a neural network. These verify specific properties pertaining to neural networks, such as robustness against norm-bounded perturbation (Dvijotham et al., 2018; Singh et al., 2018), robustness against adversarial frequency or severity (Katz et al., 2017) and robustness against rotations (Singh et al., 2019a).\nDuring the early development of neural network verification, satisfiability modulo theories (SMT) solver (Katz et al., 2017) and semidefinite programming (SDP) methods (Raghunathan et al., 2018) were used. A SMT solver yields tight verification bounds but is not scalable to contemporary networks with sophisticated architecture. The SDP method requires less time but is limited to linear architectures. Recent studies have developed verification tools for more realistic scenarios, such as a fully connected neural network (FCNN) with an activation function and a convolution neural network (CNN). As indicated by Salman et al. (2020), the main methods for neural network verification can be categorized as either primal view or dual view.\nThe primal view method involves Abstract interpretation and Interval bound propagation. There are classic frameworks for abstract interpretation (e.g., AI2 (Gehr et al., 2018), DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a)). As a step further, RefineZono (Singh et al., 2019b) and RefinePoly (Singh et al., 2019b) use mixed integer linear programming (MILP) to improve the verification bounds for DeepZ and DeepPoly, respectively. However, the computation time that is required for verification is significantly increased. Another bounding technique for the primal view method is interval bound propagation, which uses interval arithmetic to obtain the bound for each individual neuron in each layer. Representative works include IBP (Gowal et al., 2018) and CROWN-IBP (Zhang et al., 2019). Dual-view methods (Wong & Kolter, 2018; Dvijotham et al., 2018; Wong et al., 2018; Bunel et al., 2020; Xu et al., 2020; Wang et al., 2021) formulate the verification problem as an optimization problem, so according to Lagrangian duality (Boyd et al., 2004), each dual feasible solution yields a lower bound to the primal problem and verification bounds are derived by solving the dual problem. Moreover, noteworthy among these methods is the state-of-the-art approach \u03b1,\u03b2-CROWN (Wang et al., 2021), which is grounded in the LiRPA framework (Xu et al., 2020)."}, {"title": "1.1 Verification of a CNN with maxpooling", "content": "The maxpool function is an integral part in most real-world neural network architectures, especially CNNs (e.g., LeNet (LeCun et al., 1998), AlexNet (Krizhevsky et al., 2012) and VGG (Simonyan & Zisserman, 2015)), which are widely used for image classification. However, past works have the following shortage in the verification of networks involving maxpool functions:\nNot applicable: IBP (Gowal et al., 2018) and others (Wong & Kolter, 2018; Wong et al., 2018) (Bunel et al., 2020; De Palma et al., 2021) verify a CNN but there is no theory to verify maxpool-based networks. Gowal et al. (2018) analyzed several monotonic activation functions (e.g., ReLU, tanh, sigmoid) in IBP but they did not consider non-monotonic functions (e.g., maxpool). Wong & Kolter (2018) discussed the verification of a ReLU-based FCNN and a later study (Wong et al., 2018) uses this for the verification of residual networks. However, besides referring to the work of Dvijotham et al. (2018), the study by Wong et al. (2018) does not address much about handling maxpool functions. Bunel et al. (2020); De Palma et al. (2021) analyzed networks with nonlinear activation functions, such as ReLU and sigmoid, but there is no analysis of the maxpool function.\nHas theory but lack of implementation evidence: These studies analyze the maxpool function but experiments only verifiy ReLU-based CNNs. Examples include AI2 (Gehr et al., 2018), DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a), RefineZono (Singh et al., 2019b), RefinePoly (Singh et al., 2019b) and LiRPA (Xu et al., 2020). Dvijotham et al. (2018) analyzed a large variety of activation functions, such as ReLU, tanh, sigmoid and maxpool, but they only demonstrated the experiment result on a small network consisting of one linear layer, followed by sigmoid and tanh. CROWN-IBP (Zhang et al., 2019) used the verification method of IBP (Gowal et al., 2018) and analyzed non-monotonic functions, including maxpool, but experiments only verify results for ReLU-based CNNs. In spite of providing functions corresponding to maxpool, LIRPA is currently unable to function properly on maxpool-based CNNs. The definitions of DenseNet and ResNeXt used in their experiments can be found in their GitHub repository, and it's noteworthy that these definitions do not include a maxpool layer.\nImprecise: These studies give an imprecise verification bound for maxpool-based CNN. DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a), and PRIMA (M\u00fcller et al., 2022) implement the verification of maxpool-based CNN but experimental results are nevertheless lacking. For comparison purposes, we implement these methods on 6 maxpool-based CNN benchmarks modified from (Mirman et al., 2018) (cf. Supplementary Material A.4). Our experiment indicates that DeepZ, DeepPoly, and PRIMA are imprecise in our benchmarks. For a norm-bounded perturbation \u2208 = 0.0024, the verified robustness for a convSmall CIFAR10 structure decreases to 1%, 25%, and 26%, respectively (cf. Fig. 3). Due to the implementation of the BaB (branch and bound) algorithm in \u03b1,\u03b2-CROWN (Wang et al., 2021) on maxpool-based CNNs, it results in excessive GPU memory requirements (more than 13GB) or prolonged execution times (more than 5 minutes per example). Consequently, we consider examples that trigger the BaB algorithm as not verified.\nComputational costly: These studies involve a significant computational cost to verify each input image in the maxpool-based CNN benchmarks (cf. Sec. 3.1). Our experiment shows that for \u2208 = 0.0006 on convBig CIFAR10 (cf. Fig. 4), PRIMA (M\u00fcller et al., 2022) requires 6.5 days and DeepPoly (Singh et al., 2019a) requires 3 days to verify 100 images. (See Sec. 3.1 for hardware spec)"}, {"title": "2 Method", "content": "This section illustrates the verification of a CNN classifier under the l\u221e norm-bounded perturbations. Sec. 2.1 defines the verification problem and Sec. 2.2 gives an overview of CAPM. More details for solving the verification problem for a maxpool-based CNN are in Supplementary Material A.1 and Supplementary Material A.2.\nSupplementary Material A.1 specifies the CNN architecture for this study; Supplementary Material A.2 describes the formulation of the the verification problem in terms of Lagranian dual problems, and simplifies the dual constraints to the form of a leaky ReLU dual network."}, {"title": "2.1 Definition of the verification problem", "content": "This study evaluates the robustness of a CNN to arbitrary adversarial examples within a bounded norm budget, to see whether or not the prediction result of the CNN will change under such adversarial perturbations. The verification problem is reformulated through convex relaxation as a convex optimization problem and the duality theorem states that any dual feasible solution can serve as a lower bound for the original verification problem.\nA neural network f consisting of k convolution layers with ReLU activation and maxpool functions, followed by flattening and t fully connected layers with ReLU activation is shown in Fig 1. If a clean image x is added with perturbation A, to which this study impose a l\u221e-norm constraint $||A||_\\infty\\leq \\epsilon$, the perturbed input z1 resides in an input adversarial polytope that is described as:\n\n$z_1 \\leq x + \\epsilon$ and $z_1 \\geq x - \\epsilon$.\n\n(1)\nThe perturbed input z\u2081 is taken as the input of the network f. Though at first glimpse the input adversarial polytope (cf. equation 1) is a hyper-cube which is convex, and that the ReLU function is itself a convex function, the intermediate adversarial polytope after passing the input adversarial polytope through the convolution and ReLU activation is in general not a convex set, as the set ${(\\xi, ReLU(\\xi)) : \\xi\\in\\mathbb{R}}$ is not a convex subset of R2. The verification problem deviates from a convex optimization framework due to"}, {"title": "2.2 CAPM overview", "content": "This section describes a toy example to illustrate the use of CAPM to solve the optimization problem in equation 2 using a Maxpool-based network. The dual problem is formulated using Lagrangian relaxation (Boyd et al., 2004) and convex relaxation (Wong & Kolter, 2018), so any dual feasible solution corresponds to a lower bound to the original problem in equation 2. Convex relaxation loosens the verification bound but Wong & Kolter (2018) showed that this lower bound can be calculated using a backpropagation-like dynamic programming process in a so called dual network. As the determination of upper and lower bounds for preceding layers constitutes a sub-problem within the dual network framework for subsequent layers, employing a dynamic programming algorithm becomes a viable approach to address this verification problem. This study extends the method of Wong & Kolter (2018) to a maxpool-based CNN and demonstrates that maxpool-based CNNs can also be verified efficiently and precisely using a dual network."}, {"title": "2.2.1 Toy example", "content": "CAPM verifies the robustness of a simple maxpool-based network under the l\u221e norm constraint in equation 1. The verification problem for this toy example is formulated as an optimization problem in equation 3. If the lower bound of equation 3 is positive for all possible target classes, then this network is not misled by any input perturbation, l\u221e-norm that is less than \u03f5. If not, then this network may not be safe for this input perturbation.\n\n$\\min\\limits_{z_3} (e_{y^*}-e_{y^{targ}})^Tz_3 = d^Ty_3$\n\ns.t. $z_1 \\leq x + \\epsilon$\n$z_1 \\geq x-\\epsilon$\n$z_2 = W_1z_1 + b_1$\n\n\n$z^R_2 = max(z_2, 0)$\n\n\nmax(z2,0) = max(z_{2,0}, z_{2,1}, z_{2,2}, z_{2,3})$\n\n$z_3 = W_2z^R_2 + b_2$\n\n(3)\nIn equation 3, the perturbed input z\u2081 is the input to a simple maxpool-based network. The feature map z2 is obtained by inputting z\u2081 into the linear operation in the fully-connected layer. ReLU and maxpool"}, {"title": "2.2.2 Determining the upper-lower bound", "content": "The node-wise upper-lower bounds are required for the convex relaxation of ReLU functions. To determine the upper-lower bounds, namely $l_{2,j} \\leq z_{2,j} \\leq \\bar{u}_{2,j}$, for the input nodes of the ReLU function, a verification problem is formulated that corresponds to the network up to the linear layer before the first ReLU. The node-wise bounds for $z_{2,j}$ are determined by evaluating the resulting (smaller) dual network with one-hot input vector $e_j$ (instead of d) (Wong & Kolter, 2018). In terms of the element-wise lower and upper bounds, namely $l_{2,j} \\leq z_{2,j} \\leq \\bar{u}_{2,j}$, that pertain to the maxpool functions, each maxpool function is decomposed into multiple ReLU activations (cf. equation 4). Thus computing these bounds layer-by-layer as in (Wong & Kolter, 2018) would be very costly. The values for $l_{2,j}$ and $\\bar{u}_{2,j}$ can be calculated more efficiently as follows: For (cf. equation 5a)\n\n$z^{\\mathcal{M}}_{2,j} = y_j - z_2$\n\nif the element-wise lower and upper bounds for $z_{2,j}$ and $z$, namely\n\n$l_{2,j} \\leq y \\leq \\bar{u}_{2,j}$ and $l \\leq z \\leq \\bar{u}_2$,\n\n\nthen are derived as\n\n\nthe element-wise lower and upper bounds $l_{2,j}$ and $\\bar{u}_{2,j}$ for $z^{\\mathcal{M}}$ are derived as\n\n$l_{2,j} = y - \\bar{u}_2$ and $\\bar{u}_{2,j} = \\bar{y} - l_2$.\n\nThe elementwise bounds $l^{\\mathcal{M}}_{j'}$ and $\\bar{u}^{\\mathcal{M}}_{j'}$ on the pre-maxpool activations can be computed in a way similar to\nhow the elementwise bounds for pre-ReLU activations are computed in (Wong & Kolter, 2018). To compute\n$l^{\\mathcal{M}}_{2,j+1}$ and $\\bar{u}^{\\mathcal{M}}_{2,j+1}$, recall that\n\n$z^{\\mathcal{M}}_{2,j+1} = max{z^{\\mathcal{M}}_{2j'}, : j' \\in [0, j]} $."}, {"title": "3 Experiment", "content": "This section determines the verified robustness and the average verification time for CAPM, DeepZ, DeepPoly, PRIMA (M\u00fcller et al., 2022) and \u03b1,\u03b2-CROWN for a l\u221e norm-bounded perturbation of various budgets and for various attack schemes, such as FGSM and PGD. Sec. 3.1 details the experimental network architecture and the input dataset. Sec. 3.2 compares the results for this study with those of previous studies (DeepZ, DeepPoly, PRIMA and \u03b1,\u03b2-CROWN) in terms of the verified robustness and the average verification time, and Supplementary Material A.5 illustrates how we reproduced the state-of-the-art methods so that we can have a fair comparison with them. Experiments in Supplementary Materials A.3.2 also demonstrate that the neural network verification problem cannot be simply evaluated using a Monte-Carlo simulation. All experiments were conducted on a 2.6 GHz 14 core Intel(R) Xeon(R) CPU E5-2690 v4 with a 512 GB main memory."}, {"title": "3.1 Experiment setting", "content": "Robustness is calculated against adversarial examples on several networks that are trained using different methods:\nDataset: Models are trained using the MNIST and CIFAR10 datasets. Images are normalized using the default setting for DeepPoly (Singh et al., 2019a). For MNIST, the mean and standard deviation is 0.5 and 0.5, respectively. For CIFAR 10, the mean and standard deviation of the RGB channels is (0.485, 0.456, 0.406) and (0.229, 0.224, 0.225), respectively.\nArchitecture of neural networks: There are no empirical verificaion results on maxpool-based CNNs so maxpool layers are added to the common benchmark networks, convSmall, convMed and convBig in (Mirman et al., 2018). The parameter for striding and padding is adjusted to achieve a similar number of parameters to previous studies. Information about these 6 networks is shown in Table 1. The detail structures are shown in Supplementary Material A.4. Moreover, although the authors of \u03b1,\u03b2-CROWN didn't conduct experiments in maxpool-based CNNs before and they did make some additional assumptions on their maxpool layers, we would like to compare with them in maxpool-based CNNs. Hence, we also create the network benchmark convs, convm and conv for their settings.\nTraining methods: We compared the verification results of CNNs trained either normally (without adversarial training) or with adversarial examples such as Fast-Adversarial (Wong et al., 2020) and PGD (Madry et al., 2018).\nPerformance metrics: The performance of neural network verification is often evaluated through the following metrics (Singh et al., 2019a):\nVerified robustness: This is expressed as the number of images verified to be resilient to adversary example attack, divided by the total number of accurate images. This ratio represents the analysis precision of a verifier when a neural network is applied to a test image dataset that is subject to attack by an adversarial example.\nAverage verified time: This is the total time that is required by the verification algorithm to verify images, divided by the total number of images."}, {"title": "3.1.2 Robustness evaluation", "content": "For each test dataset, the settings for DeepPoly (Singh et al., 2019a) are used and the top 100 clean images are used as the evaluation test dataset. Adversarial examples are generated by adding to clean images with l\u221e norm-bounded perturbation for various budgets \u03f5 and various attack schemes, such as FGSM and PGD. The generated adversarial examples are then applied to the neural network to compare the accuracy of lower bounds that are evaluated using various verification methods. A better verification method must give a tighter (higher) accuracy for the lower bound and never exceeds that of existing attack schemes. The implementation details for DeepPoly, PRIMA and \u03b1,\u03b2-CROWN are described as follows:\n\u2022 DeepZono and DeepPoly: We follow the implementation as suggested by the default command in their GitHub (Eth-Sri).\n\u2022 PRIMA: We use exactly the same configuration mentioned in (M\u00fcller et al., 2022) for convSmall and convBig. Since PRIMA didn't report any results on convMed, and that convMed has the same number of layers as convSmall, we use the same configuration that PRIMA applied to convSmall on convMed as well.\n\u2022 \u03b1,\u03b2-CROWN: We used the default parameters and set the parameter conv mode to matrix in order to enable the operation of the BaB algorithm. The examples that would trigger the BaB algorithm were considered not verified. This adjustment was made because the implementation of the BaB algorithm on maxpool-based CNNs results in excessive GPU memory requirements (more than 13GB) and extended execution times (more than 5 minutes per example)."}, {"title": "3.2 Experimental results", "content": "The results for CAPM are compared with those of previous studies (DeepZ, DeepPoly, PRIMA) in terms of the verified robustness and average runtime metrics for various adversary budgets \u03f5 for six different networks, as shown in Fig. 3 and Fig. 4. The classification accuracy for a real-world PGD attack is also determined. A verification method must demonstrate verified robustness that is no greater than the accuracy of real-world attack schemes. Fig. 3 and Fig. 4 illustrate that CAPM achieves better verification robustness than all other schemes for all combination of the CIFAR10 dataset and has a much lower computational cost. The computational cost of CAPM is independent of \u03f5, because a different adversary budget corresponds to the same dual network architecture so computational costs are similar. However, the verification time that is required by PRIMA increases as \u03f5 increases, possibly because as \u03f5 increases, the intermediate adversarial polytope becomes more complicated and must be described by a more complex MILP optimization problem. This demonstrates the promising potential of CAPM towards verification of large scale CNNs and colour images. Due to the excessive GPU memory requirements of \u03b1,\u03b2-CROWN, we did not include \u03b1,\u03b2-CROWN in this set of experiments."}, {"title": "4 Conclusion", "content": "This study extends Wong & Kolter (2018)'s work to general purpose CNNs with maxpool, padding, and striding operations. The key idea for handing the maxpool function is to decompose it into multiple ReLU functions, while special care is taken to speed-up the computation of element-wise bounds required for the convex relaxation of intermediate ReLUs in maxpool layer. General purpose CNNs are expressed using a dual network, which allows efficient computation of verified bounds for CNNs.\nThe experimental results show that CAPM outperforms previous methods (DeepZ, DeepPoly, and PRIMA) in terms of verified robustness and computational cost for most adversary budget settings, and especially for large-scale CNNs for color images. For an adversary budget \u2208 = 0.0024, the verified robustness for DeepZ, DeepPoly and PRIMA for convSmall CIFAR10 decreases by to 1%, 25%, and 26%, respectively, but CAPM has a verified robustness of 87.5%; For an adversary budget \u2208 = 0.0006 for convBig CIFAR10, CAPM is 40-times and 20-times faster than PRIMA and DeepPoly, respectively, and gives a significantly higher verified robustness (see Fig. 3 and Fig. 4).\nThe proposed method gives comparable or better verification with significantly less runtime cost. Unlike many verification methods, for which runtime increases with the adversary budget \u03f5, CAPM has a constant runtime, regardless of the adversary budget, so it can be used for larger-scale CNNs which are usually computationally prohibitive for other verification methods. The proposed verification method is suited for use with large scale CNNs, which are an important element of machine learning services.\nThis study does provide a more precise and efficient verification for maxpool-based CNNs but the verified network is limited to a specific architecture that is defined in Supplementary Material A.1.1. Future study will involve the design of a verification framework that is applicable to neural networks with a more flexible architecture.\nAdditionally, the method of simplifying certain layers into multiple ReLU layers may likely be limited to maxpool layers only. Therefore, our preliminary future direction will focus on achieving greater flexibility in maxpool-based CNNs. Subsequently, we will continue exploring more flexible neural network architectures, such as residual connections."}, {"title": "A Appendix", "content": "As mentioned in section 2.1, the network f in consideration is a maxpool-based CNN, which consists of k convolution layers with ReLU activation and maxpool functions, followed by flattening and t fully connected layers with ReLU activation. In this manuscript we separate layers 1 - 1 and I with the linear operations. That is, the first layer simply contains a convolution operation; and from layer 2 to k \u2212 1, there are ReLU, maxpool, and convolution operations in order; while the k-th layer contains ReLU, maxpool, flatten, and linear (fully connected) operations. After the flatten operation is the fully-connected part of the network. Denote T = k+ t as the total number of layers in f, then within layers k+1 to T there are ReLU and linear (fully connected) operations in order, while the last layer is a pure output layer containing no operations. In the following derivation, we consider CNN with k\u2265 2 and t > 1. The explicit notations pertaining to all intermediate results during the calculation of f are specified in Sec. A.1.1 and Table 4."}, {"title": "A.1.1 Notation and data flow", "content": "We use the tuple (l, c, m, n) to indicate the pixel located at the m-th row and n-th column in the c-th channel of the corresponding l-th layer feature map. For instance, such a pixel in the feature map zi is indicated as zl,c,m,n.\nTo consider padding which is a common practice in convolutions, we extend the pixel region of the feature map zi, which is the input to the convolution operation, to $S_1 = S^{IN} \\cup S^{UD} \\cup S^{LR}$ as indicated in Table 5 and Fig. 6. Here $S^{IN}$ represents the index region of the feature map zi without padding, while $S^{UD}$ represents the padded index region located at the upper/down-sides of the feature map zi, and $S^{LR}$ represents the padded index region located at the left/right-sides of the feature map zi."}, {"title": "\u2022 Convolution kernel hi,c", "content": "As illustrated in Fig. 7, we use hi,e to represent the c-th convolution kernel in the 1-th layer, where l\u2208 [1, k \u2212 1] and c\u2208 [0,C1+1 \u2013 1]. In addition, each kernel contains ci channels with both height and width kiu, namely the index region of hi,c is [0, c\u0131 \u2013 1] \u00d7 [0, \u03ba\u03b5\u03c5 \u2212 1] \u00d7 [0, kv \u2212 1]. Here we use hi,c(\u00ea, m, n) to refer to the kernel value at the \u00ea-th channel, m-th row and n-th column, and define hi,c(\u00ea, m, n) = 0 for each index (\u00ea, m, n) that is out of the range [0, ci - 1] \u00d7 [0, kv \u2013 1] \u00d7 [0, kv \u2013 1]."}, {"title": "Flat kernel W", "content": "The flat kernel unfolds the feature map zk to the vector \u017ee in the flattening layer, namely\n\n\n$z_{k,a} = \\sum\\limits_{(c,m,n)\\in S^{IN}}(W_{c,m,n})_az_{k,c,m,n}, a \\in [0, a_k - 1],$\n\n\nwhere $(W_{c,m,n})_a = 1\\{a = C_kN_kN_k + mN_k + n\\}$ for $(c, m, n) \\in S^{IN}$, and that $a_k = C_kN_kN_k$.\nBefore introducing the details of the math operations processing through network f, we first illustrate how to decompose the maxpool: Instead of considering the whole group of candidates as the input of maxpool, e.g., $Y_{out} = max(x_1, x_2,..., X_N)$, we split the maxpool function into several lines of one-by-one comparisons, each considering only one additional input\n\n$y_1 = max(x_1,0) = ReLU(x_1 - 0) + 0,$\n$y_2 = max(x_2,y_1) = ReLU(x_2 - y_1) + y_1,$\n:\n$Y_{out} = max(x_N, Y_{N-1}) = ReLU(X_N - Y_{N-1}) + Y_{N-1}$.\n\n(7)\nNote that we assume all of the inputs $x_1,..., X_N$ are non-negative, since they are drawn from the output of ReLU. The operations through network f is given as follows:\nStarting with feature map $z_{l-1}$ (l\u2208 [2, k]) with index region $S^{IN}_1$, to apply convolution with zero-padding, we first pad the four boundaries of $z_{l-1}$ with 0, namely\n\n$z_{l-1,c,m,n} = 0, (c,m,n) \\in S^{UD} \\cup S^{LR},$\n\n(8)\n$z_{l,c,m',n'} = b_{l-1,c}+ \\sum\\limits_{(\\hat{c},m,n) \\in S_{l-1}} h_{l-1,c}(\\hat{c}, m+\\rho_l-1-s_{l-1}m',n+\\rho_l-1-s_{l-1}n')z_{l-1,\\hat{c},m,n}, (c, m', n') \\in Q^{IN} ~ l \\in [2, k].$\n(9)\nBy taking convolution between the convolution kernel $h_{l-1,c}$ and the padded $z_{l-1}$, we compute\u017c as in equation 9. As such, $z^R_1$ is obtained by applying ReLU to 21 as follows:\n\n$z^R_{l,c,m,n} = max \\{z_{l,c,m,n}, 0\\}, (c,m,n) \\in Q^{IN}$.\n\n(10)"}]}]}