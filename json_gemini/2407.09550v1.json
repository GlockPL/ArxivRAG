{"title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network", "authors": ["Jia-Hau Bai", "Chi-Ting Liu", "Yu Wang", "Fu-Chieh Chang", "Pei-Yuan Wu"], "abstract": "This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. (cf. Fig. 3 and Fig. 4). Furthermore, we additionally present the time complexity of our algorithm as O(W2NK), where W is the maximum width of the neural network, N is the number of neurons, and K is the size of the maxpool layer's kernel.", "sections": [{"title": "Introduction", "content": "In the past few years, convolution neural networks have reached unprecedented performance in various tasks such as face recognition (Hu et al., 2015; Mehdipour Ghazi & Kemal Ekenel, 2016) and self-driving cars (Rao & Frtunikj, 2018; Maqueda et al., 2018), to name a few. However, these networks are vulnerable to malicious modification of the pixels in input images, known as adversarial examples, such as FGSM (Goodfellow et al., 2015), PGD (Madry et al., 2018), One Pixel Attack (Su et al., 2019), Deepfool (Moosavi-Dezfooli et al., 2016), EAD (Chen et al., 2018), GAP (Poursaeed et al., 2018), MaF(Chaturvedi & Garain, 2020) and many others (Wong et al., 2019).\nIn view of the threat posed by adversarial examples, how to protect neural networks from being tricked by adversarial examples has become an emerging research topic. Previous studies of defense against adversarial examples are categorized as Removal of adversarial perturbation (Akhtar et al., 2018; Xie et al., 2019; Jia et al., 2019; Samangouei et al., 2018) and Adversarial training (Shafahi et al., 2019; Han et al., 2020; Tramer et al., 2020). Both defense mechanisms may protect the network from certain adversarial examples but there is only empirical evidence that they do so. The robustness of the network is not guaranteed. It is impossible to train or evaluate all possible adversarial examples so these methods are vulnerable to other adversarial examples that are not in the data sets that are used.\nThe need for guaranteed robustness assessments has led to the development of verification mechanisms for a neural network. These verify specific properties pertaining to neural networks, such as robustness against norm-bounded perturbation (Dvijotham et al., 2018; Singh et al., 2018), robustness against adversarial frequency or severity (Katz et al., 2017) and robustness against rotations (Singh et al., 2019a).\nDuring the early development of neural network verification, satisfiability modulo theories (SMT) solver (Katz et al., 2017) and semidefinite programming (SDP) methods (Raghunathan et al., 2018) were used. A SMT solver yields tight verification bounds but is not scalable to contemporary networks with sophisticated architecture. The SDP method requires less time but is limited to linear architectures. Recent studies have developed verification tools for more realistic scenarios, such as a fully connected neural network (FCNN) with an activation function and a convolution neural network (CNN). As indicated by Salman et al. (2020), the main methods for neural network verification can be categorized as either primal view or dual view.\nThe primal view method involves Abstract interpretation and Interval bound propagation. There are classic frameworks for abstract interpretation (e.g., AI2 (Gehr et al., 2018), DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a)). As a step further, RefineZono (Singh et al., 2019b) and RefinePoly (Singh et al., 2019b) use mixed integer linear programming (MILP) to improve the verification bounds for DeepZ and DeepPoly, respectively. However, the computation time that is required for verification is significantly increased. Another bounding technique for the primal view method is interval bound propagation, which uses interval arithmetic to obtain the bound for each individual neuron in each layer. Representative works include IBP (Gowal et al., 2018) and CROWN-IBP (Zhang et al., 2019). Dual-view methods (Wong & Kolter, 2018; Dvijotham et al., 2018; Wong et al., 2018; Bunel et al., 2020; Xu et al., 2020; Wang et al., 2021) formulate the verification problem as an optimization problem, so according to Lagrangian duality (Boyd et al., 2004), each dual feasible solution yields a lower bound to the primal problem and verification bounds are derived by solving the dual problem. Moreover, noteworthy among these methods is the state-of-the-art approach \u03b1,\u03b2-CROWN (Wang et al., 2021), which is grounded in the LiRPA framework (Xu et al., 2020)."}, {"title": "Verification of a CNN with maxpooling", "content": "The maxpool function is an integral part in most real-world neural network architectures, especially CNNs (e.g., LeNet (LeCun et al., 1998), AlexNet (Krizhevsky et al., 2012) and VGG (Simonyan & Zisserman, 2015)), which are widely used for image classification. However, past works have the following shortage in the verification of networks involving maxpool functions:\nNot applicable: IBP (Gowal et al., 2018) and others (Wong & Kolter, 2018; Wong et al., 2018) (Bunel et al., 2020; De Palma et al., 2021) verify a CNN but there is no theory to verify maxpool-based networks. Gowal et al. (2018) analyzed several monotonic activation functions (e.g., ReLU, tanh, sigmoid) in IBP but they did not consider non-monotonic functions (e.g., maxpool). Wong & Kolter (2018) discussed the verification of a ReLU-based FCNN and a later study (Wong et al., 2018) uses this for the verification of residual networks. However, besides referring to the work of Dvijotham et al. (2018), the study by Wong et al. (2018) does not address much about handling maxpool functions. Bunel et al. (2020); De Palma et al. (2021) analyzed networks with nonlinear activation functions, such as ReLU and sigmoid, but there is no analysis of the maxpool function.\nHas theory but lack of implementation evidence: These studies analyze the maxpool function but experiments only verifiy ReLU-based CNNs. Examples include AI2 (Gehr et al., 2018), DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a), RefineZono (Singh et al., 2019b), RefinePoly (Singh et al., 2019b) and LiRPA (Xu et al., 2020). Dvijotham et al. (2018) analyzed a large variety of activation functions, such as ReLU, tanh, sigmoid and maxpool, but they only demonstrated the experiment result on a small network consisting of one linear layer, followed by sigmoid and tanh. CROWN-IBP (Zhang et al., 2019) used the verification method of IBP (Gowal et al., 2018) and analyzed non-monotonic functions, including maxpool, but experiments only verify results for ReLU-based CNNs. In spite of providing functions corresponding to maxpool, LIRPA is currently unable to function properly on maxpool-based CNNs. The definitions of DenseNet and ResNeXt used in their experiments can be found in their GitHub repository, and it's noteworthy that these definitions do not include a maxpool layer.\nImprecise: These studies give an imprecise verification bound for maxpool-based CNN. DeepZ (Singh et al., 2018), DeepPoly (Singh et al., 2019a), and PRIMA (M\u00fcller et al., 2022) implement the verification of maxpool-based CNN but experimental results are nevertheless lacking. For comparison purposes, we implement these methods on 6 maxpool-based CNN benchmarks modified from (Mirman et al., 2018) (cf. Supplementary Material A.4). Our experiment indicates that DeepZ, DeepPoly, and PRIMA are imprecise in our benchmarks. For a norm-bounded perturbation \u03f5 = 0.0024, the verified robustness for a convSmall CIFAR10 structure decreases to 1%, 25%, and 26%, respectively (cf. Fig. 3). Due to the implementation of the BaB (branch and bound) algorithm in \u03b1,\u03b2-CROWN (Wang et al., 2021) on maxpool-based CNNs, it results in excessive GPU memory requirements (more than 13GB) or prolonged execution times (more than 5 minutes per example). Consequently, we consider examples that trigger the BaB algorithm as not verified.\nComputational costly: These studies involve a significant computational cost to verify each input image in the maxpool-based CNN benchmarks (cf. Sec. 3.1). Our experiment shows that for \u03f5 = 0.0006 on convBig CIFAR10 (cf. Fig. 4), PRIMA (M\u00fcller et al., 2022) requires 6.5 days and DeepPoly (Singh et al., 2019a) requires 3 days to verify 100 images. (See Sec. 3.1 for hardware spec)"}, {"title": "Verification problem", "content": "This study evaluates the robustness of a CNN to arbitrary adversarial examples within a bounded norm budget, to see whether or not the prediction result of the CNN will change under such adversarial perturbations. The verification problem is reformulated through convex relaxation as a convex optimization problem and the duality theorem states that any dual feasible solution can serve as a lower bound for the original verification problem.\nA neural network f consisting of k convolution layers with ReLU activation and maxpool functions, followed by flattening and t fully connected layers with ReLU activation is shown in Fig 1. If a clean image x is added with perturbation A, to which this study impose a l\u221e-norm constraint ||A||\u221e\u2264 \u03f5, the perturbed input z1 resides in an input adversarial polytope that is described as:\n$$Z_1 \\leq X + \\epsilon \\text{ and } Z_1 \\geq X - \\epsilon.$$\nThe perturbed input z\u2081 is taken as the input of the network f. Though at first glimpse the input adversarial polytope (cf. equation 1) is a hyper-cube which is convex, and that the ReLU function is itself a convex function, the intermediate adversarial polytope after passing the input adversarial polytope through the convolution and ReLU activation is in general not a convex set, as the set {(\u03be, ReLU(\u03be)) : \u03be\u2208R} is not a convex subset of R2. The verification problem deviates from a convex optimization framework due to the non-linearity of ReLU and maxpool equalities. The presence of these non-linear equalities introduces complexity, rendering the optimization problem non-convex. Similarly, the application of a nonlinear function leads to a non-convex output polytope, even if the input polytope maintains convexity. In other words, substituting nonlinear equality constraints with linear inequality constraints results in the creation of a convex outer bound. To make the feasible solution a convex set, a convex outer bound (Wong & Kolter, 2018) is constructed when passing through each of the ReLU and maxpool functions. The output polytope Ze, which is the collection of all possible results computed by f at the output layer with a perturbed input z1, is contained within a convex polytope \u017d. Both Z\u025b and \u017d\u02b9 are subsets of RK for a K-class classification task.\nFor an image x that is labeled with ground truth y* \u2208 {1, ..., K} to which an adversary attempts to mislead network f into falsely predicting a target label ytarg \u2208 {1, ..., K} rather than y*, a necessary condition is that the adversary must find a perturbed input z1 satisfying equation 1 so that ey*T f(z1) < eytargT f(z1), where ey* and eytarg are one-hot encoded vectors of y* and ytarg, respectively. Therefore, as f(z1) \u2208 Ze C 2, if the minimum for the optimization problem\n$$\\min_{J \\in \\dot{Z}} (e_{y^*} - e_{y^{targ}})^T \\hat{y}$$\nis positive for every target class ytarg \u2208 {1, ..., K} \\ {y*}, then network f cannot be fooled by an adversarial example that differs from image x by a perturbation with at most \u03f5 under l\u221e-norm. This method can guarantee zero false negatives, so the system flags every image that is prone to attack by an adversarial example, but it may falsely flag some images resilient to perturbations."}, {"title": "CAPM overview", "content": "This section describes a toy example to illustrate the use of CAPM to solve the optimization problem in equation 2 using a Maxpool-based network. The dual problem is formulated using Lagrangian relaxation (Boyd et al., 2004) and convex relaxation (Wong & Kolter, 2018), so any dual feasible solution corresponds to a lower bound to the original problem in equation 2. Convex relaxation loosens the verification bound but Wong & Kolter (2018) showed that this lower bound can be calculated using a backpropagation-like dynamic programming process in a so called dual network. As the determination of upper and lower bounds for preceding layers constitutes a sub-problem within the dual network framework for subsequent layers, employing a dynamic programming algorithm becomes a viable approach to address this verification problem. This study extends the method of Wong & Kolter (2018) to a maxpool-based CNN and demonstrates that maxpool-based CNNs can also be verified efficiently and precisely using a dual network."}, {"title": "Toy example", "content": "CAPM verifies the robustness of a simple maxpool-based network under the l\u221e norm constraint in equation 1. The verification problem for this toy example is formulated as an optimization problem in equation 3. If the lower bound of equation 3 is positive for all possible target classes, then this network is not misled by any input perturbation, l\u221e-norm that is less than \u03f5. If not, then this network may not be safe for this input perturbation.\n$$\\min_{z_3} (e_y - e_{y^{targ}})^T z_3 = d^Tz_3$$\ns.t. z1 \u2264 x + \u03f5\nz1 \u2265 x - \u03f5\nz2 = W1z1 + b1\n$z_2^R = max(z_2, 0)$\nz3 = W2$z_2^\\dot{R}$ + b2\nIn equation 3, the perturbed input z\u2081 is the input to a simple maxpool-based network. The feature map z\u2082 is obtained by inputting z\u2081 into the linear operation in the fully-connected layer. ReLU and maxpool are then used to compute the intermediate results $z_2^\\dot{R}$ and z2. The output z3 is calculated using the linear operation. This is a non-convex optimization problem because of the non-affine activation functions ReLU and maxpool so Wong & Kolter (2018)'s method of convex relaxation (see Supplementary Material A.1.2 for more details) is applied to the ReLU function over the input interval, which approximates the ReLU function using the linear outer bounds (cf. Fig. 9). In terms of the maxpool function (see A.1.1 and A.1.2 for more details), $z_2^M$ = max($z_{2,0}^R$, $z_{2,1}^R$, $z_{2,2}^R$, $z_{2,3}^R$) is decomposed into several one-by-one comparisons using dummy variables\n$$z_{2,j+1}^M = max(z_{2,j}^R, z_{2,j}^R) = z_{2,j}^R + max(z_{2,j}^R - z_{2,j}^R, 0), j \\in [0,3].$$"}, {"title": "Determining the upper-lower bound", "content": "The node-wise upper-lower bounds are required for the convex relaxation of ReLU functions. To determine the upper-lower bounds, namely $l_{2,j} \\leq z_{2,j} \\leq \\hat{u}_{2,j}$, for the input nodes of the ReLU function, a verification problem is formulated that corresponds to the network up to the linear layer before the first ReLU. The node-wise bounds for z2,j are determined by evaluating the resulting (smaller) dual network with one-hot input vector ej (instead of d) (Wong & Kolter, 2018). In terms of the element-wise lower and upper bounds, namely $l_{2,j}^M \\leq z_{2,j}^M \\leq \\hat{u}_{2,j}^M$, that pertain to the maxpool functions, each maxpool function is decomposed into multiple ReLU activations (cf. equation 4). Thus computing these bounds layer-by-layer as in (Wong & Kolter, 2018) would be very costly. The values for $l_{2,j}$ and $\\hat{u}_{2,j}$ can be calculated more efficiently as follows:\nFor (cf. equation 5a)\n$$\\tilde{z_{2,j}} = z_{2.j}^R - z_{2.j}^M$$"}, {"title": "Experiment", "content": "This section determines the verified robustness and the average verification time for CAPM, DeepZ, DeepPoly, PRIMA (M\u00fcller et al., 2022) and \u03b1,\u03b2-CROWN for a l\u221e norm-bounded perturbation of various budgets and for various attack schemes, such as FGSM and PGD. Sec. 3.1 details the experimental network architecture and the input dataset. Sec. 3.2 compares the results for this study with those of previous studies (DeepZ, DeepPoly, PRIMA and \u03b1,\u03b2-CROWN) in terms of the verified robustness and the average verification time, and Supplementary Material A.5 illustrates how we reproduced the state-of-the-art methods so that we can have a fair comparison with them. Experiments in Supplementary Materials A.3.2 also demonstrate that the neural network verification problem cannot be simply evaluated using a Monte-Carlo simulation. All experiments were conducted on a 2.6 GHz 14 core Intel(R) Xeon(R) CPU E5-2690 v4 with a 512 GB main memory."}, {"title": "Experiment setting", "content": "Robustness is calculated against adversarial examples on several networks that are trained using different methods:\nDataset: Models are trained using the MNIST and CIFAR10 datasets. Images are normalized using the default setting for DeepPoly (Singh et al., 2019a). For MNIST, the mean and standard deviation is 0.5 and 0.5, respectively. For CIFAR 10, the mean and standard deviation of the RGB channels is (0.485, 0.456, 0.406) and (0.229, 0.224, 0.225), respectively.\nArchitecture of neural networks: There are no empirical verificaion results on maxpool-based CNNs so maxpool layers are added to the common benchmark networks, convSmall, convMed and convBig in (Mirman et al., 2018). The parameter for striding and padding is adjusted to achieve a similar number of parameters to previous studies. Information about these 6 networks is shown in Table 1. The detail structures are shown in Supplementary Material A.4. Moreover, although the authors of \u03b1,\u03b2-CROWN didn't conduct experiments in maxpool-based CNNs before and they did make some additional assumptions on their maxpool layers, we would like to compare with them in maxpool-based CNNs. Hence, we also create the network benchmark convs, convm and conv for their settings.\nTraining methods: We compared the verification results of CNNs trained either normally (without adversarial training) or with adversarial examples such as Fast-Adversarial (Wong et al., 2020) and PGD (Madry et al., 2018).\nPerformance metrics: The performance of neural network verification is often evaluated through the following metrics (Singh et al., 2019a):\nVerified robustness: This is expressed as the number of images verified to be resilient to adversary example attack, divided by the total number of accurate images. This ratio represents the analysis precision of a verifier when a neural network is applied to a test image dataset that is subject to attack by an adversarial example.\nAverage verified time: This is the total time that is required by the verification algorithm to verify images, divided by the total number of images."}, {"title": "Robustness evaluation", "content": "For each test dataset, the settings for DeepPoly (Singh et al., 2019a) are used and the top 100 clean images are used as the evaluation test dataset. Adversarial examples are generated by adding to clean images with l\u221e norm-bounded perturbation for various budgets \u03f5 and various attack schemes, such as FGSM and PGD. The generated adversarial examples are then applied to the neural network to compare the accuracy of lower bounds that are evaluated using various verification methods. A better verification method must give a tighter (higher) accuracy for the lower bound and never exceeds that of existing attack schemes. The implementation details for DeepPoly, PRIMA and \u03b1,\u03b2-CROWN are described as follows:\nDeepZono and DeepPoly: We follow the implementation as suggested by the default command in their GitHub (Eth-Sri).\nPRIMA: We use exactly the same configuration mentioned in (M\u00fcller et al., 2022) for convSmall and convBig. Since PRIMA didn't report any results on convMed, and that convMed has the same number of layers as convSmall, we use the same configuration that PRIMA applied to convSmall on convMed as well.\n\u03b1,\u03b2-CROWN: We used the default parameters and set the parameter conv mode to matrix in order to enable the operation of the BaB algorithm. The examples that would trigger the BaB algorithm were considered not verified. This adjustment was made because the implementation of the BaB algorithm on maxpool-based CNNs results in excessive GPU memory requirements (more than 13GB) and extended execution times (more than 5 minutes per example)."}, {"title": "Experimental results", "content": "The results for CAPM are compared with those of previous studies (DeepZ, DeepPoly, PRIMA) in terms of the verified robustness and average runtime metrics for various adversary budgets \u03f5 for six different networks, as shown in Fig. 3 and Fig. 4. The classification accuracy 1 for a real-world PGD attack (orange solid line with triangle marker) is also determined. A verification method must demonstrate verified robustness that is no greater than the accuracy of real-world attack schemes. Fig. 3 and Fig. 4 illustrate that CAPM achieves better verification robustness than all other schemes for all combination of the CIFAR10 dataset and has a much lower computational cost. The computational cost of CAPM is independent of \u03f5, because a different adversary budget corresponds to the same dual network architecture so computational costs are similar. However, the verification time that is required by PRIMA increases as \u03f5 increases, possibly because as \u03f5 increases, the intermediate adversarial polytope becomes more complicated and must be described by a more complex MILP optimization problem. This demonstrates the promising potential of CAPM towards verification of large scale CNNs and colour images. Due to the excessive GPU memory requirements of \u03b1,\u03b2-CROWN, we did not include \u03b1,\u03b2-CROWN in this set of experiments."}, {"title": "Conclusion", "content": "This study extends Wong & Kolter (2018)'s work to general purpose CNNs with maxpool, padding, and striding operations. The key idea for handing the maxpool function is to decompose it into multiple ReLU functions, while special care is taken to speed-up the computation of element-wise bounds required for the convex relaxation of intermediate ReLUs in maxpool layer. General purpose CNNs are expressed using a dual network, which allows efficient computation of verified bounds for CNNs.\nThe experimental results show that CAPM outperforms previous methods (DeepZ, DeepPoly, and PRIMA) in terms of verified robustness and computational cost for most adversary budget settings, and especially for large-scale CNNs for color images. For an adversary budget \u03f5 = 0.0024, the verified robustness for DeepZ, DeepPoly and PRIMA for convSmall CIFAR10 decreases by to 1%, 25%, and 26%, respectively, but CAPM has a verified robustness of 87.5%; For an adversary budget \u03f5 = 0.0006 for convBig CIFAR10, CAPM is 40-times and 20-times faster than PRIMA and DeepPoly, respectively, and gives a significantly higher verified robustness (see Fig. 3 and Fig. 4).\nThe proposed method gives comparable or better verification with significantly less runtime cost. Unlike many verification methods, for which runtime increases with the adversary budget \u03f5, CAPM has a constant runtime, regardless of the adversary budget, so it can be used for larger-scale CNNs which are usually computationally prohibitive for other verification methods. The proposed verification method is suited for use with large scale CNNs, which are an important element of machine learning services.\nThis study does provide a more precise and efficient verification for maxpool-based CNNs but the verified network is limited to a specific architecture that is defined in Supplementary Material A.1.1. Future study will involve the design of a verification framework that is applicable to neural networks with a more flexible architecture.\nAdditionally, the method of simplifying certain layers into multiple ReLU layers may likely be limited to maxpool layers only. Therefore, our preliminary future direction will focus on achieving greater flexibility in maxpool-based CNNs. Subsequently, we will continue exploring more flexible neural network architectures, such as residual connections."}, {"title": "Bound analysis for intermediate layers", "content": "From Fig. 3, we observe that the accuracy lower bound predicted by each verification method becomes looser as \u03f5 increases, and such phenomenon is also present in CAPM. As bounds estimated for the previous operations will affect the later operation's bound prediction, it is crucial for us to understand how the bounds estimated in each intermediate operation (e.g., convolution, ReLU, Maxpool) differ from the actual adversarial polytopes. As such we may identify the dominant factors that loosens the accuracy lower bound as a guidance for future improvements."}, {"title": "Evaluate bound tightness by bound gap", "content": "If the real upper/lower bounds for each neuron from an arbitrary adversarial example were known, then a comparison with those real bounds would demonstrate the accuracy of the predicted bounds for each intermediate operation. The gap between the upper and lower bounds for the real and predicted bounds are compared, which is described as\ngr=ur-lr and gp=up-lp\nwhere ur and ly denote the real upper and lower bounds, and up and lp denote the predicted upper and lower bounds. The difference in the bound gap gp-gr is always non-negative and a perfectly predicted bound gives a zero bound gap difference. By reporting the real/predicted bound gaps averaged over all neurons pertaining to that operation, we can demonstrate how tight the predicted bounds are in general compared to the real bounds in each specific operation.\nIn reality, the real upper and lower bounds are not known. A Monte-Carlo simulation procedure for an adversary randomly draws a large amount of Nadu adversary examples from the adversarial polytope at the input layer following a uniform distribution. The Nadu randomly drawn adversarial examples are then fed into the network and the intermediate values for each neuron are computed. For each neuron, the maximum and minimum of the Nadv values as realized by the Nadu adversary examples are then computed as an estimate of the real upper and lower bounds."}, {"title": "Limitation on approximating adversarial polytope with Monte Carlo simulation", "content": "In the previous section we described an intuitive and easy-to-implement Monte-Carlo simulation method to estimate the real upper and lower bounds of the intermediate adversarial polytopes at each operation. Several questions naturally arise: Under what circumstances does such Monte-Carlo simulation method yield a good estimate to the real upper and lower bounds to the adversarial polytopes? Is it possible that such Monte-Carlo simulation method can even replace the optimization-theoretic robustness verification methods proposed in literature as well as in this work? To answer such questions, we consider a simple neural network consisting of only one fully-connected layer, to which the lower bound of the j-th output node subject to adversarial examples with l\u221e norm-bounded constraint is described as the following optimization problem: (The upper bound can be formulated in an analogous manner, namely by replacing ej with -ej followed by a negation.)\n$$\\min_y e_y^Tz_1$$\ns.t. z1\u2264x+\u03f5\nz1\u2265x-\u03f5\ny=WTz1+b1\nSince (49) is a convex optimization problem, its primal and dual optimums must coincide. We use the CVX tool (Cvxpy) to find the primal optimum, and apply the dual network (cf. (Wong & Kolter, 2018), also in Sec. 2.2) to find dual optimum. The primal/dual optima are then compared with the bounds that re-estimated using the Monte-Carlo simulation method in Sec. A.3.1."}, {"title": "Network structure", "content": "For the CNNs verified in Sec. 3 (namely convSmallMNIST, convMedMNIST, convBigMNIST, convSmallCIFAR10, convMedCIFAR10, and convBigCIFAR10), we add maxpool layers to the convSmall, convMed, and convBig counterparts in (Mirman et al., 2018) and slightly adjust the parameters of striding and padding to achieve similar number of parameters as in (Mirman et al., 2018). The detailed network architectures are listed below: convSmallMNIST\ninput \u2192 Conv2,1,2,1 16\u00d74\u00d74 \u2192 Conv2,1,2,1 32\u00d74\u00d74 \u2192 Flat \u2192 FC(800,100) \u2192 ReLU \u2192 FC(100,10) \u2192 output\nconvMedMNIST\ninput \u2192 Conv1,1,2,0 16\u00d72\u00d72 \u2192 Conv1,1,2,0 32\u00d72\u00d72 \u2192 Flat \u2192 FC(1568,100) \u2192 ReLU \u2192 FC(100,10) \u2192 output\nconvBigMNIST\ninput \u2192 Conv1,1,2,1 32\u00d73\u00d73 \u2192 Conv1,0,2,1 32\u00d74\u00d74 \u2192 Conv1,0,2,1 64\u00d73\u00d73 \u2192 Conv2,0,2,0 64\u00d74\u00d74 \u2192 Flat \u2192 FC(1024,512) \u2192 ReLU \u2192 FC(512,512) \u2192 ReLU \u2192 FC(512,10) \u2192 output\nconvs MNIST\ninput \u2192 Conv2,1,2,2 16\u00d74\u00d74 \u2192 Conv2,1,2,2 32\u00d74\u00d74 \u2192 Flat \u2192 FC(32,24) \u2192 ReLU \u2192 FC(24,10) \u2192 output\nconvm MNIST\ninput \u2192 Conv2,1,2,2 16\u00d74\u00d74 \u2192 Conv2,1,2,2 32\u00d74\u00d74 \u2192 Conv1,1,2,2 64\u00d72\u00d72 \u2192 Flat \u2192 FC(64,32) \u2192 ReLU \u2192 FC(32,10) \u2192 output\nCONVL MNIST\ninput \u2192 Conv1,1,2,2 32\u00d72\u00d72 \u2192 Conv1,1,2,2 64\u00d72\u00d72 \u2192 Conv1,1,2,2 128\u00d72\u00d72 \u2192 Flat \u2192 FC(2048,256) \u2192 ReLU \u2192 FC(256,10) \u2192 output\nconvSmallCIFAR10\ninput \u2192 Conv2,1,2,1 16\u00d74\u00d74 \u2192 Conv2,1,2,1 32\u00d74\u00d74 \u2192 Flat \u2192 FC(1152,100) \u2192 ReLU \u2192 FC(100,10) \u2192 output\nconvMedCIFAR10\ninput \u2192 Conv1,1,2,0 16\u00d72\u00d72 \u2192 Conv1,1,2,0 32\u00d72\u00d72 \u2192 Flat \u2192 FC(2048,100) \u2192 ReLU \u2192 FC(100,10) \u2192 output\nconvBigCIFAR10\ninput \u2192 Conv1,1,2,1 32\u00d73\u00d73 \u2192 Conv1,1,2,0 32\u00d74\u00d74 \u2192 Conv1,0,2,1 64\u00d73\u00d73 \u2192 Conv2,0,2,1 64\u00d74\u00d74 \u2192 Flat \u2192 FC(4096,512) \u2192 ReLU \u2192 FC(512,512) \u2192 ReLU \u2192 FC(512,10) \u2192 output Here Convs,p,k,t C\u00d7W\u00d7H represents a convolution layer consisting of a convolution operation followed by ReLU and maxpool with kernel size kxk and stride t, where the convolution operation consists of C convolution kernels each of width W and height H along with stride s and padding p; FC(M,N) represents a fully-connected layer with M input neurons and N output neurons We use open source repo provided in (Wong et al., 2020) for adversarial training and slightly modify its default parameters to fit our models. Specifically, the hyperparameters we used are illustrated in Table 6."}, {"title": "Reproducing the state-of-the-art method", "content": "As there were no reported empirical verification performance on maxpool-based CNNs, it is necessary to correctly reproduce and test the state-of-the-art methods on maxpool-based CNNs such as the models described in Sec. 1.1. We reproduce DeepPoly and DeepZ on the neural networks (which includes convolution and ReLU but without maxpool) following the settings in (Singh et al., 2019a; 2018) with the implementation provided in (Eth-Sri). Fig. A.5 indicates that the reproduced result is highly consistent with the reported results in (Singh et al., 2019a).\nPRIMA is reproduced using a pretrained model from (Eth-Sri). Table 7 shows the reproduced results for verified robustness for the first 10"}]}