{"title": "EMPHASIZING DISCRIMINATIVE FEATURES FOR DATASET DISTILLATION IN COMPLEX SCENARIOS", "authors": ["Kai Wang", "Zekai Li", "Zhi-Qi Cheng", "Samir Khaki", "Ahmad Sajedi", "Ramakrishna Vedantam", "Konstantinos N Plataniotis", "Alexander Hauptmann", "Yang You"], "abstract": "Dataset distillation has demonstrated strong performance on simple datasets like CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in more complex scenarios. In this paper, we propose EDF (emphasizes the discriminative features), a dataset distillation method that enhances key discriminative regions in synthetic images using Grad-CAM activation maps. Our approach is inspired by a key observation: in simple datasets, high-activation areas typically occupy most of the image, whereas in complex scenarios, the size of these areas is much smaller. Unlike previous methods that treat all pixels equally when synthesizing images, EDF uses Grad-CAM activation maps to enhance high-activation areas. From a supervision perspective, we downplay supervision signals that have lower losses, as they contain common patterns. Additionally, to help the DD community better explore complex scenarios, we build the Complex Dataset Distillation (Comp-DD) benchmark by meticulously selecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In particular, EDF consistently outperforms SOTA results in complex scenarios, such as ImageNet-1K subsets. Hopefully, more researchers will be inspired and encouraged to improve the practicality and efficacy of DD. Our code and benchmark will be made public at NUS-HPC-AI-Lab/EDF.", "sections": [{"title": "1 INTRODUCTION", "content": "Dataset Distillation (DD) has been making remarkable progress since it was first proposed by Wang et al. (2020). Currently, the mainstream of DD is matching-based methods (Zhao et al., 2021; Zhao &"}, {"title": "2 METHOD", "content": "Our approach, Emphasize Discriminative Features (EDF), enhances discriminative features in synthetic images during distillation. As shown in Figure 3, EDF first trains trajectories on real images T and synthetic images S and computes the trajectory matching loss. Then, Common Pattern Dropout filters out low-loss supervision signals, retaining high-loss ones for backpropagation. After obtaining gradients for the synthetic images, Discriminative Area Enhancement uses dynamically extracted Grad-CAM activation maps to rescale pixel gradients, focusing updates on discriminative regions."}, {"title": "2.1 \u0421\u043e\u043cMON PATTERN DROPOUT", "content": "This module reduces common patterns in supervision by matching expert and student trajectories on real and synthetic data, then removing low-loss elements. This ensures only meaningful supervision enhances the model's ability to capture discriminative features."}, {"title": "Trajectory Generation and Loss Computation.", "content": "To generate expert and student trajectories, we first train agent models on real data for E epochs, saving the resulting parameters as expert trajectories, denoted by {\u03b8t}t=0F. At each distillation iteration, we randomly select an initial point \u03b8t and a target point \u03b8t+M from these expert trajectories. Similarly, student trajectories are produced by initializing an agent model at \u03b8t and training it on the synthetic dataset, yielding the parameters {\u03b8t}t=0N. The"}, {"title": "Low-loss Element Dropping.", "content": "Our analyses of Figure 2a and 2b show that low-loss signals typically correspond to common patterns, which hinder the learning of key discriminative features, particularly in complex scenarios. To address this, we sort the array of losses computed from the previous step in ascending order. Using a predefined dropout ratio \u03b1, we discard the smallest \u230a\u03b1\u22c5P\u230b losses (\u230a\u230b denotes the floor function), which are assumed to capture common, non-discriminative features. The remaining losses are summed and normalized to form the final supervision:"}, {"title": "2.2 DISCRIMINATIVE AREA ENHANCEMENT", "content": "After the pruned loss from Common Pattern Dropout is backpropagated, this module amplifies the importance of discriminative regions in synthetic images. Grad-CAM activation maps are dynamically extracted from the synthetic data to highlight areas most relevant for classification. These activation maps are then used to rescale the pixel gradients, applying a weighted update that prioritizes highly activated regions, thereby focusing the learning process on key discriminative features."}, {"title": "Activation Map Extraction.", "content": "Grad-CAM generates class-specific activation maps by leveraging the gradients that flow into the final convolutional layer, highlighting key areas relevant for predicting a target class. To compute these maps, we first train a convolutional model G on the real dataset. Following the Grad-CAM formulation (Equation 3), we calculate the activation map for each class c: Mc \u2208 RIpc\u00d7H\u00d7W on the synthetic images (Ipc is the number of images per class). The activation map Mc is a gradient-weighted sum of feature maps across all convolutional layers:"}, {"title": "Discriminative Area Biased Update.", "content": "A major limitation of previous DD algorithms (Cazenavette et al., 2022; Du et al., 2022; Guo et al., 2024) on the complex scenario is that they treat each pixel equally and provide no guidance for the distillation process on which area of synthetic images should be emphasized. Therefore, we propose to update synthetic images in a biased manner. Instead of treating each pixel equally, we enhance the significance of discriminative areas by guiding the optimization with activation maps extracted in the previous step. We define the discriminative area of a synthetic image as the percentage of pixels with activation values above the mean since synthetic images are dynamically changing (see Section 4.3 for discussion). Specifically, we process activation maps from the previous step with a function F(M, \u03b2) to create weights for pixel gradients as follows:"}, {"title": "3 COMPLEX DD BENCHMARK", "content": "We introduce the Complex Dataset Distillation (Comp-DD) benchmark, which is constructed by selecting subsets from ImageNet-1K based on their complexity. This benchmark represents an early and pioneering effort to address dataset distillation in complex scenarios. Although there are numerous benchmarks (Krizhevsky, 2009; Le & Yang, 2015; Cui et al., 2022b) for simpler tasks, there is a notable absence of benchmarks designed specifically for complex scenarios. This gap presents a significant challenge to advancing research in this area and limits the practical application of dataset distillation. To bridge this gap, we propose the first dataset distillation benchmark explicitly built around scenario complexity, aiming to promote further exploration within the DD community."}, {"title": "Complexity Metrics.", "content": "We evaluate the complexity of an image by measuring the average size of high-activation regions of the Grad-CAM activation map. Using a pre-trained ResNet model, we first generate Grad-CAM activation maps for all images, class by class. For each image, we calculate the percentage of pixels with activation values above a predefined threshold (set to 0.5 in our case), with higher percentages indicating lower complexity (more clarifications can be found in Appendix D.2)."}, {"title": "Subset Selection.", "content": "To reduce the influence of class differences, we select subsets from each category, where a category consists of classes representing visually similar objects or animals of the same species. This approach allows us to focus on complexity while controlling for inter-class variability."}, {"title": "4 EXPERIMENT", "content": "4.1 EXPERIMENTAL SETUP"}, {"title": "Datasets and Architecture.", "content": "We conduct a comprehensive evaluation of EDF on six ten-class subsets (Howard, 2019) of ImageNet-1K (ImageNette, ImageWoof, ImageMeow, ImageYellow, ImageFruit, and ImageSquawk) and a one-hundred-class subset (ImageNet100). Each subset contains ten classes, with approximately 13,000 images in the training set and 500 images in the validation set. On the Comp-DD benchmark, we report the results of the Bird, Car, and Dog categories. For all experiments, we use a 5-layer ConvNet (ConvNetD5) as both the distillation and the evaluation architecture. For cross-architecture evaluation (see results in Appendix C.1), we validate synthetic data accuracy on Alexnet (Krizhevsky et al., 2012), VGG11 (Simonyan & Zisserman, 2014), and ResNet18 (He et al., 2015)."}, {"title": "Baselines.", "content": "We compare two baselines: dataset distillation (DD) methods and methods utilizing knowledge distillation (Eval. w/ Knowledge Distillation) (Hinton et al., 2015). For DD methods, we include trajectory-matching-based methods such as MTT (Cazenavette et al., 2022), FTD (Du et al., 2022), and DATM (Guo et al., 2024). In the knowledge distillation group, we compare against SRe2L (Yin et al., 2023) and RDED (Sun et al., 2023). The results for subsets not covered in these papers are obtained through replication using the official open-source codebases and hyperparameters."}, {"title": "4.2 MAIN RESULTS", "content": "ImageNet-1K Subsets. We mainly conduct extensive experiments on various ImageNet-1K sub-sets and compare the performance of EDF with other different approaches. The detailed re-sults are shown in Table 1. EDF consistently achieves state-of-the-art (SOTA) results across all settings when compared to other dataset distillation methods. On larger IPCs, i.e., 200 or 300, the performance of EDF significantly outperforms that observed with smaller IPCs.We achieve lossless performances on ImageMeowand ImageYellow under IPC300, 23% of real data,as shown in Table 2. When evaluated against Eval.w/ Knowledge Distillation methods, our distilleddatasets outperform SRe2L and RDED in 14 out of 18settings. It is important to note that applying knowl-edge distillation (KD) for evaluation tends to reduceEDF's pure dataset distillation performance, partic-ularly in low IPC (images per class) settings such asIPC1 and IPC10. This occurs because smaller IPCSlack the capacity to effectively incorporate the knowledge from a well-trained teacher model. Wealso provide results without knowledge distillation in Appendix C.2."}, {"title": "Comp-DD Benchmark.", "content": "The results for EDF on the Bird, Car, and Dog categories from the Comp-DD Benchmark are shown in Table 3. EDF demonstrates superior test accuracies and recovery ratios across both easy and hard subsets. As expected, the recovery ratios for easy subsets are consistently higher than those for hard subsets, confirming that the hard subsets present a greater challenge for dataset distillation methods. These results validate our complexity metrics, which effectively distinguish the varying levels of difficulty between easy and hard subsets."}, {"title": "4.3 ABLATION STUDY", "content": "We conduct an ablation study to evaluate the impact of EDF's key components, including the supervision dropout ratio, strategies for discriminative area enhancement, and the frequency of activation map updates. Unless otherwise specified, the following results are all based on ConvNetD5."}, {"title": "Effect of Modules.", "content": "EDF introduces two key modules: Discriminative Area Enhancement (DAE) and Common Pattern Dropout (CPD). We conduct an ablation study to assess the contribution of each module independently. The results, presented in Table 4, demonstrate that both DAE and CPD significantly improve the baseline performance. DAE's biased updates toward high-activation areas using activation-based gradient weights effectively enhance the discriminative features in synthetic images. CPD, on the other hand, mitigates the negative influence of common patterns by filtering out low-loss supervision, ensuring that the synthetic images retain their discriminative properties."}, {"title": "Supervision Dropout Ratio.", "content": "The dropout ratio in CPD is critical for balancing the removal of common patterns and dataset capacity (IPC). As shown in Table 5a, smaller IPCs benefit most from moderate dropout ratios (12.5-25%), which filter low-loss signals while preserving important information. For larger IPCs, higher dropout ratios (37.5-50%) improve performance, as these datasets can tolerate more aggressive filtering. However, an excessively high ratio (e.g., 75%) reduces performance across all IPCs by discarding too much information, weakening the ability to learn."}, {"title": "Frequency of Activation Map Update.", "content": "To accurately capture the evolving discriminative features in synthetic images, EDF dynamically updates the Grad-CAM activation maps at a predefined frequency. The choice of update frequency should be adjusted based on the IPC to achieve optimal performance. As shown in Table 5b, larger IPCs benefit from a lower update frequency, as the pixel learning rate is set lower for more stable distillation. In contrast, smaller IPCs require a higher update frequency to effectively adapt to the faster changes in the synthetic images during training."}, {"title": "Strategies for Discriminative Area Enhancement.", "content": "The Discriminative Area Enhancement (DAE) component involves two key factors: the enhancement factor \u03b2 and the threshold for activation maps. Ablation studies (Table 6a) show that the best performance is achieved when \u03b2 is between 1 and 2. When \u03b2 < 1, some discriminative areas are diminished rather than enhanced, as their gradient weights become < 1. Conversely, excessively large \u03b2 values (\u2265 10) lead to overemphasis on certain areas, distorting the overall learning process (see Appendix C.3 for examples of this distortion). Therefore, \u03b2 should be reasonably controlled to balance the emphasis on discriminative regions."}, {"title": "5 ANALYSIS AND DISCUSSION", "content": "Disitlled Images of Different Supervision. As pointed out earlier, low-loss supervision tends to introduce common patterns, such as backgrounds and general colors, while high-loss supervision"}, {"title": "Supervision Dropout Criteria.", "content": "To assess the effectiveness of supervision dropout strategies, we compare several dropout approaches. These strategies are classified into two categories: (i) dynamic dropout, which includes random selection from all layers, and (ii) static dropout, which includes uniform selection across layers and fixed selection from the first, middle, or last layers. As shown in Table 7, all strategies except EDF's loss-based dropout lead to performance degradation, with uniform selection and last-layer dropout causing the most significant performance loss."}, {"title": "6 RELATED WORK", "content": "Approaches. Dataset Distillation (DD) aims to create compact datasets that maintain performance levels comparable to full-scale datasets. It can be applied in practical fields such as continual learning (Masarczyk & Tautkute, 2020; Rosasco et al., 2021), privacy preservation (Dong et al., 2022; Yu et al., 2023), and neural architecture search (Jin et al., 2018; Pasunuru & Bansal, 2019). Approaches in DD can be categorized into two primary approaches: matching-based and knowledge-distillation-based."}, {"title": "Benchmarks.", "content": "DD research has mainly focused on simpler datasets such as CIFAR (Krizhevsky, 2009), TinyImageNet (Le & Yang, 2015), and DC-BENCH (Cui et al., 2022b). These datasets contain a high proportion of class-specific information, enabling DD methods to extract and synthesize dis-criminative features more easily. However, research in more complex scenarios has been limited. To address this, we propose the Comp-DD benchmark, which systematically explores dataset distillation complexity by curating subsets from ImageNet-1K with varying degrees of difficulty. This benchmark provides a more rigorous evaluation framework, facilitating deeper exploration of DD in complex, real-world settings and encouraging further advances in the field."}, {"title": "7 CONCLUSION", "content": "We introduced Emphasize Discriminative Features (EDF), a dataset distillation method that enhances class-specific regions in synthetic images. EDF addresses two key limitations of prior methods:"}]}