{"title": "RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals", "authors": ["Yuyang Miao", "Zehua Chen", "Chang Li", "Danilo Mandic"], "abstract": "Respiratory rate (RR) is a critical health indicator often monitored under inconvenient scenarios, limiting its practicality for continuous monitoring. Photoplethysmography (PPG) sensors, increasingly integrated into wearable devices, offer a chance to continuously estimate RR in a portable manner. In this paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model for respiratory waveform estimation from PPG signals. RespDiff does not require hand-crafted features or the exclusion of low-quality signal segments, making it suitable for real-world scenarios. The model employs multi-scale encoders, to extract features at different resolutions, and a bidirectional RNN to process PPG signals and extract respiratory waveform. Additionally, a spectral loss term is introduced to optimize the model further. Experiments conducted on the BIDMC dataset demonstrate that RespDiff outperforms notable previous works, achieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while others range from 1.66 to 2.15 bpm, showing its potential for robust and accurate respiratory monitoring in real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "Respiratory waveform monitoring is vital in clinical as it is important to indicate the health condition of patients. Respiratory rate (RR) is informative to several fatal diseases within the respiratory and cardiovascular systems [1], [2]. Hence, the methods to accurately measure RR in a convenient manner are gaining increasing attention\nUsually, respiratory signal is measured with methods such as impedance pneumography, capnography and spirometry. However, these methods require bulky machines, which are not portable and restrict the scenarios for measuring RR. Furthermore, in clinical settings, manually counting is still considered the primary technique to estimate respiratory rates. This is inconvenient for the widespread respiratory rate estimation. Thus, there is a need to extract respiratory rates or estimate respiratory waveform in a convenient and human-labour-free manner. Meanwhile, Photoplethysmography (PPG) signals have gained broad interest and have been widely integrated into wearable devices recently. PPG sensor measures the blood volume change in the microvascular bed of tissue. The PPG signals are modulated by the respiratory signals, including frequency, amplitude and baseline modulations [3]. Then it will be beneficial to extract respiratory information from PPG signals, utilizing the portable nature of PPG sensors leading to continuous and portable RR estimation.\nHowever, previous works show limited performance in RR estimation using deterministic mapping methods and hand-crafted features. Meanwhile diffusion model has gained tremendous interest recently due to its powerful iteratively optimizing ability [4]. The diffusion model has shown its prominent performance in various domains, including speech generation [5], [6], time series generation [7]\u2013[9], time series imputation [10] and biomedical signal denoising [11]. Thus we leverage the diffusion model and introduce the diffusion model to the respiratory waveform estimation task for the first time. We also propose multi-scale encoders under the assumption that the modulation of breathing activities on PPG signals scatters over different frequency ranges. Besides, we aid the optimization of the diffusion model by adding a spectral loss term, directly measuring the sampling quality in the frequency domain. With the diffusion model's strong modelling capacity, we utilize the whole dataset without deleting signal segments due to low signal quality, which better mimics real-world scenarios.\nIn summary, we propose RespDiff, an end-to-end multi-scaled RNN based diffusion model giving the key contributions"}, {"title": "II. RELATED WORKS", "content": "Various works have been proposed to estimate RR from PPG signals. Dong et al. first applied classical signal processing techniques to extract multiple respiratory waveforms and remove trials with low signal quality indexes. Then they fused the extracted signals using sequence processing deep learning algorithms [13]. Iqbal et al. removed low-quality signals and combined preprocessing, filtering and postprocessing techniques to give the final RR estimation [14]. Osathitporn et al. proposed RRWaveNet, a U-net structure Network with Convolutional Neural Networks (CNN) layers as encoders and decoders. The proposed RRWaveNet works on a processed dataset with low signal quality segments deleted to give the final RR estimation [15]. Aqajari et al. reformulated the respiratory waveform generation task as a conditional generation task and chose cycle GAN as the generation model [16]."}, {"title": "III. METHODS", "content": "In this work, we have introduced a conditional diffusion model to the task of respiratory waveform estimation task. Under the backbone of the bidirectional RNN model, we propose novel multi-scale encoders which help extract features at different resolutions. Also, in addition to the diffusion loss in the distribution domain, we bring in a spectral loss term, optimizing the model regarding of signal quality in the frequency domain."}, {"title": "A. Conditional Diffusion Models", "content": "Conditional diffusion models are composed of two processes: a forward process to corrupt the clean data to a known prior distribution, e.g., standard Gaussian noise, and a reverse process to iteratively recover the data distribution from the prior under the guidance of condition information.\nIn this work, given respiratory waveform $y \\in R^L$ and corresponding PPG signal $x_{ppg} \\in R^L$, we develop a waveform-domain diffusion model to generate $y$ conditioned on $x_{PPG}$. In the forward process, we progressively corrupt the clean respiratory waveform $y_0$ into a standard Gaussian noise $y_T \\sim N(0, I)$ with a predefined noise schedule $0 < \\beta_1 < \\beta_2 < ... < \\beta_{T-1} < \\beta_T < 1$, where the transition probability can be written as:\n$q(y_t | y_{t-1}) = N(y_t; \\sqrt{1 - \\beta_t}y_{t-1}, \\beta_tI)$.\nWith the property of isotropic Gaussian noise, we can efficiently calculate the noisy representation at time step $t$ with:\n$q(y_t | y_0) = N(y_t; \\sqrt{\\bar{a}_t}y_0, (1 - \\bar{a}_t)\\epsilon)$,\nwhere $a_t = 1 - \\beta_t$ and $\\bar{a}_t = \\prod_{s=1}^{t} a_s$ indicate noise level and $\\epsilon \\sim N(0, I)$ denotes the Gaussian noise injected to corrupt the clean signal $y_0$.\nIn reverse process, we start the denoising process from $y_T \\sim N(0, I)$, and gradually removes the noise added to the clean signal $y_0$ at each time step:\n$p_\\theta(y_{0:T}) = p(y_T) \\prod_{t=1}^{T} p_\\theta(y_{t-1} | y_t, x_{ppg})$.\nThe training objective of diffusion models is to maximize the variation lower bound (ELBO) of the likelihood of $p_\\theta(y_0)$ [4]. In practice, we adopt a re-weighted loss function from previous works [4], [17], [18] as follows:\n$L_{diff}(\\theta) = E_{y_0,\\epsilon,t} ||\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{a}_t}y_0 + \\sqrt{1 - \\bar{a}_t}\\epsilon, t, x_{ppg}) ||^2$.\nIn bio-electrical signal processing, several previous works have established strong diffusion baselines for EMG synthesis [19] and denoising [11], EEG imagine speech decoding [20], and ECG imputation and forecasting [21], [22]. However, none of the previous studies explored the performance of diffusion models for respiratory waveform, which is a vital sign of health conditions in clinical."}, {"title": "B. Network Architecture", "content": "1) Multi-scale fine-grained feature encoder: CNN is known for its powerful potential in feature extraction. The size of the kernel of CNN decides the spatial resolution of the extracted features. It is considered to be difficult to carefully design kernel sizes without any prior knowledge. To cope with this challenge, we propose the encoder $E_{fine}$ which aims to extract characteristics from PPG at multiple scales. The $E_{fine}$ is composed of a stack of K convolutional layers with varying resolution sizes. Multi-scale fine-grained feature extractor can be formulated as:\n$E_{fine}(x) = Concat_{k=1}^{K} (Conv1D(x, kernel \\text{ size } = k_i))$.\n2) Multi-scale coarse-grained feature encoder: Breathing activities can generate slow-varying components in PPG signals, such as baseline modulation. Even a large kernel size is hard to capture such information. Thus we need feature extraction methods with large receptive fields. We propose the dilated multi-scale encoder $E_{coarse}$, which aims to capture coarse-grained spatial features from the PPG signal and uses a similar multi-resolution design with $E_{fine}$ with N layers. However, the convolutional layer is replaced by dilated convolutions $DilConv1D(:, k_i)$, which significantly helps increasing the receptive field:\n$E_{coarse}(x) = Concat_{k=1}^{K} (DilConv1D(x, kernel \\text{ size } = k_i))$.\n3) Bidirectional RNN: During the respiratory estimation process, the beginning of the sequence usually suffers from bad quality due to the lack of context before it. Thus, we utilize bidirectional RNN, which leverages both past and future context to improve the quality of predictions even at the beginning of the sequence. To make better use of the information in the input signal, firstly, the multi-scale PPG feature $f_{ppg}$ with feature fusion ratio $A_{ppg}$ can be formulated as:\n$f_{ppg} = E_{fine}(x_{ppg}) + A_{ppg}E_{corase}(x_{ppg})$.\nThe bidirectional RNN processes the input feature $f_{ppg}$ and aims to estimate the noise illustrated in 4. Through training, the timestep for the diffusion process is uniformly sampled with $t \\sim U(0, 1)$. Instead of directly sending the noised input"}, {"title": "C. Spectral Loss", "content": "The training objective of diffusion models shown in (4) is to faithfully recover the data distribution from the prior distribution, while it may not guarantee the optimal sample quality in RR estimation. Hence, to strengthen the sample quality of our proposed RespDiff, we further investigate the function of auxiliary loss functions which highlights the RR information in synthesized respiratory signals. Specifically, we introduce a spectral loss into the original training objective of diffusion models. At each training iteration, given the noisy representation $y_t$, the network predicts the added noise $\\epsilon_t$ and then we can estimate a coarse respiratory waveform $y_0$ with a single step:\n$\\hat{y}_0 = \\frac{1}{\\sqrt{\\bar{a}_t}} (y_t - \\sqrt{1 - \\bar{a}_t}\\epsilon_t)$.\nThen, we apply the Fourier transform magnitude extractor $Fft$ to both estimated $\\hat{y}_0$ and the ground-truth signal $y_0$, and calculate a distance between them with:\n$L_{spec} = \\frac{1}{N} \\sum_{i=1}^{N} ||F(\\hat{y}_0) - F(y_0)||^2$,\nwhere N is the number of frequency bins. Hence, during the training process, we employ both the diffusion loss shown in (4) and a weighted $L_{spec}$, where the weight $\\lambda_{spec}$ is set as 0.01 in our experiments. In inference, at each sampling step, the generation of diffusion models has been strengthened by our proposed auxiliary loss, leading to a final improvement in RR estimation after iterative sampling steps."}, {"title": "IV. EXPERIMENTS", "content": "Our conduct experiments on the BIDMC dataset [12], a widely-used benchmark dataset containing 53 recordings of ECG, PPG, and impedance pneumography signals, each of which has a length of 8 minutes. The PPG signal and respiratory waveform are first downsampled to 30Hz since the breathing activity predominantly happens in the low frequency domain. Then, the breathing and PPG signals are further low-pass filtered with a cutoff frequency of 1Hz, segmented into lengths of 5 seconds, and normalized to a range of [-1, 1] and [0, 1] respectively. To mimic the real-world scenarios, we retain each processed sample, rather than deleting low-quality ones [14], [15]. Leave-one-subject-out method is chosen as the training scheme for a comprehensive evaluation.\nAt the inference stage, we employ both DDPM [4] and DDIM [23] sampler to generate 5-second samples and concatenate the samples to obtain 8-minute results. RR estimation"}, {"title": "B. Results Analysis", "content": "As shown in table I, we compare our works with three previous works, where our RespDiff outperforms other methods in RR estimation by a large margin. Especially, compared with RRWaveNet [15] and the work from Iqbal et al. [14] which only estimate RR, our work generates the whole respiratory waveform. We perform a more complex task but achieve stronger performance. Moreover, our end-to-end network does not require laborious task-specific tuning, e.g., the threshold selection process required by the baseline Iqbal et al. [14].\nAlso, our work utilizes the whole dataset without removing any segments. This approach better mimics the real-world scenario, where a clean recording environment is not a guarantee. The waveform MAE estimation results for RespDiff with and without spectral loss are 0.307 and 0.316. All mentioned works did not mention waveform estimation loss."}, {"title": "C. Ablation Study on Spectral Loss", "content": "We test the function of our proposed spectral loss under diverse inference processes of diffusion models, i.e., numerous-step sampling and few-step sampling. As shown in Table II, in 50-step synthesis, the RR estimation error has distinctively decreased because of spectral loss. When reducing the number of sampling steps to 6, our proposed spectral loss still plays an important role in improving RR estimation accuracy. Notably, the spectral loss makes 6-step sampling outperform the 50-step RespDiff without this auxiliary loss, considerably improving the inference speed of RespDiff. In our observation, with 6 inference steps, RespDiff could generate an 8-minute respiratory waveform in 7 seconds. Figure 2 gives an example of respiratory waveform estimation under different settings. It is manifest that when the spectral loss is not employed, the estimated respiratory waveform gives the wrong RR by generating one more peak indicated by grey shades."}, {"title": "D. Ablation Study on Multi-Scale Encoder", "content": "To further justify the idea of applying a multi-scale encoder to extract features with different spatial resolutions. We set"}, {"title": "V. CONCLUSION", "content": "In this work, we have introduced RespDiff, a novel multi-scale diffusion model designed for the challenging task of respiratory waveform estimation from PPG signals. Our model leverages a bidirectional RNN as its backbone, coupled with multi-scale encoders that effectively capture features across various temporal resolutions. RespDiff has demonstrated promising results, outperforming several recent approaches in terms of both respiratory rate (RR) estimation and waveform reconstruction accuracy.\nFurthermore, we have empirically shown that incorporating a spectral loss term significantly enhances the model's RR estimation capabilities, regardless of whether DDPM or DDIM sampling is employed. This highlights the importance of considering both time-domain and frequency-domain information for accurate RR estimation.\nTo the best of our knowledge, this is the first application of diffusion models to the problem of respiratory waveform estimation from PPG signals. Our results underscore the powerful modelling capacity of diffusion models in this new domain, opening up exciting possibilities for future research."}]}