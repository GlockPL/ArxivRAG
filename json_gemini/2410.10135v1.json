{"title": "FORMALALIGN: AUTOMATED ALIGNMENT EVALUATION FOR AUTOFORMALIZATION", "authors": ["Jianqiao Lu", "Yingjia Wan", "Yinya Huang", "Jing Xiong", "Zhengying Liu", "Zhijiang Guo"], "abstract": "Autoformalization aims to convert informal mathematical proofs into machine-verifiable formats, bridging the gap between natural and formal languages. However, ensuring semantic alignment between the informal and formalized statements remains challenging. Existing approaches heavily rely on manual verification, hindering scalability. To address this, we introduce FORMALALIGN, the first automated framework designed for evaluating the alignment between natural and formal languages in autoformalization. FORMALALIGN trains on both the autoformalization sequence generation task and the representational alignment between input and output, employing a dual loss that combines a pair of mutually enhancing autoformalization and alignment tasks. Evaluated across four benchmarks augmented by our proposed misalignment strategies, FORMALALIGN demonstrates superior performance. In our experiments, FORMALALIGN outperforms GPT-4, achieving an Alignment-Selection Score 11.58% higher on FormL4-Basic (99.21% vs. 88.91%) and 3.19% higher on MiniF2F-Valid (66.39% vs. 64.34%). This effective alignment evaluation significantly reduces the need for manual verification. Both the dataset and code can be accessed via https://github.com/rookie-joe/FormalAlign.", "sections": [{"title": "1 INTRODUCTION", "content": "Autoformalization is the task of automatically converting informal theorems and proofs into machine-verifiable formats (Wang et al., 2018; Szegedy, 2020; Wu et al., 2022; Jiang et al., 2023c). It bridges the gap between natural and formal languages, leveraging the strengths of both: natural language carries extensive logical reasoning and human knowledge. while formal language enables rigorous verification and proof (Kaliszyk et al., 2014). While promising, autoformalization faces challenges in ensuring semantic alignment between these languages. The availability of fully formalized and computer-checked content is limited (Kaliszyk et al., 2017). This lack of alignment information hinders the development of robust autoformalization models (Bansal & Szegedy, 2020).\nCurrent evaluation for autoformalization (Jiang et al., 2023c; Huang et al., 2024) focus solely on logical validity, which can be easily verified by formal language compilers (e.g., the Lean 4 compiler\u00b9). Another direct but suboptimal evaluation resort to surface form matching via BLEU (Papineni et al., 2002), which is widely used by recent works (Wu et al., 2022; Jiang et al., 2023c; Azerbayev et al., 2023a), but struggles with semantic alignment or logical equivalence (Li et al., 2024).\nTake the case in Figure 1 as an example, to correctly translate the natural language proof target into a Lean 4 statement, first, the variables for the objects \"ligs\", \"lags\", and \"lugs\" should be included and real numbers greater than zero. Then, the two equations should be translated into two corresponding hypotheses h\u2081 and h2. Finally, the proof target \u201cHow many ligs are equivalent to 80 lugs? Show that 63\" needs to be formalized into \u201c63 * a = 80 * c", "ligs\u201d. However, because the incorrectly translated \u201c80 * c = 63": "s logically valid in Lean 4 and similar to the ground truth in surface form, it is flawless to a theorem compiler or the BLEU score. The semantic misalignment of lacking a \u201clig\u201d in the equation is undetected. Moreover, due to its elusive nature, this misalignment is often challenging to detect, even with methods like BERTscore (Zhang et al., 2020b), which are designed to assess semantic similarity, Therefore, a robust and effective approach to Automated Alignment Evaluation (AAE) is urgently needed.\nTo bridge this gap, we introduce the FORMALALIGN framework, which assesses the alignment between informal and formal languages during autoformalization. As demonstrated in Figure 2, FORMALALIGN learns both the sequence generation task of autoformalization (top half in Figure 2) and the representational alignment (bottom half in Figure 2) between input and output. FORMALALIGN jointly trains the pair of mutually enhancing tasks. This encourages the model to generate similar embeddings for corresponding pairs and distinct embeddings for non-corresponding pairs, enhancing its ability to differentiate between aligned and misaligned sequences, as the case in Figure 1.\nWe evaluate FORMALALIGN on four benchmarks sourced from MiniF2F (Zheng et al., 2022b) and FormL4 (Lu et al., 2024b). Compared with GPT-4, FORMALALIGN achieves a substantially higher precision score across these datasets, e.g., in the FormL4-Basic dataset (93.65% vs. 26.33%). It also outperforms GPT-4 in alignment-selection score across multiple datasets, including a remarkable 99.21% vs. 88.91% in FormL4-Basic and 66.39% vs. 64.34% in MiniF2F-Valid. Extensive experimental results demonstrate the effectiveness of FORMALALIGN, significantly reducing the reliance on manual verification. Our contributions are summarized as follows:\n\u2022 To the best of our knowledge, we design the first method for automatically evaluating alignment in autoformalization, reducing the reliance on manual verification.\n\u2022 We develop a combined loss framework that simultaneously enhances a model for both autoformalization and semantic alignment.\n\u2022 Extensive experiments on established autoformalization benchmarks demonstrate the effectiveness and robustness of FORMALALIGN."}, {"title": "2 RELATED WORK", "content": "Autoformalization with LLMs Early efforts (Wang et al., 2018; Bansal & Szegedy, 2020) employed encoder-decoder neural networks to translate informal statements into formal languages like Mizar (Rudnicki, 1992), HOL Light (Harrison, 1996), and Coq (Barras et al., 1997). The advent of LLMs (Chen et al., 2021; Chowdhery et al., 2022; Lewkowycz et al., 2022; Achiam et al., 2023)"}, {"title": "3 METHOD: FORMALALIGN", "content": "The FORMALALIGN framework trains an LLM that can evaluate the alignment between natural (informal) and formal languages during autoformalization. As illustrated in Figure 2, FORMALALIGN combines two types of loss in the training process: one for the sequence generation task of autoformalization and another for the representational alignment between input and output. This dual loss framework mutually enhances autoformalization and alignment.\n3.1 NOTATIONS\nWe first define the notations as follows:\nNL : The ith informal input sequence in a batch, NL\u1d62 = (NL\u1d62,\u2081, NL\u1d62,\u2082,..., NL\u1d62,\u2098), where m is the sequence length of NL\u1d62\nFL: The ith ground-truth formal output sequence in a batch, FL\u1d62 = (FL\u1d62,\u2081, FL\u1d62,\u2082,..., FL\u1d62,\u2099), where n is the sequence length of FL\u1d62\nP\u00f8(FL\u1d62,\u2c7c|FL\u1d62,<\u2c7c, NL\u1d62) : The probability of predicting the jth token in the formal sequence FL\u1d62 by the auto-regressive language model with parameters \u00f8, given the previous tokens FL\u1d62,<\u2c7c in the formal sequence and the informal input NL\u1d62.\nZ\u00f8(NL\u1d62): The hidden state from the auto-regressive language model with parameters \u00f8 for the final position in the ith informal input NL\u1d62, i.e., NL\u1d62,\u2098.\nZ\u00f8(FL\u1d62|NL\u1d62): The hidden state from the auto-regressive language model with parameters \u00f8 for the final position in the ith ground-truth formal output FL\u1d62, i.e., FL\u1d62,\u2099, conditioned on the paired ith informal input NL\u1d62.\nZ\u00f8(FL\u1d62\u2032|NL\u1d62) : The hidden state from the auto-regressive language model with parameters \u00f8 for the final position in the (i')th unpaired formal output FL\u1d62\u2032, in a batch, conditioned on the ith informal input NL\u1d62.\ncos(x,y): The cosine similarity between embeddings, defined as cos(x, y) = \\frac{xy}{||x|| \\cdot ||y||} .\nN: The batch size.\n3.2 TRAINING\nAutoformalization Task For the autoformalization task of converting an informal input sequence NL to a formal output sequence FL\u1d62, we use the cross-entropy loss function. This function measures the error in predicting each word in the formal sequence given the previous words and the informal input. It is defined as:\nLCE = - \\sum_{j=1}^{n} log P(FL_{i,j} | FL_{i, j'}| j' < j, NL_i)\nAlignment Task To ensure that the embeddings of the informal and formal sequences are well-aligned in the FORMALALIGN model, we introduce a contrastive loss LCL. Let u\u1d62 and v\u1d62 denote the hidden state representations of the i -th informal input NL\u1d62 and its corresponding formal output FL\u1d62 , respectively u\u1d62 = Z\u00f8(NL\u1d62) and v\u1d62 = Z\u00f8(FL\u1d62|NL\u1d62).\nThe contrastive loss encourages the cosine similarity cos(u\u1d62, v\u1d62) between the representations of corresponding informal-formal pairs to be higher than the cosine similarity cos(u\u1d62, v\u1d62\u2032) between non-corresponding pairs:\nL_{CL} = - \\frac{1}{N} \\sum_{i=1}^{N} log \\frac{exp (cos(u_i, v_i) / \\tau)}{\\sum_{j=1}^{N} exp (cos(u_i, v_j) / \\tau)} (1)\nwhere \u03c4 is a temperature parameter that scales the cosine similarities. By minimizing this contrastive loss, the FORMALALIGN model learns to align the embeddings of corresponding informal-formal sequences while ensuring that the embeddings of non-corresponding sequences are dissimilar.\nFORMALALIGN Loss We jointly train an evaluator model with the autoformalization and alignment tasks, resulting in a FORMALALIGN model. The combined training loss is:\nL = LCE + LCL (2)"}, {"title": "3.3 INFERENCE", "content": "During the inference phase, the FORMALALIGN model generates an alignment evaluation score Valign for each pair of informal input NL\u1d62 and formal output FL\u1d62 . This score combines two metrics: the certainty score and the similarity score.\nCertainty Score The certainty score Vcer measures the confidence of the fine-tuned FORMALALIGN model in predicting the formal output based on the corresponding informal input. It is calculated by taking the exponential of the average log-probability assigned by the model to each token in the formal sequence:\nV_{cer} = exp ( \\frac{1}{n} \\sum_{j=1}^{n} log P(FL_{i,j} | FL_{i,<j}, NL_i) ) (3)\nwhere P represents the probability output of the model with parameters \u00f8, FL\u1d62,<\u2c7c denotes the tokens in the formal sequence up to position j \u2013 1, and n is the length of the formal sequence.\nSimilarity Score The similarity score Vsim measures alignment between the embedding representations of the informal input and the formal output. It is computed using the cosine similarity between the hidden states of the informal input and the formal output conditioned on the informal input:\nV_{sim} = cos(Z_\u00f8(NL_i), Z_\u00f8(FL_i|NL_i)) (4)\nwhere Z\u00f8(NL\u1d62) represents the hidden state from the final position in the informal input, and Z\u00f8(FL\u1d62|NL\u1d62) represents the hidden state from the formal output conditioned on informal input.\nAlignment Score The overall alignment evaluation score Valign is computed by taking the average of the certainty score and the similarity score:\nValign = (Vcer + Vsim)/2 (5)\nThis combined score reflects both the accuracy of the translation from informal to formal expressions and the alignment of the internal representations of the sequences, providing a robust evaluation metric during the inference stage."}, {"title": "4 EXPERIMENT", "content": "4.1 DATASETS\nIn our experimental setup, we conduct fine-tuning on the FormL4 (Lu et al., 2024b) and MMA (Jiang et al., 2023a) training sets, both of which are derived from Mathlib, a library of fundamental mathematical statements. This training data enables our model to align informal mathematical statements with their formal counterparts.\nWe employ a comprehensive set of test sets that covers both in-domain and out-of-domain data. Specifically, we use four distinct test sets: the basic and random test sets from FormL4, and the valid and test sets from MiniF2F (Zheng et al., 2022a). FormL4, designed to assess the autoformalization capabilities of LLMs in Lean 4 (de Moura & Ullrich, 2021) sourced from Mathlib, provides a comprehensive evaluation framework. The basic and random test sets from FormL4 allow us to gauge the model's performance in autoformalizing fundamental math statements that are similar to the training data. In contrast, the validation and test sets from MiniF2F serve as out-of-domain test data, providing a more challenging evaluation setting. MiniF2F is a benchmark containing 488 manually formalized mathematical competition statements sourced from various mathematical olympiads (AMC, AIME, IMO) and high-school and undergraduate math classes. .\nThese datasets primarily provide paired input-output instances, lacking the negative examples crucial for a more robust assessment of our model. Consider one aligned informal-formal pair shown"}, {"title": "4.2 METRICS", "content": "To assess the performance of models in evaluating the alignment of informal and formal language pairs, we introduce three automated metrics:\nAlignment Selection (AS): This metric quantifies how well a model selects the aligned formal output from multiple candidates when given an informal input. We calculate the alignment evaluation score Valign as described in Section 3 for each informal-formal pair. The pair with the highest score is selected as the aligned pair.\nAlignment Detection: We introduce a predefined threshold \u03b8 to detect the alignment for each informal-formal pair. If Valign exceeds \u03b8, the model considers the pair to be aligned. We evaluate this detection method using two metrics: precision and recall. Precision measures the fraction of pairs identified as aligned by the model that is truly informal-formal pairs. It is calculated as Precision = \\frac{TP}{TP+FP}, where TP represents the number of true positives (correctly identified aligned pairs) and FP represents the number of false positives (incorrectly identified aligned pairs). Recall measures the fraction of true informal-formal pairs correctly identified by the model. It is calculated as: Recall = \\frac{TP}{TP+FN}, where FN represents the number of false negatives (missed aligned pairs).\n4.3 MAIN RESULTS\nWe fine-tune a Mistral-7B model (Jiang et al., 2023b) as the FORMALALIGN model and evaluate its performance on various autoformalization benchmarks. The datasets used in this study include"}, {"title": "5 ANALYSIS AND DISCUSSION", "content": "To further validate the robustness and effectiveness of our FORMALALIGN framework, we conducted seven additional experiments, some of which are detailed in the Appendix due to limited space. We begin by validating the generalized effect of our FORMALALIGN across different baseline language models (Section 5.1). We investigate the necessity and effectiveness of our combined training loss (Section 5.2) and the impact of our proposed alignment score Valign (Section 5.3).\nFurthermore, we address concerns regarding potential data contamination in pre-trained language models through a comprehensive analysis of our experimental data (Appendix D). Next, we investigate the generalization ability of our method and the impact of different training datasets on its performance (Appendix E). We then explore the effect of incorporating contrastive learning loss on the performance"}, {"title": "5.1 EFFECTS OF DIFFERENT BASELINES", "content": "In this section, we validate the generalized effect of our FORMALALIGN across different baseline language models. These baselines are Phi2-2.7B (Javaheripi et al., 2023) (Phi), LLaMA2-7B (Touvron et al., 2023) (LLaMA), DeepSeekMath-Base 7B (Shao et al., 2024a) (DeepSeek) and Mistral-7B (Jiang et al., 2023b) (Mistral). Table 4 presents the Alignment-Selection performance of the different baseline models across four datasets:"}, {"title": "5.2 EFFECTS OF DIFFERENT TRAINING LOSS", "content": "We investigate the necessity and effectiveness of our combined training loss, defined in Eq. equation 2, by conducting an ablation study with different loss configurations. The results, presented in Table 5, provide valuable insights into the impact of each loss component on the model's performance.\nAutoformalization Inherently Learns Alignment:The configuration using only the cross-entropy loss (w/ CE) achieves comparable performance, particularly on the FormL4 dataset. This result suggests that the autoformalization task, optimized by the cross-entropy loss, inherently learns alignment between informal and formal sequences.\nComplementary Role of Contrastive Loss:Although the configuration using only the contrastive loss (w/ CL) shows limited performance, it plays a crucial complementary role to the cross-entropy loss. The combined approach (Ours), which incorporates both cross-entropy and contrastive losses, achieves the best performance across all datasets. The combined loss function ensures that the FORMALALIGN model benefits from both the sequence alignment inherent in the autoformalization process and the representation alignment facilitated by the contrastive learning process. By leveraging the strengths of both loss components, our model achieves a more holistic understanding of the task, enabling it to generate high-quality formal sequences that accurately capture the meaning and structure of the informal inputs."}, {"title": "5.3 EFFECTS OF DIFFERENT ALIGNMENT SCORE VALIGN", "content": "We investigate the necessity of our proposed alignment score Valign as described in Eq. equation 5. Table 6 provides a comprehensive evaluation of the effectiveness of our proposed alignment score Valign. By analyzing different configurations of the model, we derive the following key insights:\nLanguage Generation Capabilities Build a Strong Basis: The configuration using only the certainty score (w/ cer) achieves high performance, particularly on the FormL4 dataset. This result indicates that the model's language generation capabilities are robust and significantly contribute to the alignment evaluation. The certainty score measures the model's confidence in predicting the formal output, underscoring the importance of accurate language generation in our method.\nSuperiority of Combined Score: While using only the similarity score (w/ sim) shows limited performance, the combined approach (Ours), which integrates both certainty and similarity scores, achieves the best result across all datasets. This result demonstrates that combining both scores provides a more holistic and reliable evaluation metric. The combined score captures language-based and representation-level information, ensuring a robust evaluation during inference.\nIn summary, the ablation study confirms that the combination of certainty and similarity scores provides a more robust and reliable metric for alignment evaluation. This integrated approach ensures that the evaluation metric reflects both the model's confidence in the generated outputs and the semantic alignment of the sequences, leading to superior performance in the AAE task."}, {"title": "6 CONCLUSION", "content": "In this study, we introduce FORMALALIGN, a framework designed to automate the alignment evaluation in the autoformalization process using LLMs. Our approach utilizes a dual loss function that combines cross-entropy and contrastive learning loss, significantly enhancing the model's ability to discern and align informal-formal language pairs. This methodology not only preserves the integrity of logical constructs but also improves the accuracy of alignment between informal and formal sequences. Extensive experiments conducted across four datasets demonstrate that FORMALALIGN effectively reduces the reliance on manual verification processes, thereby streamlining the autoformalization workflow. The results confirm that our method provides reliable, effective, and robust evaluations, proving its practical utility in real-world scenarios. We believe that FORMALALIGN opens new avenues for research and application in the autoformalization field, offering a scalable and efficient solution to one of the most pressing challenges in the domain."}, {"title": "A LEAN 4 COMPILER", "content": "The Lean 4 Compiler is a critical component of the Lean 4 programming language. This tool enables users to craft effective proof automation tactics within the Lean environment and transform them into optimized C code. The Lean 4 Compiler in our scope is referred to as the tool available at https://github.com/leanprover-community/repl. This particular resource provides a read-eval-print loop (REPL) designed for Lean 4, which supports user interaction through JSON formatted input and output streams (stdin and stdout, respectively). Our compilation projection is therefore founded on REPL."}, {"title": "B MORE RELATED WORKS", "content": "Formal Mathematics Formal mathematics has seen significant advancements with the development of interactive theorem provers (ITPs) such as Isabelle (Wenzel et al., 2008), Lean (de Moura & Ullrich, 2021), HOL Light (Harrison, 1996), and Coq (Barras et al., 1997). These systems serve as programming languages that allow users to input mathematical statements and proofs in a formal language for automatic verification. The field of autoformalization has emerged to bridge the gap between natural language mathematics and these formal languages (Wang et al., 2018; Szegedy, 2020), aiming to leverage the strengths of both: the extensive logical reasoning and human knowledge embedded in natural language (Lu et al., 2024c;a), and the rigorous verification capabilities of formal systems (Kaliszyk et al., 2014).\nRecent years have witnessed substantial progress in dataset creation for formal mathematics. These efforts have primarily focused on two approaches: extracting information from established formal libraries and manually annotating or formalizing problems expressed in natural language. In the realm of data extraction, several datasets have been developed for popular proof assistants. Notable examples include LeanDojo (Yang et al., 2023) and MLFMF (Bauer et al., 2023), which utilize the mathlib library in Lean. LeanDojo, in particular, has extracted an impressive collection of over 98,000 theorems and proofs, along with 130,000 premises from Mathlib.\nComplementing these extraction efforts, researchers have also focused on manually formalizing problems from various mathematical domains. MiniF2F (Zheng et al., 2022b) stands out in this category, offering 488 manually formalized Olympiad-level problems across four proof systems, equally divided into validation and test sets. Other notable contributions include FIMO (Liu et al., 2023a) and ProofNet (Azerbayev et al., 2023a), which formalize theorem statements from IMO and undergraduate-level problems in Lean.\nDomain-specific formalizations have also gained attention. TRIGO (Xiong et al., 2023) focuses on formalizing trigonometric reduction problems, while UniGeo (Chen et al., 2022) and Formal-Geo (Zhang et al., 2023) concentrate on annotating proof steps for geometry proving problems. These diverse datasets provide invaluable resources for researchers working on automated theorem proving, proof verification, and natural language processing in the context of formal mathematics. By offering a rich array of formalized mathematical content, they facilitate the development and evaluation of algorithms that can bridge the gap between natural and formal mathematical languages, potentially revolutionizing how we approach mathematical reasoning and verification in the digital age."}, {"title": "C EXPERIMENTAL DETAILS", "content": "C.1 FINETUNING DETAILS\nOur experiments are conducted in a computing environment with 8 NVIDIA A100 GPUs, each with 40GB of memory. All models are fine-tuned in a full-parameter setting.\nWe employ the AdamW optimizer for model training over 1 epoch, with a batch size of 512. The learning rate is set at 2e \u00d7 10\u22126, incorporating a 3% learning rate warmup period. Below, we present a comprehensive overview of the training hyperparameters utilized. These parameters are consistently applied across training all LLMs."}, {"title": "C.2 PROMPT DETAILS", "content": "We report greedy decoding results for GPT-4 and GPT-3.5 using a temperature setting of 0.0. Additionally, For the GPT-3.5 version, we query the API of gpt-3.5-turbo-0125. For GPT-4, we query the API of gpt-4-1106-preview.\nPrompt for Querying GPT for Automated Alignment Evaluation Below, we provide the prompt used to query GPT for automated alignment evaluation.\nGiven an informal mathematical input and a formal theorem statement, your task is to evaluate the alignment between them. Assign a value between 1 and 5 to each formal output, where:\n1 indicates that the formal output is not aligned with the informal input at all.\n5 indicates that the formal output is perfectly aligned with the informal input.\nConsider the following criteria while assigning the values:\n1. Semantic Consistency: How accurately does the formal output capture the meaning of the informal input?\n2. Structural Correspondence: How well does the structure of the formal output reflect the structure implied in the informal input?\n3. Completeness: Does the formal output include all relevant information from the informal input?\n4. Precision: Is the formal output free from extraneous or incorrect information that is not present in the informal input?\nTask:\n1. Read the informal input.\n2. Evaluate the formal theorem using the criteria above.\n3. Assign a value between 1 and 5 to each formal output, reflecting its alignment with the informal input. Your output should follow this format: # Alignment Score: [your assigned value]\nInformal Input: {Informal_Input}\nPool of Formal Outputs: {Formal_Outputs}\n# Alignment Score:\nWe apply the prompt below for our FORMALALIGN model to obtain the alignment score without involving language generation settings.\nPrompt for Querying FORMALALIGN Model for Automated Alignment Evaluation: Below, we provide the prompt used to query the FORMALALIGN model for automated alignment evaluation.\nStatement in natural language: {Informal_Input}\nTranslate the statement in natural language to Lean: {formal_output}"}, {"title": "D DATA CONTAMINATION ANALYSIS", "content": "To address concerns regarding potential data contamination in pre-trained language models, we conducted a comprehensive analysis of our experimental data. This analysis is crucial, as language models are often trained on large amounts of unsupervised data, which may include samples similar to those used in our experiments.\nExperiment Design We designed our experiments to mitigate the risk of data contamination by sourcing MiniF2F data from math olympiads such as AMC, AIME, and IMO. These datasets differ significantly from Mathlib, the largest Lean theorem library and the primary source of Lean data, reducing the likelihood of data contamination. Additionally, our automated alignment evaluation task involves augmenting aligned pairs with 20 negative examples using our proposed six misalignment strategies, ensuring that these data are not included in the pre-training corpus of LLMs.\nResults We calculated the loss of different pre-trained models on the MiniF2F test/valid sets in the autoformalization task to further analyze the potential data contamination issue. This approach is inspired by the data contamination detection method in (Wei et al., 2023), which suggests that if a language model has not been exposed to a dataset during pre-training, its loss on the dataset should be relatively high and approximately equivalent to its loss on a reference dataset composed of new, similar samples. The losses of the models in our experiments are shown below:\nAnalysis The loss values for each pre-trained model fall within the range of 1 to 3, consistent with and even higher than the findings in (Wei et al., 2023), which reports that losses higher than around 1 on the GSM8K test set indicate low data leakage. These results suggest a low level of data contamination in our experimental data. The combination of carefully sourced datasets and the augmentation of aligned pairs with negative examples using our misalignment strategies further strengthens the robustness of our experiments against data contamination."}, {"title": "E GENERALIZATION ANALYSIS", "content": "To explore the generalization capabilities of our FORMALALIGN method, we conduct a series of experiments analyzing the impact of different datasets on the model's performance. These experiments aim to provide insights into the method's adaptability and effectiveness across various mathematical domains.\nExperiment Design We design our experiments to assess the model's performance when trained on different datasets:\n1. Our original model is fine-tuned on a combination of the FormL4 training set and the MMA training set from Mathlib.\n2. To evaluate the impact of individual datasets, we separately train models on FormL4 and MMA.\n3. We test all models on the MiniF2F test and valid sets, which are sourced from math olympiads such as AMC, AIME, and IMO, providing a fair comparison across challenging and diverse problem types.\nThis approach allows us to gauge the generalization ability of our method and understand how different training datasets influence its performance.\nResults The results of our experiments, focusing on the alignment-selection score for clear comparison, are presented in the following table:\nOur results highlight several key findings:\nDataset Content Impact: TThe FormL4 dataset, which contains both statements and proofs, outperforms the MMA dataset, which only contains statements. This suggests that the inclusion of proofs provides richer information about the underlying mathematical concepts, leading to a more robust understanding of the alignment process.\nSynergy of Datasets: Combining both FormL4 and MMA datasets for training results in improved performance compared to using either dataset alone. This demonstrates the potential benefits of leveraging diverse data sources to enhance the model's capabilities.\nGeneralization Ability: The strong performance on MiniF2F sets, which contain problems from challenging domains like math olympiads, indicates that our method can effectively handle diverse and complex mathematical problems. This suggests that FORMALALIGN has the potential for wider applicability across various mathematical domains.\nThese findings highlight the robustness of our FORMALALIGN method and its ability to generalize across different types of mathematical problems. The experiments demonstrate that by leveraging diverse datasets and considering both the quality and quantity of training data, we can enhance the method's performance and adaptability to new, unseen mathematical challenges."}, {"title": "F AUTOFORMALIZATION PERFORMANCE ANALYSIS", "content": "Given our model is primarily trained for the autoformalization task, we conduct additional experiments to explore its capabilities in converting natural language (NL) statements to formal language (FL) statements. These experiments aim to provide a comprehensive evaluation of our model's performance and demonstrate the effects of incorporating contrastive learning loss on autoformalization.\nExperiment Design To assess the impact of contrastive learning loss on autoformalization performance, we compare two models:\n1. A baseline model trained with cross-entropy loss only (LCL)\n2. Our proposed model, which incorporates both cross-entropy loss and contrastive learning loss (LCL + LCE)\nWe evaluate both models on the FormL4 Basic and FormL4 Random test sets to obtain a comprehensive understanding of their autoformalization capabilities across different complexity levels.\nAnalysis The results demonstrate that incorporating contrastive learning loss improves autoformalization performance on both test sets. This improvement can be attributed to several factors:\nEnhanced Discrimination: Contrastive learning acts as a form of data augmentation, introducing additional negative examples that enhance the model's ability to distinguish between correct and incorrect formalizations.\nImproved Representation Learning: The contrastive approach helps the model learn more robust and discriminative representations of mathematical concepts, leading to more accurate autoformalization results.\nGeneralization Across Complexity: The performance improvement is observed in both the Basic and Random test sets, suggesting that the benefits of contrastive learning extend to various levels of problem complexity.\nThese findings highlight the potential of contrastive learning in improving autoformalization performance. By leveraging this approach, we not only enhance our model's capabilities but also pave the way for future research in this area. The success of incorporating contrastive learning loss suggests promising directions for developing more effective autoformalization techniques and advancing the field of automated mathematical reasoning.\nOur experiments demonstrate that combining traditional cross-entropy loss with contrastive learning leads to a more robust and accurate autoformalization model. This approach could inspire further innovations in the field, potentially leading to even more sophisticated methods for bridging the gap between natural language mathematics and formal mathematical representations."}, {"title": "G COMPARISON WITH HUMAN EVALUATION AND LLM-AS-JUDGE", "content": "Experiment Design We design our experiment as follows:\n1. Sample Selection: We sample 80 items from the MiniF2F test set in our dataset. Originally, each item consists of:\n\u2022 An informal natural language problem\n\u2022 A formal statement\n\u2022 A ground-truth label indicating alignment or misalignment between informal and formal statements\n\u2022 The misalignment type (if the formal statement is misaligned with the informal one)\n2. Sample Distribution: We ensure a balanced distribution between misalignment and alignment labels and include a diversity of misalignment types for a robust and representative evaluation.\n3. Human Evaluation: The same informal and formal statements in the 80 samples are provided to four human experts in Lean 4, who are tasked to independently evaluate autoformalization alignment (i.e., binary classification of alignment/misalignment).\n4. Performance Metrics: We calculate the correctness ratio of each human evaluator by comparing their assessments with the ground-truth labels."}, {"title": "H CASE STUDY", "content": "We present a case study of a randomly selected informal-formal statement from our test dataset. We compare how our method and three other metrics (BLEU, BERTscore, Lean 4 Compiler) evaluate the alignment of various types of incorrect formal statements.\nFive types of misaligned formal statements are listed in Table 13, together with the original natural language statements. As shown in Table 12, for misalignments involving missing conditions, wrong constants, variable type mismatches, and equality violations, the FORMALALIGN scores are consistently below a threshold of 0.7, indicating low semantic precision of the formal statement and a likely misalignment. In contrast, both BLEU and BERTscore reported similarly high scores regarding various types of misalignment, demonstrating an inferior performance in evaluating the elusive misalignment in autoformalization."}]}