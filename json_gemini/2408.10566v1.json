{"title": "SparseGrow: Addressing Growth-Induced Forgetting in Task-Agnostic Continual\nLearning", "authors": ["Yuqing Zhao", "Divya Saxena", "Jiannong Cao", "Xiaoyun Liu", "Changlin Song"], "abstract": "In continual learning (CL), model growth enhances adaptabil-\nity over new data, improving knowledge retention for more\ntasks. However, improper model growth can lead to severe\ndegradation of previously learned knowledge, an issue we\nname as growth-induced forgetting (GIFt), especially in task-\nagnostic CL using entire grown model for inference. Existing\nworks, despite adopting model growth and random initializa-\ntion for better adaptability, often fail to recognize the pres-\nence of GIFt caused by improper model growth. This over-\nsight limits comprehensive control of forgetting and hinders\nfull utilization of model growth. We are the first in CL to iden-\ntify this issue, and conduct an in-depth study on root cause of\nGIFt, where layer expansion stands out among model growth\nstrategies, widening layers without affecting model function-\nality. Nonetheless, direct adoption of layer expansion presents\nchallenges. It lacks data-driven control and initialization of\nexpanded parameters to balance adaptability and knowledge\nretention. In this paper, we propose a novel sparse model\ngrowth (SparseGrow) approach to overcome the issue of GIFt\nwhile enhancing adaptability over new data. SparseGrow em-\nploys data-driven sparse layer expansion to control efficient\nparameter usage during model growth, reducing GIFt from\nexcessive growth and functionality changes. It also com-\nbines the sparse growth with on-data initialization at train-\ning late-stage to create partially zero-valued expansions that\nfit learned distribution, enhancing retention and adaptability.\nTo further minimize forgetting, freezing is applied by calcu-\nlating the sparse mask, allowing data-driven preservation of\nimportant parameters. Through experiments across datasets\nwith various task-agnostic settings, use cases and large num-\nber of tasks, we demonstrate the necessity of layer expansion\nand showcase the effectiveness of SparseGrow in overcoming\nGIFt, highlighting its adaptability and knowledge retention\nfor incremental tasks. Code will be available upon publica-\ntion.", "sections": [{"title": "Introduction", "content": "In the field of continual learning (CL), model growth be-\ncomes essential for better adaptation to new data, improving\nscalability in managing incremental data. In real-life sce-\nnarios with dynamic environments or evolving needs such\nas autonomous vehicles, healthcare and smart cities, model\ngrowth is crucial for model deployment in handling in-\ncreased task complexity, incorporating new features or new\nmodality data. As the volume of incremental data exceeds\nthe model's learning capacity, it struggles to adapt to new\ninputs or retain previous knowledge. This necessitates aug-\nmenting the model's parameter capacity to sustain or en-\nhance its adaptability, thereby improving scalability.\nHowever, improper model growth often leads to a degra-\ndation of performance on previously learned tasks, an issue\nwe identify and name as growth-induced forgetting (GIFt),\nespecially in task-agnostic CL settings such as domain and\nclass incremental learning settings (Shim et al. 2021; Hu\net al. 2021). In these scenarios, the task label is unavail-\nable, and the entire model, including expanded parameters,\nis used for inference. Differing from catastrophic forgetting\n(CF), which arises from data distribution changes, growth-\ninduced forgetting is a distinct type of forgetting that occurs\nwhen a trained single model, upon increasing its parameter\ncapacity through model growth, is affected in its ability to\nretain or effectively utilize previously learned information.\nThis concept is echoed in neuroscience, where increasing\nneurogenesis in the brain after memory formation can pro-\nmote forgetting, referred to as neurogenesis-based forgetting\n(Davis and Zhong 2017).\nSome existing works in continual learning adopt differ-\nent model growth strategies and randomly initialize them\nto enhance adaptability. However, they fail to recognize the\npresence of GIFt resulting from improper model growth.\nThese methods may either be task-specific, requiring man-\nual task identification during inference to avoid forgetting\nissues, not applicable for domain or class incremental sce-\nnarios, or adopting improper model growth strategies that\nmay further lead to GIFt. Nevertheless, the lack of explicit\nacknowledgement of the growth-induced forgetting issue\nposes challenges in identifying suitable model growth ap-\nproaches. This not only limits comprehensive control of for-\ngetting but also hinders full utilization of model growth.\nWe are the first in CL to identify this issue and con-\nduct an in-depth study to identify appropriate model growth\nstrategies for increasing model capacity while minimizing\nthe occurrence of growth-induced forgetting. Our research\nrevealed that layer expansion, which widens layers with-\nout affecting model functionality, stands out compared with\nother model growth strategies, such as lateral connection\nand in-depth growth. The impacts of these growth meth-\nods on growth-induced forgetting (GIFt) differ: Layer ex-\npansion expands parameters in width, which are computed\ncollectively during inference. Lateral connections add new\nmodules in width connecting adjacent layers, overwriting\nold module values. In-depth growth adds new hidden lay-\ners, introducing new computations for preceding and suc-\nceeding parameters. Drawing inspiration from neurogenesis\n(Davis and Zhong 2017; Deng, Aimone, and Gage 2010),\nwe propose a novel sparse model growth (SparseGrow) ap-\nproach to overcome the issue of GIFt while enhancing adapt-\nability. SparseGrow employs data-driven sparse layer ex-\npansion to control efficient parameter usage during model\ngrowth, reducing growth-induced forgetting caused by ex-\ncessive growth and functionality changes. While achieving\ndata-driven control, the choice of initialization values signif-\nicantly impacts expansion, with zero-initialization stopping\nits update and random-initialization causing heavy GIFt.\nSparseGrow combines the sparse growth with on-data ini-\ntialization at final stage of training to create partially zero-\nvalued expansions that fit the learned distribution, mini-\nmizing GIFt while enhancing adaptability. To further mini-\nmize forgetting, freezing is applied by calculating the sparse\nmask, allowing data-driven preservation of important pa-\nrameters. To validate our findings, we conducted compre-\nhensive experiments on various task-agnostic settings with\ndomain and class incremental datasets and varying numbers\nof tasks. The results demonstrate the necessity of layer ex-\npansion, showcasing the effectiveness of our approach in\novercoming GIFt while highlighting the adaptability and\nknowledge retention of the method for incremental tasks."}, {"title": "RELATED WORK", "content": "There are three principal model growth methods: 1) Layer\nExpansion (LayerExp)", "operations": "new", "adaptation": "and 'reuse', appli-\ncable to specially designed Conv2d networks. These meth-\nods demonstrate the potential of lateral connections for CL\nbut highlight the need for more general approaches with less\nGIFt applicable for complex networks.\nDEN (Yoon et al. 2017) uses layer ex-\npansion in a top-down manner, growing every layer if the\nloss does not meet a threshold. (Hung et al. 2019) ex-\npands the number of filters (weights) for new tasks and\nadopts gradual pruning to compact the model, limited to\ntask-specific settings. (Ostapenko et al. 2019) expands the\nsame number of neurons used in a layer in the GAN gener-\nator for rehearsal scalability. (Geng et al. 2021) expands the\nhidden size by the pruning ratio of task. (Yang et al. 2021)\ngrow a randomly initialized expanded filter and concatenate\nit into the network. (Xu and Zhu 2018) adaptively expands\neach layer of the network when new task arrives, applicable\nfor simple convolutional networks and fully-connected net-\nworks. (Yan, Xie, and He 2021) expand the model with new\nparameters by creating a separate feature extractor for in-\ncoming data, applicable for class-incremental learning. Our\nwork could further exploit layer expansion's potential by re-\nducing GIFt.\nKozal et al. (Kozal and Wozniak 2023)\nadd new layers atop existing ones. Zhang et al. (Zhang et al.\n2020) use AutoML for width and depth growth, incorporat-"}]}