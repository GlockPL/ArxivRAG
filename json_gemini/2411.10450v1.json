{"title": "Dataset Refinement for Improving the Generalization Ability of the EEG Decoding Model", "authors": ["Sung-Jin Kim", "Dae-Hyeok Lee", "Hyeon-Taek Han"], "abstract": "Electroencephalography (EEG) is a generally used neuroimaging approach in brain-computer interfaces due to its non-invasive characteristics and convenience, making it an effective tool for understanding human intentions. Therefore, recent research has focused on decoding human intentions from EEG signals utilizing deep learning methods. However, since EEG signals are highly susceptible to noise during acquisition, there is a high possibility of the existence of noisy data in the dataset. Although pioneer studies have generally assumed that the dataset is well-curated, this assumption is not always met in the EEG dataset. In this paper, we addressed this issue by designing a dataset refinement algorithm that can eliminate noisy data based on metrics evaluating data influence during the training process. We applied the proposed algorithm to two motor imagery EEG public datasets and three different models to perform dataset refinement. The results indicated that retraining the model with the refined dataset consistently led to better generalization performance compared to using the original dataset. Hence, we demonstrated that removing noisy data from the training dataset alone can effectively improve the generalization performance of deep learning models in the EEG domain.", "sections": [{"title": "I. INTRODUCTION", "content": "Brain-computer interface (BCI) is a system that facilitates communication between humans and computers by interpreting human intentions [1]-[5]. One of the most widely utilized approaches to capture human intentions is electroencephalography (EEG). EEG is a non-invasive method for measuring brain activity, which has advantages such as portability and convenience [6]. However, due to its non-invasive approach, EEG is more susceptible to various noises compared to invasive methods [3]. Therefore, research has been conducted to decode human intentions embedded in EEG signals [7]. In particular, since neural network-based deep learning has demonstrated robust performance in pattern recognition across different domains, many studies have focused on applying deep learning methodologies to decode EEG signals [8], [9].\nNeural network-based deep learning operates by learning the underlying patterns in data through the use of large amounts of training data [10]. This necessitates the availability of high-quality datasets. However, EEG signals, which are bio-signals, are prone to noise due to various factors during signal acquisition. Moreover, EEG signals exhibit significant variability in data distribution across sessions and subjects [3]. \u03a4\u03bf address these issues, previous research has focused on refining model architectures to enhance pattern recognition capabilities [11] or applying domain adaptation techniques [12] to reduce distributional discrepancies. Nonetheless, these methods typically assume that the training datasets are composed of finely curated data. We assumed that this strong assumption is difficult to meet in EEG datasets, which are inherently noisy and often lack quality verification. Therefore, before applying advanced methodologies to enhance performance, we assumed the refining process of the dataset was necessary. Hence, we considered the use of data pruning techniques to refine the dataset.\nGenerally, data pruning is a method to reduce training time in domains where the dataset is vast, and the model has numerous parameters [13]. Therefore, the primary objective of conventional data pruning is to identify easy samples that have minimal impact on training and can be removed with negligible performance degradation [14]. However, we hypothesized that EEG datasets, despite their limited size, contain numerous data that hinder the training of deep learning models. In this environment, a few noisy samples with high influence can significantly degrade the model's generalization performance. Hence, we aimed to improve the generalization performance of models by employing commonly used data pruning techniques, not to remove easy samples but rather to identify and eliminate hard samples.\nIn this paper, we propose the dataset refinement algorithm aimed at improving model generalization performance. First, we utilized various metrics to assess the influence of each data during the training process. Based on these influence assessments, we designed an algorithm to refine the dataset. To validate the effectiveness of our proposed method, we em-"}, {"title": "II. METHODS", "content": "We utilized two approaches to quantitatively measure the influence of data during the training process: the influence score [15] and Monte Carlo dropout (MC dropout) [16]. The influence score measures how much a particular data impacts the model's predictions. This score is widely used to analyze the effects of outliers or noisy data on the model. The following equation represents the calculation method for the influence score:\n$I(x_i) = \\sum_{(x,y) \\in D} \\nabla_{\\theta} L(x, y; \\theta)^T H_{\\theta}^{-1} \\nabla_{\\theta} L(x_i, y_i; \\theta),$\nwhere D indicates the training dataset which contains n number of data and x and y implies data and label, respectively. Lis the objective function. 0 and H inciates the emperical risk minimizer and Hessian matrix, respectively. That is,\n$\\theta = argmin_\\theta \\sum_{i=1}^n L(x_i, y_i)$ and $H_{\\theta} = \\sum_{i=1}^n \\nabla^2 L(x_i, y_i)$. Data with high uncertainty are more likely to be considered outliers or noisy data. To measure aleatoric uncertainty, we adopted the uncertainty quantification method proposed by Deodato et al. [16], which is based on MC dropout. This quantification approach can be formulated as:\n$U(x_i) = - \\frac{T}{\\sum_{t=1}^T P_{t,i}}$,\nwhere T indicates the number of repetition, and $P_{t,i}$ is the confidence score of model from xi at $t^{th}$ dropout."}, {"title": "B. Algorithm for Refining Dataset", "content": "We designed the algorithm for dataset refinement based on the scores of data's influence in the training process. The algorithm consists of three main stages. First, we get the model weights that can minimize the empirical risk using the training dataset. Based on the empirical risk minimizer obtained in the first stage, we compute data influence scores by executing the respective algorithms to measure the influence of each data. Finally, after refining the training dataset by removing data that exhibited the highest influence score and identifying them as noisy samples, we retrain the model with the refined dataset. Through this iterative process, we successfully enhanced the model's generalization performance by eliminating noisy samples from the training dataset. The details of the proposed algorithm are presented as Alg. 1."}, {"title": "C. Datasets", "content": "To evaluate the proposed algorithm, we utilized two public motor imagery-based EEG datasets that are most generally used for assessment in the motor imagery EEG domain: BCI Competition IV 2a [17] and BCI Competition IV 2b [18].\nBCI Competition IV 2a (BCIC2a) was acquired from nine subjects performing motor imagery tasks using 22 electrodes placed according to the international 10/20 system. The electrodes were set with a sampling rate of 250 Hz. The subjects were instructed to perform four different motor imagery tasks: imagining movements of the right hand, left hand, tongue, and foot. EEG signals were collected over two sessions per subject, each consisting of 288 trials, corresponding to 72 repetitions per class. We defined the imagery segment as the period between 2 to 6 seconds and applied a low-pass Butterworth filter at 38 Hz to focus on the target frequency range associated with motor imagery.\nBCI Competition IV 2b (BCIC2b) was collected from nine subjects who performed right-hand and left-hand motor imagery tasks while three electrodes were placed over the sensory-motor cortex. The electrodes were configured with the sampling rate of 250 Hz, similar to BCIC2a. Data was"}, {"title": "D. Evaluation Settings", "content": "To evaluate the robustness and effectiveness of our proposed algorithm, we applied it to three different models generally used in the motor imagery domain. The selected models were EEGNet [19], DeepConvNet [20], and ShallowConvNet [20], [21]. Each model was trained from scratch, with a learning rate of 2e-3 for 300 epochs and ten epochs warm-up phase to stabilize training. These hyperparameters were consistently applied across both datasets. We used a cosine learning rate scheduler and the AdamW optimizer to stabilize the training process. The batch size was set to 64. For evaluation, we employed leave-one-subject-out cross-validation to conduct experiments in a subject-independent setting. The evaluation metric was average accuracy, which is widely used in subject-independent motor imagery domains [22], [23], and we reported results obtained over ten different runs with various random seeds. To verify whether the performance gain of the proposed algorithm was solely due to data reduction, we additionally introduced a random dropout approach that randomly removes data. The threshold for distinguishing noisy data was determined through the grid search, and all corresponding results were reported. For data preprocessing, we used exponential moving standardization to remove outliers within the signal [12], and the respective formulation is provided below.\n$\\hat{x}_{i,k} = \\frac{x_{i,k} - \\mu_k}{\\sqrt{\\sigma_k^2}}$,\n$\\mu_k = (1 - \\alpha) x_{i,k} + \\alpha \\mu_{k-1}$,\n$\\sigma_k^2 = (1 - \\alpha) (x_{i,k} - \\mu_k)^2 + \\alpha \\sigma_{k-1}^2,$\nwhere k is the index of time point in data xi, and $\\hat{x}_{i,k}$ indicates the preprocessed data. We set the a as 0.999."}, {"title": "III. RESULTS AND DISCUSSION", "content": "As shown in Fig. 1, we evaluated the performance of the proposed algorithm by applying it to three different models on two different datasets. The results indicate that refining the dataset using influence scores and MC dropout consistently led to performance improvement compared to using the original dataset. For the BCIC2a dataset, the highest performance improvement was observed when refining 10 % of the dataset for EEGNet and 40 % for both DeepConvNet and ShallowConvNet, resulting in performance gains of 0.97%, 4.67 %, and 4.54%, respectively. For the BCIC2b dataset, the highest improvements were obtained by refining 30% of the data, with EEGNet achieving 1.42 %, DeepConvNet achieving 3.90 %, and ShallowConvNet achieving 3.43 % gains. For MC"}, {"title": "IV. CONCLUSION AND FUTURE WORKS", "content": "In this paper, we proposed the algorithm to refine EEG datasets to improve decoding models' generalization performance. Pioneer studies on extracting significant features from EEG signals have been conducted in various directions, such as enhancing model architectures and applying domain adaptation. However, these methods often rely on the assumption that the dataset is well-curated, which is difficult to achieve with EEG data due to its susceptibility to noise. To address this issue, we proposed the algorithm that applies various metrics to quantify data influence during training, allowing for effective dataset refinement. Our results demonstrated that refining the dataset using the proposed algorithm resulted in significant improvements in model performance, with up to 5.27% improvement on the BCIC2a dataset and up to 3.90% improvement on the BCIC2b dataset. This improvement was achieved simply by eliminating data that adversely affected the training process, thus enhancing model generalization.\nFurthermore, by validating the robustness of the proposed algorithm by applying it to three different models across two different datasets, we observed consistent performance improvements. The contribution of the proposed algorithm lies in its applicability as a preprocessing technique alongside other existing methods. Despite the effectiveness of the algorithm in removing noisy data from the dataset, there remain limitations. Specifically, the process of calculating influence scores and optimizing the threshold requires additional computational resources and costs. While this approach was feasible for relatively small datasets like BCIC2a and BCIC2b, applying it to larger datasets may present challenges. Therefore, our future work will focus on developing a more efficient dataset refinement algorithm that can effectively operate even with large-scale datasets."}]}