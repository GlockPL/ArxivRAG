{"title": "Discovering highly efficient low-weight quantum error-correcting codes\nwith reinforcement learning", "authors": ["Austin Yubo He", "Zi-Wen Liu"], "abstract": "The realization of scalable fault-tolerant quantum computing is expected to hinge on quantum\nerror-correcting codes. In the quest for more efficient quantum fault tolerance, a critical code param-\neter is the weight of measurements that extract information about errors to enable error correction:\nas higher measurement weights require higher implementation costs and introduce more errors, it\nis important in code design to optimize measurement weight. This underlies the surging interest in\nquantum low-density parity-check (qLDPC) codes, the study of which has primarily focused on the\nasymptotic (large-code-limit) properties. In this work, we introduce a versatile and computationally\nefficient approach to stabilizer code weight reduction based on reinforcement learning (RL), which\nproduces new low-weight codes that substantially outperform the state of the art in practically rel-\nevant parameter regimes, extending significantly beyond previously accessible small distances. For\nexample, our approach demonstrates savings in physical qubit overhead compared to existing results\nby 1 to 2 orders of magnitude for weight 6 codes and brings the overhead into a feasible range for\nnear-future experiments. We also investigate the interplay between code parameters using our RL\nframework, offering new insights into the potential efficiency and power of practically viable coding\nstrategies. Overall, our results demonstrate how RL can effectively advance the crucial yet chal-\nlenging problem of quantum code discovery and thereby facilitating a faster path to the practical\nimplementation of fault-tolerant quantum technologies.", "sections": [{"title": "I. INTRODUCTION", "content": "Quantum information processing offers promising po-\ntential for revolutionary advantages over conventional\nmethods in computation and various other types of tech-\nnologies [1-4]. However, a fundamental obstacle stands\nin the way: quantum systems and their manipulation\nare inherently prone to a wide variety of noise and er-\nrors, necessitating efficient fault tolerance strategies that\nmaintain the protection of quantum information when\nall components may be faulty, in order to make quantum\nadvantages practically scalable and unlock their full po-\ntential. Quantum error-correcting (QEC) codes provide\na pathway to efficient fault tolerance, positioning them as\na pivotal field of research in quantum information [5-8].\nFurthermore, they have recently made a profound im-\npact on physics [9-12], underscoring their fundamental\nimportance.\nStabilizer codes serve as a canonical framework for\nQEC codes, enabling logical qubits to be encoded in more\nphysical qubits in a way that information about errors\nneeded for correction can be inferred through measur-\ning certain parity-check (stabilizer) operators [6]. Since\nmeasurements of higher weight (the size of nontrivial sup-\nport) typically require larger circuits and qubit overhead,\nwhich can make experimental executions significantly\nmore difficult and introduce more errors, it is crucial to\nminimize the check weight in code design for practical\nquantum computing. Note that lower check weight is\nalso a key motivation behind the interest in various gen-\neralized coding schemes such as subsystem codes [13, 14]\nand dynamical codes [15, 16].\nIn line with this, constraining the check weight (as\nwell as the degree) to be asymptotically O(1)\u2014that is,\nbounded by a constant as the code length grows gives\nrise to the so-called quantum low-density parity-check\n(qLDPC) codes which have attracted intensive interest\nas a promising scheme for fault tolerance with low over-\nhead [17-20]. In particular, general qLDPC codes can\nachieve substantially better code parameters and fault\ntolerance efficiency [18, 21, 22] than those with geomet-\nric connectivity constraints including the surface code,\nwhich has long been regarded the leading scheme for\nimplementing fault tolerance [9, 23-26]. The need for\nsubstantial long-range connectivity to overcome geomet-\nric barriers for code parameters [27-31] poses a signifi-\ncant obstacle to capitalizing on the advantages of qLDPC\ncodes. However, recent remarkable advances in quan-\ntum computing with the reconfigurable atom array plat-\nform [32] bring hope for alleviating this difficulty, po-\ntentially establishing qLDPC code-based fault tolerance\nschemes as mainstream. Driven largely by theoretical\ninterest, intensive study has been devoted to the con-\nstructions of qLDPC code families with desirable asymp-\ntotic parameters in the infinite code length limit (see\ne.g. Ref. [18] for a slightly outdated review). Notably,\nthere has been a recent surge of breakthroughs in achiev-\ning asymptotically 'good' qLDPC code families that si-\nmultaneously attain optimal scalings of both code rate"}, {"title": "II. REINFORCEMENT LEARNING\nFRAMEWORK FOR WEIGHT REDUCTION", "content": "Reinforcement learning (RL) is a widely used machine\nlearning paradigm in which an agent interacts with an\nenvironment by selecting actions and receiving feedback\nin the form of reward signals. The agent iteratively\nrefines its decision-making policy to maximize cumula-\ntive rewards [48]. This paradigm has proven successful\nin a number of problems in physics [53-57], as well as\nproblems with exceptionally large and complex decision\nspaces [58] and thus naturally lends itself to the combi-\nnatorial nature of code design.\nAs illustrated in Fig. 1, the environment of our weight\nreduction framework is defined by the Tanner graph of\na stabilizer code. The agent can remove or add edges\nin the Tanner graph, and its objective is to minimize\nthe maximum degree of variable and check nodes while\npreserving the code distance.\nWe utilize the Proximal Policy Optimization (PPO)\nalgorithm with action masking to efficiently explore the\naction space [59]. PPO balances exploration and ex-\nploitation by constraining policy updates, ensuring stable"}, {"title": "learning. The objective function is", "content": "$\\mathcal{L}^{CLIP}(\\theta) = E_t [min (r_t(\\theta) A_t, clip (r_t(\\theta), 1 - \\epsilon, 1 + \\epsilon) \\hat{A}_t)]$,\n                                                              (1)\nwhere $r_t(\\theta) = \\frac{\\pi_{\\theta}(a_t | s_t)}{\\pi_{\\theta_{old}}(a_t | s_t)}$ is the probability ratio, $\\hat{A}_t$ is the\nadvantage estimate, and $\\epsilon$ controls the clipping range.\nThen we design the reward function to guide our Re-\ninforcement Learning (RL) agent in optimizing Tanner\ngraphs for stabilizer codes. The function balances node\ndegree reduction with code distance preservation, ensur-\ning robust error-correcting capabilities. We define lo-\ncal reward functions $R_v(\\kappa_v)$ and $R_c(\\kappa_c)$ for variable and\ncheck nodes, respectively, by assigning fixed rewards for\ndegrees up to $V_{max}$, and an exponential penalty for de-\ngrees above $V_{max}$:"}, {"title": "We exclude all adding operations from nodes with de-\ngree greater than the maximum desired weight, and all\ndeleting operations from nodes with degree 1 or the min-\nimum desired weight. Masked actions are assigned zero\nprobability, and the remaining action probabilities are\nre-normalized to form a valid probability distribution.\nThis preserves the theoretical properties of PPO, such as\nthe trust region constraint and still ensures stable policy\nupdates [60]. Most importantly, this allows us to restrict\nthe agent to only focus on codes within the target weight,\nwhich enhances learning efficiency without compromising\nthe algorithm's convergence guarantees. The mask can\nbe adapted to codes with a variety of constraints on their\nstructure. For example, the masked property for general\nstabilizer codes is symplectic orthogonality of H, while\nfor CSS codes it is the orthogonality between $H_x$ and\n$H_z$. We can also extend this to various important re-\nfined constraints are as needed, such as k-orthogonality\nwhich induces codes with transversal non-Clifford gates,\nand geometric locality or connectivity constraints that\nubiquitously arise in physical and experimental scenar-\nios.", "content": "$R_v(\\kappa_v) =  \\begin{cases}\nC_1, & \\kappa_v = 1, \\\\\nC_2, & \\kappa_v = 2, \\\\\nC_3 & \\kappa_v  V_{max},\\\\\nexp[-\\lambda (\\kappa_v - V_{max})], & \\kappa_v > V_{max},\n\\end{cases}$\n                                                     (2)\nwhere $\\lambda$ controls the severity of the penalty for large de-\ngrees, and the constants $C_1, C_2, ..., C_{vmax}$ reflect the rel-\native desirability of each integer degree within the allow-\nable range. A similar function $R_c(\\kappa_c)$ can be defined\nfor check nodes. In our demonstration using hypergraph\nproduct codes we have $V_{max} = 3$. The gap between the\nvalues of $C_3$ and $C_2$ was set to be close, with both around\n0.7 to 1.0, while $C_1$ was set to be a smaller value around\n0.1 to 0.5. The precise values were adjusted empirically\nbased on training results to encourage degree distribu-\ntions to avoid under-utilizing check operators.\nWe min-max normalize each local reward\n$R_v(\\kappa_v), R_c(\\kappa_c)$ and the distance-based terms $d, \\Delta d$\nto fall in the interval [0, 1]. Specifically, for any quantity\nX that lies in [$X_{min}, X_{max}$], the min-max normalized\nversion $\\hat{X}$ is defined as\n$\\hat{X} =\n\\frac{X - X_{min}}{X_{max} - X_{min}},                                                      \\quad X \\in [0,1].$\n                                                        (3)\nThe normalized quantities $\\hat{R}_v(\\kappa_v), \\hat{R}_c(\\kappa_c), \\hat{d}, \\widehat{\\Delta d}$ are de-\nfined analogously. The minima and maxima are\ndetermined from known bounds of the code dis-\ntance [dmin, dmax], and viable degree distributions for\n$R_v(\\kappa_v), R_c(\\kappa_c)$.\nThe reward is formulated as\n$\\hat{R} = \\alpha(\\sum_{v\\in V} \\hat{R}_v(\\kappa_v) + \\sum_{c\\in C} \\hat{R}_c(\\kappa_c)) + \\beta \\hat{d} - \\delta \\widehat{\\Delta d}$,\n               (4)\nwhere V and C are variable and check nodes, $\\kappa_v$ and\n$\\kappa_c$ are their degrees, d is the code distance, and $\\Delta d =$\n$d_{new} - d_{prev}$ is the change in distance. The weights $\\alpha,$\n$\\beta$, and $\\delta$ balance degree reduction, distance preservation,\nand penalize distance reductions. The weights sum to 1\nto ensure the reward is between 0 and 1."}, {"title": "To enforce weight constraints on parity checks, we em-\nploy action masking:", "content": "$M(a|s) =  \\begin{cases}\n1, & \\text{if action a is permissible in state s,}\\\\\n0, & \\text{otherwise,}\n\\end{cases}$\n                              (5)"}, {"title": "III. MAIN RESULTS", "content": "We now showcase the representative code discovery re-\nsults achieved through our RL weight reduction scheme\nand discuss important comparisons with existing results.\nAdditional information including more complete data\nand numerous auxiliary results and illustrations can be\nfound in the Supplementary Information.\nWe extend the standard [n,k,d] notation for QEC\ncodes (n, k are the number of physical and logical qubits\nrespectively and d is the code distance) to [n, k,d](w,q),\nwhere w denotes the check weight and q denotes qubit\ndegree."}, {"title": "A. Overview of code discovery", "content": "Here we primarily focus on the following setting: we\napply our RL agent to hypergraph product codes, and\naim to reduce to a maximum weight of six and qubit\ndegree of three, matching the parameters produced in\nRef. [46]. These are favorable parameters for practical\nimplementation and also allow us to make direct com-\nparisons. Note that our method can be adapted for any\ngiven weight or degree, and we also show examples for\nmaximum weight eight and degree four. Furthermore,\none can easily apply our method to general stabilizer\ncodes settings and specialize to certain types including\nCSS codes, product codes, k-orthogonal codes and so on\nas needed, as addressed in Sec. II by adapting the action\nmasking logic accordingly.\nHypergraph product codes [62] provide an elegant\nframework for constructing quantum codes from classi-"}, {"title": "cal ones and serve as a prototypical model in the study\nof qLDPC codes with desirable code parameters and FT\nproperties [18, 62-64]. More explicitly, given parity check\nmatrices of classical codes $H_1$ and $H_2$, define", "content": "$H_x = (H_1 \\otimes I_{n_2} I_{r_1} \\otimes H_1^T)$,                        (6)\n$H_z = (I_{n_1} \\otimes H_2 H_2^T \\otimes I_{r_2}),$                        (7)\nrepresent the X and Z check matrices of a CSS code re-\nspectively. Here $H_1$ and $H_2$ are the check matrices of\nthe original classical codes, and I denotes identity matrices\nof appropriate dimensions. This construction ensures or-\nthogonality between $H_x$ and $H_z$ for any pair of linear\nclassical codes and therefore produces a valid CSS stabi-\nlizer code. In this work we use the same classical code\nfor $H_1$ and $H_2$.\nWe generate new codes by executing our RL scheme on\nhypergraph product base codes constructed from all clas-\nsical codes with n < 30 from the best known linear codes\ndatabase in the GUAVA package in GAP [65, 66], which\nwe collectively refer to as HGP-30. Several examples of\ncodes with particularly large distances beyond this range\nwill also be included. All results were produced using\nan i7-13700HX CPU and RTX-4060 GPU. With more\nextensive training it is feasible to further optimize code\nparameters or scale to larger sized codes [67]."}, {"title": "IV. CONCLUSION AND OUTLOOK", "content": "In this work, we introduced a powerful new scheme\nfor designing low-weight stabilizer QEC codes based on\na highly efficient RL-based algorithm for weight reduc-\ntion, which takes the effective route of starting with a\ncode with the target distance and then optimizing weight,\nrather than designing a code from scratch. This method\nenables the discovery of an abundance of new low-weight\ncodes that extend well beyond the previously accessi-\nble code parameter regime even with modest computa-\ntional resources. In particular, while existing numeri-\ncal methods generally stagnate at single-digit distance\ncodes, our approach systematically generates efficient\nlow-weight codes with distances in the tens a regime\nexpected to be crucial for experimental developments in\nthe coming years. As low-weight QEC codes are criti-\ncal components of fault-tolerant quantum computing, our\nfindings pave the way for more feasible implementation\nof high-performance QEC, potentially bringing fault tol-\nerance closer to realization in the near future.\nMoreover, from the machine learning perspective, we\nhave demonstrated that RL is particularly well-suited for\nstabilizer code design problems and, notably, far more\nscalable than previously thought. Our simple model is\nable to circumvent previous obstacles in designing codes\nwith high distance and low weight, and exhibit great po-\ntential for further scalability, as discussed. Our current\nresults are produced by running on 16 cores, and with\nabout a thousand cores we expect to be able to design\nproduct codes with a few million qubits and non-product\ncodes with a few thousand qubits."}]}