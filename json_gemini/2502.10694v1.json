{"title": "Simulations of Common Unsupervised Domain Adaptation Algorithms for Image Classification", "authors": ["Ahmad Chaddad", "Yihang Wu", "Yuchen Jiang", "Ahmed Bouridane", "Christian Desrosiers"], "abstract": "Traditional machine learning assumes that training and test sets are derived from the same distribution; however, this assumption does not always hold in practical applications. This distribution disparity can lead to severe performance drops when the trained model is used in new data sets. Domain adaptation (DA) is a machine learning technique that aims to address this problem by reducing the differences between domains. This paper presents simulation-based algorithms of recent DA techniques, mainly related to unsupervised domain adaptation (UDA), where labels are available only in the source domain. Our study compares these techniques with public data sets and diverse characteristics, highlighting their respective strengths and drawbacks. For example, Safe Self-Refinement for Transformer-based DA (SSRT) achieved the highest accuracy (91.6%) in the office-31 data set during our simulations, however, the accuracy dropped to 72.4% in the Office-Home data set when using limited batch sizes. In addition to improving the reader's comprehension of recent techniques in DA, our study also highlights challenges and upcoming directions for research in this domain. The codes are available at https://github.com/AIPMLab/Domain_Adaptation.", "sections": [{"title": "I. INTRODUCTION", "content": "Rapid advancement in the field of deep learning has led to the emergence of novel approaches that exhibit remarkable performance in various domains, however, achieving high levels of performance with deep learning typically requires a large number of well-annotated training data, which can be challenging to acquire [1], particularly in healthcare. Another problem often encountered in deep learning techniques arises from the fact that the data used to train the model may have different characteristics from the data on which the model is evaluated [2]. This shift in distribution inevitably leads to a severe drop in performance, as the model cannot generalize well to these new data. In the literature, this problem is commonly referred to as domain adaptation (DA) [3]. Conceptually, DA refers to scenarios where the source and target tasks are identical but the data distributions of the source and target domains differ. In most cases, many labeled samples from the source domain are available, while the target domain has either no labeled samples or only a few. Depending on whether the target domain has labeled data or not, DA can be subdivided into the following three categories: 1) Supervised DA where the target domain data are all labeled, 2) Semi-supervised DA in which part of the target domain data is labeled, and 3) Unsupervised DA where target domain data are without labels. As illustrated in Figure 1, applying a model trained on data from the source domain directly to samples from the target domain leads to poor performance. By reducing the discrepancy between domains, DA methods can effectively improve model performance.\nDA methods have been proposed for a wide range of applications in computer vision [4]. One of the most prevalent applications of DA in this field is image classification [5]. For example, the authors of [6] proposed a DA technique that gradually expands the source data with the target data, thus improving the performance model. DA research has also focused on the task of semantic segmentation [7], where the goal is to assign a class label to each pixel in a given image. For example, the work presented in [7] introduces a novel source-free open compound DA method for segmentation. This method considers data privacy, multiple target domains, and open, unseen domains. The authors also proposed a cross-patch style swap strategy to enhance the feature-level style of the training samples.\nFurthermore, DA has also played an important role in the healthcare field. For example, in [8], they developed unsupervised DA for brain MRI segmentation tasks, achieving higher performance compared to other supervised models. This method greatly reduces the time for manual annotations. In [9], they proposed a source-free DA, which uses adversarial sample augmentation and performs self-adaptation to improve the model performance. It shows great value for data privacy"}, {"title": "II. BACKGROUND", "content": "There exist certain factors that serve as motivators for the implementation of DA. The initial aspect pertains to the inherent characteristics of big data technology, which facilitates the acquisition of vast amounts of data to use in training and updating machine learning processes. However, a significant portion of the data is unique, which requires users to assign appropriate labels to them. To utilize DA effectively, it is advantageous to incorporate labels by identifying data that share a similar labeling with the target data. However, the available training data are constrained, even though numerous applications are filled with complexities and uncertainties. Especially for medical-related applications, accessing large medical data is often considered not practical due to the limited number of cases and privacy leakage problems. DA, in other words, allows one to apply uncontrollable overheads to a broader range of new situations and cases."}, {"title": "A. The definition of unsupervised domain adaptation", "content": "Given two data domains $D_s = \\{x_i, y_i\\}_{i=1}^{N_s}$ and $D_t = \\{x_j, y_j\\}_{j=1}^{N_t}$, where x and y represent samples and labels, respectively. In cases where the feature space $X$ and the class space $Y$ exhibit similarity, but their joint distributions differ ($P_s(x,y) \\neq P_t(x, y)$), a common approach is to use the data of the source domain to train a prediction function $f : X_t \\rightarrow Y_t$ that minimizes prediction loss (denoted by $l$) in the target domain [2].\n$f^* = arg \\min_f E_{(x,y)\\in D_t} [l(f(x), y)].$ \t\t(1)\nHowever, in UDA, the labels for the target data $y$ are not available during training. The objective is to minimize the prediction loss using labeled source data and unlabeled target data, thereby training a robust classifier that generalizes to the target domain."}, {"title": "B. Why is domain adaptation developing rapidly", "content": "This section classifies UDA into two distinct types: traditional UDA, and UDA that uses deep learning methodologies. In this type of classification, traditional UDA refers to techniques such as TCA, which are more primitive and rely on classical ML methods and hand-crafted/extracted features. Unlike traditional UDA, deep learning-based UDA approaches mainly rely on the dominant feature extraction ability of deep neural networks, further aligning the features of the source and target data directly on fully connected layers, offering better adaptation capabilities and convenience. We selected papers based on their relevance in the paper title, abstract, and the quality of the paper, such as the number of citations in Google Scholar. Figure 3 illustrates the timeline of common traditional and deep learning based DA techniques. The following Sections, including Section IV, will provide a more detailed explanation of these DA methods."}, {"title": "III. THE TYPES OF UNSUPERVISED DOMAIN ADAPTATION", "content": "The use of traditional DA establishes a robust basis for advancing DA in the future. When considering small datasets, traditional DA is superior to deep neural networks. The present study highlights the prevalent divergence measures used in DA, including MMD [10], Correlation Alignment (Coral) [11], Contrastive Domain Discrepancy (CDD) [12].\nMMD based techniques. For example, the Transfer Component Analysis (TCA) method, as described in [13], uses the MMD distance metric to evaluate the degree of marginal distribution discrepancy between the source and target domains. MMD, a conventional technique for computing distribution dissimilarity, has undergone several decades of development and has derived some enhanced methodologies. In [14], they introduced a technique called Joint Distribution Adaptation (JDA) that simultaneously adjusts the marginal MMD distance and the conditional MMD distance to improve the adaptation performance. According to [15], existing UDA methods based on MMD do not account for the variations in the prior class distributions, thus contributing to the deterioration of DA performance. The proposal is for a weighted MMD approach that incorporates class-specific weights that account for the prior probability of each class. After related experiments, the results show that the weighted MMD is better than the traditional MMD method. The authors of [16] presented a novel discriminative joint probability MMD (JP-MMD) approach to enhance inter-domain transferability by accounting for the discriminability of distinct classes in UDA. In contrast to the conventional MMD approach for computing distribution dissimilarity, JP-MMD enhances transferability and discriminability across diverse domains while being more straightforward and precise.\nCorrelation alignment based techniques. Coral is a conventional technique for domain alignment that primarily attains the linear transformation of the source and target domains to align the second-order features of both domains. On the basis of this method, some new methods are also produced. Deep Coral is one of the very well-known methods. To alleviate the problem of domain mismatch between training and test data sets due to statistical differences, in [17], a new unsupervised DA based on Coral was proposed. In their approach, they improved the Coral algorithm into the Coral++ algorithm for speech recognition. Furthermore, the algorithm has shown excellent results in many tests.\nContrastive alignment based techniques. The use of CDD is prevalent in UDA techniques [18]. The authors of [18] introduced a novel framework for Source-Free Domain Adaptation (SFDA). The CDD method was incorporated into the framework to enhance intra-class compactness and inter-class separability. Furthermore, the experimental findings indicate that the SFDA approach outperforms conventional UDA techniques using source data."}, {"title": "A. Traditional unsupervised domain adaptation", "content": "Generative Adversarial Network (GAN) was initially introduced as a zero-sum game. Artificial intelligence has recently witnessed a surge in interest towards a particular area, as noted by Goodfellow in his work on generative models [19]. The model can be partitioned into two distinct components: the generator and the discriminator. The generator and the discriminator engage in adversarial training to enhance their respective capabilities. The Domain-Adversarial Neural Network (DANN) [20] was the first adversarial UDA. The DANN method takes advantage of the inherent features of the adversarial generative network. The feature extractor and domain discriminator engage in a reciprocal training process to acquire domain-invariant features throughout the training procedure.\nBased on the previous DANN method, more methods are derived from it. For example, inspired by Wasserstein GAN, in [21], they introduce the Wasserstein distance to guide the"}, {"title": "B. Unsupervised domain adaptation based on deep learning", "content": "Furthermore, in [22], they demonstrate that using a single domain discriminator is insufficient for fine-grained alignment of different data distributions, further proposing a multi-discriminator adaptation network. Empirical studies indicate that the proposed model outperform SOTA methods with linear-time complexity. Furthermore, in [23], they introduced adversarial DA into partial DA, where the source label space differs from the target label space. Experiments show that it can outperform SOTA results for partial DA. In [24], they extended the DANN to dynamic adversarial adaptation (DAAN). They introduced a balancing parameter to control the impact of the global feature domain classifier and the local feature domain classifier. Experiments demonstrate that their method can improve the performance of DANN in natural image classification tasks. In [25], the authors suggested that domain mix-up [26] can further guide the domain discriminator in judging the differences of samples relative to the source and target domains. Experimental results using the Office-31 dataset demonstrate that their method can achieve an average accuracy of 81.6%. Furthermore, in [27], the authors improved the traditional DANN method and proposed a new DA technique called DANN-IB, which can improve the ability to learn features relevant to the task. Experiments on three benchmark datasets using the DANN-IB framework show that the DANN-IB has better stability than the general method. In [28], they rethought adversarial UDA methods, hoping to adequately learn domain-specific representations to alleviate performance degradation caused by subtle domain shifts. So, they propose the orthogonal decomposition adversarial UDA architecture, which can efficiently extract domain-invariant representations. Extensive experiments demonstrate the effectiveness of this method. Furthermore, in a recent work [29], they proposed a novel sparse adversarial domain adaptation model for the classification of traffic scenes. Experimental results in a real-world dataset indicate the impressive results of their method.\nFurthermore, in [30], they explored unpaired image-to-image translation tasks with GAN. Unlike paired image-to-image translation, they considered a training set and a test set with different style (e.g., texture shifts), then performed a cycle consistency loss to ensure the training process of GAN. The goal of their approach is to learn a model that can translate an image from a source domain X to a target domain Y in the absence of paired examples. Similarly, in [31], they maintained that models trained purely on synthetic images often fail to generalize to real images, thereby introducing a GAN to perform pixel level adaptation. Experimental results in the USPS dataset indicate that their method can achieve SOTA accuracy. In [32], feature space adaptation methods periodically fail to capture pixel-level and low-level domain shifts. Image-space approaches often miss high-level semantic knowledge. They proposed using GAN to perform both pixel-level and feature-level adaptations. The experimental results show competitive accuracy in the classification tasks of digits. In [33], they propose a novel UDA method that performs entropy minimization with adversarial training for semantic segmentation. Experiments using GTA5 and Cityscapes datasets demonstrate the effectiveness of their method in synthetic-2-real setup. In [34], they explore the source free UDA with adaptive adversarial network adaptation. The contrastive and self-supervised learning techniques are employed to enhance the target classifier performance. Experiments on Office-31 indicate that their method can achieve an average accuracy of 90.1% without accessing source data. In [35], they introduced adversarial self-training (AST). AST notably improves both adversarial and clean accuracy in the target domain for gradual DA tasks. They included a case study explaining why AST enhances accuracy.\nHowever, does GAN necessarily require a special discriminator? In [36], the authors introduced the first discriminator-free adaptive learning network (DALN), which has a good classification effect on some universal datasets in 2022. The method mainly reuses the category classifier as a discriminator again. Recently, the authors of [37] proposed Spectral Unsupervised UDA for Visual Recognition (SUDA) that uses a spectrum transformer to address inter-domain discrepancies. Furthermore, they also proposed a multiview spectral learning procedure that can learn useful feature representations."}, {"title": "1) Unsupervised domain adaptation based on adversarial:", "content": "Similarly to traditional UDA, non-adversarial deep learning based DA can be further grouped into methods based on MMD, correlation alignment, and other approaches. MMD based adaptation. For example, in [38], the authors proposed a deep domain confusion (DDC) technique to solve adaptive problems of deep networks for both supervised DA and UDA. Their method mainly used the Alex-net network [39] pre-trained on the ImageNet data set for DA learning. Then, they fixed the first seven layers of Alex-net and added adaptive metrics to the 8th layer, resulting in higher improved performance. In [40], they extended the work of DDC, further introduced Deep Adaptation Networks (DAN), a method that simultaneously adds three adaptive layers to constrain the features by adopting the multi-kernel MMD (MK-MMD) metric. Furthermore, condition-based, joint, and dynamic distribution adaptive methods based on MMD have been proposed. For example, the deep subdomain adaptation network (DSAN) [41] is an extensive and flexible distribution adaptation method through a weighted MMD measurement for feature alignment. DSAN achieves feasible performance on many natural datasets such as Office31 and OfficeHome. Given the significant performance improvements achieved by the DSAN method over traditional neural network-based DA networks such as DDC and DAN, numerous researchers have shown interest in further enhancing the DSAN model. For example, in [42], they attempted to improve the DSAN method by proposing a new DA method called the Deep Subdomain Associate Adaptation Network (DSAAN) and its application to EEG emotion recognition. The adaptive process of the method is achieved by minimizing the domain classification loss and the Subdomain Associate Loop. Furthermore, several modified methods have shown that DSAAN has remarkable classification ability. In [43], they proposed a modified DSAM method, referred to as the sub-DA feature alignment architecture,"}, {"title": "2) Unsupervised domain adaptation based on non-adversarial:", "content": "In [46], they propose that the DA process can be achieved by reducing the discrepancies in higher-order statistical features (e.g., second-order moment features) between the source and target domains. Inspired by the traditional second-order"}, {"title": "IV. A BRIEF OVERVIEW OF COMMONLY USED DOMAIN ADAPTATION TECHNIQUES", "content": "Generative Adversarial Networks (GANs) were first introduced into DA in [20]. The technique relies on training a domain classifier to distinguish between data from the source and target domains. In particular, the domain classifier computes the loss and determines whether the data originate from the source or target domain. A gradient inversion layer is added between the domain classifier and the feature extractor during the parameter update phase of backpropagation. The input data are correctly classified into the right domain category (source or target domain) by the domain classifier according to this layer. In addition, they designed a feature extractor to be trained to do the opposite things (due to the gradient inversion layer), to build an adversarial relationship by making the extracted features not accurately classified by the domain discriminator. Figure 4 illustrates the DANN pipeline. For each iteration, batches of 2B samples are randomly generated by selecting the same number of source and target samples. The adversarial DA loss is defined using cross-entropy, as follows:"}, {"title": "A. Domain adversarial neural networks", "content": "$L_{DA} = \\frac{1}{2B} \\sum_{j=1}^{2B} z_j log \\mathcal{D}_i(I_j) + (1 - z_j) log (1 - \\mathcal{D}_i(I_j))\t\\t(2)$\nwhere $z_j = \\mathbb{1}(x_j \\in D_i)$ the domain label of example $x_j$. $I_j$ are the features extracted by $e_f$. The domain classifier $D$ predicts if a given image representation $I_j$ is from a source ($\\mathcal{D}_i(I_j) = 1$) or a target domain ($\\mathcal{D}_i(I_j) = 0$)."}, {"title": "B. Deep Coral", "content": "moment feature alignment method (Coral), they propose an end-to-end covariance-based feature alignment method (Deep Coral). It can be incorporated into various strata of Deep Neural Networks and various neural network configurations.\nTo simplify, suppose that $n_s$ and $n_T$ represent the quantities of source and target data, respectively, with $D_i^s (D_i^t)$ denoting the value in the j-th dimension of the i-th data sample from the source (target) domain. Assume $C_s$ and $C_T$ denote the covariance matrices for the source and target domain, their Deep Coral metric can be expressed as follows.\n$\\ell_{Coral} = \\frac{1}{4d^2} ||C_s - C_T||^2_F$\t\t(3)\nwhere $||.||_F$ is the square of the Frobenius norm of a matrix. The dimensionality of the matrix is indicated by the variable d. Specifically, the covariance matrices of both source and target data can be measured as follows:\n$C_s = \\frac{1}{n_s - 1} (D_s^T D_s - (1^T D_s) (1^T D_s))$\t\t(4)\n$C_T = \\frac{1}{n_T - 1} (D_t^T D_t - (1^T D_t) (1^T D_t))$\t\t(5)\nThe final loss of deep Coral is expressed as follows.\n$\\ell_{loss} = \\ell_{cla} + \\ell_{Coral}$\t\t(6)\nwhere $\\ell_{cla}$ is the classification loss."}, {"title": "C. Deep subdomain adaptation network", "content": "Categorizing similar samples into distinct subdomains within a larger domain, guided by various criteria, such as class labels, has been proposed in [41]. This strategy results in subdomains that cover identical classes, and this particular study uses class categories as the basis for segmentation. Instead of focusing on a comprehensive alignment throughout the domain, this approach emphasizes the independent matching of these localized subdomains.\nThe core of DSAN is to use the local maximum mean discrepancy (LMMD) for DA instead of MMD. Typically, MMD focuses only on feature alignment in the whole dataset, but for many datasets with imbalanced classes, the classes with fewer samples may be incorrectly aligned within the categories with more samples, leading to incorrect DA effects. LMMD, which considers the impacts of each class by introducing weights to different classes, can effectively eliminate this problem. Suppose H is the reproducing kernel Hilbert space (RKHS) endowed with a characteristic kernel $\\phi : X \\rightarrow H$. $\\phi(\\cdot)$ is a mapping function that maps the original samples to the RKHS space. The MMD metric can be measured as follows.\n$\\delta_H(p,q) = ||\\frac{1}{n_s} \\sum_{x_i \\in D_s} \\phi(x_i) - \\frac{1}{n_t} \\sum_{x_j \\in D_t} \\phi(x_j)||^2_H$\t(7)\nBased on MMD, LMMD has achieved the best results among metric-based methods in recent years, and unlike MMD, it focuses on the discrepancy of local distributions. And their LMMD is defined as:\nd$\\chi (p,q) = E_c [||E_{p(c)} [\\phi (x^s)] - E_{q(c)} [\\phi (x^t)]||^2_H ]$\t(8)"}, {"title": "D. Batch nuclear-norm maximization", "content": "The authors in [52] suggest that the ability of a model to distinguish tends to reduce when used with unlabeled data. Thus, they propose the use of entropy constraints as a technique to improve the model's ability to discriminate between classes. However, this approach may result in samples from a few classes being incorrectly classified as the majority class, which may affect the diversity of model predictions. To address this issue, they used F-norm and matrix rank to constrain distinguishability and diversity, respectively. To be more efficient, they propose to use the nuclear norm to approximate the rank of the matrix. They show a lower bound and an upper bound based on the nuclear norm as follows:\n$\\frac{1}{\\sqrt{D}}||A||_* \\le ||A||_F \\le ||A||_* < \\sqrt{D}||A||_F$ \t(10)\nwhere $D = min(B, C)$. B and C here are the batch size and the number of classes, respectively. $||A||_*$ is the Nuclear-norm of matrix A."}, {"title": "E. Safe self-refinement for transformer-based domain adaptation", "content": "The SSRT algorithm [53] uses a ViT a technique well recognized in the domain of natural language processing [54] to enhance the adaptability of models through judicious predictions on perturbed target domain data [55]. In particular, perturbations are applied to the hidden label sequence of the target domain data by introducing random offsets. The Kullback-Leibler (KL) divergence is minimized as a measure of the discrepancy between the model's predicted probabilities under the original and perturbed conditions.\nThe framework of SSRT is illustrated in Fig. 5. It should be noted that only data from the target domain are displayed here. Examining Fig. 5 (Left), it can be seen that there are four main components, namely, the TF block, the classifier, the KL divergence, and the Ptch Emb. The TF block is a ViT that is utilized as the entire network. The classifier is utilized for image categorization. Regarding Ptch Emb, the patch Embedding layer transforms the target domain data into a sequence of tokens, which comprise a specific category token and image tokens. Subsequently, they employed TF Blocks to refine this progression. The classifier processes the category token and produces a label prediction. About its random offset, assume that $x$ represents a target domain image and $b_e$ is a latent representation of $x$ in a hidden space. Instead of using only $b_e$ to perturb the token sequence, they tend to use another target domain image $x_r$ to better perturb the token sequence, which can be represented as:\n$\\hat{b}_e = b_e + [b^r_e - b_e]\\times \\lambda$\t\t(11)\nwhere $\\lambda$ is a scalar and [] means no back-propagation. The Kullback-Leibler divergence [56] measures the dissimilarity between the distributions of samples from the source and target domains. The KL divergence is defined as:\n$D_{KL}(p_t||p_s) = \\sum_i p_t(i) log \\frac{p_t(i)}{p_s(i)}$\t\t(12)\nwhere $p_t, p_s$ are target sample probability and source sample probability. Notice that the KL distance is asymmetric, which means $D_{KL}(p_t||p_s) \\neq D_{KL}(p_s||p_t)$. Based on this, the authors claimed in their paper that using both KL distances concurrently results in a more resilient model:\n$\\ell_{SR} = E_{B_t~D_t} [\\omega E_{x~F[B_t;p]} D_{KL}(p_s||p_t) + (1-\\omega) E_{x~F[B_t;p]} D_{KL}(p_t||p_s)]$\t\t(13)\nTo obtain reliable results, they adopt a Confidence Filter F. To decrease the risk of model collapse, they then proposed a Safe Training mechanism to learn the model. Their confidence filter F can be defined as:\n$F[D;p] = \\{x \\in D|max(p_x) > \\epsilon\\}$\t\t(14)\nwhere e is a predefined threshold.\nRegarding the Safe Training mechanism, it is expected that when the model begins to crash, the diversity of model predictions will reduce simultaneously. Therefore, the core idea is to find such collapses during the training process. Once it occurs, the learning setting is reset, and the model is restored to a previous success state. To achieve this, the authors proposed that an adaptive scalar $r \\in [0, 1]$ is used to adjust $\\alpha$ and $\\beta$, i.e., $\\alpha_r = r \\alpha$ and $\\beta_r = r \\beta$ [53]. Furthermore, they propose a fixed period T and divide the training procedure into successive intervals. At the end of each interval, the model snapshot will be saved simultaneously. Then r is defined as:\nr(t) = \\begin{cases} sin( \\frac{\\pi}{2T} (t - t_r)), t - t_r < T_r\\\\ 1.0, otherwise \\end{cases}\t\t(15)\nwhere t represents the current training step. To begin with, they set $T_r = T$ and $t_r = 0$. Then r will increase to 1 by taking T steps. At the end of each interval, according to their Safe Training mechanism, if there is no abrupt drop, r remains the same. Otherwise, $t_r$ is reset to the current training step t, and the model is restored to the last snapshot. Figure 5 (Right) shows the Safe Training mechanism. Note that the diversity of droppings is marked with pink areas.\nTo determine the diversity of dropping, they proposed a diversity of measurement:\ndiv(t; B_t) = unique_labels(h(B_t))\t\t(16)\nwhere $B_t$ is a batch of each target training samples, unique_labels is the unique model predicted labels on target domain.\nIn the end, the losses of their model can be formulated as:\n$\\ell = \\ell_{CE} - \\ell_d + \\beta \\ell_{SR}$\t\t(17)\nwhere the aforementioned equation involves three distinct loss functions, namely, the cross-entropy loss on source data denoted by $\\ell_{CE}$, the adversarial loss denoted by $\\ell_d$, and the self-refinement loss denoted by $\\ell_{SR}$. The parameter $\\beta$ represents a trade-off between two or more variables."}, {"title": "V. DOMAIN ADAPTATION MODELS\u2019 PERFORMANCE", "content": "This section provides a summary of the metrics typically employed when assessing the performance of DA models. Furthermore, this section reports the performance of image classification models on benchmark datasets. We have provided an in-depth description of the datasets used in Subsection V-B, while the others have been enumerated in Table I."}, {"title": "A. Metrics for domain adaptation models", "content": "In image segmentation tasks, Intersection over Union (IoU) and Dice coefficient (Dice) are commonly used metrics [86]. On the other hand, for classification or recognition tasks, Accuracy, Precision, Recall, Specificity, Area under the ROC curve (AUC) and F1 score are commonly used [87]."}, {"title": "B. The benchmark datasets commonly used in domain adaptation", "content": "Table I provides an overview of the data sets frequently used in the domain of DA, which have been classified primarily by their application, including handwritten digit recognition, image classification, activity recognition, semantic segmentation, sentiment classification, speech recognition, medical imaging, and face recognition. However, some of these datasets are outdated (e.g., MNIST, Image_CLEF), with many approaches such as DSAN and SSRT, achieving more than 98% accuracy. With the development of neural networks, the outdated datasets are not suitable for evaluating current"}, {"title": "VI. EXPLORING DOMAIN ADAPTATION TECHNIQUES", "content": "Currently, the most prevalent applications of DA are in image classification, where it has demonstrated feasible performance in many natural and medical datasets [90], [91]. The results in Table IV show that DA significantly increases accuracy and effectively minimizes data distribution discrepancies caused by different capturing devices. This study further examined the potential of DA, specifically in image classification tasks, under various conditions."}, {"title": "A. Experiments using common neural networks", "content": "This study tested these algorithms using common neural networks. First, the neural networks commonly used in DA were ResNet50, ResNet34, and AlexNet. The data set for the experiments is the Office-Home dataset. Table IV reports the classification results using the Office-Home dataset. All DA algorithms show a substantial performance improvement when using ResNet50 compared to CNN alone. For example, our simulations show that DCAN can improve the ACC with large margins (e.g., > 20% on task R to P) compared with ResNet50 alone, as reported in Table IV. Similarly, there is a large increase in performance when the network is upgraded from AlexNet to the ResNet series; however, there is less enhancement when changing from ResNet34 to ResNet50."}, {"title": "B. Experiments with modern unsupervised DA dataset", "content": "Although these algorithms have remarkable performance using the Office31 data set, the model might use a series of tricks to achieve biased performance. Thus, this study further uses one more unsupervised DA dataset named Modern Office-31 [92] to verify these methods. This dataset has four domains, namely amazon (A), webcam (W), dslr (D) and synthetic (S). Similarly to Section V-B, four domains were used to build 12 DA tasks. More details of the implementation can be found in Table II. The DA benchmark test used the following training parameters: mini-batch SGD optimizer with a learning rate of 0.01, batch size of 16, weight decay of 0.0005, momentum of 0.9, 30 rounds of training, and 200 iterations per round. Table V reports the highest test accuracy in the target domain. DANN shows the best performance gain (+9.4%) compared to ResNet50 alone in ModernOffice31 dataset. Deep Coral indicates the lowest performance boost (+0.4%) compared to ResNet50 alone. Surprisingly, DANN outperforms recent DA methods such as DSAN, BNM, which shows the potential to use adversarial methods for DA. Especially for synthesis images, DANN achieves the highest accuracy with a large performance improvement (e.g. > 10%). Furthermore, Figure 6 shows the representations learned using t-SNE for these techniques on task A\u2192D and S\u2192A, respectively. The use of DA leads to better features alignment results compared to ResNet50 alone, particularly using DCAN and DSAN. This highlights the potential of DA for feature adaptation."}, {"title": "C. Experiments with cross-dataset settings", "content": "Even though these DA techniques demonstrate remarkable performance in standard benchmark datasets, the ability to generalize across various datasets remains a significant challenge. Therefore, this study selected the commonly occurring categories (backpack, bike, bottle, calculator, desk lamp, file cabinet, keyboard, laptop, monitor, and mouse) from office31 and the office-home data set, to test the generalizability of these DA methods. Specifically, the study involved the selection of the Amazon (A) and Webcam (W) domains from Office-31, as well as the Art (Ar) and Real World (R) domains from Office-Home for testing. The benchmark test conducted using AlexNet, ResNet34 and ResNet50 without DA used the same training parameters as indicated in Seciton VI-B. Table VI shows the classification accuracy using these approaches. The Deep Coral algorithm exhibited minimal gains in performance using a shallow network such as AlexNet. Furthermore, when deeper neural networks such as ResNet34 and ResNet50 were used, the algorithm demonstrated limited performance improvement or even negative growth. This leads to the algorithm's limited ability to generalize well when tested on different datasets. Furthermore, the DSAN algorithm shows a performance improvement of 3%-4% compared to those without DA. On the other hand, the DANN algorithm shows a relatively slight improvement using ResNet34, which can be attributed to its limited feature extraction ability to generalize during cross-dataset testing. This suggests that adversarial based techniques may fail to align the feature distributions with inappropriate deep networks. In terms of the BNM algorithm, when applied to AlexNet, it shows a significant performance improvement of 6.6%. However, when applied to ResNet, the improvement is comparatively smaller, ranging between 1% and 4%. Furthermore, the use of CNN alone in cross-dataset context shows better performance compared with the results under the same dataset as previously mentioned in Table IV. The primary reason for this discrepancy is the class scale. OfficeHome and Office31 have 65 and 31 classes, respectively, whereas the cross-dataset has 10. Clustering of data samples on a small class scale is less challenging than under a large scale."}, {"title": "D. Experiments under different data quality", "content": "The previously mentioned datasets such as OfficeHome and Office31 assume that the data from the source and target domains are of high quality (e.g., without noise or corruption). However, this assumption is impractical in real-world situations. Therefore, we validate the usefulness of DA techniques under different data quality. In particular, ImageNet with different levels of Gaussian noise selected from Imagenet-C [65"}]}