{"title": "A Two-Stage Machine Learning-Aided Approach for Quench Identification at the European XFEL", "authors": ["L. Boukela", "A. Eichler", "J. Branlard", "N.Z. Jomhari"], "abstract": "This paper introduces a machine learning-aided fault detection and isolation method applied to the case study of quench identification at the European X-Ray Free-Electron Laser. The plant utilizes 800 superconducting radio-frequency cavities in order to accelerate electron bunches to high energies of up to 17.5 GeV. Various faulty events can disrupt the nominal functioning of the accelerator, including quenches that can lead to a loss of the superconductivity of the cavities and the interruption of their operation. In this context, our solution consists in analyzing signals reflecting the dynamics of the cavities in a two-stage approach. (I) Fault detection that uses analytical redundancy to process the data and generate a residual. The evaluation of the residual through the generalized likelihood ratio allows detecting the faulty behaviors. (II) Fault isolation which involves the distinction of the quenches from the other faults. To this end, we proceed with a data-driven model of the k-medoids algorithm that explores different similarity measures, namely, the Euclidean and the dynamic time warping. Finally, we evaluate the new method and compare it to the currently deployed quench detection system, the results show the improved performance achieved by our method.", "sections": [{"title": "1. INTRODUCTION", "content": "Fault detection plays a crucial role in ensuring the safe and optimal operation of complex systems. Traditional model- based approaches, although widely explored, have some limitations in their ability to isolate all possible faults, especially those with evolving patterns as complete models are usually hard to obtain. Machine learning (ML) approaches, on the other hand, are simpler and handle more effectively complex systems, however, their performance relies heavily on the data quantity and quality. Hybrid solutions seem to be promising although the choice of methods to integrate is challenging (Wilhelm et al., 2021). A hybrid method is thus developed for our case study, i.e., the problem of quench detection at the European X-Ray Free-Electron Laser (EuXFEL), where a fault detection method based on physical model residuals and data-driven clustering for fault isolation are combined.\n\nThe EuXFEL is the largest particle accelerator for X-ray laser generation worldwide. Along with the high-voltage power supplies, the klystrons and the waveguides, the superconducting radio-frequency cavities (SRFCs), are key components of the power transfer chain to the electron beam. The plant's linac comprises hundreds of 1.3 GHz TESLA-type cavities, controlled and monitored with the low level radio frequency (LLRF) system and operated in a pulsed mode with a pulse repetition rate of 10 Hz and at an average gradient of 23.6 MV/m (Reschke et al., 2017). This enables the three self-amplified spontaneous emission undulators to generate up to 27000 photon flashes every second. This setup is exploited by several hundred interdisciplinary users every year to carry out their experiments.\n\nEnhancing the availability, safety and reliability of the accelerator is therefore crucial to meet the demand, minimize potential energy and financial losses and avoid the degradation of the facility. In this context, the behavior of the SRFCs is monitored through the LLRF system to detect and report the faulty events, especially quenches. These are severe faults that cause a loss of the superconductivity of the SRFCs and thus an operation downtime. If a quench goes undetected, it has the potential to generate sufficient heat that can lead to disturbances in the helium flow of the cryogenic system and to an operation interruption that could last up to 24 hours.\n\nA quench detection system (QDS) has been deployed at the EuXFEL since its first commissioning in 2017 (Branlard et al., 2013). It relies on a statistical analysis of the pulses for indication of changes of the cavity quality factor $Q_L$, which is an indicating measure of the field coupling and the dissipating power in the SRFCs. The"}, {"title": "2. RESIDUAL-BASED FAULT DETECTION", "content": "Model-based fault detection relies on the assessment of consistency between available measurements and prior knowledge. This is achieved through residuals that can be obtained with different methods. In our case, the nonlinear parity space method is used, and it is detailed here.\n\n2.1 The physical model of the SRFCs\n\nBecause of its structure that is able to exhibit a resonant behavior at specific frequencies, a superconducting cavity is considered as a resonator. The parameters influencing the cavity's dynamics are the detuning $\\Delta\\omega(t)$ and the half bandwidth $\\omega_{1/2}$ which represent, respectively, the difference between the driving frequency and the resonance frequency, and how sensitive a SRFC is towards the detuning. The cavity electromagnetic model as elaborated in (Schilcher, 1998) is given by\n\n$\\begin{bmatrix}V_{P,I}(t) \\\\ V_{P,Q}(t)\\end{bmatrix} = \\begin{bmatrix} -\\omega_{1/2} & -\\Delta\\omega(t) \\\\ \\Delta\\omega(t) & -\\omega_{1/2} \\end{bmatrix} \\begin{bmatrix} V_{P,I}(t) \\\\ V_{P,Q}(t) \\end{bmatrix} +  \\begin{bmatrix} V_{F,I}(t) \\\\ V_{F,Q}(t) \\end{bmatrix} + \\frac{2}{\\omega_{1/2}}\\begin{bmatrix} V_{B,I}(t) \\\\ - V_{B,Q}(t) \\end{bmatrix}$  (1)\n\nwhere I and Q are the in-phase and quadrature components of the different signals. $V_F(t)$ is the forward field coupled into the cavity, $V_P(t)$ is the probe signal, i.e., the field generated inside the cavity, and $V_B(t)$ is the field induced by the beam.\n\n2.2 Residual generation\n\nThe nonlinear parity space is an analytical redundancy method that aims at generating redundant expressions using the state-space model. Successive derivations of the model must be performed in order to retain only the known variables and obtain residuals. The residuals are then used as indicators of faults presence, a residual is non-zero in presence of faults, it is equal to zero otherwise. For the problem at hand, the cavity model has been exploited to derive the residual\n\n$r(t) = \\begin{bmatrix}  -\\dot{V}_{P,I}(t) + \\omega_{1/2} [-\\dot{V}_{P,I}(t) + 2\\dot{V}_{F,I}(t) - \\dot{V}_{B,I}(t)] \\\\ \\dot{V}_{P,Q}(t) \\end{bmatrix} \\begin{bmatrix}   \\dot{V}_{P,Q}(t) + \\omega_{1/2} [\\dot{V}_{P,Q}(t) - 2\\dot{V}_{F,Q}(t) + \\dot{V}_{B,Q}(t)]  \\end{bmatrix}$ \n\nthat is based on the analytical redundancy of (1) with respect to the detuning. More details regarding the choice of the residual can be found in (Nawaz et al., 2018).\n\n2.3 Residual assessment\n\nIn order to automate the residual analysis for presence of faults, the log-likelihood ratio is used with the assumption that the residual follows a Gaussian distribution $N(\\mu, \\sigma)$ with a mean of zero under nominal conditions, i.e., $\\mu = 0$, representing the null hypothesis. While with fault occurrence, the residual is expected to exhibit a Gaussian distribution with a mean different from zero, i.e, $\\mu \\neq 0$, representing the non-null hypothesis. Unlike the variance, the mean is unknown and needs to be estimated, the generalized likelihood ratio is therefore applied,\n\n$\\Lambda_{GLR}(k) = \\frac{K}{2} \\ln(2\\pi \\sigma^2) +  \\frac{1}{2K \\sigma^2} \\sum_{i=k-K+1}^{k} r(i)^2$ (6)\n\nwhere $r(i)$ is the evaluated and discretized residual, K is the size of the moving evaluation window and $\\sigma$ is the variance of the nominal residual. The result follows a $\\chi^2$ distribution, which gives, with a desired false alarm rate, directly the corresponding threshold on rating events as anomalous (Eichler et al., 2023)."}, {"title": "3. CLUSTERING-BASED QUENCH ISOLATION", "content": "The statistical test helps to detect faults, it is however unable to identify their types. Data-driven methods help to address this issue. The goal in our case is to isolate the quenches from the rest of faulty data. The k-medoids algorithm (Kaufman and Rousseeuw, 1990) is thus used to obtain quench clustering models from the statistical results. Furthermore, decision boundaries are used in addition to thresholds in order to ensure an optimal separation of the different faults during the inference.\n\n3.1 Quench clustering models\n\nThe k-medoid method is briefly summarized in the following. Given $X = \\{X_1,X_2,...,X_n\\}$, with $x_i \\in R^d$, a dataset of n observations with dimension d. The k-medoids is a clustering algorithm that aims to partition X into k clusters $C = \\{C_1, C_2,...,C_k\\}$ by iteratively assigning every observation to a cluster medoid $M = \\{m_1, m_2,..., m_k\\}$, here, a medoid is a representative observation, i.e., $M \\subset X$. In the same cluster, observations show high degree of similarity $S(x_1, x_2)$, while they are as dissimilar as possible in different clusters. The clustering can be achieved with different partitioning algorithms. The main input parameters are the number of clusters k, the similarity measure S and the maximum number of iterations.\n\nTwo models are built in our case, based on two different similarity measures. As base measure, the EUC is used,\n\n$EUC(x_1, x_2) = \\sqrt{\\sum_{i=1}^{n}(x_i - x_i)^2}$.\n\nGiven the GLR traces of normalized quench pulses that exhibit variability, characterized primarily by stretches and shifts in time, as shown in Fig. 1, the DTW (Sakoe and Chiba, 1978)\n\n$DTW(x_1, x_2) = arg \\underset{i,j}{min} \\sum dist(x_1, x_2)$,\n\nis also explored, where i,j$\\in$ $\\{1,2,...,d\\}$ are sample indices of the observations $x_1$ and $x_2$. Any distance (dist) can be employed for DTW, here, the Euclidean is used.\n\nThe difference between the two, as can be seen from the previous equations and from the illustrative example in Fig. 1, consists mainly in what the measures are trying to capture. While the EUC computes the similarity as the sum of the distances between each sample from observation $x_1$ and its time-corresponding sample in observation $x_2$, DTW is the sum of distances from the optimal time-warping path, i.e., the one assigning samples of observation $x_1$ to the closest samples in observation $x_2$. DTW tries therefore to capture the shape similarity in addition to the distance. And the quench traces in Fig. 1 are thus more similar with respect to DTW that is equal to 2.8 compared to EUC found to be equal to 18.6. Data from 2021, consisting of $n = 76$ quench traces of dimension d = 1819, have been used to build the models. The data are first pre-processed, a maximum-based normalization is adopted in order to equalize the scale of the data without changing its inherent structure that is important for DTW. The scaling is further accompanied by a reduction, in order to retain the frame of interest from the traces. It is obtained by keeping 300 samples following the first sample greater than 0.2. This applies only to the Euclidean distance, as it is unable to capture the similarity of traces with time misalignment.\n\nThe models are then built using k-medoids. The Partitioning Around Medoids (Kaufman and Rousseeuw, 1990) algorithm is utilized. Two main patterns of the quench traces have been noticed, two clusters are therefore built, i.e., k = 2, and two medoids $M = \\{m_1, m_2\\}$ are obtained with 100 iterations. The traces and medoids of the clusters obtained with the two distances are shown in Fig. 2. With both measures, the second cluster gathers the quenches appearing at an early stage, (at the beginning of the pulse), while those in the first cluster are quenches that have occurred at a later stage (at the end of the pulse).\n\n3.2 Inference\n\nGiven a new faulty trace $g \\in R^d$, in order to make decision whether it is a quench or not, its distance to the quench medoids is computed to assess its similarity with the quench clustering model. For both similarity measures, we define a set, based on the distances to the medoids, within which a trace is labeled as a quench. To estimate the sets, we set lower and/or upper thresholds on the distance to the quench medoids, in addition to decision boundaries H. To estimate H, a validation dataset N, with a total of 407 non-quench faulty traces, is used.\n\nEUC-based inference: Fig. 3 depicts the distance space (distance from the medoids), obtained with EUC, of the two quench clusters from X and the validation data N. As can be seen, the two quench clusters are not distinct and present a semi-elliptical shape. In order to separate the quenches from the other faults, and given the shape of the quench distances, in addition to the thresholds, two ellipses are used as decision boundaries, an inner boundary $H_{EUC}^I$ and an outer boundary $H_{EUC}^O$. The two ellipses are obtained as a scaling of the main ellipse $H_{EUC}$ fitted to the quench distances through the Least Squares method, and satisfying the following equation\n\n$H_{EUC}(s_1, s_2) = \\frac{((s_1 - s_1^0) cos(\\phi) - (s_2 - s_2^0) sin (\\phi))^2}{a^2} + \\frac{((s_1 - s_1^0) sin (\\phi) + (s_2 - s_2^0) (cos (\\phi)))^2}{b^2} = r^2$,\n\nwhere $s_1$ is the distance to the first cluster, $s_2$ is the distance to the second cluster, $\\phi$ is the rotation angle, $s_1^0$ is the center at the horizontal axis, $s_2^0$ is the center at the vertical axis and r is the scaling factor equal to 1.\n\nA set of quench traces based on EUC can be defined as\n\n$Q_{EUC} = \\{q|q \\in R^d, \\$\n$\\quad\\quad EUC(q, m_j) < max(EUC(x_i, m_j)) + \\epsilon, \\$\n$\\quad\\quad (r^I)^2 < H_{EUC}(EUC(q, m_1), EUC(q, m_2)) < (r^O)^2, \\quad\\quad \\forall x_i \\in X, \\forall m_j \\in M\\},\\quad\\quad$ \n\nwhere $\\epsilon$ is a small tolerance value learned empirically, $r^I$ and $r^O$ are the radii of $H_{EUC}^I$ and $H_{EUC}^O$, respectively, obtained as the closest and furthest distances, $H_{EUC}(EUC(x_i, m_1), EUC(x_i, m_2))$ with $x_i \\in X$, minus or plus $\\epsilon$. The detection for a new trace g is therefore achieved as in the following\n\n$Inference_{EUC}(g) = \\begin{cases}Quench, & if g \\in Q_{EUC} \\\\ Other fault, & otherwise.\\end{cases}$ \n\nDTW-based inference: Fig. 4 depicts the distance space, obtained with DTW, of both the quench clusters from X and the validation data N. Here, we can see a clear separation of the two trace types. While the quench cluster in the top left of the plot is well isolated from the non-quench faults, some overlapping can be noticed between the other faults and the second quench cluster, a decision boundary is therefore fitted as follows\n\n$H_{DTW}(s_1) = as_1^3 + bs_1^2 + cs_1 + f,$\n\nwith a, b, c and f being the polynomial coefficients. The decision boundary is obtained by adapting the intercept of the cubic fit of the distances in the cluster in the bottom of the plot.\n\nLet $Q_{DTW}$ be the set of quench traces based on DTW\n\n$Q_{DTW} = \\{q|q \\in R^d, \\$\n$\\quad\\quad DTW(q, m_j) < max(DTW(x_i, m_j)) + \\epsilon, \\$\n$\\quad\\quad DTW(q, m_j) > min(DTW(x_i, m_j)) - \\epsilon, \\$\n$\\quad\\quad DTW(q, m_2) < H_{DTW} (DTW(q, m_1)), \\quad\\quad \\forall x_i \\in X, \\forall m_j \\in M\\},\\quad\\quad$ \n\nwhere $\\epsilon$ is a small tolerance value. The inference for a new trace g is therefore achieved as follows\n\n$Inference_{DTW}(g) = \\begin{cases}Quench, & if g \\in Q_{DTW} \\\\ Other fault, & otherwise.\\end{cases}$"}, {"title": "4. EVALUATION", "content": "4.1 Setup\n\nThe EuXFEL linac is organized into 25 stations, each comprising 4 cryomodules. Within each cryomodule, there are 8 cavities, resulting in a total of 32 SRFCs per station. The data from the SRFCs consist of the forward and probe signals that correspond to the radio frequency pulses, where each pulse lasts for 1.82 ms and is sampled at 1 MHz (i.e., 1819 samples). The data are captured by a snapshot recorder and saved in files in the hdf5 format. The snapshots are triggered by different protection systems, such as, klystrons, modulators, couplers, quadrupoles and cryogenics, but also the quench detection system and/or the finite state machine. Each file, identified by a unique timestamp, corresponds to a specific faulty event from an individual station, and gathers the sampled signals for 250 consecutive pulses in all the cavities of the station. Results of the residual-based detection, i.e., the GLR traces, are also saved to the same file. The ground truth for the specific faults, however, is not available. For this study, data from the first half and second half of 2022, corresponding to a total of 671 station-related snapshots, have been collected and annotated in order to evaluate the performance of the proposed approach.\n\nWe compare the proposed solution to the currently deployed QDS that relies on a statistical analysis of the quality factor $Q_L$ of the cavities. The $Q_L$ is computed for almost every pulse and compared to a running average from the previous 100 pulses, and a sudden drop of the $Q_L$ is an indicator of a quench. Results of the QDS are event-wise, i.e., the QDS pulse-by-pulse predictions are not available. In our case, an event is considered as a quench if at least one pulse in the station is identified as a quench. This is applicable to the problem at hand, as the identification of a quench results in the interruption of the radio frequency driving the affected station.\n\nIn order to illustrate the performance comparison in terms of quench identification, the area under the curve (AUC) of the receiver operating characteristics (ROC) curves is used. The ROC-AUC depicts the true positive rate\n\n$TPR= \\frac{TP}{(FN +TP)}$,\n\nas a function of the false positive rate\n\n$FPR= \\frac{FP}{(FP + TN)}$,\n\nwhere TP are the true positives (i.e. the method accurately identified a quench), TN are the true negatives (i.e. the method accurately recognized a fault was not a quench), FP are false positives (i.e. the method identified a quench that's in reality another fault), and FN are the false negatives (i.e., the algorithm failed to identify a real quench).\n\n4.2 Implementation\n\nThe online and offline residual generation and evaluation are integrated to the trip event logger (Timm et al., 2021), an efficient tool implemented in C++ for automatic fault handling and prevention. The machine learning clustering models, along with an annotation tool, being at a testing phase so far, have been implemented in Matlab. The clustering models are deployed offline, and run daily to analyse the statistical results on the hdf5 snapshots.\n\n4.3 Results\n\nResults of the residual-based fault detection have shown that given the total number of 671 events, 354 were detected as faults within the SRFCs, some of them are documented in (Eichler et al., 2023). After annotation, 87 events were found corresponding to quenches. The highest number was recorded in April with a total of 21 quenches. This is because the facility was running at high energies, i.e., most cavities were operated just below the quench gradient. More detailed evaluation of the residual-based fault detection, and examples of the events that triggered alarms with the GLR, can be found in previous publications (Nawaz et al., 2018; Eichler et al., 2023).\n\nIt is worth mentioning that the current residual implementation does not include the voltage induced by the beam VB, as additional input, as shown in (1), but its effect is compensated as presented in (Eichler et al., 2023). This becomes problematic in certain rare cases where inaccurate inferences may be triggered due to transitions of the beam turning on and off or changes in its pattern occurring within the 250 pulses captured in the snapshots. First tests where the bunch charge measurements from the toroids are added as an additional input have therefore been carried out, this will be automated and evaluated in the future. Results of EUC and DTW are relatively similar, the EUC (TPR=0.95 and FPR=0.07) is however slightly better in terms of real quench detection and the DTW (TPR=0.93 and FPR=0.04) is slightly better in terms of false positives. Examples of false negatives and false positives can be seen in Fig.6. The false negatives are mostly caused by quenches exhibiting patterns relatively different from those used to learn the clustering models. The examples fn1 and fn2 are, for instance, caused by the beam signal, i.e., the quenches occurred simultaneously with other events, this will however be resolved upon the inclusion of the toroid. Example fn3, however, represents a quench captured at a time in between the two clusters learned with DTW. Similarly, the false positives are faults having a GLR trace with a pattern close to those of the quenches used for the model learning. The false positives fp1, fp2 and fp3 were, for instance, caused by problems with other systems than the SRFCs.\n\nUnlike the complexity of DTW that is quadratic in the pulse length, the complexity of EUC is linear in the length of the frame of interest from the pulse. It's important to note that both approaches can operate on inter-pulse intervals, but using the Euclidean distance allows for intra-pulse analysis too. Both intra-pulse and inter-pulse analyses are needed and both methods perform similarly in terms of interpretability, as both make cluster assignments mostly based on the time of the quench occurrence. The EUC therefore appears to be more advantageous for an online setup, despite the possibility of deploying both methods as part of a more collaborative strategy."}, {"title": "5. CONCLUSION", "content": "In this paper, a hybrid method to detect quenches at the EuXFEL is presented. It is a two-stage method in which the first stage generates and evaluates residuals with the nonlinear parity space method and the generalized likelihood ratio, respectively, in order to detect faults. The quenches are subsequently distinguished from the other faults in the second stage through two different clustering models, based on the EUC and DTW similarity measures. The proposed solution has been implemented and evaluated on recent data, the obtained results depict its high performance compared to the currently deployed detection system. In the near future, the beam information will be included to the implementation of the residual generation, this will help to eliminate some false alarms. The current deployment of the proposed solution is however offline, an implementation on dedicated server and on a FPGA for an online deployment has therefore been initiated. We also aim to develop and compare other detection methods and implement a human-in-the-loop procedure, in which, all methods will be deployed, and in case of disagreement, an expert intervention will be initiated. Subsequently, with the new information, there will be an automatic retraining or adjustment of the inference strategy, in order to enhance both the detection and the identification."}]}