{"title": "An Empirical Study of Vulnerability Detection using Federated Learning", "authors": ["PEIHENG ZHOU", "MING HU", "XINGRUN QUAN", "YAWEN PENG", "XIAOFEI XIE", "YANXIN YANG", "CHENGWEI LIU", "YUEMING WU", "MINGSONG CHEN"], "abstract": "Although Deep Learning (DL) techniques, especially Large Language Models (LLMs), are becoming increasingly\npopular in vulnerability detection, their performance is seriously limited by insufficient training data. This is\nmainly because few existing software companies or organizations can maintain a complete set of high-quality\nsamples for DL-based vulnerability detection. Due to the concerns about privacy leakage, most of them\nare reluctant to share such samples, thus resulting in the data silo problem. As an emerging distributed DL\nparadigm, Federated Learning (FL) enables model training among clients without compromising their data\nprivacy. Therefore, it has been investigated as a promising means of addressing the data silo problem in\nDL-based vulnerability detection. However, since existing FL-based vulnerability detection methods focus\non specific applications, it is still far unclear i) how well FL adapts to common vulnerability detection tasks\nand ii) how to design a high-performance FL solution for a specific vulnerability detection task. To answer these\ntwo questions, this paper first proposes VulFL, an effective evaluation framework for FL-based vulnerability\ndetection. Then, based on VulFL, this paper conducts a comprehensive study on a well-known real-world\ndataset named DiverseVul, aiming to reveal the underlying capabilities of FL in dealing with different types of\nCommon Weakness Enumeration (CWEs), especially when facing various data heterogeneity scenarios. Our\nexperimental results show that, compared to independent training, FL can significantly improve the detection\nperformance of common AI models on all investigated CWEs, though the performance of FL-based vulnerability\ndetection is limited by heterogeneous data. To highlight the performance differences between different FL\nsolutions for vulnerability detection, we extensively investigate the impacts of different configuration strategies\nfor each framework component of VulFL, involving various mainstream data processing strategies, parameter-\nefficient model training schemes, and FL algorithms built on top of different Natural Language Processing\n(NLP)-based or Graph Neural Network (GNN)-based models. Our study sheds light on the potential of FL in\nvulnerability detection, which can be used to guide the design of FL-based solutions for vulnerability detection.", "sections": [{"title": "1 INTRODUCTION", "content": "As a promising software Quality Assurance (QA) technology, vulnerability detection [1-3] plays a\nvital role in ensuring the robustness and security of software projects. However, due to the exponen-\ntially increasing complexity and scale of software, developers will have to invest significantly more\ntime and effort in vulnerability detection, inevitably prolonging the agile development processes\nof modern software systems. To mitigate this problem, more and more developers resort to Deep\nLearning (DL) techniques [4-7], especially Large Language Models (LLMs), to perform vulnerabil-\nity detection, since they provide powerful code understanding and reasoning capabilities. So far,\nexisting DL-based vulnerability detection methods can be mainly classified into two categories:\ni) Graph Neural Network (GNN)-based methods [8-12] that can deal with various graph-based\ninputs including Abstract Syntax Trees (ASTs), Control Flow Graphs (CFGs) and Dataflow Graphs\n(DFGs); and ii) Text sequence neural network-based methods [5] for Natural Language Processing\n(NLP) tasks that take token sequences generated from text data as input.\nAlthough DL-based vulnerability detection methods enable knowledge sharing among participat-\ning companies or organizations, they are facing the serious challenge of insufficient training data.\nTypically, training a well-performing DL model requires a large amount of high-quality and diverse\nvulnerability data. However, few existing companies or organizations can maintain such a set of\nsufficient vulnerability data for model training. Worse still, due to concerns about privacy leakage,\nmost companies and organizations are reluctant to share their vulnerability data for collaborative\nmodel training. All these factors result in the notorious data silo problem, strongly limiting the\nuse of DL techniques in vulnerability detection tasks. To address this issue, Federated Learning\n(FL) [13-17] has been proposed as an effective distributed machine learning-based solution. Based\non a client-server architecture, FL maintains a global model on the cloud server for knowledge\naggregation and sharing, enabling collaborative training among clients without compromising\ntheir data privacy. In each FL training round, the cloud server first dispatches the global model to\nclients for local model training and then aggregates the trained local models to update the global\nmodel. Since only model gradients are transmitted between the cloud server and participant clients,\nthe privacy of clients can be guaranteed.\nDue to the merits of privacy-aware collaborative learning, FL has been considered a new means\nfor DL-based vulnerability detection. As an initial attempt at FL-based vulnerability detection, the\nwork VDBFL [18] demonstrates the feasibility and potential of FL in enhancing the performance of\nvulnerability detection. However, it focuses on GNN-based performance optimization for vulnerabil-\nity detection. Without taking various important issues such as i) DL models, ii) data heterogeneity\nscenarios, and iii) categories of vulnerabilities into account, existing FL-based vulnerability detec-\ntion methods, including VDBFL, fail to comprehensively explore the potential and limitations of\nFL in dealing with common vulnerability detection tasks. For example, although LLMs play an\nimportant role in NLP-based vulnerability detection, they have not yet been explored as underlying\nDL models in FL-based vulnerability detection. Besides the model issue, existing FL methods suffer\nfrom the \"gradient divergence\" problem [19] caused by underlying data heterogeneity, which\nstrongly degrades the overall collaborative learning performance of FL. Without a thorough study\non this topic, developers will often get frustrated when contributing their heterogeneous code data\nfor FL-based vulnerability detection. Meanwhile, different code owners may encounter different\ntypes of Common Vulnerabilities and Exposures (CWEs), thus requiring that FL-based vulnerability"}, {"title": "2 BACKGROUND", "content": "Typically, an FL system consists of a cloud server and multiple clients. In each FL training round,\nthe cloud server dispatches a global model to local clients, and each client uses their raw data to\ntrain the received model. Then, each client uploads its trained model to the cloud server, and the\ncloud server aggregates all the collected models to update the global model. The objective of FL is\ncommonly to optimize a global model represented as follows:\n$\nminF(W) = \\frac{1}{N} \\sum_{i=1}^{N} L_i(W; D_i),\n$\nwhere $N$ denotes the number of clients, $W$ is the global model's parameters, $L_i$ indicates the loss\ngenerated by each client, and $D_i$ represents the local data provided by each client.\nThe main challenge in FL is the data heterogeneity problem. To address these problems, existing\nFL methods can be classified into five categories: global variable-based, clustering-based, knowledge\ndistillation-based, mutation-based, and multi-model-based methods. The global variable-based\nmethods [19, 27] aim to use a global variable to guide the local models in clients to be optimized\ntowards a similar direction. Clustering-based methods [28, 29] cluster clients according to their\nspecific characteristics, such as data distribution and activation of specific layers. Based on clusters,\nthe cluster-based methods prefer to fairly select clients from each cluster to participate in each\nround of local training. Knowledge distillation-based methods [30, 31] conduct knowledge distilla-\ntion technologies using a public or proxy dataset to optimize model training. Multi-model-based\nmethods [27, 32] use multiple homogeneous models for local training rather than the same global\nmodel and use heuristic model collaboration methods to transform knowledge among models. In\nthis way, multi-model-based methods guide the models optimized towards a flat area, thereby\nachieving a well-generalized performance. Mutation-based method [33] mutates the global model\nto make the model shift in the solution space to eliminate the optimal local solution.\nRecently, FL has been widely used in various applications, such as AIoT systems [34, 35], au-\ntonomous driving [36], and medical health [37]. However, FL-based vulnerability detection is still"}, {"title": "3 OUR EVALUATION FRAMEWORK", "content": "To understand the effectiveness of FL for vulnerability detection, according to the study in Section 2,\nwe designed a general and easy-to-extend evaluation framework, named VulFed, which integrates\nvarious vulnerability detection methods and FL optimization methods. As shown in Figure 1,\nVulFed adopts a classic central cloud-based FL architecture, consisting of a cloud server and\nmultiple project owners. To integrate various vulnerability detection and FL optimization methods,\nVulFed includes four configurable components, i.e., pre-processor, trainer, aggregator, and client\nselector, respectively. Specifically, the pre-processor integrates data transformation methods to\nconvert source code into a format suitable for specific DL-based vulnerability detection methods.\nThe trainer incorporates training schemes for specific models and optimization strategies for FL\nmethods. The aggregator implements model aggregation and server-side optimization strategies for\nFL methods. The client selector employs client selection strategies tailored to specific FL methods.\nBy configuring the four components, we can implement vulnerability detection methods based on\ndifferent FL optimization algorithms.\nAs described in Section 2.1, existing vulnerability detection meth-\nods are based on different data structures. To integrate various vulnerability detection methods\non VulFed, we implemented our pre-processer to convert source code into four data structures,"}, {"title": "4 STUDY DESIGN", "content": "We conducted extensive experiments to evaluate the performance of VulFed involving various\nvulnerability detection tasks. Our objectives are to i) understand the effectiveness of different FL\ncomponents in detecting vulnerabilities, focusing on the performance of detecting vulnerabilities of\ndifferent categories by different DL models within various data heterogeneity scenarios, and ii) help\ncode owners manage the underlying FL framework to maximize the performance of collaborative\nvulnerability detection, e.g., provide useful guidance on selecting the best suitable FL components\nor settings according to the specific requirements and contexts of given vulnerability detection\ntasks. All these experiments try to answer the following three research questions (RQs).\nWe conducted performance comparisons on various vulnerability detection\ntasks, aiming to figure out the superiority of FL over traditional independent training in vulner-\nability detection. In other words, we want to figure out can the collaborative training scheme\nprovided by FL can substantially improve the vulnerability detection performance achieved by\nexisting methods that rely on independent learning on local data only. To evaluate the effectiveness\nof FL in detecting different types of vulnerabilities, we analyzed performance improvements within\nthe subsets of samples corresponding to different CWE categories.\nDue to differences in business and specific technology stacks, the distributions of vulnerability\ndata of different project owners vary significantly. To investigate the effectiveness of FL-based\nvulnerability detection on data heterogeneity scenarios, we simulated non-IID situations by con-\nstructing heterogeneous client data using the Dirichlet distributions [50]. We evaluated the model\nperformance within various simulated heterogeneous scenarios and conducted statistical analyses\nfor both binary tasks and multi-classification tasks according to their CWE types.\nTo figure out optimal configuration strategies for different components of an FL-based vulnerability"}, {"title": "5 EVALUATION RESULTS", "content": "To evaluate the effectiveness of FL in vulnerability detection, we compared the performance of\nvanilla FL-based with independent training-based vulnerability detection methods in VulFed, where\neach client, in the latter case, only utilizes its raw data to train an isolated local model. Here, we\nselected the DiverseVul dataset for evaluation because it is a relatively new and comprehensive\ndataset among those deployed in VulFed, encompassing a sufficient amount of vulnerable code"}, {"title": "6 DISCUSSION", "content": "When designing VulFed, we priorly choose representative methods or models as optional frame-\nwork components. Firstly, in terms of the model we deployed, we comprehensively considered the\nrequirements of the FL framework for lightweight models and the necessity of LLM maintaining\nits type and then selected six most typical LLMs under three different architectures. At present,\nthe performance and parameter scale of LLM are developing rapidly, but we have not adopted the"}, {"title": "7 CONCLUSION", "content": "Along with the prosperity of AI techniques, Federated Learning (FL) is becoming a promising\ncollaborative learning scheme for software vulnerability detection since it can effectively address\nthe data silo problem among relevant companies or departments without compromising their\ndata (software) privacy. However, existing FL-based vulnerability detection methods focus on\napplication-specific tasks with GNN-like inputs, limiting their usage in common vulnerability\ndetection tasks. To reveal the potential of FL in this domain, in this paper, we proposed a novel\nFL vulnerability detection framework named VulFed that supports both traditional DL models\nand rapidly evolving LLMs. Based on VulFed, we revealed that FL-based methods can significantly\nimprove overall vulnerability detection performance at the CWE-case level for both IID and non-\nIID scenarios. Meanwhile, we evaluated the performance of different data processing and FL\noptimization methods (e.g., data preprocessing mechanisms, FL training schemes, PEFT) on VulFed.\nComprehensive experimental results obtained from the study reveal the impacts of such different FL\nconfigurations on various vulnerability detection tasks, which can help researchers build their own\nFL frameworks to address specific vulnerability detection tasks. In the future, we plan to investigate\nlarger models and their performance optimization mechanisms based on our VulFed framework.\nMoreover, the finer-grained (e.g., line or character level) and cross-language vulnerability detection\ntasks are also worth further study."}]}