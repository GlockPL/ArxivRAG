{"title": "Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning", "authors": ["Zhenni Bi", "Kai Han", "Chuanjian Liu", "Yehui Tang", "Yunhe Wang"], "abstract": "Large Language Models (LLMs) have shown remarkable abilities across various language tasks, but solving complex reasoning problems remains a challenge. While existing methods like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) enhance reasoning by decomposing problems or structuring prompts, they typically perform a single pass of reasoning and may fail to revisit flawed paths, compromising accuracy. To address this, we propose a novel reasoning framework called Forest-of-Thought (FoT), which integrates multiple reasoning trees to leverage collective decision-making for solving complex logical problems. FoT utilizes sparse activation strategies to select the most relevant reasoning paths, improving both efficiency and accuracy. Additionally, we introduce a dynamic self-correction strategy that enables real-time error correction and learning from past mistakes, as well as consensus-guided decision making strategies to optimize correctness and computational resources. Experimental results demonstrate that the FoT framework, combined with these strategies, significantly enhances the reasoning capabilities of LLMs, enabling them to solve complex tasks with greater precision and efficiency.", "sections": [{"title": "1. Introduction", "content": "Large Language Models (LLMs) have revolutionized natural language processing by demonstrating remarkable abilities across a wide range of language tasks. Leveraging vast datasets and complex architectures, LLMs such as ChatGPT (Kojima et al., 2022; Achiam et al., 2023) and LLaMA (Touvron et al., 2023) can generate coherent essays, answer complex questions, and even engage in multi-turn dialogues with human-like fluency. These models excel at tasks requiring not only linguistic understanding but also basic reasoning, such as translating text between languages, summarizing lengthy documents, and creating code based on plain language instructions. The versatility and adaptability of LLMs have made them invaluable tools in both industry and research, simultaneously providing new avenues for addressing general-purpose problems.\nHow to enable LLM to successfully solve hard reasoning problems is still challengable. A seires of works have been proposed to introduce more inference at test time based on a well-trained LLM (Wei et al., 2022; Yao et al., 2024; Snell et al., 2024; OpenAI, 2024). Chain-of-Thought (CoT) (Wei et al., 2022) provides a few chain of thought demonstrations in prompting as exemplars to emerge reasoning abilities of LLMs. Tree-of-Thought (ToT) (Yao et al., 2024) allowing language models to explore multiple reasoning paths and self-evaluate to make more globally informed decisions. Graph-of-Thought (GoT) (Besta et al., 2024) advances LLM prompting by structuring information as a graph of interconnected \"thoughts\", enabling synergistic reasoning and feedback loops.\nThese method perform reasoning by richer prompt or decomposing complex problem into several easier subproblems. They only perform a single complete reasoning pass on the problem, which cannot ensure that the problem is solved or guarantee correctness. For example, in a complex mathematical word problem, a Tree-of-Thought approach might decompose the problem into smaller steps, such as isolating terms or simplifying expressions. However, while breaking down the question, it may still overlook critical details or make errors in intermediate steps, leading to an incorrect final answer. Once it completes a single reasoning path, it typically does not revisit other possible approaches if the initial path is flawed. This lack of re-evaluation can result in a solution that fails to address the full complexity of the problem, as alternative paths are often prematurely abandoned and left unexplored, thereby compromising accuracy. Instead, humans tend to repeatedly think and verify from different perspectives when dealing with complex problems to truly solve the problem and provide answers with higher accuracy."}, {"title": "2. Related Works", "content": "Starting from Chain-of-Thought (CoT), XOT reasoning (e.g., ToT and GoT) began to be an important technique to enhance the reasoning ability of LLMs, leading to the development of a series of XoT reasoning algorithms.\nChain-of-Thought (CoT) (Wei et al., 2022) decomposes a problem into a series of intermediate steps, each of which provides a portion of the information needed for the final answer. This approach mimics human problem-solving strategies, involving step-by-step reasoning to reach a conclusion. However, while the CoT method performs well in many tasks, it has limitations when dealing with complex mathematical and logical problems. These intricate problems often require multidimensional, non-linear thinking, rather than just sequential reasoning. Despite numerous subsequent studies that have improved the CoT, including Zero-Shot-CoT (Kojima et al., 2023), Self-Consistency with CoT (CoT-SC) (Wang et al., 2023), Auto-CoT (Zhang et al., 2022), VerifyCoT (Zhao et al., 2023), CoF-CoT (Nguyen et al., 2023), further exploration and optimization are still necessary to address highly complex tasks.\nLeast-to-Most Prompting (LtM) (Zhou et al., 2023) leads the model through a step-by-step process, progressively assisting it in constructing a solution, in contrast to methods like CoT that attempt to solve complex problems directly. This approach effectively avoids the reasoning errors that can arise when attempting to solve complex problems all at once. By decomposing complex problems into a series of simpler tasks, Program of Thought (PoT) (Chen et al., 2023), Chain of Code (CoC) (Li et al., 2024) and Buffer of Thought (BoT) (Yang et al., 2024) transform this process into a set of programmatic steps, using variable names to convey semantic information. On the other hand, Algorithm of Thought (AoT) (Sel et al., 2024) method aims to integrate these steps into a single prompt, enabling LLMs to learn how to break down problems, generate solutions, assess their feasibility, and determine the next step in the search process. This approach reduces token consumption and improves efficiency.\nTree-of-Thought (ToT) (Yao et al., 2024) constructs a tree structure to explore various possible choices and their outcomes, where each node represents a decision point and the edges represent transitions from one state to another. Typically, a depth-first search (DFS) approach is used to gradually explore each branch. Tree Prompting (Morris et al., 2023) establishes a decision-tree-based prompting system, chaining multiple language model calls together to collaboratively complete a specific task. However, for complex problems, the depth of the tree may become very large, leading to an exponential increase in the search space and an increased computational burden. Graph-of-Thought (GoT) (Besta et al., 2024) builds upon the ToT framework by introducing an aggregation process. GoT models the reasoning process of LLMs as a graph structure, allowing information units to form arbitrary dependencies, not limited to linear or tree-based arrangements. Through the aggregation process, GoT can consolidate information from multiple paths, supporting complex dynamic path selection and backtracking. Skeleton-of-Thought (SoT) (Ning et al., 2023) reduces generation latency in large language models (LLMs) by first generating a skeleton answer outline, then completing content in parallel, achieving significant speed-ups and potential quality improvements across various question types."}, {"title": "2.1. XoT reasoning", "content": "Starting from Chain-of-Thought (CoT), XOT reasoning (e.g., ToT and GoT) began to be an important technique to enhance the reasoning ability of LLMs, leading to the development of a series of XoT reasoning algorithms.\nChain-of-Thought (CoT) (Wei et al., 2022) decomposes a problem into a series of intermediate steps, each of which provides a portion of the information needed for the final answer. This approach mimics human problem-solving strategies, involving step-by-step reasoning to reach a conclusion. However, while the CoT method performs well in many tasks, it has limitations when dealing with complex mathematical and logical problems. These intricate problems often require multidimensional, non-linear thinking, rather than just sequential reasoning. Despite numerous subsequent studies that have improved the CoT, including Zero-Shot-CoT (Kojima et al., 2023), Self-Consistency with CoT (CoT-SC) (Wang et al., 2023), Auto-CoT (Zhang et al., 2022), VerifyCoT (Zhao et al., 2023), CoF-CoT (Nguyen et al., 2023), further exploration and optimization are still necessary to address highly complex tasks.\nLeast-to-Most Prompting (LtM) (Zhou et al., 2023) leads the model through a step-by-step process, progressively assisting it in constructing a solution, in contrast to methods like CoT that attempt to solve complex problems directly. This approach effectively avoids the reasoning errors that can arise when attempting to solve complex problems all at once. By decomposing complex problems into a series of simpler tasks, Program of Thought (PoT) (Chen et al., 2023), Chain of Code (CoC) (Li et al., 2024) and Buffer of Thought (BoT) (Yang et al., 2024) transform this process into a set of programmatic steps, using variable names to convey semantic information. On the other hand, Algorithm of Thought (AoT) (Sel et al., 2024) method aims to integrate these steps into a single prompt, enabling LLMs to learn how to break down problems, generate solutions, assess their feasibility, and determine the next step in the search process. This approach reduces token consumption and improves efficiency."}, {"title": "2.2. Monte Carlo Tree Search", "content": "Monte Carlo Tree Search (MCTS) (Chaslot et al., 2008), a probability-based search algorithm, has achieved significant progress across various domains since its introduction in computer Go in 2006. It evaluates nodes through randomized simulations (rollouts) and incrementally builds a local game tree to identify optimal or near-optimal solutions within limited time. To enhance MCTS performance, researchers have proposed various improvements. (Browne et al., 2012) surveyed extensions like sparse activation, dynamic pruning, parallelization, and distributed computation, broadening MCTS applications. (Srinivas et al., 2012) introduced UCB1-Tuned, an improved exploration-exploitation strategy suited for high-dimensional spaces. Recently, integrating MCTS with"}, {"title": "3. Method", "content": "By introducing multiple reasoning trees (e.g., ToT (Yao et al., 2024) or MCTSr (Zhang et al., 2024)) for independent decision-making and employing sparse activation strategies to filter the results of key trees, we can construct an integrated framework known as the \"forest of thought\" to enhance the reasoning capability of LLMs, as shown in Figure 1(d) and Algorithm 1. This strategy leverages collective wisdom to compensate for individual deficiencies, thereby enhancing the model's ability to think comprehensively from multiple directions. Our experimental validation demonstrates that the practice of integrating the results of multiple reasoning trees through sparse activation strategies indeed enhances the reasoning capabilities of larger models to a certain extent. This discovery not only enriches our understanding of model integration methods but also offers novel insights and approaches for improving the mathematical reasoning abilities of large language models (LLMs)."}, {"title": "3.1. The FoT Framework", "content": "Suppose we have n reasoning trees $T_1, T_2, ..., T_n$, each of which approaches the input problem from a different perspective. The root node of each tree represents the initial state or problem input, and each node represents an intermediate result or step in the reasoning process. Let the input be x. Each reasoning tree will start from the input and produce a result through different reasoning steps:\n$s_i = T_i(\\varepsilon(x))$, $i \\in \\{1,2,..., n\\}$\nwhere $\\varepsilon(x)$ is the function that enhances x before it is used as input (details in the following paragraph) and $T_i()$ represents the reasoning process of the ith tree. FoT will consider the results of these trees in a sparse activation manner and produce high-quality response via majority voting. A dynamic self-correction strategy is proposed for enhancing the accuracy (Sec. 3.2), and early stopping strategies are introduced for improving inference efficiency (Sec. 3.3).\nSparse Activation. In the reasoning process of a forest of reasoning trees, only the most relevant reasoning trees (or certain nodes within them) are selected for computation, rather than performing a complete calculation on all trees. This approach enhances efficiency while improving model accuracy by selecting the most relevant reasoning paths. Through sparse activation, we filter the activations of each reasoning tree, ensuring that only the paths of certain reasoning trees are \u201cactivated\u201d for inference.\nFor each reasoning tree $T_i$, each layer considers the top-scoring nodes for further reasoning. Nodes with the highest scores are selected to split into child nodes at the next layer. If the nodes at a certain level of the tree cannot produce valid outputs, the tree's splitting process will terminate early, and the activation indicator value will be set to"}, {"title": "3.2. Dynamic Self-Correction Strategy", "content": "To improve the probability for giving correct answer in each tree, we introduce the dynamic self-correction strategy. For the initial result $s_i$ from a reasoning tree, the self-correction strategy evaluates its correctness and effectiveness, and assigns corresponding scores upon completion of each reasoning step. The score can be obtained with a LLM $p_\\theta$:\n$score_i \\sim p_\\theta(score_i | s_i, x)$.\nOnce a step's score falls below the predefined threshold, the strategy automatically triggers a correction mechanism. This mechanism first reviews and analyzes past failure cases (denoted as C) to identify the causes of low scores and common error patterns, subsequently attempting to correct errors and optimize the reasoning direction. The correction process can be performed by the LLM itself:\n$s'_i \\sim p_{\\theta_1}(s'_i | C, s_i, x)$.\nBy employing this learning-from-history and real-time correction mechanism, the model not only avoids repeating mistakes on the same issues but also finds effective solutions to new and complex problems more swiftly and accurately. This continuous learning and optimization process significantly enhances the model's reasoning capabilities."}, {"title": "3.3. Decision Making Strategy", "content": "To address complex mathematical problems, we designed the Consensus-Guided Expert Decision (CGED) strategy to ensure high accuracy and reliability in the final answers generated by FoT. The CGED approach combines collective intelligence with expert judgment, guiding the reasoning process from consensus-based decision-making to expert evaluation.\nSelecting the Optimal Leaf Node. In the FoT method, each independent tree generates one or more possible answers through its unique reasoning path. Subtrees vote for the candidate answer that receives the most support. If a consensus cannot be reached, the math expert evaluates the reasoning processes and selects the final answer to ensure its accuracy and validity.\nFoT Decision-Making Process. During reasoning, each activated tree produces an optimal solution for its path. These answers are then filtered through majority voting and expert evaluation. For complex tasks, if answers from mul-"}, {"title": "4. Experiments", "content": "We evaluate the proposed FoT method on the widely-used LLM reasoning benchmarks including Game of 24, GSM8K and MATH."}, {"title": "4.1. Experimental setups", "content": "For the Game of 24, our FoT is built using the ToT as the reasoning tree. Beyond the ToT-based FoT, we developed an MCTSr-based FoT to address more complex and diverse mathematical problems, including those in the GSM8K and MATH benchmarks.\nIn all the three benchmarks, the Llama3-8B-Instruct (at Meta, 2024) is used as the base language model. In addition, we extend our method on Mistral-7B (Jiang et al., 2023), and GLM-4-9B (GLM et al., 2024) on GSM8K benchmark to verify its generalization."}, {"title": "4.2. Game of 24", "content": "The Game of 24 originates from ToT (Yao et al., 2024), where the objective is to construct an arithmetic expression using each of the four given numbers exactly once, such that the expression evaluates to 24. The 24-point game process is shown in Figure 2. We conducted multiple inference experiments on a V100-32G GPU using Llama3-8B, optimizing parameters such as the number of trees in the forest, activation mechanisms, and sparsity settings. We evaluated the impact of different configurations on inference speed and accuracy.\nResults. In Table 1, we compare the results of increasing the number of leaf nodes at each layer in the ToT framework to allow for a greater diversity of potential reasoning outcomes. The hypothesis was that by expanding the leaf nodes, ToT would be able to explore more reasoning paths, leading to improved accuracy. However, when the number of leaf nodes per layer was increased to 32, the experimental results did not show significant improvement. It appears that the system reached a reasoning bottleneck, where further expansion of the leaf nodes did not lead to substantial gains in performance. This suggests that beyond a certain threshold, simply increasing the number of available reasoning paths does not necessarily translate into better reasoning outcomes, likely due to diminishing returns from excessive node expansion.\nIn contrast, FoT approach demonstrated a notable improvement in accuracy without a significant increase in computa-"}, {"title": "4.3. GSM8K Benchmark", "content": "In addition to ToT, we evaluated the benefits of integrating multiple methods into the FoT framework on the GSM8K (Cobbe et al., 2021) dataset.\nResults. As shown in Figure 3, we constructed forests using various methods, including Zero-Shot-CoT, MCTSr with one turn, MCTSr with 4 rollouts, and MCTSr with 8 rollouts. The experimental results demonstrate that as the number of trees in the forest increases, the advantages of the multi-method forest approach become more pronounced. Notably, the 4-rollouts MCTSr with 2 trees achieved 3.2% higher accuracy compared to the 8-rollouts MCTSr. Additionally, it outperformed the 8-rollouts MCTSr with 2 trees, highlighting its clear advantage. These findings indicate that increasing the diversity of reasoning outcomes has a more significant impact on performance than merely extending the depth of individual trees.\nWhen using MCTSr with 2 trees in the FoT framework, the accuracy improvement is notably significant, highlighting the substantial benefit of introducing even a small amount of diversity in reasoning paths. However, as the number of trees continues to increase, the rate of improvement gradually diminishes. This phenomenon suggests that the initial addition of trees provides a major boost by expanding the range of explored solutions, but subsequent increases contribute less incrementally to the overall accuracy. The diminishing returns can be attributed to overlapping reasoning paths or the fact that additional trees may explore regions of the solution space that are already well-covered, thereby reducing their impact. This highlights the importance of balancing tree diversity and computational efficiency to achieve optimal performance in the FoT framework."}, {"title": "4.4. MATH Benchmark", "content": "This section presents the results of applying the FoT algorithm across various complexity levels on the MATH dataset (Hendrycks et al., 2021). The dataset is stratified into five difficulty levels, ranging from level 1 (easiest) to level 5 (most challenging)."}, {"title": "4.5. Ablation Studies of Stopping Strategies", "content": "This paper compares three methods for selecting the optimal leaf node from subtrees, highlighting their effectiveness and performance:\nRandom Selection: A leaf node is selected randomly as the final answer. This method is simple and requires minimal computation but often results in unstable and less accurate outcomes."}, {"title": "4.6. Ablation Studies of Self-Correction methods", "content": "The advantages of incorporating a dynamic self-correction module into the Zero-Shot-CoT and ToT approaches are summarized in Table 4. Specifically, adding this dynamic adjustment mechanism improves the efficacy of the CoT method by 5%. Remarkably, the accuracy of the ToT approach increases from an error-prone initial state in single-step reasoning to over 50% after integrating the self-correction mechanism. This improvement is particularly significant because errors in ToT's single-step reasoning tend to propagate through subsequent reasoning steps, severely impairing overall performance. Consequently, the dynamic self-correction process plays a critical role in ToT by promptly addressing early-stage mistakes, preventing their compounding effects, and significantly enhancing the final accuracy."}, {"title": "5. Conclusion", "content": "This paper introduces a novel method, the Forest of Thought (FoT), aimed at significantly enhancing the reasoning capabilities of large language models (LLMs). FoT leverages a structured framework that integrates multi-path exploration and dynamic activation of reasoning paths, addressing key limitations in existing LLM reasoning paradigms. This enables the model to achieve robust and efficient problem-solving across complex tasks while generating diverse reasoning outcomes without relying on back-propagation or fine-tuning.\nBy integrating multiple independent \u201cthinking\u201d models, such as the Tree of Thought and Monte Carlo Trees, FoT effectively tackles complex problems and incorporates a sparse activation mechanism to substantially improve computational efficiency. Additionally, this paper systematically investigates the scaling relationship between reasoning time and accuracy in LLMs, providing a theoretical foundation for optimizing their reasoning performance."}]}