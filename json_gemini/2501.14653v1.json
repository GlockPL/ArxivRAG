{"title": "FEDERATED DOMAIN GENERALIZATION WITH DATA-FREE ON-SERVER GRADIENT MATCHING", "authors": ["Trong-Binh Nguyen", "Minh-Duong Nguyen", "Jinsun Park", "Quoc-Viet Pham", "Won Joo Hwang"], "abstract": "Domain Generalization (DG) aims to learn from multiple known source domains a model that can generalize well to unknown target domains. One of the key approaches in DG is training an encoder which generates domain-invariant representations. However, this approach is not applicable in Federated Domain Generalization (FDG), where data from various domains are distributed across different clients. In this paper, we introduce a novel approach, dubbed Federated Learning via On-server Matching Gradient (FedOMG), which can efficiently leverage domain information from distributed domains. Specifically, we utilize the local gradients as information about the distributed models to find an invariant gradient direction across all domains through gradient inner product maximization. The advantages are two-fold: 1) FedOMG can aggregate the characteristics of distributed models on the centralized server without incurring any additional communication cost, and 2) FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional performance improvements by being seamlessly integrated with them. Extensive experimental evaluations on various settings to demonstrate the robustness of FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).", "sections": [{"title": "1 INTRODUCTION", "content": "Federated Learning (FL) has gained widespread recognition due to its ability to train models collaboratively across multiple clients while keeping their individual data secure. However, one of the practical problems, how to make models trained on sites of heterogeneous distributions generalize to target clients of unknown distributions, i.e., Federated Domain Generalization (FDG), remains under explored. While label distribution shift has been considered in traditional FL, FDG focuses on the feature shift among clients and considers each client as an individual domain.\nFDG shares a similar goal as standard Domain Generalization (DG) (Nguyen et al., 2022b; Li et al., 2018), i.e., generalizing from multi-source domains to unseen domains. However, unlike DG, where knowledge from various domains can be jointly utilized to develop an efficient algorithm, FDG prohibits direct data sharing among clients, which makes most existing DG methods hardly applicable. To address the challenges inherent to FDG, recent methods circumvent these difficulties by adopting alternative strategies, e.g., unbiased local training within each isolated domain, local data preprocessing Huang et al. (2022; 2024), or knowledge sharing among users (Liu et al., 2021; Chen et al., 2023). As a consequence, an open question remains for FDG:\nHow can knowledge across domains be effectively leveraged to design FDG algorithms that achieve performance comparable to DG, while avoiding additional communication overhead?\nAddressing the aforementioned question, we inherit the gradient matching rationale (Shi et al., 2022; Rame et al., 2022). The rationale is straightforward: if the model \u03b8 is domain-invariant, the gradients induced by \u03b8 across different domains should exhibit a high correlation with each other. To this end,"}, {"title": "2 PRELIMINARIES", "content": "Notations: By default, \u27e8,\u27e9 and || \u00b7 || denote the Euclidean inner product and Euclidean norm, respectively. In our research, we use dM(\u00b7,\u00b7) to represent any distance metric M between two distributions. We denote \u2299 as Hadamard product. We denote P(\u03b8;D) as the output distribution of model \u03b8 given input as dataset D. We denote \u03b8\u207d\u02b3\u207e,\u03b8,\u03b8\u1d64,\u03b8\u1d64\u207d\u1d49\u207e \u2208 \u211d\u00b9\u02e3\u1d39 as the global, local, trained local model parameters used in the FL system at round r, respectively. Let g(\u03b8\u1d64\u207d\u02b3\u207e; D\u1d64) \u2208 \u211d\u00b9\u02e3\u1d39 be local gradient of client u at epoch e of round r, g(\u03b8\u1d64\u207d\u02b3\u207e; D\u1d64) \u2208 \u211d\u00b9\u02e3\u1d39 be gradient of client u at round r. Without loss of generality, we abuse g(\u03b8\u1d64\u207d\u02b3\u207e; D\u1d64) = g\u1d64\u207d\u02b3\u207e,\u1d49, g(\u03b8\u1d64\u207d\u02b3\u207e; D\u1d64) = g\u1d64\u207d\u02b3\u207e.\nProblem Setup: We consider an FL system comprising a set of source clients U\u209b = {u|u = 1,2,..., U\u209b}, and target clients U\u1d1b = {u|u = U\u209b + 1, 2, . . ., U\u209b + U\u1d1b}. Each client u gains access to its data D\u1d64 = {x\u1d62, y\u1d62}\u1d62=\u2081\u1d3a\u1d58 with N\u1d64 data samples, where u \u2208 {U\u209b;U\u1d1b}. Source and target clients are assigned to the source datasets D\u209b = {D\u1d64|u \u2208 U\u209b}and target datasets D\u1d1b = {D\u1d64|u \u2208 U\u1d1b}, respectively. Each client is trained for E epochs every round. The system objectives are two-fold.\nObjective 1 (guarantee on the conventional FL setting) The method has to perform well on the source clients set U\u209b, i.e., \u03b8* = arg min \u03b8 E\u209b = \u2211\u1d64\u2208U\u209b \u03b3\u1d64E(\u03b8, D\u1d64), where E(\u03b8,D\u1d64) is the local empirical risk, \u03b3\u1d64 represents the weight on client u, satisfying \u2211\u1d64\u2208U\u209b \u03b3\u1d64 = 1."}, {"title": "3 MOTIVATION BEHIND ON-SERVER OPTIMIZATION FEDERATED LEARNING", "content": "3.1 FROM FEDERATED LEARNING TO ON-SERVER OPTIMIZATION FEDERATED LEARNING\nTo efficiently aggregate knowledge from all clients, we propose an on-server optimization framework designed to identify an optimal aggregated gradient for achieving domain invariance, thus, eliminating the need for direct access to client data. This approach leverages meta-learning to decompose the FDG optimization problem into two meta-learning steps. Specifically, we reformulate the FDG optimization problem from Eq. (2) into two sequential stages: local update and meta update. Drawing on the meta-learning principle (Hospedales et al., 2022), the problem is formulated as follows:\n\u03b8\u207d\u02b3\u207e = \u03b8\u207d\u02b3\u207b\u00b9\u207e \u2212 \u03b7 \u03b9 \u2211 [\u2207 E(\u03b8;D\u1d64)+\u03bb \u2211 \u2207d \u2133 (P(\u03b8;D\u1d64), P(\u03b8;D\u1d65))], \n s.t. \u03b8\u1d64\u207d\u02b3\u207e = \u03b8\u207d\u02b3\u207b\u00b9\u207e \u2212 \u03b7 \u2089g(\u03b8\u1d64\u207d\u02b3\u207b\u00b9\u207e; D\u1d64), \nwhere \u03b7 \u03b9 and \u03b7 \u2089 are the local and global learning rate of FL system, respectively. The local update in Eq. (3b) is designated for on-device training, while the meta update in Eq. (3a) is utilized for on-server update. The on-server update in (3a) consists of two terms: the first term \u2207 E(\u03b8;D\u1d64) refers to the FL update, and the second term \u2207d \u2133 (P(\u03b8;D\u1d64), P(\u03b8;D\u1d65)) represents the update of domain divergence reduction between any pair of clients from the source client set U\u209b. However, as aforementioned in Section 2, the integration of Eq. (2) into Eq. (3) is infeasible due to the requirement of accessibility to all source clients' data.\n3.2 MOTIVATION OF INTER-DOMAIN GRADIENT MATCHING\nAddressing the demand for local data access in conventional DG approach, we utilize Invariant Gradient Direction (IGD):\nDefinition 1 (Invariant Gradient Direction Shi et al. (2022)) Considering a model \u03b8 with task of finding domain-invariant features, the features generated by the model \u03b8 is domain-invariant if"}, {"title": "4 FEDOMG: DATA FREE ON-SERVER MATCHING GRADIENT", "content": "4.1 OVERALL SYSTEM ARCHITECTURE\nWe propose a novel method FedOMG, which efficiently aggregates the clients' knowledge to learn a generalized global model \u03b8\u1d64. The main differences between our approach and other current FL and"}, {"title": "5 THEORETICAL ANALYSIS", "content": "To prove the generalization capability of FedOMG, we have the following lemma:"}, {"title": "6 EXPERIMENTAL EVALUATIONS", "content": "6.1 ILLUSTRATIVE \u03a4\u039f\u03a5 TASKS\nFig. 1 presents the performance of FedOMG on Rect-4, revealing several key findings. Firstly, a significant gradient conflict is observed when training in systems with heterogeneous users (e.g., feature divergence), while in the IID setting, the gradient is more aligned toward one direction. Secondly, in FedAvg, users 1 and 2 tend to steer the global model away from the ideal ERM (where data is randomly sampled and not affected by heterogeneity). This issue is exacerbated in the FDG setting, causing the gradient to shift upward, meaning the bias increases (ideally, the bias should be close to zero). Thirdly, FedOMG demonstrates effective gradient matching, aligning closely with ERM gradients in the FL setting or moving towards the optimal point in the FDG setting. The details of experimental settings are demonstrated in Appendix C."}, {"title": "7 CONCLUSION", "content": "In this paper, we present FedOMG, a novel and effective federated learning (FL) domain generalization method aimed at addressing the challenge of heterogeneous client data distributions by learning an invariant gradient. Our method introduces two key innovations: (1) utilizing the local gradient as a critical factor for server-side optimization, and (2) devising a training strategy that identifies optimal coefficients to approximate the invariant gradient across client source domains. We provide theoretical proof to ensure the global invariant gradient solution and conduct extensive experiments demonstrating FedOMG's significant improvements in both standard FL and domain generalization (FDG) settings. This work establishes an optimal approach for server optimization, leading to enhanced FL performance while maintaining privacy constraints."}, {"title": "A RELATED WORKS", "content": "Federated Learning: To contextualize our paper's contribution to on-server optimization, FL can be divided into two primary categories: 1) local training and 2) on-server aggregation. In the first category, substantial efforts have been dedicated to improving the performance of FL, particularly in scenarios involving non-IID data. FedRod (Chen & Chao, 2022) proposes using balanced softmax for training a generic model while utilizing vanilla softmax for personalized heads. FedBABU (Oh et al., 2022) keeps the global classifier fixed during feature representation learning and performing local adaptation through fine-tuning. FedPAC (Xu et al., 2023) adds a regularizer on local training to learn task-invariant representations. Similar to FedPAC, FedAS (Yang et al., 2024) finds the shared parameters which are task-invariant by leveraging the parameter alignment technique. Recently, researchers have focused on on-server aggregation to improve the performance of FL. This approach can be implemented by utilizing generative AI on the server with pseudo data Zhu et al. (2021), or leveraging local gradients to adjust the learning rate (Jhunjhunwala et al., 2023; Panchal et al., 2023).\nFederated Domain Generalization and Adaptation: Huang et al. (2022) and Huang et al. (2024) leverage unlabeled public data to reduce bias toward local data distributions. Nguyen et al. (2022a) regularizes local training via conditional mutual information. Guo et al. (2023) adds a regularization on the local training to implicitly align gradients between the local global models. Qu et al. (2022), Sun et al. (2023) and Fan et al. (2024) leverage sharpness aware minimization to smooth the loss landscape. Tang et al. (2024) utilizes the shared local hidden features to reduce the gradient dissimilarity. Zhang et al. (2023b) introduces server-side weight aggregation adjustments leveraging the auxiliary local generalization gap. Jiang et al. (2024) utilizes the divergence between source and target data gradients to formulate a joint server aggregation rule. However, it requires access to target domain data, which may not be feasible in domain generalization scenarios. Park et al. (2023) introduced a style-based strategy to enhance the diversity of data on source client. Additionally, they integrated attention into the network to highlight common and important features across different domains."}, {"title": "B DETAILED ALGORITHMS", "content": "In Algorithm 1, we present the detailed training procedure of our FedOMG approach. The primary contribution of our method lies in the server-side optimization, while the client-side follows the standard FedAvg algorithm (McMahan et al., 2017), ensuring no additional communication or computation overhead. During each communication round, clients receive the global model parameters and perform local training using SGD for E epochs. The locally updated parameters are then sent back to the centralized server for optimization. On the server, local gradients are computed and used as key components in solving Eq. (15). The resulting gradient closely approximates the invariant gradient direction, as demonstrated in Section 4. Subsequently, the global gradient is computed as shown in Eq. (16), and the global model is updated according to Eq. (17)."}, {"title": "C \u03a4\u039f\u03a5 DATASET DESCRIPTION", "content": "Dataset and Settings Descriptions. Based on Zhao et al. (2019), we design a toy dataset, coined Rect-4, a synthetic binary classification dataset with 4 domains, according to 4 different users. In each domain, a two-dimensional key point xd = (xd,1, xd,2) is randomly selected in the two-dimensional space with varying region distributions. To visualize the gradient of the toy dataset, we design a 1-layer, 2-parameters network. To this end, we can visualize the gradients in a 3-D space, consisting of 2 parameters and 1 weight.\nWe visualize the training data in Figs. 7 and 8. In the FDG setting, the users are from different domains. To this end, we design the data where the point are distributed into rectangular with different size and shape. The rationale of designing the data distribution is as follows:\n The global dataset consists of two classes from two rectangular regions, which has the classification boundary equal to y = 0.\n Each domain-wise dataset has different classification boundary (e.g., x = -6 for domain 1). We add the noisy data on every domains so that the user assign to each domain will tend to learn the local boundary instead of the global boundary. Thus, we can observe the gradient divergence more clearly, as the global boundary is not the optimal solution when learn on local dataset.\n All of the local classification boundary is orthogonal from the global classification boundary, thus, we can make the learning more challenging despite the simplicity of the toy dataset."}, {"title": "D EXTENSIVE EXPERIMENTAL SETTINGS", "content": "D.1 DATASETS\nMNIST (Lecun et al., 1998) consists of 70,000 grayscale images of handwritten digits and ten classes\nEMNIST (Cohen et al., 2017) extension version of original MNIST dataset consists of 70,000 samples and 10 classes\nCIFAR10 (Krizhevsky, 2012) consists of 60,000 images across 10 classes \"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\" and \"Truck\"\nCIFAR-100 (Krizhevsky, 2012) is a more challenging extension of CIFAR-10, consisting of 60,000 images distributed across 100 distinct classes.\nVLCS (Torralba & Efros, 2011) includes 10,729 images from four domains: \"VOC2007\", \"LabelMe\", \"Caltech101\", \"SUN09\" and five classes ('bird', 'car', 'chair', 'dog' and 'person').\nPACS (Li et al., 2017) includes 9,991 images from four domains: \u201cPhotos\u201d, \u201cArt\u201d, \u201cCartoons\u201d, and \u201cSketches\u201d and seven classes ('dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', and 'person').\nOfficeHome (Venkateswara et al., 2017) includes four domains: \u201cArt", "Clipart": "Product\", and \"Real\". The dataset contains 15,588 samples and sixty five classes.\nD.2 BASELINES\nFL Baselines. We consider the following baselines: FedAvg (McMahan et al., 2017), PerAvg (Fallah et al., 2020), FedRod (Chen & Chao, 2022), FedBABU (Oh et al., 2022), FedPac (Xu et al., 2023) and FedAS (Yang et al., 2024) comparing with our proposed method FedOMG.\nFDG Baselines. We implement the following methods: FedAvg (McMahan et al., 2017), FedGA (Zhang et al., 2023b), FedIIR (Guo et al., 2023), FedSam (Qu et al., 2022), FedSR (Nguyen et al., 2022a) and StableFDG (Park et al., 2023).\nD.3 EVALUATION METRIC\nWe report accuracy as the standard metric, defined as the ratio of correctly paired samples to the total number of samples, with Top-1 accuracy being used. In FL scenarios, accuracy is reported as the ratio of the total number of correct samples across all clients to the total number of samples. In FDG scenarios, accuracy is reported for each test domain individually, and the average accuracy across all domains is provided.\nD.4 MODEL\nFor the standard FL task, we use a CNN architecture consisting of two convolutional layers (32 and 64 channels) followed by max pooling layers. It includes two fully connected layers with 512 and number of output classes units, respectively, and ends with a softmax output for class probabilities.\nFor the domain generalization task, we employ a pretrained ResNet-18 backbone model (Zhang et al., 2023b; Park et al., 2023; Guo et al., 2023), which is downloaded from PyTorch. The detailed architecture of the ResNet-18 model used is outlined in Tab. 3.\""}, {"title": "D.5 HYPERPARAMETERS", "content": "In this section, we present the hyperparameters chosen for FedOMG across different datasets."}, {"title": "D.6 IMPLEMENTATION DETAILS", "content": "To evaluate the performance of our proposed federated learning (FL) method, we adopt the methodologies described in Lin et al. (2020); Acar et al. (2021) to simulate non-IID data. We utilize the Dirichlet distribution with two levels of data heterogeneity, specifically \u03b1 = 0.1 and \u03b1 = 0.5. Our experimental setup comprises three configurations of 100 clients, with join rate ratios of 1, 0.6, and 0.4, respectively, and global communication rounds set at 800. Each client undergoes 5 local training rounds using a local learning rate of 0.005, an SGD optimizer, and a batch size of 16. To ensure a fair comparison, all methods are evaluated with the same network architecture and settings.\nFor FDG scenarios, we evaluate model performance using the conventional leave-one-domain-out method Guo et al. (2023); Fan et al. (2024), where one domain is designated as the test domain and all other domains are used for training. Number of clients is set to match the number of source domains. In line with Zhang et al. (2023b); Park et al. (2023); Guo et al. (2023), we use a pretrained ResNet-18 backbone model. Our experiments involve 100 global communication rounds with 5 local training rounds, utilizing the SGD optimizer with a learning rate of 0.001 and a training batch size of 16. Each experiment is conducted three times, and we report the average performance of the global model on the test domain, with each domain serving as the test domain once."}, {"title": "E ADDITIONAL RESULTS AND ABLATION TESTS", "content": "In this section, we provide additional results and conduct an ablation test, including (1) FL accuracy performance across different datasets, (2) convergence analysis, (3) the effect of using a pretrained model, and (4) an ablation test on various global learning rates and hyper-sphere radius."}, {"title": "F PROOF ON THEOREMS", "content": "F.1 TECHNICAL ASSUMPTIONS\nAssumption 1 (L-smoothness) Each local objective function is Lipschitz smooth, that is,\n||\u2207E(x; D\u1d64) \u2013 \u2207E(y; D\u1d64)|| \u2264 L||E(x; D\u1d64) \u2013 E(y; D\u1d64)||, \u2200D\u1d64 \u2208 U\u209b.\nAssumption 2 (\u00b5-strongly convex) Each local objective function is Lipschitz smooth, that is,\n||\u2207E(x; D\u1d64) \u2013 \u2207E(y; D\u1d64)|| \u2265 \u00b5||E(x; D\u1d64) \u2013 E(y; D\u1d64)||, \u2200u \u2208 U\u209b.\nAssumption 3 (Domain triangle inequality Zhao et al. (2019)) For any hypothesis space \u210b, it can be readily verified that d\u210b\u0394\u210b(\u00b7,\u00b7) satisfies the triangular inequality:\nd\u210b\u0394\u210b(D,D\u2033) \u2264 d\u210b\u0394\u210b(D,D\u2032) + d\u210b\u0394\u210b(D\u2032, D\u2033).\nF.2 TECHNICAL LEMMAS\nLemma 4 If we have \u0112\u209b(\u03b8) = \u2211\u1d64\u2208U\u209b \u03b3\u1d64E\u1d64, then for any unseen domain D\u1d1b, we have:\nd\u210b\u0394\u210b(D\u209b, D\u1d1b) = \u2211\u1d64\u2208U\u209b \u03b3\u1d64d\u210b\u0394\u210b(D\u1d64, D\u1d1b).\nProof. From the definition of d\u210b\u0394\u210b(\u00b7, \u00b7) in (Arjovsky et al., 2020), we can get\nd\u210b\u0394\u210b(D\u209b, D\u1d1b) = 2 sup |PrD\u209b(A) \u2013 PrD\u1d1b(A)| = 2 sup |\u2211\u1d64\u03b3\u1d64 PrD\u1d64(A) \u2013 PrD\u1d1b(A)|\nA\u2208A\u210b\u0394\u210b\nA\u2208A\u210b\u0394\u210b\n\u22642 sup |\u2211\u1d64\u03b3\u1d64 [PrD\u1d64(A) - PrD\u1d1b(A)]|\nA\u2208A\u210b\u0394\u210b\n sup |\u2211\u1d64\u03b3\u1d64 [PrD\u1d64(A) \u2013 PrD\u1d1b(A)]|\nA\u2208A\u210b\u0394\u210b\n 2 \u2211\u1d64\u03b3\u1d64 sup |PrD\u1d64(A) - PrD\u1d1b(A)|\nA\u2208A\u210b\u0394\u210b\n= \u2211\u1d64\u03b3\u1d64d\u210b\u0394\u210b(D\u1d64, D\u1d1b).\nLemma 5 For any \u03b8 \u2208 \u0398, the expectation risk gap between domain A and domain B is bounded by the domain divergence d\u210b\u0394\u210b(A, B).\n|EA(\u03b8) \u2013 EB(\u03b8)| \u2264 \u00bdd\u210b\u0394\u210b(A, B).\nProof. By the definition of d\u210b\u0394\u210b(\u00b7, \u00b7) in (Arjovsky et al., 2020), we have:\nd\u210b\u0394\u210b(A, B) = 2 sup |Pr\u2093~\u1d00[f(x; \u03b8) \u2260 f(x; \u03b8\u2032)] \u2212 Pr\u2093~\u0299[f(x; \u03b8) \u2260 f(x; \u03b8\u2032)]|,\n\u03b8,\u03b8\u2032\u2208\u0398\nwhere f(x; \u03b8) means the prediction function on data x with model parameter \u03b8. We chose \u03b8\u2032 as parameter of the label function, then f(x; \u03b8) \u2260 f(x; \u03b8\u2032) means the loss function L(x; \u03b8), so we have:\nd\u210b\u0394\u210b(A, B) = 2 sup |Pr\u2093~\u1d00[L(x; \u03b8)] \u2212 Pr\u2093~\u0299[L(x; \u03b8)]| \u2265 2|EA(\u03b8) \u2212 EB(\u03b8)|.\n\u03b8\u2208\u0398\nHere, (a) holds due to Assumption 1."}, {"title": "F.5 PROOF ON THEOREM 1", "content": "To find the optimal solution of invariant gradient direction \ud835\udc54\u1d35\u1d33\u1d30(\ud835\udc5f) in Eq. (12)", "\ud835\udf06": "s.t. \ud835\udf06 \u2265 0.\nSince the problem is a convex programming and and Slater's condition is satisfied for \ud835\udf05 > 0 (meanwhile", "followings": "nA\u2081 = 9 (+9)-119/+12+\nSubstituting \ud835\udc54\u1d64(\u02b3) = \u2211\u1d64\u03b3\u1d64 \u210e\u1d64(\u02b3). Consider the optimization problem of Eq. (39)", "have": "nA\u2081 = \ud835\udc54(\u02b3)\u2090\u2090 +\u2212\u00bd||\ud835\udc54\u207d\u02b3\u207e\u2090\u2090||\u00b2 +\nTherefore, we have Eq. 37 is equivalent to\nmin \u2212\u00bd||\ud835\udc54\u207d\u02b3\u207e\u2090\u2090||\u00b2 +"}]}