{"title": "AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought", "authors": ["Xin Huang", "Tarun Kumar Vangani", "Zhengyuan Liu", "Bowei Zou", "Ai Ti Aw"], "abstract": "Large language models (LLMs) have shown impressive multilingual capabilities through pretraining on diverse corpora. While these models show strong reasoning abilities, their performance varies significantly across languages due to uneven training data distribution. Existing approaches using machine translation, and extensive multilingual pretraining and cross-lingual tuning face scalability challenges and often fail to capture nuanced reasoning processes across languages. In this paper, we introduce AdaCoT (Adaptive Chain-of-Thought), a framework that enhances multilingual reasoning by dynamically routing thought processes through intermediary \"thinking languages\" before generating target-language responses. AdaCoT leverages a language-agnostic core and incorporates an adaptive, reward-based mechanism for selecting optimal reasoning pathways without requiring additional pretraining. Our comprehensive evaluation across multiple benchmarks demonstrates substantial improvements in both factual reasoning quality and cross-lingual consistency, with particularly strong performance gains in low-resource language settings. The results suggest that adaptive reasoning paths can effectively bridge the performance gap between high and low-resource languages while maintaining cultural and linguistic nuances.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities (Achiam et al., 2023), yet their performance varies significantly across languages, with a notable bias toward high-resource languages like English. Moreover, this limits the effectiveness and accessibility of LLMs for speakers of other languages, despite increasing worldwide demand for AI systems that can serve diverse linguistic communities. While machine translation offers a straightforward solution, it proves inadequate for developing robust multilingual reasoning capabilities, often introducing artifacts and failing to capture nuanced logical processes across linguistic boundaries.\nPrevious work has focused primarily on data-level improvements through training on large-scale, balanced multilingual corpora, including continual pretraining (Xu et al., 2024; Yang et al., 2023), multilingual instruction fine-tuning (Li et al., 2023; Zhang et al., 2024), and cross-lingual instruction fine-tuning on translation pairs (Zhang et al., 2023; Zhu et al., 2023). Recent efforts have explored representation-level solutions by aligning multilingual representations (Li et al., 2024a,b), building on evidence that consistent multilingual representations enhance knowledge transfer (Tang et al., 2022). However, these methods typically require extensive training data or fail to deliver uniform improvements across languages (Zhu et al., 2023; Li et al., 2024a).\nStudies on language representation subspaces in LLMs demonstrate that LLMs have a language-agnostic reasoning core that can be exploited to improve multilingual performance without extensive cross-lingual pretraining (Tang et al., 2024; Zhao et al., 2024). However, while this core enables basic reasoning capabilities, the uneven distribution of cultural and domain-specific knowledge across languages leads to significant performance gaps in factual reasoning tasks. This challenge is particularly acute for low-resource languages, which receive limited exposure during training, and a framework leveraging language-specific strengths while preserving cultural context is needed. Building on this insight, we introduce AdaCoT, a novel framework for optimizing multilingual reasoning in LLMs through adaptive chain-of-thought. AdaCoT strategically routes reasoning steps through intermediate \"thinking languages\" before generating target-language outputs. Our key insight is that certain languages may be more effective for specific categories of reasoning tasks, whether due to structural characteristics, cultural context, or the model's training distribution. For instance, languages with rich logical connectives may perform better in deductive reasoning, whereas languages with extensive mathematical vocabulary could be more adept at quantitative tasks.\nThe AdaCoT framework operates on two key principles: (1) Dynamic Routing Optimization, which learns to select the most effective intermediate languages based on task characteristics and performance history; and (2) Cross-Lingual Knowledge Integration, which synthesizes insights from multiple linguistic perspectives to produce more robust final outputs.\nOur approach incorporates an adaptive reward-based mechanism that dynamically selects optimal reasoning pathways, learning to route queries through appropriate intermediate languages based on performance feedback. This selective approach allows the model to leverage the strengths of different languages while maintaining computational efficiency, as it requires no additional pretraining on large multilingual corpora. The reward mechanism considers factors such as reasoning consistency, answer accuracy, and linguistic fluency to continuously refine its routing decisions.\nEmpirical evaluation across multiple benchmark datasets, including multilingual Truthful-QA, CrossAlpaca-Eval 2.0, Cross-MMLU and Cross-LogiQA, demonstrates significant improvements in reasoning quality and consistency across diverse languages. Our analysis reveals particularly strong gains in low-resource languages when reasoning is routed through linguistically related high-resource languages, suggesting the existence of transferable reasoning patterns within language families. Furthermore, we observe that the adaptive routing mechanism learns meaningful patterns, such as preferring languages with precise technical vocabularies for scientific reasoning tasks and those with rich emotional expression for sentiment-based tasks. These findings not only validate the effectiveness of AdaCoT but also provide insights into the nature of multilingual reasoning in LLMs. The success of language-specific routing suggests that different languages may encode different cognitive patterns, and leveraging these differences can lead to more robust and nuanced reasoning capabilities. Our work opens new avenues for research into language-aware neural architectures and cross-lingual knowledge transfer mechanisms."}, {"title": "2 Related Work", "content": "Large language models (LLMs) exhibit multilingual capabilities through pretraining on diverse corpora (Bang et al., 2023). While primarily developed for resource-rich languages such as English, French, and Chinese, LLMs have shown unexpected proficiency across languages (Dubey et al., 2024). However, uneven training data distribution at language level leads to performance disparities between high and low-resource languages (Qi et al., 2023; Wang et al., 2024a; Chua et al., 2024).\nEffective multilingual alignment requires careful design of both pretraining and instruction tuning strategies (Gao et al., 2024). Recent approaches include multilingual contrastive learning with cross-lingual instruction tuning (Li et al., 2024a) and word-level alignment before code-switched pre-training (Li et al., 2024b). Translation parallel pairs have proven particularly effective (Zhang et al., 2023; Zhu et al., 2024; Mu et al., 2024; Lin et al., 2024). Notable advances include two-stage training combining extensive monolingual data with high-quality translation datasets (Xu et al., 2024), integration of multilingual translation and task instructions (Zhu et al., 2023), and self-distillation methods transferring capabilities from high to low-resource languages (Zhang et al., 2024). While Cross-lingual Expert Language Models (X-ELM) train independently on multilingual corpus subsets (Blevins et al., 2024), native language prompting remains crucial for culture-specific tasks requiring nuanced understanding (Liu et al., 2024).\nFor cross-lingual reasoning, multilingual instruction tuning with English as the default thinking language improves reasoning consistency on math problems (Lai and Nissim, 2024). Moreover, layer transplantation between language and math experts, fine-tuned from a common pretrained model, enhances mathematical performance in target languages (Bandarkar et al., 2024).\nRecent studies on language processing dynamics reveal that English-centric LLMs use English as an internal pivot language (Wendler et al., 2024), while non-English-centric models leverage their primary training language (Zhong et al., 2024). Analysis of language-agnostic knowledge neurons and cross-lingual neural patterns suggests that aligning multilingual representations enhances knowledge transfer (Wang et al., 2024c; Tang et al., 2024; Cao et al., 2024)."}, {"title": "3 Methodology", "content": "We propose a novel framework, AdaCoT, for optimizing multilingual reasoning in LLMs through adaptive chain-of-thought. The core concept of AdaCoT is to leverage intermediate reasoning steps in one or more auxiliary \u201cthinking languages\" to improve the final output quality in a target language. This approach builds on the observation that, although LLM reasoning is largely language-agnostic, model performance can vary significantly across different languages due to disparities in training data, linguistic features, and alignment.\nAdaCoT leverages the dynamic integration of reasoning tokens in thinking languages. The thinking languages are selected based on their linguistic similarity, resource availability, or alignment with the target language. The reasoning tokens in auxiliary languages guide the model toward generating more accurate and contextually appropriate responses in the target language. For instance, dominant or well-aligned languages with extensive resources (e.g., English) may serve as mediators for reasoning tasks in underrepresented languages. To this end, we propose a dual-pathway mechanism, where Cross-Lingual Chain-of-Thought leverages chain-of-thought reasoning in auxiliary languages to enhance output quality, while Direct Generation bypasses intermediate languages for efficient generation in well-supported target languages or contexts requiring minimal cross-linguistic reasoning.\nThe pathway selection is optimised through a reward-based fine-tuning process, making the model dynamically select the most effective reasoning strategy based on the input context. The optimisation process is to train the base model with reward signals derived from a GPT-based reward LLM, which the model learns to balance the trade-offs between intermediate and direct reasoning strategies. It leads to improved performance across diverse languages and contexts. An overview of AdaCoT is illustrated in Figure 1 and 2."}, {"title": "3.1 Candidate Response Generation", "content": "During the training stage, given a user query in a specific language, AdaCoT first leverages an LLM to translate the input into multiple primary languages, including the original input language and three auxiliary languages: English, Chinese, and Indonesian. Such multilingual translation step forces the model to reason with diverse linguistic contexts. Based on this setup, we employ two distinct reasoning strategies to generate a diverse pool of candidate outputs:\n\u2022 Cross-Lingual Chain-of-Thought. This approach uses intermediate reasoning steps in auxiliary languages to guide the creation of the final response. We begin by translating the original prompt into auxiliary languages such as English, Chinese, and Indonesian, then instruct the LLM to generate responses for each translated version. Because the internal knowledge of the model can vary between languages, these responses may differ and reflect unique linguistic and cultural nuances. To synthesize these diverse outputs into a coherent final response that both follows the original instructions of the prompt and preserves the underlying knowledge of each intermediate response, we employ a teacher model (e.g., GPT-40) in each of the primary languages. Formally, given a prompt $P_l$ in language $l$ and an intermediate response $I_t$ in auxiliary language $t$, we instruct the teacher model to produce a final response $R_l$ in language $l$. The aim is for $R_l$ to keep the semantic meaning of $I_t$ while adhering to the original instruction $P_l$.\n\u2022 Direct Generation. Direct Generation creates responses in the intended language without relying on any auxiliary languages. Given a prompt $P_l$ in language $l$, the model directly produces the response $R_l$ in the same language. This strategy is especially useful if the model is already strong in that language or in situations where using multiple languages might degrade the performance, such as linguistic dependent tasks like writing poetry.\nThe algorithm 1 depicts the training pair generation process. With these two strategies, AdaCoT generates diverse responses across multiple language pathways, which can then be ranked by a powerful LLM. Because certain knowledge may not be available or shared in all languages, the approach helps reduce the risk of factual hallucinations."}, {"title": "3.2 Candidate Response Ranking", "content": "We score the diverse responses in different language pathways using an LLM as a judge, then select the optimal auxiliary language or opt for direct generation based on the highest score. Given"}, {"title": "3.3 AdaCoT Fine-Tuning", "content": "We use the judging scores $S_t$ to guide the selection of optimal reasoning actions, maximizing the likelihood of choosing the pathway with the highest score across various primary thinking languages. We fine-tune only on instances where $S_t >= 9$ allowing the model to learn from reasoning strategies that yield the highest quality outputs. For each training example, we select the optimal reasoning pathway that attains the highest score, whether it involves reasoning through an intermediate language or directly generating in the target language. Note that both the intermediate response $I_t$ and the final response $R_l$ are generated by the LLM itself rather than using labels from external dataset, to prevent possible potential knowledge forgetting during fine-tuning. The fine-tuning process allows the model to dynamically adapt different thinking process based on contextual requirements of input prompts.\nTraining examples are formatted with special prompts to represent the reasoning pathways. For a input query $P_i$ with a corresponding final answer $R_t$, if intermediate reasoning $I_t$ is included, the training example is structured as:\n$P_i [P_l^f] I_t [P_l^r] R_l$\nWe use $P_l^f$ to denote a special prompt that separates intermediate reasoning tokens from the query, and $P_l^r$ to separate the final answer from the intermediate tokens. Note that $R_l$ is not a direct translation of the intermediate reasoning tokens. Rather, $R_l$ is generated using $I_t$ as an in-context learning example. The distinction allows the model to generate responses that adhere to the user query, rather than generating responses with fixed language that could be contextually inappropriate if the response requires multiple languages.\nWhen it's direct generation of the answer without intermediate thinking, the format simplifies to:\n$P_i [P_l^r] R_l$\nWe also set attention mask of $P_i$ to 0 during the fine-tuning process to force the model only predicts correct reasoning pathways and final responses given an input prompt."}, {"title": "4 Experimentation", "content": ""}, {"title": "4.1 Experiment Setup", "content": ""}, {"title": "4.1.1 Base Models", "content": "The AdaCoT is applicable to various open-source models. For this experiment, we use LLaMA3.1-8B-Instruct (Dubey et al., 2024) and Qwen2.5-7B-Instruct (Qwen et al., 2025) as the base models. LLaMA3.1-8B is particularly strong in English reasoning tasks and Qwen2.5-7B excels at reasoning in both English and Chinese. Thus we can explore AdaCoT's impact in base LLMs that possess high-resource knowledge in multiple languages."}, {"title": "4.1.2 Primary Thinking Languages", "content": "We select English, Chinese, and Indonesian as intermediate reasoning languages. We choose English and Chinese for their extensive knowledge bases and linguistic resources, as well as the often unshared or misaligned knowledge between them, which can create performance gaps when transferring knowledge. We also include Indonesian as a low-resource language to evaluate AdaCoT's ability to transfer knowledge from high-resource languages and reduce performance disparities."}, {"title": "4.1.3 Training Datasets", "content": "To determine best reasoning pathway for the base LLM, we need to explore diverse instructions and cover as many input instruction types as possible. To this end, we use 1 million English OpenHermes 2.5 (Teknium, 2023) and 1.1 million chinese instruction dataset from Firefly (Yang, 2023) as our base dataset. We further augment the dataset by leveraging GPT-40 model to translate the datasets which covers all primary thinking languages including English, Chinese, and Indonesian. We use only the instructions of these datasets, and leverage algorithm 1 and the Candidate Response Ranking method to generate the final dataset for fine-tuning."}, {"title": "4.2 Evaluation Datasets", "content": ""}, {"title": "4.2.1 Multilingual TruthfulQA", "content": "Multilingual TruthfulQA (Lai et al., 2023) is designed to assess the truthfulness of LLMs in multilingual settings. It includes parallel questions translated from original TruthfulQA (Lin et al., 2021) into 31 diverse languages using GPT-3.5-turbo."}, {"title": "4.2.2 CrossAlpaca-Eval 2.0", "content": "The CrossAlpaca-Eval 2.0 dataset is an open-ended question-answering dataset with paralleled instruction pairs in English, Chinese, and Indonesian languages from Alpaca-Eval 2.0 (Dubois et al., 2024) by translating the original English instruction pairs into these languages via GPT-40. We choose this dataset in order to understand the effectiveness of AdaCoT in diverse tasks."}, {"title": "4.2.3 Cross-MMLU and Cross-LogiQA", "content": "For logical reasoning evaluation, we use Cross-MMLU and Cross-LogiQA (Wang et al., 2024b).\nCross-MMLU: Cross-MMLU is derived from the MMLU (Hendrycks et al., 2021) dataset. The dataset contains parallel questions from MMLU in English, Chinese and Indonesian, and each language comprising 150 questions. The original English questions were initially translated using Google Translate, and have been edited and filtered by native speakers to ensure accurate translations and guarantee semantically equitable evaluations across all languages.\nCross-LogiQA: Cross-LogiQA is adapted from the LogiQA2.0 (Liu et al., 2023) dataset, a benchmark for evaluating logical reasoning abilities in natural language understanding. The dataset consists of 176 questions per language across English, Chinese and Indonesian languages, developed using the same translation and verification process as Cross-MMLU to produce parallel versions in all languages. This dataset allows us to examine whether models can perform consistent logical deductions across different linguistic representations of the same logical problem."}, {"title": "4.2.4 Evaluation Metrics", "content": "Our evaluation consists of two primary evaluation metrics. For open-ended question-answering tasks in the CrossAlpaca-Eval 2.0 dataset, we use LLM-as-a-judge for the comprehensive evaluation of model responses. Recent work such as Zheng et al. (2024) finds that reward LLMs like GPT-4 align well with human preferences which archives over 80% agreement, therefore providing scalable and consistent evaluations of model outputs. We employ GPT-40 as judging model, we use likert scale from 0 to 10 to score model outputs based on criteria including correctness, coherence, and adherence to instructions.\nFor multiple-choice question tasks in the multilingual TruthfulQA, Cross-MMLU and Cross-LogiQA datasets, we implement an answer selection evaluation method. In this method, the evaluation LLM is prompted to select the correct answer from a set of labeled options provided in the model's output. The model's selections are then compared to the ground-truth answers to calculate accuracy. We use instructed version of gemma-2-27b (Team et al., 2024) as the evaluator. This method provides an accurate evaluation of the model's response in different styles and better handles cases where the model produces chain-of-thought tokens. Note that for AdaCoT models, we remove the intermediate thinking tokens before evaluation to ensure fair evaluations.\nWe additionally evaluate cross-lingual consistency $C$ for Cross-MMLU and Cross-LogiQA to measure the consistency of the answers regardless of whether answer is correct or not. Let $Q$ be the total number of questions, $L$ be the number of languages, and $\\hat{y}_{l,q}$ be the model's prediction for language $l$ on question $q$. We measure the consistency for all 3 languages using following formula:\n$C = \\frac{1}{Q} \\sum_{q=1}^Q \\mathbb{I}(\\hat{y}_{1,q} = \\hat{y}_{2,q} = ... = \\hat{y}_{L,q})$"}, {"title": "4.3 Experimental Results", "content": ""}, {"title": "4.3.1 AdaCoT improves multilingual factual reasoning", "content": "Table 1 reports the comparison results on multilingual TruthfulQA dataset. The LLaMA3.1-8B-AdaCoT model demonstrates performance improvements across all primary languages. The model achieves a 2.5%, 5.7% and 7.2% relative performance gain in English, Chinese and Indonesian respectively compared to the base LLaMA3.1-8B model. We also find the AdaCoT enhanced LLaMA model generalises to other low-resource languages, including Danish, Basque, Armenian, and Russian, with performance improvements exceeding 9% in absolute terms. The LLaMA3.1-8B-AdaCoT model shows marked improvements in 30 out of 32 languages tested. For Qwen 2 7B, AdaCoT yields more modest improvements in primary languages with a relative performance increase that is smaller compared to the LLAMA model, possibly due to the much smaller performance gaps across all primary languages.\nTable 2 presents the evaluation results on the CrossAlpaca-Eval 2.0 dataset. We first observe that both LLaMA3.1-8B and Qwen2.5-7B base models perform strongly in English, with Qwen2.5-7B also demonstrating strong performance in Chinese. Then we find the AdaCoT method maintains the same performance in English while exhibiting significant performance gains in Chinese and Indonesian for the LLaMA3.1-8B model. It also yields small performance gains in Chinese and noticeable performance gains in Indonesian for Qwen2.5-7B model. The results show the effectiveness of AdaCoT which leverages the knowledge from high-resource languages to improve response quality of general instructions in low-resource languages.\nWe also notice similar performance gains in reasoning benchmarks like CrossMMLU and Cross-LogiQA dataset as shown in table 3. For Cross-MMLU dataset, the AdaCoT method improves both Qwen2.5-7B and LLaMA3.1-8B in Chinese and Indonesian reasoning while maintaining same performance in English. For CrossLogiQA dataset, we find the AdaCoT method also improves English which is already a high resource language, suggesting the adaptive language routing can also benefit high resource language settings. Finally, we find that AdaCoT improves the consistency of the models' responses when they are prompted with the same question in different primary languages."}, {"title": "4.3.2 Adaptive Language Routing for Enhanced AdaCoT Performance", "content": "Adaptive Language Routing (ALR) serves as a fundamental mechanism in the AdaCoT framework, which improves multilingual factual reasoning by strategically selecting intermediate thinking language based on characteristics of input prompt and performance feedback. ALR enables a contextually adaptive reasoning process that can draw upon the most suitable pre-trained linguistic knowledge for each unique instruction.\nWe conduct an ablation study on CrossAlpaca-Eval 2.0 to systematically analyze the influence of different language routing strategies. This dataset allows us to compare performance of the models across more input instruction types and more comprehensively explore the various routing strategies. The ablation study compares five variants of our approach applied to the LLaMA 3.1-8B model, alongside the official LLaMA 3.1-8B baseline and the original AdaCoT model. Table 4 summarizes the mean GPT-40 scores in all three primary languages.\nWe first investigate the effect of consistently \"thinking\u201d in a single auxiliary language by analyzing four variants against the official LLaMA 3.1-8B baseline and then analyses the effectiveness of score-based filtering method. We observe that: (1) Thinking exclusively in English consistently outperforms thinking in other primary languages, which is largely attributable to the model's extensive English pre-training. This finding underscores English as the dominant knowledge resource for diverse tasks within the LLaMA model. (2) The score-based filtering mechanism can improve the performance of ALR, which demonstrates the importance of retaining only high-quality training examples. (3) Limiting thinking to English is significantly worse than adaptive language routing. The results show 5.2% and 9.3% relative performance gains compared to thinking only in English, suggesting the need to dynamically adjust reasoning strategies for improved performance."}, {"title": "4.3.3 Case Studies on AdaCoT", "content": "Table 5 shows how LLaMA3.1-8B-AdaCoT adapts its reasoning pathways based on the prompt. In linguistically dependent tasks like composing a poem, the model strategically generates content directly in Chinese, leveraging the language's inherent semantic richness to preserve poetic fluency and avoid the potential information loss associated with translation or intermediate reasoning processes. Likewise, when prompted with an English word riddle that simply asks for a rhyming word, AdaCoT again employs direct generation and provides the correct answer on par with the baseline. Notably, in both cases, the AdaCoT fine-tuned model shows no degradation in answer quality.\nFor questions where intermediate reasoning can help, AdaCoT leverages high-resource languages (e.g., English) to boost accuracy. An example is the Chinese probability question, where the base LLaMA3.1-8B model incorrectly predicts the chance of getting at least one head in two coin tosses, but AdaCoT's chain-of-thought in English yields the correct 3/4 answer in Chinese. Similarly, when asked in Indonesian about Singapore's longest expressway, the baseline mistakenly identifies the KPE, while AdaCoT correctly names the PIE by tapping into its richer English-based knowledge. These examples underscore the AdaCoT's adaptive reasoning approach, highlighting its capacity to dynamically select optimal linguistic pathways and significantly improve multilingual reasoning across diverse task domains while maintaining performance in high-resource language setting."}, {"title": "5 Conclusion", "content": "We introduced AdaCoT, a framework that strategically uses intermediate \u201cthinking languages\" to boost cross-lingual factual reasoning. By adaptively routing queries through well-resourced or better-aligned languages, AdaCoT bridges performance gaps in low-resource languages while retaining strong results in high-resource settings. We also introduce an AdaCoT fine-tuning process that leverages a reward LLM to rank different reasoning pathways and selects the best pathway to optimize the model. Our experiments on Multilingual Truth-fulQA, CrossAlpaca-Eval 2.0, CrossMMLU, and CrossLogiQA show consistent improvements, highlighting the benefits of Adaptive Language Routing in selecting the optimal reasoning pathway."}, {"title": "Limitation", "content": "While our experiments show the potential of leveraging three primary thinking languages to enhance cross-lingual factual reasoning, the current approach has limitations in comprehensive linguistic transfer. The framework depends on a limited set of languages which restricts its generalization across broader linguistic contexts. Expanding the number of thinking languages presents a complex trade-off: potential performance improvements in underrepresented languages are counterbalanced by substantive challenges, including increased training complexity and the risk of introducing semantic distortions from wrongly translated data. Furthermore, the adaptive routing mechanism, despite its innovative design, introduces computational inefficiencies manifested through higher inference latency. Lastly, AdaCoT requires diverse, high-quality training instructions which may be hard to obtain for certain domains or low-resource languages."}]}