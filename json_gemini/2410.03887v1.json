{"title": "Solving Dual Sourcing Problems with Supply Mode Dependent Failure Rates", "authors": ["Fabian Akkerman - University of Twente", "Nils Knofius - Fieldmade AS", "Matthieu van der Heijden - University of Twente", "Martijn Mes - University of Twente"], "abstract": "This paper investigates dual sourcing problems with supply mode dependent failure rates, particularly relevant in managing spare parts for downtime-critical assets. To enhance resilience, businesses increasingly adopt dual sourcing strategies using both conventional and additive manufacturing techniques. This paper explores how these strategies can optimise sourcing by addressing variations in part properties and failure rates. A significant challenge is the distinct failure characteristics of parts produced by these methods, which influence future demand. To tackle this, we propose a new iterative heuristic and several reinforcement learning techniques combined with an endogenous parameterised learning (EPL) approach. This EPL approach \u2013 compatible with any learning method \u2013 allows a single policy to handle various input parameters for multiple items. In a stylised setting, our best policy achieves an average optimality gap of 0.4%. In a case study within the energy sector, our policies outperform the baseline in 91.1% of instances, yielding average cost savings up to 22.6%.", "sections": [{"title": "Introduction", "content": "Unplanned asset downtime is a costly issue in many industries, as over the past five years, the average cost of downtime across the consumer goods, automotive, oil and gas, and heavy industry sectors has doubled, rising from $400,000 to $800,000 per hour (Siemens 2024). For example, offshore oil and gas companies face annual costs of $49 million due to unplanned downtime (GE Oil and Gas 2016), while the aerospace industry loses $6 billion annually because of grounded aircraft (Locatory 2023). Globally, the 500 largest companies are estimated to lose $1.4 trillion per year due to unplanned downtime, equivalent to 11% of their revenues. Downtime results in lost sales, production delays, safety hazards, and significant expenses for (temporary) fixes. A major cause of unplanned downtime is the failure of critical parts (such as those found in manufacturing equipment), which accounts for 45% of reported downtime instances (VansonBourne 2023).\nSpare parts' repair and replenishment lead times are lengthy across various industries. For instance, in the aerospace and defence sector, the average replenishment lead time of spare parts is approximately 100 days (Deloitte 2024). For some parts used on offshore oil and gas platforms, lead times can extend up to 16 weeks (Everett 2022), while in the automotive industry, it can take up to 9 months (Antich 2023). Traditionally, downtime of critical assets is mitigated by stocking spare parts close to the installed base. However, since these bases are often geographically dispersed, a substantial portion of the inventory must be stocked at multiple global locations. Additionally, complex assets contain thousands of expensive components, making the stocking of critical spare parts a costly endeavor.\nTo improve the balance between asset downtime and spare parts inventory investment, reducing lead"}, {"title": "Literature Review", "content": "Our research is related to three areas in the literature that we will discuss, namely AM for spare parts (Section 2.1), dual sourcing (Section 2.2), and RL for inventory problems (Section 2.3). In Section 2.4, we state our contribution to the existing body of literature."}, {"title": "AM for Spare Parts", "content": "The possible application of AM for spare parts supply chains have attracted considerable attention in the literature in the last years, as AM is in particular useful for one piece manufacturing of customised products. Most spare parts assortments for high-tech assets contain many slow movers with conventionally long lead times, for which shorter lead times are highly desirable. Early papers on the application of AM to spare parts focused on the selection of parts that are suitable for AM (Lindemann et al. 2015;\nKnofius et al. 2016). These papers proceed from the characteristics of parts that are currently sourced through CM. An aspect that is typically challenging to address is the difference in failure behaviour.\nWits et al. (2016) explain that part properties will differ significantly between AM and CM produced items, leading to differences in failure behaviour and thus impacting spare parts demand.\nNumerous model variants have been investigated. Westerweel et al. (2018) study the trade-off between deploying AM or CM for spare parts. Sgarbossa et al. (2021) include multiple AM and CM techniques to decide between AM and CM. Song and Zhang (2020) examine the trade-off between AM and CM across multiple SKUs, considering the finite capacity of 3D printers.\nKnofius et al. (2019) analyse the impact of using AM print parts in one piece (consolidation) versus assembling them from multiple subcomponents on life cycle costs. They find that initial cost savings from AM may be offset by higher maintenance costs if expensive consolidated AM parts are needed for repairs, instead of the cheaper subcomponents in CM. Additionally, Cantini et al. (2024) demonstrate that AM, by enabling decentralised manufacturing, influences the spare parts supply chain design.\nWesterweel et al. (2021) show the value of AM for decentralised spare parts production, especially for remote assets like those in defence missions. AM remains viable even if the part quality is lower than centrally produced spare parts. Further research has revealed that AM of spare parts is useful in cases of supply disruptions, such as natural disasters, unexpected demand surges, or when a part supplier discontinues production during the asset's life cycle (e.g., Ivanov et al. (2019)). For a more comprehensive discussion, we refer to the literature reviews by Verboeket and Krikke (2019), and Kunovjanek et al. (2022)."}, {"title": "Dual Sourcing", "content": "Dual sourcing models typically differentiate between two supply options: one that is inexpensive but has a long resupply lead time (regular supply), and another that is expensive but offers a shorter resupply lead time (expedited order). The first contribution to the dual sourcing literature is by Barankin (1961),"}, {"title": "RL for Inventory Problems", "content": "An early paper on RL for inventory management is Gijsbrechts et al. (2022). They use a deep RL approach (employing neural networks) and find that their general solution framework is matching or even outperforming commonly used heuristics. However, they also acknowledge that these results were achieved with substantial tuning effort. For the dual sourcing problem they consider, it is not yet clear whether an RL framework or a dedicated heuristic is the better approach.\nTemiz\u00f6z et al. (2023) introduce a novel deep RL framework based on approximate policy iteration that is specifically designed to solve inventory problems. The authors emphasise a significant advantage: a single set of hyperparameters proves effective across all their experiments. This implies high robustness and reduces the necessity for fine-tuning hyperparameters to individual problem instances. Therefore, this technique emerges as a promising candidate for application to our specific dual sourcing problem.\nTang et al. (2024) apply online learning to dual sourcing problems with periodic review to learn unknown demand distributions from demand realisations. They use a dual index policy as a heuristic for sourcing decisions, following Veeraraghavan and Scheller-Wolf (2008). Their focus on demand learning is distinctly different from our approach, as we explore broader RL applications and novel heuristic methods to enhance dual sourcing strategies.\nB\u00f6ttcher et al. (2023) explore dual sourcing inventory systems using recurrent neural networks (RNNs) to learn near-optimal inventory policies. While their approach offers valuable insights, it may not be"}, {"title": "Contribution", "content": "The literature shows a gap in addressing dual sourcing problems with sourcing decisions influencing future demand, lacking scalable policies for realistically sized problems. Despite growing interest in RL, it proves non-robust for spare parts management with changing parameters, leading to ineffective policies for different items. This reveals a need for scalable and generalizable solutions. Our contribution to the scientific body of literature includes:\n1.  We design three distinct classes of RL approaches to obtain policies for the same problem, each trained separately on individual SKUs, and evaluate the conditions under which each method is preferred.\n2.  We introduce an approach where a single RL policy is trained to generalise across multiple SKUs. We evaluate this approach on trained SKUs and demonstrate its effectiveness on SKUs that are not included in the training set.\n3.  We develop a novel iterative heuristic for large-scale dual sourcing problems with sourcing-dependent demand, extending beyond slow movers.\n4.  We apply our proposed approaches to a real-world case study in the energy sector, showcasing the practical applicability of our model and methodology."}, {"title": "Problem Formulation", "content": "We formalise the dual sourcing problem as an MDP in this section. Section 3.1 provides the problem setting. Section 3.2 outlines the model notation. Sections 3.3 and 3.4 describe the constraints on the state and decision spaces, respectively. Section 3.5 covers transitions and transition probabilities. Finally, Section 3.6 explains the evaluation of expected costs for given states and decisions."}, {"title": "Problem Setting and Assumptions", "content": "We consider a service provider that orders spare parts for a specific critical component using either CM or AM. Both supply modes are characterised by different failure rates, replenishment lead time, and piece price. CM may require significant setup costs, necessitating batch ordering, in contrast to AM where setup costs are typically low once the digital asset for the part is created. Parts are non-repairable and always need to be replaced whenever they fail. The service provider has to decide how many batches to order from the CM suppliers, and how may items from the AM supplier.\nWe formulate the problem as a discrete-time, periodic-review model. The sequence of events at a given period t is as follows:\n1.  At the start of a period, the current state of the system is recorded as input to the reorder policy.\n2.  Potential replenishment orders from the CM and/or AM source are placed.\n3.  Holding, reordering, maintenance, and backorder costs are incurred.\n4.  During a period, parts may fail and are replaced by the stock on-hand, or alternatively backordered.\n5.  At the end of a period, possible replenishment arrives, which is put in stock and/or used for backorder clearing without further delay.\nDuring this event sequence, the decision-maker has to decide on the reordering decision at step (2). In addition, we make the following assumptions to obtain a tractable model with an exact solution procedure.\n1.  Lead times are deterministic.\nResupply lead times are usually part of contractual agreements that guarantee a high delivery reliability within the specified lead time.\n2.  Lead times are a multiple of the review period.\nThis assumption simplifies the analysis because orders can only arrive at the end of a period. This is an assumption with marginal effect, as in practice we can always select a review period that ensures this.\n3.  Demand per item is i.i.d. between subsequent periods, conditional on the number of operating CM and AM parts at the beginning of the period, and follows a discrete distribution for the individual demand.\nThe demand is endogenous, and failures and replacements may change the proportion of operating CM and AM items during a period. However, demand is independent from the demand in the previous period."}, {"title": "Transitions", "content": "We first describe the transition function for each state variable, followed by the computation of transition probabilities. Recall that the realised number of CM and AM failures in a period are denoted by $k_{c,t}$ and $k_{a,t}$, respectively. The number of CM (AM) items in the installed base at the beginning of period t + 1 is equal to the number at the beginning of period t, minus the number of CM (AM) parts that failed, plus the number of CM (AM) parts that replaced the failed parts, and any backorders. The last component is complex, as it depends on the availability of parts (AM and CM) and on which part has the lowest failure rate, see Assumption 4. The installed base composition at the beginning of period t+1 is then obtained as follows:\n$n_{c,t+1} = n_{c,t} - k_{c,t} + y_{c,t} + z_{c,t}$,\n$n_{A,t+1} = n_{A,t} - k_{A,t} + y_{A,t} + z_{A,t}$,\nwhere the helper variables $y_{c,t}$ ($y_{A,t}$) denote the maximum number of CM(AM) items that are available before a possible replenishment arrives at the end of period t, and $z_{c,t}$ ($z_{A,t}$) the maximum number of CM(AM) items that are available after a possible order arrival. We need this distinction, since we assume that items with lower failure rate are consumed first with on-hand stock available before the arrival of replenishments; cf. Assumption 4. In Appendix A we detail how we calculate the values of $y_{c,t}, y_{A,t}, z_{c,t}$, and $z_{A,t}$. For the on-hand stock in period t + 1, we have:\n$s_{C,t+1} = s_{C,t} + A_{c,t} - y_{C,t} - z_{C,t}$,\n$s_{A,t+1} = s_{A,t} + A_{A,t} - y_{A,t} - z_{A,t}$,\nwhere $A_{ct}$ ($A_{A,t}$) equal the number of CM (AM) replenishment items that may arrive at the end of period t, see Appendix A for its definition. The order quantities are updated by recording all orders still to arrive:\n$u_{C,t+1,t'} = x_{C,t'} \\forall t' \\in [t - l_c + 1, t]$,\n$u_{A,t+1,t'} = x_{A,t'} \\forall t'\\in [t-l_a+1,t]$,\n$u_{c,t+1,t'}$ and $u_{a,t+1,t'}$ may contain zeros, indicating that no order was placed at t'.\nNext, we derive the transition probabilities of the items in operation. Equations 6-11 show the deterministic transitions dependent on the decisions. The only stochastic component of the transitions are failures ($k_{c,t}$ and $k_{a,t}$) in a review period, which influence the parts in operation ($n_{c,t}$ and $n_{A,t}$). Using Assumption 3 from Section 3, the probability mass functions $P_c(k_{c,t}|n_{c,t})$ and $P_A(k_{a,t}|n_{a,t})$ are characterised by $E[k_x] = \\mu_x n_{x,t}$ and $Var[k_x] = V_x n_{x,t}$ for production method $x \\in \\{C, A\\}$. Assumption 3 may result in $k_{c,t} > n_{c,t}$ and $k_{a,t} > n_{A,t}$ with low probability, as we do not track the installed base during a review period. We address this by assigning the probability masses to cases where $k_{c,t} = n_{c,t}$ and $k_{a,t} = n_{A,t}$, respectively, thus limiting failures to $n_{c,t}$ and $n_{A,t}$. This simplification is reasonable since the probability of failures exceeding the installed base size within one review period is negligible for realistic instances. We define the transition probabilities using $k_{c,t}$ and $k_{a,t}$:\n$P (n_{c,t+1}, n_{A,t+1}|n_{C,t}, n_{a,t}) = P_c (k_{c,t}|n_{c,t})P_a(k_{a,t}|n_{a,t}).$"}, {"title": "Cost Function", "content": "We minimise the average service costs per period, $C(i_t, x_C, x_A)$, consisting of purchasing costs $P(x_C, x_A)$ (fixed and variable), holding costs $H(i_t)$, backorder costs $BO(i_t)$ and maintenance costs $M(i_t)$ over an infinite horizon. The purchasing costs are equal to:\n$P(x_C,x_A) = 1_{x_C>0}k_C + 1_{x_A>0}k_a + c_cx_CQ_c + c_Ax_A,$\nwhere $1_{x_C>0}$ ($1_{x_A>0}$) is the indicator function, which is equal to 1 if $x_c > 0$ ($x_a > 0$) and 0 otherwise, and used to determine the fixed order costs. The holding costs and the expected backorder costs are equal to:\n$H(i_t) = h(s_{c,t} + s_{A,t}),$\n$BO(i_t) = max(k_{c,t} + k_{a,t} + B_t - s_{C,t} - s_{A,t}, 0)b.$\nWe encounter expected maintenance cost for each failure and assign these costs to the period in which the failures occurs, and not to the period where the repair is made, thus we have:\n$M(i_t) = m(\\mu_cn_{c,t} + \\mu_An_{A,t}).$\nIf the policy \u03c0is optimal, the optimal long-run average service costs g(\u03c0) and the value function v(it) satisfy the Bellman equation:\n$v(i_t) = min_{(x_C,x_A) \\in A} {C(i_t, x_C, x_A) - g(\\pi) + \\sum_{i_{t+1} \\in \\mathcal{Z}_{t+1}} P(i_{t+1}|i_t, x_C, x_A)V(i_{t+1})}, \\forall i_t \\in \\mathcal{I},$"}, {"title": "Solution Approaches", "content": "The size of the state space makes exact analysis impractical for medium to large problem sizes, allowing benchmarking against an exact policy only for small instances. In Appendix B, we outline the exact solution procedure. Section 4.1 explains a heuristic iterative method that allows for extending a standard discrete-time dual sourcing heuristic such that is can deal with endogeneous demand. Section 4.2 outlines the three studied RL algorithms. Finally, Section 4.3 presents a novel approach, denoted by Endogenously parameterised learning (EPL), to enhance RL methods."}, {"title": "Iterative weight adjustment (IWA)", "content": "We propose an algorithm to obtain a policy that balances CM and AM sourcing. The key idea is as follows. We use a standard dual sourcing policy $w_s$ with a single demand rate, based on a fixed fraction of AM and CM parts in the installed base. This demand rate is computed as a weighted average of the CM and AM failure rates, with weights iteratively adjusted.\nIn each iteration, the algorithm outputs the fraction of AM parts from the total parts sourced using AM and CM, (AM/(AM+CM)). This output gives us a new single weighted average failure rate, which is then fed back into the model to estimate the fraction of AM and CM parts in the installed base. This fraction, denoted by $\\gamma_j$ (where j is the iteration index of the IWA process), offers an updated estimate for spare parts demand, differing from our initial hypothesis, denoted by $\\rho_j$."}, {"title": "RL approach", "content": "RL is a framework for modelling sequential decision-making problems, where an agent learns to minimise costs by interacting with an environment. The agent observes the state, makes decisions, and receives feedback in the form of rewards. We implement three RL algorithms from the main RL classes: policy-based (Deep controlled learning (DCL), Temiz\u00f6z et al. (2023)), value-based (Approximate value iteration (AVI), Powell (2022)), and actor-critic (Proximal Policy Optimization (PPO), Schulman et al. (2017)). DCL and PPO use neural networks, while AVI uses linear regression. Implementation details for DCL, AVI, and PPO are given in Appendix F, E, and G, respectively.\nFor sake of conciseness, we provide generic preliminaries for RL. A policy in RL determines decisions based on the current state it. Policies can be deterministic (DCL and AVI) or stochastic (PPO). The agent's objective is to learn an optimal policy \u03c0* that maximises expected cumulative rewards. The RL training process involves:"}, {"title": "EPL", "content": "We present an approach called EPL, which significantly reduces the overall training burden by training a single policy applicable to multiple SKUs. The basic idea is to train an RL policy using a fine grid of SKU parameter values, and sampling from this grid during training. We assume that similar parameter settings yield comparable optimal decisions, enabling more efficient joint training. As endogenous problem parameters change during training, they become part of the state observation.\nWe consider two primary strategies for training the RL policy embedded in EPL. First, we can train a single policy on a given set of SKUs and then use this global learning model specifically for those SKUs. Second, we can train (cross-learn) a policy on a grid of parameter settings, allowing it to be applied to any settings within this grid, even those not explicitly trained on. This strategy aims to create a more generalised policy capable of handling variations within the parameter space, e.g., the application to new products with similar characteristics.\nChoosing the second strategy requires careful consideration of grid design and parameter settings selection. The grid must be detailed enough to capture variability without becoming computationally infeasible. While this initial grid design and training method aim to demonstrate the potential of our EPL approach, optimizing the selection of training instances and including strategies for refining the grid, could be explored further in subsequent studies (as discussed in Section 6). Below, we provide more details of our EPL approach.\nWe denote the input parameters by $\\Theta \\in \\Theta$, where $\\Theta$ represents the set of all parameters, e.g., installed base size, backorder costs, etc. Each parameter $\\theta_j$ (j = 1, 2, ..., n) has a set of possible values $V_j = \\{\\theta_{j1}, \\theta_{j2}, ..., \\theta_{jw}\\}$, derived from the known information about all SKUs. In each iteration i, a value is sampled for each parameter, denoted as $\\theta_{ji}$. Thus, the set of sampled values in iteration i is:\n$\\Theta_i = (\\theta_{1i}, \\theta_{2i}, ..., \\theta_{ni}),$\nwhere $\\theta_{ji} \\in V_j$. By treating problem parameters as part of the state space, we allow the learning policy to account for variations in problem settings, improving generalisation and robustness. The methodology can be summarised as:\n1.  Problem parameter sampling: Define a fine grid over the dual sourcing problem parameters and sample parameter values $\\theta_{ji}$ from the set $V_j$ during training."}, {"title": "Adaptations for EPL", "content": "Two main adaptations are needed to support embedding in EPL compared to standard RL approaches:\n1.  Complexity of Q-value estimation: Adding more state variables makes the Q-value distribution more complex, requiring a more powerful estimator. This is achieved by increasing the neural network size (if applicable) by adding more hidden layers.\n2.  Increased training requirements: A larger state space requires more samples and longer training runs, for details, see Appendix H."}, {"title": "Numerical Experiments", "content": "In this section, we study the performance of IWA and the RL approaches. To summarise, we compare the following policies:\n*   Base stock policy (BSP): a single source base stock baseline that orders AM or CM, whichever is cheaper.\n*   IWA: our proposed heuristic.\n*   AVI: using linear regression as value function, as proposed in, e.g., Powell (2022).\n*   DCL: using fully connected neural networks as policy, see Temiz\u00f6z et al. (2023).\n*   PPO: with fully connected neural networks as actor and critic, see Schulman et al. (2017)\nFor IWA, we need to define a standard dual sourcing method to be used as supporting policy $\\pi^s$. For the smaller tractable instances (Section 5.1), we employ an exact policy $\\pi^s$, see Appendix B for more details. For the large instance (Section 5.2), we use an approximate dual index policy $\\pi^s$, as proposed by Veeraraghavan and Scheller-Wolf (2008). For more details, we refer to Appendix C. The complete explanation of AVI, DCL, and PPO can be found in Appendix E, F, and G, respectively.\nAdditionally, we test all learning frameworks embedded in our proposed EPL approach, we denote these policies as AVIEPL, DCLEPL, and PPOEPL. We employ two primary training strategies: training on a specific set of SKUs (Section 5.1) and training on a grid of parameter settings (Section 5.2). All problems and algorithms are implemented in C++, the neural network models are implemented in LibTorch, a C++ library version of PyTorch (Paszke et al. 2019). The PPO algorithm is implemented using PyBindings with the Tianshou RL library (Weng et al. 2022). Computations are conducted on a single thin CPU node. The node is equipped with a 2.6 GHz AMD Genoa 7H12 processor, has 192 CPU cores, and 384 GB of memory. All hyperparameter settings are reported in Appendix H. We only tune hyperparameters once on a single representative instance and do not tune afterwards.\nIn Section 5.1, we provide the results for a case with synthetic data, and in Section 5.2, we provide the results for the real-world case in the energy sector. The synthetic case is intended to study more fundamental problem characteristics and allows us to benchmark against an exact policy. The energy case shows the performance of our policies in a real-world setting, which allows us to distill managerial insights."}, {"title": "Synthetic Case", "content": "In this section, we discuss the experimental design of our case study based on synthetic data in Section 5.1.1 and provide results in Section 5.1.2. Our experiments aim to determine which approach works best and under what conditions."}, {"title": "Synthetic Case Experimental Design", "content": "In our experiments, we first study small synthetic instances with an installed base size of N = 7 slow moving items. For these small instances, computing the optimal policy is feasible using a standard policy iteration algorithm, see Appendix B. The instance parameters are summarised in Table 2. We consider two primary scenarios for the synthetic instances:"}, {"title": "Results for the Synthetic Case", "content": "As we stressed in Section 4.1, IWA may be applied in combination with most dual sourcing solution procedures since it only relies on an estimate of a weight of items ordered from either supply mode. In this section we apply IWA in combination with an exact policy, see Appendix B.\nTable 4 shows the results for each problem instance. We observe that DCL and DCLEPL are the best performing policies, with an average optimality gap of 0.4%. In two instances (Instance 6 and 7), our proposed IWA approach is the single best performing policy. These instances have the smallest gap between the single sourcing BSP policy and the optimal dual sourcing method. This suggests that IWA outperforms other policies when the advantage of dual sourcing over single sourcing is relatively small. However, in Instance 8, where the BSP gap is also relatively small, DCL finds a policy that matches IWA. We conjecture this is due to the lower AM purchase, maintenance, and backorder costs in Instance 8 compared to Instances 6 and 7.\nObservation 1. Generally DCL performs best, and in instances where other algorithms do better, the gains from dual sourcing are minimal.\nFor the remaining 7 instances, either DCL, DCLEPL, or both policies achieve the best performance. AVI, using a linear regression value function, and PPO, using neural networks, are unable to find a performant policy. We find that both policies hardly order AM parts. Due to the low demand rates, the optimal decision for most states is to order nothing. Therefore, the deviating reorder decision of only a few states determines the solution quality. For example, for Instance 4, we find that the optimal decision is to order nothing in more than 93% of all states. Both AVI and PPO struggle to learn a policy for such sparse reward states, which explains the large gaps of AVI and PPO. Linear regression (used for AVI) seems not powerful enough to approximate the complex state-decision function and PPO is unable to find a competitive policy due to its sampling and updating structure which does not evaluate enough exogenous scenarios, i.e., it is unable to deal with the sparse reward structure.\nInterestingly, for three instances (Instance 3, 4, and 10), DCLEPL finds the best policy and outperforms standard DCL. Remember that DCLEPL is a single policy, globally trained on all 10 problem instances. We conclude that for these instances, the EPL embedding facilitated generalisation across different instances. Specifically, while the algorithm is trained on one set of instance parameters, it"}, {"title": "Energy Case", "content": "In this section, we explain the real-world energy sector case in Section 5.2.1 and show the results for this case in Section 5.2.2. Our experiments are aimed at further evaluating the EPL approach and providing managerial insights."}, {"title": "Energy Case Description", "content": "We conducted our case study using data from TotalEnergies, focusing on parts in valves used on offshore platforms in remote locations. These platforms utilise various valves, and when a valve component fails, the entire valve is replaced with a new valve and the old valve is send to a repair shop where the failed component is replaced. Then the repaired valve is send back to stock. If no replacement is available, temporary fixes can minimise production loss but still cause inconvenience and reduce efficiency, resulting in backorder costs. The components used inside these valves are available in both CM and AM versions.\nOur dataset, summarised in Table 5, includes five different valve types, each having several components, operating in different assets on the offshore platform. Note that because of confidentiality we do not report the absolute values but only the relative values compared to item 1. Only the values for CA, LA, and m are ratios compared to the corresponding CM value of the same item. We performed a sensitivity analysis with various parameter settings, and added some additional instances. For instance, we also considered a larger installed base than the original data, which covers only a single platform. Hence, some parameter settings with larger installed bases have higher demand and thus can be considered fast moving. Managing spare parts for multiple platforms within a region is more efficient as we profit from the risk pooling effect, so we studied installed bases ranging from 5 to 150 valves. The single part demand is considerably lower than in the synthetic case, with mean time between failures between 3 and 20 years. Although for this case AM parts have higher production costs than CM parts, they"}, {"title": "Results for the Energy Case", "content": "Note that the IWA policy is now internally using the dual index policy (cf. Veeraraghavan and Scheller-Wolf 2008), as an exact approach (used in the synthetic case) is intractable for most energy case instances. For the EPL approach, we define a grid $|\\Theta| = 10^{12}$ of all problem parameters and sample from it during training, see Appendix H for details. Due to the significantly larger grid size compared to the synthetic case, EPL cannot observe all possible combinations of problem parameters during training. Note that EPL is trained once on all different items and different parameter settings to obtain a single policy.\nFirst, we analyse the results across all 1215 experiments, see Figure 5. In 8.9% of the settings, no method is able to outperform BSP, suggesting that one of the supply modes is dominant and dual sourcing is not an attractive option. In 26.6% of the settings, all our proposed methods (IWA, DCL, and DCLEPL) significantly outperform the BSP baseline. In 0.7% of the instances, only IWA outperforms BSP, while in 44.7% of the instances, only DCL and DCLEPL outperform BSP. For the remaining settings, no significant difference is observed between the dual sourcing policies. Figure 5 shows the savings made for all non-dominant settings, i.e., excluding the 8.9% of settings where BSP is the best policy. The boxplot confirms that IWA and DCL are able to significantly improve upon the single sourcing benchmark, on average they save 16.9% and 22.6% in total costs compared to BSP, respectively. Furthermore, we observe that DCL outperforms IWA in many settings, with an average saving in total costs of 6.1% compared to IWA.\nObservation 3. DCL finds the overall best policy on real-world instances, saving 6.1% in total costs compared to the proposed IWA heuristic and 22.6% compared to the single sourcing BSP benchmark.\nThe EPL approach (used with DCL) is also able to outperform IWA, although less convincingly as DCL. DCLEPL saves on average 3.1% in total costs compared to IWA, which is 3%pt worse compared to the standard DCL algorithm. However, the DCLEPL is trained once on all items (35 hours training time), whereas the standard DCL policy is trained separately on all 1215 instances, amounting to a total training time of almost 76 days, which is a computational time saving of a factor 52. Thus, when computational time is limited or there are thousands of different spare parts for which no separate training runs can be conducted, IWA or DCLEPL are considered preffered over DCL.\nObservation 4. When employing EPL to learn a single policy for multiple SKUs we achieve competitive performance while significantly reducing the computational time required for training.\nNext, we zoom in on the cost components and the ordering behaviour of the policies, see the barchart in Figure 6 showing costs over all non-dominated instances (10,000 replications). Here, it becomes visible"}, {"title": "Transition Function", "content": "We detail the calculation of the values for $y_{C,t}, y_{A,t}, z_{C,t}$, and $z_{A,t}$, which are used as helper variables to support the transition from a state $i_t$ to $i_{t+1}$.\n*   $y_{c,t} = min\\{B_t + k_{c,t} + k_{a,t}, s_{C,t}\\}$ where the first element describes the total demand (backorders + new demand arrivals in period t), and the second element the CM on-hand stock.\n*   $y_{a,t} = min\\{B_t + k_{c,t} + k_{a,t} - y_{C,t}, s_{A,t}\\}$ where the first element describes the total demand not satisfied by CM before a possible order arrival, and the second element the AM on-hand stock.\n*   $z_{c,t} = min\\{B_t + k_{c,t} + k_{a,t} - y_{C,t"}]}