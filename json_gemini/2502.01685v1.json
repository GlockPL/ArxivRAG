{"title": "Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment", "authors": ["Si-Ioi Ng", "Pranav S. Ambadi", "Kimberly D. Mueller", "Julie Liss", "Visar Berisha"], "abstract": "Existing methods for analyzing linguistic content from picture descriptions for assessment of cognitive-linguistic impairment often overlook the participant's visual narrative path, which typically requires eye tracking to assess. Spatio-semantic graphs are a useful tool for analyzing this narrative path from transcripts alone, however they are limited by the need for manual tagging of content information units (CIUs). In this paper, we propose an automated approach for estimation of spatio-semantic graphs (via automated extraction of CIUs) from the Cookie Theft picture commonly used in cognitive-linguistic analyses. The method enables the automatic characterization of the visual semantic path during picture description. Experiments demonstrate that the automatic spatio-semantic graphs effectively differentiate between cognitively impaired and unimpaired speakers. Statistical analyses reveal that the features derived by the automated method produce comparable results to the manual method, with even greater group differences between clinical groups of interest. These results highlight the potential of the automated approach for extracting spatio-semantic features in developing clinical speech models for cognitive impairment assessment.", "sections": [{"title": "I. INTRODUCTION", "content": "Dementia is a neurodegenerative disease that leads to decline in multiple cognitive domains, affecting an individual's social or occupational function [1]. Traditional methods for characterising cognitive impairment involve reviewing an individual's history, collecting data from patient and caregiver questionnaires, conducting neuropathological and neuropsychological tests, etc. The growing prevalence of dementia requires automated assessment tools that enable early diagnosis and longitudinal monitoring of cognitive impairment. A patient's speech is a prominent biomarker since the speech production process can reflect problems in cognition and perception [2]. Speech analytic systems designed for cognitive impairment are typically based on neuropsychological tests, which involve recalling the keywords in verbal memory tests, or describing the objects and actions in picture description tasks [3], [4]. When the elicited speech is recorded and transcribed, automated speech and language analytics can be used for early detection of impairment.\nAmong the most common ways to elicit speech from patients is the Cookie Theft picture description task from the Boston Diagnostic Aphasia Examination [5]. The task is straight-forward to administer and can magnify changes occurring in brain regions implicated by cognitive impairment. Explained in [6], the diverse features derived from the task, such as semantic categories, referential cohesion, and mental state language, etc., are particularly suited to detecting cognitive impairments. Previous studies have developed approaches to detect cognitive impairment using speech processing, natural language processing [7], [8]. Acoustic features such as paralinguistic feature sets, MFCCs, neural network embeddings of speech; and language features such as TF-IDF, text embeddings extracted from large language model, are applied to model training and clinical label prediction [9]-[12].\nThese existing features are often highly abstract and do not link to clinical constructs of cognitive impairment. As a result, speech analytic systems developed on these features cannot easily be adopted in real-world clinical settings or provide useful feedback to clinicians. An alternative approach could be utilizing measures used by clinicians in clinical assessments. Specific to the Cookie Theft task, clinicians utilize transcriptions of participant descriptions to determine features such as content information units (CIUs), pauses, and repetitions as well as acoustic measures derived from the recorded speech, such as speech rate and voice quality [13], [14]. Less accessible to clinicians, however, is the visual-path analysis of a participant's description. Picture description engages not only the cortical pathways responsible for semantic retrieval and production, but also pathways connecting the parietal lobe with visual processing circuits. Growing evidence indicates that the parietal lobe, implicated in visuospatial tasks, is among the earliest regions to exhibit neurodegenerative changes [15], [16]. Such impairments can manifest in a patient's description of a complex visual scene. Tools that capture the visual relationship between objects in the picture can help clinicians better understand the underlying neuropathology behind cognitive deficits.\nOne such tool was recently introduced in the form of spatio-semantic graphs [17]. The authors propose a graph-theoretic representation that aims to encode the sequential listing of CIUs and their relative spatial position in the Cookie Theft picture. Results showed significant differences in features extracted from spatio-semantic graphs between cognitively impaired and cognitively unimpaired speakers, reflecting measurable deficits in visuospatial, attentional, and organizational abilities in cognitively impaired speakers. A limitation of integrating this tool into clinical speech analytics pipeline"}, {"title": "II. SPEECH DATASETS", "content": "This study utilizes speech data from the Wisconsin Registry for Alzheimer's Prevention (WRAP) dataset [19] and the DementiaBank (DB) Pitt Corpus [22]. The two datasets contain 1,058 and 291 speech recordings, respectively. Both speech datasets utilize the Cookie Theft picture description as the speech elicitation task. WRAP is a longitudinal, observational cohort of individuals in midlife, with an emphasis on those with a parental history of Alzheimer's disease. Participants attend study visits every two years to provide detailed health and lifestyle data, and undergo comprehensive neuropsychological testing. During each visit, participants are diagnosed into one of the following categories: cognitively unimpaired-stable, cognitively unimpaired-declining, mild cognitive impairment (MCI), or dementia. The Pitt Corpus from DB consists of speech recordings collected as part of a large-scale study conducted by the Alzheimer and Related Dementia Study at the University of Pittsburgh School of Medicine. At the time of the speech recording, each participant was assigned a clinical label of cognitively unimpaired, MCI, or dementia.\nAll speech data were transcribed by trained listeners using the Codes for the Human Analysis of Transcripts (CHAT) format [23]. During data pre-processing, to maintain a one-to-one correspondence between speakers and data, only speech data from a patient's first visit was used. The cognitively unimpaired data from both DB and WRAP were combined to form the Cognitively Unimpaired group, while the MCI and dementia data were merged into the Cognitively Impaired group. Ultimately, the analysis included 1,089 recordings in the Cognitively Unimpaired group and 219 recordings in the Cognitively Impaired group."}, {"title": "III. THE COOKIE THEFT PICTURE AND CONTENT INFORMATION UNITS", "content": "Figure 1 illustrates the Cookie Theft picture and its 23 CIUs. The picture depicts a mother drying dishes, unaware of the overflowing sink. Meanwhile, her children try to take cookies: the boy climbs a wobbly stool to reach the jar, while the girl waits with an outstretched hand. Typically, the CIUs are manually tagged from the transcribed speech by trained listeners. The list of CIUs and their corresponding words are presented in Table I. These words were selected by examining the word frequency histogram across the datasets. The word selection rules differ from [24], as we include more relevant words to capture the visual path during the picture description task, but the dictionary construction remains flexible and can be tailored to the study's objectives.\nTable II compares the CIUs sequences extracted manually and automatically (using Table I) from the same speech example. Although the two sequences are slightly misaligned with each other (as seen in the CIUs highlighted in blue and red), the automated approach encodes CIUs that were skipped by human annotators (as highlighted in green), which provides a more fine-grained description regarding the visuospatial path of speakers when performing the picture description task."}, {"title": "IV. SPATIO-SEMANTIC GRAPHS AND FEATURES", "content": "A spatio-semantic graph can be constructed by mapping the CIUs to their respective locations, representing the visual path the speaker took when describing the picture. Each CIU is assigned a 2-dimensional coordinate on a pixel scale, with the Cookie Theft image sized at 546 \u00d7 290 pixels. The procedure for creating the spatio-semantic graph follows the implementation outlined in [17]. The sequence of extracted CIUs is automatically encoded with their coordinate pairs. Using the NetworkX toolkit, a set of graph nodes and edges is constructed from these coordinates and their orderings. The resulting graph visualizes the nodes as the 23 CIUs in the picture, with the nodes representing the 23 CIUs in the picture and the edges representing the order of CIUs mentioned by the speaker. The distance between two connected CIUs is measured by the Euclidean distance. Additionally, each CIU can be assigned to one of the four quadrants of the picture. A graph can be constructed from the sequences of quadrant labels, where the nodes represent the quadrants and the edges illustrate how the speaker's attention transitions between different quadrants during the description of the picture.\nOnce the graph is constructed based on the CIUs, a set of spatio-semantic features can be derived from the graph representation and the spatial position of the CIUs in the Cookie Theft picture. Table III defines the 12 spatio-semantic features computed in this study. These features are designed to capture the semantic order and summarize visuospatial relationships among the mentioned CIUs. They are able to describe aspects such as dispersal, efficiency, fixation, memory lapses and sporadicity in speech [17]."}, {"title": "V. EXPERIMENTAL SETUP", "content": "The spatio-semantic features derived from automatically extracted CIUs should produce similar results and conclusions as those obtained from manually extracted CIUs. In [17], statistical analyses were conducted to confirm group-level differences in spatio-semantic features between different clinical groups. We repeat the same analyses here for the automatic spatio-semantic graph. To automatically encode CIUs from a given Cookie Theft description, all punctuation in the original CHAT transcriptions is first removed. The text is then lemmatized using the SpaCy toolkit [25]. The lemmatized text is then mapped to a sequence of CIUs using the dictionary in Table I. The spatio-semantic graph and its derived features are computed using the methods described in Section IV.\nTo ensure a fair comparison between the manual and automatic approaches for deriving spatio-semantic features, we followed the statistical analyses outlined in [17], which utilize analysis of covariance (ANCOVA). In this approach, each spatio-semantic feature is treated as the dependent variable in its own ANCOVA model. Demographic factors such as age, education, gender, and the count of unique nodes are included as covariates. The rationale for adjusting for unique nodes is based on the observation that the number of unique CIUs in the transcribed speech may differ between cognitively unimpaired and cognitively impaired groups; furthermore, this feature may correlate with all other features derived from the graph [17]. In the ANCOVA test, a significance level of p = 0.05 is used."}, {"title": "VI. EXPERIMENTAL RESULTS AND DISCUSSION", "content": "Figure 2 illustrates examples of spatio-semantic graphs generated from automatically extracted CIUs for both cognitively unimpaired and cognitively impaired speakers. The graph for the cognitively impaired speaker diagnosed with dementia reveals an inefficient visual path characterized by frequent cross-quadrant transitions and a longer total path. In contrast, the unimpaired speaker's path is more organized, with fewer repetitions and shorter total distances. These spatio-semantic features derived from the graphs are expected to reflect the differences in cognitive function between the two groups.\nTable IV presents the ANCOVA analysis results of spatio-semantic features derived from both manually and automatically extracted CIUs, along with the 95% confidence intervals for each feature. The total path distance computed from automatically extracted CIUs is generally longer than that from manually extraction. This difference is consistent with the earlier illustration in Table II, where the automated method captured more CIUs. Most features show statistical significance, regardless of the CIU extraction method used. When comparing manual and automatic spatio-semantic graphs, differences were observed only in the self cycles (according to both CIUs and quadrants) derived from automatically extracted CIUs. Since the automated approach detects more CIUs, there is a higher likelihood of consecutive CIUs occurring within the same quadrant, as indicated by the confidence interval. This altered distribution of CIUs across quadrants could lead to slightly different conclusions in the ANCOVA test.\nFor all spatio-semantic features with significant group differences, those derived from automatically extracted CIUS yield higher F-values than those from manual extraction, indicating greater distinction between groups. Overall, the ANCOVA results suggest that the proposed dictionary in Table I effectively supports the automatic extraction of CIUs and spatio-semantic features, achieving performance comparable to or better than the manual method. Considering the importance of automatic dementia detection in clinical speech analytics, these findings imply that researchers can extract spatio-semantic features without human annotation of CIUs and use them as inputs for clinical speech models. Additionally, these features are linked to clinically relevant constructs, offering clinical interpretability."}, {"title": "VII. CONCLUSION", "content": "This study proposes an approach for automatically extracting content information units (CIUs) from the Cookie Theft picture description task. A dictionary containing words relevant to the CIUs was constructed, enabling the creation of spatio-semantic graphs. These graphs allow the derivation of spatio-semantic features that can distinguish cognitively impaired speakers from cognitively unimpaired ones. Experimental results demonstrate that the automated extraction method accurately identifies more CIUs than the manual approach, offering a more detailed description of the speakers' visual path during the task. ANCOVA analyses of the spatio-semantic features indicate that the automated method produces conclusions similar to the manual approach while yielding greater group differences across each feature. Future work will explore using large language models for CIU extraction, without the need for manual dictionary design."}]}