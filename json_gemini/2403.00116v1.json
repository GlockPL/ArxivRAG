{"title": "Federated Linear Contextual Bandits with Heterogeneous Clients", "authors": ["Ethan Blaser", "Chuanhao Li", "Hongning Wang"], "abstract": "The demand for collaborative and private bandit learning across multiple agents is surging\ndue to the growing quantity of data generated from distributed systems. Federated bandit\nlearning has emerged as a promising framework for private, efficient, and decentralized\nonline learning. However, almost all previous works rely on strong assumptions of client\nhomogeneity, i.e., all participating clients shall share the same bandit model; otherwise,\nthey all would suffer linear regret. This greatly restricts the application of federated bandit\nlearning in practice. In this work, we introduce a new approach for federated bandits for\nheterogeneous clients, which clusters clients for collaborative bandit learning under the\nfederated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and\ncommunication cost for all clients, subject to the communication protocol under federated\nlearning that at anytime only one model can be shared by the server.", "sections": [{"title": "1 Introduction", "content": "Bandit learning algorithms (Auer et al., 2002; Chapelle and Li, 2011; Li et al., 2010a;\nAbbasi-Yadkori et al., 2011) have become a reference solution to the problems of online\ndecision optimization in a wide variety of applications, including recommender systems\n(Li et al., 2010a), clinical trials (Durand et al., 2018), and display advertising (Li et al.,\n2010b). Typically, these algorithms are operated by a centralized server; but due to the\ngrowing quantity of data generated from distributed systems, there is a surge in demand\nfor private, efficient, and decentralized bandit learning across multiple clients. Federated\nbandit learning has emerged as a promising solution framework, where multiple clients\ncollaborate to minimize their cumulative regret under the coordination of a single central\nserver (Wang et al., 2020; Dubey and Pentland, 2020a; Shi and Shen, 2021; Li and Wang,\n2022; He et al., 2022). The server's role is limited to facilitating joint model estimation\nacross clients, without having access to any clients' arm pulling or reward history."}, {"title": "2 Related Work", "content": "Our work is closely related to studies in federated bandit learning and collaborative bandits.\nIn this section, we discuss the most representative solutions in each area and highlight the\nrelationships between them and our work."}, {"title": "Federated Linear Contextual Bandits:", "content": "There have been several works that study the\nfederated linear contextual bandit setting, where multiple clients work collaboratively to\nminimize their cumulative regret with the coordination of a single central server (Wang et al.,\n2020; Li and Wang, 2022; Huang et al., 2021). Wang et al. (2020) introduced DisLinUCB,\nwhere a set of homogeneous clients, each with the same linear bandit parameter, conduct\njoint model estimation through sharing sufficient statistics with a central server. Li and\nWang (2022) and He et al. (2022) extended this setting by introducing an event-triggered\nasynchronous communication framework to achieve sub-linear communication cost as well as\nsub-linear regret in a homogeneous environment. Additionally, Dubey and Pentland (2020b)\nconsiders deferentially private federated contextual bandits in peer-to-peer communication\nnetworks. Fed-PE, proposed in (Huang et al., 2021), is a federated phase-based elimination\nalgorithm for linear contextual bandits that handles both homogeneous and heterogeneous\nsettings. However, in their setting, the client is trying to learn the fixed context vectors\nassociated with each arm as opposed to the linear reward parameter (which is known in\ntheir setting). With the exception of Fed-PE, which utilizes a different bandit formulation\naltogether, all of these prior works rely on strong assumptions of client homogeneity, while\nour work seeks to extend federated linear contextual bandit learning to a heterogeneous\nenvironment."}, {"title": "Collaborative Bandits:", "content": "Collaborative bandits seek to leverage similarities between het-\nerogeneous clients to improve bandit learning. Clustered bandit algorithms are one example,\nwhere similar clients are grouped together, and a shared bandit model is used for all clients\nin the same group(Gentile et al., 2014; Li et al., 2016; Gentile et al., 2017; Cesa-Bianchi et al.,\n2013; Wu et al., 2016). Gentile et al. (2014) assumed that observations from different clients\nin the same cluster are associated with the same underlying bandit parameter. Gentile\net al. (2017) further studied context-dependent clustering of clients, grouping clients based\non their similarity along their bandit parameter's projection onto each context vector. Li\net al. (2021) unified non-stationary and clustered bandit by allowing for a time varying\nbandit parameter for each client, which requires online estimation of the dynamic cluster\nstructure at each time. Other works leverage explicit inter-client and inter-arm relational\nstructures, such as social networks (Buccapatnam et al., 2013; Cesa-Bianchi et al., 2013; Wu\net al., 2016; Hong et al., 2021; Caron et al., 2012; Mannor and Shamir, 2011) to facilitate\ncollaboration. However, most existing collaborative bandit solutions are designed under a\ncentralized setting, where all clients' observation data is readily available at a central server.\nLiu et al. (2022) and Korda et al. (2016) consider online cluster estimation in a distributed\nsetting. However, their federated learning architectures do not align with the standard\nfederated learning architecture and real world implementations where a single central server"}, {"title": "3 Methodology", "content": "In this section, we begin by outlining the problem setting investigated in this work. Then we\npresent our two-stage federated clustered bandit algorithm designed to serve a population of\nheterogeneous clients under the standard communication setup in federated learning. We\nprovide theoretical analysis of the upper regret bound for our developed solution. Lastly, we\nintroduce a set of improvements to our proposed algorithm, including dynamic re-clustering\nof clients using an adaptive clustering criterion, and the implementation of a priority queue\nto enhance online performance, both of which were found empirically effective."}, {"title": "3.1 Problem Setting", "content": "A federated bandit learning system consists of two components: 1) N clients, which take\nactions and get reward feedback from their environment (e.g., edge devices in a recom-\nmendation system interacting with end users) and 2) a central server coordinating client\ncommunication for collaborative model estimation. In each time step $t = 1, 2, ...T$, each\nclient $i \\in N$ chooses an action $x_{t,i}$ from its action set $A_{t,i} = \\{x_{t,1}, x_{t,2}..., x_{t,K}\\}$, where\n$x \\in \\mathbb{R}^d$. Adhering to the standard linear reward assumption from (Li et al., 2010b), the\ncorresponding reward received by client $i$ is $Y_{t,i} = \\langle \\theta^{*}_i, x_{t,i}\\rangle + n_t$, where noise $n_t$ comes from\na $\\sigma^2$ sub-Gaussian distribution, and $\\theta^{*}_i$ is the true linear reward parameter for client $i$.\nWithout loss of generality, we assume $||x||_2 \\leq 1$ and $||\theta|| \\leq 1$.\nThe learning system interacts with the environment for $T$ rounds, aiming to minimize\nthe cumulative pseudo-regret $R_T = \\sum_{t=1}^{T}\\sum_{i=1}^{N} \\max_{x \\in A_t} \\langle \\theta^{*}_i, x\\rangle - \\langle \\theta^{*}_i, x_{t,i}\\rangle$.\nFollowing the federated learning setting, we assume a star-shaped communication network,\nwhere the clients cannot directly communicate among themselves. Instead, they must share\nthe learning algorithm's parameters (e.g., gradients, model weights, or sufficient statistics)\nthrough the central server. To preserve data-privacy, raw observations collected by each\nclient $(x_{t,i}, Y_{t,i})$ are stored locally and will not be shared with the server. At every timestep\n$t = 1, ...T$, the central server is capable of using the shared learning algorithm to update\nand broadcast one model to the selected clients. The communication cost is defined as\nthe amount of sufficient statistics communicated across the learning system over the entire\ntime-horizon.\nUnlike existing federated bandit works (Wang et al., 2020; Li and Wang, 2022; He\net al., 2022) which assume homogeneous clients, we adopt the standard clustered bandit\nsetting to model a heterogeneous learning environment. Without an underlying cluster\nstructure in the environment, collaboration between clients would be infeasible. Therefore,\nwe assume that clients sharing similar reward models form clusters, collectively represented\nas $C = \\{C_1, C_2, ..., C_M\\}$. The composition and quantity of these clusters, are unknown to\nthe system, necessitating on-the-fly inference. Consistent with prevalent clustered bandit"}, {"title": "3.2 Algorithm: HetoFedBandit", "content": "In this section, we present our two-stage federated clustered bandit algorithm. As discussed\nin Section 1, there are two primary challenges associated with extending clustered bandit\nlearning to the federated learning setting. The first challenge is to identify the subsets of\nheterogeneous clients that can benefit from collaboration among themselves. To achieve\nthis, in the first stage of our algorithm, all clients conduct random exploration ahead of\na non-parametric clustering of clients based on the statistical homogeneity test (Li et al.,\n2021). The second challenge arises from the communication network setting in federated\nlearning framework, which allows only one model to be broadcast at each time step (He\net al., 2020; Foley et al., 2022). To accommodate this constraint, a first-in-first-out queue\nis utilized on the server side, enabling event-triggered collaboration (Wang et al., 2020) at\nthe cluster level during our algorithm's second phase. We provide an overview of the key\ncomponents of our algorithm, with the full details available in Algorithm 3."}, {"title": "Pure Exploration Phase", "content": "Under our relaxed context regularity assumption, we execute a\nshort exploration phase of length $T_0$ to guarantee the accuracy of our homogeneity test. Our\ndiscussion on the choice of $T_0$ is deferred to Section 3.3. Although our derived theoretical\nvalue for $T_0$ depends on an unknown environmental parameter $\\gamma$, in practice, $T_0$ can be\ntuned as a hyperparameter."}, {"title": "Cluster Estimation", "content": "The key challenge in online clustering of bandits is to measure the\nsimilarity between different bandit models. Previous works identify whether a set of clients\nshare exactly the same underlying reward model; while we cluster similar clients (as defined\nby $\\epsilon$) to widen the radius of beneficial collaboration. We realize this by testing whether\n$||\\theta_i^* - \\theta_j^*|| \\leq \\epsilon$ via the homogeneity test introduced in (Li et al., 2021)."}, {"title": "Optimistic Learning Phase", "content": "Upon identifying client clusters suitable for collaboration,\nwe proceed to the optimistic learning phase of our algorithm. Here, clients optimistically\nchoose arms, utilizing the collaboration with other similar clients to enhance their local"}, {"title": "3.3 Theoretical Results", "content": "As presented in Section 3.2, our algorithm first utilizes a homogeneity test to cluster similar\nclients in a heterogeneous environment. We prove that with our homogeneity test, Algorithm\n2 correctly identifies the underlying clusters."}, {"title": "Theorem 1 (Clustering Correctness)", "content": "Under the condition that we set the homogeneity\ntest threshold $v^\\epsilon > F^{-1}(1 - \\frac{\\delta}{N^2}, df, \\psi^c)$, with probability at least $1 - \\delta$, we have $\\hat{C} = C$.\n$F^{-1}(\\cdot)$ is the inverse of the CDF of the non-central $\\chi^2$ distribution, and $\\psi^c = \\frac{\\psi}{4}$. We\nprovide the complete proof of Theorem 1 in Appendix B. Moreover, Algorithm 3 adopts a\nUCB-based arm selection, which requires the construction of a confidence ellipsoid."}, {"title": "Lemma 2 (Confidence Ellipsoids)", "content": "Suppose client $i$ is a member of cluster $\\hat{C}_k \\in \\hat{C}$, and\nis therefore collaborating with clients $j \\in \\hat{C}_k$. For any $\\delta > 0$, with probability at least $1 - \\delta$,\nfor all $t > 0$ and all clients $i \\in N$, $\\theta^*_i$ lies in the set:\n$\\beta_{t,i} =\\{\\theta \\in \\mathbb{R}^d : ||\\theta - \\hat{\\theta}_{t,i}||^2_{V_{t,i}} \\leq \\sigma \\sqrt{2 log(\\frac{det(V_{t,i})^{1/2}}{det(\\lambda I)^{1/2} \\delta})} + \\sqrt{\\lambda} + || \\sum_{j\\in\\hat{C}_k \\{i\\}} X_j( \\theta_j^* - \\theta^*_i)||_{V^{-1}_{t,i}}  \\}$"}, {"title": "Theorem 3 (Regret and Communication Cost)", "content": "With an exploration phase length of\n$T_0 = \\frac{16\\gamma^2 d \\sigma^4}{\\lambda^2 \\epsilon^4}$, with probability $1 - \\delta$ our protocol achieves a cumulative regret of\n$R_T = O(\\frac{N \\gamma d \\sigma^2}{\\lambda \\epsilon} + \\sum_{k=1}^{M} d\\sqrt{|C_k| T \\log^2(|C_k| T)} + d |C_k|^2 M \\log(|C_k| T))$\nwhere $\\psi^d = F^{-1}(\\frac{N \\delta}{2(M-1)}; d, v^\\epsilon)$, with communication cost\n$C_T = O(N d^2) + \\sum_{k=1}^{M} O(|C_k|^{1.5} d^3)."}, {"title": "3.4 Empirical Enhancements: HetoFedBandit-E", "content": "In this section, we describe the details of our proposed empirical enhancements to our\nHETOFEDBANDIT algorithm, where we perform re-clustering to improve the quality of\nestimated clusters of clients and replace the first-in-first-out queue with a priority queue\nto help clusters where a shared model update can most rapidly reduce regret for clients\nin that cluster. We present the details of our enhanced algorithm HETOFEDBANDIT-E in\nAlgorithm 5."}, {"title": "3.4.1 DATA-DEPENDENT CLUSTERING", "content": "We propose a data-dependent clustering procedure to enhance collaboration among clients\nwith similar observational histories. Our homogeneity test for cluster formation ensures\nan upper bound on the bias term $H$, as outlined in Lemma 2. This term depends on the\ndifferences in underlying parameters $(\\Theta_i \\ vs., \\Theta_j)$ and each client's observation history. For\ninstance, if client j's observations are in the null space of $(\\theta_i - \\theta_j)$, collaborating with client\nj will not introduce excessive bias to client i. But without further assumptions about the\ncontext vector sequence, we must conservatively assume in our original design that every\nclient j's entire observation history aligns with $(\\theta_i - \\theta_j)$.\nPreviously, we used a homogeneity test with threshold $\\epsilon = \\frac{1}{N\\sqrt{T}}$ to verify clients'\ncollaboration across all timesteps. Now, we can relax the homogeneity test threshold to\ncheck if two clients can collaborate at a specific timestep t by examining if $||\\theta_i - \\theta_j|| \\leq \\epsilon = \\frac{1}{\\lambda_{max}(X_{t,i}X^T_{t,i})}$.\nTo achieve this, we modify our algorithm to forgo single round\ncluster estimation. Instead, every time a client requests collaboration, we re-cluster the\nclients using the data-dependent thresholds for our pairwise homogeneity tests. By making\nthese thresholds data-dependent, each client can collaborate with more neighbors earlier,\nboosting overall collaborative benefits in our learning system."}, {"title": "3.4.2 PRIORITY QUEUE", "content": "The second enhancement to HETOFEDBANDIT involves utilizing a priority queue instead of\na FIFO queue to determine the order in which to serve clusters requesting collaboration. As\nis demonstrated in (Wang et al., 2020; Li and Wang, 2022), the cumulative regret incurred\nby a federated bandit algorithm is determined by the determinant ratios of the clients within\nthe system: $\\Delta t_{t,i} \\log \\frac{det(V_{t,i})}{det(\\Delta V_{t,i})}$. Since the central server cannot assist all clusters at\nonce, determinant ratios of awaiting clients can increase as they linger in the queue. In the\noriginal HETOFEDBANDIT, clusters are attended based on their request order. However, an\nearlier-joining cluster might have a slower regret accumulation compared to a later one with\na larger and faster growing determinant ratio. By utilizing a priority queue that serves the\nclusters based on: $\\arg \\max_{\\hat{C}_k \\in \\hat{C}} \\sum_{i \\in \\hat{C}_k} \\Delta t_{t,i} \\log \\frac{det(V_{t,i})}{det(\\Delta V_{t,i})}$, the server ensures clusters are\naddressed in an order that minimizes the system-wide cumulative regret."}, {"title": "4 Experiments", "content": "In this section, we investigate the empirical performance of HETOFEDBANDIT and HETOFEDBANDIT-\nE, by comparing them against several baseline models on both simulated and real-world\ndatasets."}, {"title": "4.1 Baselines", "content": "In our evaluation, we compare our proposed HETOFEDBANDIT algorithm with several\nrepresentative algorithms from both the clustered and federated bandit learning domains.\nWe compare against, LinUCB algorithm from (Abbasi-Yadkori et al., 2011), DisLinUCB\n(Wang et al., 2020), FCLUB_DC (Liu et al., 2022), and DyClu (Li et al., 2021). To ensure\ncompatibility with our setting, we set the number of local servers in FCLUB_DC to be equal\nto the number of clients."}, {"title": "4.2 Synthetic Dataset", "content": "We first present the results of our empirical analysis of HETOFEDBANDIT and HETOFEDBANDIT-\nE on a synthetic dataset."}, {"title": "Synthetic Dataset Generation", "content": "In this section, we describe the pre-processing procedure\nfor the synthetic dataset used in Section 4.2. We first create an action pool $\\{x_k\\}_{k=1}^{K}$ where $x$\nis sampled from $N(0_d, I_d)$. To create a set of $N$ clients in accordance with our environment\nassumptions, we first sample $M$ cluster centers $\\{\\theta_m\\}_{m=1}^{M}$ from $N(0_d, I_d)$ that are $\\gamma + 2\\epsilon$ away\nfrom each other (enforced via rejection sampling). Then, we randomly assign each client\nindex $i \\in N$ to one of the $M$ clusters. To generate each $\\theta_i$, we first sample a vector on the\nunit d-sphere, then we scale it by a value uniformly sampled from $[0, \\epsilon]$ with $\\epsilon = \\frac{1}{N\\sqrt{T}}$ and\nadd it to the cluster center $\\theta_k$ corresponding to the cluster client $i$ was assigned to. At each\ntime step $t = 1, 2, ...T$ for each client in $[N]$ is presented a subset of 25 arms are sampled\nfrom $\\{x_k\\}_{k=1}^{K}$, and shared with the client. The reward of the selected arm is generated by\nthe linear function governed by the corresponding bandit parameter and context. In our\nexperiments, we chose $d = 25, K = 1000, N = 50, M = 5$, and $T = 3000$. Since we conducted\nour experiment in a synthetic environment, we utilized the known values of $\\gamma = 0.85, \\sigma = 0.1,"}, {"title": "4.3 LastFM Dataset", "content": "In this section, we present the results of our empirical analysis of HETOFEDBANDIT and\nHETOFEDBANDIT-E on the LastFM dataset, demonstrating their effectiveness in distributed\nrecommender systems."}, {"title": "LastFM Dataset", "content": "The dataset used in this experiment is extracted from the LastFM-2k\ndataset, which originally contains 1892 clients (users) and 16632 items (artists) (Cantador\net al., 2011). Each \"client\" can be considered as an edge device serving a particular user\nin a distributed recommender system. The \"listened artists\" of each client are treated as\npositive feedback. To adapt this dataset for our experiments, we kept clients with over\n350 observations, resulting in a dataset with $N = 75$ clients and $T = 41284$ interactions.\nThe dataset was pre-processed following the procedure in (Cesa-Bianchi et al., 2013) to\naccommodate the linear bandit setting (with $d = 25$ and the action set $K = 25$). Since the\nenvironmental parameters $\\sigma, \\gamma$ are unknown for this real-world dataset, we directly tuned\nthe values of our test threshold $v^\\epsilon = 0.01, T_0 = 5000$, and $\\alpha_{t,i} = \\alpha = 0.3 \\forall i \\in [N], \\forall t \\in T$\nusing a grid search."}, {"title": "5 Conclusion", "content": "In this work, we address the challenge of heterogeneous clients in federated bandit learning by\nintroducing HETOFEDBANDIT. Our approach combines the strengths of federated learning\nand collaborative bandit learning, enabling efficient communication and learning among\nclients with diverse objectives. We demonstrate through rigorous theoretical analysis that"}, {"title": "Appendix A. Technical Lemmas", "content": "In this section, we introduce the technical lemmas utilized in the subsequent proofs in this\npaper."}, {"title": "Lemma 5 (Lemma 11 in Abbasi-Yadkori et al. (2011))", "content": "Let $\\{X_t\\}_{t=1}^{T}$ be a sequence\nin $\\mathbb{R}^d$, $V$ is a $d \\times d$ positive definite matrix and define $V_t = V + \\sum_{t=1}^{T} X_t X_t^\\intercal$, where $V = \\lambda I$.\nAdditionally we have that $\\lambda_{min}(V) \\geq max(1, L^2)$ and $||X_t||_2 < L$ for all $t$, then\n$\\log(\\frac{det(V_T)}{det(V)}) - \\sum_{t=1}^{T} ||X_t||^2_{V^{-1}_{t-1}} \\leq  \\sum_{t=1}^{T} ||X_t||^4_{V^{-1}_{t-1}} \\log(\\frac{det(V_T)}{det(V)}).$"}, {"title": "Lemma 6 (Theorem 1 of Abbasi-Yadkori et al. (2011))", "content": "Let $\\{F_t\\}_{t=0}$ be a filtration.\nLet $\\{\\eta_t\\}_{t=1}^T$ be a real-valued stochastic process such that $\\eta_t$ is $F_t$-measurable, and $\\eta_t$ follows\nconditionally zero mean $R$-sub-Gaussian for some $R > 0$. Let $\\{X_t\\}_{t=1}^T$ be an $\\mathbb{R}^d$-valued\nstochastic process such that $X_t$ is $F_{t-1}$-measurable. Assume that $V$ is a $d \\times d$ positive definite\nmatrix. For any $t > 0$, define\n$V_t = V + \\sum_{\\tau=1}^{t} X_{\\tau} X_{\\tau}^\\intercal, S_t = \\sum_{\\tau=1}^{t} \\eta_{\\tau} X_{\\tau}.$\nThen for any $\\delta > 0$, with probability at least $1 - \\delta$,\n$||S_t||^2_{V_t^{-1}} \\leq R^2 d/2 \\log \\frac{det(V_t)^{1/2}}{det(V)^{1/2} \\delta}, \\forall t \\geq 0$."}, {"title": "Lemma 7 (Determinant-Trace Inequality)", "content": "Suppose $X_1, X_2, ..., X_t \\in \\mathbb{R}^d$ and for any\n$1 \\leq \\tau \\leq t$, $||X_{\\tau}||_2 < L$, Let $V_t = \\lambda I + \\sum_{\\tau=1}^{t} X_{\\tau} X_{\\tau}^\\intercal$ for some $\\lambda > 0$. Then,\n$det(V_t) \\leq (\\lambda + tL^2/d)^d.$"}, {"title": "Lemma 8 (Lemma 12 from (Li et al., 2021))", "content": "When the underlying bandit parameters\n$\\theta^*_i$ and $\\theta^*_j$ of two observation sequence $H_{t-1,i}$ and $H_{t-1,j}$ from client $i$ and $j$ are not the\nsame, the probability that the cluster identification phase clusters them together corresponds\nto the type-II error probability given in Lemma 10, which can be upper bounded by:\n$P (S(H_{t-1,i}, H_{t-1,j}) \\leq v^\\epsilon || |\\theta_i - \\theta_j|| > \\epsilon) < F(v^\\epsilon; d, \\psi^d)$,\nunder the condition that both $\\lambda_{min} (\\sum_{(x_k,y_k)\\in H_{t-1, i}} x_k x_k^\\intercal)$ and $\\lambda_{min} (\\sum_{(x_k,y_k)\\in H_{t-1, j}} x_k x_k^\\intercal)$ are\nat least $\\frac{24 d \\sigma^2}{\\lambda^2}$."}, {"title": "Lemma 9 (Lemma B1 from Li and Wang (2022))", "content": "Denote the number of observations\nthat have been used to update $\\{V_{i,t}, b_{i,t}\\}$ as $T_i$, i.e., $V_{i,t} = \\lambda I + \\sum_{t=1}^{T_i} x_t x_t^\\intercal$. Then under\nAssumption 3, with probability at least $1 - \\delta$, we have:\n$\\lambda_{min} (V_{i,t}) \\geq \\lambda + \\frac{\\lambda_c T_i}{8}, \\forall T_i \\in \\{T_{min}, T_{min} + 1, . . ., T\\}, i \\in [N]$, where $T_{min} = [\\frac{64 \\lambda \\sigma^2}{\\lambda_c^2} \\log(\\frac{2NTd}{\\delta})]."}, {"title": "Lemma 10 Lemma 3 from Li et al. (2021)", "content": "When $X_1$ and $X_2$ are rank-sufficient, the type-II\nerror probability can be upper bounded by,\n$P(s(H_{t-1,1}, H_{t-1,2}) \\leq v^\\epsilon || |\\theta_1 - \\theta_2|| > \\epsilon)  < F(v^\\epsilon; d,  \\frac{||\\theta_1 - \\theta_2||^2 / \\sigma^2}{1/\\lambda_{min}(X_1 X_1^\\intercal) + 1/\\lambda_{min}(X_2 X_2^\\intercal)}).$"}, {"title": "Appendix B. Proof of Theorem 1", "content": "In this section, we provide the full proof of Theorem 1, which states that utilizing our\nhomogeneity test with threshold $v^\\epsilon > F^{-1}(1 - \\frac{\\delta}{N^2}; df, \\psi^c)$, after the exploration phase of\nlength $T_0 = \\frac{16\\gamma^2 d \\sigma^2}{\\lambda^2 \\epsilon^4}$, the clusters $\\hat{C} = \\{\\hat{C}_1, \\hat{C}_2, ..., \\hat{C}_M\\}$ estimated by HETOFEDBANDIT match\nthe ground-truth clusters of the environment $C = \\{C_1, C_2, ..., C_M\\}$.\nThe homogeneity test statistic $s(H_{t-1,1}, H_{t-1,2})$ follows a non-central $\\chi^2$ distribution\n$s(H_{t-1,1}, H_{t-1,2}) \\sim \\chi^2(df, \\psi)$, where the degree of freedom\n$df = rank(X_1) + rank(X_2) - rank([X_1 X_2]),$\nand the non-centrality parameter\n$\\psi = \\frac{1}{\\sigma^2} [X_1 \\theta^*_1 - X_2 \\theta^*_2]^\\intercal [I_{t_1+t_2} - [X_1 X_2] [X_1 X_1^\\intercal + X_2 X_2^\\intercal]^{-1} [X_1 X_2]^\\intercal] [X_1 \\theta^*_1 - X_2 \\theta^*_2].$"}, {"title": "B.1 Lower Bounding P(CCC)", "content": "Recall that based on our cluster definition presented in Assumption 1, all clients that belong\nto the same cluster are within $\\epsilon$ of each other. We denote the ground-truth client graph\nG* as the graph where $\\exists e(i, j) \\in G^* \\forall i, j \\in N$ where $||\\theta^*_i - \\theta^*_j|| \\leq \\epsilon$. By Assumption 2,\nwe know that clients that do not belong to the same cluster are separated by $\\gamma$, so that\nthe ground-truth clusters C are the maximal cliques of G*. Thus, in order to prove that\nP(C $\\subseteq$ C), we need to show that the set of edges in the ground-truth client graph G* is a\nsubset of the edges in the estimated client graph G. To achieve this, we need to prove an\nupper-bound of the type-I error probability of the homogeneity test, which corresponds to\nthe probability that our algorithm fails to cluster two clients together when the underlying\nbandit parameters $||\\theta^*_i - \\theta^*_j|| \\leq \\epsilon$."}, {"title": "Lemma 11", "content": "The type-I error probability of the test can be upper bounded by:\n$P(s(H_{t-1,1}, H_{t-1,2}) > v^\\epsilon || |\\theta_1 - \\theta_2|| \\leq \\epsilon) \\leq 1 - F(v; df, \\psi^c)$,\nwhere F(v; df, $\\psi^c$) denotes the cumulative density function (CDF) of distribution $\\chi^2(df, \\psi^c)$\nevaluated at v, and $\\psi^c := \\frac{\\psi}{2}$ denotes its non-centrality parameter."}, {"title": "Appendix C. Proof of Lemma 2", "content": "In this section, we present the complete proof of the confidence ellipsoids, following similar\nsteps to the proof of Theorem 2 in (Abbasi-Yadkori et al., 2011).\nBefore we begin the proof, we will introduce a couple of useful notations to prevent\nclutter. Recall from Section 3.1 that the design matrix of client i, denoted as $X_i$, only\ncontains the observations made by client i through timestep t and does not include aggregated\nobservations from other clients. In this proof, we assume without loss of generality, that client\ni is a member of ground-truth cluster Ck and is therefore collaborating with clients $j\\in C_k$.\nAs a result, we can denote $V_{t,i} = \\lambda I + \\sum_{j \\in C_k} X_j X_j^\\intercal$ and $b_{t,i} = \\sum_{j \\in C_k} X_j (X_j\\theta^* + \\eta_j)$ due\\"}]}