{"title": "Explainable AI for Enhancing Efficiency of DL-based Channel Estimation", "authors": ["Abdul Karim Gizzini", "Yahia Medjahdi", "Ali J. Ghandour", "Laurent Clavier"], "abstract": "The support of artificial intelligence (AI) based decision-making is a key element in future 6G networks, where the concept of native AI will be introduced. Moreover, AI is widely employed in different critical applications such as autonomous driving and medical diagnosis. In such applications, using AI as black-box models is risky and challenging. Hence, it is crucial to understand and trust the decisions taken by these models. Tackling this issue can be achieved by developing explainable AI (XAI) schemes that aim to explain the logic behind the black-box model behavior, and thus, ensure its efficient and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST framework that is oriented toward channel estimation in wireless communications. The core idea of the XAI-CHEST framework is to identify the relevant model inputs by inducing high noise on the irrelevant ones. This manuscript provides the detailed theoretical foundations of the XAI-CHEST framework. In particular, we derive the analytical expressions of the XAI-CHEST loss functions and the noise threshold fine-tuning optimization problem. Hence the designed XAI-CHEST delivers a smart input feature selection methodology that can further improve the overall performance while optimizing the architecture of the employed model. Simulation results show that the XAI-CHEST framework provides valid interpretations, where it offers an improved bit error rate performance while reducing the required computational complexity in comparison to the classical DL-based channel estimation.", "sections": [{"title": "I. INTRODUCTION", "content": "Artificial intelligence (AI) is expected to play a crucial role in the overall design of future networks. In particular, 6G will transform the classical Internet of Things (IoT) to \"connected intelligence\", by leveraging the power of AI to connect billions of devices and systems worldwide [1]. This concept is defined as native (AI) which is a key element that differentiates 6G networks from the previous wireless networks. In native AI, distributed AI will be embedded within the functionality of all layers [2] to support demands for high data rates and low latency-critical applications.\nGenerally speaking, the AI-enabled intelligent architecture for 6G networks defines several layers including the intelligent sensing layer [3]. It is worth mentioning that robust envi-ronment monitoring and data detection are of great interest in 6G smart applications like autonomous driving [4]. Note that ensuring the reliability of the intelligent sensing layer is highly impacted by the channel estimation accuracy since a precisely estimated channel response influences the follow-up equalization and decoding operations at the receiver, therefore, it affects the sensing accuracy [5]. In this context, channel estimation is one of the major physical (PHY) layer issues due to the doubly-selective nature of the channel in mobile applications. Conventional channel estimation schemes such as least squares (LS) and linear minimum mean square error (LMMSE) can not be practical in real-case scenarios. This is because the LS channel estimation scheme ignores the presence of noise in the estimation process and requires the transmission of a large number of pilots which decreases the transmission data rate. Whereas, the LMMSE channel estima-tor provides good performance assuming the prior knowledge of the channel and noise statistics in addition to its high computational complexity."}, {"title": "A. DL-based Channel Estimation", "content": "Recently, deep learning (DL) has been employed in the PHY layer of wireless communications [6], including channel estimation [7]\u2013[10], due to its ability in providing good performance-complexity trade-offs. Among different DL net-works, feed-forward neural networks (FNNs) have been widely used as a post-processing unit following conventional channel estimators. In [11], the authors proposed an end-to-end FNN-based scheme for channel estimation and signal detection, where it directly detects the received bits from the received signal. The proposed FNN model consists of 3 hidden layers with 500, 250, and 120 neurons, respectively. We note that in this scheme the FNN model is trained to predict 16 bits only, hence, several concatenated models are needed according to the total number of transmitted bits. Using the same FNN model proposed in [11], the authors in [12] proposed an FNN-based channel estimation scheme that is used to predict the channel response using the received signal, received pilots, and previously estimated channel. Simulation results show that using the previously estimated channel as an FNN input improves the channel estimation accuracy. Another FNN-based channel estimation scheme has been proposed in [13], where LS channel estimation is first applied and combined with the previously estimated channel to be fed as an input to a3 hidden layer FNN consisting of 512, 256, and 128 neurons, respectively. As reported in [13], employing LS as an FNN input improves the channel estimation accuracy and provides a comparable performance to the LMMSE channel estimation scheme.\nTo further improve the performance while preserving low computational complexity, the authors in [7]\u2013[9] tried a dif-"}, {"title": "B. XAI Main Concepts, Categories, and Taxonomy", "content": "XAI defines four main concepts as shown in Figure 1: (i) Interpretability: is based on the model design and it refers to how much the black-box model can be understood by humans. For example, decision tree models have good inter-pretability since a human can easily understand their logic. ii) Explainability: is the ability to clarify and justify a particular prediction performed by the black-box model. Hence, it aims to clarify the internal functioning of the employed model. (iii) Trustworthiness: is the ability to make professionals feel confident in the decisions taken by the black-box model. (iv) Causality: is related to the generalization ability of the black-box model, where models should be able to detect cause-effect relations and adapt to environmental changes.\nGenerally speaking, XAI methods can be divided into two main categories [22]: (i) Perturbation-based or gradient-free methods, where the concept is to perturb input features by masking or altering their values and record the effect of these changes on the model performance. (ii) Gradient-based methods where the gradients of the output are calculated with respect to the input via back-propagation and used to estimate importance scores of the input features. Moreover, in terms of the provided explanations, the XAI methods can be further classified into [23]:\n\u2022 Model-agnostic vs model-specific: Model-agnostic XAI schemes are independent of the internal architecture of the black-box model including the weights and the hidden layers. Whereas, model-specific schemes depend on a specific model like FNN or CNN and can not be gen-eralized to any other model. Therefore, model-agnostic schemes are characterized by their high flexibility and can be used despite the type of the considered model.\n\u2022 Local vs global: Local XAI schemes are those that generate explanations for a group of samples, thus, they are highly dependent on the utilized dataset. In contrast, global XAI schemes generate explanations that are related more to the model behavior.\n\u2022 Pre-model, in-model, and post-model strategies: Knowing that the XAI schemes can be applied throughout the entire development pipeline. Hence, interpretability can be acquired in three main phases. Pre-modeling explain-ability is used to define the useful features of the dataset for a better representation. Hence, pre-modeling aims to perform exploratory data analysis, explainable feature engineering, and dataset description. In contrast, in-model explainability is to develop inherently explainable models instead of generating black box models. Finally, the post-model explainability method extracts explanations that are dependent on the model predictions."}, {"title": "C. XAI for Wireless Communications", "content": "Wireless communications are still in the early stages of using XAI. The majority of related works in the literature are surveys and reviews about the guidelines and importance of using XAI in wireless communications. In [24] the authors provided a review of the core concepts of XAI including definitions and possible performance vs. explainability trade-offs. They mainly focused on reviewing the recent DL-based schemes for the PHY and MAC layers and specified the explainability level of the studied schemes which is in general low. In [25] the authors proposed a novel XAI knowledge-powered framework for network automation that effectively adapts to the dynamic changes of complex communication systems as well as provides a human-understandable explana-tion. The proposed XAI scheme aims to explain the decision-making for automated path selection within the network.\nThe deployment of XAI in the open radio access net-work (O-RAN) was recently surveyed in [26], where the authors performed a comprehensive survey on the use of XAI to design a trustworthy and explainable O-RAN archi-tecture. Moreover, an explainable machine learning operations (MLOps) for streamlined automation-native 6G networks has been proposed in [27], [28], where Shapley additive ex-planations (SHAP) \u03a7\u0391I scheme is employed to assign the features importance [29]. We note that SHAP XAI scheme has been also employed for short-term resource reservation in 5G networks [30] and energy-efficient resource allocation, where the problem becomes more challenging [31], [32]. It is worth mentioning that, the majority of DL-based resource allocation schemes are based on deep reinforcement learning (DRL) where SHAP assigns importance to the features used by the DRL agent at each state. These features could be the number of active antennas, utilized bandwidth, number of connected users, and the average data rate. We note that SHAP is useful in such applications, however, it can not be efficiently used in channel estimation due to the absence of predefined features and the high dimensionality of the DL input vector.\nIn addition to network optimization and resource allocation, XAI has been employed also in internet-of-things (IoT) net-works. In [33] the authors presented a comprehensive survey on XAI solutions for IoT systems including the state-of-the-art past and ongoing research activities. In particular, they focused on the XAI for IoT adaptive solutions using several architectures based on 5G services, cloud services, and big data management. In [34] the authors proposed a novel model-agnostic XAI scheme denoted as transparency relying upon statistical theory (TRUST) for numerical applications. They further tested the proposed TRUST scheme on cybersecurity of the industrial IoT (IIoT). Simulation results show that TRUST scheme outperforms the local interpretable model-agnostic explanations (LIME) scheme [35] in terms of performance, speed, and explainability."}, {"title": "D. Motivation and Contributions", "content": "To the best of our knowledge, the methodology of de-ploying XAI schemes in PHY layer applications, specifically, channel estimation is still unclear. Noting that the proposed XAI-based schemes for network optimization [27], resource allocation [30], and secured IoT [33] can not be adapted to the PHY layer applications because in such applications there are no clear discriminative features within the model inputs. In this context, this paper aims to design a novel XAI framework for FNN-based channel estimation denoted as XAI-CHEST. This framework is based on a perturbation-based model-agnostic global pre-model methodology that jointly performs the channel estimation task and provides the corresponding interpretability. The XAI-CHEST concept has been partially proposed in [36], where the key idea is to provide the inter-pretability of black box models by inducing noise on the model input while preserving accuracy. The model inputs are then classified into relevant and irrelevant sets based on the induced noise. The contributions of this work can be summarized as follows:\n\u2022 Establishing the theoretical foundations of the XAI-CHEST framework where the detailed loss functions are formulated.\n\u2022 Deriving the analytical expression and the corresponding simulations of the noise threshold optimization to select the best threshold used in filtering the relevant model inputs."}, {"title": "II. SYSTEM MODEL", "content": "This section illustrates the considered generic system model in addition to the considered DL-based channel estimation scheme to be interpreted."}, {"title": "A. OFDM transceiver", "content": "In this work, we use an orthogonal frequency division mul-tiplexing (OFDM)-based transmission with non-linear radio frequency (RF) represented by the high power amplifier (HPA) at the OFDM transmitter. As shown in Figure 2, the first operation on the transmitter side is the binary bits generation. Generated bits are scrambled in order to randomize the bits pattern, which may contain long streams of 1s or Os. The scrambled bits are then passed to the encoder, which intro-duces some redundancy into the bits stream. This redundancy is used for error correction that allows the receiver to combat the effects of the channel, hence reliable communications can be achieved. Bits interleaving is used to cope with the channel noise such as burst errors or fading. The interleaver rearranges input bits such that consecutive bits are split among different blocks. This can be done using a permutation process that ensures that adjacent bits are modulated onto non-adjacent subcarriers and thus allows better error correction at the receiver. After that, the interleaved bits are mapped according to the employed modulation technique, i.e., BPSK, QPSK, 16QAM, 64QAM, etc. Bits mapping operation is followed by constructing the OFDM symbols to be transmitted. The data symbols and pilots are mapped to the active subcarriers and passed to the IFFT block to generate the time-domain OFDM symbols and followed by inserting the cyclic prefix (CP). Finally, the CP-OFDM symbol is subjected to the impacts of HPA non-linear distortion as well as the channel and the additive white Gaussian noise (AWGN) noise.\nAt the receiver side, the CP is removed and the FFT applied to the received symbol. Channel estimation and equalization are performed where the equalized data are de-mapped to obtain the encoded bits. Afterwards, deinterleaving, decoding, and descrambling are performed to obtain the detected bits. We note that the employed system model is based on the IEEE 802.11p standard [37]."}, {"title": "B. Signal Model", "content": "Consider a frame consisting of I OFDM symbols. The i-th transmitted frequency-domain OFDM symbol $s_i \\in \\mathbb{C}^{K\\times1}$, can be expressed as:\n$$s_i[k] =\\begin{cases}s_{i,d}[k], & k \\in K_d\\\\s_{i,p}[k], & k \\in K_p\\\\0, & k \\in K_n\\end{cases}$$\nwhere $0 \\leq k \\leq K - 1$ denotes the subcarrier index. We note that $K_{on}$ useful subcarriers are used where $K_{on} = K_p + K_d$. $s_{i,p} \\in \\mathbb{C}^{K_p\\times1}$ and $s_{i,d} \\in \\mathbb{C}^{K_d\\times1}$ represent the allocated pilot symbols and the modulated data symbols at a set of subcarriers denoted $K_p$ and $K_d$, respectively. $K_n = K - K_{on}$ denotes the null guard band subcarriers. $K_{cp}$ samples are added to the time-domain OFDM symbol resulting in $\\bar{x}_i \\in \\mathbb{C}^{K+K_{cp}\\times1}$ which is then passed to the HPA. According to the Bussgang theorem [38], the HPA output $\\bar{u}_i \\in \\mathbb{C}^{K+K_{cp}\\times1}$ can be expressed as follows:\n$$\\bar{u}_i = \\rho x_i + z_i,$$\nwhere $\\rho$ and $z_i$ refer to the complex gain and the non-linear distortion (NLD), respectively. After that $\\rho$ is compensated at the transmitter and $\\bar{u}_i$ can be rewritten as:\n$$\\frac{\\bar{u}_i}{\\rho} = x_i + \\frac{z_i}{\\rho},$$\nwhere $\\frac{z_i}{\\rho}$ denotes the remaining NLD of the HPA.\nThe received frequency-domain OFDM symbol $y_i \\in \\mathbb{C}^{K_{on}\\times1}$ is expressed as follows:\n$$y_i[k] = h_i[k]\\frac{\\bar{u}_i}{\\rho}[k] + e_i[k] + \\bar{e}_i[k],$$"}, {"title": "C. DL-based Channel Estimation", "content": "Conventional channel estimation depends highly on environ-ment conditions. In frequency-selective slow fading channels, the preamble-based channel estimation is sufficient, since the communication system encounters only muti-path fading and the channel is not changing over time. However, in double selective channels, the impact of Doppler interference is added to the communication system. Thus, the estimated channel at the beginning of the frame, i.e., the preambles, becomes outdated and channel tracking becomes more challenging, especially, in high mobility scenarios. To cope with this challenge, pilot subcarriers are allocated within a transmitted OFDM symbol to allow better channel tracking over time, where several conventional channel estimation and tracking schemes are proposed in the literature. In order to further improve the conventional channel estimation accuracy, DL models are applied as post-processing on top of conventional channel estimators. In this work, we considered the STA-FNN channel estimator [8] as a case study, where we used the op-timized XAI-CHEST framework to provide the corresponding reasonable interpretations.\nConventional STA channel estimation scheme [14] is based on the DPA estimation where the demapped data subcarriers of the previously received OFDM symbol are used to estimate the channel for the current OFDM symbol such that:\n$$d_i = D(\\frac{y_i}{h_{DPA_{i-1}}}), h_{DPA_i} = h_{LS},$$\nwhere D(.) refers to the demapping operation to the nearest constellation point according to the employed modulation order. $h_{LS}$ stands for the LS estimated channel at the received preambles. Thereafter, the DPA channel estimates are updated in the following manner:\n$$h_{DPA_i} = \\frac{y_i}{d_i}$$\nAfter that, frequency-domain averaging is applied where the DPA estimated channel at each subcarrier is updated as follows:\n$$h_{FD_i}[k] = \\sum_{\\lambda=-\\beta}^{\\beta} \\omega_\\lambda h_{DPA_i}[k+\\lambda], \\omega_\\lambda = \\frac{1}{2\\beta+1}$$\nFinally, time-domain averaging is employed to reduce the AWGN noise impact such that:\n$$h_{STA_i} = (1-\\alpha)h_{STA_{i-1}} + \\alpha h_{FD_i}$$\nWe note that conventional STA channel estimation performs well in the low signal-to-noise ratio (SNR) region. However, it suffers from a considerable error floor in high SNR regions due to the large DPA demapping error resulting from (7) and the fixed frequency and time averaging coefficients $\\alpha = \\beta = 2$ in (9) and (10), respectively. Therefore, the conventional STA channel estimation scheme is not practical in real-case scenarios due to the high doubly-selective channel variations.\nAs a workaround, a 3 hidden layer FNN consisting of 15 neurons per layer is utilized as a nonlinear post-processing unit following STA [8]. STA-FNN can better capture the time-frequency correlations of the channel samples, in addition to correcting the conventional STA estimation error."}, {"title": "III. XAI-CHEST FRAMEWORK DESIGN", "content": "Providing external interpretability of the black-box model used for channel estimation could be achieved through clas-sifying the model\u2019s input into relevant and irrelevant by employing a perturbation-based methodology. The main in-tuition is that if a subcarrier is relevant for the decision-making of a trained black box model, then adding noise with high weight to this subcarrier would negatively impact the accuracy of the model. Whereas, if the subcarrier is not contributing to the decision-making of the model, then whatever the induced noise is, the channel estimation accuracy will be preserved. Therefore, it is expected that considering only the relevant subcarriers as model inputs would improve channel estimation performance in comparison to the case where the full subcarriers are given to the model. Moreover, by reducing the model input size, the employed architecture could be further optimized resulting in significantly decreasing the overall computational complexity. Hence, by using the XAI-CHEST framework, we can obtain a reasonable interpreta-tion of the model decision-making methodology, improve the channel estimation performance as well as reduce the required computational complexity."}, {"title": "A. Methodology", "content": "Let U be the black-box utility model with parameters $\\theta_\\upsilon$. In general, the U model refers to the channel estimation model, where $h\\in \\mathbb{R}^{2K_{on}\\times1}$ and $\\hat{h}_\\upsilon \\in \\mathbb{R}^{2K_{on}\\times1}$ denote the conventional estimated channel that is given as an input to the U model and the corresponding output, respectively. We note that the size of $h$ is $2K_{on}$ since the conventional estimated channel is converted from complex to real domain before further processing by stacking the real and imaginary values vertically in one vector. $\\Phi$ refers to the employed conventional channel estimation scheme. The objective is to provide a reasonable interpretation of the behavior of the U model. Besides the U model, we define the interpretability noise model N, with parameters $\\theta_\\eta$, whose purpose is to compute the weight of the noise induced to each subcarrier within the U input vector. The key idea is that the induced noise weights of the N model should not impact the accuracy of the U model. This could be achieved by customizing the loss function of the N model that will adjust the induced noise while simultaneously maximizing the performance of the U model. We note that the U model is trained before the X\u0391\u0399 processing of the N model, i.e., the weights of the U model are frozen. Moreover, the U and N models have the same FNN architecture.\nLet $\\hat{h}_\\Phi$ be the input of the interpretability N model. The role of the N model is to find a mask $b'_\\eta \\in \\mathbb{R}^{2K_{on}\\times1}$ that can be represented as follows:\n$$b'_\\eta = N(\\hat{h}_\\Phi, \\theta_\\eta),$$\nwhere $b'_\\eta = (b'_\\eta[1], b'_\\eta[2], ..., b'_\\eta[2K_{on}]) \\in [0, 1]^{2K_{on}}$ determines the weight (standard deviation) of the noise applied to each element in $\\hat{h}_\\Phi$. We note that the scaling of $b'_\\eta$ is achieved using the sigmoid activation function. After that, the generated noise weight mask $b'_\\eta$ is first multiplied by a random noise $\\epsilon \\sim N(0, 1)$ sampled from the standard normal distribution, the resultant is added to the conventional estimated channel vector, such that:\n$$\\hat{h}'_\\Phi = \\hat{h}_\\Phi + b'_\\eta . \\epsilon,$$\nAfter that, $\\hat{h}'_\\Phi$ is fed as input to the U model, such that:\n$$\\hat{h}'' = U(\\hat{h}'_\\Phi, \\theta_\\upsilon).$$\nThe customized loss function of the N model can be expressed as follows:\n$$\\min_{\\theta_\\eta} L_N = \\frac{\\min}{\\theta_\\eta} (L_U - \\lambda L_X),$$\n$L_U$ denotes the loss unction of the U model when $\\hat{h}''_\\Phi$ is fed as an input. Hence, $L_U$ can be expressed as:\n$$L_U = \\frac{1}{N_{tr}} \\sum_{i=1}^{N_{tr}} ||h_i - \\hat{h}''_i||^2,$$\nwhere $h_i$ refers to the true channel and $N_{tr}$ is the number of training samples. Moreover, the induced noise is controlled by $L_X$ that can be written as:\n$$L_X = \\frac{1}{2K_{on}}\\sum_{j=1}^{2K_{on}} log(b'_\\eta[j])$$"}, {"title": "B. Noise Weight Threshold Fine Tuning", "content": "After accomplishing the N model training, the fine-tuning of the noise weight threshold denoted by $\\gamma$ is essential for classifying the model inputs into relevant and irrelevant. This could be formulated as an optimization problem, where the objective is to select the best input combination that minimizes the mean squared error (MSE) between the corresponding estimated channel by the U model and the true channel. We note that the fine-tuning optimization problem is subjected to improving or preserving the BER in comparison to the case where the full subcarriers are given to the U model.\nLet $\\Omega$ be the generic input given to the U model and $\\Psi$ be the optimized model input. The considered fine-tuning optimization problem can be mathematically expressed as:\n$$\\min_{\\Psi,\\theta_\\upsilon} L_U = \\frac{1}{N_{tr}} \\sum_{i=1}^{N_{tr}} (h_i - U(\\Omega=\\Psi, \\theta_\\upsilon))^2$$\ns.t. BER($\\Omega = \\Psi) < $ BER($\\Omega = ALL$)\nWe note that the defined optimization problem in (17) is not convex. The non-convexity can be shown by the line restriction method illustrated in Lemma 1 [40].\nLemma 1. Restriction of a convex function to a line A function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is convex, if and only if $\\forall x \\in dom f$ and $\\forall v \\in \\mathbb{R}^n$, the function $g = f(x + tv)$ is convex on $dom g = {t \\in \\mathbb{R} | x + tv \\in dom f}$.\nLemma 1 is based on the line restriction method to prove the convexity of the considered function. In this context, the initial loss function $L_U$ is reduced to the restricted loss function denoted as $g(t) = L_U(\\theta_\\upsilon + tv)$, where $v$ and t denote the randomly selected slice and the step size, respectively.\nFigure 4 shows the $g(t)$ where we can see numerous lo-cal minima signifying the non-convexity of our optimization function expressed in (17). We note that in the next section, we provided a heuristic solution of (17), where the BER vs noise weight threshold is analyzed and the best threshold is selected according to the lowest recorded BER among all the considered thresholds."}, {"title": "IV. SIMULATION RESULTS", "content": "This section illustrates the performance evaluation of the proposed XAI-CHEST framework, where BER performance of STA-FNN channel estimation scheme is analyzed taking into consideration full, relevant, and irrelevant subcarriers. First of all, we start with the noise weight threshold fine-tuning, where the simulation-based solution of (17) is provided. After that, the performance evaluation is performed according to several criteria including the (i) modulation order, (ii) frequency selec-tivity of the channel, (iii) training SNR, and (iv) conventional channel estimation accuracy. Finally, a detailed computational complexity analysis is discussed where we show that further significant reduction in the overall computational complexity can be achieved by employing only the relevant subcarriers identified by the proposed XAI-CHEST framework.\nWe note that the considered channel models [41] as shown in Table I: (i) Low-frequency selectivity (LFS), where VTV Expressway (VTV-EX) scenario is employed. (ii) High-frequency selectivity (HFS), where VTV Expressway Same Direction with Wall (VTV-SDWW) scenario is considered. In both scenarios, Doppler frequency $f_d$ = 1000 Hz is considered. Both the U and N models are trained using a 100,000 OFDM symbols dataset, splitted into 80% training, and 20% testing. ADAM optimizer is used with a learning rate lr = 0.001 with batch size equals 128 for 500 epoch. Simulation parameters are based on the IEEE 802.11p standard [5], where the comb pilot allocation is used so that $K_p = 4$, $K_d = 48$, $K_n = 12$, and I = 50. Table II summarizes the simulation parameters considered in this work. Finally, we note that the STA channel estimation is considered as an initial estimation prior to the FNN processing. Hence, $\\Phi$ = STA, unless stated otherwise."}, {"title": "A. Noise weight threshold fine-tuning", "content": "The first step of solving (17) is to analyze the distribution of the noise weight vector $b'_{STA}$, over the input subcarriers. Both the U and N models are trained using the HFS channel model with QPSK modulation and 40 dB training SNR. We note that we train the models on SNR = 40 dB since the models can learn the channel better when the training is performed at a high SNR value because the impact of the channel is higher than the impact of the AWGN noise in this SNR range [42]. Owing to the robust generalization properties of DL, trained networks can still estimate the channel even if the AWGN noise increases, i.e., at low SNR values.\nFigure 5(a) shows the distribution of $b'_{STA}$. We notice that the majority of subscribers are distributed more towards zero. This signifies that the model is not sure if the subcarriers can be neglected or not. It is worth mentioning that the pilot subcarriers are assigned the lowest noise weight, i.e., 0.1 which reveals that the U model is not able to neglect the estimated channels at the pilots, and considering them is crucial for high estimation accuracy. This is consistent with the channel estimation rules, where the channel estimates at the pilots are very close to the ideal channel estimation.\nSelecting the optimized U model input $\\Psi$ is determined by choosing the best noise weight threshold $\\gamma$ which is mainly responsible for classifying the subcarriers into relevant and irrelevant. To select the optimal $\\gamma$, we simulated the BER considering all possible values, i.e, $\\gamma$ = [0.1, 0.2, 0.3, ..., 0.8]. In each case, we trained the U model considering both the relevant and irrelevant subcarrier combinations.\nAs shown in Figure 5(b), we can notice that considering $\\gamma$ = 0.4 gives the best BER performance among other thresholds. Therefore, the STA-FNN model needs only $\\Psi$ = 28 subcarriers out of the full set, i.e, $|\\Psi|$ = 52 in order to provide the best possible performance in the considered HFS channel model. On the contrary, all the irrelevant subcarrier combinations are worse than the full case in terms of BER performance. In other words, considering $|\\Psi|$ = 48 which corresponds to excluding only the four pilot subcarriers is not enough to preserve the BER performance of the full case.\nFigure 5(c) shows the BER in terms of $\\gamma$ considering SNR = 40 dB. Again, increasing $\\gamma$ is beneficial until reaching $\\gamma$ = 0.4, where the BER performance degrades. This signifies that in complicated scenarios as the case in employing the"}, {"title": "B. Impact of modulation order", "content": "In this section, we further investigate the impact of the employed modulation order on the noise weight distribution considering also the HFS channel model. Figure 6 shows the BER performance of employing the HFS channel model using QPSK, 16QAM, and 64QAM, respectively. In general, the BER performance degrades as the modulation order increases. This degradation is mainly due to the impact of the dominant multi-path fading in addition to the DPA remapping error. Moreover, in this scenario, employing only the four pilot subcarriers performs almost similarly to the full case. To improve further the BER performance, more relevant subcar-riers are needed. Therefore, when the environment becomes more challenging, the channel variation increases among the subcarriers, thus, the noise distribution is shifted towards zero signifying the need for more relevant subcarriers.\nHowever, we can notice that for higher the modulation order, the number of neglected subcarriers increases. This is because the conventional STA channel estimates at these subcarriers are so noisy, so the model neglects them. It is worth mentioning that, the model neglects subcarriers due to two main reasons: (i) LFS: The channel variation among the subcarriers is slow, so few subcarriers are required to accurately estimate the channel, as we will discuss in the next Section. (i) HFS: Here the channel variation is significant among the subcarriers, thus, the U model should consider more relevant subcarriers to guarantee good channel estimation accuracy. However, this is subject to the condition where the conventional estimated channel at the considered subcarriers is useful and not so noisy. Therefore, in the HFS channel model, more relevant subcarriers are needed and this is shown in generally shifting the noise weight distribution towards zero. However, for higher modulation orders, mainly 64QAM, the neglected subcarriers are huge due to the bad channel estimation quality at these subcarriers. Hence, avoiding them is useful to guarantee BER performance. We note that the four pilot subcarriers are assigned the lowest noise weight for"}, {"title": "C. Impact of channel frequency selectivity", "content": "In this section, we will investigate the performance eval-uation using the same methodology of Section IV-B but considering the LFS channel model. Figure 8 shows the BER results of employing QPSK, 16QAM, and 64QAM modulation orders, respectively. We can notice a significant performance degradation as the modulation order increases which is expected. The nice thing lies in employing the pilot subcarriers only, where the corresponding BER performance improves in comparison to the full case. In other words, the BER performance improvement of employing the pilots in comparison to the full case for 64QAM modulation is higher than that for 16QAM and QPSK modulations, respectively. This is because applying the frequency and time domain averaging in the conventional STA channel estimation is no longer reliable due to high demapping error resulting from the DPA channel estimation (7) that is applied prior to the STA estimation. Similarly to the discussion in Section IV-A, employing more relevant and irrelevant subcarriers leads to a BER performance degradation in both cases where in the relevant case, the BER performance is approaching the full case, while in the irrelevant case, the performance is going off the full case.\nFigure 9(a) illustrates the noise weight distribution of train-ing the models using different modulation orders. We can notice that distribution is shifted towards one, where the majority of subcarriers are assigned noise weight equal to one. This signifies that these subcarriers are not important for the decision-making methodology of the U model. This is because, in the LFS channel model, the channel presents a smooth variation over the subcarriers, thus, the STA-FNN model needs few subcarriers to accomplish the channel es-timation task. Moreover, as the modulation order increases, the noise weight distribution becomes wider, where more subcarriers are assigned more weights. For example, in the 64QM modulation order, it seems that the model needs more subcarriers to preserve good performance, thus the number of subcarriers that are assigned noise weight = 1 decreases. Moreover, in all cases, the model is able to classify pilots as the most relevant subcarriers by assigning them the lowest noise weight regardless of the employed modulation order. The BER vs the noise weight for the considered modulation orders is shown in Figure 9(b) where we can notice that considering only the pilots in the LFS channel model is enough, and there is no need to consider any other subcarriers. On the contrary, all the irrelevant subcarrier combinations are worse than the full case in terms of BER performance. Hence, the absence of the four pilots leads to performance degradation even if the other || = 48 subcarriers are considered."}, {"title": "D. Impact of RF non-linear distortion", "content": "In order to further analyze the impact of HPA-induced nonlinearities, we employ QPSK modulation and IBO = 2 dB in the HFS channel models. Figure 10 shows the noise weight distributionas well as the BER analysis. It can be noticed that only 2 pilots are assigned the lowest noise weight in comparison to 4 in the linear case. This ensures that the HPA-induced nonlinearities contribute to confusing the subcarrier filtering procedure. However, a slight BER rate performance improvement can be achieved by employing || = 27 for $\\gamma$ = 0.5. Therefore, similar insights can be concluded as the linear case where the proposed perturbation based XAI framework is able to filter out the relevant subcarriers while preserving the BER performance when using the full subscribers as an input to the U model."}, {"title": "E. Impact of training SNR", "content": "The sensitivity of the U model training considering different SNR values is analyzed in this section. Figure 11(a) shows the noise distribution when considering several training SNRs employing the LFS channel model and QPSK modulation order. Starting by training SNR = 0 - 5 dB, we can see that the pilot subcarriers are assigned 0.2 noise weight and the distribution is flattened along the entire range. This reveals that even though the pilots have accurate channel estimates, due to the dominant impact of AWGN noise, the U model is not able to assign the lowest noise weight to the pilot subcarriers. It is worth mentioning that when training on SNR = 10 dB, the model starts to identify the pilot subcarriers as the most relevant subcarriers by assigning to two pilots the lowest noise weight, i.e., 0.1. Moreover, as the training SNR increases, the noise distribution is shifted more towards one, signifying that the model is better identifying the relevant and irrelevant subcarriers. Figure 11(b) shows the BER performance when the U model is trained on a specific SNR and tested on the entire SNR range. We can notice that training on higher SNR gives better performance than training on the lower SNR due to the fact the AWGN noise is negligible at high SNRs, thus the U model can learn more efficiently the channel. In addition, the trained model on high SNR can perform well when tested on lower SNRs due to the generalization ability of FNN networks. In conclusion, training on low SNR values leads to a limited performance improvement over the conventional STA channel estimation. Whereas training on high SNR allows the smart feature selection resulting in optimizing the U model input size, as well as significantly improving the BER performance in comparison to the conventional STA channel estimation."}, {"title": "F. Impact of conventional channel estimation accuracy", "content": "To further analyze the impact of the conventional channel estimation which is implemented prior to the FNN processing on the noise weight distribution, we considered in this section the DPA-FNN [7] and TRFI-FNN [9] channel estimation schemes in addition to STA-FNN. We note that we consider the HFS channel model with QPSK modulation in this analysis since it is more challenging.\nAs we can see from Figure 11(b), the conventional TRFI channel estimation outperforms the STA channel estimation in the high SNR region. This is due to the cubic interpolation employed on top of the DPA channel estimation in the TRFI scheme. Similar behavior can be seen with respect to the TRFI-FNN and STA-FNN channel estimators, where the TRFI-FNN also outperforms the STA-FNN in the high SNR region."}, {"title": "G. Computational complexity reduction", "content": "This section aims to investigate the possibility of optimizing the U model architecture following selecting the most relevant subcarriers so that the BER performance improvement as well as reducing the computational complexity can be achieved. In this context, we considered the same simulation parameters as Section IV-A, where the pilot subcarriers are fed to the U model with different architectures. The objective is to reduce the computational complexity of the classical STA-FNN model (15 \u2013 15 \u2013 15) while preserving the BER performance of the best relevant case, i.e., employing only the pilots in the LFS channel model.\nFigure 13 shows the BER performance of different STA-FNN architectures. We can notice that the FNN architecture could be reduced up to one hidden layer with 15 neurons while preserving the best possible performance. Moreover, decreasing the number of neurons within this architecture to 10 performs the same as the classical STA-FNN channel estimation scheme, i.e., considering the full subcarriers as inputs with the (15 \u2013 15 \u2013 15) FNN architecture. However, employing shallow FNN architecture with 5 neurons is not useful at all, where a significant performance degradation is recorded in comparison to the classical STA-FNN architecture.\nThe computational complexity of the employed FNNs is computed in terms of the number of FLOPS\u00b9 required by each FNN architecture, as shown in Table III. Employing the same FNN architecture as the classical STA-FNN one but using the pilot subcarriers as input reduces the complexity by around 1.5\u00d7 times in comparison to the classical STA-FNN channel estimation scheme. However, further complexity reduction can be recorded by employing a shallow FNN with 15 neurons, where 2\u00d7 times can be achieved in comparison to the classical STA-FNN channel estimation scheme. We would like to mention that similar BER performance can be guaranteed as the classical STA-FNN channel estimator by feeding the four pilots to a shallow FNN architecture with 10 neurons, where 3\u00d7 times less computational complexity is required. Finally, we would like to mention that the proposed XAI-CHEST framework resolves the main issues related to the black box DL models by providing interpretability to the model behavior, performance improvement, and computational complexity reduction by selecting the relevant model inputs and optimizing the architecture of the employed FNN model."}, {"title": "V. CONCLUSION", "content": "Ensuring the transparency and trustworthiness of AI is a crucial need for its efficient and safe deployment in criti-cal applications. In this paper we designed a novel XAI-CHEST framework that provides the interpretability of the FNN models employed in the channel estimation application. The XAI-CHEST framework aims to classify the black-box model inputs into relevant and irrelevant inputs by using a perturbation-based methodology. We developed the theoretical foundations of the XAI-CHEST framework by formalizing the related loss functions. Moreover, the noise threshold fine-tuning optimization problem has been analytically derived. Extensive simulations have been conducted where the results reveal that a trustworthy, optimized, and low-complexity chan-nel estimation scheme can be designed by selecting only the relevant inputs. As a future perspective, the gradient-based XAI for wireless communication will be investigated, where we will study the possibility of providing robust interpretation by using the internal architecture of the FNN model."}]}