{"title": "WavePulse: Real-time Content Analytics of Radio Livestreams", "authors": ["Govind Mittal", "Sarthak Gupta", "Shruti Wagle", "Chirag Chopra", "Anthony J DeMattee", "Nasir Memon", "Mustaque Ahamad", "Chinmay Hegde"], "abstract": "Radio remains a pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present WAVEPULSE, a framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of WAVEPULSE in a collaborative project with a team of political scientists focusing on the 2024 Presidential Election. We use WAVEPULSE to monitor livestreams of 396 news radio stations over a period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate WAVEPULSE's efficacy in capturing and analyzing content from radio livestreams sourced from the Web. Code and dataset can be accessed at https://wave-pulse.io", "sections": [{"title": "1 INTRODUCTION", "content": "Despite the rise of the World Wide Web and the emergence of social media networks, radio as a cornerstone of mass media has demonstrated remarkable staying power. Since 2018, even though television viewership and print readership have plummeted by 29%, radio listenership has experienced a mere 7% decrease [33]. This resilience is further underscored by radio's dominance in terms of its reach among the public. In 2023, AM/FM radio can be freely accessed by over 84% of U.S. adults, outperforming both smartphone-based social networking (78%) and live TV (72%) [22, 33].\nRadio's enduring relevance stems from its unique attributes. In contrast to global social media platforms, radio's focus is primarily hyperlocal, and fosters deep community connections through content tailored to specific geographical areas (such as towns, counties, and states). Radio's primary function is as a one-way communication channel, allowing listeners to passively engage during their everyday activities, such as during commutes and/or at work. Many radio broadcasts are spontaneous and ephemeral, and the irreversible nature of radio broadcasts lends authenticity and immediacy to its content, particularly crucial in political discourse. These features have positioned radio as a trusted, community-oriented medium which provides an alternative to the deluge of social media content, and gives (to some) welcome respite during digital fatigue.\nWhile these distinctions make radio unique as a medium, they also make radio content much more challenging to monitor. In the United States, these features take on heightened significance. Radio serves as a vital link across diverse urban and rural landscapes, functioning a primary information source in remote areas and during long drives.\nMedia exposure, especially through radio, plays a crucial role in shaping political attitudes by both reinforcing and challenging existing beliefs. Theories of opinion formation suggest intensity of competing media messages is crucial in explaining changes in opinions over time [11, 35]. While partisan news tends to modestly reinforce existing beliefs, it is also shown to activate and convert individuals when they are continually exposed to opposing viewpoints, leading them to shift away from their original affiliations and preferences [12]. Resistance to these opposing viewpoints requires the ability and motivation to recognize discrepancies between the message and one's values and beliefs [35]."}, {"title": "2 FRAMEWORK AND DATA COLLECTION", "content": ""}, {"title": "2.1 Design of WavePulse", "content": "The proposed framework comprises three primary components, as illustrated in Fig. 1. Each component serves a distinct function in the process of capturing, processing, and analyzing radio content:\nRadio Streamer is responsible for acquiring audio feeds from web-based radio broadcasts [1]. It operates on a configurable schedule, enabling parallel recording of multiple audio streams at predetermined intervals throughout the day. The streamer segments incoming audio into manageable chunks to facilitate batch processing. Upon completion of each chunk, the component transfers the file to the audio buffer of the subsequent component.\nThe Radio Streamer continuously records all configured radio streams in parallel and segments them into 30-minute MP3 files. These files are then forwarded to the system's audio buffers for further processing. To optimize capture of relevant content while allowing time for system maintenance and backup, the streamer automatically initiates operations at 05:00 and concludes at 03:00 the following day (UTC-4).\nAudio Processor transforms the recorded audio chunks into time-stamped, diarized transcripts through a multi-stage process:\nDiarization and Transcription: We first utilize WhisperX [4], which integrates OpenAI's Whisper-large-v3 [25] model with PyAnnote [23] for speaker diarization; this converts each audio file into structured JSON format. The resulting output contains spoken text segments, speaker indices, and precise start and end times for each segment (typically a sentence long, see Fig. 3 for examples).\nContent Classification: Radio broadcasts intermix political news and discussion with ads and apolitical content. We process the radio broadcast in the JSON output using Google's Gemini-1.5-Flash model [30], which categorizes each segment as either political or apolitical. In alignment with the project's focus on political discourse, apolitical segments are archived in cold storage.\nAdvertisement Identification: Political segments undergo a second round of classification using Gemini to distinguish advertisements from substantive content. The remaining material consists of news reports and political discussions.\nHaving labeled each segment as apolitical, political ad, or political content (implicitly news and discussions), we split each JSON transcript into three mutually-exclusive parts. The filtered political content is then sent for final processing.\nWhile we started with classifying audio to segment out music and delete segments that were devoid of speech, we ended up removing this step because music was rare in news-oriented stations and radio stations tend to keep any gaps to a minimum in order to not waste air-time.\nFinal Transcript Generation: The system generates timestamped transcripts that include speaker indices using the start time of each transcript, offset with the segment-specific stamp (as illustrated in Fig. 3). Additionally, we split the transcript into three mutually-exclusive parts - news/discussion, ads, apolitical - and append continuation markers in these transcripts to prevent temporal discontinuities. For example, we insert \"political ad...\" between two segments of a political discussion. For more details, see Sec. A.1."}, {"title": "2.2 A Dataset of Nationwide Radio Transcripts", "content": "WAVEPULSE produces a comprehensive, segmented record of radio content, categorized into mutually exclusive, chronologically ordered, speaker-tagged, chat-like transcripts. This approach preserves the temporal integrity of the original broadcast, clearly delineating transitions between political discourse, advertisements, and apolitical content. Consequently, users can navigate the transcribed content with a clear understanding of its structure and context, even when encountering interruptions such as advertisements within political discussions. Please refer to Sec. A for details.\nWe collected the dataset for a period of 100 days starting June 26th, 2024 with a cutoff on Oct 3rd, 2024. In this period, we started"}, {"title": "3 ANALYSIS AND CASE STUDIES", "content": "Having a time-stamped radio transcript database, that captures a unique snapshot in American political broadcasting, we analyze them in the following three case studies. The studies demonstrate how WAVEPULSE can be used to explore the spread of a specific misinformation claim, the amplification of information by a network of radio stations, and assessment of the overall sentiment of major party candidates."}, {"title": "3.1 Case Study: Spread of a Political Narrative", "content": "Overview. We collaborated with a democracy group at the Carter Center which champions social causes including election integrity. Our goal was to understand how a system like WAVEPULSE could be useful to gain insights into the political/election discourse.\nThe center aimed to track a narrative that revolved around the integrity of the 2020 US Presidential election in Fulton County, Georgia (US), that stemmed from a report analyzing the election in Georgia, published by a campaign spokesperson, claiming that the election was stolen from Trump. Taking this narrative as an example, we searched through our corpus for matching pieces of the narrative. Our dataset came out positive with at least 50 positive samples, including a majority amplifying the claim in this narrative, a handful reporting and a few debunking it."}, {"title": "3.2 Case Study: Content Syndication Across Radio Stations", "content": "Our analysis of radio station transcripts revealed extensive verbatim duplications across geographically dispersed stations, suggesting the existence of a complex social network among broadcasters. This phenomenon, observed across state boundaries and varying time frames, indicates structured information sharing among media outlets. For instance, a specific claim regarding a presidential candidate's alleged substance use before a debate was simultaneously broadcast by 31 distinct stations. While this synchronicity in content dissemination does not establish causality between broadcasts, it strongly suggests coordinated information sharing."}, {"title": "Methodology: Connecting and Categorizing Stations", "content": "To investigate information sharing patterns, we developed an algorithm to identify unique broadcasts and their repeats, comprising the following steps:\nHashing and Similarity Computation: We computed locality-sensitive hashes of text-only portions of all transcripts using MinHash. We considered transcript pairs with Jaccard similarity exceeding a predefined threshold ($\\theta$ = 0.8) related and thus added to each other's adjacency list. As causality is hard to predict, we consider such a content-based match to only suggest a symmetric connection.\nSubgroup Identification: Utilizing these adjacency lists, we expanded our search to identify distinct subgroups through a Breadth-First Search (BFS) approach. We started with the initial list of unvisited transcripts, and BFS all connected transcripts, forming exhaustive lists of resonating broadcasts which matched thematically.\nNetwork Refinement: To identify long-term collaborations and information propagation hubs, we implemented the following steps:\n(1) Merged broadcasters in the same subgroup on consecutive dates (e.g., We would consolidate KM_WXYZ_2024_07_15_13_30 and LM_WABC_2024_07_16_02_00 broadcasted identical content).\n(2) Discarded single-broadcaster subgroups, eliminating instances of content repetition on two-consecutive days.\n(3) In the remaining subgroups, extracted only the station names, such as KLMN and KOPQ, for each unique station.\n(4) Removed single-station lists, further refining the network by eliminating stations who broadcast their own content several days apart.\n(5) Created bidirectional edges between stations in each subgroup (e.g., for stations KLMN, KOPQ, and KRST, edges were created between all pairs).\n(6) Ensured uniqueness across rows and order invariance, standardizing edge representation.\n(7) Generated pair-wise connections, excluding self-connections."}, {"title": "Results and Discussion", "content": "Our analysis initially identified 22,149 unique subgroups broadcasting similar content. Post-refinement, this reduced to 1,776 subgroups with 2,684 unique edges. This content mirroring pattern suggests coordinated messaging strategies transcending geographical and temporal boundaries. Figure 5 illustrates this broadcasting station network. Notable findings include:\n\u2022 Fifteen stations exhibiting over 40 connections, suggesting key information exchanges.\n\u2022 A ten-station network spanning 10 mid-western and southern states shared content several times, indicating a regional syndication network.\n\u2022 50 stations remained disconnected in our final network, potentially indicating non-participation in syndicates, self-broadcasters or representing false negatives in our analysis. For instance, a station in New Jersey, despite being a major broadcaster, showed no connections in our network, suggesting it might prioritize original content or use syndication methods our analysis could not capture.\n\u2022 Content propagation chains, such as a station in Iowa broadcasted a story, another one in Tennessee echoed it ten days later, and followed by Illinois after another eight days."}, {"title": "3.3 Case Study: Presidential Candidates' Favorability Trends", "content": "The summer of 2024 marked a pivotal period in American politics, with public perception of presidential candidates fluctuating in response to unfolding events. This study delves into these dynamics through a sentiment analysis of the dataset, focusing on the three most prominent figures: Harris, Biden, and Trump, with Biden dropping out in mid-July.\nWe isolated relevant text segments by keyword matching, carefully excluding instances of multiple candidate mentions to ensure sentiment clarity\u00b3. The Twitter-roBERTa-base model [9], denoted as S, served as the foundation for sentiment analysis, generating positive ($S_p$), neutral ($S_0$), and negative ($S_n$) sentiment counts. To distill these multifaceted sentiment counts into a single, comprehensible metric, we developed a normalized sentiment score $\\hat{S} \\in [0, 1]$:\n$\\hat{S} = (2S_p + 1S_0 + 0S_n) / (2S_T)$ where $S_p, S_0, S_n \\in \\mathbb{Z}^+$ and $S_p + S_0 + S_n = S_T$\nThis formulation captures the nuances of all three sentiment categories, while providing a holistic view of content sentiment and enables day-to-day sentiment comparisons independent of mention frequency.\nThe lower part of Fig. 6 illustrates the ebb and flow of nationwide sentiment as computed from the radio content, smoothed with a 7-day moving average to reveal underlying trends, as radio shows had less programming during weekends which caused weekly dips. Annotated political events offer context for significant shifts, painting a picture of how key moments shaped public perception. We derive the upper part of the figure from raw data of Nate Silver's model [29].4 Diving deeper, Fig. 7 breaks the trends down according"}, {"title": "Findings and Discussion", "content": "Our sentiment predictions demonstrate similarity with the 2024 Presidential polling averages, which in turn is based on reputable national polls and summarized by a competitive model from a prominent pollster. This alignment suggests that radio content analysis can serve as a valuable proxy for public sentiment, offering real-time insights into political trends.\nThe state-wise sentiment analysis reveals a granular view of political leanings across the country. However, some anomalies emerged, such as the surprisingly strong Democratic lead in Wisconsin (D+12). This discrepancy between state-level and nationwide trends warrants further investigation."}, {"title": "4 RELATED WORK", "content": "Radio Content Analytics. While radio has a century-long history as a broadcasting medium for entertainment and information dissemination, modern radio in the U.S. has its roots in the deregulation adopted in the Telecommunications Act of 1996 that fundamentally reshaped the U.S. radio industry. The deregulation altered the industry's economics, with large conglomerates implementing cost-cutting measures such as staff reductions and automated programming, while also changing advertising dynamics by offering multi-station, multi-market packages to advertisers [14]. Also, due to the rise in online music streaming and piracy making music expensive to broadcast, talk shows gained popularity. We did not include iHeartMedia stations in this study as they have restrictive terms of service, but still found several other syndicates [6].\nHofstetter [16, 17] studied how radio shows shape public opinion and found that they play several roles for their listeners, including seeking information, contextualizing, interpreting the information, and serving as a proxy for interaction with the hosts and guests.\nFrom 2006-2011, DARPA undertook efforts to collect and transcribe cross-lingual broadcast news and talk shows under its GALE project [31]. In 2019, RadioTalk [5] was the first work that created a large corpus of talk radio transcripts comprising 284,000 hours of radio and 2.8 billion words. The authors conducted transcription using a TDNN model which produced noisy samples with a WER of 13.1%. Using this dataset, Brannon and Roy [8] compared the speed of news on Twitter versus radio during 2019-2021 and found that Twitter news circulates and evaporates faster and is more negative than radio. A follow-up work assembled the Interview media dialog dataset [20] comprising of collection of 20 years of NPR radio transcripts that enables discourse pattern analysis. Our work simultaneously provides an end-to-end pipeline, based on modern LLMs with 8.3% WER, which continuously produces a rich dataset while being able to run real-time analytics to poll it.\nSocial Media Analytics Frameworks. Aggarwal et al. [2] developed a multimodal framework to track bias and incivility on Indian TV news. Saez-Trumper et al. [28] used unsupervised methods on a geographically diverse set of news sources by examining 'gatekeeping, coverage, and statement bias' to find bias in online news. Ribeiro et al. [27] employed scalable methodologies that leverage social media's advertiser interfaces to infer the ideological slant of thousands of news outlets. Allen et al. [3] analyzed Facebook posts during the COVID pandemic for content in the grey area and found"}, {"title": "5 DISCUSSION AND CONCLUSION", "content": "Ethics statement. We have maintained strict ethical principles during the data collection, usage, and analysis conducted in this work. Our research utilizes data broadcast to the web on public radio streams, which falls under fair use unless explicitly restricted under terms of service. We meticulously reviewed broadcasters' license agreements where applicable and excluded stations with such restrictions. The dataset does not contain personally identifying information (PII) about listeners.\nThe dataset may include PII about advertisers (e.g., names and contact information of organizational representatives) and show hosts. Given our focus on political topics, we have strived to avoid political bias by using politically neutral prompts and presenting case studies without subjective labeling. We acknowledge that the usage of LLMs in our analysis may inherently exhibit some biases due to their respective training data. We leave the study of any political bias to political scientists.\nLimitations and Future Directions. Our analysis does not incorporate population data along with reach of each stations waves' to calculate exposure to each station. Nielsen Audio sells exposure ratings and FCC hosts ground conductivity data. We also included only stations which are livestreamed over the Internet. Terrestrial-only radio broadcasts would require dedicated hardware (an antenna, transceiver, and recording equipment). Finally, while WAVEPULSE is widely applicable, our analysis derives results and conclusions from only US radios. An important direction of future work is to broaden the scope to worldwide radio livestreams; due to the multilingual nature of LLMs we anticipate our system to scale up with no significant design changes.\nWhile we are confident about WavePulse's scalability and error rates, our analyses should be considered within the context of case studies. A comprehensive evaluation would require interdisciplinary collaboration and usage-based assessment. Our case studies demonstrate a non-exhaustive variants of general-purpose tasks - search, finding syndicate network, sentiment analysis \u2013 that WavePulse can perform.\nConclusions. We introduce WAVEPULSE, an end-to-end pipeline for gathering and analyzing live-stream radio broadcasts which can increasingly be accessed via the Web. Using this system, we collected nearly half a million hours of news/talk radio content over a 100-day period of significant political activity in the United States. We conducted three case studies: tracking political narratives with political scientists, building a social network of radio stations, and predicting political trends in real-time. Our findings highlight the depth of insights derivable from WavePulse's comprehensive dataset."}, {"title": "A SUPPLEMENTARY MATERIAL FOR WAVEPULSE", "content": ""}, {"title": "A.1 Data Collection Pipeline", "content": ""}, {"title": "A.1.1 Radio Streamer", "content": "This component is used to stream and record audio streams from multiple parallel radio broadcasts. It takes as input a configurable schedule in the form of a JSON file, for when to stream and from which radio. There will be one entry per radio stream, its live URL, name, record times, and the state in which it is located along with a list start and end times for streaming for that particular radio stream, as shown in Listing 1. The component processes the schedule to get unique start times across all the stations and durations specific for each station and then create cron jobs appropriately to achieve its objective.\nConventionally, radio stations are referred to by their call signs (3-4 letter string) with the starting letter being either W (Stations east of the Mississippi River), K (Stations west of the Mississipi River), N (military stations), A (Army or Air Force stations). See Table 2, Table 3, and Table 4 for the full list of stations that have been streamed successfully.\nThe audio files are recorded and saved in chunks of 30 minutes to facilitate batch transcription and analysis. The recorded audio files are distributed into buffer folders for running transcription in parallel. Buffer folders are created based on the number of GPUs available in the system to run transcription. The files are named in format SS_RRRR_yyyy_mm_dd_HH_MM.mp3 where SS stands for State Abbreviation, RRRR stands for Radio Call Sign which is unique for each radio station, followed by year, month, day, hour, and minute, such as CA_KAHI_2024_07_16_13_30.mp3. This naming format allows us to be able to easily filter files based on state, radio station or dates."}, {"title": "A.1.2 Audio Processor", "content": "This component is responsible for the transcription, adding punctuation and capitalization to the text, providing time stamps, and diarization of the speakers of the recorded audio files. We tried multiple ASR models for transcription like facebook's MMS-1B, Nvidia's Parakeet-RNNT-1.1B and OpenAI's whisper-large-v3. Fig. 2 has sample outputs of these models for same input audio. We found word error rate of mms-1b to be significantly higher compared to Parakeet-RNNT and whisper-large-v3, for the latter two it was comparable. Ultimately we decided to go ahead with WhisperX implementation of Whisper as it provides a built-in pipeline for transcription using Whisper, accurate timestamps using Wav2Vec2 and Speaker Diarization using PyAnnote at a reasonable inference speed. Listing 1. shows a snippet of output using WhisperX pipeline.\nOne H100 GPU takes around 30 seconds to process one audio file of 30 minutes. So one GPU can process 60 audio files of 30 minute length, in other words one GPU can process 60 radio streams without resulting in any backlog. Since we were trying to process 400+ streams so we had to use 7 H100 GPUs. Due to resource"}, {"title": "WavePulse Deployment", "content": "Radio-streamer Configuration:\nStreams: 396 on 64 cores\nDaily Recordings : 17,000 (30-min each)\nGPU Processing: 7 GPUs for real-time\nML Model: Google Gemini\nResource Utilization:\nTranscription: 10,105 A100 GPU hours\nGemini Cost: $4,000 (1.5-flash)\nVectorization : 24 H100 GPU hours for 10\u00ba transcripts\nStorage Rate: 180 GB/day \u2192 18 TB/100 days\nMinimal Deployment Requirements (100 streams):\nStorage: 200 GB\nComputing: 2 GPUs + 24 CPU cores\n(16 streaming, 4 per GPU)"}, {"title": "A.2 Summarization", "content": "The summarization process is a critical step in condensing lengthy conversation transcripts into concise, meaningful summaries. This"}, {"title": "A.3 Dense Embedding for Summaries", "content": ""}, {"title": "A.3.1 Overview", "content": "Once the conversation segments are generated and summarized, the next step is to create embeddings for each summary. These embeddings serve as high-dimensional vector representations that capture the semantic meaning of the text. The"}, {"title": "A.3.2 Mathematical Representation", "content": "The embedding function, denoted by f, transforms a given summary S into a high-dimensional vector v \u2208 Rd, where d represents the number of dimensions in the vector space. The process can be mathematically described as:\n$v_s = f(S), \\quad f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^d$ (1)\nHere, S is the summary, vs is its corresponding embedding, n is the number of words in the summary, and d is the dimensionality of the embedding space. This transformation allows each summary to be represented as a vector, which can then be compared against other vectors in terms of cosine similarity or other distance measures."}, {"title": "A.3.3 Cosine Similarity of Embeddings", "content": "To compare the semantic similarity between two summary embeddings, cosine similarity is used. The cosine similarity between two vectors vi and vj, representing summaries Si and Sj, is given by:\nCosine Similarity($v_i, v_j$) = $\\frac{v_i\\cdot v_j}{||v_i||||v_j||}$ (2)\nWhere vi vj represents the dot product of the vectors, and ||vi|| and ||vj|| are the magnitudes (or norms) of the vectors. This similarity measure is particularly useful for clustering, retrieval, and semantic search tasks."}, {"title": "A.3.4 Asynchronous Embedding Generation", "content": "Given the large number of summaries, the embeddings are generated asynchronously to improve performance and scalability. By parallelizing the generation process, we can significantly reduce the processing time, ensuring that embeddings are computed efficiently for each summary.\nThe embedding function is queried asynchronously for each summary, as shown in the following pseudo-code:\nBy leveraging the embeddings, we ensure that each summary is represented in a vector space, allowing for more advanced semantic operations."}, {"title": "A.3.5 Usage of Embeddings", "content": "The generated embeddings are then used for multiple downstream tasks, such as:\n\u2022 Clustering: Grouping similar conversations based on their semantic embeddings.\n\u2022 Retrieval: Efficiently finding summaries that are similar to a given query.\n\u2022 Semantic Search: Searching through conversation summaries based on the semantic content rather than exact matches."}, {"title": "A.4 Semantic Similarity Search with FAISS", "content": "A.4.1 Why FAISS?. FAISS (Facebook AI Similarity Search) was chosen for its ability to perform efficient nearest-neighbor search in high-dimensional vector spaces. Given the large number of summaries and their associated embeddings, FAISS provides a highly scalable solution for searching through these embeddings."}, {"title": "A.4.2 FAISS Workflow", "content": "The FAISS workflow consists of the following steps:\n(1) Initialize a FAISS index with the appropriate dimension size d, where d is the size of the embedding vectors.\n(2) Add the embeddings for each summary to the index.\n(3) Perform nearest-neighbor search queries on the index to find semantically similar summaries.\nThe FAISS index is initialized as:\nFAISS Index = faiss.IndexFlatL2(d) (3)\nWhere d is the dimension of the embedding vectors. The similarity search is then performed by querying the index with the query embedding q.\nDistances, Indices = FAISS Index.search(q, k) (4)\nWhere k is the number of nearest neighbors to retrieve."}, {"title": "A.5 Finding Unique Narrative Network", "content": "Analysis of transcripts revealed that the same narrative, content, or show was often broadcast multiple times on a radio station and across multiple stations, even when the stations appeared independent. An algorithm was developed to identify unique narratives that were shared multiple times and form a network of radio stations for each narrative. MinHash with a similarity threshold of 0.8 was used to check if any two transcripts contained the same content. This process identified approximately 22,000 unique narratives from the dataset. We use only a part of it in WAVEPULSE, where we perform LSH and BFS to find a social network. The narratives from this subsection can help us answer: What is getting amplified in that network?"}, {"title": "A.6 Wave-Pulse.io Frontend", "content": "Wave-Pulse.io is a comprehensive real-time data visualization platform that leverages React for the frontend and Django with PostgreSQL for the backend. The system is designed to create an intuitive and responsive user interface that facilitates data analysis and exploration.\nThe frontend, built with React, establishes communication with the backend through REST API calls, utilizing Axios for data management. To enhance performance and user experience, the frontend implements asynchronous data fetching techniques and employs caching mechanisms.\nThe platform comprises key components, each serving a specific purpose in the data visualization ecosystem:"}, {"title": "A.6.1 Home Page", "content": "The Home Page functions as the central navigation hub for the Wave-Pulse.io application, providing users with access to various features and data visualization options."}, {"title": "A.6.2 Map UI", "content": "The Map UI is built upon the ComposableMap component from 'react-simple-maps', offering users an interactive exploration of the United States map. This visualization includes state boundaries, county outlines, and markers representing population centers and radio station coverage areas.\nTo enhance user interaction and data analysis capabilities, the map interface offers toggles and filters:\nMap level toggle."}, {"title": "A.7 Wave-Pulse.io Backend", "content": "The Django-powered backend is designed to expose APIs that facilitate interaction with the frontend. This backend infrastructure is responsible for processing, aggregating, and formatting data to enable real-time visualizations. The PostgreSQL database underpinning the system is optimized to handle complex queries and store time-series data, ensuring rapid data retrieval and analysis capabilities.\nWave-Pulse.io employs a hosting solution that leverages the strengths of multiple platforms. GitHub Pages is utilized to host the frontend, while the DigitalOcean App Platform is responsible for hosting the backend and PostgreSQL database. This setup ensures efficient resource utilization and cost-effectiveness, while maintaining high performance and scalability."}, {"title": "A.7.1 GitHub Pages Frontend", "content": "GitHub Pages serves as the hosting platform for the frontend, providing key advantages:\nPerformance. GitHub Pages delivers pre-built assets directly to the browser, resulting in fast load times for users. This approach eliminates the need for server-side rendering, enhancing the responsiveness of the application.\nAutomated Deployment. Updates to the frontend trigger automatic deployment processes using GitHub Actions. This automation streamlines the development workflow and ensures that new features and improvements are made available to users.\nAdvantages.\n\u2022 Cost-effectiveness: GitHub Pages offers free hosting for public repositories, reducing operational costs.\n\u2022 Seamless integration: The tight integration with the GitHub ecosystem facilitates a smooth development and deployment process.\n\u2022 Version control: Inherent version control capabilities allow for tracking of changes and rollbacks if necessary."}, {"title": "A.7.2 DigitalOcean Backend", "content": "The DigitalOcean App Platform is employed to handle the Django backend and PostgreSQL database, offering a robust and scalable solution for server-side operations.\nFunctionality. The backend processes incoming requests, manages complex business logic, and interfaces with the database to serve real-time data to the frontend. This setup ensures efficient data management and enables the dynamic features of the Wave-Pulse.io platform.\nAdvantages.\n\u2022 Dynamic resource allocation: DigitalOcean adjusts resource allocation based on the backend's workload, ensuring optimal performance during peak usage periods.\n\u2022 Comprehensive monitoring: Integrated monitoring tools provide real-time insights into system performance, allowing for proactive management and optimization.\n\u2022 Streamlined deployment: Automatic deployment processes are triggered by GitHub pushes, ensuring that the backend remains synchronized with the latest code changes.\n\u2022 Managed database services: DigitalOcean's managed PostgreSQL service reduces the operational overhead of database management while maintaining high availability and performance."}, {"title": "A.8 Extension: Scraping Fact Checks", "content": "The fact-checking program is a system designed for the automated collection, processing, and post-processing of fact-checking articles from various reputable websites. Developed using Python and leveraging the Scrapy framework for web scraping, the system incorporates specialized spiders for specific fact-checking websites, including FactCheck.org, Lead Stories, Politifact, Snopes, and TruthOrFiction. Although we do not use it in WAVEPULSE, matching fact checks from authoritative resources with transcript embeddings can help automate fact-checking."}, {"title": "A.8.1 Websites Overview", "content": "Our team developed a Fact Check Web Crawler capable of scraping fact-checking articles from multiple authoritative websites. The data collection period spans from January 1, 2020, to August 6, 2024, providing a substantial dataset for analysis. To ensure ethical and legal compliance, we reviewed the terms of service for each website prior to data collection."}, {"title": "A.8.2 Scrapy Implementation", "content": "The core of our fact-checking system utilizes Scrapy spiders to scrape fact-checking articles. These spiders are designed with flexibility, supporting various filtering options including date range, keywords, tags, and pagination. This adaptability allows for targeted data collection based on specific research needs.\nPost-crawling, the system employs a data merging process that combines information from all scraped websites into a unified dataset. A key feature of our system is the standardization of fact-checking rulings across different articles, ensuring consistency in our analysis. The merged dataset undergoes a filtering process to isolate political content, enabling focused studies on political misinformation."}, {"title": "A.8.3 Deduplication Process", "content": "To ensure data integrity and prevent redundancy, we implemented a deduplication module. This component is designed to identify and manage duplicate fact-checking articles by conducting analysis of textual content and publication dates.\nThe deduplication process employs natural language processing techniques, including TF-IDF (Term Frequency-Inverse Document Frequency) vectorization. This method transforms the text into a numerical representation, enabling the calculation of cosine similarity between articles. By setting thresholds for similarity and considering publication date proximity, the system clusters and manages duplicate content."}, {"title": "A.8.4 Results Visualization", "content": "To facilitate understanding and analysis of the collected fact-checking data, we developed visualization tools, including word clouds and histograms."}, {"title": "A.9 Extension: Audio Classifier", "content": "As part of our data analysis toolkit, we developed a system for segmenting and classifying speech from audio files. This system leverages the audio processing capabilities of MediaPipe, enabling us to extract and analyze spoken content with accuracy. Although we do not use it in WAVEPULSE, we can use it to separate music from speech content.\nAudio Segmentation. The process begins with the loading of the audio file into our system. Once loaded, the audio data is converted into a numpy array, allowing for manipulation and analysis. The system then employs a segmentation approach, dividing the audio into fixed-length chunks with a specified overlap between consecutive segments. This segmentation is crucial for analyzing smaller portions of the audio stream, enabling us to capture specific speech events with precision.\nThe overlap between segments plays a role in ensuring continuity and preventing the loss of important speech elements that might occur at segment boundaries. For instance, in a scenario with a sample rate of 44.1 kHz, a one-second audio segment would contain 44,100 data points. If we set the segment length to 5 seconds, each segment would encompass 220,500 samples. With an overlap of 2 seconds, each segment would share 88,200 samples with its predecessor, ensuring smooth transitions and coverage.\nMediaPipe AudioClassifier Implementation. Following the segmentation process, each audio chunk is passed through MediaPipe's AudioClassifier. This step begins with the loading of a pre"}]}