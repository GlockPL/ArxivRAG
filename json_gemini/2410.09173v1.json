{"title": "Resource-Constrained Heuristic for Max-SAT", "authors": ["Brian Matejek", "Daniel Elenius", "Cale Gentry", "David Stoker", "Adam Cobb"], "abstract": "We propose a resource-constrained heuristic for instances\nof Max-SAT that iteratively decomposes a larger problem\ninto smaller subcomponents that can be solved by optimized\nsolvers and hardware. The unconstrained outer loop main-\ntains the state space of a given problem and selects a subset\nof the SAT variables for optimization independent of previ-\nous calls. The resource-constrained inner loop maximizes the\nnumber of satisfiable clauses in the \"sub-SAT\" problem. Our\nouter loop is agnostic to the mechanisms of the inner loop, al-\nlowing for the use of traditional solvers for the optimization\nstep. However, we can also transform the selected \"sub-SAT\"\nproblem into a quadratic unconstrained binary optimization\n(QUBO) one and use specialized hardware for optimization.\nIn contrast to existing solutions that convert a SAT instance\ninto a QUBO one before decomposition, we choose a subset\nof the SAT variables before QUBO optimization. We analyze\na set of variable selection methods, including a novel graph-\nbased method that exploits the structure of a given SAT in-\nstance. The number of QUBO variables needed to encode a\n(sub-)SAT problem varies, so we additionally learn a model\nthat predicts the size of sub-SAT problems that will fit a fixed-\nsize QUBO solver. We empirically demonstrate our results\non a set of randomly generated Max-SAT instances as well\nas real world examples from the Max-SAT evaluation bench-\nmarks and outperform existing QUBO decomposer solutions.", "sections": [{"title": "Introduction", "content": "Max-SAT is an NP-Hard optimization problem that asks for\nthe maximum number of satisfiable clauses of a Boolean\nformula written in conjunctive normal form (CNF) (Krentel\n1986). For an N variable problem, this requires searching\nover the space of 2^N possible truth assignments. This gener-\nalization of the satisfiability problem (SAT) has significant\napplications in various sectors (As\u00edn Ach\u00e1 and Nieuwen-\nhuis 2014; Fu and Malik 2006). Although there are a num-\nber of algorithms and commercial tools for exactly solv-\ning Max-SAT (Argelich and Many\u00e0 2006; De Moura and\nBj\u00f8rner 2008; Xing and Zhang 2005), these techniques can-\nnot scale to arbitrarily large problem instances. Therefore,\na significant amount of research has focused on incomplete\n(or anytime) solvers that provide a solution without guar-\nanteeing correctness. These algorithms generally fall into\ntwo categories: local heuristics and global approximation\napproaches. In this paper we focus on a local neighborhood\nsearch heuristic (LNS) that continually optimizes small sub-\nproblems of the full SAT instance.\nWe propose a resource-constrained heuristic for Max-\nSAT problems that operates in a two-tier framework. The\nouter-loop iteratively selects a sub-selection of SAT vari-\nables and extracts a partial CNF formula. An inner-optimizer\nproposes a variable assignment for the sub-problem. A com-\nposer merges this solution with the global one to reduce\nthe energy of the current, global, variable assignment. Our\nmethod is agnostic to the mechanisms of both the selec-\ntor and optimizer, allowing us to use specialized hardware\nas our optimizer. Our approach contrasts with existing so-\nlutions that first reformulate a SAT instance into a QUBO\nproblem before decomposition, optimization, and composi-\ntion. We devise a novel graph-based selection method for\nchoosing small sub-SAT instances. Since our framework is\nagnostic to the inner-optimizer, we show results using exact\nand anytime optimizers. Additionally, we can convert our\nsub-SAT instances into QUBO problems and use existing\nsolvers with constrained, but optimized, hardware. Selecting\nvariables in the SAT space before producing a QUBO out-\nperforms existing strategies that convert a SAT problem into\na QUBO one before decomposition. We demonstrate our re-\nsults on a series of random Max-SAT instances, as well as\nexamples from the Max-SAT 2016 challenge benchmark."}, {"title": "Background and Notation", "content": "A propositional logic formula or Boolean expression in con-\njunctive normal form (CNF) contains a series of L clauses\neach comprised of a (sub)set of N literals. In each clause,\nwe define each variable as either a positive or negative lit-\neral, depending on the inclusion of a negation sign for a\ngiven literal. Each clause is a disjunction of the variables\nand a given formula is a conjunction of all clauses. A CNF\nis satisfiable if some assignment of true or false for each\nvariable satisfies each clause. Max-SAT seeks to find an as-\nsignment that satisfies the maximum number of clauses over\nall possible assignments. For both k-SAT and Max-kSAT the\nproblems constrain the number of variables per clause \u2264 k.\nWe use the following notation for a given Max-SAT instance\nwith N variables and L clauses. Clauses and variables are\nuniquely labeled C1, ..., C1, ..., CL and X1, ..., Xi, ..., XN, re-\nspectively. A clause ci contains k \u2265 1 positive or negative\nliterals Xi, xj, ... with a negation sign, \u00ac, indicating a neg-"}, {"title": "Methodology", "content": "We propose a two component heuristic for optimizing Max-\nSAT instances, where the optimization routine is constrained\nin the number of variables it can handle. In particular, our al-\ngorithm contains an outer-loop and an inner-optimizer. The\ninner-optimizer is constrained by the number of variables\nover which it can operate. Therefore the outer-loop is lim-\nited in the size of the sub-SAT it can pass to the inner-\noptimizer. Note, by maximum sub-SAT size, we constrain\nonly the number of variables sent, M, not the number of\nclauses.\nDuring optimization, we find an assignment that min-\nimizes the number of unsatisfied clauses in the sub-SAT\nproblem, independent of the rest of the full problem space.\nDuring decomposition, we enforce any constraints imposed\nby the inner-optimizer such as QUBO size or sub-SAT size.\nThe outer-loop is agnostic to the internal mechanisms of\nthe inner-optimizer, allowing us to use exact, anytime,\nor QUBO solvers as the inner-optimizer. After the inner-\noptimizer concludes, a composer updates the global solu-\ntion with the optimized variables. We provide pseudocode\nfor various components of our algorithm in the supplemen-\ntary material."}, {"title": "Decomposer", "content": "We propose four different methods for selecting M variables\nfrom a 3-SAT instance: random, energy-based, softmax, and\ngraph-based. In each instance, the method takes as input the\ncurrent state of the Max-SAT problem and the number of\nSAT variables, M, to return.\nRandom Selector. The random selector returns M ran-\ndom SAT variables regardless of the state or structure of the\nCNF instance. This simple selector allows one to explore the\nstate space without existing bias, which can help break out\nof local minima.\nEnergy Selector. The energy-based selector identifies the\nvariables that produce the largest delta between the two\npossible assignments, assuming all other variables remain\nfrozen. That is, we look at the current energy of an as-\nsignment versus the energy when switching each variable\nindependently. We can order these differences to create a\nranking of the variables that would improve the energy the\nmost if switched. We select the M variables that provide\nthe most improvement in energy. These variables, when\nswitched independently, provided the largest increase in sat-\nisfied clauses. Note, the energy selector is similar to the in-\nner loop of GSAT (Selman, Mitchell, and Leveque 1992).\nHowever, as opposed to selecting one variable for flipping,\nwe select M variables for optimization. This is also the ap-\nproach that is used by Qbsolv."}, {"title": "Softmax Selector", "content": "The softmax selector is similar to prior\nwork of Hickey et al. on the Large Neighborhood Search\n(LNS) method (Hickey and Bacchus 2022). The selector\nfirst calculates the potential changes in energy when flip-\nping each variable. We then normalize the potential energy\nchanges into an array e using the softmax function. We then\nsample M variables without replacement according to these\nsoftmax probabilities."}, {"title": "Graph Selector", "content": "Our graph-based selector attempts to ex-\nploit the internal structure of the CNF instance by finding\nsets of clauses that have a high overlap of variables. Further-\nmore, we identify the variable/clause pairs that have a high\ndegree of unsatisfiability (i.e., the unsatisfied clauses in the\ncurrent state). We model any k-SAT instance as a weighted\nbipartite graph (Figure 1). Our graphical model matches\nthe Clause Variable-Incidence Graph common in the liter-\nature (Ans\u00f3tegui, Gir\u00e1ldez-Cru, and Levy 2012), with some\nchanges to the edge weighting scheme.\nWe construct a graph with L + N nodes with one node for\neach clause and variable. We do not differentiate between\npositive and negative literals of the same variable. For every\nvariable xi in clause cj we add an edge between the cor-\nresponding nodes labeled xi and cj. The number of edges\nhas an upper bound of kL, with fewer edges if some clauses\nhave fewer than k literals. For simplicity, we define the set\nof vertices in the graph as V\u2208 v1...vL+N, and the set of\nedges as E \u2208 (vi, vj).\nWe apply weights to the edges based on the state of the\nk-SAT instance. We look at every clause and determine the\nnumber of unsatisfied literals (i.e., a positive literal where\nthe variable is false, or a negative literal where the variable is\ntrue). If there are n unsatisfied literals for a clause ci, we as-\nsign an edge weight of f(n) to all edges adjacent to the node\ncr. f(x) \u2192 R is a real-valued function that takes an integer\nand produces an edge weight. We only consider functions f\nthat are monotonically increasing so that clauses with more\nunsatisfied literals have adjacent edges with higher values.\nAfter graph construction, we run an iterative algorithm to\nfind a subset of variable nodes and clauses that have a high\naverage weighted degree. Our goal is to identify subgraphs\n(clusters of nodes and clauses) where there is a high-level of\noverlap between the nodes in clauses and the clauses are un-\nsatisfiable. We begin by selecting n variable nodes and add\nthem to a set of \"in\" nodes. The \"in\" nodes, and the edges\nthat connect them, will comprise our current subgraph. Note,\nour first subgraph will not contain any edges since we select\nonly variables nodes and our graph is bipartite. We construct\ntwo sets: I and O, representing the nodes that are \"in\" the\ncurrent subgraph and those that are \"out\" of the current sub-\ngraph. A vertex is either in I or O, and I UO = V and\nIn O = 0. For each vertex vi, we define the \u201cconnectivity\u201d\nfunction:\n$$c(v_i) = \\sum_{v_j\\in I, (v_i,v_j)\\in E} w_{ij}$$\n(1)\nThe connectivity function measures the sum of edge weights\nbetween the vertex vi and its neighbors in I.\nDuring each iteration of the algorithm, we select the ver-\ntex vi \u2208 O with the maximum c(vi) value and the vertex\nvj \u2208 I with the minimum c(vj) value. We swap vi and vj\ninto the opposite set and update all c values for the other\nvertices. At the first iteration, we will remove a vertex cor-\nresponding to a variable with one corresponding to a clause.\nHowever, we want to maintain the number of variable ver-\ntices in the set I for our sub-SAT selector. Thus, if the num-\nber of variable nodes ever drops below our target size, we\nadd the variable vertex in O with the highest c value to I.\nConversely, if the number of variable nodes exceeds our tar-\nget size, we remove the variable vertex with the lowest c\nvalue in I."}, {"title": "Clause Pruning", "content": "At this point, we have selected the dynamic (M) and frozen\n(N \u2212 M) variables. Any clause that does not contain any\ndynamic variables can be removed from the sub-SAT in-\nstance since its state cannot change. Furthermore, since the\nassignment of the frozen variables cannot change in the\ninner-optimizer, certain clauses may remain satisfied de-\nspite changes to the dynamic variables. For example, if cl\nis xi \u2228 \u00acXjVXk, and xj is frozen as false, ci will remain\nsatisfied regardless of changes to xi and xk. Therefore, we\ncan exclude this clause from the inner loop. We can also\nuse the frozen variables to reduce the number of literals per\nclause, which is significant when we introduce inner QUBO\noptimizers, since clauses with k \u2264 2 can be directly rep-\nresented in QUBO problems without the need for additional\nvariables. This is a significant strength of our approach when\nreducing to QUBO after the decomposer."}, {"title": "Inner-Optimizer", "content": "The outer-loop mechanism for selecting a subset of SAT\nvariables is only constrained by the number of variables that\ncan be operated on by the inner-optimizer. For this work, we\nhave focused on three inner-optimizer algorithms, including\ntraditional SAT solvers and QUBO optimizers. The QUBO\noptimizers come with the additional challenge of the trans-\nlation to QUBO. Therefore, for QUBO, the constraint on\nthe number of variables corresponds to the QUBO size Q,\nwhich presents itself as a challenge, since the decomposer\nprovides an M. We overcome this using a cheap linear re-\ngression model in a novel way.\nSAT Solvers. We use two optimizers in this work: z3, an\nexact solver (De Moura and Bj\u00f8rner 2008), and Walk-SAT,\na local heuristic (Selman, Kautz, and Cohen 1993)."}, {"title": "QUBO Optimizers", "content": "The motivation for converting to\nQUBO problems comes from significant research focused\non specialized hardware specifically designed to QUBO\nproblems (Booth, Reinhardt, and Roy 2017; Date et al. 2019;\nKalinin et al. 2023). Such hardware comes with physical\nconstraints on the number of variables can fit on the hard-\nware. However, their performance power can still be lever-\naged if we can ensure the problems are small enough. The\nchallenge of incorporating a QUBO optimizer within our op-\ntimization loop comes from the need to translate from the M\nvariable sub-SAT problem to a Q variable QUBO problem.\nThe direct mapping from a 3-SAT problem formulation to\na QUBO problem uses the following construction to define\nthe energy \u0424(x):\n$$\\sum_{i=1}^{L}(X_{i1}+X_{i2}+X_{i3} - X_{i1}X_{i2} - X_{i1}X_{i3} - X_{i2}X_{i3}+X_{i1}X_{i2}X_{i3})$$\nwhere L is the number of clauses. This pseudo-Boolean\nfunction contains a cubic term that we can remove by\nadding an extra variable wi \u2208 {0,1} per clause such that\nXi1Xi2Xi3 = maxwi Wi (Xi1 + Xi2 + Xi3 \u2212 2). Thus, we de-\nfine the energy \u0424(x):\n$$\\sum_{i=1}^{L}(1+W_i)(X_{i1}+X_{i2}+X_{i3})-X_{i1}X_{i2}-X_{i1}X_{i3}-X_{i2}X_{i3}-2W_i$$\nIf Xi1, Xi2, and 213 all evaluate to true, w\u2081 = 1; if two of the\nthree literals evaluate to true, wi can be 0 or 1; if one of the\nthree literals evaluate to true, w\u2081 = 0; if none of the literals\nevaluate to true, w\u2081 = 0. One can check that the expres-\nsion for each clause thus evaluates to 1 if the clause is satis-\nfied, and 0 otherwise. As a result, an N variable, L clause 3-\nSAT problem would generate a QUBO problem with N + L\nvariables QUBO problem using this default formulation. For\nconverting clauses with k < 3, we can remove the auxiliary\ncubic terms. For clauses with k > 3, we can first convert to\n3-SAT before QUBO conversion.\nA significant amount of optimization has focused on re-\nducing the number of auxilary variables needed when con-\nverting a SAT problem into a QUBO one (Zaman, Tana-\nhashi, and Tanaka 2021), and the methods for generating\nthose variables (N\u00fc\u00dflein et al. 2023; Chancellor et al. 2016).\nFor our work, we focus on methods from Chancellor et\nal. (Chancellor et al. 2016) and N\u00fc\u00dflein et al. (N\u00fc\u00dflein et al.\n2023). Since we call the QUBO conversion method for each\niteration of the outer-loop, we prioritized speed over a reduc-\ntion in auxiliary variables. This speed tradeoff is less critical\nin existing strategies that convert a full SAT instance into a\nQUBO formulation exactly once."}, {"title": "Learned Variable Mapping", "content": "Going back to the challenge\nof translating from the M variable sub-SAT problem to the\nQ variable QUBO problem, we need a way to impose the\nQ constraint on the outer-loop. Our interesting solution is to\nuse a simple linear regression model that takes five inputs to\ngenerate a candidate M. These inputs include the final max-\nimum QUBO size, Q, the maximum number of literals in\nany clause, the total number of literals in the CNF, N, and\nL. To account for when the linear regression model predicts\nan M that leads to a Q too large for the optimizer, we in-\nclude a binary search as a backup. Therefore, we perform a\nbinary search as well to identify the optimal number of SAT\nvariables M given the QUBO matrix constraint Q. We first\nuse our learned predictor to determine a preliminary M. If\nconverting the returned sub-SAT instance results in a QUBO\nmatrix that exceeds the hardware constraints, we perform a\nbinary search to identify the optimal M* that produces a\nQUBO matrix within the hardware constraints. If we could\nhave fit a larger QUBO matrix on the hardware, we increase\nthe value of M for the next call to the optimizer. If we ex-\nceed the value of Q, we reduce the value of M before calling\nthe inner-optimizer. The function from M \u2192 Q is stochastic\nand depends on the variables returned by the selector. Thus,\nwe continually check to confirm that the QUBO produced\nwith a sub-SAT selection of M variables fit within the con-\nstraints of the optimizer."}, {"title": "Tabu Search", "content": "The specific algorithm that we use to op-\ntimize the QUBO problems in this paper is Tabu search\n(Palubeckis 2004). Tabu search iteratively chooses variables\nto flip. Once the algorithm chooses a variable for flipping,\nit stores the variable for a set number of iterations in the\ntabu list. Variables on this list cannot change for a set num-\nber of iterations. There are many variants of Tabu search;\nfor our work we use the implementation provided by D-\nWave's Qbsolv (Booth, Reinhardt, and Roy 2017). Finally,\nwe convert from the solution in the QUBO space to the SAT\nspace."}, {"title": "Composer", "content": "During the composition step, we update the assignment of\nthe dynamic variables based on the output from our inner-\noptimizer. By decoupling the sub-SAT selection method\nfrom the solver, we avoid the issues with rectifying multi-\nple disjoint solutions into a coherent best choice."}, {"title": "Early Stopping", "content": "After each iteration of the outer-loop, we calculate the en-\nergy of the current state of the solution. If the energy doesn't\nimprove after conv number of iterations, we terminate the\nprocess. Otherwise, we terminate after max_iters number\nof calls to the inner-optimizer. We find that some selectors,\nsuch as Energy and Softmax, require fewer iterations to con-\nverge to a local minima. Other selectors, such as the Ran-\ndom and Graph approaches, generally reach better minima\nbut only after more iterations."}, {"title": "Experimental Setup", "content": "Datasets. We demonstrate our results on a range of SAT\ninstances. We make our data and code publicly available.\u00b9\nWe construct a set of random datasets with 100, 200, and\n500 variables and clause to variable ratios of 4.00, 4.25, and\n4.50. These three ratios correspond to satisfiable, a mix, and\nunsatisfiable random instances. We use the randkenf for-\nmula from the CNFgen toolkit to generate these random 3-\nSAT instances (Lauria et al. 2017). We consider a subse-"}, {"title": "Conclusions", "content": "We propose a resource-constrained heuristic for Max-SAT\nproblems that decomposes the problem in the SAT space\nbefore calling a optimized solver. We decouple the prob-\nlem partitioning and sub-problem solving to enable greater\nflexibility. We contrast with existing solutions that first re-\nformulate a SAT instance into a QUBO problem before the\ndecomposition step. We outperform such existing strategies\non randomly generated instances of various variable and\nclause size. Our method enables us to make sure of spe-\ncialized hardware, such as quantum annealers, that offer sig-\nnificant throughput when presented with small QUBO in-\nstances. We demonstrate our results on a thousands of ran-\ndom and crafted Max-SAT instances."}]}