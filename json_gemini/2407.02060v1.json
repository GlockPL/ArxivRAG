{"title": "Terminating Differentiable Tree Experts", "authors": ["Jonathan Thomm", "Michael Hersche", "Giacomo Camposampiero", "Aleksandar Terzi\u0107", "Bernhard Sch\u00f6lkopf", "Abbas Rahimi"], "abstract": "We advance the recently proposed neuro-symbolic Differentiable Tree Machine, which learns tree operations using a combination of transformers and Tensor Product Representations. We investigate the architecture and propose two key components. We first remove a series of different transformer layers that are used in every step by introducing a mixture of experts. This results in a Differentiable Tree Experts model with a constant number of parameters for any arbitrary number of steps in the computation, compared to the previous method in the Differentiable Tree Machine with a linear growth. Given this flexibility in the number of steps, we additionally propose a new termination algorithm to provide the model the power to choose how many steps to make automatically. The resulting Terminating Differentiable Tree Experts model sluggishly learns to predict the number of steps without an oracle. It can do so while maintaining the learning capabilities of the model, converging to the optimal amount of steps.", "sections": [{"title": "1 Introduction", "content": "Neuro-symbolic AI aims to combine the strengths of statistical AI, like machine learning, with the capabilities of symbolic AI, to address the weaknesses of each. Recent neuro-symbolic AI methods exhibit notable benefits from a tight integration of low-level statistical perception and high-level reasoning, e.g., in various tasks demanding out-of-distribution (OOD) generalization [1,2,3,4,5,6,7]. However, compared to pure neural approaches, neuro-symbolic AI suffers from the non-differentiability of inherently discrete symbolic operations, unlike real numerical values, which makes them incompatible with gradient-based learning methods. One solution can be reinforcement learning-based learning approaches; however, they suffer from ill-defined gradients [8]. Another solution is to use a fully symbolic search. For instance, DreamCoder [9] builds an increasing library"}, {"title": "2 Background", "content": "In this section, we briefly introduce Tensor Product Representations (TPRs) and the architecture of DTM."}, {"title": "2.1 Tensor Product Representations", "content": "Tensor Product Representation (TPR) provides a general encoding of structured symbolic objects in vector space. A TPR consists of roles and fillers [11]. While fillers describe the data, the roles define its context, and therefore, the TPR allows for a compositional symbolic representation via distributed vectors and tensors.\nTo represent a symbolic object, one computes the outer product (\u2297) of the filler (f) and the role (r) vectors, resulting in a matrix $M = f \\otimes r = fr^T$. A set of N symbolic objects is represented by the superposition of the role-filler products:\n\n$T = \\sum_{n=1}^{N} f_n \\otimes r_n.$\n(1)"}, {"title": "2.2 Differentiable Tree Machine", "content": "The Differentiable Tree Machine (DTM) [20] manipulates TPR-based tree representations using three Lisp operations: CAR, CDR, and CONS. Given a tree (T), Lisp CAR extracts the subtree that is the left child of the root by CAR(T) = $D_0T$. Here, $D_0 = I \\otimes \\sum_x r_x r_x^T$ is a linear operator that shifts all roles from the left subtree up to the root by one level, and I corresponds to the identity matrix on the filler space. Applying Lisp CAR to the example tree in Fig. 1 would yield $T_0$ = CAR(T) = $f_{some} r_0$. Lisp CDR extracts the right child by CDR(T) = $D_1T$, where $D_1 = I \\otimes \\sum_x r_x r_x^T$ is the linear operator that shifts all roles from the right subtree up to the root. Finally, the CONS operation takes two trees ($T_0$ and $T_1$) as arguments plus a new root node (s) and assembles a new tree by CONS($T_0$, $T_1$, s) = $E_0T_0 + E_1T_1 + s \\otimes r_{root}$. The linear operators $E_0 = I \\otimes \\sum_x r_0 z_x^T$ and $E_1 = I \\otimes \\sum_x r_1 z_x^T$ shift all roles to the left and right subtrees down to the leaves, respectively.\nDTM generates a sequence of trees ($T^{(0)}$, $T^{(1)}$, ..., $T^{(L)}$), where the initial tree ($T^{(0)}$) is the source tree, and the final tree ($T^{(L)}$) is the target tree (i.e., the result of the task). DTM computes the tree at step t as a convex combina- tion of the results provided by the three Lisp operations, which creates a TPR representation of a new tree superposition:\n\n$T^{(t+1)} = w_{CAR}CAR(T_{CAR}^{(t)}) + w_{CDR}CDR(T_{CDR}^{(t)}) + w_{CONS}CONS(T_{CONS, 0}^{(t)}, T_{CONS, 1}^{(t)}, s^{(t)})$.\n\nA transformer encoder layer (with the standard quadratic attention) predicts the weights ($w_{CAR}$, $w_{CDR}$, $w_{CONS}$) for the three Lisp operations, and their arguments ($T_{CAR}^{(t)}$, $T_{CDR}^{(t)}$, $T_{CONS, 0}^{(t)}$, $T_{CONS, 1}^{(t)}$, $s^{(t)}$). Given a list of previously generated trees plus the input tree, each tree is encoded as one token by encoding the tree TPR representation to a dense vector using a deep learning encoder [26]. Each tree argument for the next Lisp operation is computed as a weighted sum of all past trees, e.g.,\n$T_{CAR}^{(t)} = \\sum_{i=0}^{t-1} \\alpha_{CAR}^i T^{(i)}$"}, {"title": "3 Terminating Differentiable Tree Experts", "content": ""}, {"title": "3.1 Differentiable Tree Experts", "content": "This section presents the main contribution of our paper: Differentiable Tree Experts (DTE). Instead of learning a different transformer encoder in each step for DTM, one could share the weights. However, according to our experiments, using the same transformer encoder layer leads to a non-converging DTM. We, therefore, propose integrating a Mixture of Experts in the DTM architecture, which enables convergence again despite the weight sharing between each step. This means that in every step, the same router in DTE weights several experts (in our experiments, 16 experts) that then give proposals for the operation and the arguments. Those predictions are weighted, and then the DTE execution takes place.\nIn our router, a transformer encoder layer encodes all current trees. The current step is encoded as a sinusoidal positional encoding [27]. From the concatenation of the tree encoding and the step encoding, the router probabilities are computed with a linear map."}, {"title": "3.2 Sluggish Termination", "content": "Several termination heuristics have been proposed in the literature [28,29]. For this work, we found termination inspired by speculative execution to work best for our Terminating DTE (TDTE). In general, the training convergence of DTE is brittle, as also observed with the DTM. In particular, changing the termination decision too often caused the model to not converge anymore. We, therefore, use two termination predictors. One predictor follows the other as soon as it is confident. This way, changes in the termination are only made if a certain confidence is reached.\nLet us denote $i_{damp} := argmax_s (P_{damp}(s))$, $i_{expl} := argmax_s (P_{expl}(s))$ the predictions of the two predictors, and $p(i_{damp})$, $p(i_{expl})$ the probabilities of the predictors at those indices. The probabilities over all steps sum up to 1 for each predictor. We define the loss label (i.e., the target step) of the two termination predictors as:\n\n$i_{expl}$ if $p(i_{expl}) \\geq 0.8$\n$Y_{damp} = $\n$i_{damp}$ otherwise\n(2)\n\n$\\underset{s \\in S}{argmax} (loss(s) * 0.9^{idx(s)})$ if $p(i_{damp}) \\geq 0.8 / i_{damp} = i_{expl}$\n$Y_{expl} = $\n$i_{expl}$ otherwise\n(3)\n\nAs shown in Equations (2) and (3), we use a confidence threshold of 0.8 which was determined by a grid search based on the training convergence. S denotes the local set of choices around the current prediction, i.e. S = {$i_{damp}$ \u2013 4, $i_{damp}$, $i_{damp}$ + 5} and idx($i_{damp}$ \u2013 4) = 0, idx($i_{damp}$) = 1, idx($i_{damp}$ + 5) = 2. The choices in S are hyperparameters that worked well in practice.\nWe learn one termination for the DTM on each task. Each predictor consists of a series of constant parameters, one for each potential step, which is enough for the datasets investigated here and in the datasets used in [20]. By scaling the termination parameters (and initializing them to small values) by a large factor, one can make sure that the gradient updates are high enough for those single values. The method can also be applied to sample-wise predictors from the main model, which remains to be explored in future work.\nTo compute which of the three considered termination steps is the best (see Equation 3 top case), we calculate the loss at each of the three steps and deduct a small multiplicative factor for later termination. This way the model will choose to terminate earlier if iterating longer does not bring significant improvements. We use cross-entropy loss to train the predictors, which are single numbers for"}, {"title": "4 Experiments", "content": "We evaluate our Differentiable Tree Experts (DTE) and the Terminating DTE (TDTE) on the same set of four tasks used for the evaluation of DTM [20]. Fig. 4 visualizes examples of these tasks. The first task, CAR-CDR-SEQ, encodes left-subtree and right-subtree Lisp operations in the root node of the input tree. Those should be executed, and the resulting sub-tree is the answer. The task ACTIVE\u2194LOGICAL task contains sentence grammar trees in either active or logical form; the task is to transform the tree into the other grammatical form. The PASSIVE\u2194LOGICAL task is analogous, having a sentence grammar in passive form instead of active. Finally, the ACTIVE&PASSIVE\u2194LOGICAL task contains either active or passive sentence grammar trees and the target is the logical form. All tasks come with an ID test set and two OOD test sets. The lexical OOD set contains trees with adjectives never seen on the leaves. The structural OOD test set contains trees where additional adjectives are added.\nWhile DTM and DTE use the same hidden dimension in the transformer encoder layers (64), we observe that TDTE requires a larger one (256) in order to obtain performance competitive with DTM and DTE. For the Mixture of Experts"}, {"title": "4.1 Ablation: Sparse Mixture of Experts", "content": "One can further reduce the computational amount required for the DTE during training and inference by introducing sparsity in the selection of experts. To this end, we always select only the top four experts and normalize the corresponding selection weights using the softmax function."}, {"title": "4.2 New Task: Tree Reversal", "content": "This section evaluates DTM and TDTE on a new tree reversal task. The model gets a tree and has to reverse it exactly. This means that every inner node that has two children has to be extracted and reversed. Because the trees sometimes differ and subtrees to a higher depth have to be extracted, this task is more challenging. Especially the structural OOD now requires more and different opera- tions. The input trees are the same as the input trees of the ACTIVE\u2194LOGICAL task. See Fig. 5 for a visualization with 28 steps.\nAs shown in Table 3, the models are able to learn tree reversals partially, which is a good sign, since the model needs to choose different Lisp operations for"}, {"title": "5 Discussion", "content": "DTM is a neuro-symbolic method for solving tree-to-tree transformation tasks, effectively combining a neural controller (i.e., a transformer) with a symbolic manipulator (TPR). The TPR engine performs symbolic manipulations in a continuous vector space, which allows a convex combination of different discrete operations (i.e., CAR, CDR, and CONS) and their operators (i.e., weighted su- perposition of past trees). This yields a fully differentiable neuro-symbolic archi- tecture that can be trained end-to-end, without requiring reinforcement learning techniques. We further enhanced DTM by introducing a mixture of experts and a novel automatic termination method, which reduces both the number of pa- rameters and the required knowledge about the number of steps.\nBoth the DTM and TDTE still face some inherent limitations, which we elaborate on in this section. Future work addressing the following limitations would notably enhance the DTM/TDTE approach."}, {"title": "5.1 Limited Lisp operations", "content": "DTM and TDTE models focus on binary tree-to-tree transformation tasks that can be solved with a limited subset of Lisp operations (CAR, CDR, and CONS). We have seen that the tasks presented in [20] can be solved with a relatively low number of sequential operations. By introducing the novel tree reversal task, however, we could show that DTE can indeed learn to execute longer sequences of the three operations.\nDistributed representations are not restricted to the three Lisp operations. For example, leveraging fractional power encoding (FPE) [13] would allow one to perform arithmetic operations. In fact, FPE has been applied in probabilis- tic abductive reasoning to solve Raven's progressive tests [6]. Representing both logical and arithmetic rules with distributed representations yielded a differen- tiable and fast symbolic engine, which can even learn the underlying rules [30]. Using FPE to support arithmetic operations in DTM or TDTE would further enrich the architectures and is an interesting avenue for future work."}, {"title": "5.2 OOD generalization", "content": "Our novel tree reversal task reveals an important limitation of the DTM and TDTE models in OOD generalization, showing that when the data does not fit the strong inductive biases of Lisp operations, the models do not seem to generalize well. The three Lisp operations have strong inductive biases to allow certain tasks to be done in very few steps. However, other tasks, such as tree reversal, require many steps. The fixation on the Lisp operations, therefore, is a limitation for other tree-to-tree tasks than the tasks evaluated in the previous sections.\nFurther, the tree-to-tree tasks evaluated in the original paper [20] require mostly the same sequence of the three Lisp operations for all samples including the OOD test sets. This allows DTM to generalize very well\u2014the model is in- variant to the OOD variants tested, rather than generally having excellent OOD capabilities. For ACTIVE\u2194LOGICAL and PASSIVE\u2194LOGICAL, the model only has to detect if the input is a sentence tree in active or in logical form, which is possible by simply looking at the children of the root node. These nodes are"}, {"title": "5.3 Training stability", "content": "Although the model combines deep learning and TPR successfully, the brittle training convergence is still a limitation. Removing this issue would be critical to allow the broader applicability of these hybrid models. The dependence on the initialization suggests that the optimization landscape is very non-convex or that the correct gradients are vanishing. Given the nature of the model, which linearly superposes all operations, the latter seems especially plausible. Investigating this problem and potentially finding improved optimizers or in-model solutions would make the applications of deep learning combined with TPR much more attractive to a broader audience. To avoid vanishing gradients, one could also introduce a hybrid optimization including elements to limit the number of superpositions and, therefore, strengthen the remaining ones."}, {"title": "6 Conclusion", "content": "We have introduced Terminating Differentiable Tree Experts (TDTE) which enhances the recently proposed DTM architecture. Our improvements allow the model to scale constantly when the depth of computation increases. Based on this, we are further able to introduce a new halting mechanism that changes its decisions slowly and looks ahead multiple steps to be more precise and have less impact on the model performance. This method makes it possible to learn the right termination without having access to an oracle termination information within the training data (which is usually not given)."}]}