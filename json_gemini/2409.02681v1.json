{"title": "REDES NEURAIS COM LSTM E GRU NA MODELAGEM DE FOCOS ATIVOS NA AMAZ\u00d4NIA", "authors": ["Ramon Lima de Oliveira Tavares"], "abstract": "This study presents a comprehensive methodology for modeling and forecasting the historical time series of fire spots detected by the AQUA_M-T satellite in the Amazon, Brazil. The approach utilizes a mixed Recurrent Neural Network (RNN) model, combining Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures to predict monthly accumulations of daily detected fire spots. A summary of the data revealed a consistent seasonality over time, with annual maximum and minimum fire spot values tending to repeat at the same periods each year. The primary objective is to verify whether the forecasts capture this inherent seasonality through rigorous statistical analysis. The methodology involved careful data preparation, model configuration, and training using cross-validation with two seeds, ensuring that the data generalizes well to the test and validation sets, and confirming the convergence of the model parameters. The results indicate that the mixed LSTM and GRU model offers improved accuracy in forecasting 12 months ahead, demonstrating its effectiveness in capturing complex temporal patterns and modeling the observed time series. This research significantly contributes to the application of deep learning techniques in environmental monitoring, specifically in fire spot forecasting. In addition to improving forecast accuracy, the proposed approach highlights the potential for adaptation to other time series forecasting challenges, opening new avenues for research and development in machine learning and natural phenomenon prediction.", "sections": [{"title": "1 Introdu\u00e7\u00e3o", "content": "S\u00e9ries temporais s\u00e3o amplamente utilizadas em diversas \u00e1reas, como economia, climatologia, e monitoramento ambiental, e contam com grandes refer\u00eancias como Box e Jenkins (1976) [1], Hamilton (1994) [13], e Brockwell e Davis (2002) [2]. De maneira geral, uma s\u00e9rie temporal pode ser definida como um conjunto de informa\u00e7\u00f5es fixadas no tempo e/ou no espa\u00e7o de forma padronizada ou n\u00e3o. Quando tratamos de s\u00e9ries temporais de dados quantitativos discretos, onde o tempo \u00e9 o principal fator de interesse, podemos entender essa s\u00e9rie como um conjunto de observa\u00e7\u00f5es que representam quantidades espec\u00edficas, registradas ao longo do tempo. No contexto deste trabalho, focamos na s\u00e9rie temporal dos focos ativos detectados pelo sat\u00e9lite AQUA_M-T na Amaz\u00f4nia, Brasil. Os focos ativos s\u00e3o detectados com base em anomalias de temperatura em pixels observados pelo sat\u00e9lite. Quando a temperatura de um pixel atinge n\u00edveis significativamente elevados, como, por exemplo, acima de 47\u00b0C \u2014 valor que, segundo o Sistema Estadual de Informa\u00e7\u00f5es Ambientais e Recursos H\u00eddricos (SEIA, 2024) [20], caracteriza um foco de calor o sat\u00e9lite registra a ocorr\u00eancia de um foco ativo. Por exemplo, se mil focos ativos foram detectados em um determinado m\u00eas, isso significa que mil metros quadrados na regi\u00e3o amaz\u00f4nica apresentaram temperaturas acima de 47\u00b0C. Esses dados, disponibilizados mensalmente pelo Instituto Nacional de Pesquisas Espaciais (INPE), oferecem uma vis\u00e3o hist\u00f3rica importante, embora seja sabido que os sat\u00e9lites como o AQUA_M-T possuem limita\u00e7\u00f5es em termos de precis\u00e3o, devido \u00e0 sua idade e tecnologia. Entretanto, mesmo com essas limita\u00e7\u00f5es, os dados s\u00e3o valiosos para a identifica\u00e7\u00e3o de padr\u00f5es sazonais e anomalias ao longo dos anos. Futuramente, espera-se que esses dados sejam atualizados com a entrada em"}, {"title": "2 Referencial Te\u00f3rico", "content": "De acordo com Graves et al. (2013) [11], as Redes Neurais Recorrentes Recurrent Neural Networks (RNNs) s\u00e3o modelos poderosos para dados sequenciais. Elas s\u00e3o capazes de lidar com problemas de rotulagem de sequ\u00eancias onde o alinhamento entre entrada e sa\u00edda \u00e9 desconhecido. Esses modelos s\u00e3o constru\u00eddos para aprender depend\u00eancias temporais em dados sequenciais e mant\u00eam uma mem\u00f3ria interna para processar informa\u00e7\u00f5es anteriores."}, {"title": "2.1 Unidade RNN", "content": "Dada uma sequ\u00eancia de entrada (xt, Xt+1, Xt+2,..., Xt+n), uma Rede Neural Recorrente padr\u00e3o computa a sequ\u00eancia de vetores ocultos (ht\u22121, ht, ht+1, ht+2,..., ht+n) e a sequ\u00eancia de vetores de sa\u00edda (yt, Yt+1, Yt+2,\u00b7\u00b7\u00b7, Yt+n).\n$h_t = A(W_{hh}h_{t-1} + W_{xh}x_t + b_h),$ (1)\n$y_t = (W_{yi} h_t + b_y),$ (2)\nem que W \u00e9 a matriz de pesos e b\u00e9o vi\u00e9s, e o operador representa a multiplica\u00e7\u00e3o elemento a elemento; o estado de sa\u00edda yt gerado no tempo t\u00e9 determinado pela informa\u00e7\u00e3o de entrada xt e pelo estado oculto anterior ht\u22121 no tempo t-1.\nA Equa\u00e7\u00e3o (1) mostra como o estado oculto atual h\u2081 \u00e9 calculado usando uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o (A), pesos (Whh) e vi\u00e9s (bh) correspondentes. Esse modelo de unidade de Redes Neurais Recorrentes \u00e9 fundamental para compreender a propaga\u00e7\u00e3o de informa\u00e7\u00f5es ao longo do tempo em uma Rede Neural Recorrente. A estrutura interna da unidade RNN \u00e9 exibida na Figura 1."}, {"title": "2.2 Unidade LSTM", "content": "No artigo Speech Recognition with Deep Recurrent Neural Networks Graves et al. (2013) [11], os autores enfatizam que a arquitetura das Redes de Mem\u00f3ria de Longo e Curto Prazo (Long Short-Term Memory, LSTM) \u00e9 particularmente eficaz"}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "para tarefas que requerem o processamento de sequ\u00eancias temporais longas. As LSTMs se destacam pela capacidade de superar as limita\u00e7\u00f5es das Redes Neurais Recorrentes (RNNs) tradicionais, permitindo que informa\u00e7\u00f5es relevantes sejam retidas por per\u00edodos mais prolongados. Isso \u00e9 primordial para lidar com depend\u00eancias temporais extensas. Enquanto as RNNs funcionam em sequ\u00eancias temporais mantendo uma mem\u00f3ria interna, as LSTMs aprimoram essa capacidade ao utilizar gates \u201cport\u00f5es\u201d para controlar o fluxo de informa\u00e7\u00f5es. Esses port\u00f5es facilitam uma reten\u00e7\u00e3o mais eficaz das informa\u00e7\u00f5es a longo prazo, comparado \u00e0s RNNs tradicionais, que enfrentam dificuldades em manter depend\u00eancias temporais mais longas. Dessa forma, as LSTMs demonstram uma capacidade superior de generaliza\u00e7\u00e3o e previs\u00e3o quando confrontadas com dados de entrada que se estendem por longos per\u00edodos de tempo.\nA arquitetura Long Short-Term Memory (LSTM), conforme descrito por Greff et al. (2017) [12], \u00e9 projetada para lidar com as limita\u00e7\u00f5es das Redes Neurais Recorrentes tradicionais em tarefas de aprendizado de sequ\u00eancias temporais. O bloco LSTM \u00e9 composto por tr\u00eas componentes principais:\n\u2022 Port\u00e3o de Entrada: Este port\u00e3o regula a quantidade de nova informa\u00e7\u00e3o que ser\u00e1 incorporada na c\u00e9lula de mem\u00f3ria. Ele determina quais informa\u00e7\u00f5es devem ser adicionadas ao estado da c\u00e9lula.\n\u2022 Port\u00e3o de Esquecimento: Este port\u00e3o decide quais informa\u00e7\u00f5es presentes na c\u00e9lula de mem\u00f3ria devem ser descartadas. Ele ajuda a manter a relev\u00e2ncia dos dados ao longo do tempo, removendo informa\u00e7\u00f5es que n\u00e3o s\u00e3o mais necess\u00e1rias.\n\u2022 Port\u00e3o de Sa\u00edda: Este port\u00e3o controla a quantidade de informa\u00e7\u00e3o da c\u00e9lula de mem\u00f3ria que ser\u00e1 utilizada na sa\u00edda do bloco LSTM. Ele decide quais informa\u00e7\u00f5es da c\u00e9lula de mem\u00f3ria ser\u00e3o passadas para a pr\u00f3xima etapa na sequ\u00eancia.\nEsses port\u00f5es s\u00e3o respons\u00e1veis por regular o fluxo de informa\u00e7\u00f5es dentro do bloco LSTM, permitindo a reten\u00e7\u00e3o e atualiza\u00e7\u00e3o eficaz de dados relevantes por longos per\u00edodos. A estrutura interna do LSTM permite que o modelo capture depend\u00eancias temporais extensas e mantenha a precis\u00e3o em tarefas que envolvem sequ\u00eancias longas e complexas.\nSeja x\u0165 o vetor de entrada no tempo t, N o n\u00famero de unidades LSTM na camada e M o n\u00famero de entradas (aqui NX M representa a dimens\u00e3o da matriz de pesos). Ent\u00e3o, obtemos os seguintes pesos para uma camada LSTM:\n\u2022 Pesos de entrada: $W_z, W_i, W_f, W_o \\in R^{N\\times M}$;\n\u2022 Pesos recorrentes: $R_z, R_i, R_f, R_o \\in R^{N\\times N}$;\n\u2022 Pesos de vi\u00e9s: $b_z, b_i, b_f, b_o \\in R^{N}$.\nEnt\u00e3o, de acordo com Greff et al. (2017) [12], as f\u00f3rmulas vetoriais para uma passagem direta em uma camada LSTM podem ser escritas como:\n$z_t = W_z x_t + R_z y_{t-1} + b_z,$ (3)\n$z_t = g(z_t) \\quad \\text{entrada do bloco};$\n$i_t = W_i x_t + R_i y_{t-1} + b_i,$ (4)\n$i_t = \\sigma(i_t) \\quad \\text{porta de entrada};$\n$f_t = W_f x_t + R_f y_{t-1} + b_f,$ (5)\n$f_t = \\sigma(f_t) \\quad \\text{porta de esquecimento};$\n$c_t = z_t \\odot i_t + c_{t-1} \\odot f_t \\quad \\text{c\u00e9lula};$ (6)\n$\\bar{o}_t = W_o x_t + R_o y_{t-1} + b_o,$ (7)\n$o_t = \\sigma(\\bar{o}_t) \\quad \\text{porta de sa\u00edda};$\n$y_t = h(c_t) \\odot o_t \\quad \\text{sa\u00edda do bloco}.$ (8)\nEm que o, g e h s\u00e3o fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares ponto a ponto. A fun\u00e7\u00e3o sigmoide ($\\sigma(x) = \\frac{1}{1+e^{-x}}$) \u00e9 usada como fun\u00e7\u00e3o de ativa\u00e7\u00e3o da porta, e a tangente hiperb\u00f3lica (g(x) = h(x) = tanh(x)) \u00e9 comumente usada como fun\u00e7\u00e3o de ativa\u00e7\u00e3o de entrada e sa\u00edda do bloco. A multiplica\u00e7\u00e3o ponto a ponto de dois vetores \u00e9 denotada por."}, {"title": "2.3 Unidade Recorrente com Portas GRU", "content": "As Unidades Recorrentes com Portas Gated Recurrent Units (GRU), introduzidas por Chung et al. (2014) [6], s\u00e3o uma varia\u00e7\u00e3o das LSTM. Enquanto as LSTM possuem tr\u00eas port\u00f5es e uma c\u00e9lula de mem\u00f3ria, as GRU simplificam essa estrutura ao fundir os port\u00f5es de entrada e esquecimento em um \u00fanico port\u00e3o de atualiza\u00e7\u00e3o. Essa simplifica\u00e7\u00e3o tem como objetivo tornar o treinamento mais eficiente e reduzir o n\u00famero de par\u00e2metros, mantendo um desempenho compar\u00e1vel \u00e0s LSTM.\nAs f\u00f3rmulas vetoriais para uma passagem direta em uma camada GRU foram encontradas no artigo de Cheng et al. (2024) [4] de uma forma mais simplista que s\u00e3o:\n$z_t = W_z x_t + R_z y_{t-1} + b_z,$ (9)\n$z_t = \\sigma(z_t) \\quad \\text{port\u00e3o de atualiza\u00e7\u00e3o};$\n$r_t = W_r x_t + R_r y_{t-1} + b_r,$ (10)\n$r_t = \\sigma(r_t) \\quad \\text{port\u00e3o de reset};$\n$\\bar{h}_t = W_h x_t + R_h (r_t \\odot y_{t-1}) + b_h,$ (11)\n$h_t = z_t \\odot y_{t-1} + (1 - z_t) \\odot \\bar{h}_t \\quad \\text{estado oculto},$\nem que W s\u00e3o matrizes de pesos; b s\u00e3o vetores de vi\u00e9s; o \u00e9 a fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoide e o denota a multiplica\u00e7\u00e3o ponto a ponto."}, {"title": "2.4 Fun\u00e7\u00f5es de Ativa\u00e7\u00e3o", "content": "As fun\u00e7\u00f5es de ativa\u00e7\u00e3o s\u00e3o componentes fundamentais em redes neurais, respons\u00e1veis por introduzir n\u00e3o-linearidades nas sa\u00eddas das camadas, o que permite \u00e0s redes neurais aprender e modelar rela\u00e7\u00f5es complexas nos dados. Essas fun\u00e7\u00f5es n\u00e3o possuem par\u00e2metros ajust\u00e1veis e s\u00e3o fixas, usadas especificamente para introduzir n\u00e3o-linearidade nas redes neurais conforme Goodfellow, Bengio e Courville (2016) [10]. A Figura 4 ilustra a transforma\u00e7\u00e3o linear e a ativa\u00e7\u00e3o linear em uma camada densa final de uma rede neural."}, {"title": "2.5 Entendendo o Funcionamento das Camadas Densas em Redes Neurais Recorrentes", "content": "Os neur\u00f4nios em redes neurais recorrentes (RNNs) s\u00e3o unidades fundamentais que processam informa\u00e7\u00f5es ao longo do tempo. Eles s\u00e3o respons\u00e1veis por realizar opera\u00e7\u00f5es matem\u00e1ticas nos dados de entrada e nos estados ocultos anteriores (previs\u00e3o do bloco anterior) para gerar sa\u00eddas e atualizar seus pr\u00f3prios estados. Uma camada densa \u00e9 uma camada comumente usada em redes neurais, em que cada neur\u00f4nio na camada est\u00e1 totalmente conectado a todos os neur\u00f4nios na camada anterior. Os c\u00e1lculos realizados em uma camada densa envolvem multiplica\u00e7\u00e3o de matriz entre a entrada dos dados e os pesos (par\u00e2metros) da camada, seguida por uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o. Aqui est\u00e3o os c\u00e1lculos para uma camada densa: Seja x a matriz de entrada de dimens\u00e3o (m \u00d7 n), em que m\u00e9 o n\u00famero de amostras e n \u00e9 o n\u00famero de caracter\u00edsticas. Seja W a matriz de pesos da camada densa de dimens\u00e3o (n \u00d7 p), com p sendo o n\u00famero de neur\u00f4nios na camada densa. Al\u00e9m disso, seja b o vetor de vi\u00e9s da camada densa de dimens\u00e3o (p \u00d7 n). A sa\u00edda da camada densa Z \u00e9 calculada da seguinte forma:\n$Z = xW + b,$\naqui, xW representa a multiplica\u00e7\u00e3o de matriz entre a entrada e os pesos da camada densa, e b\u00e9 o vi\u00e9s adicionado para produzir a sa\u00edda final. \u00c9 importante notar que ap\u00f3s essa opera\u00e7\u00e3o, geralmente \u00e9 aplicada uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o aos elementos de Z para introduzir n\u00e3o linearidade na camada densa conforme Goodfellow, Bengio e Courville (2016) [10]."}, {"title": "2.6 Algoritmo de Otimiza\u00e7\u00e3o Adam: Uma Vis\u00e3o Geral", "content": "O algoritmo Adam, desenvolvido por Kingma e Ba (2014) [15], utiliza m\u00e9dias m\u00f3veis exponenciais dos gra- dientes para atualizar os par\u00e2metros, acelerando a converg\u00eancia e evitando que o modelo fique preso em m\u00ed- nimos locais. O Adam incorpora estimativas de primeira e segunda ordens com corre\u00e7\u00f5es de vi\u00e9s para me- lhorar a efic\u00e1cia da otimiza\u00e7\u00e3o. As configura\u00e7\u00f5es padr\u00e3o para os problemas de aprendizado de m\u00e1quina tes- tados s\u00e3o a = 0.001, \u03b2\u03b9 = 0.9, \u03b22 = 0.999 \u0435 \u0454 = 10-8. Todas as opera\u00e7\u00f5es em vetores s\u00e3o reali-"}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "zadas elemento a elemento (matricialmente). Com \u1e9e e 2 denotados como B\u2081 e \u03b22 elevados \u00e0 pot\u00eancia t."}, {"title": "2.6.1 Descri\u00e7\u00e3o dos Par\u00e2metros", "content": "De acordo com Kingma e Ba (2014) [15], o algoritmo Adam \u00e9 considerado uma t\u00e9cnica avan\u00e7adda de otimiza\u00e7\u00e3o que calcula taxas de aprendizado adaptativas para cada par\u00e2metro. Ele combina caracter\u00edsticas dos m\u00e9todos Adagrad e RMSprop, mantendo m\u00e9dias m\u00f3veis exponenciais dos gradientes e dos gradientes ao quadrado para ajustar as taxas de aprendizado.\n\"mt e vt s\u00e3o estimativas do primeiro momento (a m\u00e9dia) e do segundo momento (a vari\u00e2ncia n\u00e3o centralizada) dos gradientes, respectivamente, da\u00ed o nome do m\u00e9todo. Como mt e vt s\u00e3o inicializados como vetores de zeros, os autores do Adam observam que eles s\u00e3o tendenciosos para zero, especialmente durante os passos iniciais, e especialmente quando as taxas de decaimento s\u00e3o pequenas [...],\"Ruder (2016) [19].\nEles contrabalan\u00e7am esses vieses calculando estimativas corrigidas de vi\u00e9s para o primeiro e segundo momentos:\n$\\hat{m}_t = \\frac{B_1 m_{t-1}+(1- \\beta_1)g_t}{(12)}$\n$\\hat{v}_t = \\frac{B_2 v_{t-1} + (1 - \\beta_2)g}{(13)}$\nAqui, mt representa a estimativa da m\u00e9dia dos gradientes e vt a estimativa da vari\u00e2ncia n\u00e3o centralizada. Para corrigir o vi\u00e9s de inicializa\u00e7\u00e3o dessas estimativas, s\u00e3o calculadas as corre\u00e7\u00f5es de vi\u00e9s:\n$\\hat{m}_t = \\frac{m_t}{1-\\beta} $ (14)\n$\\hat{v}_t = \\frac{v_t}{1-\\beta} $ (15)\nCom essas estimativas corrigidas, a atualiza\u00e7\u00e3o dos par\u00e2metros \u00e9 dada por:\n$\\theta_{t+1} = \\theta_{\\tau} - \\frac{\\eta}{\\sqrt{v_t} + \\epsilon} \\hat{m}_t$ (16)\nReiterando o que foi afirmado no in\u00edcio desta se\u00e7\u00e3o, os valores padr\u00e3o sugeridos para os hiperpar\u00e2metros s\u00e3o \u03b2\u2081 = 0.9, \u03b22 = 0.999, \u0435 \u0454 = 10\u22128. O otimizador Adam \u00e9 conhecido por sua efic\u00e1cia em uma ampla gama de problemas de aprendizado de m\u00e1quina, proporcionando uma atualiza\u00e7\u00e3o eficiente e eficaz dos par\u00e2metros durante o treinamento de redes neurais."}, {"title": "3 Metodologia", "content": "Nesta se\u00e7\u00e3o, descrevemos o procedimento adotado para modelar e prever s\u00e9ries temporais utilizando redes neurais recorrentes. Utilizamos dados de contagem dos focos ativos detectados pelo sat\u00e9lite AQUA_M-T no bioma da Amaz\u00f4nia, abrangendo uma s\u00e9rie hist\u00f3rica registrada desde junho de 1998 at\u00e9 31 de agosto de 2024. Esses dados est\u00e3o dispon\u00edveis no site do INPE (2024) [17]. O processo metodol\u00f3gico para modelar e prever essa s\u00e9rie temporal segue pr\u00e1ticas estabelecidas na literatura de s\u00e9ries temporais e aprendizado de m\u00e1quina. Inicialmente, dividimos os dados em conjuntos de treino e teste para avaliar a performance do modelo, aplicando t\u00e9cnicas como valida\u00e7\u00e3o cruzada para assegurar a robustez do modelo, conforme descrito por Kingma e Ba (2014) [15]. Ap\u00f3s garantir que o modelo apresentava uma boa capacidade de generaliza\u00e7\u00e3o, optamos por treinar o modelo final utilizando 100% dos dados dispon\u00edveis. Essa abordagem visa maximizar a precis\u00e3o das previs\u00f5es, especialmente em cen\u00e1rios de passos \u00e0 frente da \u00faltima observa\u00e7\u00e3o treinada, como indicado por G\u00e9ron (2017) [9]. No contexto de deep learning, onde ajustes finos (fine-tuning) s\u00e3o comuns, o uso do conjunto completo de dados ap\u00f3s valida\u00e7\u00e3o \u00e9 uma pr\u00e1tica justificada para aprimorar o desempenho, conforme discutido por Goodfellow, Bengio e Courville (2016) [10]. Dessa forma, utilizamos o modelo treinado com 100% dos dados para realizar previs\u00f5es de n passos \u00e0 frente, garantindo que as previs\u00f5es fossem baseadas na maior quantidade de informa\u00e7\u00f5es poss\u00edvel."}, {"title": "3.1 Prepara\u00e7\u00e3o dos Dados", "content": "Na prepara\u00e7\u00e3o dos dados, adotamos uma abordagem de treino, valida\u00e7\u00e3o e teste adaptada para s\u00e9ries temporais cont\u00ednuas. Para garantir a efic\u00e1cia da avalia\u00e7\u00e3o do modelo, seguimos o processo de divis\u00e3o dos dados de frente para tr\u00e1s. Primeiramente, removemos os \u00faltimos 12 lags (meses) da s\u00e9rie para o conjunto de teste, considerando a s\u00e9rie completa menos esses 12 lags. Em seguida, removemos 24 lags adicionais para o conjunto de valida\u00e7\u00e3o, o que deixou a s\u00e9rie completa menos 36 lags para o treinamento. Embora tenhamos seguido a abordagem de divis\u00e3o de dados, utilizamos valida\u00e7\u00e3o cruzada com duas sementes para avaliar a performance do modelo. Conforme descrito por G\u00e9ron (2017) [9], a valida\u00e7\u00e3o cruzada \u00e9 essencial para garantir que o modelo generalize bem para novos dados. Foram utilizadas duas sementes distintas para criar dois modelos diferentes, o que permitiu avaliar a robustez e a estabilidade do modelo. A divis\u00e3o final dos dados foi a seguinte:\n\u2022 Conjunto de Treino: Junho de 1998 at\u00e9 agosto de 2021;\n\u2022 Conjunto de Valida\u00e7\u00e3o: Setembro de 2021 at\u00e9 agosto de 2023;\n\u2022 Conjunto de Teste: Setembro de 2023 at\u00e9 agosto de 2024.\nEssa abordagem, combinada com o uso de sementes fixas, garantiu a replicabilidade dos resultados e confirmou a consist\u00eancia das generaliza\u00e7\u00f5es para os conjuntos de treino, valida\u00e7\u00e3o e teste."}, {"title": "3.2 Configura\u00e7\u00e3o dos Modelos", "content": "Foi utilizado a combina\u00e7\u00e3o dos modelos de redes neurais recorrentes LSTM+GRU essa arquitetura consiste em:\n\u2022 Camada de Entrada: Recebe os dados da s\u00e9rie temporal em janelas fixadas previamente, que na nossa arquitetura escolhemos tamanho de 12 para que a partir de 12 meses se tenha a primeira previs\u00e3o no 13\u00ba ponto.\n\u2022 Camada Recorrente: Para o modelo LSTM+GRU, foi configurada uma camada LSTM seguida por uma camada GRU, ambas com 256 neur\u00f4nios.\n\u2022 Camada Densa: Uma camada densa com 256 neur\u00f4nios e fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU.\n\u2022 Camada de Sa\u00edda: Uma camada densa com 1 neur\u00f4nio e ativa\u00e7\u00e3o linear, fornecendo a previs\u00e3o final para cada janela de entrada.\nVeja a figura 5 que melhor ilustra essa configura\u00e7\u00e3o."}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "A Figura 5 ilustra a transmiss\u00e3o de informa\u00e7\u00f5es entre as camadas at\u00e9 a sa\u00edda final e n\u00e3o aborda o funcionamento de dropout ou fun\u00e7\u00f5es de ativa\u00e7\u00e3o. A explica\u00e7\u00e3o da arquitetura \u00e9 a seguinte:\nCada entrada Xt no tempo t\u00e9 inicialmente processada pela camada LSTM composta por 256 neur\u00f4nios. A sa\u00edda dessa camada LSTM, com dimens\u00e3o (1 \u00d7 256) considerando o nosso trabalho com uma \u00fanica vari\u00e1vel no tempo (focos ativos), resulta em (1 \u00d7 256) \u00e9 ent\u00e3o passada para uma camada densa com 256 neur\u00f4nios, resultando novamente em uma sa\u00edda de dimens\u00e3o (1 \u00d7 256). Esta sa\u00edda \u00e9 usada como entrada para a camada GRU, que tamb\u00e9m tem 256 neur\u00f4nios. A sa\u00edda da camada GRU \u00e9 processada por outra camada densa com 256 neur\u00f4nios, mantendo a dimens\u00e3o (1 \u00d7 256). Finalmente, essa sa\u00edda \u00e9 alimentada na camada densa de sa\u00edda com 1 neur\u00f4nio, resultando em uma previs\u00e3o \u00fanica para o pr\u00f3ximo ponto da s\u00e9rie temporal. Para ilustrar o funcionamento, considere um bloco de dados com 12 valores, onde a entrada Xt \u00e9 o vetor de valores de 1 a 12. A previs\u00e3o \u00e9 feita para o 13\u00ba valor. O processo \u00e9 repetido ao mover a janela de entrada, de modo que o segundo bloco ser\u00e1 de 2 a 13, e a previs\u00e3o ser\u00e1 para o ponto 14, e assim por diante at\u00e9 o final da s\u00e9rie. Essa abordagem permite calcular m\u00e9tricas de erro, como a diferen\u00e7a entre as previs\u00f5es e os valores reais da s\u00e9rie. O erro m\u00e9dio \u00e9 ent\u00e3o utilizado para avaliar a converg\u00eancia do modelo a cada \u00e9poca de treinamento, onde uma \u00e9poca \u00e9 definida como o ciclo completo de treinamento atrav\u00e9s de todos os pontos da s\u00e9rie temporal. O otimizador Adam foi utilizado para ajustar os par\u00e2metros do modelo, com a taxa de aprendizado fixada em 0,001 para o modelo combinado de LSTM+GRU."}, {"title": "3.3 Treinamento e Avalia\u00e7\u00e3o dos Modelos", "content": "Os modelos foram treinados utilizando a linguagem de programa\u00e7\u00e3o Python Software Foundation [8], com as bibliotecas Scikit-learn [16] e Keras [5], 2015. Cada modelo foi treinado por 1000 \u00e9pocas, e as m\u00e9tricas Erro Absoluto M\u00e9dio (MAE) e Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE) foram utilizadas para avaliar o desempenho. Para cada \u00e9poca, o modelo gerou previs\u00f5es utilizando uma t\u00e9cnica conhecida como janela/bloco deslizante (ou sliding window). Este procedimento funciona da seguinte forma:\n1. Janela de Entrada: Definimos uma janela de 12 lags, ou seja, o modelo usa os dados dos 12 per\u00edodos anteriores para prever o valor do pr\u00f3ximo per\u00edodo. Por exemplo, se temos dados mensais e a janela \u00e9 de 12 lags, o modelo usa os"}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "dados dos \u00faltimos 12 meses para prever o valor do m\u00eas seguinte. 2. Deslizamento da Janela: Ap\u00f3s gerar uma previs\u00e3o para o pr\u00f3ximo per\u00edodo (o 13\u00b0), a janela \u00e9 deslocada uma posi\u00e7\u00e3o para frente. Isso significa que a previs\u00e3o \u00e9 feita usando os dados dos per\u00edodos de 2 a 13 para prever o 14\u00ba per\u00edodo. Esse processo \u00e9 repetido at\u00e9 que todas as previs\u00f5es sejam feitas para o restante da s\u00e9rie temporal. 3. Avalia\u00e7\u00e3o das Previs\u00f5es: As previs\u00f5es geradas para cada \u00e9poca s\u00e3o comparadas com os dados reais da s\u00e9rie temporal. Para avaliar a precis\u00e3o das previs\u00f5es, utilizamos as m\u00e9tricas MAE e RMSE. O MAE calcula a m\u00e9dia dos erros absolutos das previs\u00f5es, enquanto o RMSE calcula a raiz quadrada da m\u00e9dia dos erros quadr\u00e1ticos. Os par\u00e2metros iniciais dos modelos foram definidos utilizando uma distribui\u00e7\u00e3o de probabilidade espec\u00edfica, a distribui\u00e7\u00e3o normal de He (He normal). Essa distribui\u00e7\u00e3o \u00e9 definida com m\u00e9dia zero e desvio padr\u00e3o $\\sqrt{2/n}$, onde n \u00e9 o n\u00famero de unidades na camada de entrada. A escolha dessa distribui\u00e7\u00e3o ajuda a garantir uma inicializa\u00e7\u00e3o adequada dos pesos, facilitando o treinamento eficaz de redes neurais profundas, conforme os Keras Developers (2024) [7].\nOs dados foram divididos da seguinte forma:\n\u2022 Treino: Junho de 1998 at\u00e9 agosto de 2021;\n\u2022 Valida\u00e7\u00e3o: Setembro de 2021 at\u00e9 agosto de 2023;\n\u2022 Teste: Setembro de 2023 at\u00e9 agosto de 2024.\nUtilizamos duas sementes distintas para garantir a replicabilidade dos resultados e a estabilidade das m\u00e9tricas de desempenho. O modelo que apresentou o menor erro m\u00e9dio nas m\u00e9tricas MAE e RMSE durante o treinamento foi selecionado como o modelo final."}, {"title": "3.4 Como as Previs\u00f5es s\u00e3o Calculadas?", "content": "As previs\u00f5es foram realizadas ap\u00f3s o treinamento completo dos dados de focos ativos registrados na regi\u00e3o da Amaz\u00f4nia, Brasil, dispon\u00edveis no site do INPE (2024)[17], abrangendo o per\u00edodo de junho de 1998 at\u00e9 agosto de 2024. Ap\u00f3s o treinamento, utilizamos a fun\u00e7\u00e3o predict do pacote Keras [5], para gerar as previs\u00f5es. O processo envolveu o uso do modelo treinado, que j\u00e1 cont\u00e9m todos os par\u00e2metros otimizados e ajustados. O modelo, armazenado e salvo como o melhor obtido durante o treinamento, \u00e9 utilizado com a fun\u00e7\u00e3o predict, que \u00e9 chamada como modelo.predict(). Este modelo foi treinado com uma vari\u00e1vel e um bloco de tamanho 12. A fun\u00e7\u00e3o predict segue a sequ\u00eancia dos dados, incorporando as previs\u00f5es anteriores para gerar novos resultados, adicionando esses resultados \u00e0 s\u00e9rie temporal e prevendo o pr\u00f3ximo ponto. Para detalhar o processo: a fun\u00e7\u00e3o predict utiliza as \u00faltimas 12 observa\u00e7\u00f5es da s\u00e9rie temporal (o tamanho da janela deslizante), que v\u00e3o de setembro de 2023 a agosto de 2024, para prever o 13\u00ba ponto, que corresponde a setembro de 2024. A abordagem de \"janela deslizante\"\u00e9 usada, permitindo que ap\u00f3s a primeira previs\u00e3o para setembro de 2024, o modelo integre essa previs\u00e3o e gere uma nova previs\u00e3o para o pr\u00f3ximo m\u00eas. No segundo passo, por exemplo, ele utiliza as observa\u00e7\u00f5es de outubro de 2023 a setembro de 2024, agora incluindo a previs\u00e3o anterior (de setembro), para prever outubro de 2024 (um dado que ainda n\u00e3o existe na s\u00e9rie temporal). No terceiro passo, o modelo usa os dados de novembro de 2023 a outubro de 2024, incluindo as previs\u00f5es obtidas de setembro e outubro \u00e0 s\u00e9rie temporal, e assim por diante. Esse processo continua at\u00e9 que todas as previs\u00f5es dos 12 meses sejam realizadas. Essa abordagem assegura que cada previs\u00e3o mensal se baseie nos dados hist\u00f3ricos mais recentes, juntamente com as previs\u00f5es feitas nos passos anteriores, resultando em uma modelagem robusta para s\u00e9ries temporais de dados de contagem, conforme descrito na literatura e referenciado nesta se\u00e7\u00e3o. A ilustra\u00e7\u00e3o detalhada desse processo est\u00e1 apresentada na Figura 5."}, {"title": "4 Resultados da An\u00e1lise Estat\u00edstica", "content": "Nesta se\u00e7\u00e3o, apresentamos uma an\u00e1lise descritiva da s\u00e9rie temporal de focos ativos na Amaz\u00f4nia, com \u00eanfase na m\u00e9dia, desvio padr\u00e3o, vari\u00e2ncia e nos valores m\u00e1ximos e m\u00ednimos registrados ao longo dos anos, veja a Tabela 1.\nA an\u00e1lise foi realizada cuidadosamente, aplicando t\u00e9cnicas de an\u00e1lise de dados para identificar os pontos mais extremos de cada ano. Nosso objetivo \u00e9 oferecer uma vis\u00e3o clara e direta desses valores, evitando a complexidade que seria"}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "introduzida por uma tabela detalhada. Ao inv\u00e9s disso, optamos por uma representa\u00e7\u00e3o gr\u00e1fica que facilita a visualiza\u00e7\u00e3o e compreens\u00e3o dessas estat\u00edsticas importantes.\nA s\u00e9rie temporal de junho de 1998 at\u00e9 agosto de 2024 apresenta dados mensais do total de focos ativos registrados pelo sat\u00e9lite de refer\u00eancia a cada m\u00eas. Como vemos na figura 6, os meses de agosto e setembro foram consistentemente registrados como aqueles com o maior n\u00famero de focos ativos durante esse per\u00edodo de mais de 20 anos."}, {"title": "5 Resultados da An\u00e1lise de Treinamento do Modelo de Aprendizado de M\u00e1quina", "content": "Nesta se\u00e7\u00e3o, apresentamos e discutimos os resultados obtidos para os modelos de redes neurais recorrentes avaliados, especificamente a abordagem mista que combina LSTM e GRU. Vamos explorar o desempenho do modelo, utilizando m\u00e9tricas de avalia\u00e7\u00e3o, como Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE) e Erro Absoluto M\u00e9dio (MAE), tanto para os conjuntos de treino quanto para os de teste. Cada modelo foi avaliado isoladamente, e os resultados obtidos ser\u00e3o apresentados em tabelas detalhadas. Utilizaremos essas m\u00e9tricas para comparar o desempenho dos modelos e determinar qual deles apresenta os menores valores de erro. O modelo que demonstrar melhor desempenho, com os menores valores de erro, ser\u00e1 selecionado como o mais eficaz para a tarefa de previs\u00e3o em quest\u00e3o. As implica\u00e7\u00f5es dos resultados ser\u00e3o discutidas, incluindo a an\u00e1lise da varia\u00e7\u00e3o das m\u00e9tricas com diferentes sementes e configura\u00e7\u00f5es. Esta an\u00e1lise fornecer\u00e1 uma vis\u00e3o abrangente da efic\u00e1cia de cada modelo, permitindo a escolha do modelo mais adequado para realizar as previs\u00f5es necess\u00e1rias com base nos crit\u00e9rios estabelecidos."}, {"title": "6 Resultados do Modelo LSTM + GRU", "content": "A Tabela 2 e a Figura 9 relacionadas ilustram o desempenho do modelo LSTM + GRU para os conjuntos de treino e teste, utilizando diferentes sementes de inicializa\u00e7\u00e3o. As m\u00e9tricas de Erro Quadr\u00e1tico M\u00e9dio (RMSE) e Erro Absoluto M\u00e9dio (MAE) s\u00e3o fundamentais para avaliar a precis\u00e3o das previs\u00f5es do modelo."}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "O Erro Absoluto M\u00e9dio (MAE) mede a m\u00e9dia das diferen\u00e7as absolutas entre os valores reais e as previs\u00f5es, e \u00e9 definido pela seguinte f\u00f3rmula:\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|,$ (17)\nem que n \u00e9 o n\u00famero total de meses, yi s\u00e3o os valores reais de cada m\u00eas, e \u011di s\u00e3o as previs\u00f5es do modelo para cada m\u00eas. Nesse contexto, conseguimos obter para cada \u00e9poca todas as diferen\u00e7as entre os valores mensais reais e o que o modelo LSTM+GRU prev\u00ea para cada um desses meses. Depois, extra\u00edmos a m\u00e9dia dessas diferen\u00e7as, que nada mais \u00e9 do que a soma dessas diferen\u00e7as absolutas dividida pelo total de meses (n). J\u00e1 o Erro Quadr\u00e1tico M\u00e9dio (RMSE) leva em considera\u00e7\u00e3o o quadrado dessas diferen\u00e7as, penalizando erros maiores de forma mais severa, e \u00e9 dado por:\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2},$ (18)\nem que n \u00e9 o n\u00famero total de meses, yi s\u00e3o os valores reais de cada m\u00eas, e \u0177\u2081 s\u00e3o as previs\u00f5es do modelo para cada m\u00eas. O RMSE calcula a raiz quadrada da m\u00e9dia dos quadrados das diferen\u00e7as entre os valores reais e as previs\u00f5es. Isso penaliza erros maiores de forma mais intensa, fornecendo uma medida que reflete a magnitude dos erros em um n\u00edvel mais severo do que o MAE. Essas m\u00e9tricas s\u00e3o utilizadas para selecionar o melhor modelo entre os 1000 treinamentos realizados. Em cada \u00e9poca, a diferen\u00e7a entre os valores reais e as previs\u00f5es \u00e9 calculada, e o modelo que apresenta a menor diferen\u00e7a m\u00e9dia \u00e9 escolhido como o melhor. Observa-se que, embora haja uma diferen\u00e7a significativa nas previs\u00f5es, especialmente no RMSE, o MAE nos fornece uma diferen\u00e7a m\u00e9dia de pouco mais de 3000 focos ativos, em compara\u00e7\u00e3o a uma m\u00e9dia hist\u00f3rica de 9000 focos. Isso sugere que, apesar de n\u00e3o ser extremamente preciso, o modelo ainda consegue capturar a tend\u00eancia geral, com um erro que representa aproximadamente um ter\u00e7o da m\u00e9dia hist\u00f3rica.\nA Figura 10 ilustra a valida\u00e7\u00e3o cruzada realizada com duas sementes distintas, 2024 e 2025, comparando dois conjuntos de treino e teste. Esta abordagem \u00e9 fundamental para avaliar a capacidade de generaliza\u00e7\u00e3o do modelo em s\u00e9ries temporais, onde a sequ\u00eancia dos dados \u00e9 extremamente importante. Ao utilizar sementes diferentes para os conjuntos de treino, teste e valida\u00e7\u00e3o, garantimos que a valida\u00e7\u00e3o cruzada considere varia\u00e7\u00f5es na inicializa\u00e7\u00e3o do modelo e na estima\u00e7\u00e3o dos par\u00e2metros, permitindo uma avalia\u00e7\u00e3o mais robusta da generaliza\u00e7\u00e3o. Em s\u00e9ries temporais, a fixa\u00e7\u00e3o das sementes ajuda a assegurar que a performance do modelo \u00e9 consistente e n\u00e3o apenas um reflexo de uma configura\u00e7\u00e3o espec\u00edfica. Os resultados obtidos para ambas as sementes s\u00e3o bastante similares, indicando que o modelo generaliza bem e segue de forma confi\u00e1vel a tend\u00eancia geral dos focos ativos na Amaz\u00f4nia. Essa similaridade sugere que o modelo tem uma boa capacidade de generaliza\u00e7\u00e3o e que, ao treinar com os dados completos, ele poder\u00e1 fornecer previs\u00f5es na dire\u00e7\u00e3o correta para identificar per\u00edodos com maiores e menores tend\u00eancias de focos ativos."}, {"title": "A PREPRINT 5 DE SETEMBRO DE 2024", "content": "1000 \u00e9pocas, \u00e9 poss\u00edvel avaliar se o modelo est\u00e1 generalizando bem para novos dados, o que \u00e9 essencial para prever a tend\u00eancia dos dados. Portanto, esses gr\u00e1ficos ilustram a evolu\u00e7\u00e3o da perda e fornecem detalhes sobre a capacidade da converg\u00eancia dos par\u00e2metros a cada modelo de se ajustar aos dados, refletindo diretamente na qualidade das previs\u00f5es e na efetividade do treinamento realizado."}, {"title": "6.1 Treinamento para os dados completos", "content": ""}]}