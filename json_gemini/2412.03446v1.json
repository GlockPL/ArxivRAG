{"title": "From Words to Workflows: Automating Business Processes", "authors": ["Laura Minkova", "Jessica L\u00f3pez Espejel", "Taki Eddine Toufik Djaidja", "Walid Dahhane", "El Hassane Ettifouri"], "abstract": "As businesses increasingly rely on automation to streamline operations, the limitations of Robotic Process Automation (RPA) have become apparent, particularly its dependence on expert knowledge and inability to handle complex decision-making tasks. Recent advancements in Artificial Intelligence (AI), particularly Generative AI (GenAI) and Large Language Models (LLMs), have paved the way for Intelligent Automation (IA), which integrates cognitive capabilities to overcome the shortcomings of RPA. This paper introduces Text2Workflow, a novel method that automatically generates workflows from natural language user requests. Unlike traditional automation approaches, Text2Workflow offers a generalized solution for automating any business process, translating user inputs into a sequence of executable steps represented in JavaScript Object Notation (JSON) format. Leveraging the decision-making and instruction-following capabilities of LLMs, this method provides a scalable, adaptable framework that enables users to visualize and execute workflows with minimal manual intervention. This research outlines the Text2Workflow methodology and its broader implications for automating complex business processes.", "sections": [{"title": "1. Introduction", "content": "Robotic Process Automation (RPA) has long been a key enabler of business process automation, allowing organizations to streamline repetitive tasks and enhance operational efficiency. However, despite its widespread adoption, RPA has notable limitations. In particular, its reliance on expert knowledge, both in coding and business processes, makes its implementation and maintenance costly and complex (Moreira et al., 2023; Eulerich et al., 2024; Zeng et al., 2024). Additionally, RPA's cognitive capabilities fall short when handling tasks that require more advanced decision-making, leading to failure when faced with unforeseen circumstances or errors. As businesses evolve, these limitations underscore the need for more intelligent and adaptable automation solutions.\nThe emergence of Artificial Intelligence (AI) has opened new avenues for overcoming the challenges inherent in RPA systems, leading to the emergence of systems known as Intelligent Process Automation (IPA). By integrating advanced AI technologies, including Machine Learning (ML) and Generative Artificial Intelligence (GenAI), IPA extends automation beyond rule-based processes to encompass tasks requiring human-like cognitive abilities (Siderska et al., 2023). Recent developments in GenAI, particularly with the advent of Large Language Models (LLMs) such as GPT (Generative Pre-trained Transformer) (Radford et al., 2018a,b; OpenAI, 2023), have revolutionized the way automation systems can understand and generate natural language"}, {"title": "2. Related works", "content": "In this section, we review related work in the fields of Robotic Process Automation, Generative Artificial Intelligence for Text Generation-highlighting developments from both the pre- and post-Transformers era\u2014and workflow automation."}, {"title": "2.1. Robotic Process Automation", "content": "RPA is a collection of technological tools designed to automate business processes by executing code that operates independently on software systems (van der Aalst et al., 2018; Costa et al., 2022; Moreira et al., 2023). Developing RPA solutions requires close collaboration between coding experts and business process experts (Costa et al., 2022), in order to create rule-based automation systems capable of operating with minimal human intervention.\nMany companies have turned to adopting such solutions or have outsourced their implementation to specialized firms such as Blue Prism \u00b9 and UiPath \u00b2\n(van der Aalst et al., 2018).\nRPA offers several key advantages that help businesses remain competitive in a rapidly evolving landscape (Siderska et al., 2023; Lo et al., 2024).\nFirst, RPA improves operations by accelerating processes and reducing human errors, leading to increased efficiency. Second, it is highly scalable, with RPA-equipped bots capable of handling heavy workloads without necessarily an increase in resources. Additionally, as highlighted by Lo et al. (2024), significant cost savings are achieved through reduced labor expenses"}, {"title": "2.2. Generative Artificial Intelligence for Text Generation", "content": "Bengesi et al. (2024) examines recent advancements in GenAI, high-"}, {"title": "2.2.1. Pre-Transformers Era", "content": "The field of generative artificial intelligence began long before the recent emergence of transformers, GPTs (Radford et al., 2018a,b; Brown et al., 2020), and other LLMs (Gordijn and Have, 2023; Minaee et al., 2024; Bengesi et al., 2024). A significant early contribution to this field was the development of Recurrent Neural Networks (RNNs) by Rumelhart et al. (1986), which opened up numerous applications for treating sequential data, including natural language processing (NLP) (Farooq et al., 2023; Kang et al., 2023) tasks and time series analysis (Yu et al., 2021; Wang et al., 2022). Subsequently, Hochreiter and Schmidhuber (1997) introduced the Long Short-Term Memory (LSTM) model, addressing a major limitation of RNNs by enabling the processing of longer and more complex sequences. Similarly, Cho et al. (2014)"}, {"title": "2.2.2. Post-Transformers Era", "content": "The field of GenAI took a turn with the groundbreaking advancements introduced by the transformer architecture (Vaswani et al., 2017). The transformer model revolutionized NLP by leveraging self-attention mechanisms to improve efficiency and accuracy in handling sequential data (Valmeekam et al., 2023b), leading to the eventual development of models such as BERT (Devlin et al., 2018) and more recently, GPT-4 (OpenAI et al., 2024). Other key advancements include diffusion models (Ho et al., 2020; Peebles and Xie, 2023; Yang et al., 2024c), which have achieved state-of-the-art performance in image generation, and hybrid models like Chinchilla (Hoffmann et al., 2022) that improve training efficiency and scalability. Additionally, methods such as Reinforcement Learning from Human Feedback (RLHF) (Ouyang et al., 2022) have been introduced to align AI models with human intentions and improve the coherence of their generated outputs. These innovations have expanded the capabilities of GenAI, allowing it to tackle more complex tasks"}, {"title": "2.3. Workflow Automation", "content": "The existing literature on the automation of generating workflows in JSON format from natural language requests remains limited. However, several relevant research developments address adjacent topics, including action planning and scheduling, code generation, JSON generation, and workflow"}, {"title": "3. Methodology", "content": null}, {"title": "3.1. JSON-Based Structure in Text2Workflow", "content": "The goal of Text2Workflow is to automatically transform a natural language user request into a structured workflow of actionable steps, represented in JSON format, with the ultimate aim of autonomously executing the entire process. In the following subsection, we outline the methodology of our approach. We begin by describing the structure of the output, followed by"}, {"title": "3.2. Enhancing Generation in Text2Workflow through Master and Experts", "content": "To construct the aforementioned JSON structures, Text2Workflow can be broken down into seven distinct layers of prompts that we detail in this section:\n1. User Request Ambiguity Screening. User Request Screening Prompt.\n2. Building the Workflow Skeleton. General Process Prompt & Master Prompt.\n3. Human Feedback Loop. High-level Summary Prompt & Workflow Modification Prompt.\n4. Workflow Details. Expert Prompts.\n5. *Special Case* Further Workflow Details. Parameter Expert Prompt.\n6. Verifying Missing Parameters. Questions Prompt.\n7. Final Modifications. Workflow Modification Prompt.\nThe remainder of this subsection provides a detailed analysis of each layer within Text2Workflow. The prompts used in each layer are listed in Appendix B. For a visual overview of how each prompt layer functions within our approach, please refer to Section 3.4."}, {"title": "3.2.1. User Request Clarification", "content": "The first step in Text2Workflow involves verifying that the user request is, at a minimum, not blatantly missing any information, logically structured, and relevant to business processes. This is achieved through the User Request Screening Prompt (see Figure B.21), which either returns an empty response if the request is valid or provides follow-up questions if clarification is needed. The user can then choose to re-write their request to clarify specific points raised by the Text2Workflow agent or ignore the suggestions if preferred. This initial layer serves as a preliminary check, alerting the user to potential issues without blocking further progress in Text2Workflow."}, {"title": "3.2.2. Building the Workflow Skeleton", "content": "We define a workflow skeleton as a nearly complete version of the business process' workflow JSON, lacking only the specific parameters for each step. In order to construct this skeleton, we concatenate the results from two"}, {"title": "3.2.3. User Feedback Loop", "content": "The workflow skeleton, as described in Section 3.2.2, is subsequently reviewed by a human user. This approach is inspired by the findings of Zeng et al. (2024), which demonstrated that incorporating a human-in-the-loop mechanism for confirming or editing a workflow resulted in an accuracy improvement of over 6.5% in more complex scenarios.\nInitially, the workflow skeleton is summarized using the High-level Summary Prompt (see Figure B.28). This prompt provides a natural language summary of the skeleton without presuming any coding knowledge of the user that will be analyzing it. In other words, it articulates each step as presented in the steps key of the workflow.\nAfterwards, the summary is then presented to the user, upon which they"}, {"title": "3.2.4. Workflow Details", "content": "Once the workflow has been validated by the user, Text2Workflow iteratively traverses the steps. For each step, a specific Expert Prompt is invoked based on the step's type. For a comprehensive list of the Expert Prompts, please refer to Figures B.29 to B.38. Each Expert Prompt returns the correct parameters, with the exception of step types that require an API. In such cases, the Expert Prompt is a generic prompt that simply returns the necessary function based on the tool being used such as Outlook, Excel, File, Web, or Desktop.\nThe Expert Prompt is also responsible for creating and keeping track of the workflow's context, which is a dictionary that tracks all of the variables throughout the workflow's execution. This context includes variables that store extracted or read text, calculated entities, data tables, and more. The Expert Prompt populates each step's parameters, which may involve using previously instantiated variables or updating the context with a newly instantiated variable."}, {"title": "3.2.5. Special Case \u2013 Further Workflow Details", "content": "This applies to steps requiring additional parameter details, such as steps of type Outlook, Excel, File, Web, Desktop, or Exception (TryBlock). In such cases, an additional layer, called the Parameter Expert Prompt, is invoked (Figures B.39 to B.42). This extra layer of a Parameter Expert Prompt has nearly identical functionality to the previous layer, simply returning the parameters of certain steps, and updating the context if needs be."}, {"title": "3.2.6. Verifying Missing Parameters", "content": "Once the business process workflow is fully defined with all steps and their corresponding parameters, a final check is done to identify any missing essential parameters that may not have been filled out by the Expert Prompts. Essential parameters are prerequisites for executing the API function and are predetermined. For example, in sending an email, the \u201cto\u201d and \u201cbody\" fields are essential. For every step, a list of missing essential parameters is manually created and is verified by checking for empty strings or null values. This list is then sent as input to the Questions Prompt (see Figure B.43), which formulates a natural sounding question that will be displayed to the user. The user can then manually add the missing information they may have not provided initially or that the LLM may not have caught."}, {"title": "3.2.7. Final Modifications", "content": "Finally, if the user chooses to make changes to the generated workflow after everything has been done, they can do so by providing certain modifications they would like to be made. These modifications, along with the complete, generated workflow are then provided as input to the Workflow"}, {"title": "3.3. Prompt Engineering to Improve the Text2Workflow pipeline", "content": "To design precise prompts, we applied prompt engineering research strategies, including few-shot prompting, where a small set of examples demonstrates the desired output. Following Chen (2023), we found that a single example is often sufficient to guide the model effectively and produce favorable results. For this reason, nearly all Expert prompts have a single example. The only exceptions are the Loop Expert Prompt with 2 examples (see Figures B.36 and B.37) and the Master Prompt with 4 examples- two in English and two in French (see Figures B.23 to B.27). We felt the latter two prompts required more than one example given the complexity of the task at hand. Additionally, we applied the Chain-of-Thought (Wei et al., 2023) technique, prompting the model to break down complex tasks into logical steps to improve its responses on specific tasks. Finally, we used role-based prompting (Zhao et al., 2021) to align responses from both gpt-3.5-0125 and gpt-4o-mini with the intended context and style.\nAfter designing the prompts, we found that the average baseline prompt length is as high as 9058 tokens. Given the context window capacities of gpt-3.5-0125 (16,385 tokens) and gpt-4o-mini (128K tokens), we hypothesize that gpt-4o-mini may perform better due to its larger window. However, existing studies (Li et al., 2024; Hosseini et al., 2024) suggest that an extended context window does not inherently ensure accurate comprehension of lengthy"}, {"title": "3.4. General Architecture", "content": "Consequently, through the use of the seven distinct layers of prompts outlined in Section 3.1, Text2Workflow can be summarized further into five main mechanisms, as listed below:\n1. Breakdown Creation (Figure 2)\n2. User Feedback Loop (Figure 3)\n3. Workflow Creation and Question Generation (Figure 4)\n4. Manual Completion of Workflow (Figure 5)\n5. Workflow Modification (Figure 6)"}, {"title": "4. Evaluation methodology", "content": "This section presents a thorough analysis of the metrics and evaluation criteria applied to our dataset."}, {"title": "4.1. Proposed Dataset", "content": "We constructed our own dataset, Process2JSON, consisting of 60 concise example user requests. We define a short user request as being anything less than half a page. The dataset is categorized into three levels of complexity: 20 easy examples, 20 medium examples, and 20 complex examples.\nEasy examples are deemed as examples that do not require Decision, Loop or Exception steps, and that are very clearly communicated, and having no ambiguity. Medium level examples include Decision and Loop steps but are logical and well-explained. Finally, complex examples are characterized by"}, {"title": "4.2. Evaluation and Metrics", "content": "To evaluate Text2Workflow, we focused on three key criteria: (1) generation time, (2) token usage, and (3) JSON accuracy. These metrics provide a comprehensive view of both the tool's efficiency and its output quality, allowing us to assess how well Text2Workflow performs in real-world applications. Each of these metrics plays a crucial role in understanding the overall effectiveness of the system.\nFor the first criterion, generation time is essential in assessing the efficiency of Text2Workflow, as the goal of automating workflow creation is to reduce the time required for building, modifying, and maintaining workflows. All tests were conducted using OpenAI's API, meaning that generation time is influenced not only by Text2Workflow itself but also by the performance of the OpenAI platform, which may vary under different conditions.\nToken usage is another critical metric. Since the experimentation relied on OpenAI's API models\u2014 specifically gpt-3.5-0125 and gpt-4o-mini \u2014 understanding token consumption provides insights into the potential costs of deploying Text2Workflow in real-world applications. However, if the underlying language model is hosted locally, token usage becomes less of a concern.\nLastly, JSON accuracy evaluates more than just literal accuracy; it considers semantic consistency and contextual coherence throughout the JSON structure. Our evaluation differentiates between minor and major errors to provide a nuanced measure of quality. The scoring criteria for each level of accuracy are detailed in Table 2, allowing a more granular assessment of JSON output quality."}, {"title": "5. Results and Discussion", "content": "To evaluate the effectiveness of our Text2Workflow approach, which utilizes distinct prompts across multiple pipeline layers, we established two primary baseline models that rely on a single comprehensive prompt (see"}, {"title": "6. Limitations", "content": "According to Ruan et al. (2023), LLMs demonstrate four main limitations: inconsistency in adhering to specified formats, challenges in fully interpreting task instructions, over-dependence on single tools, and limited summarization capabilities. Given Text2Workflow's strong reliance on LLMs, it similarly encounters these issues. As demonstrated in Section 5, although infrequent, Text2Workflow sometimes generates incorrect keys in the JSON structure that should not exist (e.g. Exception steps with Try-Blocks tend to have keys that are not in the predefined structure).\nAnother significant limitation is the specificity of the prompts. While the Master and Experts strategy helps break down the task into smaller, more manageable problems, the prompts themselves remain highly specialized. This specificity poses challenges for maintenance, especially if the JSON structure, step types, or function/API lists are updated, requiring substantial rework to adapt the prompts accordingly. Moreover, the use of multiple prompts may result in better performance but comes at the cost of consuming more tokens and increasing the complexity of maintenance.\nAdditionally, the current solution exclusively uses GPT, a cloud-based service, which could introduce potential security concerns for businesses.\nFinally, the evaluation method in this study requires further research, as it is biased by reliance on a single evaluator. A more robust approach would use multiple evaluators with averaged or consensus scoring, or develop a metric to capture the system's performance more objectively."}, {"title": "7. Conclusions and Future Work", "content": "This paper presents Text2Workflow, a novel approach designed for generalized business workflow automation. Additionally, we introduce a dataset of general user requests translated into JSON workflows, named Process2JSON.\nTo the best of our knowledge, no existing methods in the literature have addressed the generalized automation of workflows spanning a diverse range of business processes.\nThe results of our experiments demonstrated that Text2Workflow significantly outperforms OpenAI's gpt-4o-mini model used with a single long prompt, specifically when treating complex user requests. Our ablation study confirmed that the user input mechanisms integrated into the Text2Workflow pipeline substantially enhance performance, with the user feedback loop alone contributing to an improvement of over 10%. While the initial logic screening of user requests also enhanced results, the increase was modest at 2%, likely due to its infrequent invocation. Further exploration into optimizing the Logic Screening Prompt could yield additional benefits for the Text2Workflow approach.\nDespite these advancements, we acknowledge several limitations, including inconsistencies, difficulties in fully interpreting task instructions, over-reliance on specific tools, and constrained summarization capabilities. Nonetheless, we believe that this approach marks a significant step forward in the field of automated workflow generation across various business processes and industries.\nLooking ahead, future work will focus on addressing these limitations by strengthening the robustness of the prompts to minimize the occurrence of"}]}