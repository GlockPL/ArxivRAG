{"title": "Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits", "authors": ["Yunlong Hou", "Vincent Y. F. Tan", "Zixin Zhong"], "abstract": "We propose a novel piecewise stationary linear bandit (PSLB) model, where the environment randomly samples a context from an unknown probability distribution at each changepoint, and the quality of an arm is measured by its return averaged over all contexts. The contexts and their distribution, as well as the changepoints are unknown to the agent. We design Piecewise-Stationary \u03b5-Best Arm Identification+ (PS\u03b5BAI+), an algorithm that is guaranteed to identify an \u03b5-optimal arm with probability > 1 \u2013 \u03b4 and with a minimal number of samples. PS\u03b5BAI+ consists of two subroutines, PS\u03b5BAI and NA\u00cfVE \u03b5-\u0392\u0391\u0399 (\u039d\u03b5\u0392\u0391I), which are executed in parallel. PS\u03b5BAI actively detects changepoints and aligns contexts to facilitate the arm identification process. When PS\u03b5BAI and N\u03b5BAI are utilized judiciously in parallel, PS\u03b5BAI+ is shown to have a finite expected sample complexity. By proving a lower bound, we show the expected sample complexity of PS\u03b5BAI+ is optimal up to a logarithmic factor. We compare PS\u03b5BAI+ to baseline algorithms using numerical experiments which demonstrate its efficiency. Both our analytical and numerical results corroborate that the efficacy of PS\u03b5BAI+ is due to the delicate change detection and context alignment procedures embedded in PS\u03b5BAI.", "sections": [{"title": "1 Introduction", "content": "In stochastic multi-armed bandits (MABs), an agent interacts with the environment at each time step. The agent pulls an arm and observes the corresponding return provided by the environment. The classical MAB framework assumes a stationary environment where the expected return of each arm remains unchanged over time. However, we usually face ever-changing environments in real life. For instance, in investment option selection and portfolio management, fund managers want to select a subset of good candidate portfolios. However, the market may be bullish, bearish, or in some other state. The transition between these states can be well-modelled as being stochastic. We wish to select portfolios that yield the best long-term option under such a piecewise stationary environment. Further examples such as one based on agriculture in the face of stochastically changing weather patterns are discussed in detail in Appendix A. These motivate us to formulate and investigate a piecewise stationary linear bandit (PSLB) model.\nOur PSLB model is equipped with an arm set X, a context set \u0398 and a deterministic but unknown sequence of changepoints C. At each changepoint, the environment samples a context \u03b8\u2208 \u0398 from an unknown probability distribution P\u03b8, and the returns of arms may change when the context changes. The return of each arm under each context is determined by its feature x \u2208 X and the context \u03b8. In particular, the expected return of an arm is the weighted sum \\(\\mu_x = E_{\\theta \\sim P_{\\Theta}} [x^T \\theta]\\). While the sequence of changepoints, as well as the distribution and latent vectors of contexts are not known, the agent samples an arm and observes the corresponding return at each time step so that it can identify the best arm arg max \u03bcx up to some tolerance \u03b5 with probability > 1 \u2013 \u03b4 and with as few samples as possible. The agent's behavior does not affect the sequence of contexts that is drawn from P\u03b8.\nMain Contributions. We are the first to study the fixed-confidence best arm identification (BAI) problem in piecewise stationary bandits (PSB). Given \u03b4 > 0, we say the arm with the highest expected return \u03bc* is the best, and an arm is \u03b5-optimal if its expected return is at least \u03bc* \u2212 \u03b5. We seek to design an (\u03b5, \u03b4)-PAC algorithm which can identify an \u03b5-optimal arm with probability > 1 - \u03b4 in as few time steps as possible, i.e., with minimal sample complexity.\nOur first contribution concerns the formulation of a novel PSLB model, where we measure the quality of an arm x according to its expected return \\(\\mu_x = E_{\\theta \\sim P_{\\Theta}} [x^T \\theta]\\) for the following reasons. Consider that an arm is measured by its average return across time, which is a generalization of the definition in stationary bandits (SB). A notable feature of PSB models is that the context changes as time evolves, and hence the arm's average return across time also changes, in general. Hence, we aim to identify an arm whose average return across contexts is high, and benefits the agent for interacting with the environment in the long run after the arm identification task. We are thus inspired to introduce the distribution of contexts under the PSLB model, define the expected return \u03bcx for each arm, and use this ensemble (non-time varying) statistic as the benchmark for what we seek to learn. The BAI task using this statistic is meaningful but challenging, as the agent needs to reliably estimate the context vectors, changepoints, and context distribution.\nSecondly, we propose PIECEWISE-STATIONARY \u03b5-BAI+ (PS\u03b5BAI+), an algorithm designed to tackle the BAI problem in our PSLB model. We prove that it is (\u03b5, \u03b4)-PAC and bound its sample complexity. PS\u03b5BAI+ samples arms according to a suitably defined G-optimal allocation, and runs two algorithms: NA\u00cfVE \u03b5-\u0392\u0391\u0399 (\u039d\u03b5BAI) and PS\u03b5BAI as subroutines in parallel to achieve efficiency and attain a bound on the sample complexity in expectation.\n\u2022 Being a baseline but na\u00efve algorithm, the complexity of Ne\u0392\u0391\u0399 grows linearly with the maximum length between two changepoints Lmax, motivating us to design a more efficient algorithm, PS\u03b5BAI, to reduce the impact of Lmax.\n\u2022 PS\u03b5BAI is equipped with two delicately designed subroutines LINEAR-CHANGE DETECTION (LCD) and LINEAR-CONTEXT ALIGNMENT (LCA) to actively detect changepoints and align contexts with those observed in the previous time steps respectively. Concretely, in terms of the design, PS\u03b5BAI determines whether samples from two intervals are under the identical context via a sliding window mechanism, and detects changepoints and aligns contexts accordingly; this facilitates the estimation of context vectors and their distribution. Combining these elements into the design of PS\u03b5BAI and analyzing them requires some care. On the theoretical side, we prove PS\u03b5BAI identifies an \u03b5-optimal arm faster than N\u025bBAI with high probability. The success of PS\u03b5BAI relies on the LCD and LCA subroutines, while a minor drawback is that they require a non-vanishing failure probability budget which does not allow us to bound the sample complexity of PS\u03b5BAI in expectation. To achieve a complete theoretical understanding, we delicately design the PS\u03b5BAI+ algorithm whose efficiency is inherited via the LCD and LCA procedures in PS\u03b5BAI as well as the effective utilization of running PS\u03b5BAI and N\u025bBAI in parallel.\nThirdly, we derive a lower bound on the complexity of any (\u03b5, \u03b4)-PAC algorithm in PSLB models. To derive this bound, we first lower bound the complexity of an algorithm when the contextual information (and changepoints) are available, and then quantify the number of arm samples (and realized contexts) required to reliably infer an \u025b-best arm. We compare the upper bound of PS\u03b5BAI+ and this generic lower bound in several instances. The matching (up to logarithmic terms) of bounds illustrate that our PS\u03b5BAI+ algorithm is almost asymptotically optimal.\nLastly, we demonstrate the efficiency of PS\u03b5BAI+ with numerical experiments. The first half of our experiment shows that PS\u03b5BAI+ is (\u03b5, \u03b4)-PAC and with significantly lower sample complexity compared to N\u025bBAI, corroborating our theoretical findings. In the second half, we compare PS\u03b5BAI+ to N\u025bBAI, and two other benchmarks DISTRIBUTION \u03b5-BAI (D\u03b5BAI) and D\u03b5BAI\u00df. While contexts and changepoints are not available to PS\u03b5BAI+ and N\u025bBAI, they are observed by D\u03b5BAI and DEBAIB. Nevertheless, PS\u03b5BAI+ is still competitive compared to D\u03b5BAI and D\u03b5BAI\u00df in our"}, {"title": "2 Problem Setup", "content": "For m\u2208 N, let [m] := {1,2,...,m}. For a finite set S, let \\(\\Delta_S\\) denote the |S|-dim probability simplex on S. Let \\(A(q) := \\sum_{x \\in X} q_x x x^\\top\\) be the matrix induced by q \u2208 \u2206x with X \u2282 \u211d\u1d48. An instance of piecewise stationary linear bandit is a tuple \\(A = (X, \\Theta, P_{\\theta}, C)\\). Specifically, x \u2208 \u211d\u1d48 is an arm (vector) and the arm set X \u2282 \u211d\u1d48 is composed of |X| = K arms that spans \u211d\u1d48. The latent vector matrix \\(\\Theta = (\\theta_1, ..., \\theta_N) \\in \\mathbb{R}^{d \\times N}\\) contains N latent column vectors where the jth column \\(\\theta_j\\) is associated with context j \u2208 [N]. For the sake of normalization, we assume \\(|x^T\\theta| \\leq 1\\) for all x \u2208 X, j \u2208 [N]. Let P\u03b8 denote the distribution (probability mass function) of the latent vectors and pj = P\u03b8[\u03b8]. We represent the probabilities of latent vectors as p = (p1,...,pN) \u2208 \u0394N. The fixed but unknown sequence of changepoints C := (c1, c2, . . .) is an sequence of increasing positive integers 1 = c1 < c2 < . . ., characterizing all the changepoints (time steps).\nThe return of arm x under latent context j is a random variable \\(Y = x^\\top\\theta_j + \\eta\\), where \u03b7 is a zero-mean random variable (noise) supported on [-1,1], and the expected return of arm x is \\(\\mu_x := E_{\\theta \\sim P_{\\Theta}} [x^T\\theta] = \\sum_{j=1}^N P_{\\Theta}[\\theta] x^T\\theta\\). The best arm, which we assume is unique, is denoted as \\(x^* := \\arg \\max_{x \\in X} \\mu_x\\) with mean \\(\\mu^* := \\mu_{x^*}\\). Given a slackness parameter \u03b5 > 0, we define the set of \u03b5-best arms \\(X_\\epsilon := \\{ x \\in X : \\mu_x \\ge \\mu^* - \\epsilon \\}\\). For each pair of arms (x, x\u0303) \u2208 X\u00b2, define the contextual mean gap between x and x\u0303 under latent context j as \\(\\Delta_j(x, \\tilde{x}) := (x - \\tilde{x})^T \\theta_j\\) and the mean gap between x and x\u0303 as \\(\\Delta(x, \\tilde{x}) := \\mu_x - \\mu_{\\tilde{x}}\\).\nGiven l \u2208 N, the interval (cl, . . ., cl+1 \u2212 1) is known as the lth stationary segment and its length is \\(L_l := c_{l+1} - c_l\\). We assume Lmin \u2264 Ll < Lmax. Let lt := max{l : cl \u2264 t} denote the number of"}, {"title": "3 Algorithms", "content": "We first devise the NA\u00cfVE E-BEST ARM IDENTIFICATION (or N\u03b5BAI) algorithm (presented in Algorithm 2). In the design of N\u03b5BAI, only the choice of confidence radius pt takes the potential context changes into consideration. Even though N\u03b5BAI does not attempt to detect potential changes in the context, it can identify an \u03b5-optimal arm w.h.p. and is with a finite expected sample complexity.\nProposition 3.1. Let \\(\\Delta_{\\min} = \\min_{x \\neq x^*} \\Delta(x^*, x)\\),\n\\(\\tau = \\frac{d}{(\\epsilon + \\Delta_{\\min})^2} \\ln \\frac{1}{\\delta}\\) and \\(T_N = \\frac{L_{\\max}}{(\\epsilon + \\Delta_{\\min})^2} \\ln \\frac{1}{\\delta}\\).\nThe N\u03b5BAI algorithm is (\u03b5, \u03b4)-PAC and its expected sample complexity is \\(\\tilde{\\mathcal{O}}(T_{\\mathcal{V}} + T_N)\\).\nThe upper bound in Proposition 3.1 (also see Appendix F) consists of two main terms. (i) As \u039d\u03b5\u0392\u0391\u0399 samples arms according to the G-optimal allocation (see Appendix D), the amount of samples needed to estimate the average of latent vectors \\(\\sum_{i=1}^N \\theta_i /t\\) contributes to \\(T_{\\mathcal{V}}\\). (ii) TN quantifies how fast \\(\\sum_{i=1}^N \\theta_i /t\\) converges to the expectation of context vectors \\(\\sum_{i=1}^N P_\\theta\\).\nThe sample complexity of N\u03b5BAI grows linearly with Lmax, but we surmise that the sample complexity of a close-to-optimal algorithm should have a reduced dependence on Lmax.\nThe algorithm PIECEWISE-STATIONARY \u03b5-BEST ARM IDENTIFICATION (or PS\u03b5BAI) is presented in Algorithm 1. By using a sliding window mechanism, PS\u03b5BAI actively detects the change- points and aligns the current latent context with contexts observed in the previous time steps via LINEAR-CHANGE DETECTION (or LCD) and LINEAR-CONTEXT ALIGNMENT (or LCA), which are presented in Algorithms 3 and 4 (see App. D.2.2), respectively. PS\u03b5BAI consists of three phases: (i) Exploration phase (Exp): Estimate latent vectors and their distribution P\u03b8 (Lines 8 to 11 and 25); (ii) Change Detection phase (CD): Detect changepoints (Lines 12 to 16); (iii) Context Alignment phase (CA): Evaluate the current context and align it with the contexts observed in previous time steps (Lines 17 to 21)."}, {"title": "3.2.1 Theoretical guarantee of PS&BAI", "content": "To facilitate the analysis of PS\u03b5BAI, we propose the following assumptions. Note that our PS\u03b5BAI algorithm may still succeed to identify an \u03b5-optimal arm w.h.p. when the assumptions do not hold.\nAssumption 1 (Distinguishability Condition). The agent can choose \u03c9, \u03b3 and b such that (1) 2b < Ac where Ac := mino\u22600 maxxex |xT (\u03b8 - \u03b8)| is the minimum gap between two contexts; and (2) 3\u03c9\u03b3 < Lmin. A possible choice is\n\\begin{equation}\n\\begin{aligned}\nb & = \\frac{8d}{3\\omega} \\ln \\frac{2}{\\delta_{FAE}} + \\sqrt{\\left( \\frac{8d}{3\\omega} \\ln \\frac{2}{\\delta_{FAE}} \\right)^2 + \\frac{24d}{\\omega} \\ln \\frac{\\gamma}{\\delta_{FAE}}}, \\text{where} \\quad \\delta_{FAE} = \\frac{\\gamma \\delta}{4(\\tau^*)^2 K} \n\\end{aligned}\n(3.5)\n\\end{equation}\nThis assumption guarantees (i) PS\u03b5BAI will not abandon all samples during the reversion procedure (Line 21 of Algorithm 1); (ii) each two latent vectors can be distinguished if the window size w is sufficiently large (e.g., Lmin/6). We clarify that this assumption is only for the rigor of theoretical guarantees and it holds provided that each stationary segment is sufficiently long; this is a feature of PSB models and similar assumptions are also present in existing works for their analyses [21, 10, 22]. We demonstrate the robustness of PS\u03b5BAI to these parameters using experiments in Section 6.\nTheorem 3.2. Define the context distribution estimation (DE) hardness parameter\n\\begin{equation}\nH_{DE}(X_\\epsilon, X) := \\frac{L_{\\max}}{((\\Delta(x^*,x)+\\epsilon)^2} \\sum_{j=1}^N \\min \\left\\{ \\frac{1}{16p_j}, \\frac{1}{4} \\right\\} |\\Delta_j(x_\\epsilon, x)+\\epsilon|^2.\n(3.6)\n\\end{equation}\nUnder Assumption 1, with probability at least 1 \u2212 \u03b4, PS\u03b5BAI identifies an \u03b5-optimal arm and its sample complexity is\n\\begin{equation}\n\\tilde{O}\\left(\\max_{\nx \\in X_{\\epsilon}, x\\neq x^*} \\left{\\frac{d}{(\\Delta(x^*, x) + \\epsilon)^2} \\ln \\frac{1}{\\delta} + \\frac{H_{DE}(X_{\\epsilon}, x)}{\\epsilon^2} \\ln \\frac{N}{\\delta} + \\frac{N L_{\\max}}{\\Delta(x^*,x) + \\epsilon} \\ln \\frac{1}{\\delta} \\right}\\right),\n\\end{equation}\nThe upper bound comprises three terms which serve distinct purposes:\n(i) Latent vector estimation (VE): \\(\\tilde{O} \\left(T_\\mathcal{V}(x)\\right)\\) quantifies the bulk of samples needed to obtain a good estimate of latent context vectors such that the returns of xe and x can be distinguished, where Xe is an \u03b5-best arm and x \u2209 X is a suboptimal arm. T\\mathcal{V}(x) recovers the sample complexity in the stationary linear bandits in [1], indicating that PS\u03b5BAI estimates latent vectors efficiently.\n(ii) Context distribution estimation (DE): \\(\\tilde{O} \\left(T_\\mathcal{D}(x_{\\epsilon}, x)\\right)\\) characterizes the bulk of samples needed to learn the distribution of latent context vectors.\n(iii) Residual estimation (RE): \\(\\tilde{O} \\left(T_R(x)\\right)\\) counts the remaining samples needed for VE and DE, in addition to O (T\\mathcal{V} + T\\mathcal{D}).\nBesides, the max operator is applied to exclude all suboptimal arms. We also see that T\\mathcal{V}(x) and TD(xe, x) are similar to TV and TN in Proposition 3.1 respectively.\nFirstly, the bound in (3.6) implies that, in an instance with smaller relaxed mean gap (\u2206(x*, x) + \u03b5), PS\u03b5BAI terminates after a larger number of time steps; in other words, it is more difficult to identify an \u03b5-optimal arm. In difficult instances with small \u2206(x*, x) + \u03b5, the different orders of this term in T\\mathcal{V}(x), TD(xe, x) and TR(x) indicate that, TR(x) is small compared to T\\mathcal{V}(x) and TD(x\u025b, x).\nSecondly, DE solely utilizes context samples generated with P\u03b8 and they are generated only at changepoints in C, while all the observations in Exp phases facilitate VE. From this perspective, there are less samples that can be used for DE than for VE as PS\u03b5BAI processes, and hence TD(xe, x) is supposed to be with larger order than T\\mathcal{V}(x).\nMoreover, for the purpose of DE, PS\u03b5BAI needs to observe context samples at \\(H(x,x)\\) changepoints where Lmax is the maximum length of a\nstationary segment, leading us to \\(T_\\mathcal{D}(x_{\\epsilon}, x) = \\tilde{O}\\left(H_{DE}(x_{\\epsilon},x) \\frac{L_{\\max}}{(\\Delta(x^*,x)+\\epsilon)^2} \\ln \\frac{N}{\\delta}\\right)\\). Close examination of the definition of H (xe, x) reveals that both the vectors and their probabilities influence the number of samples needed for DE. The comparison between TD(x\u025b, x) and TN in Proposition 3.1 clearly indicates that PS\u03b5BAI mitigates the influence of Lmax by detecting changepoints and aligning the detected context with observed ones, while N\u025bBAI does not do so."}, {"title": "3.3 PS\u03b5BAI+ = PS\u03b5\u0392\u0391\u0399 \u222a \u039d\u03b5\u0392\u0391\u0399", "content": "We have provided a high-probability result for PS\u03b5BAI in Theorem 3.2. The design of PS\u03b5BAI (Line 7 of Algorithm 1) indicates that PS\u03b5BAI will not recommend any arm if it does not terminate at time \u03c4*. This result is nontrivial, as the high-probability result in Theorem 3.2 depends on the success of change detection (Algorithm 3) and context alignment (Algorithm 4), which requires a non-vanishing failure probability (e.g., \u03b4/2). Thus, we cannot derive an upper bound on the expected sample complexity of PS\u03b5BAI. We devise a solution by designing the Piecewise-Stationary \u03b5-Best Arm Identification+ (PS\u03b5BAI+) algorithm with a simple but effective trick.\nThe PS\u03b5BAI+ algorithm samples one arm with the G-optimal allocation \u03bb* at each time step, with which Algorithms 1 and 2 are executed in parallel (detailed in Algorithm 5). This is feasible since PS\u03b5BAI and N\u03b5BAI algorithms have the same sampling rule.\nTheorem 3.3. The PS\u025bBAI+ algorithm is (\u03b5, \u03b4)-PAC and its expected sample complexity is\n\\begin{equation}\n\\tilde{O}\\left(\\min \\left\\{\\max_{x \\in X_{\\epsilon}, x \\neq x, x^*} \\left{T_\\mathcal{V}(x) + T_\\mathcal{D}(x_{\\epsilon}, x) + T_R(x)\\right\\}, T_\\mathcal{V} + T_N\\right\\}\\right).\n\\end{equation}\nPS\u03b5BAI+ inherits the superiority of PS\u03b5BAI to adapt to the piecewise stationary environment, and employs the stopping rule of N\u03b5BAI to maintain a finite expected sample complexity. As a result, the expected complexity of PS\u03b5BAI+ in Theorem 3.3 is of the same order as the high-probability one of PS\u03b5BAI in Theorem 3.2 and is not larger than the complexity of N\u025bBAI in Proposition 3.1. We show how our results particularize to the stationary linear bandits BAI problem, as well as additional discussions on the upper bound, in Appendix P."}, {"title": "4 Lower Bound on the Sample Complexity", "content": "Given \\(A = (X, \\Theta, P_{\\theta}, C)\\), define the alternative instance \\(\\Lambda' = (X, \\Theta', P_{\\theta'}, C)\\) w.r.t. \u039b, where \\(\\Theta' = (\\theta_1', ..., \\theta_N') \\in \\mathbb{R}^{d \\times N}\\), \\(P_{\\theta'}[\\theta'_j] = P_{\\theta}[\\theta]\\), and there exists x \u2208 X \\ X\u03b5, such that \\(x^T E_{\\theta' \\sim P_{\\Theta'}}[\\theta'] < x^T E_{\\theta' \\sim P_{\\Theta'}}[\\theta'] - \\epsilon\\) for all \\(x_{\\epsilon} \\in X_{\\epsilon}\\). Let \\(Alt_{\\Theta}(A)\\) be set of all alternative instances (w.r.t. \u039b).\nTheorem 4.1. For all (\u03b5, \u03b4)-PAC algorithm \u03c0, there exists an instance A = (X, \u0398, P\u03b8, C) such that\n\\begin{equation}\n\\mathbb{E}[T] \\ge \\max \\left\\{T_\\epsilon(\\Lambda) \\ln \\frac{1}{2.4\\delta}, T_{\\epsilon}(\\Lambda) \\ln \\frac{N_c}{8\\delta} \\right\\},\n\\end{equation}\nwhere\n\\begin{equation}\nT_\\epsilon(\\Lambda)^{-1} := \\max_{\n{v_j} \\in \\Delta_X}  \\min_{\n\\Lambda' \\in Alt_{\\Theta}} \\frac{\\left(\\sum_{j=1}^N p_j \\sum_{x \\in X} \\upsilon_j,x (x^T(\\theta^* - \\theta_j))^2\\right)^2}{\\sum_{j=1}^N p_j ||x^* - x_{\\Lambda(\\upsilon_j)}||^2_{\\Lambda(\\upsilon_j)^{-1}} },\n\\end{equation}\nand\n\\begin{equation}\nN_c := \\max_{x \\neq x^*} \\frac{1}{4} \\left(\\frac{\\sum_{j=1}^N p_j (\\Delta_j (x^*, x) +\\epsilon)^2}{((\\Delta(x^*, x)+\\epsilon)^2} \\right)^2 \\ln \\frac{1}{4\\delta}.\n\\end{equation}\nRecall that CNC is the Nc-th changepoint in the changepoint sequence C, which is lower bounded by NcLmin and is Nc Lmax in the worst case. To derive the lower bound in Theorem 4.1, we investigate two environments different from the one defined in Section 2 (and as in Dynamics 1):\n\u2022 Dynamics 2: the agent observes the index of current context jt (i.e., contextual linear bandits);\n\u2022 Dynamics 3: the agent observes the changepoints in C and context vector \u03b8's, and hence she solely needs to estimate the distribution of contexts.\nWe bound the sample complexity of an (\u03b5, \u03b4)-BAI algorithm in Dynamics 2 and 3 respectively, which when combined, yield the lower bound in Theorem 4.1; this is detailed in Appendix M.\nNote that T\u03b5 (\u039b)\u22121 in the lower bound generalizes [16] to the setting of linear bandits. In addition, Theorem 4.1 can be reduced to a bound in stationary linear bandits with one latent vector [24] (see the discussion leading to (M.15))."}, {"title": "5 On the Asymptotic Optimality of PS\u03b5BAI+", "content": "To illustrate the efficiency of our PS\u03b5BAI+ algorithm, we compare the upper bound on its expected sample complexity in Theorem 3.3 and the generic lower bound in Theorem 4.1 under specific instances below and in Appendix N. We also gain further insight into our PS\u03b5BAI+ algorithm."}, {"title": "6 Numerical Experiments", "content": "We now evaluate the empirical performance of PS\u03b5BAI+. We utilize the instance defined in Example 1 with d = 2, \u03c6 = \u03c0/8, We generate a changepoint sequence C such that ci+1 = ci + Li with Lmin = 3 \u00d7 104, Lmax = 5 \u00d7 104, P[Li = Lmin] = 0.8, P[Li = Lmax] = 0.2, and fix it throughout the whole set of experiments. We set the confidence parameter \u03b4 = 0.05 and vary the slackness parameter \u03b5 from 0.04 to 0.6 (i.e., \u03b5 = 0.03 \u00d7 1.35k for k \u2208 [12]). We set \u03b3 = 6, the window size w = Lmin/(3) and compute b via (3.5) in Assumption 1.3 For each choice of algorithm and instance, we run 20 independent trials. All the code to reproduce our experiments can be found at https://github.com/Y-Hou/BAI-in-PSLB.git.\nWe first compare PS\u03b5BAI+ and N\u025bBAI. Both algorithms succeed to identify an \u025b-optimal arm, while empirically, the complexity of PS\u03b5BAI+ is < 1% of that of N\u025bBAI. The empirical averages and standard deviations of the sample complexities of both algorithms are presented in Figure 2(a)."}, {"title": "7 Conclusion and Future Work", "content": "We proposed a novel PSLB model and designed the PS\u03b5BAI+ algorithm to identify an \u025b-optimal arm with probability > 1 \u2013 \u03b4. The efficacy of PS\u03b5BAI+ has been demonstrated both empirically and theoretically. We argued that this is due to the embedded change detection and context alignment procedures. There are several directions for further exploration.\nFirstly, our PS\u03b5BAI+ algorithm provides a fairly general framework for algorithm design. For instance, in addition to utilization the G-optimal allocation to sample arms as in PS\u03b5BAI+, the XY-allocation and adaptive XY-allocation [1] can also be considered. In other words, our PS\u03b5BAI+ algorithm can be generalized to form an entire class of algorithms for BAI in PSLB models. In addition, deriving instance-dependent guarantees is also of great interest.\nSecondly, most of the literature on piecewise-stationary bandits [21, 10, 22] make assumptions to provide theoretical guarantees. It would be interesting to remove or reduce these assumptions under our \u03b5-BAI problem setup, and yet still be able to provide similar theoretical guarantees.\nFinally, we believe that it is possible to adapt our PS\u03b5BAI+ algorithm to the fixed-budget setting, i.e., to identify an \u025b-optimal arm with high probability in a fixed time horizon in PSLB models."}, {"title": "A Further Motivating Examples", "content": "We elaborate on the some concrete real-life examples that motivate our problem setup of identifying the ensemble best arm in piecewise-stationary linear bandits.\nIn scenarios such as investment option selection and portfolio management also mentioned by [10, 20], there is a multitude of options for fund managers to choose from and typically, they want to find, in the initial pure exploration process, a small subset of candidate portfolios (or even the \u201cbest\u201d portfolio) based on various economic indicators and the market performance of individual stocks before further exploitation. In a bearish market, more portfolios tend to incur losses; while in a bullish market, more portfolios tend to generate gains. The transition between these two contexts can be effected by stochastic factors, e.g., the weather, or the outbreak of a pandemic, making the market conditions (contexts) stochastic. In the face of these uncertainties (in the contexts and rewards), we wish to design and analyze algorithms that selected portfolio to yield the best long-term option under such a piecewise-stationary environment.\nCrop rotation is another example. Since crop yields can be influenced by various factors, such as weather conditions (analogous to our stochastically generated contexts), selecting the most suitable crop to grow and harvest from is crucial. Given several candidate crops, crops of similar types (e.g., potatoes and sweet potatoes) are correlated as they tend to favor similar conditions, thus, they can be"}, {"title": "B Limitations", "content": "Similar to existing works on piecewise stationary bandits [21, 10, 22], we introduced some assump- tions to provide theoretical guarantees for PS\u03b5BAI+ although PS\u03b5BAI+ has shown to be robust even in the absence of these assumptions. Since an algorithm may not need to differentiate two contexts with close latent vectors for identifying an \u025b-optimal arm, we surmise it is possible to weaken these assumptions. For this purpose, we will consider clustering the contexts into a few classes based on the distances between their latent vectors and design an algorithm that only aims to detect the change of context class, instead of the change of context."}, {"title": "C More Related Work", "content": "In drifting bandits (DB), the regrets of algorithms are affected by the level of nonstationarity of the environment, which can be measured by various quantities, such as the total variation of the context sequence and the number of time steps when the return of at least one arm changes [23, 25].\nIn contextual bandits (CB), where the contextual information is visible to the agent, [16, 26, 17, 27] aim to identify the best arm with the assumption that the context changes at every time step according to a fixed distribution, and the return of an arm is averaged across all contexts. We see that the context distribution is involved to measure the quality of arms. However, while the agent in CB models can observe the context information, the agent has no access to the contexts but still aims to identify an \u025b-optimal arm in our piecewise stationary linear bandit (PSLB) model.\nIn adversarial bandits, existing works pertaining to the BAI problem only explored the fixed-horizon setting [28]. Due to the difference between the fixed-confidence and fixed-horizon setting and the difference between adversarial and piecewise stationary bandits, their results cannot be trivially extended to solve the fixed-confidence BAI problem in piecewise stationary bandits."}, {"title": "D More Details of Algorithms N\u03b5BAI, PS\u03b5BAI and PS\u03b5BAI+", "content": "All proposed algorithms make use of the well known G-optimal allocation (design) [1, 29], which is widely used in the linear bandits literature. The G-optimal allocation minimizes the maximal mean-squared prediction error in all directions [1]. Given an arm set X, the G-optimal allocation \u03bb* is a distribution over the arm set, which is the minimizer of \\(g(x) = \\max_{x \\in X} ||x||^2_{A(\\lambda)^{-1}}\\, where A(\u03bb) = \u2211x\u2208X \u03bb(x)xxT and \u03bb\u2208 \u2206x. Interested readers may refer to Chapter 21 in [29].\nAs presented in Algorithm 2, N\u03b5BAI samples an arm with the G-optimal allocation at each time steps; its stopping rule is grounded on the property of G-optimal allocation (see Lemma E.1) and affected by the maximum length of a single stationary segment Lmax."}, {"title": "F Analysis of N\u03b5\u0392\u0391\u0399", "content": "To analyze the theoretical performance of N\u03b5BAI, we first show that it can identify an \u03b5-optimal arm with probability 1 \u2013 \u03b4 and derive a high-probability upper bound on its stopping time in Lemma F.1.\nLemma F.1 (High-probability upper bound of N\u025bBAI). With probability 1 \u2013 \u03b4, the N\u025bBAI algorithm identifies an e-optimal arm after at most\n\\(\\tilde{O}\\left( \\frac{L_{\\max}}{(\\epsilon + \\Delta_{\\min})^2} \\ln \\frac{1}{\\delta} \\right)\\)\ntime steps, where \\(\\Delta_{\\min} = \\min_{i\\neq i^*} \\Delta(x^{i^*}, x^i)\\).\nNext, we prove that after a sufficiently large number of time steps, the probability that N\u025b\u0392\u0391\u0399 does not terminate is small in Lemma F.2.\nLemma F.2. Let\n\\[T_0 = \\frac{768(8L_{\\max} + 25d)}{(\\epsilon + \\Delta_{\\min})^2} \\ln \\frac{768KC_3 (8L_{\\max} + 25d)}{(\\epsilon + \\Delta_{\\min})^2 \\delta} \\]\nWith \\(C_3 = \\sum_{n=1}^{\\infty} n^{-3}\\). For \\(t > T_0\\), the probability that N\u025bBAI does not terminate before t time steps is\n\\[O\\left( \\frac{\\delta}{(a-1)C_3(t/2)^{a-1}} \\right)\\]\nLastly, we apply Lemmas F.1 and F.2 to prove Proposition 3.1."}, {"title": "G Proof Outline of Theorem 3.2", "content": "A proof outline of Theorem 3.2 is provided in this section. It consists of three steps:\nStep 1: PS\u03b5BAI (Algorithm 1) depends on the success of change detection and context alignment (Algorithm 3 and 4). We firstly upper bound the failure probability of these two subroutines via Lemma G.1", "2": "Subsequently", "3": "Lastly, utilizing the above elements, we provide a sufficient condition for the stopping rule, and upper bound the number of time steps in Exp phases T, via Lemma G.6 whose proof is presented in Appendix J. As the total number of time steps \u03c4 is upper bounded by a constant multiple of T"}]}