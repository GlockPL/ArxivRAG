{"title": "SpectralEarth: Training Hyperspectral Foundation Models at Scale", "authors": ["Nassim Ait Ali Braham", "Conrad M Albrecht", "Julien Mairal", "Jocelyn Chanussot", "Yi Wang", "Xiao Xiang Zhu"], "abstract": "Foundation models have triggered a paradigm shift in computer vision and are increasingly being adopted in remote sensing, particularly for multispectral imagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped due to the absence of comprehensive and globally representative hyperspectral datasets. To close this gap, we introduce SpectralEarth, a large-scale multi-temporal dataset designed to pretrain hyperspectral foundation models leveraging data from the Environmental Mapping and Analysis Program (EnMAP). SpectralEarth comprises 538,974 image patches covering 415,153 unique locations from more than 11,636 globally distributed EnMAP scenes spanning two years of archive. Additionally, 17.5% of these locations include multiple timestamps, enabling multi-temporal HSI analysis. Utilizing state-of-the-art self-supervised learning (SSL) algorithms, we pretrain a series of foundation models on SpectralEarth. We integrate a spectral adapter into classical vision backbones to accommodate the unique characteristics of HSI. In tandem, we construct four downstream datasets for land-cover and crop-type mapping, providing benchmarks for model evaluation. Experimental results support the versatility of our models, showcasing their generalizability across different tasks and sensors. We also highlight computational efficiency during model fine-tuning. The dataset, models, and source code will be made publicly available.", "sections": [{"title": "1. Introduction", "content": "Hyperspectral imaging (HSI) from space provides valuable information about the material composition of the Earth's surface and atmosphere. With hundreds of narrow bands, each a few nanometers in width, hyperspectral images record detailed electromagnetic information across a wide range of wavelengths, from long-wave ultraviolet to the shortwave infrared [39]. This rich spectral information provides opportunities for numerous environmental applications such as soil and mineral mapping, pollution tracking, agricultural assessment, and forest monitoring [13, 35, 45, 61, 62].\nIn recent years, the availability of hyperspectral data has been significantly expanded by the launch of new satellite missions. Notable examples include: Germany's Environmental Mapping and Analysis Program (EnMAP) [37] with precursor Earth Sensing Imaging Spectrometer mission (DESIS) [38] mounted to the International Space Station (ISS), Italy's Hyperspectral Precursor and Application Mission (PRISMA) [52], and the European Space Agency's upcoming Copernicus Hyperspectral Imaging Mission for the Environment (CHIME) [53]. These developments open new avenues to employ deep learning and Self-Supervised Learning (SSL) for large-scale HSI analysis."}, {"title": "2. Related Work", "content": "2.1. Hyperspectral Datasets\nTraditionally, hyperspectral benchmark datasets have been limited in geographical coverage, often confined to a single or a limited number of scenes [3, 30, 49, 60]. This limitation primarily roots in the expenses associated with air-"}, {"title": "2.2. Self-Supervised Learning for Remote Sensing", "content": "SSL emerged as a powerful paradigm for learning representations from unlabeled data [36]. Early SSL methods were based on engineered pretext tasks to encourage the model to learn distinct features by solving auxiliary problems such as image colorization [71], jigsaw puzzles [48], or rotation angle prediction [21]. Recently, progress in SSL has been primarily focused on two families of methods:\n1. Joint-Embedding Architectures: These methods train models to generate consistent representations for augmented views of the same input, enforcing invariance to these augmentations. To avoid convergence to trivial"}, {"title": "3. SpectralEarth & Benchmarks", "content": "This section introduces the SpectralEarth dataset and related downstream datasets for benchmarking. Additional details are provided in Appendix.\n3.1. SpectralEarth\nData Acquisition. The EnMAP data was sourced from the DLR GeoPortal. A total of 11,636 tiles were retrieved via the portal's graphical interface through a significant manual effort. All tiles were carefully selected based on human visual inspection. Cloud coverage was kept below ~10%. The selection process encompassed the entire EnMAP archive from April 2022 to April 2024. All acquired tiles underwent radiometric, geometric, and atmospheric corrections, resulting in Level-2A products.\nData Pre-processing. The EnMAP tiles have been split into geospatial patches-each of size 128x128 pixels where an individual pixel includes 224 bands. Bands dominated by water absorption were excluded due to the frequent presence of missing values (no-data). Removing those badns is a common practice in hyperspectral dataset creation [19, 60]. As a result, the total number of bands per image reduced to 202."}, {"title": "Temporal Views Extraction", "content": "To exploit all available tiles, we utilized overlaps between EnMAP data acquisitions to generate time series of EnMAP patches\u00b9. At the same time SpectralEarth data patches for a fixed geolocation never overlap. This process required (a) identification of tiles that overlap spatially to (b) extract patches from the intersection of those tiles. Time series include valuable information on landscape evolution and provide characteristic signals for seasonal variation-an asset for contrastive learning [46, 65]. Algorithm 1 outlines the steps taken to generate temporal positives by high-level pseudo-code.\nAs a result of Algorithm 1 we identified a few long time series in the EnMAP archive. Those involving more than 25 intersecting tiles. Calculating intersections of all subsets was computationally intractable due to combinatorial explosion. To address this, we implemented several heuristics to optimize the computation:\n1. Consider only a subset of possible intersections using a breadth-first search (BFS) approach.\n2. Avoid redundant computations across tiles.\n3. Parallelization of the code across all connected components of the overlap graph.\nFollowing this approach, we extracted 73,307 non-overlapping locations with multiple timestamps. For areas"}, {"title": "3.2. Downstream Tasks", "content": "To evaluate the models pretrained on SpectralEarth, we assembled four downstream datasets for benchmarking. Each benchmark involves a subset of EnMAP or DESIS images, aligned with specific geospatial products with focus on specific aspects of land cover and agricultural analysis. While the labels in these datasets carry some inherent uncertainty, they are sufficiently accurate for a proof-of-concept evaluation of model performance. Similar strategies have previously been employed to create remote sens-"}, {"title": "4. Hyperspectral Foundation Models", "content": "This section presents the design choices behind our models, including the choice of SSL algorithms and network architecture."}, {"title": "4.1. Pre-training Algorithms", "content": "Hyperspectral data has very different characteristics compared to natural images. Therefore, traditional SSL leaderboards in computer vision may not directly translate to the hyperspectral domain. To address this gap, we explore a broad range of SSL methods to establish a set of baseline pretrained models for hyperspectral imagery. We use MoCo-V2 [26] and DINO [12] for their effectiveness in frozen encoder performance [51] and their compatibility with both CNNs and ViTs. Furthermore, we include MAE [27] for its strong performance in fine-tuning scenarios. Together, these methods form a representative set of algorithms to investigate SSL in the hyperspectral domain."}, {"title": "4.2. Network Architectures", "content": "Since we aim for large-scale coverage and pre-training with spaceborne imagery, our models must operate on large patches instead of pixels or small patches, as traditionally done in the hyperspectral literature. Most models developed at the pixel level in HSI literature do not scale well with large patches [28, 29, 72]. On the other hand, models like ResNet [24] and ViT [18] are designed to handle larger spatial contexts. Therefore, we seek to adapt these architectures for hyperspectral imaging. A key challenge is that classical ResNet and ViTs treat spectral bands independently, failing to capture the correlations between adjacent bands and the overall characteristics of the spectrum. Our models should address the following requirements for hyperspectral imaging:\n\u2022 Spectral Feature Extraction: We aim to extract features from both the spatial and the spectral domain.\n\u2022 Adaptability to Diverse Sensors: The architecture should accommodate variability in the number of spectral bands. This property is important when transferring pretrained models to different sensors.\n\u2022 Preserving Fine-Grained Details: Natural images often deal with large objects compared to medium-resolution remote sensing data. Therefore, the spatial downscaling in classical vision models can lead to a significant loss of details. Our architecture needs to preserve this fine-grained information.\n\u2022 Computational Efficiency: 3D convolution or tokenizing the image in the spectral dimension is computationally expensive for large models. We seek for adaptation of classical architectures with minimal overhead.\nTo meet these requirements, we follow a pragmatic approach and implement a simple modular design, integrating 1D convolutional layers as a Spectral Adapter at the onset of the standard vision backbones, as depicted in Figure 7. These layers perform convolutions across the spectral dimension, generating feature maps for the core backbone. Specifically:\n\u2022 Spectral ResNet: We replace the stem layers with three 1D convolutional layers and pooling, allowing the network to process spectral information effectively before the residual backbone. By removing the original stem layers in the ResNet architecture, we avoid the 4x downscaling factor of the image to better capture fine-grained details.\n\u2022 Spectral ViT: The 1D convolutions and pooling are placed before the patch embedding layer, ensuring that the transformer receives fixed-size spectral features as input. We use 4x4 patches instead of the typical 16x16 patches, which helps maintain fine spatial details and better preserves spectral information at the patch projection layer.\nThis simple strategy results in an architecture that can be used on various hyperspectral sensors while leveraging a lightweight adapter for spectral feature extraction. Similar designs have been used effectively for spectral-spatial classifiers in the HSI literature [1]. Our approach extends this idea to foundation models, enabling the extraction of both spatial and spectral features while avoiding the extra computational cost incurred by 3D convolutions or spatial-spectral tokenization in ViTs."}, {"title": "5. Experimental Setup", "content": "5.1. Self-Supervised Pre-training\nWe pre-train a spectral ResNet-50 (Spec. RN50) and a spectral ViT-S (Spec. ViT-S) with MoCo-V2, DINO, and MAE. For larger models, Spec. ViT-Base(B)/Large(L)/Huge(H)/Giant(g), we restrict the experiments to MAE given the high computational cost. For ViT-g, we follow the implementation from [51]. We use the augmentations from SimCLR [14] without color-jittering and gray-scale for DINO and MoCo-V2 to avoid distorting spectral information. When available, we use the"}, {"title": "5.2. Downstream Tasks", "content": "Multi-label classification on EnMAP-CORINE. We append a linear layer to the pretrained encoders and train the models with Binary Cross-Entropy loss for 100 epochs.\nSemantic segmentation on EnMAP-CDL/-NLCD and DESIS-CDL. We use a lightweight transfer protocol for the segmentation tasks, following previous works [22, 26]. We train for 100 epochs with a cross-entropy loss. The pretrained encoders are converted into segmentation models as follows:\n\u2022 ResNet: We remove all strides from convolutions, replace them with atrous convolutions, and append two final convolutional layers.\n\u2022 ViT: We reshape the tokens from the last layer and add two additional convolutional layers with upscaling to recover the full spatial resolution.\nParameter regression on Hyperview. We use the training set of the Hyperview challenge [49] to evaluate cross-sensor transferability. Hyperview is a soil parameter estimation dataset comprising 1,732 hyperspectral patches with 150 spectral bands. Each patch is annotated with four soil parameters, including potassium (K), phosphorus pentoxide (P2O5), magnesium (Mg), and acidity pH. For this downstream task, we append two fully connected layers to the backbones. The models are optimized based on the normalized MSE criterion defined in Section 5.4 with the AdamW optimizer for 200 epochs."}, {"title": "5.3. Evaluation Protocols", "content": "We consider multiple evaluation protocols with various levels of fine-tuning of the pretrained models.\n\u2022 Frozen Encoder: Evaluates the quality of learned representations without fine-tuning the backbone. It is the most common evaluation protocol in the SSL literature [7, 51].\n\u2022 Fine-tuning: Fine-tuning of all model parameters on downstream datasets to evaluate the transferability of the pretrained weights.\n\u2022 Fine-tuning Adapter: While frozen encoder evaluation is a common measure of the quality of learned representations, it does not yield optimal results. In remote sensing, it is often beneficial to adapt the model to the specific distribution of the downstream dataset, which can be influenced by several factors: geo-location, atmospheric conditions, seasonal changes, etc. Additionally, the relevance of individual spectral bands may vary depending on the downstream task. Therefore, we consider an intermediate setting where only the initial spectral adapter block is fine-tuned."}, {"title": "5.4. Evaluation Metrics", "content": "Depending on the nature of the downstream task, we report the following metrics:\n\u2022 Classification: The multi-label F1-score is reported for the EnMAP-CORINE dataset.\n\u2022 Segmentation: The mean Intersection over Union (mIoU) is reported for the EnMAP-CDL, EnMAP-NLCD and DESIS-CDL datasets.\n\u2022 Regression: For the Hyperview dataset, we follow the metric defined in the challenge [49]: let $MSE_i, i \\in [1, 4]$ be the mean squared error of the predictor for soil parameter i. Let $MSE_{base}$ be the corresponding MSE of a base predictor returning the mean value of the soil parameter, calculated over the training set. The reported normalized MSE is defined as: $MSE_{norm} = \\sum_{i=1}^{4}MSE_i/MSE_{base}$."}, {"title": "6. Benchmark Results", "content": "Our main results are summarized in Tables 2 and 3. We include random initialization baselines for each downstream task, along with our pretrained models. Due to hundreds of spectral channels of the SpectralEarth patches, a comparison with RGB-ImageNet weights or multispectral pretrained models is of little use.\n6.1. Comparing SSL Algorithms\nTable 2 summarizes our results for three SSL algorithms with the Spec. RN50 and Spec. ViT-S backbones.\nEnMAP-CORINE. Pretrained models outperform random weights in linear evaluation for MoCo-V2 and DINO, with DINO yielding the best results, demonstrating the ability of joint-embedding methods to learn robust representations, even in the absence of fine-tuning. Additionally, we observe that MAE under-performs in linear probing, which is consistent with existing literature [41]. This can be attributed to the reconstruction pre-training objective, which focuses on low-level features, whereas joint-embedding methods learn more global and semantic representations. For full fine-tuning, pretrained models are on par with/slightly outperform training from scratch.\nFine-tuning the adapter yields a notable performance boost compared to linear evaluation. This significant performance improvement aligns with reports in the literature [40]: fine-tuning early network layers is an efficient compromise between frozen weights vs. complete fine-tuning. In terms of F1-score, only fine-tuning the adapter"}, {"title": "6.2. Scaling-up Pretrained Models", "content": "Recent studies have shown significant performance gains through model scaling in SSL [27, 51]. Consequently, recent geospatial foundation models are exploring ViT architectures with hundreds of millions of parameters [31, 34,"}, {"title": "6.3. Efficient Fine-tuning", "content": "Model convergence. Using a pretrained model can speed up convergence during fine-tuning, hence reducing the computational cost of training deep neural networks. To assess this for our models, we compare the training efficiency of Spec. RN50 models pretrained with DINO relative to training from scratch on the CORINE and CDL benchmarks. Figure 8 displays the evolution of the validation metrics across training epochs. We observe that pretrained models converge more rapidly, particularly in the early stages of training. Notably, fine-tuning matches the 100 epochs performance of training from scratch in ~ 30 epochs for EnMAP-CDL. These results highlight the computational advantage of using our pretrained models compared to training from scratch."}, {"title": "6.4. Cross-Sensor Transferability", "content": "To assess the transferability of our pretrained models to other sensors, we evaluate them on the Hyperview and DESIS-CDL datasets. Images in both datasets have been"}, {"title": "6.5. Ablation Studies", "content": "Impact of temporal positives. Temporal positives provide a natural data augmentation for joint-embedding methods and have demonstrated their benefits for multi-spectral imagery [46, 56, 65]. Given that only a subset of SpectralEarth includes temporal positives, it is unclear whether using temporal pairs significantly contributes to the overall performance of the pretrained models. To analyze their effect, we pretrain a Spec. RN50 using DINO with and without temporal pairs. Results in Table 5 confirm that excluding temporal positives degrades performance, with the effect most pronounced in frozen encoder evaluation.\nHow much data is needed for pre-training? To answer this question, we explore the impact of dataset size by pre-training a Spec. RN50 with DINO on randomly sampled subsets of SpectralEarth with sizes 10K, 25K, 50K, 100K,"}, {"title": "7. Conclusion", "content": "We introduce SpectralEarth, a large-scale dataset derived from EnMAP imagery as basis for SSL methodologies in the hyperspectral domain. We leveraged SpectralEarth to pre-train foundation models based on popular SSL algorithms. Extensive evaluation on several downstream tasks benchmarked the pre-trained models. Our results demonstrate the effectiveness of models pre-trained on SpectralEarth to improve performance and to reduce computational costs for downstream applications. We believe that the insights derived from this study serve as a basis for future development in SSL for hyperspectral imagery.\nAs it stands, we encourage further effort to construct additional hyperspectral benchmark datasets. Covering tasks such as unmixing enables a more comprehensive assessment in terms of generalizability of hyperspectral foundation models. In particular, transferability across different hyperspectral sensors remains a challenging problem. Moreover, exploration of a wider range of architectures and SSL algorithms, beyond the Spectral ResNet-50 and ViT models employed in this work, may provide a more comprehensive toolbox for practical deep learning on HSI. Last but not least, exploration and benchmarking multi-sensor SSL methods entails a promising endeavor toward more general geospatial foundation models."}]}