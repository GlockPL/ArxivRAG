{"title": "SpectralEarth: Training Hyperspectral Foundation Models at Scale", "authors": ["Nassim Ait Ali Braham", "Conrad M Albrecht", "Julien Mairal", "Jocelyn Chanussot", "Yi Wang", "Xiao Xiang Zhu"], "abstract": "Foundation models have triggered a paradigm shift in computer vision and are increasingly being adopted in remote sensing, particularly for multispectral imagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped due to the absence of comprehensive and globally representative hyperspectral datasets. To close this gap, we introduce SpectralEarth, a large-scale multi-temporal dataset designed to pretrain hyperspectral foundation models leveraging data from the Environmental Mapping and Analysis Program (EnMAP). SpectralEarth comprises 538,974 image patches covering 415,153 unique locations from more than 11,636 globally distributed EnMAP scenes spanning two years of archive. Additionally, 17.5% of these locations include multiple timestamps, enabling multi-temporal HSI analysis. Utilizing state-of-the-art self-supervised learning (SSL) algorithms, we pretrain a series of foundation models on SpectralEarth. We integrate a spectral adapter into classical vision backbones to accommodate the unique characteristics of HSI. In tandem, we construct four downstream datasets for land-cover and crop-type mapping, providing benchmarks for model evaluation. Experimental results support the versatility of our models, showcasing their generalizability across different tasks and sensors. We also highlight computational efficiency during model fine-tuning. The dataset, models, and source code will be made publicly available.", "sections": [{"title": "1. Introduction", "content": "Hyperspectral imaging (HSI) from space provides valuable information about the material composition of the Earth's surface and atmosphere. With hundreds of narrow bands, each a few nanometers in width, hyperspectral images record detailed electromagnetic information across a wide range of wavelengths, from long-wave ultraviolet to the shortwave infrared [39]. This rich spectral information provides opportunities for numerous environmental applications such as soil and mineral mapping, pollution tracking, agricultural assessment, and forest monitoring [13, 35, 45, 61, 62].\nIn recent years, the availability of hyperspectral data has been significantly expanded by the launch of new satellite missions. Notable examples include: Germany's Environmental Mapping and Analysis Program (EnMAP) [37] with precursor Earth Sensing Imaging Spectrometer mission (DESIS) [38] mounted to the International Space Station (ISS), Italy's Hyperspectral Precursor and Application Mission (PRISMA) [52], and the European Space Agency's upcoming Copernicus Hyperspectral Imaging Mission for the Environment (CHIME) [53]. These developments open new avenues to employ deep learning and Self-Supervised Learning (SSL) for large-scale HSI analysis."}, {"title": "2. Related Work", "content": "Traditionally, hyperspectral benchmark datasets have been limited in geographical coverage, often confined to a single or a limited number of scenes [3, 30, 49, 60]. This limitation primarily roots in the expenses associated with air-\nFoundation models pre-trained with SSL demonstrated remarkable generalization capabilities with minimal fine-tuning in computer vision [51]. Subsequently, there has been a surge in developing geospatial foundation models, particularly for multispectral and high-resolution RGB imagery [64]. This line of research benefits from the abundance of publicly available satellite data from missions like Copernicus Sentinel-2 which provides petabytes of archive data for model training. In contrast, progress in foundation models for the hyperspectral domain has been hindered by the lack of large-scale HSI datasets for pre-training. Historically, access to hyperspectral imagery has been costly, with most benchmarks restricted to small-scale aerial imagery datasets [3]. While recent efforts [19, 55, 63] have begun to address this limitation, they still fall short in terms of data volume and geographic diversity to effectively train general hyperspectral foundation models.\nTo bridge this gap, we introduce SpectralEarth, a large-scale dataset derived from the EnMAP satellite mission, featuring over 538,974 hyperspectral image patches from 415,153 unique locations with global spatial distribution and cloud coverage below 10%. SpectralEarth, as illustrated in Figure 1, represents an important leap in scale, being significantly larger than existing HSI datasets, and spans a wide variety of landscapes to reflect the full diversity of spectral signatures. Compiled from 11,636 EnMAP scenes, the dataset volume exceeds 3TB in hyperspectral images. Notably, about 17% of its geospatial locations include timeseries data to enable multi-temporal HSI analysis. To effectively harness the rich information in hyperspectral data, we modify conventional vision backbones such as ResNet and ViT with a spectral adapter module. It enables such backbones to capture the unique spectral characteristics of HSI. Using three popular SSL algorithms, MoCo-V2 [15, 26], DINO [12] and MAE [27], we train these backbones on SpectralEarth, to provide a plurality of pretrained models for hyperspectral image analysis. To benchmark the efficacy of our models, we introduce four downstream datasets geospatially co-registered with EnMAP and DESIS imagery for land cover and crop type mapping. Our experiments demonstrate the potential of the foundation model paradigm to efficiently generalize across various hyperspectral imaging contexts, including adapting to data from alternative sensors with different spectral characteristics. Our contributions summarized:\n\u2022 Assembly of SpectralEarth, a large-scale dataset comprising around 3.3TB of nearly cloud-free EnMAP hyperspectral images. SpectralEarth features a global geospatial distribution encompassing over 538,974 image patches from 415,153 unique geo-locations, 73,307 of which include multiple timestamps.\n\u2022 Construction of four downstream datasets designed to benchmark classification and semantic segmentation tasks for HSI.\n\u2022 Training of various foundation models on SpectralEarth to test and demonstrate their generalizability to multiple hyperspectral sensors. In addition, we demonstrate the models' computational benefit through faster convergence in fine-tuning."}, {"title": "2.1. Hyperspectral Datasets", "content": ""}, {"title": "2.2. Self-Supervised Learning for Remote Sensing", "content": "SSL emerged as a powerful paradigm for learning representations from unlabeled data [36]. Early SSL methods were based on engineered pretext tasks to encourage the model to learn distinct features by solving auxiliary problems such as image colorization [71], jigsaw puzzles [48], or rotation angle prediction [21]. Recently, progress in SSL has been primarily focused on two families of methods:\n1. Joint-Embedding Architectures: These methods train models to generate consistent representations for augmented views of the same input, enforcing invariance to these augmentations. To avoid convergence to trivial"}, {"title": "3. SpectralEarth & Benchmarks", "content": "This section introduces the SpectralEarth dataset and related downstream datasets for benchmarking. Additional details are provided in Appendix."}, {"title": "3.1. SpectralEarth", "content": "Data Acquisition. The EnMAP data was sourced from the DLR GeoPortal. A total of 11,636 tiles were retrieved via the portal's graphical interface through a significant manual effort. All tiles were carefully selected based on human visual inspection. Cloud coverage was kept below ~10%. The selection process encompassed the entire EnMAP archive from April 2022 to April 2024. All acquired tiles underwent radiometric, geometric, and atmospheric corrections, resulting in Level-2A products.\nData Pre-processing. The EnMAP tiles have been split into geospatial patches\u2014each of size 128x128 pixels where an individual pixel includes 224 bands. Bands dominated by water absorption were excluded due to the frequent presence of missing values (no-data). Removing those badns is a common practice in hyperspectral dataset creation [19, 60]. As a result, the total number of bands per image reduced to 202.\nTemporal Views Extraction. To exploit all available tiles, we utilized overlaps between EnMAP data acquisitions to generate time series of EnMAP patches\u00b9. At the same time SpectralEarth data patches for a fixed geolocation never overlap. This process required (a) identification of tiles that overlap spatially to (b) extract patches from the intersection of those tiles. Time series include valuable information on landscape evolution and provide characteristic signals for seasonal variation\u2014an asset for contrastive learning [46, 65]. Algorithm 1 outlines the steps taken to generate temporal positives by high-level pseudo-code.\nAs a result of Algorithm 1 we identified a few long time series in the EnMAP archive. Those involving more than 25 intersecting tiles. Calculating intersections of all subsets was computationally intractable due to combinatorial explosion. To address this, we implemented several heuristics to optimize the computation:\n1. Consider only a subset of possible intersections using a breadth-first search (BFS) approach.\n2. Avoid redundant computations across tiles.\n3. Parallelization of the code across all connected components of the overlap graph.\nFollowing this approach, we extracted 73,307 non-overlapping locations with multiple timestamps. For areas\nwith a single timestamp we patchified avoiding any spatial overlap. Correspondingly, in SpectralEarth we extracted 415,153 locations with a spatial extent of 128x128 pixels, totaling 538,974 patches. Figure 6 illustrates the distribution of timestamp counts in SpectralEarth. Over the two-year's period, 17.5% of locations were covered by more than one timestamp in the EnMAP archive\u2014with the majority having only two timestamps. This highlights the challenge of collecting extensive hyperspectral time series data with broad geographical coverage today. Missions such as ESA'S CHIME satellite constellation [53] will eventually resolve the issue.\nThe spatial coverage of SpectralEarth showcases the dataset's global diversity, cf. Figure 3. Notably, the data distribution varies across geo-locations. EnMAP is a mission with scheduled acquisition depending on areas of interest."}, {"title": "3.2. Downstream Tasks", "content": "To evaluate the models pretrained on SpectralEarth, we assembled four downstream datasets for benchmarking. Each benchmark involves a subset of EnMAP or DESIS images, aligned with specific geospatial products with focus on specific aspects of land cover and agricultural analysis. While the labels in these datasets carry some inherent uncertainty, they are sufficiently accurate for a proof-of-concept evaluation of model performance. Similar strategies have previously been employed to create remote sens-"}, {"title": "4. Hyperspectral Foundation Models", "content": "This section presents the design choices behind our models, including the choice of SSL algorithms and network architecture."}, {"title": "4.1. Pre-training Algorithms", "content": "Hyperspectral data has very different characteristics compared to natural images. Therefore, traditional SSL leaderboards in computer vision may not directly translate to the hyperspectral domain. To address this gap, we explore a broad range of SSL methods to establish a set of baseline pretrained models for hyperspectral imagery. We use MoCo-V2 [26] and DINO [12] for their effectiveness in frozen encoder performance [51] and their compatibility with both CNNs and ViTs. Furthermore, we include MAE [27] for its strong performance in fine-tuning scenarios. Together, these methods form a representative set of algorithms to investigate SSL in the hyperspectral domain."}, {"title": "4.2. Network Architectures", "content": "Since we aim for large-scale coverage and pre-training with spaceborne imagery, our models must operate on large patches instead of pixels or small patches, as traditionally done in the hyperspectral literature. Most models developed at the pixel level in HSI literature do not scale well with large patches [28, 29, 72]. On the other hand, models like ResNet [24] and ViT [18] are designed to handle larger spatial contexts. Therefore, we seek to adapt these architectures for hyperspectral imaging. A key challenge is that classical ResNet and ViTs treat spectral bands independently, failing to capture the correlations between adjacent bands and the overall characteristics of the spectrum. Our models should address the following requirements for hyperspectral imaging:\n\u2022 Spectral Feature Extraction: We aim to extract features from both the spatial and the spectral domain.\n\u2022 Adaptability to Diverse Sensors: The architecture should accommodate variability in the number of spectral bands. This property is important when transferring pretrained models to different sensors.\n\u2022 Preserving Fine-Grained Details: Natural images often deal with large objects compared to medium-resolution remote sensing data. Therefore, the spatial downscaling in classical vision models can lead to a significant loss of details. Our architecture needs to preserve this fine-grained information.\n\u2022 Computational Efficiency: 3D convolution or tokenizing the image in the spectral dimension is computationally expensive for large models. We seek for adaptation of classical architectures with minimal overhead.\nTo meet these requirements, we follow a pragmatic approach and implement a simple modular design, integrating 1D convolutional layers as a Spectral Adapter at the onset of the standard vision backbones, as depicted in Figure 7. These layers perform convolutions across the spectral dimension, generating feature maps for the core backbone. Specifically:\n\u2022 Spectral ResNet: We replace the stem layers with three 1D convolutional layers and pooling, allowing the network to process spectral information effectively before the residual backbone. By removing the original stem layers in the ResNet architecture, we avoid the 4x downscaling factor of the image to better capture fine-grained details.\n\u2022 Spectral ViT: The 1D convolutions and pooling are placed before the patch embedding layer, ensuring that the transformer receives fixed-size spectral features as input. We use 4x4 patches instead of the typical 16x16 patches, which helps maintain fine spatial details and better preserves spectral information at the patch projection layer.\nThis simple strategy results in an architecture that can be used on various hyperspectral sensors while leveraging a lightweight adapter for spectral feature extraction. Similar designs have been used effectively for spectral-spatial classifiers in the HSI literature [1]. Our approach extends this idea to foundation models, enabling the extraction of both spatial and spectral features while avoiding the extra computational cost incurred by 3D convolutions or spatial-spectral tokenization in ViTs."}, {"title": "5. Experimental Setup", "content": "We pre-train a spectral ResNet-50 (Spec. RN50) and a spectral ViT-S (Spec. ViT-S) with MoCo-V2, DINO, and MAE. For larger models, Spec. ViT-Base(B)/Large(L)/Huge(H)/Giant(g), we restrict the experiments to MAE given the high computational cost. For ViT-g, we follow the implementation from [51]. We use the augmentations from SimCLR [14] without color-jittering and gray-scale for DINO and MoCo-V2 to avoid distorting spectral information. When available, we use the\n5.1. Self-Supervised Pre-training"}, {"title": "5.2. Downstream Tasks", "content": "Multi-label classification on EnMAP-CORINE. We append a linear layer to the pretrained encoders and train the models with Binary Cross-Entropy loss for 100 epochs.\nSemantic segmentation on EnMAP-CDL/-NLCD and DESIS-CDL. We use a lightweight transfer protocol for the segmentation tasks, following previous works [22, 26]. We train for 100 epochs with a cross-entropy loss. The pretrained encoders are converted into segmentation models as follows:\n\u2022 ResNet: We remove all strides from convolutions, replace them with atrous convolutions, and append two final convolutional layers.\n\u2022 ViT: We reshape the tokens from the last layer and add two additional convolutional layers with upscaling to recover the full spatial resolution.\nParameter regression on Hyperview. We use the training set of the Hyperview challenge [49] to evaluate cross-sensor transferability. Hyperview is a soil parameter estimation dataset comprising 1,732 hyperspectral patches with 150 spectral bands. Each patch is annotated with four soil parameters, including potassium (K), phosphorus pentoxide (P2O5), magnesium (Mg), and acidity pH. For this downstream task, we append two fully connected layers to the backbones. The models are optimized based on the normalized MSE criterion defined in Section 5.4 with the AdamW optimizer for 200 epochs."}, {"title": "5.3. Evaluation Protocols", "content": "We consider multiple evaluation protocols with various levels of fine-tuning of the pretrained models.\n\u2022 Frozen Encoder: Evaluates the quality of learned representations without fine-tuning the backbone. It is the most common evaluation protocol in the SSL literature [7, 51].\n\u2022 Fine-tuning: Fine-tuning of all model parameters on downstream datasets to evaluate the transferability of the pretrained weights.\n\u2022 Fine-tuning Adapter: While frozen encoder evaluation is a common measure of the quality of learned representations, it does not yield optimal results. In remote sensing, it is often beneficial to adapt the model to the specific distribution of the downstream dataset, which can be influenced by several factors: geo-location, atmospheric conditions, seasonal changes, etc. Additionally, the relevance of individual spectral bands may vary depending on the downstream task. Therefore, we consider an intermediate setting where only the initial spectral adapter block is fine-tuned."}, {"title": "5.4. Evaluation Metrics", "content": "Depending on the nature of the downstream task, we report the following metrics:\n\u2022 Classification: The multi-label F1-score is reported for the EnMAP-CORINE dataset.\n\u2022 Segmentation: The mean Intersection over Union (mIoU) is reported for the EnMAP-CDL, EnMAP-NLCD and DESIS-CDL datasets.\n\u2022 Regression: For the Hyperview dataset, we follow the metric defined in the challenge [49]: let $MSE_i$, $i \\in [1, 4]$ be the mean squared error of the predictor for soil parameter i. Let $MSE_{base}$ be the corresponding MSE of a base predictor returning the mean value of the soil parameter, calculated over the training set. The reported normalized MSE is defined as: $MSE_{norm} = \\sum_{i=1}^4 MSE_i/MSE_{base}$."}, {"title": "6. Benchmark Results", "content": "Our main results are summarized in Tables 2 and 3. We include random initialization baselines for each downstream task, along with our pretrained models. Due to hundreds of spectral channels of the SpectralEarth patches, a comparison with RGB-ImageNet weights or multispectral pretrained models is of little use."}, {"title": "6.1. Comparing SSL Algorithms", "content": "Table 2 summarizes our results for three SSL algorithms with the Spec. RN50 and Spec. ViT-S backbones.\nEnMAP-CORINE. Pretrained models outperform random weights in linear evaluation for MoCo-V2 and DINO, with DINO yielding the best results, demonstrating the ability of joint-embedding methods to learn robust representations, even in the absence of fine-tuning. Additionally, we observe that MAE under-performs in linear probing, which is consistent with existing literature [41]. This can be attributed to the reconstruction pre-training objective, which focuses on low-level features, whereas joint-embedding methods learn more global and semantic representations. For full fine-tuning, pretrained models are on par with/slightly outperform training from scratch.\nFine-tuning the adapter yields a notable performance boost compared to linear evaluation. This significant performance improvement aligns with reports in the literature [40]: fine-tuning early network layers is an efficient compromise between frozen weights vs. complete fine-tuning. In terms of F1-score, only fine-tuning the adapter"}, {"title": "6.2. Scaling-up Pretrained Models", "content": "Recent studies have shown significant performance gains through model scaling in SSL [27, 51]. Consequently, recent geospatial foundation models are exploring ViT architectures with hundreds of millions of parameters [31, 34, 63]. We investigate model scaling on SpectralEarth by pre-training Spec. ViT architectures of varying sizes: Base (B), Large (L), Huge (H), and Giant (g). Our findings are presented in Table 3. We observe that MAE consistently outperforms training from scratch across all model sizes. Remarkably, fine-tuning the adapter, which corresponds to 56K trainable parameters, matches or surpasses training from scratch for the EnMAP-CORINE and EnMAP-CDL tasks. Moreover, we observe initial benefits from scaling up the models up to Spec. ViT-L/H. However, additional increases in model size do not improve performance, possibly due to the size of the pretraining dataset. While SpectralEarth is significantly larger than previous HSI datasets, it remains smaller than the datasets used in computer vision for training state-of-the-art models [51]. This highlights the importance of scaling the data when training large vision transformers in remote sensing."}, {"title": "6.3. Efficient Fine-tuning", "content": "Model convergence. Using a pretrained model can speed up convergence during fine-tuning, hence reducing the computational cost of training deep neural networks. To assess this for our models, we compare the training efficiency of Spec. RN50 models pretrained with DINO relative to training from scratch on the CORINE and CDL benchmarks. Figure 8 displays the evolution of the validation metrics across training epochs. We observe that pretrained models converge more rapidly, particularly in the early stages of training. Notably, fine-tuning matches the 100 epochs performance of training from scratch in ~ 30 epochs for EnMAP-CDL. These results highlight the computational advantage of using our pretrained models compared to training from scratch.\nParameter-efficient fine-tuning. Foundation models are typically evaluated in linear probing to assess the quality of the learnt representations [26]. While a frozen encoder can achieve competitive performance, fine-tuning often surpasses it at a higher computational cost. We experiment with the progressive unfreezing of network layers as a compromise between both scenarios. As depicted in Figure 9, fine-tuning the first two blocks of a pretrained Spec. RN50 produces results that closely resemble full fine-tuning. This demonstrates the cost- and energy efficiency of our pretrained models for downstream tasks."}, {"title": "Training with limited labels.", "content": "Pre-trained models are very useful when labeled data is scarce [50]. To assess this, we evaluate the performance of the Spec. ViT-L model, pre-trained with MAE, on varying subset sizes of EnMAP-CORINE and EnMAP-NLCD datasets. The results, reported in Figure 10, demonstrate the benefits of pre-training across all data regimes. In particular, we observe large gaps of 9 points in F1 score for EnMAP-CORINE, and 5 points in mIoU for EnMAP-NLCD, when using 5% of the labels compared to training from scratch. Interestingly, in lower data regime scenarios, fine-tuning the adapter only suffices to outperform training from scratch. This demonstrates the generalizability of the features learned from pre-training."}, {"title": "6.4. Cross-Sensor Transferability", "content": "To assess the transferability of our pretrained models to other sensors, we evaluate them on the Hyperview and DESIS-CDL datasets. Images in both datasets have been"}, {"title": "6.5. Ablation Studies", "content": "Impact of temporal positives. Temporal positives provide a natural data augmentation for joint-embedding methods and have demonstrated their benefits for multi-spectral imagery [46, 56, 65]. Given that only a subset of SpectralEarth includes temporal positives, it is unclear whether using temporal pairs significantly contributes to the overall performance of the pretrained models. To analyze their effect, we pretrain a Spec. RN50 using DINO with and without temporal pairs. Results in Table 5 confirm that excluding temporal positives degrades performance, with the effect most pronounced in frozen encoder evaluation.\nHow much data is needed for pre-training? To answer this question, we explore the impact of dataset size by pre-training a Spec. RN50 with DINO on randomly sampled subsets of SpectralEarth with sizes 10K, 25K, 50K, 100K, and 200K locations. We conduct frozen-encoder evaluation on EnMAP-CORINE and EnMAP-CDL. Figure 11 summarizes our findings. We observe a consistent improvement in performance metrics as the scale of the pre-training dataset increases from 10k samples to the full size of SpectralEarth. While the performance on EnMAP-CDL appears to saturate, the F1 Score for EnMAP-CORINE still increases, despite the small size of Spec. RN50. This trend confirms the importance of large-scale datasets for pre-training hyperspectral foundation models."}, {"title": "Importance of the patch size.", "content": "Medium-resolution remote sensing imagery requires more fine-grained detail preservation than natural imagery, especially for segmentation tasks. This aspect is sometimes overlooked in the literature, where vision transformers with a patch size of 16x16 or 8x8 are commonly used as backbones to pretrain foundation models to reduce the computational cost [16, 34, 63, 69]. We argue that a smaller image size with a smaller patch size can lead better trade-offs, particularly for HSI imagery where pixel information is rich and should not be heavily compressed in the embedding space. To analyze the impact of the patch size, we pre-trained Spec. ViT-S using MAE with patch sizes of 4x4, 8x8 and 16x16. Results in Figure 12 show that smaller patches consistently improve performance for segmentation tasks. This is further supported by qualitative results in Figure 13, where models with smaller patches produce more refined segmentation maps. These results are consistent with the performance gap between ViT-based foundation models and ConvNet baselines observed in previous studies [67]. In practice, using additional trainable parameters to extract high-resolution features in combination with a pre-trained ViT can mitigate this issue.\nMasking ratio in MAE. Given our small 4x4 patch size for Spec. ViT models, we expect a higher masking ratio is needed for MAE compared to the usual 75% used in Com-"}, {"title": "Impact of the spectral adapter.", "content": "To assess the impact of the spectral adapter, we compare the classical ResNet-50 with our modified architecture, Spec. RN50. We adjust the first convolutional layer of the ResNet-50 model to accommodate the 202 input bands. Both models are pretrained with MoCo-V2 and evaluated on the EnMAP-CORINE and EnMAP-CDL datasets. The results are summarized in Table 6. Spec. RN50 consistently outperforms the standard ResNet-50 in both frozen encoder evaluation and full fine-tuning. This result confirms the importance of a dedicated spectral feature extractor when dealing with hyperspectral images, particularly for tasks requiring fine-grained spectral discrimination."}, {"title": "7. Conclusion", "content": "We introduce SpectralEarth, a large-scale dataset derived from EnMAP imagery as basis for SSL methodologies in the hyperspectral domain. We leveraged SpectralEarth to pre-train foundation models based on popular SSL algorithms. Extensive evaluation on several downstream tasks benchmarked the pre-trained models. Our results demonstrate the effectiveness of models pre-trained on SpectralEarth to improve performance and to reduce computational costs for downstream applications. We believe that the insights derived from this study serve as a basis for future development in SSL for hyperspectral imagery.\nAs it stands, we encourage further effort to construct additional hyperspectral benchmark datasets. Covering tasks such as unmixing enables a more comprehensive assessment in terms of generalizability of hyperspectral foundation models. In particular, transferability across different hyperspectral sensors remains a challenging problem. Moreover, exploration of a wider range of architectures and SSL algorithms, beyond the Spectral ResNet-50 and ViT models employed in this work, may provide a more comprehensive toolbox for practical deep learning on HSI. Last but not least, exploration and benchmarking multi-sensor SSL methods entails a promising endeavor toward more general geospatial foundation models."}, {"title": "8. Implementation Details", "content": "Supplementary Material"}, {"title": "8.1. Network Architecture", "content": "Spectral Adapter. The Spectral Adapter consists of three (1D Conv + BN + ReLu) layers. The kernel sizes for the 1D convolutions are 7, 7, and 5, with strides of 5, 5, and 3, respectively. The resulting feature maps have 128 channels. To accommodate different sensors and feed the input into standard 2D backbones, we use a global pooling layer to aggregate the remaining spectral dimensions (if any).\nSpec. RN50. The architecture of Spec. RN50 closely follows the classical ResNet-50 design with two modifications: (a) We replace the stem layers with the spectral adapter without downscaling; (b) The first bottleneck block is adjusted to take an input feature map of 128 channels, as opposed to the ResNet-50's 64-channel input at this stage.\nSpec. ViT-S. For Spec. ViT-S, we set the number of input channels in the projection layer to 128. A patch size of 4 is chosen based on two considerations: (a) to preserve the rich spectral information in hyperspectral tokens without excessive compression in the patch projection layer, and (b) to preserve fine-grained details spatially while keeping a reasonable compute cost given the small image size of 128x128."}, {"title": "8.2. Training Details", "content": "Detailed training configurations and hyperparameters for each downstream task are presented below. For each experiment, a search over the learning rate was performed.\nMulti-label Classification For multi-label classification, we utilized the Binary Cross-Entropy (BCE) loss function. Training was conducted over 100 epochs with a batch size of 128. AdamW optimizer was employed with a cosine annealing scheduler. Data augmentation included random resized crop, horizontal and vertical flipping.\nSemantic Segmentation Training was conducted for 100 epochs on all datasets, using a Cross-Entropy loss. AdamW optimizer was used with a batch size of 64 for EnMAP-NLCD and 32 for EnMAP-CDL and DESIS-CDL. We used a cosine annealing scheduler. Data augmentation included random resized crop, horizontal and vertical flipping.\nRegression We resized all images in the Hyperview dataset to 128x128 pixels. We trained for 200 epochs with a normalized mean squared error (MSE) loss function, as described in Section 5.4. The AdamW optimizer was used along with a cosine annealing scheduler and a batch size of 16. As for the other tasks, we used random resized crop, horizontal and vertical flipping during training."}, {"title": "9. Data Visualizations", "content": "In this section, we provide additional data visualizations to get deeper insights into the characteristics of SpectralEarth, as well as hyperspectral EnMAP imagery. Samples of EnMAP tiles, i.e. before division into patches and the filtering of water absorption bands, used to create our dataset are displayed in Figure 15."}, {"title": "9.1. Spectral Reflectance Analysis", "content": "To gain more insights into the spectral characteristics in our dataset, we present an analysis of per-class spectral reflectance for the NLCD task, visualized in Figure 16.\nThe spectral reflectance profiles across different land cover classes show diverse characteristics. Classes such as 'Open Water' and 'Barren Land' have distinct spectral signatures that are characteristic of their respective land cover types. Conversely, some classes, such as 'Deciduous Forest' and 'Evergreen Forest', have profiles that are harder to differentiate from one another. This inter-class similarity poses challenges in classification tasks, highlighting the need for advanced feature extractors capable of capturing such subtle differences.\nFurthermore, Figure 16 reveals a high level of intra-class spectral variability, a well-known characteristic of hyperspectral imagery. This variance reflects the diverse nature of each land cover class, influenced by factors such as illumination conditions and seasonal changes. This emphasizes the need for robust models to ensure reliable performance across different geographic regions and environmental conditions."}, {"title": "9.2. Temporal Analysis", "content": "We analyze the temporal coverage of our dataset in Figure 17. SpectralEarth includes data from all seasons, with a relatively balanced distribution across months. However, certain disparities can be observed, e.g., January is underrepresented while July, August, and March are over-represented. This can be attributed to several factors: (a) Increased cloud cover during winter months, which inherently limits the availability of clear imagery; (b) A satellite"}, {"title": "9.3. Class Distribution in Downstream Tasks", "content": "EnMAP-CORINE The EnMAP-CORINE dataset exhibits a diverse range of land cover types. As Figure 18 demonstrates, some classes such as 'Arable Land' and 'Complex cultivation patterns' are more frequent, while others like 'Coastal/Inland wetlands' and 'Beaches, dunes, sand' are comparatively rare. This class imbalance reflects the natural land cover distribution in Europe.\nEnMAP-CDL The EnMAP-CDL dataset is primarily focused on agricultural crop types. However, following the CDL map, the dataset also includes some non-agricultural classes such as grassland, which is over-represented as shown in Figure 19. Overall, the dataset exhibits a reasonable level of class balance among the different crop types.\nEnMAP-NLCD The EnMAP-NLCD dataset provides a comprehensive view of natural and urban land covers. As depicted in Figure 20, albeit some infrequent classes like 'Developed, High Intensity', the class distribution is well-balanced.\nDESIS-CDL Similar to the EnMAP-CDL dataset, DESIS-CDL is focused on agricultural classes. Due to the limited availability of DESIS tiles, it was not possible to pair this dataset with EnMAP-CDL. Therefore, the class distribution (see Figure 21) and geographical coverage differ."}]}