{"title": "A Survey of LLM-based Agents in Medicine: How far are we from Baymax?", "authors": ["Wenxuan Wang", "Zizhan Ma", "Zheng Wang", "Chenghan Wu", "Jiaming Ji", "Wenting Chen", "Xiang Li", "Yixuan Yuan"], "abstract": "Large Language Models (LLMs) are transforming healthcare through the development of LLM-based agents that can understand, reason about, and assist with medical tasks. This survey provides a comprehensive review of LLM-based agents in medicine, examining their architectures, applications, and challenges. We analyze the key components of medical agent systems, including system profiles, clinical planning mechanisms, medical reasoning frameworks, and external capacity enhancement. The survey covers major application scenarios such as clinical decision support, medical documentation, training simulations, and healthcare service optimization. We discuss evaluation frameworks and metrics used to assess these agents' performance in healthcare settings. While LLM-based agents show promise in enhancing healthcare delivery, several challenges remain, including hallucination management, multimodal integration, implementation barriers, and ethical considerations. The survey concludes by highlighting future research directions, including advances in medical reasoning inspired by recent developments in LLM architectures, integration with physical systems, and improvements in training simulations. This work provides researchers and practitioners with a structured overview of the current state and future prospects of LLM-based agents in medicine.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) are changing the field of artificial intelligence with their strong capabilities in text understanding, generation, and reasoning. The development of LLM-based agents has achieved notable success in many areas, from creative writing (Yuan et al., 2022) to complex decision-making (Chai et al., 2025; Wei et al.,"}, {"title": "2 Background", "content": "This section outlines the core differences between LLMS and LLM-based agents and highlights the unique considerations required for deploying such agents in medicine."}, {"title": "2.1 LLM vs. LLM-based Agent", "content": "An agent, as defined in AI, perceives its environment and takes actions accordingly (Russell and Norvig, 2016). An LLM-based agent extends traditional LLMs by integrating external knowledge retrieval, task planning, and tool invocation, enabling structured decision-making in real-world applications (Xi et al., 2023). Unlike standard LLMs, which primarily process text, these agents operate autonomously and adapt dynamically to new information and tasks."}, {"title": "2.2 Unique Considerations for LLM-based Agents in Medicine", "content": "Deploying LLM-based agents in healthcare requires addressing several critical factors:\nMultimodal Integration. Medical data spans text, imaging, and laboratory results. Agents must process and synthesize these inputs for accurate decision support (Zhang et al., 2024).\nClinical Collaboration. Healthcare relies on interdisciplinary work. Agents should facilitate information sharing and human-AI collaboration, ensuring physicians maintain oversight (Strong et al., 2024).\nAccuracy and Reliability. Given the impact on patient outcomes, these agents must meet strict validation standards and minimize errors in diagnosis and treatment (Reddy, 2024).\nTransparency and Traceability. Clinical decisions must be auditable and explainable to align with medical ethics and regulatory requirements (Kiseleva et al., 2022)."}, {"title": "3 LLM-based Medical Agent Architecture", "content": "LLM-based agents in medicine require well-defined architectures to integrate complex clinical knowledge, facilitate medical decision-making, and ensure safe and effective deployment. This section presents a systematic overview of their architectural components, focusing on how these agents structure their operations to enhance clinical performance."}, {"title": "3.1 Profile", "content": "The profile of an agent plays a key role in defining and managing its role attributes, behavioral patterns, and operational competencies within medical systems, which traditionally involve information dissemination, resource distribution, and quality assurance. In medical applications, agent profiles follow three prototypes:\nFunctional Modularization. This approach structures the agent system into specialized functional modules, each responsible for distinct tasks such as clinical data analysis or diagnostic reasoning. Systems like MEGDA (Bani-Harouni et al., 2024) implement function-driven profiles where task assignments and workflows are explicitly defined to improve efficiency and adaptability.\nRole Specialization By mirroring real-world medical roles, this paradigm assigns agents to specific clinical functions, including diagnosis, medical imaging, treatment planning, and surgical assistance. These agents incorporate domain-specific knowledge and interact with healthcare systems for tasks such as imaging analysis and interdisciplinary coordination. In agent-driven operating room simulations (Wu et al., 2024), LLM-based agents take on distinct medical roles to support clinical decision-making.\nDepartmental Organization This framework structures agents based on medical disciplines, such as cardiology or hematology, establishing domain-specific knowledge boundaries. Agents rely on specialized disease knowledge graphs and dynamic collaboration mechanisms to facilitate interdisciplinary consultations. In multi-agent medical applications (Tang et al., 2024), profiles are defined to reflect departmental expertise, improving coordination and decision-making in complex medical scenarios."}, {"title": "3.2 Clinical Planning", "content": "Effective clinical planning is at the core of LLM-based medical agents. The planning process breaks down complex medical tasks into smaller subtasks so that the system can interact with tools and databases specific to each clinical area (Mehandru et al., 2024). This division of tasks improves opera-"}, {"title": "Task Decomposition", "content": "Clinical planning often follows a structured decomposition from high-level objectives to specific actions. A Single-Agent model handles tasks autonomously, while a Sequential Task Chain approach structures planning into distinct steps, such as data ingestion, hypothesis generation, treatment planning, and risk assessment. Each step interacts with specialized medical tools, ensuring task separation and facilitating precise error correction (Liu et al., 2024a)."}, {"title": "Multi-Agent Collaboration Across Departments", "content": "For complex cases requiring interdisciplinary expertise, a Collaborative Experts model assigns specialized agents to clinical areas such as radiology, pathology, and laboratory analysis. These agents communicate using standardized protocols to aggregate findings and refine diagnoses. This reduces diagnostic uncertainty by integrating insights from multiple specialties (Tang et al., 2024)."}, {"title": "Adaptive Planning Architecture", "content": "A dynamic Sequential Task Chain or Collaborative Experts framework adjusts decision-making based on real-time data and task complexity. For example, MDAgents framework (Kim et al., 2024a) employs LLMs with predefined medical roles, which function autonomously or in coordination. Planning layer continuously updates clinical strategies, prioritizes urgent cases, and refines past decisions based on new evidence. Federated learning mechanisms further enhance adaptability by integrating diverse clinical experiences (Dutta and Hsiao, 2024)."}, {"title": "Iterative Self-Evolution", "content": "Beyond static workflows, Iterative Evolution frameworks enable continuous improvement. These systems maintain an experience base of past cases, refining decision-making over time. Self-improvement mechanisms allow agents to autonomously incorporate new medical data and learn from previous outcomes, progressively enhancing accuracy and reliability (Li et al., 2024b; Du et al., 2024)."}, {"title": "3.3 Medical Reasoning", "content": "The Medical Reasoning module enhances diagnostic accuracy and transparency by structuring logical inference processes and integrating real-time feedback."}, {"title": "Multi-Step Diagnostic Reasoning", "content": "Complex cases are analyzed through sequential inference, where Chain-of-Thought methods (Wei et al., 2023) generate step-by-step reasoning, and Tree-of-Thought approaches (Yao et al., 2023a) explore multiple hypotheses in parallel, discarding less probable options. This structured approach improves diagnostic precision (Dutta and Hsiao, 2024)."}, {"title": "Reflective Decision-Making", "content": "To handle clinical uncertainty, the system iteratively refines conclusions by incorporating real-time feedback and expert input. Inspired by the ReAct framework, it alternates between reasoning and action, identifying inconsistencies and improving decision robustness (Yao et al., 2023b; Yue et al., 2024)."}, {"title": "Collaborative Group Reasoning", "content": "A multi-agent reasoning framework assigns specialized agents\u2014such as primary care providers and specialists\u2014to perform independent analyses. Their conclusions are aggregated through consensus mechanisms, mitigating biases and enhancing reliability (Zuo et al., 2025)."}, {"title": "Memory-Enhanced Reasoning", "content": "Integrating long-term memory modules enables agents to accumulate medical knowledge and past clinical experiences, refining decision-making over time. This persistent memory allows the system to adapt to new medical insights, improve reasoning capabilities, and maintain continuity in patient care (Li et al., 2024b). Additionally, experience-based learning mechanisms enable LLM-based agents to update their diagnostic strategies dynamically, leading to more context-aware and personalized medical insights (Jiang et al., 2024)."}, {"title": "3.4 External Capacity Enhancement", "content": "The external capacity enhancement augments the agent's capabilities by integrating it with real-world clinical data sources and specialized tools.\nPerception This subsystem processes diverse clinical inputs, including structured electronic health records (EHRs) to access patient histories and clinical parameters. Advanced Optical Character Recognition (OCR) techniques convert scanned documents into text, while models like CLIP analyze medical images, facilitating comprehensive multimodal understanding.\nKnowledge Integration connects the agent with external sources such as medical knowledge graphs, drug interaction databases, and clinical guideline repositories. This connection helps the agent verify its inferences with trusted sources, thereby in-"}, {"title": "4 Application Scenarios", "content": "LLM-based agents are applied in various areas of medicine. This section outlines the main application scenarios and provides a summary in Table 1."}, {"title": "4.1 Clinical Decision Support and Diagnosis", "content": "In the area of Clinical Decision Support and Diagnosis, multi-agent frameworks based on LLMs improve clinical decision-making by addressing limitations of standalone LLMs. Systems in this area assign specialized roles to agents for intent recognition, diagnostic reasoning, and treatment planning so that healthcare delivery can be both personalized and sensitive to the context. For example, the framework proposed by Dutta and Hsiao (Dutta and Hsiao, 2024) simulates interactions between doctors and patients to refine diagnostic reasoning and has shown better performance on datasets such as MedQA. The system developed by Ke et al. (Ke et al., 2024) reduces cognitive biases in diagnosis by using agents that provide expert opinions and critical evaluations. Other systems, such as MedAide (Wei et al., 2024b), coordinate agents across stages including pre-diagnosis, diagnosis, medication, and post-diagnosis, while frameworks such as MDagents (Kim et al., 2024c) and EHRagent (Tang et al., 2024) improve diagnostic accuracy through structured discussions and shared reasoning. Domain-specific applications also show promise. For instance, the work by Yue et al. (Yue et al., 2024) uses multi-agent collaboration to predict clinical trial outcomes by integrating large-scale domain knowledge. The Polaris framework (Mukherjee et al., 2024) combines general communication agents with task-specific agents to ensure safe patient interactions, and the system known as Rx Strategist (Van et al., 2024) uses knowledge graphs and multi-stage reasoning to check prescriptions for correct indications, dosages, and drug interactions."}, {"title": "4.2 Clinical Data Analytics and Documentation", "content": "In Clinical Data Analytics and Documentation, LLM-based agents show strong performance in processing both structured and unstructured data by using advanced architectures and retrieval-augmented generation techniques. The system ColaCare proposed by Wang et al. (Wang et al., 2024b) integrates different agents to perform tasks such as mortality prediction and analysis of hospital readmission, demonstrating improved performance on the MIMIC-III and MIMIC-IV datasets. The work by Lee et al. (Lee et al., 2024) introduces Sporo AI Scribe to address challenges related to the variability and complexity of clinical documentation. Research by Sudarshan (Sudarshan et al., 2024) shows that technical medical reports can be converted into patient-friendly formats by using iterative self-reflection and retrieval-augmented generation. In addition, Agent Hospital (Li et al., 2024b) contributes to simulation systems by generating complete interactions that improve diagnostic and treatment capabilities."}, {"title": "4.3 Medical Training and Simulation", "content": "In Medical Training and Simulation, simulation environments are used to test and refine LLM-based agents before their use in clinical practice. Systems such as ClinicalLab (Yan et al., 2024) and Al Hospital (Fan et al., 2024) evaluate diagnostic and treatment performance by simulating interactions across many specialties and complex healthcare scenarios. The system Agent Hospital (Li et al., 2024b) further improves this process by allowing repeated training through large-scale simulations. In the field of medical education, systems such as MEDCO (Wei et al., 2024a) support training in diagnostic reasoning and collaborative problem solving, while AIPatient (Yu et al., 2024) integrates electronic health records with knowledge graphs to simulate realistic clinical scenarios. The system SurgBox (Wu et al., 2024) provides a training environment for surgical procedures with real-time decision support that has been validated against actual surgical records."}, {"title": "4.4 Healthcare Service Optimization", "content": "In Healthcare Service Optimization, LLM-based agents improve the delivery of healthcare by automating tasks such as patient education, data collection, and support services. Research shows that automating these non-diagnostic tasks reduces the workload of healthcare professionals while maintaining service quality (Swarms, 2025; Mukherjee"}, {"title": "5 Evaluation and Benchmarking", "content": "Evaluating LLM-based medical agents is essential for confirming their reliability, safety, and clinical effectiveness. A comprehensive evaluation framework is required to measure performance across different medical tasks, identify limitations, and guide improvements for clinical applications. A summary of the evaluation metrics and benchmark categories is provided in Table 2 in the appendix."}, {"title": "5.1 Benchmark Categories", "content": "Benchmarks for LLM-based medical agents can be divided into three categories.\nStatic Question-Answering benchmarks evaluate medical knowledge through tasks that have predetermined answers. For example, MedQA (Jin et al., 2020) simulates USMLE-style questions, MedMCQA (Pal et al., 2022) includes 194,000 questions covering 2,400 topics across 21 subjects, PubMedQA (Jin et al., 2019) assesses the understanding of biomedical research, and MMLU (Hendrycks et al., 2021b,a) offers cross-domain single-choice questions. Although these datasets are useful for testing factual knowledge, they do not capture the interactive and sequential decision-making seen in clinical practice.\nWorkflow-based Simulation benchmarks mimic clinical decision-making through multiple stages. For instance, MedChain (Liu et al., 2024a) contains 12,163 cases from 19 specialties and uses 7,338 medical images, AI Hospital (Fan et al., 2024) evaluates interactions between healthcare providers and patients using the MVME dataset, AgentClinic (Schmidgall et al., 2024b) offers versions for both multimodal analysis and dialogue-based scenarios, and ClinicalLab (Yan et al., 2024) tests diagnostic performance across 24 departments and 150 diseases. These benchmarks reflect the dynamics of clinical reasoning and the adaptation required when patient information changes, although their complexity makes standardization challenging.\nAutomated Evaluation frameworks are developed to reduce reliance on human evaluators. For example, AI-SCE (Mehandru et al., 2024) uses an OSCE-"}, {"title": "5.2 Metrics for Task-specific Evaluation", "content": "Exact Match Metrics are used for tasks with clear correct answers, such as multiple-choice questions. In these tasks, accuracy, precision, and recall are calculated by directly comparing the model outputs with reference answers. Benchmarks such as MedQA (Jin et al., 2020) and MedMCQA (Pal et al., 2022) often use these metrics. While these metrics are effective for assessing factual knowledge, they may not be sufficient for tasks that involve complex reasoning or detailed explanations.\nSemantic Similarity Metrics are applied to text generation tasks, such as writing clinical reports or diagnostic summaries. These metrics assess how well the meaning of the generated text matches that of the reference text. Metrics such as BLEU (Papineni et al., 2002), which measures n-gram overlap, ROUGE (Lin, 2004), which evaluates summarization quality, and BertScore (Zhang et al., 2020), which uses contextual embeddings to capture semantic relationships, have been applied in benchmarks such as ClinicalLab and MedChain.\nLLM-based Evaluation Metrics use language models themselves to evaluate outputs based on factors such as coherence, relevance, and reasoning quality. For example, ChatCoach (Huang et al., 2024a) uses LLMs to assess the effectiveness of communication and decision making in patient consultations, while the Retrieval-Augmented Evaluation framework (Liu et al., 2024b) used in RJUASPs measures the alignment of outputs with standard clinical pathways. This approach provides a scalable and adaptable method for assessing complex, multi-step clinical tasks."}, {"title": "6 Discussions", "content": "Integrating Large Language Model (LLM)-based agents into medical workflows presents both challenges and opportunities. While previous work has achieved successes, the field remains in its early stages. Several significant challenges persist, and many opportunities require further exploration to fully realize their potential in healthcare applications. The following sections discuss these challenges and opportunities."}, {"title": "6.1 Technical Challenges", "content": ""}, {"title": "6.1.1 Hallucination Management", "content": "LLM hallucinations\u2014instances where models generate incorrect or misleading information\u2014pose a significant risk in medical contexts, potentially leading to erroneous diagnoses and treatments (Huang et al., 2024b). Benchmarks such as MedHallBench (Zuo and Jiang, 2024) and HaluEval (Li et al., 2023) highlight the need for reliable verification systems and error prevention mechanisms, especially in multi-agent scenarios where mistakes can propagate. Future research should focus on developing verification systems and dynamic error-correction methods that continuously update models with real-time, validated medical knowledge."}, {"title": "6.1.2 Multimodal and Multilingual Integration", "content": "LLM-based agents must process various data types, including clinical texts and medical images, and handle variability in medical terminology across different languages and cultures (Li et al., 2024a; Mehandru et al., 2024). Variations in documentation standards and regional practices add to this complexity. It is crucial to develop models that can reliably operate in both multilingual and multimodal contexts."}, {"title": "6.1.3 Cross-Department Integration", "content": "Healthcare environments encompass various departments, such as emergency, outpatient, and long-term care, each with its own workflows and documentation standards (Qiu et al., 2024). Achieving interoperability and accurate data exchange among these settings is challenging. Future work should focus on developing universal standards and adaptive interfaces that harmonize terminology and processes across departments, ensuring effective communication among LLM-based agents."}, {"title": "6.2 Evaluation Challenges", "content": "Evaluating LLM-based medical agents is challenging. Traditional static benchmarks, which focus on fixed question-answering tasks, do not capture the dynamic and interactive aspects of clinical workflows, such as sequential decision-making, adaptive reasoning, and effective communication with patients and clinicians (Jin et al., 2020; Schmidgall et al., 2024b). Moreover, many medical applications require integrating heterogeneous data types, including text records, images, and laboratory results, which calls for evaluation"}, {"title": "6.3 Implementation Barriers", "content": ""}, {"title": "6.3.1 System Integration Complexity", "content": "Large-scale systems like the Polaris healthcare system (Mukherjee et al., 2024), which involve millions of professionals and established decision-making processes, illustrate the complexity of integration. Although many LLM frameworks prove valuable in specific applications, their broader integration does not always lead to improvements in operational efficiency."}, {"title": "6.3.2 Resource Allocation Dilemma", "content": "Developing and maintaining LLM-based agents requires significant computational resources, resulting in high costs for medical institutions. Such investments may produce systems that are not entirely reliable, raising concerns about their cost-effectiveness."}, {"title": "6.4 Ethical and Privacy Concerns", "content": ""}, {"title": "6.4.1 Patient-Centered Design", "content": "Medical diagnosis systems powered by LLM agents currently receive limited feedback from patients and caregivers, despite the importance of including their perspectives in decision-making (Kim et al., 2024b). Most existing frameworks focus solely on interactions with physicians. A more responsible approach would integrate patient narratives, physician observations, and caregiver input to support a truly patient-centered process."}, {"title": "6.4.2 Algorithmic Bias", "content": "Both general-purpose and medically fine-tuned LLMs can exhibit various biases, including social and cognitive biases. The BiasMedQA benchmark (Schmidgall et al., 2024a) evaluated seven types of"}, {"title": "6.4.3 Privacy and Security Threats", "content": "Sensitive data used for training may be exposed during text generation or extracted through techniques such as inference attacks (Kandpal et al., 2023) or data extraction (Carlini et al., 2021). It is critical to protect sensitive information in accordance with regulations like GDPR (EU) (GDPR, 2016) and HIPAA (USA) (Act, 1996) when deploying medical agents. Data collection for developing LLM agents must prioritize privacy protection. (Dou et al., 2024) suggests using LLMs for autonomous data generation and labeling as a means to protect privacy. In addition, privacy-preserving data processing methods, such as differential privacy, can add controlled noise to data so that individual records do not significantly influence overall results while preserving data utility."}, {"title": "6.5 Future Opportunities and Application", "content": ""}, {"title": "6.5.1 Inspiration of O1 and R1 for Medical Reasoning", "content": "The evolution of LLM-based medical agents can benefit from insights drawn from DeepSeek R1 and inference-time scaling strategies. DeepSeek R1 (Guo et al., 2025) has shown that reinforcement learning combined with long-chain reasoning leads to more accurate and context-aware medical decision-making, offering potentials for improving autonomous medical agents (Faray de Paiva et al., 2025). By continuously optimizing AI-generated diagnoses and treatment recommendations through iterative self-evolution, LLM-based agents can better integrate multimodal clinical data, including electronic health records, medical images, and laboratory findings (Xu et al., 2024). Inference-time scaling, allowing LLMs more reasoning time, has been shown to improve performance in complex tasks such as differential diagnosis and treatment planning (Huang et al., 2025), consistent with the hypothetico-deductive method used in clinical reasoning. Future research should explore how LLM-based agents can dynamically adjust inference time based on task complexity while incorporating reinforcement learning-based optimization techniques"}, {"title": "6.5.2 Integration with Physical Systems", "content": "Expanding LLM-based agents from virtual applications to integration with physical systems represents a significant step in medical care. While LLMs excel at data analysis and decision support, connecting them with physical systems such as medical robots could enable direct patient care. Such systems might combine language processing with physical inputs to support tasks like surgical assistance and patient monitoring. For example, empowering nursing robots (Zhao et al., 2025) is one potential approach. However, this integration raises challenges regarding safety and real-time performance. Addressing technical limitations, ensuring system reliability, and resolving ethical concerns are necessary for successful integration. Hardware systems must accurately execute LLM outputs because errors could endanger patient safety, and high costs or technical complexity may limit system availability. Future work should focus on improving the integration of LLM-based agents with physical systems and on creating practical implementation frameworks."}, {"title": "6.5.3 Advancements in Training Simulation", "content": "Current medical LLM agents often use simulated hospitals for training, such as the Agent Hospital framework, which enables the autonomous evolution of doctor agents through synthetic patient interactions (Li et al., 2024b). Extending these simulations to include educational medical games could improve training data generation and learning experiences, even though challenges in data quality remain. AI-driven patient simulations that provide structured feedback have demonstrated effectiveness in enhancing clinical decision-making (Br\u00fcgge et al., 2024), but validating data generated by such games remains resource intensive."}, {"title": "7 Conclusion", "content": "This survey examines LLM-based agents in medicine, covering their architectures, applications, and challenges. While these agents enhance diagnostics, data analysis, and clinical workflows, issues remain in hallucination management, multimodal integration, and medical reasoning accuracy. Future work should focus on real-time error correction, improved multimodal fusion, and hybrid reasoning to enhance reliability and clinical utility."}, {"title": "Limitations", "content": "This survey has several inherent limitations that should be considered. Due to the rapid development of LLM-based medical agents, our review primarily covers works published between 2022 and early 2024, which means future developments may introduce new architectures and approaches not captured in this analysis. Additionally, while we aimed for comprehensive coverage, we focused mainly on English-language publications in major academic databases such as PubMed, ACM Digital Library, arXiv, and Google Scholar. Valuable work published in other languages or regional databases may not be included in our analysis. These limitations reflect the inherent constraints of conducting a survey in a rapidly evolving field rather than shortcomings in the reviewed research itself."}]}