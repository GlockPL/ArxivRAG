{"title": "Why Misinformation is Created? Detecting them by Integrating Intent Features", "authors": ["Bing Wang", "Ximing Li", "Changchun Li", "Bo Fu", "Songwen Pei", "Shengsheng Wang"], "abstract": "Various social media platforms, e.g., Twitter and Reddit, allow people to disseminate a plethora of information more efficiently and conveniently. However, they are inevitably full of misinformation, causing damage to diverse aspects of our daily lives. To reduce the negative impact, timely identification of misinformation, namely Misinformation Detection (MD), has become an active research topic receiving widespread attention. As a complex phenomenon, the veracity of an article is influenced by various aspects. In this paper, we are inspired by the opposition of intents between misinformation and real information. Accordingly, we propose to reason the intent of articles and form the corresponding intent features to promote the veracity discrimination of article features. To achieve this, we build a hierarchy of a set of intents for both misinformation and real information by referring to the existing psychological theories, and we apply it to reason the intent of articles by progressively generating binary answers with an encoder-decoder structure. We form the corresponding intent features and integrate it with the token features to achieve more discriminative article features for MD. Upon these ideas, we suggest a novel MD method, namely Detecting Misinformation by Integrating Intent featuRes (DM-INTER). To evaluate the performance of DM-INTER, we conduct extensive experiments on benchmark MD datasets. The experimental results validate that DM-INTER can outperform the existing baseline MD methods.", "sections": [{"title": "1 Introduction", "content": "In our daily lives, various social media platforms, e.g., Twitter, allow people to disseminate a plethora of information more efficiently and conveniently. However, these platforms are inevitably full of misinformation, causing damage to diverse aspects, e.g., people's spirit and social economy [24, 39, 42]. For example, a recent article demonstrated that a stagnant glass of water was seen in videos of Chinese astronauts, and its caption attempted to prove the footage wasn't filmed in space. Subsequent investigation confirmed this article as misinformation, and its goal is to smear China, and inflict significant damage on its international standing. To reduce the negative impact caused by misinformation, timely identification of them, namely Misinformation Detection (MD), has become an active research topic receiving widespread attention [11, 13, 52]. Basically, the goal of MD is to automatically detect the veracity, e.g., fake and real, of any article posted by social media users.\nTo handle the task of MD, many attempts have been made over the past decade [25, 57, 65, 66]. Different from the traditional text classification problem, MD is much more challenging since the veracity of articles is influenced by diverse aspects, instead of the article content only. Therefore, the cutting-edge MD methods concentrate on extracting more discriminative features by incorporating influential aspects from psychology and sociology perspectives,"}, {"title": "2 Related Works", "content": "We systematically review the previous published works on MD and intent reasoning, and briefly summarize them in this section."}, {"title": "2.1 Misinformation Detection", "content": "Misinformation, based on the data format of the information, can be classified as fake news and rumors, which has caused seriously negative impacts on the economy, politics, and more [39, 42]. To alleviate their effects, MD is emergent as an active topic. Existing methods for detecting misinformation primarily focus on content-based approaches [11, 13, 34, 44, 52, 57]. In general, they employ a variety of deep learning models to learn the potential correlations between content and veracity labels. In addition to this, content-based MD methods also introduce various external features to aid detection [57, 65, 66]. For example, some works propose to introduce domain labels to enhance the performance of MD models across different domains, thereby improving its overall performance on the dataset [25, 26, 66]. Beyond these discriminative approaches, with the rapid development of large language models, some arts have harnessed the world knowledge stored within these models, and prompt them to generate veracity predictions and even their underlying rationales in a generative manner [10, 43, 45].\nUnlike these approaches, we find that the intent of articles also determines the veracity of the news. For instance, if an article exhibits clear racial bias, it is more likely to be misinformation. To this end, we propose to progressively reason the potential intent behind the article and mine the intent features to enhance MD methods. Within the community, there are few efforts that explore the relationship between intent and misinformation. These studies primarily analyze the intents of misinformation spreaders on social media [1, 62], instead of focusing on the potential role of misinformation creators for the MD task. For example, Agarwal et al. [1] heuristically assess the intent of fake news spreaders by presenting"}, {"title": "2.2 Intent Reasoning", "content": "Intent detection. This work focuses on uncovering the intents behind the misinformation creators. In the natural language processing community, several studies have delved into detecting the intent expressed by textual content [7, 17, 63]. This task can be employed to enable conversational agents to identify potential purposes in user dialogues and provide responses promptly. Current studies primarily concentrate on the typical supervised learning settings, where the data distribution and corresponding intent labels for the training and testing sets are identical [7, 56], or in a more practical scenario, involving the detection of out-of-distribution intents [17, 63, 64]. These efforts aim to train prominent intent detection models under the condition of existing out-of-distribution data in the training set. In this paper, due to the lack of ground-truth intent labels in MD datasets, our focus is on a more challenging scenario, namely zero-shot intent detection. Unlike zero-shot tasks where an additional support set is provided for training, and then the trained model is transferred to new data [20, 36], our scenario involves identifying intents without any supervised data. To address this challenge, recent efforts leverage the reasoning capabilities of pre-trained language models (PLMs) [2, 50]. Through the use of manually crafted prompt queries, various prompting strategies are designed for reasoning [16, 55, 58].\nReasoning on language models. Recently, with the rapid development of cutting-edge pre-training techniques, a considerable amount of arts leverage PLMs for reasoning in various areas such as sentiment analysis [6, 27], mathematics [50, 59], and multi-modality [60]. Beyond directly prompting language models to generate answers, some studies propose using PLMs for chained reasoning, e.g., Chain-of-Thought (CoT) [15, 50, 59] and tree-of-thought [54], to explicitly generate the reasoning process. Accordingly, our work draws inspiration from these approaches to manually construct an intent hierarchy and utilize PLMs for progressive reasoning within this hierarchical structure."}, {"title": "3 Our Proposed Method", "content": "In this section, we briefly describe the task formulation of MD, and then introduce the proposed DM-INTER method in detail.\nProblem formulation of MD. Formally, each training sample (x, y) is composed of a raw article x and its ground-truth veracity label y \u2208 {0, 1}, where y = 0/1 represents the article is real / fake. Given a collection of N training samples D = {(xi, yi)}^N_{i=1}, the goal of MD is to train a misinformation detector Fe(\u00b7) with D to predict veracity labels for unseen articles. For clarity, the important notations and their descriptions are summarized in Table 2."}, {"title": "3.1 Overview of DM-INTER", "content": "As illustrated in Fig. 2, DM-INTER consists of the following four components. (1) LM encoder, specified by the T5 encoder [30], extracts the hidden token embeddings of a given article. (2) LM decoder, initialized by the T5 decoder, reasons intents on the pre-defined intent hierarchy and generate the intent features. (3) Fusion network integrates the token embeddings and intent features into an overall article representation. Finally, (4) veracity classifier provides the veracity prediction of the article.\nFormally, given an article xi = {xij}^L_{j=1}, where L indicates the length of the article, we use a pre-trained T5 encoder F\u03b8(\u00b7) to generate its hidden token embeddings h = F\u03b8(xi) = {hij}^L_{j=1}.\nThen, to reason the potential intent behind xi, we refer to some psychological concepts [21, 37] and present an intent hierarchy in Fig. 1, which can formulate intent detection as a hierarchical text classification problem [48, 61] along the hierarchy, and we solve it by using a generative approach. Specifically, for intents in the pre-defined set I = { Public, Emotion, Individual, Popularize, Clout, Conflict, Smear, Bias, Connect }, we manually design their corresponding natural language queries Q = {Qk}^I_{k=1}, which can be answered by yes / no (specific implementation is described in Sec. 3.2). Based on these queries, we progressively prompt a T5 decoder F\u03b7(\u00b7) to reason one or multiple paths on the hierarchy, and obtain a textual intent reasoning sequence, which is represented as z\u2081 = {zij}^l_{j=1} where I denotes the length of the sequence. To further supervise the decoder to generate answers for unseen articles, we introduce an auto-regressive objective LD with zi to conduct a self-training strategy. Meanwhile, during the reasoning process, the T5 decoder also outputs the token embeddings of zi, represented by h^d\u1d62 = Fn(zi) = {h^d_{ij}}^L_{j=1} {h^d_{ij}}^L_{j=1}. Then, we directly adopt the following average pooled representation, which can be seen as the intent feature.\n\nh^d\u1d62 = 1/L \u03a3^L_{j=1} h^d_{ij}\n\n(1)\nAccordingly, given two features h\u1d62 and h^d\u1d62, we adopt a multi-head attention network to fuse them to obtain the overall article representation e\u1d62 = F\u03a8(h\u1d62,\u0125^d\u1d62), and formulate the following objective to optimize the model parameters.\nmin L = 1/N \u03a3^N_{i=1} ai(lCE (e\u1d62W, yi) + \u03b2LD), (2)\n\u03a6,\u03a0,\u03a8,W\nwhere W represents a learnable veracity classifier, lCE (,) denotes a cross-entropy loss function, and \u03b2 is a trade-off parameter to balance two objectives, respectively. Additionally, we further improve DM-INTER by heuristically assigning weights a\u1d62 for training samples to"}, {"title": "3.2 Intent Feature Extraction and Optimization", "content": "Given an article xi, we extract its intent reasoning sequence zi and intent feature h^d\u1d62 with an LM decoder F\u03a6(\u00b7), and optimize it by using a self-training strategy. To achieve this, we follow the implementation process below.\nIntent hierarchy and queries. We review the viewpoints expressed by the psychological literature [21, 33, 42] on the question, \u201cwhy misinformation is created?\". The answers can be referred to as intents. Based on their granularity, we build an intent hierarchy, shown in Fig. 1, enabling us to reason intents from coarse to fine granularity (from top to bottom on the hierarchy) and thereby improving the reliability of intent reasoning. Specifically, these pre-defined intents and their corresponding descriptions are detailed as follows:\n\u2022 Public. The article intends to influence public perceptions.\n\u2022 Emotion [42, 49, 57]. The article aims to express emotions or stir up emotions in others.\n\u2022 Individual. The article conveys opinions about specific individuals or events.\n\u2022 Popularize [38]. The article seeks to disseminate knowledge, e.g., scientific facts and current societal issues, thereby providing valuable information to enhance public awareness of ongoing events and problems.\n\u2022 Clout [21]. The article is strategically crafted to attract the attention of other social media users to achieve profit. These articles often feature attention-grabbing headlines and content.\n\u2022 Conflict [23]. The article attempts to create conflicts between certain individuals or groups for political purposes or other improper reasons.\n\u2022 Smear [32]. The article deliberately smears and attacks specific individuals or organizations, due to personal animosity, political opposition, or competitive relationships.\n\u2022 Bias [37]. The article expresses an explicit personal bias.\n\u2022 Connect. The article provides a platform for individuals to share authentic perspectives on the same event or topic, fostering social connections and common interests.\n\u2022 NoIntent [33, 62]. The intent expressed by the article is not among the intents listed above, or the article does not express a clear intent, e.g., simply sharing.\nAfterwards, to prompt an LM decoder to reason intents, we design several natural language queries for the above intents, which is denoted as Q = {Qk}^|I|k=1 in Table 3.\nIntent reasoning and feature extraction. Based on the above intent hierarchy and queries, we can conduct reasoning of intents and extract their features. Specifically, following a breadth-first\""}, {"title": "3.3 Veracity Feature Fusion", "content": "Given the token embedding h\u1d62 output from the encoder and the intent feature h^d\u1d62, we fuse them into an overall article representation ei and use it for veracity prediction. Specifically, we leverage a confidence-guided attention network to fuse them as follows:\n\nei = Att (c\u1d62h\u1d62WO, h^d\u1d62WK, h^d\u1d62W\u1d62), (6)\nwhere Att() is a typical attention network [40], and WO, WK and Wy are learnable query, key and value parameters, respectively. Additionally, we take into account that the confidence of intent Ti answers {ait}^T\u1d62_{t=1} can impact the credibility of intent features. If the output confidences of answers are low, it is advisable to assign a smaller weight to the corresponding intent feature h^d\u1d62 during the feature fusion stage. Building upon this consideration, we propose to assign an adaptive weight c\u1d62 to intent features h^d\u1d62, calculated as the average probability value of the Ti answers generated during the intent reasoning process."}, {"title": "3.4 Adaptive Weight Assigning", "content": "During the reasoning on the intent hierarchy, two challenges inevitably arise: error propagation and veracity inconsistency. To alleviate these issues, we assign an adaptive weight, denoted as ai, in Eq. (2) for each training sample. The specific descriptions are as follows:\nError propagation. The error propagation issue means that if an intent in the intent hierarchy is reasoned incorrectly, then its child intents will also be incorrect. To mitigate this, we design a weight a^V\u1d62. Specifically, for the reasoning reasoning steps {1, 2, \u2026\u2026\u2026, Ti} described in Sec. 3.2, we reversely re-reason them and output new answers {a'\u1d62t}^T\u1d62_{t=1}. If there is a significant difference between the original and reversed answers, indicating that the error propagation exists, and we will assign a lower weight to this sample. We implement the calculation of the weight with an L2 norm as follows:\n\n\u03b1^V\u1d62 = T^\u207b\u00b9 sqrt(\u03a3^T\u1d62_{t=1} ||ait - a'it||\u00b2)\n\n(7)\nVeracity inconsistency. Given the pre-defined hierarchy shown in Fig. 1, each intent corresponds to a veracity label, e.g., the article expressing Bias tends to be fake. Based on this premise, we suggest"}, {"title": "4 Experiments", "content": "In this section, we conduct extensive experiments for answering the following questions:\n\u2022 Q1: How effective is our proposed model DM-INTER in integrating intent features compared to the backbone models without it?\n\u2022 Q2: Does each module in DM-INTER have a promoting effect on the overall performance?\n\u2022 Q3: Can our proposed DM-INTER accurately and explicitly reason intents of articles?"}, {"title": "4.1 Experimental Settings", "content": "Datasets. We conduct our experiments across three benchmark MD datasets to evaluate the performance of DM-INTER. For clarity, their statistics are demonstrated in Table 4, and we declare their details as follows:\n\u2022 GossipCop is a prevalent MD dataset collected by Shu et al. [34], which totally includes 11,800 pairs of articles and their veracity labels. We follow Zhu et al. [65] to divide GossipCop into training, validation, and test subsets. Specifically, they divide the dataset according to the time stamps of articles, which is a more practical and challenging setting. Its training articles were posted between 2000 and 2017, and test and validation samples were published in 2018, respectively.\n\u2022 PolitiFact is provided by Popat et al. [29]. Its original veracity labels include {true, mostly true, half true, mostly false, false, pants-on-fire}. Following Rashkin et al. [31], we incorporate {true, mostly true, half true} into the real class, and {mostly false, false, pants-on-fire} into fake. Additionally, we divide the dataset by following the settings of Vo and Lee [41].\n\u2022 Snopes\u00b2 [28] is collected from a fact-checking website, and the veracity labels have been manually verified by human experts, and we follow Vo and Lee [41] to divide this dataset.\nBaselines. We thoroughly compare our DM-INTER to several baseline MD models to demonstrate its performance. They are briefly described as follows:\n\u2022 BERT [4] is a prevalent language model pre-trained using masked tokens and next-sentence prediction objectives. It is typically employed to extract semantic features from texts.\n\u2022 T5 [30] is the language model pre-trained for the text generation task. It consists of an encoder to capture features of input queries and a decoder to auto-regressively generate"}, {"title": "4.2 Main Results (Q1)", "content": "We measure our DM-INTER with 7 typical evaluation metrics in the experiments, including accuracy, precision, recall, macro F1 value, F1 values Flreal and F1fake corresponding to two categories, and Area Under Curve (AUC)."}, {"title": "4.3 Ablative Study (Q2)", "content": "To empirically answer Q2, we conduct ablative experiments to assess the positive effect of each key component in DM-INTER. The experiments are implemented using T5 as the baseline model across all three MD datasets, and the results are shown in Table 6. Our used ablative versions of DM-INTER are briefly described as follows:\n\u2022 w/o LD indicates the version without optimizing the model parameters using LD in Eq. (2), equivalent to setting the parameter \u03b2 to 0;\n\u2022 w/o hierarchy indicates the version without utilizing the intent hierarchy designed in this paper for intent reasoning. In other words, it flattens the intent hierarchy in Fig. 1, and inputs all intent queries Q into the model during reasoning;\n\u2022 w direct query indicates the version without the intent reasoning process, instead, it directly queries the model at the decoder side, \"what is the intent behind this article?\" and outputs a short answer;\n\u2022 w/o weights indicates the version without employing the weights proposed in this paper for sample filtering.\nIn general, the performance of all ablation experiments is consistently lower than that of our comprehensive model DM-INTER,"}, {"title": "4.4 Sensitivity Analysis (Q2)", "content": "To further investigate Q2, we conduct a sensitivity analysis on a crucial hyper-parameter, \u03b2 in Eq. (2), to examine the model's sensitivity to \u03b2 and determine its most beneficial value. The experimental results are illustrated in Fig. 3, where we evaluate our experiments using macro F1 on all three datasets GossipCop, PolitiFact, and Snopes, and we select \u03b2 from the set {0, 0.0001, 0.001, 0.01, 0.1, 1, 10}. Generally, the model consistently shows the best performance on all datasets when \u03b2 is approximately 0.0001 and exhibits a declining trend as it decreases or increases."}, {"title": "4.5 Case Study (Q3)", "content": "In this section, we provide illustrative examples to partially answer Q3. We select three representative cases from the GossipCop dataset and show them in Table 7. Specifically, the first example employs some exaggerated vocabulary, e.g., \"Warning,\" to capture the reader's attention, and DM-INTER accurately identifies the intent of the article as Clout. The second example primarily popularizes information about the Coachella music festival's schedule, and DM-INTER also provides accurate answers. In the final case, the article simply shares information without manifesting a clear intent,"}, {"title": "5 Conclusion and Future Work", "content": "In this work, we present to investigate the intents expressed by articles and utilize them to identity misinformation. Therefore to achieve this target, we design a new MD model named DM-INTER, which explicitly reasons intents and captures the intent features. To be specific, we design an intent hierarchy based on several psychological studies and use it to progressively reason intents with a pre-trained auto-regressive decoder. Additionally, we also assign adaptive weights for training samples to avoid error propagation and veracity inconsistency issues. Our experimental results can indicate that DM-INTER can improve the performance of the baseline models, and we also provide some representative cases to demonstrate that DM-INTER can accurately reason intents. Furthermore, we also declare a limitation existing in our work, which can be improved in our future work. We construct the intent hierarchy by collecting different types of intents and organizing them into a hierarchical structure. The hierarchy used in this article has only two layers. In the future, with deep research in psychology and sociology, we look forward to designing more complex and diverse hierarchical structures to further improve the accuracy of intent recognition."}]}