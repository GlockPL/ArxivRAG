{"title": "Korean Aspect-Based Sentiment Analysis via Implicit-Feature Alignment with Corpus Filtering", "authors": ["Kibeom Nam"], "abstract": "Investigations into Aspect-Based Sentiment Analysis (ABSA) for Korean restaurant reviews are notably lacking in the existing literature. Our research proposes an intuitive and effective framework for ABSA in low-resource languages such as Korean. It optimizes prediction labels by integrating translated benchmark and unlabeled Korean data. Using a model fine-tuned on translated data, we pseudo-labeled the actual Korean NLI set. Subsequently, we applied LaBSE and MSP-based filtering to this pseudo-NLI set as implicit feature, enhancing Aspect Category Detection and Polarity determination through additional training. Incorporating dual filtering, this model bridged dataset gaps, achieving positive results in Korean ABSA with minimal resources. Through additional data injection pipelines, our approach aims to utilize high-resource data and construct effective models within communities, whether corporate or individual, in low-resource language countries. Compared to English ABSA, our framework showed an approximately 3% difference in F1 scores and accuracy. We release the dataset and our code for Korean ABSA, at this link\u00b9.", "sections": [{"title": "Introduction", "content": "In low-resource downstream tasks such as Korean ABSA, constraints exist in constructing ABSA systems that are socially and industrially beneficial (e.g., obtaining accurate labels and high-quality training data, building a efficient serving model). Addressing this challenge is fundamentally crucial for the practical implementation of multilingual ABSA leveraging the advantages of language models (Zhang et al., 2021; Lin et al., 2023). On the other hand, ABSA utilizing Large Language Models like ChatGPT can perform labeling through prompt tuning. However, it still has limitations compared to small-scale models in terms of classifier metrics and resource for training and inference (Wang et al., 2023; Wu et al., 2023).\nIn this study, we derive pseudo-labels for real Korean reviews using machine-translated English ABSA data, inspired by the past research (Balahur and Turchi, 2012; Hoshino et al., 2024). Moreover, we employ Dual filtering on the actual Korean corpus converted to implicit NLI task (Hendrycks and Gimpel, 2017; Sun et al., 2019; Feng et al., 2022), thereby constructing an effective framework coined as Korean ABSA using Pseudo-Classifier with Corpus Filtering (KPC-CF) for implicit-feature alignment. Through this process, we assess the impact of our constructed classifier on the practical alignment of actual reviews. We validate that the pseudo-classifier, generated through the sentence-pair approach, outperforms the single approach in translation task. Furthermore, using the model that predicts the translated dataset most effectively as a baseline, we generate pseudo-labels for actual data and conduct real-world testing of Korean ABSA. This involves subsequent fine-tuning the filtered corpus based on language-agnostic embedding similarity for review and aspect sentence pairs, along with setting a threshold for Maximum Softmax Probability (MSP) in pseudo-labels.\nThe main contributions of our work are:\n\u2022 This is, to our knowledge, the first approach to generating a pseudo-classifier for automatic classification of aspect-based sentiment in the actual Korean domain.\n\u2022 For actual review-based ABSA, we propose a filtered NLI corpus as implicit feature and fine-tuning framework that enables important data selection in low-resource languages on models trained with high-resource dataset.\n\u2022 A new challenging dataset of Korean ABSA, along with a KR3 and translated benchmark correlated with cross-lingual understanding."}, {"title": "Two phase of Pseudo-Classifier", "content": "The goal of this research is to propose a framework for achieving the best ABSA on actual data with Korean nuances through high-resource languages. Past research by Balahur and Turchi (2012) has shown that Machine Translation (MT) systems can obtain training data for languages other than English in general sentiment classification. However, existing research using translation data for alignment and alignment-free methods (Li et al., 2020; Zhang et al., 2021) inadequately address the challenge of universal knowledge transfer for linguistic subgroups like Korean. Also, although it was a different domain at Zhou et al. (2021), we found it necessary to investigate whether the concept of pseudo-labels could help bridge the gap of feature between translated source data $D_s$ and actual target language data $D_T$. Therefore, we attempted the following two phases to assess the impact of the generated pseudo-classifier, fine-tuned using translated datasets from the ABSA benchmark and pseudo-labeled actual review data, on Korean ABSA. Fig. 2 shows the two-phase pseudo-classifiers we will employ. In the first phase, similar to the findings of Hoshino et al. (2024), the optimal baseline model for Korean reasoning is identified from the pool of models trained and assessed utilizing the translation dataset. In Phase 2, we fine-tune the baseline model $\\Psi_{pre}(\\Phi(D_s);\\theta_{D_s})$, which was effective in training on $D_s$, by additionally incorporating pseudo-labeled actual $D_T$. Employing the tuned model $\\Psi_{post}(\\Phi(D_T);\\theta_{D_s\\rightarrow D_T})$, we conduct predictions and evaluations on manually labeled actual Korean reviews. Throughout this process, LaBSE and confidence score filtering are performed to enhance implicit features $(D_T)$. Detailed description of our Language Adaptation for aligned ABSA task is provided in Appendix B."}, {"title": "LaBSE based Filtering", "content": "In this approach, we aim to extract good-quality sentences-pair from the pseudo-NLI corpus. Language Agnostic BERT Sentence Embedding model (Feng et al., 2022) is a multilingual embedding model that supports 109 languages, including some Korean languages. Feng et al. (2022) suggested that the dual-encoder architecture of the LaBSE model, originally designed for machine translation in source-target language data (Batheja and Bhattacharyya, 2022, 2023), can be applied not only to other monolingual tasks like Semantic Textual Similarity (STS) but also to data (i.e., sentence pair-set) filtering for creating high-quality training corpora in terms of meaning equivalence. Therefore, to mitigate performance degradation caused by the linguistic gap between translated $D_s$ and actual Korean $D_T$ during fine-tuning, we introduce the following filtering method that enables the identification of meaning equivalence or connotation (Ghadery et al., 2019) in actual Korean sentence-pairs, even when viewed from the perspective of model trained on bilingual translation pairs. We generate the sentence embeddings for the review text and aspect of the pseudo-NLI corpora using the LaBSE model. Then, we compute the cosine similarity between the review text and aspect sentence embeddings. After that, we extract good quality NLI sentences based on a threshold value of the similarity scores.\nLaBSE scoring Let $D_I = \\{(x_s^i,x_a^i)\\}_{i=1}^N$ be a pseudo-NLI corpus with $N$ examples, where $x_s^i$ and $x_a^i$ represents $i^{th}$ review and aspect sentence respectively. We first feed all the review sentences present in the pseudo-parallel corpus as input to the LaBSE model\u00b2, which is a Dual encoder model with BERT-based encoding modules to obtain review sentence embeddings $(S_i)$. The sentence embeddings are extracted as the 12 normalized [CLS] token representations from the last transformer block. Then, we feed all the aspect sentences as input to the LaBSE model to obtain aspect sentence embeddings $(A_i)$. We then compute cosine similarity $(score_i)$ between the review and the corresponding aspect sentence embeddings.\n$S_i = LaBSE (x_s^i)$ (1)\n$A_i = LaBSE (x_a^i)$ (2)\n$score_i = cosine\\_similarity (S_i, A_i)$ (3)\nWe aimed to apply the LaBSE scoring to the actual Korean data $D_T$, KR3, intending to facilitate flexible learning compared to the translated data $D_s$, Kor-SemEval (see Appendix C.1)."}, {"title": "Confidence score Filtering", "content": "Meanwhile, we need to develop a classifier $\\Psi_{post}$ capable of optimal predictions on the $D_T$ test, which can be considered as out-of-distribution data separate from the $D_s$. Drawing on previous research (Arora et al., 2021), we expect that language shifts ($D_s \\rightarrow D_T$) embody both Background and Semantic shift characteristics. To ensure robust learning in both aspect detection and sentiment classification, we introduce additional thresholding on Maximum Softmax Probability (MSP; Hendrycks and Gimpel 2017) after LaBSE-based filtering on the $D_T$ train set. When considering an input $x = (x_s, x_a) \\in X$ and its corresponding pseudo-label $y \\in Y$, the $score_s(x)$ for MSP is expressed as:\n$SMSP(x) = max_{key} P_{model}(y=k | x)$. (4)\nThrough this, we intended a dual scoring and filtering process to ensure that our $\\Psi_{post}$ does not retrain on misplaced confidence or subpar prediction outcomes for out-of-distribution data. The algorithm for calculate scores and filter with the target $D_T$ batch set can be found in Algorithm 1."}, {"title": "Experiment", "content": "Based on the results from Kor-SemEval, we observed analogous patterns between mBERT and XLM-RBase, notwithstanding their distinct properties (see Appendix D). Accordingly, We opted for the Baseline-NLI approach (i.e., $Baseline_{mBERT, XLM-R}$), which demonstrated the best performance, as the base model for Phase 2.\nMain Results To investigate the effect of features $(D_T)$ for each corpus, we conduct baseline tuning comparisons between the PL and the PL-CF (see Tab. 1, 2 for details). The variants of our tuning framework includes:\n\u2022 Baseline+PL (Pseudo-Labeled data): Fine-tuning Baseline-NLI with pseudo-KR3.\n\u2022 Baseline+PL-CF (Corpus Filtering): Fine-tuning Baseline-NLI with the data obtained by truncating instance from pseudo-KR3, where the threshold of MSP (Hendrycks and Gimpel, 2017) is less than 0.5 and the cosine similarity between LaBSE embeddings is less than 0.15.\n\u2022 Baseline+TR (TRanslated data)+PL: Fine-tuning Baseline-NLI (pre-tuned or jointly fine-tuned with Kor-SemEval) using pseudo-KR3.\n\u2022 KPC-CF (Baseline+TR+PL-CF): Fine-tuning Baseline-NLI (pre-tuned or jointly fine-tuned with Kor-SemEval) using PL-CF.\nResults on the KR3 test set are presented in Tab. 2 and Fig. 3. We find that the KPC-CF approach achieved adequately trained results in both subtasks for the actual korean data. The model pre-tuned with Kor-SemEval achieves the best performance in Aspect Category Detection (ACD).\nFor Aspect Category Polarity (ACP), it performs exceptionally well in the tuning of Pseudo-Labels, especially in the Binary setting. Filtered Pseudo-Labels preserve this characteristic well and amplify the performance of all metrics within ACP."}, {"title": "Discussion", "content": "In Phase 1, XLM-R, known for its proficiency in capturing cross-lingual representations, exhibits an underfitting tendency concerning the contextual disparities in aspect vocabulary within a single task. This can be attributed to data scarcity relative to model availability for each classifier or viewed as a limitation in single task using SPM in low-resource Korean ABSA (Son et al., 2023). Nevertheless, in the NLI task, it showcases potential by outperforming mBERT, guided by \"aspect\". Conversely, mBERT demonstrates stable results in both single and NLI tasks, exhibiting an overall accuracy increase, particularly in the NLI task (Appendix D).\nFurthermore, Phase 2 reveals that the combination of the NLI approach and translation impacts the metrics of detection in aspects. Pseudo-labels in this phase contribute to enhancing the determination of sentiment, resulting in improved classifier performance. Notably, PL-CF, unlike a mere addition to translated data, play a crucial role in maintaining and enhancing accuracy and F1 score, even with fewer samples. Essentially, the filtered pseudo-NLI set alleviates the bias of pre-trained model parameters during training and enhances performance. This impact of the quality of PL further trained on TR is manifested through the embeddings generated by our model and the ablation results via thresholding (see Fig. 1, 3).\nLooking at Figure 4, In $Baseline_{XLM-R}+TR$, the Target None class exhibits relatively high softmax probabilities, while data with polarity show relatively low probabilities, indicating significant confidence in polarity and asymmetric learning between classes. The results of KPC-CF demonstrate that additional fine-tuning with filtered data significantly increases the maximum probability of the model for Target Polarity. Simultaneously, with a reduction of over 40% in data, it prevents biased class learning, forming similar distributions among Target classes. In addition, by providing shallow features as input to a low-complexity LR model, we further confirmed the efficacy of the inherent characteristics of the filtered data through observed variations in training outcomes (see Tab. 3). Our framework suggests improving task stability and reliability by setting an optimal threshold to adjust biased classes or data with uncertain classification outcomes. Building upon Ouyang et al. (2023), we've shown that filtered training data is more effective for performance than simply having a large amount of information in real-world settings."}, {"title": "Conclusion", "content": "Aspect-Based Sentiment Analysis (ABSA) has been recognized as one of the most attractive subareas in text analytics and NLP. However, obtaining high-quality or ample-size labeled data has been one of the most essential issues hindering the development of ABSA. In this paper, we addressed the language gap in ABSA by building a pseudo-classifier. This involved aligning implicit features through dual filtering, further fine-tuning Korean NLI pairs with optimal pseudo-labels from a model trained on translated data. Additionally, we presented Kor-SemEval and KR3 train (pseudo labeled & filtered), testset (Gold) composed of Korean fine-grained set. We invite the community to extend Korean ABSA by providing new datasets, trained models, evaluation results, and metrics."}, {"title": "Computational Resources", "content": "All experiments in this study were conducted using high-performance computing resources from a leading cloud platform. The computational infrastructure included instances with 50GB or more of RAM, featuring NVIDIA A100 and V100 GPUs, chosen for advanced parallel processing capabilities essential for our LMs."}]}