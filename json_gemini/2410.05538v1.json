{"title": "Online Dynamic Pricing for Electric Vehicle Charging Stations with Reservations", "authors": ["Jan Mrkos", "Anton\u00edn Komenda", "David Fiedler", "Ji\u0159\u00ed Vok\u0159\u00ednek"], "abstract": "The transition to electric vehicles (EVs), coupled with the rise of renewable energy sources, will significantly impact the electric grid. Unlike conventional fuel sources, electricity for EVs is constrained by grid capacity, price fluctuations, and long EV charging times, requiring new pricing solutions to manage demand and supply. This paper proposes a model for online dynamic pricing of reserved EV charging services, including reservation, parking, and charging as a bundled service priced as a whole. Our approach focuses on the individual charging station operator, employing a stochastic demand model and online dynamic pricing based on expected demand. The proposed model uses a Markov Decision Process (MDP) formulation to optimize sequential pricing decisions for charging session requests. A key contribution is the novel definition and quantification of discretization error introduced by the discretization of the Poisson process for use in the MDP. The model's viability is demonstrated with a heuristic solution method based on Monte-Carlo tree search, offering a viable path for real-world application.", "sections": [{"title": "1 Introduction", "content": "The mass electrification of personal transportation, concurrent with the introduction of green energy resources, will significantly impact the electric grid. Most likely, these changes will mean that drivers will need to adapt to a new way of using their soon-to-be electric vehicles. Unlike gasoline and diesel, electricity is not as easily stored in the charging location. Therefore, charging electric vehicles is subject to grid constraints and varying prices of electricity.\nTo make the allocation of the charging capacity more efficient, it is reasonable to price the charging of EVs dynamically. This way, the price signals coming from the energy markets and grid operators can propagate to the EV users. Additionally, dynamic pricing can help charging station (CS) operators maximize revenue and reduce congestion by responding to the changing demand for charging.\nThe benefits of dynamic pricing of EV charging are clear when applied to, e.g., overnight charging at home. However, when it comes to traveling long distances, EV charging is already more complicated than refueling a gasoline car and takes a lot more planning. Adding price uncertainty to the mix could make planning and travel even more difficult.\nHowever, if EV charging could be reserved ahead of time, then the price could be fixed at the time of reservation. This way, the driver could plan the whole trip and know the exact cost of charging. This is the idea behind the dynamic pricing model we propose in this paper. This type of dynamically priced, reserved EV charging session is not common in the EV pricing literature.\nThere are three things that set this work apart from the previous works: First, the product we consider is charging session reservations, which include the energy delivered to the EV, time spent at the charging station, and the parking spot. While other works often make use of some form of reserva- tions [1]-[4], they are often a byproduct of a top-down allocation scheme that assigns charging slots to EV drivers.\nSecond, the pricing of these products happens online and is fully dynamic; the price of each requested reservation can be different, reflecting the current state of the charging station, the parameters of the request, and the expected future demand for charging. Many previous works are a lot more conservative in the variability and complexity of pricing [2], [5]\u2013[7], either because their product is different, such as \u201ccharged kWh,\" or because of the computational complexity of optimizing such pricing.\nFinally, we focus on revenue maximization for the seller, operator of a single charging location. This point of view has become more popular in recent years [6], [8] as many realized that the transition to and sustainability of electric mobility is not feasible without profitable EV charging stations."}, {"title": "2 Literature review", "content": "Pricing of EV charging is an active research topic, with many papers tackling the problem from different points of view. We provide an overview of the structure of our literature survey in Figure 1.\nThe works on the pricing of EV charging are commonly divided between centralized and decentralized approaches, as is also the case in the surveys [8], [9]. A centralized approach collects all the inputs with a central authority who then makes and distributes decisions. On the other hand, the decentral- ized approach allows the participants to make decisions independently. As centralization is practically problematic in the context of public EV charging, many works, ours included, focus on decentralized approaches.\nOne branch of decentralized research takes a \"global\" view of the EV charging ecosystem, modeling both EV drivers and CSs individually in their interactions in the transportation network. The second branch of research, which includes this work as well, focuses on the \u201clocal\u201d viewpoint of a single actor in the ecosystem, such as the charging station, without the ambition of optimizing some ecosystem-wide criteria.\nThe first segment of papers that take the \u201cglobal\u201d view uses a game theoretical approach to the problem of EV charging. In [2]-[4], [10], [11], the allocation arises as part of iterative negotiation between the charging stations and the EV drivers. Price changes are used as signals to influence the decisions of the drivers and to guarantee some useful properties, such as individual rationality [2], [3] or incentive compatibility and preservation of privacy [2]. While these approaches do not rely on a central authority to make decisions, they require a widespread consensus on the rules and protocols of the system. An additional drawback of this approach is that it requires many iterations of negotiation between drivers and the CSs. This can be addressed by having agents in the form of, e.g., smartphone applications perform the negotiation on drivers' behalf. Overall, these approaches are often not practically scalable, as the required consensus between CS owners and EV drivers is difficult to achieve.\nOther works that take the \u201cglobal\u201d view of electromobility look at the EV drivers and CSs individually without applying game theoretical concepts. For example, Seyedyazdi, Mohammadi, and Farjah [12] proposes a selection algorithm for EV drivers to choose the best charging station based on the trip price travel time, as well as a pricing algorithm that considers previously reserved pricing requests and day-ahead pricing of electricity. The proposed algorithms are then allowed to interact in a simulation. Simulation results show that the proposed solution improves upon the selected baselines. However, the work suffers from the same coordinational weaknesses as the game-theoretical approaches; it assumes all the EV drivers and CSs are all using the proposed algorithms."}, {"title": "2.1 Local view of pricing", "content": "We follow the \u201clocal\u201d branch of research, focusing on an individual charging station or charging station operator and their pricing strategy. Here, the EV drivers' needs are abstracted into a much simpler model, usually a stochastic demand model. This approach is useful when the charging stations are modeled in greater detail or when the interactions are more complex. Representatives of this approach are, for example, Zhang, You, and Cai [13] and Abdalrahman and Zhuang [7], who propose a model of pricing EV charging that considers different charging speeds and prices them differently.\nWithin the local focus on the charging stations point of view, we are interested in reservations and the form that the dynamic pricing of these reservations has."}, {"title": "2.1.1 Reservations", "content": "Reservations are not common in the EV charging industry. However, for example, charging station operator EVgo [14] has recently introduced a reservation system for their charging stations. Reservation systems are useful for CS operators as they can better plan the utilization of their resources. For EV drivers, reservations reduce uncertainty about their trips.\nIn the \"local\" literature on EV charging, reservations are not particularly common either. They are present implicitly or explicitly in the auction-like mechanisms that result in the allocation of the charging capacity, such as [1], [3], [10]. Other works assume a less organized EV ecosystem and model reservations explicitly, such as [6], [15]. Fang, Lu, Hong, et al. [6] is of most interest to us as it studies the pricing of a single CS that offers reservations, and the pricing responds to previously reserved demand."}, {"title": "2.1.2 Dynamic pricing", "content": "Dynamic pricing is a relatively common feature of papers on EV charging, as illustrated in the survey [9]. However, there are big differences between the dynamic pricing schemes. First, different works price different products. Second, dynamic pricing can mean different things in different papers. Some works apply dynamic pricing to the electricity price [13]. In that case, the common choice of pricing is extending the smart-grid concept of time-of-use pricing to EV charging [16], which works by setting different prices per kWh for different time intervals, usually well ahead of time. Other works apply dynamic pricing to the per-minute fee, which is viewed as an improvement over the current state of charging per kWh as it incentivizes drivers to disconnect when their vehicle is sufficiently charged [17]. Others don't look at the charging and instead focus on the pricing of parking reservations, e.g., Fang, Lu, Hong, et al. [6] and Lei and Ouyang [18]."}, {"title": "2.2 Contributions", "content": "In this work, we focus on the full reservations (following the taxonomy proposed in Basmadjian, Kirpes, Mrkos, et al. [19]), and we price these reservations as a complete product, including the delivered electricity and the parking spot. De-facto full reservations are common with papers that take the global view of EV pricing and result in allocations. Our approach is most similar to Boateng, Si, Xia, et al. [1], who let drivers reserve charging stations before their arrival at the charging location and proposes a dynamic pricing scheme to manage demand. However, Boateng, Si, Xia, et al. [1] focuses on autonomous vehicles and takes the global view of the problem, with both customers and service provider constantly adjusting their strategies to maximize their individual utilities.\nIn the pricing, our work is most similar to Fang, Lu, Hong, et al. [6], who take the local approach to pricing. In this work, the pricing is also dynamic in the sense that the price changes in 1-hour timesteps based on demand. The price updates are broadcast to all potential customers. In contrast, our protocol has the customers request charging reservations, and the station responds with a price.\nThe main contributions of this work are:\n1. MDP-based model of online dynamic pricing of reserved EV charging service that includes the parking spot and delivered charge and that is based on available charging capacity and expected customer demand, modeled as a possibly time-dependent Poisson process,\n2. Definition of a novel error metric that quantifies the error introduced by the discretization of the Poisson process in the MDP model,\n3. Scalable heuristic solution method for the model based on Monte-Carlo tree search for pricing of the EV charging service reservations.\nWhile reservations reduce uncertainty for both the EV drivers and the CS operators, they also introduce a new layer of complexity and reduce flexibility for the EV drivers. However, this complexity can be reduced by the use of driver assistant technologies, such as smartphone apps, to make reservations on behalf of the drivers. For example, routing algorithms for EVs can plan whole trips, including the charging stops, and let the driver select the best tradeoff between the trip time and the cost [20]. Reservations are a natural extension of this approach."}, {"title": "3 MDP model for dynamic pricing", "content": "In our work, the pricing of EV charging is a question of sequential pricing decisions for incoming charging reservation requests. As such, MDP is a natural model for the problem. MDP is model of choice for other dynamic pricing works, especially when combined with reinforcement learning [7], [12], [21]. In these works, the state space is constructed with as many state variables as possible, and the pricing policy is learned from the data. However, we systematically avoid the use of reinforcement learning in our work due to the large computing requirements to train the model and the currently low availability of representative data to train the model on. Instead, we focus on a concise model of the problem and a scalable heuristic solution method.\nLastly, the demand model in our work uses a Poisson process to model the arrival of the charging requests. This is a relatively common choice in the literature on dynamic pricing of EV charging, used by [6], [12], [13]. By applying the Poisson process to our discrete-time model of online dynamic pricing, we introduce a discretization error. This error is described and quantified in Section 4."}, {"title": "3.1 Pricing Problem Description", "content": "In this work, dynamic pricing of EV charging involves setting optimal or near-optimal prices online for different charging products as customer requests for these products arrive, one after another. Seller, the CS operator, combines his resources, the charging capacity of a set of charging stations, into products offered to customers, such as half-day charging of an EV. In our case, the product is a charging session, and the different resources it consists of are charging capacities in different time slots.\nAlthough the demand for these products is unknown beforehand, the seller has historical data about customer request arrivals and a model of customer responses to changing prices. The seller's goal is to price each arriving product request in a way that maximizes its objective function, considering demand uncertainty. The objective function can be maximizing either revenue or efficiency, such as for CS operated by public utilities. This optimization occurs over a finite time horizon, after which the resources can no longer be sold.\nHere, we give a minimalist formal description of the pricing problem by considering first the supply side that puts constraints on the seller and the demand side that prompts the seller's actions. The description is illustrated by Figure 2.\nThe supply side of the problem is formed by a set of $n$ resources that can be combined into $m$ products available for sale. Each product is represented by a vector $p \\in \\mathbb{N}$, elements of which prescribe the number of individual resources used in the product. The availability of these products is constrained by the initial capacity of the resources $c_0 \\in \\mathbb{N}^n$ and the lengths of selling periods of different resources $T \\in \\mathbb{R}^+$ that determine the time after which each resource and product, it is part of, can no longer be sold.\nThe demand side of the problem is modeled by a non-homogeneous, compound Poisson counting process $N(\\tau)$, $\\tau \\in (0, \\text{max}(T))$ that models the arrivals of requests for different products in time and distributions of finite internal customer valuations for different products, {$\\mathcal{B}_p | p \\in P$}. The customers accept the offered price for the requested product if it is below their internal valuation. Otherwise, they reject the offer and leave the system.\nRealized demand takes the form of a sequence of timestamped product requests (pair $(p, \\tau)$) associated with hidden customer valuations of products, $b_i \\sim \\mathcal{B}_p$:\n\\begin{equation}\nd = ((p_1, \\tau_1, b_1), (p_2, \\tau_2, b_2), ...)\n\\end{equation}"}, {"title": "3.2 MDP Model", "content": "Having described the dynamic pricing problem, we will now develop the MDP model to determine the pricing policy $\\pi$. The pricing policy is a mapping that assigns price $a$ to the product-time pair $(p, \\tau)$ combined with the currently available and planned future capacity $c$ of the seller's resources.\nIn our MDP, defined as a 5-tuple $(S, T, R, A, s_0)$, the seller starts in some initial state $s_0 \\in S$. Each state captures the current timestep, what product is being requested, and how many resources are currently available. The seller offers a price $a \\in A$ for the requested product, taking an action that results in a transition to a new state $s' \\in S$. However, the transition is not deterministic because it is unknown whether the customer will accept or reject the price and what the next product request will be. By fitting the random demand process $N(T)$ and distributions of the customer internal valuations {$\\mathcal{B}_p | p \\in P$} to the historical data, we can estimate the transition probability $T(s'|a, s)$, which determines the likelihood of reaching state $s'$ when taking action $a$ in the state $s$. The transition between states also generates rewards for the seller, determined by the function $R(s, a, s')$."}, {"title": "3.2.1 State Space", "content": "The MDP state space $S$ consists of states $s = (c, t, p)$ (we also use the notation $s_t = (c, p)$). That is, the state is defined by the supply of all the resources $c$ at time step $t$ and the product $p$ being requested by some customer at time step $t$. By discretizing the selling period $(0, \\text{max}(T))$ into $k$ time steps, we make sure the state space is finite.\nWhile continuous-time MDP formulation [22] is possible, it complicates the description of the problem, making it less intuitive and the solution more complex. The arrival time of customer product requests is continuous; the service provider can't influence these arrival times. However, they arrive as discrete events. Additionally, in pricing problems we are interested in, we assume that customer product requests arriving at similar times will mostly exhibit similar types of behavior. That is to say that we expect demand to depend on time in a piecewise continuous fashion with a finite number of discontinuities, where the discretization can be made to match these discontinuities. Additionally, as discussed in Section 4, the discretization only needs to be fine enough to ensure that the probability of multiple requests arriving in a single timestep remains low.\nThe time step $t$ increases by one with every transition, so $s_t = (c, p)$ is always followed by some $s_{t+1} = (c', p)$."}, {"title": "3.2.2 Action Space", "content": "The MDP action space $A \\subset \\mathbb{R}$ is a set of possible prices that the seller can offer customers. This set can principally be continuous, but we assume the prices to form a finite set for our experiments.\nSimilarly, as with continuous time, our model could accommodate for continuous action spaces [23]. Doing so could improve the sellers' objectives, as the proposed prices could get closer to the internal customer's product valuation $b$. Most current service providers\u00b9 selling directly to customers, however, offer discrete service prices. Therefore, it seems to be a natural simplification in our case as well. Furthermore, where possible, we compare"}, {"title": "3.2.3 Reward Function", "content": "The MDP reward function $R(s_t, a, s_{t+1})$ determines the reward obtained by transitioning from $s_t$ to $s_{t+1}$ by taking action $a$. If the seller's goal is revenue maximization, the reward is the price offered for the product. The reward has the value of the action $a$ if the customer accepts the offered price $a$ and 0 otherwise. Formally:\n\\begin{equation}\nR(s_t, a, s_{t+1}) = \\begin{cases}\na, & \\text{if } b > a \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\end{equation}\nHere, $a$ on the right-hand side of the equation is the value of the action $a$. $b > a$ means that the customers budget $b$ is greater than the price $a$, meaning customer accepts the price. Note that a successful sale implies capacity is reduced between $s_t = (c, p)$ and $s_{t+1}$ from $c$ to $c - p$ in $s_{t+1}$, which brings us to the definition of the transition function."}, {"title": "3.2.4 Transition Function", "content": "The transition function $T(s_t, a, s_{t+1})$ is the most complex component of the MDP model. It determines the state $s_{t+1}$ the system develops into from state $s_t$ when the service provider takes action $a$. The transition function $T$ is determined by two factors: the customer arrival processes $\\mathcal{D}(t)$ and the distributions of customer internal valuations {$\\mathcal{B}_p | p \\in P$}. The structure of the transition function and how it combines these two components is shown in Figure 4.\nIn some state $s_t = (c, p)$ (the root of the tree in Figure 4), the seller picks a price $a$ for product $p$ requested by a customer with a hidden internal valuation of the product. Since the customer accepts the offered price only if his internal valuation (modeled by a random variable $X \\sim \\beta_p$ of the product $p$) is greater than the offered price $a$, the probability of a customer accepting the offered price is given by the complementary cumulative density function"}, {"title": "FBp of \u03b2p as", "content": "\\begin{equation}\nP_{acc}(p, a) = \\mathbb{P}(X > a) = 1 - F_{\\mathcal{B}_p}(a)\n\\end{equation}\nThis is shown in the second level of the tree in Figure 4. The budget distribution $\\mathcal{B}_p$ could also be time-dependent, but we assume it is not for simplicity.\nIndependently of whether the product $p$ is sold at time step $t$ in Figure 4, some product $p'$ could be requested at time step $t + 1$. The demand model $\\mathcal{D}(t)$ that determines the probability of a product request at time step $t$ is derived from the compound Poisson counting process $N(\\tau)$ with rate $\\Lambda$.\nThe choice of the Poisson process to model arrival is a natural consequence of the so-called memoryless property that assumes that, at any point, the time until the next customer request does not depend on how much time has passed since the last customer request. Fortunately, this assumption holds in many pricing problems, since the assumed customer populations are large and customers act independently. For this reason, as well as its simplicity and useful properties, the Poisson process is a popular choice for modeling customer arrivals.\nIn our case, $N(T)$ counts the arrival of a request for any product, and is created by merging independent, product-specific Poisson counting processes $N_p(\\tau)$ with rates $\\Lambda_p$ into a single combined process.\nFor the sake of explanation and without the loss of generality, we assume these processes are homogenous, i.e., the intensity $\\Lambda$ does not depend on time. Thus, the intensity of each product subprocess is $\\Lambda_p$ and is constant, and from the properties of the Poisson process, we have $\\sum_{p \\in P} \\Lambda_p = \\Lambda$.\nHowever, in our MDP definition, we discretize the selling period $(0, T)$ into $k$ intervals, the timesteps\u00b2. Assuming for now that each timestep in the discretization has constant length $\\epsilon$, we approximate the Poisson process with a discrete demand process $D(t)$, $t \\in \\{1, 2, 3, ..., k\\}$. $\\mathcal{D}(t)$ gives the probability of product arrivals in each timestep. However, it allows for at most one product to be requested at any timestep. $\\mathcal{D}(t)$ is a multi-class extension of the Bernoulli process with $|P| + 1$ possible outcomes, with $+1$ for no (empty) product request arriving in a timestep. The probabilities of"}, {"title": "4 Properties of the Demand Approximation in the MDP Model", "content": "Here, we formalize the definition of the discrete demand process used in our MDP model and quantify how well it approximates the assumed Poisson demand process."}, {"title": "4.1 Convergence of the Discrete Demand Process", "content": "In this section, we will assume that the selling period (0, T) is a unit interval (0, 1), which is without a loss of generality through simple rescaling of the timeline. Next, let us describe the Poisson demand process obtained by combining the Poisson sub-processes for each product. We assume there is a Poisson counting process $N\u266d(\u03c4)$ for each product $p \u2208 P$, defined by the rate $\\Lambda_p$, generating arrival times of requests for that specific product. From the convenient properties of Poisson processes, the arrival times of all product requests can be considered as coming from a single compound Poisson process $N(\u03c4)$ with intensity $\u03bb = \\sum_{p\u2208P}\u03bb_p$. The compound Poisson process generates arrivals of requests for any product."}, {"title": "the different products at timestep t in D(t) are chosen in the following way:", "content": "\\begin{equation}\n\\mathbb{P}_{req}(p, t) = \\begin{cases}\n\\frac{\\Lambda_p}{\\Lambda k}  & p \\in P \\\\\n1 - \\sum_{p' \\in P} \\mathbb{P}_{req}(p')  & p = \\emptyset\n\\end{cases}\n\\end{equation}\nSee Section 4 for details on how the discrete demand process with product request probabilities chosen this way behaves concerning the compound Poisson process $N(T)$ and what is the quality of this approximation.\nWe consider the approximation of $N(T)$ by $\\mathcal{D}(t)$ to be acceptable for a given number of timesteps $k$ and the expected number of requests $XT$ under one condition. $\\mathcal{D}(t)$ can generate at most 1 request in any interval of the discretization. In contrast, $N(T)$ can generate any positive number of requests in any interval. Thus, for $\\mathcal{D}(t)$ to approximate $N(\u03c4)$ well, we want the expected number of requests assigned to different intervals between $\\mathcal{D}(t)$ and $N(7)$ to be low. Specifically, we want to pick $k$ so that the error term $\\frac{Err2(k,\\Lambda)}{\\Lambda}$ is small. In the next section, we explain what we mean by $Err2$ and justify this approximation."}, {"title": "5 Dynamic Pricing Algorithm Using MCTS", "content": "This section describes the method we use to derive the dynamic pricing policies. Our solution method of choice for large-scale problems is MCTS. Unlike tabular methods, such as Value Iteration (VI) or policy iteration, MCTS does not need to enumerate the whole state space. Instead, it looks for the best action from the current state and expands only to states that the"}, {"title": "5.1 Tree Policy and Backpropagation", "content": "The input of Algorithm 1 is the current state for which we seek to estimate the best action $a$. The algorithm has three parameters, the exploration constant"}, {"title": "5.2 Rollout Policy", "content": "Algorithm 2 presents the second part of the MCTS algorithm, the rollout. It is applied from state-action pairs that were used for the first time in the tree policy. The rollout approximates the reward of the selected action by quickly reaching the terminal state. In our experiments, we use the uniformly random rollout policy that applies random actions until a terminal state in the MDP is reached.\nBecause we use the Poisson process (Bernoulli processes after discretiza- tion) as the customer arrival process, we can speed up the rollout by sampling the time to the next arrival from the inter-arrival distribution. It has a geo- metric distribution in the discretization (Line 8 in Algorithm 2). Therefore, we can arrive at the terminal state in fewer steps. In the rollout, we simu- late actions without storing their resulting states until reaching a terminal state. When the terminal state is reached, the rollout terminates immediately, returning the accumulated reward."}, {"title": "5.2.1 Implementation", "content": "Our implementation is based on the MCTS implementation in the POMDPs.jl[26] library that uses recursion when traversing the tree, unlike the description in Algorithm 1. We provide the unrolled iterative description for clarity.\nThe implementation we use reuses the constructed decision tree between the steps of the \u201creal\u201dMDP that happen outside of the MCTS algorithm, improving the convergence speed. In our experiments, we build the tree to the maximum depth $d_{max} = 3$ with the exploration constant set to $c = 1$. The number of iterations is capped at $n_{iter} = 800$. We find that these low"}, {"title": "6 Experiments and Results", "content": "We compare our MCTS pricing solution against multiple baselines on arti- ficially generated problem instances modeled on a real-life charging station dataset provided by a local German charging station operator.\nThe main goal of the experiments is to demonstrate the viability of the MCTS dynamic pricing algorithm for EV charging. To show this, we run a number of simulations with problem instances created using different problem parameters and compare the average performance of the MCTS algorithm with the baseline methods."}, {"title": "6.1 Problem Instances", "content": "While the generated instances are simple, the approach is flexible, and it can accommodate much more complicated inputs. We use basic distributions with parameters fitted to our EV charging dataset. The user budgets are sampled from the user budget distribution for the given charging session length. As we did not have any data on user budgets, the choice of pa- rameters is arbitrary. We set the charging session start times to follow the normal distribution and the charging session length to follow the exponential distribution. We set both distributions to be independent. While this is not true in practice, it is sufficient to showcase our method and make the definition of the instances simpler.\nThe request arrival times are obtained from a discretized homogeneous Poisson process, as described in Section 4. Time-variable Poisson demand process intensity that appears in the real world would be handled by a simple transformation of the timeline, resulting in discrete variable-length timesteps, which lead to a constant probability of request arrival in the discretized arrival process. Therefore, using a homogenous Poisson demand process is without the loss of generality. Where available, we set their parameters based on the data analysis of our dataset; these values are collected in Table 1.\nEach problem instance has a form of a charging request sequence, as shown by Equation (1). Each pricing method, including the baseline methods described below, then prices the requests in the order they come in. The accumulated reward is averaged across 100 simulated runs to measure the performance of each method for comparison with other methods."}, {"title": "6.2 Baseline Methods", "content": "Because of the difficulties of evaluating the dynamic pricing policies, we evaluate our proposed MCTS solution against three baseline methods: flat rate, MDP-optimal VI, and Oracle pricing methods. The flat rate represents the lower bound on the revenue we might expect from a dynamic pricing solution. The VI baseline returns an optimal pricing policy and represents the best possible pricing method for the MDP model. Finally, the Oracle policy represents the unachievable upper bound on dynamic pricing performance. Oracle provides the best possible allocation by assuming the CS operator has a perfect knowledge of future requests and EV users' budgets, which is unrealistic in real-world use cases."}, {"title": "6.2.1 Flatrate", "content": "This baseline provides a lower bound for our MCTS pricing method and a reference for showing how much improvement dynamic pricing could bring."}, {"title": "6.2.2 Value Iteration (VI)", "content": "Our second baseline pricing method is the optimal MDP policy generated by a VI algorithm [29]. VI is a simple yet accurate method for solving MDPs that converges to an optimal policy for any initialization. The advantage of VI is that it quickly converges to a complete near-optimal pricing policy at the cost of enumerating the whole state space in memory.\nBased on the structure of our MDP state, the state-space size of our MDP model is $kn2^n$, where $k$ is the number of timesteps, $n$ is the number of charging timeslots and $c_0$ is the initial charging capacity. If we limit the reservations to contain only the contiguous timeslots, as we do, the state-space size reduces to $kn(n + 1)/2$. This gives VI an exponential space complexity in the number of timeslots. Thus, it does not scale well to larger problem instances. Therefore, we use VI only to obtain optimal policies on smaller problem instances to validate the heuristic approach of MCTS.\nNote that there are other exact solution methods for MDP problems than VI, such as policy iteration or linear programming. All these methods can provide the same optimal pricing policy as VI. However, just like VI, all these methods require enumeration of the whole state space. Our choice of VI is, therefore, arbitrary in this sense.\nSince VI gives optimal pricing policy, we use it to benchmark the per- formance of our MCTS approach, which, since it is heuristic, is expected to provide worse results. How much worse is the question we want to answer by comparing the performance of the two methods on small-enough instances that VI can solve."}, {"title": "6.2.3 Oracle", "content": "Finally, we compare our MCTS-based pricing method against the Oracle baseline strategy. It's important to note that the Oracle strategy, while used for benchmarking, isn't practically applicable due to its nature. Unlike other pricing strategies, Oracle relies on having prior knowledge of the entire request sequence and the budgets of EV users to determine prices.\nUsing this knowledge, Oracle maximizes the optimization metric to provide a theoretical upper bound on the revenue and resource usage achievable by any pricing-based allocation strategy. It works for large and small problem instances; therefore, we can use it to track the performance of MCTS across a wide range of problem sizes.\nThe Oracle pricing solution is obtained from a linear program. For kth sequence of charging requests dk with requests indexed by i, the optimum revenue is the result of a simple binary integer program:\n\\begin{equation}\n\\text{maximize } \\sum_{i \\in \\{1...|d_k|\\}} x_i [b_i]_A,  \\text{ subject to:}\n\\end{equation}\n\\begin{equation}\n\\sum_{i \\in \\{1...|d_k|\\}} x_i p^i < c_0 ^j  j= 1, ..., |R|\n\\end{equation}\n\\begin{equation}\nx_i \\in \\{0, 1\\}  i = 1, ..., |d_k|.\n\\end{equation}\nwhere, $x_i$ are the binary decision variables that determine which requests from $d_k$ are accepted by the CS operator. In the objective function (Equation (11)), the term $[b_i]_A = \\text{max}_{a \\in A, a & < b_i} a$ denotes the fact that the budget values in the sequence $d_k$ are mapped to the closest lower values in the action space $A$. Conditions (Equation (12)) mean that the accepted charging sessions have to use fewer resources than the initial supply $c_0$."}, {"title": "6.3 Results", "content": "We evaluate the proposed MCTS pricing method in the experiments against the baselines described in Section 6. First, we analyze the performance of the MCTS algorithm in a set of small instances to select the best hyperparameters. Then, we compare the performance of the MCTS algorithm with the Flatrate, VI, and Oracle baselines in a set of different instances, ranging from instances with a small state space where VI can still generate results to instances with a larger state space."}, {"title": "6.3.1 MCTS Hyperparameter Grid Search", "content": "The MCTS algorithm (Algorithm 1) has three parameters, the number of iterations $n_{iter}$, the exploration constant $c$, and the tree depth limit $d_{max}$. To determine its hyperparameters, we use a modestly sized instance with 12 timeslots and 96 timesteps, three charging stations, and expected 24 charging requests.\nWe perform a full grid search with discretized sequences of these parame- ters. The results of the grid search are shown in Figure 6. The results are averaged from 100 sampled request sequences. The main takeaway from the grid search is that the number of iterations has the most significant impact on the performance of the algorithm. The exploration constant and the tree depth limit have a much smaller impact. However, the number of iterations and the tree depth have the highest impact"}]}