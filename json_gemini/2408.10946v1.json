{"title": "Large Language Model Driven Recommendation", "authors": ["Yashar Deldjoo", "Zhankui He", "Julian McAuley", "Anton Korikov", "Scott Sanner", "Arnau Ramisa", "Rene Vidal", "Mahesh Sathiamoorthy", "Atoosa Kasrizadeh", "Silvia Milano", "Francesco Ricci"], "abstract": "While previous chapters focused on recommendation systems (RSs) based on standardized, non-verbal user feedback such as purchases, views, and clicks \u2013 the advent of LLMs has unlocked the use of natural language (NL) interactions for recommendation. This chapter discusses how LLMs' abilities for general NL reasoning present novel opportunities to build highly personalized RSs \u2013 which can effectively connect nuanced and diverse user preferences to items, potentially via interactive dialogues. To begin this discussion, we first present a taxonomy of the key data sources for language-driven recommendation, covering item descriptions, user-system interactions, and user profiles. We then proceed to fundamental techniques for LLM recommendation, reviewing the use of encoder-only and autoregressive LLM recommendation in both tuned and untuned settings. Afterwards, we move to multi-module recommendation architectures in which LLMs interact with components such", "sections": [{"title": "4.1 Introduction", "content": "The advent of LLMs has enabled conversational, natural language (NL) interactions with users while also unlocking the rich NL data sources within recommendation systems (RSs) such as item descriptions, reviews, and queries. These advances create the opportunity for highly personalized RSs which harness the general reasoning abilities of LLMs to accommodate diverse and nuanced user preferences through customized recommendations and interactions. Such NL-based personalization contrasts starkly to the ID-based RSs described in Chapters 2 and 3 which are highly specialized for standard recommendation tasks (e.g., rating prediction, sequential recommendation) and require large volumes of non-textual interaction data - though many synergies between these two paradigms are possible, as discussed below."}, {"title": "4.1.1 Natural Language vs. Non-Textual Interaction Data", "content": "Both textual and non-textual data are important in this chapter - Figure 4.1 illustrates how such data can represent key RS information, covering items, users, and system interactions. This figure is discussed in detail in Section 4.2.\nNon-textual Interaction Data:\nOn one hand, non-textual user-item interactions such as purchases, views, clicks, or ratings facilitate the collection of large volumes of data in fixed formats (e.g., rating matrices, item ID sequences) and enable the large-scale training of conventional RSs \u2013 namely, collaborative filtering (CF) and content-based filtering (CBF) systems (c.f. Ch 2). On the"}, {"title": "4.1.2 General vs. Specialized Recommendation Reasoning", "content": "Task-specific Reasoning with Conventional RSs\nConventional RSs must be trained on large amounts of task-specific interaction data - making them highly-specialized tools that are typically optimized for either rating prediction or top-k, sequential, or page-wise recommendation. While their performance on offline benchmarks for these tasks is generally very strong (c.f. Ch. 6), these specialized systems are limited by the inability of standardized interaction data (e.g., purchases, views, clicks, etc.) to capture nuanced and diverse user preferences. These systems also often require considerable data engineering efforts and design time to deploy.\nHowever, despite these limitations, conventional RS remain powerful and scalable methods for predicting future interactions, able to work with millions of users and items. Therefore, as will be discussed in Sections 4.5-4.7, many researchers are actively studying the integration of conventional RSs as specialized sub-components within larger, LLM-powered system architectures (e.g., Friedman et al., 2023; Hou et al., 2023; Zhang et al., 2023b).\nGeneral Recommendation Reasoning with LLMs\nIn contrast to conventional RSs, the pretraining of LLMs on large text corpora provides them with emergent abilities for general reasoning with LLMs achieving impressive performance on many diverse and previously unseen tasks (Bubeck et al., 2023). Through pretraining, LLMs have internalized fine-grained knowledge about a wide range of entities, human preferences, and interaction patterns \u2013 knowledge which could enhance RS personalization while reducing data and design time requirements."}, {"title": "4.2 Data Sources in LLM-Driven RSs", "content": "The use of language in recommendation is not new. For instance, text has long been leveraged for content-based recommendation (Lops et al., 2011), key-phrase explanations (McAuley and Leskovec, 2013; Wu et al., 2019c), and metadata-driven Dialogue State Tracking (DST, Yan et al., 2017). However, LLM's have enabled far more advanced NL reasoning about items, users, and their interactions (Geng et al., 2022), creating opportunities for more nuanced and interactive RS personalization. This section thus outlines the primary data sources which could be used by LLM-era RS, covering item data, interaction data, and user profiles, summarized in Figure 4.1."}, {"title": "4.2.1 Item Text", "content": "The right side of Figure 4.1 illustrates data sources for textual item representations, including titles, descriptions, metadata, and reviews.\nTitles\nIn most settings, items are assigned a title: a short, descriptive text span which aims to distinguish the item. A title's capacity to represent an item can vary greatly with domain and item popularity: for example while some hit movies and books can be summarized in one or two words (e.g., \"Titanic (1999)\u201d, \u201cDune (1965)\"), less unique and less popular items (e.g., articles of clothing) do not have such information-dense titles. Items may even entirely lack titles in certain domains, such as user-generated social media video recommendation, though in these\""}, {"title": "Descriptions", "content": "Items may also be associated with longer and more detailed NL content which we call descriptions, which may be human-written or LLM generated (e.g. Acharya et al., 2023; Wei et al., 2024; Li et al., 2023b). The length and format of descriptions can vary greatly across domains, ranging from non-existent (e.g., social media videos), to short summaries (e.g., eShopping products), to many pages long (e.g., news articles and books).\nMetadata\nItem metadata often contains structured information about item at-tributes such as product categories, brands, technical specifications, price, release date, and so on. It can contain various types of informa-tion including numerical, categorical, temporal, geographical, and visual data.\nReviews\nA plentiful source of user-generated text are often reviews which express nuanced opinions across a diverse range of item attributes and user experiences. However, reviews are often highly subjective, especially when describing \"soft\" attributes such as \u201cinexpensive\", \"funny\", or \"safe\" (Radlinski et al., 2022b; Balog et al., 2021)."}, {"title": "4.2.2 Interaction Data", "content": "The top and bottom of Figure 4.1 illustrate sources of user-system interaction data, including both non-textual interactions (e.g., clicks, purchases, etc.) and NL interactions such as queries, dialogue utterances, and reviews (discussed in the previous section)."}, {"title": "Verbalizing Non-Textual Interactions", "content": "Conventional non-textual user-item interaction history \u2013 such as views, clicks, likes, purchases, and ratings\ncan easily be represented as text. For this, a simple template may be sufficient \u2013 for instance, Hou et al. (2023) represent a user's movie viewing history with a template such as: \u201cI've watched the following movies in the past in order: 1. Multiplicity, 2. Jurassic Park, \". Alternatively, LLMs can be prompted to summarize such interaction histories (Yin et al., 2023; Zhou et al., 2024; Wei et al., 2024). In either case, such verbalized histories offer an alternative to the sometimes arbitrary mapping of distinct interactions types to numerical or categorical formats, and can also cover pointwise, sequential, and bundle interactions.\nNL Interactions\nOther user-system interactions are inherently text-based \u2013 for instance, reviews were already discussed in Section 4.2.1.\nQueries While RSs have traditionally focused on query-less personal-ization, queries \u2013 short text spans expressing a user's real-time infor-mation need are becoming a key part of language-driven RSs (Reddy et al., 2022; He et al., 2022). In fact, this integration of NL queries into RSs is contributing to the convergence of the recommendation and information retrieval (IR) fields.\nUser-System Dialogue As conversational recommendation systems (CRS) develop, user-system dialogues are emerging as a primary source of textual interaction data (Li et al., 2018a). Each user and system utterance can reflect diverse intents, including conveying preferences, recommendations, and explanations, as well as asking and answering questions about items or preferences (Lyu et al., 2021), as discussed further in Section 4.7."}, {"title": "4.2.3 NL User Profiles", "content": "The left side of Figure 4.1 illustrates various textual representations of user preferences, including metadata and NL user profiles. Recently, Radlinski et al. (2022) proposed that language-driven recommendation could be centered on scrutable NL user profiles: textual descriptions of user preferences that are editable and understandable by humans. Such user profiles could succinctly summarize user interests through both specific examples of preferred items and generic preference descriptions. While research on effectively generating, editing, and leveraging these interpretable NL preference representations is still nascent, several initial studies have emerged. For instance, Sanner et al. (2023) have users directly express generic NL item preferences in personal NL profiles, while other authors (Yin et al., 2023; Zhou et al., 2024) use and LLM to generate NL profiles based on item rating histories \u2013 both works find that recommendation performance is competitive with or better than conventional baselines in cold-start settings.\nUser Agency via Editable NL Profiles In principle, an editable NL profile has the potential to empower users to correct system errors, safeguard their privacy, and exert natural control over their preference representations (Radlinski et al., 2022a). It may also be well-suited to handle preference shifts (Hosseinzadeh Aghdam et al., 2015; Pereira et al., 2018) by allowing users to delete obsolete interests or describe temporary contexts. In addition, users can express aspirations - desires that do not necessarily align with past behavior, but should influence future recommendations (Ekstrand and Willemsen, 2016). Finally, user edits that result in improved recommendations can incentivize further feedback and increase user satisfaction (Bostandjiev et al., 2012; Harper et al., 2015; Knijnenburg et al., 2012)."}, {"title": "4.3 Encoder-only LLM Recommendation", "content": "We now begin our discussion of how textual data can be used in LLM-driven RSs - starting with recommendation with encoder-only LLMs. As shown in Figure 4.3, encoder-only LLMs can be used in two main"}, {"title": "4.3.1 Dense Retrievers", "content": "First introduced in the field of information retrieval (IR), dense retrievers produce a ranked list of documents given a query by evaluating the similarity (e.g., dot product or cosine similarity) between a document embedding and query embedding (Fan et al., 2022). Dense retrieval is highly scalable (especially with approximate search libraries like FAISS\u00b9) since document embeddings can be pre-computed and only the query embedding needs to calculated at query time.\nTo use dense retrieval for recommendation, first, a component of each item's text content, such as its title, description, reviews, etc., is treated as a document. Then, a query is formed by some NL user preference description \u2013 for instance: an actual search query, the user's"}, {"title": "4.3.2 Cross-Encoders", "content": "In contrast to dense retrievers, cross-encoders embed a query and document jointly, allowing cross-attention between query and document tokens (Fan et al., 2022). Several works approach rating prediction by jointly embedding NL item and preference descriptions in LLM cross-encoder architectures with a rating prediction head (Zhang et al., 2021; Yao et al., 2022; Wu et al., 2021; Qiu et al., 2021; Zhang and Wang, 2023). Such fusion-in-encoder methods often exhibit strong performance because they allow interaction between user and item representations, but are much more computationally expensive than dense retrieval and thus may be best used for small item sets or as rerankers."}, {"title": "4.4 Generative Recommendation and Explanation", "content": "We next move beyond item-preference scoring to generative recommendation (c.f. Sec 4.4.1-4.4.2) and explanation (c.f. Sec 4.4.3) with autoregressive LLMs. Autoregressive LLM inputs are called prompts, which are sequences of tokens expressing a task such as top-k recommendation, rating prediction, or explanation generation (Geng et al.,"}, {"title": "4.4.1 Zero- and Few-Shot Recommendation", "content": "The simplest way an autoregressive LLMs can be used is in the untuned (i.e., \"off-the-shelf\") setting (e.g. Sileo et al., 2022; Sanner et al., 2023). As illustrated in Figure 4.4, this includes:\n\u2022 zero-shot (ZS) approaches, which rely solely on the LLM's pre-trained knowledge without any additional training data (Figure 4.4 a)\n\u2022 few-shot (FS) approaches, which provide a small number of input-output examples in the prompt (Figure 4.4 b), and thus are also referred to as in-context-learning (ICL) methods.\nZero- and Few-Shot Prompt Engineering Clearly, there is a large design space for prompting approaches, including choices for representing user preferences, specifying task instructions, and selecting few-shot examples. Figure 4.4 illustrates two specific examples from this design space (Sanner et al., 2023): a) a ZS prompt with a user-generated NL preference description, and b) a FS prompt based on sequences of liked movie titles from multiple users. Many other variants are possible, for instance: constructing FS examples based on interactions from the same user instead of from different users, including user dispreferences, or using LLM-generated user profiles (Zhou et al., 2024).\nInitial Experimental Findings Several recent publications have evaluated off-the-shelf LLMs for movie and book recommendation \u2013 domains where relevant knowledge is likely to be internalized during pretraining. Specifically, these methods construct prompts using NL representations of user preferences and instructions to recommend item titles (Sanner et al., 2023; Sileo et al., 2022; Liu et al., 2023) or predict ratings (Kang et al., 2023; Liu et al., 2023; Zhou et al., 2024). These initial studies find that while untuned LLMs generally underperform supervised CF methods given sufficient training data (Kang et al., 2023; Sileo et al., 2022), they are competitive in near cold-start settings (Sileo et al., 2022; Sanner et al., 2023; Zhou et al., 2024). They also suggest that FS typi-"}, {"title": "4.4.2 LLM Tuning for Generative Recommendation", "content": "To improve an LLM's generative recommendation performance, multiple works study LLM tuning on historical RS data. First, historical data is converted into textual input-output training pairs for generative recommendation tasks (Geng et al., 2022), which may include:\n\u2022 top-k recommendation (e.g., Geng et al., 2022; Li et al., 2023c), such as in Figure 4.4 a-b\n\u2022 sequential recommendation (e.g., Harte et al., 2023; Li et al., 2023c; Mao et al., 2023), such as in Figure 4.4 c\n\u2022 rating prediction (e.g.,Bao et al., 2023; Kang et al., 2023; Zhang et al., 2023b)\nNotably, Geng et al. et al. (2022) point out that text is a unifying format for training data, enabling multi-task LLM tuning on all of the above tasks. They also show that LLMs can learn to use user and item ID tokens for these tasks (e.g., Figure 4.4 \u0441).\nGiven textual RS training data, the two main approaches to LLM tuning are:\n\u2022 fine-tuning, where training set performance is optimized by adjusting LLM weights (Geng et al., 2022; Bao et al., 2023; Harte et al., 2023; Mao et al., 2023; Kang et al., 2023)\n\u2022 prompt-tuning where training set performance is optimized by learning prompt tokens (hard prompt-tuning) or embeddings (soft prompt-tuning) (Li et al., 2023b; Cui et al., 2022; Zhang et al., 2023b)"}, {"title": "4.4.3 Generative Explanation", "content": "Autoregressive LLMs can also generate explanations that aim to help users comprehend why recommendations were made. Similarly to recommendation generation, explanations can be generated by prompting"}, {"title": "4.5 Retrieval Augmented Recommendation", "content": "While the previous two sections explore the use of LLM knowledge internalized through pretraining or tuning to generate recommendations and explanations, relying solely on internal LLM knowledge has several limitations (Lewis et al., 2020):\n\u2022 a relatively large number of LLM weights are needed to store knowledge\n\u2022 retraining is needed for each knowledge update\n\u2022 there is no inherent source attribution mechanism\nTo address these limitations, recent work (e.g., Lewis et al., 2020; Izacard and Grave, 2020; Borgeaud et al., 2022; Mialon et al., 2023) explores a framework called retrieval-augmented generation (RAG) in which: 1) relevant content is retrieved from an external knowledge source and 2) the retrieved content is used to prompt an autoregressive LLM to generate textual output. These studies provide evidence that, in"}, {"title": "4.5.1 RAG in RSS", "content": "There are many opportunities to use RAG in RSs, including to generate recommendations, explanations, and question answers. More broadly, the RAG framework introduces us to modular architectures for LLM-driven RSS a concept we'll explore further when discussing LLM representation generation (c.f. Sec. ??) and conversational RS architectures (c.f. Sec. 4.7)."}, {"title": "RAG for Recommendation", "content": "As illustrated in Figure 4.5, the most commonly studied RAG recommendation method has been LLM candidate item set reranking. Specifically, this method involves: 1) selecting a candidate item set based on RS interaction data and 2) prompting an LLM to rerank the candidate set given some information about user preferences (Yang et al., 2022; Hou et al., 2023; Chen, 2023; Wang and Lim, 2023; Dai et al., 2023; Wei et al., 2024). Recall from Section 4.2 that user preferences can be represented in diverse forms, leading to many alternatives for candidate selection and reranking methods. For instance, Figure 4.5 a) illustrates candidate selection with a retriever driven by a user query, and LLM candidate reranking given this query. As another example, Figure 4.5 b) shows candidate selection with an RS based on item interaction history, and LLM reranking given this history.\nRAG for Explanation and Conversational Recommendation Other examples of how RAG can be used in RSs include explanation generation and as a tool for conversational recommendation. For RAG-based explanation generation, Xie et al. (2023) generate queries based on interaction history to retrieve an item's reviews, which are then used as context to generate an explanation of the recommendation. Examples of RAG in conversational recommendation, discussed further in Section 4.7, include work by Friedman et al. (2023) to retrieve relevant user preference descriptions from a user \u201cmemory\u201d module, and by Kemper et al. (2024) to retrieve information from an items reviews to answer user questions."}, {"title": "4.6 LLMs Representation Generation", "content": "While Section 4.5 explored using an external module such as retrievers or RSs to select LLM inputs, this section discusses the converse setting in which LLMs generate inputs to downstream modules, as illustrated in 4.6. Specifically, LLMs can be used to transform text such as item and preference descriptions into representations (e.g., embeddings, text, item ratings) that serve as inputs to modules such as RSs, retrievers, or autoregressive LLMs. Such text transformations can be interpreted"}, {"title": "4.6.1 Text to Text", "content": "Two common settings where an LLM generates text that serves as input to a downstream module are search queries and LLM prompt elements, with several example studies for both approaches discussed below.\nSearch Queries Given a user's item interaction history (and item text), MINT (Mysore et al., 2023) and GPT4Rec (Li et al., 2023a) prompt an LLM to generate an search query for a dense retriever with the goal of finding new items to recommend. Similarly, recent work on conversational recommendation uses dialogue history to generate search queries to find items to recommend (Friedman et al., 2023; Kemper et al., 2024)."}, {"title": "4.6.2 Text to Embeddings", "content": "As discussed in Chapters 2 and 3, many RS techniques rely on latent representations of items and user preferences. Thus, a recent line of research uses LLMs to encode semantic information from text into latent embeddings which are then used for recommendation. While encoder-only LLM recommendation was already discussed in Section 4.3, this section covers multi-stage pipelines where LLM embeddings are used for downstream recommendation modules, discussed next.\nSequential Recommendation with LLM Embeddings Recall that Chapter 3 discussed several attention-based sequential recommendation models (e.g., BERT4Rec REF, SASRec REF) which predict the next item ID to recommend given a sequence of item IDs that a user has interacted with. Recent work uses LLMs to initialize item ID embeddings based on item text (Harte et al., 2023; Yuan et al., 2023; Rajput et al., 2024), reporting significant performance gains. Similarly, Query-SeqRec (He et al., 2022) incorporates user query information into sequential recommendation by using an LLM to encode queries alongside item embeddings.\nRating Prediction with LLM Embeddings LLMs have also been used to generate latent representations of items (based on item text) and users (based on item interactions) that serve as inputs to a neural network which predicts a user-item rating (Wu et al., 2021; Yuan et al., 2023). These approaches essentially augment the well-known"}, {"title": "4.6.3 Text to Item Ratings", "content": "As discussed further in Section 4.7, LLMs have been used to map dialogue history to item rating predictions, with these ratings then treated as observations by an RS to make recommendations. Examples include sentiment analysis towards items mentioned in a dialogue (Li et al., 2018b) and natural language inference between user-stated aspect preferences and item text (Austin et al., 2024)."}, {"title": "4.7 Conversational Recommendation", "content": "The previous sections mostly focused on single-turn LLM recommenda-tion personalized based on pre-existing user history information, such as non-verbal interactions, queries, reviews, and so on (c.f. Figure 4.1), and item text. However, LLMs provide new opportunities for multi-turn conversational recommender systems (CRSs) where each turn presents a chance for the user to clarify or revise their preferences, critique and ask questions about recommended items, or convey a variety of other real-time intents such as those shown in Table 4.1 (Lyu et al., 2021). Correspondingly, CRSs should facilitate a wide range of responses including revising recommendations, responding to questions, and per-sonalizing explanations. Further, each turn is also an opportunity for the CRS to generate proactive utterances such as clarifying questions or explanations focused on key topics to help elicit user preferences. As with user intents, various possible CRS actions are summarized in Table 4.2 (Lyu et al., 2021). LLM-driven CRSs thus present opportunities not only to personalize recommendations, but also to personalize system interactions more broadly.\nPre-LLM CRS Architectures Historically, most pre-LLM CRSs fol-lowed a two-step process in each turn: 1) belief tracking to maintain a dialogue state, and 2) response generation to produce a system ut-terance (Jannach et al., 2020). Belief tracking was often implemented"}, {"title": "LLM-Driven CRSs", "content": "In contrast to highly constrained slot-based dialogue states described above, LLMs enable rich textual representations of the dialogue state. For instance, if we consider the basic case of using a monolithic LLM as a CRS (e.g., He et al., 2023), the dialogue state simply becomes the conversation history, which preserves the full dialogue context. As discussed further in Section 4.7.1, recent CRS research often explores more complex text-augmented dialogue states - expanding or replacing the raw conversation history with elements such as JSON-like dialogue states (e.g., Figure 4.7), user preference summaries (Friedman et al., 2023; Joko et al., 2024), or numerical variables (e.g., inferred item ratings). These text-augmented dialogue states are then used to form inputs to response generation modules, which may include not only LLMs but also tools such as retrievers, RSs, and KGs, as discussed in Section 4.7.2."}, {"title": "4.7.1 Belief Tracking", "content": "LLMs enable a CRS to track its beliefs about the conversation through text-augmented dialogue states. This section covers the use of purely textual components in dialogue states as well as the incorporation of non-textual elements alongside text. Both textual and non-textual dialogue state elements can form inputs to response generation modules, discussed further in Section 4.7.2."}, {"title": "Textual Dialogue State Components", "content": "The most basic form of a textual dialogue state is simply the conversation history - the default state representation when a monolithic LLM is used as a CRS (e.g., He et al., 2023). However, the pure conversation history can also be extended or substituted with other textual state components. For instance, Kemper et al. (2024) prompt an LLM to convert the conversation history into a JSON dialogue state, as shown in Figure 4.7, which provides a semi-structured format to represent beliefs about the user's item preferences (e.g., preferred cuisine type) and the dialogue flow (e.g., whether the user is expecting an answer to a question). Other authors (Friedman et al., 2023; Joko et al., 2024) prompt an LLM to generate textual user preference memories, and store these memories as documents in a long-term memory corpus."}, {"title": "Semi-textual Dialogue States", "content": "In addition to textual components such as those described above, other works also feature categorical or numerical variables in the dialogue state. Specifically, the conversation history can be used to assign values to variables such as:\n\u2022 liked/disliked item titles (Liu et al., 2020) or item categories (Huang et al., 2023)\n\u2022 mentioned item-related KG entities (Chen et al., 2019; Zhou et al., 2020; Liu et al., 2020; Ma et al., 2020; Wang et al., 2022)\n\u2022 user constraints in a constraint reasoning-based CRSs (Zeng et al., 2024)\nDialogue states can also include numerical variables \u2013 for instance Li et al. (2018) use a sentiment classification module to infer a user rating towards mentioned items, while Austin et al. (2024) maintain Bayesian beliefs over user-item preferences."}, {"title": "4.7.2 System Response Generation", "content": "The primary purpose of the dialogue state elements discussed above is to guide the system response by forming inputs to response generation"}, {"title": "Prompting", "content": "There are many diverse ways that prompting can be used to guide CRS utterance generation. Several works study single-intent systems, where the prompt is constructed using the dialogue history and an instruction to generate an utterance with a fixed intent, such as to recommend (He et al., 2023) or ask a preference elicitation query (Handa et al., 2024; Austin et al., 2024). Other methods (Joko et al., 2024; Kemper et al., 2024) express hand-crafted dialogue rules through prompts, asking an LLM to select the best system action given the dialogue state and some rules (e.g., \"Ask a user for their location if they have not provided it, otherwise, recommend a restaurant.\"). In addition, prompts can be partially or fully system generated, for instance using the output of another LLM module, a retriever, or a reasoning tool such as an RS or KG (e.g., Zhou et al., 2020; Wang et al., 2022; Friedman et al., 2023; Gao et al., 2023)."}, {"title": "Tuning", "content": "CRS dialogue policies can also be controlled by tuning LLMs on human-human or synthesized conversation data (Li et al., 2018a; Kang et al., 2019; Zhou et al., 2020; Liu et al., 2020; Ma et al., 2020; Li et al., 2022b; Wang et al., 2022; Friedman et al., 2023; Joko et al., 2024). While these methods cover many tuning approaches, they all lead to an LLM internalizing some knowledge about how to respond to the user in NL or execute some reasoning step such as a search or recommendation."}, {"title": "Tool Use", "content": "LLM-driven CRS response generation can also be augmented by the use of external tools such as retrievers or RSs. The techniques for interfacing"}]}