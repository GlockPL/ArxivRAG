{"title": "Large Language Model Driven Recommendation", "authors": ["Yashar Deldjoo", "Zhankui He", "Julian McAuley", "Anton Korikov", "Scott Sanner", "Arnau Ramisa", "Rene Vidal", "Mahesh Sathiamoorthy", "Atoosa Kasrizadeh", "Silvia Milano", "Francesco Ricci"], "abstract": "While previous chapters focused on recommendation systems (RSs) based on standardized, non-verbal user feedback such as purchases, views, and clicks \u2013 the advent of LLMs has unlocked the use of natural language (NL) interactions for recommendation. This chapter discusses how LLMs' abilities for general NL reasoning present novel opportunities to build highly personalized RSs \u2013 which can effectively connect nuanced and diverse user preferences to items, potentially via interactive dialogues. To begin this discussion, we first present a taxonomy of the key data sources for language-driven recommendation, covering item descriptions, user-system interactions, and user profiles. We then proceed to fundamental techniques for LLM recommendation, reviewing the use of encoder-only and autoregressive LLM recommendation in both tuned and untuned settings. Afterwards, we move to multi-module recommendation architectures in which LLMs interact with components such", "sections": [{"title": "Introduction", "content": "The advent of LLMs has enabled conversational, natural language (NL) interactions with users while also unlocking the rich NL data sources within recommendation systems (RSs) such as item descriptions, reviews, and queries. These advances create the opportunity for highly personalized RSs which harness the general reasoning abilities of LLMs to accommodate diverse and nuanced user preferences through customized recommendations and interactions. Such NL-based personalization contrasts starkly to the ID-based RSs described in Chapters 2 and 3 which are highly specialized for standard recommendation tasks (e.g., rating prediction, sequential recommendation) and require large volumes of non-textual interaction data - though many synergies between these two paradigms are possible, as discussed below."}, {"title": "Natural Language vs. Non-Textual Interaction Data", "content": "Both textual and non-textual data are important in this chapter - Figure 4.1 illustrates how such data can represent key RS information, covering items, users, and system interactions. This figure is discussed in detail in Section 4.2."}, {"title": "Task-specific Reasoning with Conventional RSs", "content": "Conventional RSs must be trained on large amounts of task-specific interaction data - making them highly-specialized tools that are typically optimized for either rating prediction or top-k, sequential, or page-wise recommendation. While their performance on offline benchmarks for these tasks is generally very strong (c.f. Ch. 6), these specialized systems are limited by the inability of standardized interaction data (e.g., purchases, views, clicks, etc.) to capture nuanced and diverse user preferences. These systems also often require considerable data engineering efforts and design time to deploy.\nHowever, despite these limitations, conventional RS remain powerful and scalable methods for predicting future interactions, able to work with millions of users and items. Therefore, as will be discussed in Sections 4.5-4.7, many researchers are actively studying the integration of conventional RSs as specialized sub-components within larger, LLM-powered system architectures (e.g., Friedman et al., 2023; Hou et al., 2023; Zhang et al., 2023b)."}, {"title": "General Recommendation Reasoning with LLMs", "content": "In contrast to conventional RSs, the pretraining of LLMs on large text corpora provides them with emergent abilities for general reasoning with LLMs achieving impressive performance on many diverse and previously unseen tasks (Bubeck et al., 2023). Through pretraining, LLMs have internalized fine-grained knowledge about a wide range of entities, human preferences, and interaction patterns \u2013 knowledge which could enhance RS personalization while reducing data and design time requirements."}, {"title": "Recommendation and Explanation", "content": "Firstly, LLMs can use NL data (e.g., descriptions of items and a user's preferences) to make recommendations \u2013 either by generating text (c.f. Sec 4.4) or via embedding-based"}, {"title": "Conversational Recommendation", "content": "LLMs can also drive NL recommendation dialogues where users interactively convey various intents, including: stating and refining preferences, critiquing recommendations, asking questions, or engaging in trade-off negotiations (c.f. Sec 4.7). Conversational recommendation systems (CRSs) can facilitate such complex dialogues by leveraging LLMs to generate a variety of personalized responses, including recommendations and explanations, answers to questions, and requests for more information. Thus, the general reasoning abilities of LLMs provide opportunities to better personalize not only recommendations, but also user-system interaction sessions more broadly."}, {"title": "Limitations of LLM-Driven Recommendation", "content": "Unfortunately, these LLM-driven opportunities for RSs also come with new risks, biases, and limitations, as discussed further in Chapter 7. Firstly, LLMs may hallucinate, generating outputs which are incorrect or misleading (Ji et al., 2023) which creates significant risks in settings where reliability is key. More broadly, our ability to control LLM behaviour is limited: while prompt engineering and fine-tuning influence outputs, neither approach achieves total control (Mialon et al., 2023). More optimistically however, this chapter also discusses approaches to mitigate some of these limitations, including through retrieval-augmented generation (RAG) and external tool calls to improve system control and reliability (c.f. Sec 4.5-4.7)."}, {"title": "Chapter Outline", "content": "Before diving into recommendation methodologies, we first present a structured overview of NL data sources for describing items, users, and interactions in Section 4.2. Then, as summarized in Figure 4.2, the subsequent sections cover key techniques and research in LLM-driven"}, {"title": "Data Sources in LLM-Driven RSs", "content": "The use of language in recommendation is not new. For instance, text has long been leveraged for content-based recommendation (Lops et al., 2011), key-phrase explanations (McAuley and Leskovec, 2013; Wu et al., 2019c), and metadata-driven Dialogue State Tracking (DST, Yan et al., 2017). However, LLM's have enabled far more advanced NL reasoning about items, users, and their interactions (Geng et al., 2022), creating opportunities for more nuanced and interactive RS personalization. This section thus outlines the primary data sources which could be used by LLM-era RS, covering item data, interaction data, and user profiles, summarized in Figure 4.1."}, {"title": "Item Text", "content": "The right side of Figure 4.1 illustrates data sources for textual item representations, including titles, descriptions, metadata, and reviews."}, {"title": "Verbalizing Non-Textual Interactions", "content": "Conventional non-textual user-item interaction history \u2013 such as views, clicks, likes, purchases, and ratings\ncan easily be represented as text. For this, a simple template may be sufficient \u2013 for instance, Hou et al. (2023) represent a user's movie viewing history with a template such as: \u201cI've watched the following movies in the past in order: 1. Multiplicity, 2. Jurassic Park, ...\u201d. Alternatively, LLMs can be prompted to summarize such interaction histories (Yin et al., 2023; Zhou et al., 2024; Wei et al., 2024). In either case, such verbalized histories offer an alternative to the sometimes arbitrary mapping of distinct interactions types to numerical or categorical formats, and can also cover pointwise, sequential, and bundle interactions."}, {"title": "NL Interactions", "content": "Other user-system interactions are inherently text-based \u2013 for instance, reviews were already discussed in Section 4.2.1."}, {"title": "NL User Profiles", "content": "The left side of Figure 4.1 illustrates various textual representations of user preferences, including metadata and NL user profiles. Recently, Radlinski et al. (2022) proposed that language-driven recommendation could be centered on scrutable NL user profiles: textual descriptions of user preferences that are editable and understandable by humans. Such user profiles could succinctly summarize user interests through both specific examples of preferred items and generic preference descriptions.\nWhile research on effectively generating, editing, and leveraging these interpretable NL preference representations is still nascent, several initial studies have emerged. For instance, Sanner et al. (2023) have users directly express generic NL item preferences in personal NL profiles, while other authors (Yin et al., 2023; Zhou et al., 2024) use and LLM to generate NL profiles based on item rating histories \u2013 both works find that recommendation performance is competitive with or better than conventional baselines in cold-start settings."}, {"title": "User Agency via Editable NL Profiles", "content": "In principle, an editable NL profile has the potential to empower users to correct system errors, safeguard their privacy, and exert natural control over their preference representations (Radlinski et al., 2022a). It may also be well-suited to handle preference shifts (Hosseinzadeh Aghdam et al., 2015; Pereira et al., 2018) by allowing users to delete obsolete interests or describe temporary contexts. In addition, users can express aspirations - desires that do not necessarily align with past behavior, but should influence future recommendations (Ekstrand and Willemsen, 2016). Finally, user edits that result in improved recommendations can incentivize further feedback and increase user satisfaction (Bostandjiev et al., 2012; Harper et al., 2015; Knijnenburg et al., 2012)."}, {"title": "Encoder-only LLM Recommendation", "content": "We now begin our discussion of how textual data can be used in LLM-driven RSs - starting with recommendation with encoder-only LLMs. As shown in Figure 4.3, encoder-only LLMs can be used in two main"}, {"title": "Dense Retrievers", "content": "First introduced in the field of information retrieval (IR), dense retrievers produce a ranked list of documents given a query by evaluating the similarity (e.g., dot product or cosine similarity) between a document embedding and query embedding (Fan et al., 2022). Dense retrieval is highly scalable (especially with approximate search libraries like FAISS\u00b9) since document embeddings can be pre-computed and only the query embedding needs to calculated at query time.\nTo use dense retrieval for recommendation, first, a component of each item's text content, such as its title, description, reviews, etc., is treated as a document. Then, a query is formed by some NL user preference description \u2013 for instance: an actual search query, the user's"}, {"title": "Cross-Encoders", "content": "In contrast to dense retrievers, cross-encoders embed a query and document jointly, allowing cross-attention between query and document tokens (Fan et al., 2022). Several works approach rating prediction by jointly embedding NL item and preference descriptions in LLM cross-encoder architectures with a rating prediction head (Zhang et al., 2021;\nYao et al., 2022; Wu et al., 2021; Qiu et al., 2021; Zhang and Wang, 2023). Such fusion-in-encoder methods often exhibit strong performance because they allow interaction between user and item representations, but are much more computationally expensive than dense retrieval and thus may be best used for small item sets or as rerankers."}, {"title": "Generative Recommendation and Explanation", "content": "We next move beyond item-preference scoring to generative recommendation (c.f. Sec 4.4.1-4.4.2) and explanation (c.f. Sec 4.4.3) with autoregressive LLMs. Autoregressive LLM inputs are called prompts, which are sequences of tokens expressing a task such as top-k recommendation, rating prediction, or explanation generation (Geng et al.,"}, {"title": "Zero- and Few-Shot Recommendation", "content": "The simplest way an autoregressive LLMs can be used is in the untuned (i.e., \"off-the-shelf\") setting (e.g. Sileo et al., 2022; Sanner et al., 2023). As illustrated in Figure 4.4, this includes:"}, {"title": "LLM Tuning for Generative Recommendation", "content": "To improve an LLM's generative recommendation performance, multiple works study LLM tuning on historical RS data. First, historical data is converted into textual input-output training pairs for generative recommendation tasks (Geng et al., 2022), which may include:"}, {"title": "Generative Explanation", "content": "Autoregressive LLMs can also generate explanations that aim to help users comprehend why recommendations were made. Similarly to recommendation generation, explanations can be generated by prompting"}, {"title": "Retrieval Augmented Recommendation", "content": "While the previous two sections explore the use of LLM knowledge internalized through pretraining or tuning to generate recommendations and explanations, relying solely on internal LLM knowledge has several limitations (Lewis et al., 2020):"}, {"title": "RAG in RSSs", "content": "There are many opportunities to use RAG in RSs, including to generate recommendations, explanations, and question answers. More broadly, the RAG framework introduces us to modular architectures for LLM-driven RSS a concept we'll explore further when discussing LLM representation generation (c.f. Sec. ??) and conversational RS architectures (c.f. Sec. 4.7)."}, {"title": "RAG for Explanation and Conversational Recommendation", "content": "Other examples of how RAG can be used in RSs include explanation generation and as a tool for conversational recommendation. For RAG-based explanation generation, Xie et al. (2023) generate queries based on interaction history to retrieve an item's reviews, which are then used as context to generate an explanation of the recommendation. Examples of RAG in conversational recommendation, discussed further in Section 4.7, include work by Friedman et al. (2023) to retrieve relevant user preference descriptions from a user \u201cmemory\u201d module, and by Kemper et al. (2024) to retrieve information from an items reviews to answer user questions."}, {"title": "LLMs Representation Generation", "content": "While Section 4.5 explored using an external module such as retrievers or RSs to select LLM inputs, this section discusses the converse setting in which LLMs generate inputs to downstream modules, as illustrated in 4.6. Specifically, LLMs can be used to transform text such as item and preference descriptions into representations (e.g., embeddings, text, item ratings) that serve as inputs to modules such as RSs, retrievers, or autoregressive LLMs. Such text transformations can be interpreted"}, {"title": "Text to Text", "content": "Two common settings where an LLM generates text that serves as input to a downstream module are search queries and LLM prompt elements, with several example studies for both approaches discussed below."}, {"title": "Text to Embeddings", "content": "As discussed in Chapters 2 and 3, many RS techniques rely on latent representations of items and user preferences. Thus, a recent line of research uses LLMs to encode semantic information from text into latent embeddings which are then used for recommendation. While encoder-only LLM recommendation was already discussed in Section 4.3, this section covers multi-stage pipelines where LLM embeddings are used for downstream recommendation modules, discussed next."}, {"title": "Rating Prediction with LLM Embeddings", "content": "LLMs have also been used to generate latent representations of items (based on item text) and users (based on item interactions) that serve as inputs to a neural network which predicts a user-item rating (Wu et al., 2021; Yuan et al., 2023). These approaches essentially augment the well-known"}, {"title": "Conversational Recommendation", "content": "The previous sections mostly focused on single-turn LLM recommendation personalized based on pre-existing user history information, such as non-verbal interactions, queries, reviews, and so on (c.f. Figure 4.1), and item text. However, LLMs provide new opportunities for multi-turn conversational recommender systems (CRSs) where each turn presents a chance for the user to clarify or revise their preferences, critique and ask questions about recommended items, or convey a variety of other real-time intents such as those shown in Table 4.1 (Lyu et al., 2021). Correspondingly, CRSs should facilitate a wide range of responses including revising recommendations, responding to questions, and personalizing explanations. Further, each turn is also an opportunity for the CRS to generate proactive utterances such as clarifying questions or explanations focused on key topics to help elicit user preferences. As with user intents, various possible CRS actions are summarized in Table 4.2 (Lyu et al., 2021). LLM-driven CRSs thus present opportunities not only to personalize recommendations, but also to personalize system interactions more broadly."}, {"title": "Pre-LLM CRS Architectures", "content": "Historically, most pre-LLM CRSs followed a two-step process in each turn: 1) belief tracking to maintain a dialogue state, and 2) response generation to produce a system utterance (Jannach et al., 2020). Belief tracking was often implemented\nwith slot-filling techniques, where the dialogue history would be used to update a dialogue state consisting of variables, or slots (e.g., \u201cpre-ferred_cuisine: _\"), that were filled from a set of predefined values (e.g., \"Mexican\u201d, \u201cFrench\u201d, ...) (Williams et al., 2014; Budzianowski et al., 2018). These slot-based states would then be used to determine the system response, which often used NL templates and item metadata. However, these slot-based architectures exhibited limited NL reasoning capabilities, constraining their capacity to understand and represent complex user intents and generate deeply personalized responses and recommendations.\""}, {"title": "Belief Tracking", "content": "LLMs enable a CRS to track its beliefs about the conversation through text-augmented dialogue states. This section covers the use of purely textual components in dialogue states as well as the incorporation of non-textual elements alongside text. Both textual and non-textual dialogue state elements can form inputs to response generation modules, discussed further in Section 4.7.2."}, {"title": "System Response Generation", "content": "The primary purpose of the dialogue state elements discussed above is to guide the system response by forming inputs to response generation"}, {"title": "Prompting", "content": "There are many diverse ways that prompting can be used to guide CRS utterance generation. Several works study single-intent systems, where the prompt is constructed using the dialogue history and an instruction to generate an utterance with a fixed intent, such as to recommend (He et al., 2023) or ask a preference elicitation query (Handa et al., 2024; Austin et al., 2024). Other methods (Joko et al., 2024; Kemper et al., 2024) express hand-crafted dialogue rules through prompts, asking an LLM to select the best system action given the dialogue state and some rules (e.g., \"Ask a user for their location if they have not provided it, otherwise, recommend a restaurant.\"). In addition, prompts can be partially or fully system generated, for instance using the output of another LLM module, a retriever, or a reasoning tool such as an RS or KG (e.g., Zhou et al., 2020; Wang et al., 2022; Friedman et al., 2023; Gao et al., 2023)."}, {"title": "Tuning", "content": "CRS dialogue policies can also be controlled by tuning LLMs on human-human or synthesized conversation data (Li et al., 2018a; Kang et al., 2019; Zhou et al., 2020; Liu et al., 2020; Ma et al., 2020; Li et al., 2022b; Wang et al., 2022; Friedman et al., 2023; Joko et al., 2024). While these methods cover many tuning approaches, they all lead to an LLM internalizing some knowledge about how to respond to the user in NL or execute some reasoning step such as a search or recommendation."}]}