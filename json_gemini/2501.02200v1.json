{"title": "Learning Evolution via Optimization Knowledge Adaptation", "authors": ["Chao Wang", "Licheng Jiao", "Jiaxuan Zhao", "Lingling Li", "Fang Liu", "Shuyuan Yang"], "abstract": "Evolutionary algorithms (EAs) maintain populations through evolutionary operators to discover diverse solutions for complex tasks while gathering valuable knowledge, such as historical population data and fitness evaluations. However, traditional EAs face challenges in dynamically adapting to expanding knowledge bases, hindering the efficient exploitation of accumulated information and limiting adaptability to new situations. To address these issues, we introduce an Optimization Knowledge Adaptation Evolutionary Model (OKAEM), which features dynamic parameter adjustment using accumulated knowledge to enhance its optimization capabilities. OKAEM employs attention mechanisms to model the interactions among individuals, fitness landscapes, and genetic components separately, thereby parameterizing the evolutionary operators of selection, crossover, and mutation. These powerful learnable operators enable OKAEM to benefit from pre-learned extensive prior knowledge and self-tune with real-time evolutionary insights. Experimental results demonstrate that OKAEM: 1) exploits prior knowledge for significant performance gains across various knowledge transfer settings; 2) achieves competitive performance through self-tuning alone, even without prior knowledge; 3) outperforms state-of-the-art black-box baselines in a vision-language model tuning case; 4) can improve its optimization capabilities with growing knowledge; 5) is capable of emulating principles of natural selection and genetic recombination.", "sections": [{"title": "1 Introduction", "content": "Inspired by biological evolution, evolutionary algorithms (EAs) continuously update population systems through crossover, mutation, and selection to explore complex fitness landscapes [1]. Prominent examples of EAs include the genetic algorithm (GA) [2], the evolution strategy (ES) [3], and the genetic programming (GP) [4]. These methods rely solely on the fitness values of individuals to drive the evolutionary process without requiring gradient information. Advances in computational techniques [5] have allowed EAs to provide diverse solutions for highly complex optimization tasks such as neuroevolution [6, 7], robotic control [8, 9], industrial design [10], and scientific discoveries [11, 12]. As the scale and complexity of these tasks increase [1, 13], EAs generate a significant amount of valuable knowledge, including historical populations and their fitness data. However, existing EAs face challenges in enhancing their optimization capabilities as knowledge bases grow. Two long-standing issues are particularly prominent: incomplete utilization of prior knowledge and inflexible knowledge adaptation strategies.\nEvolutionary knowledge transfer (EKT) leverages prior knowledge from source tasks to accelerate evolutionary optimization for challenging target tasks [14-20]. Current mainstream EKT methods focus mainly on knowledge derived from highly related individuals [21], thus neglecting valuable information from other candidates within the population. This limited knowledge utilization hampers the exploitation of underlying evolutionary behaviors on source tasks. Furthermore, adaptability has long been a key challenge in the field of EAs [2, 22-24]. The absence of a unified framework for heuristic evolutionary operators results in adaptability strategies specific to particular EAs. For example, the covariance matrix adaptation used in evolution strategies (CMAES) [25] may not be effective in GA contexts. Recent studies [26-30] have explored training parameterized EAs in various tasks to improve generalization and adaptability. However, these learnable EAs (LEAs) cannot dynamically adjust parameters using generated populations and fitness data, potentially limiting their optimization capabilities.\nTo address these challenges, we introduce the Optimization Knowledge Adaptation Evolutionary Model (OKAEM), which exhibits powerful transferability and adaptability. OKAEM pre-learns extensive prior knowledge from source tasks and dynamically adjusts to incorporate new knowledge from target tasks. By leveraging attention mechanisms, OKAEM explicitly models the relationships among individuals, fitness landscapes, and genetic components, guiding selection, crossover, and mutation. These parameterized evolutionary operators enable learnable and highly parallelizable update rules. Multilayer perceptrons (MLPs) with Dropout are employed to introduce stochasticity into the operators. To our knowledge, this is the first instance where neurons are used to represent the random behavior in EAs.\nOKAEM involves two stages: pre-training and adaptive optimization (Fig. 1). During the pre-training stage, OKAEM learns population evolution behaviors on source tasks by predicting the next generation's population, thereby leveraging prior knowledge to enhance performance. In the adaptive optimization phase, OKAEM continuously generates offspring and dynamically tunes its parameters to adapt to new evolutionary insights by minimizing the distance between generated populations and"}, {"title": "2 Optimization knowledge adaptation evolutionary model", "content": "We consider applying optimization knowledge to EAs to find the optimal solution of a complex non-analytic function: $\\min_x[f(x) | M, P]$, where $f \\in \\mathbb{R}^1$ is the objective function, and $x \\in \\mathbb{R}^d$ is the decision variable. $M = \\{(P^{(t)}_k, F^{(t)}_k) | P^{(t)}_k \\in \\mathbb{R}^{N \\times d}, F^{(t)}_k \\in \\mathbb{R}^{N \\times 1}, k = 1,..., K, t = 1, . . ., T\\}$ represents a series of prior knowledge accumulated from source tasks. $P^{(t)}_k$ and $F^{(t)}_k$ denote the population and fitness data of the k-th source task at generation t. Each individual in the population represents a candidate solution for the optimization task. Fig. 1a visualizes the prior knowledge M accumulated by GA and CMAES on two 2D source optimization tasks: Ackley and Sphere. These visualizations intuitively reflect the evolutionary behaviors of populations on the source tasks. $P = \\{(P^{(t)}, F^{(t)}) | P^{(t)} \\in \\mathbb{R}^{N \\times d}, F^{(t)} \\in \\mathbb{R}^{N \\times 1},t = 1,..., j\\}$ denotes the optimization knowledge accumulated from the 1st to the j-th generation on the target task. The proposed OKAEM includes two stages: 1) pre-training on M (Fig. 1a); adaptive optimization using P (Fig. 1b). For the pseudocode of OKAEM, see Supplementary Appendix A."}, {"title": "2.1 Architecture", "content": "Given the current population $P^{(t)} \\in \\mathbb{R}^{N \\times d}$ and fitness data $F^{(t)} \\in \\mathbb{R}^{N \\times 1}$, OKAEM generates an offspring population $\\hat{p}^{(t)} \\in \\mathbb{R}^{N \\times d}$ through selection, crossover, and mutation, denoted as $\\hat{p}^{(t)} = OKAEM_w (P^{(t)}, F^{(t)})$ (Fig. 1 b(i)). The selection module defines a selection matrix $A^{(t)} \\in ]\\mathbb{R}^{N \\times N}$, where $A_{ij}$ indicates individual j's contribution to generating the i-th individual for crossover. Multi-head attention mechanisms [31] parameterize $A^{(t)}$ to model individual and fitness relationships. Using $A^{(t)}$, the crossover module recombines individuals in $P^{(t)}$ to produce an intermediate population $P'^{(t)}$. In addition, an MLP with Dropout is employed to ensure the randomness of the crossover operator. The mutation module perturbs each $p_i^{(t)} \\in \\mathbb{R}^{d \\times 1}$ in $P'^{(t)}$ to generate the corresponding offspring $\\hat{p}_i^{(t)} \\in \\mathbb{R}^{d \\times 1}$. A mutation matrix $M^{(t)} \\in \\mathbb{R}^{d \\times d}$,"}, {"title": "2.2 Pre-training and adaptive optimization", "content": "The pre-training aims to uncover the patterns underlying prior knowledge to enhance the performance of OKAEM. As shown in Fig. 1a, given prior knowledge M, the optimization objective of pre-training is to minimize the Euclidean distance between the predicted offspring population $\\hat{P}_k^{(t)}$ and the actual next-generation population $P_k^{(t+1)}$ in the prior knowledge:\n$\\min_W L_1 = \\sum_{k=1}^K \\sum_{t=1}^{T-1} ||P_k^{(t+1)} - \\hat{P}_k^{(t)} ||^2_2,  \\hat{P}_k^{(t)} = OKAEM_W(P_k^{(t)}, F_k^{(t)}).$\nThis allows OKAEM to explicitly learn population evolution behavior by predicting the next generation. Traditional EKT methods rely on heuristic rules to determine what, when, and how to transfer knowledge, focusing only on a subset of promising prior knowledge and heavily depending on expert design [14, 21]. In contrast, OKAEM utilizes all prior knowledge for pre-training, avoiding knowledge waste. Moreover, prior knowledge generated by different EAs on a set of source optimization tasks can be used as training data, enabling OKAEM to learn diverse types of evolution behaviors (see detailed analysis in Fig. 2b).\nAs shown in Fig. 1b, adaptive optimization comprises initialization, reproduction, evaluation, elitism, and self-tuning. Over T generations, the best individual $p^* \\in \\mathbb{R}^d$ is obtained. Initially, Latin hypercube sampling is used to generate a random initial"}, {"title": "3 Results", "content": "We evaluate OKAEM's performance on the sequence transfer optimization problem (STOP) suite [33], a comprehensive benchmark comprising 12 problems that simulate knowledge transfer scenarios in EAs. Each STOP task encompasses a target task and prior knowledge derived from a set of source optimization tasks, effectively representing the spectrum of similarity relationships between optimal solutions encountered in real-world applications. The problems are categorized into three groups based on their degree of similarity: high (STOP1-4), mixed (STOP5-8), and low (STOP9-12). The baselines include both classical and advanced EKT methods [21], encompassing various dimensions of knowledge transfer: non-transfer strategies (N), what to transfer (H, M1, WD, OC, ROC, KLD), how to transfer (M1-Te, M1-Tr, M1-Tm, M1-M, M2-A, OC-L, OC-A, OC-K, OC-N, ROC-L), and when to transfer (F-1, F-5, F-10, D-M, D-P, and D-G). Additionally, two variants of OKAEM serve as baselines for comparison: OKAEM-PT, which relies solely on pre-training, and OKAEM-ST, which focuses exclusively on self-tuning. This setup allows us to comprehensively assess the effectiveness of OKAEM's dual-phase approach in leveraging prior knowledge and adapting to new tasks. For detailed problem configurations and parameter settings, see Supplementary Appendix B.\nAs shown in Fig. 2a, the experimental results provide several key insights:"}, {"title": "3.2 Black-box optimization benchmark problem", "content": "In many practical scenarios, collecting prior knowledge can be challenging, rendering pre-training infeasible. Leveraging its flexibility, OKAEM can perform adaptive optimization independently to solve complex tasks. This section evaluates OKAEM's"}, {"title": "3.3 Black-box prompt tuning for the vision-language model", "content": "Pre-trained models, particularly those for vision-language tasks, are commonly released as services that allow users to set task-specific prompts to query the models [41]. EAs such as CMAES are widely used to optimize these prompts to enhance the performance of pre-trained models [41-44]. Without access to the model's architecture or gradient information, optimizing prompts in this black-box setting remains a significant challenge. Let the forward propagation of a vision-language model be denoted"}, {"title": "3.4 Parameter sensitivity analysis", "content": "Fig. 6 presents the sensitivity analysis of OKAEM's four critical parameters on the STOP suite: the number of layers L, population size N, dropout probability pc in crossover, and dropout probability pm in mutation. Fig. 6a illustrates that the performance of OKAEM improves with an increase in both the number of source tasks and model depth, regardless of whether the task similarity is high (STOP1-STOP4) or low (STOP9-STOP12). More source tasks provide richer prior knowledge, allowing deeper models to capture complex patterns. The positive correlation between"}, {"title": "4 Methods", "content": "We employ attention mechanisms to model individual and fitness relations, parameterizing the selection module. Given the current population $P^{(t)} \\in \\mathbb{R}^{N \\times d}$ and fitness $F^{(t)} \\in \\mathbb{R}^{N \\times 1}$, the selection matrix $A^{(t)} \\in \\mathbb{R}^{N \\times N}$ is defined as follows:\n$A^{(t)} = \\text{softmax} (\\frac{A^{(t)}_p + A^{(t)}_f}{\\sqrt{d_A}}).$\nwhere\n$A^{(t)}_p = (P^{(t)} W_Q^P)(P^{(t)} W_K^P)^T, A^{(t)}_f = (F^{(t)} W_Q^F) (F^{(t)} W_K^F)^T$.\n$A^{(t)}_p$ captures pairwise interactions between individuals in the population, while $A^{(t)}_f$ models the interplay between their fitness scores. The matrices $W_Q^P, W_K^P \\in \\mathbb{R}^{d \\times d_A}$ and $W_Q^F, W_K^F \\in \\mathbb{R}^{1 \\times d_A}$ are learnable parameters that transform the original features into a space conducive to learning the selection policy. The softmax function converts the relation scores into a probability distribution, scaled by $\\sqrt{d_A}$ to stabilize optimization and prevent gradient explosion. Element $A^{(t)}_{ij}$ in the selection matrix can be used to quantify the extent to which individual j influences the generation of individual i by crossover."}, {"title": "4.1.2 Crossover", "content": "The crossover module begins by applying the selection matrix $A^{(t)}$ to the current population $P^{(t)}$ for individual-level recombination:\n$O^{(t)} = A^{(t)} P^{(t)} W_V,$\nwhere the transformation $W_V \\in \\mathbb{R}^{d \\times d_A}$ reduces the dimensionality of the search space. This dimensionality reduction is a well-established technique in EAs to enhance optimization efficiency and reduce computational complexity [54, 55].\nTo enhance the expressiveness of the crossover, we employ multi-head attention mechanisms that focus on the features of the population and fitness across different subspaces. Given H heads, Eq. (5) becomes:\n$O^{(t)} = ||_{h=1}^H A_h^{(t)} P^{(t)} W_V^h,$\nwhere\n$A_h^{(t)} = \\text{Softmax} (\\frac{(P^{(t)}W_Q^hP)(P^{(t)}W_K^hP)^T + (F^{(t)}W_Q^hF)(F^{(t)}W_K^hF)^T}{\\sqrt{d_A/H}}).$"}, {"title": "4.1.3 Mutation", "content": "The mutation module individually perturbs each individual $p_i^{(t)} \\in \\mathbb{R}^{d \\times 1}$ in the intermediate population $P'^{(t)}$ to generate the corresponding offspring $\\hat{p}_i^{(t)} \\in \\mathbb{R}^{d \\times 1}$. Employing attention mechanisms, we model gene relations to guide the mutation process. The mutation matrix $M^{(t)} \\in \\mathbb{R}^{d \\times d}$ is defined as:\n$M^{(t)} = \\text{Softmax} (\\frac{(P^{(t)} W_Q^M) (P^{(t)} W_K^M)^T}{\\sqrt{d_A}})$\nwhere $W_Q^M, W_K^M \\in \\mathbb{R}^{1 \\times d_A}$. Similar to the crossover module, we use residual connections and a MLP to generate offspring:\n$\\hat{p}_i^{(t)} = p_i^{(t)} + MLP(O_i^{(t)}),$\nwith\n$O_i^{(t)} = M^{(t)} p_i^{(t)} W_V^M,$\nand\n$MLP(O_i^{(t)}) = \\text{Dropout}_{P_M} (\\text{Tanh}(O_i^{(t)} W_3 + b_3))W_4 + b_4,$\nwhere $W_V^M \\in \\mathbb{R}^{1 \\times d_A}, W_3 \\in \\mathbb{R}^{dA \\times dM}, b_3 \\in \\mathbb{R}^{d_M}, W_4 \\in \\mathbb{R}^{dM \\times 1}$, and $b_4 \\in \\mathbb{R}^{1}$. The Dropout layer with probability $p_M$ introduces stochasticity into the mutation process.\nAll generated offspring are then combined into the offspring population $P^{(t)} \\in \\mathbb{R}^{N \\times d}$.\n$P^{(t)} = ||_{i=1}^N (\\hat{p}_i^{(t)})^T$.\nThe parameters of the mutation module are summarized as:"}, {"title": "4.2 Computational complexity analysis", "content": "The selection matrix and the MLP primarily determine the computational complexity of the selection and crossover. According to Eq. (4), the complexity of computing the selection matrix is $O(N \\cdot d \\cdot d_A + N^2 \\cdot d_A)$, where N is the population size, d is the dimensionality of the search space, and dA is the embedding dimension. From Eq. (7), the complexity of the MLP involved in the crossover is $O(N\\cdot d_A\\cdot d_M + N\\cdot d_M\\cdot d)$, with $d_M$ representing the hidden layer dimension. Therefore, the total complexity for selection and crossover is $O(N\\cdot d \\cdot d_A + N^2 \\cdot d_A + N\\cdot d_A\\cdot d_M + N\\cdot d_M\\cdot d)$.\nAccording to Eq. (10), the complexity of computing the mutation matrix is $O(d \\cdot d_A + d^2 \\cdot d_A)$. Eq. (13) indicates that the MLP involved in mutation has a complexity of $O(d \\cdot d_A\\cdot d_M)$. Thus, the overall complexity for mutation is: $O(d^2 \\cdot d_A + d\\cdot d_A\\cdot d_M)$.\nConsolidating these results, the total computational complexity for an L-layer architecture is $O(L\\cdot N\\cdot d\\cdot d_A + L\\cdot N^2\\cdot d_A + L\\cdot N\\cdot d_A\\cdot d_M + L\\cdot N\\cdot d_M\\cdot d + L\\cdot d^2\\cdot d_A + L\\cdot d\\cdot d_A d_M)$. Assuming $d_A = d_M = d$, this simplifies to $O(L\\cdot N\\cdot d^2 + L \\cdot N^2 \\cdot d + L \\cdot d^3)$. In complex optimization scenarios, where the population size N is generally smaller than the problem dimension d, the leading term of complexity is $O(L\\cdot d^3)$. This highlights the significant impact of the problem dimension d on computational requirements in high-dimensional search spaces. The assumption $d_A = d_M = d$ simplifies the analysis but may not hold in practice. Careful consideration should be given to the specific values of $d_A$ and $d_M$ based on the application context."}, {"title": "5 Discussion", "content": "With the advancement in computational capabilities, complex optimization tasks in scientific and industrial fields have become increasingly intricate and challenging. Traditional EAs often rely heavily on specific problem structures, limiting their ability to leverage the vast amount of valuable knowledge generated during optimization. This constrained transferability and adaptability hinder their optimization performance and reduce confidence in practical applications. This paper introduces a novel neural representation-based evolutionary framework, OKAEM, which efficiently utilizes prior knowledge and quickly adapts to self-generated new knowledge. As demonstrated on 12 STOPs, 24 BBOBs, and a real-world case study, OKAEM exhibits superior optimization performance compared to existing baselines, thanks to its robust transferability and adaptability. Extensive experiments show that OKAEM exhibits strong learnability: 1) Its optimization capability improves as knowledge accumulates; 2) It can explicitly learn the principles of natural selection and genetic combination"}]}