{"title": "P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Networks", "authors": ["Zheng Wang", "Wanwan Wang", "Yimin Huang", "Zhaopeng Peng", "Ziqi Yang", "Cheng Wang", "Xiaoliang Fan"], "abstract": "In recent years, graph neural networks (GNNs) have been commonly utilized for social recommendation systems. However, real-world scenarios often present challenges related to user privacy and business constraints, inhibiting direct access to valuable social information from other platforms. While many existing methods have tackled matrix factorization-based social recommendations without direct social data access, developing GNN-based federated social recommendation models under similar conditions remains largely unexplored. To address this issue, we propose a novel vertical federated social recommendation method leveraging privacy-preserving two-party graph convolution networks (P4GCN) to enhance recommendation accuracy without requiring direct access to sensitive social information. First, we introduce a Sandwich-Encryption module to ensure comprehensive data privacy during the collaborative computing process. Second, we provide a thorough theoretical analysis of the privacy guarantees, considering the participation of both curious and honest parties. Extensive experiments on four real-world datasets demonstrate that P4GCN outperforms state-of-the-art methods in terms of recommendation accuracy. The code is available at https://github.com/WwZzz/P4GCN.", "sections": [{"title": "1 INTRODUCTION", "content": "Graph neural networks (GNNs) [1, 2] are a class of deep learning models specifically designed to handle graph-structured data, including various scenarios such as social networks [3, 4], finance and insurance technology [5, 6], etc. By harnessing the capabilities of GNNs, social recommendation systems can gain an in-depth understanding of the intricate dynamics and social influence factors that shape users' preferences, leading to improved recommendation accuracy. For example, an insurance company could utilize social relationships extracted from a social network platform by a GNN model to enhance the accuracy of personalized product recommendations (i.e., insurance marketing). However, in real-world scenarios, privacy and business concerns often hinder direct access to private information possessed by aforementioned social platforms. Consequently, the integration of privacy-preserving technologies, such as federated learning [7], secure multi-party computation [8], homomorphic encryption [9], and differential privacy [10], into social recommendation tasks has attracted significant attention from both academia and industries.\nRecent works mainly enable the recommender to collaboratively train matrix factorization [11] based recommendation models without accessing the social data owned by other platforms[12, 13]. [12] proposed the secure social MF to utilize the social data as the regularization term when optimizing the model. Further, [13] significantly reduces both the computation and communication costs of the secure social matrix factorization by designing a new secure multi-party computation protocol. However, these solutions cannot be applied to training GNN models, because the computation processes involved in training GNN models are typically more complex compared to MF-based methods. For example, in GNN models, the aggregation of features from different users on the social graph involves multiplying the aggregated results with additional parameter matrices. In contrast, MF-based methods focus on reducing the distances between neighbors' embeddings based on the social data, without the need for additional parameters. In addition, the formulations used in the forward and backward processes of GNN models are much more complex than those of MF-based methods. Consequently, it is essential to develop a secure social recommendation protocol tailored explicitly to enhance the optimization of GNN models.\nTo address the aforementioned challenges, we propose a novel vertical federated Social recommendation with Privacy-Preserving Party-to-Party Graph Convolution Networks (P4GCN) to improve the social recommendation system without direct access to the social data. In our approach, we first introduce the Sandwich-Encryption module, which ensures data privacy throughout the collaborative computing process. We then provide a theoretical analysis of the security guarantees under the assumption that all participating parties are curious and honest. Finally, extensive experiments are conducted on three real-world datasets, and results demonstrate that our proposed P4GCN outperforms state-of-the-art methods in terms of both recommendation accuracy and communication efficiency.\nThe main contributions of this study can be summarized as follows:\n\u2022 We propose P4GCN, a novel method for implementing vertical federated social recommendation with theoretical guarantees. Unlike previous works that assume the availability of social data, we focus on leveraging GNN to enhance recommendation systems with fully unavailable social data in a privacy-preserving manner.\n\u2022 We introduce the sandwich encryption module, which guarantees data privacy during model training by employing a combination of homomorphic encryption and differential privacy. We provide theoretical guarantees to support its effectiveness.\n\u2022 Experimental results conducted on four real-world datasets illustrate the enhancements in performance and efficiency. Furthermore, we evaluate the impact of the privacy budget on the utility of the model."}, {"title": "2 RELATED WORKS", "content": "Existing social recommendation methods have adopted various architectures according to their goals and achieved outstanding results [14]. For instance, many SocialRS methods employ the graph attention neural network (GANN) [2] to differentiate each user's preference for items or each user's influence on their social friends. Some other methods [15-19] use the graph recurrent neural networks (GRNN) [20, 21] to model the sequential behaviors of users. However, these centralized methods cannot be directly applied when the social data is inaccessible."}, {"title": "2.1 Social recommendation", "content": "There are mainly two types of works addressing recommendation systems in FL. The first type is User-level horizontal FL. FedMF [22] safely train a matrix factorization model for horizontal users. FedGNN [23] captures high-order user-item interactions. FedSoG [24] leverages social information to further improve model performance. The second type is Enterprise-level vertical FL which considers training a model with separated records kept by different companies. To promise data security in this case, techniques such as differential privacy[25] and homomorphic encryption[26], are widely used. [27] uses random projection and ternary quantization mechanisms to achieve outstanding results in privacy-preserving. However, these works failed to construct the social recommendation model when the social data is unavailable. To address this issue, SeSorec [12] protects social information while utilizing the social data to regularize the model. [13] proposed two secure computation protocols to further improve the training efficiency. Although these works can be applied to matrix factorization models, the GNN-based models have not been considered in this case."}, {"title": "2.2 Federated recommendation", "content": "In this section, we first introduce the notations we used, and then we give the formal definition of our problem. Let $U = \\{u_i\\}$, $u_i \\in N$ denote the user set and $V = \\{v_i\\}$, $v_i \\in N$ denote the item set, where the number of users is $N_u = |U|$ users and the number of items is $N_v = |V|$. There are two companies $P_1$, $P_2$ that own different parts of the user and item data. $P_1$ owns the user set $U$ and the item set $V$ with the interactions between users and items $R = \\{(u_i, v_j, r_k)\\}$, where each $r_k \\in R$ is a scalar that describes the kth interaction"}, {"title": "3 PROBLEM FORMULATION", "content": "Forward.\n$L_{sym} = D^{-\\frac{1}{2}} (A + I)D^{-\\frac{1}{2}}, D = diag([1 + \\sum_j a_{1j}, ..., 1 + \\sum_j a_{Nj}])$    (1)\n$Z = \\sigma(Y + 1\\bar{b}), Y = L_{sym}XW$  (2)\nBackward.\n$\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y} \\frac{\\partial Y}{\\partial X} = L_{sym}W^T$,\n$\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial Y} \\frac{\\partial Y}{\\partial W} = X^T L_{sym}^T \\frac{\\partial L}{\\partial Y}$  (3)"}, {"title": "4 METHODOLOGY", "content": "After social aggregation in Eq.(1) and Eq.(2), $P_1$ obtains the output $Y$ for further computation of the loss $L$. To optimize the model, $P_1$ uses $\\frac{\\partial L}{\\partial X}$ to compute the derivate of node features $X$. We notice that a key computation paradigm, multiplying three matrices, repeatedly appears in both forward and backward processes. Further, if we let the parameter matrix $W$ be kept by $P_2$ that owns $L_{sym}$, the matrices on both sides and the matrix at the middle for each equation will be kept by different parties. In addition, the left-side result of each equation will be only needed by the one that owns the middle matrix. This observation motivates us to consider such a problem\nGiven the matrices $L \\in R^{p \\times q}$, $N \\in R^{r \\times s}$ owned by the party $P_1$ and the matrix $M \\in R^{q \\times r}$ owned by the party p2, how can we design an algorithm to satisfy the two requirements below\nR1. the party $p_2$ obtains the multiplication $J = LMN$ without exposing $M$ to the party $p_1$.\nR2. the party $p_2$ cannot infer $L$ and $N$ from $J$ and $M$.\nAs long as the above problem is solved, the computing processes of a graph convolution operator can be done without leaking data privacy. Therefore, we now focus on how to find a solution to this problem with the theoretical guarantee of privacy-preserving."}, {"title": "4.1 Motivation", "content": "Solution to R1. For the first requirement, each time there is a need to compute $J = LMN$, the party first p2 encrypts the matrix $M$ with the public key $P_{pub,2}$ by simply using Homomorphic Encryption (e.g. Paillier [28]). Then, the ciphertext $[M]_{P_{pub,2}}$ is sent to the party p\u2081 to compute $[J]_{P_{pub,2}} = L[M]_{P_{pub,2}}N$, and the result"}, {"title": "4.2 Sandwich encryption", "content": "Analytic Matrix Gaussian Mechanism [29]). For a function $f(X) \\in R^{m \\times n}$ and a matrix variate $Z \\sim MN_{m,n}(0, \\Sigma_1, \\Sigma_2)$, the analytic Matrix Gaussian Mechanism is defined as\n$\\mathcal{MGM}(f(X)) = f(X) + Z$   (4)\nwhere $MN_{m,n} (0, \\Sigma_1, \\Sigma_2)$ denotes matrix gaussian distribution."}, {"title": "4.2.1 Solution to R1.", "content": "The probability density function for the $m \\times n$ matrix-valued random variable $Z$ which follows the matrix Gaussian distribution $MN_{m,n} (M, \\Sigma_1, \\Sigma_2)$ is\n$Pr(Z|M, \\Sigma_1, \\Sigma_2) = \\frac{\\exp{-\\frac{1}{2}tr[\\Sigma_2^{-1}(Z-M)^T\\Sigma_1^{-1}(Z-M)]}}{(2\\pi)^{mn/2}|\\Sigma_2|^{n/2}|\\Sigma_1|^{m/2}}$    (5)\nwhere $U \\in R^{m \\times m}$ $V \\in R^{n \\times n}$ are invertible matrices and $UU^T = \\Sigma_1$, $VV^T = \\Sigma_2$. $|\\cdot|$ is the matrix determinant and $M \\in R^{m \\times n}$, $\\Sigma_1 \\in R^{m \\times m}$, $\\Sigma_2 \\in R^{n \\times n}$ are respectively the mean, row-covariance, column-covariance matrices.\nThe privacy protection is guaranteed by Lemma.4.4\nLEMMA 4.4 (DP OF AMGM [29]). For a query function f, aMGM satisfies (\u20ac, \u03b4) \u2013 DP, iff\n$\\frac{s_2 (f)}{b} \\leq \\sigma_m (U) \\sigma_n (V)$   (6)\nwhere b is decided by (e, d) and $s^2(f)$ is the L2-sensitivity, $\\sigma_m (U)$ and $\\sigma_n (V)$ are respectively the smallest singular values of U and V.\nThe general procedure of the Sandwich Encryption is listed in Algorithm.1. The encryption process is like making a sandwich where the two pieces of bread are corresponding to the two-side matrices and the middle matrix is the meat in the sandwich as shown in Figure 2. By properly pre-processing the materials, the data privacy of each material can be preserved. While we apply DP to enhance privacy protection, how to preserve the utility of these computing processes as much as possible still brings non-trivial challenges. To this end, we design the Privacy-Preserving Two-Party Graph Convolution Network (P4GCN) to enhance the utility of the model while applying DP."}, {"title": "4.2.2 Solution to R2.", "content": "Overview. The architecture of P4GCN is as shown in Figure 3. During each training iteration, $P_1$ first locally aggregates the user features $X_{user}^{(0)}$ and the item features $X_{item}^{(0)}$ by the backend (e.g., LightGCN[31]) into embeddings $X_{user}^{(1)}$ and $X_{item}^{(1)}$. Then, $P_1$ uses Algo.1 to collaboratively compute the user social embeddings that are aggregated on the social data by the GCN layer with $P_2$. After obtaining the user social embeddings $X_{user}^{(2)}$, $P_1$ uses the fusion layer to aggregate $X_{user}^{(1)}$ and $X_{user}^{(2)}$ together to construct the new user embeddings $X_{user}^{(3)}$. Finally, both $X_{user}^{(3)}$ and $X_{item}^{(1)}$ are input into the decoder to obtain the predictions to compute the loss. The backward computation of the social GCN layer is also protected by Algo.1.\nFusion Layer. The fusion layer is designed for two reasons. For one thing, the DP mechanism may bring too much noise that leads to the degradation of the model performance. For another thing, the social information of different users may not consistently improve the model's performance but harm it. Therefore, we design the fusion layer to adaptively extract useful information by reweighing the inputs. Concretely, the fusion layer allocates weights to each activation in each user's embeddings by a two-layer MLP with a softmax function and position-wisely fuses them. This introduces"}, {"title": "4.3 P4GCN", "content": "Then, the corresponding computing process is\n$Y_B = (B L_{sym})XW, \\frac{\\partial L}{\\partial X_B} = (B L_{sym}^T) \\frac{\\partial L}{\\partial Y_B} W^T$   (10)\nIn this way, the party $P_2$ can store the full ciphertext $[X]$ that will be only encrypted once and batch-wisely update it by $\\frac{\\partial L}{\\partial Y_B}$. Unlike full batch training, the embeddings of users out of the batch cannot be updated. Otherwise, the social interactions will be easily exposed to the recommender."}, {"title": "4.3.1 Architecture.", "content": "Lemma 4.5. [Privacy Loss of aMGM.[30]] The privacy loss variable of aMGM follows gaussian distribution $N(\\eta, 2\\eta)$ and $\\eta$ is given by\n$\\eta = \\frac{||U^{-1} (f(X)-f(X'))V^{-T}||}{2}$   (11)"}, {"title": "4.3.2 Privacy-Preserved Social Aggregation.", "content": "Batch-wise optimization. We now show how to optimize the model in a batch-wise manner for efficiency. The full batch training will bring large communication and computation costs (e.g., frequently encrypting large matrices and transmitting the expanded ciphertext). To tackle this issue, for a batch of records $\\{(u_{b_k}, v_{b_k}, r_{b_k})\\}_{k=1}^{|B|}$ we denote the users in the current batch as $B \\in R^{|B| \\times N}$, $|B| \\leq |B|$"}, {"title": "4.3.3 Efficiency.", "content": "We use four social recommendation datasets to validate the effectiveness of the proposed method: Filmtrust [33], CiaoDVD [34], Douban [35], and Epinions [36]. Specifically, we set the social data owned by P2 and other data owned by P1. We show the statistics of the datasets in Table 2."}, {"title": "5 EVALUATION", "content": "From Table 1, we find that: (1) P4GCN* without DP consistently improves both MAE and RMSE metrics over all the baselines on the first three datasets (i.e., FilmTrust, CiaoDVD, and Douban) and achieves competitive results (e.g., RMSE= 1.0642, MAE=0.8186) against others' optimal results (e.g., RMSELightGCN = 1.0746 and MAENeuMF = 0.8020). (2) Our proposed Sandwich Encryption Module can well preserve the final model performance over four datasets given proper privacy budges, which achieves the optimal or second optimal results over 87.5% columns. (3) P4GCN exhibits superior performance to traditional matrix-decomposition-based social recommendation (e.g., SeSoRec and S3Rec), especially on datasets of large-scale (e.g., CiaoDVD with 7375 clients and Epinions with 22158 clients). We attribute this enhancement to the adaption of GNN which has a stronger representation ability than the traditional matrix-decomposition-based model in recommendation."}, {"title": "5.1 Experimental Setting", "content": "We investigate the impact of privacy budget e on our proposed method in Figure 4, where the red dashed line corresponds to results without leveraging social data and the green dashed line corresponds to the ideal results without adding DP noise. First, as the privacy budget grows properly, P4GCN introduces non-trivial improvements over the results without using"}, {"title": "5.2 Model performance", "content": "We show that existing local recommendation methods (e.g.,, PMF and GCN) without considering social data can benefit from our proposed P4Layer on FilmTrust and CiaoDVD in Table 3, which suggests that companies can improve their local recommendation system by leveraging our proposed P4GCN in a plug-in manner. The parameters of differential privacy are consistent with the settings in Table 1."}, {"title": "5.3 Impact of privacy budget e", "content": "We study the impact of the choice of hyper-parameter \u03b2 on the model performance in Figure 5. We denote P4GCN without adding DP noise as the ideal case (e.g., the red notations). The figure shows that the optimal value of \u03b2 is always larger than 0 across all the datasets, indicating that the recommendation system can consistently benefit from social information integrated by our P4GCN regardless of differential privacy. In addition, the DP noise lowers the optimal degree of leveraging social information (e.g., the blue star never appears on the left of the red star) since the aggregation efficiency can be degraded by the noise. We also notice that a large value of \u03b2 will lead to the degradation of the model performance, which suggests the choice of \u03b2 should be very careful in practice. We consider how to efficiently and adaptively decide effective \u03b2 as our future works."}, {"title": "5.4 Integrate To Existing Methods", "content": "We list the communication costs of P4GCN and another communication-efficient VFL social recommendation method (i.e., S3Rec [13]) in"}, {"title": "5.5 Impact of hyper-parameter \u03b2", "content": "We finally compare our method with FeSog-Ideal which can directly access the full social data to verify the advantage of P4GCN in enhancing recommendation systems with social data. As shown in Figure 6, integrating social data can slightly improve model performance in FeSog when the social data is fully available in most"}, {"title": "5.6 Communication cost", "content": "This paper addresses the development of GNN-based models for a secure social recommendation. We present P4GCN, a novel vertical federated social recommendation approach designed to enhance recommendation accuracy when dealing with inaccessible social data. P4GCN incorporates a sandwich-encryption module, which guarantees comprehensive data privacy during collaborative computing. Experimental results on four datasets demonstrate that P4GCN outperforms state-of-the-art methods in terms of recommendation accuracy. We are considering leveraging other formats of graph information like LLM guidance, and knowledge graph, by P4GCN to enhance recommendation systems in our future works."}, {"title": "5.7 Comparison with FeSog w. social data", "content": "We derive adjacent databases by $A$ and $A'$ where $A'_{km} = 1-A_{km}$. And other elements of the two matrix are the same. The kth row in the $L_{sym}$ of A is $l_k$ (e.g., $l$ for $A'$). Letting $d_j = \\sqrt{||a_j||_1}$, then we have"}, {"title": "6 CONCLUSION", "content": "Given $J = LMN$, $L \\in R^{p\\times q}$, $M \\in R^{q\\times r}$, $N \\in R^{r\\times s}$, we have\n$rank(LM) = rank([LM;J])$   (12)\nNow we consider the equation\n$(L'M)X = J, X \\in R^{r\\times s}, L \\neq L'$   (13)\nAs long as equation (13) is solvable, then we can directly set $N'$ to be the solver $X$, leading to the establishment of $J = L'MN'$. Therefore, to make the equation (13) solvable, we must establish the following equation\n$rank(L'M) = rank([L'M;J])$   (14)\nWithout loss of generality, we denote $L' = L+\\Delta L$. We now introduce a way to choose $L'$ without changing rank($[L'M]$).\n$L'M = LM + \\Delta LM$   (15)"}, {"title": "A DERIVATIONS", "content": "First randomly selects two large prime numbers p and q that satisfy the formula gcd(pq, (p-1) (q\u2212 1)) = 1, and p, q are equal in length. Then we calculate n = pq and x = lcm(p-1, q-1). Second, randomly selection of integer g \u2208 Z* Z2 and define function L as $L(x) = \\frac{x-1}{n}$ and calculate $\\mu = (L (g^{\\lambda} mod n^2))^{-1}$ mod n. Finally, we get private key (n, g) and public key (\u03bb, \u03bc)."}, {"title": "A.1 The derivation of the upper bounds of l2 sensitivity", "content": "During each iteration, the party $P_1$ first inputs the batch data (e.g. the batched users' features $X_{user, B}^{(0)}$ and the items' features $X_{item}^{(0)}$) and the user-item graph into the local aggregation GC layer to obtain $X_{user}^{(1)}$ and $X_{item}^{(1)}$. Then, $P_1$ uses sandwich encryption to make the social aggregation on users' features with $P_2$ to obtain $X_{user, B}^{(2)}$. $P_1$ further fuses the two types of users' embeddings together by the fusion layer. Concretely, for each user $u_i$ in the current batch, its fusion of embeddings is $x_{u_i}^{(3)} = [X_{user,u_i}^{(1)T}, X_{user,u_i}^{(2)T}](W_{fusion,u_i; user} [X_{user,u_i}^{(1)T}; X_{user,u_i}^{(2)T}]) \\in R^{2d}$. Finally, both the items' embeddings $X_{item}^{(1)}$ and the users' embeddings $X_{user, B}^{(3)} = [x_{u_1}^{(3)T},...,x_{u_p}^{(3)T}]$ will be input into the decoder to predict the rating $f_{u,v} = 4*sigmoid(Relu ([X_{user,u}^{(3)T}; X_{item,v}^{(1)}]W_{mlp1} W_{mlp2})$."}, {"title": "A.2 Proof of Theorem 4.1", "content": "Encryption. First input the plaintext m satisfies 0 \u2264 m \u2264 n. Then choose a random number r that satisfies $r \\in Z_n^*$. Finally, we calculate the ciphertext as c = gmrn mod n\u00b2.\nDecryption. Input ciphertext c that satisfies $c \\in Z_{n^2}^*$, and then calculate the plaintext message as $m = L (c^{\\lambda} mod n^2 n^2)^{-1} \\cdot \\mu mod n$"}, {"title": "B THE ARCHITECTURE OF P4GCN", "content": "This work introduces a way to leverage user's social data to improve the recommendation system on the company view. One limitation lies in that we only discuss the method on GCN operator. And we plan to extend this work to other operators like graph attention as our future work."}, {"title": "C HOMOMORPHIC ENCRYPTION", "content": "Paillier is a public-key cryptosystem that supports additive homomorphism [39]. The main steps of the Paillier algorithm are key generation, encryption, and decryption."}, {"title": "C.1 Paillier algorithm", "content": "Key generation. First randomly selects two large prime numbers p and q that satisfy the formula gcd(pq, (p-1) (q\u2212 1)) = 1, and p, q are equal in length. Then we calculate n = pq and x = lcm(p-1, q-1). Second, randomly selection of integer g \u2208 Z* Z2 and define function L as $L(x) = \\frac{x-1}{n}$ and calculate $\\mu = (L (g^{\\lambda} mod n^2))^{-1}$ mod n. Finally, we get private key (n, g) and public key (\u03bb, \u03bc)."}, {"title": "D LIMITATION AND BROADER IMPACT", "content": "This work introduces a way to leverage user's social data to improve the recommendation system on the company view. One limitation lies in that we only discuss the method on GCN operator. And we plan to extend this work to other operators like graph attention as our future work."}]}