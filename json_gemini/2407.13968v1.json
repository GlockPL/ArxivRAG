{"title": "Optimizing Agricultural Order Fulfillment Systems: A Hybrid Tree Search Approach", "authors": ["Pranay Thangeda", "Hoda Helmi", "Melkior Ornik"], "abstract": "Efficient order fulfillment is vital in the agricultural industry, particularly due to the seasonal nature of seed supply chains. This paper addresses the challenge of optimizing seed orders fulfillment in a centralized warehouse where orders are processed in waves, taking into account the unpredictable arrival of seed stocks and strict order deadlines. We model the wave scheduling problem as a Markov decision process and propose an adaptive hybrid tree search algorithm that combines Monte Carlo tree search with domain-specific knowledge to efficiently navigate the complex, dynamic environment of seed distribution. By leveraging historical data and stochastic modeling, our method enables forecast-informed scheduling decisions that balance immediate requirements with long-term operational efficiency. The key idea is that we can augment Monte Carlo tree search algorithm with problem-specific side information that dynamically reduces the number of candidate actions at each decision step to handle the large state and action spaces that render traditional solution methods computationally intractable. Extensive simulations with realistic parameters\u2014including a diverse range of products, a high volume of orders, and authentic seasonal durations\u2014demonstrate that the proposed approach significantly outperforms existing industry standard methods.", "sections": [{"title": "1. Introduction", "content": "The seed supply chain plays a pivotal role in global agricultural business, acting as the cornerstone for both plant breeding programs and agricultural sustainability. The importance of these seed stocks is underscored by the critical need for timely fulfillment of seed orders to meet specific planting windows, often mandated by the seasonal growth cycles of different crops. Failure to meet these strict timelines can lead to a host of downstream issues, including suboptimal crop yields and financial loss [1].\nOrder fulfillment in industries such as e-commerce [2] and retail [3] often involve centralized fulfillment centers that simultaneously process arriving inventory and fulfill orders based on their deadlines. The fulfillment process with large catalogs often handle a batch of orders, hereinafter referred to as wave, together using automated sortation systems [4]. The supply chain in these sectors is typically well-established, with known inventory quantities and deterministic restock times. The problem of optimally scheduling waves to maximize fulfillment efficiency is addressed using traditional operations research and optimization techniques [5], [6] as order deadlines and inventory levels are known a priori or can be forecasted with low uncertainty."}, {"title": null, "content": "However, the seed distribution system presents a unique set of challenges that are not typically encountered in traditional supply chains. The nature of seed development and distribution involves a plethora of seed varieties, each with specific growing conditions and market demands. The perishability and seasonality of seeds make seed supply chains a highly intricate web of moving parts [7], [8]. Complicating matters further, the seed supply chain is inherently stochastic \u2013 the variability in seed yields is influenced by numerous factors including weather conditions, soil quality, environmental factors [9], crop diseases [10], [11], and pest infestations [12], [13].\nTraditional optimization approaches [14], [15], [16] often fall short in pro-viding efficient solutions for seed wave scheduling with stochastic inventory arrivals. For instance, a simple greedy strategy that prioritizes fulfilling orders based on their deadlines and current available inventory can be mis-leading. Such an approach tends to focus on short-term gains, neglecting to consider the stochastic nature of future seed arrivals.\nMarkov Decision Processes (MDPs) [17], [18] serve as a useful framework to approach stochastic decision-making problems. MDPs have been widely applied in a range of domains such as robotics [19], [20], [21], finance [22], [23], and healthcare [24], providing a systematic way to make optimal deci-sions in situations characterized by uncertainty. However, directly applying traditional solution methods such as value iteration [25] and policy iteration [26] to wave scheduling problem with large state and action spaces is compu-tationally intractable due to the curse of dimensionality [27]. Instead, Monte Carlo tree search (MCTS) [28] provides an intelligent tree search method that is effective in large MDPs where exhaustive search is not feasible [29]. However, the size of the search space in the problem of seed order fulfillment poses challenges even for MCTS.\nTo address this challenge, we propose an adaptive hybrid tree search ap-proach that augments MCTS with domain-specific knowledge to efficiently navigate the decision space. The key insight is that we can augment MCTS with additional problem-specific side information to make it tractable for large MDPs. The proposed hybrid tree search method dynamically narrows down the action space by leveraging the information about order deadlines and inventory levels. Our approach is particularly suited for scenarios with large state and action spaces, as it iteratively constructs a practical search tree that helps in exploring the most promising strategies.\nWe validate our approach through extensive experiments, employing a high-fidelity warehouse simulator based on real-world data to showcase its"}, {"title": "2. Preliminaries and Background", "content": "In this section we provide a brief overview of the mathematical structures that form the basis of our approach. We first introduce Markov chains, followed by time-varying Markov chains and Markov decision processes. We begin by defining the notation used in the paper.\nGiven a finite set A, we use |A| to denote the cardinality of the set. Pr[\u00b7] denotes the probability of an event and E[\u00b7] denotes the expectation of a random variable. N denotes the set of natural numbers and [N] for \\(N \\in \\mathbb{N}\\) denotes the set {0, . . ., N \u2212 1}. \\(\\mathbb{I}[.]\\) denotes the indicator function, a function that takes a condition as its argument and returns 1 if the condition is true, and 0 otherwise."}, {"title": "2.1. Markov Chains", "content": "A Markov chain [30] is a stochastic model of transition dynamics defined over a sequence of states to represent systems that follow the Markov prop-erty, i.e., systems in which the state at any given time depends solely on the state at the previous time step. Formally, a finite-state discrete-time Markov chain is defined by:\n\u2022 a finite set \\(S = \\{s_1, s_2, ..., s_n\\}\\), representing all possible states the system can attain, and\n\u2022 a square matrix \\(P \\in [0, 1]^{n \times n}\\), where the entry \\(P_{ij}\\) denotes the proba-bility of transitioning from state \\(s_i\\) to \\(s_j\\)."}, {"title": "2.2. Time-Varying Markov Chains", "content": "Markov chains generally assume stationary transition probabilities, which may not always be suitable for modeling systems where the transition prob-abilities evolve over time [31], [32]. Time-Varying Markov Chains (TVMCs) [33] are a generalization of Markov chains that allow the transition probabil-ities to vary over time.\nA TVMC retains the essential structure of a Markov chain but extends it by making the transition probabilities a function of time t. Formally, instead of a static P, it introduces \\(P_t\\), where \\(P_t(s^i, s^j)\\) is the transition probability from state \\(s^i\\) to \\(s^j\\) at time t, i.e., \\(Pr(s_{t+1} = s' | s_t = s, t) = P_t(s, s')\\)."}, {"title": "2.3. Markov Decision Processes", "content": "Markov Decision Processes (MDPs) [17], [25] generalize Markov chains by introducing actions and rewards, thereby creating a framework for decision-making in stochastic environments. An undiscounted, finite-horizon MDP is formally defined as \\(M(S, A, P, R, H)\\), where:\n\u2022 S denotes the finite state space analogous to that in Markov chains,\n\u2022 A denotes the finite action space, with \\(A(s) \\subset A\\) denoting the set of actions available in state \\(s \\in S\\),\n\u2022 \\(P: S \times A \times S \rightarrow [0, 1]\\) satisfying \\(\\sum_{s' \\in S} P(s' | s, a) = 1\\) for any \\(s \\in S\\) and \\(a \\in A\\) denotes the state transition probability function,\n\u2022 \\(R: S \times A \times S \rightarrow [R_{min}, R_{max}]\\) denotes the bounded reward function, quantifying the immediate reward for each transition,\n\u2022 H is the finite planning horizon for the problem.\nTaking an action \\(a \\in A(s)\\) at a state \\(s \\in S\\) results in a transition to a new state \\(s' \\in S\\) with probability \\(P(s' | s, a)\\) and a reward \\(R(s, a, s')\\). The goal is to maximize the expected sum of rewards over planning horizon H.\nA policy \\(\\pi : S \rightarrow A\\) is a mapping from states to actions such that \\(\\pi(s) \\in A(s)\\) for all \\(s \\in S\\). The state value function of a policy \\(\\pi\\) for a given state s is defined as the expected sum of rewards over the next H time steps, i.e.,\n\\(V_{\\pi}(s) = E \\left[ \\sum_{k=0}^H R(s_k, \\pi(s_k), s_{k+1}) | s_0 = s \right]\\)"}, {"title": null, "content": "The state-action value function, denoted by \\(Q_{\\pi}(s, a)\\), is defined as the expected sum of rewards over the next H time steps, given that the first action is a and the first state is s, i.e.,\n\\(Q_{\\pi}(s, a) = E \\left[ \\sum_{k=0}^H R(s_k, \\pi(s_k), s_{k+1}) | s_0 = s, \\pi(s_0) = a \right]\\)\nThe optimal policy \\(\\pi^*\\) is one that maximizes \\(V_{\\pi^*}(s)\\) irrespective of the initial state, i.e., \\(V_{\\pi^*}(s) \\ge V_{\\pi}(s)\\) for all \\(s \\in S\\).\nIn the next section, we define the seed processing warehouse scheduling problem and formalize the problem statement."}, {"title": "3. Problem Formulation", "content": "We consider the setting of a warehouse processing incoming inventory of different products to fulfill orders made up of one or more products before fulfillment deadlines known a priori. The incoming inventory is arranged into intermediate containers, which are fixed size storage containers. The warehouse utilizes an automated sorter system [4] that can process a batch of orders, hereinafter referred to as wave, using accumulation chutes temporarily assigned to individual orders. Processing a wave requires human pickers to pick the required items from intermediate containers at the sorter's induction stations and place them on the sorter's circulation loop.\nSeveral existing approaches in the literature consider different objectives for optimally scheduling the orders in waves [5], [6], [34], [35]. These ap-proaches assume that the order information and deadlines are available along with the inventory required to fulfill these orders. This assumption, however, is unrealistic in our setting where the inventory arrives over the duration of entire season as the harvesting progresses with no prior knowledge of the incoming inventory's distribution [36].\nFormally, let T represent the total number of discrete time steps in the planting season, each with a duration of \\(\\Delta t\\). Consider a set of products \\(P = \\{p_1, p_2, ..., p_{n_p}\\}\\) in the catalog. We assume that the quantity of each product replenished in the inventory at any time step is stochastic and unknown a priori. As a consequence, the total incoming quantity of all products is"}, {"title": null, "content": "stochastic. Let \\(q_t^p \\in \\mathbb{Z}\\) denote the quantity of product p that arrived at time step t.\nLet \\(n_c\\) denote the capacity of each intermediate container. Let \\(C_t\\) denote the set of all intermediate containers arriving at time t. Let \\(c_i^p\\) denote the quantity of product p in intermediate container i arriving at time t. We note that the total quantity of all products in an intermediate container is less than or equal to the capacity of the intermediate container, i.e., \\(\\sum_{p \\in P} c_i^p \\le n_c\\). Also, the total number of items of a product p in all the intermediate containers arriving at time t is equal to the quantity of product p arriving at time t, i.e., \\(\\sum_{i \\in C_t} c_i^p = q_t^p\\). The number of intermediate containers arriving at time t, i.e., \\(|C_t|\\), can be calculated as \\(|C_t| = \\lceil \\frac{\\sum_{p \\in P} q_t^p}{n_c} \rceil\\).\nLet O denote the set of orders, \\(O = \\{o_1, o_2, ..., o_{n_o}\\}\\), where each order \\(o_i\\) is defined by the quantities of each product needed, \\(b_i^p\\) for \\(p \\in P\\), and the deadline \\(d_i\\). All orders in O are of the same size \\(n_b\\), i.e., \\(\\sum_{p \\in P} b_i^p = n_b\\) for all \\(i \\in [n_o]\\). Let \\(n_w\\) denote the wave capacity, i.e., the number of orders processed in a single wave. Assuming all the items required to fulfill orders in a wave are available, the time taken to fulfill a wave is proportional to the number of intermediate containers accessed by the pickers to fulfill the orders in that wave.\nIn order to handle situations where it is not feasible to satisfy all order deadlines, we introduce a pre-emptive processing parameter, \\(\\alpha\\), ranging from 0.5 to 1. The parameter \\(\\alpha\\) indicates the required proportion of available"}, {"title": null, "content": "items in an order relative to the total number of items for initiating process-ing. Importantly, the preemptive processing is reserved for the last feasible opportunity to process an order without missing its deadline. For instance, if \\(\\alpha\\) is 0.5, order processing is triggered only when at least half of the items are available and processing at this point is the only way to avoid missing the deadline. This approach ensures the timely, albeit partial, fulfillment of orders, aligning closely with their respective deadlines.\nLet \\(f_i\\) denote the time step when an order \\(o_i\\) is fulfilled. Let W denote the set of all waves in the season, and let \\(w = (w_{1,1}, w_{2,1}, ..., w_{n_o,1}, ..., w_{n_o,|W|})\\) denote the decision variables where \\(w_{i,j} = 1\\) if order \\(o_i\\) is processed in wave j and \\(w_{i,j} = 0\\) otherwise. Given these definitions, the problem can be formu-lated as follows:\nProblem Formulation (Wave Scheduling Problem)\nGiven a set of orders and incoming inventory in a warehouse setting, minimize the total delay across all orders, defined as\n\\(\\min_W D = \\sum_{i=1}^{n_o} \\max(0, f_i(w, \\alpha) - d_i) \\hspace{1cm} (1)\\)\nwhile satisfying the constraints ensuring that the required inventory is available to fulfill the orders, complete and preempted, at the beginning of each wave, each order is assigned to exactly one wave, and the number of orders in a wave is less than or equal to the wave capacity.\nIn this formulation, for each order \\(o_i\\), we calculate the delay as the dif-ference between the time step when it was fulfilled \\(f_i\\) and its deadline \\(d_i\\). If an order is fulfilled before its deadline, the difference \\(f_i - d_i\\) will be less than or equal to zero, and we consider its contribution to the total delay as zero. Only when \\(f_i - d_i\\) is greater than zero (i.e., the order is fulfilled after its deadline), it contributes to the total delay.\nThe stochastic nature of inventory arrivals render conventional operations research and optimization techniques inadequate for our problem. In the next section, we discuss our approach that provides an efficient, approximate solution to the problem using a combination of historical data, stochastic modeling, domain knowledge, and tree search methods."}, {"title": "4. Solution Methodology", "content": "This section describes our approach to solving the wave scheduling prob-lem. We begin by discussing the data available to us and the challenges of modeling the stochasticity in product arrivals. We then describe our ap-proach to modeling the problem as a Markov Decision Process (MDP) and discuss the challenges of solving such an MDP at scale. Finally, we propose a novel hybrid tree search approach to overcome these challenges and provide an efficient solution to the wave scheduling problem."}, {"title": "4.1. Stochastic Modeling of Product Arrival Distributions", "content": "Consider the historical data depicting the quantity of each product ar-riving at various times across seasons. Let \\(m_p\\) denote the number of seasons with historical data for a given product p. The quantity of product p ar-riving at time t in the i-th season can be denoted as \\(h_{p,t}^i\\) where \\(i \\in [1, m_p]\\). We note that \\(m_p\\) can vary across products, particularly when they have been introduced to the market at different times.\nGiven the historical data, the total quantity for product p during sea-son i is \\(\\sum_{t=1}^T h_{p,t}^i\\). We normalize these quantities as \\(h_{p,t}^{i'} = \\frac{h_{p,t}^i}{\\sum_{t=1}^T h_{p,t}^i} \times 1000\\).\nSubsequently, we round \\(h_{p,t}^{i'}\\) to the nearest integer. This transformation stan-dardizes historical quantities for each product p into a uniform integer range of 0 to 1000. This range ensures that the problem is computationally feasible while maintaining a sufficient resolution to capture the details in incoming inventory distribution.\nTime-Varying Markov Chain Model\nTo model the product arrival dynamics in the current season, we use a time-varying Markov chain for the cumulative quantity of each product p. The state space S consists of integers from 0 to 1000, \\(S = \\{0, 1, 2, ..., 1000\\}\\). Transition probabilities for each product p are dictated by \\(P_{p,t}\\), a time-dependent transition probability matrix. We determine \\(P_{p,t}\\) based on his-torical data.\nLet \\(E_t^j(s \rightarrow s')\\) represent the transition from state s at time t \u2212 1 to state s' at time t during the j-th season for product p. Similarly, let \\(E_t^j(s)\\) be the event that the state at time t \u2212 1 was s. The transition probability is then given by \\(P_{p,t}(s, s') = \\frac{\\# (E_t^j(s \rightarrow s'))}{\\sum_{s \\in S} \\# (E_t^j(s))}\\) where \\( \\# (E_t^j(s \rightarrow s'))\\) denotes"}, {"title": null, "content": "the number of times the event \\(E_t^j(s \rightarrow s')\\) occurred and \\(\\# (E_t^j(s))\\) denotes the number of times the event \\(E_t^j(s)\\) occurred."}, {"title": "4.2. Wave Scheduling Problem as a Markov Decision Process", "content": "We model the wave scheduling problem as a Markov Decision Process (MDP) to enable sequential decision-making while accounting for the prod-uct arrival uncertainty. Formally, the MDP model \\(M = (S, A, P, R, H)\\) is defined as follows:\nState Space\nTo efficiently schedule the orders in waves, the state of the system which forms the basis for decisions must capture all the relevant information. The current inventory levels of all products dictate the feasibility of fulfilling orders in the planned wave. Furthermore, the time step and order deadlines are essential for both assessing and modeling the time-varying stochasticity of product arrivals. Accordingly, each state in the state space S, represented as \\(s = (q^1, q^2, ..., q^{n_p}, d^1, d^2, ..., d^{n_o}, t)\\), captures the current inventory levels of all products in the catalog, the deadlines, and the time step \\(t \\in [T]\\)."}, {"title": "Action Space", "content": "At each decision step, the agent must decide which orders to process in the wave. The action space A, therefore, is the set of all possible waves of orders that can be processed. The set of available actions at state s, \\(A_s \\subseteq A\\), depends on s as the order feasibility is constrained by the available quantities of each product. Any action \\(a \\in A_s\\) represents a feasible wave of orders \\(O_a\\), i.e., \\(\\sum_{o_i \\in O_a} b_i^p \\le q^p\\) for any product p that is a part of the orders \\(O_a\\).\nTransition Probability Function\nThe transition probability function P models how the system transitions from one state to another given an action. In the case of wave scheduling, after fulfilling the set of orders in a selected action, the system transitions to a new state based on the deterministic, known quantities of products consumed to fulfill the wave, the time taken to execute the wave, and the stochastic replenishment of inventory.\nFormally, let \\(T_a\\) denote the random variable that represents the time taken"}, {"title": null, "content": "to execute an action a and let \\(Q_t^p\\) denote the random variable that represents the stochastic replenished quantity of product p between time steps t and t'. For notational convenience, let D denote the set of all deadlines in the state space. Further, recall that the total quantity of product p consumed by fulfill-ing orders \\(O_a\\) specified by action a is given by \\(\\sum_{o_i \\in O_a} b_i^p\\). Then, given a state \\(s_k = (q_k^1, q_k^2, ..., q_k^{n_p}, D, t_k)\\) and an action \\(a_{k+1}\\) at decision step k, the proba-bility of transitioning to a new state \\(s_{k+1} = (q_{k+1}^1, q_{k+1}^2, ..., q_{k+1}^{n_p}, D, t_{k+1})\\) is given by\n\\(P(s_{k+1} | s_k, a_{k+1}) = Pr(q_{k+1}^1, q_{k+1}^2, ..., q_{k+1}^{n_p}, D, t_{k+1} | q_k^1, q_k^2, ..., q_k^{n_p}, D, t_k, a_{k+1})\\),\nwhich can be further decomposed as follows:\n\\(P(s_{k+1} | s_k, a_{k+1}) = Pr(T_{a_{k+1}} = t_{k+1} - t_k) \times \\prod_{p \\in P} Pr(Q_{t_k}^{t_{k+1}} = q_{k+1}^p - (q_k^p - \\sum_{o_i \\in O_a} b_i^p)).\\)\nThe distribution of the quantity replenished for each product \\(Q_{t_k}^{t_{k+1}}\\) is de-termined by the time-varying Markov chain model discussed in Section 4.1 and the distribution of \\(T_{a_{k+1}}\\) is established using empirical data specific to the configuration of the sortation system.\nNote that we use t to indicate a time step in the discretized season dura-tion, which is distinct from the decision step k in the MDP. The decision step k in the MDP is the instant at which the agent takes k-th action in the se-quential decision-making process."}, {"title": "Reward Function", "content": "The objective of the wave scheduling problem is to ensure that all the orders are fulfilled before deadline, and in cases where this is not possible, to minimize the delay. We design the reward function R to reflect this objective.\n\\(R(s, a, s')\\) specifies the immediate reward for taking action a in state s and transitioning to s'. We calculate the reward as the number of orders met before their deadlines minus a penalty for the late orders proportional to the delay, weighted by a factor \\(\\lambda > 0\\):\n\\(R(s, a, s') = \\sum_{o_i \\in O_a} \\mathbb{I}[f_i \\le d_i] - \\lambda \\sum_{o_i \\in O_a} \\max(0, f_i - d_i)\\)\nWe now proceed to discuss the challenges of solving the above MDP formulation in practice."}, {"title": "Challenges of Solving the Wave Scheduling MDP", "content": "Existing methods for solving an MDP M, given known transition prob-abilities P and a reward function R, include dynamic programming-based approaches, deep learning-based techniques, and tree search methods that learn through interactions from a simulator of system dynamics. However, applying these algorithms to the wave scheduling MDP is challenging for the following reasons:\nLarge State and Action Spaces. In real-world wave planning problems, the substantial size of the state and action spaces presents significant computa-tional challenges. The state space S in the wave scheduling MDP consists of all possible combinations of product quantities and the time step, with a cardinality of \\(|S| = \\prod_{p \\in P} (q^p + 1) \times T\\). The action space at each state, \\(A_s\\), includes all feasible waves based on the available product quantities, pend-ing orders, and their deadlines. The size of the complete action space A is \\(|A| = \\sum_{s \\in S} |A_s|\\), which is exponential in the number of products and orders.\nFor dynamic programming based approaches like value iteration, the com-putational complexity of each iteration is quadratic in the size of the state space and linear in the size of the action space which for the wave-scheduling problem translates to \\(O \\left( \\prod_{p \\in P} (q_{max}^p + 1) \times T \times \\sum_{s \\in S} |A_s| \right)\\), rendering dy-namic programming approaches intractable for our problem. Similarly, tree search methods like MCTS are also computationally infeasible due to the large branching factor of the tree associated with large action spaces. Al-though deep learning-based approaches offer greater scalability by generaliz-ing performance across state and action spaces, they necessitate a compact representation of the state space and an extensive dataset encompassing the entire action space, which is impractical in our context.\nImperfect Transition Model. The stochastic arrival of products is modeled us-ing time-varying Markov chains, with associated transition probability ma-trix estimated from historical data, as discussed in Section 4.1. However, the transition probability models are often susceptible to inaccuracies due to the lack of sufficient historical data, the presence of outliers, and the in-herent stochasticity of the crop harvest dynamics. This imposes additional challenges on dynamic programming based approaches since each iteration might require recalculating the value function, exacerbating the already high computational cost."}, {"title": "4.3. Adaptive Hybrid Tree Search for Wave Scheduling", "content": "To overcome the computational challenges inherent in solving the wave scheduling problem, we propose a hybrid approach that combines domain knowledge with tree search methods. The central idea of our approach is to combine the intelligent tree search and anytime properties of general Monte Carlo Tree Search (MCTS) with domain-specific knowledge to dynamically curate a narrowed-down action space at each state to increase the likelihood of identifying promising actions under practical computational constraints.\nIn rest of this section, we delve into specifics of our approach, structured into three main components. Firstly, we present our approach to identifying and refining the feasible orders into a set of candidate orders. Next, we outline our method for constructing a practical and effective set of wave actions from the narrowed-down set of candidate orders. Finally, we elaborate on how we adapt MCTS algorithm in the context of our problem to parallely learn dynamic parameters that guide action set reduction process and tree search.\nCandidate Order Set Selection\nAt any decision step in an episode, let \\(O_{uf}\\) denote the set of unfulfilled but feasible orders, i.e., orders that have not been fulfilled but can be ful-filled given the current inventory levels. In order to reduce the action space size, we generate two subsets \\(O_{df}^*\\) and \\(O_{lf}^*\\) from \\(O_{uf}\\). We select orders for \\(O_{df}^*\\) based on the ascending deadline order while ensuring that orders past their deadlines do not account for more than a predetermined proportion of the total number of orders in \\(O_{df}^*\\). For \\(O_{lf}^*\\), we first calculate the peak of unfulfilled order deadlines, i.e., the time step at which the maximum number of orders are unfulfilled, and select orders based on their proximity to this peak. We constrain \\(|O_{df}^*| \\le 2n_w\\), \\(|O_{lf}^*| \\le 2n_w\\), and \\(O_{lf}^* \\cap O_{lf}^*| = \\emptyset\\). The in-tuition is that \\(O_{df}^*\\) prioritizes orders with earlier deadlines, while \\(O_{lf}^*\\) focuses on orders likely to cause bottlenecks due to deadlines clustering around the peak. This decomposition attempts to balance urgency of individual orders against long-term risk of developing system-wide bottlenecks.\nTo construct the candidate order set \\(O_c\\) of size \\(2n_w\\), we introduce a dy-namic parameter called the peak reducing factor \\(\rho \\in [0, 1]\\). The value of \\(\rho\\) varies based on tree search evaluation outcomes from previous rounds; de-tails on how \\(\rho\\) adapts are provided in later sections. \\(\rho\\) adaptively adjusts the"}, {"title": null, "content": "proportion of orders selected from \\(O_{df}^*\\) and \\(O_{lf}^*\\) while ensuring a minimum number from each set. \\(O_c\\) consists of the first \\(2n_w \rho\\) orders from \\(O_{df}^*\\) and the first \\(2n_w (1 - \rho)\\) orders from \\(O_{lf}^*\\). When \\(|O_{df}^*| < 2n_w \rho\\), we add the remaining orders from \\(O_{lf}^* \\) to \\(O_c\\), and conversely, when \\(|O_{lf}^*| < 2n_w (1 - \rho)\\), we add the remaining orders from \\(O_{lf}^* \\) to \\(O_c\\).\nAction Set Generation\nWhile \\(O_c\\) provides a reduced set of candidate orders, generating an appro-priate and computationally tractable set of wave actions remains a challenge. Given that the size of \\(O_c\\) is \\(2n_w\\), the combinatorial possibilities yield \\(\\frac{(2n_w)!}{(n_w!)^2}\\) candidate waves for the action space. The action set for our tree search must be manageable in size, only contain waves that are feasible at currently in-ventory levels, and filled with actions likely to be beneficial for maximizing our reward.\nWe adopt a two-step approach to generate the action set. First, we con-struct a set of feasible candidate waves by incrementally adding randomly selected orders from \\(O_c\\) that ensure wave feasibility until the size of the set reaches wave capacity \\(n_w\\). Next, we calculate the estimated fulfillment time of each candidate wave and select a predetermined number of waves with the lowest estimated fulfillment time. While this approach may not always yield the optimal set of candidate actions, it provides a computationally tractable way to generate the action set which is critical for our tree search algorithm that involves simulating multiple rollouts from each action.\nAdaptive Tree Search\nIn this section we discuss how we use the proposed adaptive hybrid tree search algorithm to solve the wave scheduling problem. Our approach closely follows the steps involved in Upper Confidence Bound for Trees (UCT) [28] variant of MCTS with the modifications that we proposed in the previous sections. We begin with a brief overview of UCT algorithm and then proceed to discuss our approach to adapt it for the wave scheduling problem.\nMCTS involves iteratively building a search tree to identify the best pos-sible action to execute at the root node. It consists of four steps: (i) selection, (ii) expansion, (iii) simulation, and (iv) backpropagation. The tree starts as a single node, representing the current state. At each iteration, in the selec-tion step, the algorithm starts at the root and moves down the tree according to a tree policy until it reaches a leaf node. Then, if the leaf node is not a"}, {"title": null, "content": "terminal state, the expansion step adds a child node to the tree, represent-ing possible next state, by taking an action. The simulation step simulates a random rollout from a newly expanded node until it reaches a terminal state, resulting in a sequence of rewards. Finally, the backpropagation step propagates these reward values back up the tree, updating the state-action value estimate Q(s, a) and visit count of each node it traversed on the way.\nThe UCT algorithm proposed the following tree policy to effectively bal-ance between exploring new states and exploiting known, valuable states:\n\\(\\pi_{tree}(s) = \text{arg max}_{a \\in A} \\left[ \\hat{Q}(s, a) + c \\sqrt{\\frac{\\log \\#(s)}{\\#(s, a)}} \right]\\),\nwhere \\(\\hat{Q}(s, a)\\) is the current estimate of state-action value, #(s) is the visit count of state s, #(s, a) is the visit count of state-action pair (s, a), and c is a constant that controls the amount of exploration.\nIn the context of the wave scheduling problem, at each decision step where we need to select an action, we initiate a tree with the root node representing the current state that encapsulates information about the current inventory levels of all products and the current time step. Then, we generate the action set on the go at each state and use the UCT tree policy to select the action to execute until we reach a leaf node and then expand the tree. We then simulate a rollout from the newly expanded node until we reach a terminal state, randomly selecting actions from generated reduced action sets at each state. Finally, we backpropagate the reward obtained from the rollout that depends on the number of orders that were fulfilled before their deadline and that missed their deadline. We perform iterations for a fixed time budget that depends on the wave completion time in the real system, and then execute the recommended action from the tree with the highest estimated state-action value at the root node in the warehouse. In order to execute the selected wave, we select the smallest set of available intermediate containers that contain all the products required to fulfill the orders in the wave and move them to the induction station of the sortation system. Note that this recommended action is the only action (wave) that is executed in the real sortation system. Once the wave is executed in the real system and transitions to the next state, we repeat the above steps before taking the next action. Algorithm 1 summarizes our approach to solving the wave scheduling MDP using UCT and selective action spaces.\nThe adaptive hybrid tree search approach provides a tractable way to"}, {"title": "5. Experiments and Results", "content": "In this section, we present the results of our experiments comparing the baseline 'greedy' approach and the proposed approach. We begin with a description of our experimental setup, baseline policy, and then proceed to discuss the results."}, {"title": "5.1. Experimental Setup", "content": "We conduct our experiments in a simulation environment designed to replicate the operational dynamics of a real-world centralized seed processing facility. While the simulated facility information is not publicly accessible, we expect the results to be consistent on any simulator that can model the problem. The simulator accurately models the core components of the warehouse operations, including inventory management, order processing, and the automated sortation system. The environment is parameterized to align closely with real-world data, ensuring the relevance and applicability of our findings.\nWe consider a season duration of 90 days which is consistent with typical seed distribution season lengths. The time step size is set to 1 minute to capture the fine-grained information in the sortation system. As discussed in Section 3, the sortation system receives the inventory in intermediate containers. We consider intermediate containers with a capacity of 250 items and assume that the facility has sufficient capacity to accommodate all the intermediate containers. The sortation system has 30 induction stations and 400 chutes, which restricts the maximum number of orders processed in a wave also to 400. An order is fulfilled when all the items in the order reach a designated chute and a wave ends only when all of its orders are fulfilled.\nThe experiment simulates 200 products in the catalog, each with a unique arrival distribution over the season. The quantity of each product arriving over the season is consistent with the quantity needed to fulfill the all the"}, {"title": "5.2. Baseline Approach", "content": "As a baseline, we employ a greedy heuristic approach to allocate products to orders that is commonly used in real-world scheduling problems due to its"}, {"title": "5.3. Results and Discussion", "content": "In this section, we present the results of our experiments comparing the baseline approach and the proposed approach. In order to account for the stochasticity in the product arrival distribution and order contents, we sim-ulate each approach 30 times with different random seeds and report the average results. Further, to ensure a fair comparison, we use the same set of"}, {"title": "6. Conclusion and Future Work", "content": "In this paper, we introduced an adaptive hybrid tree search algorithm to address the stochastic wave scheduling problem, with a particular focus on order fulfillment in the agricultural domain. The method synergistically blends Monte Carlo tree search with domain-specific knowledge to provide a computationally tractable solution to our problem with large state and action spaces. Our approach outperforms the baseline greedy approach in terms of order fulfillment efficiency, demonstrating its effectiveness in manag-ing complex agricultural sortation systems. The flexibility of our approach extends beyond seed order fulfillment, making it a versatile solution that can be adapted to a wide range of problems in order fulfillment and other domains that involve sequential decision-making under uncertainty.\nWhile this paper develops the framework for fulfillment under stochastic inventory conditions, much work remains to be done in adapting to unex-pected events, such as equipment malfunctions or sudden shifts in demand. Another possible area of future work is handling the interplay between the wave scheduling policy and the inventory management policy that creates products from raw material inventory. Relevant further study also includes developing hierarchical policies that plan in the space of order scheduling primitives instead of individual orders."}]}