[{"title": "Optimizing Agricultural Order Fulfillment Systems: A Hybrid Tree Search Approach", "authors": ["Pranay Thangeda", "Hoda Helmi", "Melkior Ornik"], "abstract": "Efficient order fulfillment is vital in the agricultural industry, particularly due to the seasonal nature of seed supply chains. This paper addresses the challenge of optimizing seed orders fulfillment in a centralized warehouse where orders are processed in waves, taking into account the unpredictable arrival of seed stocks and strict order deadlines. We model the wave scheduling problem as a Markov decision process and propose an adaptive hybrid tree search algorithm that combines Monte Carlo tree search with domain-specific knowledge to efficiently navigate the complex, dynamic environment of seed distribution. By leveraging historical data and stochastic modeling, our method enables forecast-informed scheduling decisions that balance immediate requirements with long-term operational efficiency. The key idea is that we can augment Monte Carlo tree search algorithm with problem-specific side information that dynamically reduces the number of candidate actions at each decision step to handle the large state and action spaces that render traditional solution methods computationally intractable. Extensive simulations with realistic parameters\u2014including a diverse range of products, a high volume of orders, and authentic seasonal durations\u2014demonstrate that the proposed approach significantly outperforms existing industry standard methods.", "sections": [{"title": "1. Introduction", "content": "The seed supply chain plays a pivotal role in global agricultural business, acting as the cornerstone for both plant breeding programs and agricultural sustainability. The importance of these seed stocks is underscored by the critical need for timely fulfillment of seed orders to meet specific planting windows, often mandated by the seasonal growth cycles of different crops. Failure to meet these strict timelines can lead to a host of downstream issues, including suboptimal crop yields and financial loss [1]."}, {"title": "2. Preliminaries and Background", "content": "In this section we provide a brief overview of the mathematical structures that form the basis of our approach. We first introduce Markov chains, followed by time-varying Markov chains and Markov decision processes. We begin by defining the notation used in the paper.\nGiven a finite set A, we use |A| to denote the cardinality of the set. Pr[\u00b7] denotes the probability of an event and E[\u00b7] denotes the expectation of a random variable. N denotes the set of natural numbers and [N] for N\u2208 N denotes the set {0, . . ., N \u2212 1}. I[.] denotes the indicator function, a function that takes a condition as its argument and returns 1 if the condition is true, and 0 otherwise."}, {"title": "2.1. Markov Chains", "content": "A Markov chain [30] is a stochastic model of transition dynamics defined over a sequence of states to represent systems that follow the Markov property, i.e., systems in which the state at any given time depends solely on the state at the previous time step. Formally, a finite-state discrete-time Markov chain is defined by:\n\u2022 a finite set S = {s1,s2,...,s"}, "representing all possible states the system can attain, and\n\u2022 a square matrix P\u2208 [0, 1]n\u00d7n, where the entry Pij denotes the probability of transitioning from state si to si."]}, {"title": "2.2. Time-Varying Markov Chains", "content": "Markov chains generally assume stationary transition probabilities, which may not always be suitable for modeling systems where the transition probabilities evolve over time [31], [32]. Time-Varying Markov Chains (TVMCs) [33] are a generalization of Markov chains that allow the transition probabilities to vary over time.\nA TVMC retains the essential structure of a Markov chain but extends it by making the transition probabilities a function of time t. Formally, instead of a static P, it introduces Pt, where Pt(si, si) is the transition probability from state si to si at time t, i.e., Pr(st+1 = s'|st = s,t) = Pt(s, s')."}, {"title": "2.3. Markov Decision Processes", "content": "Markov Decision Processes (MDPs) [17], [25] generalize Markov chains by introducing actions and rewards, thereby creating a framework for decision-making in stochastic environments. An undiscounted, finite-horizon MDP is formally defined as M(S, A, P, R, H), where:\n\u2022 S denotes the finite state space analogous to that in Markov chains,\n\u2022 A denotes the finite action space, with A(s) \u2282 A denoting the set of actions available in state s \u2208 S,\n\u2022 P:S\u00d7A\u00d7S \u2192 [0, 1] satisfying \u2211s'\u2208S P(s'|s, a) = 1 for any s \u2208 S and a \u2208 A denotes the state transition probability function,\n\u2022 R:S\u00d7A\u00d7 S \u2192 [Rmin, Rmax] denotes the bounded reward function, quantifying the immediate reward for each transition,\n\u2022 H is the finite planning horizon for the problem.\nTaking an action a \u2208 A(s) at a states \u2208 S results in a transition to a new state s' \u2208 S with probability P(s'|s, a) and a reward R(s, a, s'). The goal is to maximize the expected sum of rewards over planning horizon H. A policy \u03c0 :S \u2192 A is a mapping from states to actions such that \u03c0(s) \u2208 A(s) for all s \u2208 S. The state value function of a policy for a given state s is defined as the expected sum of rewards over the next H time steps, i.e.,\nVH(s) = E[\u2211k=0^H R(sk, \u03c0(sk), sk+1) |s0=s]."}, {"title": "3. Problem Formulation", "content": "We consider the setting of a warehouse processing incoming inventory of different products to fulfill orders made up of one or more products before fulfillment deadlines known a priori. The incoming inventory is arranged into intermediate containers, which are fixed size storage containers. The warehouse utilizes an automated sorter system [4] that can process a batch of orders, hereinafter referred to as wave, using accumulation chutes temporarily assigned to individual orders. Processing a wave requires human pickers to pick the required items from intermediate containers at the sorter's induction stations and place them on the sorter's circulation loop.\nSeveral existing approaches in the literature consider different objectives for optimally scheduling the orders in waves [5], [6], [34], [35]. These approaches assume that the order information and deadlines are available along with the inventory required to fulfill these orders. This assumption, however, is unrealistic in our setting where the inventory arrives over the duration of entire season as the harvesting progresses with no prior knowledge of the incoming inventory's distribution [36].\nFormally, let T represent the total number of discrete time steps in the planting season, each with a duration of \u0394t. Consider a set of products P = {P1, P2,..., Pnp } in the catalog. We assume that the quantity of each product replenished in the inventory at any time step is stochastic and unknown a priori. As a consequence, the total incoming quantity of all products is stochastic. Let q_t^p \u2208 Z denote the quantity of product p that arrived at time step t."}, {"title": "Problem Formulation (Wave Scheduling Problem)", "content": "Given a set of orders and incoming inventory in a warehouse setting, minimize the total delay across all orders, defined as\nminW D = \u2211i=1^no max(0, fi(w, \u03b1) \u2013 di)  (1)\nwhile satisfying the constraints ensuring that the required inventory is available to fulfill the orders, complete and preempted, at the beginning of each wave, each order is assigned to exactly one wave, and the number of orders in a wave is less than or equal to the wave capacity.\nIn this formulation, for each order oi, we calculate the delay as the difference between the time step when it was fulfilled fi and its deadline di. If an order is fulfilled before its deadline, the difference fi \u2013 di will be less than or equal to zero, and we consider its contribution to the total delay as zero. Only when fi \u2013 di is greater than zero (i.e., the order is fulfilled after its deadline), it contributes to the total delay.\nThe stochastic nature of inventory arrivals render conventional operations research and optimization techniques inadequate for our problem. In the next section, we discuss our approach that provides an efficient, approximate solution to the problem using a combination of historical data, stochastic modeling, domain knowledge, and tree search methods."}, {"title": "4. Solution Methodology", "content": "This section describes our approach to solving the wave scheduling problem. We begin by discussing the data available to us and the challenges of modeling the stochasticity in product arrivals. We then describe our approach to modeling the problem as a Markov Decision Process (MDP) and discuss the challenges of solving such an MDP at scale. Finally, we propose a novel hybrid tree search approach to overcome these challenges and provide an efficient solution to the wave scheduling problem."}, {"title": "4.1. Stochastic Modeling of Product Arrival Distributions", "content": "Consider the historical data depicting the quantity of each product arriving at various times across seasons. Let mp denote the number of seasons with historical data for a given product p. The quantity of product p arriving at time t in the i-th season can be denoted as h_t^(p,i) where i \u2208 [1, mp]. We note that mp can vary across products, particularly when they have been introduced to the market at different times.\nGiven the historical data, the total quantity for product p during season i is \u2211t=1^T h_t^(p,i). We normalize these quantities as h_t^(p,i) = (h_t^(p,i))/(\u2211t=1^T h_t^(p,i)) \u00d7 1000.\nSubsequently, we round h_t^(p,i) to the nearest integer. This transformation standardizes historical quantities for each product p into a uniform integer range of 0 to 1000. This range ensures that the problem is computationally feasible while maintaining a sufficient resolution to capture the details in incoming inventory distribution."}, {"title": "Time-Varying Markov Chain Model", "content": "To model the product arrival dynamics in the current season, we use a time-varying Markov chain for the cumulative quantity of each product p. The state space S consists of integers from 0 to 1000, S = {0, 1, 2, . . ., 1000}. Transition probabilities for each product p are dictated by Pp,t, a time-dependent transition probability matrix. We determine Pp,t based on historical data.\nLet Et(s\u2192 s') represent the transition from state s at time t - 1 to state s' at time t during the j-th season for product p. Similarly, let Et(s) be the event that the state at time t - 1 was s. The transition probability is then given by Pp,t(s, s') = (#(Et^(m_p) (s\u2192 s')))/(\u2211s\u2032(#(Et^(m_p) (s)))) where #(Et(s \u2192 s')) denotes"}, {"title": "4.2. Wave Scheduling Problem as a Markov Decision Process", "content": "We model the wave scheduling problem as a Markov Decision Process (MDP) to enable sequential decision-making while accounting for the product arrival uncertainty. Formally, the MDP model M = (S,A,P,R, H) is defined as follows:"}, {"title": "State Space", "content": "To efficiently schedule the orders in waves, the state of the system which forms the basis for decisions must capture all the relevant information. The current inventory levels of all products dictate the feasibility of fulfilling orders in the planned wave. Furthermore, the time step and order deadlines are essential for both assessing and modeling the time-varying stochasticity of product arrivals. Accordingly, each state in the state space S, represented as s = (q1, q2, ..., qnp, d1, d2, ..., dn_o, t), captures the current inventory levels of all products in the catalog, the deadlines, and the time step t\u2208 [T]."}, {"title": "Action Space", "content": "At each decision step, the agent must decide which orders to process in the wave. The action space A, therefore, is the set of all possible waves of orders that can be processed. The set of available actions at state s, As \u2286 A, depends on s as the order feasibility is constrained by the available quantities of each product. Any action a \u2208 As represents a feasible wave of orders Oa, i.e., \u2211oi\u2208Oa b_i^p \u2264 q^p for any product p that is a part of the orders Oa."}, {"title": "Transition Probability Function", "content": "The transition probability function P models how the system transitions from one state to another given an action. In the case of wave scheduling, after fulfilling the set of orders in a selected action, the system transitions to a new state based on the deterministic, known quantities of products consumed to fulfill the wave, the time taken to execute the wave, and the stochastic replenishment of inventory.\nFormally, let Ta denote the random variable that represents the time taken to execute an action a and let Qt,t\u2032^p denote the random variable that represents the stochastic replenished quantity of product p between time steps t and t\u2032. For notational convenience, let D denote the set of all deadlines in the state space. Further, recall that the total quantity of product p consumed by fulfilling orders Oa specified by action a is given by \u2211oi\u2208Oa b_i^p. Then, given a state sk = (q1_k, q2_k,..., qnp_k, D, tk) and an action ak+1 at decision step k, the probability of transitioning to a new state sk+1 = (q1_(k+1), q2_(k+1),..., qnp_(k+1), D, tk+1) is given by\nP(sk+1|sk, ak+1) = Pr(q1_(k+1), q2_(k+1),..., qnp_(k+1), D, tk+1 | q1_k, q2_k,..., qnp_k, D, tk, ak+1),\nwhich can be further decomposed as follows:\nP(sk+1|sk, ak+1) = Pr(Ta_(k+1) = tk+1-tk) \u00d7 \u220fp\u2208P Pr(Qt,t\u2032^p = q^p_(k+1) - (q^p_k-\u2211oi\u2208Oa b_i^p )).\nThe distribution of the quantity replenished for each product Qt,t\u2032^p is determined by the time-varying Markov chain model discussed in Section 4.1 and the distribution of Ta_(k+1) is established using empirical data specific to the configuration of the sortation system.\nNote that we use t to indicate a time step in the discretized season duration, which is distinct from the decision step k in the MDP. The decision step k in the MDP is the instant at which the agent takes k-th action in the sequential decision-making process."}, {"title": "Reward Function", "content": "The objective of the wave scheduling problem is to ensure that all the orders are fulfilled before deadline, and in cases where this is not possible, to minimize the delay. We design the reward function R to reflect this objective.\nR(s, a, s\u2032) specifies the immediate reward for taking action a in state s and transitioning to s\u2032. We calculate the reward as the number of orders met before their deadlines minus a penalty for the late orders proportional to the delay, weighted by a factor \u03bb > 0:\nR(s, a, s\u2032) = \u2211oi\u2208Oa I[fi \u2264 di] \u2212 \u03bb \u2211oi\u2208Oa max(0, fi \u2013 di)\nWe now proceed to discuss the challenges of solving the above MDP formulation in practice."}, {"title": "Challenges of Solving the Wave Scheduling MDP", "content": "Existing methods for solving an MDP M, given known transition probabilities P and a reward function R, include dynamic programming-based approaches, deep learning-based techniques, and tree search methods that learn through interactions from a simulator of system dynamics. However, applying these algorithms to the wave scheduling MDP is challenging for the following reasons:"}, {"title": "Large State and Action Spaces", "content": "In real-world wave planning problems, the substantial size of the state and action spaces presents significant computational challenges. The state space S in the wave scheduling MDP consists of all possible combinations of product quantities and the time step, with a cardinality of |S| = \u220fp\u2208P(q^p+ 1) \u00d7 T. The action space at each state, As, includes all feasible waves based on the available product quantities, pending orders, and their deadlines. The size of the complete action space A is |A| = \u2211s\u2208S |As|, which is exponential in the number of products and orders.\nFor dynamic programming based approaches like value iteration, the computational complexity of each iteration is quadratic in the size of the state space and linear in the size of the action space which for the wave-scheduling problem translates to O (\u220fp\u2208P (q_(max)^p + 1) \u00d7 T \u00d7 \u2211s\u2208S |As|), rendering dynamic programming approaches intractable for our problem. Similarly, tree search methods like MCTS are also computationally infeasible due to the large branching factor of the tree associated with large action spaces. Although deep learning-based approaches offer greater scalability by generalizing performance across state and action spaces, they necessitate a compact representation of the state space and an extensive dataset encompassing the entire action space, which is impractical in our context."}, {"title": "Imperfect Transition Model", "content": "The stochastic arrival of products is modeled using time-varying Markov chains, with associated transition probability matrix estimated from historical data, as discussed in Section 4.1. However, the transition probability models are often susceptible to inaccuracies due to the lack of sufficient historical data, the presence of outliers, and the inherent stochasticity of the crop harvest dynamics. This imposes additional challenges on dynamic programming based approaches since each iteration might require recalculating the value function, exacerbating the already high computational cost."}, {"title": "4.3. Adaptive Hybrid Tree Search for Wave Scheduling", "content": "To overcome the computational challenges inherent in solving the wave scheduling problem, we propose a hybrid approach that combines domain knowledge with tree search methods. The central idea of our approach is to combine the intelligent tree search and anytime properties of general Monte Carlo Tree Search (MCTS) with domain-specific knowledge to dynamically curate a narrowed-down action space at each state to increase the likelihood of identifying promising actions under practical computational constraints.\nIn rest of this section, we delve into specifics of our approach, structured into three main components. Firstly, we present our approach to identifying and refining the feasible orders into a set of candidate orders. Next, we outline our method for constructing a practical and effective set of wave actions from the narrowed-down set of candidate orders. Finally, we elaborate on how we adapt MCTS algorithm in the context of our problem to parallely learn dynamic parameters that guide action set reduction process and tree search."}, {"title": "Candidate Order Set Selection", "content": "At any decision step in an episode, let O_uf denote the set of unfulfilled but feasible orders, i.e., orders that have not been fulfilled but can be fulfilled given the current inventory levels. In order to reduce the action space size, we generate two subsets O_df and O_f^uf from O_uf. We select orders for O_df based on the ascending deadline order while ensuring that orders past their deadlines do not account for more than a predetermined proportion of the total number of orders in O_df. For O_f^uf, we first calculate the peak of unfulfilled order deadlines, i.e., the time step at which the maximum number of orders are unfulfilled, and select orders based on their proximity to this peak. We constrain |O_df| \u2264 2n_w\u03c1, |O_f^uf| \u2264 2n_w(1 - \u03c1), and |O_df \u2229 O_f^uf| = 0. The intuition is that O_df prioritizes orders with earlier deadlines, while O_f^uf focuses on orders likely to cause bottlenecks due to deadlines clustering around the peak. This decomposition attempts to balance urgency of individual orders against long-term risk of developing system-wide bottlenecks.\nTo construct the candidate order set Oc of size 2nw, we introduce a dynamic parameter called the peak reducing factor \u03c1\u2208 [0,1]. The value of \u03c1 varies based on tree search evaluation outcomes from previous rounds; details on how \u03c1 adapts are provided in later sections. \u03c1 adaptively adjusts the"}, {"title": "Action Set Generation", "content": "While Oc provides a reduced set of candidate orders, generating an appropriate and computationally tractable set of wave actions remains a challenge. Given that the size of Oc is 2nw, the combinatorial possibilities yield (2nw!) / ((nw!)2) candidate waves for the action space. The action set for our tree search must be manageable in size, only contain waves that are feasible at currently in-ventory levels, and filled with actions likely to be beneficial for maximizing our reward.\nWe adopt a two-step approach to generate the action set. First, we construct a set of feasible candidate waves by incrementally adding randomly selected orders from Oc that ensure wave feasibility until the size of the set reaches wave capacity nu. Next, we calculate the estimated fulfillment time of each candidate wave and select a predetermined number of waves with the lowest estimated fulfillment time. While this approach may not always yield the optimal set of candidate actions, it provides a computationally tractable way to generate the action set which is critical for our tree search algorithm that involves simulating multiple rollouts from each action."}, {"title": "Adaptive Tree Search", "content": "In this section we discuss how we use the proposed adaptive hybrid tree search algorithm to solve the wave scheduling problem. Our approach closely follows the steps involved in Upper Confidence Bound for Trees (UCT) [28] variant of MCTS with the modifications that we proposed in the previous sections. We begin with a brief overview of UCT algorithm and then proceed to discuss our approach to adapt it for the wave scheduling problem.\nMCTS involves iteratively building a search tree to identify the best possible action to execute at the root node. It consists of four steps: (i) selection, (ii) expansion, (iii) simulation, and (iv) backpropagation. The tree starts as a single node, representing the current state. At each iteration, in the selection step, the algorithm starts at the root and moves down the tree according to a tree policy until it reaches a leaf node. Then, if the leaf node is not a terminal state, the expansion step adds a child node to the tree, representing possible next state, by taking an action. The simulation step simulates a random rollout from a newly expanded node until it reaches a terminal state, resulting in a sequence of rewards. Finally, the backpropagation step propagates these reward values back up the tree, updating the state-action value estimate Q(s, a) and visit count of each node it traversed on the way.\nThe UCT algorithm proposed the following tree policy to effectively balance between exploring new states and exploiting known, valuable states:\n\u03c0tree(s) = arg maxa\u2208A  Q(s, a)/#(s, a) + c \u221a(log #(s))/(#(s, a)),\nwhere Q(s, a) is the current estimate of state-action value, #(s) is the visit count of state s, #(s, a) is the visit count of state-action pair (s, a), and c is a constant that controls the amount of exploration.\nIn the context of the wave scheduling problem, at each decision step where we need to select an action, we initiate a tree with the root node representing the current state that encapsulates information about the current inventory levels of all products and the current time step. Then, we generate the action set on the go at each state and use the UCT tree policy to select the action to execute until we reach a leaf node and then expand the tree. We then simulate a rollout from the newly expanded node until we reach a terminal state, randomly selecting actions from generated reduced action sets at each state. Finally, we backpropagate the reward obtained from the rollout that depends on the number of orders that were fulfilled before their deadline and that missed their deadline. We perform iterations for a fixed time budget that depends on the wave completion time in the real system, and then execute the recommended action from the tree with the highest estimated state-action value at the root node in the warehouse. In order to execute the selected wave, we select the smallest set of available intermediate containers that contain all the products required to fulfill the orders in the wave and move them to the induction station of the sortation system. Note that this recommended action is the only action (wave) that is executed in the real sortation system. Once the wave is executed in the real system and transitions to the next state, we repeat the above steps before taking the next action."}, {"title": "5. Experiments and Results", "content": "In this section, we present the results of our experiments comparing the baseline 'greedy' approach and the proposed approach. We begin with a description of our experimental setup, baseline policy, and then proceed to discuss the results."}, {"title": "5.1. Experimental Setup", "content": "We conduct our experiments in a simulation environment designed to replicate the operational dynamics of a real-world centralized seed processing facility. While the simulated facility information is not publicly accessible, we expect the results to be consistent on any simulator that can model the problem. The simulator accurately models the core components of the warehouse operations, including inventory management, order processing, and the automated sortation system. The environment is parameterized to align closely with real-world data, ensuring the relevance and applicability of our findings.\nWe consider a season duration of 90 days which is consistent with typical seed distribution season lengths. The time step size is set to 1 minute to capture the fine-grained information in the sortation system. As discussed in Section 3, the sortation system receives the inventory in intermediate containers. We consider intermediate containers with a capacity of 250 items and assume that the facility has sufficient capacity to accommodate all the intermediate containers. The sortation system has 30 induction stations and 400 chutes, which restricts the maximum number of orders processed in a wave also to 400. An order is fulfilled when all the items in the order reach a designated chute and a wave ends only when all of its orders are fulfilled.\nThe experiment simulates 200 products in the catalog, each with a unique arrival distribution over the season. The quantity of each product arriving over the season is consistent with the quantity needed to fulfill the all the"}, {"title": "5.2. Baseline Approach", "content": "As a baseline, we employ a greedy heuristic approach to allocate products to orders that is commonly used in real-world scheduling problems due to its"}, {"title": "5.3. Results and Discussion", "content": "In this section, we present the results of our experiments comparing the baseline approach and the proposed approach. In order to account for the stochasticity in the product arrival distribution and order contents, we simulate each approach 30 times with different random seeds and report the average results. Further, to ensure a fair comparison, we use the same set of"}, {"title": "6. Conclusion and Future Work", "content": "In this paper, we introduced an adaptive hybrid tree search algorithm to address the stochastic wave scheduling problem, with a particular focus on order fulfillment in the agricultural domain. The method synergistically blends Monte Carlo tree search with domain-specific knowledge to provide a computationally tractable solution to our problem with large state and action spaces. Our approach outperforms the baseline greedy approach in terms of order fulfillment efficiency, demonstrating its effectiveness in managing complex agricultural sortation systems. The flexibility of our approach extends beyond seed order fulfillment, making it a versatile solution that can be adapted to a wide range of problems in order fulfillment and other domains that involve sequential decision-making under uncertainty.\nWhile this paper develops the framework for fulfillment under stochastic inventory conditions, much work remains to be done in adapting to unexpected events, such as equipment malfunctions or sudden shifts in demand. Another possible area of future work is handling the interplay between the wave scheduling policy and the inventory management policy that creates products from raw material inventory. Relevant further study also includes developing hierarchical policies that plan in the space of order scheduling primitives instead of individual orders."}]