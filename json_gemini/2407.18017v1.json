{"title": "A Sensitivity Analysis of Cellular Automata and Heterogeneous Topology Networks: Partially-Local Cellular Automata and Homogeneous Homogeneous Random Boolean Networks", "authors": ["Tom Eivind Glover", "Ruben Jahren", "Francesco Martinuzzi", "Pedro Gon\u00e7alves Lind", "Stefano Nichele"], "abstract": "Elementary Cellular Automata (ECA) are a well-studied computational universe that is, despite its simple configurations, capable of impressive computational variety. Harvesting this computation in a useful way has historically shown itself to be difficult, but if combined with reservoir computing (RC), this becomes much more feasible. Furthermore, RC and ECA enable energy-efficient AI, making the combination a promising concept for Edge AI. In this work, we contrast ECA to substrates of Partially-Local CA (PLCA) and Homogeneous Homogeneous Random Boolean Networks (HHRBN). They are, in compari-", "sections": [{"title": "1 INTRODUCTION", "content": "Standard Artificial Intelligence (AI) approaches rely on high-performance computing such as with cloud or cluster computing. However, these are very energy-intensive resources, and many popular models are energy-intensive in training [90] and inference [56]. Conversely, biological intelligence has made highly energy-effective solutions, e.g. the brain. Despite operating under conditions such as increased decentralisation, asynchronisation, and"}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "In this section, we will detail the background, related work, and theory relevant to this paper. This paper connects many fields, uses several substrates, and relies on several empirical and theoretical methods. This has made this section necessarily extensive to provide a comprehensive overview. In general this sections begins by explaining the different substrates, followed by more theoretical overview of said substrates as well as relevant concepts. Finally, the relevant related work is presented."}, {"title": "2.1 Cellular Automata", "content": "Cellular Automata (CA) are a simple model consisting of a grid of cells possessing a limited set of k discrete states placed on a uniformly connected grid, typically in 1 or 2 dimensions. The cell state changes iteratively, depending on the state of the neighbours. Which neighbour state combination results in which next state is determined by a lookup table, typically called the Transition Table (TT). CA was first used to study self-replication by John von Neumann in 1940 but published in 1966 [96]. It can be considered an idealised system for parallel and decentralised computation [68]."}, {"title": "Two Dimensional CA (2D CA)", "content": "Beyond ECA are many other types of CA, such as 2-dimensional CA, where instead of configuring the cells in a 1-dimensional line, they are now configured as a 2D surface. In 2D CA, the most typical neighbourhood scheme is one of two configurations in Figure 3.\nThe Rule space of 2D CA is quite large, especially with a Moore neighbourhood. This space have $2^{2^9} = 1.32 * 10^{154}$ different Rules. It is too large to search exhaustively, but explorations into 2D CA are often limited to totalistic or outer-totalistic rules. Totalistic rules mean the rule does not distinguish which neighbours are in which state, but rather \"counts\" the number of neighbours with a specific state. 2D CA, with a Moore neighbourhoods, has only ten states to differentiate 0,1,...9 alive neighbours. Only $2^{10} = 1024$ totalistic rules exist in this rule-space. Outer-totalistic does the same but differs on the central cell. This means if the central cell is \"dead\" there are 9 (0,1,...8) different totalistic states the outer neighbours can be in and likewise, if the central cell is \"alive\". This means there are $2 * 9 = 18$ states for outer-totalistic rules to differentiate. Therefore, there are $2^{18} = 262144$ different rules in this rule-space, though this can be somewhat reduced with symmetry equivalence classes [28]."}, {"title": "\\u201cLife-Like\\u201d Rules", "content": "The 2D outer-totalistic binary CA rule space is often called the \"life-like\" [50] rules-space, and beyond GoL, there are several other rules that are said to have \"life-like\" properties. In [20], the goal was to identify rules that could support similar \"life-like\" structures that can be constructed in GoL. In addition to identifying new ones, this article also provides an overview of many"}, {"title": "2.2 Random Boolean Networks", "content": "The RBN is similar to a CA yet has two key differences. Firstly, in the RBN, the grid neighbour connections are not regular but randomly set up. Secondly, every node (cell) typically has a random TT, often called an Activation function or Boolean function. This type of RBN is also sometimes called Classical RBN (CRBN) [25]. The number of direct neighbours can be random, semi-random or constant. The latter is called homogeneous RBN [25], an example is given in Figure 5.\nAs with CAs, several extensions exist beyond the original RBN, such as Continuous RBN [95] or stochastic RBN [19, 85]. While Kauffman first de-"}, {"title": "2.3 RBN Classification", "content": "ECA is often partitioned and classified into several different categories or traits. In [63], a good overview of many common or well-known ones can be found.\nSimilarly, RBN can be classified by their behaviour, i.e. ordered, complex or chaotic [25, 47]. Depending on the value of N and K, the behaviour might differ, and one alternative name for RBN is the NK model. In [46], Kauffmann added another parameter P, which can organise the rule-space. The rule has a given P parameter value based on the number of neighbourhood combinations resulting in a 1 or a 0. In later work [47], the larger distribution dominates, meaning $P\\geq 0.5$. Figure 5 has $P=0.5$. One can use this parameter to control the behaviour. P close to 1 would likely result in ordered behaviour, and P close to 0.5 would likely result in chaotic behaviour. In between these, a critical (complex) $P_c$ behaviour might be found in the phase transition between order and chaos. This point or border is often also called the edge of chaos. The work is reminiscent of CA work in [49], which we will introduce later. The P is the same as A is in Langton's work, and in this work, we will use the A notation for both.\nAnother way to categorise RBN and CA is to look at the basin of attraction. [105, 106, 107, 109] did extensive work in both RBN and CA and their basin of attractions. What opened up this possibility was a method that could calculate backwards from a state. Take a cell in a state and consider what possible local neighbourhood configurations would result in this state. These are the possible previous states (preimage) for the neighbourhood. Finally, this can be applied to all the cells and limit the possibilities between cells by constraining satisfaction. The possible preimages often collapse to very few, making it possible to calculate the basin of attraction quickly."}, {"title": "2.4 Intermediate Substrates", "content": "A system can be in a range of possible states that would be somewhere between CA and RBN. This paper will discuss a substrate with homogeneous rules but random neighbour wiring. This is what we define as HHRBN. HHRBN to distinguish it from what is in [25] called HRBN. It is called HHRBN rather than non-local CA because the substrate seems to behave more like RBN than CA, and the equivalence in this substrate is more applicable in RBN than CA.\nIn [51], Li worked with systems where all cells had the same activation function (TT), but the neighbour connections were in various configurations. In this work Li classified the different connection schemes as between non-local (random) and partially-local (central self-reference) as well as non-distinct and distinct input/output (uniform number of outputs). Li then classifies the rule-space for these substrates using mean field approximation and shows they are very neatly classified, particularly non-local CA (HHRBN).\nMuch earlier [97, 98, 99] studied a system that Li would classify as partially-local CA.\nHHRBN has additional commonly used names beyond non-local CA [51], such as Graph CA [31, 61] or (Cellular) Automata Networks [6]\nIn [105], Wuensche examined substrates between CA and RBN, including non-local CA and other disordered CA. He defines disordered CA as a superset of CA, which includes non-local CA and mixed rule CA. Furthermore, Wuensche calculates these networks' basin of attraction fields and demonstrates how rewiring the network can train or modify the basin of attraction. Mixed rule CA is also known as Non-uniform CA [6, 11] or hybrid CA [6]."}, {"title": "2.5 Minimum Equivalent (ME)", "content": "In ECA, RBN and everything in between, we find equivalence classes that effectively reduce the number of unique rules for a given substrate. The List of rules that make up the minimum set of unique rules is called the Minimum equivalent (ME). These rules can be used as a smaller replacement for the entire computational space of a specific substrate.\nMinimum Equivalence (ME) in Elementary Cellular Automata (ECA)\nECA consists of $2^{2^3} = 256$ rules, but due to symmetries and other properties, there are only 88 rules that are considered unique. The reason is that all excluded rules can be transformed into one of the 88 unique rules by one of the following trivial methods."}, {"title": "2.6 Definition of chaotic behaviour in nonlinear systems", "content": "To this day, the definition of chaotic behaviour is not mathematically univocal [48, 93]. Still, we will work with a well-accepted definition of chaotic function. The definition is as follows (see. [17, subsection 1.8]): a function or map $f: V \\rightarrow V$, on a vector space V, is chaotic if it satisfies the following conditions:\n* f has a sensitivity to initial conditions,\n* f must be topologically transitive,\n* has dense periodic orbits (periodic points are dense in V).\nIn essence, a function or map is unpredictable as it is sensitive to initial condition, indecomposable (can not be decomposed into two or more subsys-"}, {"title": "2.7 Identifying the edge of chaos and with a parameter", "content": "The parameter space of a complex system often has a phase transition between order and disorder; this phase transition region is often called \"Edge of Chaos\" It is theorised that this region commonly contains the highest capacity for computation defined as transformation, manipulation and storage of information.\nLangton [49] explored this theory in 1-dimensional multi-state CA with enlarged neighbourhoods and found that the CA rule-space forms a phase transition between order and chaos when organised over a \\u03bb (Lambda) parameter. The \\u03bb parameter starts by defining a state as the quiescent state. To generate a Transition Table (TT) with a given \\u03bb value, one allocates to each TT entry a random number $a$ uniformly distributed between 0 and 1 and attributes the quiescent state to all entries with $a < \\lambda$ and a non-quiescent state to the other. Using this method, Langton generated different candidate rules in several regions of the rule-space over the \\u03bb parameter. He showed that the rules-space organises into a phase transition between order and chaos and that strong candidates for computation are more likely to be found there. Notably, this lambda method does not seem to work in the ECA rule space, as mentioned in [49] and previous work."}, {"title": "2.8 Reservoir Computing (RC)", "content": "Reservoir Computing (RC) is a substrate-independent framework for computing. RC is independent because it works on many different substrates, but"}, {"title": "2.9 Reservoir Properties", "content": "An important property in ESN is the Echo State Property (ESP). Given some input signal, the reservoir must asymptotically remove the initial condition information to have this property. In [37], it is shown that for a reservoir with specified conditions, it violates the ESP if the spectral radius of the weight matrix is larger than 1, and it was empirically observed that for Spectral radius below 1, the ESP is given. Note that in [36] Jaeger warns that this does not mean that ESP is granted for any system with a spectral radius of below 1"}, {"title": "2.10 Reservoir Computing with CA (ReCA)", "content": "The first study that introduced CA as a substrate in reservoir computing is [110]. This study investigated Game of Life and several ECA rules as reservoir substrates and tested on a 5-bit and 20-bit memory benchmark. In addition, it presents a theoretical comparison of CA vs ESN, using the metric of the number of operations needed to solve the benchmark, which documents a clear advantage of using CA.\nAs an ECA reservoir only relies on simple discrete binary interactions between cells (see [83] for details), it affords a hardware-friendly substrate implementation. The problem (perhaps ironically) becomes how to implement the readout layer in hardware. In [70], ReCA using ECA with a max-pooling and softmax strategy was implemented on a Field Programmable Gate Array (FPGA). In [75], a CA was implemented on Complementary metal-oxide-semiconductor (CMOS) combined with a custom hardware SVM implemented in resistive random-access memory (ReRAM). In [53], a synthesised hardware implementation of ReCA using ECA with a max-pooling and ensemble bloom filter classifier. Showing impressive results compared to \"state-of-the-art\" in terms of energy efficiency, memory usage and area(number of gates) usage, but with comparably poor accuracy [70].\nOther works have also studied ReCA using the 5-bit memory benchmark. [73] changed the structure of the CA to a deep-layered architecture and compared it to a single layer, which resulted in noticeable performance improvements. Additionally, in [72] the authors organised the CA substrate as consisting of two regions of different ECA rules. Different combinations of rules were explored, and some showed great promise. In [59], an exploration was conducted of different cell history selection methods for the classification model on the 5-bit memory task, a temporal order task and arithmetic and logic operation tasks. In [4], CA rules with multiple states and larger neigh-"}, {"title": "2.11 Reservoir computing with Random Boolean Networks (ReRBN)", "content": "In [88, 89], ReRBN was explored on temporal parity and temporal density (temporal majority task). For the tasks and parameters explored, it was found that the heterogeneous RBN (different in-degree RBN) reservoir worked best at a critical connectivity $K = 2$ (in-degree of 2). In contrast, [8] found that for homogeneous RBN, criticality was instead found at $K = 3$. [9] extended this work, exploring different reservoir properties such as perturbation percentage, the relationship with attractor and performance and comparing a subset reading from a larger reservoir to a subset equal reservoir.\nIn [10], the relationship between N and K was also studied with a balance b between excitatory and inhibitory nodes. They find that K is the most important of the control parameters, as it affords simpler fine tuning of the other parameters."}, {"title": "2.12 Reservoir computing with Intermediate substrates", "content": "RC explorations Between CA and RBN substrates are less common. This paper reports and extends on work done in a master thesis [39], where Life-like CA, ECA, PLCA and HHRBN were explored using the 5-bit memory benchmark.\nIn another master thesis [40], Reservoir computing with cellular automata networks where explored on a simple text classification task. The study explores and compares different ways to construct the network and how that affects performance. The cellular automata networks described include fixed predecessors (in-degree); from the description, it seems they explored PLCA, confirmed by the lack of the same score for rules 204 and 170. Yet, we can not directly compare it with the work in this paper, as the study constructs the transitions rule differently."}, {"title": "2.13 5-bit Memory Benchmark", "content": "The 5-bit memory benchmark traces its root to the short long-term memory task introduced in [33]. Although often cited as the source [4, 72, 73, 110], none of the benchmarks in [33] are the 5-bit memory benchmark, but some of them are very similar in intention. The earliest source where the 5-bit memory benchmark is recognisable is in [62], but named \"noiseless memorisation\\u201d, corroborated with the clearer and more detailed explanation of the benchmark in [91, p. 47] and in [38].\nThe 5-bit memory benchmark's goal is to test whether a system is capable of memorising a 5-bit and reproducing it at a later stage."}, {"title": "2.14 Small-world", "content": "In [100], they explored graphs varying on p value where p = 1 meant random connectivity and p = 0 is regular connectivity. They demonstrated that small worldliness was achieved with a relatively low p-value. However, in relation to this work, they have a larger neighbour degree. Additionally, we work with fixed in-degree networks (all cells have 3 neighbours). For these reasons, we might not see the same level of small-worldness in our topologies, but naturally, in contrast to ECA, some is expected in PLCA and HHRBN."}, {"title": "2.15 Derrida Plots and the Derrida Coefficient", "content": "Derrida Plots is named after the author of its origin in [16]. It is a tool primarily used to identify the behaviour of a particular RBN (critical, chaotic or ordered (frozen)). Derrida originally used it to compare a classical RBN (quenched) and an \"annealed\" RBN, in which every connection and activation function is randomly reassigned after each iteration. To construct a Derrida"}, {"title": "3 METHODOLOGY AND EXPERIMENTAL SETUP", "content": "This section will detail the specific methods and experimental setup used in this paper. We begin with the experimental methods by documenting the x-bit memory benchmark details used for the 2D life-like (CA, HHRBN) and the 1D (CA, PLCA, HHRBN). Then, we will explain the details of the Temporal Derrida Plots (TDP) used to analyse the sensitivity. Then, we will give details on how we measured the rate of defect collapse (collapse rate). We continue with the network analysis method of the longest simple cycle and how it is estimated. Finally, we will document the source code and the dependencies with which the code was built."}, {"title": "3.1 x-bit memory benchmark", "content": "The 2D life-like experiments use the same setup as [64]. It uses a parameter of R, which in this specific experiment is the grid size, and in terms of full grid size, it is R x R. The Iterations I represent the number of iterations between encoding steps and the number of steps fed into the classifying model, chose to be a ridge regression model. The projection ratio $P_r$ is the ratio of cells that the input is encoded into, set to P = 0.6.\nFor the 1D substrates 5-bit memory benchmarks, the experimental setup and the default parameters are the same in [30]. Redundancy R = 4 is the number of connected \"sub-reservoirs\" with individual mapped input. Note"}, {"title": "3.2 Temporal Derrida Plots (TDP)", "content": "In this work, we introduce a variant of Derrida plots: Instead of introducing a new defect at each step (see subsection 2.15), we follow the development of one or a few defects starting at t = 0 and see how $D_h$ changes throughout time (i.e. as a function of iterations). In this way, one follows how $D_h$ diverges or converges to a specific value over multiple iterations. Henceforth, we call these plots \"temporal Derrida plots\\u201d (TDP). Derrida plots retrieve approximately the Lyapunov exponent in state space, whereas the temporal Derrida plot retrieves the Lyapunov exponent in time.\nIf we take the simple example of the rules 204 and 170, a simple inspection of these rules would tell you they are very ordered in their behaviour, simply propagating the initial condition. Yet, using the original method [16] and as described in [108] (cf. [3, Appendix A]), Derrida plots for rule 204 and 170 yields Dc = 0, meaning that they follow the 45 angle line. This interpretation is that rules 204 and 170 are complex/ critical in the Derrida Plot method. This is not the case with our TDP. Therefore, we argue that the Derrida plot method's weaknesses in ECA substrates are solved with our variant"}, {"title": "3.3 Defect collapse", "content": "We explore whether the systems tend to collapse into the same attractor after a defect is introduced. This can happen in CA because the attractor basin is large enough to encompass the defect. However, in PLCA and HHRBN, this can also occur due to the neighbourhood itself, e.g. if you encode the information into a node that is not the in-node of any other cell, the information can not propagate anywhere. We inspect the substrate in two ways: via the Defect plots when all collapsed defects have been excluded from the data in Subsection 4.3, and we look at the statistic of collapsing in Subsection 4.4."}, {"title": "3.4 Longest Simple Cycle", "content": "The difference between CA, PLCA, and HHRBN is essentially that of the topology. All the topologies can be reduced to graphs, and therefore, it is"}, {"title": "3.5 Source code and Dependencies", "content": "The source code for the project can be found at [27]. The code relies primarily on Evodynamics [79] to run the ECA, PLCA and HHRBN and on scikit-learn [77] for the classification models. A more detailed list of dependencies can be found in [27]."}, {"title": "4 RESULTS", "content": "In this section, we present the results of this paper in chronological order. Starting with the 5 bit memory benchmark experiments, then the TDP and collapse rate results, followed by the network analyse and finally a extended 3 and 4 bit memory benchmark results are presented."}, {"title": "4.1 Life-like 5-bit memory benchmark", "content": "We begin with a smaller experiment between 2D outer totalistic CA (life-like CA) and HHRBN (note that the concept of 2D breaks down in HHRBN). There are $2^{2^{18}} = 262144$ different rules in the \"life-like\" rule space(see subsection 2.1). Therefore, an exhaustive search was not practical. A subset of interesting behaving rules were selected from [64, 65, 78]. The results can be found in Table 7, and we see here that many of the rules perform well in the CA case but not in the HHRBN case, except for B368/S12578. We can quite clearly see from Figure 11a and 11b that the behaviour of said rule changes. It is important to point out that there is a bias as these rules have been selected for their behaviour in a CA context. Therefore one can not conclude about the greater scope of ECA, and HHRBN reservoirs, we can at least say that the topology changes the behaviour. The CA results are better overall than in [64, 65], though not of a different scale, this might be explained by the difference in hyper-parameter or other implementation detail of the ridge regression model as one was implemented in Julia and the other in Python, we therefore still consider it a successful replication of the previous study."}, {"title": "4.2 ECA 5-bit memory benchmark", "content": "A similar exploration of the full ME set of ECA rules for ECA, PLCA, and HHRBN was also conducted. The bias of selecting rules is removed by exploring the entire rule space. The rules have different ME sets [28], but the ECA ME set is a super-set of the HHRBN ME set. Therefore, we use the ECA ME set by default. In Figure: 12, we see these results. There is a clear trend that general performance goes down from CA to PLCA to HHRBN. In the perfect run metric, only three rules scored any perfect run for HHRBN (108, 170, 204). We see a similar trend in the weighted average metric. Note that these rules (108, 170, 204) are all ordered in behaviour and that rules 170 and 204 are equivalent in the HHRBN ME set, meaning in effect, only 2 behaviours of the 46 unique HHRBN managed to solve the task. More details and results can be found in [39]."}, {"title": "4.3 Temporal Derrida Plots", "content": "In this subsection, we will present the TDP, all plots except Figure 17a have the collapsed runs removed; the tally of the collapsed runs can be found later in Table 8, 9 and 10. They are separated because the collapse can greatly impact the temporal Derrida plots. In short, we still see this impact by removing"}, {"title": "4.4 Collapse rate", "content": "We will begin with the collapse rate for the selection of rules in the previous section; these are found in Table 8, 9 and 10.\nWe see that for these rules, there is almost no collapse in ECA, but for PLCA, 1-bit defects regularly collapse except for Rule 54. In contrast, rules"}, {"title": "4.5 Network topology, longest simple cycle", "content": "We can see from examples such as Figure 13a that the original ECA \"speed of light\" is still there in a sense also for PLCA and HHRBN, though vastly different. Defects can still only affect neighbouring cells, but the pathways through the network that the defects can propagate are more small-world than ECA. This is unsurprising as they are randomly generated in contrast to ECA. We want to create a sense of how this affects the computations. We do this by finding a network's longest simple cycle. The longest simple cycle indicates the theoretical memory size that can be encoded into the network and the substrate's ability to retain a memory in the cycle.\nWe begin by considering a 1-dependency rule, such as rule 170. A ECA"}, {"title": "4.6 Sensitivity in the x-bit memory benchmark", "content": "As was established in [30], the 5-bit memory benchmark can be solved with a simple random vector given sufficient dimensions. Therefore, it would be interesting to see if, as we compare CA, PLCA and HHRBN, as the tasks become easier, more and more rules can solve this issue and whether that would be true for HHRBN than for PLCA and PLCA compared to ECA. We expect HHRBN and PLCA to be more sensitive, and we expect them to perform better on the 3 and 4-bit memory benchmarks. We see from Figure 12, 23 and 24 that yes, more rules are capable of solving the easier tasks, but it is not entirely clear that a more significant portion of the rule-space"}, {"title": "5 DISCUSSION", "content": "This section focuses on discussing the results and, how they relate to each other, and how they relate to the field in a larger context. We will also give a short account of how we would approach the problem of a more natural definition of fully discrete chaos."}, {"title": "5.1 A complicated relationship between disordered topology and its computation", "content": "We see through the collapse rate that in random topologies, the collapse rate significantly increases in PLCA and HHRBN, meaning random topology"}, {"title": "5.2 Implications for RBN and RBN reservoirs", "content": "Our HHRBN has the same topology as Classical RBN, so implications beyond HHRBN can be derived. We demonstrated how different fixed in-degree networks should have a lower than max longest simple cycle. As RBN has"}, {"title": "5.3 Weaknesses of this study", "content": "Though this work is quite extensive, the work has some limitations. Due to computational constraints, we limit ourselves to CA grid sizes of a specific size, and we know that CA can exhibit significant behaviour changes on different grid sizes [30]."}, {"title": "5.4 Size of the Edge of Chaos", "content": "In [54, 86] several examples where introducing more heterogeneity extended the critical area. As we introduce topological heterogeneity to our networks, it would be interesting to consider if we are observing the same phenomenon of an increasing critical range. We begin by considering Wolfram's well-known ECA classification [63, 101]; there are only 11/88 rules in the \"chaotic\" class. We might also argue that the additive rules 60, 90 and 150 should not be con-"}, {"title": "5.5 Implications for ReCA, ReRBN and intermediates", "content": "We can consider some implications for reservoir computing with CA, PLCA, and HHRBN reservoirs from our results. If one considers the tool in practical terms, the ECA substrate seems superior as its regular topology lends reliability to the implementation, but also the localised neighbourhood affords easier implementation into FPGA, as the other substrates would naturally create more issues with the transfer of information due to the placement of neighbours.\nIt is common practice in RC to have redundant mappings for encoding the input. As we observe a higher collapse rate in PLCA and HHRBN, reservoir usage of these substrates will benefit more from higher input redundancy than"}, {"title": "5.6 A \"discrete\" version of chaos", "content": "In this paper, we pointed out that the definition of chaos breaks down when applied to fully discrete systems, i.e., systems intrinsically discrete in space and time and with a discrete number of accessible states. The sensitivity on initial conditions required in the definition of chaotic function has a natural analogy for discrete systems, but what about the concept of dense periodic orbits and topological transitivity?\nHere, we propose a definition of the meaning of a dense set of trajectories of a discrete system, with some additional mathematical formalism. The set of accessible trajectories of a discrete system is dense in the full phase space of possible configurations if, for each configuration in phase space, the minimal Hamming distance, $\\min (D_h)$ to an accessible trajectory converges to zero not slower than the size N of the system:\n$\\lim_{N\\rightarrow\\infty} N \\min (D_h) = 1$.\nIn practice, this definition can be read as\n$\\min (D_h) \\sim \\frac{1}{N}$.\nso graphically, plotting minimum Hamming distances as a function of the inverse of the system's size should hold a line with a unitary slope. If we consider the orbit, the natural analogy is the attractor in binary systems, A cyclic trajectory that the deterministic discrete system must eventually converge to. Therefore, we conclude that a natural analogy for a dense periodic orbit is a long attractor that periodically expands and contracts the $D_h$ between previous states without finding the exact previous state. Expanding and contracting are important because a long attractor does not necessarily mean chaos. Consider the example of a binary vector that does iterative counting upwards by 1. This would have full coverage over the state space and the longest possible attractor, but it should not be considered chaotic behaviour.\nAs for the topological transitivity, it is similarly defined in continuous space [17, subsection 1.8]: an iterative map $f : J \\rightarrow J$ is said to be topological transitivity if, for any pair of non-empty sets $U, V \\subset J$, there exists $k \\geq 0$ such that $f^k (U) \\cap V \\neq \\emptyset$. In other words, it still implies that a system can not be decomposed into two subsystems. It also means that it must"}, {"title": "6 CONCLUSION", "content": "This work investigated computational differences between ECA, PLCA, and HHRBN. It explores what happens with the simplest computational universe when introducing topological heterogeneity. We investigated using a simple 5-bit memory benchmark, sensitivity metric and collapse rate of the different substrates. We see how, in PLCA and HHRBN, performance on the 5-bit memory benchmark is substantially worse. That collapse rate increases substantially, which counterintuitively means that a more disordered topology can sometimes mean more ordered computation. In general, we see a weak sign of increased sensitivity, and if the collapse rate is controlled for, we see a strong sign of increased sensitivity. This indicates that we are observing a shrinking critical range. We see evidence consistent with the previous observations when we make the 5-bit memory benchmark easier by solving a 4 and 3-bit memory benchmark. Our results conclude that ECA is, at least with current hardware, the better reservoir for edge AI. We also try to address the issue of \"chaos\" in a fully discrete system and attempt to define a condition for the natural analogy."}, {"title": "7 FUTURE WORK", "content": "Many future work projects can naturally extend this work. As we identified in the intro (Figure 1), there are many steps between ECA and BBN, which can be explored. Additionally, there are different paths between ECA and BNN, so other orders of steps could be explored. For example, would we get the same results if we introduce other forms of heterogeneity, such as mixed-rule CA? Furthermore, our networks have a random topology beyond what is typically true in most biological systems. It would be interesting to see how the regular topology (ECA) and the irregular topology (HHRBN) perform when compared to evolved networks such as the connectome of a C. elegans. Alternatively, if we explore networks with increasing locality of connections, this might even be a suitable control parameter for reservoir quality."}]}