{"title": "Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking", "authors": ["Pedro Ruas", "Fernando Gallego", "Francisco J. Veredas", "Francisco M. Couto"], "abstract": "State-of-the-art deep learning entity linking methods rely on extensive human-labelled data, which is costly to acquire. Current datasets are limited in size, leading to inadequate coverage of biomedical concepts and diminished performance when applied to new data. In this work, we propose to automatically generate data to create large-scale training datasets, which allows the exploration of approaches originally developed for the task of extreme multi-label ranking in the biomedical entity linking task. We propose the hybrid X-Linker pipeline that includes different modules to link disease and chemical entity mentions to concepts in the MEDIC and the CTD-Chemical vocabularies, respectively. X-Linker was evaluated on several biomedical datasets: BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical, BioRED-Chemical, and NLM-Chem, achieving top-1 accuracies of 0.8307, 0.7969, 0.8271, 0.9511, 0.9248, and 0.7895, respectively. X-Linker demonstrated superior performance in three datasets: BC5CDR-Disease, NCBI-Disease, and BioRED-Chemical. In contrast, SapBERT outperformed X-Linker in the remaining three datasets. Both models rely only on the mention string for their operations. The source code of X-Linker and its associated data are publicly available for performing biomedical entity linking without requiring pre-labelled entities with identifiers from specific knowledge organization systems.", "sections": [{"title": "I. INTRODUCTION", "content": "ENTITY LINKING (EL) is the task of linking an entity mention in a given piece of text to an entry in a target Knowledge organization system (KOS), such as an ontology, a knowledge base or graph, a terminology, etc. The entry must accurately represent the meaning of the linked entity. EL is essential in text mining and natural language processing pipelines since it connects text expressed in natural language to semantic, computer-friendly representations. In the biomedical field, substantial amounts of information are captured in clinical notes written in natural language. These notes include entities that require standardization using ontologies like SNOMED-CT or UMLS.\nChallenges in the biomedical EL task include name variations (synonyms, acronyms), ambiguity (where the same name can denote different entities) [1], and the highly spe- cialised language, which hinders the use of complex re- sources typically available for general EL approaches, such as Wikipedia. The challenge of ambiguity is illustrated by the entity mention \"iris\", which can have several possible meanings: an eye-related anatomical structure, an insect or a plant taxonomic genus, a disease's acronym (immune re- constitution inflammatory syndrome) or a gene. Searching for \"iris\" in NCBI-Gene returns multiple homonymous re- sults: \"[Drosophila melanogaster (fruit fly)]\" Gene ID: 33290), \u201cIris iris [Tribolium castaneum (red flour beetle)]\" Gene ID: 103314968, and \"Iris iris [Dalotia coriaria]\" Gene ID: 1357899981. Besides, the insufficient coverage of the target KOS results in outdated information and unlink- able entity mentions [2].\nAnother challenge is that current state-of-the-art approaches resort to supervised, deep-learning-based approaches that re- quire abundant quality annotated data [1]. Large human- labelled datasets are expensive and hard to build since their creation requires biomedical expertise [3], [4]. The perfor- mance of the deep learning models is bounded by the in- formation accessed during their training. The applicability will be similarly restricted if most of the datasets are small- scale. To unlock the vast amount of biomedical text available and improve the performance of the task, it is necessary to go beyond supervised approaches trained on limited human- annotated data.\nTo evaluate the true generalization capability of EL ap- proaches, in [5] the authors underscored the significance of assessing these methods, in particular supervised ones, on refined test sets. These test sets exclude annotations that are concurrently present in both the training and development sets. The performance of a supervised approach is heavily reliant on the dataset, which does not align with a real setting where these approaches are employed for inference without artificial partitions of the available data into training and test sets.\nTo mitigate the requirement for costly human-labelled train- ing data, emphasis should be placed on domain-independent approaches trained on domains with large amounts of labelled data and then applied in domains with limited labelled data available [4]. To achieve this objective, distant supervision [6]- [8] and zero-shot methods [9], [10] have been investigated in the context of the EL task."}, {"title": "II. RELATED WORK", "content": "In the past decade, varied types of approaches have been proposed to address the problem of EL in the biomedical domain, ranging from heuristics [15] to the most recent deep- learning-based architectures [9], [10], [16].\nRule-based approaches offer the advantage of bypassing the requirement for a large volume of labelled data, albeit at the cost of performance. For example, [15] proposed a multi-pass sieve approach for EL in clinical records and scientific articles. This work shares some similarities to our work in the sense that it outlines a rule-based pipeline that includes multiple entity processing steps, including string matching the input mentions to the target KOS, abbreviation expansion, identification of composite mentions and several syntactic transformations, such as stemming, hyphenation or dehyphenation, suffixation and the replacement of numbers by their extended form.\nMachine learning-based supervised approaches improve the performance in the task, but require human-labelled data. For instance, TaggerOne [17] is a machine learning-based approach that models jointly NER and EL. The EL component is a supervised semantic indexer that generates vectorized rep- resentations for both input token and candidate KOS entities and then it assesses the correlation between tokens and target KOS entities using a semi-Markov model.\nSupervised approaches work better for domains with plenty of labelled data available, such as the general domain that has Wikipedia. Therefore, more recent approaches to the biomedical EL task focus on deep-learning architectures that require less annotated data.\nFor instance, BioSyn [18] focus on learning sparse and dense representations for entities using the synonym marginal- ization technique. The approach applies an iterative candidate retrieval to maximise the marginal likelihood of the synonyms being present in the top candidates.\nThe recently proposed BELHD [19] expands on BioSyn by focusing on homonym entities. The approach replaces homonym entities with a disambiguated version included in the target KOS and then introduces candidate sharing and a new objective function to train the BioSyn model.\nBERN2 [20] shares similarities with our work as it adopts a hybrid approach: initially employing a rule-based module to link entities, then applying the deep-learning BioSYN model for more challenging cases. However, BERN2 is a supervised approach that uses annotations from the training sets of evaluation datasets to fine-tune BioSYN.\nSeveral zero-shot approaches have been proposed to tackle the EL task but these mostly focus on the general domain [21]-[24]. In the biomedical domain, two zero-shot approaches have achieved state-of-the-art performance: SapBERT [9] and KRISSBERT [10]. SapBERT [9] represents an unsupervised approach with a focus on learning representations for enti- ties within the target KOS. The method involves pretraining a Transformer-based model on UMLS data using a self-alignment objective. Initially, it clusters synonyms of UMLS entries, after which a BERT-based model learns a mapping function between names and their corresponding Concept Unique Identifiers (CUIs). KRISSBERT [10] introduces a self-supervised method for EL aimed at mitigating the scarcity of annotated data for model training. The approach generates entity annotations by matching UMLS entity names with unlabelled PubMed documents. Subsequently, it employs con- trastive learning to train a contextual encoder. This involves creating positive pairs, where two entity mentions are associ- ated with the same UMLS CUI, and negative pairs, where two entity mentions are linked to different CUIs. The encoder is trained to map mentions of the same entity closer together and mentions of different entities further apart, thereby generating distinct representations for UMLS entities.\nRecently, in [25] the authors introduced an XMR-based"}, {"title": "III. METHODS", "content": "A. Named Entity Linking definition\nLet T be a text document containing a set of entity mentions \\(M = \\{m_1, m_2,...,m_n\\}\\), and KOS a knowledge organization system including a set of entities or concepts \\(E = \\{e_1,e_2,...,e_k\\}\\). The goal of EL is to map each mention \\(m_i \\in M\\) recognized in a given document to its corresponding entity \\(e_j \\in E\\). Ideally, input entity mentions are linked to entities that accurately represent their semantic meaning.\nThere are two essential phases in the EL task:\n\u2022 Candidate Generation: the goal is, for each mention \\(m_i\\), to generate a set of candidate entities \\(C_i \\subseteq E\\).\n\u2022 Candidate ranking and disambiguation: the goal is to rank the candidate entities \\(C_i\\) based on their sim- ilarity scores \\(sim(m_i, e_j)\\). Depending on the approach, the similarity can be calculated based on the features of the individual mentions (local approach), the features of other mentions within the same document (global approach), or a combination of both. The entity \\(e_t\\) with the highest similarity score in the candidates set is selected:\n\\(e_t = \\arg \\max_{e_j \\in C_i} sim(m_i, e_j)\\)\nThe final mapping M from mentions M to entities E is given by:\n\\(M(m_i) = e \\quad m_i \\in M\\)\nThere are various methods for candidate generation and ranking in the EL task. We demonstrate in this work that no single approach is universally optimal for all entities. Instead, a combination of different approaches yields better performance.\nB. Entity Linking as a string similarity problem\nThe candidate generation is achieved using a string sim- ilarity function. One commonly employed string similarity function is the edit distance also designated by Levenshtein Distance. The Levenshtein distance between two given strings represents the minimum number of single-character edits (insertions, deletions, or substitutions) necessary to convert one string into the other. Defining the distance as d, the distance between a given mention \\(m_i \\in M\\) and an entity \\(e_i \\in E\\), the goal is to compute the distance between a mention and every entity and then choose the entity the smallest distance to link the mention to. The limitation is that it relies solely on individual features of the input entity mention, and these features are strictly string-based, lacking consideration of contextual information.\nC. Entity Linking as an eXtreme Multilabel Ranking problem: PECOS-EL\nIn this work, we investigate framing of the biomedical EL task as an XMR problem, which to the best of our knowledge, has been only recently attempted in the general domain by [25]. Given an input entity mention, the goal is to return the most relevant labels or identifiers from a large set of labels included in the target KOS. We used PECOS [26], a framework originally designed for Information Retrieval approaches. In the EL task, the input mention serves as the text and the set of entities E in the KOS represents the target labels. The PECOS framework encompasses three stages:\n1) Semantic Label Indexing: the set of KOS entities E is partitioned into K clusters.\n2) Matching: an entity mention is mapped into relevant clusters through a learned scoring function.\n3) Ranking: a ranker assigns scores to the candidate enti- ties present in the matched clusters.\nIn semantic label indexing, labels/entities from a target KOS are grouped into clusters reducing the search space. Represen- tations for each entity \\(z_e: e \\in E\\) are obtained by aggregating the feature vectors of the training instances associated with the entity. The clustering algorithm maps each entity to a cluster: \\(c_e \\in C_E\\), where \\(c_e\\) denotes the index of the cluster containing the entity e. The clustering is represented by the clustering matrix \\(C_{IE} \\in \\{0,1\\}^{E \\times K}\\) with E representing the entities in the target KOS and K representing the number of entity clusters.\nDuring the matching stage, a general matcher function \\(g(x, k)\\) determines the relevance between an instance x (an entity mention) and the k-th entity cluster. The top-b clusters in Cl are identified through \\(g_b(x)\\):\n\\(g_b(x) \\triangleq \\arg \\max_{S \\subseteq C_l: |S| = b} \\sum_{k \\in S} g(x, k)\\)\nThe function \\(g_b(x)\\) attempts to find the subset S of size b included in Cl that maximises the function g evaluated at each S for a given x. The deep text vectorizer is a pre-trained Transformer model, specifically BioBERT. We briefly explored other BERT-based models (BERT, SciBERT, BioBERT, Pub-MedBERT), but we found the differences to be minimal.\nAfter the matching stage, the ranker h(x, e) models the relevance between x and each candidate entity belonging to the clusters previously identified by the matcher function g(x).\nWe trained two PECOS models for two entity types, 'Disease' and 'Chemical. We further describe the generated training data.\nD. Generation of training data with automatic labelling\nDeep-learning-based approaches that focus on specific tasks usually require a vast amount of human-labelled data, which is scarce in the biomedical domain. The annotation process is a bottleneck in the development of such approaches since it is"}, {"title": "E. Entity linking as collective coherence maximization prob- lem: Personalized PageRank", "content": "One of the main obstacles in the EL task is the presence of homonym entities, i.e., entities sharing the same string but with highly different meanings [19]. One way to diminish the impact of such cases is by applying a global approach, which takes into account the document context to perform the linking process. In this type of approach, a given entity mention is linked according to how the other entity mentions present in the same document are linked. We previously demonstrated how the Personalized PageRank (PPR) algorithm can be integrated into such global approach [29], [30].\nIn a given document T, for each entity mention \\(m_i \\in M\\), the approach generates a set of candidate entities \\(C_i\\subseteq E\\). Using these candidates entities, the approach builds a graph disambiguation G, represented as G(N, V), with N as the set of nodes in the graph and V as the set of vertices or edges connecting the nodes. Each node \\(n \\in N\\) corresponds to a pair consisting of an entity mention and its respective KOS candidate. The graph can be described as \\(G = \\{(m, c) | m \\in M,c \\in C\\}\\). The edges between candidate nodes are based on the direct edges defined in the target KOS, for instance, on is-a relationships. The original PageRank algorithm [31] simulates random walks on a graph, and in each walk, there is a teleport probability e of going to a random node and a 1-e probability of going to a node connected with the current one. In the PPR [32] variation, the teleports are always performed to some predefined source node. The stationary distribution resulting from these walks assigns scores or weights to each node in the graph. The PPR algorithm calculates the coherence of each node in the graph G, i.e., how well the node fits into the set of all nodes. The algorithm starts by measuring the pairwise coherence of a source node s and a target node t:\n\\(coherence_s(t) = PPR(s \\rightarrow t)\\)\nFollowing the previous approach developed by our group [29], we enhance the coherence by multiplying it by the infor- mation content (IC) of the node t. This adjustment encourages the algorithm to select more specific entries within the KOS at the expense of more general ones:\n\\(coherence_s(t) = PPR(s \\rightarrow t) \\cdot IC(t)\\)\nWe opted for the intrinsic definition for IC, in which the IC of a KOS entity e is given by its frequency in the respective KOS [33]:\n\\(IC(e) = -log(p(e))\\)\nwhere p is the probability of the entity e and is represented as\n\\(p(e) = \\frac{Desc(e) + 1}{E}\\)\nWhere Desc correspond to the number of child entities or direct descendants of the entity e in the structure of the target KOS, and E is the set of every entity represented in the target KOS.\nAfter calculating all the pairwise coherences for node s, the global coherence of t is given by the sum of its coherence with each source node s:\n\\(coherence(t) = \\sum_{s \\in G} coherence_s(t)\\)\nOne drawback of this approach is its vulnerability to noise propagation. In certain scenarios, there might be multiple entity mentions with \"imperfect\" candidate lists, meaning the list either lacks the correct candidate or contains candidates that are highly unrelated to the initial mention. However, if these unrelated candidates integrate well into the graph, the PPR algorithm may assign them a high score, even though they are not the correct linking decision. The impact of this error type amplifies with the number of entity mentions featuring \"imperfect\" candidate lists.\nDifferent entities require different linking approaches, hence it is essential to combine different approaches to minimize the drawbacks of each one."}, {"title": "F. X-Linker: pipeline for named entity linking", "content": "To deal with different entities, we explore the combination of the previous approaches into a single pipeline, designated by X-Linker. X-Linker is a heuristic that resorts to abbreviation detection, string matching, to the PECOS-EL model and the PPR-based model according to the entity being linked. The overview of the X-Linker pipeline is shown in Fig. 1 and the pseudo-code is shown in Algorithm 1.\nThe algorithm starts by taking a set of entity mentions M and initializing a score threshold for filtering matches out- putted by the respective PECOS-EL model. For each mention m, it applies an abbreviation detector to convert m to its long form long_m. Then, it retrieves candidate matches using a string matcher and the PECOS-EL model, storing results in string_matches and pecos_matches, respectively. If the top candidate from string_matches or pecos_matches has a perfect score (1.0), it is added to the candidate list C. If the top candidate from pecos_matches has a score above the threshold, it is also added to C. If the score is below the threshold, both the top candidate from pecos_matches and the top candidate from string_matches are added to C. Once candidate lists for all mentions are completed, a disambiguation graph G is built based on these candidates. The PPR algorithm is then applied to G to compute scores for each candidate. Finally, for each mention m, the highest-scoring candidate from the PPR results is selected to disambiguate the mention."}, {"title": "IV. EXPERIMENTS", "content": "The datasets used for the evaluation of the several ap- proaches are described in Table II. We selected datasets including annotations of the type \"Disease\u201d or \u201cChemical\" that are commonly used: BC5CDR (819 citations), BioRED (74 citations), NCBI-Disease (843 citations), NLM-Chem (52 citations). From each dataset, we removed the NIL annota- tions, including annotations associated with no KOS identifiers (whose identifier is '-1' or '-'), but also obsolete annotations, i.e., annotations with KOS identifiers that are not present in the KOS version used in our experiments. The performance of an approach in the target evaluation dataset is assessed through the calculation of the top-k accuracy, which is defined as:\n\\(Top-k Accuracy = \\frac{1}{N} \\sum_{i=1}^{N} 1\\{y_i \\in \\{y_{i,1}, y_{i,2},..., y_{i,k}\\}\\}\\)\nwhere:\n\u2022 N is the total number of evaluation instances.\n\u2022 \\(y_i\\) is the true KOS identifier for the i-th instance.\n\u2022 \\(\\hat{y}_{i,1}, \\hat{y}_{i,2},..., \\hat{y}_{i,k}\\) are the top k predicted identifiers (ranked by confidence) for the i-th instance.\n\u2022 1{} is the indicator function, which returns 1 if the true identifier \\(y_i\\) is among the top k predicted identifiers \\(\\hat{y}_{i,1}, \\hat{y}_{i,2},..., \\hat{y}_{i,k}\\), and 0 otherwise.\nBesides the baselines defined in our work, we used the state- of-the-art approach SapBERT [9] for a relative comparison of the performance."}, {"title": "V. RESULTS AND DISCUSSION", "content": "A. Impact of training data in the PECOS-EL model\nTo assess the impact of the size of the training data and of the addition of Pubtator3 annotations, we evaluated the performance of the model PECOS-EL-Disease trained on different versions of the training data as described in Table I. Since the training dataset \"Disease-All\u201d is large (9,497,985), we were not able to train the PECOS-EL-Disease model in this dataset due to the out-of-memory error. The performance of the Disease PECOS-EL model when applied to the different dataset versions is shown in Table III. For the PECOS-EL- Disease model, incorporating Pubtator annotations into the training data enhances performance in the EL task. Moreover, as the number of Pubtator annotations increases, performance improves accordingly. However, there are some caveats. In the NCBI-Disease dataset, the addition of Pubtator annotations to the \"Disease-100\" training dataset decreases the top-1- accuracy to 0.6519 from 0.5961, which was obtained training PECOS-EL-Disease in the \u201cDisease-KOS\" dataset. Training the model in the dataset \"Disease-200\u201d increases the top 1 accuracy to 0.6394, still below the performance of the model trained in the dataset in the \u201cDisease-KOS\" dataset. It's only when PECOS-EL-Disease is trained in the dataset \"Disease- 300\" that the top-1 accuracy surpasses the baseline (0.6837). The highest top-1 accuracy is obtained when the model is trained in the dataset \"Disease-400\": 0.7292. In the BioRED evaluation dataset, the performance of the PECOS-EL-Disease increases with the number of Pubtator annotations in the training data, reaching a maximum of 0.7380. In the BC5CDR- Disease dataset, the performance of the model PECOS-EL- Disease also increases with the number of Pubtator annotations in the training data, peaking when the model is trained in the dataset \"Disease-300\u201d with a top-1-accuracy of 0.7870 and decreasing with the model training in \u201cDisease-400", "Incorrect\" in Table VI). For example, 12.0% of the strings present in the \"Disease\u201d training dataset that are also present in the BioRED-Disease dataset are associated with different identifiers. Even if the KOS identifier that appears associated with a given string in the evaluation dataset is also associated with the same string in the training dataset, there is a relevant part of ambiguity (check column \u201cAmbiguous": "n Table VI), i.e., there are more than one identifier for the string. For example, in the BioRED-Disease dataset, 89.29% of the strings in the training dataset are associated with the correct identifier as defined in the evaluation dataset, but only 49.16% of those strings have only one identifier. The remaining 50.84% strings have more than one associated identifier.\nAs shown in Table VI, there are annotations in the evalu- ation datasets associated with entity names/strings that have an exact match in the respective target KOS. However, not always the identifier associated with the exact matching is the same as the identifier chosen to annotate the entities in the evaluation datasets. This highlights the inherent ambiguity of the annotation process, but also that the task EL does not have a universal definition. The annotation criteria are strictly associated with the scope of the motivation. For example, in the context of an annotation project centred on rare diseases, the annotation guidelines will instruct annotators to prioritise selecting more specific diseases. However, if the project encompasses various entity types simultaneously, such as chemicals, anatomical parts, cell types, etc., the annotation guidelines may not necessitate the same level of specificity as in the case of rare diseases. In such instances, a broader categorization may be sufficient to fulfil the project's objectives. Evaluation datasets are useful to straightforwardly assess the performance of EL approaches, which can be then complemented by more extensive and realistic evaluations, for example, user testing. A rule-based pipeline such as X-Linker helps diminish the impact of these disparities.\nE. Document context improves the performance\nTable V shows the impact of adding the PPR algorithm- based module to the X-Linker pipeline. With the previously mentioned modules, the PECOS-EL module jointly with the abbreviation detector and the string matcher can deal with a large part of the entities present in the evaluation datasets. However, context in the EL task is relevant, since the same entity string can have multiple meanings according to the sur- rounding entities. For that, establishing a measure of coherence between a given entity and the other entities present in the same document can help to disambiguate decisions, as shown in the literature [32], [38].\nFigure 2 shows an example of how the X-Linker pipeline links two entity mentions present in the document with PubMed ID 19263707 from the BC5CDR-Disease dataset to entries in the MEDIC vocabulary: \u201cvasculitic\u201d and \u201cvasculitis.", "Congenital Disorder": "ith identifier D009358 and", "vasculitis": "ith identifier D014657 for the mentions", "vasculitic": "nd"}, {"vasculitis": "espectively. Concurrently, the string matcher retrieves the candidate"}, {"vasculitis": "D014657) from MEDIC for both mentions. In the disambiguation pro- cess, for", "vasculitic": "ECOS-EL-Disease scores low (0.0964), and the string matcher finds a close candidate (score 0.9). Both are added to the candidate list due to the low PECOS- EL-Disease score. For"}, {"vasculitis": "ECOS-EL-Disease scores 1.0, and the string matcher confirms an exact match (MEDIC). Only"}, {"vasculitis": "D014657) is listed. Both lists feature"}, {"vasculitis": "inked in the disambiguation graph by MEDIC relations. The PPR selects \u201cvasculitis", "Chemical": "ntities. Like the PECOS-EL model, SapBERT re- lies on the mention string. Therefore, we also present its results"}, {"title": "VI. CONCLUSION", "content": "We generated large-scale training datasets including auto- matic annotations to train a deep-learning-based XMR ap- proach adapted to the biomedical EL designated by PECOS- EL. This module was integrated into the hybrid pipeline X-Linker, an EL approach including different modules to link disease and chemical entities to the MEDIC and CTD-Chemical vocabularies without the need for human- labelled data. We carried out an extensive evaluation of the X-Linker approach, resulting in top-1 accuracy values of 0.8307, 0.7969, 0.8271, 0.9511, 0.9248, 0.7895 in the datasets BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical, BioRED-Chemical and NLM-Chem, re- spectively. X-Linker demonstrated superior performance com- pared to SapBERT in three datasets: BC5CDR-Disease, NCBI- Disease, and BioRED-Chemical. The source code is publicly available: https://github.com/lasigeBioTM/X-Linker.\nIn future work, we plan to enhance entity linking using X- Linker to connect mentions to the UMLS. While our current study focused on smaller KOS due to computational limits, future directions include adapting PECOS-EL to utilize the UMLS with lightweight BERT-based matchers. Additionally, we'll explore integrating NCBI Gene and Taxonomy data from Pubtator3 for generating training datasets. Currently, PECOS- EL employs a modified K-means algorithm based on string representations of KOS entities, so we aim to boost model performance by exploring different clustering approaches that incorporate KOS information and metadata."}, {"title": "APPENDIX", "content": "IMPLEMENTATION\nOur approach includes as a first step the rule-based abbrevi- ation detector Ab3P created by [39]. To implement X-Linker we used the PECOS framework [26], with the code available at https://github.com/amzn/pecos. Model training was done in two setups: (1) a server including 2 Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz and 8 Tesla M10 GPUs; Total CPU memory: \u2248 64 GB. Total GPU memory: \u2248 64 GB; (2) an HPC cluster with 8 nodes with each 2 x AMD EPYC 7742 processors/node x 64 cores 128 cores, 1024 GB RAM, 40 GB VRAM each GPU, 4 GPU NVIDIA A100 (only 80GB RAM were used for training). Training time varied according to the entity type and the number of instances: Disease-400 (the large file with Disease entities) \u2248 8 hours in the HPC cluster; Chemical \u2248 16 hours. In the X-Linker pipeline, the threshold for candidate filtering is set to 0.1 as the default."}]}