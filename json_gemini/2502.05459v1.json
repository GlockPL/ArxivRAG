{"title": "DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability", "authors": ["Sibasish Dhibar"], "abstract": "White blood cells (WBC) are important parts of our immune system, and they protect our body against infections by eliminating viruses, bacteria, parasites and fungi. The number of WBC types and the total number of WBCs provide important information about our health status. A traditional method, convolutional neural networks (CNN), a deep learning architecture, can classify the blood cell from a part of an object and perform object recognition. Various CNN models exhibit potential; however, their development often involves ad-hoc processes that neglect unnecessary layers, leading to issues with unbalanced datasets and insufficient data augmentation. To address these challenges, we propose a novel ensemble approach that integrates three CNN architectures, each uniquely configured with different dropout and max-pooling layer settings to enhance feature learning. This ensemble model, named DCENWCNet, effectively balances the bias-variance trade-off. When evaluated on the widely recognized Rabbin-WBC dataset, our model outperforms existing state-of-the-art networks, achieving highest mean accuracy. Additionally, it demonstrates superior performance in precision, recall, F1-score, and Area Under the ROC Curve (AUC) across all categories. To delve deeper into the interpretability of classifiers, we employ reliable post-hoc explanation techniques, including Local Interpretable Model-Agnostic Explanations (LIME). These methods approximate the behavior of a black-box model by elucidating the relationships between feature values and predictions. Interpretable results enable users to comprehend and validate the model's predictions, thereby increasing their confidence in the automated diagnosis.", "sections": [{"title": "1. Introduction", "content": "Blood comprises various components, including sugars, hormones, proteins, minerals, carbon dioxide, and blood cells, which are categorized into three main types: red blood cells (RBCs), white blood cells (WBCs), and platelets. These cells, distinct in color, shape, and structure, fulfill specific bodily roles. For example, while RBCs transport oxygen throughout the body, WBCs defend against infectious diseases and foreign bodies, and platelets ensure blood clotting, which is vital for stopping bleeding. The various types of WBCs, namely monocytes, eosinophils, basophils, lymphocytes, and neutrophils (White J., 2020), are instrumental in combating various infections (see Fig. 1). The differential count of the WBCs is done in a complete blood cell count (CBC), which is used to detect any abnormality. Any variation from the average size, maturity, or number of healthy blood cells is analyzed for diagnosing various hematological diseases.\nAn increased count of WBCs often hints at an infection. For instance, in CBC, an escalation in the number of immature leukocytes can be linked with leukemia. An excess or lack of white blood cells may cause various diseases (Ullah et al., 2016). Diagnoses of these diseases are carried out by blood tests. These blood tests are also performed in order to monitor the results of chemotherapy and radiation therapy. WBCs are extensively distributed throughout human blood, lymph, and various tissues, playing a crucial role in maintaining the body's immune function. Nonetheless, their detection and classification remain challenging owing to the human body's RBC-to-WBC and complexity involved in accurately identifying the types of WBCs in a blood smear sample. Recently, there have been significant advances in deep learning techniques applied to medicine, underlining their potential in detecting and classifying WBCs in blood samples.\nDifferent blood cell classification algorithms are primarily focused on classifying WBCs. These algorithms leverage features, appearances, textures, patterns, and various attributes of WBCs extracted using feature engineering techniques in deep learning, which play a crucial role in image classification. Currently, image processing techniques are employed for classification, segmentation, feature extraction, and identification of WBCs (Krizhevsky et al., 2017). Various deep learning models have been introduced to classify WBC images through both manual processes and computer-aided diagnostic machine learning algorithms based on image processing techniques like k-means clustering, decision trees, support vector machines (SVM), and the integration of CNN and RNN, as well as pre-trained models, which are reported in the research paper S\u00e1nchez (2017). These customized CNN models can be further enhanced to achieve higher accuracy rates and improved statistical results."}, {"title": "1.1 Motivation of the research work", "content": "The type and count of WBCs are crucial for diagnosing and managing many diseases. CNN based methods have been identified as effective solutions for WBC classification (Habibzadeh et al., 2013; Sharma et al., 2019; Wang et al., 2018). While CNN-based approaches ensure high classification accuracy through an end-to-end learning schema, their performance can be further enhanced by using deep features extracted at various levels of the CNN architecture. To this end, incorporating feature selection methods can boost WBC classification accuracy by identifying more discriminative features within a lower-dimensional space. Applying feature selection methods to different CNNs can further improve classification accuracy. This paper proposes and evaluates the combination of feature selection methods. It aims to assess individual features versus simple feature combinations and compare the effectiveness of feature selection methods with simple feature combinations to determine the optimal number of selected features.\nThe aim of this research is to enhance classification accuracy by employing multiple customized CNNs through tailored dropout rates and maxpooling strategies. The DCNNs are specifically designed with minimized dropout layers to facilitate effective learning at different feature levels, complemented by corresponding max-pooling layers. The final prediction is determined by aggregating the highest accuracy from individual DCNN outputs. This deep learning model independently learns, trains, validates, and refines features extracted from multiple images. This innovative approach aids in extracting features and patches from input images, thereby improving recognition rates, reducing computational time, and mitigating overfitting issues (Yang et al., 2017). Additionally, the trained images from the three customized models are fed into a CNN, enhancing classification accuracy. Ultimately, the fine-tuned models categorize WBCs into five distinct groups. To improve the interpretability of the model's predictions, LIME (Korica et al., 2021) is utilized."}, {"title": "2. Related research articles review", "content": "In this section, various algorithms for WBC classification are briefly described, particularly those categorized into three types. Additionally, the LIME explainability of the predicted outcomes is discussed.\nThe WBC classification generally falls into three primary techniques: microscopy, flow cytometry, and machine learning (ML). Microscopy-based methods offer high accuracy but are hindered by inefficiencies and prolonged cell culture cycles (Nazlibilek et al., 2014). Flow cytometry has become a widely used technique for blood sample analysis, yet it presents a major limitation it destroys blood samples, making retrospective WBC studies unfeasible (Othman et al., 2017). On the other hand, ML has emerged as the most widely adopted approach due to its simplicity, reliability, and robustness in WBC classification (Ravikumar, 2016). Within the ML framework, WBC classification is achieved through three distinct methodologies: traditional ML algorithms (Nassar et al., 2019; Habibzadeh, Krzy\u02d9, et al., 2013; Huai, T., Zhao, J., & Cao, 2015; Agaian et al., 2018; Al-Dulaimi et al., 2018; Musliman et al., 2021; Cengil et al., 2022; Ahmad et al., 2023; Wang et al., 2024); deep learning (DL) (Duan et al., 2019; Liang et al., 2018; Jiang et al., 2018; Ye et al., 2019; Patil et al., 2021; Khouani et al., 2020; S. Sharma et al., 2022; Girdhar et al., 2022; Dong et al., 2023; Amine Tahiri et al., 2023; Yentrapragada, 2023); and hybrid methods of ML and DL (Zhao et al., 2017; Hegde et al., 2018; S\u00e1nchez et al., 2017; Baydilli & Atila, 2020; \u00d6zyurt, 2020; Baghel et al., 2022; Ha et al., 2022; Zhu et al., 2023).\nTraditional ML algorithms have emphasized the importance of morphological features in accurately classifying WBCs (Nassar et al., 2019). For instance, combining shape, intensity, and texture features with a support vector machine (SVM) classifier achieved an 84% accuracy in classifying 140 digital blood smear images across five WBC types (Habibzadeh et al. 2013). Similarly, an algorithm integrating synthetic features with a random forest (RF) classifier attained a 95.4% accuracy in classifying 800 images of five WBC types (Huai et al. 2015). Additionally, using bi-spectral invariant features with SVM and classification trees resulted in a 96.13% average accuracy in distinguishing 10 WBC types across three datasets: Cellavision, ALL-IDB, and Wadsworth Center (Al-Dulaimi et al., 2018). Furthermore, applying multiple features-such as texture, spatial, and spectral data to an SVM classifier for hyperspectral images of five WBC types led to a 98.3% classification accuracy (Duan et al., 2019). Musliman et al. (2021) utilized HSV segmentation and GLCM for WBC identification, comparing KNN, NBC, and MLP methods, with accuracies of 82%, 80%, and 94% respectively on test data. Cengil et al. (2022) studied the retraining of AlexNet, ResNet18, and GoogleNet architectures using the fine-tuning method with datasets from Kaggle, employing SoftMax and SVM for classification. This approach demonstrated that the hybrid architecture combining ResNet18 with SVM achieved an accuracy of 99.83%. Ahmad et al., (2023) proposed extracting optimal deep features from enhanced and segmented WBC images using DenseNet201 and Darknet53 via transfer learning. They applied an entropy-controlled marine predator algorithm (ECMPA) to filter and select dominant features from a serially fused feature vector. The optimized feature vector was then classified using multiple baseline classifiers with different kernel settings. Wang et al. (2024) employed an unsupervised ML strategy combining dimensionality reduction and eigenvector analysis to explore clinical feature relationships. They discovered that baseline serum WBC counts were predictive of overall survival, showing a significant median survival difference of over six months between the highest and lowest quartiles. Additionally, they noted increased PD-L1 expression in glioblastoma patients with higher WBC counts, identified using an objective PD-L1 quantification algorithm.\nIn recent years, DL has become increasingly prevalent in medical image classification, particularly for WBC identification. For example, Thanh et al. (2018) utilized CNNs to distinguish between two WBC types from the ALL-IDB dataset, achieving a 96.6% accuracy. Similarly, Macawile et al. (2018) applied CNNs to classify five WBC types within the same dataset, reaching an accuracy of 96.63%. Liang et al. (2018) developed a hybrid model combining CNN and recurrent neural network (RNN) architectures to categorize four WBC types in the BCCD dataset, resulting in a 90.79% accuracy. Yu et al. (2017) reported an 88.5% accuracy in classifying seven WBC types using CNNs on a proprietary dataset. Notably, Jiang et al. (2018) achieved an 83% accuracy in identifying 40 WBC types from a substantial dataset of 92,800 images. Further advancements include the dual attention CellNet (DACellNet) model by Ye et al. (2019), which accomplished fine-grained recognition of 40 WBC types with minimal human intervention, attaining accuracy of 84.21% on a leukocyte dataset, 98.78% on ALL-IDB, and 94.7% on the Cellavision database. Patil et al. (2021) proposed a model integrating CNN and RNN with canonical correlation analysis, demonstrating a 95.89% accuracy in classifying four WBC types using public data from the Shenggan/BCCD dataset and Kaggle. Khouani et al. (2020) developed a deep learning method to automatically recognize white blood cells in images, improving hematologists' efficiency with advanced preprocessing and enhanced segmentation techniques. Sharma et al. (2022) implemented a deep learning model using DenseNet121 to classify various types of WBC. The model was optimized with normalization and data augmentation preprocessing techniques. It achieved an accuracy of 98.84%, a precision of 99.33%, a sensitivity of 98.85%, and a specificity of 99.61%. Girdhar et al. (2022) proposed an algorithm to detect WBCs from microscope images, utilizing the simple relationship of colors R and B, along with morphological operations. They then applied a granularity feature (pairwise rotation invariant co-occurrence local binary pattern, PRICOLBP) and SVM to initially classify eosinophils and basophils from other WBC types. Dong et al. (2023) innovatively proposed a white blood cell classification algorithm that combines deep learning features with artificial features. This algorithm not only utilizes artificial features but also leverages the self-learning capabilities of Inception V3 to fully exploit the image's feature information. Amine Tahiri et al. (2023) proposed a classification method divided into two main phases: preprocessing, which computes image moments using a new quaternion Meixner-Charlier hybrid moment characterized by parameters a, \u1e9e, and q, and optimization using the grey wolf algorithm to enhance classification accuracy. More recently, Yentrapragada (2023) designed a combined CNN structure merging AlexNet, GoogLeNet, and ResNet-50 to extract 3000 crucial features. The hybrid mayfly algorithm with particle swarm optimization (HMA-PSO) selects essential features, updating mayfly velocity using PSO.\nTo enhance the accuracy of WBC classification, researchers have developed hybrid methodologies that integrate various feature extraction techniques with different classifiers. For instance, Zhao et al. (2017) combined granular features and CNNs with SVM and RF classifiers to categorize five WBC types across datasets from Cellavision, ALL-IDB, and Jiashan, achieving a 92.8% accuracy. Similarly, Hegde et al. (2018) proposed a hybrid classifier merging SVM and neural networks (NN) for five-category WBC classification, resulting in an average accuracy of 96%. In another approach, Sengur et al. (2019) utilized shape and deep features to represent WBCs and employed a long short-term memory (LSTM) network to classify four WBC types, attaining an 85.7% accuracy. Furthermore, Sahlol et al. (2020) applied an efficient WBC leukemia classification method that incorporated improved swarm optimization of deep features on two datasets, achieving accuracies of 96.11% and 83.3%, respectively. \u00d6zyurt (2020) used AlexNet, VGG-16, GoogleNet, and ResNet as feature extractors, combining outputs from their last layers. Efficient features selected via minimum redundancy maximum relevance were classified using an extreme learning machine (ELM) classifier, diverging from typical CNN approaches. Baghel et al. (2022) presented an automatic classification method using machine learning to classify blood cells from medical images of blood samples. The proposed method can identify and classify each segmented white blood cell image as either granular or non-granular white blood cell types. Ha et al. (2022) proposed a novel semi-supervised WBC classification method called fine-grained interactive attention learning (FIAL). It features a Semi-Supervised Teacher-Student (SSTS) module and a fine-grained interactive attention (FGIA) mechanism, using limited labeled WBC images to generate predicted probability vectors for numerous unlabeled WBC samples. Zhu et al. (2023) introduced DLBCNet for blood cell multi-classification, employing a synthetic image-generating model (BCGAN) and a pre-trained ResNet50 as the feature extractor. The proposed ETRN enhances multi-classification, achieving average accuracy, sensitivity, precision, specificity, and fl-score of 95.05%, 93.25%, 97.75%, 93.72%, and 95.38%, respectively.\nModel-agnostic interpretation methods, often referred to as explainable AI (XAI) models, gained popularity in 2017 for their ability to provide transparency into AI models' results by revealing their underlying mechanisms and logic. Various XAI models have been developed, including instance-based methods like LIME, feature-based methods like SHAP, and gradient-based techniques such as DeepLIFT and Attribution Maps. XAI has revolutionized the healthcare industry by enabling medical professionals and researchers to gain a deeper understanding of AI systems and their decision-making processes. This transparency has made Al systems more accountable and reliable, fostering greater trust among healthcare providers in using AI-based recommendations. Most XAI algorithms are post-hoc and model-agnostic, meaning they can be applied to any black-box model (Ribeiro et al. 2016; Korica et al., 2021)."}, {"title": "3. Preliminary materials and proposed methodology", "content": "In this study, our aim is to develop an efficient method which classifies WBC images into five classes. Thus, for classification purposes, we provide a brief overview of require deep neural networks in the following subsection."}, {"title": "3.1 Convolution neural network (CNN)", "content": "Currently, in the area of computer vision, various CNN pre-trained models e.g., GoogLeNet (Szegedy et al. 2015), ResNet (He et al. 2016), AlexNet (Krizhevsky et al. 2017), and VGGNet (Simonyan & Zisserman, 2014), among others, have been introduced. Such kind models like GoogLeNet and ResNet, are also accessible as pre-trained on around 1.28 million natural images from the ImageNet database. This allows us to utilize the pre-established weights and biases of these models. By adjusting the layers of these models through backpropagation with our specific data, they can be adapted for our unique classification tasks. Conversely, pre-trained models e.g., ResNet and VGGNet are designed with initial weights and biases that remain unaffected by pictorial information not related to our predicted images. Here, we provide a concise summary of these widely utilized CNN architectures."}, {"title": "4 Data experimental and environment setup", "content": "We now outline the experimental setup necessary for training, testing, and validating the proposed DCENWCNet-based model for WBC classification. The training phase involved executing each method for 30 iterations. The technical aspects, along with the mathematical framework discussed earlier, are consolidated into a comprehensive workflow illustrated in Fig. 5. This workflow encompasses three key phases: dataset preprocessing, model training and testing, and blood cell class prediction. Each of these stages is briefly discussed to emphasize the experimental configurations essential for assessing the model's classification performance."}, {"title": "4.1 Data description", "content": "The dataset employed in this research work is Raabin-WBC dataset (Rubin et al. 2023), a comprehensive dermoscopy imaging library consisting of 14514 images and their corresponding diagnostic labels, sourced from various places. The Raabin-WBC dataset comprises five blood cell types: (i) Basophils (ii) Eosinophils (iii) Lymphocytes (iv) Monocytes (v) Neutrophils. Table 2 provides examples of diseases associated with abnormal changes in white blood cell counts. For instance, allergic conditions often lead to an increase in basophils, while blood malignancies result in a rise in blood cell precursors and alterations in their shape and size. Consequently, accurately identifying the type and count of white blood cells is crucial for diagnosing a range of diseases."}, {"title": "4.2 Data pre-processing", "content": "For the classification of white blood cells, we employed a widely recognized dataset, the Raabin-WBC dataset. This dataset comprises a total of 14,514 training images, sourced from a diverse population spanning various ethnicities, ages, genders, and more. It is organized into five distinct classes, with the distribution of images per class detailed in Table 2. The preprocessing of the dataset involves three key steps: (i) balanced sampling of the dataset, (ii) pixel standardization, and (iii) augmentation. Each of these steps is elaborated below, accompanied by the necessary technical specifics."}, {"title": "(i) Dataset balancing", "content": "The dataset is organized in a CSV file (Rubin et al. 2023), containing 17,965 rows, where each row represents a specific image. Each row consists of 2,353 columns, with the last column indicating the class label for the corresponding image. The Raabin-WBC dataset comprises a total of 14,514 microscopic blood cell images. For training (80% of the dataset), the distribution includes 212 Basophils, 744 Eosinophils, 2,427 Lymphocytes, 561 Monocytes, and 6,231 Neutrophils. For testing (20%), the dataset includes 89 Basophils, 322 Eosinophils, 1,034 Lymphocytes, 2,660 Neutrophils, and 234 Monocytes. Table 2 provides detailed information on blood cell types and sample images for both training and testing datasets. The images are represented as pixel values of 64 \u00d7 64 \u00d7 3 RGB images, which have been reshaped to form the final image. The compact dimensions of these images reduce computational complexity while preserving feature integrity, leveraging the CNN backbone architecture's invariance to spatial resolution and scale."}, {"title": "(ii) Data pixel standardization", "content": "Prior to inputting the training images into the model, an effective data normalization technique is applied using the widely recognized Gaussian pixel standardization approach. As described in Eq. (13), this method involves adjusting each pixel by subtracting the mean pixel intensity and normalizing it by the standard deviation of the pixel values within the training dataset. This ensures consistent scaling, improving the model's learning efficiency and stability. If there are outliers and more noise in the data, pixel standardization can indirectly avoid the influence of outliers and extreme values through centralization. In classification problems, when distance is needed to measure similarity, Gaussian pixel-standardization method performs better. Therefore, pixel-standardization is used in this study as per the given formula:\nThis approach facilitates stable training by mitigating the risk of exploding gradients caused by excessively large pixel values. Further details on the processed samples from the Raabin- WBC dataset are provided in Table 3."}, {"title": "(iii) Data augmentation", "content": "Before being utilized for training, the Raabin- WBC dataset undergoes data augmentation to ensure a more balanced distribution among its categories. This process helps mitigate the risk of bias towards classes with a higher count of training images, which would otherwise likely achieve greater accuracy compared to classes with fewer images. For the augmentation of images, the dataset leveraged an image data generator within Keras preprocessing, a component of TensorFlow. The specifics of the augmentation process are detailed in Table 4. As a result of augmentation, the image count in the dataset expanded from 14,514 to 50,024, significantly enlarging the training dataset. This expansion helps reduce the risk of overfitting, as depicted in Fig. 8."}, {"title": "4.3 Software for experiment", "content": "For this investigation, we conducted all comparisons on the same CPU machine and same dataset. The runtime of all techniques was recorded and compared in the experimental findings. To assess classification performance, we utilized the Python-Sklearn library's classification report utility. All experiments in this study were conducted using Python 3.10.0 within a Jupyter Notebook environment. The hardware utilized was an HP laptop equipped with an Intel Core i5 processor operating at 3.20 GHz, 8 GB of RAM, and a 4 GB graphics card. For the implementation of our models, we employed the TensorFlow and Keras libraries."}, {"title": "4.4 Performance metrics", "content": "Performance metrics are essential for measuring the performance of machine learning and deep learning models.\n\u2022 True Positive (TP): normal is appropriately classified as normal.\n\u2022 True Negative (TN): WBC is appropriately classified as WBC.\n\u2022 False Positive (FP): WBC is inappropriately classified as normal.\n\u2022 False Negative (FN): normal is inappropriately classified as WBC.\nIn this proposed work, we concentrate on various key performance metrics to evaluate the efficiency of the proposed research model.\nI. Accuracy: Assesses the model's overall prediction accuracy by determining the ratio between of samples correctly classified out of the total sample count. Reliance on accuracy alone may not provide a comprehensive evaluation, particularly in cases involving imbalanced datasets. However, accuracy is not only always sufficient condition for evaluation, especially when datasets become imbalanced.\nAccuracy = $\\frac{(TP+TN)}{(TP + FP+TN + FN)}$ (11)\nII. Precision: Precision measures is the proportion of true positives out of the total number of predicted positives, summing true positives and false positives. It emphasizes the trustworthiness of positive predictions.\nPrecision = $\\frac{TP}{(TP+FP)}$ (12)\nIII. Recall: This quantity is calculating by the ratio between true positives in relation to the total of true positives and false negatives. It concentrates on the thoroughness of positive predictions.\nRecall = $\\frac{TP}{(TP+FN)}$ (13)\nIV.F1 Score: The F1 score is the harmonic mean of precision and recall, ranging between 0 and 1, where 1 indicates the highest possible performance.\nF1 score = $\\frac{TP}{\\frac{1}{2}TP+\\{FP+FN\\}}$ (14)\nV.Specificity: It is defined as the proportion of true negative in relation to the total of true negative and false positives. It is denoted as:\nSpecificity = $\\frac{TN}{(TN + FP)}$ (15)\nVI. ROC:\nROC=0.5x$\\frac{TP}{TP+FN}$+$\\frac{TN}{TN+TP}$\nIn multi-class classification, accuracy is determined by the proportion of correct predictions (both true positives and true negatives) to the total predictions made, irrespective of the class. Conversely, precision, recall, and F1 score are calculated as weighted averages in multi-class scenarios. This approach takes into account any imbalance among the classes in the dataset."}, {"title": "5 Results and discussion", "content": "This section presents the experimental findings, starting with a detailed statistical analysis of the predicted classes to assess the overall classification performance. The presentation is structured into the following subsections:\n\u2022 Subsection 5.1 display the model's learning progress over epochs, highlighting trends in both loss reduction and accuracy improvement.\n\u2022 Subsection 5.2 provides in-depth statistical review of the model's classification performance.\n\u2022 Subsection 5.3 represent a confusion matrix to visualize the model's performance across various classes, aiding in the identification of misclassifications.\n\u2022 Subsection 5.4 illustrates the model's diagnostic ability by plotting the ROC curve and calculating the AUC, offering a measure of the model's predictive accuracy.\n\u2022 Subsection 5.5 conducts a comparative analysis of the model's performance against benchmarks of other models.\n\u2022 Subsection 5.6 compares our proposed model with existing studies"}, {"title": "5.1 Accuracy and Loss Per Epoch", "content": "Achieving an optimal fit for a deep learning model necessitates a precise alignment between training and testing characteristics, typically evaluated through accuracy vs. epoch and loss vs. epoch curves. This similarity indicates that a DCNN is learning instead rather than just remembering the data and is able to perform equally well on both the seen and unseen data. Conversely, substantial discrepancies between training and testing features suggest that the model performs well only on the training data, indicating overfitting. Therefore, in a well- structured model, accuracy should steadily increase across epochs, while the loss should progressively decline. The training and testing phases should exhibit similar patterns. The key results can obtain as following:\n\u2022 Figs. 4 (i-ii)-5 (i-ii) present the training and testing accuracy, as well as the training and testing loss, over 50 iterations of the proposed DCENWCNet model on the dataset, utilizing both RMSprop and Adam optimizers, respectively.\n\u2022 Fig. 5 (ii) demonstrates that the training accuracy appears to surpass the validation accuracy at almost every point, which is a common occurrence as models tend to perform better on data they have seen before.\n\u2022 The validation accuracy increases alongside the training accuracy, which is a good sign because it means the model is not just memorizing the training data but is also improving its ability to generalize to new data as shown in Fig. 5 (ii)\n\u2022 We have seen a minor case of overfitting in the loss curve of proposed model (see Fig. 5 (i)), especially noticeable in the elevated loss during the latter phases of training. As illustrated in Fig. 5(i) and (ii), the training and test accuracy curves demonstrate that as the number of iterations increases, the model effectively learns, resulting in successful test accuracy outcomes.\n\u2022 As depicted in Fig. 5(i) and (ii), both the training and test loss curves demonstrate that as the number of iterations increases, the model effectively learns, leading to a decrease in the test error rate.\nComparison of Fig. 4 and Fig. 5 reveals that the accuracy results of our proposed model using the Adam optimizer are much better compared to the RMSprop optimizer. Therefore, for further performance metrics and classification accuracy comparisons with existing articles, we will only consider the Adam optimizer."}, {"title": "5.2 Performance of statistical results on image classification", "content": "In this section, we assessed the statistical performance of our method using various evaluation metrics. Specifically, we evaluated recall, precision, and F1-score for each class prediction to measure the method's effectiveness. Statistical examinations of classification performance often indicate the level of certainty in the class prediction made by a deep learning model. These metrics are shown in Table 5 & Table 6 for optimizer RMSProp & Adam, respectively. An ideal model should have unity values for these parameters, indicating that a higher classification performance is achieved as the value approaches unity. From Tables 5 and 6, we obtain the following key results:\n\u2022 Given that the accuracy, recall, and F1 score values in Table 6 are consistently close to 0.98, we may anticipate that the proposed models will effectively categorize the WBC classification.\n\u2022 According to this experimental study, the accuracy obtained is 93.93% with the RMSProp optimizer. Similarly, the performance accuracy for the Adam optimizer is 98.53%. A comparison of overall accuracy rates reveals that the proposed model is quite significant for image classification when using the Adam optimizer.\n\u2022 For example, of Basophil class (see. Table 5), the DCENWCNet model achieves perfect precision and specificity, with a recall of 0.9888 and an F1 score of 0.9944, indicating robust and reliable classification with a support of 89.\n\u2022 The model shows robust performance in classifying WBC images in the Raabin dataset, with high scores across key metrics: an average precision of 0.9782 reflects accurately predicted positive cases; an average recall of 0.9817 confirms the effective identification of true positives; an average F1 score of 0.9834 highlights a well-balanced precision and recall; and an average specificity of 0.9865 shows precise identification of true negatives, underlining the model's overall effectiveness.\n\u2022 The performance metrics indicate that DCENWCNet, with the Adam optimizer, is highly effective for classifying white blood cells in the Raabin-WBC dataset. The model shows excellent precision, recall, F1 scores, and specificity, with consistent performance across all classes, making it a reliable tool for medical diagnostics involving white blood cells.\nIn order to provide a visual representation of the proposed model's classification capability, Fig. 6 displays the classification outputs of a collection of unseen images (i.e., testing dataset). Each image has a label on top that indicates its actual class which is the image's original label as well as its predicted class. The values for each class (0: Basophils; 1: Eosinophils; 2: Lymphocytes; 3: Monocytes; 4: Neutrophils) are shown in Fig. 6. For accurate image classification, the predicted class (Pre:) must match the actual class (Act:). The following classifications were derived from the given datasets:\n\u2022 Fig. 6 presents samples from all five classes, where the predicted class labels accurately match the actual class labels for each sample.\n\u2022 As an example, the top left picture in Fig. 6 belongs to the real class of Basophil (Act: Basophil), and the ensemble architecture prediction for the same image is similarly Basophil (Pre: Basophil). The other images also show instances that are similar.\n\u2022 A Neutrophils (Act: Neutrophils) class is identified as Lymphocytes (Pre: Lymphocytes) in the fourth column of the second row of the figure, for example, on an infrequent misclassify detection.\n\u2022 Therefore, the suggested model accurately predicts almost all occurrences of the predicted class, even with the considerable visual changes within the same class."}, {"title": "5.3 Confusion matrix", "content": "A confusion matrix is applied to summarize the output of a classification system. Classification accuracy by itself may be misleading if the dataset has more than two classes or if the number of observations in each class is different. The confusion matrix is made up of four major features (numbers) that define the classifier's metric of measurement. TP, TN, FP, FN are the four numbers. One may have a deeper comprehension of the categorization model's achievements and shortcomings via the computation of a confusion matrix. The diagonal cells should approach the deep learning model to function well, indicating the model's accurate prediction for the relevant class. In both figures, the first confusion matrix is a normalized confusion matrix, where the values represent the proportion of correctly and incorrectly classified instances out of the total number of true instances for each cell type. The second matrix shows raw counts of classified instances, providing insight into the actual number of correct and incorrect predictions.\nFig. 7 (i-ii) and Fig. 8 (i-ii) showcase the confusion matrices for the average and weighted ensemble models recommended, utilizing both the RMSProp and Adam optimizers. The best model attains an accuracy of 98.93% after only 50 epochs for 5 classes. Fig. 8(i) reveals that high values on the diagonal indicate strong model performance, with Basophil and Lymphocyte classifications showing near-perfect accuracy (1.00 and 0.97, respectively), while Monocyte classification is slightly less accurate (0.89). In Fig. 8(ii) presents the DCENWCNet model correctly predicted 89 Basophils, 295 Eosinophils, and 2587 Neutrophils, but misclassified some instances, such as 45 Eosinophils misclassified as Neutrophils. From both Fig. 7 and Fig. 8, the Adam optimizer demonstrates superior overall classification accuracy, particularly for Neutrophils and Lymphocytes. Conversely, the RMSprop optimizer results in fewer misclassifications for Neutrophils and exhibits slightly enhanced performance for Eosinophils."}, {"title": "5.4 ROC with testing", "content": "We utilized the ROC curve to assess classifier performance by plotting the true positive rate (TPR = TP/(TP + FN)) against the false positive rate (FPR = FP/(TN + FP)) for the RMSProp and Adam optimizers. To ensure reliable predictions on new data, the dataset was split into 80% for training and 20% for testing using the scikit-learn library, maintaining balanced representation across all five classes. Figs. 9(i) and 9(ii) depict the ROC curves for the proposed DCENWCNet models optimized with RMSProp and Adam, respectively. The ROC curve and AUC score were computed for each class under this evaluation framework. Efficient algorithms, transfer learning strategies, and optimization techniques such as RMSProp and Adam contribute significantly to reducing model training time. The AUC values for all class labels surpass those obtained using the RMSProp and"}]}