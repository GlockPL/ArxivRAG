{"title": "Metaheuristic Enhanced with Feature-Based Guidance and Diversity Management for Solving the Capacitated Vehicle Routing Problem", "authors": ["Bachtiar Herdianto", "Romain Billot", "Flavien Lucas", "Marc Sevaux"], "abstract": "We propose a metaheuristic algorithm enhanced with feature-based guidance that is designed to solve the Capacitated Vehicle Routing Problem (CVRP). To formulate the proposed guidance, we developed and explained a supervised Machine Learning (ML) model, that is used to formulate the guidance and control the diversity of the solution during the optimization process. We propose a metaheuristic algorithm combining neighborhood search and a novel mechanism of hybrid split and path relinking to implement the proposed guidance. The proposed guidance has proven to give a statistically significant improvement to the proposed metaheuristic algorithm when solving CVRP. Moreover, the proposed guided metaheuristic is also capable of producing competitive solutions among state-of-the-art metaheuristic algorithms.", "sections": [{"title": "1 Introduction", "content": "Routing represents a significant activity in logistics and supply chains, involving the movement of products or goods, from one location to another. This process is crucial for driving economic and social activities, impacting various aspects of daily lives (Arnold and S\u00f6rensen, 2019b). The main challenge arises from the increasing delivery costs, that may directly influence the pricing of goods. Optimizing the delivery routes becomes one significant solution for mitigating this problem (Simchi-Levi et al., 2002). Various routing problems exist, with one of the most studied being the Capacitated Vehicle Routing Problem (CVRP) (Toth and Vigo, 2014; S\u00f6rensen and Schittekat, 2013; Prodhon and Prins, 2016; Arnold and S\u00f6rensen, 2019a; Accorsi and Vigo, 2021). The first research that attempted to solve the CVRP was performed by Dantzig et al. (1954). Yet, despite decades of study, the CVRP remains a challenging problem in laboratory and industrial applications (Prins, 2004; Laporte, 2009).\nRecently, there has been a growing interest in using Machine Learning (ML) to enhance optimization algorithms (Bengio et al., 2021). However, many optimization algorithms start from scratch for similar problem types, ignoring valuable insights from previous solutions. Utilizing historical data could offer efficient and effective ways to improve optimization algorithms Arnold and S\u00f6rensen (2019b). Furthermore, the optimization algorithm can learn from its own decisions, adapting its behavior for improved performance. In parallel, Explainable Artificial intelligence (XAI) offers techniques that can identify the strongest features, as well as investigate how these features behave for making a decision (Lundberg and Lee, 2017; Arrieta et al., 2020; Lundberg et al., 2020).\nIn this research, we aim to solve CVRP by developing a hybrid ML and metaheuristic algorithm. Our approach involves developing a learning model that can learn how to achieve an optimal quality solution, based on the problem features. Subsequently, we try to interpret the developed learning model and use these insights to formulate a guidance able to boost the performance of the metaheuristic algorithm."}, {"title": "1.1 Related Work", "content": "The CVRP can be characterized as an undirected graph G = (V, E). The set of nodes V is composed of a depot D and a collection of customer nodes C, where $C = C_1, C_2, ..., C_N$ and $N = |V| - 1$ represents the set of customers (excluding the depot). Then, the set of customers neighboring $c_i$ can be referred to as the neighborhood of $c_i$, denoted as $N(c_i)$ (Prodhon and Prins, 2016). The CVRP is an extended version of the Vehicle Routing Problem (VRP). In CVRP, a set of valid routes R is defined as a collection of routes, where a route can be defined as a sequence of nodes, with the first and last nodes being the depot D and the remaining nodes representing customers $C_k$, in which the total demand of customer nodes does not exceed the capacity Q of identical vehicles in the fleet. Therefore, a CVRP solution is considered feasible when it consists of valid routes, ensuring each customer is visited exactly once. The CVRP aims to determine a feasible solution that minimizes the sum of route costs for all routes in the solution (Laporte, 2009).\nMetaheuristics for solving the CVRP Heuristics and local search mechanisms are the main components of metaheuristics (Prodhon and Prins, 2016). In Glover (1997), a tabu search heuristic was proposed, allowing the algorithm to escape local optima by preventing cyclic evaluation. Following this, Granular Neighborhoods mechanism (GNs), proposed by Toth and Vigo (2003), defines a heuristic filtering of less promising neighbors. This mechanism, when combined with the tabu search, has empirically demonstrated an excellent trade-off between computation time and solution quality (Toth and Vigo, 2003), even with very large scale problems, up to 30,000 customers (Accorsi and Vigo, 2021). Another way for enhancing tabu search involves bolstering the intensification mechanism while preserving solution diversity through the integration of the path relinking (Glover, 1997; Glover et al., 2000) procedure. In parallel, Prins (2004) introduced a new representation of the solution, called the giant tour, and a splitting mechanism to transform it into a VRP solution. In Prins (2004), this was implemented alongside population-based metaheuristic, and further refined and applied to solve a broad range of VRP variants (Vidal et al., 2014), and has particularly proven to effectively solve the CVRP (Vidal, 2022) up to 1,000 customers. Path relinking, as proposed by Glover (1997), has been proven to enhance the intensification strategy of tabu search (Laguna et al., 1999; Ho and Gendreau, 2006). In S\u00f6rensen and Schittekat (2013), a metaheuristic algorithm is proposed to hybridize path relinking with GRASP (Greedy Randomized Adaptive Search Procedure) and VND (Variable Neighborhood Descent). However this study highlights a limited contribution of path relinking compared with the simple hybridization of GRASP and VND.\nHybridizing machine learning with metaheuristic for solving CVRP The integration of machine learning (ML) and optimization algorithms can be classified into three strategies, as outlined by Bengio et al. (2021): (1) end-to-end learning, (2) learning based on problem properties, and (3) learning repeated decisions. The concept of learning based on problem properties entails utilizing ML to formulate a configuration (in a broad sense) for the optimization algorithm. Meanwhile, the mechanism of learning repeated decisions is applied by constructing an in-loop ML-assisted optimization algorithm to allow the algorithm to learn from its own decisions and adapt its behavior. Recent studies have aimed to enhance the performance of metaheuristics by hybridizing them with ML when solving the CVRP.\nThe hybridizing mechanism may initially involves by analyzing the structure of the parent problem of the CVRP, that is the VRP, through statistic analysis and classification model (Arnold and S\u00f6rensen, 2019b). Arnold and"}, {"title": "1.2 Research Questions and Contributions", "content": "In Arnold and S\u00f6rensen (2019a), the authors have shown that clearly defining the preferred structural properties of an optimal VRP solution is highly valuable for designing an efficient heuristic. Furthermore, with more interpretation by using an explainable learning model, we can change our way of solving VRP (Lucas et al., 2019). An ML model, through the learning phase, builds predictive models that can map data features into a class (Guidotti et al., 2018). Then, the explanation of these models gives insights into how the models utilize features to make decisions. As Guidotti et al. (2018) describes, the ranking of the relative importance of the problem attributes can be incorporated into guidance rules. Inspired by those advances, in this research, our main questions are:\n1. How can we extract the most important features of a good solution and use them to guide a heuristic?\n2. To what extent does the developed heuristic bring a significant improvement for solving the CVRP?\nTo address these questions, we propose a simple mechanism of hybridization between ML and metaheuristics by adopting the concept of \"learning to configure algorithms\". Here, we introduce an explainable learning framework for classifying the quality of the VRP solution. This is done by generating a dataset of VRP features and developing a classification model that can identify the features that have the most significant influence, then explaining the developed model to study the feature that influences the quality of the solution. Furthermore, we introduce a metaheuristic for solving the CVRP that consists of neighborhood search and path relinking. In our proposed metaheuristic, we also present a novel mechanism of path relinking for solving CVRP that hybridizes with the split algorithm. Ultimately, we present a feature-based guidance applied to the proposed metaheuristic. In summary, the main design steps and contributions of this research are the following:\n1. We generate a dataset of features related to the instances and solutions of VRP. This dataset contains optimal solutions and near-optimal solutions. This dataset is generated by solving all 10,000 XML100 instances, introduced in Queiroga et al. (2021).\n2. We develop and explain a machine learning model that classifies a solution as good or not based on its features. By explaining this model, the most important features are identified.\n3. Based on this knowledge, we formulate a guidance for managing the diversity of the solution during the optimization processes whenever the metaheuristic algorithm solves a problem.\n4. For implementing our proposed guidance, we develop a new metaheuristic algorithm for solving CVRP. Our proposed algorithm is composed of neighborhood improvement and path relinking.\n5. In our proposed metaheuristic, we propose a novel mechanism of path relinking for solving the CVRP. Our proposed path relinking mechanism compromises with the giant tour concatenation and hybridizes with the split algorithm. We show that our proposed path relinking mechanism can contribute statistically significantly to the proposed algorithm's overall mechanism but also compete with state-of-the-art algorithms."}, {"title": "2 Learning From Solutions", "content": "Here, let assume X as the set training samples, with size N, that consist of a set of problem features $x^{(i)}$ and its label $y^{(i)}$, such that: $x^{(i)}, y^{(i)} \\in X^{(i)}$, where $i \\in N$. For every $x \\in X$, we have a set of pfeatures, such that $x = [X_1,..., X_p]$. Here, the label $y \\in X$ represents the quality of the solution as a binary variable, such as:\n\n$y =\\begin{cases}\n1 & \\text{if it corresponds to an optimal solution} \\\\\n0 & \\text{if it correspond to a near-optimal solution}\n\\end{cases}$\n\nThen, the aim of the learning model f(x) is to classify between optimal and near-optimal solutions, such as:\n\n$f(x) =\\begin{cases}\n1 & \\text{if it corresponds to an optimal solution} \\\\\n0 & \\text{if it corresponds to a near-optimal solution}\n\\end{cases}$\n\nIn this paper, our proposed methodology to develop a learning model is composed of three main steps: (1) generating a dataset, (2) performing classification using several learning models, and (3) explaining the developed learning model by using SHAP values (as shown in Figure 1). The dataset alongside the source code and the documentation for performing the analysis can be downloaded at https://github.com/bachtiarherdianto/MS-Feature."}, {"title": "2.1 Data Generations and Feature Extractions", "content": "The CVRP has a great variety of instances according to the following attributes (Uchoa et al., 2017): (1) the positioning and number of customers, (2) the positioning of the depot, (3) the distribution of demand, and (4) the average route size or the number of routes. In this research, we use the 10,000 XML100 instances\u00b9 from Queiroga et al. (2021) to generate a dataset that is used to develop a learning model f(x)."}, {"title": "2.2 Learning Model: Binary Classification", "content": "Several supervised classification algorithms have been developed, such as K-Nearest Neighbors (Fix, 1985; Cover and Hart, 1967), Decision Tree Classifier (Breiman et al., 2017), and Random Forest (Breiman, 2001). Some boosting algorithms for classification, such as the Gradient Boosting classifier (Friedman, 2001), Extreme-Gradient Boosting (X-Gradient Boosting) (Chen and Guestrin, 2016), and Light Gradient Boosting (Ke et al., 2017) have also been tested. Those algorithms were fed using our dataset of VRP features, implemented in Python, and performed on a 64-bit mini-computer with an AMD Ryzen 7 PRO 5850U processor and 16 GB RAM running on Ubuntu 22.04.1 operating system. Based on a classical train/test procedure, the performances are compared to the $F_1$-score. As described by Sokolova et al. (2006), the $F_1$-score can be calculated as:\n\n$F_1-\\text{score} = \\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$"}, {"title": "2.3 Explaining The Learning Model", "content": "Explainable AI offers necessary insights into how a developed AI system learns, makes decisions, and represents information (Arrieta et al., 2020). Various approaches exist to achieve model explainability, as described in Arrieta et al. (2020). One notable approach is the SHAP model (SHapley Additive exPlanations) (Lundberg and Lee, 2017; Lundberg et al., 2020; Baptista et al., 2022). The SHAP calculates the impact of each feature on the predictions made by the trained model Lundberg and Lee (2017). As shown in Table 1, here we will calculate the SHAP value of the Gradient Boosting classifier. The distribution of the SHAP values for each feature from the Gradient Boosting classifier is illustrated in Figure 3."}, {"title": "2.4 Integration into the Metaheuristic", "content": "Guidotti et al. (2018) describes that the ranking of the relative importance of the problem attributes can be incorporated into rules. As shown in Figure 3, S19 and S20 have a higher magnitude in their corresponding SHAP value than other features. Thus, based on our explanation related to the features, particularly about features S19 and S20 in Section 2.3, we define a hypothesis about how to control the diversity of solution in the pool of elite solutions when solving the CVRP, based on the most important features.\nHypothesis: features related to capacity utilization can be used to control the diversity of a pool of elite set of solutions\nTo test our hypothesis, we first develop a metaheuristic algorithm to solve the CVRP, and then we will enhance the proposed metaheuristic algorithm using guidance from our previous explanation of the learning model. In Section 5.2, we will perform a computational experiment to investigate our hypothesis."}, {"title": "3 Development of the Metaheuristic Algorithm", "content": "This section proposes a new metaheuristic algorithm for solving the CVRP named the Multiple Search (MS) algorithm. The general overview of the MS algorithm is shown in Algorithm 1. The MS algorithm consists of a construction phase (line 2) and a further improvement phase that comprises neighborhood search improvement and path relinking. Moreover, to enhance diversity and intensification mechanism, we introduce a new hybrid split and path relinking mechanism into our proposed metaheuristic. Subsequent paragraphs provide a detailed description of the proposed algorithm, including the novel hybrid split and path relinking."}, {"title": "3.1 Generating Initial Solutions", "content": "The initial solution is constructed using a savings algorithm proposed by Clarke and Wright (1964). As demonstrated by several authors (Arnold and S\u00f6rensen, 2019a; Accorsi and Vigo, 2021), the algorithm can be accelerated by only considering a pruned number new of neighbors j in New (C) for each customer i in C when computing the saving value. The number of neighborhoods for the Clarke and Wright algorithm, New, is set to 100, summarized in Table 3. As in the proposed algorithm, the minimum number of generated initial solutions is $E_{min}$. Thus, after the algorithm generates an initial solution by using the Clarke and Wright algorithm, another solution is generated by performing tour perturbations. The main idea of tour perturbation is to destroy two random routes from the solution, resulting from the Clarke and Wright algorithm, and insert all customers into their best position in the remaining routes. If we do not find any sufficient position for insertion, we construct a new route for that customer node with 50% chance. The solution will be accepted whenever it is a feasible solution with a total cost smaller than the solution generated by the Clarke and Wright algorithm or has the same/smaller number of routes as the estimated number of routes $R_{estimated}$. The $R_{estimated}$ is a lower bound of the number of routes needed for the current instance and is calculated as follows.\n\n$R_{estimated} = \\frac{\\sum_{i \\in N} q(c_i)}{Q}$"}, {"title": "3.2 Pool of the Elite Set Solutions", "content": "The pool of the elite set of solutions is a collection of a small number of solutions found during the search process. The size of the pool is described in Table 3, consisting of its minimum size $E_{min}$, and its maximum size $E_{max}$. The pool of elite set solutions starts empty. If the pool is not yet full, the candidate is simply added to the pool, provided it differs from all existing elite set members. Once the pool is full, if the new candidate is better than the current members, it replaces the worst member. The detailed process is shown in Algorithm 2."}, {"title": "3.2.1 Diversity Control Mechanism", "content": "The diversity control mechanism controls the level of diversity of the small number of solutions in the pool while maintaining the quality of solutions (S\u00f6rensen and Sevaux, 2006). Mart\u00ed et al. (2013) proposed a multi-start mechanism where the algorithm will be restarted and construct a new initial solution whenever it finds a local optimum that is unlikely changed.\nBuild upon by these studies, we try to manage the solutions in the pool by measuring its non-improving iterations. The detailed mechanism used in the proposed algorithm is shown in Algorithm 4. The algorithm will re-generate solutions whenever $v$ exceeds the maximum limit of non-improving iterations, $\\Theta_E$."}, {"title": "3.3 Neighborhood Improvement", "content": "In the proposed algorithm, the neighborhood improvement processes are composed of two major steps: perturbation and local search improvement. The full mechanism of neighborhood search is shown in Algorithm 5. The perturbation mechanism is done by destroying and reconstructing a set of tours in the solution. The local search improvement is implemented through various local search operators, which are categorized into two groups. Within each group, the local search operators are randomly ordered."}, {"title": "3.3.1 Perturbation Mechanism", "content": "The perturbation mechanism prevents the algorithm from becoming trapped in local optima during optimization processes. The proposed perturbation mechanism used for this metaheuristic can be seen in Algorithm 6. In summary, the algorithm attempts to change the structure of solutions by randomly destroying a set of routes and inserting the customer nodes (from the destroyed route) around their neighbor nodes. If there is no suitable location for relocating the node, then a new route is created for that customer node."}, {"title": "Perturbation mechanism according to Estimated Route Sizes", "content": "In the proposed metaheuristic, we apply a perturbation strategy based on the estimation of the number of customers in a route. This estimation is calculated using Equation (6). We categorize the perturbation strategy as destroy strategy and rebuilding strategy. For example, if an instance is categorized as a short route, we will destroy a random pair of routes. However, if an instance is categorized as a long route, we will only destroy one random route. This mechanism based on $k_{estimated}$ value is also applied whenever we perform parameter setting in the beginning of the algorithm, summarized in Table 3.\n\n$k_{estimated} = \\frac{Q}{N+1} \\begin{cases} \\text{long routes:} & \\text{if } k_{estimated} > 20 \\\\ \\text{short routes:} & \\text{otherwise} \\end{cases}$"}, {"title": "3.3.2 Local Search Improvement", "content": "In metaheuristics, local search is known as a strong tool for improving a solution (Arnold and S\u00f6rensen, 2019a). The basic idea underlying local search is that high-quality solutions to an optimization problem can be found by iteratively improving a solution using small (local) modifications called moves."}, {"title": "3.4 Path Relinking", "content": "In path relinking, the initial solution should be improved toward guiding solution (Ho and Gendreau, 2006). However, in the VRP solution, the number of routes (strings of solution) is mostly more than one, so it is a challenge to ensure that the initial solution perfectly transforms toward the guiding solution. Apart from that, Prins (2004) introduces an approach in VRP that represents the solution as a permutation of visits, a string, called as Giant Tour (GT), and transforming the GT into VRP solution using the split algorithm (described in Algorithm 14)."}, {"title": "Truncated Path Relinking", "content": "Resende and Ribeiro (2005) demonstrated that there tends to be a higher concentration of better solutions close to the initial solutions explored by path relinking. Additionally, we may reduce the computational time while still possible to obtain good solutions by adapting this mechanism. As described by Glover et al. (2000), adapting the truncated path relinking mechanism when exploring the restricted neighborhood can be done by introducing $npr$ as the index defining the portion of the path to be explored, where $0 < npr \\le 1$, which the best value is shown in Table 3. As we utilized $npr$, instead of evaluating all $A_{pr}$ restricted neighborhoods, we will use $N_{pr}$ as the main loop for evaluating the restricted neighborhood."}, {"title": "4 Hybridizing Metaheuristics with Feature-Based Guidance", "content": "As outlined in our hypothesis in Section 2.4, we aim to use the most important feature to formulate rules for enhancing the performance of our proposed metaheuristic algorithm. In this section, we detail how we construct a rule based on our explainability learning model to boost the performance of our proposed metaheuristic algorithm, which has been described before in Section 3."}, {"title": "4.1 Guidance for Diversity Control", "content": "In Section 3.2.1, we simply rely on the number of non-improving iterations $v$ to determine whether the pool E is still worth to improve or should the algorithm re-generate the pool E. Hence, through Section 2.3, we understand that the quality of the solution can be measured by its capacity utilization."}, {"title": "4.2 Metaheuristic with Guidance for Diversity Control", "content": "As shown in Equation (9), we denoted the guidance as W, where it can be applied as shown in Algorithm 11. Then, the full mechanism of the guided version of Algorithm 1 can be written as follows: In the following section,"}, {"title": "5 Experiment and Analysis", "content": "The algorithm was implemented in C++ and compiled using g++ 8.3.0. For all algorithms tested in this paper, the experiment was performed on a 64-bit mini-computer with an AMD Ryzen 7 PRO 5850U processor and 16 GB RAM, running on Ubuntu 22.04.1 operating system. As the randomized processes of the algorithm, we follow an experiment procedure from Accorsi and Vigo (2021) where each experiment involved a set number of five runs for every instance, with the seed of the pseudo-random engine defined as the run counter minus one. Throughout the experimentation, we refer to the following:\n* BKS: the total cost value of the best-known solutions. All the information related to the instances and best-known solutions are available at http://vrp.galgos.inf.puc-rio.br/index.php/en/.\n* Gap: the difference between the obtained solution and the best-known solution of the problem. The gap value is calculated as follows:\n\n$Gap = \\frac{\\text{Obtained Solution} - BKS}{BKS} \\times 100\\%$"}, {"title": "5.1 Parameter Tuning", "content": "The parameters used consist of parameters for pruning the Clarke and Wright when constructing a solution, parameters to control the size of the pool of elite set solution, and the search intensification. Furthermore, we also vary several parameters based on the estimated number of customers for every route. The variation mechanism is similar to that described in Section 3.3.1 and defined using Equation (6). The details for these values are summarized in Table 3."}, {"title": "5.2 Computational Experiment with XML100 Instances", "content": "To investigate whether our proposed guided metaheuristic in Algorithm 12 can outperform our proposed metaheuristic in Algorithm 1, we will perform a computation experiment using XML100 instances, from Queiroga et al. (2021). The computational experiment was performed by using 100 randomly sampled XML100 instances. In this experiment, we use the MNS-TS algorithm as a baseline for comparing our proposed algorithms, as it was also already used for generating near-optimal data, described in Section 2.1. In this experiment, the baseline algorithms and all proposed algorithms are given a 60-second time budget to solve each sampled XML100 instances. Computational results of the baseline algorithm, all proposed proposed algorithms on sampled XML100 instances, are summarized in Table 4."}, {"title": "5.3 Testing the Guided Metaheuristic on X Instances", "content": "The detailed result on the X instances (Uchoa et al., 2017) for the Guided-MS algorithm is presented in Table 6. We compared the performance of the Guided-MS with several state-of-the-art metaheuristic algorithms for solving the CVRP, such as: LKH-32 (Helsgaun, 2017), HGS\u00b3 (Vidal, 2022), and FILO Accorsi and Vigo (2021). As all the source codes are available, we execute our proposed algorithm and all the state-of-the-art algorithms under similar conditions using a similar mini-computer.\nWe follow experiments from Vidal (2022), where we set the termination criteria for all algorithms is the maximum computation time, $T_{max} = N \\times 240/100$ seconds, in which N represents the number of customer nodes. As also described in Section 5, here we execute all the baseline algorithms five times with five different random seeds, where each seed was executing one algorithm run. From table Table 6, although the proposed guided metaheuristic cannot outperform all the state-of-the-art metaheuristic algorithms, it can still outperform the LKH-3. Also, for some small instances, the proposed guided metaheuristic can perform similarly with the HGS and FILO. Hence, we can conclude that the proposed guided metaheuristic is competitive with the state-of-the-art metaheuristics tested in the Table 6."}, {"title": "6 Conclusion", "content": "In this paper, we have presented a method to enhance a metaheuristic algorithm for solving CVRP by formulating a feature-based guidance. To formulate the proposed feature-based guidance, we have developed and explained the solution learning model that can classify whether the resulting solution is good or not based on both instances and solutions features inputs.\nFurthermore, to implement our proposed guidance, we have developed a new metaheuristic algorithm composed of neighborhood improvements and path relinking. As our proposed algorithm utilizes path relinking, we have also proposed a novel mechanism of path relinking that compromises with the giant tour concatenation and hybridizes with the split algorithm. Here, we also show that our proposed path relinking mechanism can make a statistically significant contribution to the overall mechanism of the proposed algorithm. Finally, the resulting proposed guidance can statistically improve the performance of our proposed metaheuristic algorithm. Furthermore, we have also shown that our proposed guided metaheuristic competes with other state-of-the-art algorithms for solving the CVRP.\nFrom a more general perspective, we understand that by only utilizing simple feature-based guidance, we are still not unlocking the full performance of ML to improve the metaheuristic algorithm. For future work, we will try to enhance the influence of the ML on the proposed hybrid algorithm. Thus, we plan to adapt the mechanism of learning repeated decisions. In the next proposed hybrid algorithm, our objective is to develop a hybrid algorithm that will adjust its decision and its behavior automatically."}, {"title": "A Appendix", "content": "A.1 Feature of VRP\nMathematical notations for features of VRP In the context of VRP features, let R represents the set of all routes in a solution. A route, denoted as $r_k = C_1, C_2,..., C_k \\in R$, comprises a sequence of nodes. The rank of the neighborhood between nodes $c_i$ and $c_j$ is denoted as $R_{ij}$. We define $R_k$ as the average rank of the neighborhood for each member of route k, calculated as $R_k = (\\sum_{i,j\\in k}R_{ij})/k$. Each route $k \\in \\{r_1,r_2,...,r_k\\} \\in R$ consists of edges $(D, C_1), (C_1, C_2), . . ., (c_k, D) \\in E$, where D represents the depot. The Euclidean distance between nodes $c_j$ and $c_k$ is denoted as $d(c_j, c_k)$. Additionally, $x(c_k)$ and $y(c_k)$ represent the x and y-coordinates of node $C_k$ respectively, with $|x|$ indicating the absolute value of x. The demand of node $c_j$ is denoted as $q(c_j)$. The x-coordinate of the center of gravity $G_k$ of route k is given by $x(G_k) = (\\Sigma x(c_k)+x(D))/k+1$, and the y-coordinate is computed as $y(G_k) = (\\Sigma y(c_k)+y(D))/k+1$ (Arnold and S\u00f6rensen, 2019b). Additionally, we define $L_{Gk}$ as the line passing through D and $G_k$, and $d(L_{Gk}, c_i)$ as the distance between line $L_{Gk}$ and customer $c_i$. The distance is positive when the customer is on the right side of the line and negative otherwise. We also introduce $rad(c_j, c_k)$ to denote the difference in radians between nodes $c_j$ and $c_k$ concerning the depot D, representing the angle spanned between the lines connecting each node with the depot. Finally, $I(r_1,r_2)$ denotes the number of intersections between routes $r_1$ and $r_2$\nInstance Features Here are the specific details about features that depend on the respective instance. These features are drawn from the research of Arnold and S\u00f6rensen (2019b) and Lucas et al. (2020).\nI01: Number of customers\n$I01(S) = N = |V| - 1$\nI02: Number of vehicles\n$I02(S) = |R|$\nI03: Degree of capacity utilization\n$I03(S) = \\frac{\\sum_{i \\in N} q(C_i)}{Q \\cdot R}$\nI04: Average distance between each pair of customers\n$I04(S) = \\frac{\\sum_{i,j \\in N\\ \\text{i != j}} d(C_i, C_j)}{N}$\nI05: Standard deviation of the pairwise distance between customers\n$I05(S) = \\sqrt{\\frac{\\sum_{i,j \\in N\\ \\text{i != j}} (d(c_i, C_j) - I04)^2}{N}}$\nI06: Average distance from customers to the depot\n$I06(S) = \\frac{\\sum_{i \\in N} d(c_i, D)}{N}$\nI07: Standard deviation of the distance from customers to the depot\n$I07(S) = \\sqrt{\\frac{\\sum_{i \\in N} (d(c_i, D) - I06)^2}{N}}$\nI08: Average radians of customers towards the depot\n$I08(S) = \\frac{\\sum_{i \\in N} rad(c_i, D)}{N}$\nI09: Standard deviation of the radians of customers towards the depot\n$I09(S) = \\sqrt{\\frac{\\sum_{i \\in N} (rad(c_i, D) - I08)^2}{N}}$"}, {"title": "A.2 Feature Engineering", "content": "Feature engineering, also known as feature discovery, involves extracting characteristics, properties, or attributes from raw data to facilitate the training of downstream statistical models (Hastie et al., 2009). As outlined in Section 2.1, the dataset generated for this research is divided into two groups: optimal and near-optimal solutions. Both optimal and near-optimal solutions are obtained by solving all 10,000 XML100 instances (Queiroga et al., 2021). These instances consist of a similar number of customer nodes, totaling 100 nodes each. However, they vary across different categories, such as the position of their depots, the distribution of customers, the distribution of demands, and the average size of the routes in their optimal solutions. In total, there are 378 groups of instances. The first 172 groups contain 27 instances each, while the remaining 206 groups contain 26 instances respectively. Furthermore, the dataset comprises 20,000 data points, with an equal distribution of optimal and near-optimal solutions. The features utilized for classification in the proposed learning model are categorized into two groups: instance features and solution features, which are comprehensively described in Appendix A.1."}, {"title": "A.3 Concatenation Method and Split Algorithm", "content": "Prins (2004) shows an innovative approach for solving CVRP, called \"route-first cluster-second\" paradigm. The approach is started by forming a giant tour (refer to Figure 13).\nIn this research, the giant tour T of solution S is formed by using a simple randomized concatenation. The concatenation process starts by identifying the head customer of every router \u2208 R. Thus, the process is continued by randomized concate the route"}]}