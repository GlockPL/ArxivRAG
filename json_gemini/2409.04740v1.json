{"title": "Up-sampling-only and Adaptive Mesh-based GNN for Simulating Physical Systems", "authors": ["Fu Lin", "Jiasheng Shi", "Shijie Luo", "Qinpei Zhao", "Weixiong Rao", "Lei Chen"], "abstract": "Traditional simulation of complex mechanical systems relies on numerical solvers of Partial Differential Equations (PDEs), e.g., using the Finite Element Method (FEM). The FEM solvers frequently suffer from intensive computation cost and high running time. Recent graph neural network (GNN)-based simulation models can improve running time meanwhile with acceptable accuracy. Unfortunately, they are hard to tailor GNNs for complex mechanical systems, including such disadvantages as ineffective representation and inefficient message propagation (MP). To tackle these issues, in this paper, with the proposed Up-sampling-only and Adaptive MP techniques, we develop a novel hierarchical Mesh Graph Network, namely UA-MGN, for efficient and effective mechanical simulation. Evaluation on two synthetic and one real datasets demonstrates the superiority of the UA-MGN. For example, on the Beam dataset, compared to the state-of-the-art MS-MGN, UA-MGN leads to 40.99% lower errors but using only 43.48% fewer network parameters and 4.49% fewer floating point operations (FLOPs).", "sections": [{"title": "1 INTRODUCTION", "content": "Simulation of complex mechanical systems is important in numerous engineering domains, such as structural mechanics [15, 41] and aerodynamics [3, 28, 52]. Traditional simulations rely on the numerical solution of Partial Differential Equations (PDEs), e.g., using the Finite Element Method (FEM). For example, given an external force F, Figure 1 illustrates the FEM simulation result of stress field on a steering wheel when the steering column is fixed on the bottom plane. To perform mechanical simulation, FEM tools first divide the input steering wheel into a mesh structure (e.g., a triangular mesh of roughly equal triangle size) and derive the numerical solution of stress field. When the number of divided mesh elements is high (e.g., tens of thousands and even more), we have to solve a large number of PDEs, suffering from intensive computation cost and high running time. Moreover, when simulation boundary conditions (e.g., the force F or the geometric structure of the steering wheel) change, the FEM solver has to re-process the entire simulation, leading to high overhead.\nRecently, with the success of deep learning, researchers have developed end-to-end learning models that map simulation input to the output results [17, 27, 47]. The adopted models include Convolutional Neural Networks (CNNs) [10, 42, 54] and Graph Neural Networks (GNNs) [2, 29, 49]. Compared to FEM numerical solvers, learning models improve running time meanwhile with acceptable simulation accuracy. In particular, when the input geometric object is divided into a mesh structure (such as a triangular mesh), the works [14, 46] model the mesh structure as a graph and exploit GNNs to learn a spectrum of mechanical system simulation.\nUnfortunately, existing works are hard to tailor GNNs for effective and efficient simulation of complex mechanical systems. Above all, effective representation of a mechanical system, i.e., the steering wheel above, is non-trivial, involving the overall global representation and accurate local one, e.g., the small area to which the external force F is applied. (1) Existing works perform node feature representation equally for all nodes in the mesh graph, with no differentiation of those boundary nodes where the external force F is applied. If the number of boundary nodes is rather small among all mesh nodes (see Figure 1), no differentiation of boundary nodes could falsely miss the associated meaningful node features and suffer from inaccurate local representation. (2) Typical Internet and social networks exhibit power law graphs, and the GNNs on these graphs frequently require 2 or 3 message propagation (MP) steps [31, 56, 62]. Instead, the node degree distribution of mesh graphs is rather even, ranging from 3 to 40 with an average 5 - 6 in our datasets. How to tune the MP steps in mesh graphs is difficult. Too high MP steps lead to the over-smoothing issue [6, 30], making the representation of mesh graph nodes rather similar and indistinguishable. Too small steps may not propagate the effect of the external force F from a small number of its boundary nodes to the entire steering wheel. (3) MP on too many small triangles in a triangular mesh could lead to message propagation loops surrounding such triangles, again leading to the over-smoothing issue [19, 48].\nBesides the ineffectiveness issue above, existing GNN works on complex mechanical system simulation suffer from high computation overhead. More specifically, for better global and local representation of a mechanical system (i.e., the steering wheel), multi-level mesh graphs have been developed [14, 33, 38, 45], where the bottom graph is with the finest mesh (e.g., the smallest triangle size) and the top one is the coarsest mesh (with the largest triangle size). Hierarchical GNN models, e.g., the popular U-shaped networks [14, 33, 38], can effectively learn the multi-level mesh graphs. However, these hierarchical GNN models require the MP to start from the finest mesh graph (the bottom one) to coarse ones until the top one, and next back to the original bottom one, involves both down- and up- sampling steps. Obviously, the two sampling steps require high MP overhead and suffer from the inefficiency issue.\nTo tackle the aforementioned issues, in this paper, we develop a novel Up-sampling-only and Adaptive Mesh Graph Network (UA-MGN), consisting of two key techniques. Firstly, we propose an up-sampling-only GNN model on multi-level mesh graphs. That is, it performs MP firstly on the top coarse mesh graph and next fine ones with gradually increasing resolutions until the bottom finest one. It means that our UA-MGN model requires the up-sampling steps alone. Unlike the previous works requiring both up- and down-sampling steps, our model does not require the down-sampling and thus leads to a much smaller number of MP steps. Moreover, since it performs MP firstly on coarse mesh graphs, those boundary nodes have a chance to be within GNN receptive fields at the early stage for better global representation. Meanwhile, it postpones the propagation of too many local messages on fine mesh graphs at the late stages, and thus our UA-MGN model can avoid the inefficient propagation of those local messages on fine mesh graphs and mitigate the over-smoothing issue.\nSecondly, we develop an adaptive MP tailored to diverse mechanical systems. That is, in a mesh graph, we first divide mesh edges into groups based on edge directions (e.g., by the K-means algorithm), next tune the MP steps for every edge group, and then perform the adaptive MP. After that, we perform adaptive propagation along the grouped edge directions by the associated MP steps. Intuitively, it indicates some edge directions may involve much further MP and others are limited to small areas. Thus, this technique not only mitigates the issues of infinite MP loops and over-smoothing, but also is adaptive to the diverse mechanical simulation with various geometric shapes and external conditions for better generalization. As a summary, we make the following contributions in this paper.\n\u2022 To the best of our knowledge, this is the first to tailor a hierarchical learning model for efficient and effective simulation with up-sampling-only GNNs and adaptive MP.\n\u2022 We develop the up-sampling-only hierarchical GNN model, leading to higher efficiency and better global receptive fields at the early stage.\n\u2022 Our adaptive technique can tune the number of MP steps along grouped edge directions to overcome the issue of infinite MP loops and over-smoothing, and leads to high simulation generalization capability."}, {"title": "2 RELATED WORK", "content": "CNN-based Simulation. CNN-based approaches have been recognized for their effectiveness in many simulation works, due to the capacity to learn spatial and temporal dependencies from data. For example, some previous works demonstrate the application of CNNs in fluid simulation [18, 54], and some exhibit their power in material mechanical simulation [24, 42]. Nonetheless, CNNs suffer from issues in representing complex mechanical systems and irregular geometric structures.\nGNN-based Simulation. GNNs have emerged as a promising solution to model the topologies and interactions of mechanical systems. The work [50] demonstrates that GNNs can effectively learn dynamic interactions in particle-based fluid systems by representing neighbor particles as connected graph nodes. The previous work [46] exploits GNNs to simulate various mechanical systems by leveraging mesh graphs to represent the geometric structure of such systems. Yet, flat GNNs in these works do not work well in representing complex geometric structures due to the limited range of MP. To address this issue, some works [14, 45] introduce hierarchical GNNs to extend the range of MP via low-resolution meshes with a larger mesh size. The recent work [45] employs skip connections by MP on a multi-graph consisting of uniform grids with various resolutions, and information can be spread beyond the local neighborhoods. However, these approaches require careful trade-off between the range of MP and representation resolution.\nNeural Operators for PDE Solutions. Instead of end-to-end neural networks, some works [33, 35, 43] propose to replace compute-intensive PDE operators by neural networks. In this way, neural operators are incorporated into the PDE computation framework. However, the performance of neural operators still depends upon the original PDE operation, typically leading to much higher overhead, when compared to end-to-end CNN or GNN-based models. The Fourier neural operator [34] mitigates this issue by employing frequency domain multiplications via Fourier transforms, as an alternative to spatial domain integrals. Such an operator can optimize global representation, but at the cost of worse local precision and spatial interactions. Fourier transforms perform well only on uniform grids. To overcome this limitation, the very recent work [32] introduces learnable deformation from physical irregular meshes to computational uniform grids in the geometric domain. However, this work still faces challenges of complex topologies when there does not exist a diffeomorphism from the physical space to the computational space [32].\nPhysics-Informed Models. Unlike the approaches above, some works [22, 40, 47] introduce physical information into solution"}, {"title": "3 PROBLEM DEFINITION", "content": "PDEs for mechanical systems. In literature, PDEs are ubiquitous in mathematically oriented scientific fields, such as engineering and physics, and have been widely used to model mechanical systems, involving initial and boundary conditions. Here, the initial conditions indicate the state of the system at the initial time step t = 0, and the boundary conditions define the behavior of the system at the boundary of the geometric domain, such as the geometric structure of the simulation object and the external force. The PDEs and the associated initial-boundary conditions define the dynamic evolution of system states. By the previous work [12], we define the following PDE governing a mechanical system.\n$\\mathcal{F}(x, t; u, \\frac{\\partial u}{\\partial x}, \\frac{\\partial u}{\\partial t}, \\frac{\\partial^2 u}{\\partial x^2}, \\frac{\\partial^2 u}{\\partial t^2}) = 0, x \\in D, 0 \\leq t \\leq T$ (1)\nwhere $u(x, t)$ denotes the function to be solved involving the space coordinates x within the geometric domain D and time t, and F is a function regarding a certain mechanical system. If F is a linear function of u and its derivatives, the PDE is said to be linear. Regarding the initial-boundary conditions, we give the following example.\n$\\begin{aligned}\n&u(x, 0) = u_0(x), x \\in D, \\\\\n&u(a, t) = f_a(t), u(b, t) = f_b(t), a, b \\in \\partial D\n\\end{aligned}$ (2)\nHere, $u_0(x)$ is the initial state for $x \\in D$ with t = 0, and for two certain point sets a and b at the boundary of D denoted by bd, the two functions $f_a(t)$, $f_b(t)$ indicate the time-dependent boundary behaviors of the two boundary point sets a and b, respectively. For the example in Figure 1, the set a could denote the mesh nodes to which the external force F is applied, and b could denote the nodes at the bottom of the steering column which is fixed on the plane.\nFinite Element Method (FEM). FEM stands as a cornerstone of numerical methods to solve PDEs, and has been widely used as de facto ground truth in many mechanical engineering applications [63]. Practically, FEM first discretizes an input simulation object with continuous shapes or bodies in the geometric domain D to a set of divided mesh elements. Depending on a specific application, the mesh elements could be either surface elements (i.e., triangles) or volume elements (i.e., tetrahedra). After the discretization, we have a mesh graph G = {V, E, C}, where V = {$v_i$}, $v_i \\in D$ is the set of mesh nodes, E = {{$v_i, v_j$ }} with i \u2260 j is the set of mesh edges, and C = {$c_i$} is the set of mesh elements which are surrounded by mesh nodes and edges. Each element $c_i$ is a subdomain of D (e.g., triangles in a triangular mesh, or tetrahedra in a tetrahedral mesh) and $\\bigcup c_i = D$. Given the discretized mesh elements, we can exploit FEM to solve the PDEs and have numerical results of u ($v_i$, t).\nDefinition 1. [Mesh Graph-based Mechanical Simulation] Given a mechanical system modeled by a mesh graph G = (V, E, C) with an initial condition $u_0(x)$, boundary conditions $f_{a,b,...}(t)$ and the resulting response U = {u ($v_i$, t)} with $v_i \\in V$, we want to learn a mesh graph regression model R(\u00b7) with U = R(G, $u_0, f_{a,b,...}$).\nIn the problem above, the simulation input includes the mesh graph G and initial-boundary conditions applied to a subset of nodes V, for example, an external force F = {$f_k$}, $o_k \\in V$ at t = 0. The simulation output is a set of mechanical responses u ($v_i$, t), indicating the state of each node $v_i$ at time step t. Depending upon the specific simulation application, we might be interested in the detailed simulation result of continuous time steps (e.g., fluid simulation) or the final convergent simulation result for a large time step t (e.g., rigid body simulation).\nNote that the problem definition above requires that simulation systems can be modeled as mesh graphs. For those fluid and rigid body simulations, we can comfortably exploit nowadays FEM tools to generate mesh elements and next model them as a mesh graph. Yet for those simulation systems such as human mobility, traffic control and urban city behaviour system simulations [7, 58, 59], it is non-trivial to model such systems within the geometric domain D by mesh graphs and we may resort to other techniques, i.e., multi-agent and discrete event simulation."}, {"title": "4 SOLUTION DETAIL", "content": "4.1 Overview\nBefore introducing our solution detail, we first give R-level mesh graphs that are required by UA-MGN. In Figure 2, the bottom R-th mesh graph is with the smallest mesh element size and the top one is the coarsest mesh with the largest element size. Note that the bottom mesh graph $G_R$ is just the input graph G given by Problem 1, i.e., $G_R$ = G. To generate coarser mesh graphs, say $G^r$ with 1 \u2264 r \u2264 R - 1, we could iteratively set a larger mesh element size than the one of the current graph $G^{r+1}$ to perform a lower resolution discretization on the geometric domain D, e.g., by the widely used Delaunay triangulation [11]. By repeating the mesh generation step, we can have the top coarsest mesh graph $G^1$. Practically, we set R = 3 that is sufficient to learn global and local representation, and a larger R may lead to a very large mesh element size in the top mesh graph and suffer from the mesh fragment issue [57]. Now given the R-level mesh graphs $G^1$, ..., $G^R$, we can build an associated GNN for each mesh graph, and expect that the MP on the top coarsest graph $G^1$ can learn the global representation of the mechanical system and yet the MP on the bottom finest graph $G^R$ captures the local representation of a small area in the system. With the help of the R-level mesh graphs, we have a chance to capture both global and local representation of the system.\n4.2 Up-sampling-only Graph Neural Networks\nOverall, our UA-MGN network follows the Encoder-Processor-Decoder framework. The key is that the Processor stage requires the up-sampling-only steps from the top coarsest graph to the bottom finest one across the multi-level mesh graphs.\nEncoder. The encoder learns each of R-level mesh graphs, including mesh edges and nodes, into embedding vectors. Since mesh nodes and edges are with spatial coordinates, we expect that the learned embedding vector should be independent of specific coordinate systems that are adopted by FEM solvers, i.e., the so-called shift invariance or spatial invariance [5, 20]. We thus exploit relative position coordinates of edge endpoints, instead of absolute ones. To learn edge embedding vectors, for an undirected edge {$v_i, v_j$ }, we regard it as two directed edges: $\\bar{e}_{ij}$ from $v_i$ to $v_j$ and $\\bar{e}_{ji}$ from $v_j$ to $v_i$, and develop the edge feature for each directed edge. By taking $\\bar{e}_{ij}$ for illustration, we have one relative displacement vector $v_j$ - $v_i$, and the norm $v_i$ \u2013 $v_j$, i.e., the Euclidean distance of $\\bar{e}_{ij}$.\nFor each node $v_i$, we mainly focus on those nodes at the boundary of the geometric domain or within the initial-boundary conditions. That is, we have two node features: a binary indicator $I_i$ equal to 1 if $v_i$ is at the boundary and otherwise 0, and values regarding the initial-boundary conditions. For example, in the input graph G, if an external force F = 100 Newtons is applied to an area of 5 mesh nodes, we assume that each node is on average with 20 Newtons. Next, since such node features are originally provided by the finest input graph $G_R$ = G but not by the coarse graphs $G^1$, ..., $G^{R\u22121}$, we thus interpolate these node attributes from the input graph $G_R$ to the coarse graphs $G^1$, ..., $G^{R\u22121}$, e.g., by the barycentric interpolation [4]. Now, for each mesh graph, given the mesh edge features and node features, we exploit a MultiLayer Perceptron (MLP) to transform the concatenated features into a latent vector of size 128.\nProcessor. This step is to update the node and edge embedding vectors by (1) adaptive MP among the nodes within each mesh graph $G^r$ for 1 \u2264 r \u2264 R, and (2) up-sampling operations from coarse graphs $G^r$ to fine ones $G^{r+1}$ until $G^R$.\nFor the MP within the graph $G^r$, we perform adaptive message propagation along graph edges. That is, depending upon the average number of edges of the mesh element, we choose the number K and divide $G^r$ into K subgraphs $G^{r,1}$, ..., $G^{r,K}$ (identified by K = 3 colors in Figure 2), and perform the proposed adaptive MP (that will be given in Section 4.3). That is for each subgraph $G^{r,k}$ with 1 \u2264 k \u2264 K, we have the associated MP steps $L_{rk}$. In this way, we do not propagate messages from a certain node evenly to all neighbours, and instead perform directed MP adaptively along graph edges. For each MP step, we perform the embedding update:\n$\\bar{e}_{ij}^{r,k,l+1} \\leftarrow f_{e}^{r,k}(\\bar{e}_{ij}^{r,k,l}, v_i^{k,l}, v_j^{k,l})$ (3)\nNext, the key of our multi-level UA-MGN model is to build the up-sampling connections from the nodes in coarse mesh graphs $G^r$ to those in fine graphs $G^{r+1}$. Thus, for every node $v_j$ in fine graphs $G^{r+1}$, we first need to locate a coarse mesh element $c \\in G^r$, where the node $v_j$ belongs to, and next build connections from every vertex node of the located coarse mesh element c to the node $v_j$. In the right subfigure in Figure 2, for the node, say $v$, in $G^2$, we can first locate a triangle element in the coarse graph $G^1$ which this node v belongs to, and next build three up-sampling connections from three nodes of the found triangle element to the node v. Such a projection ensures that every node in a fine mesh graph can receive the up-sampling operation from the nodes in a coarse graph.\nDenote $\\varpi_{ij}^{r,r+1}$ to be an up-sampling connection from a vertex node $v_i \\in G^r$ in the found mesh element c to a node $v_j \\in G^{r+1}$. We perform the following up-sampling MP operation to update a node embedding vector $v_j^{r+1}$ in $G^{r+1}$:\n$\\begin{aligned}\n&\\varpi_{ij}^{r,r+1} \\leftarrow f_{e}^{r,r+1}(\\varpi_{ij}^{r,r+1}, v_i^r, v_j^{r+1}), \\\\\n&v_j^{r+1} \\leftarrow f_{v}^{r,r+1}(v_j^{r+1}, \\sum \\varpi_{ij}^{r,r+1})\n\\end{aligned}$ (4)\nWe again implement $f_{e}^{r,r+1}$ and $f_{v}^{r,r+1}$, r = 1, . . ., R \u2212 1 by MLPs with an output embedding size of 128.\nDecoder. This step again exploits the MLP to transform the node embedding vectors $v_i$ in the R-th level finest mesh graph back to the output mechanical response (such as stress field on the entire mesh graph G).\n4.3 Adaptive Message Propagation\nFor a given mesh graph $G^r$, the adaptive message propagation (MP) within $G^r$ involves two tasks. Firstly, we need to divide $G^r$ into K subgraphs $G^{r,k}$ with 1 \u2264 k \u2264 K, and next tune the MP steps $L_{rk}$ on the subgraph $G^{r,k}$. Since each subgraph $G^{r,k}$ is with an associated number $L_{rk}$, we expect to guide the MP purposely towards those important subgraphs but not equally towards all subgraphs.\nMesh Graph Division. To enable the directed MP along mesh edges, our general idea is to cluster those edges with similar directions into the same group. That is, if the included angle of two edges is close to zero, i.e., two edges are parallel, we would like to cluster them into the same group. Following the idea, we exploit the classic K-means algorithm to divide the edges of a certain mesh graph into K subgraphs. Intuitively, we now have K different edge directions associated with such divided subgraphs.\nAlg. 1 gives the Pseudocode of mesh graph division. Line 5 computes the distance of an edge $\\bar{e}_{ij}$ and a cluster $\\bar{\\mu}^k$ by the arc-cosine function, and line 8 computes the mean of a cluster by the average of all edge direction vectors within the cluster. Finally, when the cluster membership does not change, we stop the loop in line 2.\nTime complexity is O(TK|E|) where T (resp. K) is the number of iterations (resp. groups) and |E| is the edge count.\nTuning MP steps. For each divided subgraph $G^{r,k}$, in Alg. 2, we tune an associated number of MP steps $L_{rk}$ by using the largest diameter of a certain connected component (CC) within the subgraph $G^{r,k}$. To this end, we first project every coarse element $\\tilde{c}^{r\u22121} \\in G^{r\u22121}$ into the fine graph $G^r$ (see Figure 3). That is, for every node $v_j$ in $G^r$, we can locate a coarse element $\\tilde{c}^{r\u22121}$ to which $v_j$ belongs, e.g., by BVHTree [13]. The nodes belonging to the same coarse element and their neighboring edges then form an area $a^r$ in $G^r$, such that the area $a^r$ can cover the coarse element $c^{r-1}$.\nNote that we have already divided the mesh graph $G^r$ into K subgraphs $G^{r,k}$ with 1 \u2264 k \u2264 K. As a result, the area $a^r$ is further divided into multiple sub-areas $a^{r,k}$. In lines 6-9, for each sub-area $a^{r,k}$, we may have multiple CCs and next find the diameter $l_{r,k}$ for each CC. For a certain 1 \u2264 k \u2264 K, a coarse element $c^{r\u22121} \\in G^{r\u22121}$ is with the largest diameter $l_{r,k}$ on the fine graph $G^r$, and we thus can find the largest one $L_{rk}$ among all coarse elements in $G^{r\u22121}$. In Figure 3, the area $a^r$ is with three sub-areas (due to K = 3 groups), and the sub-area $a^{r,k}$ highlighted by the orange color is with three CCs. Among such CCs, we can find that the largest diameter is 4.\nIt is not hard to find that the found number $L_{rk}$ is the diameter regarding a certain CC within some sub-areas $a^{r,k}$. Since the size of such a CC is smaller than the size of the sub-area $a^{r,k}$, much smaller than the size of the area $a^r$, and significantly smaller than the subgraph $G^{r,k}$, we thus have a chance to greatly optimize the overhead of MP by setting a small number $L_{rk}$ of MP steps. Alg. 2 lists the steps to tune the number $L_{r,k}$.\nTime complexity: The running time mainly depends upon the projection (line 3) with O(|V|log|C|) and the computation of diameters (line 7) with O(|V|+|E|), leading to the total O(|V|log|C|+|E|), where |C| is the number of coarse mesh elements in $G^{r\u22121}$.\nAdaptive Message Propagation. Until now, we are ready to give the adaptive MP within each subgraph $G^{r,k}$ by the steps $L_{rk}$ to update node and edge embedding vectors.\n$\\begin{aligned}\n&\\bar{e}_{ij}^{r,k,l+1} \\leftarrow f_{e}^{r,k}(\\bar{e}_{ij}^{r,k,l}, v_i^{k,l}, v_j^{k,l}), \\\\\n&k=1...K; l=0... L_{rk} - 1\n\\end{aligned}$ (5)\n$v_i \\leftarrow g_v([v_i^{k,1,0},...,v_i^{k,1,L_{r1}},...,v_i^{k,K,L_{rK}}])$ (6)\nIn the equations above, we first update the edge and node embedding vectors by the l-th step of MP within each subgraph $G^{r,k}$ with totally $L_{rk}$ steps (see Eq. 5), and next concatenate and aggregate all node embedding vectors of K subgraphs (see Eq. 6). Here, we implement $f_{e}^{r,k}$, $f_{v}^{r,k}$, $g_v$ by MLPs with an output embedding size of 128, and the network parameters of $f_{e}^{r,k}$ and $f_{v}^{r,k}$ are shared within the same subgraph. The aggregated vectors are then fed into the mesh graph $G^r$ for 1 \u2264 r \u2264 R-1 via the up-sampling step, and finally to the decoder in the R-th level finest mesh graph $G_R$. During these steps, we can find that each node embedding is updated by (1) the MP within the subgraph $G^{r,k}$ via the adaptive MP to learn local information in the $G^{r,k}$, and (2) meanwhile those across mesh graphs to learn global information via up-sampling from coarse graphs $G^{r\u22121}$ to fine ones $G^r$.\nFinally, Alg. 3 gives the Pseudocode of the overall processing steps of UA-MGN. The input includes the R \u00d7 K pre-divided subgraphs (by Alg. 1) and the numbers of MP steps (by Alg. 2). In lines 3-8, the for loop performs associated adaptive MP on each subgraph $G^{r,k}$. Note that the propagation of the K subgraphs is independent and we thus perform parallel propagation for better speedup. Then, line 10-13 performs up-sampling for each non-final level. Finally, line 15 decodes the final node embedding vectors of the bottom graph $G_R$ (i.e., the input graph G) to generate the mechanical response output.\nTime complexity is $O(\\frac{R\u00b7K\u00b7L_{rk}}{\\Theta})$ where \u0398 is the speedup ratio after parallel MP is adopted."}, {"title": "5 EXPERIMENTS", "content": "5.1 Experimental Setup\n5.1.1 Datasets. We use two synthetic and one real datasets.\n\u2022 Beam. We generate the 2D Beam dataset by a widely used FEM solver ABAQUS to simulate the deformation responses of rectangular beams subjected to an external force. The beams have the size of 15 \u00d7 100 mm\u00b2. Each beam contains a circular hole with a diameter of 5 mm. By varying the center of the hole, we generate 111 beam objects. That is, starting from the initial center (5, 5) mm with the step size 2.5 mm, we move the center horizontally and vertically by 3 and 37 times, respectively. Meanwhile, we fix the bottom of the beam structure and then apply an external force of 300 N (Newton) to the top. We also vary the force direction by changing the included angle between the force and the horizontal direction from -60\u00b0 to 60\u00b0 with a step of 30\u00b0, generating 5 loading settings. For a given mesh graph, we solve the stress field on the associated Beam structure by the FEM solver ABAQUS as ground truth.\n\u2022 Steering Wheel. The real dataset includes 239 samples of 3D steering wheels provided by expert engineers from an automotive supplier. Following an industry trial standard, the engineers apply a force of 700 N in the negative z-axis direction at the steering wheel rim and meanwhile fix the steering column at the bottom plane. In each sample, we divide the steering wheel into hybrid mesh types of hexa-, penta- and tetra-hedral. The engineers then exploit an industry-level FEM solver LS-DYNA to generate numerical result of the stress field (as ground truth).\n\u2022 CylinderFlow. This synthetic dataset [46] consists of time series of 2D mesh-based dynamic velocity evolution of fluid flow around a cylinder as an obstacle. Each mesh is with an associated time series. By varying the radius and centers of the obstacles, we have the associated simulation samples. Since the dataset involves the multi-step time series data, we thus are interested in the 1-step data from t = 0 to t = 1, and the multi-step rollout data from t = 0 to t = T for T > 1.\nNote that the Beam and CylinderFlow datasets are with the raw geometries, we can comfortably exploit the Delaunay triangulation [11] to generate coarse meshes for R-level mesh graphs. Yet the samples of the SteeringWheel dataset provided by the supplier are with one fine mesh graph without the raw geometries, we follow the work [38] to generate coarse mesh graphs $G^1$, ..., $G^{R\u22121}$.\nFor the Beam and SteeringWheel datasets, we use 80% samples for training, 10% samples for validation, and 10% samples for testing. For the CylinderFlow dataset, we follow the settings in the previous work [46] by using 1000 trajectories for training, 100 trajectories for validation, and 100 trajectories for testing. We perform baseline study on the three datasets. In terms of the remaining studies such as generalization and ablation study, we mainly use the Beam dataset, because we can comfortably change the initial and boundary conditions during the stress field simulation.\n5.1.2 Baselines.\n\u2022 UNet [54]: We use a U-shaped CNN model to learn multi-scale physical system simulation.\n\u2022 FNO [34]: A Neural Operator approach using Fourier space to learn complex patterns and correlations.\n\u2022 Geo-FNO [32]: A very recent geometry-aware improved version of FNO to learn deformation from the irregular input mesh to a latent uniform grid to avoid the limitations of Fourier transforms.\n\u2022 MGN [46]: A flat GNN model to learn mesh-based simulations. The GNN is to represent the spatial relationships within mesh graphs.\n\u2022 MS-MGN [14]: The state-of-the-art work essentially is a hierarchical version of MGN with multi-stacked U-shapes to represent fine and coarse meshes.\n\u2022 AMR-GNN [45]: A very recent U-shaped GNN model with multigraphs consist of uniform grids of various resolutions to learn features at different scales.\nNote that UNet and FNO require very regular input structures. Yet, for our mesh graph data, particularly for the SteeringWheel samples with rather complex structure, these two approaches cannot work well, and we do not have the evaluation results of UNet and FNO on the SteeringWheel data. For fairness, we use the equal number of total MP steps for MGN, ours and MS-MGN (including the MP steps in MGN, up-sampling steps in ours, and the up- and down-sampling steps in MS-MGN).\n5.1.3 Evaluation Metric. We measure the performance by Root Mean Square Error with RMSE = $\\sqrt{\\frac{1}{\\sum_{i=1}^{N} n_{i}} \\sum_{i=1}^{N} \\sum_{j=1}^{n_{i}}\\left(y_{i j}-\\hat{y}_{i j}\\right)^{2}}$, where N is the number of testing samples and $n_i$ is the number of nodes in i-th sample, and $y_{ij}$ is the ground truth value while $\\hat{y}_{ij}$ is the prediction value of the j-th node in the i-th sample."}, {"title": "5.2 Performance Study", "content": "5.2.1 Baseline Study. Figure 4 first gives the baseline study. Among all approaches, our work UA-MGN performs best on three datasets with the following findings.\n\u2022 In the Beam dataset, the four hierarchical GNN models (UNet, AMR-GNN, MS-MGN and ours) and two neural operator models (FNO and Geo-FNO) can learn wide or global receptive fields and lead to better performance than the single-layer flat GNN model (MGN). Similar results occur in the CylinderFlow 1-step and Rollout scenarios.\n\u2022 Note that UNet and FNO do not work on the SteeringWheel dataset due to complex geometric structures (see Section 5.1.2). We thus plot the results of the five remaining approaches. In this dataset, Geo-FNO, AMR-GNN and MS-MGN do not achieve"}]}