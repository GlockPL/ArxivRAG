{"title": "AVATAR: Adversarial Autoencoders with Autoregressive Refinement for Time Series Generation", "authors": ["MohammadReza EskandariNasab", "Shah Muhammad Hamdi", "Soukaina Filali Boubrahimi"], "abstract": "Data augmentation can significantly enhance the performance of machine learning tasks by addressing data scarcity and improving generalization. However, generating time series data presents unique challenges. A model must not only learn a probability distribution that reflects the real data distribution but also capture the conditional distribution at each time step to preserve the inherent temporal dependencies. To address these challenges, we introduce AVATAR, a framework that combines Adversarial Autoencoders (AAE) with Autoregressive Learning to achieve both objectives. Specifically, our technique integrates the autoencoder with a supervisor and introduces a novel supervised loss to assist the decoder in learning the temporal dynamics of time series data. Additionally, we propose another innovative loss function, termed distribution loss, to guide the encoder in more efficiently aligning the aggregated posterior of the autoencoder's latent representation with a prior Gaussian distribution. Furthermore, our framework employs a joint training mechanism to simultaneously train all networks using a combined loss, thereby fulfilling the dual objectives of time series generation. We evaluate our technique across a variety of time series datasets with diverse characteristics. Our experiments demonstrate significant improvements in both the quality and practical utility of the generated data, as assessed by various qualitative and quantitative metrics.", "sections": [{"title": "1 Introduction.", "content": "Data scarcity poses a significant challenge in many real-world, machine learning-based prediction tasks [1]. This issue can be particularly pronounced for certain classes within a dataset, especially when dealing with rare events such as major solar flares [2, 3, 4], or patients with specific medical conditions, such as cancer. Additionally, data scarcity may arise from privacy concerns [5, 6, 7], especially in healthcare, or due to noisy and complex data collection environments [8]. Beyond individual classes, data scarcity can affect entire datasets, as deep learning models are notoriously data-hungry [9], often requiring vast amounts of data to achieve optimal performance. To address these challenges, data augmentation techniques are commonly employed to artificially increase the size of datasets and facilitate the training of machine learning and deep learning models [10]. This approach has found widespread use in fields such as computer vision [11, 12], time series analysis [13, 14, 15], and signal processing [16]. However, the quality of the augmented data is critical, especially in time series analysis, where models must capture not only the distribution of features at individual time points but also the complex interactions between these points over time. For instance, in multivariate sequential data $X_{1:T} = (x_1,...,x_T)$, an effective model must accurately capture the conditional distribution $p(x_t | X_{1:t-1})$, which governs temporal transitions. Failure to do so leads to poor model performance, underscoring the importance of preserving temporal dynamics in time series data.\nConsiderable research has been directed towards enhancing the temporal behavior of autoregressive models used in sequence forecasting. The primary aim is to reduce the effect of sampling errors by making targeted adjustments during training, thereby improving the modeling of conditional distributions [17, 18, 19]. Autoregressive models represent the sequence distribution as a product of conditional probabilities $\\prod_t P(x_t | X_{1:t-1})$, which makes them well-suited for forecasting due to their deterministic nature. However, these models are not truly generative, as they do not rely on external inputs to generate new data sequences.\nIn contrast, studies applying generative adversarial networks (GANs) [20] to sequential data generally employ recurrent neural networks (RNNs) for both the generator and discriminator, aiming to optimize an adversarial objective [21, 22]. While this approach is con-"}, {"title": "2 Related Work.", "content": "Autoregressive RNNs trained with maximum likelihood estimation frequently encounter significant errors during multi-step predictions [24]. These errors arise due to the discrepancy between the training phase, conducted in a closed-loop setting (where the model is conditioned on actual data), and the inference phase, which operates in an open-loop manner, relying on previous predictions. To address this issue, approaches such as Professor Forcing, based on adversarial domain adaptation [25], have been proposed. This method introduces an additional discriminator designed to distinguish between self-generated hidden states and those derived from teacher-forced inputs [26]. This alignment of training and prediction improves the consistency of the model's behavior. However, while these methods attempt to capture stepwise transitions, they remain deterministic and do not involve sampling from a learned probability distribution, an essential requirement for generating synthetic data.\nThe introduction of GANs [20] represented a major innovation in data generation. GANs consist of two neural networks, a generator and a discriminator, trained simultaneously in a competitive, zero-sum game framework. Although GANs can effectively generate data by sampling from a learned distribution, they struggle to model sequential dependencies, which are crucial for time series data [27]. The adversarial feedback from the discriminator alone is often insufficient for the generator to accurately learn and replicate the temporal patterns necessary for time series generation.\nSeveral adaptations of the GAN framework have been developed specifically for time series data [28]. One of the earliest models, C-RNN-GAN [21], applied GANs to sequential data using LSTM networks for both the generator and the discriminator. This model generates sequences recurrently, starting with a noise vector and"}, {"title": "3 Problem Specification.", "content": "Let $X$ denote the space of the temporal features, and consider $X \\in X$ as random vectors, with each vector attaining particular values represented by $x$. We focus on sequences of temporal data, denoted $X_{1:T}$, sampled from a joint probability distribution $p$. The sequence length $T$ is itself a random variable integrated into the distribution $p$. The training dataset contains $N$ samples, each indexed by $n \\in \\{1,...,N\\}$, and is expressed as $D = \\{X_{n,1:T_n}\\}_{n=1}^{N}$. For simplicity, we omit the subscript $n$ unless necessary for clarity.\nThe objective of AAEs is to leverage the training data $D$ to estimate a probability density function $\\hat{p}(X_{1:T})$ that approximates the true distribution $p(X_{1:T})$ as closely as possible. Achieving this is challenging due to the complex nature of the distribution. Additionally, in order to capture the temporal dynamics of data using autoregressive models, our objective is to decompose the joint distribution $p(X_{1:T})$ in an autoregressive manner as $p(X_{1:T}) = \\prod_{t=1}^{T} p(X_t|X_{1:t-1})$. This approach refocuses the task on learning a conditional density function $\\hat{p}(X_t|X_{1:t-1})$ that serves as an approximation of $p(X_t|X_{1:t-1})$ at each time step $t$. Therefore, we define two key objectives:\n1. Global objective: This objective involves aligning the joint distribution of entire sequences between real and synthetic data. It is expressed as:\n(3.1)\n$\\min_{\\hat{p}} D (p(X_{1:T}) || \\hat{p}(X_{1:T})),$\nwhere $D$ represents an appropriate distance metric between the distributions.\n2. Local objective: This objective focuses on matching the conditional distributions at each time step for all $t$, formulated as:\n(3.2)\n$\\min_{\\hat{p}} D (p(X_t|X_{1:t-1}) || \\hat{p}(X_t|X_{1:t-1})),$\nIn the context of data augmentation, the global objective corresponds to minimizing the Jensen-Shannon divergence [32] between real and generated distributions, while the local objective in supervised learning aims to"}, {"title": "4 Proposed Framework: AVATAR.", "content": "Based on Figure 1, let $z$ denote the latent representation (hidden code) in the autoencoder with a deep encoder-decoder architecture. We define $\\hat{q}(z)$ as the prior Gaussian distribution we aim to impose on the latent codes, $q(z|x)$ as the encoding distribution, and $p(x|z)$ as the decoding distribution. The encoding function $q(z|x)$ in the autoencoder determines the aggregated posterior distribution of the latent code $q(z)$.\nIn AAEs, optimization is achieved by aligning the aggregated posterior $q(z)$ with a Gaussian prior $\\hat{q}(z)$. Consequently, decoding any area of the prior space produces meaningful synthetic data. To facilitate this alignment, an adversarial network is incorporated at the latent code layer of the autoencoder. The adversarial network's role is to ensure that $q(z)$ closely matches the prior $\\hat{q}(z)$, while the autoencoder's primary objective is to minimize the reconstruction error. The generator within the adversarial network serves as the encoder of the autoencoder $q(z|x)$, helping it produce an aggregated posterior that can deceive the discriminator in the adversarial training, making the discriminator believe that the hidden code $q(z)$ comes from the true prior $\\hat{q}(z)$. Upon the completion of training, the decoder of the autoencoder functions as a generative model, mapping the prior $\\hat{q}(z)$ to the data distribution $p(x)$.\nAlthough this method is beneficial, it is inadequate on its own for modeling the conditional distribution of time series data at each time step $t$. To overcome this limitation, as depicted in Figure 1, we have enhanced the decoder of the AAE by integrating a supervisor network that employs teacher forcing training. This supervisor network is responsible for learning the inherent temporal dependencies in time series data. By training the supervisor jointly with the autoencoder, we aim to fulfill both objectives of time series generation. This integration is crucial because time series data exhibit temporal characteristics such as trends, seasonality, noise, and periodicity. Without capturing these essential features, the synthetic samples produced would be inadequate and of limited practical value."}, {"title": "4.1 Autoregressive Refinement.", "content": "By integrating AAEs with autoregressive learning, we can not only estimate the true distribution $p(X_{1:T})$ using a learned probability density function $\\hat{p}(X_{1:T})$, but also capture the conditional density function $p(X_t|X_{1:t-1})$, which approximates the true $p(X_t|X_{1:t-1})$ at any specific time step $t$. AVATAR achieves this by training a supervisor network in parallel with the autoencoder, thereby fulfilling both objectives. The autoencoder and supervisor are trained jointly with a combined loss function $L_{AE}$ that includes $L_{Rjoint}$, $L_{Ad}$, $L_s$, and $L_D$:\n(4.3)\n$L_{AE} = L_{Rjoint} + L_{Ad} + L_S + L_D$\nIn Equation (4.3), the supervised loss $L_s$ represents a novel contribution used to train the supervisor network. This loss is designed to train the autoencoder-supervisor as a unified network to predict time step $t$ using inputs from time steps 1 to t-1 and also from time steps 1 to t-2. This dual approach enables the integrated autoencoder-supervisor network to learn temporal dependencies without overfitting to immediate next-step dynamics. Specifically, in closed-loop mode, the supervisor receives sequences of the autoencoder's output $X_{1:t-1}^{AE}$ and $X_{1:t-2}^{AE}$ to predict the vector at time step t, denoted as $X_t^{AE}$. Gradients are calculated from a loss that measures the divergence between the distributions $p(X_t^{AE}|X_{1:t-1}^{AE})$ and $\\hat{p}(X_t^{AE}|X_{1:t-1}^{AE})$, as well as between $p(X_t^{AE}|X_{1:t-2}^{AE})$ and $\\hat{p}(X_t^{AE}|X_{1:t-2}^{AE})$. Using maximum likelihood estimation, this leads to the following supervised loss:\n$L_S = E_{x_{1:T}~p} [ || X_t^{AE} - s(X_{1:t-1}^{AE}) ||_2 + || X_t^{AE} - s(X_{1:t-2}^{AE}) ||_2]$\nwhere $s$ is the supervisor function and $X^{AE}$ is the output of the autoencoder for input data $X$. Through joint training of the autoencoder and supervisor, the framework learns to capture the temporal dynamics of time-series data."}, {"title": "4.2 Distribution Loss.", "content": "The adversarial feedback from the discriminator to the encoder is insufficient for guiding the encoder to effectively learn the prior Gaussian distribution. To address this limitation, we propose a novel distribution loss $L_D$, which facilitates the encoder's ability to better approximate the target probability distribution by explicitly capturing the differences in the mean and standard deviation (std) between batches of latent code $Z$ and the prior distribution $\\hat{Z}$:\n(4.6)\n$L_D = L_{Mean} + L_{Std}$\nAlthough various statistical measures can be used to describe a distribution, in the context of our framework, metrics such as minimum, maximum, median, mode, and quartiles are not applicable. This is due to the fact that the AVATAR framework automatically normalizes the data within the range of 0 to 1, making the minimum and maximum values redundant as all data points fall within this standardized interval. Additionally, because we employ a Gaussian distribution as the prior, the median and mode align with the mean. Quartiles, meanwhile, introduce unnecessary noise and do not provide significant insights into the distribution's characteristics. Consequently, the only metrics of relevance in this context are the mean and std, as these effectively capture the properties of the Gaussian distribution.\n$L_{Mean} = E_{z_{1:T}~q,\\hat{z}_{1:T} ~\\hat{q}} [ \\frac{1}{N} \\sum_{t=1}^{T} |\\frac{1}{N} \\sum_{n=1}^{N} Z_{t,n} - \\frac{1}{N} \\sum_{n=1}^{N} \\hat{Z}_{t,n}|]$\nIn this formulation, $L_{Mean}$ computes the mean absolute error (MAE) between the means of a batch of latent code $Z$ and prior distribution data $\\hat{Z}$. We consider sequences of temporal data, denoted as $Z_{1:T}$ or $\\hat{Z}_{1:T}$, drawn from a joint distribution $q$ or $\\hat{q}$, where each sample is indexed by $n \\in \\{1, . . ., N \\}$, and the batch is represented as $B = \\{Z_{n,1:T_n}\\}_{n=1}^{N}$\n$L_{Std} = E_{z_{1:T}~q,\\hat{z}_{1:T} ~\\hat{q}} [ \\frac{1}{N} \\sum_{t=1}^{T} | \\frac{1}{N} \\sum_{n=1}^{N} (Z_{t,n} - \\bar{Z}_t)^2 - \\frac{1}{N} \\sum_{n=1}^{N} (\\hat{Z}_{t,n} - \\bar{\\hat{Z}}_t)^2 |]$\nSimilarly, $L_{Std}$ measures the MAE between the std of a batch of $Z$ and $\\hat{Z}$. In this context, $\\bar{Z}$ and $\\bar{\\hat{Z}}$ represent the means of $Z$ and $\\hat{Z}$, respectively, for a batch of data."}, {"title": "4.3 Regularized GRU.", "content": "The architecture of each network in the AVATAR framework significantly impacts performance. Based on previous research in time series generation [28], we found that GRU outperforms LSTM and RNN, and thus we chose GRU layers for all four networks: the encoder, decoder, supervisor, and discriminator. GRUs consist of two gates: a reset gate and an update gate, which regulate the flow of information and enable the network to decide what information to retain or discard. This simplified structure allows GRUs to efficiently manage sequential data while maintaining strong predictive power, especially in cases where memory of prior inputs is critical. However, GRU layers can be further enhanced by incorporating additional components. To improve performance, we combine batch normalization with GRU layers. As a result, each layer consists of both a batch normalization and a GRU unit, with multiple such layers used for the encoder, decoder, and supervisor. For the discriminator, we avoid using batch normalization, as it would make the discriminator overly powerful, disrupting the balance between the discriminator and encoder, leading to the discriminator's dominance. To further maintain this balance, we train the encoder with twice as many iterations as the discriminator to prevent the latter from overpowering the former."}, {"title": "4.4 Joint Training.", "content": "The training process of the AVATAR framework consists of three distinct stages. In the first stage, the autoencoder is trained independently, relying solely on a reconstruction loss $L_R$. At this point, neither the supervisor nor the discriminator is present, and the autoencoder functions as a conventional autoencoder:\n(4.9)\n$L_R = E_{x_{1:T}~p} || X_t - X_t^{AE} ||_2$\nwhere $X$ denotes the input data and $X^{AE}$ represents the autoencoder's output.\nIn the second stage, the supervisor is trained using the previously defined $L_S$ loss.\nThe third stage consists of two distinct phases. In the initial phase, the integrated autoencoder and supervisor are trained jointly, guided by the loss function $L_{AE}$. This loss function is composed of four sub-components as discussed earlier, two of which are: (i) $L_{Rjoint}$, representing the joint reconstruction loss for the integrated network, and (ii) $L_{Ad}$, which captures the conventional adversarial feedback loss."}, {"title": "5 Experiments and Results.", "content": "The Python implementation of the AVATAR framework, along with a tutorial Jupyter notebook demonstrating its usage and the results of experiments, is available online. This implementation incorporates all the innovations discussed, as well as the hyperparameters necessary to achieve optimal results.\nBaseline Methods. The AVATAR framework has been evaluated against several state-of-the-art data augmentation techniques, including TimeGAN [29], Standard GAN [20], Standard AAE [23], Teacher Forcing (T-Forcing) [26], and Professor Forcing (P-Forcing) [25], covering both GAN-based and autoregressive-based approaches. To ensure a fair and rigorous evaluation, identical hyperparameters are applied across all methods. These include the number of iterations, the type of recurrent neural network, the number of layers, batch size, and hidden dimensions.\nBenchmark Datasets. We evaluate AVATAR's effectiveness using time series datasets that showcase a wide range of features, such as periodicity, noise intensity, and trend patterns. These datasets are selected based on various combinations of these features.\n*   Energy: The UCI Appliances Energy Prediction dataset [34] is distinguished by irregular periodic patterns, noise, a high number of dimensions (28),\n*   Google Stock: Stock price data is continuous but lacks periodicity, with correlated features. We utilize historical daily stock data from Google between 2004 and 2019, including variables such as trading volume, daily highs and lows, opening prices, closing prices, and adjusted closing values.\n*   Sinusoidal Data: We generate multivariate sinusoidal time series, where each series has distinct frequencies (n) and phases (\u03b8), resulting in continuous, periodic signals with independent features. For each dimension i (ranging from 1 to 4), the function is represented as $x_i(t) = sin(2\u03c0nt + \u03b8)$, where n is drawn from a uniform distribution U [0, 1] and 0 from U[-\u03c0, \u03c0].\nFor the Energy and Stocks series, we slice each continuous time series into samples using a slicing window of size 24, moving the window forward by one time step to extract each subsequent sample throughout the series.\nEvaluation Criteria. Evaluating the performance of GANs and AAEs comes with significant challenges. Methods based on likelihood, such as Parzen window estimates [35, 36], can produce misleading outcomes. While human evaluation is typically viewed as the most reliable way to assess quality, it is both impractical and expensive. As a result, this work evaluates performance based on three recent evaluation metrics, incorporating both qualitative and quantitative assessments of the generated data. These include resemblance score, predictive fidelity score, and distributional alignment analysis using t-SNE and PCA visualization."}, {"title": "5.1 Resemblance Score.", "content": "To quantitatively assess similarity, we train a time series classifier based on LSTM to distinguish between sequences from the original and synthetic datasets. The LSTM classifier is trained to separate these two categories in a typical supervised learning setup. The classification error on a separate test set is used to derive a quantitative measure, which is then subtracted from 0.5, setting the optimal score to O rather than 0.5. This metric emphasizes the utility of the generated data in downstream classification tasks. To ensure reliable and robust results, each experiment is repeated 10 times. The mean and std of these observations are reported in Table 1 for a comprehensive comparison. Based on the results presented in Table 1, AVATAR significantly outperforms the baseline techniques, including the state-of-the-art TimeGAN, across the specified three datasets. Specifically, AVATAR reduces the resemblance score by 46.86% compared to TimeGAN. Both GANs and AAEs fail to capture the time series characteristics effectively, leading to the production of unrealistic data. This highlights the importance of incorporating innovative techniques to enhance their performance in time series data generation. Additionally, T-forcing achieved a reliable score, underscoring the effectiveness of autoregressive learning for time series generation."}, {"title": "5.2 Predictive Fidelity Score.", "content": "We expect AVATAR to successfully capture the conditional distributions over time. To measure this, we train an LSTM model on the synthetic dataset for sequence prediction, focusing on forecasting the next-step temporal vectors for each input sequence. The performance of the model is then evaluated on the original dataset, with accuracy assessed using MAE. This metric demonstrates the quality of the synthetic data in predictive tasks, which is a key objective in time series analysis. Similar to the evaluation of the resemblance score, we repeated the experiments 10 times to ensure a robust assessment. As shown in Table 1, AVATAR demonstrates superior results in terms of the predictive capability of synthetic data compared to the baseline techniques. Specifically, AVATAR reduces the predictive error by 20.44% in comparison to TimeGAN. Furthermore, AVATAR exhibits significantly greater stability compared to TimeGAN and GAN-based techniques, consistently yielding the same results across different training sessions. Additionally, T-forcing achieved a stronger performance relative to the other baseline models, highlighting the effectiveness of autoregressive training for synthetic data generation."}, {"title": "5.3 Distributional Alignment.", "content": "We utilize t-SNE [37] and PCA [38] analyses on both original and synthetic datasets by reducing the temporal dimension for visualization. By doing so, we can qualitatively evaluate how well the distribution of the generated samples aligns with that of the original data in a two-dimensional space. This method provides insight into one of the core goals of a generative model, which is to approximate the probability density function, $\\hat{p}(X_{1 : T})$, to the true distribution $p(X_{1 : T})$. Based on Figures 2 and 3, the distributional alignment between the original and synthetic data generated by AVATAR is exceptional across all three datasets. This highlights the model's strength in learning the entire data distribution of the original datasets. Moreover, AVATAR demonstrates a more accurate alignment compared to TimeGAN. This improvement can be attributed to two key factors: first, the use of autoregressive learning, which enhances the overall quality of the synthetic data, and second, the introduction of a novel distribution loss, which enables the aggregated posterior of the latent code to better match the prior Gaussian distribution."}, {"title": "5.4 Contribution of Innovations.", "content": "In this section, we analyze the impact of each innovation on improving the performance of the AVATAR framework. To evaluate their contributions, we systematically remove each novelty and rerun the resemblance and predictive fidelity score experiments. As shown in Table 2, removing the joint training mechanism significantly degrades the framework's performance, as key objectives, including autoregressive learning, rely on joint training through combined loss functions. Similarly, removing autoregressive learning causes a substantial drop in performance, as it addresses the local objective of time series generation by capturing the conditional distribution at each time step. Additionally, excluding the regularized GRU and distribution loss leads to lower scores, as these components facilitate training and ensure alignment between the prior distribution and the latent code."}, {"title": "5.5 Visual Analysis.", "content": "As shown in Figure 4, which presents four randomly selected original and synthetic data samples generated by AVATAR for the Stocks dataset, the synthetic data demonstrates a strong resemblance to the original data. This high level of similarity plays a key role in the promising results observed across the evaluation metrics."}, {"title": "6 Conclusion.", "content": "In this study, we present AVATAR, an innovative framework built on top of AAEs specifically designed for generating high-quality time series data. AVATAR outperforms TimeGAN and other advanced methods through a comprehensive evaluation using multiple qualitative and quantitative metrics across diverse datasets with varying characteristics. While previous techniques exhibit variability in performance due to instability, leading to inconsistent results with each training session, AVATAR demonstrates significant stability, consistently achieving optimal results after each session. Key innovations in AVATAR include a novel integrated autoregressive training, which effectively captures temporal dynamics, a novel distribution loss that more efficiently models the probabilistic distribution of the data, as well as the incorporation of an improved GRU architecture and joint training. These components collectively drive the superior performance and stability of AVATAR. For future work, we plan to extend the use of AAEs to design a state-of-the-art framework for time series-based missing value imputation."}]}