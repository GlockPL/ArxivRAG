{"title": "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents", "authors": ["Jaekyeom Kim", "Dong-Ki Kim", "Sungryull Sohn", "Lajanugen Logeswaran", "Honglak Lee"], "abstract": "In this paper, we introduce Auto-Intent, a method to adapt a pre-trained large language model (LLM) as an agent for a target domain without direct fine-tuning, where we empirically focus on web navigation tasks. Our approach first discovers the underlying intents from target domain demonstrations unsupervisedly, in a highly compact form (up to three words). With the extracted intents, we train our intent predictor to predict the next intent given the agent's past observations and actions. In particular, we propose a self-exploration approach where top-k probable intent predictions are provided as a hint to the pre-trained LLM agent, which leads to enhanced decision-making capabilities. Auto-Intent substantially improves the performance of GPT-{3.5, 4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation benchmarks from Mind2Web and online navigation tasks from WebArena with its cross-benchmark generalization from Mind2Web.", "sections": [{"title": "1 Introduction", "content": "Recently, large language models (LLMs) pre-trained on a massive amount of data (Achiam et al., 2023; Dubey et al., 2024) have excelled at reasoning and a variety of tasks. They exhibit robust planning and reasoning abilities, enabling LLM agents to perform diverse tasks (Wang et al., 2023; Xi et al., 2023; Zeng et al., 2023). However, these agents often face challenges in domains with less prior knowledge, especially ones with large action spaces, such as navigating websites or operating mobile devices (Cheng et al., 2024; Hong et al., 2023; Koh et al., 2024).\nWe explore improving decision-making with pre-trained LLMs on downstream tasks by injecting domain knowledge into the input context, in the form of natural language hints for the next action. This allows them to fully retain their strong general reasoning capabilities while avoiding overly costly or impossible fine-tuning. Leveraging natural language guidance for improving LLM planning and reasoning capabilities has found much success in prior work (Wei et al., 2022; Yao et al., 2022; Shinn et al., 2024; Fu et al., 2024; Zhao et al., 2024).\nAlthough prior work has shown that LLMs have strong priors to reason about intermediate subgoals (Logeswaran et al., 2022; Huang et al., 2022; Hao et al., 2023), the resulting performance can be largely affected by the injected hints' accuracy, which could be limited especially in complex environments such as real-world web navigation with numerous elements and possible actions. In this work, we aim to improve the LLM agent's performance further by proposing self-exploration. Our key insight is to provide multiple plausible and semantically varied hints that we call intents to the LLM agent for flexible reasoning and acting given a set of possible directions. To achieve this, we constrain intents to very short phrases and generate top-k intents to provide as a collective hint with a beam search using a smaller model fine-tuned for intent prediction. This fine-tuning is enabled by discovering intents from demonstration data with our intent extractor. The compact intent space encourages semantically distinct intents to be sampled (as opposed to syntactically diverse intents that are semantically identical). This self-exploration with multiple intents enhances the agent to find the correct directions and associated actions. See Figure 1 for an illustration of our approach.\nOur main contributions are as follows:\n\u2022 We introduce Auto-Intent, a method to extract natural language intents from demonstration trajectories in an unsupervised manner and leverage intents as hints for pre-trained LLM agents through a fine-tuned intent prediction model.\n\u2022 We present a self-exploration strategy where the LLM agent reviews varied plausible intents suggested by the intent prediction model and demonstrate that this results in more accurate action prediction compared to relying on a single intent.\n\u2022 We empirically show that the injection of predicted top-k intents effectively improves the performance of GPT-{3.5, 4} and Llama-3.1{-70B, 405B} agents on the large-scale real-website benchmark tasks from Mind2Web (Deng et al., 2024) and online navigation tasks from WebArena (Zhou et al., 2023) in a cross-benchmark generalization setting from Mind2Web."}, {"title": "2 Auto-Intent: Intent Discovery and Self-Exploration with Intent Prediction", "content": "To address the inadequate domain knowledge in pre-trained LLM agents, we introduce an abstract natural language representation we refer to as an intent, which hints what the agent can perform next. We aim to enhance LLM agents further without limiting them by the intent prediction model's performance, via providing top-k predicted intents as a set of probable directions to consider. We describe the problem definition (Section 2.1), design of the intent space and discovery of underlying intents from demonstrations in an unsupervised manner (Section 2.2), and fine-tuning and using the intent prediction model for acting with top-k probable intents as a flexible hint (Section 2.3) in detail."}, {"title": "2.1 Problem Statement", "content": "We consider sequential decision-making for completing each given task. At each time step t starting from t = 1, the agent receives an observation $o_t \\in O$ and performs an action $a_t \\in A$ until the episode ends, with access to previous observations and actions. We use a demonstration dataset $D_{demo} = \\{T\\}_{i=1}^N$, where each trajectory $T = \\{(O_t, a_t)\\}_{t=1}^T$ consists of observations and actions from the same episode. Empirically, we put our focus on real-world web navigation tasks."}, {"title": "2.2 Intent Space and Discovery", "content": "Intent space design. We aim to provide a semantically varied set of predicted intents to be examined by the LLM policy for more flexible reasoning and improved action prediction. Given a vocabulary V, we define our intent space as $Z = V^L$ where L is a small number. We find expressing each intent using only up to L = 3 words in the form gerund + noun phrase (object) appropriate for our use with the desired expressiveness while being computationally efficient. Thanks to its compactness, even single-word changes can lead to clear semantic distinctions (e.g., selecting date vs. selecting time vs. selecting guests). The smaller semantic overlap between different intents makes the intent space suitable for specifying more varied directions using the same number of intents, which fits our goal.\nIntent discovery. With the intent space Z, we define the intent discovery procedure with a prompt-based intent extractor $M_{extract}$ as"}, {"title": null, "content": "$z_t = M_{extract}(O_t, a_t, Z_{1:t-1})$\n(1)\nwhere $z_t \\in Z$ denotes the intent discovered for time step t. We instruct it to take the observation (including task description), action, and previous-step intents together into account to discover the intent. Refer to Figure 2 for a hard example that requires a contextual understanding and Appendix A.3 for our full prompt.\nIntent-augmented demonstrations. Given the dataset $D_{demo}$, we discover intents using Equation (1) for each step. We construct an intent-augmented demonstration set $D_{intent} = \\{T\\}_{i=1}^N$ where each trajectory is $\u03c4' = \\{(o_t, a_t, z_t)\\}_{t=1}^T$."}, {"title": "2.3 Self-Exploration with Intent Prediction and Acting with LLMs", "content": "Intent predictor. Using the intent-augmented demonstration dataset $D_{intent}$ from Section 2.2, we train a smaller language model to predict each discovered natural language intent $z_t$ given $O_t, A_{1:t-1}, z_{1:t-1}$ as input. We employ this model trained on $D_{intent}$ as our intent predictor, $M_{intent}$. See Appendix A.4 for the training details.\nIntent prediction. One important property of the intents that $M_{intent}$ outputs is the compactness. Thanks to the definition of our compact intent space Z with a small L from Section 2.2, multiple intent predictions can span a broader spectrum of meanings and thus improve the recall of the correct intent effectively. Therefore, we employ the generation of multiple intent predictions with $M_{intent}$ for finding the correct intent, which is expressed as"}, {"title": null, "content": "$\\tilde{z}_t^1, \\tilde{z}_t^2,...,\\tilde{z}_t^k \\sim M_{intent}(o_t, a_{1:t-1}, z_{1:t-1})$\n(2)\nwhere the previous intents $z_{1:t-1}$ are obtained with $M_{extract}$ using Equation (1). The generated top-k intents can be employed as a set of probable, different directions for the LLM policy, providing the ingredients for self-exploration. While different generation strategies might be applicable depending on the requirements (e.g., more semantic diversities of the intents), we find beam search effective and efficient enough for our top-k intent prediction.\nLLM policy with self-exploration. We incorporate the top-k intents $\\tilde{z}_{1:k}$ as a concatenated list into the input prompt for the LLM policy \u03c0:"}, {"title": null, "content": "$a_t = \u03c0(0_{1:t}, A_{1:t\u22121}, \\tilde{z}_{1:k}).$\n(3)\nWe instruct the LLM to examine the suggested intents together to act with an appropriate one. Combined with the intent prediction, the agent internally infers top-k intents and reasons with them as a set of probable directions for acting, which we refer to as self-exploration. Its exploration effect is achieved implicitly and internally, unlike exploration via environment interactions in reinforcement learning. This can be especially effective in complex environments where predicting the correct intent on the first try is challenging. See Appendix A.5 for the prompt."}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Setup for Main Evaluation", "content": "Evaluation. We evaluate our approach on a large-scale real website navigation dataset, Mind2Web (Deng et al., 2024). Its three test splits evaluate agents' generalization to unseen (a) tasks, (b) websites, and (c) domains. \"Elem. acc\" measures the accuracy with respect to the correct elements, \u201cOp, F1\" is a metric based on string matching, and \"Step SR\" denotes the rate of fully successful steps. Refer to Appendix A.1 for more details.\nCompared methods. We compare our results with MindAct (Deng et al., 2024), a directly trained agent with the same backbones, and SeeAct (Zheng et al., 2024), a prompt-based agent with GPT-4V. For all method, we use the same pre-processing of keeping only top-N candidate elements by Deng et al. (2024). We examine Flan-T5XL and Mistral-7B as both MindAct baselines and our intent predictor. Refer to Appendix A for more details."}, {"title": "3.2 Main Evaluation Results", "content": "Table 1 presents our main evaluation results on Mind2Web. Our method significantly enhances not only the GPT-3.5 agent but also the much stronger GPT-4, Llama-3.1-70B, and Llama-3.1-405B-FP8 agents in all cases with both Flan-T5XL and Mistral-7B intent predictors, which suggests its effectiveness. Overall, it brings noteworthy improvements to the element accuracies, which thus contribute to the step success rates as well. Our intent predictor fine-tuned on the train set produces larger improvements on the cross-task split, but we observe its efficacy even on the more challenging generalization splits, cross-website and cross-domain, outperforming MindAct with the same backbones and SeeAct as well."}, {"title": "3.3 Online Evaluation Results with Cross-Benchmark Generalization", "content": "To evaluate Auto-Intent in an online setting where agents need to interact with live websites, we conduct experiments on tasks from WebArena (Zhou et al., 2023) to leverage the automatic evaluators they provide. Specifically, we employ our intent predictors trained on the train split of Mind2Web as-is for this online evaluation in the WebArena environment, which allows us to examine Auto-Intent in two aspects: its applicability to online environments and generalization capabilities.\nTable 2 shows the results of the online evaluation. Interestingly, in this cross-benchmark online evaluation, we find that our intent predictors trained on Mind2Web improve the performance of both GPT-4 and Llama-3.1-405B agents on Shopping tasks from WebArena. It suggests that not only can Auto-Intent be useful for enhancing the decision-making capabilities of LLM agents in online environments as well, but it can also generalize to a different domain from where it is trained, which could be helpful in practical scenarios, such as demonstration data scarcity in the target domain. Refer to Appendix A.6 for more details."}, {"title": "3.4 Empirical Analysis and Ablation Study", "content": "Q1. Does our intent extractor discover underlying intents effectively?\nWe provide Figure 2 as a qualitative example of intent discovery from hard samples. While the action (CLICK <svg id=5 />) does not carry any semantic information about the underlying intent, our intent extractor successfully discovers it by understanding the context from the task, observation, and previous intents. It shows the intent extractor's capabilities of identifying intents from demonstrations with enough understanding of interactions. Additionally, in Table 3, we compare the performance of the GPT-4 baseline agent without any intents or hints and the agent with a single intent discovered with our intent extractor as a hint. It demonstrates that despite the conciseness of each discovered intent (up to three words), directly incorporating it into the LLM agent can bring significant performance improvements, which suggests the effectiveness of the intent extractor at discovering semantically valid intents from demonstrations.\nQ2. Is top-k intent prediction effective at finding the correct intent?\nWe compare the top-k predicted intents with the intent labels discovered using ground-truth actions, on the three test splits. Figure 3 shows the average recalls of the intent labels with respect to the top-k predictions computed using sentence embedding similarities (see Appendix A.1 for details). We observe that the recall enhances as k increases, which suggests that the intent prediction provides the exploration effect for finding the appropriate intent in the intent space.\nQ3. Is self-exploration with top-k intents effective?\nWe conduct an ablation study on self-exploration, where we compare Auto-Intent's performance with its variant that uses only the top-1 intent prediction without self-exploration. Table 4 shows the results on the random subset of the test splits. We find that on the cross-website and cross-domain test splits, where the generalization of the intent predictor $M_{intent}$ is more challenging, only giving the top-1 predictions is considerably less efficacious than on the cross-task split and our self-exploration provides notable performance boosts.\nQ4. Is a top-k intent prediction an effective hint for correct action prediction?\nTo examine how efficacious a top-k intent prediction hint is for predicting correct actions, we isolate the evaluation of intent hints from the LLM agent evaluation with those injected hints. For Table 4, we act with each of the top-k intents separately and aggregate the results to obtain the \"Oracle select\" performance with the best intent among the top-k. The significant improvement from the \u201cGPT-4\u201d and \"Top-1\" baselines suggests that the top-k intent prediction can be an effective hint for acting and employing a stronger pre-trained LLM might benefit the performance of our agent even further."}, {"title": "4 Conclusion", "content": "We investigated a way to improve LLM agents on downstream tasks where they possess insufficient domain knowledge. Our Auto-Intent discovers concise intents from demonstrations and predicts multiple, semantically varied intents so that our LLM policy examines the top-k intents for acting. On Mind2Web (Deng et al., 2024), a large-scale benchmark with real-website tasks, we empirically showed that our top-k intent prediction is effective for predicting correct actions and improving LLM agent's performance. In addition, we performed the evaluation of our approach in an online setting on Shopping tasks from the WebArena benchmark (Zhou et al., 2023), which suggests its applicability to online tasks and generalization capabilities to different domains from where it is trained."}, {"title": "Limitations", "content": "Our empirical investigation is limited to a web navigation setting. Although we choose Mind2Web (Deng et al., 2024) for our main evaluation as it provides a challenging, large-scale benchmark built based on many real websites and domains and different generalization problem settings, future work could examine the empirical effectiveness of our approach on more domains for decision-making, such as mobile device operation (Cheng et al., 2024)."}, {"title": "A Experimental Details", "content": ""}, {"title": "A.1 Dataset and Evaluation", "content": "Dataset We employ Mind2Web (license: CC BY 4.0, allows research purposes) (Deng et al., 2024), a large-scale web navigation dataset with task instructions and corresponding trajectories on 137 real websites. The dataset is in English and constructed by explicitly instructing annotators to refrain from using personal or sensitive information. The goal is to complete each given natural language task by performing a series of actions, where three types of actions exist: CLICK, SELECT, and TYPE. The agent needs to choose the target element to perform each action with, and each SELECT or TYPE action additionally requires a string value for selecting a specific option or typing the desired text, respectively. Mind2Web provides three test splits for evaluating web navigation agents' generalization capabilities. The cross-task split is the most in-distribution setting; it contains new tasks but in the domains and websites seen from the train split. The cross-website split has new tasks on unseen websites but in previously seen domains. Lastly, the cross-domain split is for testing with new tasks in unseen domains as well as websites. We summarize the information about the Mind2Web dataset and its statistics in Table 5.\nEvaluation metrics. We employ the evaluation protocol by Deng et al. (2024). The element accuracy (\"Elem. acc\") measures whether the agent chose one of the ground-truth elements from the web page at each time step. The operation F1 (\"Op. F1\") is the F1 score for the predicted action (the type and string value) computed with respect to the ground-truth action. The step success rate (\"Step SR\") counts successful steps, where each step is considered successful only if the chosen target element is correct and the action type and string value match the ground truth. Following Deng et al. (2024), these three step-wise metrics are macro-averaged over tasks. For our empirical analysis based on embedding similarity (Q2 from Section 3.4), we use all-mpnet-base-v2 (Apache 2.0, allows research purposes) from SentenceTransformers (Reimers and Gurevych, 2019; Song et al., 2020)."}, {"title": "A.2 Compared Methods", "content": "We employ the same element-ranking model suggested and provided by Deng et al. (2024). Given each element from the web page, the model outputs the score for its correctness as a target element. The element-ranking model alone is not as effective at predicting correct target elements by choosing the highest-scoring elements. However, as each web page often contains numerous candidate elements, the element-ranking model is used to reduce the set of candidate elements by keeping only top-N-scoring elements, as the first stage of the action prediction with all the compared methods. MindAct (Deng et al., 2024) uses N = 50 and conducts a tournament of elements, by grouping N = 50 candidate elements into sets of 5 or less. SeeAct (Zheng et al., 2024) groups N = 50 candidates into three batches and tries predicting the action given each with the screenshot. For our in-context learning (ICL) agents with or without intents, we predict the action in a single pass given all the top-N candidates at once."}, {"title": "A.3 Intent Extractor", "content": "For discovering intents given demonstration trajectories, we use our intent extractor $M_{extract}$ powered by GPT-4 (gpt-4-0125-preview) (Achiam et al., 2023) for our GPT agents and by Llama-3.1-405B-FP8 (Dubey et al., 2024) for our Llama agents, with the prompt in Figure 4. While we use three in-context examples, we only present one example due to the limited space. The input for actual samples follows the same format as the in-context examples, where the previously discovered intents are used as part of the input for discovery in subsequent time steps."}, {"title": "A.4 Intent Predictor", "content": "For training our intent predictor $D_{intent}$, we augment each of the transitions from the train set of Mind2Web (Deng et al., 2024) with intents discovered with the intent extractor $M_{extract}$, where the target intent is randomly selected from 5 intents obtained with a temperature of 0.2. Similarly to the dataset augmentation practice by Deng et al. (2024), for each transition from the original trajectory, we form 32 samples with different candidates from the top-80-scoring elements, where 5% of the original train set is excluded for a validation purpose. We employ Mistral-7B-v0.1 (~ 7B parameters, license: Apache 2.0, allows research purposes) (Jiang et al., 2023) for fine-tuning with Low-Rank Adaptation (LoRA) (Hu et al., 2021) and Flan-T5-XL (~ 3B parameters, license: Apache 2.0, allows research purposes) for full fine-tuning, on the intent-augmented train set. We estimate approximately 1k GPU hours (Nvidia A100 40GB) are used for training Mistral-7B-v0.1, including the exploration and hyperparameter search. For the additional Flan-T5-XL training and hyperparameter search, we roughly used 0.4k GPU hours (Nvidia A100 40GB). See Table 6 and Table 7 for the hyperparameter search for Mistral-7B-v0.1 and Flan-T5-XL respectively with best-found values (bold-faced). For intent prediction during the inference phase, we generate up to 5 tokens and use up to 12 beams for N = 20 and up to 8 beams for N = 40, where the full beam search for each input takes around 1 second."}, {"title": "A.5 LLM Policy", "content": "Given the top-k predicted intents, we use a prompt-based LLM policy for action prediction. We present our prompt for the LLM policy, powered by GPT-4 (gpt-4-0125-preview), GPT-3.5 (gpt-3.5-turbo-0125), Llama-3.1-70B, and Llama-3.1-405B-FP8 in Figure 5. We incorporate two in-context examples, but due to the limited space, we show only one example. The actual sample input follows the same format as the in-context examples, but we use the in-context examples from a simpler setting (with N = 7 element choices) than the actual problem setting (with N = 20 or N = 40 element choices) to avoid having overly long input contexts. Note that using a smaller N deteriorates the correct element recall and the upper-bound performance as well. We use k = 5 top intent predictions for N = 20 element choices and k = 7 top intent predictions for N = 40 element choices."}, {"title": "A.6 Online Evaluation", "content": "For the online evaluation, we use a subset of tasks from the Shopping split of the WebArena benchmark (Zhou et al., 2023) with automatic evaluators based on URLs. We leverage our fine-tuned Mistral-7B intent predictors from the Mind2Web experiments without any modifications. As Mind2Web (Deng et al., 2024) does not include stop actions in its dataset, we perform step-wise evaluations to check task completion for all the compared methods. We employ the observation processing and element-ranking model described in Appendix A.2 for all the methods compared in this online evaluation."}]}