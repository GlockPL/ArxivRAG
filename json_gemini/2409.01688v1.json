{"title": "Differentially Private Kernel Density Estimation", "authors": ["Erzhi Liu", "Jerry Yao-Chieh Hu", "Alex Reneau", "Zhao Song", "Han Liu"], "abstract": "We introduce a refined differentially private (DP) data structure for kernel density estimation (KDE), offering not only improved privacy-utility tradeoff but also better query efficiency over prior results. Specifically, we study the mathematical problem: given a similarity function $f$ (or DP KDE) and a private dataset $X \\subset \\mathbb{R}^d$, our goal is to preprocess $X$ so that for any query $y \\in \\mathbb{R}^d$, we approximate $\\sum_{x \\in X} f(x, y)$ in a differentially private fashion. The best previous algorithm for $f(x,y) = ||x - y||_1$ is the node-contaminated balanced binary tree by [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. Their algorithm requires $O(nd)$ space and time for preprocessing with $n = |X|$. For any query point, the query time is $d \\log n$, with an error guarantee of $(1 + \\alpha)$-approximation and $\\epsilon^{-1}\\alpha^{-0.5}d^{1.5} R \\log^{1.5} n$.\nIn this paper, we use the same space and pre-processing time, improve the best previous result [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024] in three aspects\n*   We reduce query time by a$\\alpha^{-1} \\log n$ factor\n*   We improve the approximation ratio from $\\alpha$ to 1\n*   We reduce the error dependence by a factor of $\\alpha^{-0.5}$\nFrom a technical perspective, our method of constructing the search tree differs from previous work [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. In prior work, for each query, the answer is split into $\\alpha^{-1}\\log n$ numbers, each derived from the summation of $\\log n$ values in interval tree countings. In contrast, we construct the tree differently, splitting the answer into $\\log n$ numbers, where each is a smart combination of two distance values, two counting values, and $y$ itself. We believe our tree structure may be of independent interest.", "sections": [{"title": "Introduction", "content": "We propose a refined differentially private (DP) data structure for DP kernel density estimation, offering improved privacy-utility tradeoff over prior results without compromising efficiency. Let $X \\subset \\mathbb{R}^d$ be a private dataset, and let $f(x, y) : \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a similarity function\u00b9, such as a kernel or distance function, between a user query $y \\in \\mathbb{R}^d$ and a private data point $x \\in X$.\nProblem 1 (DP Kernel Density Estimation Query). The DP Kernel Density Estimation (KDE) query problem aims for an algorithm outputting a private data structure $D_X : \\mathbb{R}^d \\rightarrow \\mathbb{R}$, that approximates the map $y \\rightarrow \\sum_{x \\in X} f(x, y)$ in a DP fashion\u00b2. Especially, we require $D_X$ to remain private with respect to $X$, regardless of the number of queries.\nProblem 1 is well-studied [HRW13, HR14, WJF+16, AR17, ACSS20, CS21, AA22, QRS+22, AS23, GSY23, WNM23, AS24, HLSL24, LLSS24, BLM+24] due to its broad applicability and its importance in productizing large foundation models [LGK+24, XLB+24]. What makes this problem interesting is its generic abstraction of many practical DP challenges in modern machine learning. These include generating synthetic data similar to a private dataset [LJW+20, LTLH22, YNB+22, YLJ+22], and selecting a similar public dataset for pre-training ML models [HZS+23, YGK+24, YIL+23]. Such problem becomes more prevalent in this era of large foundation models [LGK+24, XLB+24]. Essentially, these problems involve computing the similarity between a private dataset (i.e., $X$) and a processed data point (i.e., query $y$), thus falling under Problem 1.\nIn this note, we focus on the $l_1$ kernel\u00b2 (i.e., $f(x, y) = ||x - y||_1$). By far, the algorithm with the best privacy-utility tradeoff and query efficiency for Problem 1 is by Backurs, Lin, Mahabadi, Silwal, and Tarnawski [BLM+24]. They propose a DP data structure via a node-contaminated balanced binary tree for $l_1$ kernel. To be concrete, we begin by defining the similarity error between two data structures and then present their results.\nDefinition 1.1 (Similarity Error between Two Data Structures). For a fixed query, let $A$ represent the value output by our private data structure, and let $A'$ represent the true value. We say that $A$ has an error of $(\\mathcal{M}, \\mathcal{Z})$ for $\\mathcal{M} \\geq 1$ and $\\mathcal{Z} > 0$, if $E[|A - A'|] \\leq (\\mathcal{M} - 1)A' + \\mathcal{Z}$. This implies a relative error of $\\mathcal{M} - 1$ and an additive error of $\\mathcal{Z}$. The expectation is taken over the randomness used by the data structure.\nLet $n := |X|$ be the size of the dataset, $X_{i,j}$ be the $j$-th dimension of the $i$-th data point, $R := \\max_{i,j}(X_{i,j})$ be the max value of each data entries from each dimension, and $\\alpha \\in [0,1]$ be a parameter of the data structure selected before calculation. For $l_1$ kernel, [BLM+24] gives the error bound $(1 + \\alpha, \\alpha^{-0.5}\\epsilon^{-1} R d^{1.5} \\log^{1.5} n)$ through their DP data structure."}, {"title": "Preliminaries", "content": "For a positive integer $n$, we use $[n]$ to denote $\\{1,2,\\dots,n\\}$. For a vector $x$, we use $||x||_1 := \\sum_{i=1}^n |x_i|$ to denote its $l_1$-norm. We use $E[\\cdot]$ to denote the expectation. We use Var$[\\cdot]$ to denote the variance. We use Pr$[\\cdot]$ to denote the probability. We use Laplace$(\\lambda)$ random variable with parameter $\\lambda$. It is known that $E[$Laplace$(\\lambda)$] = 0$ and Var$[Laplace(\\lambda)] = 2\\lambda^2$."}, {"title": "Basic Facts", "content": "Fact 2.1. Let $X$ denote a random variable with $E[X] = 0$. Then it holds\n$E[|X|] \\leq (Var[X])^{1/2}$."}, {"title": "Differential Privacy", "content": "For completeness, we state the definitions of differential privacy [DMNS06, DRV10].\nDefinition 2.1 (Pure/Approximate Differential Privacy). A randomized algorithm $\\mathcal{M} : \\mathcal{X}^n \\rightarrow \\mathcal{Y}$ satisfies $(\\epsilon, \\delta)$-differential privacy if, for all $x,x' \\in \\mathcal{X}^n$ differing on a single element and for all events $E \\subset \\mathcal{Y}$, we have Pr$[\\mathcal{M}(x) \\in E] < e^\\epsilon \\cdot$ Pr$[\\mathcal{M}(x') \\in E] + \\delta$\nFor special case of $(\\epsilon, 0)$-differential privacy, we use pure or pointwise $\\epsilon$-differential privacy to denote it. For the other case of $\\delta > 0$, we denote it as approximate differential privacy.\nNext, we introduce a common tool in DP proofs. For multiple independent DP functions, the next lemma provides an estimation on the privacy of their composition:\nLemma 2.1 (Advanced Composition Starting from Pure DP [DRV10]). Let $\\mathcal{M}_1, ..., \\mathcal{M}_k : \\mathcal{X}^n \\rightarrow \\mathcal{Y}$ be randomized algorithms, each of which is $(\\epsilon, \\delta)$-DP. Define $\\mathcal{M} : \\mathcal{X}^n \\rightarrow \\mathcal{Y}^k$ by $\\mathcal{M}(x) = (\\mathcal{M}_1(x), ..., \\mathcal{M}_k(x))$ where each algorithm is run independently. Then $\\mathcal{M}$ is $(\\epsilon', \\delta')$-DP for any $\\epsilon, \\delta > 0$ and\n$\\epsilon' = k\\epsilon^2/2 + \\epsilon\\sqrt{2k \\log(1/\\delta)}$\nFor $\\delta = 0, \\mathcal{M}$ is $k\\epsilon$-DP."}, {"title": "[BLM+24]'s DP Data Structure: Node-Contaminated Balanced Tree", "content": "[BLM+24] propose a data structure for general high-dimensional (e.g., $d$-dimensional) $l_1$ kernel via 1-dimensional decomposition: $\\sum_{x \\in X} ||x - y||_1 = \\sum_{i=1}^d \\sum_{x \\in X} | x_i - y_i|$. Namely, they create a DP data structure for a $d$-dimensional dataset $X$ by considering $d$ copies 1-dimensional DP data structures (i.e., $\\sum_{x \\in X} | x_i - y_i|$ for $i \\in [d]$). For each of these 1-dimensional DP data structures, they employ a node-contaminated balanced tree algorithm as follows.\nLet $n = |X|$ be the size of the dataset $X$. Considering all input values are integer multiples of $R/n$ in $[0, R]$,"}, {"title": "High-Level Overview of Our DP Data Structure", "content": "We improve [BLM+24] by providing a refined balanced tree for DP 1-dimensional $l_1$ KDE. Specifically, we introduce a new data representation on each node of the balanced binary tree as follows.\nLet $n = |X|$ be the size of the dataset $X$ and $\\{x_k\\} \\in [0, R)$ for $k \\in [n]$.\n1.  We use a balanced binary tree where in each node stores both distance $s$ and the counts $c$. Here, $s$ denotes the pre-summation of certain distances, and $c$ denotes the pre-counting.\n2.  We make a key observation (Lemma 3.1) that these values ($s$ and $c$) are not depending on query $y$, while they are critical components of the final answer (the $l_1$ kernel $\\sum_{x \\in X} ||x - y||_1$). This motivate us to construct the answer by using $L = \\log n$ layers result, where each layer result is a smart combination of $y, s_1, s_2, c_1, c_2$ (i.e, $(s_1 - s_2 + y \\cdot (c_1 - c_2))$).\n3.  To ensure DP, we need a noise version of the tree, due to $s$ and $c$ have different sensitivities, thus we need to add different levels of noise for $s$ and $c$.\nA few remarks are in order:\n*   Query Time. For each query $y$, to report the answer, we first extract four $L = O(\\log n)$ numbers along with $y$ and apply a special function: $(s_1 - s_2 + y \\cdot (c_1 - c_2))$ (see our key observation in Lemma 3.1).\n*   Error Bound and Accuracy. Since our algorithm does not use the $(1 + \\alpha)^i$ region concept, we avoid the $\\alpha^{-1}$ error. As a result, our error is purely additive, with no relative error.\n*   Sensitivity and DP Guarantee. Since $s$ approximates the summation of distances, the sen- sitivity is $O(LR)$, where each node in one of the $L$ layers contributes a factor of $R$. On the other hand, since $c$ counts the points, its sensitivity is $O(L)$, with each node in the $L$ layers contributing an $O(1)$ factor. Previous work [BLM+24] only use $y$ to determine which region to count points, but our algorithm uses $y$ to construct the final answer. Since $y < R$, this explains the $R$ gap between the noise levels in $s$ and $c$."}, {"title": "Related Works", "content": "Privacy, Security and Safety in Large Foundation Models. The motivating problems for this work come from the privacy concerns of large foundation models [LGK+24, XLB+24]. In mod- ern machine learning, Foundation models [BHA+21], including pretrained transformer and dif- fusion models, gain popularity in many AI applications due to their ability to generalize across diverse tasks with minimal fine-tuning. Pretrained transformers, such as BERT [DCLT18], GPT [BMR+20], and Llama [TMS+23, TLI+23], leverage vast amounts of data to learn general- purpose, context-aware representations. Diffusion models [PX23, HJA20, SE19], on the other hand, excel in generative tasks, particularly in producing high-quality images and data distribu- tions through iterative refinement [NDR+21, RDN+22, LZL+24, ZCY+24, ZXC+24, WZY+24, WWS+24]. Importantly, what makes them fundamental and versatile is their flexibility for diverse downstream tasks via fine-tuning methods [ZZZ+24, DQY+22, LARC21, LJF+21, HysW+22], hence \u201cfoundation.\u201d Together, these models signify a shift towards more powerful AI systems that serve as the basis for a wide range of applications across different domains.\nHowever, despite their empirical [FC20, YLW23, WIL+23, NPF+24, ZWH+24, ZJL+23, JZLD21, TTE+23, SAT+23, MBA+23, HCL+24, LZL+24, EKB+24, MGA+24, PX23, GZCY23, ZNVA23, BLCZ22] and theoretical successes [BCW+23, WCWH23, KS24, ZL24, LWL+24, LWLC23, LIPO23, TLTO23, WHHL24, WHL+24, AS24, AS23, HSK+24, HYW+23, RSL+20, YBR+20, LLSS24, SWXL24, XSL24, LSSZ24b, LSSZ24a, LSSS24, LLS+24b, LLS+24a, LSSY24, WMS+24, CMFW24, FDG+24, FYWC24, WCL+24, DCWY24, GYY+24, HWSL24, LWCC24, ZLC23, WWY24, CCL+23a, CHZW23, OAS23, CCL+23b], there exists a gap from productizing many these advancements due to privacy, safety, and security concerns [QHZ+24, SHW+24, LHLW24, WMR+21]. These models, due to their vast scale and extensive training on large datasets, risk exposing sensitive information and amplifying biases present in the data. Privacy issues arise when models inadvertently memorize and reproduce personal data from training sets [CHN+23, CTW+21]. Safety concerns include the potential for generating harmful or misleading content, especially in applications where accuracy is paramount [WMR+21, Ope23, TAB+23, Ant23, YLH+24, LYZ+24, SCB+24, DLL+23, LDX+23, LXCX23, SPT+23, YLX23]. Security vulnerabilities also exist, as these models may be susceptible to adversarial attacks that manipulate outputs or extract proprietary information [ZYZ+24, JXN+24, XQZ+24]. Addressing these challenges is essential to ensure the responsible and secure use of foundation models across various applications. In this work, we focus on the privacy of foundation models at a fundamental level by study the formalized KDE query Problem 1.\nDifferential Privacy (DP). Differential Privacy (DP) is a standard tool for understanding and mitigating privacy concerns in machine learning. Proposed by [DMNS06], DP offers a robust approach to protecting sensitive information. Given the fact that non-private ML models ex- pose sensitive user data [FJR15, CLE+19, CYZF20, CTW+21, CCN+22, CIJ+23, HVY+22, TSJ+22, CHN+23], researchers propose various methodologies. One approach involves gener- ating synthetic datasets that closely resemble the original private data and training models on these synthetic datasets [LJW+20, LTLH22, YNB+22, YLJ+22, YIL+23, LGK+24]. Another strategy is to use similar public examples for pre-training models [HZS+23, YGK+24]. Addition- ally, the DP-SGD method has benefited from incorporating public data similar to private datasets to enhance downstream model performance [YZCL21, DBH+22, YNB+22, YLJ+22, LTLH22, HZS+23, YGK+24, LGK+24]. As highlighted by [BLM+24], the common denominator of all these works is the need to compute similarities to a private dataset. In this work, we study this problem at a fundamental level by formalizing it as the PD-KDE query problem (Problem 1).\nKernel Density Estimation (KDE). Kernel Density Estimation (KDE) is a key technique in statistics and machine learning. This technique converts a collection of data points into a smoothed probability distribution [SS02, STC04, HSS07]. It is prevalent in many private ap- plications such as crowdsourcing and location sharing [HWM+19, CCF21]. Although research on non-private KDE already produce efficient methods [BCIS18, BIW19, ACSS20, CKNS20, LSXZ22, QRS+22, BIK+22, HSW+22, DJS+22], adapting these techniques to DP remains com- plex [GRU12, BLR13, AR17, WNM23, BLM+24]. The best algorithm to date is by [BLM+24]. In this work, we introduce a new data structure for DP-KDE that improves upon [BLM+24] in both privacy-utility trade-off and efficiency."}, {"title": "A Refined Differentially Private Data Structure", "content": "We propose a new data structure with $\\epsilon$-differential privacy that achieves $O(\\epsilon^{-1}R\\log^{2}n)$ additive error. Our method improves the balanced binary tree structure proposed by Backur, Lin, Ma- habadi, Silawal, and Tarnawsk [BLM+24] in both DP guarantee and efficiency. Our data structure adapts a new data representation on each node that simplifies each query without losing privacy guarantees."}, {"title": "Key Observation and New Data Structure for One Dimensional $l_1$ KDE Query", "content": "For simplicity, we consider the 1-dimensional KDE query problem with $l_1$ kernel distance. Note that any high-dimensional KDE query problem can be reduced to this case via the 1-dimensional decomposition discussed in Section 2.3 or in [BLM+24].\nWhen doing queries, we observe that\nLemma 3.1. For a collection of values $\\{x_1,x_2,\\cdots, x_n\\} \\subset \\mathbb{R}$ and a value $y$, we define two sets\n$S_+ := \\{k \\in [n] : x_k > y\\}$\n$S_- := \\{k \\in [n] : x_k < y\\}$.\nIt holds\nProof.\nn\\\\\n$\\sum_{k=1} |x_k - y| = (\\sum_{x_k \\in S_+} x_k) - (\\sum_{x_k \\in S_-} x_k) +y \\cdot |S_-|-y\\cdot |S_+|$.\n$\\sum_{k=1} |x_k - y| = \\sum_{k \\in S_+} (x_k - y) + \\sum_{k \\in S_-} (y - x_k)$\n$= (\\sum_{k \\in S_+} x_k) - (\\sum_{k \\in S_-} x_k) + y \\cdot (\\sum_{k \\in S_-} 1) - y \\cdot (\\sum_{k \\in S_+} 1)$\n$= (\\sum_{k \\in S_+} x_k) - (\\sum_{k \\in S_-} x_k) + y \\cdot |S_-| - y \\cdot |S_+|$.\nLemma 3.1 provides a neat decomposition of the $l_1$ KDE query into four components. This motivates us to design a new PD data structure that pre-computes these terms and storing them in a balanced tree for possible algorithmic speedup. Surprisingly, this preprocessing not only accelerates query time but also improves the privacy-utility tradeoff. The following discussion illustrates this.\nTo calculate each part efficiently, we define our data representation on a balanced binary tree as follows:\n*   Dataset: Given a dataset $X := \\{x_i\\}_{i=1}^n$ containing $n$ values in the range $[0, R)$, we build a balanced binary tree using $X$.\n*   Tree Structure:\n    *   Let $L$ denote the total number of layers in the tree.\n    *   At the $l$-th layer, there are exactly $2^l$ nodes.\n*   Node Representation:\n    *   Each node represents a consecutive interval of $X$.\n    *   The interval for the $j$-th node at the $l$-th layer is defined as $I_{l,j} := [(j - 1) \\cdot \\frac{R}{2^l}, j \\cdot \\frac{R}{2^l})$.\n    *   The left and right children of $I_{l,j}$ are $I_{l+1,2j-1}$ and $I_{l+1,2j}$, respectively.\nEach node $I_{l,j}$ stores two values: $c_{l,j}$ and $s_{l,j}$. Here:\n*   $c_{l,j} := |\\{x_k : x_k \\in I_{l,j}\\}|$ represents the count of data points in the interval.\n*   $s_{l,j} := \\sum_{x_k \\in I_{l,j}} x_k$ represents the sum of the data points' values in the interval.\nAfter calculating each $c_{l,j}$ and $s_{l,j}$, we add independent noise drawn from Laplace$(\\frac{L}{\\epsilon})$ to each $c$ value and from Laplace$(\\frac{LR}{\\epsilon})$ to each $s$ value. The INIT algorithm (Algorithm 1) outlines the construction of our data structure.\nIn the QUERY algorithm (Algorithm 2), we sum the $s$ and $c$ values at the relevant nodes. Here:\n*   $s_{\\text{left}}$ represents $\\sum_{x_k \\in S_-} x_k$\n*   $c_{\\text{left}}$ represents $|S_-|$\n*   $s_{\\text{right}}$ represents $\\sum_{x_k \\in S_+} x_k$\n*   $c_{\\text{right}}$ represents $|S_+|$\nFor each query, we first locate the leaf that $y$ belongs to, then traverse the tree from the bottom up, summing the values of the left and right nodes.\nNext, we prove the time complexity, differential privacy property and error of results of out algo- rithm respectively."}, {"title": "Time Complexity", "content": "Lemma 3.2 (Init Time). If he total layer $L = \\log(n)$, the running time of INIT (Algorithm 1) is $O(n)$.\nProof. By definition, on $l$-th layer, there are $2^l$ nodes. Therefore, the total number of nodes is $\\sum_{l=1}^L 2^l = 2^{L+1} - 1$. When $L = \\log(n)$, the total number of nodes on the tree is $O(n)$. In INIT (Algorithm 1), we iterate over $n$ data points, then iterate all nodes. Therefore the total time complexity of pre-processing is $O(n)$.\nLemma 3.3 (Query Time). If the total layer $L = \\log(n)$, the time QUERY function (Algorithm 2) is $O(\\log(n))$ time.\nProof. For each single query, we iterate the node that $y$ belongs to on each layer. The total layer number is $\\log(n)$, so the time complexity of each query is $O(\\log(n))$"}, {"title": "Privacy Guarantees", "content": "Lemma 3.4 (Differential Privacy). The data structure FASTERTREE returned by FASTERTREE.INIT (Algorithm 1) is $\\epsilon$-DP.\nProof. For binary tree of $L$ layers, there are $2^{L+1} - 1$ nodes. On each node, there are 2 values $s$ and $c$. We consider $c$ and $s$ separately.\nLet the functions $\\mathcal{F}_c(X)$ and $\\mathcal{F}_s(X) : [0, R)^n \\rightarrow [\\mathbb{R}]^{2^{L+1}-1}$ represent the mappings from dataset $X$ to $c$ and $s$, respectively. Next, we prove that both $\\mathcal{F}_c(X)$ and $\\mathcal{F}_s(X)$ are $\\epsilon/2$-DP.\nWhen changing each data point, only the nodes containing the point change their values. On each layer, there is at most one such node. Therefore, only $O(L)$ values change.\nSensitivity for Storing Counts. For $\\mathcal{F}_c$, each $c$ value changes by at most 1, so the sensitivity is $L$. Adding coordinate-wise Laplace noise with magnitude $\\eta = O(2L/\\epsilon)$ suffices to ensure $\\epsilon/2$-DP using the standard Laplace mechanism.\nSensitivity for Storing Distances. For $\\mathcal{F}_s$, changing one data entry affects at most $O(L)$ values, and each value can be affected by at most $R$. Therefore, the sensitivity is $RL$. Adding coordinate-wise Laplace noise with magnitude $\\eta = O(2RL/\\epsilon)$ ensures $\\epsilon/2$-DP.\nBy Lemma 2.1, the differential privacy parameter $\\epsilon$ of the tree $T := (\\mathcal{F}_c(X), \\mathcal{F}_s(X))$ equals $2 \\cdot \\epsilon/2 = \\epsilon$. This completes the proof."}, {"title": "Error Guarantee", "content": "Lemma 3.5 (Error Guarantee). Let $X = \\{x_i\\}_{i \\in [n]}$ be a dataset of $n$ one dimensional values $x_i \\in [0, R)$. Let $A' = \\sum_{i=1}^n |x_i - y|$ be the true distance query value. Let $A$ be the output of QUERY (Algorithm 2) with $L = \\log(n)$. Then we have $E[|A - A'|] \\leq O(\\log^{1.5}(n)R/\\epsilon)$.\nProof. We analyze the additive error of our algorithm. We notice that the difference between true distance and our output can be divided into two parts.\nPart I. The first part is the data in the leaf node which contains query $y$. In QUERY(Algorithm 2), We ignore these data points. Let the leaf node $i$ of layer $L$ be the node that query point $y$ belongs to. The error is\n$\\sum_{x_k \\in [(j-1)\\cdot R/2^L,j\\cdot R/2^L)} |x_k - y|$.\nSince the distance between each data point and $y$ is no more than the length of the interval $R/2^L$, and their total number is no more than $n$. When $L = \\log(n)$, this error is $O(R)$.\nPart II. The second part is the Laplace noises. In our query, we add up $c$ and $s$ from $O(L)$ intervals. In these intervals, each contains a Laplace noise. Therefore, the total error is the sum of these noises:\nE[|A - A'|] < E[|$\\sum_{i=1}^L Laplace(RL/\\epsilon) + y \\cdot \\sum_{i=1}^L Laplace(L/\\epsilon)$|]\n< E[|$ \\sum_{i=1}^L Laplace(RL/\\epsilon)$|] + |y| $\\cdot$ E[|$ \\sum_{i=1}^L Laplace(L/\\epsilon)$|]\nwhere the second step follows from triangle inequality.\nFor a random variable $Q$ with E[$Q$] = 0, using Fact 2.1 we have E[|$Q$|] $\\leq$ $\\sqrt{Var[Q]}$, thus\nE[|A - A'|] $\\leq$ $(Var[$\\sum_{i=1}^L Laplace(RL/\\epsilon)$])$^{1/2}$ + |y| $\\cdot$ $(Var[$\\sum_{i=1}^L Laplace(L/\\epsilon)$])$^{1/2}$\n< $\\sqrt{L \\cdot Var [Laplace(RL/\\epsilon)]}$ + |y|$\\cdot$ $\\sqrt{ L \\cdot Var[Laplace(L/\\epsilon)]}$\n= $\\sqrt{L \\cdot 2R^2L^2/\\epsilon^2}$ + |y|$\\cdot$ $\\sqrt{ L \\cdot 2L^2/\\epsilon^2}$\n= $\\sqrt{2} \\cdot$ ($R$ + |y|)$L^{1.5}/\\epsilon$\n= $O(\\epsilon^{-1}R\\log^{1.5}(n))$.\nwhere the third step follows from Var[Laplace($\\lambda$)] = $2\\lambda^2$. The last step is because $y \\in [0, R)$ and $L = \\log(n)$"}, {"title": "One Dimensional Data Structure", "content": "Theorem 3.1. Given a dataset $X \\subset \\mathbb{R}$ with $|X|$. There is an algorithm that uses $O(n)$ space to build a data-structure (Algorithm 1, 2) which supports the following operations\n*   INIT($X, \\epsilon$) It takes dataset $X$ and privacy parameter $\\epsilon$ as input and spends $O(n)$ time to build a data-structure.\n*   QUERY($y \\in \\mathbb{R}$). It takes $y$ as input and spends $O(\\log n)$ time to output a scalar $A$ such that E[|$A - A'|$] < $O(\\epsilon^{-1}R\\log^{1.5} n)$.\nFurthermore, the data structure is $\\epsilon$-DP.\nProof. By Lemma 3.2, we prove the storage space, and the initialization time.\nBy Lemma 3.3, we prove the query time of the data-structure.\nBy Lemma 3.4, we prove the differential privacy guarantee.\nBy Lemma 3.5, we prove the error guarantee after adding the noise."}, {"title": "High Dimensional $l_1$ Distance Query", "content": "By applying our one dimensional data structure on each dimension independently, we calculate high dimensional queries."}, {"title": "High Dimensional Distance Query", "content": "Lemma 3.6 (Differential Privacy). The data structure HIGHDIMFASTERTREE returned by HIGHDIMFASTERTREE.INIT (Algorithm 3) is $\\epsilon$-DP.\nProof. The proof directly follows from calling Lemma 3.4 for $d$ times with replacing $\\epsilon$ by $\\epsilon/d$. Then using the DP composition Lemma.\nLemma 3.7 (Error Guarantee). Let $X = \\{x_i\\}_{i \\in [n", "A'|$": "O(\\epsilon^{-1}Rd^{1.5}\\log^{1.5} n)$.\nProof. The output of Algorithm 3 is the sum of each dimension. Let $A_i'$ be the output of $D_i$, $A_i$ be the true distance of the $i$-th dimension. The total error of Algorithm 3 is $|\\sum_{i=1}^d (A_i - A_i')|$. From the proof of Algorithm 2, we know $A_i - A_i'$ is the sum of $O(L)$ Laplace noises, where $L = O(\\log n)$. Therefore, we have E[$A_i - A_i'$", "A_i'$": "O(\\epsilon^{-2}d^2R^2 \\log^3(n))$. Using the independence property of $A_i - A_i'$ for all $i$, we bound $|\\sum_{i=1}^d (A_i - A_i')|$ by\nE[|$ \\sum_{i=1}^d (A_i - A_i')$|"}, {"A_i'$": {}}]}