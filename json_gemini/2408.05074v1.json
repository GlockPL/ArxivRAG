{"title": "RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records", "authors": ["Sangjoon Park", "Chan Woo Wee", "Seo Hee Choi", "Kyung Hwan Kim", "Jee Suk Chang", "Hong In Yoon", "Ik Jae Lee", "Yong Bae Kim", "Jaeho Cho", "Ki Chang Keum", "Chang Geol Lee", "Hwa Kyung Byun", "Woong Sub Koom"], "abstract": "Background: Accurate patient selection is essential in radiotherapy (RT) to prevent ineffective\ntreatments. Traditional survival prediction models, which rely on structured data, often lack\nprecision. Large language models (LLMs) offer a novel approach to structuring unstructured\nelectronic health record (EHR) data, potentially improving survival predictions by integrating\ncomprehensive clinical information.\nMethods: This study analyzed data from 34,276 patients treated with RT at Yonsei Cancer\nCenter from 2013 to 2023. The dataset included structured and unstructured data. An open-\nsource LLM was used to structure the unstructured EHR data using single-shot learning. The\nLLM's performance was compared with a domain-specific medical LLM and a smaller variant.\nSurvival prediction models were developed using statistical, machine learning, and deep\nlearning approaches, incorporating both structured and LLM-structured data. Clinical experts\nevaluated the LLM-structured data's accuracy.\nFindings: The open-source LLM achieved an average accuracy of 87.5% in structuring\nunstructured EHR data, without requiring additional training. The domain-specific medical\nLLM performed significantly worse, with only 35.8% accuracy. Larger LLMs proved more\neffective, particularly in extracting clinically relevant features like general condition and\ndisease extent, which correlated with patient survival. Incorporating LLM-structured clinical\nfeatures into survival prediction models substantially improved their accuracy, with the C-\nindex increasing from 0.737 (95% confidence interval [CI] 0.727-0.746) to 0.820 (95% CI\n0.813-0.827) in deep learning model. The models also became more interpretable by\nemphasizing clinically meaningful factors.\nInterpretation: This study shows that general-domain LLMs, despite not being specifically\ntrained on medical data, can effectively structure large-scale unstructured EHR data,\nsignificantly improving the accuracy and interpretability of clinical predictive models.\nKeywords: Large language models; Electronic health records; Data structurization;\nRadiotherapy; Survival prediction", "sections": [{"title": "Introduction", "content": "Radiotherapy (RT) is an essential component in cancer treatment, with approximately 60% of\ncancer patients undergoing RT during their treatment course, according to the 2023 Radiation\nOncology Case Rate Report.\u00b9 Projections from the SEER database indicate that the number of\nRT patients will rise to 3.38 million by 2020 and 4.17 million by 2030.2 The benefits of RT,\nsuch as symptom relief and improved survival, are well documented but are influenced by\nfactors including tumor type, treatment site, and patient health status. However, some patients\nmay not live long enough to benefit from RT, making accurate patient selection crucial to avoid\nunnecessary treatments, burdens, and healthcare costs.3,4\nSeveral studies have aimed to predict survival outcomes for RT patients by focusing\non short-term mortality factors or developing prognostic nomograms. 5-7 However, these\nmethods often fall short in accurately predicting survival durations, thus limiting their practical\nutility in clinical decision-making. The advent of machine learning has enabled the exploration\nof survival prediction in RT patients using electronic health record (EHR) data, primarily\nstructured data like patient demographics, vital signs, and laboratory results. This approach,\nhowever, neglects critical information found in unstructured clinical notes, such as disease\nextent, treatment purpose, and patient condition. Manually structuring this unstructured data is\nimpractical on a large scale.\nLarge language models (LLMs), such as OpenAI's ChatGPT, have demonstrated\nsignificant capabilities in processing unstructured text. These models can perform new tasks\nwith few-shot learning, enabling data structuring without explicit training, heralding a new era\nof generative artificial intelligence models.9-11 Their flexibility and adaptability, especially\nwhen well-structured prompts are used, make them ideal for structuring clinical records.\nConsequently, there is growing interest in using LLMs for data standardization in the medical\ndomain. 12-14\nThis study aims to develop a model to predict post-RT mortality by leveraging\ncomprehensive structured and unstructured data from patient records at a large-volume center.\nUsing an open-source LLM that can be deployed with internal hospital resources, we ensure\ndata privacy without risking patient information leakage. By structuring unstructured clinical\ndata, we aim to enhance survival prediction accuracy and provide guidelines on how LLMs can\nbe effectively utilized in clinical practice through data standardization, ultimately advancing\npatient outcomes."}, {"title": "Materials and Methods", "content": "Study design and participants\nWe utilized data from a single large-volume center to create a model that could aid clinical\ndecision-making by providing estimated survival predictions at the time of consultation for RT,\nthereby informing treatment decisions of practicing physicians.\nData were collected from patients who underwent RT at Yonsei Cancer Center between\nAugust 2013 and July 2023. Patients were excluded if they had (1) incomplete radiation\noncology records that hindered the LLM's ability to structure data or (2) an inability to confirm\npost-RT survival through the national insurance system. Of the 51,821 patients treated, 34,276\nwere included in the LLM structurization analysis and 25,183 in the survival prediction\nanalysis. A random 20% of the data was reserved for testing, with no overlap of unique patient\nidentifiers (Supplementary Figure 1).\nBoth structured data (including age, height, weight, BMI, vital signs, complete blood\ncell count, and routine blood chemistry results) and unstructured data (text-based medical\nrecords and imaging reports) were collected. To ensure broad applicability, we included only\nthose test results that were universally available across all patients, excluding cancer-specific\ntumor markers.\nThe study was conducted in accordance with the principles of the Helsinki Declaration\nand received approval from the ethics committee of Severance Hospital (IRB number 2024-\n1487-001). Given the retrospective nature of the cohort study, informed consent was waived.\nData collection\nData were automatically extracted using the Severance Clinical Research Analysis Portal\n(SCRAP) from the Yonsei University Healthcare System. SCRAP is a system capable of\nextracting both structured and unstructured data from the EHR system. Utilizing SCRAP, we\nextracted basic patient information and clinical records from the day of the RT consultation in\nthe Department of Radiation Oncology, which included referral reasons, medical history,\nclinical summaries, and treatment plans. Additionally, we extracted unstructured text reports of\nimaging studies (positron emission tomography-computed tomography [CT], chest CT,\nabdominopelvic CT, magnetic resonance imaging, chest and abdomen radiographs) taken\nclosest to the consultation date. Vital signs, physical measurements, complete blood cell count,\nand routine blood chemistry results closest to the outpatient visit were also collected. Details\nof data collection are provided in Supplementary Methods, Supplementary Figure 2, and\nSupplementary Table 1.\nThe survival duration of patients was calculated from the date of RT initiation to the\ndate of death as confirmed by the national insurance registration system."}, {"title": "RT-Surv framework", "content": "The RT-Surv framework proposed in this study, along with its comparison to conventional\nmethods, is depicted in Figure 1. While structured data is readily applicable for predictive\nmodel development (Figure 1A), unstructured text-based data, which encompasses both\nEnglish and Korean, presents significant challenges. To address this, we employed open-source,\npre-trained LLMs within the RT-Surv framework to effectively structure the extensive EHR\ndata (Figure 1B).\nProprietary API-based LLMs, such as GPT-4, Gemini 1.5 Pro, and Claude 3.5 Sonnet,\noffer superior performance but pose significant privacy concerns due to the transmission of\npatient data to external corporate servers. .15 To address these concerns, we investigated the\nfeasibility of employing a pre-trained open-source LLM within the confines of a single\ninstitution-level resources. Specifically, we utilized Meta's LLaMA-3 model without tuning\nand compared the performance of different model sizes (8B and 70B). Additionally, to evaluate\nthe potential advantages of domain-specific models, we included a comparison with a\nmedically fine-tuned LLM (Med-LLaMA).16 Further details on the framework development\nand implementation are provided in the Supplementary Methods.\nWe provided the LLM with expert-crafted prompts utilizing a single-shot learning\napproach. The LLM then structured data from EHRs by categorizing the patient's (1) general\ncondition, (2) pathology classification of primary tumor, (3) current disease extent, (4) overall\ndisease control trend, (5) purpose of RT, (6) history of prior RT to the same site, and (7) urgency\nof RT. This process of data structurization was grounded in comprehensive radiation oncology\nrecords, including referral reasons, medical history, clinical summaries, treatment plans, and\nthe most recent imaging reports. The design of the prompts, the data utilized, and the\nclassification methods are detailed in the Supplementary Methods and Supplementary Table 2."}, {"title": "Prediction models and benchmarking", "content": "Subsequently, we developed a predictive model incorporating both structured EHR data and\nLLM-structured clinical features from unstructured data, and compared its performance against\na model based solely on structured data to assess the benefits of LLM-driven data structuring.\nWithin the RT-Surv framework, we developed and benchmarked predictive models using three\napproaches: the Cox Proportional Hazards (Cox PH) model, representing a statistical method;\nthe Random Survival Forest (RSF) model, based on machine learning; and the DeepSurv model,\nutilizing deep learning.17 This comprehensive evaluation sought to determine the extent to\nwhich the inclusion of unstructured EHR data, structured through the application of LLM,\nenhances model performance across these varied analytical approaches.\nTo prevent performance degradation and overfitting due to missing data, we first\nidentified features associated with short-term mortality. Guided by the UK's National Health\nService 30-day mortality (30-DM) rate, we initially selected features showing significant\ndifferences in relation to 30-DM occurrence. .18 We further refined the selection by assessing the\ncorrelation between each feature and 30-DM using Kendall's Tau rank correlation, including\nonly features with an absolute correlation value of 0.1 or greater in the modeling analysis.\nEvaluation of LLM accuracy in single-shot structurization\nTo assess the accuracy of LLMs in single-shot structurization, a board-certified radiation\noncologist selected 20 patient cases from the entire dataset, encompassing a range of RT\nscenarios and patient conditions. Cases with insufficient unstructured data for accurate\nstructuring were excluded."}, {"title": "Statistical analysis", "content": "The accuracy of LLM-structured clinical features was evaluated across the\naforementioned seven categories, with each category assessed on a binary scale (0 for incorrect,\n1 for correct). Two board-certified radiation oncologists, each with over five years of\nexperience and from different centers, conducted the evaluations independently. The evaluators\nwere blinded to each other's assessments to ensure unbiased and rigorous evaluation of the\nLLM-structured clinical features.\nTo assess the accuracy of LLM-generated summaries, we calculated accuracy for each of the\nseven categories. Differences in features based on 30-DM occurrence were visualized using\nbox plots for continuous variables and stacked bar plots for categorical variables. Survival\nprediction accuracy was evaluated using three primary metrics: Harrell's concordance index\n(C-index), the integrated Brier score (IBS), and the Negative Binomial Log-Likelihood\n(NBLL). Confidence intervals (CIs) for each metric were calculated using a non-parametric\nbootstrap method, with 1,000 random samples drawn with replacement. Mean values and 95th\npercentile CIs were estimated from the relative frequency distribution of each trial. Non-\noverlapping confidence intervals or a p-value < 0.05 were considered statistically significant."}, {"title": "Results", "content": "The demographics of 34,276 patients, derived from directly extracted structured EHR data, are\npresented in Supplementary Table 3. Among patients who developed 30-DM post-RT, there\nwere overall poorer characteristics, such as lower body mass index, faster pulse rate, lower\nblood cell counts, higher inflammation markers, elevated liver enzymes, and lower levels of\nplasma protein and albumin. Specifically, these patients exhibited higher levels of pulse rate\n(Kendall's tau correlation coefficient 0.095, p<0.001), absolute neutrophil count (0.112,\np<0.001), neutrophil-lymphocyte ratio (0.156, p<0.001), and alkaline phosphatase (0.129,\np<0.001). Conversely, they showed lower levels of red blood cells (RBC) (-0.101, p<0.001),\nhemoglobin (-0.105, p<0.001), hematocrit (-0.106, p<0.001), total protein (-0.102, p<0.001),\nabsolute lymphocyte count (-0.110, p<0.001), albumin (-0.169, p<0.001), sodium (-0.154,\np<0.001), and chloride (-0.117, p<0.001) (Supplementary Figure 3).\nTable 1 provides the accuracy of LLMs in structuring unstructured EHR data across\nseven LLM-structured clinical features, as evaluated by clinical experts. General-purpose, non-\nfine-tuned LLMs, such as LLaMA-3-70B, exhibited significantly higher accuracy compared to\ndomain-specific, fine-tuned models like Med-LLaMA, which struggled with more complex\nprompts (Supplementary Table 4). The average accuracy across the seven clinical features was\n87.5% (95% CI, 83.6%-91.1%) for LLaMA-3-70B, while Med-LLaMA achieved only 35.8%\n(95% CI, 30.4%-41.4%). Additionally, models with larger parameters demonstrated superior\naccuracy compared to smaller models, with LLaMA-3-70B achieving 87.5% (95% CI, 83.6%-\n91.1%) versus 70.7% (95% CI, 65.4%-76.1%) for LLaMA-3-8B. The highest accuracy was\nnoted in classifying primary pathology (100.0%, 95% CI, 100.0%-100.0%), with high\naccuracies also observed in determining disease extent (92.5%, 95% CI, 82.5%-100.0%),\ndisease control trends (94.9%, 95% CI, 87.5%-100.0%), and the aim of RT (92.6%, 95% CI,\n84.9%-100.0%). However, lower accuracy was seen in determining the urgency of RT (84.8%,\n95% CI, 72.5%-95.0%) and identifying whether the current RT session was a re-irradiation\n(82.4%, 95% CI, 70.0%-92.5%). The lowest accuracy was observed in assessing the general\ncondition of patients, with an average accuracy of 65.2% (95% CI, 50.0%-80.0%).\nThe demographics including variables structured by LLM from unstructured EHR data\nare presented in Supplementary Table 5. The LLM identified that patients who developed 30-\nDM post-RT generally had poorer general conditions, more extensive disease, poorer disease\ncontrol, higher rates of palliative RT, higher rates of re-irradiation, and more urgent RT needs.\nSpecifically, these patients were more likely to be in poorer general condition (Kendall's tau\ncorrelation coefficient 0.145, p<0.001), have more extensive disease (0.191, p<0.001),\ndemonstrate poor disease control (0.063, p<0.001), receive palliative rather than curative RT\n(0.221, p<0.001), undergo re-irradiation (0.062, p<0.001), and require more urgent treatment\n(0.175, p<0.001).\nIncorporating LLM-structured clinical features into predictive models significantly\nenhanced their performance (Table 2 and Figure 3). For the Cox PH model, the C-index\nincreased from 0.710 (95% CI, 0.699-0.719) to 0.809 (95% CI, 0.801-0.817). Additionally, the\nIBS improved from 0.196 (95% CI, 0.192-0.201) to 0.136 (95% CI, 0.130-0.142), and the\nNBLL decreased from 0.570 (95% CI, 0.558-0.582) to 0.422 (95% CI, 0.405-0.440). Similarly,\nfor the RSF model, the C-index improved from 0.710 (95% CI, 0.700-0.719) to 0.809 (95% CI,\n0.801-0.817), the IBS decreased from 0.196 (95% CI, 0.191-0.201) to 0.136 (95% CI, 0.130-\n0.142), and the NBLL decreased from 0.570 (95% CI, 0.558-0.582) to 0.422 (95% CI, 0.406-\n0.439). The DeepSurv model also showed substantial improvements, with the C-index\nincreasing from 0.737 (95% CI, 0.727-0.746) to 0.820 (95% CI, 0.813-0.827), the IBS\nimproving from 0.183 (95% CI, 0.177-0.190) to 0.131 (95% CI, 0.125-0.137), and the NBLL\ndecreasing from 0.546 (95% CI, 0.527-0.566) to 0.409 (95% CI, 0.391-0.427).\nIn the feature importance analysis of the prediction models, as shown in Figure 4,\nalbumin was identified as the most significant feature across all three models when utilizing\nonly structured EHR data, with RBC and alkaline phosphatase also demonstrating considerable\nimportance. However, upon incorporating LLM-structured clinical features, variables such as\ngeneral condition, disease extent, and the aim of RT emerged as more critical for predicting\npost-RT survival than traditional laboratory results like albumin, RBC, and alkaline\nphosphatase."}, {"title": "Discussion", "content": "This study represents a significant advancement in the application of LLMs within the medical\ndomain. Previous research has predominantly focused on evaluating how well LLMs encode\nclinical knowledge, often employing them for tasks such as question answering or\nsummarization. 19-24 While valuable for assessment purposes, these applications have limited\npractical utility in clinical settings, typically not enhancing patient outcomes or significantly\nimproving clinical practice. However, our study is the first to demonstrate that the appropriate\napplication of LLMs can potentially improve prognosis and the quality of healthcare delivery.\nIt offers a novel perspective on how LLMs can be effectively utilized, providing a guide for\nfuture applications.\nOur findings suggest the potential of LLMs to process extensive unstructured data,\nwhich would be impractical to manually structure, thereby advancing the development of more\nsophisticated predictive models. Notably, LLMs demonstrated high accuracy in structuring\nunstructured data even without extensive tuning, using a single-shot example approach. This\ncapability was evident in the clinically predictable trends observed in the structured data. For\ninstance, higher 30-DM rates were noted among palliative patients, those in poorer general\ncondition, and patients with extensive disease. These trends align with clinical expectations,\nreinforcing the potential of LLMs to transform unstructured EHR data into a structured format\nthat is both reliable and actionable for clinical decision-making.\nDespite these promising results, the study also highlighted areas where LLMs showed\nlimitations. While LLMs performed well in distinguishing clear-cut clinical variables such as\nprimary pathology, they struggled with more complex tasks requiring comprehensive\ncontextual understanding, such as integrating longitudinal data and anatomical correlations.\nFor example, identifying previous RT fields, which necessitates an understanding of anatomical\ndetails combined with historical treatment records, posed significant challenges. Additionally,\nthe accuracy in assessing general condition was the lowest, reflecting the difficulty of inferring\na patient's condition accurately from imaging results or clinical records without direct clinical\ninterview with patient. These limitations highlight the difficulties LLMs face in handling tasks\nthat require extensive anatomical knowledge, complex contextual understanding, or are\nambiguous due to insufficient information. Nonetheless, the reasonable trends captured by\nLLMs were observed, and it contributed to substantially enhanced performance of predictive\nmodels.\nIn addition to improving predictive model performance, the inclusion of LLM-\nstructured clinical features enhanced the interpretability of these models. Factors such as\ngeneral condition, disease extent, and aim of RT, when structured by the LLM, emerged as\nsignificantly correlated with patient outcomes, aligning with clinical expectations and known\nrelevance to patient survival. This improvement in interpretability suggests that structured data\nderived from unstructured text not only enhances predictive accuracy but also provides more\nclinically meaningful insights by quantifying the relative importance of clinically significant\nfactors not originally structured in the EHR data.25,26\nOur findings challenge the prevailing assumption that domain-specific models,\nincluding medically fine-tuned LLMs, are inherently superior for processing specialized\ndomain data.27-29 Contrary to this belief, we observed that general-domain LLMs, even without\nfine-tuning for the medical domain, performed exceptionally well. This stands in contrast to\nthe approach taken in many studies that emphasize tuning LLMs for specific fields, like\nmedicine, which, while potentially enhancing domain-specific knowledge, often diminishes\nlanguage adaptability. For instance, Med-LLaMA, a medically fine-tuned model, struggled to\neffectively process complex prompts, as shown in Supplementary Table 4. These results\nsuggest that utilizing open-source LLMs optimized for general language comprehension and\nprompt adherence, possibly employing single-shot learning, may be more effective and\nclinically valuable than the conventional approach of extensive domain-specific tuning.\nThe framework developed in this study, RT-Surv, demonstrates broader applications\nbeyond the field of radiation oncology. Unstructured clinical records are the fundamental form\nof EHR data across all medical specialties, not limited to radiation oncology.30 Therefore, this\nframework can be adapted for various medical fields to reduce overall hospital mortality rates\nand in scenarios requiring the integration and analysis of large-scale clinical data. The ability\nto automatically structure vast amounts of unstructured data facilitates more accurate and\nefficient predictive modeling across healthcare settings.\nSeveral limitations must be acknowledged. Firstly, the accuracy of data structured by\nLLMs was approximately 90%. Although the overall trends were interpretable and reliable,\nthey might not have achieved optimal performance compared to manually entered data.\nSecondly, the study encountered significant amounts of missing data. While tree-based models\nlike the RSF managed this effectively, models such as Cox PH and DeepSurv had to impute\nmissing values with mean values, which may introduce biases and affect model robustness.\nLastly, external validation was not performed. Although the addition of LLM-structured\nclinical features significantly improved predictive model performance within our institution's\ndataset, validation with external datasets is necessary to ensure the generalizability of these\nresults.\nIn conclusion, this study demonstrates the effective integration of LLMs into\npredictive modeling, highlighting their potential to handle unstructured data and improve\nclinical outcomes. Our research shows that LLMs can accurately structure unstructured clinical\ndata, leading to significantly enhanced performance in predictive models. These findings offer\nvaluable insights for future applications of LLMs in healthcare, extending beyond radiation\noncology to benefit the broader medical field. This study highlights the utility of LLMs and\ntheir capacity to potentially enhance healthcare quality in clinical practice."}]}