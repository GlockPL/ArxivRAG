{"title": "RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records", "authors": ["Sangjoon Park", "Chan Woo Wee", "Seo Hee Choi", "Kyung Hwan Kim", "Jee Suk Chang", "Hong In Yoon", "Ik Jae Lee", "Yong Bae Kim", "Jaeho Cho", "Ki Chang Keum", "Chang Geol Lee", "Hwa Kyung Byun", "Woong Sub Koom"], "abstract": "Background: Accurate patient selection is essential in radiotherapy (RT) to prevent ineffective treatments. Traditional survival prediction models, which rely on structured data, often lack precision. Large language models (LLMs) offer a novel approach to structuring unstructured electronic health record (EHR) data, potentially improving survival predictions by integrating comprehensive clinical information.\nMethods: This study analyzed data from 34,276 patients treated with RT at Yonsei Cancer Center from 2013 to 2023. The dataset included structured and unstructured data. An open-source LLM was used to structure the unstructured EHR data using single-shot learning. The LLM's performance was compared with a domain-specific medical LLM and a smaller variant. Survival prediction models were developed using statistical, machine learning, and deep learning approaches, incorporating both structured and LLM-structured data. Clinical experts evaluated the LLM-structured data's accuracy.\nFindings: The open-source LLM achieved an average accuracy of 87.5% in structuring unstructured EHR data, without requiring additional training. The domain-specific medical LLM performed significantly worse, with only 35.8% accuracy. Larger LLMs proved more effective, particularly in extracting clinically relevant features like general condition and disease extent, which correlated with patient survival. Incorporating LLM-structured clinical features into survival prediction models substantially improved their accuracy, with the C-index increasing from 0.737 (95% confidence interval [CI] 0.727-0.746) to 0.820 (95% CI 0.813-0.827) in deep learning model. The models also became more interpretable by emphasizing clinically meaningful factors.\nInterpretation: This study shows that general-domain LLMs, despite not being specifically trained on medical data, can effectively structure large-scale unstructured EHR data, significantly improving the accuracy and interpretability of clinical predictive models.", "sections": [{"title": "Introduction", "content": "Radiotherapy (RT) is an essential component in cancer treatment, with approximately 60% of cancer patients undergoing RT during their treatment course, according to the 2023 Radiation Oncology Case Rate Report.\u00b9 Projections from the SEER database indicate that the number of RT patients will rise to 3.38 million by 2020 and 4.17 million by 2030.2 The benefits of RT, such as symptom relief and improved survival, are well documented but are influenced by factors including tumor type, treatment site, and patient health status. However, some patients may not live long enough to benefit from RT, making accurate patient selection crucial to avoid unnecessary treatments, burdens, and healthcare costs.3,4\nSeveral studies have aimed to predict survival outcomes for RT patients by focusing on short-term mortality factors or developing prognostic nomograms. 5-7 However, these methods often fall short in accurately predicting survival durations, thus limiting their practical utility in clinical decision-making. The advent of machine learning has enabled the exploration of survival prediction in RT patients using electronic health record (EHR) data, primarily structured data like patient demographics, vital signs, and laboratory results. This approach, however, neglects critical information found in unstructured clinical notes, such as disease extent, treatment purpose, and patient condition. Manually structuring this unstructured data is impractical on a large scale.\nLarge language models (LLMs), such as OpenAI's ChatGPT, have demonstrated significant capabilities in processing unstructured text. These models can perform new tasks with few-shot learning, enabling data structuring without explicit training, heralding a new era of generative artificial intelligence models.9-11 Their flexibility and adaptability, especially when well-structured prompts are used, make them ideal for structuring clinical records. Consequently, there is growing interest in using LLMs for data standardization in the medical"}, {"title": null, "content": "domain. 12-14\nThis study aims to develop a model to predict post-RT mortality by leveraging comprehensive structured and unstructured data from patient records at a large-volume center. Using an open-source LLM that can be deployed with internal hospital resources, we ensure data privacy without risking patient information leakage. By structuring unstructured clinical data, we aim to enhance survival prediction accuracy and provide guidelines on how LLMs can be effectively utilized in clinical practice through data standardization, ultimately advancing patient outcomes."}, {"title": "Materials and Methods", "content": "Study design and participants\nWe utilized data from a single large-volume center to create a model that could aid clinical decision-making by providing estimated survival predictions at the time of consultation for RT, thereby informing treatment decisions of practicing physicians.\nData were collected from patients who underwent RT at Yonsei Cancer Center between August 2013 and July 2023. Patients were excluded if they had (1) incomplete radiation oncology records that hindered the LLM's ability to structure data or (2) an inability to confirm post-RT survival through the national insurance system. Of the 51,821 patients treated, 34,276 were included in the LLM structurization analysis and 25,183 in the survival prediction analysis. A random 20% of the data was reserved for testing, with no overlap of unique patient identifiers (Supplementary Figure 1).\nBoth structured data (including age, height, weight, BMI, vital signs, complete blood cell count, and routine blood chemistry results) and unstructured data (text-based medical"}, {"title": null, "content": "records and imaging reports) were collected. To ensure broad applicability, we included only those test results that were universally available across all patients, excluding cancer-specific tumor markers.\nThe study was conducted in accordance with the principles of the Helsinki Declaration and received approval from the ethics committee of Severance Hospital (IRB number 2024-1487-001). Given the retrospective nature of the cohort study, informed consent was waived."}, {"title": "Data collection", "content": "Data were automatically extracted using the Severance Clinical Research Analysis Portal (SCRAP) from the Yonsei University Healthcare System. SCRAP is a system capable of extracting both structured and unstructured data from the EHR system. Utilizing SCRAP, we extracted basic patient information and clinical records from the day of the RT consultation in the Department of Radiation Oncology, which included referral reasons, medical history, clinical summaries, and treatment plans. Additionally, we extracted unstructured text reports of imaging studies (positron emission tomography-computed tomography [CT], chest CT, abdominopelvic CT, magnetic resonance imaging, chest and abdomen radiographs) taken closest to the consultation date. Vital signs, physical measurements, complete blood cell count, and routine blood chemistry results closest to the outpatient visit were also collected. Details of data collection are provided in Supplementary Methods, Supplementary Figure 2, and Supplementary Table 1.\nThe survival duration of patients was calculated from the date of RT initiation to the date of death as confirmed by the national insurance registration system."}, {"title": "RT-Surv framework", "content": "The RT-Surv framework proposed in this study, along with its comparison to conventional methods, is depicted in Figure 1. While structured data is readily applicable for predictive model development (Figure 1A), unstructured text-based data, which encompasses both English and Korean, presents significant challenges. To address this, we employed open-source, pre-trained LLMs within the RT-Surv framework to effectively structure the extensive EHR data (Figure 1B).\nProprietary API-based LLMs, such as GPT-4, Gemini 1.5 Pro, and Claude 3.5 Sonnet, offer superior performance but pose significant privacy concerns due to the transmission of patient data to external corporate servers. .15 To address these concerns, we investigated the feasibility of employing a pre-trained open-source LLM within the confines of a single institution-level resources. Specifically, we utilized Meta's LLaMA-3 model without tuning and compared the performance of different model sizes (8B and 70B). Additionally, to evaluate the potential advantages of domain-specific models, we included a comparison with a medically fine-tuned LLM (Med-LLaMA).16 Further details on the framework development and implementation are provided in the Supplementary Methods.\nWe provided the LLM with expert-crafted prompts utilizing a single-shot learning approach. The LLM then structured data from EHRs by categorizing the patient's (1) general condition, (2) pathology classification of primary tumor, (3) current disease extent, (4) overall disease control trend, (5) purpose of RT, (6) history of prior RT to the same site, and (7) urgency of RT. This process of data structurization was grounded in comprehensive radiation oncology records, including referral reasons, medical history, clinical summaries, treatment plans, and the most recent imaging reports. The design of the prompts, the data utilized, and the classification methods are detailed in the Supplementary Methods and Supplementary Table 2."}, {"title": null, "content": "Subsequently, we developed a predictive model incorporating both structured EHR data and LLM-structured clinical features from unstructured data, and compared its performance against a model based solely on structured data to assess the benefits of LLM-driven data structuring."}, {"title": "Prediction models and benchmarking", "content": "Within the RT-Surv framework, we developed and benchmarked predictive models using three approaches: the Cox Proportional Hazards (Cox PH) model, representing a statistical method; the Random Survival Forest (RSF) model, based on machine learning; and the DeepSurv model, utilizing deep learning.17 This comprehensive evaluation sought to determine the extent to which the inclusion of unstructured EHR data, structured through the application of LLM, enhances model performance across these varied analytical approaches.\nTo prevent performance degradation and overfitting due to missing data, we first identified features associated with short-term mortality. Guided by the UK's National Health Service 30-day mortality (30-DM) rate, we initially selected features showing significant differences in relation to 30-DM occurrence. .18 We further refined the selection by assessing the correlation between each feature and 30-DM using Kendall's Tau rank correlation, including only features with an absolute correlation value of 0.1 or greater in the modeling analysis."}, {"title": "Evaluation of LLM accuracy in single-shot structurization", "content": "To assess the accuracy of LLMs in single-shot structurization, a board-certified radiation oncologist selected 20 patient cases from the entire dataset, encompassing a range of RT scenarios and patient conditions. Cases with insufficient unstructured data for accurate structuring were excluded."}, {"title": null, "content": "The accuracy of LLM-structured clinical features was evaluated across the aforementioned seven categories, with each category assessed on a binary scale (0 for incorrect, 1 for correct). Two board-certified radiation oncologists, each with over five years of experience and from different centers, conducted the evaluations independently. The evaluators were blinded to each other's assessments to ensure unbiased and rigorous evaluation of the LLM-structured clinical features."}, {"title": "Statistical analysis", "content": "To assess the accuracy of LLM-generated summaries, we calculated accuracy for each of the seven categories. Differences in features based on 30-DM occurrence were visualized using box plots for continuous variables and stacked bar plots for categorical variables. Survival prediction accuracy was evaluated using three primary metrics: Harrell's concordance index (C-index), the integrated Brier score (IBS), and the Negative Binomial Log-Likelihood (NBLL). Confidence intervals (CIs) for each metric were calculated using a non-parametric bootstrap method, with 1,000 random samples drawn with replacement. Mean values and 95th percentile CIs were estimated from the relative frequency distribution of each trial. Non-overlapping confidence intervals or a p-value < 0.05 were considered statistically significant."}, {"title": "Results", "content": "The demographics of 34,276 patients, derived from directly extracted structured EHR data, are presented in Supplementary Table 3. Among patients who developed 30-DM post-RT, there were overall poorer characteristics, such as lower body mass index, faster pulse rate, lower blood cell counts, higher inflammation markers, elevated liver enzymes, and lower levels of plasma protein and albumin. Specifically, these patients exhibited higher levels of pulse rate"}, {"title": null, "content": "(Kendall's tau correlation coefficient 0.095, p<0.001), absolute neutrophil count (0.112, p<0.001), neutrophil-lymphocyte ratio (0.156, p<0.001), and alkaline phosphatase (0.129, p<0.001). Conversely, they showed lower levels of red blood cells (RBC) (-0.101, p<0.001), hemoglobin (-0.105, p<0.001), hematocrit (-0.106, p<0.001), total protein (-0.102, p<0.001), absolute lymphocyte count (-0.110, p<0.001), albumin (-0.169, p<0.001), sodium (-0.154, p<0.001), and chloride (-0.117, p<0.001) (Supplementary Figure 3).\nTable 1 provides the accuracy of LLMs in structuring unstructured EHR data across seven LLM-structured clinical features, as evaluated by clinical experts. General-purpose, non-fine-tuned LLMs, such as LLaMA-3-70B, exhibited significantly higher accuracy compared to domain-specific, fine-tuned models like Med-LLaMA, which struggled with more complex prompts (Supplementary Table 4). The average accuracy across the seven clinical features was 87.5% (95% CI, 83.6%-91.1%) for LLaMA-3-70B, while Med-LLaMA achieved only 35.8% (95% CI, 30.4%-41.4%). Additionally, models with larger parameters demonstrated superior accuracy compared to smaller models, with LLaMA-3-70B achieving 87.5% (95% CI, 83.6%-\n91.1%) versus 70.7% (95% CI, 65.4%-76.1%) for LLaMA-3-8B. The highest accuracy was noted in classifying primary pathology (100.0%, 95% CI, 100.0%-100.0%), with high accuracies also observed in determining disease extent (92.5%, 95% CI, 82.5%-100.0%), disease control trends (94.9%, 95% CI, 87.5%-100.0%), and the aim of RT (92.6%, 95% CI,\n84.9%-100.0%). However, lower accuracy was seen in determining the urgency of RT (84.8%, 95% CI, 72.5%-95.0%) and identifying whether the current RT session was a re-irradiation (82.4%, 95% CI, 70.0%-92.5%). The lowest accuracy was observed in assessing the general condition of patients, with an average accuracy of 65.2% (95% CI, 50.0%-80.0%).\nThe demographics including variables structured by LLM from unstructured EHR data are presented in Supplementary Table 5. The LLM identified that patients who developed 30-DM post-RT generally had poorer general conditions, more extensive disease, poorer disease"}, {"title": null, "content": "control, higher rates of palliative RT, higher rates of re-irradiation, and more urgent RT needs. Specifically, these patients were more likely to be in poorer general condition (Kendall's tau correlation coefficient 0.145, p<0.001), have more extensive disease (0.191, p<0.001), demonstrate poor disease control (0.063, p<0.001), receive palliative rather than curative RT (0.221, p<0.001), undergo re-irradiation (0.062, p<0.001), and require more urgent treatment (0.175, p<0.001).\nIncorporating LLM-structured clinical features into predictive models significantly enhanced their performance (Table 2 and Figure 3). For the Cox PH model, the C-index increased from 0.710 (95% CI, 0.699-0.719) to 0.809 (95% CI, 0.801-0.817). Additionally, the IBS improved from 0.196 (95% CI, 0.192-0.201) to 0.136 (95% CI, 0.130-0.142), and the NBLL decreased from 0.570 (95% CI, 0.558-0.582) to 0.422 (95% CI, 0.405-0.440). Similarly, for the RSF model, the C-index improved from 0.710 (95% CI, 0.700-0.719) to 0.809 (95% CI,\n0.801-0.817), the IBS decreased from 0.196 (95% CI, 0.191-0.201) to 0.136 (95% CI, 0.130-0.142), and the NBLL decreased from 0.570 (95% CI, 0.558-0.582) to 0.422 (95% CI, 0.406-0.439). The DeepSurv model also showed substantial improvements, with the C-index increasing from 0.737 (95% CI, 0.727-0.746) to 0.820 (95% CI, 0.813-0.827), the IBS improving from 0.183 (95% CI, 0.177-0.190) to 0.131 (95% CI, 0.125-0.137), and the NBLL decreasing from 0.546 (95% CI, 0.527-0.566) to 0.409 (95% CI, 0.391-0.427).\nIn the feature importance analysis of the prediction models, as shown in Figure 4, albumin was identified as the most significant feature across all three models when utilizing only structured EHR data, with RBC and alkaline phosphatase also demonstrating considerable importance. However, upon incorporating LLM-structured clinical features, variables such as general condition, disease extent, and the aim of RT emerged as more critical for predicting post-RT survival than traditional laboratory results like albumin, RBC, and alkaline phosphatase."}, {"title": "Discussion", "content": "This study represents a significant advancement in the application of LLMs within the medical domain. Previous research has predominantly focused on evaluating how well LLMs encode clinical knowledge, often employing them for tasks such as question answering or summarization. 19-24 While valuable for assessment purposes, these applications have limited practical utility in clinical settings, typically not enhancing patient outcomes or significantly improving clinical practice. However, our study is the first to demonstrate that the appropriate application of LLMs can potentially improve prognosis and the quality of healthcare delivery. It offers a novel perspective on how LLMs can be effectively utilized, providing a guide for future applications.\nOur findings suggest the potential of LLMs to process extensive unstructured data, which would be impractical to manually structure, thereby advancing the development of more sophisticated predictive models. Notably, LLMs demonstrated high accuracy in structuring unstructured data even without extensive tuning, using a single-shot example approach. This capability was evident in the clinically predictable trends observed in the structured data. For instance, higher 30-DM rates were noted among palliative patients, those in poorer general condition, and patients with extensive disease. These trends align with clinical expectations, reinforcing the potential of LLMs to transform unstructured EHR data into a structured format that is both reliable and actionable for clinical decision-making.\nDespite these promising results, the study also highlighted areas where LLMs showed limitations. While LLMs performed well in distinguishing clear-cut clinical variables such as primary pathology, they struggled with more complex tasks requiring comprehensive contextual understanding, such as integrating longitudinal data and anatomical correlations."}, {"title": null, "content": "For example, identifying previous RT fields, which necessitates an understanding of anatomical details combined with historical treatment records, posed significant challenges. Additionally, the accuracy in assessing general condition was the lowest, reflecting the difficulty of inferring a patient's condition accurately from imaging results or clinical records without direct clinical interview with patient. These limitations highlight the difficulties LLMs face in handling tasks that require extensive anatomical knowledge, complex contextual understanding, or are ambiguous due to insufficient information. Nonetheless, the reasonable trends captured by LLMs were observed, and it contributed to substantially enhanced performance of predictive models.\nIn addition to improving predictive model performance, the inclusion of LLM-structured clinical features enhanced the interpretability of these models. Factors such as general condition, disease extent, and aim of RT, when structured by the LLM, emerged as significantly correlated with patient outcomes, aligning with clinical expectations and known relevance to patient survival. This improvement in interpretability suggests that structured data derived from unstructured text not only enhances predictive accuracy but also provides more clinically meaningful insights by quantifying the relative importance of clinically significant factors not originally structured in the EHR data.25,26\nOur findings challenge the prevailing assumption that domain-specific models, including medically fine-tuned LLMs, are inherently superior for processing specialized domain data.27-29 Contrary to this belief, we observed that general-domain LLMs, even without fine-tuning for the medical domain, performed exceptionally well. This stands in contrast to the approach taken in many studies that emphasize tuning LLMs for specific fields, like medicine, which, while potentially enhancing domain-specific knowledge, often diminishes language adaptability. For instance, Med-LLaMA, a medically fine-tuned model, struggled to effectively process complex prompts, as shown in Supplementary Table 4. These results"}, {"title": null, "content": "suggest that utilizing open-source LLMs optimized for general language comprehension and prompt adherence, possibly employing single-shot learning, may be more effective and clinically valuable than the conventional approach of extensive domain-specific tuning.\nThe framework developed in this study, RT-Surv, demonstrates broader applications beyond the field of radiation oncology. Unstructured clinical records are the fundamental form of EHR data across all medical specialties, not limited to radiation oncology.30 Therefore, this framework can be adapted for various medical fields to reduce overall hospital mortality rates and in scenarios requiring the integration and analysis of large-scale clinical data. The ability to automatically structure vast amounts of unstructured data facilitates more accurate and efficient predictive modeling across healthcare settings.\nSeveral limitations must be acknowledged. Firstly, the accuracy of data structured by LLMs was approximately 90%. Although the overall trends were interpretable and reliable, they might not have achieved optimal performance compared to manually entered data. Secondly, the study encountered significant amounts of missing data. While tree-based models like the RSF managed this effectively, models such as Cox PH and DeepSurv had to impute missing values with mean values, which may introduce biases and affect model robustness. Lastly, external validation was not performed. Although the addition of LLM-structured clinical features significantly improved predictive model performance within our institution's dataset, validation with external datasets is necessary to ensure the generalizability of these results.\nIn conclusion, this study demonstrates the effective integration of LLMs into predictive modeling, highlighting their potential to handle unstructured data and improve clinical outcomes. Our research shows that LLMs can accurately structure unstructured clinical data, leading to significantly enhanced performance in predictive models. These findings offer"}, {"title": null, "content": "valuable insights for future applications of LLMs in healthcare, extending beyond radiation oncology to benefit the broader medical field. This study highlights the utility of LLMs and their capacity to potentially enhance healthcare quality in clinical practice."}, {"title": "Contributions", "content": "SJP contributed to concept development, data collection, analysis, and both drafting and revising the manuscript. HKB was involved in refining the research concept, data collection, analysis, and manuscript drafting and revision. WSK formulated the research concept, proposed the research question, and revised the manuscript. SJP, HKB, and WSK approved the final version of the manuscript. All authors contributed to data collection, manuscript revision, and approval of the final manuscript, with full access to all data."}, {"title": "Declaration of interests", "content": "We declare that there are no conflicts of interest."}, {"title": "Data sharing", "content": "Data used in this study can be shared upon request to the corresponding authors."}]}