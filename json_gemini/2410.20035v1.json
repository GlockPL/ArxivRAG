{"title": "TRAINING THE UNTRAINABLE: INTRODUCING INDUCTIVE BIAS VIA REPRESENTATIONAL ALIGNMENT", "authors": ["Vighnesh Subramaniam", "David Mayo", "Colin Conwell", "Tomaso Poggio", "Boris Katz", "Brian Cheung", "Andrei Barbu"], "abstract": "We demonstrate that architectures which traditionally are considered to be ill-suited for a task can be trained using inductive biases from another architecture. Networks are considered untrainable when they overfit, underfit, or converge to poor results even when tuning their hyperparameters. For example, plain fully connected networks overfit on object recognition while deep convolutional networks without residual connections underfit. The traditional answer is to change the architecture to impose some inductive bias, although what that bias is remains unknown. We introduce guidance, where a guide network guides a target network using a neural distance function. The target is optimized to perform well and to match its internal representations, layer-by-layer, to those of the guide; the guide is unchanged. If the guide is trained, this transfers over part of the architectural prior and knowledge of the guide to the target. If the guide is untrained, this transfers over only part of the architectural prior of the guide. In this manner, we can investigate what kinds of priors different architectures place on untrainable networks such as fully connected networks. We demonstrate that this method overcomes the immediate overfitting of fully connected networks on vision tasks, makes plain CNNs competitive to ResNets, closes much of the gap between plain vanilla RNNs and Transformers, and can even help Transformers learn tasks which RNNs can perform more easily. We also discover evidence that better initializations of fully connected networks likely exist to avoid overfitting. Our method provides a mathematical tool to investigate priors and architectures, and in the long term, may demystify the dark art of architecture creation, even perhaps turning architectures into a continuous optimizable parameter of the network.", "sections": [{"title": "INTRODUCTION", "content": "When creating neural networks, we tend as a community to follow recipes that select among a few architectures known to work for particular tasks (Ren et al., 2021; Cong & Zhou, 2023; Goodfellow et al., 2014). Architecture is critical. The gains made on tasks like object recognition are attributable to imposing an inductive bias, i.e., a prior, on the design of new architectures (Goyal & Bengio, 2022; Bachmann et al., 2024). Convolutional networks unlocked many vision problems (Krizhevsky et al., 2012; He et al., 2016a) and the recent advent of the Transformer (Vaswani, 2017; Devlin, 2018; Achiam et al., 2023) did the same for language. Despite this, finding new architectures and over-coming the limitations of existing architectures remains a sort of \"dark art\". While an architecture imposes some prior, we often do not fully understand what that prior is. One example of this that remains an open discussion is the role of residual connections in making very deep convolutional networks easier to train (Jastrzebski et al., 2017). If we fully understood the priors that architectures imposed, we could translate between priors and architectures freely \u2013 either by specifying the prior we want and then deriving the appropriate architecture or by dispensing with architectures and imposing the prior directly.\nRecent theorems (Poggio & Fraser, 2024) state that for each function which is efficiently Turing computable, there exists a deep network that can approximate it well. Furthermore, a graph rep-resenting such a function is compositionally sparse; that is, the nodes of the associated Directed Acyclic graph (DAG) represent constituent functions with a small effective dimensionality. A rea-sonable conjecture is that neural networks with an architecture which is similar to the DAG of the unknown target function are especially successful in learning it, as it is the case for convolutional networks for image recognition and similar tasks. Because we do not understand the relationship between the kinds of priors on the target functions that different architectures impose, even simple questions have no known answer, such as, does there exist an initialization of an FCN that makes it behave like a CNN, though the graphs of the function they represent are fundamentally different?\nWe introduce a new tool which we term guidance to study this problem and to expand the space of viable networks. Given a target network, we guide it with a guide network. In addition to the target's original loss, the target attempts to match the representation of its intermediate layers to those of the guide. We use a measure of representational similarity (Kornblith et al., 2019; Cristianini et al., 2001; Cortes et al., 2012), also termed a neural distance function, to compute the distance between representations of two arbitrary layers. Neural distance functions are often used in neuroscience to compare activity in networks and brains (Schrimpf et al., 2018; Conwell et al., 2021a; Subramaniam et al., 2024). In light of recent work that shows that networks of very different architectures have internal activity that is extremely similar to one another (Han et al., 2023; Conwell et al., 2021a;b), we repurpose this distance function as a means to transfer priors between networks layer by layer.\nWe make the following contributions:\n1. We develop guidance to transfer priors between networks using representational alignment, investigate one representational alignment method, centered kernel alignment, CKA (Kornblith et al., 2019), and apply it to several classical problems."}, {"title": "RELATED WORK", "content": "Representational Distance: Our method builds on several metrics that measure distance between high-dimensional activations extracted from neural networks or activity in the brain (Klabunde et al., 2023). Some of these distance metrics make comparisons based on kernel matrices (Kornblith et al., 2019; Cristianini et al., 2001; Cortes et al., 2012) or relative distances (Kriegeskorte et al., 2008) between sample representations in a set. Others compute linear (Wehbe et al., 2014; Schrimpf et al., 2018) or orthogonal projections (Beauducel, 2018) from one set of representations to another. Others use canonical correlation analysis which finds linear relationships between pairs of vectors (Raghu et al., 2017; Morcos et al., 2018). These metrics are designed based on a set of desired invariant properties such as permutation invariance or invariance to linear transformations.\nSuch approaches have been commonly applied in neuroscience for measuring representational dis-tance of activations from networks and activity in the brain to understand which neural networks are architecturally most similar to the brain (Wehbe et al., 2014; Conwell et al., 2021a; Subramaniam et al., 2024; Goldstein et al., 2020). Under this context, Han et al. (2023) has shown the inability of current representational distance metrics to distinguish representations based on architecture. This provides a basis for our experiments to use these metrics to align representations across different neural networks. This paper gives the foundation for our intuition that networks may have similar representations that allow for transferring inductive biases from one network to another. Moreover, like Han et al. (2023), we use centered kernel alignment as our main metric of representational align-ment. Recent work has explored the relationship between representational and functional distance of networks, discovering transformations between activations of networks and when these make networks functionally equivalent (Klabunde et al., 2023; Bertalan et al., 2024).\nUntrainable Networks: In this work, we focus on applications of FCNs and plain CNNs for image classification and RNNs for sequence modeling. Prior work has designed such approaches for these tasks, although unsuccessfully relative to the guide networks we use to improve training."}, {"title": "METHODS", "content": "Guidance introduces a term in the loss of a target network, $N_T$, to encourage representational align-ment with a guide network, $N_G$. Only the parameters, $\\theta_T$, of the target are updated - the guide's parameters, $\\theta_G$, remain fixed. Per minibatch, representational similarity is computed between the activations of $i^{th}$ layer of the guide, $A_i(\\theta_G)$, and activations from a corresponding layer it of the target, $A_i(\\theta_T)$. We refer to the correspondence between layers of the guide ${i_G}$ and layers of the target ${i_T}$ as I. While this correspondence, I, could be complex as any two architectures can form a guide/target pair, here we choose architectures that make the correspondence obvious as is discussed later. For example, the stacked RNNs and Transformers have the same number of layers in our experiments."}, {"title": "LAYERWISE MAPPING", "content": "We design a simple method for mapping guide layers to target layers as part of providing supervision. The goal of this method is to make guide and target networks architecturally agnostic, i.e. we can supervise any target network with any guide network.\nAs a simple approach, we evenly spread layer computations of our guide network over our target network. For example, if we consider ResNet-18 and a 50-layer FCN, we would map every convolu-tional ResNet layer to every second or third linear layer of the FCN. The intuition for this approach follows from the aim of discovering the same function of the guide network using a target network. Through the design of evenly spreading layers of our ResNet-18, we are guiding the FCN to find a function similar to the guide network.\nFor our mapping, we consider activations from all layers with tunable weights i.e. convolutional, linear, or LSTM/RNN based layers as well as activations from layer normalizations. For multiple stacked RNNS, LSTMs, or transformers, we extract feature representations from intermediate layers in the stack as well. Using all layers is useful for guidance as it provides a strong signal to induce alignment between the target and guide networks during training. We empirically find that more lay-ers leads to stronger results. Skipping layers based on non-linear transformations reduces memory overhead associated with storing representations per batch."}, {"title": "EXPERIMENTS", "content": "We design several settings with different target and guide networks to thoroughly test our approach. We include a range of image and sequence modeling tasks. In choosing target networks, we con-sider a broad range of designs for networks that are not traditionally applied (e.g., a FCN in image classification).\nTo systematically evaluate our approach, we categorize our experiments into the following groups of untrainability that our proposed method improves upon:\n1. Untrainable Architectures: Experiments where the target networks are difficult to train due to architectural limitations, irrespective of the task.\n2. Untrainable Tasks: Experiments where certain tasks are inherently challenging for spe-cific architectures, making them untrainable without additional supervision."}, {"title": "TASKS", "content": "Here, we describe the task settings. For an image-based task, we focus on image classification and use the ImageNet-1K dataset (Deng et al., 2009) for training and testing. We use the splits defined by the dataset. We report accuracy on the validation set for all experiments.\nWe next consider three sequence modeling tasks that allow for a broader range of architectural settings. We first consider a task called copy-paste (Graves, 2014). In this task, we generate a sequence of numbers in the range of 1 10. The model is trained to recover the same sequence in the output. In our setting, we consider sequence lengths that range from 20 to 40 values total (internal sequence and padding). We generate a copy-paste dataset, sampling sequences containing numbers between 1 and 10. We generate a total of 100, 000 examples, training on 80, 000 examples, validating on 10,000 examples, and testing on 10, 000 examples.\nWe also include the parity task, a binary classification task where a model is fed a bitstring and outputs 1 when there is an even number of ones in the bitstring and 0 otherwise. We generate a series of bitstrings with sequence lengths that range from 2 to 50 (as in prior work) (Bhattamishra et al., 2020).\nFinally, we consider a language modeling task using the WikiText-103 dataset (Merity et al., 2016) where models must predict the next token given some context. This uses the train, validation and testing splits defined by the WikiText dataset and for all experiments, we use a context length of 50. We tokenize the text data using the GPT-2 (Radford et al., 2019) tokenizer."}, {"title": "ARCHITECTURES", "content": "For all tasks, we describe our target untrainable architectures for each task separately as well as the guide networks that are employed to make the untrainable network trainable.\nImage Classification: We use three target networks: Deep FCN, Wide FCN, and Deep ConvNet. Deep FCN is a fully-connected network with 50 blocks consisting of feedforward layers followed by non-linearities. This network is an untrainable architecture, lacking inductive biases to prevent overfitting and having vanishing gradients. Wide FCN is a fully connected network with 3 blocks with feedforward layers that have 8192 units. This is categorized as an untrainable task due to a saturation in the training performance. Deep ConvNet is the same architecture as ResNet-50 (He et al., 2016a), but without residual connections. This is categorized as an untrainable architecture due to the vanishing gradient problem.\nSequence Modeling: For our copy-paste task, we use a vanilla, 4-layer RNN and language mod-eling tasks, we use a vanilla 5-layer RNN as our target networks. In copy-paste, architectural and algorithmic limitations make RNNs an untrainable architecture. For language modeling, vanishing gradients and limited context incorporation make RNNs an untrainable architecture as the training loss saturates. For the parity task, we use a 1-layer transformer encoder architecture, similar to prior work (Bhattamishra et al., 2020; Hahn & Rofin, 2024).\n4.3 TRAINING\nFor each setting, we train the base target network and perform an experiment where both a trained and untrained guide network supervises the base target network. All networks are trained with either cross-entropy loss or binary cross-entropy loss, although other loss functions could be applied as well.\nWhen training networks for object detection using ImageNet-1K, we use the Adam (Kingma, 2014) optimizer. For all sequence modeling tasks, i.e. copy-paste, parity, and the language modeling task we use AdamW (Loshchilov, 2017). For language modeling, we also incorporate gradient clipping due to unstable training with long sequences.\nTo ensure consistency of comparisons across learning curves, we use a consistent batch size of 256. In general, representational similarity metrics are affected by the number of samples in the calculation. The more samples, the better the metric approximates representational distance. We use 256 as a proxy, dependent on GPU memory, although more memory would allow for bigger batch sizes with potentially better results. Due to the large number of training settings, we employ several different learning rates. We tune the learning rate carefully for baseline training to ensure"}, {"title": "RESULTS", "content": "Here, we report the findings from our use of guidance to train our set of untrainable networks. Re-sults are shown in the following order: image classification task; sequence modeling tasks; language modeling tasks."}, {"title": "IMAGE CLASSIFICATION", "content": "Across all our networks, we observe significant improvement from using a guide network to provide guidance; see table 2. We see significant accuracy gains of 5-10% on validation performance. We also observe significantly better loss curves from a better fit with the training loss and reduced overfitting with the validation loss. Most interestingly, we highlight that using a randomly initialized guide network can perform better than using a trained guide network. For example, the Deep FCN results in the top left of fig. 2 are significantly better with a randomly initialized ResNet-18 as the guide network instead of a trained ResNet-18. This trend also occurs with Wide FCN.\nWe note that this trend is not entirely consistent as indicated by the Deep ConvNet. One potential explanation is that the architectural prior is the same for both the Deep ConvNet and ResNet-50. This explanation provides an additional interpretation for the role of residual connections and their influence on the representation space. This indicates that residual connections must be trained to have an influence on the representation space, and aligns with prior studies of residual connections (Jastrzebski et al., 2017; He et al., 2016b)."}, {"title": "SEQUENCE MODELING", "content": "On the copy-paste task, see fig. 2 and table 3, we see significant improvement when using a trans-former as our guide network over an RNN target network. Prior work has observed the difficulty that RNNs have with copy-paste and usually attributes this to a fundamental algorithmic limit on the capability of RNNs to memorize input sequences. Our results show a potential optimization scheme for RNNs that is applicable for sequence memorization. Similar to prior results with fully con-nected networks, this result improves when using a randomly initialized network. We explore this more thoroughly in further analyses but this is likely because optimization with randomly initialized networks is easier due to the degrees of freedom in CKA."}, {"title": "REPRESENTATIONAL SIMILARITY LOSS", "content": "We can view the representational alignment between the guide and target networks during train-ing. This allows us to better understand how this representational alignment influences network performance.\nWe notice that across most tasks, reducing representational dissimilarity is easier with activations from randomly initialized networks rather than trained networks. This provides additional evidence of representational alignment for inductive bias transfer. We notice that for certain cases, such as Parity, the randomly initialized guide network has higher representational dissimilarity loss than the trained guide network. This is matched with the Parity result in table 3 and fig. 2."}, {"title": "ERROR CONSISTENCY", "content": "Given our guided networks, we can analyze the functional properties of the guided network to con-firm whether networks adopt priors from their guide networks. Using Deep FCN as our target model, we guide it with a ResNet-18 or a ViT-B-16 (Dosovitskiy, 2020). We then measure the error consis-tency (Geirhos et al., 2020) between all of the networks which indicates the error overlap between two networks based on the accuracy of the networks, i.e. do the two networks make similar class predictions? The measure first calculates the expected error overlap. Suppose $a_1$ is the accuracy of the first guided network and $a_2$ is the accuracy of the second. The expected error overlap is given by $C_{exp} = a_1 * a_2 + (1 - a_1) * (1 \u2013 a_2)$. Next, we measure the observed error overlap across each sample in the validation set as $C_{obs} = \\frac{\\text{# of samples where both models agree}}{\\text{total trials}}$. Finally, we can write $\\kappa$ as:\n$\\kappa = \\frac{C_{obs} - C_{exp}}{1 - C_{exp}}$"}, {"title": "NETWORK INITIALIZATION", "content": "Is guidance needed throughout training, or is the effect of the guide to move the target into a regime where the two are aligned and the target can be optimized further without reference to the guide? The answer to this question can shed light on whether the guide is telling us that better initializations are likely to exist for the target. To answer this question, we disconnect the guide from the target after an arbitrary and nominal number of training steps, 150. We did not investigate what the minimal number of steps needed was.\nFor FCNs, even this early disconnect avoids overfitting; see fig. 5. Furthermore, while preventing overfitting, we have lower training loss from guidance, indicating a better fit. This implies that there likely exists a better initialization for FCNs. In future work, we intend to investigate what the untrained guide is doing to the FCN weights to prevent validation loss from increasing dramatically."}, {"title": "CONCLUSION", "content": "We demonstrated that guidance eliminates the failure modes of networks previously considered unsuitable or ineffective for specific tasks. Aligning with another network overcomes these short-comings by transferring inductive biases-either architectural and knowledge-based, or solely ar-chitectural when using an untrained guide. This opens the door to many applications.\nFor some networks, like fully connected ones, we only overcame the initial obstacle. Further re-search is needed to refine these into effective vision models, as they avoid immediate overfitting. This may be a matter of scale, optimizers, learning rates, or other aspects of model design and train-ing. Our results suggest practical applications by significantly narrowing the performance gap be-tween vanilla stacked RNNs and Transformers, albeit in small-scale experiments. Given that stacked RNNs are equivalent to single-layer RNNs, most directly to delayed RNNs (Turek et al., 2020), this implies that complex modifications to RNNs may be unnecessary for language modeling. In future, one might be able to focus on the suitability for inference of different architectures with fewer hard constraints from architecture.\nGuidance also proved to be a tool with which to discover the possibility of new initializations. At the moment, no known method exists to find better initializations for networks. In some cases, as with the FCNs for vision, guidance can be disconnected after a nominal number of steps, but still goes on to regularize the target network. This strongly implies that an initialization regime for that target with the same regularization exists. This is all that guidance could do in that case. We now need tools to go backwards, given networks which are correctly initialized and networks which are not, discover what that initialization is. This is a much better place to be in. A systematic sweep of targets and guides to look for better initializations should be carried out.\nOur method can be used to study representational and functional design of neural networks in new ways to reinforce or reanalyze prior theory of neural network optimization. For example, we can understand distances between architectural components based on which target networks are easier to guide with a particular guide network. We also refine this notion to include a narrow channel through which guidance can occur, the representational similarity. This can serve as a kind of probe. Different representational similarity methods enforce alignment between different properties of the activations of networks.\nCharacterizing architectural priors and untrainable networks can be made more precise using our methodology. For example, guidance clearly distinguishes between at least three cases. One where the guide does not help. Another where the architecture of the guide helps, but not the knowledge. And one where both the architecture and the knowledge of the guide help. These are different phenomena whose root causes are not understood at present but that could elucidate the relationship between priors and architectures.\nLooking into the long-term future, it may be that architecture can be turned into a prior that we add to the loss of a generic fully-connected network, or any convenient and capable-enough network. Architecture would lose its prominence and the computational substrate could be disconnected from the priors we need for learning and inference. Architecture could potentially even be turned into a parameter to be optimized, rather than a hyperparameter."}, {"title": "METHODOLOGY LIMITATIONS", "content": "Our guide network supervision through representational alignment has one primary limitation due to increased memory usage during training. Due to saving activations across several layers of the two networks, GPU memory usage increases dramatically. Moreoever, our methodology works better as batch size increases since this allows for better approximation of representational similarity, increasing memory usage even more. Furthermore, including more layers for supervision leads to improved results.\nIn this paper, we introduce simple techniques to handle memory constraints such as gradient ac-cumulation and gradient checkpointing (Lin et al., 2017). In practice, more memory optimization techniques may become necessary to consider larger untrainable networks. Further work could con-sider using stronger representational alignment strategies to reduce the number of samples necessary to achieve a strong fit."}, {"title": "METHODS OVERVIEW", "content": "We give an overview of guidance in algorithm 1 and highlight crucial changes to base neural network training in either red or blue. We use blue to indicate the collection of network activations and red to indicate the layerwise mapping and representational alignment using a distance metric. This gives an overview of our layer mapping between the target and guide network. Crucially, we find that the simplest layer mapping where we evenly distribute guide network layers across target network layers for supervision obtains strong results."}, {"title": "ARCHITECTURE AND TRAINING DETAILS", "content": "For all tasks, we describe our target untrainable architectural designs for each task separately as well as the guide networks that are employed to make the untrainable network trainable."}, {"title": "IMAGE CLASSIFICATION", "content": "We design a fully-connected network consisting of 50 blocks. Each block contains a feedforward linear layer, a batch normalization, and a ReLU nonlinear activation. The intermediate feedforward linear layers contain 2048 units. This network is untrainable due to vanishing gradients since the network is very deep and due to overfitting.\nWe design a network similar to Deep FCN but only containing 3 blocks where each feedforward linear layer contains 8192 units. This network is considered untrainalbe due to a satu-ration on the training performance."}, {"title": "COPY-PASTE", "content": "We design a 4-layer RNN with a hidden dimension of 768 units, followed by a fully connected layer. In copy-paste, architectural and algorithmic limitations make RNNs an untrainable architec-ture fortask. Specifically, RNNs must memorize the input sequence which is difficult, particularly with a padding token. RNNs are generally considered to be unapplicable to the copy-paste task.\nWe consider a 4 layer transformer decoder architecture with a hidden dimension of 768 units across 12 transformer heads. The transformer is well-suited for copy-paste as the attention mechanism can act as a routing mechanism for the sequence. We train the transformer guide from scratch, as with language modeling and achieve 96.90% accuracy on the task."}, {"title": "PARITY", "content": "We design a 5 layer vanilla RNN with a hidden dimension of 512 and with a tanh activation function. We train this with on sequences with a context length of 75. This makes the network un-trainable due to problems associated with exploding and vanishing gradients during backpropagation through time."}, {"title": "TRAINING", "content": "In Table 4, we show the different learning rate settings we converged to in each experiment. For each experiment, we did a grid search over 5 different learning rate parameters to ensure optimal"}, {"title": "REPRESENTATIONAL REGULARIZATION", "content": "We also aim to understand the role of the guide network as in guidance. In all experiments, we use trained and untrained guide networks and see consistent improvements for training the target network. The success of untrained networks implies that our training method is not performing distillation but instead truly transferring a prior from the guide network to the target network. To more strictly test this theory, we include an experiment where we feed noise to the guide network instead of the same batch of data fed to the target network as implied by eq. (1).\nWe apply this experiment to the Deep FCN with an untrained ResNet-18 as the target network. At each training step, we pass a noisy batch which is sampled from a random Gaussian with mean of 0 and standard deviation of 1. We train for 100 epochs and report the learning curve results in fig. 6.\nThis result confirms our intuition about the role of guide network: as a guide on model priors rather than a pure distillation of information. While the overall cross-entropy loss magnitudes are higher and the overall accuracy is lower when passing noise to the guide network, our results are significantly better than applying vanilla training approaches to the Deep FCN."}, {"title": "TEST ACCURACY ACROSS TRAINING", "content": "We plot accuracies over training as a complement to cross-entropy loss in fig. 7 for the sequence modeling experiments. We can use these experiments to de-couple our results from properties of cross-entropy loss that may lead to misleading improvements across training. We find that accuracies improve consitently across training, supporting the loss curve interpretation that guided training improves results."}, {"title": "MEAN-SQUARED ERROR LOSS", "content": "Throughout this work, we have mainly focused on a classification task and employed the cross-entropy loss function as our main task loss. However, other loss functions can be applied which do not have the same properties as cross-entropy loss for learning classification tasks as well as other kinds of tasks like regression tasks. One such loss is mean-squared error (MSE) loss. We include an additional experiment with guidance where we train the Deep FCN for image classification with a ResNet-18 guide.\nWe design an experiment where we train Deep FCN on the CIFAR-10 dataset (Krizhevsky et al., 2010) with an untrained ResNet-18 guide. Our reasoning for using CIFAR-10 instead of ImageNet"}, {"title": "GUIDANCE WITH RSA", "content": "To further understand the generality of guidance as an approach, we include one experiment where we guide a network using a different metric for representational alignment. We choose representa-tional similarity analysis (RSA) (Kriegeskorte et al., 2008) as our main approach. Our main criteria for a metric is differentiability and compute time. RSA is differentiable and can be computed quickly per batch. This makes it a natural candidate after CKA. We first describe RSA and use it as part of guidance between ResNet-18 and the Deep FCN."}, {"title": "REPRESENTATIONAL SIMILARITY ANALYSIS", "content": "We use the RSA formulation as described in Kriegeskorte et al. (2008). Specifically, RSA constructs representational dissimilarity matrices (RDMs) for two sets of representations and compares them using an outer similarity function.\nGiven two sets of representations, $R \\in \\mathbb{R}^{b \\times d_1}$ and $R' \\in \\mathbb{R}^{b \\times d_2}$, we first calculate RDMs for each set of representations using a distance function d. Formally, we define $D \\in \\mathbb{R}^{b \\times b}$ as\n$D_{i,j} := s(R_i, R_j)$"}, {"title": "RESULTS", "content": "We apply guidance with RSA to Deep FCN as our target network and ResNet-18 as our guide network. Similar to our CKA results, we train for 100 epochs with a batch size of 256, as RSA is sensitive to the number of samples when comparing sets of representations. We see results over the training, validation, and representational dissimilarity loss in fig. 9. The Deep FCN guided by a trained ResNet-18 achieves a top-5 accuracy of 11.02% and the Deep FCN guided by a randomly initialized ResNet-18 achieves a top-5 accuracy of 11.74%.\nWe can first observe that guided training improves over base training as noted in fig. 2 and table 2. This demonstrates the generality of our approach to other metrics. As long as a representational similarity metric is differentiable, we can optimize the metric for alignment between two networks as a method to transfer the prior of one network to another."}]}