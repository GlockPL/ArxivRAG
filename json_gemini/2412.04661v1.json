{"title": "HEAL: Hierarchical Embedding Alignment Loss for Improved Retrieval and Representation Learning", "authors": ["Manish Bhattarai", "Ryan Barron", "Maksim Eren", "Minh Vu", "Vesselin Grantcharov", "Ismael Boureima", "Valentin Stanev", "Cynthia Matuszek", "Vladimir Valtchinov", "Kim Rasmussen", "Boian Alexandrov"], "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by integrating external document retrieval to provide domain-specific or up-to-date knowledge. The effectiveness of RAG depends on the relevance of retrieved documents, which is influenced by the semantic alignment of embeddings with the domain's specialized content. Although full fine-tuning can align language models to specific domains, it is computationally intensive and demands substantial data. This paper introduces Hierarchical Embedding Alignment Loss (HEAL), a novel method that leverages hierarchical fuzzy clustering with matrix factorization within contrastive learning to efficiently align LLM embeddings with domain-specific content. HEAL computes level/depth-wise contrastive losses and incorporates hierarchical penalties to align embeddings with the underlying relationships in label hierarchies. This approach enhances retrieval relevance and document classification, effectively reducing hallucinations in LLM outputs. In our experiments, we benchmark and evaluate HEAL across diverse domains, including Healthcare, Material Science, Cybersecurity, and Applied Maths.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs), such as GPT-4 [OpenAI, 2023], have demonstrated exceptional capabilities in natural language understanding and generation. However, LLMs are prone to hallucinations, generating plausible but incorrect or nonsensical content [Ji et al., 2023]. Retrieval-Augmented Generation (RAG) frameworks [Lewis et al., 2020] mitigate this issue by integrating external knowledge through document retrieval, enhancing the factual accuracy of LLM outputs. A critical component of RAG systems is the embedding model used for document retrieval. Standard embedding models, however, often fail to capture the hierarchical and semantic relationships within domain-specific corpora, leading to suboptimal retrieval and, consequently, increased hallucinations. This issue is particularly pronounced in domains with increased specificity such as Healthcare, Legal sytem, and Scientific research.\nCorpus of documents for a specialized domain inherently exhibit a high degree of semantic coherence, presenting an opportunity to align embedding models for retrieving the most contextually relevant information. Hierarchical Non-negative Matrix Factorization (HNMF) [Eren et al., 2023] is a powerful technique for semantically categorizing documents into clusters that exhibit thematic coherence. By grouping documents into hierarchical clusters of supertopics and subtopics, HNMF provides a rich semantic categorization of the corpus, enabling a deeper understanding of document relationships. Leveraging this semantic knowledge in the form of hierarchical cluster labels, we can align embedding models to preserve hierarchical information within the embedding space. This alignment enhances the embeddings to capture both coarse-grained and fine-grained document similarities, improving contextual relevance in retrieval tasks and enabling better downstream capabilities.\nTo tackle the challenges of hallucination and suboptimal retrieval in RAG systems, we introduce the Hierarchical Embedding Alignment Loss (HEAL), a refined extension of the Hierarchical Multi-label Contrastive Loss [Zhang et al., 2022]. HEAL leverages an improved hierarchical weighting scheme to align embeddings more effectively with the underlying hierarchical structure. By incorporating hierarchical label structures, HEAL fine-tunes embedding models to align with document clusters derived from HNMF. The method computes contrastive losses at each hierarchical level, combining them with depth-specific penalties to emphasize distinctions at higher levels of the hierarchy.\nOur contributions are summarized as follows:\n1. Introduce a refined contrastive learning framework, named HEAL, that incorporates hierarchical label structures to align embeddings with hierarchical document relationships.\n2. Integrate HEAL into RAG systems, fine-tuning embedding models to improve retrieval accuracy and reduce hallucinations in LLM outputs.\n3. Validate and benchmark HEAL through extensive experiments on domain-specific datasets from specialized scientific sub-domains of Healthcare, Material Science, Tensor Decomposition, and Cyber-security.\n4. Showcase significant improvements in retrieval relevance and downstream tasks compared to baseline method."}, {"title": "2 Related Work", "content": "Contrastive learning has become a cornerstone of representation learning, particularly in computer vision and natural language processing. Methods like SimCLR [Chen et al., 2020] and MoCo [He et al., 2020] have achieved state-of-the-art performance in unsupervised settings by learning representations that are invariant to data augmentations. In supervised contrastive learning, Khosla et al. [2020] extended the contrastive loss to utilize label information, improving performance on classification tasks. Similarly, the SciNCL framework employs neighborhood contrastive learning to capture continuous similarity among scientific documents, leveraging citation graph embeddings to sample both positive and negative examples Ostendorff et al. [2022]. However, these methods generally assume flat label structures and do not exploit hierarchical relationships."}, {"title": "3 Method", "content": "In this section, we propose an embedding alignment framework comprising hierarchical label extraction with HNMF, embedding alignment using HEAL, and retrieval with aligned embeddings as outlined in Figure 1."}, {"title": "3.1 Hierarchical Document Clustering with HNMFk.", "content": "Hierarchical Non-negative Matrix Factorization with automatic latent feature estimation (HNMFk) Eren et al. [2023] is an advanced technique for uncovering hierarchical patterns within document collections. It builds on traditional Non-negative Matrix Factorization (NMF) Vangara et al. [2021] by dynamically and automatically determining the optimal number of latent features at each level. Effective contrastive learning relies on well-separated document cluster labels to align embeddings effectively. HNMFk's ability to automatically balance stability and accuracy using a bootstrap approach enhances the quality of clustering results. In this work, we utilize the publicly available HNMFk implementation from the TELF library 6.\nGiven a Term Frequency-Inverse Document Frequency (TF-IDF) matrix $X \\in \\mathbb{R}^{n \\times m}$, where n represents the vocabulary size and m denotes the number of documents, HNMFk performs a sequence of matrix factorizations across hierarchical levels to capture the nested structure of topics. At each level 1, the factorization is expressed as $X \\approx W^{(l)}H^{(l)}$, where $W^{(l)} \\in \\mathbb{R}^{n \\times k_l}$ is the basis matrix representing latent topics, and $H^{(l)} \\in \\mathbb{R}^{k_l \\times m}$ is the coefficient matrix quantifying the contribution of each topic to the composition of documents. Here, $k_l$ is the number of topics at level l, which is determined automatically through stability analysis Vangara et al. [2021]. This analysis involves bootstrapping the data to create resampled versions of the TF-IDF matrix, applying NMF across a range of k values, and evaluating the stability of clusters across the resampled datasets. The optimal $k_l$ is selected as the value that produces the most consistent clustering results, indicating a robust underlying structure in the data.\nTo construct hierarchical labels for each document, the coefficient matrix $H^{(l)}$ is used to determine topic assignments. For each level 1, the topic for document i is identified by selecting the index of the maximum value in the corresponding column of $H^{(l)}$, expressed as $y_i^{(l)} = arg max_k H_{ki}^{(l)}$. The hierarchical label for document i is then formed by aggregating the topic assignments across all levels, resulting in $y_i = (y_i^{(0)}, y_i^{(2)}, ..., y_i^{(L-1)})$. Here, L is the total number of hierarchical levels, or hierarchical depth that is the number of NMFk operations from the first one to the leaf. $y_i^l$ is the label of sample i at level l, with l = 0 corresponding to the shallowest (most general or root node) level and l = L \u22121 to the deepest (most fine-grained, or leaf node) level."}, {"title": "3.2 Hierarchical Multilevel Contrastive Loss (HEAL)", "content": "Upon the unsupervised data decomposition with HNMFk, the datasets have clusters with hierarchical structures. To incorporate such structures, we propose the HEAL, which extends supervised contrastive loss [Khosla et al., 2020] by introducing level-wise contrastive losses and aggregating them with level-specific penalties."}, {"title": "Level-wise Contrastive Loss", "content": "For a batch of N samples ${(x_i, y_i)}_1^N$, where $x_i \\in \\mathbb{R}^d$ is the input and $y_i \\in \\mathbb{R}^L$ is the hierarchical cluster label, we obtain normalized embeddings ${h_i}_1^N$ using an encoder network $f_\\theta(\\cdot)$:\n$h_i = \\frac{f_\\theta(x_i)}{||f_\\theta(x_i)||_2},  h_i \\in \\mathbb{R}^d.$\nFor a given level l, the set of positive samples for sample i is:\n$P(i, l) = \\{p | y_i^l = y_p^l, p \\neq i\\}.$\nThe contrastive loss at level l for sample i is:\n$L_{i,l} = -\\frac{1}{|P(i, l)|}\\sum_{p\\in P(i,l)} log \\frac{exp (h_i \\cdot h_p /\\tau)}{\\sum_{a=1}^N exp (h_i \\cdot h_a /\\tau)}$\nIf P(i, l) is empty (i.e., no positive samples at level l for i), $L_{i,l}$ is excluded from the total loss."}, {"title": "Aggregating Level-wise Losses with Penalties", "content": "To prioritize discrepancies at shallower levels, we assign penalties $\\lambda_l$ to each level l, where shallower levels have higher penalties. The penalties are defined as:\n$\\lambda_l = \\frac{2^{L-1-l}}{\\sum_{k=0}^{L-1} 2^{L-1-k}} = \\frac{2^{L-1-l}}{2^{L-1}-1}.$\nThe penalties $\\lambda_l$ satisfy:\n1. $\\lambda_l > \\lambda_{l+1}$ for l = 0, 1, ..., L - 2, i.e., penalties decrease for deeper levels.\n2. $\\sum_{l=0}^{L-1} \\lambda_l = 1$, i.e., the penalties are normalized.\nThe total HEAL loss is then:\n$C_{HEAL} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{l=0}^{L-1} \\lambda_l L_{i,l}$"}, {"title": "3.3 Fine-tuning Embedding Models with HEAL for RAG", "content": "To enhance retrieval performance in RAG systems, we fine-tune the embedding model to align with the hierarchical structure of the document corpus. Given a specialized document corpus, we first apply HNMFk (as described in Section 3.1) to the corresponding TF-IDF matrix X producing hierarchical cluster labels $y_i = (y_i^{(0)},y_i^{(2)},...,y_i^{(L-1)})$ for each document i. Next, we generate embeddings from each document $x_i$ using a pretrained embedding model $f_\\theta(.)$. The embedding model is initialized with pre-trained weights and produces normalized embeddings $h_i \\in \\mathbb{R}^d$ for document i. To align embeddings with the hierarchical structure, we optimize the HEAL presented in 3.3.\nThe embedding model is trained by minimizing $C_{HEAL}$ using gradient-based optimization:\n$\\theta^* = arg min C_{HEAL},$\nwhere $\\theta$ are the parameters of the embedding model $f_\\theta(.)$.\nAfter fine-tuning, the updated embeddings $h_i = f_{\\theta^*}(x_i)$ are used to replace the initial embeddings in the vector store. During inference, a query q is embedded using $f_{\\theta^*}(.)$ as $h_q = f_{\\theta^*}(q)$, and retrieves top p documents based on cosine similarity:\n$Similarity (q, x_i) = \\frac{h_q \\cdot h_i}{||h_q|| ||h_i||}.$\nTo maximize retrieval performance in RAG systems, it is essential to align the query embeddings with the hierarchically aligned document embeddings. Since queries are typically shorter and may not capture the full semantic richness of the documents, we need to semantically align queries and documents in the embedding space. To achieve this, we generate question-answer (Q&A) pairs using a language model (e.g., LLaMA-3.1 70B) for each document and leverage HEAL to jointly align both query and document embeddings during training. For each document $x_i$, we generate a set of queries $\\{q_{i,k}\\}_{k=1}^{K_i}$, where $K_i$ is the number of queries generated for document i. Each query $q_{ik}$ is associated with the same hierarchical labels $y_i$ as its source document $x_i$, since it is derived from the content of $x_i$. We extend the HEAL framework to include both documents and queries by defining a unified set of samples:\n$S = \\{x_1,..., x_N\\} \\cup \\{q_{i,k} | i = 1, ..., N; k = 1, ..., K_i\\}.$\nEach sample $s_j \\in S$ has an associated hierarchical label $y_j$, where:\n$y_j = \\begin{cases} y_i, & \\text{if } s_j = x_i \\text{ (document)}; \\\\ y_i, & \\text{if } s_j = q_{i,k} \\text{ (query generated from document } x_i). \\end{cases}$\nBased on this dataset, the HEAL is leveraged to finetune the embedding model."}, {"title": "4 Experiments", "content": "We evaluate our method on datasets specifically constructed from scientific publications in the domains of Material Science, Medicine, Tensor Decomposition, and Cybersecurity. To construct our datasets, we leveraged the Bibliographic Utility Network Information Expansion (BUNIE) method, a machine learning-based approach that integrates subject-matter expertise in a human-in-the-loop framework Solovyev et al. [2023]. For completeness, we briefly summarize the BUNIE approach in this paper. BUNIE begins with a small core corpus of documents selected by subject-matter experts (SMEs). From this starting point, it constructs a citation network to identify additional relevant documents, leveraging BERT based text embeddings to assess semantic similarity. Through iterative cycles of dataset expansion and pruning-guided by embedding visualization, topic modeling, and expert feedback-the method ensures the corpus is both comprehensive and domain-specific. We apply this procedure to each scientific domain with guidance from SMEs, who provide target keywords/phrases and/or a core set of papers relevant to the sub-topic of interest within the domain. Using this knowledge base, we employ BUNIE to expand the dataset from the initial core papers to a larger collection of domain-specific documents."}, {"title": "4.1 Datasets", "content": "1. Material Science: A collection of 46,862 scientific articles, which explore 73 Transition Metal Dichalcogenides (TMD) compounds, combining transition-metal and chalcogen atoms (S, Se, or Te). With a layered structure similar to graphite, TMDs excel as solid lubricants and exhibit unique quantum phases like superconductivity and charge density waves. Their atomically thin layers offer tunable properties, with applications in spintronics, optoelectronics, energy harvesting, batteries, and flexible electronics.\n2. Healthcare: A collection of 9,639 scientific articles, which examine Pulmonary Hypertension (PH) disease a rare condition causing elevated pulmonary arterial pressure, right heart strain, and reduced oxygen delivery. The WHO classifies PH into five groups based on causes, including pulmonary arterial hypertension (PAH), which has a prevalence of 15-25 cases per million in the U.S. Treatments such as endothelin receptor antagonists and prostacyclin analogs aim to improve symptoms, but prognosis varies, with untreated PAH having a median survival of less than three years.\n3. Applied Mathematics: A collection of 4,624 scientific articles, which explore tensor network techniques, such as Tensor-Train (TT) decomposition, which recently emerged as a powerful mathematical tool for solving large-scale Partial Differential Equations (PDEs). Tensor network PDE solvers efficiently manage high-dimensional data by mitigating the curse of dimensionality, drastically reducing computational costs and memory usage while maintaining high solution accuracy. These advancements hold significant promise for breakthroughs in scientific computing, including material science, climate modeling, and engineering design optimization.\n4. Cyber-security: We created a dataset of 8,790 scientific publications focusing on the application of tensor decomposition methods in cybersecurity and ML techniques for malware analysis. This dataset serves as a knowledge base covering topics for cyber-security such as ML-based anomaly detection, malware classification, novel malware detection, uncertainty quantification, real-world malware analysis challenges, tensor-based anomaly detection, malware characterization, and user behavior analysis."}, {"title": "4.2 Experimental Setup", "content": "For training, we used the Adam optimizer with a learning rate of 10-5, a batch size of 128, and early stopping based on validation performance with a patience of 5 epochs. The experiments were conducted on a high-performance computing cluster, with each node equipped with 4 NVIDIA GH200 GPUs. Document metadata, comprising the title and abstract combined, were used as input. Hierarchical labels were generated using HNMF with dataset-specific factorization depths: Material Science (depth 3), Healthcare (depth 4), Applied Mathematics (depth 3), and Cybersecurity (depth 3). HEAL loss was applied with a temperature parameter of 0.07. The embedding base model, SciNCL Ostendorff et al. [2022], was chosen for its robust contrastive pretraining on scientific documents, serving as a strong baseline for fine-tuning. The data was split into 60% training, 20% validation, and 20% test sets, with early stopping monitored on the validation set. Evaluation metrics were reported on the test set, while Q&A retrieval analysis used the entire dataset (train + validation + test) for constructing the vector store.\nThe efficacy of the RAG system was evaluated at two levels. First, we characterized the embeddings on document-level tasks, including hierarchical classification, retrieval, and hallucination measurement. For hierarchical classification, we used a hierarchical classifier applying random forests to each node [Miranda et al., 2023]. The classifier is trained on embeddings corresponding to train dataset and evaluated against the test set. We perform this for embeddings derived from aligned and unaligned embedding model. Retrieval performance was assessed by measuring whether retrieved documents belonged to the same hierarchical class as the query document. Hallucination likelihood was evaluated based on the retrieval of incorrect documents for a given query. Second, we evaluated the performance of the embedding model within a RAG framework. To support retrieval and hallucination analysis, we used the LLaMA-3.1 70B model to generate 10 Q&A pairs per document using abstracts as input, providing a robust test for embedding alignment and retrieval capabilities. Next, we leveraged the questions as queries to the embedding model to retrieve the best metadata and assessed whether the model retrieved the exact document that generated the query during Q&A analysis, as well as the rank of the returned document within the top 10 results. Furthermore, the retrieved documents were augmented with LLaMA-3.1 70B LLM to generate responses, with hallucinations evaluated based on response accuracy and relevance.\nGiven the specialized nature of our dataset and the requirement for hierarchical labels, fine-tuning is essential. Comparing our method to approaches that do not leverage hierarchical labels is inequitable, as they are inherently less effective for this task. Our approach simplifies training by eliminating HEAL loss hyperparameter tuning, unlike HiMulCon Zhang et al. [2022], which requires extensive tuning of penalty parameters for optimal results. While HiMulCon focuses on root-level classification in vision datasets, our method aligns embeddings across all hierarchical depths. We optimize hierarchical metrics such as classification, retrieval, and hallucination indirectly through the HEAL loss, ensuring a robust alignment with the hierarchical structure.\nFor these reasons, we evaluate the performance of HEAL using the baseline model SciNCL, both without and with hierarchical alignment on our diverse specialized datasets. We evaluate performance using hierarchical metrics to capture nuances of hierarchical label structures in retrieval, classification, and hallucination assessments as presented in Table 1."}, {"title": "4.3 Results", "content": "Table 2 summarizes the performance metrics for three datasets (Healthcare, Materials, Applied Mathematics, and Cybersecurity) across three tasks: classification, retrieval, and hallucination evaluation. The aligned model corresponds to the embedding model trained using the HEAL loss, whereas the non-aligned model corresponds to the original embedding model without HEAL-based training. The metrics are reported for both non-aligned and aligned SciNCL embeddings, demonstrating the significant impact of HEAL on improving performance. Figure 2 illustrates hierarchical embedding alignment achieved through HEAL training, resulting in well-separated super and sub-clusters for the Materials and Healthcare datasets which enhances the performance of downstream tasks.\nFirst, we evaluate the performance on document-level tasks using hierarchical labels. Specifically, we assess the ability of the hierarchical classifier to predict hierarchical labels in the classification task. Additionally, we quantify the retrieval of documents from the same hierarchical category based on a query document to characterize retrieval accuracy and evaluate hallucinations. The results presented in table 2 demonstrate that HEAL significantly improves hierarchical classification metrics across all datasets. For the Healthcare dataset, the Hierarchical F1 Score improves from 0.5164 to 0.6588, reflecting a more accurate representation of hierarchical labels. Similarly, the Materials dataset achieves near perfect classification metrics (F1 Score, Precision, Recall = 0.99) with aligned embeddings, while the most challenging Healthcare dataset (4 depth cluster label) sees improvements in F1 Score from 0.5164 to 0.6588. In retrieval tasks, HEAL aligned embeddings consistently outperform non-aligned embeddings across all metrics. For the Healthcare dataset, Hierarchical MRR improves from 1.6259 to 2.2525, and nDCG@k increases from 0.3752 to 0.5908 where k = 10, indicating better ranking and retrieval relevance. The Materials dataset achieves a dramatic increase in retrieval precision, with Precision@k rising from 0.4787 to 0.9707, while nDCG@k reaches 0.99, showcasing near-perfect retrieval performance. For the Cyber dataset, aligned embeddings yield an MRR improvement from 2.7538 to 3.1482 and a corresponding nDCG@k increase from 0.6781 to 0.7908. Hallucination metrics further underscore the superiority of HEAL. Aligned embeddings reduce hallucination rates significantly across all datasets. For the Healthcare dataset, FPR@k drops from 0.9386 to 0.8771, and severity decreases from 0.7306 to 0.5533, indicating fewer irrelevant or misleading retrievals. The Materials dataset shows the most striking improvement, with FPR@k reduced from 0.8534 to 0.0878 and severity declining from 0.6041 to 0.0644, nearly eliminating hallucination tendencies. For the Cyber dataset, aligned embeddings lower FPR@k from 0.7968 to 0.6236 and severity from 0.4402 to 0.3654.\nNext, we evaluate the performance of aligned RAG in retrieving the correct documents for generated queries to augment the LLM and minimize hallucinations. From each test dataset, we randomly sampled 100 documents and generated 10 Q&A pairs per document using the LLAMA-3.1 70B model, resulting in a total of 1,000 Q&A pairs for each dataset. Each Q&A pair was tagged with the corresponding document from which it was generated. The prompt used for Q&A generation was as follows: \u201cFirst, provide a concise summary of the following abstract that emphasizes its key concepts and hierarchical relationships. Then, based on this summary, generate 10 unique, nuanced Q&A pairs. Focus on creating questions that delve into specialized details of the hierarchical concepts discussed.\u201d The generated queries were used to fetch documents via both aligned and unaligned models. We assessed the ability of each model to correctly retrieve the original document and evaluated the rank/order of retrieval. On average, the unaligned model achieved an MRR of 0.273 and a Recall@10 of 0.415. These metrics represent regular retrieval scores, not hierarchical scores. In contrast, the aligned model significantly improved performance, achieving an MRR of 0.514 and a Recall@10 of 0.731, demonstrating its superior ability to retrieve the correct set of documents. Furthermore, when integrating RAG with LLAMA-3.1 70B for generating answers from the queries and retrieved documents, the unaligned model produced a ROUGE score of 0.42, while the aligned model achieved a ROUGE score of 0.68. This highlights the impact of alignment on improving the quality and relevance of generated responses."}, {"title": "5 Conclusion", "content": "In this work, we introduced HEAL, a novel framework for aligning embeddings in RAG systems through hierarchical fuzzy clustering and matrix factorization, integrated within a contrastive learning paradigm. HEAL effectively computes level-specific contrastive losses and applies hierarchical penalties to align embeddings with domain-specific structures, enhancing both retrieval relevance and classification performance. Experimental results across diverse domains Healthcare, Materials Science, Cybersecurity, and Applied Mathematics demonstrate HEAL's capability to significantly improve retrieval accuracy and mitigate hallucinations in LLM-based systems. By bridging hierarchical semantics with contrastive alignment, HEAL establishes itself as a versatile and robust tool for advancing RAG methodologies, enabling more precise, reliable, and domain-adaptive applications of large language models."}]}