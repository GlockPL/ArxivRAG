{"title": "COUNTERFACTUAL GENERATION FROM LANGUAGE\nMODELS", "authors": ["Shauli Ravfogel", "Anej Svete", "V\u00e9steinn Sn\u00e6bjarnarson", "Ryan Cotterell"], "abstract": "Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery-e.g., model ablations or ma-\nnipulation of linear subspaces tied to specific concepts to intervene on these\nmodels. To understand the impact of interventions precisely, it is useful to ex-\namine counterfactuals-e.g., how a given sentence would have appeared had it\nbeen generated by the model following a specific intervention. We highlight that\ncounterfactual reasoning is conceptually distinct from interventions, as articulated\nin Pearl's causal hierarchy. Based on this observation, we propose a framework for\ngenerating true string counterfactuals by reformulating language models as Gener-\nalized Structural-equation. Models using the Gumbel-max trick. This allows us to\nmodel the joint distribution over original strings and their counterfactuals resulting\nfrom the same instantiation of the sampling noise. We develop an algorithm based\non hindsight Gumbel sampling that allows us to infer the latent noise variables and\ngenerate counterfactuals of observed strings. Our experiments demonstrate that the\napproach produces meaningful counterfactuals while at the same time showing that\ncommonly used intervention techniques have considerable undesired side effects.", "sections": [{"title": "1 INTRODUCTION", "content": "The study of language model (LM) interpretability often borrows terminology from Pearl's causal\ncalculus (Pearl, 1989), e.g., researchers often talk of intervening a model's parameters and counter-\nfactually generating strings. Pearl's framework distinguishes between three levels of causal reasoning\n(Shpitser & Pearl, 2008). Association, the first level, pertains to statistical correlations, i.e., ob-\nserving patterns observed in data without interacting with the world. Intervention, the second level,\npertains to actively changing variables in the world and observing their effects at a macro level.\nCounterfactuality, the third level, pertains to imagining what could have happened if past events\nhad unfolded differently. However, LM literature often uses these three causal terms causally and\nat times imprecisely-particularly when it comes to counterfactuality, which remains challenging to\nrigorously define (Feder et al., 2022; Mueller, 2024; Mueller et al., 2024). In this paper, we are given a\nwell-defined notion of counterfactuality in LMs using the framework of structural equation modeling.\nEfforts to exert control over LMs have led to substantial research on targeted interventions in\nthe models. One such technique is representation surgery, which involves modifying an LM's\narchitecture to manipulate its internal representation space (Lakretz et al., 2019; Vig et al., 2020;\nFeder et al., 2021; Ravfogel et al., 2021b; Elhage et al., 2021; Elazar et al., 2021; Nanda, 2023; Syed\net al., 2023; Kram\u00e1r et al., 2024; Avitan et al., 2024). The linear subspace hypothesis (Bolukbasi\net al., 2016; Vargas & Cotterell, 2020; Ravfogel et al., 2022) posits that human-interpretable concepts,\nsuch as gender or grammatical number, are encoded within specific linear subspaces of the LM's\nrepresentation space. This makes it possible to perform precise interventions on these high-level\nconcepts, such as removing the concept's information by projecting the representations onto the"}, {"title": "2 LANGUAGE MODELS AS GENERALIZED STRUCTURAL-EQUATION MODELS", "content": "Let \u2211 be an alphabet\u2014a finite, non-empty set of symbols. A language model (LM) is a probability\ndistribution over \u2211*, the set of all strings formed from symbols in \u03a3. A language encoder is a\nfunction ho: \u03a3* \u2192 Rd parameterized by parameters \u2295 that maps strings to d-dimensional vectors\n(Chan et al., 2024). Representational surgery is performed by intervening on ho. Popular architectures\nfor implementing language encoders include Transformers (Vaswani et al., 2017) and recurrent neural\nnetworks (RNNs; Elman, 1990). Language encoders are particularly valuable because under mild\nconditions (Du et al., 2023, Thm. 4.7), they ensure the model defines a distribution over strings-thus\nforming an LM-as follows:\n$$p(w) = p(\u03c9_1\u2026\u03c9_T)$$\n$$= p(EOS | w) \\prod_{t=1}^T p(w_t | w_{<t})$$\n$$= softmax(E h_\\Theta(w) + b)_{EOS} \\prod_{t=1}^T softmax(E h_\\Theta(w_{<t}) + b)_{w_t}$$\nHere, E \u2208 R^{|\\Sigma| \\times d} and b \u2208 R^{|\\Sigma|}. We assume that EOS & \u2211 and define \u2211 = \u2211 \u222a {EOS}."}, {"title": "2.1 STRUCTURAL EQUATION MODELING", "content": "We begin by briefly reviewing structural equation modeling, which provides a framework for dis-\ncussing causal manipulations of the generation process and allows us to precisely define the intuitive\nnotion of a counterfactual."}, {"title": "2.2 LANGUAGE PROCESSES AND GENERALIZED STRUCTURAL CAUSAL MODELS", "content": "We next show how LMs can be framed as GSEMs. We begin by defining the Gumbel distribution.\nDefinition 2.4 (Gumbel distribution). The cumulative distribution function of the standard Gum-\nbel distribution Gumbel(0, 1) is F (x) = exp(- exp(-x)) and its density function is f (x) =\nexp (- (x + exp(-x))).\nThe Gumbel distribution is useful to model the distribution of the maximum (or minimum) of a set of\nsamples from various distributions. This is the core idea behind the Gumbel-max trick, which shows\nthe utility of Gumbel-distributed random variables for sampling from the categorical distribution\n(Luce, 1959; Yellott, 1977; Maddison et al., 2017; Hazan & Jaakkola, 2012; Maddison et al., 2014;\nHazan et al., 2016). We restate the trick below for the specific case of the softmax; see App. C for the\nproof.\nTheorem 2.1 (The Gumbel-max Trick). Let X be a categorical random variable over M categories\nsuch that\n$$P (X = m) = \\frac{exp (\u03c0_m)}{\\Sigma_{m'=1}^M exp (\u03c0_{m'})} = softmax (\u03c0)_m,$$\nfor m\u2208 {1,..., M} and a given vector of logits \u03c0\u2208 RM. The Gumbel-max trick states that\nsampling from X can be performed as follows: (i) draw M outcomes Y1,..., YM from a standard\nGumbel distribution Gumbel(0, 1) and (ii) set the outcome of X as\n$$m= argmax_{m' \\in {1,...,M}} \u03c0_{m'} + Y_{m'}.$$\nAs we make formal below, sampling from an encoder-based LM can be formulated with the Gumbel-\nmax trick, since the (affinely transformed) representations he (w) provide the logits \u03c0m in Eq. (3).\nLet \u2211 be an alphabet. A language process W {Wt}1 is an infinite sequence of (correlated)\nE-valued random variables, where we think of Wt as the random variable whose outcome generates\nthe tth symbol of a string (Du et al., 2024).3 Let U = {Ut}=1 be an infinite sequence of random\n|\u03a3|-dimensional vectors indexed by w \u2208 \u03a3where Ut(W) ~ Gumbel(0, 1). As explicated by Eq. (1c),"}, {"title": "3 COUNTERFACTUAL GENERATION", "content": "Framing LMs as GSEMs allows us to use the expansive set of causal tools on LMs. We focus on\ngenerating counterfactual strings for given observed ones\u2014strings that differ in particular features\nbut are generated with the same sampling noise\nas the previously observed ones. More precisely, let w = w\u2081\u2026\u03c9\u03c4 \u2208 \u03a3* be the string sampled\nfrom the LM induced by the encoder he with the parameters E and b, and the noise U.\nGiven a counterfactual encoder he with the parameters E and b, Eq. (4) tells us that w's counterfac-\ntual can be sampled as\n$$W_t = argmax_{w \\in \\Sigma} (E h_\\Theta (w_{<t}) + b)_w + U_t (w).$$\nThis procedure results in pairs of strings in 2*\u2014the original string w and its counterfactual w\u2014\nfrom the joint distribution P(W = w, W = \u0169). The counterfactual w is sampled from the same\ninstantiation of the exogenous variables U."}, {"title": "4 EXPERIMENTS", "content": "Many standard intervention techniques, such as knowledge editing (Meng et al., 2022; 2023) or\ninference-time intervention (Li et al., 2024; Singh et al., 2024) are intended to modify targeted aspects\nof model behavior, such as altering specific knowledge or increasing its truthfulness (Li et al., 2024).\nIf these interventions are surgical, we expect them to preserve the model's behavior on unrelated,\n\"neutral\" sequences\u2014such as random Wikipedia sentences, resulting in counterfactuals similar to the\noriginal sentence. We test this assumption."}, {"title": "4.1.1 EXPERIMENTAL SETUP", "content": "Setup. We perform experiments using GPT2-XL (Radford et al., 2018) and LLaMA3-8b (Touvron\net al., 2023) along with several well-established intervention techniques. These include MEMIT\n(Meng et al., 2023), inference-time interventions using linear steering (Li et al., 2024; Singh et al.,\n2024), and Instruction tuning (Touvron et al., 2023):\n\u2022 MEMIT (Meng et al., 2023) uses a low-rank update to the MLPs in the LM to update the\nknowledge of the model on a specific fact. We apply MEMIT on GPT2-XL model to edit the\nlocation of the Louvre from Paris to Rome, and the natural habitat of koalas from Australia\nto New Zealand. We refer to the resulting models as MEMIT-Louvre and MEMIT-Koalas,\nrespectively.\n\u2022 Inference-time intervention linearly steers the representations of the LM in a given layer,\nto encourage some behavior of interest. We use two similar but distinct methods: Honest\nLlaMa (Li et al., 2024) steers by linearly translating the attention modules to encourage\na more truthful behavior. MiMiC (Singh et al., 2024) steers by linearly transforming the\nsource class representations such that they exhibit the same mean and covariance as the\ntarget class. We focus on the concept of gender and take the source and target class to be\nshort biographies of males and females, respectively. We refer to the steered models as\nSteering-Honest and Steering-Gender.\n\u2022 Instruction Tuning finetunes the pretrained models on demonstrations of instruction fol-\nlowing. We refer to this model as LLAMA3-Instruct.\nIn each case, we define the model prior to the intervention as the original model and the model\nfollowing the intervention as the counterfactual model. For full details on the generation of the\ncounterfactual models, refer to App. D.1. For each original and counterfactual model pair, we generate\n500 sentences by using the first five words of randomly selected English Wikipedia sentences as\nprompts for the original model. We generate a continuation of a maximum of 25 tokens by sampling\nfrom the model using multinomial sampling (i.e., sampling from the entire model distribution over\nthe vocabulary). We then use Alg. 1 to generate a counterfactual sentence.\nEvaluation. Being prompted by a prefix from Wikipedia, the original model is not likely to generate\na continuation that exhibits a property that is the focus of any of the specific model intervention\ntechniques we examine (e.g., it is not likely to generate a sentence that discusses the location of the\nLouvre, for the MEMIT intervention). Accordingly, we expect the counterfactual strings to be similar\nto the original ones. This is desirable, as we ideally want surgical intervention without side effects.\nTo quantify side effects on arbitrary strings, we record the longest common prefix, which we define as\nthe length of the longest prefix of the original sentence that is shared with the counterfactual sentence\nnormalized by the length of the original sentence. To evaluate the semantic similarity between the"}, {"title": "4.1.2 RESULTS", "content": "The distribution of the normalized length of the longest common prefix is shown in Fig. 2. Among\nthe methods, MEMIT demonstrates the most precise intervention, with a median longest shared prefix\nlength of around 50% for both the Louvre and Koalas concepts. The steering vector interventions\nfollow at around 30%, with the instruction tuning intervention being the least surgical, sharing only"}, {"title": "4.2 INTERVENTION-FOCUSED COUNTERFACTUALS", "content": "In the previous section, we examine the degree to which different interventions are surgical. Ac-\ncordingly, we focused the evaluation on prompts drawn from Wikipedia, a domain we expect to be\nlargely orthogonal to the specific properties on which the interventions target. Here, we examine the\ncomplementary question: What do counterfactuals to sentences that are related to the focus of the\nintervention look like? We focus on two case studies: MEMIT, which edits for the location of the\nLouvre, and MiMiC, which employs a steering intervention to push the model in the male \u2192 female\ndirection."}, {"title": "4.2.1 GENDER STEERING", "content": "Setup. We focus this analysis on gender steering of the LLaMA3-Instruct model. We apply the\nMiMiC method (Singh et al., 2024), which modifies model representations by aligning male-focused\ntext representations with female-focused text representations. This approach results in a linear\ntransformation of the residual stream, ensuring that the mean and covariance of the source class\n(male-focused texts) match those of the target class (female-focused texts). We fit the transformation\non the Bios dataset (De-Arteaga et al., 2019), which consists of short biographies of individuals\nworking in various professions. Each biography is annotated with both gender and profession labels.\nFor the full details on the fitting of the MiMiC intervention, see App. D.1. Once the intervention\nis fitted, we first generate a continuation for 500 biographies in the dataset by sampling from the\noriginal model after prompting it with the first words in the biography, and then use Alg. 1 to generate\ncounterfactual continuations under the modified models.\nResults. A sample of the results can be found in Fig. 4 and App. E.2. The intervention demonstrates\nreasonable effectiveness in altering the pronouns used in the continuations. While the original\nbiographies all contain male pronouns, in 52.2% of the counterfactual continuations, only female\npronouns such as \"she\" and \"her\" are observed. In 23.2% of the cases, male pronouns persist, while\n16.6% show a mixture of female and male pronouns, and 7.6% of the counterfactuals do not include\nany pronouns at all.\nAn examination of the counterfactual continuations in Fig. 4 and App. E.2 reveals that the changes\nextend beyond pronouns. Specifically, there is a noticeable shift from stereotypically male-dominated"}, {"title": "4.2.2 \u039cEMIT LOCATION EDITING", "content": "Setup. We focus this analysis on the MEMIT-edited model, where the location of the Louvre was\nupdated from \"Paris\u201d to \u201cRome\". We begin by prompting the original model to generate sentences\nthat mention Paris as the location of the Louvre, such as \"Paris offers many attractions, but the\". See\nApp. D.2 for details. We filter out sentences that do not mention both Paris and the Louvre, resulting\nin 75 sentences. We then generate the counterfactuals with the counterfactual model.\nResults. First, we observe that the Louvre-focused counterfactuals deviate much more from the\nsemantics of the original sentences than non-Louvre-focused generations. The median normalized\nlongest prefix consists of only 23% of the tokens in the original sentences, compared with around\n50% in the Wikipedia-based counterfactuals. A manual inspection of the counterfactuals reveals a"}, {"title": "5 CONCLUSION", "content": "We introduce a framework for generating true counterfactuals from LMs by reformulating LMs as\nGeneralized Structural-equation Models with the Gumbel-max trick. This allows us to precisely\nmodel the joint distribution over original and counterfactual strings, enabling us to investigate causal\nrelationships at the highest level of Pearl's causal hierarchy. Our experiments reveal that commonly\nused intervention techniques, such as knowledge editing and linear steering, often induce unintended\nsemantic shifts in the generated text, highlighting the challenges of achieving precise and isolated\ninterventions. These observations underline the need for more refined methods that can achieve\ntargeted modifications with minimal collateral changes to the model's outputs."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "We detail our experimental setup in \u00a74.1.1 and App. D.1."}, {"title": "D EXPERIMENTAL SETUP", "content": "D.1 INDUCING COUNTERFACTUAL MODELS\nMEMIT. We run MEMIT on the GPT2-XL model. We have tried to replicate the results on\nLLaMA3-8b, but have not managed to induce successful knowledge edits. Following Meng et al.\n(2023), we focus the intervention on layer 13 of the model. We replicate all the hyperparameters"}, {"title": "D.2 MEMIT-TARGETED EVALUATION", "content": "In \u00a74.2.2, we evaluate the MEMIT knowledge editing technique, applied to update the Louvr'e\nlocation from Paris to Rome. For this evaluation, we need original sentences that mention Paris as the\nlocation of the Louvre. We generated such sentences by prompting the base GPT2-XL model with\nthe following prompts:\n\u2022 \"Paris offers many attractions, but the\"\n\u2022 \"The Louvre, located\",\n\u2022 \"While in Paris, I attended a guided tour of the\",\n\u2022 \"The Louvre Museum in\"\n\u2022 \"Paris is home to museums such as\"\n\u2022 \u201cThe Louvre Pyramid in\u201c\n\u2022 \"The famous Mona Lisa is displayed in the\"\n\u201cAmong all the art museums in the world, the Louvre\u201c\nWe generated continuations to these prompts using nucleus sampling and filtered those that do\nnot mention Paris and the Louvre. The process results in 75 sentences, from which we generate\ncounterfactual sentences using the MEMIT-edited model."}, {"title": "E OUTPUT EXAMPLES", "content": "In this appendix, we present 5 randomly-sampled pairs of original and counterfactual sequences,\nNote that since we generate a continuation of at most 25 tokens, some of the sentences end abruptly."}]}