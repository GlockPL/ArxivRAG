{"title": "HOW DOES DATA DIVERSITY SHAPE THE WEIGHT LANDSCAPE OF NEURAL NETWORKS?", "authors": ["Yang Ba", "Michelle V. Mancenido", "Rong Pan"], "abstract": "To enhance the generalization of machine learning models to unseen data, techniques such as dropout, weight decay ($L_2$ regularization), and noise augmentation are commonly employed. While regularization methods (i.e., dropout and weight decay) are geared toward adjusting model parameters to prevent overfitting, data augmentation increases the diversity of the input training set, a method purported to improve accuracy and calibration error. In this paper, we investigate the impact of each of these techniques on the parameter space of neural networks, with the goal of understanding how they alter the weight landscape in transfer learning scenarios. To accomplish this, we employ Random Matrix Theory to analyze the eigenvalue distributions of pre-trained models, fine-tuned using these techniques but using different levels of data diversity, for the same downstream tasks. We observe that diverse data influences the weight landscape in a similar fashion as dropout. Additionally, we compare commonly used data augmentation methods with synthetic data created by generative models. We conclude that synthetic data can bring more diversity into real input data, resulting in a better performance on out-of-distribution test instances.", "sections": [{"title": "1 INTRODUCTION", "content": "Machine learning (ML) models excel at discovering patterns from training data, which allows them to make predictions on unseen data. However, as models grow more complex, they risk a phenomenon called overfitting \u2013 the tendency of models to capture not only meaningful patterns but also noise and random variations from the training data, resulting in poor generalization to new instances. To address this, model regularization techniques, such as dropout (Srivastava et al., 2014) and weight decay ($L_2$ regularization)(Krogh & Hertz, 1991), are used in conjunction with Deep Neural Networks (DNNs) to enhance their generalization capability. While dropout reduces model complexity by randomly deactivating neurons during training, weight decay adds a penalty to the loss function based on the magnitude of model weights. These techniques shape the model's weight landscape in different ways: dropout works by randomly deactivating neurons during each training iteration, forcing the network to distribute learning across multiple independent pathways rather than over-relying on particular features. Weight decay, on the other hand, encourages a smoother and more evenly distributed weight structure by penalizing large weights, pushing the model toward simpler and more generalizable solutions (Andriushchenko et al., 2023; Zhang et al., 2018).\nBeyond direct parameter adjustments, empirical regularization techniques such as adding noise to input data or employing data augmentation have also proven effective for improving model generalization (Bishop, 1995). By exposing models to greater breadths of input patterns, these methods help improve their adaptability to diverse, real-world data. Despite existing evidence of their effectiveness, the underlying mechanisms of data augmentation remain an insufficiently studied area of research. Recently, synthetic data generated by models such as stable diffusion (Rombach et al., 2022) and large language models (LLMs) (Brown, 2020), has emerged as a promising, new approach to boost model performance(Sahu et al., 2023; He et al., 2022). Synthetic data not only augments existing datasets but also simulates rare events and edge cases (Santoso et al., 2017)."}, {"title": "2 METHODS", "content": "Despite existing evidence of their effectiveness, the underlying mechanisms of data augmentation remain an insufficiently studied area of research. Recently, synthetic data generated by models such as stable diffusion (Rombach et al., 2022) and large language models (LLMs) (Brown, 2020), has emerged as a promising, new approach to boost model performance(Sahu et al., 2023; He et al., 2022). Synthetic data not only augments existing datasets but also simulates rare events and edge cases (Santoso et al., 2017).\n2.1 PRELIMINARY\nThis section introduces data diversity measurement and the basics of RMT, as well as the metrics that will be used in the subsequent analyses."}, {"title": "2.1.1 REGULARIZATION", "content": "Dropout. Dropout (Srivastava et al., 2014) helps minimize overfitting during training by randomly disabling neurons in fully connected layers based on a given probability $p$. This randomness is controlled by a Bernoulli distribution, where neurons are either kept or deactivated during each training iteration. However, during inference, all neurons are active. To ensure consistency between training and inference, the output is scaled by $1-p$ during training. Dropout has become almost a default method for training or fine-tuning deep neural networks. In this paper, we implement dropout operations on different layers in transformer-based models.\nWeight Decay. Weight decay (Krogh & Hertz, 1991; Ishii & Sato, 2018) is another commonly used regularization technique to prevent overfitting. It works by adding a small penalty, which is proportional to the size of weight parameters, to the loss function during training. This encourages the model to keep weights smaller. During training, the weights are updated not only based on the prediction error-induced losses but also on this penalty, which pushes the model to find simpler solutions.\nData Augmentation. Data augmentation (Rebuffi et al., 2021; Shorten & Khoshgoftaar, 2019) is a strategy to artificially expand the size and diversity of training datasets without requiring the acquisition of new data. This technique involves applying a range of transformations to existing samples, such as flipping, cropping, adjusting brightness, and adding noise. Mixup (Zhang, 2017) is a specific data augmentation technique that creates new training examples by linearly combining pairs of input data and their corresponding labels. By introducing these variations, data augmentation enables models to learn more robustly from a wider array of instances, improving generalization. This approach is particularly advantageous in domains related to image tasks."}, {"title": "2.1.2 DIVERSITY MEASURE", "content": "Vendi Score (Dan Friedman & Dieng, 2023) has been recently proposed for measuring diversity in ML data. This score quantifies data diversity based on the similarities between elements in a dataset, making it particularly useful for evaluating the effectiveness of data augmentation techniques and assessing the diversity of synthetic samples from generative models. The score is derived by using a set of samples along with a pairwise similarity function, which calculates a value that reflects the effective count of unique elements in the dataset. More specifically, given a positive semi-definite matrix $K \\in R^{n\\times n}$ representing similarity scores, the Vendi Score (VS) is defined as\n$VS(K) = exp(-trlog(\\frac{K}{n})) = exp(-\\sum_{i=1}^{n}\\lambda_ilog\\lambda_i)$", "latex": ["K \\in R^{n\\times n}", "VS(K) = exp(-trlog(\\frac{K}{n})) = exp(-\\sum_{i=1}^{n}\\lambda_ilog\\lambda_i)"]}, {"title": "2.1.3 RANDOM MATRIX THEORY", "content": "Consider a d-layer DNN with corresponding weight matrices $W_1, W_2,..., W_d$. For each weight matrix $W_i$ with shape N \u00d7 M, assume without loss of generality that N > M (otherwise, consider", "latex": ["W_1", "W_2", "...", "W_d", "W_i"]}, {"title": "2.2 ANALYSIS APPROACH", "content": "Since the heavy-tailed nature of pre-trained models, we cannot obtain direct conclusions if our evaluation is based on a single metric. Instead, we focus on the trend of how regularization and diverse data influence the weight spectrum by calculating the differences in multiple metrics before and after fine-tuning on specific downstream tasks to gain valuable insights. For example, the initialized $\\alpha$ in the classification layer is around 6 while its value after fine-tuning can still display a certain degree of heavy-tailed property (2-6 typically). The relative changes compared with the baseline (no regularization applied) tell us the direction and magnitude of the impact of a regularization method on the weight landscape.", "latex": ["\\alpha"]}, {"title": "3 EXPERIMENT", "content": "The metric $num\\_pl\\_spikes$ counts the number of eigenvalues that are larger than $\\lambda_{min}$.\nTable 1 describes how the changes in these metrics may reflect the changes in weight space and the corresponding characteristics of its spectrum. Our spectral analysis is implemented by a tool called WeightWatcher(Martin et al., 2021), which provides multiple scale and shape metrics.\n3.1 EXPERIMENT SETUP\nWe employ the state-of-the-art text-to-image model CLIP (Radford et al., 2021) given its powerful capability of performing image classification tasks and fine tune CLIP on CIFAR-10 and CIFAR-100 (Krizhevsky et al., 2009). During fine-tuning, we freeze the text encoder, thus only the weights in the image encoder and the last classification layers are updated. The pre-trained vision model we used is CLIP-VIT-B32. The setting of the following training hyperparameters \u2013 a learning rate of 1e-5, 5 epochs, and a batch size of 32 \u2013 are kept the same in all experiments. Model performance measures are evaluated on the real test images.\n3.2 IMPACT OF REGULARIZATION\nThe default CLIP-VIT-B32 model does not apply dropout in the image encoder. To investigate the impact of dropout on both hidden layers and output layers, we add dropout layers in both Multi-headAttention layers and feedforward layers within each transformer block, as well as in the final", "latex": ["num\\_pl\\_spikes", "\\lambda_{min}"]}, {"title": "3.3 IMPACT OF DATA DIVERSITY", "content": "To increase training data diversity, we implement ten types of data augmentation: First, four automatic image augmentation techniques in PyTorch are applied: AutoAugment (Cubuk et al., 2018), RandAugment (Cubuk et al., 2020), AugMix (Hendrycks et al., 2019), and TrivialAugment(M\u00fcller & Hutter, 2021). Then we add Gaussian noise into the original images with a ratio of 0.1, 0.3, and 0.5. Finally, we created three advanced augmented datasets by combining AutoAugment with other data augmentation methods. They are auto-v1: AutoAugment + Gaussian noise with 0.5 ratio;"}, {"title": "3.4 DIVERSITY OF SYNTHETIC DATA", "content": "To investigate whether or not synthetic data can bring in more input data diversity and thus further enhance model performance in the transfer learning context, we utilize the state-of-the-art image generative model Stable Diffusion v1-5 (SD) (Rombach et al., 2022) to generate synthetic images. We use Domainnet (Peng et al., 2019) datasets to evaluate the CLIP model performance on both in-distribution (ID) and out-of-distribution (OOD) tasks. Specifically, for ID tasks, we use 50000 instances from the \"real\" category (i.e., they are real images, as opposed to artificially stylized images), which covers 142 image labels. The baseline model is trained on these instances and evaluated on \u201creal\u201d test images. Data augmentation techniques mentioned in section 3.3 are applied to the \"real\" training data for model training as a comparison. For OOD tasks, we evaluate trained models on stylized images, including \"clippart\", \"infograph\", \"inpainting\" and \"sketch\" styles in DomainNet. All model parameters remain the same as those in previous sections.\nTo improve the diversity of SD-generated images, we increase the variance of prompts for the stable diffusion model. We provide four prompt formats that are randomly picked for individual image-generating processes. Moreover, we dynamically adjust the generated images by randomly selecting and applying compressed resolutions within the ranges of 320-640 pixels for the first dimension and 240-720 pixels for the second dimension.\nWe use Top-1 accuracy and Expected Calibration Error (ECE) as evaluation metrics for both ID and OOD tasks. ECE is widely used for model uncertainty evaluation. It quantifies how well a model's predicted probabilities (confidence) align with its actual outcomes (accuracy) (Guo et al., 2017). The smaller ECE is, the better the model is calibrated. Synthetic training datasets are created by replacing a certain proportion (15%, 25%, and 35%) of real images with SD-generated images, thereby the total training data size is kept the same as the baseline and other data augmentation methods."}, {"title": "5 DISCUSSION", "content": "Model generalizability is an open challenge for deploying machine learning and deep learning models, as it directly impacts their adaptability and reliability in real-world applications. Regularization techniques, such as dropout and weight decay, are typically used to reduce overfitting and improve model robustness. Data augmentation, an empirical method that increases the diversity of training data, particularly in situations where training data is scarce, could achieve similar effects. However, the underlying mechanisms of how and why data augmentation enhances model performance remain an open question in theory and practice. With advancements in generative AI, the concept of data diversity has received significant attention with respect to both training data and model outputs. Diverse training data enables large pre-trained models to learn a wide range of meaningful features without overfitting to noise, while ensuring diversity in generated outputs is crucial for their use as effective training data in downstream tasks. This motivates our investigation into the role of data diversity in the learning process of a model. Specifically, we aim to understand how data diversity influences the weight landscape and provide insights into why data augmentation can lead to more robust models. To achieve this, we used Random Matrix Theory (RMT) to analyze spectral patterns in the weight matrices of neural networks, comparing the effects of dropout, weight decay, and various data augmentation techniques. Additionally, we quantified the diversity of training sets using the Vendi score, which measures data variability and helps assess how training diversity contributes to model generalization in our framework.\nWe observed that dropout and data augmentation exhibit similarities in how they affect the weight space of neural networks. Both methods reduce the overall magnitude of the weight matrix and induce similar changes in the spectral metrics of the empirical spectral density (ESD) on the same dataset. This suggests that they influence weight formation in a comparable way: dropout forces the model to be less reliant on specific weight correlations, resulting in a less concentrated ESD, while the rich features in a diverse dataset encourage the model to focus on a broader range of information during training, leading to a more balanced weight landscape. In contrast, weight decay, another regularization method, also reduces the overall size of the weight matrix but impacts the shape of the ESD differently, leading to distinct regularization effects.\nWe also explored the use of synthetic data generated by generative models as an augmentation strategy to improve model performance. While previous studies have not thoroughly examined its effectiveness, we compared this new approach with traditional data augmentation in both in-distribution (ID) and out-of-distribution (OOD) tasks. Our results show that incorporating a small amount of synthetic data enhances average model performance on both ID and OOD tasks, primarily due to the increased diversity provided by the synthetic data. However, there is also a risk of model collapse when relying too heavily on synthetic data, which occurs when the model starts overfitting to synthetic patterns that lack the variability and quality of real-world data. This over-reliance can reduce generalizability, cause biased learning, and diminish the model's ability to recognize a broad range of real-world features, ultimately making the model less robust and effective in practical applications. Therefore, a careful balance between real and synthetic data is still necessary to prevent model collapse and prevent overfitting."}]}