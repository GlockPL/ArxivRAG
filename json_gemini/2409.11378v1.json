{"title": "Diversify and Conquer: Diversity-Centric Data Selection with Iterative Refinement", "authors": ["Simon Yu", "Liangyu Chen", "Sara Ahmadian", "Marzieh Fadaee"], "abstract": "Finetuning large language models on instruction data is an important step in enriching the knowledge learned during pre-training and improving instruction-following capabilities. As the number of instruction datasets continues to grow, selecting the right data to achieve optimal results becomes increasingly important. In this work, we ask a prominent question: How can we determine the optimal subset of data for effective training? While much of the existing research primarily emphasizes local criteria, such as instance quality, for subset selection, we argue that a global approach focused on data diversity is more critical. Our approach utilizes k-means clustering to ensure that the selected subset effectively represents the full dataset. We propose an iterative refinement method inspired by active learning techniques to resample instances from clusters, with the importance and sampling weight of each cluster being reassessed in every training iteration. This method allows us to reduce the effect of outliers and automatically filter out clusters containing low-quality data. Through extensive evaluation across natural language reasoning, general world knowledge, code and math reasoning tasks, and by fine-tuning models from various families, we observe consistent improvements, achieving a 7% increase over the random selection and a 3.8% improvement over state-of-the-art sampling methods. Our work highlights the significance of diversity-first sampling when finetuning LLMs to enhance performance across a broad array of evaluation tasks.", "sections": [{"title": "Introduction", "content": "Large language models are trained on vast amounts of data scraped from the internet, containing a wide range of content qualities. Models develop a broad understanding of language and acquire general knowledge from the unstructured data in this pretraining phase and align with user intent in the finetuned stage using instruction datasets which consists of a more structured format of question and response pairs. Recent years have seen substantial efforts to create datasets using various manual and synthetic methods, making it increasingly challenging to determine which dataset is best suited for downstream tasks. A crucial question regarding the scalability of finetuning LLMs is: \"what is the optimum subset of data that allows for efficient training and captures aspects of the data relevant to downstream tasks?\u201d\nInstances in a dataset contribute to a model's learning process with varying degrees of impact, affecting the model's performance and generalization . While recent research has predominantly emphasized local features, such as the quality of individual instances for subset selection, we argue that prioritizing a global feature \u2014diversity\u2014yields greater benefits. When selecting a subset of instances, we manage computational complexity while balancing the trade-off between diversity and representativeness , ensuring that the subset captures the underlying data distribution . Preserving a high level of sample diversity during finetuning is crucial for improving generalization capabilities . revealed that using a range of instruction datasets can boost downstream tasks.  provided a theoretical analysis using determinantal point processes to underscore the significance of diversity in the selection of subsets. However, ensuring diversity during sampling is difficult, and current methodologies fall short of fully addressing this challenge. Most scoring-based subset selection methods prioritize sample quality and characteristics and subsequently apply a diversity filter. Still, since diversity is inherently a global property, addressing it only in the second step limits its effectiveness because it lacks a comprehensive view of the entire collection. This limitation often arises because assessing the data collection globally is computationally expensive.\nIn this work, we propose a scalable iterative sampling and refinement method to efficiently select a subset of instruction data and maximize the diversity of samples. We iteratively refine the sample selection using early training signals from the fine-tuning model and proceed with continued fine-tuning. With the same training budget, we achieve substantial improvements over fixed sampling approaches and previous state-of-the-art data selection methods. We evaluate the finetuned models on a wide range of tasks, including question answering, math, reasoning, and code, and show consistent improvements over baselines. Overall, our experiments and analyses demonstrate that by sampling a small subset of data, we achieve performance improvements of up to 7% over random selection and 3.8% over the previous sampling methods on a wide variety of tasks. In summary, our contributions are as follows:\n\u2022 We systematically analyze various clustering and sampling methods and demonstrate that k- means clustering is particularly effective for selecting an optimal, diverse subset of instruction data, especially when paired with a quality sampling step.\n\u2022 Our simplest variant, which involves efficiently clustering data points and randomly sampling from each cluster, already achieves performance on par with advanced state-of-the-art sampling techniques, without the need for costly LLM scoring. This supports our hypothesis on the importance of diversity and the representativeness of the sampling process.\n\u2022 We further propose an iterative clustering algorithm that simultaneously combines the learning feedback from the training model and optimizes for diversity based on data distri- bution for effective instruction tuning. This method outperforms previous approaches on all downstream tasks."}, {"title": "Methodology", "content": "Given a large and diverse set of instruct data $D = \\{x_1,x_2,...,x_n\\}$, we select a subset $D'$ with budget $b \\in N^+$, where $b = |D'| < |D|$ and finetune a language model and evaluate a selection of downstream tasks. This subset should be a representative sample of the training data, maintaining high quality and offering a diverse range of examples. We propose to define the problem of sample selection for training data of a language model as a clustering problem with clustering objectives where we want to group similar samples together and separate dissimilar samples into different clusters. We explore various sampling methods to ensure the inclusion of optimal samples from different clusters.\nFor clustering purposes, we consider two main clustering objectives: k-center and k-means. Both of these two objectives are metric clustering where we are given a set of points $D$ with distance metric $d : D \\times D \\rightarrow R_{>0}$ and the goal is to pick a set of centers $C = \\{C_1, . . ., C_k\\} \\subseteq D$ of size at most $k$. For k-center, we want to pick $C$ such that the maximum distance of data points to centers is minimized. More precisely, in k-center, we want to minimize"}, {"title": "Static Data Selection", "content": ""}, {"title": "", "content": "$\\max_{x_i\\in D} d(x_i, C)$"}, {"title": "", "content": "where $d(x_i, C) = \\min_{c_j\\in c}d(x_i, c_j)$ is the distance of point i to the closest center in C. The k-means objective is similar to k-center objective but instead of looking at the $l_{\\infty}$ norm of the vector that defines the distance of points to C, we look at the $l_2$ norm of this vector. More precisely, in k-means, we want to minimize"}, {"title": "", "content": "$\\Sigma_{x_i \\in D} d^2(x_i, C)$"}, {"title": "", "content": "Based on this objective and given the set of centers $C = C_1,..., C_k$, we define $D_j$ as the subset of data points in $D$ that are closest to center $c_j$ and belong to the jth cluster:"}, {"title": "", "content": "$D_j = \\{x_i \\in D | d(x_i, c_j) \\leq d(x_i, c_l) for all l \\neq j,l = 1,...,k\\}$"}, {"title": "", "content": "where $d(x_i, c_j)$ is the distance between data point $x_i$ and center $c_j$.\nBeyond the clustering, the next step concerns how to sample data from the clusters with a fixed budget of m. We investigate both random sampling and a more informed, quality-based sampling approach. For the quality-based sampling, inspired by the previous approaches , we propose k-means-quality (kMQ), where we first perform the traditional k-means by clustering the instruction data into k centroids, in which $k \\ll b$, and sample data from each cluster to form D'. Note that we assign each cluster a budget proportional to its size $(b_j = \\frac{b}{\\vert D\\vert})$ and draw samples within each cluster based on the probability weighted by the quality score. We use the same scoring method introduced by  to obtain quality scores, enabling a fair comparison of the hypotheses regarding the importance of diversity-first versus quality-first sampling. More concretely, we sample:"}, {"title": "", "content": "$\\mathbb{Z}_{>0}$"}, {"title": "", "content": "$\\frac{\\vert D\\vert}{\\vert D_j\\vert}$"}, {"title": "", "content": "$\\frac{\\vert D_j\\vert}{\\vert D\\vert}$"}, {"title": "", "content": "$\\frac{\\vert D\\vert}{\\vert D_j\\vert}$"}, {"title": "", "content": "$\\frac{b_j}{b}$"}, {"title": "", "content": "$\\frac{\\vert D_j\\vert}{\\vert D\\vert}$"}, {"title": "", "content": "$\\frac{b}{\\vert D\\vert}$"}, {"title": "", "content": "$\\frac{\\vert D\\vert}{\\vert D_j\\vert}$"}, {"title": "Iterative Data Selection", "content": "In the previous section, we introduced a two-step approach: sampling a fixed subset of data first and finetuning a model on it. The sampling and finetuning steps are performed independently without any information exchange between the two steps. However, the initial stages of finetuning can offer insights into how individual data points influence the learning process. Here, we investigate whether we can improve our sampling method by"}, {"title": "", "content": ""}, {"title": "", "content": "$\\underset{k}{\\operatorname{argmax}}\\{\\sum_{x_\\in D}{d(x,k)}\\}"}, {"title": "Experiments", "content": "We focus on two large and widely used instruction datasets that include prompts on a diverse set of topics: Alpaca  and WizardLM . The Alpaca dataset includes 52K prompts and uses the self-instruct framework to evolve seed human instruction datasets and generate a large collection. WizardLM includes 196K prompts where they used Evol-Instruct to automatically augment instruction tuning datasets (Alpaca, ShareGPT) to make their instructions more complex (in-depth evolution) and more diverse (in-breadth evolution).\nWe use Cohere English em- bedding (embed-english-v3.0) to embed the instruc- tion datasets. Note that we encode both the prompts and completions. To study the impact of the embed- ding model, in Section 4.3 we experiment with other models to encode instances in our training pool, namely OpenAI embedding (text-embedding-3-large) and Llama-2-7B model (using the last hidden state of the last token).\nFor all experiments, we finetune the llama-2-7B base model . We train for 3 epochs to achieve convergence and optimal instruction-following performance. We use an AdamW optimizer , with a learning rate of le-5 and 1,000 warming-up steps. The maximum token size is 2048, and the effective batch"}, {"title": "Training setup", "content": ""}, {"title": "Source Datasets", "content": ""}, {"title": "Encoding data points", "content": ""}, {"title": "Training Recipes", "content": ""}, {"title": "Evaluation setup", "content": "To present a comprehensive overview of the performance of our method, we conduct a comprehensive evaluation of our approaches and the established baselines across a range of LLM benchmarks.\nWe use HellaSwag , and TruthfulQA . HellaSwag is a test of commonsense inference. TruthfulQA measures a model's propensity to reproduce falsehoods.\nWe evaluate on MMLU and ARC . MMLU consists of a range of multiple-choice academic questions. ARC is a set of grade-school science questions.\nWe use the extensively utilized HumanEval benchmark consisting of 164 coding problems to evaluate LLMs' code-writing capabilities at the function level by reporting the pass@10 metric.\nWe use GSM8k to evaluate the mathematical abilities of models; GSM8k contains 1319 grade school math test data. We adopt 8-shot testing and report the exact matching."}, {"title": "Natural Language Reasoning", "content": ""}, {"title": "World Knowledge", "content": ""}, {"title": "Code Generation", "content": ""}, {"title": "Math Reasoning", "content": ""}, {"title": "Baselines", "content": "We implement two strong data selection methods, Deita and QDIT and compare our methods against them. Additionally, we explore other clustering and sampling methods: k-center clustering (k-Center), where k equals the number of data points, k-means-closest (kM-Closest), which selects samples based on the closest distance, and k-means- random (kM-Random), which selects randomly from each cluster, both with the same budget as our proposed approach kMQ. We also compare our methods to the random selection of data points."}, {"title": "Results and Discussion", "content": "Table 2 presents the performance of the proposed methods for instruction data selection compared to several baselines across various tasks. Our first observation is that by clustering data points using the k-means method and randomly sampling instances (kM-Random sampling) we already outperform random sampling and achieve comparable results to strong baselines: Deita and QDIT. This is significant because this sampling method is significantly more efficient than both Deita and QDIT and does not depend on costly LLMs for scoring. The success of this simple and efficient method highlights the impact of prioritizing diversity in sampling.\nNext, we observe that by replacing the random selection step with the quality-based approach (kMQ) we can improve model performance on all downstream tasks. kMQ outperforms strong sampling approaches, Deita  and QDIT , on all tasks. Next, we observe that the iterative sampling approach (Iterative kMQ), which leverages early training signals to refine the selected subset, outperforms all previous baselines on most tasks. This suggests that the iterative process of resampling and finetuning based on cluster performance can effectively identify and prioritize high-quality instruction data, leading to better task performance.\nOverall, our findings highlight the impact of a diversity-focused sampling approach, which selects a compact yet representative subset of the data through clustering and weighted sampling from the clusters. We find that it is also crucial to consider a feedback loop from the finetuning model and understand how it perceives and learns from the data. By incorporating this feedback we ensure that the sampling process aligns with the model's learning behavior for optimal results."}, {"title": "Main Findings", "content": ""}, {"title": "Comparing different scoring methods in iterative feedback", "content": "To study the impact of how we score samples during training in our iterative selection approach, we compare three methods: calculating the perplexity score of generations, using GPT-4 to obtain a quality score, and using a reward model's\u00b9 output. In Figure 2 we observe that all three variants effectively improve the average performance over random selection. It is important to note that during the first and second iterations, the iterative methods have been exposed to fewer data points compared to the random and kMQ baselines. It is only at the third iteration that all methods have had the opportunity to process an equal amount of data. While both perplexity-based and GPT-4-based scoring achieve similar performance to kMQ and improve over random sampling, the reward model variant largely outperforms a single-run kMQ. For this experiment, we arbitrarily selected an iteration value of 3, which can be modified in future experiments."}, {"title": "Impact of Number of Clusters", "content": "In k-means data selection, an important question is how to choose the appropriate value for the parameter k (the number of clusters). Increasing the value of k results in more fine-grained clusters and by ensuring that we sample from each cluster, we can increase the diversity of the selected subset. However, overly large values of k would also inevitably create outlier clusters that consist entirely of low-quality, noisy data. Since we ensure each cluster is represented in the final selection, this results in noise being included. There is no one-size-fits-all answer, as the optimal k depends on the characteristics of the pool of data. Exploring the optimal parameter value is costly, as it must be conducted with each new dataset. Here we use established heuristics in the clustering literature to guide this decision and study the correlation of these metrics with downstream performance of"}, {"title": "Comparing scoring different methods in iterative feedback", "content": ""}, {"title": "Iterative Data Selection", "content": ""}, {"title": "", "content": "$\\frac{\\vert D\\vert}{\\vert D_j\\vert}$"}, {"title": "", "content": "$\\frac{\\vert D_j\\vert}{\\vert D\\vert}$"}, {"title": "", "content": "$\\frac{b_j}{b}$"}, {"title": "", "content": "$\\frac{\\vert D_j\\vert}{\\vert D\\vert}$"}, {"title": "", "content": "$\\frac{b}{\\vert D\\vert}$"}, {"title": "", "content": "$\\frac{\\vert D\\vert}{\\vert D_j\\vert}$"}, {"title": "Analysing Cluster Quality", "content": "In our approaches, we rely on k-means clustering to ensure high diversity, but there is a risk that some clusters may consist solely of noise. To understand how this varies with different values of k, we use a reward model to evaluate the quality of each cluster with a score between 0 and 1."}, {"title": "Experiment", "content": ""}, {"title": "Transferability of Results", "content": "We conduct experiments with two additional base models, Mistral-7B and Llama-3 8B , to assess whether our findings generalize to other model families and more powerful models. Our results in Table 3 demonstrate that the effectiveness of iterative refinement remains valid for the Mistral-7B model, which exhibits more robust performance. However, the evaluation results for Llama-3 are mixed across different benchmarks. We observe improvements on average with kMQ sampling and a slight decrease in performance with iterative sampling especially in reasoning tasks. We hypothesize that Llama-2 differs from Mistral in its training data, model parameters, and training strategies. Consequently, using Llama-2 as a scorer reveals novel data points from which Mistral can benefit. However, Llama-3, a more advanced model than its predecessors with extended training as one of the primary distinctions, uncovers fewer new, valuable data points for further learning. This highlights that the quality scorer's effectiveness can vary, sometimes proving more beneficial and other times less so, depending on the base model for which we are sampling.\nWhile the iterative refinement pipeline can select a dataset restricted to certain models, we do not view this as a limitation. The primary contribution of this work is to propose a function that takes a fixed dataset and model as input and outputs the most valuable subset for learning. This approach aligns with similar works . Specifically, the task is to extract a subset of data that leverages early reward signals to enhance the targeted model's post-training performance."}, {"title": "Related Work", "content": ""}, {"title": "Conclusion", "content": "In this paper, we present a novel approach to selecting a subset of data and optimizing the fine-tuning of language models. Our method involved a scalable sampling technique that maximizes diversity and efficiency in subset selection. Through our proposed k-means-quality (kMQ) algorithm and iterative selection process, we demonstrated significant performance improvements over strong baselines while maintaining a limited training budget. Our contributions include an efficient instruction selection algorithm, the release of our encoded instruction dataset, and a systematic analysis of our method's effectiveness across a range of tasks. Our method outperforms existing baselines, achieving up to 7%"}, {"title": "Limitations and Future Work", "content": "While our proposed method has shown promising results, there are a few limitations to consider. Our evaluation focused on a specific set of tasks, and future work can aim to validate our method's effectiveness across a broader range of language models and tasks, including data selection in the pre-training stage and alignment . Furthermore, our iterative selection process relies on early training signals, and we only presented this as a pilot study to encourage further research. Future work could explore alternative model feedback mechanisms to refine the selected instruction data subsets, especially in mitigating the potential for reward hacking in the iterative refinement process .\nFinally, while we considered diversity and difficulty crucial factors, other characteristics of instruction data could be explored to enhance the finetuning process further. Addressing these limitations and extending this research will contribute to more robust and adaptable language models, capable of excelling in a wide range of real-world applications."}, {"title": "Broader Impact", "content": "If the data selection process fails to capture important aspects of the full dataset, it could lead to biased or inconsistent outputs from the finetuned models. There are also broader societal risks around the misuse of large language models for generating misinformation, perpetuating biases, or enabling privacy violations that could be exacerbated by making these models more accessible through efficient finetuning techniques."}]}