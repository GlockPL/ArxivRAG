{"title": "LORE-MERGING: Exploring Low-Rank Estimation For Large Language Model Merging", "authors": ["Zehua Liu", "Han Wu", "Yuxuan Yao", "Ruifeng She", "Xiongwei Han", "Tao Zhong", "Mingxuan Yuan"], "abstract": "While most current approaches rely on further training techniques, such as fine-tuning or re-inforcement learning, to enhance model capacities, model merging stands out for its ability of improving models without requiring any additional training. In this paper, we propose a unified framework for model merging based on low-rank estimation of task vectors without the need for access to the base model, named LORE-MERGING. Our approach is motivated by the observation that task vectors from fine-tuned models frequently exhibit a limited number of dominant singular values, making low-rank estimations less prone to interference. We implement the method by formulating the merging problem as an optimization problem. Extensive empirical experiments demonstrate the effectiveness of our framework in mitigating interference and preserving task-specific information, thereby advancing the state-of-the-art performance in model merging techniques.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have become ubiquitous in numerous real-world applications (Bommasani et al., 2021; Zhuang et al., 2020). The utilization of LLMs typically involves fine-tuning them for specific tasks, a process that often yields superior performance compared to general-purpose LLMs. A rapidly emerging technique in this domain is model merging (Garipov et al., 2018; Wortsman et al., 2022; Yu et al., 2024b), which aims to create a single multi-task model by combining the weights of multiple task-specific models. This approach facilitates the construction of multi-task models by integrating knowledge from fine-tuned (FT) models without requiring additional training. Building on recent studies (Ilharco et al., 2022; Yadav et al., 2024; Yu et al., 2024b), task vector-based merging approaches have demonstrated significant effectiveness, where task vectors are defined as the parameter differences between fine-tuned models and the base LLM. Achieving optimal results in model merging often requires minimizing interference between task vectors associated with different tasks. To address this, existing approaches utilize modified task vectors instead of the original ones. For instance, Yu et al. (2024b) applied random dropping with probability p to obtain a sparse representation of task vectors, while Yadav et al. (2024) retained only the top-k elements of each task vector based on magnitude, setting the remaining elements to zero. These strategies aim to produce sparse estimations of task vectors, a common technique for mitigating interference.\nNevertheless, task vector-based model merging approaches remain constrained by two fundamental limitations. First, the computation of task vectors necessitates access to the base model parameters and demonstrates heightened sensitivity to parametric variations (Yu et al., 2024b). As fine-tuning progress goes deeper, substantial parametric divergence emerges between the original base model and its fine-tuned counterpart, thereby greatly hindering them merging effectiveness (Yu et al., 2024a). Second, empirical evidence from Yadav et al. (2024) reveals that conflicting task vectors interactions could appear even when employing sparse estimation techniques. On the other hand, the sparsification process risks inadvertently eliminating essential task-specific features, thereby compromising the efficacy of the resultant merged model. These inherent constraints of sparse approximation methodologies underscore the necessity for developing alternative frameworks to estimate higher-fidelity low-rank task vector representations.\nTo this end, we first empirically validate that task vectors exhibit a small number of dominant singular values, with the remaining singular values being significantly smaller in magnitude, as shown in Figure 1. Additionally, the dimension of the intersection of the images of two matrices is bounded by the minimum of their ranks. Therefore, we propose LORE-MERGING, a unified framework for model merging based on Low-Rank Estimation of task vectors, which eliminates the need for access to the base model. Specifically, given a set of FT models, we formulate the merging problem as an optimization problem whose goal is to simultaneously identify an approximate base model integrated with a set of low-rank task vectors that collectively approximate the behavior of the FT models. By leveraging low-rank estimations, task vectors become inherently less susceptible to interference, effectively addressing a fundamental challenge in model merging. We conduct extensive experiments on optimization modeling problems and math word problems to confirm the effectiveness of our method."}, {"title": "2 Related Works", "content": "Merging fine-tuned models has been shown to offer several benefits, such as improving performance on a single target task (Gupta et al., 2020; Choshen et al., 2022; Wortsman et al., 2022), enhancing out-of-domain generalization (Cha et al., 2021; Arpit et al., 2022; Ilharco et al., 2022; Ram\u00e9 et al., 2023), creating multi-task models from different tasks (Jin et al., 2022; Li et al., 2022; Yadav et al., 2024), supporting continual learning (Yadav and Bansal, 2022; Yadav et al., 2023), and addressing other challenges (Don-Yehiya et al., 2022; Li et al., 2022). Among these methods, task-vector-based merging approaches play an important role. Task Arithmetic (Ilharco et al., 2022) first introduced the concept of task vectors and shows that simple arithmetic operations can be performed to obtain the merged models. Building on this idea, methods like DARE (Yu et al., 2024b) and Ties (Yadav et al., 2024) adopt pruning-then-scaling techniques to merge task vectors, based on the assumption that not all parameters equally contribute to the final performance. However, these methods based on sparsity estimation consistently suffer from the interference among task vectors and require access to the base model, thus limiting their overall effectiveness."}, {"title": "3 Methodology", "content": "We denotes \\(M_i\\) as the candidate models to be merged, where each \\(M_i\\) is parameterized by \\(\\theta_i\\). In this work, we focus on the homogeneous model merging (Wortsman et al., 2022; Ilharco et al., 2022; Yadav et al., 2024), suggesting that the base models share the same model architecture. Specifically, these models can be obtained from the training process, such as checkpoints, or fine-tuned from the same pre-trained model, referred to as task-specific models. The primary objective of model merging is to construct a new model, \\(M^*\\), having better performance on the target single or multiple tasks."}, {"title": "3.1 Problem Setting", "content": "As demonstrated in Yu et al. (2024b,a), model pairs would exhibit limited mergeability, especially when comprehensive fine-tuning or extended pre-training procedures are employed and result in substantial parameter shifts. Under such conditions, existing task-vector based merging methods struggle to work due to the significant representational divergence between the base model and its fine-tuned derivative. To address this challenge, we propose an implicit low-rank estimation model merging method, named LORE-MERGING, which not only employs the robustness of low-rank estimation against the interference but also eliminates the need for access to the base model.\nThe core idea of LORE-MERGING is straightforward: instead of using the original base model,"}, {"title": "3.2 Implicit Low-Rank Estimation for Model Merging"}, {"title": "Algorithm 1 Implicit low-rank merging method", "content": "Input: fine-tuned models {\\(\\theta_i\\)}\\_{i=1}^n, parameter dimension d, and hyperparameter \u03bb, \u03bc.\nOutput: merged model \\(\\theta^*\\).\n\u25b7 Step 1: Coordinate descent method to solve problem (1).\nSet \\(\\delta_i\\) = 0 for i = 1, 2, ..., n.\nwhile iteration NOT converges do\n\\(\\theta_0\\) = - \\(\\frac{1}{n}\\) \\(\\sum_{i=1}^n (\\theta_i - \\delta_i)\\)\nfor i = 1,...,n do\n\\(\\delta_i\\) = SVT(\\(\\theta_i\\) \u2013 \\(\\theta_0\\); \u03bc);\nend for\nend while\n\u25b7 Step 2 (Optional 1): Direct sum.\n\u03c4 = \\(\\sum_{i=1}^n \\delta_i\\).\n\u25b7 Step 2 (Optional 2): TIES selection (Yadav et al., 2024).\n\u03b3 = sgn(\\(\\sum_{i=1}^n \\delta_i\\)).\nfor p = 1, 2, . . ., d do\n\\(A^p\\) = {i : \\(\\gamma = \\gamma^p\\)}\n\\(\\tau^p\\) = \\(\\frac{1}{|A^p|}\\) \\(\\sum_{i \\in A^p} \\delta_i^p\\)\nend for\n\u25b7 Step 3: Obtain merged checkpoint.\n\\(\\theta^*\\) = \\(\\theta_0\\) + \u03bb\u03c4.\nreturn \\(\\theta^*\\)\nOnce the optimization problem is solved, we can obtain the approximate base model and a set of low-rank task vectors. Then, existing task-vector based approaches, such as Average Merging and Ties-Merging, can be applied to combine the task vectors and the base model. In this work, we directly adopt Average Merging as our post-calculation merging methods for simplicity, as as it demonstrated comparable performance to Ties-Merging in our preliminary experiments. The overall process is outlined in Algorithm 1."}, {"title": "4 Experiments", "content": "We compare LORE-MERGING with following popular merging methods. Average Merging (Choshen et al., 2022): This method computes the element-wise mean of all the individual models. DARE (Yu et al., 2024b): This approach randomly drops task-specific vectors and rescales the remaining vectors back to the base model. We set the hyperparameter for the random probability to 0.5. Ties-Merging (Yadav et al., 2024): In this method, task-specific vectors are randomly dropped, and only the parameters aligned with the final agreed-upon sign are merged. For Ties-merging, we set the top-k value to 20%, and the hyperparameter A is fixed at 1. For LORE-MERGING, the rank r is determined dynamically. For a given task vector \\(\\delta \\in \\mathbb{R}^{m \\times n}\\), we set the rank r = 0.2 \u00d7 min{m, n} to get a low-rank estimation.\nWe first evaluate LORE-MERGING on math word problems using the popular benchmarks GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al.). For comprehensive evaluation, we test both DeepSeek-series models (NuminaMath-7B (Beeching et al., 2024) and DeepSeek-Math-7B-Base (Shao et al., 2024)) and LLaMA-series models (WizardLM-13B (Xu et al., 2023) and WizardMath-13B (Luo et al., 2023)). Additionally, we also evaluate the effectiveness of LORE-MERGING on another advanced task, i.e. mathematical optimization modeling problems (Ramamonjison et al., 2023; Huang et al., 2024, 2025). This task aims to generate solvable mathematical models given an optimization problem in natural language. As the lack of public models on this task, we first fine-tune Qwen-2.5-Coder-7B-Instruct model (Hui et al., 2024) with the datasets provided by Huang et al. (2025) and merge the checkpoints in the training process. The evaluations are conducted on MAMO dataset (Huang et al., 2024) which includes two subsets EasyLP and ComplexLP, and NL4OPT dataset (Ramamonjison et al., 2023).\nAs shown in Table 1, LORE-MERGING achieves superior performance across most metrics, as well as the highest overall score. For the math word problem evaluation, our method demonstrates consistently superior performance compared to the baselines, except for the evaluation on the MATH dataset when merging DeepSeek-Math with NuminaMath. due to the significant performance gap between the base models, where DeepSeek-Math achieves only a score of 36.2 on the MATH dataset, while NuminaMath reaches 55.8. As indicated in Yao et al. (2024), a large performance gap can significantly impact the effectiveness of model merging. Another worthy-noting observation is that DARE demonstrates significantly poorer performance when merging WizardLM and WizardMath. This can likely be attributed to the substantial parameter divergence between these models, which results in the failure of calculating the task vector derived from the base model. In contrast, our LORE-MERGING with the approximate base model and low-rank task vectors demonstrates superior robustness and effectiveness in solving math word problems. For the evaluations on optimization modeling with checkpoints merging, we can see existing task-vector based merging methods consistently improve the performance because of the marginal gap between the checkpoints. Therefore, we believe that checkpoint merging can serve as a highly effective technique complementary to training methods, particularly our LORE-MERGING method. We also conduct a detailed analysis how our method enhance the modeling capacity on ComplexLP dataset. We found that the earlier checkpoint is more good at identifying the variables and parameters in the questions while the later one focuses on more complex components, such as formulating variables and the constraints. With the merging of task vectors, the merged model exhibits superior overall performance on the task."}, {"title": "Baselines & Settings"}, {"title": "Evaluation"}, {"title": "Main Results"}, {"title": "5 Conclusion", "content": "In this paper, we propose a unified framework for merging homogeneous models based on low-rank estimation, named LORE-MERGING. The main motivation of our work is to estimate task vectors using low-rank approximation without the need of access to the base model. We achieve it by formulating the merging problem as an optimization problem. Extensive experiments demonstrate the efficacy and efficiency of our proposed methods."}, {"title": "Limitations", "content": "Although we have demonstrated the effectiveness of our method on merging homogeneous models, we have not yet evaluated it on merging heterogeneous models which is a much more challenging task. Compared to existing task-vector based model merging methods, our method is the most suitable one that can be adapted to heterogeneous model merging, as we disentangle the base model and task vectors. We think how to expand LORE-MERGING to heterogeneous model merging should be a promising future direction."}], "equations": ["\\min_{\\theta_0,\\delta_1,...,\\delta_n} f := \\sum_{i=1}^n (||\\theta_0 + \\delta_i \u2013 \\theta_i||_* + \\mu||\\delta_i||_*),", "{\\theta_i^{k+1} = \\arg \\min_{\\theta} f(\\theta, \\delta_1^k,...,\\delta_n^k)}\n{\\delta_i^{k+1} = \\arg \\min_{\\delta} f(...,\\delta_{i-1}^{k+1}, \\delta, \\delta_{i+1}^k,...), \\forall i}", "\\delta_i^{k+1} = SVT(\\theta_i \u2013 \\theta_0^{k+1}; \\mu)."]}