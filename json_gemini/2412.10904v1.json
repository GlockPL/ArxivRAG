{"title": "CEKER: A Generalizable LLM Framework for Literature Analysis with a Case Study in Unikernel Security", "authors": ["Alex Wollman", "John Hastings"], "abstract": "Literature reviews are a critical component of formulating and justifying new research, but are a manual and often time-consuming process. This research introduces a novel, generalizable approach to literature analysis called CEKER which uses a three-step process to streamline the collection of literature, the extraction of key insights, and the summarized analysis of key trends and gaps. Leveraging Large Language Models (LLMs), this methodology represents a significant shift from traditional manual literature reviews, offering a scalable, flexible, and repeatable approach that can be applied across diverse research domains.\n\nA case study on unikernel security illustrates CEKER'S ability to generate novel insights validated against previous manual methods. CEKER's analysis highlighted reduced attack surface as the most prominent theme. Key security gaps included the absence of Address Space Layout Randomization, missing debugging tools, and limited entropy generation, all of which represent important challenges to unikernel security. The study also revealed a reliance on hypervisors as a potential attack vector and emphasized the need for dynamic security adjustments to address real-time threats.", "sections": [{"title": "I. INTRODUCTION", "content": "As academic research rapidly expands in volume and scope across many fields of study [1], thorough and effi-cient systematic literature reviews have become increasingly important [2]. Literature reviews serve as the foundation for identifying primary themes, research gaps, and emerging trends, thereby informing future research and innovation. However, the traditional approach to literature reviews is quickly being replaced by more modern approaches in order to reduce manual, time-consuming efforts which are prone to inconsistencies in the selection, analysis and synthesis of information from large bodies of academic papers [3]-[7].\n\nThis research addresses these challenges by introducing a novel, generalizable approach to literature analysis. The method is designed to be efficient, flexible, and applica-ble across any literature-backed research domain. Unlike conventional methods that require manual collection and review of literature, this approach supports both the reuse of existing literature collections and the generation of new collections using either traditional or AI-based search strate-gies. By utilizing large language models (LLMs) to extract key features, analyze trends, and identify research gaps, this approach streamlines the literature review process while also maintaining rigor and reproducibility.\n\nThis approach, named CEKER (pronounced seeker), is a three-step literature review approach that can be generally applied to any research domain as follows:\n\n1) Collect corpus: Reuse a previously collected corpus of literature if available or collect new literature using traditional search methods or AI tools.\n2) Extract Key features: Using an LLM, analyze each paper individually to extract themes related to the topic of interest. Collate these results.\n3) Analyze and Evaluate Results: Using an LLM, analyze the results from Step 2 to produce a summary analysis which provides insights into trends, correlations, and gaps, which can be used to guide future research.\n\nTo demonstrate the applicability of CEKER, the research applies this method to the domain of unikernel security, a niche but important field within operating system re-search. The results not only demonstrate the general utility of CEKER, but also provide a comprehensive analysis of unikernel-related literature, identifying key security trends, research gaps, and areas for future exploration. We compare these findings against those from a previous study of uniker-nel security [8] to highlight new insights that emerge from the refined analysis process.\n\nThe remainder of this paper is organized as follows: Section II details the general steps in CEKER. Section III applies CEKER to unikernel security, demonstrating its utility through a case study. Section IV discusses the broader"}, {"title": "II. GENERAL APPROACH: CEKER", "content": "The CEKER approach presented in this paper is formulated to provide researchers with a systematic, repeatable, and efficient method for corpus-based literature analysis. CEKER can be flexibly applied across a wide range of research do-mains, from cybersecurity and computer science to healthcare and social sciences. At its heart, CEKER leverages LLM analysis, and supports the selection of any modern LLM. Each step in the approach is described in detail below.\n\nA. Step 1: Collect corpus\n\nThe first step in the approach is to establish a clear, well-defined corpus of relevant literature for subsequent analysis. This step is intentionally flexible to support two possible scenarios:\n\n1) Reuse an existing corpus: In some research contexts, a previously constructed set of literature may already exist. Reusing such a collection saves time and effort while ensuring consistency. Researchers may select prior literature from past systematic reviews, prior research studies, or internal datasets.\n2) Collect new literature: If no suitable corpus exists, researchers can collect a new set. This can be done using traditional academic search engines or modern AI-based tools that support intelligent search and fil-tering. Search queries can be tailored to necessarily limit results to relevant materials. For example, speak-ing hypothetically, an LLM could be broadly asked, \"Provide 25 highly cited research articles that link blue orangutans to urban development.\" The results would then be checked for accuracy and added to the corpus for further evaluation. It is possible for an LLM to generate non-existent papers (i.e., LLM text generation may creatively constructs \"new\" papers), and this tendency may increase as more papers are requested. Before adding any papers to the corpus, they should be vetted for availability and relevance. This process can repeat until the corpus reaches a point of diminishing returns (i.e., very few new papers are being found) or the size of the corpus is sufficiently large.\n\nNote that these two approaches are not mutually exclusive and can be combined as needed (i.e., an existing corpus might be augmented by AI search results). Members of this set might be further vetted (by manual inspection or AI screening) to further refine the results.\n\nB. Step 2: Extract key features\n\nThe next step extracts critical insights from the collected literature using LLMs. LLMs offer significant advantages over traditional keyword-based approaches, as they can understand context (on a grander scale), identify implicit themes, and generate qualitative insights.\n1) Prompt design: To effectively extract relevant features, identify key themes, and highlight knowledge gaps, carefully designed prompts guide the LLMs. For ex-ample, prompts may include:\n\n\u2022 \"Identify and summarize key points discussed in this paper.\"\n\nThe prompts can be adjusted based on the themes of interest. Further, prompts can be included to check for hallucinations.\n2) Extraction of features and trends: LLMs process each paper in the corpus, extracting important features, research methods, findings, and areas requiring further exploration.\n\nResults are aggregated from this process for analysis in the next step. Papers that don't sufficiently align with the research topic can be filtered out.\n\nC. Step 3: Analyze and evaluate results\n\nThe final step of the approach uses the LLM to analyze and evaluate the extracted data. Through careful prompting, the LLM can produce a variety of analyses. For example, the following prompt might be used to uncover trends:\n\n\u2022 \"List the most frequently discussed trends in this liter-ature.\"\n\nAdditional analysis by the LLM might include the following:\n1) Thematic analysis: LLMs categorize extracted insights into themes and topics, identifying patterns, relation-ships, and outliers.\n2) Gap analysis: LLMs identify knowledge gaps by pinpointing underrepresented themes and areas with limited research coverage. This allows researchers to suggest directions for future studies.\n3) Visualization and reporting: Depending on LLM ca-pabilities, data visualizations, such as bar charts, heat maps, or word clouds, might be created to visually represent trends in the literature.\n4) Comparison to prior research: If applicable, the re-sults from this process can be compared against prior studies to highlight new findings or confirm previously established insights.\n\nPrompts should be adjusted to give the results desired. Invalid results might suggest prompts that need to be adjusted, so prelimiary results from new prompts should be quality checked.\n\nCollectively, the three steps in CEKER present a thorough overview of trends, gaps, and emerging themes within a given research domain. This general approach not only aims to enhance the rigor of systematic reviews but can also accelerate the process of identifying key areas for future research."}, {"title": "III. CASE STUDY: APPLICATION TO UNIKERNEL SECURITY", "content": "By following the systematic three-step methodology in CEKER, we demonstrate how the general approach is applied to the specific domain of unikernel security. This case study not only validates the effectiveness of CEKER but also highlights its ability to generate new actionable insights into security features, trends, and knowledge gaps within unikernel research. ChatGPT-40 [9] was selected as the LLM for this case study, but another modern LLM could be chosen. The focus of this research is not in \u201cproving\u201d which LLM is \"superior\" for the CEKER approach, but rather that CEKER can be capably applied.\n\nA. Unikernels\n\nUnikernels are an evolution of an old idea: Library Oper-ating Systems (LibOS). The principle idea behind LibOSs is that OS functionality is implemented in the form of libraries, customized to increase performance of the application by providing closer access to hardware [10]. Utilization of libraries, in addition to a unified address space, enables replacing syscalls and context switches with simpler function calls as well [10]-[12]. To help achieve the reduced size, many familiar security features have also been removed including Address Space Layout Randomization (ASLR), Non-executable Bits (NX bits), and stack canaries [11], [13], [14]. Adhering to the reductionist principle adopted by unikernels, these features, in addition to others, have been removed to save space, simplify the code base, and eliminate extra, unnecessary features [11], [13], [14].\n\nThe topic of unikernel security was selected for multiple reasons. Existing research [8], [13], [14] indicates that there are potential security challenges facing unikernels, possibly due to removing security features, so it represents a research area where contributions could prove valuable. Except for one paper [8], researchers were unable to identify other papers that conducted a literature review focused on unikernel security. Furthermore, an existing unikernel study [8] has provided initial quantitative results with which to compare CEKER's results. Thus this domain offers an opportunity for CEKER to provide valuable insights.\n\nB. Step 1: Collect corpus\n\nThe first step of CEKER collects a corpus of literature for analysis in the later stages. For the topic of unikernel"}, {"title": "C. Step 2: Extract Key Features", "content": "The second step of CEKER extracts key features from each paper. As discussed in III-A, a need exists to better understand the state of unikernel security research. Previous research was able to generate quantitative values for specific security terms, however the breadth of security"}, {"title": "D. Step 3: Analyze and Evaluate Results", "content": "The third step of CEKER uses the LLM to analyze and evaluate the extracted data to produce summary insights. Each of the six documents from Step 2 were uploaded to new ChatGPT sessions. Separate sessions were employed to avoid cross-contamination of contexts and results. The only prompt which did not receive follow-on analysis was P-5.\n\nAfter the analysis was completed, the following results were observed.\n\n1) Themes: Within this corpus six themes were identified. Of the six, the three themes in bold were further identified as the most significant; appearing in nearly every paper. Reduced attack surface was singled out further and identified as the most common feature. Minimalism and a single address space were frequently cited as elements contributing to the reduced attack surface theme. It also frequently scored close to, or at, 1.00 on relevance scores. The themes sometimes shared overlapping reasons for their ranking. While single address space was attributed to reduced attack surface, it was also attributed to isolation mechanisms and customization. Similarly, minimalism was a"}, {"title": "2) Gaps", "content": "There were several identified gaps in the corpus. The biggest gap was Missing Traditional OS Features. Dynamic Security Adjustments were further identified as the least common security feature in the cor-pus. This feature would enable on-the-fly regeneration of unikernels and enable unikernels to adapt to real-time threats. ASLR was also frequently discussed as a gap, however there were differing ideas as-to its significance. Many of the re-search papers focused on ASLR as a solution, however some implementations prefer a dynamic form such as function-based ASLR to by-pass the limitations imposed by the single address space. Entropy generation was another discussed gap, attributed to limited entropy sources and resource limited environments.\n\nThree security features were specified in the prompts: ASLR, DEP, stack canaries. ASLR was the most common term discussed in the corpus, as discussed above. The spe-cific term DEP did not appear frequently but was generally associated with the idea of privilege separation, which was prevalent in the corpus. Of the three, stack canaries appeared least frequently and was often disregarded as a security feature. The reasons for this often came back to compile-time guarantees and the focus on unikernel simplicity."}, {"title": "3) Comparisons", "content": "The calculation for number of mentions was based on direct mentions, contextual significance, and ap-pearance across papers. Comparing these results to previous research the findings are similar, with HermiTux included in CEKER's top 5 instead of Graphene-SGX or Ling [8]."}, {"title": "IV. DISCUSSION", "content": "Because of the flexibility of CEKER, applying it to uniker-nel security research was simple and intuitive. Ensuring the prompts for Step 2 returned accurate information required some consideration and experimentation, but not overly bur-densome. Generating two sets of prompts for Step 3 resulted in more impactful data than expected. GP-1 generated very thorough summaries comprised of three to four lists consist-ing of six to seven elements all containing multiple sentence descriptions. Human analysis of the results, combined with GP-2 data, generated a concise and accurate portrait of the corpus. Based on the researchers' subject expertise, reviewing the results did not reveal hallucinations nor false or inaccurate information.\n\nThe biggest strength of CEKER is demonstrated through its theme and gap generation. LLMs can process vast amounts of data and generate detailed summaries such that the human counterpart would require weeks and multiple readings of papers to achieve, and only achieve the theme. Gap identifi-cation, if not explicitly identified in research, is an extremely challenging component. LLMs once again can process the data and provide, at minimum, missing information it identi-fied. In this case study it identified traditional OS features as a gap in unikernel security research. This is indeed a specifically noted gap in many research papers, but also alluded to through discussion of omitted security features (e.g., ASLR, memory protections).\n\nNoted limitations in [8] were the inability to account for all possible variations of a security feature's name and account for variations in context of a security feature within a paper. The CEKER process enabled prompt generation to account for variations in names in a simple fashion (P-1 in Table II for example). A programmatic approach could not exhaustively account for all possibilities, and a manual approach would be infeasible given a large enough corpus, or a varied enough set of search elements.\n\nA notable finding in this case study was the two research efforts ChatGPT offered: cloud native orchestration tools and a container-unikernel hybrid. There are research papers in the corpus which discuss cloud integrations of unikernels [15]-[18], and also papers which compare and contrast differ-ent virtualization technologies [19], [20]. This demonstrates how CEKER can not only be used in analysis, but also the generation of research ideas from the corpus. CEKER can begin anew with this seed idea and re-evaluate at each step of CEKER as necessary."}, {"title": "V. FUTURE WORK", "content": "In this research the only LLM utilized was ChatGPT-40. Other LLMs have different strengths which can be utilized to generate different results. For example Google's Gemini has a larger context window, which could perhaps enable it to understand data in a larger document. This would be beneficial to provide the LLM with one single document containing all the research papers instead of uploading individual ones. Gemini's ability in this area remains to be tested.\n\nMany LLMs also provide API access, which enables programmatic solutions and further decreases the time needed for CEKER. While CEKER is able to utilize API access, this research relied on direct interaction with the ChatGPT website in order to demonstrate proof of concept. Automation would also simplify utilizing additional LLMs (after the initial programming effort) as prompts could be submitted simultaneously, or directed by user interactions."}, {"title": "VI. CONCLUSION", "content": "Utilizing LLMs to supplement, or replace, time-consuming steps in the literature analysis process, this research intro-duced a novel three-step approach called CEKER: Collect corpus, Extract Key features, Analyze and Evaluate Results. CEKER can be conveniently applied to any research domain due to its flexible and general approach utilizing LLMs.\n\nA case study on unikernel security illustrates CEKER's ability to generate novel insights validated against previous manual methods. CEKER's analysis highlighted reduced at-tack surface as the most prominent unikernel security theme. Key security gaps included the absence of ASLR, missing debugging tools, and limited entropy generation, all of which represent important challenges to unikernel security. The study also revealed a reliance on hypervisors as a potential attack vector and emphasized the need for dynamic security adjustments to address real-time threats. As seen through its application in the case study, CEKER's rapid, repeatable process is capable of uncovering research avenues, thereby supporting a continuous research process."}]}