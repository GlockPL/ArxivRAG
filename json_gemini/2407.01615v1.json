{"title": "Edge-DIRECT: A Deep Reinforcement Learning-based Method for Solving Heterogeneous Electric Vehicle Routing Problem with Time Window Constraints", "authors": ["Arash Mozhdehi", "Mahdi Mohammadizadeh", "Xin Wang"], "abstract": "In response to carbon-neutral policies in developed countries, electric vehicles route optimization has gained importance for logistics companies. With the increasing focus on customer expectations and the shift towards more customer-oriented business mod-els, the integration of delivery time-windows has become essential in logistics operations. Recognizing the critical nature of these developments, this article studies the hetero-geneous electric vehicle routing problem with time-window constraints (HEVRPTW). To solve this variant of vehicle routing problem (VRP), we propose a DRL-based ap-proach, named Edge-enhanced Dual attentIon encoderR and feature-EnhanCed dual aTtention decoder (Edge-DIRECT). Edge-DIRECT features an extra graph representa-tion, the node connectivity of which is based on the overlap of customer time-windows. Edge-DIRECT's self-attention encoding mechanism is enhanced by exploiting the en-ergy consumption and travel time between the locations. To effectively account for the heterogeneity of the EVs' fleet, a dual attention decoder has been introduced. Experi-mental results based on two real-world datasets reveal that Edge-DIRECT outperforms a state-of-the-art DRL-based method and a well-established heuristic approach in solu-tion quality and execution time. Furthermore, it exhibits competitive performance when compared to another leading heuristic method.", "sections": [{"title": "1. Introduction", "content": "Recently, electric vehicles (EVs) have surged in popularity, driven by global commitments to reduce carbon emissions and increased environmental awareness among corporations [1-3]. This trend is particularly evident in the logistics sector, where companies are actively integrating EVs into their transportation fleets. At the heart of this transition is the electric vehicle routing problem (EVRP), an optimization problem central to the operations of these logistics companies, focusing on dealing with the complexities of deploying EVs instead of internal combustion engine vehicles. This article addresses a practical routing problem for EVs, named heterogeneous electric vehicle routing problem with time-window constraints (HEVRPTW). It considers both vehicle attributes, such as varying cargo and battery capa\u0430\u0441ities [4] and customer preferences regarding delivery times [5]. These factors create a more realistic and applicable model for contemporary logistics challenges. HEVRPTW, recog-nized as an NP-hard optimization problem, seeks to determine a set of routes with minimal cost, total traveling time, or total traveling distance, for a fleet of Heterogeneous EVs to serve each geographically dispersed customer's demands within a specified time-window.\nTraditional methods, including exact and heuristics solvers, are conventionally employed to solve various vehicle routing problem (VRP) variants. Due to the NP-Hard nature of HEVRPTW, and VRPs in general, exact methods, such as branch-and-price [6] and branch-and-price-and-cut [7], consume prohibitively long time for solving practical-size problems [8]. Heuristics solvers, on the other hand, are significantly faster than exact methods, trading"}, {"title": "2. Related Works", "content": "In the operations research literature, only a few studies have focused on HEVRPTW. We briefly review these and then explore DRL-based approaches proposed for solving different VRPs.\nThe study by Hiermann et. al. [10] introduced an adaptive large neighborhood search-based heuristic method to tackle the HEVRPTW. In another study, Sassi et. al. [11] presented a mixed integer programming model formulation for HEVRPTW and proposed a constructive-based heuristic method combined with a local search heuristic using an inject-eject technique for solving this NP-hard optimization problem. While numerous studies have employed heuristic solvers for VRPs, a significant drawback of these methods is their reliance on complex, manually-engineered search rules. Secondly, these methods suffer from a lack of generalizability and adaptability. Even a minor modification to the problem may necessitate rerunning the algorithm to find a solution [12].\nMotivated by promising results utilizing DRL-based methods for solving combinatorial optimizations, Nazari et al. [13] proposed a DRL algorithm for solving VRP with an RNN-based decoder for its policy model and utilized the aggregated Euclidean travel distance as feedback for training the model. In subsequent research, Kool et al. [14] enhanced the Deep Reinforcement Learning (DRL)-based method by utilizing a Transformer-based policy network. They also employed a self-critical REINFORCE algorithm for training the policy model, which resulted in performance surpassing competitive baselines, including Google OR-Tools. Duan et al. [8] argued that previously proposed methods fall short in effectively solving the VRP when actual travel distances replace aggregated Euclidean distances. In such scenarios, these methods fail to outperform OR-Tools. To address this, they proposed using a graph convolutional network that leverages the actual travel distances between locations, successfully surpassing the performance of OR-Tools in terms of total travel distance. However, none of these studies investigated the EVRP were vehicles due to their limited battery capacity need to be recharged multiple times within a planning horizon. The study by Lin et. al. [15] tried to improve the previous DRL-based methods for solving the EVERP with time-window constraints. To this end, Structure2Vec is used to capture the EVs features as well as the location and demands of the customers. A decoder comprised of an attention-based model and an LSTM-based was used for route construction. However, this method utilizes a complete graph to represent and embed the problem using its encoder. Hence, it fails to consider the reachability of the node based on their time-window constants and captures the underlying structure for effective routing when time-windows are considered. Besides, the RNN-based model used in the decoder leads to insufficient parallel processing and reduced computational efficiency compared to decoder models used by previous studies such as Kool et al. [14]. Thirdly, this proposed method does not consider the heterogeneity of the fleets in real-world logistics operations. Finally, this approach does not consider utilizing the energy consumption between the locations and only relies on the travel distance for decision-making despite its importance for effective policy search considering the limited capacity of EV batteries."}, {"title": "3. Problem Definitions and Formulation", "content": "In this section, we define the HEVRPTW and express this routing problem through Markov decision process (MDP) formulation."}, {"title": "4. Methodology", "content": "In this section, we introduce our deep reinforcement learning (DRL)-based method, termed Edge-enhanced Dual attentIon encoderR and feature-EnhanCed dual aTtention decoder (Edge-DIRECT), designed for tackling the HEVRPTW. We first delve into the"}, {"title": "4.1. Policy Network Architecture of Edge-DIRECT", "content": "Edge-DIRECT, as illustrated in Figure 1, employs a Transformer-style policy network to solve the HEVRPTW instance constructively, which involves sequentially adding a node to the solution at each decoding step. The policy network of Edge-DIRECT comprises two primary elements: an edge-enhanced dual attention encoder and a feature-enhanced dual decoding module. The functionalities and characteristics of each of these components are detailed in the subsequent sections."}, {"title": "4.1.1. Edge-Enhanced Dual Attention Encoder", "content": "The edge-enhanced dual attention Encoder projects the raw features of an instance into a higher-dimensional space, facilitating the extraction of features pertinent to the problem instance. This encoder consists of two key encoding modules: a time-window graph attention module and a feature-enhance self-attention encoding module.\nIn the time-window graph attention module, given the time-window graph $G = (N, E)$, a $L$-layer graph attention (GAT) operation, as detailed in [16], is applied. This method is specifically tailored to capture the correlations between neighbor nodes that are able to be reached from each other based on their time-window constraints. The introduction of a time-window graph, coupled with this technique for node correlation extraction, is to enhance the policy network's decision-making process, in the presence of time-window constraints, for better routing performance.\nIn each layer $l$, for every element $a_{ij}$ in the time-window graph's adjacency matrix, an attention coefficient $A_{ij}^{(l)}$ is calculated at the $l$-th GAT layer. This coefficient, determined by a learnable weight vector $a^{(l)}$ and a learnable weight matrix $W^{(l)}$, quantifies the influence of neighboring nodes, as follows:\n$A_{ij}^{(l)} = \\frac{\\exp(\\text{ReLU}(a^{(l)T} [W^{(l)}h_{i}^{(l-1)} ||W^{(l)}h_{j}^{(l-1)}]))}{\\Sigma_{k \\in N(i)} \\exp(\\text{ReLU}(a^{(l)T}[W^{(l)}h_{i}^{(l-1)} ||W^{(l)}h_{k}^{(l-1)}]))}$ (4.1)\nwhere $||$ denotes the concatenation operation, ReLU represents the ReLU non-linear activa-tion function, and $h_{i}^{(l-1)}$ is the feature vector of the node $n_i$ at layer $(l - 1)$. For layer 0, this feature vector is equivalent to a linear projection of the attributes associated with node $n_i$, as described in Definition 1."}, {"title": "4.1.2. Feature-Enhanced Dual Decoder", "content": "Given node embeddings $h_i$, where $i$ ranges from 0 to $|N|$, derived from the encoder, and the aggregate graph embedding $\\bar{h}$, the decoder, at each step T, produces two distinct probability distributions: $p^F_T$ for selecting a vehicle from a heterogeneous fleet, and $p^V_T$ for determining the node to be visited by the chosen vehicle. This setup includes two dedicated modules: the vehicle decoder module and the node decoder module.\nEach decoding step starts by selecting a vehicle from a heterogeneous fleet using the vehicle decoder module. This module allows the policy model to make informed routing decisions for a fleet of heterogeneous EVs, by capturing the diverse characteristics of these vehicles. For this vehicle decoding module, we propose employing a deep learning model with cross-attention mechanism.\nGiven the vehicle fleet features vector F and fleet's state $s_T^F$, for each vehicle j, a high-dimensional representation $\\bar{h}_j^F$ is computed by: $\\bar{h}_j^F = FF(f_j) || FF(s_T^F)$ where FF represents a two-layer, fully connected network with ReLU activation func-tions. It is important to note that for efficiency, the operation of the fully connected network on fj is performed only at the start of each episode.\nThen, given the vehicle embeddings vector HF = $\\{ \\bar{h}_1^F, ..., \\bar{h}_V^F \\}$ and node embeddings $\\{ h_i \\}_{i \\in N}$, a context embedding $\\bar{h}_T^{(c)F}$ is computed through the following equation:\n$\\bar{h}_T^{(c)F} =  \\text{Readout} (HF) || \\text{Readout} (\\cup_{i \\in N_{\\text{visited}}} \\{ h_i \\})|| \\text{Readout} (\\cup_{i \\in N_{\\text{to-visit}}} \\{ h_i \\})$ (4.4)\nwhere Readout is denotes the standard Readout operation [20].\nAfterward, given the vehicle embeddings HF and the context embedding $\\bar{h}_T^{(c)F}$, using a Multi-Head Attention (MHA) operation, as described in Kool et al. [14], an embedding $\\bar{h}_j^{(g)F} = MHA(W_Q^{(g)F} \\bar{h}_T^{(c)F}, W_K^{(g)F} HF, W_V^{(g)F} HF)$ is calculated. $W_Q^{(g)F}, W_K^{(g)F}$ and $W_V^{(g)F}$ are respectively the learnable weights for the query, key, value. Using a Single-Head At-tention [21], and given the embedding $\\bar{h}_j^{(g)F}$ and the vector HF, with learnable parameters $W_Q^{(c)F}, W_K^{(c)F}$, and $W_V^{(c)F}$ for query, key, and value respectively, the compatibility $\\bar{h}_{j}^{(c)F}$ calculated as $\\bar{h}_{j}^{(c)F}$ = SHA($. Finally, a probability distri-bution $p_T^F$ over the heterogeneous fleet is computed through a Softmax operation on $\\bar{h}_{j}^{(c)F}$.\nAt the beginning of node decoding process, given the selected vehicle j, problem instance's graph embedding $\\bar{h}$, node representations H = $\\{ h_0, ..., h_{|N|-1} \\}$, and vehicle state $s_T^V$, a context embedding $\\bar{h}_T^{(c)V}$ is computed through: $\\bar{h}_T^{(c)V}$ = $[\\}$.\nHere, $N_T^V, r_T^V$, and $r_T^C$ represent the current location of the vehicle j, its remaining energy, and its remaining capacity, respectively.\nThis novel context embedding equips the policy network with essential state information needed to handle the constraints of HEVRPTW, facilitating informed and effective decision-making in solving the routing problem.\nNext, given the context embedding $\\bar{h}_T^{(c)V}$ and encoded node features vector H at the decoding step T, using a MHA layer, glimpse $\\bar{h}_T^{(g)} = MHA(W_Q^{(g)} \\bar{h}_T^{(c)V}, W_K^{(g)} H, W_V^{(g)} H)$ is computed.\n$W_Q^{(g)} \\in R^{d_h \\times d_Q}, W_K^{(g)} \\in R^{d_h \\times d_k}$, and $W_V^{(g)} \\in R^{d_h \\times d_v}$ are the trainable parameters corresponding to the query, kay, and value, respectively. For every node ni, given the node embedding $h_i$ and the glimpse $\\bar{h}_T^{(g)}$, a compatibility score is determined to indicate"}, {"title": "5. Experiments", "content": "This section presents thorough experimental analyses using two real-world datasets, de-rived from traffic data of two major Canadian cities, Edmonton and Calgary, to address the subsequent research questions:\n\u2022 RQ1: How does Edge-DIRECT perform compared to the state-of-the-art DRL-based and heuristics methods in solving the HEVRPTW in terms of the aggregated travel time and computational time?\n\u2022 RQ2: How do the time-windows encoding module, edge-enhanced encoding mod-ule, and dual attention decoder contribute to improving solution quality for the HEVRPTW?\n\u2022 RQ3: How do varying ratios of the number of charging stations to the number of customers impact the results?\nWe conducted training and testing experiments for DRL-based models on servers equipped with A100 GPUs with 40 GB memory size. Servers with 32 cores Intel(R) Xeon(R) Gold 6240R CPUs. In the DRL models, we configure the hidden dimension size at 128, establish 3 encoding layers, and set the number of attention heads to 8. The model is trained using the Adam optimizer with the learning rate of 10-3 with a batch size of 256."}, {"title": "5.1. Performance Analysis (RQ1)", "content": "In evaluating the performance of Edge-DIRECT for solving the HEVRPTW, we bench-marked its performance against heuristic methods and a state-of-the-art Deep Reinforcement Learning (DRL)-based approach. Specifically, we adapted and enhanced the Ant Colony Op-timization (ACO) method originally proposed by Mavrovouniotis et al. [25] for the EVRP by integrating techniques from Han et al. [26] to tackle time-window constraints and fleet heterogeneity. Furthermore, we utilized and enhanced the Variable Neighborhood Search / Tabu Search (VNS/TS) heuristic, based on the work by Schneider et al. [27], for EVRP within the context of heterogeneous fleets and time-window considerations. Alongside these heuristics, Edge-DIRECT's performance was compared with a DRL-based method, named EVRPTW-RL, as described by Lin et al. [15], which employs an encoder-decoder structure specifically designed for EVRP challenges. To ensure a fair comparison, as EVRPTW-RL cannot accommodate vehicle selection, vehicles are randomly selected at the end of each trip. HEVRPTW-X denotes problem instances with X customers.\nFor DRL-based methods, there are two decoding strategies: 1. The Greedy approach, where at each decoding phase, the decoder selects the vehicle and the node being visits by that vehicle with the highest probability as indicated by the Softmax layers. 2. The Sampling strategy, where 1280 routes are sampled from the distributions, outputted by vehicle decoder and node decoder modules, and the route with the highest reward is selected.\nAs perceivable through Table 1, Edge-DIRECT with sampling-based decoding outper-forms the state-of-the-art DRL-based method proposed for EVs' routing, i.e. EVRPTW-RL, with with decoding strategies in terms of cost. As the size of the problem increases the per-formance gap widens favoring Edge-DIRECT over EVRPTW-RL despite requiring much less computational times, due to EVRPTW-RL's step-wise encoding. Edge-DIRECT (Sam-pling) significantly surpasses the performance of ACO, a well-established heuristic methods on both datasets. This superiority is not only evident in terms of solution quality but also in computational efficiency and the gap increases as the problem size grows. Edge-DIRECT with greedy decoding strategy mandates least amount of running time compared to all baselines and is able to exceeds the performance of ACO for problem of size 100 on both datasets. While the sampling strategy of Edge-DIRECT demands more computational time compared to its greedy-based counterpart, it remains competitive in terms of total travel time when juxtaposed with heuristic methods such as VNS/TS. Moreover, it benefits from significantly reduced computational time compared to both heuristic approaches and EVRPTW-RL (Sampling)."}, {"title": "5.2. Ablation Study (RQ2)", "content": "Edge-DIRECT is featured with 3 major enhancements to effectively solve the HEVRPTW. The contribution of each of these features has been investigated on the Calgary Dataset with greedy decoding strategy and results are detailed in Table 2. \"Edge-DIRECT w/o \u0395\u0395\" represents Edge-DIRECT without the edge-enhanced encoder, wherein the encoder only exploits the node features. \"Edge-DIRECT w/o TWE\" indicates the variant lacking the time-window graph encoding module, where time-windows are instead assigned as raw fea-tures to each node. Finally, \"Edge-DIRECT w/o HD\" denotes the model variant excluding the specialized decoder designed to manage fleet heterogeneity.\nResults demonstrate that the original Edge-DIRECT has better performance compared to the other variants. While removing the time-window encoding module notably reduces running time more than the other two variants, this module also yields a more substantial improvement in cost compared to the 2 enhancements to Edge-DIRECT. After the time window encoder, the addition of the heterogeneous vehicle decoder notably boosts cost efficiency. In terms of computational time, its impact is comparable to that of the time window encoder, yet marginally less. The edge-enhanced encoder contributes the least to cost reduction compared to the other modules and incurs minimal computational time among them."}, {"title": "5.3. Impact of Charging Station-to-Customer Ratio (RQ3)", "content": "Experiments were conducted to explore the effect of varying the ratio of charging sta-tions to customers on the performance of DRL-based methods, on the Calgary dataset for a problem instance comprising 100 customers. The findings are detailed in Table 3. Notably, increase in charging stations leads to a reduction in overall cost but a rise in computa-tional time, attributable to the enhanced complexity from incorporating more nodes into"}, {"title": "6. Conclusion", "content": "In this study, we address the HEVRPTW by introducing a DRL-based method, Edge-DIRECT. This approach features a Transformer-style policy network with an edge-enhanced encoder that leverages energy and travel costs between nodes for efficient EV routing. To accommodate time-window constraints, Edge-DIRECT employs a GAT layer to discern the graph's structure from the nodes' connectivity based on time-window constraints. Addi-tionally, a dual-attention decoder is utilized to account for fleet heterogeneity, focusing on battery and cargo capacity. Through comprehensive testing on datasets from Edmonton and Calgary, Edge-DIRECT's efficacy is assessed against leading heuristics and state-of-the-art DRL methods. The results demonstrate that Edge-DIRECT outperforms EVRPTW-RL, a competitive deep reinforcement learning (DRL)-based approach designed for addressing Electric Vehicle Routing Problems with Time-Windows (EVRPTW), in terms of solution quality with significantly reduced computational time. Notably, it competes well with the VNS/TS and surpasses ACO in route efficiency, with substantially less running time.\nThere are several avenues for future research endeavors. First, in this article we assumed that the energy recharging and consumption is linear. However, we aim to delve into more complex, non-linear models of consumption and recharging in subsequent research, aligning our approach more closely with real-world dynamics. Second, we plan to explore routing variations that accommodate the potential for order cancellations, further enhancing the practical applicability of our findings."}]}