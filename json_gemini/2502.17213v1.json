{"title": "Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics", "authors": ["Jiahe Li", "Xin Chen", "Fanqi Shen", "Junru Chen", "Yuxin Liu", "Daoze Zhang", "Zhizhang Yuan", "Fang Zhao", "Meng Li", "Yang Yang"], "abstract": "Neurological disorders represent significant global health challenges, driving the advancement of brain signal analysis methods. Scalp electroencephalography (EEG) and intracranial electroencephalography (iEEG) are widely used to diagnose and monitor neurological conditions. However, dataset heterogeneity and task variations pose challenges in developing robust deep learning solutions. This review systematically examines recent advances in deep learning approaches for EEG/iEEG-based neurological diagnostics, focusing on applications across 7 neurological conditions using 46 datasets. We explore trends in data utilization, model design, and task-specific adaptations, highlighting the importance of pre-trained multi-task models for scalable, generalizable solutions. To advance research, we propose a standardized benchmark for evaluating models across diverse datasets to enhance reproducibility. This survey emphasizes how recent innovations can transform neurological diagnostics and enable the development of intelligent, adaptable healthcare solutions.", "sections": [{"title": "I. INTRODUCTION", "content": "Neurological disorders represent one of the most significant challenges to global health today, with profound consequences for both individuals and healthcare systems. According to the World Health Organization (WHO), neurological disorders affect over one-third of the global population, making them a leading cause of illness and disability worldwide [1]. Dementia, which affects 47.5 million people worldwide, is a primary concern, with Alzheimer's disease being the most common form. Seizure impacts more than 50 million individuals, while sleep disorders are widespread yet often underdiagnosed. Other significant disorders, including Parkinson's disease, schizophrenia, depression, and ADHD, further exacerbate the global burden, placing additional strain on healthcare systems [2]. In low- and middle-income countries, where limited resources constrain access to neurological care and treatment, the situation is particularly dire.\nPractical diagnostic tools are essential to alleviate the growing global burden of neurological disorders, and electrical brain signals are indispensable among them. Electrical brain signals, specifically electroencephalography, are critical for understanding and diagnosing neurological disorders. Electroencephalography evaluates electrical activity in the brain and is categorized into scalp electroencephalography (EEG) and intracranial electroencephalography (iEEG). EEG is noninvasive, recording brain activity from electrodes placed on the scalp. iEEG includes inserting electrodes into the brain (stereoelectroencephalography, SEEG) or onto the brain's surface (electrocorticography, ECoG), providing more detailed and localized information [3].\nThe analysis of brain signals such as EEG/iEEG poses significant challenges for traditional machine learning (ML) approaches. These methods typically rely on manually engineered features that may not fully capture the complex patterns in neurophysiological data, while their performance is often compromised by inherent noise and artifacts in raw neural recordings. Deep learning (DL) addresses these limitations by automatically extracting features, modeling temporal dependencies, and improving robustness against signal variability. The ability of DL methods to detect and classify neurological disorders with high accuracy has driven widespread adoption in brain signal analysis. This survey systematically examines the workflow of DL models in brain signal analysis, focusing on their applications in diagnosing neurological disorders."}, {"title": "A. General Workflow", "content": "The general workflow of electrical brain signal analysis in neurological diagnostics, as illustrated in Fig. 1, consists of three main stages: signal collection, signal preprocessing, and analysis and diagnosis.\nIn the signal collection stage, electrical brain activity is recorded using EEG, ECoG, or SEEG systems (Fig. 1.a). These signals are typically captured across multiple channels at specific sampling frequencies and are often accompanied by labeled tasks and corresponding labels.\nThe signal preprocessing stage (Fig. 1.b) involves a series of low-level techniques, including denoising, filtering, artifact removal, and normalization. These steps are crucial for reducing noise and artifacts, enhancing relevant patterns, and structuring the data for effective feature extraction.\nIn the analysis and diagnosis stage (Fig. 1.c), the preprocessed signals undergo feature extraction and neurodiagnostic classification."}, {"title": "B. Related Studies and Our Contributions", "content": "Existing brain signal analysis surveys exhibit diverse scopes and focuses. Some focus specifically on EEG signals, emphasizing their wide availability [4]\u2013[6]. Others broaden the scope to include brain signals like magnetic resonance imaging (MRI) [7], [8], which differ from EEG and iEEG in acquisition methods, temporal resolution, and preprocessing requirements. From a task perspective, some reviews focus specifically on diseases such as seizure [9], [10], providing in-depth insights into disease-specific applications. Others take a broader view, covering diverse brain-computer interface (BCI) applications [11], [12], which focus on interaction and control, differing fundamentally from neurological diagnostic tasks.\nOur work establishes three foundational contributions to advance deep learning-driven neurodiagnosis: First, we systematically curate and analyze 46 public EEG/iEEG datasets across seven neurological conditions, establishing the most comprehensive data landscape to date. We also unify fragmented methodologies by standardizing data processing, model architectures, and evaluation protocols. Besides, we identify self-supervised learning as the optimal paradigm for developing multi-task diagnostic frameworks, offering a comprehensive overview of pre-trained multi-task frameworks and their advancements. Additionally, we propose a benchmarking methodology to evaluate brain signal models across tasks, providing a foundation for scalable and versatile solutions in EEG/iEEG-based neurological diagnostics applications."}, {"title": "II. METHODS", "content": null}, {"title": "A. Problem Definition", "content": "In this survey, we classify neurological diagnostic tasks into sample-level classification and event-level classification, both of which fall under the broader framework of classification problems. Sample-level classification involves assigning a single label to an entire signal, which typically represents a specific subject or sample (e.g., Alzheimer's disease diagnosis). By comparison, event-level classification focuses on identifying and classifying distinct temporal segments within a more"}, {"title": "B. Signal Collection", "content": "EEG have evolved significantly since Hans Berger first recorded EEG signals from the human scalp in 1924 [14]. While EEG signals are typically collected non-invasively using scalp electrodes placed according to the 10-20 system [15], more recent studies employ higher-density EEG electrode configurations for enhanced spatial resolution and detailed brain activity mapping. EEG captures brain oscillations across frequency bands, each linked to specific neural states: delta (deep sleep), theta (light sleep), alpha (relaxation), beta (focus), and gamma (higher cognition) [16]. Depending on the study, participants may perform tasks or rest to elicit relevant brain activity. Resting-state EEG evaluates baseline activity, while specific tasks can highlight disease-related abnormalities [17].\niEEG involves implanting electrodes either within deep and superficial brain structures via burr holes (SEEG) or on the brain's surface by placing grids during craniotomy (ECOG). Compared to EEG, iEEG offers excellent spatial resolution and reduced susceptibility to artifacts from scalp muscle activity and eye movements. SEEG allows recording from deep and distributed brain regions with minimal invasiveness, while ECOG provides higher spatial resolution for cortical surface"}, {"title": "C. Signal Preprocessing", "content": "EEG/iEEG signals require low-level preprocessing to address challenges such as noise and artifact removal, normalization for consistency, and segmentation into analyzable time windows. These steps refine raw data, ensuring it accurately reflects brain activity and provides a robust foundation for analysis. Representative methods are summarized in Table I, with one key work per category highlighted.\n1) Noise Reduction and Filtering: Filtering techniques, such as Finite Impulse Response (FIR) and Infinite Impulse Response (IIR) filters, are employed to isolate specific frequency components. Advanced methods like MSEC noise reduction and wavelet transforms [21] provide specialized solutions for effective denoising and precise data refinement.\n2) Artifact Removal: Artifact removal strategies include Blind Source Separation techniques, such as Independent Component Analysis (ICA), Principal Component Analysis (PCA), and Multiple Component Analysis (MCA) [37], along with Artifact Correction methods, including Ocular Correction and Artifact Subspace Reconstruction. Wavelet decomposition is also commonly used mitigate artifacts.\n3) Baseline Correction and Detrending: Baseline correction and detrending address baseline drift caused by eye movements, breathing, and subject motion. Baseline correction standardizes power data, baseline removal reduces subjectindependent noise, and detrending eliminates linear or nonlinear trends, enhancing signal reliability."}, {"title": "7) Segmentation:", "content": "Segmentation divides EEG and iEEG data into smaller sections for localized information extraction and data augmentation to enhance sample diversity. Overlap windows ensure continuity and capture transitional features, while non-overlapping segments prioritize computational efficiency and maintain distinct temporal boundaries."}, {"title": "D. Feature Extraction", "content": "Feature extraction techniques reconfigure data into alternative representations by isolating key features or decomposing it into core components essential for modeling and analysis. This process effectively primes the data for more sophisticated, abstract analytical tasks. Representative methods are summarized in Table II, with one key work per category highlighted.\n1) Data Augmentation: Data augmentation generates new samples to increase dataset diversity and improve classification activity due to its densely packed electrode grids. However, iEEG can still be affected by cardiac artifacts, electrode shifts, and other forms of noise. Rigorous preprocessing techniques are essential to ensure the accuracy and reliability of EEG and iEEG signals in clinical and research applications.\naccuracy and stability. Oversampling is commonly used to address class imbalances, while the Extreme Learning Machine Autoencoder (ELM-AE) employs autoencoders to synthesize data by reconstructing input features [39].\n2) Spectral and Power Analysis: Spectral and power analysis focuses on examining the frequency components and energy distribution of signals. Key techniques include power spectrum calculation, frequency band energy analysis, and partial-directed coherence for evaluating signal causality.\n3) Time Domain Feature Extraction: Time domain features, such as statistical measures, Hjorth parameters, and ZeroCrossing Rate, effectively represent signal amplitude, time scale, and complexity. These features provide valuable insights into signal distribution, intensity, and rate of change.\n4) Frequency Domain Feature Extraction: Frequency domain features, such as band power, band energy, median frequency, spectral edge frequency, and power spectral density (PSD), provide insights into the spectral content of signals.\n5) Time-Frequency Feature Extraction: Time-frequency features capture both temporal and spectral information, providing a comprehensive signal representation. Short-time Fourier Transform (STFT) analyzes frequency variations over time, while Continuous and Discrete Wavelet Transforms (CWT, DWT) offer detailed time-frequency representations. Advanced techniques like FBSE-EWT filter banks [58] and Smoothed Pseudo Wigner Ville Distribution (SPWVD) [59] enhance analysis precision.\n6) Other Feature Extraction: Nonlinear features, such as entropy measures, fractal dimensions, and Lyapunov exponents, capture complex patterns that linear methods may miss. Spatial features, including Common Spatial Patterns and connectivity measures like phase-locking value (PLV) and phase-lag index (PLI), represent spatial domain activities. Transformbased features further enhance analysis by reconstructing signals into more informative representations.\n7) Signal Decomposition and Transformation: Signal decomposition and transformation techniques decompose complex signals to facilitate detailed analysis, such as wavelet transforms, Gabor Transform [40], Fast Fourier Transform, Empirical Mode Decomposition, and Hilbert-Huang Transform."}, {"title": "E. Data Partitioning Strategies", "content": "Building on the detailed definition of $X^{(i)} \\in \\mathbb{R}^{C \\times T}$ in Section II-A, where $X^{(i)}$ represents the EEG or iEEG signal of subject $i$, we further introduce additional notations to formalize the data partitioning strategies:\n* $P = \\{1, 2, . . ., N\\}$: The set of $N$ subjects in the dataset.\n* $X_{\\text{train}}, X_{\\text{val}}, X_{\\text{test}}$: The training, validation, and testing sets, respectively.\n* $a_{\\text{train}}, a_{\\text{val}}, a_{\\text{test}} \\in (0,1)$: The proportion of data used for training, validation and test, and $a_{\\text{train}} + a_{\\text{val}} + a_{\\text{test}} = 1$.\n* $K^{(i)}$: The total number of temporal segments or events derived from subject $i$'s data."}, {"title": "F. Deep Learning Architectures", "content": "Neurological data processing relies on several key architectures: Convolutional Neural Networks (CNNs) [60] excel at extracting spatial/spectral features through hierarchical convolutions. Recurrent Neural Networks (RNNs) [61] capture temporal dependencies via recurrent connections. Transformers [62] model long-range spatiotemporal relationships using self-attention. Graph Neural Networks (GNNs) [63] analyze functional connectivity in graph-structured data. Autoencoders (AEs) [64] learn compressed representations through encoder-decoder structures. Generative Adversarial Networks (GANs) [65] synthesize signals through adversarial training. Spiking Neural Networks (SNNs) [66] leverage spike-based computation for temporal dynamics."}, {"title": "G. Deep Learning Paradigms", "content": "Deep learning applications in neurological diagnostics can be categorized into four paradigms: supervised learning, self-supervised learning, unsupervised learning, and semisupervised learning. Each paradigm addresses specific challenges in processing brain signals by leveraging architectures tailored to data availability and task requirements. These paradigms will be further discussed in detail in Section III.\n1) Supervised Learning: Supervised learning is the dominant paradigm for neurological diagnostics tasks, training models to map signals $X \\in \\mathbb{R}^{C \\times T}$ to labels $y \\in Y$.\n2) Unsupervised Learning: Unsupervised learning is essential for uncovering intrinsic data structures in signals $X$, enabling representation learning without relying on labels.\n3) Semi-Supervised Learning: Semi-supervised learning combines a small set of labeled examples $\\{(x_i, \\hat{y}_i)\\}_{i=1}^{r}$, where $\\hat{y}_{r}$ denotes the provided labels, with a larger set of unlabeled examples $\\{x_j\\}_{j=r+1}^{l}$ to learn a mapping from $X$ to $Y$.\n4) Self-Supervised Learning: Self-supervised learning (SSL) leverages unlabeled EEG/iEEG data by constructing pretext tasks that generate pseudo-labels $\\hat{y}$ from intrinsic properties of the raw signals $X$. These tasks enable models to learn robust representations, which can be fine-tuned for downstream tasks. SSL methods fall into three main categories: contrastive, predictive, and reconstruction-based learning. Contrastive-based methods, such as Contrastive Predictive Coding (CPC) [18] and Transformation Contrastive Learning [67], learns by maximizing similarity between related views while minimizing it between unrelated ones, capturing distinguishing signal features. Predictive-based learning employs pretext tasks such as Relative Positioning and Temporal Shuffling to extract structural patterns across temporal, frequency, and spatial domains [68], [69]. By predicting transformations applied to the data, it enhances domain-specific feature learning. Reconstruction-based learning trains models to reconstruct masked signal segments. Methods like Masked Autoencoders (MAE) reconstruct temporal or spectral components, learning intrinsic patterns in the process [28], [70]. Studies have also explored hybrid methods, which combine elements from contrastive, predictive, and reconstruction-based approaches [18], [71]."}, {"title": "III. APPLICATIONS", "content": "This section systematically reviews neurological disease diagnosis methodologies. Each subsection starts with an introduction to the disease's background, including its characteristics, diagnostic tasks, and relevant public datasets. We will then review representative works for each disease, highlighting disease-specific features in the context of deep learning-based diagnosis, such as data types, frequency bands, brain regions, and methodological trends. Given their extensive research history, seizure detection and sleep staging receive dedicated"}, {"title": "A. Seizure Disorder", "content": "1) Task Description: Epilepsy, a neurological disorder affecting 50 million people globally, is characterized by recurrent seizures caused by abnormal brain activity. Seizures range from brief confusion or blanking out to severe convulsions and loss of consciousness. According to the World Health Organization (WHO), up to 70% of epilepsy cases can be effectively treated with proper care. However, in low-income regions, limited resources and stigma often hinder access to treatment, heightening the risk of premature death [90].\nSeizure detection primarily relies on standardized EEG/iEEG datasets, summarized in Table III. The key challenge is distinguishing seizure events from background activity, typically framed as binary classification where $y_k \\in \\{0,1\\}$. Most approaches segment long EEG sequences into smaller windows for sample-level classification, aggregating segment predictions to form event-level outcomes as $Y = \\bigcup_{k=1}^{K}{\\{Y_k\\}}$ [91], [92]. Another approach detects optimal cut points within continuous recordings to identify the boundaries of meaningful segments $\\{X_k\\}_{k=1}^{K}$, and each segment is classified individually [56]. The final event-level prediction is obtained by combining these event-level labels $Y = \\bigcup_{k=1}^{K}{\\{segment(X_k; \\theta)\\}}$.\nMore detailed classifications have also been explored, including three-class tasks, where $y_k \\in \\{A, D, E\\}$ represents interictal (A, the period between seizures), preictal (D, the time before seizure onset), and ictal (E, seizure) states [93]. Five-class tasks refine this further by subdividing the preictal state into early, middle, and late stages [94]. The Temple University Seizure Corpus (TUSZ) [81] supports detailed epilepsy studies, classifying events into pathological patterns"}, {"title": "2) Supervised Methods:", "content": "Supervised seizure detection using EEG/iEEG data has advanced alongside growing datasets and improved technology. Early studies relies on subject-specific or mixed-subject evaluations using short, pre-segmented EEG clips. For example, the Bonn dataset [72] consists of manually labeled seizure/non-seizure segments, leading to models optimized for fixed-length inputs. Approaches based on raw signals employ CNNs or RNNs to automatically extract spatiotemporal features from these standardized segments [29], [95], while feature-based methods derive handcrafted or transformed representations, such as scalograms [94] and waveletbased features [96], which are more suited for shallow classifiers. These techniques inherently assume limited temporal context and avoided segmentation challenges.\nWith the adoption of long-term recordings like CHB-MIT [76], the focus shifts toward cross-subject paradigms. These datasets provide extensive seizure examples within continuous, long-term EEG streams, necessitating more flexible detection frameworks capable of handling variable-length inputs and identifying seizure boundaries in unsegmented data. Approaches integrate temporal modeling through sliding windows [91], sequence-aware architectures such as Transformers [97], or hybrid feature fusion techniques [98]. Concurrently, cross-subject validation becomes standard, reflecting clinical requirements that generalize across diverse conditions.\nThe necessity of cross-subject modeling in seizure detection stems from its critical role in ensuring clinical generalization. The invasive nature of iEEG fundamentally differentiates its modeling requirements from EEG through distinct acquisition paradigms and neurophysiological characteristics, as its patient-specific recording conditions and electrode configurations lead to substantial inter-subject heterogeneity in temporal features and spatial sampling properties, unlike EEG's"}, {"title": "B. Sleep Staging", "content": "1) Task Description: Sleep staging is critical to understanding sleep disorders like insomnia and sleep apnea, as well as the impact on overall health. It is estimated that 20% to 41% of the global population is affected by sleep disorders, which are linked to an increased risk of obesity, cardiovascular diseases, and mental health issues [128]. Therefore, accurately identifying sleep stages is essential for addressing these concerns.\nSleep staging involves segmenting signals into 30-second epochs and classifying them into stages: awake (W), rapid eye movement (REM), and three non-REM (NREM) stages (N1, N2, N3). Wake is characterized by high-frequency B and a waves. In N1, the transition from wakefulness to sleep, low-amplitude @ waves appear. N2, the light sleep stage, is marked by sleep spindles and K-complexes associated with sensory processing and memory consolidation. N3, or deep sleep, features slow-wave \u03b4 activity. REM sleep, essential for emotional regulation and dreaming, is characterized by rapid, low-voltage brain activities.\nMultimodal modeling is fundamental for sleep analysis, as polysomnography (PSG) integrates EEG (e.g., Fpz-Cz, Pz-Oz), Electrooculography (EOG), and Electromyography (EMG) to enhance staging accuracy. The public datasets listed in Table IV are frequently employed in sleep analysis. A detailed overview of all related works is provided in Appendix Table XII.\n2) Supervised methods: Selecting biosignal modalities is critical for designing supervised learning frameworks in PSG-based sleep staging. Two primary paradigms are widely used. Single-channel EEG methods, preferred in resource-constrained settings, offer hardware simplicity, reduced cross-modal interference, and enhanced computational"}, {"title": "C. Depression Identification", "content": "1) Task Description: Depression, particularly Major Depressive Disorder (MDD), is a psychological condition affecting 5% of individuals worldwide, with a higher prevalence among women. In low- and middle-income countries, up to 75% of individuals lack adequate care due to limited resources and stigma, despite effective treatments being available [143]. Depression severity is quantified using standardized scales like the Beck Depression Inventory (BDI) to differentiate clinical depression from normal mood variations. Existing studies adopt heterogeneous classification criteria: some focus on binary discrimination (e.g., patients vs. healthy controls), while others stratify cohorts by treatment status (medicated vs. non-medicated) or severity levels (mild vs. moderate/severe). Table V summarizes datasets used in MDD research. A detailed overview of all related works is provided in Appendix Table XIII.\n2) Approach overview: Depression impacts both superficial and deeper brain structures, presenting challenges for traditional handcrafted features. Acharya introduces the first end-to-end DL model for EEG-based depression detection, showing that right-hemisphere signals are significantly more distinctive than left-hemisphere ones, which aligns with clinical findings [144]. This insight has driven further studies analyzing hemispheric EEG separately, often confirming similar patterns. For example, Ay et al. introduces a hybrid CNN-LSTM architecture, with experimental results revealing a more pronounced performance improvement in the right cerebral hemisphere [21]. DeprNet [35] employs a CNN-based architecture with visualizations highlighting prominent activity in right-hemisphere electrodes for depressed subjects.\nSpiking neural networks (SNNs) excel in EEG-based depression diagnosis, capturing brain-inspired spatiotemporal dynamics with biologically interpretable insights. Shah et al. [145] employ the NeuCube SNN framework to encode EEG signals into temporal spike trains, mapping them onto a 3D spiking neural network reservoir (SNNr) aligned with the Talairach brain atlas. The SNNr models spatiotemporal relationships between EEG channels using unsupervised spike-timingdependent plasticity (STDP), offering interpretable brain connectivity visualizations. Sam et al. [146] integrates a 3D brain-inspired SNN with an LSTM, leveraging SNN's energy efficiency with LSTM's temporal modeling capabilities."}, {"title": "D. Schizophrenia Identification", "content": "1) Task Description: Schizophrenia (SZ) is a psychiatric disorder affecting 24 million people worldwide, characterized by cognitive impairments, including memory deficits, delusions, and hallucinations [150]. SZ is associated with disruptions in structural and functional brain connectivity, marked by decreased global efficiency, weakened strength, and increased clustering [151]. These abnormalities are detectable in EEG signals, making them useful for binary classification to distinguish SZ patients from healthy controls. Table VI summarizes publicly available datasets for SZ research. A detailed overview of all related works is provided in Appendix Table XIV.\n2) Approach overview: Transfer learning has emerged as a powerful technique for fine-tuning pre-trained computer"}, {"title": "E. Alzheimer's Disease Diagnosis", "content": "1) Task Description: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that starts with mild memory loss and advances to severe cognitive impairment, affecting daily life. While medical interventions can improve quality of life, a definitive cure remains elusive [159]. Alzheimer's disease (AD) progresses through three stages: preclinical, mild cognitive impairment (MCI), and Alzheimer's dementia. Classification tasks typically distinguish MCI or Alzheimer's dementia from healthy controls. EEG abnormalities, such as slowed brain rhythms and desynchronization, serve as biomarkers for AD-related neurodegeneration [160]. Table VII summarizes publicly available datasets. A detailed overview of all related works is provided in Appendix Table XV.\n2) Approach overview: EEG abnormalities in Alzheimer's disease, such as disrupted functional connectivity and altered brain rhythms, provide critical insights into the neurological changes. Brain connectivity modeling in AD can be approached from several angles. One approach, as seen in ST-GCN [161], generates functional connectivity matrices that incorporate metrics like wavelet coherence and phase-locking value to simulate spatial and temporal dependencies in EEG signals. Alves et al. [162] uses functional connectivity matrices derived from Granger causality and correlation measures to emphasize the spatial structure of brain networks. Additionally, some studies focus on spectral analysis, such as Morabito et al. [163], who convert EEG data into 2D spectral images using FFT and process these images with techniques like discriminative DCssCDBM to identify hybrid features that highlight EEG patterns associated with AD."}, {"title": "F. Parkinson's Disease Diagnosis", "content": "1) Task Description: Parkinson's disease (PD) is a progressive neurodegenerative disorder marked by motor symptoms (tremors, rigidity, bradykinesia) and non-motor symptoms (depression, sleep disturbances, cognitive decline). In 2019, over 8.5 million people worldwide were living with PD [167]. EEG is widely used in PD research due to its noise resistance and sensitivity to neurological changes, such as slowing cortical oscillations and increased low-frequency power [168]. Most studies focus on supervised learning for binary classification, with some incorporating transfer learning. Table VIII summarizes publicly available datasets. A detailed overview of all related works is provided in Appendix Table XVI.\n2) Approach overview: Transforming raw EEG signals into 2D representations is a well-established approach for PD classification, with various techniques offering distinct insights. Spectrograms, generated via Gabor Transform, as in GaborPDNet [40], preserve time-frequency characteristics while minimizing information loss. Scalograms, created using CWT, provide another effective representation [169]. According to Chu et al. [170], power spectral density (PSD) mapping is another method, where specific frequency bands like highand low-a can serve as potential biomarkers for early PD diagnosis. Connectivity-based 2D representations can be obtained, like those applied by Arasteh et al. [171], compute directional connectivity and produce heatmaps that effectively capture inter-channel relationships across frequency bands."}, {"title": "G. ADHD Identification", "content": "1) Task Description: Attention-deficit/hyperactivity disorder (ADHD) is a neurodevelopmental disorder affecting around 3.1% of individuals aged 10-14 and 2.4% of those aged 15-19 [174]. It is categorized into three subtypes: Inattentive (ADHD-I), Hyperactive-Impulsive (ADHD-H), and Combined (ADHD-C) [175]. EEG is widely used alongside neuroimaging and physiological measures for ADHD diagnosis. However, deep learning remains underexplored, with most existing approaches relying on supervised learning and featurebased classification. Research focuses on binary classification tasks, and Table IX lists two publicly available datasets. A detailed overview of all related works is provided in Appendix Table XVII.\n2) Approach overview: Studies on ADHD diagnosis identify distinct EEG neurophysiological markers, particularly"}, {"title": "IV. UNIVERSAL PRE-TRAINED MODELS", "content": "In recent years, SSL has revolutionized EEG/iEEG analysis in neurological diagnosis. Emerging methods focus on generalizable SSL frameworks that integrate heterogeneous datasets during pre-training, overcoming the limitations of task- and dataset-specific models and enabling seamless adaptation to multiple downstream tasks. These innovations bring us closer to the development of universal neurodiagnostic models capable of addressing challenges across diverse clinical settings. Table X summarizes pre-trained SSL frameworks for multitask neurodiagnosis, organized by the SSL paradigms to align with their technical evolution analyzed in this section. While some frameworks extend to broader time-series data, such as BCI signals and motion sensor data, we focus on datasets and tasks directly relevant to neurological applications. Below, we further explore these frameworks, examining their contributions to unified pre-training strategies, multitask adaptability, and their potential to impact real-world applications."}, {"title": "A. Contrastive- and Predictive- Based Learning", "content": "a) Contrastive Predictive Coding: Early SSL approaches in EEG/iEEG analysis are largely based on the Contrastive Predictive Coding (CPC) paradigm [18], [71], which learns robust representations by predicting signal segments through contrastive learning. While these models employed generic architectures across neurophysiological tasks, they fail to achieve true cross-task generalization. As a result, they are trained separately on specific datasets, limiting their clinical applicability across diverse neurodiagnostic applications. CPC variants like TS-TCC [178] introduce a one-to-one feature transfer mechanism. This framework enables feature migration across tasks such as human activity recognition, sleep staging, and epileptic seizure detection, paving the way for broader multi-domain diagnostic generalization.\nBuilding on the foundational principles of CPC, two distinct approaches have emerged: contrastive learning (CL) and predictive-based variants. CL retains CPC's contrastive framework but emphasizes explicit instance-level discrimination through hand-crafted augmentations for positive/negative pairs, instead of CPC's autoregressive future state prediction. Predictive variants inherit CPC's structure but replace its autolearned latent contexts with manually defined features.\nb) Contrastive-Based learning: SeqCLR [67], inspired by SimCLR, employs contrastive learning to EEG data, enhancing similarity between augmented views of the same channel through domain-specific transformations. Adopting a mixed-dataset training approach, it unifies diverse EEG"}, {"title": "B. Reconstruction-Based Learning", "content": "a) Masked Autoencoding: The paradigm shift from CPC to masked reconstruction in SSL aims for higher data efficiency and scalability, inspired by cross-domain advances like masked language modeling in NLP (e.g., BERT [189]), with MAE's generative approach enhancing classification performance while avoiding complex negative sampling.\nNeuro2vec [70] extends masked reconstruction by integrating EEG-specific spatiotemporal recovery and spectral component prediction into a unified framework, utilizing a CNN-ViT hybrid architecture for patch embedding and reconstruction. CRT [182] further introduces multi-domain reconstruction through cross-domain synchronization of temporal and spectral features, replacing conventional masking with adaptive input dropping to preserve data distribution integrity, thereby improving robustness in physiological signal modeling. NeuroBERT [183] introduces Fourier Inversion Prediction (FIP), reconstructing masked signals by predicting their Fourier amplitude and phase, then applying an inverse Fourier transform. The spectral-based prediction framework inherently matches the physiological nature of EEG signals.\nb) Large-Scale Continuous-Reconstruction Models: Transformer architectures excel in neurodiagnostics due to their scalability and attention mechanisms, which adaptively capture global dependencies in irregular neural signals. BERTstyle pretraining, particularly masked reconstruction, enhances neurodiagnostic classification by enforcing robust contextual learning of latent bioelectrical patterns, which is crucial for distinguishing subtle neurological signatures. Their parallelizable training and tokenized time-frequency representations pave the way for scalable foundation models, driving large-scale pretraining in neural signal analysis."}, {"title": "V. CONCLUSION", "content": "This survey systematically reviews 448 studies and 46 public datasets to advance deep learning-driven analysis of EEG/iEEG signals across seven neurological diagnostic tasks:"}, {"title": "ACKNOWLEDGMENT", "content": "This work is supported by NSFC (62322606) and Zhejiang NSF (LR22F020005)."}]}