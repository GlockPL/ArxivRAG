{"title": "Socratic: Enhancing Human Teamwork via Al-enabled Coaching", "authors": ["Sangwon Seo", "Bing Han", "Rayan E. Harari", "Roger D. Dias", "Marco A. Zenati", "Eduardo Salas", "Vaibhav Unhelkar"], "abstract": "Coaches are vital for effective collaboration, but cost and resource constraints often limit their availability during real-world tasks. This limitation poses serious challenges in life-critical domains that rely on effective teamwork, such as healthcare and disaster response. To address this gap, we propose and realize an innovative application of AI: task-time team coaching. Specifically, we introduce SOCRATIC, a novel AI system that complements human coaches by providing real-time guidance during task execution. SOCRATIC monitors team behavior, detects misalignments in team members' shared understanding, and delivers automated interventions to improve team performance. We validated SOCRATIC through two human subject experiments involving dyadic collaboration. The results demonstrate that the system significantly enhances team performance with minimal interventions. Participants also perceived SOCRATIC as helpful and trustworthy, supporting its potential for adoption. Our findings also suggest promising directions both for AI research and its practical applications to enhance human teamwork.", "sections": [{"title": "1 INTRODUCTION", "content": "Consider your favorite sports team whether it is soccer, cricket, basketball, or another team sport - working together to achieve a common goal. Even though all the team members are trained professionals, some teams consistently outperform others. Indeed, a team of individual experts does not necessarily make for an expert team [3]; building a successful team requires the confluence of multiple factors [40]. Human factors research has identified key drivers of team effectiveness, including capability, coordination, communication, and coaching [83]. Through targeted training and interventions, human teams can significantly improve coordination and enhance their performance in collaborative tasks.\nCoaches play a crucial role in both team training and inter-ventions. Rather than performing tasks themselves, they enhance collaboration by offering expert insights. These insights are pro-vided both during task execution, such as in games, and during training sessions, such as in practice. While coaches are common in professional sports, integrating them into life-critical fields presents significant challenges [52, 74]. Resource constraints and a shortage of experts make it difficult to employ coaches during task execution. For example, in surgical teamwork, a coach could be invaluable in reducing preventable medical errors [39, 74, 92]. Reducing these errors would significantly improve patient health outcomes. How-ever, due to the shortage of medical professionals, it is not feasible for a specialist to continuously serve in this coaching role. Similarly, in aviation, coaches assist with simulation-based training, but they cannot accompany a flight crew on every flight [34].\nRecognizing the need for coaching assistance in life- and safety-critical applications, we propose an innovative use of artificial intel-ligence (AI): task-time team coaching. Specifically, we envision an AI agent that complements a human coach by monitoring a team during task execution and providing real-time guidance to improve teamwork, particularly in situations where the human coach may be busy or unavailable. While coaches offer a variety of feedback before, during, and after tasks, in this work, we limit our scope to delivering task-time feedback in time-critical tasks. For this setting,\nThis article is an extended version of an identically-titled paper accepted at the Inter-national Conference on Autonomous Agents and Multiagent Systems (AAMAS 2025)."}, {"title": "2 BACKGROUND", "content": "Before describing SOCRATIC, we present the concepts and related research that inform our approach.\n2.1 Collaborative Tasks\nTeamwork is fundamental to many human endeavors, spanning sce-narios such as sports, healthcare, aviation, and more. Our focus is on time-critical scenarios, such as healthcare and disaster response, where effective teamwork is crucial for mission success. Team-work occurs at various levels, ranging from large organizations to small ad-hoc teams. We focus on mission-oriented, sequential tasks, where an established team works toward a clearly defined mission (e.g., Fig. 2). Although the mission is well-defined, there are often multiple ways to achieve the task. Real-world challenges, such as uncertainty, information asymmetry, and partial observabil-ity, can create barriers to efficient teamwork and task completion. Finally, we consider teams composed of human members, either in human-only teams or hybrid human-AI teams.\nTo develop an Al agent capable of supporting such teamwork, the first step is to mathematically model the task and team dy-namics. Fortunately, research in multi-agent systems offers several established formalisms for modeling collaborative tasks, includ-ing belief-desire-intention frameworks, Markov models, and game theory [2, 7, 15, 19, 20, 24, 43, 46, 47, 71, 80, 82, 85]. In our work, we leverage decentralized multi-agent partially observable Markov decision processes (Dec-POMDPs) [51]. This choice is motivated by their ability to model tasks with well-defined missions, structured teams, time constraints, action uncertainties, and partial observabil-ity, as well as their prior use in modeling time-critical collaboration scenarios like disaster response [8, 12, 36, 37, 87].\nWe define a task as the tuple M = (n, S, A, \u03a9, \u03a4, O, R, \u03b3, h), where n is the number of agents, S, A = \u00d7\u00a1A\u00a1 and \u03a9 = \u00d7\u00a1\u03a9\u00a1 denote a state space, an action space and an observation space, respectively, T(s'|s, a) denotes a probability of a state s transitioning to another state s' given a joint action a = (a1,\uff65\uff65\uff65, an), O(o|s', a) is a probabil-ity of a joint observation 0 = (01,..., on) given a state s' and a joint action a, R is the task reward (objective), y is the discount factor, and h is the task horizon. In theory, a team could act optimally by computing a decentralized policy using Dec-POMDP solvers based on the task model. However, it is unrealistic to expect human team members to compute and execute such a policy flawlessly and without errors. Therefore, we draw on human factors research to model team behaviors and identify strategies for improving teamwork."}, {"title": "2.2 The Science of Human Teamwork", "content": "The science of human teamwork focuses on the question: What makes teams work? [68]. Over the past four decades, psychologists and human factors researchers have systematically identified the factors that make teamwork challenging and developed methods to improve it [9, 10, 65, 67]. We briefly review key insights that inform our work, while directing readers to recent survey by Tan-nenbaum and Salas [83] for more details. There is broad consensus that teamwork is especially challenging in time-critical scenarios, where success depends on the convergence of multiple factors. A major challenge is that humans often make suboptimal deci-sions due to bounded rationality [29, 30, 78] and limited situational awareness [13, 14, 54, 79], especially under time constraints. Hence, SOCRATIC does not assume perfect rationality or situational aware-ness from team members. Even teams composed of experts may not function optimally due to a lack of shared mental models, leading to poor coordination and even fatal errors [6, 22, 28, 40, 41, 90]. Thus, SOCRATIC explicitly considers team members' intent and allows for potential misalignment, which can lead to suboptimal teamwork.\nTo enhance teamwork, the science of teamwork recommends sev-eral methods and best practices, including effective communication, simulation-based training, and coaching \u2013 the latter being the focus of this paper. Coaches play a crucial role by assessing teamwork and providing feedback to improve it. While human coaches rely on their expertise and experience for these activities, the science of teamwork has developed principled methods and formalized best practices for coaching. Researchers have established robust methods for assessing teams [11, 16, 17, 32, 68] and generating targeted insights to enhance teamwork [4, 21, 55, 66, 94]. However, these assessments are typically post-hoc, lack automation, and are limited to contexts where a human coach is available. Thus, we explore the design of an AI coach capable of operationalizing these insights, detecting misalignments in team members' shared intents, and providing real-time feedback during task execution."}, {"title": "2.3 AI-Assisted Teamwork", "content": "Al-assisted human teamwork is an emerging area of research with applications being explored across various domains [23, 31, 56, 57, 62, 72, 74, 91]. For instance, DeepMind and Liverpool FC are in-vestigating data-driven approaches to analyze and enhance team strategies in football [86]. For applications in healthcare and disaster response, researchers have applied AI to analyze team conversa-tions and improve extended-duration teamwork [1, 33]. Closer to our focus on time-critical scenarios, domain-specific methods for automated teamwork assessment have been developed [16, 35]. However, these methods, to our knowledge, provide only post-hoc support, and AI has not yet been used for task-time coaching.\nApproaches for assessing and improving teamwork in human-robot or robot-only teams are also relevant to our work [63, 64, 84, 87, 95]. Research in human-robot collaboration introduces metrics for evaluating teamwork [26, 38, 50] and algorithms for improv-ing it [5, 45, 49, 70, 88]. However, these methods focus on training robots to work with humans. In contrast, our work centers on an AI agent that provides coaching and decision support, without directly performing the task. Closest to our work are the recent frameworks TIC [73] and TARS [98], which generate task-time interventions to enhance multi-agent teamwork. TARS uses Dynamic Epistemic Logic-POMDP to generate interventions through planning algo-rithms [98]. TIC employs Dec-POMDPs and multi-agent imitation learning to generate interventions through a learned model [73, 77]. However, these methods have not been applied or evaluated in settings with human team members.\nOur work builds on these methods but differs in key ways. First, we adopt a systems perspective to develop SOCRATIC that includes both an intervention algorithm and a user interface, enabling in-teraction with and coaching for human users. Second, our method-ology incorporates mechanisms to collect training data on human teamwork, including their cognitive states. Finally, we validate the effectiveness of the solution through human subject experiments."}, {"title": "3 SOCRATIC", "content": "We now describe SOCRATIC: the System for Objective Coaching through Automated Task-time Interventions for Collaboration. Draw-ing on multiple disciplines (Sec. 2), we begin by outlining the sys-tem's design requirements and architecture. We then detail its key components: a module for monitoring team performance, an algo-rithm for learning team behavior models, another for generating task-time interventions, and a user interface to communicate these interventions to the team. We illustrate SOCRATIC using two human-Al collaboration tasks, detailed in Sec. 4.1 and inspired by real-world scenarios, implemented on a web-based simulation platform."}, {"title": "3.1 System Overview", "content": "3.1.1 Scope. We limit our scope to collaborative tasks modeled as Dec-POMDPS (Sec. 2.1) and teams that include at least one human member. Importantly, we do not make assumptions about team members' rationality or expertise levels. As reviewed in Sec. 2.2, the science of teamwork identifies several key drivers of effective teamwork. In this proof-of-concept work, we focus on team align-ment\u00b9 \u2013 ensuring that the team is \u201con the same page.\u201d Misalignment is particularly common in time-critical scenarios, where teams may lack sufficient time to communicate and coordinate shared plans. Additionally, real-world factors such as partial observability, fatigue, and uncertainty can further degrade team member's understanding of each other's beliefs, desires, and intentions.\n3.1.2 Design Requirements. With this scope defined, we design So-CRATIC: an Al-enabled coaching agent to improve teamwork during task execution. The design process began by identifying system requirements through brainstorming sessions with an interdisci-plinary team of researchers in human factors, team training, AI, and usability. We determined that an AI agent capable of detecting misalignments in team members' intents and alerting the team to pause, reflect, and adjust their plans is both feasible to develop and can significantly enhance collaboration. For the successful realiza-tion and adoption of such an agent, we distilled key requirements (Rx); namely, SOCRATIC must be:\nR1. able to sense and monitor teamwork;\nR2. able to accurately infer intents of the team members;\nR3. able to accurately anticipate future actions of the team;\nR4. able to generate effective task-time interventions;\nR5. able to effectively deliver the interventions; and\nR6. perceived as useful by the team members.\nInvestigating other drivers of effective teamwork, intervention mechanisms, and teamwork settings is an important avenue for future research."}, {"title": "3.1.3 System Architecture", "content": "To meet the design requirements, So-CRATIC leverages recent advancements in imitation learning and multi-agent systems, incorporating an interactive user interface to monitor the team and deliver interventions. For R1 (sensing and monitoring teamwork), we assume SOCRATIC is equipped with sen-sors to observe both the team and task environment. Similar to sport scenarios, where team members may have partial observability, the coach has full visibility of the environment. To meet R2 (inferring intents) and R3 (anticipating future actions), SOCRATIC employs a recent multi-agent imitation learning algorithm BTIL that explicitly models team members' intents and learns a generative model of team behavior [77]. Building on this model, SOCRATIC utilizes a specialized instance of the TIC framework to generate task-time interventions to meet R4 [73]. Lastly, SOCRATIC includes a user interface to deliver these interventions to the team, addressing R5.\n3.1.4 System Operation. SOCRATIC operates in two phases: training and execution. During the training phase, SOCRATIC observes the team performing tasks in practice sessions, collecting teamwork data and learning generative models of team behavior. During task execution, SOCRATIC uses the learnt generative model to infer team intents, detect misalignments, and compute and deliver effective interventions. We now detail each system component."}, {"title": "3.2 Training Phase", "content": "3.2.1 Team Model. To effectively monitor the team, SOCRATIC builds upon a mathematical model of the task and team behavior. Having described the task model in Sec. 2.1, we now formalize the model of team behavior. Human decision-making often depends on factors beyond the task state, such as cognitive states corresponding to beliefs and intents [25, 48]. Hence, SOCRATIC explicitly models the influence of team members' intent - a latent variable on their behavior. More specifically, following the Agent Markov Model (AMM) [89], j-th team member's behavior is defined by the tuple Hj = (\u03a7, \u03c0j, \u03b6j; M), where X represents the set of possible task-specific intents, \u03c0j(a|x, s) denotes the team member's policy, and \u03b6j(x'|s', a, x) represents the intent transition model.\u00b2 While this model is well-defined, it is not trivial for domain experts to specify. Therefore, SOCRATIC leverages imitation learning to learn the model parameters from demonstrations collected during training sessions.\n3.2.2 Model Learning. In particular, SOCRATIC uses BTIL to learn the unknown parameters of the team behavioral model: \u03c0(a|s, x) and \u03b6(x'|s', x, a). BTIL is a multi-agent imitation learning algorithm that explicitly models latent decision factors, such as intents [77]. By leveraging a Bayesian approach, BTIL has been shown to attain sample- and label- efficient model learning from team demonstra-tions. Additionally, BTIL can learn from both optimal and sub-optimal demonstrations. This is especially important for SOCRATIC, as it learns the team model from demonstrations collected during practice sessions, where team behavior may not always be optimal. In practice, SOCRATIC'S model learning begins with the collection\n\u00b2Although team members' behavior may also depend on other latent factors, such as cognitive states and beliefs about unobserved parts of the environment, the decision to model only intent simplifies the system design. Our experiments confirm that this modeling choice is valid for the domains considered. However, we believe that performance of future AI-enabled coaching systems could be further enhanced by incorporating additional decision factors and more sophisticated behavioral models."}, {"title": "3.2.3 Team Monitoring", "content": "Equally critical to team modeling are the mechanisms for monitoring the team and collecting teamwork data: specifically, (s, a)-trajectories and annotations of (x) for a subset of the training data. In this proof-of-concept, we focus on collabo-rative tasks conducted through a web-based interface and develop methods for data collection and annotation specific to this setting, illustrated in Fig. 3 and detailed in Sec. 4.2. For real-world appli-cations, we recommend using multimodal sensors to monitor and gather teamwork data. We leave the exploration of related percep-tion challenges for future work, with relevant research directions discussed in Sec. 5. SOCRATIC uses the same monitoring mechanisms during the task execution phase, which we describe next."}, {"title": "3.3 Execution Phase", "content": "3.3.1 Intent Detection. SOCRATIC monitors the team during task execution, identifying potential misalignments in team members' intents and computing timely interventions. This capability is en-abled by TIC, a framework that has been experimentally shown to generate task-time interventions that enhance teamwork among AI agents [73]. We extend this framework to develop an AI-enabled coaching system for teams that include human members. During task execution, SOCRATIC can observe team members' states and actions, but their intents (a latent variable) remain unobservable. While SOCRATIC leverages a human annotator to obtain partial in-tent annotations during the training phase, involving a human in the loop during task execution is impractical. Therefore, to infer team members' intents, SOCRATIC frames the problem as one of Bayesian filtering. Specifically, given the learned model of team behavior (Hj\u2200j = 1 : n) and the partial (s, a)-trajectory of the team's task execution, SOCRATIC employs the forward-backward algorithm to infer each team member's current intent x\u0302.\n3.3.2 Intervention Generation. SOCRATIC next uses the inferred intents to assess whether the team is aligned. If the intended plans of the team members are likely to lead to suboptimal task performance, SOCRATIC intervenes by weighing the costs and benefits of the intervention. Under the TIC framework, determining this balance requires an intervention strategy, which can be hand-crafted or learned. For SOCRATIC, we opt for a learned, value-based strategy to minimize human effort in intervention generation. Specifically,\u00b3\n\u2022 SOCRATIC first computes the expected return (g) conditioned on the inferred intent: g(x|s) = E\u03c0,\u03b6[\u03a3t \u03b3t rt|s, x].\n\u2022 Next, SOCRATIC computes the intent values and return for a hypothetical fully aligned team as x\u2217 = arg maxxg(x|s) and g(x\u2217|s) = E\u03c0,\u03b6[\u03a3t \u03b3t rt|s, x\u2217], respectively. We define the benefit of an intervention as the difference between the optimal and estimated return: g(x\u2217|s) \u2013 g(x|s).\n\u2022 Finally, if the benefit of an intervention exceeds its cost c by a pre-defined threshold (i.e., g(x\u2217|s) - g(x|s) > c + \u03b4), then SOCRATIC prompts the team to pause, reflect on their plans, and recommends the optimal plan corresponding to x\u2217.\nChoosing an appropriate cost (c) and threshold (\u03b4) for interven-tions is crucial, as unnecessary or incorrect interventions could impair team performance and reduce human trust in, and adoption of, SOCRATIC. Sec. 4.3 outlines the approach for selecting these hy-perparameters for our implementation and evaluation of SOCRATIC.\n3.3.3 Intervention Delivery. To assist human team members, in addition to generating interventions, Socratic requires effective mechanisms for delivering these instructions. In this work, we utilize an interactive user interface for delivering interventions, as illustrated in Fig. 4 and detailed in Sec. 4.2. Since human team members can choose whether to accept the AI-generated recom-mendations, Socratic incorporates a hyperparameter pa, which models the probability of a human accepting its recommendation.\n\u00b3Since this computation relies on observations, task model, and the learned model of team behavior, it requires no additional human input or domain-specific knowledge."}, {"title": "4 FEASIBILITY STUDIES", "content": "We conducted human subject evaluations to assess the feasibility of AI-enabled coaching in enhancing collaborative task execution. The IRB-approved experimental protocols were designed to evaluate:\nQ1. Is SOCRATIC capable of learning a useful team model?\nQ2. Is SOCRATIC capable of improving team performance?\nQ3. IS SOCRATIC perceived as useful by human users?\nThe evaluations consisted of two studies: training and validation. Both studies involved dyadic teams completing two collaborative tasks. In the training study, we curated a novel dataset of human demonstrations, annotated with intents, to train SOCRATIC. In the validation study, we conducted a randomized controlled trial to evaluate the objective performance of Socratic and gather subjective feedback from participants regarding AI-enabled coaching."}, {"title": "4.1 Domains", "content": "We first describe the collaborative tasks used in our evaluations: Movers and Flood. Introduced in [73], these dyadic tasks require teams to maintain a shared plan for effective execution. However, due to partial observability and lack of communication, achieving coordination and high task performance is challenging.\n\u2074Validation Study: The experimental group received coaching from SOCRATIC, while the control group completed tasks without any AI-enabled coaching."}, {"title": "4.1.1 Movers", "content": "As shown in Fig. 2a, Alice and Rob are tasked with moving three boxes to the truck as quickly as possible. The boxes are heavy and require both teammates to lift them together. Teamwork is effective as long as the teammates agree on which box to move and act accordingly, regardless of the order. However, as depicted in Fig. 2b, each team member has a limited view of the environment and cannot communicate with the other during task execution, making coordination challenging. The task ends after 150 time steps or when all boxes are moved to the truck, whichever comes first. The cumulative team reward is defined as 150 minus the time step at which the task terminates."}, {"title": "4.1.2 Flood", "content": "The second task is inspired by time-critical disaster response scenarios. As shown in Fig. 2c, the environment includes victims at three sites: one at City Hall, two at the Campsite, and four at the Mall. A rescue team, consisting of a police car and a fire truck, must save all victims within a time limit of 30 time steps. While victims at City Hall and the Campsite can be rescued by a single vehicle, rescuing those at the Mall requires both vehicles to collaborate in repairing one of two bridges. Teamwork in this task is more complex: sometimes the team must work together (e.g., at the Mall), while in other cases, dividing sub-tasks is more efficient (e.g., at City Hall and the Campsite). As depicted in Fig. 2d, team members can only observe each other when at the same location or a landmark, complicating coordination. The total team reward is defined as the number of victims rescued within the time limit."}, {"title": "4.2 Study 1: Training", "content": "The first study focused on the training phase of SOCRATIC to collect training data and evaluate Q1. Forty participants (20 females, 20 males, mean age: 28.5\u00b14.9 years) completed the Movers and Flood tasks with a robot teammate, while also providing annotations of their task-relevant intent (x \u2208 X). For Movers, intent is defined as the box a team member plans to pick up or drop next. For Flood, intent refers to the site a team member plans to approach next.\n4.2.1 Materials and Setup. We developed a website using the Flask framework [18] that included the two tasks, complete with a user interface for task execution and intent labeling (Fig. 3). This plat-form enabled participants to perform the experiment remotely. Each participant was paired with a robot teammate, forming a dyadic human-robot team. Following Sec. 3.2.1, behavior of each teammate was modeled as Hj = (\u03a7, \u03c0j, \u03b6j; M). The robot (denoted as R) had its policy \u03c0R pre-trained using value iteration, and its intent dynam-ics \u03b6R were manually specified. The experiment aimed to collect data on the human teammate's (denoted as H) behavior in order to learn their policy \u03c0H and intent dynamics \u03b6H. Both teammates had to make decisions under partial observability and infer the intent of their teammate to complete the task successfully.\n4.2.2 Procedure. Upon providing informed consent, participants were introduced to the experiment and completed a demographic survey. They were then instructed to complete the dyadic tasks with the robot, following the same process for both Movers and Flood. This process included an interactive tutorial and four task trials. The tutorial introduced participants to the task and trained them on how to navigate the user interface (UI). The tutorial featured a guided scenario that mirrored the actual task. For each domain,"}, {"title": "4.2.3 Annotation", "content": "Training SOCRATIC requires both observable (s, a)-trajectories and time series data of team members' intents (x), which are latent and must be manually annotated. In this study, we collected intent data through participant reports, supported by user-centered annotation mechanisms to ensure reliable data collection. Recall that in both domains, intent is tied to a physi-cal location in the task scene, such as a box or a rescue site. To streamline reporting, we developed a \"Destination Selection\" UI, allowing participants to report their intended destination during task execution (Fig. 3b). Potential destinations are highlighted, and participants select their intended location with a mouse click. Par-ticipants are encouraged to update their intent when it changes and are prompted if five time steps pass without a report. Selected intents are visually indicated with a flashing red circle. Addition-ally, key actions like \u201cPick Up,\u201d \u201cDrop,\u201d or \u201cRescue\" are restricted to the selected destination, ensuring alignment between reported intents and actions. After each task trial, participants use the \"after-action review\" UI to verify and, if needed, correct their annotations (Fig. 3c). This interface replays the task execution, displaying both team actions and selected intents, allowing participants to confirm their reports. If discrepancies are found, participants can adjust incorrect intents using the \"Fix Destination\" button, improving the accuracy of the dataset used to train and validate SOCRATIC.\n4.2.4 Data Analysis. We collected 160 demonstrations per domain and trained SOCRATIC using a semi-supervised approach. Recogniz-ing that intent annotation is resource-intensive, we used only 30% of the intent labels for training and reserving the rest for valida-tion. This approach enables evaluating SOCRATIC in a more realistic setting, where only partial intent annotations are available."}, {"title": "4.3 Study 2: Validation", "content": "After collecting the training data, we conducted a second study to evaluate SOCRATIC's performance (Q2) and perceived usefulness (Q3). The study was a randomized control trial, where only the experimental group received coaching from SOCRATIC.\n4.3.1 Participants. We recruited participants via Prolific [53]. Of the 73 users who accessed the experiment, 61 completed it. To ensure balanced group sizes, we used the first 30 participants from each group. The control group consisted of 13 females and 17 males (age: 28.7\u00b18.4 years), while the experimental group included 11 females, 17 males, and 2 non-binary participants (27.8\u00b19.1 years).\n4.3.2 Materials and Setup. Similar to the first study, we developed a website featuring the two tasks with an interactive user interface. However, instead of intent annotation mechanisms, this version incorporated SOCRATIC on the backend and its user interface on the frontend for interacting with the team during task execution. As shown in Fig. 4, the interface features an Al coach icon with a speech balloon above the task screen. During task execution, the speech balloon nominally displays: \"Keep up the good work.\" However, if SOCRATIC detects misaligned intents and decides to intervene, it pauses the task, prompts the team to reflect on their plans, and recommends an optimal course of action corresponding to x\u2217. As illustrated in Fig. 4b, the speech balloon displays:\n\"I've spotted a potential opportunity to enhance our teamwork: Please (recommendation)\u201d.\nThe suggestion is highlighted with a red circle, and participants must click the \"Confirm\" button to resume the task. While SOCRATIC offers recommendations, participants ultimately decide whether to accept them. To account for the fact that not all recommenda-tions will be followed, we set pa = 0.9 for this study. SOCRATIC utilizes two additional hyperparameters: the cost of intervention c and the threshold \u03b4. For Movers, the intervention cost is set to 1, representing the loss of one time step to pause and reflect on the recommendation. In contrast, for the life-critical Flood task, the cost is considered negligible (c = 0) as any small delays caused by interventions are justified if they assist in rescue efforts. The threshold \u03b4 was determined through a grid search over the hyper-parameter space, with values set to 5 for Movers and 0.1 for Flood based on simulated experiments with the learned teamwork model."}, {"title": "4.3.3 Procedure", "content": "The overall structure of this experiment closely mirrors that of the first study. It is web-based and includes a study overview, a demographic survey, Movers and Flood domains, and a post-experiment survey. For each domain, participants completed an interactive tutorial followed by four task trials. While the tutori-als and trials were similar to the first study, intent annotation fea-tures were removed. Only for the experimental group, SOCRATIC'S features were integrated into the tutorial and task trials. Each do-main involved one practice trial to help participants familiarize themselves with the task and the robot teammate, followed by three test trials. Neither group received assistance from SOCRATIC during the practice trial. In the test trials, the control group per-formed the task without coaching, while the experimental group received task-time interventions from SOCRATIC. After the trials, participants completed the survey described next."}, {"title": "4.3.4 Measures", "content": "We assess Q1 by quantifying the intent-condition-ed success rate of the learned model. For Q2, team performance is evaluated using task scores. Beyond improving teamwork, the perceived usefulness of SOCRATIC is essential for its adoption by human users. Hence, to address Q3, we use subjective statements adapted from a widely used scale [26]. The first three questions solicited participants perception regarding the robot teammate, while the rest regarding SOCRATIC the AI coach. Control group rated the first three statements listed in Table 1, while the experimental group rated all statements. Responses were recorded on a 5-point scale, ranging from strongly disagree (1) to strongly agree (5)."}, {"title": "4.4 Experimental Results", "content": "4.4.1 SOCRATIC learns intent-driven models of team behavior. To address Q1, SOCRATIC first learns models of team behavior using the training data. We then evaluate if the learned model captures intent-driven behaviors by simulating the policy 1000 times for each intent x and measuring its success rate in completing the intended sub-task within 20 time steps. For instance, if the specified intent is to rescue victims at City Hall, we check how often the model succeeds. Table 2 presents the success rates of the learned model for each intent. Failures are categorized as either Wrong (where the model accomplishes a sub-task associated with a different intent, such as rescuing victims at the Camp Site when the specified intent was City Hall) or Nowhere (where the model fails to complete any sub-task within the time limit). On the challenging task of modeling team behaviors from human data, the model achieved an average success rate of 79% for Movers and 58% for Flood. Most failures belong to the Nowhere category, suggesting that model learns intent-driven models of team behavior. Through the second study, we find that this model learning performance is sufficient for SOCRATIC to deliver effective task-time interventions to improve teamwork."}, {"title": "4.4.2 SOCRATIC improves teamwork via targeted interventions", "content": "To answer Q2, we compared the performance of the two groups, using a cost-adjusted score that accounts for the time spent on processing and responding to interventions. Specifically, Score is defined as R - cC, where R is the cumulative team reward and C is the total cost of interventions. For the control group, Score is equal to the task score, as no interventions took place. As shown in Fig. 5, the experimental group outperformed the control group. In Movers,"}, {"title": "4.4.3 SOCRATIC is perceived as useful by human users", "content": "To answer Q3, we analyzed participants' survey responses. Fig. 6 displays the percentage of positive, neutral, and negative assessments for each statement. Responses to statements #1-3, which evaluated the robot teammate, were largely similar across both groups, indicating that participants had comparable perceptions of the robot teammate's capabilities. This consistency ensures a fair comparison between the groups, allowing us to accurately evaluate the AI coach's utility. Statements #4-9, which evaluated SOCRATIC and were rated only by the experimental group, indicate that participants perceived SOCRATIC as useful, effective, intelligent, and trustworthy. Based on these statements, the average rating of SOCRATIC was 3.81(\u00b11.03) for Movers and 3.28(\u00b11.32) for Flood on a 1-5 scale. Except for statement #8 for Flood task, the positive responses outweighed the negative ones for all statements.\nOpen-ended feedback suggested that SOCRATIC was seen as more helpful in the Movers task, while participants found Flood more challenging. Regarding statement #8, which asked about the timeli-ness of SOCRATIC 's recommendations, one participant commented:\n\"There was one occasion when the Al's suggestion came a bit late, causing me to waste a few moves.\"\nWhile SOCRATIC is already designed to provide proactive guidance using a predictive model of teamwork, participants' responses sug-gest that they value this proactivity and may expect even more planning support from an AI Coach. Informed by these findings, we conclude by summarizing our contributions and discussing their implications for both team training and AI research."}, {"title": "5 CONCLUSION", "content": "We introduce SOCRATIC: a system that provides AI-enabled coach-ing to teams with human members during task execution. Through human subject experiments on challenging dyadic tasks, we demon-strated that SoCRATIC not only enhances team performance but is also perceived as useful by participants. Since SOCRATIC does not perform the tasks itself, it has the potential to assist in various domains, including those where Al agents may lack the capability to act but can still analyze and enhance human task execution.\nAlong with its strengths, we also highlight the limitations of this proof-of-concept work, which suggest exciting future research directions. First, while the experimental tasks captured challeng-ing elements of real-world collaboration, they were conducted in a web-based environment. Future work should investigate AI-enabled coaching in more complex scenarios that include dynamic environ-ments, larger teams, multiple objectives, ad-hoc collaboration, or members with diverse expertise [75, 76, 80"}]}