{"title": "Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer", "authors": ["Sungmin Kang", "Jaeha Song", "Jihie Kim"], "abstract": "Understanding the morphological structure of medical images and precisely segmenting the region of interest or abnormality is an important task that can assist in diagnosis. However, the unique properties of medical imaging make clear segmentation difficult, and the high cost and time-consuming task of labeling leads to a coarse-grained representation of ground truth. Facing with these problems, we propose a novel Diffusion Transformer Segmentation (DTS) model for robust segmentation in the presence of noise. We propose an alternative to the dominant Denoising U-Net encoder through experiments applying a transformer architecture, which captures global dependency through self-attention. Additionally, we propose k-neighbor label smoothing, reverse boundary attention, and self-supervised learning with morphology-driven learning to improve the ability to identify complex structures. Our model, which analyzes the morphological representation of images, shows better results than the previous models in various medical imaging modalities, including CT, MRI, and lesion images. Our code and dataset are publicly available at githublink", "sections": [{"title": "Introduction", "content": "Medical image segmentation is crucial in improving our understanding of complex anatomy, providing critical insights for accurate medical diagnosis and precise treatment planning. This is especially important in computed tomography(CT) scans, where the intrinsic complexity of medical images presents unique challenges that require sophisticated solutions for organ segmentation. Unlike general images, CT images are quantitative imaging, and pixel intensities are normalized to Hounsfield units (HU) values[31]. (e.g., air as -1000 HU, bone as +400 to +1000 HU). Therefore, clinicians must understand the quantitative meanings and select the appropriate range to enhance the visual contrast of specific tissues or organs. In particular, research is conducted to find appropriate range values for each tissue or organ in CT scans[1, 31, 37, 41, 44] and studies show that segmenting CT images with an inappropriate HU range normalized leads to poor performance[22, 28]. This is because inappropriate normalization can occlude organs, as illustrated in Fig.1 (a). Additionally, clinicians can have different opinions in labeling[2, 7, 26, 39]. Due to this, ground truths are not determinstic, and it may be difficult to obtain detailed representations of organ or lesion labels. Inaccurate manual labeling can further increase the complexity of organ segmentation, as shown in Fig.1 (b). We address intrinsic challenges in medical images with an architecture that combines the advantages of the adaptive and resilient Swin Transformer encoder[33] with the efficient decoder in UNet[43]. We break away from the conventional Denoising U-Net[42] structure because we need a model that captures a global contextual representation and can handle the various medical imaging data. In addition, we introduce three approaches to improve the segmentation process further. First, distance-aware label smoothing[12, 57, 59] is a guidance mechanism that recognizes anatomical locations in the medical image and smoothes labels by calculating location-based distances. Second, reverse boundary attention captures areas of subtle and ambiguous boundaries. This component contributes to more precise and accurate segmentation by explicitly directing the model attention to edges [30, 51], especially in the regions that have not been manually labeled. Third, self-supervised learning [3, 16, 46] allows complex features of organs to capture meaningful representations from input images in a scenario of insufficient data. We reduce reliance on labeled data and improve model adaptability to diverse and complex features of medical images. Our proposed method demonstrates generalizability beyond medical images when we evaluate it with a different domain task that can utilize morphological information. Therefore, our contribution is summarized as follows.\n\u2022 We presents a new diffusion transformer segmentation(DTS) model which performs better than previous framework(i.e. CNN based Denoising Diffusion Probabilistic Model).\n\u2022 We introduce a novel approach to address the medical image segmentation by integrating morphology-driven learning into the image processing, such as k-neighbor label smoothing, reverse boundary attention, and self-supervised learning.\n\u2022 Our model demonstrates the generality in segmentation tasks in medical modalities such as CT, MRI, and lesion images and further suggests that this approach may be adaptable to other domains."}, {"title": "Related Work", "content": "The diffusion segmentation model which applies the generative diffusion process, allows users to manipulate the ambiguity of each time step through a hierarchical structure, solving the image quality and diversity problems of existing methods, allowing the learning process to proceed stably. There is research that has notable potential applied to medical imaging[17, 27, 53]. SegDiff[4], which showed consistent performance under various imaging conditions, is the first approach to solving the image segmentation problem by applying diffusion. The feature of this model is a mechanism that integrates the information of the input image and the current estimate of the segmentation map through each encoder and uses the decoder to improve the segmentation map iteratively. MedSegDiff[54] also applied the diffusion segmentation model to medical image segmentation. The input of the conditional image and noise segmentation map are integrated using a mechanism such as SegDiff, but high-frequency noise is constrained through the Fast Fourier transform module during the connection process. In addition, Diff-UNet[56] implemented the standard U-shaped architecture, which learns from the input volume in medical image segmentation effectively to extract semantic information. Here, we focus on the architecture and compare it with the existing diffusion segmentation model to demonstrate through experiments that the inductive bias, which is a major feature of CNN, can be replaced by ViT in diffusion segmentation.\nLabel Smoothing for Image Segmentation. Ground truth labeling for image segmentation is a time-consuming and intensive task involving experts. These processes are inherently subjective and susceptible to factors such as image quality, observer diversity, and difficulty depicting specific structures. Moreover, earlier label smoothing methods [14, 25, 32, 40, 49, 58], the inter-class relationships are usually overlooked since the labels are smoothed into one-hot encoding vectors. To address these challenges, we experimentally highlight the implementation of strategic label smoothing based on the spatial location of organs.\nReverse boundary attention refers to the integration of reverse attention[20, 36], which learns opposite concepts that are not associated with the target class in a way that substitutes existing attention mechanisms for objects, and boundary attention[5, 15, 45], which emphasizes pixels or features of parts related to the boundary. This mechanism plays a crucial role in enhancing the performance of object segmentation in medical images. This is particularly important because medical imaging, such as CT and MRI scans, often exhibit ambiguous organ boundaries and significant amounts of noise, posing challenges for accurate segmentation. Therefore, we explore the benefits of combining unique advantages, such as a reverse boundary attention mechanism, into our framework."}, {"title": "DTS: Diffusion Transformer Segmentation", "content": "The diffusion model is a generative model that consists of two stages: a diffusion process and a denoising process. In the diffusion process, Gaussian noise is added incrementally to the segmentation label xo over a series of steps t.\n$P_{\\theta}(x_{0:T-1}|x_T) := \\prod_{t=1}^{T} P_{\\theta}(x_{t-1}|x_{t})$\n(1)\n$P_{\\theta}(x_{t-1}|x_t) := \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_t,t), \\Sigma_{\\theta}(x,t))$\n(2)\nThe denoising process, parametrized by 0, involves training a neural network to recover the original data from the noise, and the distribution $p_{\\theta}(x_t)$ is defined as $N(x_T;0,I_{n \\times n})$ where I represents the raw image assumed to be an n \u00d7 n matrix. The denoising process then operates to transform the latent variable distribution $p_{\\theta}(x_t)$ (i.e. gaussian noise image) into the data distribution $p_{\\theta}(x_0)$ (i.e. final segmentation map).\ntransformer[33], which has advantages such as scalability and computational efficiency when processing various images due to its hierarchical structure. Also, similar to the conditional mechanism[38, 42, 47], our model incorporates another type of conditional encoder, \\tau_{\\theta} where the original image is used as input. These are demonstrated in the diffusion encoder and conditional encoder in Fig.2. Our method combines information from the current estimate $x_t$, the image I, and the time step index t to adjust the step estimate function $\\varepsilon_e$ at the input. It also takes the conditional image $\\tau_{\\theta}(I))$ and reconstructs it through a UNet decoder to produce the global feature map. Subsequently, the RBA modules facilitate the derivation of the final segmentation map, which exhibits precise edge representation, as detailed in Fig.3. In conclusion, DTS(\u00b7) represents our novel diffusion transformer segmentation model, which performs segmentation by integrating the described components.\n$\\varepsilon_{\\theta}(x_{t},I,t) = DTS((x_t,I),t, \\tau_{\\theta} (I))$\n(3)"}, {"title": "Morphology Driven Learning", "content": "k-Neighbor Label smoothing by organ distance. We explore medical data from body parts such as the abdomen and brain, which have organs or diseases located structurally within a compact space. As the relative positions of organs do not differ from person to person, we propose a k-neighbor label smoothing method that leverages the relative positions of organs for distance-aware smoothing of the labels of k neighbors for a given class or organ. In a multi-class (k > 2) situation, such as in this case, there is an advantage if there is a positional relationship between them. The positional relationship refers to the relative positional relationship of organs anatomically. As shown in Fig. 1 (b), the liver(+) is close to the gall bladder(\u25b2) but relatively far from the left kidney(). We provided semantic information to the model based on which body structure would match this prior knowledge. The equation of k-neighbor label smoothing (k \u2013 NLS) is:\n$d_{i} = {d_{xyz} | x, y, z \\in N,x < W, y <H,z <D}$\n(4)\nThe distance is calculated channel-wise, measuring the distance between a random point and the centroid of ith class.\n$y_t^{k-NLS} = Y_t + \\frac{\\alpha}{d + \\varepsilon}$\n(5)\nwhere yt is \"1\" for the target class and \"0\" for the rest of all, the label smoothing scale factor \u03b1 is crucial. Based on previous research[40] and empirical experiments on the BTCV dataset(Table.3), opting for \u03b1 as 0.1 yields optimal outcomes. & is constant le-6 to prevent division by zero, and $d_{x,y,z} = {d_0,d_1, ...,d_i | i = k}$ is a set of centroids and distances between each pixel and class. The pseudo code is expressed as follows:\nRBA: Reverse-boundary Attention. Complex anatomy and the inherent ambiguity in defining boundaries of adjacent organs are factors that hinder accurate segmentation of organ boundaries in medical images. Considering that these factors are likely to result in false positives or missing details in the initial segmentation, our approach includes selectively dropping or reducing the prediction weights of overlooked regions. The Reverse Boundary Attention method aims to improve the prediction of segmentation models by gradually capturing and specifying areas that may have been initially ambiguous. Thus, our architecture removes previously estimated predictive areas from high-level output features where existing estimates are upsampled in deeper layers, sequentially explores these details, including areas and boundaries, and finally, improves the segmentation model predictions progressively. In the Fig. 2, the global feature map which is the output of the decoder, is resized to match the input size using a convolution layer, and reverse attention[21] is then performed to obtain the weight R\u012f. Multiplying(element-wise this by the high-level output{$F_i, i = 0,1,2,3$} to obtain the output reverse attention RA\u012f.\n$R_i = (\\sigma(\\mathcal{U}(S_{i+1})))$\n(6)\n$RA_i = F_i R_i$.\n(7)\nwhere $\\mathcal{U}(\u00b7), \\sigma(\u00b7), (\u00b7)$ is up-sampling , sigmoid, reverse function respectively, The reverse function removes the matrix, which in all the elements is 1.\nAs shown below, the reverse attention weight RA; is passed through two convolution layers with normalization and finally the reverse boundary attention Si+1 is obtained.\n$S_{i+1} = \\mathcal{L}_{conv}(RA_i)$\n(8)\nSelf-supervised learning (SSL) can encode anatomical information of the human body in the image effectively. We propose three proxy tasks for learning comprehensive semantic representations within masked images without using labels. Our framework combines (1) Contrastive learning(e.g. SimCLR[10]), which encodes masked images to improve the ability to distinguish between different samples with hidden feature representations; (2) Masked Location Prediction, which predicts the location of the samples; and (3) Partial Reconstruct Prediction(e.g. SimMIM[55]), which learns the feature representation by reconstructing the masked patch area of each sub-volume. These widely recognized self-supervised learning strategies are both straightforward and effective.\nWhen the input(demonstrated 2D image in Fig.4) is divided into patches and then passed as input to the encoder twice, two sets of latent embeddings are obtained, and a contrastive learning is performed through constrastive loss[50] (Eq.9). Then, masked location prediction is conducted to predict the number of randomly masked parts by dividing the $h_i$ image into patches from 0 to 8 (Eq.10). In addition, Partial Reconstruct Prediction is performed by masking the image of $h_j$, reconstructing it through a decoder, and learning the difference from the original through L2 loss (Eq.11).\n$L_{CL} = -log\\frac{exp (sim (x_i, x_j) /\\tau)}{\\sum_{k=1}^{N}1_{k \\neq i, j}exp (sim (x_i, x_k) /\\tau)}$\n(9)\n$L_{Loc} = - \\frac{1}{|R|} \\sum_{n=1}^R v_nlog(\\hat{v}_n)$\n(10)\n$L_{Rec} = \\frac{1}{|R|} \\sum_{r \\in R}||y_r - \\hat{y}_r||2$\n(11)\nFinally, We minimize total objective loss functions combining partial reconstruction prediction, masked location prediction and contrastive learning losses, as follows:\n$L_{total} = L_{Rec} + \\lambda_1 L_{Loc} + \\lambda_2L_{CL}$\n(12)\nwhere $\\lambda_1, \\lambda_2$ are set to 0.1 and 0.01 respectively, as a result of empirical experiments."}, {"title": "Experiments", "content": "Datasets. The pre-training dataset consists of medical images sourced from partial accessible CT, MRI datasets encompassing 3,358, 6,970 subjects respectively. Notably, the pre-training step does not involve the utilization of annotations or labels on this dataset. The primary objective of this pre-training process is to enable the model to learn meaningful representations from the available image data, thus eliminating the need for manual annotation. The BTCV[29] dataset comprises 3D abdominal multi-organ CT images from 30 cases, each associated with a specific form and featuring 13 multi class segmentation objectives. The BraTS2021[6] dataset includes 1,251 subjects of brain MRI images. Each image is annotated with three segmentation targets and encompasses four modalities T1, T1Gd, T2, and T2-FLAIR. The ISIC2018[8] dataset contains 2,594 dermoscopic images of skin lesions, each annotated by experts for segmentation purposes. The Cityscapes [11] dataset contains several urban street scenes for segmentation purposes and is used to test the generalization performance of our approach. It consists of 3475 semantically annotated train, val sets and 1525 test set. Details about datasets are shown in the appendix.\nImplementation Details. Our architecture implemented in PyTorch and MONAI\u00b9. For pre-training tasks, the reconstruction strategy is applied with a mask ratio of 0.4. Moving on to the fine-tuning phase, the AdamW optimizer[35] is used with a weight decay 1e-3. The warm-up is set to 0.1 of the total epochs, and the learning rate undergoes linear updates following the Cosine Annealing schedule[34]. The loss function incorporates DICE loss[48], BCE loss, and MSE loss. Random flips, rotations, intensity scaling, and shifts were applied to augment the data. We set the number of diffusion steps as 1000, and the sliding window overlap rate is 0.8 until the final prediction. Preprocessing details for each dataset are provided in the appendix.\nEvaluation Metrics are important to quantify the performance of the segmentation model. Two commonly used metrics are the dice similarity coefficient[60](Dice) and the Hausdorff distance[23](HD). The evaluation metric are as define. Y and \u0176 represent the actual and predicted values in input units, and g' and p' represent the actual and predicted values of points on the surface.\n$Dice = \\frac{2 \\sum Y}{\\sum Y + \\sum \\hat{Y}}$\n(13)\n$HD = max{max_{g'\\in G} min_{p'\\in P}||g' - p' ||, max_{p'\\in P} min_{g'\\in G}||p' \u2013 g' ||}.$\n(14)\nExploring the performance of Label Smoothing We concentrate on the performance of k-neighbor label smoothing and explore its applicability to general datasets with structural properties. We explore its applicability to a cityscapes[11] dataset with structural properties by utilizing only our baseline model and label smoothing. Compared with basic label smoothing(uniform), Non-Uniform Label Smoothing(NULS), and especially Spatially Varying Label Smoothing(SVLS), which applies label smoothing to neighboring pixels using weight matrix in the form of Gaussian kernel, we can see that our performance is superior. Previous methods compensate for the label's uncertainty in image segmentation, but our methods further estimate the positional relationship between classes"}, {"title": "Efficiency of Self Supervised Objectives.", "content": "We conduct comprehensive ablation experiments on the BTCV dataset to evaluate the efficiency of self-supervised learning. In these experiments, we employed specific settings for calculating the loss, and the obtained results are presented in the Table.4. Notably, the $L_{Rec}$ is learned based on the pixel representation of input images, $L_{Loc}$ (Masked Location Prediction) is learned by recognizing the location of the masked region, and $L_{CL}$ (Contrastive Learning) is focused on contrastive learning at two augmented sample level. The $L_{Rec}$ lies in its important role in understanding meaningful representation learning from medical images, as shown in experimental results. By employing these three loss functions, our self-supervised learning approach aims to capture intricate details at both pixel and region levels, enhancing the model's ability to extract meaningful features from the the inputs."}, {"title": "Selecting the optimal architecture", "content": "Remind the our approaches, in the case of self-supervised learning (SSL), feature representations pre-trained from the three proxy tasks are transferred to the conditional encoder to assist in understanding the original image. We experiment with the effect of freezing or leaving all weights trainable during benchmark fine-tuning. Additionally, our framework explores the ablation study on reverse boundary attention, which is integrated with the general diffusion segmentation process. We comprehensively verify the effectiveness of morphology-driven learning within the architecture to prove its hypothesis. As shown in the Table.5, the single module experiments(presented in the second section) show higher performance than the scratch model, but learning by leaving the conditional encoder trainable shows a large margin in the BTCV dataset. This indicates that feature representation was achieved by aligning the learned features well with the downstream task. Our model, which comprehensively combines morphology-driven learning techniques, shows remarkable improvement in results, and our final architecture is shown in Fig. 2."}, {"title": "Comparative Results", "content": "As shown in Table.6, we compare our model with the BTCV benchmark dataset. Compared with other models, the proposed DTS achieves the best performance and presents a higher dice result of 0.906. It can be seen that previous diffusion segmentation models show comparable performance to conventional segmentation models in relatively large organs(e.g. liver, stomach), but poor performance in small organs(e.g. esophagus, aorta). DTS surpasses the closest competing methods by an average of 2% across all classes, with an even more significant improvement of 7% specifically for gall bladder. We believe that our approach and the application of the high performance transformer architecture will lead to improved accuracy. Comprehensive qualitative results of our model, which demonstrate good segmentation performance for small organs, can be found in Fig.5, highlighting our model's ability to capture details and achieve accurate boundary representations.\nThe results presented in Table.7 demonstrate that the two datasets showed optimal outcome with an average accuracy in terms of both Dice and HD score. In particular, within the ISIC dataset, solely K-neighbor label smoothing was omitted from the application. This decision was made due to the dataset has only a single label without structural position relationships between adjacent labels. Consequently, employing the K-neighbor label smoothing method in this specific scenario is unnecessary. Overall, SwinUNETR [19] has a competitive performance in the benchmark results. Although it uses a similar architecture as DTS, we believe that it does not lead to the robustness and of diffusion models, which excel against noise and artifacts in the input data, particularly in medical images."}, {"title": "Future work and Conclusion", "content": "Our study focuses on the advantages of morphology-driven learning for segmentation tasks, where our approach demonstrates substantial improvements. Building on these promising results, we aim to broaden the scope of our framework by applying it to other critical imaging tasks, such as classification and detection, to evaluate its effectiveness across various domains and imaging scenarios. In conclusion, we present a novel approach to medical image segmentation. DTS suggests the potential to replace existing CNN-based down-sampling by using a Swin Transformer encoder. We believe that this model architecture enables accurate segmentation with small, detailed representations and improves performance by complementing the chronic problems of medical images with Morphological-based learning, such as k-neighbor label smoothing, reverse boundary attention and self-supervised learning. We hope that this inspires future tasks in situations with morphologically complex problems."}]}