{"title": "Deep Autoencoder with SVD-Like Convergence and Flat Minima", "authors": ["Nithin Somasekharan", "Shaowu Pan"], "abstract": "Representation learning for high-dimensional, complex physical systems aims to identify a low-dimensional intrinsic latent space, which is crucial for reduced-order modeling and modal analysis. To overcome the well-known Kolmogorov barrier, deep autoencoders (AEs) have been introduced in recent years, but they often suffer from poor convergence behavior as the rank of the latent space increases. To address this issue, we propose the learnable weighted hybrid autoencoder, a hybrid approach that combines the strengths of singular value decomposition (SVD) with deep autoencoders through a learnable weighted framework. We find that the introduction of learnable weighting parameters is essential -- without them, the resulting model would either collapse into a standard POD or fail to exhibit the desired convergence behavior. Additionally, we empirically find that our trained model has a sharpness thousands of times smaller compared to other models. Our experiments on classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and forced isotropic turbulence datasets, demonstrate that our approach significantly improves generalization performance compared to several competing methods, paving the way for robust representation learning of high-dimensional, complex physical systems.", "sections": [{"title": "1. Introduction", "content": "Computational fluid dynamics involves solving large dynamical systems with millions of degrees of freedom, resulting in significant computational overhead. In order to alleviate this problem, reduced order modeling [1] is widely employed, which uses a smaller number of modes to provide approximate solution at lower computational expense. A crucial step in reduced-order modeling is the projection of system states to a reduced latent space. The projection error onto the latent space represents the overhead error that affects the solution accuracy throughout the time-stepping scheme. Linear dimensionality reduction techniques such as Proper Orthogonal Decomposition (POD) [2, 3, 4] are often used to create efficient representations of large-scale systems by projecting the solution manifold onto the space spanned by a set of linear orthonormal basis. Advances in deep learning techniques, such as deep autoencoders (AE) [5], capture intrinsic nonlinear features for better compression and retrieval of high-fidelity information, outperforming POD at lower ranks, thus overcoming the well-known Kolmogorov barrier [6, 7]. Milano and Koumoutsakos [8] highlighted one of the earliest works of utilizing a fully-connected autoencoder in reconstructing the flow field, offering better performance as compared to POD. Further studies have reported the usage of convolutional neural networks on 2D or 3D flow fields [9, 10, 11]. Such methods have been adopted in the fluid dynamics community to obtain a non-linear model order reduction [12], but they do not provide rapid error convergence at higher rank. Recently, there have also been studies on using hybrid approach [13, 14] combining POD with deep learning, by passing the latent space produced by POD to a neural network to find the corrections required to enhance the reconstruction. These hybrid techniques have proven to enhance the reconstruction beyond the capabilities of vanilla autoencoders. Following a similar path, here we propose a novel dimensionality reduction technique that combines traditional dimensionality reduction technique, i.e., POD, with deep learning techniques in a weighted manner at the encoder and decoder stage, where such weights of hybridization are also learnt from data, to achieve a more effective and flexible dimensionality reduction. We also compare this approach with a straightforward hybrid technique, where a direct sum of POD and AE is utilized to construct the autoencoder, demonstrating the need of using learnable weighting parameters between POD and AE. Interestingly, our proposed approach obtains a flat minima as opposed to other approaches, which contributes to the improved generalization and"}, {"title": "2. Methodology", "content": "Without loss of generality, we begin with sampling a general vector-valued spatial-temporal field u(x, t) \u2208 R\u00ba on a fixed mesh with N cells, where (x, t) is the space-time coordinate. At each time t, a cell-centered snapshot sample is a matrix x \u2208 RN\u00d7Q. In the current framework, we start with two encoders: 1) POD based encoder using r-dominant left singular vectors from the matrix consisting of stacked flattened columns of x, denoted as POD. 2) the neural network encoder with output dimension as r, denoted as \u00d3nn. As shown in eq. (1), the latent state z\u2208 R is obtained by a weighted sum of POD projection and the output of encoder,\nz = (1 - a)POD(X) + a\u00d8NN(x),\nwhere 1 \u2208 R\u201d is a vector of ones, and a \u2208 R\u201d is a vector of learnable weights. Next for the decoder part, we project the latent state z back to the reconstructed system state following eq. (2),\nX = VPOD(z) (I \u2013 B) + VNN(z)B,\nwhere I is Q \u00d7 Q identity matrix, B = diag(b), b \u2208 R, VPOD, and an are POD decoder and NN decoder, respectively. In addition to the parameters of NN encoder and decoder, both a \u2208 R\" and b \u2208 R\u00ba are trainable through gradient-based optimization as well. Hence, we name the above framework as learnable weighted hybrid autoencoder. It is important to note that such NN can be either fully-connected or convolutional.\nM\nGiven the training dataset D = {x}11, we trained the autoencoder by\nminimizing the mean-squared error (MSE) mine,a,B-1 ||xi-xi||2, where\n|| || is Frobenius norm, and refers to the set of the trainable parameters\nof neural network encoder \u00f8nn and decoder \u03c8nn. \u2299 is initialized using stan-\ndard Kaiming initialization [15]. Motivated by Wang et al. [16], we choose\nto initialize a and b with zeros, leading to the proposed framework being\nequivalent to the classical POD at the beginning of neural network training.\nThus, the model starts from the optimal linear encoder and becomes progres-\nsively nonlinear as the training proceeds. We choose Adam optimizer with\nlearning rate of 10-4 for \u0472 and 10-5 for a and B."}, {"title": "3. Datasets and model setup", "content": "3.1. Kuramoto-Sivashinsky (KS)\nThe governing equation of the KS equation is $\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} + \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^4 u}{\\partial x^4} = 0$,\nwhere x \u2208 [0, Lx), Lx = 64\u03c0, and periodic boundary conditions are as-\nsumed. The initial conditions comprise a sum of ten random sine and co-\nsine waves u(x, 0) = \u03a3\u03ba1 Ak (sin (\\frac{2\u03c0nkx}{Lx} + Ok) + cos (\\frac{2\u03c0nkx}{Lx} + \u03a6\u043a)), where\n\u2200k \u2208 {1,...,10}, Ak ~ U(\u22121,1),\u00a2k ~ U(0,2\u03c0), and wavenumber nk ~\nU{1, ..., 6}, respectively. We employ Fourier decomposition in space and 2nd\norder Crank-Nicolson Adam-Bashforth semi-implicit finite difference scheme\nfor temporal discretization. The data is generated for around 2000 time\nsteps with a timestep of 0.01. Grid sizes of 512, 1024 and 2048 is used for\nthe simulation. A few initial snapshots of the simulation that corresponds to\ntransient phase are ignored.\nFor the NN encoder, we use a feedforward neural network with one hid-\nden layers. Hyperbolic tangent function is used for activation in all layers\nexcept the last linear layer. The NN decoder is symmetric to the encoder.\nAfter shuffling, snapshot data is split into training and testing with 7:3 ra-\ntio. Before training, we standardize the data by subtracting the mean and\ndividing by the standard deviation. All models are trained for 40k epochs\nwith a batch size of 64.\n3.2. Homogeneous isotropic turbulence (HIT)\nDirect numerical simulation data of forced homogeneous isotropic turbu-\nlence is obtained from Johns Hopkins turbulence database [18]. The dataset\nis generated by solving the forced Navier Stokes equation on a periodic cu-\nbic box using pseudo-spectral method. We interpolate the velocity field,\nu(x,t) = (Ux, Uy, uz) \u2208 R\u00b3, from the original dataset of resolution 10243 to\ngrid sizes of 163, 323 and 643 and extract the data from timestep 1 to 2048\nwith a stride of 16, resulting around 128 snapshots.\nWe choose a deep convolutional autoencoder [19] as the NN part of the\nproposed framework. The NN encoder starts with 4 hidden layers of con-\nvolution, each followed by Swish activation. The number of filters increase\nfrom 256 to 2048 by a factor of two every layer. Then we flatten last layer\noutput and pass it through a linear layer to obtain the reduced space rep-\nresentation. The NN decoder is symmetric to the encoder. Dropout with a\nprobability of 0.4 was used at each layer of the encoder and decoder except\nthe output layer. Without shuffling, we systematically sample the dataset"}, {"title": "4. Discussion", "content": "4.1. Generalization performance and convergence\nTo demonstrate the effectiveness of the proposed approach, we compare\nour model against three other methods: POD, vanilla deep autoencoder\n(AE), simple hybrid autoencoder, as autoencoders for the two chaotic PDE\ndatasets in sections 3.1 and 3.2 with varying rank r and resolution N. Sixteen\nensembles of the model is trained by setting different random seeds. From\nfig. 2, both of the two hybrid approaches perform better than AE and POD.\nBut the simple approach doesn't maintain its convergence with increasing\nrank in contrast to our proposed approach. In addition, our approach shows\norders of magnitude improvement in generalization as compared to any of\nthe other methods. The simple and our learnable weighted hybrid approach\ngive nearly the same test error at low ranks, but their gap increases multi-\nple times with increasing rank. Surprisingly, such substantial improvement\nmerely requires a negligible additional trainable parameters (i.e. r+Q \u226a N),\nas shown in table 2. For this dataset the convergence of our approach follows\na SVD like convergence, while the simple approach has a behaviour similar\nto AE.\nFor the more challenging 3D HIT dataset, fig. 3 shows that our pro-\nposed approach continues to outperform the other three methods in terms\nof generalization, especially when the resolution increases (e.g., 323, 643 as\nopposed to 163). It is important to note that the simple approach shows\nlittle improvement over POD at resolution of 323 or 643 while our approach\nexcels. Again, this highlights the important role of learnable weights in our\nhybrid approach. Additionally for this dataset, we study the impact of activa-\ntion function on the reconstruction performance by utilizing ReLU activation\nfunction for the NN part of the auto-encoder. It is worth noting that the\nperformance of both the AE and simple hybrid approaches exhibit noticeable\nvariations when the activation function is changed. In contrast, our approach\nshows minimal changes in performance, demonstrating the robustness of the\nproposed framework. A further comparison among four models is shown\nin fig. 4, which visualizes the improvement in performance of our learnable\nweighted approach, especially on the small-scale turbulence. It is interesting"}, {"title": "5. Conclusions", "content": "In this work, we present a novel deep autoencoder framework that demon-\nstrates convergence properties akin to SVD. By incorporating a learnable\nweighted average between SVD and vanilla deep autoencoders (either feed-\nforward or convolutional), our approach achieves SVD-like convergence as\nthe rank increases. We validate the effectiveness of this framework on two\nchallenging chaotic PDE datasets: the 1D Kuramoto-Sivashinsky and the\n3D homogeneous isotropic turbulence. The results show that our learnable\nweighted hybrid autoencoder consistently achieves the lowest testing error\nand exhibits superior robustness to noisy data compared to other methods\nsuch as POD, vanilla deep autoencoders, and simple hybrid autoencoders.\nRemarkably, we find that our proposed approach leads to a minimum with a\nsharpness that is a thousand times smaller than that of other deep autoen-\ncoder frameworks, highlighting its potential for robust generalizable repre-\nsentation learning for complex PDE systems."}]}