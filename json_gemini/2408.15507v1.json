{"title": "What Machine Learning Tells Us About the Mathematical Structure of Concepts", "authors": ["Jun Otsuka"], "abstract": "This paper examines the connections among various approaches to understanding concepts in philosophy, cognitive science, and machine learning, with a particular focus on their mathematical nature. By categorizing these approaches into Abstractionism, the Similarity Approach, the Functional Approach, and the Invariance Approach, the study highlights how each framework provides a distinct mathematical perspective for modeling concepts. The synthesis of these approaches bridges philosophical theories and contemporary machine learning models, providing a comprehensive framework for future research. This work emphasizes the importance of interdisciplinary dialogue, aiming to enrich our understanding of the complex relationship between human cognition and artificial intelligence.", "sections": [{"title": "Introduction", "content": "What are concepts? This is arguably one of the fundamental questions in philosophy, with nearly as many answers as there are philosophers. Aristotle's Categories, Locke's compositional theory of ideas, Kant's transcendental logic, Hegel's concrete universals, Cassirer's Funktionsbegriff, and Wittgenstein's discussion of family resemblance are just a few notable examples of philosophical theories on concepts. Since the last century, philosophical inquiries into concepts have been further accelerated and enriched through interaction with cognitive science, which added an empirical dimension to the discussion. Various models of concepts, such as prototype theory, exemplar theory, and the so-called theory-theory, have been proposed, oftentimes in opposition to or drawing inspiration from existing philosophical theories, and brought to empirical scrutiny (Margolis and Laurence, 1999; Murphy, 2004). At the same time, the discussions"}, {"title": "The Abstractionism", "content": "According to abstractionism, concepts are formed through abstractions from individual data. For instance, the concept human is formed from individual humans by abstracting away idiosyncratic differences, say in height, hair color, or any physical and psychological characteristics. The abstraction process can be done in stages. The concept mammal may be formed by abstracting away differences among human, tiger, dog, etc., and by repeating a similar process one can obtain more general concepts such as animal, organism, and so on. The resulting upside-down tree-like structure is called the Porphyrian tree. Going up and down through this tree respectively correspond to abstraction and specification. Each downward branching of the tree represents logical disjunction, such as mammal = human V tiger V. Disjunction amounts to ignoring differences among the terms. Conversely, one may also create a concept through conjunction, like centaur = human horse, whereby the concept of a centaur is formed by combining the features possessed by humans and horses. Conjunction is represented by upward branching, which yields a lattice-like structure.\nThis way of looking at concepts, which Heis (2007) dubbed as \u201cAristotelian abstractionism,\u201d dates back to Aristotle's Categories and reached a certain level of perfection in the modern period, as witnessed in Arnauld and Nicole's Port Royal Logic and Kant's Logik (Igarashi, 2023). Modern logic made an explicit distinction between extents and intents. The extent is a set of objects to which a given concept applies, while its intent is a set of properties that defines the concept. For instance, the extent of human includes Socrates, Caesar, etc., while its intent would include such properties as being bipedal, rational, etc. A concept is fully identified by its intent, i.e., conditions that are separately necessary and jointly sufficient for being its instance, or in other words, the properties shared by all and only members of the corresponding extent.\nThe notion reminiscent of abstractionism extends beyond the boundaries of philosophy. Because concepts are essential building blocks of human thought and understanding, cognitive scientists have developed several models of concepts to characterize their cognitive functionalities in perception, memory, reasoning, language processing, and decision-making. The Classical Theory is one such theory that has often served as a foil for other views, and identifies a concept with the corpus of information pertaining to its defining attributes (Margolis and Laurence, 1999; Murphy, 2004; Machery, 2009). Along with its name, the resemblance to abstractionism should be clear.\nThe abstractionist conceptualization of concepts has also laid the foundational framework for initial AI research, notably influencing the development of the knowledge base for expert systems (e.g., Sowa, 2000). Expert systems aim to emulate the decision-making ability of human experts (e.g. medical doctors) by applying inferential rules to information stored in the knowledge base. The standard form of knowledge representation, often called ontology, stores infor-"}, {"title": "The Similarity Approach", "content": "As we have seen above, one major criticism against abstractionism was targeted at its essentialism that a concept is definable by a set of necessary and sufficient conditions, or its essence. Most real concepts seem to lack such essence. What, for example, are properties that are shared by all instances of game, which would presumably include football, Go, Tetris, and so on? Wittgenstein famously pointed out that what unites these games are not the shared properties but rather family resemblance, i.e., they are related via loose similarity relationship among objects. Similarity is symmetric but not necessarily transitive: I might resemble my maternal grand father and paternal grand mother, but they do not need to resemble each other. Likewise, an arbitrary pair of games, say football and Tetris, need not be similar or have shared properties. What make them game is the fact they resemble to other items that together form a cluster of objects we call game.\nSimilarity judgments depend on properties or standards under considerations. Two people may have similar body heights but not weights. To measure the similarity between objects, therefore, one first needs to determine a set of relevant properties or dimensions, which can take either continuous, discrete, or binary (yes or no) values, and then plot objects according to their value in each dimension. Suppose we have n relevant properties and let xi(a) be the value of the i-th property/dimension of an object a. One straightforward similarity measurement of a pair (a, b) of objects is a weighted sum of the absolute difference\n$\\sum_{i=1}^{n} w_i|x_i(a) - x_i(b)|$ (1)\nor the Euclidean distance\n$\\sqrt{\\sum_{i=1}^{n} w_i \\cdot (x_i(a) - x_i(b))^2}$ (2)\nwhere the weight w\u2081 gives the relative importance of the i-the property toward calculating similarity. A pair similar in this sense will be mapped closely in the n-dimensional property space. A concept, then, can be defined as a cluster in the high-dimensional space. Such a cluster may be \"cloud-like\" and need not"}, {"title": "The Functional Approach", "content": "Above we have seen that the similarity approach was prompted by the criticism on the essentialist aspect of abstractionism. The functional approach is inspired by another issue of abstractionism that permits an arbitrary concept formation through the abstraction of random objects, say the concept of red juicy food from cherry and raw meat (Lotze, 1874; Heis, 2007). A similar point may be raised against the similarity approach. Recall that in the similarity approach concepts are represented as regions or \"chunks\" in the metric space. Now consider abstracting these concepts. The straightforward way to do this is to combine all the regions corresponding to these concepts to form a greater region: for instance, mammal could be formed by combining all such clusters like human, dog, whale, etc. But obviously not any amalgamation would do: gerrymandered or isolated patches, like the notorious \"grue\" formed by all green things observed before a certain time t and blue things observed thereafter, should not make a bona fide concept (G\u00e4rdenfors, 1990). This means that there must be a certain restriction on the shape of a region or cluster for it to count as a concept.\nSuch a constraint can be represented by a certain functional relationship. According to this idea, a concept is not a mere combination of attributes or items but rather embodies a certain functional relationship among its possible features. Heis (2007) attributes this \"functional\" view of concept to Lotze:\nAs a rule, the marks of a concept are not coordinated as all of equal\nvalue, but they stand to each other in the most various relative\npositions, offer to each other different points of attachment, and so\nmutually determine each other; an appropriate symbol for the\nstructure of a concept is not the equation S = a + b + c + d, etc,\nbut such an expression as S = F(a, b, c, etc.) indicating merely that,\nin order to give the value of S, a, b, c, etc, must be combined in a\nmanner precisely definable in each particular case, but extremely\nvariable when taken generally. (Lotze 1874 \u00a728, quoted from Heis\n2007, p. 283)\nLotze's point is that a concept cannot be created by combining arbitrary features willy-nilly. It is rather characterized by its internal functional relationship, through which its possible attributes are constrained by each other. For instance, each concept that belong to animal should specify as its attributes the means for locomotion, reproduction, and respiration, etc, like dog = f(walking, viviparous, pulmonary, ...) (Asano, 2020). Moreover, these attributes are not independent from each other: e.g., the respiratory system of an organism should match its locomotive means. Lotze's proposal is that the concept animal should"}, {"title": "The Invariance Approach", "content": "The generative capability of concept manifolds, which allows one instance to morph into another, highlights a dynamic aspect of concepts, enabling various forms of inductive reasoning about hypothetical changes. When we classify an object under a certain concept, e.g. identify it as a face, we are at the same time attributing to it a various projections about how its appearance would change or would not change under possible transformations, say in perspective or the passing of time. As Cassirer puts it, \"the apprehension of the particular qua 'existence' involves apprehension of the possibilities of transformation which it contains within itself\" (Cassirer, 1944, p. 15). In the context of psychological research, the same idea underlies Gibson's pioneering work on affordance, which posits that animal perceptions encompass not merely sensory stimuli but also rich information about what the environment offers or affords the organism in terms of possibilities for action. This includes, for example, the organism's anticipation of how visual perception might alter upon moving through its surroundings (Gibson, 1979). This is echoed by Barsalou's perceptual theory of knowledge, which identifies a concept to be a \"simulator\" that allows the cognitive argent to mentally simulate different aspects and instances of a given category, say chair, in many different circumstances (Barsalou, 1999, p. 587).\nThe key insight here is that objects and their appearances change in a systematic fashion, and thus our recognition system must be robust enough to identify the object under different guises, while also being flexible enough to track these changes. These features are respectively captured by invariance or equivariance with respect to group actions (Cassirer, 1944; Hoffman, 1966; Dodwell, 1983; Jantzen, 2015). This framework first models various changes in objects or their appearance as transformations, represented by functions g: X \u2192 X where X is a set of items in question. For instance, if X is the set of visual images formed on the retina, a shift g in perspective changes one image x \u2208 X to another g(x) \u2208 X. The premise is that the set G of all such transformations forms a group, so that (i) it contains an identity or \"do nothing\" transformation e \u2208 G such that e.x = x for all x \u2208 X; (ii) for every transformation g \u2208 G there is an inverse \u201ccancellation\u201d g\u00af\u00b9 \u2208 G such that g. (g\u00ae1.x) = g\u00ae1.(g.x) = x for all x \u2208 X; and (iii) transformations are associative, so that (gi\u00b7gj)\u00b79k = gi\u00b7(9j\u00b79k) for any gi, 9j,gk \u2208 G. Changes in perspective, for instance, arguably satisfy these rules and thus present group actions on X.\nConceptualization can be understood as a function : X \u2192 R that maps objects or stimuli x \u2208 X to their representations \u03c6(x) \u2208 R. Such a representation map is called invariant with respect to group actions Gon X if actions do not affect representation, such that f(x) = $(g(x)) for all x \u2208 X and g \u2208 G . This means that however one transform an object x within the range of G, & still identifies them as the \"same thing.\u201d This is arguably a desirable feature of conceptual recognition, as the apprehension of \"what it is\u201d such as identifying whose face it is should not depend on a certain range of transformations like perspectival shifts. In other words, the ability to classify objects or stimuli into one concept, or \"the apprehension of the particular qua 'existence' \" as Cassirer puts it, involves determining the range of group actions G' CG with respect to which representation & remains invariant.\nOn the other hand, equivariance refers to the aspect of representations that \"tracks\u201d changes in objects. Perspectival shifts, for instance, though leaves in-"}, {"title": "Discussion", "content": "The preceding sections have examined various theories on concepts and representations in philosophy, cognitive science, and machine learning, classifying them into four categories: abstractionist, similarity, functional, and invariance approaches. This section compares these views from a meta-perspective, exploring their connections and deriving implications for further studies. By identifying the intersections and differences among these approaches, this discussion section aims to provide a clearer framework for interdisciplinary studies of concepts and representations.\nThe first axis for comparison is the role of concepts. Arguably, concepts play various roles in classification, learning, communication, problem solving, and so on; but these roles can be further understood through the lens of two major functionalities: descriptive and inferential. In the descriptive use, concepts serve to characterize and summarize data in various formats. Among the approaches discussed so far, the abstractionist and similarity approaches are particularly motivated by these descriptive tasks. The major goal of abstractionists is to"}, {"title": "Conclusion", "content": "This paper has explored the connections among various approaches to understanding concepts in philosophy, cognitive science, and machine learning, with a particular focus on their mathematical nature. By categorizing these approaches into Abstractionism, the Similarity Approach, the Functional Approach, and the Invariance Approach, we have highlighted the distinct yet interconnected ways in which concepts are represented, organized, and learned across different disciplines.\nEach approach offers unique insights into the nature of concepts. Abstractionism provides a structured, hierarchical framework that has influenced both philosophy and early AI research. The Similarity Approach, with its focus on resemblance and metric spaces, has been instrumental in both psychological theories and modern machine learning techniques, such as word embeddings. The Functional Approach introduces a dynamic perspective, emphasizing the internal relationships and constraints that govern concept formation, which aligns with the manifold learning methods used in generative models. Finally, the Invariance Approach, rooted in group theory, underscores the importance of understanding how concepts remain stable under transformations, a principle that is central to the robustness and generalizability of deep learning models.\nThis paper has also underscored the importance of interdisciplinary exchange. Philosophical insights into concepts can guide the development and refinement of computational models, while empirical findings in cognitive science and machine learning can offer new perspectives on longstanding philosophical questions. As AI continues to advance, the need for a deeper understanding of the representations used by machines becomes increasingly critical. By integrating the mathematical rigor of machine learning with the conceptual analysis of philosophy, we can move towards more transparent, interpretable, and robust models.\nNeedless to say, the exploration presented in this paper is only a preliminary sketch of the vast landscape of concept representation across disciplines. Notably, the implications of advanced machine learning models such as Attention mechanisms and Diffusion models have not been fully addressed, leaving significant avenues for further inquiry. Additionally, the relationships among the four categories-Abstractionism, the Similarity Approach, the Functional Approach, and the Invariance Approach-require deeper examination, as there may be further connections and insights to uncover. Consequently, systematic and comprehensive investigation remains necessary to deepen our philosophical and mathematical understanding of these interrelated approaches to concepts."}]}