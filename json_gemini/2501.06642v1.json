{"title": "COMMON SENSE IS ALL YOU NEED", "authors": ["Hugo Latapie"], "abstract": "Artificial intelligence (AI) has made significant strides in recent years, yet it continues to struggle with a fundamental aspect of cognition present in all animals: common sense. Current AI systems, including those designed for complex tasks like autonomous driving, problem-solving challenges such as the Abstraction and Reasoning Corpus (ARC), and conversational benchmarks like the Turing Test, often lack the ability to adapt to new situations without extensive prior knowledge. This manuscript argues that integrating common sense into AI systems is essential for achieving true autonomy and unlocking the full societal and commercial value of AI.\nWe propose a shift in the order of knowledge acquisition (ordo cognoscendi), emphasizing the importance of developing AI systems that start from minimal prior knowledge and are capable of contextual learning, adaptive reasoning, and embodiment\u2014even within abstract domains. Additionally, we highlight the need to rethink the AI software stack to address this foundational challenge. Without common sense, AI systems may never reach true autonomy, instead exhibiting asymptotic performance that approaches theoretical ideals like AIXI but remains unattainable in practice due to infinite resource and computation requirements.\nWhile scaling AI models and passing benchmarks like the Turing Test have brought significant advancements in applications that do not require autonomy, these approaches alone are insufficient to achieve autonomous AI with common sense. By redefining existing benchmarks and challenges to enforce constraints that require genuine common sense, and by broadening our understanding of embodiment to include both physical and abstract domains, we can encourage the development of AI systems better equipped to handle the complexities of real-world and abstract environments. This approach aligns with the ultimate goals of AI research and ensures that investments contribute to sustainable and meaningful progress.", "sections": [{"title": "1 Introduction", "content": ""}, {"title": "1.1 Background and Motivation", "content": "Artificial intelligence has achieved remarkable feats, from mastering complex games to enabling voice-activated as-sistants. However, despite these advancements, AI systems often lack common sense-the ability to understand and reason about the world in a way that all animals do. This deficiency becomes especially evident in autonomous agents operating in dynamic, real-world environments, such as self-driving cars, robotic assistants, and conversational systems, as well as in abstract problem-solving tasks like the Abstraction and Reasoning Corpus (ARC) challenge 1.\nFor instance, while AI-powered vehicles can navigate predefined routes using extensive sensor data and mapping, they may struggle with unexpected obstacles or novel scenarios that require adaptive decision-making. Similarly, AI systems tackling problem-solving challenges rely heavily on extensive training data, limiting their ability to generalize and reason beyond their programmed knowledge. Even AI systems that pass the Turing Test, capable of engaging in human-like conversation, may lack genuine understanding and common sense reasoning."}, {"title": "1.2 The Path to Autonomy Requires Common Sense", "content": "The central thesis of this manuscript is that common sense is all you need for AI to reach true autonomy and func-tionality comparable to human and animal intelligence. We assert that:\n\u2022 Current AI Approaches Are Inadequate:\nMany AI development workflows lack a focus on integrating common sense, leading to limitations in adapt-ability and understanding.\nAI systems built on these approaches may exhibit performance improvements but ultimately plateau, unable to achieve true autonomy.\n\u2022 Asymptotic Behavior Towards Theoretical Ideals:\nWithout common sense, AI systems may approach theoretical constructs like AIXI 3\u2014a hypothetical optimal agent-but never truly reach practical autonomy.\nAIXI requires infinite computational resources and time, making it unattainable in the real world.\nCurrent AI paths may lead to diminishing returns, demanding ever-increasing resources for marginal gains.\n\u2022 Focusing on Common Sense Is Essential:\nBy integrating common sense, AI systems can adapt to new situations, make intuitive decisions, and operate autonomously without exhaustive computational demands.\nThis focus aligns AI development with the practical capabilities exhibited by humans and animals."}, {"title": "1.3 The Need to Rethink AI Software Architectures", "content": "In recognizing the limitations of current AI systems in achieving true autonomy, it becomes apparent that we may need to rethink the entire software stack used in AI development. Traditional software architectures are often not designed to accommodate the integration of common sense reasoning. This realization is challenging, as it requires a departure from established methodologies and an openness to fundamentally new approaches. However, to develop AI systems capable of reliable and autonomous operation, redesigning the software stack to support common sense integration may be essential.\nOur approach questions whether incremental improvements within existing frameworks are sufficient. We propose that achieving true autonomy may necessitate a fundamental redesign of AI software architectures to incorporate mechanisms that enable contextual learning, adaptive reasoning, and embodiment, both physical and abstract. This shift may involve integrating concepts from cognitive science, neuroscience, and other disciplines to build systems that learn and reason in ways more akin to biological intelligence."}, {"title": "1.4 Objectives of the Manuscript", "content": "The main objectives of this manuscript are to:\n\u2022 Define Common Sense in Detail:\nProvide a comprehensive definition of common sense in the context of AI, emphasizing its components such as contextual learning, adaptability, starting from minimal prior knowledge, and highlighting its presence in all animals.\nIntroduce a broader concept of embodiment that applies not only to physical interactions but also to abstract domains, such as problem-solving tasks like the ARC challenge.\n\u2022 Analyze Current Problems and Approaches:\nExamine existing benchmarks like the ARC challenge, the Turing Test, and autonomous driving levels to highlight how they fall short in testing and developing common sense in AI systems.\nDiscuss how current AI development paths, without integrating common sense, may never lead to true auton-omy and instead require impractical resources.\n\u2022 Incorporate Expert Insights:\nReference perspectives from AI leaders like Yann LeCun and Eric Schmidt to underscore the recognized lim-itations of current AI systems compared to animal intelligence and to address concerns about self-improving \u0391\u0399.\n\u2022 Propose a Shift in Development Focus:\nArgue for the importance of developing common sense-focused variants of existing problems, suggesting that achieving partial success on these more challenging tasks is more valuable than full success on tasks that do not truly test common sense.\nAdvocate for rethinking the AI software stack to better support the integration of common sense.\n\u2022 Address Theoretical Counterarguments:\nDiscuss theoretical challenges, such as the No Free Lunch Theorem, and demonstrate how constraining the problem space to well-defined domains mitigates these limitations.\n\u2022 Provide Actionable Recommendations:\nOffer practical steps for the AI community to redesign benchmarks, develop new evaluation metrics, and em-brace interdisciplinary collaboration to prioritize common sense in AI development."}, {"title": "2 Defining Common Sense in AI", "content": ""}, {"title": "2.1 Detailed Definition of Common Sense", "content": "Common sense in Al refers to the ability of a system to understand, learn, and reason about the world in a way that is flexible, contextual, and adaptable, much like humans and animals do. Key components include:\n\u2022 Contextual Learning:\nDefinition: The capacity to interpret and respond to new information based on the context in which it occurs.\nImportance: Enables AI systems to adjust their behavior in real-time, considering the nuances of each situation.\nExample: Recognizing that a stop sign is still a stop sign even if partially obscured by foliage or graffiti.\n\u2022 Adaptive Reasoning:\nDefinition: The ability to modify reasoning strategies when faced with novel or unexpected situations.\nImportance: Allows AI to handle scenarios not explicitly programmed or encountered during training.\nExample: Adjusting navigation when a usual route is blocked due to unforeseen circumstances.\n\u2022 Embodied Cognition:\nDefinition: Understanding that arises from an Al's interactions with environments, which can be physical or abstract, integrating sensory and motor experiences.\nImportance: Grounds the Al's reasoning in experiences, leading to more intuitive and practical decision-making."}, {"title": "2.2 Embodiment Beyond the Physical World", "content": "While embodied cognition traditionally refers to physical interaction with the real world, we propose a broader concept of embodiment that includes interactions within abstract or virtual domains. In this context, embodiment signifies an Al system's ability to engage with any environment-physical or abstract-through perception and action.\n\u2022 Cognitive Embodiment:\nDefinition: The process by which an AI system interacts with and learns from an abstract environment, such as mathematical problems, puzzles, or logical tasks.\nExample: In the ARC challenge, an AI system manipulates and interprets abstract patterns and rules to solve tasks, embodying cognition within that constrained domain.\n\u2022 Importance of Generalized Embodiment:\nRecognizes that common sense arises from interaction with structured environments, not solely from physical experiences.\nAllows AI systems to develop common sense by learning from a variety of domains, enhancing their adaptabil-ity and reasoning capabilities.\nBy embracing both physical and abstract forms of embodiment, we expand the potential for AI systems to acquire common sense across diverse contexts. This generalization is crucial for tasks like the ARC challenge, where physical embodiment is not applicable, but cognitive embodiment plays a significant role."}, {"title": "2.3 All Animals Exhibit Common Sense", "content": "It is important to recognize that common sense is not exclusive to humans; all animals exhibit common sense essential for their survival. Common sense in animals refers to the innate and learned behaviors that enable them to:\n\u2022 Interact Effectively with Their Environment:\nAnimals use their senses to navigate their surroundings, locate food and water, and find shelter.\n\u2022 Avoid Danger and Threats:\nInstinctive responses, such as fleeing from predators or avoiding hazardous environments, demonstrate an un-derstanding of threats.\n\u2022 Adapt to Changing Conditions:\nAnimals adjust their behaviors in response to environmental changes, such as seasonal shifts, resource avail-ability, or social dynamics.\n\u2022 Reproduce and Ensure Species Continuity:\nBehaviors related to mating, nurturing offspring, and social cooperation contribute to survival and propagation."}, {"title": "3 Limitations of Current AI Benchmarks", "content": ""}, {"title": "3.1 Analysis of the ARC Challenge", "content": "The Abstraction and Reasoning Corpus (ARC) is a set of tasks designed to evaluate an AI system's ability to generalize and reason abstractly. While it aims to move beyond pattern recognition toward cognitive reasoning, several limitations hinder its effectiveness in testing for true common sense:\n\u2022 Use of Prior Knowledge Beyond Assumed Knowledge:\nCurrent Practice:\n* Al systems often utilize the 400 training problems and may even indirectly access the 400 test problems during development.\nIssue:\n* There is nothing inherently preventing AI systems from including these problems in their training data, leading to over-reliance on specific examples rather than developing general reasoning abilities.\nConsequence:\n* Al systems may appear successful on ARC tasks but lack genuine common sense, as they rely on memorized solutions rather than contextual understanding.\n\u2022 Not Starting from a Tabula Rasa:\nProblem:\n* The inclusion of extensive prior examples prevents AI systems from approaching problems with minimal preconceptions.\nImpact:\n* This hinders the evaluation of an AI's ability to reason and adapt to entirely new situations, a key aspect of common sense.\n\u2022 Lack of Cognitive Embodiment:\nObservation:\n* While ARC operates in an abstract domain, it requires AI systems to engage in cognitive embodiment by interacting with and learning from the problem environment.\nIssue:\n* AI systems often fail to embody cognition within this abstract domain, instead relying on pattern matching without deeper understanding or adaptability.\n\u2022 Resource-Intensive Solutions with Limited Common Sense:"}, {"title": "3.2 Case Study: Full Self-Driving (FSD) and SAE Levels", "content": "The development of Full Self-Driving (FSD) vehicles provides a practical example of the limitations arising from not prioritizing common sense.\nUnderstanding SAE Levels of Autonomy:\n\u2022 Level 1 to Level 4:\nLevels 1-3:\n* Involve increasing degrees of automation but still require human intervention in specific circumstances.\nLevel 4:\n* Vehicles can operate without a driver in specific conditions or geofenced areas.\n* May require remote human intervention for edge cases or unexpected situations.\nLimitation:\n* The AI systems lack the common sense to handle all possible scenarios independently, thus relying on remote assistance.\n\u2022 Level 5 (Full Autonomy):\nIntended to operate without any human input, remote or otherwise, under all conditions and environments.\nChallenge:\n* Without integrating common sense, reaching Level 5 is unattainable. AI systems may continue to improve incrementally but will asymptotically approach a ceiling where true autonomy is unachievable due to the lack of common sense reasoning.\nThe Role of Common Sense in FSD:\n\u2022 Handling Unpredictable Scenarios:"}, {"title": "3.3 The \"Magic Happens Here\" Phenomenon", "content": "In AI development workflows, there is often an implicit assumption that certain complex capabilities, such as common sense reasoning, will emerge naturally from incremental improvements. This leads to a critical gap:\n\u2022 Undefined Processes:\nDescription:\n* The progression from current capabilities to full autonomy lacks a concrete plan for integrating common sense.\nImplication:\n* Developers may proceed through a series of steps, but the crucial component, common sense, is not system-atically addressed.\n\u2022 Asymptotic Limitations:\nObservation:\n* AI systems may show initial progress but eventually exhibit asymptotic behavior, where further improve-ments require disproportionate resource investments with minimal returns.\nAnalogy to Theoretical Ideals:\n* Similar to approaching the theoretical AIXI agent, AI systems may get closer to optimal performance in theory but remain impractical due to resource constraints.\n\u2022 Risks Associated with This Approach:\nStagnation:"}, {"title": "3.4 The Contributions and Limitations of Scaling", "content": "Acknowledging the Achievements of Scaling in AI:\nScaling AI models by leveraging vast amounts of data, computing power, and sophisticated architectures has led to significant advancements, particularly in applications that do not require autonomy. These achievements include:\n\u2022 Enhanced Performance in Specific Domains:\nNatural Language Processing (NLP):\n* Large language models like GPT-3 and GPT-4 generate coherent and contextually relevant text, aiding in tasks such as translation, summarization, and content creation.\nComputer Vision:\n* Advanced models excel in image recognition, object detection, and even image generation, impacting fields like healthcare imaging and autonomous inspection.\n\u2022 Practical Applications and Societal Benefits:\nHealthcare:\n* AI aids in diagnosing diseases, analyzing medical images, and personalizing treatment plans.\nFinance:\n* AI enhances fraud detection, algorithmic trading, and customer service through chatbots.\nEntertainment and Media:\n* AI algorithms curate personalized content recommendations, create music, and generate visual effects.\nThe Limitations of Scaling for Achieving Autonomy:\nWhile scaling brings advanced capabilities that are undeniably beneficial, it is important to note that autonomy is not achieved through scaling alone. The limitations include:\n\u2022 Lack of Common Sense and Understanding:\nScaled models often operate as statistical learners, lacking true understanding of context or the ability to adapt to unforeseen situations.\n\u2022 Inability to Function Autonomously in Complex Environments:\nWithout common sense, AI systems struggle with reliable decision-making in dynamic, real-world or abstract environments, which is essential for autonomy.\n\u2022 Dependence on Pre-Defined Data:\nScaled AI models require extensive training data and may not perform well when encountering scenarios out-side their training distribution."}, {"title": "3.4.1 Evidence of Performance Plateaus in AI Benchmarks", "content": "While scaling AI models has driven remarkable progress, there is growing evidence of a plateau effect, where in-creasing resources yields diminishing improvements in performance. Several prominent AI benchmarks illustrate this phenomenon:\n\u2022 Object Detection on COCO:\nDespite extensive efforts to scale models and datasets, top-performing models on the COCO dataset have stalled at around 65% mean Average Precision (mAP) for over a year [Papers With Code, 2025a].\n\u2022 Anomaly Detection in Surveillance Videos on UCF-Crime:\nPerformance on the UCF-Crime dataset has plateaued at approximately 87% Area Under the Curve (AUC), un-derscoring the limitations of current methods in handling real-world complexities [Papers With Code, 2025b].\n\u2022 Temporal Action Localization on ActivityNet-1.3:\nResults on the ActivityNet-1.3 benchmark remain stagnant, with performance hovering around 11% mAP over the past year [Papers With Code, 2025c].\nThese benchmarks provide concrete evidence of the asymptotic behavior of contemporary AI systems. Despite sub-stantial increases in computational resources and dataset sizes, performance improvements have reached a plateau, reflecting the diminishing returns of scaling alone.\nThis stagnation is not limited to specific benchmarks. Industry leaders, including Elon Musk, have highlighted that the AI field has effectively exhausted the supply of high-quality training data, further limiting the potential for continued scaling [Wiggers, 2025]. Without integrating novel approaches such as common sense reasoning and more efficient data utilization, AI systems are unlikely to overcome these limitations. Current models excel at recognizing patterns within predefined contexts but struggle to generalize to unseen scenarios\u2014a critical challenge that must be addressed to achieve further breakthroughs."}, {"title": "4 The Correct Ordo Cognoscendi: Focusing on Common Sense", "content": ""}, {"title": "4.1 Redefining the Approach to AI Challenges", "content": "To achieve true autonomy in AI systems, it's imperative to revisit and redefine our approach to AI challenges. The traditional method of incrementally improving AI capabilities without explicitly integrating common sense has proven insufficient. Instead, we advocate for a paradigm shift that prioritizes the development and assessment of common sense in Al from the outset.\nRethinking the AI Software Stack:\n\u2022 Fundamental Redesign:\nConsider restructuring the underlying software architectures to better support common sense integration.\n\u2022 Incorporating Principles from Cognitive Science and Neuroscience:\nLeverage insights into how biological systems process information to inform AI design.\n\u2022 Building Systems for Embodied Cognition:\nDevelop AI that can engage in both physical and cognitive embodiment, interacting with environments to learn and adapt.\nFocusing on Common Sense Variants of Existing Problems:\n\u2022 Redesigning Benchmarks Like ARC:"}, {"title": "4.2 Advantages of Tackling Harder Problems First", "content": "While it may seem counterintuitive to begin with more challenging problems, focusing on common sense-centric tasks offers several significant benefits:\nPromoting Deep Understanding:\n\u2022 Quality Over Quantity:\nAchieving even partial success on complex, common sense-focused challenges demonstrates that the AI has developed meaningful reasoning abilities.\n\u2022 Building Robust Foundations:\nThis approach ensures that the AI system's capabilities are grounded in fundamental understanding rather than superficial pattern recognition.\nAccelerating Long-Term Progress:\n\u2022 Avoiding Diminishing Returns:\nInvesting in the core issue of common sense prevents the plateauing effect seen in current AI development paths.\n\u2022 Paving the Way for True Autonomy:\nBy overcoming foundational challenges early, subsequent advancements can build upon a solid base, leading to more significant and sustainable progress.\nReducing Resource Wastage:\n\u2022 Efficient Use of Computational Resources:\nFocusing on common sense reduces the need for massive datasets and extensive computational power, which may not yield proportional improvements without foundational reasoning abilities."}, {"title": "5 Theoretical Counterarguments and Resolutions", "content": "Developing AI systems with common sense faces several theoretical challenges. However, by constraining the problem space to well-defined domains and adopting appropriate strategies, these limitations can be mitigated."}, {"title": "5.1 Addressing the No Free Lunch Theorem", "content": "Understanding the No Free Lunch (NFL) Theorem:\n\u2022 Definition:\nIn the context of optimization and search algorithms, the NFL theorem states that no single algorithm can perform optimally across all possible problems.\n\u2022 Implications for AI:\nSuggests that an AI optimized for one set of problems may perform poorly when faced with a different set, posing a challenge for creating general-purpose AI systems.\nMitigating NFL Limitations by Constraining the Problem Space:\n\u2022 Focusing on Well-Defined Domains:\nBy limiting the AI's problem space to specific, well-understood domains\u2014whether they are physical environ-ments or abstract problem spaces-we reduce the applicability of the NFL theorem.\n\u2022 Exploiting Structural Regularities:\nDomains often exhibit consistent patterns and structures that AI can learn and generalize from, improving performance.\n\u2022 Argument for Feasibility:\nBiological Systems as Proof:\n* Humans and animals effectively navigate and reason within their environments despite the NFL theorem, indicating that it's possible to develop intelligent systems optimized for specific domains.\nSpecialization is Acceptable:\n* A system doesn't need to solve every conceivable problem but should perform well within the domain it is designed for."}, {"title": "5.2 Overcoming Other Theoretical Challenges", "content": "The Frame Problem:\n\u2022 Definition:\nThe challenge of determining what is relevant in a given situation and what can be ignored when reasoning about action and change.\n\u2022 Resolution through Embodied Cognition:"}, {"title": "6 Constraining the Problem Space to Well-Defined Domains", "content": ""}, {"title": "6.1 Structured Domains as Environments", "content": "The effectiveness of AI systems in acquiring common sense is enhanced when operating within structured domains\u2014environments that have consistent rules, patterns, and constraints. These domains can be physical, such as the real world, or abstract, such as mathematical problem spaces or game environments.\nCharacteristics of Structured Domains:\n\u2022 Defined Rules and Constraints:\nDomains have specific rules that govern interactions, which can be physical laws or logical principles.\n\u2022 Observable Regularities:\nRepeating patterns and structures enable recognition and prediction, facilitating learning.\n\u2022 Finite and Relevant Scenarios:\nThe set of possible scenarios is manageable and relevant to the AI's functions, allowing for effective modeling."}, {"title": "6.2 Implications for AI Development", "content": "Simplification of Complexity:\n\u2022 Reduction of Possibility Space:\nBy focusing on structured domains, the infinite possibilities considered in theoretical arguments are narrowed to a finite, manageable set.\n\u2022 Exploitation of Domain Regularities:\nAI can learn from and generalize based on consistent patterns present in the environment.\nAlignment with Human and Animal Learning:\n\u2022 Embodied Interaction:\nJust as humans and animals learn through interaction with their environments, AI systems can develop common sense by engaging with structured domains.\n\u2022 Grounding Knowledge:\nDomain constraints help ground AI reasoning in tangible experiences or logical principles, enhancing under-standing and adaptability.\nPractical Development Strategies:\n\u2022 Hierarchical Learning Models:\nImplementing layered architectures that process information from basic inputs to abstract reasoning.\n\u2022 Continuous Learning and Adaptation:\nAllowing AI systems to learn over time, adjusting to new information and changing environments within the domain."}, {"title": "7 Practical Steps to Integrate Common Sense", "content": ""}, {"title": "7.1 Redesigning Benchmarks and Challenges", "content": "Modifying Existing Benchmarks:\n\u2022 Enhancing the ARC Challenge:"}, {"title": "7.2 Developing New Evaluation Metrics", "content": "Assessing Cognitive Processes:\n\u2022 Explainability and Transparency:\nRequire Al systems to provide explanations or justifications for their decisions, allowing evaluators to assess the presence of common sense reasoning.\n\u2022 Measuring Adaptability and Learning Efficiency:\nTrack how quickly and effectively AI systems learn from new experiences or adapt to changes within their domain.\nFocusing on Resource Utilization:\n\u2022 Efficiency Metrics:\nEvaluate the computational and data resources required to achieve performance levels, promoting solutions that are resource-effective.\n\u2022 Scalability Assessments:\nDetermine how well AI systems maintain performance when scaled to more complex tasks or larger domains, indicative of robust common sense capabilities."}, {"title": "7.3 Embracing Interdisciplinary Collaboration", "content": "Integrating Insights from Other Fields:\n\u2022 Cognitive Science and Neuroscience:\nLeverage understanding of human and animal cognition to inform AI architectures and learning models.\n\u2022 Philosophy and Ethics:\nIncorporate ethical reasoning frameworks and philosophical perspectives on knowledge and understanding.\nCollaborative Research Initiatives:"}, {"title": "7.4 Rethinking the AI Software Stack", "content": "Addressing Architectural Limitations:\n\u2022 Developing New Software Frameworks:\nDesign AI software architectures that inherently support common sense reasoning, possibly inspired by neural and cognitive structures found in biological organisms.\n\u2022 Incorporating Modular and Hierarchical Structures:\nImplement software designs that allow for layered learning and reasoning processes, enabling AI systems to build complex understanding from simpler components.\nAdopting Novel Methodologies:\n\u2022 Integration of Symbolic and Statistical Approaches:\nCombine the strengths of symbolic reasoning (for logic and rules) with statistical learning (for pattern recogni-tion) to enhance common sense capabilities.\n\u2022 Emphasizing Learning Over Programming:\nShift focus from hard-coded knowledge to systems that learn and adapt from interactions, aligning with how common sense develops in humans and animals."}, {"title": "8 Risks of the Current Approach and the Need for Change", "content": ""}, {"title": "8.1 Potential Misalignment of Expectations and Resources", "content": "Risks of Overemphasizing Scaling for Autonomy:\n\u2022 Misallocated Investments:\nContinuing to invest heavily in scaling with the expectation that it will lead to autonomy may divert resources from the core challenge of integrating common sense.\n\u2022 Expectation Gaps:\nOverestimating what scaling can achieve in terms of autonomy may lead to disappointment and skepticism when Al systems fail to meet these expectations.\nAddressing the Core Challenge:\n\u2022 Redirecting Focus:\nBalancing efforts between scaling and integrating common sense ensures that advancements in AI are aligned with the goal of achieving reliable autonomy.\n\u2022 Maximizing Return on Investment:\nBy working on the right problem, resources can be utilized more effectively, leading to AI systems that offer greater societal and commercial value."}, {"title": "8.2 Technological Disillusionment", "content": "Loss of Public Trust:\n\u2022 Unmet Expectations:\nRepeated failures to deliver on promises of autonomous AI can lead to skepticism among users, investors, and policymakers.\n\u2022 Ethical and Safety Concerns:\nSystems lacking common sense may behave unpredictably, leading to accidents or ethical breaches that erode confidence.\nImpacts on Research and Development:\n\u2022 Decreased Funding:\nDisillusionment may result in reduced funding for AI research, hindering progress.\n\u2022 Talent Drain:\nResearchers may shift focus to other fields if AI development appears stalled."}, {"title": "8.3 Addressing Concerns About Self-Improving AI", "content": "Expert Perspectives on Self-Improving AI:\nEric Schmidt, former CEO of Google, warned that when AI systems begin to self-improve, \"we need to be thoughtful about the implications\u201d. This concern reflects apprehension about the potential risks of AI systems that can modify and enhance their own capabilities without adequate oversight.\nThe Danger of Intelligence Without Common Sense:\n\u2022 Unpredictable Behavior:\nAl systems lacking common sense may not understand the broader implications of their self-improvements, leading to unintended and potentially harmful outcomes.\n\u2022 Lack of Ethical Reasoning:\nWithout common sense, AI might optimize for objectives in ways that conflict with human values or safety norms.\nComparing AI Without Common Sense to AI With Common Sense:\n\u2022 AI Without Common Sense:\nMay inadvertently cause harm due to a lack of understanding of context and consequences.\nSelf-improvement could amplify existing flaws or biases, increasing negative impacts.\n\u2022 AI With Common Sense:\nBetter positioned to make informed decisions that align with human values.\nCapable of ethical self-improvement, recognizing and mitigating risks.\nAddressing Concerns Through Integrated Common Sense:\n\u2022 Enhanced Oversight and Control:\nAl with common sense can comprehend the importance of adhering to safety protocols and respecting human oversight.\n\u2022 Ethical Self-Improvement:\nIncorporating common sense ensures that Al systems self-improve responsibly, prioritizing safety and align-ment with human values."}, {"title": "8.4 The Real Fear: Intelligence Without Common Sense", "content": "Understanding Public Apprehension:\n\u2022 Fear of Unpredictable AI:\nThe fear of AI or superintelligence often stems from concerns about intelligent systems operating without common sense, potentially making harmful decisions.\n\u2022 Lack of Trust in AI Decision-Making:\nWithout common sense, AI may not understand or adhere to societal norms and ethical standards, leading to mistrust.\nMitigating Fear Through Common Sense Integration:\n\u2022 Building Reliable and Predictable AI:\nEnsuring AI systems possess common sense reduces the likelihood of unexpected behaviors.\n\u2022 Aligning AI with Human Values:\nAl with common sense is better equipped to recognize and respect ethical considerations, enhancing public trust."}, {"title": "9 Conclusion", "content": ""}, {"title": "9.1 Reiterating the Central Thesis", "content": "The development of AI systems capable of true autonomy hinges on integrating common sense, an ability inherently present in all animals and fundamental for interaction with both physical and abstract environments. While scaling has brought significant advancements in non-autonomous applications, and benchmarks like the Turing Test have offered valuable insights into human-like conversation, autonomy will not be achieved through these approaches alone.\nWe have argued that:\n\u2022 Current AI Approaches Are Inadequate:\nRelying solely on scaling and incremental improvements without integrating common sense leads to asymptotic performance limitations.\nAl systems may exhibit impressive capabilities in specific domains but lack the adaptability and understanding required for true autonomy.\n\u2022 Common Sense is Essential for Autonomy:\nIntegrating common sense enables AI systems to adapt to new situations, make intuitive decisions, and operate autonomously without exhaustive computational demands.\nThis includes the ability to engage in both physical and cognitive embodiment within well-defined domains.\n\u2022 Rethinking the AI Software Stack is Necessary:\nAchieving true autonomy may require a fundamental redesign of AI software architectures to support common sense integration.\nIncorporating insights from cognitive science, neuroscience, and other disciplines can inform the development of AI systems that learn and reason more like biological intelligence.\nBy redefining the order of knowledge acquisition (ordo cognoscendi) to prioritize common sense, we can:"}, {"title": "9.2 Call to Action", "content": "We urge the AI community-researchers, developers, policymakers, and educators-to:\n\u2022 Acknowledge the Contributions and Limitations of Scaling:\nAppreciate the advancements scaling brings to AI in non-autonomous applications while recognizing its limita-tions regarding autonomy.\n\u2022 Prioritize Research on Common Sense Integration:\nFocus on the core challenge of integrating common sense to achieve reliable, trustworthy autonomy.\n\u2022 Embrace Interdisciplinary Collaboration:\nLeverage insights from cognitive science, neuroscience, philosophy, and other fields to inform AI development.\n\u2022 Invest Strategically:\nAllocate resources to both scaling efforts and foundational research addressing common sense, ensuring bal-anced progress.\n\u2022 Rethink AI Software Architectures:\nConsider fundamental redesigns of the software stack to better support the integration of common sense, incor-porating new methodologies and frameworks."}, {"title": "9.3 Embracing Safe and Ethical AI Development", "content": "Building on concerns raised by experts like Yann LeCun and Eric Schmidt, we emphasize the critical importance of integrating common sense into AI systems to ensure safe and ethical self-improvement. The fear surrounding AI and superintelligence often stems from the prospect of intelligence operating without common sense, potentially leading to unpredictable or harmful behaviors.\nBy integrating common sense, we can:\n\u2022 Mitigate Risks Associated with AI Autonomy:\nEnsure that AI systems understand context, consequences, and ethical considerations, reducing the likelihood of unintended harm.\n\u2022 Enhance Public Trust and Acceptance:\nDevelop AI technologies that align with human values and societal norms, addressing public apprehension.\n\u2022 Promote Responsible Innovation:\nFoster an environment where Al systems contribute positively to society, advancing technology while safe-guarding ethical standards.\nIn conclusion, common sense is all you need to bridge the gap between current AI capabilities and true autonomy. By prioritizing its integration and rethinking our approaches-including the software architectures\u2014we can create AI systems that not only perform tasks efficiently but also understand and adapt to the complexities of both the physical and abstract worlds. This holistic approach is imperative for realizing the full promise of beneficial artificial intelligence."}]}