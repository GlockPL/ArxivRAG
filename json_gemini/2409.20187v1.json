{"title": "Choosing DAG Models Using Markov and Minimal Edge Count in\nthe Absence of Ground Truth", "authors": ["Joseph D. Ramsey", "Bryan Andrews", "Peter Spirtes"], "abstract": "We give a novel nonparametric pointwise consistent\nstatistical test (the Markov Checker) of the Markov\ncondition for directed acyclic graph (DAG) or com-\npleted partially directed acyclic graph (CPDAG)\nmodels given a dataset. We also introduce the\nCross-Algorithm Frugality Search (CAFS) for reject-\ning DAG models that either do not pass the Markov\nChecker test or that are not edge minimal. Edge\nminimality has been used previously by Raskutti and\nUhler as a nonparametric simplicity criterion, though\nCAFS readily generalizes to other simplicity condi-\ntions. Reference to the ground truth is not necessary\nfor CAFS, so it is useful for finding causal structure\nlearning algorithms and tuning parameter settings\nthat output causal models that are approximately\ntrue from a given data set. We provide a software\ntool for this analysis that is suitable for even quite\nlarge or dense models, provided a suitably fast point-\nwise consistent test of conditional independence is\navailable. In addition, we show in simulation that\nthe CAFS procedure can pick approximately correct\nmodels without knowing the ground truth.", "sections": [{"title": "Introduction", "content": "Directed acyclic graph (DAG) data models are often\npublished, making modeling claims for which little\njustification exists, other than that they are produced\nby a \"reliable\" algorithm. Claims about \"reliability\"\nare typically justified in two different ways: theorems\nthat state that under suitable assumptions the algo-\nrithm is correct in the large sample limit and/or sim-\nulation studies. However, both types of reliability\nindicator may not be applicable to a particular algo-\nrithm or search parameter choice on given data. Sim-\nulations routinely make assumptions that real data\nviolate (e.g., no latent confounders, no selection bias,\nno measurement error, i.i.d. sampling, etc.). Real\ndata may require, for correctness, assumptions that\nare not simultaneously satisfied by any existing algo-\nrithm, and when these implicit assumptions are vio-\nlated, errors can occur. Accordingly, algorithms may\nonly be reliable in certain contexts, primarily simu-\nlation contexts, in aggregate, and perhaps not in a\ncontext suitable for analyzing a specific dataset.\nIn the case of theorems guaranteeing the correct-\nness of causal structure learning algorithms, the the-\norems typically either only guarantee correctness in\nthe large sample limit [Spirtes et al., 2000, Chick-\nering, 2002], or they make implausibly strong as-\nsumptions [Kalisch and B\u00fchlman, 2007, Uhler et al.,\n2013], or at finite sample sizes they guarantee only\nvery loose bounds on the probability of being correct\n(Spirtes and Zhang, Spirtes and Wang). Correctness\nin the large-sample limit does not guarantee success\nat any given finite sample size. Thus, in many (but\nnot all) cases, violations of assumptions and/or fi-"}, {"title": "Preliminaries", "content": "We define some terms that we will need. A graph G\nis an ordered pair (E, V), where V is a set of vertices,\nand E is a set of edges over V, and each edge (x, y)\nis either directed from x to y with a tail at x and\nand arrow at y (we represent these as $x \\rightarrow y$) or\nundirected with a tail at both x and y (we represent\nthese as $x - y$. We denote vertices with lowercase\nletters, and we denote sets of variables with uppercase\nletters. We refer to the arrows and tails in a graph\nas endpoint markings. An adjacency is an edge in a\ngraph regardless of endpoint markings. A path is a\nlist $(x_1,x_2,...,x_n)$ in G where $(x_i, x_{i+1})$ is an edge\nin G for each i. A directed path is a path where\n$(x_i, x_{i+1})$ is a directed edge in G from $x_i$ to $x_{i+1}$ for\neach i. A cycle is a directed path from a node to\nitself. A directed graph is a graph with only directed"}, {"title": "The Markov Condition", "content": "We may further remark on the Markov relationship\nmentioned above. Usually, one makes the Causal\nMarkov Assumption in algorithm construction for a\ntrue unknown causal graph. If the Causal Markov\nAssumption is true, and the output of causal search\nalgorithm is correct, then the output CPDAG will be\nMarkov to the population distribution. However, the\nMarkov condition (MC) itself [Spirtes et al., 2000]\nis an assumption that can be checked for any DAG.\nFor DAG models, we can state the Markov condi-\ntion in terms of a relationship between d-separation\nclaims for a DAG (or CPDAG) G and independence\nfacts that hold in a probability distribution P over\nthe variables in G\nDefinition 1 (Global MC) (G, P) satisfies\nthe Markov condition if, for sets X,Y and Z,\ndsep(X, Y | Z) in G implies that I(X,Y | Z) in P.\nSince every DAG represented by a CPDAG has"}, {"title": "Repurposing Raskutti and\nUhler's Recommendations", "content": "We next discuss how to repurpose Raskutti and Uh-\nler's idea to compare DAG algorithms more generally.\nRaskutti and Uhler [2018] indirectly recommend\nchecking two assumptions for DAG models when giv-\ning justification for their Sparsest Permutation (SP)\nalgorithm. They first define the sparsest Markov rep-\nresentation (SMR) assumption as follows. Let |G|\nbe the number of edges in G and let M(G) be the\nMarkov equivalence class (MEC) of G."}, {"title": "A Test of the Markov Condition", "content": "Next, we describe our proposed check of the Markov\ncondition for an empirical graphical model G given a\ndata set.\nWe can check Markov by making a list of graph-\nical conditional independence claimed to hold made\nby an empirical graph G using the d-separation crite-\nrion S for the model class it represents and then check\nthe correctness of this list. Checking to ensure that\nall independence facts implied by an empirical model\nare judged as independent by a statistical test of in-\ndependence is not quite what is needed. Statistical\ntests of conditional independence use a significance\ncut-off point (a) to reject independence, assuming\nthat the null hypothesis of independence is true. If\nthe null hypothesis is true, false rejections of the null\nhypothesis will occur at a rate of \u03b1, which are un-\navoidable errors. False dependence judgments can\nalso be rendered for similar reasons because of the\ndistribution of p-values under the alternative depen-"}, {"title": "Data Overlap", "content": "One worry about collecting p-values from multiple\nconditional independence tests is that tests with vari-"}, {"title": "The CAFS Procedure", "content": "Given a data set D, we can test various candidate\ngraphs under Markov conditions and compare uni-\nform p-values and the number of edges in these\ngraphs. This lets us define a metaloop over a set\nof candidate DAGs or CPDAGs. Candidate DAGS\nor CPDAGs can come from background beliefs, algo-\nrithms with fixed search parameters, or some combi-\nation of the two. CAFS will then search for graphs\nthat cannot be rejected by either a Markov check or\nthe frugality criterion. We call this meta-loop \"Cross-\nAlgorithm Frugality Search\" (CAFS) and give the\nalgorithm in Algorithm 2. Importantly, it does not\nmatter which principles or background assumptions\nthat the various algorithms use to search the space of\nDAG models; in our experimental section below, we\nconsider algorithms applied to simulation data that\nappeal to very different types of theory and com-\npare them directly to one another using the notion"}, {"title": "Implementation", "content": "We provide a software tool, the Markov Checker, for\nchecking Markov as part of the Tetrad software suite\nfor those who do not wish to handle the details them-\nselves, though the test can be readily implemented."}, {"title": "Expanding the Toolkit for\nDomain Experts", "content": "In a strict sense, BIC [Schwarz, 1978, Haughton,\n1988], or, for that matter, any penalized likelihood\nstatistic, does not allow one to reject false models.\nUnless the correct model is among the models be-\ning compared, one can never know how far one is\nin practice from optimizing the penalized likelihood\nstatistic. BIC is often used without ground truth\nby optimizing this score to the extent possible, even\nthough the problem is recognized (e.g. Teyssier and\nKoller [2005]). A hope is that exact searches can get\naround this stricture, though exact searches do not\nguarantee that the correct model is among the com-\npared models at finite sample sizes; also, they may\nbe searching the wrong class of models.\nFor linear Gaussian models, the p-value of a chi-\nsquared test is often appealed to without ground\ntruth, though in practice, if even one or two edges\nare out of place in one's model, the p-value of the\nmodel drops numerically to zero, a known draw-\nback (Bentler and Bonett [1980]). A response to\nthis has been the development of various model fit\nindices, particularly in the social science literature\n[Bollen and Long, 1993], such as the Comparative\nFit Index (CFI, Bentler [1990]) or the Normed Fit\nIndex (NFI, Bentler and Bonett [1980]), the so-called"}, {"title": "Limitations", "content": "Notably, the Markov checker is looking for minimal\nMarkov models, which amounts, for the causally suf-\nficient case, to looking for CPDAGs that explain the\ndata with the fewest number of edges, though other\nsimplicity principles such as minimizing the number\nof parameters of the model could also be used. What\nit cannot do is help pick out a particular model from a\nMarkov equivalence class (MEC). Several algorithms\nare available that can do this under assumptions that\nare stronger than linear Gaussian. For example, if\nthe model can be placed into the class of linear non-\nGaussian models, then it is possible to orient all\nedges in the model [Shimizu et al., 2011], though the\nMarkov checker would not be able to say whether\nthese additional orientations are correct; some other\ntest would be needed for that, such as checking the\nindependence of residuals. Similarly, one can find\nmore orientations than the MEC allows if the model\ncan be correctly placed into the class of nonlinear\nmodels with additive noise or heteroskedastic mod-\nels, and the Markov checker would not be able to say\nwhether the additional orientations afforded by algo-\nrithms taking advantage of these stronger assump-\ntions are correct, even if the data one has at hand"}, {"title": "A Simulation Comparison", "content": "We determine how well a search for frugal models,\niterating over multiple algorithms and tuning param-\neter choices, without referring to ground truth, picks\nout models judged as accurate by subsequent com-\nparison to M(G*). We focus on the scenario where\none is judging whether a specific model should be\njudged as passing Markov. One could also raise the\nquestion of which algorithms may be expected to pass\nMarkov under which settings of their hyperparame-\nters; we will leave discussion of this question to an-\nother time. One feature of the Markov checker is that\nit is entirely possible that all compared models fail\na Markov check, so that there are no recommended\nmodels. We take this to be a feature and not a bug.\nAs noted, a number of statistics in common use do\nnot have this property but instead return a model\nmaximizing or minimizing a score. So, if the set of\nmodels compared does not contain a suitable model,\nan inadequate model may be returned. The Markov\nchecker aims to find adequate models, if not good or\nexcellent ones, in a theoretically motivated way.\nWe consider models from the following algorithms\nfor the linear Gaussian case that generate CPDAGS:\nPC [Spirtes et al., 2000], CPC [Ramsey et al., 2006],\nFGES [Ramsey et al., 2017], GRaSP [Lam et al.,\n2022], BOSS [Andrews et al., 2023], DAGMA [Bello\net al., 2022], BiDAG [Suter et al., 2023], M\u041cH\u0421\n[Tsamardinos et al., 2006], and PCHC [Tsagris,\n2021]. We consider a linear Gaussian data only for\nthese comparisons, and so leave out any algorithm\nthat requires stronger (or different) assumptions. We\nsimulate both training and testing data, learn the\ngraphs on the training data, and test the Markov\ncondition on the testing data. As for the models in\nFigure 1, these are for linear Gaussian models, using\nthe DaO simulation method [Andrews and Kummer-\nfeld, 2024]. Random graphs are selected with a given\nnumber of nodes and a given average degree of nodes"}, {"title": "An Empirical Example", "content": "As noted above, our presentation is subject to a num-\nber of limitations that make it somewhat difficult to\nfind off-the-shelf real data sets easily to analyze. We\nchoose a data set that has been analyzed many times,\nthe US Crime data set. This has 14 variables with\nN = 47 and thus gives us the opportunity to consider\nthe additional problem of small sample size. Since\nthe sample size is so small, we will use an \u03b1 thresh-\nold for our Anderson-Darling uniformity test of 0.2.\nSince we do not have ground truth, we are not able\nto give plots for the F1 or SHD statistics, above, but\nwe can give plots for |G|, BIC, CFI and NFI. Be-\ncause they often do not produce legal CPDAGS for\nthese data (in violation of our choice to use Ordered\nLocal Markov to generate conditional independence\nfacts implied by a model), we remove PC and CPC\nfrom our list of algorithms. Otherwise, we follow the\nsame procedure as above.\nFigure 3a shows the number of edges in the esti-\nmated model plotted against pad for these data; Fig-\nure 3b shows the BIC plotted against pad; Figure 3c\nshows CFI plotted against pad; Figure 3d shows NFI\nplotted against pad."}, {"title": "Discussion", "content": "For the simulation data, regarding Figure 2a, plot-\nting the number of edges against $p_{ad}$, the CAFS\nprocedure suggests that we should consider the set\nof starred models and then choose some set of mod-\nels with lower |G|. Looking at the scatter plot, the\nmodel with the least |G| is a GRaSP variant. If we\nwere to look at the full results, we could easily pick\nout which model this is, and if this were an empirical\ninvestigation, this would be a warrant to use one of\nthese minimal or nearly minimal models for empirical\ninvestigation.\nIn Figure 2b, we see that the models that the\nMarkov checker selects are among those with the\nhighest BIC scores. Note that BIC does not pro-\nvide a threshold for rejection; in use for empirical\nmodels, one tries to maximize the BIC score, though\nthe score itself does not specifically endorse or reject\nany model. Nevertheless, the Markov checker for this\ncomparison picks out models with the highest score,"}, {"title": "Conclusion", "content": "DAG models make numerous claims about the inde-\npendence and conditional independence of variables,\nso checking Markov for such models given a dataset\nis something that a domain expert can do without\nreference to ground truth. If one does not have\nenough conditional independence p-values to get a\ngood Markov check test, one can generate more by\ncalculating the p-values for these conditional inde-\npendence tests for replacement random subsets, al-\nthough, as mentioned in Section 6, there is a trade-off\nof the number of additional p-values generated to the"}]}