{"title": "Can GPT-4 learn to analyze moves in research article abstracts?", "authors": ["Danni Yu", "Marina Bondi", "Ken Hyland"], "abstract": "One of the most powerful and enduring ideas in written discourse analysis is that genres can be described in terms of the moves which structure a writer's purpose. Considerable research has sought to identify these distinct communicative acts, but analyses have been beset by problems of subjectivity, reliability and the time-consuming need for multiple coders to confirm analyses. In this paper we employ the affordances of GPT-4/Copilot to automate the annotation process by using natural language prompts. Focusing on abstracts from articles in four applied linguistics journals, we devise prompts which enable the model to identify moves effectively. The annotated outputs of these prompts were evaluated by two assessors with a third addressing disagreements. The results show that an 8-shot prompt was more effective than one using two, confirming that the inclusion of examples illustrating areas of variability can enhance GPT-4's ability to recognize multiple moves in a single sentence and reduce bias related to textual position. We suggest that GPT-4 offers considerable potential in automating this annotation process, when human actors with domain-specific linguistic expertise inform the prompting process.", "sections": [{"title": "INTRODUCTION", "content": "Move analysis is an approach to text analysis used to investigate the organizational and rhetorical structure of written genres. Pioneered by Swales (1990), it is an essential component of his genre model, referring to the recognizable stages of particular institutional genres and the constraints on typical move sequences. For Swales (2004: 228), a move is \u2018a discoursal or rhetorical unit that performs a coherent communicative function in a written or spoken discourse', thus it helps frame a writer/speaker's rhetorical decision-making to meet the expectations of a particular community. Moves, then, are genre-dependent and perform both local purposes for the writer and collectively contribute to the communicative purpose of the genre itself. Move analysis has been one of the most productive approaches to texts in recent years with a plethora of papers attempting to describe the structural organization of academic genres as diverse as mathematics research articles (Kuteeva and McGarth 2015), 3-minute theses (Hu and Liu 2018), and student lab reports (Parkinson 2017).\nBut while analyzing schematic structures has proved an invaluable way of looking at texts, analysts have long been aware of the dangers of interpreting units as mono-functional (Hyland, 2002) and ignoring writers' complex purposes and \u2018private intentions' (Bhatia 1999). There is also the problem raised by Crookes (1986) of validating analyses to ensure they are not simply products of the analyst's intuitions. Because moves are a functional, rather than a formal unit, there are difficulties in identifying specific lexico-grammatical units as conveying particular rhetorical functions. Transitions from one move to another in a text are, of course, always motivated outside the text as writers respond to their social context and personal goals, but analysts have not always been convincingly able to identify the ways these shifts are explicitly signalled (for a discussion see for example Gray et al. 2020).\nAs a result, move analysis is a complex, subjective and time-intensive business and replication of such studies is hampered by the limited information typically provided on the process by researchers (Moreno and Swales 2018). As Casal and Kessler have recently observed:\nMethodological issues such as the number of annotators, the procedure for developing/modifying a framework, the unit of analysis (linguistic or rhetorical), inter-coder reliability, and the procedures for resolving disagreements are not uniformly reported. (Casal and Kessler 2024: 96).\nTransparency regarding these issues can be potentially enhanced by LLMs such as GPT-4. To condition a model for a move annotation task, it is essential to create well-drafted prompts with explicit descriptions of the moves and clear criteria for the unit of analysis, which can then serve as protocols for replicating the study. Additionally, as the model can be consistently used to annotate the entire corpus, the results are less likely to be affected by low inter-coder reliability.\nIn this paper we seek to resolve some of these methodological issues by designing prompts which enable the freely available GPT-4 model on the Microsoft Copilot interface (formerly Bing chatbot) to automatically annotate research article abstracts."}, {"title": "ARTICLE ABSTRACTS AND RHETORICAL MOVES", "content": "The need to easily access information to guide reading has led, in recent years, to the widespread use of structured abstracts in the life sciences, and particularly in clinical journals (Hartley 2014). Authors are encouraged to label their abstracts with pre-defined headings (such as Purpose, Design, Analysis, Findings), essentially mirroring the IMRD (Introduction-Method-Results-Discussion) structure of a full article. Structured abstracts have subsequently expanded to other areas such as engineering (e.g. Radix and Mohammed 2017) and the humanities and social sciences. Despite the relatively standardized structure of abstracts, researchers fail to concur on the number and names of abstract moves. Bhatia (1993) for example, identifies four moves while Swales and Feak (2012), Dos Santos (1996), and Hyland (2004) recognize five. The present study follows the latter three studies in recognizing the move schema shown in"}, {"title": "TOWARDS AUTOMATED MOVE ANNOTATION", "content": "Recent studies have shown the considerable potential of GPT models to recognize and annotate various phenomena such as stance (Gilardi et al., 2023), text categories (Kuzman et al., 2023), pragmatic units in speech acts (Yu et al. 2024) and speech functions in conversations (Ostyakova et al., 2023). In particular, Yu et al. (2024) found that GPT-4/Bing (now called Copilot) achieved accuracy approaching that of a human coder in annotating pragmatic units, including those without conventional formal markers, such as reasons for an apology. In this paper we aim to assess whether move annotation tasks can be conducted with GPT-4 by using prompts with examples representing moves."}, {"title": "METHODS: PROMPTING FOR MOVE ANNOTATION IN ABSTRACTS", "content": "To assess whether rhetorical moves can be annotated automatically by an LLM, we went through a set of exploratory and confirmatory analyses (Roettger, 2019) using the GPT-4 model on Copilot in creative mode\u00b9. As Copilot is now freely available, researchers can use the same platform to replicate our analysis. Our approach had three main stages: 1) task setting; 2) prompt designing; and 3) output assessing. The stage of prompt designing comprises a set of exploratory tests, where we observed the impact of prompting factors on outputs, in order to design a prompt that could complete the annotation task effectively. Building upon these exploratory analyses, we concluded that the number of examples included in the prompt may affect the model's performance in the annotation task. To test this possibility and provide details of the annotation, we systematically assessed the outputs of two prompts with different numbers of input examples. Details are provided below.\nTask setting\nThe task we assigned to the LLM was to annotate rhetorical moves in RA abstracts written in English from applied linguistics. The corpus under investigation was composed of 180 abstracts collected from four leading journals in applied linguistics, which are Language Learning, Applied Linguistics, TESOL Quarterly, and Language Teaching Research. These abstracts are drawn from the most recent articles, as of December 2023. The corpus was divided into five sub-corpora according to the chronological order of the texts. Among these, S1, S2, S3, and S4, which contained 20"}, {"title": "Prompt design", "content": "To prepare the LLM for the annotation task, we paid particular attention to prompt design. Prompting is the method of conditioning, or \u2018teaching', the model to generate expected outputs (Liu et al. 2023). In this study, prompt design involved two steps. The first aimed to draft a prompt that could help the model generate coherent and contextually relevant responses in appropriately completing the annotation task, at least on \u201ceasy cases\u201d, i.e., instances with explicit linguistic markers indicating the function of a move (e.g., we conclude with recommendations for which indicates the conclusion move). This step was conducted on S1. Here we consulted instructional articles on Microsoft Learn\u00b2 related to prompting strategies. This meant, following, for example, suggestions such as being specific, being descriptive by using analogies, repeating instructions, ordering matters to account for the model's recency bias, and giving the model an example of output to avoid generating false responses\u00b3. Based on trials with S1, a candidate prompt was established, using the following strategies:\nUsing clear boundaries and signals to separate the different sets of instructions. The annotation task required multiple instructions, so we divided them into paragraphs and labelled them as instruction 1, instruction 2, etc. This helped the model to learn the instructions one by one.\nProviding detailed definitions for each label. For instance, the METHOD move was explained with \u2018this move describes the research design, data collection, data analysis procedures, analysis techniques, and theories used in the study'. This descriptive definition helped the model identify the move more accurately than the simpler 'this move describes the methodology'.\nAdapting the language to the model's own output. For example, we asked the model to define the five rhetorical moves and used the resulting expressions as a reference to refine the prompt.\nAvoiding ambiguous indications that could confuse the LLM. For example, the LLM misinterpreted the indication \u2018annotate the following abstract with the five rhetorical moves' as meaning that an abstract must contain all five rhetorical moves. We resolved this by changing the instruction to \u2018annotate each sentence in the following abstract'.\nUsing explicit directives. For example, the model misunderstood the indication 'Learn instruction 1' as implying that we wanted to learn instruction 1. We corrected this misunderstanding by using the more explicit directive \u2018Please learn instruction 1'. This misunderstanding may occur because the LLM, unable to capture paralinguistic information, requires more explicit linguistic cues (please in this case) to comprehend the user's intent.\nEmphasizing the aspects that the model often missed. For example, the model frequently overlooked combined moves. Therefore, we added the reminder \u2018pay attention to combined moves' in the instruction."}, {"title": "A pilot experiment", "content": "To assess the improvement of the model's performance with different prompts, we conducted a pilot experiment on ten texts randomly selected from the error corpus, using nine prompts containing different numbers of examples (Table 2). These prompts, except for the 0-shot prompt, applied the few-shot prompting technique, which exposes the model to examples (\u2018shots') for in-context learning, a widely recognized ability of LLMs in learning from a few task-relevant demonstrations to improve their performance (Brown et al., 2020).\nWe evaluated these annotations in terms of sentence-level accuracy, assessing the proportion of sentences correctly coded out of the total number of sentences. The results show that there was a stable improvement from the 0-shot prompt to the 4-shot prompt, but a drop emerged with the 5-shot and 6-shot prompts (Figure 1). The errors generated by these two prompts concern mainly the false recognition of the first sentence as BACKGROUND, which may be due to the fact that these two prompts have added examples beginning with BACKGROUND. To address this issue, in the 7-shot and 8-shot prompts we added examples that do not begin with BACKGROUND. The accuracy of the 8-shot prompt achieved 93.33%."}, {"title": "Assessing output", "content": "The comparison of the effectiveness of the 8-shot prompt and the 2-shot prompt was conducted on S5 composed of 100 texts with 678 sentences in total. Two human evaluators judged the accuracy of the LLM's annotated outputs. The results indicated a disagreement of 1.8% between the two human evaluators, with disagreement over just 12 GPT-annotated sentences. These different assessments concerned mainly the moves METHOD (six cases) and PURPOSE (six cases). A third assessor, with considerable expertise in academic discourse studies, was asked to review the 12 cases to decide whether the model correctly annotated a move. The final assessment results were measured using the parameters of precision, recall, and Fl-score. To take the label METHOD as an example,\nPrecision indicates the proportion of instances correctly assigned with METHOD among all the instances assigned with this move. It is calculated as the number of True Positives (TP) divided by the sum of True Positives and False Positives (FP). Precision = TP / (TP + FP).\nRecall indicates the proportion of instances correctly identified as METHOD among all actual instances of this move in the sample. It is calculated as the number of True Positives divided by the sum of True Positives and False Negatives (FN). Recall = TP / (TP + FN).\nFl-score is the harmonic mean between precision and recall and provides overall assessment of the model's accuracy in annotating METHOD. F1 Score = 2*(Precision*Recall) / (Precision + Recall).\nTo sum up,"}, {"title": "EXPERIMENTAL RESULTS AND ANALYSIS", "content": "The outputs generated by both the 8-shot and 2-shot prompts have high accuracy readings (Table 5), indicating that GPT-4 can be used to assist rhetorical move annotation. The model accurately labelled all five moves with F1 over 0.8, except for PURPOSE which was annotated with the 2-shot prompt at 0.78 accuracy.\nAlthough the overall results for both prompts are impressive, we can observe a gap in the results in Table 5 with the 8-shot prompt performing better in identifying all the labels than the 2-shot prompt,. This suggests that the use of more examples and instructions can help condition the model to better understand the task."}, {"title": "Over-recognition of BACKGROUND: meanings concealed by textual position", "content": "We can see from Table 5 that among all the labels, BACKGROUND led to the lowest F1 score for both prompts. The precision score is particularly low (0.81 with the 8-shot prompt and only 0.69 with the 2-shot prompt), while the recall score is high with both prompts (0.93 vs 0.94). This means that the model was able to recognize most of the true BACKGROUND moves, but had a tendency to excessively identify other moves as BACKGROUND.With a qualitative analysis of the cases of false BACKGROUND, we noticed that the misrecognition of this move seemed to be related to sentence location in the text. The model tended to over-recognize the first sentence as BACKGROUND while ignoring the more prominent presence of other moves such as METHOD and PURPOSE. This phenomenon where certain meanings are concealed by the textual position occurred 14 times in the experiment with the 8-shot prompt and 29 times with the 2-shot prompt."}, {"title": "Recognition of PURPOSE and METHOD: challenges with combined moves", "content": "In abstracts, the PURPOSE and METHOD moves are often merged (e.g. Dos Santos 1996). This tendency was also noted in our corpus, posing a significant challenge for the model. The results show that the 2-shot prompt was much less effective in recognizing these two moves in combination compared to the 8-shot prompt. Upon examining the data, we identified two main cases where PURPOSE and METHOD were ignored by the model. The first case concerns the misrecognition of BACKGROUND in a sentence which should have been annotated with PURPOSE and/or METHOD. The second case concerns the model's failure to recognize combined moves. Using the 2-shot prompt, the model tended to assign only one label to a sentence that should have been annotated with two moves, omitting PURPOSE or METHOD."}, {"title": "Recognition of RESULTS: being overshadowed by a leading move", "content": "The RESULTS move achieved high F1 score with both prompts. However, in terms of recall, the 8-shot prompt appeared to be more effective than the 2-shot prompt. The former failed to identify 6 cases out of the 219 instances of RESULTS, while the latter missed 15 cases. Analyzing the unrecognized RESULTS, we noticed that the move, although expressed with explicit markers such as revealed that, illustrates, the findings evince, our findings show, tended to be neglected when it was \u2018overshadowed' by the leading move, mostly METHOD, that initiated the sentence,"}, {"title": "Recognition of CONCLUSION: a case of hallucination", "content": "The model performed outstandingly in recognizing CONCLUSION. Among the 94 cases of CONCLUSION in the corpus, only one was ignored by the 8-shot prompt, while two cases were missed by the 2-shot prompt. The precision was also exceptionally high. No case was falsely predicted with the 8-shot prompt, while the 2-shot prompt falsely identified only 3 cases."}, {"title": "Summing up", "content": "The errors discussed above can be categorized into three major types: unrecognition of a move, false recognition of a move, and hallucination (Table 6). Additional analysis of instances representing these errors reveal possible relevant factors related to them.\nBuilding on the comparison between the 2-shot and 8-shot prompts in terms of error types, we have discussed the pros and cons of the two prompts and offered potential countermeasures to address some of the errors. In particular, the enhanced performance of the 8-shot prompt in recognizing combined moves and in reducing the over- recognition of BACKGROUND indicates that the inclusion of examples illustrating relevant linguistic phenomena could help the model more effectively manage these challenges. However, the emphasis on a particular linguistic phenomenon could possibly induce the model to over-recognize that phenomenon. For example, the use of the 8-shot prompt has led to a higher frequency of over-annotation with combined moves compared to the 2-shot prompt. This suggests that we need to determine priorities when using this automated analysis ."}, {"title": "CONCLUSION", "content": "The present study provides evidence to the applicability of Large Language Models such as GPT-4 in assisting rhetorical move annotation through skillful prompting. The results show that the 8-shot prompt was more effective than the 2-shot prompt, which suggests that the inclusion of examples, illustrating variations in rhetorical move structures, can contribute to enhancing the overall accuracy of the assigned task.\nPerhaps equally importantly, we should point out that one result of our study is the conclusion that, in the era of Artificial Intelligence and the use of LLM-driven bots for language analysis, domain-specific linguistic expertise is essential for appropriate prompt design. As illustrated in this study, for the task of rhetorical move annotation, expertise in linguistics, or more specifically, in corpus-based genre analysis, can aid in at least the following six steps: 1) collection of representative texts of the genre under investigation; 2) identification of moves in the genre; 3) establishment of a move scheme containing adequate definitions of each move; 4) selection of representative examples annotated with moves to be used in the prompt (representative examples may emerge during the tests); 5) assessment of the annotated results, paying particular attention to inconsistent cases (which may offer opportunities for theory-building); 6) qualitative analysis of incorrectly annotated cases to find possible solutions to enhance the accuracy of the model.\nThe GPT-assisted move annotation approach offers significant practical advantages for genre studies. First, and most importantly, this automated approach, with human verification, can produce faster and more objective results than those relying entirely on human annotation. Second, the approach can be effectively integrated into writing classrooms. For example, teachers can encourage students to devise prompts that guide a GPT interface in annotating rhetorical moves within texts of a specific genre. This process engages students in the six steps mentioned above and can develop their understanding of generic move functions, thus allowing them to improve their own writing. While there remains some way to go in exploiting the affordances of AI in language analysis, we believe this is a valuable beginning and involves genre analysts in a fascinating area of development."}, {"title": "APPENDIX", "content": "Appendix 1. The 8-shot prompt\n(refer to the forthcoming published version)"}]}