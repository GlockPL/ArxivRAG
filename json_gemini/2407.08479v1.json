{"title": "Robust Generalization of Graph Neural Networks for Carrier Scheduling", "authors": ["Daniel F. Perez-Ramirez", "Carlos P\u00e9rez-Penichet", "Nicolas Tsiftes", "Dejan Kosti\u0107", "Magnus Boman", "Thiemo Voigt"], "abstract": "Battery-free sensor tags are devices that leverage backscatter techniques to communicate with standard IoT devices, thereby augmenting a network's sensing capabilities in a scalable way. For communicating, a sensor tag relies on an unmodulated carrier provided by a neighboring IoT device, with a schedule coordinating this provisioning across the network. Carrier scheduling-computing schedules to interrogate all sensor tags while minimizing energy, spectrum utilization, and latency-is an NP-Hard optimization problem. Recent work introduces learning-based schedulers that achieve resource savings over a carefully-crafted heuristic, generalizing to networks of up to 60 nodes. However, we find that their advantage diminishes in networks with hundreds of nodes, and degrades further in larger setups. This paper introduces RobustGANTT, a GNN-based scheduler that improves generalization (without re-training) to networks up to 1000 nodes (100x training topology sizes). RobustGANTT not only achieves better and more consistent generalization, but also computes schedules requiring up to 2x less resources than existing systems. Our scheduler exhibits average runtimes of hundreds of milliseconds, allowing it to react fast to changing network conditions. Our work not only improves resource utilization in large-scale backscatter networks, but also offers valuable insights in learning-based scheduling.", "sections": [{"title": "1 Introduction", "content": "Recent advancements in backscatter communication enable the battery-free operation of sensor devices-termed sensor tags-that perform bi-directional communication with standard Internet of Things (IoT) devices [10, 22, 26, 27, 44, 52]. Such sensor tags can be added to an existing network of Commercial Off-The-Shelf (COTS) IoT devices to augment the network's sensing capabilities without requiring additional modifications to the IoT devices [47]. However, communication between a sensor tag and its hosting IoT device requires the provision of an unmodulated carrier by a neighboring IoT device. A schedule coordinates this provisioning globally across the network to interrogate all sensor values.\nMotivation. Battery-free sensor tags provide a scalable, cost- and energy-efficient way to augment the sensing capabilities of existing IoT networks [27, 44, 47]. Their battery-free operation reduces electronic waste, and prevents extensive maintenance costs compared to battery-powered alternatives. It also allows placing sensors in hard-to-reach locations, such as medical implants, moving machinery, or embedded in physical infrastructure. The sensor tags may, e.g., prevent patients from undergoing surgery just to replace the battery of medical implants. Reducing the energy consumption of networks hosting sensor tags is of paramount importance not only for sustainability reasons, but also because such networks are often energy constrained.\nChallenges. Carrier scheduling-computing a schedule to interrogate all sensor tags while minimizing energy, spectrum utilization, and latency-is, in general, an NP-Hard Combinatorial Optimization Problem (COP) [45]. It is similar to the traditional wireless link scheduling, but must consider additional constraints for tag interrogations and resource minimization (see Sec. 2.1). There are also several symmetries involved, both in permuting the timeslots and in selecting carrier generators [46]. E.g., in Figure 1, exchanging the timeslots' order alters neither the number of carriers required, nor the latency to query all tags. Also, for timeslot s3, nodes v2 and v3 are equally valid carrier providers for T5. A scheduler must process variable input-output structures: networks of different sizes, and schedules of different lengths. It must also leverage the topological structure of the network to favor using one carrier for multiple concurrent tag interrogations (e.g., timeslots s1 and s2 in Figure 1). Additionally, it must compute schedules in a timely manner to react to connectivity changes of the IoT network.\nCurrent Learning-based Schedulers exhibit Limited Scalability. In general, it is impractical to compute the analytically optimal schedule for IoT networks of hundreds of nodes and sensor tags. This implies running a Constraint Optimizer (CO) for several hours, most likely yielding an obsolete schedule due to changes in the network's connectivity. Alternatively, one can use the TagAlong scheduler [45], a carefully-crafted heuristic with polynomial runtime. However, its performance is increasingly sub-optimal as the network size increases. Recent work introduces DeepGANTT, a scheduler that learns from optimal schedules of small networks (up to 10 nodes) and scales to networks of up to 60 nodes, while reducing the number of carriers compared to TagAlong [46]. As we show in Sec. 6.2.2, reducing the number of carriers directly translates to energy savings.\nHowever, DeepGANTT presents two main issues when further scaling the problem to graphs larger than 60 nodes, as depicted in Figure 2. We train eight independent models"}, {"title": "Approach", "content": "In this paper, we leverage the latest advances in Graph Neural Networks (GNNs) and Machine Learning (ML) to present RobustGANTT, a scheduler for backscatter networks with strong and consistent generalization capabilities. To design RobustGANTT, we set out to explore ML-related training aspects, beginning with our own implementation of DeepGANTT. We train our scheduler with optimal schedules of networks of up to 10 nodes and 14 tags computed by a CO. The use of GNNs in our system design allows the scheduler to process variable input-output structures, and to process much larger, previously unseen topologies without the need for re-training. For designing our system, we investigate three aspects influencing the scheduler's generalization as follows.\nFirst, we assess the influence of warmup [37], and prove it highly beneficial for the model's ability to compute complete schedules for larger topologies. Furthermore, we explore incorporating Positional Encoding (PE) into the node features to enhance the GNN's ability to handle symmetries in schedule computation. We find that the node-degree PE offers the best trade-off for achieving good generalization, while avoiding the computation overhead of Eigenvalue Decomposition (EVD)-based methods. Finally, we study the influence of increasing the number of attention heads of the GNN layers to capture more complex topological dependencies among the IoT nodes in the network [41].\nContributions. Based on the former, we present Robust-GANTT, a novel GNN-based scheduler that generalizes to networks of up to 1000 nodes (100\u00d7 training sizes), far beyond the capabilities of current learning-based systems [46], while delivering schedules that require up to 2x less resources than those by the TagAlong heuristic [45]. Our system exhibits polynomial time complexity, allowing it to react fast to changing network conditions. Figure 2 shows how our scheduler not only outperforms DeepGANTT, but also exhibits consistent generalization across the independently trained models.\nTo evaluate RobustGANTT's capabilities on real-life IoT networks, we use it to compute schedules for a testbed with 23 nodes and varying number of sensor tags. Our system achieves 12% on average and up to 53% savings in energy and spectrum utilization compared to the TagAlong heuristic, which corresponds to up to 1.9\u00d7 more savings over the DeepGANTT scheduler. Furthermore, thanks to the polynomial time complexity of the model, it exhibits average runtime of 540 ms for the real IoT network, and achieves up to 2\u00d7 reduction in 95th percentile runtime against DeepGANTT. These characteristics enable RobustGANTT to compute schedules for IoT networks even in dynamic changing conditions.\nWe make the following specific contributions:"}, {"title": "2 Background and Related Work", "content": "Our work draws upon backscatter communication, scheduling for backscatter networks and ML for scheduling."}, {"title": "2.1 Backscatter Communication", "content": "Several recent efforts advance backscatter communications and battery-free networks [1, 10, 13, 15, 22, 24, 26, 27, 34, 38, 52, 63]. While some work focus on monostatic or multistatic backscatter configuration [19, 25, 61, 62], we focus on networks hosting sensor tags in the bistatic configuration (separated receiver from carrier generator).\nSensor tags leverage backscatter techniques to perform bidirectional communication with their hosting IoT node over standard physical layer protocols [10, 26, 44, 52]. They achieve their low-power operation by offloading the local oscillator to a neighboring IoT node (different from its host), which provides the tag with an unmodulated carrier [47]. The COTS IoT nodes achieve this by, e.g., using their radio test mode [44]. An IoT node in the network hosts zero or more sensor tags. Moreover, we assume that a sensor tag is hosted by exactly one IoT node responsible for querying the sensor readings. Sensor tags are located within decimeters range to its hosting IoT node, while the IoT nodes in the network are within meters from each other (see Figure 3).\nThe host-to-tag communication occurs over a time-slotted channel access mechanism due to its ease of integration of sensor tags and their widespread use in commodity devices. Both Bluetooth and Zigbee/IEEE 802.15.4 support this in their standards [4, 21]."}, {"title": "2.2 Existing Schedulers", "content": "A scheduler is a system that receives a description of the IoT network hosting sensor tags, and computes a schedule for interrogating the sensor tags. While recent work explores autonomous scheduling for TDMA based networks [7], carrier scheduling requires more powerful hardware for such purposes. In general, carrier scheduling can be solved analytically by using a CO to obtain the optimal schedule. However, this is only feasible for small-sized IoT networks, since the NP-Hard nature of the problem prevents the practical application of the CO due to the long runtimes (e.g., up to 10 hours for a 10-node network).\nAlternatively, P\u00e9rez-Penichet et al. present TagAlong [45], a heuristic algorithm that uses graph coloring to compute schedules. While TagAlong exhibits polynomial runtime, its performance becomes increasingly sub-optimal as the network size increases. Additionally, P\u00e9rez-Ram\u00edrez et al. present DeepGANTT [46], the first ML-based system for carrier scheduling that iteratively builds the schedule timeslot by timeslot. DeepGANTT learns from optimal schedules (computed by a CO) of networks of up to 10 IoT nodes and 14 sensor tags [46]. It generalizes to networks of up to 60 nodes, achieving significant reduction in the number of carriers required in the schedule against TagAlong. In this work, we advance learning-based scheduling by considering networks of hundreds of nodes, far beyond DeepGANTT's capabilities."}, {"title": "2.3 Learning-based Scheduling", "content": "Several works explore applying ML and GNNs for both COP and scheduling [3, 5, 23, 35, 39, 40, 55, 56], but few explore their usage for backscatter networks [46]. In this work, we"}, {"title": "3 Carrier Scheduling Problem", "content": "The COP of computing a schedule to interrogate all sensor tags in an IoT network while minimizing both the length of the schedule L and the number of carrier slots C is described as follows. We model the network as an undirected connected graph G, defined by the tuple $G = (V_a, E)$, where $V_a$ is the set of N IoT nodes in the network $V_a = {v_i}_{i=0}^{N-1}$, and E is the set of edges between the nodes $E = {(u, v) | u, v \\in V_a}$. The connectivity among IoT nodes is determined by the wireless link signal strength, i.e., there is an edge between two nodes only if there is a sufficiently strong wireless signal for providing unmodulated carrier [45, 46]. We denote the set of T tags in the network as $N_t = {t_i}_{i=1}^{T}$, and their respective tag-to-host assignment as $H_t: t \\in N_t \\leftrightarrow v \\in V_a$. The role of a node v within a timeslot s is indicated by the map $R_{v,s}: v \\in V_a, s \\in [1, L] \\rightarrow {C, T, 0}$, where L is the schedule length in timeslots. Hence, a timeslot $s_j$ consists of an N-dimensional vector containing the roles assigned to every node during timeslot j: $s_j = [R_{v_i, j}| v_i \\in V_a]^T$.\nFor a given problem instance $g = (G, N_t, H_t)$, the carrier scheduling problem is formulated as follows:\n$\\min \\quad (T \\cdot C + L)$\n$\\forall t \\in N_t \\quad \\exists ! s \\in [1, L] : R_{H_t, s} = T$\n$\\forall s \\in [1, L] \\forall t \\in N_t | R_{H_t, s} = T \\quad \\exists ! v_j \\in V_a : R_{v_j, s} = C \\land (H_t, v_j) \\in E$,\nwhere C is the total number of carriers required in the schedule. Constraints (3) and (4) enforce that tags are interrogated only once in the schedule and that there is exactly one carrier-providing neighbor per tag in each timeslot (to prevent collisions), respectively. The objective function (2) prioritizes reducing C over L because we are most concerned with energy and spectrum efficiency-reducing C often implies a reduction of L, but the converse is not necessarily true [46].\nSolutions to the carrier scheduling problem are highly symmetrical, which limits effective training of a supervised ML model [46]. Symmetries arise both from the network topology and from the sensor tags' distribution among the nodes. E.g., for a star topology hosting one sensor tag in the center node, any of the leaf nodes can be the carrier provider, but the scheduler needs to select only one of these. Additionally, we do not assume any a-priori order for tag interrogations. Hence, any of the L! permutations of a schedule's timeslots is also a valid schedule with the same length L and number of carrier slots C.\nSymmetry-breaking constraints allow to efficiently learn the behavior of the optimal scheduler and properly train an ML model [46]. For the training data generation procedure, we further constrain the optimization objective in Eq. 2 by enforcing two lexicographical minimizations: first of a vector of length T (number of tags) that indicates the timeslot when each tag is interrogated, and another length-T vector containing the node that provides the carrier for each tag."}, {"title": "4 RobustGANTT System Design", "content": "We consider networks consisting of COTS wireless IoT devices, or nodes, equipped with radio transceivers that support standard physical layer protocols, such as Bluetooth or IEEE 802.15.4/ZigBee. These nodes perform their regular computation and communication tasks according to their normal schedule [7, 47]. The IoT nodes are either battery-powered or connected to mains power. We extend the sensing capabilities of the nodes with battery-free sensor tags [44, 47], which"}, {"title": "4.1 System Description", "content": "RobustGANTT resides at the Edge/Cloud, and asynchronously receives requests by one or multiple IoT networks hosting battery-free sensor tags to compute schedules. Note that this is also true for any scheduler to tackle this problem due to the computational demands required in computing schedules. The interaction between RobustGANTT and the IoT network is depicted in Figure 1.\nFirst, the IoT network collects the MAC and routing protocol information to build the network topology G and the tag-to-host mapping Ht. In our evaluation in Sec. 6, we use metrics from both TSCH [8] and RPL [58], but the process is analogous for other physical layer and routing protocols. Upon detection of changes either in the network's connectivity or in the tag-to-host mapping, the network issues a request to RobustGANTT for computing a new schedule. Next, the scheduler receives the network information g and performs iterative node classification using a GNN model to compute the interrogation schedule timeslot by timeslot. Finally, RobustGANTT delivers the schedule back to the IoT network, where it is disseminated using existing network flooding mechanisms, such as Glossy [11].\nAt the core of RobustGANTT lies an attention-based GNN model to perform iterative one-shot node classification. In each iteration j, the GNN model receives as input a node feature matrix $X_j \\in R^{N \\times D}$ with D = 3 features per node, and delivers as output the scheduling timeslot $s_j \\in R^N$. The resulting sj corresponds to assigning each of the N nodes to one of three possible classes {T, C, 0}.\nRobustGANTT keeps a cached representation of the topology G and the tag-to-host mapping Ht that is updated after each iteration. After computing the jth timeslot sj, the tags assigned to be interrogated are removed from the cached representation of the topology, and a new input feature matrix is generated $X_{j+1}$ to compute the next scheduling timeslot $s_{j+1}$. Being a probabilistic model, RobustGANTT has a component for checking that sj complies with the scheduling constraints at each iteration. This process is repeated until there are no more tags in the cached topology."}, {"title": "4.2 Scheduling Approach", "content": "Upon receiving the IoT network information, RobustGANTT builds a graph representation of the topology and parses this information for input to"}, {"title": "4.3 Model Training", "content": "We train RobustGANTT with optimal schedules from relatively small networks that are computed by the optimal scheduler. We then use RobustGANTT to compute schedules for much larger and previously-unseen networks without the need for the scheduler to be re-trained.\nAs loss function, we select the modified cross-entropy loss that includes both a scaling factor to give more importance to the carrier generator class C [46], and L2 weight regularization [31, 33]. As optimizer, we use Adam with its default hyperparameters [28]. We use learning rate decay by 2% every epoch, with an initial learning rate $\\epsilon_{init} = 10^{-3}$. We early stop model training after 25 consecutive epochs without minimization of the validation loss, and save the best performing model based on the carrier-class F1-score [46]."}, {"title": "5 System GNN Model Design", "content": "We explore ML-related design aspects that provide Robust-GANTT with strong and consistent generalization to larger, previously unseen, IoT networks. We believe our findings not only advance carrier scheduling, but also provide insights on designing learning-based schedulers for IoT networks.\nSetup. We undergo a structured and sequential process in three stages, selecting the best configuration in each stage before transitioning to the next one: i) learning rate warmup, ii) local and global PE, and iii) increasing the number of attention heads. For each stage, we train multiple models according to Sec. 4.3 using the training dataset from Sec. 5.1.1, while fixing the hyperparameter configuration. To mitigate the effect of randomness, we fix the random seeds from software libraries at the application level: Python, PyTorch, and NumPy [12, 43]. Since the best performance for a given model configuration may greatly diverge from its average (see Figure 2), we train multiple, but identical, ML models for each configuration to assess their performance consistency to larger topologies. However, we are limited to training 4-8 models per configuration, since the training and subsequent deployment to larger graphs takes between 10-45 hours for a single model, depending on its configuration. Our analysis results in the training of over 50 ML scheduler models.\nAfter training, we deploy the models to compute schedules for the generalization dataset \u2013 previously unseen topologies of larger size than those trained (see Sec. 5.1.2). No re-training is done at this stage. We report mean and percentile statistics across the runs for each model configuration, and select the best one based on the performance metrics from Sec. 5.2.\nWe highlight the following key findings:"}, {"title": "5.1 Datasets", "content": "We train all models using the data fom Sec. 5.1.1. After training, their performance is compared on the dataset described in Sec. 5.1.2, on which the models are not trained."}, {"title": "5.1.2 Generalization Dataset", "content": "Consists of larger and previously unseen topologies on which models are not trained. We select the best performing model configuration in this dataset when deciding the final ML model. We consider 200 problem instances (network topologies and tag assignments) for every (N, T) pair from the sets $N \\in {10, 20, 40, 60, 80, 100}$ nodes and $T \\in {40, 80, 160, 240}$ tags-i.e., 4800 networks."}, {"title": "5.2 Performance Metrics", "content": "In this work, we are interested in the system-related aspects of RobustGANTT. Hence, we consider the following application-related performance metrics in ML model design.\n$\\Pi$-Correctly Computed Schedules. Given a set of IoT networks, $\\Pi \\in [0, 100] \\%$ represents the percentage of networks for which RobustGANTT produces a complete schedule -- one that interrogates all sensor tags. Since Robust-GANTT is a probabilistic model, we must account for cases in which the scheduler cannot produce all the required timeslots to query all sensor values in the network. If RobustGANTT fails to deliver all timeslots, even if it correctly delivered some of them, we consider it a failed schedule.\nThis metric directly relates to the energy and spectrum utilization of the network. It compares the total number of carrier generator slots C from the schedule generated by the TagAlong heuristic $C_{ta}$ against the total"}, {"title": "5.3 Results", "content": "We describe the considered ML design aspects and their influence in our system's generalization to larger topologies."}, {"title": "5.3.1 Influence of Warmup", "content": "Based on the findings from Ma et al. [37], we evaluate the influence of learning rate warm-up on the optimization. It involves starting training with a small learning rate $\\tilde{\\epsilon} << \\epsilon_{init}$ and gradually increase $\\tilde{\\epsilon}$ until reaching the initial learning rate $\\epsilon_{init}$. Intuitively, warmup provides more stability by regularizing the magnitude of parameter updates in early stages of training for momentum-based optimizers. Since such optimizers perform the parameter updates considering past statistical moments of the gradients, warmup allows the optimizer to calculate moments' statistics before performing big jumps in the parameter update, which reduces variance of the update steps [37].\nWe choose an untunned linear warmup schedule [37] due to its simplicity and competitive performance. It requires $2 * (1 - \\beta_2)^{-1}$ steps so that $\\tilde{\\epsilon} \\approx \\epsilon_{init}$, where $\\beta_2 = 0.999$ is Adam's second moment decay rate [28]. The warm-up update of the learning rate is performed as: $\\tilde{\\epsilon} = \\epsilon_{init} * \\min \\left(1, \\frac{i}{2 * (1 - \\beta_2)^{-1}}\\right)$, where i is the mini-batch iteration. We independently train two sets of eight identical models, with and without warmup."}, {"title": "5.3.2 Influence of Positional Encoding", "content": "We investigate augmenting the input node features to the GNN with PEs to aid the model in breaking symmetries. Based on the results from Sec. 5.3.1, all models are trained with warmup. We consider three types of PEs considering both local and global graph properties. We train four models for each PE configuration.\nNode Degree PE. We include one additional vector in the input node feature matrix that corresponds to the normalized node degree vector. Given the adjacency matrix $A \\in R^{N \\times N}$ of an undirected graph $G = (V_a, E)$ with $|V_a| = N$ nodes, where $A[u, v] = 1$ if (u, v) $\\in$ E and A[u, v] = 0 otherwise, the degree of node u is $d_u = \\sum_{v \\in V_a} A[u,v]$ [17]. We append the node degree vector d = $[d_u/d_{max}]_{u \\in V_a} \\in R^N$ as a column to the input node feature matrix $X \\in R^{N \\times D}$, where dmax is the degree with highest magnitude. Including node degree PE results in D = 3 + 1 = 4 input features per node.\nWe investigate using global properties of the graph as PE. We define the symmetric normalized graph Laplacian as $L = I - D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}}$, where D = diag(d) is the diagonal node degree matrix and I is the identity matrix. We perform EVD of L resulting in $L = V \\Lambda V^{-1}$, where $\\Lambda \\in R^{N \\times N}$ is a diagonal matrix containing the eigenvalues $\\lambda_i \\in R$ of L, and $V \\in R^{N \\times N}$ is a matrix containing the eigenvectors $v_i \\in R^N$ for $i \\in V_a$. We first augment the node feature matrix with a vector that contains the eigenvalues of the graph $\\Lambda = [\\lambda_i]_{i \\in V_a} \\in R^N$. We normalize $A$ using the highest eigenvalue. Including Eigvals PE results in D = 3 + 1 = 4 input features per node.\nWhile eigenvalues provide an indication of magnitude and transformation strength, eigenvectors contain richer geometric information in the directional properties. Eigenvectors are not unique, and suffer from sign invariance-i.e., if v is an eigenvector, so is -v. Geometrically, this means that they are nontrivial solutions for finding the EVD: any orthogonal change of basis of V yields the same Laplacian L [32].\nWhile early work introduces random eigenvector sign flipping during training to account for sign invariance [9, 30], recent work explores learning the invariances that account for changes in the eigenspace basis V [20, 36]. The goal is to learn a permutation-invariant transformation of A and V that accounts for their geometrical significance. We choose"}, {"title": "5.3.3 Influence of Attention Heads", "content": "We include warmup and node degree PE based on the results from the previous sections. We now evaluate the influence of model complexity by increasing the number of attention heads M in each of the GNN layers. We train eight models for each number-of-heads"}, {"title": "5.4 Final GNN Model", "content": "Our analysis from Sec. 5.3 results in a RobustGANTT model of 12 attention heads with node degree PE that is trained with warmup. It exhibits strong generalization to larger topologies, and its performance is consistent across independently trained models. We train RobustGANTT's model according to Sec. 4.3 using the dataset described in Sec. 5.1.1. Training the model with a mini-batch size of 1024 requires 22 hours on an NVIDIA A100 GPU."}, {"title": "6 Evaluation", "content": "In this section, we compare RobustGANTT's performance against the DeepGANTT scheduler in terms of resource savings over the TagAlong heuristic [45]. We use both simulated topologies and a real-life IoT network. The design choice of GNNs allows our scheduler to generalize to larger, previously unseen network topologies without retraining. Hence, no further RobustGANTT's ML model training is performed for these experiments.\nScalability to 1000-node topologies"}, {"title": "6.1", "content": "We evaluate RobustGANTT's generalization to larger topologies, far exceeding DeepGANTT's capabilities, while still achieving significant resource savings against TagAlong."}, {"title": "6.2 Performance for a Real IoT Network", "content": "We now evaluate RobustGANTT's ability to compute schedules for a real-life IoT network."}, {"title": "7 Discussion", "content": "RobustGANTT is a scheduler that far surpasses the generalization capabilities of existing learning-based systems. Our system can not only processes much larger IoT network topologies than previously possible, but also delivers more resource-efficient schedules.\nOur system is designed to reduce energy consumption in IoT networks. This is of paramount importance not only for sustainability reasons, but also because such networks are typically energy constrained. Moreover, ensuring energy savings without increasing querying latency is highly relevant, specially for dense network deployments, since it reduces spectrum utilization.\nThe NP-Hard nature of generating resource-efficient schedules requires deploying RobustGANTT at the Edge/Cloud, which is also true for other schedulers [45, 46]. However, one does not require deploying a RobustGANTT scheduler for every IoT network. Rather, one RobustGANTT instance can process requests from multiple IoT networks either in sequence, or by batching those requests and computing their schedules in parallel. However, the number of requests processed in parallel is limited by the total the amount of GPU memory available.\nRobustGANTT's schedules require roughly the same number of timeslots as those produced by TagAlong. This implies that our system does not sacrifice querying latency to achieve its significant energy savings. However, there are cases in which TagAlong schedules are shorter than those from RobustGANTT. We attribute this to the optimization objective (Eq. 2), which prioritizes reducing the number of carriers, since we are most interested in energy savings. Moreover, we do not envision backscatter sensor tags to assist in time-critical settings, but rather in energy-efficient sensing and monitoring.\nOur system exhibits average runtimes of hundreds of milliseconds, allowing it to react fast to connectivity changes in the IoT devices. Similarly, adding or removing IoT nodes would trigger a new request to compute a schedule. However, detecting the addition or removal of sensor tags to the IoT nodes is a general problem for the type of backscatter networks considered, and lies outside our scope."}, {"title": "8 Conclusion", "content": "We present RobustGANTT, a novel system that leverages the latest advancements in GNNs and ML to schedule communications in an IoT network augmented with backscatter sensor tags. We exploit our system design choice of using GNN to train our scheduler using optimal schedules from"}]}