{"title": "Robust Generalization of Graph Neural Networks for Carrier Scheduling", "authors": ["Daniel F. Perez-Ramirez", "Carlos P\u00e9rez-Penichet", "Nicolas Tsiftes", "Dejan Kosti\u0107", "Magnus Boman", "Thiemo Voigt"], "abstract": "Battery-free sensor tags are devices that leverage backscatter techniques to communicate with standard IoT devices, thereby augmenting a network's sensing capabilities in a scalable way. For communicating, a sensor tag relies on an unmodulated carrier provided by a neighboring IoT device, with a schedule coordinating this provisioning across the network. Carrier scheduling-computing schedules to interrogate all sensor tags while minimizing energy, spectrum utilization, and latency-is an NP-Hard optimization problem. Recent work introduces learning-based schedulers that achieve resource savings over a carefully-crafted heuristic, generalizing to networks of up to 60 nodes. However, we find that their advantage diminishes in networks with hundreds of nodes, and degrades further in larger setups. This paper introduces RobustGANTT, a GNN-based scheduler that improves generalization (without re-training) to networks up to 1000 nodes (100x training topology sizes). RobustGANTT not only achieves better and more consistent generalization, but also computes schedules requiring up to 2x less resources than existing systems. Our scheduler exhibits average runtimes of hundreds of milliseconds, allowing it to react fast to changing network conditions. Our work not only improves resource utilization in large-scale backscatter networks, but also offers valuable insights in learning-based scheduling.", "sections": [{"title": "1 Introduction", "content": "Recent advancements in backscatter communication enable the battery-free operation of sensor devices-termed sensor tags-that perform bi-directional communication with standard Internet of Things (IoT) devices [10, 22, 26, 27, 44, 52]. Such sensor tags can be added to an existing network of Commercial Off-The-Shelf (COTS) IoT devices to augment the network's sensing capabilities without requiring additional modifications to the IoT devices [47]. However, communication between a sensor tag and its hosting IoT device requires the provision of an unmodulated carrier by a neighboring IoT device. A schedule coordinates this provisioning globally across the network to interrogate all sensor values. Figure 1 shows the high-level procedure of computing a schedule, and its structure. It consists of one or more timeslots s, each assigning one of three possible actions to the IoT devices in the network: provide unmodulated carrier C, interrogate one of its hosted tags T, or remain idle 0.\nMotivation. Battery-free sensor tags provide a scalable, cost- and energy-efficient way to augment the sensing capabilities of existing IoT networks [27, 44, 47]. Their battery-free operation reduces electronic waste, and prevents extensive maintenance costs compared to battery-powered alternatives. It also allows placing sensors in hard-to-reach locations, such as medical implants, moving machinery, or embedded in physical infrastructure. The sensor tags may, e.g., prevent patients from undergoing surgery just to replace the battery of medical implants. Reducing the energy consumption of networks hosting sensor tags is of paramount importance not only for sustainability reasons, but also because such networks are often energy constrained.\nChallenges. Carrier scheduling-computing a schedule to interrogate all sensor tags while minimizing energy, spectrum utilization, and latency-is, in general, an NP-Hard combinatorial Optimization Problem (COP) [45]. It is similar to the traditional wireless link scheduling, but must consider additional constraints for tag interrogations and resource minimization (see Sec. 2.1). There are also several symmetries involved, both in permuting the timeslots and in selecting carrier generators [46]. E.g., in Figure 1, exchanging the timeslots' order alters neither the number of carriers required, nor the latency to query all tags. Also, for timeslot s3, nodes v2 and v3 are equally valid carrier providers for T5.\nA scheduler must process variable input-output structures: networks of different sizes, and schedules of different lengths. It must also leverage the topological structure of the network to favor using one carrier for multiple concurrent tag interrogations (e.g., timeslots s1 and s2 in Figure 1). Additionally, it must compute schedules in a timely manner to react to connectivity changes of the IoT network.\nCurrent Learning-based Schedulers exhibit Limited Scalability. In general, it is impractical to compute the analytically optimal schedule for IoT networks of hundreds of nodes and sensor tags. This implies running a Constraint Optimizer (CO) for several hours, most likely yielding an obsolete schedule due to changes in the network's connectivity. Alternatively, one can use the TagAlong scheduler [45], a carefully-crafted heuristic with polynomial runtime. However, its performance is increasingly sub-optimal as the network size increases. Recent work introduces DeepGANTT, a scheduler that learns from optimal schedules of small networks (up to 10 nodes) and scales to networks of up to 60 nodes, while reducing the number of carriers compared to TagAlong [46]. As we show in Sec. 6.2.2, reducing the number of carriers directly translates to energy savings.\nHowever, DeepGANTT presents two main issues when further scaling the problem to graphs larger than 60 nodes, as depicted in Figure 2. We train eight independent models"}, {"title": "Approach", "content": "In this paper, we leverage the latest advances in Graph Neural Networks (GNNs) and Machine Learning (ML) to present RobustGANTT, a scheduler for backscatter networks with strong and consistent generalization capabilities. To design RobustGANTT, we set out to explore ML-related training aspects, beginning with our own implementation of DeepGANTT. We train our scheduler with optimal schedules of networks of up to 10 nodes and 14 tags computed by a CO. The use of GNNs in our system design allows the scheduler to process variable input-output structures, and to process much larger, previously unseen topologies without the need for re-training. For designing our system, we investigate three aspects influencing the scheduler's generalization as follows.\nFirst, we assess the influence of warmup [37], and prove it highly beneficial for the model's ability to compute complete schedules for larger topologies. Furthermore, we explore incorporating Positional Encoding (PE) into the node features to enhance the GNN's ability to handle symmetries in schedule computation. We find that the node-degree PE offers the best trade-off for achieving good generalization, while avoiding the computation overhead of Eigenvalue Decomposition (EVD)-based methods. Finally, we study the influence of increasing the number of attention heads of the GNN layers to capture more complex topological dependencies among the IoT nodes in the network [41].\nContributions. Based on the former, we present Robust-GANTT, a novel GNN-based scheduler that generalizes to networks of up to 1000 nodes (100\u00d7 training sizes), far beyond the capabilities of current learning-based systems [46], while delivering schedules that require up to 2x less resources than those by the TagAlong heuristic [45]. Our system exhibits polynomial time complexity, allowing it to react fast to changing network conditions. Figure 2 shows how our scheduler not only outperforms DeepGANTT, but also exhibits consistent generalization across the independently trained models.\nTo evaluate RobustGANTT's capabilities on real-life IoT networks, we use it to compute schedules for a testbed with 23 nodes and varying number of sensor tags. Our system achieves 12% on average and up to 53% savings in energy and spectrum utilization compared to the TagAlong heuristic, which corresponds to up to 1.9\u00d7 more savings over the DeepGANTT scheduler. Furthermore, thanks to the polynomial time complexity of the model, it exhibits average runtime of 540 ms for the real IoT network, and achieves up to 2\u00d7 reduction in 95th percentile runtime against DeepGANTT. These characteristics enable RobustGANTT to compute schedules for IoT networks even in dynamic changing conditions.\nWe make the following specific contributions:"}, {"title": "2 Background and Related Work", "content": "Our work draws upon backscatter communication, scheduling for backscatter networks and ML for scheduling."}, {"title": "2.1 Backscatter Communication", "content": "Several recent efforts advance backscatter communications and battery-free networks [1, 10, 13, 15, 22, 24, 26, 27, 34, 38, 52, 63]. While some work focus on monostatic or multistatic backscatter configuration [19, 25, 61, 62], we focus on networks hosting sensor tags in the bistatic configuration (separated receiver from carrier generator).\nSensor tags leverage backscatter techniques to perform bidirectional communication with their hosting IoT node over standard physical layer protocols [10, 26, 44, 52]. They achieve their low-power operation by offloading the local oscillator to a neighboring IoT node (different from its host), which provides the tag with an unmodulated carrier [47]. The COTS IoT nodes achieve this by, e.g., using their radio test mode [44]. An IoT node in the network hosts zero or more sensor tags. Moreover, we assume that a sensor tag is hosted by exactly one IoT node responsible for querying the sensor readings. Sensor tags are located within decimeters range to its hosting IoT node, while the IoT nodes in the network are within meters from each other (see Figure 3).\nNode-to-Tag Communication. The host-to-tag communication occurs over a time-slotted channel access mechanism due to its ease of integration of sensor tags and their widespread use in commodity devices. Both Bluetooth and Zigbee/IEEE 802.15.4 support this in their standards [4, 21]. Figure 3 describes the communication between a tag T and its host v2, when assisted by a neighboring carrier provider IoT node v1. trx and ttx are the times for the sensor tag to receive the request-to-transmit from its host, and for transmitting the sensor value back, respectively. tcg is the time spent in carrier provisioning for tag-to-host communication. The timeslot is long enough to complete one request-response cycle between a node and a tag-e.g., two consecutive Time-Slotted Channel Hopping (TSCH) timeslots (10 ms each) for both transmitting the request to the tag and receive the response [46, 47]. During treq, v2 sends a request signal to v1 to start carrier provisioning, allowing v2 to regulate the frequency of tag interrogation-e.g., in a schedule with 10 timeslots (200 ms total duration with TSCH), a node might not want to query its tag 1000 ms/200 ms = 4 times per second.\nSchedule. A schedule coordinates the interrogation of all sensor tags and the provisioning of unmodulated carriers by the IoT nodes for such purposes. It consists of L \u2265 1 timeslots, each assigning one of three possible actions to IoT nodes in the network: interrogate one of its tags T, provide unmodulated carrier C for neighboring tags, or remain idle 0. We leverage the spatial distribution of nodes and tags to perform concurrent tag interrogations with one carrier provider (see Figure 4b). There are two constraints for performing tag interrogations [47]. First, due to the time-slotted channel access control mechanism, a node can interrogate only one of its hosting tags per timeslot. Additionally, for a tag to communicate with its hosting node, exactly one neighboring IoT node must provide it with an unmodulated carrier. Multiple impinging carriers on a sensor tag causes interference, and prevents proper tag interrogations (see Figure 4c).\nResource Efficiency. Two metrics determine a schedule's resource efficiency: the length of the schedule L and the number of carrier slots C. While L indicates the latency of querying all sensor values, C is directly related to spectrum utilization and energy consumption of the IoT network (see Sec. 6.2.2). Figures 4a and 4b show how resource efficient schedules exploit the topological structure of the network to re-use carrier generating nodes within a timeslot."}, {"title": "2.2 Existing Schedulers", "content": "A scheduler is a system that receives a description of the IoT network hosting sensor tags, and computes a schedule for interrogating the sensor tags. While recent work explores autonomous scheduling for TDMA based networks [7], carrier scheduling requires more powerful hardware for such purposes. In general, carrier scheduling can be solved analytically by using a CO to obtain the optimal schedule. However, this is only feasible for small-sized IoT networks, since the NP-Hard nature of the problem prevents the practical application of the CO due to the long runtimes (e.g., up to 10 hours for a 10-node network).\nAlternatively, P\u00e9rez-Penichet et al. present TagAlong [45], a heuristic algorithm that uses graph coloring to compute schedules. While TagAlong exhibits polynomial runtime, its performance becomes increasingly sub-optimal as the network size increases. Additionally, P\u00e9rez-Ram\u00edrez et al. present DeepGANTT [46], the first ML-based system for carrier scheduling that iteratively builds the schedule timeslot by timeslot. DeepGANTT learns from optimal schedules (computed by a CO) of networks of up to 10 IoT nodes and 14 sensor tags [46]. It generalizes to networks of up to 60 nodes, achieving significant reduction in the number of carriers required in the schedule against TagAlong. In this work, we advance learning-based scheduling by considering networks of hundreds of nodes, far beyond DeepGANTT's capabilities."}, {"title": "2.3 Learning-based Scheduling", "content": "Several works explore applying ML and GNNs for both COP and scheduling [3, 5, 23, 35, 39, 40, 55, 56], but few explore their usage for backscatter networks [46]. In this work, we explore GNNs to design a system that generates schedules for backscatter networks consisting of hundreds of nodes."}, {"title": "Graph Neural Networks", "content": "GNNs are a flexible ML tool for tackling various inference tasks on graphs, such as node classification [16, 51, 59]. Intuitively, stacking K GNN layers generates node embedding vectors that consider their K-hop neighborhood by utilizing the graph's structure and the relationships between nodes [14, 29]. These embeddings are generally processed further with linear layers to produce the final output based on the specific task. For instance, node classification can be achieved by feeding each node embedding vector through a classification layer. For a graph G = (V, E) with nodes v \u2208 V and edges (v, u) \u2208 E, at GNN layer i, each node feature vector hvi is updated as:\n$h_v^{i+1} = f_2(h_v^i, \\bigcup_{u \\in \\kappa(v)} f_1(h_v^i, h_u^i)),$\nwhere N(v) is the set of neighbors of node v with hu representing their feature vectors, and \u222a is a commutative aggregation function. f1, f2 are non-linear transformations [14]. For attention-based GNNs, additional learnable scaling parameters are included within \u222a to weight the contributions of neighboring nodes differently.\nOne key advantage of GNNs is their ability to leverage the structural dependencies within the graph, and their ability to perform inference on new graphs not encountered during training without needing to retrain the model [18, 54, 55].\nPE in GNNs. PE augments each node's input feature vector with additional information of its structural role in the graph. The intuition is to aid subsequent GNN layers to better distinguish the nodes involved in symmetries-i.e., to perform injective aggregation of neighboring nodes' features. Recent work explore PE with both local and global graph properties [2, 9, 20, 36, 50, 57]. While most focus on using PE to better distinguish different graphs, we are interested in assessing their advantage for effective node classification."}, {"title": "3 Carrier Scheduling Problem", "content": "The COP of computing a schedule to interrogate all sensor tags in an IoT network while minimizing both the length of the schedule L and the number of carrier slots C is described as follows. We model the network as an undirected connected graph G, defined by the tuple G = (Va, E), where Va is the set of N IoT nodes in the network Va = {vi}i=1, and E is the set of edges between the nodes E = {(u,v)|u,v\u2208 Va}.\nThe connectivity among IoT nodes is determined by the wireless link signal strength, i.e., there is an edge between two nodes only if there is a sufficiently strong wireless signal for providing unmodulated carrier [45, 46]. We denote the set of T tags in the network as N\u2081 = {ti}i=1, and their respective tag-to-host assignment as H\u2081 : t \u2208 N\u2081 \u2194 v \u2208 Va. The role of a node v within a timeslot s is indicated by the map Rv,s:\nv\u2208Va, s\u2208 [1,L] \u2192 {C, T, 0}, where L is the schedule length in timeslots. Hence, a timeslot sj consists of an N-dimensional vector containing the roles assigned to every node during timeslot j: sj = [Rvi,j|vi e Va]T.\nFor a given problem instance g = (G, N\u2081, H\u2081), the carrier scheduling problem is formulated as follows:\n$min (T \\cdot C + L)$ (2)\ns.t.   \u2200t\u2208Nt \u2203! s\u2208 [1,L] : RHt,s = T (3)\n\u2200s\u2208 [1,L] \u2200t\u2208Nt | RHt,s = T \u2203! vj\u2208 Va :\nRvj,s = C \u2227 (Ht, vj) \u2208\u0395, (4)\nwhere C is the total number of carriers required in the schedule. Constraints (3) and (4) enforce that tags are interrogated only once in the schedule and that there is exactly one carrier-providing neighbor per tag in each timeslot (to prevent collisions), respectively. The objective function (2) prioritizes reducing C over L because we are most concerned with energy and spectrum efficiency-reducing C often implies a reduction of L, but the converse is not necessarily true [46].\nSymmetry-Breaking Constraints. Solutions to the carrier scheduling problem are highly symmetrical, which limits effective training of a supervised ML model [46]. Symmetries arise both from the network topology and from the sensor tags' distribution among the nodes. E.g., for a star topology hosting one sensor tag in the center node, any of the leaf nodes can be the carrier provider, but the scheduler needs to select only one of these. Additionally, we do not assume any a-priori order for tag interrogations. Hence, any of the L! permutations of a schedule's timeslots is also a valid schedule with the same length L and number of carrier slots C.\nSymmetry-breaking constraints allow to efficiently learn the behavior of the optimal scheduler and properly train an ML model [46]. For the training data generation procedure, we further constrain the optimization objective in Eq. 2 by enforcing two lexicographical minimizations: first of a vector of length T (number of tags) that indicates the timeslot when each tag is interrogated, and another length-T vector containing the node that provides the carrier for each tag."}, {"title": "4 RobustGANTT System Design", "content": "We consider networks consisting of COTS wireless IoT devices, or nodes, equipped with radio transceivers that support standard physical layer protocols, such as Bluetooth or IEEE 802.15.4/ZigBee. These nodes perform their regular computation and communication tasks according to their normal schedule [7, 47]. The IoT nodes are either battery-powered or connected to mains power. We extend the sensing capabilities of the nodes with battery-free sensor tags [44, 47], which require an additional schedule to coordinate carrier provisioning and tag interrogations. This schedule is appended to the IoT network's normal schedule.\nWe base our system design on DeepGANTT and set to explore ML related aspects to design a scheduler with better and more robust generalization to larger networks."}, {"title": "4.1 System Description", "content": "RobustGANTT resides at the Edge/Cloud, and asynchronously receives requests by one or multiple IoT networks hosting battery-free sensor tags to compute schedules. Note that this is also true for any scheduler to tackle this problem due to the computational demands required in computing schedules. The interaction between RobustGANTT and the IoT network is depicted in Figure 1.\nFirst, the IoT network collects the MAC and routing protocol information to build the network topology G and the tag-to-host mapping H\u2081. In our evaluation in Sec. 6, we use metrics from both TSCH [8] and RPL [58], but the process is analogous for other physical layer and routing protocols. Upon detection of changes either in the network's connectivity or in the tag-to-host mapping, the network issues a request to RobustGANTT for computing a new schedule. Next, the scheduler receives the network information g and performs iterative node classification using a GNN model to compute the interrogation schedule timeslot by timeslot. Finally, RobustGANTT delivers the schedule back to the IoT network, where it is disseminated using existing network flooding mechanisms, such as Glossy [11].\nAt the core of RobustGANTT lies an attention-based GNN model to perform iterative one-shot node classification. In each iteration j, the GNN model receives as input a node feature matrix Xj \u2208 RN\u00d7D with D = 3 features per node, and delivers as output the scheduling timeslot sj e RN. The resulting sj corresponds to assigning each of the N nodes to one of three possible classes {T, C, 0}.\nRobustGANTT keeps a cached representation of the topology G and the tag-to-host mapping H\u2081 that is updated after each iteration. After computing the jth timeslot sj, the tags assigned to be interrogated are removed from the cached representation of the topology, and a new input feature matrix is generated Xj+1 to compute the next scheduling timeslot sj+1. Being a probabilistic model, RobustGANTT has a component for checking that sj complies with the scheduling constraints at each iteration. This process is repeated until there are no more tags in the cached topology."}, {"title": "4.2 Scheduling Approach", "content": "Input Node Feature Matrix. Upon receiving the IoT network information, RobustGANTT builds a graph representation of the topology and parses this information for input to the GNN model. The input node feature matrix to the GNN Xj consists of D = 3 features per node:\n(1) Hosted-Tags: the number of tags hosted by the node.\n(2) Node-ID: integer identifying the node in the graph.\n(3) Min. Tag-ID: integer that represents the minimum tag ID among tags hosted by the node.\nIntuitively, Hosted-Tags is decisive for assigning carrier-generating nodes - the node hosting the greatest number of tags in the network should avoid providing unmodulated carriers. Thanks to the symmetry-breaking constraints (\u00a73), including features 2 and 3 provides the scheduler with context on how to prioritize carrier-provider nodes, and with an order to interrogate the tags, respectively. In practice, network operators can exploit this by, e.g., prioritizing IoT nodes connected to mains power as carrier providers, or by prioritizing certain tags to be interrogated early in the schedule, simply by assigning them a lower node/tag-ID.\nML Model Architecture. Figure 5 depicts the system's ML model. The node feature matrix is first passed through a node-wise embedding layer, followed by a concatenation and layer normalization operation. Subsequently, the hidden representation is passed through a stack of 12 GNN layers, each containing both a linear activation and self-attention GNN. We fix 12 as the number of layers due to its wide application in language modelling with both GPT and BERT [6, 48, 49], and its success in learning-based schedulers [46]. The linear layer is a fully-connected neural network that acts on each node intermediate feature vector independently, while the GNN uses a multi-head attention mechanism of M heads for computing message passing operations [54]. The structure and skip connections of each GNN-Block is inspired by the Transformer architecture [53]."}, {"title": "4.3 Model Training", "content": "We train RobustGANTT with optimal schedules from relatively small networks that are computed by the optimal scheduler. We then use RobustGANTT to compute schedules for much larger and previously-unseen networks without the need for the scheduler to be re-trained.\nAs loss function, we select the modified cross-entropy loss that includes both a scaling factor to give more importance to the carrier generator class C [46], and L2 weight regularization [31, 33]. As optimizer, we use Adam with its default hyperparameters [28]. We use learning rate decay by 2% every epoch, with an initial learning rate einit = 10-3. We early stop model training after 25 consecutive epochs without minimization of the validation loss, and save the best performing model based on the carrier-class F1-score [46]."}, {"title": "5 System GNN Model Design", "content": "We explore ML-related design aspects that provide Robust-GANTT with strong and consistent generalization to larger, previously unseen, IoT networks. We believe our findings not only advance carrier scheduling, but also provide insights on designing learning-based schedulers for IoT networks.\nSetup. We undergo a structured and sequential process in three stages, selecting the best configuration in each stage before transitioning to the next one: i) learning rate warmup, ii) local and global PE, and iii) increasing the number of attention heads. For each stage, we train multiple models according to Sec. 4.3 using the training dataset from Sec. 5.1.1, while fixing the hyperparameter configuration. To mitigate the effect of randomness, we fix the random seeds from software libraries at the application level: Python, PyTorch, and NumPy [12, 43]. Since the best performance for a given model configuration may greatly diverge from its average (see Figure 2), we train multiple, but identical, ML models for each configuration to assess their performance consistency to larger topologies. However, we are limited to training 4-8 models per configuration, since the training and subsequent deployment to larger graphs takes between 10-45 hours for a single model, depending on its configuration. Our analysis results in the training of over 50 ML scheduler models.\nAfter training, we deploy the models to compute schedules for the generalization dataset - previously unseen topologies of larger size than those trained (see Sec. 5.1.2). No re-training is done at this stage. We report mean and percentile statistics across the runs for each model configuration, and select the best one based on the performance metrics from Sec. 5.2.\nWe highlight the following key findings:\n\u2022 Warm-up significantly contributes to computing complete and correct schedules for larger topologies.\n\u2022 Node degree PE allows for a good trade-off to assist in breaking graph symmetries with a low-overhead PE method.\n\u2022 12 attention heads consistently achieves good generalization performance to larger topologies."}, {"title": "5.1 Datasets", "content": "We train all models using the data fom Sec. 5.1.1. After training, their performance is compared on the dataset described in Sec. 5.1.2, on which the models are not trained."}, {"title": "5.1.1 Training Dataset", "content": "We use artificially generated problem instances (topologies and tag assignments) according to Perez-Ramirez et al. [46]. The dataset contains 580000 problem instances with networks of 2-10 nodes and 1-14 tags that are randomly assigned. We use the optimal scheduler to obtain schedules for these problem instances. This implies using a CO to solve analytically the COP described in Sec. 3. We use 80%-20% training and validation data splits."}, {"title": "5.1.2 Generalization Dataset", "content": "Consists of larger and previously unseen topologies on which models are not trained. We select the best performing model configuration in this dataset when deciding the final ML model. We consider 200 problem instances (network topologies and tag assignments) for every (N, T) pair from the sets N \u2208 {10, 20, 40, 60, 80, 100} nodes and T \u2208 {40, 80, 160, 240} tags-i.e., 4800 networks."}, {"title": "5.2 Performance Metrics", "content": "In this work, we are interested in the system-related aspects of RobustGANTT. Hence, we consider the following application-related performance metrics in ML model design.\n\u041f-Correctly Computed Schedules. Given a set of IoT networks, \u03a0\u2208 [0, 100]% represents the percentage of networks for which RobustGANTT produces a complete schedule - one that interrogates all sensor tags. Since Robust-GANTT is a probabilistic model, we must account for cases in which the scheduler cannot produce all the required timeslots to query all sensor values in the network. If RobustGANTT fails to deliver all timeslots, even if it correctly delivered some of them, we consider it a failed schedule.\nAc-Carriers Saved. This metric directly relates to the energy and spectrum utilization of the network. It compares the total number of carrier generator slots C from the schedule generated by the TagAlong heuristic Cta against the total number of carrier slots from the schedule computed by a learning-based scheduler Cnn as: Ac = Cnn \u2013 Cta."}, {"title": "5.3 Results", "content": "We describe the considered ML design aspects and their influence in our system's generalization to larger topologies."}, {"title": "5.3.1 Influence of Warmup", "content": "Based on the findings from Ma et al. [37], we evaluate the influence of learning rate warm-up on the optimization. It involves starting training with a small learning rate \u1ebd << Einit and gradually increase \u1ebd until reaching the initial learning rate Einit. Intuitively, warmup provides more stability by regularizing the magnitude of parameter updates in early stages of training for momentum-based optimizers. Since such optimizers perform the parameter updates considering past statistical moments of the gradients, warmup allows the optimizer to calculate moments' statistics before performing big jumps in the parameter update, which reduces variance of the update steps [37].\nWe choose an untunned linear warmup schedule [37] due to its simplicity and competitive performance. It requires 2 *(1-\u03b22)-1 steps so that \u1ebd \u2248 \u20acinit, where \u03b22 = 0.999 is Adam's second moment decay rate [28]. The warm-up update of the learning rate is performed as: \u1ebd = \u20acinit * min (1,(1-\u03b21)*i), where i is the mini-batch iteration. We independently train two sets of eight identical models, with and without warmup.\nWarmup contributes to higher II values. Without warmup, Figure 6a shows how the performance from the percentage of correctly computed schedules II deteriorates (also with increasing std-err) as the topology size increases. Including warmup significantly mitigated the variance in I for the larger topologies, as shown in Figure 6b. Moreover, it improves Carriers Saved Ac values for the 25th, mean, 75th and 95th percentiles in topologies of up to 60 nodes. However, the average performance of Ac across the multiple runs is similar for 100 node topologies, with only marginal improvements when including warmup. Moreover, including warm-up also reduced the standard error of all metrics (vertical lines), regardless of the topology size."}, {"title": "5.3.2 Influence of Positional Encoding", "content": "We investigate augmenting the input node features to the GNN with PEs to aid the model in breaking symmetries. Based on the results from Sec. 5.3.1, all models are trained with warmup. We consider three types of PEs considering both local and global graph properties. We train four models for each PE configuration.\nNode Degree PE. We include one additional vector in the input node feature matrix that corresponds to the normalized node degree vector. Given the adjacency matrix A \u2208 RN\u00d7N of an undirected graph G = (Va, E) with |Va| = N nodes, where A[u, v] = 1 if (u, v) \u2208 E and A[u, v] = 0 otherwise, the degree of node u is du = \u2211v\u2208Va A[u,v] [17]. We append the node degree vector d = [du/dmax]ueVa e RN as a column to the input node feature matrix X \u2208 RN\u00d7D, where dmax is the degree with highest magnitude. Including node degree PE results in D = 3 + 1 = 4 input features per node.\nEigenvalues of Graph Laplacian (Eigvals PE). We investigate using global properties of the graph as PE. We define the symmetric normalized graph Laplacian as L = I \u2212 D\u2212\u00bd AD\u2212\u00bd, where D = diag(d) is the diagonal node degree matrix and I is the identity matrix. We perform EVD of L resulting in L = VAV\u2212\u00b9, where A \u2208 RN\u00d7N is a diagonal matrix containing the eigenvalues \u03bbi \u2208 R of L, and V \u2208 RN\u00d7N is a matrix containing the eigenvectors vi e RN for i \u2208 Va. We first augment the node feature matrix with a vector that contains the eigenvalues of the graph \u00c2 = [li]iev, \u2208 RN. We normalize \u00c2 using the highest eigenvalue. Including Eigvals PE results in D = 3 + 1 = 4 input features per node.\nStable and Expressive Positional Encodings (SPE PE). While eigenvalues provide an indication of magnitude and transformation strength, eigenvectors contain richer geometric information in the directional properties. Eigenvectors are not unique, and suffer from sign invariance-i.e., if v is an eigenvector, so is -v. Geometrically, this means that they are nontrivial solutions for finding the EVD: any orthogonal change of basis of V yields the same Laplacian L [32].\nWhile early work introduces random eigenvector sign flipping during training to account for sign invariance [9, 30], recent work explores learning the invariances that account for changes in the eigenspace basis V [20, 36]. The goal is to learn a permutation-invariant transformation of A and V that accounts for their geometrical significance. We choose the Stable and Expressive PE (SPE) method presented by Huang et al. [20] due to its benefits over previous methods [36]. We construct a PE matrix \u0393\u2208 RN\u00d7Z using the first Z smallest Eigenvalues \u00c2 = [\u00d1i]ie[o:z] \u2208 RZ and Eigenvectors V = [V[:,i]]i\u20ac[0:Z] \u2208 RN\u00d7Z as [20]:\n\u0393 = p ( diag($1(^)),..., diag($m())), (5)\nwhere p is a permutation invariant function and {$i}i=1 are m independent linear transformations. We implement p using a Graph Isomorphism Network [60] and 6 with multi-layer perceptrons, using the same hyperparameters as Huang et al. [20]. However, as we operate on a supervised setting, the choice of Z is determined by the training graph sizes (topologies up to 10 nodes). Hence, we choose the first Z = 9 eigenvalues larger than 0 and their eigenvectors. Including SPE PE results in D = 3 + Z = 12 input features per node.\nNode degree PE provides the best trade-off between symmetry-breaking and computational overhead. Figure 7 depicts the model's performance for different PE methods. While SPE achieved the best carrier saved Ac results in topologies up to 20 nodes (Figure 7a), its II value significantly reduces for an increasing number of sensor tags. Moreover, it is completely unable to compute schedules for topologies of 60 and 100 nodes (I = 0). Moreover, Figures 7b and 7c for Eigvals PE and node degree PE show similar profiles. Notably, node degree PE achieves higher 75th and 95th percentile values for both 60 node and 100 node topologies. Additionally, node degree PE does not incur in the expensive computation overhead of estimating the EVD. E.g., it takes on average 450 ms extra to compute the EVD on a multi-core processor for 100 node topologies. Hence, node degree PE representsgood trade-off to improve the performance, while avoiding the EVD computation overhead."}, {"title": "5.3.3 Influence of Attention Heads", "content": "We include warmup and node degree PE based on the results from the previous sections. We now evaluate the influence of model complexity by increasing the number of attention heads M in each of the GNN layers. We train eight models for each number-of-heads value in M = {4, 8, 12}, and four 16-head models due to their long runtimes (+40 hours per model). We report average and standard error from performance metrics' statistics.\n12 heads crucial for robust generalization. Figure 8 shows the influence of increasing the number of attention heads in the model. As observed from Figure 8a- 8c, increasing the attention heads implies an increase in the carriers saved Ac performance for all percentiles. While the models from 8 heads and 12 heads exhibit similar performance, the overall stability of 12 heads is better for both percentage of correctly computed schedules II and for pushing the 25th percentile of Ac above 0. Increasing the attention heads beyond 12 to 16 yields no benefit. On the contrary: Figure 8d shows how the mean and 25th percentile of Ac fall below 0."}, {"title": "5.4 Final GNN Model", "content": "Our analysis from Sec. 5.3 results in a RobustGANTT model of 12 attention heads with node degree PE that is trained with warmup. It exhibits strong generalization to larger topologies, and its performance is consistent across independently trained models. We train RobustGANTT's model according to Sec. 4.3 using the dataset described in Sec. 5.1.1. Training the model with a mini-batch size of 1024 requires 22 hours on an NVIDIA A100 GPU."}, {"title": "6 Evaluation", "content": "In this section, we compare RobustGANTT's performance against the DeepGANTT scheduler in terms of resource savings over the TagAlong heuristic [45]. We use both simulated topologies and a real-life IoT network. The design choice of GNNs allows our scheduler to generalize to larger, previously unseen network topologies without retraining. Hence, no further RobustGANTT's ML model training is performed for these experiments. We highlight the following key findings:\n\u2022 RobustGANTT far surpasses the generalization capabilities of DeepGANTT. It scales to 1000 node topologies, while increasingly saving resources compared to TagAlong without sacrificing latency (Figure 9).\n\u2022 Both RobustGANTT and DeepGANTT achieve resource savings against TagAlong for the real-life IoT network. However, our scheduler achieves up to 1.9\u00d7 more energy savings, up to a 5.7\u00d7 reduction in the schedule's latency, and up to 2x reduction in 95th percentile runtime compared to DeepGANTT (Figures 11 and 12).\n\u2022 For the real-life IoT network topology, RobustGANTT achieves an average runtime of 540ms, which allows it to react fast to changing network conditions."}, {"title": "6.1 Scalability to 1000-node topologies", "content": "We evaluate RobustGANTT's generalization to larger topologies, far exceeding DeepGANTT's capabilities, while still achieving significant resource savings against TagAlong."}, {"title": "6.1.1 Dataset", "content": "We consider 200 problem instances (simulated IoT networks with random sensor tag assignments) for (N,T) pairs from the sets N \u2208 {100, 500, 1000} nodes and \u03a4\u2208 {250, 500, 1000, 1500} sensor tags."}, {"title": "6.1.2 Performance metrics", "content": "Besides I and Ac (see Sec. 5.2), we consider a metric related to the schedule length L.\n\u2206L-Timeslots Saved. Relates to the latency of querying all sensor tag values in the network. Given a network topology, it compares the length of the schedule produced by TagAlong Lta against the length from the schedule produced by a learning-based scheduler Lnn as: \u2206L = Lta \u2013 Lnn."}, {"title": "6.1.3 Results", "content": "Figure 9a depicts the carriers saved Ac of both RobustGANTT and DeepGANTT against the TagAlong heuristic. RobustGANTT consistently achieves higher savings with both an increase in the number of nodes and number of sensor tags. Notably, even its 1st percentile lies above zero, i.e., for at least 99% of the cases RobustGANTT achieves savings against TagAlong. Our scheduler achieves on average 12% and up to a 1.4\u00d7 reduction in the number of carriers compared to TagAlong. Sec. 6.2.2 demonstrates how Ac directly translates to energy savings. The DeepGANTT scheduler is, however, only marginally better than TagAlong for 100-node topologies, and increasingly worse for larger networks. Additionally, DeepGANTT's correctly computed schedules II decreases for 100 nodes, while RobustGANTT's values are consistently I = 100%.\nRobustGANTT computes schedules requiring roughly the same number of timeslots as TagAlong (AL \u2248 0) as shown in Figure 9b. Hence, our scheduler achieves significant savings in energy and spectrum without a significant reduction in the latency to query all sensor tags. Across all topologies considered, RobustGANTT requires on average 1.12 additional timeslots compared to TagAlong. In contrast, DeepGANTT requires on average 20 additional timeslots, and achieves no resource savings for such large topologies. Moreover, Figure 9b shows how DeepGANTT requires increasingly more timeslots than our scheduler."}, {"title": "6.2 Performance for a Real IoT Network", "content": "We now evaluate RobustGANTT's ability to compute schedules for a real-life IoT network."}, {"title": "6.2.1 Testbed", "content": "Our experimental setup utilizes an indoor IoT testbed composed of 23 Zolertia Firefly devices running Contiki-NG [42] (see Figure 10). These devices employ the RPL routing protocol [58] and communicate via IPv6 over IEEE 802.15.4 TSCH [8]. Link connectivity data between IoT nodes was gathered at 30-minute intervals across a four-day span, assuming a link exists between node pairs when the signal strength reaches at least -75 dBm, suitable for carrier provisioning. Additionally, we enhanced each network topology by assigning simulated tags randomly to achieve various densities, defined as N/T = 23/T, for T \u2208 {46, 115, 230, 460}, with each density configuration tested 100 times."}, {"title": "6.2.2 Performance metrics", "content": "Besides \u03a0, \u2206c (see Sec. 5.2), and AL (see Sec. 6.1.2) we explicitly evaluate energy consumption. Moreover, percentages for Ac and A\u2081 imply normalization with respect to the heuristic values, e.g., \u2206c% = Ac/Cta.\n\u0394\u0395%-Energy Saved. We consider the average energy required for querying the tag's sensor values \u1ebc. It corresponds to the total energy required to interrogate all sensor tags Etot divided by the number of tags T in the network [46]:\n$\\tilde{E}=\\frac{E_{tot}}{T} = \\frac{1}{T}\\left( P_{txt_{tx}} + P_{rx}t_{req} + \\frac{C}{L}(t_{req} + t_{rx})+P_{tx}(t_{req} + t_{cg}) \\right),$ (6)\nwhere both Prx and Prx correspond to the radio power at transmit and receive mode, respectively. trx, ttx, treq, and tcg are defined as in Figure 3. Calculating a percentage of energy saved against the TagAlong scheduler corresponds to \u0394\u0395% = (Enn \u2013 \u0112ta)/\u0112ta. Given a schedule, all values in Eq. 6 except C are constant for calculating both \u0112ta and Enn. Hence, lower values of C directly translates to energy savings.\nWe adopt Prx = 72mW, Ptx = 102mW based on the Firefly's reference values. Moreover, we assume treq = ttx = 128\u00b5s, trx = 256\u00b5s, and tcg = 15.75ms [45, 46]."}, {"title": "6.2.3 Results", "content": "For the real-life IoT network, RobustGANTT achieves on average 14% and up to 53% energy savings \u0394\u0395% (i.e., up to 2x less energy) compared to TagAlong. Even for the highest tag densities N/T considered, our scheduler achieves 44% energy savings. Such savings represent up to 1.9x the savings achieved by DeepGANTT, as shown in Figure 11d. Figures 11a and 11d demonstrate the equivalence between Ac% and \u2206E%: a reduction in the number of carriers directly translates to energy savings.\nIn terms of latency to query all sensor values, Figure 11b shows how DeepGANTT always requires on average more timeslots than TagAlong. In contrast, our scheduler requires on average as many timeslots as TagAlong for tag densities 2.0 and 5.0, and 10. However, it requires on average 8.8 more timeslots for tag density 20. Figure 12 shows the runtime distributions of both schedulers across tag densities. Their profiles are those of heavy-tailed distributions. Both schedulers require roughly the same average runtimes across tag densities. In particular, RobustGANTT's average runtimes are 120 ms, 260 ms, 540 ms, and 1.2 sec for the respective tag densities 2, 5, 10, and 20. However, Figure 12 demonstrates how RobustGANTT reduces the runtime's 95th percentile up to a factor of 2\u00d7 compared to DeepGANTT.\nWhile the real-life network's size is within DeepGANTT's proven generalization capabilities [46], we demonstrate that our scheduler requires on average up to 1.9\u00d7 less carriers (energy savings), up to 5.7\u00d7 less timeslots (reduction in latency to query all sensor tags), and up to a 2\u00d7 reduction in 95th percentile runtime to compute the schedule."}, {"title": "7 Discussion", "content": "RobustGANTT is a scheduler that far surpasses the generalization capabilities of existing learning-based systems. Our system can not only processes much larger IoT network topologies than previously possible, but also delivers more resource-efficient schedules.\nLarge-scale IoT networks. Our system is designed to reduce energy consumption in IoT networks. This is of paramount importance not only for sustainability reasons, but also because such networks are typically energy constrained. Moreover, ensuring energy savings without increasing querying latency is highly relevant, specially for dense network deployments, since it reduces spectrum utilization.\nServing IoT networks in parallel. The NP-Hard nature of generating resource-efficient schedules requires deploying RobustGANTT at the Edge/Cloud, which is also true for other schedulers [45, 46]. However, one does not require deploying a RobustGANTT scheduler for every IoT network. Rather, one RobustGANTT instance can process requests from multiple IoT networks either in sequence, or by batching those requests and computing their schedules in parallel. However, the number of requests processed in parallel is limited by the total the amount of GPU memory available.\nLatency to query all sensor values. RobustGANTT's schedules require roughly the same number of timeslots as those produced by TagAlong (see Figures 9b and 11b). This implies that our system does not sacrifice querying latency to achieve its significant energy savings. However, there are cases in which TagAlong schedules are shorter than those from RobustGANTT. We attribute this to the optimization objective (Eq. 2), which prioritizes reducing the number of carriers, since we are most interested in energy savings. Moreover, we do not envision backscatter sensor tags to assist in time-critical settings, but rather in energy-efficient sensing and monitoring.\nDynamic Environments. Our system exhibits average runtimes of hundreds of milliseconds, allowing it to react fast to connectivity changes in the IoT devices. Similarly, adding or removing IoT nodes would trigger a new request to compute a schedule. However, detecting the addition or removal of sensor tags to the IoT nodes is a general problem for the type of backscatter networks considered, and lies outside our scope."}, {"title": "8 Conclusion", "content": "We present RobustGANTT, a novel system that leverages the latest advancements in GNNs and ML to schedule communications in an IoT network augmented with backscatter sensor tags. We exploit our system design choice of using GNN to train our scheduler using optimal schedules from small networks of up to 10 nodes, and demonstrate that RobustGANTT can seamlessly generalize without re-training to networks of up to 1000 nodes. Our scheduler surpasses the generalization capabilities of current learning-based systems, while achieving significant savings in energy usage, spectrum utilization, and compute runtime. RobustGANTT facilitates the large-scale integration of IoT networks with sensor tags, and significantly reduces their operational expenses by efficiently utilizing their resources."}]}