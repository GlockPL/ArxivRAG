{"title": "Deep Learning for Video Anomaly Detection: A Review", "authors": ["Peng Wu", "Chengyu Pan", "Yuting Yan", "Guansong Pang", "Peng Wang", "Yanning Zhang"], "abstract": "Video anomaly detection (VAD) aims to discover behaviors or events deviating from the normality in videos. As a long-standing task in the field of computer vision, VAD has witnessed much good progress. In the era of deep learning, with the explosion of architectures of continuously growing capability and capacity, a great variety of deep learning based methods are constantly emerging for the VAD task, greatly improving the generalization ability of detection algorithms and broadening the application scenarios. Therefore, such a multitude of methods and a large body of literature make a comprehensive survey a pressing necessity. In this paper, we present an extensive and comprehensive research review, covering the spectrum of five different categories, namely, semi-supervised, weakly supervised, fully supervised, unsupervised and open-set supervised VAD, and we also delve into the latest VAD works based on pre-trained large models, remedying the limitations of past reviews in terms of only focusing on semi-supervised VAD and small model based methods. For the VAD task with different levels of supervision, we construct a well-organized taxonomy, profoundly discuss the characteristics of different types of methods, and show their performance comparisons. In addition, this review involves the public datasets, open-source codes, and evaluation metrics covering all the aforementioned VAD tasks. Finally, we provide several important research directions for the VAD community.", "sections": [{"title": "I. INTRODUCTION", "content": "ANOMALY represents something that deviates from what is standard, normal, or expected. There are myriads of normalities, and anomalies are considerably scarce. However, when anomalies do appear, they often have a negative impact. Anomaly detection aims to discover these rare anomalies built on top of machine learning, thereby reducing the cost of man- ual judgment. Anomaly detection has widespread application across various fields [1], such as financial fraud detection, network intrusion detection, industrial defect detection, and human violence detection. Among these, video anomaly de- tection (VAD) occupies an important place, in which anomaly indicates the abnormal events in the temporal or spatial dimen- sions. VAD not only plays a vital role in intelligent security (e.g., violence, intrusion, and loitering detection) but is also widely used in other scenarios, such as online video content review and traffic anomaly prediction in autonomous driving [2]. Owing to its significant potential for applications across different fields, VAD has attracted considerable attention from both industry and academia.\nIn the pre-deep learning era, the routine way is to separate feature extraction and classifier design, which forms a two- stage process, and then combine them together during the inference stage. First, there is a feature extraction process to convert the original high dimensional raw videos into compact hand-crafted features based on prior knowledge of experts. Although hand-crafted features lack robustness and are difficult to use for capturing effective behavior expressions in the face of complex scenarios, these pioneer works deeply enlighten subsequent deep learning based works.\nThe rise of deep learning has made traditional machine learning algorithms fall out of favor over the last decade. With the rapid development of computer hardware and the massive data in the Internet era, we have witnessed great progress in developing deep learning based methods for VAD in recent years. For example, ConvAE [3], the first work using deep auto-encoders based on convolutional neural networks (CNNs) for capturing the regularities in videos; FuturePred [4], the first work making use of U-Net for forecasting future anomalies; DeepMIL [5], the first endeavor exploring deep multiple instance learning (MIL) framework for real-world anomalies. In order to more intuitively manifest the research enthusiasm for the VAD task in the era of deep learning, we conduct a statistical survey on the number of publications related to VAD over the past decade (the era driven by the rise of deep learning based methods) through Google"}, {"title": "II. BACKGROUND", "content": "As aforementioned, the studied problem, VAD, can be for- mally divided into five categories based on supervision signals. Different supervised VAD tasks aim to identify anomalous behaviors or events, but with different training and testing setups. We demonstrate these different VAD tasks in Figure 3.\nThe general VAD problem is presented as follows. Suppose we are given a set of training samples $X = {x_i}_{i=1}^{N+A}$ and corresponding labels $y$, where $X_n = {x_i}_{i=1}^{N}$ is the set of normal samples and $X_a = {x_i}_{i=N+1}^{N+A}$ is the set of abnormal samples. Each sample $x_i$ is accompanied by a corresponding supervision label $y_i$ in $Y$. During the training phase, the detection model $\\Phi(\\theta)$ takes $X$ as input and generates anomaly predictions; it is then optimized according to the following objective,\n$1 = L (\\Phi (\\theta,X), X \\text{ or } Y)$ (1)\nwhere $L(\\cdot)$ is employed to quantify the discrepancy between the predictions and the ground-truth labels or original samples. During inference, the detection model is expected to locate the abnormal behaviors or events in videos based on the generated anomaly predictions. Depending on the input to $L$, VAD can be categorized into one of the following five task settings.\nSemi-supervised VAD assumes that only normal samples are available during the training stage, that is, $X_a = \\emptyset$. This task aims to learn the normal patterns based on the training samples and consider the test samples which fall outside the learned patterns as anomalies. Pros and Cons: Only normal samples are required for training, hence, there is no need to painstakingly collect scarce abnormal samples. However, any unseen test sample may be recognized as abnormal, leading to a higher false positive rate.\nWeakly supervised VAD has more sufficient training sam- ples and supervision signals than semi-supervised VAD. Both normal and abnormal samples are provided during the training stage, but the precise location stamps of anomalies in these untrimmed videos are unknown. In other words, only coarse video-level labels are available (i.e., inexact supervision). Formally, $y = {0,1}^{+A}$, where $y_i = 0$ indicates that $x_i$ is normal, and $Y_i = 1$ indicates that $x_i$ is abnormal. Pros and Cons: Compared to fully supervised annotations, it can significantly reduce labeling costs. However, it places higher demands on algorithm design and may lead to situations of blind guessing.\nFully supervised VAD, as its name implies, comprises the complete supervision signals, meaning that each abnormal sample has precise annotations of anomalies. This task can be viewed as a standard video or frame classification problem. Due to the scarcity of abnormal behaviors and intensive manual labeling in reality, there has been little research on the fully supervised VAD task. It is noteworthy that video violence detection can be regarded as a fully supervised VAD, hence, we denote violence detection as a fully supervised VAD task in this paper. Formally, each video $x_i$ in $X_a$ is accompanied by a corresponding supervision label $y_i = {(t_0^j, t_0^j)}_{j=1}^{U_i}$, where $t_0^j$ and $t_0^j$ denote the start and end time of the j-th violence event, $U_i$ indicates the total number of anomalies present in the video. Pros and Cons: In contrast to weakly supervised VAD, with full supervised information, the detection perfor- mance of the algorithms would be remarkable. However, the corresponding drawback is the high requirement for intensive manual annotations.\nUnsupervised VAD aims to discover anomalies directly from fully unlabeled videos in an unsupervised manner. Thus, unsupervised VAD no longer requires labeling normal and abnormal videos to build the training set. It can be expressed formally as follows, $X = X_test$, and $y = \\emptyset$, in which $X_test$ denotes the set of test samples. Pros and Cons: No time-consuming effort is needed to collect training samples, avoiding the heavy labeling burden. Besides, this assumption also expands the application fields of VAD, implying that the detection system can continuously retrain without human intervention. Unfortunately, due to the lack of labels, the detection performance is relatively poor, leading to a higher rate of false positives and false negatives.\nOpen-set supervised VAD is devised to discover unseen anomalies that are not presented in the training set. Un- like semi-supervised VAD, open-set supervised VAD includes abnormal samples in the training set, which are referred to as seen anomalies. Specifically, for each $x_i$ in $X_a$, its corresponding label $y_i \\in Chase$, here $Chase$ represents the set of base (seen) anomaly categories, and $Chase \\subset C$, with"}, {"title": "III. SEMI-SUPERVISED VIDEO ANOMALY DETECTION", "content": "Based on our in-depth investigation of past surveys, we found that previous surveys mostly lack a scientific taxonomy, in which many surveys simply categorize semi-supervised VAD works into different groups based on usage approaches, such as reconstruction-based, distance-based, and probability- based approaches, and some surveys classify works according to inputs, such as image-based, optical flow-based, and patch- based approaches. It is particularly apparent that existing clas- sification reviews are relatively simplistic and superficial, thus making it challenging to cover all methods comprehensively and effectively. To address this issue, we establish a compre- hensive taxonomy, encompassing model input, methodology, architecture, model refinement, and model output. The detailed illustration is presented in Figure 4.\nAs aforementioned, only normal samples are available for training in the semi-supervised VAD task, rendering the su- pervised classification paradigm inapplicable. Common ap- proaches involve leveraging the intrinsic information of the training samples to learn deep neural networks (DNNs) for solving a pretext task. For instance, normality reconstruction is a classic pretext task [3]. During this process, several critical aspects need consideration: selection of sample information (Model Input), design of pretext tasks (Methodology), utiliza- tion of deep networks (Network Architecture), improvement of methods (Refinement), and expression of anomaly results (Model Output). These key elements collectively contribute to the effectiveness of semi-supervised VAD solutions. In the following sections, we introduce existing deep learning based VAD methods systematically according to the aforementioned taxonomy.\nExisting semi-supervised VAD methods typically use the raw video or its intuitive representations as the model input. Depending on the modality, these can be categorized as fol- lows: RGB images, optical flow, skeleton, and hybrid inputs, where the first three represent appearance, motion, and body posture, respectively.\n1) RGB: RGB images are the most common input for conventional vision tasks driven by deep learning techniques, and this holds true for the VAD task as well. Unlike other modalities, RGB images do not require additional processing steps such as optical flow calculations or pose estimation algorithms. In deep learning era, various deep models can be employed to extract compact and high-level visual features from these high-dimensional raw data. Utilizing these high-level features enables the design of more effective subsequent detection methods. Moreover, depending on the input size, RGB image based input can be categorized into three principal groups: frame level, patch level, and object level.\nFrame-level RGB input provides a macroscopic view of the entire scene, encompassing both the background, which is usually unrelated to the event, and the foreground objects, where anomalies are more likely to occur. The conventional approach typically uses multiple consecutive video frames as a single input to capture temporal context within the video, as seen in methods like ConvAE [3], ConvLSTM-AE [14], and STAE [15]. On the other hand, several research studies focus on using single-frame RGB as input, aiming to detect anomalies at the spatial level, such as AnomalyGAN [16] and AMC [17].\nPatch-level RGB input involves segmenting the frame-level RGB input spatially or spatio-temporally, which focuses on local regions, effectively separating the foreground from the background and differentiating between various individ- ual entities. The primary advantage of patch-level input is"}, {"title": "B. Methodology", "content": "For semi-supervised VAD, only normal samples are pro- vided during the training phase, rendering conventional su- pervised classification methods inapplicable. The current ap- proach involves designing a pretext task based on the prop- erties inherent in normal samples themselves to encapsulate a paradigm that encompasses all normal events, referred to as the normal paradigm or normal pattern. Through exten- sive research on existing works, we categorize three major approaches for learning the normal paradigm: self-supervised learning, one-class learning, and interpretable learning.\n1) Self-supervised Learning:\nSelf-supervised learning primarily leverages auxiliary tasks (pretext tasks) to derive supervisory signals directly from un- supervised data. Essentially, self-supervised learning operates without external labeled data, as these labels are generated from the input data itself. For semi-supervised VAD task, which lacks explicit supervisory signals, self-supervised learn- ing naturally becomes essential for learning normal represen- tations and constructing the normal paradigm based on these auxiliary tasks. Consequently, self-supervised learning based methods consistently dominate the leading position in semi- supervised VAD task. Throughout this process, a significant research focus and challenge lie in designing effective pretext tasks derived from the data itself. Here, we compile the common design principles of auxiliary tasks used in existing self-supervised learning based methods.\nReconstruction is currently the most commonly used pre- text task for self-supervised learning based methods in the field of semi-supervised VAD [3], [14], [17], [22], [48], [52]- [54]. The main process involves inputting normal data into the network, performing encoding-decoding operations, and generating reconstructed data, encouraging the network to produce reconstructions that closely match the original input data. The objective can be expressed as,\n$l_{rec} = L (\\Phi (\\theta, x),x)$ (2)\nFor convenience, in the following sections, unless otherwise specified, x represent normal data, which could be a normal video, a normal video frame, a normal feature, or similar. The above objective function measures the reconstruction error, which serves as a criterion for determining whether the test data is anomalous during the test stage. The larger the reconstruction error, the higher the probability that the data is considered anomalous. However, due to the high capacity of deep neural networks, reconstruction based methods cannot guarantee that larger reconstruction errors for abnormal events do necessarily happen.\nPrediction fully leverages the temporal coherence inherent in videos, which is also a commonly used pretext task. This pretext task is based on the assumption that normal events are predictable, while abnormal ones are unpredictable. Specifically, the prediction pretext task takes historical data as input and, through encoding-decoding operations within the network, outputs the predicted data for the current moment."}, {"title": "IV. WEAKLY SUPERVISED VIDEO ANOMALY DETECTION", "content": "Weakly supervised VAD is currently a highly regarded research direction in the VAD field, with its origins traceable to DeepMIL [5]. Compared to semi-supervised VAD, it is a newer research direction, and therefore existing reviews lack a comprehensive and in-depth introduction. As shown in Table I, both Chandrakala et al. [12] and Liu et al. [13] mention the weakly supervised VAD task. However, the former only briefly describes several achievements from 2018 to 2020, while the latter, although encompassing recent works, lacks a scientific taxonomy and simply categorizes them into single-modal and multi-modal based on the different modalities. Given this context, we survey related works from 2018 to the present, including the latest methods based on pre-trained large models, and we classify existing works from four aspects: model input, methodology, refinement strategy, and model output. The taxonomy of weakly supervised VAD is illustrated in Figure 8.\nCompared to semi-supervised VAD, weakly supervised VAD explicitly defines anomalies during the training process,"}, {"title": "V. FULLY SUPERVISED VIDEO ANOMALY DETECTION", "content": "Fully supervised VAD refers to the task of detecting video anomalies under the condition that the dataset has detailed frame-level or video-level annotations. Here, we consider video violence detection as a fully supervised VAD task.\nVideo violence detection typically takes the appearance, motion, skeleton, audio, or a combination of these as the input. It can be categorized based on the type of input into the following types:\nAppearance input mainly consists of raw RGB images, di- rectly showcasing the visual effect of video frames. This helps the model better understand anomalies that can be directly"}, {"title": "VI. UNSUPERVISED VIDEO ANOMALY DETECTION", "content": "Despite the great popularity of supervised VAD, supervised methods still have shortcomings in practical applications. On the one hand, we cannot clearly define what constitutes normal behavior of real-life human activities in many cases, e.g., running in a sports ground is normal but running in a library is forbidden. On the other hand, it is impractical to know every possible normal event in advance, especially for scientific research. Therefore, VAD in unsupervised environments is of significant research value.\nThrough an in-depth investigation, we roughly classify the current unsupervised VAD methods into 3 categories: pseudo label, change detection, and others."}, {"title": "VII. OPEN-SET SUPERVISED VIDEO ANOMALY DETECTION", "content": "It is challenging to make well-trained supervised model deployed in the open world detect unseen anomalies. Unseen anomalies are highly likely to occur in real-world scenarios, thus research on open-set anomaly detection has garnered sig- nificant attention. Open-set supervised VAD is a challenging task where the goal is to detect anomalous events in videos that are unseen during the training phase. Unlike traditional (closed-set) VAD, where the types of anomalies are known and well-defined, open-set VAD must handle unforeseen and unknown anomalies. This is crucial for real-world applications, as it is impractical to anticipate and annotate every possible anomaly during training. Therefore, research on open-set VAD has garnered significant attention. However, existing review works lack an investigation into open-set VAD. Based on this, we conduct an in-depth survey and make a systematic taxonomy of existing open-set VAD works. To our knowledge, this is the first review that includes a detailed introduction to open-set supervised VAD. In this section, we broadly categorize open-set supervised VAD into two types based on different research directions: open-set VAD and few-set VAD."}, {"title": "VIII. FUTURE OPPORTUNITIES", "content": "The current VAD benchmarks have various limitations in terms of data size, modality, and capturing views. Thus, an important future direction is to extend benchmarks along these dimensions for providing more realistic VAD test platforms.\n1) Large-scale: Currently, in VAD\u2014especially in semi- supervised VAD\u2014the data scale is too small. For example, the UCSD Ped dataset [228] lasts only a few minutes, and even the larger ShanghaiTech dataset [14] is only a few hours long. Compared to datasets in video action recognition tasks [229], which can last hundreds or thousands of hours, VAD datasets are extremely small. This is far from sufficient for training VAD models, as training on small-scale datasets is highly prone to over-fitting in large models. While this might lead to good detection results on the small-scale test data, it can severely impact the performance of VAD models intended for real-world deployment. Therefore, expanding the data scale is a key focus of future research.\n2) Multi-modal: Currently, there is limited research on multimodal VAD. Just as humans perceive the world through multiple senses [230], such as vision, hearing, and smell, effectively utilizing various modality information in the face of multi-source heterogeneous data can enhance the performance of anomaly detection. For example, using audio information can better detect anomalies such as screams and panic, while using infrared information can identify abnormal situations in dark environments.\n3) Egocentric, Multi-view, 3D, etc.: Egocentric VAD in- volves using data captured from wearable devices or body- mounted cameras to simulate how individuals perceive their environment and identify abnormal events, such as detecting falls or aggressive behavior in real time. Creating multi-view benchmarks that leverage data from viewpoints allows for a"}, {"title": "IX. CONCLUSION", "content": "We present a comprehensive survey of video anomaly detection approaches in the deep learning era. Unlike previous reviews mainly focusing on semi-supervised video anomaly detection, we provide a taxonomy that systematically divides the existing works into five categories by their supervision signals, e.g., semi-supervised, weakly supervised, unsuper- vised, fully supervised, and open-set supervised video anomaly detection. For each category, we further refine the categories based on model differences, e.g., model input and output, methodology, refinement strategy, and architecture, and we demonstrate the performance comparison of various methods. Finally, we discuss several promising research directions for deep learning based video anomaly detection in the future."}]}