{"title": "MetaOpenFOAM: an LLM-based multi-agent framework for CFD", "authors": ["Yuxuan Chen", "Xu Zhu", "Hua Zhou", "Zhuyin Ren"], "abstract": "Remarkable progress has been made in automated problem solving through societies of agents based on large language models (LLMs). Computational fluid dynamics (CFD), as a complex problem, presents unique challenges in automated simulations that require sophisticated solutions. MetaOpenFOAM, as a novel multi-agent collaborations framework, aims to complete CFD simulation tasks with only natural language as input. These simulation tasks include mesh pre- processing, simulation and post-processing, etc. MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks. Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs. Tests on a benchmark for natural language-based CFD solver, consisting of 8 CFD simulation tasks, have shown that MetaOpenFOAM achieved a high pass rate per test (85%), with each test case costing only $0.22 on average. The 8 CFD simulation tasks include compressible and incompressible flows, 2D and 3D flows, heat transfer, and combustion, demonstrating the ability to automate CFD simulations using only natural language input and iteratively correct errors to achieve the desired simulation at a low cost. An ablation study was conducted to verify the necessity of each component in the multi-agent system and the RAG technology. A sensitivity study on the randomness of LLM showed that LLM with low randomness can obtain more stable and accurate results. Additionally, MetaOpenFOAM own the ability to identify and modify key parameters in user requirements and excels in correcting bugs when failures occur, with or without human participation, which demonstrates the generalization of MetaOpenFOAM.", "sections": [{"title": "1. Introduction", "content": "Computational Fluid Dynamics (CFD) is a discipline that uses numerical methods to solve fluid mechanics problems [1]. Since the introduction of CFD, scientists and engineers have employed complex code to simulate and predict fluid behavior, with open-source software like OpenFOAM being a notable and mature example [2]. This approach requires researchers to possess high-level programming and specialized skills. As technology progresses, automated tools and user- friendly interfaces have emerged, allowing users to perform complex CFD simulations with simply clicking buttons on GUI, leading to the development of industrial software like Fluent [3] and COMSOL [4]. However, even with these improvements, conducting CFD simulations remains highly technical, requiring specialized knowledge and substantial manual operations. Recently, the rapid advancement of natural language processing (NLP) technologies, particularly the advent of large language model (LLM) [5-10], has brought new hope to CFD research, promising to revolutionize the field.\nThe emergence of LLM represents a significant breakthrough in natural language processing. LLM can understand and generate natural language, handling vast amounts of information and providing intelligent feedback. Recent advancements, such as GPT-4 [11], Llama 2 [12], and ChatGLM [13], have demonstrated powerful capabilities in tasks like translation, text generation, and question-answering. However, despite their impressive performance in many tasks, single LLM still face limitations in solving complex problems requiring extensive text generation [6, 9, 10, 14- 16]. For example, CFD problems typically involve intricate geometric modeling, physical modeling, and numerical methods, which exceed the current capabilities of individual LLM. To harness the potential of LLM in the CFD field, new approaches are needed to enhance their ability to tackle complex problems.\nTo address the limitations of single LLM in solving complex problems, the development of Multi-Agent System (MAS) has emerged as a promising approach [5-10, 16]. MAS involves the collaboration of multiple intelligent agents to complete complex tasks, with each agent focusing on different sub-tasks or domains, thereby improving the overall system's efficiency and accuracy. Notably, MAS can achieve unsupervised adversarial generation by iteratively having certain agents evaluate the text generated by other agents, helping refine and enhance the precision of the generated text to better meet user requirements. In CFD simulation tasks, MAS can assign different agents to"}, {"title": "2. Methodology", "content": "handle CFD task division, input file writing, CFD simulation, and CFD simulation result evaluation.\nThe evaluating agents can provide feedback to other agents, optimizing their outputs. Once implemented, this natural language-based MAS approach to CFD simulation can significantly lower the barrier to conducting CFD simulations and reduce the workload for researchers, making CFD studies more efficient and accessible.\nCurrently, various LLM-based tools have been developed to facilitate the collaboration and integration of multi-agent systems. MetaGPT [7] and Langchain [17] are two notable tools in this field. MetaGPT is a framework designed for multi-agent collaboration, enabling the coordination of multiple LLM agents to tackle complex CFD problems. Through MetaGPT, researchers can chain different LLM agents together, each playing a specific role, to accomplish tasks collectively. Langchain, on the other hand, is a tool for Retrieval-Augmented Generation (RAG) technology. By effectively integrating information from multiple documents, Langchain can provide more professional support for CFD research. Building on the MetaGPT and Langchain frameworks, this paper develops MetaOpenFOAM, a natural language-based CFD simulation framework. MetaOpenFOAM takes user requirements as input, generates OpenFOAM input files through LLM, and returns simulation results that meet user requirements after automatically running OpenFOAM.\nThe structure of this paper is as follows: first, the basic framework of MetaOpenFOAM and the implementation method of RAG are introduced. Next, a series of test datasets and evaluation methods for CFD simulations with natural language input are presented. Following this, the results of MetaOpenFOAM are quantitatively introduced, along with an ablation study and parameter sensitivity analysis. Finally, the results of MetaOpenFOAM are qualitatively analyzed."}, {"title": "2.1 MetaOpenFOAM Framework", "content": "As shown in Figure 1, MetaOpenFOAM is architected to interpret user requirements,\ndecompose them into manageable subtasks, and execute these subtasks through a series of specialized agents. The framework leverages the MetaGPT assembly line paradigm to assign distinct roles to each agent, ensuring efficient task execution and error handling.\nThe framework is divided into four primary roles, each with specific responsibilities and\nactions:\nArchitect (Role): This role is responsible for the initial interpretation of the user's natural"}, {"title": "2.2 Retrieval-Augmented Generation based on Langchain", "content": "Langchain's RAG technology is a critical component that supports MetaOpenFOAM by\nintegrating a searchable database of OpenFOAM official documents and tutorials. This system\nenhances the agents' ability to perform their tasks by providing relevant information and contextual\nguidance, ensuring that the framework can handle a wide range of CFD scenarios with minimal user\nintervention."}, {"title": "3. Experiment", "content": "Figure 2 shows the procedure of RAG in action \u201cFind similar case\" of MetaOpenFOAM. First,\nbased on the tutorials provided by OpenFOAM, a database containing file structures. These\ndocuments are then split into chunks. Each individual case is divided into separate chunk. A vector\nstore is then created using these chunks. After saving the database, it only requires querying to\nretrieve the most similar chunks. These chunks are then combined with the user message as input\nfor the LLM, completing the entire Retrieval-Augmented Generation (RAG) process. And for other\nactions of MetaOpenFOAM, the procedure of RAG is similar, and only the database should be\nchanged into file context or file command, corresponding to the OpenFOAM tutorials and\nOpenFOAM commands in Figure 1. During the actions \"Write input OpenFOAM files\" and\n\"Rewrite input OpenFOAM files,\" documents containing tutorial file contents are required. For the\naction \"Write the Allrun file,\" documents containing the collection of OpenFOAM execution\ncommands are needed to ensure that the written commands comply with the standards. Specific\nexamples of these documents can be found in Appendix B.\nThe more detailed document segmentation facilitates more accurate matching during retrieval.\nThe necessity of the above data-enhanced retrieval (RAG) method will be validated in Section 4.1."}, {"title": "3.1 Setup", "content": "MetaGPT v0.8.0 [7] was selected to integrate various LLMs, while OpenFOAM 10 [2] was\nutilized for CFD computations due to its stability and reliability as an open-source CFD solver. GPT-\n40 [11] was chosen as the representative LLM because of its outstanding performance. The\ntemperature of the LLM is set to 0.01 to ensure highly focused and deterministic outputs. The\ninfluence of temperature on performance is evaluated later in the paper."}, {"title": "3.2 Benchmarking Natural Language Input for CFD Solvers", "content": "For RAG technology, LangChain v0.1.19 [17] was employed to link the LLM and the database.\nThe FAISS vector store [18], known for its efficiency and user-friendliness, was used as the database\nvector store, and OpenAIEmbeddings were selected for embedding the data chunks. The \u201csimilarity\"\nmethod was utilized for matching similar chunks. The combination of retrieved documents and user\nmessages represents the simplest form of stacking. More details could be found in the code:\nhttps://github.com/Terry-cyx/MetaOpenFOAM\nCurrently, there are no public benchmarks for CFD user requirements to validate CFD solvers\nthat take natural language as input. Therefore, this paper derives several common simulation\nrequirements from OpenFOAM tutorials and lists several relevant simulations needs.\nIt is important to note that, from the user's perspective, natural language-based CFD user\nrequirements are generally incomplete. They cannot cover all the necessary information required\nfor input files and can only provide the most essential details, such as the case name, case category,\nsolver, mesh, boundary conditions, and initial conditions. Therefore, in the constructed cases below,\nonly partial information is provided as user requirements, aligning with the usage habits of natural\nlanguage.\n8 cases, covering 2D and 3D flows, heat transfer, and combustion, were tested. These cases\ninvolve three turbulence models: Reynolds-Averaged Navier-Stokes (RANS), Large Eddy\nSimulation (LES), and Direct Numerical Simulation (DNS). Both compressible and incompressible\nsolvers are included, along with methods for Newtonian and non-Newtonian fluids. All these cases\nwere modified from OpenFOAM tutorials, with specific parameters adjusted accordingly.\n\u2460 HIT: do a DNS simulation of incompressible forcing homogeneous isotropic turbulence\nwith Grid 32^3 using dnsFoam\n\u2461 PitzDaily: do a LES simulation of incompressible pitzDaily flow using pisoFoam with inlet\nvelocity = 5 m/s\n\u2462 Cavity: do a 2D RANS simulation of incompressible cavity flow using pisoFoam, with\nRANS model: RNGkEpsilon, grid 15*15*1\n\u2463 LidDrivenCavity: do an incompressible lid driven cavity flow simulation with the top wall\nmoves in the x direction at a speed of 1 m/s while the other 3 are stationary\n\u2464 SquareBendLiq: do a compressible simulation of squareBendLiq of using rhoSimpleFoam\nwith endTime = 100, deltaT = 1, and writeInterval = 10\nPlanarPoiseuille: do a laminar simulation of incompressible planar Poiseuille flow of a non-\nNewtonian fluid with grid 1*20*1, modelled using the Maxwell viscoelastic laminar stress\nmodel, initially at rest, constant pressure gradient applied from time zero"}, {"title": "3.3 Evaluation Metrics", "content": "\u2466 CounterFlowFlame: do a 2D laminar simulation of counterflow flame using reactingFoam\nin combustion with grid 50*20*1\n\u2467 BuoyantCavity: do a RANS simulation of buoyantCavity using buoyantFoam, which\ninvestigate natural convection in a heat cavity with a temperature difference of 20K is\nmaintained between the hot and cold; the remaining patches are treated as adiabatic.\nIt is essential to establish evaluation metrics to assess the performance of natural language-\nbased CFD solvers. These metrics need to consider common indicators in the CFD domain, such as\nsuccessful mesh generation and convergence of calculations, as well as computational costs and\ngeneration success rates (pass@k [19]) relevant to the LLM domain. Therefore, we evaluate the\npractical performance of natural language-based CFD solvers using the following five metrics: A,\nB, C, D for single experiments and E for multiple experiments.\nSingle experiments can be evaluated by the following metrics:\n(A) Executability: This metric rates input files on a scale from 0 (failure) to 4 (flawless). A\nscore of '0' indicates grid generation failure, '1' indicates grid generation success but running failure,\n'2' indicates that the case is runnable but does not converge, '3' indicates that the case runs to the\nendTime specified in the controlDict, and '4' indicates flawless input foam files, which not only run\nto the endTime but also meet all user requirements. A single experiment is considered to have passed\nthe test if its executability score reaches '4'. Among them, '1' to '3' can be judged automatically by\nthe program, but '4' requires human participation.\n(B) Cost: The cost evaluation includes (1) running time, (2) number of iterations, (3) token\nusage, and (4) expenses, which are proportional to token usage.\n(C) Code Statistics: This metric includes (1) the number of input files, (2) the number of lines\nper input file, and (3) the total number of lines in the input files.\n(D) Productivity: This metric is defined as the number of tokens used divided by the number\nof lines in the input files, representing token consumption per input line.\nFor multiple experiments, a new metric needs to be added:\n(E) the pass@k metric [19]: This metric represents the probability that at least one of the k\ngenerated input file samples passes the unit tests. It measures the model's ability to generate correct\ninput files within k attempts. We follow the unbiased version of pass@k as presented by Chen et al.\n(2021a) and Dong et al. (2023) to evaluate the pass@k of MetaOpenFOAM:"}, {"title": "3.4 Main results", "content": "Overall, the average pass rate (pass@1) of 85% and high executability score 3.6 demonstrate\nthe outstanding performance of MetaOpenFOAM. On average, each test case requires 44,045 tokens.\nGiven a cost of $5 per 1M tokens, generating one test case costs only $0.22, and each line of input\nfile consumes an average of 67.1 tokens, costing just $0.0003, which is significantly lower than\nmanual labor costs. Therefore, in terms of lowering the barrier to use, reducing labor costs, and\nincreasing efficiency, MetaOpenFOAM is revolutionary.\nFor different test cases, it can be seen that HIT, PitzDaily, Cavity, and SquareBendLiq have an\nexecutability score of 4, meaning flawless results that satisfy all user requirements. These cases\nrequire fewer iterations and fewer tokens. However, for cases with lower executability scores, such\nas BuoyantCavity and LidDrivenCavity, the LLM fails to correctly modify errors, resulting in more\niterations and higher token usage, and consequently, a lower pass@1 rate.\nAnalyzing the correlation between iteration and token usage, we find a Pearson correlation\ncoefficient of 0.89 with a p-value of 0.0013. This indicates a strong positive correlation between\niteration and token usage, and this correlation is statistically significant (p-value much less than\n0.05). The reason is evident: more iterations mean more input to the LLM. Therefore, in the"}, {"title": "4. Discussion", "content": "This section will discuss the necessity of each component in MetaOpenFOAM as well as\nsensitivity analysis of key parameters related to large language models and qualitative analysis of\nsome MetaOpenFOAM results."}, {"title": "4.1 Ablation Analysis", "content": "To validate the necessity of each component in MetaOpenFOAM, we removed some\ncomponents to quantitatively discuss how their removal influences the model outputs. Specifically,\nsince MetaOpenFOAM primarily consists of Roles, Actions, and RAG, the ablation study focused\non these three aspects.\nA. Remove \"Reviewer\" Role\nAs shown in section 2.1, there are 4 roles in MetaOpenFOAM where the Architect, InputWriter,\nand Runner are essential roles. Removing any of these would result in an executability of 0, making\nablation analysis meaningless. However, the Reviewer is not strictly necessary, allowing for\ncomparison with and without it. It's important to note that the Reviewer is the key component of\nMetaOpenFOAM that distinguishes automated multi-agent collaboration from a simple aggregation\nof single agents. Therefore, examining how the Reviewer affects model outputs is vital.\nB. Remove \"Review architecture\" action\nEach role involves several actions. Some actions, like creating the input architecture, writing\nOpenFOAM input files, and running OpenFOAM, are essential. Omitting these actions would\nobviously prevent the tests from passing. Therefore, we only considered the non-essential action of\n\"Review architecture\u201d. If \u201cReview architecture\" is missing, errors related to wrong file architecture\nbecome difficult to resolve.\nC. Remove RAG\nRAG technology is another key component of MetaOpenFOAM, providing professional\nknowledge missing from general LLMs. To verify the importance of RAG, we tested the\nperformance of MetaOpenFOAM without it."}, {"title": "4.2 Influence of parameter temperature", "content": "In LLM, the \"temperature\" is a key parameter, which controls the randomness and creativity of\nthe generated text. When the temperature is high (for example near 1), the probability distribution\nbecomes flatter, making the model more likely to choose fewer probable words. The generated text\nbecomes more diverse and creative, but it may also be less coherent or sensible. When the\ntemperature is low (for example near 0), the probability distribution becomes sharper, making the\nmodel more likely to choose the most probable words. The generated text becomes more\nconservative and coherent but less diverse and creative."}, {"title": "4.3 Generalizability Study", "content": "Therefore, a dynamic temperature model might be beneficial. It could dynamically adjust from\nlow to middle temperatures when low-temperature generation is ineffective, resulting in higher pass\nrates and lower costs in MetaOpenFOAM.\nIn this section, we will qualitatively analyze the performance of MetaOpenFOAM in some\nspecial situation such as requiring modification of key parameters, matching with less similar cases,\nor requiring human participation to improve performance.\nA. Key data identification and modification\nOne of the most important capabilities in a natural language based CFD simulation framework\nis the ability to identify changes to key data in the user requirement and correct those changes when"}, {"title": "5. Conclusion", "content": "For the first time, an LLM-based multi-agent framework for CFD was established,\nincorporating the construction of a multi-agent system based on MetaGPT and RAG technology\nbased on Langchain. Specifically, the multi-agent system consists of four roles: Architect,\nInputWriter, Runner, and Reviewer. These roles work together by first decomposing the CFD\nsimulation task into a series of input file generation subtasks (Architect), then generating the\ncorresponding input files based on the subtasks (InputWriter), running the CFD simulation (Runner),\nand finally providing feedback to the InputWriter by checking the simulation results (Reviewer)"}]}