{"title": "MetaOpenFOAM: an LLM-based multi-agent framework for CFD", "authors": ["Yuxuan Chen", "Xu Zhu", "Hua Zhou", "Zhuyin Ren"], "abstract": "Remarkable progress has been made in automated problem solving through societies of agents based on large language models (LLMs). Computational fluid dynamics (CFD), as a complex problem, presents unique challenges in automated simulations that require sophisticated solutions. MetaOpenFOAM, as a novel multi-agent collaborations framework, aims to complete CFD simulation tasks with only natural language as input. These simulation tasks include mesh pre-processing, simulation and post-processing, etc. MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks. Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs. Tests on a benchmark for natural language-based CFD solver, consisting of 8 CFD simulation tasks, have shown that MetaOpenFOAM achieved a high pass rate per test (85%), with each test case costing only $0.22 on average. The 8 CFD simulation tasks include compressible and incompressible flows, 2D and 3D flows, heat transfer, and combustion, demonstrating the ability to automate CFD simulations using only natural language input and iteratively correct errors to achieve the desired simulation at a low cost. An ablation study was conducted to verify the necessity of each component in the multi-agent system and the RAG technology. A sensitivity study on the randomness of LLM showed that LLM with low randomness can obtain more stable and accurate results. Additionally, MetaOpenFOAM own the ability to identify and modify key parameters in user requirements and excels in correcting bugs when failures occur, with or without human participation, which demonstrates the generalization of MetaOpenFOAM.", "sections": [{"title": "1. Introduction", "content": "Computational Fluid Dynamics (CFD) is a discipline that uses numerical methods to solve fluid mechanics problems [1]. Since the introduction of CFD, scientists and engineers have employed complex code to simulate and predict fluid behavior, with open-source software like OpenFOAM being a notable and mature example [2]. This approach requires researchers to possess high-level programming and specialized skills. As technology progresses, automated tools and user-friendly interfaces have emerged, allowing users to perform complex CFD simulations with simply clicking buttons on GUI, leading to the development of industrial software like Fluent [3] and COMSOL [4]. However, even with these improvements, conducting CFD simulations remains highly technical, requiring specialized knowledge and substantial manual operations. Recently, the rapid advancement of natural language processing (NLP) technologies, particularly the advent of large language model (LLM) [5-10], has brought new hope to CFD research, promising to revolutionize the field.\nThe emergence of LLM represents a significant breakthrough in natural language processing. LLM can understand and generate natural language, handling vast amounts of information and providing intelligent feedback. Recent advancements, such as GPT-4 [11], Llama 2 [12], and ChatGLM [13], have demonstrated powerful capabilities in tasks like translation, text generation, and question-answering. However, despite their impressive performance in many tasks, single LLM still face limitations in solving complex problems requiring extensive text generation [6, 9, 10, 14-16]. For example, CFD problems typically involve intricate geometric modeling, physical modeling, and numerical methods, which exceed the current capabilities of individual LLM. To harness the potential of LLM in the CFD field, new approaches are needed to enhance their ability to tackle complex problems.\nTo address the limitations of single LLM in solving complex problems, the development of Multi-Agent System (MAS) has emerged as a promising approach [5-10, 16]. MAS involves the collaboration of multiple intelligent agents to complete complex tasks, with each agent focusing on different sub-tasks or domains, thereby improving the overall system's efficiency and accuracy. Notably, MAS can achieve unsupervised adversarial generation by iteratively having certain agents evaluate the text generated by other agents, helping refine and enhance the precision of the generated text to better meet user requirements. In CFD simulation tasks, MAS can assign different agents to"}, {"title": "2. Methodology", "content": "Currently, various LLM-based tools have been developed to facilitate the collaboration and integration of multi-agent systems. MetaGPT [7] and Langchain [17] are two notable tools in this field. MetaGPT is a framework designed for multi-agent collaboration, enabling the coordination of multiple LLM agents to tackle complex CFD problems. Through MetaGPT, researchers can chain different LLM agents together, each playing a specific role, to accomplish tasks collectively. Langchain, on the other hand, is a tool for Retrieval-Augmented Generation (RAG) technology. By effectively integrating information from multiple documents, Langchain can provide more professional support for CFD research. Building on the MetaGPT and Langchain frameworks, this paper develops MetaOpenFOAM, a natural language-based CFD simulation framework. MetaOpenFOAM takes user requirements as input, generates OpenFOAM input files through LLM, and returns simulation results that meet user requirements after automatically running OpenFOAM.\nThe structure of this paper is as follows: first, the basic framework of MetaOpenFOAM and the implementation method of RAG are introduced. Next, a series of test datasets and evaluation methods for CFD simulations with natural language input are presented. Following this, the results of MetaOpenFOAM are quantitatively introduced, along with an ablation study and parameter sensitivity analysis. Finally, the results of MetaOpenFOAM are qualitatively analyzed."}, {"title": "2.1 MetaOpenFOAM Framework", "content": "As shown in Figure 1, MetaOpenFOAM is architected to interpret user requirements, decompose them into manageable subtasks, and execute these subtasks through a series of specialized agents. The framework leverages the MetaGPT assembly line paradigm to assign distinct roles to each agent, ensuring efficient task execution and error handling.\nThe framework is divided into four primary roles, each with specific responsibilities and actions:\nArchitect (Role): This role is responsible for the initial interpretation of the user's natural"}, {"title": "2.2 Retrieval-Augmented Generation based on Langchain", "content": "Langchain's RAG technology is a critical component that supports MetaOpenFOAM by integrating a searchable database of OpenFOAM official documents and tutorials. This system enhances the agents' ability to perform their tasks by providing relevant information and contextual guidance, ensuring that the framework can handle a wide range of CFD scenarios with minimal user intervention."}, {"title": "3. Experiment", "content": "MetaGPT v0.8.0 [7] was selected to integrate various LLMs, while OpenFOAM 10 [2] was utilized for CFD computations due to its stability and reliability as an open-source CFD solver. GPT-40 [11] was chosen as the representative LLM because of its outstanding performance. The temperature of the LLM is set to 0.01 to ensure highly focused and deterministic outputs. The influence of temperature on performance is evaluated later in the paper."}, {"title": "3.1 Setup", "content": "For RAG technology, LangChain v0.1.19 [17] was employed to link the LLM and the database. The FAISS vector store [18], known for its efficiency and user-friendliness, was used as the database vector store, and OpenAIEmbeddings were selected for embedding the data chunks. The \u201csimilarity\" method was utilized for matching similar chunks. The combination of retrieved documents and user messages represents the simplest form of stacking. More details could be found in the code:\nCurrently, there are no public benchmarks for CFD user requirements to validate CFD solvers that take natural language as input. Therefore, this paper derives several common simulation requirements from OpenFOAM tutorials and lists several relevant simulations needs.\nIt is important to note that, from the user's perspective, natural language-based CFD user requirements are generally incomplete. They cannot cover all the necessary information required for input files and can only provide the most essential details, such as the case name, case category, solver, mesh, boundary conditions, and initial conditions. Therefore, in the constructed cases below, only partial information is provided as user requirements, aligning with the usage habits of natural language.\n8 cases, covering 2D and 3D flows, heat transfer, and combustion, were tested. These cases involve three turbulence models: Reynolds-Averaged Navier-Stokes (RANS), Large Eddy Simulation (LES), and Direct Numerical Simulation (DNS). Both compressible and incompressible solvers are included, along with methods for Newtonian and non-Newtonian fluids. All these cases were modified from OpenFOAM tutorials, with specific parameters adjusted accordingly.\n\u2460 HIT: do a DNS simulation of incompressible forcing homogeneous isotropic turbulence with Grid 32^3 using dnsFoam\n\u2461 PitzDaily: do a LES simulation of incompressible pitzDaily flow using pisoFoam with inlet velocity = 5 m/s\n\u2462 Cavity: do a 2D RANS simulation of incompressible cavity flow using pisoFoam, with RANS model: RNGkEpsilon, grid 15*15*1\n\u2463 LidDrivenCavity: do an incompressible lid driven cavity flow simulation with the top wall moves in the x direction at a speed of 1 m/s while the other 3 are stationary\n\u2464 SquareBendLiq: do a compressible simulation of squareBendLiq of using rhoSimpleFoam with endTime = 100, deltaT = 1, and writeInterval = 10\nPlanarPoiseuille: do a laminar simulation of incompressible planar Poiseuille flow of a non-Newtonian fluid with grid 1*20*1, modelled using the Maxwell viscoelastic laminar stress model, initially at rest, constant pressure gradient applied from time zero"}, {"title": "3.2 Benchmarking Natural Language Input for CFD Solvers", "content": "\u2466 CounterFlowFlame: do a 2D laminar simulation of counterflow flame using reactingFoam in combustion with grid 50*20*1\n\u2467 BuoyantCavity: do a RANS simulation of buoyantCavity using buoyantFoam, which investigate natural convection in a heat cavity with a temperature difference of 20K is maintained between the hot and cold; the remaining patches are treated as adiabatic."}, {"title": "3.3 Evaluation Metrics", "content": "It is essential to establish evaluation metrics to assess the performance of natural language-based CFD solvers. These metrics need to consider common indicators in the CFD domain, such as successful mesh generation and convergence of calculations, as well as computational costs and generation success rates (pass@k [19]) relevant to the LLM domain. Therefore, we evaluate the practical performance of natural language-based CFD solvers using the following five metrics: A, B, C, D for single experiments and E for multiple experiments.\nSingle experiments can be evaluated by the following metrics:\n(A) Executability: This metric rates input files on a scale from 0 (failure) to 4 (flawless). A score of '0' indicates grid generation failure, '1' indicates grid generation success but running failure, '2' indicates that the case is runnable but does not converge, '3' indicates that the case runs to the endTime specified in the controlDict, and '4' indicates flawless input foam files, which not only run to the endTime but also meet all user requirements. A single experiment is considered to have passed the test if its executability score reaches '4'. Among them, '1' to '3' can be judged automatically by the program, but '4' requires human participation.\n(B) Cost: The cost evaluation includes (1) running time, (2) number of iterations, (3) token usage, and (4) expenses, which are proportional to token usage.\n(C) Code Statistics: This metric includes (1) the number of input files, (2) the number of lines per input file, and (3) the total number of lines in the input files.\n(D) Productivity: This metric is defined as the number of tokens used divided by the number of lines in the input files, representing token consumption per input line.\nFor multiple experiments, a new metric needs to be added:\n(E) the pass@k metric [19]: This metric represents the probability that at least one of the k generated input file samples passes the unit tests. It measures the model's ability to generate correct input files within k attempts. We follow the unbiased version of pass@k as presented by Chen et al. (2021a) and Dong et al. (2023) to evaluate the pass@k of MetaOpenFOAM:"}, {"title": "3.4 Main results", "content": "Table 1 presents the performance of MetaOpenFOAM on 8 test cases from the benchmark proposed in Section 3.2. The complete flow chart for the individual examples is described in detail in Appendix C, using HIT as an example. Only a selection of key metrics from Section 3.3 is displayed, while the rest are provided in Appendix D. Each metric for single experiments (A-D) is the average of n tests (n=10). For the iteration metric in the cost, max iteration is set to 20 in the program to prevent infinite iterations. If executability does not reach 3 or above after 20 iterations, the test is automatically marked as failed and the iteration is stopped.\nOverall, the average pass rate (pass@1) of 85% and high executability score 3.6 demonstrate the outstanding performance of MetaOpenFOAM. On average, each test case requires 44,045 tokens. Given a cost of $5 per 1M tokens, generating one test case costs only $0.22, and each line of input file consumes an average of 67.1 tokens, costing just $0.0003, which is significantly lower than manual labor costs. Therefore, in terms of lowering the barrier to use, reducing labor costs, and increasing efficiency, MetaOpenFOAM is revolutionary.\nFor different test cases, it can be seen that HIT, PitzDaily, Cavity, and SquareBendLiq have an executability score of 4, meaning flawless results that satisfy all user requirements. These cases require fewer iterations and fewer tokens. However, for cases with lower executability scores, such as BuoyantCavity and LidDrivenCavity, the LLM fails to correctly modify errors, resulting in more iterations and higher token usage, and consequently, a lower pass@1 rate.\nAnalyzing the correlation between iteration and token usage, we find a Pearson correlation coefficient of 0.89 with a p-value of 0.0013. This indicates a strong positive correlation between iteration and token usage, and this correlation is statistically significant (p-value much less than 0.05). The reason is evident: more iterations mean more input to the LLM. Therefore, in the"}, {"title": "4. Discussion", "content": "This section will discuss the necessity of each component in MetaOpenFOAM as well as sensitivity analysis of key parameters related to large language models and qualitative analysis of some MetaOpenFOAM results."}, {"title": "4.1 Ablation Analysis", "content": "To validate the necessity of each component in MetaOpenFOAM, we removed some components to quantitatively discuss how their removal influences the model outputs. Specifically, since MetaOpenFOAM primarily consists of Roles, Actions, and RAG, the ablation study focused on these three aspects.\nA. Remove \"Reviewer\" Role\nAs shown in section 2.1, there are 4 roles in MetaOpenFOAM where the Architect, InputWriter, and Runner are essential roles. Removing any of these would result in an executability of 0, making ablation analysis meaningless. However, the Reviewer is not strictly necessary, allowing for comparison with and without it. It's important to note that the Reviewer is the key component of MetaOpenFOAM that distinguishes automated multi-agent collaboration from a simple aggregation of single agents. Therefore, examining how the Reviewer affects model outputs is vital.\nB. Remove \"Review architecture\" action\nEach role involves several actions. Some actions, like creating the input architecture, writing OpenFOAM input files, and running OpenFOAM, are essential. Omitting these actions would obviously prevent the tests from passing. Therefore, we only considered the non-essential action of \"Review architecture\u201d. If \u201cReview architecture\" is missing, errors related to wrong file architecture become difficult to resolve.\nC. Remove RAG\nRAG technology is another key component of MetaOpenFOAM, providing professional knowledge missing from general LLMs. To verify the importance of RAG, we tested the performance of MetaOpenFOAM without it."}, {"title": "4.2 Influence of parameter temperature", "content": "In LLM, the \"temperature\" is a key parameter, which controls the randomness and creativity of the generated text. When the temperature is high (for example near 1), the probability distribution becomes flatter, making the model more likely to choose fewer probable words. The generated text becomes more diverse and creative, but it may also be less coherent or sensible. When the temperature is low (for example near 0), the probability distribution becomes sharper, making the model more likely to choose the most probable words. The generated text becomes more conservative and coherent but less diverse and creative."}, {"title": "4.3 Generalizability Study", "content": "In this section, we will qualitatively analyze the performance of MetaOpenFOAM in some special situation such as requiring modification of key parameters, matching with less similar cases, or requiring human participation to improve performance.\nA. Key data identification and modification\nOne of the most important capabilities in a natural language based CFD simulation framework is the ability to identify changes to key data in the user requirement and correct those changes when"}, {"title": "5. Conclusion", "content": "For the first time, an LLM-based multi-agent framework for CFD was established, incorporating the construction of a multi-agent system based on MetaGPT and RAG technology based on Langchain. Specifically, the multi-agent system consists of four roles: Architect, InputWriter, Runner, and Reviewer. These roles work together by first decomposing the CFD simulation task into a series of input file generation subtasks (Architect), then generating the corresponding input files based on the subtasks (InputWriter), running the CFD simulation (Runner), and finally providing feedback to the InputWriter by checking the simulation results (Reviewer)"}]}