{"title": "REPLAY CONSOLIDATION WITH LABEL PROPAGATION FOR CONTINUAL OBJECT DETECTION", "authors": ["Riccardo De Monte", "Davide Dalle Pezze", "Marina Ceccon", "Francesco Pasti", "Francesco Paissan", "Elisabetta Farella", "Gian Antonio Susto", "Nicola Bellotto"], "abstract": "Object Detection is a highly relevant computer vision problem with many applications such as robotics and autonomous driving. Continual Learning (CL) considers a setting where a model incrementally learns new information while retaining previously acquired knowledge. This is particularly challenging since Deep Learning models tend to catastrophically forget old knowledge while training on new data. In particular, Continual Learning for Object Detection (CLOD) poses additional difficulties compared to CL for Classification. In CLOD, images from previous tasks may contain unknown classes that could reappear labeled in future tasks. These missing annotations cause task interference issues for replay-based approaches. As a result, most works in the literature have focused on distillation-based approaches. However, these approaches are effective only when there is a strong overlap of classes across tasks. To address the issues of current methodologies, we propose a novel technique to solve CLOD called Replay Consolidation with Label Propagation for Object Detection (RCLPOD). Based on the replay method, our solution avoids task interference issues by enhancing the buffer memory samples. Our method is evaluated against existing techniques in CLOD literature, demonstrating its superior performance on established benchmarks like VOC and COCO.", "sections": [{"title": "1 Introduction", "content": "Object Detection is a critical computer vision problem involving both the localization and classification of objects within an image, with applications from robotics to autonomous driving [1]. However, a key challenge of Deep Learning systems is that they cannot learn incrementally over time, as they are prone to Catastrophic Forgetting [2, 3] when training on new data. Continual Learning (CL) addresses this problem, introducing techniques to learn new information over time while retaining previously acquired knowledge.\nMany CL studies focus on image classification, where replay-based approaches are the most common way to achieve strong results [4, 5, 6, 7]. These approaches involve storing a subset of samples from previous tasks in a memory buffer and replaying them when training on new data. However, Continual Learning for Object Detection (CLOD) is more complex because images seen in previous tasks may contain unlabeled classes that the model must learn as new classes in future tasks, causing missing annotations and training conflicts [8]. For example, the image in Fig. 1 has the"}, {"title": "2 Related Work", "content": "Continual Learning aims to enable DL models to continuously accumulate knowledge over time without the need to re-train from scratch and with limited access to past data [16]. In particular, this framework has emerged to tackle the Catastrophic Forgetting problem [2, 3]; after a DL model is trained on one task and subsequently trained on another, it tends to forget the previously learned task. The methods in the CL literature can be grouped into three big families: rehearsal, regularization, and architecture-based approaches.\nMost of the literature on Continual Learning for Object Detection focuses on the Class Incremental Learning (CIL) scenario, where each new task introduces new classes [8]. For example, Fig. 1 depicts a CLOD setting composed of three tasks where a new class must be learned each time. At the end of the training, the model should be able to provide predictions on all these classes. Moreover, most of the works were conducted on two-stage object detectors, whose time complexity scales linearly with the number of predicted objects in the scene. On the contrary, one-stage object detectors are known to be able to perform real-time object detection. In particular, recent papers focus on anchor-free architectures, with the most known probably being the modern versions of YOLO [15, 14, 17].\nThe first CL approach proposed for a CLOD scenario work is [18]. The authors propose to use the Learning without Forgetting (LwF) regularization-based approach in the context of a two-stage object detector, Fast-R-CNN [19]. LwF [20], following the idea of knowledge distillation [21], forces the outputs of the training model, called student, to be similar to the corresponding outputs of a frozen version of the model trained on old tasks, called teacher. Following this work, many subsequent approaches in the literature are distillation-based approaches [8].\nHowever, all of them consider either two-stage object detectors [19, 22] or old one-stage object detectors like YOLOv3 [23], which are not anchor-free like FCOS [24] or more recent versions of YOLO like v8 and v10 [17, 14].\nMore recent works applied to anchor-free fully convolutional detectors [25] revisit regularization-based algorithms for the FCOS object detector. Indeed, this type of model has a separate branch for regression outputs that introduces noise when training with techniques like LwF. Building on this work, a solution for CLOD on the Edge called Latent Distillation was proposed [26]. However, these solutions are tailored FCOS-based architectures, which makes its adoption in modern YOLO architectures challenging.\nAnother popular regularization-based approach is Pseudo Label [27]. Before training on the new task, the new task samples are passed through the old model, and its predicted labels are concatenated to the ground truth. However, like all distillation-based approaches, the main issue with pseudo-label is that performance remains high until images containing classes of the previous tasks are present in the new images. Otherwise, performance decreases quickly.\nAlso, Replay is used in the CLOD literature[8]. This method stores a portion of the old data in a memory buffer. While training on a new task, the new data is combined with the data from the memory buffer to maintain knowledge of old tasks. According to the CL literature for image classification, Replay is one the most effective solutions for catastrophic forgetting [4, 28].\nHowever, this is not the case in object detection, where task interference arises caused by the missing annotations. When training on a new task, images saved in the memory buffer during previous tasks may also present unlabeled instances of new classes. This means that for those buffer samples, the ground truth interferes with the new class knowledge that the model is trying to learn.\nTo address these issues, the authors of [12] building on the YOLOv3 architecture proposed to mask the loss associated with new classes during the training of old samples and vice-versa for the new data. However, the masking loss only partially solves the problem caused by the missing annotations. Indeed, this approach fails to fully leverage the potential information contained within the replay memory. Indeed, when saving the current task training samples in the replay memory, the images are labeled only on the classes of the current task but might contain instances of new classes (example in Fig. 3), leading to an under-utilization of the replay memory's potential."}, {"title": "3 Replay Consolidation with Label Propagation for Object Detection", "content": "To tackle the complexities of Object Detection within a Continual Learning framework, we combine multiple compo-nents to maximize their effectiveness and achieve optimal results.\nThe first component of our method is a Replay memory, but instead of randomly selecting the images for the memory buffer, we adopt the OCDM selection mechanism [10], which aims to have a memory buffer with a more balanced class distribution (see Fig. 4b). This selection mechanism is advantageous because it is tailored for settings like CLOD, where each image is associated with multiple labels. The second component is the Label Propagation mechanism, which fully leverages the memory buffer potential by integrating old and new knowledge into its ground truths, thus addressing the interference problems inherent in Replay. To further reduce the task interference problem, we introduce a Masking Loss specifically designed for the anchor-free YOLOv8 model, as explained in Sec. 3.2. Finally, to further decrease the forgetting of old knowledge, we also apply the Feature Distillation technique [11] as presented in Sec. 3.3."}, {"title": "3.1 Label Propagation", "content": "In multi-label classification and object detection, replay-based methods commonly face interference issues. This interference arises between the current task samples and the replayed samples when there is an overlap between task classes, as each sample ground truth only has information pertinent to the labels of the associated task. Moreover, the full potential of Replay buffers is not realized in these scenarios, as each sample is stored in the memory buffer with ground truth labels limited to the specific classes of its original task (see Fig. 3a).\nLabel Propagation, illustrated in Fig. 2, is composed of the forward and backward steps.\nIn the forward step, information from old labels is added to the new data during training and subsequently into the replay buffer through a pseudo-labeling technique. In detail, let $D_t = {X_t, Y_t}$ be the data of the current task t with labels corresponding to a set of classes $C_t$. During the training of task t, for a sample $(x, y) \\in D_t$, the forward step modifies the ground truth y adding pseudo-labels of the classes $C_1, ..., C_{t\u22121}$ by leveraging the knowledge of the previously trained model $f_{\\theta_{t\u22121}}$. Indeed, the model $f_{\\theta_{t\u22121}}$ provides predictions associated with classes $C_1, ..., C_{t-1}$."}, {"title": "3.2 Masking Loss", "content": "Label Propagation considerably reduces task interference in replay-based techniques. However, the issue of handling new classes for replay memory samples when training on new tasks remains. On the other hand, since YOLO uses Task Alignment Learning (TAL) [29] for label-prediction assignment, the extent to which interference affects the performance depends on the saved images. In fact, for a given image and its corresponding ground truths, the YOLO assigner assigns at least one model prediction to each ground truth based on the intersection area between the ground truths and the predictions. Consequently, if an object of a new class is not close to an object of an old class, the prediction for the new class object is not assigned to any ground truth, meaning that this prediction doesn't contribute to the loss.\nTherefore, depending on the specific dataset, if instances of new-class objects don't overlap frequently with those from previous tasks, interference does not arise; otherwise, as in Fig. 5 where, without any class masking, the tennis racket prediction would be penalized in the loss computation, samples from the replay memory can prevent the model from learning new classes effectively.\nTo tackle this problem independently of the dataset, we propose a masking loss approach similar to the method used in [12]. In this method, the contribution of new classes for computing the classification loss is ignored for the samples saved in the memory buffer; recalling that, for a prediction assigned to a ground truth, the classification loss is given by $L_{cls} = \\Sigma_i L_{cls}^i$, where $L_{cls}^i$ is the usual Binary Cross Entropy for class i, by applying the masking approach, the classification loss for any sample in the Replay memory is given by:\n$L_{cls-mask} = \\sum_{i \\notin C_t} L_{cls}^i$ (1)\nwhere $C_t$ is the set of the new classes at task t. In the case of samples for the current task, the classification loss is the original one instead."}, {"title": "3.3 Feature Distillation", "content": "Finally, to further enhance the method's performance, we employ the Feature Distillation technique [11], similar to RCLP and SID approaches[25]. The core idea behind feature distillation is that the features generated by the new model for both new and old data should remain close to those produced by the previous model for the same data. This approach helps the model maintain a more cohesive memory, mitigating the effects of catastrophic forgetting and ensuring more stable performance across tasks.\nIn our method, we perform feature distillation on the model's intermediate representations. In details, let our model $f(x) = g(h_w(x))$, where given an input x, h gives the intermediate features, and g produces the model output based on such features. Formally, given an input sample x, the distillation loss on intermediate features is given by:\n$L_{feat_dist} = ||h_{w_t}(x) \u2013 h_{w_{t\u22121}}(x)||_2$ (2)\nwhere $w_t$ denotes the current model parameters while $w_{t-1}$ the ones belonging to the old model trained on the previous task.\nHowever, the YOLOv8 architecture includes a neck in addition to the usual backbone hw. Therefore, we propose to compute the distillation loss on the intermediate features of the backbone and the neck. Recalling that the YOLOv8 backbone outputs three feature maps at multiple levels $C_3, C_4, C_5$ and the neck does the same $P_3, P_4, P_5$ [30, 31], the overall loss can be computed as:\n$L = L_{YOLO} + \\lambda L_{feat_dist}$ (3)\nwhere $L_{YOLO}$ is the YOLOv8 loss, while $L_{feat_dist}$ is the feature distillation loss. Specifically, for YOLOv8, we consider the distillation of 6 feature maps $C_3, C_4, C_5, P_3, P_4, P_5$, 3 of the necks and 3 of the backbone, rewriting the generic equation 2 for YOLO as follows:\n$L_{feat_dist} = \\sum_{i=3}^{6} (||C_i^t \u2013 C_i^{t-1}|| + ||P_i^t \u2013 P_i^{t-1}||)$ (4)"}, {"title": "3.4 OCDM", "content": "The OCDM method was originally proposed to work in the multi-label image classification setting [32]. Its main contribution is proposing a new selection mechanism that differs from the classic random selection used when constructing the replay memory. Referring to Fig. 4, OCDM addresses the unbalanced label distribution found in replay memory samples, which makes them unrepresentative for many non-frequent labels. This is done by ensuring a more uniform label frequency distribution via a greedy approach that removes samples one by one based on how much they contribute to the distribution. We integrate OCDM's selection mechanism into RCLPOD to determine which samples to include in the replay memory after it has been enhanced by the Label Propagation technique."}, {"title": "4 Experimental Setting", "content": null}, {"title": "4.1 Scenarios and Metrics", "content": "Following previous works [18, 25, 8], we test our proposed CLOD method on 2017 version of the PASCAL VOC [33] detection benchmark, which includes 20 different object classes, and on the Microsoft COCO challenge dataset [34] which has 80 object classes. Given one of the two datasets, we derive a CIL problem by dividing the classes into groups, with each task corresponding to a subset of classes of the original dataset. To split the classes into groups, we follow prior works [18, 25], where the tasks are obtained incrementally. Using the notation NpM, the first task (i = 1) consists of the first N classes in the list (e.g., in alphabetical order), while each subsequent task (i > 1) consists of the classes from N + (i \u2212 2) \u00b7 M to N + (i \u2212 1) \u00b7 M \u2013 1. For example, given the VOC dataset with 20 classes, the CL scenario 15p1 (read 15 plus 1) consists of 6 tasks: the first one with the first 15 object classes, the second one with the 16-th class, the third one with the 17-th class and so on. Another example is 15p5 with the first task being trained with 15 classes and the second one with 5 classes."}, {"title": "4.2 YOLO training details", "content": "To evaluate how the CL performances are affected by the model size, in our study we consider two different versions of YOLOv8: YOLOv8n with 3.2M parameters and YOLOv8m with 25.9M parameters. We initialize the backbone parameters with the ones pre-trained on Image-Net, available on [14].\nIn Table 3 we report the hyper-parameters used for training. In particular, by following [14, 17], we use SGD with Nestorov momentum and weight decay. For both the learning rate and the momentum we have 3 warmup epochs, while just for the learning rate we employ a linear decay scheduling from 10-2 to 10\u22124. In all the experiments we set the number of epochs per task to 100, which is a suitable value for reaching convergence."}, {"title": "4.3 CL strategies details", "content": "We compare the following methods against RCLPOD: Joint training, Fine-tuning, Replay, OCDM, LwF, and Pseudo-Label. In particular, while Replay, LwF, and Pseudo-label were already evaluated in the CLOD setting, this is the first time, to the best of our knowledge, that OCDM approach is implemented and tested in the CLOD setting. Join Training is considered as an upper bound and corresponds to the model performances when trained on the entire dataset with all the classes. Fine-tuning is used as a lower bound; each task is trained sequentially, and no CL technique is employed to avoid catastrophic forgetting.\nRegarding the Replay methods, the memory has a small capacity fixed to around 5% of the entire dataset, namely 800 images for PASCAL VOC and 6,000 for COCO. Once the model is trained on task i, n samples are randomly selected from the current training set and added to the Replay memory. To prevent exceeding the memory's total capacity when adding n new samples, n samples are randomly removed from the replay memory. For OCDM, we use the same memory size as all the other replay-based approaches.\nFor LwF, by following [18], we set the distillation loss weight X to 1. For Pseudo-Labeling, to ensure consistency with inference, we set the classification threshold to 0.5 and the IoU threshold, for Non-maximum Suppression, to 0.7. For RCLPOD we use the same hyper-parameters of Pseudo-Labels and Replay. As for LwF, we set the gain for the feature distillation loss to x = 1."}, {"title": "5 Results", "content": "In this section, we discuss the outcomes of each method on the VOC and COCO CLOD benchmarks. Table 1 reports the results after all tasks have been completed for YOLOv8n.\nIn Sec. 5.1, we discuss the results obtained in the 2-tasks scenarios, namely 15p5, 10p10, 19p1, and 40p40. In Sec. 5.2, we consider the more challenging scenarios 15p1 and 40p10."}, {"title": "5.1 Two tasks scenarios", "content": "The results for all the two task scenarios are reported in Tab. 1. Specifically, scenarios 10p10, 19p1, and 15p5 for the VOC dataset and scenario 40p40 for the COCO dataset.\nAs expected, using only distillation, as in LwF, does not guarantee good performances for YOLOv8, as it performs even worse than fine-tuning. Indeed, as discussed in Sec. 2, the noisy regression outputs of the teacher prevent the model from learning the new classes and avoiding forgetting. Therefore, a simple L2 loss between the teacher and the student outputs is highly incompatible with the YOLO training.\nThe results for the Replay method show strong performance on the VOC dataset, particularly in the 10p10 and 19p1 scenarios, where it achieves mAP scores of 54.5 and 60.9, respectively. This indicates that Replay can effectively retain knowledge from earlier tasks when applied to simpler datasets like VOC. When comparing the Replay method with OCDM, we can observe similar results except for the scenario COCO 40p40, which has a slight improvement.\nNotably, it performs better than Replay in the 15p1 scenario with a mAP of 50.2, highlighting its effectiveness in handling challenging incremental tasks.\nRegarding Pseudo-label, we can observe its effectiveness for most of the scenarios except for the 19p1, where the gap with respect to RCLPOD is significant. We suppose this is due to the low number of old-class objects in the images for the new tasks; the lower the number of classes for the second task, the less overlap between tasks we have (see the plots of Fig. 9 in the Appendix). On the contrary, this is not the case for the 40p40 scenario, where Pseudo-label, despite its simplicity, reaches the best mAP. Even if the overall mAP is higher than the RCLPOD one, a higher forgetting is observed, while plasticity brings that higher final result. For more details, we refer to Sec. 2 Appendix, where we compare RCPLOD and Pseudo-label, the two best methods in the 40p40 scenario, in the case of the bigger model YOLOv8m."}, {"title": "5.2 Scenarios VOC 15p1 and COCO 40p10", "content": "Here, we discussed the two longer and more challenging streams: VOC 15p1 and COCO 40p10. As mentioned earlier, COCO 40p10 is more complex since the VOC dataset is much smaller. However, the analysis of VOC 15p1 is still meaningful because the overlap in images among tasks is much smaller in VOC than in COCO.\nThe first observation is that LwF doesn't perform well with the YOLOv8 architecture for COCO and VOC, achieving comparable performance at Fine-Tuning (lower bound). This confirms the results obtained for the simpler and shorter scenarios.\nIn contrast to these approaches, Pseudo-Label works very well in a complex scenario like COCO 40p10. This is partially due to the very high intersection between tasks in terms of images, which allows the model to maintain knowledge of previous classes as it implicitly revisits them in the new task. However, in cases where the intersection between tasks is very low the Pseudo-Label performance is expected to be much worse. This is demonstrated by the VOC 15p1"}, {"title": "5.3 Ablation study", "content": "Here, we discuss the contribution of each component to the final performance of our novel approach, RCLPOD. Recall that the components are OCDM, Label Propagation (LP), Feature Distillation (FD), and Masking Loss (Mask). Tab. 2 reports the ablation studied, where the effect of each component is studied.\nFirst, we compare Replay (Model 1) with OCDM (Model 2). Even in a short CL scenario like COCO 40p40, OCDM performs better than Replay, showing the positive effect of balancing the Replay memory. By adding the Label Propagation (LP) mechanism (Model 3), a significant improvement of 3 mAP is obtained. In fact, by doing so, we both reduce the interference problem, and we fully utilize the potential of the replay memory. Feature Distillation (Model 4) brings an additional improvement of 0.4 mAP. Once we add the Masking Loss component (Model 5), namely, we use all the components of RCLPOD, we get a further increase of 4.1 mAP. In fact, as shown in Fig.10, the important overlap of many classes between tasks brings interference. Therefore, when a Replay memory is employed, masking is needed even in the case of modern versions of YOLO. Finally, we test OCDM once all the other components are used. By removing OCDM (Model 6), a 1.6 mAP drop is observed, showing the importance of balancing the replay memory in reducing forgetting, particularly for longer streams such as VOC 15p1 and COCO 40p10."}, {"title": "6 Conclusions and Future Work", "content": "To solve the Continual Object Detection, we propose a novel approach called RCLPOD, composed of multiple components such as the Label Propagation technique to exploit, at best, the replay memory, the Feature Distillation to maintain better the old representations, and using a selection mechanism fitted than the classic random mechanism of Replay. By effectively composing these components for the YOLOv8 architecture, we can obtain excellent results for the CLOD setting. We used well-known datasets, such as VOC and COCO, to prove the superiority of RCLPOD to the other methods tested in CLOD.\nWhile our method has allowed us to reduce the gap in the literature with upper-bound Joint Training, it is clear that further work is required to achieve performance comparable to Joint training. An issue that our current approach does not address is that while the introduction of pseudo-labels in replay memory has proven to be beneficial, the noise of such labels must be taken into account as well. Indeed, it is realistic to expect the model to generate false positives and negatives, which will be kept in the replay memory, partially causing noise to the model.\nMoreover, we believe that future research should give more attention to longer streams like COCO40p10 and beyond to better represent the real performances of the CL techniques in the CLOD setting."}]}