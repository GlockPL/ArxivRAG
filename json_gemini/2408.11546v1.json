{"title": "MEMORIZATION IN IN-CONTEXT LEARNING", "authors": ["Shahriar Golchin", "Mihai Surdeanu", "Steven Bethard", "Eduardo Blanco", "Ellen Riloff"], "abstract": "In-context learning (ICL) has proven to be an effective strategy for improving\nthe performance of large language models (LLMs) with no additional training.\nHowever, the exact mechanism behind these performance improvements remains\nunclear. This study is the first to show how ICL surfaces memorized training data\nand to explore the correlation between this memorization and performance across\nvarious ICL regimes: zero-shot, few-shot, and many-shot. Our most notable find-\nings include: (1) ICL significantly surfaces memorization compared to zero-shot\nlearning in most cases; (2) demonstrations, without their labels, are the most effec-\ntive element in surfacing memorization; (3) ICL improves performance when the\nsurfaced memorization in few-shot regimes reaches a high level (about 40%); and\n(4) there is a very strong correlation between performance and memorization in\nICL when it outperforms zero-shot learning. Overall, our study uncovers a hidden\nphenomenon\u2014memorization\u2014at the core of ICL, raising an important question:\nto what extent do LLMs truly generalize from demonstrations in ICL, and how\nmuch of their success is due to memorization?", "sections": [{"title": "1 INTRODUCTION", "content": "In-context learning (ICL) has emerged as a powerful method for improving the performance of\nlarge language models (LLMs) without extra training (Brown et al., 2020). This method involves\nincluding a few task-specific examples, known as demonstrations, within the input prompt, which\nenables the LLM to infer the target task and generate improved responses. With long-context LLMs\n(OpenAI, 2023; Anil et al., 2023; Lu, 2023, inter alia), ICL has evolved to incorporate hundreds\nor even thousands of demonstrations, leading to greater performance improvements (Bertsch et al.,\n2024; Agarwal et al., 2024; Zhang et al., 2023b). However, despite its widespread use and straight-\nforward nature, the underlying principles of ICL and its performance improvement capabilities re-\nmain unclear (Min et al., 2022b; von Oswald et al., 2023; Razeghi et al., 2022, inter alia).\nIn this work, we further study the inner workings of ICL by investigating the previously unexplored\nrelationship between ICL and memorization of training data in LLMs, and how this memorization\ncorrelates with performance. In particular, to show how ICL surfaces memorization, we replace\nthe learning component (target variable) in ICL with a text completion task which is based solely\non memorization. To achieve this, we adapt the data contamination detection method proposed by\nGolchin & Surdeanu (2023a). This method aims to replicate dataset instances through memorization\nto verify their presence in the training data. The process begins by splitting a dataset instance into\ntwo random-length segments. The initial segment and the corresponding label of the dataset instance\nare integrated into the input prompt, instructing the LLM to generate the subsequent segment. The\ngenerated completion is then evaluated against the original subsequent segment and categorized as\nan exact, near-exact, or inexact match, with the first two indicating memorization. To implement\nthis for ICL, we use the same strategy to replicate dataset instances but with a tweak. We include a\nfew pairs of initial and subsequent segments from different dataset instances along with their labels\nin the input prompt as demonstrations. Specifically, a demonstration includes (1) a segment pair\nconsisting of an initial and subsequent segment, and (2) a label. We then quantify the memorization\nof training data across various regimes (i.e., zero-shot, few-shot, and many-shot) by counting the\nnumber of exact and near-exact matches."}, {"title": "2 TERMINOLOGY", "content": "Before discussing our methodology, we establish specific terminology for clarity and consistency.\nElement: Throughout this paper, we use the term \"element\" to refer to any of the following: in-\nstruction, segment pairs, or labels. In our experiments, we assess the impact of each element on\nmemorization in ICL.\nSetting: One of the key objectives of this study is to identify the main element influencing memo-\nrization in ICL. For this, we experiment with three settings, each varying by the amount of in-context\ninformation in the input prompt. Thus, the term \u201csetting\u201d refers to the amount of information incor-\nporated into the input prompt in our experiments.\nRegime: Contrary to settings, we define regimes based on the values of k in k-shot scenarios. Hence,\nthe term \"regime\" emphasizes the number of demonstrations (shots) used in the input prompt. We\nelaborate on these regimes in Subsection 3.5.\nDemonstration: In the scope of ICL, various terms describe task-specific examples (k-shot) in-\ncluded in the input prompt. For clarity, we use only \u201cdemonstrations\u201d and \u201cshots\u201d to refer to these\nexamples. As previously noted, each demonstration in our experiments comprises (1) a segment pair\nwith an initial and subsequent segment, and (2) a label. Therefore, when we mention demonstrations\nwithout labels, we only refer to segment pairs."}, {"title": "3 APPROACH", "content": ""}, {"title": "3.1 DETECTING AND QUANTIFYING MEMORIZATION: GENERAL APPROACH", "content": "Detecting Memorization. To detect memorization, we employ the method proposed by\nGolchin & Surdeanu (2023a), originally designed to detect data contamination in LLMs. This tech-\nnique verifies if instances from a particular dataset partition (e.g., test set) were included in the\ntraining data by replicating them through memorization. We specifically use the \u201cguided instruc-\ntion\" from this work. First, dataset instances are split into two random-length segments. Then, the\nLLM is prompted with the guided instruction, which includes dataset-specific details (i.e., dataset\nand partition name), the initial segment of an instance, and the label if available, asking the LLM to\ncomplete the subsequent segment. The similarity between the generated completion and the original\nsubsequent segment is then evaluated to determine if the dataset instance was part of the training\ndata or not.\nEvaluating Memorization. As mentioned, the generated completion is evaluated against the orig-\ninal subsequent segment to determine how closely they match. Golchin & Surdeanu (2023a) pro-\nposed three categories for this evaluation:"}, {"title": "3.2 DETECTING AND QUANTIFYING MEMORIZATION: ADAPTED APPROACH FOR\nIN-CONTEXT LEARNING", "content": "As discussed in Subsection 3.1, we use the method of Golchin & Surdeanu (2023a) to detect and\nquantify memorization in ICL. The rationale behind this choice is to fulfill three primary needs.\nFirst, this method relies solely on memorization for detecting data contamination, making it suitable\nfor examining memorization in our study. Second, its simplicity allows easy adaptation to various\nICL regimes by simply adding k demonstrations to the input prompt. Third, since each demon-\nstration consists of multiple elements, we can assess each element's contribution to memorization\nin ICL by removing each element one at a time. In the following, we first describe how we adjust\nthe original method by Golchin & Surdeanu (2023a) to detect memorization in ICL and detail the\nprocedure for quantifying it.\nDetecting Memorization in In-Context Learning. We employ the guided instruction and adapt\nthe strategy of splitting dataset instances for k-shot scenarios. This involves integrating k pairs of\ninitial and subsequent segments from k distinct dataset instances into the input prompt, including\ntheir associated labels. This setting meets the three primary needs. First, it closely mirrors standard\nICL, allowing us to accurately measure memorization with all elements involved. Second, similar\nto standard few-shot and many-shot ICL, we can vary the number of demonstrations in the input\nprompt to study how memorization changes across different ICL regimes. Third, by quantifying\nmemorization in different ICL settings-such as with and without labels we can evaluate their\nroles in revealing memorization in ICL, identify the key factor affecting memorization in ICL. Ex-\namples of demonstrations and their integration into the replication process to study memorization in\nICL are shown in Figure 1.\nEvaluating Memorization in In-Context Learning. Following Golchin & Surdeanu (2023a), we\nemploy GPT-4 with few-shot ICL to classify generated completions as exact, near-exact, or inexact\nmatches, adhering to the same definitions. While their findings showed this evaluation strategy\nachieves high accuracy in matching evaluations from human judgments, we conduct an additional\nhuman evaluation on top of the GPT-4 evaluation to guarantee optimal accuracy in our findings.\nThis is important as our conclusions significantly rely on the number of detected exact and near-\nexact matches. We detail our human evaluation process in Section 4, under Human Evaluation.\nQuantifying Memorization in In-Context Learning. Following Golchin & Surdeanu (2023a), we\nconsider both exact and near-exact matches as indicators of memorization. We quantify memoriza-\ntion levels across various ICL regimes by counting the number of detected exact and near-exact\nmatches, expressing them as percentages of the total number of dataset instances in the question.\nFurther, in Section 5, we show that using exact and near-exact matches to measure memorization is\na valid approach since near-exact matches can turn into exact matches when demonstrations increase\nacross ICL regimes."}, {"title": "3.3 IDENTIFYING KEY ELEMENT IN MEMORIZATION IN IN-CONTEXT LEARNING", "content": "Our experiments involve three distinct settings, all aiming at quantifying memorization but differ-\ning in the amount of information included in the input prompt. This helps us measure the amount\nof memorization in ICL regimes based on the information provided by each element and iden-\ntify the key element in the process. As shown in Figure 1 and discussed in Section 2, the input\nprompt is composed of two main parts: the instruction, which contains dataset-specific details, and\ndemonstrations, which include segment pairs and their respective labels. We combine these three\nelements-instruction, segment pairs, and labels in different ways to create three unique settings\nwith varying amounts of in-context information. Below, we detail each setting.\n(1) Full Information. This setting maximizes in-context information by including all three ele-\nments: instruction, segment pairs, and labels. This setting contains\nmore information than standard ICL, as it includes dataset-specific details not typically mentioned\nin standard ICL. We use it to establish an upper bound for the highest possible amount of memo-\nrization that can be surfaced in ICL regimes. By comparing the impact of each element against this\nmaximum, we can determine which element most significantly influences memorization in ICL.\n(2) Segment Pairs and Labels. In this setting, we exclude the instruction containing dataset-specific\ninformation and include only segment pairs and labels."}, {"title": "3.4 PERFORMANCE AND MEMORIZATION IN IN-CONTEXT LEARNING", "content": "As the primary goal of employing ICL is to enhance downstream performance, we explore the\nconnection between the underlying memorization in ICL and performance. We calculate the per-\nformance of the samples for which we assess memorization, and analyze the correlation between\nperformance and memorization across our three settings using the Pearson correlation (Pearson,\n1895). In addition, we separately evaluate performance for memorized and non-memorized instances\nacross ICL regimes to gain further insight into the relationship between performance and memoriza-\ntion in ICL. In this context, following the definitions provided in Subsection 3.1, instances that are\nreplicated exactly or nearly exactly are considered memorized, while those replicated inexactly are\nconsidered non-memorized. Note that, for performance measurement, we use standard k-shot ICL,\nwhich includes an instruction to perform the downstream task with k demonstrations and labels."}, {"title": "3.5 SELECTION OF IN-CONTEXT LEARNING REGIMES", "content": "We work with five k-shot ICL regimes across our three settings, where k = {0, 25, 50, 100, 200},\ncovering all ICL categories: zero-shot, few-shot, and many-shot. Specifically, we define zero-\nshot regimes when k = 0, few-shot regimes when k = {25,50}, and many-shot regimes when\nk = {100,200}. In our experiments, to assess the impact of increasing demonstrations on mem-\norization and performance, we progressively increase the number of demonstrations, ensuring that\nlarger regimes include all demonstrations from the smaller ones. For example, the 100-shot ICL\nincludes 50 demonstrations from the 50-shot ICL, which itself includes 25 demonstrations from the\n25-shot ICL."}, {"title": "3.6 SELECTION OF MODELS", "content": "To meet the goals of our study, the LLMs must possess specific properties to be selected for our\nexperiments. First, they need to be highly performant, with strong steerability and controlled gener-\nation capabilities, so we can effectively quantify memorization using their outputs. Less performant\nmodels may keep memorization internal by not explicitly emitting memorized data, or generate\nunstructured outputs that make detecting memorized data intangible. Second, as we extend our ex-\nperiments to many-shot regimes, the LLMs must support long contexts to accommodate our largest\nmany-shot regime with 200 demonstrations across all datasets. Third, the candidate LLMs must\nhave been trained on an array of datasets. This is essential for observing how memorization evolves\nacross different ICL regimes through instance replication."}, {"title": "3.7 SELECTION OF DATASETS", "content": "In line with the settings outlined in Subsection 3.3, the datasets for our study must fulfill certain cri-\nteria. First, the datasets must be part of the training corpora for the LLMs used in our study, ensuring\nthat their instances can be replicated through memorization. Second, to evaluate the impact of la-\nbels on memorization in ICL regimes, we need datasets with labeled samples. Third, these datasets\nshould have a complex label space or be challenging enough for LLMs, allowing us to observe"}, {"title": "4 EXPERIMENTAL SETUP", "content": "Model. Per the criteria detailed in Subsection 3.6 for selecting models, we conducted a pilot study to\ndetermine which existing LLMs fulfill all requirements. We initially selected a set of long-context,\nhigh-performing LLMs, including GPT-4 (OpenAI, 2023), GPT-40 (OpenAI, 2023), Gemini 1.5\nPro (Anil et al., 2023; Reid et al., 2024), and Claude 3.5 Sonnet (Anthropic, 2024). Our pilot study\nfound that GPT-40 and Gemini 1.5 Pro struggled with controlled generations, particularly in many-shot regimes, and Claude 3.5 Sonnet was unable to perform our tasks due to strict safety filters pre-\nventing the generation of copyrighted content in our case, replicating dataset instances. Among\nthe models evaluated, only GPT-4 showed the ability to produce controlled outputs. Also, GPT-4 automatically satisfied the final criterion, having been shown to be trained on several datasets (Golchin & Surdeanu, 2023a). Thus, we selected GPT-4 with 32k context length for all our experi-ments.\nIn our experiments, we use GPT-4 for three main tasks: measuring memorization, computing per-formance, and evaluating generated completions as exact, near-exact, or inexact matches. For\nall these three tasks, we access GPT-4 through the Azure OpenAI API. Specifically, we use the\ngpt-4-0613-32k snapshot for the first two tasks and the gpt-4-0613 snapshot for evaluation.\nTo promote deterministic generations, we set the temperature to zero in all our experiments. Addi-tionally, we limit the maximum completion lengths to 100 tokens for measuring memorization and\n10 tokens for both computing performance and evaluating generated completions. For performance assessment, we repeat our experiments three times and report the average results.\nData. Based on the criteria listed in Subsection 3.7 for selecting datasets, we use four label-based datasets from two tasks: natural language inference (NLI) and classification. Although all criteria\nfor selecting datasets can be independently verified, the first criterion must be verified in relation\nto the chosen model-here, GPT-4. To ensure our datasets were part of the training corpora of our LLM, we conducted a pilot study using proposed strategies for detecting data contamination in fully\nblack-box LLMs (Golchin & Surdeanu, 2023a;b). we selected the following datasets:\nWNLI (Wang et al., 2019b), RTE (Wang et al., 2019a), TREC (Hovy et al., 2001b), and DBpedia\n(Wang et al., 2020).\nDemonstrations. Our preparation process for demonstrations closely follows the method used for dataset instances. Specifically, we randomly subsample 200 demonstrations from each dataset's train set, ensuring an even label distribution to prevent majority label bias in ICL (Zhao et al., 2021).\nThese subsampled demonstrations are then split into two random-length segments, with the initial segment containing 60% to 80% of the instance's length, based on the white space count. Finally,\nthese 200 segment pairs along with their labels constitute our 200-shot ICL, with smaller k-shot\nICLs created by further subsampling this set.\nRegarding the order of demonstrations, while the order matters in few-shot regimes (Lu et al., 2022),\nits impact diminishes in many-shot regimes (Bertsch et al., 2024). To reduce this effect in few-shot regimes and ensure our findings are order-independent, we present demonstrations in a random order\nwithin the input prompt for our experiments on both memorization and performance. However, demonstrations retain the same order when studying memorization and performance for the same k-shot ICL. For example, in a 25-shot ICL, the order of demonstrations is random, but this order remains consistent when examining memorization and performance."}, {"title": "5 RESULTS AND DISCUSSION", "content": "In the following, we first discuss our results on quantifying memorization across various ICL regimes\nin our three settings. Then, we explore the correlation between this quantified memorization and\nperformance. Finally, we compare our insights on memorization in ICL with previous studies, each\nof which reported specific characteristics of ICL."}, {"title": "5.1 RESULTS ON QUANTIFYING MEMORIZATION", "content": "Figures 2 and 3 present a series of plots that quantify memorization across various ICL regimes in\nour three settings: (1) full information, (2) segment pairs and labels, and (3) only segment pairs.\nNote that, for most discussions on ICL memorization, we refer to Figure 2. All our observations are primarily based on memorization quantified by both exact and near-exact matches in this figure, unless we specifically mention exact matches only . We use\nthe first setting only when comparing with the maximum memorization. We use the second setting\nwhen discussing memorization in ICL, as it closely resembles standard ICL. Lastly, we use the third\nsetting when identifying the key element contributing the most to memorization in ICL.\nWe draw eight observations regarding memorization in ICL:\nObservation 1: ICL significantly surfaces memorization compared to zero-shot learning. In zero-shot regimes, memorization ranges from 11% to 16.50%. This increases to 18% to 63.50% in few-shot regimes and further to 24% to 75% in many-shot regimes, more than doubling the amount in zero-shot regimes.\nObservation 2: In terms of memorization behavior, providing only a few demonstrations (e.g., 25 shots) sharply increases memorization in ICL for most datasets. While this increase continues for\nlarger ICL in some datasets, it levels off in others. For example, for the WNLI and RTE datasets, memorization increases up to 75% and 24% at 200-shot ICL. However, for the TREC and DBpedia datasets, memorization remains at around 40% and 53%, respectively, after the 25-shot ICL.\nObservation 3: Memorization tends to remain stable across many-shot regimes for most datasets. However, within these regimes, memorization becomes more explicit as near-exact matches gradu- ally transform into exact matches. Table 1 provides examples of near-exact matches turning into exact matches as the number of demonstrations increases.\nObservation 4: The memorization pattern remains the same when quantified using both exact and near-exact matches, and when using only exact matches, across all settings. This further supports\nthe idea that near-exact matches are indicative of memorization in ICL and generally in LLMs.\nObservation 5: The amount of surfaced memorization in the setting with segment pairs and labels reaches its maximum-equivalent to the full information setting-as soon as a few demonstrations (25 shots and onward) are provided in the input prompt. In other words, the key difference between\nthe full information setting and the setting with segment pairs and labels lies in the zero-shot regimes.\nIn fact, the dataset-specific information is overshadowed by the information from segment pairs and labels (or demonstrations) in the input prompt in terms of contributing to the memorization in ICL.\nTherefore, the amount of memorization surfaced by segment pairs and labels is at its maximum.\nObservation 6: Individual instances of the same context can significantly increase memorization. This is supported by viewing demonstrations as individual dataset instances within the same dataset\n(context) that contribute to memorization. This complements the findings of Carlini et al. (2023)"}, {"title": "5.2 RESULTS ON PERFORMANCE AND MEMORIZATION", "content": "Figure 4 shows a series of plots comparing performance (left-hand plots) and memorization (right-hand plots) across different ICL regimes in all three settings. We present four observations about the connection between performance and memorization in ICL:\nObservation 1: ICL outperforms zero-shot learning when the surfaced memorization in few-shot regimes is substantial, reaching around 40% or higher."}, {"title": "5.3 COMPARING OUR OBSERVATIONS WITH PREVIOUS STUDIES", "content": "In a nutshell", "alone": "nBrown et al. (2020): They showed that larger models benefit more from ICL in terms of perfor- mance improvement. This is consistent with our observations. We discovered a very strong correla- tion between memorization and performance when ICL improves performance.\nRazeghi et al. (2022): They found a strong correlation between improved performance in ICL and term frequency for instances with terms that are more prevalent in the training data. This aligns\nwith our observations. As previously noted", "2022b)": "They showed that labels do not contribute to performance in ICL, i.e., randomly replacing labels in ICL barely hurts performance. This matches our observations. We observed that demonstrations alone, without labels, are the most effective in surfacing memorization in ICL."}]}