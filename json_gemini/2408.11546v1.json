{"title": "MEMORIZATION IN IN-CONTEXT LEARNING", "authors": ["Shahriar Golchin", "Mihai Surdeanu", "Steven Bethard", "Eduardo Blanco", "Ellen Riloff"], "abstract": "In-context learning (ICL) has proven to be an effective strategy for improving the performance of large language models (LLMs) with no additional training. However, the exact mechanism behind these performance improvements remains unclear. This study is the first to show how ICL surfaces memorized training data and to explore the correlation between this memorization and performance across various ICL regimes: zero-shot, few-shot, and many-shot. Our most notable findings include: (1) ICL significantly surfaces memorization compared to zero-shot learning in most cases; (2) demonstrations, without their labels, are the most effective element in surfacing memorization; (3) ICL improves performance when the surfaced memorization in few-shot regimes reaches a high level (about 40%); and (4) there is a very strong correlation between performance and memorization in ICL when it outperforms zero-shot learning. Overall, our study uncovers a hidden phenomenon\u2014memorization\u2014at the core of ICL, raising an important question: to what extent do LLMs truly generalize from demonstrations in ICL, and how much of their success is due to memorization?", "sections": [{"title": "1 INTRODUCTION", "content": "In-context learning (ICL) has emerged as a powerful method for improving the performance of large language models (LLMs) without extra training (Brown et al., 2020). This method involves including a few task-specific examples, known as demonstrations, within the input prompt, which enables the LLM to infer the target task and generate improved responses. With long-context LLMs (OpenAI, 2023; Anil et al., 2023; Lu, 2023, inter alia), ICL has evolved to incorporate hundreds or even thousands of demonstrations, leading to greater performance improvements (Bertsch et al., 2024; Agarwal et al., 2024; Zhang et al., 2023b). However, despite its widespread use and straightforward nature, the underlying principles of ICL and its performance improvement capabilities remain unclear (Min et al., 2022b; von Oswald et al., 2023; Razeghi et al., 2022, inter alia).\nIn this work, we further study the inner workings of ICL by investigating the previously unexplored relationship between ICL and memorization of training data in LLMs, and how this memorization correlates with performance. In particular, to show how ICL surfaces memorization, we replace the learning component (target variable) in ICL with a text completion task which is based solely on memorization. To achieve this, we adapt the data contamination detection method proposed by Golchin & Surdeanu (2023a). This method aims to replicate dataset instances through memorization to verify their presence in the training data. The process begins by splitting a dataset instance into two random-length segments. The initial segment and the corresponding label of the dataset instance are integrated into the input prompt, instructing the LLM to generate the subsequent segment. The generated completion is then evaluated against the original subsequent segment and categorized as an exact, near-exact, or inexact match, with the first two indicating memorization. To implement this for ICL, we use the same strategy to replicate dataset instances but with a tweak. We include a few pairs of initial and subsequent segments from different dataset instances along with their labels in the input prompt as demonstrations. Specifically, a demonstration includes (1) a segment pair consisting of an initial and subsequent segment, and (2) a label. We then quantify the memorization of training data across various regimes (i.e., zero-shot, few-shot, and many-shot) by counting the number of exact and near-exact matches. Figure 1 shows prompts for an illustrative two-shot ICL to replicate a dataset instance."}, {"title": "2 TERMINOLOGY", "content": "Before discussing our methodology, we establish specific terminology for clarity and consistency.\nElement: Throughout this paper, we use the term \"element\" to refer to any of the following: instruction, segment pairs, or labels. In our experiments, we assess the impact of each element on memorization in ICL.\nSetting: One of the key objectives of this study is to identify the main element influencing memorization in ICL. For this, we experiment with three settings, each varying by the amount of in-context information in the input prompt. Thus, the term \u201csetting\u201d refers to the amount of information incorporated into the input prompt in our experiments. We detail our settings in Subsection 3.3.\nRegime: Contrary to settings, we define regimes based on the values of k in k-shot scenarios. Hence, the term \"regime\" emphasizes the number of demonstrations (shots) used in the input prompt. We elaborate on these regimes in Subsection 3.5.\nDemonstration: In the scope of ICL, various terms describe task-specific examples (k-shot) included in the input prompt. For clarity, we use only \u201cdemonstrations\u201d and \u201cshots\u201d to refer to these examples. As previously noted, each demonstration in our experiments comprises (1) a segment pair with an initial and subsequent segment, and (2) a label. Therefore, when we mention demonstrations without labels, we only refer to segment pairs."}, {"title": "3 APPROACH", "content": null}, {"title": "3.1 DETECTING AND QUANTIFYING MEMORIZATION: GENERAL APPROACH", "content": "Detecting Memorization. To detect memorization, we employ the method proposed by Golchin & Surdeanu (2023a), originally designed to detect data contamination in LLMs. This technique verifies if instances from a particular dataset partition (e.g., test set) were included in the training data by replicating them through memorization. We specifically use the \u201cguided instruction\" from this work. First, dataset instances are split into two random-length segments. Then, the LLM is prompted with the guided instruction, which includes dataset-specific details (i.e., dataset and partition name), the initial segment of an instance, and the label if available, asking the LLM to complete the subsequent segment. The similarity between the generated completion and the original subsequent segment is then evaluated to determine if the dataset instance was part of the training data or not.\nEvaluating Memorization. As mentioned, the generated completion is evaluated against the original subsequent segment to determine how closely they match. Golchin & Surdeanu (2023a) proposed three categories for this evaluation:"}, {"title": "3.2 DETECTING AND QUANTIFYING MEMORIZATION: ADAPTED APPROACH FOR IN-CONTEXT LEARNING", "content": "As discussed in Subsection 3.1, we use the method of Golchin & Surdeanu (2023a) to detect and quantify memorization in ICL. The rationale behind this choice is to fulfill three primary needs. First, this method relies solely on memorization for detecting data contamination, making it suitable for examining memorization in our study. Second, its simplicity allows easy adaptation to various ICL regimes by simply adding k demonstrations to the input prompt. Third, since each demonstration consists of multiple elements, we can assess each element's contribution to memorization in ICL by removing each element one at a time. In the following, we first describe how we adjust the original method by Golchin & Surdeanu (2023a) to detect memorization in ICL and detail the procedure for quantifying it.\nDetecting Memorization in In-Context Learning. We employ the guided instruction and adapt the strategy of splitting dataset instances for k-shot scenarios. This involves integrating k pairs of initial and subsequent segments from k distinct dataset instances into the input prompt, including their associated labels. This setting meets the three primary needs. First, it closely mirrors standard ICL, allowing us to accurately measure memorization with all elements involved. Second, similar to standard few-shot and many-shot ICL, we can vary the number of demonstrations in the input prompt to study how memorization changes across different ICL regimes. Third, by quantifying memorization in different ICL settings-such as with and without labels we can evaluate their roles in revealing memorization in ICL, identify the key factor affecting memorization in ICL. Examples of demonstrations and their integration into the replication process to study memorization in ICL are shown in Figure 1.\nEvaluating Memorization in In-Context Learning. Following Golchin & Surdeanu (2023a), we employ GPT-4 with few-shot ICL to classify generated completions as exact, near-exact, or inexact matches, adhering to the same definitions. While their findings showed this evaluation strategy achieves high accuracy in matching evaluations from human judgments, we conduct an additional human evaluation on top of the GPT-4 evaluation to guarantee optimal accuracy in our findings. This is important as our conclusions significantly rely on the number of detected exact and near-exact matches. We detail our human evaluation process in Section 4, under Human Evaluation.\nQuantifying Memorization in In-Context Learning. Following Golchin & Surdeanu (2023a), we consider both exact and near-exact matches as indicators of memorization. We quantify memorization levels across various ICL regimes by counting the number of detected exact and near-exact matches, expressing them as percentages of the total number of dataset instances in the question. Further, in Section 5, we show that using exact and near-exact matches to measure memorization is a valid approach since near-exact matches can turn into exact matches when demonstrations increase across ICL regimes. Examples of these transitions are presented in Table 1."}, {"title": "3.3 IDENTIFYING KEY ELEMENT IN MEMORIZATION IN IN-CONTEXT LEARNING", "content": "Our experiments involve three distinct settings, all aiming at quantifying memorization but differing in the amount of information included in the input prompt. This helps us measure the amount of memorization in ICL regimes based on the information provided by each element and identify the key element in the process. As shown in Figure 1 and discussed in Section 2, the input prompt is composed of two main parts: the instruction, which contains dataset-specific details, and demonstrations, which include segment pairs and their respective labels. We combine these three elements-instruction, segment pairs, and labels in different ways to create three unique settings with varying amounts of in-context information. Below, we detail each setting.\n(1) Full Information. This setting maximizes in-context information by including all three elements: instruction, segment pairs, and labels. Figure 1 illustrates this setting. This setting contains more information than standard ICL, as it includes dataset-specific details not typically mentioned in standard ICL. We use it to establish an upper bound for the highest possible amount of memorization that can be surfaced in ICL regimes. By comparing the impact of each element against this maximum, we can determine which element most significantly influences memorization in ICL.\n(2) Segment Pairs and Labels. In this setting, we exclude the instruction containing dataset-specific information and include only segment pairs and labels. To illustrate this setting, it omits the gray parts in Figure 1 and includes only the red parts. This setting is closest to standard ICL, although standard ICL usually includes an instruction for executing the target task, which is an additional part not present in this setting. However, since this instruction lacks relevant information that could impact memorization, its impact on memorization is either zero or negligible. Moreover, as we will see in Section 5, even instruction with dataset-specific information (used in the previous setting) has minimal impact on memorization in ICL regimes.\n(3) Only Segment Pairs. We further remove elements from the input prompt and include only segment pairs, excluding the instruction and labels. While the previous setting examines the combined effect of segment pairs and labels on memorization in ICL, this setting shows their individual contributions. By comparing the amount of surfaced memorization in this setting with the one that includes both segment pairs and labels, as well as the full information setting, we can assess how much memorization in ICL is due to segment pairs alone versus labels. This helps identify the primary element driving memorization across ICL regimes."}, {"title": "3.4 PERFORMANCE AND MEMORIZATION IN IN-CONTEXT LEARNING", "content": "As the primary goal of employing ICL is to enhance downstream performance, we explore the connection between the underlying memorization in ICL and performance. We calculate the performance of the samples for which we assess memorization, and analyze the correlation between performance and memorization across our three settings using the Pearson correlation (Pearson, 1895). In addition, we separately evaluate performance for memorized and non-memorized instances across ICL regimes to gain further insight into the relationship between performance and memorization in ICL. In this context, following the definitions provided in Subsection 3.1, instances that are replicated exactly or nearly exactly are considered memorized, while those replicated inexactly are considered non-memorized. Note that, for performance measurement, we use standard k-shot ICL, which includes an instruction to perform the downstream task with k demonstrations and labels."}, {"title": "3.5 SELECTION OF IN-CONTEXT LEARNING REGIMES", "content": "We work with five k-shot ICL regimes across our three settings, where k = {0, 25, 50, 100, 200}, covering all ICL categories: zero-shot, few-shot, and many-shot. Specifically, we define zero-shot regimes when k = 0, few-shot regimes when k = {25,50}, and many-shot regimes when k = {100,200}. In our experiments, to assess the impact of increasing demonstrations on memorization and performance, we progressively increase the number of demonstrations, ensuring that larger regimes include all demonstrations from the smaller ones. For example, the 100-shot ICL includes 50 demonstrations from the 50-shot ICL, which itself includes 25 demonstrations from the 25-shot ICL."}, {"title": "3.6 SELECTION OF MODELS", "content": "To meet the goals of our study, the LLMs must possess specific properties to be selected for our experiments. First, they need to be highly performant, with strong steerability and controlled generation capabilities, so we can effectively quantify memorization using their outputs. Less performant models may keep memorization internal by not explicitly emitting memorized data, or generate unstructured outputs that make detecting memorized data intangible. Second, as we extend our experiments to many-shot regimes, the LLMs must support long contexts to accommodate our largest many-shot regime with 200 demonstrations across all datasets. Third, the candidate LLMs must have been trained on an array of datasets. This is essential for observing how memorization evolves across different ICL regimes through instance replication. Clearly, without this criterion, studying memorization is unfeasible."}, {"title": "3.7 SELECTION OF DATASETS", "content": "In line with the settings outlined in Subsection 3.3, the datasets for our study must fulfill certain criteria. First, the datasets must be part of the training corpora for the LLMs used in our study, ensuring that their instances can be replicated through memorization. Second, to evaluate the impact of labels on memorization in ICL regimes, we need datasets with labeled samples. Third, these datasets should have a complex label space or be challenging enough for LLMs, allowing us to observe performance change across different ICL regimes and explore its correlation with memorization. Fourth, the sample length must be limited to a few dozen words/tokens to fit within the input context length of LLMs for all datasets, handling up to 200 demonstrations in our largest many-shot regime."}, {"title": "4 EXPERIMENTAL SETUP", "content": "Model. Per the criteria detailed in Subsection 3.6 for selecting models, we conducted a pilot study to determine which existing LLMs fulfill all requirements. We initially selected a set of long-context, high-performing LLMs, including GPT-4 (OpenAI, 2023), GPT-40 (OpenAI, 2023), Gemini 1.5 Pro (Anil et al., 2023; Reid et al., 2024), and Claude 3.5 Sonnet (Anthropic, 2024). Our pilot study found that GPT-40 and Gemini 1.5 Pro struggled with controlled generations, particularly in many-shot regimes, and Claude 3.5 Sonnet was unable to perform our tasks due to strict safety filters preventing the generation of copyrighted content in our case, replicating dataset instances. Among the models evaluated, only GPT-4 showed the ability to produce controlled outputs. Also, GPT-4 automatically satisfied the final criterion, having been shown to be trained on several datasets (Golchin & Surdeanu, 2023a). Thus, we selected GPT-4 with 32k context length for all our experiments.\nIn our experiments, we use GPT-4 for three main tasks: measuring memorization, computing performance, and evaluating generated completions as exact, near-exact, or inexact matches. For all these three tasks, we access GPT-4 through the Azure OpenAI API. Specifically, we use the gpt-4-0613-32k snapshot for the first two tasks and the gpt-4-0613 snapshot for evaluation. To promote deterministic generations, we set the temperature to zero in all our experiments. Additionally, we limit the maximum completion lengths to 100 tokens for measuring memorization and 10 tokens for both computing performance and evaluating generated completions. For performance assessment, we repeat our experiments three times and report the average results.\nData. Based on the criteria listed in Subsection 3.7 for selecting datasets, we use four label-based datasets from two tasks: natural language inference (NLI) and classification. Although all criteria for selecting datasets can be independently verified, the first criterion must be verified in relation to the chosen model-here, GPT-4. To ensure our datasets were part of the training corpora of our LLM, we conducted a pilot study using proposed strategies for detecting data contamination in fully black-box LLMs (Golchin & Surdeanu, 2023a;b). Based on this, we selected the following datasets: WNLI (Wang et al., 2019b), RTE (Wang et al., 2019a), TREC (Hovy et al., 2001b), and DBpedia (Wang et al., 2020). The first two datasets are for NLI, while the latter two are for classification. Consistent with prior work (Golchin & Surdeanu, 2023a;b; Bertsch et al., 2024; Zhao et al., 2021; Lu et al., 2022; Han et al., 2023; Ratner et al., 2023), to control costs and work with a manageable sample size, we subsample 200 instances from the train split of each dataset, evenly distributed by labels, to study both memorization and performance in all our experiments. For measuring memorization, we create pairs of random-length segments for dataset instances by randomly deriving the initial segment from 60% to 80% of each instance's length, based on the white space count.\nDemonstrations. Our preparation process for demonstrations closely follows the method used for dataset instances. Specifically, we randomly subsample 200 demonstrations from each dataset's train set, ensuring an even label distribution to prevent majority label bias in ICL (Zhao et al., 2021). These subsampled demonstrations are then split into two random-length segments, with the initial segment containing 60% to 80% of the instance's length, based on the white space count. Finally, these 200 segment pairs along with their labels constitute our 200-shot ICL, with smaller k-shot ICLs created by further subsampling this set.\nRegarding the order of demonstrations, while the order matters in few-shot regimes (Lu et al., 2022), its impact diminishes in many-shot regimes (Bertsch et al., 2024). To reduce this effect in few-shot regimes and ensure our findings are order-independent, we present demonstrations in a random order within the input prompt for our experiments on both memorization and performance. However, demonstrations retain the same order when studying memorization and performance for the same k-shot ICL. For example, in a 25-shot ICL, the order of demonstrations is random, but this order remains consistent when examining memorization and performance."}, {"title": "5 RESULTS AND DISCUSSION", "content": "In the following, we first discuss our results on quantifying memorization across various ICL regimes in our three settings. Then, we explore the correlation between this quantified memorization and performance. Finally, we compare our insights on memorization in ICL with previous studies, each of which reported specific characteristics of ICL."}, {"title": "5.1 RESULTS ON QUANTIFYING MEMORIZATION", "content": "Figures 2 and 3 present a series of plots that quantify memorization across various ICL regimes in our three settings: (1) full information, (2) segment pairs and labels, and (3) only segment pairs. Note that, for most discussions on ICL memorization, we refer to Figure 2. All our observations are primarily based on memorization quantified by both exact and near-exact matches (left-hand plots) in this figure, unless we specifically mention exact matches only (right-hand plots). We use the first setting only when comparing with the maximum memorization. We use the second setting when discussing memorization in ICL, as it closely resembles standard ICL. Lastly, we use the third setting when identifying the key element contributing the most to memorization in ICL.\nWe draw eight observations regarding memorization in ICL:\nObservation 1: ICL significantly surfaces memorization compared to zero-shot learning. In zero-shot regimes, memorization ranges from 11% to 16.50%. This increases to 18% to 63.50% in few-shot regimes and further to 24% to 75% in many-shot regimes, more than doubling the amount in zero-shot regimes.\nObservation 2: In terms of memorization behavior, providing only a few demonstrations (e.g., 25 shots) sharply increases memorization in ICL for most datasets. While this increase continues for larger ICL in some datasets, it levels off in others. For example, for the WNLI and RTE datasets, memorization increases up to 75% and 24% at 200-shot ICL. However, for the TREC and DBpedia datasets, memorization remains at around 40% and 53%, respectively, after the 25-shot ICL.\nObservation 3: Memorization tends to remain stable across many-shot regimes for most datasets. However, within these regimes, memorization becomes more explicit as near-exact matches gradually transform into exact matches, as shown in Figure 3. This highlights the importance of near-exact matches in quantifying memorization, as they indeed indicate memorization. Table 1 provides examples of near-exact matches turning into exact matches as the number of demonstrations increases.\nObservation 4: The memorization pattern remains the same when quantified using both exact and near-exact matches, and when using only exact matches, across all settings. This further supports the idea that near-exact matches are indicative of memorization in ICL and generally in LLMs.\nObservation 5: The amount of surfaced memorization in the setting with segment pairs and labels reaches its maximum-equivalent to the full information setting-as soon as a few demonstrations (25 shots and onward) are provided in the input prompt. In other words, the key difference between the full information setting and the setting with segment pairs and labels lies in the zero-shot regimes. In fact, the dataset-specific information is overshadowed by the information from segment pairs and labels (or demonstrations) in the input prompt in terms of contributing to the memorization in ICL. Therefore, the amount of memorization surfaced by segment pairs and labels is at its maximum.\nObservation 6: Individual instances of the same context can significantly increase memorization. This is supported by viewing demonstrations as individual dataset instances within the same dataset (context) that contribute to memorization. This complements the findings of Carlini et al. (2023) that memorization significantly increases with the tokens of context used to prompt the model. We discuss this in more detail in Subsection 5.3, where we compare our observations with other studies.\nObservation 7: Comparing memorization levels across three settings shows that maximum memorization in ICL can be achieved even when only segment pairs are included in the input prompt. This indicates that demonstrations without their respective labels, i.e., the segment pairs alone, are the key element contributing to memorization in ICL.\nTo clarify, the WNLI dataset is not an exception to this observation, although it experiences a slightly larger decrease (e.g., 22.50% in 200-shot ICL) compared to other datasets. In fact, we discovered that in the WNLI dataset, multiple sentence pairs share sentence 1 with different labels. For instance, for \"Bill passed the gameboy to John because his turn was next.\" as sentence 1, there are different options for sentence 2, such as \"John's turn was next.\" and \"Bill's turn was next.\", with distinct labels entailment and not entailment, respectively. Hence, when the model is prompted with only sentence 1 to generate sentence 2, the completion could be either of these options. However, our criteria for exact and near-exact matches require both semantic and structural similarity. If the completion does not semantically or structurally match the original sentence 2, even if it matches the other sentence 2 with a different label, it is not counted as an exact or near-exact match. Dismissing these alternative completions as exact or near-exact matches aligns with prior work by Carlini et al. (2023), where they adopted the same approach. We found several cases of this occurring in the WNLI dataset, and the number of such cases exactly corresponds with the drop observed for the WNLI dataset in the setting containing only segment pairs.\nObservation 8: Similar to memorization, the presence of data contamination varies under different regimes. Contamination is more evident in few-shot and many-shot regimes compared to zero-shot."}, {"title": "5.2 RESULTS ON PERFORMANCE AND MEMORIZATION", "content": "Figure 4 shows a series of plots comparing performance (left-hand plots) and memorization (right-hand plots) across different ICL regimes in all three settings. Accordingly, Tables 2 and 3 list the Pearson correlation coefficients between overall performance and memorization, with memorization quantified using both exact and near-exact matches, and only exact matches, respectively.\nWe present four observations about the connection between performance and memorization in ICL:\nObservation 1: ICL outperforms zero-shot learning when the surfaced memorization in few-shot regimes is substantial, reaching around 40% or higher."}, {"title": "5.3 COMPARING OUR OBSERVATIONS WITH PREVIOUS STUDIES", "content": "In a nutshell, our observations align well with previous research on ICL and memorization alone in language models. Beyond confirming previous work, our findings on memorization in ICL and its correlation with performance offer novel and deeper insights into previously reported characteristics.\nWe discuss several studies that have provided notable insights into ICL and memorization alone:\nBrown et al. (2020): They showed that larger models benefit more from ICL in terms of performance improvement. This is consistent with our observations. We discovered a very strong correlation between memorization and performance when ICL improves performance, and as Carlini et al. (2023) reported, memorization significantly increases with model size.\nRazeghi et al. (2022): They found a strong correlation between improved performance in ICL and term frequency for instances with terms that are more prevalent in the training data. This aligns with our observations. As previously noted, we found that there is a very strong correlation between memorization and performance when ICL enhances performance, and as Carlini et al. (2023) showed, memorization significantly increases with the number of times an instance is duplicated in training data.\nMin et al. (2022b): They showed that labels do not contribute to performance in ICL, i.e., randomly replacing labels in ICL barely hurts performance. This matches our observations. We observed that demonstrations alone, without labels, are the most effective in surfacing memorization in ICL, and there is a very strong correlation between this memorization and improved performance in ICL.\nCarlini et al. (2023): They found that memorization significantly increases with the number of tokens of context used to prompt the model. Our results on memorization closely match this finding. However, we extend this finding by noting that tokens from individual instances can also be considered part of the tokens of context, not necessarily tokens from a single instance. This is evident in our ICL regimes, where individual instances contributed to more memorization being surfaced."}, {"title": "6 RELATED WORK", "content": "In-Context Learning. Brown et al. (2020) first introduced ICL to enhance performance in LLMs without additional training costs by including a few demonstrations in the input prompt. Despite its simplicity, the internal mechanisms of ICL are not yet well understood. Several studies explored ICL from various perspectives: Lu et al. (2022) examined the impact of the order of demonstrations, B\u00f6l\u00fcc\u00fc et al. (2023) investigated the effect of example selection, Zhao et al. (2021) explored biases in ICL, such as label, recency, and common token biases, Li et al. (2023b) studied the influence of input distribution and explanations, and Min et al. (2022b) looked into the role of labels and found that randomly replacing labels does not harm performance while others showed that this is not true for all tasks and models (Yoo et al., 2022; Kossen et al., 2023; Lin & Lee, 2024). Different perspectives were employed to better understand ICL: Hendel et al. (2023) viewed ICL as compressing the training set into a single task vector that modulates the transformer to produce the output, while von Oswald et al. (2023) interpreted ICL as gradient descent, a view refuted by Deutch et al. (2023). Some research efforts focused solely on maximizing ICL performance through different paradigms: several studies extremely increased the number of demonstrations in the input prompt (Bertsch et al., 2024; Agarwal et al., 2024; Zhang et al., 2023b; Milios et al., 2023; Anil et al., 2023), Min et al. (2022a) fine-tuned language models to perform ICL, and Zhao et al. (2021) used prompt engineering to enhance ICL. More recently, a few studies highlighted additional capabilities of ICL beyond its performance on standard datasets and benchmarks, such as performing regression (Vacareanu et al., 2024), kNN (Agarwal et al., 2024; Dinh et al., 2022), and jailbreaking (Anil et al., 2024).\nMemorization. Memorization is a well-studied topic in the context of language models (Carlini et al., 2023; 2021; Song & Shmatikov, 2019; Zhang et al., 2023a; McCoy et al., 2023; Song et al., 2017). While some studies aimed to verify the presence of memorization (Henderson et al., 2018; Thakkar et al., 2020; Thomas et al., 2020; Carlini et al., 2019; Golchin & Surdeanu, 2023b), others attempt to quantify it (Carlini et al., 2023; 2021). Quantifying memorization is typically handled using membership inference attack (Shokri et al., 2017; Yeom et al., 2018) to reproduce training data from models (Carlini et al., 2023; 2021; Golchin & Surdeanu, 2023a). This quantification is conducted for several reasons, including showcasing potential privacy risks (Nasr et al., 2023; Biderman et al., 2023; Lukas et al., 2023), addressing copyright infringement (Grynbaum & Mac, 2023; Karamolegkou et al., 2023), and generating factual information (Li et al., 2023a; Tay et al., 2022; AlKhamissi et al., 2022; Petroni et al., 2019; Haviv et al., 2023). On the other hand, several works proposed methodologies to mitigate memorization (Lee et al., 2022) and its implications (Kandpal et al., 2022; Meeus et al., 2024; Wei et al., 2024; Wang et al., 2023).\nTo the best of our knowledge, there is no existing work studying memorization in ICL and its correlation with performance."}, {"title": "7 CONCLUSION", "content": "We studied how in-context learning (ICL) surfaces memorized training data in large language models (LLMs). We quantified this memorization and identified the most effective element in surfacing it. We also explored the correlation between this memorization and performance in ICL. Among our many observations, the key findings are: (1) ICL significantly surfaces memorization compared to zero-shot learning in most cases, with demonstrations\u2014excluding their labels-being the most influential element; and (2) there is a very strong correlation between performance and memorization when ICL outperforms zero-shot learning. Overall, our findings highlight memorization as a new factor impacting ICL. While our research offers a deeper understanding of ICL, it also presents new challenges, particularly regarding how much LLMs truly learn from demonstrations in ICL versus how much their success is due to memorization."}, {"title": "A EVALUATION PROMPT", "content": "Figure 5 illustrates the few-shot ICL prompt used to evaluate the LLM-generated completion against the original subsequent segment of a dataset instance. In this prompt, the \"reference text\u201d represents the original subsequent segment, while the \"candidate text\" refers to the LLM-generated completion. We provide GPT-4 with one exact match and three near-exact matches, all pre-annotated by human evaluators. These examples help GPT-4 distinguish between near-exact and inexact matches, aligning its evaluation with human judgment."}, {"title": "B DETAILED DESCRIPTIONS OF DATASETS", "content": "Winograd Natural Language Inference (WNLI) Dataset. The WNLI dataset is a benchmark for assessing natural language understanding", "editions": "RTE1 (Dagan et al., 2005), RTE2 (Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009). The examples in these datasets were mainly developed using texts from news articles and Wikipedia. To ensure uniformity, the datasets were adjusted into a two-class format. In cases where datasets originally had three classes, the \"neutral\u201d and \u201ccontradiction\" categories were merged into a single \"not entailment\" class. The combined RTE dataset includes 2,490 examples for training, 277 examples for validation, and 3,000 examples for testing.\nText Retrieval Conference (TREC) Dataset. This dataset, created by the National Institute of Standards and Technology"}]}