{"title": "Transient Fault Tolerant Semantic Segmentation for Autonomous Driving", "authors": ["Leonardo Iurada", "Niccol\u00f2 Cavagnero", "Fernando Fernandes Dos Santos", "Giuseppe Averta", "Paolo Rech", "Tatiana Tommasi"], "abstract": "Deep learning models are crucial for autonomous vehicle perception, but their reliability is challenged by algorithmic limitations and hardware faults. We address the latter by examining fault-tolerance in semantic segmentation models. Using established hardware fault models, we evaluate existing hardening techniques both in terms of accuracy and uncertainty and introduce ReLUMax, a novel simple activation function designed to enhance resilience against transient faults. ReLUMax integrates seamlessly into existing architectures without time overhead. Our experiments demonstrate that ReLUMax effectively improves robustness, preserving performance and boosting prediction confidence, thus contributing to the development of reliable autonomous driving systems. Code available at: https://github.com/iurada/neutron-segmentation", "sections": [{"title": "1. Introduction", "content": "Autonomous vehicles face significant challenges in perceiving and navigating complex environments. Reliable scene recognition models are crucial, especially for Advanced Driver Assistance Systems (ADAS) that must comply with functional safety standards like ISO 26262 [18]. While deep learning has advanced capabilities such as obstacle detection and traffic sign recognition, certification of these components remains a challenge. Recent research has focused on improving algorithmic robustness through domain generalization [31,38], anomaly detection [32], and open-set recognition [22]. However, hardware robustness is equally critical. Transient hardware faults, often caused by cosmic particles, can result in bit-flip errors [1,2] that may lead to incorrect predictions and potentially fatal decisions in autonomous vehicles (see Fig. 1). Our work addresses this hardware vulnerability in the context of semantic segmentation, a key task in scene interpretation for autonomous driving. We aim to understand and mitigate the impact of hardware errors on this critical function.\nIdeal fault-resilient systems require low-latency and cost-effective strategies. However, current solutions involve expensive hardware or high-cost redundancy [19,39], exemplified by Tesla's Full Self-Driving Chip [36]. Traditional error-correcting code (ECC) focuses on GPU memories rather than functional units [13,35]. Software-based strategies typically adapt classical techniques to neural networks, introducing significant time overhead [15, 40]. Recent research on computer vision model reliability addresses limited datasets with simplified fault models [27,37] or relies on reactive post-processing approaches [3], overlooking the model training process.\nWith this work, we present to the computer vision community:\n\u2022 the first fault tolerance analysis on deep learning-based semantic segmentation for autonomous driving. Our study leverages fault models obtained from physical experiments rather than standard synthetic ones.\n\u2022 a new hardening technique for deep convolutional segmentation models. We introduce the activation function ReLUMax that allows monitoring the training phase and operates corrections at inference time with no latency."}, {"title": "2. Related Works", "content": "Transient Faults and Hardening. Transient faults affect deep learning system reliability, with impact varying by network architecture and processing unit. Software hardening techniques to mitigate these effects are actively researched. Strategies include selective feature map duplication [27], convolution checksums [15, 23, 28, 34], re-execution [11, 24], prediction ensembles [14], specialized pooling layers [21, 34], and value attenuation [8,21]. Recent approaches designed for object classification combine fault-aware training, ReLU activation clipping, and batch normalization positioning [5]. Only two previous works considered the task of semantic segmentation on fish-eye images. One proposed to improve fault tolerance by calculating activation statistics in a post-processing stage to identify faulty values and apply zero masking on them [3]. The collected statistics capture a late snapshot of the model and do not value the dynamic nature of the training process. The second work [4], adopts a fixed ReLU activation clipping as [5] but observed that it may hinder training convergence and reduce accuracy compared to unmodified models.\nFault Models. Faults can affect any component of deep neural network hardware platforms, with increasing risks as transistors shrink. Fault models represent how faults manifest as incorrect states leading to prediction failures. Common synthetic abstractions include bit-flips in weights, activations, or convolution outputs [3, 4]. Recent studies on neutron beam exposure show faults can corrupt feature maps, affecting entire rows, columns, or blocks of tensors, with magnitudes reaching infinity or NaN [34]. We adopt the strategy from [5], considering random combinations of feature map region variations."}, {"title": "3. Method", "content": "Background. One tangible consequence of hardware transient faults is a notable alteration in the range of internal deep network values, often resulting in the emergence of excessively large activations. Existing strategies to tackle this problem include manually setting upper bounds based on the values of the neurons in each layer in the absence of faults [21]. In [3] the authors proposed to collect the distribution of the Average, Minimum, Maximum, and Standard deviation (AMMS) of the activation values for each layer at the end of the training phase. They fix an error detection threshold for each statistic, identifying when it is one standard deviation beyond the minimum or maximal value.\nThey show that if the average and minimum are both out of range, it is possible to reliably identify a fault, and mitigate it by masking values to zero.\nWe remark that deep neural networks are inherently wired to manage out-of-range activation values thanks to the ReLU functions, thus adding handcrafted procedures is clearly suboptimal. A clipped ReLU activation function was used in [17] to map high-intensity (possibly faulty) activation values to zero. The selected clipping threshold was refined with a dedicated fine-tuning algorithm but could be below the maximum activation value in the training phase, possibly modifying the error-free behavior of the network. In [5] the authors adopted ReLU6 from the literature on efficient deep learning models where the threshold of 6 was chosen to reduce the risk of overflow/underflow [20] and demonstrated to produce the best accuracy-reliability trade-off in case of hardware-permanent faults [17]. Moreover, they exploited fault-aware training via a tailored data augmentation which mimicked the effects of hardware faults to learn patterns that are robust to fault-related noise. Later, [4] discussed how the use of ReLU6 for mitigating faults in segmentation is not without drawbacks.\nReLUMax. We propose to leverage a new version of the ReLU function to improve deep neural network fault resilience for semantic segmentation, while overcoming the limitations of existing approaches. In particular, we introduce ReLUMax, which builds upon the established ReLU-n concept [20], but with a key distinction: it dynamically computes the optimal clipping value for each feature map during the training process. Each ReLUMax activation function stores the observed maximal value (i.e. a single floating-point number) from its own output during training and uses it at evaluation time as a trigger to clip activation values to zero."}, {"title": "4. Experiments", "content": "In this section we present our experimental analysis to assess the performance of ReLUMax as a hardening solution for fault-resilient semantic segmentation.\n4.1. Experimental Setting\nArchitecture. We use DeepLabV3 [7] on a ResNet-50 backbone [16]. By following standard practices, we start from a pre-trained model obtained on a subset of COCO [25], using only the 20 categories that are present in the Pascal VOC dataset [12].\nDatasets. We run the semantic segmentation experiments on GTA5 [33] and Cityscapes [9] datasets, following standard procedures described in [6,26] and [7,9], respectively. Both are large-scale datasets for urban scene understanding. The former consists of 24,966 synthetic images 1052\u00d71914 with pixel-perfect annotations. The latter, contains 3,975 images 1024 \u00d7 2048 with fine-grained annotations of real-world road scenes, comprising up to 30 different categories.\nTransient Fault Injection. We inject transient faults using the module from [5]. Errors appear as row or column-wise stripes or localized blocks within the feature maps. Corruption involves multiplying the output tensor with a uniformly sampled random value determining the error magnitude. This fault injection is stochastically applied to random layers during each forward pass.\n4.2. Semantic Segmentation Results\nWe evaluate ReLUMax against five baselines: No Hardening, Fault-Aware Training [5], ReLU6 [4, 5], ReLU6 + Fault-Aware Training [5], and AMMS [3]. We use mean Intersection over Union (mIoU) for evaluation and classify silent data corrupts (SDCs) according to [3,4] as Masked, if no bit-level difference is present in the output logits. No Impact, if the predicted pixel-level categories are the same. Tolerable, if less than 1% of pixels in the output prediction are affected by the SDCs and no semantic class appears or disappears. They are Critical SDCs otherwise. Results are presented in Tab. 1. In fault-free scenarios, hardening methods don't significantly impact performance, though ReLU6 shows a slight decrease. With fault injections, ReLUMax proves most effective, followed by AMMS. Both use similar masking logic, but ReLUMax estimates clipping thresholds during training, generating superior fault estimates.\n4.3. Qualitative Effect of Fault Injections\nAs shown in Fig. 1, the absence of hardening measures leads to substantial corruption from transient faults, posing serious safety risks for autonomous driving. Faults typically generate patterns where entire columns in layer outputs are perturbed. ReLUMax demonstrates a notable ability to mitigate fault influence, providing consistent predictions. Fig. 2 illustrates the worst-case scenario recorded at inference time on Cityscapes. Without hardening, significant performance degradation is observed. Fault-aware training without clipping leads to completely corrupted predictions. ReLU6 activation avoids complete corruption but overestimates the person class (in red) in shattered blobs. Combining ReLU6 with fault-aware training or using AMMS doesn't resolve the issue, with the person class missing entirely. ReLUMax provides proper localization of persons even in the worst case.\n4.4. Uncertainty Analysis of Hardened Models\nWhile mIoU assesses pixel-level segmentation accuracy, it overlooks model confidence, which is crucial in real-world applications where uncertain predictions can have significant consequences. To address this, we analyze model confidence using predictive uncertainty [30], computed via softmax entropy from model outputs. We then evaluate this uncertainty using four metrics proposed in [10, 29, 30]. For the first three metrics we need to decompose the image in patches of size w \u00d7 w, with w > 1 and evaluate on them pixel accuracy and prediction uncertainty. The results are then collected in a confusion matrix containing the number of patches that are accurate and certain $n_{ac}$, accurate and uncertain $n_{au}$, inaccurate and certain $n_{ic}$ and inaccurate and uncertain $n_{iu}$. Finally, we can compute $P_{ac}$ which measures the probability that the model is accurate on its output given that it is confident in its prediction, and $P_{ui}$ which measures the probability that the model is uncertain about its output given that its prediction is wrong. They are respectively defined as\n$P_{ac}: p(accurate | certain) = \\frac{n_{ac}}{n_{ac} + n_{ic}}$ (1)\n$P_{ui}: p(uncertain | inaccurate) = \\frac{n_{iu}}{n_{ic} + n_{iu}}$ (2)\nFinally, $P_{A \\cup PU}$ computes the probability of the model being confident on accurate predictions and uncertain on inaccurate ones:\n$P_{A \\cup PU} = \\frac{n_{ac} + n_{iu}}{n_{ac} + n_{au} + n_{ic} + n_{iu}}$ (3)\nThese metrics can be calculated using various uncertainty thresholds, which define the meaning of certain for the model. In this regard, we align with [29,30]: we use w = 4 as the window size and 50% as the threshold for defining a patch as accurate (given w = 4, at least 9 out of 16 pixels in each patch must be correctly predicted by the model)."}, {"title": "5. Conclusions", "content": "We investigated the robustness of semantic segmentation models to transient faults, evaluating existing hardening techniques under realistic fault injection scenarios. Moreover, we propose ReLUMax, a novel activation function that enhances model resilience by identifying acceptable activation ranges during training and clipping high-intensity faulty activations to zero during deployment. Despite its simplicity the proposed solution provides top accuracy results and shows promising performance in terms of maintaining model confidence. Up to our knowledge no previous work assessed uncertainty of hardened models, while we believe it is a crucial aspect to consider, especially in critical application scenarios as autonomous driving.\nFuture work will extend our study to further architectures (i.e. transformer-based) and will involve tests on hardware platforms under neutron beam irradiation by following [5]."}]}