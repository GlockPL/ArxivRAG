{"title": "ASSESSING THE IMPACT OF PACKING ON MACHINE LEARNING-BASED MALWARE DETECTION AND CLASSIFICATION SYSTEMS", "authors": ["Daniel Gibert", "Nikolaos Totosis", "Constantinos Patsakis", "Giulio Zizo", "Quan Le"], "abstract": "The proliferation of malware, particularly through the use of packing, presents a significant challenge\nto static analysis and signature-based malware detection techniques. The application of packing to the\noriginal executable code renders extracting meaningful features and signatures challenging. To deal\nwith the increasing amount of malware in the wild, researchers and anti-malware companies started\nharnessing machine learning capabilities with very promising results. However, little is known about\nthe effects of packing on static machine learning-based malware detection and classification systems.\nThis work addresses this gap by investigating the impact of packing on the performance of static\nmachine learning-based models used for malware detection and classification, with a particular focus\non those using visualisation techniques. To this end, we present a comprehensive analysis of various\npacking techniques and their effects on the performance of machine learning-based detectors and\nclassifiers. Our findings highlight the limitations of current static detection and classification systems\nand underscore the need to be proactive to effectively counteract the evolving tactics of malware\nauthors.", "sections": [{"title": "1 Introduction", "content": "The generation of continually changing products and services in the cyber domain has led to a large opportunity space\nfor capital through cybercrime. These developments are very attractive for criminals, as they significantly increase their\noutreach while also allowing for automation. This trend maps to the number of malware samples per year, which in the\npast decade has stabilised to more than 80 million [1]. This massive number of samples, along with the increase in\nsophistication and impact of malware, requires better and more advanced countermeasures [2]. To fill this gap, many\nresearchers and anti-malware companies are harnessing artificial intelligence (AI) and machine learning (ML).\nOf particular interest in this work are the strong results reported by using machine learning and artificial intelligence\nto classify binaries as benign or malicious, or to perform multiclass malware family classification using visualization\ntechniques. Research in this domain has generated numerous articles in recent years, most of which report almost\nperfect results with very high accuracy and precision. Querying Scopus for relevant publications, resulted in well\nbeyond 400 documents from 2008 to 2024, clearly showing the research interest in this research field."}, {"title": "2 Related Work", "content": "Machine learning has increasingly been adopted to detect and classify malware due to its ability to learn patterns\nand characteristics from large amounts of data. Despite showing promising results in the detection and classification\nof binaries, ML-based solutions are vulnerable against adversarial examples [4, 5]. In addition, previous studies on\nthe limits of ML-based models based on static features against packing have highlighted their limitations [6]. This\nstudy builds upon their work, and it studies the impact of packers and obfuscation tools on various types of static ML-\nbased malware detection systems, including feature-based detectors, end-to-end detectors, and greyscale image-based\ndetectors, showcasing the limitations of state-of-the-art static ML-based detectors and classifiers.\nFeature-based detectors rely on feature engineering and expert knowledge to extract specific features or characteristics\nfrom binary files that are believed to be indicative of malware. The most well-known feature-based detector is the\nEMBER LightGBM model [7]. This detector refers to a LightGBM model trained using various features to represent a\ncomputer program, including general file information (e.g., file size, PE header data), header information (e.g., COFF\nand Optional headers), imported and exported functions (from Import and Export Address Tables), section information\n(e.g., section size and entropy), byte histograms, byte-entropy histograms (computed using a sliding window), and\nstring information (e.g., statistics about printable strings).\nOn the other hand, end-to-end malware detectors refer to deep learning models (e.g., convolutional neural networks)\nthat take raw binary files as input and output a classification (benign or malicious) without human intervention. End-\nto-end detectors eliminate the need to manually extract expert-crafted features, automating the feature learning and\nclassification process. A well-known end-to-end detector is MalConv [8], a shallow convolutional neural network that\nconsists of a gated convolutional layer with large filters, followed by a global max pooling layer and a fully connected\nlayer.\nFinally, greyscale image-based detectors take the raw binary data of a file and convert them into a greyscale image [3].\nEach byte in the binary is mapped to a pixel in the image, with the byte value (0-255) corresponding to the greyscale\nintensity of the pixel. Then, the resulting image is resized, normalised, and classified using a convolutional neural\nnetwork (CNN) [9] such as ResNet [10] and EfficientNet [11], or with vision transformer models [12, 13]. The greyscale\nimage representation of malware has been mainly used to classify malware into families because, as shown in Figure 1,\nthe visual representation of malware exhibits obvious visual similarities between samples belonging to the same family\nwhile being different from those samples belonging to a different family."}, {"title": "3 Motivation and dataset analysis", "content": "Setting aside the efficacy of different malware detectors using visualisations of malware binaries, it is essential to\nunderstand why they are efficient. However, this cannot be answered by using explainability frameworks, e.g., Shapley\nAdditive Explanations (SHAP) [14] or Local Interpretable Model-Agnostic Explanations (LIME) [15], as the answers\nwill refer to visual data. We argue that before going through the visual features and their weights, one has to examine\nthe underlying data, which, in this case, is the malware itself.\nThe most principled way is to directly and manually examine one of the reference datasets in this domain, with the\nmost broadly used being the Malimg dataset [3]. The dataset dates back to 2011 and contains 9,339 malware samples\nbelonging to 25 malware families and consists of visualisations of these binaries into greyscale images. Unfortunately,\nthe image conversion that has been used to construct the dataset is lossy, as some bytes at the end of the files are\nremoved to fit them to a specific image width. Thus, it is not possible to directly derive all the original binaries from\nthe images of the dataset. Since each image is named after the hash of the original binary, one can easily check that\nby reversing the process, only 3666 of the samples can be extracted. Moreover, the names can be used to retrieve\nintelligence reports from various OSINT services (e.g., VirusTotal, Abuse.ch, and VX Underground) or even reconstruct\nthem if only a few bytes are missing, e.g., by brute forcing some bytes at the end of the file to find the suffix to match\nthe hash of the name.\nUsing the above methods, we managed to reconstruct and collect intelligence reports from 8263 files (87.36% of the\noriginal files). For the rest of the 1076 files, we have the truncated version of these files, so some information is missing,\nand there is no available information from OSINT sources. The information per family is shown in Table 1. Note\nthat information such as the names of the sections, the hashes of the sections that have not been tampered with by the\nchopping, the import tables, etc., can be safely extracted from these files. Evidently, the fuzzy hashes (ssdeep and"}, {"title": "4 Methodology", "content": "In this study, we explore the impact of packing on the performance of static ML-based malware detectors and classifiers.\nWhile malware detectors aim to identify malicious software, malware classifiers categorise them into specific malware\nfamilies. We hypothesise that packing and obfuscation techniques substantially reduce the effectiveness of these\nML-based systems, while the extent of their impact likely varies based on the diversity of packers and the number and\ntype of packed executables encountered during the training phase. To help answer our hypothesis, we pose the following\nresearch questions and conduct a series of experiments specifically designed to shed light on how packing influences\nboth the detection and classification capabilities of these systems, particularly under different training conditions.\nResearch Question 1: Does a bias in the distribution of packers used in benign and malicious executables cause\nmalware detectors to learn \"benign\" and \"malicious\" packing routines? How does a bias in the distribution of\npackers affect malware classifiers?\nThere are several reasons that could lead to biases in the distribution of packers used in benign and malicious executables.\nFor instance, the period during which the data were collected affects the representation of the packing techniques in the\nsamples since newer packing and obfuscation techniques have been developed, and older ones have become obsolete.\nThus, a model trained with samples packed using obsolete techniques may perform poorly, on newer, unseen, packing\ntechniques. The time perspective has been discussed in [22, 23] but focuses on the malware family perspective and\nconcept drift. Likewise, the capability of existing tools to detect and unpack certain types of packed executables might\ninfluence the prevalence of these packers in the datasets. Even more, the intent behind the software affects the packer's"}, {"title": "4.1 Packers", "content": "The following packers and tools have been executed either using wine\u00b3 on a Ubuntu system or using the ProtectMyTool-\ning tool on a Virtual Machine running Windows 10."}, {"title": "4.1.1 UPX", "content": "The Ultimate Packer for eXecutables is a packer commonly used by malware authors to compress and obfuscate\ntheir malicious executables. When UPX packs an executable, it compresses the original executable's code, data, and\nresources using a compression algorithm. UPX then appends a decompression stub to the compressed data. This stub is\nresponsible for decompressing the executable in memory when it is run. Upon execution, the operating system loads\nthe UPX-packed binary into memory, including the decompression stub. Then, the stub decompresses the packed data back\nto their original form in memory, and the control is transferred to the entry point of the now-decompressed executable.\nIn our experiments, the LZMA algorithm has been used to compress the executables."}, {"title": "4.1.2 Enigma Protector", "content": "The Enigma Protector is a Windows software program for protecting, licensing and securing software programs. It is\nprimarily used by software developers to safeguard their applications against illegal copying, hacking, modification, and\nreverse engineering. Enigma encrypts the executable files, making the code unreadable without the correct decryption\nkey. When the protected application starts, the decryptor unpacks the original code in memory, ensuring that it runs\nas intended. In addition, it employs various methods of code obfuscation, mutation, and virtualization to protect the\ncomputer programs."}, {"title": "4.1.3 Themida", "content": "Themida 7 is a software protector designed to prevent unauthorized use and reverse engineering of software programs.\nThemida uses various sophisticated techniques, including encryption, code virtualization, anti-debugging, and anti-\ntampering techniques (e.g., checksums, cryptographic hashes), to secure software against cracking, tampering, and\nother attacks."}, {"title": "4.1.4 MPress", "content": "MPress is a packer for PE32/PE32+/.NET executable formats. Similarly to UPX, MPress packs an executable by\ncompressing the original executable's code and data with the LZMA compression algorithm and uses an in-place\ndecompression technique to decompress the executable without additional memory overhead."}, {"title": "4.1.5 Hyperion", "content": "Hyperion is a crypter for PE32/PE32+ files that converts a PE file into an encrypted version capable of self-decrypting\nat runtime. Hyperion takes a PE binary as input, loads the entire file into memory, calculates its checksum, and attaches\nthis checksum to the file. Then, it generates a random key to encrypt the checksum and the input file using AES-128.\nThe resulting encrypted output is then copied into the container data section. Its container serves as both a decryptor\nand PE loader. It loads the encrypted file into memory, decrypts it, and starts the file's execution."}, {"title": "4.1.6 Amber", "content": "Amber10 is a position-independent (reflective) PE loader that loads and executes the original PE file in memory. The\nexecutable files packed with Amber begin by allocating memory to load the PE file. Then, the loader reads the PE file\nstructure and maps it into the allocated memory, making the necessary adjustments and relocations of addresses within\nthe code. Amber then resolves any dependencies and imports that the PE file requires. Finally, Amber transfers control\nto the entry point of the PE file, starting the execution of the loaded executable directly from memory without leaving\ntraces on the hard disk."}, {"title": "4.1.7 Mangle", "content": "Mangle\u00b9\u00b9 is not a packer, but a tool that obfuscates well-known Indicators of Compromise (IoC) based strings and\nreplaces them with random characters. In addition, Mangle allows the cloning of code-signing certificates of known\nlegitimate PE files. Code signing is a widespread security measure where the developer digitally signs an executable to\nverify its authenticity and integrity. The signature confirms that the file has not been altered since it was signed and\nhelps establish trust in the software's source. In practice, the majority of legitimate software developers code-sign\ntheir executables to establish trust with users and operating systems. Conversely, malware authors typically do not\nhave access to valid code-signing certificates for signing their malicious payloads. In our experiments, we cloned the\ncertificate of the Microsoft Word executable file (e.g., WINWORD.EXE)."}, {"title": "4.1.8 Nimcrypt2", "content": "Nimcrypt212 is a free packer for PE/PE+/.NET that uses Nim-RunPE13 for reflective PE-loading from memory, and\nNimGetSyscallStub 14 for dynamically obtaining system calls from a clean copy of the \"ntdll.dll\" file."}, {"title": "4.2 Dataset", "content": "The BODMAS dataset [18] was collected from August 2019 and September 2020 and consists of 57,293 malware samples\nbelonging to 581 malware families and 77,142 benign samples. The analysis with the Detect It Easy tool15 revealed\nthe most common packers and protectors used (Cf. Table 2), showing that 35,316 out of 57,293 (59.90%) malware\nand 40,243 out of 77,142 (52.17%) benign samples are packed, highlighting that packing is slightly more prevalent in\nmalware."}, {"title": "5 Experiments", "content": "In what follows, we detail the conducted experiments to answer the research questions outlined in Section 4."}, {"title": "5.1 Experiment I-A: malware detection - \"no packed executables\"", "content": "In this experiment, we trained the malware detectors with 22,500 malicious and 22,500 benign unpacked executables\nrandomly sampled from the BODMAS dataset. This subset of data has been split into training (36,000 executables - 80%),\nvalidation (4500 executables - 10%) and test sets (4500 executables - 10%). In addition, we randomly sampled 4500\npacked executables (2250 benign and 2250 malicious) to compare the performance of the detectors against unpacked\nand packed executables. The detectors have been evaluated based on their true positive rate (TPR) and true negative rate\n(TNR), also known as sensitivity and specificity, respectively. Sensitivity measures how good a model is at correctly\nclassifying malicious executables. Low sensitivity poses a cybersecurity risk, as it means that more malicious software\ngoes undetected. Specificity indicates how good a model is at correctly classifying benign executables as benign. High\nspecificity is also important as it ensures that benign software is not mistakenly flagged as malicious.\nThe results in Figure 4 show that while the specificity and sensitivity of malware detectors are moderately high\nfor unpacked executables, they drop noticeably for packed executables. From all detectors, the LightGBM model\nappears to be more robust to packing. Its robustness can be attributed to the use of various features for representing a\ncomputer program, including structural and metadata features, each of which provides a different perspective on the\ndata. Consequently, even if packing changes the statistical properties of the executables files, the LightGBM model can\nrely on metadata features to reach a decision. On the other hand, visual methods such as ResNet, EfficientNet, and\nVisionTransformer base their decision solely on the greyscale image representation of the computer program and thus,\npacking dramatically affects their ability to detect malware correctly, as the visual patterns these methods have learned\nare significantly distorted."}, {"title": "5.2 Experiment I-B: malware classification - \"no packed executables\".", "content": "In this experiment, we trained malware classifiers without packed executables. To this end, a random subset of 50\nunpacked executables has been selected from each malware family (malware families with fewer than 50 unpacked\nexecutables have been excluded). This approach ensures that trained classifiers are trained and tested against a\nstandardised set of data, reducing variability that could arise from different sample sizes per family. The resulting\ndataset of 2,650 executables from 53 families has been split into training, validation, and test sets, with the training,\nvalidation and test sets containing 40, 5, and 5 executables belonging to each family, respectively. The classifier's\nperformance has then been evaluated against the test set, which does not include any packed executables, and against\npacked versions of the executables in the test set created using the packers described in Section 4.1."}, {"title": "5.3 Experiment II: malware detection - \"only packed goodware or packed malware\".", "content": "Using as baseline the dataset described in Experiment I-A, 22,500 additional packed malware has been added to\nthe training (+18,000 packed malware), validation (+2250 packed malware), and test sets (+2250 packed malware).\nThe resulting training set consists of up to 18,000 packed malware, 18,000 unpacked malware and 18,000 unpacked\ngoodware. In this experiment, the ML-based malware detectors have been trained using varying quantities of packed\nmalicious executables, e.g., +3600, +7200, +10800, +14400 and +18000, to determine whether the exposure to packed\nmalicious executables during training leads to a predisposition of the detectors to classify packed executables, i.e.,\nbenign and malicious, as malicious."}, {"title": "5.4 Experiment III: good versus bad packers.", "content": "In this experiment, we trained the detectors using a dataset with goodware packed by UPX, Themida, Enigma, and\nMPress, and malware packed with Hyperion, Amber, Mangle, and Nimcrypt2. We then tested the detectors on\nexecutables packed with the previously mentioned packers. The results in Table 6 reveal that the detectors are strongly\ninclined to classify all executables packed with the \"good\" packers as benign and those with the \"bad\" packers as\nmalicious. This shows a significant bias, increasing the risk of false positives and negatives based on the packers\npredominantly used for packing benign and malicious executables in the training set."}, {"title": "5.5 Experiment IV: packers detection.", "content": "This experiment shifts focus from training a malware detector to developing a packer detector. The primary objective is\nto evaluate the feasibility of using machine learning to classify executables based on the packer employed. The packer\ndetectors have been trained using the dataset from Experiment I-A obfuscated with the packers defined in Section 4.1.\nThe results in Table 7 show that all detectors achieved over 99% accuracy, indicating that the structural manipulations\napplied by different packers are easily detectable and classifiable."}, {"title": "5.6 Experiment V-A: malware detection - \"unpacked and packed executables\".", "content": "In this experiment, the malware detectors were trained with varying amounts of packed goodware and malware to\ndetermine the impact of including packed executables during training. The results in Figure 6 reveal that the inclusion\nof packed executables during the training phase significantly improves the detectors' performance, especially when\nexposed to 7,200 packed executables (3,600 goodware and 3,600 malware)."}, {"title": "5.7 Experiment V-B: Train a malware classifier with packed and unpacked executables.", "content": "This experiment extends the dataset from Experiment I-B with packed executables from each family where available16.\nEach family has been extended with 50 packed executables, 40 for training and 5 for validation and testing. The"}, {"title": "5.8 Experiment VI-A: \"single packer\" detector.", "content": "This experiment simulates a scenario where a detector must determine the maliciousness of executables packed with a\npacker encountered during training. For each packer, we extended the training set from Experiment I-A with benign\n(+4,000) and malicious (+4,000) executables obfuscated with that packer. Then, the detectors are evaluated against\nexecutables obfuscated with the same packer. The results in Table 10 show that while the detectors' performance\ngenerally improved compared to those trained with packed executables randomly selected from the BODMAS dataset, the\nconsistency varied between packers and detectors. For instance, detectors struggled against executables packed with\nHyperion, Amber, and Nimcrypt2."}, {"title": "5.9 Experiment VI-B: \"single packer\" classifier.", "content": "This experiment assesses the classifiers' ability to generalise across different malware families when using a known\npacker to pack unseen executables. We utilised a subset of samples from the BODMAS dataset, selecting 250 unpacked\nexecutables from each family. Families with fewer than 250 unpacked executables were excluded to ensure uniformity\nand data sufficiency. The resulting dataset consists of 17 malware families. Each family's 250 unpacked executables\nwere divided into training, validation, and test sets of 200, 25, and 25 executables, respectively. We trained multiple\nclassifiers using a combined dataset of unpacked and packed executables with a single packer. Thus, each classifier\nwas exposed to both unpacked and packed malware samples obfuscated with a specific packer during training. These\nclassifiers were then evaluated on a test set packed with the same packer seen during the training. This evaluation\nhelps us observe the classifier's performance in a controlled environment where the packing method remains constant\nacross the training and testing phases. The results in Table 11 illustrate that augmenting the training set with packed\nexecutables does not necessarily improve the accuracy at test time against executables packed with the packer used\nto augment the training set. More precisely, while all classifiers maintain high accuracy when trained and tested with\nexecutables packed with UPX, Themida, and Enigma, they struggle against executables packed with MPress, Hyperion,\nand Nimcrypt2."}, {"title": "5.10 Experiment VII-A: \"withheld\" packer detector.", "content": "This experiment simulates a scenario where malware detectors must identify executables obfuscated with a packer not\nencountered during training. To achieve this, the training set from Experiment I has been extended with executables\nobfuscated with each packer except for one, which was withheld (4,000 benign and 4,000 malicious executables packed\nwith each packer). The resulting detectors were then evaluated against executables obfuscated with the packer excluded"}, {"title": "5.11 Experiment VII-B: \"withheld\" packer classifier.", "content": "Using the subset introduced in Experiment VI-B, we train multiple classifiers with unpacked executables and packed\nexecutables obfuscated with all packers except one, which was withheld. The resulting classifiers were then evaluated\nagainst executables obfuscated by the packer excluded from training. This setup assesses the classifiers' ability to\ngeneralise across different malware families when an unknown packer is used to pack the executables at test time. The"}, {"title": "5.12 Experiment IX: anti-malware engines in the industry versus packers", "content": "The packed test set used in Experiments 5.8 and 5.10 was submitted to VirusTotal to evaluate the performance of eight\nanti-malware products that are described as static machine learning-based malware detectors on the VirusTotal blog"}, {"title": "6 Conclusions", "content": "The recent advances in machine learning and artificial intelligence have enabled a plethora of applications and facilitated\nmany tasks and automation. Undeniably, they have both boosted the quality of cybersecurity measures; however, this is\nnot a panacea. Our work demonstrates the pitfalls that well-established models in the field of malware detection face\nwhen dealing with obfuscated malware. Our dataset analysis reveals the underlying similarities of the samples and\njustifies, to a great extent, the visual similarities and why visual methods exhibit such excellent results. For instance,\nhaving very similar files (at the byte level) or files sharing identical sections can obviously lead to visually similar\nimages. By identifying these inherent biases, we performed several targeted and extensive experiments exhibiting\nthe strong dependence of all these models on training with obfuscated samples. Indeed, the efficacy of all models\nsignificantly drops when they face specific packers.\nWhat is interesting to note is that our work demonstrates a realistic, low barrier technique to evade ML-based malware\nclassifiers. A real-world adversary will require non-trivial technical skill to create adversarial samples to bypass an\nML-based model. Most malware authors are not experts in machine learning, and the required changes to bypass\ndetection and maintain original functionality are not trivial and not always achievable. Nevertheless, using another"}]}