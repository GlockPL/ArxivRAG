{"title": "CognArtive: Large Language Models for Automating Art Analysis and Decoding Aesthetic Elements", "authors": ["Afshin Khadangi", "Amir Sartipi", "Igor Tchappi", "Gilbert Fridgen"], "abstract": "Art, as a universal language, can be interpreted in diverse ways, with artworks embodying profound meanings and nuances. The advent of Large Language Models (LLMs) and the availability of Multimodal Large Language Models (MLLMs) raise the question of how these transformative models can be used to assess and interpret the artistic elements of artworks. While research has been conducted in this domain, to the best of our knowledge, a deep and detailed understanding of the technical and expressive features of artworks using LLMs has not been explored. In this study, we investigate the automation of a formal art analysis framework to analyze a high-throughput number of artworks rapidly and examine how their patterns evolve over time. We explore how LLMs can decode artistic expressions, visual elements, composition, and techniques, revealing emerging patterns that develop across periods. Finally, we discuss the strengths and limitations of LLMs in this context, emphasizing their ability to process vast quantities of art-related data and generate insightful interpretations. Due to the exhaustive and granular nature of the results, we have developed interactive data visualizations, available online https://cognartive.github.io/, to enhance understanding and accessibility.", "sections": [{"title": "1 Introduction", "content": "Art serves as a universal language, capable of conveying multiple meanings and offering diverse interpretations. Artists, through their unique expressions, provide fresh insights into various concepts, influencing us on both personal and global levels. While traditional analyses of art focus on elements like color, line, and shape, and principles such as balance, contrast, and proportion, a more profound understanding emerges when considering factors beyond the physical. Artists deliberate on materials, scale, composition, and techniques, often infusing their work with emotion, reflecting the zeitgeist, or utilizing light to manipulate mood and meaning [Hodge, 2024]. We can depart from conventional analyses [Jin et al., 2024b] by exploring elements that delve deeper into the essence of artworks, aiming to make the understanding of art more compelling and comprehensive. Such framework encourages a richer, more stimulating engagement with art by examining the reasons behind its creation and the diverse approaches of artists, revealing dynamic methods of questioning and interpreting art [Hodge, 2024].\nArtificial Intelligence (AI) in general and LLMs in particular have emerged as powerful tools with the potential to revolutionize art analysis [Akhtar, 2024]. LLMs are trained on massive datasets of text, enabling them to perform tasks such as translation, summarization, and question answering [Kumar, 2024]. By leveraging computer vision, machine learning (ML), and natural language processing (NLP), we can extract meaningful information from digital images of art [Castellano et al., 2022; Castellano and Vessio, 2022; Cetinic et al., 2019; Imran et al., 2023; Zhang et al., 2024]. These techniques enable computers to detect visual elements, classify styles, identify artists, and even generate descriptions of artworks [Bin et al., 2024].\nThe advent of LLMs with visual capabilities, often referred to as vision LLMs, offers a transformative approach to art analysis, expanding the scope of inquiry beyond traditional methods. These models, such as GPT-4V\u00b9, Flamingo [Alayrac et al., 2022], and LLaVA [Liu et al., 2024], are capable of processing and interpreting visual data in conjunction with textual information, enabling them to identify artistic styles, recognize artists, describe scene elements, and even infer emotional content within artworks. By leveraging vast datasets of images and text, vision LLMs can provide insights into the formal elements, contextual factors, and cultural significance of art pieces, assisting in tasks like attribution, stylistic classification, analysis of composition, color, and other visual elements [Bin et al., 2024; Cao, 2024; Constantinides et al., 2024; Ozaki et al., 2024; Hayashi et al., 2024; Tao and Xie, 2024]. While still in their early stages of development, these models demonstrate immense potential to enhance our understanding of art by automating analytical processes and uncovering hidden connections between different art pieces and their history, offering a novel lens through which to appreciate and examine the multifaceted world of artistic creation.\nGPT-4V represents a significant leap forward in AI technology, enabling a new level of interaction between humans and"}, {"title": "2 Related Works", "content": "The study of computational aesthetics and art analysis has grown significantly with advancements in AIML. These technologies have provided new methods for exploring artistic styles and understanding cultural patterns. Datasets play an essential role in this progress, serving as the foundation for training and testing models. The quality and diversity of datasets greatly impact model performance and generalizability to various artistic and cultural contexts. Over recent decades, many initiatives have contributed to digitizing art collections, making them accessible for computational analysis and enabling the creation of robust datasets.\nOne of the most well-known datasets for aesthetic evaluation is the aesthetic visual analysis (AVA) dataset, created by [Murray et al., 2012]. It contains over 250,000 images, each annotated with scores that reflect their aesthetic quality. This dataset was primarily focused on photographs, as was the aesthetic and attribute database (AADB) introduced by [Kong et al., 2016] containing aesthetic scores and meaningful attributes assigned to each image by multiple human raters. While these datasets helped researchers study the aesthetics of photographs, they were not suitable for analyzing artistic works such as paintings and drawings. To address this, art-specific datasets like WikiArt\u00b3 and the Rijksmuseum Challenge [Mensink and van Gemert, 2014] introduced thousands of images of artworks, enabling tasks such as artist identification and style recognition.\nDeep learning (DL) methods have advanced the analysis of art, making it possible to classify styles [Scaringi et al., 2025] and attribute artworks to their creators with high accuracy. One common approach is transfer learning, where convolutional neural networks trained on large datasets like ImageNet [Deng et al., 2009] are fine-tuned for tasks specific to art analysis [Cetinic and She, 2022]. This method was effective for style classification and artist attribution. Neural style transfer (NST) [Jing et al., 2019; Gatys, 2015] is another approach allowing models to separate an artwork's style from its content. NST contributed for further research into how stylistic features can be analyzed and even replicated computationally. Researchers have also studied how styles evolve and connect with cultural patterns. For example, [Cetinic and She, 2022] showed that neural networks could detect stylistic features that align with historical concepts in art, while datasets like OmniArt [Strezoski and Worring, 2018] have been used to map stylistic diversity across different cultures.\nHowever, while DL models have significantly transformed the analysis of art by identifying, for example, patterns and predict aesthetic scores, they often struggle to interpret the symbolic meanings or historical significance of artworks [Cetinic and She, 2022]. Moreover, DL models rely heavily on labeled dataset while creating such datasets for art analysis is time-consuming and expensive knowing that they often focus on a limited range of artistic styles and concepts. Furthermore, models designed for one type of artistic task, such as style classification, struggle to adapt to other tasks without significant adjustments [Cetinic and She, 2022; Elgammal et al., 2018]. Multimodal approaches, which combine text and images, have become an important area of research. Projects like Artpedia [Stefanini et al., 2019] and SemArt [Garcia and Vogiatzis, 2018] introduced models that align both visual and textual description (contextual descriptions) in a shared semantic space. This alignment enables advanced searches based on content. For example, a user could search for paintings that match a specific theme or historical context, and the system would retrieve relevant results by analyzing both visual features and textual descriptions. The OmniArt dataset has been particularly useful in this field, as it includes detailed metadata alongside visual and textual annotations, supporting deeper studies of iconography and stylistic elements. These methods highlight the potential of combining different types of data to improve how we study and interpret art.\nThe rise of LLM such as GPT [Brown et al., 2020], Gemeni [Team et al., 2023], and CLIP [Radford et al., 2021] has further contributed to improve computational aesthetics by bridging the gap between visual and textual data. LLMs have expanded the possibilities for multimodal analysis, allowing models to process text and images in a unified framework. For example, CLIP aligns textual and visual embeddings, enabling the evaluation of artworks based on textual descriptions, such as \"a serene landscape with balanced composition\". Such models offer new capabilities for integrating narrative and aesthetic elements, facilitating tasks like multimodal retrieval"}, {"title": "3 Methods", "content": null}, {"title": "3.1 Dataset", "content": "We retrieved dataset for our study by obtaining a collection of digital reproductions of artworks sourced from WikiArt, a comprehensive online repository of visual art. We focused on a selection of 23 artists widely regarded as among the most influential figures in art history. The dataset encompasses a total of 15,000 artworks across 34 different ground-truth art"}, {"title": "3.2 Proposed art analysis criteria", "content": "Figure 2 illustrates the concept and structure used in our analysis. We evaluated the artworks from two distinct yet related perspectives: technical and conceptual. Each perspective encompasses a set of corresponding criteria, as detailed in Figure 2. Technical analysis involves a broad range of criteria, including shape and scale, light, material, and the techniques employed by the artists. Expressive and conceptual analysis includes assessing the artworks based on their use of color, figures, objects, and movement.\nTo facilitate this analysis, we utilized GPT-4V. We sent API requests to the model, uploading a digitized image of each artwork along with a prompt consisting of eight questions [Hodge, 2024] (Figure 3). These questions covered the assessment"}, {"title": "4 Results", "content": "Going forward, we will incorporate figures accessible online as supplementary material, designated with the prefix \"S\". The following is a structured presentation of the key findings of our study."}, {"title": "4.1 Form and scale", "content": "Figure S1 depicts the distribution of the form types across different years. Natural forms have consistently been predominant throughout the observed period, maintaining a higher representation compared to geometric forms. In recent years, however, geometric forms have become increasingly prominent. Additionally, irregular forms have gained popularity more recently, surpassing the contributions of regular forms, which were previously more dominant across various periods. Figure S2 illustrates the distribution of scale types among artists. It shows a preference for large or oversized scales in their work. Notably, there has been a recent increase in popularity for smaller or reduced scales among different artworks."}, {"title": "4.2 Color", "content": "We analyzed the color distribution in artworks to discern trends in emotional themes or color tones reflected by their palettes. Figure S3 displays the temporal distribution of colors in our"}, {"title": "4.3 Light, shadow and contrast", "content": "Figure S7 represents the distribution of light and contrast compositional elements. We aimed to explore the relationship between light, contrast, and their intended purposes in artworks. As demonstrated, most artists employ light and contrast to enhance highlights, depth, and textures. Similarly, the representation of emotions increased substantially during"}, {"title": "4.4 Movement and material", "content": "Figure S11 illustrates the distribution of representations of movement. The results suggest that most of the artists have conveyed the movement rather than implying or suggesting it actually. Additionally, the findings indicate that most recent artworks have eschewed overt literal representations of movement in their compositions. The distribution of mediums and materials is presented in Figure S12. As shown, oil together canvas are the most dominant material types. Paper and ink were also frequently used, particularly in the 16th and 17th centuries, although to a lesser extent than oil and canvas. Wood was a prevalent material in the 16th and 17th centuries, with its use declining in later periods. Notably, acrylic emerged in the 20th century, reflecting the introduction of new synthetic materials in art production."}, {"title": "4.5 Techniques", "content": "Figure S13 represents the distribution of techniques and textures. The data reveal significant temporal variations. We found that blending and layering had been dominant techniques employed by artists. Smooth brushstrokes saw a significant increase in the late 19th and early 20th centuries, coinciding with the rise of Impressionism and related movements. Fine lines also exhibited a notable increase during the 19th and 20th centuries, though less pronounced than blending. Crosshatching showed a fluctuating trend from the 17th century onwards exhibiting a decline in the 20th century, while scarping and pointillism began to emerge."}, {"title": "4.6 Time and figures", "content": "Figure S14 depicts the distribution of times of day and seasons in artworks. The data show that morning and afternoon settings have been more commonly portrayed compared to other times of the day, with this trend remaining relatively consistent across various periods. Recently, however, there has been an increase in artists opting for nighttime in their works. The distribution of the type of figures is illustrated in Figure S15. Human Figures consistently dominated representations"}, {"title": "5 Evaluation", "content": "In order to evaluate the accuracy of our analytical methodology, we compared our results with established descriptions of the ground-truth art styles. We transitioned from traditional topic modeling approaches, such as Latent Dirichlet Allocation (LDA) [Blei et al., 2003], to more advanced text embedding techniques to enhance the semantic accuracy of our analyses. Specifically, we utilized four state-of-the-art embedding models to transform textual data into meaningful, comparable representations. These models included Sentence-BERT (SBERT) [Reimers and Gurevych, 2019], BGE-M3 [Multi-Granularity, 2024], OpenAI's text-embedding-3-small4 and NVIDIA's NV-Embed-v2 [Lee et al., 2024].\nThe results of the artwork analysis and the corresponding descriptions of known art styles were encoded into embeddings using the four models mentioned above. Specifically, for the SBERT embeddings, we utilized the \"all-mpnet-base-v2\" model [Thakur et al., 2021], which is fine-tuned to capture sentence-level semantic meanings effectively. All evaluations were conducted on an Apple MacBook M3 Pro with a 14-core GPU, except for the final model. For the evaluation with NV-Embed-v2, we utilized four RTX A6000 GPUs, each equipped with 48 GB of GPU memory.\nThe core of our evaluation process involves computing the cosine similarity between the embeddings generated from the art analysis results and those derived from style-specific descriptions. This approach enables us to quantitatively assess the alignment between our analytical outputs and established art style descriptors. Based on the statistics presented in Table 1 (also shown in Figures S16-S20), our evaluation demonstrates significant variation in the cosine similarity scores across different embedding models and focus areas. Among the models, NVIDIA's NV-Embed-v2 consistently exhibits the highest median scores across all focus areas, with particularly strong performance in Form/Scale (0.62), Movement (0.63), and Techniques (0.70). This suggests that NV-Embed-v2 embedding space captures stylistic features more effectively than other models, particularly in technical and dynamic aspects of artwork. BGE-m3 follows closely, achieving comparable median scores in most categories, especially in Light/Contrast (0.61), Movement (0.61), and Material (0.62). On the other hand, SBERT and OpenAI models generally yield lower similarity scores, indicating that their embeddings may be less specialized in distinguishing artistic styles based on our predefined criteria. Aggregating across all models, the SBON (summary statistics) row highlights that Techniques (0.61 median) and Movement (0.57 median) emerge as the most consistently aligned features between analysis results and art style embeddings. This indicates that aspects related to brushwork, composition techniques, and movement patterns are more effectively captured by language models compared to material or light-based attributes. The relatively lower similarity scores in"}, {"title": "6 Discussion", "content": "Our study demonstrates the significant potential of LLMs, specifically GPT-4V, Gemini 2.0, and GPT-4, in revolutionizing the field of art analysis. By leveraging these advanced AI models, we were able to process and interpret over 15,000 art-"}, {"title": "7 Conclusion and Future Work", "content": "Our findings demonstrate that our approach to decoding the authentic nuances of artworks can be effectively addressed using LLMs. This method not only reveals patterns and trends in the evolution of artistic styles, visual elements, composition, and techniques over time but also generates insightful interpretations. Additionally, it provides a more objective and efficient means of art analysis, complementing traditional methods and offering a valuable tool for art historians, researchers, and enthusiasts.\nFuture research could explore further advancements in LLM techniques and their applications in a broader range of artworks. Investigating the potential of LLMs in other aspects of art analysis-such as identifying forgeries, understanding the influence of social and cultural factors on art, and predicting future trends could deepen our understanding of art and its evolution. Furthermore, the development of more interactive and user-friendly interfaces for LLM-based art analysis could make these powerful tools more accessible to students, educators, and art enthusiasts."}]}