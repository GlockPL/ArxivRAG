{"title": "Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts", "authors": ["Soojin Yoon", "Sungho Ko", "Tongyoung Kim", "SeongKu Kang", "Jinyoung Yeo", "Dongha Lee"], "abstract": "Cross-lingual entity alignment (EA) enables the integration of multiple knowledge graphs (KGs) across different languages, providing users with seamless access to diverse and comprehensive knowledge. Existing methods, mostly supervised, face challenges in obtaining labeled entity pairs. To address this, recent studies have shifted towards a self-supervised and unsupervised frameworks. Despite their effectiveness, these approaches have limitations: (1) they mainly focus on entity features, neglecting the semantic information of relations, (2) they assume isomorphism between source and target graphs, leading to noise and reduced alignment accuracy, and (3) they are susceptible to noise in the textual features, especially when encountering inconsistent translations or Out-Of-Vocabulary (OOV) problems.\nIn this paper, we propose ERALIGN, an unsupervised and robust cross-lingual EA framework that jointly performs Entity-level and Relation-level Alignment using semantic textual features of relations and entities. Its refinement process iteratively enhances results by fusing entity-level and relation-level alignments based on neighbor triple matching. The additional verification process examines the entities' neighbor triples as the linearized text. This Align-and-Verify pipeline that rigorously assesses alignment results, achieving near-perfect alignment even in the presence of noisy textual features of entities. Our extensive experiments demonstrate that robustness and general applicability of ERALIGN improved the accuracy and effectiveness of EA tasks, contributing significantly to knowledge-oriented applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Knowledge graphs (KGs) are structured data that represent the real-world knowledge [1, 3, 26] and are used in various applications such as question answering [12, 40] and commonsense reasoning [15, 19]. Over the past decade, KGs have typically been developed for specific domains and languages, resulting in unique knowledge bases with some overlapping information. This has led to the rise of the cross-lingual entity alignment (EA) task [22, 37], which aims to identify equivalent entities across different languages. This task is not trivial as entities often have proper nouns as names, making simple machine translation ineffective. For instance, the entity named '\u9ece\u660e' represents the Hong Kong actor, with its aligned pair being 'Leon Lai'. However, \u2019\u9ece\u660e' translates to 'dawn', which may not align correctly with the intended meaning. Also, entities with the same name can refer to different things, or a single entity can have multiple names, complicating the alignment process. EA addresses these challenges by enabling the seamless integration of expanded knowledge across different language KGs.\nMost existing methods for cross-lingual EA use supervised approach that trains a parametric encoder [2, 33, 38]. These methods compute embeddings for entities by encoding their structural information, using translation embedding [2, 6, 28, 37] or Graph Neural Networks (GNNs) [33, 35, 36]. They rely on a few pre-aligned pairs for supervision. However, obtaining labeled entity pairs is challenging in practice. To address the scarcity of annotated pairs, recent studies have explored self-supervised and unsupervised frameworks. Self-supervised methods generate pseudo seed alignments from auxiliary information, such as images or texts, to learn embeddings without pre-aligned pairs. State-of-the-art unsupervised methods treat the EA task as an Optimal Transport (OT) problem, using algorithms like Hungarian [14] or Sinkhorn [8] to align entities based on similarity.\nThese approaches, while effective, have limitations: (1) They mainly rely on features of entities, neglecting semantic information of relations, which hinders the consideration of heterogeneous relationships among entities. (2) They assume that source and target graphs are isomorphic, which is rarely the case in practice. As a result, their approaches introduce noise, degrading the final performance. (3) They are susceptible to noise or errors in textual features caused by inconsistent translations or Out-Of-Vocabulary (OOV) proplems, ultimately reducing alignment accuracy.\nIn this paper, we focus on utilizing semantic textual features of relations jointly with those of entities to capture neighbor triples for EA. We propose a robust cross-lingual EA framework named ERALIGN, which jointly performs Entity-level and Relation-level Alignment. Unlike existing methods that often neglect the semantic information of relations, ERALIGN aims to enhance the efficacy and robustness of EA through triple-level semantic matching. This is achieved by using dual knowledge graphs, where entities and relations are represented as edges and nodes, respectively, contrary to their original KGs. This innovative structure enables ERALIGN to align relations across KGs without requiring additional technique, making it broadly applicable to various KGs.\nWe obtained initial alignment result for entities and relations from the original and dual KGs. Then, a collaborative refinement process iteratively merges alignment scores through neighbor triple matching, effectively integrating both structural and textual information of entities and relations within the source and target KGs. Additionally, we introduce an Align-and-Verify pipeline that includes an extra verification step to rigorously assess and refine alignment results. In the verification step, ERALIGN identifies misaligned entity pairs by evaluating alignment confidence and consistency, and corrects them by examining the semantic relevance of their linearized neighbor triples. This approach effectively filters out misalignments caused by non-isomorphic structures and robustly handles noise introduced in earlier steps by leveraging the rich textual context.\nWe conduct various experiments using five different datasets to explore performance of ERALIGN in multiple perspectives. The results demonstrate that ERALIGN exhibits greater robustness to noisy text features associated with entities compared to existing methods. Additionally, our verification step effectively identifies and corrects inaccuracies in EA results, achieving near-perfect alignment even with noisy features. Furthermore, we show that our Align-and-Verify pipeline can be generally applied to other EA methods, enhancing their robustness to noise. This is significant, as in knowledge-oriented tasks like EA, improving accuracy is crucial; even a small increase in accuracy is meaningful. With its compatibility across unsupervised EA methods, ERALIGN can serve as a general cross-lingual EA framework. For reproducibility, our codes and datasets are publicly available at https://github.com/eralign/eralign.\nThe contributions of this paper are summarized as follows.\n\u2022 ERALIGN conducts simultaneous entity-level and relation-level alignment through dual graph construction. Then it refines both alignments jointly in an iterative fashion by merging them based on the neighbor triple matching leveraging both structural and textual information.\n\u2022 ERALIGN introduces the Align-and-Verify pipeline, which rigorously refines alignment results with two metrics, enhancing accuracy even with noisy text features, by examining the semantic relevance of neighbor triples. Its noise robustness is demonstrated through experiments.\n\u2022 ERALIGN is generally applicable to other entity alignment (EA) methods, improving their robustness and overall performance. This makes ERALIGN a versatile solution that significantly contributes to the accuracy and effectiveness, ensuring near-perfect alignment in real-world scenarios."}, {"title": "2 RELATED WORK", "content": "Most existing studies on EA primarily operate within a supervised framework, where they align source and target KGs in an embedding space using either translation embeddings [2, 6, 28, 37] or GNN encoders [33, 35, 36]. However, such a supervised approach heavily relies on manually curated entity pairs, which can be both expensive and prone to errors. Recently, unsupervised EA methods have emerged to address the absence of aligned entity pairs by utilizing side information within KGs to identify a small set of seed alignments. This approach replaces the need for human-labeled pairs by using auxiliary information such as auxiliary information in KGs, such as entity-associated images [7, 16], temporal details of triples [17], and literal entity information [22]. For instance, EVA [16] adopts \"visual pivoting\" to extract visual and structural information from KG triples, MeaFormer [7] dynamically predicts inter-modal relative weights using associated images, and Dual-Match [17] aligns entities within temporal KGs by using a weighted graph matching framework.\nThe latest method [22] introduces an innovative parameter-free framework, which revolutionizes traditional optimization processes. By directly comparing entities across both the source and target knowledge graphs (KGs) and leveraging structure-enhanced textual features associated with entities, this method introduces a novel perspective to the alignment challenge. This unique approach reformulates the alignment problem as an OT problem, achieving state-of-the-art accuracy and efficiency. As ERALIGN obtain initial alignment score based on this method, we avoid the complexity associated with neural networks such as GNNs and Transformer encoders, seeking to further advance the field of cross-lingual EA."}, {"title": "2.2 Cross-lingual Entity Alignment", "content": "Cross-lingual EA is a kind of knowledge-oriented task that aimed to aligning entities across the KGs constructed in different languages. Within EA, the quality of entity embeddings plays a critical role for achieving accurate alignment results. Recent studies have explored embedding methodologies that leveraging textual information, such as entity and attribute names in natural language, to incorporate semantic nuances into embeddings. In this sense, various attempts have been made; they typically use either entity names [10, 21, 35, 36, 38], entity descriptions [5], or a combination of both [31, 41]. However, despite their efficacy, these strategies are susceptible to OOV problem, wherein terms or entities not present in the training data pose challenges.\nTo address this, some methods incorporate lexical features, encompassing character or word occurrences [20, 34, 39], and even integrating both semantic and lexical features [22]. Despite these advancements, existing cross-lingual EA methodologies mainly rely on textual information associated with nodes (i.e., entities) and often disregarding the heterogeneous relationships existing among entities within KGs. Our objective is to enhance these methods by strategically incorporating textual information on various types of edges (i.e., relations). By doing so, we aim to achieve to achieve more accurate alignment by considering the relational structure inherent relational structure within KGs, thereby overcoming the limitations of current approaches."}, {"title": "3 PRELIMINARY", "content": "A KG is represented as G = (E, R, T), where &, R, and T are the set of entities, relations, and triples, respectively. Each triple is represented as (h, r, t) \u2208 T, where h, t \u2208 & denote the head and tail entities and r\u2208 R denotes the relation between h and t. The structural information can be summarized as the adjacency matrix A \u2208 R|&|\u00d7|8|, and the textual features of all entities and relations are encoded in $H_{ent} \\in \\mathbb{R}^{|E| \\times d}$ and $H_{rel} \\in \\mathbb{R}^{|R| \\times d}$ where d is the dimensionality.\nThe cross-lingual entity alignment (EA) task aims to find out every pair of equivalent entities between the source knowledge graph $G_{S} = (E_{S}, R_{S}, T_{S})$ and the target knowledge graph $G_{T} = (E_{T}, R_{T}, T_{T})$, built upon different languages. In this work, we focus on the unsupervised setting, where no labels are available.\nTo leverage the structural information of KGs, we construct the adjacency matrix, as done in previous work [22]. Considering that an edge type appearing less frequently in triples conveys more unique information, higher weight values are allocated to the edges with lower frequency. The (i, j)-th entry of adjacency matrix A which represents the connection between node i and node j is formulated as:\n$[A]_{ij} = \\frac{\\sum_{r \\in R(i,j)} log (\\frac{|T|}{|T_{r}|})}{\\sum_{k \\in N(i)} \\sum_{r' \\in R(i,k)} log (\\frac{|T|}{|T_{r'}|})},$\nwhere N(i) is the set of neighbor nodes of node i, R(i, j) is the set of relations connecting node i and node j, T = $T_{S} \\cup T_{T}$ is all triples from the source and target KGs, and $T_{r}$ is the set of triples with relation r. Note that the adjacency matrices are separately constructed for the source and target graphs.\nWe consider two different types of feature encoding for entity/relation texts, which are semantic and lexical features. In general, for cross-lingual EA, semantic features can be acquired in two ways: (1) encoding machine-translated text with pre-trained language models (PLMs) or (2) directly capturing semantics through multi-lingual PLMs. However, the semantic features often suffer from an OOV issue, which cannot capture the meaning of words (or tokens) unseen during the training phase. Especially, in case of the KGs for encyclopedia (i.e., DBP15K), as the entity names are usually proper nouns, such as the name of celebrities or cities, handling OOV words properly is critical for obtaining useful embeddings. Therefore, we extract the character-level features from translated texts, and use them as the additional lexical features along with the semantic features described above."}, {"title": "3.2 Optimal Transport-based Entity Alignment", "content": "The state-of-the-art approach to the unsupervised cross-lingual EA task formulates the alignment problem as an OT problem [22]. The OT problem aims to match two probability distributions by assigning one to the other to achieve the best profits, as follows:\n$\\underset{P}{\\text{argmax}} (P, X)_{F}.$\nX is the profit matrix, P is a transportation matrix, and $ \\langle \\rangle_{F}$ is the Frobenius inner product. Note that, for the cross-lingual EA task, the transportation matrix P has an additional constraint of having only one entry of 1 in each row and column with entries of 0 elsewhere; this is also known as assignment problem.\nThere are several well-known solvers for the OT problems, including Hungarian [14] and Sinkhorn [8] algorithms. In terms of time complexity, the improved Hungarian algorithm takes $O(n^{3})$, whereas $O(kn^{2})$ for Sinkhorn algorithm described by\n$\\begin{aligned}S_{0}(X) &= exp(X), \\\\S_{k}(X) &= F_{c}(F_{r}(S_{k-1}(X))), \\\\Sinkhorn(X) &= \\lim_{k \\rightarrow \\infty} S_{k}(X),\\end{aligned}$\nwhere $F_{r}(\\cdot)$ and $F_{c}(\\cdot)$ are the row-wise and column-wise normalization operators that divide each element by the sum of its row and column, respectively. The Sinkhorn algorithm is proved to solve the assignment problem as follows [24]:\n$\\underset{P}{\\text{argmax}} (P, X)_{F} = \\underset{\\tau \\rightarrow 0^{+}}{\\text{lim}} Sinkhorn(\\frac{X}{\\tau}).$\nThe previous work [22] empirically found that a very small k value is enough to perform the EA task. This makes the time complexity of Sinkhorn $O(n^{2})$, apparently more time efficient than that of Hungarian algorithm. Therefore, we mainly adopt the Sinkhorn algorithm to solve the cross-lingual EA task, even though it can obtain only approximate results."}, {"title": "4 METHOD", "content": "In this section, we present ERALIGN, a novel unsupervised cross-lingual EA framework. Designed to exhibit robustness to noisy features, ERALIGN aligns source and target KGs by capitalizing on the textual features of entities and relations (i.e., names) in conjunction with structural information (i.e., neighbor triples)."}, {"title": "4.1 Overview", "content": "The key idea of ERALIGN is to align entities and relations across the source and target KGs simultaneously. This involves an iterative fusion of entity-level and relation-level alignment based on structural information within the KGs.\nTo be specific, ERALIGN consists of the three steps: (1) dual alignment of entities and relations, (2) iterative refinement of dual alignment, and (3) erroneous alignment verification. ERALIGN starts by computing the initial entity-entity and relation-relation alignment based on textual node features on the original KGs (for entities) and the dual KGs (for relations), respectively. Then, it jointly refines the two types of alignment scores in an iterative manner via neighbor triple matching, which aims to additionally match the sets of relevant triples between source and target KGs. Finally, ERALIGN further detects and rectifies the incorrectly aligned entity pairs with the help of language models, by directly capturing the semantic meaning of the neighbor triples of each entity. Algorithm 1 outlines the comprehensive pseudo-code for ERALIGN."}, {"title": "4.2 Dual Alignment of Entities and Relations", "content": "In the first step, ERALIGN computes the entity and relation alignment between Gs and Gr. To this end, it first calculates the entity-entity and relation-relation similarity matrices based on textual features of the source and target graphs. We enhance entity features in both source and target KGs by integrating structural information. This involves propagating textual node features to their l-hop neighbor nodes using a basic graph convolution operation, denoted as $(A_{ent})^{l} H_{ent}$ for depth of l \u2208 N. By computing the inner product of these structure-enhanced entity features in Gs and Gr, we determine the entity-entity similarities. The final pairwise similarity matrix $X^{ent} \\in \\mathbb{R}^{|E_{S}| \\times |E_{T}|}$ is defined as the sum of the similarities across depths 1 = 0, . . ., L:\n$X^{ent} = \\sum_{l=0}^{L} ((A_{ent}^{s})^{l} H_{ent}^{s})((A_{ent}^{t})^{l} H_{ent}^{t})^{T},$\nSimilarly, to enhance relation features through textual propagation, we construct the dual knowledge graph $G^{\\ast} = (E, R, T)$, derived from the original KG G. In this dual KG, nodes represent edges in G (i.e., & = R) and the edges correspond to nodes in G (i.e., R = 8).1 The adjacency matrix of the dual KG, denoted as $A^{rel}$, is also constructed based on its definition in Equation (1). By utilizing both source and target dual KGs, we define the relation-relation similarity matrix $X^{rel} \\in \\mathbb{R}^{|R_{S}| \\times |R_{T}|}$ in the same manner as Equation (5), ensuring consistency in the propagation of textual features through the dual KGs:\n$X^{rel} = \\sum_{l=0}^{L} ((A_{rel}^{s})^{l} H_{rel}^{s})((A_{rel}^{t})^{l} H_{rel}^{t})^{T},$\nApplying the Sinkhorn algorithm on the similarity matrices leads to the initial alignment results. This effectively establish correspondence between nodes across both original and dual KGs based on their similarity.\n$\\hat{X}^{ent} = \\underset{\\tau \\rightarrow 0^{+}}{\\text{lim}} Sinkhorn(X^{ent} /\\tau),$\n$\\hat{X}^{rel} = \\underset{\\tau \\rightarrow 0^{+}}{\\text{lim}} Sinkhorn(X^{rel} /\\tau),"}, {"title": "4.3 Iterative Refinement of Dual Alignment", "content": "In the second step, ERALIGN iteratively refines the alignment scores for both entity-entity and relation-relation alignment by integrating their alignment results through neighbor triple matching between the source and target KGs (Figure 2). The initial alignment scores for entities, $\\hat{S}^{ent}$, and relations, $\\hat{S}^{rel}$, are derived from the matrices $\\hat{X}^{ent}$ and $\\hat{X}^{rel}$, as specified in Equations (7) and (8), respectively.\nFor the (i, j)-th entity alignment, the score is refined by aggregating alignment scores from neighboring triples in both the source and target KGs. Specifically, by considering all neighboring triples (i, p, i') \u2208 Ts and (j, q, j') \u2208 T\u012b (or (i', p, i) \u2208 Ts and (j', q, j) \u2208 TT), ERALIGN effectively combines alignment scores for tail (or head) entity pairs (i', j') by weighting them based on the alignment scores of their corresponding relation pair (p, q). Neighbor triples of entity i can be pre-specified based on whether the head (or tail) entity in each triple (h, r, t) is equal to i. Likewise, the (i, j)-th relation alignment score is updated by leveraging neighbor triples in the dual KGs. To summarize, the n-th iteration updates the entity and relation alignment scores as follows:\n$\\begin{aligned}\\[S^{ent}]_{ij}^{n} = & \\lambda \\cdot [S^{ent}]_{ij}^{n-1} \\\\&+ (1-\\lambda) \\cdot \\sum_{\\substack{(i,p,i') \\in T' \\\\ (j,q,j') \\in T'}} \\frac{exp([S^{rel}]_{pq}^{n-1})}{\\sum_{(j,q,j') \\in T'} exp([S^{rel}]_{pq'}^{n-1})} [S^{ent}]_{i'j'}^{n-1} \\\\, [S^{rel}]_{ij}^{n} = & \\lambda \\cdot [S^{rel}]_{ij}^{n-1} \\\\&+ (1-\\lambda) \\cdot \\sum_{\\substack{(i,p,i') \\in T' \\\\ (j,q,j') \\in T'}} \\frac{exp([S^{ent}]_{i'j'}^{n-1})}{\\sum_{(i',p,i') \\in T'} exp([S^{ent}]_{i'p}^{n-1})} [S^{rel}]_{pq}^{n-1} ,\\end{aligned}$\nwhere \u03bb\u2208 (0, 1) is the hyperparameter to govern the weighting of the alignment score from the preceding iteration. For notational convenience, we use the reverse-augmented triple set, denoted by T' := T\u222a {(t, r,h)|(h, r,t) \u2208 T}, to represent an entity's all neighbor triples. Note that, in each iteration, entity and relation alignment intertwine through 1-hop neighbor triple matching. By increasing the total number of iterations N, we can incorporate a more extensive relational structure within the KGs.\nThe final alignment results for the cross-lingual EA task are obtained by applying the Sinkhorn algorithm to the alignment scores $S^{ent}$ and $S^{rel}$. The Sinkhorn algorithm leads to more accurate and reliable cross-lingual entity and relation alignments.\n$\\hat{S}^{ent} = \\underset{\\tau \\rightarrow 0^{+}}{\\text{lim}} Sinkhorn(S^{N^{ent}} /\\tau),$\n$\\hat{S}^{rel} = \\underset{\\tau \\rightarrow 0^{+}}{\\text{lim}} Sinkhorn(S^{N^{rel}} /\\tau)."}, {"title": "4.4 Erroneous Alignment Verification", "content": "The last step is the verification of entity alignment results to enhance robustness against noisy textual features. Such noise, often resulting from machine translation or textual encoding issues, significantly impacts on the overall performance of the cross-lingual EA task. To address this challenge, we directly scrutinize the neighbor triples of each entity as the text. This approach, which is less affected by noisy features within rich textual contexts, defines the alignment score between two entities based on the semantic similarity of their neighbor triples' linearized texts, utilizing PLMs. Our verification step first identifies flawed entity alignments, subsequently reorders the entities according to their semantic similarity computed by PLMs.2\nTo effectively identify misaligned entity pairs, we devise and examine two distinct metrics tailored to assess the accuracy of entity alignment. These metrics are individually crafted for each entity within the source KG, i \u2208 Es.\n\u2022 Confidence: It gauges the confidence with which the top-1 entity (in &r) is aligned with i: Conf(i) = max([\u015cent]i:).\n\u2022 Consistency: It reflects how consistently entities (in &r) are aligned during iterative refinement. Higher consistency implies less discrepancy between the entity-level and relation-level alignments: Cons(i) = cos([xent]i:, [Sent]i:).\nWe conduct a thorough analysis of the correlation between these metrics and the actual alignment errors made by ERALIGN. In Figure 3, it is evident that erroneous entity pairs are distinguishable from correct pairs based on their confidence and consistency. Precisely, the AUROC (and AUPR) of confidence and consistency for error detection are respectively 0.965 (0.998) and 0.977 (0.999), indicating the effectiveness of these metrics as discriminators. In light of this, we selectively collect the set of entities for verification, denoted as $E_{ver}$ = {i|Conf(i) < $\u03b8_{conf}$ V Cons(i) < $\u03b8_{cons}$, Vi \u2208 &s}.\nAfter collecting the potentially incorrect entities, we replace their alignment scores with semantic relevance derived from the linearized texts of the neighbor triples associated with these entities. For each entity i \u2208 Ever, we identify its top-K aligned entities as candidates, denoted as Cand(i) = Top-K([\u015cent]i:). It is these candidates that undergo reranking based on textual semantic relevance.3 To measure textual semantic relevance, we utilize PLMs [9, 18, 32] fine-tuned specifically for the task of semantic textual similarity (STS).4\nThe semantic relevance scores obtained from PLMs hinge on the order of neighbor triples within the linearized text. We initially sort all neighbor triples (i, p, i') \u2208 T' for an entity i \u2208 Ever based on the inverse frequency of its relation p (Equation (1)). Subsequently, we sort the neighbor triples (j, q, j') \u2208 Tf of each candidate entity je Cand(i) so that their order becomes consistent with the order of (i, p, i') based on the alignment score, i.e., [\u015crel] pq \u00b7 [\u015cent] i' j'. The resulting sequence of neighbor triples is then directly transformed into linearized text, serving as the basis for reranking entities.\n$\\begin{aligned}\\mathcal{V}_{T}(i) &= \\underset{j \\in Cand(i)}{\\text{argsort}}\\left(f_{\\phi}\\left(Z_{S}(i), Z_{T}(j)\\right)\\right),\\mathcal{V}_{S}(j) &= \\underset{i \\in Cand(j)}{\\text{argsort}}\\left(f_{\\phi}\\left(Z_{S}(i), Z_{T}(j)\\right)\\right),\\end{aligned}$\nwhere Zs (i) and ZT (j) are the linearized texts of entities i and j's neighbor triples. The function f(,) calculates the relevance, and $\u03c6$ denotes the parameters of the PLM. In the end, we can obtain the reordered list V of candidate entities based on semantic textual similarity. For linearization, we use a straightforward text template that summarizes relevant knowledge, focusing on the entity. For instance, the entity \"Football League One\" can be represented through linearized text based on its neighbor triples: \"Football League One, which relegation is Football League Championship, promotion is Football League Championship, promotion is Football League Two, relegation is Football League Two, league is Sheffield United F.C..\".\nIn addressing the correction of the (i, j) entity pair, our empirical findings indicate that the reranking strategy, as applied to entities aligned with i \u2208 Gs (Equation (13)), falls short of fully harnessing the ranking knowledge associated with entities aligned to je G\u0442. To overcome this limitation, we adopt a cross-verification strategy. This approach entails acquiring the ranked list for entity j\u0454 G\u0442 (Equation (14)) and selectively replacing alignment outcomes only when the conditions j == Vr (i)1 and i == Vs(j)1 are satisfied. For an in-depth exploration of this strategy, we provide detailed analyses in the supplementary material."}, {"title": "5 EXPERIMENTS", "content": "In our experiments, we use five public datasets, which have been extensively used in previous works [21, 22, 36]: DBP15KZH-EN, DBP15KJA-EN, and DBP15KFR-EN [27] are the three cross-lingual subsets from multi-lingual DBpedia. SRPRSEN-FR and SRPRSEN-DE [11] cover much sparse KGs. The statistics of the datasets are provided in Table 1.\nOur main aim is to demonstrate how ERALIGN effectively use semantic information for triple-level matching, and improves the base method (SEU), instead of solely pursuing state-of-the-art performance. We precisely select baseline methods to ensure a fair comparison in terms of the entity information employed, considering previous findings [7] highlighting the advantages of incorporating additional side information about entities. While ERALIGN mainly leverages entity names for semantic information, other recent researches [13, 29, 30] integrate attributes and other features to enhance entity features. We categorize them according to their feature encoding strategies.\nThe first category only captures local structure information (i.e., triples) of each entity into the embedding.\n\u2022 MTransE [6]: A translation-based method, which offers cross-lingual embedding translation by using axis calibration, translation vectors, and linear transformations.\n\u2022 GCN-Align [33]: A GNN-based method, which generates neighbor-aware entity embeddings via Graph Convolution Networks (GCN) trained with the equivalent entity pairs.\n\u2022 BootEA [28]: A bootstrapping approach that iteratively collects likely aligned entity labels and uses them as training data for learning alignment-oriented KG embeddings.\nThe second category leverages semantic textual information of entities, along with their structure information within KGs.\n\u2022 JEANS [4]: A joint embedding approach that learns both multilingual KG embeddings and language models, for leveraging incidental supervision signals from text corpora.\n\u2022 GM-Align [38]: A cross-lingual EA method based on graph matching networks, which compute the similarity between local graphs constructed using 1-hop neighbors.\n\u2022 HGCN [36]: A cross-lingual EA method that jointly learns representations of entities and relations based on a GCN with an added highway mechanism.\n\u2022 Dual-AMN [21]: Graph matching networks that model both intra-graph and cross-graph information with reduced computational complexity for efficient computation.\n\u2022 SEU [22]: An unsupervised and parameter-free method that solves the cross-lingual EA problem as an OT problem by utilizing the Sinkhorn algorithm [8].\n\u2022 LightEA [23]: Non-neural EA framework that utilizes Three-view Label Propagation mechanism for Label Propagation. Also they used Random Orthogonal Label Generation and Sparse Sinkhorn Iteration for reducing computational complexity and enhance the scalability.\nThe last category includes ERALIGN leveraging textual features pertaining to entities and relations. We build two variants as follows.\n\u2022 ERALIGN: Our proposed framework that jointly refines the entity and relation alignment based on neighbor entity matching in an iterative manner.\n\u2022 ERALIGN++: A variant of ERALIGN with the Align-and-Verify pipeline, where its verification step additionally detects and corrects erroneously aligned entity pairs.\nNote that most of the baseline methods rely on a given set of aligned entity pairs (i.e., seed alignments) for supervised learning of embeddings or GNN parameters; typically, these methods employ a random partitioning strategy, splitting all entity pairs into 30% for training (and development) and 70% for testing. On the contrary, SEU, LightEA and ERALIGN are parameter-free unsupervised framework, using all entity pairs are utilized for testing. For the baselines, we opt to exclude consideration of multi-modal EA methods that incorporate visual or temporal information within KGs [7, 16, 17]."}, {"title": "Experimental settings.", "content": "To encode entity/relation texts, we utilize Sentence BERT (SBert)5 for semantic features and character-level bigram (Bigram) for lexical features. In the iterative refinement process (Section 4.3), we maintain fixed hyperparameters with \u03bb = 0.5 and N = 2. For erroneous alignment detection (Section 4.4.1), we manually configure the thresholds @conf and cons to ensure that 20% of source entities undergo additional verification. 6 For the correction of erroneous alignments (Section 4.4.2), we used sentence transformer as verifier and consider K = 20 candidate entities to be reranked. Comprehensive analyses of these hyperparameters are presented in Section 5.2.6."}, {"title": "5.2 Experimental Results", "content": "For comprehensive comparisons against other baseline methods, we evaluate the performance of both ERALIGN and ERALIGN++ in the cross-lingual EA task. As shown in Table 2, both ERALIGN and ERALIGN++ achieve the highest accuracy in most datasets without relying on human-curated aligned entity pairs or learnable parameters. Overall, baseline methods utilizing only structural features perform worse than those incorporating textual features. Supervised EA methods are likely to suffer from overfitting, as the size of training data (i.e., pre-aligned entity pairs) is small. This makes the unsupervised EA approach, SEU and LightEA, more effective with the help of their Sinkhorn, which mitigates overfitting. ERALIGN consistently outperforms the base method (SEU) in accuracy across all datasets and metrics, demonstrating the advantage of our iterative refinement based on neighbor triple matching for entity-level and relation-level alignment. Compared to LightEA, the performance improvement may not seem substantial, but ERALIGN is generally applicable and can achieve higher performance by using LightEA instead of SEU as the initialization method. This experiment is detailed in Section 5.2.3.\nThe performance improvement is particularly notable for the DBP15KZH-EN and DBP15KJA-EN datasets, which are more challenging due to their distinct language families compared to English, in contrast to French and Deutsch, which have linguistic roots in common with English. Furthermore, ERALIGN++ further increases hit@1 scores with its verification step, indicating that the semantic similarity between linearized texts of neighbor triples is a robust alignment score."}, {"title": "5.2.2 The effect of textual feature types.", "content": "We initially assess the accuracy of our dual alignment, $\\hat{X}^{ent}$ and $\\hat{X}^{rel}$ in Section 4.2, employing various textual features (or text encoding strategies), including semantic features (i.e., GloVe and SBert) and lexical features (i.e., Bigram). For the evaluation of relation alignment, we use a subset of aligned relation pairs available within KGs.\nIn Table 3, the alignment performance is heavily influenced by the quality of textual features for both entities and relations. Regarding semantic features, SBert significantly outperforms GloVe by accurately capturing the contexts of word tokens, highlighting the importance of effective semantic encoding in achieving successful alignment between KGs. Moreover, the inclusion of additional Bigram features notably enhances the accuracy of GloVe and SBert, enabling Xent and \u0176rel to encode lexical similarities between entities and relations, respectively. This proves effective in handling OOV words or phrases within entities and relations."}, {"title": "5.2.3 ERALIGn as a General Framework.", "content": "Lastly, we demonstrate that ERALIGN can serve as a general framework for robust cross-lingual EA. Note that the steps we propose for refinement (Step 2) and verification (Step 3) are entirely independent of the method used to calculate initial entity-level and relation-level alignment scores (Step 1). In this sense, we validate the effectiveness of ER-ALIGN on three unsupervised (or self-supervised) EA methods on DBP15KZH-EN: EVA [16], LightEA [23] and SEU. To retain the concept of ERALIGN, unsupervised method using textual and structural information, we tailor EVA and LightEA fit to our settings. Using 100% of labeled sets as test set, and combining SBert (as semantic features) and Bigram (as lexical features) to obtain textual embeddings. Other detail settings are consistent with original papers, respectively.\nWe apply ERALIGN on three type of initial alignment scores, EVA based, LightEA based, and SEU based. The performance of each step was illustrated in Figure 4 across various pairs of initial alignment scores with the SEU-SEU results presented in Table 2. Step 1 represents the performance of the initial alignment scores, Step 2 is the performance after the refinement step, and Step 3 is the performance of applying the verification step to the results of Step 2. The result demonstrates the effectiveness of ERALIGN, especially when the performance of initial entity-entity alignment is low, the effectiveness of ERALIGN is emphasized. This shows broad applicability of ERALIGN, emphasizing its utility even when alignment scores are derived independently of SEU."}, {"title": "5.2.4 Effect of heterogeneity between KGs.", "content": "Most EA methods assume aligned entity pairs share the same structure across source and target graphs. However, practically perfect isomorphic graphs is rare, leading to performance declines due to KG heterogeneity. To simulate non-isomorphic scenarios, we randomly dropped triples in the target graph of DBP15KZH-EN at varying rates (0%, 25%, 50%, and 75%). Table 4 shows that in highly non-isomorphic scenarios, both Step 1 (Initialization) and Step 2 (Refinement) can introduce noise. We analysis that this occurs because these steps assume that aligned entity pairs have identical representations, including both structure and text. However, due to the high drop ratio, substantial non-isomorphism exists between the KGs. At a 75% drop ratio, Step 2 even degraded the performance achieved by Step 1. However, Step 3 (Verification) can mitigate such detrimental effects. We found that semantic contexts in neighbor triples are similar even when the KGs are non-isomorphic. Thus, the semantic similarities of verbalized neighbor triples further enhance performance in highly non-isomorphic situations, as demonstrated in Table 4."}, {"title": "5.2.5 Robustness to noisy textual features.", "content": "To demonstrate the robustness of ERALIGN and ERALIGN++, we assess their alignment accuracy under artificially injected textual noises in entities and relations with noise levels from 0% to 20%. We conduct experiments by simulating various types of textual noise: phonetic errors, missing characters, and attached characters. In Figure 5, ERALIGN shows lower sensitivity to textual noises compared to SEU, attributed to our iterative refinement step that enhancing noise tolerance through the relation-level alignment fusion. The incorporation of lexical features consistently improves accuracy by capturing lexical similarities among entities and relations. Notably, the verification step enhances robustness in both ERALIGN++ and SEU++, effectively correcting erroneous alignments through semantic similarity in linearized neighbor triples. Furthermore, the effectiveness of our verification step becomes particularly pronounced as the noise level increases, strongly indicating that the additional verification substantially enhances alignment accuracy in the presence of textual noise."}, {"title": "5.2.6 Hyperparameter analysis.", "content": "We investigate the impact of various hyperparameters on the performance of ERALIGN, on the DBP15KZH-EN and DBP15KJA-EN datasets. These hyperparameters include the weight assigned to the previous alignment (\u03bb), the number of refinement iterations (N), and the number of candidate entities considered during verification of each detected erroneously aligned pairs (K). Figure 6 shows ERALIGN maintains consistent performance within the A range of [0.3, 0.9]. Regarding the number of iterations, optimal performance is achieved at N = 2 for both datasets. We also find that the optimal value for K falls within the range of 10 to 20; this suggests that a small K may fail to include the correct entity in the candidate set, while a large K introduces noisy candidates, compromising the efficacy of our correction process."}, {"title": "5.2.7 Ablation study.", "content": "To evaluate the efficacy of individual components in ERALIGN and ERALIGN++, we conducted ablation analyses on the cross-lingual EA task, demonstrating that these components contribute to accurate alignment. We tested variants of ERALIGN: (1) using GloVe [25] instead of SBert features and (2) using SBert without Bigram features, compared to SEU, which adopted GloVe and Bigram. For ERALIGN++, we altered metrics for erroneous alignment detection to exclude (3) confidence and (4) consistency, and modifying the misalignment correction steps to (5) skip sorting neighbor triples during linearization and (6) use an NLI fine-tuned language model instead of STS. Table 6 shows the importance of semantic and lexical features for ERALIGN. For ERALIGN++, confidence and consistency metrics are crucial for robust verification, reducing false positives (i.e., correctly aligned pairs). Additionally, the sorting strategy for triple linearization and the STS pretext task for the PLM are crucial for accurate alignment errors correction."}, {"title": "5.2.8 Case study on erroneous alignment correction.", "content": "We provide a specific example of our alignment correction process. In Table 5, we show an instance where ERALIGN++ correctly rectifies entity pairs in DBP15KZH-EN. Each entity (and relation) name is annotated with its translation into English from its original language. ERALIGN++ successfully identifies that the target entity \"Gan Chinese\u201d (\u2192 \"Gan Chinese\") is most relevant to the source entity\u201c\u8d63\u8bed\u201d (\u2192 \"Gan language\"). This demonstrates that a direct examination of neighbor triple sets, guided by semantic textual similarity, can effectively rectify erroneously aligned entity pairs."}, {"title": "6 CONCLUSION", "content": "This paper introduces ERALIGN, a novel unsupervised cross-lingual EA framework that effectively leverages semantic textual features for both entities and relations. ERALIGN's robust alignment process involves three key steps: (1) obtaining representations of entities and relations using both original and dual KGs, (2) iteratively refining by fusing entity-level and relation-level alignment based on neighbor triple matching, and (3) verifying erroneous alignments by examining entities' neighbor triples as linearized texts. Employing a parameter-free unsupervised approach, ERALIGN outperforms existing methods by accurately aligning entities without manual entity pairs or learnable parameters.\nOur experiments, conducted across various datasets, demonstrate ERALIGN's superior performance and robustness to noisy textual features. We show the effectiveness of ERALIGN in non-isomorphic scenarios, contrasting with methods assuming isomorphism. The Align-and-Verify pipeline of ERALIGN has general applicability and consistently enhance the performance of base method. These analyses confirmed that combining semantic and lexical features, along with the iterative refinement and verification steps, is crucial for achieving high accuracy in cross-lingual EA tasks."}]}