{"title": "Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation", "authors": ["Yiwei Li", "Ji Zhang", "Shaoxiong Feng", "Peiwen Yuan", "Xinglin Wang", "Jiayi Shi", "Yueqi Zhang", "Chuyi Tan", "Boyuan Pan", "Yao Hu", "Kan Li"], "abstract": "Self-consistency improves reasoning by aggregating diverse stochastic samples, yet the dynamics behind its efficacy remain underexplored. We reframe self-consistency as a dynamic distributional alignment problem, revealing that decoding temperature not only governs sampling randomness but also actively shapes the latent answer distribution. Given that high temperatures require prohibitively large sample sizes to stabilize, while low temperatures risk amplifying biases, we propose a confidence-driven mechanism that dynamically calibrates temperature: sharpening the sampling distribution under uncertainty to align with high-probability modes, and promoting exploration when confidence is high. Experiments on mathematical reasoning tasks show this approach outperforms fixed-diversity baselines under limited samples, improving both average and best-case performance across varying initial temperatures without additional data or modules. This establishes self-consistency as a synchronization challenge between sampling dynamics and evolving answer distributions.", "sections": [{"title": "1 Introduction", "content": "Self-consistency (Wei et al., 2022) is a well-established decoding method that enhances model performance by aggregating multiple stochastic samples via majority voting. It has been demonstrated to be highly effective across a variety of tasks (Chen et al., 2023; Wang et al., 2024b), particularly in improving reasoning abilities (Wei et al., 2022). Despite its empirical success, the underlying mechanisms behind self-consistency remain underexplored. In this work, we revisit self-consistency from a distributional perspective, reframing it as a dynamic alignment problem, to achieve more robust and effective performance in answer aggregation."}, {"title": "2 Fundamental Analysis of Self-Consistency", "content": "In this section, we first present a distribution alignment perspective on how self-consistency works with specific true answer distributions, supported by experimental evidence to substantiate this viewpoint. Building upon this foundation, we proceed to provide both a formal definition of self-consistency convergence and practical criteria for assessment."}, {"title": "2.1 Why Self-Consistency Works: A Distributional Perspective", "content": "Self-Consistency is a widely-used decoding method for improving reasoning performance by aggregating multiple stochastic samples. By applying a majority voting scheme, it mitigates issues such as local optima and high variance that arise from relying on a single sample. Formally, it can be expressed as:\n\n\u0177_{sc} = arg max_y \\sum_{i=1}^n \\mathbb{I}(y_i = y) \\tag{1}\n\nwhere \\(y_i\\) is the i-th sampled answer, and \\(\\mathbb{I}(y_i = y)\\) is the indicator function that equals 1 if \\(y_i\\) matches the candidate answer y, and 0 otherwise. The result, \\(\\hat{y}_{sc}\\), is the answer with the highest number of votes (the top-1 answer).\nFrom a probabilistic perspective, self-consistency can be seen as a Monte Carlo estimator of the true answer distribution p(y | x). As the number of samples increases, the empirical distribution formed by the samples approximates the true distribution, and the most frequent answer aligns with the true distribution:\np_{sc}(y) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(Y_i = y) \\rightarrow p(y | x), \\text{ as } n \\rightarrow \\infty \\tag{2}\nAs the number of samples increases, the estimation becomes more reliable, and the voting mechanism converges towards the true answer."}, {"title": "2.2 Convergence Analysis of Answer Aggregation", "content": "According to Insights 1, since the accuracy of the true distribution is fixed, the performance of self-consistency is guaranteed to converge. To further investigate it, we provide the following definition according to the Cauchy convergence criterion:\nDefinition 2.1. Let \\(f^{M}(i) = \\sum_{i=1}^{M} \\mathbb{I}(Y_i = i)\\), where \\(\\hat{Y}_i\\) represents the set of answers generated by the model, and M is the number of samples. For any given \\(\\epsilon > 0\\), there exists a positive integer L such that for N, M > L, if the following holds:\n\n|argmax f^{M}(i) - argmax f^{N}(i)| < \\epsilon \\tag{3}\n\nwe can conclude that self-consistency has converged.\nBased on Definition 2.1, we prove that self-consistency also converges in terms of the accuracy on the dataset:\nTheorem 2.2. Let \\(\\underset{j \\in D}{Acc} = \\frac{1}{D} \\sum_{j \\in D} [argmax_{i} f_{j}^{M}(i) = gt_j]\\) denote the accuracy of self-consistency when a single question is sampled M times on dataset D, where \\(gt_j\\) represents the correct answer to the j-th question. If Definition 1 holds, then for any given \\(\\epsilon > 0\\), there exists a positive integer L such that when N, M > L, the following holds:\n\n| Acc_D^M - Acc_D^N | < \\epsilon \\tag{4}\n\nThe Proof of Theorem 2.2 is in Appendix A. By setting \\(\\epsilon\\) to \\(\\frac{1}{D}\\), the following definition is established:\nDefinition 2.3. If the following holds on dataset D:\n| Acc_D^M - Acc_D^{M/5} | < \\frac{1}{D} \\tag{5}\nwe can consider self-consistency to have converged at a sample size of M."}, {"title": "3 Diversity Trade-offs for Self-Consistency", "content": "3.1 Sampling Diversity Affection\nAccording to Insight 2, to gain a deeper understanding of the impact of diversity on self-consistency, we investigate how accuracy varies with temperature changes in increments of 0.1. The study is divided into two parts: convergence analysis and finite-sample analysis.\nConverge Condition Figure 4 indicates Findings 5: As the temperature increases, the accuracy of single samples exhibits a declining trend, while the accuracy of self-consistency after convergence shows an increasing trend (the optimal point is often near 1.01). Please refer to Appendix B for more results. The disagreement resolution theorem in ensemble learning provides a potential explanation, suggesting that the overall performance of an ensemble is determined by the trade-off between the accuracy of individual models and the diversity among them. From this trend and Insights 1, we gain Insights 3: When the sample size is sufficient, the temperature should be increased to better explore the true distribution with higher accuracy.\nFinite-Sample Condition Figure 5 indicates Findings 6: When the sample size is limited, the optimal temperature gradually shifts toward lower values as the sample size decreases. Please refer"}, {"title": "3.2 Chain-of-thought Affection", "content": "Besides the sampling diversity decided by temperature, Chain-of-Thought (Wei et al., 2022) is also a key factor. From Figure 6 we can get Findings 7: Using CoT prompt leads to higher confidence compared to not using it. A deeper Insight 6 emerges: Chain-of-thought (CoT) reasoning narrows the output space and reduces diversity, thereby increasing answer confidence. However, investigating this phenomenon is not the focus of this paper, and we leave it for future work."}, {"title": "4 From Static to Adaptive: Confidence-Driven Optimization of Self-Consistency Distributions", "content": "4.1 Motivation\nTraditional self-consistency methods rely on static sampling strategies with fixed sample sizes and temperatures, which face limitations: When the confidence of the sampling distribution is too low, a limited sample size struggles to accurately capture the true top-1 answer, restricting the performance gains of self-consistency (Insight 4). Conversely, when the confidence is too high, the model fails to explore potentially better distributions at higher temperatures (Insight 3). Our method addresses these issues through adaptive confidence-distribution alignment (Insight 5). By dynamically adjusting the sampling distribution's diversity based on real-time confidence levels, we optimize alignment by proactively adapting to the evolving gap between model confidence and true distribution uncertainty. This dynamic mechanism enables efficient convergence to the correct answer even under limited sample sizes while facilitating exploration of better true distributions when needed. Through this approach, we enhance both the accuracy and robustness of self-consistency across diverse conditions.\n4.2 Diversity Control Strategy\nDynamic Temperature Adjustment We introduce a confidence-driven diversity optimization mechanism to dynamically align the sampling distribution with the latent answer distribution. First-Second Distance (FSD) (Lyu et al., 2024) is employed as the confidence metric to quantify the gap between top candidates. Formally, at decoding step t:\nFSD(t) = p_1(t) - p_2(t) \\tag{6}\nwhere \\(p_1(t)\\) and \\(p_2(t)\\) are the probabilities of the top two answers from the first t samples. This metric directly reflects the model's uncertainty in distinguishing between the dominant candidates.\nTo ensure stable optimization, we design a conservative adjustment rule with a dead zone around confidence threshold \\(\\tau\\). The temperature T is updated based on the FSD metric:\nT^{(t+1)} = \\begin{cases} T^{(t)} - 0.1 & \\text{if } FSD^{(t)} < \\tau - \\epsilon, \\\\ T^{(t)} + 0.1 & \\text{if } FSD^{(t)} > \\tau + \\epsilon, \\tag{7} \\\\ T^{(t)} & \\text{otherwise,} \\end{cases}\nwhere \\(\\epsilon\\) is a stability margin, which we set to 0.05 for simplicity. Temperature T is clamped to [0.1, 1.0] to avoid extreme values.\nPhased Sampling Strategy To balance exploration and efficiency, we employ a three-phase sampling protocol:\n\\bullet Exploration Phase: Collect small number of samples (n\u2081 = 5) with preset \\(T^{(1)}\\) as a window to estimate initial \\(FSD^{(1)}\\).\n\\bullet Adaptive Phase: Adjust \\(T^{(2)}\\) through Equation 7, then generate n2 = 0.5N \u2212 \u03b71 (N: total budget) additional samples.\n\\bullet Exploitation Phase: Finalize \\(T^{(3)}\\) and generate the remaining n3 = 0.5N samples.\nThe phased approach progressively shifts from broad exploration to focused exploitation. Finally, the accuracy is calculated by majority voting from the total of N samples.\nIn summary, our method dynamically adjusts the sampling diversity by monitoring the confidence levels, allowing for more efficient exploration and convergence. This adaptive mechanism ensures better alignment with the true answer distribution under sampling constraints to improve accuracy.\n4.3 Theoretical Analysis\nTo ensure a rational and effective selection of the FSD threshold \\(\\tau\\), we construct a one-sided z-test for analysis. The test employs the null hypothesis as follows:\nH0: The current sampled top-1 answer is not the true answer for the given question under infinite sampling.\nTo simplify this problem, we assume that only the current top-2 answer could potentially become the true answer under infinite sampling. Consequently, it is natural to focus on the relationship between FSD and confidence. Therefore, this hypothesis can be described as:\nz = \\frac{d - d_{\\mu}}{SE} \\tag{8}"}, {"title": "5 Experiments", "content": "5.1 Experiment Setup\nDatasets and Models We evaluate our method on two widely-used mathematical reasoning benchmarks: GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021). Experiments span multiple model families to assess generalizability, including Qwen (Yang et al., 2024), Llama (Dubey et al., 2024), Mistral(Jiang et al., 2023), DeepSeek(Shao et al., 2024), Gemma(Rivi\u00e8re et al., 2024) and Phi(Li et al., 2023b).\nImplementation Details To systematically compare dynamic versus static temperature strategies, we test initial temperatures To \u2208 {0.1, 0.2, ..., 1.0} with sampling budgets N \u2208 {10, 20, 40}."}, {"title": "5.2 Results", "content": "From the results presented in Table 1 through 15 models, we can find:\nDynamic temperature sampling mitigates the performance degradation associated with fixed-temperature sampling. We find that the average accuracy across different temperatures for dynamic temperature sampling outperforms fixed-temperature sampling in the majority of models. This suggests that our method is not constrained by the temperature range and can identify samples that are more effective for self-consistency performance across various temperatures. To some extent, this approach mitigates the performance loss caused by ineffective sampling at a single fixed temperature.\nFor different samples, dynamic temperature sampling searches for a more suitable temperature for each sample. Similarly, we observe that dynamic temperature sampling also provides a certain improvement in terms of the maximum accuracy. This can be attributed to the fact that different samples require different temperature ranges. Fixed-temperature sampling can only achieve the desired accuracy for the dataset as a whole, whereas dynamic temperature sampling automatically searches for a more optimal temperature for each individual sample, maximizing the performance of self-consistency optimization across various temperatures."}, {"title": "5.3 Analysis", "content": "Visualization We provide a detailed analysis of the model's accuracy at different temperatures. Figure 7 presents the accuracy and temperature curve for the Qwen2.5-Math-7B model. We observe that, with sampling sizes of 20 and 40, both low temperature ranges (0.1-0.4) and high temperature ranges (0.7-1.0) exhibit notable improvements. This suggests that dynamic temperature sampling yields more robust results. However, with a sampling size of 10, the performance in the low temperature range is almost identical to that of fixed-temperature sampling, primarily due to the constraints of the sample size. In the more optimal temperature range (0.4-0.7), the performance of dynamic and fixed-temperature sampling is similar, which aligns with our expectations and indicates that the intermediate temperature has already achieved a balanced trade-off."}, {"title": "Direction Analysis of Temperature Variation", "content": "Taking the sample level into account, we first analyzed the proportions of samples that experienced temperature increases, decreases, or remained constant throughout the dynamic temperature sampling process, as illustrated in Figure 8. We observed that in the low temperature range, at least 80% of the samples experienced an increase in temperature. This observation is consistent with our hypothesis derived from dataset-level considerations, which suggests that increasing the temperature tends to result in higher expected accuracies. As the temperature rises, the proportion of samples experiencing temperature increases gradually declines, indicating that for some samples at the current sampling size, excessive temperatures are insufficient to confidently select the correct answer. Consequently, lowering the temperature becomes necessary to enhance FSD. Additionally, we noticed that with higher sampling sizes, the proportion of samples"}, {"title": "Proportion of Optimal Temperature Range", "content": "We analyze the proportion of FSD instances that ultimately reach the dead zone. We consider reaching the dead zone as an indication that the sample operates within an optimal temperature range. As shown in Figure 9, dynamic temperature sampling results in a higher proportion of FSD instances entering the dead zone compared to fixed-temperature sampling, suggesting that our method enables better alignment for a larger number of samples."}, {"title": "6 Related Work", "content": "Self-Consistency Self-consistency (Wang et al., 2023), also known as majority voting, is a significant method for effectively enhancing the reasoning performance of large language models (LLMs) within the context of chain-of-thought (Wei et al., 2022) settings. Research on this method primarily focuses on two aspects: First, the effectiveness of self consistency is further improved through weighted majority voting (Li et al., 2023a, 2024b) or input diversity (Sathe et al., 2024). Addition-"}, {"title": "7 Conclusion", "content": "This work revisits self-consistency through the lens of dynamic distributional alignment, challenging the conventional view of passive convergence to a fixed answer distribution. We demonstrate that decoding temperature critically shapes both sampling behavior and the latent answer distribution itself, revealing a trade-off between diversity-driven exploration and finite-sample convergence. By introducing a confidence-aware mechanism that dynamically adjusts temperature based on real-time alignment with the distribution, we bridge this gap, enabling efficient synchronization between sampling dynamics and evolving answer distributions. Empirical results validate that this approach outperforms static strategies, achieving robust performance improvements without external resources. Our findings position self-consistency as an active alignment challenge, opening avenues for adaptive aggregation frameworks in reasoning tasks."}, {"title": "Limitations", "content": "While our approach advances the understanding and application of self-consistency, several limitations remain:\n\\bullet Task Scope: Experiments focus on mathematical reasoning tasks, thus generalization to broader domains (e.g., open-ended generation or multi-step decision-making) requires further validation.\n\\bullet Optimal Temperature: The specific value of the optimal temperature when the sample size approaches infinity, and how it varies with factors such as the model and dataset, remains unexplored.\n\\bullet Decoding Strategy Interactions: The interplay between temperature modulation and other decoding techniques (e.g., top-k or top-p sampling) remains unexplored, potentially affecting broader applicability."}, {"title": "Ethics Statement", "content": "All of the datasets used in this study were publicly available, and no annotators were employed for our data collection. We confirm that the datasets we used did not contain any harmful content and was consistent with their intended use (research). We have cited the datasets and relevant works used in this study."}, {"title": "A Proof of Theorem 2.2", "content": "Proof A.1. Firstly, we need to introduce true labels into Definition 2.1. As we are not concerned with the specific numerical values of the predicted and true answers, we map the set of predicted answers onto a sequence of natural numbers (in simple terms, we only need to know which of the i-th answers is the correct one). Consequently, we can establish the following partial order relation:\n\\left| argmax f^{M}(i) - argmax f^{N}(i) \\right|\ni\\newline = \\left| \\mathbb{I}[argmax f^{M}(i) = gt_j] \\right.\\\\\n-\\left| \\mathbb{I}[argmax f^{N}(i) = gt_j] \\right|\n\\geq \\left| \\mathbb{I}[argmax f^{M}(i) = gt_j] \\right|\n-\\left|\\mathbb{I}[argmax f^{N}(i) = gt_j] \\right| \\tag{15}\nBased on Definition 2.1, we have:\n\\left| \\mathbb{I}[argmax f^{M}(i) = gt_j] -  \\mathbb{I}[argmax f^{N}(i) = gt_j] \\right| < \\epsilon \\tag{16}\nNext, we introduce the dataset D into Equation 16:\n\\frac{1}{D} \\sum_{j \\in D} \\left| \\mathbb{I}[argmax f^{M}(i) = gt_j] - \\mathbb{I}[argmax f^{N}(i) = gt_j] \\right| < \\epsilon \\tag{17}\nAccording to \\(|a + b| < |a| + |b|\\), we have:\n\\frac{1}{D} \\sum_{j \\in D} \\left| \\mathbb{I}[argmax f^{M}(i) = gt_j] -  \\mathbb{I}[argmax f^{N}(i) = gt_j] \\right| < \\epsilon \\tag{18}\nFinally, we can derive Theorem 2.2:\n\\left| Acc^M - Acc^N \\right| < \\epsilon \\tag{19}"}, {"title": "B Additional Results of Section 3", "content": ""}]}