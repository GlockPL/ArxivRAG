{"title": "How Do Large Language Monkeys Get Their Power (Laws)?", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "John Hughes", "Jordan Juravsky", "Sara Price", "Aengus Lynch", "Erik Jones", "Robert Kirk", "Azalia Mirhoseini", "Sanmi Koyejo"], "abstract": "Recent research across mathematical problem solving, proof assistant programming and multimodal jailbreaking documents a striking finding: when (multimodal) language model tackle a suite of tasks with multiple attempts per task \u2013 succeeding if any attempt is correct \u2013 then the negative log of the average success rate scales a power law in the number of attempts. In this work, we identify an apparent puzzle: a simple mathematical calculation predicts that on each problem, the failure rate should fall exponentially with the number of attempts. We confirm this prediction empirically, raising a question: from where does aggregate polynomial scaling emerge? We then answer this question by demonstrating per-problem exponential scaling can be made consistent with aggregate polynomial scaling if the distribution of single-attempt success probabilities is heavy tailed such that a small fraction of tasks with extremely low success probabilities collectively warp the aggregate success trend into a power law - even as each problem scales exponentially on its own. We further demonstrate that this distributional perspective explains previously observed deviations from power law scaling, and provides a simple method for forecasting the power law exponent with an order of magnitude lower relative error, or equivalently, ~2 - 4 orders of magnitude less inference compute. Overall, our work contributes to a better understanding of how neural language model performance improves with scaling inference compute and the development of scaling-predictable evaluations of (multimodal) language models.", "sections": [{"title": "1. Introduction", "content": "Scaling behaviors of large neural language models have surprised and fascinated engineers, scientists and society alike (Hestness et al., 2017; Kaplan et al., 2020; Brown et al., 2020a; Hoffmann et al., 2022; Ganguli et al., 2022; Sorscher et al., 2022; Wei et al., 2022b; Schaeffer et al., 2023; OpenAI et al., 2024), shaping engineering, economic and governmental interests in frontier AI systems (Bommasani et al., 2021; Eloundou et al., 2023; Anderljung et al., 2023; Wang et al., 2023; Reuel et al., 2024; Besiroglu et al., 2024a; Maslej et al., 2024). For a more thorough exposition of relevant literature, please see Related Work (Section 6).\nOne direction of renewed interest is inference-time compute scaling, whereby compute is controllably increased at infer-"}, {"title": "2. Should Power Law Scaling Be Expected?", "content": "Should we expect large language monkeys to have such power (laws)? That is, should the negative log of the average success rate scale polynomially with the number of independent attempts k? As we now explain mathematically and demonstrate empirically, such polynomial scaling with k is perhaps surprising because, for any single problem, the negative log success rate at k should fall exponentially with k; the intuition is that $pass_i@k$ is 1 unless all attempts fail, and since attempts are independent, the probability that all fail is exponentially unlikely with the number of attempts."}, {"title": "3. Distribution of Per-Problem Single-Attempt Success Rates Creates Power Law Scaling", "content": "How does polynomial scaling of the negative log average success rate emerge from exponential scaling of the negative log per-problem success rate? The answer to this question must lie in the distribution D over benchmark problems of single attempt (i.e., k = 1) success rates because this distribution's density $P_D(pass_i@1)$ links the per-problem scaling behavior to the aggregate scaling behavior via the definition of the aggregate success rate $passp@k$:\n$pass@k \\stackrel{\\text{def}}{=} E_{pass_i @ 1 \\sim D} [pass_i @ k (pass_i @ 1)]$\n$= 1-(\\int E [(1-pass_i @ 1)^k] P_D(pass_i@1) dpass_i @1$.\nBased on a known result that power laws can originate from an appropriately weighted sum of exponential functions (Appendix E.1), we begin by considering simple distributions for the single-attempt success probabilities and asking which yield power law scaling between $- \\log(passp@k)$ and k, as well as what properties of the distributions set the scaling exponent. In Appendices E.3-E.8, we derive that several simple distributions yield power law scaling with different exponents whereas others do not:\n$- \\log pass_{Uniform(0, \\beta \\leq 1)} @k  \\propto  k^{-1}$.\n$- \\log (pass_{Beta(a, \\beta)} @k  \\propto  k^{-a}$.\n$- \\log (pass_{Kumaraswamy(\\alpha, \\beta)} @k \\propto k^{-a}$.\n$- \\log (pass_{ContinuousBernoulli(<1/2)} @k \\propto k^{-1}$.\n$\\log(\\frac{1}{E}) (pass_{Reciprocal(0<a<\\beta<1)} @k  \\propto  (1-a) k$\nTo test this understanding, we examined whether the data of Brown et al. (2024) and Hughes et al. (2024) had per-problem single-attempt success rate distributions that matched one of these simple distributions (Fig. 4). We found that the distributions could indeed be well fit by a 3-parameter Kuamraswamy $(\\alpha, \\beta, \\alpha = 0,c)$ distribution with scale parameter c (Fig. 4, black dashed lines); we found the scale parameter was critical to obtain good fits because the standard 2-parameter Kumaraswamy distribution is supported on (0, 1) whereas most single-attempt success distributions have a smaller maximum such as 0.01 or 0.1.\nMore generally, what are the distributional properties that create such power law scaling and that set the specific power law exponent? As we now show, the negative log average success rate will exhibit power law scaling in k with exponent b if and only if the distribution over problems of single-attempt success probabilities itself behaves like a"}, {"title": "4. Lack of Distributional Structure Explains Deviations from Power Law Scaling", "content": "Notably, previous papers observed that not every model exhibits power law scaling in every setting. To highlight one, Hughes et al. (2024) observed that when jailbreaking Meta's"}, {"title": "5. A New Distributional Estimator for Predicting Power Law Scaling", "content": "A natural consequence of this connection between the scaling of - log(passp@k) and the left tail of the distribution $P_D (pass_i@1)$ is that the distribution of single-attempt success rates can be used to predict whether power-law scaling will appear and if so, what the intercept and exponent of the power law will be. To do this, one can fit the distribution $P_D (pass_i@1)$ and then simulate how passp@k will scale with k (Fig. 5) using the relationship:\n$passd@k \\stackrel{\\text{def}}{=} E_{pass_i@1}[1- (1-pass_i@1)^k P_D (pass_i@1) d pass_i @1]$.\nTo empirically test this claim, we compared the standard least squares regression estimator (in log-log space) (Hoffmann et al., 2022; Caballero et al., 2022; Besiroglu et al., 2024b) against a distributional estimator. To motivate our distributional estimator, we first need explain a key obstacle and how the distributional estimator overcomes it. The obstacle is that there are problems or prompts whose single-attempt success probabilities $pass_i@1$ lie between (0, 1/Number of Samples) such that, due to finite sampling, we lack the resolution to measure. While we do not know the true single-attempt success probability for the problems that lie in this interval, we do know how many problems fall into this left tail bucket, and we can fit a distribution's parameters such that the distribution's probability mass in the interval (0, 1/Number of Samples) matches the empirical fraction of problems in this tail bucket. Thus, our distributional estimator works by first selecting a distribution (e.g., a scaled 3-parameter Beta distribution), discretizing the distribution according to the sampling resolution 1/Number of Samples and performing maximum likelihood estimation under the discretized distribution's probability mass function.\nWe tested this distributional estimator in two different ways. First, focusing on Large Language Monkeys, we used all available real data from all problems and all samples per"}, {"title": "7. Discussion and Future Directions", "content": "This work advances our mathematical understanding of how and why language model performance improves with additional inference compute through repeat sampling. By establishing rigorous theoretical foundations for these empirically-observed power laws, our work provides practitioners with principled ways to understand and predict model performance when scaling inference compute. The distributional perspective we develop explains previously puzzling deviations from power law scaling and enables more efficient estimation of scaling parameters.\nTwo related questions are why such distributional structure exists in the single-attempt success rates and whether one should expect such structure to appear in future benchmarks. We conjecture there are at least two reasons: (1) benchmark design, in that benchmarks are intentionally crafted that problems have a spread of difficulty without being too easy or too hard, and (2) selection bias, in that more interesting patterns such as power law scaling are more likely to garner more interest from the research community.\nDespite focusing on scaling inference compute, our paper contributes is a new hypothesis for an open question in scaling pretraining compute: why are neural scaling laws power laws? Just as the scaling behavior of \u2013 log(passp@k) only becomes clear for large k, so too might the scaling behavior of pretraining cross entropy with pretraining compute C. Specifically, suppose the pretraining cross entropy L as a function of pretraining compute C is a sum of many functions which decay at different rates:\n$L(C) = \\Sigma_i w_i (\\frac{1}{C^{a_i}}) + A \\frac{1}{C^a} + o(\\frac{1}{C^a})$,\nwhere a is the smallest (positive) polynomial exponent and $w(\\frac{1}{C^{a}})$ represents functions that decay more slowly than any polynomial. Initially, for small C, the dominant term may be unclear, but as pretraining compute is scaled up across 8 10 orders of magnitude, the leading order term"}, {"title": "A. Clarification of How Large Language Monkeys and Best-of-N Jailbreaking Sampled Data", "content": "In this manuscript, we used the phrasing of \"independent attempts,\" which is not fully correct. In this appendix section, we clarify why we chose this terminology, what likely impacts we believe this inaccuracy may have had on our results, and how to correct the paper accordingly.\nLarge Language Monkeys (Brown et al., 2024) indeed drew 10,000 independent attempts per problem, but Best-of-N Jailbreaking (Hughes et al., 2024) sampled data slightly different: for each problem, jailbreaking attempts were drawn until either a successful jailbreak was obtained or until a maximum limit of 10, 000 attempts was hit. Samples were also drawn in minibatches of size 60, making the (in)dependence of samples a bit tricky.\nWe omitted this nuance because it offers a second-order correction to our paper's main story while offering little additional insight. Neither of our theorems and none of our main text figures change. We suspect that this slightly different sampling procedure explains why, in Fig. 6, the estimated power law exponents between the least squares power law estimator and the distributional power law estimator deviate more significantly from identity for Best-of-N Jailbreaking than for Large Language Monkeys. A natural way to correct for this is to use a beta-negative binomial distribution rather than a beta-binomial distribution, with an additional correction for the maximum number of attempts. For more information, please see Appendix H."}, {"title": "B. Estimating Success Rates Using Chen et al. (2021)'s Estimator", "content": "In this manuscript, we defined $pass_i@k$ and $ASR_i@k$ as:\n$pass_i@k \\stackrel{\\text{def}}{=} E_{k \\text{ Attempts}} [[\\text{At least 1 attempt by the model solves the i-th problem}]]$\n$ASR_i@k \\stackrel{\\text{def}}{=} E_{k \\text{ Attempts}} [[\\text{At least 1 attempt jailbreaks the model on the i-th prompt}]]$\nThroughout this manuscript, to estimate $pass_i @k$ and $ASR_i @k$, we used the unbiased and lower variance estimator introduced by Chen et al. (2021): for the i-th problem, we sampled n > k attempts per problem, counted the number of successful attempts c, and then swept k to compute an estimate of $pass_i@k$ for different k values:\n$pass_i @ k = 1 - \\frac{\\binom{n-c}{k}}{\\binom{n}{k}}$.\nTwo comments: Firstly, n as used here has no relationship with the number of problems in the benchmark (Sec. 1), and secondly, our notation differs slightly from that of Chen et al. (2021), but the ideas are consistent. A numerically stable Python implementation of the estimator is provided in Fig. 8:"}, {"title": "C. Fitting Power Laws to Large Language Monkeys and Best-of-N Jailbreaking", "content": "We fit power laws to a subset of data from Large Language Monkeys (Brown et al., 2024) and from Best-of-N Jailbreaking (Hughes et al., 2024), specifically Pythia language models (Biderman et al., 2023) on the MATH benchmark (Hendrycks et al., 2021) and frontier AI models \u2013 Claude, GPT4 (OpenAI et al., 2024), Gemini (Team et al., 2024a;b) and Llama 3 (Grattafiori et al., 2024) on the HarmBench jailbreaking benchmark (Mazeika et al., 2024). We show the functional forms and the fit parameters in Table 1 and Table 2 respectively. To fit the parameters, for Large Language Monkeys, we simply minimized the squared error between the actual and predicted $- \\log(passp@k)$, and for Best-of-N Jailbreaking, we similarly minimized the squared error between the actual and predicted $- \\log(ASRD@k))$"}, {"title": "D. Mathematical Equivalence Between Coverage and Average Success Rate", "content": "Brown et al. (2024) and Hughes et al. (2024) phrase their research in terms of \"coverage\", defined as the fraction of problems that can be solved or the fraction of prompts that can jailbreak a model, but as Brown et al. (2024) comment and we here derive, the coverage is mathematically equivalent to the average $pass_i @k$ (equivalently, $ASR@k$ due to two simple probabilistic primitives: (1) linearity of expectation, (2) the expectation of an indictor random variable of some event is the probability of said event and (3) the definition of $pass_i@k$:\n$E_{\\text{Prompts} \\atop \\text{Attempts}} [Coverage] \\stackrel{\\text{def}}{=} E_{\\text{Problems} \\atop \\text{Attempts}} [Fraction \\text{ of Problems Solved After k Attempts}]$\n$= E_{\\text{Problems}} [ E_{\\text{Attempts}} [[[Problem \\text{ Solved After k Attempts}]] = pass_{problem} @ k] = pass@k$.\nIn our work, we prefer phrasing along the lines of \"success rate\" over \u201ccoverage\" because success rate avoids coverage's binary implication that each problem/prompt is either \u201csolved\" or \"not solved\"."}, {"title": "E. Aggregate Power Laws from a Probability Distribution over Exponential Functions", "content": "A known result is that power laws can emerge from appropriately weighted sums of exponential functions, e.g., (Bochud & Challet, 2006; Elkies, 2016; Bousquet et al., 2020). For a concrete example with a short proof:\n$x^{-r} = \\frac{1}{\\Gamma(r)} \\int_0^{\\infty} p^{r-1} e^{-px} dp,$\nwhere $\\Gamma(r) \\stackrel{\\text{def}}{=} \\int_0^{\\infty} s^{r-1} e^{-s} ds$ is the Gamma function. The proof is via u-substitution $u \\stackrel{\\text{def}}{=} px$:\n$\\frac{1}{\\Gamma(r)} \\int_0^{\\infty} p^{r-1} e^{-px} dp  = \\frac{1}{\\Gamma(r)} \\int_0^{\\infty} (u/x)^{r-1} e^{-u}  \\frac{du}{x} = \\frac{1}{x^r \\Gamma(r)} \\int_0^{\\infty} u^{r-1} e^{-u} du = \\frac{1}{x^r}$.\nIn our particular context, we are interested in the scaling with k of the expected success rate over problems sampled from the benchmark's data distribution:\n$pass@k \\stackrel{\\text{def}}{=} E_{pass_i @ 1 \\sim D} [pass_i @ k]$ distribution (over problems in a benchmark) of $pass_i@k$ scores that yields power law scaling with respect to the number of attempts k:\n$- \\log(\\Sigma_i (\\frac{1}{pass_i @ k}) \\approx a k^{-b}$.\nE.2. Delta Distribution: $pass_i@1 \\sim \\delta(p), p \\in (0,1)$\nTo start with a negative result, we will show that not all distributions of the per-problem success probabilities $pass_i@1$ yield aggregate power law scaling. Suppose that the model's $pass_i@1$ probabilities across the benchmarks' problems are all exactly $p\\in (0, 1)$. For brevity, let $p_i \\stackrel{\\text{def}}{=} pass_i @ 1$. Then the aggregate success rate is:\n$E_{p_i \\sim \\delta(p)} [pass_i@k]  = 1 - E_{p_i} [(1 - p_i)^k] = \\int  \\delta(p) (1 - p_i)^k dp_i = (1 - p)^k$.\nRecalling that the expansion of log(\u00b7) for small x is \u2013 log(1 - x) = x + O(x^2), in our case, we obtain:\n$- log (1 - E_{p_i \\sim \\delta(p)} [pass@k]) = (1 - p)^k + O((1 - p)^{2k}) = (1 - p)^k + o((1 - p)^k)$.\nThus, in the large k regime, we find the negative log aggregate success rate exhibits exponential scaling with k as we intuitively expect.\nE.3. Uniform Distribution: $pass_i@1 \\sim Uniform(\\alpha, \\beta)$\nSuppose $pass_i@1$ probabilities follow a uniform distribution $Uniform(\\alpha, \\beta)$ where $0<\\alpha<\\beta<1$. The aggregate success rate after k attempts is defined as:\n$pass_{Uniform(\\alpha, \\beta)} @k \\stackrel{\\text{def}}{=}  1 - E[(1 - p)^k].$"}, {"title": "E.4. 2-Parameter Beta Distribution: $pass_i@1 \\sim Beta(\\alpha, \\beta)$", "content": "Suppose that the model's $pass_i@1$ probabilities across the benchmark problems follow a Beta distribution:\n$pass_i@1 \\sim Beta(\\alpha, \\beta)$\nThe probability density function of this distribution over the support $x \\in (0, 1)$ is:\n$f(x; \\alpha, \\beta)  \\stackrel{\\text{def}}{=}  \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1} (1-x)^{\\beta-1}.$\nwhere $\\alpha > 0, \\beta > 0$ and $B(\u00b7, \u00b7)$ is the Beta function. For brevity, let $p_i \\stackrel{\\text{def}}{=} pass_i@1$. Under our assumed Beta distribution:\n$pass_{Beta(a,\\beta)}@k \\stackrel{\\text{def}}{=} 1 - E_{p_i \\sim Beta(a,\\beta)} [(1 \u2212 p_i)^k] = 1 - \\int_{0} \\frac{p^{\\alpha - 1} (1 - p)^{\\beta-1}}{B(\\alpha, \\beta)} (1 - p_i)^k dp = 1 -  \\frac{\\Gamma(\\alpha + \\beta) \\Gamma(\\beta + k)}{\\Gamma(\\alpha)\\Gamma(\\beta) \\Gamma(\\alpha + \\beta + k)}$\nwhere $\\Gamma(\u00b7)$ is again the Gamma function. The $\\Gamma(\\alpha)$ terms cancel, and a standard asymptotic result of the gamma function for large k tells us that:\n$\\frac{\\Gamma(\\beta + k)}{\\Gamma(\\alpha + \\beta + k)} \\sim  k^{-\\alpha}$,\nand thus:\n$\\frac{\\Gamma(\\alpha + \\beta) \\Gamma(\\beta + k)}{\\Gamma(\\beta) \\Gamma(\\alpha + \\beta + k)} \\sim \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)}  k^{-\\alpha}$.\nRecalling again that the expansion of log(\u00b7) for small x is \u2013 log(1 - x) = x + O(x^2), in our case, we obtain:\n$-log (passp@k) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)} k^{-\\alpha} + O(k^{-2\\alpha}) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)}  k^{-\\alpha} + o(k^{-\\alpha})$.\nFrom this final result, we see that under a Beta distribution and in the large k regime, the negative log aggregate success rate exhibits polynomial (power-law) scaling with k for exponent a"}, {"title": "E.5. Kumaraswamy Distribution: pass\u00a1@1 ~ Kumaraswamy (\u03b1, \u03b2)", "content": "Next, suppose the model's $pass_i@1$ probabilities follow a Kumaraswamy distribution. The probability density function of this distribution over the support $x \\in (0, 1)$ is:\n$f(x; \\alpha, \\beta) \\stackrel{\\text{def}}{=} \\alpha \\beta x^{\\alpha-1} (1 - x^{\\alpha})^{\\beta-1}$\nAgain for brevity, let $p_i \\stackrel{\\text{def}}{=} pass_i@1$. Under our assumed Kumaraswamy distribution:\n$pass_{Kumaraswamy (a, \\beta)}@k \\stackrel{\\text{def}}{=}  1 - E_{p_i \\sim Kumaraswamy(a,\\beta)} [(1 \u2212 p_i)^k] = 1 - \\int_{0}^{1}  (1-p)^k \\alpha \\beta p^{\u03b1-1} (1 - p^{\\alpha})^{\\beta-1} dp$"}, {"title": "E.6. Continuous Bernoulli Distribution: pass\u00a1@1 ~ ContinousBernoulli(\u03bb)", "content": "Next, suppose the model's $pass_i@1$ probabilities follow a Continous Bernoulli distribution. The probability density function of this distribution over the support $x \\in [0, 1]$ is:\n$f(x; \\lambda) \\stackrel{\\text{def}}{=} C(\\lambda) x^{\\lambda \\frac{x}{\\lambda}} (1 \u2013 x)^{1-\\lambda \\frac{1-x}{1-\\lambda}}$\n$C(\\lambda) \\stackrel{\\text{def}}{=} \\begin{cases} \\frac{1}{2} & \\text{if } \\lambda = 1/2 \\\\ \\frac{1 - 2 \\lambda}{2 \\tanh^{-1}(1 - 2 \\lambda)} & \\text{otherwise} \\end{cases}$\nThe density can equivalently be rewritten in a more convenient form for our purposes:\n$f(x; \\lambda) = C(\\lambda)  x^{\\lambda \\frac{x}{\\lambda}} (1 \u2013 x)^{1-\\lambda \\frac{1-x}{1-\\lambda}} = C(\\lambda)  (1 - \\frac{x}{\\lambda})^{\\lambda}  (1 - \\frac{1-x}{1-\\lambda})^{(1-x)}$.\nBecause the individual success probability is low in our data, we shall consider the small $\\lambda < 1/2$ regime. We follow the same approach as with the Kumaraswamy distribution.\nStep 1: Write the aggregate pass rate. The aggregate pass rate is defined as:\n$pass_{ContinuousBernoulli(\\lambda)}@k \\stackrel{\\text{def}}{=} 1 - Ik,  \\text{ where } I_k = \\int_{0}^{1} (1-p)^k f (p; \\lambda) dp$"}, {"title": "E.7. Any Continuous Distribution with $\\rho(pass_i @ 1) = c>0$", "content": "Suppose that the distribution over $pass_i @ 1$ is continuous and has constant non-zero density near 0:\n$f(0) = c > 0$\nBecause the density is continuous at 0 with $f(0) = c > 0$, there exist some $\\delta > 0$ such that:\n$f(p) = c + O(p)  \\text{ for all } p \\in [0, \\delta]$"}, {"title": "H. Maximum Likelihood Estimation of Scaled Beta-Negative Binomial Distribution", "content": "To model the distribution of $pass_i@1$, we can perform maximum likelihood estimation on a scaled three-parameter Beta-Negative Binomial distribution. Recall that the scaled three parameter Beta distribution is:\n$f_P(p;\\alpha, \\beta, a=0,c)=\\frac{p^{\\alpha-1}(c-p)^{\\beta-1}}{c^{\\alpha+\\beta-1}B(\\alpha,\\beta)}.$ We want the PMF of a three-parameter Beta-Negative Binomial distribution based on this scaled Beta distribution. For r desired successes, the PMF that we first draw x failures is:\n$P(X=x;\\alpha,\\beta,c,r) = \\int_0^c {x+r-1 \\choose x} P_{NegBin}(r,p)\\frac{p^{\\alpha-1}(c-p)^{\\beta-1}}{c^{\\alpha+\\beta-1}B(\\alpha,\\beta)}dp$ where $P_{NegBin}(r,p)$ is beta distribution."}]}