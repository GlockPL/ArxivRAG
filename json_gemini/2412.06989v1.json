{"title": "Learning about algorithm auditing in five steps: scaffolding how high school youth can systematically and critically evaluate machine learning applications", "authors": ["Luis Morales-Navarro", "Yasmin B. Kafai", "Lauren Vogelstein", "Evelyn Yu", "Dana\u00eb Metaxa"], "abstract": "While there is widespread interest in supporting young people to critically evaluate machine learning-powered systems, there is little research on how we can support them in inquiring about how these systems work and what their limitations and implications may be. Outside of K-12 education, an effective strategy in evaluating black-boxed systems is algorithm auditing-a method for understanding algorithmic systems' opaque inner workings and external impacts from the outside in. In this paper, we review how expert researchers conduct algorithm audits and how end users engage in auditing practices to propose five steps that, when incorporated into learning activities, can support young people in auditing algorithms. We present a case study of a team of teenagers engaging with each step during an out-of-school workshop in which they audited peer-designed generative AI TikTok filters. We discuss the kind of scaffolds we provided to support youth in algorithm auditing and directions and challenges for integrating algorithm auditing into classroom activities. This paper contributes: (a) a conceptualization of five steps to scaffold algorithm auditing learning activities, and (b) examples of how youth engaged with each step during our pilot study.", "sections": [{"title": "Introduction", "content": "Given the growing presence of artificial intelligence (AI) and machine learning (ML) in young people's lives, it is critical to provide them with the resources they need to engage with, create, and evaluate AI/ML applications. AI education efforts have focused on developing AI/ML literacy so that young people can interact with AI/ML technologies as critical users, designers, and evaluators (Dennison et al. 2024; Long and Magerko 2020; Touretzky, Gardner-McCune, and Seehorn 2023). The lack of transparency in ML models adds an additional barrier to understanding and critically engaging with AI/ML concepts. Furthermore, existing research pays little attention to assisting youth in investigating the limitations and implications of AI/ML systems (Van Mechelen et al. 2023), focusing instead on discussing issues and providing direct instruction (Morales-Navarro and Kafai 2024), with little emphasis on how youth can empirically and critically assess system behaviors.\nIn algorithmic accountability and human-centered computing research, algorithm auditing has become an effective strategy for investigating and comprehending how AI/ML systems behave. Algorithm auditing involves \"repeatedly querying an algorithm and observing its output in order to draw conclusions about the algorithm's opaque inner workings and possible external impact\" (Metaxa et al. 2021b). The majority of algorithm audits have been conducted either by experts or adult end-users to identify potential problematic system behaviors in AI/ML-powered systems (Bandy 2021; Lam et al. 2023). More recently, this research has been expanded to examine how high school youth participate in auditing practices (Solyst et al. 2023; Morales-Navarro et al. 2024; Walker, Sherif, and Breazeal 2022). These studies are promising in demonstrating how auditing activities can assist youth in critically evaluating and understanding AI/ML systems, as well as making connections to youths' lived experiences as users and designers. However, a common challenge they present is how to scaffold activities so that auditing moves from one-off observations to more systematic evaluations.\nIn this paper, we address this issue by conceptualizing a five-step auditing process that youth can engage with in learning activities to critically evaluate AI/ML systems. We base our five steps on common auditing methods used by expert auditors (Metaxa et al. 2021b; Bandy 2021) and research on user-driven auditing practices (DeVos et al. 2022; Shen et al. 2021; Lam et al. 2023; Solyst et al. 2023). We conducted a two-week workshop with 16 youth (ages 14-15) in which they designed, tested, and audited TikTok filters. In this paper, we address the following research question: How can youth engage with each step of the auditing process while auditing peer-designed filters? We analyzed youth-created artifacts and video and screen recordings of youth engagement with each step to create a case study. We discuss the kind of scaffolds we provided to support youth in each step of algorithm auditing and directions and challenges for integrating algorithm auditing into classroom activities."}, {"title": "Background", "content": "Over the past decade, K-12 education researchers have started turning their attention to the design and study of critical computing learning activities (Ko et al. 2020). These activities often involve critical inquiry by approaching computing applications as sociotechnical systems and having learners investigate how computing systems work and what their implications are (Morales-Navarro and Kafai 2023). Within critical inquiry, deconstruction involves evaluating and reflecting on the values and intentions embedded in sociotechnical systems and considering their possible impact on people and the environment (Dindler, Smith, and Iversen 2020; Schaper et al. 2022). This entails: (1) evaluating a system's inputs, outputs, and materials (such as data); (2) researching how a system is actually used; (3) investigating the values, worldviews, and presumptions that are ingrained in the system; and (4) determining how a system may affect individual people, communities, and the environment (Dindler, Smith, and Iversen 2020). While efforts to engage learners in critical computing activities are becoming increasingly common, particularly in the case of ML education, instructional activities that address issues of justice and ethics tend to be based on discussion or direct instruction (Morales-Navarro and Kafai 2024) without methodically evaluating how systems work.\nOne promising activity to engage learners in evaluating AI/ML systems and investigate potential harmful biases is algorithm auditing. As described above, algorithm auditing involves querying and observing the outputs of systems (Metaxa et al. 2021b). Auditing is different from traditional testing and evaluation in various ways (Metaxa et al. 2021b). Unlike other types of testing, auditing is systematic, with the goal of drawing system-wide conclusions rather than individual test case results. Audits are also generally external evaluations performed by independent third parties without insider access, based on externally measured system behaviors. Algorithm auditing has been used in rigorous studies conducted by experts on racial housing discrimination in algorithmic systems, employee recruitment applications, recommendation systems, AI/ML-powered diagnosis and care systems in healthcare, and search engines (for a review of expert algorithm audits, see Bandy (2021); for details on the method, see Metaxa et al., (2021b)). Recent work in auditing has begun exploring how systems' end-users can, without auditing expertise, be engaged in identifying harmful algorithmic behaviors through auditing practices. In one paradigm, adult users collaborate with experts, who explicitly task them with conducting an algorithm audit and provide friendly user interfaces for doing so (see Lam et al., (2023)). Meanwhile, other studies have examined the phenomenon of bottom-up, user-driven auditing practices that emerge organically among some user bases in the absence of explicit instructions (DeVos et al. 2022; Shen et al. 2021). In K-12 AI education, several efforts have explored different approaches to auditing-related activities. For instance, Walker and colleagues (2022) proposed having youth conduct \"evocative audits\" to research the positive and negative ways in which computing systems affect the socio-political realities of their communities. Solyst et al. (2023) adapted user-driven everyday auditing tasks, such as making observations of Google search results (DeVos et al. 2022) into activities for middle schoolers, noting that there is plenty of potential for youth to be involved in identifying and mitigating harmful algorithmic biases. Morales-Navarro et al. (2024) designed a workshop in which high school participants designed ML-powered physical computing projects and then audited their peers' projects. In a clinical interview study, they found that after the workshop, participants showed more nuanced understandings of data issues that may cause harmful biases, reflecting on how potential harmful biases and behaviors may emerge from the qualities of the data used to train models. Collectively, these observations support the idea that youth-driven algorithm audits are feasible, connecting to young people's everyday experiences while also deepening their understanding of algorithmic systems. However, the auditing activities observed in these studies mostly center on a single or a couple of observations without engaging youth in the systematic analysis of inputs and outputs and the full process of conducting an audit from beginning to end. Thus, a major challenge is to identify and articulate an auditing approach that is systematic, accessible to, and actionable by youth."}, {"title": "Auditing algorithmic systems in five steps", "content": "To address this challenge, we turn to the research on algorithm auditing and conceptualize five different steps that make up the process of auditing algorithms. We recognize that not all algorithm audits are conducted the same way (Bandy 2021; Costanza-Chock, Raji, and Buolamwini 2022); these steps are a general blueprint of one common process of auditing algorithmic systems (Metaxa et al. 2021b). Based on our review, algorithm auditing involves: (1) developing a hypothesis, (2) generating a set of systematic, thorough, and thoughtful inputs to test the hypothesis, (3) running the test, (4) analyzing the data, and (5) reporting the results. Before discussing our case study with youth, we will walk through each step using an illustrative example of an expert-driven audit entitled \u201cAn Image of Society\" (hereafter: AIS), conducted by Metaxa and colleagues (2021a), in which they investigated the effect of gender and racial representation in image search results for common workforce occupations. We also draw on examples from other expert-driven and user-driven audits to demonstrate common approaches to each step."}, {"title": "Step 1: Developing a Hypothesis", "content": "To begin an audit, researchers must first generate a hypothesis about the kind of behavior they expect the algorithmic system being audited to exhibit. In AIS, the hypothesis was that gender and racial biases would be reflected in Google search results. This hypothesis was developed as a follow-up to an earlier audit by Kay et al. (2015) that studied how different levels of gender diversity in search results affected users' perceptions of occupations and the search engine. Hypotheses are often based on auditors' personal experiences using AI/ML systems. This was the case, for example, in the Gender Shades study by Buolamwini & Gebru (2018), where Buolamwini's personal experiences with facial recognition led the team to investigate racial disparities in gender classification systems. At the same time, in user-driven audits, everyday people come up with hypotheses based on observed unexpected behaviors (DeVos et al. 2022) and are often collectively formulated (Shen et al. 2021). In one such high-profile user-driven audit example of Twitter's image cropping algorithm,"}, {"title": "Step 2: Generating a set of systematic, thorough, and thoughtful inputs", "content": "In the second step of most expert audits, auditors design a set of inputs to the system in question, carefully selected so as to rigorously test their hypothesis. These are ideally systematic, thorough, and thoughtful, such that their results could constitute convincing proof of the hypothesis. In AIS, researchers generated a list of 100 occupations to test their hypothesis on a wide range of jobs, some with racial and gender parity and some with documented racial and gender inequities, to be able to observe if search results were actually biased or accurately reflected the real-world gender and racial make-up of those occupations. In user-driven audits, auditors may be less systematic, with end users' planning being more ad hoc and reactive to system behaviors or their own personal experience (DeVos et al. 2022). However, thanks to the scaling power of social media, some user-driven audits can approach expert levels of systematicity. Clearly, unlike the generation of a hypothesis, this step may be more compromised in audits directly involving users. This has implications for learning activities with youth, as we discuss in our case study."}, {"title": "Step 3 - Running a test", "content": "The next step, running the tests, involves repeatedly querying the algorithmic system using the inputs designed in the step above, and recording the system's outputs. In AIS, researchers conducted search queries of Google Image Search for each of the 100 selected occupations and collected the top 100 images for each search using automated web scrapers. Other expert-driven audits have been conducted using both manual and automated means. That was the case for Sweeney's (2013) study of racial discrimination in online ad delivery, in which she investigated whether a Google search for a Black-sounding name resulted in ads suggestive of an arrest record compared to White-sounding names, with the researcher conducting 1373 manual searches and 812 automated ones. In user-driven audits that occur organically, often testing is impromptu, for instance, in the Twitter case with users replicating tests conducted by other users. More recently, researchers have built tools for user-driven auditing that support users in running and documenting their tests (Lam et al. 2023)."}, {"title": "Step 4 - Analyzing the data", "content": "After testing, data is analyzed by describing the findings and/or conducting statistical analyses. In the AIS study, researchers recruited crowdworkers through Amazon Mechanical Turk to label the race and gender of the image outputs from the search results, with the goal of understanding how outside viewers perceived the people in those images. Then they used statistical tests to compare gender representation in Google Image Search results to 2020 data on occupation demographics from the United States Bureau of Labor and Statistics (BLS), discovering evidence of men's systematic over-representation. In terms of race, they found stronger systematic over-representation of the dominant group, white people, relative to people of color. In other expert-driven studies, data analysis involves grouping outputs and reporting descriptive statistics, rather than conducting statistical hypothesis testing. In Sweeney's audit, discussed above, for instance, she calculated the percentage of arrest ads and neutral ads delivered after searching for Black- and White-sounding names on Google. In some user-driven audits, analysis may be similarly descriptive or even qualitative, with users inspecting and interpreting data based on their own lived experiences (DeVos et al. 2022), or seeing if they can replicate the findings of other users (Shen et al. 2021). In short learning activities, students could analyze patterns in the outputs and, like Sweeney, calculate percentages."}, {"title": "Step 5 Reporting the results", "content": "An important part of conducting an audit is to report its results in order to effect change. Expert-driven audits, such as AIS, often become academic papers that are presented at conferences like CSCW or FAccT, and can lead to discussions directly with the teams responsible for the product. Other expert-driven audits lead to long-form journalism articles (Nicoletti and Bass 2023) or interactive websites where people can explore the data and see the analysis and results (Buolamwini et al. 2018), with the goal of raising public awareness. While some reports are directed toward informing future researchers, others target policymakers or the general public.\nDistilling auditing into this five-step model and adapting it for learning activities requires us to think about algorithm auditing from a learner-centered perspective (Soloway, Guzdial, and Hay 1994; Hsi and Soloway 1998). This involves carefully considering the kind of scaffoldings that learners may need, their diverse lived experiences, and the shift in goals (from auditing a system to learning about and from auditing) (Soloway, Guzdial, and Hay 1994). As such, learning activities should incorporate aspects of expert-driven auditing to support learners in understanding how and why audits are conducted. They should also draw from user-driven auditing practices to incorporate and speak to youths' everyday lived experiences as users of AI/ML systems. In the following sections, we share the iterative design story of supporting high school youth to audit to foreground the shifts in specificity in the scaffolds we developed and the increased amount of time participants needed to thoroughly engage in each of the five auditing steps."}, {"title": "Methods", "content": "As the context in which to study the affordances of algorithm auditing activities, we worked with high school youth enrolled in a four-year after-school program, Science Investigators (a pseudonym), at a science center in the North-"}, {"title": "Findings", "content": "We present the findings of our case study, focusing on two youths, Ishmael and Ziyi, a 14-year-old male and 15-year-old female, and their respective engagement with the five auditing steps laid out above. Together, they audited a filter designed by their peers. The filter was designed with the intention of giving the user red hair, red clothes, and a background that looked like a cloudy sky. Through their auditing process, Ishmael and Ziyi developed the hypothesis that this filter also enhanced or exaggerated the female characteristics of its users. They then designed a set of inputs, ran their tests, and analyzed the outputs, concluding that the filter indeed displayed this bias, reporting that it transformed all input images in their dataset into female-presenting people."}, {"title": "Step 1: Developing a Hypothesis", "content": "Before developing a hypothesis, Ziyi and Ishmael spent some time playing with the filter by first testing it on the default images available on Effect House (see Figure 1). After a few minutes, Ziyi explained, \"I noticed that it turns everyone into a woman, and it makes the hair red.\" Ishmael noted that the filter gave everyone thick eyebrows. He loaded the filter on his phone and started testing it on himself, realizing that the filter made him look like a light-skinned woman and gave him red nails and blush on his cheeks. Ziyi experimented with the filter, using it on pictures of herself taken from different angles. After a while, they decided that they wanted to test if the filter always made people female-presenting. Ishmael explained: \"It changes the individual's gender automatically to female, and then, like enhancing, it enhances female characteristics.\" Ziyi and Ishmael's initial open-ended exploration of the filter and its behaviors was instrumental in helping them develop their hypothesis."}, {"title": "Step 2: Generating a set of systematic, thorough, and thoughtful inputs", "content": "We observed that selecting inputs was one of the most challenging aspects of conducting an audit for youth. Ishmael was clear that they needed images of both male and female people and people with different hair styles. Ziyi also thought it was important to make sure people in the images had different skin tones to observe if the filter worked in the same way for people of different racial backgrounds. This was particularly notable in light of the fact that the group's hypothesis did not make any direct mention of race or skin color. They started using the organizer to put pictures of male and female celebrities. Ishmael noted that \"some of them have to go in the middle [between female and male].\" As the group has having this discussion, one of the science center educators, Dolly, approached and asked, \"Do you want pictures of only male and female people? Or also non-conforming people?\" Ishmael agreed, \"Yeah, we also need non-binary people.\" Ziyi added, \u201cMaybe we should also think about hair length because it is gender-coded.\" They started adding images to their input organizer with hair length and gender as the two axes (see Figure 2), also ensuring they had people of a diverse range of skin colors and racial backgrounds in their dataset. For every image selected, the pair discussed where to locate it in the input organizer. At the end they had 33 images to test the filter."}, {"title": "Step 3 - Running tests", "content": "In the testing phase, Ziyi and Ishmael imported the pictures from their input organizer into Effect House, ran the filter and copied the outputs into a document where they kept track of input and output pairs using a table provided by instructors (Figure 3). For every image, they discussed their observations and took notes in the table, blending steps 3 (tests) and 4 (analysis) of the auditing process. In taking notes, they first decided on different aspects of the images they wanted to consider. The group agreed to make a note if there were any changes in hairstyle, clothes, gender, or skin tone of the output image. For example, for the first image they tested (see Figure 4) they noted that the hair became more curvy, a braid became a bead, and the clothes changed. The person went from wearing a white tank top with bare arms to a white and red long sleeve shirt. They also noted that the filter changed the gender presentation of the input figure, adding feminine features like blush on their cheeks, red lipstick, and breasts; the skin tone also changed from a \u201cdarker skin tone to a tanner orange skin tone\u201d (Ishmael). After annotating two outputs as a team, Ziyi and Ishmael divided the work, with Ziyi running the tests and adding the images to the spreadsheet and Ishmael annotating them."}, {"title": "Step 4 - Analyzing the data", "content": "After conducting the test and qualitatively annotating each of the input-output pairs, Ziyi and Ishamel examined their data as a whole, calculating percentages for gender, hair style, and eurocentric features in the outputs. Ziyi explained: \"What we noticed is that it creates a female picture regardless of a person's gender. We put in a bunch of inputs with a variety of skin tones and gender identities, and we noticed that all of them came out to be female.\" They noted that, although their input images were 60% male, 30% female, and 30% non-binary people, all of the outputs looked female. More specifically, they recorded, all of the outputs had blush, tanned skin, and eurocentric features. They also recorded that 26% of inputs had their hair style changed, and 75% of the outputs had red hair."}, {"title": "Step 5 - Reporting results", "content": "The group decided to report their audit findings in a TikTok video. Ishmael suggested they make the video humorous, like other TikTok videos he had seen, to engage the audience. To do so, Ishmael changed his voice and introduced the project as an analysis that shows that the filter transformed everyone \u201cinto a skibidi\u00b9 female.\" In the video, Ishmael and his friend Brooklyn-May introduced the audit study, sharing the hypothesis and how they decided on different inputs. Then Ziyi reported on the findings from the study. The pair subsequently recorded the video a second time, calling the first one a \"blooper.\""}, {"title": "Discussion", "content": "This paper provides a first illustration of how we can empower youth to systematically and critically evaluate machine learning applications through algorithm auditing. We proposed a five-step model for learners to engage in algorithm auditing activities and provided a case study in which a team of high school youth used these five steps to conduct an algorithm audit of a TikTok filter. We developed these five steps based on a review of prior literature on expert- and user-driven algorithm auditing. In the following paragraphs, we address some of the affordances and challenges of how the steps scaffolded youths' engagement and how youth's practices relate to expert- and user-driven auditing.\nDividing algorithm auditing into different steps scaffolded youth by directing their attention to key features on how to systematically evaluate the performance of the filters. We further scaffolded youth's engagement with each step by modeling what each step looked like and providing guidance and structured time for youth to conduct their investigations. For example, for step 1, we modeled what a hypothesis could look like and showed examples of hypotheses developed by other youth. In addition, we provided them with time to become familiar with the filter they were auditing through open-ended exploration or play. Here, using the filter on Effect House's default images and on themselves was key for them to begin observing potentially harmful system behaviors that required further investigation. Following, we asked them to document moments when the filters did not work as expected and finally to formulate a hypothesis based on their explorations. Another area that required scaffolding was input generation to support youth in coming up with systematic, thorough, and thoughtful inputs. Introducing the two-axis input organizer (Figure X.) supported learners in coming up with diverse inputs, but as we saw in the case of Ziyi and Ishamel, learners may consider the diversity of inputs across more than two variables.\nFuture iterations of auditing activities should further scaffold the creation of inputs, data analysis, and reporting of findings. Having learners create a large input data set can be a challenge due to the perceived repetitive nature of the task. As we saw in our case study, the team built a dataset of only 33 images to test their hypothesis. Here we see opportunities to explore how generating inputs could be a class-wide group activity where youth build a collaborative dataset or how existing datasets could be leveraged by youth to test their hypotheses. In terms of data analysis, while we asked youth to count and describe patterns they observed in the data, this process could be better scaffolded so that youth can further analyze data by applying statistics knowledge and creating data visualizations. Finally, to report on the findings, youth in our study created TikTok videos, while these short videos were fun to make, other forms of reporting to emphasize computational communication (Lui, Fields, and Kafai 2019) could be explored, including having youth create infographics, data visualization projects, or longer videos in which they can explain how they conduct an audit and showcase their findings.\nAdopting this five-step model for youth required us to think about algorithm auditing from a learner-centered perspective (Soloway, Guzdial, and Hay 1994), that is, acknowledging that the goals of learning about auditing are different than those of conducting expert- or user-driven audits. The goal for learners is to understand and experience auditing as a systematic method to evaluate ML-powered systems from the outside-in and not to conduct expert-like audits or user-like one-off observations. Yet, as we observed in the analysis of the case study, incorporating aspects of expert-driven auditing supported youth in being systematic in generating inputs, analyzing data, and drawing conclusions based on evidence. For instance, despite the difficulty of generating all inputs in a single step before beginning to test, we felt this structure was important as it avoided the ad hoc and reactive nature in which everyday users create inputs (DeVos et al. 2022). It also supported youth in engaging, albeit on a smaller scale, with some of the discussions that experts also have when designing protocols to test their hypotheses (Metaxa et al. 2021b). At the same time, practices observed in user-engaged auditing were particularly helpful to support youth in generating hypotheses. Like everyday users in user-driven audits (Shen et al. 2021; DeVos et al. 2022), through casual interaction, youth were able to make ad hoc observations and build hypotheses about potentially harmful behaviors. These kinds of ad hoc observations are also present in some expert-driven audits, as expert auditors sometimes draw on their own everyday interactions and user experiences to inspire their hypotheses (Buolamwini and Gebru 2018; Sweeney 2013). In scaffolding auditing learning activities, we observed how incorporating aspects of expert-driven auditing supports learners in understanding how audits are conducted systematically, while drawing from user-driven auditing practices enabled us to build on youths' everyday lived experiences as users of AI/ML systems."}, {"title": "Implications & Future Work", "content": "Next steps for this work involve exploring how the five steps could be used to integrate algorithm auditing activities in classroom settings. This work must consider a variety of issues, such as choice of AI/ML systems that youth audit, collaborative arrangements, and teacher professional development. To start, in our study youth audited peer-designed TikTok filters. However, Tiktok's upcoming legal challenges and restricted access to TikTok and Effect House platforms on school devices present challenges for conducting similar work in school settings. To overcome this impending obstacle, future work must identify other applications that could be audited in school settings and that are relevant to youths' lives, and also identify other viable community spaces in which this particular tool may remain a viable option, such as community centers and after-school programs.\nA second important consideration for implementing algorithm auditing learning activities concerns collaborative arrangements. In our particular case, we decided to have youth work in pairs. As we could observe in our case study, even without the explicit assignment of roles, Ziyi and Ishamel adopted their own work arrangement when running tests and recording observations. While working in small teams was a productive arrangement, we noted that the design of extensive test data remains a challenge. Here future work might investigate how youth in a class or workshop can collectively build a data set, with each student or team contributing a number of test cases, resulting in a more extensive set a single team or student could assemble.\nFinally, we must acknowledge the central role teachers will play in implementing successful algorithm auditing activities in classroom settings. In our case, workshop organizers and staff were instrumental in providing scaffolding and feedback that helped to guide youth through the five steps. We have already started participatory design work with a group of experienced K-12 CS educators to bring algorithm auditing activities into high school classrooms and encourage the proliferation of such efforts. We hope that this work can contribute to empowering youth to systematically investigate how ML systems work and what their implications are."}]}