{"title": "A Short Survey on Set-Based Aggregation Techniques\nfor Single-Vector WSI Representation in Digital Pathology", "authors": ["S. Hemati", "Krishna R. Kalari", "H.R. Tizhoosh"], "abstract": "Digital pathology is revolutionizing the field of pathology by enabling the digitization,\nstorage, and analysis of tissue samples as whole slide images (WSIs). WSIs are gigapixel files\nthat capture the intricate details of tissue samples, providing a rich source of information for\ndiagnostic and research purposes. However, due to their enormous size, representing these\nimages as one compact vector is essential for many computational pathology tasks, such as\nsearch and retrieval, to ensure efficiency and scalability. Most current methods are \"patch-\noriented,\" meaning they divide WSIs into smaller patches for processing, which prevents a\nholistic analysis of the entire slide. Additionally, the necessity for compact representation is\ndriven by the expensive high-performance storage required for WSIs. Not all hospitals have\naccess to such extensive storage solutions, leading to potential disparities in healthcare quality\nand accessibility. This paper provides an overview of existing set-based approaches to single-\nvector WSI representation, highlighting the innovations that allow for more efficient and effective\nuse of these complex images in digital pathology, thus addressing both computational\nchallenges and storage limitations.", "sections": [{"title": "Introduction", "content": "Whole Slide Images (WSIs) are a critical resource in the field of digital pathology, allowing for\nthe digitization, storage, and detailed analysis of biopsy samples. However, the gigapixel scale\nof these images poses substantial computational challenges. To address this issue, typically\neach WSI is split to multiple patches that can be fitted into GPU memory. In this scenario, we\nend up with a set of patch embeddings per WSI. such representation still is not optimal in terms\nof memory storage and downstream data analysis tasks. To mitigate these issues, recent\nresearch has concentrated on developing methods to aggregate and condense these massive\nimages into compact single-vector representations. These techniques not only facilitate more\nefficient storage but also enhance the capabilities for classification, retrieval, and analysis of the\ndata. This brief survey delves into the importance of these technological advancements by\nreviewing the key studies that have significantly contributed to the field.\n\nAn alternative approach to condensing or aggregating whole slide image (WSI) embeddings into\na single representation is the \"median-of-minimums\" method, which has been proposed for\nimage retrieval and applied in classification tasks using the k-nearest neighbors (k-NN)"}, {"title": "Evolutionary Deep Feature Selection for Compact Representations, (Bidgoli, 2022):\nPooling (SVA) + Evolutionary Feature Selection", "content": "In their 2022 study, Bidgoli et al. address the challenge of creating compact WSI\nrepresentations by proposing an evolutionary deep feature selection approach. The method\ninvolves extracting deep feature vectors from WSIs and using a simple average pooling to\nobtain single WSI embedding per WSI. Having this single vector WSI representation,\nevolutionary algorithms are used to optimize and condense these vectors into a compact feature\nvector (CFV). This CFV is significantly smaller\u2014up to 11,000 times\u2014than the original feature\nset while maintaining high classification accuracy. This reduction in data size facilitates more\nefficient computational processing and storage, making it easier to handle large volumes of\npathology images. The study demonstrates that this compact representation improves\nclassification accuracy by 11% compared to previous benchmarks, highlighting its potential to\nenhance the efficiency and scalability of digital pathology workflows."}, {"title": "Set Representation Learning using Memory Networks (Kalra, 2020): Two-stage\nAggregation (SVB)", "content": "Kalra et al. developed the Memory-based Exchangeable Model (MEM) concept to learn the\npermutation invariant representations for the set data. In this method, a MEM is constructed\nfrom multiple memory blocks where each memory block is a sequence-to-sequence model\ncontaining multiple memory units. The output of each memory block is invariant to the\npermutations of the input sequence. The memory units in this architecture are in charge of\ncalculation of attention values for each instance. To calculate these attention values, the\nmemory vectors are aggregated using a pooling operation (weighted averaging) to form a\npermutation-invariant representation. Increasing the number of memory units enables the\nmemory block to capture more complex dependencies between the instances of a set by\nproviding an explicit memory representation for each instance in the sequence. MEM shows\npromising results on different set classification tasks including point cloud and lung WSIs\nclassification."}, {"title": "CNN and Deep Sets for WSI representation learning, (Hemati, 2021): End-to-end\nAggregation (SVC)", "content": "In the study by (Hemati, 2021) the authors tackle the issue of computational bottlenecks\ninherent in processing WSIs. They propose a novel neural network architecture that integrates\nConvolutional Neural Networks (CNNs) and Deep Sets (Zaheer, 2017) as one the first deep\nMultiple Instance Learning (MIL) techniques to extract a single permutation-invariant vector\nrepresentation for each WSI. They showed that by incorporating 40 patches per WSI, and\ntraining the CNN and Deep Sets units in an end-to-end manner, they can achieve high quality\nsingle-vector WSI representations that can outperform earlier multi vector (Kalra, 2020)\nrepresentations. This approach is particularly significant as it addresses the difficulty of\nemploying deep learning directly on gigapixel images by avoiding the need for patch-based\nprocessing. Instead of working with a bag of patches, this method provides a cohesive and\ncompact vector representation that simplifies downstream tasks such as image search and\nclassification. The network is trained in a multi-label setting to encode both primary site and\ndiagnosis, enabling efficient transfer learning and achieving superior performance in retrieval\nand classification tasks compared to existing methods like Yottixel (Kalra, 2020)."}, {"title": "Attention-based deep multiple instance learning, (Ilse, 2018): End-to-end Aggregation\n(SVC)", "content": "To tackle limitations of early stage MIL layers including being non-trainable and giving no score\nto the importance of instances within a bag as in Deep Sets (Zaheer, 2017), Ilse et al. proposed\nattention based MIL pooling layer. Authors were also motivated given ability to detect more\nimportant instances, such a flexible and adaptive MIL pooling could lead superior set level\nrepresentation and offer better interpretability. Attention based MIL use a weighted average of\nlow-dimensional instance representations where weights must sum to 1 and determined by a\nsimple network. Ilse et al. validated their proposed attention based MIL on two different\npathology datasets breast and colon cancer and showed superior performance compared with\nthe rigid max and average pooling."}, {"title": "CNN with Attention based MIL and Self-Supervised Contrastive Learning, (Fashi, 2022):\nEnd-to-end Aggregation (SVC)", "content": "Fashi et al. introduced a self-supervised contrastive learning framework specifically designed\nfor learning end-to-end WSI representation learning. This method leverages the primary site\ninformation of WSIs to enhance the robustness of the learned representations. Unlike traditional\naugmentation-based self-supervised learning approaches, this framework directly focuses on\nend-to-end WSI representation (rather than patch-based processing) given primary site\ninformation as the first training stage. Then, the Network is further fine-tuned using a supervised\ncontrastive loss. By doing so, it improves the generalization capabilities of the model for\ndownstream tasks such as classification and search. In this work, the patch embeddings are\naggregated into a single vector using an attention-based MIL layer proposed by (Ilse, 2018).\nThe model was trained and evaluated on over 6,000 WSIs from The Cancer Genome Atlas\n(TCGA) repository, demonstrating excellent performance across various primary sites and\ncancer subtypes, particularly excelling in lung cancer classification. This study underscores the\npotential of self-supervised learning in generating robust and efficient WSI representations."}, {"title": "Focal Attention for WSI Representation Learning, (Kalra, 2021): Two-stage Aggregation\n(SVB)", "content": "Another MIL scheme developed for WSI classification/search is focal attention proposed in\n(Kalra, 2021). In this work, the authors were inspired by the two recent developments in\nrepresentation learning literature focal loss and attention based MIL and proposed the novel\npooling layer called focal attention (FocAtt-MIL). In FocAtt-MIL, the attention-weighted averaging\nproposed by (Ilse, 2018) is additionally modulated by a trainable focal factor. More precisely,\nFocAtt-MIL is composed from four main components. Prediction MLP, WSI Context, Attention\nModule, and Focal Network. The Prediction MLP is a trainable neural network that calculates a\nprediction for each patch embedding in the set. WSI context is also a neural network (basically\nDeep Sets from (Zaheer, 2017) that obtains one embedding per WSI in a simple efficient\nmanner that capture a general information from the WSI. The attention module is taken from the\nto (Ilse, 2018) work which is itself made from two MLPs transformation, and the Attention\nnetworks. The attention module takes the patch embedding and WSI context and output the an\nattention value between 0 to 1 for each instance. Finally, the focal network receive the WSI\ncontext and computes a focal factor per dimension which further guide the final prediction\ntowards better WSI representation. FocAtt-MIL has been tested on classification of Lung\nAdenocarcinoma (LUAD) and Lung Squamous Cell Carcinoma (LUSC) and also Pan-cancer\nAnalysis for a dataset of 7,097 training, and 744 test WSIs covering 24 different anatomic sites,\nand 30 different primary diagnoses."}, {"title": "Incorporating intratumoral heterogeneity into weakly-supervised deep learning models\nvia variance pooling (Carmichael, 2022): End-to-end Aggregation (SVC)", "content": "As an improvement to the attention-based pooling, Carmichael et al. proposed to add a variance\npooling on top of attention values to capture within-WSI heterogeneity (intratumoral\nheterogeneity). In this architecture, the variance of attention values is concatenated to the mean\nvalues and fed to a MLP to calculate the final WSI embedding. This architecture was evaluated\non five cancer types from TCGA and showed adding this variance pooling on attention values\nimproves predictive performance of the model on survival prediction."}, {"title": "Dual-stream multiple instance learning network for whole slide image classification with\nself-supervised contrastive learning, (Li, 2021): Two-stage Aggregation (SVB)", "content": "Li et al. proposed Dual-stream multiple instance learning (DSMIL) aggregation technique to\ncapture the dependencies of the instances in a dual-stream architecture with trainable distance\nmeasurement. In DSMIL, aggregation is performed using two units namely a masked non-local\nblock and a max-pooling layer (Zaheer, 2017). Additionally, to mitigate challenges caused by\nlarge or unbalanced bags for the training of the models, authors proposed to use self-\nsupervised contrastive learning. In DSMIL, the instance and the bag classifiers are used\nsimultaneously for both streams. The first stream applies max pooling on embeddings obtained\nthrough an instance classifier on each instance. The second stream aggregates the above\ninstance embeddings into a bag embedding which is eventually scored by a bag classifier.\nFinally, an attention-like scoring mechanism is used to detect important instances. Authors"}, {"title": "ReMix: A general and efficient framework for multiple instance learning based whole\nslide image classification, (Yang, 2022): Two-stage Aggregation (SVB)", "content": "Authors in ReMix paper target the memory and computational load of recent MIL techniques\ndeveloped for WSI representation learning task. This is due the large size of WSIs that usually\nlead to gigantic bags to tens of thousands of elements (patches). Additionally, data\naugmentation for MIL based WSI representation learning is explored. RemMix involves two\nstages: reduce and mix. First, the patch prototypes, i.e., patch cluster centroids are detected\nand used instead of non-prototype patches. Then the bag mixing augmentation step which\nincludes four latent space augmentations is performed. This step diversify discriminative\nrepresentations in the latent space. The effectiveness of ReMix was validated on UniToPatho\nand Camelyon16 datasets where authors showed significant improvement over DSMIL by (Li,\n2021)."}, {"title": "Deep fisher vector for Sparse and Binary permutation invariant Representations for Real-\nTime Image Retrieval, (Hemati, 2023): Two-stage Aggregation (SVB)", "content": "In their 2023 study, Hemati et al. propose a framework for learning sparse and binary\npermutation invariant WSI representations to improve real-time image retrieval and classification\nperformance. The framework leverages deep conditional generative modeling and Fisher Vector\nTheory to create two types of compact representations: Conditioned Sparse Fisher Vector (C-\nDeep-SFV) and Conditioned Binary Fisher Vector (C-Deep-BFV). These representations are\ndesigned to be memory-efficient and computationally efficient, making them suitable for large-\nscale medical archives. Given that Fisher Vector is the normalized gradient of generative model\nloss function with respect to its parameters, to have sparse and binary WSI embeddings the\nauthors introduced new loss functions\u2014gradient sparsity and gradient quantization losses\u2014that\nencourage gradient space of the generative model to be sparse and binary respectively. This is\nthe first study that obtain sparse or binary permutation WSI embeddings which are efficient for\nretrieval systems. Validated on datasets from TCGA and the Liver-Kidney-Stomach (LKS)\ndataset, the proposed method outperforms existing retrieval systems like Yottixel, achieving\nbetter retrieval accuracy and speed. Additionally, the framework shows competitive performance\nin WSI classification tasks, further demonstrating its practical utility in clinical settings."}, {"title": "Graph convolutional neural network for WSI representation learning, (Adnan, 2020): Two-\nstage Aggregation (SVB)", "content": "Adnan et.al. proposed to represent each WSI as a fully connected graph where patch\nembeddings concatenated with a global context vector obtained by a pooling function represent\nnodes in the graph. Zaheer et.al. In the Deep Sets paper, Zaheer showed that a mapping\nfollowed pooling function can be used as a universal set approximator which is used as context\nvector by Adnan. Having the edges, the Adjacency Matrix is learned using an Adjacency Matrix\nlearning layer. The element in row i and column j of Adjacency Matrix quantifies similarity\nbetween nodes i and j. Having the graph representation of each WSI, graph convolution network\nis used to learn the representation of the WSI as a graph. This representation encodes relations\namong patch embeddings. To obtain the single vector representation of the WSI, the graph\nrepresentation is fed to graph pooling layer. Adnan et.al. introduced attention via graph pooling\nto capture infer patches with higher importance. They tested their proposed technique for\nclassifying lung cancers into Lung Adenocarcinoma (LUAD) & Lung Squamous Cell Carcinoma\n(LUSC) over 1,026 lung cancer WSIs in 40X magnification and obtained the state-of-the-art\naccuracy of 88.8%."}, {"title": "Conclusions", "content": "The representation of WSIs as single vectors marks a significant advancement in digital\npathology. These methods not only address the computational challenges posed by gigapixel\nimages but also enhance the efficiency and accuracy of downstream tasks such as\nclassification and retrieval. By leveraging deep multi-instance learning, self-supervised learning,\nand evolutionary algorithms, researchers have been able to obtain WSI embeddings with higher\nquality. These innovations hold great promise for improving diagnostic accuracy and treatment\noutcomes in clinical settings. For future work, this is interesting to see quantitative comparison\nof WSI representation learning techniques in terms of final embedding quality, their applicability\nfor different tasks (classification, retrieval, segmentation, etc.) and computational load in a fair\nand comprehensive manner."}]}