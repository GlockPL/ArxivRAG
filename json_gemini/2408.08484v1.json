{"title": "An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem", "authors": ["Huaiyuan Liu", "Xianzhang Liu", "Donghua Yang", "Hongzhi Wang*", "Yinchi Long", "Mengtong Ji", "Dongjing Miao", "Zhiyu Liang"], "abstract": "The Maximum Minimal Cut Problem (MMCP), a NP-hard combina- torial optimization (CO) problem, has not received much attention due to the demanding and challenging bi-connectivity constraint. Moreover, as a CO problem, it is also a daunting task for machine learning, especially without labeled instances. To deal with these problems, this work proposes an unsupervised learning framework combined with heuristics for MMCP that can provide valid and high-quality solutions. As far as we know, this is the first work that explores machine learning and heuristics to solve MMCP. The unsu- pervised solver is inspired by a relaxation-plus-rounding approach, the relaxed solution is parameterized by graph neural networks, and the cost and penalty of MMCP are explicitly written out, which can train the model end-to-end. A crucial observation is that each solution corresponds to at least one spanning tree. Based on this finding, a heuristic solver that implements tree transformations by adding vertices is utilized to repair and improve the solution quality of the unsupervised solver. Alternatively, the graph is sim- plified while guaranteeing solution consistency, which reduces the running time. We conduct extensive experiments to evaluate our framework and give a specific application. The results demonstrate the superiority of our method against two techniques designed.", "sections": [{"title": "1 INTRODUCTION", "content": "The graph is a fundamental structure used to depict diverse relation- ships among entities [15, 42], such as social networks, communica- tion networks, biological information, and power grids. Combinato- rial optimization (CO) on graphs is a crucial field in computational mathematics, with typical examples including the Max-cut [35], Maximum Independent Set (MIS) [8], and Traveling Salesman Prob- lem (TSP) [12] applied in various scenarios. The exact solutions for most combinatorial optimization problems are intractable to search, primarily due to their NP-hard nature. Consequently, sig- nificant research efforts have been dedicated to solving these tasks by generating approximate solutions [18, 32]. The Max-cut problem, a classic NP-hard problem in graph the- ory, has been extensively studied for decades, while the Maximum Minimal Cut (MMC) problem as a variant of the max-cut problem is rarely mentioned. Given a connected graph G = (V, E), the objec- tive of the max-cut problem is to discover a partition method that divides all vertices into two complementary sets, denoted as K and L, in a way that maximizes the cardinality of edges between K and L. The maximum minimal cut problem (MMCP) adds the requirement that both K and L be connected based on the max-cut problem, also called the largest bond problem [29]. As a well-known fact, a cut C = (K, L) of G is minimal if and only if both subgraphs induced by K and L are connected [39], where K, L \u2208 V and L = V\\K. Therefore, a minimal cut is regarded as a two-sided connected cut [19]. Additionally, the Connected Maximum Cut (CMC) problem is a"}, {"title": "2 RELATED WORK", "content": "This section briefly reviews the related work on the maximum minimal cut problem and the combinatorial optimization solvers. Maximum Minimal Cut Problem (MMCP). Unlike general CO problems, the study of MMCP is still in its infancy. As a NP-hard issue, the optimal solution of MMCP cannot be approximated by a constant factor in polynomial time unless P = NP [17]. Based on this point, researchers have developed a wide range of complexity analyses for the MMCP, while there exist rare results about the approximate solvers of the MMCP in general graphs [6, 41]. Notably, Flynn et al. [33] showed that the size of the largest bond is at least O(nlog3 2) for any simple 3-connected graph G(V, E), where n = |V|. Later, Duarte et al. [29] proved that the MMCP is NP- complete even on planar bipartite graphs and split graphs. Moreover, they gave a O* (2O(twlog tw))-time algorithm for the MMCP from the perspective of the parameterized complexity. Although these methods have achieved breakthroughs in the computational theory of MMCP, they are still limited in the application of the real scene. Combinatorial Optimization (CO) Solver. Due to the high time complexity of exact algorithms [37, 40], approximation ap- proaches have become the mainstream for solving CO problems [4, 13]. Heuristics are one of the most efficient and effective ap- proaches for solving the CO problem which obtains a sub-optimal solution within a reasonable time [23, 50, 52]. Unfortunately, heuris- tics are problem-specific and time-consuming. With the blowout of artificial intelligence, the approaches of neural networks for CO emerge as the times require [30, 36, 46]. Most neural approaches to CO are supervised, and such methods rely on training large-scale"}, {"title": "3 PRELIMINARIES", "content": "In this section, we describe the key concept applied in the paper. Firstly, We give some notations that will be used. Notation. Let G(V, E, W) be a weighted, undirected, connected graph with n = |V| vertices, m = |E| edges, and weights W = (w1,..., wm), where wi \u2208 R+ and n, m \u2208 N*. Unweighted graphs can be regarded as weighted graphs with all edge weights equal to 1. There are two disjoint connected subgraphs K = (V1, E1) and L = (V2, E2) of G, K and L can be connected by the edge set F = {e1, ..., ec} which has weight WF = (w1,..., wc). Besides, \u015a and S denote relaxed and discrete solutions throughout the paper. Then, the problem that we are addressing, i.e. the maximum minimal cut problem (MMCP), is formulated. Problem Formulation. The MMCP is to find a set of edges that divides the connected graph into two connected subgraphs so that the sum of the weight (or cardinality) on the edge set is the largest. The formal definition is given as follows.\nDEFINITION 1 (THE MAXIMUM MINIMAL CUT PROBLEM). If K and L satisfy: 1) V1 \u222a V2 = V and V1 \u2229 V2 = \u2205; 2) E1, E2, F \u2286 E, E1 \u222a E2 \u222a F = E and E1 \u2229 E2 \u2229 F = \u2205; 3) c \u2208 N*.\nThen C = (K, L) can be called a minimal cut of G, and F is named the cut-set of G. Alternatively, K and L are known as the connected cut. Each C and F corresponds uniquely, where the cut value of |F| is given by \u2211i=0 c wi. The maximum minimal cut is the minimal cut C* with the largest cut value among all C of G.\nIn the above definition, we can consider F or Cu as the solution of MMCP, where Cu = (V1, V2) is the vertex set form of C. We assert that MMCP is more challenging than the Max-cut problem [7]."}, {"title": "4 METHODOLOGY", "content": "In this section, the proposed framework, its components, and related theories will be elaborated comprehensively. Moreover, a random algorithm is presented as a baseline."}, {"title": "4.1 Overview", "content": "In summary, we achieve acceleration through graph partitioning and the performance-guaranteed unsupervised solver, and further repair and obtain higher-quality solutions by leveraging the heuris- tic solver. We overview the proposed unsupervised learning frame- work combined with heuristics (PIONEER) in Figure 2. Given a connected graph G = (V, E) as input, the connected components of G can be formed by removing all bridges of G, which does not affect the final solution and also reduces the graph size (see Section 4.2). The connected components with a larger number"}, {"title": "4.2 Graph Partitioning", "content": "Considering that the time complexity of solving MMCP grows expo- nentially with the graph size, we exploit the theorem presented in this subsection to simplify the graph without affecting the solutions. The bridge is a special edge in the undirected connected graph, also called cut-edge. The removal of the bridge will increase the number of connected components in the graph. Suppose that G1 and G2 are the connected components obtained by disconnecting one bridge eb of G, which satisfies G1 \u222a G2 \u222a eb = G, G1 \u2229 G2 = \u2205. In addition, F, F1, and F2 are the maximum minimal cut-set of G, G1, and G2, respectively. Then, we have the following theorem.\nTHEOREM 1. The maximum minimal cut-set F of G can only be obtained on one of the two sides of the bridge or on the bridge, that is, F = max{eb, F1, F2}.\nThe above theorem manifests that the solution of MMCP for a connected graph G can be obtained by separately solving connected"}, {"title": "4.3 The Unsupervised Combinatorial Solver", "content": "We aim to leverage unsupervised learning for solving MMCP. Gen- erally, combinatorial optimization (CO) problems on graphs admit solutions that are binary vectors S = {x1, ..., xn} \u2208 {0, 1}n of the set of vertices to denote whether the vertex is selected or not. Thus, a CO problem on graphs is to minimize a cost f given a constraint g by solving the following equation.\nmin S\u2208V f(S; G) subject to g(S; G) \u2264 1  (1)\nLearning for MMCP. The learning for MMCP is to learn an algorithm A\u03b8 (G) \u2192 S \u2208 {0, 1}n, e.g. a neural network (NN) pa- rameterized by \u03b8 to solve MMCP. Given an undirected weighted graph G(V, E, \u03c9) with |V| = n and |E| = m, whose degree matrix and adjacency matrix are denoted by D and A, respectively. The complete pipeline of unsupervised solver is given in Figure 3. Inspired by [44], we adopt a relaxation-plus-rounding mecha- nism and add a term to the loss function that penalizes deviations from the constraint. Let a continuous vector \u015a = {x1,..., xn} \u2208 [0, 1]n as the relaxed solution obtained by graph neural networks (GNNs). Formally, we define a new loss function for MMCP:\nmin \u03b8 L(\u03b8; G) = \u03b1 \u00b7 f(\u015c; G) + \u03b2 \u00b7 g(\u015c; G)), \u03b1, \u03b2 > 0  (2)\nwhere, \u03b1 = m/n or 1, \u03b2 = max f (S; G). Note that \u03b2 = \u2211i=1 m wi for weighted graph and \u03b2 = m for unweighted graph. Since connectiv- ity is a feature that is strongly correlated with the number of edges, \u03b1 controls the balance between cost and penalty.\nCost Function. To ensure the non-negativity of the loss function, we translate the cost function by minimizing the difference between the maximum value \u03b3 of the objective and the sum of cut-set weights. Typically, the sum of edge weights or cardinality of the graph is employed as \u03b3. We define the cost function as follows.\nf(\u015c; G) = \u03b3 \u2212 \u2211 i,j\u2208V,i<j wij (xi \u2212 xj) 2  (3)\nPenalty Function. The connected constrain g(\u015c; G)) for MMCP is then considered. According to the definition of a maximal minimal cut, we devote to dividing the graph G into two cuts by encoding all the vertices as 0 or 1. Thus, the constraint is satisfied if the graph G', with the removal of edges between 0 and 1, has only two connected components; otherwise, it is illegal and should be punished. We enlighten from the Matrix-Tree theorem [16] in the Appen- dix A.5 and the property of Laplacian matrix, i.e. the number of eigenvalues with value 0 of Laplacian matrix is equal to the num- ber of connected components of G. Consequently, the number of eigenvalues with value 0 of the Laplace matrix L(G') for G' should be equal to 2. Formally, let \u03bb1 \u2264 ... \u2264 \u03bbn is ordered eigenvalues"}, {"title": "4.4 Solution Forest", "content": "A natural idea for addressing CO problems is to initially discover a solution and subsequently verify whether the constraints are met. However, if the solution adhering to the constraints can be reformulated into a directly obtainable equivalent form, it would substantially enhance the efficiency of the search. Consequently, we attempt to convert the Bernoulli solution of the MMCP into another closed form such that all solutions achieved by a given algorithm must satisfy the constraints.\nIt is well-known that the spanning tree of the graph possesses some interesting properties [51], such as, each edge of the tree is a bridge. Based on this conclusion, we state the following theorem.\nTHEOREM 4. Suppose that C = (K, L) is a maximum minimal cut with cut value \u03c8 of G, which can definitely be obtained by discon- necting an edge of a certain spanning tree T = (VT, ET) of G.\nThe theorem above indicates that each feasible solution of MMCP corresponds to at least one spanning tree of G. In other words, we can explore legal solutions for the MMCP by transforming the span- ning tree, eliminating the need to check for constraint violations, which is the core idea behind the design of our subsequent heuristic solver. Additionally, to facilitate the subsequent description of the heuristic solver, we define a notion of disconnect-vertex as follows.\nDEFINITION 3 (DISCONNECTED-VERTEX). An optimal solution of G can be obtained by disconnecting the edge ed = (vi, vj) of spanning tree T. Such edge is called disconnected-edge of T and vi, vj are named disconnected-vertex of T."}, {"title": "4.5 Heuristic Tree Transformation", "content": "To further repair and improve the solutions of the unsupervised solver while disregarding the impact of the graph structure, we aim to design a heuristic that achieves the transformation of the span- ning tree by adding vertices for the cut to explore better solutions. Suppose Cu = (V1, V2) is the maximum minimal cut of G obtained from the spanning tree T of G, where V1 = V\\V2, w.l.o.g, we assume |V1| < |V2. Let pk \u2208 V1 and pk+1 \u2208 V2. We aim to optimize the existing spanning tree by introducing an appropriate pk+1 related to pk into V1, seeking enhanced solutions. The transformation of the current spanning tree will undergo the following four phases. Phase I. Selection.\nAs not all vertices in V2 are suitable to join V1, the selection of pk+1 must meet the constraint that pk+1 is the neighbor of pk, which ensures V1 is connectable after each vertex movement. Therefore, different neighbors of V1 can be chosen to join V1, altering the shape of the spanning tree in conjunction with the subsequent phases. Phase II. Disconnect edge."}, {"title": "4.6 Random Tree Search", "content": "According to Theorem 4, we designed a random search algorithm as a baseline based on the conclusion that transforming the shape of the spanning tree can lead to diverse feasible solutions. Drawing in- spiration from the Kruskal algorithm [28] employed in constructing minimum spanning trees, we arrange all edges in ascending order based on their weights. For unweighted graphs, the order of edges is randomized. In each iteration, the edge sequence is randomly shuffled, and subsequently, the spanning tree T, of the graph G is"}, {"title": "5 EXPERIMENTAL EVALUATION", "content": "This section discusses our experimental setup and results. As a case study, we provide a specific real-world application of MMCP."}, {"title": "5.1 Experimental Setup", "content": "We conduct extensive experiments to evaluate the practical ef- fectiveness of the proposed method. Here we briefly describe the hardware, datasets, baselines, and evaluation metrics. Implementations. We implement the PIONEER by Python 3.7.11 and PyTorch 1.9.2. All experiments are conducted on an Ubuntu ma- chine with NVIDIA GeForce RTX 3090 (24 GB VRAM) and Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz (256 GB RAM). For the unsupervised solver, the training, validating, and testing datasets use an 8:1:1 dataset split, and each synthetic dataset contains 10,000 graphs. In addition, in the interest of fairness, our unsupervised solver and [24] share the same neural network structure and param- eter setting without the GAT layer. We refer interested readers to [24] for more details. Given the significant variations and sparsity observed in real-world datasets, we select the suitable \u03b1 based on parameter study in Appendix C.2.2. We set \u03b1 = m/n for synthetic graphs, allowing the model to explore the solutions that yield larger objective values. For the random tree search, we report the best result by running the algorithm for 500 rounds. Our code can be available at https://github.com/luckyseasalt/PIONEER. Datasets. We assess our methods in a wide variety of experiments, rigorously conducted on synthetic and real-world datasets. Real- world datasets are all unweighted graphs, including, ENZYMES [49], IMDB [25], and REDDIT [47] datasets. Noteworthy, the real-world dataset also includes actual power grids and associated parameters. Synthetic datasets are constructed with 36 vertices based on the pictures in MNIST [5]. There are 60, 000 pictures in Mnist which cor- respond to different one-digit [5]. The construction of the synthetic datasets is inspired by [38]. Here, we first generate a complete graph G as a motherboard. We associated each edge with \u03be = {0, 1}|E| and each vertex with the picture. Thus, synthetic graphs can be built by a random sequence \u03be whose element denotes whether the corresponding edge in G exists. We give an instance in Figure 4. Considering the impact of various graph structures and the re- quirements of our framework, constraints can be imposed on the random graph generation process to obtain different types of graphs. It should be noted that the unsupervised solver is employed to han- dle graphs that have undergone graph partitioning. Hence, we focus on the scenario without bridges when creating the dataset. In sum- mary, the synthetic Mnist datasets are classified into two primary types, i.e. isomorphic graphs and heterogeneous graphs with the notation 'I-36|m' and 'H-36', where m is the number of edges. More configurations of all datasets are described in Appendix C.1. Baselines. As few algorithms can be fully adapted to solve MMCP, we mainly designed the brute force algorithm and the random algorithm, which can individually obtain the exact and approximate"}, {"title": "5.2 Main Results", "content": "Table 1, 2 and 3 report the results on synthetic datasets and real- world datasets, respectively. Note that the results of the brute force algorithm are not included because it is still too time-consuming even when adopting graph partitioning to simplify. All methods are graphically simplified and accelerated by graph partitioning. In summary, the proposed PIONEER achieves better solutions than the competitors on all datasets and runs quickly. The re- sults show that PIONEER exhibits superior performance in solving MMCP with various graph structures. We discuss the results of each task in more detail below. Note that the best results among the methods are highlighted in bold across all Tables. Experiments on synthetic datasets. The results of the synthetic tasks are shown in Table 1, where PIONEER demonstrates com- petitive performance across all datasets. It consistently delivers solutions of the highest quality while maintaining a rapid process- ing speed. Surprisingly, the random tree search method achieves acceptable results within a relatively short time frame, benefiting from Theorem 4. However, the performance of the proposed ran- dom algorithm weakens as the number of edges increases. This"}, {"title": "5.3 Ablation Study", "content": "To validate the effectiveness of the key components in PIONEER, we conduct ablation studies on all aforementioned datasets. Only two critical results are reported here. w/o Unsupervised solver. We remove the unsupervised solver in our framework and directly construct a random spanning tree as input for the heuristic solver to evaluate the effectiveness of the unsupervised solver. As can be seen in Figure 5, the variant without an unsupervised solver can solve with almost the same quality as PIONEER (Avg. 3750.48 vs 3756.20). However, the speed of implementation of the two showed marked differences (Avg. 9.45 s/g vs 5.54 s/g). This is an interesting finding that the unsupervised solver serves as an effective starting point for the heuristic solver, leading to a substantial improvement in search speed.\nw/o Heuristic solver. Similarly, we assess the heuristic by directly taking the output of the unsupervised solver as a result. The results are summarized in Table 4, showing the heuristic solver plays a cru- cial role in repairing and enhancing the solutions. Encouragingly, although the unsupervised solver does not yield optimal solutions, its fastest running speed and acceptable solution quality are also im- pressive. Furthermore, we have observed that unsupervised solvers exhibit surprisingly effective performance in tackling MMCP for dense graphs with fast speed."}, {"title": "5.4 More Results", "content": "We conduct more experiments to further analyze the key compo- nents and parameters of PIONEER. For detailed information, please refer to Appendix C.2 due to space limitations. Supplemental ablation study. To validate the effectiveness of graph partitioning, rounding, and the upper bound \u03bb3 (G), ad- ditional ablation experiments are performed. The results indicate that graph partition can dramatically accelerate execution, the pro- posed rounding methods improve the ability to generate constraint- satisfying solutions, and \u03bb3 (G) enables the model to better learn the bi-connectivity for different graph structures. Parameter study. Parameter experiments are conducted to study the key parameters, including the balanced control parameter \u03b1 and the self-adaptive coefficient \u03f5. The results show that suitable \u03b1 and \u03f5 can enhance the learning process of the unsupervised solver, leading to improved quality and legality of the solutions. Performance guarantee study. Our method avoids the intri- cate analysis of loss monotonicity, ensuring Theorem 3 through deterministic rounding. When the relaxed loss is successfully mini- mized to a sufficiently small value, the inequality L(S; G) < L(\u015c; G) < \u03b1 \u00b7 \u03b2 is satisfied, yielding low-cost and feasible solutions. Heuristic study. A constraint checking is incorporated into a genetic algorithm to perform a comparative study. The algorithm is provided in Appendix B.5. The results reveal that exploring solu- tions from spanning trees is significantly superior to the method of obtaining cuts and subsequently determining their legality."}, {"title": "5.5 Case Study", "content": "Recall that we mentioned a demand for the power grid motivating this work. Therefore, we utilize the task of cross-section identi- fication in the power grid as a case study. We leave the problem statement and the visualization of solutions in Appendix C.2.5. We study the performance of PIONEER on the power grid of certain regions. Due to the confidentiality of power grid data, we only give some important details in the Appendix C.1. Additionally, training is not feasible due to the limited dataset containing only three graphs. Therefore, we utilize models trained on the REDDIT dataset, which exhibits relative similarity to the power grid. As shown in Table 5, our method exhibits superior performance across all cases. Notably, PIONEER appears to take more time on"}, {"title": "6 CONCLUSIONS AND FUTURE WORKS", "content": "In this paper, we propose a novel unsupervised learning framework combined with heuristics named PIONEER for MMCP. In particular, we demonstrate the theoretical foundation of graph simplification and the equivalent form of solutions for MMCP. On these bases, we design an unsupervised framework with mathematical guarantees, which is not only sufficiently rapid in acquiring acceptable solu- tions independently but also enhances the speed of downstream solvers. We also construct a heuristic solver for further repairing and improving the quality of solutions. Extensive experiments man- ifest that PIONEER outperforms the baselines in various graph structures with good generalization. In the future, one promising direction is to enhance the ability of the unsupervised solver to han- dle sparse graphs. Another interesting theme is to explore a more explicit relationship between spanning trees and optimal solutions."}, {"title": "APPENDIX", "content": "In the Appendix, we provide proofs of the proposed theorems, details and pseudo-cod of the algorithms involved, more details of the experiments and more results, broader impact for the maximum minimal cut problem (MMCP), and license for all datasets."}, {"title": "A THE PROOF AND RELATED THEOREM", "content": ""}, {"title": "A.1 Proof of Theorem 1", "content": "PROOF. Consider whether eb is in the cut-set F of G. If eb \u2208 F, such that F = eb, that is the maximum minimal cut C = (G1, G2). Without loss of generality, we let C = (K, L) and eb \u2208 K if eb /\u2208 F. Suppose v1, v2 are on the different sides of eb, and v1, v2 cannot be connected if v1, v2 \u2208 L. Thus, the cut-set F of G will be equal to the F of G1 if v1, v2 \u2208 K. Similarly, the case where eb \u2208 L can also be proved."}, {"title": "A.2 Proof of Theorem 2", "content": "To prove Theorem 2, we first introduce the eigenvalue interlacing theorem [21].\nTHEOREM 5 (WEYL'S INEQUALITY). Let H and U be n \u00d7 n Hermitian matrices, with their ordered eigenvalues \u03bb1(\u00b7) \u2264 ... \u2264 \u03bbn(\u00b7). Then the following inequality holds:\n\u03bbi(H) + \u03bbn(U) \u2264 \u03bbi(H + U) \u2264 \u03bbi(H) + \u03bb1(U), i = 1, ..., n.\nEndow Cn with the Euclidean inner product (\u00b7, \u00b7) which is anti- linear in the second coordinate. For u \u2208 Cn, the linear rank one map u \u2297 u = uu*.\nThen, we can draw the following corollary.\nCOROLLARY 1. Let H be an n \u00d7 n Hermitian matrices with ordered eigenvalues \u03bb1 \u2264 ... \u2264 \u03bbn. For nonzero vector u \u2208 Cn and n \u2265 2, let the eigenvalues of Z = H + u \u2297 u be \u00b51 \u2264 ... \u2264 \u00b5n. Then the eigenvalues of H and Z interlace,\n\u03bb1 \u2264 \u00b51 \u2264 \u03bb2 \u2264 \u00b52 \u2264 ... \u2264 \u03bbn \u2264 \u00b5n.\nWith these preliminaries, we then prove Theorem 2.\nPROOF. Let L be a Laplacian matrix of graph G, without loss of generality, we remove an edge euv from G in turn to obtain subgraphs G' of G. We consider the variation of the adjacency matrix from the subgraph G' to G when removing one edge euv from G.\nL(G') =\n{\naij ,lij , i \u0338= j ,luu, lov \nAL = L(G' + e) \u2212 L(G') = \n{\naij ,lij , i \u0338= j ,luu, lov \nLet p is an nonzero vector with element pu = 1 and pv = -1, then \u2206L = pp*. There is \u03bbi(L(G')) \u2264 \u03bbi(L(G' + e)) = \u03bbi(L(G)) based on the Corollary 1. Similarly, all subgraphs of G can be obtained in this way so that the same conclusions can be reached by just superimposing pp*. Consequently, the eigenvalues of the Laplacian matrices of all subgraphs of G are correspondingly smaller than the eigenvalues of the Laplacian matrix of G."}, {"title": "A.3 Proof of Theorem 3", "content": "PROOF. Let w(\u015c) = \u2211i,j\u2208V,i<j wij (xi \u2212 xj)2 denote a weight obtained by a relaxed solution \u015a = A\u03b8(G), x \u2208 [0, 1]n. We analyze the rounding process of the relaxed solution \u015a into the discrete solution S \u2208 {0, 1}n. Let xi and xi, i = 1, 2, ..., n denote their entries respectively. The rounding procedure has no requirement on the order of the rounding sequence, w.l.o.g, suppose we round from index i = 1 to i = n.\nIn the deterministic rounding phase, we opt for the rounding method that minimizes the loss per round. Additionally, further rounding is conducted for the cases that do not meet the loss in- equality. Then the following inequality holds:\nL(\u03b8; G) = \u03b1 \u00b7 f(\u015c; G) + \u03b2 \u00b7 g(\u015c; G)\n=\u03b1\u00b7[\u03b3 \u2212 \u2211 i,j\u2208V,i<j wij (xi \u2212 xj)2] + \u03b2 \u00b7 e\u2212\u03c4\u00b7[\u03bb3 (\u015c)\u2212\u03bb2 (\u015c)]\n\u2265\u03b1\u00b7[\u03b3 \u2212 \u2211 i,j\u2208V,i<j wij (xi \u2212 xj)2] + \u03b2 \u00b7 e\u2212\u03c4\u00b7[\u03bb3 (S)\u2212\u03bb2 (S)]\n=\u03b1 \u00b7 f(S; G) + \u03b2 \u00b7 g(S; G)\nwhere, (a) denotes the phase of deterministic rounding.\nNote. We state that finding an entry-wise concave principle sim- ilar to [44] for the maximum minimal cut problem is challenging. We consider the case of unweighted graphs for convenience, i.e., wij = 1. We begin with the change in cost function f(\u015c; G) after rounding \u015c to S.\nw(\u015c) = \u2211 i,j\u2208V,i<j wij (xi \u2212 xj)2 = n \u2211 i\u2208V x2 \u2212 (\u2211 i\u2208V xi)2\n= n(x2 1 + ... + x2 n) \u2212 (x1 + ... + xn)2   (9)\nRounding x1 to x1 and the difference of them is similarly denoted to \u2206x1 = x1 \u2212 x1. If \u2206x1 > 0 then show that x1 rounds to xi = 1; \u2206x1 < 0 then x1 rounds to xi = 0; otherwise xi is unchanged, i.e. x = xi.\nw(\u015c + \u2206x1) = n[(x1 + \u2206x1)2 + x2 + ... + x2 n] \u2212 (x1 + \u2206x1 + x2 + ... + xn)2  (10)\nConsequently, the variation of w(\u015c) after rounding x1 to x1 can be obtained.\n\u2206w(\u015c + \u2206x1) = w(\u015c + \u2206x1) \u2212 w(\u015c) = n[(\u2206x1)2 + 2x1\u2206x1] \u2212 (2(\u2211 i xi + x1)\u2206x1 + (\u2206x1)2)\n= (n \u2212 1)(\u2206x1)2 + 2(nx1 \u2212 \u2211 i xi)\u2206x1 = 2(nx1 \u2212 \u2211 i xi)\u2206x1 \u2212 (n + 1)(\u2206x1)2   (11)\nWe analyze \u2206w(\u015c + \u2206x1) in conjunction with the quadratic func- tion f(x) = ax2 + bx + c. \u2206x1 is regarded as a quadratic function of x. Thus, it is easy to see that \u2206w is hardly uniformly monotonic. In addition, the monotonicity of the eigenvalues is even more difficult"}, {"title": "B.1 Inherent Complexity of MMCP", "content": "Although max-cut and maximum minimal cut are both NP-hard problems, computing the maximum minimal cut of a graph seems to be harder. Interestingly, the max-cut problem can be optimally solved in polynomial time in planar graphs [11], while MMCP was proved NP-complete even on planar graphs in [7] that showed the MMC on graphs of clique-width w cannot be solved in time f(w) \u00d7 nO(w) unless the Exponential Time Hypothesis (ETH) fails."}, {"title": "B.2 Details of Heuristic Solver", "content": "The case of disconnecting edges. In Section 4.5, recall that in Phase II of Heuristic, all the edges of pk+1 are broke. The following cases may appear. Case 1: The current graph is exactly two parts after discon- necting the edges of pk+1. Then it only needs to connect one edge between the two connected components to induce a new tree. (e.g. Pk+1 = v4 in Figure B.1)\nCase 2: The disconnected edge will be reserved if the neigh- bor of pk+1 only has neighbor pk+1 in V2, and such vertex will be removed from the neighbor of pk+1. (e.g. v7 in Figure B.2)\nCase 3: The current graph is divided into several connected components after disconnecting the edges of pk+1 and it is necessary to connect all the neighbors of pk+1 to V2 to induce a new tree. It should be noted, that the correspond- ing edge should be added according to case 1 if pk+1 is the disconnected-vertex in V1."}, {"title": "B.3 Exact Search Algorithm", "content": "To verify the accuracy of the proposed method on small graphs, we developed an algorithm for brute force search to achieve exact solutions. The graph is first simplified by graph partitioning. We traverse all possible vertex subsets, checking whether they form valid cuts, and return the vertex subset with the maximum cut value along with its value. We give the pseudo-code of in Algorithm 1.\nComplexity analysis. The time complexity of the brute force search algorithm is O(2n), where n is the number of vertices. It is not applicable for solving MMCP on larger-scale graphs."}, {"title": "B.4 Random Search Algorithm", "content": "We designed a random tree search algorithm in Section 4.6. The demonstration and the pseudo-code of the algorithm are given in Figure B.4 and Algorithm 2, respectively."}, {"title": "B.5 Genetic Algorithm", "content": "To further assess the performance of the proposed heuristic solver, we adaptively modified a classical heuristic, Genetic Algorithm (GA) [3], as a baseline. The graph is initially simplified through graph par- titioning. Linear ranking selection is employed to generate the par- ent population. After obtaining new individuals through crossover and mutation, the solutions are evaluated for bi-connectivity re- quirements using Depth-First Search (DFS). The fitness of a valid solution is defined by its cut value, while solutions that do not meet the constraint are assigned a fitness of 0. The pseudo-code of the genetic algorithm for the MMCP is as shown in Algorithm 3."}, {"title": "C MORE DETAILS OF THE EXPERIMENTS", "content": ""}, {"title": "C.1 Datasets", "content": "Synthetic Mnist datasets. Synthetic Mnist 1 datasets are gen- erated according to Section 5.2. In summary, the synthetic Mnist datasets are classified into two primary types as explained below. (1) Isomorphic graph. The datasets are constructed by individually setting the number of vertices and edges to be 36 and m, where m = 60, 120, 180, 240, 300. These graphs are undirected, connected, and do not contain bridges, encoded as 'I-36|m'. (2) Heterogeneous graph. Undirected connected graphs without bridges are built whose number of vertices is 36, named 'H-36'. We divide all the datasets into training, validating, and testing sets and count all the constructed datasets as shown in Table C.1. It"}, {"title": "C.2.1 Supplemental"}]}