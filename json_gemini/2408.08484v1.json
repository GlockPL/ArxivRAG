{"title": "An Unsupervised Learning Framework Combined with Heuristics\nfor the Maximum Minimal Cut Problem", "authors": ["Huaiyuan Liu", "Xianzhang Liu", "Donghua Yang", "Hongzhi Wang*", "Yinchi Long", "Mengtong Ji", "Dongjing Miao", "Zhiyu Liang"], "abstract": "The Maximum Minimal Cut Problem (MMCP), a NP-hard combina-\ntorial optimization (CO) problem, has not received much attention\ndue to the demanding and challenging bi-connectivity constraint.\nMoreover, as a CO problem, it is also a daunting task for machine\nlearning, especially without labeled instances. To deal with these\nproblems, this work proposes an unsupervised learning framework\ncombined with heuristics for MMCP that can provide valid and\nhigh-quality solutions. As far as we know, this is the first work that\nexplores machine learning and heuristics to solve MMCP. The unsu-\npervised solver is inspired by a relaxation-plus-rounding approach,\nthe relaxed solution is parameterized by graph neural networks,\nand the cost and penalty of MMCP are explicitly written out, which\ncan train the model end-to-end. A crucial observation is that each\nsolution corresponds to at least one spanning tree. Based on this\nfinding, a heuristic solver that implements tree transformations\nby adding vertices is utilized to repair and improve the solution\nquality of the unsupervised solver. Alternatively, the graph is sim-\nplified while guaranteeing solution consistency, which reduces the\nrunning time. We conduct extensive experiments to evaluate our\nframework and give a specific application. The results demonstrate\nthe superiority of our method against two techniques designed.", "sections": [{"title": "1 INTRODUCTION", "content": "The graph is a fundamental structure used to depict diverse relation-\nships among entities [15, 42], such as social networks, communica-\ntion networks, biological information, and power grids. Combinato-\nrial optimization (CO) on graphs is a crucial field in computational\nmathematics, with typical examples including the Max-cut [35],\nMaximum Independent Set (MIS) [8], and Traveling Salesman Prob-\nlem (TSP) [12] applied in various scenarios. The exact solutions\nfor most combinatorial optimization problems are intractable to\nsearch, primarily due to their NP-hard nature. Consequently, sig-\nnificant research efforts have been dedicated to solving these tasks\nby generating approximate solutions [18, 32].\nThe Max-cut problem, a classic NP-hard problem in graph the-\nory, has been extensively studied for decades, while the Maximum\nMinimal Cut (MMC) problem as a variant of the max-cut problem\nis rarely mentioned. Given a connected graph G = (V, E), the objec-\ntive of the max-cut problem is to discover a partition method that\ndivides all vertices into two complementary sets, denoted as K and\nL, in a way that maximizes the cardinality of edges between K and L.\nThe maximum minimal cut problem (MMCP) adds the requirement\nthat both K and L be connected based on the max-cut problem, also\ncalled the largest bond problem [29]. As a well-known fact, a cut\nC = (K, L) of G is minimal if and only if both subgraphs induced by\nK and L are connected [39], where K, L \u2208 V and L = V\\K. There-\nfore, a minimal cut is regarded as a two-sided connected cut [19].\nAdditionally, the Connected Maximum Cut (CMC) problem is a"}, {"title": "2 RELATED WORK", "content": "This section briefly reviews the related work on the maximum\nminimal cut problem and the combinatorial optimization solvers.\nMaximum Minimal Cut Problem (MMCP). Unlike general\nCO problems, the study of MMCP is still in its infancy. As a NP-hard\nissue, the optimal solution of MMCP cannot be approximated by\na constant factor in polynomial time unless P = NP [17]. Based on\nthis point, researchers have developed a wide range of complexity\nanalyses for the MMCP, while there exist rare results about the\napproximate solvers of the MMCP in general graphs [6, 41]. Notably,\nFlynn et al. [33] showed that the size of the largest bond is at\nleast O(nlog3 2) for any simple 3-connected graph G(V, E), where\nn = |V|. Later, Duarte et al. [29] proved that the MMCP is NP-\ncomplete even on planar bipartite graphs and split graphs. Moreover,\nthey gave a O* (2O(twlog tw))-time algorithm for the MMCP from\nthe perspective of the parameterized complexity. Although these\nmethods have achieved breakthroughs in the computational theory\nof MMCP, they are still limited in the application of the real scene.\nCombinatorial Optimization (CO) Solver. Due to the high\ntime complexity of exact algorithms [37, 40], approximation ap-\nproaches have become the mainstream for solving CO problems\n[4, 13]. Heuristics are one of the most efficient and effective ap-\nproaches for solving the CO problem which obtains a sub-optimal\nsolution within a reasonable time [23, 50, 52]. Unfortunately, heuris-\ntics are problem-specific and time-consuming. With the blowout\nof artificial intelligence, the approaches of neural networks for CO\nemerge as the times require [30, 36, 46]. Most neural approaches to\nCO are supervised, and such methods rely on training large-scale"}, {"title": "3 PRELIMINARIES", "content": "In this section, we describe the key concept applied in the paper.\nFirstly, We give some notations that will be used.\nNotation. Let G(V, E, W) be a weighted, undirected, connected\ngraph with n = |V| vertices, m = |E| edges, and weights W =\n(@1,..., @m), where w \u2208 R+ and n, m \u2208 N*. Unweighted graphs\ncan be regarded as weighted graphs with all edge weights equal\nto 1. There are two disjoint connected subgraphs K = (V1, E1)\nand L = (V2, E2) of G, K and L can be connected by the edge set\nF = (e1, ..., ec) which has weight WF = (\u03c9\u2081, ..., \u03c9\u00b4). Besides, \u015c and\nS denote relaxed and discrete solutions throughout the paper.\nThen, the problem that we are addressing, i.e. the maximum\nminimal cut problem (MMCP), is formulated.\nProblem Formulation. The MMCP is to find a set of edges that\ndivides the connected graph into two connected subgraphs so that\nthe sum of the weight (or cardinality) on the edge set is the largest.\nThe formal definition is given as follows.\nDEFINITION 1 (THE MAXIMUM MINIMAL CUT PROBLEM). If K\nand L satisfy: 1) V\u2081 \u222a V2 = V and V10 V2 = 0; 2) E1, E2, F CE,\nE1 U E2 UF = E and E1 E2 \u2229 F = 0; 3) c\u2208 N*.\nThen C = (K, L) can be called a minimal cut of G, and F is named\nthe cut-set of G. Alternatively, K and L are known as the connected\ncut. Each C and F corresponds uniquely, where the cut value of|F| is\ngiven by \u2211\u03af=\u03bf \u03c9. The maximum minimal cut is the minimal cut C*\nwith the largest cut value among all C of G.\nIn the above definition, we can consider F or Co as the solution\nof MMCP, where Cu = (V1, V2) is the vertex set form of C. We assert\nthat MMCP is more challenging than the Max-cut problem [7]."}, {"title": "4 METHODOLOGY", "content": "In this section, the proposed framework, its components, and related\ntheories will be elaborated comprehensively. Moreover, a random\nalgorithm is presented as a baseline."}, {"title": "4.1 Overview", "content": "In summary, we achieve acceleration through graph partitioning\nand the performance-guaranteed unsupervised solver, and further\nrepair and obtain higher-quality solutions by leveraging the heuris-\ntic solver. We overview the proposed unsupervised learning frame-\nwork combined with heuristics (PIONEER) in Figure 2.\nGiven a connected graph G = (V, E) as input, the connected\ncomponents of G can be formed by removing all bridges of G, which\ndoes not affect the final solution and also reduces the graph size\n(see Section 4.2). The connected components with a larger number"}, {"title": "4.2 Graph Partitioning", "content": "Considering that the time complexity of solving MMCP grows expo-\nnentially with the graph size, we exploit the theorem presented in\nthis subsection to simplify the graph without affecting the solutions.\nThe bridge is a special edge in the undirected connected graph,\nalso called cut-edge. The removal of the bridge will increase the\nnumber of connected components in the graph. Suppose that G1\nand G2 are the connected components obtained by disconnecting\none bridge e\u2081 of G, which satisfies G1 U G2 U e\u2081 = G, G1 \u2229 G2 = 0.\nIn addition, F, F1, and F2 are the maximum minimal cut-set of G, G1,\nand G2, respectively. Then, we have the following theorem.\nTHEOREM 1. The maximum minimal cut-set F of G can only be\nobtained on one of the two sides of the bridge or on the bridge, that is,\nF = max{eb, F1, F2}.\nThe above theorem manifests that the solution of MMCP for a\nconnected graph G can be obtained by separately solving connected"}, {"title": "4.3 The Unsupervised Combinatorial Solver", "content": "We aim to leverage unsupervised learning for solving MMCP. Gen-\nerally, combinatorial optimization (CO) problems on graphs admit\nsolutions that are binary vectors S = {x1, ..., Xn} \u2208 {0, 1}n of the\nset of vertices to denote whether the vertex is selected or not. Thus,\na CO problem on graphs is to minimize a cost f given a constraint\ng by solving the following equation.\n$\\displaystyle \\min_{S \\subset V} f(S; G) \\text{ subject to } g(S; G) \\leq 1$\nLearning for MMCP. The learning for MMCP is to learn an\nalgorithm A (G) \u2192 S \u2208 {0,1}n, e.g. a neural network (NN) pa-\nrameterized by \u03b8 to solve MMCP. Given an undirected weighted\ngraph G(V, \u0395, \u03c9) with |V| = n and |E| = m, whose degree matrix\nand adjacency matrix are denoted by D and A, respectively. The\ncomplete pipeline of unsupervised solver is given in Figure 3.\nInspired by [44], we adopt a relaxation-plus-rounding mecha-\nnism and add a term to the loss function that penalizes deviations\nfrom the constraint. Let a continuous vector \u015c = {x1,..., xn} \u20ac\n[0, 1]n as the relaxed solution obtained by graph neural networks\n(GNNs). Formally, we define a new loss function for MMCP:\n$\\displaystyle \\min_{\\theta} \\mathcal{L}(\\theta;G) = \\alpha \\cdot f(\\hat{S}; G) + \\beta \\cdot g(\\hat{S}; G)), \\alpha, \\beta > 0$\nwhere, \u03b1 = m/n or 1, \u03b2 = max f (S; G). Note that \u03b2 = \u03a31 1 wi for\nweighted graph and \u1e9e = m for unweighted graph. Since connectiv-\nity is a feature that is strongly correlated with the number of edges,\na controls the balance between cost and penalty.\nCost Function. To ensure the non-negativity of the loss function,\nwe translate the cost function by minimizing the difference between\nthe maximum value \u03b3 of the objective and the sum of cut-set weights.\nTypically, the sum of edge weights or cardinality of the graph is\nemployed as y. We define the cost function as follows.\n$\\displaystyle f(\\hat{S};G) = \\gamma - \\sum_{i,j\\in V,i<j} w_{ij} (\\hat{x}_{i} - \\hat{x}_{j})^2$\nPenalty Function. The connected constrain g(\u015c; G)) for MMCP is\nthen considered. According to the definition of a maximal minimal\ncut, we devote to dividing the graph G into two cuts by encoding all\nthe vertices as 0 or 1. Thus, the constraint is satisfied if the graph G',\nwith the removal of edges between 0 and 1, has only two connected\ncomponents; otherwise, it is illegal and should be punished.\nWe enlighten from the Matrix-Tree theorem [16] in the Appen-\ndix A.5 and the property of Laplacian matrix, i.e. the number of\neigenvalues with value 0 of Laplacian matrix is equal to the num-\nber of connected components of G. Consequently, the number of\neigenvalues with value 0 of the Laplace matrix L(G') for G' should\nbe equal to 2. Formally, let \u03bb\u2081 \u2264 < \u03bbn is ordered eigenvalues"}, {"title": "4.4 Solution Forest", "content": "A natural idea for addressing CO problems is to initially discover\na solution and subsequently verify whether the constraints are\nmet. However, if the solution adhering to the constraints can be\nreformulated into a directly obtainable equivalent form, it would\nsubstantially enhance the efficiency of the search. Consequently,\nwe attempt to convert the Bernoulli solution of the MMCP into\nanother closed form such that all solutions achieved by a given\nalgorithm must satisfy the constraints.\nIt is well-known that the spanning tree of the graph possesses\nsome interesting properties [51], such as, each edge of the tree is a\nbridge. Based on this conclusion, we state the following theorem.\nTHEOREM 4. Suppose that C = (K, L) is a maximum minimal cut\nwith cut value \u03c8 of G, which can definitely be obtained by discon-\nnecting an edge of a certain spanning tree T = (VT, ET) of G.\nThe theorem above indicates that each feasible solution of MMCP\ncorresponds to at least one spanning tree of G. In other words, we\ncan explore legal solutions for the MMCP by transforming the span-\nning tree, eliminating the need to check for constraint violations,\nwhich is the core idea behind the design of our subsequent heuristic\nsolver. Additionally, to facilitate the subsequent description of the\nheuristic solver, we define a notion of disconnect-vertex as follows.\nDEFINITION 3 (DISCONNECTED-VERTEX). An optimal solution of\nG can be obtained by disconnecting the edge ed = (vi, vj) of spanning\ntree T. Such edge is called disconnected-edge of T and vi, vj are named\ndisconnected-vertex of T."}, {"title": "4.5 Heuristic Tree Transformation", "content": "To further repair and improve the solutions of the unsupervised\nsolver while disregarding the impact of the graph structure, we aim\nto design a heuristic that achieves the transformation of the span-\nning tree by adding vertices for the cut to explore better solutions.\nSuppose Cu = (V1, V2) is the maximum minimal cut of G obtained\nfrom the spanning tree T of G, where V\u2081 = V\\V2, w.l.o.g, we assume\n|V1| < |V2|. Let pk \u2208 V\u2081 and Pk+1 \u20ac V2. We aim to optimize the\nexisting spanning tree by introducing an appropriate pk+1 related\nto pk into V\u2081, seeking enhanced solutions. The transformation of\nthe current spanning tree will undergo the following four phases.\nPhase I. Selection.\nAs not all vertices in V2 are suitable to join V\u2081, the selection of\nP k+1 must meet the constraint that pk+1 is the neighbor of pk, which\nensures V\u2081 is connectable after each vertex movement. Therefore,\ndifferent neighbors of V\u2081 can be chosen to join V\u2081, altering the shape\nof the spanning tree in conjunction with the subsequent phases.\nPhase II. Disconnect edge."}, {"title": "4.6 Random Tree Search", "content": "According to Theorem 4, we designed a random search algorithm as\na baseline based on the conclusion that transforming the shape of\nthe spanning tree can lead to diverse feasible solutions. Drawing in-\nspiration from the Kruskal algorithm [28] employed in constructing\nminimum spanning trees, we arrange all edges in ascending order\nbased on their weights. For unweighted graphs, the order of edges\nis randomized. In each iteration, the edge sequence is randomly\nshuffled, and subsequently, the spanning tree T, of the graph G is"}, {"title": "5 EXPERIMENTAL EVALUATION", "content": "This section discusses our experimental setup and results. As a case\nstudy, we provide a specific real-world application of MMCP."}, {"title": "5.1 Experimental Setup", "content": "We conduct extensive experiments to evaluate the practical ef-\nfectiveness of the proposed method. Here we briefly describe the\nhardware, datasets, baselines, and evaluation metrics.\nImplementations. We implement the PIONEER by Python 3.7.11\nand PyTorch 1.9.2. All experiments are conducted on an Ubuntu ma-\nchine with NVIDIA GeForce RTX 3090 (24 GB VRAM) and Intel(R)\nXeon(R) Platinum 8260 CPU @ 2.40GHz (256 GB RAM). For the\nunsupervised solver, the training, validating, and testing datasets\nuse an 8:1:1 dataset split, and each synthetic dataset contains 10,000\ngraphs. In addition, in the interest of fairness, our unsupervised\nsolver and [24] share the same neural network structure and param-\neter setting without the GAT layer. We refer interested readers to\n[24] for more details. Given the significant variations and sparsity\nobserved in real-world datasets, we select the suitable \u03b1 based on\nparameter study in Appendix C.2.2. We set a = m/n for synthetic\ngraphs, allowing the model to explore the solutions that yield larger\nobjective values. For the random tree search, we report the best\nresult by running the algorithm for 500 rounds. Our code can be\navailable at https://github.com/luckyseasalt/PIONEER.\nDatasets. We assess our methods in a wide variety of experiments,\nrigorously conducted on synthetic and real-world datasets. Real-\nworld datasets are all unweighted graphs, including, ENZYMES [49],\nIMDB [25], and REDDIT [47] datasets. Noteworthy, the real-world\ndataset also includes actual power grids and associated parameters.\nSynthetic datasets are constructed with 36 vertices based on the\npictures in MNIST [5]. There are 60, 000 pictures in Mnist which cor-\nrespond to different one-digit [5]. The construction of the synthetic\ndatasets is inspired by [38]. Here, we first generate a complete graph\nG as a motherboard. We associated each edge with $ = {0,1}|E|\nand each vertex with the picture. Thus, synthetic graphs can be\nbuilt by a random sequence & whose element denotes whether the\ncorresponding edge in G exists. We give an instance in Figure 4.\nConsidering the impact of various graph structures and the re-\nquirements of our framework, constraints can be imposed on the\nrandom graph generation process to obtain different types of graphs.\nIt should be noted that the unsupervised solver is employed to han-\ndle graphs that have undergone graph partitioning. Hence, we focus\non the scenario without bridges when creating the dataset. In sum-\nmary, the synthetic Mnist datasets are classified into two primary\ntypes, i.e. isomorphic graphs and heterogeneous graphs with the\nnotation 'I-36 m' and 'H-36', where m is the number of edges. More\nconfigurations of all datasets are described in Appendix C.1.\nBaselines. As few algorithms can be fully adapted to solve MMCP,\nwe mainly designed the brute force algorithm and the random\nalgorithm, which can individually obtain the exact and approximate"}, {"title": "5.2 Main Results", "content": "Table 1, 2 and 3 report the results on synthetic datasets and real-\nworld datasets, respectively. Note that the results of the brute force\nalgorithm are not included because it is still too time-consuming\neven when adopting graph partitioning to simplify. All methods\nare graphically simplified and accelerated by graph partitioning.\nIn summary, the proposed PIONEER achieves better solutions\nthan the competitors on all datasets and runs quickly. The re-\nsults show that PIONEER exhibits superior performance in solving\nMMCP with various graph structures. We discuss the results of\neach task in more detail below. Note that the best results among\nthe methods are highlighted in bold across all Tables.\nExperiments on synthetic datasets. The results of the synthetic\ntasks are shown in Table 1, where PIONEER demonstrates com-\npetitive performance across all datasets. It consistently delivers\nsolutions of the highest quality while maintaining a rapid process-\ning speed. Surprisingly, the random tree search method achieves\nacceptable results within a relatively short time frame, benefiting\nfrom Theorem 4. However, the performance of the proposed ran-\ndom algorithm weakens as the number of edges increases. This"}, {"title": "5.3 Ablation Study", "content": "To validate the effectiveness of the key components in PIONEER,\nwe conduct ablation studies on all aforementioned datasets. Only\ntwo critical results are reported here.\nw/o Unsupervised solver. We remove the unsupervised solver\nin our framework and directly construct a random spanning tree\nas input for the heuristic solver to evaluate the effectiveness of\nthe unsupervised solver. As can be seen in Figure 5, the variant\nwithout an unsupervised solver can solve with almost the same\nquality as PIONEER (Avg. 3750.48 vs 3756.20). However, the speed\nof implementation of the two showed marked differences (Avg. 9.45\ns/g vs 5.54 s/g). This is an interesting finding that the unsupervised\nsolver serves as an effective starting point for the heuristic solver,\nleading to a substantial improvement in search speed.\nw/o Heuristic solver. Similarly, we assess the heuristic by directly\ntaking the output of the unsupervised solver as a result. The results\nare summarized in Table 4, showing the heuristic solver plays a cru-\ncial role in repairing and enhancing the solutions. Encouragingly,\nalthough the unsupervised solver does not yield optimal solutions,\nits fastest running speed and acceptable solution quality are also im-\npressive. Furthermore, we have observed that unsupervised solvers\nexhibit surprisingly effective performance in tackling MMCP for\ndense graphs with fast speed."}, {"title": "5.4 More Results", "content": "We conduct more experiments to further analyze the key compo-\nnents and parameters of PIONEER. For detailed information, please\nrefer to Appendix C.2 due to space limitations.\nSupplemental ablation study. To validate the effectiveness\nof graph partitioning, rounding, and the upper bound \u03bb3 (G), ad-\nditional ablation experiments are performed. The results indicate\nthat graph partition can dramatically accelerate execution, the pro-\nposed rounding methods improve the ability to generate constraint-\nsatisfying solutions, and \u03bb3 (G) enables the model to better learn\nthe bi-connectivity for different graph structures.\nParameter study. Parameter experiments are conducted to\nstudy the key parameters, including the balanced control parameter\n\u03b1 and the self-adaptive coefficient e. The results show that suitable\n\u03b1 and e can enhance the learning process of the unsupervised solver,\nleading to improved quality and legality of the solutions.\nPerformance guarantee study. Our method avoids the intri-\ncate analysis of loss monotonicity, ensuring Theorem 3 through\ndeterministic rounding. When the relaxed loss is successfully mini-\nmized to a sufficiently small value, the inequality L(S; G) < L(\u015c; G)\n< \u03b1 \u00b7 \u03b2 is satisfied, yielding low-cost and feasible solutions.\nHeuristic study. A constraint checking is incorporated into a\ngenetic algorithm to perform a comparative study. The algorithm\nis provided in Appendix B.5. The results reveal that exploring solu-\ntions from spanning trees is significantly superior to the method of\nobtaining cuts and subsequently determining their legality."}, {"title": "5.5 Case Study", "content": "Recall that we mentioned a demand for the power grid motivating\nthis work. Therefore, we utilize the task of cross-section identi-\nfication in the power grid as a case study. We leave the problem\nstatement and the visualization of solutions in Appendix C.2.5.\nWe study the performance of PIONEER on the power grid of\ncertain regions. Due to the confidentiality of power grid data, we\nonly give some important details in the Appendix C.1. Additionally,\ntraining is not feasible due to the limited dataset containing only\nthree graphs. Therefore, we utilize models trained on the REDDIT\ndataset, which exhibits relative similarity to the power grid.\nAs shown in Table 5, our method exhibits superior performance\nacross all cases. Notably, PIONEER appears to take more time on"}, {"title": "6 CONCLUSIONS AND FUTURE WORKS", "content": "In this paper, we propose a novel unsupervised learning framework\ncombined with heuristics named PIONEER for MMCP. In particular,\nwe demonstrate the theoretical foundation of graph simplification\nand the equivalent form of solutions for MMCP. On these bases, we\ndesign an unsupervised framework with mathematical guarantees,\nwhich is not only sufficiently rapid in acquiring acceptable solu-\ntions independently but also enhances the speed of downstream\nsolvers. We also construct a heuristic solver for further repairing\nand improving the quality of solutions. Extensive experiments man-\nifest that PIONEER outperforms the baselines in various graph\nstructures with good generalization. In the future, one promising\ndirection is to enhance the ability of the unsupervised solver to han-\ndle sparse graphs. Another interesting theme is to explore a more\nexplicit relationship between spanning trees and optimal solutions."}, {"title": "A THE PROOF AND RELATED THEOREM", "content": "A.1\nProof of Theorem 1\nPROOF. Consider whether ed is in the cut-set F of G. If ed \u2208 F", "21": ".", "holds": "n$\\displaystyle \\lambda_{i}(H) + \\lambda_{n}(U) \\leq \\lambda_{i}(H + U) \\leq \\lambda_{i}(H) + \\lambda_{1} (U), i = 1, ..., n.$\nEndow Ch with the Euclidean inner product (,) which is anti-\nlinear in the second coordinate. For u \u2208 Cn, the linear rank one\nmap u \u2297 u = uu*.\nThen, we can draw the following corollary.\nCOROLLARY 1. Let H be an \u00d7 n Hermitian matrices with ordered\neigenvalues \u03bb\u2081 \u2264 ... \u2264 \u03bbn. For nonzero vector u \u2208 Cn and n \u2265 2,\nlet the eigenvalues of Z = H + u \u2297 u be \u00b5\u2081 <\u2264 .. \u2264 \u00b5n. Then the\neigenvalues of H and Z interlace,\n$\\displaystyle \\lambda_{1} \\leq \\mu_{1} \\leq \\lambda_{2} \\leq \\mu_{2} \\leq .. \\leq \\lambda_{n} \\leq \\mu_{n}.$\nWith these preliminaries, we then prove Theorem 2.\nPROOF. Let L be a Laplacian matrix of graph G, without loss\nof generality, we remove an edge euv from G in turn to obtain\nsubgraphs G' of G. We consider the variation of the adjacency\nmatrix from the subgraph G' to G when removing one edge euv\nfrom G.\n$\\displaystyle L(G') = \\begin{cases}\nL(G) & \\text{lii}\\\\\n  a_{ij}, & \\text{lij, i \\neq j}\n\\end{cases}$\n$\\displaystyle \\Delta L = L(G' + e) - L(G') = \\begin{cases}\n a_{ij},& \\text{luv, lou}\n\\end{cases}$\n$\\square$\nA.3 Proof of Theorem 3\nPROOF. Let w($) = \u2211i,j\u2208V,i<jwij(\u00c2\u00a1 \u2212 \u00eej)\u00b2 denote a weight\nobtained by a relaxed solution S = A\u011d(G), x \u2208 [0, 1"}]}