{"title": "FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning", "authors": ["Evelyn Ma", "Rasoul Etesami", "Chao Pan", "Han Zhao", "Olgica Milenkovic"], "abstract": "The performance of Transfer Learning (TL) significantly depends on effective pretraining, which not only requires extensive amounts of data but also substantial computational resources. As a result, in practice, it is challenging to successfully perform TL at the level of individual model developers. Federated Learning (FL) addresses these challenges by enabling collaborations among individual clients through an indirect expansion of the available dataset, distribution of the computational burden across different entities, and privacy-preserving communication mechanisms. Despite several attempts to devise effective transferable FL approaches, several important issues remain unsolved. First, existing methods primarily focus on optimizing transferability within local client domains, thereby ignoring transferability over the global learning domain. Second, most approaches focus on analyzing indirect transferability metrics, which does not allow for accurate assessment of the final target loss and the degree of transferability. To address these issues, we introduce two important FL features into the model. The first boosts transferability via an exchange protocol between the clients and the server that includes information about cross-client Jacobian (gradient) norms. The second feature promotes an increase of the average of the Jacobians of the clients at the server side, which is subsequently used as a local regularizer that reduces the cross-client Jacobian variance. A rigorous analysis of our transferable federated algorithm, termed FedGTST (Federated Global Transferability via Statistics Tuning), reveals that increasing the averaged Jacobian norm across clients and reducing the Jacobian variance ensures tight control of the target loss. This insight leads to an upper bound on the target loss of transferable FL in terms of the source loss and source-target domain discrepancy. Extensive experimental results on datasets including MNIST \u2192 MNIST-M and CIFAR10 \u2192 SVHN suggest that FedGTST significantly outperforms other relevant baselines, such as FedSR. For example, on the second source-target dataset pair, we improve the accuracy of FedSR by 9.8% and that of FedIIR by 7.6% when the backbone used is LeNet.", "sections": [{"title": "Introduction", "content": "Transfer Learning (TL) has received significant interest in the machine learning community due to its ability to extract representative features from source tasks and use them to improve the generalization capability on related target domain problems [47, 51]. In addition to boosting the performance of a target domain model, TL also reduces the computational cost of fine-tuning the target domain model. Nevertheless, effective source pretraining in TL is practically challenging for individual model developers because it requires access to large datasets as well as significant computational resources [35]. To resolve this problem, one can leverage Federated Learning (FL), which refers to decentralized learning protocols used in mobile and IoT devices [18]. FL not only increases access to multiple datasets in a decentralized manner and alleviates the computational burden of individual clients, but it also protects the privacy of local data [32]. As a result, a number of recent works have outlined methods for transferable FL, including FedADG (Federated Adversarial Domain Generalization) [54], FedCDG (Federated Contrastive Domain Generalization) [52], FedSR (Federated Simple Representations) [34], FedIIR (Federated Implicit Invariant Relationships) [12], FedCCST (Federated Cross-Client Style Transfer) [4] and StableFDG (Stable Federated Domain Generalization) [36]. Despite the promising initial findings provided by the aforementioned techniques, several combinations of important issues remain unsolved across the spectrum of methods.\nWith respect to privacy leakage, the drawabacks of a collection of the methods are as follows: 1. FedADG forces each client source domain to align its representation distribution with that of the target domain, and therefore violates data privacy because source domains are given access to the target domain in order to perform the alignment; 2. FedCCST boosts global transferability by increasing local diversity to avoid local overfitting. It therefore requires clients to share their local representations with each other and this information is subsequently used for local data augmentation. This is a direct violation of FL privacy constraints; 3. StableFDG expands local data diversity by sharing style statistics (i.e., representations, including means and variances). This clearly leads to leakage of local privacy-sensitive information.\nWith respect to local overfitting, the shortcomings of a group of the aforementioned methods are as follows: 1. FedSR learns a simple representation through regularization during local training, by exploiting the similarity between the representation and the data, given the labels. However, since the regularized local training relies completely on local structures (i.e., local models, representations, labels, data), it leads to overfitting of local distributions, and thus has limited capability to learn cross-client invariant features, which is key for global transferability; 2. FedCDG uses a contrastive local regularizer on representations generated by various samples within the same class. This leads to overfitting in the local domain since no cross-client information is exploited.\nWith respect to communication complexity, we observe that: 1. FedIIR is suboptimal. Although it mitigates the problem of privacy violation and avoids local overfitting by adding a local regularizer capturing the distance between the local gradient and the global gradient, it requires communicating gradients between the clients and the server and therefore doubles the communication cost compared to baselines (additionally, FedIIR performs well for a large number of clients, but offers average performance when this number is small); 2. Similar communication complexity problems are faced by FedCCST and StableFDG, which rely on communicating styles (i.e., representations).\nFinally, prior works mostly lack explicit theoretical analyses of global transferability: they do not tend to quantify the performance/loss of the pretrained model fine-tuned on the target domain.\nIn summary, the most important unresolved problem with known transferable FL models (with the exception of FedIIR) is that they use centralized TL approaches during local training, and do not fully exploit features specific to federated learning (for details, see also the discussion in Section 2).\nOur contributions. We describe what is, to the best of our knowledge, the first approach to federated transfer learning termed Federated Global Transferability via Statistics Tuning (FedGTST) that simultaneously alleviates the above issues faced by existing methods. Our main contributions can be summarized as follows.\n1. We use a new regularizer that encodes cross-client statistics and forces the local training process to tune the global statistics in a \"direction\" that improves global transferability rather than just local transferability. This is achieved through subtractions of global norms of Jacobians (gradients) communicated by the server."}, {"title": "Related Work", "content": "FL is a machine learning paradigm in which multiple entities collaborate to train a global model without sharing their local data (see [15] for a comprehensive review). FL has gained significant attention due to its potential to address privacy concerns while enabling large-scale collaborative learning [43]. Relevant to this work, [32] proposed the Federated Averaging (FedAvg) algorithm, which aggregates model updates from multiple client devices to train a global model. Another relevant line of work [50] introduced FedProx, a federated optimization algorithm that incorporates proximal terms to handle non-iid data distributions. FL methods nevertheless still face several challenges. One challenge is dealing with highly heterogeneous local datasets [26], for which the recent work FedImpro[45] proposed leveraging aggregated feature distributions to address client drift. Another challenge is the communication overhead incurred during the aggregation of model updates [2]. Minimizing communication costs while ensuring convergence and data privacy remain active topics of research in FL. Also, many FL solutions primarily emphasize performance in the client domain without considering the performance of the model on unseen domains.\nTL is a powerful machine learning technique that allows models to leverage knowledge gained from one task to improve performance on another related task [35]. TL has been widely adopted in various domains such as computer vision, natural language processing, and speech recognition, where labeled data may be scarce or expensive to acquire [46, 47]. A common approach in TL involves fine-tuning a pre-trained model on a target task using a small amount of labeled data, which often leads to improved generalization and faster convergence compared to training from scratch [51]. Recent works in TL have focused on developing more effective algorithms, such as domain adaptation methods that address the discrepancy between the source and target domains [11]. Additionally, TL techniques have been used to handle tasks with limited amounts of labeled data through techniques like semi-supervised and self-supervised learning [40]. TL still faces challenges such as negative transfer, where information from the source task actually degrades performance on the target task; and, it requires careful selecting of appropriate pretrained models and transfer strategies for specific tasks and domains [35]. Current TL methods often require that one entity possesses knowledge of all data, violating the privacy requirements of FL. Moreover, we comment on Gradient Matching in TL in Appendix I.1\nTransferable Federated Learning (TFL) is an emerging research area at the intersection of FL and TL. One of earliest contributions to the field, FedADG [54], encourages the transferablity of FL through adversarial local training. However, the work does not provide theoretical guarantees, and existing studies [49] indicate that adversarial robustness does not necessarily lead to better transferability. Other methods, such as FedSR [34] and FedCDG [52], enhance transferability by adapting standard representation learning from a single-agent to a federated setting; they do not incorporate FL-specific features (i.e., instructions provided by the server, cross-client model properties etc). Note that although FedSR has successfully included centralized invariant feature learning into FL, it uses centralized methods locally and then shares information with the global model, and"}, {"title": "Preliminaries", "content": "General Supervised Learning Settings. We denote the data space by X, the feature space by Z, and the label space by Y. A model $h : X \\rightarrow Y$ typically takes the form $h = g \\circ f$, where $f : X \\rightarrow Z$ is a feature extractor and $g : Z \\rightarrow Y$ is a classifier. Denote the function class for the entire model, the feature extractor and the classifier by H, F, G, respectively, so that $h \\in H, f \\in F, g \\in G$. Denote the weights of model $\\psi \\in \\{f,g,h\\}$ as $w_\\psi$. Given a loss function $l : Y \\times Y \\rightarrow \\mathbb{R}$ and a domain distribution D over X \u00d7 Y, the population loss $L_D(h)$ is defined as\n$L_D(h) := \\mathbb{E}_{(x,y)\\sim D} l (h(x), y) .$ \nGeneral Framework of TFL. In TL, the two typical learning phases are: a) pretraining on the source domain; and, b) finetuning on the target domain. In the context of TFL, pretraining is conducted via FL over source (local) domains, while the global model is trained and then finetuned on the target domain during the second phase. In both phases, supervised learning is performed with full access to the labels. More details are provided next.\nPretraining Phase in TFL: FL on Source (Local) Domains. The source domain is a composition of the agents' local domains, $\\{D^{(k)}\\}$, with $k \\in [K]$ denoting the client index and K representing the total number of clients. The source loss is defined as the standard federated loss on the source domains.\n$L_{src}(g \\circ f) := \\frac{1}{K}\\sum_{k=1}^K L_{D^{(k)}} (g \\circ f).$ \nLet $h^* = g^* \\circ f^*$ be an optimal global solution for the objective (2). In FL approaches, the problem solution is the result of the central server's aggregation of local models into a global one. We denote the local solutions involved in creating the optimal global solution $\\psi^* (\\psi \\in \\{f,g,h\\})$ by $\\{\\psi^{*(k)}\\}$; through averaging aggregation, we obtain the optimal global weights $w_{\\psi^*} = \\frac{1}{K}\\sum_k w_{\\psi^{*(k)}}.$\nFinetuning Phase in TFL: Supervised Finetuning on the Target Domain. Upon obtaining the optimal pretrained global solution $h^* = g^* \\circ f^*$, the pretrained feature extractor $f^*$ is fixed and applied to the target domain $D_T$. The target loss is defined as the loss on the target domain $D_T$, i.e.,\n$L_{tgt}(g \\circ f^*) := L_{D_T}(g \\circ f^*).$ \nThrough finetuning, a new classifier $g_T^* := \\arg \\inf_{g\\in g} L_{tgt}(g \\circ f^*)$ is determined by minimizing the target objective (3).\nTransferability Assessment. With a slight abuse of notation, we define the optimal target loss as\n$L_{tgt}^* := L_{tgt}(g_T^* \\circ f^*).$ \nWe formally define the measure of transferability of TFL as the optimal target loss $L_{tgt}^*$, as it directly reflects the performance of a transferable model on the target domain. A smaller $L_{tgt}^*$, or a tighter bound on it, indicates better transferability."}, {"title": "Theoretical Bounds on the Target Loss", "content": "4.1 A General Bound Based on Discrepancy/Divergence\nWe start with Definitions 1 and 2 borrowed from existing TL studies that characterize the domain discrepancy, and then propose a new domain divergence tailored to Transferable FL (TFL), including the cross-client discrepancy in Definition 2 and the source-target discrepancy in Definition 3."}, {"title": "Practical Bounds Based on Cross-Client Statistics", "content": "The goal of FL is to estimate the optimal solution $f^*$ by updating the global model through multiple federated rounds 1. Denote the total number of rounds by P and the output global model after round P by $f_p$. Denote the target loss under $f_p$ instead of $f^*$ as $L_{tgt}^*$ (which is an estimate of $L_{tgt}^*$). At the end of local training during any round p < P, let $h_p^{(k)}$ with weight $w_p^{(k)}$ represent the model of client k, and let $h_p$ with weight $w_p$ represent the global model. Denote the Jacobian (gradient) of the loss $l$ w.r.t the model weights at domain k as $J_p^{(k)}(w) = \\mathbb{E}_{D^{(k)}} \\nabla_{w_h}l(h(x), y)|_{w_h=w}$.\nThroughout the remainder of the manuscript, we use $J_p^{(k)}$ as shorthand for $J^{(k)}(w_p)$. Furthermore, we denote the learning rate of agent k at round p by $\\lambda_p^{(k)}$. We make a single-step local update assumption (Assumption 4.2) and use the definitions for cross-client statistics (Definition 4) to derive bounds exploiting the cross-client statistics from Lemma 4.1 and Theorem 2).\nAssumption 4.2 (Single-Step Local Update). During local training, all clients perform one step of gradient descent (GD) to update their model for transmission, $w_{p+1}^{(k)} = w_p - \\lambda_{p+1}^{(k)} J_p^{(k)}(w_p)$. This is a common assumption in the FL literature [30, 32]. 2\nDefinition 4 (Cross-Client Statistics). At federated round p, given K clients with local Jacobians $\\{J_p^{(k)}\\}_{k\\in[K]}$, we define the cross-client averaged Jacobian norm $|| J_p||_2$ and the cross-client Jacobian variance, respectively, as\n$||J_p||_2= \\frac{1}{K}\\sum_{k} ||J_p^{(k)}||_2 \n\nd_p^2 = \\frac{1}{K}\\sum_{k} ||J_p^{(k)}||_2^2 - \\frac{1}{K^2} ||\\sum_k J_p^{(k)} ||_2^2$ \nNote that we assumed the loss function to have a $\\alpha$-Lipschitz continuous gradient. When the gradient is large, $\\alpha$ is also large, and to make $\\beta_1(\\lambda) \\geq 0$, $\\lambda$ has to be close to 0. In this case, the absolute value of the second term can be small and that of the third term can be large.\nLemma 4.1 (Loss Bound Using Cross-Client Statistics). Under Assumptions 4.2 and 4.1, and the cross-client statistics defined in Definition 4, after P rounds of federated pretraining one has\n$L_{tgt} \\leq L_{src} (h_0) - \\sum_{p=0}^{P-1} \\beta_1(\\lambda_{p+1})||J_p||_2 + \\sum_{p=0}^{P-1} \\beta_2(\\lambda_{p+1})\\sigma_p^2 + d_{G,F}(D_{fed}, D_T),$ \nwhere $h_0$ is the initial global model and $\\beta_2(x) = \\alpha \\lambda^2$, $\\beta_1(x) = x - \\beta_2(\\lambda)$.\nNote that during the training process, a large Jacobian norm can promote transferability (the Jacobian is expected to be small at the end of training).\nInterpretation of Key Terms. Lemma 4.1 shows that the target loss of the finetuned pretrained model (LHS) is bounded by a sum (RHS) involving four key terms: 1) $L_{src}(h_0)$, the initial source loss; 2) $|| J_p ||_2$, the cross-client averaged Jacobian norm; 3) $\\sigma_p^2$, the cross-client Jacobian variance; 4) $d_{G,F}(D_{fed}, D_T)$, the TFL-specific source-target domain divergence. Since $L_{src}(h_0)$ is fixed throughout the pretraining process, and $d_{G,F}(D_{fed}, D_T)$ can be reduced using general regularization, we focus on analyzing the two tunable cross-client statistics, $||J_p||_2$ and $\\sigma_p^2$."}, {"title": "Our Algorithm", "content": "Algorithmic Solution for the Theoretical Challenges. From Lemma 4.1 and Theorem 2, we can see that certain round-wise FL-specific statistics, the cross-client averaged Jacobian norm $||J_p||_2$ and cross-client Jacobian variance $\\sigma_p^2$ control the bound on the target loss. The challenge is that, while $\\sigma_p^2$ can be reduced using straightforward techniques (i.e., such as gradient alignment from FedIIR [12]), such techniques unavoidably prevent $J_p$ from increasing properly. We therefore propose our FedGTST approach which reduces $\\sigma_p^2$ while enlarging $||J_p||_2$. A round-wise description of FedGTST is given in Algorithm 5.\nTuning the Cross-Client Jacobian Variance $\\sigma_p^2$. The cross-client Jacobian variance is controlled via regularization at the local client level (Line 5 of Algorithm 5). The local clients, upon receiving a"}]}