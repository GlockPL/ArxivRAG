{"title": "Enhancing Frame Detection with Retrieval Augmented Generation", "authors": ["Papa Abdou Karim Karou Diallo", "Amal Zouaq"], "abstract": "Recent advancements in Natural Language Processing have significantly improved the extraction of structured semantic representa-tions from unstructured text, especially through Frame Semantic Role Labeling (FSRL). Despite this progress, the potential of Retrieval-Augmented Generation (RAG) models for frame detection remains under-explored. In this paper, we present the first RAG-based approach for frame detection called RCIF (Retrieve Candidates and Identify Frames). RCIF is also the first approach to operate without the need for explicit target span and comprises three main stages: (1) generation of frame embeddings from various representations; (2) retrieval of candidate frames given an input text; and (3) identification of the most suitable frames. We conducted extensive experiments across multiple configurations, including zero-shot, few-shot, and fine-tuning settings. Our results show that our retrieval component significantly reduces the complexity of the task by narrowing the search space thus allowing the frame identifier to refine and complete the set of candidates. Our approach achieves state-of-the-art performance on FrameNet 1.5 and 1.7, demonstrating its robustness in scenarios where only raw text is provided. Furthermore, we leverage the structured representation obtained through this method as a proxy to enhance generalization across lexical variations in the task of translating natural language questions into SPARQL queries.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have significantly contributed to better semantic representations of natural language sequences, as witnessed by their state-of-the art performance in several natural language understanding tasks. However, LLMs are prone to a degradation of performance depending on their natural language input or prompt, which leads to limitations in terms of robustness and generalization (Leidinger et al., 2023; Meng et al.; Zheng et al., 2023). Our high-level objective in this work is to explore if structured representations of natural language input, and more precisely frame semantics, can contribute to more robust models. Another objective is to explore a RAG-based approach for frame detection. Frames, as defined in Frame Semantics (Baker et al., 1998), are conceptual structures that capture the semantic and syn-"}, {"title": "Related Works", "content": "The literature on frame parsing can be broadly divided into two main approaches: methods that frame the task as a sequence-to-sequence (Seq2Seq) generation problem and methods based on representation learning.\nSeq2Seq approaches (Sutskever, 2014; Raffel et al., 2020; Kalyanpur et al., 2020; Chanin, 2023) define frame parsing as a generative task, decomposing it into subtasks such as trigger identification, frame classification, and argument extraction. These methods leverage pre-trained language models and task-specific optimizations to balance the subtask distributions and mitigate data scarcity (Kalyanpur et al., 2020; Chanin, 2023). As illustration, models like T5 (Raffel et al., 2020) are pre-trained on PropBank (Kingsbury and Palmer, 2002, 2003) and FrameNet exemplars, with text augmentation techniques applied to improve ro-bustness and FrameNet lexical units incorporated to enhance frame classification accuracy. Then, they are fine-tuned on each of the aforementioned sub-tasks. For exemple, (Kalyanpur et al., 2020) adopt a shared encoder with specialized decoders for each sub-task, enabling the model to leverage a common representation while handling each task independently within the same architecture. The Seq2Seq methods share a focus on utilizing the flexibility of generative models to capture the sequential nature of frame parsing tasks.\nRepresentation learning approaches, in contrast, focus on constructing enriched embeddings that align sentence-level context (or just the target span) with candidate frames (Hartmann et al., 2017; Jiang and Riloff, 2021). They often employ graph-based techniques, such as Graph Neural Networks (GNNs) (Wu et al., 2020), or contrastive learning (Ju et al., 2024) to incorporate external knowledge and enhance the robustness of frame repre-sentations. These methods also emphasize seman-tic alignment through embedding techniques that integrate knowledge from FrameNet's structure."}, {"title": "Frame semantic parsing", "content": "tactic relationships underlying language. They are helpful in providing a structured semantic context for understanding relationships between entities, enabling tasks like Machine Reading Comprehension (Guo et al., 2020; Flanigan et al., 2022; Bonn et al., 2024) and Information Extraction (Su et al., 2021; Li et al., 2024b; Chanin, 2023; Su et al., 2023) to be more accurate and contextually aware. Each frame represents a specific type of situation, event, or object along with the roles (or frame elements) associated with it. Frame identification involves selecting the most suitable semantic frame for a target word in a sentence context. Generally, state-of-the-art approaches require to indicate, in a free-form text, the explicit target for which a frame should be found. Consequently, they struggle to generalize to text without explicit targets, limiting their utility in broader downstream tasks, where these targets are not necessarily known.\nTo solve these aforementioned limitations, our proposed method called RCIF (Retrieve Candidates and Identify Frames) for frame detection, as depicted in Figure 1, leverages a RAG framework combined with a generative large language model (LLM) functioning mostly as a classifier. The approach operates in three main stages. First, we generate embeddings for candidate frames based on a variety of representations, including frame labels, descriptions, lexical units (LUs), and frame elements (FEs), and store these embeddings in a vector database. Next, for a given text input, we retrieve frames with the highest similarity scores as candidate frames. Finally, a generative LLM selects the best-matching frames from these candidates, effectively acting as a classifier. Given the hypothesis that structured representations have the potential to bridge the gap between different lexical variations of the same text, we utilize frames as an intermediate structured representation to translate natural language questions into SPARQL queries. The contributions of this paper are as follows:\n1.  We present the first approach that leverages a RAG model for frame detection.\n2.  We also introduce the first method to perform target-free frame detection directly from text. This makes our framework more useful for any text that does not have a predefined target.\n3.  Finally, we demonstrate that the structured representations obtained through this approach has the potential of improving the gen-"}, {"title": "SPARQL queries generation", "content": "eralization of SPARQL query generation for different lexical variations of a question.\nOverall, our approach not only enhances frame detection accuracy but also addresses the challenge of target-free input by dynamically narrowing the search space to relevant frames, improving both recall and precision in frame identification."}, {"title": "Methodology", "content": "To ensure a fair comparison with prior work, we assess our model's performance on FrameNet 1.5, adhering to the original train/dev/test data splits established by (Das et al., 2014). Additionally, we extend our evaluation to FrameNet 1.7, released in 2016, which offers approximately 20% more gold-standard annotations compared to FrameNet 1.5. For both FrameNet 1.5 and FrameNet 1.7, we follow the data splits defined by An et al. (An et al., 2023)."}, {"title": "Concepts definition and task description", "content": "A FrameNet frame $f$ is defined by its label, representing its name, and accompanied by a textual description that provides a comprehensive explana-tion of its semantics. Each frame is further characterized by a set of frame elements (FEs), which serve as its core semantic components, capturing contextual and relational information about the frame. Additionally, frames are associated with a set of lexical units (LUs), consisting of lemmas paired with their parts of speech, which denote the frame or specific aspects of it. Within a sentence, tokens (words or phrases) that evoke a frame are referred to as targets.\nWe formulate our task as the detection of frames $f_1,..., f_j$ within a sentence $S = W_1, ..., W_n$, without any predefined target span for frame triggering. This formulation reflects real-world applications, where the input typically consists of raw text, and frames must be identified directly from it. Unlike approaches such as CoffTea (An et al., 2023) and related works that rely on both a sentence and a specific target span $t = w_{ts}, ..., w_{te}$ (with $w_{ts}$ and $w_{te}$ respectively corresponding to the start and the end of the target span) to identify a single frame, our model, RCIF, is designed to identify frames in the absence of such target span information.\nThe original dataset consists of entries such as the sentence \"I was sad when I could n't go to the snack bar to buy a soda.\" where the underlined span is the target whose position is provided as well as the frame which is \"Commerce_buy\" and its definition. Thus, the entry is repeated as many times as there are target spans or possible frames for the same sentence with, for every instance, a new target span and a new frame.\nTo generalize over target-less raw text, we adapt the original dataset by grouping frames by sentence so that each unique sentence is associated with all the frames it evokes. For instance, the six occurrences of the previous sentence are merged into a single entry, discarding information about the target and retaining only the following list of possible frames such as \"Emotion_directed\", \"Capability\", \"Likelihood\", \"Locative_relation\", \"Goal\", \"Com-merce_buy\" and \"Temporal_collocation\". As one can see, this new dataset formulation constitutes a harder task than the previous one. We thus address this problem by first retrieving a set of candidates and then identifying the appropriate frames, as de-tailed in Section 3.3."}, {"title": "Retrieval of candidates", "content": "In this phase, we employ a frozen-RAG model to facilitate candidate retrieval. For the retrieval com-ponent, we compare different frame representations using labels, descriptions, lexical units (LUs), or frame elements (FEs). We systematically explore all these options, generating embeddings for each frame representation, which are then stored in a vector database, as illustrated in Figure 3 in Appendix A.1. When processing a new text, we gen-erate its vector embedding and perform a similarity search to retrieve the top $k$ candidates based on sim-ilarity scores. For embedding generation, we uti-lize the English version of BGE2 (Li et al., 2024a; Xiao et al., 2023). BGE is a unified embedding model designed to produce general-purpose text embeddings applicable to diverse tasks, including retrieval, ranking, and classification, across settings such as question answering and conversational sys-tems. The model employs a BERT-like architec-ture, utilizing the hidden state of the [CLS] token"}, {"title": "Identification of frames", "content": "Identifying the set of frames evoked by a sentence without a specified target span presents significant complexity, influenced by sentence length and the total number of frames in the lexicon (1019 in FrameNet 1.5 and 1221 in FrameNet 1.7) (see Figure 4 in Appendix A.2). To address this, we reduce the search space by generating a list of potential frame candidates that guide the model towards the correct frames. This is achieved through an initial retrieval component (described in section 3.3) that provides a list of candidates prior to using a pretrained LLM to finalize frame selection. The LLM is fine-tuned in an Instruction-Input-Output format. This prompt design allows the fine-tuned model to not only gain inspiration from the retrieved candidates but also to consider frames identified in previous batches, thereby accommodating retrieval imperfections where some correct frames may not appear in the candidates list. More detail about the prompt and this process is provided in Appendix A.2."}, {"title": "Frames for SPARQL query generation", "content": "In this section, we investigate the role of structured representations in enhancing the generalization of SPARQL query generation across lexical variations of a question. As reported in (Diallo et al., 2024), template-based questions yield higher performance than reformulated natural language questions, indicating that transforming unstructured questions into structured representations has the potential to improve the accuracy and relevance of SPARQL query generation. Thus, we fine-tuned several LLMs including Llama 3.1-8B, Llama 3.2-3B model (Dubey et al., 2024), Phi-4 and Qwen2.5-7B-Instruct. The core of the paper focuses on the best-performing results obtained with Llama 3.1-8B while the results of the other LLMs are provided in Appendix A.3."}, {"title": "Datasets LCQ2F and LCQ2F+", "content": "In order to get datasets of natural language questions that also in-corporate frame semantic parsing, we perform the intersection of the datasets LC-QuAD 2.0 and Wik-iBank that are described in Appendix A.5. The re-sulting dataset LCQ2F of size 2, 963 entries (train:\n2, 146 | val: 224 | test: 593) consists of the subset of LC-QuAD 2.0 (Dubey et al., 2019) questions re-maining after their intersection with WikiBank (Sas et al., 2020) where each question is augmented by the list of frames evoked in it. The construction of LCQ2F is based on the following postulate: given an LC-QuAD 2.0 question NLQ and its correspond-ing SPARQL query Q, along with a sentence S from WikiBank, NLQ evokes the same frame as S if and only if Q and S share the same set of relations and classes from the Wikidata Knowledge Base. When this condition is met, the set of frames evoked in S is attributed to NLQ and subsequently used as augmented information.\nThe dataset LCQ2F+ extends LCQ2F (with the same train, validation and test splits size) by in-corporating additional information, including the textual descriptions of the frames and a detailed list of associated Frame-Elements. This provides richer structured representations to further contextualize the NLQ. For each dataset the splits size double for Combined questions (more details provided in Appendix A.6)."}, {"title": "Results", "content": "Table 3 presents the performance of candidate frames retrieval using the English version of the BGE embedding model (Li et al., 2024a; Xiao et al., 2023). Retrieval is configured to select $K = maxframes = 24$ candidates, which corre-sponds to the maximum number of frames a sen-tence might evoke. This setting is chosen to max-imize recall, ensuring that the subsequent detec-tion/identification stage has a high likelihood of finding relevant frames among the candidate set.\nAs seen in the table, the third frame represen-tation (Representation 3, including frame label and description, the list of frame-elements and lexical-units, yields on average the highest recall, highlighting it as the most effective representation format. Across all datasets and frame represen-tations, precision remains low, a consequence of maximizing recall by retrieving a surplus of frames ($maxframes = 24$) compared to the average need"}, {"title": "Retrieval component", "content": "($avgframes = 5$). This retrieval strategy not only provides the frame detector component with the broadest possible set of relevant candidates, but it also encourages the model during fine-tuning to rely less on parametric memory and more on generalization, enhancing its robustness."}, {"title": "Frame detection", "content": "Experiments. We conducted multiple experi-ments using several models such as Llama 3.2-3B model (Dubey et al., 2024), Llama 3.1-8B, Phi-4, and Qwen2.5-7B-Instruct across three main set-tings: zero-shot, few-shot, and fine-tuning but we just keep the best performing model (Llama 3.2-3B). For each setting, we implemented two configu-rations: one that explicitly indicates the number of frames the model is expected to detect, and another that does not. This distinction allows us to test the hypothesis that, without specifying the number of frames, the model may struggle to accurately de-termine the appropriate number of candidates to select.\nAdditionally, we included a baseline experiment that involves fine-tuning the model to generate frames without leveraging the retrieval component as an initial step.\nResults of frame detection. Table 4 presents the frame detection results of the Llama 3.2 - 3B (Dubey et al., 2024) model fine-tuned for 10 epochs on the complete training sets of FrameNet 1.5 and FrameNet 1.7. While the best accuracy is reported in (Tamburini, 2022) and COFFTEA (An et al., 2023) for FrameNet 1.5, our model achieves higher precision/recall, outperforming prior work by ap-proximately 4 points in recall. This improvement is attributed to the reduction in search space during the retrieval phase and effective de-noising (elimination of irrelevant candidates) by the fine-tuned LLM. Starting with a retrieval phase precision of 5% and a recall of 89% as shown in Table 3, our final model enhances both metrics to around 92%, indicating successful removal of incorrect candi-dates while retaining relevant ones. This effect is even more pronounced in FrameNet 1.7, where our model achieves top performance across all metrics, with a precision of 99% and a recall of 97%, demon-strating that the model effectively filters out incor-rect candidates. The additional training samples in FrameNet 1.7 (26% more than FrameNet 1.5) further contribute to this improvement. Interestingly, specifying the exact number of frames to be gen-erated had minimal impact on performance, some-times even reducing it. This finding is crucial for real-world applications, as providing exact frame counts is often infeasible with out-of-distribution data. Consistent with the task description in sec-tion 3.2, this framework is designed for practical deployment where only the sentence is provided without target or frame count specifications.\nConsistent with findings from (Chanin, 2023) and (An et al., 2023), our experiments using ex-emplar data for training\u2014while testing on the same test split as in previous experiments showed lower performance, as indicated in Table 6. Additionally, when exemplars are used as initial training data (i.e., training with exemplars first and then continuing with the official training split of the two datasets), the performance remains slightly lower compared to not using exemplars at all. We hy-pothesize that this drop in performance stems from the nature of exemplar data, where each sentence typically evokes only one frame, with annotations limited to a single frame per sentence. This charac-teristic makes exemplar data less suitable for train-ing models intended to detect multiple frames per sentence, as previously noted by (Chanin, 2023)."}, {"title": "SPARQL query generation using LCQ2F and LCQ2F+", "content": "In this section we report the LLMs' performance on LCQ2F and LCQ2F+ datasets introduced in Section 3.5.\nTo obtain a comprehensive understanding of the model's behavior, we consider multiple training and testing configurations. At each stage, we eval-uate two training setups: (1) training on template-based questions (raw questions), and (2) training on a dataset that combine template-based and refor-mulated questions as separate entries, each mapped to the same SPARQL query (combined questions)."}, {"title": "Conclusion", "content": "In this paper, we introduced a novel approach called RCIF (Retrieve Candidates and Identify Frames) to frame detection leveraging RAG models. Unlike previous SOTA methods, which rely on predefined spans within the input text for frame detection, our method operates solely on the input text sequence without requiring additional information about the target span. Our proposed pipeline consists of two components: a candidates retriever and a LLM that selects the correct frames from the retrieved set of candidates. This approach demonstrated improved performance over SOTA methods on FrameNet 1.5 and achieved significantly higher performance on FrameNet 1.7, which provides a larger train-ing set. Consequently, our method is well-suited to real-world applications where only raw text is available, and specific spans for frame detection are not predefined. Furthermore, we showed that such structured representations with frames can enhance generalization towards template-free questions, and despite being trained on a relatively small dataset. This result highlights a promising research direction for improving the generalization capabilities of models to handle lexical variations."}, {"title": "Limitations", "content": "One limitation of this study is the relatively small size of the constructed datasets used to evaluate the impact of frame-structured representations on the generalization of SPARQL query generation for reformulated questions. Future research should explore methods for developing larger, high-quality datasets, extending beyond English to include mul-tilingual resources. Additionally, this study is lim-ited to the use of \"frozen-RAG\" for the retrieval component. Exploring trained versions of RAG could be a promising direction for future research."}, {"title": "Frame representations for candidates retrieval component", "content": "For the retrieval component, we compare different frame representations using labels, descriptions, lexical units (LUs), or frame elements (FEs). Figure 3 shows different representations of the frame \"Historic_event\"."}, {"title": "Details about the frames detection component", "content": "As depicted in Figure 4, To reduce the complex-ity of frame detection (shown in 4) using a Large Language Model (LLM), the input comprises a sen-tence alongside a list of potential candidate frames that could be evoked by the sentence, as illustrated in the input of Figure 5. For each candidate frame, we provide its textual description, the list of Frame Elements (FEs), and the list of Lexical Units (LUs)"}, {"title": "Additional experiments with Phi-4 and Qwen2.5-7B-Instruct", "content": "For our additional experiments with alternative large language models (LLMs), we employed two advanced models: Phi-4 and Qwen2.5-7B-Instruct. Phi-4 is a 14B parameter dense decoder-only Transformer model, designed with a focus on high-quality data and advanced reasoning. It was trained on a blend of synthetic datasets, filtered public domain content, and academic resources, ensuring a strong foundation for instruction adher-ence and safety. Through supervised fine-tuning and direct preference optimization, Phi-4 achieves precise alignment and robust instruction-following capabilities. In contrast, Qwen2.5-7B-Instruct is part of the Qwen2.5 model series, featuring en-hanced knowledge, stronger coding and mathemati-cal capabilities, and improved instruction following. It generates structured outputs such as JSON, and excels in handling structured data like tables which"}, {"title": "Overview of LC-QuAD 2.0 and WikiBank", "content": "In this section we introduce the two foundational datasets, LC-QuAD2.0 (Dubey et al., 2019) and WikiBank (Sas et al., 2020), as they form the basis for constructing the derived datasets, LCQ2F and LCQ2F+.\n- LC-QUAD2.0: LC-QuAD 2.0 (Dubey et al., 2019) dataset is a widely used, publicly available bench-mark, consisting of question-query pairs referred to as entries. Each entry comprises a question in English and its corresponding SPARQL query as the target. The dataset was generated automatically using a templates-based approach, where templates align question-query structures with placeholders, later replaced by specific URIs. These aligned pairs are referred to as global templates."}, {"title": "Details about the constructed datasets LCQ2F and LCQ2F+", "content": "For instance, the global template:\nQuestion: \"What is the <1> of <2>?\"\nQuery: SELECT DISTINCT ?uri WHERE {<2> <1> ?uri}\nproduces the following entry:\nEntry Question: \"What is the country with the max individual tax rate?\"\nEntry Query: SELECT ?ent WHERE {?ent wdt:P31 wd:Q6256 . ?ent wdt: P2834 ?obj } ORDER BY DESC (?obj) LIMIT 5\nThe LC-QuAD2.0 dataset comprises a total of 30,225 entries, with 21,761 allocated to the training set, 2,418 to the validation set, and 6,046 to the test set.\n- WikiBank: WikiBank is a multilingual dataset constructed to enhance frame-semantic parsing by aligning semantic structures from Wikidata with sentences from Wikipedia. This resource includes partially annotated sentences in multiple languages, using a heuristic-based approach to extract se-mantic roles and argument structures from knowl-edge base triples. By leveraging distant supervi-sion, WikiBank facilitates cross-lingual transfer and significantly improves semantic parsing per-formance, particularly in low-resource languages. The dataset has demonstrated its utility in training frame-semantic parsers by providing substantial im-provements when integrated into existing parsing frameworks, such as SLING, in both monolingual and multilingual settings. WikiBank contains over 795,000 sentences and 990,000 examples, but it is limited to a set of 247 relations derived from Wikidata, characterized by a highly uneven distri-bution. Although the LC-QuAD2.0 dataset pro-vides the advantage of containing a comprehensive set of questions paired with their corresponding SPARQL queries, it lacks the frame-semantic pars-ing annotations available in WikiBank. To leverage the strengths of both resources, we construct new datasets by intersecting the two."}]}