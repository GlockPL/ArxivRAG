{"title": "Mapping the Neuro-Symbolic AI Landscape by Architectures: A Handbook on Augmenting Deep Learning Through Symbolic Reasoning", "authors": ["Jonathan Feldstein", "Paulius Dilkas", "Vaishak Belle", "Efthymia Tsamoura"], "abstract": "Integrating symbolic techniques with statistical ones is a long-standing problem in artificial intelligence. The motivation is that the strengths of either area match the weaknesses of the other, and - by combining the two - the weaknesses of either method can be limited. Neuro-symbolic AI focuses on this integration where the statistical methods are in particular neural networks. In recent years, there has been significant progress in this research field, where neuro-symbolic systems outperformed logical or neural models alone. Yet, neuro-symbolic AI is, comparatively speaking, still in its infancy and has not been widely adopted by machine learning practitioners. In this survey, we present the first mapping of neuro-symbolic techniques into families of frameworks based on their architectures, with several benefits: Firstly, it allows us to link different strengths of frameworks to their respective architectures. Secondly, it allows us to illustrate how engineers can augment their neural networks while treating the symbolic methods as black-boxes. Thirdly, it allows us to map most of the field so that future researchers can identify closely related frameworks.", "sections": [{"title": "1. Introduction", "content": "Over the last decades, machine learning has achieved outstanding performance in pattern recognition across a range of applications. In particular, in the areas of computer vision (LeCun et al., 1998; Goodfellow et al., 2020; Dosovitskiy et al., 2021; Liu et al., 2022), natural language processing (NLP) (Hochreiter & Schmidhuber, 1997; Mikolov et al., 2013; Vaswani et al., 2017; Devlin et al., 2019), and recommendation systems (He et al., 2017; Zheng et al., 2018; Rashed et al., 2019), neural networks have outperformed more traditional machine learning models. These breakthroughs have led to significant progress in fields such as medicine (Kearnes et al., 2016; Xie et al., 2019; Huang et al., 2019), finance (Deng et al., 2016; Bao et al., 2017), and autonomous driving (Bojarski et al., 2016; Luo et al., 2018)."}, {"title": "Structured reasoning.", "content": "Neural networks are particularly suited for pattern recognition but do not lend themselves well to hierarchical or composite reasoning and do not differentiate between causality and correlation (Lake & Baroni, 2017)."}, {"title": "Data need.", "content": "To achieve robustness in the predictions of neural models, large amounts of data are needed (Halevy et al., 2009; Ba & Caruana, 2014). However, large datasets are unavailable in many applications, making neural networks an unviable choice."}, {"title": "Knowledge integration.", "content": "Given that humans have extensive knowledge in many areas that we try to tackle with machine learning, it would be helpful to integrate this knowledge into models. However, neural networks do not easily support to integrate expert or even common sense knowledge (Davis & Marcus, 2015). Enabling knowledge integration would reduce the amount of required training data and the training cost."}, {"title": "Explainability.", "content": "Neural networks are black-box systems. In other words, it is often impossible to understand how the model reached its predictions for a given input. This can be seen as the inverse of the preceding point. Neural networks are not only not amenable to integrating knowledge but also to extracting knowledge. Lack of explainability has serious consequences for ethics, security, and extending human knowledge (Ribeiro et al., 2016; Samek et al., 2017)."}, {"title": "Guarantees.", "content": "Neural networks compute a probability distribution over possible outcomes. Inherently, outcomes may be predicted that violate constraints, which can be consequential in safety-critical applications (Gopinath et al., 2018; Cardelli et al., 2019; Ruan et al., 2019)."}, {"title": "2. Contributions and Structure of the Survey", "content": "This section describes the contributions of this survey, from which we derive the structure of the remainder of this work."}, {"title": "A gentle introduction to SRL.", "content": "Our first contribution is an in-depth, yet succinct, introduction to SRL in Section 3. To this end, we discuss various concepts of probability, logic, and SRL. We connect the different concepts through examples, which we continuously extend throughout this survey to illustrate the commonalities and differences between the methods. We aim to give enough details to enable a robust understanding of the frameworks discussed in this survey without getting lost in details that are not pertinent."}, {"title": "A map of the neuro-symbolic AI landscape by architectures.", "content": "Our second contribution is a map of the neuro-symbolic AI research area, illustrated in Figure 1, through the lens of the architectures of the different frameworks. At the top level, we distinguish between composite and monolithic frameworks. While composite frameworks keep the symbolic (i.e. logical) and neural components separate, monolithic frameworks integrate logical reasoning directly into the architecture of neural networks. The two groups are, thus, complement of each other. At lower levels of the hierarchy, we differentiate how symbolic and neural components are connected, as well as the types of neural models and inference properties of the symbolic methods used in the frameworks."}, {"title": "A handbook for extending existing AI models with neuro-symbolic concepts.", "content": "Our third contribution is a guide for researchers on how to augment their existing neural networks with concepts from neuro-symbolic AI. We therefore focus primarily on composite frameworks (Section 4). As these frameworks tend to be model agnostic, they allow for a simple extension of an existing logical or neural model."}, {"title": "A comprehensive account of neuro-symbolic concepts.", "content": "While it is not in the scope of this survey to discuss every paper, we aim to cover the area more broadly to position regularisation techniques in relation to other approaches. To this end, Section 5 discusses the complement of composite frameworks, i.e. monolithic frameworks. We keep the discussion of such frameworks brief and refer the reader to d'Avila Garcez et al. (2019) for more details."}, {"title": "A discussion on the desiderata and actual achievements of neuro-symbolic AI.", "content": "Our final contribution is a qualitative perspective on how the different architectures achieve the expectations for neuro-symbolic AI, namely support for complex reasoning, knowledge integration, explainability, reduction of data need, and guarantee satisfaction. To this end, we provide a short discussion at the end of each main section comparing different frameworks that fit within each category and end our survey, in Section 7, with a discussion on the achievements in neuro-symbolic AI to date and an outlook on the main open problems."}, {"title": "3. Preliminaries", "content": "This section briefly covers probabilistic models (Section 3.1), propositional and first-order logic (Section 3.2), SRL (Section 3.3), and neural networks (Section 3.4). Since the field is developing, there are proposals where some of the structures are adapted to fit for purpose, and covering all variations is beyond the scope of this survey. We aim to cover the essentials which should be sufficient for someone to get started in the field of neuro-symbolic AI."}, {"title": "3.1 Probabilistic Graphical Models", "content": "Probabilistic graphical models are probabilistic models, where a graph expresses the conditional dependencies between random variables. We start, in Section 3.1.1, by introducing factor graphs (Pearl, 1988) a general undirected graphical model, which makes the factorisation of probability distributions explicit. Then, in Section 3.1.2, we introduce parameterised factor graphs a model that allows us to consider factor graphs at a higher level of abstraction, offering a more succinct representation."}, {"title": "3.1.1 FACTOR GRAPHS", "content": "TL;DR (Factor Graph). Factor graphs (Pearl, 1988) are graphical models that make the factorisation of a function explicit, e.g. a factorisation of a joint probability distribution. Both directed (e.g. Bayesian networks (Pearl, 1988)) and undirected probabilistic models (e.g. Markov random fields (Kindermann & Snell, 1980)) can be mapped to equivalent factor graphs, allowing us to generalise discussions in the remainder of the survey.\nConsider a factorisable function $g(x) = \\prod_{i=1}^M f_i(x_i)$, with x a set of variables, and $x_i \\subseteq x$. A factor graph F(x, f) is an undirected bipartite graph representing g(x), where the two sets of nodes are the factors $f = \\{f_i\\}_{i=1}^M$ and the variables $x = \\{x_i\\}_{i=1}^N$, and there is an edge between each $x_i \\in x$ and $f_j \\in f$, if and only if $x_i \\in x_j$ of $f_j(x_j)$.\nLet us fix a set of random variables (RVs) $X = \\{X_i\\}_{i=1}^N$, each with its own domain. An instantiation I(X), maps the RVs to values from the domain of the corresponding RV. We use I(X) to denote the set of all sets that can be obtained by instantiating the random variables in X in all possible ways. A factor graph F(X, f), where all factors map to non-negative real numbers, also known as potentials, then defines a joint probability as\n$P_F(X = x) := \\frac{1}{Z} \\prod_{i=1}^M f_i(x_i),$\\"}, {"title": "Log-linear models.", "content": "Factor graphs can always be represented in a log-linear model, by replacing each factor by an exponentiated weighted feature function $F_i$ of the state as\n$Pr(X = x) = \\frac{1}{Z} exp( \\sum_{i=1}^M w_iF_i(x_i)),$ \nwhere $w_i$ is its corresponding coefficient. A feature function can be any real-valued function evaluating the state of (part of) the system. A state is a specific instantiation I of the variables. In this survey, we consider binary features, i.e. $F_i(x_i) \\in \\{0,1\\}$, and features mapping to the unit interval, i.e. $F_i(x_i) \\in [0, 1]$."}, {"title": "Marginal distributions.", "content": "Computing probabilities for assignments to a subset $X' \\subseteq X$, from the full joint distribution, is known as computing marginals. Let $X'^c$ denote the complement of $X'$ in $X$, then\n$P(X' = x') = \\sum_{x'c \\in I(X'c)} P(X = x) .$\nComputing marginals is generally intractable. Consider for example a distribution over just 100 Boolean variables, then, to compute marginals one would need to compute $2^{100}$ states."}, {"title": "Conditional probabilities.", "content": "Computing marginals allows us to compute conditional probabilities. Let $X_\\mathcal{O} \\subseteq X$ denote the subset of observed RVs, i.e. RVs with known values, and let $X_u \\subseteq X$ denote the subset of unobserved RVs, i.e. RVs with unknown values. For a subset of unobserved variables $X \\subseteq X_u$, the conditional probability of $X = x$ given $X_\\mathcal{O} = x_\\mathcal{O}$, as evidence is given by\n$P(X = x | X^\\mathcal{O} = x_\\mathcal{O}) = \\frac{P(X = x_u, X = x_\\mathcal{O})}{P(X = x_\\mathcal{O})}.$\nComputing conditional probabilities, typically, also relies on sum-product message passing."}, {"title": "Maximum a posteriori state.", "content": "Computing conditional probabilities, in turn, allows us to compute the maximum a posteriori state (MAP). The goal of MAP is to compute the most likely joint assignment to $X_u$, given an assignment $x_\\mathcal{O}$ to the variables $X_\\mathcal{O}$:\n$MAP(X_u = x_u | X^\\mathcal{O} = x_\\mathcal{O}) = arg max P(X' = x_u | X = x_\\mathcal{O})$\nThe MAP can be computed using max-product message passing, where instead of summing messages the maximum is chosen. The operation $MAP(X_u = X_u | X_\\mathcal{O} = x_\\mathcal{O})$, i.e. predicting all unobserved RVs, is called the most probable explanation (MPE)."}, {"title": "3.2 Logic", "content": "TL;DR (Logic). Logic allows us to reason about connections between objects and express rules to model worlds. The goal of logic programming is threefold:\n\u2022 State what is true: Alice likes Star Wars.\n\u2022 Check whether something is true: Does Alice like Star Wars?\n\u2022 Check what is true: Who likes Star Wars?\nThis section begins by introducing propositional logic (Section 3.2.1) and first-order logic (Section 3.2.2), and finishes with a brief introduction to logic programming (Section 3.2.3) \u2013 a programming paradigm which allows us to reason about a database using logical theories. We present the syntaxes of the different languages and their operations, for the semantics, the reader is referred to Bradley and Manna (2007)."}, {"title": "3.2.1 PROPOSITIONAL LOGIC", "content": "The language of propositional logic (Bradley & Manna, 2007) consists of Boolean variables and logical connectives. An atom in propositional logic is a logical variable. A literal is either an atom X or its negation \u00acX. Formulae in propositional logic are expressions formed over literals and the logical connectives \u00ac (negation), \u2227 (conjunction), \u2228 (disjunction) and \u2192 (implication). Let \u03c6 be a propositional formula. A formula \u03c61 \u2227 \u03c62 is called a conjunction, with \u03c61 and \u03c62 its conjuncts. A conjunction is True if both conjuncts are True. A formula \u03c61 \u2228 \u03c62 is called a disjunction, with \u03c61 and \u03c62 its disjuncts. A disjunction is True if either of the disjuncts is True. A formula \u03c61 \u2192 \u03c62 is called a (material) implication, \u03c61 \u2192 \u03c62 \u2261 \u00ac\u03c61 \u2228 \u03c62. A clause is a disjunction of one or more literals. A theory is a set of sentences, with a sentence being a formula in which each variable is quantified. Theories are interpreted as a conjunction of their sentences. A theory is in conjunctive normal form (CNF) if it is a conjunction of clauses. An interpretation of a propositional formula is an instantiation of each of its variables to either True or False, which we, therefore, also denote by I. A model M of \u03c6 is an interpretation that makes \u03c6 evaluate to True, which we denote by M |= \u03c6. While checking whether an assignment to logical variables satisfies a logical theory can be done in polynomial time, finding a solution for a theory is the original NP-complete problem (Cook, 1971). This problem, known as the satisfiability problem, is often abbreviated as SAT."}, {"title": "3.2.2 FIRST-ORDER LOGIC", "content": "In first-order logic (FOL) (Bradley & Manna, 2007), a term is either a variable or a constant. A substitution \u03c3 is a mapping from variables to constants. An atom in FOL is an expression of the form P(t), where P is a relational predicate and t is a vector of terms. An atom P(t) is ground, if t includes only constants. For example, a := FRIENDS(U1, U2) is an atom consisting of the predicate FRIENDS and variables U1 and U2, \u0101 := FRIENDS(alice, bob) is a ground atom, and, for a substitution \u03c3 := {U1 \u2192 alice, U2 \u2192 bob}, \u03b1\u03c3 = \u0101. In classical Boolean logic, each ground atom is mapped to either True or False. However, other logical formalisms may map ground atoms to the unit interval [0,1]. A function in FOL maps constants to constants. For example, the function friendOf could map alice to bob, i.e. friendOf(alice) would evaluate to bob.\nA literal in FOL is an atom a or its negation \u00aca. Formulae in FOL are expressions that, similarly to propositional logic, are formed over literals and the logical connectives \u00ac, \u2227, \u2228, and \u2192, with the addition of universal \u2200 and existential \u2203 quantifiers. A formula is instantiated or ground if each atom in the formula is ground. A Rule \u03c1 is a universally quantified formula of the form a1 \u2227 ... \u2227 an \u2192 an+1, where each term occurring in the atom an+1 also occurs in some atom aj \u2208 {aj}j=1^n. The left-hand side of the implication is referred to as the premise and the right-hand side as the conclusion of the rule. We denote a theory consisting only of rules by \u03c1.\nFOL allows us, thus, to reason about groups rather than individual instances. On one hand, this allows for a more succinct representation but as we will see later it also allows for more efficient computations. The process of going from propositional to first-order logic is often referred to as lifting, and models that support first-order logic are said to be lifted."}, {"title": "3.2.3 LOGIC PROGRAMMING", "content": "A logic program P is a tuple (\u03c1,\u0101), where \u03c1 is a set of rules, and \u0101 is a set of ground atoms typically called facts (Sterling & Shapiro, 1994).\nThe Herbrand universe Hu(P) is the (possibly infinite) set of all terms that one can construct using all constants and function symbols in the logic program P. In most neuro-symbolic frameworks, however, the program is limited to function-free theories over finite sets of constants. Therefore, the Herbrand universe is simply the set of all constants. For a given Herbrand universe, its Herbrand base HB(P) is the set of all possible ground atoms that can be created by instantiating the atoms in the set of rules \u03c1 with the terms from Hu(P).\nThe Herbrand base in logic programming consists of two sets: the abducibles A, with \u0101 \u2286 A, and the outcomes O. The two sets are disjoint, i.e. A \u2229 O = \u2205. In logic programming, we operate under the closed world asummption, i.e. any ground atom in the abducibles that is not in the input facts is assumed to be false: \u2200\u0101\u2208 A \\ \u0101 : \u0101 is False. Further, all groundings of atoms in the conclusion of the rules are in O.\nThe Herbrand instantiation HI(P) is the set of all ground rules obtained after replacing the variables in each rule in \u03c1 with terms from its Herbrand universe in every possible way. A Herbrand interpretation or possible world I, is a mapping of the ground atoms in the Herbrand base to truth values. For brevity, we will use the notation \u0101\u2208I (resp. \u0101\u2209 I), when a ground atom \u0101 is mapped to True (resp. False) in I. A partial interpretation is a truth assignment to a subset of atoms of the Herbrand base. A Herbrand interpretation I is a model M of P if all rules in \u03c1 are satisfied. A model M of P is minimal if no other model M' of P has fewer atoms mapped to True than M. Such a model is called the least Herbrand model. Each logic program has a unique least Herbrand model, which is computed via the consequence operator.\nDefinition 1 (Consequence operator). For a logic program P and a partial interpretation I of P, the consequence operator is defined by\n$T_P(I) := \\{\u0101 |\u0101 \u2208 I  or  \u2203(\u0101 \u2190 \\wedge \\overline{a_p}) \u2208 H_I(P), s.t.  \u2200\\overline{a_p} \u2208 \\overline{a_p}, \\overline{a_p} \u2208 I  is True\\}\\$\nConsider the sequence I1 = TP(\u2205), I2 = TP(I1), . . .. Let n be the smallest positive integer such that In = TP(In), then In is the least Herbrand model of P.\nEntailment. A program P entails a ground atom \u0101 \u2013 denoted as P |= \u0101 or \u03c1 \u222a \u0101 if \u0101 is True in every model of P. Note that if \u0101 is True in every model of P, then it is True in the least Herbrand model of P."}, {"title": "Queries.", "content": "A query Q is an expression of the form P(t), where P is a predicate, and t is a tuple of terms. If t is a tuple of constants, then Q is Boolean. The answer to a Boolean query Q is True when P |= Q and false otherwise. If Q is non-Boolean, then a substitution \u03c3 is an answer to Q on P, if P |= Q\u03c3. The task of finding all answers to Q on P is called query answering under rules, or simply query answering. Note that if Q is Boolean, then \u03c3 is the empty substitution."}, {"title": "3.3 Statistical Relational Learning", "content": "A limitation of classical Boolean logic is that atoms are either mapped to True or False. However, the real world is often uncertain and imprecise. Therefore, there is a need to associate facts and logical formulae with some notion of uncertainty that quantifies the extent to which facts are true and the confidence in the formulae.\nTL;DR (Statistical relational learning). Statistical relational learning (SRL) (Getoor & Taskar, 2007) is the area of research that concerns itself with the unification of logic and probability to allow for logical reasoning under uncertainty both in the data, and the theory.\nThis section describes different concepts from SRL, namely, lifted graphical models (Section 3.3.1), weighted model counting (Section 3.3.3), and probabilistic logic programs (Section 3.3.4). As we will see in Section 4, these frameworks often form the logical components in neuro-symbolic architectures."}, {"title": "3.3.1 LIFTED GRAPHICAL MODELS", "content": "TL;DR (Lifted graphical models). Lifted graphical models (LGMs) are SRL frameworks combining probabilistic graphical models with first-order logic. Par-factor graphs (Section 3.1.2) lend themselves particularly well for this purpose, where the feature functions compute the extent to which the formulae are satisfied.\nThis section outlines the general steps taken to construct and use LGMs. We defer details, such as what it means for a formula to be satisfied, to the next section as those depend on the specific LGM. We denote an LGM by L(\u03c6,\u03c9\u03c6), where \u03c6 is a set of formulae \u03c6i with confidence value \u03c9i \u2208 \u03c9\u03c6. For a logical theory \u03c6, an LGM can be constructed as follows:\n1. Assign a confidence value \u03c9i \u2208 R to each formula \u03c6i \u2208 \u03c6 to soften the constraints of logical formulae. This confidence value allows the model to have assignments to atoms that contradict the formula. When \u03c9i\u2192 \u221e, we obtain hard rules.\n2. Treat each unground atom ai in \u03c6 as a par-RV Xi; and each possible grounding aij as an RV Xij, where the domains of the variables and atoms are the same.\n3. As atoms in a formula are dependent on each other, assign each formula \u03c6i a par-factor \u03a6i = exp(\u03c9iFi(xi)), where each feature function Fi computes the satisfaction of a grounding \u03c6i of \u03c6i given the truth assignments xi to the ground atoms ai in the formula. Fi returns a value in [0, 1] representing how much the formula \u03c6i is satisfied.\nGiven the probability density function of par-factor graphs in Equation (6), and knowing how to represent a set of FOL formulae as par-factors in a log-linear model, we can now define the probability distribution of an LGM as\n$P_C(X = x) := \\frac{1}{Z} exp(\\sum_{i=1}^M (\\sum_{x_j \\in I(X_i)} W_iF_i(x_j))),$\nwhere $X_j \\subseteq X$ are the different sets that can be instantiated from the par-RVs $X_i$ partic ipating in the par-factor $\u03a6_i$, and $x_j \\subseteq x = I(X)$, such that $x_j = I(X_j)$. Here, $\u03a6$ map to atoms, X to ground atoms, and x to truth assignments of the ground atoms. Note that X = IC(X), i.e. the atoms of the theory are grounded in every possible way. Thus, the outer sum iterates over the different formulae and the inner sum iterates over the different groundings of each formula. Then, one can compute marginals and conditional probabilities as in Equations (4) and (5)."}, {"title": "Inference.", "content": "Inference consists in computing the MPE for a set of unobserved variables $X_u$, given assignments to observed variables $X_\\mathcal{O} = x_\\mathcal{O}$ by means of a conditional distribution:\n$\\hat{x_u} = arg max P_C(X_u = x_u|X_\\mathcal{O} = x_\\mathcal{O};w_\\varepsilon)$\nTraining. Training is formalised as finding the \u03c9\u03b5 maximising the log-likelihood of the assignments x \u2208 D, where D is the training data provided to the LGM:\n$\\omega^{t+1}_\\mathcal{L} = arg max logP_C(X = x; \\omega_\\mathcal{L})^t$\nEquation (15) works when x provides truth assignments to all variables in X. If this assumption is violated, i.e. unobserved variables exist in the training data, training resorts to an expectation-maximisation problem. Parameter learning in LGMs works via gradient ascent (Richardson & Domingos, 2006; Bach et al., 2017).\nIn most neuro-symbolic frameworks, it is assumed that a logical theory is given and that the only trainable parameters are \u03c9\u03b5. However, algorithms to learn the theory, known as structure learning, exist. The general approach consists of three steps: i) finding commonly recurrent patterns in the data, ii) extracting formulae from the patterns as potential candidates, iii) reducing the set of candidates to the formulae explaining the data best. The first step helps to reduce the search space, as generally, the number of possible formulae grows exponentially. Khot et al. (2015) use user-defined templates as a starting point to find formulae. However, this approach therefore still requires user input. Kok and Domingos (2010) and Feldstein et al. (2023b) present algorithms based on random walks to find patterns in a hypergraph representation of the relational data. However, the algorithms fail to scale past O(103) relations. Feldstein et al. (2024) present a scalable (O(106)) algorithm that avoids expensive inference by estimating the \"usefulness\" of candidates up-front, but only find rules of a specific form."}, {"title": "3.3.2 EXAMPLES OF LIFTED GRAPHICAL MODELS", "content": "Markov logic networks (MLNs) (Richardson & Domingos, 2006). MLNs are LGMs that consist of a tuple L(\u03c6; \u03c9\u03b5), where each \u03c6i \u2208 \u03c6 is a FOL formula, and \u03c9i \u2208 R is its weight. For a given set of constants, an MLN can be instantiated as a Markov network, similar to how a par-factor graph can be instantiated as a factor graph. Each (\u03c6i, \u03c9i) uniquely determines a par-factor \u03a6i(Xi = xi) = exp(\u03c9iFi(xi)), where, as above, Xi are the groundings of \u03c6i, and xi are the assignments of each ground element to either True or False. Each feature function Fi, corresponding to a formula \u03c6i, of the MLN evaluates to 1 if xi |= \u03c6i, and 0 otherwise."}, {"title": "Probabilistic soft logic (PSL) (Bach et al., 2017).", "content": "Similarly to MLNs, PSL defines, for a tuple L(\u03c6; \u03c9\u03b5), how to instantiate an MRF from the grounded formulae. However, PSL has four major differences:\n1. Formulae in PSL are universally quantified rules \u03c1 (Section 3.2.2).\n2. While in MLNs, all ground atoms take on Boolean values (True or False), in PSL, ground atoms take soft truth values from the unit interval [0, 1]. Depending on the application, this allows for two interpretations of LIKES(alice, starwars) = 0.7 and LIKES(alice, startrek) = 0.5: it could either be understood as a stronger confidence in the fact that alice likes starwars rather than startrek or it can be interpreted as alice liking starwars more than startrek.\n3. PSL uses a different feature function F to compute the rule satisfaction: For a grounding Xi of a rule \u03c1i and an assignment xi, the satisfaction of \u03c1i computed by Fi(Xi = xi) in PSL is evaluated using the \u0141ukasiewicz t-(co)norms, defined as follows:\n$x_i \\wedge x_j = max\\{x_i + x_j - 1,0\\}\\$\n$x_i \\vee x_j = min\\{x_i + x_j,1\\}\\$\n$\\neg x = 1-x$\n4. Finally, \u03a6i(Xi = xi) = exp(\u2212\u03c9i \u00b7 (1 \u2212 Fi(xi))\u03c1), where \u03c1\u2208 {1,2} provides a choice of the type of penalty imposed on violated rules. One can see 1 \u2212 Fi(xi) as measuring a distance to satisfaction of rule \u03c1."}, {"title": "Step 1", "content": "Map each rule to its disjunctive normal form:\nf(U1, U2) \u2227 l(U1, I) \u2192 l(U2, I) \u2261 \u00ac(f(U1, U2) \u2227 l(U1, I) \u2228 l(U2, I))\n\u2261 \u00acf(U1, U2) \u2228 \u00acl(U1, I) \u2228 l(U2, I)"}, {"title": "Step 2", "content": "Find the possible groundings of Equation (18):\n1. \u00acf(a, b) \u2228 \u00acl(a, s) \u2228 l(b, s)\n2. \u00acf(b, a) \u2228 \u00acl(b, s) \u2228 l(a, s)\n3. \u00acf(a, a) \u2228 \u00acl(a, s) \u2228 l(a, s)\n4. \u00acf(b, b) \u2228 \u00acl(b, s) \u2228 l(b, s)"}, {"title": "Step 3", "content": "Compute the potentials:\n1. F(x1) = min{xs + (1 \u2212 0.7) + (1 \u2212 0.7), 1} = min{0.6 + xs, 1}\n2. F(x2) = min{(1 \u2212 0.7) + (1 \u2212 xs) + 0.5, 1} = min{1.8 \u2212 xs, 1} = 1\n3. F(x3) = min{(1 \u2212 1) + (1 \u2212 0.7) + 0.7, 1} = min{1, 1} = 1\n4. F(x4) = min{(1 \u2212 1) + (1 \u2212 xs) + xs, 1} = min{1, 01} = 1\nxi are the soft truth values of the ground atoms of the ground rule i (of Step 2), xs is the to-be-determined soft truth value of likes(bob, startrek), and we applied (17)."}, {"title": "Step 4", "content": "Then, the probability density function is given as\n$P(x) = \\frac{exp(\\frac{-0.5(1-min(0.6+x_s,1))}{Z(x)} = \\frac{exp(\\frac{-0.5 max\\{0.4-x_s,0))}{Z(x)}},$\nwith\nZ(x) =  1 \\int_0 exp(\u22120.5 max{0.4 \u2212 xs, 0}) dxs\n= 0.4 \\int_0 exp(\u22120.5(0.4 \u2212 xs) dxs + 1 \\int 0.4 1 dxs\n= exp(\u22120.2)  0.4 0 exp(0.5xs) dxs + 0.6\n= exp(\u22120.2)\\frac{2 exp(0.5 \u00b7 0.4) \u2212 2 exp(0)}{0.5}+ 0.6\n\u22480.963 ."}, {"title": "Step 5", "content": "Compute the mean estimate for P(likes(bob, startrek)):\n\u27e8xs\u27e9 = 1 \\int0 xs \u00b7 P(xs) dxs\n= 0.4 \\int0 xs \\frac{exp(\u22120.2 + 0.5xs)}{0.963} dxs + 1 \\int0.4 xs\\frac{1}{0.963} dxs\n\u2248 0.515 ."}, {"title": "3.3.3 WEIGHTED MODEL COUNTING", "content": "Another notion that was proposed to unify logic with probability theory is weighted model counting (WMC) and its extensions. Weighted model counting captures a variety of formalisms", "w": "X\u03c6 \u2192 R\u22650 and w: X\u03c6 \u2192 R\u22650 be two functions that assign weights to all atoms of \u03c6", "\u03c9)": "\u03a3 M|=\u03c6"}]}