{"title": "Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with Differential Transformer Based Deep Learning Model Incorporating Pixelwise Instrument Response Function", "authors": ["ISMAIL ERBAS", "VIKAS PANDEY", "NAVID IBTEHAJ NIZAM", "Nanxue Yuan", "Amit Verma", "MARGARIDA BAROSSO", "XAVIER INTES"], "abstract": "Fluorescence lifetime imaging (FLI) is an important molecular imaging modality that can provide unique information for biomedical applications. FLI is based on acquiring and processing photon time of arrival histograms. The shape and temporal offset of these histograms depends on many factors, such as the instrument response function (IRF), optical properties, and the topographic profile of the sample. Several inverse solver analytical methods have been developed to compute the underlying fluorescence lifetime parameters, but most of them are computationally expensive and time-consuming. Thus, deep learning (DL) algorithms have progressively replaced computation methods in fluorescence lifetime parameter estimation. Often, DL models are trained with simple datasets either generated through simulation or a simple experiment where the fluorophore surface profile is mostly flat; therefore, DL models often do not perform well on samples with complex surface profiles such as ex-vivo organs or in-vivo whole intact animals. Herein, we introduce a new DL architecture using state-of-the-art Differential Transformer encoder-decoder architecture, MFliNet (Macroscopic FLI Network), that takes an additional input of IRF together with TPSF, addressing discrepancies in the photon time-of-arrival distribution. We demonstrate the model's performance through carefully designed, complex tissue-mimicking phantoms and preclinical in-vivo cancer xenograft experiments.", "sections": [{"title": "1. Introduction", "content": "Fluorescence lifetime imaging (FLI) is a powerful molecular imaging technique with high sensitivity and the ability to provide unique signatures with high specificity [1,2]. Fluorescence lifetime and its associated parameters enable multiplexing studies [3-5] and can report on numerous unique biological signatures, including micro-environmental parameters, protein conformations, metabolic states, protein-protein interactions, and/or ligand-target engagement [6-9]. FLI has known constant growth over the last three decades, with a significant acceleration in its dissemination thanks to the availability of a user-friendly FLI microscope [10-12]. In parallel, over the last two decades, FLI has found an increased utility in translational applications, ranging from the mesoscopic (mFLI) [13] to the macroscopic regime (MFLI) [14-16]. Compared to microscopic implementations, mFLI and MFLI are significantly more challenging due to the requirement of using Near Infrared (NIR) fluorophores for deeper tissue penetration. As fluorophores are red shifted, it is typical that their lifetimes are shorter (nanosecond (ns) or sub-nanosecond compared to few nanoseconds in the visible) [16] whereas large-format detectors exhibit low quantum efficiency (a few percent only) [17, 18]. Hence, quantifying lifetime and its associated parameters can be challenging due to very short fluorescence decays and/or low photon counts [19\u201322]. Unlike microscopic imaging, where the sample preparation allows for precise control over the imaging plane, mFLI, and MFLI samples can exhibit a large depth of field (DOF). These lead to significant variations in the time of arrival of the acquired data, which needs also be taken into account for accurate lifetime quantification. This is especially important in clinical systems, such as endoscopic or fluorescence-guided surgical instruments in which the tissue profiles can lead to DOF variations of a few centimeters.\nTo address these challenges, understanding the underlying methodology for estimating lifetime parameters becomes important. In mFLI and MFLI, lifetime parameters can be estimated by deconvolving the temporal point spread function (TPSF) and instrument response function (IRF). TPSF is the temporal histogram of the acquired fluorescence photons exiting the surface of the sample after a pulse excitation. The IRF represents the temporal response of the imaging system to pulsed illumination [23]. Considering the complexity involved in estimating FLI parameters across diverse imaging conditions, fast and advanced data processing techniques are necessary to enhance both the precision and efficiency of these analyses. Recently, the field has seen a shift toward rapid, fit-free deep learning (DL) methodologies to alleviate the computational burden and reliance on user expertise, typically associated with methods such as nonlinear least squares fitting (NLSF) for FLI parameter estimation [24,25]. This advancement makes real-time FLI a possibility [26, 27], driven by the development of novel DL methods that eliminate traditional time-consuming computational approaches. FLI-Net, a DL model developed for FLI parameter estimation [28], is used to analyze FLI data quickly, producing 2D quantitative images of the lifetimes and corresponding parameters directly without requiring manual parameter adjustments, outputting 2D quantitative images of the lifetime parameters directly. FLI-Net is versatile of FLI experiments, including visible and near-infrared (NIR) imaging, making it adaptable to a large range of biomedical applications. FLI-Net takes the TPSF as an input and outputs FLI parameters. The experimental IRF was used in data generation of the training data; hence, it was represented in the TPSFs. However, FLI-Net was not designed to analyze pixel-wise IRFs while it predicts the lifetime parameters.\nDespite the advancements in deep learning for FLI data analysis, the lack of pixel-wise IRF considerations poses limitations. The IRF integrates both the excitation part (including the laser source temporal profile) and detection (including the electronic limited reaction time) aspects of the optical setup. The complex broadening or distortion of the intrinsic fluorescence decay is caused by the detection part of the IRF from imaging system characteristics; however, the temporal offset in the IRF is caused by the photon time-of-arrival delays caused by the distance between the imager and sample surface [22]. Hence, topographic variations in the sample surface can lead to variations in delays in photon arrival times per pixel. In such cases, it is important to incorporate pixel-wise IRF in the FLI data processing pipeline. To address these limitations and consider the essential role of the IRF in accurate FLI parameter estimation, we propose a novel deep-learning approach tailored specifically for processing FLI data.\nFollowing the developments in DL models, we leverage herein the ability of transformers to handle sequential data. Generally, transformers have a natural ability to capture long-range connections within data [29-32]. In the context of FLI, they can effectively identify and learn the relationships between the TPSF and IRF for accurate lifetime estimation. Furthermore, the self-attention mechanism in transformers allows them to focus on the most relevant parts of the input data for making predictions [32]. In this study, we developed MFliNet to incorporate the Differential Transformer (DIFF Transformer) [33], enhancing its ability to process sequential data for accurate fluorescence lifetime parameter estimation. Our work introduces a novel decoder layer design that integrates the DIFF Transformer for the first time in literature, improving the model's adaptability to account for shifts caused by variations in the DOF. The DIFF Transformer employs a differential attention mechanism, which calculates attention scores as the difference"}, {"title": "2. Methods", "content": "All experimental data used in this work were captured on our MFLI system, where the detailed information can be found in [34]. Briefly, the system uses a large-format Intensified Charge- Coupled Device (ICCD) camera (Picostar HR, LaVision GmbH, Germany), for wide-field detection over a 8 \u00d7 6 cm\u00b2 in combination with a Digital micro-mirrors device (DMD), DLi 4110, Texas Instruments, TX, USA, for a wide-field illumination. As an excitation source, we used a tunable Ti-Sapphire laser, Mai Tai HP, Spectra-Physics, CA, USA, which delivers 100 femtosecond pulses at 80 MHz. A gate width of 300 picoseconds (ps) and gate delay of 40 ps were used for capturing time-resolved fluorescence decays (for in vivo and in vitro experiments) with a total of 176 time points, which is referred to as a number of gates (G=176). An emission filter at 740 \u00d7 10 nm (FF01-740/13-25, Semrock, IL, Rochester, NY, USA) is used to capture the TPSFs, with the laser set at a 700 nm wavelength, and Alexa Fluor 700 dye was used to obtain the time-resolved fluorescence signals."}, {"title": "2.2. Generation of training data and classical Fluorescence lifetime processing", "content": "Fluorescence Lifetime decay follows exponential decay. Depending on the number of components present in the sample, the decay kinetics can be described by a combination of multi-exponential functions. Most FLI imaging experiments involve up to two components, hence a bi-exponential model is typically used. The two-component or bi-exponential model also includes mono- exponential cases (where fractional amplitudes AR are one or zero). Mathematically, the TPSF is the convolution of the IRF and the fluorescence decay associated with the lifetime parameters as shown in Eq. 1, where lifetime decays are denoted as T1, T2, and AR is the amplitude fraction.\nTPSF(t) = IRF(t) * (Are^{-t/\u03c4_1} + (1-A_R)e^{-t/\u03c4_2})\n(1)\nThe in silico data used for training and validating the proposed model was generated using Eq. 1. Initially, time-resolved fluorescence lifetime images with dimensions of 28 \u00d7 28 pixels were generated by using the MNIST dataset. Fluorescence decays were generated for a range of lifetime values commonly used in NIR applications: 0.2 ns to 0.8 ns for \u03c4\u2081 (short-lifetime component) and 0.8 ns to 1.5 ns for t2 (long-lifetime component). The range of the Ar (fraction amplitude) was set from 0% to 100%, respectively (both bound corresponding to mono-exponential cases). To ensure that our simulated data accurately represents experimental applications, pixel-wise IRFs were used. To capture experimental IRFs, a white diffused paper was placed on the imaging table and illuminated using the DMD with an excitation wavelength of 700 nm. The reflected light was captured using a neutral density (ND) filter. Subsequently, each TPSF was generated by convolving randomly selected IRF from the dataset with simulated fluorescence decay profiles. To approximate the noise characteristics of real-world measurements, system-derived noise,"}, {"title": "2.3. Deep learning network architecture", "content": "MFliNet is a novel architecture designed for FLI parameter estimation, particularly effective under varying IRFs. The model leverages a Differential Transformer framework, incorporating a unique differential attention mechanism to enhance feature extraction while mitigating the effects of noise. The theoretical background on the differential attention mechanism is detailed in [33].\nAt the core of MFliNet is the differential attention mechanism, which computes attention scores by contrasting two separate multi-head attention outputs. Specifically, the mechanism calculates the difference between two attention maps, scaled by a parameter A, to focus on relevant patterns and suppress noise. The differential attention is defined as:\nDiffAttn(X) = (softmax(\\frac{Q_1K_1^T}{\\sqrt{d_k}})V_1 - \\lambda \\cdot softmax(\\frac{Q_2K_2^T}{\\sqrt{d_k}})V_2).\n(2)\nwhere:\n\u2022 Q1, K1, V\u2081 are the query, key, and value matrices for the first attention head, derived from the input X using learned projections.\n\u2022 Q2, K2, V2 are the query, key, and value matrices for the second attention head, also derived from X.\n\u2022 dk is the dimensionality of the key vectors.\n\u2022 A is a learnable scalar parameter that balances the contributions of the two attention maps.\nThe queries, keys, and values are computed as:\nQ_i = XW_i^Q, K_i = XW_i^K, V_i = XW_i^V, for i = 1,2,\n(3)\nwhere W_i^Q, W_i^K, and W_i^V are the learned weight matrices for the i-th attention head.\nThis differential attention mechanism enhances the model's ability to focus on critical features by emphasizing the differences between two attention outputs, effectively reducing the impact of noise. The parameter \u00e0 controls the degree to which the second attention output is subtracted from the first.\nEach input sequence passes through two stacked encoder blocks, each comprising a differential attention layer, followed by layer normalization and a feed-forward network (FFN) with SwiGLU activation. The encoder block operates as follows:\nAttention Output = DiffAttn(X),\n(4)\nAdd & Norm\u2081 = LayerNorm(X + Attention Output),\n(5)\nFFN Output = FFN(Add & Norm\u2081),\n(6)\nEncoder Output = LayerNorm(Add & Norm\u2081 + FFN Output),\n(7)\nwhere the feed-forward network is defined as:\nFFN(x) = (Swish(xW_1 + b_1) \\odot (xW_2 + b_2)) W_3 + b_3,\n(8)\nwith W1, W2, W3 being learned weight matrices, b1, b2, b3 bias vectors,  \\odot representing element- wise multiplication, and Swish being the activation function defined as Swish(x) = x \u00b7 \u03c3(x), where \u03c3(x) is the sigmoid function.\nThe decoder blocks incorporate both self-attention and cross-attention mechanisms. The self-attention layer within the decoder uses the differential attention mechanism to capture intra-sequence relationships. The cross-attention layer aligns the decoder's inputs with the encoder outputs, integrating information from both inputs. The decoder block operates as:\nSelf-Attn Output = DiffAttn(X),\n(9)\nAdd & Norm\u2081 = LayerNorm(X + Self-Attn Output),\n(10)\nCross-Attn Output = Attention(Add & Norm\u2081, E, E),\n(11)\nAdd & Norm2 = LayerNorm(Add & Norm\u2081 + Cross-Attn Output),\n(12)\nFFN Output = FFN(Add & Norm2),\n(13)\nDecoder Output = LayerNorm(Add & Norm2 + FFN Output),\n(14)\nwhere E represents the encoder outputs from the corresponding input sequence, and the standard attention mechanism is defined as:"}, {"title": "2.4. Phantom preparation", "content": "For experimental validation, we designed a step ladder phantom to introduce variations in sample-detector distance, as depicted in Figure 2(a). A 3D printable case was designed to accommodate five discrete containers arranged at various heights: ground level, 5 mm, 10 mm, 15 mm, and 20 mm. Each container was crafted with dimensions of 40\u00d740\u00d710 mm to accommodate tissue-mimicking phantoms. The phantoms were made with agar constituting 1% of the total volume (80 cm\u00b3). To prepare the phantoms, agar was first dissolved in distilled water, heated until fully integrated, and then allowed to cool slightly before further processing. The optical properties of the phantoms (absorption coefficient (\u00b5a) of 0.005 mm\u00af\u00b9 and a reduced scattering coefficient (\u00b5's) of 1 mm\u00af\u00b9) were controlled through the addition of India Ink and intralipid solutions, to provide absorption and scattering contrasts respectively [38]. In each ladder step, a specific area was designated for the placement of a cuboidal fluorescence embedding, with dimensions of 5 \u00d7 5 \u00d7 40 mm. This embedding consisted of Alexa Fluor 700 dye dissolved in phosphate-buffered saline to achieve a concentration of 20 \u00b5M. The embeddings were placed at a depth of 1 mm from the surface of each phantom.\nTo examine the offset variation across different heights on the phantom and in live intact animals, we plotted the pixelwise IRFs for comparison as shown in Figure 2. For each specified height in the step ladder phantom, we plotted the average IRFs in Figure 2 (a). Moreover, we also illustrated the IRFs of various anatomical regions in live intact animals, including the liver, urinary bladder (UB), and tumors, in Figure 2(b). Lastly, in Figure 2(c), we examined the variability of the IRF within a single tumor. This plot contains IRFs on three points within a tumor: the top, middle, and bottom. The top refers to an IRF from the upper region of the tumor, the middle corresponds to an IRF from the central area in terms of height, and the bottom shows an IRF from the lowest part of the tumor."}, {"title": "2.5. In vivo experiment", "content": "For in vivo MFLI imaging experiments, we imaged HER2+ breast tumor xenografts HCC1954 in athymic nude mice. The cell line was sourced from ATCC (Manassas, VA, USA) and maintained in RPMI 1640 media enriched with 10% fetal bovine serum (ATCC) and 50 units/mL/ 50 \u00b5g/mL penicillin/streptomycin from ThermoFisher Scientific (Waltham, MA, USA). We initiated tumor xenografts by subcutaneously injecting 5 \u00d7 10\u00ba HCC1954 cells suspended in PBS and mixed in a 1:1 ratio with Cultrex BME (R&D Systems Inc, Minneapolis, MN, USA) into the inguinal mammary fat pads of female athymic nude mice aged 4 weeks (CrTac: NCR-Foxn1nu, Taconic Biosciences, Rensselaer, NY, USA). Tumors were monitored daily for 4 weeks. The mouse was administered with a retro-orbital injection of AF700 conjugated with MDT-TZM (MDT-TZM-AF700) at 20 \u00b5g and AF750 conjugated with MDT-TZM (MDT-TZM-AF750) at 40 \u00b5g in a 2:1 acceptor to donor ratio through staggered injection [9]. Donor injection was performed 2 hours ahead of acceptor injection through the retro-orbital route. MFLI Imaging was conducted 24 hours post-injection using the MFLI imaging setup. Throughout the imaging process, the mouse was anesthetized with isoflurane, and the body temperature was maintained with a Rodent Warmer X2 (Stoelting, IL, USA). All animal procedures were conducted with the approval of the Institutional Animal Care and Use Committee (IACUC) at both Rensselaer Polytechnic Institute and Albany Medical College. The animal facilities of both institutions have been accredited by the American Association for Accreditation for Laboratory Animals Care International."}, {"title": "3. Results", "content": "We conducted the ladder phantom experiment designed to validate the MFliNet model under controlled conditions that mimic biological tissues. Figure 3 shows the phantom experiment results where the analysis was done using three methods: NLSF, FLI-Net, and MFliNet. To compare the precision and stability of each method under varying conditions reflective of real-world applications, results were evaluated across five different heights: ground, 5 mm, 10 mm, 15 mm, and 20 mm. A 160 ps shift in the IRF was observed from ground level to a height of 20 mm, with a shift of approximately 40 ps for each 5 mm increment in height. For simplicity in comparison, the amplitude-weighted average lifetime was calculated using Eq. 17, for all outputs.\n\u03c4_M = (A_R\u03c4_1 + (1 - A_R)\u03c4_2)\n(17)\nNLSF analysis using pixel-wise IRF showed consistency in lifetime estimation across all tested heights. The mean fluorescence lifetime values obtained by NLSF were clustered around 1.01 \u00b1 0.02 ns. NLSF without offset correction results deteriorated with each increase in height. At the ground level, NLSF without offset correction began with a mean value of 1.04 \u00b1 0.01 ns. However, as the height increased, a steady decline in lifetime estimation was observed, reaching a mean value of 0.93 \u00b1 0.01 ns at 20 mm. FLI-Net, in contrast, demonstrated a wider variation in estimated fluorescence lifetime values. At the ground level, it reported a mean value of 0.96 \u00b1 0.01 ns, which was lower than the NLSF values. As the distance increased, FLI-Net's estimations deviated further, peaking at 1.14 \u00b1 0.01 ns at 10 mm and estimating 20 mm with a mean value of 1.10 \u00b1 0.02 ns. In contrast, MFliNet, showed closer results with NLSF, where the mean values were within the same range as NLSF. Moreover, in terms of processing speed, NLSF took approximately 6 hours to analyze 598 pixels (covering only the tumor area), whereas MFliNet analyzed the entire dataset of 90,480 pixels in just 63 seconds."}, {"title": "4. Discussion and Conclusion", "content": "In this study, we introduced MFliNet, a novel deep learning model based on the DIFF Transformer architecture, to address the challenges of accurate FLI parameter estimation, particularly in complex and variable biological environments. Our results, as illustrated in Figure 2, demonstrate shifts in IRFs at varying heights, highlighting how each organ's unique geometry and composition contribute to IRF offsets. This variation in the IRF offset underscores the challenge of accurately estimating the FLI parameters and the necessity for MFliNet, which can adapt to these complexities. The integration of pixel-wise IRF analysis within MFliNet specifically addresses the effects of surface irregularities on early photon arrival times, which is often overlooked in other DL models. The differential attention mechanism within the DIFF Transformer enhances the model's ability to focus on relevant features while suppressing noise, leading to improved performance.\nComparative analysis indicates that MFliNet not only matches the accuracy of NLSF analysis but also enhances processing speed. MFliNet eliminates the need for manual user dependency and extensive user training, making it better suited for real-time applications. In addition, as shown in the phantom experiment, an increasing trend in lifetime estimations from the FLI-Net suggests a distance-related bias, which reflects an underlying limitation in the model's ability to account for variations in time-of-flight. The effect of the IRF offset on lifetime estimation is further validated through NLSF analysis without using the offset correction, where lifetime estimations result in noticeable declines, potentially leading to systematic underestimations of fluorescence lifetimes and inaccuracies in diagnostics.\nThe significance of these improvements is particularly relevant in complex imaging environ- ments such as fluorescence-guided surgery (FGS), where the understanding of these variables can significantly impact the quality of imaging and, consequently, the surgical outcomes. Potential integration of MFliNet with existing FGS systems can lead to the development of advanced surgical guidance systems that offer real-time, precise imaging for cancer surgery [39]. Moreover, the capabilities of MFliNet extend beyond clinical applications, offering potential benefits in various research applications. In drug development, for instance, MFliNet's enhanced accuracy could be used to determine drug-target interactions more precisely, thus accelerating the develop- ment of therapeutics by providing clearer insights into molecular engagements. Additionally, in biological research, the improved measurement accuracy of molecular interactions facilitated by MFliNet could foster a deeper understanding of cellular functions and disease mechanisms. This could open new avenues for exploring and developing targeted therapies. This work contributes to the field by providing a robust and efficient tool for FLI parameter estimation, with potential applications in clinical diagnostics, fluorescence-guided surgery, and various biomedical research areas."}]}