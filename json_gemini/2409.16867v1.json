{"title": "Multi-objective Evolution of Heuristic Using Large Language Model", "authors": ["Shunyu Yao", "Fei Liu", "Xi Lin", "Zhichao Lu", "Zhenkun Wang", "Qingfu Zhang"], "abstract": "Heuristics are commonly used to tackle diverse search and\noptimization problems. Design heuristics usually require te-\ndious manual crafting with domain knowledge. Recent works\nhave incorporated large language models (LLMs) into auto-\nmatic heuristic search leveraging their powerful language and\ncoding capacity. However, existing research focuses on the\noptimal performance on the target problem as the sole ob-\njective, neglecting other criteria such as efficiency and scal-\nability, which are vital in practice. To tackle this challenge,\nwe propose to model heuristic search as a multi-objective\noptimization problem and consider introducing other prac-\ntical criteria beyond optimal performance. Due to the com-\nplexity of the search space, conventional multi-objective\noptimization methods struggle to effectively handle multi-\nobjective heuristic search. We propose the first LLM-based\nmulti-objective heuristic search framework, Multi-objective\nEvolution of Heuristic (MEOH), which integrates LLMs in\na zero-shot manner to generate a non-dominated set of\nheuristics to meet multiple design criteria. We design a new\ndominance-dissimilarity mechanism for effective population\nmanagement and selection, which incorporates both code dis-\nsimilarity in the search space and dominance in the objective\nspace. MEoH is demonstrated in two well-known combinato-\nrial optimization problems: the online Bin Packing Problem\n(BPP) and the Traveling Salesman Problem (TSP). Results in-\ndicate that a variety of elite heuristics are automatically gen-\nerated in a single run, offering more trade-off options than ex-\nisting methods. It successfully achieves competitive or supe-\nrior performance while improving efficiency up to 10 times.\nMoreover, we also observe that the multi-objective search in-\ntroduces novel insights into heuristic design and leads to the\ndiscovery of diverse heuristics.", "sections": [{"title": "1 Introduction", "content": "Heuristics are commonly used in solving optimization and\ndecision-making problems in a variety of fields, including\nengineering (Bozorg-Haddad, Solgi, and Lo\u00e1iciga 2017),\nindustry (Silver 2004), and economics (Vasant 2012). Un-\nlike exact methods, heuristics offer practical alternatives\nfor finding sub-optimal solutions within a reasonable time"}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Automated Heuristic Design", "content": "Automated heuristic design methods can be broadly clas-\nsified into automated heuristic configuration, automated\nheuristic selection, and automated heuristic composi-\ntion (Pillay and Qu 2021). The first category involves\nusing optimization methods and machine learning tech-\nniques (Ramos et al. 2005; Visheratin, Melnik, and Nasonov\n2016) to automatically adjust the parameters within a given\nalgorithm framework (Agasiev and Karpenko 2017). The\nsecond category focuses on automatically choosing a suit-\nable heuristic for each specific instance from a pool of ex-\nisting heuristics (Tang et al. 2014; Xu, Hoos, and Leyton-\nBrown 2010). The third category combines various algorith-\nmic elements to create novel heuristics (Burke et al. 2010;\nDrake et al. 2020; Pillay and Qu 2018). While these methods\nhave shown promise in enhancing the automation of heuris-\ntic design and improving performance, they still heavily rely\non human-designed algorithmic components."}, {"title": "2.2 LLM-based Automated Heuristic Design", "content": "Large language models have shown remarkable perfor-\nmance across a variety of tasks and exhibit promising zero-\nshot capabilities in linguistic processing and code gener-\nation. The use of LLMs in automated heuristic design is\nstill in its early stages. For example, FunSearch (Romera-\nParedes et al. 2024) leverages LLMs to generate and im-\nprove code implementations of heuristics based on EC\nframeworks, achieving state-of-the-art results in mathemat-\nical and combinatorial optimization problems. EoH (Liu\net al. 2024) evolves both idea descriptions and code imple-\nmentations of heuristics simultaneously, leading to competi-\ntive performance in a more efficient manner. This EC+LLM\napproach has been successfully applied in heuristic and\nfunction design across various tasks such as reward func-\ntion design (Ma et al. 2023), molecular design (Wang et al."}, {"title": "2.3 Multi-objective Heuristic Design", "content": "Dr\u00e9o (2009) view automated heuristic design as a multi-\nobjective problem, emphasizing the importance of identi-\nfying a set of non-dominated heuristics that can effectively\nbalance optimality and efficiency. By automatically adjust-\ning multiple sets of parameters for a heuristic (Dr\u00e9o 2009;\nDang and De Causmaecker 2014), it can be tailored to\ndifferent scenarios. Zhang, Georgiopoulos, and Anagnos-\ntopoulos (2013) introduce S-Race, which employs a racing\nalgorithm to automatically choose machine learning mod-\nels based on multiple objectives. Furthermore, Blot et al.\n(2016) extend the single-objective heuristic configuration\nframework ParamILS to handle multiple objectives with\nMO-ParamILS. These methods rely on existing hand-crafted\nheuristics. Multi-objective genetic programming has also\nbeen applied on heuristic search (Schmidt and Lipson 2009;\nVladislavleva, Smits, and Den Hertog 2008; Fan et al. 2024).\nHowever, they still demand existing hand-crafted primitives\nfor defining and generating heuristics."}, {"title": "3 Preliminaries", "content": null}, {"title": "3.1 Multi-objective Optimization", "content": "A multi-objective optimization problem (MOP) can be de-\nfined as\n$\\min_{x \\in X} f(x) = (f_1(x), f_2(x), ..., f_M (x)),$ (1)\nwhere $X$ represents the search space, $x$ is a decision vector,\nand $f(x)$ is an M-objective vector to optimize. A non-trivial\nMOP cannot be solved by a single decision vector, and we\nhave the following definitions for multi-objective optimiza-\ntion:\nPareto Dominance: Let $x_a, x_b \\in X$, $x_a$ is said to dom-\ninate $x_b$ ($x_a \\prec x_b$) if and only if $f_i(x_a) \\le f_i(x_b), \\forall i \\in\n\\{1,2,..., M\\}$ and $f_j(x_a) < f_j(x_b), \\exists j \\in \\{1, 2, ..., M\\}$.\nPareto Optimality: A decision vector $x^* \\in X$ is Pareto-\noptimal if there does not exist $x' \\in X$ dominates $x^*$, i.e.,\n$\\nexists x'\\in X$ such that $x' \\prec x^*$.\nPareto Set/Front: The set of all Pareto-optimal decision\nvectors is called the Pareto Set (PS), and its mapping in the\nobjective space is called the Pareto Front (PF).\nIn this paper, we investigate multi-objective heuristic de-\nsign. The decision vector $x$ indicates the heuristic and the\nM-objective vector represents different criteria measuring\ndifferent aspects of the performance of heuristics (e.g., opti-\nmal performance and complexity)."}, {"title": "3.2 Multi-objective Evolutionary Algorithms", "content": "Multi-objective evolutionary algorithms (MOEAs) are\namong the most commonly used methods to solve MOPs.\nMOEAs work by maintaining a population of $N$ candidate\nindividuals that evolve iteratively through genetic operators"}, {"title": "4 Methodology", "content": null}, {"title": "4.1 Framework", "content": "Multi-objective Evolution of Heuristic (MEoH) is a fusion\nof LLMs and multi-objective evolutionary optimization for\neffective multi-objective heuristic design. As is illustrated\nin Algorithm 1, MEoH commences with population initial-\nization, where the population comprises heuristics, and pro-\ngressively improves the population using MOEA until the\ntermination condition is satisfied, to obtain a set of non-\ndominated heuristics that represent trade-offs among multi-\nple objectives. Throughout each iteration, MEoH generates\noffspring using search operators. These operators are imple-\nmented through LLMs and predefined prompts to create off-\nspring based on the selected parents from the population.\nNew offspring are added to the population and population\nmanagement is utilized to update the population to keep its\nsize, with a focus on maintaining diversity and convergence.\nThe dominance-dissimilarity mechanism is utilized in both\nparent selection and population management. Detailed ex-\nplanations of each of these components will be provided in\nthe subsequent sections.\nMEOH represents a significant advancement in LLM-\nbased heuristic design by extending the single-objective ap-\nproach in existing works to the multi-objective scenarios\nand designing a set of non-dominated heuristics in a sin-\ngle run. Moreover, unlike directly combining MOEA and\nLLM-based heuristic search, MEoH introduces a unique\ndominance-dissimilarity measure to navigate the complex\nand discrete heuristic search space, overcoming challenges\nfaced by conventional MOEAs like NSGA-II and MOEA/D."}, {"title": "4.2 Dominance-dissimilarity Mechanism", "content": "Traditional MOEAS (Deb et al. 2002; Zhang and Li 2007)\nand single-objective LLM-based heuristic design meth-"}, {"title": "4.3 Heuristic Representation", "content": "Similar to Liu et al. (2024), each heuristic in MEoH is com-\nposed of three elements: a description in plain language, a\ncode snippet in a specific format, and a fitness score.\nThe description is a brief linguistic explanation generated\nby LLMs that conveys the main idea. The code snippet is the\nactual implementation of the heuristic. In the experiments,\nwe opted to use Python functions for implementation. The\ncode snippet must include the 1) function name, 2) input\nvariables, and 3) output variables for clarity. The fitness is\nevaluated on a set of instances for the specific target prob-\nlem. Example heuristics can be found in Appendix G."}, {"title": "4.4 Heuristic Generation", "content": "Initial Heuristic Generation The initial population of\nMEOH is comprised of heuristics. These heuristics can be\ngenerated by leveraging a LLM with a predefined genera-\ntion prompt or by using human-designed existing heuristics.\nIn order to fully demonstrate the capability of MEoH in de-\nsigning competitive heuristics, we let LLM generate all the\nheuristics in both the initiation and evolution processes.\nOffspring Heuristic Generation The parent selection is\nthe first step of generating offspring, in which a set of parent\nheuristics $S$ are selected from the current population. In or-\nder to take into account the convergence and diversity of the\nheuristic search process, the dominance-dissimilarity score\nis employed to guide the probability of parent selection. A"}, {"title": "4.5 Population Management", "content": "As the offspring generated through search operations are in-\ncorporated into the population, the size of the population\ngradually increases. In order to ensure a consistent popu-\nlation size and update the population effectively, a popu-\nlation management strategy is proposed. The dominance-\ndissimilarity score is utilized for this purpose. Specifically,\nthe heuristics in the population are sorted based on their\ndominance-dissimilarity score and the worst heuristics are\nremoved to ensure that only the most promising individu-\nals are retained within the population with details in Ap-\npendix A. By employing this strategy, the population is con-\ntinually refined to maintain a high-quality and diverse set of\nindividuals, enhancing the overall efficiency and effective-\nness of the evolutionary process."}, {"title": "5 Experiments", "content": null}, {"title": "5.1 Experimental Settings", "content": "Problems & Implementation Details We demonstrate\nMEoH on two representative combinatorial optimization\nproblems:\n1) Online Bin Packing Problem: In online Bin Packing\nProblem (BPP) (Seiden 2002), a set of items, each with its\nown weight, needs to be packed into bins with a predeter-\nmined capacity. The objective of the BPP is to minimize the\ntotal number of bins required to accommodate all the items.\nIn an online scenario, items are packed as they are received\nwithout prior knowledge. The generated heuristics are eval-\nuated on 5 Weibull instances with 5,000 items (referred to\nas 5k), and the capacity of bins is 100.\nWe inherit the settings from Romera-Paredes et al. (2024)\nto design constructive heuristics for aligning the arriving\nitems to the appropriate bins. The designed heuristics in-\nvolve a function scoring the bins, where the input includes\nthe arriving item size and the remaining capacities of the\nbins. The item with the highest score will be assigned to the\nbin.\n2) Travelling Salesman Problem: In Traveling Salesman\nProblem (TSP) (Reinelt 2003), the objective is to find the\nshortest route that visits all given nodes exactly once and\nreturns to the starting node. In this work, we evaluate the fit-\nness of designed heuristics during evolution on 64 instances\nwith 100 nodes. The coordinate of each node is randomly\nsampled from [0, 1] (Kool, van Hoof, and Welling 2018).\nThe Guided Local Search (GLS) framework is em-\nployed (Voudouris, Tsang, and Alsheddy 2010) to iteratively"}, {"title": "5.2 Experimental Results", "content": "Convergence Analysis 1) BPP: The curve of HV and IGD\nfor the heuristic populations generated in each iteration are\ndisplayed in Figure 3(b) and (c), respectively. As EoH only\npursues optimal gap without considering diversity, the HV\nand IGD become worse as the evolution progresses. In con-\ntrast, MEoH systematically takes into account both the op-\ntimal gap and running time. As a result, MEOH achieves\nnotably higher HV and lower IGD, indicating significantly\nbetter multi-objective trade-off results. Figure 4(b) and (c)\nprovide more evidence. MEoH converges faster and clearly\noutperforms EoH in terms of HV and IGD.\nPareto Fronts Figure 3(a) and Figure 4(a) compare the\napproximate non-dominated heuristics of the final popula-\ntion obtained by MEoH and EoH. Results show that 1)\nMEOH generates a diverse set of heuristics with different\ntrade-offs over the two objective. In contrast, EoH only finds\nsimilar heuristics that cover a much smaller region in the\nobjective space. 2) The heuristics obtained from MEoH can\nsignificantly reduce the running time (up to 10 times) when\nachieving a similar optimal gap.\nPerformance Measurement 1) BPP: To comprehen-\nsively evaluate the performance of our MEoH in more gen-\neral cases, we test FunSearch, EoH, and MEOH on various\nproblem instances with different sizes and capacities. The\nproblem sizes in our test include 5k, 10k, and 100k, and\nthe capacities of the bins are set at 100 and 500. Each test"}, {"title": "5.3 Comparison to Conventional MOEAS", "content": "In this section, we evaluate the impact of our proposed\ndominance-dissimilarity mechanism on the optimization"}, {"title": "5.4 Visualization of Dominance-dissimilarity\nScores", "content": "We visualize the evolution of Dominance-dissimilarity\nScores in Figure 5. The x-axis is the heuristic index, and\nthe y-axis is the iteration index. It is important to note that\nthe presence of blank blocks in the early iterations indicates\ncases where the population is not filled, due to the genera-\ntion of illegal code segments by LLM. As shown in Figure 5,\nMEOH heuristics can maintain diversity during the evolu-\ntionary process, while the diversity of EoH drastically dete-\nriorates. We also depict the average dominance-dissimilarity\nscore, as depicted in Figure 3 (d) and Figure 4 (d). Re-\nsults demonstrate the superiority of MEoH and the efficiency\nof our dominance-dissimilarity mechanism in maintaining\npopulation diversity."}, {"title": "5.5 Comparison to Any-time Performance", "content": "The performance of a single heuristic at any given time can\nprovide a set of heuristics that offer different trade-offs be-"}, {"title": "6 Conclusion, Limitation, and Future Work", "content": "Conclusion This paper developes a novel framework,\ntermed MEoH, for LLM-based multi-objective automatic\nheuristic design. We propose a dominance-dissimilarity\nmechanism for effective search in the discrete and com-\nplex heuristic space. We demonstrate MEoH on two widely-\nstudied combinatorial optimization problems to optimize\nboth heuristics' optimal gap and running time. Results show\nthat MEoH significantly outperforms existing LLM-based\nheuristic design methods including FunSearch and EoH in\nproducing trade-off heuristics over multiple objectives. The\nefficiency can be increased dramatically up to 10 times with\na close optimal gap. Moreover, additional ablation studies\nand visualization of the evolution process validate the su-\nperiority of MEoH over conventional MOEAs and the ef-\nfectiveness of the proposed dominance-dissimilarity mecha-\nnism in multi-objective automatic heuristic design.\nLimitation and Future Work While we have demon-\nstrated the effectiveness of MEOH, we only test it on two\nobjectives. We want to investigate the performance of MEoH\non many-objective cases and more heuristic design tasks."}, {"title": "A Algorithm Details", "content": "In this part, we elaborate on the details of parent selection and population management used in our proposed MEoH, as\nshown in Algorithm 1 and Algorithm 2, respectively.\nCalculation of Dominance-dissimilarity Score The lines 3-16 in Algorithm 1 and the lines 4-17 in Algorithm 2 are almost\nidentical, illustrating the computation of the dominance-dissimilarity score. Specifically, two square matrices, namely the dis-\nsimilarity score matrix S and the dominance mask matrix D, are initialized to be zeros. Each heuristic within the population is\ncompared in pairs, with their dissimilarity (negative AST similarity) and dominance relationships recorded in the corresponding\nmatrices. Subsequently, these matrices are element-wise multiplied to yield the dominance-dissimilarity score matrix S'. The\ndominance-dissimilarity vector v is then derived by summing the columns of S'. This vector encapsulates a blend of dominance\nand dissimilarity considerations, guiding the following parent selection and population management.\nParent Selection For parent selection, as delineated in Algorithm 1, the dominance-dissimilarity vector v is leveraged to con-\nstruct a probability distribution $\u03c0$ using the softmax function. The parents are subsequently sampled based on this distribution\nto strike a balance between exploration and exploitation.\nPopulation Management For population management, as shown in Algorithm 2, the dominance-dissimilarity vector v is\ndescending sorted, and the resulting indices k are utilized to truncate the population, and the first N individuals consists the\nnew population P'."}, {"title": "B Heuristic Design Task Details", "content": "We demonstrate the proposed method on two heuristic design tasks: 1) heuristics design for online Bin Packing Problem\n(BPP) and 2) heuristic design for guided local search for Traveling Salesman Problem (TSP). We introduce the detailed heuristic\ndesign settings for each task."}, {"title": "B.1 BPP", "content": "In online Bin Packing Problem (BPP) (Seiden 2002), a set of items, each with its own weight, needs to be packed into bins with\na predetermined capacity. The objective of the BPP is to minimize the total number of bins required to accommodate all the\nitems. In an online scenario, items are packed as they are received without prior knowledge.\nThe heuristic operates by loading items sequentially in an online fashion, requiring only the selection of the best bin at each\niteration. This designed function scores bins based on their remaining capacities and the size of the arriving item, with the\nhighest scoring bin chosen for each iteration. The function takes two inputs - the size of the arriving item and the remaining\ncapacities of the bins - and outputs a vector that ranks the bins accordingly. A task description used in the prompt and the\nPython code snippet requirements are illustrated as follows:"}, {"title": "B.2 TSP", "content": "For TSP, one of the widely used metaheuristics, Guided Local Search (GLS), is used (Voudouris, Tsang, and Alsheddy 2010).\nThe pipeline of GLS is as follows:\nStep 1: Create an initial solution using nearest neighbor constructive heuristics.\nStep 2: Local Search Stage: Perform a local search (swap and relocate) to improve the current solution and generate a local\noptimal solution.\nStep 3: Perturbation Stage: Update the distance matrix. Perform another local search based on the updated distance matrix\nto perturb the local optimal solution to escape from local optimality.\nSteps 2 and 3 are iteratively repeated until the stopping criterion (maximum number of iterations set to 1,000 in the experi-\nments) is satisfied. The best solution obtained throughout the iterations is considered the final solution.\nOur goal is to develop a heuristic to update the distance matrix in the perturbation step. The task description provided in the\nprompt and the requirements for the Python code snippet are outlined below. The inputs include the original distance matrix,\nthe local optimal solution, and the frequency of edge usage in perturbation. The output should be the updated distance matrix."}, {"title": "C Baseline Settings", "content": "In this work, we employ FunSearch (Romera-Paredes et al. 2024) and EoH (Liu et al. 2024) as baseline. For EoH, we inherit\nthe default settings, including the number of iterations T = 20, the parent selection size d = 5, and the population size N = 10\nfor the TSP and N = 20 for the BPP. Our MEoH also follows these settings. In summary, 1, 000 heuristics are generated for\nsolving TSP, and 2, 000 heuristics for BPP. For FunSearch, we also adopt the default settings, the number of islands is 10 and\nthe number of samples for each prompt is 4. FunSearch generates 10, 000 heuristics for solving BPP and TSP."}, {"title": "D Metric Definition", "content": null}, {"title": "D.1 HV", "content": "Hypervolume (HV) is calculated as follows:\n$HV(P, r^*) = VOL (\\bigcup_{v_i \\in P} [v_i, r_i^*]),$ (3)\nwhere $P$ represents the approximate Pareto front obtained by an automated algorithm design approach, $v = (v_1,..., v_M)^T$\ndenotes the corresponding objective vector, $VOL(\u00b7)$ represents the Lebesgue measure, and $r^* = (r_1,...,r_M)^T$ is a reference\nobjective vector.\nTo account for variations in HV values across different objective domains, i.e., the scalar of intrinsic objective value and the\nrunning time, we normalized each objective value for each instance. Specifically, the generated algorithm $x$ can be normalized\nin the objective space using the approximated ideal point $z^{ideal} = (z_1^{ideal},..., z_M^{ideal})$ and the approximated nadir point $z^{nadir} =\n(z_1^{nadir},...,z_M^{nadir})$ derived from the union of all approximated Pareto-front $P$ as\n$f'_i(x) = \\frac{f_i(x) - z_i^{ideal}}{z_i^{nadir}-z_i^{ideal}},$ (4)\nwhere $z_i^{ideal} = \\min\\{v_i | v \\in P\\}$ and $z_i^{nadir} = \\max\\{v_i | v \\in P\\}, \\forall i \\in \\{1, ..., M\\}$. Consequently, the value of each objective is\nnormalized to [0, 1]. Based on that, the reference point $r^* = (1.1, ..., 1.1)."}, {"title": "D.2 IGD", "content": "Inverted Generational Distance (IGD) measures the convergence and diversity of the obtained Pareto front approximation\nconcerning the true Pareto front. It is calculated as follows:\n$IGD(P, P^*) = \\frac{1}{|P^*|} \\sum_{p \\in P^*} \\min_{q \\in P} d(p,q),$ (5)\nwhere P is the set of decision vectors, i.e, the approximated Pareto front. P* is the true Pareto front, $ |P^* | $ is the number of\npoints in the true Pareto front d(p, q) is the Euclidean distance between the points p and q in the objective space.\nThe IGD calculates the average distance from the true Pareto front points to their nearest neighbor in the approximated Pareto\nfront. A lower IGD value indicates a better approximation of the true Pareto front.\nIt's important to note that the true Pareto front is required for calculating the IGD metric, which may not always be available\nin many cases. So, a reference set of well-distributed Pareto-optimal solutions is often used as an approximation of the true\nPareto front, here the reference set is the nondominated set derived from the union of all generated heuristics."}, {"title": "E Additional Experimental Results", "content": "In this section, we assess the influence of our proposed dominance-dissimilarity mechanism on the optimization process and\ncompare to two representative MOEAs: NSGA-II (Deb et al. 2002) and MOEA/D (Zhang and Li 2007). The experiments\nare conducted consistently across identical experimental settings, with each experiment repeated three times to ensure the\nrobustness and reliability of the results. To enhance clarity, the standard deviation, represented by the shaded area, is reduced\nby a factor of 0.3.\nAs shown in Figure 3 and Figure 4, compared NSGA-II and MOEA/D, our MEOH can achieve the best HV and IGD on\nboth BPP and TSP. These findings demonstrate the effectiveness of our dominance-dissimilarity mechanism, which integrates\nconsiderations from both the search and objective spaces, in improving the optimization process."}, {"title": "F Search Operators", "content": "MEOH inherits 5 search operators from EoH (Liu et al. 2024). These operators are all implemented based on LLMs. In this\npart, the corresponding prompts will be elaborated. Generally, the prompt consists of operator-specific guidance, task descrip-\ntion, and code requirements. For brevity, the task description and the code requirements are denoted as $Task Description and\n$Code Requirements, respectively."}, {"title": "F.1 E1 Operator", "content": "As shown in Figure 5, the E1 operator is used to explore a new heuristic different from the 5 selected heuristics. For simplicity,\nthe heuristics including corresponding algorithm description and code are omitted."}, {"title": "F.2 E2 Operator", "content": "As shown in Figure 6, the E2 operator is used to generate a new heuristic based on the common idea of the 5 selected heuristics."}, {"title": "F.3 M1 Operator", "content": "As shown in Figure 7, the M1 operator is desired to generate a new heuristic based on a given heuristics to improve the\nperformance."}, {"title": "F.4 M2 Operator", "content": "As shown in Figure 8, the goal of the M2 operator is to modify the parameters of a given heuristic."}, {"title": "F.5 M3 Operator", "content": "In Figure 9, the M3 operator is used to simplify a given heuristic by eliminating redundant components. In this context, the task\ndescription is not required. Furthermore, only the part introducing the input and output from code requirements is needed."}, {"title": "G Designed Heuristics", "content": "In this section, we present a variety of representative heuristics designed by LLM-based automated heuristic design frame-\nworks, encompassing FunSearch (Romera-Paredes et al. 2024), EoH (Liu et al. 2024), and our own MEOH."}, {"title": "G.1 BPP", "content": "EoH Heuristics The heuristic developed by EoH with the best performance in terms of the optimal gap, as shown in Fig-\nure 10, utilizes sophisticated mathematical operators such as logarithm, square root, and exponential. The complexity of this\nscoring function renders it challenging to construct manually due to its intricate nature and reliance on advanced mathematical\noperations."}, {"title": "G.2 TSP", "content": "EoH Heuristics The heuristic crafted by EoH, as illustrated in Figure 13, intricately incorporates advanced mathematical\nfunctions such as tanh alongside sophisticated parameters. It is noteworthy that this complex operation is executed within two\nnested for-loops, resulting in a computational complexity of O(n\u00b2)."}]}