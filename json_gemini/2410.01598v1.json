{"title": "Elaborative Subtopic Query Reformulation for Broad and Indirect Queries in Travel Destination Recommendation", "authors": ["Qianfeng Wen", "Yifan Liu", "Joshua Zhang", "George Saad", "Anton Korikov", "Yury Sambale", "Scott Sanner"], "abstract": "In Query-driven Travel Recommender Systems (RSs), it is crucial to understand the user intent behind challenging natural language (NL) destination queries such as the broadly worded \"youth-friendly activities\" or the indirect description \"a high school graduation trip\". Such queries are challenging due to the wide scope and subtlety of potential user intents that confound the ability of retrieval methods to infer relevant destinations from available textual descriptions such as WikiVoyage. While query reformulation (QR) has proven effective in enhancing retrieval by addressing user intent, existing QR methods tend to focus only on expanding the range of potentially matching query subtopics (breadth) or elaborating on the potential meaning of a query (depth), but not both. In this paper, we introduce Elaborative Subtopic Query Reformulation (EQR), a large language model-based QR method that combines both breadth and depth by generating potential query subtopics with information-rich elaborations. We also release TravelDest, a novel dataset for query-driven travel destination RSs. Experiments on TravelDest show that EQR achieves significant improvements in recall and precision over existing state-of-the-art QR methods.", "sections": [{"title": "1. Introduction", "content": "Air travel is a rapidly growing industry with revenues exceeding 800 billion USD in 2023 [3]. Providing personalized travel destination recommendations to users based on their natural language (NL) queries offers novel opportunities for the air travel industry to engage potential travelers and better serve their travel needs.\nA Query-driven Travel Destination Recommender System (RS) can leverage a retrieval subsystem to match NL queries to relevant passages in destination descriptions (e.g., sourced from CC-licensed content such as WikiVoyage\u00b9) and score destinations (e.g., as later defined in Algorithm 1). However, such a retrieval approach is prone to fail in light of challenging NL queries that often occur in the Travel RS setting as evident in the following two query types:\n1. Broad Queries: These are queries that specify a broad category and imply multiple potentially relevant subtopics (e.g., \u201ccities for youth-friendly activities\u201d).\n2. Indirect Queries: These are queries that do not directly reflect the user intent but require several further reasoning steps (e.g., \"cities for a high school graduation trip\").\nTo address such challenging NL queries, existing retrieval research has explored Query Reformulation (QR) to improve intent understanding [4, 5] with recent methods additionally leveraging Large Language Models (LLMs) [6, 7]. LLM QR methods focus on either (a) expanding queries w.r.t. diverse keywords using LLMs, which can be interpreted as a focus on adding subtopic breadth to the original query [1, 8] or (b) generating paraphrases or relevant answer passages, which can be interpreted as a focus on adding conceptual depth to the description [9, 1, 2, 10, 7].\nWe conjecture that both breadth and depth are key for connecting a user's NL queries to relevant recommendations in travel destination RSs. Further, we observe that LLMs' general reasoning abilities [11, 12] allow them to expand queries with both diverse (i.e., breadth) and nuanced (i.e. depth) content that facilitates more effective sparse and dense retrieval with broad and indirect queries.\nIn summary, we make the following contributions:\n1. We propose a novel LLM-based Elaborative Subtopic Query Reformulation (EQR) method 2 3 that infers multiple subtopic intents covering an original query (i.e., breadth) while providing information-rich elaborations of each subtopic (i.e., depth). EQR leverages the abilities of LLMs to understand and reason about broad and indirect user intent on the query side that facilitates effective matching via sparse and dense retrieval. A comparison of two existing QR method-ologies with EQR in Figure 1 provides clear evidence that EQR better addresses breadth and depth as we have conjectured.\n2. We introduce and release TravelDest, a novel man-ually curated benchmark dataset for query-driven travel destination RSs with 50 broad and indirect NL queries and complete relevance labels for 774 destination cities to support our initial comparative evaluation of Travel RS QR methods.\nWe conclude with a comparative evaluation of QR methods on TravelDest and find that EQR outperforms existing methods in terms of recall and precision metrics, thus im-proving the ability of Travel RSs to address challenging broad and indirect NL queries."}, {"title": "2. Related Work", "content": "We review Travel Recommender Systems followed by Query Reformulation that is the methodological focus of our con-tributions."}, {"title": "2.1. Travel Recommender Systems", "content": "Traditional travel RSs have primarily focused on query-free recommendations using collaborative filtering (CF) that leverages the collective travel patterns of users [13, 14], or content-based filtering (CBF) that recommends items similar to a user's past preferences using item features such as location, cost, and reviews [15, 16, 17].\nThese methods provide coarse insights into user infor-mation needs through their past non-textual interactions, such as clicks, purchases, and likes. However, NL queries provide a more nuanced form of user interaction that en-capsulates more explicit and personalized user information needs [18, 19]. This highlights a research need for explo-ration of query-driven travel RSs as we do in this work."}, {"title": "2.2. Query Reformulation", "content": "The literature on LLM-based QR methods can be broadly taxonomized into keyword, paraphrase, and relevant answer passage methods. While such QR techniques have been stud-ied for decades - with well-known examples being latent semantic analysis (LSA) [20, 21] and pseudo relevance feed-back (PRF) [22, 23, 24] - modern LLMs introduce the ability to use internalized NL knowledge for query reformulation in highly versatile ways as we discuss below.\nKeyword-based methods focus on expanding the origi-nal query to include broader coverage of subtopics or rel-evant terms [1, 8, 25]. In a recent line of work, Q2E[1] experimented with different setups for keyword-level LLM-based expansion, including zero-shot vs. few-shot prompt-ing, chain-of-thought prompting, and the incorporation of PRF. ProQE [26] utilized LLMs in a PRF setting to assess the relevance of retrieved pseudo-documents and extract keywords from them.\nParaphrase-based methods [10] and answer passage-based methods [1, 2, 9] focus on enhancing the depth of the original query by either rephrasing the query to bet-ter reflect user intent (e.g., GenQR [7]) or enriching it with information-rich relevant answers (e.g., GQR [10]). Addi-tionally, several studies propose generating relevant answer passages directly using LLMs and demonstrate effectiveness in both sparse and dense retrieval, e.g., Query2Doc [2] in few-shot settings by concatenating the original query with the answer passage and Q2D [1] using various prompting setups and a similar concatenation approach.\nCurrent QR methods appear to focus exclusively on either expanding the breadth or depth of queries, but not simul-taneously, which we previously conjectured in Section 1 is a limitation of QR methods for broad and indirect queries. Further, while non-LLM-based QR methods have been ex-plored in RSs [27, 28], there is a research need to investigate the use of LLM-based methods in query-driven RSs, which is important as the information needs and intent behind NL queries in RSs can differ from standard retrieval [15, 29]."}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Query-driven Travel Recommendation", "content": "Let q be an NL travel destination query, and let D be the set of all travel destinations. Each destination $d_i \\in D$ is asso-ciated with a document $C_{d_i} = \\{c_1, c_2,..., c_m\\}$ describing the destination $d_i$, where each $c_j$ represents a paragraph within the document.\nThe objective of the travel RS is to generate a ranked list S that orders each $d_i \\in D$ based on a scoring function. A"}, {"title": "Algorithm 1 Destination Scoring Algorithm", "content": "1: q' Reformulate(q) {See Section 3.2}\n2: for each destination $d_i \\in D$ do\n3: for each paragraph $c_j \\in C_{d_i}$ do\n4: $q' \\leftarrow Encode(q')$\n5: $c_j \\leftarrow Encode(c_j)$\n6: $score(q',c_j) \\leftarrow cos(q',c_j)$ {dense} or BM25$(q',c_j)$\n7: end for\n8: $C_{q'} \\leftarrow top\\text{-}n\\text{ paragraphs }\\{c_1, c_2, ..., c_n\\} \\text{ using score(q',c_j)}$\n9: $score(d_i) \\leftarrow \\frac{1}{n}\\sum_{c_j \\in C_{q'}} score(q', c_j) \\text{ {Avg of top-n scores}}$\n10: end for\n11: $S \\leftarrow Sort\\text{ destinations }d_i\\text{ in descending order of score(}d_i\\text{)}$"}, {"title": "3.2. Query Reformulation", "content": "In this work, we fix the structure of the Query-driven Travel Recommender as in Algorithm 1 while experimenting with the impact of different QR methods to implement Line 1, defined as follows:\nNo QR : q' = q, which means no QR is applied.\nQ2E [1]: q' = q + LLM(q, Q2E-prompt), which expands the original query by adding multiple keywords us-ing the LLM. See Figure 2 (top-left) for a detailed prompt.\nQuery2Doc [2]: q' = q + LLM (q, Query2Doc-prompt), which generates relevant answer passages from the query using the LLM and concatenates them with the original query. See Figure 2 (top-right) for a detailed prompt.\nGenQR [7]: q' = q+LLM(q, GenQR-prompt), which para-phrases the original query using the LLM. See Figure 2 (bottom-left) for a detailed prompt.\nEQR : q' = q + LLM(q, EQR-prompt), which generates k subtopic elaboration paragraphs from the query using the LLM. See Figure 2 (bottom-right) for a detailed prompt and Section 3.3 for a detailed dis-cussion on EQR."}, {"title": "3.3. EQR: Elaborative Subtopic Query Reformulation", "content": "The general idea behind our novel contribution of EQR as motivated in Section 1 is to infer multiple subtopics from an original query (i.e., breadth) while elaborating each with information-rich content using the LLM's general reasoning abilities (i.e., depth).\nSpecifically, EQR begins with generating k distinct subtopics from a given NL query q, which adds a breadth as-pect to capture a wider range of relevant or latent subtopics compared to answer-based and paraphrase-based methods [9, 2, 1, 10]. Following this, EQR produces an information-rich elaboration for each subtopic, denoted $e_1, e_2,..., e_k$,"}, {"title": "4. TravelDest: Benchmark Dataset for Travel Destination Recommender Systems", "content": "To facilitate our empirical comparison of QR methods for Query-driven Travel RS, we introduce TravelDest\u00b9 de-signed specifically for travel RS with a focus on broad and indirect travel queries. TravelDest consists of 50 broad and indirect NL travel queries, spanning various categories, including cultural, adventure, nature, entertainment, and culinary. The dataset contains full per-query labels for 774 target destination cities accessible by major airlines, each with a WikiVoyage\u00b9 CC-licensed detailed text description.\nThe ground truth for each query was established by ask-ing three human labellers to manually assess all 774 target cities per query and assign relevance scores on a scale from 1 to 5. Cities achieving an average score of at least 3 were selected and verified by two additional independent travel experts to ensure relevance."}, {"title": "5. Experiments", "content": "We comparatively evaluate the query-driven RS methodol-ogy of Algorithm 1 using each of the QR methods defined"}, {"title": "5.1. Setup", "content": "We tested dense retrieval via cosine similarity using the TAS-B [31] and MiniLM [32] encoders, which are both pop-ular BERT-based sentence transformer models [33] based on a HuggingFace implementation [34]. We tested sparse re-trieval via BM25 [30] using the Python Rank-BM25 library implementation [35]. For each query, the system retrieves the top-n most relevant paragraphs from each wikivoyage destination document. We refer to the Appendix for full details and analysis of hyperparameter tuning for n.\nWe compared EQR against various LLM-based QR meth-ods (cf. Section 3.2), with both sparse and dense retrievers as outlined above. Across all QR methods, we utilized GPT-40 [36] as the commonly shared gold standard LLM for query reformulation."}, {"title": "5.2. Metrics", "content": "We primarily focus on Recall metrics to ensure the minimal number of relevant items are missed (critical for geograph-ical fairness) and report Recall@30 and Recall@50. Addi-tionally, we report R-Precision to verify system precision relative to the actual ground truth size and MAP@30 and MAP@50 to assess system ability to rank more relevant destinations earlier in the results list."}, {"title": "5.3. Results", "content": "Table 1 presents the full comparative results for different QR methods on 50 broad and indirect queries using the Trav-elDest dataset, with various recall and precision evaluation metrics reported.\nRQ1: EQR outperforms other LLM-based QR methods across all evaluation metrics and retriever types (and with high statistical significance in many cases). EQR en-hances coverage of retrieved destinations compared to depth-focused answer-passage-based methods, as reflected by its notable improvement at higher k-levels (i.e., @50) over Query2Doc, and also appears to provide better intent reasoning compared to breadth-focused expansion-based methods, as indicated by its significant improvement com-pared to Q2E.\nRQ2: All QR methods achieved greater scores in dense retrieval than in sparse retrieval, as well as greater improve-ments in scores when compared to No QR. This suggests that for query-driven RSs in the travel domain (with broad and indirect queries), dense retrieval may be more effective than sparse retrieval, likely because keyword matching in sparse retrieval cannot fully capture the nuances embedded in both original and reformulated queries. Interestingly, EQR still performs the best among all baselines in sparse retrieval, indicating that the idea of combining breadth and depth in query reformulation applies to both sparse and dense retrieval."}, {"title": "6. Conclusion", "content": "We introduced Elaborative Subtopic Query Reformulation (EQR), an LLM-based QR method that adds both depth and breadth by generating multiple, information-rich subtopic elaborations to a broad or indirect query. We also intro-duced the TravelDest benchmark dataset to evaluate query-reformation in travel RSs, with EQR demonstrating state-of-the-art performance across evaluation metrics and retriever types. Future work includes extending EQR to conversa-tional RSs (e.g., [37, 38, 39, 40]) and diverse travel data types such as destination reviews (e.g., [41, 42, 43])."}, {"title": "A. Analysis of Hyperparameters", "content": ""}, {"title": "A.1. Effect of Top-n Paragraphs", "content": "In this section, we discuss how the number of top para-graphs aggregated by the retrievers affects the performance of travel RSs in order to determine the optimal n for various retrievers. We examine the scenario where no QR method is applied. According to Figure 3, we observed a performance increase across different evaluation metrics for all types of retrievers w.r.t. the number of top paragraphs, which was then followed by a plateau. We report the optimal values for n and adopt them in Section 5.1:\n\u2022 Dense - TAS-B: n = 31\n\u2022 Dense - MiniLM: n = 18\n\u2022 Sparse - BM25: n = 13"}, {"title": "A.2. Effect of Number of Subtopics", "content": "In this section, we discuss the influence of the number of subtopics k generated in EQR methods by testing k values from 5 to 20. As shown in Figure 4, we did not observe a clear trend between k and the performance of EQR across different types of retrievers. We report the performance for k = 12 for all types of retrievers."}, {"title": "B. Ablation Studies", "content": "To test the robustness of EQR, we conducted two ablation studies on the prompts of EQR using the TAS-B dense encoder."}, {"title": "B.1. Few-shot Examples", "content": "We evaluated the performance of EQR with and without few-shot examples. The results did not show a significant difference, with the prompt using few-shot examples per-forming slightly better on recall-based metrics, while the version without few-shot examples performed better on MAP."}, {"title": "B.2. Target Destinations List", "content": "We evaluated the performance of EQR with and without the 774 target destination list provided in the prompt to define a valid range of choices for the LLM to select as examples. The results were mixed: the version with the target destination list performed better on MAP and Recall@30, while the version without it performed better on Recall@50."}]}