{"title": "Formative Study for Al-assisted Data Visualization", "authors": ["Rania Saber", "Anna Fariha"], "abstract": "This formative study investigates the impact of data quality on AI-assisted data visualizations, focusing on how uncleaned datasets influence the outcomes of these tools. By generating visualizations from datasets with inherent quality issues, the research aims to identify and categorize the specific visualization problems that arise. The study further explores potential methods and tools to address these visualization challenges efficiently and effectively. Although tool development has not yet been undertaken, the findings emphasize enhancing AI visualization tools to handle flawed data better. This research underscores the critical need for more robust, user-friendly solutions that facilitate quicker and easier correction of data and visualization errors, thereby improving the overall reliability and usability of AI-assisted data visualization processes.", "sections": [{"title": "1 Introduction", "content": "With the emergence of AI tools such as ChatGPT in today's data-driven world, the ability to visualize data effectively is crucial for extracting actionable insights from large and complex datasets. AI-assisted data visualization tools have gained prominence due to their capability to automate and enhance the visualization process, making it accessible to a wider audience. However, the effectiveness of these tools is heavily dependent on the quality of the underlying data. Poor data quality, characterized by errors, inconsistencies, and missing values, can lead to inaccurate or misleading visualizations, ultimately compromising decision-making processes.\nDespite the growing reliance on AI-driven visualization tools, there is a significant gap in understanding how these tools handle uncleaned datasets. This study addresses this gap by exploring the specific challenges and limitations of AI-assisted visualizations when faced with data quality issues. By generating visualizations using uncleaned datasets, we aim to identify and categorize common visualization problems, providing valuable insights into the weaknesses of current AI tools in processing flawed data.\nThe primary objective of this research is to investigate methods and tools that could potentially address these visualization issues quickly and effectively. While this study focuses on identifying the problems and proposing potential solutions, it does not yet involve the development of new tools. Instead, it lays the foundation for future work aimed at enhancing the efficiency and usability of AI-assisted data visualization tools.\nThis research is significant as it highlights the critical need for more robust solutions in the field of AI-assisted data visualization. By understanding the impact of data quality on visualization outcomes, we can begin to design tools that better handle imperfect data, thereby improving the reliability and utility of these visualizations in real-world applications. The findings of this study are expected to inform future efforts to develop faster, more user-friendly tools that facilitate the correction of data and visualization errors, ultimately leading to more accurate and trustworthy visualizations."}, {"title": "2 Literature Review", "content": "Before conducting experiments, I reviewed several key research papers to provide a solid foundation for my study. These papers offered insights into the relationship between data quality and automated visualizations, as well as the tools and methods used to address common issues. Through this review, I gained a deeper understanding of how poor data quality impacts AI-assisted visualizations and what methods have been proposed to mitigate these problems.\nOne of the key papers I explored was \"Surfacing Visualization Mirages\" by [4]. In this paper, the authors introduced the concept of \"visualization mirages\"-errors or distortions in visualizations caused by noise, bias, or poor data quality. I was particularly interested in how poor data quality can lead to misleading visualizations and the potential consequences for users who rely on these visualizations for decision-making. The paper's focus on identifying and mitigating these mirages provided valuable insights into the types of data issues that might arise during my own research. Their methods for recognizing and addressing mirages helped shape my approach to analyzing the visualizations generated by AI, particularly when dealing with unclean datasets. The authors emphasized the importance of first identifying the sources of inaccuracies before attempting to resolve them, a principle I adopted in my own experiments.\nBuilding on this foundation, I also reviewed \"Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study\u201d by [6]. This study examined the ability of large language models (LLMs) to handle visualization tasks based on natural language input. The authors demonstrated that while LLMs have great potential for automating the creation of data visualizations, they face limitations when dealing with more complex or unclean datasets. This paper was particularly relevant to my study because it highlighted the capabilities and shortcomings of AI models when tasked with generating visualizations, especially in scenarios where data quality is compromised. It helped frame my understanding of how well LLMs handle visualization tasks and what challenges arise when these models are applied to datasets with inherent quality issues.\nIn addition to these foundational studies, I explored research on tools designed to detect and correct visualization errors. The paper \"Linting for Visualization: Towards a Practical Automated Visualization Guidance System\" by [5] introduced a linting system that automatically detects and flags errors in visualizations. This system provides real-time feedback to users, enabling them to identify and correct mistakes early in the process. Their research demonstrated the value of automated guidance in improving the accuracy of visualizations, particularly when users are dealing with complex datasets. This paper informed my understanding of how AI-assisted tools can be enhanced by integrating automated error-checking mechanisms.\nSimilarly, \"VisuaLint\" by [2] focused on providing real-time annotations to help users detect chart construction errors. Their approach to identifying visualization errors aligns with my research goal of understanding how AI tools can assist users in correcting visualizations based on unclean data. The idea of \"sketchy\" annotations, as described in this paper, highlighted the potential for Al systems to offer iterative feedback and guidance, which I considered while designing the error correction process in my experiments.\nFurther insights were gained from \"The Data Linter: Lightweight Automated Sanity Checking for ML Data Sets\" by [3], which introduced a system for automatically checking the quality of datasets used in machine learning pipelines. This system's lightweight, automated approach to identifying data quality issues underscored the importance of early detection and correction of data problems before visualizations are generated. This paper helped me better understand the role of automated tools in ensuring data integrity and informed my approach to evaluating the impact of unclean data on Al-generated visualizations.\nFinally, the work of [1] in \"VizLinter: A Linter and Fixer Framework for Data Visualization\" further contributed to my understanding of how automated systems can not only detect errors in visualizations but also suggest fixes. Their framework extended traditional linting by providing users with actionable solutions to correct data quality issues, an approach that I aimed to explore in my own study. The ability of AI tools to offer suggestions for correcting errors, rather than just identifying them, was a key focus of my analysis.\nThese studies collectively provided a strong foundation for understanding the challenges and opportunities in AI-assisted data visualization, particularly when dealing with poor data quality. While previous research has explored various tools and methods for detecting and correcting visualization errors, there remains a gap in understanding how AI-driven systems cope with unclean datasets. My research builds on these ideas by exploring how data quality issues specifically affect AI-generated visualizations and how these errors manifest when using unclean datasets."}, {"title": "3 Methodology", "content": "This study was conducted in three phases to explore the impact of data quality on Al-assisted data visualizations. The first phase involved analyzing visualizations created from a clean dataset, while the second phase focused on using an unclean dataset. The third phase consisted of an experimental study where specific data quality issues were systematically injected into clean datasets to observe their impact on visualizations."}, {"title": "3.1 Phase 1: Clean Dataset Analysis", "content": "A clean dataset, the 911 dataset from Kaggle, was selected for initial analysis. This dataset was chosen due to its well-documented structure and absence of quality issues, making it ideal for baseline comparisons. Ten different visualizations were generated using ChatGPT by providing the first five rows of the dataset and specifying the desired visualization type. Python scripts provided by ChatGPT were executed in Google Colab, and any errors in the visualizations or code were noted. The process of correcting these visualizations was documented, including the number of iterations and steps required to resolve any issues."}, {"title": "3.2 Phase 2: Unclean Dataset Analysis", "content": "For the second phase, The Metropolitan Museum of Art Open Access dataset from GitHub was used, which included several known quality issues such as missing values, inconsistent information, and possible duplications. The objective was to generate visualizations using ChatGPT, similar to the clean dataset phase, and document the errors and corrections. ChatGPT was allowed three attempts to fix each visualization error. The time taken and the difficulty of resolving each issue were recorded to evaluate the challenges associated with unclean data."}, {"title": "3.3 Phase 3: Experimental Study with Injected Data Quality Issues", "content": "In the third phase, ten clean datasets were selected, and eight different data quality issues were systematically injected into these datasets. These issues included missing data, duplicate data, inconsistent data, inconsistent data types, inaccurate data, irrelevant data, data entry errors, and incorrect data formats. Each modified dataset version was used to generate five different types of visualizations: pie charts, word clouds, histograms, heat maps, and scatter plots, totaling fifty visualizations per dataset. Python scripts were developed to automate the injection of data quality issues, such as removing 15% of values to simulate missing data or randomizing data formats to create inconsistencies.\nThe visualizations were analyzed to assess how each type of data quality issue affected the outcome. Errors, iterations, and time taken to correct visualizations were meticulously documented, providing insights into the specific challenges posed by different types of flawed data.\nNote on study limitations:\nThe experimental study phase was initiated in the seventh week of a ten-week Distributed Research Experiences for Undergraduates (DREU) program. Due to time constraints, not all planned analyses and evaluations of the various injected data quality issues were completed. Specifically, while initial efforts focused on generating and analyzing visualizations with several data quality issues, the comprehensive examination of all intended issues was not fully realized. This limitation should be considered when interpreting the findings, as further work is needed to complete the analysis of the remaining data quality issues."}, {"title": "3.4 Data Analysis", "content": "3.4.1 Approach and Framework. The analysis focused on understanding the effects of data quality issues on AI-assisted data visualizations and their impact on users who rely on these visualizations for decision-making. The study adopted a user-centered approach, wherein each visualization was evaluated from the perspective of a user encountering these data issues. This involved both qualitative and observational analysis to assess the clarity, accuracy, and reliability of the visualizations produced.\n3.4.2 Evaluation Criteria. The analysis was guided by the following key criteria:\n\u2022 Visual Integrity: Assessing whether the visualization accurately represents the data. This includes checking for distortions, misleading representations, or inaccuracies caused by data quality issues.\n\u2022 Clarity and Comprehensibility: Evaluating how easily a user can understand the visualization. This involves considering whether the data quality issues resulted in visual clutter, confusing graphics, or an overwhelming amount of information.\n\u2022 Insightfulness: Determining the extent to which the visualization provides meaningful insights. This criterion assesses whether the data quality issues obscure or highlight trends and patterns in ways that might mislead or confuse a user.\n\u2022 User Confidence: Assessing how the presence of data quality issues might affect a user's trust and confidence in the visualization. This involves considering whether a user would find the visualization reliable or useful for decision-making, given the observed data issues.\n3.4.3 Analytical Procedure.\n(1) Observation of Effects: For each visualization created, detailed observations were recorded regarding how specific data quality issues (such as missing data, duplicate data, or inconsistent data types) impacted the visual output. This included noting any anomalies, unexpected results, or misrepresentations that occurred due to these issues.\n(2) Impact Assessment: Placing oneself in the role of a user, the analysis focused on the potential cognitive and interpretative challenges these visualizations would present. This involved reflecting on how a user might perceive and react to the inaccuracies or complications caused by the data quality problems.\n(3) Categorization of Issues: The observed effects were categorized based on the type of data quality issue and the nature of the visualization error or distortion it caused. This categorization helped in identifying common patterns and understanding the specific ways in which different data issues affect visualization outcomes.\n(4) Iterative Feedback Loop: Using an iterative approach, each visualization was reassessed after corrections were suggested and implemented by ChatGPT. This helped in evaluating the effectiveness of the AI in addressing the identified data issues and understanding the limitations of AI-assisted visualizations in handling flawed data"}, {"title": "4 Results", "content": "This section presents the findings of the study, organized into three phases: analysis of a clean dataset, analysis of an unclean dataset, and an experimental study with injected data quality issues."}, {"title": "4.1 Phase 1: Clean Dataset Analysis Results", "content": "Visualizations created from the clean dataset largely adhered to the expected results, with only minor corrections needed in some cases. The visualizations created in this phase were mostly accurate, though a few errors were encountered during the generation process, which were either corrected by ChatGPT or flagged by the user. These errors can be classified into two categories: code errors and visual errors. The first category, code errors, included errors such as KeyError, RuntimeError, and TypeError, which were immediately identified and thrown by the Python script. For instance, in the bar chart (visualization #3), a KeyError occurred due to incorrect column referencing, which was automatically corrected in the second iteration after the code was adjusted. Similarly, in the map visualization (#4), a RuntimeError was encountered because the mapping library failed to load due to missing data references, which was resolved in the second attempt by fixing the data input format. These types of errors were easily detectable by the system, allowing ChatGPT to assist in correcting them after the initial iteration.\nThe second category, visual errors, were not caught by the code itself but were noticeable as a user in the final visualization output. In these cases, the Python code executed successfully without error messages, but the resulting visualizations were flawed or unreadable due to incorrect data interpretation. For example, in the comparison bar chart (visualization #6), too many bars were generated, resulting in an overcrowded chart, which made it unreadable. This issue occurred because the dataset was incorrectly interpreted, causing the visualization to include extraneous categories that were not relevant. This error required user intervention to notice and correct.\nIn visualization #7 (word cloud), the type of data being displayed was incorrect-words that should not have appeared in the word cloud were included due to a mismatch in the dataset columns used for analysis. This issue was not flagged by the code, but the user had to manually identify the error and modify the dataset input for the visualization to reflect the correct words. Additionally, in visualization #8 (pie chart), the zip codes were incorrectly displayed as decimal numbers instead of integers. Although the visualization was technically correct in terms of structure, this formatting issue can cause different problems for a user when interpreting it. In this case, the error did not affect the logic of the code, but it created a misleading or unclear visualization that had to be manually corrected.\nOverall, the errors in this phase were either detected automatically by the code (and subsequently fixed by ChatGPT) or noticed by the user in the visual outputs, requiring manual corrections. The visual errors, in particular, highlight the importance of user oversight in ensuring that AI-assisted visualizations accurately reflect the intended data."}, {"title": "4.2 Phase 2: Unclean Dataset Analysis Results", "content": "In this phase, visualizations were generated using an unclean dataset from The Metropolitan Museum of Art Open Access dataset. Several data quality issues were present in this dataset, such as missing values, inconsistent data types, duplicate data, and incomplete documentation. These issues led to a variety of data mirages that distorted the accuracy and reliability of the visualizations. \nThe visualizations created during this phase encountered several types of errors, both from code-related issues and visual inaccuracies caused by the underlying data. Data mirages, in particular, significantly distorted the interpretation of the visualizations. 4.2.1 Overview of Errors and Data Mirages. The visualizations created during this phase encountered several types of errors, both from code-related issues and visual inaccuracies caused by the underlying data. Data mirages, in particular, significantly distorted the interpretation of the visualizations."}, {"title": "4.2.2 Analysis:", "content": "(1) Artwork Distribution by Department (Bar Chart)\n\u2022 Prompt: \"Create a bar chart using this dataset and information I gave you to visualize the distribution of artworks across different departments of the museum.\"\n\u2022 Initial Code: The initial code was provided by ChatGPT based on the prompt, which was designed to visualize the distribution of artworks across different museum departments.\n\u2022 Error Encountered: A NameError was thrown when running the code, indicating that a variable or function had not been correctly defined.\n\u2022 Fix and Resolution: ChatGPT was able to identify and correct the NameError in the second iteration. After making the necessary adjustments to the code (correcting the undefined variable), it successfully generated the desired bar chart.\n\u2022 Code After Fix: The adjusted code (after the error was fixed) ran without issues and produced the correct visualization.\n\u2022 Time Taken: 10 minutes.\n\u2022 Iterations: 2 iterations were needed to resolve the issue and generate a proper bar chart fully.\n\u2022 Observation: The error encountered was a basic coding mistake, which was quickly resolved by ChatGPT. Once fixed, the visualization was generated without any further complications. This particular visualization did not exhibit any data mirages, as the dataset was relatively clean for this analysis.\n(2) Temporal Distribution of Artworks (Histogram)\n\u2022 Prompt: \"Create a histogram showing the distribution of artworks by their object begin dates.\"\n\u2022 Initial Code and Observations: The initial code provided by ChatGPT resulted in an incorrect visualization, with all artworks grouped under the year \"0\" on the x-axis. This was due to inconsistencies in the \"Object Begin Date\" column of the dataset. The data contained various formats, such as numeric values, date ranges, and approximations (e.g., \"1850,\u201d \u201ccr. 1850,\u201d \u201c1850-80,\u201d and \u201cca. 1850\"). These inconsistencies made it difficult for ChatGPT to generate an accurate histogram on the first attempt.\n\u2022 Error Encountered: The visualization did not parse the object begin dates correctly, leading to the incorrect placement of all artworks under \"0.\"\n\u2022 Steps taken:\nFeedback 1: After observing the issue, I asked ChatGPT why all artworks were being placed under \"0.\u201d ChatGPT explained that the issue stemmed from how the dates were being read or processed.\nFeedback 2: I informed ChatGPT that the dataset contained inconsistent date formats, such as \"1850-80\" and \"cr. 1850-80,\" and asked for an update to the code to account for these variations.\nResult: ChatGPT updated the code but encountered a TypeError related to data types, which it successfully corrected in the next iteration."}, {"title": "(3) Culture Composition (Pie Chart)", "content": "\u2022 Prompt: \"Create a pie chart to display the composition of artworks by Culture (e.g., American, Mexican, etc.).\"\n\u2022 Initial Code and Observations: ChatGPT initially generated a pie chart based on the provided dataset, which appeared correct at first glance. However, upon closer examination of the \"Culture\" column, it became clear that the data contained multiple inconsistencies. These included entries with multiple cultures combined (e.g., \"American or French\"), entries with subcultures (e.g., \"Chinese, for American market\"), and entries with null values. Additionally, some entries had qualifying remarks (e.g., \"French, probably\"), making it difficult to group cultures accurately.\n\u2022 Challenges Encountered:\nData Inconsistencies: The dataset contained inconsistent entries, such as cultures combined into a single entry, subcultures listed after commas, and ambiguous values like \"Attic\" (a subcategory of Greek culture), which led to inaccurate results in the visualization.\nMissing Data: The dataset included many null cells, which resulted in missing data being ignored by the original visualization. An \"unknown\" category was created for these missing entries after further prompting.\nValueError: During one of the iterations, a ValueError was thrown due to duplicate values in the dataset. This was resolved by resetting the index of the DataFrame to eliminate duplicates.\n\u2022 Steps taken:\nInitial Visualization: A pie chart was generated, but the inconsistent and missing data led to inaccurate cultural representations. For example, subcultures such as \"Attic\" (Greek civilization) were listed as separate cultures rather than grouped with the broader \"Greek\" culture.\nIteration 2: After noticing the null data cells, I informed ChatGPT, which then created an \"unknown\" category for missing data. During this iteration, a ValueError was thrown and subsequently fixed by resetting the DataFrame's index.\nIteration 3: I informed ChatGPT of the presence of entries like \"American or French\" and asked it to account for these types of cases in the visualization. ChatGPT provided an updated visualization, but further inconsistencies remained.\nIteration 4: While parsing the dataset, I discovered more complex entries, such as subcultures within general cultures (e.g., \"Attic\u201d and \u201cGreek\u201d listed separately). I asked ChatGPT to address this by grouping subcultures with their parent cultures. However, this required a deeper understanding of the dataset and cultural history, which was not fully handled by the AI.\nIteration 5: I pointed out additional inconsistencies, such as cultures with qualifiers and subcategories. ChatGPT made progress by creating grouped categories for these subcultures, but more complexities remained.\nIteration 6: Finally, I identified redundant entries, such as \"Japan\" and \"Japanese\u201d listed as separate categories, even though they referred to the same culture. I prompted ChatGPT to fix this, and a more accurate pie chart was produced.\n\u2022 Time taken: Al-assisted time: Approximately 3 hours, spread across 6 iterations. Human intervention: Significant manual input was required to identify and flag the numerous data inconsistencies.\n\u2022 Iterations: 6 iterations were required to reach an acceptable solution.\n\u2022 Level of Difficulty: Difficult (due to the complexity of data cleaning and categorization).\n\u2022 Final Observations: The dataset presented significant challenges in handling subcultures and combined cultures. ChatGPT was able to handle some cases by creating mapping rules and managing a mapping dictionary to group similar cultures together (e.g., \"Attic\" and \"Greek\"). However, human oversight was essential for identifying new cases of repetition and inconsistency that did not appear in the first rows of the dataset. Even after multiple iterations, certain subcultures were still misrepresented in the visualization, suggesting that additional cases in the dataset were not covered. The process of cleaning the data and ensuring accurate cultural representation was time-consuming, highlighting the limitations of AI tools when working with complex, unclean datasets. Human intervention was necessary to review and manually inspect the entire dataset for these issues."}, {"title": "(4) Geographical Representation of Artworks (Heatmap)", "content": "\u2022 Prompt: \"Create a heatmap of the different cities/countries that each artwork came from.\"\n\u2022 Data Observations: The dataset contains several inconsistencies, including missing data and duplicate entries (e.g., \"United States | England\" or \"United States | United States\"). Additionally, there were entries where countries were uncertain or described with qualifiers (e.g., \"France or North Spain,\" \"possibly Syria,", "Southern Italy\"), which made it difficult to correctly plot the origins of the artworks on the heatmap. Furthermore, differences between the dataset's country names and those in the geopandas library added to the complexity of the task.\n\u2022 Iterations": "nIteration 1: The initial heatmap was generated, but many countries had missing data. The dataset's inconsistencies caused certain artworks to be incorrectly mapped or excluded from the heatmap.\nIteration 2: Upon reviewing the data further, I realized that many artworks were misrepresented due to the input format. For example, entries like \"France or North Spain\" and \"Gaul (Northern France)\" were not parsed properly, leading to an incorrect representation of the countries where the artworks originated. This resulted in a disproportionate number of artworks appearing to come from Egypt, while other countries were underrepresented.\nIteration 3: I asked ChatGPT why certain countries were missing on the map despite being present in the dataset. ChatGPT identified that this issue could be caused by discrepancies between the country names in the dataset and those in the geopandas library. For example, in the dataset, the USA is listed as \"United States,\" while geopandas uses \"United States of America.\" Older country names or inconsistent spellings also contributed to missing data on the map.\nIteration 4: After identifying and mapping some of the differences between the MET dataset and the geopandas dataset, ChatGPT was able to correct certain countries. However, many regions and civilizations were still not properly mapped. This was particularly evident for historical regions or subregions that did not match modern country boundaries in the geopandas library, such as \"Byzantine Egypt\" or \"North Africa (box) | Spain (lid).\"\n\u2022 Time taken: Al-assisted time: 5 hours. Human intervention: 2 days were required to manually identify and match the differences between country names in the dataset and the geopandas library.\n\u2022 Iterations: 4 iterations were required to fix the major inconsistencies, though many issues remained unresolved due to the complexity of mapping historical regions and inconsistent data entries.\n\u2022 Level of Difficulty: Moderately difficult (due to the need to match country names between two datasets and handle geographic inaccuracies).\n\u2022 Final Observations: The main challenge in this visualization was aligning the dataset's country names with those recognized by the geopandas library. For example, \"United States\" was not recognized by geopandas, causing the USA to be omitted from the map until it was corrected to \"United States of America.\" Additionally, many historical or ambiguous regions (e.g., \"Gaul,"}, {"title": "(5) Text Analysis of Medium (Word Cloud)", "content": "\u2022 Prompt: \u201cGenerate a word cloud visualization from the description of the mediums to show common materials and techniques from the 'Medium' column.\"\n\u2022 Initial Code and Observations: ChatGPT generated an initial word cloud based on the data from the \"Medium\" column of the dataset. While the word cloud appeared visually correct, a closer look revealed that several terms were duplicated (e.g., \"silver,\" \"terracotta,\" \"commercial,\" \"color,\" and \"gelatin\"). This duplication distorted the representation of the most common materials, as the same word appeared multiple times in the visualization.\n\u2022 Data Mirage: The word cloud gave the false impression that certain terms were more frequent than they actually were, due to the repetition of the same words. This data mirage led to an inaccurate understanding of the frequency of materials and techniques used in the artworks.\n\u2022 Iterations:\nIteration 1: The initial word cloud showed duplicated terms, which led to misrepresentations of the data.\nIteration 2: After prompting ChatGPT to remove the duplicates, some terms were corrected, but others remained. The issue of duplicated words persisted, with terms like \"silver\" and \"color\" still appearing multiple times.\nIteration 3: To address the persistent issue, ChatGPT implemented a tokenizer and stemmer to break down the words into root forms and attempt to eliminate duplicates. However, the duplicated terms continued to appear, suggesting that the underlying data may have had inconsistencies or variations in how the terms were stored (e.g., case sensitivity or minor spelling differences).\nIteration 4: In this final iteration, I prompted ChatGPT to clean up irrelevant terms and further refine the word cloud by ensuring that only unique, meaningful terms were displayed. The result was a more accurate word cloud, but some minor issues with term duplication remained due to the complexity of handling variations in the dataset.\n\u2022 Time Taken: Al-assisted time: 60 minutes. Human Inter-vention: 3 hours\n\u2022 Iterations: 4 iterations were required to reach a satisfactory visualization."}, {"title": "(6) Acquisition Analysis (Violin Plot)", "content": "\u2022 Prompt: \"Create a violin plot to visualize the distribution of acquisition methods used over time for this dataset.\"\n\u2022 Data Insights: The Accession Year column, which contains the dates of acquisition, is mostly consistent, though there are some null data cells. The Credit Line column, which describes the acquisition method, is entered as descriptive text (e.g., \"Gift of Mr. and Mrs. John Doe\"). ChatGPT's initial approach involved splitting the acquisition methods into three categories: gift, purchase, and other. This basic classification does not account for the full complexity of the descriptions in the Credit Line column.\n\u2022 Iterations:\nFirst Iteration: The initial code provided by ChatGPT threw a TypeError. This error was likely due to issues handling the null values in the AccessionYear column or misinterpreting certain entries in the Credit Line column.\nSecond Iteration: After prompting ChatGPT to address the error, the TypeError was resolved, and a violin plot was successfully generated. The plot displayed the distribution of acquisition methods (categorized into gift, purchase, and other) over time.\n\u2022 Time taken: Al-assisted time: 30 minutes (including error correction and generation).\n\u2022 Iterations: 2 iterations were required to fix the error and generate the correct visualization.\n\u2022 Level of Difficulty: Easy (as the errors were relatively simple to resolve, and the dataset was mostly clean in terms of the Accession Year column).\n\u2022 Final Observations: While the violin plot was successfully generated after the second iteration, the categorization of acquisition methods was too simplified. ChatGPT only distinguished between gift, purchase, and other, which does not capture the full range of acquisition methods described in the Credit Line column (e.g., donations, bequests, transfers). A more detailed classification of acquisition methods could provide additional insights into the distribution. The presence of null data in the Accession Year column did not significantly impact the visualization after the error was fixed, though more thorough handling of missing data could improve the robustness of the plot.\nOverall, the visualization was produced without major issues, but there is room for improvement in how acquisition methods are categorized and represented."}, {"title": "4.3 Phase 3: Experimental Study with Injected Data Quality Issues Results", "content": "In this phase", "datasets": "n\u2022 Missing data\n\u2022 Duplicate data\n\u2022 Inconsistent data\n\u2022 Inconsistent data types\n\u2022 Inaccurate data\n\u2022 Irrelevant data\n\u2022 Data entry errors\n\u2022 Incorrect data formats\nEach dataset was used to generate five different types of visualizations: pie charts", "1": "Most Streamed Spotify Songs 2024\nThe first dataset used in this phase was the \"Most Streamed Spotify Songs 2024\" dataset from Kaggle. Results from the clean dataset:\n\u2022 Visualization 1: Bar Graph: The bar graph was generated successfully", "2": "Line Graph: The line graph displayed the streaming trends of the top artists over time without issue.\n\u2022 Visualization 3: Word Cloud: The word cloud accurately represented the most common artist names based on the dataset.\n\u2022 Visualization 4: Heat Map: The heat map successfully visualized the geographical distribution of streams for the top artists.\n\u2022 Visualization 5: Pie Chart: The pie chart showed the distribution of streaming numbers for the top artists.\n4.3.1 Data Quality Issue 1: Missing Data. The experiment simulated missing data by removing 15% of the dataset at random using a Python script. Prior to injecting the data quality issue", "Issue": "An initial encoding issue was encountered when reading the dataset", "Artist\" column.\nAfter injecting 15% missing data into the dataset, the five visualizations were re-run to observe the impact of the missing values.\n(1) Visualization 1": "Bar Graph: The bar graph remained largely unaffected by the missing data"}, {"2": "Line Graph: The line graph was similarly unaffected", "3": "Word Cloud: The word cloud was noticeably impacted by the missing data. Several artist names appeared more frequently due to the removal of data for other artists. Additionally", "4": "Heat Map: The heat map was impacted by the missing data. Several artists had different streaming values", "5": "Pie Chart: The pie chart displayed altered proportions after the missing data was injected"}, {"2": "Duplicate Data. To simulate the effects of duplicate data on visualizations", "dataset": "n(1) Visualization 1: Bar Chart: The bar chart was affected by the duplicated data"}, {"2": "Line Graph: At first glance", "3": "Word Cloud: The word cloud showed a clear impact from the duplication of data. Some artists appeared more frequently than in the clean dataset", "4": "Heat Map: The heat map", "5": "Pie Chart: The pie chart displayed noticeable shifts in the percentages associated with various artists. Due to the duplication"}, {"3": "Inconsistent Data. To simulate the effect of inconsistent data", "dataset": "n(1) Visualization 1: Bar Graph: The bar graph was affected by the inconsistent artist names", "As It Was\u201d by Harry Styles appeared twice due to the inconsistent capitalization of the artist's name. This duplication reduced the available space for other entries in the visualization and led to inaccurate representations of the top tracks. Impact": "This duplication could cause users to miss valuable insights by presenting redundant information", "2": "Line Graph: The line graph was unaffected by the inconsistent data because the graph used parameters unrelated to the artist's names", "Impact": "No significant effect was observed due to inconsistent data in this case.\n(3) Visualization 3: Word Cloud: Despite the initial hypothesis that the word cloud would be heavily impacted by inconsistent data"}, {"Impact": "The word cloud did not show noticeable changes between the clean"}]}