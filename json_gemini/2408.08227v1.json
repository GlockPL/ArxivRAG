{"title": "Evolving A* to Efficiently Solve the K Shortest-Path Problem (Extended Version)", "authors": ["Carlos Linares L\u00f3pez", "Ian Herman"], "abstract": "The problem of finding the shortest path in a graph G(V, E) has been widely studied. However, in many applications it is necessary to compute an arbitrary number of them, \u043a. Even though the problem has raised a lot of interest from different research communities and many applications of it are known, it has not been addressed to the same extent as the single shortest path problem. The best algorithm known for efficiently solving this task has a time complexity of O(|E| + |V| log |V| + \u043a|V|) when computing paths in explicit form, and is based on best-first search. This paper introduces a new search algorithm with the same time complexity, which results from a natural evolution of A* thus, it preserves all its interesting properties, making it widely applicable to many different domains. Experiments in various testbeds show a significant improvement in performance over the state of the art, often by one or two orders of magnitude.", "sections": [{"title": "Introduction", "content": "Given a graph G(V, E), the problem of finding the shortest path between two designated vertices sandt is a long-studied task, and A* (P. E. Hart et al., 1968) is a prominent algorithm used to solve it. A natural extension consists of computing the best paths\u00b9 between the same vertices. David Eppstein (Eppstein, 1998) provides a thorough review in the history of the research on this task, noting that it dates back as far as 1957. Many variants have been considered, differing on various criteria, such as whether paths are required to be simple (or loopless) or whether the graphs considered are directed or undirected. This paper focuses on the problem of finding the K, not necessarily simple, shortest paths between a start state, s, and a goal state, t, in directed graphs.\nThe problem has been already addressed with various heuristic search algorithms, usually with various derivative versions. mA* (Dechter et al., 2012; Flerova et al., 2016) is a straightforward application of A* which allows the expansion of nodes up to times. Doing so clearly allows the discovery of k paths, and the idea can be easily applied to different domains. In contrast, K* (Aljazzar, 2009; Aljazzar & Leue, 2011) expands nodes only once. It is a heuristic variant of Eppstein's algorithm (EA) (Eppstein, 1998) which, in addition, can be built on-the-fly significantly improving its running time. K* essentially transforms EA to return paths as soon as practical. At the center of both EA and K* is the path graph, a structure which stores information from the search allowing the enumeration of paths through a one-to-one mapping between paths in the path graph and paths in the true graph. The algorithm swaps between search and enumerating paths from the path graph based on some swapping criterion, which can lead to the algorithm expanding nodes unnecessarily. The algorithm has been recently modified (Katz & Lee, 2023) with a variety of improvements, including a modification of the swapping criterion. Still, both EA and K* have an algorithmic complexity equal to O(E+ |V|log |V| +\u043a) when outputting paths in implicit form, i.e., as a sequence of sidetrack edges. Usually, however, paths are required in explicit form, i.e., as a sequence of vertices and their algorithm complexity is then O(|E|+|V|log |V| + \u043a|V|).\nIn this paper, a novel search algorithm, BELA* (Bidirectional Edge Labeling A*), is introduced. Some relevant definitions are introduced first and, among them, a novel use of sidetrack edges is proposed which splits paths into two components. At the core of our contribution is the notion of a centroid which we then use for the introduction of the brute-force variant of our algorithm, BELA0. Its theoretical properties are examined and its algorithmic complexity studied. We then consider the heuristic version of the algorithm, BELA*. Afterwards, through empirical evaluation, we show BELA, and BELA* outperform both mA* and K* (as well as their brute-force variants), in a wide selection of problems often by one or two orders of magnitude in running time, and sometimes even more."}, {"title": "Definitions", "content": "Given a directed graph G(V, E) characterized by its set of vertices v \u2208 V and edges eij : Vi \u2192 Vj, Eij \u2208 E, let s and t denote the start and goal vertices respectively, between which an arbitrary number of shortest-paths has to be\nIf s = no and t = nk then is denoted as a solution path. The edges are weighted with non-negative integers, where w(ni-1, ni) denotes the cost of traversing the edge eni-1,n\u2081. Thus, the cost of a path \u03c0is defined according to the additive model as C(\u03c0) = \\sum_{i=1}^{k}\u03c9(n_{i-1}, n_{i}). When the path is clear from the context or it is irrelevant, the same cost can be denoted also as g(ni) if and only if the path starts at the start vertex, s. Analogously, gb(ni) denotes the cost of the path from ni to t computed as gb(ni) = \\sum_{j=i+1}^{k}\u03c9(n_{j-1},n_{j}) if and only if nk = t. A path \u03c0 is said to be optimal, and is denoted as \u03c0*, if and only if C(\u03c0*) \u2264 C(\u03c0') for every solution path \u03c0' between s and t, and is termed as suboptimal otherwise. Following the previous definitions, g* (ni), and g(ni) denote the cost of an optimal path from the start vertex, s to ni, and from ni to t, respectively.\nHeuristic functions are denoted as h(.). A heuristic function is said to be admissible if and only if h(n) \u2264 h*(n) for every node n, where h*(n) denotes the cost of an optimal solution from n to the goal t. Note that this definition refers to nodes instead of vertices, which are defined in turn, as the representation of a unique path from s to it, so that the same vertex can be represented with multiple nodes in a search algorithm. A heuristic function is said to be consistent if and only if h(n) \u2013 h(n\u2081) \u2264 w(n, n\u2081), for every node n, where ni is any descendant of it.\nThe set of all solution paths (either optimal or suboptimal) in G is denoted as Gr, and the set of all paths which are suboptimal is denoted as G, GCG.\nDefinition 1. Given a directed G(V, E) potentially infinite locally finite graph with natural edge weights, and two designated vertices, s,t \u2208 V, the single-source\u043a shortest-path problem consists of finding a set of different, not necessarily simple paths II = {\u03c0\u03bf, \u03c01,...,\u03c0\u03ba\u22121} such that:\n\u2022 If there exists a path \u03c0' such that C(\u03c0') < C(\u03c0\u2081), 0 \u2264 i < \u03ba, then \u03c0' \u2208 \u03a0\n\u2022 If |G| \u2264 \u03ba, then II = G\nEvery solution path \u03c0\u03af \u2208 \u03a0 has a cost possibly different than the cost of other accepted solution paths. Co represents the cost of all optimal solution paths \u03c0\u03af \u2208 G\u03c0\\G; C is the cost of the cheapest suboptimal solution, C> C. Likewise, C is the cost of all suboptimal solution paths which are the i-th best, and C represents the cost of the worst solutions in II. In particular, C(\u03c0\u03ba-1) = C*.\nEppstein's Algorithm (EA) classified all edges in a graph in two different categories: tree edges and sidetrack edges, and K* slightly modified the definition of the second term. In the following, we adhere to the definitions used in K*:\nDefinition 2. An edge eni,n; is a tree edge if and only if g*(nj) = g*(ni)+w(ni, nj), and is said to be a sidetrack edge otherwise, i.e., g*(nj) < g* (ni) + w(ni, nj).\nClearly, the existence of at least one sidetrack edge is both a necessary and sufficient condition for a path to be suboptimal. One of our core contributions is that they also provide a means for distinguishing different components of any suboptimal solution path:\nDefinition 3. Given a directed cyclic graph G(V, E) with natural edge weights, and two designated vertices, s, t \u2208 V, any suboptimal solution path \u03c0\u03af\u03c2 = \u03b7\u03bf, \u03b71, N2, ..., Nk = t) can be decomposed into a prefix and a suffix, via a sidetrack edge eni\u22121,n; \u2208\u03c0, for any i with 0 < i < k as follows: Letni be the first node in a which verifies that g*(ni) <g*(ni-1) + w(Ni-1, Ni), then:\n\u2022 \u03c6(s = \u043f\u043e, \u043f1,...,ni\u22121) is the prefix, possibly empty.\n\u2022 \u03c3\u3008ni, Ni+1,...,nk = t) is the suffix, possibly empty.\n\u2022 The edge eni\u22121,n; \u2208\u03c0 is a sidetrack edge."}, {"title": "Centroids", "content": "A new definition, which refines the notion of sidetrack edge is proposed first:\nDefinition 5. A centroid z is defined as the association of a sidetrack edge eu,v \u2208 E with u, v \u2208 V, and an overall cost Cz.\nHence, two centroids are different if they use different sidetrack edges or they have different overall costs. Clearly, every suboptimal solution path \u03c0using a centroid is divided into a prefix and suffix, and C(\u03c0) = g*(u) + \u03c9(u, v) + g(v) = Cz. Of course, question is how to find the paths defined by the cost and sidetrack edge of the centroid. To do this, we must enumerate all valid suffixes and prefixes for paths of the centroid. Before returning to this question it is first shown that centroids create an equivalence class over the set of all suboptimal solution paths, G.\nLemma 2. Any suboptimal path is represented by one and only one centroid z.\nProof: Indeed, there is a unique combination of an overall cost and a sidetrack edge that represents any suboptimal solution path \u03c0: It is trivially observed that the cost of \u03c0is unique, C'(\u03c0) and thus, its centroid has to have an overall cost Cz = C(\u03c0); secondly, Definition (3) explicitly uses the first sidetrack in to split the path into its prefix and suffix, and hence it has to be unique. To conclude the second observation, note that every suboptimal path must necessarily have at least one sidetrack, otherwise it would be an optimal path.\nLemma 3. The equivalence class induced by the definition of centroids forms a partition over the set of all suboptimal solution paths G', i.e., every suboptimal solution path \u03c0\u03af \u2208 I belongs to one and only one equivalence class defined by a centroid z."}, {"title": "BELA", "content": "We consider first the uninformed variant of our search algorithm, BELA,, where heuristics are not available. From the preceding Section, the computation of the shortest-paths can be computed from the union of all centroids with cost less than or equal to C, where every centroid is defined as the association of a sidetrack edge and an overall cost. As indicated in the Definitions, Co is the cost of all the optimal solution paths and an ordinary application of Dijkstra's can be used to compute all of them. For the case of a centroid z such that C\u2082 = C, i \u2265 1, we will soon show how to compute its set of paths from its cost and sidetrack edge.\nThe first extension that we propose to Dijkstra's algorithm consists of storing all edges traversed in the CLOSED list. When a duplicate is found (e.g., node D in Figure 2a), the edge to it (i.e., eF,D) is stored in CLOSED, and the node is not re-expanded. This way, all existing sidetrack edges can be easily distinguished from tree edges: Given a node n in CLOSED, one of its incoming edges em,n is a sidetrack edge if and only if g*(n) < g*(m) + w(m,n). This operation can be performed in O(1) because Dijkstra's algorithm already stores in CLOSED the optimal cost to"}, {"title": "BELA*", "content": "This Section considers the availability of a heuristic function, h(\u00b7), which is assumed to be consistent and thus, admissible. As a matter of fact, all of the discussion from the previous Section apply to this one and only a few novel remarks are necessary. Indeed, Algorithm 2 becomes BELA* when using f(n) = g(n) + h(n)."}, {"title": "Empirical evaluation", "content": "This last section provides all relevant details of the experiments described in the main paper. All of the source code, along with documentation, unit tests, and various scripts for running the experiments and generating figures and tables are available on github\u00b3. All the instances for all experiments are stored in Zenodo (Linares L\u00f3pez & Herman, 2024). The selection of domains considers both map-like and combinatorial domains, with branching factors ranging from slightly above 2 (in the roadmap domain), to two-digit branching factors in the N-Pancake domain; depths ranging from dozens of vertices (as in the N-Puzzle or the N-Pancake domains) to several hundreds, often exceeding 1,000 -as in the Random Maps and the Roadmap domains. We also consider both unit cost and non-unit cost versions (the definition of non-unit costs is domain dependent). The selection of a values has been always from 1 to 10, from 10 to 100 in steps of 10, next getting to 1,000 in steps of 100 and, finally, to 10,000 in steps of 1,000, unless inferior values were enough to compare the selected algorithms, or too hard to solve. The benchmarking suite has been configured so that every algorithm is able to solve all instances for all the selected values of \u043a.\nIn each domain, we measure runtime, number of expansions, and memory usage for each algorithm. Importantly, memory usage is simply the memory measured at the termination of the algorithm, with the memory needed for storing solutions subtracted. Data is provided first, as figures, and also in tabular form in Appendix A.\nAll the experiments have been executed on a machine with 8 core i7 and 32 Gb of RAM. All algorithms have been implemented in c++-17."}, {"title": "Roadmap", "content": "The roadmap domain was used in the empirical evaluation of K* in (Aljazzar & Leue, 2011) and thus, it is considered in this section. It is taken from the 9th DIMACS Shortest-Path Challenge. Two variants are considered, dimacs and unit. The first uses the provided edge costs. The latter considers all edges to have cost 1."}, {"title": "9th DIMACS Challenge", "content": "Figures 5-10 show the results of running BELA*, mA*, K*, and their brute-force variants over a selection of maps from the 9th DIMACS Shortest Paths Challenge. In the empirical evaluation of K* only NY and E were used. Table 1 shows all of the available maps and their size measured in the number of vertices and edges. The figures show the runtime (in seconds), memory usage (in Mbytes) and number of expansions of each algorithm. Every point has been averaged over 100 instances randomly generated where, as in the original evaluation of K* a random pair s t was accepted if and only if the distance between them was at least 50 km measured as the great-circle distance using the haversine function, as described in (Aljazzar & Leue, 2011).\nFigure 5 compares only BELA0, Ko and mDijkstra, and it shows a clear trend. Even if Ko is faster than BELA, for large values of k, this only occurs in the smallest graphs, NY and BAY. In larger graphs, the margin of improvement in runtime provided by BELA, increases with the K see Figures 5d and 5f. Note that mDijkstra, the brute-force variant of mA* performs so poorly that it was not practically possible to compute more than K = 10 paths with it, while either BELA, of Ko output 10,000 paths in roughly the same amount of time.\nRegarding memory usage, Figure 6a shows an effect that will be seen in other experiments as well, i.e., that memory usage in either BELA, or BELA* can decrease when increasing the number of paths to seek, \u03ba. This phenomena is attributed to the fact that the number of centroids can decrease when looking for more paths and thus, less memory is required to store all the necessary information, as shown in the example discussed in Section 4.\nFigure 8 shows the runtime (in seconds) of BELA*, mA* and K*. Again, the same trend we observed before is seen here. Even though K* performs better than BELA* in smaller graphs, this margin shrinks as the size of the graph increases, and, eventually, it performs worse in the larger map, E. The relatively good performance of K* in this domain is attributed to a variety of factors. On one hand, the maximum number of paths requested, 10,000 does not require expanding the whole graph as Figure 10 shows. Second, all of the graphs where K* performs better than BELA* are rather small (the largest one with less than 2 million vertices). Third, of all the benchmarks tried, this is the one with the lowest branching factor. Most importantly, the heuristic function suggested in (Aljazzar & Leue, 2011) is very poor. Figure 13 (where mA* has been removed due to its poor performance) shows that the reduction in the number of expansions is always around 10% both for BELA* and K*, which is too small to pay off for the extra work at each node for computing the heuristic function. In fact, the brute-force variants of both K* and BELA*, i.e., Ko and BELA,, outperform their heuristic counterparts in all maps, as shown in Figure 11, with the only exception being the smallest graphs, NY and BAY. As a consequence of the poor performance of the heuristic function, mA* performs the worst, as it expands nodes near the start state many times.\nIn the end, BELA, is the fastest among all algorithms tried in this domain in the majority of cases."}, {"title": "Unit variant", "content": "The edge costs found in the dimacs variant of the roadmap domain vary quite a lot and are decently large. Weighting every edge with these costs makes the mapping between centroids and solution paths provided by BELA* to be very poor, because each centroid can only be expected to represent a few paths. For example, BELA* exploits about 1,800 centroids to generate 10,000 paths in the NY map, whereas in the E map (which is larger), on average, it uses almost 1,100 centroids to generate the same number of solution paths. Thus, every centroid generated in the dimacs variant of this domain approximately represents 5 to 9 paths. Simply using unit costs produces a dramatic change in these figures. Of course, doing so invalidates the heuristic function used in the dimacs variant and thus, only the brute-force versions are considered in this case. In the unit variant of the roadmap domain, BELA, needs 15 centroids on average to generate 10,000 paths in the NY map, and a little bit more than 18 in the E map to generate the same number of paths, improving the number of paths per centroid by about two orders of magnitude.\nThe experiments conducted in the unit variant aim to demonstrate how BELA, can benefit from this increase in the number of paths per centroid. Figure 14 shows the runtime (in seconds) of all brute-force search algorithms in the unit variant. Again, mDijkstra performs so poorly that only \u043a = 10 paths can be computed in the time used by Ko and BELA, to find 10,000 distinct paths. As Figure 14 shows, the difference in running time between Ko and BELA, increases with larger values of k in all maps, regardless of their size.\nThus, BELAo strongly dominates both Ko and mDijkstra in the unit variant of the roadmap domain, being three or four times faster than Ko."}, {"title": "Random maps", "content": "The random map is taken from the 2d Pathfinding movingai benchmark4. Only the first instance from the random maps benchmark has been used (with 512\u00d7512 locations), but considering different percentages of obstruction: 10, 15, 20, 25, 30 and 35, yielding a total of 6 different random maps. For each map, 100 instances were randomly generated where the heuristic distance between the start and goal state is at least 90% of the largest possible distance. All results are averaged over all runs."}, {"title": "Unit variant", "content": "In the first variant it is only possible to move either horizontally or vertically, and the cost of all operators is equal to 1. Both brute-force and heuristic variants of all search algorithms are considered. The heuristic function used is the Manhattan distance.\nFigures 17-19 show the runtime (in seconds), the memory usage (in Mbytes), and the number of expansions of BELA, Ko, and mDijkstra. The first observation is that with the absence of a heuristic function, mDijkstra performs even worse than in the previous domain, and it only finds K = 4 paths before using more time than BELA, takes to output 10,000 different paths. This shows a difference of several orders of magnitude in runtime. The performance of K* in this domain deserves attention. First, it performs much worse than BELA, in all maps. In fact, Ko was requested only to find \u03ba = 1,000 paths, yet it always takes significantly longer than BELA, takes to compute \u043a = 10,000 paths, even if it expands around the same number of nodes as shown in Figure 19. This indicates a difference in runtime of several orders of magnitude. Secondly, as conjectured in the roadmap domain, Ko's performance improves as the branching factor is reduced. As the percentage of obstruction increases, the"}, {"title": "Octile variant", "content": "In this variant, in addition to horizontal and vertical moves, it is also possible to move to cells diagonally adjacent to the current cell, provided they are not marked as inaccessible. This doubles the branching factor from 4 to 8. In addition, the octile variant is a non-unit domain because the diagonal moves have a cost equal to 14, whereas horizontal and vertical moves have a cost equal to 10 units. The heuristic function used is the octile distance.\nThis variant is harder than the previous variant for all algorithms. Again, mDijkstra is only able to find K = 4 different paths, usually taking longer than the other algorithms which find either two orders of magnitude or even four orders of magnitude more paths in the same allotted time, as shown in Figure 23. This time, Ko is restricted to find only k = 100 different paths (10 times less than in the unit domain) and it consistently takes one order of magnitude more time than BELA0, which computes \u043a = 10,000 solution paths. Even if BELA, also takes longer than it does in the unit variant, it still performs much better than all the other algorithms, being able to compute up to 10,000 paths in less than a second (averaged over each map). The difference in runtime between Ko and BELA, can not be attributed neither to an increase in graph size (since they are the same than in the unit variant), nor the number of expansions performed by each algorithm. shown in Figure 25, since the difference is rather small. The degradation in performance of Ko is therefore attributed to the increase in the branching factor which forces Ko to consume more time in building and maintaining the path graph. Regarding BELA,, its performance does not decrease significantly and, again, it delivers K = 10,000 solution paths in less than a second on average across"}, {"title": "N-Pancake", "content": "The N-Pancake domain defines a permutation state space with a size equal to N!. It is thus a significant challenge, as it also has a large branching-factor, N \u2013 1. The heuristic used is the GAP heuristic (Helmert, 2010), which is known to be very well informed in the unit variant discussed next. This allows current state-of-the-art solvers to solve instances of the 60-Pancake in less than 30 seconds on average per instance. In all cases, 100 instances were randomly generated and only those instances where the heuristic distance between the start state and the goal state was greater than or equal to (N \u2212 2) were accepted. All of the points in the following plots have been averaged over 100 runs each. This domain has never been used, to the best of the authors' knowledge, as a testbed for algorithms solving the shortest path problem."}, {"title": "Unit variant", "content": "The unit variant is the classic version of the N-Pancake problem (Dweighter, 1975), where an arbitrary permutation of the symbols {1, ..., N} has to be transformed into the identity permutation by performing prefix reversals, all of which have cost 1.\nThe brute-force variants of the algorithms under consideration were only tested on the 10-Pancake, because this state space is big enough for them, with 3,628,800 different states. The results are shown in Figures 29-31. Only BELA, was able to find 10 different paths in less than 25 seconds on average. In this domain, mDijkstra performed significantly better than Ko, but only for very low values of K. In fact, mDijkstra was requested to find only \u043a = 3 different solutions, because finding a fourth solution exhausts the available memory for some instances. Ko performed much worse than BELA,, doubling the number of expansions, being almost five times slower in the end, and taking also five times more memory than it.\nExperiments using the GAP heuristic were particularly interesting. K* is indeed the worst algorithm in this domain. For example, in the 20-Pancake (see Figure 32a) it takes a huge amount of time for finding only \u043a = 10 paths, while mA* and BELA* can find up to 1,000 solutions in much less time. Indeed, both mA* and BELA* are already two orders of magnitude faster with \u043a = 10, the maximum value attempted with K*. In the end, BELA* is one order of mangitude faster for finding two orders of magnitude more solutions. This degradation in the running time of K* is attributed to two different factors: On one hand, the large branching factor which forces K* to spend much more time updating and maintaining its path graph; secondly, it expands significantly more nodes than BELA*, which is likely caused by the swapping criterion used. For the first time, mA* seems to be competitive with BELA*, even if it consistently performs worse than it over all values of K. This behavior is due to the accuracy of the heuristic function. Observing the results in the 30 and 40-Pancake (see Figures 32b and 32c)"}, {"title": "Heavy-cost variant", "content": "In the heavy-cost variant, the cost of each prefix reversal is defined as the size of the disc that becomes first in the permutation after the reversal. This variant is much harder than the unit version, because the GAP heuristic is not so well informed now, even if a weighted version of the GAP heuristic is being used. In the weighted variant of the GAP heuristic, each gap gets weighted by the size of the smaller disc adjacent to it. As a result of its hardness, experiments in the octile variant of the N-Pancake were conducted with 32Gb of RAM memory.\nFigures 35-37 show the results using the brute-force search algorithms. As before, only the 10-Pancake was tested. As shown in Figure 35a BELA, takes an average time slightly above 30 seconds to find \u043a = 10 solutions, whereas mDijkstra can solve instances only with \u043a \u2264 2 with a much worse average time than BELA, for \u043a = 2; \u041a\u043e"}, {"title": "N-Puzzle", "content": "The N-Puzzle is a classical combinatorial task (W. A. Johnson, 1879) that has a state space with 2 different states. Up to N\u00b2 \u2013 1 different symbols are arranged over a square matrix (though other arrangements are possible), leaving only one blank position, so that only symbols horizontally or vertically adjacent to it can swap their locations. The goal is to re-arrange all symbols into the identity permutation where the blank tile must be located in the upper-left corner. The 8-Puzzle and the 15-Puzzle were used for our experiments. In the first case, 100 random instances were randomly generated, whereas in the 15-Puzzle the 40 easiest instances of the Korf's test suite were selected (E. Korf, 1985). As a matter of fact, this test suite is known to extremely difficult for best-first search strategies when using the Manhattan distance (Burns et al., 2012), even without trying to find \u043a > 1 solution paths. As in the case of the N-Pancake, this is the first time this domain is used as a testbed for a shortest path algorithms to the best of the authors' knowledge."}, {"title": "Unit variant", "content": "In the unit variant, all operators cost the same and thus, they are all equal to one. There are various heuristic functions for this domain. The current state-of-the-art uses Additive Pattern Databases (Felner et al., 2004). However, they are known to be inconsistent and thus they have been discarded for our experimentation, and the Manhattan distance is used instead.\nExperiments with the brute-force variants were restricted to the 8-Puzzle, with 181,440 states. Figures 41-43 show the running time, memory usage and number of expansions. In this domain, Ko is roughly twice as slow as BELA, for K = 10,000, while mDijkstra performs very poorly due to the lack of a heuristic function.\nFigures 44-46 show the results when using heuristic search algorithms, both in the 8-Puzzle (with \u043a = 10,000) and the 15-Puzzle with \u043a = 100. The results in the 15-Puzzle (see Figure 44b) show huge improvements in running time when using BELA*, which finds the best 100 solutions in roughly 5 seconds on average, whereas both K* and mA* take one order of magnitude more time for very low values of K. As observed in Figures 45 and 46, the profiles shown in running time are closely followed by those for memory usage and the number of expansions."}, {"title": "Heavy-cost variant", "content": "In the heavy-cost variant, the cost of a movement is equal to the content of the tile exchanged with the blank. A weighted variant of the Manhattan distance, where the distance of each tile is multiplied by its content is used as our heuristic. The resulting variant is much harder than the previous one, and thus only experiments with the"}]}