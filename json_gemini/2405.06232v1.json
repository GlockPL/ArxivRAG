{"title": "Learning to Solve Geometry Problems via Simulating Human Dual-Reasoning Process", "authors": ["Tong Xiao", "Jiayu Liu", "Zhenya Huang", "Jinze Wu", "Jing Sha", "Shijin Wang", "Enhong Chen"], "abstract": "Geometry Problem Solving (GPS), which is a classic and challenging math problem, has attracted much attention in recent years. It requires a solver to comprehensively understand both text and diagram, master essential geometry knowledge, and appropriately apply it in reasoning. However, existing works follow a paradigm of neural machine translation and only focus on enhancing the capability of encoders, which neglects the essential characteristics of human geometry reasoning. In this paper, inspired by dual-process theory, we propose a Dual-Reasoning Geometry Solver (DualGeoSolver) to simulate the dual-reasoning process of humans for GPS. Specifically, we construct two systems in DualGeoSolver, namely Knowledge System and Inference System. Knowledge System controls an implicit reasoning process, which is responsible for providing diagram information and geometry knowledge according to a step-wise reasoning goal generated by Inference System. Inference System conducts an explicit reasoning process, which specifies the goal in each reasoning step and applies the knowledge to generate program tokens for resolving it. The two systems carry out the above process iteratively, which behaves more in line with human cognition. We conduct extensive experiments on two benchmark datasets, GeoQA and GeoQA+\u00b9. The results demonstrate the superiority of DualGeoSolver in both solving accuracy and robustness from explicitly modeling human reasoning process and knowledge application.", "sections": [{"title": "1 Introduction", "content": "Automatically solving math problems with AI techniques has attract much attention recently [Xie and Sun, 2019;"}, {"title": "2 Related Works", "content": "Existing works on GPS could be divided into two genres: Symbolic Geometry Solvers and Neural Geometry Solvers."}, {"title": "2.1 Symbolic Geometry Solvers", "content": "[Seo et al., 2015] proposed the first symbolic solver GeoS, which first parsed the problem text and diagram into first-order logic literals using handcrafted rules and OCR techniques [Seo et al., 2014], then solved the geometry problem by finding an assignment that satisfied all the parsed literals. In order to alleviate the reliance of GeoS on handcrafted rules, [Sachan et al., 2017; Sachan and Xing, 2017] injected geometry theorem knowledge as the form of horn-clauses into the solver and replaced the handcrafted rules. Recently, Inter-GPS [Lu et al., 2021] improved the reasoning process of previous symbolic solves by iteratively searching geometry primitives and applying a series of manually defined geometry theorems. Although symbolic solvers have achieved significant progress and possess strong interpretability, they heavily rely on the handcrafted rules to parse the geometry problems and lack generalization."}, {"title": "2.2 Neural Geometry Solvers", "content": "With the rising usage of deep learning for automated math problem solving, [Chen et al., 2021] first proposed a neural geometry solver called NGS which solved the geometry problems with an encoder-decoder framework. It encoded the problem text and diagram separately, then fused them using a multi-modal fusion module, and finally sent them to a program decoder to generate program tokens that can produce final numeric result through program execution. On this basis, to improve the text encoder, DPENGS [Cao and Xiao, 2022] adopted both Bi-LSTM and ROBERTa[Liu et al., 2019] for encoding, which were further enhanced by SCA-GPS [Ning et al., 2023] through integrating diagram features with symbolic characters. Geoformer [Chen et al., 2022] adopted T5 [Raffel et al., 2020] model as the backbone and strengthened the reasoning ability by introducing geometry proving problems. For precisely describing the diagram, [Zhang et al., 2022] proposed PGDP-Net which utilized instance segmentation [He et al., 2017; Ying et al., 2021] and scene graph generation [Xu et al., 2017] techniques to parse the geometry primitives and their relations from the diagram. Subsequently, to better understand the semantics meanings of different geometry primitives, PGPSNet [Zhang et al., 2023] solved geometry problems by applying semantic embeddings to different types of geometry primitives. Though neural solvers have achieved remarkable performance and possessed strong generalization ability, they still solve geometry problems by following a neural machine translation paradigm, while neglecting the characteristics of human reasoning in geometry problem solving, which may lead to model confusion and robustness issues. Differently, in this paper, we draw insights from dual-process theory and simulate human dual-reasoning process to solve geometry problems."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 Problem Definition", "content": "Formally, a geometry problem is defined as a tuple $(D, P, c)$, where $D$ represents the geometry diagram, $P = [P_1, P_2,..., P_n]$ represents $n$ tokens in the problem description, and $c = \\{C_1, C_2, C_3, C_4\\}$ represents the multi-choice candidates where each choice is a numeric value. Given the geometry diagram $D$ and problem description $P$, one GPS solver is trained to select a choice $c_i \\in c$.\nIn the current field of GPS, researchers do not make neural solvers predict a choice from candidates $c$ directly. Alternately, they annotate a program as a sequence of tokens $Y_p = [Y_1,Y_2,..., y_T]$ that can be executed to obtain a numeric result. Each $y_t \\in Y_p$ comes from a program vocabulary $V_p$ composed of four parts: the operators $V_o$ where each operator represents a mathematical operation (e.g., \"Minus\"), the numeric constants $V_c$ (e.g., \"C_3\" which stands for 180\u00b0), the numeric values $N_p$ which appear in problem description $P$ (e.g. \u201cN_0\u201d which stands for 40\u00b0), and the numeric variables $N_v$ which are the intermediate execution results of previous reasoning steps (e.g., \u201cV_0\" which stands for 140\u00b0). That is, $V_p = V_o \\cup V_c \\cup N_p \\cup N_v$. It is worth noting that $N_p$ and $N_v$ are constructed by number mapping, which transforms the numerical values into a unified representation.\nDefinition 3.1. Given a geometry problem $(D, P, c)$, our goal is to build a model that could reason the program $Y_p = [Y_1, Y_2,..., Y_T]$, then obtain the numeric result $z$ through executing the program $Y_p$, and finally select a choice $c_i$ matching $z$ from candidates $c$."}, {"title": "3.2 Overall Framework", "content": "To explicitly model human reasoning process, inspired by the dual-process theory, we propose a Dual-Reasoning Geometry Solver (DualGeoSolver) as depicted in Figure 2. Firstly, we encode the problem text $P$ and diagram $D$ through separate encoders and fuse them through a multi-modal fusion module. Then, we feed them into our dual-reasoner to iteratively generate the target program $Y_p = [y_1, y_2,\u2026\u2026\u2026, y_T]$ with the cooperation of Knowledge-Inference systems, and obtain the numeric result through program execution."}, {"title": "3.3 Problem Encoders", "content": "We adopt two encoders to extract the features of diagram $D$ and problem text $P$ separately, and then fuse and align them.\nDiagram Encoder. To extract visual information from geometry diagram $D$, We employ a ViTMAE [He et al., 2022] that handles geometry diagram through two pre-training tasks, including Masked Image Modeling (MIM) and symbolic character detection [Ning et al., 2023]. Given diagram $D$, we divide it into regularly non-overlapping $\\gamma \\times \\gamma$ patches and input them into ViTMAE. We take the outputs of last hidden layer as the visual features $H_{D_1} = [h_1^D, h_2^D,..., h_m^D]$, where $m = \\gamma \\times \\gamma$ is the number of diagram patches.\nText Encoder. Given textual problem description with $n$ tokens $P = [P_1, P_2, ..., P_n]$, we feed it into a LSTM [Hochreiter and Schmidhuber, 1997] and RoBERTa [Liu et al., 2019] separately to obtain richer representations of $P$. Then, we aggregate them through a linear layer to obtain the final encoded textual features $H_P = [h_1^P, h_2^P,..., h_n^P]$.\nMulti-modal Fusion Module. We employ a multi-modal co-attention module [Yu et al., 2019] to fully fuse and align the diagram features $H_D$ and text features $H_P$. The co-attention module takes $H_D$ and $H_P$ as inputs and outputs the multi-modal representation $F_D = [f_1^D, f_2^D,...,f_m^D]$. We concatenate $H_P$ and $F_D$ to form $H_M = [H_P;F_D] = [h_1^M, h_2^M,...,h_n^M, f_1^M,...,f_m^M]$ for subsequent reasoning. Additionally, we apply an attention-reduction network [Chen et al., 2021] to aggregate $F_D$ into a vector. We then concatenate this vector with the features of the last token in $H_P$, obtaining the aggregated multi-modal feature vector $h_M$."}, {"title": "3.4 Dual-Reasoner", "content": "Existing geometry solvers decode the program $Y_p$ in a totally Seq2Seq manner, which is greatly different from human reasoning process. Taking Figure 1 as an example, humans start by identifying the first reasoning goal as \u201ccalculate \u2220CAB\". Then, they conduct implicit reasoning from two aspects: 1) refer to the diagram and capture relationships between \u2220CAB and other geometry primitives, 2) retrieve the geometry knowledge such as \u201cParallel Lines\". Under the guidance of them, humans conduct explicit reasoning and deduce tokens \"[Minus, C_3, N_0]\" to solve this goal. Afterwards, they realize the next goal is to \"calculate \u2220AEC' and repeat the above processes until obtaining the final answer.\nTo achieve the above processes, we draw insights from dual-process theory [Schneider and Shiffrin, 1977; Evans, 2008; Kahneman, 2011; Lieto et al., 2017] to propose a dual-reasoner which conduct a dual-reasoning process with two systems, namely Knowledge System and Inference System."}, {"title": "Knowledge System", "content": "In Knowledge System, we design three modules: Knowledge Selection Module (KSM), Visual Spotlight Module (VSM) and Knowledge Injection Module (KIM). At time step $t$, KSM receives reasoning goal $g_t$ from Inference System and then retrieves geometry knowledge $H_K$ that contributes to resolving the reasoning goal from an external knowledge base. Meanwhile, VSM retrieves diagram information $h^{vis}$ from the diagram based on $g_t$, which captures the relationships between reasoning goal and geometry primitives in the diagram. Finally, KIM integrates $H_K$, $h^{vis}$ and previous reasoning state (denoted as $s_{t-1}$) from Inference System to form a guiding information $r_t$ that directs the subsequent explicit reasoning process in Inference System.\nKnowledge Selection Module. Given a reasoning goal $g_t$ generated by Inference System, we utilize Knowledge Selection Module (KSM) to retrieve relevant geometry knowledge (e.g., \"Parallel Lines\"). To the best of our knowledge, there hasn't been a dedicated geometry knowledge collection, so we first manually build a geometry knowledge base $K_G$. Each item in $K_G$ is a knowledge-explanation pair, where the \u201cknowledge\u201d represents a geometry knowledge concept, and the \"explanation\" provides a textual description of the knowledge. For example, the knowledge concept \"Parallel Lines\" in $K_G$ corresponds to the textual description \u201cIf the two lines are parallel, then consecutive interior angles are supplementary\". To build $K_G$ from scratch, we initially gathered the geometry knowledge annotated in GeoQA and GeoQA+ datasets, then collected the detailed explanations of these knowledge concepts from WikiPedia 2 and Baidu-Baike 3. Subsequently, these explanations were manually verified for correctness and underwent optimization of expression and logic by three well-trained annotators with undergraduate degrees.\nFormally, for each knowledge-explanation pair $<k^c,k^e>_i$ in knowledge base $K_G$, we denote its knowledge concept as $k^c_i$ and corresponding explanation as $k^e_i$:\n$K_G = \\cup_{i=1}^{N}\\{< k^c_i, k^e_i>\\}, N = |K_G|$"}, {"title": "Knowledge Selection Module", "content": "We model knowledge selection as a multi-label classification task. Therefore, we input $g_t$ into a linear layer with sigmoid activation to obtain the prediction score for each geometry knowledge. We then select and concatenate explanations whose prediction score are higher than a pre-defined threshold @ for further reasoning. Finally, the selected explanations will be fed into the same text encoder of problem description to obtain knowledge representation $H_K = [u_1, u_2,..., u_{n_e}]$, where $n_e$ represents the length of concatenated explanations.\nVisual Spotlight Module. Given the reasoning goal $g_t$, humans also refer to the diagram to capture essential relationships between geometry primitives in the diagram (e.g. notice that \u2220ACD and \u2220CAB are consecutive interior angles in Figure 2). We simulate this behavior through Visual Spotlight Module (VSM). To let Knowledge System pay more attention to the geometry primitives related to the reasoning goal $g_t$ rather than other meaningless places, we utilize an attention mechanism to fuse $g_t$ and the features of geometry diagram $H_D$, and obtain the visual context vector $h^{vis}_t$.\n$h_t^{vis} = \\frac{\\sum_i h_i^D \\exp{(g_t^T h_i^D)}}{\\sum_j \\exp{(g_t^T h_j^D)}}$"}, {"title": "Knowledge Injection Module", "content": "Knowledge Injection Module (KIM) aims to integrate the knowledge $H_K$ and visual context $h^{vis}_t$ to form a guiding information $r_t$. We first utilizes an attention mechanism to aggregate $H_K$ into vector $h^{know}$ based on $r_{t-1}$, then we employ a single-layer uni-directional LSTM network $\\Theta$ to integrates $h^{know}$, $h^{vis}$ and the previous reasoning state $s_{t-1}$ from Inference System (described later in Eq. (6)), updating $r_{t-1}$ into $r_t$ ($r_0$ is obtained by feeding $h^M$ into a linear layer):\n$h^{know} = \\sum_i u_i \\frac{\\exp{(r_{t-1}^T u_i)}}{\\sum_j \\exp{(r_{t-1}^T u_j)}}$\n$r_t = \\Theta([h^{vis}_t, h^{know}_t, s_{t-1}], r_{t-1})$"}, {"title": "Inference System", "content": "In Inference System, we design two modules: Token Prediction Module (TPM) and Goal Generation Module (GGM). TPM combines the multi-modal features $H_M$ and guiding information $r_t$ from Knowledge System to sequentially generate the target program tokens \\{y_i\\} (t < i < t + l) until it reaches a pre-defined delimiter (e.g. \u201c[SEP]\" token in Figure 2). Here, $l$ represents the number of program tokens generated by TPM in the current reasoning step. Next, GGM finds the next reasoning goal $g_{t+1}$ according to the known conditions and the preceding reasoning information until time step $t+l-1$. It then sends $g_{t+1}$ back to Knowledge System to start the next reasoning step. For the sake of symbol consistency, we denote next reasoning goal as $g_{t+1}$ rather than $g_{t+1}$.\nToken Prediction Module. Token Prediction Module (TPM) is designed to generate target program tokens \\{y_i\\} (t < i < t + 1) which could resolve the current reasoning goal $g_t$ through program execution. We employ an LSTM network with attention mechanism [Bahdanau et al., 2014] as our TPM. At time step $t$, updates its hidden state $s_{t-1}$ according to the multi-modal features $H_M$, guiding information $r_t$, and the embedding of last generated token $e_{t-1}$:\n$h_t^M = \\sum_i h_i^M \\frac{\\exp{(s_{t-1}^T h_i^M)}}{\\sum_j \\exp{(s_{t-1}^T h_j^M)}}$\n$s_t = \\Lambda([h_t^M, r_t, e_{t-1}], s_{t-1})$\nThen we feed $s_t$ into a linear layer with softmax function to predict the distribution of next program token $P_t$. It is worth noting that the guiding information $r_t$ will not change within a reasoning step, i.e., $r_t = r_{t+1} = ... = r_{t+l-1}$.\nGoal Generation Module. Goal Generation Module (GGM) is designed to identify the next solvable reasoning goal according to the known conditions and preceding reasoning information. Specifically, we consider the multi-modal features $H_M$ as the known conditions since it contains rich information about the raw problem. We regard $H_S = [S_0, S_1,..., S_{t+l-1}]$ containing all the preceding reasoning information. Then we employ a 2-layer Transformer-Decoder [Vaswani et al., 2017] network to fully integrate $H_M$ and $H_S^{t+l-1}$, where we treat $H_S^{t+l-1}$ as query and $H_M$ as key and value, and take the last vector of the outputs as the next reasoning goal $g_{t+1}$. When t = 0, $H_S$ degenerates to only include the \"[BOS]\" token, which means GGM only takes known conditions of the question to determine the first solvable reasoning goal.\nIn summary, the training objectives of DualGeoSolver come from two parts, a generation loss $L_g$ from Token Prediction Module and a multi-label classification loss $L_c$ from Knowledge Selection Module. Specifically, $L_g$ is the negative log-likelihood (NLL) of generating target program tokens:\n$L_g = - \\frac{1}{T} \\sum_{t=1}^{T}\\log P_t (y_t | H_D, H_P, y_1, y_2,\u2026\u2026\u2026, y_{t-1})$\nThe multi-label classification loss is the sum of binary cross entropy (BCE) loss of all reasoning steps:\n$L_c = - \\sum_{i=1}^{S} \\sum_{j=1}^{N} k_{ij} \\log p_{ij} + (1 - k_{ij}) \\log(1 - p_{ij})$\nwhere $S$ is the number of reasoning steps of the geometry problem, $k_{ij}$ and $p_{ij}$ are the label/probability for the j-th knowledge in i-th reasoning step, respectively. The entire loss is the sum of $L_g$ and $L_c$: $L = L_g + L_c$."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Setup", "content": "Datasets. We conduct experiments on two public available datasets: GeoQA and GeoQA+. The problems in GeoQA are classified into three categories: Angle, Length, and Other, and problems in GeoQA+ are also classified into three categories: Angle, Length and Area. GeoQA+ dataset is an extension of GeoQA dataset, which includes additional problems with a higher average number of reasoning steps and a wider range of problem types, making them more challenging to solve [Cao and Xiao, 2022].\nSince Knowledge Selection Module retrieves knowledge for each reasoning step, it requires knowledge annotations on each individual reasoning step for training. However, both datasets only provide annotations for the entire problem without specifying them to each individual reasoning step. Fortunately, both datasets provide a detailed textual analysis for each problem, which allows us to leverage ChatGPT 4 to assign a subset of knowledge to each reasoning step.\nImplementation Details. During training, we keep the parameter of diagram encoder unchanged, and we set the learning rate of ROBERTa to 2e-5, the learning rate of multi-modal fusion module and Goal Generation Module (GGM) to 1e-5, and the learning rate of other modules to 1e-3. We use Adam as the optimizer and set the batch size as 32 while training. The total training epochs is set to 100. All experiments were conducted on an NVIDIA A6000 GPU, with PyTorch version 1.13.1.\nWhile testing, we apply beam-search strategy with beam size B = 10 to generate program sequences and utilize a program executor to execute these program sequences in descending order of their predicted probabilities to obtain numerical results. It selects the program sequence that is first successfully executed and matches an option ci in the candidates c = \\{C_1, C_2, C_3, C_4\\} as the final solution. If all B program sequences fail or none of them matches an option in the candidates, the executor will report \"No Result\" instead of guessing an option.\nBaselines. We compare our DualGeoSolver with baselines from 3 classes, including: general Seq2Seq methods, GPS specified neural solvers and large language models. Specifically, general Seq2Seq methods include a LSTM-based model (LSTM2Prog) [Hochreiter and Schmidhuber, 1997], a BERT-based model (BERT2Prog) [Devlin et al., 2018] and a RoBERTa-based model (ROBERTa2Prog) [Liu et al., 2019]. GPS specified solvers are NGS [Chen et al., 2021], Geoformer [Chen et al., 2022], DPE-NGS [Cao and Xiao, 2022] and SCA-GPS [Ning et al., 2023]. LLMs include methods utilize textual inputs only, including ChatGPT and GPT-4 [Achiam et al., 2023], and methods utilize both text and diagram, including CogVLM-17B [Wang et al., 2023], VisualGLM-6B [Ding et al., 2021; Du et al., 2022] and GPT-4V. We also provide LLMs with geometry knowledge extracted from $K_G$, which are denoted as \"GPT-4(V) + Knowledge\". The prompt for instructing LLMs to solve geometry problems is designed in a one-shot approach:"}, {"title": "4.2 Experimental Results", "content": "We show the Total Accuracy (\u201cTotal\u201d), accuracy on specific problem categories (e.g., \u201cAngle\u201d), and No Result Rate (\u201cNo Result\u201d) in Table 1 5. First, our DualGeoSolver surpasses all the baselines. By applying paired t-test, its improvements over the SOTA method SCA-GPS on \"Total\" of both datasets are statistically significant with $p < 0.01$ (marked with *). It demonstrates the rationality and effectiveness of our DualGeoSolver in modeling human reasoning process for GPS. Second, our DualGeoSolver achieves greater performance improvements on the more difficult dataset GeoQA+. It reflects that through modeling human application of geometry knowledge and the goal-oriented reasoning manner in dual-reasoner, our DualGeoSolver has better generalization ability and robustness. Third, all the GPS specific solvers, except NGS on GeoQA+, outperforms the general Seq2Seq methods. It indicates the importance of diagram in solving geometry problems, which further shows the necessity of our Visual Spotlight Module to capture the relationship between reasoning goals and diagram. Fourth, LLMs do not perform well in GPS, which we believe is caused by the disparity between geometry diagrams and images used for pre-training LLMs. But we notice that by applying geometry knowledge, GPT-4(V)'s performances have drastically improved, which demonstrates the necessity of introducing knowledge into current methods."}, {"title": "4.3 Ablation Study", "content": "To verify the effectiveness of modules in our DualGeoSolver, we conduct the ablation study in Table 2. Specifically, for Knowledge System, \u201cw/o KSM\u201d omits Knowledge Selection Module, thus ignores the geometry knowledge application in reasoning and the loss $L_c$ in Eq. (8) in training. \"w/o VSM\u201d ignores Visual Spotlight Module that captures visual information related to reasoning goal and only inputs $H_K$ into KIM for generating guiding information. \"w/o KIM\" ignores Knowledge Injection Module, and directly feeds the geometry knowledge $H_K$, which will be aggregated by $s_{t-1}$, and visual context vector $h^{vis}$ into Token Prediction Module. For Inference System, \"w/o GGM\" omits Goal Generation Module and directly regards $s_t$ as the reasoning goal.\nFrom Table 2, we first notice that the accuracy degrades when any module is missing, which verifies the rationality and necessity of all components in DualGeoSolver. Second, the accuracy degrades the most when KSM is missing, showing that KSM is the most crucial module in DualGeoSolver and applying geometry knowledge in solving geometry problems is important. Third, the performance of DualGeoSolver is significantly hindered without Goal Generation Module, which indicates that it is necessary to develop a human-like goal-oriented mechanism that fully integrates the known conditions and all preceding reasoning information to derive the next reasoning goal. Last but not least, the importance of KIM and VSM varies with the difficulty of the geometry problems. On GeoQA+, which is more challenging than GeoQA, KIM becomes more crucial than VSM. We believe this is because, for harder geometry problems, simply capturing the relationships between geometry primitives in the diagram is not sufficient to provide enough information for solving the problem, where KIM is needed to effectively integrate the diagram information with geometry knowledge."}, {"title": "4.4 Knowledge Analysis", "content": "To verify the role of geometry knowledge in solving geometry problems, we conduct two experiments: evaluating the performance of our DualGeoSolver with varying threshold @ in Knowledge Selection Module, and assessing the single-step accuracy with/without application of geometry knowledge.\nFrom Figure 3, we observe that the performance is better when the threshold @ is closer to the middle value and decreases when the threshold is too low or too high. This demonstrates that applying excessive incorrect knowledge or missing essential knowledge during reasoning is detrimental to geometry problem solving. Besides, the optimal knowledge threshold for our DualGeoSolver to achieve the best performance varies across different datasets, being 0 = 0.5 on GeoQA and 0 = 0.7 on GeoQA+. It indicates that our DualGeoSolver prefers the usage of more precise and accurate geometry knowledge on GeoQA+, while tends to use a greater amount of geometry knowledge on GeoQA+.\nWe also assess the single-step accuracy with and without applying geometry knowledge in Table 3. Specifically, \u201cOP\u201d means the accuracy of operator in each reasoning step, and \"Absolute\" means the accuracy of the whole step. For example, for Step 1 in Figure 1 that requires to reason \"[Minus, C_3, N_0]\", if the model correctly derives operator \u201cMinus\u201d, then \u201cOP\u201d will be considered correct; only if all three tokens are correctly generated, \"Absolute\" will be considered correct. From Table 3, the performances are worse without Knowledge Selection Module on both datasets, which directly demonstrates the effectiveness of applying geometry knowledge in GPS. It is worth noting that the lower accuracy on \"OP\" and \"Absolute\" compared to \"Total Accuracy\" may be due to that model predicts a program that differs from the gold program but can still solve the geometry problem."}, {"title": "4.5 Case Study", "content": "Further, we present a typical case in Figure 4 to verify the interpretability of DualGeoSolver. We first present the problem and program sequences generated by different solvers. Then, we report the knowledge selection probability in knowledge Selection Module and visualize the attention weights of Visual Spotlight Module in our DualGeoSolver.\nThis problem requires solvers to understand the properties of parallel lines and be aware that an angle bisector AE divides \u2220CAB into two equal angles. The program sequence generated by SOTA method SCA-GPS is incorrect, which appears to calculate the corresponding angle of \u2220ACE. Comparatively, our DualGeoSolver achieves a two-step reasoning process. In step 1, its reasoning goal focuses on LACE, \u2220CAB and parallel lines AB, CD according to the heatmap. Meanwhile, it selects geometry knowledge \"Parallel Lines\" with the confidence of 0.889. Combining them, it correctly deduces the program tokens \u201c[Minus, C_3, N_0]", "Parallel Lines\" and \"Angle Bisector\" simultaneously, and finally deduces the correct program tokens": "Half, V_0]\u201d. These observations verify the rationality and effectiveness of DualGeoSolver in simulating human reasoning process, which benefits from Knowledge System and Goal Generation Module in dual-reasoner."}, {"title": "5 Conclusion", "content": "In this paper, we proposed a novel Dual-reasoning Geometry Solver (DualGeoSolver), which drew insights from dual-process theory and built Knowledge-Inference systems to conduct human-like dual-reasoning. Knowledge System managed geometry knowledge and diagram information that aided reasoning. Inference System adopted a goal-oriented reasoning mechanism and applied knowledge to program generation. Experiments on GeoQA and GeoQA+ datasets demonstrated the advantages of DualGeoSolver in answer accuracy and robustness. For future studies, we will enhance the ability of LLMs by introducing reasoning goals and geometry knowledge to achieve more reliable and interpretable GPS."}]}