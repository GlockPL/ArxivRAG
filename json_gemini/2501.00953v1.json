{"title": "Incremental Dialogue Management:\nSurvey, Discussion, and Implications for HRI", "authors": ["Casey Kennington", "Pierre Lison", "David Schlangen"], "abstract": "Efforts towards endowing robots with the ability to speak have benefited from recent advancements\nin NLP, in particular large language models. However, as powerful as current models have become,\nthey still operate on sentence or multi-sentence level input, not on the word-by-word input that\nhumans operate on, affecting the degree of responsiveness that they offer, which is critical in situ-\nations where humans interact with robots using speech. In this paper, we review the literature on\ninteractive systems that operate incrementally (i.e., at the word level or below it). We motivate the\nneed for incremental systems, survey incremental modeling of important aspects of dialogue like\nspeech recognition and language generation. Primary focus is on the part of the system that makes\ndecisions, known as the dialogue manager. We find that there is very little research on incremental\ndialogue management, offer some requirements for practical incremental dialogue management,\nand the implications of incremental dialogue for embodied, robotic platforms.", "sections": [{"title": "1. Introduction", "content": "As people interact with technology, their expectations on how technology should respond is strongly\ninfluenced by the interaction channel: a press of a keyboard key should result in a character on\nthe screen, and a chatbot interface that takes in text should respond in kind. The expectations of\nresponse are much more challenging when people interact with robots, because robotic interfaces\nhave anthropomorphic characteristics. If, for example, a robot has what appear to be eyes, people\nexpect that the robot can see them, or if the robot has an arm they expect the robot to be able to point\nor grasp objects. Furthermore, it has been shown that people antrhopomorphize robots for gender\n(Reich-Stiebert and Eyssel; Eyssel and Hegel, 2012), intelligence (Novikova et al., 2015), and even\nage (Plane et al., 2018) depending on the robot's morphology, size, and movements, which affects\nthe expectations of how robots behave."}, {"title": null, "content": "The expectation of high responsiveness is compounded when the robot can speak. If, for ex-\nample, a robot uses certain vocabulary that gives an impression that it is intelligent, humans tend\nto expect it to be able to hold fluent conversations (Plane et al., 2018). A recent survey of spoken\ninteraction on robots showcases a long history of research that spoken dialogue systems (henceforth\nSDSS) are key to endowing a robot with handling common artifacts in spoken interaction which are\nnot commonly found in text or written interaction such as turn-taking, requests for clarification,\nbuilding common ground and mutual understanding (Reimann et al., 2023). At the heart of their\nfocus is the dialogue manager because both SDSS and robots have to make decisions about which\nactions they will take, either by uttering a response or moving a robotic arm. Lison and Kenning-\nton (2023) also argue that the division of labor between SDS decision-making and robotic planning\nshould be an \"integral part of the design process\".\nOne dimension that is often neglected in current SDS research is the granularity at which the\ndialogue is processed. Recent SDS work (including text-based dialogue research) largely focuses\non systems that operate on full utterances; indeed, recent transformer-based models-upon which\nmany recent dialogue system models are based\u2014are designed to operate on sentence or even multi-\nsentence level input, for example using large language models (LLMs). More specifically, while a\nLLM decoder can process any kind of input, they are trained to act upon complete, sentence-level\ninput, rendering them unable to produce behavior where input and output happen concurrently. This\ntrend is in sharp contrast to how humans comprehend and produce language; humans must see and\nprocess individual words while reading text, and psycholinguistic research has shown that speech\ncomprehension happens at a word or even sub-word level (Tanenhaus and Spivey-Knowlton, 1995).\nThis has implications for how SDSs should be modeled because humans have the expectation that\nsystems which can comprehend human speech and produce spoken responses should be responsive,\nfast, and natural as rated by humans, which is challenging to models that operate at full utterance or\nsentence level. This is especially crucial when SDSs are the primary method of interaction between\nhumans and robots due to the high expectations of naturalness, intelligence, and responsiveness as\nexplained above.\nThe technical term for SDSs that can process and produce speech at sub-sentence granularity is\nincremental. Most often, incremental SDSs operate at the word-level. Incremental SDS research has\na long history. Comparisons between incremental and non-incremental systems have shown that\nincremental systems significantly improve system performance (Ghigi et al., 2014a), are perceived\nby humans as being more natural (Aist et al., 2007; Asri et al., 2014) and human-like (Edlund et al.,\n2008), which suggests that the most approprite SDSS for robots should be incremental, echoing the\nrequirements of robot-ready SDS in Kennington et al. (2020).\nIn this paper, we review the literature for incremental SDS with a particular focus on the decision-\nmaking component known as dialogue management (DM; explained further below). We find in our\nreview that ample work has been done in incrementalizing other aspects of SDSs such as automatic\nspeech recognition and natural language generation, but there is little work on incremental decision\nmaking. We identify some of the challenges and requirements to help guide future research on incre-\nmental decision making. The next section begins with background on incremental SDSs, focusing\nfirst on common modules then fully implemented and evaluated systems. The section that follows\nthen focuses on DM, giving first a brief overview of DM research, then focuses on incremental DM.\nWe then end this review with some concluding remarks and suggested paths for future work."}, {"title": "2. Background: Incremental Spoken Dialogue Systems", "content": "In this section, we review literature on common incremental spoken dialogue system modules ex-\ncept DM, which we save for the following section, explain incremental frameworks that have been\nadopted, and explain different paradigms of modeling incremental processing."}, {"title": "2.1 Spoken Dialogue Systems: Overview", "content": "In addition, but equally important, to the distinction between incremental (word-level) and non-\nincremental (utterance/sentence-level) SDS is the distinction between end-to-end and modular SDSS.\nAn end-to-end system is modeled using a single model that takes in input and produces an expected\noutput directly, such as a question-answering system that produces an answer given a question,\nor social chatbot that produces responses given text input. End-to-end systems often focus on the\ncapability of producing a written or spoken response no matter what the input is. End-to-end ar-\nchitectures now constitute the dominant approaches for developing open-domain dialogue systems\nwhere the main focus is the social aspect of the interaction (Roller et al., 2020; Ni et al., 2023).\nThe social aspects of interaction are, of course, important in a natural dialogue, but in task-oriented\ndialogue there is often something that is required outside of the dialogue itself for the dialogue to\nbe considered successful; e.g., look up information in a database, perform some kind of robotic\naction, or complete a payment. In contrast, modular SDSs are often task-based in that they help the\nuser achieve a goal such as booking a flight; they do not usually focus on social aspects beyond\nwhat helps to accomplish the task (Budzianowski et al., 2018; Zhang et al., 2020b). This traditional\ndistinction between open-ended end-to-end systems and task-based modular architectures is, how-\never, increasingly blurry, as recent years have seen the emergence of end-to-end models specifically\ndesigned for task completion (Liu et al., 2018; Zhang et al., 2020a; Hosseini-Asl et al., 2020; Young\net al., 2022). Interestingly, end-to-end models for task-oriented systems often operate by augment-\ning the generative model with implicit \u201cmodules\" in the form of retrieval mechanisms (Qin et al.,\n2019), knowledge bases (Yang et al., 2020) or domain-specific ontologies (Chen et al., 2023), or by\npre-training the response generation model in a modular fashion (Qin et al., 2023).\nAs the name suggests, modular systems are made up of modules that have well-defined roles\nin the system, and which can be made to communicate with each other. Figure 1 depicts visually a\nmodular SDS. For example, a prototypical SDS is often made up five modules including automatic\nspeech recognition (ASR) that transcribes speech to a text representation of the human utterances,\nnatural language understanding (NLU) that takes the text and yields a computable semantic ab-"}, {"title": null, "content": "straction, dialogue management (including dialogue state tracking) that makes a high-level decision\nabout the next action to take (e.g., look up information in a database and respond to the user), natural\nlanguage generation (NLG) that takes the dialogue manager's decision and determines which words\nto use and in what order, and text-to-speech (TTS) which actually speaks the words. These modules\nare further explained below.\nModular SDSS that process incrementally have an added complexity that all of the modules must\noperate at granularities that downstream modules can make use of, such as at the word level from\nASR to NLU. For example, given a system on a robot that is made up of the standard five modules\nas explained above (along with connections to robotic modules), and someone utters Hand me the\ngreen book on the left, an incremental SDS begins to process as soon as speech is detected. The ASR\noutputs each word, one at a time, and the NLU updates its understanding state each time a word\nis outputted by the ASR, and the NLU likewise produces outputs as it gathers information about\nthe utterance, for example, tagging hand as the action as the first word is uttered is uttered, and a\nspecific book as the target once the green book it has been uttered. The DM is tasked with querying a\nmodule that takes in visual information and instructing an arm to reach for the book in question. An\nincremental DM might already extend its arm in no particular direction as the first word is uttered,\nthen towards any green book once green book is uttered, then narrow the target down further as on\nthe left is uttered. The NLG actually then could utter something like green book as it begins to move\nits arm then ah, here we go once it determines a unique referent.\nThe above example highlights some things that differentiate an incremental DM from a more\ntraditional DM. First, the incremental DM receives installments of information over time, whereas\na traditional DM receives all of the information at once after everything has been uttered and the\nNLU processes the ASR's transcription. The incremental DM has an important job to do that the non-\nincremental DM does not: it not only must decide which action to take, but it also must decide when\nto take that action given the information that it has so far, and perhaps a bigger challenge-perform\nconcurrent actions as it is still receiving input. Traditional SDS has often relied on endpointing;\ni.e., waiting for silence after a speaker begins to speak, which burdens the ASR with determining\nwhen to act. However, pauses in speech are not always signals that someone is done speaking, and\nincremental SDS that relies on a DM to determine when to take an action can potentially use speech,\nsilence, as well as information from the content of the utterance (i.e., via the NLU) to make decisions\nabout when to act."}, {"title": "2.2 Frameworks & Architectures", "content": null}, {"title": "2.2.1 THE INCREMENTAL UNIT FRAMEWORK", "content": "A well-known framework for incremental processing that we will make reference to throughout\nthis paper is the incremental unit (IU) framework (Schlangen and Skantze, 2009, 2011). The IU\nframework views each bit of information created by the modules (e.g., words produced by ASR and\nslots produced by NLU) as part of a global network of interconnected IUs no matter which module\nproduced them. The framework defines functions for changing the network including how nodes of\nthe network are added and how the nodes are interconnected. Newly created IUs by a module (e.g.,\nwords by ASR) can be added to the IU network, revoked from the network if the module determines\nthat an IU was erroneously added in light of new information (e.g., the ASR first added the word IU\nfour but later revoked and added forty), and IUs can be committed, meaning they have already been\nadded to the IU network, and are guaranteed to not be revoked."}, {"title": null, "content": "To be added to the IU network, an IU has to be connected to other IUs that already exist in the\nnetwork through two relations: same level links which are relations between IUs created by the same\nmodule (e.g., if the ASR recognizes the and dog as two IUs, the later word dog as a same level link\nto the), and grounded-in links where a relation is created between and IU an the IU(s) that gave rise\nto that IU, for example the IUs the and dog from the ASR might give rise to a subject tag in the NLU,\nso it will have to grounded-in links, one to each word IU. When IUs are operated on (i.e., added,\nrevoked, or committed) the modules that triggered the operation signal downstream modules that\nconsume their input. For example, as the ASR module recognizes words from a microphone, it adds\neach of them to the IU network and signals to the NLU module that a new word has been added.\nThe IU framework has been implemented in several software packages, notably in Java as In-\nprotk (Baumann and Schlangen, 2012) and more recently in Python as ReTiCo (Michael and M\u00f6ller,\n2019). Other conceptual frameworks such as the Information State Approach (Traum and Larsson,\n2003) and Cohen's belief-desire-intent model (Cohen, 2017) remain valid in incremental SDS, in-\ncluding within the IU framework, though they are not strictly incremental dialogue frameworks."}, {"title": "2.2.2 RESTART VS. UPDATE INCREMENTAL MODELS", "content": "Khouzaimi et al. (2014) points out that not all methods and models are inherently incremental,\nthough many can be made to work incrementally under certain constraints. While their proposed\nmethod is important step for making systems incremental, we point out here that there are two ways\nto approach modeling incremental systems which has implications for how an incremental DM could\nwork: restart incremental and update incremental, which we explain presently."}, {"title": null, "content": "Restart Incremental Restart incremental models can take in input and produce incremental out-\nput (e.g., at the word level), but the input is repeated as the prefix grows, and models themselves\nare agnostic to the incremental updates themselves. Any model (e.g., a language model using zero-\nshot classification) could be used restart incrementally. For example, a NLU module that is restart\nincremental would take in the following input (time moves from top to bottom; each line represents\ninput to a NLU model):\nthe\nthe dog\nthe dog barks\nUpdate Incremental In contrast to restart incremental models, update incremental models do not\nneed repeated input and the model is designed to maintain a state that updates for each incremental\ninput. An NLU model that works in an update incremental way would not need to repeat a growing\nprefix from the ASR :\nthe\ndog\nbarks\nThe model explained in Kennington and Schlangen (2017), for example, was a Bayesian model\nthat produced a distribution over possible slot values that updated the distribution at each word in-\ncrement. An open question that we explore below is if a DM model should be either restart or update\nincremental."}, {"title": "2.3 Common Modules in Incremental Spoken Dialogue Systems", "content": null}, {"title": "2.3.1 AUTOMATIC SPEECH RECOGNITION", "content": "Current ASR systems receive streaming input and produce partial transcriptions, and can often\nwork at word-level increments. Early incremental ASR was implemented in Sphinx (Baumann\net al., 2009), and recent, neural ASR systems can often operate at the character level (Hwang and\nSung, 2016). The most common evaluation of ASR is word error rate, and recent neural models\nare showing very low error rates in common ASR benchmark datasets. However, evaluation of\nincremental ASR requires a closer look at how often a model alters its output and latency of results\n(Baumann et al., 2016). Because of the nature of the input and incremental output of ASR, it can be\nevaluated in isolation though it is also important to evaluate ASR in larger systems because certain\nmistakes will propagate to downstream modules."}, {"title": "2.3.2 NATURAL LANGUAGE UNDERSTANDING", "content": "Understanding natural language in SDSs also has a long history. In most NLU models, the input is\ntext. It the case of SDS, the input to NLU is transcribed speech. The output of NLU is important to\nconsider here, because it is often what serves as the input to the DM. The output needs to abstract\nsufficiently over the input text to form a computable meaning representation that the DM can use for\nmaking a decision on how to act. That meaning representation in incremental NLU has been tagged\nwords, logical forms, or frames (i.e., a set of key-value pairs known as slots), recent models tend to\nuse tags to produce slots and frames as output, or latent representations (e.g., embeddings). Below\nis an example frame for the utterance I want to book a flight from Seattle to Berlin for next Tuesday\nmade up of four slots:\nintent flight\nsource Seattle\ntarget Berlin\ntime 1 October 2023\nLike incremental ASR, incremental NLU produces output as much as possible as early as pos-\nsible (for example, individual filled slots), but unlike ASR, the input is discrete words instead of a\ncontinuous speech signal, so the intervals of when output is produced can vary depending on the\ninput and the domain. Early incremental NLU focused on classifying frames. Each input word pro-\nduced a partially complete frame as output (Devault et al., 2011; DeVault and Traum, 2012, 2013;\nYamauchi et al., 2013; Kennington and Schlangen, 2014; Kennington et al., 2014, 2015). Part of the\nframe is also the dialogue act; i.e., the overarching type of utterance produced by the interlocutor\n(e.g., a question or an assertion), which has also a history of incremental models (Petukhova and\nBunt, 2011).\nSimilar to their non-incremental counterparts, incremental NLU can benefit from syntactic pars-\ning to guide the language understanding, but in the case of incremental NLU, the parsers must also\nwork incrementally (i.e., produce a partial syntactic parse such as a tree for each word input). There\nhas been ample research in incremental parsing for different syntactic theories, including depen-\ndency parsing (Nivre, 2008), combinatory categorical grammar parsing (Hassan et al., 2008; Beuck\nand Menzel, 2013), as well as formalisms that have more semantic relational information includ-\ning robust minimal recursion semantics parsing (Copestake, 2007; Peldszus et al., 2012), dynamic"}, {"title": null, "content": "syntax (Eshghi et al., 2013) (see Hough et al. (2015) for a comparison of robust minimal recursion\nsemantics and dynamic syntax for incremental dialogue), as well as abstract meaning representation\n(Damonte et al., 2017).\nIn multimodal SDS, there is sometimes a need for the NLU to resolve references to objects\nthat exist in the shared space with the system and the human interlocutor. Incremental reference\nresolution can be viewed as the ability to narrow down possible referents in a shared visual space\nto an individual object. An incremental reference resolution model might, for example, understand\nthe word red to refer to objects that have a red color, and book to then further narrow down from all\nred objects to only red books. Incremental reference resolution is sometimes an integral part of NLU\n(Kennington et al., 2014), but have also been designed for modules that only resolve references\n(Schlangen et al., 2009; Paetzel et al., 2015; Kennington and Schlangen, 2015; Schlangen et al.,\n2016; Kennington and Schlangen, 2017), information that the DM may need to use for making a\ndecision.\nRecent work has explored how deep learning architectures can be used for incremental NLU,\nincluding recurrent architectures (Shivakumar et al., 2019) and to what degree architectures that\nare not inherently incremental (e.g., transformers) can be used for incremental NLU (Madureira and\nSchlangen, 2020), with mixed results. It is important to explore further how neural models can\nwork incrementally because many dialogue phenomena are incremental in natural. For example,\nShalyminov et al. (2017) showed that that deep neural dialogue models failed on common spoken\nphenomena like restarts and self-corrections."}, {"title": "2.3.3 INCREMENTAL NATURAL LANGUAGE GENERATION AND SPEECH SYNTHESIS", "content": "Early work in incremental NLG focused on resolving references in situated dialog. Kelleher and\nKruijff (2006) presented an approach to generating locative expressions using a basic incremen-\ntal algorithm that considered visual salience as a computation of an object's perceivable size and\ncentrality relative to the viewer, choosing words that will distinguish between the target object and\ndistractor objects. While the algorithm the authors present is \u201cincremental\u201d, it is not evaluated as\na word-by-word incremental model, but given the co-location and potential of being used at the\nword level, we include it here. More recent work has shown that incremental installments of words\nthat refer to a visual object using a model trained on visual object/word pairings that uses a beam\nsearch to determine the best possible word to utter can use a model of vision/word that isn't trained\nspecifically for NLG (Zarrie\u00df and Schlangen, 2016).\nIncremental NLG that builds on the IU framework included work that used a buffer of words to\nbe uttered, and three operations ADD, REVOKE, and PURGE were used for operating on the buffer\n(Dethlefs et al., 2012a). The ADD operation, of course, means a word is added to the buffer and even-\ntually uttered, unless it was REVOKEd (removed from the buffer) or PURGEd (all words currently\nin the buffer are removed in favor of a new hypothesis/goal). The NLG module often produced\nwords faster than they could be articulated by a TTS, giving an incremental NLG time to determine\nwhich words should be uttered, and in which order. The authors also carried out experiments to ex-\nplore how NLG interacts with output generation of other modalities, such as information on a screen\n(Dethlefs et al., 2012b). Others also looked at how incremental multimodal generation affects the\ninteraction qualities when the SDS is part of a virtual agent; articuluation of course included NLG,\nbut also hand gestures and eye gaze by the agent (Van Welbergen et al., 2012). Instead of plan-\nning all articulations before they were realized, the model generated behaviors incrementally and"}, {"title": null, "content": "linked increments in the multiple output modalities to each other so what happened correspdoned\ntemporally to other modalities (e.g., saying that in conjunction with a pointing gesture). In general,\nthe research has shown how incremental generation produces systems that are more reactive and\npereceived as more natural to human dialogue partners.\nSuch articulation means that the speech synthesis must also be incremental because an ongoing\nutterance that is offered by the NLG to the TTS might change before the TTS actually articulates a\nword in the utterance, thereby changing prosody or duration; e.g., the system may want to hold the\nfloor longer so will need to take longer to speak or insert artifacts such as ummm (Buschmeier et al.,\n2012; Baumann, 2014)."}, {"title": "2.3.4 INCREMENTAL SYSTEMS & EVALUATION", "content": "Incremental systems improve over non-incremental counterparts Beyond individual modules,\nfull systems are more complex and difficult to evaluate, but some have shown how incremental\nsystems are better in some domains than non-incremental counterparts. For example, a virtual in-\ncar dialogue that presented information incrementally was shown to be safer and more effective at\nhelping users remember information (Kousidis et al., 2014). The system was able to detect changes\nin the car's control (e.g., changing lanes or speed) and if any change was detected, the system would\npause its output and resume after the driving was constant. This allowed drivers to focus on driving\ninstead of non co-located interlocutors.\nIn another system, Fischer et al. (2021) used incremental speech adaptation to initiate human-\nrobot interactions in noisy (in-the-wild) scenarios. The robot incrementally adjusted the loudness\nof its voice depending on the circumstances, and was perceived positively by human users. Finally,\nGhigi et al. (2014b) showed that that an incremental dialogue strategy significantly improved system\nperformance by eliminating long and often off-task utterances that generally produce poor speech\nrecognition results. User behavior is also affected; the user tends to shorten utterances after being\ninterrupted by the system.\nChallenges of incremental evaluation K\u00f6hn (2018) reviewed incremental processing in the field\nof natural language processing (including parsing, machine translation, among others which are\nbeyond our scope), pointing out that granularity, grounding, monotonicity, and timeliness are all\naspects of incremental processing that play into how incremental systems are perceived. Most\nincremental SDS research is performed with the level of granularity set at the word level, but it might\nbe better in certain cases to work at sub-word or phrase levels, or on speech directly (see Kebe et al.\n(2022) for a non-incremental model that grounds language with raw speech). Grounding, moreover,\nis how a system aligns its output (in the case of SDS, generated speech) to what is happening in the\ndialogue state including physical context and the conversation up until that point.\nMonotonicity is an open question in SDS research; an ideal incremental ASR, for example,\nwould only output the correct word as early as possible as they are spoken without the need for\nrevoking and replacing words. Thus while monotonicity is an ideal to strive for, system modules\nmake mistakes and need to be able to repair those mistakes (hence the need for the IU framework),\nbut knowing how monotonic a system or an individual module is can be a useful metric for measur-\ning stability. Finally, timeliness is important: the system needs to respond quickly, but the system\nshould reach a level of confidence that the response is the proper one."}, {"title": "3. Review of Incremental Dialogue Management", "content": "In this section, we review literature relating to incremental DM. We give an overview of DM, dia-\nlogue state tracking, and attempts at incremental DM."}, {"title": "3.1 A Brief Overview of Dialogue Management", "content": "Dialogue management lies at the crossroads between NLU and NLG and is responsible for controlling\nthe general flow of the interaction, often in relation with the task(s) that should be fulfilled by the\ndialogue agent. In their seminal work on the Information State approach to dialogue management,\nTraum and Larsson (2003) mention four objectives:\n1. updating a representation of the dialogue context on the basis of interpreted communication\n(from all dialogue participants) ;\n2. providing context-dependent expectations for interpretation of observed signals as commu-\nnicative behavior ;\n3. interfacing with task/domain processing (e.g., database, planner, execution module, other\nback-end system), to coordinate dialogue and non-dialogue behavior and reasoning ;\n4. deciding what content to express next and when to express it.\nCurrent DM approaches distinguish between two central (and consecutive) components, respec-\ntively called dialogue state tracking and action/response selection."}, {"title": "3.1.1 DIALOGUE STATE TRACKING", "content": "The task of maintaining a representation of the current dialogue state over the course of the inter-\naction is called dialogue state tracking (Williams et al., 2016; Ren et al., 2018; Heck et al., 2020).\nThe dialogue state aims to reflect the system knowledge of the current conversational situation, and\noften includes multiple variables related to the dialogue history, common ground, external context\n(including the physical context, in the case of human-robot interaction), and the task(s) to perform.\nThis update of this dialogue state should occur upon the reception of any new observation that\nmay potentially impact the system's understanding of the current conversational situation, such\nas new user utterances, but also changes in the physical context of the interaction (for instance,\nnew entities perceived in the visual scene, or updates on the current location of the robot). For\nincremental systems, those observations will typically correspond to incremental units produced by\nthe NLU module.\nIn task-oriented systems, the dialogue state is often represented as a list of slots to fill (Williams\net al., 2016; Mrk\u0161i\u0107 et al., 2017), where a slot typically represents a required or optional attribute\nwhose value should be derived from the user inputs to complete the task. For instance, a restaurant\nbooking system might have slots for the date, time and number of people. Although such slot-filling\nrepresentation can be applied to many domains, it remains restricted to a fixed list of predefined\nslots, and may therefore be difficult to apply to conversational domains with varying numbers of\nentities and relations between them. This is notably the case in human-robot interaction, where the\nnumber of persons in a room, or the number of objects detected in the current visual scene is not\nfixed in advance and may change over the course of the interaction. In such settings, representing"}, {"title": null, "content": "the dialogue state as a graph of entities connected through various relations is a preferred alternative\n(Ultes et al., 2018; Walker et al., 2022).\nApproaches to dialogue state tracking also differ in whether they explicitly represent uncertainty\nrelated the current dialogue state using probability distributions. Many dialogue management ap-\nproaches represent the current dialogue state as a mere collection of key-value pairs (slots and their\nvalues). Although this representation does simplify both dialogue state tracking and action selection\n(in particular when this selection is optimized using reinforcement learning), it makes it harder to\ncapture uncertain, ambiguous or untrustworthy information, which may arise from e.g. error-prone\nsensory inputs (e.g. imperfect object recognition or ASR) or non-deterministic inference (e.g. lin-\nguistic ambiguities). An alternative is to explicitly represent the dialogue state as partially observ-\nable and define a probability distribution over possible state values (Young et al., 2013a; Mrk\u0161i\u0107\net al., 2017), often called the belief state. This belief state can notably be expressed as a Bayesian\nnetwork over state variables (Thomson and Young, 2010)."}, {"title": "3.1.2 ACTION/RESPONSE SELECTION", "content": "The second core DM task is action selection, whose role is to determine the next (verbal or non-\nverbal) action(s) to undertake by the system, based on the dialogue state updated through dialogue\nstate tracking. Although those actions will frequently correspond to verbal system responses, they\nmay also express other types of actions, such as API calls or high-level physical actions in the case\nof robotic platforms. A given dialogue state may lead to the selection of several actions to execute\nin parallel or in sequence (for instance, a robot may simultaneously move to a new location and\nutter a sentence to describe his movement to the user) or to no action at all.\nThe selection of the next action/response may take several forms, from handcrafted flowcharts\nand logical rules to data-driven techniques. Early work includes Larsson (2002), which surveyed ex-\nisting approaches to DM including logic-based, finite state, form-based, and plan-based approaches,\nbut the author regarded those approaches as limited in their practicality\u2014most were theoretical\nmodels without a concrete implementation. To remedy this situation, Larsson (2002) introduced\nIssue-based Dialogue Management. Issues are modeled semantically as questions, which can be\nimplemented in multiple theories (e.g., plan-based or form-based). This kind of dialogue is system-\ndriven in that the system has a specific task that it must perform and it drives the dialogue by asking\nquestions to the user, for example an automated travel agency would ask questions about price\nranges, travel dates, origin and destination airports, and airlines if it is going to help a user find\nan appropriate flight. As is the case with most dialogues, a kind of \u201cinformation exchange\" takes\nplace, the system is not requiring anything of the user beyond responding verbally with requested\ninformation.\nAlso seminal is the early work of Cohen and Levesque (1990) on plan-based approaches to\ndialogue management, building on earlier work by Allen (1979). More recently, Cohen and Galescu\n(2023) showcases a fully working multimodal conversational system that infers users' intentions and\nplans to achieve those goals. The system can infer obstacles to goals and actions and find ways to\naddress them collaboratively. The DM is broken down int four parts: plan recognition, obstacle\ndetection and goal adoption, planning, then execution. Planning here is an important aspect of the\nDM; it does not just identify an action to take now, it identifies a plan (i.e., a series of actions)\nthat must be taken to achieve a higher-level user goal, making it potentially more amenable to\nmultimodal (including IVA and robotic) control."}, {"title": null, "content": "The mapping from dialogue state to action(s) is called a dialogue policy, and various methods\nhave been developed to automatically learn"}]}