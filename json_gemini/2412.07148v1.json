{"title": "MM-POE: MULTIPLE CHOICE REASONING VIA. PROCESS OF ELIMINATION USING MULTI-MODAL MODELS", "authors": ["Sayak Chakrabarty", "Souradip Pal"], "abstract": "This paper introduces Multiple Choice Reasoning via. Process of Elimination using Multi-Modal models, herein referred to as Multi-Modal Process of Elimination (MM-PoE). This novel methodology is engineered to augment the efficacy of Vision-Language Models (VLMs) in multiple-choice visual reasoning tasks. Diverging from conventional approaches that evaluate each option independently, MM-PoE employs a dual-step scoring paradigm that initially identifies and excludes implausible choices, subsequently concentrating on the most probable remaining options. This method emulates human test-taking strategies, where individuals typically eliminate clearly incorrect answers prior to selecting the optimal response. Our empirical evaluations, conducted across three benchmark datasets, reveal that MM-PoE significantly improves both zero-shot and few-shot performance of contemporary state-of-the-art VLMs. Critically, this approach not only broadens the application of the elimination process to multi-modal contexts but also allows few-shot experiments, thereby addressing two principal limitations concerning usage of PoE only in zero-shot settings and only with a language-only framework. As a result, MM-PoE not only refines the reasoning capabilities of VLMs but also broadens their applicability to complex visual question-answering scenarios. All code and documentation supporting our work are available at https://pypi.org/project/mm-poe/, enabling researchers and practitioners to easily integrate and further develop these techniques.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have shown remarkable in-context learning capabilities [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], including proficiency in multiple-choice reasoning tasks [15, 16, 17]. However, while humans often engage in a process of elimination discarding obviously incorrect choices before selecting the final answer[18, 19, 20], current models do not inherently emulate this approach. The same limitation applies to Vision-Language Models (VLMs), especially in scenarios where a question-answering system must consider both textual and visual information simultaneously. This discrepancy can limit the effectiveness of vision language models in accurately solving such tasks.\nTo address this gap, we present the Multi-Modal Process of Elimination (MM-PoE), a two-step scoring method that closely mimics human reasoning strategies in multi-modal settings. First, MM-PoE scores and filters out likely incorrect answers by masking. Next, it re-scores the remaining subset of options to identify the most plausible one. By incorporating a structured elimination step, MM-PoE improves the models' ability to handle complex visual reasoning tasks and yields more accurate, interpretable results. Our zero-shot and few-shot experiments[20, 21, 17, 9] demonstrate the effectiveness of MM-PoE on three datasets encompassing a range of visual reasoning challenges[22, 23, 24]. The"}, {"title": "1.1 Background and Related Work", "content": "The rapid advancement in machine learning[25, 26, 27] techniques have been fueled by training large models[28, 29, 9, 3, 6, 13] on massive multi-modal datasets like [30]. In the context of multiple-choice question-answering, humans commonly employ a process of elimination, systematically removing unlikely answers to streamline their decision[18, 22, 20]. Such reasoning patterns have been explored in other domains, for example, through logical inference methods [24, 31, 32, 18], and have demonstrated that aligning computational approaches with human strategies can be beneficial.\nDespite their impressive capabilities, both LLMs and VLMs like [33, 34, 35, 36, 37, 38] typically consider each candidate solution independently or rely on aggregated likelihood without explicitly discarding less plausible options[13, 12, 28, 11, 19, 9]. This can be problematic in visually complex tasks, where multiple distractors may appear superficially similar. Prior research [39, 18] has indicated that more human-like reasoning frameworks can enhance performance, suggesting that incorporating elimination steps could address known limitations [15]. Our hypothesis posits that vision language models, when equipped with a mechanism to discard implausible answers systematically, can achieve better performance on multiple-choice visual reasoning tasks[16, 10]. This is particularly relevant in the context of logical reasoning, where the elimination of clearly incorrect options can simplify the decision process and potentially lead to more accurate outcomes.\nOur MM-PoE approach grounded in everyday test-taking strategies leverages these insights, focusing on structured elimination prior to final selection. The recent success of large-scale vision-language models [40] and foundational architectures for multi-modal reasoning, such as BLIP-2 [41], [42], provides a strong basis to improve upon. By integrating a two-step reasoning mechanism, we align the decision-making process with human heuristics, ultimately leading to more accurate and interpretable outcomes. MM-PoE aims to refine the ability to eliminate unlikely choices, making it more targeted and efficient in dealing with the nuanced challenges presented by multiple-choice questions, thus showing that by mimicking human reasoning processes, we can make VLMs not only perform better on standardized visual reasoning tasks but also behave in ways that are more interpretable and aligned with human cognitive processes. This approach also resolves one of the key limitations mentioned in [15] and thus extends their language-based model to a multimodal(language and vision) framework."}, {"title": "1.2 Our Contributions", "content": "\u2022 This study demonstrates that the Multi-Modal Process of Elimination (MM-PoE) enhances performance across three benchmark datasets, with notable efficacy in logical and visually grounded multiple-choice question-answering tasks.\n\u2022 It also establishes that MM-PoE can be seamlessly integrated with existing state-of-the-art Vision Language Models (VLMs), extending the conceptual framework of [15] to a more comprehensive multi-modal context. This addresses the previous limitation of focusing on a single modality as noted in [15].\n\u2022 While the preceding research in [15] was confined to zero-shot[9] settings and did not address few-shot scenarios, this work extends the application to few-shot settings as well, thereby broadening the scope of the original findings."}, {"title": "2 Methodology", "content": "The Multi-Modal Process of Elimination (MM-PoE) introduced in this paper operates on a two-step mechanism designed to enhance the decision-making capabilities of vision language models (VLMs) in multiple-choice visual reasoning tasks. This method employs a novel approach to option elimination followed by a focused prediction phase. The strategy is rooted in the belief that separating the elimination of clearly incorrect options from the choice of the best remaining option will improve overall task performance.\nGiven a multiple-choice visual reasoning task, we define the problem setting as follows:\n\u2022 Let x be the question or context provided.\n\u2022 Let h be the image provided."}, {"title": "2.1 Two-Step Scoring Method", "content": null}, {"title": "2.1.1 Step 1: Elimination", "content": "In the first step of the MM-PoE method, each option $y_i$ is scored based on a specified metric. The score function, $score(x, h, y_i)$, evaluates each option's plausibility given the question x and image h. The scores are used to eliminate options that are deemed less likely to be correct. Specifically, options whose scores are below the average score are eliminated. This is calculated as follows:\n$s_i = score(x, h, y_i)$\n$Y_{wrong} = \\{Y_i | s_i < avg(s_1,..., s_n)\\}$\nThis elimination strategy intuitively aligns with how humans often discard options that seem clearly incorrect before carefully considering the remaining choices."}, {"title": "2.1.2 Step 2: Prediction", "content": "The second step involves making the final choice from the non-eliminated options. This step utilizes a binary mask to exclude the eliminated options during the prediction phase. The mask for each option $y_i$ is defined as follows:\n$m_i = \\begin{cases}\n0 & \\text{if } y_i \\in Y_{wrong} \\\\\n1 & \\text{otherwise}\n\\end{cases}$\nThe masked context $x_{mask}$ is then constructed by modifying the original context x to include only the options for which $m_i = 1$. Each option is scored again, but this time within the context that explicitly excludes the eliminated options, possibly by using a template T that masks out $Y_{wrong}$ in the presentation of the options:\n$x_{mask} = T(x, Y, mask)$\nThe final predicted answer \u0177 is then the option with the highest score among the remaining options:\n$\\hat{y} = arg \\underset{i|m_i=1}{max}[score(x_{mask}, h, y_i)]$"}, {"title": "3 Experimental Setup", "content": "To evaluate the effectiveness of the MM-PoE, we designed an experimental framework that tests the method across a diverse set of visual reasoning datasets. This setup aims to compare MM-PoE with existing scoring methods to highlight its potential improvements in accuracy and reasoning capability. Following prior work on evaluating vision-language reasoning capabilities [15, 14], we initially adopt a zero-shot experimental framework without any task-specific tuning to gauge the inherent reasoning strength of MM-PoE. Performance is measured using accuracy, averaged over multiple random seeds to ensure statistical robustness. Additionally, to examine the adaptability of MM-PoE to limited supervision scenarios, we also consider few-shot experiments where we aimed to observe any changes in effectiveness when provided with a small number of context-specific demonstrations are provided to the model."}, {"title": "3.1 Benchmark Datasets", "content": "Our experiments were conducted on two different multiple-choice visual reasoning datasets - ScienceQA [14] and Diagram Understanding(AI2D) [24], selected to cover a broad spectrum of reasoning types and complexities. These tasks include both traditional visual reasoning tasks and more specialized ones designed to test specific reasoning skills. For example, AI2D focuses on diagrammatic reasoning, testing the model's ability to interpret schematic information and select correct answers from multiple choices. To ensure a comprehensive evaluation, we used train sets from established benchmarks when available; otherwise, we utilized development sets. In the case of varying number of options in the multiple-choice answers for ScienceQA and AI2D datasets, we standardize the dataset by filtering questions containing image context and exactly four answer choices. The evaluation ensures that the comparisons reflect the intrinsic capabilities of MM-PoE without confounding effects from extensive fine-tuning."}, {"title": "3.2 Models", "content": "For the core experiments, we utilized the GIT[33, 34] and BLIP[42, 41, 43] models, chosen for its balance between computational efficiency and performance in instruction-tuned vision language tasks. GIT, a generative image-to-text transformer, and BLIP, a bootstrapped language-image pre-training framework, represent state-of-the-art architectures capable of handling complex visual reasoning queries. These models have demonstrated strong capabilities in handling various multi-modal tasks and serves as a robust and reliable platform for evaluating our MM-PoE method."}, {"title": "3.3 Baselines Approaches", "content": "We compared MM-PoE against the following five baseline scoring methods to assess its relative performance:\n\u2022 Language Modeling (LM): This baseline uses the raw vision language modeling likelihood as the scoring function.\n\u2022 Average Language Modeling (AVG): This method averages the log probabilities across all tokens in the option.\n\u2022 Calibration: This involves adjusting the VLM scores based on calibration techniques that aim to correct for the model's confidence.\n\u2022 Channel: Channel methods score each option based on how likely the question is given the option, which reverses the typical conditional probability used in VLMs.\n\u2022 Multiple Choice Prompting (MCP): This approach formats the input by presenting the question followed by all options, prompting the model to select the most likely option.\nThese baselines, as shown in Table 4, offer a comprehensive view of existing techniques, ranging from standard likelihood-based methods to more sophisticated calibration and prompting strategies. By positioning MM-PoE against these methodologies, we rigorously assess its relative strengths in structured elimination and final choice selection."}, {"title": "3.4 Implementation", "content": "The effectiveness of MM-PoE hinges on the robustness of the scoring function and the accuracy of the elimination step. The scoring function can be any VLM-based likelihood estimator, such as vision language modeling likelihood, or any of its alternatives like average log probability or calibrated log probability. Our implementation tests multiple such scoring functions to identify the most effective ones in both eliminating implausible options and accurately selecting the final answer.\nThe MM-PoE method is designed to be model-agnostic, meaning it can be implemented using any existing VLM capable of scoring text options, and it is flexible enough to be adapted to different types of multiple-choice visual answering questions across various domains. The scoring functions were carefully chosen based on their theoretical alignment with the two-step elimination and prediction philosophy of PoE. We conducted extensive parameter tuning and optimization to maximize the performance of both the elimination step and the final prediction accuracy. All code\u00b9 and instructions for reproducing our experiments are publicly available, ensuring that interested researchers can integrate and refine MM-PoE within their own frameworks."}, {"title": "4 Results", "content": "Our experimental setup was designed to rigorously test the effectiveness of MM-PoE across a range of visual reasoning tasks and compare its performance against standard baseline methods. By thoroughly examining the interplay between scoring methods, model architectures, and the elimination strategy, our sample results, as shown in Figure 1, demonstrate the generality and utility of MM-PoE in advancing multi-modal reasoning capabilities and the potential benefits of integrating a process of elimination approach into visual reasoning strategies for multiple-choice questions."}, {"title": "5 Conclusion", "content": "This paper introduces the Multi-Modal Process of Elimination (MM-PoE), an innovative approach designed to enhance the reasoning capabilities of Vision-Language Models (VLMs) in multiple-choice visual reasoning tasks. By adopting human-like test-taking strategies\u2014specifically, the elimination of patently incorrect options prior to refining the final choice MM-PoE achieves notable improvements in accuracy and robustness as seen in Table 2. Even in the case of few-shot experiments, our approach shows comparable performance with respect to the zero-shot case. It is to be noted that a better masking accuracy after Step 1 of the two-step scoring process, may not necessarily lead to better final score the models cannot completely ignore the masked options provided as inputs in Step 2. In general, a higher masking accuracy can surely convince us that the model is practically eliminating the incorrect options as expected. Thus, this method effectively addresses two critical shortcomings of the previous research [15] by not only extending the investigation to few-shot settings from zero-shot scenarios but also by introducing a multi-modal dimension to the previously single-modality, language-only framework. Future research directions include refining the elimination criteria, removing masked options, and investigating more sophisticated scoring functions. MM-PoE can also potentially be integrated into broader multi-modal pipelines and extended to advanced domains such as medical imaging and complex scientific classification, where robust multiple-choice reasoning is critically important."}, {"title": "A Ethical Limitations", "content": "While MM-POE offers a step towards more interpretable and accurate reasoning in multi-modal AI systems, potential ethical concerns remain. Over-reliance on model-generated reasoning may lead to unintentional biases or misinterpreta- tions, particularly if datasets contain skewed examples or sensitive visual content. Additionally, as MM-PoE and related techniques become more capable, users must remain vigilant about ensuring that these models are applied in ethically responsible ways. Future work will focus on developing safeguards, including fairness audits and transparency tools, to mitigate potential harms and ensure that improvements in reasoning quality do not come at the expense of ethical integrity."}]}