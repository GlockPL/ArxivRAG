{"title": "CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression", "authors": ["Caiwen Jiang", "Xiaodan Xing", "Zaixin Ou", "Mianxin Liu", "Walsh Simon", "Guang Yang", "Dinggang Shen"], "abstract": "The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly correlates with higher patient mortality rates. Early detection of IPF progression is critical for initiating timely treatment, which can effectively slow down the advancement of the disease. However, the current clinical criteria define disease progression requiring two CT scans with a one-year interval, presenting a dilemma: a disease progression is identified only after the disease has already progressed. To this end, in this paper, we develop a novel diffusion model to accurately predict the progression of IPF by generating patient's follow-up CT scan from the initial CT scan. Specifically, from the clinical prior knowledge, we tailor improvements to the traditional diffusion model and propose a Clinically-Informed Residual Diffusion model, called CIResDiff. The key innovations of CIResDiff include 1) performing the target region pre-registration to align the lung regions of two CT scans at different time points for reducing the generation difficulty, 2) adopting the residual diffusion instead of traditional diffusion to enable the model focus more on differences (i.e., lesions) between the two CT scans rather than the largely identical anatomical content, and 3) designing the clinically-informed process based on CLIP technology to integrate lung function information which is highly relevant to diagnosis into the reverse process for assisting generation. Extensive experiments on clinical data demonstrate that our approach can outperform state-of-the-art methods and effectively predict the progression of IPF.", "sections": [{"title": "1 Introduction", "content": "Idiopathic Pulmonary Fibrosis (IPF) is a severe and irreversible lung disease that scars and thickens lung tissues, leading to respiratory difficulties [15,21]. Timely treatment of IPF can effectively slow down its process and improve patients' quality of life [4, 22]. The progression of IPF can either remain stable or exac- erbate over time. Consequently, to save healthcare expenses, in some countries (especially those with universal healthcare like the UK), antifibrotic treatment is initiated only if the IPF is confirmed to exacerbate over time. This approach presents a challenge: treatment is delayed until the fibrosis has advanced, losing early intervention opportunities for patients at high risk but not yet showing sig- nificant progression. In this context, predicting the progression of IPF in advance is extremely important for enabling timely treatment and reducing healthcare costs.\nA feasible approach for predicting the progression of IPF is to generate the follow-up CT scan from the initial CT scan. This method of disease predic- tion or diagnosis through generation has already achieved success in numerous studies [5,6,10,11,14]. For instance, Han et al adopt the regularized generative adversarial networks to generate images of future time points for predicting the risk of osteoarthritis [6]. Jiang et al employ a transformer-based generative ad- versarial network to generate dual-energy CT images from single-energy CT for diagnosing postoperative cerebral hemorrhage [10]. Moreover, we choose to gen- erate the follow-up CT scan rather than directly predicting disease progression from the initial CT scan considering the following facts: 1) The use of follow-up CT scan is more clinically natural in terms of diagnosis and thus more subjec- tively convincing. 2) The generation of follow-up CT scan can better exploit in the information entailed initial CT scan, thus more likely to produce a correct di- agnosis. 3) The generated follow-up CT scan can provide additional information, such as the location of the lesion area.\nAmong the existing image generation techniques, the diffusion model has shown large potential and obtained great success [7, 20, 25]. They accomplish this by converting complex generation tasks into a series of simpler denoising tasks, enabling more stable and detailed generation. Meanwhile, clinical obser- vations reveal the following prior information. First, due to patient posture and physiological movement, there is a significant spatial difference between the two CT scans. Second, as both scans are from the same individual, the majority of their content (i.e., the anatomical structure) is identical, while the lesion areas we focus on only constitute a minor part. Lastly, patients typically undergo lung function tests during their initial CT scan, and the information from these tests is highly relevant to the progression of IPF.\nTaking all into consideration, in this paper we propose a Clinically-Informed Residual Diffusion model (CIResDiff) based on the traditional diffusion model to"}, {"title": "2 Method", "content": "Our method is illustrated in Fig. 1. First, we extract and align the lung region from the two CT scans by the target region pre-registration. Then, in the residual diffusion process, the follow-up lung image xo is converted to the noisy initial lung image x by incrementally incorporating the differences of two CT scans. Subsequently, the noisy initial lung image x undergoes a series of reconstruction steps guided by the clinically-informed process until it's converted back to the follow-up lung image xo. Note that only the reverse process is involved during"}, {"title": "2.1 Target Region Pre-registration", "content": "Voxel-to-voxel supervised generation is less challenging compared to direct un- supervised generation. Hence, we employ a target area pre-registration to obtain spatially-aligned lung image pairs from the initial and follow-up CT scans for model training.\nSpecifically, for the input of two CT scans, to eliminate background inter- ference, we first use the TotalSegmentator [23], an open-access tool based on nnU-Net and trained with more than one thousand samples, to segment the left and right lung regions from both CT scans. Then, we perform a dilation oper- ation on the segmented results to preserve lung-surrounding tissues relevant to diagnosis. Subsequently, we apply an affine registration method [1] to align the segmented left and right lung regions individually. Finally, we merge the aligned left and right lung regions to obtain spatially-aligned lung region image pairs for model training."}, {"title": "2.2 Residual Diffusion", "content": "In the process of generating follow-up scans from initial scans, the main learn- ing objective for the model is the lesion areas that are crucial for diagnosis but occupy a small proportion. Thus, we integrate residual learning with the diffu- sion model to enhance the model's ability to learn changes in such lesion areas, proposing a residual diffusion strategy. This strategy enables the diffusion model to exclusively learn the residuals between the initial and follow-up scans.\nUnlike the traditional diffusion process, which disrupts the input initial lung image xo into pure Gaussian noise, our proposed residual diffusion converts the input initial lung image xo into noisy follow-up lung image x\u0442. Specifically, we first calculate the difference e0 = yo \u2212 xo between the initial lung image yo and the corresponding follow-up lung image xo, and then apply a shifting sequence {\u03b7t}T t=1 to incrementally add this difference e0 to xo. In this way, the residual diffusion process can be formulated as follows:\n$$q(x_t|x_0, y_0) = \\mathcal{N}(x_t; x_0 + \\eta_t e_0, k^2 \\eta_t I), \\quad t = 1, 2, ..., T,$$"}, {"title": "2.3 Clinically-informed Process", "content": "During the diagnosis of IPF, lung function tests are typically conducted in addi- tion to two CT scans. The information derived from these tests is highly relevant to the lung anatomical structure. Therefore, we believe that capturing the cor- relation between function test information and the corresponding CT scan, and using it to guide the generation process, can aid in producing CT scans with higher diagnostic value. To achieve this, we design a clinically-informed process based on Contrastive Language-Image Pretraining (CLIP) [18] technology.\nDetails of the clinically-informed process are shown in Fig. 1 (b), which in- cludes pre-training and feature fusion stages. In the pre-training stage, we extract textual and image features from function text information and the correspond- ing initial scan using text and image encoders, respectively. Then, we constrain these features to be aligned using the contrastive loss. In this way, we can obtain the pre-trained text encoder for incorporating function text information into the reverse process. Note that the samples used for pre-training are exclusively from the training set and do not involve any test samples.\nIn the feature fusion stage, for a particular reconstruction in the reverse process, the pre-trained text encoder first extracts textual features ztext from function test information. Then ztext is fed into a denoising attention U-Net [16] at each step for calculation of cross-attention, where the query Q and key K are calculated from ztext while the value V is still calculated from the output of the previous layer because our final goal is CT estimation. Denoting the output of previous layer as zCT, the CT-guided cross-attention can be formulated as follows:\n$$Output = softmax(\\frac{Q_{text} K_{text}^T}{\\sqrt{d}} + B) V_{CT}$$\n$$Q_{text} = Conv_Q(z_{text}), K_{text} = Conv_K(z_{text}), V_{CT} = Conv_V(z_{CT}),$$"}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Dataset and Implementation", "content": "Our dataset originates from OSIC\u2079, an openly accessible global database con- taining numerous CT scans related to Idiopathic Pulmonary Fibrosis (IPF). We collect a total of 200 samples, each comprising of two CT scans with a 46.3\u00b17.8 weeks interval, along with corresponding lung function test information (includ- ing physiological indicators such as vital capacity, peak expiratory flow, etc.) and diagnostic labels. Among these 200 samples, 160 samples are used for training and the remaining 40 samples are used for testing. During the evaluation, we conduct five-fold cross-validation to exclude randomness.\nIn our implementation, experiments were conducted on the PyTorch plat- form using two NVIDIA Tesla A100 GPUs and an Adam optimizer with initial learning rate of 0.001. All images are resampled to voxel spacing of 1\u00d71 \u00d71 mm\u00b3 and resolution of 512 \u00d7 512 \u00d7 256, while their intensity range is normalized to [0, 1] by min-max normalization. For increasing the training samples and reduc- ing the dependence on GPU memory, we extract the overlapped patches of size 96 \u00d7 96 \u00d7 96 from every whole CT scan. We evaluate the quantitative results by two commonly used quantitative metrics, including Peak Signal to Noise Ratio (PSNR) [9] and Structural Similarity Index (SSIM)."}, {"title": "3.2 Ablation Analysis", "content": "To verify the effectiveness of our proposed strategies, i.e., residual diffusion and clinically-informed process, we design another four variant diffusion models (DMs) including: 1) DM: standard DM; 2) DM-CIP: DM with clinically-informed process; 3) DM-R: DM with residual diffusion; 4) DM-R-CIP: DM with residual diffusion and clinically-informed process. All methods use the same experimental settings, and their quantitative results are given in Table 1."}, {"title": "3.3 Comparison with State-of-the-art Methods", "content": "We further compare our CIResDiff with six state-of-the-art generation meth- ods, which can be divided into three classes: 1) GAN-based methods, including Pix2Pix-GAN [8] and SAGAN [13]; 2) transformer-based methods, including TransUNet [2] and ResViT [3]; 3) diffusion model-based methods, including DiffusionCT [19] and conditional Diffusion (cDiff) [17]. The quantitative and qualitative results are provided in Table 2 and Fig. 3, respectively.\nQuantitative Comparison: The quantitative results are provided in Table 2. From the table, it is evident that diffusion model-based methods generally out- perform GAN-based and transformer-based methods, validating our selection of the diffusion model as the baseline. Moreover, among all diffusion model- based methods, our CIResDiff achieves the optimal results, with improvements in PSNR and SSIM over the sub-optimal cDiff by 1.68 dB and 1.06%, respec- tively. This demonstrates the effectiveness of our targeted improvements to the traditional diffusion model, including residual diffusion and clinically-informed process.\nQualitative Comparison: We provide a visual comparison of follow-up lung images generated by six different methods in Fig. 3. First, compared to other methods, our CIResDiff can generate the overall optimal images, characterized by the least noise, fewest artifacts but clearest structure. Second, in terms of detail, our CIResDiff can also most accurately generate the lesion areas (i.e., areas marked by red boxes) that are crucial for predicting the progression of IPF. Finally, the lightest color in the difference map demonstrates our CIResDiff can generate lung images with the smallest difference from the ground truth. Such key observations demonstrate that our CIResDiff is superior to those state-of- the-art methods."}, {"title": "3.4 Diagnostic Evaluation", "content": "Our ultimate goal is to predict the progression of IPF using generated follow-up lung images. Therefore, we design relevant downstream diagnostic tasks to assess the diagnostic value of follow-up lung images generated by different methods. Specifically, we first train a ResNet-based classifier using real image pairs (i.e., real follow-up lung image and real initial lung image) from the training set. During the training process, follow-up and initial lung images are concatenated together as input to predict diagnostic labels. Then, we use the pre-trained classifier to assess the diagnostic value of images generated by different methods. During evaluation, the input is the fake image pairs (i.e., generated follow-up lung image and real initial lung image). The prediction results are provided in Fig. 2.\nFig. 2 shows that the follow-up lung images generated by our CIResDiff yield the best results for predicting IPF compared to other methods. Specifically, com- pared to Pix2Pix-GAN, which obtains the worst results, our CIResDiff shows a significant improvement in accuracy by 18%. This may be due to our method's incorporation of highly relevant lung function information into the generation process, thereby producing images more beneficial for diagnosis. These results"}, {"title": "4 Conclusion", "content": "In this paper, to achieve early prediction of IPF progression, we develop a novel diffusion model named CIResDiff to predict patients's follow-up CT scan from the initial CT scan. To facilitate more precise and effective generation, our CIRes- Diff employs three strategies: 1) pre-aligning lung regions in both CT scans to reduce the complexity of generation; 2) learning residuals between initial and follow-up CT scans to focus more on lesion areas critical for prediction; 3) in- tegrating clinical lung function test information to help generate results with greater diagnostic value. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches and can generate images with higher diagnostic value."}]}