{"title": "GRAPHMUSE: A LIBRARY FOR SYMBOLIC MUSIC GRAPH PROCESSING", "authors": ["Emmanouil Karystinaios", "Gerhard Widmer"], "abstract": "Graph Neural Networks (GNNs) have recently gained traction in symbolic music tasks, yet a lack of a unified framework impedes progress. Addressing this gap, we present GraphMuse, a graph processing framework and library that facilitates efficient music graph processing and GNN training for symbolic music tasks. Central to our contribution is a new neighbor sampling technique specifically targeted toward meaningful behavior in musical scores. Additionally, GraphMuse integrates hierarchical modeling elements that augment the expressivity and capabilities of graph networks for musical tasks. Experiments with two specific musical prediction tasks \u2013 pitch spelling and cadence detection \u2013 demonstrate significant performance improvement over previous methods. Our hope is that GraphMuse will lead to a boost in, and standardization of, symbolic music processing based on graph representations.", "sections": [{"title": "1. INTRODUCTION", "content": "Symbolic music processing entails the manipulation of digital music scores, encompassing various formats such as MusicXML, MEI, Humdrum, **kern, and MIDI. Unlike audio-based representations, symbolic formats offer granular information on note elements, including onset, pitch, duration, and other musical attributes like bars and time signatures.\nWhile prior research in symbolic music processing often adopted techniques from the image processing [1-3] or natural language processing [4-6] domains, recent attention has shifted towards graph-based models, which could presumably better capture the dual sequential and hierarchical nature of music. Graph Neural Networks (GNNs) have been showcased as potent tools for diverse symbolic music tasks, including cadence detection [7], optical music recognition [8], music generation [9], Roman numeral analysis [10], composer classification [11], voice separation [12], and expressive performance rendering [13].\nHowever, a standardized framework for constructing and processing music graphs has not yet been introduced to the field. To address this challenge, we developed Graph-Muse, a Python-based framework to efficiently and effectively process information from musical scores, construct musically meaningful graphs, and facilitate the training of graph-based models for symbolic music tasks.\nA key innovation of our work lies in the introduction of a new sampling technique tailored to specific properties of music while maintaining efficient and robust training of GNNs. Additionally, GraphMuse integrates within the graphs and models hierarchical elements that augment the capabilities of graph networks for musical tasks.\nWe evaluate our framework on pitch spelling and cadence detection tasks, comparing it against existing state-of-the-art methods. Through the synergistic utilization of our framework's components, we achieve a significant performance increase compared to the previous methods. Our overarching objective is to establish a standardized framework for graph processing in symbolic music analysis, thus catalyzing further progress in the field.\nAltogether, our contributions are three-fold: i) We provide a structured, generic, and flexible framework for graph-based music processing; ii) we release an open source Python library that comes with it; iii) we achieve performance improvements in a principled way by focusing on the design of the individual parts of the framework."}, {"title": "2. PROCESSING MUSIC SCORES WITH GNNS", "content": "In this section, we describe existing graph modeling approaches for musical scores. They all have a common pipeline which involves building a graph from a given musical score (see Figure 1) and using a series of convolutional blocks to produce context-aware hidden representations for each node. We start by describing the graph-building procedure and a generic graph convolutional block; we then take a detailed look at the problem of graph sampling, which will motivate a new sampling procedure that will be presented in the next section."}, {"title": "2.1 Preprocessing: Constructing Graphs from Scores", "content": "A score graph can be represented as a heterogenous attributed graph. A heterogeneous graph has a type associated with each node and edge in the graph [14]. An attributed graph has an associated feature vector for\neach node in the graph [15]. Therefore, a heterogenous attributed graph is defined by a quintuple $G = (V, E, X, A, R)$, together with the mappings $\\phi: V \\rightarrow A$ and $\\psi: E \\rightarrow R$, where V is the set of nodes, E is the set of edges, $X \\in V \\times R^k$ the feature matrix A is the node types and R is the edge types. $\\phi$ maps each node to its type and $\\psi$ maps its each edge to its corresponding type.\nWe create such a graph from a musical score by following previous work [10-13]. Each node $v \\in V$ corresponds to one and only one note in the musical score. R includes 4 types of relations: onset, during, follow, and silence, corresponding, respectively, to two notes starting at the same time, a note starting while the other is sounding, a note starting when the other ends, and a note starting after a time when no note is sounding. The inverse edges for during, follows, and silence relations are also created.\nFormally, let us consider three functions on(v), dur(v), and pitch(v) defined on a note $v \\in V$ that extract the onset time, duration, and pitch, respectively. A typed edge (u,r,v) of type $r \\in R$ between two notes u, v $\\in$ V belongs to E if the following conditions are met:\n\u2022 on(u) = on(v) \u2192 r = onset\n\u2022 on(u) > on(v) \u2227 on(u) \u2264 on(v) + dur(v) \u2192 r= during\n\u2022 on(u) + dur(u) = on(v) \u2192 r = follow\n\u2022 on(u) + dur(u) < on(v) \u2227 \u2260v' \u2208 V, on(v') < on(v) \u2227 on(v') > on(u) + dur(u) \u2192 r = silence\nA in the literature usually only includes a single type, i.e. the note type v. However, we extend this definition in Section 3.1."}, {"title": "2.2 Encoding: Graph Convolution", "content": "Graph convolution and message passing are core operations in graph neural networks (GNNs) for learning node representations. In graph convolution, in its simplest form, each node aggregates messages from its immediate neighbors by computing a weighted sum of their features:\n$h_v^{(l+1)} = \\sigma(\\sum_{w \\in N(v)} W^{(l)} h_w^{(l)})$\nwhere $h_v^{(l)}$ is the representation of node v at layer l, N(v) denotes the neighbors of node v, $W^{(l)}$ is a learnable weight, and $\\sigma$ is a non-linear activation function. Through successive iterations of message passing and aggregation, each node refines its representation by incorporating information from increasingly distant nodes in the graph, ultimately enabling the network to capture complex relational patterns and dependencies within the graph data.\nIn the context of music, graph convolution can be understood as a method for defining a note not only by its own characteristics and properties but by also considering the characteristics of its neighboring notes within the musical graph. In this work, as well as previous graph-based work on music [7,10,11] the preferred graph convolutional block is SageConv taken from one of the first and fundamental works in graph deep learning [16]."}, {"title": "2.3 Sampling: Handling Graph Data for Training", "content": "In an ideal world without computing resource considerations, we can imagine a training pipeline that receives an entire graph as input to a graph convolutional model. Assuming that we have the resources and time to perform such a task the process is easy to grasp. All nodes of the graph are updated in a single step based on their neighbors as described in the previous section.\nHowever, the graph world presents us with several complexity issues. Graph datasets in the wild typically come in two forms: i) a (possibly large) collection of small graphs, each containing maybe fewer than 50 nodes [15]; ii) a single large-scale graph such as a social network [17], a recommender system [18], or a knowledge graph [19]. The previous naive scenario presents a time-efficiency and computation waste bottleneck for the former and a memory insufficiency issue for the latter. To mitigate these issues, in the former case one can batch many small graphs"}, {"title": "2.4 Task-specific Modeling", "content": "Finally, the node embeddings created by the graph convolutional encoder serve as input to task-specific models that solve some specific prediction or recognition task. In a graph context, we distinguish, at an abstract level, between node classification, link prediction, and entire graph classification tasks. Examples of node classification tasks can be found in [7] which takes the embeddings from the GCN encoder and employs an edge decoder coupled with a graph convolution classifier for cadence prediction labels; and in [10], which forwards the embeddings to sequential layer and then MLP classifiers to perform Roman Numeral Analysis. In [12], musical voice separation is framed as a link prediction task; the node embeddings are input to a pairwise edge similarity encoder to predict link probabilities between notes in the same voice. An example of a graph classification task can be found in [11] where the embeddings are aggregated and passed through a shallow MLP for composer classification.\nNaturally, task-specific models will not be part of the generic graph processing pipeline and library which we publish with this paper."}, {"title": "3. METHODOLOGY", "content": "In this section, we discuss our approach to addressing the different components of the pipeline shown in Figure 1. In particular, we explain the preprocessing procedure for creating score graphs, we detail our strategy for musically intuitive graph sampling, and finally, we discuss model variants that are made possible by the previous steps of the pipeline."}, {"title": "3.1 Preprocessing", "content": "The central activity in the preprocessing step is the creation of graphs from musical scores. In our library, we extend the conventional graph creation process by introducing hierarchical musical dimensions (beats and measures), in order to enhance the score graphs' representational capacity. More specifically, we enrich the node type set A (defined in Section 2.1) with two additional types $\u03b2$ and $\u03bc$ for beats and measures respectively. The process involves detecting beats and measures within the musical score, generating edges (of type connect to every beat from each note falling within its temporal boundaries, and repeating this process for measures. Additional edges of type next are drawn between consecutive beats and measures to enrich the connectivity and contextual understanding within the graph. Furthermore, we aggregate features from constituent notes through the connect edges via message passing to equip each beat and measure with informative attributes by computing the mean vector of their note features.\nThe inclusion of beat and measure node elements, as well as the creation of inverse edges, are made optional, ensuring compatibility with diverse research needs and\navoiding imposing rigid structures onto the graph-based music processing framework.\nWe prioritize the efficiency and speed of the graph creation process by transitioning the graph creation implementation to C code, leveraging its performance benefits, and establishing a Python binding for seamless integration into our workflow. Recognizing the temporal nature of musical elements, such as notes, beats, and measures, we refine our neighbor searching windows accordingly, optimizing computational efficiency."}, {"title": "3.2 Sampling", "content": "We discussed general neighbor sampling for large-scale graphs in Section 2.3 and some problems related to graph-structured music data. In this section, we elaborate on our musically informed sampling process for music graphs, which enables the training of the models outlined in the subsequent sections. In this process, we aim to sample sections of scores and employ neighbor sampling to fetch the neighbors of notes within those sections.\nIndeed while our nodes could be ordered in various ways, the most perceptually significant aspect is time organization. Recognizably, individuals can still identify a musical piece when segmented along the time axis,\nwhereas focusing solely on pitch intervals may be challenging. Moreover, perceptual research indicates that the commencement time of a note holds greater salience than its offset time, particularly for percussive instruments like the piano, where the sound naturally fades over time [23]. Hence, when constructing graphs from musical scores, we prioritize node arrangement based on absolute onset time followed by pitch.\nOur initial limitations are mostly related to memory usage. To limit our memory we need to predefine three initial arguments: i) the size of each target subgraph S from every score, ii) the number B of scores in each batch, and iii) the number of hops and neighbors for each hop (similar to node-wise sampling techniques). In each batch, we update the representation of our target nodes which is essentially the size of S \u00d7 B.\nOnce the ordering is set and the three arguments are defined we can initiate the process of sampling a subgraph, as shown in Figure 3. First, we sample a random note from the graph of each score. Next, we correct the position of the note by searching for any vertical neighbors (same onset value notes and potentially different pitch). Then we extend to S notes to the right where S indicates a predefined maximum subgraph size. We also correct the rightmost boundaries to include or exclude vertical neighbors for the last onset always respecting the aforementioned size S. Once this process is completed we obtain the target nodes per score within the batch. These are the nodes whose representation we want to update at the end of the graph convolutional process.\nHowever, since graph convolution is performed recursively we need to fetch the k-hop neighbors for each one of the target nodes where k indicates the depth of the GCN. For this step, we can consult the literature [16] and perform neighbor sampling to fetch the k-hop neighbors. This process is repeated for B different scores. Finally, the B score subgraphs of size at most S each are first joined together and then fed to the model.\nDuring this process, we can keep information about the target nodes and the size of each score subgraph, which could allow us to design more creative models that can exploit this information. Such models are presented in the next section. Moreover, we adopt a potential approach for hierarchical graphs by also extending the sampling for beat and measure nodes as shown in Figure 3."}, {"title": "3.3 Model Designs", "content": "In this section, we explore various model designs for the graph-based encoder in our processing pipeline (Figure 1). Designing such an encoder involves addressing two fundamental questions: the selection of graph convolutional blocks and the selective exploitation of information from the input graph.\nThe first question, regarding graph convolutional blocks, remains open-ended, offering numerous possibilities for exploration and customization. In its current version, GraphMuse offers the options of convolutional blocks on a per-node or per-edge type basis. We suggest that graph-attention networks may offer promising avenues, particularly for hierarchical elements such as beats or measures.\nIn response to the second question, we devise a series of models by selectively incorporating or excluding elements from the input graph. Our foundational model, termed NoteGNN, exclusively utilizes note elements and their corresponding edges. This model serves as the basis for further extension. For instance, we expand upon NoteGNN to construct BeatGNN, which incorporates beat elements (see Section 3.1 above) alongside notes. Similarly, we develop MeasureGNN by integrating measures into the encoding process. When all note, measure, and beat elements are included, the resultant model is denoted as MetricalGNN. Furthermore, we explore the possibility of hybridizing model types, such as combining GNNs with sequential models. This hybridization is facilitated by the sampling process that organizes notes in onset order, allowing for the batch to be unfolded by score. Consequently, the same batch can be processed through both GNN and sequential models simultaneously. Specifically, we employ a graph encoder and a sequential encoder in parallel \u2013 in our case we use a stack of 2 bidirectional GRU layers. The GRU stack receives the unfolded batch of size (B, S, K) where B is the number of scores within the batch, S is the number of sampled target nodes for each score order by onset and then by pitch, and K is the number of node features. The embeddings of both encoders are concatenated together and an additional linear layer is applied to project them to the required dimension.\nThis architecture, which we call HybridGNN in our experiments, combines the strengths of both GNNs and sequential models, resulting in better performance as shown in our experiments."}, {"title": "3.4 The Library", "content": "The components discussed in the preceding section have been implemented and made available in an open-source Python library called GraphMuse. This library follows a similar philosophy as PyTorch and PyTorch Geometric, comprising models and graph convolutional blocks, loader pipelines, data pipelines, and related utilities. GraphMuse is built upon and thus requires PyTorch and PyTorch Geometric. The loaders and models provided by GraphMuse are fully compatible with those of PyTorch Geometric. For musical input and output, GraphMuse is compatible with Partitura [24], a Python library for symbolic music processing, allowing it to work with a variety of input formats such as MusicXML, MEI, Humdrum **kern, and MIDI."}, {"title": "4. EVALUATION", "content": "To evaluate our framework, we perform experiments on two tasks, cadence detection and pitch spelling. We put to the test both the models discussed as well as the sampling process. For pitch spelling, we compare our models to the previous sequential state-of-the-art model, PKSpell [25] and the GraphSAGE variant of our note-level model. For cadence detection, we compare our models to the previous state-of-the-art model by Karystinaios and Widmer [7] which is also graph-based and follows a GraphSAGE sampling strategy. For both tasks, we perform ablations by removing the hierarchical elements such as beat and measure nodes and edges, or incorporating hybrid models. This work focuses on the application of the GraphMuse library therefore, a detailed comparison of various input encodings and architectures, as conducted by [11], is beyond the scope of this paper."}, {"title": "4.1 Pitch Spelling", "content": "Previous work on Pitch Spelling set the state-of-the-art by using a sequential model [25]. The task of pitch spelling tackles in parallel key signature estimation and pitch spelling estimation per note, however, the key signature is a global attribute usually set for the whole piece although it can sometimes change midway. The previous architecture uses a GRU encoder for pitch spelling and then infuses the logits together with the latent representation to another GRU layer for the key signature prediction.\nFor our approach, we use a GNN encoder as described in Section 3.3 followed by two classification heads for key and pitch spelling respectively. We train and evaluate all models on the ASAP dataset [26] using a random split with 15% of the data for testing and the 85% for train and validation as described in [25]."}, {"title": "4.2 Cadence Detection", "content": "For the cadence detection model, we chose to use a modified version of the cadence detection model originally proposed in [7]. Our considerations were based on a more efficient training process, and the integration of our pipeline possibilities. The model was expanded to accept a heterogeneous score graph as input, as described in Section 2.1. Additionally, we enhanced the model's predictive capabilities from binary (no-cad or PAC) to multiclass cadence prediction, encompassing PAC, IAC, and HC labels. Furthermore, we refined the architecture by incorporating an onset regularization module, which aggregates the latent representations (post-GNN encoder) of all notes occurring at a distinct onset within the score and assigns them to every note sharing that onset.\nIn the training phase, the input graph first undergoes processing through the graph encoder. The resulting node embeddings are then grouped based on onset information extracted from the score, and their representations are averaged. Subsequently, embedded SMOTE [27] is applied to balance the distribution of cadence classes compared to the notes lacking cadence labels in the score. However, during inference, this synthetic oversampling step is omitted. Finally, the oversampled embeddings are fed into a shallow 2-layer MLP classifier to predict the cadence type.\nWe trained our model with a joined corpus of cadence annotations from the DCML corpora2, the Bach fugues"}, {"title": "4.3 Experiments", "content": "The configuration for training pitch spelling graph models with our sampling technique uses a batch size B = 300, sampling from 300 scores at each step, and target node size S = 300. For cadence graph models, B = 200 and S = 500. All graph models, including GraphSAGE, utilize three heterogeneous SageConv layers with a hidden size of 256 and a dropout of 0.5. Neighbor sampling for each layer fetches up to three neighbors per sampled node per relation. We train all models with the Adam optimizer (learning rate 10-3, weight decay 5 \u00d7 10-4) on a GTX 1080 Ti. Each experiment is repeated at least four times with different random seeds, and statistical significance testing is performed using the ASO method at a confidence level \u03b1 = 0.05 [31].\nTable 1 presents the results of experiments experiments conducted on the two tasks. The metrics used for evaluation are Accuracy (A) for pitch spelling and key recognition, and the macro F1 score (F1) for cadence detection. Note that the model employed on the GraphSAGE methods and the model NoteGNN are virtually the same apart from the sampling strategy with which they were trained.\nFor the pitch spelling task, we can observe that the actual pitch spelling accuracy (A-Pitch) of all proposed models surpasses both the PKSpell and GraphSAGE methods. Across all models, the MetricalGNN achieves the highest accuracy of 95.6%, closely followed by BeatGNN and MeasureGNN with accuracies of 95.1% and 95.4%, respectively. These results indicate the benefits of incorporating hierarchical musical elements such as beats and measures. However, it is worth noting that while MetricalGNN achieves the highest accuracy, it is closely followed by the hybrid model, HybridGNN, which achieves an accuracy of 95.4%, suggesting that competitive performance can also be achieved by mixing model types.\nFocusing on the key estimation subtask (A-Key) of pitch spelling we notice that the PKSpell model achieves a very good key accuracy of 69.9%, closely followed by the MeasureGNN model and only surpassed by the Hybrid model. We attribute the effectiveness of key detection of a sequential model such as PKSpell to the persistence of the key label across elements of the sequence. Therefore, a hybrid model in this case seems to be able to adapt to\nthe diversity of labels for pitch spelling and uniformity of labels for key estimation. We found our best model to be stochastically dominant over PKSpell with min_\u0454 = 0.17.\nIn the cadence detection task, we evaluate the results using the macro F1 score to account for the overwhelming presence of non-cadence nodes, as instructed by [7]. We observe that GraphSAGE, the previously used technique for training, obtains the lowest F1 score and it is surpassed by all the proposed GNN-based models trained with the new sampling method.\nAmong our GNN models, BeatGNN and HybridGNN achieve the highest scores of 57.4% and 58.6%, respectively, closely followed by MeasureGNN. In this case, the MetricalGNN model surprisingly does not achieve such a good score even though it includes both measure and beat elements. However, it still performs better than the NoteGNN and the GraphSAGE method.\nOverall, the results demonstrate the efficacy of GNN-based models trained using our new sampling method. Incorporating hierarchical elements such as beats and measures improves both pitch spelling and cadence detection tasks. Additionally, the hybrid approach of combining GNNs with sequential models produces promising results."}, {"title": "5. CONCLUSION", "content": "In this paper, we introduced GraphMuse, a framework and Python library for symbolic graph music processing. We designed a specialized sampling process for musical graphs and demonstrated our pipeline's effectiveness through experiments on pitch spelling and cadence detection. Our results show that carefully designed GNN architectures, especially those incorporating hierarchical elements like beats and measures, can lead to better performance. Finally, hybrid models that integrate GNNS with sequential models yield further performance improvements.\nFuture research will focus on refining GNN-based models in music processing, adding more tasks, and exploring novel architectures. This includes investigating advanced graph convolutional blocks, other sampling techniques, and attention mechanisms to enhance model performance."}]}