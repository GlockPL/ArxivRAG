{"title": "Analysis of LLM as a grammatical feature tagger for African American English", "authors": ["Rahul Porwal", "Alice Rozet", "Jotsna Gowda", "Pryce Houck", "Sarah Moeller", "Kevin Tang"], "abstract": "African American English (AAE) presents\nunique challenges in natural language pro-\ncessing (NLP) This research systematically\ncompares the performance of available NLP\nmodels-rule-based, transformer-based, and\nlarge language models (LLMs)-capable of\nidentifying key grammatical features of AAE,\nnamely Habitual Be and Multiple Negation.\nThese features were selected for their distinct\ngrammatical complexity and frequency of oc-\ncurrence. The evaluation involved sentence-\nlevel binary classification tasks, using both\nzero-shot and few-shot strategies. The anal-\nsis reveals that while LLMs show promise\ncompared to the baseline, they are influenced\nby biases such as recency and unrelated fea-\ntures in the text such as formality. This study\nhighlights the necessity for improved model\ntraining and architectural adjustments to better\naccommodate AAE's unique linguistic charac-\nteristics. Data and code are available.", "sections": [{"title": "1 Introduction", "content": "African American English (AAE) is a low-resource\nlanguage, facing the challenge of inadequate train-\ning data for natural language processing (NLP)\n(Blodgett et al., 2018; Luca and Streiter, 2003).\nWhile efforts have shown promise in improving\nNLP performance on AAE (Dacon, 2022; Masis\net al., 2023), progress is limited. Consequently,\nAAE lacks access to the same host of language-\nspecific tools available to varieties such as Main-\nstream American English (MAE). With the increas-\ning use of large language models (LLM) to per-\nform annotation tasks, studies found that LLMs\nperforms well for high-resource languages such as\nEnglish but the performance drops for non-English\nlanguages (Jadhav et al., 2024; Pavlovic and Poesio,\n2024). This raises the question of whether LLMs\nwould be able to handle AAE, a variety of English\nthat is low-resource.\nThis paper evaluates the ability of different NLP\nsystems to recognize distinctive AAE grammat-\nical features, comparing a rule-based model, a\ntransformer-based model, and LLM on the same\ntasks, specifically tagging distinctive AAE gram-\nmatical features. It compares LLM zero- or few-\nshot classification. Data and code are available.\u00b9\nThe systems are evaluated on two distinctive\nAAE features as a test case: Habitual Be and Mul-\ntiple Negation. Habitual Be is relatively rare and\ndifficult to model while Multiple Negation is preva-\nlent in AAE and occurs across various non-standard\nEnglish dialects. These features provide differ-\nent frequency of occurrence, extremity in terms\nof grammatical complexity, and possible prior ex-\nposure by LLMs. Furthermore, Habitual Be and\nMultiple Negation is found in 27% and 81% of\nEnglish varieties, respectively.\u00b2\nThis work poses these questions:\n\u2022 How LLMs compare to rule-based models or\ntrained-from-scratch Transformer models at\nidentifying AAE grammatical features?\n\u2022 How does recency or order of examples influ-\nence LLM performance?\n\u2022 How do factors of transcribed spoken lan-\nguage influence LLM performance at iden-\ntification of AAE?"}, {"title": "2 Related Work", "content": "NLP research for AAE have explored social media\nuse (Blodgett et al., 2018), POS-tagging (Dacon,\n2022; J\u00f8rgensen et al., 2016), hate speech classifi-\ncation (Harris et al., 2022; Sap et al., 2019), ASR\n(Koenecke et al., 2020; Martin and Tang, 2020), di-\nalectal analysis (Blodgett et al., 2016; Dacon, 2022;\nStewart, 2014) and feature detection (Masis et al.,\n2022; Santiago et al., 2022; Previlon et al., 2024)."}, {"title": "3 AAE Grammatical Features", "content": "Our work focuses on two morphosyntactic features\nthat characterize AAE and distinguish it from MAE.\nThe features provide extremity in terms of gram-\nmatical complexity and possible prior exposure by\nLLMs. Multiple Negation is prevalent in our AAE\ndataset and its occurrences are uniform enough to\ncaptured with a rule-based model. Habitual Be is\ncomparatively rare. Its complexity requires a com-\nbined rule-based and probabilistic baseline from\nprevious work (Santiago et al., 2022; Moeller et al.,\n2024; Previlon et al., 2024)."}, {"title": "3.1 Habitual Be", "content": "Although relatively infrequent, habitual be is em-\nployed regularly by AAE speakers (Blodgett et al.,\n2016) as well as speakers of 90 other Englishes\n(Kortmann, 2020). It is an aspectual marker denot-\ning a recurring, or habitual, action (Green, 2002;\nFasold, 1969). In contrast to other instances of\n\"be\", the habitual be is never changes form. As\nshown in the MAE sentence below, non-habitual\n\"be\" must agree with \"I\" resulting in \u201cI am\" rather\nthan \"I be\". Additionally, the adverb \"usually\" in\nindicates the event is recurring. Habitual Be, as in\nthe AAE exmaple, does not require the adverb to\nspecify habituality.\nAAE: I be in my office by 7:30.\nMAE: I am usually in my office by 7:30."}, {"title": "3.2 Multiple negation", "content": "Multiple Negation, or Double Negative or Nega-\ntive Concord, is characterized by multiple negative\nwords such that each negator confirms an overall\nnegative meaning of a single linguistic constituent\nas in the AAE example below. This contrasts to \u201cI\ndidn't ask you not to come\" where each negative\nword belongs to, and negates, a different clausal\nconstituent. Multiple Negation was used in Old\nEnglish (Kallel, 2011) and is today a recognized\nfeature of several English varieties but is absent\nfrom MAE (Mart\u00ednez, 2003), as shown below.\nAAE: I ain't step on no dog.\nMAE: 'I didn't step on a dog.'"}, {"title": "4 Data & Corpus", "content": "All data used for the training, testing, and analy-\nsis of the included models was transcribed, tagged,\nand annotated for AAE features by hand from texts\nin the Joel Buchanan Archive,\u00b3 a collection of oral\nhistories gathered primarily from African Ameri-\ncans, or in The Corpus of Regional African Ameri-\ncan Language (CORAAL) (Kendall and Farrington,\n2021). Each example is sourced from an interview\nwith an AAE speaker and contains a key compo-\nnent of the grammatical feature, i.e. 'be' for habit-\nual be and at least one instance of a negative word\n(i.e. not, never, etc.) for multiple negation. For\nsimplicity sake, Non/Habitual Be examples were\nlimited to sentences with a single \u201cbe\u201d.\nSentences in the the databases are marked by\nhumans for the presence of AAE grammatical or\nphonological features. For example, if a sentence\ncontains a habitual \u201cbe\u201d, its line is tagged with a\n'1' in a column corresponding to the feature, other-\nwise '0'. All annotators had to qualify after train-\ning in recognition of AAE linguistic features with\na high level of accuracy. For detailed annotation\nguidelines and training materials, see Moeller et al.\n(2025). Each transcribed interview is annotated\nby at least one annotator, and through the tagger\nand model creation process, the annotations of sen-\ntences used for data input or analysis are reviewed\nfor accuracy. The labels assigned by human anno-\ntators are treated as gold standard when analyzing\nthe performance of the models.\nTraining/testing sets are generated for individ-\nual grammatical features. Using sentences from\nannotated interviews, datasets are created with a\npredetermined ratio of \u2018positive examples' that con-\ntain the grammatical feature, to negative examples,\nwhich do not. This guarantees that the models we\nbuild do not experience an increase in perceived ac-\ncuracy from their ability to word search but rather\ncan truly distinguish AAE from MAE."}, {"title": "5 Model architecture and configurations", "content": "We compared two LLMs, one Transformer model,\nand one rule-based model. The task was set up as\nbinary classification on sentences such that each\nmodel tags a given sentence as either positive or\nnegative for a specific AAE feature of interest. For\nthe sentence-level binary classification tasks, each\ntask involved analyzing, training, or prompting\nthese models on batches of sentences, which were\nprocessed with a consistent prompt format in the\nLLMs."}, {"title": "5.1 Large Language Models", "content": "The language models used in this study were cho-\nsen based on their suitability for sentence-level\nbinary classification tasks, given the context and\nparameter constraints. Each model was config-\nured with a consistent set of hyperparameters and\nprompt structures to enable a fair evaluation of their\nperformance across various sentence structures.\nOpenAI \u2013 GPT. OpenAI's gpt-40-mini model,\na compact language model containing approxi-\nmately 8 billion parameters, was accessed through\nthe OpenAI REST API with a configuration set\nto a temperature of 0.7 and a top-p value of 0.9,\nproviding a balance between response coherence\nand variability.\nMeta - LLaMA Meta's LLAMA 3-8B-Instruct\nhas a similar architecture and parameter size (8\nbillion parameters) to OpenAI's gpt-4o-mini.\nThe LLAMA model was accessed through the\nHuggingface transformers library executed us-\ning PyTorch v12.4 with NVIDIA CUDA support.\nThe experimental settings, including temperature\n(0.7) and top-p (0.9), were set identical to those\nused for gpt-40-mini to maintain consistency in\nresponse characteristics."}, {"title": "5.2 Baselines", "content": "We compared the LLMs models previously built to\nidentify specific AAE grammatical features. The\nHabitual Be baseline is a Transformer model based\non the work in Previlon et al. (2024). The inputs\nto the model include n-grams windows around \"be\"\nalong with predictions of the feature's presence\nbased on part of speech (POS) windows and con-\ntextual syntactic structures. Since training data was\nlimited, we averaged results across a 10-fold cross\nvalidation and augmented the dataset. Approxi-\nmately 3,500 more Habitual Be sentences with the"}, {"title": "6 Prompt Design", "content": "In LLMs such as GPT4o, prompt design plays a\ncrucial role. Prompt length and structure can im-\npact the responses generated, making it important\nto optimize prompt formulation for specific tasks.\nWe analyzed variations in prompt instructions.\nThe same input phrased differently can result\nin outputs of varying lengths and formats. For\ninstance, a prompt like:\n\"Classify the sentence '{sentence}' as 'habitual\nbe' or 'non-habitual be' in one word:\"\nresults in the desired concise response which con-\ntains only the classification label. Without specify-\ning the \"in one word\" constraint, a prompt like:\n\"Classify the sentence '{sentence}' as 'habitual\nbe' or 'non-habitual be':\"\noften leads to the model adding unstructured text\nsuch as \"This sentence uses 'be' in a\nhabitual sense because it describes a\nrepeated action\". This behavior arises because\nthe absence of strict word count or formatting in-\nstructions leaves the model room to interpret the"}, {"title": "7 LLM Compared to Baselines", "content": "To answer our first question regarding the perfor-\nmance of LLMs on AAE features compared to\nolder models, we compare each baseline model to\nthe two LLMs, using the classification report from\nsklearn (Pedregosa et al., 2011). We chose F1-\nscore weighted by class size as our primary metric\nfor evaluation as opposed to accuracy due to the\nimbalanced class sizes.\nWe found that zero and few shot LLM models\nperformed worse compared to the baselines on both\ntask. It underperformed the Habitual Be baseline\nrecall by about -0.02 and overall F\u2081-score by -0.18.\nCompared to our multiple negation baseline tagger,"}, {"title": "7.1 Results of Baselines", "content": "These are the results against which we evaluated\nthe LLM models.\nResults of Habitual Be Baseline The Habitual\nBe baseline model was evaluated as an average of\nthe overall F\u2081-score of the 10 folds. The model re-\nturned, on average, a 0.88 recall and a 0.92 overall\nF\u2081-score on the habitual class.\nResults of Multiple Negation Baseline The Mul-\ntiple Negation baseline model achieved a recall of\n1.00 and a 0.99 overall F\u2081-score. This means that\nall sentences containing multiple negation were\ncorrectly classified. Only one non-feature sentence\nwas tagged incorrectly."}, {"title": "7.2 Results of Large Language Models", "content": "The LLM models results with zero shot and few\nshot prompting strategies are shown in Table 2. In\nthe table, the '+' class indicates presence of the\nfeature and '-' indicates absence of the feature.\nOverall, the GPT model performed better than\nLLAMA both in terms of memory constraints and rate\nlimit as well as quality of detection, compared to\nthe LLAMA model. It seems evident that the LLAMA\nmodel has not been trained on a lot of data from\nAfrican American English. Showing it a few ex-\namples helped the performance immensely. This"}, {"title": "7.2.1 Habitual Be", "content": "For Habitual Be, the GPT model performance for\nzero-shot prompting was quite poor compared to\nfew shot, particularly when we compare between\nboth prompting styles the numbers for the feature\n(habitual) class recall, that is, how many true Ha-\nbitual Be samples the LLM was able to capture.\nThis can be attributed to the complex and nuanced\nnature of Habitual Be. The increase in performance\nof the GPT model from zero to few shot prompt-\ning can also be primarily attributed to the increase\nin recall of the habitual class. We speculate that\nwhen the LLM is exposed to a few examples, it\ndevelops a better understanding of what syntactic\nstructure to look for in order to detect Habitual\nBe. In the case of the GPT model, the precision\nstays almost the same. Meanwhile, the recall of\nthe non-habitual class decreases. It is possible that\nwith prompting, the model may be more biased to-\nwards detecting that a sentence contains a habitual\nbe feature, leading to both higher habitual recall\nand lower non-habitual recall.\nThe performance with the LLAMA model could\nnot be computed on all the 7,739 samples due\nto memory constraints and rate limits. So we\nperformed the experiment with a reduced total\ndataset of 1,000 samples (430 habitual and 570\nnon-Habitual). We utilized a similar 10 fold data\nsplit as the GPT model but because the number\nof samples for each fold was lower, we decided\nto generate a combined classification report for all\nthe 1000 samples. The LLAMA model is unable to\ndetects Habitual Be poorly unless being nudged by\na few examples."}, {"title": "7.2.2 Multiple Negation", "content": "For the multiple negation model, we tested the per-\nformance of the GPT model on a dataset containing\n198 samples, out of which 162 contain Multiple\nNegation and the remaining 36 do not. On GPT,\nthe zero-shot prompting produced better results\ncompared to few shot. This performance difference\nis prominent when we look at the dip in precision\nscores for both the feature (multiple negation) and\nnon-feature (not multiple negation) class. The high\nrecall and low precision of the LLM is likely be-\ncause the LLMs are biased towards predicting a\nsentence has multiple negation if there are two or\nmore negative words in a sentence. Multiple Nega-\ntion is a simpler feature to detect, requiring only\nthat there are two negators within a single clause.\nIt is possible, albeit with less accuracy, to iden-\ntify Multiple Negation with high likelihood based\nsolely on the number of negative words the LLM\nsees in a sentence. This may be one reason the\nmodel tends to have a higher recall and lower preci-\nsion. This nuance whether any two negative words\nin the same sentence are not also in the same clause,\ncan easily be overlooked, leading to sentences be-\ning mistakenly classified as having the feature. The\nprecision score falls further with few shot prompt-\ning, likely due to the model overfitting to the few\nextra samples that it learns in the prompt. For a\nsimple-to-detect feature with nuanced underlying\ngrammatical structure, like multiple negation, it\nmay be counterproductive to feed the LLM more\nexamples.\nWe also tested the performance of LLAMA model\nfor multiple negation with the same dataset of 198\nsamples. The LLAMA model performed poorly com-\npared to GPT overall, but its precision for the fea-\nture class is much higher than the GPT model. This\nappears to due more to the model's bias towards\npredicting that the sentences do not contain mul-\ntiple negation. The lower recall for LLAMA can be\nattributed to the much smaller training dataset com-\npared to GPT. We notice a similar trend with LLaMA\nfor Multiple Negation that we saw with GPT-that\nperformance with zero shot is better than few shot."}, {"title": "8 Potential LLM Biases", "content": "To understand the cause for the bias towards pre-\ndicting the presence of an AAE feature and to an-\nswer our last three questions, we analyzed the LLM\npredictions and saw three major factors influencing\nthem."}, {"title": "8.1 Hypothesis 1: Recency Bias", "content": "8.1.1 Methodology\nRecency bias in the LLMs' predictions was as-\nsessed using logistic regression fitted using Maxi-\nmum Likelihood Estimation on aforementioned ex-\nperiments, where the relevant input sentences were\npresented to the LLM in a random order without\nprobing for any specific error. The regression was\nconducted using the Python packages \u2018statsmod-\nels', 'numpy', and 'pandas'. The dependent vari-\nable is the model prediction (presence or absent of\na feature). The independent variable of interest is\nthe presence of a recency bias. It is operationalised\nas the proportion of the predicted values of the last\nfive samples (N_5,...N_1) that match the predicted\nvalue of the given sample (N). The recency bias\ncan either positively or negatively affect the predic-\ntion. A positive effect indicates the model prefers\nusing recently predicted values, while a negative\neffect indicates the model avoids using recently\npredicted values. Ground truths were treated as an\nadditional independent variable to control for the\nexpected performance of the model, since the pre-\ndicted values are expected to positively correlate\nwith the ground truth."}, {"title": "8.1.2 Analysis: Zero-shot Prompting", "content": "The logistic regression analysis reveals whether the\nrecency bias has an effect on sentence classifica-\ntion of two AAE features under each prompting\nparadigm. The regression summaries can be found\nin Table 3.\nHabitual Be detection with GPT The regres-\nsion analysis reveal that the \u03b2 for recency bias to be\n-0.21 and it is not statistically significant (p-value =\n0.42). This indicates that, in the zero-shot setting,\nrecency bias does not have a meaningful impact on"}, {"title": "8.1.3 Additional analysis: Few-Shot\nprompting", "content": "Habitual Be detection with GPT In contrast,\nthe few-shot prompting results indicate a significant\nnegative impact of recency bias on prediction accu-\nracy (\u03b2 = -1.03, p-value = 0.003). This substantial\neffect suggests that the few-shot model is consid-\nerably influenced by the timing and sequence of\ninput data, potentially leading to biased predictions\nbased on recent but not necessarily representative\nsamples. The true label in this scenario also ex-\nhibits a strong positive influence (\u03b2 = 3.42, p-value\n< 0.001), reinforcing the label's dominant role in\ndriving predictions. With a higher Pseudo R2 of\n0.33, the few-shot model demonstrates a better fit\nthan the zero-shot model.\nMultiple Negation detection with GPT In the\nfew-shot prompting scenario for the Multiple Nega-\ntion feature, the analysis presents an even more\npronounced negative impact of recency bias (\u03b2 =\n-12.35). This stronger negative effect could be at-\ntributed to the few-shot model's reliance on a lim-\nited number of examples, which may accentuate\nthe influence of recent inputs, thereby skewing pre-\ndiction outcomes significantly. The presence of a\nlower, yet still positive, coefficient for the ground\ntruth variable (\u03b2 = 4.13) underscores a consistent\ntrend where the intrinsic attributes of labels influ-\nence model predictions, but the effect of recency\nbias remains a dominant factor, adversely affecting\nprediction accuracy."}, {"title": "Few-Shot Prompting with LLAMA", "content": "Some addi-\ntional testing examined the relationship between\nLLAMA's strong recency bias and the examples pro-\nvided in few-shot testing more closely. A set of ten\nprompts were chosen that the LLM failed on pre-\nvious experiments, five with true labels '0' and\nfive with true labels '1'. First, these were pre-\nsented in alternating order, then with all consec-\nutive 1-labeled sentences followed by all 0-labeled\nsentences, and finally with this ordering reversed.\nThese two experiments were run again with the\nbatch size increased to 30. Each of these four tests\nwere run six separate times with the same set of ex-\namples ordered differently to measure if the order\nof provided samples impacted recency bias. Over-\nall, few-shot prompting demonstrated more sensi-\ntivity to recency in provided examples than sen-\ntence history, while still being much more accurate\nthan zero-shot counterparts even when negatively\nimpacted. The ordering of example sentences had a\nsubstantial impact on prediction accuracy while the\nordering of input sentences largely did not, further\nsuggesting that text within the most recently pro-\ncessed five to ten sentences have a strong impact on\nLLAMA's predictions when the criteria for a given\nfeature's presence is not clear."}, {"title": "8.2 Hypothesis 2: Formality bias", "content": "Our second hypothesis is that the LLM models\nare hyper-sensitive to deviations from formal writ-\nten texts with the according sentence structure and\nstyle. Therefore, they flag excessive or unusual\npunctuation, missing subjects, or run on sentences\nas AAE features.\nWe define 'excessive or unusual' as any repeti-\ntive or unnecessary punctuation that leads to syn-\ntactic errors or sentence disjunction. We defined\n'run-on sentences' as either overly long sentences\nwithout standard punctuation or multiple disjointed\nthoughts connected via punctuation.\nExample: \"And so they had really- you know;\nmiddle-class- they hadn't encountered any\nreal racism.\"\nExample: \"And so that made me really feel\ngood because you did not have to do this and\nI thought it was the greatest gesture that you\ncould have come and share this information\nwith us of how to move forward and I don't\nknow if Florida would have done that even\nthough I just don't if they would have taken\nthe time to do that.\"\nIn the first example above, the speaker makes\nfalse starts and switches between multiple trains\nof thought, leading to a disjointed sentence. The\nsentence is not particularly long, but the phrasing\nand intention is repeatedly broken up, making it\nmore difficult for a model to process and identify\ngrammatical features. This arises from accurately\ntranscribed spoken language. In the second exam-\nple, the sentence is excessively long and run-on,\nwith pronouns referring to entities that are several\nclauses back. Similar to the first example, it shows\npeople's natural conversation process. This makes\nthe data, which is sourced from interview transcrip-\ntions, more difficult to understand and analyze."}, {"title": "8.2.1 Methodology", "content": "Similarly to Section 8.1.1, we employed a logistic\nregression analysis. The dependent variable is the\npredicted value of the models. To examine the hy-\npothesis, the variable of interest is the presence of a\ndeviation from formal written text. Each sentence\nwas manually tagged as '1' if it contained excessive\nor unusual punctuation, missing subjects, or run-on\nsentences, and as '0' if it did not. Ground truths are\nwhether the habitual be or multiple negation fea-\ntures were actually present, were treated as control\nvariables in the regression. Due to the size of the\nHabitual Be dataset, only fold 2 was tested in this\nhypothesis. It is a fair representation of the entire\nHabitual Be dataset because it yielded the median\nk-fold results from the zero-shot GPT model."}, {"title": "8.2.2 Analysis", "content": "The logistic regression summaries can be found in\nTable 5. Unsurprisingly, the ground truth variable\nhas a positive and significant effect in all four mod-\nels. Turning to the bias variable, the GPT model\nwith zero-shot prompting does not suffer from a"}, {"title": "9 Conclusion", "content": "Large Language Models (LLMs) continue to show\npromise in automating feature annotation tasks, yet\nsignificant challenges remain, particularly when it\ncomes to language varieties with complex gram-\nmatical features that are not represented in stan-\ndard written conventions, such as the Habitual Be\nin African American English (AAE). The main\ncontributions of our work are:\n\u2022 Rule-based and Transformer-based models of\nAAE grammatical features outperform zero-\nand few-shot LLMs.\n\u2022 LLMs recognition of AAE is influenced by re-\ncency and unrelated features of non-standard\nwritten conventions.\n\u2022 We release a Multiple Negation tagger that\noutperforms LLMs for AAE.\nWe found that, surprisingly, the few-shot ap-\nproach did not always performed better. It per-\nformed worse than the zero-shot approach for Mul-\ntiple Negation, but better for Habitual Be. We\nconclude the choice between employing zero-shot\nand few-shot approaches for classification should\nbe influenced by the complexity of the feature per-\nhaps more than the extent to which relevant data is\nrepresented in the LLM's pre-training corpus.\nOur baseline transformer model currently outper-\nforms LLMs in detecting the Habitual Be, but sev-\neral strategies might enhance LLM performance,\nespecially in light of the hypotheses we have ex-\nplored. One approach is to mitigate recency bias, a\nknown issue in LLMs, by interleaving or randomiz-\ning the order of sentences presented for prediction,\nwhich can otherwise skew results. Additionally,\npre-processing the input data to remove or correct\nextraneous punctuation and properly segmenting\ndisjointed sentences may help minimize noise and\nerrors when working with something other than\nmainstream English or transcribed oral speech.\nOur findings provide valuable insights into the\npotential and limitations of LLMs for AAE. The\nresults underscore the need for further experimenta-\ntion to assess LLM performance on other linguistic\nfeatures specific to AAE and transcribed speech.\nAdditionally, exploring how multiple AAE features\nwithin a sentence influences the accuracy of LLM\npredictions could offer a deeper understanding and\nlead to more robust work on non-standard language\nvarieties in NLP.\nRegarding how these findings could influence\nthe deployment of NLP applications where AAE\nis spoken, we note that inadequate training of a\nmodel to accurately process African American En-\nglish can result in misrepresentation or difficulty\nin understanding the speaker's intended message.\nThis may arise from either incoherent transcription\noutputs or the model's attempt to convert AAE into\nMainstream American English (MAE), which can\nlead to significant errors if the model lacks suffi-\ncient training to recognize and handle AAE effec-\ntively. Furthermore, an indirect benefit of making\nAAE-specific annotations more available would be\nthe development of LLMs trained to treat AAE as\na distinct language or dialect, thereby contributing\nto its preservation and recognition as a linguistic\nstandard in its own right."}, {"title": "Limitations", "content": "We only gathered transcribed spoken speech data\nfor this experiment. We could have looked at more\nsources like written texts and speeches from re-"}, {"title": "Ethical considerations", "content": "The involved university does not require IRB ap-\nproval for this kind of study, which uses publicly\navailable data.\nThe materials are used in accordance with\nSPOHP's guidelines for academic research and\neducational purposes. Proper credit is given to\nthe program for the original data sources, and\nthe use of these materials complies with the pro-\ngram's policies on non-commercial, educational,\nand research use. This research uses data from\nthe CORAAL, which is licensed under a Creative\nCommons Attribution-NonCommercial 4.0 Inter-\nnational License (CC BY-NC 4.0). The dataset is\nused for non-commercial academic research, with\nproper attribution given to the creators. All usage\ncomplies with the terms outlined in the license,\nensuring that the data is used for educational and\nresearch purposes only.\nThe GPT model used in this research were\naccessed through OpenAI's platform following\nOpenAI's terms of service and usage policies.\nThe LLaMA models were used under the non-\ncommercial research license provided by Meta, en-\nsuring compliance with the restrictions specified in\nthe LLaMA License Agreement. The models were\nused solely for academic research purposes.\nWe do not see any other concrete risks concern-\ning use of our research results. Of course, in the\nlong run, any research results on AI methods based\non large language models could potentially be used\nin contexts of harmful and unsafe applications of\nAI. It is possible that feature tagging of a language\nof specific group of people could be used to iden-\ntify the demographics of the individuals who use\nAfrican American English.\nWe recognized the ethical and environmental\nimpact of the carbon footprint associated with using\nLLMs. Our findings show that LLM indeed might\nnot be suitable for solving even a simple tagging\ntask. This result will encourage future researchers\nto rethink whether LLM can be helpful, considering\nperformance and the chance of generating carbon\nfootprint."}, {"title": "Contribution statement", "content": "SM and KT are the senior and corresponding au-\nthors. We follow the CRediT taxonomy5. Concep-\ntualization: SM, KT; Data curation: RP, AR, JG,\nPH; Formal Analysis: KT, SM; Funding acquisi-\ntion: SM, KT; Investigation: SM, KT; Methodol-\nogy: RP, AR, JG, PH, SM, KT; Project administra-\ntion: RP; Resources: SM; Software: RP, AR, JG,\nPH; Supervision: SM, KT; Validation: RP, AR, JG,\nPH; and Writing \u2013 original draft: RP, AR, JG, PH,\nSM, KT and Writing \u2013 review & editing: AR, PH,\nSM, KT."}]}