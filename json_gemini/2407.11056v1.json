{"title": "Industrial-Grade Time-Dependent Counterfactual Root Cause Analysis through\nthe Unanticipated Point of Incipient Failure: a Proof of Concept", "authors": ["Alexandre Trilla", "Rajesh Rajendran", "Ossee Yiboe", "Quentin Possama\u00ef", "Nenad Mijatovic", "Jordi Vitri\u00e0"], "abstract": "This paper describes the development of a counter-factual Root Cause Analysis diagnosis approach\nfor an industrial multivariate time series environment. It drives the attention toward the Point of\nIncipient Failure, which is the moment in time when the anomalous behavior is first observed, and\nwhere the root cause is assumed to be found before the issue propagates. The paper presents the ele-mentary but essential concepts of the solution and illustrates them experimentally on a simulated set-ting. Finally, it discusses avenues of improvement for the maturity of the causal technology to meet\nthe robustness challenges of increasingly complex environments in the industry.", "sections": [{"title": "1 INTRODUCTION", "content": "The degradation of complex industrial assets is a multi-faceted problem that can be explained by different factors.\nFor instance, in the Reliability Engineering field, assets are\nmost expected to fail either prematurely (early) during their\nbreak-in period, or late by the end of their remaining use-ful life (wear-out) [Dersin, P., 2023]. These failure types\ncan be anticipated because their modes and mechanisms\nare well known. Moreover, their impact can be mitigated\nby introducing quality checks in the manufacturing process\nand inspection actions in their (more-or-less conservative)\npreventive maintenance schedule. However, for as long as\nthe machines operate, failures can randomly appear at any\npoint in time. This is especially challenging for dependable\nassets while they transit the middle region, when the failure\nrate is relatively low, but uniform/constant.\nIn this uncertain setting, the field of Predictive Maintenance\ntackles the problem by introducing the data as a means\nto closely follow the actual degradation of each asset and\nmake better informed and timely decisions [Fink, O., Wang,\nQ., Svens\u00e9n, M., Dersin, P., Lee, W.-J., and Ducoffe, M.,\n2020]. In this sense, the detection of anomalous behaviors\nand the capacity to diagnose their root causes become in-creasingly important to guarantee the availability of the\nmachines. Since these failures appear abruptly, they cannot\nbe anticipated, and their evolution is not smooth as they\nundergo various stages of severe degradation. What is more,\nthe available operational-service data always comes from\nthe field, and thus it is regarded as observational time series\ndata, where the value of the variables is always determined\nby their causes, not through experimentation.\nThe literature on causal approaches for identifying the root\ncauses dealing with such type of data typically assume that\nthe influences between observed processes change smoothly\nover time, which is introduced as a general confounding\nvariable [Huang, B., Zhang, K., and Sch\u00f6lkopf, B., 2015],\nand modeled probabilistically to logically reason on the\nlikelihood of an event within a certain interval [Van Houdt,\nG., Depaire, B., and Martin, N., 2022]. The most common\napproach, though, is to frame the problem around the topic\nof anomaly detection by modeling the normal operational\nregime. Specifically, Assaad, C. K., Ez-zejjari, I., and Zan,\nL. [2023] develop a summary graph and apply a decomposi-tion into abstract causal relations, Budhathoki, K., Minorics,\nL., Blobaum, P., and Janzing, D. [2022] assess the con-tribution of each variable to the target outlier score using\ncounterfactuals, Strelnikoff, S., Jammalamadaka, A., and\nLu, T.-C. [2023] develop a flexible neural graph for edge\nattribution, Yang, W., Zhang, K., and Hoi, S. C.H. [2023]\nfocus on abnormal data points that do not follow the regular\ndata-generating process, and for Han, X., Zhang, L., Wu,\nY., and Yuan, S. [2023], anomalies are caused by external\ninterventions on the normal causal mechanism and therefore\nfind the algorithmic recourse via counterfactuals to revert\nthem.\nThis workshop paper exploits the fact that root causes can\nbe found directly from the causal graph and from the time of\nappearance of anomalies [Assaad, C. K., Ez-zejjari, I., and\nZan, L., 2023]. We follow previous works on developing a"}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 ROOT CAUSE ANALYSIS", "content": "Root Cause Analysis (RCA) is a troubleshooting method\nof problem solving used for identifying the root causes of\nfaults or failures [Wilson, P. F., Dell, L. D., and Anderson,\nG. F., 1993]. RCA is a form of deductive inference since it\nrequires an understanding of the underlying causal mech-anisms for the potential root causes and the problem, i.e.,\nwhat is typically found in the context of Predictive Mainte-nance. RCA can be decomposed into four steps:\n1. Identify and describe the problem clearly.\n2. Establish a timeline from the normal situation until the\nfailure finally occurs, through the Point of Incipient\nFailure.\n3. Distinguish between the root cause and other causal\nfactors.\n4. Establish a causal graph between the root cause and\nthe observed problem.\nThe trigger signal of the RCA is given by the failure times-tamp (i.e., the point in time when the failure variable is\nobserved). Then, RCA yields a list of potential root cause\nvariables along with their probabilities, which aligns with\nthe way complex systems fail [Cook, R. I., 2000]. The vari-ables that comprise the data are required to be representative\nenough to help the developers and engineers pinpoint the\nsource of the observed problems through the root causes\nand their effects [Weidl, G., Madsen, A. L., and Dahlquist,\nE., 2008]."}, {"title": "2.2 STRUCTURAL CAUSAL MODEL", "content": "The causal links among the variables X that build the model\nof a system are assumed to be most effectively represented\nusing the tools from the field of Causality. In this sense, the\nStructural Causal Model (SCM) is the framework that can\nmost generally capture such directed associations [Pearl, J.,"}, {"title": "2019]. The SCM defines a set of assignments governing\ntheir specific functional associations f, along with some\nindependent noise N that accounts for everything that is not\nexplicitly included in the model:", "content": "$X_j := f_j(PA_j, N_j)$,\nwhere $PA_j$ represents the direct causes of the $X_j$ variable.\nIf enough knowledge and experience from the field is avail-able from the subject matter experts, i.e., strictly complying\nwith the RCA requirements, then a complete SCM may be\ndeveloped right from the start. However, this is not the typ-ical use-case scenario in complex industrial settings, and\ndata generally needs to be carefully leveraged to drive the\ndevelopment of the causal model."}, {"title": "2.2.1 Causal Discovery", "content": "Whenever the structure of the model is to be inferred from\nthe observed variables, i.e., the Causal Discovery task, as-sumptions need to be made about the data generating pro-cess, constraints need to be applied, and usually the statis-tical methods of the algorithms yield different graphs that\nexplain the same factual data [Glymour, C., Zhang, K., and\nSpirtes, P., 2019].\nIn a multivariate environment, the most straightforward ap-proach is led by the so-called \"constraint-based\" discovery\nmethods. These traditional approaches iteratively build the\ncausal graph by utilizing a score such as the p-value of\nconditional independence tests. As a general technique, the\nPeter-Clark (PC) algorithm is described [Spirtes, P., Gly-mour, C., and Scheines, R., 2001]. PC is a causal network\nstructure learning algorithm that copes well with high di-mensionality and can often also identify the direction of\ncontemporaneous links [Runge, J., Bathiany, S., Bollt, E. et\nal., 2019]. It is consistent under i.i.d. sampling assuming\nno latent confounders, i.e., all relevant variables need to\nbe observed in the data. Its outcome is a Markov Equiva-lence Class, and thus it is likely to have different graphical\nrepresentations that explain the same observed data. The\nPC algorithm is especially suited to discover causality in\ncombination with the Fisher-Z independence test because it\nrequires less constraints for the input data [Kobayashi, S.,\nOtomo, K., Fukuda, K., and Esaki, H., 2017]."}, {"title": "2.2.2 Causal Bayesian Network", "content": "Once the structural graph that binds the variables is de-termined, the functional associations of the SCM may be\nlearned, and this work adopts a stochastic interpretation of\nthe world. Therefore, it treats all X as random variables, and\nthe resulting SCM statistically describes their (conditional)\nprobability distributions."}, {"title": "2.3 CAUSAL INFERENCE", "content": "Beyond probabilistic inference, Causal Inference provides\nthe tools that allow estimating causal conclusions even in\nthe absence of a true experiment, given that certain assump-tions are fulfilled. These assumptions increase in strength\nas is defined in Pearl's Causal Hierarchy (PCH) abstrac-tion [Bareinboim, E., Correa, J. D., Ibeling, D., and Icard,\nT., 2022], which is summarized as follows."}, {"title": "2.3.1 PCH Rung 1: Associational", "content": "Describes the observational distribution of the factual data\nthrough their joint probability function P(X). From this\npoint forward, interesting quantities, i.e., the queries XQ,\ncan be directly computed given some evidence XE, through\ntheir conditional probability:\n$P(X_Q|X_E) = \\frac{P(X_Q, X_E)}{P(X_E)}$\nThis level of analysis displays a degree sophistication akin\nto classical (un)supervised Machine Learning techniques.\nAs such, it is subject to confounding bias."}, {"title": "2.3.2 PCH Rung 2: Interventional", "content": "Describes an actionable distribution, which endows causal\ninformation at the population level. This level of analysis\ncan be achieved through actual experimentation via Ran-domized Control Trials, or through statistical adjustments\nthat smartly combine observed conditional probabilities to\nreduce spurious associations in the estimation. Pearl's do-calculus is likely to be the most effective approach to de-termine the identifiability of causal effects by applying the\nfollowing three rules: 1) insertion/deletion of observations,\n2) action/observation exchange, and 3) insertion/deletion of\nactions [Pearl, J., 2012]."}, {"title": "2.3.3 PCH Rung 3: Counterfactual", "content": "Describes a potential distribution at the individual level\ndriven by hypothetical speculations over data that may con-tradict the facts. Conducting this estimation requires the\nfollowing three steps [Pearl, J., Glymour, M., and Jewell, N.\nP., 2016]:\n1. Abduction: Beliefs about the world are initially up-dated by taking into account all the evidence E given in\nthe context. Formally, the exogenous noise probability\ndistributions P(U) are updated to P(U|E).\n2. Action: Interventions are then conducted to reflect the\ncounterfactual assumptions, and a new causal model is\nthus created.\n3. Prediction: Finally, counterfactual reasoning occurs\nover the new model using the updated knowledge."}, {"title": "3 METHOD", "content": "Since the applied industrial environment belongs to the\narea of Predictive Maintenance, the observation of a com-mon development standard such as the ISO 13374 is rec-ommended [ISO, 2003]. This specification breaks down the\ncomplexity of a problem into small modules that may be de-veloped in isolation, thus increasing the chances of project\nsuccess while improving the interpretability and explain-ability of the technical solution, and also help to reduce the\ntechnical debt. This section describes the Data Manipula-tion, State Detection, and Health Assessment processing\nblocks."}, {"title": "3.1 DATA MANIPULATION", "content": "Causality is an emergent property of complex industrial\nsystems [Yuan, B., Zhang, J., et al., 2024]. In this setting,\nevent variables constitute high level, nominal, time-stamped,\nqualitative data records that group functions into categories\nand hierarchies. In fact, the causal relation is a relation\namong events (not properties or states) [Bunge, M., 2009].\nTo preprocess these collected event logs [Van Houdt, G.,\nDepaire, B., and Martin, N., 2022], a message template\nextractor is typically used [Chuah, E., Kuo, S.-h., et al.,\n2010]."}, {"title": "3.1.1 Event Transformation", "content": "To progress with their analysis, the event variables need to\nbe standardized into a time-series format through a trans-formation [Hu, X., Eklund, N., and Goebel, K., 2007]. A\ncommon approach is to utilize a counting function, which\nadds up the number of logged messages within a given time-slot, therefore yielding an integer-valued representation for\nall the variables. Other details such as the sampling rate"}, {"title": "3.1.2 Relevance Filter", "content": "Since the event-variable space may be large at this stage, it\nis advised to reduce it by filtering the relevant variables only.\nIn this sense, the proposed data strategy consists of first\nusing a robust measure of Mutual Information between any\ntwo variables [Reshef, Y. A., Reshef, D. N., Finucane, H. K.,\nSabeti, P. C., and Mitzenmacher, M., 2016], then discarding\nthe non-significant variable relationships via independence\ntesting, and finally ranking the remaining variables. At last,\nit is also advised to remove periodic events such as timers\nthat are unrelated to troubleshooting, e.g., using Fourier anal-ysis and regressions [Kobayashi, S., Otomo, K., Fukuda, K.,\nand Esaki, H., 2017]. As a result, a collection of signifi-cant integer-valued time series variables representing the\nevolution of event counts is obtained."}, {"title": "3.2 STATE DETECTION", "content": "This module builds the data-driven SCM and conducts a\ncoarse-grained diagnosis by determining if the asset under\ntest shows a normal or abnormal working condition. How-ever, if the resolution is not adequate in the sampled data, the\ncausal precedence may not be observed, leading to cycles\nand unobserved confounding. Therefore, what makes this\napproach especially suited for dynamic data is the explicit\nconsideration of time in the causal model, which is espe-cially required to break cycles and resolve race conditions."}, {"title": "3.2.1 Structure Learning", "content": "The proposed approach initially infers the causal relations\nfrom observational time series event data. Nevertheless, no\nfamily or method for causal discovery in time series stands\nout in all situations with different characteristics [Assaad,\nC. K., Devijver, E., and Gaussier, E., 2022].\nAn initial baseline is obtained with the PC algorithm (using\nthe Fisher-Z independence test) on data augmented with\ntime lags. The count-based transformation described in Sec-tion 3.1.1 naturally lends itself to the application of this\ntechnique as long as the counts approximate a Gaussian\ndistribution, which can be asserted using the Lilliefors nor-mality test [Lilliefors, H. W., 1967]."}, {"title": "3.2.2 Dynamic Networks", "content": "What follows is the construction of the probabilistic model\nfrom the learned time-dependent causal structure. This ap-proach is agnostic to any specific (non/linear) parametric\nfunctional relationship, and also provides natural access\nto its inherent uncertainty (even at the individual instance\nlevel).\nIn this sense, the Dynamic CBN (DCBN) yield a factor-ized representation of a stochastic process. They extend the\nstandard causal Bayesian network formalism by providing\nexplicit discrete temporal dimensions. DCBN represent a\nprobability distribution over the possible histories of a time-invariant process; their advantage with respect to classical\nprobabilistic temporal models like a Markov chain is that:\na DCBN is a stochastic transition model factored over a\nnumber of random variables, over which a set of conditional\ndependency assumptions is defined [Bobbio, A., Codetta-Raiteri, D., Montani, S., and Portinale, L., 2008].\nConsidering n time-dependent discrete random variables\n$X_1^t, X_2^t, ..., X_n^t$, a DCBN is essentially their replication over\ntime slices $t - \\triangle$ (creating the so-called discretization steps),\nwith the addition of a set of arcs in the graph representing\nthe transition model, which is defined through the distri-\nbution $P(X_i^t|X_j^{t-\\triangle})$, for all time-related variables i and j.\nArcs connecting nodes at different time-slices ($\\triangle > 0$) are\ncalled interslice edges, while arcs connecting nodes at the\nsame slice ($\\triangle = 0$) are called intraslice edges. The joint\nprobability distribution of the DCBN is shown as follows:\n$P(X) = \\prod_j \\prod_t P (X_j^t|PA_j^{t-\\triangle})$."}, {"title": "3.2.3 Failure Prediction", "content": "The learned DCBN shall be used to estimate the probabil-ity of the Failure variable XF in time PF(t), which is the\nsink node in the model that represents the eventual system\ncrash, given the observed data (i.e., the root causes and their\neffects):\n$P_F(t) = P(X^t_F|PA^t_F)$.\nIdeally, the probability of observing a high count of fail-ure events $X^t_F=H$ should be a monotonically increasing\nfunction (in time) until the moment of system failure."}, {"title": "3.3 HEALTH ASSESSMENT", "content": "This module exploits the probabilistic SCM and conducts a\nfine-grained diagnosis by determining the root cause of the\nobserved anomaly."}, {"title": "3.3.1 Path Finding", "content": "The hypothesis of isolation is a methodological requirement\nof the sciences for research; hence, the useful fiction of the\nisolated \u201ccausal chain\u201d or \u201csingled-out path\" in the structure\nwill work to the extent to which such an isolation takes place,\nand this is often the case in definite respects during limited\nintervals of time. Moreover, since every isolable process is\ncausal, anomalies can emerge solely as a result of external\nperturbations [Bunge, M., 2009].\nConcerning the analysis of a DCBN for RCA, estimating\nthe most likely time-sequence chain of variables for the ob-served anomaly event adds explanatory value in an industrial\nenvironment. In the DCBN, each node represents an event\ncount or state change of a variable, and the arcs represent\ncausal-temporal relationships between the nodes. In this\nsetting, probabilistic temporal logic determines that causes\nand effects are steady state formulas, the properties of which\nhold for the system at a certain point in time [Van Houdt, G.,\nDepaire, B., and Martin, N., 2022], and this allows for each\nformula to be a path formula too where multiple variables\nare involved. Therefore, the causal paths shall be given by\nthe structure of the graph: a search algorithm shall be used\nto traverse it and find all the routes S from the different root\nnodes to the sink Failure node.\nFor the Point of Incipient Failure T, the most likely causal\npath S* that explains the anomaly data can be determined\nafter the exhaustive search among all the potential paths S\nand their respective probabilities:"}, {"title": "$S^* = \\underset{S}{\\text{max}} P(s|s); t = T,$", "content": "where s represents a structural path from a source node to\nthe sink node (i.e., the failure event variable).\nConditioning on the variables not in the path under anal-ysis (3) is important to block spurious associations. This\nis especially relevant in the case of descendants, because\nin the event of an anomaly, the parent/ancestor variables\nare preferred as precedents [Li, M., Li, Z., Yin, K., Nie, X.,\nZhang, W., Sui, K., Pei, D., 2022].\nFinally, in addition to putting the focus on the most expected\nbehavior, one could argue that the root cause may also have\noccurred in the most unexpected/irregular setting [Yang,\nW., Zhang, K., and Hoi, S. C.H., 2023], assuming that the\nmost commonly experienced issues will have already been\nsolved. This alternative perspective may also be covered in\nthe proposed approach by minimizing the path likelihood\nprobability."}, {"title": "3.3.2 Algorithmic Recourse", "content": "So far, the main focus of the analysis has been on the ob-served factual data. However, these data represent only\none of the many potential outcomes the system could have\nexperienced: had things been different, an alternative out-come may have been observed. Algorithmic Recourse ex-plores these counterfactual worlds [Karimi, A.-H., Barthe,\nG., Sch\u00f6lkopf, B., and Valera, I., 2022]. Such environments\nare simulated via inference through (atomic) interventions a\nin time on a specific abnormal instance in order to revert the\nanomaly [Han, X., Zhang, L., Wu, Y., and Yuan, S., 2023],\ni.e., to lower the risk of failure XF. This is expected to help\nin the recognition and understanding of the general root\ncauses that lead to the system failure [Li, M., Li, Z., Yin, K.,\nNie, X., Zhang, W., Sui, K., Pei, D., 2022].\nFormally, the specific retrospective reasoning that these\ncounterfactuals explore on the anomaly, i.e., the Point of\nIncipient Failure at t = T, can be stated as:\n$P(X_F^{t=T} = L|do(X_i^{t=T} = a), X_{i^*}^{t=T}, X_{F^*} = H).$"}, {"title": "4 RESULTS", "content": "This section elaborates on the experimental work. For fur-ther details, the code along with the description of the re-quired software tools is available here.\u00b9"}, {"title": "4.1 SYSTEM DATA DESCRIPTION", "content": "For illustrative purposes, the system considered in this work\nis synthetic. It is comprised of 4 integer-valued time-series\nvariables that could describe a 2-out-of-3 redundant system\nas follows: three full-duplex data channels that exchange\nmessages among the devices X, and three simplex alarm\nchannels from X to Y, which checks that the system is in\ngood working condition, see Figure 1."}, {"title": "4.2 CAUSAL MODEL LEARNING", "content": "The structure of the model is learned with time-dependent\ndiscovery algorithms to deal with the implicit confounding\nissue. Figure 3 shows the ground truth of the time-explicit\ngraph of the system under analysis. In this structure, the\nlagged terms correspond to the channel data, and the con-temporaneous terms correspond to the alarm signal.\nTo statistically train the causal model, a dataset of 100 in-stances is generated, barely over the required minimum\namount of failure examples for the three potential root cause\nvariables Lejeune, M. [2010]. Table 1 charts the causal\ndiscovery performance of PC (stable version, manually aug-mented with time lags) and PC-MCI algorithms over differ-"}, {"title": "4.3 CAUSAL DIAGNOSIS", "content": "Having a model that is able to accurately predict the ob-served alarm level, and therefore, the anomaly at the Point\nof Incipient Failure T before the issue propagates, Table 2\nshows the list of paths that traverse its graph from a source\n(channel) node to the sink (alarm) node, ranked by their\nlikelihood scores. Note how the most likely path explains\nthe observed anomaly at t = T+, immediately after the\nincipient failure has occurred on Channel 1 (this diagno-sis is necessarily reactive since by definition it cannot be\nanticipated).\nFinally, to further assert the blame for the root\ncause, the following counterfactual is evaluated\n$P(Y^{t=T+}|do(X^{t=T+}_1), X^{t=T+}_{1^*},Y^{t=T+}).$ The result-ing estimand shall adjust for the anticausal backdoor path\nintroduced by the $X^{t-1}$ confounder. Figure 4 shows the\nresults for a range of potential alarm outcomes through their\ndistributions. Note how the alarm level would have stayed\nlow had the root cause X\u2081 kept the values it had before\nthe Point of Incipient Failure. Also note how the region\naround those values is the one that displays the least amount\nof uncertainty. In retrospect, the diagram also shows how\nthis one single variable, i.e. the root cause, was sufficient\nto cause the anomaly that would end up with the system\nfailure."}, {"title": "5 DISCUSSION", "content": "Up to this point, the solution presented in this workshop\npaper has described the basic principles of its causal RCA\ntechnology and an initial experimental proof of concept has"}, {"title": "5.1 VALIDATE THE TECHNOLOGY IN A\nRELEVANT ENVIRONMENT (TRL 4-5)", "content": "One first idea could be to improve the learning of the struc-ture of the model. In line with similar constraint-based ap-proaches, the consideration of tiers that heuristically strat-ify groups of variables can be advantageous [Andrews, B.,\nSpirtes, P., and Cooper, G. F., 2020]. Alternatively, score-based approaches, where multiple candidate models are fit\nand checked, can also be explored [Glymour, C., Zhang,\nK., and Spirtes, P., 2019]. Finally, the usage of reductionist\nFunctional Causal Models (FCM) may be especially help-ful. A FCM represents a pairwise (or bivariate) interaction\nof the effect as an analytic function of a direct cause and\nsome unmeasurable noise. Several forms of the FCM have\nbeen shown to be able to produce unique causal directions\nand have received practical applications [Huang, B., Zhang,\nK., and Sch\u00f6lkopf, B., 2015]. In specific scenarios such as\nmultivariate time series, FCM can even improve the perfor-mance of traditional constraint-based approaches [Runge, J.,\nBathiany, S., Bollt, E. et al., 2019]. Additionally, different\nindependence tests can be introduced in the FCM-based\ndiscovery process to tackle heterogeneous data settings.\nSecond, in industrial settings where only the crash event\nat the end of the timeline is available (instead of an evolv-ing alarm signal), a different approach shall be adopted. If"}, {"title": "5.2 DEMONSTRATE THE TECHNOLOGY IN AN\nOPERATIONAL ENVIRONMENT (TRL 6\u20137)", "content": "The next enhancement idea has to do with the processing\nof real-world data, and while they may come from the lab\n(perhaps also using an accelerated degradation testing pro-cedure), what is actually required are data from the field.\nHowever, operational data often suffer from imbalance is-sues, especially showing a shortage of failure instances. In\nthis case, probably the most sensible way forward is to\nadopt causal approaches that initially tackle the detection\nof anomalies, in line with the standard pipeline of Predic-tive Maintenance, including point, contextual, and collective\nirregularities. Causality-based anomaly detection methods\nprovide at least two significant theoretical benefits over\npurely statistical methods: 1) improved robustness to non-anomalous out-of-distribution data, which implies a reduc-tion in false-alarms, and 2) a potential for failure localization\ndue to the topological ordering of the causal graph [Strel-nikoff, S., Jammalamadaka, A., and Lu, T.-C., 2023].\nWhat is potentially weak in the current state of the art in\ncausal RCA is the specific assessment of heteroskedasticity.\nThe causal relationships are stationary unless an anomaly oc-curs [Yang, W., Zhang, K., and Hoi, S. C.H., 2023]. Anoma-lous data are non-stationary, and this violates one of the\nfundamental assumptions of time series models. Therefore,\na stronger emphasis on preprocessing transformations may\nbe necessary. Additionally, the case of time-varying expo-sure in the presence of time-varying confounders requires\nspecial attention [Hern\u00e1n, M. A., and Robins, J. M., 2023].\nFinally, it would also be interesting to relax the assumption\nthat failures can only occur through the path of the root\ncause, and explore the impact of direct and indirect effects.\nIn this case, mediation analysis is a specific application of\ncounterfactuals that seeks to identify and explain the mech-"}, {"title": "6 CONCLUSION", "content": "This workshop paper has developed a complete top-down\ncounterfactual Root Cause Analysis approach from first\ncausal inference principles that is also compliant with in-dustrial development guidelines. On the basis of processing\nmultivariate time series data, the focus of this diagnosis\nchallenge has been put on detecting the Point of Incipient\nFailure, which displays the first anomaly pattern before the\nissue propagates to the rest of the system. This moment in\ntime is believed to be where the root cause is most likely to\nbe found. This hypothesis has been illustrated on a synthetic\nsystem showing how one single counterfactual is sufficient\nto explain the anomalous behavior, therefore pinpointing\nthe root cause of the eventual failure problem."}]}