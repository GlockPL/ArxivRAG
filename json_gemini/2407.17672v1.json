{"title": "Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs", "authors": ["Maryam Abbasihafshejani", "Anindya Maiti", "Murtuza Jadliwala"], "abstract": "Federated machine learning enables model training across multiple clients while maintaining data privacy. Vertical Federated Learning (VFL) specifically deals with instances where the clients have different feature sets of the same samples. As federated learning models aim to improve efficiency and adaptability, innovative neural network architectures like Spiking Neural Networks (SNNs) are being leveraged to enable fast and accurate processing at the edge. SNNs, known for their efficiency over Artificial Neural Networks (ANNs), have not been analyzed for their applicability in VFL, thus far. In this paper, we investigate the benefits and trade-offs of using SNN models in a vertical federated learning setting. We implement two different federated learning architectures - with model splitting and without model splitting that have different privacy and performance implications. We evaluate the setup using CIFAR-10 and CIFAR-100 benchmark datasets along with SNN implementations of VGG9 and ResNET classification models. Comparative evaluations demonstrate that the accuracy of SNN models is comparable to that of traditional ANNs for VFL applications, albeit significantly more energy efficient.", "sections": [{"title": "I. INTRODUCTION", "content": "Federated learning represents a significant advancement in collaborative machine learning, allowing multiple clients to train a shared model without exchanging their local data, thus preserving data privacy [13], [17], [15], [7]. Vertical Federated Learning (VFL) [16] is a special form of federated learning, particularly suited for scenarios where different clients possess different (often, non-overlapping) sets of features for the same samples. This model of learning is crucial in environments where data cannot be centralized due to privacy concerns or regulatory requirements, such as in finance, healthcare, and telecommunications. However, while VFL has been extensively studied using traditional Artificial Neural Networks (ANNs) [3], there has been limited exploration into its integration with neuromorphic and potentially more efficient models, such as Spiking Neural Networks (SNNs).\nNeuromorphic or neuro-inspired learning techniques are increasingly recognized as a powerful and energy-efficient alternative to traditional deep learning methods, particularly in edge computing applications [26], [4], [29], [31]. The development and deployment of neuromorphic hardware, such as IBM's TrueNorth [1] and Intel's Loihi [5], have propelled their popularity even further. Among these learning techniques, SNNs have emerged as a notable candidate for delivering performance and accuracy on par with conventional deep learning algorithms while being more energy and computationally efficient [23]. Unlike classical neural networks that use continuous signal processing, SNNs operate with Integrate-and-Fire neurons that process information through discrete spikes, closely mimicking the electrical activity of neurons in the human brain. These characteristics make SNNs an attractive option for deployment in federated learning scenarios where computational resources and energy efficiency are critical constraints. However, despite their advantages, the application of SNNs in VFL settings remains largely unexplored. This gap in research motivates our investigation into the feasibility and performance of SNNs within a VFL framework.\nIn this paper, we integrate SNN models into vertical federated setups and adapt existing techniques to effectively train SNNs in these settings. We design two distinct architectures for training SNN models in the vertical federated learning setting (VFL-SNN): one with model splitting, where different segments of the SNN are processed and stored across different clients, and another without model splitting, where the entire model, albeit distributed, is collaboratively updated without segmenting the model. Each architecture offers different benefits and trade-offs in terms of privacy preservation and computational efficiency and is adaptable to various operational needs and privacy requirements.\nWe evaluate the performance of the VFL-SNN models using well-known benchmark datasets, CIFAR-10 and CIFAR-100, and adapting two popular convolutional neural network (CNN) models, VGG9 and ResNET, for use with SNNs. Our comparative analysis focuses on several key metrics, including model accuracy and energy consumption, comparing these to results obtained with traditional ANNs in similar VFL setups. Our results indicate that VFL-SNN models achieve comparable accuracy to traditional ANNs while significantly reducing energy consumption, thereby confirming the potential of SNNs in vertical federated learning environments. This research not only extends the current understanding of federated learning applications, but also demonstrates potential for utilizing energy-efficient neural network models in privacy-sensitive collaborative learning tasks."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "This section presents an overview of federated machine learning models, SNNs, and prior work in the union of these fields."}, {"title": "A. Spiking Neural Networks (SNNs)", "content": "A SNN consists of three main components: an encoder that transfers input data to a temporal dimension, the SNN model, which processes this data by leveraging the dynamics of synaptic interactions and neuronal firing patterns, and a decoder that translates the output of SNN from the spike data back to a form that can be understood or used in the context of the problem being solved. Following is a brief explanation of the individual components:\n1) Input Encoding: Input encoding transforms information into spike trains, allowing it to effectively represent input content as discrete spikes in a time-series. A common method for this transformation is rate coding, which quantifies information by averaging the number of spikes over a parameterized time period. Rate coding is particularly effective in image processing tasks like classification, where it converts pixel intensity into firing rates, successfully capturing the complex details of images [10]. In this encoding method, the frequency of the spikes is proportional to the magnitude of the input value. For instance, a higher pixel intensity in an image can result in a higher firing rate of spikes. Poisson-distributed spike train [8] is a widely used type of rate encoding, where spikes are generated at each time step following a Poisson process, in which the probability of spike occurrence is typically linked to the intensity or rate of the input signal. A limitation of rate encoding is its disregard for the timing of spikes. To overcome this, several temporal encoding methods have been introduced. The time-to-first-spike method [10] is a notable technique that considers the timing of the first spike within a specific interval as the encoded information. Phase encoding utilizes the phase of a pulse relative to a background oscillation to mark the arrival time of a spike. Additionally, correlation and synchrony encoding [22] are used to represent spatio-temporal spike patterns in response to specific stimuli.\n2) SNN Models: Several SNN models have been de-veloped in the research literature, with three of the most commonly used models outlined below:\n\u2022 Leaky Integrate-and-Fire Model: This model is one of the simplest and most widely used in SNN architectures. In this model, neurons receiving inputs (post-synaptic neurons) aggregate the action potentials from sending neurons (pre-synaptic neurons). If the accumulated membrane potential surpasses a certain threshold, the neuron generates a spike. This spike then travels through synaptic connections, influencing the membrane potential of connected neurons [22]. The equation governing the Leaky Integrate-and-Fire (LIF) model is as follows:\n$\\frac{dv(t)}{dt} = -\\frac{(v(t) \u2013 V_{rest})}{\\tau} + RI(t)$\nwhere $\\tau$ = RC is the membrane time constant, indicating how quickly the membrane potential responds to changes in input current, $v(t)$ is the membrane potential at time t, $V_{rest}$ is the resting membrane potential, R is the membrane resistance, and I(t) is the input current at time t.\n\u2022 Spike Response Model: The Spike Response Model (SRM) incorporates the refractory dynamics of a neuron following a spike. This model reflects the temporary unresponsiveness of the neuron after firing, during which it undergoes a refractory period before it can return to its baseline voltage level. Several factors contribute to this state: the neuron might show\n\u2022 Izhikevich Model: The Izhikevich model is designed to simulate the dynamics of a neuron's membrane potential along with its recovery characteristics [22]. Unlike other models with a fixed firing threshold, the Izhikevich model allows the threshold to vary depending on the recent activity of the neuron. This feature makes the model highly versatile and capable of representing various neuron types found throughout the brain, accurately reflecting their complex behavior.\n3) Output Decoding: Decoding in SNN serves as the counterpart to encoding, converting spike trains back into interpretable information. Methods such as rate-based decoding directly translate neuron firing rates into input intensities, aligning with rate encoding techniques. Temporal decoding strategies reconstruct precise input timing from spikes, complementing temporal encoding like time-to-first-spike. Population decoding uses collective neuronal activity to infer input characteristics, mirroring population encoding techniques [6]."}, {"title": "B. Batch Normalization Through Time (BNTT)", "content": "The non-differentiable nature of a spiking neuron makes accurate and efficient training of SNNs challenging. To overcome this training issue in SNN, [11] proposes an adapted batch normalization approach that operates in the temporal dimension, called the Batch Normalization Through Time (BNTT). BNTT captures the temporal dynamics of spikes during batch normalization by associating a learnable parameter (\u03b3) to each time step. These temporally evolving learnable parameters in BNTT allow a neuron to control its spike rate through different time steps, thereby expanding the batch normalization layer through time and enabling accurate and efficient training from scratch. During forward propagation, the BNTT layer is applied after each convolutional or linear layer as follows:\n$v_i^t = \\lambda v_i^{t-1} + BNTT \\Big(\\sum_{j \\in n} W_{ijo_j^{t-1}}\\Big)$\n$o_i^t = \\lambda v_i^{t-1} + \\frac{\\Big(\\sum_{j \\in n} W_{ijo_j^{t-1}} - \\mu_t \\Big)}{\\sqrt{(\\sigma_t)^2 + \\epsilon}}$\nwhere, $\\mu_t$ and $\\sigma_t$ are the mean and variance from samples in a mini-batch b at time instant t. $o_j^t$ is the (binary) output of neuron j at time t which takes a value 1 when j fires at time t and 0 otherwise, v is the membrane potential of neuron i at time t, \u03bb is the leak factor and n is the set of input neurons connected to neuron i. The parameter \u03b3, associated with each neuron and different for each time instant t, is learnt during backpropagation. During testing/validation, a global value for both mean and variance is used, which are determined by computing a exponential moving average over the values estimated during the training rounds."}, {"title": "C. Federated Learning", "content": "Federated machine learning offers a framework where different entities can collaboratively train a model without having to share their data. Here, we provide an overview of two main types of federated learning, differentiated by their approach to data partitioning: Horizontal Federated Learning (HFL) and Vertical Federated Learning (VFL).\n1) Horizontal Federated Learning: In HFL, participants have datasets that share the same feature space but differ in the data samples. An example of this is various hospitals possessing similar medical record formats for different patients. These entities are typically unable to share their data due to privacy regulations. However, they can engage in HFL by sharing only their model updates with a server. The server orchestrates the learning process, selecting which participants contribute in each round and updating the global model using algorithms like FedAvg [20], FedProx [14], and FedMA [27].\n2) Vertical Federated Learning: VFL is applicable in scenarios where participants hold data on the same subjects but the data features vary. For example, a scenario might involve a consortium of smart home device manufacturers collaborating to improve energy efficiency and enhance user comfort using Vertical Federated Learning. Each manufacturer gathers proprietary data on energy consumption patterns, indoor climate conditions, and user preferences. Due to privacy regulations, these manufacturers cannot directly share their data. Instead, they use VFL techniques to collectively train a model that predicts optimal energy usage and adjusts home settings au-tonomously, ensuring privacy while optimizing smart home functionalities. VFL is categorized into two types (Figure 1): (i) without model splitting and (ii) with model splitting [24]. In scenarios without model splitting, each participant runs a complete model on their data and sends the results to a server. The server then aggregates these outputs to derive the final model output. Based on this aggregation, the server updates the gradients for each participant. In the with model splitting scenario, the machine learning model is segmented at a designated \"cut layer\", creating a top model and multiple bottom models (one for each participant). Each participant processes local data through their bottom model, while the top model, usually managed by a participant with access to labels, aggregates these inputs to compute the final output. The server then updates each participant's model based on the computed gradients."}, {"title": "D. SNN and Federated Learning", "content": "Recent research works in the literature have explored different approaches to implement federated learning in SNNs. The application of HFL within SNNs has been implemented with adaptations made to standard SNN learning parameters to suit a distributed dataset environment [25]. There have also been efforts to enhance the training of deep SNNS, particularly emphasizing the need to refine techniques like batch normalization to boost performance and decrease network latency [11]. The concept of asynchronous federated learning has been introduced to increase the efficiency and scalability of neuromorphic learning in SNNs, accommodating the delays and computation styles typical of neuromorphic systems [28]. Additionally, innovations in network design, such as integrating slimmable neural networks with superposition coding, are being explored to improve the data efficiency and adaptability of federated learning frameworks [30]. Despite this progress, there is a noticeable lack of research exploring the implementation of VFL with SNNs. To bridge this gap, we adapt the vertical federated learning training algorithm for SNN models, exploring both split and non-split model architectures. We then investigated the advantages and trade-offs of utilizing SNNs these setups and compared them with those of using ANN models."}, {"title": "III. VERTICAL FEDERATED TRAINING OF SPIKING NEURAL NETWORKS", "content": "The first step to efficiently training SNNs is to prepare the input data by appropriately encoding it. As discussed in Section II, the choice of encoding algorithm depends on the type of data being used. In this work, as we explore application of VFL with image data, and accordingly employ a rate encoding technique. Rate encoding works well for images because it effectively captures image features by using pixel intensity as the rate of spikes.\nWe assume a VFL system comprising of K participants/clients {Pk}K k=1 and a server S. One of the participant can act as the server, however for ease of exposition we treat them as separate entities here. The system assumes a dataset comprising of N (overlapping) samples D = {(xi, yi)}. In a VFL setting, all the participants P1 and the server S attempt to collaboratively train a joint machine learning model. Each feature vector xi \u2208 R1,d in the dataset Dis distributed (in a non-overlapping fashion) among the K participants, {xi,k \u2208 [R1,dk}Kk=1, where xi,k and dk is the feature (partition) held by participant Pk and its dimension, respectively.\nAs discussed earlier, a VFL system can be trained in two ways, depending on whether the top (or global) model is a trainable learning model or simply an aggregation function. The former one is referred to as VFL with model splitting, while the latter one is referred as VFL without model splitting. Next, we first describe VFL-SNN training approach with model splitting (outlined in Algorithm 1). Following that, we describe the approach without model splitting (outlined in Algorithm 2)."}, {"title": "A. VFL-SNN with Model Splitting", "content": "In VFL with model splitting, each participant k trains a local model Gk, parameterized by \u03b8k, using its corresponding local data (i.e., xi,k). These local participant models are also referred to as bottom models. Additionally, a global model F (also referred to as the top model), parameterized by \u03c8, operates on the server. The global or top model uses the outputs of the local models Gk to compute the final prediction by minimizing some joint task loss L:\n$L = Loss\\_Function(F(\\psi; Concat(o_1(\\theta_1; x_{i,1}),...,o_K(\\theta_K; x_{i,K}))), y_i)$ (2)\nWhere Loss_Function() is some loss function such as cross-entropy. Ok(\u03b8k; Xi,k) represents the output of the k-th bottom model for the i-th data sample, parameterized by \u03b8\u03ba. Concat() represents the concatenation of outputs from all bottom models. Then, the server computes the gradient of this loss with respect to the top model parameters, i.e., $\\frac{\\partial L}{\\partial \\psi}$, by unrolling along the time dimension. This gradient is used to update the top model parameters using the learning rate \u03b72, i.e., \u03c8 \u2190 \u03c8 \u2212 \u03b72 \u00d7 $\\frac{\\partial L}{\\partial \\psi}$. Simultaneously, the gradient of the loss with respect to each of the outputs from the bottom models $\\frac{\\partial L}{\\partial o_k}$ is computed. These gradients are sent back to each participant, who then performs their own backpropagation. Each participant calculates the gradient of the loss with respect to their model parameters $\\frac{\\partial o_k}{\\partial \\theta_k}$using this received gradient $\\frac{\\partial L}{\\partial o_k}$ (from the server). This involves using the following chain rule $\\frac{\\partial L}{\\partial \\theta_k} = \\frac{\\partial L}{\\partial o_k} \u00d7 \\frac{\\partial o_k}{\\partial \\theta_k} \u00d7 \\frac{\\partial \\theta_k}{\\partial v_k}$and unrolling the network along the time dimension. As ok is a thresholding function, its derivative is not defined at the time of the spike and is zero everywhere else, which makes computing the gradient of intractable. This can be addressed by approximating $\\frac{\\partial o_k}{\\partial \\theta_k}$ using either a piecewise linear or exponential function [18]. Once the gradient $\\frac{\\partial L}{\\partial o_k}$is approximated, each participant updates their model parameters by applying $\\theta_k = \\theta_k - \\eta_1 \u00d7 \\frac{\\partial o_k}{\\partial \\theta_k}$, where \u03b71 is the learning rate for the bottom models.\nThis structure allows the participants to train complex SNN models collaboratively in a VFL setting with the top layers of the model being trained centrally on the server, thereby reducing exposure to raw data. A significant security advantage in this setup is that only the server has access to the labels, enhancing privacy protection."}, {"title": "B. VFL-SNN without Model Splitting", "content": "VFL without model splitting involves each participant running a bottom model Gk, but unlike model splitting, there is no trainable top model on the server. Instead, the server uses a simple aggregation function, such as summation, to combine outputs ok = Gk(\u03b8k; xi,k) from all participants' bottom models to compute the final output using a joint task loss function (such as cross-entropy), as shown below:\n$L = Loss\\_Func \\Big(\\sum_{k=1}^K o_k, y_i \\Big)$ (3)\nThis approach minimizes the computational burden on the server and reduces the potential for sensitive data exposure, as the server merely aggregates model outputs without further processing or learning. The server then computes the gradient of this joint loss (L) with respect to each output (ok), i.e., $\\frac{\\partial L}{\\partial o_k}$, which are sent back to each corresponding participant in order to inform them how their local model parameters should be adjusted. Each participant uses these gradients ($\\frac{\\partial L}{\\partial o_k}$) received from the server to backpropagate, as described in the chain rule for the model splitting case, to calculate the gradient of the loss with respect to its own model parameters, i.e., $\\frac{\\partial o_k}{\\partial \\theta_k}$. Participants finally update their model parameters \u03b8k based on these gradients to optimize their local models."}, {"title": "IV. EVALUATION", "content": "In this section, we evaluate VFL-SNN by analyzing its energy consumption and performance under various settings."}, {"title": "A. Experimental Setup", "content": "We evaluated VFL-SNN using the CIFAR-10 and CIFAR-100 datasets [2], which are commonly employed as benchmarks in image classification tasks. Both CIFAR-100 and CIFAR-10 datasets comprise 50,000 32\u00d732 RGB images for training and 10,000 images for testing. Our evaluations were conducted on an NVIDIA V100 GPU equipped with 32 GB of RAM. In particular, we compared the performance of ANN and SNN implementations using the VGG9 [19] and ResNet-18 [12] architectures in vertical federated learning setups. The VGG9 model is designed to effectively process and classify complex visual data, utilizing seven convolutional layers with 3\u00d73 filters and two linear layers. The ResNet-18 model is a robust convolutional neural network that integrates 18 layers, featuring convolutional layers and skip connections that allow bypassing of certain layers. This design enables the network to learn from both shallow and deep layer features, thereby enhancing the training efficiency of the network. We distributed the features vertically among N clients and conducted experiments using VFL-SNN with both model splitting and without model splitting. VFL-SNN implementation was derived from the HFL-SNN code base of [25], with significant additions and modifications made for the VFL setup. We used the Leaky Integrate-and-Fire (LIF) neuron model with a neuron leakage rate (\u03bb) set at 99% and Poisson encoding [8] for encoding inputs. Poisson encoding is a type of rate encoding that introduces unpredictability and temporal variations in spike patterns, enhancing the network's adaptability to diverse scenarios and its responsiveness to noisy inputs. To decode the output from SNN models, we compute the average firing rate of the output neurons. For classification tasks, these firing rates are averaged, and the neuron exhibiting the highest firing rate is identified as representing the predicted class. For the VFL-SNN VGG9 model, we chose a spike learning rate of 0.1, a leak memory rate of 0.99, a momentum of 0.95, and a weight decay of 1 \u00d7 10-4, with the Stochastic Gradient Descent (SGD) optimizer employed to optimize the model. In the VFL-SNN ResNet18, the best accuracy is obtained with a learning rate of 0.02, while the other parameters are left unchanged. Due to the differences in architecture of ANN models, we use a different set of optimized parameters, for comparisons with VFL-SNN. For reference implementations of VFL-ANN (artificial neural network for vertical federated learning) models of VGG9 and ResNet18, we obtained the best accuracy with a learning rate of 0.001 and a weight decay of 5 \u00d7 10-4. The models were configured to classify 10 different classes for CIFAR-10 and 100 for CIFAR-100."}, {"title": "B. Models and Splitting", "content": "Our first evaluation aims to determine the impact of various learning models on performance metrics in both VFL-SNN without model splitting and with model splitting configurations. We specifically assessed the performance of both VFL-SNN and VFL-ANN versions of VGG9 and ResNet18 under conditions where there were two clients and the SNN time step was set at 32. The results, presented in Tables I and II, demonstrate a relatively minor performance disparity between the SNNs and ANNs versions, with about a 3% difference. For instance, in VFL without model splitting on CIFAR-10, the best test accuracy for the ANN VGG9 is 80.35, while for the SNN VGG9, it is 77.95. Although VFL-ANNS surpass VFL-SNN in performance, the minimal difference in accuracy can be inconsequential, positioning SNNs as a viable alternative for edge computing applications if power efficiency (evaluated in Section IV-E) and the capability to handle time-varying data are essential."}, {"title": "C. Number of Clients", "content": "Next, we evaluate the models' stability by altering the number of clients and distributing segments of the image between them. For example, in a scenario with 2 clients, one client processes the right side of the images, while the other handles the left side. Figures 2a and 2b demonstrate how accuracy shifts with varying numbers of clients using the VFL-SNN VGG9 model at a fixed time-step of 32, in comparison to the ANN model across both VFL with model splitting and VFL without model splitting configurations. The results indicate that as the number of clients increases, the accuracy of the ANN model declines more sharply, suggesting that SNNs are more scalable in a vertical federated learning context. This effect is particularly pronounced with CIFAR-100 (Figure 2b), where the accuracy of the VFL-ANN decreases from approximately 50% with two clients to 43% with four clients. In contrast, the accuracy for VFL-SNN drops from about 50% to 45% only."}, {"title": "D. Time Steps", "content": "To examine the impact of the SNN time step on VFL-SNN accuracy, we varied the time steps from 10 to 50 while maintaining three clients. As shown in Figure 3, increasing the time step from 10 to about 30 led to improved accuracy. However, extending the time step beyond this point did not significantly affect performance, as evidenced by the minimal changes in accuracy."}, {"title": "E. Energy Consumption", "content": "In this section, we evaluate the energy consumption associated with each layer of the models during training. Because SNNs only activate a subset of neurons at any given time, energy consumption is significantly reduced. To compare the energy consumption with ANN models, we recorded the number of spikes generated by neurons in each layer of the SNN-VFL and then computed the energy consumption based on the energy required for SNN model operations as follows: The energy required for operations (OPS) in a convolution layer is calculated as OPS = M2 x I x k2 x O, where k is the kernel size, I is the input channels count, O is the output channels count, and MX M is the feature map size. The relationship between M and the size of the input feature map, N1 \u00d7 N1, leads to a refined OPS formula:\n$OPS = \\Big(\\frac{N_1 - k + 2p}{s} + 1\\Big)^2 x I x k^2 x O$, (4)\nwhere p represents padding and s is the stride. For fully connected layers, where I inputs connect to O outputs, the OPS formula simplifies to:\nOPS = I \u00d7 O (5)\nEquation 4 illustrates how the input size significantly affects energy consumption. By implementing vertical federated learning, which distributes features across multiple devices, the energy demand on each device is reduced. Additionally, SNNs utilize binary spikes that convert the multiply accumulate (MAC) operation predominantly into an accumulation (AC) operation, greatly enhancing energy efficiency. The energy consumption for ANNs is given by:\nEANN = OPS \u00d7 EMAC (6)"}, {"title": "F. Training Time", "content": "Although SNNs benefit from low energy consumption, they typically require longer training times compared to ANNS. This prolonged training period is due to the inherent use of time steps in SNNs for processing spikes. Figure 5 depicts the training times with three clients and a time step of 32 for SNN VGG9 (SNN-VFL), ANN VGG9 (ANN-VFL), and also SNN and ANN without federated learning for comparison. Training VFL-SNN with model splitting resulted in an average client training time per epoch of 123 seconds and a total training time of 559 seconds. Without model splitting, VFL-SNN had a higher average training time of 142 seconds but a much lower total time per epoch of 300 seconds. In contrast, VFL-ANN displayed dramatically lower training times of approximately 1.53 seconds per client per epoch. It is evident that the overall training duration for VFL-SNN, both with and without model splitting, is substantially longer than that for VGG9 ANNS and non-federated SNNs, underscoring the trade-off between energy efficiency and training time."}, {"title": "V. DISCUSSION AND CONCLUSION", "content": "The integration of SNNs into VFL frameworks represents a promising direction in machine learning, particularly in scenarios demanding high computational efficiency and privacy preservation. The experimental results from the VFL-SNN framework highlight both the potential benefits and the limitations inherent in this novel approach."}, {"title": "A. Efficiency and Performance", "content": "The findings from our evaluation indicate that SNNs, while slightly underperforming in comparison to traditional ANNS in some metrics, offer significant improvements in energy efficiency. This trade-off is crucial in edge computing and IoT scenarios where power consumption is a limiting factor. The lower energy requirements of SNNs, as demonstrated in the VFL-SNN setting, suggest that the slight decrease in accuracy is compensated by the reduced operational costs and enhanced sustainability of the models."}, {"title": "B. Scalability and Adaptability", "content": "The adaptability of SNN models to different VFL configurations - namely, with and without model splitting - offers flexible approaches tailored to varying privacy and computational constraints. The scalability of SNNs is particularly notable, as evidenced by their performance stability across different client numbers and learning configurations. This suggests that SNNs could handle increasing data or feature distribution complexities better than ANNs, a valuable characteristic as federated learning applications grow in scale and complexity."}, {"title": "C. Challenges and Future Work", "content": "Despite these promising results, the extended training times of SNNs present a significant challenge. The inherent complexity of temporal data processing in SNNs, necessary for their energy efficiency and neuromorphic advantages, leads to longer training periods compared to ANNs. This aspect may limit the immediate widespread adoption of SNNs in time-sensitive applications. Future research can focus on optimizing the training processes of SNNs within federated frameworks, perhaps by developing new algorithms that can reduce training time without compromising the model's performance or energy efficiency. Moreover, exploring more advanced SNN models and their specific adaptations for VFL could further enhance the performance metrics, closing the gap with traditional ANNs. Also, while we estimate SNN processor energy consumption based on precise approximations from spiking rate simulations and benchmarks, real-world energy use may vary due to deployment conditions, hardware differences, and variations in SNN algorithms."}, {"title": "VI. CONCLUSION", "content": "In this study, we adjusted two VFL architectures - with model splitting and without model splitting - for Spiking Neural Networks (SNNs), addressing the challenge of efficiently conducting model training across multiple clients while preserving data privacy. We compared these adjusted VFL-SNN setups with ANN-VFL setups through comprehensive evaluation on the CIFAR-10 and CIFAR-100 datasets using SNN adaptations of VGG9 and ResNet models. Our results demonstrated comparable accuracy to traditional ANNs in VFL scenarios. VFL-SNN was also found to be significantly more energy-efficient, suggesting its potential for wider adoption in privacy-sensitive, distributed computing environments."}]}