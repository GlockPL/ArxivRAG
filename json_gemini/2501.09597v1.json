{"title": "Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining", "authors": ["Nathan Vaska", "Justin Goodwin", "Robin Walters", "Rajmonda S. Caceres"], "abstract": "Meshes are used to represent complex objects in high fidelity physics simulators across a variety of domains, such as radar sensing and aerodynamics. There is growing interest in using neural networks to accelerate physics simulations, and also a growing body of work on applying neural networks directly to irregular mesh data. Since multiple mesh topologies can represent the same object, mesh augmentation is typically required to handle topological variation when training neural networks. Due to the sensitivity of physics simulators to small changes in mesh shape, it is challenging to use these augmentations when training neural network-based physics simulators. In this work, we show that variations in mesh topology can significantly reduce the performance of neural network simulators. We evaluate whether pretraining can be used to address this issue, and find that employing an established autoencoder pretraining technique with graph embedding models reduces the sensitivity of neural network simulators to variations in mesh topology. Finally, we highlight future research directions that may further reduce neural simulator sensitivity to mesh topology.", "sections": [{"title": "I. INTRODUCTION", "content": "Highly accurate physics simulators operating on 3D ob-jects and scenes exist for a variety of domains, such as optical rendering [2], aerodynamics [3], and radar signature generation [4], [5]. Often this high accuracy is enabled by a correspondingly high computational cost [6]. This has led to a growing interest in accelerating simulations of complex physical phenomena using neural network models [7]-[9].\nNeural networks leverage vast amounts of data and a computationally intensive training process in order to learn a mapping between the input modality and the corresponding output. This enables subsequent simulations using fewer com-putational resources. The existence of large datasets containing millions of training samples and effective data augmentation strategies have allowed deep learning methods to be extremely successfully in tasks related to computer vision and natural language processing [10], [11]. However, generating physical simulation datasets of the same magnitude as typical deep learning datasets can be challenging.\nAnother challenge in training neural networks for simulation is the input data format. Physics simulators often operate on mesh representations of 3D objects [6], [12], which are chal-lenging for neural network architectures to process due to their irregular structures [6]. Additionally, there can be many valid underlying mesh representations, or topologies, for a single 3D object; for example, a flat plane is typically represented with fewer triangles in a computer aided design workflow as compared to a simulation workflow. Neural networks are typically trained to be robust to variation in mesh topologies through mesh augmentation [13]. However, as demonstrated in Fig. 1, many physics simulators are extremely sensitive to changes in mesh shape and augmented meshes would need to be re-simulated to ensure accurate training data. Since simulation is often a computational bottleneck, this limits the applicability of common mesh augmentations to training neural network models for simulation tasks. In this work, we investigate the impact of variations in mesh topology on neural simulator performance.\n\u2022 Using radar simulation as our physics simulation task, we show that neural simulators are extremely sensitive to variations in mesh topology.\n\u2022 We compare existing methods for pretraining on large mesh datasets and find that pretraining on a mesh recon-struction objective reduces sensitivity to mesh topology.\n\u2022 We introduce Basic Shapes, a novel mesh dataset that enables direct analysis on the sensitivity of neural simu-lators to topology through shape-preserving variations."}, {"title": "II. RELATED WORK", "content": "A variety 3D object representations are used by neural networks, including meshes, point clouds, voxel occupancy, and sign distance functions [14], [15]. However, since meshes are the native format for many physics simulators, there is a strong motivation to use meshes as the input for neural simulators [7]-[9].\nNeural network architectures have been developed for tasks like mesh classification, segmentation and generation [14], [16], [17]. The first component in these architectures is a mesh embedding network that embeds faces as a feature vector. Direct face embedding networks calculate face features from quantities like vertex positions and face normals [17], [18]. Graph embedding networks calculate initial face features, but then utilize graph convolutions to incorporate information from nearby faces [17]. Face tokenization methods pair graph embedding with a learned codebook to enable mesh recon-struction tasks [17]. Once faces have been embedded, their features are aggregated to create an overall mesh feature.\nThere is limited work examining the impact of mesh topol-ogy on neural simulators. The closest body of work evaluates the impact of mesh augmentations on downstream tasks [13] or pre-training strategies for mesh representations [16], [17]. This prior work focuses on improving mesh representations for tasks like mesh segmentation or generation, while our work examines whether existing representations are insensitive to mesh topology in the context of physics simulation tasks."}, {"title": "B. Pretraining Neural Networks", "content": "Pretraining is a technique used to improve neural network performance on a target task by first training on a related task for which more training data is available [19]. Pretraining is effective when it is able to learn latent representations of data that generalize to the target task [11], [20]; due to the availability of large labeled datasets like Shapenet [21], many styles of mesh pretraining are viable. We examine:\n\u2022 Unsupervised: Pretraining with an autoencoding mesh reconstruction task operating on local features, as in [17].\n\u2022 Supervised: Pretraining to predict the semantic class of a mesh via a global classification objective [22], [23]."}, {"title": "C. Radar Modeling and Simulation", "content": "We use radar simulation as a representative task to evaluate the impact of mesh topology on model performance. Radar is not sensitive to mesh topology but is highly sensitive to small changes in object shape, preventing the use of standard mesh augmentations in training. Radar also has applications across domains such as air traffic control and autonomous driving [1], and there exists prior work on neural radar simulators [7], [8] showing promise in neural solutions for this space."}, {"title": "III. METHODS", "content": "We describe the radar simulation task, the different mesh embedding methods, and the pretraining tasks we investigated."}, {"title": "A. Radar Simulation Task and Architecture", "content": "We use the radar simulation task defined in [7] for our experiments. Given a mesh M composed of a set of vertices VM and a set of faces FM, the neural simulator g must output a radar response R that is similar to the ground truth simulation response R. The neural simulator g is composed of three components; a face embedding network f, an ag-gregation network a, and a decoding network d, such that R = d(a(f(VM, F\u043c))), represents the radar signal output."}, {"title": "B. Face Embedding", "content": "The first step in generating a learned representation for meshes is typically to generate a feature embedding er for each face fi \u2208 FM. In our experiments, we use three different types of face embedding networks."}, {"title": "1) Direct Face Embedding", "content": "Face embeddings are calculated from geometric face features, such as vertex positions and face normals, using standard neural network layers. We implement the transformer-based method from [7] for our experiments, since it has already shown good performance on the radar simulation task."}, {"title": "2) Graph-based Face Embedding", "content": "Direct face embeddings are refined using a graph neural network. We use the graph encoding network from [17], which has been able to effectively generate features for complex mesh generation tasks 1."}, {"title": "3) Tokenization-based Embeddings", "content": "Codebook tokeniza-tion can be used to reduce mesh embedding size and effec-tively discretize mesh representations for generative tasks [17]; we use the codebook tokenization from [17]."}, {"title": "C. Aggregator and Decoder Networks", "content": "Once face embeddings have been generated, a feature ag-gregator network a maps the face information into a single feature vector C\u043c = a({ei}), which represents the full mesh. The decoder network d then maps this to the simulated radar response R = d(CM). The radar simulator is optimized to minimize error with respect to the true response.\nFor our experiments, we use a transformer for the aggre-gator network architecture and a MLP for the decoder [25]. This architecture was introduced for radar simulation in [7]; however, it did not utilize scale-normalization on mesh inputs as is typical in pre-training mesh embedding models. We augment the decoder to handle scale-normalized meshes by learning a categorical embedding to represent discretized scale and concatenating this embedding with the aggregated mesh representation before decoding. We train all models using a mean squared error loss that is weighted by target intensity to emphasize important radar signature features."}, {"title": "D. Training Methods", "content": "Effective mesh encodings for simulation tasks must empha-size features like object shape while ignoring irrelevant mesh topology. We use these training strategies in our experiments."}, {"title": "1) Training from Scratch", "content": "The face embedding network f is randomly initialized and trained end-to-end on the target simulation dataset to predict R."}, {"title": "2) Classification-based Pretraining", "content": "The features generated by a mesh face embedding network are fed to a transformer encoder with a classification head [25] that is trained to predict semantic class labels on a larger auxiliary mesh data set. Since radar response is not needed, standard mesh augmentation techniques can be applied during training. The weights of the embedding network are used to initialize f, which is then trained end-to-end to predict R."}, {"title": "3) Autoencoder-based Pretraining", "content": "Mesh face embedding networks are trained in the augmented auxiliary dataset, using an objective of the autoencoder based on mesh reconstruction [17]. The weights of the embedding network are used to initialize f, which is then trained end-to-end to predict R."}, {"title": "E. Data Generation", "content": "To evaluate the impact of topology variations on down-stream simulation tasks, we need a set of objects paired with various mesh instantiations that map to the same simulation output. Without this property, it is difficult to isolate the impact of mesh variation from the general simulation capability. There are many 3D object datasets that contain wide varieties of meshes such as Shapenet [21] and Objaverse [26]; however, these do not provide multiple mesh topologies for individual objects.\nTo address this gap, we propose a new dataset Basic Shapes. We use Blender [27], an open source 3D modeling and rendering program, along with the following process to generate simple and complex mesh topologies with exactly the same underlying shape. First, we select a primitive 3D shape from Blender's built-in defaults, generate a mesh to represent the object, and scale it by random values along the independent object axes. We ensure that no primitive of the same type is generated with a similar scale to ensure object diversity. This mesh is considered the simple mesh for that object. Next, we randomly add loop cuts to create additional faces and follow up with a decimation operation to reduce faces in a pseudorandom manner [27]. We carefully choose the decimation level so that the shape of the underlying object is not changed. We also randomly vary the number of vertices used to define the curvature for primitives that have curved components. We repeat this process by varying the number of loop cuts, decimation parameters, and curvature vertices until the desired number of complex mesh variations has been generated; examples can be seen in Fig. 2.\nUsing this process, we generate the Basic Shapes dataset to enable analysis on the impact of variations in mesh topologies that preserve object shape. This dataset consists of Cube, Cylinder, and Sphere primitives, where each class contains 1000 different objects at different scales. For each object, a single simple mesh and 99 complex mesh variants are generated, for a total of 100 mesh instantiations. In total, we generate 3000 objects and 300,000 meshes for this dataset, split 90/10 between training and testing."}, {"title": "IV. EXPERIMENTS", "content": "We follow the procedure in [7] for simulating radar re-sponses, but use objects from the Basic Shapes dataset as our mesh source. We then separate the simple mesh topologies from the complex mesh variants; the simple meshes are used for training models, while complex mesh variants are used only for evaluation and an ideal training scenario. For pretraining, we follow the process described in [17] to prepare Shapenet, resulting in 20,789 decimated Shapenet objects [21]."}, {"title": "B. Metrics", "content": "We use three variants of MSE 2 to evaluate the impact of mesh artifacts on the quality of a predicted radar response [7].\nSimple MSE: $MSE(R, R_{s})$, \nComplex MSE :\n$\\frac{1}{ \\left| C \\right| }  \\sum_{C}MSE(R, R_{C})$, \nVariation MSE :\n$\\frac{1}{ \\left| C \\right| }  \\sum_{C}MSE(R_{s}, R_{C})$."}, {"title": "C. Training and Model information", "content": "Models were pretrained on Shapenet using 30 V100 gpus for 50 epoches (~1 day). Simulation models for each established combination of embedding method and training condition were trained for 50 epochs on the simple meshes in Basic Shapes 3 using two V100 gpus (~3 hours). Models were also trained from scratch on all meshes to provided an idealized comparison; these models were trained on 2 V100 gpus for 5 epoches (~1 day)."}, {"title": "V. RESULTS AND DISCUSSION", "content": "Table I shows the performance of each algorithm on each metric. We observe that the graph embedding model pre-trained with the autoencoding objective had the most accurate predictions on both simple and complex meshes, while also performing best on the variation metric. In general, algorithms using graph or tokenization embedding performed better than algorithms using direct embedding, and autoencoder training also generally outperformed classification pretraining or no pre-training. Taken together, these results indicate that graph-based encoders and autoencoder pre-training are more effec-tive at handling complex and varied mesh topology. There is potentially a theoretical underpinnings to these results; both graph embeddings and the autoencoding pretraining objective are more strongly tied to local spatial features, which are extremely important for accurate simulation in physics- based radar simulators [4], [5]. Additionally, the pre-training exposes algorithms to additional meshes and their topologies, likely improving their feature quality on complex mesh topologies.\nSince local features are important to a variety of simulators in other domains [2], [3], we expect that better mesh embeddings for the radar simulation task will transfer well to such domains.\nWhile the autoencoding-pretrained graph embedding ar-chitecture is the least sensitive to mesh topologies of the methods tested, it is still significantly more sensitive than models trained on the idealized dataset that includes typically unavailable topology augmentations. This indicates that the sensitivity of these architectures to mesh topology can be further reduced. In particular, the pre-training objectives might prove to be more effective when trained against a larger mesh dataset (the dataset size considered here is significantly lower to other domains, like computer vision and NLP, where significant improvements due to pre-training have been ob-served [11] [20]), altering the pre-training loss function to enforce similarity between similar meshes, or by incorporating equivariance to mesh orientations into the mesh embedding structures [7]."}, {"title": "VI. CONCLUSION", "content": "Many high-fidelity physics simulators use mesh representa-tions as inputs, and there is a growing interest in using neural networks to reduce their high computational cost. In parallel, there have been advancements in neural network models which work directly on mesh data. However, the unique requirements of physics simulation as compared to other mesh-based tasks limit the use of common mesh augmentations. Utilizing the new Basic Shapes dataset that we introduce in this work, we show that the performance of neural simulators trained without these augmentations is degraded by irrelevant variations in mesh topology. We find that pre-training graph-based mesh embedding networks on an autoencoding task effectively re-duces this sensitivity to mesh topology, and suggest additional avenues of research to continue reducing this sensitivity."}]}