{"title": "UNLOCKING THE POWER OF GRADIENT GUIDANCE\nFOR STRUCTURE-BASED MOLECULE OPTIMIZATION", "authors": ["Keyue Qiu", "Yuxuan Song", "Jie Yu", "Hongbo Ma", "Ziyao Cao", "Zhilong Zhang", "Yushuai Wu", "Mingyue Zheng", "Hao Zhou", "Wei-Ying Ma"], "abstract": "Structure-based molecule optimization (SBMO) aims to optimize molecules with\nboth continuous coordinates and discrete types against protein targets. A promising\ndirection is to exert gradient guidance on generative models given its remarkable\nsuccess in images, but it is challenging to guide discrete data and risks inconsisten-\ncies between modalities. To this end, we leverage a continuous and differentiable\nspace derived through Bayesian inference, presenting Molecule Joint Optimization\n(MolJO), the first gradient-based SBMO framework that facilitates joint guidance\nsignals across different modalities while preserving SE(3)-equivariance. We intro-\nduce a novel backward correction strategy that optimizes within a sliding window\nof the past histories, allowing for a seamless trade-off between explore-and-exploit\nduring optimization. Our proposed MolJO achieves state-of-the-art performance\non CrossDocked2020 benchmark (Success Rate 51.3%, Vina Dock -9.05 and SA\n0.78), more than 4\u00d7 improvement in Success Rate compared to the gradient-based\ncounterpart, and 2\u00d7 \u201cMe-Better\u201d Ratio as much as 3D baselines. Furthermore, we\nextend MolJO to a wide range of optimization settings, including multi-objective\noptimization and challenging tasks in drug design such as R-group optimization\nand scaffold hopping, further underscoring its versatility and potential.", "sections": [{"title": "INTRODUCTION", "content": "Structure-based drug design (SBDD) plays a critical role in drug discovery by identifying three-\ndimensional (3D) molecules that are favorable against protein targets (Isert et al., 2023). While\nrecent SBDD focuses on the initial identification of potential drug candidates, these compounds must\nundergo a series of further modifications for optimized properties, a process that is both complex and\ntime-consuming (Hughes et al., 2011). Therefore, structure-based molecule optimization (SBMO) has\ngarnered increasing interest in real-world drug design (Zhou et al., 2024), emphasizing the practical\nneed of optimizing 3D molecules to meet specific therapeutic criteria.\n\nConcretely, SBMO can be viewed as a more advanced task within the broader scope of general SBDD,\nrequiring precise control over molecular properties while navigating the chemical space. Specifically,\nSBMO addresses two key aspects: (1) SBMO prioritizes targeted molecular property enhancement\naccording to expert-specified objectives, whereas generative models for SBDD primarily focus on\nmaximizing data likelihood without special emphasis on property improvement (Luo et al., 2021; Peng\net al., 2022). Therefore these models can only produce outputs similar to their training data, limiting\nthe ability to improve molecular properties. (2) SBMO is capable of optimizing existing compounds\nwith 3D structural awareness, addressing a critical gap left by previous molecule optimization\nmethods with 1D SMILES or 2D graph representations (Bilodeau et al., 2022; Fu et al., 2022), and\nallowing for a more nuanced control. The focus on structure makes SBMO particularly suited for key\ndesign tasks, such as R-group optimization and scaffold hopping."}, {"title": "RELATED WORK", "content": "Pocket-Aware Molecule Generation. Pocket-aware generative models aim to learn a conditional\ndistribution over the protein-ligand complex data. Initial approaches adopt 1D SMILES or 2D graph\nrepresentation (Bjerrum & Threlfall, 2017; G\u00f3mez-Bombarelli et al., 2018), and recent research has\nshifted its focus towards 3D molecule generation in order to better capture the interatomic interactions.\nEarly atom-based autoregressive models (Luo et al., 2021; Peng et al., 2022; Liu et al., 2022) enforce\nan atom ordering to generate molecules atom-by-atom. Fragment-based methods (Powers et al.,"}, {"title": "PRELIMINARY", "content": "3D Protein-Ligand Representation. A protein binding site $p = (x_p, v_p)$ is represented as a point\ncloud of $N_p$ atoms where atom coordinates $x_p = \\{x_p^{(i)}\\}^N_{i=1} \\in \\mathbb{R}^{N_p \\times 3}$ and $K_p$-dimensional\natom features $v_p = \\{v_p^{(i)}\\}^N_{i=1} \\in \\mathbb{R}^{N_pK_p}$. Similarly, a ligand molecule $m = (x_M, v_M)$\ncontains $N_M$ atoms, where $x_M \\in \\mathbb{R}^3$ is the atomic coordinate and $v^{(i)} \\in \\mathbb{R}^{K_M}$ the atom type. For\nbrevity, the subscript for molecules $M$ and the pocket condition $p$ are omitted unless necessary."}, {"title": "METHOD", "content": "In this section, we introduce MolJO that guides the distribution over $\\theta$, utilizing aggregated infor-\nmation from previous latents. Though different from guided diffusions that operate on noisy latent\n$y$, this guidance aligns with our generative process conditioned on $\\theta$. By focusing on $\\theta$, we can\neffectively steer the clean samples towards desirable direction, ensuring a smooth gradient flow.\n\nNotation. Following Kong et al. (2024) and denoting the guided distribution $\\pi$ as product of experts\n(Hinton, 2002) modulated by energy function $E$ that predicts certain property, we have $\\pi(\\theta_i | \\theta_{i-1}) \\propto\np_{\\Phi}(\\theta_i | \\theta_{i-1})p_E(\\theta_i)$, where $\\Phi$ is the pretrained network for BFN, $p_E(\\theta_i) = \\text{exp} [-E(\\theta_i, t_i)]$ is the\nunnormalized Boltzmann distribution corresponding to the time-dependent energy function.\n\nOverview. As illustrated in Figure 1, we introduce MolJO as follows: in Sec. 4.1, we propose the\nconcept of gradient guidance over the multi-modality molecule space, derive the form of guided\ntransition kernel $\\pi(\\theta_i|\\theta_{i-1})$ via first-order Taylor expansion, and explain the underlying manipula-\ntions of distributions the guidance corresponds to. In Sec. 4.2, we present a generalized advanced\nsampling strategy termed backward correction for $p_{\\Phi}$, which allows for a flexible trade-off between\nexplore-and-exploit by maintaining a sliding window of past histories. We empirically demonstrate\nour strategy helps optimize consistency across steps, ultimately improving the overall performance."}, {"title": "EQUIVARIANT GUIDANCE FOR MULTI-MODALITY MOLECULAR DATA", "content": "In this section, we derive the detailed guidance over $\\Theta$ for molecule $m = (x, v)$ with $N$ atoms, where\n$x \\in \\mathbb{R}^{N\\times 3}$ represent continuous atom coordinates and $v \\in \\{1, ..., K\\}^N$ for $K$ discrete atom types,\nand thus $\\theta := [\\mu, z]$ for the continuous and discrete modality, respectively.\n\nGuidance over Multi-Modalities. To steer the sampling process towards near-optimal samples,\nwe utilize the score $\\nabla_{\\theta}\\text{log } p_E(\\theta)$ as a gradient-based property guidance, for which we have the\nfollowing proposition (proof in Appendix C.1), followed by details for each modality."}, {"title": "GUIDED BAYESIAN UPDATE WITH BACKWARD CORRECTION", "content": "Here we propose a general backward correction sampling strategy inspired from the optimization\nperspective, and analyze its effect on aligning the gradients. Recall that from Eq. 1 we can aggregate\n$\\theta_i$ based on latents from the previous step:\n$$p_{\\Phi}(\\theta_i | \\theta_{i-1}) = \\frac{\\mathbb{E}_{p_{\\O}(\\theta_i(\\theta_{i-1},t_i))}}{p_U(\\theta_i|\\theta_{i-1}, x_i; a_i)}$$\n\nBackward correction aims at \u201ccorrecting the past to further optimize\". Since we obtain an optimized\n$\\theta^*_i$ from the guided kernel $\\pi(\\theta_i|\\theta_{i-1})$, there will be an optimized version of $x = x^*_{i+1}$ for the next\nstep. By backward correcting the Bayesian update distribution $p_U$ given the optimized $x^*$, we are\nable to reinforce the current best possible parameter $\\theta$, instead of building on the suboptimal history.\nBy utilizing the property of additive accuracy once $p_U$ follows certain form as described by Graves\net al. (2023), the one-step backward correction can be derived as follows:\n$$p_{\\Phi}(\\theta_i | \\Theta_{i-1}, \\theta_{i-2}) = \\frac{\\mathbb{E}_{p_{\\O}(\\Phi(\\theta_{i-1},t_i))p_U(\\theta_{i-1}|\\theta_{i-2}, x_i; a_{i-1})}}{p_U(\\theta_i | \\theta_{i-2}, x_i; a_{i-1} + a_i)}$$\nOriginally $\\theta_{i-1} \\thicksim p_{\\O}(x_{i-1} (\\theta_{i-2}, t_{i-1}))$\n\nand we arrive at the $k-$ step corrected estimation of $p_{\\Phi}$:\n$$p_{\\Phi}(\\theta_n | \\theta_{n-1}, ..., \\theta_{n-k}) = \\frac{\\mathbb{E}_{p_{\\O}(\\Phi(\\theta_{n-1},t_n))}}{\\prod_{i=n-k+1}^n p_U(\\theta_n | \\theta_{-k}, x_n; \\sum a_i)}$$\n\nPlugging Eq. 7 and 9 together with the sender distributions defined above into the right hand side\naccording to Eq. 1, yields the analytic form of the backward corrected Bayesian update\n$$p_U(\\mu_n | \\mu_{n-k}, x_n) = N(\\frac{\\Delta \\beta x_n^* + \\mu_{n-k} p_{n-k}}{p_n}, \\frac{\\Delta \\beta}{p_n} I)$$\n$$p_U(z_n | z_{n-k}, v_n) = \\frac{\\mathbb{E}_{y \\thicksim N(y | \\Delta \\beta'(K \\hat{e}v_{n-1}), \\Delta \\beta' KI)}}{\\sum_{i=1}^K \\text{exp}(y)_i(\\text{z}_{n-k})_i} \\text{exp}(y) z_{n-k}$$\n\nwhere $\\hat{m} = [\\hat{x}, \\hat{v}]$ is drawn from the output distribution $p_{\\O} (\\hat{m} | \\Phi(\\theta_{i-1}, t_{i-1}, p))$ given pocket $p$,\n$\\Delta \\beta = \\beta_n - \\beta_{n-k}$ and $\\Delta \\beta' = \\beta'_n - \\beta'_{n-k}$ are obtained from corresponding schedules."}, {"title": "EQUIVARIANT GUIDANCE FOR MULTI-MODALITY MOLECULAR DATA", "content": "In practice, we employ the gradient scale $s$ as a tem-\nperature parameter, which is equivalent to adopting\n$p(\\theta,t) \\propto \\text{exp}[-sE(\\theta, t)]$. The general sampling pro-\ncedure is summarized in Algorithm 1."}, {"title": "EXPERIMENTAL SETUP", "content": "We conduct two sets of experiments for structure-based molecule optimization (SBMO), although the\nconstrained setting seems within the scope of unconstrained one, it is biologically meaningful and\nmore practical in rational drug design, and further showcases the flexibility of our method.\n\nTask. For a molecule $m \\in M$ where $M$ denotes the set of molecules, there are oracles $a_i(m) :\nM \\to \\mathbb{R}$ for property $i$, each with a desired threshold $\\delta_i \\in \\mathbb{R}$. MolJO is capable of different levels\nof controllability: (1) unconstrained optimization, where we identify a set of molecules such that\n$\\left\\{ m \\in M | a_i(m) \\geq \\delta_i, \\forall i \\right\\}$, i.e. the goal is to optimize a number of objectives. (2) constrained\noptimization, where we aim to find a set of molecules that contain specific substructures $s$ such that\n$\\left\\{ m \\in M | a_i(m) \\geq \\delta_i, s \\subset m, \\forall i \\right\\}$.\n\nDataset. Following previous SBDD works (Luo et al., 2021; Peng et al., 2022; Guan et al., 2022),\nwe utilize CrossDocked2020 (Francoeur et al., 2020) to train and test our model, and adopt the same\nprocessing that filters out poses with RMSD > 1\u00c5 and clusters proteins based on 30% sequence\nidentity, yielding 100,000 training poses and 100 test proteins.\n\nBaselines. We divide all baselines into the following: (1) Generative models (Gen.), including AR\n(Luo et al., 2021), GraphBP (Liu et al., 2022), Pocket2Mol (Peng et al., 2022), FLAG (Zhang et al.,\n2023), DiffSBDD (Schneuing et al., 2022), TargetDiff (Guan et al., 2022), DecompDiff (Guan et al.,\n2023), IPDiff (Huang et al., 2024) and MolCRAFT (Qu et al., 2024), (2) Oracle-based optimization\n(Oracle Opt.) that rely on docking simulation in each round, such as RGA (Fu et al., 2022), and\nDecompOpt (Zhou et al., 2024), (3) Gradient-guided (Grad. Opt.) TAGMol (Dorna et al., 2024).\nDetailed descriptions of baselines are left in Appendix F.\n\nMetrics. We employ the commonly used metrics as follows: (1) Affinity metrics calculated by\nAutodock Vina (Eberhardt et al., 2021), in which Vina Score calculates the raw energy of the given\nmolecular pose residing in the pocket, Vina Min conducts a quick local energy minimization and\nscores the minimized pose, and Vina Dock performs a relatively longer search for optimal pose\nto calculate the lowest energy. Success Rate measures the percentage of generated molecules that\npass certain criteria (Vina Dock < -8.18, QED > 0.25, SA > 0.59) following Long et al. (2022) and\nGuan et al. (2022). (2) Molecular properties, including drug-likeness (QED) and synthesizability\nscore (SA). (3) Metrics for sample distribution, such as diversity (Div). A more comprehensive set of\nmetrics are detailed in Appendix F."}, {"title": "UNCONSTRAINED OPTIMIZATION", "content": "In this section, we demonstrate the ability of our framework to improve molecular properties in both\nsingle and multi-objective optimization. We sample 100 molecules for each protein and evaluate\nMolJO in optimizing binding affinity and molecular properties. For additional evaluation of molecular\nconformation besides optimization performance, please see Appendix G.\n\nMolJO effectively enhances molecular property w.r.t. generative models. The optimized\ndistribution greatly improves upon the original generated distribution, as shown in the distribution\nshift in Figure 3 for single objective optimization, and Table 1 (row 13 vs. row 9).\n\nMolJO outperforms gradient-based method with 4\u00d7 higher Success Rate. As shown in Table 1,\nour model achieves state-of-the-art in affinity-related metrics while being highly drug-like, with the\nbest Success Rate of 51.3%, a fourthfold improvement over TAGMol (row 13 vs. row 12).\n\nMolJO has more potential than oracle-based baselines if equipped with oracles. RGA (Fu\net al., 2022) and DecompOpt (Zhou et al., 2024) show satisfactory Success Rate, enjoying the\nadvantage of oracle-based screening at some expense of diversity. Given the same use of Z-score\n(Zhou et al., 2024), we report a variant of MolJO with beam search width 10, selecting a tenth of top\nscoring molecules and showing that it is more effective than oracle-based methods once in a similar\nsetting. Moreover, the higher diversity of DecompOpt and MolJO suggests the superiority of 3D\nstructure-aware generative models over 2D optimization of RGA (row 14 vs. row 10 & 11).\n\nMolJO is 2x as effective in proposing \"me-better\" candidates. For gradient-based method\nTAGMol (Dorna et al., 2024), although it produces seemingly promising high affinity binders,\nthey come at the expense of sacrificed molecular properties like QED and SA, demonstrating the\nsuboptimal control of coordinate-only guidance signals. Notably, the ratio of all-better samples is\nbelow 17% for all other baselines, and MolJO is twice as effective (39.8%) in generating feasible\ndrug candidates that pass this criteria, as shown in Figure 1.\n\nMolJO excels even in optimizing large OOD molecules. Note that for fair comparison, we\nrestrict the size of generated molecules by reference molecules so that both generative models and\noptimization methods navigate the similar chemical space, as we observe a clear correlation between\nproperties and sizes in Figure 6. For model variants capable of exploring larger number of atoms,\nwe report the results in Table 2 with sizes, where MolJO consistently outperforms other baselines,\ndemonstrating its robustness. A detailed discussion can be found in Appendix E."}, {"title": "CONSTRAINED OPTIMIZATION", "content": "Constrained optimization seeks to optimize the input reference molecules for enhanced properties\nwhile retaining specific structures. We generalize our framework with such structural control and\nshow its potential for pharmaceutical use cases including R-group optimization and scaffold hopping,\nachieved by infilling. Details of this task are in Appendix D.2.\n\nMolJO captures the complex environment of infilling. Table 3 shows that our method generates\nvalid connected molecules and captures the complicated chemical environment with better molecular\nproperties than all baselines, showcasing its potential for lead optimization. As for diffusion baselines,\nthey generate fewer valid connected molecules especially in the challenging case with scaffold\nh hopping, with diffusion baselines lower than 70% validity, and proves to be less effective in proposing\nfeasible candidates, with Success Rate < 20%.\n\nOptimized molecules form more key interactions for binding. The visualization for constrained\noptimization is shown in Figure 4. It can be seen that the optimized molecules establish more key\ninteractions with the protein pockets, thus binding more tightly to the active sites. For example, the\noptimized molecule for 2PC8 retains the key interaction formed by its scaffold, with R-group grown\ndeeper inside the pocket, forming another two \u03c0-\u03c0 stackings."}, {"title": "ABLATION STUDIES", "content": "We conduct ablation studies to thoroughly validate our design. More details are left in Appendix F.2.\n\nJoint guidance is consistently better than single-modality guidance. To validate our choice of\njoint guidance over different modalities, we ablate the gradient for coordinates or types. As shown"}, {"title": "EFFECT OF MOLECULAR SIZE ON PROPERTIES", "content": "The size of molecules are found with a notable impact over molecular properties including Vina\naffinities (Qu et al., 2024). We quantify the relationship and plot the distribution of molecular\nproperties w.r.t. the number of atoms with the Pearson correlation coefficient in Figure 6. It is not\nsurprising to see a non-negligible correlation between properties and molecular sizes, since the size of\nmolecules typically constrain its possibility over the chemical space. To ensure a fair comparison, we\nstick to the molecular space with similar size to the reference. For further comparison among different\nmodel variants, we report the molecular properties under different sizes in Table 5. Results show\nthat our method consistently achieves the highest success rate, demonstrating its robust optimization\nability even in an Out-of-Distribution (OOD) scenario."}, {"title": "FULL OPTIMIZATION RESULTS", "content": "Baselines. We provide a detailed description of all baselines here:\n\n\u2022 AR (Luo et al., 2021) uses MCMC sampling to reconstruct a molecule atom-by-atom given\nvoxel-wise densities.\n\n\u2022 GraphBP (Liu et al., 2022) is an autoregressive atom-based model that uses normalizing\nflow and encodes the context to preserve 3D geometric equivariance."}, {"title": "MOLECULE OPTIMIZATION", "content": "Overall Distributions. We additionally report the property distributions for Vina Score, SA, and\nQED in Figure 15, 13, 14, respectively, demonstrating the efficacy of our proposed method in\noptimizing a number of objectives for \u201cme-better\" drug candidates.\n\nAffinity Analysis. We present the tail distribution of Vina affinities in Table 6, demonstrating that\nour method not only excels in optimizing overall performance as shown in Figure 3, but also enhances\nthe quality of the best possible binders.\n\nTo better understand the enhanced binding affinites, we further analyze the distribution of non-\ncovalent interactions that are known to play an important role in stabilizing protein-ligand complexes.\nFigure 7 demonstrates that the improved affinity results are achieved by forming a greater number of\nhydrophobic interactions, more hydrogen bond acceptors as well as \u03c0 interactions."}, {"title": "MORE RELATED WORKS", "content": "Molecule Optimization As an alternative to target-aware generative modeling of 3D molecules,\nthe optimization methods are goal-directed, obtain desired ligands usually by searching in the drug-\nlike chemical space guided by property signals (Bilodeau et al., 2022; Du et al., 2024). General\noptimization algorithms were originally designed for ligand-based drug design (LBDD) and optimize\ncommon molecule-specific properties such as LogP and QED (Olivecrona et al., 2017; Jin et al.,\n2018; Nigam et al., 2020; Spiegel & Durrant, 2020; Xie et al., 2021; Bengio et al., 2021), but could\nbe extended to structure-based drug design (SBDD) given docking oracles. However, since most\nearly attempts did not take protein structures into consideration thus were essentially not target-aware,\nit means that they need to be separately trained on the fly for each protein target when applied to\npocket-specific scenarios. RGA (Fu et al., 2022) explicitly models the protein pocket in the design\nprocess, overcoming the transferability problem of previous methods."}, {"title": "LIMITATION", "content": "Limitation of this work lies in that as the first proof-of-concept, MolJO adopts no more than three\nobjectives (Affinity, QED, SA) in the optimization process, while there are more objectives that are\nbiologically meaningful such as ADMET. Future directions include extending the general framework\nto accommodate a wider range of objectives, and even beyond the scope of structure-based molecule\noptimization (SBMO), for MolJO is a general gradient-based optimation method for continuous and\ndiscrete variables, and can be tailored to a great many read-world applications."}]}