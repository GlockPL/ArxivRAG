{"title": "A Deep Learning Framework for Three Dimensional Shape Reconstruction from Phaseless Acoustic Scattering Far-field Data", "authors": ["Doga Dikbayir", "Abdel Alsnayyan", "Vishnu Naresh Boddeti", "Balasubramaniam Shanker", "Hasan Metin Aktulga"], "abstract": "The inverse scattering problem is of critical im-portance in a number of fields, including medical imaging,sonar, sensing, non-destructive evaluation, and several others.The problem of interest can vary from detecting the shapeto the constitutive properties of the obstacle. The challengein both is that this problem is ill-posed, more so when thereis limited information. That said, significant effort has beenexpended over the years in developing solutions to this problem.Here, we use a different approach, one that is founded on data.Specifically, we develop a deep learning framework for shapereconstruction using limited information with single incidentwave, single frequency, and phase-less far-field data. This is doneby (a) using a compact probabilistic shape latent space, learnedby a 3D variational auto-encoder, and (b) a convolutional neuralnetwork trained to map the acoustic scattering information tothis shape representation. The proposed framework is evaluatedon a synthetic 3D particle dataset, as well as ShapeNet, apopular 3D shape recognition dataset. As demonstrated via anumber of results, the proposed method is able to produceaccurate reconstructions for large batches of complex scatterershapes (such as airplanes and automobiles), despite the significantvariation present within the data.", "sections": [{"title": "I. INTRODUCTION & RELATED WORK", "content": "Inverse acoustic scattering problems (IASP) [1] have beenextensively studied in the research community for decades,given their wide applicability. The goal of IASPs is to deducethe shape and/or constitutive properties of an object based onthe acoustic scattering data due to an incident field collectedat a set of receivers. A diverse variety of application areashave this problem at their center, including sonar detection[2], nondestructive testing [3], medical imaging [4], remotesensing [5] and several more.\nInverse scattering problems can be addressed with bothphase and phaseless data [6]. Methods utilizing phase datainclude the regularized Gauss-Newton method [7], recursivelinearization methods [8], [9], source inversion method [10],two-stage least squares method [11], direct sampling methods[12], [13]. While being accurate, a downside is the difficultyof obtaining phase data in practical applications comparedto phaseless data. Due to this fact, despite the phaselessreconstruction being significantly more ill-posed and non-linear, it is often preferred over phase-based reconstruction[14], [15].\nSeveral iterative methods using phaseless scattering datahave been proposed to solve the inverse scattering problem[16]\u2013[20]. However, for iterative solvers, an intermediaryshape is optimized by minimizing a loss function between itsscattered field and the scattered field of the target shape. Thisprocess requires the execution of an expensive forward scat-tering solver at each optimization step, rendering the methodimpractical for several real-world use cases. Non-iterativemethods such as sampling-based methods [12], [14], [21],[22] are faster, however they may not produce accurate results.These limitations underline the importance of developing moreefficient and scalable methods to solve IASP.\nIn the last decade, machine learning and deep learningmethods have been widely adopted in the scientific computingcommunity as fast and data-driven alternatives to expensive it-erative numerical solvers. Several deep learning methods havealso been proposed to solve both the forward and the inverseacoustic scattering problems. In [23], a convolutional neuralnetwork is used to learn a mapping between 2D obstaclesand corresponding acoustic scattering far-field patterns. Later,in [24] and [25], this idea is expanded to solve the forwardacoustic scattering problem for 3D obstacles using a PointNet[26] encoder. For the inverse acoustic scattering problem, theproposed solutions are mainly focused on the 2D problem.A random forest model is used to perform surface shape"}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "Consider an acoustically soft scatterer, \u0393, embedded in ahomogeneous medium \u03a9 \u2208 R\u00b3. A time-harmonic (e\u2212iwt de-pendence is assumed and suppressed) incident pressure wavewith velocity potential, \u03a6i(r), illuminates \u0393, giving rise to aascattered wave with velocity potential, \u03a6s(r). The resultingtotal velocity potential \u03a6t(r) = \u03a6i(r) + \u03a6s(r) satisfies thefollowing boundary value problem,\n\u25bd2\u03a6t(r) + \u03ba2\u03a6t(r) = 0 \u0393 \u2208 \u03a9, (1a)\n\u03a6t(r) = 0 r \u2208 \u0393, (1b)\nlimr\u2192\u221e \u221ar (\u2202\u03a6\u2202n \u2212 i\u03ba\u03a6) = 0 r \u2208 \u03a9, (1c)\nwhere \u03ba is the wavenumber. Using an equivalence theorem,the scattering problem can be cast in terms of trace values ofthe velocity potential [35], [36]; we introduce the scatteringcross-section (SCS) far-field operator Lfar in terms of thesurface pressure as\nLfar[\u03a6, \u0393](k) = 14\u03c0\u222b\u0393(\u2202\u03a6\u2202n\u2032(r\u2032) + i\u03ba\u03a6(r\u2032))e\u2212iknr\u2032 dr\u2032. (2)\nHere, the observation domain is on the unit k-sphere S2, wherek(\u03b8, \u03c6) \u2208 S2 is parametrized by (\u03c6, \u03b8) \u2208 [0, \u03c0] \u00d7 [0, 2\u03c0]. Fromhereon, this data is referred to as the scattered data or far-fielddata. The analytical solution of (1) is generally unavailable.The numerical solution of the integral equations is effected ina discrete setting using the boundary element method (BEM)[36].\nThe goal of ISSRNet is to reconstruct the three-dimensional(3D) shape of the scatterer \u0393, when scattering data on k(\u03b8, \u03c6)is available. In [34] the authors develop a method for shapeoptimization problem, which relies on an iterative scheme,that perturbs an initial shape \u03930, until its scattering datamatches that of the target scatterer. While producing accurate\nreconstructions, this method requires the execution of theexpensive forward scattering solver at each step of the op-timization, which dominates the overall optimization processand becomes a serious computational bottleneck. To addressthis bottleneck, we formulate the inverse scattering problemfor shape reconstruction using neural networks and define anobjective function to optimize their parameters."}, {"title": "A. Preliminaries: Neural network", "content": "Following the generic formulation given in [37], we math-ematically define a neural network and its optimization pro-cedure. A neural network can be represented by a functionf, which maps an n-dimensional input feature space, to ac-dimensional latent space: f : Rn \u2192 Rc. Neural network f isparameterized by an m-dimensional weight vector w \u2208 Rm.Therefore we can express f as f(x, w), where x \u2208 Rn is theinput training data-point. Training the neural network involvesupdating the weights w, by minimizing the loss functionJ : Rm \u2192 R. If we write the objective function J in terms ofnetwork weights w, it takes the following form:\nJ(w) = 1N\u2211i=1NL(f(x(i), w),y(i)) (3)\nwhere x and y are the i-th input data-point and thecorresponding ground-truth observation in the training data set(x(i),y(i)) where 0 < i < N and N is the total number oftraining samples. The function L is a term-wise loss function"}, {"title": "B. Preliminaries: Shape encoding and mapping to scattered field data", "content": "The proposed framework operates on a compressed latentshape representation space. This latent space is learned by the3D shape auto-encoder, prior to the inverse mapping. The aimof the proposed framework is to map the input scattering datato this compressed shape latent space using an inverse neuralnetwork. For sake of simplicity, we only formulate the inverseneural network in this section and assume that the weightsWAEE of the auto-encoder are learned a-priori. The trainingprocess and the overall architecture of the auto-encoder aredescribed in detail in Section III-B1. Let d(s, WAEE) = pcbethe pre-trained decoder of the shape auto-encoder that decodesshape latent vectors s into their corresponding 3D point-cloudspc. We define an inverse neural network inn(sc, Winn) = s,that aims to map input phaseless far-field scattering data sc(formulated in 2) to shape latent vectors s. Subsequently,we can define an end-to-end inverse scattering frameworkd(inn(sc)) = pc, that maps input scattering data sc, to 3Dpoint-clouds pc, which represent the scatterers of interest.Given a training data set (sc(i), pc(i)),0 < i < N, theobjective of our training process is to find the set of valuesfor the weights Winn, such that d(inn(sc(i)), WAEE) = pc,where pc and sc(i) are the i-th goal (ground-truth) point-cloud and input training scattering data respectively. This isequivalent to minimizing the following objective function:\nJ(Winn) := 1N\u2211iCD(d(inn(sc(i))), pc(i)) (4)\nCD(P1, P2) = \u2211x\u2208P1miny\u2208P2||x \u2212 y||2 +\u2211y\u2208P2minx\u2208P1||x \u2212 y||2 (5)\nThe term-wise loss function to optimize the inverse networkis Chamfer distance (CD), defined in Equation 5. As it can beseen from the formulation, CD is a metric that quantifies thedistance between two point clouds by summing the distancesbetween each point and its closest neighbor in the other cloud."}, {"title": "III. ISSRNET", "content": "Next, we present the different modules and methods thatcompose our predictive framework. These include data gen-eration/preprocessing and neural network components. In ourexperiments, we evaluate the proposed method on both thesynthetic random 3D particle dataset as well as the widelyShapeNet [39], a used 3D computer vision benchmark dataset."}, {"title": "A. Pre-processing and Generation of Geometry Data", "content": "In this subsection, we explain the data generation andpre-processing steps utilized. Training the proposed networksrequires the computation of scattered fields for all shapes inthe training data set. We use the solver introduced in [36] tocompute the scattering far-fields. As with any physics basedsolver, it requires high quality tesselation (sufficiently fine tocapture the underlying physics, conformal elements, elementswith the right aspect ratio, watertight, etc). This is a challengefor available meshes that are intended for visualization andnot for computational physics.\nIn order to overcome this practical issue, we utilize tworemeshing methods to pre-process our shape data. The firststep is to make the scatterer meshes watertight. We utilizeManifoldPlus [40], which is a scalable and robust tool de-veloped to generate watertight surface meshes from trianglesoups. After the mesh is transformed into a watertight mesh,we use geogram, which utilizes anisotropic smooth remesh-ing methods presented in [41], [42].\nWe use two sets of data to train the network; one withrandom particles and the other with real geometries. Theseare described next."}, {"title": "1) Random 3D Particle Data Generation:", "content": "The randomparticle data generation process consists of random 3D shapegeneration and the corresponding scattered field computation.To generate the random 3D shapes, the random particlegenerator introduced in [43] is used.\nThe particle generator utilizes low-frequency spherical har-monics to determine shape properties such as elongation,roundness and aspect ratio, based on the shape analysisperformed in [44]. The process yields a variety of randomparticles which can have sharp, non-convex and flat features.These shape properties introduce complex patterns in theresulting scattered fields, increasing variation. In addition, theshape generator uses an evenly subdivided icosahedron meshfor each particle as a starting point, therefore the data set doesnot have any mesh quality problems. The idea is similar to thedata generation method used in [23], however the 3D shapesin this work can have variations in all 3D directions and arenot limited to convex prisms."}, {"title": "2) ShapeNet Pre-processing:", "content": "Popular 3D shape datasetssuch as ShapeNet or ModelNet [39], [45] include a rich varietyof meshes belonging to different classes of objects. We use twoclasses in our analysis here. As was alluded to earlier, thesemeshes are not made for analysis and have to be modifiedusing the procedure described earlier."}, {"title": "B. Neural Network Modules", "content": "The predictive end of the proposed framework consistsof a pipeline of three different neural architectures: A 3Dvariational auto-encoder, a convolutional inverse network, anda forward network. Let PC be the set of 3D scatterer point-clouds and SC the corresponding set of 3D acoustic scatteredfar-fields. The auto-encoder, the inverse network and theforward network are trained to learn the mappings PC \u2192 PC,SC \u2192 (PC \u2192 PC) and PC \u2192 SC, respectively. Note thatthe inverse mapping is not directly between SC and PC. Theinverse network instead learns a mapping from SC to the 3Dshape latent space, PC \u2192 PC, which is learned by the 3Dauto-encoder.\nThe goal of the framework is to learn the mapping SC \u2192 PC.To this end, first the 3D shape latent space PC \u2192 PCis learned by the auto-encoder. Then, the inverse networklearns a mapping from SC to this latent space. Each M-dimensional vector from the latent space represent a 3D point-cloud. Since these vectors are samples from PC \u2192 PC, theycan be decoded by the auto-encoder into 3D point-clouds.After the intermediary (predicted) scatterer shape is producedby the pre-trained generator (red section in Figure 3), thereare two approaches we consider, to calculate a loss functionto optimize the inverse encoder. The first approach,(see II-Bin Section II), which makes the training process completelyindependent from the forward solution, operates the loss solelyon the target (3D shape) space by employing a Chamferdistance (see 5) between the predicted and target point-cloudsof the scatterers. The second approach calculates a loss on theinput-space, to indirectly morph the intermediary point-clouds.This can be achieved by feeding the generated point-cloud intothe pre-trained forward network (PC \u2192 SC) to predict thescattered far-field information. Since the shape is optimizedbased on the loss between target and intermediary scatteredfields, this method is similar to the existing iterative and 2DML methods [30], [31], [34]. Therefore, we implement andcompare both approaches to investigate the necessity and/or"}, {"title": "1) 3D Variational Auto-encoder:", "content": "The proposed predictiveframework operates on a configurable, smooth latent space,representing each 3D scatterer in the data set. This compressedvector representation provides an advantage when designingthe inverse network, since the target output becomes a singlesize-configurable vector. This allows us to easily experimentwith very compact representations for the 3D scatterers. Tolearn the latent space from 3D point clouds, we adopt thevariational auto-encoder architecture proposed in [46].\nThe input 3D point-cloud x of the scatterer of interestis first fed into the PointNet Encoder, shown in Figure 6.This component encodes the input point-cloud to an M-dimensional global feature vector. The next step is to learna mapping from this feature vector, back to the original point-cloud. The architecture utilizes a variational auto-encodingapproach to achieve this goal. The goal in variational auto-encoders is to learn an approximation q(z|x) to the posterior\ndistribution p(z|x) for the training data set X, where datapoints x \u2208 X, when a known prior distribution such as thenormal distribution p(z) = N(\u03bc, \u03c32) is given. Therefore,given a data point x, the process can generate the codez \u223c q(z|x), which approximates p(z|x) = N(\u03bc, \u03c32), theprobability distribution over all possible values of the inputx. This approach allows the model to learn a generative latentspace for the scatterers, where samples from it are similar tothe training data, and the statistical properties of the underlyingdistribution are interpretable, thanks to the approximation tothe prior normal distribution. To draw a random sample fromthe learned latent z, the model utilizes a technique known as"}, {"title": "IV. RESULTS AND DISCUSSION", "content": "In this section, we present the 3D reconstruction resultsobtained by the proposed framework."}, {"title": "A. Experimental Setup", "content": "For our experiments, we consider two cases. First, weevaluate the proposed method on the random smooth particledata set. We randomly generate 50000 random particles withthe method described in Section III-A, then compute thescattered fields at 600 Hz, using the BEM solver. The fieldsare computed at 51 latitudinal and 101 longitudinal Gauss-Legendre quadrature coordinates. Next, we evaluate the pro-posed method on the airplane and cars classes of the popular3D vision benchmark data set ShapeNet [39]. We first processthe data set with the preprocessing step explained in SectionIII-A2. Then, we calculate the scattered fields at 750 Hz at thesame Gauss-Legendre points as in the random particle data set.The cars contain 3146 samples and airplanes classes consists of 3227 sample. Objects from both classes are normalized intoa bounding sphere with approximately r = 2m. The pointclouds representing the scatterer meshes are sampled usingthe furthest point sampling algorithm, and the sample size is2048. For the embedding size, we select M = 64 (see SectionIII). All neural network models use the LeakyReLU activationfunction, with the negative slope parameter set to 10\u22122. Weoptimize all models using the Adam optimizer with weightdecay hyperparameter set to 10\u22124. In order to schedule thelearning rate, we use a cosine annealing learning rate scheduler[48] and set the initial learning rate to 5e \u2212 4. For each dataset, we use a training-testing split ratio of 9 : 1.\nAll experiments are run on a single node equipped with anIntel Xeon 8358 CPU with 256GB of memory and a singleNVIDIA A100-40GB GPU."}, {"title": "B. Case 1: Random Particles", "content": "In this section, we discuss the evaluation results of theproposed framework, on the random particle data. This dataand LossFarField, as explained in Section III.\nWe first start by evaluating the forward network, trainedwith the random particle point-clouds and the correspondingscattered fields. Figure 7 shows the field reconstruction resultsfor random particles drawn from the test set of 5000 samples.As it can be observed from the results, the forward networkis able to capture the global structure of the scattered fields.However, local details are sometimes mispredicted and/orsmoothened by the forward network. Figure 8 shows the errordistribution for the test samples, evaluated by the forward net-work. For measuring the reconstruction error for the scatteredfields, we use the relative L2-norm of the difference betweenthe ground-truth scattered field SCTgt and the predicted scat-tered field SCTpred, so RelativeL2 = L2(SCTgt\u2212SCTpred). Asit can be observed from the error distribution histogram, mostreconstruction errors are accumulated around 5%.\nAfter verifying the reconstruction capability of the forwardnetwork, we continue with our experiment by training theshape auto-encoder and the inverse network, using the randomparticle data set. We aim to determine the effect of utilizingthe forward pass to optimize the model. In order to do this, weuse the loss function defined as LossInverse = LossShape +\nOFF \u00d7 LossFarField (see Section III). Here OFF is a tunablehyperparameter that controls the amount of LossFarField wewant to include for the training procedure. Table I, shows theloss values for different OFF values of 0.0, 0.25, 0.50 and0.75, as higher factors did not result in any improvements. Asit can be seen from the loss values, using a composite loss ofboth shape and scattering data does not improve the results.\nFigure 9, shows the reconstruction results for the randomparticle data set, with the forward step bypassed by settingOFF = 0. We can see that the proposed framework is able tocapture the global structure. However, we see a significantsmoothing of sharp features. Note that we don't observesuch degree of smoothing in the ShapeNet reconstructions,which are presented in the next subsection. Moreover, theChamfer distance error distribution for 5000 reconstructedtest shapes for the random particles data set shows that mostreconstruction errors are accumulated around 0.03, which is ahigher error average than both ShapeNet results (see Table I.This suggests that, despite ShapeNet dataset containing morecomplex structures, the random particles data set provides amore challenging learning task for the framework. This is dueto the fact that the global structure of airplanes (the position ofthe wings, body, tail etc.) and that of cars (the position of thewheels, body, windshield etc.) are much more well-determined"}, {"title": "C. Case 2: ShapeNet", "content": "While the random particle data set provides a practical wayof testing the proposed method, it doesn't contain any commonobjects from benchmark computer vision data sets that wouldallow us to make a more meaningful evaluation. The airplaneand cars classes of the ShapeNet data set, help us to addressthis issue. Both classes contain very different shapes that havedistinct complex features. Also, under the light of the resultsobtained in the previous section, we optimize the frameworkusing Lossshape, bypassing the forward step completely. Fig-ure 13 and Figure 14 show the reconstruction results for testsamples drawn from the cars and airplane classes respectively.Note that the camera is rotated to a specific angle for each case,to demonstrate the differences between the reconstructionsand the ground-truth data more effectively. The left columncontains the ground-truth point clouds of the scatterers andthe right column contains the reconstructed point clouds, bythe proposed framework. We intentionally pick samples thatbelong to different subclasses, having either significant localand/or global structural differences. The framework is ableto learn most global and local features, as it can be seenfrom the figures. For the cars class, we can easily see thata limousine (blue), a convertible (purple) and a truck (brown),which all have distinct features, are successfully reconstructed.However, we also observe subtle errors in the reconstructions.For example the number of seats in the convertible are notpredicted correctly. Also, the corners of the roof in the truckexample are not as sharp. These kind of reconstruction errorsare observed throughout the test data set. However, as theframework is data-driven, these imperfections are expectedand strongly depend on the training data too. Figure 11 showsthe error (Chamfer Distance) distribution of 320 test samplesfrom each data set. As it can be seen from the figure, mostreconstruction errors are accumulated around 0.01.\nWith the airplanes class, we observe much more complexfeatures and diversity amongst the scatterers. As it can beseen from Figure 14, the framework is able to successfullydifferentiate between the number and location of the jetpropellers, and the global structure of the different aircraft.Again, we observe a loss of density and accuracy in the fighterjet (purple) and stealth bomber (brown) reconstructions. Thisis partly due to the fact that half of the data set consists ofcommercial airliners, which is also reflected in the errordistribution in Figure 12, where the lower errors mostly belongto commercial airliner reconstructions, and there are much lessexamples of other aircraft types. Still, the framework is ableto capture the overall global and local properties of the shape,like the tail-wings and sharp wing features in the fighter jetreconstruction. Figure 12 shows the error distribution of thetest samples. Again, the errors are mostly accumulated around0.01.\nLastly, we evaluate the performance of the proposedmethod, relative to the iteration time of the numerical solverutilized in [34]. To this end, we report the execution time ofthe numerical forward scattering solver, for the airplane objectin the top row of Figure 1 at 750 Hz. The forward solver takes954 seconds to complete on a single Intel(R) Xeon(R) Gold6148 CPU. This would mean that a single iteration of theinverse shape optimization procedure for this airplane wouldapproximately take 954 seconds. The proposed method, on theother hand, is able to compute the predictions for 322 airplaneobjects in the test data, in 18 seconds (0.056 sec/airplane). Thisis several orders of magnitude faster, rendering the proposedframework appealing to a wide range of practical applications."}, {"title": "V. CONCLUSION", "content": "In this paper, we have demonstrated ISSRNet, a deep learn-ing framework for solving the 3D inverse acoustic scatteringfor shape reconstruction problem. Using a convolutional neuralnetwork, ISSRNet encodes the scattering far-field data intoa latent space. Then it maps this scattering latent space,to the 3D shape latent space, which is learned by a 3Dvariational auto-encoder. ISSRNet only requires data froma single incident wave, at a single frequency and performsorders of magnitudes faster than a traditional iterative method,while still capturing both global and local shape details aboutcomplex scatterers. Moreover, in contrast to existing iterativeand machine learning solutions, ISSRNet does not depend onthe forward solution for the scattering problem. We evaluatethe proposed framework on both a synthetic random 3D shapedata set with a high amount of random surface variation;as well as the cars and airplanes classes of the popular3D shape data set ShapeNet. As is evident, the results areextremely promising, while leaving room for improvementto capture finer grained details. These improvements include,using multiple frequencies to interrogate the object, usingmultiple incident field data, better shape descriptors througha more physics-aware encoder and/or loss function and soon. These will be topics that will be discussed in subsequentpapers."}]}