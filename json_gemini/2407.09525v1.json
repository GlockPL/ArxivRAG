{"title": "A Deep Learning Framework for Three Dimensional Shape Reconstruction from Phaseless Acoustic Scattering Far-field Data", "authors": ["Doga Dikbayir", "Abdel Alsnayyan", "Vishnu Naresh Boddeti", "Balasubramaniam Shanker", "Hasan Metin Aktulga"], "abstract": "The inverse scattering problem is of critical importance in a number of fields, including medical imaging, sonar, sensing, non-destructive evaluation, and several others. The problem of interest can vary from detecting the shape to the constitutive properties of the obstacle. The challenge in both is that this problem is ill-posed, more so when there is limited information. That said, significant effort has been expended over the years in developing solutions to this problem. Here, we use a different approach, one that is founded on data. Specifically, we develop a deep learning framework for shape reconstruction using limited information with single incident wave, single frequency, and phase-less far-field data. This is done by (a) using a compact probabilistic shape latent space, learned by a 3D variational auto-encoder, and (b) a convolutional neural network trained to map the acoustic scattering information to this shape representation. The proposed framework is evaluated on a synthetic 3D particle dataset, as well as ShapeNet, a popular 3D shape recognition dataset. As demonstrated via a number of results, the proposed method is able to produce accurate reconstructions for large batches of complex scatterer shapes (such as airplanes and automobiles), despite the significant variation present within the data.", "sections": [{"title": "I. INTRODUCTION & RELATED WORK", "content": "Inverse acoustic scattering problems (IASP) [1] have been extensively studied in the research community for decades, given their wide applicability. The goal of IASPs is to deduce the shape and/or constitutive properties of an object based on the acoustic scattering data due to an incident field collected at a set of receivers. A diverse variety of application areas have this problem at their center, including sonar detection [2], nondestructive testing [3], medical imaging [4], remote sensing [5] and several more.\nInverse scattering problems can be addressed with both phase and phaseless data [6]. Methods utilizing phase data include the regularized Gauss-Newton method [7], recursive linearization methods [8], [9], source inversion method [10], two-stage least squares method [11], direct sampling methods [12], [13]. While being accurate, a downside is the difficulty of obtaining phase data in practical applications compared to phaseless data. Due to this fact, despite the phaseless reconstruction being significantly more ill-posed and non-linear, it is often preferred over phase-based reconstruction [14], [15].\nSeveral iterative methods using phaseless scattering data have been proposed to solve the inverse scattering problem [16]\u2013[20]. However, for iterative solvers, an intermediary shape is optimized by minimizing a loss function between its scattered field and the scattered field of the target shape. This process requires the execution of an expensive forward scattering solver at each optimization step, rendering the method impractical for several real-world use cases. Non-iterative methods such as sampling-based methods [12], [14], [21], [22] are faster, however they may not produce accurate results. These limitations underline the importance of developing more efficient and scalable methods to solve IASP.\nIn the last decade, machine learning and deep learning methods have been widely adopted in the scientific computing community as fast and data-driven alternatives to expensive iterative numerical solvers. Several deep learning methods have also been proposed to solve both the forward and the inverse acoustic scattering problems. In [23], a convolutional neural network is used to learn a mapping between 2D obstacles and corresponding acoustic scattering far-field patterns. Later, in [24] and [25], this idea is expanded to solve the forward acoustic scattering problem for 3D obstacles using a PointNet [26] encoder. For the inverse acoustic scattering problem, the proposed solutions are mainly focused on the 2D problem. A random forest model is used to perform surface shape reconstruction from phaseless acoustic scattering data in [27]. In [28], [29], the authors propose physics-constrained neural network architectures to solve the acoustic inverse scattering problem for basic 2D shapes. In [30] a pipeline of a forward and inverse networks are evaluated to reconstruct the 2D shapes of random scatterers from their 2D scattering cross-sections. In [31], the inverse design of an acoustic cloak is done by a forward and inverse neural network. In [32], the authors attempt to derive the interfacial defects on laminated surfaces by using a simple multi-layer perceptron. We refer the readers to [33] for a comprehensive review of deep learning methods proposed to solve the inverse scattering problem. All these works highlight the potential and importance of the field, yet machine learning methods for solving inverse acoustic scattering problems for 3D shape reconstruction, to the best of our knowledge, remain unexplored.\nIn this paper, we propose ISSRNet (inverse scattering shape reconstruction network), a machine learning framework to solve the inverse acoustic scattering problem for retrieving the 3D shape of the scatterer, using phaseless acoustic scattering data from acoustically soft objects. We utilize scattering data obtained by illuminating the scatterer with a single incident wave (fixed angle, single frequency). The inversion framework consists of three different neural networks: a 3D shape auto-encoder, an inverse network, and a forward network. To optimize ISSRNet, we calculate a loss between the target and predicted shapes. This is in contrast to existing methods that calculate the optimization loss in terms of a derived quantity, viz., the difference between scattered field data from the target and predicted obstacles [30], [31], [34]. As experiments will show, our approach performs very well. Our main contributions of this work are as follows:\n\u2022 We propose a ISSRNet, a deep learning framework for 3D shape reconstruction from phaseless acoustic scattering data. As alluded to earlier, the approach we present relies on a different loss function, which is both a direct measure of performance and is more computationally different.\n\u2022 ISSRNet produces excellent results despite acting on limited scattering data, i.e., data obtained due to a single incident wave at a fixed frequency. This points to improvements that can be made with greater data diversity.\n\u2022 As will be shown, ISSRNet is evaluated on both the synthetic random particles and ShapeNet data sets. The reconstructions capture both the global properties of the scatterers as well as the local details and differentiate between different types of objects."}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "Consider an acoustically soft scatterer, \u0393, embedded in a homogeneous medium \u03a9 \u2208 R\u00b3. A time-harmonic ($e^{-iwt}$ dependence is assumed and suppressed) incident pressure wave with velocity potential, $\u03a6^i(r)$, illuminates \u0393, giving rise to a scattered wave with velocity potential, $\u03a6^s(r)$. The resulting total velocity potential $\u03a6^t(r) = \u03a6^i(r) + \u03a6^s(r)$ satisfies the following boundary value problem,\n$\u25bd^2 \u03a6^t(r) + \u03ba^2 \u03a6^t(r) = 0 \\\\ \u03a6^t(r) = 0 \\\\  lim_{r\u2192\u221e} r(\\frac{\u2202\u03a6^s}{\u2202n} - \u1f30\u03ba\u03a6^s) = 0$\n\u0393\u0395\u03a9,\nr\u2208\u0393,\n\u0393\u0395\u03a9,\nwhere is the wavenumber. Using an equivalence theorem, the scattering problem can be cast in terms of trace values of the velocity potential [35], [36]; we introduce the scattering cross-section (SCS) far-field operator $L_{far}$ in terms of the surface pressure as\n$L_{far} [\u03a6, \u0393](k) = \\frac{1}{4\u03c0} \\int_\u0393 (r)e^{inker'} dr'.$", "eqs": ["\u25bd^2 \u03a6^t(r) + \u03ba^2 \u03a6^t(r) = 0", "\u03a6^t(r) = 0", "lim_{r\u2192\u221e} \u221ar (\\frac{\u2202\u03a6^s}{\u2202n} - \u1f30\u03ba\u03a6^s) = 0", "L_{far} [\u03a6, \u0393](k) = \\frac{1}{4\u03c0} \\int_\u0393 (r)e^{inker'} dr'."]}, {"title": "A. Preliminaries: Neural network", "content": "Following the generic formulation given in [37], we math- ematically define a neural network and its optimization pro- cedure. A neural network can be represented by a function f, which maps an n-dimensional input feature space, to ac- dimensional latent space: f : Rn \u2192 RC. Neural network f is parameterized by an m-dimensional weight vector w \u2208 Rm. Therefore we can express f as f(x, w), where x \u2208 Rn is the input training data-point. Training the neural network involves updating the weights w, by minimizing the loss function J: Rm \u2192 R. If we write the objective function J in terms of network weights w, it takes the following form:\n$J(w) = \\frac{1}{N} \\sum_{i=1}^N L(f(x^{(i)}, w),y^{(i)})$", "eqs": ["J(w) = \\frac{1}{N} \\sum_{i=1}^N L(f(x^{(i)}, w),y^{(i)})"]}, {"title": "B. Preliminaries: Shape encoding and mapping to scattered field data", "content": "The proposed framework operates on a compressed latent shape representation space. This latent space is learned by the 3D shape auto-encoder, prior to the inverse mapping. The aim of the proposed framework is to map the input scattering data to this compressed shape latent space using an inverse neural network. For sake of simplicity, we only formulate the inverse neural network in this section and assume that the weights $W_{AAE}$ of the auto-encoder are learned a-priori. The training process and the overall architecture of the auto-encoder are described in detail in Section III-B1. Let $d(s, W_{AAE}) = p_c$ be the pre-trained decoder of the shape auto-encoder that decodes shape latent vectors s into their corresponding 3D point-clouds $p_c$. We define an inverse neural network $inn(sc, W_{inn}) = s$, that aims to map input phaseless far-field scattering data sc (formulated in 2) to shape latent vectors s. Subsequently, we can define an end-to-end inverse scattering framework $d(inn(sc)) = p_c$, that maps input scattering data sc, to 3D point-clouds pc, which represent the scatterers of interest. Given a training data set $(sc^{(i)}, p_c^{(i)}),0 < i < N$, the objective of our training process is to find the set of values for the weights $W_{inn}$, such that $d(inn(sc^{(i)}), W_{AAE}) = p_c^{(i)}$, where $p_c$ and $sc^{(i)}$ are the i-th goal (ground-truth) point- cloud and input training scattering data respectively. This is equivalent to minimizing the following objective function:\n$J(W_{inn}) := \\frac{1}{n} \\sum_i CD(d(inn(sc^{(i)})), p_c^{(i)})$.\n$CD(P_1, P_2) = \\sum_{x\u2208P_1} min_{y\u2208P_2} ||x - y||_2 + \\sum_{y\u2208P_2} min_{x\u2208P_1} ||x - y||_2$", "eqs": ["J(W_{inn}) := \\frac{1}{n} \\sum_i CD(d(inn(sc^{(i)})), p_c^{(i)}).", "CD(P_1, P_2) = \\sum_{x\u2208P_1} min_{y\u2208P_2} ||x - y||_2 + \\sum_{y\u2208P_2} min_{x\u2208P_1} ||x - y||_2"]}, {"title": "III. ISSRNET", "content": "Next, we present the different modules and methods that compose our predictive framework. These include data generation/preprocessing and neural network components. In our experiments, we evaluate the proposed method on both the synthetic random 3D particle dataset as well as the widely ShapeNet [39], a used 3D computer vision benchmark dataset."}, {"title": "A. Pre-processing and Generation of Geometry Data", "content": "In this subsection, we explain the data generation and pre-processing steps utilized. Training the proposed networks requires the computation of scattered fields for all shapes in the training data set. We use the solver introduced in [36] to compute the scattering far-fields. As with any physics based solver, it requires high quality tesselation (sufficiently fine to capture the underlying physics, conformal elements, elements with the right aspect ratio, watertight, etc). This is a challenge for available meshes that are intended for visualization and not for computational physics.\nIn order to overcome this practical issue, we utilize two remeshing methods to pre-process our shape data. The first step is to make the scatterer meshes watertight. We utilize ManifoldPlus [40], which is a scalable and robust tool de- veloped to generate watertight surface meshes from triangle soups. After the mesh is transformed into a watertight mesh, we use geogram, which utilizes anisotropic smooth remesh- ing methods presented in [41], [42]. The original mesh in ShapeNet and the watertight remeshed version is shown Figure 1. In this 2-step pre-processing phase, the number of triangles in the final re-mesh is also configurable, therefore this provides an easy way of adjusting the average edge length in our scatterer meshes, a necessary feature to accurately capture the physics.\nWe use two sets of data to train the network; one with random particles and the other with real geometries. These are described next.\n1) Random 3D Particle Data Generation: The random particle data generation process consists of random 3D shape generation and the corresponding scattered field computation. To generate the random 3D shapes, the random particle generator introduced in [43] is used.\nThe particle generator utilizes low-frequency spherical har- monics to determine shape properties such as elongation, roundness and aspect ratio, based on the shape analysis performed in [44]. The process yields a variety of random particles which can have sharp, non-convex and flat features. These shape properties introduce complex patterns in the resulting scattered fields, increasing variation. In addition, the shape generator uses an evenly subdivided icosahedron mesh for each particle as a starting point, therefore the data set does not have any mesh quality problems. The idea is similar to the data generation method used in [23], however the 3D shapes in this work can have variations in all 3D directions and are not limited to convex prisms. Figure 2 shows samples from the random particle data set.\n2) ShapeNet Pre-processing: Popular 3D shape datasets such as ShapeNet or ModelNet [39], [45] include a rich variety of meshes belonging to different classes of objects. We use two classes in our analysis here. As was alluded to earlier, these meshes are not made for analysis and have to be modified using the procedure described earlier."}, {"title": "B. Neural Network Modules", "content": "The predictive end of the proposed framework consists of a pipeline of three different neural architectures: A 3D variational auto-encoder, a convolutional inverse network, and a forward network. Let PC be the set of 3D scatterer point- clouds and SC the corresponding set of 3D acoustic scattered far-fields. The auto-encoder, the inverse network and the forward network are trained to learn the mappings PC \u2192 PC, SC \u2192 (PC \u2192 PC) and PC \u2192 SC, respectively. Note that the inverse mapping is not directly between SC and PC. The inverse network instead learns a mapping from SC to the 3D shape latent space, PC \u2192 PC, which is learned by the 3D auto-encoder.\nFigure 3 shows the overall deep learning framework. The goal of the framework is to learn the mapping SC \u2192 PC. To this end, first the 3D shape latent space PC \u2192 PC is learned by the auto-encoder. Then, the inverse network learns a mapping from SC to this latent space. Each M- dimensional vector from the latent space represent a 3D point- cloud. Since these vectors are samples from PC \u2192 PC, they can be decoded by the auto-encoder into 3D point-clouds. After the intermediary (predicted) scatterer shape is produced by the pre-trained generator (red section in Figure 3), there are two approaches we consider, to calculate a loss function to optimize the inverse encoder. The first approach,(see II-B in Section II), which makes the training process completely independent from the forward solution, operates the loss solely on the target (3D shape) space by employing a Chamfer distance (see 5) between the predicted and target point-clouds of the scatterers. The second approach calculates a loss on the input-space, to indirectly morph the intermediary point-clouds. This can be achieved by feeding the generated point-cloud into the pre-trained forward network (PC \u2192 SC) to predict the scattered far-field information. Since the shape is optimized based on the loss between target and intermediary scattered fields, this method is similar to the existing iterative and 2D ML methods [30], [31], [34]. Therefore, we implement and compare both approaches to investigate the necessity and/or improvement effects of utilizing the second approach. The two approaches are also visualized in Figure 3. We experiment with optimizing the network using only Loss Shape and with adding LOSS FarField as a regularizing term. As it can be seen from the figure, calculating LOSS FarField, requires the extra step of generating a scattered field from the generated point-cloud, using the forward network.\n1) 3D Variational Auto-encoder: The proposed predictive framework operates on a configurable, smooth latent space, representing each 3D scatterer in the data set. This compressed vector representation provides an advantage when designing the inverse network, since the target output becomes a single size-configurable vector. This allows us to easily experiment with very compact representations for the 3D scatterers. To learn the latent space from 3D point clouds, we adopt the variational auto-encoder architecture proposed in [46]. Figure 4 shows the network architecture.\nThe input 3D point-cloud x of the scatterer of interest is first fed into the PointNet Encoder, shown in Figure 6. This component encodes the input point-cloud to an M- dimensional global feature vector. The next step is to learn a mapping from this feature vector, back to the original point- cloud. The architecture utilizes a variational auto-encoding approach to achieve this goal. The goal in variational auto- encoders is to learn an approximation $q(z|x)$ to the posterior distribution $p(z|x)$ for the training data set X, where data points x \u2208 X, when a known prior distribution such as the normal distribution $p(z) = N(\u03bc,\u03c3^2)$ is given. Therefore, given a data point x, the process can generate the code z ~ q(z|x), which approximates p(z|x) = N(\u03bc,\u03c3^2), the probability distribution over all possible values of the input x. This approach allows the model to learn a generative latent space for the scatterers, where samples from it are similar to the training data, and the statistical properties of the underlying distribution are interpretable, thanks to the approximation to the prior normal distribution. To draw a random sample from the learned latent z, the model utilizes a technique known as the \"reparametrization trick\". The sample z ~ q(z|x), where p(z|x) = N(\u03bc,\u03c3^2), can be reconstructed as z = \u03c3\u03b5 + \u03bc, where \u20ac ~ N(0, 1). This trick allows backpropagation to work with the random sampling involved, since the sampling is performed via the deterministic function z = \u03c3\u03b5 + \u03bc. The final step is to approximate x ~ p(x|z) with the generator multi- layer perceptron (MLP), which given a code z, reconstructs x as x. We refer the readers to [47] for further details and explanation.\n$KLD(P||Q) = \\sum_{x\u2208X} P(x)log \\frac{P(x)}{Q(x)}$\n$LOSS_{VAE} = CD(P_1, P_2) + KLD(p(z)||q(z|x))$", "eqs": ["KLD(P||Q) = \\sum_{x\u2208X} P(x)log \\frac{P(x)}{Q(x)}", "LOSS_{VAE} = CD(P_1, P_2) + KLD(p(z)||q(z|x))"]}, {"title": "IV. RESULTS AND DISCUSSION", "content": "In this section, we present the 3D reconstruction results obtained by the proposed framework.\nFor our experiments, we consider two cases. First, we evaluate the proposed method on the random smooth particle data set. We randomly generate 50000 random particles with the method described in Section III-A, then compute the scattered fields at 600 Hz, using the BEM solver. The fields are computed at 51 latitudinal and 101 longitudinal Gauss- Legendre quadrature coordinates. Next, we evaluate the pro- posed method on the airplane and cars classes of the popular 3D vision benchmark data set ShapeNet [39]. We first process the data set with the preprocessing step explained in Section III-A2. Then, we calculate the scattered fields at 750 Hz at the same Gauss-Legendre points as in the random particle data set. The cars contain 3146 samples and airplanes classes consists of 3227 sample. Objects from both classes are normalized into a bounding sphere with approximately r = 2m. The point clouds representing the scatterer meshes are sampled using the furthest point sampling algorithm, and the sample size is 2048. For the embedding size, we select M = 64 (see Section III). All neural network models use the LeakyReLU activation function, with the negative slope parameter set to 10-2. We optimize all models using the Adam optimizer with weight decay hyperparameter set to 10-4. In order to schedule the learning rate, we use a cosine annealing learning rate scheduler [48] and set the initial learning rate to 5e - 4. For each data set, we use a training-testing split ratio of 9: 1.\nAll experiments are run on a single node equipped with an Intel Xeon 8358 CPU with 256GB of memory and a single NVIDIA A100-40GB GPU."}, {"title": "B. Case 1: Random Particles", "content": "In this section, we discuss the evaluation results of the proposed framework, on the random particle data. This data set contains globally round and smooth objects with random local perturbations. These perturbations can result in sharp, non-convex and/or flat local features, which can have very distinct scattering properties. At a first glance, the variation in the random particle data set might look minor. However, indirectly differentiating the subtle local differences between shapes that globally agree is a challenging task in the context of a learning problem. We consider this step as a warm-up and tuning step for our experiments with ShapeNet data. In this experiment, we train the framework using both Loss Shape and Loss Far Field, as explained in Section III.\nWe first start by evaluating the forward network, trained with the random particle point-clouds and the corresponding scattered fields. Figure 7 shows the field reconstruction results for random particles drawn from the test set of 5000 samples. As it can be observed from the results, the forward network is able to capture the global structure of the scattered fields. However, local details are sometimes mispredicted and/or smoothened by the forward network. Figure 8 shows the error distribution for the test samples, evaluated by the forward net- work. For measuring the reconstruction error for the scattered fields, we use the relative L2-norm of the difference between the ground-truth scattered field $SCT_{gt}$ and the predicted scat- tered field $SCT_{pred}$, so $RelativeL_2 = \\frac{L_2(SCT_{gt} - SCT_{pred})}{L_2(SCT_{gt})}$. As it can be observed from the error distribution histogram, most reconstruction errors are accumulated around 5%.\nAfter verifying the reconstruction capability of the forward network, we continue with our experiment by training the shape auto-encoder and the inverse network, using the random particle data set. We aim to determine the effect of utilizing the forward pass to optimize the model. In order to do this, we use the loss function defined as $Loss_{Inverse} = LOSS_{Shape} + OFF \u00d7 LOSS_{FarField}$ (see Section III). Here OFF is a tunable hyperparameter that controls the amount of $Loss_{FarField}$ we want to include for the training procedure. Table I, shows the loss values for different OFF values of 0.0, 0.25, 0.50 and 0.75, as higher factors did not result in any improvements. As it can be seen from the loss values, using a composite loss of both shape and scattering data does not improve the results. Figure 9, shows the reconstruction results for the random particle data set, with the forward step bypassed by setting OFF = 0. We can see that the proposed framework is able to capture the global structure. However, we see a significant smoothing of sharp features. Note that we don't observe such degree of smoothing in the ShapeNet reconstructions, which are presented in the next subsection. Moreover, the Chamfer distance error distribution for 5000 reconstructed test shapes for the random particles data set shows that most reconstruction errors are accumulated around 0.03, which is a higher error average than both ShapeNet results (see Table I. This suggests that, despite ShapeNet dataset containing more complex structures, the random particles data set provides a more challenging learning task for the framework. This is due to the fact that the global structure of airplanes (the position of the wings, body, tail etc.) and that of cars (the position of the wheels, body, windshield etc.) are much more well-determined through-out the data set. This results in more predictable shape perturbations for different training samples. On the other hand, the random particles share the global spherical structure, but the local perturbations are much more unpredictable, increasing the random variation. Subsequently, this makes it more difficult to distinguish between two different samples in the data set.\nFinally, existing iterative methods such as [20] and ML methods like [30], [31] optimize their model parameters using solely $Loss_{FarField}$, which makes the forward pass essential for the methods. Our observations confirm that, in contrary, the shape reconstruction process in IASPs does not have to depend on the forward pass to produce high-quality results. The inverse network, a convolutional neural network equipped with non-linear activation functions, it is able to successfully learn the severely ill-posed and non-linear mapping between the scattering information and the scatterer shapes.", "eqs": ["RelativeL_2 = \\frac{L_2(SCT_{gt} - SCT_{pred})}{L_2(SCT_{gt})}"]}, {"title": "C. Case 2: ShapeNet", "content": "While the random particle data set provides a practical way of testing the proposed method, it doesn't contain any common objects from benchmark computer vision data sets that would allow us to make a more meaningful evaluation. The airplane and cars classes of the ShapeNet data set, help us to address this issue. Both classes contain very different shapes that have distinct complex features. Also, under the light of the results obtained in the previous section, we optimize the framework using $Lossshape$, bypassing the forward step completely. Figure 13 and Figure 14 show the reconstruction results for test samples drawn from the cars and airplane classes respectively. Note that the camera is rotated to a specific angle for each case, to demonstrate the differences between the reconstructions and the ground-truth data more effectively. The left column contains the ground-truth point clouds of the scatterers and the right column contains the reconstructed point clouds, by the proposed framework. We intentionally pick samples that belong to different subclasses, having either significant local and/or global structural differences. The framework is able to learn most global and local features, as it can be seen from the figures. For the cars class, we can easily see that a limousine (blue), a convertible (purple) and a truck (brown), which all have distinct features, are successfully reconstructed. However, we also observe subtle errors in the reconstructions. For example the number of seats in the convertible are not predicted correctly. Also, the corners of the roof in the truck example are not as sharp. These kind of reconstruction errors are observed throughout the test data set. However, as the framework is data-driven, these imperfections are expected and strongly depend on the training data too. Figure 11 shows the error (Chamfer Distance) distribution of 320 test samples from each data set. As it can be seen from the figure, most reconstruction errors are accumulated around 0.01.\nWith the airplanes class, we observe much more complex features and diversity amongst the scatterers. As it can be seen from Figure 14, the framework is able to successfully differentiate between the number and location of the jet propellers, and the global structure of the different aircraft. Again, we observe a loss of density and accuracy in the fighter jet (purple) and stealth bomber (brown) reconstructions. This is partly due to the fact that half of the data set consists of commercial airliners, which is also reflected in the error distribution in Figure 12, where the lower errors mostly belong to commercial airliner reconstructions, and there are much less examples of other aircraft types. Still, the framework is able to capture the overall global and local properties of the shape, like the tail-wings and sharp wing features in the fighter jet reconstruction. Figure 12 shows the error distribution of the test samples. Again, the errors are mostly accumulated around 0.01.\nLastly, we evaluate the performance of the proposed method, relative to the iteration time of the numerical solver utilized in [34]. To this end, we report the execution time of the numerical forward scattering solver, for the airplane object in the top row of Figure 1 at 750 Hz. The forward solver takes 954 seconds to complete on a single Intel(R) Xeon(R) Gold 6148 CPU. This would mean that a single iteration of the inverse shape optimization procedure for this airplane would approximately take 954 seconds. The proposed method, on the other hand, is able to compute the predictions for 322 airplane objects in the test data, in 18 seconds (0.056 sec/airplane). This is several orders of magnitude faster, rendering the proposed framework appealing to a wide range of practical applications."}, {"title": "V. CONCLUSION", "content": "In this paper, we have demonstrated ISSRNet, a deep learn- ing framework for solving the 3D inverse acoustic scattering for shape reconstruction problem. Using a convolutional neural network, ISSRNet encodes the scattering far-field data into a latent space. Then it maps this scattering latent space, to the 3D shape latent space, which is learned by a 3D variational auto-encoder. ISSRNet only requires data from a single incident wave, at a single frequency and performs orders of magnitudes faster than a traditional iterative method, while still capturing both global and local shape details about complex scatterers. Moreover, in contrast to existing iterative and machine learning solutions, ISSRNet does not depend on the forward solution for the scattering problem. We evaluate the proposed framework on both a synthetic random 3D shape data set with a high amount of random surface variation; as well as the cars and airplanes classes of the popular 3D shape data set ShapeNet. As is evident, the results are extremely promising, while leaving room for improvement to capture finer grained details. These improvements include, using multiple frequencies to interrogate the object, using multiple incident field data, better shape descriptors through a more physics-aware encoder and/or loss function and so on. These will be topics that will be discussed in subsequent papers."}]}