{"title": "Robust and Reliable Early-Stage Website Fingerprinting Attacks via Spatial-Temporal Distribution Analysis", "authors": ["Xinhao Deng", "Qi Li", "Ke Xu"], "abstract": "Website Fingerprinting (WF) attacks identify the websites visited\nby users by performing traffic analysis, compromising user pri-\nvacy. Particularly, DL-based WF attacks demonstrate impressive\nattack performance. However, the effectiveness of DL-based WF\nattacks relies on the collected complete and pure traffic during the\npage loading, which impacts the practicality of these attacks. The\nWF performance is rather low under dynamic network conditions\nand various WF defenses, particularly when the analyzed traffic is\nonly a small part of the complete traffic. In this paper, we propose\nHolmes, a robust and reliable early-stage WF attack. Holmes uti-\nlizes temporal and spatial distribution analysis of website traffic\nto effectively identify websites in the early stages of page loading.\nSpecifically, Holmes develops adaptive data augmentation based on\nthe temporal distribution of website traffic and utilizes a supervised\ncontrastive learning method to extract the correlations between the\nearly-stage traffic and the pre-collected complete traffic. Holmes\naccurately identifies traffic in the early stages of page loading by\ncomputing the correlation of the traffic with the spatial distribution\ninformation, which ensures robust and reliable detection according\nto early-stage traffic. We extensively evaluate Holmes using six\ndatasets. Compared to nine existing DL-based WF attacks, Holmes\nimproves the F1-score of identifying early-stage traffic by an av-\nerage of 169.18%. Furthermore, we replay the traffic of visiting\nreal-world dark web websites. Holmes successfully identifies dark\nweb websites when the ratio of page loading on average is only\n21.71%, with an average precision improvement of 169.36% over the\nexisting WF attacks.", "sections": [{"title": "1 Introduction", "content": "Tor [12] is the most popular anonymous communication system,\nboasting millions of active daily users [28]. Tor utilizes various\nmechanisms, including randomly selected relays and multi-layer\nencryption, to anonymize user browsing behaviors. Unfortunately,\nTor is vulnerable to Website Fingerprinting (WF) attacks [2, 10,\n21, 35, 36, 39, 40]. WF attacks utilize Machine Learning (ML) or\nDeep Learning (DL) models to extract unique traffic patterns of\nwebsites and effectively identify the websites visited by Tor users. In\nparticular, existing DL-based WF attacks demonstrate outstanding\nattack performance, achieving over 95% accuracy [10, 37, 39, 40].\nWF attacks on Tor traffic are challenging, yet these attacks can also\nbe successfully applied to other privacy-preserving systems [11, 47].\nThe DL-based WF attacks heavily rely on the collected com-\nplete and pure traffic during the page loading for traffic analysis. In\npractice, adversaries cannot perceive the entire process of website\nloading traffic due to mixed background traffic. Existing WF attacks\napply fixed conditions for traffic collection [10, 36, 37, 39, 40]. These\nsettings do not consider the differences between websites and may\ncompromise the attack performance, e.g., the adversary can only\ncollect partial traffic from slow-loading websites. Particularly, poor\nnetwork conditions and WF defenses also prevent the adversary\nfrom effectively collecting the complete pure traffic of page load-\ning, leading to a significant decrease in attack performance against\ncertain websites [23]. Our study shows that the robust WF attack\n(i.e., DF) achieves an average precision of over 91% for all web-\nsites under the WTF-PAD defense. Notably, the lowest precision of\nfingerprinting is only less than 55%.\nTo address the limitations of existing DL-based WF attacks, we\naim to develop an effective WF attack, i.e., the early-stage WF attack,\nthat only utilizes the traffic generated from the early stage of page\nloading. The early-stage WF attack can identify the visited website\nduring early-stage page loading. As shown in Figure 1, compared\nwith existing WF attacks, the early-stage attack does not require\nwaiting for the complete traffic of page loading. However, there are\nthree critical challenges in constructing the early-stage WF attack.\n(i) Early-stage traffic under dynamic network conditions is prone\nto traffic misidentification. Dynamic network conditions refer to"}, {"title": "2 Background & Problem Statement", "content": "Website fingerprinting (WF) attacks identify the websites visited\nby Tor users by analyzing traffic patterns, such as packet sizes and"}, {"title": "2.1 Background", "content": "timing information. Previous WF attacks extract fingerprinting\nfeatures from traffic based on expert knowledge and employ Ma-\nchine Learning (ML) models to classify these features for website\nidentification [18, 32, 43]. However, features extracted based on\nexpert knowledge can be easily compromised by defenses [23].\nWith the advancement of deep learning (DL), DL-based WF attacks\nachieve automated feature extraction and significantly enhance\nperformance [3, 36, 39]. DL-based WF attacks can effectively iden-\ntify websites in various real-world scenarios, such as multi-tab\nbrowsing [10, 21, 46], under defenses [35, 37], dynamic network\nenvironments [2], and concept drift [40]. However, reliance on the\ncollection of pure traffic throughout the entire page loading hin-\nders the real-world deployment of WF attacks. Holmes achieves\nearly-stage WF attacks by utilizing both the temporal and spatial\ndistributions of website traffic.\nWebsite fingerprinting (WF) defenses aim to undermine the ef-\nfectiveness of WF attacks. Existing defenses mainly fall into two\ncategories: disturbing traffic and splitting traffic. The defenses for\ndisturbing traffic involve padding dummy packets [16, 23], delay-\ning packets [19, 44], inserting adversarial perturbations [30] and\nobfuscating traffic [31]. However, the significant overhead of de-\nfenses may affect the operation of relay nodes [7]. Only a variant\nof the lightweight defense WTF-PAD has been deployed in the Tor\nnetwork [1]. Traffic splitting defenses involve splitting traffic into\nmultiple paths so that the adversary can only collect a portion of\nthe packets, thereby obscuring the traffic patterns [8]. We evaluate\nthe robustness of Holmes against existing defenses in Section 6.4."}, {"title": "2.2 Problem Statement", "content": "The goal of this paper is to develop reliable WF attacks (i.e., accu-\nrately identifying all websites) based on the traffic in the early stage\nof page loading. Previous WF attacks rely on collecting pure traffic\nthroughout the entire page load process. However, under dynamic\nnetwork conditions or defenses, existing attacks cannot effectively\ncollect complete traffic from all websites. Meanwhile, increasing\nthe traffic collection time incurs more noise from background traf-\nfic or defenses, which further impacts the WF performance. We\nanalyze the SOTA multi-tab attack ARES [10] and the robust attack\nDF [39]. ARES and DF achieve over 90% average precision in the\npresence of obfuscated traffic under multi-tab browsing and WTF-\nPAD defenses, respectively. We find that the minimum precision of\nfingerprinting achieved by ARES and DF is only 42.86% and 54.11%,\nrespectively."}, {"title": "3 Threat Model", "content": "This paper aims to develop an early-stage website fingerprinting\nattack that can identify websites visited by Tor users based on the\ntraffic in the early stages of page loading. In particular, early-stage\nWF attacks can identify websites while the Tor user is still waiting\nfor the page to fully load. In Figure 3, we show the threat model of\nour early-stage WF attack. Similar with previous works [2, 10, 18, 21,\n32, 35, 36, 39, 40], we consider a local and passive adversary for Tor,\nsuch as network administrators, Internet Service Providers (ISPs),\nand Autonomous Systems (AS). The adversary can only collect\npackets without the capability to decrypt packets. Specifically, a\npassive adversary is unable to detect the end of a webpage loading,\nand can only configure fixed conditions for traffic collection [10, 36,"}, {"title": "4 Design of Holmes", "content": "In this section, we present the key observation for our design and\npropose a robust and reliable early-stage WF attack."}, {"title": "4.1 Key Observation", "content": "As discussed in Section 2.2, identifying websites by analyzing single\nearly-stage traffic is challenging due to dynamic network conditions\nand deployed defenses. Particularly, the loaded content during the\nsame loading interval varies under different network conditions.\nHowever, we observe a strong correlation between the early-stage\ntraffic and the pre-collected complete traffic of the same website,\nboth of which invariably contain the same website information,\nincluding parts of the website content and elements.\nFigure 4 illustrates the distribution of website information across\ndifferent stages of page loading, i.e., the temporal distribution of\nthe website features. For simplicity without losing generality, we\nrandomly select 20 websites from the Alexa-top 95 websites. We\ncannot directly analyze the website information corresponding to\nthe encrypted packets. Thus, we measure the importance of traffic\nfeatures for each page loading stage based on the feature attribution\nmethod, i.e., SHAP [27]. The importance of traffic features refers to\ntheir contribution to website identification. The more website in-\nformation contained in the page loading stage, the more important\nthe corresponding traffic features. We observe that the early-stage\ntraffic of all websites shares similar sufficient website information\nwith the complete traffic. Therefore, it is possible for us to achieve"}, {"title": "4.2 Overview of Holmes", "content": "In this paper, we propose Holmes that exploits the correlations be-\ntween the early-stage traffic and the pre-collected complete traffic\nto achieve early-stage WF attacks. Particularly, Holmes captures\nthe spatial and temporal distribution of different websites so that it\ncan accurately fingerprint the traffic according to a small amount\nof the traffic visiting the websites, even under varied network con-\nditions and WF defenses. Holmes first performs data augmentation\nbased on the unique temporal distribution of traffic features for\neach website, which generates early-stage traffic that contains suf-\nficient website information. Second, Holmes utilizes Supervised\nContrastive Learning (SCL) [24] to transform traffic features into a\nlow-dimensional embedding space, where each flow of traffic corre-\nsponds to a point in the space. SCL extracts the correlation between\nearly-stage and complete traffic of the same website by clustering\nthe points of early-stage and complete traffic in the embedding\nspace. Finally, Holmes projects unknown early-stage traffic into the\nembedding space and calculates its correlation with each website\nbased on the spatial distribution of website traffic in the embedding\nspace. Note that, to avoid misidentification of early-stage traffic\ncontaining only connection information, Holmes rejects results of\nidentifying early-stage traffic with low correlations to all websites.\nTherefore, Holmes performs attacks at each short time interval\nof traffic collection until the corresponding website is identified\nwith high confidence, thus enabling adaptive traffic collection and\nreliable identification for each website.\nFigure 5 illustrates the overview of Holmes. Holmes consists\nof three modules designed to construct robust and reliable early-\nstage WF attacks, including adaptive data augmentation, spatial\ndistribution analysis, and early-stage website identification.\nAdaptive Data Augmentation. The adaptive data augmentation\nmodule generates early-stage traffic by masking the tail of complete\ntraffic during the training phase, which ensures that early-stage\ntraffic contains sufficient website information based on the unique\ntemporal distribution of the website. Holmes employs the feature\nattribution method, i.e., SHAP [27], to analyze the temporal distri-\nbution of the website traffic. It aggregates the feature attribution\nresults of multiple traffic associated with the same websites to ob-\ntain the feature importance distribution of the website. Holmes\nleverages the temporal distribution of websites to apply tail mask-\ning of various lengths for the traffic of different websites so that\nit can adaptively generate early-stage traffic containing sufficient\nwebsite information for each website. The details of this module\nwill be described in Section 5.1.\nSpatial Distribution Analysis. The spatial distribution analysis\nmodule utilizes supervised contrastive learning to transform traffic\nfeatures and computes the spatial distribution of websites according\nto the new feature space. To effectively extract the correlation\nbetween early-stage traffic and complete traffic, Holmes utilizes\nan encoder built on supervised contrastive learning to transform\ntraffic features into low-dimensional embedding features, ensuring\nthat the embedding features corresponding to the early-stage and"}, {"title": "5 Design Details", "content": "In this section, we present the design details of Holmes, including\nthe adaptive data augmentation module, the spatial distribution\nanalysis module, and the early-stage website identification module."}, {"title": "5.1 Adaptive Data Augmentation", "content": "The Adaptive Data Augmentation module generates traffic at dif-\nferent stages of page loading based on masked tail traffic, thereby\nfacilitating the analysis of the correlation between early-stage traf-\nfic and complete traffic. However, randomly generated early-stage\ntraffic may not contain sufficient website information. The reason\nis that due to network dynamic conditions and defenses, randomly\ngenerated early-stage traffic may only contain connection infor-\nmation and dummy packets. Furthermore, differences in website\nloading speed can also affect the correlation between the generated\nearly-stage traffic and the complete traffic. To achieve website-\nadaptive data augmentation, Holmes utilizes the feature attribution\nmethod to analyze the temporal distribution of traffic features, en-\nsuring that the generated early-stage traffic is correlated with the\ncomplete traffic of the same website.\nTemporal Distribution Analysis. Holmes analyzes the temporal\ndistribution by profiling the feature importance, which is challeng-\ning for two reasons: (i) Packets are encrypted in multiple layers by\nTor, making it difficult to analyze their importance. (ii) In dynamic\nnetwork environments or under traffic obfuscation by defenses, the\npositions of important packets may change.\nTo address these challenges, we extend the feature attribution\nmethod SHapley Additive exPlanations (SHAP) [27] to analyze the\nfeature importance distribution at different stages of page loading.\nSHAP calculates the marginal contribution of each feature by gen-\nerating combinations of all features. It is based on Shapley values, a\nconcept from cooperative game theory, which ensures a fair distri-\nbution of the contribution among the features. SHAP provides local\nexplanations showing how much each feature in a specific instance\ncontributes to the model's output, as well as global insights about\nthe overall model behavior.\nThe advantages of SHAP over other feature attribution meth-\nods include (i) Accuracy. SHAP calculates all feature combinations,\nwhich enables effective analysis of the relationships among fea-\ntures in encrypted traffic, resulting in more accurate attribution\noutcomes. (ii) Consistency. SHAP provides consistent feature attri-\nbution results for multiple traffic to the same website. Therefore,\nHolmes can aggregate the feature attribution results of multiple\ntraffic to obtain a website-level distribution of feature importance.\nLet $U = \\{f_1, f_2, ..., f_n\\}$ represent the feature set of traffic, where\n$n$ is the number of features. Holmes divides the page loading time\ninto $n$ equal time intervals and counts the number of incoming\nand outgoing packets in each interval as traffic features, where $f_i$"}, {"title": "5.2 Spatial Distribution Analysis", "content": "Utilizing the early-stage traffic generated by the temporal distri-\nbution analysis module, the spatial distribution analysis module\nextracts the correlation between early-stage and complete traf-\nfic. Specifically, Holmes builds an Encoder based on Supervised\nContrastive Learning (SCL) [24] to extract common features of\nearly-stage and complete traffic, generating low-dimensional em-\nbeddings that are spatially proximate. Then Holmes analyzes the\nspatial distribution of websites using the Median Absolute Devia-\ntion (MAD) [25].\nTraffic Embedding Based on SCL. To address the challenges\nposed by network jitter and defenses in the real world on the anal-\nysis of early-stage traffic, Holmes employs Supervised Contrastive\nLearning (SCL) for traffic embedding. The generated embeddings"}, {"title": "Algorithm 1: Website Profiling", "content": "Input:\nW: all websites.\nz: the embeddings of all websites.\nOutput:\nc: the centroids of all websites.\nr: the radii of all websites.\n1 for $w \\in W$ do\n2  $c_w = Mean(z_w)$ \u25ba Calculate the centroid of website w\n3  for $z \\in z_w$ do\n4   $d = 1 - cosine\\_similarity(c_w, z)$\n5  end\n6  $M_W = Median \\{d\\}$ \u25ba Calculate the median\n7  $r_w = Median\\{\\vert d_y - M_W \\vert\\}$ \u25ba Calculate the radius\n8 end\n9 for $w_i, w_j \\in W$ do\n10  $d = 1 - cosine\\_similarity(c_i, c_j)$\n11  if $r_i + r_j \\geq d$ then\n12   \u25ba Tuning the radius\n13   $r_i = r_i - \\frac{r_i}{r_i+r_j}(r_i+r_j-d)$\n14   $r_j = r_j - \\frac{r_j}{r_i+r_j}(r_i+r_j - d)$\n15  end\n16 end\n17 return c, r\nanchor\u2019s corresponding website as positive samples and traffic of\nother websites as negative samples. Holmes repeats this process\nmultiple times to ensure that the selected anchors include multiple\ntraffic for all websites.\nSCL can learn various correlations between the anchor and the\npositive samples, ensuring that in the generated embedding space,\nthe distance between the anchor and positive samples is close,\nwhile the distance between the anchor and negative samples is far.\nFormally, for the i-th traffic $x_i$ with embedding $z_i$, we can calculate\nits loss by SCL:\n$L_i = - \\frac{1}{\\vert P(i)\\vert} \\sum_{p \\in P(i)} log \\frac{exp(z_i \\cdot z_p / \\gamma)}{\\sum_{n \\in N(i)} exp(z_i \\cdot z_n / \\gamma)}$\nwhere $P(i)$, $N(i)$ are the set of the index of all positive samples and\nnegative samples of the i-th traffic, respectively. For the embedding\nof anchor $z_i$, we calculate the similarity with each positive sample\nembedding $z_p$ and compare it with similarities between the anchor\nand all negative samples. In particular, $\\gamma$ is temperature, a hyper-\nparameter that controls the distance of traffic $x_i$ from the most\nsimilar negative sample. The smaller the temperature $\\gamma$, the greater\nthe differentiation from the negative samples, but it tends to affect\nthe similarity to the positive samples. Through Equation 4, we can\neffectively train the Encoder and extract the correlations of website\ntraffic at different loading stages.\nSpatial Distribution Based on MAD. Holmes aims to achieve\nreliable early-stage website identification. However, the early-stage\ntraffic contains little website information and is prone to misidenti-\nfication under the interference of network dynamics and defenses.\nHolmes addresses the challenge by utilizing the spatial distribu-\ntion of website traffic. Traffic from different websites has different"}, {"title": "5.3 Early-Stage Website Identification", "content": "The early-stage website identification module leverages the correla-\ntions between different loading stages of website traffic to achieve\nrobust and reliable identification of early-stage traffic. To achieve\nearly-stage website identification, Holmes attempts website identifi-\ncation at each fixed time interval. The challenge faced by Holmes is\nensuring high confidence in website identification to avoid misiden-\ntification of early-stage traffic. To address the above challenge,\nHolmes calculates the correlation between unknown traffic and\nmonitored websites based on the position of unknown traffic in the\nfeature space and the spatial distribution of monitored websites.\nHolmes rejects the identification of early-stage traffic with low\ncorrelation to all monitored websites and continues to collect more\npackets.\nIn Algorithm 2, we show the pseudocode for early-stage web-\nsite identification. At every time interval, Holmes first projects the\nunknown early-stage traffic into the embedded space (lines 6-7)\nand calculates the distance between the unknown traffic and the"}, {"title": "Algorithm 2: Early-stage Website Identification", "content": "Input:\n$\\tau$: the time interval.\n$\\sigma$: the maximum traffic collection time.\nW: all monitored websites.\nc: the centroids of all monitored websites.\nr: the radii of all monitored websites.\n$\\widehat{w}$: the unmonitored website.\n$\\epsilon$: threshold for concept drift detection.\nOutput:\nres: the identification result.\n1 res = $\\widehat{w}$\n2 count = 0\n3 while True do\n4  time.sleep($\\tau$) \u25ba Wait time interval $\\tau$\n5  count = count + $\\tau$\n6  x = getTraffic() \u25ba Get the current collected traffic\n7  z = Encoder(x)\n8  for w $\\in$ W do\n9   d = 1 - cosine\\_similarity(c_w, z)\n10   if d $\\leq$ $r_w$ then\n11    res = w \u25ba Identification success\n12    break\n13   end\n14  end\n15  if (res $\\neq$ w) or (count > $\\sigma$) then\n16   break \u25ba Exit identification\n17  end\n18 end\n19 if res == $\\widehat{w}$ then\n20  $d_{min} = \\epsilon$\n21  for w $\\in$ W do\n22   d = 1 - cosine\\_similarity(c_w, Z)\n23   if d - $r_w < d_{min}$ then\n24    $d_{min} = d -r_w$\n25    res = W\n26   end\n27  end\n28 end\n29 return res\ncentroids of all monitored websites (lines 8-9). If the distance be-\ntween the unknown traffic and a website's centroid is less than\nthe radius of the website, Holmes successfully identifies the traffic\n(lines 10-12). Otherwise, Holmes continues to collect traffic and\nwaits for the next time interval.\nHowever, not all early-stage traffic can be guaranteed to be iden-\ntified. Changes in the content of monitored websites can lead to vari-\nations in traffic patterns (i.e., concept drift). Furthermore, Holmes\nis unable to detect early-stage traffic from unmonitored websites.\nHolmes sets a maximum traffic collection time $\\sigma$. After collecting\ntraffic for $\\sigma$ seconds, Holmes will detect whether the unknown traf-\nfic is due to concept drift or originates from unmonitored websites\n(lines 19-28). A key insight is that the distance between a website's\nconcept drift traffic and its centroid should be slightly greater than\nthe website's radius, yet much smaller than the distance between\nunmonitored website traffic and the website's centroid. Therefore,"}, {"title": "6 Performance Evaluation", "content": "In this section, we evaluate Holmes with public datasets and real-world datasets. We compare the performance of Holmes with the\nstate-of-the-art WF attacks."}, {"title": "6.1 Experimental Setup", "content": "Implementation. We prototype Holmes using PyTorch 2.0.1 and\nPython 3.8 with more than 1,400 lines of code. In particular, we use\na single NVIDIA GeForce RTX 4090 GPU for our experiments. We\nshow the default parameter values in Table 1. Furthermore, we split\nthe dataset into training, validation, and testing, with an 8:1:1 ratio.\nThe parameter tuning and spatial-temporal analysis are performed\non the validation dataset to avoid leakage of the testing dataset.\nDataset. Our datasets comprise six categories of data, including a\ndataset of Alexa-top websites, a dataset of dark web websites, and\nfour types of defended datasets.\n\u2022 Dataset of Alexa-top websites: This dataset is from [39], which\nincludes data from both closed-world and open-world scenarios.\nThe closed-world data comprises 95 monitored websites, each\nwith over 1000 traces. In the open-world scenario, there are over\n40,000 unmonitored websites, each with only one trace. All web-\nsites belong to the Alexa-top websites list, which ranks websites\nbased on popularity.\n\u2022 Dataset of dark web websites: Since Alexa-top does not repre-\nsent the popularity of visits by Tor users, we select 80 of the most\npopular dark web websites based on the measurement of Tor v3"}, {"title": "Table 1: Parameter settings in our evaluation", "content": "Parameter settings in our evaluation"}, {"title": "6.2 Closed-World Evaluation", "content": "We first evaluate the performance of Holmes in the closed-world\nscenario using the dataset of Alexa-top 95 websites. To assess the\nperformance of Holmes in identifying early-stage website traffic,\nwe generate traffic for different loading stages of websites based\non packet timestamps from the testing dataset. As shown in Fig-\nure 8, Holmes achieves optimal attack performance under different\npage loading ratios. As the loading progress of websites increases\nfrom 20% to full completion, the Accuracy of Holmes in identify-\ning the website gradually improves, rising from 50.94% to 98.36%.\nCompared to existing attacks, Holmes demonstrates a significant ad-\nvantage in early-stage traffic analysis. For example, when websites\nare 40% loaded, Holmes achieves an Accuracy of 90.65%, which\nrepresents an improvement of 26.84%, 90.68%, 109.50%, 140.32%,\n175.36%, 194.22%, 224.68%, 235.12%, and 323.60% over RF, Var-CNN,\nARES, NetCLR, DF, Tik-tok, TMWF, AWF, and TF, respectively.\nSpecifically, Holmes exhibits the highest Accuracy for traffic at"}, {"title": "Figure 8: Comparison of WF attacks at different loading", "content": "stages of websites in the closed-world scenario."}, {"title": "6.3 Open-World Evaluation", "content": "We further evaluate the realistic open-world scenario using the\ndataset of Alexa-top websites, including 95 monitored websites\nand 40,000 unmonitored websites. The number of unmonitored\nwebsites significantly exceeds the number of monitored websites. To\neffectively assess attack performance in the open-world setting, we\nfollow previous works [42] by utilizing r-precision for evaluation.\nFigure 9 shows the comparison of r-precision for WF attacks\nwhen the ratio of page loading ranges from 30% to 60%. Holmes\nconsistently achieves high r-precision across different page load-\ning ratios. Compared to existing attacks, Holmes demonstrates a\nsignificant advantage in identifying early-stage traffic in the open-\nworld scenario. For example, when the ratio of page loading is 40%,\nHolmes achieves the r-precision of 94.96%, while the F1-scores\nfor RF, Var-CNN, ARES, NetCLR, DF, Tik-tok, TMWF, AWF, and TF\nare 83.77%, 71.72%, 56.99%, 51.49%, 49.33%, 51.26%, 38.46%, 31.31%,\nand 26.06%, respectively. When websites are loaded to 30%, 40%,\n50%, and 60%, the r-precision of Holmes shows an average in-\ncrease of 130.61%, 109.91%, 79.00%, and 57.62% over existing attacks,\nrespectively.\nThe experimental results demonstrate that Holmes can effec-\ntively distinguish between early-stage traffic from monitored and\nunmonitored websites in the open-world scenario. Particularly,\nHolmes reduces training overhead compared to baselines by elim-\ninating the requirement for training samples from unmonitored\nwebsites. Holmes leverages the spatial distribution of monitored\nwebsites in the feature space. By comparing the distance of un-\nknown traffic in the feature space to the centroid of the website\nand the website's radius, Holmes achieves early-stage WF attacks\nwith high precision in the open-world scenario."}, {"title": "6.4 Robustness Evaluation", "content": "Next, we evaluate the robustness of Holmes using datasets of Alexa-top 95 websites with four defenses. In Figure 10, we demonstrate\nthe accuracy of WF attacks in different loading stages of websites\nunder defenses.\nAs shown in Figure 10(a), for the WTF-PAD defense, Holmes\nachieves the best accuracy across all ratios of page loading. For\nearly-stage traffic, Holmes is more robust compared to other attacks.\nWhen the page loading ratio is 40%, Holmes achieves an accuracy of"}, {"title": "6.5 Reliability Evaluation", "content": "The page loading speeds vary significantly across different websites,\nmaking it difficult to ensure high precision in detecting early-stage\ntraffic of all websites. Therefore, we use the minimum precision\namong all websites (i.e., P@min) to evaluate the reliability of WF\nattacks on early-stage traffic.\nFigure 11 illustrates the reliability of WF attacks under WTF-PAD defense. We use the dataset of Alexa-top 95 websites with\nWTF-PAD defense for evaluation because the variation of WTF-PAD defense based on circuit-level padding has been practically\ndeployed in Tor [1]. When the page loading ratio is 60%, Holmes\nachieves the best P@min of 70.25%, while Var-CNN, ARES, Net-CLR, DF, Tik-tok, TMWF, AWF, and TF have the P@min of 0. The\nP@min equals 0 means there are websites that these WF attacks\ncannot identify. For traffic at page loading rates of 80% and 100%, Holmes achieves an average P@min improvement of 299.43% and\n160.60% over baselines, respectively. We find that multi-tab WF"}, {"title": "6.6 Real-World Evaluation", "content": "Next, we evaluate Holmes using the dataset of 80 dark web web-sites collected from the real world. Alexa-top websites are widely\nused for evaluating WF attacks [10, 36, 37, 39, 40]. However, the\nranking of Alexa-top websites is based on the interests of all inter-net users, which may not accurately represent the interests of Tor\nusers in the real world. Based on the measurements of Tor onion\nservices [41], we selected 80 of the most popular dark web websites.\nWe utilized 20 servers deployed across three different countries to\ncollect dark web traffic in August 2023 and April 2024. Therefore,\nthis dataset encompasses traffic under various network conditions\nand traffic exhibiting concept drift due to changes in the websites.\nWe replay packets of testing traffic to evaluate the time overhead\nand performance of different WF attacks. Moreover, the adversary\ncannot know the end time of the page loading in advance. We set\nup baselines to end traffic collection when the number of packets\nmeets the input requirements or when no new packets are collected\nwithin 1 second. Particularly, we use one NVIDIA GeForce RTX\n4090 to accelerate the inference of DL models.\nTable 3 shows the comparison of WF attacks using the dataset of\ndark web websites in the real-world evaluation. The attack latency\nrefers to the average time taken to collect and identify unknown\ntraffic, while the loading ratio represents the average page loading\nratio when the website identification result is obtained from the\nWF attack. In particular, we optimize the best-performing attack\nRF. RF30% represents RF attacks with the packet sequence lengths\nreduced to 30% of the original length. We adjust the input sequence\nlengths of the RF and retrain the models. Reducing the input length\nsignificantly optimizes latency, but also compromises the identifi-cation precision of RF. We find that compared to existing attacks\nand enhanced RF, Holmes exhibits the best attack efficiency and\nidentification precision. Specifically, Holmes reduces latency by an\naverage of 66.33% and improves precision by an average of 169.36%\ncompared to baselines.\nDark web websites utilize onion services for server anonymiza-tion, requiring more Tor relays and additional time overhead to\nload. We additionally use the dataset of Alexa-top websites under\nWTF-PAD defense for real-world evaluation. Holmes outperforms\nexisting attacks and enhanced RF in terms of latency and perfor-mance. For Alexa-top websites, Holmes reduces latency by an av-erage of 66.38% and increases precision by an average of 32.32%\ncompared to baselines. Holmes's advantages are attributed to adap-tive data augmentation for different websites and leveraging the\nspatial distribution of websites for adaptive traffic collection and\nhigh-precision website identification."}, {"title": "6.7 Comparison with Enhanced Baselines", "content": "In this section, we enhance the baselines and compare them with\nHolmes. Similar to the data augmentation module of Holmes, we\ngenerate early-stage traffic by masking the tail of the traffic with\nrandom lengths, which is added to the training datasets of baselines.\nWe evaluate the accuracy of WF attacks on early-stage traffic using\nthe dataset of the Alexa-top 95 websites. As shown in Figure 12,\nHolmes maintains a significant advantage in identifying early-stage\ntraffic compared to the enhanced baselines"}]}