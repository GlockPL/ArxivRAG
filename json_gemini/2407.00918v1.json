{"title": "Robust and Reliable Early-Stage Website Fingerprinting Attacks via Spatial-Temporal Distribution Analysis", "authors": ["Xinhao Deng", "Qi Li", "Ke Xu"], "abstract": "Website Fingerprinting (WF) attacks identify the websites visited\nby users by performing traffic analysis, compromising user pri-\nvacy. Particularly, DL-based WF attacks demonstrate impressive\nattack performance. However, the effectiveness of DL-based WF\nattacks relies on the collected complete and pure traffic during the\npage loading, which impacts the practicality of these attacks. The\nWF performance is rather low under dynamic network conditions\nand various WF defenses, particularly when the analyzed traffic is\nonly a small part of the complete traffic. In this paper, we propose\nHolmes, a robust and reliable early-stage WF attack. Holmes uti-\nlizes temporal and spatial distribution analysis of website traffic\nto effectively identify websites in the early stages of page loading.\nSpecifically, Holmes develops adaptive data augmentation based on\nthe temporal distribution of website traffic and utilizes a supervised\ncontrastive learning method to extract the correlations between the\nearly-stage traffic and the pre-collected complete traffic. Holmes\naccurately identifies traffic in the early stages of page loading by\ncomputing the correlation of the traffic with the spatial distribution\ninformation, which ensures robust and reliable detection according\nto early-stage traffic. We extensively evaluate Holmes using six\ndatasets. Compared to nine existing DL-based WF attacks, Holmes\nimproves the F1-score of identifying early-stage traffic by an av-\nerage of 169.18%. Furthermore, we replay the traffic of visiting\nreal-world dark web websites. Holmes successfully identifies dark\nweb websites when the ratio of page loading on average is only\n21.71%, with an average precision improvement of 169.36% over the\nexisting WF attacks.", "sections": [{"title": "1 Introduction", "content": "Tor [12] is the most popular anonymous communication system,\nboasting millions of active daily users [28]. Tor utilizes various\nmechanisms, including randomly selected relays and multi-layer\nencryption, to anonymize user browsing behaviors. Unfortunately,\nTor is vulnerable to Website Fingerprinting (WF) attacks [2, 10,\n21, 35, 36, 39, 40]. WF attacks utilize Machine Learning (ML) or\nDeep Learning (DL) models to extract unique traffic patterns of\nwebsites and effectively identify the websites visited by Tor users. In\nparticular, existing DL-based WF attacks demonstrate outstanding\nattack performance, achieving over 95% accuracy [10, 37, 39, 40].\nWF attacks on Tor traffic are challenging, yet these attacks can also\nbe successfully applied to other privacy-preserving systems [11, 47].\nThe DL-based WF attacks heavily rely on the collected com-\nplete and pure traffic during the page loading for traffic analysis. In\npractice, adversaries cannot perceive the entire process of website\nloading traffic due to mixed background traffic. Existing WF attacks\napply fixed conditions for traffic collection [10, 36, 37, 39, 40]. These\nsettings do not consider the differences between websites and may\ncompromise the attack performance, e.g., the adversary can only\ncollect partial traffic from slow-loading websites. Particularly, poor\nnetwork conditions and WF defenses also prevent the adversary\nfrom effectively collecting the complete pure traffic of page load-\ning, leading to a significant decrease in attack performance against\ncertain websites [23]. Our study shows that the robust WF attack\n(i.e., DF) achieves an average precision of over 91% for all web-\nsites under the WTF-PAD defense. Notably, the lowest precision of\nfingerprinting is only less than 55%.\nTo address the limitations of existing DL-based WF attacks, we\naim to develop an effective WF attack, i.e., the early-stage WF attack,\nthat only utilizes the traffic generated from the early stage of page\nloading. The early-stage WF attack can identify the visited website\nduring early-stage page loading. As shown in Figure 1, compared\nwith existing WF attacks, the early-stage attack does not require\nwaiting for the complete traffic of page loading. However, there are\nthree critical challenges in constructing the early-stage WF attack.\n(i) Early-stage traffic under dynamic network conditions is prone\nto traffic misidentification. Dynamic network conditions refer to"}, {"title": "2 Background & Problem Statement", "content": "Website fingerprinting (WF) attacks identify the websites visited\nby Tor users by analyzing traffic patterns, such as packet sizes and"}, {"title": "2.1 Background", "content": "timing information. Previous WF attacks extract fingerprinting\nfeatures from traffic based on expert knowledge and employ Ma-\nchine Learning (ML) models to classify these features for website\nidentification [18, 32, 43]. However, features extracted based on\nexpert knowledge can be easily compromised by defenses [23].\nWith the advancement of deep learning (DL), DL-based WF attacks\nachieve automated feature extraction and significantly enhance\nperformance [3, 36, 39]. DL-based WF attacks can effectively iden-\ntify websites in various real-world scenarios, such as multi-tab\nbrowsing [10, 21, 46], under defenses [35, 37], dynamic network\nenvironments [2], and concept drift [40]. However, reliance on the\ncollection of pure traffic throughout the entire page loading hin-\nders the real-world deployment of WF attacks. Holmes achieves\nearly-stage WF attacks by utilizing both the temporal and spatial\ndistributions of website traffic.\nWebsite fingerprinting (WF) defenses aim to undermine the ef-\nfectiveness of WF attacks. Existing defenses mainly fall into two\ncategories: disturbing traffic and splitting traffic. The defenses for\ndisturbing traffic involve padding dummy packets [16, 23], delay-\ning packets [19, 44], inserting adversarial perturbations [30] and\nobfuscating traffic [31]. However, the significant overhead of de-\nfenses may affect the operation of relay nodes [7]. Only a variant\nof the lightweight defense WTF-PAD has been deployed in the Tor\nnetwork [1]. Traffic splitting defenses involve splitting traffic into\nmultiple paths so that the adversary can only collect a portion of\nthe packets, thereby obscuring the traffic patterns [8]. We evaluate\nthe robustness of Holmes against existing defenses in Section 6.4."}, {"title": "2.2 Problem Statement", "content": "The goal of this paper is to develop reliable WF attacks (i.e., accu-\nrately identifying all websites) based on the traffic in the early stage\nof page loading. Previous WF attacks rely on collecting pure traffic\nthroughout the entire page load process. However, under dynamic\nnetwork conditions or defenses, existing attacks cannot effectively\ncollect complete traffic from all websites. Meanwhile, increasing\nthe traffic collection time incurs more noise from background traf-\nfic or defenses, which further impacts the WF performance. We\nanalyze the SOTA multi-tab attack ARES [10] and the robust attack\nDF [39]. ARES and DF achieve over 90% average precision in the\npresence of obfuscated traffic under multi-tab browsing and WTF-\nPAD defenses, respectively. We find that the minimum precision of\nfingerprinting achieved by ARES and DF is only 42.86% and 54.11%,\nrespectively.\nNote that, the fixed traffic collection settings required by the\nexisting attacks further undermine the practicality. For example,\nthe DF attack sets a traffic collection time of 120 seconds and an\ninput length of 5000. The input is the direction sequence of pack-\nets, which is either truncated or zero-padded. However, different\nwebsites exhibit significant variations in page loading latency and\nthe number of generated packets, and such fixed settings cannot\nguarantee reliable identification of all websites. Figure 2 illustrates\nthe distribution of page loading latency and the number of packets\nfor the Alexa-top 10k websites. We observe that the page loading\nlatency of 5.04% of websites exceeds 120 seconds or the packet\ncount is over 5000, making it difficult for the existing attacks to\ncollect pure traffic with sufficient website information. Moreover,\nwe find that over 58.17% of websites require less than 60 seconds\nor fewer than 2500 packets for page loading. When these websites\nfinish loading, existing attacks continue collecting noise packets,\nwhich further degrades the performance of attacks.\nTo address the issues above and achieve effective WF attacks\nat the early stage of page loading, we develop Holmes to achieve\nthe following goals. (i) Reliability. Holmes utilizes traffic collected\nfrom the early stages of page loading to achieve high identification\nprecision across all websites. (ii) Adaptivity. For traffic from various\nwebsites, Holmes dynamically performs an attack during each time\ninterval of the traffic collection. Holmes should adaptively stop\ntraffic collection once enough website information is obtained, and\naccurately identify traffic. (iii) Robustness. Holmes should maintain\nrobust performance under various WF defenses.\nIn a nutshell, Holmes aims to achieve robust and reliable early-\nstage WF attacks, effectively identifying each website during the\nearly stages of page loading. Compared to previous attacks, Holmes\nmay be more practical in the real world, with applications such as\nearly detection and prevention of dark web crimes."}, {"title": "3 Threat Model", "content": "This paper aims to develop an early-stage website fingerprinting\nattack that can identify websites visited by Tor users based on the\ntraffic in the early stages of page loading. In particular, early-stage\nWF attacks can identify websites while the Tor user is still waiting\nfor the page to fully load. In Figure 3, we show the threat model of\nour early-stage WF attack. Similar with previous works [2, 10, 18, 21,\n32, 35, 36, 39, 40], we consider a local and passive adversary for Tor,\nsuch as network administrators, Internet Service Providers (ISPs),\nand Autonomous Systems (AS). The adversary can only collect\npackets without the capability to decrypt packets. Specifically, a\npassive adversary is unable to detect the end of a webpage loading,\nand can only configure fixed conditions for traffic collection [10, 36,"}, {"title": "4 Design of Holmes", "content": "In this section, we present the key observation for our design and\npropose a robust and reliable early-stage WF attack."}, {"title": "4.1 Key Observation", "content": "As discussed in Section 2.2, identifying websites by analyzing single\nearly-stage traffic is challenging due to dynamic network conditions\nand deployed defenses. Particularly, the loaded content during the\nsame loading interval varies under different network conditions.\nHowever, we observe a strong correlation between the early-stage\ntraffic and the pre-collected complete traffic of the same website,\nboth of which invariably contain the same website information,\nincluding parts of the website content and elements.\nTherefore, it is possible for us to achieve\naccurate early-stage traffic fingerprinting by analyzing the correla-\ntion between the early-stage traffic and the pre-collected complete\ntraffic."}, {"title": "4.2 Overview of Holmes", "content": "In this paper, we propose Holmes that exploits the correlations be-\ntween the early-stage traffic and the pre-collected complete traffic\nto achieve early-stage WF attacks. Particularly, Holmes captures\nthe spatial and temporal distribution of different websites so that it\ncan accurately fingerprint the traffic according to a small amount\nof the traffic visiting the websites, even under varied network con-\nditions and WF defenses. Holmes first performs data augmentation\nbased on the unique temporal distribution of traffic features for\neach website, which generates early-stage traffic that contains suf-\nficient website information. Second, Holmes utilizes Supervised\nContrastive Learning (SCL) [24] to transform traffic features into a\nlow-dimensional embedding space, where each flow of traffic corre-\nsponds to a point in the space. SCL extracts the correlation between\nearly-stage and complete traffic of the same website by clustering\nthe points of early-stage and complete traffic in the embedding\nspace. Finally, Holmes projects unknown early-stage traffic into the\nembedding space and calculates its correlation with each website\nbased on the spatial distribution of website traffic in the embedding\nspace. Note that, to avoid misidentification of early-stage traffic\ncontaining only connection information, Holmes rejects results of\nidentifying early-stage traffic with low correlations to all websites.\nTherefore, Holmes performs attacks at each short time interval\nof traffic collection until the corresponding website is identified\nwith high confidence, thus enabling adaptive traffic collection and\nreliable identification for each website.\nFigure 5 illustrates the overview of Holmes. Holmes consists\nof three modules designed to construct robust and reliable early-\nstage WF attacks, including adaptive data augmentation, spatial\ndistribution analysis, and early-stage website identification.\nAdaptive Data Augmentation. The adaptive data augmentation\nmodule generates early-stage traffic by masking the tail of complete\ntraffic during the training phase, which ensures that early-stage\ntraffic contains sufficient website information based on the unique\ntemporal distribution of the website. Holmes employs the feature\nattribution method, i.e., SHAP [27], to analyze the temporal distri-\nbution of the website traffic. It aggregates the feature attribution\nresults of multiple traffic associated with the same websites to ob-\ntain the feature importance distribution of the website. Holmes\nleverages the temporal distribution of websites to apply tail mask-\ning of various lengths for the traffic of different websites so that\nit can adaptively generate early-stage traffic containing sufficient\nwebsite information for each website. The details of this module\nwill be described in Section 5.1.\nSpatial Distribution Analysis. The spatial distribution analysis\nmodule utilizes supervised contrastive learning to transform traffic\nfeatures and computes the spatial distribution of websites according\nto the new feature space. To effectively extract the correlation\nbetween early-stage traffic and complete traffic, Holmes utilizes\nan encoder built on supervised contrastive learning to transform\ntraffic features into low-dimensional embedding features, ensuring\nthat the embedding features corresponding to the early-stage and"}, {"title": "5 Design Details", "content": "In this section, we present the design details of Holmes, including\nthe adaptive data augmentation module, the spatial distribution\nanalysis module, and the early-stage website identification module."}, {"title": "5.1 Adaptive Data Augmentation", "content": "The Adaptive Data Augmentation module generates traffic at dif-\nferent stages of page loading based on masked tail traffic, thereby\nfacilitating the analysis of the correlation between early-stage traf-\nfic and complete traffic. However, randomly generated early-stage\ntraffic may not contain sufficient website information. The reason\nis that due to network dynamic conditions and defenses, randomly\ngenerated early-stage traffic may only contain connection infor-\nmation and dummy packets. Furthermore, differences in website\nloading speed can also affect the correlation between the generated\nearly-stage traffic and the complete traffic. To achieve website-\nadaptive data augmentation, Holmes utilizes the feature attribution\nmethod to analyze the temporal distribution of traffic features, en-\nsuring that the generated early-stage traffic is correlated with the\ncomplete traffic of the same website.\nTemporal Distribution Analysis. Holmes analyzes the temporal\ndistribution by profiling the feature importance, which is challeng-\ning for two reasons: (i) Packets are encrypted in multiple layers by\nTor, making it difficult to analyze their importance. (ii) In dynamic\nnetwork environments or under traffic obfuscation by defenses, the\npositions of important packets may change.\nTo address these challenges, we extend the feature attribution\nmethod SHapley Additive exPlanations (SHAP) [27] to analyze the\nfeature importance distribution at different stages of page loading.\nSHAP calculates the marginal contribution of each feature by gen-\nerating combinations of all features. It is based on Shapley values, a\nconcept from cooperative game theory, which ensures a fair distri-\nbution of the contribution among the features. SHAP provides local\nexplanations showing how much each feature in a specific instance\ncontributes to the model's output, as well as global insights about\nthe overall model behavior.\nLet $U = \\{f_1, f_2, ..., f_n\\}$ represent the feature set of traffic, where\n$n$ is the number of features. Holmes divides the page loading time\ninto $n$ equal time intervals and counts the number of incoming\nand outgoing packets in each interval as traffic features, where $f_i$\nrepresents the feature of the i-th interval. Holmes calculates the\nimportance of the i-th feature $f_i$ based on the difference in the\nexpected model output when conditioning on the feature $f_i$. To\nminer the dependencies among traffic features, Holmes generates\nall feature combinations excluding the feature $f_i$ to calculate the\nmarginal contribution of the feature $f_i$. Specifically, the importance\nof the i-th feature i can be computed as follows:\n$\\Phi_i = \\sum_{S \\subseteq U \\setminus \\{f_i\\}} \\frac{|S|! (n - |S| - 1)!}{n!} \\bullet (O(S \\cup \\{f_i\\}) - O(S)),$     (1)\nwhere $S$ is a feature subset excluding $f_i$. $O(S \\cup \\{f_i\\})$ and $O(S)$\nrepresent the expected outputs of the model when feature $f_i$ is\npresent and absent, respectively. The weight of the set $S$ is the\nfrequency of occurrence among all possible feature combinations.\nSubsets of varying sizes are balanced in terms of weight to ensure\nthat the contributions of each feature can be fairly assessed. Due to\nthe high computational cost of Equation 1, we employ the DeepLIFT\nalgorithm [38] for approximation to expedite the calculation.\nWe select the SOTA WF attack RF [37] as the target model for\nfeature profiling. For each website, we randomly select 10 traffic.\nWe calculate the importance of features corresponding to different\nloading stages of the website and represent the temporal distribu-\ntion of each website using the average temporal distribution of the\ntraffic.\nMask-based Data Augmentation. Data augmentation is a ma-\nchine learning technique that enhances the diversity of training\ndata by artificially modifying samples to improve model perfor-\nmance [2]. Holmes achieves the data augmentation by masking\nthe tail of the traffic. However, the setting of mask proportion is\nchallenging. A prolonged mask results in early-stage traffic lack-\ning information related to the website, whereas a too-brief mask\nrequires the adversary to spend a lot of time collecting enough\npackets. To address the above challenges, Holmes employs website-\nadaptive data augmentation based on the temporal distribution of\nwebsites.\nIn Figure 6, we show the details of the data augmentation. Holmes\ninitially calculates the effective loading ranges of websites. When\nthe page loading ratio of a website reaches the effective loading\nrange, the early-stage traffic contains enough website information\nto be correlated with the complete traffic. As shown in Figure 6(a),\nHolmes generates the cumulative distribution of feature impor-\ntance for all websites. Holmes sets two parameters, \u03bb and \u00b5, rep-\nresenting the upper and lower bounds of the cumulative feature\nimportance corresponding to the effective loading proportions of\nwebsites. Based on the parameters \u03bb and \u00b5, Holmes can calculate\nthe effective loading range for each website.\nTo ensure the correlation between the generated early-stage\ntraffic and the complete traffic, Holmes adaptively enhances the\ntraffic for each website, making the generated traffic originate\nfrom the effective loading range of the corresponding website. Let\n$R = \\{(s_1, t_1), (s_2, t_2), ..., (s_m, t_m)\\}$ represent the effective loading\nranges for m monitored websites, where the effective loading range\nfor the i-th website is from $s_i$ to $t_i$. In Figure 6(b), we show the\ndetails of early-stage traffic generation. For the traffic of the i-th\nwebsite, Holmes randomly samples an integer $I$ from $s_i$ to $t_i$, then\nmasks the tail of traffic from the loading ratio $I$ to the entire page\nloading. We select the starting point of the mask randomly within\nan effective range, ensuring that the generated traffic belongs to\nthe early stages of page loading and contains adequate website\ninformation.\n$I \\sim Uniform[s_i, t_i]$.       (2)\nHolmes performs data augmentation on each traffic a times. The\nhigher the value of a, the more early-stage traffic is generated.\nHowever, excessive generation of early-stage traffic can lead to\nsignificant time overhead of model training."}, {"title": "5.2 Spatial Distribution Analysis", "content": "Utilizing the early-stage traffic generated by the temporal distri-\nbution analysis module, the spatial distribution analysis module\nextracts the correlation between early-stage and complete traf-\nfic. Specifically, Holmes builds an Encoder based on Supervised\nContrastive Learning (SCL) [24] to extract common features of\nearly-stage and complete traffic, generating low-dimensional em-\nbeddings that are spatially proximate. Then Holmes analyzes the\nspatial distribution of websites using the Median Absolute Devia-\ntion (MAD) [25].\nTraffic Embedding Based on SCL. To address the challenges\nposed by network jitter and defenses in the real world on the anal-\nysis of early-stage traffic, Holmes employs Supervised Contrastive\nLearning (SCL) for traffic embedding. The generated embeddings"}, {"title": "5.3 Early-Stage Website Identification", "content": "The early-stage website identification module leverages the correla-\ntions between different loading stages of website traffic to achieve\nrobust and reliable identification of early-stage traffic. To achieve\nearly-stage website identification, Holmes attempts website identifi-\ncation at each fixed time interval. The challenge faced by Holmes is\nensuring high confidence in website identification to avoid misiden-\ntification of early-stage traffic. To address the above challenge,\nHolmes calculates the correlation between unknown traffic and\nmonitored websites based on the position of unknown traffic in the\nfeature space and the spatial distribution of monitored websites.\nHolmes rejects the identification of early-stage traffic with low\ncorrelation to all monitored websites and continues to collect more\npackets.\nIn Algorithm 2, we show the pseudocode for early-stage web-\nsite identification. At every time interval, Holmes first projects the\nunknown early-stage traffic into the embedded space (lines 6-7)\nand calculates the distance between the unknown traffic and the\ncentroids of all monitored websites (lines 8-9). If the distance be-\ntween the unknown traffic and a website's centroid is less than\nthe radius of the website, Holmes successfully identifies the traffic\n(lines 10-12). Otherwise, Holmes continues to collect traffic and\nwats for the next time interval.\nHowever, not all early-stage traffic can be guaranteed to be iden-\ntified. Changes in the content of monitored websites can lead to vari-\nations in traffic patterns (i.e., concept drift). Furthermore, Holmes\nis unable to detect early-stage traffic from unmonitored websites.\nHolmes sets a maximum traffic collection time \u03c3. After collecting\ntraffic for o seconds, Holmes will detect whether the unknown traf-\nfic is due to concept drift or originates from unmonitored websites\n(lines 19-28). A key insight is that the distance between a website's\nconcept drift traffic and its centroid should be slightly greater than\nthe website's radius, yet much smaller than the distance between\nunmonitored website traffic and the website's centroid. Therefore,"}, {"title": "6 Performance Evaluation", "content": "In this section, we evaluate Holmes with public datasets and real-\nworld datasets. We compare the performance of Holmes with the\nstate-of-the-art WF attacks."}, {"title": "6.1 Experimental Setup", "content": "Implementation. We prototype Holmes using PyTorch 2.0.1 and\nPython 3.8 with more than 1,400 lines of code. In particular, we use\na single NVIDIA GeForce RTX 4090 GPU for our experiments. We\nshow the default parameter values in Table 1. Furthermore, we split\nthe dataset into training, validation, and testing, with an 8:1:1 ratio.\nThe parameter tuning and spatial-temporal analysis are performed\non the validation dataset to avoid leakage of the testing dataset.\nDataset. Our datasets comprise six categories of data, including a\ndataset of Alexa-top websites, a dataset of dark web websites, and\nfour types of defended datasets.\n\u2022 Dataset of Alexa-top websites: This dataset is from [39], which\nincludes data from both closed-world and open-world scenarios.\nThe closed-world data comprises 95 monitored websites, each\nwith over 1000 traces. In the open-world scenario, there are over\n40,000 unmonitored websites, each with only one trace. All web-\nsites belong to the Alexa-top websites list, which ranks websites\nbased on popularity.\n\u2022 Dataset of dark web websites: Since Alexa-top does not repre-\nsent the popularity of visits by Tor users, we select 80 of the most\npopular dark web websites based on the measurement of Tor v3"}, {"title": "6.2 Closed-World Evaluation", "content": "We first evaluate the performance of Holmes in the closed-world\nscenario using the dataset of Alexa-top 95 websites. To assess the\nperformance of Holmes in identifying early-stage website traffic,\nwe generate traffic for different loading stages of websites based\non packet timestamps from the testing dataset. As shown in Fig-\nure 8, Holmes achieves optimal attack performance under different\npage loading ratios. As the loading progress of websites increases\nfrom 20% to full completion, the Accuracy of Holmes in identify-\ning the website gradually improves, rising from 50.94% to 98.36%.\nCompared to existing attacks, Holmes demonstrates a significant ad-\nvantage in early-stage traffic analysis. For example, when websites\nare 40% loaded, Holmes achieves an Accuracy of 90.65%, which\nrepresents an improvement of 26.84%, 90.68%, 109.50%, 140.32%,\n175.36%, 194.22%, 224.68%, 235.12%, and 323.60% over RF, Var-CNN,\nARES, NetCLR, DF, Tik-tok, TMWF, AWF, and TF, respectively.\nSpecifically, Holmes exhibits the highest Accuracy for traffic at\nall loading stages of websites. The primary reason is that Holmes\nextracts traffic correlations at different loading stages of websites\nthrough spatial-temporal analysis. This correlation enhances the\nability of Holmes to identify traffic across all loading stages of\nwebsites.\nWe further evaluate the Precision, Recall, and F1-score of Holmes\nin identifying early-stage traffic. Table 2 presents a comparison of\nHolmes with existing WF attacks. Holmes significantly outperforms\nother attacks in all stages of page loading. For instance, when web-\nsites are loaded to 20%, 30%, 40%, 50%, and 60%, the F1-score of\nHolmes shows an average increase of 330.43%, 245.52%, 151.51%,\n79.59%, and 38.85% over existing attacks, respectively. For early-\nstage traffic, we observe that Holmes exhibits higher Precision\nthan Recall. This indicates that Holmes is effective in avoiding the\nmisidentification of traffic with insufficient website information.\nBenefiting from the temporal distribution analysis of website fea-\ntures and website-adaptive data augmentation, Holmes is capable\nof effectively identifying early-stage traffic that contains sufficient\nwebsite information while avoiding misidentification of early-stage\ntraffic without adequate website information."}, {"title": "6.3 Open-World Evaluation", "content": "We further evaluate the realistic open-world scenario using the\ndataset of Alexa-top websites, including 95 monitored websites\nand 40,000 unmonitored websites. The number of unmonitored\nwebsites significantly exceeds the number of monitored websites. To\neffectively assess attack performance in the open-world setting, we\nfollow previous works [42] by utilizing r-precision for evaluation.\nFigure 9 shows the comparison of r-precision for WF attacks\nwhen the ratio of page loading ranges from 30% to 60%. Holmes\nconsistently achieves high r-precision across different page load-\ning ratios. Compared to existing attacks, Holmes demonstrates a\nsignificant advantage in identifying early-stage traffic in the open-\nworld scenario. For example, when the ratio of page loading is 40%,\nHolmes achieves the r-precision of 94.96%, while the F1-scores\nfor RF, Var-CNN, ARES, NetCLR, DF, Tik-tok, TMWF, AWF, and TF\nare 83.77%, 71.72%, 56.99%, 51.49%, 49.33%, 51.26%, 38.46%, 31.31%,\nand 26.06%, respectively. When websites are loaded to 30%, 40%,\n50%, and 60%, the r-precision of Holmes shows an average in-\ncrease of 130.61%, 109.91%, 79.00%, and 57.62% over existing attacks,\nrespectively.\nThe experimental results demonstrate that Holmes can effec-\ntively distinguish between early-stage traffic from monitored and\nunmonitored websites in the open-world scenario. Particularly,\nHolmes reduces training overhead compared to baselines by elim-\ninating the requirement for training samples from unmonitored\nwebsites. Holmes leverages the spatial distribution of monitored\nwebsites in the feature space. By comparing the distance of un-\nknown traffic in the feature space to the centroid of the website\nand the website's radius, Holmes achieves early-stage WF attacks\nwith high precision in the open-world scenario."}, {"title": "6.4 Robustness Evaluation", "content": "Next, we evaluate the robustness of Holmes using datasets of Alexa-\ntop 95 websites with four defenses. In Figure 10, we demonstrate\nthe accuracy of WF attacks in different loading stages of websites\nunder defenses.\nAs shown in Figure 10(a), for the WTF-PAD defense, Holmes\nachieves the best accuracy across all ratios of page loading. For\nearly-stage traffic, Holmes is more robust compared to other attacks.\nWhen the page loading ratio is 40%, Holmes achieves an accuracy of\n82.03%, while the accuracy of all baselines is below 45%. For early-\nstage traffic when websites are 50% loaded, Holmes achieves an\naccuracy of 89.45%, marking significant improvements over RF, Var-\nCNN, ARES, NetCLR, DF, Tik-tok, TMWF, AWF, and TF by 46.95%,\n88.04%, 138.98%, 284.73%, 123.23%, 115.65%, 191.18%, 539.84%, and\n436.59%, respectively. Similar to Holmes, NetCLR and TF generate\nembeddings of traffic features based on contrastive learning and\nmetric learning, respectively. However, the accuracies of NetCLR\nand TF for early-stage traffic with WTF-PAD defense are both below\n30%. The advantage of Holmes is attributed to its feature extraction\nand SCL-based traffic embedding, which enable robust website\nidentification under defenses.\nFront is a more powerful padding-based defense compared to\nWTF-PAD. By padding dummy packets at the front of the traffic,\nFront significantly impacts the identification of early-stage traf-\nfic. Figure 10(b) shows the evaluation of WF attacks under Front\ndefense. Holmes achieves the best accuracy across all page load-\ning ratios. When the page loading ratio is 30%, 40%, 50%, and 60%,\nHolmes improves the accuracy of baselines by 561.40%, 480.92%,\n316.03%, and 192.97% on average, respectively. Existing WF attacks\nrely on the complete features of individual traffic, whereas Holmes\nleverages the correlation between early-stage traffic and complete\ntraffic of the same website to achieve a more robust WF attack.\nIn Figure 10(c), we show the accuracy of WF attacks under the\nWalkie-Talkie defense. We find that the attack performance of RF\nis close to that of Holmes. The reason is that traffic aggregation\ninformation based on time windows has been proven to effectively\nundermine the Walkie-Talkie defense [37]. Holmes still holds an\nadvantage in identifying early-stage traffic. For instance, at a page\nloading ratio of 30%, Holmes achieves an accuracy of 87.04%, while\nthe accuracy of RF, Var-CNN, ARES, NetCLR, DF, Tik-tok, TMWF,\nAWF, and TF are 83.70%, 61.80%, 38.07%, 21.93%, 30.24%, 26.47%,\n16.93%, 8.39%, and 6.56%, respectively.\nTrafficSliver is a potent defense that combats WF attacks by\nsplitting traffic. Figure 10(d) shows the comparison of WF attacks\nunder TrafficSliver defense. We observe a significant decrease in\nthe accuracy of baselines under TrafficSliver defense, while Holmes\nmaintains its robustness. When the page loading ratios are 30%, 40%,\n50%, and 60%, the accuracy of Holmes is improved by an average\nof 711.28%, 593.93%, 417.82%, and 283.98% compared to other WF"}, {"title": "6.5 Reliability Evaluation", "content": "The page loading speeds vary significantly across different websites,\nmaking it difficult to ensure high precision in detecting early-stage\ntraffic of all websites. Therefore, we use the minimum precision\namong all websites (i.e., P@min) to evaluate the reliability of WF\nattacks on early-stage traffic.\nFigure 11 illustrates the reliability of WF attacks under WTF-\nPAD defense. We use the dataset of Alexa-top 95 websites with\nWTF-PAD defense for evaluation because the variation of WTF-\nPAD defense based on circuit-level padding has been practically\ndeployed in Tor [1]. When the page loading ratio is 60%, Holmes\nachieves the best P@min of 70.25%, while Var-CNN, ARES, Net-\nCLR, DF, Tik-tok, TMWF, AWF, and TF have the P@min of 0. The\nP@min equals 0 means there are websites that these WF attacks\ncannot identify. For traffic at page loading rates of 80% and 100%,\nHolmes achieves an average P@min improvement of 299.43% and\n160.60% over baselines, respectively. We find that multi-tab WF\nattacks, ARES and TMWF, fail to ensure reliable identification un-\nder obfuscated traffic. Existing attacks focus only on high average\nprecision, ignoring the low P@min caused by differences between\nwebsites. Particularly, for traffic during the complete loading of\nwebsites, the reliability of existing WF attacks is limited. RF, Tik-\ntok, ARES, and DF, which claim to be robust attacks capable of\nundermining WTF-PAD defense, achieve high average precisions\nof 96.78%, 94.51%, 91.09%, and 91.19% in our evaluation. However,\nthe P@min for RF, Tik-tok, ARES, and DF are only 66.87%, 64.46%,\n54.30% and 54.11%, respectively. In contrast, Holmes significantly\nimproves the reliability of WF attacks and achieves the best P@min\nof 82.11%.\nThe reliability of Holmes is attributed to three aspects: (i) Holmes\nachieves adaptive data augmentation based on the unique temporal\ndistribution of each website, ensuring high precision in the identifi-\ncation of early-stage traffic across all websites. (ii) Holmes employs\nsupervised contrastive learning to transform features, effectively\nseparating traffic from different websites in the new feature space,\nthus reducing the misclassification of similar websites. (iii) Holmes\ncalculates the spatial distribution features of website traffic in the\nfeature space and enhances the reliability of identification by as-\nsessing the correlation between unknown traffic and the unique\nspatial distribution of each website."}, {"title": "6.6 Real-World Evaluation", "content": "Next, we evaluate Holmes using the dataset of 80 dark web web-\nsites collected from the real world. Alexa-top websites are widely\nused for evaluating WF attacks [10, 36, 37, 39, 40]. However, the\nranking of Alexa-top websites is based on the interests of all inter-\nnet users, which may not accurately represent the interests of Tor\nusers in the real world. Based on the measurements of Tor onion\nservices [41], we selected 80 of the most popular dark web websites.\nWe utilized 20 servers deployed across three different countries to\ncollect dark web traffic in August 2023 and April 2024. Therefore,\nthis dataset encompasses traffic under various network conditions\nand traffic exhibiting concept drift due to changes in the websites.\nWe replay packets of testing traffic to evaluate the time overhead\nand performance of different WF attacks. Moreover, the adversary\ncannot know the end time of the page loading in advance. We set\nup baselines to end traffic collection when the number of packets\nmeets the input requirements or when no new packets are collected\nwithin 1 second. Particularly, we use one NVIDIA GeForce RTX\n4090 to accelerate the inference of DL models.\nTable 3 shows the comparison of WF attacks using the dataset of\ndark web websites in the real-world evaluation. The attack latency\nrefers to the average time taken to collect and identify unknown\ntraffic, while the loading ratio represents the average page loading\nratio when the website identification result is obtained from the\nWF attack. In particular, we optimize the best-performing attack\nRF. RF30% represents RF attacks with the packet sequence lengths\nreduced to 30% of the original length. We adjust the input sequence\nlengths of the RF and retrain the models. Reducing the input length\nsignificantly optimizes latency, but also compromises the identifi-\ncation precision of RF. We find that compared to existing attacks\nand enhanced RF, Holmes exhibits the best attack efficiency and\nidentification precision. Specifically, Holmes reduces latency by an\naverage of 66.33% and improves precision by an average of 169.36%\ncompared to baselines.\nDark web websites utilize onion services for server anonymiza-\ntion, requiring more Tor relays and additional time overhead to\nload. We additionally use the dataset of Alexa-top websites under\nWTF-PAD defense for real-world evaluation. Holmes outperforms\nexisting attacks and enhanced RF in terms of latency and perfor-\nmance. For Alexa-top websites, Holmes reduces latency by an av-\nerage of 66.38% and increases precision by an average of 32.32%\ncompared to baselines. Holmes's advantages are attributed to adap-\ntive data augmentation for different websites and leveraging the\nspatial distribution of websites for adaptive traffic collection and\nhigh-precision website identification."}, {"title": "6.7 Comparison with Enhanced Baselines", "content": "In this section, we enhance the baselines and compare them with\nHolmes. Similar to the data augmentation module of Holmes, we\ngenerate early-stage traffic by masking the tail of the traffic with\nrandom lengths, which is added to the training datasets of baselines.\nWe evaluate the accuracy of WF attacks on early-stage traffic using\nthe dataset of the Alexa-top 95 websites. As shown in Figure 12,\nHolmes maintains a significant advantage in identifying early-stage\ntraffic compared to the enhanced baselines. When the page loading\nratio is 20%, 30%, 40%, and 50%, Holmes' accuracy improved by an\naverage of 255.78%, 215.09%, 136.12%, and 72.15% compared to the\nenhanced baselines.\nHolmes utilizes the temporal distribution of websites to achieve\nwebsite-adaptive data augmentation, effectively generating early-\nstage traffic that contains sufficient website information. Further-\nmore, Holmes employs supervised contrastive learning to extract\nthe correlations between early-stage traffic and complete traffic,\nwhich enables more effective correlation analysis between samples\ncompared to traditional supervised learning."}, {"title": "6.8 Parameters Analysis", "content": "We further study the impact of different parameter values on the\nperformance of Holmes. We select four key parameters, including\nthe lower bound of the cumulative time distribution \u00b5, the upper\nbound of the cumulative time distribution \u03bb, the embedding size \u03b7,\nand the temperature y. We measure the accuracy of Holmes when\nthe website loading ratios are 20%, 40%, and 60%, respectively.\nAs shown in Figure 13, we show the accuracy of Holmes un-\nder different parameter settings. The performance of Holmes is\ninsensitive to the settings of the lower bound \u03bc, upper bound \u03bb, and\nembedding size n. For example, when the embedding size \u03b7 is in-\ncreased from 64 to 768, the accuracy of Holmes for the traffic of 20%\nloaded ranges from 64.06% to 65.29%. For the traffic of 60% loaded,\nthe accuracy of Holmes ranges from 96.45% to 96.58%. Moreover,\nwe observe that a larger temperature y leads to a decrease in the\nperformance of Holmes. The reason is that larger temperature y\nwill make model training difficult. Particularly, the performance of\nHolmes is still stable when the temperature y is less than 0.15. In\ngeneral, the performance of Holmes is not sensitive to parameter\nchoices."}, {"title": "7 Discussion", "content": "Concept Drift. The changing content of websites over time can\nlead to a decline in the effectiveness of WF attacks, i.e., concept\ndrift. Concept drift can be addressed by periodically collecting new\ntraffic and retraining models [2, 10, 36, 40]. However, there are two\nkey challenges. (i) Detecting concept drift is difficult, and exist-\ning attacks detect concept drift by observing the degradation of\nattack performance. (ii) Collecting traffic from all websites and re-\ntraining models is time-consuming and resource-intensive. Holmes\ncan effectively detect concept drift samples for each website in the\nopen-world setting. Furthermore, Holmes does not require frequent"}, {"title": "Practical WF Attacks", "content": "The feasibility of deploying existing WF\nattacks in the real world is hampered by strong assumptions [7,\n22]. Recent works aim to relax these assumptions in real-world\nsettings, e.g., multi-tab browsing [10, 21], robust WF attacks against\ndefenses [37], attacks with a small number of training samples [40],\ndynamic network conditions [2], open-world attacks [42]. Holmes\naims to accurately identify websites at a very early stage of page\nloading, further enhancing the practicality of WF attacks.\nEarly-Stage Traffic Analysis. Early-stage traffic analysis facili-\ntates real-time processing of traffic, which is crucial for throttling\nmalicious traffic [9, 14, 26, 33]. Most existing studies focus on early-\nstage non-encrypted traffic analysis, where traffic can be accurately\nidentified by using a small number of packets [15, 20]. The challenge\nintensifies if the traffic under analysis is encrypted [34]. Recently,\nDL-based traffic analysis methods [45, 47] achieve accurate early-\nstage encrypted traffic classification in specific scenarios. However,\nexisting methods cannot achieve WF attacks in the early stages\nunder Tor traffic. Holmes achieves early-stage WF attacks by ana-\nlyzing the spatial-temporal correlations among website traffic. To\nthe best of our knowledge, Holmes is the first early-stage traffic\nanalysis for Tor traffic."}, {"title": "9 Conclusion", "content": "In this paper, we propose Holmes, a reliable and robust early-stage\nWF attack. Specifically, Holmes utilizes the temporal distribution\nof website traffic to achieve website-adaptive data augmentation\nand employs supervised contrastive learning to embed traffic into a\nlow-dimensional feature space. Holmes calculates the correlation of\nearly-stage traffic with each website by leveraging the spatial distri-\nbution of website traffic in the embedding space, thereby enabling\nearly-stage website identification. We conduct extensive evalua-\ntions of Holmes using six datasets, and the experiment results\ndemonstrate its effectiveness in identifying early-stage traffic."}, {"title": "Related Work", "content": "DL-based WF Attacks. Recently deep learning has been widely\napplied to construct website fingerprinting attacks [2, 3, 10, 21, 35-\n37, 39]. DL-based WF attacks demonstrate outstanding attack per-\nformance. However, these attacks require traffic close to the com-\npletion of page loading to identify websites. Holmes leverages the\ntemporal distribution and spatial distribution of website traffic, en-\nabling the extraction of correlations among website traffic. There-\nfore, our constructed attack can achieve robust and reliable WF\nattacks based on the early-stage traffic of page loading."}]}