{"title": "LLM-Generated Heuristics for AI Planning: Do We Even Need\nDomain-Independence Anymore?", "authors": ["Alexander Tuisov", "Yonatan Vernik", "Alexander Shleyfman"], "abstract": "Domain-independent heuristics have long been a\ncornerstone of AI planning, offering general solu-\ntions applicable across a wide range of tasks with-\nout requiring domain-specific engineering. How-\never, the advent of large language models (LLMs)\npresents an opportunity to generate heuristics tai-\nlored to specific planning problems, potentially\nchallenging the necessity of domain independence\nas a strict design principle. In this paper, we ex-\nplore the use of LLMs to automatically derive plan-\nning heuristics from task descriptions represented\nas successor generators and goal tests written in\ngeneral purpose programming language. We in-\nvestigate the trade-offs between domain-specific\nLLM-generated heuristics and traditional domain-\nindependent methods in terms of computational\nefficiency and explainability. Our experiments\ndemonstrate that LLMs can create heuristics that\nachieve state-of-the-art performance on some stan-\ndard IPC domains, as well as their ability to solve\nproblems that lack an adequate Planning Domain\nDefinition Language (PDDL) representation. We\ndiscuss whether these results signify a paradigm\nshift and how they can complement existing ap-\nproaches.", "sections": [{"title": "Introduction", "content": "Heuristics are critical tools in domain-independent planning,\nas they enable planners to efficiently search through exten-\nsive state spaces by providing guidance on which paths are\nlikely to lead to a solution. The domain-independent plan-\nning approach relies on a common language in which prob-\nlems are specified. As such, the propositional planning lan-\nguage STRIPS was introduced in 1971 by Fikes & Nils-\nson (1971). Later, the propositional variables were replaced\nby finite-domain ones, FDR [B\u00e4ckstr\u00f6m and Nebel, 1995;\nHelmert, 2009], and eventually numeric variables were intro-\nduced [Erol et al., 1995; Helmert, 2002; Hoffmann, 2003].\nUnfortunately, writing domains in such languages is\nusually too cumbersome, since problems may have thou-\nsands or even tens of thousands of variables, and hun-\ndreds of thousands of actions that cannot be specified man-"}, {"title": "Preliminaries", "content": "PDDL2.1 (Planning Domain Definition Language, version\n2.1) [Fox and Long, 2003] is a widely adopted formalism for\nspecifying planning problems in artificial intelligence. It ex-\ntends the original PDDL standard by introducing support for\nnumeric fluents and durative actions, enabling the representa-\ntion of temporal and resource-constrained planning domains.\nIn this work we concentrate on the PDDL2.1 part the operates\nwith numeric and propositional fluents, and is collectively\nknown as numeric planning. Below, we summarize its key\ncomponents relevant to this work."}, {"title": "Problem Definition", "content": "A planning problem in PDDL2.1 (level 2) can be represented\nas a tuple $\\Pi = (P, F, O, A, s_0, G)$, where: P is a set of pred-\nicate symbols, F is a set of function symbols, O is a set of\nobjects, A is a set of action schemata, $s_0$ is the initial state,\nand G is a goal condition. Every predicate symbol $P \\in P$ and\nevery function symbol $F \\in F$ have an associated arity. If P\nor F is an n-ary predicate and $t = (t_1,..., t_n)$ is a tuple of\nvariables or objects from O, then P(t) is an atom, and F(t) is\na function. When we ground (i.e., substitute) the variables of\nan atom P(t) with objects from O, we obtain a ground atom.\nThe grounded functions are obtained in the same fashion, we\nwill refer to this grounded functions as fluents. A state, such\nas $s_0$, is a set of ground atoms and functions, interpreted a full\nassignment over binary atoms and numeric fluents.\nAn action schema a[A] is a tuple\n$\\langle pre(a[A]), eff(a[\\triangle])\\rangle$, corresponding to preconditions\nand effects. These elements of a[A] are sets of formulas,\nwere each formula is given over predicate and function sym-\nbols. We can ground an action schema a[$\\triangle$] by substituting\nthe free variables A with objects in O, which results in a\nground action a without free variables (sometimes referred to\nsimply as an action when the context is clear). Preconditions\nin a grounded action are logical conditions that must hold\nfor the action to be applied. The atoms, or propositional\nvariables, in these formulas can be seen as literals, and each\nformula is a conjunction of such literals. The conditions\non numeric fluents are represented as comparison of a\nrational function to zero, i.e., $R(v_1,..., v_n) < 0$, where\n$v_1,..., v_n$ are grounded numeric fluents and R is a quotient\nof multivariable polynomials with rational coefficients, and\nX\u2208 {>, \u2265, =, <, \u2264}. Grounded action Effects describe how\nthe action modifies the state. Effects can be:"}, {"title": "The Rust Programming Language", "content": "Rust is a modern systems programming language designed\nwith a focus on performance, safety, and concurrency\n[Klabnik and Nichols, 2019; The Rust Team, 2024]. Origi-\nnally developed by Mozilla, it has gained significant traction\nin both academia and industry. Below, we outline the key\nfeatures of Rust relevant to this work.\nMemory Safety Each value in Rust has a single owner, A\nvalue is borrowed via references, and is automatically deal-\nlocated when the owner goes out of scope. This eliminates\ncommon memory-related errors and ensures memory safety\nat compile time, making Rust particularly resilient against\nmemory leaks in generated code.\nPerformance and Low-Level Control Rust provides low-\nlevel control over system resources akin to C and C++, while\navoiding the overhead of runtime checks. It compiles directly\nto machine code using LLVM, enabling high performance.\nThe language supports zero-cost abstractions, ensuring that\nhigher-level constructs do not impose a runtime penalty.\nIn this paper, we leverage Rust to implement key com-\nponents of our approach, including the successor generator,\ngoal-testing function, LLM-generated heuristic, and Greedy\nBest-First Search (GBFS) [Pearl, 1984] ensuring robust and\nefficient execution of the planning tasks.\nWhy Rust over other general-purpose languages?\nRust's strict compiler checks, memory safety guarantees, and\nzero-cost abstractions make it ideal for integrating LLM-\ngenerated code. Additionally, we required a compiled lan-\nguage to ensure the heuristic operates deterministically as a"}, {"title": "Methodology", "content": "We start with the overview of our approach. Our approach\nintegrates automated code generation, heuristic design using\nLLMs, and a custom search procedure to solve planning prob-\nlems efficiently. The process begins by accepting two types of\ninput: structured representations provided in PDDL2.1 format\nand general problem descriptions given informally or in non-"}, {"title": "Prompt Construction", "content": "With the foundational components in place, we employ a\nLLM to generate the heuristic function. An LLM is pro-\nvided with the Rust code for the successor generator and goal-\ntesting function. We generate the heuristic using Chain-of-\nThought [Wei et al., 2022] method consisting of three phases:\nPhase 1 (problem understanding and heuristic concep-\ntion): In the first phase, we give an LLM an Rust domain\nimplementation (successor generator and goal test functions)\nand request an English description of a heuristic that could\nsolve it effectively. We present an LLM with a sequence of\ninstructions on how to parse the problem and what is and is\nnot required for an effective satisficing heuristic.\nPhase 2 (unrefined heuristic): In the second phase, we de-"}, {"title": "Empirical Evaluation", "content": "The experiments were conducted on a 13th Gen Intel\u00ae\nCore\u2122 i9-13900 processor running at 2.00 GHz, supported\nby a 64-bit operating system and 32 GB of RAM. To ensure\nconsistency and reliability, each experiment was constrained\nby a time limit of 30 minutes and a memory usage limit of 8\nGB.\nWe test our approach in the context of satisfying numeric\nplanning. We have evaluated our approach on several do-\nmain, some of which appear in the Numeric International\nPlanning Competition (IPC) 2023. These domains include:"}, {"title": "Choosing between LLM-generated and\nDomain-independent Heuristics", "content": "Choosing between LLM-generated and domain-independent\nheuristics involves weighing their respective advantages.\nLLM-generated heuristics offer flexibility, intuitive model-\ning, and superior performance in certain numeric domains,\nwhile domain-independent heuristics provide broad applica-\nbility, integration with established frameworks, and proven\nreliability. The optimal choice depends on the specific re-\nquirements and constraints of the planning task at hand. Be-\nlow we discuss the advantages of both approaches."}, {"title": "Advantages of LLM-Generated Heuristics", "content": "LLM-generated heuristics offer several advantages over tradi-\ntional domain-independent heuristics. Representing domains\nthrough Rust-based successor generators and goal test func-\ntions is often more intuitive and accessible than using PDDL,\nwhich has a steeper learning curve and is less widely under-\nstood. LLM-generated heuristics also handle complex do-\nmain beyond the representational limits of PDDL, leverag-\ning Rust-based frameworks to address a broader range of\nchallenges. In numeric domains, they frequently outperform\ntraditional heuristics by incorporating domain expertise and\npractical reasoning, enabling efficient prototyping of specific\nproblems. Moreover, these heuristics are presented as well-\ncommented, human-readable code, simplifying debugging,"}, {"title": "Advantages of Domain-Independent Heuristics", "content": "Domain-independent heuristics remain valuable due to their\ngeneral applicability, functioning across diverse tasks with-\nout requiring domain-specific modifications. This versatility\nmakes them suitable for a wide range of planning problems\nwith minimal customization. Moreover, they are not sensitive\nto problem semantics, such as descriptive variable names.\nThese heuristics are deeply integrated into es-\ntablished planning frameworks such as Fast For-\nward [Hoffmann, 2001], Metric-FF [Hoffmann, 2003],\nFast Downward [Helmert, 2006], and ENHSP-\n20 [Scala et al., 2020]. Additionally, the extensive In-\nternational Planning Competition (IPC) benchmarks written\nin PDDL provide a robust testbed for evaluation, ensuring\ntheir reliability and robustness.\nTheir minimal customization requirements save significant\ntime and resources, enabling rapid deployment across mul-\ntiple domains without the need for domain-specific develop-ment.\nFinally, their extensive history and theoretical foundation\noffer well-understood limitations and guarantees, providing a\nlevel of trust and reliability that LLM-generated heuristics are\nstill working to achieve."}, {"title": "Conclusion", "content": "This paper has examined the potential of large language mod-els (LLMs) to generate heuristics tailored to specific AI plan-ning problems, challenging the long-standing reliance on domain-independent heuristics. By deriving heuristics di-rectly from task descriptions in Rust-including successor gen-erators and goal tests we explored the trade-offs between LLM-generated and traditional methods. Our findings demonstrate that LLMs can produce domain-specific and problem-specific heuristics that exhibit state-of-the-art performance at least on some domains. This suggests a future where domain-specific enhancements coexist with domain independent frameworks. Future research should focus on improving the adaptability of LLM-generated heuristics across diverse domains, com-paring them to hand-crafted heuristics, and leveraging chain-of-thought models to further enhance performance. By refin-ing these methods, we can pave the way for more efficient and scalable planning systems that integrate the strengths of domain-specific and independent strategies."}, {"title": "Discussion", "content": "As shown by the experimental results in Table 1, LLM-based heuristics demonstrate state-of-the-art performance across the evaluated domains. Notably, these heuristics excel in the MarketTrader domain, traditionally considered very complex, where domain-independent planners fail to solve even a single instance. The highest-performing LLM-based heuristics were generated by gpt-4o, as Gemini models (especially 1.5-pro) tend to generate code that does not compile properly. The discrepancy between the best@1 and best@5 metrics is largely attributed to compilation errors in every model, as the best@1 metric allows the LLM only one attempt to produce syntactically correct code. However, some domains pose challenges for LLM-based heuristics. This difficulty likely stems from the sensitivity of LLMs to non-descriptive variable names and obscure goal specifications, as observed in the Sailing domain. In the Pacman and Twin Prime domains, no available planner can solve problems requiring this level of expressive power, necessitating a comparison against BFS. Unsurprisingly, LLM-based heuristics outperformed BFS. Overall, LLM-based heuristics surpass state-of-the-art numerical planners while addressing problems that demand greater expressive power. LLM-generated heuristics are typically less computationally intensive, enabling rapid expansion, and are highly explainable. For instance, the following is the output of a heuristic for a specific Pacman instance:"}]}