{"title": "Anatomy-Informed Deep Learning and Radiomics for Automated Neurofibroma Segmentation in Whole-Body MRI", "authors": ["Georgii Kolokolnikov", "Marie-Lena Schmalhofer", "Lennart Well", "Said Farschtschi", "Victor-Felix Mautner", "Inka Ristow", "Ren\u00e9 Werner"], "abstract": "Neurofibromatosis Type 1 is a genetic disorder characterized by the development of neurofibromas (NFs), which exhibit significant variability in size, morphology, and anatomical location. Accurate and automated segmentation of these tumors in whole-body magnetic resonance imaging (WB-MRI) is crucial to assess tumor burden and monitor disease progression. In this study, we present and analyze a fully automated pipeline for NF segmentation in fat-suppressed T2-weighted WB-MRI, consisting of three stages: anatomy segmentation, NF segmentation, and tumor candidate classification. In the first stage, we use the MRSegmentator model to generate an anatomy segmentation mask, extended with a high-risk zone for NFs. This mask is concatenated with the input image as anatomical context information for NF segmentation. The second stage employs an ensemble of 3D anisotropic anatomy-informed U-Nets to produce an NF segmentation confidence mask. In the final stage, tumor candidates are extracted from the confidence mask and classified based on radiomic features, distinguishing tumors from non-tumor regions and reducing false positives. We evaluate the proposed pipeline on three test sets representing different conditions: in-domain data (test set 1), varying imaging protocols and field strength (test set 2), and low tumor burden cases (test set 3). Experimental results show a 68% improvement in per-scan Dice Similarity Coefficient (DSC), a 21% increase in per-tumor DSC, and a two-fold improvement in F1 score for tumor detection in high tumor burden cases by integrating anatomy information. The method is integrated into the 3D Slicer platform for practical clinical use, with the code publicly accessible.", "sections": [{"title": "I. INTRODUCTION", "content": "EUROFIBROMATOSIS Type 1 (NF1) is an autosomal-dominant genetic disorder affecting 1 in 2,500 to 3,000 individuals [1]. The clinical manifestations of NF1 are diverse, with the hallmark feature being neurofibromas (NFs) distributed throughout the body [2]. NFs (Fig. 1), which can be cutaneous, subcutaneous, or plexiform (PNFs) [3], vary in size, number, and location, leading to disease heterogeneity [4]. Compared to cutaneous and subcutaneous NFs, PNFs are of higher clinical importance due to the elevated risk of transforming into malignant peripheral nerve sheath tumors (MPNSTs). MPNSTs are a leading cause of premature mor-\nN"}, {"title": "II. RELATED WORK", "content": "Early work on NF segmentation relied on semi-automated techniques. In 2004, Solomon et al. [11] introduced a thresholding-based method with manual initialization, which was prone to errors in iso-intense regions.\nIn 2012, Weizman et al. [9] proposed a method with manual initialization, followed by a segmentation based on tumor connectivity. It struggled with intensity similarities between PNFs and healthy tissues. A refinement in 2013 utilized a histogram-based tool requiring minimal user input [14]; however, it showed lower accuracy for small-volume tumors and diffusion of segmentation into high-signal-intensity structures adjacent to tumors.\nA shift towards deep learning (DL) in NF segmentation was marked by Wu et al. in 2020 [15], who introduced the Deep Parametric Active Contour Model (Deep-PAC). It combined active contour models with DL features. Deep-PAC demonstrated superior performance over Fully Convolutional Networks (FCN) and U-Net. However, it required manual initialization and was computationally intensive.\nAdvancements in fully automated methods were demonstrated by Ho et al. in 2020 [13]. They developed a multi-spectral neural network classifier that utilized diffusion-weighted imaging data. Although this method reduced intra- and inter-observer variability, it struggled with misclassifying normal anatomy as pathological.\nIn 2021, Zhang et al. [12] proposed Deep Interactive Networks (DINs), using an Exponential Distance Transform to convert user interactions into guide maps. Compared to 3D U-Net and nnU-Net, DINs achieved significantly higher DSC, though it required user interaction.\nIn 2022, Wu et al. introduced a Deep Hybrid Contextual Feature Network, integrated with a Multi-Gradient Active Contour model [16]. The method consistently outperformed both U-Net and FCN, but it faced challenges due to intensity inhomogeneity and fuzzy boundaries, in addition to numerical instabilities during contour evolution.\nDespite progress in NF segmentation, existing methods remain sensitive to tumor appearance variability, are often restricted to 2D operations, or are limited to segmenting only a few tumors within a region of interest. Our approach addresses these limitations by integrating anatomical knowledge and radiomics in a fully automated multistage pipeline."}, {"title": "III. METHODS", "content": "This single-center retrospective study was approved by the local ethics committee (2022-300201-WF, 2022-300201_1-WF) with a waiver of informed consent, adhering to data protection regulations and the Declaration of Helsinki.\nThe proposed novel fully-automated pipeline for NF segmentation in T2w WB-MRI contains three main stages (Fig. 2): anatomy segmentation using the MRSegmentator [18] (Section III-A), NF segmentation using an ensemble of 3D anisotropic anatomy-informed U-Nets (Section III-B), and tumor candidate classification leveraging radiomic features (Section III-C). Since the pipeline does not require user interaction, it reduces the manual workload and potential bias typically present in semi-automated methods [9]\u2013[12], [14], [15]. Furthermore, the pipeline can serve as a pre-segmentation step for refinement by interactive techniques [12], [19], though this is beyond the scope of the current study."}, {"title": "A. Stage 1: Anatomy Segmentation Using MRSegmentator", "content": "1) Rationale: NFs are more likely to occur in certain anatomical regions, particularly along the nerves in the head, neck, trunk, and extremities, with a higher concentration around areas such as the spine, brachial plexus, and sciatic nerves [3], [4], [20], [21]. To enhance NF segmentation accuracy, we used anatomical context to focus the neural network model on areas with a higher likelihood of NFs (see Section III-B). This idea is inspired by the prompting strategy in the Segment Anything Model [22]. There, the prompts helped the neural network identify the region of interest.\n2) Prior Anatomical Knowledge: To extract an anatomy segmentation mask from the input data, we utilized MRSegmentator [18]. Despite its capabilities, the model exhibited limitations when applied to the highly anisotropic fat-suppressed T2w WB-MRIs of this study due to low resolution in certain planes and low contrast of soft tissues. These issues contributed to less reliable segmentation outputs from MRSegmentator as shown in Fig. 3.a, e.g., in structures like the duodenum, small bowel, colon, and bones.\nTherefore, the anatomy segmentation was refined by post-processing and incorporating anatomical knowledge of typical NF locations [3], [4], [20], [21]. Organs with DSC below 0.85 on the NAKO dataset [18] and vessels were excluded due to poor segmentation performance. Additionally, paired organs were merged, and muscle groups were consolidated into one label (Table I).\nBased on prior knowledge about typical NF localizations [3], [4], [20], [21], we defined an NF high-risk zone near the lungs (around ribs and intercostal nerves) and the spine (near spinal nerves). The NF high-risk zone, i.e. areas with a high probability of the occurrence of NFs, was added as a separate label to the anatomy segmentation mask by dilating segmentation masks of the lungs and spine.\nThe refined mask (Fig. 3.b) included 11 organ labels and an additional label for the NF high-risk zone. Fig. 3.c shows NFs within the labeled NF high-risk zone. We also defined specific anatomical regions based on landmarks:\n\u2022 Head and neck. Above the highest point of the lungs.\n\u2022 Chest. Between the lungs' lowest and highest points.\n\u2022 Abdomen. Between the lowest point of the lungs and the lowest point of the hips (ischium).\n\u2022 Legs. Below the lowest point of the hips."}, {"title": "B. Stage 2: Neurofibroma Segmentation Using an Ensemble of 3D Anisotropic Anatomy-Informed U-Nets", "content": "1) Anisotropy of NF Data: The T2w WB-MRI data are highly anisotropic, with the anterior-posterior axis voxel size being over ten times larger than for the cranio-caudal and lateral axes. We hypothesized that maintaining this anisotropic spacing during processing can improve segmentation accuracy by avoiding interpolation artifacts. We, therefore, resampled the data to a unified mean anisotropic spacing derived from the dataset for consistency (see Section IV-A.2).\n2) Segmentation Model Architecture: We selected U-Net as the backbone architecture for its versatility. Unlike data-hungry transformer-based models (e.g., UNETR, Swin UNETR) [23], [24], U-Net is more suitable for datasets with limited samples, like in the NF segmentation case.\nOur approach differs from previous methods [9]\u2013[13], [15], [16] by leveraging anatomical context to enhance NF segmentation accuracy. We concatenated the anatomy segmentation mask with the T2w WB-MRI as a two-channel input to guide the neural network to focus on specific regions within the T2w WB-MRI. While multiple methods exist to integrate anatomical knowledge into neural networks [12], [19], [22], [25], we opted for this simpler concatenation method to minimize architectural changes to the baseline U-Net model. This allowed us to more directly assess the impact of anatomical knowledge on segmentation performance.\nTo handle anisotropy, the 3D anisotropic U-Net maintained the original voxel resolution. With a patch size of 10 x 640 x 256, it balanced computational efficiency and anatomical context. The nnU-Net framework [26] was applied to optimize the architecture, featuring seven encoder and six decoder stages with convolutional blocks, instance normalization, and leaky rectified linear unit activation. Strides and kernel sizes were adapted to downsample along cranio-caudal and lateral axes while preserving anterior-posterior resolution. A 1x1x1 convolution with sigmoid activation mapped tumor probability.\n3) Ensembling: We employed an ensemble of three 3D anisotropic anatomy-informed U-Nets, each trained with random initialization and different data splits via three-fold cross-validation. The tumor probability masks of the individual models were averaged to reduce variance and bias in predictions, generating an NF segmentation confidence mask."}, {"title": "C. Stage 3: Tumor Candidate Classification", "content": "1) Rationale: The tumor candidate classification step was introduced to improve specificity in NF segmentation, i.e., the reduction the number of typical misclassification of non-tumorous tissues like muscles and fat as NFs.\n2) Extracting Tumor Candidates: After generating the NF segmentation confidence mask, thresholding was applied to distinguish tumors from the background. The confidence threshold, a hyperparameter, balanced true tumor detection against false positives. A higher confidence threshold (0.5 -\ndefault value) minimized false positives but could miss some true tumors (false negatives), whereas a lower confidence threshold (0.25 - median of the lowest confidence values in the predicted NF segmentation masks) captured more true tumors but increased false positives. Based on the resulting binary mask, component analysis was used to identify tumor candidates, grouped by anatomical region to account for appearance variability.\n3) Extracting Radiomic Features: For each tumor candidate, we extracted 800 radiomic features (shape, intensity, texture) using PyRadiomics [27], leveraging their potential for NF tumor classification [28], [29]. Feature selection followed standard radiomics workflow [30]: removal of features with near-zero variance, retention of non-intercorrelated features using Spearman correlation, and selection of the top 10 features via recursive feature elimination with a random forest classifier.\n4) Classification: Selected features describing each tumor candidate were classified using region-specific random forest classifiers to account for NF variability across anatomical regions. Random forests were chosen as classifiers for their robustness and ability to handle small datasets and high-dimensional feature spaces [31]. Identified non-tumor candidates were excluded, forming the final NF segmentation mask."}, {"title": "IV. EXPERIMENTS", "content": "1) Source of Data: The NF dataset was acquired at the neurofibromatosis outpatient clinic at the University Medical Center Hamburg-Eppendorf, using a Siemens Magnetom scanner (Siemens Healthineers, Erlangen, Germany). The inclusion criteria were: confirmed NF1 diagnosis [32], no ongoing medication, and availability of WB-MRIs with documented peripheral nerve sheath tumors. T2w WB-MRIs were collected over 14 years (2006-2020), and tumor segmentation was manually performed by two radiologists (I.R. and M.-L. S.).\n2) Demographic, Imaging, and Clinical Characteristics: The NF dataset included 109 T2w WB-MRI scans from 74 patients (37 males, 37 females; mean age: 29.7 years). The scans had high anisotropy (in-plane resolution of 0.63 mm x 0.63 mm; mean slice thickness of 7.79 mm). Ground truth annotations focused on PNFs due to their elevated risk of malignant transformation. A summary of the demographic and imaging characteristics of the data is presented in Table II.\nTumor burden and count varied across the patients with differences in anatomical distribution (Fig. 4). The abdomen and legs were the most affected regions, displaying the highest tumor volumes and counts, whereas the chest, head, and neck were less involved, consistent with previous findings [4].\n3) Dataset Partitioning: To evaluate the NF segmentation performance in different scenarios, the NF dataset was split into a train and three distinct test sets. The partitioning strategy was as follows: patients scanned with a 1.5T MRI were allocated to Test Set #2 (out-of-domain). For the remaining 3T scans, the tumor burden distribution was analyzed, and cases in the first quartile (tumor burden <47 cm\u00b3) were assigned to Test Set #3 (low tumor burden). The remaining cases were randomly split between the train and Test Set #1 (in-domain) at the patient level. A summary of each set is provided below:\n\u2022 Train set. Showed a wide range of tumor burdens (median: 618.2 cm\u00b3; interquartile range (IQR): 1276.9 cm\u00b3) and counts (median: 224 tumors per scan; IQR: 319). The abdomen had the highest tumor burden (median volume: 219.9 cm\u00b3; IQR: 690.8 cm\u00b3; median count: 72.2), and the legs had the highest tumor count (median volume: 115.2 cm\u00b3; IQR: 306.7 cm\u00b3; median count: 99.5).\n\u2022 Test set #1 (in-domain). Included scans that matched the train set in terms of MRI protocols, field strength, and tumor burden to assess the model performance under known conditions. This set had the highest tumor burden (median: 1311.2 cm\u00b3; IQR: 3872.1 cm\u00b3) and showed significant variability in tumor counts (median: 62; IQR: 608). Tumor burden and variability were high across all regions, especially in the legs (median volume: 490.8 cm\u00b3; IQR: 921.9 cm\u00b3; median count: 120.5).\n\u2022 Test set #2 (out-of-domain). Included scans acquired with different MRI protocols (repetition time, echo time, flip angle) and at a lower field strength (1.5T compared to 3T used in the train set) to assess the model generalization ability across varying imaging environments. This set demonstrated moderate tumor burden (median: 442.4 cm\u00b3; IQR: 512.1 cm\u00b3) and count (median: 112; IQR: 288), with the abdomen (median volume: 139.3 cm\u00b3; IQR: 145.9 cm\u00b3; median count: 58.9) and legs (median volume: 97.4 cm\u00b3; IQR: 227.9 cm\u00b3; median count: 79.9) being the most affected regions.\n\u2022 Test set #3 (low tumor burden). Included scans from patients with low tumor burden (median: 5.6 cm\u00b3; IQR: 10.9 cm\u00b3) and count (median: 2; IQR: 5), allowing assessment of model sensitivity to sparse tumors. Tumor burden was minimal across anatomical regions."}, {"title": "B. Experimental Design", "content": "The segmentation performance of the proposed pipeline was evaluated for the described three test sets. First, we compared a baseline 3D isotropic U-Net (input patch size: 128 x 128 x 128; spacing: 1.0 mm x 1.0 mm x 1.0 mm) with the 3D anisotropic U-Net (input patch size: 10 x 640 x 256; spacing: 7.8 mm x 0.625 mm x 0.625 mm) to assess the impact of anisotropic image processing. Next, we evaluated the benefit of anatomical knowledge integration by comparing the 3D anisotropic U-Net with a 3D anisotropic anatomy-informed U-Net that used two-channel input (T2w WB-MRI and anatomy segmentation mask). Finally, we tested the effect of tumor candidate classification by comparing an ensemble of 3D anisotropic anatomy-informed U-Nets with and without this post-processing step, employing both low- and high-confidence thresholds."}, {"title": "C. Evaluation Metrics", "content": "We used several metrics to evaluate NF segmentation performance, including DSC, Volume Overlap Error (VOE), and Absolute Relative Volume Difference (ARVD). DSC, a widely used metric for assessing spatial overlap [26], was calculated per scan and per tumor. VOE and ARVD, which quantify volumetric differences, were included for consistent comparison with the previous study [12].\nWhile DSC, VOE, and ARVD measured the accuracy of tumor segmentation, the F1 score was used to assess the NF detection performance per scan and anatomical region. This metric required calculating True Positives (TP), False Positives (FP), and False Negatives (FN). A tumor instance from a ground truth mask was counted as a TP if it overlapped with a prediction, and as an FN if it did not. A tumor instance from a predicted segmentation mask was counted as an FP if it did not match any ground truth."}, {"title": "D. Implementation Details", "content": "The NF segmentation pipeline was implemented in Python 3.9 and integrated into 3D Slicer [17] via MONAI Label. U-Net models were built using MONAI [33] and PyTorch, with architecture refinement via the nnU-Net framework. Image processing used SimpleITK, and anatomy segmentation relied on the MRSegmentator repository. Tumor candidate classification utilized PyRadiomics for feature extraction, Scikit-Learn for feature selection and random forest-based classification. All experiments were run on two NVIDIA RTX A6000 GPUs.\nThe 3D anisotropic anatomy-informed U-Net model had a batch size of 2 with 2-channel inputs (T2w WB-MRI and anatomy segmentation mask). We applied Z-score normalization to T2w WB-MRI images to standardize the intensity distribution across different scans, compensating for variability in MRI protocols and acquisition parameters. The anatomy segmentation masks were rescaled to the range 0-1, maintaining numerical stability during training. The model was trained with generalized Dice Focal Loss for imbalanced segmentation, and optimized with the AdamW algorithm (weight decay = 5 \u00d7 10-5). An initial learning rate of 1 \u00d7 10-4 was decayed by 0.99 per epoch over 1000 epochs, with the best validation checkpoint used as the final model. We used 3-fold cross-validation. Inference was performed using a sliding window approach with a 25% overlap."}, {"title": "V. RESULTS", "content": "We evaluated six NF segmentation methods across three test sets to determine improvements over the baseline (Table III): a baseline 3D isotropic U-Net, a 3D anisotropic U-Net, a 3D anisotropic anatomy-informed U-Net, an ensemble of 3D anisotropic anatomy-informed U-Nets, and ensembles of 3D anisotropic anatomy-informed U-Nets with low- and high-confidence tumor candidate classification. The low-confidence threshold used for tumor candidate classification was set at the median of the lowest confidence values in the predicted NF segmentation masks, and the high-confidence threshold at a default value of 0.5.\nFirst, the segmentation metrics were calculated per scan. Methods incorporating anisotropy handling and anatomical knowledge outperformed the baseline across all test sets. Ensembling-based method further improved performance in datasets with higher variability in MRI protocols and tumor presentation (Test set #2 and #3). Tumor candidate classification had mixed results. The ensemble of the 3D anisotropic anatomy-informed U-Nets with low-confidence tumor candidate classification achieved the highest per-scan DSC of 0.64 on Test set #1, representing a 68.4% increase over the baseline. For Test set #2 and #3, the ensembling-based methods without and with high-confidence tumor candidate classification achieved the highest per-scan DSCs of 0.51 and 0.23, respectively."}, {"title": "B. Neurofibroma Detection Performance", "content": "1) Per-Scan Analysis: We compared the tumor detection performance using per-scan F1 scores across three test sets (Table IV). Method 2 (i.e., anisotropic U-Net) significantly outperformed Method 1 (baseline) across all sets. Method 3 (with anatomical knowledge and ensembling) improved the results on Test set #3 but did not consistently outperform Method 2 on the other sets. Method 4 (with tumor candidate classification) achieved the highest F1 scores of 0.44, 0.54, and 0.17 on Test set #1, #2, and #3, corresponding to increases of 110%, 170%, and 1600% over the baseline, although the improvement over Method 3 on Test set #3 was not statistically significant.\n2) Analysis Per Anatomical Region: We analyzed mean F1 scores for tumor detection across anatomical regions: head and neck, chest, abdomen, and legs (Fig. 5). Performance generally improved with method complexity, from Method 1 to Method 4. Methods 2 (anisotropic U-Net) and 3 (with anatomical knowledge and ensembling) showed gradual improvements, whereas Method 4 (with tumor candidate classification) consistently outperformed the others in most regions.\nAll methods performed best in the legs region, indicating fewer challenges for tumor detection in the lower body. The chest and abdomen regions showed moderate performance. The head and neck was the most challenging region for tumor detection, with the lowest mean F1 scores across all methods."}, {"title": "C. Domain Shift Robustness Analysis", "content": "We assessed the robustness of NF segmentation methods to domain shifts by analyzing performance degradation when the neural networks trained on 3T MRI were tested on 1.5T MRI dataset (Test set #2). Performance changes were measured using per-scan DSC (Fig. 6). The analysis revealed varying levels of robustness to domain shifts. Methods 1 (baseline), 2 (with anisotropy), and 3 (with anatomical knowledge and ensembling) experienced moderate performance differences, although these changes were not statistically significant. Method 4 (with tumor candidate classification) exhibited a statistically significant performance drop, indicating limited robustness to changes in MRI field strength compared to other methods."}, {"title": "VI. DISCUSSION", "content": "1) Key Findings and Implications: Introducing anisotropy into the U-Net architecture significantly improved NF segmentation, with the 3D anisotropic U-Net outperforming the baseline 3D isotropic U-Net, especially for hard-to-segment anatomical regions (e.g., improved segmentation in head, cases 1 and 3, Fig. 7). The 3D anisotropic anatomy-informed U-Net enhanced performance by leveraging anatomical context to focus on likely NF regions, increasing true positive rates (e.g., improved segmentation in superior mediastinum, case 1, Fig. 7). The ensemble strategy with tumor candidate classification achieved the best overall performance, reducing false positives by using radiomic features to distinguish tumors from non-tumor regions. It also improved segmentation in low-confidence areas, capturing larger tumor regions in diffuse NF cases (Fig. 7, cases 2 and 3). However, this method was more sensitive to domain shifts.\n2) Comparison with Previous Studies: Direct comparison with other studies is limited by data availability, but we benchmarked our findings across diverse datasets against [12], as both used the same evaluation protocol (Table V). Compared to the nnU-Net baseline, our method showed superior performance on Test set #1 and #2, due to the integration of anatomical knowledge, ensembling, and tumor candidate classification, underscoring the potential of our approach for NF segmentation. Whereas the interactive DINs method performed well, our method achieved competitive performance on Test set #1 with no manual intervention."}, {"title": "B. Limitations of Existing Evaluation Protocols", "content": "As outlined in Table VI, multiple protocols and strategies exist for evaluating NF segmentation. Although recent studies adopted DSC to measure segmentation accuracy, DSC can be calculated differently depending on the study: in 2D or 3D, per tumor or over all tumors in a scan. Size thresholds for the inclusion of tumors in the evaluation also differ, with some studies using 75 cm\u00b3 as a minimum [9], [11], whereas others include tumors as small as 5 cm\u00b3 [10], [14], [15]. This lack of a unified evaluation protocol complicates direct comparisons between segmentation methods [9]-[12].\nPer-scan DSC, commonly used in evaluation of DL-based methods, has limitations in the case of NF task, characterized by many small tumors spread across the body. Per-scan DSC is heavily skewed by background voxels in WB-MRI, and excluding the background increases sensitivity to small errors, resulting in high variability, especially in datasets with few tumors (e.g., Test set #3)."}, {"title": "VII. CONCLUSION", "content": "We presented a novel automated segmentation pipeline for NF in T2w WB-MRI, incorporating anatomical knowledge through a 3D anisotropic U-Net with ensembling and radiomics-based tumor candidate classification. Our method outperformed reported fully automated methods like nnU-Net and achieved performance comparable to interactive, i.e. semi-automated methods such as DINs.\nThe integration into the 3D Slicer platform [17] showed promise for clinical application. However, challenges for clin-"}]}