{"title": "MeGA: Merging Multiple Independently Trained Neural Networks Based on Genetic Algorithm", "authors": ["Daniel Yun"], "abstract": "In this paper, we introduce a novel method for merging the weights of multiple pre-trained neural networks using a genetic algorithm called MeGA. Traditional techniques, such as weight averaging and ensemble methods, often fail to fully harness the capabilities of pre-trained networks. Our approach leverages a genetic algorithm with tournament selection, crossover, and mutation to optimize weight combinations, creating a more effective fusion. This technique allows the merged model to inherit advantageous features from both parent models, resulting in enhanced accuracy and robustness. Through experiments on the CIFAR-10 dataset, we demonstrate that our genetic algorithm-based weight merging method improves test accuracy compared to individual models and conventional methods. This approach provides a scalable solution for integrating multiple pre-trained networks across various deep learning applications. Github is available at: Here", "sections": [{"title": "1 Introduction", "content": "In recent years, deep learning has achieved state-of-the-art performance across various tasks, such as image classification and natural language processing, largely due to the use of pre-trained neural networks [9, 22, 28]. These networks can be fine-tuned for specific tasks, saving computational resources and time. However, effectively combining multiple pre-trained models of the same architecture to harness their collective strengths and mitigate individual weaknesses remains a significant challenge.\nMerging weights from different pre-trained models with identical architectures is crucial because individual models often learn complementary features from the data [12, 4, 24]. Combining these models can create a more robust and accurate system, leveraging the strengths of each model and leading to improved performance. Additionally, model fusion can help achieve better generalization by averaging out individual biases and reducing overfitting [4, 21, 32].\nTraining models in parallel rather than sequentially offers efficiency and practicality. Multiple models can learn diverse patterns quickly, and merging their"}, {"title": "2 Related Works", "content": "The fusion of neural network models has been an active area of research due to its potential to enhance model performance by leveraging the strengths of individual models. Several methods have been proposed to address the challenges associated with model merging, each with unique approaches and varying degrees of success.\nWeight Merge. One of the earliest and simplest methods for model fusion is weight averaging, where the weights of two or more models are averaged to create a new model. This approach, while straightforward, often fails to consider the complex interactions between different layers of the networks. Goodfellow et al. introduced an approach that averages the weights of neural networks trained with different initializations, showing marginal improvements in performance [10]. Similarly, ensemble methods, where the predictions of multiple models are combined, have been extensively studied and are known to improve model robustness and accuracy [20]. However, these methods do not directly merge the models' internal representations, potentially limiting their effectiveness. Izmailov et al. proposed Stochastic Weight Averaging (SWA), which improves generalization by averaging weights along the trajectory of SGD with a cyclical or constant learning rate [17]. Welling and Teh applied Stochastic Gradient Langevin Dynamics (SGLD) to sample from the posterior distribution of model weights, thereby integrating Bayesian principles into model merging [32]. This method helps in capturing the model uncertainty but is computationally intensive and complex to implement. Huang et al. introduced the concept of Snapshot En-"}, {"title": "3 Methodology", "content": "In this section, we describe the methodology used to merge the weights of two pre-trained neural network models using a genetic algorithm. We call our methodology, MeGA. Genetic algorithms provide a robust optimization framework by mimicking natural selection, making them suitable for complex tasks like weight merging [26].\nOur approach aligns with the lottery ticket hypothesis, which suggests that neural networks contain critical weights (winning tickets) necessary for maintaining and enhancing performance [7]. In our MeGA algorithm, child models inherit and preserve these beneficial weight configurations from their parent models. By iteratively selecting the best-performing individuals as parents, the algorithm ensures that critical weights are retained and combined, allowing child models to evolve and enhance overall performance. This method enables us to effectively navigate the weight space, merging multiple pre-trained models into a single, superior model that leverages the strengths of each original network."}, {"title": "3.1 Genetic Algorithm Framework", "content": "The process of merging two neural networks using a genetic algorithm is illustrated in Figure 1. The initial population is created by combining the element-wise weights from two pre-trained networks. Each individual in the population represents a potential solution with a unique combination of weights. The genetic algorithm iteratively selects the best-performing individuals as parents based on their evaluation, performs crossover to generate new children, and applies mutation to introduce variability. This process continues during several generations, resulting in a single merged network that combines the strengths of both original networks.\nGenetic algorithms operate on a population of potential solutions, iteratively improving them through the processes of selection, crossover, and mutation [26]. Each individual in the population represents a candidate solution, and its fitness is evaluated based on a predefined objective function. The algorithm proceeds by selecting individuals with higher fitness to produce offspring, combining their traits through crossover, and introducing random variations through mutation. Over successive generations, the population evolves towards better solutions [26]."}, {"title": "Preliminaries", "content": "Let $X \\in \\mathbb{R}^{n \\times d}$ be the training data, where $n$ is the number of samples and $d$ is the dimensionality of each sample. The corresponding labels are denoted by $y \\in \\mathbb{R}^n$. We define two pre-trained neural networks, $f_1(X; \\theta_1)$ and $f_2(X; \\theta_2)$, where $\\theta_1$ and $\\theta_2$ represent the weights of the respective models. Our objective is to merge these weights to create a new model $f(X; \\theta)$ that achieves superior performance."}, {"title": "Algorithm Execution", "content": "The genetic algorithm iterates through $G$ generations, performing selection, crossover, and mutation at each step. The best individual $\\theta^*$ with the highest fitness across all generations is selected as the final set of weights for the fused model. The overall procedure is summarized as follows:\n1. Initialization: Create an initial population $P$ of $N$ individuals.\n2. Fitness Evaluation: Evaluate the fitness $F(\\theta)$ for each individual in $P$.\n3. Selection: Select $K$ parents from $P$ using tournament selection.\n4. Crossover: Generate offspring through crossover of selected parents.\n5. Mutation: Apply mutation to the offspring.\n6. Population Update: Form the new population $P'$ with the best individual from $P$ (elitism) and the newly generated offspring.\n7. Iteration: Repeat steps 2-6 for $G$ generations."}, {"title": "Initialization", "content": "The initial population $P$ consists of $N$ individuals, where each individual represents a potential solution in the form of a set of weights $\\theta$. Each individual is initialized to ensure diversity, which is crucial for the effectiveness of the genetic algorithm.\nThe weights of each individual $\\theta$ are initialized as a linear combination of the weights from two pre-trained models, $\\theta_1$ and $\\theta_2$:\n$\\theta_i = \\alpha \\theta_1 + (1 - \\alpha) \\theta_2, \\quad \\alpha \\sim \\text{Uniform}(0, 1)$"}, {"title": null, "content": "Here, $\\alpha$ is a random scalar drawn from a uniform distribution between 0 and 1. This ensures that each individual's weights are a unique blend of the two parent models. By initializing the population in this manner, we promote diversity among the candidate solutions, helping the genetic algorithm effectively explore the solution space and avoid premature convergence.\nThe combination of weights is applied element-wise to preserve the detailed characteristics of both parent models. Let $\\theta_{1,j,k}$ and $\\theta_{2,j,k}$ denote the $(j, k)$-th element of the weight matrices of the two pre-trained models. The $(j, k)$-th element of the combined weight matrix for the $i$-th individual is given by:\n$\\theta_{i,j,k} = \\alpha \\theta_{1,j,k} + (1 - \\alpha) \\theta_{2,j,k}, \\quad \\alpha \\sim \\text{Uniform}(0, 1)$"}, {"title": "Fitness Evaluation", "content": "The fitness of each individual in the population is assessed based on the validation accuracy on a hold-out validation set $(X_{\\text{val}}, y_{\\text{val}})$. For an individual with weights $\\theta_i$, the fitness function $F(\\theta_i)$ is defined as follows:\n$F(\\theta_i) = \\text{Accuracy}(f(X_{\\text{val}}; \\theta_i), y_{\\text{val}})$"}, {"title": null, "content": "This function measures how accurately the model with weights $\\theta_i$ predicts the labels of the validation set. The model $f(X; \\theta_i)$ is evaluated, and the accuracy is computed as the proportion of correctly classified samples in $X_{\\text{val}}$.\nMathematically, the accuracy is given by:\n$\\text{Accuracy}(f(X; \\theta), y) = \\frac{1}{N_{\\text{val}}} \\sum_{i=1}^{n_{\\text{val}}} I\\left(\\arg \\max_j f_j(X_i; \\theta) = y_i\\right)$"}, {"title": null, "content": "where $n_{\\text{val}}$ is the number of validation samples, $f_j(X_i; \\theta)$ is the predicted probability for class $j$ for the $i$-th validation sample, and $I$ is the indicator function that equals 1 if the predicted class matches the true label $y_i$, and 0 otherwise."}, {"title": "Selection", "content": "Tournament selection is employed to choose $K$ parents for the next generation. This method ensures that individuals with higher fitness are more likely to be selected, promoting desirable traits in subsequent generations. The selection process involves several steps.\nFirst, we randomly select $t$ individuals from the current population $P$ to form a tournament set $T$:\n$T = {\\theta_1, \\theta_2, ..., \\theta_t}, \\quad T \\subseteq P$"}, {"title": null, "content": "Next, the fitness $F(\\theta)$ of each individual $\\theta$ in the tournament set $T$ is evaluated using the previously defined fitness function:\n$F(\\theta) = \\text{Accuracy}(f(X_{\\text{val}}; \\theta), y_{\\text{val}})$"}, {"title": null, "content": "After evaluating the fitness of all individuals in the tournament set, the individual with the highest fitness is selected as a parent:\n$\\theta_{\\text{parent}} = \\arg \\max_{\\Theta \\in T} F(\\theta)$"}, {"title": null, "content": "This process is repeated until $K$ parents are selected for crossover."}, {"title": "Crossover", "content": "Crossover is performed on pairs of selected parents to generate offspring. This process combines the genetic material (weights) of two parents to produce a new individual (offspring), thereby promoting genetic diversity. Given two parents $\\theta_a$ and $\\theta_b$, an offspring $\\theta_{\\text{child}}$ is created by taking a weighted combination of the parents' weights:\n$\\theta_{\\text{child}} = \\beta \\theta_a + (1 - \\beta) \\theta_b, \\quad \\beta \\sim \\text{Uniform}(0, 1)$"}, {"title": null, "content": "The crossover is performed element-wise for each weight:\n$\\theta_{\\text{child},j,k} = \\beta \\theta_{a,j,k} + (1 - \\beta) \\theta_{b,j,k}, \\quad \\beta \\sim \\text{Uniform}(0, 1)$"}, {"title": "Mutation", "content": "Mutation introduces variability into the population by perturbing the weights of the offspring. For each weight $\\theta_{j,k}$ in the offspring $\\theta_{\\text{child}}$, mutation is applied with a probability $p_{\\text{mut}}$:\n$\\theta_{\\text{child},j,k} \\leftarrow \\theta_{\\text{child},j,k} + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2)$"}, {"title": null, "content": "Here, $\\epsilon$ is a random variable drawn from a normal distribution with mean 0 and variance $\\sigma^2$. The mutation rate $p_{\\text{mut}}$ controls the likelihood of each weight being mutated. This mutation process ensures that the population maintains genetic diversity by introducing new genetic material."}, {"title": "4 Experimental Results", "content": "We utilized the CIFAR-10 dataset [19]. We trained Convolutional Neural Network (CNN) models: ResNet [13], Xception [2], and DenseNet [16] without pre-trained weights and without data augmentation. These models were trained using a batch size of 256 over 50 epochs with the Adam optimizer [18], using a learning rate of 0.01. Each model followed the same architecture and hyperparameters to ensure consistency and a fair comparison. After training, we applied the genetic algorithm-based neural network merging (MeGA) approach to merge the weights of these models into a single set of weights. The performance of the"}, {"title": "4.1 Experimental Settings", "content": "We utilized the CIFAR-10 dataset [19]. We trained Convolutional Neural Network (CNN) models: ResNet [13], Xception [2], and DenseNet [16] without pre-trained weights and without data augmentation. These models were trained using a batch size of 256 over 50 epochs with the Adam optimizer [18], using a learning rate of 0.01. Each model followed the same architecture and hyperparameters to ensure consistency and a fair comparison. After training, we applied the genetic algorithm-based neural network merging (MeGA) approach to merge the weights of these models into a single set of weights. The performance of the"}, {"title": "4.2 Image Classification Results", "content": "The results of the image classification experiments on the CIFAR-10 dataset [19] demonstrate the effectiveness of the Genetic Algorithm-based Neural Network (MeGA) weight merging approach, as shown in Table 2.\nFigure 2 shows the progression of the best fitness values over 20 generations for the ResNet-56 and DenseNet 121 models. For the ResNet-56 model, the best fitness improved steadily from 0.8042 in the first generation to 0.8224 in the twentieth generation. Similarly, the DenseNet 121 model saw an improvement in best fitness from 0.7290 to 0.7427 over the same period. These plots illustrate the genetic algorithm's capability to effectively navigate the weight space and optimize combinations to enhance model performance."}, {"title": "4.3 Extended Experiments for Multi-Models", "content": "In this section, we illustrate the application of our genetic algorithm-based weight merging method to combine multiple neural network models. This process leverages the collective strengths of various models, thereby enhancing overall performance. The hierarchical merging approach we employed systematically and effectively merges the weights of eight independently trained ResNet56 models into a single robust model. The hierarchical structure of this merging process is depicted in Figure 3.\nThe hierarchical merging process begins with training eight ResNet56 [13] models on the CIFAR-10 dataset [19]. These models are then paired and merged"}, {"title": null, "content": "using a genetic algorithm, resulting in four intermediate models: Merged Network 1 through Merged Network 4. The algorithm optimizes weight combinations through selection, crossover, and mutation. Next, these four intermediate models are further merged into two higher-level models, Merged Network 5 and Merged Network 6, using the same genetic algorithm approach. Finally, the two higher-level models are merged into a single final model, the Final Network, ensuring it combines the strengths of all eight original models."}, {"title": "5 Discussion", "content": "The application of genetic algorithm-based weight merging to combine multiple neural network models presents several significant advantages. This method is particularly beneficial for leveraging the strengths of various independently trained models, leading to enhanced overall performance. Belows are several significant advantages:\nCapturing Complementary Features: Merging multiple neural networks captures complementary features learned by individual models. Each model specializes in recognizing different patterns within the data, and combining their weights results in improved accuracy and robustness.\nSupport for Distributed Environments: This method supports efficient and scalable training in distributed environments. By enabling the merging of models trained across multiple GPUs or devices, the approach facilitates distributed training, which is valuable in cloud-based systems or edge computing environments.\nReduced Inference Resource Usage: Using a single, high-performance merged model reduces inference resource usage compared to using multiple models. This is particularly beneficial in environments where computational resources are limited or where efficiency is critical, such as mobile or embedded systems.\nThe genetic algorithm-based weight merging technique significantly enhances the performance of neural networks by effectively combining multiple pre-trained models. This method improves accuracy and generalization while offering practical benefits in terms of training efficiency, scalability, and resource usage. The hierarchical merging approach underscores the potential of genetic algorithms in optimizing neural network weights, providing a robust and efficient tool for modern deep learning applications."}, {"title": "6 Conclusion", "content": "In this paper, we introduced a genetic algorithm-based method for merging the weights of multiple pre-trained neural networks. This approach demonstrated"}, {"title": null, "content": "significant improvements in model performance and robustness by effectively combining the strengths of individual models. Our experiments on the CIFAR-10 dataset confirmed that the hierarchical merging process of eight ResNet56 models results in a final model with superior accuracy and generalization compared to traditional methods like weight averaging and ensemble techniques.\nThe genetic algorithm's ability to optimize weight combinations through selection, crossover, and mutation allows for the creation of a more effective merged model without the need for additional training or architectural changes. This method also supports scalable and efficient training in distributed environments, making it a practical solution for various deep learning applications.\nOverall, the genetic algorithm-based weight merging technique offers a powerful tool for enhancing neural network performance, providing a robust and efficient framework for integrating multiple pre-trained models. This work highlights the potential of genetic algorithms in neural network optimization, paving the way for further research and applications in artificial intelligence and machine learning."}]}