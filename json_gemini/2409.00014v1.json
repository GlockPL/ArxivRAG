{"title": "DivDiff: A Conditional Diffusion Model for Diverse Human Motion Prediction", "authors": ["Hua Yu", "Yaqing Hou", "Wenbin Pei", "Yew-Soon Ong", "Qiang Zhang"], "abstract": "Diverse human motion prediction (HMP) aims to predict multiple plausible future motions given an observed human motion sequence. It is a challenging task due to the diversity of potential human motions while ensuring an accurate description of future human motions. Current solutions are either low-diversity or limited in expressiveness. Recent denoising diffusion models (DDPM) hold potential generative capabilities in generative tasks. However, introducing DDPM directly into diverse HMP incurs some issues. Although DDPM can increase the diversity of the potential patterns of human motions, the predicted human motions become implausible over time because of the significant noise disturbances in the forward process of DDPM. This phenomenon leads to the predicted human motions being hard to control, seriously impacting the quality of predicted motions and restricting their practical applicability in real-world scenarios. To alleviate this, we propose a novel conditional diffusion-based generative model, called DivDiff, to predict more diverse and realistic human motions. Specifically, the DivDiff employs DDPM as our backbone and incorporates Discrete Cosine Transform (DCT) and transformer mechanisms to encode the observed human motion sequence as a condition to instruct the reverse process of DDPM. More importantly, we design a diversified reinforcement sampling function (DRSF) to enforce human skeletal constraints on the predicted human motions. DRSF utilizes the acquired information from human skeletal as prior knowledge, thereby reducing significant disturbances introduced during the forward process. Extensive results received in the experiments on two widely-used datasets (Human3.6M and HumanEva-I) demonstrate that our model obtains competitive performance on both diversity and accuracy.", "sections": [{"title": "I. INTRODUCTION", "content": "Human motion prediction has gained tremendous attention in the realm of human-robot interactions. This field has wide-ranging applications, such as human motion understanding [1], [2], autonomous driving [3], [4], and animation [5]\u2013[7]. Prior works for human motion prediction mainly focus on deterministic methods [8], [9]. Given the observed human motion sequence, the designed model aims to predict the most likely future human motions, such as Recurrent Neu-ral Networks (RNNs)-based [10], [11], Graph Convolutional Networks (GCNs)-based [12], [13], Transformer-based [5], [8] methods. However, human motions are often stochastic owing to the complex environments and the uncertainty of human intentions. The deterministic methods are inappropriate for real-world applications in a more complex environment, ignoring the \u201cone-to-many\" nature of the problem. For ex-ample, the observed human motion is \u201cwalking\", the future human motions might be \"jumping\u201d, \u201cwalking\" or \"running\". It means that our designed model is anticipated to predict potential motions corresponding to various walking patterns. Under these settings, the designed method is supposed to learn the multi-modal distribution for diverse human motions.\nGiven a historical motion sequence, the designed stochastic method is supposed to predict multiple possible future mo-tions, i.e., to fully capture all potential patterns of human motions. However, this task is still complex due to the wide variety of human motions and intricate interactions with the surroundings, making it challenging to model dynamic human motions [14], [15]. Deep generative models, such as variational auto-encoders (VAEs) [16]-[18] and generative adversarial networks (GANs) [12], [15], [19], have demonstrated their effectiveness in capturing the data distribution cross all pos-sible human motions. For the VAE-based methods, Yan et al. [20] proposed motion transformation variational auto-encoders (MT-VAE) for generating multiple plausible motions through a stochastic sampling of the feature transformations. Sadegh et al. [21] incorporated a latent variable sampling into the rep-resentation of the observed human motion sequences, which can serve as a source of diversity. Yuan et al. [22] investigated a trainable sampling strategy called DLOW, enhanced with prior knowledge to promote the diversity of future predictions, aiming to reduce redundancy. Although significant progress has been made, the VAE-based methods usually tend to capture the major patterns of human motions, i.e., the most likely human motions, while ignoring the minor patterns, i.e., low-probability motions.\nFor GAN-based methods, Barsoum et al. [23] proposed a probabilistic generative adversarial network (HP-GAN) along with a noise variable to learn a probability density function of future human motions. This method utilizes a random vector z from a prior distribution to control the generation of multiple possible future human poses. However, their method tends to ignore the random vectors. To alleviate this issue, Kundu et al. [24] introduced a novel bidirectional method (BiHMP-"}, {"title": "II. RELATED WORK", "content": "Motivated by the recent advances in synthesis and genera-tion tasks [26], [27], Denoising Diffusion Probabilistic Model (DDPM) [28] is utilized to predict future human motions [29]. The forward process of DDPM gradually adds Gaussian noise to the input sequences controlled by the variance schedule B until the whole sequence is completely corrupted as Gaussian noise. The reverse process of DDPM aims to recover the realistic human motion from the noise. After conducting ex-tensive experiments, we have noticed that introducing DDPM into the diverse human motion prediction may incur some issues. When using a smaller number of denoising steps (typically \u226450) in the reverse diffusion process, the predicted human motions might be more diverse but usually lead to low accuracy. On the other hand, when using a larger number of denoising steps (typically >500), though the accuracy of the results is improved, the diversity of predicted human motions is declined. This is mainly because using more diffusion steps usually generates realistic human motions and is not capable of learning multiple patterns of motions, while too few steps cannot generate realistic human motions due to significant disturbances. In addition, more denoising steps lead to a slow inference process. The noise parameter in the late stage of the forward process fluctuates significantly compared to the early stage, causing noticeable disturbances in the late stage of the reverse process. The aforementioned phenomenon involves a delicate balance between the diversity and accuracy of predicted human motions. However, this issue has received limited attention in existing works on human motion prediction. In view of this, it is prompted to investigate an effective method that promotes high diversity and motion quality.\nTo facilitate this, we propose a novel method called DivDiff, which is based on a conditional DDPM, for more diverse and realistic 3D human motion prediction. Specifically, for the forward process of DDPM, the motion sequence is diffused into white noise by progressively adding Gaussian noise at each time step. For the reverse process of DDPM, the proposed method designs a state embedding to instruct the reverse diffusion process, which consists of encoding the observed sequence using Discrete Cosine Transform (DCT) [30] and transformers [31]. The aim is to capture temporal smooth and spatial relations between human joints. In addition, a novel Diversified Reinforcement Sampling Function (DRSF) is introduced into the late stage of the reverse process due to the significant disturbances of added noise in the forward process. DRSF leverages graph convolutional network [9] to obtain the human skeleton constraint information, which functions as prior knowledge to effectively capture the internal relationship between human bones. Thereby improving the quality of predicting human motions. This operation enables the prediction of realistic and diverse human motions while accelerating the inference process with fewer denoising steps. As shown in Fig. 1, given an observed human sequence, the proposed DivDiff method is capable of predicting multiple and realistic human motions.\nOverall, the contributions of this work are summarized as follows:\n\u2022 We propose an efficient diffusion-based generative model, called DivDiff, for 3D diverse human motion prediction. Our method is built upon the conditional Denoising Diffusion Probabilistic Model and is capable of predicting"}, {"title": "A. Deterministic Human Motion Prediction", "content": "Most previous efforts on human motion prediction have focused on predicting the most likely future human motions, and tend to utilize deterministic models [8], [32]. Specifically, these methods cast motion prediction as a regression task where one output is produced given the observed sequence. Considering the efficacy of recurrent neural networks (RNNs) [10] in capturing temporal dependencies in time-series data, numerous researchers [11], [33], [34] resort to employing RNNs-based variant for this task. Nevertheless, these ap-proaches frequently encounter issues of discontinuity and error accumulation due to their structure characteristics.\nTo mitigate this phenomenon, Graph Convolutional Net-works (GCNs) [13], [30], [32], [35] based methods have been leveraged as a solution for predicting future human motions, as they are effective in capturing the intricate spatial and tem-poral relations between human motions. Nevertheless, GCNS have some limitations in modeling long-range dependencies, because the convolutional operations have a limited receptive field. To address this issue, the transformer mechanism [31] has been introduced as an alternative to handle the human motion prediction [5], [8]. The transformer mechanism uti-lizes the self-attention mechanism to model the dependencies between any two positions in the sequence, regardless of their distance. This makes it well-suited for capturing long-range dependencies.\nWhile remarkable progress has been made, these methods seldom consider the inherent uncertainty of human motions under the complex real world. This refers to the fact that there are diverse solutions for human motion prediction. Different from these methods, this work attempts to predict multiple possible human motions given a single observed human se-quence."}, {"title": "B. Diverse Human Motion Prediction", "content": "Given the inherent indeterminacy of future human motions, the generative models like variational autoencoders (VAEs) [16], [17], generative adversarial networks (GANs) [19], [36], [37] and denoising diffusion probabilistic model (DDPM) [28], [29] are appropriate methods for diverse human motion prediction due to their capability of generating a diverse set of valid solutions. Generally, VAEs [17], [38] utilize the encoder-decoder mechanism to handle the task by capturing the probability distribution of human motions. In these methods, the major modes (with higher likelihood) corresponding to a particular human motion pattern will more likely generate samples, minor patterns (those with lower likelihood) will almost not generate any samples. For example, as shown in Fig. 2, the VAEs method generates a large number of samples, which are mainly concentrated on the major patterns of the data distribution and fail to cover the minor patterns. Our method is capable of capturing the potential likely patterns of human motions. GANs [19], [36] employ a generator to produce multiple future human motions, while a discrimi-nator ensures that the generated motions are similar to the ground truth. However, these methods are often prone to mode collapse and involve complex adversarial learning. This phenomenon may result in the predicted motions being limited to a narrow set of possibilities, instead of capturing the full diversity of the observed human motions.\nMore recently, DDPM [28] has been proposed as an al-ternative generative approach for the task of human motion generation. For example, Tevet et al. [29] designed a Motion Diffusion Model (MDM) for various human motion genera-tion, enabling different modes of conditioning, and different generation tasks. Ye et al. [27] have attempted to alleviate this issue by introducing physics simulation, which is based on a pre-trained physical model through reinforcement learning. However, their approach is computationally intensive and the physics simulator cannot be trained together with the proposed"}, {"title": "III. THE PROPOSED METHOD", "content": "In this section, we first briefly introduce the problem formulation. Then, the preliminaries are described for the mechanism of acquiring spatio-temporal information of human motions. Subsequently, the forward motion diffusion process is reported for diverse human motion prediction. Finally, the diversity reinforcement sampling function is presented in the conditional reverse process to enhance the diversity and control the quality of future human motions."}, {"title": "A. Problem Formulation", "content": "An overview of the proposed DivDiff method is illustrated in Fig. 3. The observed historical sequence is denoted as X = {x\u2081,x\u2082,...,x\u209c} with length T, and the predicted human sequences is denoted as Y = {Y\u209c\u208a\u2081, Y\u209c\u208a\u2082,..., Y\u209c\u208a\u2099} with length N, where x \u2208 \u211d\u00b3\u02e3\u1d36 is denoted by 3D coordinates at time t, J is the number of human joints in a frame. Our goal is to predict diverse and realistic human motions through denoising process. Specifically, the forward process gradually introduces Gaussian noise to the input motions, ending with a whitened latent state. Conversely, the reverse process recon-structs the diverse future motions with a parameterized Markov chain. The DCT and transformer mechanisms are leveraged to encode the spatio-temporal information of human motions as a condition, so as to produce more smooth and realistic human motions. The DCT and Transformer operations extract both periodic temporal properties and spatial relations from the motion sequence, which is beneficial for obtaining continuous motions. At the same time, the DRSF is introduced into the reverse process to enhance the diversity and quality of the predicted human motions."}, {"title": "B. Preliminaries", "content": "Discrete Cosine Transform The Discrete Cosine Transform (DCT) operation extracts both current and periodic temporal properties from the motion sequence, which is beneficial for obtaining continuous motions. The proposed method leverages DCT to capture the smoothness property of human motions. Given a human sequence X, the proposed method projects the sequence into the DCT domain through the following operation:\ny = DCT(x), (1)\nThe DCT operation is an orthogonal transform, we can recover the motion sequence from the DCT domain via an inversed iDCT operation, which is formulated as follows:\nx = iDCT(y) (2)\nSpatial Transformer As shown in Fig. 3, the spatial transformer mainly focuses on the inter-dependencies among human joints within the same time step. In the spatial trans-former module process, given a human pose embedding at time t, E\u209c = [e\u207d\u00b9\u207e,...,e\u207d\u00aa\u207e]\u1d40 and the weight matrices W\u207d\u1d3c\u207e, the summary of the spatial joints \u0112\u209c is calculated by"}, {"title": "Algorithm 1 The Diversified Reinforcement Sampling Algo-rithm.", "content": "Input: The state embedding {x\u207d\u2071\u207e, S\u207d\u2071\u207e}\u2081, DDPM D\u03b8(\u03b5, S, t), sample time t, target time s\nOutput: The diversified sampling function g\u03b3(S)\n1: Initialize \u03b3 randomly\n2: if sample time t > time s then\n3: while not converged do\n4: for each \u03b3\u00b2 do\n5: Generate noises \u03b5\u03b8 = {\u03b5\u2081, ..., \u03b5\u2099} with g\u03b3(S)\n6: Generate the predicted future motions Y = Y\u209c\u208a\u2081, ..., Y\u209c\u208a\u2099 with the DDPM D\u03b8(\u03b5, S, t)\n7: Compute the similarity matrix S and quality vector r with Eq. (7) and Eq. (8)\n8: Compute the DPP kernel L(\u03b3) = Diag(r) \u22c5 S\u22c5 Diag(r)\n9: Calculate the final loss L\ud835\udcb9\u1d62\u1d65\u2091\u1d63\u209b\u2091(\u03b3)\n10: Update \u03b3 with gradient \u2207L\ud835\udcb9\u1d62\u1d65\u2091\u1d63\u209b\u2091(\u03b3)\n11: end for\n12: end while\n13: else\n14: Generate noises \u03b5\u03b8 = {\u03b5\u2081, ..., \u03b5\u2099} with DDPM f\u03b8(\u03b5, S, t)\n15: Generate the predicted future motions Y = Y\u209c\u208a\u2081, ..., Y\u209c\u208a\u2099 with the DDPM D\u03b8(\u03b5, S, t)\n16: end if"}, {"title": "E. The Diversified Reinforcement Sampling Strategy", "content": "motion prediction have rarely been considered to address this problem. Therefore, we introduce the DRSF function into the late stage of the reverse process.\nAs previously mentioned, introducing DDPM into human motion prediction cannot guarantee the high diversity and fidelity of predicted human motions. The noise parameter \u03b2 fluctuates significantly in the late stage of the forward process. This causes significant disturbances in the reverse process, making it difficult to control the predicted human motions. In this work, we propose a new strategy (DRSF) for diversified reinforcement sampling that utilizes human skeleton information as prior to predict random noise during the later stages of the reverse process.\nDRSF involves the determinantal point process function (DPP) to improve the diversity of predictions. DPP is an effi-cient probabilistic function to enhance diversity by capturing negative correlations between samples, which has been suc-cessfully applied in many tasks, e.g., document summarization [39], object detection [40] and diverse trajectory forecasting [41]. Our method aims to test the influence of DPP on DDPM for future human motion prediction. DPP models the probability of encompassing a sample while reducing the prob-ability of including similar samples, making it an appropriate tool to capture diversity in a set. In particular, the DRSF is implemented by 3-layer \u03b3-parameterized graph convolutional networks, denoted by g\u03b3(S). In the late stage of the reverse process, the g\u03b3(S) takes the state embedding information S as the input, which contains the human skeleton constraints to output random noises. Then, DDPM samples according to the random noises and decodes them into human motions, i.e., g\u03b3(S) \u2192 \u03b5. To optimize the DRSF, a diversity loss based on DPP is introduced into this work. The detailed procedure is illustrated in Algorithm 1. The following describes how the DPP kernel L constructs a loss function so as to optimize the DRSF.\nDPP establishes the probability associated with selecting a random subset from Gaussian distributions, which involves the Similarity matrix S between two motions, and the Quality vector r of each generated human motion, i.e., L(\u03b3) = Diag(r) \u22c5 S \u22c5 Diag(r). In this work, DPP kernel L(\u03b3) is formulated based on \u03b3 as it is defined on the ground truth Y decoded by the DRSF g\u03b3(S).\nSimilarity: Regarding similarity, the Euclidean distance can serve as a simple yet efficient metric between human motions, then the similarity S\u1d62\u2c7c between two motions y\u1d62 and y\u2c7c are defined as follows:\nS\u1d62\u2c7c = exp(\u2212\u03ba ||y\u1d62 \u2014 y\u2c7c||\u00b2), (7)\nwhere \u03ba is the scaling vector. This operation assures 0 < S\u1d62\u2c7c < 1 and S\u1d62\u1d62 = 1, and S a is positive matrix.\nQuality: Different from the similarity metric, the quality metric is measured as follows:\nr\u1d62 = { \u03c9,  if ||m\u1d62|| \u2264 R\nw exp(\u2212(m\u1d62\u1d40m\u1d62 + R\u00b2)), otherwise, (8)\nwhere R is the radius of a sphere \ud835\udcab that encompasses the majority of samples from the Gaussian prior distribution, and m is the feature representation of human motion. In this way, samples within the boundary defined by \ud835\udcab are treated equally, regardless of whether they belong to major or minor patterns. Samples located far away from the data manifold receive a heavy penalty as they fall outside of \ud835\udcab. \u03c9 denotes the base quality, which controls the item selection in DPP. A larger value of \u03c9 leads the DPP to choose a greater number of items from a whole set.\nWe introduce the following loss function L\ud835\udcb9\u1d62\u1d65\u2091\u1d63\u209b\u2091(\u03b3) to optimize the DRSF g\u03b3(S). The diversity of Y is assessed using the expected cardinality of the DPP, defined as E\u1d67~P\u2097\u208d\u1d67\u208e[|Y|]. Essentially, a randomly drawn subset following the DPP is inclined to include a larger number of diverse items from Y, given that the DPP discourages the selection of similar items. The expected cardinality offers the advantage of being well-defined even when the ground set Y contains duplicate items. Formally, the expected cardinality is defined as follows:\nE[|Y|] = \u2211\u2099=\u2081\u1d3a  \u03bb\u2099/(\u03bb\u2099 + 1) = tr(I \u2212 (L(\u03b3) + I)\u207b\u00b9), (9)\nwhere \u03bb\u2099 is the n-th eigenvalue of L and I denotes the identity matrix. The diversity loss is defined as follows:\nL\ud835\udcb9\u1d62\u1d65\u2091\u1d63\u209b\u2091 (\u03b3) = \u2212 tr (I \u2212 (L(\u03b3) + I)\u207b\u00b9), (10)\nThe L\ud835\udcb9\u1d62\u1d65\u2091\u1d63\u209b\u2091(\u03b3) is employed to optimize the DRSF.\nIn addition, according to [28], the objective training func-tion of the early stage of the reverse process in DDPM is summarized as a simplified loss function:\nL(\u03c8, \u03b8) = \ud835\udd3c\u2096,\u2098, \u03b5 [||\u03b5 \u2014 \u03b5\u03b8 (Y\u2096, k, f\u1d67(S) ||\u00b2], (11)\nwhere k is the diffusion step, f\u1d67(S) denotes the encoded state embedding S with the parameter \u03c8 and \u03b5\u03b8 is the predicted noise in each diffusion step.\nIn brief, the overall loss in the proposed method is a weighted sum of the aforementioned individual loss functions. The formula for the global loss, denoted as L\u209c\u2092\u209c\u2090\u2097, is articu-lated as follows:\nL\u209c\u2092\u209c\u2090\u2097 = \u03b1\u2081L\ud835\udcb9\u1d62\u1d65\u2091\u1d63\u209b\u2091(\u03b3) + \u03b1\u2082L(\u03c8, \u03b8) + \u03b1\u2083min (||Y \u2014 X||\u00b2), (12)\nL\u209c\u2092\u209c\u2090\u2097 is utilized to balance the diversity and the accuracy of the results. The third loss function is used to ensure that the distance of predicted motions is not too far away from the observed motion, thus guaranteeing realism and accuracy. The parameters \u03b1\u2081, \u03b1\u2082, and \u03b1\u2083 represent the coefficients for different losses. These values are determined empirically in our experiments. Specifically, we set \u03b1\u2081 = 0.4, \u03b1\u2082 = 0.3, and \u03b1\u2083 = 0.3 as the loss coefficients.\nSampling: Given a learned reverse diffusion network \u03b8\u2091, an observed sequence X and its corresponding encoder f\u1d67(S), we first sample chaotic states Y\u2096 from \ud835\udca9(0, I). Subsequently, we progressively predict realistic human motions from Y to Y\u2080 by the following formula:\nY\u2096\u208b\u2081 = 1/\u221a\u03b1\u2096 (Y\u2096 - (\u03b2\u2096/\u221a1-\u03b1\u2096)\u03b5\u03b8(Y\u2096,k,f\u1d67(X))) + \u221a\u03b2\u2096 z, (13)\nwhere z is a random variable from standard Gaussian distri-bution."}, {"title": "IV. EXPERIMENTAL DESIGN", "content": "In this section, the experimental design will be described, encompassing benchmark datasets, parameter settings, evalu-ation metrics, and baseline methods."}, {"title": "A. Datasets", "content": "To keep consistent with the latest methods [12], [27], we evaluate the proposed method on two widely-used datasets, Human3.6M (H3.6M) [42] and HumanEva-I [43]. The details are as follows.\nHuman3.6M: Human3.6M is a widely utilized dataset for 3D human motion prediction, featuring 15 motions performed by 7 actors. We preprocess the dataset through a down-sampling operation to enhance the training efficiency, reducing the frame rate (in frames per second, fps) from 50 to 25. This down-sampling operation aims to make the inherent motion patterns clearer. The proposed method is trained on data from 5 subjects (S1, S5, S6, S7, S8), while subjects S9 and S11 are reserved for testing and validation. In this study, we input 25 frames, equivalent to 0.5 seconds at 50fps, to predict 100 frames.\nHumanEva-I: HumanEva-I consists of 3 subjects, which are performed in 5 action categories, depicted by video cap-tured at 60 Hz. A person is represented by a skeleton with 15 joints. We adopt the official train/test split [22] and also remove the global translation. The proposed method predicts 60 future poses (1s, 60fps) given 15 past frames."}, {"title": "B. Parameter Settings", "content": "For the diffusion network, the proposed DivDiff method utilizes an encoder to upsample the hidden dimension of 3D coordinates of human joints from 3d to 512d, which consists of DCT and transformer mechanisms. Then, the DivDiff employs a decoder that has the same structure to decode the dimension to 3d. The DSRF is implemented by a 3-layer GCN. Our method predicts 50 diverse future motions (N = 50) given a past motion. In contrast with other methods, the number of steps K in the diffusion process is set to 200. The variance schedules is set to be \u03b2\u2081 =0.0001 and \u03b2\u043a =0.05, where \u03b2K are linearly interpolated (1 < k < K). The proposed DivDiff method is implemented using the PyTorch framework in Python 3.6. To ensure the convergence of the proposed method, we employ the Adam optimizer for model training. The learning rate is initially set to 10\u207b\u2074 and undergoes a decay of 0.98 every 10 epochs. Training for the proposed method spans 500 epochs, utilizing a batch size of 64 for both training and evaluation. All experiments are conducted on the Nvidia Tesla A100 GPU."}, {"title": "C. Evaluation Metrics", "content": "In order to contrast with other methods, we employ the following metrics to measure the diversity and ac-curacy of the proposed method. (1) APD: Average Pair-wise Distance between all pairs of motion samples de-fined as (2/(N(N-1)))\u2211\u1d62\u208c\u2081\u1d3a \u2211\u2c7c>\u1d62 ||Y\u1d62 - Y\u2c7c ||\u2082. (2) ADE: Aver-age Displacement Error over the whole sequence between the ground truth and the closest generated motion defined as min\u1d62 ||Y\u1d62 - X||\u2082. (3) FDE: Final Displacement Error between the last frame of the ground truth and the closest motion's last frame defined as min\u1d62 ||Y\u1d62[f] \u2013 X[f]||\u2082. (4) MMADE: the multi-modal version of ADE; (5) MMFDE: the multi-modal version of FDE. Note that ADE is utilized to measure the diversity while others are utilized to measure the accuracy of the proposed method."}, {"title": "D. Baseline Methods", "content": "Two types of baselines (deterministic and stochastic motion prediction methods) are leveraged in this work to evaluate the performance of the proposed method from the aspect of accuracy and diversity. (1) Deterministic motion prediction methods, including LTD [30], MSR [35] and acLSTM [44]. (2) Stochastic motion prediction methods, including Pose-Konws [38], MT-VAE [20], GMVAE [45], DLow [22], HP-GAN [23], DSF [41], MOJO [46], DivSamp [47], BeLFusion [29] and MotionDiff [26]."}, {"title": "V. RESULTS AND ANALYSIS", "content": "The section endeavors to provide a comprehensive analysis of the experimental results for accuracy and diversity, includ-ing the quantitative comparison results between the state-of-the-art methods and the proposed method, ablation analysis and qualitative analysis."}, {"title": "A. Comparision to Existing Methods", "content": "Table 1 summarizes the comparison prediction results under multiple baseline methods on Human3.6M and HumanEva-I datasets, DivDiff achieves state-of-the-art performance in accuracy and diversity metrics for both datasets. From the empirical evidence, it is observed that the proposed DivDiff method consistently outperforms all the baselines based on all the evaluation metrics. For the deterministic approaches, the diversity results are 0.000 since these approaches only predict one output. The prediction accuracy is also inferior to stochas-tic methods. We speculate that deterministic prediction models tend to predict an average mode as the final result, which leads to higher prediction errors. For the stochastic methods, it can be observed that the DivDiff method outperforms other methods by a large margin in terms of diversity and accuracy, including the DDPM-based method under the same denoising steps. This pronounced discrepancy in performance can likely be attributed to a couple of key factors. The foremost factor is the strategic utilization of the DCT and transformer mecha-nisms as conditional elements for forecasting future motions."}, {"title": "B. Ablation Studies", "content": "In this subsection, ablation studies are conducted to examine the effectiveness of different components of the proposed DivDiff method quantitatively. As described in Table 2, intro-ducing the DCT into this work did not enhance the diversity performance dramatically, but improved the accuracy of the results. This proves that the introduced DCT method is bene-ficial to this task. Notably, incorporating the proposed DRSF-significantly promotes the performance both in diversity and accuracy, which can capture more modes of human motions. Fig. 5 shows the effectiveness of our choice by qualitative results. It can be seen that the diversity of the motions improved through the DRSF (below).\nTo evaluate the influence of the different number of diffu-sion steps K in the proposed method, we provide an analysis of the results between diversity and prediction error on the Human3.6M dataset. As shown in Fig. 6, when K is small, the predicted human motions are more diverse (measured by APD) but usually lead to low accuracy (except when K approaches 200). The other metrics (ADE, FDE, MMADE, and MMFDE) all worsen as the diffusion steps increase. This is because more diffusion steps lead to the predicted close to the ground truth, while fewer diffusion steps can generate more diverse, yet implausible samples. Compared to other methods where the error gradually increases when K approaches 100 (the predicted motions are far from the ground truth, highlighted by red boxes), our method can increase up to nearly 200 diffusion steps. In addition, Fig. 7 shows the change in predicted results with the increase of denoising steps K. It can be observed that the denoising step of 200 produced more diverse human motions compared to setting it to 100. Although a denoising step of 500 can enhance the slight accuracy, the diversity of the predicted motions declines dramatically, which also validates the effectiveness of the proposed method.\nIn addition to the aforementioned results, the experiments have also conducted a visual analysis of the training pro-cess. As illustrated in Fig. 8, comparing the training curves associated with and without the utilization of the DRSF function. This visualization offers valuable insights into the effectiveness of the proposed DRSF function. Specifically, the blue curve represents the training process conducted without the incorporation of the DRSF function, while the green curve corresponds to the proposed DivDiff method in conjunction with the DRSF function. It is clearly evident that the inte-gration of the proposed DRSF function results in a significant acceleration of the convergence speed, consequently enhancing the overall performance of our method. The comprehensive experiments demonstrated that our method achieves better performance with the proposed DRSF function.\nThe comprehensive experiments demonstrate that our method consistently outperforms the state-of-the-art methods. These findings serve to underscore the pivotal role of the proposed DRSF function, particularly in terms of the diversity and reality of the predicted human motions."}, {"title": "VI. CONCLUSION", "content": "The goal of this paper is to predict more diverse and realistic human motions based on the diffusion method. This has been achieved by designing a new method (called DivDiff), which combines the inherent relationships of human skeletons with a conditional DDPM to balance motion diversity and quality in the predicted human motions. Specifically, the observed sequence is encoded by the DCT and transformer and utilized as a condition to instruct the reverse diffusion process. More-over, the proposed DivDiff method utilizes the designed DRSF that leverages graph neural networks to add more human skeleton constraints on the predicted human motions. The DRSF serves as a prior to produce random noises, thereby alleviating significant disturbances of the reverse process.\nIn the experiments, the proposed DivDiff method was compared with two types of human motion prediction methods (i.e., deterministic and stochastic motion prediction methods). Extensive experiments demonstrate that the proposed DivDiff method achieved superior performance in almost all cases. In addition, considering that our method can alleviate the significant disturbance in the late stage of the reverse process in DDPM, the proposed DivDiff method also can be used for many generative-related tasks, such as human motion estimation and image synthesis."}]}