{"title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation", "authors": ["Shu Wang", "Yixiang Fang", "Yingli Zhou", "Xilin Liu", "Yuchi Ma"], "abstract": "Retrieval-Augmented Generation (RAG) has proven effective in integrating external knowledge into large language models (LLMs) for question-answer (QA) tasks. The state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. However, existing graph-based RAG approaches cannot accurately identify the relevant information from the graph and also consume large numbers of tokens in the online retrieval process. To address these issues, we introduce a novel graph-based RAG approach, called Attributed Community-based Hierarchical RAG (ArchRAG), by augmenting the question using attributed communities, and also introducing a novel LLM-based hierarchical clustering method. To retrieve the most relevant information from the graph for the question, we build a novel hierarchical index structure for the attributed communities and develop an effective online retrieval method. Experimental results demonstrate that ArchRAG outperforms existing methods in terms of both accuracy and token cost.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) like GPT-4 [1], Qwen2.5 [65], and LLaMA3.1 [11] have received tremendous attention from both industry and academia [15, 23, 29, 32, 41, 57, 59, 73]. Despite their remarkable success in question-answering (QA) tasks, they may still generate wrong answers due to a lack of domain-specific, real-time updated, and proprietary knowledge outside their pre-training corpus [43]. To enhance the trustworthiness and interpretability of LLMs, Retrieval-Augmented Generation (RAG) methods [13, 14, 21, 23, 62, 68, 71] have emerged as a core approach, which often retrieve relevant information from documents, relational data, and graph data to facilitate the QA tasks.\nThe state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. Given a question Q, the key idea of graph-based RAG is to retrieve relevant information (e.g., nodes, subgraphs, or textual information) from the graph, incorporate them with Q as the prompt, and feed them into the LLM, as illustrated in Figure 1. As shown in the literature, a few recent graph-based RAG methods have emerged for both abstract question [12, 17, 47] and specific question [17, 18, 28, 47, 60, 61], where the former is more conceptual, encompassing broader topics, summaries, or overarching themes (e.g., \"What are the potential impacts of LLMs on education?\"), while the latter is detail-oriented and typically references specific entities within the graph (e.g., \"Who has won the Turing Award in 2024?\") [17]. Technically, the abstract questions need a comprehensive understanding to extract high-level insights, while the specific questions require multi-hop reasoning to connect discrete information."}, {"title": "2 Preliminaries", "content": "Existing graph-based RAG methods often follow a general framework that leverages external structured knowledge graphs to improve contextual understanding of LLMs and generate more informed responses [43]. Typically, it involves two phases:\n(1) Offline indexing: Building a KG G(V, E) from a given corpus D where each vertex represents an entity and each edge denotes the relationship between two entities, and constructing an index based on the KG.\n(2) Online retrieval: Retrieving the relevant information (e.g., nodes, subgraphs, or textual information) from KG using the index and providing the retrieved information to the LLM to improve the accuracy of the response."}, {"title": "3 Our Approach ArchRAG", "content": "Unlike GraphRAG, which purely uses links to generate communities, we propose to detect communities that can be organized into a hierarchical tree structure by exploiting both links and attributes in the knowledge graph, also called attributed communities. An attributed community is a group of entities with a summary, where the entities are not only densely connected but also share similar themes, providing detailed information for answering specific questions, and the summary can offer a condensed view for answering abstract questions since it enables more focused engagement with the entities' attributes. Moreover, in the hierarchical tree structure, the lower-level communities and entities contain detailed knowledge from the KG, while higher-level communities provide global summaries, which naturally enable ArchRAG to address questions with different granularity in abstraction.\nMoreover, to answer questions, we need to efficiently identify highly relevant attributed communities at different levels of the hierarchical structure. Considering that our hierarchical attributed communities and the HNSW index [36] are similar in structure,"}, {"title": "3.1 Offline Indexing", "content": "3.1.1 KG construction. Our first step is to build a KG by prompting the LLM to extract entities and relations from each chunk of the text corpus D. Specifically, all text contexts are segmented into chunks based on specified chunk length, enabling the LLM to extract entities and relations from each chunk using in-context learning [4], thus forming subgraphs. These subgraphs are then merged, with entities and relations that appear repeatedly across multiple subgraphs being consolidated by the LLM to generate a complete description. Finally, we get a KG, denoted by G(V, E), where V and E are sets of vertices and edges, respectively, and each vertex and edge is associated with some textual attributes.\n3.1.2 LLM-based hierarchical clustering. As aforementioned, a high-quality hierarchical attributed community structure provides different granularities of abstraction for the entire knowledge graph, which is beneficial for answering both abstract and specific questions. Therefore, we propose an iterative LLM-based hierarchical clustering framework that supports arbitrary graph augmentation (e.g., KNN connections and CODICIL [46]) and graph clustering algorithms (e.g., weighted Leiden [54], weighted spectral clustering, and SCAN [64]). Specifically, we propose to augment the KG by linking entities if their attribute similarities are larger than a threshold (e.g., KNN connections), and then associate each pair of linked entities with a weight denoting their attribute similarity value. Next, we generate the attributed communities using any given graph clustering algorithm.\nAlgorithm 1 shows the above iterative clustering process. Given a graph augmentation method and clustering algorithm, we perform the following steps in each iteration: (1) augmenting the graph (line 3); (2) computing the edge weights (lines 4-5); (3) clustering the augmented graph (line 6); (4) generating a summary for each community using LLM (line 7); and (5) building a new attributed graph where each node denotes an attributed community and two nodes are linked if their community members are connected (line 9). We repeat the iterations until the stopping condition (such as insufficient nodes or reaching the specified level limit) is met. Since each iteration corresponds to one layer, all the attributed communities HC can be organized into a multi-layer hierarchical tree structure, denoted by A, where each community in one layer includes multiple communities in the next layer."}, {"title": "3.1.3 C-HNSW index", "content": "Given a query, to efficiently identify the most relevant information from each layer of the hierarchical tree \u2206, a naive method is to build a vector database for the attributed communities in each layer, which is costly in both time and space. To tackle this issue, we propose to build a single hierarchical index for all the communities. Recall that the attributed communities in A form a tree structure, and the number of nodes decreases as the layer level increases. Since this tree structure is similar to the HNSW (Hierarchical Navigable Small World) index which is the most well-known index for efficient ANN search [36] (Appendix A.2 introduces its details), we propose to map entities and attributed communities of A into high-dimensional nodes, and then build a unified Community-based HNSW (C-HNSW) index for them.\n\u2022 The structure of C-HNSW. Conceptually, the C-HNSW index is a list of simple graphs with links between them, denoted by H = (G, Linter) with G = {Go = (Vo, Eo), G\u2081 = (V1, E1),\uff65\uff65\uff65, G\u2081 = (VL, EL)}, where Gi is a simple graph and each node of the simple graph corresponds to an attributed community or entity. The number L of layers (simple graphs) of H is the same as the that of A. Specifically, for each attributed community or entity in the i-the layer of A, we map it to a high-dimensional node in the i-th layer of H by using a language model (e.g., nomic-embed-text [42]). After obtaining the high-dimensional nodes, we establish two types of links between them, i.e., intra-layer and inter-layer links:\n\u2022 Intra-layer links: These links exist between nodes in the same layers. Specifically, for each node in each layer, we link it to at least M nearest neighbors within the same layer, where M is a predefined value, and the nearest neighbors are determined according to a given distance metric d. Thus, all the intra-layer links are edges in all the simple graphs:\n$L_{intra} = \\bigcup_{i=0}^{L} E_{i}$\n\u2022 Inter-layer links: These links cross two adjacent layers. Specifically, we link each node in each layer to its nearest neighbor in the next layer. As a result, all the inter-layer links can be represented as follows:\n$L_{inter} = \\bigcup_{i=1}^{L}{\\{(v, \\psi(v))|v \\in V_{i}, \\psi(v) \\in V_{i-1}\\}\\}$"}, {"title": "3.2 Online retrieval", "content": "In the online retrieval phase, after obtaining the query vector for a given question, ArchRAG generates the final answer by first conducting hierarchical search on the C-HNSW index, and then analyzing and filtering of retrieved information.\n3.2.1 Hierarchical search. We first introduce the query process of C-HNSW and then describe the hierarchical search. The query process is the core of C-HNSW, which can be used for constructing C-HNSW as illustrated in Algorithm 2.\nSpecifically, given a specified query layer l, query point q, and the number k of nearest neighbors, the query algorithm can be implemented through the following iterative process:\n(1) Start from a random node at the highest layer L, which serves as the starting node for layer L (line 1).\n(2) For each layer from layers L to 1 + 1, begin at the starting node and use a greedy traversal approach (i.e., the procedure SearchLayer) to find the nearest neighbor c of q, and then traverse to the next layer using c's inter-layer link as the starting node for the next layer (lines 2-4).\n(3) In the query layer l, use the greedy traversal approach to find the k nearest neighbors of q (line 5).\nSpecifically, the greedy traversal strategy compares the distance between the query point and the visited nodes during the search process. It achieves this by maintaining a candidate expansion queue Q and a dynamic nearest neighbor set R, which contains k elements:\n\u2022 Expansion Queue Q: For each neighbor x of a visited node, if d(x, q) < d(f, q), where f is the furthest node from R to q, then x is added to the expansion queue.\n\u2022 Dynamic Nearest Neighbor Set R: Nodes added to C are used to update R, ensuring that it maintains no more than k elements, where k is the specified number of query results.\nIn the greedy traversal, if a node x expanded from Q satisfies d(n, q) > d(n, f), where f is the furthest node from R to q, then the traversal stops."}, {"title": "3.2.2 Adaptive filtering-based generation", "content": "While some optimized LLMs support longer text inputs, they may still encounter issues such as the \"lost in the middle\" dilemma [33]. Thus, direct utilization of retrieved information comprising multiple text segments for LLM-based answer generation risks compromising output accuracy.\nTo mitigate this limitation, we propose an adaptive filtering-based method that harnesses the LLM's inherent reasoning capabilities. We first prompt the LLM to extract and generate an analysis report from the retrieved information, identifying the parts that are most relevant to answering the query and assigning relevance scores to these reports. Then, all analysis reports are integrated and sorted, ensuring that the most relevant content is used to summarize the final response to the query, with any content exceeding the text limit being truncated. This process can be represented as:\n$A_{i} = LLM(P_{filter}||R_{i})$\n$Output = LLM(P_{merge}||Sort(\\{A_{0}, A_{1},\uff65\uff65\uff65, A_{n}\\}\\))$"}, {"title": "4 Experiments", "content": "Our experiments aim to answer following research questions (RQs):\n\u2022 RQ1: How does ArchRAG perform compared with existing baselines on specific and abstract QA tasks?\n\u2022 RQ2: How efficient is the ArchRAG approach?\n\u2022 RQ3: What is the quality of our LLM-based attributed communities, and how does it impact the performance of RAG?\n\u2022 RQ4: How robust is ArchRAG?"}, {"title": "4.1 Setup", "content": "Datasets. We consider both specific and abstract QA tasks. For the specific QA task, we use the following datasets: Multihop-RAG [53], HotpotQA [66], and NarrativeQA [26], all of which are extensively utilized within the QA and Graph-based RAG research communities [3, 18, 22, 47, 63, 67]. Multihop-RAG is designed to evaluate retrieval and reasoning across news articles in various categories. HotpotQA is a QA dataset featuring natural, multi-hop questions. NarrativeQA is a dataset that comprises QA pairs based on the full texts of books and movie transcripts. Besides, we follow the GraphRAG [12] method for the abstract QA task. We reuse the Multihop-RAG corpus and prompt LLM to generate questions that convey a high-level understanding of dataset contents. \nBaselines. Our experiments consider three model configurations:\n\u2022 Inference-only: Using an LLM for direct question answering without any retrieval data, i.e., Zero-Shot and CoT [27].\n\u2022 Retrieval-only: Retrieval models extract relevant chunks from all documents and use them as prompts for large models. We select strong and widely used retrieval models: BM25 [45] and vanilla RAG.\n\u2022 Graph-based RAG: These methods leverage graph data during retrieval. We select HippoRAG [18], GraphRAG [12], and LightRAG [17]. Particularly, GraphRAG has two versions, i.e., GraphRAG-Global and GraphRAG-Local, which use global and local search methods respectively. Similarly, LightRAG integrates local search, global search, and hybrid search, denoted by LightRAG-Low, LightRAG-High, and LightRAG-Hybrid, respectively.\nIn GraphRAG-Global, all communities below the selected level are first retrieved, and then the LLM is used to filter out irrelevant communities. This process can be viewed as utilizing the LLM as a retriever to find relevant communities within the corpus. According to the selected level of communities [12], GraphRAG-Global can be further categorized into C1 and C2, representing high-level and intermediate-level communities, respectively, with C2 as the default.\nMetrics. For the specific QA tasks, we use Accuracy and Recall to evaluate performance on the first two datasets based on whether gold answers are included in the generations instead of strictly requiring exact matching, following [3, 37, 48]. We also use the official metrics of BLEU, METEOR, and ROUGE-1 F1 in the NarrativeQA dataset. For the abstract QA task, we follow prior work [12] and adopt a head-to-head comparison approach using an LLM evaluator (GPT-40). LLMs have demonstrated strong capabilities as evaluators of natural language generation, often achieving state-of-the-art or competitive results when compared to human judgments [56, 72]. Overall, we utilize four evaluation dimensions: Comprehensiveness, Diversity, Empowerment, and Overall."}, {"title": "4.2 Overall results", "content": "To answer the question RQ1, we compare our method with baseline methods in solving both specific and abstract QA tasks.\n\u2022 Results of specific QA tasks. Clearly, ArchRAG demonstrates a substantial performance advantage over other baseline methods on these datasets. On the Multihop-RAG dataset, HippoRAG performs worse than retrieval-only methods while outperforming retrieval-based methods on the HotpotQA dataset. The experimental results suggest that not all communities are suitable for specific QA tasks, as the GraphRAG-Global performs poorly. LLM may not be a good retriever, but is a good analyzer.\n\u2022 Results of abstract QA tasks. We compare ArchRAG against baselines across four dimensions on the Multihop-RAG dataset. achievements comparable"}, {"title": "4.3 Detailed Analysis", "content": "To answer the question RQ3, we first evaluate the community qualities under our proposed LLM-based attributed clustering framework and then conduct an ablation study.\n\u2022 Community quality of different clustering methods. We"}, {"title": "5 Related Work", "content": "In this section, we review the related works, including Retrieval-Augmentation-Generation (RAG) approaches, and LLMs for graph mining and learning.\n\u2022 RAG approaches.\n\u2022 LLM for graph mining.\n\u2022 LLM for graph learning."}, {"title": "6 Conclusion", "content": "In this paper, we propose ArchRAG, a novel graph-based RAG approach, by augmenting the question using attributed communities from the knowledge graph built on the external corpus, and building a novel index for efficient retrieval of relevant information. Our experiments show that ArchRAG is highly effective and efficient. In the future, we will explore fast parallel graph-based RAG methods to process large-scale external corpus."}, {"title": "A Method details", "content": "A.1 LLM-based hierarchical clustering\nFor example, as shown in the second step of offline indexing in Figure 2, LLM-based hierarchical clustering first enhances the original KG at layer Lo by adding similar edges. Next, the weight of each edge is calculated based on the strength of the relationship between the node embeddings, and a weighted clustering algorithm is applied to obtain four communities. Based on the existence of links between nodes within a community, the topology of communities at layer L\u2081 is constructed, resulting in a graph of communities. This process is repeated, ultimately generating a clustering result consisting of three layers of hierarchical communities.\nA.2 More details of C-HNSW\n\u2022 Introduction of HNSW. We provide a brief introduction to HNSW, an efficient Approximate Nearest Neighbor Search (ANNS) technique for vector databases.\nDefinition 1 (Hierarchical Navigable Small World (HNSW) [36]). HNSW is a graph-based ANNS algorithm that consists of a multi-layered index structure, where each node uniquely corresponds to a vector in the database. Given a set S containing n vectors, the constructed HNSW can be represented as a pair H = (G, C). G = {G0, G1, ..., GL} is a set of simple graphs (also called layers) G\u2081 = (Vi, Ei), where i \u2208 {0, 1, ..., L} and VLC VL-1 CC V\u2081 \u2282 Vo = S. C records the inter-layer mappings of edges between the same node across adjacent layers C = \u222a\u00af\u00af\u00b9{(v,\u03c6(v))|\u03c5 \u2208 Vi, \u03c6(\u03c5) \u2208 Vi+1}, where (v) : Vi \u2192 Vi+1 is the mapping function for the same node across two adjacent layers.\nThe nodes in the multi-layer graph of HNSW are organized in a nested structure, where each node at each layer is connected to its nearest neighbors. During a query, the search begins at the top layer and quickly identifies the node closest to q through a greedy search. Then, through inter-layer mapping, the search proceeds to the next lower layer. This process continues until all approximate nearest neighbors are identified in Go.\n\u2022 The construction of C-HNSW. The construction of C-HNSW is illustrated in Algorithm 3. The construction algorithm of C-HNSW follows a top-down approach. Using the query process of C-HNSW, we obtain the M nearest neighbors of each node in its layer, and the inter-layer links are continuously updated during this process. When inserting a node x at layer i, if the nearest neighbor at the layer i + 1 is cj, the inter-layer link of cj is updated in the following two cases:\n\u2022 Node cj does not have a inter-layer link to the layer i.\n\u2022 The distance from node cj to node x is smaller than the distance from cj to its previous nearest neighbor x', i.e., d(cj,x) < d(cj, x').\nAfter all nodes at layer i (i < L) have been inserted, we check each node at layer i + 1 to ensure it has a inter-layer link, confirming the traverse from the higher layer to the lower layer.\nA.3 Complexity analysis of ArchRAG\nWe now analyze the complexity of our ArchRAG approach. Since the token cost is more important in the era of LLM, we replace the space complexity with the token cost."}, {"title": "A.2 Implementation details", "content": "We implement our ArchRAG in Python, while C-HNSW is implemented in C++ and provides a Python interface for integration. We implement C-HNSW using the FAISS framework and employ the inner product metric to measure the proximity between two vectors. All methods utilize 10 concurrent LLM calls, and to maintain consistency, other parallel computations in the method, such as embedding calculations, also use 10 concurrent threads. All the experiments were conducted on a Linux operating system running on a machine with an Intel Xeon 2.0GHz CPU, 1024GB of memory, and 8 NVIDIA GeForce RTX A5000 GPUs, each with 24 GB of memory. Figure 11 demonstrates the prompt used in Adaptive filtering-based generation."}]}