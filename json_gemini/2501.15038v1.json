{"title": "Adaptive Client Selection in Federated Learning: A Network Anomaly Detection Use Case", "authors": ["William Marfo", "Deepak K. Tosh", "Shirley V. Moore"], "abstract": "Federated Learning (FL) has become a ubiquitous approach for training machine learning models on decentralized data, addressing the myriad privacy concerns inherent in traditional centralized methods. However, the efficiency of FL depends on effective client selection and robust privacy preservation mechanisms. Inadequate client selection may lead to suboptimal model performance, while insufficient privacy measures risk exposing sensitive data. This paper proposes a client selection framework for FL that integrates differential privacy and fault tolerance. Our adaptive approach dynamically adjusts the number of selected clients based on model performance and system constraints, ensuring privacy through calibrated noise addition. We evaluate our method on a network anomaly detection use case using the UNSW-NB15 and ROAD datasets. Results show up to a 7% increase in accuracy and a 25% reduction in training time compared to FedL2P. Moreover, we highlight the trade-offs between privacy budgets and model performance, with higher privacy budgets reducing noise and improving accuracy. Our fault tolerance mechanism, while causing a slight performance drop, enhances robustness to client failures. Statistical validation using Mann-Whitney U tests confirms the significance of these improvements (p < 0.05).", "sections": [{"title": "I. INTRODUCTION", "content": "Federated learning (FL) has emerged as a powerful paradigm in machine learning (ML), enabling models to be trained across decentralized data sources without the need to centralize sensitive data [1]. This approach is instrumental in privacy-preserving environments, where data cannot be easily shared across borders or entities [2]. The efficiency of FL, however, depends heavily on client participation during training. Client selection in FL is not a simple random process but requires careful consideration of various factors such as data heterogeneity, system performance, and computational resources [2]-[4].\n\nThe challenges of client selection in FL are multifaceted. First, preserving privacy during client selection and model updates is crucial to prevent adversaries from inferring sensitive information about individual clients' data [5]. Second, the unpredictable nature of client availability and potential failures in distributed environments can disrupt the training process, affecting model performance and convergence [5].\n\nAdditionally, there exists a fundamental trade-off between maintaining strong privacy guarantees and achieving high model accuracy, which complicates the design of effective FL systems [2].\n\nWe apply our proposed client selection method to the domain of network anomaly detection, which poses unique challenges due to the complexity and scale of modern networks. Detecting anomalies across distributed and diverse networks, such as the Internet of Things (IoT) systems or automotive communication networks, requires FL techniques that can manage computational efficiency while preserving data privacy. Traditional centralized ML approaches exacerbate privacy concerns, especially when dealing with sensitive network traffic data. To evaluate our method, we chose two prominent datasets: the UNSW-NB15 dataset [6], which captures a range of network traffic patterns and attacks, and the ROAD dataset [7], which focuses on automotive cybersecurity and includes complex, stealthy masquerade attacks. These datasets allow us to test the generalizability of our approach in both typical and specialized network environments, demonstrating its effectiveness in enhancing anomaly detection.\n\nMotivated by these challenges and the limitations of existing approaches, we propose a client selection algorithm that integrates differential privacy (DP) and fault tolerance mechanisms. Our approach combines adaptive client selection with privacy-preserving techniques by applying DP to model updates rather than utility scores. Specifically, we perturb the gradients with Gaussian noise to ensure (\u20ac, \u03b4)-differential privacy, protecting sensitive client data during training [5]. The method also includes a robust checkpointing mechanism for fault tolerance, allowing efficient recovery from client dropouts and ensuring continuity in real-world applications. By separating client selection from the privacy-preserving update process, we balance the need for strategic client selection with the necessity of privacy guarantees aligned with FL standards.\n\nThe key contributions of this paper are as follows:\n\n\u2022 We propose a client selection framework that integrates differential privacy through Gaussian noise added to model updates, ensuring privacy preservation without compromising model performance.\n\n\u2022 We incorporate a fault tolerance mechanism via checkpointing, enhancing system resilience to client failures."}, {"title": "II. RELATED WORK", "content": "Trindade et al. [2] proposed a two-step client selection method for Hierarchical FL (HFL), achieving notable reductions in resource usage while maintaining model accuracy on datasets like MNIST and CIFAR-10. Despite these improvements, they acknowledge the difficulty of comparing client selection methods due to varied evaluation scenarios and metrics, and their work is based on emulated environments that may not capture real-world complexities. Ruan et al. [4] examined the trade-offs in FL client recruitment, showing that more clients do not always enhance model performance, particularly in resource-constrained settings. They proposed an optimal solution for client recruitment and highlighted the need to integrate recruitment with existing selection methods. Li et al. [3] introduced AdaFL, an adaptive strategy that dynamically adjusts client numbers during training and evaluates contributions based on current and historical performance. AdaFL improved test accuracy and reduced training time. However, the study noted that many strategies still rely on a fixed number of clients, which may not optimally balance training efficiency and model performance throughout the learning process. Huang et al. [8] proposed ACFL, an active client selection framework for Clustered FL (CFL) with non-IID data, using metrics like uncertainty sampling to select informative clients. Their experiments showed that traditional FL methods, like FedAvg, struggle with class-imbalanced datasets, whereas ACFL significantly improved accuracy and reduced communication overhead. However, they emphasized the need for more refined strategies to effectively handle non-IID data in clustered environments.\n\nCompared to previous studies, this work uniquely integrates adaptive client selection with differential privacy and fault tolerance in FL for network anomaly detection. We introduce an adaptive client selection approach and a checkpointing mechanism using Weibull distribution modeling [9], enhancing both performance and fault tolerance. Evaluated on UNSW-NB15 and ROAD datasets, our approach demonstrates improved accuracy and efficiency over baselines like ACFL and FedL2P. This comprehensive solution balances privacy, performance, and fault tolerance, addressing scalability challenges in distributed environments not fully explored in existing literature."}, {"title": "III. PROBLEM FORMULATION", "content": "We formulate the client selection problem in FL as follows:\n\nConsider a FL system with N clients, denoted as $C = \\{C_1, C_2,..., C_N\\}$, where each client $c_i$ has a local dataset $D_i$.\n\nThe objective is to train a global model w by aggregating updates from a subset of clients $S_t \\subset C$ in each round t, where $|S_t|$ = K. The client selection problem is to find the optimal subset $S_t$ that maximizes performance while satisfying system constraints, including privacy preservation and fault tolerance.\n\nKey assumptions and constraints include non-IID data distribution across clients, privacy preservation through DP (applied to model gradients), limited communication bandwidth, heterogeneous client computational capabilities, and dynamic client availability. We define our objective function as $F(S_t) = \\alpha \\cdot Accuracy(S_t) - \\gamma \\cdot Cost(S_t)$, where $S_t$ is the subset of selected clients in round t, and \u03b1 and \u03b3 are weighting factors balancing the importance of accuracy and cost, respectively [3]. Here, Accuracy $(S_t)$ represents the contribution to model performance from selected clients, which could be measured using metrics such as AUC-ROC, as discussed later in the paper. The cost function $Cost(S_t) = \\sum_{i \\in S_t}(Comm_i + Comp_i)$ accounts for both communication cost $Comm_i$ and computation cost $Comp_i$ for client i. The optimization problem is then to find $S_t^* = arg \\max_{S_t} F(S_t)$, subject to $|S_t|$ = K and $S_t \\subset Available\\_Clients_t$. The set $Available\\_Clients_t$ represents the clients that are online and have sufficient resources to participate in the current round, as determined by the GetAvailableClients() function in our algorithm. This formulation incorporates considerations for DP (applied to gradients) and fault tolerance (via checkpointing), which are detailed later in the paper. These mechanisms ensure privacy preservation and system robustness while maintaining the efficiency of the client selection process."}, {"title": "A. Federated Learning Architecture for Adaptive Client Selection", "content": "Our FL architecture consists of two main components: clients and a global server. Fig. 1 illustrates the FL architecture, highlighting the coordination between the global server and local client training, including checkpointing and fault tolerance mechanisms.\n\n1. Clients: In FL, each client owns local data, which remains on the device to preserve privacy. Each client also maintains a local instance of the model that it trains using its local dataset. Let there be N clients, denoted as $c_i$ where $i \\in \\{1,...,N\\}$. Each client has its dataset $X_i$, where $X_i \\in R^{m_i \\times d}$ with $m_i$ representing the number of samples for client i and d representing the number of features in each sample. Each client also has a local model, with parameters denoted by $w_i$. The local model is trained on the dataset $X_i$ for a specified number of epochs. After training, the updated parameters $w_i$ are sent to the global server for aggregation. Specifically, if $f_i$ represents the function (or architecture) of the local model and $w_i$ represents the parameters, the training process updates $w_i$ based on the client's data $X_i$. The updated parameters $w_i$ are then sent to the global server for aggregation in the global model.\n\n2. Global Server: The global server manages the global model by aggregating the updated parameters received from all selected clients. For each round, the global server collects"}, {"title": "IV. PROPOSED CLIENT SELECTION METHOD", "content": "In this section, we outline our proposed client selection method for FL, which is designed to balance accuracy, privacy, and fault tolerance. We discuss (1) the client selection algorithm, which adaptively selects clients based on their potential contribution to the global model; (2) the implementation of checkpointing strategies, which ensure robust system performance by allowing recovery from client failures; and (3) the integration of DP, which adds noise to client model updates (gradients) to protect against inference attacks."}, {"title": "A. Client Selection Algorithm", "content": "Our selection strategy adapts client participation dynamically based on model performance and system constraints, building upon the approaches in [3], [5]. We compute utility scores for all clients, considering factors like data quality and computational capacity. These scores are solely used for client selection and do not impact user privacy [2], [8]. In each communication round, clients are selected based on these utility scores, striking a balance between performance optimization and client diversity. Once selected, they train their local models, and DP is applied by adding Gaussian noise to their model updates (gradients) before sending them to the global server, protecting sensitive data. To ensure fault tolerance, clients periodically checkpoint their progress, enabling recovery in case of failure. After training for a set number of epochs, each client's local model parameters $w_i^t$, are sent to the global server, where they are aggregated to update the global model. Algorithm 1 summarizes the overall process, incorporating both DP and fault tolerance mechanisms.\n\nTermination condition/epochs in Algorithm 1: The algorithm proceeds iteratively over multiple communication rounds, terminating when the global model converges or when the maximum number of rounds is reached. During each round, clients train their local models for a set number of epochs. To ensure fault tolerance, checkpoints are saved at intervals t, allowing clients to recover from failures without losing progress. If a failure occurs, the client recovers from the last saved checkpoint. This mechanism ensures smooth continuation of the training process while maintaining efficient updates and aggregation at the global server.\nHandling training failures in decentralized ML:\nTo handle client dropouts or disconnections in distributed environments, our framework uses a checkpointing mechanism, enabling smooth recovery and ensuring training continuity [10].\na) Recovery protocol without checkpointing\nIn the absence of checkpointing, recovery can involve either restarting the training from scratch or reinitializing the failed client's model using the latest global weights. We prefer the latter as it minimizes interruptions and allows training to continue with minimal disruption, though it may introduce temporary inconsistencies.\nb) Recovery protocol with checkpointing\nIn the case of checkpointing, clients periodically store their model state as binary files. When a failure happens, the system restores the client's state from the most recent checkpoint, allowing training to continue without restarting. If a failure occurs during aggregation, the global server can either pause for recovery or reassign the client's workload to other active clients, ensuring uninterrupted training.\nc) Optimal checkpointing interval\nWe estimate the likelihood of client failure using a Weibull distribution, as shown in [9], which is well-suited for distributed systems. The failure probability within a checkpoint-"}, {"title": "V. USE CASE: NETWORK ANOMALY DETECTION", "content": "Network anomaly detection serves as an ideal test case for our client selection framework, given the distributed and privacy-sensitive nature of network traffic data [1]. Our approach combines adaptive client selection for diverse network behavior capture, DP for data protection, and fault tolerance for continuous learning despite connectivity issues. We evaluate this framework through experiments (Section V-A), compare against baselines (Section V-B), and present statistical validation (Section V-C)."}, {"title": "A. Experimental Setup", "content": "We evaluated our method using the UNSW-NB15 dataset [6] for network intrusion detection and the ROAD dataset [7] for controller area network traffic, focusing on correlated masquerade attack. Experiments were run on a system with a 12th Gen Intel\u00ae Core\u2122 i9-12900HK CPU, NVIDIA RTX 3080 Ti GPU, and 32GB RAM, using Python 3.8.18, TensorFlow 2.6.0, and PyTorch 0.5.0. Key hyperparameters (\u20ac \u2208 [0.1, 10.0], checkpoint interval t*, client fraction K) were optimized through grid search over 10 repeated"}, {"title": "VI. CONCLUSION", "content": "This paper introduced a client selection method for FL with integrated DP and fault tolerance, demonstrating improved performance over FedL2P in network anomaly detection. Our method achieved up to 7% higher accuracy and 25% faster training. We identified trade-offs between privacy budgets and model performance, with fault tolerance enhancing robustness at a slight accuracy cost. Limitations include the lack of hyperparameter tuning. Future work will explore adaptive hyperparameter optimization and comparisons with cryptographic techniques, extending applicability to broader domains."}]}