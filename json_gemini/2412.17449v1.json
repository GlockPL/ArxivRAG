{"title": "Applying LLM and Topic Modelling in Psychotherapeutic Contexts", "authors": ["Alexander Vanin", "Vadim Bolshev", "Anastasia Panfilova"], "abstract": "This study explores the use of LLM (Large language models) to analyze therapist remarks in a psychotherapeutic setting.\nThe paper focuses on the application of BERTopic, a machine learning-based topic modeling tool, to the dialogue of two\ndifferent groups of therapists\u2014classical and modern\u2014which makes it possible to identify and describe a set of topics that\nconsistently emerge across these groups. The paper describes in detail the chosen algorithm for BERTopic, which included\ncreating a vector space from a corpus of therapist remarks, reducing its dimensionality, clustering the space, and creating\nand optimizing topic representation. Along with the automatic topical modeling by the BERTopic, the research involved\nan expert assessment of the findings and manual topic structure optimization. The topic modeling results highlighted the\nmost common and stable topics in therapists' speech, offering insights into how language patterns in therapy develop and\nremain stable across different therapeutic styles. This work contributes to the growing field of machine learning in\npsychotherapy by demonstrating the potential of automated methods to improve both the practice and training of therapists.\nThe study highlights the value of topic modeling as a tool for gaining a deeper understanding of therapeutic dialogue and\noffers new opportunities for improving therapeutic effectiveness and clinical supervision.", "sections": [{"title": "1. Introduction", "content": "In psychotherapy, the language and methods therapists\nuse play a crucial role in shaping the therapeutic process\nand influencing client outcomes. Analyzing how\ntherapists communicate, through their interventions,\nstrategies, and speech patterns, can provide valuable\ninsights into therapy's effectiveness. Traditionally, this\nanalysis relied on manual coding, a labor-intensive\nprocess prone to bias (Wampold & Imel, 2015).\nHowever, advancements in machine learning,\nparticularly in topic modeling, have made it possible to\nanalyze large volumes of textual data efficiently and\nwithout such biases.\nThis study explores the use of BERTopic, a machine\nlearning technique that leverages transformer-based\nmodels to identify and extract meaningful topics from\nunstructured datasets. BERTopic offers a powerful tool\nfor analyzing the complex themes that emerge during\ntherapy sessions. Topic modeling methods, such as LDA\n(Blei et al., 2001) and Top2Vec (Angelov, 2020), have\nproven effective in large-scale textual analysis within\nsocial science research (Gaur et al., 2018; Yanchuk et al.,\n2022). Furthermore, BERT-based models have been\napplied in mental health research to predict outcomes and\nidentify patterns in psychotherapeutic data (Zeberga et\nal., 2022). This study aims to assess the effectiveness of\nBERTopic (Grootendorst, 2022) in automatically\nextracting relevant topics from psychotherapeutic\ndialogues, providing deeper insights into the therapeutic\nprocess and therapists' strategies.\nTopic modeling offers several potential benefits in\npsychotherapy. It can identify which therapeutic\ntechniques - such as empathy, reframing, or cognitive\nrestructuring are most frequently used by therapists,\nthereby informing clinical practice, supervision, and\ntraining (Norcross & Wampold, 2011). Additionally,\nTopic modeling can track shifts in therapeutic approaches\nover time, enabling data-driven evaluations of treatment\nprogress and adjustments to better meet clients' evolving\nneeds (Lambert & Ogles, 2004).\nThis article examines BERTopic's capabilities in\nanalyzing therapist remarks, evaluating its effectiveness\nin identifying meaningful topics. Ultimately, the study\naims to contribute to the growing body of research on\nmachine learning applications in psychotherapy,"}, {"title": "2. Related Work", "content": "Recent research in machine learning and psychotherapy\nhas focused on analyzing therapeutic dialogues, often\nemphasizing patients' language or the overall therapist-\nclient interaction. For example, Gao and Sazara (2023)\n(Gao & Sazara, 2023) employed a customized Sentence-\nBERT model integrated with the BERTopic framework\nto analyze over 96,000 research paper abstracts in mental\nhealth. Their findings reveal that BERTopic outperforms\nother methods like Top2Vec and LDA-BERT in terms of\ntopic diversity and coherence, making it a valuable tool\nfor identifying emerging trends in mental health\nresearch. The study also visualizes key machine learning\ntechniques and research trends, underscoring\nBERTopic's versatility for large-scale data analysis.\nSimilarly, Ji et al. (2021) (Ji et al., 2021) introduced\nMentalBERT and MentalRoBERTa, domain-specific\nmasked language models designed to enhance machine\nlearning applications in mental health. By evaluating\nthese models on mental disorder detection benchmarks,\nthe study demonstrated that domain-adapted models\nsignificantly improve task performance, emphasizing the\nimportance of pretrained language models tailored for\nspecific domains in mental health research.\nWhile many studies focus on patients' speech or the\nbroader therapist-client interaction, our research shifts\nthe focus to the therapist's language and how their verbal\ninterventions influence the therapeutic process. Using\nBERTopic, we systematically and scalably analyze\ntherapist remarks, offering new insights into their\ncommunication strategies and role in effective therapy.\nThis study extends the growing body of work on\napplying machine learning to psychotherapy,\ncontributing to a deeper understanding of the therapist's\nimpact on therapeutic outcomes through their verbal\ntechniques and language patterns."}, {"title": "3. Materials and Methods", "content": null}, {"title": "3.1Datasets", "content": "The source material was the recordings of\npsychotherapeutic sessions posted on YouTube in the\npublic domain, which were divided into two datasets:\nrecordings of sessions with classical and modern\ntherapists. The sample of classic psychotherapeutic\nsessions includes 19 recordings, whereas the sample of\nmodern therapists is of 111 sessions. Classical therapists\nare represented by recordings of Carl Rogers, Fritz Perls,"}, {"title": "3.2Methods", "content": "The acquired document corpora were subjected to text\npreprocessing prior to the investigation, which included\nsegmentation of utterances into separate sentences,\nperforming lexical normalization, cleaning metadata,\nand converting to a unified case.\nSubsequently, topic modeling was applied to the\npreprocessed corpora using the BERTopic, a machine\nlearning-based topic modeling tool. Pre-trained\nembeddings from the Sentence-Transformer model\n'paraphrase-multilingual-MiniLM-L12-v2' were used to\ncreate a vector space. UMAP (Uniform Manifold\nApproximation and Projection) method was applied to\nreduce the vector space's dimensionality, and\nHDBSCAN (Hierarchical Density-Based Spatial\nClustering of Applications with Noise) was used to\ncluster the data. The topic representation of the clusters\nwas made using BERTopic's built-in c-TF-IDF method\nfor assessing the importance of words within the context\nof document clusters, and its optimization was primarily\nachieved through the use of large language models like\nGPT.\nAfter the topic modeling process, the results\nunderwent expert analysis, followed by the removal or\nmerging of topics so as to achieve a more interpretable\ntopic structure of therapist remarks. This required several\niterations. At each iteration, interactive visualizations\nsuch as hierarchical clustering dendrograms and distance\nmaps across topics were created to aid in the expert\nevaluation of the modeling results. In addition to\nvisualization, the coherence metric was calculated to\nassess the topic modeling quality.\nAt the conclusion of the research, a detailed\ninterpretation of topic clusters was conducted for each\ncorpus of utterances from classical and modern\ntherapists. The most semantically similar topics between\ntwo corpora were identified by calculating cosine\nsimilarity."}, {"title": "3.3 Research Environment and Tools", "content": "For this study, we selected Jupyter Notebook version\n7.0.6 as our integrated development environment,\noperating within the Anaconda Python distribution. All\ndata analysis was conducted using the Python\nprogramming language.\nLibraries and packages specific to each task are as\nfollows:\n\u2022\n\u2022\n\u2022\nText Preprocessing: The Pandas library (version\n2.1.4) was employed for handling tabular data. Text\npreprocessing was carried out using Python's\nregular expressions module (re, version 0.12.2) and\nthe advanced natural language processing library\nspaCy (version 3.7.6);\nTopic Modeling: The BERTopic framework\n(version 0.16.4) was utilized for identifying topics\nin therapeutic remarks. Pre-trained embeddings\nfrom the sentence-transformers library (version\n3.3.1) were employed. Dimensionality reduction\nwas performed using the umap-learn library\n(version 0.5.7), and clustering was achieved using\nthe hdbscan library (version 0.8.40). Topic\ncoherence was calculated using the\nCoherenceModel class from the gensim library\n(version 4.3.3);\nData Visualization: Matplotlib (version 3.8.0) and\nSeaborn (version 0.12.2) libraries were used for\ndata visualization. BERTopic's built-in\nvisualization methods were also employed,\nincluding hierarchical clustering dendrograms and\ninteractive distance maps between topics based on\nLDAvis."}, {"title": "4. Topic modeling", "content": null}, {"title": "4.1Data Corpus Preparation", "content": "To prepare the corpora for topic modeling, a set of\npreprocessing operations was carried out using the spaCy\nlibrary models pretrained on the OntoNotes Release 5.0\ncorpus (OntoNotes Release 5.0 Linguistic Data\nConsortium, n.d.) with the additional resources of\nClearNLP Constituent-to-Dependency Conversion\n(ClearNLP\nConstituent-to-Dependency\nConversion,\nn.d.) and WordNet (WordNet, n.d.). The following stages\nwere performed during corpora processing:\n\u2022\n\u2022\nsegmentation of utterances consisting of splitting\nthe continuous text of utterances into separate\nsentences in order to isolate syntactic units;\nlexical normalization, which included decoding\nabbreviations (replacing abbreviated forms of\nmodal verbs and negative particles with their full\nforms to ensure homogeneity of the vocabulary),\nunification (removal of uninformative elements,\nsuch as interjections, speech fillers and other stop\nwords) and bringing some lexical units to a single\northographic form (for example, \"okay\");\ncleaning from metadata, which included removing\ntime pause marks (excluding information from the\ntext that indicates the duration of pauses), as well as\neliminating identifiers (removing question numbers\nand other identifiers that do not carry semantic\nload) in order to preserve only linguistic\ninformation;\nbringing to a unified register consisting of\nconverting all letters to lower case so as to unify the\ntext and eliminate the influence of the register on\nfurther analysis."}, {"title": "4.2BERTopic Operation Algorithm", "content": "Two text data corpora were under topic modeling in\nparallel using the BERTopic algorithm, which is a multi-\nstage topic modeling process. The initial stage is the\nconstruction of a vector space for each document. A\ndimensionality reduction technique is used to the\nresultant vector space in order to increase the\neffectiveness of further computations and visualization.\nAfter that, documents are grouped by topic proximity\nusing a clustering technique. At the final stage, text\ndescriptions of the resulting topics are formed and\noptimized. A more detailed description of each stage is\ngiven below."}, {"title": "4.2.1 Vector Space Construction", "content": "We created the vector space from document embeddings\nobtained using language neural networks with the\ntransformer architecture [4], hence allowing not only to\neffectively take into account semantic relationships in\ntexts, but also to avoid many stages of text preprocessing,\nsuch as removing stop words, stemming or\nlemmatization (Ma et al., 2021; Thielmann et al., 2023).\nWe applied pre-trained multilingual embeddings of the\nSentence-Transformer model 'paraphrase-multilingual-\nMiniLM-L12-v2' so as to obtain embeddings of the\nconsidered text corpora. The choice of this model was\ndue to its higher efficiency compared to others, which\nwas verified empirically, including by comparing with\nspecialized models, for example, BIOBERT, trained on\nmedical texts."}, {"title": "4.2.2 Vector Space Dimensionality\nReduction", "content": "Since the vector space of embeddings is usually a sparse\nmatrix, BERTopic provides the option to apply a variety\nof dimensionality reduction algorithms, such as PCA, t-"}, {"title": "4.2.3 Vector Space Clustering", "content": "A wide range of clustering algorithms are supported by\nBERTopic, including contemporary density-based\ntechniques like HDBSCAN and more conventional\ntechniques like k-means and agglomerative clustering.\nHDBSCAN was used for the current research because it\noffered the most reliable and accurate text data clustering\nThis algorithm can efficiently handle variable-density\ndata and automatically detect outliers (McInnes & Healy,\n2017). We used the Euclidean distance to calculate the\nproximity between documents in this technique and\nassumed that a cluster had a minimum of 40 objects."}, {"title": "4.2.4 Topic Representation of Clusters", "content": "A distinctive feature of the BERTopic algorithm from\nother topic modeling algorithms (e.g., Top2Vec) is its\nability to form semantically rich representations of\ntopics. To do this, a single bag-of-words vector is\nconstructed for each cluster and then a list of the most\nsignificant words in the cluster is derived using the c-TF-\nIDF metric (Kenton & Toutanova, 2019). This metric is\nan extension of traditional TF-IDF adapted for cluster\nanalysis and allows assessing the importance of terms\n(words) in the context of a specific cluster.\nDetermining the importance of terms makes it\npossible to create a list of the most relevant keywords\ndescribing a certain cluster, which is the topic\nrepresentation of the cluster in question. This opens up\noptions for optimizing the cluster structure by combining\ntopics with similar semantic content, hence reducing the\nnumber of clusters and minimize the number of outliers."}, {"title": "4.3Assessment and Optimization of\nModeling Outcomes", "content": "Applying the BERTopic topic modeling algorithm to two\ntext corpora containing therapists' remarks from different\neras yielded 95 and 110 topic clusters, respectively. The\nsemantic similarity between words in topics, estimated\nusing the topic coherence metric (Mimno et al., 2011),\nwas 0.429 and 0.377, respectively. Interactive\nvisualization of topic spaces using LDAvis (Sievert &\nShirley, 2014) validated the results,\ndemonstrating the degree of semantic similarity between\nspecific topics in each corpus."}, {"title": "5. Interpretation of Topic Clusters", "content": "To present the results, we will examine the identified\ntopics in the therapists' remarks sequentially, referencing\ntheir representation in the results of hierarchical cluster\nanalysis (Fig. 2-3), which determines the proximity of\ntopics to each other. We will begin by discussing the\ntopics associated with classical therapists, followed by an\nexploration of the topics associated with modern\ntherapists. Finally, we will compare the proximity of\ntopics between classical and modern therapists (Fig. 4)."}, {"title": "5.1Topic Structure for Classical Therapists", "content": "For classical therapists, 44 topics were identified, which\nare described in detail below. These topics represent the\nvarious speech patterns, techniques, and themes that\nemerged in their dialogues."}, {"title": "5.2Topic Structure for Modern Therapists", "content": "For modern therapists, 47 topics were identified, which\nare described in detail below."}, {"title": "5.3Proximity of Topics Between Classical\nand Modern Therapists", "content": "The proximity of topics between classical and modern\ntherapists was determined based on cosine similarity.\nThis method calculates the cosine of the angle between\ntwo vectors in a multi-dimensional space, measuring\nhow similar the topics are in terms of their content and\ncontext. By applying this technique, we can quantify the\ndegree of similarity between the thematic representations\nof classical and modern therapists, allowing for a\ncomparative analysis of their speech patterns and\ntherapeutic approaches.\nCosine similarity helps demonstrate the most\nprominent topics in the speech of the two groups of\ntherapists, which likely reflect the core issues clients\nbring to therapy. For brevity, we will highlight only those\ntopics with a coherence level ranging from 0.9 to 1.0.\nThese include:\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nUnderstanding and combating fear: exploring its\nnature and addressing anxiety-inducing issues:\n(24)6 and (45)28;\nUnderstanding, expressing, and managing anger:\n(36)37 & (12)29;\nWork-related fear, anxiety, and challenges: (11)33\n& (35)2;\nTherapeutic session planning: (42)4 & (43)1;\nNavigating relationship and friendship\ncomplexities: (2)15 & (38)7;\nEducational concerns: (15)16 & (28)13;\nRelationships with mothers: (1)21 & (25)15;\nExploring and overcoming resentment, bitterness,\nand pain: (8)12 & (27)20;\nAging, childhood reflections, and generational\nperspectives: (28)26 & (15)23;\nExploring possibilities, potential outcomes, and\nuncertainties: (35)30 & (1)32;\nSelf-acceptance, confidence, and the impact of self-\ncriticism on social dynamics: (18)5 & (46)39;\nUnderstanding personal goals, satisfaction, and the\nprocess of goal-setting and achievement: (27)32 &\n(21)40."}, {"title": "6. Conclusion", "content": "In conclusion, the ability of BERTopic to perform \nunsupervised learning makes it a powerful tool for \npsychotherapy content analysis across a wide range of \ncontexts. As a topic modeling technique based on BERT\n(LLM-based) embeddings, it offers an effective approach \nto uncovering meaningful and interpretable themes from \nlarge volumes of unstructured text. This capability is \nespecially valuable in psychotherapy, where therapists' \nlanguage is often complex, nuanced, and highly \nindividualized. By applying BERTopic to therapist \nremarks and topic representation optimization by LLM\nspecializing in NLP, such as GPT, offers a novel \napproach to extract distinct topics, enabling deeper \ninsights into common therapeutic practices, as well as \nemerging trends in therapy sessions.\nThe results of this study demonstrate the potential of \nBERTopic to highlight the varied approaches used by \ntherapists, whether classical or modern, and provide a \nstructured analysis of how verbal interventions influence \nthe therapeutic process. This method enhances our \nunderstanding of the ways therapists guide sessions, \nmanage emotions, and address client concerns, offering \na more systematic, data-driven approach to studying \npsychotherapy. Ultimately, BERTopic opens up new \nopportunities for both clinical practice and therapist"}, {"title": "7. Future Work", "content": "A promising next step in this line of research would be\nthe exploration of client topics in addition to the\ntherapist's speech. Analyzing client remarks could\nprovide valuable insights into the most frequent concerns\nand requests that clients bring to therapy. This would, in\nturn, help identify key areas of knowledge and focus for\ntraining future therapists, allowing for a more targeted\nand informed approach to clinical education. By\nunderstanding common client needs and expressions,\ntherapists could be better equipped to address specific\nconcerns in a more personalized and effective manner.\nAnother potential avenue for future work is studying\nthe dynamic development of topics throughout a single\ntherapeutic session. Examining how topics evolve over\ntime could offer a deeper understanding of the\ntherapeutic process and the impact of interventions at\ndifferent stages of a session. Tracking these changes\nwould provide real-time insights into how therapeutic\napproaches are working and where adjustments might be\nnecessary to enhance client outcomes.\nUltimately, the automated identification of session\ntopics could pave the way for the development of digital\nassistants for therapists. Such tools could analyze and\nrecord the most significant moments of a therapy session,\noffering therapists suggestions for further exploration\nand intervention. By integrating this technology into\nclinical practice, therapists would be able to receive\nimmediate feedback and recommendations, optimizing\nthe therapeutic process and improving the quality of care\nprovided to clients. This innovation has the potential to\nsignificantly enhance both the efficiency and\neffectiveness of psychotherapy in the future."}]}