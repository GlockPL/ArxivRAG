{"title": "DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue", "authors": ["Feiyuan Zhang", "Dezhi Zhu", "James Ming", "Yilun Jin", "Di Chai", "Liu Yang", "Han Tian", "Zhaoxin Fan", "Kai Chen"], "abstract": "Retrieval-Augmented Generation (RAG) systems have shown substantial benefits in applications such as question answering and multi-turn dialogue [22]. However, traditional RAG methods, while leveraging static knowledge bases, often overlook the potential of dynamic historical information in ongoing conversations. To bridge this gap, we introduce DH-RAG, a Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue. DH-RAG is inspired by human cognitive processes that utilize both long-term memory and immediate historical context in conversational responses [32]. DH-RAG is structured around two principal components: a History-Learning based Query Reconstruction Module, designed to generate effective queries by synthesizing current and prior interactions, and a Dynamic History Information Updating Module, which continually refreshes historical context throughout the dialogue. The center of DH-RAG is a Dynamic Historical Information database, which is further refined by three strategies within the Query Reconstruction Module: Historical Query Clustering, Hierarchical Matching, and Chain of Thought Tracking. Experimental evaluations show that DH-RAG significantly surpasses conventional models on several benchmarks, enhancing response relevance, coherence, and dialogue quality.", "sections": [{"title": "Introduction", "content": "Dialogue systems and question-answering tasks have increasingly captured the interest of the artificial intelligence community. With the evolution of Large Language Models (LLMs) [1, 35], Retrieval-Augmented Generation (RAG) methods have showcased significant benefits in these areas. RAG systems, by amalgamating external knowledge bases with generative models, furnish responses not only more precise but also richly informative. As an indispensable adjunct to LLMs, RAG systems are instrumental in elevating the conversational quality of these robust models.\nSpecifically, in human interactions, responses are influenced not only by long-term memory, comparable to static knowledge bases, but also by short-term dynamic historical information crucial for contextual understanding and appropriate response formulation. This dynamic component is vital for maintaining dialogue coherence and relevance. However, existing RAG systems often fail to effectively harness these dynamically evolving contextual cues in multi-turn dialogues, possibly leading to responses that are not well-integrated with the overall conversational flow. This limitation motivates a pivotal question: Can we develop a RAG model that effectively utilizes both static external knowledge and the transient context inherent in ongoing conver-"}, {"title": "Related Work", "content": "Retrieval-Augmented Generation (RAG) systems significantly advance the capabilities of dialogue systems and question-answering tasks by amalgamating external knowledge bases with generative models. [22] introduces the RAG models, adeptly merging pre-trained parametric and non-parametric memories for enhanced language generation. Subsequent studies [23] introduce several enhancements to RAG models, focusing on refining retrieval [10, 36] and enhancing generation capabilities [2, 17]. Recent innovations include FLARE [43], which introduces a feedback loop augmented retrieval method to iteratively refine retrieval outcomes and bolster generation quality. Additionally, SelfRAG [3] presents a self-supervised retrieval-augmented framework that boosts both retrieval and generation processes through the strategic use of pseudo-labels generated by the model itself. Despite these significant advancements, the challenge of seamlessly integrating dynamic historical context in RAG models for multi-turn dialogues remains an elusive goal.\nThough achieve remarkable progress, most existing approaches continue to depend predominantly on static knowledge bases and do not adequately address the need to capture the evolving contextual nuances within conversations. This gap propels the development of DH-RAG in this paper, aimed at more effectively incorporating both static external knowledge and the transient context prevalent in ongoing dialogues, thereby enhancing the quality and coherence of multi-turn dialogue interactions.\nRetrieval-based dialogue systems [25, 34] become central in natural language processing, aiming to generate responses from large conversational datasets [1]. Early models like the reformulation-based retrieval system by [39] improve response matching in information-seeking dialogues. Subsequent developments include multi-hop retrieval methods [37] that navigate complex knowledge graphs for richer responses and few-shot learning approaches like [40], which enhance performance in resource-scarce scenarios. However, these systems often struggle with generating context-appropriate responses in multi-turn dialogues due to their reliance on selecting pre-existing responses. This has led to the exploration of hybrid models [31, 38], such as the selective knowledge fusion framework by [33], which increases response relevance and coherence.\nDespite progress, smoothly integrating changing conversational contexts remains challenging. This paper introduces DH-RAG, a novel framework that addresses this gap in multi-turn dialogue systems by creating a dynamic historical information database and a History-Learning Based Query Reconstruction Module. This approach refines queries using past context, enhancing dialogue interaction quality.\nThe study of long-term and short-term memory is essential in cognitive psychology, providing key insights into how hu- mans process information and make decisions, and have in- spired many researcher in RAG [10, 14] and dialogue sys- tem fields [6, 42]. The foundational work by [4] introduced the multi-store model of memory, differentiating between short-term and long-term memory systems. This model has been refined over the years, notably by [5], who devel- oped the working memory model that focuses on the active management of information in short-term storage. Recent studies have examined the interaction between these mem- ory systems. For example, [11] investigates the processes"}, {"title": "Method", "content": "Algorithm 1 show the overall pipeline of DH-RAG.\nNext, we introduce the two modules and the Dynamic His- torical Information Database in detail.\nGiven a query, it is crucial to merge static knowledge with dynamic historical information to craft a new query that in- forms the subsequent response generated by a LLM. This approach introduces a novel concept in the retrieval pro- cess. To facilitate this, we introduce the History-Learning Based Query Reconstruction Module, which is designed to fulfill this specific objective. This module comprises three key components: the Vanilla Static Knowledge Base, the Dy- namic Historical Information Database, and the Informa- tion Reconstruction & Integration Process."}, {"title": "Overview", "content": "Algorithm 1: DH-RAG Framework\nRequire: Query $q_{new}$, Knowledge Base $D$, Historical Database $H$\nEnsure: Response $r$\n1: $R \\leftarrow VanillaRetrieval(q_{new}, D)$\n2: // Clustering Matching\n3: $C \\leftarrow ClusterHistoricalQueries(H)$\n4: // Hierarchical Matching\n5: $S_c \\leftarrow Category Matching(q_{new}, C)$\n6: $R_h \\leftarrow \\emptyset$\n7: for $c_i \\in S_c$ do\n8: $S_h \\leftarrow QueryMatching(q_{new}, C_i)$\n9:  for $h_j \\in S_h$ do\n10:   $R_h \\leftarrow R_h \\cup ExtractInfo(h_j)$\n11:  end for\n12: end for\n13: // Chain of Thoughts Matching\n14: $S_g \\leftarrow TopKSimilarQueries(q_{new}, H)$\n15: $R_g \\leftarrow \\emptyset$\n16: for $h_i \\in S_g$ do\n17:  $R_g \\leftarrow R_g \\cup ExtractCoT(h_i)$\n18: end for\n19: $R_{final} \\leftarrow InformationIntegration(R_v, R_h, R_g)$\n20: $r \\leftarrow Generate (q_{new}, R_{final})$\n21: // Dynamic Update\n22: $H' \\leftarrow H \\cup \\{(q_{new}, r)\\}$\n23: $H_{updated} \\leftarrow FilterAndScore(H')$\n24: $C \\leftarrow UpdateClusters(H_{updated})$\n25: return $r$\nIn this study, we explore multi-turn dialogue systems and retrieval augmented generation. Traditional Retrieval- Augmented Generation (RAG) systems often struggle with the continuity and context dependency inherent in multi- turn dialogues, where user queries evolve or deviate based on preceding interactions. To address this challenge, we in- troduce the Dynamic History-aware Retrieval-Augmented Generation (DH-RAG) system. This innovative approach is specifically tailored to manage and integrate sequences of contextually interconnected queries effectively.\nBefore we explain our system, let's define the problem. Consider a series of queries $Q = \\{q_1, q_2, ..., q_t\\}$, where $q_t$ is"}, {"title": "", "content": "the current query. Our goal is to generate a response $r_t$. We can describe this process with the equation:\n$r_t = f(q_t, K, H)$                                                                                       (1)\nHere, $K$ is the static knowledge base that provides background information, and $H = \\{(q_1, p_1, r_1), (q_2, p_2, r_2), ..., (q_{t-1}, p_{t-1}, r_{t-1})\\}$ represents the history of past queries, passages, and responses. $p_i$ is the passage retrieved for query $q_i$. The challenge is to create a function $f$ that uses the current query $q_t$, the knowledge $K$, and the history $H$ to generate a suitable response $r_t$.\nFigure 2 illustrates the workflow of our system during a multi-turn conversation. The process begins with the system receiving a new query from the user. This query is first pro- cessed by the History-Learning Based Query Reconstruction Module, which leverages both a standard knowledge base and a Dynamic Historical Information Database to enrich and integrate pertinent information. The enhanced query in- formation is subsequently passed to a LLM, which gener- ates the user's response. Finally, the Dynamic History In- formation Updating Module updates the Dynamic Historical Information Database with the new response, ensuring that the system evolves and remains relevant with each interac- tion."}, {"title": "History-Learning based Query Reconstruction Module", "content": "Vanilla Static Knowledge Base Traditional RAG systems fundamentally depend on a standard knowledge base. In our DH-RAG, we continue to utilize a static knowledge base as the foundational element. When presented with a query q, we retrieve a set of relevant documents $D = \\{d_1, d_2,..., d_k\\}$ from the knowledge base K. This retrieval process can be mathematically described by the following equation:\n$D = argmax_{D'\\subset K} Sim(q, D')$    (2)\nwhere $sim(q, D')$ represents the similarity between the query q and a subset of documents $D'$ within the knowledge"}, {"title": "Dynamic Historical Information Database", "content": "As previously mentioned, relying solely on the traditional Static Knowledge Base is insufficient to provide comprehensive information for RAG systems in conversational settings. Therefore, to utilize valuable insights from historical inter- actions, we have developed the Dynamic Historical Information Database H. This database is comprised of a collection of historical query-passage-response triples:\n$H = \\{(q_1, p_1, r_1), (q_2, p_2, r_2), ..., (q_{t-1}, p_{t-1}, r_{t-1})\\}$                               (3)\nwhere $q_i$, $p_i$, and $r_i$ denote the i-th historical query, the relevant retrieved passage, and the generated response, respectively. To efficiently organize and retrieve informa- tion from this database, we implement three strategic ap- proaches: the Clustering Strategy, the Hierarchical Match- ing Strategy, and the Chain of Thoughts Tracking Strategy. These methods are designed to extract the most pertinent in- formation from complex historical interactions, enhancing the system's ability to generate informed and contextually relevant responses, which will be detailed later.\nTo effectively meld static knowledge with dynamic historical information, we propose an integration methodology uti- lizing an attention mechanism. For a given current query $q_t$, we retrieve pertinent information from both the static knowledge base K and the dynamic historical information database H as follows:\n$D_k = Retrieve(q_t, K); D_h = Retrieve(q_t, H)$                                                                                (4)\nThe retrieved dynamic historical information, $D_h$, con- sists of two components: the output from the Hierarchical Matching Strategy $D_h^{HM}$ and the output from the Chain of Thoughts Tracking Strategy $D_h^{COT}$.\n$D_h = \\{D_h^{HM}, D_h^{COT}\\}$                            (5)"}, {"title": "", "content": "Subsequently, we employ an attention mechanism to com- pute weights for each piece of retrieved information:\n$w_i = softmax(q_t^T W d_i)$                                             (6)\nHere, $d_i$ represents an information element from either $D_k$, $D_h^{HM}$, or $D_h^{COT}$, and W is a matrix of learnable param- eters.\nThese weights are then used to integrate the information:\n$C = \\sum w_i d_i$    (7)\nwhere C denotes the final integrated context, crafted to consider the relevance, novelty, and diversity of the infor- mation, thereby providing an optimal context for response generation.\nFinally, the reconstructed query $q_t^f$ along with the inte- grated context C are fed into the LLM for generating the response:\n$r_t = LLM(q_t^f, C)$                                                           (8)\nThis method enables dynamic adjustment of the impor- tance attributed to different sources of information, thus fur- nishing the most relevant and useful context for the LLM."}, {"title": "Dynamic History Information Updating Module", "content": "After obtaining the reconstructed new query, the next ob- jective is to generate a response using a LLM and update our historical database with the new response. To achieve this, we develop the Dynamic History Information Updating Module, which includes two key steps: response generation and historical information updating.\nGiven the reconstructed query $q_t^f$ alongside the integrated context C, the procedure for gen- erating a response $r_t$ through the LLM can be elegantly rep- resented as:\n$r_t = LLM(q_t^f, C)$                           (9)"}, {"title": "", "content": "where \u201cLLM\u201d denotes the function executed by the LLM.\n$P(r_t|q_t^f, C) = \\prod P(w_i|w_1,..., w_{i-1}, q_t^f, C)$ (10)\nIn this expression, $w_i$ signifies the i-th word within the response. This probabilistic formulation captures the essence of sequential word generation, wherein each word $w_i$ is predicated upon its predecessors and the contextual amal- gamation of $q_t^f$ and C.\nUpon the generation of a response, it becomes imperative to update the dynamic his- torical information database, designated as H. This update is pivotal in accommodating both temporal dynamics and rel- evance considerations. The process can be mathematically represented as follows:\n$H' = Update(H, (q_t, p_t, r_t))$                                                       (11)\nThe Update function meticulously performs the subse- quent operations:\nH\u2019=H\u222a{(qt,pt,rt)}\nfor each con- stituent  in H', a comprehensive weight is com- puted:\n$w_i = \\alpha \\cdot Relevance(q_i, q_t) + (1 - \\alpha) \\cdot Recency(t_i)$    (13)\nHere, $Relevance(q_i, q_t)$ assesses the relevance between the query $q_i$ and the current query $q_t$, while $Recency(t_i)$ eval- uates a recency score based on the timestamp $t_i$. The pa- rameter \u03b1 serves as a hyperparameter to balance these two factors."}, {"title": "", "content": "Maintenance of database size: Should the size of H' exceed N (a predefined maximum capacity), the elements bearing the least comprehensive weights are excised:\n$H' = TopN(H', w)$                                         (14)\nwhere the TopN function selects the N most significant elements based on the comprehensive weights w.\nThrough this updating process, the dynamic historical in- formation database considers both the relevance and recency of information, ensuring it contains the most relevant and up-to-date information, thereby improving the system's per- formance in future interactions."}, {"title": "Dynamic Historical Information Database", "content": "The Strategic aims to categorize similar his- torical queries and responses into semantically coherent groups. This method not only improves the efficiency of data retrieval but also facilitates the identification of com- mon themes.\nGiven a set of historical queries $Q = \\{q_1, q_2, ..., q_n\\}$, we utilize a clustering algorithm C to segregate these queries into k distinct categories:\n\nHere, $c_i$ represents the i-th category. For a new query $q_t$, the procedure involves determining its corresponding cate- gory and then conducting a similarity search within this cat- egory:\n$c^* = arg max_{c_i} sim(q_t, centroid(c_i))$    (16)\n$q^* = arg max_{q \\in c^*} sim(q_t, q)$                                                                      (17)\nThe levels are:\n$c^* = arg max_{c_i} sim(q_t, centroid(c_i))$    (18)\n$s^* = arg max_{S_{ij} \\in summaries(c^*)} sim(q_t, S_{ij})$    (19)\n$q^* = arg max_{q \\in leaves(s^*)} sim(q_t, q)$    (20)\n$(p^*, r^*) = arg max_{(p, r) \\in q^*} sim(q_t, p)$             (21)\nis designed to capture the logical progression of multi-turn dialogues, representing a series of related query-passage-response triples as a chain:\nT = [(q1, P1, r1), (q2, P2, r2),..., (qn, Pn, rn)] (22)\n$T^* = arg max_{T} sim(q_t, T)$    (23)\n$(q^*, p^*, r^*) = arg max_{(q,p,r) \\in T^*} sim(q_t, q)$             (24)\nBy integrating these strategies, our Dynamic Historical Information Database effectively organizes and retrieves complex historical interaction data, providing a robust con- text for query reconstruction and response generation."}, {"title": "Experiments", "content": "To rigorously assess the performance of DH- RAG, we conduct comprehensive experiments across var- ious datasets and benchmark it against multiple baseline methods. For domain-specific dialogues, we utilize the Mo- bileCS2 dataset [7], which simulates multi-turn dialogues in mobile customer service scenarios. To adapt open-domain question answering to our multi-turn dialogue context, we modify the TriviaQA [19] and PopQA [9] datasets using ChatGPT, with subsequent screenings and annotations by domain experts to ensure the quality of the data. Addition- ally, we evaluate our model on conversational QA datasets specifically designed for multi-turn dialogue settings, in- cluding CoQA [28] and TopiOCQA [24], providing a di- verse and challenging set of benchmarks for DH-RAG.\nIn our experiments, we use the Con- triever model [15] as the retriever for the Vanilla Knowledge Base. For Clustering Matching, we adopt a relevancy-based approach. The Hierarchical Matching Strategy employs TF- IDF [27] vectorization. In the Information Integration phase, we utilize a pre-trained Sentence Transformer model [29] to generate vector representations of queries and results. All experiments are conducted on a server equipped with 8 NVIDIA 3090 GPUs to ensure consistency in computa- tional resources. We compare DH-RAG with two categories of baseline methods: standard LLMs, including Llama 2 7B [35], Llama 3 70B [35], Mistral 7B [16], and ChatGPT 40-mini [26]; and RAG methods, including BM25 [30] and Self-RAG [20]."}, {"title": "Quantitative Analysis", "content": "To assess the effectiveness of DH-RAG, we conduct exper- iments across various datasets and compare its performance with standard language models and existing RAG methods. Table 1 presents the results, utilizing BLEU and F1 scores as evaluation metrics.\nAs can be found in Table 1, DH-RAG demonstrates a remarkable ability to surpass all standard language mod- els and existing RAG methods across a variety of datasets, particularly excelling in domain-specific and conversational QA tasks. In the domain-specific MobileCS2, it achieves a BLEU score of 0.0410 and an F1 score of 0.2783, mark- ing substantial improvements over the best-performing base- line, SelfRAG, with relative increases of 215.38% in BLEU and 58.13% in F1 scores. In the modified open-domain QA datasets, PopQAMod and TriviaQAMod, DH-RAG continues to excel, recording BLEU scores of 0.4920 and 0.3097, and F1 scores of 0.6876 and 0.5720, respectively, significantly surpassing BM25. Moreover, in conversational QA tasks such as CoQA and TopiOCQA, DH-RAG maintains supe- rior performance with BLEU scores of 0.1286 and 0.1006,"}, {"title": "Efficiency Analysis", "content": "To comprehensively evaluate the computational efficiency of DH-RAG, we conducted experiments on the MobileCS2 dataset containing 216 multi-turn dialogues. Tables 2, 3, and 4 present detailed efficiency metrics comparing DH-RAG with baseline approaches.\nThe experimental results reveal that while DH-RAG intro- duces additional computational mechanisms for managing dynamic historical information, it maintains reasonable ef- ficiency. Specifically, DH-RAG shows only a 6.4% increase in total runtime compared to SelfRAG, as shown in Table 2. The system demonstrates moderate increases in memory uti- lization and processing complexity, which are well justified by the substantial performance improvements demonstrated in our quantitative analysis.\nDetailed operation timings in Table 3 show that while DH- RAG requires additional processing time for historical infor- mation management, it maintains comparable performance in basic operations such as document loading and retrieval. The per-query processing statistics in Table 4 further demon- strate the system's efficiency in handling individual queries. These efficiency metrics, when considered alongside the sig- nificant performance improvements shown in our quantita- tive analysis, demonstrate that DH-RAG achieves an effec- tive balance between computational efficiency and enhanced dialogue quality."}, {"title": "Qualitative Analysis", "content": "analysis"}]}