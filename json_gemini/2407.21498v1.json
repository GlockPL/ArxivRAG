{"title": "MaskUno: Switch-Split Block For Enhancing Instance Segmentation", "authors": ["Jawad Haidar", "Marc Mouawad", "Imad Elhajj", "Daniel Asmar"], "abstract": "Instance segmentation is an advanced form of image\nsegmentation which, beyond traditional segmentation, requires\nidentifying individual instances of repeating objects in a scene.\nMask R-CNN is the most common architecture for instance\nsegmentation, and improvements to this architecture include\nsteps such as benefiting from bounding box refinements, adding\nsemantics, or backbone enhancements. In all the proposed\nvariations to date, the problem of competing kernels (each class\naims to maximize its own accuracy) persists when models try\nto synchronously learn numerous classes. In this paper, we\npropose mitigating this problem by replacing mask prediction\nwith a Switch-Split block that processes refined ROIs, classifies\nthem, and assigns them to specialized mask predictors. We name\nthe method MaskUno and test it on various models from the\nliterature, which are then trained on multiple classes using the\nbenchmark COCO dataset. An increase in the mean Average\nPrecision (mAP) of 2.03% was observed for the high-performing\nDetectoRS when trained on 80 classes. MaskUno proved to\nenhance the mAP of instance segmentation models regardless\nof the number and type of classes or the type of architecture in\nwhich it was applied.", "sections": [{"title": "I. INTRODUCTION", "content": "Instance segmentation is a fundamental task in computer\nvision, which combines mask segmentation and object detec-\ntion, and whose goal is to perform a per-pixel classification\nof different objects in a scene. Instance segmentation has a\nwide range of applications such as in medical diagnostics\n[1], agricultural analysis [2], and autonomous driving [3]. Its\nabundant use in practical scenarios necessitates accurate and\nrobust predictions. The problem of instance segmentation is\ndifficult and faces challenges such as occlusion, scale changes,\nand cluttered backgrounds [4].\nWith an eye toward enhancing the performance of instance\nsegmentation, some researchers adopted the cascade methods\nthat rely on progressive refinement [5]. For example, one could\npipe the output of the the bounding box prediction from a\nStage 1 cascade into a region extractor (Stage 2), and so on,\nsuch that the progressive flow of the refined bounding boxes\nguarantees better-localized feature extraction. As a result, a\nhigher accuracy is achieved in delineating masks and bounding\nboxes.\nAnother research direction concentrates on designing back-\nbone networks that can detect features that are better suited\nfor the downstream task of instance segmentation. There exists\na trade-off between the depth of a backbone model and the\nspatial resolution of features. Contrary to image classification,\ninstance segmentation requires high spatial resolution of fea-\ntures, and so research on this front is concerned in architecting\nbackbone networks that can identify features with high spatial\nresolutions [6], [7].\nMost previous work in instance segmentation adopts the\npipeline of Mask R-CNN [5]\u2013[9]: after extracting features\nusing a backbone, a Region Proposal Network (RPN) localizes\nthe regions that encompass the sought-after objects. The\nlocalized regions are then extracted using a region of interest\nblock and fed to detection and mask generation branches.\nTo avoid competition among classes, Mask R-CNN replaces\nthe multi-nomial cross entropy with a per-class sigmoid and\nbinary loss [10], keeping in mind that the weights are com-\nmon between different classes given that they belong to the\nsame branch. To tackle this gap, our method works on top\nof most instance segmentation methods by simply isolating\nthe branches corresponding to different classes. Specifically,\nour pipeline consists of two main parts: detection and per-\nclass segmentation. The output of the detection is fed to a\nswitch that directs the bounding boxes to their corresponding\nsegmentation branch. Consequently, the optimization of each\nbranch is done independently to guarantee non-competing\nkernels between different classes. These simple modifications\nsignificantly improve the performance of the baseline Mask\nR-CNN [10] and the high performing CNN based model\nDetectors [6].\nThe remainder of this paper is organized as follows. In the\nnext section, we will delve deeper into the recent methods in\nthe field of instance segmentation. In Section III, the MaskUno\nproposed method is introduced. In Section IV, experiments are\nconducted and results demonstrate the enhancements obtained\nby MaskUno when applied to various instance segmentation\nmodels, trained and tested on the standard COCO dataset\nbenchmark. Finally, Section VI concludes the paper."}, {"title": "II. RELATED WORK", "content": "The architecture of an instance segmentation model contains\ndifferent blocks, each contributing in a different manner to the\nend result. First, the backbone is responsible for extracting\nhigh-level features of the image. One can usually add a Feature\nPyramid Network (FPN) that can help the network gain multi-\nscale context, which is crucial for detecting objects of different\nsizes. Next, comes the RPN, which generates from a feature\nmap potential region candidates that might contain objects.\nThe ROI-Align layer ensures that all the regions of interest\nare of similar size. Finally, the regions of interest are fed to\na terminal block which classifies them and predicts bounding\nboxes and binary masks for each instance. In the following\nsection, we will review the various interventions at the level\nof the backbone, object detection, and cascade."}, {"title": "A. Backbones", "content": "The pillar of every deep learning model is the feature\nextraction block (named backbone) and most of them are\nbuilt around a CNN. The downside of such models is that\nspatial resolution decreases with depth, which is problematic\nfor instance segmentation models that require high spatial\nresolution for pixel-wise mask prediction. To address this\nissue, SpineNet [7] uses Neural Architecture Search to learn\nscale permuted features as well as cross-scale connections.\nDetectoRS [6] proposes a recursive FPN that mimics thinking\ntwice at a macro level; more specifically, the outputs of the\nFPN are fed to the bottom-up backbone. Additionally, they\nintroduce the looking twice concept at the micro level, which\nis achieved by adding Switchable Atrous Convolutions."}, {"title": "B. Object detection", "content": "Object detection is an essential block for instance segmenta-\ntion as it delineates the bounding box surrounding each of the\ndetected objects in a scene. Object detection methods can be\nbased either on one stage [8], [11]\u2013[15], or two stages [10],\n[16]\u2013[18], where the former achieves better inference speed\nand the latter provides higher accuracy. The high inference\nspeed in one-stage detectors is ascribed to their simple archi-\ntecture; for instance, YOLO [11] divides the image into a grid\nand places various anchors having different scales and aspect\nratios. Then, the anchors are directly classified and adjusted\nafter a feature extraction stage. For the sake of predicting\nsmall-scale objects, SSD [12] performs detection at different\nstages of the feature extraction. RetinaNet [8] proposes the\nfocal loss to attenuate the effect of the abundant easy negatives,\nresulting in improved accuracy over the standard cross entropy\nloss. To get rid of anchors, CornerNet [13] expresses the\nbounding boxes by two points, the top-left and bottom-right\ncorners. CenterNet [14] uses the corners as proposals, and the\ncenter to verify the class of the object. A more accurate object\nrepresentation is proposed by ExtremeNet [15] that replaces\nthe corners with the objects' extreme points.\nOn the other hand, two-stage object detectors include an\nRPN, whose role is to first propose regions with high objec-\ntiveness probability, and output class-agnostic bounding boxes\nof possible objects. These bounding boxes are then used by\nthe region of interest extractor.\nR-CNN [16] uses a non-learning-based proposal generator\nto propose possible objects, and then each of these regions\nof interest is passed through a CNN to extract corresponding\nfeatures. This is a slow operation as each box is passed\nindependently. On the other hand, Fast R-CNN [19] applies\na feature extractor to the entire image and then extracts the\ncorresponding features. Finally, Faster R-CNN [20], replaces\nthe non-learning-based proposal method with a learnable RPN.\nMask R-CNN [10] adds a mask prediction head to support\ninstance segmentation, and additionally proposes a region of\ninterest alignment block that takes into account the neighbor-\ning pixels surrounding the bounding box."}, {"title": "C. Cascade", "content": "Cascade is the process of iterating the output of a model to\nachieve progressive refinement. Cascade R-CNN [5] proposes\nto add a simple cascade architecture on top of Faster R-\nCNN. A Stage 1 bounding box prediction is fed to a region\nof interest extractor and has the effect of superior localized\nbounding boxes that can contribute to enhanced feature ex-\ntraction. Likewise, Cascade Mask R-CNN applies this concept\nto enhance mask predictions. Hybrid Task Cascade (HTC)\nintroduces direct connections between the different stages of\nmask branches, thereby strengthening the flow by integrating\ncomplementary features across stages [9].\nTo summarize, the most significant enhancements to in-\nstance segmentation in the literature include interventions at\nthe level of the cascade, loss function, or backbone. In this\npaper, we propose to intervene at the level of the last prediction\nlayer, in a manner to mitigate the problem of competing\ngradients between different classes. As far as we know, none\nof the previous methods do this.\nThe contributions of this paper include the following:\n\u2022 Proposing a modular Switch-Split block that can replace\nmulti-class prediction heads in most instance segmenta-\ntion methods.\n\u2022 Ensuring no competing kernels between the different\nclasses, which leads to richer representations as no trade-\noff between classes is permitted.\n\u2022 Enhancing the accuracy of instance segmentation models\non the standard COCO dataset benchmark."}, {"title": "III. PROPOSED SYSTEM", "content": "Recalling from the previous section, at the output of an\ninstance segmentation model, detected regions of interest are\nstreamed into a terminal block consisting of three different\nbranches: the first one is usually a classifier indicating the\npresence of an object in this region, and if so classifies it. The\nsecond branch predicts refined bounding box coordinates for\neach proposed region, adjusting the initially generated region\nproposals. The third branch takes the ROI-aligned features\nas input and predicts a binary mask for each object instance\nwithin the proposed regions. These masks indicate the pixel-\nlevel segmentation of the objects.\nTo our knowledge, all instance segmentation architectures\nin the literature include the aforementioned terminal block\n(i.e., including the three branches). An interesting observation\nwe came to realize is that this block in its current form\nsuffers from what we refer to as competing kernels. The\ncompeting kernels problem arises when a model tries to\nsynchronously learn multiple classes having different features.\nDuring training, the kernels learned for each class compete\nwith others from another class in an attempt to maximize their\nown segmentation accuracy.\nThe main intuition driving our proposed MaskUno system\nis that each class should be learned on its own in a block we\nname the Switch-Split block."}, {"title": "A. Switch-Split block", "content": "The idea behind adding a switch and split block is to first\nbenefit from the bounding box refinement and then specialize\nthe learning per class. In other words, we first pass the\nbounding box head output through the ROI Align layer, then\nuse it as an input to the Switch-Split block (see Fig.1). The\noutput of the classifier is given as an input to the switch, then\nthe classifier, based on the input, classifies the refined ROI\nwhich then turns the switch to the corresponding class inside\nthe splitting block. Finally, each ROI is assigned to a specific\none-class mask head.\nThe split block is a set containing N+1 blocks, each trained\nto classify and predict the bounding box and the mask of one\nspecific class.\nThis idea applies to any architecture based on Mask-RCNN,\nand to any class. In this section, we will show how to adapt it\nto the baseline Mask-RCNN, the Cascade Mask-RCNN, and\nthe hybrid task cascade.\n1) Mask-RCNN: instead of having the bounding boxes and\nthe masks predicted in parallel as is usually done in Mask-\nRCNN, in MaskUno it is done sequentially. In other words,\nthe bounding boxes are first predicted, and then based on\nthese refined boxes the mask is estimated. Figure 1 presents\nan example of the methodology applied to this architecture.\n2) Cascade Mask-RCNN and Hybrid Task Cascade: this\narchitecture already includes bounding box refinements from\none layer to the other, meaning that the output of the refined\nbounding box of Layer i+1, is fed as an input to the Switch-\nSplit block of Layer i. The split block is a set containing N+1\nblocks, each trained to classify, and predict the mask of one\nspecific class. Figure 2 shows how each block is represented:\nthey all include a mask head, all having the same functionality\nas the branches of the basic Mask-RCNN pipeline. In terms\nof hybrid-task cascade, we also replace every mask-head with\na Switch-Split block, taking as input the refined classified\nbounding boxes as shown in Fig. 3."}, {"title": "B. Loss functions", "content": "Every one of these architectures is allocated a set of three\nloss functions, one for every sub-part of this block. Hence,\nthere is the categorical cross-entropy loss defined by (1), where\nYi is the true class label, and \u0177r is the predicted class label,\nand N is the number of classes.\n$L_{cls} = - \\sum_{i=1}^{N} y_i \\log(\\hat{y_i})$ (1)\nThe second loss function is the smooth L1 loss defined by\n(2) where x represents the difference between the predicted\nand the true value.\n$L_{1}(x) = \\begin{cases}\n0.5x^2, & \\text{if } |x| < 1 \\\\\n|x|-0.5, & \\text{otherwise}\n\\end{cases}$ (2)\nFor the mask prediction part, the loss function is a pixel-\nwise binary cross entropy defined by (3).\n$L_{mask} = - [Y_{true} (i, j) \\log (y_{pred} (i, j))+ (1 - Y_{true} (i, j)) \\log(1 \u2013 y_{pred}(i, j)) (3)\nwhere $Y_{true}$ is the true pixel label, and $y_{pred}$ is the predicted\npixel label."}, {"title": "C. Training", "content": "A typical model contains its own set of loss functions\n[Lcls, L1, Lmask] that it will try to minimize, while elim-\ninating the issue of competing kernels. The mask head of\nclass i will have its own Lmask; representing the pixel-wise\nloss function that will be minimized. Having different loss\nfunctions for every class is also essential to solve the issue of\ncompeting kernels as it makes the weights of every mask head\nindependent of one another also in terms of cost.\nThe training schedule and hyper-parameters are kept the\nsame for every block to avoid overfitting on a specific class."}, {"title": "D. Generalizing to other pipelines for instance segmentation", "content": "The switch split method should be applicable to any ar-\nchitecture, by first identifying the blocks where classification,\nbounding box regression, and mask prediction, are imple-\nmented, and then splitting the segmentation block into multiple\nones, each specialized for the concerned class.\nAs a proof of concept, one can even, perform sequential\ntraining for every architecture, meaning train the model on\nClass 1 to obtain a specialized mask-head for this class. Then,\ntrain a new mask-head using the original checkpoint of the\nimported model on Class 2, up until all needed classes have\na specialized mask-head.\nIn Section IV, we perform experiments on models in the\nliterature to validate our proposed method."}, {"title": "IV. EXPERIMENTATION AND DISCUSSION", "content": "1) Data used: Experiments are performed on the Common\nObject in Context (COCO) dataset [21] because it is chal-\nlenging due to the numerous classes it contains, and its high\nnumber of samples, but also to make a fair comparison with\nthe state-of-the-art models trained using this benchmark. We\nuse the train2017 and val2017 data which contain a total of\n115,000 and 5,000 images respectively. The data is split per-\nclass for both training and validation. For the bounding box\nand mask training, instance annotations are used, and for the\nsemantics, the COCO-stuff annotations.\n2) Evaluation: to evaluate the model performance, we use\nthe mean average precision taken at different IOU thresholds\n(at 0.5 and 0.75). Additionally, different scales are taken for\nthe data: small, medium, and large. We report the AP, AP50,\nAP75, APS, APm, and AP.\nB. Experimentation\nTo validate the generalization of MaskUno we test it on\nvarious classes and various architectures. The process starts\nby removing the multiclass mask prediction head from a pre-\ntrained model with a plateau in its accuracy, followed by\nadding the Switch-Split block and finally training the new\nweights on the sought classes. Afterward, we compare its\nmean Average Precision (mAP) with the one obtained before\ntraining the model. The hypothesis is that its mean average\nprecision increases for every class using the MaskUno method.\nThe experimentats are divided accordingly. First, using the\nCOCO dataset, and the library MMDetection [22], a similar\nexperiment is conducted on four different models: the baseline\nMask-RCNN [10], the Cascade-Mask-RCNN [5], the Hybrid\nTask Cascade [9], and the DetectoRS backbone [6] on a\nlist of 10 classes. Since the pre-trained models have more\nclasses compared to the MaskUno models, we separate the\nvalidation data into different sub-datasets, each responsible for\nvalidating a specific class. Furthermore, we experiment on a\ntotal of 80 classes and compare the results for Mask-RCNN\nand DetectoRS. Mask-RCNN is used since it is the baseline\nmodel for instance segmentation. DetectoRS is an architecture\nthat contains a change in backbone, as well as a hybrid task\ncascade architecture. Note that, given the methodology, we\ncare about the mask prediction results for all models and\nclasses.\nC. Results and discussion\nWe discuss in this section the results obtained after applying\nour method to different models and a variety of classes.\nTable I shows the results of the four models on every class.\nThe experiments consist of training each of these previously\nassumed saturated models, on a list of ten classes, shown in the\ncolumn of the table. The models are chosen in a way to include\nthe different techniques found in the literature, including\n(1) a change in the backbone (DetectoRS), (2) a cascade\narchitecture (Cascade mask-RCNN), and (3) a hybrid task\n(HTC). It is worth mentioning that DetectoRS is currently the\nbest-performing CNN-based model for instance segmentation.\nMoreover, we can see comparative results of the metrics before\nand after training, and for all architectures, there is a significant\nincrease in the mAP which varies from 0.5% to 5%.\nFurthermore, for some classes, we did not observe a signif-\nicant increase in the metrics. A possible explanation would\nbe the number of samples available. One example is the\nclass 'sheep' which contains a small number of samples (765\nsamples for training). Additionally, very few entries show a\nslight decrease after applying our method.\nThis experiment supports the fact that MaskUno can be\napplied to a wide set of methods for instance segmentation."}, {"title": "V. LIMITATIONS AND FUTURE WORK", "content": "Limitations: Our experiments demonstrate that MaskUno\noutperforms previous models when evaluated on a per-class\nbasis, with each class evaluated exclusively on its positive\nimages. However, it's important to note that this experimen-\ntal setup does not account for negative frames where false\npositives may cause the switch to misdirect certain images to\nincorrect branches.\nFurther experiments: Another experiment would be to\ninvestigate the effect of splitting the bounding box regres-\nsion block on the mAP, compare it to classical bounding\nbox refinement, and merge both together. A new version of\nMaskUno where splitting is done on the branch responsible\nfor bounding box prediction, followed by the mask split. This\nwould not only enhance bounding box refinements but also\nthe segmentation branch benefiting from this refinement.\nTransformer-based models: Instance segmentation models\nbased on transformers proved to surpass CNN-based models.\nThey are usually used as a backbone for various computer\nvision downstream tasks. A similar approach could be imple-\nmented, where the bounding box regression and segmentation\nbranches of such models would be split into multiple parts to\nspecialize the training per-class."}, {"title": "VI. CONCLUSION", "content": "To address the issue of conflicting gradients, we offer\nMaskUno, a Switch-Split block that can be used for most\ninstance segmentation algorithms. It enhances the accuracy of\ninstance segmentation models based on Mask-RCNN that use\nmulti-class segmentation methods and has a complementary\neffect to tasks such as cascade or hybrid task. MaskUno pro-\nvided a 2.03% improvement over one of the best-performing\nCNN-based instance segmentation models \"Detectors\" on the\nstandard COCO dataset. Moreover, for future work, applying"}]}