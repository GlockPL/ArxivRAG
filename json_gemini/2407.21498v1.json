{"title": "MaskUno: Switch-Split Block For Enhancing Instance Segmentation", "authors": ["Jawad Haidar", "Marc Mouawad", "Imad Elhajj", "Daniel Asmar"], "abstract": "Instance segmentation is an advanced form of image segmentation which, beyond traditional segmentation, requires identifying individual instances of repeating objects in a scene. Mask R-CNN is the most common architecture for instance segmentation, and improvements to this architecture include steps such as benefiting from bounding box refinements, adding semantics, or backbone enhancements. In all the proposed variations to date, the problem of competing kernels (each class aims to maximize its own accuracy) persists when models try to synchronously learn numerous classes. In this paper, we propose mitigating this problem by replacing mask prediction with a Switch-Split block that processes refined ROIs, classifies them, and assigns them to specialized mask predictors. We name the method MaskUno and test it on various models from the literature, which are then trained on multiple classes using the benchmark COCO dataset. An increase in the mean Average Precision (mAP) of 2.03% was observed for the high-performing DetectoRS when trained on 80 classes. MaskUno proved to enhance the mAP of instance segmentation models regardless of the number and type of classes or the type of architecture in which it was applied.", "sections": [{"title": "I. INTRODUCTION", "content": "Instance segmentation is a fundamental task in computer vision, which combines mask segmentation and object detection, and whose goal is to perform a per-pixel classification of different objects in a scene. Instance segmentation has a wide range of applications such as in medical diagnostics [1], agricultural analysis [2], and autonomous driving [3]. Its abundant use in practical scenarios necessitates accurate and robust predictions. The problem of instance segmentation is difficult and faces challenges such as occlusion, scale changes, and cluttered backgrounds [4].\nWith an eye toward enhancing the performance of instance segmentation, some researchers adopted the cascade methods that rely on progressive refinement [5]. For example, one could pipe the output of the the bounding box prediction from a Stage 1 cascade into a region extractor (Stage 2), and so on, such that the progressive flow of the refined bounding boxes guarantees better-localized feature extraction. As a result, a higher accuracy is achieved in delineating masks and bounding boxes.\nAnother research direction concentrates on designing backbone networks that can detect features that are better suited for the downstream task of instance segmentation. There exists a trade-off between the depth of a backbone model and the spatial resolution of features. Contrary to image classification, instance segmentation requires high spatial resolution of features, and so research on this front is concerned in architecting backbone networks that can identify features with high spatial resolutions [6], [7]."}, {"title": "II. RELATED WORK", "content": "The architecture of an instance segmentation model contains different blocks, each contributing in a different manner to the end result. First, the backbone is responsible for extracting high-level features of the image. One can usually add a Feature Pyramid Network (FPN) that can help the network gain multi-scale context, which is crucial for detecting objects of different sizes. Next, comes the RPN, which generates from a feature map potential region candidates that might contain objects. The ROI-Align layer ensures that all the regions of interest are of similar size. Finally, the regions of interest are fed to a terminal block which classifies them and predicts bounding boxes and binary masks for each instance. In the following section, we will review the various interventions at the level of the backbone, object detection, and cascade."}, {"title": "A. Backbones", "content": "The pillar of every deep learning model is the feature extraction block (named backbone) and most of them are built around a CNN. The downside of such models is that spatial resolution decreases with depth, which is problematic for instance segmentation models that require high spatial resolution for pixel-wise mask prediction. To address this issue, SpineNet [7] uses Neural Architecture Search to learn scale permuted features as well as cross-scale connections. DetectoRS [6] proposes a recursive FPN that mimics thinking twice at a macro level; more specifically, the outputs of the FPN are fed to the bottom-up backbone. Additionally, they introduce the looking twice concept at the micro level, which is achieved by adding Switchable Atrous Convolutions."}, {"title": "B. Object detection", "content": "Object detection is an essential block for instance segmentation as it delineates the bounding box surrounding each of the detected objects in a scene. Object detection methods can be based either on one stage [8], [11]\u2013[15], or two stages [10], [16]\u2013[18], where the former achieves better inference speed and the latter provides higher accuracy. The high inference speed in one-stage detectors is ascribed to their simple architecture; for instance, YOLO [11] divides the image into a grid and places various anchors having different scales and aspect ratios. Then, the anchors are directly classified and adjusted after a feature extraction stage. For the sake of predicting small-scale objects, SSD [12] performs detection at different stages of the feature extraction. RetinaNet [8] proposes the focal loss to attenuate the effect of the abundant easy negatives, resulting in improved accuracy over the standard cross entropy loss. To get rid of anchors, CornerNet [13] expresses the bounding boxes by two points, the top-left and bottom-right corners. CenterNet [14] uses the corners as proposals, and the center to verify the class of the object. A more accurate object representation is proposed by ExtremeNet [15] that replaces the corners with the objects' extreme points.\nOn the other hand, two-stage object detectors include an RPN, whose role is to first propose regions with high objectiveness probability, and output class-agnostic bounding boxes of possible objects. These bounding boxes are then used by the region of interest extractor.\nR-CNN [16] uses a non-learning-based proposal generator to propose possible objects, and then each of these regions of interest is passed through a CNN to extract corresponding features. This is a slow operation as each box is passed independently. On the other hand, Fast R-CNN [19] applies a feature extractor to the entire image and then extracts the corresponding features. Finally, Faster R-CNN [20], replaces the non-learning-based proposal method with a learnable RPN. Mask R-CNN [10] adds a mask prediction head to support instance segmentation, and additionally proposes a region of interest alignment block that takes into account the neighboring pixels surrounding the bounding box."}, {"title": "C. Cascade", "content": "Cascade is the process of iterating the output of a model to achieve progressive refinement. Cascade R-CNN [5] proposes to add a simple cascade architecture on top of Faster R-CNN. A Stage 1 bounding box prediction is fed to a region of interest extractor and has the effect of superior localized bounding boxes that can contribute to enhanced feature extraction. Likewise, Cascade Mask R-CNN applies this concept to enhance mask predictions. Hybrid Task Cascade (HTC) introduces direct connections between the different stages of mask branches, thereby strengthening the flow by integrating complementary features across stages [9].\nTo summarize, the most significant enhancements to instance segmentation in the literature include interventions at the level of the cascade, loss function, or backbone. In this paper, we propose to intervene at the level of the last prediction layer, in a manner to mitigate the problem of competing gradients between different classes. As far as we know, none of the previous methods do this.\nThe contributions of this paper include the following:\n\u2022 Proposing a modular Switch-Split block that can replace multi-class prediction heads in most instance segmentation methods.\n\u2022 Ensuring no competing kernels between the different classes, which leads to richer representations as no trade-off between classes is permitted.\n\u2022 Enhancing the accuracy of instance segmentation models on the standard COCO dataset benchmark."}, {"title": "III. PROPOSED SYSTEM", "content": "Recalling from the previous section, at the output of an instance segmentation model, detected regions of interest are streamed into a terminal block consisting of three different branches: the first one is usually a classifier indicating the presence of an object in this region, and if so classifies it. The second branch predicts refined bounding box coordinates for each proposed region, adjusting the initially generated region proposals. The third branch takes the ROI-aligned features as input and predicts a binary mask for each object instance within the proposed regions. These masks indicate the pixel-level segmentation of the objects.\nTo our knowledge, all instance segmentation architectures in the literature include the aforementioned terminal block (i.e., including the three branches). An interesting observation we came to realize is that this block in its current form suffers from what we refer to as competing kernels. The competing kernels problem arises when a model tries to synchronously learn multiple classes having different features. During training, the kernels learned for each class compete with others from another class in an attempt to maximize their own segmentation accuracy.\nThe main intuition driving our proposed MaskUno system is that each class should be learned on its own in a block we name the Switch-Split block."}, {"title": "A. Switch-Split block", "content": "The idea behind adding a switch and split block is to first benefit from the bounding box refinement and then specialize the learning per class. In other words, we first pass the bounding box head output through the ROI Align layer, then use it as an input to the Switch-Split block (see Fig.1). The output of the classifier is given as an input to the switch, then the classifier, based on the input, classifies the refined ROI which then turns the switch to the corresponding class inside the splitting block. Finally, each ROI is assigned to a specific one-class mask head.\nThe split block is a set containing N+1 blocks, each trained to classify and predict the bounding box and the mask of one specific class.\nThis idea applies to any architecture based on Mask-RCNN, and to any class. In this section, we will show how to adapt it to the baseline Mask-RCNN, the Cascade Mask-RCNN, and the hybrid task cascade.\n1) Mask-RCNN: instead of having the bounding boxes and the masks predicted in parallel as is usually done in Mask-RCNN, in MaskUno it is done sequentially. In other words, the bounding boxes are first predicted, and then based on these refined boxes the mask is estimated.\n2) Cascade Mask-RCNN and Hybrid Task Cascade: this architecture already includes bounding box refinements from one layer to the other, meaning that the output of the refined bounding box of Layer i+1, is fed as an input to the Switch-Split block of Layer i. The split block is a set containing N+1 blocks, each trained to classify, and predict the mask of one specific class. Figure 2 shows how each block is represented: they all include a mask head, all having the same functionality as the branches of the basic Mask-RCNN pipeline. In terms of hybrid-task cascade, we also replace every mask-head with a Switch-Split block, taking as input the refined classified bounding boxes as shown in Fig. 3."}, {"title": "B. Loss functions", "content": "Every one of these architectures is allocated a set of three loss functions, one for every sub-part of this block. Hence, there is the categorical cross-entropy loss defined by (1), where $y_i$ is the true class label, and $\\hat{y_i}$ is the predicted class label, and N is the number of classes.\n$L_{cls} = -\\sum_{i=1}^{N} y_i log(\\hat{y_i})$ (1)\nThe second loss function is the smooth L1 loss defined by (2) where x represents the difference between the predicted and the true value.\n$L_1(x) = \\begin{cases} 0.5x^2, & \\text{if } |x| < 1 \\\\ |x|-0.5, & \\text{otherwise} \\end{cases}$ (2)\nFor the mask prediction part, the loss function is a pixel-wise binary cross entropy defined by (3).\n$L_{mask_{i,j}} = [Y_{true}(i, j) log (y_{pred}(i, j))+ (1 - Y_{true}(i, j)) log(1 \u2013 y_{pred}(i, j))$ (3)\nwhere $Y_{true}$ is the true pixel label, and $y_{pred}$ is the predicted pixel label."}, {"title": "C. Training", "content": "A typical model contains its own set of loss functions [$L_{cls}, L_1, L_{mask}$] that it will try to minimize, while eliminating the issue of competing kernels. The mask head of class i will have its own $L_{mask}$; representing the pixel-wise loss function that will be minimized. Having different loss functions for every class is also essential to solve the issue of competing kernels as it makes the weights of every mask head independent of one another also in terms of cost.\nThe training schedule and hyper-parameters are kept the same for every block to avoid overfitting on a specific class."}, {"title": "D. Generalizing to other pipelines for instance segmentation", "content": "The switch split method should be applicable to any architecture, by first identifying the blocks where classification, bounding box regression, and mask prediction, are implemented, and then splitting the segmentation block into multiple ones, each specialized for the concerned class.\nAs a proof of concept, one can even, perform sequential training for every architecture, meaning train the model on Class 1 to obtain a specialized mask-head for this class. Then, train a new mask-head using the original checkpoint of the imported model on Class 2, up until all needed classes have a specialized mask-head."}, {"title": "IV. EXPERIMENTATION AND DISCUSSION", "content": "In Section IV, we perform experiments on models in the literature to validate our proposed method."}, {"title": "A. Datasets and metrics", "content": "1) Data used: Experiments are performed on the Common Object in Context (COCO) dataset [21] because it is challenging due to the numerous classes it contains, and its high number of samples, but also to make a fair comparison with the state-of-the-art models trained using this benchmark. We use the train2017 and val2017 data which contain a total of 115,000 and 5,000 images respectively. The data is split per-class for both training and validation. For the bounding box and mask training, instance annotations are used, and for the semantics, the COCO-stuff annotations."}, {"title": "B. Experimentation", "content": "To validate the generalization of MaskUno we test it on various classes and various architectures. The process starts by removing the multiclass mask prediction head from a pre-trained model with a plateau in its accuracy, followed by adding the Switch-Split block and finally training the new weights on the sought classes. Afterward, we compare its mean Average Precision (mAP) with the one obtained before training the model. The hypothesis is that its mean average precision increases for every class using the MaskUno method. The experimentats are divided accordingly. First, using the COCO dataset, and the library MMDetection [22], a similar experiment is conducted on four different models: the baseline Mask-RCNN [10], the Cascade-Mask-RCNN [5], the Hybrid Task Cascade [9], and the DetectoRS backbone [6] on a list of 10 classes. Since the pre-trained models have more classes compared to the MaskUno models, we separate the validation data into different sub-datasets, each responsible for validating a specific class. Furthermore, we experiment on a total of 80 classes and compare the results for Mask-RCNN and DetectoRS. Mask-RCNN is used since it is the baseline model for instance segmentation. DetectoRS is an architecture that contains a change in backbone, as well as a hybrid task cascade architecture. Note that, given the methodology, we care about the mask prediction results for all models and classes."}, {"title": "C. Results and discussion", "content": "We discuss in this section the results obtained after applying our method to different models and a variety of classes.\nThe experiments consist of training each of these previously assumed saturated models, on a list of ten classes,. The models are chosen in a way to include the different techniques found in the literature, including (1) a change in the backbone (DetectoRS), (2) a cascade architecture (Cascade mask-RCNN), and (3) a hybrid task (HTC). It is worth mentioning that DetectoRS is currently the best-performing CNN-based model for instance segmentation. Moreover, we can see comparative results of the metrics before and after training, and for all architectures, there is a significant increase in the mAP which varies from 0.5% to 5%.\nFurthermore, for some classes, we did not observe a significant increase in the metrics. A possible explanation would be the number of samples available. One example is the class 'sheep' which contains a small number of samples (765 samples for training). Additionally, very few entries show a slight decrease after applying our method.\nThis experiment supports the fact that MaskUno can be applied to a wide set of methods for instance segmentation."}, {"title": "V. LIMITATIONS AND FUTURE WORK", "content": "Limitations: Our experiments demonstrate that MaskUno outperforms previous models when evaluated on a per-class basis, with each class evaluated exclusively on its positive images. However, it's important to note that this experimental setup does not account for negative frames where false positives may cause the switch to misdirect certain images to incorrect branches.\nFurther experiments: Another experiment would be to investigate the effect of splitting the bounding box regression block on the mAP, compare it to classical bounding box refinement, and merge both together. A new version of MaskUno where splitting is done on the branch responsible for bounding box prediction, followed by the mask split. This would not only enhance bounding box refinements but also the segmentation branch benefiting from this refinement.\nTransformer-based models: Instance segmentation models based on transformers proved to surpass CNN-based models. They are usually used as a backbone for various computer vision downstream tasks. A similar approach could be implemented, where the bounding box regression and segmentation branches of such models would be split into multiple parts to specialize the training per-class."}, {"title": "VI. CONCLUSION", "content": "To address the issue of conflicting gradients, we offer MaskUno, a Switch-Split block that can be used for most instance segmentation algorithms. It enhances the accuracy of instance segmentation models based on Mask-RCNN that use multi-class segmentation methods and has a complementary effect to tasks such as cascade or hybrid task. MaskUno provided a 2.03% improvement over one of the best-performing CNN-based instance segmentation models \"Detectors\" on the standard COCO dataset. Moreover, for future work, applying MaskUno on transformer-based models, while benefiting from a split of both bounding box regression and mask prediction, has the potential to reach a new state-of-the-art accuracy."}]}