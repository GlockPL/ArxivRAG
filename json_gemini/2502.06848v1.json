{"title": "TRANSFER LEARNING IN SCALABLE GRAPH NEURAL\nNETWORK FOR IMPROVED PHYSICAL SIMULATION", "authors": ["Siqi Shen", "Yu Liu", "Daniel Biggs", "Omar Hafez", "Jiandong Yu", "Wentao Zhang", "Bin Cui", "Jiulong Shan"], "abstract": "In recent years, Graph Neural Network (GNN) based models have shown promis-\ning results in simulating physics of complex systems. However, training dedicated\ngraph network based physics simulators can be costly, as most models are confined\nto fully supervised training, which requires extensive data generated from tradi-\ntional physics simulators. To date, how transfer learning could improve the model\nperformance and training efficiency has remained unexplored. In this work, we\nintroduce a pre-training and transfer learning paradigm for graph network simula-\ntors. We propose the scalable graph U-net (SGUNET). Incorporating an innovative\ndepth-first search (DFS) pooling, the SGUNET is adaptable to different mesh sizes\nand resolutions for various simulation tasks. To enable the transfer learning be-\ntween differently configured SGUNETS, we propose a set of mapping functions to\nalign the parameters between the pre-trained model and the target model. An extra\nnormalization term is also added into the loss to constrain the difference between\nthe pre-trained weights and target model weights for better generalization per-\nformance. To pre-train our physics simulator we created a dataset which includes\n20,000 physical simulations of randomly selected 3D shapes from the open source\nA Big CAD (ABC) dataset. We show that our proposed transfer learning meth-\nods allow the model to perform even better when fine-tuned with small amounts\nof training data than when it is trained from scratch with full extensive dataset.\nOn the 2D Deformable Plate benchmark dataset, our pre-trained model fine-tuned\non 1/16 of the training data achieved an 11.05% improvement in position RMSE\ncompared to the model trained from scratch.", "sections": [{"title": "INTRODUCTION", "content": "Graph Neural Networks (GNNs) have shown promising results in simulating physics of complex\nsystems on unstructured meshes Pfaff et al. (2021); Allen et al. (2022a); Rubanova et al. (2022);\nAllen et al. (2022c). Existing works stack message passing (MP) blocks to model propagation of\nphysical information. Different pooling operations Li et al. (2020); Cao et al. (2023) and U-Net like\narchitectures Gladstone et al. (2023); Deshpande et al. (2024) have been introduced to better solve\nthe multi-scale challenges in different simulation tasks. However, despite their potential, current\nGNN-based methods rely heavily on supervised training approaches. Collecting extensive annotated\ndata typically involves using traditional Finite Element Analysis (FEA) solvers Han et al. (2022);"}, {"title": "RELATED WORK", "content": "Graph Neural Networks (GNNs) have emerged as a powerful tool for simulating complex physical\nsystems, particularly on unstructured meshes Pfaff et al. (2021); Allen et al. (2022a); Rubanova\net al. (2022); Allen et al. (2022c;b). However, these methods predominantly rely on supervised\ntraining, which requires extensive annotated data. Common approaches involve generating data\nthrough analytical solvers like OpenFOAM Weller et al. (1998) and ArcSim Narain et al. (2012).\nAdditionally, some works use real-world observations to train models Whitney et al. (2023); Allen\net al. (2022c). Early work, such as MGN Pfaff et al. (2021), adapts the Encoder-Process-Decode\narchitecture Sanchez-Gonzalez et al. (2020) to mesh data, with the Process module implemented as\na GNN for effective message passing. Variants like EA-GNN and M-GNN Gladstone et al. (2023)\nintroduce enhancements such as virtual edges and multi-resolution graphs to improve efficiency\nand handle long-range interactions. Additionally, the transformer architecture has been explored\nin mesh-based physical simulations. Hybrid models like the GMR-Transformer-GMUS Han et al.\n(2022) and HCMT Yu et al. (2023) combine GNNs to learn local rules and transformers to capture\nglobal context and long-term dependencies over roll-out trajectories. Unlike most methods that\ndirectly predict future states from input data, C-GNS Rubanova et al. (2022) employs a GNN to\nmodel system constraints and computes future states by solving an optimization problem based on\nthese learned constraints.\nTransfer learning, which transfers knowledge from a source domain to a target domain, has gained\nprominence in deep learning for improving performance and reducing the need for annotated data\nReddy & Juliet (2019); Rezende et al. (2017); Mann et al. (2020); Touvron et al. (2023). Strategies\ntypically involve parameter control, either by sharing parameters between models or enforcing sim-"}, {"title": "METHOD", "content": "In this section, we introduce our pre-training and fine-tuning framework. We begin by detailing the\ndata format used by our model. Following this, we provide an in-depth explanation of the model\narchitecture, discussing its fundamental networks, operators, and key modules. Finally, we describe\nthe transfer learning mechanism, emphasizing two mapping functions that adjust the model size for\noptimal performance."}, {"title": "OVERVIEW", "content": "In this section, we introduce our pre-training and fine-tuning framework. We begin by detailing the\ndata format used by our model. Following this, we provide an in-depth explanation of the model\narchitecture, discussing its fundamental networks, operators, and key modules. Finally, we describe\nthe transfer learning mechanism, emphasizing two mapping functions that adjust the model size for\noptimal performance."}, {"title": "PROBLEM STATEMENT", "content": "Given the physical state of a system, our task is to predict the subsequent state over a time inter-\nval and under specified boundary conditions. The system's current state at time t is described by a\ndiscretized mesh $M_t$ and can be represented in 2D or 3D space. The mesh data $M_t$ is comprised\nof world coordinates, element connectivity, and physical parameters (stress/strain state and material\nproperties). We use one-step prediction to find the subsequent mesh state $M_{t+1}$, but for sake of no-\ntational convenience, we will omit the superscript t, which indicates the timestamp in the subsequent\nexpressions.\nTo facilitate the learning process, we transform the original mesh data M into a heterogeneous graph\n$G^{hetero} = (V,E)$, where V denotes the set of nodes and E represents the set of edges. The node\nset V comprises two types of node: mesh nodes $V^M$ and element nodes $V^E$. The mesh vertices\nin M are converted to graph nodes in $V^M$, while the mesh faces are represented as nodes in $V^E$.\nThis heterogeneous graph structure is necessary to describe physical state variables like stress in a\nsingle-valued way when multiple materials are present in a system, as is typical for many physical\nsimulations. The edge set & includes three groups of edges: (1) bidirectional edges $E^{M,M}$ between\nadjacent mesh vertices $V^M$, (2) bidirectional edges $E^{E,E}$ between adjacent faces $V^E$, and (3) direc-\ntional edges $E^{E,M}$ and $E^{M,E}$ which connect each mesh face to its vertices. Figure 1a provides a\ndemonstration of mesh data derived from the Deformable Plate dataset and its corresponding het-\nerogeneous graph.\nEach type of node and edge has its own feature matrix. For example, the feature matrix of mesh\nnodes $V^M$ is $X^M \\in R^{|V^M|\\times{h^M}}$, where the feature vector of node $i \\in V^M$ is the i-th row vector of\n$X^M$. We explain the composition of feature matrices in Appendix B.4."}, {"title": "SCALABLE GRAPH U-NET", "content": "Our model comprises four main modules, as illustrated in Figure 2a. We adopt an Encoder-Process-\nDecoder Sanchez-Gonzalez et al. (2020) style model with several key extensions: (1) the framework\nis extended to handle the heterogeneous graph structure with multiple node and edge types, and (2)"}, {"title": "UTILIZING THE PRE-TRAINED MODEL", "content": "How exactly the knowledge from a pre-trained model is instilled into a target task-specific model,\nparticularly when their architectures are mismatched, is a non-trivial task. As stated in Section 2, one\nof the widely-used approaches in transfer learning operates at the parameter level. We also adopt the\nparameter sharing and parameter restriction strategies and discuss these in more detail here. To our\nknowledge, this is the first time transfer learning has been adapted and applied to GNNs predicting\nphysics simulations."}, {"title": "PARAMETER SHARING", "content": "The parameter sharing strategy involves initializing the downstream task-specific model with a pre-\ntrained model. Typically, the pre-trained model is either the same as or more complex than the\ntask-specific model due to resource constraints Xu et al. (2023). However, this is not the case for\nour mesh-based graph network model. This distinction arises because the number of stages and\nmessage passing steps in the GUnet are closely aligned with the data size and simulation settings.\nAs a result, conventional weight initialization methods are not directly applicable. Therefore, we\ndesign alternative strategies to effectively transfer learned knowledge from the pre-trained model to\nthe downstream model within our unique framework.\nWe propose a scaling method at two levels \u2014 Processor and GUnet \u2014 to align the sizes of the pre-\ntrained and fine-tuned models. We choose between two mapping functions for both the Processors\nand GUnet: Uniform and First-N. The details of these mapping functions are described below. For\nthe Processors, we employ the mapping function on GNBs, which ensures that the alignment reflects\nthe stages of message propagation through the blocks. For the GUnet, we employ the mapping\nfunction on the GUnet stages. In general, the mapping function chosen for the Processors and GUnet\nneed not be the same, but for our present work we used the same mapping (First-N or Uniform) for\nboth Processors and GUnet for a given experiment.\nNote that the Encoder and the Decoder do not contain generalizable knowledge as they are tailored\nto specific tasks. In our implementation, we randomly initialize the parameters of the Encoder and\nDecoders during fine-tuning.\n1) Uniform Mapping: The first method of parameter sharing between pre-trained and fine-tuned\nmodels is the Uniform method. The goal of this mapping method is to achieve uniform division and\nalignment of weights. To align the weights of two Processors, we consider cases where the number"}, {"title": "PARAMETER RESTRICTION", "content": "Beyond parameter sharing, we implement a parameter restriction technique to enhance the gen-\neralization capabilities of the downstream models. Following Gouk et al. Gouk et al. (2020), we\ncalculate the Frobenius distance between the pre-trained and fine-tuned model weights to apply a\nregularization term that penalizes discrepancies between them. Let $W_{pt}$ denote the weights of the\npre-trained model, and $W_{ft}$ represent the weights of the fine-tuned model. Then the Frobenius norm\nof the difference between these two sets of weights can be expressed as:\n$||W_{pt} - W_{ft}||_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} (W_{pt}^{(i,j)} - W_{ft}^{(i,j)})^2}$.\nTo incorporate Frobenius distance into the training process, the regularization term is added to the\nloss function. The regularized loss function $L_{reg}$ can be written as:\n$L_{reg} = L_{task} + \\lambda ||W_{pt} - W_{ft}||$,\nwhere $\\lambda$ is a hyperparameter that controls the strength of the regularization term, and $L_{task}$ repre-\nsents the original task-related loss."}, {"title": "EXPERIMENTS", "content": "We present an evaluation of our proposed pre-training and fine-tuning framework for mesh-based\nsimulations. We begin by detailing the datasets used in our experiments, highlighting both the gen-\neralized dataset constructed for pre-training and the benchmark datasets employed for fine-tuning.\nFollowing this, we introduce the baseline models against which our approach is compared. We then\npresent the results of our pre-training phase and evaluate the transfer learning performance."}, {"title": "DATASETS", "content": "1) For pre-training: Since there is currently no existing work on pre-training for mesh-based phys-\nical simulations, and popular benchmark datasets contain at best a few thousands training samples,\nwe constructed a larger and more-generalized pre-training dataset. The goal of this dataset was to\nhave a wide variety of geometric shapes that are deformed after coming into contact with each other.\nWe used the ABC dataset Koch et al. (2019), which is a CAD model dataset used for geometric\ndeep learning, to get a wide sample of parts and shapes to deform. To generate a simulation in our\npre-training dataset, we first randomly select two CAD geometries, then auto-mesh them with the\nmeshing tool Shabaka Hafez & Rashid (2023). We then align the two meshed parts in 3D space\nand apply compressive boundary conditions to simulate the parts coming into contact. Figure 3\nillustrates the workflow of the pre-training dataset construction process.\nIn total, we generated a pre-training dataset of 20,000 simulations by drawing pairs of geometries\nfrom a set of 400 geometry samples. Figure 4 shows several example simulations and the modes of\ndeformation achieved through contact. Here we can see examples of mechanical contact and stress\naround a hole.\n2) For Transfer Learning: We selected two representative datasets for quasi-static mechanical\nsimulations as benchmarks to evaluate model performance on downstream tasks: 2D Deformable\nPlate Linkerh\u00e4gner et al. (2023) and 3D Deforming Plate Pfaff et al. (2021). These downstream\ntask datasets represent a subspace of simulations relative to our generalized pre-training dataset, and\nthought to be good candidates to evaluate our fine-tuning framework. For more detailed information\nabout the datasets, please refer to Table 2."}, {"title": "BASELINE AND METRIC", "content": "To demonstrate the generalization and effectiveness of our pre-training and fine-tuning paradigm,\nwe used MGN Pfaff et al. (2021), a state-of-the-art model in the field of physics simulation, as the\nbaseline for comparison. The model configurations are shown in Table 1 and more explanations can"}, {"title": "PRE-TRAINING RESULTS", "content": "We trained both the MGN and SGUNET models on ABCD for 1 million training steps. The RMSE\nlosses for MGN on the training and validation datasets are 8.3205\u00d710-4 and 5.8018\u00d710-4, re-\nspectively. In comparison, SGUNET achieves RMSE losses of 4.2041\u00d710-4 on the training set and\n4.2657\u00d710-4 on the validation set. These results demonstrate that SGUNET outperforms MGN,\nreducing the training loss by nearly 50%. Moreover, the validation loss shows that SGUNET gener-\nalizes better to unseen data while converging more effectively during training."}, {"title": "TRANSFER LEARNING PERFORMANCE", "content": "To evaluate the effectiveness of our pre-training and fine-tuning framework, we performed experi-\nments using the ABCD dataset for pre-training. Both the MGN and SGUNET models are trained for\na defined number of epochs. Subsequently, we fine-tuned these models on downstream tasks. For\nthe Deformable Plate dataset, the models were fine-tuned for 20k steps. For the Deforming Plate\ndataset, the models were fine-tuned for 500k steps. We applied two parameter sharing strategies\u2014\nUniform and First-N\u2014 when loading the checkpoint of the pre-trained model. Additionally, we\nreduced the size of the training dataset to investigate whether our framework can decrease reliance\non large volume of data. During this process, we recorded the minimum validation loss and saved\nthe corresponding model checkpoint, which was later used to assess performance on the test dataset.\nAll experiments are repeated 5 times with different random seeds.\nDeformable Plate: We reduced the training set to, and of its original size. The animations\nin Figure 5 provide an intuitive qualitative assessment. This figure presents an example from the\ntest dataset. From these visualizations, we can observe a clear improvement in the handling of\ndeformations at the contact area between the ball and the plate after fine-tuning. Specifically, the\nball and plate no longer overlap, the plate's deformation curve conforms more closely to the ball's\ncontour, and the deformation in areas farther from the contact point aligns more accurately with the\nground truth."}, {"title": "DISCUSSION", "content": "In this paper, we introduce a novel pre-training and fine-tuning framework tailored specifically for\nmesh-based physical simulations. Our approach uses a scalable graph U-net (SGUNET), which is\ndefined in a modular and configurable manner to facilitate the parameter sharing process for transfer\nlearning. We constructed a dataset for pre-training, i.e. ABCD, and utilized it to pre-train the\nmodels. Through extensive experiments, we demonstrate that not only does SGUNET outperform\nMGN, a SOTA model in this field, but also both models achieve improvements in performance across\nvarious dataset scales when fine-tuned. Notably, the fine-tuned models reduce their dependence on\nthe training data.\nDespite the promising results, there are some limitations that warrant further exploration. First, we\nhave evaluated our framework only in the context of quasi-static simulations. Future work could\nextend it to a broader range of physical systems to assess its versatility and effectiveness in more\ndynamic scenarios. Second, our current transfer learning methods, which includes two strategies for\nparameter sharing and one for parameter restriction, have proven effective, exploring alternative and\nmore advanced transfer learning techniques could offer valuable opportunities for future research."}, {"title": "ALIGNMENT OF GUNET", "content": "A GUnet module comprise L stages. To align a GUnet with $L_{pt}$ stages in the pre-trained model with\na GUnet having $L_{ft}$ stages in the fine-tuned model, it is essential to construct a mapping function that\nbuild the connection between stages of the two models. Similar to the alignment of the Processor\nmodule, we design two mapping methods. Let $g_2(GU^{pt})$ denote the function that maps a GUnet\n$GU^{pt}$ in the pre-trained model to a GUnet $GU^{ft}$ in the fine-tuned model. For Uniform Mapping,\n$GU^{ft}_i = g^{uni}_1(i; GU^{pt}) = \\begin{cases}\ng_1(\\frac{i}{\\lceil{upN}\\rceil});\\\\\\MEAN_{j=st(i)+d(i)}\\{g_1(GU^{pt}_j)\\}, \\\\\ng_1(GU^{pt}_i),\\end{cases} \\\\ \\begin{matrix}\nif \\\\L_{pt}< L_{ft}\\\\\nif \\\\L_{pt}> L_{ft}\\\\\nif \\\\L_{pt}== L_{ft}.\n\\end{matrix}$\nFor First-N Mapping,\n$GU^{ft}_i = g^{First-N}_1(i; GU^{pt}) = \\begin{cases}\ng_1(GU^{pt}_i),& \\text{if } i \\leq L_{pt}\\\\ \\text{Randomly Initialized},& \\text{if } i > L_{pt}.\n\\end{cases}$\nThe calculations for upN, dwN, st(i), and ed(i) are nearly the same as those in scaling the Processor.\nThe only difference is to replace m\u2217 with L* . Here, $GU^{i}$ denotes the Processor at the i-th layer\nof the GUnet. Prior to the alignment between GUnets, the Processor should be aligned up using the\nfunction $g_1$ to ensure consistency."}, {"title": "HOW TO CALCULATE RECEPTIVE FIELD SIZE", "content": "The receptive field size is defined as the maximum distance from which the central node can ag-\ngregate information from other nodes. Let the receptive field in the i-th stage be denoted by $r_i$,\nthe pooling ratio by $p_i$, and the number of message passing steps in the GUnet's Processors by\n$m_{GU}$. Due to the presence of a Processor at the bottom of the GUnet, we have $r_1 = m_{GU}$. Given\n$r_i$, the receptive field for the (i - 1)-th stage can be calculated as $r_{i-1} = (r_i + 1) \\cdot p_i - 1$. By\napplying this recursively, the receptive field of the central node in the first stage is determined as\n$r_0 = (m_{GU}+1) \\cdot (\\prod_{i=1}^{L-1} p_i + 1) -2$. Prior to reaching the first stage of the GUnet, the graph\nhas already undergone $m_{Enc}$ steps of information aggregation through the Processor in the Encoder.\nTherefore, the overall receptive field size is $r= m_{Enc} + (m_{GU}+1) \\cdot (\\prod_{i=1}^{L-1} p_i + 1)-2$."}, {"title": "MORE INFORMATION ABOUT HETEROGENEOUS GRAPH", "content": "As described in Section 3.2, each node and edge type has a distinct feature matrix. Specifically,\nthe feature at time t is constructed as follows: 1) for $v_i \\in V^M$, the feature is given by $\\eta_i||(x_i-\n\\bar{x})||\\\nlambda_i and $\\mu_i$ are mechanical properties of the material, $x$ denotes the\nworld coordinates of node i at time t, and $\\bar{x}$ refers to the relative world position between nodes i\nand j at time t. The operator $||$ denotes concatenation, while $||\\cdot ||$ refers to the $L_2$ norm.\nFollowing the approach in previous work Pfaff et al. (2021), we construct edges between the plate\nand the ball in the Deforming Plate and Deformable Plate datasets based on the distance between\nendpoints. Specifically, the distances used for ABCD, Deforming Plate, and Deformable Plate are\n0.0003, 0.003, and 0.05, respectively. Unlike MGN, which connects mesh nodes directly, we estab-\nlish edges between element nodes.\nPrevious work transforms the mesh data from the Deforming Plate and Deformable Plate datasets\ninto homogeneous graphs, where mesh vertices are represented as graph nodes. As a result, these\ndatasets only capture the physical information of the mesh vertices and lack material properties. To\naddress these limitations, we 1) use the average position of the mesh nodes to represent the position\nof the corresponding element node, and 2) set the material properties $\\lambda$ and $\\mu$ to zero."}, {"title": "EXPERIMENT DETAILS", "content": "MODEL CONFIGURATION"}, {"title": "LOSS", "content": "The task-related objective across all datasets is unified as the mean squared error (MSE) loss of the\nnormalized delta displacement between nodes over two steps. This can be expressed as:\n$L_{task} = \\frac{1}{|V|} \\sum_{v \\in V} ||\\tilde{x}^{pred}_v - \\tilde{x}^{GT}_v ||^2$,\nwhere $\\tilde{x}^{pred}$ and $\\tilde{x}^{GT}$ represent the normalized predicted and ground truth displacements of node\nv over two steps, respectively."}, {"title": "ADDITIONAL EXPERIMENTAL RESULTS", "content": "We present the experimental results of MGN and SGUNET on the Deformable Plate and Deforming\nPlate datasets in Table 3 and Table 4, respectively. These results are obtained by loading the check-\npoint from the best-performing step on the validation set, followed by inference on the correspond-\ning test datasets. To facilitate comparison, the best result for each training data size is highlighted in\nbold, while the second-best result is underlined."}]}