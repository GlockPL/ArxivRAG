{"title": "Non-Linear Outlier Synthesis for Out-of-Distribution Detection", "authors": ["Lars Doorenbos", "Raphael Sznitman", "Pablo M\u00e1rquez-Neila"], "abstract": "The reliability of supervised classifiers is severely hampered by their limitations in dealing with unexpected inputs, leading to great interest in out-of-distribution (OOD) detection. Recently, OOD detectors trained on synthetic outliers, especially those generated by large diffusion models, have shown promising results in defining robust OOD decision boundaries. Building on this progress, we present NCIS, which enhances the quality of synthetic outliers by operating directly in the diffusion's model embedding space rather than combining disjoint models as in previous work and by modeling class-conditional manifolds with a conditional volume-preserving network for more expressive characterization of the training distribution. We demonstrate that these improvements yield new state-of-the-art OOD detection results on standard ImageNet100 and CIFAR100 benchmarks and provide insights into the importance of data pre-processing and other key design choices. We make our code available at https://github.com/LarsDoorenbos/NCIS.", "sections": [{"title": "1. Introduction", "content": "Modern deep learning classifiers can classify unseen images into thousands of classes when trained on sufficiently broad datasets. However, unexpected samples from unseen classes will also be confidently assigned to one of the training classes [17]. In most cases, model outputs do not provide information about the reliability of a prediction, leading to silent failures that undermine the trustworthiness of these systems. This has led to significant research on detecting and filtering out these unexpected samples, a subject area known as out-of-distribution (OOD) detection. Specifically, OOD detection aims to enhance the reliability of downstream systems by identifying and removing samples that fall outside the known training distribution.\nTo identify samples that do not belong to the training distribution, OOD detectors seek to learn a boundary that separates in-distribution (ID) samples from OOD samples."}, {"title": "2. Related Work", "content": "Many works on supervised OOD detection, including most early ones, base their scoring function on the post-hoc processing of the classifier. These can, for instance, be based directly on the logits [17, 20] or processed versions thereof [29-31], the features learned by the model [24, 27, 36, 38, 45], or the gradients of the classifier [3, 23]. Other approaches adapt the classifier training process with OOD detection in mind. This can be done by modifying the loss function, such as by learning to estimate the confidence in a given prediction and rejecting samples when the confidence is low [7, 21, 26], training with an energy-based loss [30], or by adding auxiliary self-supervised objectives [2, 51].\nMore recently, a popular trend is to use large auxiliary datasets as fake OOD samples during training, a technique known as Outlier Exposure (OE) [18]. The rationale behind this approach is that by exposing the model to a diverse set of general samples such as from ImageNet when dealing with natural images - it can better learn to recognize what it does not know. While OE has been successfully applied to increase the performance of many OOD detectors (e.g., [13, 18, 34, 38]), its usefulness is limited when the OE distribution is far from the OOD distribution [35], and, for many domains, obtaining a relevant large and diverse dataset to use as pseudo-OOD samples is infeasible.\nAs such, current approaches rely only on in-distribution data to build their detectors. The state-of-the-art approaches opt to synthesize outliers, which are used to regularize the classification model during training to improve its OOD detection. VOS [11] and NPOS [47] do so in the feature space, while more recent methods [4, 12] generate outliers in pixel space and show its superior performance. Our approach also generates outliers in pixel space, allowing for interpretability, but we build upon previous work by aligning the embeddings and modeling non-linearities, allowing for a significant performance improvement. Similar ideas can also be found in anomaly segmentation, where OOD patches are pasted into images and should be correctly identified [28, 40, 46].\nIn contrast, the unsupervised OOD detection literature, where no class labels are available, has many different methods typically based on generative models [32, 39, 42], self-supervised learning [1, 19, 41], or pre-trained models [9, 35, 54]. However, their cross-domain compatibility is rarely explored. Relevant to the present work is the concept of data invariants [9], which characterizes what makes a sample in-distribution without labels, and follow-up work on learning non-linear invariants [10], where a network was developed that can learn non-linear relations that collectively describe a training dataset. We are the first to bring this concept to supervised OOD detection and introduce appropriate modifications to adapt these methods to this new context."}, {"title": "3. Method", "content": "OOD detection aims to determine whether a given test sample originates from the same distribution as the training data. Samples drawn from the training distribution are considered in-distribution (ID), while those that deviate are considered out-of-distribution (OOD). OOD detection can be formulated as finding a scoring function $s : X \\rightarrow \\mathbb{R}$ that assigns a score of in-distributionness $s(x)$ to each input x. In the context of supervised OOD detection, where the downstream task involves a classifier trained on a labeled dataset, the OOD detection is typically integrated into the classifier by introducing a training regularization term that encourages higher free energy to ID samples and lower free energy to OOD samples, effectively using the free energy as the OOD score function. However, to achieve this energy separation, the regularization term requires ID samples, available in the training data, as well as OOD samples, which must be artificially generated. Our method aims to produce high-quality OOD images that, when used by the regularization term at training time, boost the robustness of the classifier to OOD samples. The following sections describe the components of our method and how they are combined."}, {"title": "3.1. Embedding images in the diffusion conditioning space", "content": "We embed the training images directly within the native conditioning space of Stable Diffusion, which we call the diffusion conditioning space or simply diffusion space. For each training image-label pair $(x, y)$, we derive an embedding e by minimizing the standard noise-prediction loss used in diffusion models with respect to the condition vector e,\n$\\arg \\min_{e} \\mathbb{E}_{t,\\epsilon \\sim \\mathcal{N}(0,I)} ||\\epsilon - \\epsilon_{\\theta}(x_t, t, e)||^2 + R(e, e_y),$\nwhere $x_t$ is the noisy version of x with noise $\\epsilon$ and $e_y$ is the Stable Diffusion token embedding for the label y. The regularization term R encourages e to remain close to the token embedding for the label y. In practice, we implement this regularization term by initializing e to ey and minimizing only the first term in Eq. (1) over a limited number of iterations (set to 3 in our experiments). The process is summarized in Alg. 1. We apply this embedding process across the training set to obtain a collection of diffusion embeddings $\\{e_i\\}_{i=1}^N$.\nFormally, the diffusion embedding e of an image x is a maximum-a-posteriori estimate that maximizes the likelihood of Stable Diffusion generating the same image x, with the regularization term acting as the prior. Therefore, the set of training diffusion embeddings $\\{e_i\\}_{i=1}^N$ forms a non-parametric distribution capturing the regions in the diffusion conditioning space where Stable Diffusion is most likely to produce in-distribution (ID) samples. The optimal OOD samples lie in the boundaries of these regions. In the following sections, we describe how to represent these regions using non-linear parametric distributions for easy sampling along the region boundaries."}, {"title": "3.2. Fitting class-wise non-linear manifolds to ID data", "content": "As introduced in [9, 10], the manifolds where the in-distribution (ID) data lies can be effectively modeled by identifying functions, or invariants, that remain approximately constant across the ID samples. These invariants capture essential properties of the ID data, remaining stable for ID samples but diverging for OOD samples. In particular, the non-linear invariants (NL-Invs) introduced in [10] find ID data invariants g within the latent space by solving\n$\\min_g ||g(e_i)||^2$,\ns.t. $\\det(J_g(e_i) \\cdot J_g^T(e_i)) \\neq 0 \\forall i$,\nwhere the constraint ensures that the Jacobian is full-rank. This full-rank condition is achieved by design through a volume preserving network (VPN), constructed as a sequence of bijective layers (interleaved orthogonal and coupling layers) with unimodular Jacobians. During training, the VPN minimizes only the primary term in Eq. (2), and its volume-preserving structure prevents the network from collapsing to a trivial (near-)constant projection and artificially minimizing Eq. (2).\nWe extend the original formulation of NL-Invs to a supervised OOD detection framework, allowing the model to learn class-conditional manifolds within the space of the diffusion embeddings. To do so, we introduce a conditional volume-preserving network (cVPN), which implements a function $f : \\mathbb{R}^D \\times Y \\leftrightarrow \\mathbb{R}^D$ that is bijective with respect to its first argument and conditioned on the second argument representing the class. The first $K < D$ output dimensions of f correspond to the invariants, $g = f_{1:K}$, while the remaining dimensions model the variability within the ID data. Fitting the cVPN is done by optimizing a problem analog to Eqs. (2) and (3),\n$\\min_g \\sum_i ||g(e_i, y_i)||^2$,\ns.t. $\\det(J_g(e_i, y_i) \\cdot J_g^T(e_i, y_i)) \\neq 0 \\forall i$.\nThe trained cVPN thus maps elements from the diffusion space to an invariant space, ensuring that $f_k (e_i, y) \\approx$"}, {"title": "3.3. Probability distribution of ID samples", "content": "We leverage the bijective nature of the CVPN network to fit non-linear parametric distributions to the ID diffusion embeddings. Specifically, we map the diffusion embeddings to the invariant space evaluating $v_i = f(e_i, y_i)$ for each embedding $e_i$ and its corresponding label $y_i$. This process yields a collection of invariant-space vectors $\\{v_i\\}_{i=1}^N$. We then fit class-conditional Gaussian distributions to these invariant-space vectors for each class y,\n$p_v(v_i | y) \\sim \\mathcal{N}(v_i; \\mu_y, \\Sigma_y + \\lambda I)$,\n$\\mu_y = \\frac{1}{N_y} \\sum_{y_i = y} v_i$,\n$\\Sigma_y = \\frac{1}{N_y} \\sum_{y_i = y} (v_i - \\mu_y) (v_i - \\mu_y)^T$,\nwhere the regularization factor $\\lambda$ applied to the covariance matrix serves two primary purposes. First, it prevents numerical issues that might arise from the invariant dimensions approaching near-zero values. Second, it enables control over the degree of out-of-distributionness of the generated outliers. By setting $\\lambda$ to be small relative to the variant dimensions but large relative to the invariant dimensions, higher values of $\\lambda$ yield outliers with more extreme values in the invariant dimensions, as illustrated in Fig. 4. We ablate the effect of $\\lambda$ in Sec. 5.\nThe class-conditional Gaussian distributions defined in the invariant space induce non-linear class-conditional probability density functions in the diffusion space,\n$p_e(e | y) = p_v(f (e, y) | y) \\cdot |J(e, y)|$,\nwhere the determinant of the Jacobian is 1 by design, resulting in the simplified expression $p_e(e | y) = p_v(f(e, y) | y)$."}, {"title": "3.4. OOD sample generation", "content": "Generating an OOD image for a given class y follows naturally from the properties of the distributions established above. First, we apply rejection sampling in the invariant space to obtain an outlier $v'$ from the low-likelihood regions of the Gaussian distribution $p_v(v' | y)$. Then, we map this outlier back to the diffusion space using the inverse of the cVPN f, yielding an embedding $e' = f^{-1}(v'; y)$. Finally, we condition the Stable Diffusion model on prompts of the form \u201cA high-quality image of a $ \\langle e' \\rangle$\u201d to generate an OOD image x'. The entire process is denoted as $x' \\sim P_{out}$."}, {"title": "3.5. Classifier regularization with synthetic OOD samples", "content": "Synthetic OOD samples, together with real ID samples from the training data, are used to regularize the classifier, enhancing its ability to distinguish ID from OOD inputs as proposed in [11, 12, 47]. This approach combines the standard cross-entropy loss $\\mathcal{L}_{CE}$ with an additional regularization term, $\\mathcal{L}_{ood}$, yielding\n$\\mathcal{L} = \\mathcal{L}_{CE} + \\beta \\cdot \\mathcal{L}_{ood}$,\nwhere the hyperparameter $\\beta$ controls the influence of the regularization. The regularization term $\\mathcal{L}_{ood}$ is designed to encourage distinct classifier energy levels for ID and OOD samples,\n$\\mathcal{L}_{ood} = \\mathbb{E}_{x \\sim P_{out}} \\Big[ - \\log \\frac{1}{1 + \\exp( E_{f_{\\theta}}(x))}\\Big] + \\mathbb{E}_{x \\sim P_{in}} \\Big[ - \\log \\frac{\\exp( E_{f_{\\theta}}(x))}{1 + \\exp(E_{f_{\\theta}}(x))}\\Big]$."}, {"title": "4. Experiments", "content": "Following previous works [11, 12], we conduct experiments on two benchmarks:\nCIFAR-100 [25] as ID dataset with SVHN [33], Places365 [57], LSUN [56], iSun [55], and Textures [5] as OOD datasets;\nImageNet-100 [6] as the ID dataset with iNaturalist [49], Places [57], Sun [53], and Textures [5] as OOD.\nSee the appendix for more details. We report the false positive rate at 95% true positive rate (FPR95) and the area under the receiver operating characteristic curve (AUC) for the task of OOD detection, with the positive class being ID. We also report the accuracy (Acc) of the classifier on the downstream classification task.\nWe follow the training protocol described in [12] to isolate the effects of our outlier synthesis approach from other factors on the OOD detection task. We train a ResNet-34 with stochastic gradient descent, using a learning rate of $10^{-1}$ for CIFAR100 and $10^{-3}$ for ImageNet100, decaying with a cosine annealing schedule, momentum of 0.9, weight decay of $5 \\cdot 10^{-4}$, and a batch size of 160. We also use Stable Diffusion v1.4, using DDIM sampling with 50 steps, to generate the synthetic outliers and set $ \\beta $ to 1.0.\nThe classifier is trained for 20 epochs on ImageNet-100 and 250 epochs on CIFAR100. Training embeddings are obtained by optimizing Eq. (1) for three iterations with a batch size of 32, ensuring sufficient exposure to different DDIM steps. We set the number of invariants K to the average largest number of principal components that jointly account for less than p% of the variance per class [10]. We set p = 2 and a regularization strength of $ \\lambda = 10^{-5}$ in our experiments, and then we analyze the impact of different values of these hyperparameters in the ablation study.\nFollowing [12], we compare NCIS against a suite of strong baselines: MSP [17], ODIN [29], Mahalanobis [27], Energy [30], G-ODIN [21], kNN [45], ViM [50], React [44], DICE [43], VOS [11], NPOS [47], and Dream-OOD [12]. All methods use only in-distribution data with auxiliary outlier datasets for a fair comparison. As we use the same code-base and training settings from [12], we report baseline numbers from their experiments."}, {"title": "5. Discussion", "content": "We find that NCIS method reaches a new state-of-the-art (Tab. 1 and Tab. 2), surpassing the best FPR95 by 29.47 and 4.87 on CIFAR100 and ImageNet100, respectively. NCIS achieves the best performance on six out of the nine experiments, placing second in the remaining three, thereby outperforming all traditional, non-synthesis-based methods.\nWe also improve upon all other outlier synthesis methods, whether the synthesis occurs in feature or image space. NCIS surpasses the feature-space methods VOS and NPOS by 63.14 and 35.84 on CIFAR100, respectively. The improvement over the other pixel-space method, Dream-OOD, is particularly striking, demonstrating that the performance gains can be attributed to the quality of the generated outliers, as training hyperparameters were kept unchanged. We provide qualitative examples and an in-depth ablation study in the next sections to visualize the faithfulness of our outliers and analyze what drives these gains in performance."}, {"title": "5.1. Qualitative examples", "content": "Fig. 5 shows qualitative examples of outliers generated by our method along with images generated by Dream-OOD, taken directly from the official repository\u00b9. For CIFAR100, these images are provided in 32x32, explaining the lower resolution. The Dream-OOD images bear little resemblance to their supposed class. In contrast, ours are closer to the original meaning but still clearly show outlying attributes, such as a leopard-print boot instead of a leopard or a green clay hamster. Our near-OOD samples provide a better signal for OOD detection."}, {"title": "5.2. Ablation studies", "content": "We ablated the impact of three specific components in NCIS on CIFAR-100 to assess their contributions:\nEmbedding type. We compare our diffusion space embeddings (Sec. 3.1) against Dream-OOD's embeddings."}, {"title": "6. Conclusion", "content": "This work presents NCIS, a novel method for generating outliers to enhance OOD detection. By operating in the embedding space of Stable Diffusion and modeling complex distributions within the training data through a conditional volume-preserving network (cVPN), NCIS improves upon prior methods to achieve state-of-the-art results on two widely used OOD benchmarks. Through comprehensive ablation studies, we assess the importance of each component in our approach. Our findings also highlight that OOD detectors are easily misled by low-level image statistics rather than image semantics, underscoring the need for careful treatment of such features in future designs. Overall, we show that outlier synthesis effectively boosts OOD detectors without needing labor-intensive collection and curation of real OOD samples.\nA current limitation of NCIS is its reliance on the frozen image decoder of Stable Diffusion, which constrains its ability to generate realistic outliers for domains like medical imaging. Future work will explore the benefits of using domain-specific diffusion models for outlier synthesis."}, {"title": "7. Dataset Details", "content": "We follow the exact experimental protocol of [12]. The ID datasets are CIFAR-100 and ImageNet-100, which we briefly describe below:\nCIFAR-100 [25] contains 50'000 training images and 10'000 testing images belonging to 100 classes.\nImageNet-100 is a subset of the full ImageNet [6] dataset. We take the 100 classes sampled by [12] for a total of 129'860 training samples and 5'000 test samples. These classes are: n01498041, n01514859, n01582220, n01608432,\nn01616318, n01687978, n01776313, n01806567, n01833805, n01882714,\nn01910747, n01944390, n01985128, n02007558, n02071294, n02085620,\nn02114855, n02123045, n02128385, n02129165, n02129604, n02165456,\nn02190166, n02219486, n02226429, n02279972, n02317335, n02326432,\nn02342885, n02363005, n02391049, n02395406, n02403003, n02422699,\nn02442845, n02444819, n02480855, n02510455, n02640242, n02672831,\nn02687172, n02701002, n02730930, n02769748, n02782093, n02787622,\nn02793495, n02799071, n02802426, n02814860, n02840245, n02906734,\nn02948072, n02980441, n02999410, n03014705, n03028079, n03032252,\nn03125729, n03160309, n03179701, n03220513, n03249569, n03291819,\nn03384352, n03388043, n03450230, n03481172, n03594734, n03594945,\nn03627232, n03642806, n03649909, n03661043, n03676483, n03724870,\nn03733281, n03759954, n03761084, n03773504, n03804744, n03916031,\nn03938244, n04004767, n04026417, n04090263, n04133789, n04153751,\nn04296562, n04330267, n04371774, n04404412, n04465501, n04485082,\nn04507155, n04536866, n04579432, n04606251, n07714990, n07745940.\nFor CIFAR-100, we use the test sets of five different datasets as OOD:\nSVHN [33] containing 10'000 images of house numbers.\nPlaces365 [57] is a dataset of large scenes, where we use the 10'000 random images sampled and provided by [45, 47].\nLsun [56] is a large-scale dataset of scenes and objects. We use the subset of 10'000 images provided by [45, 47].\niSun [55] contains images of natural scenes, where we use the subset of 10'000 images provided by [45, 47].\nTextures [5] has 5'640 images of patterns and textures.\nFor ImageNet-100, we use four datasets where the classes of the test sets do not overlap with the full Imagenet, as provided by [22]:\niNaturalist [49] has images of plants and animals. We use a 10'000 image subset of 110 plant classes not present in ImageNet [12].\nSUN [53] contains images of natural scenes, where we use a 10'000 image subset of 50 natural objects not present in Imagenet [12].\nPlaces [57] is a dataset of large scenes, where we use 10'000 images from 50 categories that are not present in Imagenet [12].\nTextures [5] has 5'640 images of patterns and textures."}]}