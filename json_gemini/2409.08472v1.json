{"title": "An Intent Modeling and Inference Framework for Autonomous and Remotely Piloted Aerial Systems", "authors": ["Kesav Kaza", "Varun Mehta", "Hamid Azad", "Miodrag Bolic", "Iraj Mantegh"], "abstract": "An intent modeling and inference framework is presented to assist the defence planning for protecting a geo-fence against unauthorized flights. First, a novel mathematical definition for the intent of an uncrewed aircraft system (UAS) is presented. The concepts of critical waypoints and critical waypoint patterns are introduced and associated with a motion process to fully characterize an intent. This modeling framework consists of representations of UAS mission planner, used to plan the aircraft's motion sequence, as well as a defense planner, defined to protect geo-fence. It is applicable to autonomous, semi-autonomous, and piloted systems in 2D and 3D environments with obstacles. The framework is illustrated by defining a library of intents for a security application. Detection and tracking of the target are presumed for formulating the intent inference problem. Multiple formulations of the decision maker's objective are discussed as part of a deep-learning based methodology. Further, a multi-modal dynamic model for characterizing the UAS flight is discussed. This is later utilized to extract features using the interacting multiple model (IMM) filter for training the intent classifier. Finally, as part of the simulation study, an attention-based bi-directional long short-term memory (Bi-LSTM) network for intent inference is presented. The simulation experiments illustrate various aspects of the framework including trajectory generation, radar measurement simulation, etc., in 2D and 3D environments.", "sections": [{"title": "I. INTRODUCTION", "content": "Uncrewed Aircraft Systems or Uncrewed Aerial Vehicles (UAVs), also commonly known as drones, have seen rapid adoption across various domains, including agriculture, environmental monitoring, disaster management, and even last-mile delivery services. Their versatility and potential for positive impact are undeniable. However, alongside their beneficial applications, UAVs also pose security challenges and potential risks. The problem of intent recognition, prediction or inference has been widely studied from various perspectives for civilian and military aircraft [1]-[3], ground vehicles [4], [5], and human operators [6]. However, this has been relatively less true for UAVs until recently [7]-[11]. In the following, we provide a discussion of the important aspects of intent inference of aerial systems, including conventional aircraft and UAVs.\nThe literature on intent inference is diverse in terms of intent representation/encoding, problem formulation and solution methodologies. The problem has been formulated in different ways such as classification, state estimation, trajectory prediction, identification and tracking, inverse reinforcement learning, etc. In this paper, we consider an UAV's intent from its flight trajectory and motion pattern perspective, and will closely examine a common use case of securing a geographical area against UAV intrusion.\nBroadly, an aircraft's intent has been represented as trajectory behaviors or waypoint sequences that an aircraft is supposed to navigate. The relative relationship between an aircraft's current measured state and the intended (expected) trajectory behaviors is then used to infer the current intent (see [12], [14]). However, in the literature, there is considerable variation in both the qualitative definitions of intent and their mathematical descriptions, depending on the application context. Some of this variation among the intent representations and the underlying rationale is discussed below. In this work, we aim to present a simple and versatile mathematical model for UAV intent that captures the key aspects of existing intent models related to critical asset protection.\nMuch of the variation among intent representations follows from the need to transform intent from a complex cognitive construct to a low dimensional representation as intent classes. In simple surveillance/security applications, intent is generally inferred from whether a target UAV is aiming to enter or reach a specific destination within an area of interest [7]. In this case it is a binary variable dictating whether to enter or not, and is hidden from the decision maker tasked with the security of the AoI. In more complex applications where the targets have multi-dimensional action spaces, a library of intents is defined. Some security applications require identifying multiple intents such as \u201ckamikaze attack\u201d, \u201csmuggling\u201d, \u201cimage acquisiton\", etc. as in [10] or \"mapping flights\", \"point-to-point flights\", \u201cpackage delivery\u201d, \u201cperimeter flights\u201d as in [9]. This approach is justified by the difference in the mis-classification and also interception costs associated with various intents in security applications (for example surveillance versus attack). Defining an intent library is also applicable to scenarios where there is structure imposed on the aircraft pilot's navigation model by air traffic regulations. In the case of civilian aircraft, the pilot's intent library can be modelled using the flight plan structure and traffic regulation knowledge. These can be further sub-categorized as intents in horizontal plane, vertical plane, speed related, etc. [12], [13]. For crewed commercial civilian airlines, conflict avoidance is synonymous with conforming to air traffic control regulations. In this case, the target's conformance versus deviation from expected behaviour is a useful way of defining intent [15]. Recently, [16] considered expansion, free-movement and contraction as possible intents for drone swarms. Whatever the model, intents are inevitably associated with flight path or motion patterns. Two important ways of\""}, {"title": "II. SYSTEM MODEL", "content": "Let \\(E \\subset \\mathbb{R}^3\\) be the environment which contains geo-fence \\(G\\) that is of interest. The environment also contains \\(B\\), which acts as an obstacle to the flight of aerial systems. So, \\(B, G \\subset E\\).\nSome typical qualitative terms for intents that are commonly related to geographical-site security applications include head-on attack, payload drop, surveillance, criminal, harmless, etc.\nEach intent can be associated with a particular set of motion patterns. Alternatively, each intent can be associated with a distribution of possible intermediate and final destination sequences. Although most planners might agree with the qualitative description of the above terms, they might associate the same terms with slightly different motion patterns as necessary for their particular situation. For example, surveillance motion patterns can differ based on the type of facility, such as a stadium, office building, etc.\nTo shift this discussion to a quantitative format, we mathematically define intent in the following way. To efficiently describe the motion pattern we will use intermediate destinations as latent variables.\nDefinition 1. Intent :- An intent \\(I \\in \\mathcal{I}\\) of aerial system \\(AS\\) is characterized by the entities \\((\\mathcal{E}, G, \\mathcal{N}, \\mathcal{P}_I, \\Omega_I)\\) which are defined as follows.\n* \\(\\mathcal{E} \\subset \\mathbb{R}^3\\) is an environment.\n* \\(G \\subset \\mathcal{E}\\) is a geo-fence inside the environment.\n* \\(\\mathcal{N}\\) is an index set.\n* \\(\\mathcal{P}_I\\) is called the critical waypoint pattern (CWPP) of intent \\(I\\). It is a stochastic process \\(\\{\\mathbf{r}_n, n \\in \\mathcal{N}\\}\\) where \\(\\mathbf{r}_n\\) is a random variable defined on the probability space \\((\\mathcal{E}, \\mathcal{E}_\\sigma, \\mathbb{P})\\). Here, \\(\\mathcal{E}_\\sigma\\) is a Borel \\(\\sigma\\)-algebra of the subsets of \\(\\mathcal{E}\\) and \\(\\mathbb{P}\\) is a probability function.\n* \\(\\Omega_I\\) is called the motion process of \\(I\\). It is a dynamical system defined on the kinematic state space of \\(AS\\), and is described by a discrete time difference equation \\(\\mathbf{s}(k + 1) = \\Phi_I(\\mathbf{s}(k))\\). The state space is \\(\\mathcal{E} \\times \\mathcal{C}\\mathcal{S}\\) where \\(\\mathcal{C}\\mathcal{S}\\) is the configuration space of \\(AS\\) specifying the range of speed, acceleration, turn rate for each degree of freedom. We have \\(\\mathbf{s}(k) := (\\mathbf{\\hat{r}}(k), \\mathbf{\\kappa}(k)), k \\geq 0\\) with \\(\\mathbf{\\hat{r}}(k) \\in \\mathcal{E}, \\mathbf{\\kappa}(k) \\in \\mathcal{C}\\mathcal{S}\\).\nHere, \\(\\mathcal{I}\\) is the library of intents defined with reference to environment \\(\\mathcal{E}\\) and geo-fence \\(G\\). The CWPP describes the pattern of critical waypoints (CWPs) which are important waypoints essential for carrying out the intent. The motion process describes the kinematic motion of \\(AS\\) in the environment. Intents are well-defined if the CWPP and the motion process are related in the following way. There exist \\(k_n > 0\\) for each \\(n \\in \\mathcal{N}\\) such that \\(\\mathbb{P}(\\| \\mathbf{r}_n - \\mathbf{\\hat{r}}(k_n) \\|_2 < \\epsilon) > 1 - \\delta_m\\), where \\(\\epsilon, \\delta_m > 0\\) are arbitrarily small, predefined constants. This means that if critical waypoint sequence is specified, the motion process can generate a trajectory that takes \\(AS\\) into the \\(\\epsilon\\)-neighbourhood of those critical waypoints with high"}, {"title": "III. KINEMATIC MOTION MODEL", "content": "The kinematic state vector \\(\\mathbf{s}\\) of the agent at time \\(t\\) consists of the position, velocity and acceleration variables.\n\\begin{equation}\\mathbf{s}(t) = [x(t), v_x(t), a_x(t), y(t), v_y(t), a_y(t), z(t), v_z(t), a_z(t)]^T\\end{equation}\nAs the defence planner has no access to the agent's exact motion model, it assumes that the agent can be in a finite set of flight motion models or modes, whose dynamic models are described below. The following modes correspond to fixed wing UAVs, but, other modes can be defined as required by planner. The dynamical models of these modes are utilized by the planner for feature extraction. The trajectory information is passed into an IMM filter along with the dynamical models of the modes. This filter is designed to tracking highly maneuverable objects using multiple motion models. To illustrate the structure of flight modes we discuss the modes of a fixed wing UAV.\nThe basic flight modes include the constant velocity (CV) and constant acceleration (CA) modes. The horizontal motion with minimum vertical maneuvers can be represented by the Horizontal Coordinated Turn (HCT) model. If there are maneuvers in 3D space, the 3D Coordinated Turn (3DCT) model can be used instead. The set of modes is \\(\\mathcal{M} = \\{\\text{CV}, \\text{CA}, \\text{HCT}, \\text{3DCT}\\} \\). We describe the dynamic model for each mode in the following.\n\\begin{equation}\\mathbf{s}(t_k) = F_m \\mathbf{s}(t_{k-1}) + \\mathbf{w}(t_k), \\quad m \\in \\{\\text{CV}, \\text{CA}\\} .\\end{equation}\n\\begin{equation}\\mathbf{s}(t_k) = F_m [\\mathbf{s}(t_{k-1}) + \\mathbf{w}'(t_k), \\quad m \\in \\{\\text{HCT}, \\text{3DCT}\\} .\\end{equation}\n\\begin{equation}A_{\\text{CV}} = \\begin{bmatrix} 1 & T & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad \\mathbf{w}(t_k) = \\begin{bmatrix} a_{\\text{CV}} \\\\ a_{\\text{CV}} \\\\ a_{\\text{CV}} \\end{bmatrix}\\end{equation}\n\\begin{equation}A_{\\text{CA}} = \\begin{bmatrix} 1 & T & \\frac{T^2}{2} \\\\ 0 & 1 & T \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad \\mathbf{w}(t_k) = \\begin{bmatrix} a_{\\text{CA}} \\\\ a_{\\text{CA}} \\\\ a_{\\text{CA}} \\end{bmatrix}\\end{equation}\n\\begin{equation}A_{\\text{HCT}}(\\omega) = \\begin{bmatrix} \\cos(\\omega T) & -\\sin(\\omega T) & 0 \\\\ \\omega\\sin(\\omega T) & \\cos(\\omega T) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\end{equation}\n\\begin{equation}F_{\\text{HCT}}(\\omega) = \\begin{bmatrix} \\cos(\\omega T) & \\frac{1-\\cos(\\omega T)}{\\omega} & 0 \\\\ -\\omega \\sin(\\omega T) & \\cos(\\omega T) & 0 \\\\ 0 & 0 & A_{\\text{CV}} \\end{bmatrix}\\end{equation}\n\\begin{equation}A_{\\text{3DCT}}(\\Omega) = \\begin{bmatrix} \\frac{\\sin(\\Omega T)}{\\Omega} & 1 & \\frac{1-\\cos(\\Omega T)}{\\Omega^2} \\\\ 0 & \\cos(\\Omega T) & \\frac{\\sin(\\Omega T)}{\\Omega} \\\\ 0 & -\\sin(\\Omega T) & \\cos(\\Omega T) \\end{bmatrix}\\end{equation}\n\\begin{equation}F_{\\text{3DCT}}(\\Omega) = \\begin{bmatrix} A_{\\text{3DCT}}(\\Omega) & 0 & 0 \\\\ 0 & A_{\\text{3DCT}}(\\Omega) & 0 \\\\ 0 & 0 & A_{\\text{3DCT}}(\\Omega) \\end{bmatrix}\\end{equation}\nThe state sequence depends on the sequence of modes which in turn depend on the destination. Given state \\(\\mathbf{s}(t)\\) and current mode \\(m(t)\\) the next state is dictated by equations (2) and (3). The sequence of modes themselves depend on the source and destination, and are decided by a motion planning algorithm."}, {"title": "IV. REPRESENTATION OF OBJECTIVES", "content": "The overall objective of protecting the geo-fence can be described mathematically in multiple ways, depending on the protection requirements and the assumptions about the motion patterns for various intents. Different ways of formulating the intent inference problem are given part of the framework. The decision maker tasked with protecting the geo-fence can choose from these formulations. In the following we discuss different ways posing the problem as a cost minimization problem and also present loss functions that can be used for supervised training of intent classifiers.\n1) Intent inference as multi-class classification problem: The objective here is to minimize the expected mis-classification probability. For supervised training of a neural network for multi-class classification a commonly used loss function is the categorical cross entropy function. For a single sample with true label \\(\\mathbf{y} = [1_{\\ell = i}]_{\\ell \\in \\mathcal{I}}\\) and predicted label (probability vector) \\(\\mathbf{\\hat{y}} \\in [0, 1]^M\\) the loss is as follows.\n\\begin{equation}L_{\\text{CCE}} (\\Gamma, \\mathbf{y}, \\mathbf{\\hat{y}}) = - \\sum_{\\ell \\in \\mathcal{I}} y_{\\ell} \\log \\hat{y}_{\\ell}\\end{equation}\n2) Multi-class classification with class imbalance and asymmetric error costs: In practice the costs associated with various errors are not equal. For example, mistaking a UAV with payload drop intent for criminal-harmless may be considered costlier than mistaking criminal-harmless as criminal-harmful or mistaking criminal-harmless as clueless. Further, there might be class imbalance owing to relative scarcity of data for certain intents. The objective here is to minimize total cost of mis-classification which is given as\n\\begin{equation} \\min \\mathbb{E} \\Big[\\sum_{\\ell,\\ell' \\in \\mathcal{I}} c(\\ell, \\ell') \\Pr(\\mathbf{y} \\in \\ell, \\mathbf{\\hat{y}} \\in \\ell') \\Big], \\end{equation}\nwhere \\(c(\\ell, \\ell')\\) is the cost of mistaking intent \\(\\ell\\) for \\(\\ell'\\). In such cases we can use the asymmetric focal loss (AFL) function introduced by Barnes and Henn in [25] in supervised training."}, {"title": "V. SIMULATION EXPERIMENTS", "content": "In the previous sections we presented a generic framework for intent inference and discussed the different parts of the framework through examples. We do not take up an elaborate simulation study that implements all aspects of the framework, and leave it for future work. We focus on intent inference as a multi-class classification problem (other possible objectives have been discussed in Section IV). The major modules involved in the simulation setup are summarized in Fig. 3. We considered 2D and 3D environments for generating the trajectory datasets. Labelled trajectory datasets were generated for different intents using by defining critical regions as described above and summarized in Fig. 3. The number of trajectories in the dataset is given in Table II. The difference in the number of samples for each intent is due to uniform sampling of initial points from differently sized critical waypoint regions. This class imbalance was normalized after feature extraction and the generation of the final dataset. These datasets were used to train an attention based Bi-LSTM network for intent recognition. The dimensions of the 2D and 3D environments are shown in Fig. 5.\nThe architecture utilizes an attention-based Bi-LSTM classifier. This approach takes advantage of Bi-LSTM's ability to capture dependencies in both forward and reverse directions of the time series data, providing a comprehensive understanding of the UAV's trajectory. The integration of the IMM filter with this classifier ensures that the dynamic state changes. For example, consider a UAV that starts circling over the restricted area; the IMM filter updates its motion models to reflect this maneuver, while the Bi-LSTM, with its attention mechanism, focuses on this significant behavioral change, interpreting it as potential surveillance activity. This allows for precise classification of the UAV's intent, leveraging both past maneuvers and anticipating future movements.\nThe neural network model is designed for sequential data with temporal dependencies, leveraging convolutional and LSTM layers wrapped in 'TimeDistributed' to process each time step independently. It begins with a 'TimeDistributed' 1D convolutional layer with 64 filters and a kernel size of 3, applied twice to capture local patterns within each time step. This is followed by a 'TimeDistributed' dropout layer with a 0.5 rate to prevent overfitting, and a 'TimeDistributed' max-pooling layer with a pool size of 2 to reduce dimensionality. The sequence is then flattened using a 'TimeDistributed' flatten layer and fed into an LSTM layer with 20 units, which captures temporal dependencies across the sequence. The output of the LSTM is processed by a dense layer with 100 units and ReLU activation, followed by a final dense layer with 3 units and softmax activation to produce a probability distribution over three classes. The model is compiled with categorical crossentropy loss, the Adam optimizer, and accuracy as the performance metric. The classifier network is summarized in Fig. 4.\nIn this experiment we use non-optimal path finding algorithms to generated the trajectories. Further, we assume that there is a radar inside the geo-fence which detects and tracks targets. Radar measurements are simulated using MATLAB UAV and radar toolboxes. \u201cRadarDataGenerator\u201d parameters include \u201cFieldOfView\u201d = [90,90]\u00b0, \u201cCenterFrequency\u201d = 24.55GHz, \"Bandwidth\" = 45MHz, \u201cReferenceRCS\u201d = 0dBm\u00b2, \u201cReferenceRange\u201d = 2500m,\u201cFalseAlarmRate\u201d = 10-6, \"ElevationResolution\u201d = 1m, \u201cAzimuthResolution\u201d = 1m, \u201cRangeResolution\u201d = 1m. Fig. 6 shows example trajectories of different intents, their radar tracks. Simulated tracks showed a range error around 10 meters in the initial parts of the trajectories; once the tracking filter stabilizes the error falls within 2 meters. Tracking in done using Kalman filter and feature extraction is done using IMM filter with the flight mode models described earlier. Features (directional velocities, accelerations and turn rates) are extracted from radar measurements. These features are used to train the classifier. Three parametric intent scenarios are considered for simulation. The Direct Attack, Harmless and Surveillance have speed ranges 15 - 25, 5 \u2013 12, 5 \u2013 15 m/s, respectively.\""}, {"title": "VI. CONCLUSION", "content": "We presented a novel integrated framework for intent mod-elling and inference which can be applied for both autonomous and piloted aerial systems. We introduced a mathematical defi-nition of intent using the concepts of critical waypoint pattern, critical waypoint regions and critical region ordered sets. An intent is also associated with motion process which describes motion between waypoints. This framework can be utilized for defining intent libraries and building intent inference systems as per requirements, to protect a geo-fence. As future work we would like to conduct an elaborate simulation study that implements the intent inference framework for commercially available drones in realistic 3D environments using both manually defined and algorithmically derived critical regions for various various intents. Algorithms for deriving critical regions and critical waypoint patterns from experimental flight data is also an important direction for future work. Further, we would like to consider taking up the other objectives such as classification under time constraints and effective interception of unauthorized UAVs."}]}