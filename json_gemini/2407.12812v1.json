{"title": "Building Understandable Messaging for Policy and Evidence Review (BUMPER) with AI", "authors": ["Katherine A. Rosenfeld", "Maike Sonnewald", "Sonia J. Jindal", "Kevin A. McCarthy", "Joshua L. Proctor"], "abstract": "We introduce a framework for the use of large language models (LLMs) in Building\nUnderstandable Messaging for Policy and Evidence Review (BUMPER). LLMs are\nproving capable of providing interfaces for understanding and synthesizing large\ndatabases of diverse media. This presents an exciting opportunity to supercharge\nthe translation of scientific evidence into policy and action, thereby improving\nlivelihoods around the world. However, these models also pose challenges related to\naccess, trust-worthiness, and accountability. The BUMPER framework is built atop\na scientific knowledge base (e.g., documentation, code, survey data) by the same\nscientists (e.g., individual contributor, lab, consortium). We focus on a solution that\nbuilds trustworthiness through transparency, scope-limiting, explicit-checks, and\nuncertainty measures. LLMs are rapidly being adopted and consequences are poorly\nunderstood. The framework addresses open questions regarding the reliability of\nLLMs and their use in high-stakes applications. We provide a worked example\nin health policy for a model designed to inform measles control programs. We\nargue that this framework can facilitate accessibility of and confidence in scientific\nevidence for policymakers, drive a focus on policy-relevance and translatability\nfor researchers, and ultimately increase and accelerate the impact of scientific\nknowledge used for policy decisions.", "sections": [{"title": "1 Introduction", "content": "A core motivating factor, and source of funding, for many scientific studies is to improve livelihoods\nin our communities, nations, or world. Budgets for research and development have been steadily\ngrowing with the US government alone reaching over 700 billion dollars in 2020 [Anderson et al.,\n2023]. However, to have impact, a scientific result needs to be communicated effectively [Weiss, 1975,\n1979, Gluckman and Wilsdon, 2016, Wilsdon et al., 2014, Elliott et al., 2021]. Today, the way science\nis communicated often results in isolated monoliths of evidence, including papers, proceedings,\npresentations, and datasets, which are detached from the real-world situations and questions that\ncould benefit from their insights. While there are ways for decision makers to request and receive\nadvice from the scientists, they are not straightforward [Gluckman et al., 2021]. We present a\nframework for the use of large language models (LLMs) in Building Understandable Messaging for\nPolicy and Evidence Review (BUMPER). BUMPER utilizes a reactive chat interface to bridge the\ngap between individual scientific studies and their application in, for example, policy. BUMPER\nis not meant to generate new evidence by, e.g., functional search [Romera-Paredes et al., 2024] or\nsynthesis [Zheng et al., 2023]; rather, it is a translational tool for existing evidence. It features a"}, {"title": "2 Framework", "content": "Decision makers have questions, concerns, and pressures. Scientists produce analyses with results,\nassumptions, and limitations. The role of BUMPER is to bridge the two via natural language and a\nwell-defined, purposeful architecture."}, {"title": "3 Synthesizing evidence: six nations rugby championship example", "content": "We use a tutorial from PyMC as a first demonstration and template for interested users (see appendix\nA.1). The tutorial describes a Bayesian hierarchical model to analyze and predict outcomes of a rugby"}, {"title": "4 Towards trustworthiness: a case study for health policy", "content": "LLMs are fast evolving into tools that exhibit many of the human-like characteristics that encourage\ntrust and engagement: memory, speech, and multi-modal capability [ope, b,a]. However, while\nthese models may affect trust, they have not earned it. In their study establishing trustworthiness\nbenchmarks, Sun et al. [Sun et al., 2024] compare measures of trustworthiness to measures of utility.\nWe contend that in high-stakes situations, trustworthiness is essential for utility. If you cannot trust\na tool, how can you rely on it for critical tasks? We will demonstrate how BUMPER designs for\ntrustworthiness by applying our framework to an existing, open-source model that estimates the\nseasonal patterns and outbreak potential for measles [Thakkar et al., 2024b].\nMeasles is a highly contagious disease that has a safe and highly effective vaccine [Moss and Strebel,\n2023]. Currently the World Health Organization (WHO) recommends that every child receive a dose\nof the measles containing vaccine (MCV) as part of a routine childhood vaccination program but\nthere are many places where the fraction of children who receive this vaccine fall far short of WHO\ntargets (95%) [WHO/UNICEF, 2023]. In some places, particularly where measles is a constant threat,\ncountries chose to run time-limited, age-targeted supplementary immunization activities (SIAs), or\nvaccination campaigns. These activities, in conjunction with routine childhood vaccinations, have\nproven to be an essential tool in avoiding large, catastrophic measles outbreaks [WHO, 2016, Thakkar\net al., 2024a].\nPlanning and executing an SIA is challenging and requires coordination at multiple levels of gov-\nernment, attainment of funds from various sources, and management of resources and people.\nGovernment officials are key decision makers. Evidence in the form of monitoring, modelling, and\nand guidelines can help ensure that these campaigns are effective at stopping devastating measles\noutbreaks [Verguet et al., 2015, WHO, 2016]. One important consideration is the timing of, or when,\nan SIA should occur. Timing can be roughly broken down into what year, dictated by the build up\nof susceptible individuals, and what month, driven by the well-known seasonality of transmission.\nPlans are determined by individual countries informed by detailed transmission models [Thakkar\net al., 2019, Zimmermann et al., 2019] or heuristics [Verguet et al., 2015, WHO, 2016]. The analysis\nwe chose for this example uses historical measles cases to estimate country-specific seasonality and\nrelative susceptibility (see 3).\nThe example's body of evidence is composed of executable code and a paper (see table 3in appendix\nA.2). The code is written in python and fast enough to real in real-time. We wrote wrapper\nfunctions around python scripts available on GitHub to generate country-specific estimates of:\n1) low transmission months, 2) high transmission months, 3) months to run SIAs, and 4) relative\nsusceptibility. For questions regarding methodology we create a separate assistant (see Figure 1)\nthat handles the vector-database query. This allows additional prompt engineering and document\ntargeting not otherwise available through the OpenAI API. Figure 3 provides an example comparing\nthe synthesized, textual evidence provided by BUMPER with visual evidence that might be found in\nsupplementary material or a dashboard.\nThe guidelines are listed in appendix A.3. BUMPER uses an LLM to determine whether the\nsynthesized evidence is consistent with this statement of purpose (see Figure 1) and records the token"}, {"title": "5 Discussion", "content": "There exist many methods and tools that can query large, multi-modal, databases [Pietsch et al., 2019,\nLiu, 2022] and they continue to innovate on, for example, extending attention beyond fixed context\nwindows [Dai et al., 2019, Gu et al., 2022, Munkhdalai et al., 2024] and improvements upon the RAG\nschema [Glass et al., 2022, Asai et al., 2023, Yan et al., 2024]. These tools are increasingly capable in\ntheir ability to ingest any type of media, demonstrating both the exciting potential for communicating\ninformation irrespective of medium. There is a rapidly growing body of work applying such tools\nto scientific knowledge extraction and synthesis [Wang et al., 2024, Susnjak et al., 2024]. However,\nthese studies usually emphasize how to build tools that perform across a field of research. This work\npresents the BUMPER framework as a tool to be incorporated into and enhance a single study, with\nthe creators retaining clear ownership, enabling accountability and keeping the scientist \u201cin the loop\".\nWe introduce a framework for facilitating knowledge transfer through the use of LLMs between\nscientists and decision-makers called the Building Understandable Messaging for Policy and Evidence\nReview (BUMPER) framework. BUMPER has several novel features. First, it establishes clear\nownership which enables accountability and a simple method for feedback and improvements.\nSecond, it is limited in it scope due to a limited set of actions (e.g., text search, running code, database\naccess) and post-hoc evaluation. Other various guardrail architectures are well into development, but\none distinctive element of our proposed solution is that it builds the checks around the synthesized\nevidence, rather than around the original prompt or LLM. Additionally, it has the potential to help\nincrease accessibility as a digital product and multi-lingual operation. Lastly, because BUMPER does\nnot rely on fine-tuning [c.f. Zhang et al., 2024] it has the potential to scale: with the development\nof standards and increasing the availability of compute and tools, it would be possible to combing\nmultiple BUMPERs into an engine capable of synthesizing from many independent sources.\nA critical challenge associated with BUMPER, and any tool that tries to use automated evidence\ngeneration, is the potential loss of human to human interaction. Translating science to policy\nwell depends on the context which can often only be understood by establishing and maintaining\nrelationships [Connelly et al., 2021]. Therefore it is critical that these tools, while they may reduce\nsome human-to-human interaction, are not taken to be strict replacements. Instead, there are some\nclear design choices that could potentially increase the quality and availability of relations between\nscientists and decision makers. For example, attributable and interactive tools can foster follow-up\nand engagement [e.g., Dontcheva et al., 2014]."}, {"title": "A Appendix / supplemental material", "content": "A.1 Getting started\nWe implemented BUMPER using python and provide the code so that interested individuals can try\nthis framework. We have captured the workflow to run the experiments and figures for this using\nsnakemake. The environment was maintained using pixi. To install and run:\n1. Install pixi: https://pixi.sh/latest/\n2. Install dependencies: pixi install\n3. Run: pixi run start\nIndividual scripts are found in the scripts/ directory and can be run e.g., pixi run python\nfigure_3.py. An OpenAI API key is required.\nA.2 Example actions\nA.3 Guidelines\nWe provide the guidelines used for our examples:\n1. Rugby example (section 3):"}, {"title": "A.4 Prompt templates for guidelines check", "content": "We used the following prompt templates combining few-shot learning for result consistency.\nWhen evaluating synthesized evidence, E, entire guideline set, $G = (c_0, ..., c_n) \\cup (t_0, ..., t_m)$:\n\u2022 No explanation:\nDoes the statement comply with the rule criteria and topics?\nAnswer \"yes\" or \"no\".\nCriteria:\n- Do not talk about toast\nTopics:\nWhales\nStatement: Belugas are blue.\nAnswer:yes.\nDoes the statement comply with the rule criteria and topics?\nAnswer \"yes\" or \"no\".\n{G}\nStatement: {E}\nAnswer:\n\u2022 With explanation:"}, {"title": "A.5 UMAP example answers with labels", "content": "cluster: Co\n\u2022 (S = 0.99)| For Cameroon, the recommended months for conducting supplementary immu-\nnization activities (SIAs) against measles are July and August. Interestingly, these months\npartly overlap with the low transmission season for measles, which spans March through\nJuly, and do not coincide with the high transmission season that occurs in January, Septem-\nber, October, November, and December. Planning SIAs during the low transmission season\ncan be strategically advantageous for controlling the spread of measles effectively.\n\u2022 (S = 0.99)| Cameroon should plan to conduct Supplementary Immunization Activities\n(SIAs) during the months of July and August. These months also overlap with the low\ntransmission season for measles, which runs from March to July, making it an opportune\ntime to conduct SIAs and prevent outbreaks. Additionally, these months are outside of the\nhigh transmission season, which occurs from January and then again from September to\nDecember.\n\u2022 (S = 0.92)| In Cameroon, Supplementary Immunization Activities (SIAs) are recommended\nto occur in July and August. During these months, measles transmission is in a low season,\nwhich includes March through July, making it an advantageous period for implementing\nSIAs to ensure higher coverage and possibly lower transmission risks. The high transmission\nmonths for measles in Cameroon are January, September, October, November, and December.\nPlanning SIAs during the low transmission season helps in interrupting the transmission of\nmeasles more effectively.\n\u2022 (S = 0.95)| In Cameroon, the recommended months to plan Supplementary Immunization\nActivities (SIAs) for measles are July and August. This coincides with the low transmission\nseason for measles, which occurs during the months of March, April, May, June, and July.\nThe high transmission season spans from January, and September to December. Planning\nSIAs during the low transmission period helps to enhance the impact of vaccinations."}]}