{"title": "Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective", "authors": ["Jingren Liu", "Zhong Ji", "YunLong Yu", "Jiale Cao", "Yanwei Pang", "Jungong Han", "Xuelong Li"], "abstract": "Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown promise in adapting pre-trained models to sequential tasks while mitigating catastrophic forgetting problem. However, understanding the mechanisms that dictate continual performance in this paradigm remains elusive. To tackle this complexity, we undertake a rigorous analysis of PEFT-CL dynamics to derive relevant metrics for continual scenarios using Neural Tangent Kernel (NTK) theory. With the aid of NTK as a mathematical analysis tool, we recast the challenge of test-time forgetting into the quantifiable generalization gaps during training, identifying three key factors that influence these gaps and the performance of PEFT-CL: training sample size, task-level feature orthogonality, and regularization. To address these challenges, we introduce NTK-CL, a novel framework that eliminates task-specific parameter storage while adaptively generating task-relevant features. Aligning with theoretical guidance, NTK-CL triples the feature representation of each sample, theoretically and empirically reducing the magnitude of both task-interplay and task-specific generalization gaps. Grounded in NTK analysis, our approach imposes an adaptive exponential moving average mechanism and constraints on task-level feature orthogonality, maintaining intra-task NTK forms while attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable parameters with appropriate regularization, NTK-CL achieves state-of-the-art performance on established PEFT-CL benchmarks. This work provides a theoretical foundation for understanding and improving PEFT-CL models, offering insights into the interplay between feature representation, task orthogonality, and generalization, contributing to the development of more efficient continual learning systems.", "sections": [{"title": "1 INTRODUCTION", "content": "In practical applications, the relentless evolution of envi-ro ronments underscores the urgency for learning systems that can progressively accumulate knowledge. This has led to the prominence of Continual Learning (CL) [13], [43], [53], [54], [60], [78], [87], a cornerstone task that equips the learning models with the ability to seamlessly assimilate fresh information over time, while mitigating catastrophic forgetting, i.e., a phenomenon that erodes previously acquired knowledge. In recent years, with the proliferation of pre-trained models possessing strong generalization capabilities [6], [63], researchers have discovered that they can empower early exploratory methods [4], [7], [18], [22], [33], [44], [45], [46], [52], [68], [69], [80], [88], [89], [90], [97], [99], enabling CL systems to integrate new knowledge more efficiently. However, full fine-tuning of pre-trained models is computationally intensive and may compromise their original generalization capabilities [27], [50], [94]. Thus, as a promising paradigm, Parameter-Efficient Fine-Tuning for Continual Learning (PEFT-CL) emerges as an alternative, updating only a minimal set of additional parameters while keeping the pre-trained model intact. Specifically, PEFT-CL not only offers a more philosophically sound framework akin to Socratic dialogue [95] but also provides a lightweight training process that avoids generalization deterioration as-sociated with full-scale fine-tuning [35], [76]. In addition, this seamless integration of new and old knowledge aligns with the wisdom expressed by Bernard of Chartres, demonstrating how PEFT-CL builds upon pre-existing knowledge to achieve a more adaptive learner with robust memory capabilities.\nDespite initial successes in mitigating catastrophic forgetting [19], [71], [81], [82], [100], PEFT-CL largely relies on sub-jective human insights and experiential doctrines for network design and enhancement, lacking a rigorous mathematical foundation. This reliance on non-theoretical approaches constrains the potential for a deeper understanding and advancement of the fundamental mechanisms within these learning systems. While Hide-Prompt [77] acknowledges the importance of addressing this issue and offers a loss-based perspective, it falls short of modeling optimization dynamics and pinpointing key factors. Therefore, to address this gap, we adopt the Neural Tangent Kernel (NTK) theory [5], [8], [32] as a robust mathematical tool to delve deeply into the intricacies of PEFT-CL optimization. Through this rigorous analysis, we derive several fundamental theorems and lemmas, including theorem 1, theorem 2, lemma 3, and theorem 4. While initially considered from a CL perspec-tive, these have been generalized to the PEFT-CL scenario, providing profound insights into the key factors essential"}, {"title": "2 RELATED WORKS", "content": "Parameter-Efficient Fine-Tuning has emerged as a pivotal paradigm for optimizing model performance while mitigat-ing computational and memory burdens associated with large-scale model adaptation. Seminal works introduce di-verse methodologies, including Adapter modules [26], Low-Rank Adaptation (LoRA) [27], Prefix Tuning [47], Prompt Tuning [6], and BitFit [96]. These approaches demonstrate the efficacy of selectively fine-tuning components or introducing compact, trainable sub-networks within pre-trained archi-tectures. Subsequent advancements further expand PEFT's scope and capabilities. Jia et al. [34] pioneer efficient prompt tuning techniques for vision transformers, extending PEFT'S applicability to the visual domain. Zhou et al. [102] introduce contextual prompt fine-tuning, enhancing model adaptabil-ity while preserving generalization. Recent comprehensive studies [15], [20], [85], [86] reinforce PEFT's critical role in enhancing model generalization and efficiency. These investi-gations rigorously analyze the theoretical underpinnings and empirical efficacy of various PEFT methodologies, solidifying its status as a transformative paradigm in adaptive learning.\nContinual Learning is a critical field in artificial intelli-gence aimed at developing models that can learn new tasks while preserving knowledge from previous tasks. This field encompasses both task-specific strategies and generalization-based approaches. Task-specific strategies utilize four pri-"}, {"title": "3 PRELIMINARIES", "content": "In the PEFT-CL context, we augment pre-trained models with adaptive sub-networks to manage sequential tasks. Let $f_\\theta$ and $f_\\tau$ denote the initial and target parameter spaces respectively, with $*$ indicating optimized parameters. Given a series of tasks $\\mathcal{D} = {\\mathcal{D}_1, ..., \\mathcal{D}_T}$, where each $\\mathcal{D}_i$ comprises samples $(x, y)$ from $(\\mathcal{X}, \\mathcal{Y})$, we introduce task-specific optimizable sub-network parameters $p_\\tau$. The transformed model is represented as $f^* = (f^*_\\theta \\circ p_1 \\circ \\mathcal{X}_\\tau \\circ \\mathcal{Y}_\\tau)$, with $\\circ$ denoting component integration. This configuration, inspired by L2P [82], features distinct class boundaries without explicit task identification during training, aligning with practical scenarios.\nEmpirical NTK: The NTK elucidates infinite-width neural network training dynamics, mapping the learning trajectory in high-dimensional parameter space [32]. Leveraging NTK's spectral properties enables precise predictions about network generalization, linking architectural choices to extrapolation performance [5]. However, practical NTK calculation faces challenges due to extensive gradient computations across entire datasets. The empirical NTK [32] addresses this, providing a more tractable analytical tool:\n$\\Phi_{p_\\tau}(x_1, x_2) = [J_{p_\\tau}(f_{p_\\tau}(x_1))]^T [J_{p_\\tau}(f_{p_\\tau}(x_2))],$\t{(1)}\nwhere $J_{p_\\tau}(f_{p_\\tau}(x))$ denotes the Jacobian matrix of network $f_\\tau$ with parameters optimized for task T, evaluated at input $x$. This function maps D-dimensional inputs to O-dimensional features, with $J_{p_\\tau}(f_{p_\\tau}(x)) \\in \\mathbb{R}^{O \\times P}$ and $\\Phi_{p_\\tau}(x_1, x_2) \\in \\mathbb{R}^{O \\times O}$.\nNeural Tangent Kernel Regime: As layer widths ap-proach infinity, the NTK characterizes the asymptotic be-havior of neural networks, yielding a time-invariant NTK throughout training [32], [42]. This induces a linear dynam-ical system in function space, governed by the following evolution equation for the output $f(x, \\theta(t))$ at input $x$:\n$\\frac{\\partial f(x, \\theta(t))}{\\partial t} = -\\Phi(x, \\mathcal{X})\\nabla f \\mathcal{L}(f(\\mathcal{X}, \\theta(t)), \\mathcal{Y})$ \\t{(2)}\nwhere $\\Phi(x, \\mathcal{X})$ denotes the NTK matrix, $\\mathcal{X}$ represents the entire training dataset, $\\mathcal{Y}$ corresponds to labels, and $\\mathcal{L}$ signifies the loss function.\nThis formulation elucidates the network's trajectory towards the global minimum, exhibiting exponential conver-gence under a positive definite NTK [5], [8], [32], [42], [56], [92]. Furthermore, in PEFT-CL, to better adapt it for sequence learning scenarios, we have transformed it in Appendix A as follows:\n$f(x) = f^\\tau(x) + \\sum_{i=1}^{T}\\Phi_i(x, \\mathcal{X}) \\times (\\Phi_i(\\mathcal{X}, \\mathcal{X}) + \\lambda I)^{-1}(\\mathcal{Y}_i - f^{i-1}(\\mathcal{X})),$ \\t{(3)}\nwhere $\\Phi_i$ represents the locally converged NTK matrix for the $i$-th task.\nRemark: The NTK paradigm is effective across various neural architectures, including ResNets and Transformers [92], [93], with primary variations evident in the configura-tion of the NTK matrix. Ideally, all $\\Phi_i$ matrices would evolve towards a consistent as the model trains [8], [32]."}, {"title": "4 THEORETICAL INSIGHTS", "content": "The prevalent belief in PEFT-CL methods is that mitigating catastrophic forgetting should be evaluated based on accu-racy, specifically by calculating the difference between the optimal accuracy on a previous task during its optimization and the accuracy on that task at the final stage. However, using abstract accuracy metrics is not conducive to precise mathematical quantification, and the accuracy gap during testing cannot effectively intervene in training. To better align with the role of NTK in studying model generalization, we propose shifting the focus from the accuracy gap to the"}, {"title": "5 NTK-CL", "content": "Drawing from the insights in lemma 3, we recognize the substantial impact of increasing task-specific sample size on reducing generalization gaps. Building on this perspective, we propose an advanced PEFT strategy operative at three subnetworks that generate features in distinct spaces. This strategy synergistically leverages features derived from dual"}, {"title": "5.1 Extend Sample Size Through PEFT", "content": "adaptation mechanisms to forge hybrid features, effectively extending the sample size for each sub-task. By adeptly fine-tuning sub-network parameters $p_i$ through an amalgamation of these multifaceted features, our method expands each sample's representational breadth threefold, as elaborated through the sophisticated adaptive interactions in Fig. 2.\nUtilizing the pre-trained ViT architecture, our framework divides B input images, denoted as $x$, into patch tokens of dimensionality D and count N, further augmented with a class token $E_{CLS}$ to establish the initial sequence $I_0 = [E_{CLS}; E_1, E_2, ..., E_N]$. After transformation through the i-th transformer block, the sequence changes to:\n$I_i = [E_{CLS}; E_1^i, E_2^i, \\dots, E_N^i] \\in \\mathbb{R}^{B \\times (N+1) \\times D}$.\\t{(10)}\nPEFT-CL methodologies typically employ a prompt pool or introduce auxiliary parameters while preserving pre-trained weights, modifying $E_1^i, E_2^i, \\dots, E_N^i$ within each transformer block to influence the class token $E_{CLS}$. This generates a novel feature space that adapts to sub-tasks and mitigates catastrophic forgetting. In these methods, the predetermined task prompt pool is traditionally used to derive task-specific embeddings, selecting prompts through cosine similarity [36], [81], [82]. While effective, this paradigm incurs substantial computational overhead when intervening in the self-attention mechanism and constrains the network's capacity for generating diverse, instance-specific adaptive interventions dynamically. To address these limitations, our proposed NTK-CL framework implements a more efficient paradigm utilizing additional trainable parameters to au-tonomously generates instance-specific interventions. These interventions then interact with our proposed feature space post-multi-head self-attention (MSA) module to yield task-specific embeddings. This approach not only maximizes the utilization of pre-trained knowledge but also effectively reduces the computational burden brought by intervening MSA calculations.\nNext, we elucidate the generation processes for subnetwork-1 adaptation features, subnetwork-2 adaptation features, and hybrid adaptation features, which effectively triple the sample size in the feature space and reduce the generalization gaps in PEFT-CL training based on lemma 3.\nCreating Subnetwork-1 Adaptation Features: To pin-point the optimal interventions for enhancing the patch (N + 1) dimensionality within transformer blocks, we deploy a specialized subnetwork-1 adaptation module $G_{S1}$. Tailored to the post-MSA inputs $u_i$, $G_{S1}$ adaptively transforms them into the most suitable prompts $q_i$ for this task, as illustrated in Fig. 2 (right).\n$q_i = G_{S1}(u_i; q_{i-1}) \\in \\mathbb{R}^{B \\times (N+Q+1) \\times D}$,\\t{(12)}\nwhere Q denotes the dimensionality of the prompts.\nDelving into the details, within each transformer block, the prompt generator in $G_{S1}$ (as a fully connected layer) condenses the dimensional knowledge and adds it residually to the prompts generated in the previous transformer block, ensuring the integrity of the optimized information. The generated prompts $q_i$ are then concatenated with the input $u_i$ and subsequently passed into the pre-trained fully connected layers of the transformer block for continued optimization.\n$SAE_i^1 = MLP_2(MLP_1([E_{CLS}; q_i; E_1^i, E_2^i, \\dots, E_N^i]))$, \\t{(13)}\nwhere $SAE_i^1$ represents the subnetwork-1 adaptation embed-dings generated by the i-th transformer block.\nAfter passing through all transformer blocks, we extract the final optimized $SAE_i^1$ to obtain the subnetwork-1 adap-tation features $E_{CLS}^1$, thereby constructing a feature space suited to patch-level knowledge for this task.\nCreating Subnetwork-2 Adaptation Features: To enrich the embedding landscape and foster knowledge acquisition, we integrate the LORA architecture [27] as the subnetwork-2 adaptation module $G_{S2}$. Designed for efficient fine-tuning of pre-trained models by minimizing parameter adjustments, LORA enables the mastering of extensive knowledge in compact, low-rank representations while preserving efficacy during high-dimensional reconstructions. Our implementa-tion bifurcates into $G_{low}$ for low-rank space mapping and $G_{high}$ for reconversion to the high-dimensional space.\nThe input to the adaptation modules post-MSA module is structured as follows:\n$u_i = MSA(I_i) \\in \\mathbb{R}^{B \\times (N+1) \\times D}$. \\t{(11)}"}, {"title": "5.2 Task-Level Feature Constraints", "content": "Informed by insights from theorem 1, our approach un-derscores that effectively reducing generalization gap in-volves the diligent preservation of historical knowledge $\\Phi^\\tau(\\mathcal{X}^\\tau, \\mathcal{X}^\\tau)$ and $\\Phi^k(\\mathcal{X}^k, \\mathcal{X}^k)$ from the perspective of the task T, coupled with a concerted effort to diminish cross-task interactions $\\Phi^k(\\mathcal{X}^\\tau, \\mathcal{X}^k)$, for $k > \\tau$. Given $\\Phi^k(\\mathcal{X}^\\tau, \\mathcal{X}^k) = f_{\\theta^k}(\\mathcal{X}^\\tau) \\cdot f_{\\theta^k}(\\mathcal{X}^k)$, if the difference between $f_{\\theta^k}(\\mathcal{X}^\\tau)$ and $f_{\\theta^k}(\\mathcal{X}^k)$ is maximized, then $\\Phi^k(\\mathcal{X}^\\tau, \\mathcal{X}^k)$ will be minimized. Since $p_k$ in the optimization process of PEFT-CL will only be influenced by $f_{\\theta^k}(\\mathcal{X}^k)$, ensuring orthogonality between $f_{\\theta^k}(\\mathcal{X}^\\tau)$ and $f_{\\theta^k}(\\mathcal{X}^k)$ will make $f_{\\theta^k}(\\mathcal{X}^\\tau)$ extremely small [16]. However, in the practical setting of PEFT-CL, cross-task access to data is strictly prohibited, presenting a substantial challenge in maintaining task-level distinctiveness.\nTherefore, we propose a compromise approach. Within the context of NTK theory, the optimization of infinitely wide neural networks mirrors a Gaussian process [10], [40], yielding a locally constant NTK matrix [12], [32], [42], [91]. Given this, it is reasonable to assume that $\\Phi^\\tau(\\mathcal{X}^\\tau, \\mathcal{X}^k) = \\Phi^0(\\mathcal{X}^\\tau, \\mathcal{X}^k) = \\Phi^1(\\mathcal{X}^\\tau, \\mathcal{X}^k) = \\dots = \\Phi^{\\infty}(\\mathcal{X}^\\tau, \\mathcal{X}^k)$. Moreover, networks pre-trained on extensive datasets emulate the properties of infinitely wide networks [41], [75], [83], aligning with our pre-trained model. Therefore, we relax the original constraint, assuming that the pre-trained model is at this local optimum.\nUnder this framework, $\\Phi^k (\\mathcal{X}^\\tau, \\mathcal{X}^k) \\approx \\Phi^*(\\mathcal{X}^\\tau, \\mathcal{X}^k) = f_{\\theta^*}(\\mathcal{X}^\\tau) \\cdot f_{\\theta^*}(\\mathcal{X}^k)$, suggesting that ensuring orthogonality between $f_{\\theta^*}(\\mathcal{X}^\\tau)$ and $f_{\\theta^*}(\\mathcal{X}^k)$ is feasible to some extent. To practically achieve this, integrating a prototype classifier and imposing orthogonality constraints ensure that embeddings from different tasks remain distinct, thus not violating the constraints under the PEFT-CL scenarios and aligning with the objective to minimize generalization gap.\nKnowledge Retention: Effective replay of past knowl-edge is essential in PEFT-CL utilizing pre-trained models. For instance, [77] employs a distributional strategy that approximates and replays past data distributions for ongoing optimization, while [100] preserves distinct adapter parame-ters for each historical task. These strategies, while boosting knowledge retention, simultaneously escalate optimization and storage requirements, posing challenges to scalability and operational efficiency in scenarios with large datasets or extensive task sequences. To mitigate these issues, we introduce an adaptive Exponential Moving Average (EMA) mechanism tailored for efficient past knowledge preservation, illustrated in Fig. 4.\nTraditional EMA applications often maintain a static base model, incrementally integrating optimized weights to preserve historical data. However, this approach proves suboptimal in PEFT-CL settings due to the substantial disparities in weights across tasks. Directly preserving a large proportion of past weights can detrimentally affect the per-formance on current tasks, while retaining an entire model's weights is excessively redundant. Therefore, we propose two improvements. First, we categorize the adaptation parame-ters responsible for generating embedding into two segments: $p^{pre}_\\tau$ for historical knowledge and $p^{curr}_\\tau$ for current insights. Secondly, we apply the EMA mechanism exclusively to the adaptation modules' parameters, leaving other optimizable"}, {"title": "5.3 Regularization Adjustment", "content": "In accordance with the theoretical constraints delineated in Appendix A, which advocate for the incorporation of ridge regression to ensure a well-conditioned solution, we deploy an L2 regularization [28]. As specified in Eq. 32, the regularization term is structured as $||P_\\tau - P_{\\tau-1}||^2$, targeting the parameter shifts from task $T - 1$ to task $\\tau$. Consequently, we meticulously design our regularization term to mirror this structure and temporarily retain the trainable parameters $p^{pre}_\\tau$ from the preceding task. This targeted regularization is then precisely applied to the parameters of the various modules within our NTK-CL, formulated as follows:\n$\\mathcal{L}_{reg} = ||p^{GS1}_\\tau - p^{GS1}_{T-1}||_2 + ||p^{GS2}_\\tau - p^{GS2}_{T-1}||_2 + ||p^{GH}_\\tau - p^{GH}_{T-1}||,$\t{(28)}\nwhere $G_{S1}$, $G_{S2}$, and $G_{H}$ represent the trainable parameters of the subnetwork-1 adaptation module, the subnetwork-2 adaptation module, and the hybrid adaptation module.\nTraining Optimization: The composite objective for optimizing the training of each task subset within our NTK-CL is rigorously defined as follows:\n$\\mathcal{L} = \\mathcal{L}_{cls} + \\eta\\mathcal{L}_{dis} + \\nu\\mathcal{L}_{orth} + \\lambda\\mathcal{L}_{reg}$,\\t{(29)}\nwhere $\\eta$ and $\\nu$ are hyper-parameters, meticulously calibrated to maximize task-feature dissimilarity and to promote or-thogonality in task-feature representations, respectively. The parameter $\\lambda$ controls the intensity of the regularization, ensuring the model's robustness and generalizability.\nPrototype Classifier: Upon the completion of each task's training, we conduct an averaging operation on the features generated by all classes involved in that task to update the classifier $\\mathcal{C}$ with the most representative features of each class. It is important to note that the features used at this stage are designated as hybrid adaptation features $E^{HAE}_{CLS}$.\n$\\mathcal{S}_i = \\frac{1}{N_i} \\sum_{j=1}^{N_i}E^{HAE}_{CLS_{i,j}}$ \\t{(30)}"}, {"title": "6 CONCLUSION", "content": "In this study, we adopt an NTK perspective to analyze PEFT-CL tasks, elucidating model behavior and generalization gaps in sequential task learning. Our analysis identifies crucial factors affecting PEFT-CL effectiveness, particularly through the dynamics of task interplay and task-specific gen-eralization gaps. We recommend strategies to mitigate these gaps, such as expanding sample sizes, enforcing task-level feature constraints, and refining regularization techniques. These strategies inform architectural and optimization ad-justments aimed at enhancing the generalization capabilities and efficiency of PEFT-CL models across diverse tasks. This research significantly advances the theoretical framework and provides practical guidelines for improving PEFT-CL methodologies, contributing to both academic insights and real-world applications."}, {"title": "APPENDIX A\nNTK DYNAMICS IN PEFT-CL", "content": "Initially, we concentrate on analyzing the least squares loss associated with the optimization of consecutive tasks $\\tau$ and $\\tau - 1$. This involves quantifying the classification loss attributable to variations in the sub-network components' parameters, which is expressed as follows:\n$\\mathcal{L}(p_\\tau|\\mathcal{X}, \\mathcal{Y} \\in D_\\tau) = \\underset{p_\\tau}{\\text{argmin}} ||f_{\\theta^{\\tau-1}}(\\mathcal{X}) + \\nabla_{p_\\tau} f_{\\theta^{\\tau}}(\\mathcal{X}) \\times (p_\\tau - p_{\\tau-1}) - \\mathcal{Y}||^2$ \n$\\qquad \\qquad = \\underset{p_\\tau}{\\text{argmin}} ||f_{\\theta^{\\tau-1}}(\\mathcal{X}) + \\nabla_{p_\\tau} f_{\\theta^{\\tau}}(\\mathcal{X}) \\times (p_\\tau - p_{\\tau-1}) - \\mathcal{Y}||_1^2$ \\t{(31)}\nHere, $D_\\tau$ refers to the data subset associated with the $\\tau$-th task, where $\\mathcal{X}$ and $\\mathcal{Y}$ are the input images and corresponding labels, respectively. The term $\\nabla_{p_\\tau} (\\cdot)$ denotes the Jacobian matrix relevant to task $\\tau$ for the inputs $\\mathcal{X}$. At the onset of a task's optimization, the sub-network component parameters inherit parameters from the preceding task, setting the initial states for optimizing $f_{\\theta^{\\tau}}(\\cdot)$ and $p_\\tau$ as $f_{\\theta^{\\tau-1}}(\\cdot)$ and $p_{\\tau-1}$, respectively."}, {"title": "APPENDIX B\nTASK-INTERPLAY GENERALIZATION IN PEFT-CL", "content": "In this section, we explore the dynamics of task-interplay generalization gap within the PEFT-CL scenario, utilizing the NTK theory. We begin by outlining relevant mathematical properties of the NTK, followed by detailed analyses and derivations to elucidate how these properties influence generalization across tasks. This rigorous approach aims to provide a robust theoretical foundation for understanding the interplay between task transitions in PEFT-CL scenarios."}, {"title": "APPENDIX C\nTASK-INTRINSIC GENERALIZATION IN PEFT-CL", "content": "Utilizing Eq. 40 and momentarily setting aside the ini-tialization term $f_0(x)$, we identify the NTK-related term for the entire task dataset as $a_i$. Incorporating its eigen-decomposition, we derive:\n$f^*(x) = \\underset{i=1}{\\overset{T}{\\sum}} \\alpha_i \\sum_\\rho \\lambda_\\rho O_\\rho (x) O_\\rho (X)$ \\t{(65)}\n$\\qquad \\qquad = \\underset{\\rho}{\\sum} \\left( \\underset{i=1}{\\sum}  \\alpha_i O_\\rho (X) \\right) O_\\rho (x)$.\nDefining $\\omega_\\rho = \\underset{i=1}{\\sum} \\alpha_i O_\\rho (X)$, the function $f^*(x)$ is repre-sentable as $f^*(x) = \\underset{\\rho}{\\sum} \\omega_\\rho O_\\rho (x)$. Consequently, under any task scenario, its output can be decomposed into a linear combination of eigenvalues and orthogonal eigenfunctions in the RKHS.\nAt this juncture, within the task, the generalization gap can be expressed as:\n$E_D (f_\\tau, f) = <(f(x) - y(x))^2> \\newline \\qquad \\qquad =  \\underset{p \\gamma}{\\sum} (\\omega_\\rho -  \\omega_*)^2(\\omega_\\gamma -  \\omega_*)^2 < O_\\rho(x), O_\\gamma(x)>_{x \\in D_\\tau}$ .\\t{(66)}"}]}