{"title": "You-Only-Randomize-Once: Shaping Statistical Properties in Constraint-based PCG", "authors": ["Jediah Katz", "Bahar Bateni", "Adam M. Smith"], "abstract": "In procedural content generation, modeling the generation task as a constraint satisfaction problem lets us define local and global constraints on the generated output. However, a generator's perceived quality often involves statistics rather than just hard constraints. For example, we may desire that generated outputs use design elements with a similar distribution to that of reference designs. However, such statistical properties cannot be expressed directly as a hard constraint on the generation of any one output. In contrast, methods which do not use a general-purpose constraint solver, such as Gumin's implementation of the WaveFunctionCollapse (WFC) algorithm, can control output statistics but have limited constraint propagation ability and cannot express non-local constraints. In this paper, we introduce You-Only-Randomize-Once (YORO) pre-rolling, a method for crafting a decision variable ordering for a constraint solver that encodes desired statistics in a constraint-based generator. Using a solver-based WFC as an example, we show that this technique effectively controls the statistics of tile-grid outputs generated by several off-the-shelf SAT solvers, while still enforcing global constraints on the outputs. Our approach is immediately applicable to WFC-like generation problems and it offers a conceptual starting point for controlling the design element statistics in other constraint-based generators.", "sections": [{"title": "1 INTRODUCTION", "content": "In procedural content generation (PCG), we often want our generated output to satisfy a set of hard constraints (such as reachability for certain key points in a generated level) [7, 22]. Simultaneously, we would like the output to follow specific statistical properties (for instance, ensuring that the frequency of design elements used in the output is similar to the input [2, 14]).\nWhile constraint solvers provide a straightforward solution for handling hard constraints, they lack explicit mechanisms for integrating desired statistical properties. Even though many solvers offer optimization criteria as a mechanism for expressing soft constraints, this does not work for statistical properties: We do not want an optimal design, we want sampling of likely designs.\nIn this paper, we introduce the You-Only-Randomize-Once (YORO) pre-rolling technique as a method to influence the output statistics of generic constraint solvers without the need to use a new solving algorithm or even modifying the existing solvers. By generating one batch of random numbers each time we are about to run the solver, we create a special decision variable ordering which results in outputs that respect the desired distribution. Part of what makes YORO remarkable is that it does not introduce any new source of randomness into the behavior of existing solvers.\nTo illustrate this idea in an easy-to-understand application familiar to the PCG research community, we apply it to generating 2D designs in the problem setting associated with the WaveFunctionCollapse (WFC) algorithm. Starting from an extremely simple example inspired by the Ising Model from statistical mechanics [6], we scale up to a complex example involving replicating large-scale structures under path-based reachability constraints using a tileset from The Legend of Zelda. Sampling several results from multiple black-box SAT solvers, we show that YORO delivers on the promise of statistical control through decision variable order manipulation."}, {"title": "2 RELATED WORK", "content": "YORO bridges three distinct areas of research: Procedural Content Generation, Constraint Solving, and Statistical Sampling. Curiously, while researchers have explored the intersection of every pair of these topics, the trio is rarely combined.\nThe connections between PCG and constraint solving have been explored by Smith and Mateas's applications of answer-set programming (ASP) to PCG [28]. By capturing the target design space as a declarative definition, taking the form of an answer-set program, they aim to directly write down the properties that each generated output must exhibit. Similarly, Cooper's Sturgeon describes its output artifacts (i.e. tile-based game levels) by specifying a set of constraints [7]. Further, Sturgeon is able to incorporate not only pattern rules extracted from a set of examples, but also complex constraints such as path-based reachability of certain key points in the level, resulting in the generation of guaranteed-playable game levels. Additionally, Sturgeon also specifies a set of frequency rules with the goal of applying the desired statistical properties. These rules constrain the output tile count over certain tags and regions to be within a margin of those in the example data. One important distinction between Sturgeon's approach to enforcing statistical properties and our proposed method, YORO, is that YORO ensures these properties exist on a large enough population of outputs as opposed to every single acceptable artifact in the design space. As a result, the expressive range of the PCG system is unaffected by the inclusion of the desired statistical properties. In other words, the number of possible artifacts in the design space is the same since the definition of this space has not changed (only the distribution).\nLater, Cooper expanded on the idea of incorporating more complex constraints into the definition of the design space by introducing Sturgeon-MKIII [8]. By defining the game mechanics as rewrite rules, Sturgeon-MKIII simultaneously generates the level and a playthrough of it, thus ensuring the playability of the generated level. Looking forward, we would like to be able to express statistical knowledge as well.\nIn the separate context of placing objects in indoor levels, Horswill and Foged propose path constraints as a way to define a wide variety of design constraints [16]. These constraints range from lock-and-key problems to guaranteeing the survivability of the level by a careful placement of monsters and health packs. This is done by first defining path functions which summarize an attribute over some path on a graph. These attributes can be, for example, the expected health loss or gain in each node. The system is able to then define specific constraints on these functions, which are considered during the constraint solving process. Furthermore, the fast calculating of these functions made possible through dynamic programming allows for even real-time applications.\nConnecting constraint solving and statistical sampling, probabilistic logic programming systems (e.g. Markov Logic [9] or Probabilistic Soft Logic [1]) offer modeling languages reminiscent of ASP but with inference engines capable of sampling from precisely specified distributions and even adapting the definition of those distributions to fit example data. The related literature on nearly-uniform samplers [12] and weighted model counting [5] also connect these worlds. These advanced systems and techniques may serve as the foundation for content generation systems in a distant future, but the available literature currently offers no guides for how the PCG practitioner should attempt to use them.\nFinally, statistical sampling is connected to procedural content generation most obviously via the paradigm of Procedural Content Generation via Machine Learning (PCGML) [15]. Despite the importance of hard design constraints like reachability, PCGML systems often try to learn these properties from example designs rather than allowing users to directly specify what they want (potentially requiring them to need to learn a formal specification language first). It is not obvious how to provide current PCGML systems with additional symbolically-encoded background knowledge.\nSpecifically in the context of the WaveFunctionCollapse algorithm, seeking certain statistical properties in the output can improve the generated results. When introducing WFC, Gumin highlighted one of the main goals of WFC as similarity between the distribution of patterns in input and a sufficiently large number of outputs [14]. To achieve this, his algorithm used randomization during the constraint solving process to heuristically make local choices following the marginal distribution seen in the example input designs. By contrast, our method concentrates all of the randomization in a preprocessing step that runs before an existing solver runs to produce an output design. By factoring the statistical concerns out of the solver's search process, we gain the ability to drop in alternate constraint solvers.\nRecently, Bateni et al. expand on Gumin's desire for resemblance by introducing Context-Sensitive WFC [2]. By modeling the distribution of tiles or patterns conditioned on their surrounding context, they demonstrate the significance of leveraging statistical properties in both the quality and expressive range of the output. Importantly, they show that Gumin's tile-level heuristic was insufficient to achieve its original goal. Reproducing neighborhood-level statistics required using a neighborhood-level statistical model. While Bateni's method yields WFC-like results with greatly improved resemblance, it inherited WFC's limitations: it could not incorporate global constraints such as reachability. By using YORO we aim to keep the advantages of solver-based methods in employing global constraints while also gaining some control on the statistical characteristics of the output."}, {"title": "3 TECHNICAL BACKGROUND", "content": null}, {"title": "3.1 Satisfiability Solvers", "content": "Satisfiability (SAT) solvers are programs that solve the classic NP-complete Boolean satisfiability problem. They are widely used to solve a number of practical problems whose constraints can be represented as a Boolean formula. SAT solvers accept as input a description of a Boolean formula in conjunctive normal form (CNF), i.e. an \"AND of ORs,\u201d and output either a satisfying assignment or the message UNSAT to indicate that no satisfying assignment exists.\nIn a typical SAT solver, Boolean variables $x_1, x_2,..., x_n$ are represented programmatically as integers 1, 2, ..., n, and a Boolean literal is a variable in positive form (e.g., $x_7$ is 7) or negative form (e.g., $\\neg x_7$ is -7). SAT problems are typically represented in conjunctive normal form (CNF): one big conjunction (AND) of many small disjunctions (OR), each involving one or more positive or negative literals. An input CNF formula is represented as a list of clauses, which themselves are lists of literals. For example, an input to a SAT solver might be the formula $(x_1 \\lor x_2) \\land (\\neg x_1 \\lor \\neg x_2)$, represented as [[1, 2], [-1, -2]]. An output for this formula might be the satisfying assignment {$x_1$ = True; $x_2$ = False}, represented as [1, 2]. Another possible satisfying assignment is [-1, 2]. By default, most SAT solvers terminate after yielding the first satisfying solution they find, but most can be configured to continue enumerating additional solutions. In this paper, we will focus on influencing just the very first solution output by a solver."}, {"title": "3.2 Decision Variable Ordering", "content": "When representing an abstract constraint satisfaction problem as a CNF formula, a variable ordering refers to a labeling of semantically-named Boolean variables with integers from 1 through n. Although a Boolean formula has the same set of solutions regardless of how its variables are ordered, the choice of ordering can impact which of those solutions the solver will output first.\nDuring the execution of a typical SAT solver, the solver attempts to incrementally build a satisfying assignment by selecting unassigned variables one at a time and then deciding a value for them (True or False). In solvers employing constraint propagation methods, many variables are assigned values deduced from the value of previously assigned variables, and the solver's variable selection mechanism is only invoked when there is no other work that must be done first. With or without constraint propagation, solvers can encounter situations where there are no longer any values available to be assigned to a variable (i.e., the solver's previous choices have been revealed to be contradictory). To resolve this contradiction, many solvers backtrack (undoing one or more recent choices) before trying to make an alternate choice.\nWhich unassigned variable should a solver select next? Many heuristics have been developed to determine the order in which a solver chooses variables for the next decision step. SAT solvers may use static orderings, which are fixed at the beginning of solving, or dynamic orderings, which change over the course of solving. Jeroslow-Wang is an example of a common static heuristic, in which variables are ordered based on the frequency of their appearance in the input formula [18]. VSIDS is an example of a common dynamic heuristic, in which variables move up in the ordering if they cause a contradiction to occur [21]. However, when the order of decisions is not influenced by heuristics, SAT solvers will typically decide variables in ascending order of the variable ordering. Many configurable solvers even provide the ability to fully disable heuristics, falling back to a selection order based on the numerical representation used in the CNF formula. In YORO, we manipulate this ordering so that a solver's fallback strategy is to let the target statistics guide the selection order."}, {"title": "3.3 WFC as a Boolean CSP", "content": "The grid-based WaveFunctionCollapse algorithm is usually seen as having two phases: input analysis, in which the input grid is processed to extract the set of tiles and the allowed adjacencies between tiles, and then grid generation, in which tiles are assigned to a new grid while respecting the allowed adjacencies. Here, we will show how the generation phase of WFC can be implemented using any SAT solver. Recall that the goal of WFC is to find an assignment of tiles to grid cells such that tiles are only adjacent in the output if they were seen to be adjacent in the input example.\nAssume we have already extracted the set of tiles T and a set of adjacency lists right[t] and below[t], which represent the set of tiles that may be placed immediately to the right and below a tile t, respectively. Let N \u00d7 M be the desired dimensions of our output grid. For simplicity we assume that grids have periodic boundary conditions, i.e. row N + 1 and column M + 1 are understood to refer to row 1 and column 1, respectively.\nWe first define the following Boolean variables:\nassign (x, y, t) the cell at position (x, y) is assigned tile t\nThese Boolean variables can be arbitrarily labeled from 1 to NMT, for example with the mapping\nassign(x, y, t\u2081) \u2192 (x. M+ y) |T| + i\nNext, we construct Boolean clauses to represent the constraints of our WFC setting. Assume we have a function add_clause() which adds a clause to the growing CNF formula. First, we have the constraint that each cell of the grid must be assigned at least one tile.\nfor each cell position (x, y):\nadd_clause ($\\bigvee_{\\text{tile } t}$ assign(x, y, t))\nNext, we have the constraint that each cell of the grid must be assigned at most one tile. We can equivalently state this as, \"for each pair of distinct tiles, they cannot both be assigned to one cell.\"\nfor each cell position (x, y):\nfor each pair of distinct tiles $t_1, t_2$:\nadd_clause ($\\neg$ assign(x, y, $t_1$) $\\lor \\neg$ assign(x, y, $t_2$))\nFinally, we have the constraint that assigned tiles must respect allowed adjacencies. We can equivalently state this as \"if a cell is assigned tile t, then its adjacent cell must be assigned to a tile which is an allowed adjacency for t.\" On a two-dimensional grid, we must enforce constraints for both horizontal and vertical adjacencies.\nfor each cell position (x, y):\nfor each tile t:\na = assign(x, y, t)\nadd_clause(-a $\\lor \\bigvee_{t_r \\in \\text{right}[t]}$ assign(x + 1, y, $t_r$))\nadd_clause(-a $\\lor \\bigvee_{t_b \\in \\text{below}[t]}$ assign(x, y + 1, $t_b$))\nAt this point, we have a CNF formula that we can give to a SAT solver, and which we assume outputs a satisfying assignment. To decode that assignment into an output grid, we can simply identify which Boolean variables assign(x, y, t) are True in the satisfying assignment, and assign tile t to the cell at (x, y) in the output grid.\nThere are many other ways to reduce the WFC-inspired grid generation problem to SAT, but we have chosen a clean and simple one here to illustrate how to apply the YORO technique."}, {"title": "3.4 Gumbel-max Trick", "content": "Before we introduce YORO, we should note where others have drawn a theoretical connection between the procedure of sampling a distribution without replacement and generating a single stochastic ordering of the items to be sampled. Recall that in Gumin's WFC, a tile frequency heuristic is used to sample the next tile assignment to try during search from the pool of tiles remaining in a cell based on some distribution. We want to mimic within-search randomization (something that might require significant engineering effort to add to an existing constraint solver) by way of preparing a clever static ordering.\nThe Gumbel-max trick [13, 17] is a widely applied method of sampling from a categorical distribution with un-normalized weights $w_i$ for each class i \u2208 [1..k]. The Gumbel-max trick separates the distribution into a constant term, which is defined by the log-weights of each class, and an independent Gumbel noise term. The Gumbel noise term is a random sample $G_i$ from the Gumbel(0, 1) distribution, which can be conveniently and accurately approximated by $G_i \\sim log(-log(Uniform(0, 1))$. The following is equivalent to choosing a category y by a weighted random sample:\ny = argmax (log($w_i$) + $G_i$)\ni\u2208 [1..k]"}, {"title": "4 OUR TECHNIQUE: YORO DESIGN PRE-ROLLING", "content": "Figure 1 compares the YORO approach with a traditional approach to constraint solving for PCG applications (e.g. the design-space modeling paradigm sketched by Smith and Mateas [28]). With YORO, we preprocess the low-level definition of a constraint problem before the solver gets to look at it. This manipulation is intended to shape the statistical properties evident within and across the collection of first-solutions output by the solver after each randomization.\nAs mentioned in Section 3.2, when a SAT solver has no other heuristics to apply, it will typically fall back to the variable ordering implied by the problem specification to break ties. In this way, by curating the default order, we can bake our statistical desires into the solver's tie-breaking behavior without needing to modify the solver at all. To achieve this, we craft a variable ordering using pre-rolled Gumbel noise for each cell that samples from the desired distribution of design elements.\nSuppose we want to control the tile frequency statistics in the WFC setting, such that outputs follow a distribution which gives tile t a probability of P[t]. Assume we have defined Boolean variables assign(x, y, t) as described in Section 3.3, for which we now must craft a variable ordering. We can do so with the following pseudocode, which defines a Python-style sorting key function, such that variables will be sorted based on their key value:\nvariables = [assign(x, y, t) for pos (x,y), for tile t]\nvariables.sort(key=sorting_key)\nfunction sorting_key(assign(x, y, t) ):\ncell_pos_rowmajor = (y,x)\ngumbel_noise = -log(-log(random (0, 1)))\ntile_score = log(P[t]) + gumbel_noise\nreturn (cell_pos_rowmajor, -tile_score)\nFirst, we choose an arbitrary, fixed ordering for the cell positions (e.g., row-major order from the top-left). This determines the order in which the solver will choose which cells to assign a tile, and depending on the constraints of the problem, this choice may lead to bias. We use the cell position as the primary sorting key.\nNext, we use the Gumbel-max trick to sample a tile_score based on the probability for each tile. This score is used as the"}, {"title": "5 EXPERIMENTS", "content": null}, {"title": "5.1 Tile-level Pre-rolling", "content": "In our first experiment, we sought to craft a simple and easily understood example to demonstrate the impact of the YORO method on the generated output statistics without any influence by constraints. To that aim, we defined a 7 x 7 example grid with only"}, {"title": "5.2 Neighborhood-level Pre-rolling with Global Constraints", "content": "In the second experiment, we attempted to demonstrate the efficacy of using the YORO method in a realistic setting to control output statistics even while enforcing an interesting global constraint. For our input grid, we used the overworld map from The Legend of Zelda for the NES, pictured in Figure 5, which consists of 90 unique tiles of 16 \u00d7 16 pixels [23].\nTo achieve outputs with closer resemblance to the input grid, we used a more complex SAT formulation of WFC based on Bateni's context-sensitive decision heuristic [2]. The context-sensitive decision heuristic is a method to determine which tile a WFC generator should choose when assigning a cell. Rather than sampling a tile based on individual tile frequency, it samples based on the joint frequency of the tile and its four-tile neighborhood (i.e., the adjacent north, east, south, and west tiles) in the input image, accounting for cells that haven't been assigned yet. When the neighborhood for the current cell to be assigned does not exist at all in the input, the heuristic falls back to sampling based on individual tile frequency.\nIt may not be possible to directly reproduce Bateni's context-sensitive heuristic within SAT-based WFC implementation without a custom dynamic heuristic for the SAT solver. However, we can approximate it by introducing a new set of neighborhood-assignment variables. We define the following variables for each tile t and neighborhood (t, tn, te, ts, tw):\nassign(x, y, t, tn, te, ts, tw)\n(x, y) is assigned t and its neighboring tiles are assigned tn, te, ts, tw respectively\nThese Boolean decision variables are defined in addition to the individual-tile-assignment variables (assign(x, y, t)). Then, we use YORO to craft a variable ordering such that for each cell, its sub-ordering consists first of the neighborhood-assignment variables and then the tile-assignment variables. The neighborhood-assignment variables are in a randomly sampled order based on neighborhood frequency in the input, and the tile-assignment variables are similarly arranged based on a tile frequency sampling. With this formulation, the solver will assign entire neighborhoods at a time, and if no neighborhoods present in the input are possible then the solver will fall back to assigning individual tiles based on tile frequency.\nFor this experiment, also we add a simple global constraint to all generated outputs: there must be a path of only dirt tiles from (0,0) to (N \u2212 1, M-1) that moves only rightwards and down (henceforth a \"good dirt path\"). We can represent this constraint in SAT by adding new variables defined as follows:\nreachable(x, y) a good dirt path connects (0,0) and (x, y)\nWe then add recursive constraints to enforce that (x, y) is reachable iff (x, y) is a dirt tile and (x \u2013 1, y) or (x, y \u2013 1) is reachable, handling the base cases where x = 0 or y = 0 separately. Also note that we place all the reachable(x, y) variables at the end of the variable ordering, since we do not want the solver to make decisions based on them.\nWe once again compare three methods of crafting a variable ordering: a trivial variable ordering; a uniform ordering, in which neighborhoods are permuted randomly in the YORO sub-orderings for each cell; and a neighborhood-frequency YORO ordering as described above. Initial results are shown in Figure 5."}, {"title": "6 ADAPTING YORO FOR DIFFERENT SOLVERS", "content": "To demonstrate that the YORO technique is adaptable to different off-the-shelf SAT solvers, we generated outputs for the Zelda domain using the following four different solvers, each of which accepts a SAT formula encoded in the standard DIMACS file format [26]:"}, {"title": "6.1 Solver Configuration", "content": "Modern SAT solvers use a number of heuristics, preprocessing steps, and other advanced procedures to speed up solving time [4]. However, these techniques can often cause the solver to select variables in an unpredictable order during solving, which can interfere with the effectiveness of the YORO method. While these advanced techniques are often needed to achieve acceptable solving times on hard search problems (where satisfying solutions are exceedingly rare), the kind of problems that often arise in PCG are comparatively easy. Famously, Gumin's WFC algorithm does not implement a backtracking mechanism because contradictions are sufficiently uncommon that rejection sampling (i.e. generate-and-test) is sufficient to achieve good performance [19].\nFortunately, most SAT solvers are configurable and allow the user to disable advanced techniques, leaving the solver to fall back to its default variable ordering. However, it should be noted that determining a correct configuration is sometimes non-trivial and may require knowledge of the solver's implementation details. In this section, we describe the configurations used for each solver to achieve our results.\nThe PennSAT solver (designed for teaching purposes) is simple and includes no dynamic heuristics or advanced preprocessing. It uses a static Jeroslow-Wang heuristic which can be disabled."}, {"title": "6.2 Boolean Formula Transformation", "content": "While configuration parameters are the most robust method of forcing solvers to respect the variable ordering, some solvers cannot be configured. In this case, it may still be possible to circumvent unpredictable behavior by applying transformations to the Boolean SAT formula before solving. We present two transformations that produce a new formula that is equivalent to the original, but processed differently by the solver. In particular, these transformations influence the solver's phase selection; i.e., whether it assigns selected variables to True or False first.\nTypical SAT solvers default to assigning variables to False first. Since YORO relies on the solver assigning variables to True in the provided order, this will result in the solver following the reverse YORO order. Some solvers allow the user to configure the phase selection strategy. However, rather than relying on configuration, we can solve this problem with the following transformation.\nBefore solving, negate all Boolean variables in the formula. Intuitively, each variable now represents its semantic negation. For example, this redefines our tile-assignment variables as\nassign(x, y, t) \u2190 position (x, y) is not assigned tile t\nTherefore, when the solver sets assign(x, y, t) = False, it represents assigning tile t to cell (x, y) as desired. Before decoding our satisfying assignment back to an output grid, we should negate all literals once more to restore their original meaning.\nThe second formula transformation we used is a novel strategy to neutralize the influence of PicoSAT's static heuristic on the phase selection. In addition to VSIDS, PicoSAT uses a variant of Jeroslow-Wang in order to determine whether to assign variables to True or False, rather than always defaulting to False [3]. We only used this trick when solving with PicoSAT, since as noted in Section 6.1, we had no means of disabling its heuristics. This transformation is applied after the negation transformation described above.\nJeroslow-Wang is a statistical heuristic that assigns each Boolean literal l an activity score, defined as\nactivity(l) = $\\sum_{\\text{clause c containing l}}$ $2^{-\\text{|c|}}$\nIn PicoSAT, when a variable v is selected, the activity scores of its literals are compared. If activity(v) > activity(\u00acv), then v is assigned True; otherwise, it is assigned False.\nTherefore, in order to ensure that all variables are assigned False first, we pad the formula with trivial length-2 clauses such that for each variable v, activity(v) \u2264 activity(\u00ac). Our key observation is that by adding a clause of the form (di \u2228 \u00acv), we can increase activity(v) by 2-2 = 0.25 without adding any new constraints. Here di > n is a dummy variable that can always be assigned True (n is the number of variables before the transformation). The following pseudocode demonstrates the procedure:\nfor each variable v with activity(v) > activity():\ndiff = activity(v) - activity(0)\nnum_trivial_clauses_to_add = ceil(diff / 0.25)\nfor i = 1, 2, .., num_trivial_clauses_to_add:\ndi = n + i\nadd_clause(di \u2228 \u00acv)"}, {"title": "7 CONCLUSION", "content": "In this paper, we have shown how the order of decision variables in the definition of a constraint problem can be meaningfully manipulated to successfully shape the statistics of the first solutions output by various off-the-shelf SAT solvers. In particular, we show that it is possible to concentrate all of the randomness into the generation of a matrix of numbers sampled unconditionally from a uniform distribution. With each new randomization of this matrix, we can renumber an existing constraint problem so that the solver will give an appropriately new output sample. This approach shows how general purpose constraint solvers, with their ability to represent and enforce interesting local and global hard constraints, can begin to respect statistical design considerations as well."}]}