{"title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models", "authors": ["Xianda Chen", "Mingxing Peng", "PakHin Tiu", "Yuanfei Wu", "Junjie Chen", "Meixin Zhu", "Xinhu Zheng"], "abstract": "Accurate modeling of car-following behaviors is essential for various applications in traffic management and autonomous driving systems. However, current approaches often suffer from limitations like high sensitivity to data quality and lack of interpretability. In this study, we propose GenFollower, a novel zero-shot prompting approach that leverages large language models (LLMs) to address these challenges. We reframe car-following behavior as a language modeling problem and integrate heterogeneous inputs into structured prompts for LLMs. This approach achieves improved prediction performance and interpretability compared to traditional baseline models. Experiments on the Waymo Open datasets demonstrate GenFollower's superior performance and ability to provide interpretable insights into factors influencing car-following behavior. This work contributes to advancing the understanding and prediction of car-following behaviors, paving the way for enhanced traffic management and autonomous driving systems.", "sections": [{"title": "I. INTRODUCTION", "content": "CAR-FOLLOWING, a critical cornerstone of traffic flow analysis, describes the behavior vehicles travel in succession while maintaining a safe separation distance. Accurate modeling of car-following behaviors is critical for a variety of applications in transportation engineering, including traffic management systems and the development of autonomous vehicles.\nExisting research on car-following has explored a range of modeling approaches, including physics-based models and data-driven methods. However, significant research gaps remain. First, current models often exhibit limited accuracy in the long-term prediction of car-following behaviors, failing to capture the complex dynamics that unfold over extended periods. Second, while deep learning-based methods achieve promising results, their black-box nature poses a challenge where they generate predictions of future behavior without providing substantial explanations for their outputs, making it difficult to understand the reasoning behind their decisions.\nRecently, advancements in the field of large language models (LLMs) have revolutionized industries like natural language processing, demonstrating their powerful capabilities in information comprehension and common-sense reasoning. Notably, studies by Mao et al. [1], Chen et al. [2], and Wu et al. [3] have successfully leveraged LLMs for tasks related to autonomous driving, such as motion planning and perception, highlighting their potential contribution to this field. This paves the way for the exploration of LLMs in car-following, a critical aspect of autonomous driving that remains unaddressed by current LLM research.\nTo address the limitations of limited long-term prediction and lack of interpretability in existing car-following models, we propose GenFollower, a novel zero-shot prompting approach that utilizes the strong reasoning and self-explanation capabilities of LLMs for car-following prediction. We achieve this by reframing car-following behavior as a language modeling problem by integrating vehicle states and other relevant information into structured natural language prompts and feeding this information into the LLM. Furthermore, we integrate interpretability requirements into the prompts, enabling our GenFollower to generate explanations alongside its predictions. Benefiting from the power of LLMs, our proposed model demonstrates improved performance and interpretability in car-following behaviors. Experiments conducted on the Waymo Open datasets validate the performance improvement of GenFollower compared to other baseline models, while also showcasing its strong interpretability. Our main contributions are as follows:\n\u2022 We introduce GenFollower, the first large language model designed specifically for car-following behavior, leveraging its capabilities to address the limitations of existing models, such as limited long-term prediction and lack of interpretability.\n\u2022 GenFollower achieves interpretable predictions, providing not only accurate forecasts of car-following behavior but also explanations for the predicted results. This capability enhances transparency and trust in the modeling process.\n\u2022 Experiments conducted on the Waymo Open datasets demonstrate the significantly improved performance and interpretability of our GenFollower model compared to all baseline models. This highlights the effectiveness of our prompt-based approach in accurately predicting and explaining car-following behaviors."}, {"title": "II. RELATED WORK", "content": "To understand the current state-of-the-art and identify research gaps, this section reviews related work in three main areas: traditional car-following models, data-driven car-following models, and the application of LLMs in autonomous driving."}, {"title": "A. Traditional Car-Following Models", "content": "Within the category of traditional car-following models, these models have been extensively studied and form the foundation of early autonomous driving systems. They rely on mathematical formulations to describe the dynamics of car-following behavior, grounded in physical laws and human behavioral theories. Normally they can be broadly categorized into kinematic models, psycho-physical models, and adaptive cruise control (ACC) models [4].\nKinematic models offer a computationally efficient way to model car-following behavior, but they may not fully capture the complexities of driver behavior. They focus on the physical aspects of vehicle motion and dynamics, considering factors such as velocity, headway, and distance. First-order models update the vehicle's position based on its velocity, while second-order models also take acceleration into account. For example, Gipps' model [5] considers factors like the desired speed of the following vehicle, the safe distance to the leader, and the driver's reaction time to determine the following vehicle's acceleration. One of the most prominent traditional models is the Intelligent Driver Model (IDM). The IDM [6] is a strategy-based model that describes the acceleration of a vehicle using a set of basic assumptions and parameters like desired speed and desired time headway.\nPsycho-physical models are designed to approximate drivers' reasoning and decision-making processes by considering limitations in human perception, such as the ability to judge distances and speeds accurately. These models incorporate human factors into the car-following behavior analysis. The Action Point Model (APM) [7] applies Signal Detection Theory (SDT) to car-following contexts, modeling the driver's sensitivity to these perceptual limitations and potential bias in interpreting them. It predicts when drivers initiate acceleration or braking based on these limitations and calculations of angular velocity. The Fuzzy Logic Model [8], [9] employs fuzzy logic to handle the inherent uncertainty and subjectivity in drivers' decision-making processes.\nAdaptive Cruise Control (ACC) models [10], [11], [12] highlight the mechanistic control strategies used to maintain safe and efficient vehicle dynamics. ACC systems automatically adjust the vehicle's speed to keep a safe distance from the vehicle ahead, employing control techniques to ensure stability and comfort. While these models perform well in controlled environments, they may struggle to adapt to sudden lane changes, unpredictable driver behavior, or complex weather conditions. This highlights a limitation in their ability to capture the intricacies of real-world driving scenarios and their lack of adaptability to diverse environments."}, {"title": "B. Data-Driven Car-Following Models", "content": "With the emergence of large-scale driving datasets like Waymo Open Dataset [13] and advancements in machine learning techniques, data-driven car-following models have gained traction. These models leverage data to learn complex driving behaviors and interactions that are challenging to capture with traditional models. Data-driven approaches can be further divided into supervised learning models, unsupervised learning models, and reinforcement learning models.\nSupervised learning models utilize labeled data to train algorithms that predict car-following behavior. Techniques such as support vector machines [14], various neural networks [15], [16], [17], and Transformer [18] have been employed. For instance, Kehtarnavaz et al. [19] developed a time-delay neural network, and Panwai et al. [20] introduced a neural agent model for car-following that maps perceptions to actions. Additionally, hybrid models combining different machine learning approaches with traditional models have been proposed to enhance prediction performance [21]. Notably, Chen et al. [22] propose MetaFollower, an adaptable framework integrating Long Short-Term Memory (LSTM) and IDM for interpretability and temporal adaptation. It leverages Model-Agnostic Meta-Learning (MAML) [23] for generalizability and fine-tunes with minimal data from new drivers, enhancing adaptation to individual driving styles.\nUnsupervised learning models explore patterns in car-following behavior without labeled data. These models are particularly useful for clustering and anomaly detection in driving patterns [24], [25]. For instance, unsupervised models [26], [27] can identify unusual braking patterns that might indicate emergencies or potential accidents. This unsupervised approach provides insights into typical and atypical driving behaviors, enhancing the robustness of car-following models in diverse scenarios.\nReinforcement learning models [28], [29] have been increasingly applied to car-following tasks, where an agent learns optimal driving strategies through interactions with the environment. Zhu et al. [30] proposed a human-like autonomous car-following model using deep reinforcement learning, achieving performance comparable to human drivers. While data-driven models demonstrate promising results, they may struggle with the interpretability of their decision-making processes due to the complex nature of learning through trial and error, and generalization to unseen driving scenarios."}, {"title": "C. LLMs for Autonomous Driving", "content": "LLMs have emerged as powerful tools for natural language processing tasks, exhibiting capabilities in understanding complex language structures, such as the nuances of traffic regulations and natural language descriptions of the driving environment, and reasoning over vast knowledge bases. Recent research has explored the application of LLMs in various aspects of autonomous driving [31], demonstrating potential benefits for different tasks. For instance, LLMs have been integrated into perception tasks, such as 3D detection and tracking [3], to potentially improve accuracy, and used for motion planning to generate driving trajectories [1]. Additionally, LLMs have been combined with multimodal architectures to process diverse data modalities for autonomous driving applications [2]. Specifically, LLMs can be utilized for high-level decision-making and scenario understanding in autonomous vehicles. Cui et al. [32] introduced DriveLLM, which leverages LLMs to interpret complex driving scenes and make informed driving decisions. This approach integrates LLMs with other sensory inputs to create a comprehensive understanding of the driving environment. Peng et al. [33] propose LC-LLM, a novel approach leveraging LLMs to enhance lane change prediction, the model integrates explanatory prompts, enabling it to not only predict lane change intentions and trajectories accurately but also provide explanations for these predictions. Recent advancements also explore the fusion of LLMs with vision-language models [34], enabling autonomous systems to process visual and textual information concurrently. This multimodal approach enhances the vehicle's ability to navigate complex driving scenarios and interact with human drivers and pedestrians effectively.\nOverall, traditional car-following models provide a theoretical foundation, while data-driven approaches leverage real-world data to improve prediction accuracy. LLMs offer a new paradigm for understanding and reasoning over complex driving scenarios, with potential applications across various aspects of autonomous driving. While LLMs have shown promise in perception and planning tasks, their potential in prediction with transparent interpretability for car-following remains largely untapped. This gap motivates our work on GenFollower, a novel approach that leverages the reasoning and self-explanation capabilities of LLMs to address the challenges of car-following prediction with interpretability."}, {"title": "III. METHODOLOGY", "content": "In this section, we introduce our GenFollower, a model based on LLMs designed for car-following prediction in autonomous driving systems, addressing limitations of interpretability and complex scenario handling seen in traditional models. The overall pipeline of our GenFollower is depicted in Figure 1. We conceptualize the task of predicting car-following behavior as a language modeling problem. We formulate observations about the driving environment using natural language as prompts for input into the LLM. We employ a zero-shot approach, meaning we don't require extensive retraining for each specific task, allowing the LLM, such as ChatGPT-4 [35], to learn from its vast internal knowledge base and predict car-following behavior. By incorporating explanatory requirements into the prompt, our GenFollower can simultaneously predict car-following behavior and provide explanations for its predictions, thereby enhancing interpretability."}, {"title": "A. Problem Formulation", "content": "Our objective is to develop a predictive model based on LLMs to predict the behavior of a following vehicle. Given the current state of the following vehicle and its lead vehicle, our model aims to forecast the following vehicle's future speed relative to the lead vehicle, which is crucial for maintaining safe inter-vehicle spacing and ensuring smooth traffic flow. The car-following event is depicted in Figure 2.\nThese four dimensions of the input feature capture the key aspects of car-following behavior: the speed of lead vehicle (LV) denoted by $(v_{LV})$, the speed of following vehicle (FV) denoted by $(v_{FV})$, the relative spacing between them $(\\Delta d_t)$, and the relative speed $(\\Delta v_t)$. These features were chosen as they capture the key aspects of car-following behavior, including the relative distance between the vehicles, their current speeds, and the difference in their speeds. The model's output is the speed of FV in the next time step. The composition of the input features and output variables is listed below.\nInput = $X_t = [\\Delta d_t, v_{LV}, v_{FV}, \\Delta v_t]$\nOutput = $\\hat{y_t} = [v_{t+1}]$\nwhere $\\hat{y_t}$ represents the speed prediction of FV at the next time step."}, {"title": "B. GenFollower Pipeline", "content": "The GenFollower pipeline involves several stages, as shown in Figure 3, to transform raw data into meaningful predictions and explanations. The main components of the pipeline are as follows:\n1) Data Preprocessing:\n\u2022 Collect real-time data from sensors regarding the speeds of LV and FV, the relative spacing between them, and their relative speed.\n\u2022 Normalize these inputs to ensure consistency and compatibility with the LLM's input requirements.\n2) Prompt Generation:\n\u2022 Transform the normalized input features into a natural language prompt. This involves constructing sentences that describe the current state of the traffic scenario. For example, \"The lead vehicle is traveling at 5 m/s, the following vehicle is traveling at 4 m/s, the distance between them is 10 meters, and the relative speed is 1 m/s.\"\n3) LLM Inference:\n\u2022 Input the generated prompt into an LLM, such as ChatGPT-4, configured to handle zero-shot learning tasks. The model processes the prompt and generates a prediction for the following vehicle's speed at the next time step.\n\u2022 Additionally, prompt the LLM to provide an explanation for its prediction, enhancing interpretability.\n4) Post-processing:\n\u2022 Extract and parse the predicted speed from the LLM's output.\n\u2022 Validate and adjust the prediction if necessary to ensure it adheres to physical constraints and safety protocols.\n5) Output:\n\u2022 Deliver the predicted speed of the FV along with the explanatory text generated by the LLM. This combined output aids in understanding the model's decision-making process."}, {"title": "C. Prompt Design", "content": "LLMs typically receive inputs in the form of natural language prompts. In our approach, we leverage the power of natural language prompts, as LLMs excel at understanding and reasoning based on textual information. We formulate prompts that describe the current observations in natural language, guiding the LLM to generate accurate predictions. The input prompts are designed with two parts: a system message providing the context of the driving scenario, and a user message prompting the LLM for a specific action or prediction.\n1) System Message: The system message provides the role and task of ChatGPT, along with guidelines on how to construct the responses. It outlines the role of the LLM in predicting car-following behavior, specifies the input information used, and defines the format of the output predictions. The system prompt remains consistent and primarily includes an introduction to the task, input-output specifications, and the format requirements for LLM responses, as shown in Figure 4. Specifically, we use the past four seconds of car-following information as input to predict the speed for the next 0.5 seconds. The system message emphasizes that safety is the top priority during car-following, even if it means sacrificing some comfort in terms of maintaining a perfectly smooth following distance. Restrictions are placed on extreme car-following situations, such as very small following distances. We use delimiters to clearly indicate distinct parts of the input as suggested in [36].\n2) User Message: The user message describes the current state of the following vehicle relative to the lead vehicle, which varies with each car-following moment. It includes details of the historical car-following states over the past four seconds. Additionally, it incorporates the concept of Chain of Thought (CoT) [37], a technique that encourages the LLM to show its reasoning steps, potentially improving its ability to make accurate predictions about the following vehicle's future speed. The system evolves over discrete time intervals $\\Delta T$ according to the following equations:\n$\\Delta V(t + 1) = V_{LV}(t + 1) - V_{FV}(t + 1)$\n$S(t+1) = S(t) + \\frac{\\Delta V(t) + \\Delta V(t+1)}{2} \\Delta T$\nwhere $\\Delta T$ denotes the simulation time interval, S represents the spacing between the vehicles, and $V_{FV}$ and $V_{LV}$ denote the velocities of the following vehicle and lead vehicle, respectively. This car-following state update process is embedded within our user message, ensuring that the latest vehicle state quantities are incorporated into the prompt for each invocation of the large language model.\nThese details serve as input for the LLM to predict the future speed of the following vehicle. An example of our input prompts is illustrated in Figure 5."}, {"title": "D. Prompt Engineering vs. Fine-Tuning", "content": "OpenAI's introduction of fine-tuning capabilities for the GPT-3.5 model opens up new possibilities for training LLMs. However, this advancement prompts us to consider a critical question: Should car-following models aim to replicate the exact behaviors observed in a training dataset? Does mimicking human driving tendencies necessarily translate to optimal car-following behavior for autonomous vehicles?\nRecent studies indicate that supervised learning methods, which rely on data provided by human demonstrations, aim to approximate the relationship between vehicle states and vehicle acceleration actions. In essence, they are geared towards mimicking human drivers' car-following behavior. In the field of autonomous driving, some successful approaches [38], [39], [32] have achieved good results with prompt engineering alone, without fine-tuning GPT models. Additionally, with OpenAI releasing fine-tuning capabilities for GPT-3.5, there's an opportunity to explore how combining fine-tuning with prompt engineering could further enhance performance. However, merely mimicking human driving behavior may not necessarily be the optimal solution for autonomous driving. Firstly, users may not desire autonomous vehicles to drive exactly like them [40]. Secondly, in addition to replicating human drivers, driving should also be optimized for safety, efficiency, and comfort, as human drivers may not always drive optimally [41]. Therefore, Fine-tuning GPT-3.5 in the context of autonomous driving raises several intriguing questions and considerations.\n\u2022 Quality of Training Data: In the raw driving data, some drivers may be aggressive, and mimicking such driving styles could lead to collisions. Conversely, some drivers may be overly cautious, potentially impacting overall traffic flow efficiency. The question of whether raw driving data authentically embodies ideal driving behavior warrants scholarly inquiry. Driving styles can vary significantly among individuals, ranging from aggressive to conservative. Fine-tuning GPT-3.5 on this varied dataset could potentially lead to models that mimic either extreme, which may not always align with safe or efficient driving practices.\n\u2022 Defining \"Good\" Driving Behavior: Determining what constitutes \"good\" driving behavior is complex and subjective. While the training data used for fine-tuning represents real-world driving behaviors, it includes a spectrum of styles that may not all be optimal for safety or traffic efficiency. This diversity poses challenges in how the model interprets and learns from this data.\n\u2022 Alternative Approaches: Instead of relying solely on human-driving data as ground truth for fine-tuning, another approach could involve leveraging GPT's inherent capabilities for reasoning and context understanding (such as with CoT) to simulate and learn driving behaviors. This method might enable the model to develop a more nuanced understanding of driving that goes beyond mimicking specific human drivers.\nDespite these challenges, we used the driving data to fine-tune the model and explore car-following behaviors. Leveraging OpenAI's guidelines, we curated a dataset for fine-tuning using real-world speed data as ground truth to construct assistant messages. Our approach adhered to recommended practices by incorporating 50 instances of vehicle following data for the fine-tuning process. Figure 6 illustrates the construction of a fine-tuning dataset from a selected instance of car-following data."}, {"title": "E. Transparency in Predictive Explanations", "content": "To illustrate the interpretability of our predictions, we incorporate explanatory requirements into the input prompts. This allows the LLM to provide explanations for its predictions, making the reasoning behind the model's decisions transparent. By analyzing the generated explanations, users can gain insights into why the predicted speed of the following vehicle was chosen, improving trust and understanding of the autonomous driving system. The prompting-reasoning process can be formulated as:\n{V,R} = $F_{GPT}(K(S,U))$\nThis equation represents the prompting-reasoning process. Here, $F_{GPT}$ denotes the GPT model, which receives a combination of the system message S and user message U denoted by K(S,U). The model then outputs two results: V, a linguistic description of the predicted speed, and R, a linguistic explanation for the reasoning behind the prediction. Unlike conventional motion planning methods focused solely on trajectory generation, our approach generates both speed predictions V and explicit reasoning processes R, thereby enhancing transparency in decision-making processes."}, {"title": "IV. DATA AND EXPERIMENTS", "content": "We evaluate the performance of the GenFollower framework on the Waymo Open Dataset [42]. This rich and diverse resource for autonomous vehicle research, offered by Waymo, provides high-resolution sensor data, including LiDAR, camera, and radar, captured from real-world driving environments. It includes detailed information on objects, their trajectories, and interactions, making it an invaluable tool for advancing machine learning models in perception, motion prediction, and planning. Its wide range of scenarios and comprehensive labeling facilitates robust development and benchmarking in the field of autonomous driving. Hu et al. [43] and Chen et al. [44] extracted car-following events based on the Waymo Open dataset, which we leverage for our experiments."}, {"title": "A. Waymo Open Dataset", "content": "To ensure a representative sample size, we randomly selected 100 car-following events from our previous work [44] to evaluate the performance of the GenFollower. Each car-following event spans a duration of 15 seconds and comprises four key pieces of information captured at each time step:\n\u2022 Spacing: Represents the distance between the FV and the LV at each time step.\n\u2022 Following Vehicle Speed: The speed of the FV at each time step.\n\u2022 Relative Speed: Indicates the relative speed between the FV and the LV at each time step.\n\u2022 Lead Vehicle Speed: The speed of the LV at each time step."}, {"title": "B. Extracted Car-Following Data Description", "content": "To evaluate the performance of the GenFollower model, we employ established metrics commonly used in car-following models. These metrics include:\n1) Mean Squared Error (MSE): The MSE between predicted and observed relative spacing is calculated to quantify the model's ability to accurately predict relative spacing. The MSE is computed using the formula:\nMSE = $\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{T}[y_i(j) - \\hat{y_i(j)}]^2$\nwhere N represents the number of testing events, T denotes the time duration, $y_i(j)$ stands for the observed relative spacing, and $\\hat{y_i(j)}$ represents the predicted relative spacing."}, {"title": "C. Evaluation Metrics", "content": "In this section, we compare the effectiveness of the proposed GenFollower model with five baseline models, including both physics-informed and data-driven approaches:\n1) Gazis-Herman-Rothery (GHR) [45]: GHR is a physics-based safety model that determines the optimal acceleration of a following vehicle based on the driver's reaction time and sensitivity parameters. Parameter calibration is commonly performed using the Genetic Algorithm (GA) [30].\n2) Intelligent Driver Model (IDM): IDM is another classic physics-based car-following model that considers various factors such as the driver's desired speed, desired time headway, maximum acceleration, comfortable deceleration, beta, and jam space. It measures the gap between the driver's expectations and the actual scenario. IDM is widely used in traffic simulation and control due to its simplicity and effectiveness. Similar to GHR, IDM is also calibrated using real-world datasets with GA.\n3) Fully Connected Neural Network (NN): This baseline model utilizes a fully connected neural network architecture, comprising multiple layers of interconnected nodes. The NN model's hyperparameters include the number of hidden layers and neurons in each layer, activation function, learning rate, optimizer, and batch size.\n4) Long Short-Term Memory (LSTM) model: LSTM, is a type of recurrent neural network designed to process sequences of data. Unlike the fully connected neural network, LSTM has several hyperparameters such as the number of LSTM layers, hidden units, and dropout probability.\n5) Deep Deterministic Policy Gradient (DDPG): DDPG [30] has been demonstrated effective in minimizing the discrepancy between simulated and actual actions to emulate human-like driving behaviors. Building upon this foundation, this study introduces DDPGs_Max [44], which incorporates a modified reward function featuring a max operation and collision penalty. This adaptation aims to reduce collisions and improve overall accuracy."}, {"title": "D. Baselines", "content": "Our evaluation on the Waymo Open Dataset reveals valuable insights into the performance of different car-following models. Table I summarizes the results for MSE of Spacing, Collision Rate, and Minimum TTC.\n1) Mean Squared Error (MSE) of Spacing:\n\u2022 NN Model: Achieves the lowest MSE of Spacing at 14.21, indicating lowest average error in maintaining inter-vehicle distances.\n\u2022 GHR Model: Shows the highest MSE of Spacing with 50.22, suggesting less precise control over spacing compared to other models.\n\u2022 GenFollower: Compared to traditional models, our GenFollower achieves lower MSE in a zero-shot setting while ensuring collision-free performance. Our GenFollower demonstrates a balanced performance with zero collisions, competitive MSE, and a good Minimum TTC. This indicates its potential as a viable model for autonomous driving, combining safety with reasonable precision in spacing.\n2) Collision Rate:\n\u2022 NN Model: Exhibits the highest collision rate at 30%, indicating a higher incidence of collisions in simulated scenarios.\n\u2022 GHR, IDM, DDPG, GenFollower (GPT-4) Models: Achieve a 0% collision rate, demonstrating the effectiveness of these models in maintaining safe driving conditions.\n3) Time-To-Collision (TTC):\n\u2022 DDPG Model: Demonstrates exceptional performance with the longest minimum TTC of 162.21 seconds, offering an extensive warning time well ahead of potential collisions. This model excels in ensuring safety margins due to its crafted reward function.\n\u2022 NN Model: Exhibits the shortest minimum TTC among the models evaluated, at 33.69 seconds. While providing a shorter warning time compared to others, it means more aggressive driving behavior.\n\u2022 GenFollower: Shows a balance between maintaining safe distances and achieving reasonable reaction times, as evidenced by its consistently high minimum TTC values. This model leverages its predictive abilities to enhance collision avoidance strategies.\n4) Interpretability of GenFollower: One key advantage of GenFollower is its ability to provide interpretable predictions through a step-by-step analysis process, as illustrated in Figure 7. Unlike black-box models, GenFollower leverages its extensive pre-training on vast datasets to systematically process and integrate complex information from the driving environment. This enables the generation of nuanced insights and well-founded responses based on a comprehensive understanding of the context.\nGenFollower's interpretability is facilitated by its step-by-step analysis process:\n\u2022 GenFollower iteratively analyzes input data, considering various contextual cues and patterns.\n\u2022 Through this process, GenFollower builds up understanding and generates interpretable responses.\n\u2022 Each step involves interpreting and synthesizing information to arrive at a coherent output.\nThis analysis allows humans to not only trust the model's predictions but also gain insights into the underlying reasoning process.\nIn contrast, for the GHR, IDM, NN, LSTM, and DDPG models, we followed the established training procedure outlined in FollowNet [44], involving initial training on a designated training set and evaluation on a curated set of 100 test samples. Notably, our GenFollower (GPT-4) leveraged only prompt engineering techniques. This departure from conventional training paradigms underscores the capacity of large language models to achieve robust performance with either minimal or strategically chosen data inputs. Overall, GenFollower (GPT-4) demonstrates competitive performance with strong interpretability across all metrics, particularly in collision rate and TTC, underscoring its capability to perform effectively in autonomous driving scenarios without the traditional reliance on extensive training datasets."}, {"title": "E. Overall Performance", "content": "Table II presents a comparative analysis of prompt engineering and fine-tuning approaches using GenFollower models based on GPT-3.5 and GPT-4, evaluated on three aforementioned metrics. The GenFollower (GPT-3.5) model achieves an MSE of Spacing of 25.69, a Collision Rate of 8%, and a TTC of 74.31. Fine-tuning the GenFollower (GPT-3.5) improves these metrics, reducing the MSE of Spacing to 22.44 and the Collision Rate to 6%. In comparison, the GenFollower (GPT-4) model outperforms both GPT-3.5 variants, achieving the lowest MSE of Spacing at 20.14, a Collision Rate of 0%, and the highest Minimum TTC of 88.34. These results demonstrate our GenFollower's superior overall performance in maintaining safe distances and minimizing collisions.\nOverall, the GenFollower (GPT-3.5) demonstrates promise in achieving lower MSE even without explicit training on car-following data, particularly when prompted appropriately. Fine-tuning with human driver data further reduced MSE. Notably, the GenFollower (GPT-4) achieves even lower MSE in a zero-shot setting while ensuring collision-free performance."}, {"title": "F. Prompt Engineering vs. Fine-Tuning", "content": "Car-following behavior in traffic dynamics is critical for various applications, including traffic management and autonomous driving systems. In this study, we present GenFollower, a novel car-following model that leverages the power of large language models (LLMs) for improved trajectory prediction and analysis. By leveraging LLMs' ability to process sequential information and extract contextual cues, GenFollower reframes car-following as a language modeling problem and achieves competitive performance in both prediction accuracy and safety with the ability to provide explanations for its predictions on Waymo Open datasets. Notably, our GenFollower model employs a zero-shot approach, foregoing the need for fine-tuning. We harness its inherent common sense reasoning capabilities and self-explanation abilities to address the complexities of car-following behavior.\nIn conclusion, GenFollower represents a pioneering application of LLMs specifically tailored for car-following tasks. It sets a new standard by integrating state-of-the-art language modeling techniques, offering a pathway toward more reliable and interpretable autonomous driving systems."}, {"title": "V. SUMMARY AND CONCLUSION", "content": "Future research directions can build upon the foundation laid by GenFollower to further enhance the field of car-following modeling and autonomous driving systems.\n\u2022 Exploring ways to improve the robustness of GenFollower across diverse driving conditions and environments will be crucial for its practical applicability. This includes investigating adaptation techniques that allow the model to generalize effectively beyond training datasets.\n\u2022 Deploying LLMs on more lightweight models to improve real-time deployment capabilities.\n\u2022 Exploring the generalization capabilities of LLMs across diverse datasets will enhance their robustness and applicability..\n\u2022 Developing better prompts and safety filtering mechanisms to mitigate the occasional generation of invalid responses by LLMs is crucial for improving overall reliability.\nThese efforts will contribute to making LLMs more efficient, reliable, and suitable for a wider range of practical applications in autonomous driving systems."}, {"title": "VI. FUTURE WORK", "content": ""}]}