{"title": "Class Granularity: How richly does your knowledge graph represent the real world?", "authors": ["Sumin Seo", "Heeseon Cheon", "Hyunho Kim"], "abstract": "To effectively manage and utilize knowledge graphs, it is crucial to have metrics that can assess the quality of knowledge graphs from various perspectives. While there have been studies on knowledge graph quality metrics, there has been a lack of research on metrics that measure how richly ontologies, which form the backbone of knowledge graphs, are defined or the impact of richly defined ontologies. In this study, we propose a new metric called Class Granularity, which measures how well a knowledge graph is structured in terms of how finely classes with unique characteristics are defined. Furthermore, this research presents potential impact of Class Granularity in knowledge graph's on downstream tasks. In particular, we explore its influence on graph embedding and provide experimental results. Additionally, this research goes beyond traditional Linked Open Data comparison studies, which mainly focus on factors like scale and class distribution, by using Class Granularity to compare four different LOD sources.", "sections": [{"title": "Introduction", "content": "A knowledge graph is a data system comprising RDF triples structured as 'subject-predicate-object', enabling it to represent real-world entities and their associated relationships. Within the domain of information retrieval (Reinanda et al., 2020) and question-answering (Lan et al., 2021) tasks, knowledge graphs have traditionally assumed a prominent role. More recently, their significance has grown within the field of AI. They are integrated into language models as external repositories of knowledge, thereby augmenting the precision and reasoning capabilities of these models (Schneider et al., 2022). Furthermore, knowledge graphs are harnessed to enrich content-related information within recommendation systems (Shao et al., 2021).\nHowever, the efficacy of knowledge graphs relies on their quality. Consequently, various research efforts have been undertaken to measure the quality of knowledge graphs. In particular, it is essential to consider ontology, which plays a foundational role as the backbone of knowledge graphs. An ontology is a schema that formally declares classes, which represent types of instances, along with the predicates associated with each class and the hierarchical relationships between classes and predicates. Gruber (1993) defines ontology as \"explicit specifications of conceptualizations\". The comparison made in Raad and Cruz (2015) between a machine's knowledge graph and a human's level of knowledge suggests that both are crucial for decision-making. Just as humans rely on their knowledge to make decisions alongside their reasoning abilities, machines also heavily depend on their knowledge graph, or ontology, to enhance their reasoning capacity. For instance, when someone encounters the names \"Let it be\" and \"Hey Jude\", varying levels of comprehension may be observed among different individuals. Some individuals may fail to discern their meaning, while others may categorize them as \"songs\". Furthermore, certain people might even recognize that both songs share the same artist, The Beatles.\nThere are various methods available for measuring the quality of ontology and knowledge graphs. However, in this study, we aim to assess how granular a knowledge graph is using the Class Granularity metric. The granularity of a knowledge graph, in essence, refers to the presence of numerous defined predicates and the high depth and breadth of the ontology. Despite its significance, there has been a lack of research into metrics for measuring granularity and its impact. According to Fern\u00e1ndez et al. (2009), \"in general, richly populated ontologies, with higher depth and breadth variance are more likely to provide reliable semantic content\". Furthermore, in this study, we analyze the impact"}, {"title": "Terminology", "content": ""}, {"title": "2.1 Class", "content": "Class is a \"concept in a domain of discourse\" (Gruber, 1993). Sometimes it is called Concept or Type. For example, Person, Movie and Nation can be classes of open-domain knowledge graph.\nIn ontology, a hierarchy structure is established between classes. This hierarchy is typically defined in the form of \"A - is subclass of - B\", where A represents the subclass and B represents the superclass. For example, in ontology, relationship like \"Athlete - is subclass of - Person\" can be defined where Athlete is the subclass and Person is the superclass. The classes that shares the same direct superclass are sibling classes. For instance, if \"Athlete - is subclass of - Person\" and \"Politician - is subclass of - Person\", Athlete and Politician are sibling classes. The superclass that does not have any parent classes above it is referred to as the root class. In the context of Linked Open Data, this root class is often represented using classes like Entity or Thing."}, {"title": "2.2 Predicate", "content": "Predicate is a \"property of each concept describing various features and attributes of the concept\" (Gruber, 1993). It is also called Property or Attribute. Predicates are associated with each class are defined in the ontology. When there exists a subclass-superclass relationship, the predicates used in the superclass can also be used by the subclass. For instance, if Facility is the superclass of Museum, and Facility has predicates like longitude and latitude, then Museum can also use these properties. Additionally, as a subclass, Museum may have additional properties, such as collection or exhibition size, that are specific to its classification.\nHowever, in real-world knowledge graphs, it's common to find triples that don't strictly adhere to the predicates defined in the ontology. In other words, instances of a class may have triples with properties that are not explicitly defined for that class in the ontology. This flexibility allows knowledge graphs to capture a broader range of information, even if they deviate from the strict definitions in the ontology."}, {"title": "2.3 Instance", "content": "Instance is an entity that can be a subject or object of the triple that consists knowledge graph. It is also called Entity or Individual. For example, \"Mission Impossible\" is an instance and its class is Movie. \"Mission Impossible\" can be a subject of the triple like \"Mission Impossible - cast member - Tom Cruise\" and can be an object of the triple like \"Ethan Hunt - character of - Mission Impossible\"."}, {"title": "Previous Works", "content": "Ontology quality evaluation and Linked Data quality evaluation indeed share common ground in terms of assessing knowledge graph quality. However, they differ in specific metrics and perspectives. One commonality between them is the need for more comprehensive approaches to measure the granularity of data.\nWhile ontology quality evaluation typically focuses on assessing the structure, relationships, and consistency of the ontology itself, Linked Data quality evaluation often concentrates on the quality of data instances and the links between them. Consequently, the specific metrics and criteria they use may differ."}, {"title": "3.1 Ontology Quality Evaluation", "content": "In prior research on ontology quality evaluation, four distinct approaches can be delineated (Lourdusamy and John, 2018; Brank et al., 2005; Raad and Cruz, 2015). Gold Standard Evaluation measures how closely an ontology aligns with a high-quality benchmark ontology when such an ontology is available. Data-Driven Evaluation assesses the extent to which an ontology effectively encapsulates domain-specific information by methods like keyword extraction from the domain's corpus. Application or Task-Based Evaluation examines performance in downstream tasks. Metric-Based Evaluation, also known as structure-based evaluation, employs formula that discern the structure and statistical characteristics of classes and predicates to gauge quality. This study aligns with Metric-Based Evaluation.\nIn structural evaluation, various metrics are employed to compare knowledge graphs. These metrics encompass the \"schema metric,\" the \"instance/knowledgebase metric,\" the \"class metric,\" the \"graph metric,\" and the \"complexity metric.\" (Lourdusamy and John, 2018; Tartir et al., 2005), The Schema Metric assesses the number of classes, properties, and properties per class, with a particular emphasis on the ontology. The Instance/Knowledgebase Metric involves calculating statistics such as the average number of instances per class, taking into account instances within the context of an ontology. In the case of the Class Metric, it involves calculating either the number of instances of the \"Person\" class or the degree of connection of the \"Person\" class with other classes, thereby representing the characteristics of each class. The Graph metric entails the application of fundamental graph theory statistics, including cohesion and cardinality.\nThere were metrics designed to measure the granularity of knowledge graphs, but they had limitations. OntoQA(Tartir et al., 2005) introduces Relationship Richness, Attribue Richness and Inheritance Richiness as Schema Metrics to evaluate ontology's richness. Relationship Richness measures the proportion of predicates that are relationships (e.g.\"subclass of\") relative to the total number of predicates. Attribute Richness calculates the average number of predicates defined per class. Inheritance Richness quantifies the average number of subclasses per class. These metrics do not simultaneously consider both predicates and classes. For example, a high Inheritance Richness score may indicate a high level of ontology granularity, but it does not necessarily imply meaningful granularity unless subclasses have predicates distinct from their superclasses. For instance, even if Athlete is defined as a subclass of Person, if instances of Athlete share the same predicates as Person and do not introduce additional predicates like sports, a high Inheritance Richness score alone may not adequately signify effective granularity.\nThe Density Measure presented in the Alani and Brewster (2006) can also be used to assess the granularity of an ontology. This metric involves calculating the weighted sum of predicates, superclasses, subclasses, and sibling classes for each class in the ontology, and then averaging these values. While it does take into account both classes and predicates, it doesn't provide information about whether the fine-grained classes or predicates are actually used in instances. Therefore, it cannot determine whether the knowledge graph effectively reflects a finely-grained ontology. Class Granularity measures how many classes have added predicates that are not defined for superclass, and whether these added predicates are employed within instances.\nPrevious works suggest important dimensions to consider when evaluating ontologies: Accuracy, Completeness, Conciseness, Adaptability, Clarity, Computational efficiency and Consistency (Vrandecic, 2009; Obrst et al., 2007; G\u00f3mez-P\u00e9rez, 2004; Gangemi et al., 2006). High Class Granularity is related to high Completeness as Completeness \"measures if the domain of interest is appropriately covered in this ontology (Raad and Cruz, 2015)\". However, in the context of Adaptability, which \"measures how far the ontology anticipates its uses (Raad and Cruz, 2015)\", high Class Granularity can have a negative impact. This becomes particularly relevant when the schema is designed for future utilization but unused in instances yet. Regarding four quality categories (Content, Language, Methodology, Tools) of OntoMetric(Lozano-Tello"}, {"title": "3.2 Linked Data Quality Evaluation", "content": "Linked Open Data is a concept related to making data freely available and easily accessible on the internet in a structured and interlinked manner. Wikidata, DBpedia, YAGO, and Freebase are well-known examples of Linked Open Data (LOD) sources. Many studies comparing the quality of Linked Open Data (LOD) primarily focus on comparing the scale of triples, the distribution of classes and predicates within the data, the depth of ontologies, and the incoming/outgoing degree of data entities.(Ringler and Paulheim, 2017; F\u00e4rber and Rettinger, 2018; Heist et al., 2020)\nFurthermore, in Zaveri et al. (2016), four dimensions were introduced to assess the quality of Linked Data, namely the Accessibility dimensions, Intrinsic dimensions, Contextual dimensions and Representational dimensions. These dimensions were further categorized into subcategories as in Table 1, with recommended metrics for their measurement. Other studies (Debattista et al., 2018, 2016; Ringler and Paulheim, 2017) applied the framework to conduct a comparative analysis of Linked Data. While this framework provides a much richer analysis compared to previous comparative studies, it does not include an analysis of the granularity of ontologies within each Linked Open Data (LOD) source and how well this granularity is reflected in the actual RDF data. Among the metrics introduced in Zaveri et al. (2016), IN3 is a metric within the Interpretability dimension which quantifies the \"invalid usage of undefined classes and properties\". It is similar to Class Granularity in that it considers Linked Data's ontology and its instantiation. However, it cannot measure the level of granularity in the data. In this study, we provide Class Granularity for Wikidata, DBpedia, YAGO, and Freebase, allowing us to compare the level of granularity in LOD (Linked Open Data) that has not been addressed in previous research."}, {"title": "Class Granularity", "content": ""}, {"title": "4.1 Definition", "content": "Class Granularity is a metric that can measure how detailed the ontology of a knowledge graph is and how well it reflects the actual knowledge graph composed of RDF triples. In this section, the definition of the Instance with Distinct Predicate Proportion Average for calculating Class Granularity is first provided, followed by the introduction of the formula for Class Granularity."}, {"title": "4.1.1 Instance with Distinct Predicate Proportion Average", "content": "Instance with Distinct Predicate Proportion Average (IDPPA) is the average of Instance with Distinct Predicate Proportion, so Distinct Predicate and Instance with Distinct predicate proportion (IDPP) should be defined first. We define distinct predicates of a specific class as predicates that do not exist in the ontology-defined superclass or sibling classes but are present in the specific class. For example, if Athlete is a subclass of Person and Politician and Artist are sibling classes, and Athlete has its unique predicates like sport and position played on the team that are not found in Person, Politician, or Artist, then these predicates are considered as distinct predicates. Distinct predicates serve the role of adding unique characteristics to a class. IDPP of a specific distinct predicate within a particular class is the proportion of instances that possess the predicate in the total instances in that class.\nEach class's IDPPA represents the average of IDPP for its distinct predicate. For instance, if the Athlete class has two distinct predicates, namely sport and position played on the team, and if 90% of Athlete instances have the predicate sport (e.g., Michael Jordan - sport - basketball), and 50% have the predicate position played on the team (e.g., Lionel Messi - position played on the team - forward), then the IDPPA for Athlete is calculated as (0.9 +0.5)/2 = 0.7.\nHowever, to prevent the indiscriminate addition of duplicate predicates to all classes, a penalty is applied in the calculation of IDPPA. Distinct predicates should be predicates that differentiate the class from others. Therefore, for instance, defining birth place under Athlete rather than its superclass Person, or defining member of political party under Athlete instead of its sibling class Politician, may not be desirable. Classes should have distinct characteristics from their superclass and sibling classes. If a superclass or sibling class of a certain class has a higher proportion of instances with distinct predicates than that class itself, the IDPP is treated as 0. This is because even though distinct predicates are defined for that class, they are actually more prominently associated with superclass or sibling classes, and they do not serve as distinguishing features for that class. Expanding on the previous example, if the ratio of position played on the team in the Person class is 0.8, which is higher than the 0.5 in Athlete, it may not represent a unique characteristic of Athlete. In this case, the IDPPA for Athlete would be calculated as the average of 0.9 for sport and 0 for position played on the team, resulting in (0.9+0)/2 = 0.45.\nFinally, equations 1 and 2 represent the formulas for calculating IDPPA. In equation 1, IPP stands for Instance with Predicate Proportion, where IPP(P|C) is the ratio of instances in a specific class C that have a particular predicate P when class C is given. In equation 1, DP stands for Distinct Predicate of class C, and RC represents Related Class, which includes C's superclass and sibling classes. IPR(DP|RC)max is the value when among C's related classes, the ratio of instances containing DP is the highest. In equation 2, Ndp denotes the number of distinct predicates for class C, and dpi represents the i-th distinct predicate.\nIDPP(DP | C) = \\begin{cases} IPR(DP|C) & \\text{when } IPR(DP|RC)_{\\text{max}} < IPR(DP|C) \\\\ 0 & \\text{when } IPR(DP|RC)_{\\text{max}} > IPR(DP|C) \\end{cases}\nIDPPA(C) = \\begin{cases} \\frac{\\sum_{i=1}^{N_{dp}} IDPP(dp_i | C)}{N_{dp}} & \\text{when } N_{dp} > 0 \\\\ 0 & \\text{when } N_{dp} = 0 \\end{cases}"}, {"title": "4.1.2 Class Granularity", "content": "Class Granularity is the average of IDPPA calculated for all classes except the root class in the ontology. In cases where only the root class exists, Class Granularity is 0 because it signifies a complete lack of granularity or subclassification in the ontology. Equation 3 represents the formula for calculating Class Granularity.  Nc signifies the total number of classes in the ontology, and when N = 1, it indicates a scenario where only the root class exists. ci represents the i-th class in the ontology.\nClass Granularity = \\begin{cases} \\frac{\\sum_{i=1}^{N_C-1} IDPPA(c_i)}{N_C-1} & \\text{when } N_C > 1 \\\\ 0 & \\text{when } N_C = 1 \\end{cases}"}, {"title": "Calculation Example", "content": "This section demonstrates through examples that as the ontology becomes more finely defined, Class Granularity increases. Consider a knowledge graph consisting of 5 instances and 9 triples, as shown in Table 2 (The IDs like \"Q714\" and \"P161\" within the parentheses are actual identifiers used in Wikidata.). In this knowledge graph, Class Granularity can be calculated for both a \"less granularity ontology (ontology A)\" with 3 classes and a \"more granularity ontology (ontology B)\" with 9 classes which is depicted in Table 3. Both ontologies have Creative Work as the root class. Additionally, when a class has subclasses, the instances of that class are considered to include instances from its subclasses. For instance, the instances of Creative Work encompass both the instances of Audio Work and Visual Work.\nThe Class Granularity for the \"less granularity ontology\" is calculated as follows: First, calculate the IDPPA for class Audio Work and class Visual Work, excluding the root class. For the distinct predicates of class Audio Work, compare the IPR (Instance with predicate proportion) of each predicate with the IPRs of the related classes class Creative Work (a superclass) and class Visual Work (a sibling class). For predicate performer, class Audio Work's IPR is (as both \"News of the World\" and \"Isn't She Lovely\" have this predicate), class Cre"}, {"title": "Characteristics of the Metric", "content": "This section examines the properties of Class Granularity as a data quality metric. According to Heinrich et al. (2018), a data quality metric that possesses the properties of the \"existence of minimum and maximum metric values\" and \"the interval scaling of metric values\" is considered \"inherently interpretable in terms of the measurement unit\" and can be represented as a percentage. Class Granularity meets both of these"}, {"title": "4.3.1 Minimum and Maximum", "content": "Class Granularity has a minimum value of 0 in three cases: First, when only the root class is defined in the ontology. Second, when classes are defined and subdivided, but there are no instances of those classes in the knowledge graph. Third, classes are defined, instances exist, but distinct predicates are not used. In all of these cases, it is difficult to consider the ontology as well-reflecting and sufficiently subdividing the knowledge graph. The maximum value of Class Granularity is 1. This occurs when, for every class defined in the ontology, all instances of that class possess the class's distinct predicates."}, {"title": "4.3.2 Interval Scale", "content": "Class Granularity exhibits the characteristics of an interval scale. According to Allen and Yen (2001), it is always possible to achieve a transformation between any two interval scales by implementing a positive linear change of the type x \u2192 ax + b (where a > 0). Class Granularity represents the average ratio of how extensively distinct predicates are being used for each class. When Class Granularity increases from 0.5 to 0.6 and from 0.6 to 0.7, the interval retains the same meaning."}, {"title": "When Class Granularity Is Helpful?", "content": "As seen in 4.2, the higher the Class Granularity, the more easily one can anticipate the structure of the knowledge graph just by examining the ontology. Additionally, a higher Class Granularity implies that classes possess distinct characteristics and are well-subdivided. This section provides a more detailed examination of downstream tasks related to Class Granularity."}, {"title": "5.1 Graph Embedding", "content": "There have been studies showing that incorporating rich ontology information can lead to improved performance in knowledge graph embeddings (Jain et al., 2021; Li et al., 2023; Diaz et al., 2018). This section aims to demonstrate through experiments that when an ontology is well-defined with granularity, important concepts can be embedded in a similar space during the utilization phase, which can be beneficial. For instance, if individuals with similar professions are intended to have similar embedding values, then subdividing the Person class into various professions can achieve this goal."}, {"title": "5.1.1 Experiment Settings", "content": "RDF triples are obtained from Wikidata triples with human entities as subjects. An experimental knowledge graph is constructed by extracting 2-hop relations. Then, comparison was made by assigning classes to entities based on three different ontologies, as shown in Table 4. For class assignments, Person is assigned when an entity is an instance of human (Q5) in Wikidata and Thing otherwise. For the subdivided classes like Actor and Athlete, occupation (P106) property is referred. Based on the class assignments, RDF triples are added in the form of \"entity - instance of (P31) - class\" to the graph. For instance, entities that are instances of Actor in Example3, become instances of Artist in Example2 and become instances of Person in Example3. TransE model (Bordes et al., 2013) provided by pykeen\u00b9 1.10.1 with default training parameters is used for graph embedding."}, {"title": "5.1.2 Graph Embedding Results", "content": "Table 5 and Figure 1 display the graph embedding results. Embeddings for each example were adjusted using standard scaling. Table 5 illustrates"}, {"title": "5.2 Knowledge Graph Resoning and Question Answering", "content": "Knowledge graph reasoning is the task of utilizing existing information to discover unknown relationships within the graph. This task is often performed using rule-based approaches with ontology or graph embedding-based link prediction methods. Researches like Zhang et al. (2019); Liu et al. (2021); Kaoudi et al. (2022) have shown that combining ontology-based reasoning and embedding-based link prediction can enhance the performance of reasoning. Highe Class Granularity can have a positive impact on ontology-based reasoning.\nOntology-based reasoning involves creating rules based on the information in the ontology to generate new triples. Having predicates divided into specific classes allows for the generation of rules as finely as needed. For example, someone may want to create rules from the ontology like the following.\nVx, y, z \u2208 E:\n\\(x, ownerOf, y\\),\n\\(y, industry, z\\) \u2192\n\\(x, relatedIndustry, z\\)\nHowever, applying such rules to all entities of every class can lead to many unnecessary instances. In this case, if the Person class is classified as a subclass of Entrepreneur, then the rule can be selectively applied to relevant Entrepreneurs, making it more useful. This way, the rules can be more targeted and efficient in their application.\nThe ability to add finely-grained reasoning rules can also be beneficial for Knowledge Base Question Answering(KBQA) tasks. Even in situations where there are no triples in the knowledge graph, having axioms created through ontology's class and predicates can provide answers. This approach is utilized in many KBQA researches (Li et al., 2019; Abdi et al., 2018; Manna et al., 2017; Fawei et al., 2019). For instance, when answering a question like 'Who is an athlete born in America?' if people whose occupation is athlete only have triples"}, {"title": "5.3 Named Entity Disambiguation", "content": "There are researches focusing on matching text to knowledge graphs, such as NED (Named Entity Disambiguation) or entity linking in fields such as medicine (Skreta et al., 2021; Mondal et al., 2020) , biology (Mohan et al., 2021; Halioui et al., 2018; Farazi et al., 2018), chemistry (Wang et al., 2021, 2019). If there are multiple knowledge graphs in the same domain that can link entities with text, performance of NED can be anticipated the by referring to the value of Class Granularity. A high Class Granularity indicates that entities are divided into various subfields, and they possess the distinct characteristics of those subfields in the form of triples. For example, in the example previously mentioned in Table 3, when Class Granularity is high, Music Song's instances have more attributes related to songs, and Movie's instances have more attributes related to movies. Therefore, when there is an ambiguity word like 'Love', in a high Class Granularity setting, the movie 'Love' would have movie-related attributes, and the song 'Love' would have song-related attributes, making disambiguation easier."}, {"title": "6 Class Granularity of Linked Open Data", "content": "Table 6 provides basic statistics and class granularity calculation results for Freebase, YAGO, and DBpedia. This comparison shows how richly the ontologies are defined in each Linked Open Data (LOD) source and how well they represent the knowledge graph with RDF triples, addressing aspects that have not been extensively explored in previous research on LOD comparison analysis. The process of obtaining RDF triples and ontologies for each LOD is detailed in the Appendix A. For each dataset, we filtered only the entities that are instances of classes defined in the ontology among the RDF triples. In cases where obtaining the ontology that defines predicates was challenging, we extracted predicates used for each class from the triples. In addition to LOD, we also conducted a quantitative comparison for Naver's knowledge graph, Raftel, a knowledge graph constructed by consolidating Wikidata's ontology.\nWhen analyzing the results from Table 6, looking at Class Granularity alongside basic metrics such as the number of classes and predicates allows for a more multidimensional understanding of knowledge graphs. For example, when comparing DBpedia and YAGO, DBpedia has more classes and predicates, but its Class Granularity is lower. By only considering the quantity, one might conclude that DBpedia has richer information. However, when taking Class Granularity into account, it becomes apparent that, relative to the variety of predicates, DBpedia actually has a lower proportion of entities with those predicates. On the other hand, YAGO has fewer predicates in use, but its Class Granularity is higher, with an average of 2.779 entities per class having distinct predicates, which is higher than DBpedia. Having a high Class Granularity doesn't necessarily imply superiority, but it does provide a way to gauge how well classes possess distinct characteristics beyond just their quantity, which is often hard to evaluate solely based on the number of classes and predicates.\nFor the class Book, DBpedia has a wider variety of distinct predicates such as shortSummary, theme, and screenplay, with each of these predicates having instance ratios of 0.00004, 0.00004, and 0.0001, respectively within the class Book. In contrast, YAGO has fewer predicates for the class Book, but it has higher instance ratios for predicates like about (0.17) and contentLocation(0.016), indicating that these predicates are more commonly associated with instances of the class Book in YAGO. Specifically, for the common property publishedDate, DBpedia has an instance ratio of 0.00024, while YAGO has a higher instance ratio of 0.43879, indicating that a larger proportion of Book's instances in YAGO have this property."}, {"title": "Conclusion and Future Work", "content": "In this study, we introduced Class Granularity as a metric for assessing the extent to which classes are finely detailed in knowledge graphs and ontologies. We also highlighted scenarios where this metric can be beneficial. However, it's important to note that higher Class Granularity is not always better in every context. For instance, in cases where an ontology is designed with predefined classes and predicates to accommodate future data, even if there are no actual instances, the Class Granularity may be relatively low but can enhance flexibility when new data is added.\nClass Granularity is significant because it quantifies the \"structural richness\" in knowledge graph quality, which has not received as much attention in previous research. Future studies could explore the correlations between Class Granularity and other dimensions of quality metrics to gain a deeper understanding of how various quality indicators interact in knowledge graphs. Additionally, research could investigate a broader range of knowledge graph applications that may be influenced by changes in Class Granularity."}, {"title": "A The process of extracting LOD and their ontologies", "content": "This metric was evaluated by 4 Linked Open Data: DBpedia, YAGO, Freebase, and Wikidata. The characteristics of each Linked Open Data and the way it is stored are different, and we will explain them in detail below."}, {"title": "A.1 DBpedia", "content": "DBpedia is a well-known project in the Linked Open Data community. Its inauguration took place in 2007 with the collaboration of the Free University of Berlin and the University of Leipzig. It is created by automatically extracting structured information contained in Wikipedia, and it builds and manages its own ontology structure.\nThe most recent data from DBpedia is accessible via https://databus.dbpedia.org/ dbpedia/collections/latest-core and the version \"2022.12.01\" was used for the calculation. The ontology data (ontology--DEV_tag= sorted_type=parsed.nt) and RDF triple data (infobox-properties_lang=en.ttl.bzip2, instance-types_inference=specific_lang= en.ttl.bzip2) have been obtained from their respective pathways, with the exception of when the object part is left empty. Moreover, we have excluded cases where the ontology name is in unicode characters."}, {"title": "A.2 YAGO", "content": "Developed by Max Planck in 2007, YAGO is generated by extracting information from Wikipedia infobox and WordNet in various languages. The ontology structure is built on WordNet.\nThe most recent YAGO data can be accessed via https://yago-knowledge.org/data/yago4/ full/2020-02-24 and the version \"2020-02-24\" was used as stated in the link. As with DBpedia, the ontology data(yago-wd-schema.nt.gz) and RDF triple data(yago-wd-facts. nt.gz, yago-wd-labels.nt.gz, yago-wd-class.nt.gz, yago-wd-sameAs. nt.gz, yago-wd-full-types.nt.gz, yago-wd-simple-types.nt.gz) have been obtained with the exception of when the object part is left empty."}, {"title": "A.3 Freebase", "content": "Freebase was launched by MetaWeb Technologies, Inc. in 2007 and merged into Wikidata by the Wiki- media Foundation and Google in 2015. Ontology is constructed in a human-readable manner with the structure of 'domain/class/predicate'.\nAlthough the official site states that the data dump is no longer updated since 2015, the information available from Freebase can be accessed via http: //developers.google.com/freebase and the link for the data is http://commondatastorage. googleapis.com/freebase-public/rdf/ freebase-rdf-latest.gz.\nSince the ontology data and RDF triple data were consolidated into a single file, the ontology data was extracted using specific criteria. These criteria entailed selecting triples where the predicate was http://www.w3.org/1999/ 02/22-rdf-syntax-ns#type and the object was either http://www.w3.org/2002/07/owl# FunctionalProperty or http://www.w3.org/ 2000/01/rdf-schema#Property. RDF triple data containing a corresponding list of instances pertaining to topics were extracted and defined as ontology data.\nFurthermore, as there is no hierarchical relationship between classes in Freebase, a virtual root class called \" was created in order to add a hierarchical relationship in the ontology data. Also, as class information for a particular instance was obtained from other knowledge graphs using a predicate known as   Michael Jack- son), we reversed the subject and object by employing a predicate referred to as . We have renamed the  predicate to  to create a predicate with a matching definition as ."}]}