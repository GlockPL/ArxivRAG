{"title": "Cobblestone: Iterative Automation for Formal Verification", "authors": ["Saketh Ram Kasibatla", "Arpan Agarwal", "Yuriy Brun", "Sorin Lerner", "Talia Ringer", "Emily First"], "abstract": "Formal verification using proof assistants, such as Coq, is an effective way of improving software quality, but it is expensive. Writing proofs manually requires both significant effort and expertise. Recent research has used machine learning to automatically synthesize proofs, reducing verification effort, but these tools are able to prove only a fraction of the desired software properties. We introduce COBBLESTONE, a new proof-synthesis approach that improves on the state of the art by taking advantage of partial progress in proof synthesis attempts. Unlike prior tools, COBBLESTONE can produce multiple unsuccessful proofs using a large language model (LLM), identify the working portions of those proofs, and combine them into a single, successful proof, taking advantage of internal partial progress. We evaluate COBBLESTONE on two benchmarks of open-source Coq projects, controlling for training data leakage in LLM datasets. Fully automatically, COBBLESTONE can prove 48% of the theorems, while Proverbot9001, the previous state-of-the-art, learning-based, proof-synthesis tool, can prove 17%. COBBLESTONE establishes a new state of the art for fully automated proof synthesis tools for Coq. We also evaluate COBBLESTONE in a setting where it is given external partial proof progress from oracles, serving as proxies for a human proof engineer or another tool. When the theorem is broken down into a set of subgoals and COBBLESTONE is given a set of relevant lemmas already proven in the project, it can prove up to 58% of the theorems. We qualitatively study the theorems COBBLESTONE is and is not able to prove to outline potential future research directions to further improve proof synthesis, including developing interactive, semi-automated tools. Our research shows that tools can make better use of partial progress made during proof synthesis to more effectively automate formal verification.", "sections": [{"title": "I. INTRODUCTION", "content": "Bugs in software systems can be costly and dangerous. In 2022, poor software quality cost the US economy $2.41 trillion [35], and bugs can bring down critical, global systems [45]. Formal verification using proof assistants, such as Coq [70] or Lean [16], is a promising method of improving software quality. It can be used to mathematically prove the absence of entire classes of bugs, providing strong guarantees for the correctness of critical software systems. And formal verification is highly effective: A study [81] of C compilers found bugs in every tested compiler, including LLVM [37] and GCC [68], but not in the formally verified (in Coq) portions of CompCert [40]. But, formal verification requires specifying desired properties, writing mathematical proofs of the properties, and machine checking those proofs using the proof assistant. Writing these proofs requires significant expertise and manual effort. For example, the proofs verifying CompCert are 8 times longer than the functional code [39], and even small changes to the software can require heavy proof editing [58]. While hundreds of large software systems have been verified [58], including the sel4 microkernel [34], [51] and CakeML [36], most produced software today is not verified due to the high manual cost.\nRecent research has aimed to reduce the cost of formal verification by using machine learning to synthesize verification proofs [19]\u2013[21], [55], [62], [63], [79]. Unfortunately, these approaches, even when combined with a hammer-based approach [14] that calls out to SMT solvers to generate low-level proofs, can only prove one third of the desired properties on a large benchmark of open-source Coq projects [19].\nIn this paper, we present COBBLESTONE, a novel large-language-model-based (LLM) divide-and-conquer approach to software verification proof synthesis that improves on the state of the art by taking advantage of partial proof progress, such as failed proof attempts or plans for structuring the proof. The proofs COBBLESTONE generates are guaranteed to be sound, despite reliance on an LLM, because the proof assistant machine checks each proof, rejecting errors or hallucinations.\nThere are multiple types of partial proof progress that COBBLESTONE can take advantage of. For example, \u0421\u043e\u0432-BLESTONE can internally generate multiple potential proofs using an LLM, identify which parts of those proofs can be useful as part of a complete proof, and combine those parts to produce a whole, successful proof when prior work could not."}, {"title": "II. THE COBBLESTONE APPROACH", "content": "Given a theorem, COBBLESTONE iteratively uses an LLM to attempt to generate a proof for that theorem. Figure 1 overviews the COBBLESTONE approach. First, given a theorem, COBBLESTONE samples an LLM for an initial proof attempt, using that theorem and context (such as definitions or lemmas) (Section II-B). Next, COBBLESTONE uses the theorem prover to check whether the proof successfully proves the theorem, and, if not, localizes its errors (Section II-C). COBBLESTONE then attempts to repair the proof using a hammer (Section II-D). COBBLESTONE recurses on the parts of the proof that error localization identifies as incorrect but which the hammer cannot repair (Section II-E).\nCOBBLESTONE can use external information that may be relevant to a theorem, for example, from another tool"}, {"title": "A. Illustrative Example", "content": "In Coq, a programmer can write a theorem about their code and then attempt to prove that the theorem holds true. To construct a proof, they write a proof script, made up of high-level commands called tactics, such as induction. Each tactic invocation transforms the proof state, which contains the goals to prove and context of assumptions. The proof state starts with a single goal: the theorem itself. Tactics can decompose a goal into multiple goals or prove a goal. When there is more than one goal, we refer to them as subgoals. When the proof state has no more goals, the theorem is proven.\nFigure 2 shows an example of the theorem eqlistA_Eeq_eq from Graph.v in the coq-wigderson project. After the theorem statement (line 1) is the human-written proof script (lines 2\u20137), where Proof and Qed introduce and complete the proof, respectively."}, {"title": "B. Sampling Whole Proofs", "content": "COBBLESTONE starts by sampling whole proofs from an instruction-tuned LLM [54]. The prompt we send to the LLM consists of two strings\u2014a system message with high-level directions about the task the LLM should perform, and a user message with details specific to the current theorem. The system message directs the LLM to produce a whole proof for the provided theorem, and the user message contains the following information:\n\u2022 the theorem statement COBBLESTONE is trying to prove, the current proof state\n\u2022 definitions for all identifiers mentioned in the theorem statement and proof state that are not part of the standard library, and\n\u2022 contextual information.\nEach piece of information is preceded by a section header, which states what follows. For example, for the theorem"}, {"title": "C. Error Localization", "content": "Next, COBBLESTONE uses the Coq theorem prover to check the correctness of the generated proofs. If at least any one of them proves the theorem, COBBLESTONE returns that proof. However, if the generated proofs are all incorrect, COBBLESTONE uses the theorem prover to localize the errors"}, {"title": "D. Repair with Hammer", "content": "CoqHammer (hammer) is an automation tactic, invokeable without arguments, that uses a combination of SMT solvers and proof reconstruction procedures to prove the current goal. COBBLESTONE uses CoqHammer in two places. First, as shown in Figure 1, COBBLESTONE tries invoking CoqHammer at the beginning of every call. If CoqHammer is able to prove the goal, then COBBLESTONE has succeeded, and does not need to do anything further.\nSecond, after fail-safe mode runs, wherever an admit tactic is used, COBBLESTONE tries executing a version that replaces admit with the hammer tactic. If this version succeeds, the admit is changed to a call to hammer."}, {"title": "E. Recursively Invoking COBBLESTONE", "content": "After fail-safe mode and repair with a hammer are finished, results can be grouped into 3 categories. A result is a failure when its prefix cannot be run successfully. COBBLESTONE cannot use these any further, and thus dicards them.\nIt is a success when its prefix can be run successfully, and all of its subproof_results are also successes, i.e. when every tactic in the recursive structure can be run without error. The prefixes in these results can be combined to form a proof of the theorem, which COBBLESTONE returns.\nPartial successes, results that are not successes or failures, can potentially be changed into successes. They have prefixes that run successfully, but have 1 or more subproof results which are either failures themselves, or contain failures deeper in their recursive structure.\nCOBBLESTONE attempts to change these partial successes into successes by walking through the result's subgoals (and sub-subgoals and so on) in a depth-first manner. When it encounters a failure, it has found a subgoal that the current proof script cannot dispatch, along with a localized portion of the proof that fails.\nCOBBLESTONE then attempts to find a new proof for such subgoals by recursively invoking itself with the subgoal as its proof context. If this recursive invocation generates a proof,"}, {"title": "F. Applying COBBLESTONE to the Illustrative Example", "content": "We now demonstrate how the COBBLESTONE approach works on an example, namely, proving the eqlistA_Eeq_eq lemma from the coq-wigderson benchmark suite. Figure 4 displays the different steps a sampled proof script undergoes to become a completed proof script.\nCOBBLESTONE queries the LLM to generate an entire proof, where the outputted proof is shown in A. The Coq code displayed in red is code that fails with an error, and so here, both subgoals fail in the sense that they have errors in them.\nInB, COBBLESTONE recurses on the first failing subgoal generated from A, by querying the LLM to generate a proof for that subgoal alone. The generated proof has a failing part, namely apply IHForall2. When fail-safe mode encounters this error, it calls hammer, which succeeds, solving that subgoal.\nIn, COBBLESTONE recurses on the second failing subgoal from A. In this case, a call to hammer dispatches the subgoal.\n\u25b7 shows the final working proof. It uses the scripts from \u25c9 and to dispatch the failing subgoals from A. Notably, it integrates portions of two separate LLM completions and two invocations of hammer into a cohesive proof."}, {"title": "III. EVALUATION", "content": "We evaluate COBBLESTONE on two datasets of theorems from open-source Coq projects and compare to two state-of-the-art proof-synthesis tools CoqHammer, Proverbot9001, and a baseline Chain-of-thought-based approach we call Chain-OfThought. Our evaluation answers five research questions:"}, {"title": "B. RQ1: How Does COBBLESTONE Compare to State-of-the-Art Proof Generation Methods?", "content": "Figure 5 shows the success rates for CoqHammer, Chain-OfThought, Proverbot9001, and COBBLESTONE, as well as the combination of the three prior tools (CoqHammer, ChainOfThought, and Proverbot9001), and of all four tools together. On CoqGym100, Cobblestone proves 48% of the theorems, whereas prior tools prove no more than 30% individually, and 38% all together. Recall that the evaluation on CoqGym100 likely suffers from test data leakage for example, ChainOfThought proves fewer theorems on Wigderson100 (17%) than on CoqGym100 (22%). Still, for CoqGym100, Cobblestone adds 34.2% additional value than the combination of the three prior tools, meaning that COBBLESTONE proves 34.2% more theorems than the three prior tools together.\nOn Wigderson100, COBBLESTONE proves 38% of the theorems, which is similarly more than each of the prior tools and all the prior tools combined. It proves an additional 21.9% of theorems compared to the prior tools combined. (Note that value added is not as simple as the difference between two tools'"}, {"title": "C. RQ2: How Much Does CoqHammer Contribute to COBBLESTONE's Performance?", "content": "COBBLESTONE invokes CoqHammer (recall Section II) to help synthesize proofs. To measure the impact of CoqHammer on COBBLESTONE's performance, we implement an ablated version of our tool named COBBLESTONE-NoHammer, which acts identically to COBBLESTONE, but makes no hammer calls. Figure 6 shows that CoqHammer plays an important role. On CoqGym100, COBBLESTONE-NoHammer only proves 25% of the theorems, while COBBLESTONE proves 48%. On Wigderson100, COBBLESTONE-NoHammer only proves 16% of the theorems, while COBBLESTONE proves 38%. CoqHammer helps COBBLESTONE prove 96.0% and 137.5% more theorems than COBBLESTONE-NoHammer, on the two benchmarks, respectively.\nEven combining running CoqHammer just once on the theorem improves ChainOfThought's success rate significantly: from 22% to 36% for CoqGym100 and from 17% to 31% for Wigderson100.\nWe conclude that CoqHammer and COBBLESTONE are significantly complementary. Recall from RQ1 and Figure 5"}, {"title": "D. RQ3: How Much Does COBBLESTONE's Search Strategy Contribute to Its Performance?", "content": "A key novelty of COBBLESTONE's proof search strategy is that it operates on whole proof completions. By contrast, most neural theorem provers synthesize proofs using tactic-by-tactic search, predicting the next tactic and using a tree search method (typically depth-first or beam search) to search through the tactic space [19], [20], [62], [63], [79]. It also differs from other LLM-based methods, such as Baldur [21], that use samples from an LLM, unmodified.\nTo measure the effectiveness of COBBLESTONE's search procedure, we implement another tool called TacticByTactic that, like COBBLESTONE, has use of the hammer, but uses GPT-4 to predict only the next tactic at each step of its search. While inefficient, TacticByTactic attempts the hammer tactic at each step of its search.\nWe run TacticByTactic, and TacticByTactic-NoHammer, a variant that does not use hammer, with a maximum proof depth of 20, and 3 attempts to predict the next tactic at each step. Since each prediction attempt results in one call to the LLM, this gives these tools the same number of LLM samples as COBBLESTONE.\nFigure 7 shows that without using CoqHammer, TacticByTactic-NoHammer underperforms all prior tools on Wigderson100 and CoqGym100. With calls to CoqHammer,"}, {"title": "E. RQ4: How Does External Information Affect COBBLESTONE's Performance?", "content": "Recall that COBBLESTONE has the ability to use external progress from another tool or a human. As a proxy for external progress, we created two oracles that provide partial proof information. For each theorem, the perfect premises oracle (PerfPrems) knows the set of lemmas already proven in the project that the human-written proof for this theorem uses. Meanwhile, the perfect decomposition oracle (PerfDecomp) knows the set of subgoals the human-written proof proves. Specifically, PerfDecomp provides a decomposing prefix (recall Section II-C) from the human-written proof, helping COBBLESTONE break the theorem into subgoals. Using the PerfPrems oracle is equivalent to asking a human (or a tool) \"What lemmas are relevant to proving this theorem?\" and using the PerfDecomp oracle is equivalent to asking \"How would you break down this theorem into smaller goals?\"\nWe next evaluate COBBLESTONE with access to these oracles,"}, {"title": "F. RQ5: Qualitative Analysis of Theorems COBBLESTONE Proves and Fails to Prove", "content": "To better understand some cases where COBBLESTONE succeeds, we manually examined the proofs that COBBLESTONE, COBBLESTONE-PerfPrems, and COBBLESTONE-PerfDecomp generate for the theorems than prior tools fail to prove. To better understand when COBBLESTONE fails, we also examined the human-written proofs for some of the theorems they were unable to prove.\nSuccesses: The 20 theorems that COBBLESTONE proves over the prior tools (7 in CoqGym100 and 13 in Wigderson100) use an average of 9.7 tactics each. These include invocations to CoqHammer and of tactics generated by the LLM. Each proof contains parts of up to 5 LLM samples, with an average of 4 tactics used from each sample."}, {"title": "G. Threats to Validity", "content": "All evaluations of LLMs suffer from potential leakage of test data into the LLM's pretraining dataset. Overlaps between training and test data result in inaccurate measurements of models' effectiveness that fail to generalize to unseen data. We mitigate this risk by using the coq-wigderson, whose first commit on GitHub is on March 2022, after GPT-4's publicly stated pretraining cutoff date of September 2021. Still, we cannot know for certain that coq-wigderson is not in the GPT-4 pretraining data.\nOur evaluation required numerous LLM queries, which can be expensive. The cost of just the LLM usage for our evaluation, including the ablation studies, exceeded US$3K. To manage this cost, we evaluated on a total of 200 theorems sampled from public benchmarks, which is a typical test set size for such studies [9]. Evaluations on larger datasets provide better confidence that the results generalize."}, {"title": "IV. RELATED WORK", "content": "Recent work in automating theorem proving in proof assistants has mostly explored three overarching approaches: hammers, machine learning techniques, and a combination of the two. Hammers, such as CoqHammer [14] and Sledgehammer [56], call out to SMT solvers, such as E Prover [65] and Z3 [15], to construct low-level proofs. However, hammers cannot use induction, and so are limited in what they can prove on their own. Our evaluation has shown that our approach can often prove theorems CoqHammer fails to prove on its own.\nMachine learning techniques typically use a predictive model learned from a corpus of existing proofs to predict the next likely steps of a proof, such as a tactic, and then use these predictions to guide a search through the space of potential proofs [42]. These techniques are called neural theorem provers and have been built using RNNs [28], [62], LSTMs [19], [20], [79], GNNs [5], [7], and more recently, transformer-based LLMs [31], [80]. The methods that use LLMs are pretrained on a large corpus and then prompt the model zero-shot or with few-shot examples [32], [85], fine-tune the model on proof data [21], or use it as an agent [69], [74].\nPrior work has shown that hammers and machine learning techniques are complementary [19], [30], and that performance can be improved if they are combined in new ways. Thor [30] fine-tunes an LLM to learn when to apply Sledgehammer to solve a subgoal versus when to predict something from the tactic language. By contrast, COBBLESTONE does not use a fine-tuned LLM, samples whole proofs rather than tactics, and its calls to the hammer are not predicted.\nWith a focus on formalizing mathematics, DraftSketchProve (DSP) [32] uses informal proofs as drafts for an LLM to translate into a formal proof sketch with holes, filling in the holes with calls to Sledgehammer. Lyra [87] improves on DSP with correction mechanisms that fix incorrect tool usage and conjectures. Continuing to improve upon DSP, LEGO-prover [74] augments an LLM with a skill library that grows throughout proof search, while other work [86] focuses on rewriting informal proofs to more closely follow formal proofs. Mustard [29] is an iterative data generation framework that allows for iteratively generating and revising informal proofs and autoformalizing them in Lean. Our approach does not rely on the availability of natural language proofs to synthesize a decomposition and recovers from errors through recursion.\nLeanDojo [80] trains a model to select relevant premises (lemmas and defintions) at each proof step. Magnushammer [47] takes this further and trains a model to rerank the selected premises to prioritize which fit in the LLM input. COBBLESTONE simply uses the preceding lemmas in the file, though could benefit from a premise selection model to provide information just as we showed it benefited from external information in the form of an oracle's perfect premises.\nProof engineers often have to repair their previously working proofs [59]. The automation of proof repair started with the creation of symbolic tools [44], [58]. Baldur fine-tunes an LLM to repair proofs using error messages, but does so in the context of proof synthesis by synthesizing whole proofs again [21]. Unlike Baldur, which only attempts one repair, COBBLESTONE is more iterative in its synthesis approach.\nMore generally, automated program repair can improve program quality [1], [33], [38], [43], [49], [89]. Automated program repair typically either iteratively modifies a program to pass a set of tests, or constructs a patch from constraints imposed by a set of tests. Automatically pair can also help developers debug manually [17], but does not guarantee correctness, and, in fact, often introduces new bugs [50], [66]. The most common manual methods for improving quality are code reviews, testing, and debugging but only formal verification can guarantee code correctness.\nVerification requires specifying properties as well as proving them, and our work has focuses on the latter step, but important research remains in supporting manually specifying properties, automatically generating formal specifications from natural language [18], [26], [48], [84]. Some research focuses on other types of properties formal languages can capture, including privacy [73] and fairness [23], among others. Probabilistic verification of certain properties, such as fairness, in certain types of software systems can be automated [2], [25], [27], [46], [71].\nWith the advent of large foundation models [12], [53], [72], recent work has focused on how to prompt these models to get the best output. The chain-of-thought (CoT) prompting has been used to elicit reasoning in LLMs [13], [22], [75], [77], [88]. Variations include tree-of-thoughts [82], boosting-of-thoughts [11], and graph-of-thoughts [6]. Another interesting extension is work that has LLMs to decompose natural language problems into Python programs that serve as intermediate reasoning steps [24]."}, {"title": "V. CONTRIBUTIONS", "content": "This paper presented, COBBLESTONE, a novel method for synthesizing proofs for formal software verification by using LLMs to generate potential proofs, detecting faulty parts of those proofs, and combining those multiple proofs to synthesize whole, correct proofs. COBBLESTONE significantly outperforms prior neural and SMT-solver-based proof-synthesis tools, as well as LLM-based baselines we create, and can, at times, synthesize proofs for more complex theorems than prior tools can. We demonstrate a promising potential to use COBBLESTONE with external information, such as from humans or other tools, to synthesize even more proofs, which generate future research directions for the field. To ensure reproducibility of our results and enable others to build on our work, we will make all code, experimental scripts, and data publicly available [3]. Overall, our research shows that tools can make better use of partial progress made during proof synthesis to more effectively automate formal verification."}]}