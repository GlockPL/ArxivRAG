{"title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "authors": ["Chenchen Ye", "Ziniu Hu", "Yihe Deng", "Zijie Huang", "Mingyu Derek Ma", "Yanqiao Zhu", "Wei Wang"], "abstract": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents to autonomously collect world information, over which to conduct reasoning to solve complex problems. Given this capability, increasing interests have been put into employing LLM agents for predicting international events, which can influence decision-making and shape policy development on an international scale. Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability. To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events. Our benchmark features an agentic environment with tools for accessing an extensive database of historical, structured events and textual news articles. We refine the GDELT event database with careful cleaning and parsing to curate a series of relational prediction tasks with varying forecasting horizons, assessing LLM agents' abilities from short-term to long-term forecasting. We further implement APIs to enable LLM agents to utilize different tools via a code-based interface. In summary, MIRAI comprehensively evaluates the agents' capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes using domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and time to accurately predict future events. Through comprehensive benchmarking, we aim to establish a reliable framework for assessing the capabilities of LLM agents in forecasting international events, thereby contributing to the development of more accurate and trustworthy models for international relation analysis.", "sections": [{"title": "1 Introduction", "content": "Accurate forecasting of international events is crucial [1], as understanding the evolution of geopolitical developments enables stakeholders to make informed decisions, mitigate risks, and seize opportunities in the interconnected world. Traditionally, researchers in international relations rely on domain expertise [2, 3]. They conduct detailed analyses of the complex interplay among nations, considering alliances, trade agreements, ideological affinities, and historical rivalries to forecast events such as conflicts, collaborations, or alliance shifts [4]. With the rapid development of deep learning techniques, forecasting through data-driven neural networks becomes an attractive alternative. Despite their success, current methods rely on single types of information\u2014either structured knowledge graphs [5\u20137] or textual datasets [8, 9]. Knowledge graphs, although organized, can suffer from incompleteness [10] or bias [11], while textual analyses may lack the necessary factual grounding for precise predictions. Moreover, these models are unable to ground their reasoning to"}, {"title": "2 The MIRAI Benchmark", "content": "In this section, we introduce MIRAI benchmark from: the specifics of the data and tasks (Sec. 2.1), the implemented agents and environments (Sec. 2.2), and the database construction details (Sec. 2.3)."}, {"title": "2.1 Data and Tasks", "content": "We introduce MIRAI, a benchmark crafted for evaluating LLM agents for temporal forecasting in the realm of international events, with tool-use and complex reasoning. We consider forecasting as the process of collecting essential historical data and performing temporal reasoning to anticipate the outcomes of future events.\nFormally, we represent an event as \\(e_t = (t, s, r, o)\\), where t is the timestamp, s, o \u2208 C are respectively the subject and object countries from the country pool C, and r\u2208 R denotes the relation type"}, {"title": "2.2 Agents and Environments", "content": "Similar to human political analysts, LLM agents must leverage a variety of information sources to make reliable predictions. To this end, we abstract the environment by incorporating coding APIs that facilitate interactions with various knowledge sources. Within this environment, we can develop an LLM agent that employs these APIs through the ReAct strategy [33], characterized by the iterative steps of think, act, and observe. This structured approach allows the agent to analyze the current situation, retrieve additional data, and observe outcomes to make reliable forecasting.\nAPIs. We provide a comprehensive set of API to the LLM agent, enabling the execution of the generated codes to access a rich database of historical events and news articles. The API contains the"}, {"title": "2.3 Database Construction", "content": "Pre-processing. We construct a GDELT-based environment to enable agents' interaction with both knowledge graph and textual information. Initially, we filtered the dataset for events occurring between Jan. 1, 2023, and Nov. 30, 2023, aligning event dates with their respective news publish dates to avoid information leakage. We standardize the CountryCode to ISO-3166 norms and exclude any entries with missing or outdated codes, and standardize Event codes to the second level of the CAMEO ontology to ensure a consistent and detailed representation. Third-level event codes, which are more noisy and contain more extraction errors were excluded. We also only consider international events. For the news articles, credibility was assessed by counting the daily mentions of each event, with a threshold of at least 50 mentions to filter out unreliable sources. News content, including titles and body text, was then downloaded and cleaned following the OBELICS [34] protocol, which involved removing low-quality text based on word counts, character and word repetition ratios, and the presence of special characters and flagged words, thereby significantly reducing noise and enhancing the reliability of the textual information stored in our database. We list the details for dataset construction in Appendix F. We finalized a collection of 991,759 GDELT event records, corresponding to 59,161 unique (t, s, r, o) events and 296,630 unique news articles. We display our curated events over the world map in Figure 2b and 2c, illustrating global coverage and varying intensities of conflict and mediation across regions.\nTest query set construction. We construct the test data using records from November 2023, comprising 152,500 GDELT event records and 7385 unique events. To further ensure the data quality and minimize potential extraction errors inherent in GDELT records, we set a higher threshold of at least 100 daily mentions and 5 downloaded news articles for each event. This stricter filtering results in a collection of 2,136 unique (t, s, r, o) events. We construct the test query set based on this collection, which leads to 705 (t, s, ?, o) query and answer, where each answer includes a list of relations occurring between the specified subject and object country at time t in this collection. Note that this stricter filtering is only applied for the test query construction and will not remove data from the database. Additionally, we sample 100 queries from the test query set to form a test query subset, ensuring a balanced representation of dates throughout the month, countries across continents, and relations spanning the first-level CAMEO code types.\nEvaluation metrics. We instruct the agent to generate final forecasting answer in a JSON dictionary, where keys are predicted two-digit first-level CAMEO codes and the values are lists of predicted three-digit second-level CAMEO codes inherited from the keys. For example, the JSON dictionary \"{\"01\": [\"011\", \"012\"], \"02\": [\"023\"]}\" indicates the first level relation predictions for \"01: Make public statement\" and \"02: Appeal\", along with second level relation predictions \"011: Decline comment\", \"012: Make pessimistic comment\", and \"023: Appeal for material aid\". We evaluate these relation predictions by calculating precision, recall, and F1 score between the predicted and ground-truth lists. Moreover, we map the predicted and ground truth relations to their respective binary and quadratic classes (as shown in Figure 2a). Since each relation in the ground-truth list may belong to different classes, we employ the empirical Kullback-Leibler (KL) divergence of predictions to the ground truth: \\(D_{KL}(P||Q) = \\sum_{i} P(i) \\log (\\frac{P(i)}{Q(i)})\\) to measure the discrepancy, where P and Q represent the frequencies of ground-truth and predicted relations respectively. A lower KL divergence indicates a better alignment of the model's predictions with the ground-truth list."}, {"title": "3 Experiments", "content": "Our experiment section begins with comparing the forecasting performance of different agent methods with different prediction horizons (Sec.3.1). Moreover, we evaluate agents with different base language models (Sec.3.2), and finally analyze several key aspects (Sec.3.3) to understand agents' behavior."}, {"title": "3.1 Evaluate Forecasting with Different Agent Methods and Tools", "content": "We investigate the effect of different tools (APIs) and agent tool-use strategies. We use gpt-3.5-turbo-0125 [35] as the base model and evaluate on the 705 queries in the test set. For all experiments, we set the model temperature to 0.4 and run 5 times to calculate the mean and standard deviation. We provide the detailed prompts in Appendix K.\nFor agent implementations, we consider the following two methods without tool-use:\nDirect IO represents the standard LLM chatbot approach that provides answers without tool-use or explicit reasoning. This serves as a baseline to reflect the internal world knowledge of the LLMs when forecasting.\nZero-Shot Chain-of-Thought (ZS-CoT) [36, 37]: In the ZS-CoT variant, we add an instruction prompt to the LLM to encourage explicit step-by-step thinking before making the final prediction.\nFor Tool-Use agents, We follow ReAct [31] to interact with our provided environments through an iterative process of thinking, acting, and observing. We implement two variants of ReAct for tool-use: 1) \"Single Function\u201d and 2) \u201cCode Block\u201d. Details are discussed in Sec. 2.2.\nReAct agents can utilize tools. We thus implement different variants by restricting their access to utilize 1) News-Only APIs; 2) Event-Only APIs; 3) All data classes and functions.\nThe experimental results in Table 1 reveal several key insights into agent performance:\n1) MIRAI presents a challenging task for LLM agents. The best agent (ReAct with \u201cSingle Function\" using all APIs) for second-level relation predictions achieves a precision of 28.7 and an F1 score of 29.6. These results underscore the complexity and difficulty of the temporal forecasting tasks in MIRAI and highlight the substantial room for improvement in LLM agents for event forecasting.\n2) Predicting fine-grained relations proves more difficult. All models exhibit higher KL divergence for quadratic than binary classes, and lower F1 scores for second-level predictions compared to first-level ones. These findings confirm that predicting fine-grained relation types is more challenging.\n3) Diverse tool-use is critical for temporal forecasting. ZS-CoT and Direct-IO, which rely solely on the internal world knowledge of LLMs for forecasting without tool-use, significantly underperform the ReAct agent with full API access to the database. This emphasizes the importance of basing forecasting and reasoning on retrieved historical data and knowledge. In terms of tool types, ReAct agents using News-Only APIs perform much worse than agents with Event-Only APIs. While news articles provide detailed context for events, they can also introduce noise and lead to issues such as excessively long context, posing additional challenges for LLM agents. Moreover, the agents using both types of information achieve the optimal results."}, {"title": "3.2 Evaluate Forecasting with Different Base LLMs", "content": "We then investigate the role of the underlying LLMs in the agent's performance. We evaluate both open-sourced LLM Mistral-7B-Instruct-v0.2 [38] (run on a single NVIDIA RTX A6000 GPU), as well as close-sourced LLMs including gpt-3.5-turbo-0125 [35], gpt-4-turbo-2024-04-09 [22], and the recently released gpt-4o-2024-05-13 [39]. Comparisons are done on a data-balanced test subset comprising 100 queries, with all models evaluated under the ReAct framework, allowing access to all APIs. The action types can be either \u201cSingle Function\u201d or \u201cCode Block\u201d with a maximum tool call limit set to 20 steps. All models use the same prompt content and structure"}, {"title": "3.3 Analyzing Agent Behaviours", "content": "Impact of temporal distance of the forecasting target. Our defined event forecasting task varies by temporal distance l, which specifies how far into the future we want to predict. We thus conduct an ablation study with l set to 1, 7, 30, and 90 days. Specifically, we fix the query event date and limit the accessible data to l days prior to the query event date. The experimental results depicted in Figure 6 reveal a clear trend: as the temporal distance increases, the F1 score decreases and KL-divergence increases. This indicates that the agent's ability to provide accurate predictions diminishes for events further in the future. When the temporal distance is small, such as 1 or 7 days, the agent has access to more recent and relevant information, providing a strong signal (e.g., human experts' analysis) for making accurate predictions. Thus, to comprehensively benchmark the forecasting capabilities of LLM agents, we should focus on long-term predictions such as those spanning 30 or 90 days. These longer durations require the agents to capture and anticipate potential trend shifts, which may be influenced by a broader range of factors and more complex dependencies.\nForecasting accuracy on different relation types. We further split the datasets into distinct quadratic relation classes and compute the F1 score for each class, as illustrated in Figure 4b. The results show that all models exhibit significantly higher performance for \u201cverbal cooperation\u201d and \u201cmaterial conflict\", while lower in the other two categories. Several factors contribute to these observations. First, \"verbal cooperation\" events are more prevalent in the dataset, allowing the model to retrieve more such historical events. Second, \"material conflicts\" has a consistent pattern of extended duration within the same set of countries. Conversely, events categorized under \"material cooperation\" and"}, {"title": "4 Related Work", "content": "In recent years, various benchmarks have been developed to evaluate temporal reasoning capabilities in AI systems, focusing primarily on question answering and link prediction. MIRAI distinguishes itself by assessing LLMs in the forecasting task, and further employing a relational task format, incorporating diverse information sources of knowledge graphs, text, and code-based APIs, and utilizing an agent-based methodology that supports intermediate reasoning steps. We summarize our differences to these existing benchmarks in Table 3, and provide further discussions from the following aspects and more in Appendix D."}, {"title": "4.1 Temporal Reasoning Benchmarks", "content": "Many benchmarks sensing the temporal reasoning ability of AI models have been constructed, but they have different focuses and settings with MIRAI, particularly in terms of task, information, and method, as shown in Table 3. One line of benchmarks focuses on the temporal understanding ability of the model [40\u201345], such as understanding the temporal relations between available facts in knowledge graphs (KGs) or text, either a short piece of text or a document corpus. While the temporal forecasting task largely differs from understanding, where the reasoning target is unseen in the database for the model, and as such, the model has to not only understand but to reason. For forecasting, there are two main task formulations among previous benchmarks: the QA task format for benchmarks with history information represented in textual format [8, 46\u201348, 50], and graph link"}, {"title": "4.2 Evaluation of Language Agents", "content": "Previous research has investigated the performance of LLM agents in a variety of domains, including arithmetic reasoning focused on obtaining correct solutions [51\u201353], proficiency assessment in utilizing tools and reporting results [54\u201356], evaluation of web navigation skills to find specific websites [57\u201359], and planning travel itineraries under given constraints [60]. However, these evaluations do not fully address the challenges posed by tasks involving complex international events with diverse information formats and temporal attributes. MIRAI presents a unique task in this context, where the agent must navigate and reason over the structured events and textual news articles with temporal information. This setup requires the agent to effectively handle multilateral relationships and information spanning different time periods. Furthermore, MIRAI assesses the LLM agent's ability to reason and predict information that not be directly available in the provided database. This adds an additional layer of complexity, as the agent must leverage its understanding of the available information to make informed predictions about future events or fill in missing details. By evaluating LLM agents in this challenging setting, MIRAI provides valuable insights into their capacity to process and reason over complex, temporally-structured information and their ability to generate accurate predictions based on incomplete data."}, {"title": "4.3 LLMs for Tool-Use", "content": "Large Language Models (LLMs) have demonstrated remarkable language understanding [61] and reasoning capabilities [62]. However, they also possess inherent limitations, such as their inability to provide up-to-date responses based on external knowledge or to perform complex mathematical reasoning. In response to these challenges, recent advancements have seen the integration of LLMs with various external tools [63]. Notable examples include TALM [64] and ToolFormer [65], which utilize in-context learning to enhance the model's ability to leverage different tools in tasks like question answering and mathematical reasoning. Chameleon [66] employs an LLM as a natural language planner to deduce the optimal sequence of tools to be used, subsequently executing these tools to generate the final output. AVIS [67] employs dynamic tree search to synthesize the most effective tool-use sequence. ToolkenGPT [68] integrates tool-use operators as special tokens and trains the model through sequence-to-sequence training. ToolLLM [69] introduces an instruction tuning dataset encompassing over 16,000 real-world APIs, significantly enhancing the model's capability to utilize these tools effectively."}, {"title": "5 Conclusion and Limitation", "content": "In conclusion, we introduce MIRAI, a benchmark constructed for evaluating LLM agents in temporal forecasting international event with tools (APIs) to access an extensive historical event and news database. The results reveals the complexity and difficulty for current LLM Agents in generating contextually and syntax-wise correct code and performing complex temporal reasoning over the multi-party and multi-timestamped data for an effective prediction, highlighting a substantial space for further effects in this direction.\nOur work also has several limitations: 1) Only a few representative LLMs were tested, leaving broader evaluations with more open-sourced models; 2) The current API is basic, primarily providing functions for counting, listing, and statistical distribution. Future enhancements could include time series analysis and the ability for agents to add new functions for more comprehensive analysis. 3) The study was limited by cost of API usage, so we only conduct small number of experimental rounds and result in high variance. More extensive testing is suggested for future studies to achieve more stable results. Full discussion of limitation can be found in Appendix C. In the future, we plan to incorporate APIs to support more knowledge sources such as time-series and multimodal information, and consider testing more open-source LLMs and agent architectures."}]}