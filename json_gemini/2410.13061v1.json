{"title": "OPTIMAL TRANSPORT FOR PROBABILISTIC CIRCUITS", "authors": ["Adrian Ciotinga", "Yoo Jung Choi"], "abstract": "We introduce a novel optimal transport framework for probabilistic circuits (PCs). While it has\nbeen shown recently that divergences between distributions represented as certain classes of PCs can\nbe computed tractably, to the best of our knowledge, there is no existing approach to compute the\nWasserstein distance between probability distributions given by PCs. We consider a Wasserstein-type\ndistance that restricts the coupling measure of the associated optimal transport problem to be a\nprobabilistic circuit. We then develop an algorithm for computing this distance by solving a series of\nsmall linear programs and derive the circuit conditions under which this is tractable. Furthermore, we\nshow that we can also retrieve the optimal transport plan between the PCs from the solutions to these\nlinear programming problems. We then consider the empirical Wasserstein distance between a PC\nand a dataset, and show that we can estimate the PC parameters to minimize this distance through an\nefficient iterative algorithm.", "sections": [{"title": "Introduction", "content": "Modeling probability distributions in a way that enables tractable computation of certain probabilistic queries is of\ngreat interest to the machine learning community. Probabilistic circuits (PCs) [3] provide a unifying framework for\nrepresenting many classes of tractable probabilistic models as computational graphs. They have received attention\nlately for the ability to guarantee tractable inference of certain query classes through imposing structural properties on\nthe computational graph of the circuit. This includes tractable marginal and conditional inference, as well as pairwise\nqueries that compare two circuits such as Kullback-Leibler Divergence and cross-entropy [9, 17].\nHowever, to the best of our knowledge, there is no existing algorithm to compute the Wasserstein distance between two\nprobabilistic circuits.\nDefinition 1 (Wasserstein distance) Let P and Q be two probability measures on a metric space. For p > 1, the\np-Wasserstein distance between P and Q is W(P,Q) \u2261 inf-yer(P,Q) Ex(x,y) [||x \u2212 y ||] where \u0393(P,Q) denotes the\nset of all couplings which are joint distributions whose marginal distributions coincide exactly with P and Q. That is,\nfor all y \u2208 \u0393(P, Q), P(x) = \u222b y(x,y)dy and Q(y) = \u222b y(x,y)dx.1\nHere, the Wasserstein objective of some (not necessarily optimal) coupling refers to the expectation inside the infimum\ntaken over that coupling, and the Wasserstein distance between two distributions refers to the value taken by the\nWasserstein objective for the optimal coupling.\nThis paper focuses on computing (or bounding) the Wasserstein distance and optimal transport plan between (i) two\nprobabilistic circuits and (ii) a probabilistic circuit and an empirical distribution. For (i) we propose a Wasserstein-type\ndistance that upper-bounds the true Wasserstein distance and provide an efficient and exact algorithm for computing\nit between two circuits. For (ii) we propose a parameter estimation algorithm for PCs that seeks to minimize the\nWasserstein distance between a circuit and an empirical distribution and provide experimental results comparing it to\nexisting approaches."}, {"title": "Optimal Transport between Circuits", "content": "We now consider the problem of computing Wasserstein distances and optimal transport plans between distributions\nrepresented by probabilistic circuits P and Q with scopes X and Y.\nDefinition 2 (Probabilistic circuit) A probabilistic circuit (PC) C is a rooted directed acyclic graph (DAG) with three\ntypes of nodes: sum, product, and input nodes. Each internal node n has a set of child nodes ch(n); each sum node\nn has normalized parameters on i for each child node i; and each input node n is associated with function fn (e.g.,\nprobability distribution). Then a PC rooted at node n recursively defines a function over its scope sc(n) = X:\nfn(x) =\n{\n\u03a0 Ini\u2208ch(n) fni (xi) if n is a product\n(Eni\u2208ch(n) On,ifni (x) if n is a sum\n                                                                                                      (1)\nStructural properties of a PC's computational graph enable tractable computation of certain queries. In particular, as\nis common in the PC literature, we assume that the circuit structure satisfies two properties, namely smoothness and\ndecomposability. A PC C is smooth if the children of every sum node n \u2208 C have the same scope: \u2200n \u2208 ch(n),\nSc(ni) = Sc(n). C is decomposable if the children of every product node n \u2208 C have disjoint scopes: Vni, nj \u2208 ch(n),\nsc(ni) sc(nj) = \u00d8. Such circuits admit linear-time computation of marginal and conditional probabilities for arbitrary\nsubsets of variables [3].\nFurthermore, we assume that we can compute the Wasserstein distance between circuit input distributions in constant\ntime-which is the case for the 2-Wasserstein distance between Gaussian distributions and categorical distributions\nassociated with a metric space\u2014and that there is a bijective mapping between random variables in X and random\nvariables in Y.\nUnfortunately, even with the above assumptions, computing the Wasserstein distance between probabilistic circuits is\ncomputationally hard, including for circuits satisfying restrictive structural properties that enable tractable computation\nof hard queries such maximum-a-posteriori (MAP) [3]. Complete proofs of all theorems and propositions can be found\nin the Appendix.\nTheorem 1 Suppose P and Q are probabilistic circuits over n Boolean variables. Then computing the \u221e-Wasserstein\ndistance between P and Q is coNP-hard.\nAt a high level, the proof proceeds by reducing from the problem of deciding consistency of two OBDDs (a type of\ndeterministic and structured-decomposable circuit) which is NP-hard [12, Lemma 8.14]. In particular, given the two\nOBDDs, we can construct two deterministic and structured-decomposable PCs in polynomial time such that the input\nOBDDs are consistent iff W\u221e between the PCs is not 1. We refer to the Appendix for more details.\nTo address this computational challenge, we consider Wasserstein-type distances between PCs by restricting the set of\ncoupling measures to be PCs of a particular structure. Furthermore, we derive the structural conditions on the input\nPCs required to compute this distance tractably and propose an efficient and exact algorithm that runs in quadratic\ntime in the size of the input circuits. In particular, this allows us to upper-bound the true Wasserstein distance, and our\nalgorithm can also easily retrieve the associated coupling measure (transport plan).\nWe propose the notion of a coupling circuit between two compatible (see Definition 3 below) PCs, and introduce a\nWasserstein-type distance CWp which restricts the coupling set in Definition 1 to be circuits of this form. We then\nexploit the structural properties guaranteed by coupling circuits, namely smoothness and decomposability, to derive\nefficient algorithms for computing CWp.\nDefinition 3 (Circuit compatibility [17]) Two smooth and decomposable PCs P and Q over RVs X and Y, respec-\ntively, are compatible if the following two conditions hold: there is a bijective mapping ~ between RVs Xi and Yi, and\nany pair of product nodes n \u2208 P and m \u2208 Q with the same scope up to the bijective mapping are mutually compatible\nand decompose the scope the same way. Such pair of nodes are called corresponding nodes.\nDefinition 4 (Coupling circuit) A coupling circuit C between two compatible PCs P and Q with scopes X and Y,\nrespectively, is a PC with the following properties. (i) The structure of C is the structure of the product circuit [17]\nbetween P and Q; informally, this is done by constructing a cross product of children at sum nodes (product over\nsums), and the product of corresponding children at product nodes. In particular, for any corresponding sum nodes\nN1 \u2208 P, n2 \u2208 Q with edge weights 0\u017c and 0; respectively, the node n \u2208 C that is the product of n\u2081 and n2 has edge\nweights Oi,j for edges that are the product of the ith and jth children of n\u2081 and n2. (ii) The product circuit edge weights\nare constrained such that \u2211\u00bf \u03b8i,j = 0; and \u2211j0i,j = 0; for all i and j."}, {"title": "Exact and Efficient Computation of CWp", "content": "In this section, we first identify the recursive properties of the Wasserstein objective for a given parameterization of the\ncoupling circuit that enable its linear-time computation in the size of the coupling circuit. Then, we propose a simple\nalgorithm to compute the exact parameters for the coupling circuit that minimize the Wasserstein objective, giving us,\nagain, a linear-time algorithm to compute CWp as well as a transport plan between PCs.\nRecursive Computation of the Wasserstein Objective Below equation shows the recursive computation of the\nCW-objective function g(n) at each node n in the coupling circuit C (see Appx. B.2 for correctness proof). We denote\nthe ith child of node n to be ci.\ng(n) =\n{\n\u03a3i\u03b8ig(ci) \u03a3\u2081 \u03b8ig(ci) if n is a sum\n\u2211i g(ci) if n is a product with sum or product node children\nWp(C1, C2) if n is a product with input node children\n(2)\nThus, we can push computation of the Wasserstein objective down to the leaf nodes of a coupling circuit, and our\nalgorithm only requires a closed-form solution for Wp between univariate input distributions. Note that the objective\nfunction at a product node is the sum of the objective functions at its children; this is because the LB-norm decomposes\ninto the sum of norm in each dimension.\nRecursive Computation of the Optimal Coupling Circuit Parameters for CWp Leveraging the recursive properties\nof the Wasserstein objective, we can compute the optimal sum edge parameters in the coupling circuit by solving\na small linear program at each sum node. This is done by using the optimal CWp values computed at each child\nas the coefficients for the sum of corresponding weight parameters in the linear objective, which comes from the\ndecomposition of the Wasserstein objective at sum nodes in the previous section. These linear programs are constrained\nto enforce the marginal-matching constraints defined in Def. 4. Since the time to solve the linear program at each sum\nnode depends only on the number of children of the sum node, which is bounded, we consider this time constant when\ncalculating the runtime of the full algorithm. Thus, we can compute CWp and the corresponding transport plan between\ntwo circuits in time linear in the number of nodes in the coupling circuit, or equivalently quadratic in the number of\nnodes in the original circuits. Appendix B.4 presents the recursive algorithm in detail along with correctness proof."}, {"title": "Experimental Results", "content": "To determine the feasibility of computing CWp for large circuits, we implement and evaluate our algorithm on randomly-\ngenerated compatible circuits of varying sizes. As a baseline, we consider the naive application of an existing algorithm\nto compute a similar Wasserstein-type distance called \u201cMixture Wasserstein\" MW, between Gaussian mixture models\n(GMMs) [5], leveraging the fact that PCs with Gaussian input units can be \u201cunrolled\u201d into GMMs. However, we quickly\nobserve the impracticality of this baseline approach for circuits larger than even a few hundred edges due to the GMM\nrepresentation of a PC potentially being exponentially larger than the original circuit. Figure 1 illustrates how the\ndirect application of GMM-based algorithms is intractable, while our approach runs in quadratic time in the size of the\noriginal circuits just as predicted by the theory."}, {"title": "Parameter Learning of PCs using the Empirical Wasserstein Distance", "content": "Motivated by past works that minimize the Wasserstein distance between a generative model and the empirical\ndistribution, parameterized by a dataset, to train model parameters [14, 15, 16, 1], we investigate the applicability"}, {"title": "Experimental Results", "content": "To determine the performance of our proposed Wasserstein minimization algorithm, we consider learning the parameters\nof circuits of various sizes from the MNIST benchmark dataset [8]. When compared to mini-batch Expectation\nMaximization (EM) for estimating maximum-likelihood parameters, our Wasserstein Minimization (WM) approach is\nnearly competitive for small circuits but falls behind for larger circuits. We attribute this to WM's inability to make use\nof the parameter space of larger models. Detailed experimental results are provided in Appendix C.4."}, {"title": "Conclusion", "content": "This paper studied the optimal transport problem for probabilistic circuits. We introduced a Wasserstein-type distance\nCWp between two PCs an proposed an efficient algorithm that computes the distance and corresponding optimal\ntransport plan in quadratic time in the size of the input circuits, provided that their circuit structures are compatible. We\nshow that CWp always upper-bounds the true Wasserstein distance, and that\u2014when compared to the naive application\nof an existing algorithm for computing a Wasserstein-type distance between GMMs to PCs\u2014the former is exponentially\nfaster to compute between circuits. Lastly, we propose an iterative algorithm to minimize the empirical Wasserstein\ndistance between a circuit and data, suggesting an alternative, viable approach to parameter estimation for PCs which is\nmainly done using maximum-likelihood estimation. While performance was competitive with the EM algorithm for\nsmall circuits, and we leave as future work to get Wasserstein Minimization to fully exploit the increased expressiveness\nof larger models.\nWe consider this work an initial stepping stone towards a deeper understanding of optimal transport theory for\nprobabilistic circuits. Future work includes exploring more expressive formulations of coupling circuits to close the gap\nbetween CWp and MWp, extending the marginal-preserving properties of coupling circuits to the multimarginal setting,\nand computing Wasserstein barycenters for PCs."}, {"title": "Algorithms", "content": "A.1 Algorithm for Computing the Coupling Circuit between PCs\nAlgorithm 1 details the construction of a coupling circuit and the computation of the optimal parameters for sum nodes.\nLP represents a linear program and we assume that sum nodes in n\u2081 have i children and sum nodes in n\u2082 have j\nchildren. With caching of both CWp(n) and COUPLE(n1, n2) calls, this algorithm runs in quadratic time.\nAlgorithm 1 COUPLE(n1, n2): couples circuits rooted at n\u2081 and n2.\nn \u2190 cache(n1, n2)\nif n \u2260 null then\nreturn n\nend if\nif n1, n2 are input nodes then\nn \u2190 new product(n1, n2)\nelse if n1, n2 are sum nodes then\nn\u2190 new sum node\n\u25b7 will have i \u00d7 j children\nLP \u2190 new linear program with variables \u03b8i,j\n\u25b7 has i \u00d7 j variables\nfor c\u2081 \u2208 n\u2081.children do\nfor C2 \u2208 n2.children do\nn.children[i, j] \u2190 COUPLE(C1, C2)\n\u25b7 set child subcircuits\nend for\nend for\nfor \u03b8i \u2208 n\u2081.parameters do\nLP.constraints \u2013 \u03a3j \u03b8\u03ad,j = \u03b8\u03ad\n\u25b7 add marginal constraints\nend for\nfor j \u2208 n2.parameters do\nLP.constraints \u2190 \u03a3\u2081 \u03b8i,j = 0;\n\u25b7 add marginal constraints\nend for\nLP.objective \u2190 \u2211i,j\u03b8i,j\u00b7 CWp(Ci, Cj)\n\u25b7 set objective of linear program\nsolve LP\nn.parameters \u2190 optimal parameters from LP\nelse if n1, n2 are product nodes then\nn\u2190 new product node\nfor c\u2081 \u2208 n1.children, C2 \u2208 n2.children where SC(c1) = SC(C2) do\nend for\nend if\nn.children.insert(COUPLE(C1, C2))\n\u25b7 couple corresponding children\ncache(n1, n2) \u2190 n\nreturn n\nA.2 Algorithm for Computing the Wasserstein Objective for a Coupling Circuit\nGiven a coupling circuit rooted at n, Algorithm 2 computes the value of the Wasserstein objective (see Definition 1) for\nthe coupling. With caching, this algorithm runs in linear time.\nAlgorithm 2 CWp(n): p-Wasserstein objective for a coupling circuit rooted at n with i children.\nif n is a product node with input node children then\nreturn Wp(n.children[0], n.children[1])\nelse if n is a product node without input node children then\nreturn \u2211 CWp(n.children[i])\nelse if n is a sum node then\nreturn \u03a3\u03b5 \u03b8CWp(n.children[i])\nend if\n\nA.3 Algorithm for Minimum Wasserstein Parameter Estimation\nOur proposed algorithm is broadly divided into two steps: an inference step and a minimization step. These steps are\nperformed iteratively until model convergence. The inference step populates a cache, which stores the expected distance\nof each data point at each node in the circuit. This inference step is done in linear time in a bottom-up recursive fashion,\nmaking use of the cache for already-computed results. This is provided in algorithm 3.\nThe minimization step is done top-down recursively, and seeks to route the data at a node to its children in a way\nthat minimizes the total expected distance between the routed data at each child and the sub-circuit. The root node is\ninitialized with all data routed to it. At a sum node, each data point is routed to the child that has the smallest expected\ndistance to it (making use of the cache from the inference step), and the edge weight corresponding to a child is equal\nto the proportion of data routed to that child; at a product node, the data point is routed to both children. Input node\nparameters are updated to reflect the empirical distribution of the data routed to that node. The minimization step is thus\nalso done in linear time, and we note that this algorithm guarantees a non-decreasing objective function (see Appendix\nB.8 for a proof). The algorithm for this is provided in algorithm 4.\nAlgorithm 3 INFERENCE(n, D): returns a cache storing the distance between each datapoint dj \u2208 D and each\nsub-circuit rooted at n, where n has children c\u2081. For conciseness, we omit checking for cache hits\nfor ci \u2208 n.children do\nINFERENCE(ci, D)\n\u25b7 recursively build cache\nend for\nif n is a product node then\nfor dj \u2208 D do\ncache[n, dj] \u2190 \u03a3\u00bfcache[ci, dj]\nend for\nend if\nif n is a sum node then\nfor dj \u2208 D do\ncache[n, dj] \u2190 \u03a3\u2081 \u03b8icache[ci, dj]\nend for\nend if\nif n is an input node then\nfor dj \u2208 D do\ncache[n, dj] \u2190 dist(n,dj)\n\u25b7 here, dist(n, dj) is the expected distance between n and dj\nend for\nend if\nreturn cache\nAlgorithm 4 LEARN(n, D, cache): learns the parameters of circuit rooted at n on datapoints dj \u2208 D\nif not all parents of n have been learned then\nreturn\n\u25b7 We only call this method on nodes who's parents have all been learned\nend if\nif n is a product node then\nfor ci \u2208 n.children do\n[ci] \u2190 routing[n]\n\u25b7 products route their data to their children\nend for\nelse if n is a sum node then\n\u03b8\u03af, \u03b8\u03b5 \u2013 0\n\u25b7 zero out parameters\nfor dj \u2208 routing[n] do\n\u25b7 route data points at current node to children\nci \u2190 arg minc, cache [ci, dj]\n\u25b7 ci is the child node of n for which dj has the lowest distance\nrouting[ci] \u2190 dj\n\u25b7 route dj to ci\n1 1\n\u03b8i \u03b8i + routing[n]\n\u25b7 update parameter weight\nend for\nelse if n is an input node then\nn.parameters \u2190 parameters matching empirical distribution of routing[n]\nend if"}, {"title": "Proofs", "content": "B.1 Hardness Proof of the\u221e-Wasserstein Distance Between Circuits\nTheorem 2 Suppose P and Q are probabilistic circuits over n Boolean variables. Then computing the \u221e-Wasserstein\ndistance between P and Q is coNP-hard, even when P and Q are deterministic and structured-decomposable.\nProof 1 We will prove hardness by reducing the problem of deciding equivalence of two DNF formulas, which is known\nto be coNP-hard, to Wasserstein distance computation between two compatible PCs.\nConsider a DNF a containing m terms {x1,..., am} over Boolean variables X. We will construct a PC Pa associated\nwith this DNF as follows. For each term a\u017c, we construct a product of input nodes-one for each X \u2208 X whose literal\nappears in term ai, 1[X = 1] for a positive literal and 1[X = 0] for negative. Then we construct a sum unit with\nuniform parameters over these products as the root of our PC: Pa = \u221111 Pa. We can easily smooth this PC by\nadditionally multiplying Pa, with a sum node +1[X = 0] + 1[X = 1] for each variable X that does not appear in &i.\nFurthermore, note that every product node in this circuit fully factorizes the variables X, and thus the PC is trivially\ncompatible with any decomposable circuit over X and in particular with any other PC for a DNF over X, constructed\nas above.\nClearly, the above PC Pa assigns probability mass only to the models of a. In other words, for any x \u2208 {0, 1}\",\nPa(x) > 0 iff x = a (i.e. there is a term &; that is satisfied by x).\nB.2 Recursive Computation of the Wasserstein Objective\nReferring to Definition 1, the Wasserstein objective for a given coupling circuit C'(x, y) is the expected distance\nbetween x and y. Below, we demonstrate that the Wasserstein objective at a sum node that decomposes into C(x, y) =\n\u03a3\u2081 \u03b8iCi (x, y) is simply the weighted sum of the Wasserstein objectives at its children:\n||x - y || C(x, y)dxdy\nEc(x;y) [||x \u2212 y ) = \u222b ||x \u2212 y||\n| ||x \u2212 y\u22110;C;(x,y)dxdy\n=\u03a3\n=\n\u222b|x \u2212 y(x,y)dxdy = 0; Ec;(x,y)[[|x \u2212 y||}]\ni\n(4)\nNow, consider a decomposable product node, where C'(x,y) = C1(x1, y1)C2(x2, y2) 2. Below, we see that the\nWasserstein objective at the parent is simply the sum of the Wasserstein objectives at its children:\nEc(x,y) [|x \u2212 y ) = \u222b x \u2212 y || C'(x, y)dxdy\n= \u222b x \u2212 y C1 (X1,Y1)C2(x2, y2)dxdy\n= \u222b (||X1 - 1|| + ||X2 - \u04232||) \u00d7 C1(x1, y1)C2(x2, y2)dx1dx2dy1dy2\n((x1-11 C1 (x1,y1)dx11) + (x2-y2)C2(X2,Y2)dx2dy2)\n= ||X1\n=\n||x2-y2|\nEC1(x1,y1)[||\u04251 - Y1||] + EC2(x2,y2) [||X2 - \u04232||P]\nThus, we can push computation of Wasserstein objective down to the leaf nodes of a coupling circuit.\n(5)\nB.3 Proof of the Metric Properties of CWp\nProposition 2 (Metric Properties of CWp) For any set C of compatible circuits, CWp defines a metric on C\nProof 2 It is clear that CW, is symmetric since construction of the coupling circuit is symmetric. Furthermore, since\nCWp upper-bounds Wp, it must also be non-negative.\nIf CWp(P,Q) = 0, then Wp(P,Q) = 0 so P = Q. Any constraint-satisfying assignment of the parameters of a\ncoupling circuit between P and P would also result in the Wasserstein objective at the root node being 0, since the\nbase-case computation of Wp at the leaf nodes would always be zero.\""}, {"title": "Proof of the Marginal-Matching Properties of Coupling Circuits", "content": "Theorem 4 Let P and Q be compatible PCs. Then any feasible coupling circuit C as defined in Def. 4 matches\nmarginals to P and Q.\nProof 4 We will prove this by induction. Our base case is two corresponding input nodes n1, n2 \u2208 P, Q. The sub-circuit\nin C rooted at the product of n\u2081 and n2 is a product node with copies of n\u2081 and n\u2082 as children, which clearly matches\nmarginals to n\u2081 and n2.\nNow, let n\u2081 and n\u2082 be arbitrary corresponding nodes in P and Q, and assume that the product circuits for all children\nof the two nodes match marginals. We then have two cases:\nCase 1: n1, n2 are product nodes Since the circuits are compatible, we know that n\u2081 and n\u2082 have the same number\nof children - let the number of children be k. Thus, let c1,i represent the i'th child of n1, and let c2,i represent the i\u2019th\nchild of n2. The coupling circuit of n\u2081 and n2 (denoted n) is a product node with k children, where the i'th child is the\ncoupling circuit of C1,i and C2,i (denoted ci).\nBy induction, the distribution Pc\u2081(X, Y) at each child coupling sub-circuit matches marginals to the original sub-\ncircuits: Pc\u2081\u2084(X) = Pc1,\u2081(X), and Pc\u2081(Y) = Pc2,1(Y). n1 and 12 being product nodes means that Pn\u2081(X) =\n\u03a0i Pc1, (X) and Pn\u2082(Y) = \u03a0; Pc2,1 (Y), so thus Pn(X) = []; Pc\u2081 (X) = \u03a0\u2081 Pc\u2081\u2081\u2081(X) and Pn(Y) = \u041f\u2081 Pc\u2081 (Y) =\n\u03a0\u2081 Pc2. (Y). Therefore, n matches marginals to n\u2081 and n2.\nCase 2: n1, n2 are sum nodes Let the number of children of n\u2081 be k\u2081 and the number of children of n2 be k2. Let\nC1,i represent the i'th child of n\u2081, and let c2,j represent the j'th child of n2. The coupling circuit of n\u2081 and n2 (denoted\nn) is a sum node with k1 * k2 children, where the (i, j)'th child is the coupling circuit of C1,i and C2,j (denoted ci,j).\nBy induction, the distribution Pci,; (X, Y) at each child coupling sub-circuit matches marginals to the original sub-\ncircuits: Pci,j(X) = Pc1,\u2081(X), and Pci,j(Y) = PC2,5(Y). n1 and n\u2082 being sum nodes means that Pn\u2081(X) =\n\u03a3\u03b5 \u03b8iPc1, (X) and Pn2 (Y) = \u2211j0jPc2, (Y), so thus\nPn(X) = \u03a3\u03a3\u03b8\u03ae, Pci, (X) = \u03a3\u03a3\u03b8i, PC1, (X) = \u22110 PC1, (X) = Pn1 (X)\nij\nij\n\u2211\u03a3 P (Y) = \u2211\u03a3 P (Y) = \u2211\u03a3 P (Y) = \u2211\u2211\u0398iPc1, (X) = \u22110 PC1, (X) = (X\n\u2211\u03a3P (Y) = \u03a3\u03a30\u03a30\u03a3P (Y) = \u03a3 P (Y) = ()\nij\nij\nij\nijn(X) = \u03a3 P (Y) = \u2211\u2211P (Y) = \u03a3\u03a3P (Y) = \u03a3\u03a3P (Y) = \u03a3 P (X) = ()\nPn(X) = \u2211 P (Y) = \u2211\u2211P (Y) = \u03a3\u03a3P (Y) = \u03a3\u03a3\u0398iPc1, (X) = \u22110 PC1, (X) = (X\n\u2211\u03a3P (Y) = \u03a3\u03a30\u03a30\u03a3P (Y) = \u03a3 P (Y) = ()\nPn(Y) = \u03a3\u03a3 \u03b8i, Pci, (Y) = \u03a3\u03a3 \u03b8i,jPc2,3 (Y) = \u22110jPc2,3 (Y) = Pn2 (Y) (10)\n\nNote that we rewrite \u2211\u00bf0i,j = 0; and \u2211j0i,j = 0\u017c by the constraints on coupling circuits. Therefore, n satisfies\nmarginal constraints."}, {"title": "Proving that Computing Minimum Wasserstein Parameters is NP-Hard", "content": "Theorem 5 Computing the parameters of probabilistic circuit C is NP-hard.\nProof 5 We will prove this hardness result by reducing k-means clustering - which is known to be NP-hard [4] - to\nlearning the minimum Wasserstein parameters of a circuit. Consider a set of points x1...xn \u2208 Rd and a number of\nclusters k. We will construct a Gaussian PC C associated with this problem as follows: the root of C is a sum node\nwith k children; each child is a product node with d univariate Gaussian input node children (so each product node is\na multivariate Gaussian comprised of independent univariate Gaussians). Minimizing the parameters of C over xi\ncorresponds to finding a routing of data points x\u017c that minimizes the total distance between all xi's and the mean of the\nmultivariate Gaussian child each xi is routed to. A solution to k-means can be retrieved by taking the mean of each\nchild of the root sum node to be the center of each of k clusters."}, {"title": "Deriving a Closed-Form Solution to the Linear Programs for Parameter Updates", "content": "For a sum node s with m children 81...Sm and a dataset with n datapoints d\u2081...dn each with weight wj, we construct a\nlinear program with m * n variables xi,j as follows:\nmin \u03a3\u03a3\u0395, [||X \u2013 dj ||2]Xi,j s.t. \u03a3 xi,j = wjj\n\u2211j0i,j\ns.t.\n\u2211\u2211nj\u2208D j i 1\nmin Ei 1d 2Xi 1 1jjjE"}, {"title": "Additional CW, Runtime Results", "content": "To evaluate the runtime of computing CW2, we consider a fixed variable scope and randomly construct a balanced\nregion tree for the scope. Then, we randomly construct two PCs for this region tree; the PCs are constructed with a fixed\nsum node branching factor and fixed rejoin probability - which is the chance that a graph connection to an existing node\nin the PC will be made to add a child rather than creating a new node for the child, and is 0% in the case of trees and\n50% in the case of graphs. We implement our algorithm as detailed in appendix A.1 to compute the optimal transport\nmap and value for CW2, as well as also implement a PC-to-GMM unrolling algorithm and the algorithm proposed by\n[2] to compute MW2 [5]. The value obtained for each circuit size is averaged over 100 runs, and we omit data points\nfor experiments that ran out of memory. See Figure 2 for the graphs."}]}