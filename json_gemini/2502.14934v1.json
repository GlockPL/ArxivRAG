{"title": "FAST AND ACCURATE BLIND FLEXIBLE DOCKING", "authors": ["Zizhuo Zhang", "Lijun Wu", "Kaiyuan Gao", "Jiangchao Yao", "Tao Qin", "Bo Han"], "abstract": "Molecular docking that predicts the bound structures of small molecules (ligands) to their protein targets, plays a vital role in drug discovery. However, existing docking methods often face limitations: they either overlook crucial structural changes by assuming protein rigidity or suffer from low computational efficiency due to their reliance on generative models for structure sampling. To address these challenges, we propose FABFlex, a fast and accurate regression-based multi-task learning model designed for realistic blind flexible docking scenarios, where proteins exhibit flexibility and binding pocket sites are unknown (blind). Specifically, FABFlex's architecture comprises three specialized modules working in concert: (1) A pocket prediction module that identifies potential binding sites, addressing the challenges inherent in blind docking scenarios. (2) A ligand docking module that predicts the bound (holo) structures of ligands from their unbound (apo) states. (3) A pocket docking module that forecasts the holo structures of protein pockets from their apo conformations. Notably, FABFlex incorporates an iterative update mechanism that serves as a conduit between the ligand and pocket docking modules, enabling continuous structural refinements. This approach effectively integrates the three subtasks of blind flexible docking-pocket identification, ligand conformation prediction, and protein flexibility modeling into a unified, coherent framework. Extensive experiments on public benchmark datasets demonstrate that FABFlex not only achieves superior effectiveness in predicting accurate binding modes but also exhibits a significant speed advantage (208\u00d7) compared to existing state-of-the-art methods.", "sections": [{"title": "1 INTRODUCTION", "content": "Molecular docking is a pivotal technology in drug discovery, aiming at predicting the binding structures of ligand-protein complexes to elucidate how drug-like small molecules (ligands) interact with target proteins. Over the past decades, the development of molecular docking has seen continuous breakthroughs, evolving from traditional simulation software grounded in the principles of physics and chemistry to recent deep learning-based methods. Traditional methods typically utilize empirical energy scoring functions to rank numerous searched conformations, often resulting in excessive processing times and heavy computational burdens.\nThe shift towards deep learning-based docking approaches represents a significant transformation in the field, offering an alternative pathway for exploring protein-molecule interactions. Despite technological advances, a substantial number of these methods rely on the rigid docking paradigm, which assumes that proteins are rigid and remain static during the docking process. This simplification contradicts the physiological reality of molecular docking, where proteins"}, {"title": "2 RELATED WORK", "content": "Molecular docking. As a cornerstone of drug discovery, molecular docking, often synonoymous with ligand-protein docking, focuses on the interactions between ligands and proteins. Traditional methods like Vina, Smina, Glide, Gnina and Gold, use physics-based scores to analyze these interaction, which, though effective, tend to be computationally intensive. Recent progress in geometric deep learning has sparked the development of deep learning-based docking strategies, which can be broadly categorized into regression-based and sampling-based methods. Regression-based methods like EquiBind, TankBind, E3Bind and FABind leverage various geometric neural networks to directly predict binding structures. Conversely, sampling-based methods like Diff-Dock, manipulate the rotation, translation and torsion of ligands using diffusion models. These methods generally simplify the problem by assuming protein rigidity, neglecting the dynamic nature of protein in realistic docking scenarios.\nFlexible molecular docking. Recent methods in flexible docking, such as DynamicBind, ReDock, PackDock and NeuralPLexer, are primarily based on diffusion models with sampling strategy. For example, DynamicBind uses equivariant geometric diffusion networks to reconstruct the holo structures of both ligand and protein from their apo states. ReDock adopts the neural diffusion bridge model that employs energy-to-geometry mapping on geometric manifolds to predict protein-ligand binding structures. While these methods effectively enhance the docking performance, they suffer from the typical flaws associated with diffusion models and multi-round sampling strategy, i.e., low computational efficiency. This limitation impedes the scalability of these methods in assessing extensive volumes of potential, unknown molecule-protein interactions, which are crucial for advancing drug discovery. In this paper, we attempt to provide a regression-based solution aimed at achieving both fast inference and high docking accuracy."}, {"title": "3 METHODOLOGY", "content": null}, {"title": "3.1 PROBLEM STATEMENT AND PRELIMINARY", "content": "Notations. Each ligand-protein complex is denoted as a heterogeneous graph \\(G = \\{V := (V^l,V^p),E := (E^l, E^p, E^{lp})\\}\\), where V and E denote the sets of nodes and edges, respectively. Specifically, in the ligand subgraph \\(G^l = \\{V^l,\\mathcal{E}^l\\}\\), each node \\(v_i = (h_i, x_i) \\in V^l\\) corresponds an atom of ligand, with \\(h_i \\in \\mathbb{R}^d\\) representing the pre-extrated feature by TorchDrug and \\(x_i \\in \\mathbb{R}^3\\) specifying its spatial coordinate. The edge set \\(E^l\\) encompasses the chemical bonds within the ligand. In the protein subgraph \\(G^p = \\{V^p, E^p\\}\\), each node \\(v_j = (h_j,x_j) \\in V^p\\) represents a residues, with \\(h_j \\in \\mathbb{R}^d\\) derived from ESM-2 as the pretrained feature, and \\(x_j \\in \\mathbb{R}^3\\) indicating the coordinate of the Ca atom in the residue. The edge set \\(E^p\\) connects residues that are within an 8\u00c5 distance. Additionally, the set of external interface edges, denoted as \\(E^{lp}\\), comprises edges that connect nodes from the ligand set \\(V^l\\) to the protein set \\(V^p\\) when they are spatially within 10\u00c5 of each other. When specifically focusing on the true pocket region, the ligand-pocket complex is depicted as a reduced heterogeneous graph \\(G^* = \\{V^* := (V^l,V^{p*}),E^* := (E^l, E^{p*}, E^{lp*})\\}\\), where \\(V^{p*}\\), \\(E^{p*}\\) and \\(E^{lp*}\\) are derived from the subsets of the protein that constitutes the pocket. Similarly, a hat is used in the notation to represent the predicted pocket, \\(\\hat{G}^* = \\{V^* := (V^l,\\hat{V}^{p*}), \\hat{E}^* := (E^l, \\hat{E}^{p*},\\widehat{E^{lp*}})\\}\\)."}, {"title": "Blind Flexible Docking.", "content": "Given an unbounded pair of conformations: an apo ligand randomly initialized by RDKit and an apo protein predicted by AlphaFold2, the aim of blind flexible molecular docking is to predict the bound structure of ligand-pocket complex, i.e., holo ligand and holo pocket, denoted as \\(x = \\{\\{x_i\\}_{1<i<n^l}, \\{x_j\\}_{1<j<n^{p*}}\\}\\), where \\(n^l = |V^l|\\) and \\(n^{p*} = |V^{p*}|\\) indicate the number of ligand atoms and pocket residues respectively. Unlike most existing studies that assume protein rigidity or rely on pre-known pocket sites, the blind flexible setting reflects the challenges encountered in real-world molecular docking scenarios."}, {"title": "Fundamental Component: FABind Layer.", "content": "FABind and its enhanced version, FABind+, establish an end-to-end deep learning framework that simultaneously predicts binding pocket sites and holo ligand structure under rigid setting. The fundamental geometric graph neural network used in both two approaches is called \u201cFABind layer\", denoted as \\(F(\\cdot)\\), which is an improved E(3)-equivariant graph neural networks (EGNN) tailored for ligand-protein complex graph. The l-th FABind layer is denoted as follows:\n\\((h_i^{(l+1)},h_j^{(l+1)},x_i^{(l+1)},x_j^{(l+1)},p_{ij}^{(l+1)}) = F(h_i^{(l)},h_j^{(l)},x_i^{(l)},x_j^{(l)},P)\\), where \\(p_{ij} \\in \\mathbb{R}^d\\) is the pair embedding of the ligand-protein node pair \\((v_i,v_j) \\in V^l \\times V^p\\), and d is the hidden size. Similar to general graph neural networks, we can stack multiple FABind layers to extract deeper features and capture high-order information within the graph. Inspired by the fast inference of the FABind series methods, we employ the FABind layer as our fundamental component in constructing each module of our FABFlex."}, {"title": "3.2 FABFLEX", "content": null}, {"title": "3.2.1 DESIGN PHILOSOPHY", "content": "The design philosophy of FABFlex centers on achieving both high efficiency and accuracy in blind flexible docking task, which can be decomposed into three key subtasks: identifying pocket sites, predicting the bound holo structure of ligand, and predicting the bound holo structure of pocket. Specifically, the first subtask can be modelled as a binary classification problem to determine which protein residues form the docking pocket, while the other two subtasks are 3D coordinate regression problems. To pursue faster docking computation, the FABFlex model is designed to predict the docking results in a single-pass operation, without requirements of extensive sampling and repetitive computations. Additionally, FABFlex aims to operate without relying on external tools that could add extra computational overhead, such as the pocket detection tool P2Rank, which is used in existing studies to detect candidate pocket sites. According to above philosophy, the FABFlex model builds on an end-to-end multi-task learning framework tailored for blind flexible docking."}, {"title": "3.2.2 ARCHITECTURE OF FABFLEX", "content": "An overview of the proposed FABFlex model is illustrated in Fig. 2. Designed to tackle the intricacy of blind flexible docking, FABFlex employs a collaborative architecture consisting of three specialized modules: (1) a pocket prediction module, denoted as \\(M_s(\\cdot)\\); (2) a ligand docking module, denoted as \\(M_L(\\cdot)\\); (3) a pocket docking module, denoted as \\(M_p(\\cdot)\\). All modules are implemented using stacked FABind layers, while each tailored to a specific subtask decomposed from blind flexible docking. Specifically, the pocket prediction module is responsible for identifying the residues that form the pocket, addressing the \u201cblind\u201d issue, as formulated below:\n\\(\\{\\hat{y}_j\\}_{1<j<n^p} = M_s(G, \\{h_i, x_i\\}_{1<i<n^l}, \\{h_j,x_j\\}_{1<j<n^p}),\\)\n\\(\\{V_j\\}_{1<j<n^{p*}} = \\{\\hat{y}_j \\odot V_j\\}_{1<j<n^p} \\in V^{p*},\\)\nwhere G is the ligand-protein graph, \\(\\{\\hat{y}_j\\}_{1<j<n^p} (\\hat{y}_j \\in \\{0,1\\})\\) is an indicator vector predicted by the pocket prediction module to locate the pocket sites, \\(V^{p*}\\) denotes the predicted set of pocket residues and \\(n^{p*} = |\\mathcal{P}^*|, \\odot\\) symbolizes the selection operation based on the indicator vector. The predicted pocket sites by pocket prediction module enable the subsequent ligand and pocket docking modules to concentrate effectively on the crucial pocket area, narrowing the large ligand-protein graph to a more targeted ligand-pocket graph.\nThe ligand docking module and the pocket docking module cater to the \u201cflexible docking\u201d by predicting the bound structures of holo ligand and holo pocket respectively, formulated as follows:\n\\(\\{\\hat{x}_i\\}_{1<i<n^l} = M_L(G^*, \\{h_i, x_i\\}_{1<i<n^l}, \\{h_j,x_j\\}_{1<j<\\widehat{n^{p*}}}),\\)\n\\(\\{\\hat{x}_j\\}_{1<j<n^{p*}} = M_p(G^*, \\{h_i, x_i\\}_{1<i<n^l}, \\{h_j, x_j\\}_{1<j<\\widehat{n^{p*}}}),\\)\nwhere \\(G^*\\) is the ligand-pocket graph, \\(\\{\\hat{x}_i\\}_{1<i<n^l}\\) and \\(\\{\\hat{x}_j\\}_{1<j<n^{p*}}\\) are predicted structures of ligand and pocket respectively. In current model, the ligand docking module and the pocket docking module predict the structures in isolation, which has a gap to reflect the interactive influence between ligand atoms and pocket residues in docking process. To rectify this, there is a need for a bridge that connects the ligand docking module and the pocket docking module, enhancing the model to capture the nature of interactive dynamics of docking."}, {"title": "3.2.3 ITERATIVE UPDATE MECHANISM", "content": "To facilitate the exchange of predicted structures between the ligand docking module and the pocket docking module, we introduce an iterative update mechanism to further promote the coordinate refinement. Specifically, the predicted ligand and pocket, which together form the updated ligand-pocket graph, are fed back into their respective modules to produce new predictions. This k-th iterative process can be formulated as follows:\n\\(\\{x_i^{(k+1)}\\}_{1<i<n^l} = M_L(\\hat{G}^{(k)*}, \\{h_i, x_i^{(k)}\\}_{1<i<n^l}, \\{h_j, \\hat{x}_j^{(k)}\\}_{1<j<\\widehat{n^{p*}}}),\\)\n\\(\\{x_j^{(k+1)}\\}_{1<j<n^{p*}} = M_p(\\hat{G}^{(k)*}, \\{h_i, x_i^{(k)}\\}_{1<i<n^l}, \\{h_j, x_j^{(k)}\\}_{1<j<\\widehat{n^{p*}}}),\\)\nwhere \\(\\hat{G}^{(k)*}\\) denotes the ligand-pocket graph updated by the k-th iteration's predicted coordinates of ligand atoms \\(\\{x_i^{(k)}\\}_{1<i<n^l}\\) and pocket residues \\(\\{\\hat{x}_j^{(k)}\\}_{1<j<\\widehat{n^{p*}}}\\), and the number of iterations K is a hyperparameter discussed in Appendix C.5. Notably, the update mechanism iterates solely on the coordinates, excluding the features. Additionally, inspired by AlpahFold2, we only record the gradient at the final iteration during training process. These strategies are beneficial in reducing the memory demands and easing computational burden."}, {"title": "3.2.4 TRAINING LOSS AND PIPELINE", "content": "Training Loss. FABFlex is built on a multi-task learning framework, utilizing multiple losses to supervise different modules from various aspects. Referring to FABind series, the training loss comprises pocket prediction loss, ligand coordinate loss, pocket coordinate loss, and distance map constraint loss, formulated as follows:\n\\(L = \\lambda_1L_{pocket\\_pred} + \\alpha_2L_{ligand\\_coord} + \\alpha_3L_{pocket\\_coord} + \\lambda_4L_{dis\\_map},\\)\nwhere the pocket prediction loss \\(L_{pocket\\_pred}\\) encompasses a residue classification loss and a pocket center loss. The ligand coordinate loss \\(L_{ligand\\_coord}\\) is a Huber regression loss to measure the distance between predicted and ground-truth coordinates of ligand atoms. Similarly, the pocket coordinate loss \\(L_{pocket\\_coord}\\) is a Huber loss to compute the coordinate distance between predicted and ground-truth pocket residues. The distance map loss \\(L_{dis\\_map}\\) supervises the predicted relative distance of atom-residue pairs. The details of implement of training loss are provided in Appendix A.1.\nPipeline. Given an apo ligand initilized by RDKit and an apo protein predicted by AlphaFold2, the ligand is initially positioned at the center of the protein to construct the ligand-protein graph G. This graph is passed through the pocket prediction module to identify the binding pocket residues \\(\\{V_j\\}_{1<j<n^{p*}}\\). Navigated by the predicted pocket, the ligand is translated from the protein center to the pocket center, creating the ligand-pocket graph \\(G^*\\). This graph is then fed into the ligand and pocket docking modules, where it undergoes refinement through an iterative update mechanism. At the final iteration, the predicted holo structures of ligand \\(\\{\\hat{x}_i\\}_{1<i<n^l}\\) and pocket \\(\\{\\hat{x}_j\\}_{1<j<n^{p*}}\\) are obtained from their respective docking modules. The pseudo code is provided in Appendix A.2.\nNotably, we adopt a partial teacher-forcing strategy during training process. When passing pocket information from the pocket prediction module to the docking modules, a probability factor p is set to control whether the true pocket sites (with probability p) or the predicted pocket sites (with probability 1 \u2013 p) are passed to the docking modules. This strategy allows the model to rely partially on ground-truth pocket sites for stability, while progressively learning to depend on its own pocket predictions."}, {"title": "4 EXPERIMENTS", "content": null}, {"title": "4.1 EXPERIMENTAL SETTING", "content": "Dataset Construction. Our experiments are conducted on the widely used public PDBBind v2020 dataset, which contains a comprehensive collection of 19,443 protein-ligand crystal complex structures with experimentally measured binding affinities. For each complex, we align the protein component with its corresponding AlphaFold2-predicted structure to obtain the apo protein conformations. To ensure consistency with previous work, we employ the same dataset splitting and adhere to similar data preprocessing steps. Specifically, complexes deposited before 2019 are utilized as the training set (12,807 complexes) and validation set (734 complexes), while those recorded after 2019 are designated as test set (303 complexes). Additional data preprocessing details are provided in Appendix B.1.\nBaselines. We compare our proposed FABFlex against a spectrum of competitors, which are categorized into traditional docking software and deep learning docking methods. Within the traditional software category, we compare against well-established software including Vina, Glide and Gnina. For deep learning-based methods, we include TankBind, FABind, FABind+,"}, {"title": "4.2 LIGAND PERFORMANCE OF BLIND FLEXIBLE DOCKING", "content": "Table 1 summarizes the comparison of ligand performance across various docking methods. The left part of the table performs the comparison on the all test cases. It can be observed that FABFlex consistently outperforms both traditional docking software and contemporary deep learning-based methods almost across all metrics. Typically, a prediction of a ligand's structure is considered successful if its predicted structure is within a RMSD of 2\u00c5 from the true holo ligand structure. Thus, the ligand RMSD < 2\u00c5 is a critical metric to evaluate the capacity of molecular docking methods. FABFlex excels in this metric, achieving the ligand RMSD < 2\u00c5 at 40.59%, which has generated a significant margin compared to the second-best competitor, showcasing FABFlex's superior ability in predicting accurate binding structures of ligands.\nThe right part of Table 1 performs a more rigorous assessment of docking methods using 114 ligand-protein complexes that involve protein receptors that were not seen during the training process. This assessment is crucial for evaluating the generalization capability of each method. Although FABFlex does not achieve the best results in every metric, it excels significantly in the critical measure of ligand RMSD < 2\u00c5. Notably, FABFlex reaches 32.46%, markedly outperforming all competitors, which fall below 30%. This performance underscores FABFlex's ability to generalize effectively to new and unseen proteins. Additional analysis of ligand performance is provided in Appendix C.1."}, {"title": "4.3 \u0420\u041e\u0421KET PERFORMANCE OF BLIND FLEXIBLE DOCKING", "content": "Fig. 3 illustrates the cumulative distribution of pocket RMSD performance. In the left figure, which evaluates all test complexes, we observe that although FABFlex does not outperform DynamicBind, it still has a positive effect on refining pocket poses from the initial AlphaFold2 structures. The right figure focuses on complexes with unseen protein receptors. It can be observed that for pocket RMSD below 0.75\u00c5, the DynamicBind distribution curve almost always stays at the lowest position, while FABFlex maintains results that are not worse than those of AlphaFold2. This suggests that for these unseen protein receptors, FABFlex demonstrates better robustness compared to DynamicBind, as it does not degrade the protein structures. These outcomes are not surprising, as DynamicBind employs a diffusion model to adjust the conformation of the entire protein, rather than just the pocket region. While this approach reduces the degrees of freedom and enhances the accuracy, it may limit its ability to generalize to new proteins, and face computational efficiency challenges."}, {"title": "4.4 INFERENCE EFFICIENCY", "content": "High efficiency facilitates the widespread adoption of a method in real-world applications. In the last column on the right of Table 1, we showcase a comparison of the average inference time for each ligand-protein pair. Traditional docking software such as Vina, Glide, and Gnina exhibit notably longer inference times. Among regression-based methods, TankBind, FABind, and FABind+ demonstrate considerably faster speed than sampling-based approaches such as DiffDock and DynamicBind. Notably, FABFlex achieves an inference speed of only 0.49 seconds, which is approximately 208 times faster than DynamicBind, a recently developed method for flexible docking that averages 102.12 seconds. This efficiency gain is attributed to the design philosophy of FABFlex that directly predicts the bound structures without requiring multiple rounds of sampling or extra external pocket detection tools. Additionally, FABFlex specifically focuses on the conformational changes in the core pocket region, rather than the entire protein. As the pocket constitutes a small part of the protein, this design effectively reduces the computational burden."}, {"title": "4.5 POCKET PREDICTION ANALYSIS", "content": "Table 2 illustrates the performance of FABFlex's pocket prediction module in comparison with to existing P2Rank, FABind and FABind+. Among them, P2Rank is an open-source tool widely used in existing docking methods for pre-determining potential binding pocket sites. To intuitively analyze the effectiveness of pocket prediction across different methods, we evaluate the quality of pocket prediction from two perspectives: residue classification and pocket center position. For classification, we report the accuracy (CLS ACC). For the pocket center, we employ the mean-absolute-error (MAE), the root-mean-square-error (RMSE), and the Euclidean distance (EucDist), each calculated between predicted pocket center and native pocket center to quantify the accuracy of pocket localization. From Table 2, we can observe that regardless of apo or holo protein, FABFlex predicts pocket sites that are comparable to FABind and FABind+, and consistently outperform P2Rank. These results indicate the effectiveness of FABFlex in identifying pocket residues, even when confronting apo proteins. Additionally, integrating pocket prediction into the flexible docking process appears to be more advantageous than relying on an external pocket detection tool. Notably, FABFlex achieves the lowest RMSE at 4.83 and 4.89, and the lower RMSE suggests FABFlex's stability in error control, with fewer cases of extreme errors. Moreover, we provide intuitive visualization of two pocket prediction cases in Appendix C.12."}, {"title": "4.6 ABLATION STUDY", "content": "We conduct a series of ablation studies to investigate different factors affecting model performance, including the following: (1) Using a single docking module to predict both the holo structures of the ligand and pocket degrades performance for both, indicating that decomposing flexible docking into two subtasks helps reduce the complexity each module needs to handle. (2) Removing iterative update mechanism significantly impairs the ligand performance (with ligand RMSD < 2\u00c5 from 40.59% to 19.80%), indicating the critical role of iterative update in ligand coordinate refinement. (3) Applying the iterative update mechanism only internally within the ligand and pocket docking modules negatively impacts both ligand RMSD and pocket RMSD, underscoring the importance of prediction exchange to connect the two docking modules. (4) Replacing the pocket sites predicted by the pocket prediction module with those predicted by P2Rank reduces overall performance, suggesting that integrating pocket prediction within the docking process may be more effective than relying on an external pocket detection tool."}, {"title": "4.7 ANALYSIS OF ITERATIVE UPDATE", "content": "We take a case of PDB 6OIM as an example to visualize the structural refinements in iterative update process to intuitively analyze its function in FABFlex. As shown in Fig. 4, we observe"}, {"title": "4.8 CASE STUDY", "content": "Fig. 5 visualizes two cases of PDB 6OIM and PDB 6ROT, to demonstrate the effectiveness of our FABFlex in blind flexible docking. We have following observations:\nFABFlex can pinpoint the binding pocket site. In the case of PDB 6OIM, existing methods such as FABind, FABind+ and DynamicBind wrongly determine the binding sites. In contrast, FABFlex successfully locates the correct binding pockets, achieving significantly lower ligand RMSD of 3.85\u00c5. This underscores FABFlex's ability to accurately pinpoint binding pockets, even in such difficult case where other methods fall short.\nFABFlex excels in ligand structure prediction. In the case of PDB 6ROT, while all methods successfully identify the correct binding pocket, the ligand structures predicted by FABFlex are significantly closer to the ground truth compared to other methods, with ligand RMSD of merely 0.77\u00c5. This low ligand RMSD means that the ligand predicted by FABFlex is nearly identical to the actual holo ligand. This visualization suggests FABFlex's proficiency in predicting ligand structure."}, {"title": "5 CONCLUSION", "content": "A high-efficiency molecular docking method is an effective tool in drug discovery, as it enables the fast assessment and screening of millions or even billions of potential molecule-protein interactions within a limited time, discovering promising drug candidates early in the development process. This work proposes FABFlex, a regression-based, end-to-end neural model tailored for real-world blind flexible docking scenarios. FABFlex offers a solution, different from existing generative model-based sampling approaches, to achieve both fast computational speed and accurate docking performance. Looking ahead, we aim to explore fast and accurate multi-site docking, a task of great significance and heightened complexity, as it allows for the investigation of intricate interactions across multiple binding sites."}, {"title": "6 ETHICS STATEMENT", "content": "This paper proposes a model aimed at enhancing both computational efficiency and accuracy in blind flexible docking. All data used for model training and evaluation were obtained from publicly available molecular docking benchmark datasets. The advancement of molecular docking technologies has both positive and potential negative implications. On the positive side, our method can contribute to advancements in drug discovery. However, there is also the risk of misuse or malicious use, as molecular docking models could be applied to explore harmful or non-therapeutic compounds. To mitigate this risk, we are releasing our code with the explicit intent of supporting ethical and medically approved drug discovery efforts, in full compliance with relevant legal standards and institutional guidelines. This paper adheres to strict research integrity protocols and responsible dataset usage, ensuring that our contributions support the broader objectives of ethical scientific progress."}, {"title": "7 REPRODUCIBILITY STATEMENT", "content": "The experimental settings for our model are described in detail in Section 4.1. The experiments are all conducted on the widely used public molecular docking benchmark PDBBind v2020 dataset. We provide the link to our source codes to ensure the reproducibility of our experimental results:"}, {"title": "A METHODOLOGY DETAILS", "content": null}, {"title": "A.1 DETAILS OF TRAINING LOSSES", "content": "The blind flexible docking is modelled as a supervised learning task. The ground-truth encompasses residues that form binding pocket sites, along with the actual coordinates of both holo ligand and holo pocket. The training loss implementations draw extensively from the methodologies outlined in FABind and FABind+. Corresponding to the statement in Section 3.2.4, we provide detailed descriptions of each training loss to improve the reproducibility of our study:\nGiven that only a small fraction of the residues in a protein belong to the pocket, the pocket residue detection is treated as an imbalanced binary classification task using binary-classification cross en-tropy loss (BCELoss), aiming at identifying which residues belongs to the pocket. The formulation of this loss is given by:\n\\(L_{pocket\\_cls} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{p_i}{q_i} \\sum_{j=1}^{p_i} [y_j log(\\hat{y}_j) + (1 - y_j) log(1 - \\hat{y}_j)]\\},\\) where N is the total number of training complexes, p\u2081 the number of residues in the i-th protein, qi the count of residues that form the pocket in the i-th protein. The weighting factor pi/qi adjusts the emphasis on proteins with fewer pocket-forming residues, ensuring their adequate importance in the training process. Additionally, the pocket center loss, denoted as \\(L_{pocket\\_center}\\), adopts a Huber loss\u00b3 to supervise the position of the predicted pocket, formulated as follows:\n\\(L_{pocket\\_center} = \\frac{1}{N} \\sum_{i=1}^{N} HuberLoss(center_i, \\widehat{center}_i),\\)\nwhere centeri is the actual centroid coordinate of pocket in the i-th protein, and centeri is the pre-dicted centroid coordinate, which is calculated using a weighted average of all residue coordinates in the i-th protein, with the weights derived from the output probabilities of the Gumbel-Softmax dis-tribution. After that, the residue classification loss \\(L_{pocket\\_cls}\\) and the pocket center loss \\(L_{pocket\\_center}\\), are combined to formulate the overall pocket prediction loss \\(L_{pocket\\_pred}\\) as follows:\n\\(L_{pocket\\_pred} = \\alpha_{cls} L_{pocket\\_cls} + \\alpha_{center} L_{pocket\\_center}.\\)\nThe ligand coordinate loss and the pocket coordinate loss both utilize the Huber loss to regress the predicted structures towards their respective real holo structures:\n\\(L_{ligand\\_coord} = \\frac{1}{N} \\sum_{i=1}^{N} HuberLoss(x_i, \\hat{x}_i), L_{pocket\\_coord} = \\frac{1}{N} \\sum_{i=1}^{N} HuberLoss(x_i, \\hat{x}_i),\\)\nwhere x (x) and x (x) are the predicted ligand (pocket) coordinates and actual holo ligand (pocket) coordinates respectively, for the i-th complex.\nThe distance map loss serves as an auxiliary objective, employing mean-squared-error loss (MSELoss) to supervise the relative positions between ligand atoms and pocket residues, formally expressed as follows:\n\\(L_{dis\\_map} = \\frac{1}{N} \\sum_{i=1}^{N} MSELoss(\\mathcal{D}_i, \\hat{\\mathcal{D}}_i),\\)\nwhere \u010e\u00bf and \u00d4\u0189 represent the actual and predicted distance maps respectively. Each element Dkij in \u010e\u00bf is the Euclidean distance between the j-th atom in the ligand and the k-th residue in the pocket. Similarly, Dik in D\u00bf corresponds to the predicted pairwise distances."}, {"title": "A.2 PSEUDO CODE OF FABFLEX", "content": "To intuitively elucidate the comprehensive inference processes of FABFlex, we delineate the pseudo code in Algorithm 1. The inference begins with the pocket prediction module, which identifies the binding pocket sites. Subsequently, the ligand and pocket docking modules iteratively refine and predict the holo structures of ligands and pockets."}, {"title": "B EXPERIMENTAL DETAILS", "content": null}, {"title": "B.1 DETAILS OF DATASET PREPROCESSING", "content": "PDBBind v2020 is a widely utilized benchmark database in related molecular docking research. It collected 19,443 experimentally measured protein-ligand complexes along with their 3D structures. Due to the absence of apo protein structures in the dataset, we follow Lu et al. (2024) and employ the well-established AlphaFold2 to predict the apo conformations of these protein structures. Consistent with above mentioned studies, we adopt the same dataset split strategy to enhance comparability. From the dataset, we select 303 test complexes recorded after 2019 and 734 validation complexes recorded before 2019, with the remaining complexes allocated for training. For the training set, complex samples that could not be processed by RDKit or TorchDrug are excluded. Further filtering excludes samples with protein amino acid chains longer than 1500 residues and molecules larger than 150 heavy atoms, resulting in a refined set of 12,807 training complexes. The statistics of the dataset are summarized in Table 4."}, {"title": "B.2 BASELINES", "content": "We compare our proposed method with a variety of competitors, including traditional molecular docking software and recent deep learning-based methods:"}, {"title": "B.3 DETAILS OF IMPLEMENTATION SETTING", "content": "Model Configuration. The dimension d' of initial features extracted via TorchDrug for ligand atoms is set to 56, and the dimension dr of ESM-2 features for amino acid is 1280. The number of FABind-layers is configured as {1, 5, 5} for pocket prediction module, ligand docking module and pocket docking module, respectively. The number of hidden size is set to {128, 512, 512} for the same modules in the corresponding order. The pocket radius of 20\u00c5 is used to delineate the binding pocket sites for each ligand-protein complex.\nTraining details. Simultaneously optimizing all three subtasks of blind flexible docking from scratch is a challenging task. We introduce a two-stage pretraining process to warm up the model. In the first stage, the model is trained under rigid docking conditions, using a (holo protein, apo ligand) pair to predict the holo ligand structure. In the second stage, the model is trained using an (apo protein, holo ligand) pair to predict the holo pocket structure. After that, the model under-goes joint training to predict both the holo ligand and holo pocket from (apo protein, apo ligand) inputs. This progressive approach allows the model to learn from simpler tasks to more complex ones, facilitating the solution of blind flexible docking.\nTraining Configuration. Table 5 summarizes the training configurations in this study. The ex-periments are conducted using the Pytorch framework. The model is trained on eight NVIDIA RTX 4090 GPUs. The pretraining stages 1 and 2 reduce task difficulty by fixing either the small molecule or the protein as the holo structure while keeping the other as the apo structure, to warm up the model. The approximate training durations for pretraining stages 1 and 2, as well as the joint training stage, are {10, 5, 5} days, respectively. The configurations vary slightly across different stages, mainly in terms of learning rate, and the application of teacher forcing. During the pretrain-ing stages, and teacher forcing are utilized to kick-start the model effectively. As the progress to the joint training stage, the learning rate is reduced to better adapt the model to flexible docking."}, {"title": "C ADDITIONAL EXPERIMENTAL RESULTS", "content": null}, {"title": "C.1 DISTRIBUTION OF LIGAND PERFORMANCE", "content": "To showcase the ligand performance comprehensively, Fig. 6 provides the cumulative distibution"}]}