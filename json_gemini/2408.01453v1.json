{"title": "Reporting and Analysing the Environmental Impact of Language Models on the Example of Commonsense Question Answering with External Knowledge", "authors": ["Aida Usmanova", "Junbo Huang", "Debayan Banerjee", "Ricardo Usbeck"], "abstract": "Human-produced emissions are growing at an alarming rate, causing already observable changes in the climate and environment in general. Each year global carbon dioxide emissions hit a new record, and it is reported that 0.5% of total US greenhouse gas emissions are attributed to data centres as of 2021 ([20]). The release of ChatGPT in late 2022 sparked social interest in Large Language Models (LLMs), the new generation of Language Models with a large number of parameters and trained on massive amounts of data. Currently, numerous companies are releasing products featuring various LLMs, with many more models in development and awaiting release. Deep Learning research is a competitive field, with only models that reach top performance attracting attention and being utilized. Hence, achieving better accuracy and results is often the first priority, while the model's efficiency and the environmental impact of the study are neglected. However, LLMs demand substantial computational resources and are very costly to train, both financially and environmentally. It becomes essential to raise awareness and promote conscious decisions about algorithmic and hardware choices. Providing information on training time, the approximate carbon dioxide emissions and power consumption would assist future studies in making necessary adjustments and determining the compatibility of available computational resources with model requirements. In this study, we infused T5 LLM with external knowledge and fine-tuned the model for Question-Answering task. Furthermore, we calculated and reported the approximate environmental impact for both steps. The findings demonstrate that the smaller models may not always be sustainable options, and increased training does not always imply better performance. The most optimal outcome is achieved by carefully considering both performance and efficiency factors.", "sections": [{"title": "I. INTRODUCTION", "content": "With the growing problem of climate change, LLMs can potentially accelerate that process by contributing to greenhouse gas emissions. LLMs with billions of parameters may require several weeks of training time, and this duration is expected to increase further with the emergence of new models ([6, 12, 22]). I demonstrates the most recent LLMs released by famous research labs, the number of parameters of each model, the estimated emissions in net metric tons CO2eq and the equivalence in flights. The amount of produced emissions doubles if taken into consideration the manufacturing of computers. Considering the computational expenses involved, it is only essential to prevent executing identical experiments and adopt a sustainability mindset in research endeavours. This means that researchers have to report not only performance but also training time, energy consumption, pre-training and fine-tuning requirements, and any other metrics that demonstrate the model's efficiency. Reporting training time and energy consumption can help to identify resource-intensive approaches to avoid or optimize them later. Carbon dioxide equivalence helps to assess the environmental impact of the research holistically. Ultimately, understanding and minimizing resource consumption and reducing carbon emissions promote the development of more sustainable practices and making informed decisions towards effective and efficient solutions.\nIn this study, we focus on Commonsense Reasoning and Question-Answering NLP tasks. Commonsense is a set of implicit pre-knowledge about the everyday world. For example, it is common knowledge that a refrigerator can be found in the kitchen and that summer comes after spring. Commonsense reasoning requires human experience, together with social, physical, temporal and spatial information of everyday life. Learning and using implicit knowledge for humans is an easy everyday task, which makes their language concise yet precise. However, machines do not possess common sense and are not able to learn such knowledge"}, {"title": "II. RELATED WORK", "content": "Many advocate making efficiency reports a routine practice in deep learning research. Yet, when diving deeper into the problem, it is clear that part of the reason why very few researchers report efficiency results is because of the absence of a standard of measurement. There are numerous metrics available to assess the quality of the model, and often times improved performance means a better prediction ability. Some even argue that modern AI does not actually learn and is just a result of utilizing massive amounts of data and large computation power. Although sustainability in Al is still in its infancy, there are already great studies being held to bring awareness to the research community. In this section, we mention works that have been held to quantify and measure the carbon footprint of LLMs. By the end of the section, we will also briefly mention studies in knowledge infusion, which is also part of our study.\nMultiple studies have already focused on energy consumption and carbon emissions accounting; some even propose methods for mitigating the problem. Prioritizing the model's efficiency over performance is becoming more relevant as more powerful machines are being developed. Several factors contribute to the increase in training time directly or indirectly, the development of more robust and powerful hardware, more complex machine learning algorithms and approaches, data growth, and social demand.\nThe study of Strubell et al. draws attention to the potentially hazardous impacts of training large models on our environment and proposes solutions to mitigate the problem. As an example, they trained a few state-of-the-art LLMs and put them into perspective by quantifying carbon emissions produced during training. Later they compared the results with the emissions produced during a flight and cloud computing prices. The work has concluded that training BERT emits roughly the same amount of carbon into the atmosphere as a trans-American flight.\nThe work of Wu et al. goes beyond measuring carbon emissions during training. The study also includes model development and inference phases. The authors encourage not only to look at the training phase but to consider the machine learning pipeline end-to-end, starting from data collection until inference. They examine the ML development cycle across the industry scale. Operational and manufacturing carbon footprint is also taken into account, by the end of the study the authors discuss how hardware choices and optimization techniques can help to reduce the carbon footprint of an Al system.\nWork conducted by Patterson et al. proved that most of the companies and research groups try to avoid pre-training and prefer executing fine-tuning and inference stages. The study suggests that such stages are as important as pre-training and should not be neglected when it comes to carbon footprint accounting. The study proved that the inference can produce a significant amount of emissions as well.\nSo far, we have looked into measures for energy consumption and studies conducted on green AI. Now we will inspect KG-infusion methods, as it is a promising approach for carbon footprint reduction by enabling hybrid or neuro-symbolic AI. According to Bauer et al. providing LLMs with external knowledge enhances its ability to reason on a downstream task, i.e. QA, summarization, etc. Knowledge infusion enriches the model's vocabulary and allows it to \"think out of the box\". Some works have already attempted to incorporate commonsense knowledge into the BERT model to enhance reading comprehension (Yang et al.), and relation classification (Zhang et al.).\nA recently conducted study by Lal et al. extends their previous work on Commonsense QA. The authors utilize COMET KG as an external knowledge source and inject the knowledge into the LLM. As a result, they observed an increase in performance. However, none of the studies measure and report the environmental impact of their work."}, {"title": "III. EXPERIMENTAL SETUP", "content": "As external knowledge for our LLM, we combined ConceptNet (Speer et al.) and ATOMIC (Sap et al.), which are both large-scale Knowledge Graphs containing information about events in everyday life. Both KGs have to be pre-processed prior to being fed into the LLM. In the scope of this study, we pre-processed and verbalised only ConceptNet KG and combine it with already pre-processed ATOMIC KG Guan et al. ConceptNet is constructed of multiple triplets (Subject, Relation, Object) with corresponding relation weight. We start by iterating over subjects and sorting them based on their relationship weight. Then we select the top 100 triplets with respect to relation weight and transform them into sentences using simple verbalization templates (Levy et al.), see Figure 1. The combined pre-processed dataset contains 1,174,267 sentences in the train set and 66,856 in the validation set. The dataset contains physical, spatial, social, and temporal aspects of daily life.\nFollowing Lal et al. example, models are fine-tuned on the TellMeWhy corpus, the largest Commonsense QA dataset. It incorporates various stories, 30K open-ended questions, and free-form answers. The provided short narratives describe why characters performed certain actions. The answers can be explicit and found in the narrative, as well as implicit, answers that require external knowledge, some intuitive knowledge about the world.\nAs mentioned before, injecting commonsense knowledge from KG beforehand should prepare a solid base for later fine-tuning."}, {"title": "IV. RESULTS", "content": "In the scope of our study, we conducted 6 experiments, which will be further referred to as follows:\n1) T5s IK: T5-small with injected knowledge from KG\n2) T5b IK: T5-base with injected knowledge from KG\n3) T5s FT: T5-small fine-tuned for QA task\n4) T5b FT: T5-base fine-tuned for QA task\n5) T5s IK+FT: T5-small with injected knowledge from KG and fine-tuned for QA task\n6) T5b IK+FT: T5-base with injected knowledge from KG and fine-tuned for QA task\nAll experiments were performed on 2 NVIDIA RTX A5000 GPU blocks with 24GB memory each. The implementation is available on GitHub\u00b9.\nTo evaluate the model's performance, we utilized the same metrics as Lal et al. BLEURT (Sellam et al.) and BLEU (Papineni et al.) scores are both learned evaluation metrics for natural text generation based on BERT. Being trained on WMT human annotations for the machine translation task, they correlate well with human judgments. The scores are generated based on the precision of tokens of a candidate sentence to the reference. While BertScore (Zhang et al.) uses only pre-trained contextual embeddings from BERT and matches words between two sentences by cosine similarity.\nWe also measured cosine similarity between the generated and the target answers and analysed the number of unique words presented in answer vocabulary that does not exist in context vocabulary.\nTable II presents the model performance in various setups, the automatic evaluation provided on the official TellMeWhy GitHub repository\u00b2. Based on the results, we cannot prove that infusing T5 with commonsense knowledge from ConceptNet and ATOMIC influences the model's ability to reason. This could be due to the large size of the C4 corpus, and, thus, KGs ConceptNet, and ATOMIC failing to provide enough knowledge to teach the network. However, we can conclude that the T5 model is inherently bad at commonsense reasoning, due to the type of data it has been pre-trained on.\nYet, there is an observable difference in results between T5s FT and T5s IK+FT across most of the metrics. T5s IK+FT performed slightly better than T5s FT. The difference in the BLEU score is 1.01 and in BertScore is 2.4%, both are noticeable differences, considering the evaluation is for similar models and on the same dataset. We assume that due to the smaller size of the T5-small model, the significance of commonsense knowledge from ConcentNet and ATOMIC was more prominent. Compared to T5-base, T5-small seems to gain more from the knowledge infusion step. While for T5-base, ConceptNet and ATOMIC KGs are too small to make a visible difference.\nThe BLEURT score demonstrates that for all experiments, there exists a negative correlation between predicted and reference answers. The BLEURT and BLEU scores were specifically designed to assess the quality of the machine translation; this could explain the insignificance of the results. However, since BertScore only uses BERT embeddings and calculates the cosine similarity between two sentences, we observe a higher correlation between the predicted and goal answers.\nSimilarly to Lal et al., models perform best when the answer is explicitly given in the context. We observed a slight performance increase for T5b IK+FT compared to the T5 base results of Lal et al. We anticipate that the ROUGE F-1 and BertScores scores are higher in our experiments, compared to that of Lal et al., because we set max_len_seq to 200, as this was the size of the longest token in our case. However, we still came to the conclusion that the most influence comes from fine-tuning step, but it seems like knowledge infusion makes some difference for smaller models.\nIt is worth noting that the comparable results in our experiments were achieved with fewer epochs. Lal et al. suggests that T5-base reaches the best performance between epochs 30 and 50. However, we could see that longer training does not add much to the performance and adding EarlyStopping is necessary to prevent not only overfitting but also resource over usage.\nThe semantic similarity between the answers increases as the training time and size of a model also increase, but the difference is not significant. Surprisingly, infusing models with commonsense knowledge and fine-tuning on QA resulted in the model using more TellMeWhy context vocabulary rather than the model that was just fine-tuned on QA."}, {"title": "C. Efficiency Metrics", "content": "Some studies provide great solutions to facilitate carbon emissions and energy consumption calculation. Anthony et al. developed a library that accesses information about hardware and calculates the estimates after the first epoch. Their Carbontracker gives information about approximate carbon emissions in grams, energy consumption (KW/h), and an equivalent number of kilometres the car would have driven producing the same amount of emissions. Alternatively, Lacoste et al. developed a tool that can be used after executing experiments. By providing training time, location, and hardware type, you can estimate produced CO2 emissions and also how much would have been emitted if the experiment was held in a different datacenter.\nIn our study, we embedded Carbontracker (Anthony et al.) into the training loop, which approximates carbon emissions and power usage for the whole training after 1 epoch. The following formula 1 is used to calculate the power usage of an experiment pt. The average GPU power draw pg is usually obtained by querying the NVIDIA System Management Interface throughout the run. The value is then multiplied by the number of GPUs g and the Power Usage Effectiveness Coefficient (PUE) (1.55 for Germany\u00b3).\n$P_t = \\frac{1.55* t *g* P_g}{1000}$ (1)\nThe number of emissions and power consumption depends on the data center location and the local power grid it is connected to. The same experiments executed in two different locations may have different environmental impacts. As of 2022, the power sector emissions in Germany were approximately 380 grams of carbon dioxide produced per kilowatt-hours (gCO2/KWh) for generated electricity. To get the carbon emissions equivalence estimation (in kg per kilowatt-hour), emissions per hour are multiplied by the experiment's power usage, as shown in Formula 2.\n$CO2e = 0.380 * p_t$(2)\nWe report the overall time it took to execute one experiment, the energy use, carbon dioxide emissions equivalence, and the equivalence in travel by car, in Table III."}, {"title": "D. Efficiency analysis", "content": "Table III presents the training time of each experiment and corresponding efficiency metrics calculated by Carbontracker. Since we set an early stopping during the fine-tuning step, none of the experiments reached the maximum number of epochs. T5s FT ran until 12, while T5s IK+FT until 13, both T5b FT and T5b IK+FT stopped after 6 epochs. This fact demonstrates the importance of early stopping in research to prevent unnecessary resource waste and energy consumption when the models do not need long training. Clearly, the pre-training phase required a much longer training time, the difference between minor and base variants is also significant, with T5-base requiring 3 times more hours to complete 1 epoch. Having a look at the fine-tuning stage, we can see that the difference between T5s FT and T5b FT is around 2 hours, but T5b FT outperforms the former. In our case, pre-training and fine-tuning T5-small did not give a desirable performance, hence T5-base is preferred even with a longer training time.\nLooking at T5b FT and T5b IK+FT, we noticed that the latter outperforms the first one only by a mere percentage based on BLEU, F1 and BLEURT scores. On the contrary, BERTscore for T5b FT has been consistently higher than that for T5b IK+FT."}, {"title": "V. CONCLUSION", "content": "Numerous factors could have influenced the outcome of our study. We assume that among these factors, the nature of the data that we infused into our model influenced the most. While sorting the KG based on relation weight and extracting top N triples seems like a straightforward approach, it yields suboptimal results. The main limitation lies in the lack of diversity within the dataset, with many sentences being semantically close and having limited number of relationship types.\n\u2022\n\u2022\nWhen looking for a balance between performance and efficiency, T5b FT seems like a more reasonable choice.\nWe need more sophisticated approaches to linearize KGs in a meaningful way\nOur study showed that it is important to consider a model not solely based on one parameter. Focusing only on performance could lead to uncontrollable energy waste, while trying to reduce energy consumption too much can lead to a weak model that is less sustainable in the long run. The balance between the two is the key to the most optimal solution.\nTracking carbon footprint at every stage of the study is an extremely challenging task and has much more room for improvement regarding the report standards. To get the full picture, one might also need to know how much it takes to build hardware, transport them to the data center, as well as consider the lighting in the room, etc. Nevertheless, it is important to be aware of the factors that impact the quantity of carbon emissions produced by research. As we have seen, stages like fine-tuning can also produce an observable amount of emissions. Such a step towards a positive change can also greatly help follow-up studies in the field."}, {"title": "LIMITATIONS", "content": "Our study includes several limitations that couldn't been addressed in this study and could be an idea for future work. Firstly, the Knowledge Infusion part of our study did not yield desirable results due to the poor KG linearization strategy. This stage also took the most time to be executed and consumed the most computational power. Secondly, Due to server limitations, we couldn't perform any experiments on T5-large model, which restricts us from making bolder statements on LLM performance on the CSQA task. In this work, we wanted to draw attention to the importance of considering efficiency results together with the performance results of the study."}, {"title": "ETHICS STATEMENT", "content": "Our research focuses on accounting and reporting the environmental impact of LLMs. Such studies raise concerns about transparency and accountability of Deep Learning approaches. It is crucial that the processes and algorithms used in any study are transparent and open to scrutiny. We commit to making our methods and data publicly available for review and validation by the broader community.\nWhile the benefits of this research field are clear, it is essential to acknowledge and address potential ethical considerations. Calculating the exact amount of emitted carbon into the atmosphere presents a challenging task that requires acquiring server production and transportation information, as well as considering local energy grid and its fuel type. Furthermore, we should also scrutinise the Deep Learning model exploitation and life-cycle periods to get a clearer picture of its environmental impact. Hence, this field of study still requires extensive research with its potential positive impact on the research community."}]}