{"title": "Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation", "authors": ["F. HILLERSTR\u00d6M", "G.J. BURGHOUTS"], "abstract": "Many inductive logic programming (ILP) methods are incapable of learning programs from probabilistic background knowledge, e.g. coming from sensory data or neural networks with probabilities. We propose Propper, which handles flawed and probabilistic background knowledge by extending ILP with a combination of neurosymbolic inference, a continuous criterion for hypothesis selection (BCE) and a relaxation of the hypothesis constrainer (NoisyCombo). For relational patterns in noisy images, Propper can learn programs from as few as 8 examples. It outperforms binary ILP and statistical models such as a Graph Neural Network.", "sections": [{"title": "1 Introduction", "content": "Inductive logic programming (ILP) Muggleton (1995) learns a logic program from labeled examples and background knowledge (e.g. relations between entities). Due to the strong inductive bias imposed by the background knowledge, ILP methods can generalize from small numbers of examples Cropper et al. (2022). Other advantages are the ability to learn complex relations between the entities, the expressiveness of first-order logic, and the resulting program can be understood and transferred easily because it is in symbolic form Cropper and Duman\u010di\u0107 (2022). This makes ILP an attractive alternative methodology besides statistical learning methods.\nFor many real-world applications, dealing with noise is essential. Mislabeled samples are one source of noise. To learn from noisy labels, various ILP methods have been proposed to generalize a subset of the samples Srinivasan (2001); Ahlgren and Yuen (2013);\nZeng et al. (2014); De Raedt et al. (2015). To advance methods to learn recursive programs and predicate invention, Hocquette et al. (2024) proposed a method that searches for small programs that generalize subsets of the samples and are combined, as in Cropper and Hocquette (2023), under relaxed conditions to allow for mislabeled samples, while trading off program complexity for training accuracy. These methods are dealing with noisy labels, but do not explicitly take into account errors in the background knowledge, nor are they designed to deal with probabilistic background knowledge.\nMost ILP methods take as a starting point the inputs in symbolic declarative form Cropper et al. (2021). Real-world data often does not come in such a form. A predicate p(.), detected in real-world data, is neither binary or perfect. The assessment of the predicate can be uncertain, resulting in a non-binary, probabilistic predicate. Or the assessment can be wrong, leading to imperfect predicates. Dealing with noisy and probabilistic background knowledge is relevant for learning from sources that exhibit uncertainties. A probabilistic source can be a human who needs to make judgements at an indicated level of confidence. A source can also be a sensor measurement with some confidence. For example, an image is described by the objects that are detected in it, by a deep learning model. Such a model predicts locations in the image where objects may be, at some level of confidence. Some objects are detected with a lower confidence than others, e.g. if the object is partially observable or lacks distinctive visual features. The deep learning model implements a probabilistic predicate that a particular image region may contain a particular object, e.g. 0.7 :: vehicle(x). Given that most object detection models are imperfect in practice, it is impossible to determine a threshold that distinguishes the correct and incorrect detections.\nIn Helff et al. (2023) it was shown that two common ILP frameworks, Aleph Srinivasan (2001) and Popper Cropper and Morel (2021), typically fail to find the correct programs when dealing with predicted objects in images; even with a state-of-the-art object detection model, and after advanced preprocessing of said detections. In the absence of an ideal binarization of probabilities, most ILP methods are not applicable to probabilistic sources Cropper et al. (2021).\nWe propose a method towards probabilistic ILP. At a high level, ILP methods typically induce a logical program that entails many positive and few negative samples, by searching the hypothesis space, and subsequently testing how well the current hypothesis fits the training samples Cropper and Duman\u010di\u0107 (2022). One such method is Popper, which learns from failures Cropper and Morel (2021) (LFF), in an iterative cycle of generating hypotheses, testing them and constraining the hypothesis search. Our proposal is to introduce a probabilistic extension to LFF at the level of hypothesis testing. For that purpose, we consider neurosymbolic AI Garcez et al. (2019). Within neurosymbolic AI a neural network predicts the probability for a predicate. For example a neural network for object detection, which outputs a probability for a particular object being present in an image region, e.g., 0.7 :: vehicle(x). Neurosymbolic AI connects this neural network with knowledge represented in a symbolic form, to perform reasoning over the probabilistic predicates predicted by the neural network. With this combination of a neural network and symbolic reasoning, neurosymbolic AI can reason over unstructured inputs, such as images. We leverage neurosymbolic programming and connect it to the tester within the hypothesis search. One strength of neurosymbolic programming is that it can deal with uncertainty and imperfect information Garcez et al. (2019); De Raedt et al. (2020);\nHuang et al. (2021); Li et al. (2024), in our case the probablistic background knowledge.\nWe propose to use neurosymbolic inference as tester in the test-phase of the LFF cycle. Neurosymbolic reasoning calculates an output probability for a logical query being true, for every input sample. The input samples are the set of positive and negative examples, together with their probabilistic background knowledge. The logical query evaluated within the neurosymbolic reasoning is the hypothesis generated in the generate-phase of the LFF cycle, which is a first-order-logic program. With the predicted probability of the hypothesis being true per sample, it becomes possible to compute how well the hypothesis fits the training samples. That is used to continue the LFF cycle and generate new constraints based on the failures.\nOur contribution is a step towards probabilistic ILP by proposing a method called Propper. It builds on an ILP framework that is already equipped to deal with noisy labels, Popper-MaxSynth Cropper and Morel (2021); Hocquette et al. (2024), which we extend with neurosymbolic inference which is able to process probabilistic facts, i.e. uncertain and imperfect background knowledge. Our additional contributions are a continuous criterion for hypothesis selection, that can deal with probabilities, and a relaxed formulation for constraining the hypothesis space. Propper and the three contributions are outlined in Figure 1. We compare Popper and Propper with statistical ML models (SVM and Graph Neural Network) for the real-life task of finding relational patterns in satellite images based on objects predicted by an imperfect deep learning model. We validate the learning robustness and efficiency of the various models. We analyze the learned logical programs and discuss the cases which are hard to predict."}, {"title": "2 Related Work", "content": "For the interpretation of images based on imperfect object predictions, ILP methods such as Aleph Srinivasan (2001) and Popper Cropper and Morel (2021) proved to be vulnerable and lead to incorrect programs or not returning a program at all Helff et al. (2023). Solutions to handle observational noise were proposed Cropper and Duman\u010di\u0107 (2021) for small binary images. In Muggleton et al. (2018) images were analyzed via physical properties. This method could estimate the direction of the light source or the position of a ball from images in very specific conditions or without clutter or distractors. In Dai and Muggleton (2020), neural networks were learned jointly with induction of recursive first-order logic theories with predicate invention. This was demonstrated on small binary images of digits. Real-life images are more complex and cluttered. We aim to extend these works to realistic samples, e.g. large color images that contain many objects under partial visiblity and in the midst of clutter, causing uncertainties. Contrary to Dai and Muggleton (2020), we take pretrained models as a starting point, as they are often already very good at their task of analyzing images. Our focus is on extending ILP to handle probabilistic background knowledge.\nIn statistical relational artificial intelligence (StarAI) Raedt et al. (2016) the rationale is to directly integrate probabilities into logical models. StarAI addresses a different learning task than ILP: it learns the probabilistic parameters of a given program, whereas ILP learns the program Cropper et al. (2021). Probabilities have been integrated into ILP previously. Aleph Srinivasan (2001) was used by Huynh and Mooney (2008) to find interesting clauses and then learn the corresponding weights. ProbFOIL De Raedt et al. (2015) and SLIPCOVER Bellodi and Riguzzi (2015) search for programs with probabilities associated to the clauses, to deal with the probabilistic nature of the background knowledge. SLIPCOVER searches the space of probabilistic clauses using beam search. The clauses come from Progol Muggleton (1995). Theories are searched using greedy search, where refinement is achieved by adding a clauses for a target predicate. As guidance the log likelihood of the data is considered. SLIPCOVER operates in a probabilistic manner on binary background knowledge, where our goal is to involve the probabilities associated explicitly the background knowledge.\nHow to combine these probabilistic methods with recent ILP frameworks is unclear. In our view, it is not trivial and possibly incompatible. Our work focuses on integrating a probabilistic method into a modern ILP framework, in a simple yet elegant manner. We replace the binary hypothesis tester of Popper Cropper and Morel (2021) by a neurosymbolic program that can operate on probabilistic and imperfect background knowledge Garcez et al. (2019); De Raedt et al. (2020). Rather than advanced learning of both the knowledge and the program, e.g. Mao et al. (2019), we take the current program as the starting point. Instead of learning parameters, e.g. Huang et al. (2021), we use the neurosymbolic program for inference given the program and probabilistic background knowledge. Real-life samples may convey large amounts of background knowledge, e.g. images with many objects and relations between them. Therefore, scalability is essential. Scallop Huang et al. (2021) improved the scalability over earlier neurosymbolic frameworks such as DeepProbLog Manhaeve et al. (2021a;b). Scallop introduced a tunable parameter k to restrain the validation of hypotheses by analyzing the top-k proofs. They asymptotically reduced the computational cost while providing relative accuracy guarantees. This is beneficial for our purpose. By replacing only the hypothesis tester, the strengths of ILP (i.e. hypothesis search) are combined with the strengths of neurosymbolic inference (i.e. probabilistic hypothesis testing)."}, {"title": "3 Propper Algorithm", "content": "To allow ILP on flawed and probabilistic background knowledge, we extend modern ILP (Section 3.1) with neurosymbolic inference (3.2) and coin our method Propper. The neurosymbolic inference requires program conversion by grammar functions (3.3), and we added a continuous criterion for hypothesis selection (3.4), and a relaxation of the hypothesis constrainer (3.5)."}, {"title": "3.1 ILP: Popper", "content": "Popper represents the hypothesis space as a constraint satisfaction problem and generates constraints based on the performance of earlier tested hypotheses. It works by learning from failures (LFF) Cropper and Morel (2021). Given background knowledge B, represented as a logic program, positive examples E+ and negative examples E\u00af, it searches for a hypothesis H that is complete (\u2200e \u2208 E+, B\u222aH |= e) and consistent (\u2200e \u2208 E\u00af, B\u222aH |\\= e). The algorithm consists of three main stages (see Figure 1, left). First a hypothesis in the form of a logical program is generated, given the known predicates and constraints on the hypothesis space. The Test stage tests the generated logical program against the provided background knowledge and examples, using Prolog for inference. It evaluates whether the examples are entailed by the logical program and background knowledge. From this information, failures that are made when applying the current hypothesis, can be identified. These failures are used to constrain the hypothesis space, by removing specializations or generalizations from the hypothesis space. In the original Popper implementation Cropper and Morel (2021), this cycle is repeated until an optimal solution is found; the smallest program that covers all positives and no negative examples (see Cropper and Morel (2021) for a formal definition). Its extension Combo combines small programs that do not entail any negative example Cropper and Hocquette (2023). When no optimal solution is found, Combo returns the obtained best solution. The Popper variant MaxSynth does allow noise in the examples and generates constraints based on a minimum description length cost function, by comparing the length of a hypothesis with the possible gain in wrongly classified examples Hocquette et al. (2024)."}, {"title": "3.2 Neurosymbolic Inference: Scallop", "content": "Scallop is a language for neurosymbolic programming which integrates deep learning with logical reasoning Huang et al. (2021). Scallop reasons over continuous, probabilistic inputs and results in a probabilistic output confidence. It consists of two parts: a neural model that outputs the confidence for a specific concept occurring in the data and a reasoning model that evaluates the probability for the query of interest being true, given the input. It uses provenance frameworks Kimmig et al. (2017) to approximate exact probabilistic inference, where the AND operator is evaluated as a multiplication (AND(x,y) = x*y), the OR as a minimization (OR(x, y) = min(1, x + y)) and the NOT as a 1 - x. Other, more advanced formulations are possible, e.g. noisy-OR(x,y) = 1 \u2212 (1 \u2212 a)(1 \u2013 b) for enhanced performance. For ease of integration, we considered this basic provenance. To improve the speed of the inference, only the most likely top-k hypotheses are processed, during the intermediate steps of computing the probabilities for the set of hypotheses."}, {"title": "3.3 Connecting ILP and Neurosymbolic Inference", "content": "Propper changes the Test stage of the Popper algorithm (see Figure 1): the binary Prolog reasoner is replaced by the neurosymbolic inference using Scallop, operating on probabilistic background knowledge (instead of binary), yielding a probability for each sample given the logical program. The background knowledge is extended with a probability value before each first-order-logic statement, e.g. 0.7 :: vehicle(x)."}, {"title": "3.4 Selecting the Best Hypothesis", "content": "MaxSynth uses a minimum-description-length (MDL) cost to select the best solution: MDLB,E = size(h) + fnB,E(h) + fPB,E(h) Hocquette et al. (2024). The MDL cost compares the number of correctly classified examples with the number of literals in the program. This makes the cost dependent on the dataset size and requires binary predictions in order to determine the number of correctly classified examples. Furthermore, it is doubtful whether the number of correctly classified examples can be compared directly with the rule size, since it makes the selection of the rule size dependent on the dataset size again.\nPropper uses the Binary Cross Entropy (BCE) loss to compare the performance of hypotheses, as it is a more continuous measure than MDL. The neurosymbolic inference predicts an output confidence for an example being entailed by the hypothesis. The BCE-cost compares this predicted confidence with the groundtruth (one or zero). For yi being the groundtruth label and pi the confidence predicted via neurosymbolic inference for example i, the BCE cost for N examples becomes: \u0412\u0421\u0415 = 1/N* \u03a3i=1N(yi *log(pi) + (1 \u2212 yi)*log(1-pi)). Scallop reasoning automatically avoids overfitting, by punishing the size of the program, because when adding more or longer clauses the probability becomes lower by design. The more ANDs in the program, the lower the output confidence of the Scallop reasoning, due to the multiplication of the probabilities. Therefore, making a program more specific will result in a higher BCE-cost, unless the specification is beneficial to remove FPs. Making the program more generic will cover more samples (due to the addition operator for the OR). However the confidences for the negative samples will increase as well, which will increase the BCE-cost again. The BCE-cost is purely calculated on the predictions itself, and thereby removes the dependency on the dataset size and the comparison between number of samples and program length."}, {"title": "3.5 Constraining on Inferred Probabilities", "content": "Whereas Combo Cropper and Hocquette (2023) and MaxSynth Hocquette et al. (2024) yield optimal programs given perfect background knowledge, with imperfect and probabilistic background knowledge no such guarantees can be provided. The probabilistic outputs of Scallop are converted into positives and negatives before constraining. The optimal threshold is chosen by testing 15 threshold values, evenly spaced between 0 and 1 and selecting the threshold resulting in the most highest true positives plus true negatives on the training samples.\nMaxSynth generates constraints based on the MDL loss Hocquette et al. (2024), making the constraints dependent on the size of the dataset. To avoid this dependency, we introduce the NoisyCombo constrainer. Combo generates constraints once a false positive (FP) or negative (FN) is detected. \u2203e \u2208 E\u00af, B\u222aH |= e: prune generalisations. \u2203e\u2208 E+, B\u222aH |\\= e or \u2200e \u2208 E\u00af, B\u222aH |\\= e: prune specialisations. NoisyCombo relaxes this condition and allows a few FPs and FNs to exist, depending on an expected noise level, inspired by Muggleton et al. (2018). This parameter defines a percentage of the examples that could be imperfect, from which the allowed number of FPs and FNs is calculated. \u03a3(e\u2208 E\u00af, B\u222aH |= e) > noise_level * Nnegatives: prune generalisations. \u2200e \u2208 E\u00af, B\u222aH |\\= e: prune specialisations. The positives are not thresholded by the noise level, since programs that cover at least one positive sample are added to the combiner."}, {"title": "4 Analyses", "content": "We validate Propper on a real-life task of finding relational patterns in satellite images, based on flawed and probabilistic background knowledge about the objects in the images, which are predicted by an imperfect deep learning model. We analyze the learning robustness under various degrees of flaws in the background knowledge. We do this for various models, including Popper (on which Propper is based) and statistical ML models. In addition, we establish the learning efficiency for very low amounts of training data, as ILP is expected to provide an advantage because it has the inductive bias of background knowledge. We analyze the learned logical programs, to compare them qualitatively against the target program. Finally, we discuss the cases that are hard to predict."}, {"title": "4.1 First Dataset", "content": "The DOTA dataset Xia et al. (2018) contains many satellite images. This dataset is very challenging, because the objects are small, and therefore visual details are lacking. Moreover, some images are very cluttered by sometimes more than 100 objects."}, {"title": "4.2 Experimental Setup", "content": "The dataset is categorized into three subsets that are increasingly harder in terms of flaws in the background knowledge. Easy: This smallest subset excludes the incorrect groundtruths, a manual check that most object predictions are reasonable, i.e. images with many predicted objects are withheld (this includes images with many false positives). Intermediate: This subset excludes the incorrect groundtruths. Compared to Easy, this subset adds all images with many object predictions. Hard: This is the full set, which includes all images, also the ones with incorrect groundtruths. We are curious whether ILP methods can indeed generalize from small numbers of examples, as is hypothesized Cropper et al. (2022). Many datasets used in ILP are using training data with tens to hundreds (sometimes thousands) of labeled samples, see e.g. Hocquette et al. (2024) and Bellodi and Riguzzi (2015). We investigate the performance for as few as {1, 2, 4, 8} labels for respectively the positive and negative set, as this is common in practical settings. Moreover, common ILP datasets are about binary background knowledge, without associated probabilities, see e.g. Hocquette et al. (2024) and Bellodi and Riguzzi (2015). In contrast, we consider probabilistic background knowledge. From the Easy subset we construct an Easy-1.0 set by thresholding the background knowledge with a manually chosen optimal threshold, which results in an almost noiseless dataset and shows the complexity of the logical rule to learn. All experiments are repeated 5 times, randomly selecting the training samples from the dataset and using the rest of the data set as test set."}, {"title": "4.3 Model Variants and Baselines", "content": "We compare Propper with Popper (on which it builds), to validate the merit of integrating the neurosymbolic inference and the continuous cost function BCE. Moreover, we compare these ILP models with statistical ML models: the Support Vector Machine Cortes and Vapnik (1995) (SVM) because it is used so often in practice; a Graph Neural Network Wu et al. (2020) (GNN) because it is also relational by design which makes it a reasonable candidate for the task at hand i.e. finding a relational pattern between objects."}, {"title": "4.4 Increasing Noise in Background Knowledge", "content": "We are interested in how the robustness of model learning for increasing difficulty of the dataset. Here we investigate the performance on the three subsets from Section 4.2: Easy, Intermediate and Hard. Figure 4 shows the performance for various models for increasing difficulty. The four subplots show the various types of models. For a reference, the best performing model is indicated by an asterisk (*) in all subplots. It is clear that for increasing difficulty, all models struggle. The statistical ML models struggle the most: the performance of the GNN drops to zero on the Hard set. The SVMs are a bit more robust but the performance on the Hard set is very low. The most basic variant of Popper also drops to zero. The noise-tolerant Popper variants (Noisy-Combo and MaxSynth) perform similarly to the SVMs. Propper outperforms all models. This finding holds for all Propper variants (Combo, Noisy-Combo and MaxSynth). Using BCE as a cost function yields a small but negligible advantage over MDL."}, {"title": "4.5 Learning Efficiency with Few Labels", "content": "We are curious how the models perform with as few as {1, 2, 4, 8} labels for respectively the positive and negative set. The performance is measured on the Hard set. Figure 5 shows the performance for various models for increasing training set size. The four subplots show the various types of models. Again, for reference, the best performing model is indicated by an asterisk (*) in all subplots. The upper left shows the statistical ML models. They do perform better with more training samples, but the performance is inferior to the ILP model variants. The Propper variant with Scallop and Noisy-Combo and BCE is the best performer. BCE does not improve significantly over MDL. MaxSynth has an optimization criterion that cannot operate with less than three training samples. The main improvement by Propper is observed when switching from Combo to Noisy-Combo and switching from Prolog to Scallop (i.e. neurosymbolic inference)."}, {"title": "4.6 Second Dataset", "content": "We are interested how the methods perform on a different dataset. The MS-COCO dataset Lin et al. (2014) contains a broad variety of images of everyday scenes. This dataset is challenging, because there are many different objects in a wide range of settings. Similar to the previous experiment, the background knowledge is acquired by the predictions of a pretrained model Liu et al. (2023) which are used to extract the same two relations."}, {"title": "5 Discussion and Conclusions", "content": "We proposed Propper, which handles flawed and probabilistic background knowledge by extending ILP with a combination of neurosymbolic inference, a continuous criterion for hypothesis selection (BCE), and a relaxation of the hypothesis constrainer (Noisy-Combo). Neurosymbolic inference has a significant impact on the results. Its advantage is that it does not need prior thresholding on the probabilistic background knowledge (BK), which is needed for binary ILP and is always imperfect. NoisyCombo has a small yet positive effect. It provides a parameter for the level of noise in BK, which can be tailored to the dataset at hand. The BCE has little impact. Propper is able to learn a logic program about a relational pattern that distinguishes between two sets of images, even if the background knowledge is provided by an imperfect neural network that predicts concepts in the images with some confidence. With as few as a handful of examples, Propper learns effective programs and outperforms statistical ML methods such as a GNN.\nAlthough we evaluated Propper on two common datasets with different recording conditions, a broader evaluation of Propper across various domains and datasets to confirm its generalizability and robustness for various (especially non-image) use cases, is interesting. The proposed framework of integrated components allows for an easy setup of the system and simple adaptation to new developments/algorithms within the separate components. However, the integration as is performed now could be non-optimal in terms of computational efficiency. For example the output of the hypothesis generation is an answer set, which in Popper is converted to Prolog syntax. Propper converts this Prolog syntax to Scallop syntax. Developing a direct conversion from the answer sets to the Scallop syntax is recommended. We favored modularization over full integration and computational efficiency, in order to facilitate the methodological configuration and comparison of the various components. It is interesting to investigate whether a redesign of the whole system with the components integrated will lead to a better system. To make the step to fully probabilistic ILP, the allowance of probabilistic rules should be added to the system as well, for example by integration of StarAI methods Raedt et al. (2016)."}]}