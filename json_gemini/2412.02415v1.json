{"title": "Knowledge-Enhanced Conversational Recommendation via Transformer-based Sequential Modelling", "authors": ["JIE ZOU", "AIXIN SUN", "CHENG LONG", "EVANGELOS KANOULAS"], "abstract": "In Conversational Recommender Systems (CRSs), conversations usually involve a set of items and item-related\nentities or attributes, e.g., director is a related entity of a movie. These items and item-related entities are\noften mentioned along the development of a dialog, leading to potential sequential dependencies among\nthem. However, most of existing CRSs neglect these potential sequential dependencies. In this paper, we first\npropose a Transformer-based sequential conversational recommendation method, named TSCR, to model\nthe sequential dependencies in the conversations to improve CRS. In TSCR, we represent conversations by\nitems and the item-related entities, and construct user sequences to discover user preferences by considering\nboth the mentioned items and item-related entities. Based on the constructed sequences, we deploy a Cloze\ntask to predict the recommended items along a sequence. Meanwhile, in certain domains, knowledge graphs\nformed by the items and their related entities are readily available, which provide various different kinds of\nassociations among them. Given that TSCR does not benefit from such knowledge graphs, we then propose a\nknowledge graph enhanced version of TSCR, called TSCRKG. In specific, we leverage the knowledge graph to\noffline initialize our model TSCRKG, and augment the user sequence of conversations (i.e., sequence of the\nmentioned items and item-related entities in the conversation) with multi-hop paths in the knowledge graph.\nExperimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines,\nand the enhanced version TSCRKG further improves recommendation performance on top of TSCR.", "sections": [{"title": "1 INTRODUCTION", "content": "In general, a recommender system learns user preference from historical user-item interactions\nand then recommends items based on the learned user preference. The recommended items can\nbe delivered to users through various interfaces, e.g., a list of products on e-commerce websites.\nGenerally, a CRS integrates two modules: a recommender module, and a dialog module. The latter\ngenerates natural language conversations to interact with users. The recommender module focuses\non recommending desirable items to users by utilizing the information from the conversation,\nas well as related information from external sources like historical user-item interactions and\nknowledge bases. In this work, we focus on the recommender module only.\nConversational systems have shown great potential in a wide range of areas, such as information-\nseeking systems [65], conversational product search [114], dialog systems [17, 78], and CRS [75, 117].\nAs for CRS, a number of solutions have been proposed [32, 61, 67, 113], given it is a rapidly\ngrowing research topic in recent years. Early efforts in the development of CRS can be traced\nback to interactive recommendations [29, 36] and question-based recommendations [113]. More\nrecently, two categories of CRSs including anchor based CRSs [113] and dialog based CRSs [117]\nhave been proposed. Anchor based CRSs is based on the \u201csystem asks \u2013 user responds\" mode\nand simulates conversations by using some \u201canchor\u201d text, e.g., item aspects [103], facets [81],\nentities [113, 115, 116], topics [15], and attributes [41, 42, 109]. They usually utilize a belief tracker\nto infer the anchor-based preferences to improve CRS. Another mainstream approach, dialog\nbased CRSs, is based on human-generated dialogs [11, 13, 56, 57, 72, 88, 89, 97, 101, 108, 110].\nFor instance, at the early stage, Li et al. [43] proposed a CRS dataset, ReDial, and presented a"}, {"title": "2 RELATED WORK", "content": "In this section, we review the related work from the following two categories: conversational\nrecommender system and knowledge graph learning. A large number of studies have been conducted\non these topics. In this paper, we will review only the work that is most closely related to our\nresearch."}, {"title": "2.1 Conversational Recommender System", "content": "Thanks to the great power of collecting users' explicit feedback, conversations have shown great\npotential in a wide range of areas, such as information-seeking systems [65], conversational product\nsearch [114], dialog systems [17, 78], and CRS [75, 117]. In information-seeking systems, early explo-\nration investigated mixed-initiative systems by interacting with users via script-based conversation\nduring a search session [4]. Recently, researchers investigated conversational information-seeking\nsystems by asking clarifying questions [1, 118], to enhance the ability to understand the users'\nunderlying information needs and retrieve the right information [1, 28, 65, 69, 93]. In conversational\nproduct search, existing studies usually involve learning to ask strategies [114] to ask informative\nclarifying questions to form conversations [103], in order to locate relevant products a user is\nwilling to purchase [5]. Dialog systems usually structure conversations in multiple turns, including\ntask-oriented systems [58], open-domain dialogs [3], and question-answering dialog systems [17].\nCRS is an emerging field that utilizes human-like natural language to deliver personalized and en-\ngaging recommendations through conversational interfaces like chatbots and intelligence assistants\n[24, 33]. It is gaining considerable attention in recent years, driven by the rapid development of\ndialog systems. When considering CRS primarily as dialog systems, CRS can be regarded as either\n(1) system-driven (e.g., critiquing-based systems [87]), (2) user-driven [55], or (3) mixed-initiative\nsystems (most of CRS approaches) [55, 117], based on who takes the initiative in the dialog [33].\nThe dialog systems could generate flexible and contextual responses, however, they may suffer from\nmeaningless responses and fail to drive the conversation toward more attractive states for making\nrecommendations or suggestions. One type of solution tends to enable conversational systems the\nability for proactive conversations [19, 53, 112] to alleviate this problem. Various aspects have been\nexplored in this field, including proposing new intents and conversational slots through ontology\nexpansion and actively analyzing failures in novel situations (e.g., [50, 52, 99]), learning to ask\nquestions to move the conversation forward (e.g., [66, 113, 114]), leveraging task information and\ndomain knowledge to guide purposeful topic shifts and exploration (e.g., [48, 76]), controlling the\nquality of response generation (e.g., [2, 82]), and improving evaluation (e.g., [83]) etc.\nEarly efforts in the development of CRS can be traced back to the work of Bridge [9], Carenini\net al. [10], Felfernig et al. [22], Mahmood and Ricci [59], and Thompson et al. [85]. More recently,\nvarious feedback mechanisms have been explored [12, 16, 25, 35, 54, 71, 94, 98, 105]. Zhao et al. [105]\ninvestigated interactive collaborative filtering, proposing methods to enhance probabilistic matrix"}, {"title": "2.2 Knowledge Graph Learning", "content": "There has been a growing interest of research on knowledge graph learning. Knowledge graph-\nbased representation learning learns the representations of entities in a knowledge graph in the\nform of high-dimensional vectors, while preserving the intrinsic properties of the knowledge graph.\nThis learned representation can then be conveniently applied to various downstream tasks, such as"}, {"title": "3 SEQUENTIAL CONVERSATIONAL RECOMMENDER SYSTEM", "content": "We suppose there is a user set $U = \\{U_1, U_2, ..., U_{|u|}\\}$, item set $V = \\{v_1, v_2, ..., v_{|v|}\\}$, and conver-\nsations $D$. We extract entities $E = \\{e_1, e_2, ..., e_{|8|}\\ }$ from conversations $D$ based on DBpedia. The\nentity set $E$ consists of all the items and other item-related entities (i.e., $V \\subseteq E$). For a user $u \\in U$,\nwe have his/her entity mention (i.e., items or other item-related entities) history, extracted from\nhis/her conversation, denoted as a sequence $S_u = = [s_1,...,s_k,...,s_k] (s_k \\in E)$, we aim to accurately\npredict the next item $v^*$ that user $u$ likes, along the development of the conversation. The main\nnotations used throughout the paper are summarized in Table 1."}, {"title": "3.1 Base Model", "content": "Inspired by Sun et al. [79], we adopt Transformer [79, 86] as our base model, which consists of the\nembedding layer, self-attention layer, and prediction layer.\nEmbedding layer. Given a sequence, we denote the embedding for the element at position k in\nthe input sequence as $h_k^0$. For the representation of $h_k^0$, we inject a learnable position embedding,\n$p_k$, into the embedding of each element of the input sequence, $s_k$:\n$h_k^0 = s_k + p_k$.\nAll elements together form a trainable embedding matrix $H^0$. Based on this initially trainable\nembedding matrix $H^0$, we interactively calculate $H^n$ at each Transformer layer n.\nSelf-attention layer. A self-attention layer consists of two sub-layers: a multi-head self-attention\nsub-layer and a Position-wise Feed-Forward Network (PFFN). More details can be found in Vaswani\net al. [86].\n$H^{n+1} = MultiHead(PFFN(H^n))$.\nWe construct the PFFN by the Feed-Forward Network (FFN) with GELU activation [30] at each\nposition separately:\n$PFFN(H^n) = [FFN(h_1^n); ... ; FFN(h_K^n)]$.\nIn addition, we deploy a residual connection around each of the two sub-layers, followed by a\ndropout and layer normalization, i.e., the output of each sub-layer is actually:\n$LayerNorm(H^n + Dropout(sublayer(H^n)))$,\nwhere sub-layer is MultiHead or PFFN in Eq. 2.\nPrediction layer. After N layers of Transformer, we get the final output $H^N$ for the input sequence.\nAssuming we mask $s_k$ at the input sequence, we then utilize $h_k^N$ to predict the masked item $s_k$.\nSpecifically, we apply a softmax function through a two-layer FFN with GELU activation in between\nto produce an output distribution over items. To ensure recommendations are all items, we set the\nscore of non-item entities in the softmax function to -\u221e.\nIn this work, we adopt the Transformer architecture, which utilizes attention mechanisms to\ncapture temporal relations while processing input tokens of a sequence in parallel. The Trans-\nformer architecture has been demonstrated as a powerful framework for supporting large-scale\ntraining datasets with enough parameters [49]. Notably, the Transformer architecture makes few\nprior assumptions about the structural information of data but does not make any assumptions\nabout how the data is structured. This makes Transformer a universal and flexible architecture\nthat is well-suited for capturing dependencies across various ranges. However, this also poses a\nchallenge: making Transformer difficult to train on small-scale datasets. The methods to alleviate"}, {"title": "3.2 Masked Item Prediction", "content": "We apply a Cloze task [21, 84] on the sequence from the conversational history of a user (i.e., the\nsequence of mentioned items and item-related entities) to train our model. Given a sequence $S_u$,\nwe randomly mask a proportion of items in the input sequence by replacing them with the special\ntoken \u201c[mask]\u201d, and then predict the original IDs of the masked items (in our implementation,\nitems are represented by their corresponding item IDs). Following BERT [21], we leverage the\nbidirectional contextual information in the input sequence for predicting the masked item. We use\nthe negative log-likelihood of the masked targets as the loss:\n$L = \\frac{1}{\\Sigma_{s_k \\in S_u^{(mask)}} |S_u^{(mask)}|} \\Sigma_{s_k \\in S_u^{(mask)}} - log P(v'|S_u)$.\nwhere $S_u^{(mask)}$ is the masked version for user historical sequence $S_u$, $S_u^{(mask)}$ is the set of masked items\nin $S_u$, and $v'$ is one of the masked items.\nFor testing, it is not practical to use bidirectional information to predict as the testing item is\nalways in the future given the current context. To this end, we construct a contextual sequence for\neach testing item, and then add a \u201c[mask]\u201d token to the end of the sequence to predict a testing\nitem. For example, if there are three items in a sequence, we mask the first item and predict it with\npossible entities that are already mentioned in the dialog till this prediction. Then we mask and\npredict the second item based on the first item and other item-related entities mentioned so far in\nthe dialog till this prediction, then the third item. To better match the last item prediction during\ntesting, we also mask the last item for each training sequence to generate a training sample during\ntraining.\nContrary to bidirectional Transformer models like BERT [86], which is a pre-training model for\nsentence representation, our model is an end-to-end model trained for sequential conversational\nrecommendation. Also, we removed the next sentence loss and next sentence prediction since\nthere is only one sequence of user's historical mentions of items and other item-related entities in\nCRS. Different from those studies using bidirectional Transformer or pre-trained BERT for recom-\nmender systems, we trained our model in an end-to-end style and incorporated the conversational\ninformation (e.g., entities), aiming to improve CRS."}, {"title": "3.3 Offline Representation Learning", "content": "We introduce an offline representation learning technique that utilizes an external knowledge graph\nto initialize our model TSCRKG. Given it is difficult to comprehensively understand user preferences\nbased solely on conversational context, the inclusion of external knowledge is necessary to encode\nuser preferences. For dialogs in CRSs, item mentions and item-related entities can be extracted to\nconstruct external knowledge graphs. Inspired by the previous studies [13, 108], we introduce a\nknowledge graph sourced from DBpedia [40] to encode structural and relational information in"}, {"title": "3.4 Knowledge Graph Enhanced Sequence Modelling", "content": "In TSCRKG, we utilize the knowledge graph to enhance the user sequence of conversations (i.e.,\nthe sequence of mentioned items and item-related entities in the conversation). Specifically, we"}, {"title": "4 EXPERIMENTS AND ANALYSIS", "content": "In this section, we evaluate our proposed models: TSCR and TSCRKG. We first introduce our\nexperimental settings, including the used datasets, evaluation metrics, parameter settings, and\nbaselines. Then we report and analyze our experimental results. Through experiments, we aim to\nanswer the following research questions:\nRQ1 How effective is our proposed simple model compared to current state-of-the-art baselines?\nRQ2 What are the impacts of different knowledge graph components?\nRQ3 What are the contributions of items and entities in a sequence?\nRQ4 What is the effect of item position?\nRQ5 How do the parameters of our proposed model affect its efficacy?\nRQ1, and RQ3 \u2013 RQ5 were also investigated by Zou et al. [117]. In this paper, we extend Zou\net al. [117] on answering RQ1 and RQ3 \u2013 RQ5 by adding (1) more state-of-the-art baselines, (2) an\nadditional dataset TG-ReDial for validating the effectiveness of TSCR in the Chinese CRS scenario,\nand (3) additional experiments for the extension model TSCRKG. Also, we extend Zou et al. [117]\nby adding RQ2 to explore the impacts of knowledge graph representation learning and knowledge"}, {"title": "4.1 Experimental Setting", "content": "4.1.1 Dataset. In this work, we conduct the experiments on two existing conversational recom-\nmendation benchmark datasets, ReDial and TG-ReDial, as done in Ren et al. [67] and Zhou et al.\n[111]. The statistics of our datasets are shown in Table 2.\n\u2022 ReDial dataset. Same as Chen et al. [13], Li et al. [43], Sarkar et al. [72], Zhou et al. [108],\nand Ma et al. [57], we use the REcommendations through DIALog (ReDial) to evaluate our model.\nReDial is a English conversational recommendation dataset, including a set of annotated\ndialogs in which a seeker requests movie suggestions from the recommender. It contains 956\nusers, 51,699 movies, 10,006 conversations, and 182,150 utterances.\n\u2022 TG-ReDial dataset. The TG-ReDial dataset [110] is a Chinese conversational recommenda-\ntion dataset which is also used in Ren et al. [67], Zhou et al. [110] and Zhou et al. [111]. The\ndialogs are generated between a user and a recommender in the movie domain via a topic-\nguided way. It contains 1,482 users, 33,834 movies, 10,000 dialogs, and 129,392 utterances.\nThe datasets are split into training, validation, and test sets by 8:1:1 ratio. Besides movies (i.e., the\nitems), we extract the relevant entities, such as director and genre, from DBpedia, as suggested\nby Chen et al. [13], Sarkar et al. [72], Zhou et al. [108], and Ma et al. [57].\n4.1.2 Evaluation Metrics. Following Chen et al. [13], Lu et al. [56], Zhou et al. [108, 111], and Zhang\net al. [102], we use Recall@k (k = 1, 10, and 50) as our evaluation metrics for the recommendation\ntask in CRSs. Recall@k evaluates whether the target item provided by human recommenders\nappears in the top-k items produced by the recommender system. Moreover, we use the Mean\nReciprocal Rank (MRR) to indicate the mean of the reciprocal of the rank of the target item in the\nranked list predicted by the model. For each conversation, we start from the first item (movie) to\nrecommend in the recommender's responses. This means, each item in the recommender's responses\nis regarded as ground truth and we evaluate them one by one throughout the conversation following\nthe previous work [13, 108]. For each testing instance, we rank all possible items within the dataset.\n4.1.3 Parameter Settings. We train our model using Adam [38] and TensorFlow with a learning\nrate of 1e-4. We set the batch size = 256, the number of Transformer layers N = 2, head number = 2,\nthe maximum sequence length K = 100, L2 regularization strength = 0.01, and the global norm clip\nof gradients = 5 for stable training. The number of R-GCN layers and the normalization factor $Z_{e,r}$\nof R-GCN are set to 1. We study the effect of the hidden dimensionality and mask proportion in\nSection 4.6. The hidden dimensionality ranges within [32, 64, 128, 256] and the mask proportion is\ntuned within the range of [0.2, 0.4, 0.6, 0.8]. For the parameter settings of all baselines, we use the\nresults of each baseline under its optimal hyperparameter settings.\n4.1.4 Baseline. In this work, we consider two classical baselines and several strong baselines used\nagainst ReDial and TG-ReDial:"}, {"title": "4.2 Overall Performance (RQ1)", "content": "In this section, we study how effective is our proposed method compared to prior solutions. We\ncompare our recommendation performances with baselines on ReDial and TG-ReDial, as shown in\nTable 3 and Table 4, respectively. The evaluation metrics are reported as the average performance\nfor the max number of conversational turns."}, {"title": "4.3 Impact of Knowledge Graph Representation Learning and Knowledge Graph\nEnhanced Sequences (RQ2)", "content": "Next, we answer RQ2. To understand what are the contributions of different knowledge graph\ncomponents, we conduct an ablation study comparing our model with its ablation variants (TSCRKG\nremoving the offline representation learning on knowledge graphs, represented by \u201c-w/o offline\u201d,\nTSCRKG removing the part of knowledge graph enhanced sequences, represented by \u201c-w/o KGseq\u201d,\nand TSCRKG removing both offline representation learning and knowledge graph enhanced se-\nquences, represented by \u201c-w/o both\u201d). The results on the ReDial dataset are shown in Table 5 and the\nresults on the TG-ReDial dataset are shown in Table 6. From what we observed in Table 5 and Table 6,\neither removing the offline representation learning or removing path-enhanced sequences over\nknowledge graphs lowers the recommendation performance on all evaluation metrics. Specifically,\non the ReDial dataset, the performance of TSCRKG -w/o KGseq, TSCRKG -w/o offline, and TSCRKG"}, {"title": "4.4 Impact of Entity and Item in Sequence (RQ3)", "content": "To understand what are the contributions of items and entities in a sequence, we conduct an\nablation study comparing our model TSCR with its ablation variants (TSCR removing the non-item\nentities \u201c-w/o entity\u201d and TSCR removing the item mentions \u201c-w/o item\u201d). The results on the ReDial\ndataset and TG-ReDial dataset are shown in Table 7 and Table 8, respectively. Observe from Table 7\nand Table 8, both the item mentions and item-related entities in the conversation contribute to the\nfinal performance of TSCR. After removing item mentions or non-item entities from the context,\nthe recommendation performance on all three metrics on the two datasets drops, which indicates\nthe importance of the two components. Also, we observe that item mentions contribute more\nthan non-item entities on the ReDial dataset. This might be because that item mentions are more"}, {"title": "4.5 Effect of Item Position (RQ4)", "content": "In this section, we explore whether the item position in the conversation affects the recommender\nperformance. We first compare the recommender performance for each position of item predictions,\nfrom 1-st item prediction to 5+ item prediction in the conversation on the ReDial dataset. From\nFig. 3, we observe that, most of dialogs (74.1%) on the ReDial dataset contain only 1-3 item\nrecommendations. This is in line with that users expect the system can perform high-quality\nrecommendations with fewer rounds in real applications. Overall, Fig. 3 shows that the performance\nof our TSCR model and TSCRKG improve as the item position increases. We attribute this to the fact\nthat the models collect more contextual information about the user as the item position increases.\nA higher item position means a longer sequence length of item mentions and item-related entities.\nThis indicates that both the performance of TSCR and TSCRKG improve when the sequence length"}, {"title": "4.6 Parameter Sensitivity (RQ5)", "content": "In this section, we explore how our proposed model is affected by its main parameters, including\nthe hidden dimensionality and the mask proportion. For simplicity, we use TSCR model and ReDial\ndataset for the experiments.\nEffect of hidden dimensionality. We now explore how the hidden dimensionality affects the model\nperformance. As shown in Fig. 5a, we observe the recommendation performance of our TSCR\nmodel decreases with the embedding size increases. This is probably because of over-fitting. The\nTSCR model achieves the best performance when the hidden dimensionality is equal to 32."}, {"title": "4.7 Case Study", "content": "To illustrate the ability of TSCR and TSCRKG to generate reasonable recommendations, we present\nuse cases of them on the ReDial dataset, as shown in Table 11. Observe from \u201cCase1\" in Table 11,\nboth TSCR and TSCRKG can accurately recommend the movie, i.e., \u201cThe Shining (1980)\u201d, which is\nconsistent with the ground truth. This is because both TSCR and TSCRKG are able to model the\nsequential dependency of contextual information. The two scary and classic movies mentioned in\nthe context, i.e., \u201cRosemary's Baby (1968)\u201d and \u201cThe Exorcist (1973)\u201d, are usually talked together"}, {"title": "5 CONCLUSION AND FUTURE WORK", "content": "In this paper, we have proposed the Transformer-based Sequential Conversational Recommender\n(TSCR) for CRSs. TSCR deploys a Cloze task and models the sequential dependency of both items\nand entities in conversations by the deep bidirectional self-attention architecture. TSCR uses\nthe knowledge base as a dictionary to get related entities, but does not use the structure of the\nknowledge base for any reasoning, making it simple and straightforward. Experimental results on\nthe two CRS datasets show that our TSCR model, despite simple is highly effective, constituting\na very strong baseline for future researchers to use. To take advantage of knowledge graphs, we\nhave proposed an extension model TSCRKG, which fully uses the structure of knowledge graphs\nfor offline representation learning and user sequence augmentation. The extensive experiments on\nthe CRS datasets demonstrate the effectiveness of TSCRKG and the benefit of knowledge graphs.\nOne limitation of this work is that we only focus on the recommender module. As for future\nwork, we plan to incorporate the natural language response generation part as well. Moreover, in\nthis work, we do not model the sentiment of mentioned items or entities and treat them as the same\nin the conversation. It is worth exploring the CRS by incorporating and modeling the sentiment\n(e.g., positive or negative) from users' feedback in future work. Also, although we use entities\nfrom the DBpedia knowledge graph following previous CRS work [13, 57, 72, 108], the extracted\nentities may not be 100% accurate. It is thus worth exploring the CRS system by incorporating and\nmodeling uncertainty and noise.\nIn this work, we use the knowledge graph to initialize the offline representations of the augmented\nsequences, which are constructed by using the knowledge graph and conversation history. Then\nwe learn the representations of the augmented sequences by bidirectional Transformer. In this\nway, the semantic representations from the knowledge graph are aligned with the conversation.\nHowever, one can also use other techniques, e.g., contrastive learning [111], to bridge the semantic\ngap between the knowledge graph and conversation history. Moreover, we model the sequential\ndependencies in all conversations. However, this is just the first step toward sequential modeling\nand there is still room for improvement. For example, conversations may involve complicated"}, {"title": "6 ACKNOWLEDGEMENT", "content": "This study is supported under the RIE2020 Industry Alignment Fund \u2013 Industry Collaboration\nProjects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore\nTelecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelligence Lab for\nEnterprises (SCALE@NTU). This research was also supported by the Natural Science Foundation\nof China (62402093), the NWO Smart Culture - Big Data / Digital Humanities (314-99-301), the\nNWO Innovational Research Incentives Scheme Vidi (016.Vidi.189.039), and the H2020-EU.3.4. -\nSOCIETAL CHALLENGES - Smart, Green And Integrated Transport (814961). All content represents\nthe opinion of the authors, which is not necessarily shared or endorsed by their respective employers\nand/or sponsors."}]}