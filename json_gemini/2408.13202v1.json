{"title": "Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews", "authors": ["Dineth Jayakody", "A V A Malkith", "Koshila Isuranda", "Vishal Thenuwara", "Nisansa de Silva", "Sachintha Rajith Ponnamperuma", "G G N Sandamali", "K L K Sudheera"], "abstract": "Aspect-based Sentiment Analysis (ABSA) is a critical task in Natural Language Processing (NLP) that focuses on extracting sentiments related to specific aspects within a text, offering deep insights into customer opinions. Traditional sentiment analysis methods, while useful for determining overall sentiment, often miss the implicit opinions about particular product or service features. This paper presents a comprehensive review of the evolution of ABSA methodologies, from lexicon-based approaches to machine learning and deep learning techniques. We emphasize the recent advancements in Transformer-based models, particularly Bidirectional Encoder Representations from Transformers (BERT) and its variants, which have set new benchmarks in ABSA tasks. We focused on finetuning Llama and Mistral models, building hybrid models using the SetFit framework, and developing our own model by exploiting the strengths of state-of-the-art (SOTA) Transformer-based models for aspect term extraction (ATE) and aspect sentiment classification (ASC). Our hybrid model Instruct DeBERTa uses SOTA InstructABSA for aspect extraction and DeBERTa-V3-baseabsa-V1 for aspect sentiment classification. We utilize datasets from different domains to evaluate our model's performance. Our experiments indicate that the proposed hybrid model significantly improves the accuracy and reliability of sentiment analysis across all experimented domains. As per our findings, our hybrid model Instruct DeBERTa is the best-performing model for the joint task of ATE and ASC for both SemEval restaurant 2014 and SemEval laptop 2014 datasets separately. By addressing the limitations of existing methodologies, our approach provides a robust solution for understanding detailed consumer feedback, thus offering valuable insights for businesses aiming to enhance customer satisfaction and product development.", "sections": [{"title": "I. INTRODUCTION", "content": "Aspect-Based Sentiment Analysis (ABSA) has become an essential technique in Natural Language Processing (NLP) for extracting fine-grained opinions from textual data. It focuses on identifying sentiment towards specific aspects within a text, providing a detailed understanding of customer feedback and reviews. Traditional sentiment analysis techniques, while effective at determining overall sentiment, often fail to capture the nuanced opinions that consumers express about particular features or attributes of a product or service.\nOver the years, ABSA methodologies have evolved significantly. Early approaches primarily relied on lexicon-based methods, which used predefined dictionaries of sentiment-laden words to infer polarity. These methods, however, struggled with context and ambiguity. The advent of machine learning introduced more sophisticated techniques, including supervised learning models that could be trained on annotated datasets. Despite their advancements, these models required substantial manual effort for feature extraction and were often domain-specific.\nThe breakthrough in deep learning, particularly with the development of recurrent neural networks (RNNs), Long Short-Term Memory networks (LSTMs), and Convolutional Neural Networks (CNNs), marked a significant improvement in sentiment analysis. These models could automatically learn features from text, capturing context and sequential dependencies more effectively than traditional methods. LSTM and CNN-based models became popular for their ability to handle long-range dependencies and local features, respectively. However, these models still had limitations, especially in understanding long-term dependencies and complex syntactic structures.\nThe introduction of Transformer architectures, especially BERT, revolutionized the field by leveraging attention mechanisms to capture contextual relationships in both directions of a sentence. BERT and its variants, such as ROBERTA and DeBERTa, have set new benchmarks in various NLP tasks, including ABSA. These models have demonstrated superior performance in aspect extraction and sentiment classification tasks due to their ability to understand complex language patterns and relationships.\nIn our study, we focus on developing a hybrid model that leverages the strengths of the latest Transformer-based models for ABSA. We aim to address the limitations of existing approaches by combining aspect extraction and sentiment classification into a unified framework. Our approach utilizes datasets from the hospitality domain, including SemEval 2014 (Res-14), 2015 (Res-15), and 2016 (Res-16) restaurant reviews, and extends to the laptop domain with the SemEval 2014 laptop dataset (Lap-14). By evaluating these models on imbalanced datasets using the F1 metric, we ensure a balanced and comprehensive assessment of performance.\nThrough our literature review, we have identified key methodologies and their respective accuracies, guiding the design of our hybrid model. We focus on models that excel in aspect term extraction (ATE) and aspect sentiment classification (ASC), aiming to develop a model that builds on the successes of past methodologies while innovating in areas where existing methods may fall short. Our goal is to enhance the accuracy and reliability of sentiment analysis in our application domain, ultimately providing a robust solution for understanding consumer feedback."}, {"title": "II. LITERATURE REVIEW", "content": "Our literature review systematically investigates various models that have demonstrated efficacy in ATE and ASC. Notably, this table exclusively considers models that do not incorporate LLMs. lists down models that perform the joint task which is the ATE and ASC tasks together by a single model. The model is only fed in with the relevant sentences or the reviews. Then the model identifies the aspects by itself and classifies the polarities to the aspects that have been identified. Then the F1 score of the whole process is reported. For a sentence Si the ATE, ASC, and the joint task can be visualized as below.\nSi: The price was high, but the restaurant was breathtaking.\n\nA. Models for a Single Task (ATE or ASC)\n1) LSTM Based Models: Standard RNNs suffer from significant limitations, primarily the vanishing gradient and exploding gradient problems. To address these limitations, the LSTM network was developed by Hochreiter and Schmidhuber [1]. To effectively utilize aspect information, Wang et al. [2] proposed a model called LSTM with Aspect Embedding (AE-LSTM). However, to further leverage aspect information, Wang et al. [2] developed an enhanced model called Attention-based LSTM with Aspect Embedding (ATAE-LSTM).\nLi et al. [3] proposed Target-Specific Transformation Networks (TNet), a new architecture designed to improve target sentiment classification by effectively handling multiple targets and extracting relevant features without introducing noise. TNet introduces a novel Target-Specific Transformation (TST) [3] component for generating target-specific word representations. The models LSTM-FC-CNN-LF and LSTM-FC-CNN-AS were built by Li et al. [3] that incorporate a fully connected layer and context-preserving mechanisms. These models performed better with F1 scores of 70.60% and 70.23% for LSTM-FC-CNN-LF, 70.72% and 70.06% for LSTM-FC-CNN-AS for Lap-14 and Res-14 respectively.\n2) GloVe Based Models: Glove (Global Vectors for Word Representation) is an algorithm that generates word embeddings by aggregating word co-occurrence statistics from a corpus. It is important because it captures both local and global statistical information of words, enhancing the performance of natural language processing tasks. ASGCN introduced by Zhang et al. [4] proposed a novel aspect-specific sentiment classification framework while DualGCN by Li et al. [5] proposed a dual graph convolutional network model that considers the complementarity of syntax structures and semantic correlations simultaneously. Zhong et al. [6] proposed a new model named KGAN which uses a knowledge graph augmented network, which aims to effectively incorporate external knowledge with explicitly syntactic and contextual information. While all these models individually had their own importance, merging them with Glove as an embedding method, researchers were able to capture both local and global information to achieve higher F1 Scores like 84.46% with Res-14. However, UIKA (Unified Instance and Knowledge Alignment Pretraining) by Liu et al. [7], which introduces a unified alignment pretraining framework into the vanilla pretrain-finetune pipeline, incorporates both instance and knowledge level alignments. It reported a higher F1 score of 85.53% with KGAN for Res-14. Furthermore, KGAN+UIKA achieved higher F1 scores with BERT compared to GloVE.\n3) BERT Based Models: The original BERT model was introduced by Devlin et al. [8]. BERT's training process involves two main steps: pre-training and fine-tuning. BERT-DK, introduced by Zhao [9], integrates domain-specific knowledge to improve ABSA performance. By incorporating domain-specific information, BERT-DK achieved F1 scores of 77.02% and 83.55% for aspect extraction on the Res-14 and Lap-14 datasets respectively. Similarly, BERT-SPC, developed by Song et al. [10], employs a Sentence Pair Classification framework to better understand the context of aspect-specific sentences.\nInnovative approaches such as BERT-MRC, proposed by Zhao et al. [11], frame ABSA tasks as machine reading comprehension problems while Xu et al. [12] introduced BERT-PT which involves pre-training BERT on domain-specific data followed by fine-tuning. BAT which stands for BERT with Adversarial Training, introduced by Karimi et al. [13], enhances ABSA by generating adversarial examples during training.\nCutting-edge models like RGAT-BERT, DualGCN-BERT, TF-BERT, and dotGCN-BERT have further improved ABSA performance. RGAT-BERT, proposed by Bai et al. [14], uses relational graph attention networks to improve aspect extraction and sentiment classification abilities. In addition to that DualGCN-BERT introduced by Li et al. [5], uses dual graph convolutional networks to handle both aspect extraction and sentiment classification. TF-BERT, developed by Zhang et al. [15], uses task-specific fine-tuning strategies to improve ABSA performance. In contrast to that DotGCN-BERT, proposed by Chen et al. [16], uses dot-product based graph convolutional networks to improve ABSA performance. Furthermore keeping another step forward DualGCN and KGAN have used BERT as the embedding metholody in order to achieve higher F1 scores. But still we decided to move forward with DEBERTa-V3-base-absa-v1 since it provides a higher F1 Score in all datasets compared to others.\n4) ROBERTa Based Models: ROBERTa [17] is an advanced language model that builds upon the foundational work of BERT. The SARL-ROBERTa model, which was introduced by Wang et al. [18] used span-based dependency modeling to align opinion candidates with aspects and used an adversarial learning strategy to reduce sentiment bias in aspect embeddings. Among the compared ROBERTa based models, SARL-ROBERTa performs the best, achieving a F1-score of 82.44% and 82.97% for Res-14 and Lap-14 respectively.\nHowever, models such as ASGCN-ROBERTA, RGAT-ROBERTA, PWCN-ROBERTa, and ROBERTa+MLP benefited by combining ROBERTa with various specialized architectures, as demonstrated by Dai et al. [19]. Strong performance is achieved by ASGCN-ROBERTa, which combines an aspect-specific graph convolutional network with dependency tree syntactic information. With a relational graph attention network integrated to collect relational information between words, RGAT-ROBERTa performs admirably. ROBERTa+MLP integrates a multi-layer perceptron with ROBERTa. It highlights the flexibility of combining ROBERTa's embeddings with simple classifiers.\nTask-oriented syntactic information is well captured by pure ROBERTa based models, particularly by the fine-tuned variations (FT-ROBERTa). Research conducted by Dai et al. [19] demonstrates that FT-ROBERTa achieves a 1.56% improvement in the F1-score over standard ROBERTa induced trees, and performs better than parser-provided trees.\n5) DeBERTa Based Models: DeBERTa [20] introduces a disentangled attention mechanism, which utilizes two separate vectors for each word to represent its content and position independently. Also, the model incorporates an enhanced mask decoder in its pre-training phase based on masked language modeling (MLM).\nImproving from the vanilla DeBERTa model a new model named DEBERTaV3 was introduced by He et al. [21]. By further fine tuning the model to improve its performance Yang et al. [22] developed the DeBERTAV3-base-absa-V1 model. This was trained using Lap-14, Res-14, Res-16, and six more datasets counting up to 30k+ ABSA examples. The accuracy of this model showed an improvement of 9.35% and 10.87% for the ASC task of Res-14 and Lap-14 datasets respectively compared to the original DeBERTAV3 model.\nIn their independent investigations, Marcacini and Silva [23] as well as Yang and Li [24] explored the utilization of DeBERTa based models, introducing ABSA-DEBERTa and LSA-X-DeBERTa, respectively. Marcacini and Silva [23] explored disentangled learning as a method to improve BERT-based representations specifically for ABSA. On the other hand, Yang and Li [24] introduced a novel perspective in ASC by emphasizing the significance of aspect sentiment coherency. Their study revealed that neighbouring aspects usually share similar sentiments, which is known as \u201caspect sentiment coherency.\u201d To address this, they proposed a local sentiment aggregation paradigm (LSA) to effectively model fine-grained sentiment coherency. In respect to that, the LSA-X-DEBERTa model introduced by Yang and Li [24] achieved a F1-score of 87.02% for Res-14 and 84.41% for Lap-14 under the sentiment classification task.\n6) Other Models: Concerning ASC and ATE, in particular, LCF-ATEPC-CDM proposed by Yang et al. [25] and InstructABSA proposed by Scaria et al. [26] standout for their strong performances. InstructABSA, utilizing a novel instruction learning paradigm, showed exceptional abilities in obtaining pertinent aspects from the text, attaining F1 scores exceeding 92% for aspect extraction on both the Res-14 and Lap-14 datasets. Concerning ATE, LCF-ATEPC-CDM, which also employs a local context focus technique, performs fairly well. In sentiment polarity classification, InstructABSA also excels with F1 scores of 85.17% on Res-14 and 81.56% on Lap-14, outperforming many other models. The LSAT model proposed by Yang and Li [27], with its focus on aspect sentiment coherency through a local sentiment aggregation paradigm, shows impressive results, achieving a F1 score of 90.86% on Res-14. The efficacy of the BART-ABSA model in a comprehensive approach to ABSA has also been demonstrated by Yan et al. [28], which combines all ABSA subtasks into a single generative formulation.\nB. Joint Task Models\nHere we talk about the models that perform the joint task which is the ATE and ASC tasks together by a single model. The model is only fed in with the relevant sentences or the reviews. Then the model identifies the aspects by itself and classifies the polarities to the aspects that have been identified. Then the F1 score of the whole process is reported.\npresents the leading joint task models identified through our research. The InstructABSA and Grace models, which were previously described as single task models capable of performing both ATE and ASC tasks separately, also excel in the joint task. These models report the highest F1 scores for the joint task, achieving over 75% for both datasets, indicating their accuracy and robustness across different domains.\nRACL-BERT, introduced by Chen and Qian [29], is a notable ABSA (Aspect-Based Sentiment Analysis) model that utilizes the BERT-Large model to address three subtasks simultaneously: identifying aspects, detecting sentiment words, and classifying overall sentiment. Through multitasking and relation propagation, RACL-BERT enhances sentiment analy-sis accuracy. Similarly, SPAN, introduced by Hu et al. [30], employs a novel approach by focusing on key opinion points rather than tagging each word. Both RACL-BERT and SPAN achieved reasonable F1 scores but were outperformed by InstructABSA and GRACE.\nThe E2E-TBSA model, proposed by Li et al. [31], addresses both ATE and ASC tasks in a single step, using a collapsed approach that combines these tasks into a unified process. Similarly, BERT-E2E-ABSA, introduced by Li et al. [32], is based on BERT models and follows the same principles. These models achieved F1 scores in the 60%-70% range but did not outperform the leading models.\nDOER, introduced by Luo et al. [33], uses a cross-shared RNN framework to generate aspect term-polarity pairs simultaneously. IMN, introduced by He et al. [34], employs an interactive architecture with multi-task learning for end-to-end ABSA tasks, including aspect term and opinion term extraction as well as aspect-level sentiment classification.\nC. Selection Criteria: Dataset\nAfter a thorough review, the following criteria were established for dataset selection:\n\u2022 Relevance to BSA: The datasets must be specifically designed for or widely used in aspect-based sentiment analysis ensuring granularity.\n\u2022 Diversity of aspects and sentiments: The selected datasets should cover a wide range of aspects and sentiments ensuring generalizability.\n\u2022 Quality of annotations: High-quality, manually annotated datasets are preferred to ensure the accuracy.\n\u2022 Availability and accessibility: Publicly available datasets with accessibility are chosen to facilitate reproducibility.\nBased on these criteria, the SemEval datasets from the years 2014, 2015, and 2016 were selected."}, {"title": "III. METHODOLOGY", "content": "In this section, we look on to different approaches we tested out in order to find the most accurate and robust solution. These approaches can be listed below,\n1) Fine-Tuning LLAMA 2-7B with Quantized Low Rank Adaptation (QLORA)\n2) Fine-Tuning Mistral-7B with Quantized Low Rank Adaptation (QLORA)\n3) ASGCN+UIKA+Glove for Sentiment Polarity\n4) SSGCN+Glove for Sentiment Polarity\n5) Span-ASTE+BERT for Aspect Extraction\n6) SETFIT for efficient few-shot fine-tuning of Sentence Transformers\n7) Instruct-DeBERTA (Proposed Model)\nA. LLAMA 2-7B with QLORA\nGiven the current state-of-the-art interest in Large Language Models (LLMs), we opted to include an LLM-based analysis in our comparative study. LLAMA 2 is a collection of second-generation open-source LLMs from Meta that comes with a commercial license. Roumeliotis et al. [56] presented that LLAMA 2 shows a significant leap forward in natural language understanding and generation, by its advanced architecture, large training data, and refined training strategies. The architecture of LLAMA 2 is based on the transformer model, a neural network architecture that has proven highly effective in a wide range of NLP tasks. LLAMA 2 employs a multi-layered transformer architecture with self-attention mechanisms. It is designed to handle a wide range of natural language processing tasks, with models ranging in scale from 7 billion to 70 billion parameters.\nFine-tuning in machine learning is the process of adjusting the weights and parameters of a pre-trained model on new data to improve its performance on a specific task. There are three main fine-tuning methods in the context:\n1) Instruction Fine-Tuning (IFT): According to Peng et al. [57], IFT involves training the model using prompt completion pairs, showing desired responses to queries.\n2) Full Fine Tuning: Full fine-tuning involves updating all of the weights in a pre-trained model during training on a new dataset, allowing the model to adapt to a specific task.\n3) Parameter-Efficient Fine-Tuning (PEFT): Selectively updates a small set of parameters, making memory requirements more manageable. There are various ways of achieving Parameter efficient fine-tuning. Low-Rank Parameter (LoRA) [58] and Quantized Low-Ranking Adaptation (QLORA) [59] are the most widely used and effective.\nTraditional fine-tuning of pre-trained language models (PLMs) requires updating all of the model's parameters, which is computationally expensive and requires massive amounts of data; thus making it challenging to attempt on consumer hardware due to inadequate VRAMs and computing. However, Parameter-Efficient Fine-Tuning (PEFT) works by only updating a small subset of the model's most influential parameters, making it much more efficient. Four-bit quantization via QLORA allows such efficient fine-tuning of huge LLM models on consumer hardware while retaining high performance. QLORA quantizes a pre-trained language model to four bits and freezes the parameters. A small number of trainable Low-Rank Adapter layers are then added to the model. In our case, we created a 4-bit quantization with NF4-type configuration using BitsAndBytes\u00b9.\nAccording to Dettmers et al. [59] under the model fine-tuning process, Supervised fine-tuning (SFT) is a key step in Reinforcement Learning from Human Feedback (RLHF). The SFT models come with tools to train language models using reinforcement learning, starting with supervised fine-tuning, then reward modelling, and finally, Proximal Policy Optimization (PPO). During this process, we provided the SFT trainer with the model, dataset, LoRA configuration, tokenizer, and training parameters. The model was fine-tuned with a training and evaluation batch size of 4 and for 2 epochs, optimizing its ability to extract aspects and determine sentiment polarity.\nTo test the fine-tuned model, we used the Transformers text generation pipeline including the prompt. The LLAMA 2"}, {"title": "IV. RESULTS", "content": "presents the F1 scores for the models being built and evaluated by ourselves. In addition to that we have presented  which give a view on the robustness of each model for the aspect term extraction task and the sentiment polarity task separately based on the accuracies. According to , if the model shows high accuracy for each task and the accuracies for the two domains do not exhibit drastic deviations, then the relevant model will be selected.\nA. LLAMA 2-7B with QLoRA\nThe first section of  shows the performance of Llama-2-7b [62] with QLoRA [59]. It emphasizes that this model shows notable performance in both aspect extraction and sentiment polarity tasks. On Res-14 and Lap-14 datasets, Llama 2 shows a slight edge in aspect extraction compared to sentiment polarity. These performances were obtained using the L4 GPU emphasizing the model's efficiency and effectiveness in computational performance.\nB. Mistral 7B with QLORA\nAccording to the values , the model Mistral 7B exhibits superior performance in both aspect extraction and sentiment polarity tasks compared to the Llama 2 model. Specifically, Mistral 7B achieves higher F1 scores across both Res-14 and Lap-14 datasets, indicating its greater capability in accurately identifying aspects and determining sentiment polarity within the text. These results were achieved using an L4 GPU, similar to the Llama 2 model.\nWhen comparing the two models, Mistral 7B demonstrates a clear advantage in both tasks. While Llama 2 performs competently, Mistral 7B consistently outperforms it, showcasing its enhanced effectiveness and reliability in handling aspect extraction and sentiment polarity analysis. This comparison highlights Mistral 7B's performance, making it a more capable model for these specific natural language processing tasks.\nC. Some models with BERT and GloVe\nAs a part of the comparative study for the survey, we conducted experiments using several advanced models for aspect-based sentiment analysis. We experimented three main models: SSGCN+Glove, ASGCN+UIKA+Glove[4], and Span-ASTE+BERT [50] both in local and Colab environments. The focus was on to evaluating their performance on the SemEval 2014 dataset. These results are stated in . But still we observed that Instruct-DeBERTa outperforms all.\nD. SetFit\nIn the second section of , we provide a comprehensive overview of the Fl-scores for attained by various sentence models using the SETFIT framework [61] for the same amount of selected data in the respective stated data sets. If a model is reported in a single row, it means we have used the said sentence transformer model for both aspect extraction and sentiment polarity identification (eg, BGE [63]). In the cell blocks where a model is followed by other models with + are combinations. For example, the first row of Paraphrase-MiniLM-L6-v2 [64, 65] contains results of that model being used both for aspect extraction and sentiment polarity identification. The subsequent line with +MpNet [66] indicates that Paraphrase-MiniLM-L6-v2 was used for the aspect extraction component and MpNet was used for the sentiment polarity identification component.\nAt this point, a question may be raised as to why would the aspect extraction have two different values for accuracy in and in the two configurations if in both cases the same model (ie, Paraphrase-MiniLM-L6-v2 in this example) was used for that task. The reason is the fact that the fine-tuning is conducted end-to-end in a holistic manner and thus, the choice of the model used for the sentiment po-larity identification ends up influencing the ultimate accuracy obtained by the aspect extraction component. It may enhance the result as in the case of Paraphrase-MiniLM-L6-v2 and MpNet. It may also hinder as in the case of LaBSE. Overall, it can be noted that LaBSE [67] consistently emerges as a standout performer; either by itself or as the aspect extraction component of a pair. It can be argued that this robust performance is owed to its capability to capture nuanced complex information crucial for understanding both aspect-based sentiment analysis and sentiment polarity classification tasks. Specifically on the sentiment polarity classification task, it can be noted that Mpnet and ROBERTA-STSb-v2 [68] elevates performance multiple configurations.\nTo give a better overview of how various models perform, we include and , which visualize the SetFit accuracy values for the models that we evaluated. In , we present a detailed analysis of aspect extraction accuracy for various models. LaBSE emerging as the top performer across both datasets can easily be noted. It is also evident how ALBERT+DistilRoBERTa and LaBSE+ROBERTa-STSb closely follow with accuracies verging on 90%. Similarly, in , we look into the analysis of sentiment polarity identification percentages for the same models and datasets. Here, LaBSE+ROBERTA-STSb shows the highest accuracy for Res-14 while LaBSE+MpNet shows the highest accuracy for Lap-14.\nE. Instruct-DeBERTa (Proposed Model)\nFrom all the evaluated models, our model performs the best with the highest accuracies and F1 scores. It is also robust for both domains which makes it the best performing model. As discussed in the methodology we selected the best performing models from  to create our own hybrid model. When looking at , and  it is clear that Instruct-DeBERTa outperforms our finetuned Llama, Mistral, and all the Setfit based models.\n shows how the two best models we selected for each subtask perform individually on their relevant task. These F1 scores are for the combined task, which means our model is capable of performing both the aspect extraction and the sentiment polarity tasks. For the first task which is extracting the aspects, our model gives closer accuracies for what has been reported by Scaria et al. [26] for the InstructABSA model. Different ways of splitting a dataset can affect the reported accuracies. Also for the sentiment polarity classification task the original model, DeBERTa-V3-base-absa-v1 by Yang et al. [22, 40] which is specialized only for detecting po-larities gives slightly higher accuracies than our hybrid model. As seen for the Res-14 dataset the sentiment polarity accuracy for the individual task by DeBERTA-V3-base-absa-v1 is reported as 90.94% while our reported 88.63%. This is due to the models being pipelined and the extracted aspects from the first model is being fed to the second model rather than calculating the accuracies separately for individual tasks. Hence the slight deduction in the hybrid model is justified.\nSo, looking on to all the past models in  and the models that we worked on in , it is clear that our model, Instruct-DeBERTa is the best performing hybrid model designed for the combined task of aspect extraction and sentiment polarity detection. Moreover, our hybrid model shows promising results in the laptop domain as well. Our model gives an F1-score of 91.56% and 89.65% for aspect extraction and sentiment polarity respectively.\nAlso , in the literature review lists out the joint models which are equivalent to the model we built. These\nF1 scores of models for the joint task of ASC and ATE for lap-14\n\nF1 scores of models for the joint task of ASC and ATE for res-14\nperform the joint task of ABSA. Here in order for the F1 score to be counted the aspect and the respective sentiment in the original dataset needs to be correct. The F1 scores of these models along with our model can be visualized in and . It is clear that our model clearly out performs the currently available joint task hybrid models. It gives a pair extraction F1 score of 80.78% and 80.94% which exceed the current reported highest accuracy for the rest-14 and lap-14 datasets. From , and it is clear that our model is the best performing joint task model. Our model outperforms all other hybrid models in both domains which again proves that it is not only accurate but also robust to different domains as well."}, {"title": "V. CONCLUSION", "content": "In this paper, we presented a comprehensive review and detailed experimental analysis of ABSA methodologies, focusing on the latest advancements in Transformer-based models.\nOur hybrid model, Instruct-DeBERTa, was designed to harness the specific advantages of two best performing models. InstructABSA is known for its accuracy in identifying and extracting relevant aspects from text, while DeBERTa-V3-baseabsa-V1 excels in classifying the sentiment associated with these aspects. By integrating these models, we aimed to create a comprehensive tool that could perform both tasks with high precision and reliability.aspect extraction and accuracy in sentiment classification.\nIn conclusion, our comprehensive review and experimental analysis highlight the significant advancements made possible by Transformer-based models in the field of ABSA. The development of Instruct-DeBERTa represents a notable contribution, offering a powerful and versatile solution for accurately extracting aspects and classifying sentiment in diverse textual data. The superior performance of our hybrid model sets a new benchmark for future research and applications in ABSA, underscoring the potential of integrating state-of-the-art models to enhance the effectiveness of sentiment analysis methodologies."}]}