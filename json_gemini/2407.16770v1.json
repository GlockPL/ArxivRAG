{"title": "Infinite Ends from Finite Samples: Open-Ended Goal Inference as Top-Down Bayesian Filtering of Bottom-Up Proposals", "authors": ["Tan Zhi-Xuan", "Gloria Kang", "Vikash Mansinghka", "Joshua B. Tenenbaum"], "abstract": "The space of human goals is tremendously vast; and yet, from just a few moments of watching a scene or reading a story, we seem to spontaneously infer a range of plausible motiva- tions for the people and characters involved. What explains this remarkable capacity for intuiting other agents' goals, de- spite the infinitude of ends they might pursue? And how does this cohere with our understanding of other people as approx- imately rational agents? In this paper, we introduce a sequen- tial Monte Carlo model of open-ended goal inference, which combines top-down Bayesian inverse planning with bottom-up sampling based on the statistics of co-occurring subgoals. By proposing goal hypotheses related to the subgoals achieved by an agent, our model rapidly generates plausible goals without exhaustive search, then filters out goals that would be irrational given the actions taken so far. We validate this model in a goal inference task called Block Words, where participants try to guess the word that someone is stacking out of lettered blocks. In comparison to both heuristic bottom-up guessing and exact Bayesian inference over hundreds of goals, our model better predicts the mean, variance, efficiency, and resource rationality of human goal inferences, achieving similar accuracy to the ex- act model at a fraction of the cognitive cost, while also explain- ing garden-path effects that arise from misleading bottom-up cues. Our experiments thus highlight the importance of unit- ing top-down and bottom-up models for explaining the speed, accuracy, and generality of human theory-of-mind.", "sections": [{"title": "Introduction", "content": "Whether one is watching a play, reading a novel, or spend- ing time with a friend at their house, inferences about others' goals and motivations often arise spontaneously and unbidden (Moskowitz & Olcaysoy Okten, 2016): Is the person crouch- ing behind a tree trying to hide from, or spy on someone? Does the strange warrior who has just entered the fray of bat- tle intend to kill the protagonist, or save them? When your friend gets up from the couch and walks to the kitchen, are they getting a snack, or making some tea? Despite the seem- ingly infinite space of possible goals, we have little trouble in coming up with plausible hypotheses, and then as the story unfolds filtering out those that fail to explain our ob- servations. If the warrior defends our protagonist from a stray arrow, they are likely an ally. If your friend opens the fridge, they are probably having a snack. What computational mech- anisms underlie this ability to both hypothesize and evaluate the goals that explain others' behavior, even when the set of possibilities is vast and open-ended?"}, {"title": "Computational Model", "content": "Building upon prior accounts of human goal inference (Baker et al., 2009; Zhi-Xuan et al., 2020; Alanqary et al., 2021), we assume that observers perform approximately Bayesian inference over a generative model of how other agents plan and act to achieve their goals:\nGoal Prior: $g \\sim P(g)$ (1)\nOnline Planning: $\\pi_t \\sim P(\\pi_t|s_{t-1}, \\pi_{t-1}, g)$ (2)\nAction Selection: $a_t \\sim P(a_t|s_{t-1}, \\pi_t)$ (3)\nState Transition: $s_t \\sim P(s_t|s_{t-1}, a_t)$ (4)\nHere g is the agent's goal, and at each step t, \u03c0\u2081 is the agent's current plan or policy, at is the agent's action, and st is the state of the environment. Given a sequence of states s0:T and actions a1:T, the observer's task is to infer the goal g by approximating the posterior $P(g|s_{0:T}, a_{1:T})$. Approximating this posterior presents numerous computational challenges. Among these, our focus is on the challenge posed by open- ended settings, where the set of possible goals $g \\in G$ is large or potentially infinite. In this section, we first review recent advances that render goal inference over fixed spaces algo- rithmically tractable, before explaining how we can extend these ideas to open-ended spaces."}, {"title": "Modeling Boundedly Rational Plans and Actions", "content": "Since computing the posterior requires simulating the plans \u03c0\u2081 that an agent might follow to each goal g, this process is also known as Bayesian inverse planning. In general this is a difficult problem, because planning itself is a complicated and often intractable task. However, as Zhi-Xuan et al. (2020) show, this difficulty can be alleviated by treating agents as boundedly rational planners, who spend only limited com- putation at each step t on planning. We adopt a more recent version of this architecture (Zhi-Xuan et al., 2024; Ying et al., 2023), modeling agents that update a policy \u03c0\u2081 (i.e. a condi- tional plan) that defines a Boltzmann distribution over actions at that can be taken at state St-1:\n$P(a_t | s_{t-1}, \\pi_t) = \\frac{exp(-\\beta \\pi_t(s_{t-1}, a_t))}{\\sum_a exp(-\\beta \\pi_t(s_{t-1}, a))}$ (5)"}, {"title": "Bottom-Up Sampling of Plausible Goals", "content": "While the analysis above suggests that Bayesian inverse plan- ning is not only tractable, but linear in computational com- plexity, it neglects the fact that the number of goals G can grow very large. As suggested by Blokpoel et al. (2013), this might be because G itself grows exponentially with some other natural parameter in Block Words, for example, just 9-11 lettered blocks can be used to spell anywhere from 150 to 800 English words. But even without this exponential de- pendence, a large value of G can quickly render (exact) goal inference too costly to be algorithmically plausible."}, {"title": "Bayesian Filtering of Bottom-Up Samples", "content": "Given the ability to rapidly generate plausible goals, it is tempting to forgo inverse planning altogether. As Figure 1 illustrates, however, this strategy can go awry. Suppose you see someone stack the block i on top of nk, and the word pi nk comes to mind. But then you see t stacked on top of p - Ispink still a plausible goal? From a bottom-up perspective, pis still a likely completion of ink. But if we understand agents as rational plan- ners, this no longer seems likely. If pink had been the agent's goal, stacking t on p would be quite suboptimal.\nIf humans actually engage in the reasoning above, then modeling their inferences requires uniting top-down Bayesian inverse planning with bottom-up cues. Following other sampling-based accounts of sequential human inferences (Daw & Courville, 2008; Vul et al., 2009; Thaker et al., 2017), we model this integration with a sequential Monte Carlo (SMC) algorithm (Algorithm 1), extending the Sequen- tial Inverse Plan Search (SIPS) algorithm of Zhi-Xuan et al. (2020). SMC algorithms are also known as particle fil- ters, which approximate Bayesian posteriors by maintaining a weighted set of hypotheses or particles, then updating the weights of those particles as observations arrive (Del Moral et al., 2006). At each step, they may also resample particles according to their weights, or rejuvenate the particles, making perturbations to the sample collection to increase hypothesis diversity (Chopin, 2002; Lew, Matheos, et al., 2023).\nA variant of this rejuvenation phase is where our bottom- up samplers come in: As Algorithm 1 shows, after observ- ing each state st and action at at step t, we use these sam- plers as proposal distributions over goals Q(g|st,at), gen- erating N new goal hypotheses g (L4) based on bottom- up cues. These new hypotheses assigned an importance weight $P(g, \\pi_{1:t}, s_{0:t}, a_{1:t})/Q(g|s_{t}, a_{t})$, where the numerator $P(g, \\pi_{1:t}, s_{0:t}, a_{1:t})$ accounts for how well the plans \u03c01:t that lead to g explain the actions a1:t, and the denominator Q(g|st, at) compensates for g having been sampled from the"}, {"title": "Experiments", "content": "We evaluated open-ended SIPS as a model of human goal in- ference on a set of 16 scenarios in Block Words, a variant of the classic Blocksworld domain where the goal is to infer the word that an agent is spelling by stacking a tower of lettered blocks. In contrast to previous Block Words tasks (Ram\u00edrez & Geffner, 2009, 2010; Alanqary et al., 2021; Chandra et al., 2023), we did not specify a fixed set of 5 to 20 goal words. In- stead, we told participants that the goal might be any English word between 3 to 8 letters long, with the implied restriction that the word had to be spelled out of the available blocks."}, {"title": "Structure & Design", "content": "Participants were first shown the ini- tial layout of the blocks. They could then advance the sce- nario, watching several actions play out as an animated video. The video would then pause at a judgment point, giving par- ticipants time to guess the word being spelled via text box entry. Participants could add as many guesses as they liked, and also remove any previous guesses that they no longer con- sidered likely. They could then advance to the next judgment point, continuing in this way until the end of the scenario. Each participant was presented 8 out of the 16 scenarios, af- ter first completing a tutorial and a comprehension quiz. To incentivize high quality responses, we paid participants a re- ward based on the accuracy of their guesses ($0.1/n for ev- ery correct answer out of n guesses), and presented the bonus point breakdown after they completed each scenario."}, {"title": "Experimental Conditions", "content": "To tease apart the predictions of our model from those that would be made by either exact Bayesian inference or pure bottom-up proposals, we designed our 16 scenarios to fall into one of four conditions:\nBottom-Up Friendly. Words are stacked more-or-less lin- early, such that it is sufficient to guess words that complete either the most recently stacked tower, or any partial word.\nIrrational Alternatives Blocks are stacked so that some bottom-up guesses are made irrational, like our pink example from Figure 1.\nGarden Paths. Cases where bottom-up guessing suggests a plausible but misleading interpretation of the first few actions, which turn out to be merely instrumental for the true goal.\nUncommon Words. The true goal is either a longer or more uncommon word (aft, chump, wizard, banish), which people and bottom-up proposals might find difficult to initially guess. Otherwise similar to the first condition."}, {"title": "Participants", "content": "We recruited 100 US participants fluent in En- glish via Prolific (mean age 39.4; 44 women, 54 men, 2 non- binary), such that every scenario was completed by 50 in- dividuals. Participants were paid US$15/hr along with the bonus described earlier. Familiarity with word games var- ied, with 17 reporting that they played word games daily, 22 weekly, 30 every 1-2 months, 11 yearly, and 20 almost never. Despite comprehension checks, a subset of participants did not follow instructions correctly, either because they never updated their guesses (36 out of 800 scenario responses), or only added guesses without removing them (139 out of 800). As such, we excluded such responses from our analysis."}, {"title": "Model Configuration", "content": "We implemented open-ended SIPS using the particle filtering extension of the Gen.jl probabilis- tic programming framework (Zhi-Xuan, 2020; Cusumano- Towner et al., 2019), and the Blocksworld domain in the Planning Domain Definition Language (Zhi-Xuan, 2022; Mc-Dermott et al., 1998). We fit parameters via grid search to improve model similarity with humans as measured by the intersection over union (IoU) between distributions (see Ap- pendix), which gave an inverse temperature of $\u03b2 = 1.0$, plan- ning budget of B = 100, and prior P(g) fitted to tempered word frequencies from the wordfreq library (Speer, 2016), using the 30f6game word list as our dictionary (Beale, 2016). We ran open-ended SIPS with $N \\in \\{2,5,10,20,50\\}$ particles, taking the mean and variance over $M = max(10,200/N)$ tri- als. We describe the proposals Q(g|st, at) in the next section."}, {"title": "Alternative Models", "content": "As alternatives to our hybrid SMC model, we tested both (i) exact inference via fully enumer- ative Bayesian inverse planning over all valid English goal words (145-807 words, depending on the scenario) and (ii) pure bottom-up sampling using a subgoal-conditioned pro- posal. Exact inference was implemented using the same model parameters as open-ended SIPS, except that all goals were considered as hypotheses from the outset.\nFor the bottom-up proposal, we sampled complete words g by conditioning an n-gram model on some partial word that can be stacked from blocks in the current state st. We used n = 5, fitting the n-gram on the same tempered word frequen- cies used for the prior P(g). To decide which partial word to complete, the proposal first considers the tower stacked by the last action at, sampling a completion if it is sufficiently word-like (as determined by the n-gram model). If not, it con- siders if the last block was moved because the agent intended to reach some block underneath it, and tries to form a word with one of those blocks. If no way of using those blocks is sufficiently word-like, the proposal samples a random tower in state st (weighted by how word-like it is), then samples a completion. Other proposals are discussed in the Appendix."}, {"title": "Results", "content": "We analyzed human responses and model outputs by compar- ing them in terms of distribution similarity (Fig. 2a), average accuracy (Fig. 2b), step-by-step inferences (Fig. 3), response variance (Fig. 4a), sample efficiency (Fig. 4b), and resource rationality (Fig. 4c). Additional results (e.g. accuracy vs. runtime) and sensitivity analyses are in the Appendix.\nOpen-ended SIPS is most similar to human inferences across all conditions. As we predicted, human inferences showed the highest similarity with open-ended SIPS (IoU = 0.33\u20130.36 for all N) compared to exact inference (IoU = 0.31) or bottom-up guessing (IoU = 0.30\u20130.32), with N = 2 sam- ples being the most similar. Notably, open-ended SIPS was more similar to humans in the Irrational Alternatives condi- tion, with both achieving considerably higher accuracy than the bottom-up only heuristic, indicating that humans indeed engage in inverse planning. Our model was also more similar to humans than exact inference, especially in the Bottom-Up Friendly and Garden Path conditions, consistent with the hy- pothesis that humans engage in bottom-up sampling.\nStep-by-step human inferences are best matched by open-ended SIPS. The step-by-step comparisons in Figure 3 help to elucidate these aggregate findings. On one hand, open-ended SIPS and the proposal-only model make initial guesses that are biased towards words that complete the first few stacked letters, whereas the exact posterior is much more uncertain. On the other hand, humans account for the ra- tionality of the observed actions when drawing inferences (e.g. Figure 3(a), t = 10), just like our exact and approximate Bayesian inverse planning algorithms.\nOur model's algorithmic properties best explain human variance and guess counts. In Figure 4, we compare the algorithmic properties of the models. Human variance was best matched by open-ended SIPS with N = 2. Bottom-up proposals had lower variance, and did not prune samples as effectively as sample-matched counterparts. Exact inference is zero-variance, but at the cost of tracking drastically more hypotheses. As such, it was dominated by open-ended SIPS in terms of net reward when accounting for cognitive costs (Fig. 4c). The comparison with pure bottom-up proposals was more nuanced. If reweighting a sample via inverse plan- ning is costly enough, pure bottom-up guessing can be more resource-rational (Lieder & Griffiths, 2020). However, there is a large range of cost-ratios where it pays to do inverse plan- ning. Since humans attained more reward than all proposal- only baselines in the Irrational Alternatives condition, this suggests that they indeed find inverse planning worthwhile."}, {"title": "Discussion", "content": "In comparison to alternative models, our sampling-based ac- count of open-ended goal inference is best supported on both empirical and theoretical grounds, providing an algorithmi- cally plausible explanation for the speed and flexibility of hu- man goal inference. Still, our experiments find that humans remain more similar to themselves (IoU = 0.44) than our best- fitting model (IoU = 0.35). Part of this might be explained by the discrepancy between the statistics of how humans guess in word games versus the text corpus frequencies that inform our model. This could be addressed by deriving a prior and proposal from human guesses. Humans also appear to exhibit stickier inferences in garden path cases, whereas open-ended SIPS tends to avoid them when run with larger values of N by proposing new goals at every step. This suggests that hu- mans may be adaptive in deciding when to rejuvenate their hypotheses (Del Moral et al., 2012; Elvira et al., 2016). Fi- nally, unlike our model, humans might forget older observa- tions, becoming more inaccurate, but also more efficient at inference. SMC algorithms that selectively forget past obser- vations could mimic this (Beronov et al., 2021).\nAnother open question is how bottom-up sampling can be made more general. In future work, we plan to explore how the statistics of co-occurring subgoals can be distilled from web-scale language models (West et al., 2022) into domain- specific models for rapid hypothesis generation. These statis- tics might be augmented by static analysis of environment models, automatically determining which subgoals are instru- mental for other goals (Blum & Furst, 1997). Such mecha- nisms for flexible domain adaptation could provide an even richer picture of how we contend with the infinitude of ends that others pursue, even in the face of our very finite means."}, {"title": "Appendix", "content": "The web interface used by participants is shown in Fig- ure A1. At each judgment point, participants typed their guesses into the text box, which validated whether the guess was between 3 and 8 characters and used only the letters that were available. Participants could also remove their guesses by clicking the symbol next to each guess. The list of guesses was converted into a probability distribution by assigning a probability of 1/n to each word among the n guesses. Participants could rewatch the most recent seg- ment of the animation by pressing the Replay button, or re-watch the whole animation up to the judgment point by press- ing the Replay All button. This interface is accessible at https://block-words.web.app/?local=true."}, {"title": "Model Fitting and Sensitivity Analysis", "content": "Our model of open-ended goal inference is characterized by two sets of parameters: The parameters of the generative model P(g, \u03c01:1, S0:1, 1:t), and the parameters of the inference algorithm which approximates P(g|s0:1, 1:t). We fit the pa- rameters of the generative model across the following ranges:\n\u2022 Goal prior word temperature $T_w \\in \\{1,2,4,8,16\\}$\n\u2022 Inverse temperature $\u03b2 \\in \\{1,1,1,2,4\\}$\n\u2022 Planning budget $B \\in \\{5, 10, 20, 50, 100, 200, 500\\}$\n\u2022 Replanning cadence $At \\in \\{1,2\\}$\n\u2022 RTHS search strategy $\u03c3 = A* \\text{ or } BFS$\nTw controls tempering of the wordfreq-derived word fre- quencies used for the goal prior P(g), and \u1e9e controls the optimality of action selection. B is the planning budget for real-time heuristic search (RTHS) algorithm, At is the num- ber of timesteps between each call to RTHS that updates the policy \u03c0\u2081, and o controls how nodes are expanded by RTHS, which is done either via A* search around each neighbor of the current state st (guided by the FF heuristic as the default \u00d4n, value) as in LSS-LRTA* (Koenig & Sun, 2009), or via breadth-first search (BFS) around the current state st, as in LRTA*-LS (Hern\u00e1ndez & Meseguer, 2007).\nFor the inference algorithm, we fit these parameters:\n\u2022 n-gram word temperature $T_w \\in \\{1,2,4,8,16\\}$\n\u2022 n-gram termination bias $e \\in \\{0,0.05,0.1,0.15,0.2,0.25\\}$\n\u2022 Bottom-up proposal strategy $Q\\in \\{LAST-AND-NEXT,...\\}$\n\u2022 Number of samples $N \\in \\{2,5, 10, 20, 50\\}$\nTw tempers the word frequencies used to fit the n-gram model for the bottom-up proposal Q, and is matched to be the same value used for the goal prior P(g). To capture the difficulty of guessing longer words, we modified the n-gram to have an additional \u025b probability of terminating after each charac- ter. For simplicity, we fixed the context length of the n-gram model to n = 5. Various ways of implementing the bottom-up proposal Q are discussed in the next section. We also vary the number of particles N used by open-ended SIPS.\nFitting procedure. Model fitting proceeded in two stages. We first fit the generative model parameters to improve similarity with humans, using exact inference to factor out stochasticity or performance issues in the inference algorithm from the quality of the generative model itself. Instead of Pearson's correlation coefficient (commonly used in other BTOM studies), we used the intersection-over-union between human and model distributions (i.e. the Jaccard index) as our similarity metric, since it does not consider two probability vectors similar just because they both contain many zeros. Having determined values of B = 100, At = 2 and \u03c3 = BFS that led to the most similarity with humans under the con- straint of a reasonable runtime, we then fit the parameters of the open-ended SIPS algorithm. The best fitting inference parameters were Tw = 4 (which was matched with the goal prior's Tw), \u03b5 = 0.05, Q = LAST-AND-NEXT, and N = 2.\nGenerative model sensitivity analysis. Figure A2 shows how similarity with humans varies across generative model parameters when using exact Bayesian inference. A higher planning budget B leads to a stronger fit, showing the impor- tance of computing a good estimate of the agent's policy via planning."}, {"title": "Bottom-Up Proposals", "content": "For bottom-up sampling, we experimented with proposals Q(g|st, at) of varying degrees of sophistication. In all of these proposals, we sample complete words g by conditioning an n-gram language model on some partial word that can be stacked from the blocks in the current state st. However, this still leaves undetermined which partial words, or subgoals, to consider. We implemented the following strategies for select- ing partial words to complete:\nANY-TOWER samples a random block tower in state st, then tries to complete it into a full word. The probability of sampling a tower is proportional to how word-like the tower is - i.e., how probable it is according the n-gram model.\nLAST-TOWER tries to sample a word that completes the tower most recently stacked by action at. However, if this tower t is not sufficiently word-like (or if at is not a stacking action), the proposal falls back to ANY-TOWER instead. This is implemented by comparing the probability Plast of the most recently stacked tower under the n-gram against the probabil- ity Prand of an equally tall tower of random blocks, then de- ciding to complete the last tower with probability $\\frac{P_{last}}{P_{last} + P_{rand}}$.\nNEXT-TOWER focuses on cases where the agent is un- stacking a tower of blocks in order to reach a block in that tower. The proposal considers all ways of using a block in the most recently unstacked tower to complete some other block tower. One of these candidate towers \u03c4 is selected with prob- ability proportional to how word-like it is, and then a comple- tion is sampled from to the n-gram model. If no candidate is word-like enough compared to the probability of selecting a random block, then the proposal defaults to ANY-TOWER.\nLAST-AND-NEXT is the most sophisticated of our propos- als, which we describe and use in the main text. It is equiv- alent to LAST-TOWER, except it defaults to NEXT-TOWER if the last action is not a stacking action, or if the last stacked tower is not sufficiently word-like."}, {"title": "Handling auxiliary randomness", "content": "Note that all of our bottom-up proposals make use of auxiliary randomness (Lew et al., 2022) when sampling a tower t to complete into a full word g. This means that even though we can sample from g~Q(g St,at), we cannot exactly evaluate the probability Q(g St,at) used in the importance weight. Instead, we can only evaluate Q(gst, at, t) using the n-gram model, which is conditional on the choice of tower \u03c4 ~ Q(\u03c4). In the con- text of an SMC algorithm like open-ended SIPS, however, we can use an unbiased density sampler of Q(g|st, a\u2081) (Lew, Ghavamizadeh, et al., 2023; Lew et al., 2022), which returns both g and a weight w such that Eg[w\u00ae1|g] = Q(g|st,at)-1. This weight w can then be used as the denominator when computing importance weights in L6 of Algorithm 1. Using w = Q(g|St, at, \u03c4) satisfies this property."}, {"title": "Additional Similarity Metrics", "content": "In Figure A4, we report additional measures of similarity be- tween human goal inferences and model outputs: (a) Pear- son's correlation r, (b) the overlap coefficient between distri- butions (a generalized version of recall), and (c) total varia- tion distance (which captures the maximum difference in the probability of any event under two distributions). Regardless of the metric, open-ended SIPS is more similar to humans than exact inference or the bottom-up proposal. This is most pronounced in the Irrational Alternatives condition."}, {"title": "Additional Step-by-Step Comparisons", "content": "In Figure A5, we show step-by-step comparisons between hu- man and model inferences for the two experimental condi- tions not covered in the main text.\nIn the Bottom-Up Friendly scenario, limited inverse plan- ning is necessary, and so the bottom-up proposal is as good an explanation for human goal inference as open-ended SIPS for all steps except t = 8. At this step, the bottom-up proposal generates words that end in p by following the LAST-TOWER proposal strategy. This fails to take into account the previ- ous actions of stacking block n onto block s, highlighting the importance of inverse planning in even simple scenarios.\nIn the Uncommon Words scenario, we chose the uncom- mon word chump to be the goal, and designed actions to make more common distractors like jump and hump seem likely. As expected, most humans failed to think of chump as a possibility until the very last step (t = 12). Open-ended SIPS and the proposal only baseline with N = 2 particles re- flected this tendency, demonstrating how inferring rare events is difficult with a small number of samples. In contrast, the exact inference baseline enumerates all possible words at ev- ery step, and hence assigns chump a significant probability at t = 10. This is the case even though chump is less likely under the goal prior P(g): an event being rare under the pro- posal Q leads to qualitatively different behavior than exact inference over events with low prior probabilities."}, {"title": "Accuracy and Runtime", "content": "While our analysis in this paper focused on open-ended SIPS as a rational process model of human goal inference, our algorithm can also be used as a practical tool for building AI systems that better infer people's goals in order to assist them (Zhi-Xuan et al., 2024). To that end, we compare the accuracy-runtime tradeoffs of both open-ended SIPS and the baseline methods. All experiments were conducted on a lap- top with an i7-1370P 1.90 GHz CPU and 64 GB of RAM.\nEffect of planner configuration. In Figure A6, we show how the accuracy of goal inference changes as a function of the planner configuration used in the generative model. Ac- curacy is plotted against algorithm runtime per observed ac- tion. We find that accuracy generally increases with planning budget, indicating the importance of spending enough com- putation on calculating good \u00d4n, estimates, which improves the quality of the action likelihood P(at|g). The effect of the search strategy is more subtle. Using A* search as the RTHS search strategy can improve accuracy when At = 1 (i.e. when the policy is updated at every timestep). However, this leads to an increased runtime compared to BFS for any given plan- ning budget B, with A* being 2-5 times slower than BFS for low planning budgets. Still, using A* with At = 1 achieves higher accuracy than BFS ever does, indicating its value when accuracy is paramount. Unlike the planning budget, increas- ing the particle count N does not appear to substantially im- prove the average accuracy of open-ended SIPS, with changes in planner configuration dominating any accuracy improve- ment from additional particles."}]}