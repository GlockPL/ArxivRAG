{"title": "Learning for Cross-Layer Resource Allocation in MEC-Aided Cell-Free Networks", "authors": ["Chong Zheng", "Shiwen He", "Yongming Huang", "Tony Q. S. Quek"], "abstract": "Cross-layer resource allocation over mobile edge computing (MEC)-aided cell-free networks can sufficiently exploit the transmitting and computing resources to promote the data rate. However, the technical bottlenecks of traditional methods pose significant challenges to cross-layer optimization. In this paper, joint subcarrier allocation and beamforming optimization are investigated for the MEC-aided cell-free network from the perspective of deep learning to maximize the weighted sum rate. Specifically, we convert the underlying problem into a joint multi-task optimization problem and then propose a centralized multi-task self-supervised learning algorithm to solve the problem so as to avoid costly manual labeling. Therein, two novel and general loss functions, i.e., negative fraction linear loss and exponential linear loss whose advantages in robustness and target domain have been proved and discussed, are designed to enable self-supervised learning. Moreover, we further design a MEC-enabled distributed multi-task self-supervised learning (DMTSSL) algorithm, with low complexity and high scalability to address the challenge of dimensional disaster. Finally, we develop the distance-aware transfer learning algorithm based on the DMTSSL algorithm to handle the dynamic scenario with negligible computation cost. Simulation results under 3rd generation partnership project 38.901 urban-macrocell scenario demonstrate the superiority of the proposed algorithms over the baseline algorithms.", "sections": [{"title": "I. INTRODUCTION", "content": "With the rapid proliferation of the fifth generation (5G) communication technologies in recent years, people's life experience as well as industrial efficiency have achieved a further leap. However, to satisfy future demands for information and communications technology (ICT) in 2030, researchers in both academia and industry have shifted their attention to sixth generation (6G) communication systems [1], [2]. Numerous promising wireless techniques, e.g., massive multiple-input multiple-output (MIMO) [3], mobile edge computing (MEC) [4] and cell-free [5], are expected to tackle ongoing challenges, e.g., enormous wireless traffic, massive user access, and ultra-reliable low-latency communication. CF-MIMO systems have abilities to sufficiently exploit transmitting resources in massive user networks to promote the data transmitting rate through coordinated multi-point joint transmission.\nOrthogonal frequency division multiple access (OFDMA) as an effective multiplexing scheme has been adopted in the 3rd generation partnership project (3GPP) [6]. The transmission scheme design in the OFDMA CF-MIMO system contains two crucial issues, i.e., subcarrier allocation (SA) at the media access control layer [7] and beamforming (BF) design at the the physical layer [8]. These two aspects are cross-layer and tightly intertwined in the downlink transmission and thus need to be jointly optimized for better-transmitting performance. However, most relevant works optimize the SA and BF separately without any consideration of their coupled relations. Specifically, many works have investigated the separate SA optimization problem from the perspective of the traditional optimization [9], game theory [10], and machine learning [11]. On the contrary, many other literatures [12]\u2013[14] study the BF design from the same three perspectives while completely ignoring the influence of the SA design. Although separately considering the SA optimization or the BF design in these mentioned works both show the promise of improving system performance, the separate optimization will cause significant performance loss or even become impractical due to the tightly coupled relationship between the SA and the BF in the OFDMA CF-MIMO systems. In addition, the power allocation (PA) as an important part of the transmission design has been jointly considered with the SA optimization or the BF design in many related works, i.e., [9], [15]\u2013[17]. We would like to point out that the PA is not the focus of this paper and thus the reviews of the works related to the joint PA and SA/BF will not be detailed here. Nevertheless, it should be emphasized that the design of the PA is implicit in the BF design in this paper.\nIn fact, researchers have long realized the importance of the joint SA and BF optimization for improving the trans- mission performance of wireless systems, and have conducted continuous research on this joint optimization problem [18]\u2013 [24]. However, the optimization variables are coupled in high- dimensional space when considering the joint optimization of the SA and BF, which poses tough challenges, e.g., high complexity, NP-hard, etc., to the solution of this optimization problem. Especially when the CF-MIMO system is further involved, the solution of this joint optimization problem will be more challenging. On the one hand, to simplify the problem,"}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "We investigate the joint SA and BF for the coordinated multi-point joint downlink transmission of MEC-aided CF- MIMO communication system, including one macro base station (MBS), B multi-antenna SBS and I multi-antenna users. Assume that each SBS is equipped with $M_t$ transmitting antennas denoted as $M_t = \\{1,2,\\dots, M_t\\}$ and each user is equipped with $M_i$ receiving antennas denoted as $M_i = \\{1,2,\\dots, M_i\\}$. Moreover, we also assumed that each SBS has N subcarriers for the downlink transmission, denoted as $\\mathcal{N} = \\{1,2,\\dots,N\\}$. The MEC server, which can be the general-purpose computer or server, is deployed on each SBS to provide certain computing and caching capabilities. For simplicity, let $\\mathcal{B} = \\{1,2,\\dots, B\\}$ and $\\mathcal{I} = \\{1, 2, \\dots, I\\}$ be the set of SBSs and users, respectively. Let $\\mathbf{v}_b = [v_{b,1},\\dots, v_{b,I}]^T \\in \\mathbb{C}^{N \\times I}$ denote the SA indicator of the b-th SBS, where $\\mathbf{v}_{b,i} = [v_{b,i}^1,\\dots, v_{b,i}^N]^T \\in \\mathbb{C}^{N \\times 1}$ and $v_{n,i}^b$ is a binary variable that is 1 if subcarrier n of SBS b is allocated to user i and 0 otherwise. The SA vector of all SBSs on subcarrier n for user i can be given by $\\mathbf{v}_{n,i} = [v_{n,i}^1,\\dots, v_{n,i}^B]^T \\in \\mathbb{C}^{B \\times 1}$. Let $\\mathbf{w}_{b,n,i} \\in \\mathbb{C}^{M_t \\times 1}$ represent the beamforming vector of SBS b on subcarrier n for user i and $\\mathbf{w}_b \\in \\mathbb{C}^{NM_t + I}$ denote the beam- forming indicator of the b-th SBS. The beamforming vector of all SBSs on subcarrier n for user i can be denoted as $\\mathbf{w}_{n,i} = [(\\mathbf{w}_{1,n,i})^T,\\dots, (\\mathbf{w}_{B,n,i})^T]^T \\in \\mathbb{C}^{B M_t \\times 1}$, Let $\\mathbf{H}_{b,n,i} \\in \\mathbb{C}^{N M_t \\times I M_i}$ denote the channel coefficient matrix between the b-th SBS and all users. $\\mathbf{H}_{i,b}^n \\in \\mathbb{C}^{M_i \\times M_t}$ represents the channel coefficient between user i and SBS b on subcarrier n. Then, the channel coefficient matrix between user i and all SBSs on subcarrier n can be denoted as $\\mathbf{H}_{n,i} = [(\\mathbf{H}_{i,1}^n)^T,\\dots, (\\mathbf{H}_{i,B}^n)^T]^T \\in \\mathbb{C}^{B M_t + I M_i}$. For the convenience of implementation, we can concatenate the channel coefficients of the system into a matrix $\\mathbf{H} = [(\\mathbf{H}_1)^T,\\dots, (\\mathbf{H}_B)^T]^T \\in \\mathbb{C}^{B N \\times I M}$.\nThe baseband signal received by user i on subcarrier n can be defined by\n$y_{n,i} = (\\mathbf{H}_{n,i})^H (\\nabla_{n,i}\\mathbf{w}_{n,i}) s_{n,i} + \\sum_{j\\neq i} (\\mathbf{H}_{n,i})^H (\\nabla_{n,j}\\mathbf{w}_{n,j}) s_{n,j} + z_{n,i},$ (1)\nwhere $s_{n,i}$ and $z_{n,i} \\in \\mathbb{C}^{M_i \\times 1}$ denote the baseband signal for user i on subcarrier n and the additive white Gaussian noise with $\\mathcal{CN} (0, \\sigma^2)$ at user i on subcarrier n, respectively. $\\nabla_{n,i} \\in \\mathbb{C}^{B M_t + \\times B M_t}$ is the block diagonal matrix extended form $\\mathbf{v}_{n,i}$.\n$\\nabla_{n,i} = \\text{diag} (v_{n,i}^1 \\mathbf{I}_{M_t},\\dots, v_{n,i}^B \\mathbf{I}_{M_t})$ (2)\nwhere $\\otimes$ represents the Kronecker Product. Then, the achiev- able rate of user i is expressed as\n$r_i = \\sum_{n=1}^N \\log_2 |\\mathbf{I}_{M_i} + S_{n,i} \\times (A_{n,i})^{-1}|,$ (3)\nwhere $|\\cdot|$ represents the determinant of the matrix. $S_{ni}$ and $A_{ni}$ are the covariance matrix of the baseband signal and interference signal at user i on subcarrier n, respectively, denoted as\n$S_{n,i} = (\\mathbf{H}_{n,i})^H (\\mathbf{v}_{n,i} \\mathbf{w}_{n,i}) (\\mathbf{v}_{n,i} \\mathbf{w}_{n,i})^H \\mathbf{H}_{n,i},$ (4)\n$A_{n,i} = \\sum_{j\\neq i} (\\mathbf{H}_{n,i})^H (\\mathbf{v}_{n, j} \\mathbf{w}_{n,j}) (\\mathbf{v}_{n,j} \\mathbf{w}_{n,j})^H \\mathbf{H}_{n,i} + \\mathbf{I}_{M_i}$ (5)\nUnder the investigated CF-MIMO communication scenario, the objective is to maximize the weighted sum rate of the sys- tem via joint SA and BF design. Accordingly, the optimization problem is formulated as\n$\\begin{aligned}\n&\\underset{\\{\\mathbf{w},\\mathbf{v}\\}}{\\text{max}} &&\\sum_{i=1}^{I} a_i r_i,\\\\ &\text { s.t. } & & r_i \\geq r_{\\text{min}}, \\forall i \\in \\mathcal{I},\\\\ & & & \\sum_{n=1}^N \\sum_{i=1}^I |v_{n,i}^b\\mathbf{w}_{n,i}|^2 \\leq P_{\\text{max}}, \\forall b \\in \\mathcal{B},\\end{aligned}$ (6)\n$\\begin{aligned}\n& & & v_{n,i}^b \\in \\{0,1\\}, \\forall b \\in \\mathcal{B},\\\\\n& & & [\\mathbf{w}_{n,i}]_{v_{n,i}^b = 1} \\neq \\emptyset, \\forall n,i, b,\\\\ & & & \\mathbf{w}_{n,i} \\in \\mathbb{C}^{B M_t \\times 1}, \\mathbf{v}_{n,i} \\in \\mathbb{C}^{N \\times I},\\end{aligned}$\nwhere $\\mathbf{w} = [\\mathbf{w}_{n,i}]_{n=1,i=1}^{N,I}$ and $\\mathbf{v} = [\\mathbf{v}_{n,i}]_{n=1,i=1}^{N,I}$ are the stack of the $\\mathbf{w}_{n,i}$ and $\\mathbf{v}_{n,i}$, respectively. $a_i$ denotes the prior of user i and $r_{\\text{min}}$ is the minimum data rate required by user i. $P_{\\text{max}}$ represents the maximum allowable transmiting power"}, {"title": "C. Problem Recast", "content": "To address the aforementioned technical challenges by developing learning methods, we convert problem (6) into a multi-task learning problem whose learning tasks consist of the optimization objective and the constraints. Firstly, for simplicity and generalization, we herein introduce some aux- iliary functions, i.e., $\\mathbf{y} = \\{\\mathbf{w}, \\mathbf{v}\\}$, $f (\\mathbf{y}, \\mathbf{H}) = -\\sum_{i=1}^I a_i r_i$, $g_i (\\mathbf{y}, \\mathbf{H}) = r_{\\text{min}}-r_i$, and $l_b (\\mathbf{y}) = \\sum_{n=1}^N \\sum_{i=1}^I |v_{n,i}^b \\mathbf{w}_{n,i}|^2 - P_{\\text{max}}$, to equivalently rewrite problem (6) as\n$\\begin{aligned}\n&\\underset{\\mathbf{y}}{\\text{min}} &&f (\\mathbf{y}, \\mathbf{H}),\\\\ &\text { s.t. } & & g_i (\\mathbf{y}, \\mathbf{H}) \\leq 0, \\forall i \\in \\mathcal{I},\\\\ & & & l_b (\\mathbf{y}) \\leq 0, \\forall b \\in \\mathcal{B},\\end{aligned}$ (7)\n$\\begin{aligned}\n&\\underset{\\mathbf{y}}{\\text{min}} &&f (\\mathbf{y}, \\mathbf{H}),\\\\ &\text { s.t. } & & f (\\mathbf{y}, \\mathbf{H}) \\leq 0.\\end{aligned}$ (8)\n$\\begin{aligned}\n&\\underset{\\mathbf{y}}{\\text{min}} &&g_i (\\mathbf{y}, \\mathbf{H}),\\\\ &\text { s.t. } & & g_i (\\mathbf{y}, \\mathbf{H}) \\leq 0.\n\\end{aligned}$ (9)\nRegarding constraint (7c), it prevents the transmitting power overload of each SBS.\nIn this work, we focus on the weighted sum rate maximiza- tion rather than the power minimization. Therefore, each SBS is supposed to perform full power transmission to maximize the transmission rate without considerations about energy conservation. Note that, full power transmission is a desired target for the total transmission power of each SBS, while the transmission power allocation for users under this target are implicitly conducted in the specific beamforming vector w. Hence, $l_b (\\mathbf{y}) = \\sum_{n=1}^N \\sum_{i=1}^I |v_{n,i}^b \\mathbf{w}_{n,i}|^2 - P_{\\text{max}}$ is expected to approach zero. For $b\\in \\mathcal{B}$, constraint (7c) can be converted to a minimization learning task, denoted as\n$\\begin{aligned}\n&\\underset{\\mathbf{y}}{\\text{min}} &&l_b (\\mathbf{y}),\\\\ &\text { s.t. } & & l_b (\\mathbf{y}) \\leq 0.\n\\end{aligned}$ (10)\nNote from (8), (9) and (10) that, the multi-task optimization problem consists of $I+B+1$ tasks due to the fact that there are one optimization objective and $I + B$ constraints in problem (7)."}, {"title": "III. METHODOLOGY", "content": "In this section, we introduce the methodology for solving the multi-task learning problem. Firstly, we design two novel loss functions, i.e., NFL loss and EL loss, for the preparation of solving the multi-task problem in an end-to-end self- supervised learning manner. After that, we propose a CMTSSL algorithm to solve the underlying problem efficiently while avoiding costly manual labeling. Furthermore, we design a DMTSSL algorithm to reduce the computational complexity as well as improve the system performance. Finally, to handle the dynamic scenario, that a new SBS is suddenly added to the communication system, at a low cost, we further design a DATL algorithm by exploiting the scalability of the DMTSSL algorithm.\nIn supervised learning, the input of regular loss functions is the residual between labels and network outputs. However, it is difficult to obtain real labels in our problem. Therefore, we need to design new loss functions to solve the problem (7) in a self-supervised manner. The design of new loss functions should ensure that during the network training process, as the function output approaches zero, the loss function input can gradually approach the target domain without labels. To this end, we herein design two novel loss functions, i.e., NFL loss and EL loss, and introduce one classical loss function, i.e., Huber loss. Specifically, the NFL loss is defined by\n$L_{NFL} (x) = \\begin{cases}\nx, & x>\\chi_1 \\\\\n-\\infty, & x<\\chi_1<0\n\\end{cases}$ (11)\nThe EL loss is defined by\n$L_{EL} (x) = \\begin{cases}\ne^x, & x \\geq \\chi_2 \\\\\n\\chi_2\\cdot(e^{\\chi_2+1} - 2), & x < \\chi_2\n\\end{cases}$ (12)\nThe Huber loss [40], which is used to assist in the construction of subsequent training loss schemes, can be expressed as\n$L_{Huber} (x) = \\begin{cases}\n\\frac{|x|^2}{2}, & |x| < \\chi_3>0 \\\\\n\\chi_3 |x| - \\frac{\\chi_3^2}{2}, & \\text{otherwise}\n\\end{cases}$ (13)"}, {"title": "B. Centralized Self-supervised Multi-task Learning", "content": "In this subsection, we first design training losses for the multiple tasks. Then, we develop a CMTSSL algorithm based on the NFL and EL losses to solve problem (7) via centralized end-to-end self-supervised. The framework of the CMTSSL algorithm is illustrated in Fig. 2.\nAccording to (8), (9) and (10), we define the self-supervised loss for each learning task based on the newly designed losses. Specifically, based on the loss properties discussed in Appendix A, losses of the I+1 tasks in (8) and (9) can be defined by the NFL loss or the EL loss, while losses of the B learning tasks in (10) can be defined by the Huber loss. Thus, we give following two loss schemes for the conversion of problem (7),\n$\\begin{aligned}\nL_o (\\mathbf{y}, \\mathbf{H}) &= L_{NFL} (f (\\mathbf{y}, \\mathbf{H})),\\\\\nL_i (\\mathbf{y}, \\mathbf{H}) &= L_{NFL} (g_i (\\mathbf{y}, \\mathbf{H})), \\forall i \\in \\mathcal{I},\\\\\nL_b^2 (\\mathbf{y}) &= L_{Huber} (l_b (\\mathbf{y})), \\forall b \\in \\mathcal{B}.\n\\end{aligned}$ (14)\n$\\begin{aligned}\nL_o (\\mathbf{y}, \\mathbf{H}) &= L_{EL} (f (\\mathbf{y}, \\mathbf{H})),\\\\\nL_i (\\mathbf{y}, \\mathbf{H}) &= L_{EL} (g_i (\\mathbf{y}, \\mathbf{H})), \\forall i \\in \\mathcal{I},\\\\\nL_b^2 (\\mathbf{y}) &= L_{Huber} (l_b (\\mathbf{y})), \\forall b \\in \\mathcal{B}.\n\\end{aligned}$ (15)\nNote that equations (14) and (15) are general expressions that can be applied to all the proposed algorithms in this work. It is not difficult to observe from (8), (9) and (10) that the multi-task learning problem contains $I + B +1$ tasks, which is also equal to the total number of the objective and constraints in problem (6). The self-supervised loss function of each learning task can be defined by the aforesaid Loss Scheme 1 or Loss Scheme 2.\nThen, based on maximizing the Gaussian likelihood with homoscedastic uncertainty [42], the weight-adaptive joint loss for the investigated multi-task learning problem can be given by\n$\\begin{aligned}\nL_c (\\mathbf{y}, \\boldsymbol{\\beta}, \\mathbf{H}) = &\\frac{1}{(I + B + 1) (\\beta_{o})^2} L_{o} (\\mathbf{y}, \\mathbf{H}) + \\frac{1}{(I + B + 1)} \\sum_{i=1}^I \\frac{1}{(\\beta_{1,i})^2} L_{i} (\\mathbf{y}, \\mathbf{H}) + \\frac{1}{(I + B + 1)} \\sum_{b=1}^B \\frac{1}{(\\beta_{2,b})^2} L_{b}^2 (\\mathbf{y}) \\\\ &-\\log (\\beta_{o} \\prod_{i=1}^I \\beta_{1,i} \\prod_{b=1}^B \\beta_{2,b}),\n\\end{aligned}$ (16)\n$\\begin{aligned}\n\\{\\mathbf{y}, \\boldsymbol{\\beta}\\} = \\pi_{\\Theta_c} (\\mathbf{H}),\n\\end{aligned}$ (17)\n$\\begin{aligned}\nL_{avg} (\\Theta_c) = \\frac{1}{S} \\sum_{s \\in \\mathcal{D}_{mb}} L_c (\\mathbf{y}^{(s)}, \\boldsymbol{\\beta}^{(s)}, \\mathbf{H}^{(s)}),\n\\end{aligned}$ (18)"}, {"title": "C. Distributed Self-supervised Multi-task Learning", "content": "Inspired by a classic distributed algorithm in the multi- agent reinforcement learning, namely centralized training and decentralized execution [43], we herein design a distributed DL framework, i.e., DMTSSL algorithm as illustrated in Fig. 3, where the SBSs and the MBS play the similar roles of the distributed actors and centralized critic, respectively. In the DMTSSL algorithm, each SBS can individually determine its own joint SA and BF vector by deploying an NN model with the same structure, while the MBS computes the global loss to supervise the training of each local NN model during the phase of offline training. The MEC servers with sufficient computational resources provide supporting infrastructure for the design of the DMTSSL algorithm.\n$\\begin{aligned}\n\\{\\mathbf{y}^b, \\boldsymbol{\\beta}^b\\} = \\pi_{\\Theta_D^b} (\\mathbf{H}^b).\n\\end{aligned}$ (19)\n$\\begin{aligned}\n\\boldsymbol{\\beta} = \\frac{1}{B} \\sum_{b=1}^B \\boldsymbol{\\beta}^b.\n\\end{aligned}$ (20)"}, {"title": "D. Distance-aware Transfer Learning", "content": "In practical production and life, there are some common dynamic communication scenarios where new SBSs appear in the original communication network, such as emergency communication scenarios where mobile SBSs are temporarily deployed for concerts or other large-scale events, unmanned aerial vehicle (UAV)-assisted communication scenarios where mobile UAV base station cooperates with ground SBSs for dynamic networking, and etc.. When considering these dy- namic scenarios that a new SBS is added to the communication system, most learning methods need to retrain the NN model for better performance. However, the retraining process is costly in terms of time and computation. To handle this dynamic scenario with negligible cost, we develop a simple but effective DATL algorithm by exploiting the scalability of the proposed DMTSSL algorithm. The framework of the DATL algorithm is illustrated in Fig. 4.\nSpecifically, we assume that there is an original SBS set B where each SBS is deployed with an NN model trained by the DMTSSL algorithm. When a new SBS, assumed to place at $(x_o, y_o)$, is added to the original SBSs set, the new SBS first senses the geographical distance from the other SBSs in the original set B and then transfer the NN model on the nearest SBS to itself. After that, the transferred model is directly used by the new SBS for its SA and BF. The nearest SBS can be obtained by\n$\\begin{aligned}\nb^* = \\arg \\min_{b \\in B} \\sqrt{(x_b - x_o)^2 + (y_b - y_o)^2},\n\\end{aligned}$ (22)\nwhere $(x_b, y_b)$ is the geographical coordinate of the SBS b. When the transfer process is completed, these B + 1 SBSs can perform their own joint SA and BF to maximize the weight sum rate of this new system. Note that the reasonable assumption that the new SBS is the same as the original SBS on hardware configurations, i.e., the number of subcarriers and transmitting antenna, is needed for the DATL algorithm."}, {"title": "IV. NUMERICAL SIMULATIONS AND ANALYSES", "content": "In this section, we evaluate the performance of the proposed algorithms via numerical examples. We consider the 3rd generation partnership project 38.901 urban-macrocell (3GPP 38.901 UMa) scenario to cope with realistic scenarios while the quasi-deterministic radio channel generator (QuaDRiGa) [45], [46] is adopted to model the channel of the wireless communication system. The simulation environment contains a single MBS, B multi-antennas SBS and I multi-antennas users. Each SBS has N subcarriers for its download transmit- ting. For simplicity, we assume that all users on all subcarriers have the same noise variance, the maximum transmitting power of each SBS as well as the minimum data rate of each user are equal, i.e., $\\sigma_n^2 = \\sigma^2, \\forall i \\in \\mathcal{I}, n \\in \\mathcal{N}$,$P_b^{\\text{max}} = P_{\\text{max}}, \\forall b \\in \\mathcal{B}$ and $r_{\\text{min}} = r_{\\text{min}}, \\forall i \\in \\mathcal{I}$. In addition, we assume that there is no priority among users. Hence, we reasonably set $a_i = 1, \\forall i \\in \\mathcal{I}$. Simulation parameters are listed in detail in Table I."}, {"title": "A. Network Configurations", "content": "The dense NN with three hidden layers is adopted in the proposed CMTSSL algorithm, where each hidden layer con- tains a fully connected (FC) layer, a batch normalization layer and the ReLU active function. The three successive FC layers are set with 512, 1024, and 512 neural cells, respectively. As for the output layer of the deep dense NN in the proposed CMTSSL algorithm, we adopt the FC layer with the Sigmoid active function. Likewise, the same hidden layer architecture is also adopted in each local NN in the distributed DMTSSL algorithm. Note that, for the proposed CMTSSL algorithm and the proposed CMTSSL algorithm, the sizes of the input layer and output layer depend on the sizes of their input and output data. Adam optimizer [47] is used to update the parameters $\\Theta_c$ and $\\Theta_D$."}, {"title": "B. Baselines", "content": "To verify the superiority of the proposed self-supervised Loss Scheme 1 and Loss Scheme 2, we set following three loss baselines for comparisons:\n$\\begin{aligned}\nL_c (\\mathbf{y}, \\mathbf{H}) &= f (\\mathbf{y}, \\mathbf{H}) \\\\\nL_i (\\mathbf{y}, \\mathbf{H}) &=g_i (\\mathbf{y}, \\mathbf{H}), \\forall i \\in \\mathcal{I} \\\\\nL_b^2 (\\mathbf{y}) &=l_b (\\mathbf{y}), \\forall b \\in \\mathcal{B}\n\\end{aligned}$ (23)\n$\\begin{aligned}\nL_o (\\mathbf{y}, \\mathbf{H}) &= \\frac{-1}{f (\\mathbf{y}, \\mathbf{H})} \\\\\nL_i (\\mathbf{y}, \\mathbf{H}) &= \\frac{-1}{g_i (\\mathbf{y}, \\mathbf{H})}, \\forall i \\in \\mathcal{I} \\\\\nL_b^2 (\\mathbf{y}) &=L_{Huber} (l_b (\\mathbf{y})), \\forall b \\in \\mathcal{B}\n\\end{aligned}$ (24)\n$\\begin{aligned}\nL_o (\\mathbf{y}, \\mathbf{H}) &=e^{f (\\mathbf{y},\\mathbf{H})} \\\\\nL_i (\\mathbf{y}, \\mathbf{H}) &=e^{g_i (\\mathbf{y}, \\mathbf{H})}, \\forall i \\in \\mathcal{I} \\\\\nL_b^2 (\\mathbf{y}) &=L_{Huber} (l_b (\\mathbf{y})), \\forall b \\in \\mathcal{B}\n\\end{aligned}$ (25)"}, {"title": "V. CONCLUSION", "content": "In this paper, the joint SA and BF cross-layer resource allo- cation problem in the MEC-aided OFDMA CF-MIMO com- munication network is formulated to maximize the weighted sum rate while subjecting to the requirements of pre-user minimum tolerant data rate and pre-SBS maximum allowable transmitting power. We designed two novel and general self- supervised loss functions, i.e., NFL loss and EL loss, and pro- posed three learning algorithms, namely CMTSSL, DMTSSL, and DATL, to effectively solve the cross-layer resource al- location problem while avoiding the technical bottlenecks of traditional methods, e.g., the non-convexity, the complexity disaster and the NP-hard issue, as well as addressing some open challenges faced by the learning-based methods, e.g., the costly manual labeling, the dimension disaster for massive output, and the scalability limitations. The superior perfor- mance of the proposed algorithms compared to the baseline algorithms is confirmed by numerical simulations."}, {"title": "APPENDIX A", "content": "We can analyze the robustness of the designed loss func- tions, i.e., NFL loss and EL loss, by applying these losses to a general multi-class classification problem. Note that, a loss function L is robust to label noise if L is noice-tolerant to noisy labels [41]. For a general Z-class classification problem, we assume standard neural network architecture with softmax output layer and mean-absolute error residual calculation. If the network input is x, then the input of the softmax layer can be denoted as G (x). The softmax layer computes\n$u_z = \\frac{exp (G (x)_z)}{\\sum_{z=1}^Z exp (G(x)_z)}, z \\in \\{1,2,..., Z\\}$ (26)\n$\n$\\begin{aligned}\nR_L^\\prime(F) &= \\mathbb{E}_{x,\\hat{y}_x} [L(F(x), \\hat{y}_x)] \\\\\n&= \\mathbb{E}_{x} \\mathbb{E}_{\\hat{y}_x/x} [L(F(x), \\hat{y}_x)] \\\\\n&= \\mathbb{E}_{x} \\mathbb{E}_{\\hat{y}_x/x} [(1 - \\eta) L(F(x), y_x) + \\frac{\\eta}{Z - 1} \\sum_{j \\neq c} L(F(x), q_j)] \\\\\n&= (1 - \\frac{\\eta}{Z - 1}) \\mathbb{E}_{x, y_x} L(F(x), y_x) +  \\frac{\\eta}{Z - 1} \\mathbb{E}_{x, y_x} \\sum_{j \\neq c} L(F(x), q_j) \\\\\n&= (1 - \\frac{\\eta}{Z - 1}) R_L(F) +  \\frac{\\eta}{Z - 1} \\mathbb{E}_{x, y_x} \\sum_{j \\neq c} L(F(x), q_j) \\\\\n&= (1 - \\frac{\\eta}{Z - 1}) R_L(F) +  \\frac{\\eta}{Z - 1} \\sum_{j=1} \\mathbb{E}_{x, y_x} L(F(x), q_j) \\\\\n&= \\underbrace{(1 - \\frac{\\eta}{Z - 1}) R_L(F) +  \\frac{\\eta}{Z - 1} \\sum_{j=1}^{Z} [2(2 - \\frac{\\eta}{Z - 1}) - Z x_1] }_{C_{NFL}} \\text{\t , NFL} \\\\\n&= \\underbrace{(1 - \\frac{\\eta}{Z - 1}) R_L(F) +  \\frac{\\eta}{Z - 1} \\sum_{j=1}^{Z} [2(3 - \\frac{\\eta}{Z - 1}) - Z e^{\\chi_2}] }_{C_{EL}} \\text{\t , EL}.\n\\end{aligned}$"}]}