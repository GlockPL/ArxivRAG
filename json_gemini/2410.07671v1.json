{"title": "DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation", "authors": ["Xiaoshan Yu", "Chuan Qin", "Qi Zhang", "Chen Zhu", "Haiping Ma", "Xingyi Zhang", "Hengshu Zhu"], "abstract": "The rapid development of online recruitment platforms has created unprecedented opportunities for job seekers while concurrently posing the significant challenge of quickly and accurately pinpointing positions that align with their skills and preferences. Job recommendation systems have significantly alleviated the extensive search burden for job seekers by optimizing user engagement metrics, such as clicks and applications, thus achieving notable success. In recent years, a substantial amount of research has been devoted to developing effective job recommendation models, primarily focusing on text-matching based and behavior modeling based methods. While these approaches have realized impressive outcomes, it is imperative to note that research on the explainability of recruitment recommendations remains profoundly unexplored. To this end, in this paper, we propose DISCO, a hierarchical Disentanglement based Cognitive diagnosis framework, aimed at flexibly accommodating the underlying representation learning model for effective and interpretable job recommendations. Specifically, we first design a hierarchical representation disentangling module to explicitly mine the hierarchical skill-related factors implied in hidden representations of job seekers and jobs. Subsequently, we propose level-aware association modeling to enhance information communication and robust representation learning both inter- and intra-level, which consists of the inter-level knowledge influence module and the level-wise contrastive learning. Finally, we devise an interaction diagnosis module incorporating a neural diagnosis function for effectively modeling the multi-level recruitment interaction process between job seekers and jobs, which introduces the cognitive measurement theory. Extensive experiments on two real-world recruitment recommendation datasets and an educational recommendation dataset clearly demonstrate the effectiveness and interpretability of our proposed DISCO framework. Our codes are available at https://github.com/LabyrinthineLeo/DISCO.", "sections": [{"title": "I. INTRODUCTION", "content": "With the rapid development of Internet technology, various online recruitment platforms have emerged and become prevalent, such as LinkedIn and Glassdoor, which have significantly revolutionized the job-seeking process by establishing a digital bridge between job seekers and potential employers worldwide [1], [2]. Under this online paradigm of recruitment, it is crucial to develop a trustworthy job recommender system capable of accurately suggesting positions that align with job seekers' preferences and capabilities, which can assist them in efficiently finding the most suitable and credible positions [3].\nIn the literature, there are many recent studies dominated by text-matching based methods [4], [5], these job recommender systems parsed through vast textual data from resumes and job postings to identify matches based on textual similarity [6]\u2013[8], offering tailored job suggestions to users. In recent years, another category of interaction behavior based job recommendation methods [9]\u2013[13] has received increasing research attention, which mainly explores users' personalized preferences and intentions by modeling the interaction behaviors between job seekers and recruiters. For example, DPGNN [9] introduces a dual-perspective graph representation learning framework, specifically designed to model the directed inter-"}, {"title": "actions", "content": "(such as job application and resume review) between job seekers and recruiters. However, previous approaches have markedly enhanced the recommendation performance primarily by using end-to-end network models, there remains a notable deficiency in exploring the interpretability, particularly regarding the explainable abilities of job seekers and the variances in job requirements. As shown in Figure 1, the job seeker c is presented with two positions (i.e., j1 and j2) by the recommender system that appears indistinguishable in terms of skills (indeed the two are extremely different with respect to the competencies matched to this user), which is a common issue in traditional job recommendation approaches. The lack of reasons for recommendations often makes it difficult for users to choose from recommendations, and they are more susceptible to position bias, ignoring the match between personal abilities and the needs of the position. This kind of recommender system may lead job seekers to pursue positions misaligned with their abilities or career aspirations, hindering their job search success.\nTo this end, in this paper, we propose a hierarchical Disentanglement based Cognitive diagnosis framework (DISCO), aimed at flexibly accommodating the underlying representation learning model for effective and interpretable job recommendations. DISCO re-examines the recruitment recommendation process from a hierarchical disentanglement based cognitive diagnosis perspective, i.e., by viewing the process of job seekers interacting with the recruiter of the positions in the job search process as the process of exercise-solving by the learner [14]\u2013[17]. Such a modeling approach facilitates the evaluation of the diverse skill demands of various job positions within the labor market and the current competitive standing of candidates. As illustrated in Figure 1, the competency level of candidate c is explicitly depicted, alongside the skill requirement of jobs j1 and j2. This enhanced clarity enables candidates to better understand the differences in skill demands between various positions, allowing them to align their applications more precisely with jobs that match their capabilities and professional aspirations.\nHowever, this task is non-trivial and presents several crucial technical challenges: (1) How to map representations of users and jobs to specific skill dimensions to obtain interpretable content with tangible meanings? Indeed, existing text-based and behavioral modeling job recommendation methods are primarily designed to learn effective representation vectors, which are high-order and abstract, failing to provide employers and job seekers with intuitive information, such as the degree of specificity of a job's skill requirements. (2) How to hierarchize the competency level of candidates and the degree of skill required for jobs? In recruitment interactions, the skills required for a job are usually multi-granular, and similarly, the level of competence possessed by job seekers is often hierarchical. Modeling these aspects in a coarse-grained manner fails to effectively capture their intrinsic characteristics. (3) How to mitigate instability caused by interaction bias during the job search process? In real-world scenarios, the interaction between job seekers and jobs during the job search process"}, {"title": "can be influenced", "content": "by various biases, such as cognitive bias and popularity bias, which often leads to unstable profiling of the job seekers' abilities and job requirements.\nTo address these challenges, we initially developed a hierarchical representation disentangling module to effectively extract and clarify the hierarchical skill-related factors embedded in the hidden representations of job seekers and jobs. Subsequently, we design a level-aware self-attention network to explore the intrinsic associations between inter-level skill prototypes. Following that, a noise perturbation based level-wise contrastive module is proposed to enhance the robust representation learning. Finally, we devise an interaction diagnosis module is introduced that integrates a neural diagnosis function, aimed at effectively capturing the multi-level recruitment interaction process between job seekers and jobs. This module incorporates the cognitive measurement theory to enhance its explainability. Extensive experiments on two real-world recruitment recommendation datasets and an educational recommendation dataset clearly demonstrate the effectiveness and interpretability of the proposed DISCO framework in the job recommendation task."}, {"title": "II. RELATED WORK", "content": "With the burgeoning of online recruitment platforms, job recommendation [18]\u2013[21] has emerged as a pivotal task and garnered extensive research attention, attributable to its potential to accurately match job seekers with suitable job positions. Existing job recommendation approaches are mainly classified into two categories, respectively, text-matching based methods and interaction behavior based methods. The first category of methods [4], [5], [22] focuses on matching the textual content of the applicants' resumes and job descriptions by utilizing text-matching strategies or text enhancement techniques [23], [24], so as to predict the suitability of both. For example, APJFNN [4] employs a RNN to acquire word-level semantic representations and designs a hierarchical ability-aware attention strategy to measure the matching degree. Another category of methods [9], [10] mainly explores users' personalized preferences and intentions by modeling the interaction behaviors between person (job seekers) and jobs (recruiters). For instance, SHPJF [10] explicitly models the users' search histories in addition to learning semantic information from text content for comprehensive mining of underlying job intents. Despite the impressive outcomes achieved by these methods, a significant shortfall is evident in the interpretable exploration of matching job seekers with job positions."}, {"title": "B. Cognitive Diagnosis", "content": "Cognitive diagnosis (CD) [25], [26] is a classical methodology for assessing ability in educational psychology, aimed at portraying learners' proficiency profile by analyzing their learning behaviors [27], [28]. Over the past decades, numerous effective CD models have been developed. Within these, traditional psychometric-based CD approaches hold a crucial role, being designed on the basis of psychological theories to depict student knowledge state through latent factors [25], [29]. For instance, The Deterministic Inputs, Noisy And gate (DINA) [29] model characterizes each student with a binary vector that indicates mastery of the knowledge concepts associated with the exercises, requiring all relevant skills for the highest positive response probability. In recent years, the swift development of deep learning has propelled neural network (NN)-based CD approaches [30]\u2013[32] to the forefront. These methods effectively diagnose learners' mastery attributes by incorporating neural networks to model complex interactions among learning elements (e.g., students, exercises, and knowledge concepts). For example, NeuralCD [30], a notable neural CDM, employs multidimensional parameters for detailed depiction of students' knowledge level and exercise attributes, and incorporates MLP to model complex interactions between students and exercises. RDGT [31] proposes an effective group cognitive diagnosis method by designing a relation-guided dual-side graph transformer model to mine potential associations both between learners and between exercises. However, a gap remains in the skillful application of cognitive diagnostics to effectively model the job recommendation task."}, {"title": "C. Disentangled Learning", "content": "Disentangled learning aims to identify and disentangle the underlying explanatory factors of the observed complicated data, enhancing the efficiency and interpretability of the model in the learning process [33], [34]. Initially, disentangled learning received extensive research attention in the field of computer vision due to its effectiveness [34]. Recently, a variety of approaches have introduced disentangled learning to model graph-structured data [35], [36]. For instance, DGCL [36] employs contrastive learning to uncover latent factors within the graph and subsequently extracts disentangled representations of the graph. DisenGCN [35] proposes a unique neighborhood routing mechanism for disentangling node representation in graph networks, enabling dynamic identification of latent factors and improved performance in complex data scenarios. Moreover, learning disentangled representations of user latent intents from interaction feedback has been a popular topic in the recommendation domain [37]\u2013[39]. For example, Macrid-VAE [37] proposes a macro-micro disentangled variational auto-encoder to learn disentangled representations based on user behavior across multiple geometric spaces. However, learning disentangled competency representations of applicants in the cognitive diagnostic perspective is unexplored."}, {"title": "III. PRELIMINARIES", "content": "In this section, we introduce the problem definition of job recommendation. Let $C = \\{c_1, c_2,...,c_N\\}$ be the set of N job seekers, $I = \\{j_1, j_2,...,j_M\\}$ be the set of M jobs, $S = \\bigcup_{l=1}^{L} S_l$ be the set of K skills with L different granularity levels, where $S_L$ is the atomic skill level and $K = \\sum_{l=1}^{L} \\delta_l$. Each job seeker and job are associated with textual documents describing the resumes and the job requirements. The relationship between jobs and skills is represented by a Q-matrix $Q = \\{q_{uv}\\}_{M\\times K}$, where $q_{uv} = 1$ if job $j_u$ requires skill"}, {"title": "$s_v$ and", "content": "0 otherwise. Besides, the interaction matrix between the job seekers and jobs is denoted as $R = \\{r_{uv}\\}_{N\\times M}$, where $r_{uv} \\in \\{0,1,2,3\\}$ corresponds to the four kinds of interaction behaviors between the candidate $c_u$ and the job $j_v$, i.e., Browse, Click, Chat and Match, respectively, and they reflect different levels of matching. Particularly, $r_{uv} = 3$ means both the job seeker and the recruiter are satisfied with each other and this pair is matched.\nIn this paper, our goal is to recommend the appropriate jobs to job seekers. To achieve this, we aim to predict the compatibility between jobs and candidates by learning a matching function $f(c_u, j_v)$ based on the interaction records $R$, the relationship matrix between jobs and skills $Q$, and the documents describing the resume and job requirements, and then realize the top-K job recommendation based on the predicted degree of matching between candidates and jobs."}, {"title": "B. Base Embedding Model", "content": "The goal of DISCO is primarily to efficiently and interpretably model the interaction patterns between users and jobs, thus enabling a flexible framework applicable to existing representation learning recommendation models. In this section, we mainly introduce the base embedding model to output embedding representations of users and jobs. Specifically, the base embedding model $M(C,J,R)$ aims to encode job seekers $C$ and jobs $J$ with d-dimensional trainable matrices $C\\in\\mathbb{R}^{N\\times d}$ and $J\\in \\mathbb{R}^{M\\times d}$, respectively. Here N and M are the numbers of job seekers and jobs in the recruitment interaction records, respectively, and d is the embedding dimension. Notably, the process of acquiring embedding representations: $M(C, J, R) \\rightarrow (C, J)$, varies across different base models (as shown in the left part of Figure 2), with the essential purpose being to learn effective high-dimensional characterizations. Specifically, we deploy MF [40] to consider collaborative information, NGCF/LightGCN [41], [42] to extract higher-order connectivity, and DPGNN [9] to embed textual content. Here, we take the example of NGCF [41], which utilizes the user-item interaction graph to propagate high-order information and thus achieve embedding learning:\n$c_u^{(k+1)} = \\sigma(W_1 c_u^{(k)} + \\sum_{j_l\\in N_u} \\frac{1}{\\sqrt{|N_u||N_l|}}(W_1 j_l^{(k)} + W_2 (j_l^{(k)} \\odot c_u^{(k)})))$,\n$j_l^{(k+1)} = \\sigma(W_1 j_l^{(k)} + \\sum_{c_u\\in N_l} \\frac{1}{\\sqrt{|N_u||N_l|}}(W_1 c_u^{(k)} + W_2 (c_u^{(k)} \\odot j_l^{(k)})))$,\nwhere $c_u^{(k)}$ and $j_l^{(k)}$ are the refined embedding of user $c_u$ and item $j_l$ after k layers propagation, respectively, $\\sigma$ denotes the nonlinear activation function, $\\odot$ refers to the element-wise multiply operator, $N_u$ and $N_l$ respectively represent the set of items interacted by user $c_u$ and the set of users interacted by item $j_l$, and $W_1$ and $W_2$ are trainable weight matrix to conduct feature transformation in each layer. Finally, the representations of all the layers are concatenated to obtain the output embeddings, i.e., $c_u = \\|_{l=0}^{L}c_u^{(l)}$ and $j_l = \\|_{l=0}^{L}j_l^{(l)}$, where $c_u \\in C$, $j_l \\in J$, and $||$ denotes the concatenation operation."}, {"title": "IV. METHODOLOGY", "content": "In this section, we present the DISCO framework in detail. As illustrated in Figure 2, the architecture of DISCO consists of four main components, including the hierarchical skill-aware representation disentangling, the level-aware self-attention network, level-wise contrastive learning, and the interaction diagnosis module."}, {"title": "A. Hierarchical Representation Disentangling", "content": "In the job recommendation task, the main goal is to predict the matching degree between a job seeker and a job given their observed interactions. During the real recruitment process, when a candidate interacts with a job, the outcome is often influenced by skill-related factors, such as the candidate's level of skill mastery and the difficulty of the skills required by the job [43]. To capture these skill factors, we formally define our prediction objective about job seeker-job matching as follows:\n$P_{\\theta}(y|X) = E_{P_{\\theta}(z_c|X)P_{\\theta}(z_j|X)}[P_{\\theta}(y|X, z_c, z_j)]$,\nwhere $X = (c_u, j_v, S_{j_u})$ denotes the candidate, the job, and the skills involved in the job description, respectively, y is the learned matching score. Hence the optimization objective of the predictive model is as follows:\n$\\theta^* = \\arg \\max_{\\theta} \\log P_{\\theta}(y_i|X_i)$,\n$\\theta^* = \\arg \\min_{\\theta} \\sum_{i=1}^{|R|} -\\log E_{P_{\\theta}(z_c|X_i)P_{\\theta}(z_j|X_i)} [P_{\\theta} (y_i | X_i, z_c, z_j)]$,\nwhere $|R|$ denotes the number of observed samples, and $z_c$ and $z_j$ are the skill factors for candidates and jobs, respectively. We use $g(\\cdot)$ to denote the prediction function over the encoded skill factors. Referring to previous work [44], we approximate our prediction objective as follows:\n$E_{P_{\\theta}(z_c|X_i)P_{\\theta}(z_j|X_i)}[g(z_c, z_j)] \\approx g(E_{P_{\\theta}(z_c|X_i)} [z_c], E_{P_{\\theta}(z_j|X_i)}[z_j])$.\nConsidering the above inference, the approximation error can be effectively constrained within our prediction function $g(\\cdot)$."}, {"title": "2) Hierarchical Skill-Aware Disentangling", "content": "In the recruitment recommendation process, skill-related factors (e.g., skill proficiency and skill demand) are the primary determinants of the interaction outcome between the job seeker and the job position [18]. Explicitly disentangling these factors from the embedding representations of the candidates and the jobs is quite important, which facilitates understanding of the job seeker's mastery of the skill and the job's requirement of the skill, thus enhancing interpretability. Indeed, the skills involved in a job may be at different levels of granularity [43], which tend to encompass relationships (as shown in Figure 2). Towards this end, we propose to disentangle hierarchical skill characteristics from the high-dimensional and abstract representations of users and jobs that incorporate interaction information. Specifically, for the embeddings $c_u \\in C$ and $j_l \\in J$ of user $c_u$ and job $j_l$ obtained from the base model (as mentioned before), we first construct L-layer mappers to project them into different hierarchical skill spaces, respectively, as follows:\n$c_{u,l}^h = c_u W_u^l, j_{l,v}^h = j_v W_v^l, 1 \\leq l \\leq L$,\nwhere $c_{u,l}^h\\in \\mathbb{R}^{d_h}$ and $j_{l,v}^h \\in \\mathbb{R}^{d_h}$ denotes the mapped hidden representations of user $c_u$ and job $j_v$ at l-th skill layer, respectively, $W_u^l, W_v^l \\in \\mathbb{R}^{d\\times d_h}$ are the trainable matrices, and $d_h$ is the hidden dimension. Here, L represents the number of skill layers at different levels of granularity, which is a fixed parameter that comes with the dataset (as mentioned in Section 3.1). Subsequently, we build multi-level encoders for users and jobs respectively to learn L ability prototypes $\\{c_{u,l}^a\\in \\mathbb{R}^{d_h}\\}_{l=1}^L$ and L skill difficulty prototypes $\\{j_{l,v}^a\\in \\mathbb{R}^{d_h}\\}_{l=1}^L$ for the hierarchical skill space as follows:\n$c_{u,l}^a = Encoder_l^c(c_{u,l}^h), j_{l,v}^a = Encoder_l^j(j_{l,v}^h), 1 \\leq l \\leq L$,\nwhere $Encoder_l^c$ and $Encoder_l^j$ denote the l-th layer disentangled encoder for the users and jobs, respectively. Similar to previous work [36], a multilayer perceptron network (MLP) is used here. Notably, our goal is to disentangle the various levels of competencies possessed by job seekers as well as the distinct tiers of skill levels required by job positions. In particular, $d_h = |S_L|$ denotes the number of atomic skills, thereby facilitating the explicit alignment of the dimensions of both representation vectors with the skill size."}, {"title": "B. Level-Aware Association Modeling", "content": "While it is desirable for the disentangled prototypes to effectively characterize users and jobs at different skill levels, in reality, these inter-level skill representations are often influenced by underlying knowledge. For example, a job seeker's mastery of the coarse-grained skills is usually affected by their proficiency in finer-grained skills, and conversely, the same principle applies. To further explore the intrinsic associations between inter-level skill prototypes, we design a level-aware self-attention network for enhancing learning as follows:\n$\\hat{c}_{u,l} = SelfAtt(Q^c, K^c, V^c)$,\n$Q^c = c_{u,l}^a, K^c = \\{c_{u,1}^a,........, c_{u,L}^a\\}, V^c = \\{j_{1,v}^a, \u00b7\u00b7\u00b7, j_{L,v}^a\\}$,\n$\\hat{j}_{l,v} = SelfAtt(Q^j, K^j, V^j)$,\n$Q^j = j_{l,v}^a, K^j = \\{j_{1,v}^a, \u00b7\u00b7\u00b7, j_{L,v}^a\\}, V^j = \\{c_{u,1}^a,........, c_{u,L}^a\\}$.\nwhere $\\hat{c}_{u,l}$ \u2208 $\\mathbb{R}^{d_h}$ are enhanced l-level skill aware representations incorporating correlated information, $Q^c,K^c,V^c$ and $Q^j,K^j,V^j$ denote the query, key and value vectors for the user and job, respectively, and $SelfAtt(\u00b7)$ indicate the Self-Attention module [45]."}, {"title": "2) Level-Wise Contrastive Learning", "content": "In real-world scenarios, the interaction between job seekers and jobs during the job search process can be influenced by various biases [5], [46], such as cognitive bias and popularity bias. This often leads to unstable profiling of the job seekers' abilities and the job's requirements, particularly in the context of disentangled representations, resulting in sub-optimal performance as well as inaccurate interpretations. Taking inspiration from recent developments in contrastive learning, we attempt to enhance the robustness of skill-aware disentangled representations by exploring self-supervised signals. Different from previous work that constructs contrastive tasks from instance dimensions [44], we propose a level-wise contrastive learning for modeling between skill representations at different granularities. Specifically, we formalize the level-wise contrastive learning loss (from the job seeker side) as follows:\n$\\mathcal{L}_{CL} = \\frac{1}{C}\\frac{1}{L} \\sum_{u=1}^{C} \\sum_{l=1}^{L} -\\log p_{\\theta}(\\hat{c}_{u,l} | \\hat{c}_{u,l}^+, z_{c,l})$,\nwhere $p_{\\theta}(\\hat{c}_{u,l} | \\hat{c}_{u,l}^+, z_{c,l})$ denotes the candidate ability contrastive learning subtask under l-th skill level, and $z_{c,l}$ is the l-th level latent skill factor of the job seeker (i.e., ability). We aim to learn the optimal L ability prototypes which are able to maximize the expectation of L subtasks, and the contrastive learning subtask for the l-level ability is defined as follows:\n$p_{\\theta}(\\hat{c}_{u,l} | \\hat{c}_{u,l}^+, z_{c,l}) = \\frac{exp(\\phi(\\hat{c}_{u,l}, \\hat{c}_{u,l}^+)/\\tau)}{\\sum_{v=1}^{C} exp(\\phi(\\hat{c}_{u,l}, \\hat{c}_{v,l}^+)/\\tau)}$,\nwhere $\\hat{c}_{u,l}$ and $\\hat{c}_{u,l}^+$ are the user positive pair of the l-level ability, $\\tau$ is a temperature parameter, $\\phi(\\cdot)$ denotes the similarity function, and we use the cosine similarity function here:\n$\\phi(\\hat{c}_{u,l}, \\hat{c}_{v,l}^+) = \\frac{\\hat{c}_{u,l}\\hat{c}_{v,l}^+}{\\|\\hat{c}_{u,l}\\|_2 \\|\\hat{c}_{v,l}^+\\|_2}$.\nIn particular, $\\hat{c}_{u,l}^+$ here is the augmented l-level ability representation of the job seeker $c_u$. Inspired by [47], we implement an efficient and effective skill-level augmentation by directly adding random noises to the ability representation as follows:\n$\\hat{c}_{u,l}^+ = \\hat{c}_{u,l} + \\Delta_{u,l}$"}, {"content": "where the added noise vectors $\\Delta_{u,l}$ is subject to $\\|\\Delta_{u,l}\\|_2 = \\epsilon$ and $\\Delta = \\Delta \\odot sign(\\hat{c}_{u,l}), \\Delta \\in \\mathbb{R}^{d_h} \\sim U(0, 1)$, and $sign(\\cdot)$ denotes the sign function and $U(0, 1)$ represents the uniform distribution. The first constraint regulates the magnitude of $\\Delta$, which is numerically akin to coordinates on a hypersphere with the radius $\\epsilon$. The second constraint ensures that $\\hat{c}_{u,l}$ and $\\Delta_{u,l}$, remain within the same hyperoctant to avoid significant deviations in $\\hat{c}_{u,l}^+$ when noise is added, thereby maintaining the validity of positive samples. Notably, the modeling process for the job side is the same as above."}, {"title": "C. Interaction Diagnosis Module", "content": "In this section, we present an interaction diagnosis module designed to model the nuanced interactions between job seekers and jobs at multiple granularity skill levels from a cognitive measurement perspective by introducing cognitive diagnosis theory [25], [48], [49].\nIndeed, in cognitive diagnosis assessments [29], [30], the key research focus is how to effectively measure a tester's ability level by modeling their ability representations against the difficulty representations of exercises across different knowledge concepts. In our DISCO framework, the already disentangled multi-level skill characteristics of job seekers and jobs, which are explicitly mapped to skill dimensions, facilitate the interaction modeling using diagnosis functions. Similar to [30], we adopt the neural diagnosis function in our framework. It can seamlessly integrate with non-linear neural network layers, and its capability to model high-dimensional interactive elements enables the acquisition of extensive knowledge and the presentation of interpretable information. It is formalized as follows (taking as an example the disentangled l-level skill representations of $c_u$ and $j_v$):\n$T(\\hat{c}_{u,l}, \\hat{j}_{l,v}) = \\Omega (\\sigma(Q_l \\odot \\hat{c}_{u,l}) - \\sigma(\\hat{j}_{l,v} \\odot Q_l))$,\nwhere the $\\hat{c}_{u,l} \\in \\mathbb{R}^{d_h}$ and $\\hat{j}_{l,v} \\in \\mathbb{R}^{d_h}$ denote the l-level skill representations of the job seeker $c_u$ and the job $j_v$, respectively (mentioned above), $\\sigma(\\cdot)$ is the activation function (here is the Sigmoid function), $\\odot$ refers to the element-wise multiply operator, and $Q_l$ indicates the skill attribute corresponding to $j_v$ originates from the Q-matrix Q. Thus, we obtain the matching distance in the l-level skill space between $c_u$ and $j_v$: $h_{u,v}^l = T (\\hat{c}_{u,l}, \\hat{j}_{l,v}) \\in \\mathbb{R}^{d_h}$, which reflects the degree of matching between the two at the l-th skill level from a diagnosis perspective."}, {"title": "2) Hierarchical Diagnosis Prediction", "content": "To further aggregate the hierarchical competency matching distances between candidates and jobs and assess them comprehensively, we conduct a hierarchical diagnostic prediction. Specifically, we first concatenate the obtained L-layer matching distance representations as follows:\n$h_{u,v} = \\|_{l=1}^{L} h_{u,v}^l$\nwhere $||$ denotes the concatenation operation, and $h_{u,v} \\in \\mathbb{R}^{L\\cdot d_h}$ is the aggregated interaction vector, which serves to comprehensively account for the hierarchical effects of different skill levels. Subsequently, we utilize the full connection layers to model the high-order interaction features, as follows:\n$\\tilde{h}_{u,v} = \\sigma(h_{u,v}W_1 + b_1)$,\n$y_{u,v} = \\sigma(\\tilde{h}_{u,v}W_2 + b_2)$,\nwhere $W_1 \\in \\mathbb{R}^{L\\cdot d_h\\times d_h}, b_1 \\in \\mathbb{R}^{d_h}, W_2 \\in \\mathbb{R}^{d_h\\times dels}$ and $b_2 \\in \\mathbb{R}^{dels}$ are trainable parameters, $d_h$ and $dels$ are the hidden dimensions and the number of interaction categories, and $y_{u,v}$ denotes the predicted probabilities of the different interaction categories between job seeker $c_u$ and job $j_v$."}, {"title": "3) Loss Function", "content": "In the training phase, we update the model parameters mainly by predicting the job seeker-job interaction categories. Specifically, for each interaction record $(c_u, j_v, r_{uv})$, we utilize the multi-class cross-entropy loss function for the prediction:\n$\\mathcal{L}_{main} = \\frac{1}{|R|} \\sum_{(c_u, j_v, r_{u,v}) \\in R} \\sum_{i=1}^{dels} r_{u,v, i} \\log y_{u,v, i}$,\nwhere $dels$ is the number of interaction categories. It is worth noting that $r_{u,v} \\in \\{0,1\\}^{dels}$ is a category-dependent one-hot vector originating from $r_{uv}$. To optimize the self-supervised subtask, we construct the complete contrastive learning loss as follows:\n$\\mathcal{L} = \\mathcal{L}_{CL} + \\mathcal{L}_{OL}$.\nFinally, we obtain the complete optimization objective function by summing the loss functions of the above two objectives:\n$\\mathcal{L} = \\mathcal{L}_{main} + \\lambda \\cdot \\mathcal{L}_{cl}$,\nwhere $\\lambda$ is the weight coefficient to control the influence of contrastive signals. We can then train the whole model and optimize the model parameters utilizing gradient descent."}, {"title": "V. EXPERIMENTS", "content": "In this section, we conduct extensive experiments on three real-world datasets to validate the effectiveness and interpretability of the proposed DISCO framework."}, {"title": "A. Experiment Setups", "content": "In this paper, the real-world job recommendation datasets utilized for experiments were provided by an online recruitment platform. Specifically, it contains four kinds of behaviors: Browse, Click, Chat and Match. The behavior Match is considered as the positive sample otherwise the negative sample (as mentioned in Section 3). To ensure reasonableness, we filtered out the job seekers with fewer than ten Match interaction logs and jobs with fewer than five records. In particular, the dataset does not contain any sensitive information, and all IDs have been remapped by the provider to ensure they do not correspond to the original identifiers from the platform. Since the size of the entire interaction data is extremely tremendous, we selected two subsets based on the taxonomy of career clusters for our experiments: technology and service. In addition, to verify the availability and generalization of our model for other recommendation tasks, we also specifically selected a public educational dataset Edu-Rec [50] for our experiments. For each dataset, we randomly split the job seeker-job position interaction data into three parts in the ratio of 7:1:2, serving as the training set, validation set, and testing set, respectively. The detailed statistical information is shown in Table I."}, {"title": "2) Baseline Approaches", "content": "Four widely used recommendation methods for basic representation learning are selected as the base models to obtain the representations of job seekers and job positions: MF [40], NGCF [41], LightGCN [42], and DPGNN [9]. To evaluate the effectiveness of interaction modeling between job seekers and job positions, we incorporate three different interaction modeling methods into these base models, thereby constructing the complete baselines: NCF [51], AutoInt [52] and FINAL [53]. In addition, we also select two state-of-the-art methods SHPJF [10], and ECF [54] for job recommendation and interpretable recommendation, respectively, to further validate the superiority of our DISCO."}, {"title": "3) Evaluation Protocols and Implementation Details", "content": "To evaluate the performance of DISCO and all baseline methods, we employ three widely used metrics including the Area Under the ROC Curve (AUC), Hit Ratio (HR@k) and Normalized Discounted Cumulative Gain (NDCG@k). We empirically set k to 5 and 10, and utilize these metrics to do the evaluation for the job recommendation task, i.e., predicting the matching probability and ranking jobs for candidates, which is more in line with the real online recruitment scenarios. Specifically, for each positive instance, we randomly sample 25 jobs for candidates as negative instances.\nWe implemented all models with Pytorch by Python and conducted our experiments on a Linux server with eight Nvidia A800 GPUs. We conducted each of the experiments 5 times and used the average value as the final result. The t-test was used to identify the significant differences between the performances of DISCO and the baselines. To perform the training process, we initialized all network parameters with Xavier initialization. Each parameter is sampled from U( - $\\sqrt{2/(n_{in} + N_{out})}$, $\\sqrt{2/(n_{in} + n_{out})}$), where $n_{in}$ and $N_{out}$ denote the numbers of neurons feeding in and feeding out, respectively. The dimension size of hidden representations (i.e., d and $d_h$) was set as 256. We use the Adam optimizer, where the learning rate was searched in {5e-5, 8e-5, 1e"}]}