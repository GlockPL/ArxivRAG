{"title": "FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification", "authors": ["Yu Tian", "Congcong Wen", "Min Shi", "Muhammad Muneeb Afzal", "Hao Huang", "Muhammad Osama Khan", "Yan Luo", "Yi Fang", "Mengyu Wang"], "abstract": "Addressing fairness in artificial intelligence (AI), particularly in medical AI, is crucial for ensuring equitable healthcare outcomes. Recent efforts to enhance fairness have introduced new methodologies and datasets in medical AI. However, the fairness issue under the setting of domain transfer is almost unexplored, while it is common that clinics rely on different imaging technologies (e.g., different retinal imaging modalities) for patient diagnosis. This paper presents FairDomain, a pioneering systemic study into algorithmic fairness under domain shifts, employing state-of-the-art domain adaptation (DA) and generalization (DG) algorithms for both medical segmentation and classification tasks to understand how biases are transferred between different domains. We also introduce a novel plug-and-play fair identity attention (FIA) module that adapts to various DA and DG algorithms to improve fairness by using self-attention to adjust feature importance based on demographic attributes. Additionally, we curate the first fairness-focused dataset with two paired imaging modalities for the same patient cohort on medical segmentation and classification tasks, to rigorously assess fairness in domain-shift scenarios. Excluding the confounding impact of demographic distribution variation between source and target domains will allow clearer quantification of the performance of domain transfer models. Our extensive evaluations reveal that the proposed FIA significantly enhances both model performance accounted for fairness across all domain shift settings (i.e., DA and DG) with respect to different demographics, which outperforms existing methods on both segmentation and classification. The code and data can be accessed at https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k.", "sections": [{"title": "1 Introduction", "content": "Advancements in deep learning have revolutionized the field of medical imaging, enabling significant improvements in tasks such as classification [9\u201311, 32, 33, 62-65,67,74] and segmentation [7,30,34, 34, 66, 76, 89]. These technologies have the potential to enhance diagnostic accuracy, streamline treatment planning, and ultimately improve patient outcomes. Despite these advancements, the deployment of deep learning models across varied healthcare settings has unearthed a pivotal challenge: the risk of inherent algorithmic bias and discrimination against certain demographic groups, which could undermine the fairness of medical diagnostics and treatments.\nRecent studies have begun to address the issues of algorithmic biases in medical imaging by developing methodologies aimed at enhancing the fairness of deep learning models [4,14, 23, 24, 26, 27, 36-38, 44, 58, 61,68,78,86,90]. These methodologies, while pioneering, commonly presuppose that the distribution of data during training and testing remains constant, thereby assuming that fairness measures implemented during training will suffice to ensure equitable decisions during testing within identical domains. This presumption, however,\nfrequently does not hold in practical healthcare scenarios. For instance, primary care clinics and specialty hospitals may rely on different imaging technologies (e.g., different retinal imaging modalities) for patient diagnosis, leading to signifi-\ncant domain shifts that can adversely affect model performance and fairness when models trained on one type of imaging data are deployed on another.\nTherefore, it is critical to account for domain shifts and learn fair models that are robust to potential cross-domain scenarios in real-world deployment environments.\nThe previous literature extensively explores domain adaptation and domain generalization as methodologies to counteract the challenges posed by domain shifts, aiming to develop models that perform reliably across diverse but related domains. Domain adaptation, particularly in its unsupervised form, leverages both labeled data from a source domain and unlabeled data from a target domain to facilitate model generalization to new, unseen data [87]. Conversely, domain"}, {"title": "2 Related Work", "content": "Domain Adaptation and Generalization: Unsupervised Domain Adaptation (UDA) leverages unlabeled target data has become essential, with adversarial learning [12,21,70,71] and self-supervised training [42,92] standing out as principal strategies to harmonize feature distributions across different domains. These"}, {"title": "3 Dataset Analysis", "content": "Data Collection and Quality Control. Our institute's institutional review board (IRB) approved this study, which followed the principles of the Declaration of Helsinki. Since the study was retrospective, the IRB waived the requirement for informed consent from patients.\nThe subjects tested between 2010 and 2021 are from a large academic eye hospital of Harvard Medical School. Two cross-domain tasks, namely medical segmentation and classification, are studied in this work. For medical segmentation, there are five types of data: (1) En-face fundus imaging scans; (2) SLO fundus imaging scans; (3) patient demographics; (4) glaucoma diagnosis; and (5) cup-disc masks. Particularly, the pixel annotations of cup and disc regions are first acquired from the OCT machine, where the disc border in 3D OCT is segmented\nas the Bruch's membrane opening by the OCT manufacturer software, and the cup border is detected as the intersection between the inner limiting membrane (ILM) and the plane that results in minimum surface area from the intersection and disc border on the plane [16, 45]. Approximately, the cup border can be considered as the closest location on the ILM to the disc border, which is defined as the Bruch's membrane opening. Both Bruch's membrane opening and the internal limiting membrane can be easily segmented due to the high contrast between them and the background. Since the OCT manufacturer software leverages 3D information, the cup and disc segmentation is generally reliable. Given the limited availability and high cost of OCT machines in primary care, we propose a method to transfer annotations from 3D OCT to 2D SLO fundus images, aiming to enhance early-stage glaucoma screening. By utilizing the registration tool NiftyReg [46], we accurately align SLO fundus images with OCT-derived pixel-wise annotations, generating a vast set of high-quality SLO fundus mask annotations. This process, verified by a panel of medical experts, shows an 80% success rate in registrations, streamlining the annotation process for broader applications in primary care settings. Upon the alignment and manual examination of those annotations, we leverage pixel-wise masks from both the SLO and En face fundus images to examine the transfer of algorithmic fairness in segmentation models under domain shifts.\nFor medical classification, there are four types of data: (1) En-face fundus imaging scans; (2) SLO fundus imaging scans; (3) patient demographics; (4) glaucoma diagnosis. The subjects in the medical classification dataset are categorized into two classes including normal and glaucoma defined based on visual field tests.\nData Characteristics. The medical segmentation dataset contains 10,000 samp-les from 10,000 subjects. We divide our data into the training set with 8,000 samples, and the test set with 2,000 samples. The patient age average is 60.3 \u00b1 16.5 years. Within this dataset, we have six demographic attributes including age, gender, race, ethnicity, preferred language, and marital status. The demogra-phic distributions are as follows: Gender: Female: 58.5%, and Male: 41.5%;\nRace: Asian: 9.2%, Black: 14.7%, and White: 76.1%. Ethnicity: Non-Hispanic:\n90.6%, Hispanics: 3.7%, and Unknown: 5.7%. Preferred Language: English:\n92.4%, Spanish: 1.5%, Others: 1%, and Unknown: 5.1%. Marital Status: Married\nor Partnered: 57.7%, Single: 27.1%, Divorced: 6.8%, Legally Separated: 0.8%,\nWindowed: 5.2%, and Unknown: 2.4%.\nSimilarly, the medical classification dataset contains 10,000 samples from 10,000 subjects with an average age of 60.9 \u00b1 16.1 years. We divide our data into the training set with 8,000 samples, and the test set with 2,000 samples. Within this dataset, we have six demographic attributes including age, gender, race, ethnicity, preferred language, and marital status. The demographic distributions are as follows: Gender: Female: 72.5%, and Male: 27.5%; Race: Asian: 8.7%,\nBlack: 14.5%, and White: 76.8%. Ethnicity: Non-Hispanic: 96.0%, Hispanics: 4.0%. Preferred Language: English: 92.6%, Spanish: 1.7%, Others: 3.6%, and\nUnknown: 2.1%. Marital Status: Married or Partnered: 58.5%, Singe: 26.1%,\nDivorced: 6.9%, Legally Separated: 0.8%, Windowed: 1.9%, and Unknown: 5.8%."}, {"title": "4 Method", "content": "4.1 Problem Statement\nDomain Adaptation (DA) and Domain Generalization (DG) are pivotal techniqu-es in the development of machine learning models, aimed at addressing the variability that can occur when a model trained in one specific domain is applied to another. In the field of medical imaging, the techniques of DA and DG are critical in creating models that can robustly handle the variability present across different medical institutions, imaging devices, and patient populations. In this paper, we aim to explore the dynamics of fairness within the context of domain shift and develop methodologies to ensure that models remain fair and reliable as they are adapted or generalized to new domains. The problem definitions of DA and DG are as follows:\nDomain Adaptation (DA): Given a domain data \\(D_s = \\{(x_m, y_m, a_m)\\}_{m=1}^{N_s}\\), where \\(x_m \\in \\mathbb{R}^{H \\times W}\\) represents the m-th image in the source domain. For image classification, \\(y_m \\in \\mathbb{R}^{K}\\) is the category label indicating the class to which the image belongs. For image segmentation, \\(y_m \\in \\mathbb{R}^{K \\times H \\times W}\\) is the label matrix with each element specifying the class for each pixel. In both contexts, \\(a_m \\in \\mathbb{R}^{d}\\) denotes an identity attribute associated with the patient, such as gender, race, or ethnicity. Additionally, there is an unlabeled target domain \\(D_T = \\{x_m\\}_{m=1}^{N_T}\\), where the data distribution typically differs from the source domain. In addition to minimizing the distribution discrepancy between the source and target domains for effective performance on the target domain, a significant concern in DA is to ensure that the adaptation process respects fairness. This entails developing adaptation strategies that prevent the amplification of any biases present in the source domain and promote equity in treatment and outcomes across different groups defined by the identity attributes \\(a_m\\) in both the source and target domains.\nDomain Generalization (DG): Consider a setting with labeled source domain data \\(D_s = \\{(x_m, y_m, a_m)\\}_{m=1}^{N_s}\\). Unlike DA, the DG approach does not utilize data from the target domain during training. Instead, the objective is to learn a model \\(f_{\\theta}\\) from \\(D_s\\) that can generalize effectively to any related but unseen target domain T, characterized by a potential shift in data distribution. The challenge in DG is to extract robust domain-invariant features from \\(D_s\\) that are predictive of the target domain T while also ensuring that the model's predictions are fair and unbiased with respect to the identity attributes represented by \\(a_s\\), without having any access to T during training.\n4.2 Fair Identity Attention\nWe aim to develop a methodical function f that mitigates fairness deterioration, which is often observed during the transfer of models from a source domain to a target domain. Such deterioration is primarily due to domain shift that can amplify existing biases in the dataset, notably those associated with demographic attributes like gender, race, or ethnicity. To address this, we propose an attention"}, {"title": "5 Experiments", "content": "5.1 Algorithmic Fairness Across Domain Shifts\nIn our experiments, we first analyze fairness in the context of domain shifts within the Cup-Disc Segmentation task. Cup-Disc Segmentation refers to the process of accurately delineating the optic cup and disc in fundus images, which is essential for calculating the cup-to-disc ratio (CDR) a critical parameter for assessing the progression and risk of glaucoma. This task is pivotal in the field of medical imaging, particularly within the context of diagnosing and managing eye diseases such as glaucoma. Since the cup is a substantial subarea of the disc, we reformulate the segmentation task into cup and rim (the tissue area between the cup and disc border) segmentation to avoid misrepresented performance due to the large overlapped area between the cup and disc.\nWe investigate the performance of fairness across three different demographics, including gender, race, and ethnicity, across two distinct domains: En face fundus images derived from optical coherence tomography scans and SLO (Scanning Laser Ophthalmoscopy) fundus images. In the subsequent experiments, we selected en face fundus images as the source domain and SLO fundus images as the target domain. The rationale is that en face fundus images are routinely acquired in specialized ophthalmic care settings in comparison to SLO fundus images, leading to significantly greater availability of data. Therefore, we have chosen to position en face fundus images as the source domain, with SLO fundus images as the target domain. For classification, we utilize fundus images from those two domains as source and target domains, categorized into two classes: normal and glaucoma.\nEvaluation Metrics: For evaluating model performance, the Dice coefficient and the intersection over union (IoU) metrics are employed for segmentation assessments, and the area under the receiver operating characteristic curve (AUC) is utilized for classification tasks. Those traditional metrics for segmentation and classification, while indicative of model performance, do not inherently account for fairness across demographic identity groups. Inspired by [39, 68], to address the potential tradeoff between model performance and fairness in medical imaging, we use novel equity-scaled performance (ESP) metrics to assess both performance and fairness for both segmentation and classification tasks.\nLet M\u2208 {Dice, IoU, AUC, . . .} signify a generic performance metric applica-ble to either segmentation or classification. Traditional evaluation usually takes\na set of triplets (z', a, y) as input to produce the metric score M({(z', y)}), which typically disregards demographic identity attributes, thereby missing critical fairness assessment. To incorporate fairness, we first compute a performance discrepancy \u2206, defined as the aggregate deviation of each demographic group's metric from the overall performance, expressed as:\n\\(\\Delta = \\sum_{A \\epsilon A} |M(\\{(x,y)\\}) - M(\\{(x', a, y)|a = A\\})|\\, \\)\nwhere \u2206 approaches zero when performance equity across groups is achieved, reflecting minimal disparity. The ESP metric can then be formulated as follows:\n\\[ESP = \\frac{M(\\{(x',y)\\})}{1 + \\Delta}\\,\\],\nwhich ensures a balanced evaluation of model accuracy and fairness. This metric, ESP, aligns with M when \u2206 is minimized, indicating equitable performance across demographics. Conversely, an increased \u2206 denotes significant disparities between different demographic groups, lowering the ESP score with a larger penalty to indicate that the models obtain less fairness. This unified metric facilitates a comprehensive assessment of deep learning models, emphasizing not only their accuracy (as measured by segmentation and classification metrics such as Dice, IoU and AUC) but also their fairness across different demographic groups.\nCup-Rim Segmentation Results under Domain Shifts\nBaselines: We first utilized TransUNet as the baseline model to perform training on the source domain. After the model training phase, we directly evaluated the model's performance on the target domain without any domain adaptation or generalization strategies. The results of this baseline model on source and target domains are detailed in the first four rows of Table 1, Tables 2, and Table 3. It can be observed that a significant decrease in segmentation accuracy for both the optic cup and rim when applying a model trained on the source domain directly to the target domain. This performance decline highlights the critical issue of domain shift in medical imaging segmentation tasks, underscoring the challenge of transferring learned models between differing imaging domains without appropriate adaptation or generalization strategies.\nDomain Adaptation for Segmentation: To assess the performance of existing domain adaptation methods, we selected three state-of-the-art models as baseline methods for domain adaptation: PixMatch [43], CBST [91], and DAFormer [22]. Given that DAFormer has demonstrated superior performance over the other two methods in previous tasks, and considering its applicability to both domain adaptation and domain generalization tasks, we have integrated our proposed fair identity attention mechanism into DAFormer, denoted as DAFormer-FIA to evaluate the effectiveness of our model. Table 1, Tables 2, and Table 3 present the domain adaptation results of these four models across three demographic attributes: gender, race, and ethnicity. It is noteworthy that our DAFormer-FIA achieves improvements in the segmentation of both the cup and rim across all attributes compared to the baseline DAFormer. Specifically, our model improved the ES-Dice for cup segmentation from 0.781 to 0.802 and the ES-Dice for rim segmentation from 0.344 to 0.528 in the gender attribute. For race attribute, it increased the ES-Dice for cup segmentation from 0.785 to 0.796, and for rim segmentation, from 0.326 to 0.521. In terms of ethnicity attribute, the\nES-Dice for cup segmentation was enhanced from 0.773 to 0.790, and the ES-Dice for rim segmentation was elevated from 0.405 to 0.516. Concurrently, for cup segmentation, our model achieved the highest ES-Dice scores of 0.796 for gender, 0.796 for race, and 0.790 for ethnicity. Similarly, it secured the best ES-IOU scores of 0.692 for gender, 0.682 for race, and 0.674 for ethnicity. Regarding specific demographic attributes, DAFormer-FIA increased the Dice for rim segme-ntation in the male category within gender from 0.344 to 0.533, marking an improvement of approximately 54.94%. In the white category within race, it improved from 0.329 to 0.530, a 61.09% increase. Lastly, in the Hispanic category within ethnicity, the Dice was enhanced from 0.416 to 0.529, translating to a 27.16% uplift. These substantial percentage improvements underscore the effectiveness of our model across diverse demographic attributes. This consistent enhancement across various demographic attributes highlights the effectiveness of integrating fair identity attention into domain adaptation tasks, particularly in augmenting the segmentation accuracy of critical ocular structures.\nDomain Generalization for Segmentation: To validate the performance of existing domain generalization methods, we selected three state-of-the-art models as baselines for domain generalization: GIN+IPA [50], AADG [40], and DAForm-er [22]. Similarly, we integrated our proposed fair identity attention mechanism into DAFormer to assess the effectiveness of our model. Tables 2, Table 1, and Table 3 outline the domain generalization results of these four models across three demographic attributes: race, gender, and ethnicity. It can be found from these tables that our DAFormer-FIA not only enhances the segmentation of both the cup and rim across all three attributes over the standard DAFormer but also achieves the highest segmentation performance for both the cup and rim across\nall three attributes. Specifically, our model improved the ES-Dice score for cup segmentation from 0.787 to 0.816 and for rim segmentation from 0.659 to 0.704 in the gender attribute. Within the race attribute, there were increments in the ES-Dice scores for cup and rim segmentations, from 0.769 to 0.787 and 0.616 to 0.636, respectively. Regarding ethnicity, the model's cup segmentation ES-Dice improved from 0.746 to 0.785, and rim segmentation from 0.630 to 0.676. Regarding specific demographic attributes, DAFormer-FIA increased the Dice score for rim segmentation in the male category within gender from 0.663 to 0.704. In the black category within race, the IoU improved from 0.329 to 0.530. In the Non-Hispanic category within ethnicity, the Dice score was enhanced from 0.746 to 0.842. This indicates the significant impact of incorporating fair identity attention into domain generalization tasks, demonstrating substantial improvements in segmentation accuracy across diverse demographic attributes.\n5.2 Glaucoma Classification Results under Domain Shifts\nBaselines: As shown in Table 4, the basic overall AUC of using en face fundus images (i.e. source domain) to predict glaucoma is 0.803, while the ES-AUCS for gender, race, and ethnicity are 0.795, 0.730, and 0.744, respectively. There are significant AUC performance disparities for racial subgroups with Blacks are 0.085 lower than Whites and 0.058 lower than Asians. Similarly, Hispanics achieve significantly lower AUC than Non-Hispanics. However, if using slo fundus to predict glaucoma with the pretrained source-domain model, both overall AUC and group AUCs have dramatic drops for gender, racial, and ethnic groups. As shown in Fig. 2, the group disparities generally become worse while transforming the source domain to the target domain for both segmentation and classification tasks. This suggests that source and target domain fundus images present signific-antly different semantic distributions. It is necessary to adopt specific learning module to minimize such a domain shift and meanwhile reduce group performance disparities.\nDomain Adaptation for Classification: In parallel with our approach for segment-ation, we explored two leading domain adaptation (DA) methods for classification tasks: CGDM [15] and CDTrans [80], selecting the latter, CDTrans, for enhancement with our novel fair identity attention module, yielding CDTrans-FIA. This integration aims to bolster fairness across demographics under DA.\nPerformances across gender, race, and ethnicity for these models are showcased in Table 4. Our proposed CDTrans-FIA stands out by securing substantial improvements across all demographic attributes. It records the highest ES-Dice scores 0.633 for gender, 0.606 for race, and 0.607 for ethnicity, demonstrating the efficacy of our proposed fair identity attention in domain adaptation, especially for enhancing glaucoma classification algorithmic fairness. Additionally, the pro-posed method (Table 4) significantly uplifts accuracy for minority groups; it boosts performance for blacks by 0.005 to 0.016 AUC scores, and for Hispanics by 0.01 to 0.035 AUC scores, outperforming other DA approaches. Moreover, our model exhibits notable advancements in both accuracy and fairness in the target domain, surpassing the baseline with significant improvements of around 0.1 AUC scores in overall AUC and ES-AUC.\nDomain Generalization for Classification: Similarly, we selected three state-of-the-art methods including GroupDro [59], IRM [2], and G2DM [15] for the DA-based classification. Given that IRM generally achieves the best overall AUC performances for all three demographic attributes, we select IRM as the backbone architecture to incorporate our proposed fair identity attention module, termed as IRM-FIA. According to the results presented in Table 4, IRM-FIA surpasses both GroupDro and G2DM in overall AUC and ES-AUC scores, proving its superior capability in facilitating equitable glaucoma classification across diverse identity groups. In addition, IRM-FIA is generally superior to IRM in both overall AUC and ES-AUC for all three attributes, with the improvement most prominent for race. For instance, as detailed in Table 4, there was an increase of 0.024 in the overall AUC, with the AUC for Asians, Blacks, and Whites each showing gains of over 0.01 AUC score. This underscores the effective-ness of our fair identity attention module in not only boosting overall classification accuracy but also minimizing disparities among different subgroups."}, {"title": "6 Conclusion", "content": "To summarize, this paper focuses on addressing fairness in AI, especially in medical AI, which is essential for equitable healthcare. The issue of fairness in domain transfer, due to the fact that clinics may use varied imaging technologies, remains largely unexplored. Our work introduces FairDomain, a comprehensive study on algorithmic fairness in domain transfer tasks including domain adapta-tion and generalization for both medical segmentation and classification. We propose a novel plug-and-play fair identity attention module that enhances fairness by learning feature relevance through the attention mechanism according to demo-graphic attributes in domain transfer tasks. We also create the first fairness-centric dataset with two paired imaging modalities for the same patient cohort to exclude the confounding impact of demographic distribution variation on model fairness to allow precise assessment of the impact of domain shift on model fairness. Our fair identity attention model can improve existing domain adaptation and generalization methods with better model performance accounted for fairness."}, {"title": "A More training details", "content": "We conducted the experiments on a single A100 GPU with 80GB of memory.\nFor each baseline, we adhered to the training settings specified in the original paper. For the proposed DAFormer-FIA, which is designed for segmentation tasks, we added one FIA layer after the original encoder module at each feature learning stage during the downsampling process. We trained the model using the AdamW optimizer. The encoder was trained with a base learning rate of 6e - 5, and the decoder with 6e4. The model was trained with a batch size of 2 for 40k iterations. For CDTrans-FIA in the domain adaptation task, we considered demographic attributes as query in the cross-attention layer of the backbone ViT model and followed the same training parameters in CDTrans. IRM-FIA was designed for the domain generalization task, which incorporated one FIA layer after the feature encoder module of the backbone SWIM model. IRM-FIA followed the default parameters in IRM."}, {"title": "B Computational complexity", "content": "The FLOPs comparison between IRM+FIA vs IRM is 5.1e11 vs. 4.9e11. The training time per epoch and inference time per sample are 157s vs. 149s and 0.70s vs. 0.65s, respectively."}]}