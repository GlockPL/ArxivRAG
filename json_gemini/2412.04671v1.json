{"title": "Soft Tensor Product Representations for Fully Continuous, Compositional Visual Representations", "authors": ["Bethia Sun", "Maurice Pagnucco", "Yang Song"], "abstract": "Since the inception of the classicalist vs. connectionist debate, it has been argued\nthat the ability to systematically combine symbol-like entities into compositional\nrepresentations is crucial for human intelligence. In connectionist systems, the\nfield of disentanglement has emerged to address this need by producing repre-\nsentations with explicitly separated factors of variation (FoV). By treating the\noverall representation as a string-like concatenation of the inferred FoVs, however,\ndisentanglement provides a fundamentally symbolic treatment of compositional\nstructure, one inherently at odds with the underlying continuity of deep learning\nvector spaces. We hypothesise that this symbolic-continuous mismatch produces\nbroadly suboptimal performance in deep learning models that learn or use such\nrepresentations. To fully align compositional representations with continuous\nvector spaces, we extend Smolensky's Tensor Product Representation (TPR) and\npropose a new type of inherently continuous compositional representation, Soft\nTPR, along with a theoretically-principled architecture, Soft TPR Autoencoder,\ndesigned specifically for learning Soft TPRs. In the visual representation learning\ndomain, our Soft TPR confers broad benefits over symbolic compositional repre-\nsentations: state-of-the-art disentanglement and improved representation learner\nconvergence, along with enhanced sample efficiency and superior low-sample\nregime performance for downstream models, empirically affirming the value of our\ninherently continuous compositional representation learning framework.", "sections": [{"title": "1 Introduction", "content": "Compositional structure, capturing the property of being decomposable into a set of constituent\nparts, is ubiquitous in our surroundings \u2013 from the recursive application of syntax in language,\nto the parsing of richly complex visual scenes into their constituent parts. Given the central role\nsuch structure plays in our understanding of the world, it is highly intuitive that deep learning\nrepresentations also embody compositional structure. Indeed, empirical evidence highlights the\nusefulness of explicitly compositional representations, showcasing a multitude of benefits, including\nincreased interpretability [10, 12], reduced sample complexity [30, 33], increased fairness [20, 25,\n41], and improved performance in out-of-distribution generalisation [33, 48, 50].\nIn\nWe consider the following, intuitive notion of compositional representations. A represen-\ntation of compositionally-structured data is a compositional representation if it has a struc-\nture that faithfully reflects the compositional structure of the represented data [49].\nthe visual representation learning domain, data is clearly compositionally-structured, as\nimages can be decomposed into a set of constituent factors of variation (FoVs), e.g.,\n{magenta floor, orange wall, aqua object colour, oblong object shape} for the image in Figure 1."}, {"title": "2 Related Work", "content": "Disentanglement: In aiming to produce explicitly compositional representations without strong\nsupervision, our work shares the same objective as disentangled representation learning. Prior\nto the highly influential work of [25], which proved the impossibility of learning disentangled\nrepresentations without supervision or other inductive biases, disentangled representations were\nlearnt in a completely unsupervised fashion [8, 10, 14, 17, 24, 26, 37]. Our use of weak supervision\nis inspired by the work [13, 22, 31, 33, 35] relating to this highly influential impossibility result.\nIn particular, we leverage the type of weak supervision termed 'match pairing' [35], where pairs,\n(x, x'), differing in values for a subset of known FoVs are presented to the model, to incentivise\ndisentanglement. Our work, however, fundamentally diverges from all disentanglement work we\nare aware of, by adopting an inherently continuous representation of compositional structure, which\ncontrasts with the symbolic representations of compositional structure characterising existing work.\nTPR-based Work: Existing TPR-based approaches generate continuous representations of compo-\nsitional structure by producing an element with the explicit mathematical form of a TPR. To learn\nthis highly specific form, these approaches rely on the algebraic characterisation of compositionality\npresent in formal domains, such as mathematics [38], or language [19, 23, 28, 34, 52] in addition to"}, {"title": "3 Preliminaries", "content": "We adopt a generalised, non-generative version of the definition of compositional representations\nfrom [49]. Data $x \\in X$ is compositionally-structured if there exists a decomposition function $\u03b2 :$\n$X \u2192 A\u2081 \u00d7 . . . \u00d7 An$ decomposing $x$ into constituent parts, i.e. $B(x) = {a1, ..., an}$, where $ai \\in Ai$.\nA map $\u03c8 : X \u2192 VF$ produces a compositional representation if $f(x) = C(\u03c81(a1),...,\u03c8n(an))$\nwhere $Vi: Ai \u2192 Vi$ denote component functions that independently embed the parts of x into\nvector spaces, and $C : V\u2081 \u00d7 . \u00d7 Vn \u2192 VF$ denotes a composition function that combines the\nembedded parts of x together to form the overall representation. Intuitively, this definition enforces a\nfaithful structural correspondence between the constituency structure of the data, x (i.e., the parts,\n${a1,..., an}$) and the constituency structure of the representation, $\u03c8(x)$ (i.e., the embedded parts,\n${\u03c81(a1),..., \u03c8\u03b7 (an)})$ (assuming C is invertible).\n$T$\nWe formalise a symbolic compositional representation, $\u03c8s(x)$, as a compositional representation\nwhere C is a concatenation operation. Thus, $s(x) = (\u03c81(1),..., \u03c8\u03b7(an))$ for any symbolic\ncompositional representation, $\u03c8s(x)$. Clearly, the aforementioned disentanglement methods [8, 10,\n13, 14, 17, 22, 24, 26, 31, 32, 33, 35, 36, 37, 47] all fit this framework. While we observe that the\nfundamentally symbolic definition of C as concatenation produces an inherent misalignment with\nthe continuous vector spaces of deep learning for the reasons elaborated on in Section 1, it has one\nnotable benefit: the embedded FoVs, ${Vi(ai)}$, can be easily recovered from the representation,\n$Vs(x)$, by simply partitioning $Vs(x)$.\nIt is highly intuitive that for any compositional representation, $f(x)$, to be broadly useful, the FoVs,\n${a}$, should be easily recoverable from $4(x)$ (here we assume the $Vi$'s are invertible, and so, that this\nproperty corresponds to being able to recover the representational components, ${Vi(ai)}$ from $\u03c8(x))$.\nWe thus explore whether an alternative C exists that simultaneously 1) combines the embedded\nFoVs into the overall representation in an inherently continuous manner and 2) preserves the direct\nrecoverability of the embedded FoVs."}, {"title": "3.2 The TPR Framework", "content": "TPR [3] is a specific type of representation that is compositional, continuous, and under certain\nconditions, ensures the direct recoverability of the embedded parts ${Vi(az)}$ from the overall rep-\nresentation. We briefly introduce essential aspects of the framework, deferring further details and\nformal proofs to Appendix A. The TPR framework views compositionally-structured objects as\npossessing a number of (potentially infinite) roles\u00b2, where each role is bound to a corresponding filler.\nIt thus defines the constituent parts ${ai}$ of any compositionally-structured object as a set of role-filler\nbindings. This role-filler binding formalism has predominantly been applied in the natural language\ndomain [19, 28, 34, 52], with fillers often corresponding to words and roles to grammatical categories\n(e.g., the word cat as a filler, and the the category noun as a role). We translate this formalism into\nthe domain of visual representation learning by informally equating roles as FoV types, and fillers as\nFoV values, e.g., {floor colour, wall colour, object colour, object size, object shape, orientation}\nand {blue, magenta, orange, green, small, medium, large, oblong, cube, . . . } respectively for the\nShapes3D domain of Figure 1. The binding of a filler, f, from a set F of NF fillers, to a role,\nr, from a set R of NR roles, such as the filler magenta to the role object colour conveys a sort\nof filler-specific, role-modulated semantic content, and is denoted by $f/r$. The compositional"}, {"title": "4 Methods", "content": "The TPR's highly specific representational form, $Vtpr(x) := \u2211i&F(fm(i)) \u2297 \u00c9R(ri)$, can only be\nsatisfied by a discrete subset of points in the underlying representational space, VF VR. This\nimposes an arduous learning task on representation learners: to parameterise the highly constrained\nmap from the data manifold to a discrete subset of points. This representational form additionally\nassumes a strict algebraic definition of compositionality that corresponds to a set of bindings, where\neach binding comprises a single role and a single filler, precluding the TPR from representing quasi-\ncompositional objects that only approximately satisfy this strict, algebraic definition of compositional\nstructure (e.g., French liaison consonants, where a weighted sum of multiple fillers, rather than a\nsingle filler, bind to a role [9]). Our primary insight is that both these drawbacks can be mitigated\nby continuously relaxing the TPR specification (see B.1). This relaxation allows for a wider variety\nof mappings within a 'cloud' around each TPR (represented by the translucent circular regions in\nFigure 1c), which theoretically eases the difficulty of representation learning. Furthermore, it relaxes"}, {"title": "4.2 Soft TPR Autoencoder: A Concrete Implementation of Learning Soft TPRS", "content": "We define our vector spaces of interest over the reals as VF := RDF and VR := RDR where DF, DR\ndenote the dimensionality of the filler and role embedding spaces. The main insight underlying our\nmethod is that, as the Soft TPR is effectively any arbitrary element from a vector spaces RDF DR\nthat is sufficiently close to some explicit TPR, any (DF \u00b7 DR)-dimensional vector produced by an\nencoder in a standard autoencoding framework can be treated as a Soft TPR candidate. This suggests\nthat a simple autoencoding framework only needs to be slightly modified to produce Soft TPRs.\nBriefly speaking, our Soft TPR Autoencoder contains a standard encoder, E, the TPR decoder, and a\nstandard decoder, D, where the encoder output, z, corresponds to the Soft TPR. At a high level, our\nframework aims to ensure two properties: 1) representational form, and 2) representational content.\nRepresentational form requires that the encoder output, z, has the desired Soft TPR form (i.e. that\n||z - Vtpr||F < \u20ac for some TPR, \u03c8tpr). However, having a Soft TPR form alone is insufficient; the\nrepresentation produced by the autoencoder must also reflect the true role-filler content of the data\nto be a good representation, as required by the aim of representational content. These 2 properties\nare (mostly) respectively achieved using the unsupervised and weakly supervised components of our\nmethod."}, {"title": "5 Results", "content": "To assess the compositional representations produced by our Soft TPR framework, we perform\nevaluation along three dimensions: 1) Compositional Structure / Disentanglement: What is the\ndegree to which Soft TPR representations achieve explicitly compositional structure? 2) Represen-\ntation Learner Convergence Rate: Can representation learners learn the inherently continuous\ncompositional structure embodied in the Soft TPR faster than symbolic alternatives? 3) Downstream\nModels: Does the enhanced vector space alignment produced by the Soft TPR facilitate benefits for\ndownstream models using compositional representations?\nWe benchmark against a suite of weakly supervised disentanglement baselines: Ada-GVAE [33],\nGVAE [22], ML-VAE [13], SlowVAE [39], and the GAN-based model of [35], which we henceforth\nrefer to as 'Shu'. These models all produce symbolic compositional representations corresponding to\na concatenation of scalar-valued FoV tokens. Like our model, Ada-GVAE, GVAE, ML-VAE, and\nShu are trained with paired samples (x, x') sharing values for all but a subset of FoVs types (roles), I.\nML-VAE, GVAE, and Shu assume access to I, the FoV types (roles) that differ between x and x',\nmatching our model's level of supervision, while Ada-GVAE does not. We thus modify Ada-GVAE\n(method detailed in Appendix C.2.2) for more direct comparability, denoting our modification by\nAda-GVAE-k. In contrast, SlowVAE is trained with pairs of samples where all underlying FoV values\nchange, and also assumes that this change can be characterised as a sample from a Laplacian. We\nadditionally benchmark against 2 baselines producing vector-tokened compositional representations:\nCOMET [36], and Visual Concept Tokeniser (VCT) [47]. These vector-tokened models cannot\nbe directly compared to our model as they are fully unsupervised, however, we include them for\ncompleteness. We train 5 instances of each representation learning model using 5 random seeds for\n200,000 iterations across all datasets, and report results averaged over the 5 random runs."}, {"title": "5.1 Compositional Structure / Disentanglement", "content": "To evaluate the degree to which Soft TPRs achieve explicitly compositional structure, we quantify\nrepresentational disentanglement using standard disentanglement datasets Cars3D [4], MPI3D [21],\nand Shapes3D [24] (see C.4.1 for further details). As can be seen in Table 1, our model achieves\nstate-of-the-art disentanglement for all datasets, with notable DCI metric increases of 29% and 74%\non the 2 more challenging datasets of Cars3D and MPI3D respectively. To rule out the possibility\nthat the improvement in disentanglement produced by our model is due to a slight increase of 13,568\n(Cars3D), 1,824 (Shapes3D), 1,600 (MPI3D) learnable parameters produced by the addition of the\nfiller embedding matrix, M&F, to a standard (variational) encoder-decoder framework, we modify\nmodels with fewer parameters to have an identical number of parameters as ours. We note that\nthe modifications are applicable only for the scalar-tokened baselines, as our model has tens of\nmillions less parameters than COMET and VCT. In line with [40], we observe that the performance\nof scalar-tokened disentanglement models remains fairly consistent, or even deteriorates, when the\nnumber of learnable parameters increases, so we defer control experiment results, and our associated\nmethod to Appendix C.2.4."}, {"title": "5.2 Representation Learner Convergence Rate", "content": "To evaluate whether the inherently continuous compositional form of the Soft TPR can be learned\nmore quickly than symbolic alternatives, we consider representations produced at 100, 1,000, 10,000,\n100,000 and 200,000 iterations of training, and evaluate 1) their disentanglement, and 2) their utility,\nas quantified by the performance of downstream models using these representations. For downstream\nmodel performance, we consider two commonly used [30, 46, 33] tasks: the classification-based\nabstract visual reasoning task of [30] and a regression task involving the prediction of continuous\nFoV values for the disentanglement datasets. Downstream models are evaluated on a fixed, held-out\ntest set for both tasks. While our framework does not promote faster disentanglement convergence\n(results in Appendix C.4.1), it interestingly, promotes accelerated learning of useful representations\nfor both downstream tasks compared to baselines. The downstream performance improvements are\nparticularly pronounced in the low iteration regime of 100 iterations of representation learner training,\nas demonstrated by the improvements of 10%, 10%, and 31% in Table 2 and the 27% improvement\nin Table 3. To ensure fair comparison, we embed baseline representations of both higher, and lower\ndimensionality into the same space as our model. For each baseline model, we take the best result\nfrom either the original, or the modified model (denoted by \u2020), and present the full suite of results,\nand details of our embedding method and downstream model setup in Appendix C."}, {"title": "5.3 Downstream Models", "content": "To evaluate whether the enhanced alignment between compositional representations and continuous\nvector spaces produced by our Soft TPR benefits downstream models, we examine downstream\n1) sample efficiency, and 2) raw performance in the low sample regime. We use the previously\nmentioned tasks of abstract visual reasoning and FoV regression. To quantify sample efficiency, in\nline with [25], we use a ratio-based metric obtained by dividing the performance of the downstream\nmodel when trained using a restricted number of samples (100, 250, 500, 1,000 and 10,000 samples),\nby its performance when trained using all samples (between 19,104-1,036,800 samples depending on\nthe task). As illustrated in Table 4, our model has superior sample efficiencies compared to baselines,"}, {"title": "5.4 More Ablation Studies", "content": "We additionally repeat our full suite of experiments using the explicit TPR, Vipr, produced by the\nTPR decoder, in place of our Soft TPR, z. These experiments, a subset of which is presented in Table\n6, empirically demonstrate that the Soft TPR's continuously relaxed specification of compositional\nstructure confers exclusive benefits for both the representation learner and the downstream models\nnot captured by the traditional TPR (see Appendix C.6.1). Note for MPI3D, the explicit TPR has a\nlower raw R\u00b2 score when fully trained (0.785 \u00b1 0.019 vs 0.882 \u00b1 0.016), contributing to its higher\nsample efficiency in Table 6. We additionally examine the importance of the following properties of\nour model in producing explicitly compositional Soft TPR representations: 1) the presence of weak\nsupervision, by setting \u5165\u2081 = 2 = 0 in Equation 7, 2) the explicit dependency between the quantised\nfiller embeddings and the decoder output, by instead using the Soft TPR to reconstruct the input\nimage, and 3) the semi-orthogonality of the role embedding matrix, M&R by removing this constraint\nin the random initialisation of MER, with the results of these ablations illustrated in Table 7."}, {"title": "6 Conclusion", "content": "In this work, we address a longstanding issue in the connectionist approach to compositionality: the\nfundamental mismatch between disentangled representations and the inherently continuous nature of\ndeep learning vector spaces. To overcome this, we introduce Soft TPR, a novel, inherently continu-\nous compositional representational form that extends Smolensky's Tensor Product Representation,\ntogether with the Soft TPR Autocoder, a theoretically-principled architecture designed for learning\nSoft TPRs. Our flexible, continuous framework yields substantial improvements in the visual domain,\nenhancing compositional structure, accelerating convergence in representation learners, and boosting\nefficiency in downstream models. These wide-ranging empirical benefits underscore the importance\nof rethinking compositional representations to honour deep learning's continuous foundations. Future\nwork will extend our continuous framework to hierarchical forms of compositionality, enabling bound\nfillers themselves to decompose into role-filler bindings for enhanced representational expressivity."}, {"title": "A.1 Additional Details", "content": "By defining the constituent components of any compositional object as a set of role-filler bindings,\nthe TPR defines the decomposition function, \u03b2, of Section 3.1 that maps from a set of compositional\nobjects, X, to a set of parts, more explicitly as follows [3]:\n$\u03b2 : X \u2192 2^{F\u00d7R}; x \u2192 {(f,r)|f/r},$ \nwhere F denotes a set of fillers, and R denotes a set of roles. Note that in contrast to the formal\ndefinition of \u03b2 we use in Section 3.1, which assumes each $x \u2208 X$ is decomposable into a set of\nn parts, the above decomposition allows objects to be decomposed into a variably-sized set of\nrole-filler bindings, with this set corresponding to an element in the powerset of F \u00d7 R. For the\nvisual representation learning domain we consider, all considered disentanglement datasets clearly"}, {"title": "A.2 Formal Proofs", "content": "We now formally prove that the TPR with \u03b2 defined in 9 has form $Vtpr(x) = C(\u00a21(a1),...,\u03c8\u03b7 (an))$\nand thus corresponds to the definition of a compositional representation in Section 3.1.\nProof. We denote the role embedding and filler embedding functions as $\u00c9R: R\u2192 VR, \u00c9F : F \u2192 VF$\nrespectively.\nBy definition of the TPR in Eq 1, we have that:\n$tpr(x) := \u2211EF(fm(i)) & ER(ri).$\n$i$\nand hence,\n$tpr(x) = \u2211 Vi(fm(i), ri),$\n$i$\nwhere $ai := (fm(i), ri) \u2208 \u03b2(x), \u03c8i : F \u00d7 R \u2192 VF \u2297VR; (fm(i), ri) \u2192 &F(fm(i)) & \u00c9R(ri)$, and C\nis ordinary vector space addition. Hence, almost trivially, $Utpr(x)$ clearly has the required form to be\na compositional representation.\nNow, we prove the recoverability of the embedded components ${Vi(fm(i), ri)}$ from the TPR,\n$Vtpr(x)$, provided that the set of all role embedding vectors, ${\u00c9R(ri)}$, are linearly independent.\nSimilar variants of this proof can be found in [3], [19].\nProof. Assume the set of all role embedding vectors ${ER(ri)}$ are linearly independent. Then, the\nrole embedding matrix, $MER := (\u00c9R(r1).\u2026\u2026\u00c9R(TNR))$ formed by taking the role embedding vectors\nas columns, has a left inverse, U, such that:\n$UMER = INR NR.$\nHence, we have that $(UM&R)ij = Ui:M\u00a3r:j = Iij$.\nFor ease of notation, let u\u2081 denote the i-th column of UT, and note that \u00c9r(rj) clearly corresponds to\nM\u025br:J. SO, $Ui: MER:j = (UT)TM\u00a3r:j = u\u0142\u00a3r(rj) = Iij$.\nHence, we have that:\n$ER(rj)$\n$\u03b4ij = $\n${ 1 ifi=j\n10 otherwise.$\nUsing the definition of $Vtpr(x), \u03c8tpr(x) = \u2211i&F(fm(i)) \u2297 ER(ri)$, we apply the (tensor) inner\nproduct of $Utpr(x)$ with ui:"}, {"title": "A.3 Shortcomings of Symbolic Compositional Representations and How TPR Helps", "content": "Here, we provide a more detailed elaboration on the shortcomings of symbolic compositional\nrepresentations as outlined in 1. We additionally illustrate how TPR-based continuous compositional\nrepresentations circumvent such limitations through use of a concrete example.\nWe employ the formal definition of a symbolic compositional representation from Section 3.1,\nwhich states a representation, $s(x)$, is a symbolic compositional representation if $\u03c8s(x) =$\n$(\u03c81 (a1), ..., \u03c8n(an)T)$, i.e., if $4s (x)$ corresponds to a concatenation of representational compo-\nnents, ${Vi(ai)}$.\nFor more direct comparison between the symbolic compositional representation, $4s(x)$ and the\nTPR-based compositional representation, $Utpr(x)$, we rewrite the TPR-based representation as\n\u03c8tpr(x) = $V\u2081(\u00e3\u2081) + ... + Vn(\u00e3n)$. Thus, the TPR can be viewed as an ordinary vector sum of\ncomponents, ${V(\u00e3i)}$, where each component, Vi corresponds to an embedded role-filler binding\n(i.e., each component function, Vi, takes a part, ai, corresponding to a role-filler binding a\u2081 :=\n$(fm(i), ri) \u2208 \u03b2(x)$, and embeds it, so we have $\u03c8\u2081 : F \u00d7 R \u2192 VF & VR; (f,r) \u2192 \u00a3F(f) ER(r))$.\nNow, consider the following example: suppose there are 2 FoV types (i.e., roles), colour, shape and\n2 FoV values (i.e., fillers), purple, square. For the symbolic approach, suppose the representational\n1\n2\ncomponents, ${i(ai)}$ are defined as follows: $colour (purple) =\n0\nand shape(square)\n3\n3\nFor the continuous approach, suppose the role embeddings are: $ER(colour) =$\nand the filler embeddings are: $F (purple) =$\nER(shape) =\n3\n2\nand EF (square) =\nThen, a symbolic compositional representation is given by (denoting the concatenation operation by\n\u2295):\n$\u03c8s(x) = colour (purple) shape(square)$\n=\n1\n0 2\n3"}, {"title": "B.1 Shortcomings of the TPR and How Soft TPR Helps", "content": "In this subsection", "\u00c9R": "R \u2192 R2 and filler \u00c9F : F \u2192 R\u00b3 embedding functions as\nfollows:\n1\nER(shape) =", "Mapping": "Consider the set of possible TPRs", "have": "nVtpr (Xred_square) = EF(red) ER(colour) + \u00c9F (square) ER(shape)\n1\n= 2 \u00d7+\n0\n3\n21\n3\n3\n1\n323\n1\nVtpr(Xblue_square) = EF(blue) ER(colour) + \u00a3F(square) ER(shape)\n27"}]}