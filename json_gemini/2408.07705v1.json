{"title": "ENHANCING SUPPLY CHAIN VISIBILITY WITH KNOWLEDGE\nGRAPHS AND LARGE LANGUAGE MODELS", "authors": ["Sara AlMahri", "Liming Xu", "Alexandra Brintrup"], "abstract": "In today's globalized economy, comprehensive supply chain visibility is crucial for effective risk\nmanagement. Achieving visibility remains a significant challenge due to limited information sharing\namong supply chain partners. This paper presents a novel framework leveraging Knowledge Graphs\n(KGs) and Large Language Models (LLMs) to enhance supply chain visibility without relying\non direct stakeholder information sharing. Our zero-shot, LLM-driven approach automates the\nextraction of supply chain information from diverse public sources and constructs KGs to capture\ncomplex interdependencies between supply chain entities. We employ zero-shot prompting for Named\nEntity Recognition (NER) and Relation Extraction (RE) tasks, eliminating the need for extensive\ndomain-specific training. We validate the framework with a case study on electric vehicle supply\nchains, focusing on tracking critical minerals for battery manufacturing. Results show significant\nimprovements in supply chain mapping, extending visibility beyond tier-2 suppliers. The framework\nreveals critical dependencies and alternative sourcing options, enhancing risk management and\nstrategic planning. With high accuracy in NER and RE tasks, it provides an effective tool for\nunderstanding complex, multi-tiered supply networks. This research offers a scalable, flexible method\nfor constructing domain-specific supply chain KGs, addressing longstanding challenges in visibility\nand paving the way for advancements in digital supply chain surveillance.", "sections": [{"title": "1 Introduction", "content": "In an era where globalized and interconnected supply chains form the backbone of industries, achieving comprehensive\nend-to-end supply chain visibility has become a rising concern for organizations Kalaiarasan et al. (2022). Supply chain\nvisibility is \"the extent to which actors within a supply chain have access to or share information which they consider as\nkey or useful to their operations and which they consider will be of mutual benefit\" Barratt and Oke (2007). Visibility\nis viewed as not only an operational advantage, but a critical strategic asset for risk management Emrouznejad et al.\n(2023), insightful decision-making Caridi et al. (2014) and operational efficiency Brusset (2016).\nDespite its recognized importance, achieving full supply chain visibility remains a significant challenge for many\norganizations Zhang et al. (2011); Caridi et al. (2014). Limited visibility can undermine a company\u00e2\u0102\u0179s ability to\nproactively respond to supply chain disruptions, such as those caused by global events or geopolitical tensions. For\ninstance, the COVID-19 pandemic starkly exposed how disruptions in distant tiers of the supply chain could ripple\nthrough to cause substantial operational and financial impact Ivanov and Dolgui (2020). Restricted visibility hinders"}, {"title": "2 Literature Review", "content": "Given the demonstrated difficulties in obtaining information directly from supply chain partners, researchers have\nalready explored alternative avenues for information access. The internet has emerged as a rich and diverse source of\nvaluable supply chain data (Wichmann et al. 2018). Specifically, news articles, company websites, social media, and\nother public sources provide rich insights into supplier-buyer relationships, production capacities, and market trends.\nHowever, web-based information presents its own set of challenges, being siloed, fragmented, and unstructured, which\nimpedes the observation of dependencies between such decentralized data points (Wichmann et al. 2020).\nTo address these challenges, researchers have explored the potential of machine learning, particularly Natural Language\nProcessing (NLP) and Deep Learning techniques in of extracting structured information from unstructured text. Studies\nsuch as those by Kreimeyer et al. (2017); Li et al. (2022); Shickel et al. (2018); Sheikhalishahi et al. (2019); Wang\net al. (2018) have demonstrated significant advancements in this area, especially within the healthcare sector. These\nstudies highlight how NLP can effectively convert unstructured text into structured data, thereby enhancing the ability\nto extract, understand, and utilize information from unstructured clinical text.\nHowever, only a few researchers in the supply chain field have begun adapting these methods to extract structured\ninformation from web sources. By leveraging NLP and deep learning techniques, one can interpret unstructured text\nand extract critical supply chain information Wichmann et al. (2018, 2020); Kosasih et al. (2022). Specifically, Named\nEntity Recognition (NER) and Relation Extraction (RE) methods have been employed to automatically identify key\nelements such as company names, products, and locations, as well as to detect supplier-buyer relationships within\ntextual data. These techniques enable the conversion of unstructured text into structured triplets (source, relation, target),\nfacilitating the extraction of supply chain relationships.\nDespite these advancements, several limitations persist. Handling domain-specific terminology remains a significant\nchallenge, as does the ability to extend these methods to new supply chain contexts. This is mainly due to the\ncomplexity of supply chain relationships and the nuances of specific business language, as these approaches often\nrequire extensive labeled datasets for training, specially in specialized supply chain domains Kejriwal (2019); Aziz et al.\n(2021); Brockmann et al. (2022), for example, tracking ethically sourced cotton or critical mineral mining.\nTo address these challenges, we introduce a zero-shot, Large Language Model (LLM)-driven framework that utilizes\nKnowledge Graphs (KGs) to enhance supply chain visibility. KGs are structured knowledge representations that\norganize information into interconnected nodes and edges, representing entities and their relationships, respectively\nEhrlinger and W\u00f6\u00df (Ehrlinger and W\u00f6\u00df). This structure is particularly effective in complex environments like supply\nchains, as it clearly captures complex interdependencies and maps various types of relationships between different\nclasses of entities Peng et al. (2023).\nOur framework leverages the extensive pre-training of LLMs, enabling them to perform NER and RE tasks specifically\ntailored to supply chain contexts. This is achieved through Zero-Shot Learning, a technique where the model applies\nlearned patterns and knowledge without needing task-specific training or examples Kojima et al. (2022).\nEarlier LLM models such as BERT (Bidirectional Encoder Representations from Transformers) Devlin et al. (2019),\ntypically require additional domain-specific data labeling and fine-tuning to perform tasks like NER and RE. This\nadaptation involves creating and labeling large datasets relevant to the specific domain, followed by retraining the model\nto understand and process the specialized terminology and relationships within that domain.\nIn contrast, our framework KG-LLM driven framework leverages the generalizability and zero-shot capabilities of\nmore advanced LLMs such as OpenAI's GPT-4 OpenAI et al. (2023). These newer LLMs are pre-trained on vast and\ndiverse datasets, enabling them to generalize across a wide range of tasks and domains without requiring additional"}, {"title": "2.1 Knowledge Graphs in Supply Chain Management", "content": "Knowledge graphs have emerged as a powerful tool for representing and analyzing complex relationships in various\ndomains, including supply chain management (SCM). A knowledge graph is a structured representation of knowledge\nin the form of entities and relationships, providing a flexible and scalable way to integrate diverse information sources\nJi et al. (2020). Unlike supply chain networks or production networks, knowledge graphs offer greater flexibility in\nrepresenting multi-dimensional relationships and can easily incorporate new information sources. The application of\nknowledge graphs in SCM has shown promising results. Kosasih et al. (2022) and Deng et al. (2023) demonstrated the\nuse of knowledge graphs for supply chain risk analysis, showcasing their ability to capture complex interdependencies.\nHuang et al. (2019) proposed a knowledge graph-based approach for supply chain partner recommendation, leveraging\nthe rich relational information encoded in the graph structure. Furthermore, Rolf et al. (2022) proposed using knowledge\ngraphs and human-centric AI for reconfigurable supply chains, highlighting their potential for enhancing supply chain\nadaptability.\nThese studies underscore the potential of knowledge graphs to address the challenges of data fragmentation and\ncomplexity in supply chains. By providing a unified representation of supply chain entities and their relationships,\nknowledge graphs can offer enhanced visibility and support more sophisticated analysis. However, the construction of\ncomprehensive knowledge graphs is often time-intensive and challenging, particularly when dealing with large-scale\nsupply chains."}, {"title": "2.2 Natural Language Processing for Supply Chain Mapping", "content": "To address the challenges of manual knowledge graph construction, researchers have explored the use of NLP techniques\nfor automated supply chain mapping. Supply chain mapping involves creating a visual representation of the relationships\nand flows between different entities in a supply chain MacCarthy et al. (2022). Two key NLP techniques, NER and RE,\nhave shown promise in automating this process by extracting relevant information from unstructured text sources.\nNER is a subfield of NLP that focuses on identifying and classifying specific data points, known as named entities,\nwithin a text Wang et al. (2023a). These entities can include names of people, organizations, locations, dates, and other\nsignificant terms. NER works by using algorithms trained on labeled datasets to detect and categorize these entities,\ntransforming unstructured text into structured data Sun et al. (2018).\nRE, on the other hand, is an NLP technique that identifies and categorizes the connections between entities mentioned\nin a text Wadhwa et al. (2023a). This process helps in understanding how different entities are related to each other,\nsuch as \"works at\", \"located in\" or \"founded by.\"\nBERT, introduced by Devlin et al. (2019), revolutionized the field of NLP with its bidirectional training approach.\nBERT is a type of LLM designed to understand the context of words in a sentence by looking at the words that come\nbefore and after. This model is pre-trained on a large corpus of text and can be fine-tuned for specific tasks, making it"}, {"title": "2.3 Large Language Models & Knowledge Graphs", "content": "While BERT is considered an LLM, it is primarily used for understanding and processing text, specifically tailored\nfor tasks like NER and RE through fine-tuning Devlin et al. (2019). The key advantage of newer LLMs lies in their\ngeneralizability: they can understand and generate human-like text, perform complex tasks across various domains, and\nadapt quickly to new tasks with little to no additional training Kojima et al. (2022). The emergence of more advanced\nLLMs has marked a significant advancement in NLP. LLMs, such as GPT-3 introduced by Brown et al. (2020), have\ndemonstrated remarkable capabilities across various NLP tasks, including Zero-Shot and Few-Shot learning. Zero-shot\nlearning refers to the ability of a model to perform a task it has never been explicitly trained on by leveraging its\npre-existing knowledge and patterns learned during its extensive pre-training phase Kojima et al. (2022). This means\nthe model can understand and respond to new types of tasks or questions without having seen any specific examples of\nthem before.\nFew-shot learning, on the other hand, allows the model to adapt to new tasks with only a few examples or instances of\nthe task provided. In this scenario, the model uses a limited number of task-specific examples to understand the new\ntask better, enhancing its performance without requiring a large, labeled dataset for training Brown et al. (2020).\nThese capabilities enable them to efficiently handle tasks in specialized domains like supply chain management. Their\nability to perform zero-shot and few-shot learning means they can quickly adapt to domain-specific terminology and\nrelationships without the need for extensive task-specific data labeling and fine-tuning\nRecent research has explored the potential of LLMs in automating knowledge graph construction. Faria et al. (2023)\ndemonstrated the use of GPT-3 for zero-shot knowledge graph completion, achieving competitive performance with\nminimal task-specific training. Zhu et al. (2023) showed that LLMs can effectively extract triples from unstructured\ntext for knowledge graph construction. Furthermore, several studies highlighted the superior performance of LLMs as\nthey can achieve near state-of-the-art performance with only Few-Shot Prompting, roughly equivalent to existing fully\nsupervised models on both NER and RE tasks Wadhwa et al. (2023b). Additionally, studies report LLM's superior\nability in situations where the amount of training data is extremely scarce, as they can perform significantly better than\nsupervised models Wang et al. (2023b).\nWhile LLMs have been applied to various domains, their potential in supply chain management, particularly for\nenhancing visibility, remains largely unexplored. Li et al. (2023) conducted one of the first studies exploring the\nuse of LLMs for supply chain optimization, demonstrating their potential for bridging the gap between supply chain\nautomation and human comprehension."}, {"title": "2.4 Research Gaps and Opportunities", "content": "Despite notable progress in the use of NLP and knowledge graphs in enhancing supply chain visibility, significant\nchallenges remain:\n\u2022 There is a noticeable lack of flexibility in integrating diverse and heterogeneous data sets, which is crucial for\ncomprehensive supply chain visibility.\n\u2022 Earlier supply chain mapping approaches require extensive labeled data and further fine-tuning to effectively\nmanage supply chain-specific terminology.\n\u2022 The potential for enhancing supply chain visibility by integrating LLMs with knowledge graphs remains\nlargely untapped and requires further exploration."}, {"title": "3 Methodology", "content": "In this section, we begin with an overview of the KG-LLM framework designed to improve supply chain visibility.\nWe then delve into the detailed stages of the framework, covering dataset collection and pre-processing, as well as the\nconstruction of the knowledge graph. This includes three key tasks: NER, RE, and entity disambiguation."}, {"title": "3.1 LLM-driven Knowledge Graph Framework for Enhanced Supply Chain Visibility", "content": "As shown in Figure 1, we introduce a KG-LLM driven framework. Our approach addresses the critical challenge of\nextracting, structuring, and centralizing the vast amount of supply chain information dispersed across the web. While\nthis information is crucial for understanding extended supplier networks, its fragmented state severely limits its utility.\nTo overcome these limitations, we develop a framework that combines the structural advantages of knowledge graphs\nwith the advanced NLP capabilities of LLMs. We employ a zero-shot learning approach, leveraging the contextual\nunderstanding and language processing capabilities of state-of-the-art GPT-4 LLM by OpenAI OpenAI et al. (2023).\nThis integration allows for the automated construction of comprehensive, interconnected representations of supply\nchain ecosystems. As shown in Figure 1, our framework begins with systematically identifying and aggregating data\nfrom various unstructured sources such as online web pages, articles, and Wikipedia entries, forming the foundation\nfor extracting the extended supply network. We then develop two main prompts for different stages in the framework:\nthe first facilitates the extraction of entities and relationships, essential for NER and RE, while the second ensures\nprecise distinction of entities during the entity disambiguation stage. Using the LLM, we extract significant data points\nlike company names, locations, and product details in the NER process. The RE process determines the relationships\nbetween identified entities, articulating interactions and dependencies critical for constructing the links between nodes\nin the knowledge graph. Finally, entity disambiguation resolves ambiguities among entities to ensure each node in the\nknowledge graph is unique, maintaining the graph's integrity and consistency. In the following sections, we discuss\neach step in more details."}, {"title": "3.2 Data Collection & Pre-Processing", "content": "The initial stage involves systematically identifying and aggregating data from various unstructured web sources. It is\ncrucial to emphasize that the selection of data sources is critical to the integrity and credibility of the extracted insights.\nWe note that when implementing this framework, the sources should be carefully evaluated for relevance, accuracy,\nand reliability to ensure the quality of the resulting knowledge graph. It is also important to note that this framework\nprovides static information and knowledge. While exploring temporal knowledge graphs is a promising avenue for\nfuture research, it is beyond the scope of this study. Our current focus is on establishing a baseline framework for\nintegrating LLMs and knowledge graphs to enhance supply chain visibility."}, {"title": "3.3 Knowledge Graph Construction Process", "content": ""}, {"title": "3.3.1 Named Entity Recognition", "content": "Our framework leverages these capabilities through a Zero-Shot Learning (ZSL) approach. ZSL is a machine learning\nparadigm that enables AI models to recognize and categorize entities or concepts not explicitly encountered during\ntraining Kojima et al. (2022). This approach is particularly valuable in our context, as it allows for flexibility in entity\nextraction without the need for task-specific fine-tuning. To effectively guide the LLM in performing NER tasks using\nZSL, we developed a carefully crafted prompt (Prompt 1) that provides contextual descriptions of the target entities."}, {"title": "3.4 Relation Extraction", "content": "Similarly, for RE, we provide the LLM with specific instructions as shown in Figure 3.\nWe use the same prompt (Prompt 1) to continue listing the tasks for RE (T9-T16) as follows:\n\u2022 Task Definition (T9): Defines relationships as links between nodes. This basic definition helps the LLM\nunderstand the foundational concept of relationships in the context of our data.\n\u2022 Targeted Relationships (T10): Specifies three types of relationships that the LLM must capture. For example,\nhere, we list 'Produces', 'LocatedIn' and 'SuppliesTo'. Each relationship is defined with description to ensure\nclarity. By providing semantic equivalents, we increase the model's ability to capture relevant variations of the\nsame relationship.\n\u2022 Label Formatting (T11-T16): Ensures consistency and readability in our data. This standardization is crucial\nfor integrating the extracted data into our knowledge graph seamlessly."}, {"title": "3.4.1 Entity Disambiguation", "content": "Entity disambiguation is a critical process in ensuring the accuracy and integrity of the supply chain data within our\nknowledge graph. Given the diversity and inconsistency in naming conventions across various data sources, it is\nessential to correctly identify and merge entities that refer to the same underlying node.\nTo effectively address this challenge, we have developed a detailed and structured prompt for our LLM, aimed at\ndisambiguating entities identified in the initial extraction phase. This approach leverages the LLM's expertise in\nsemantics and entity recognition to accurately unify entity representations (See Figure 4).\nThe entity disambiguation process begins by instructing the LLM to assume the role of an expert in semantics and entity\nidentification. As illustrated in Figure 5, we systematically categorize all nodes by type and present each node type list\nseparately to the LLM for disambiguation. The LLM is then prompted to assign unique numerical identifiers to entities\nthat represent distinct nodes, while allocating identical numbers to entities that semantically represent the same node.\nThis approach leverages the LLM's contextual understanding to resolve naming inconsistencies and merge semantically\nequivalent entities."}, {"title": "4 Experimental Studies", "content": "In this section, we first describe the evaluation methods used to assess our proposed framework. We utilize accuracy\nas the primary evaluation metric and further analyze the framework\u00e2\u0102\u0179s consistency in generating reliable results.\nFollowing this, we present the quantitative results obtained from our framework. Additionally, we conduct a quali-\ntative evaluation using a case study focused on the electric vehicle supply chain to demonstrate the framework\u00e2\u0102\u0179s\neffectiveness in enhancing supply chain visibility in domain-specific contexts. Specifically, we examine whether the\nframework can track critical minerals and mining companies involved in the production of electric vehicle batteries,\nthereby improving the visibility of Original Equipment Manufacturers (OEMs) into their extended supplier network."}, {"title": "4.1 Evaluation Methods", "content": "In this section, we outline the evaluation methods used to assess our proposed framework's performance. We first\ndescribe the dataset developed for the evaluation and then detail the metrics employed to measure the framework's\naccuracy and consistency."}, {"title": "4.1.1 Evaluation Dataset", "content": "Given the lack of benchmark datasets specifically designed for supply chain data, we developed a tailored evaluation\nmethodology to assess the performance of our framework.\nFor our evaluation, we created a dataset of different Wikipedia pages relevant to electric vehicle manufacturers,\ncomprising of a total of 1,277 sentences. We chose Wikipedia because it is a comprehensive, diverse repository of\nfree-access information, which supports a broad view across industries, technologies, and supply chain relationships.\nThis selection was specifically tailored to align with our subsequent proof of concept case study, which focuses on\nenhancing visibility in the electric vehicle supply chain, particularly in tracing the sourcing of raw materials for batteries\nfrom mines through tier-2 and tier-3 suppliers. Guided by the objectives of our case study, we strategically selected\ncompany profiles that span mining companies, battery manufacturers, and electric vehicle producers. This selection was\nmade to maximize the likelihood of capturing comprehensive data on our predefined set of six entity types: Company,\nLocation, Material, Person, Product, and Mine, as well as four key relationship types: locatedIn, suppliesTo, owns, and\nproduces.\nIt is important to clarify that in this evaluation, our main objective is to assess the LLM's ability to accurately extract\nentities and relationships, represented as triples, from textual content. The focus is on the technical extraction abilities\nof the LLM, not on the empirical accuracy of the information represented in the triples themselves. Researchers should\ncarefully vet and select data to suit specific applications and contexts.\nFrom the analyzed dataset, our framework successfully identified 735 nodes and 433 relationships, with their distribution\ndetailed in Figure 7."}, {"title": "4.1.2 Evaluation Metrics", "content": "Our evaluation methodology is tailored to address the specific challenges and requirements of supply chain information\nextraction. We focus on assessing the accuracy of the extracted nodes and relationships, as these form the core of\nour knowledge graph and directly impact supply chain visibility and decision-making processes. We acknowledge\nthat precision, recall and f-scores, which consider the missed triplets, are also important metrics for comprehensive\nevaluation. However, the manual identification of missed triplets is resource-intensive and currently not feasible due\nto the lack of benchmark datasets. Our current evaluation method serves as a preliminary step, demonstrating the\nframework's ability to extract valuable and accurate information. By focusing on accuracy and ensuring the correctness\nof the generated triplets, we provide a solid foundation for the practical applicability of our framework. This approach\nallows us to iteratively improve the system and gradually incorporate more comprehensive evaluation metrics as the\nfield evolves.\nWe measure accuracy across three key tasks as follows:\nNER:\n\u2022 Correct: A node is correctly defined, and its type is accurate (e.g., identifying Tesla as a (Company)).\n\u2022 Incorrect: A node is incorrectly classified (e.g., identifying Tesla as a (Location) instead of a (Company)).\nAccuracy is calculated using:\n$Accuracy_{NER} = \\frac{Number \\: of \\: Correct \\: Nodes \\: Identified}{Total \\: Nodes \\: Identified \\: (Correct + Incorrect)}$ (1)\nRE:\n\u2022 Correct: A relationship is accurately defined between two suitable nodes (e.g., Tesla (Company) produces\nModel 3 (Product)).\n\u2022 Incorrect: A relationship is incorrectly defined between two nodes, or the direction of the relationship is\nincorrect (e.g., identifying Tesla as supplying to CATL instead of CATL supplying to Tesla).\nAccuracy is defined as:\n$Accuracy_{RE} = \\frac{Number \\: of \\: Correct \\: Relationships \\: Identified}{Total \\: Relationships \\: Identified \\: (Correct + Incorrect)}$ (2)\nEntity Disambiguation:\n\u2022 Correct: One or more entities are correctly merged into a unique node, indicating they are similar, or an entity\nis correctly identified as unique with no similar nodes.\n\u2022 Incorrect: An entity is incorrectly merged with another node that does not represent the same unique entity, or\nit is not merged when it should have been."}, {"title": "4.2 Results", "content": "This section presents a comprehensive analysis of our proposed framework's performance, evaluated using accuracy\nmetrics across three critical dimensions: NER, RE, and entity disambiguation."}, {"title": "4.2.1 Accuracy", "content": "Figure 8 shows the performance of our framework using Zero-Shot Learning across the three key tasks defined."}, {"title": "4.2.2 Consistency", "content": "Figure 10 shows the counts of nodes and relationships extracted over 7 distinct runs. We observe low fluctuations\nbetween different trials for both node and RE tasks.\nTo further quantify the consistency of our framework, we calculate the Mean, Standard Deviation, Coefficient of\nVariation and Range for both tasks across the 7 different trials as shown in Table 1. As observed, the low coefficients\nof variation for both node count (0.03) and relationship count (0.04) indicate high consistency in the framework's\nperformance. These values suggest that the variability in extraction is minimal relative to the mean, demonstrating\nthe framework's reliability in producing consistent results. The standard deviations of 6.22 and 5.55 for node and\nrelationship counts, respectively, compared to their respective means of 223.86 and 137.43, further support the\nframework's consistency. The relatively small ranges (17 for nodes and 14 for relationships) also indicate that the\nframework's performance remains stable across different runs.\nWe further break down the consistency metrics by node type. As shown in Table 2, Location nodes demonstrate the\nlowest CV of 0.438, among all types, indicating high consistency in identifying geographical entities. Material nodes\nexhibit the highest CV of 0.960, which may be attributed to the diverse ways materials can be mentioned in text,\npotentially leading to more variable extraction."}, {"title": "4.3 Case-Study", "content": "To demonstrate the practical benefits and effectiveness of our framework, we applied it to a focused case study aimed at\nenhancing the supply chain visibility of electric vehicle manufacturers. These supply chains are inherently complex,"}, {"title": "4.3.1 Enhanced Visibility Beyond Tier-1 Suppliers", "content": "Our framework can extend the visibility of many OEMs beyond their immediate tier-1 suppliers, uncovering the origins\nand mines of critical minerals used in electric vehicle manufacturing."}, {"title": "4.3.2 Alternative Sourcing and Supplier Diversification", "content": "As shown in Figure 11, the framework captured Audi's tier-2 and tier-3 suppliers, revealing the specific lithium mines\nthat supply the lithium used in Audi's electric batteries. For instance, Ganfeng Lithium, located in China, owns three\ndifferent lithium mines. Additionally, the framework identified that Ganfeng Lithium also supplies to competitors of\nAudi, such as BMW and Tesla. AppendixA provides a more detailed network illustration and additional examples of\nextended tier visibility. Neo4j graph database Neo4j (2024) was used to visualize these dependencies.\nBy tracing the supply chain of lithium, an OEM can identify the specific mines where their suppliers source lithium.\nThis knowledge enables proactive measures to secure alternative sources if disruptions occur at the primary mine. This\nextended visibility allows OEMs to understand the full scope of their supply chains, from raw material extraction at\nmines to the production of battery components. Such insights are crucial for strategic planning and risk management,\nespecially in scenarios involving geopolitical tensions or supply disruptions."}, {"title": "4.3.3 Mapping of Product Supply Chain Network", "content": "As shown in Figure 12, the framework also enables OEMs to visualize supply chain relationships and answer strategic\nquestions such as \"What other OEMs do my tier-1 suppliers supply to?\" and \"What alternative suppliers supply to my\ncompetitors?\". As shown, LG-Chemical is Audi's tier-1 supplier but also supplies batteries to competitors like Chrysler,\nSAIC Motor, and Ford. Additionally, although Audi shares the same tier-2 supplier with Tesla, Ford, and BMW, these\ncompanies also have other suppliers such as CATL. AppendixB provides a more detailed network illustration and\nsimilar examples of visualizing alternative suppliers and shared suppliers with OEMs.\nThis could provide decision makers with valuable insights for supply chain optimization and strategic decision-making.\nBy identifying that a key battery supplier also supplies to a competitor, an OEM can negotiate better terms or seek\nalternative suppliers to gain a competitive edge."}, {"title": "5 Conclusions", "content": "We present another application of the framework to demonstrate its capability to capture where certain materials are\nlocated, who owns and distributes these materials, and which mines they come from.\nFor example, from a few pages, we mapped a subset of the supply chain of nickel, as shown in Figure 13, identifying\nwho produces nickel, where these companies are located, and what other companies they own. This mapping allows\ndecision-makers to understand the supply chains of specific materials and make informed choices about suppliers.\nUnderstanding such supply chains can significantly aid in making key decisions in choosing the right suppliers. For\ninstance, a decision-maker interested in a specific material can use this framework to identify companies that dominate\nthe supply of that material and gain insights into their operations and dependencies. AppendixC provides a more\ndetailed network illustration and similar examples of mapping different product supply networks.\nWhile this simplified case study serves as a proof of concept, it's important to emphasize that the potential of our\nframework lies in its scalability and adaptability. The knowledge graph we constructed, though based on a limited set of\nsources, already reveals complex relationships and valuable insights. However, this is merely scratching the surface of\nwhat is possible.\nIn real-world applications, our framework can ingest and process vast amounts of data from diverse sources, including\nindustry reports, news feeds, and social media. As more data is incorporated, the knowledge graph grows exponentially\nricher, uncovering deeper connections and more nuanced insights. Furthermore, the framework's flexibility allows it to\nbe tailored to various industries and supply chain networks beyond electric vehicle manufacturing. Whether applied\nto pharmaceuticals, semiconductors, or consumer goods, the core principles remain the same \u00e2\u0102\u015e mapping complex\nrelationships, identifying vulnerabilities, and uncovering opportunities.\nThis paper has presented a new framework for enhancing supply chain visibility through the integration of knowledge\ngraphs and large language models. Our approach addresses critical challenges in modern supply chain management,\nparticularly in the context of complex, global networks such as those found in the electric vehicle industry.\nOur research has shown that this framework can potentially enhance supply chain visibility, offering a more holistic\nview of intricate supplier networks and material flows.\nOur approach addresses critical challenges in modern supply chain management, particularly in complex, global\nnetworks like those in the electric vehicle industry. The key contributions of this work include the development of a\nscalable methodology for constructing comprehensive supply chain knowledge graphs from diverse, publicly available\ndata sources, and the leveraging of zero-shot large language models to extract and contextualize complex supply\nchain relationships beyond tier-1 and tier-2 suppliers. We have demonstrated the framework's effectiveness through\na case study on electric vehicle manufacturers, revealing critical dependencies and alternative sourcing options for\nessential minerals and materials. This framework provides decision-makers with insights into supply chain structures,\nenabling more informed risk management and strategic planning. While our research has shown significant potential for\nenhancing supply chain visibility, we acknowledge several limitations. The static nature of the generated knowledge\ngraph fails to capture the dynamic nature of supply chains. Our heavy reliance on publicly available web data may\nresult in incomplete visibility if certain information is not disclosed. Additionally, the reliability of the knowledge\ngraph depends on the credibility of the information sources used, which could lead to inaccuracies if the data is\nunreliable or outdated. The ability of decision-makers to extract understanding from the framework needs to be\nvalidated through further use cases. Future work will focus on addressing these limitations. We plan to explore temporal\nknowledge graph techniques to better represent evolving supply chain relationships over time. We will also enhance our\nevaluation methodology by developing methods to estimate recall metrics and establish a gold standard for supply chain\ninformation extraction. These efforts aim to refine and expand the capabilities of our framework, further improving its\nutility in supply chain management.\nIn conclusion, this research represents a significant step in improving supply chain visibility, offering a tool for mapping\ndiverse networks within the supply chain. This work sets the stage for further research to address various use cases,\nincluding ethical considerations and sustainability. Moreover, we establish a baseline for the academic community,\nencouraging further refinement of the framework through enhanced prompting techniques or the integration of few-shot\nlearning tailored to specific supply chain domains."}, {"title": "Disclosure statement", "content": "No conflict of interest was reported by the author(s)."}, {"title": "Availability of Data", "content": "The data supporting the findings of this study were derived from publicly available Wikipedia pages. These pages were\nused as resources to feed into the framework for extracting nodes and links. All Wikipedia pages utilized in this study\nare accessible online."}]}