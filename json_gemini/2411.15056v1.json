{"title": "Financial Risk Assessment via Long-term Payment Behavior Sequence Folding", "authors": ["Yiran Qiao", "Yateng Tang", "Xiang Ao", "Qi Yuan", "Ziming Liu", "Chen Shen", "Xuehao Zheng"], "abstract": "Online inclusive financial services encounter significant financial risks due to their expansive user base and low default costs. By real-world practice, we reveal that utilizing longer-term user payment behaviors can enhance models' ability to forecast financial risks. However, learning long behavior sequences is non-trivial for deep sequential models. Additionally, the diverse fields of payment behaviors carry rich information, requiring thorough exploitation. These factors collectively complicate the task of long-term user behavior modeling. To tackle these challenges, we propose a Long-term Payment Behavior Sequence Folding method, referred to as LBSF. In LBSF, payment behavior sequences are folded based on merchants, using the merchant field as an intrinsic grouping criterion, which enables informative parallelism without reliance on external knowledge. Meanwhile, we maximize the utility of payment details through a multi-field behavior encoding mechanism. Subsequently, behavior aggregation at the merchant level followed by relational learning across merchants facilitates comprehensive user financial representation. We evaluate LBSF on the financial risk assessment task using a large-scale real-world dataset. The results demonstrate that folding long behavior sequences based on internal behavioral cues effectively models long-term patterns and changes, thereby generating more accurate user financial profiles for practical applications.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, online payment platforms have promoted diverse inclusive financial services, extending their reach to a broader user base underserved by traditional financial institutions [1]\u2013[3]. However, both this demographic expansion and low default costs contribute to persistently high default risk in online inclusive finance [4], [5]. It burgeons the significance and urgency of the financial risk assessment task in these online payment platforms to underpin a more robust modern finance ecosystem.\nFinancial risk assessment aims to evaluate the default potential of users in financial services by analyzing individuals' financial history [6]. As the era evolves and users' financial histories grow, techniques that traditional financial institutions employ for user evaluation have progressed from statistical methods [7]\u2013[9] to machine learning models [10]\u2013[12]. However, what remains unchanged is the reliance on records of conventional financial activities such as credit card usage, loan repayments, and mortgage history as the foundation for data analysis [6], [13]. Nevertheless, online platforms usually do not possess users' private financial history records due to various restrictions.\nDespite this data deprivation, online payment platforms have their unique advantages in accessing vast amounts of user payment behavior data, which can be leveraged to enhance risk management and detect high default risk. While such payment behaviors do not directly represent financial credit, these data, often in the form of sequences, can provide valuable insights into a user's financial habits, spending patterns, and overall creditworthiness. Therefore, these sequential behavioral data can be regarded as para-financial information, which can also serve as the data foundation for financial risk assessment.\nSimilar ideas could be found in some existing works of user sequential behavior modeling for financial risk assessment [14]\u2013[18]. These works follow a methodology that employs state-of-the-art sequential models as a foundation, incorporating tailored attention mechanisms [14]\u2013[16] or hierarchy establishment through external knowledge [17], [18] to capture contextual signals regarding users' financial well-being. Despite their remarkable success, these attempts focus on relatively short sequences, overlooking the significance of long-term behaviors.\nMeanwhile, the available user behavior sequences on online payment platforms are continually growing. In real business practice, as depicted in Figure 1, we experimented with behavior data spanning 45, 90, and 180 days to predict defaults, and the model performance shows a monotonic increase with longer sequence lengths. The observed phenomenon, that long-term sequential behaviors often derive better performances of the models suggests further exploitation of abundant para-financial behaviors. Consequently, both the data growth and the practical insights call for the upgrade to long-term user payment behavior modeling for financial risk assessment.\nHowever, deploying sequential models for long-term payment behaviors is challenging. The complexity escalates when dealing with extremely long sequences of user behavior data. Taking the widely deployed Transformer architecture as an example, time and storage costs increase quadratically with the length of the user behavior sequences [19]. Given the operational problem, a straightforward solution is to divide the entire sequence into shorter segments for parallel processing. However, this segmentation may lead to the loss of valuable long-range contextual information. It is crucial to find a segmentation method that brings semantic information gain to compensate for this loss.\nFollowing this idea, we aim to apply an internally guided segmentation approach based on data fields within behaviors. This approach organizes data systematically to reduce chaos and allows for adaptable sequence segmentation across various scenarios. Fortunately, long-term payment behaviors originally encompass rich data fields, including textual, temporal, and numerical data, allowing segmentation based on the inherent features of the raw behaviors themselves, rather than relying on external knowledge. Furthermore, intending to maximize the data utility, we design a multi-field encoding mechanism to characterize user payment behaviors, thus maintaining the para-financial details to the greatest extent possible.\nTo this end, in this paper, we propose a method to fold the long-term user payment behavior sequences at the merchant level for financial risk assessment. We refer to the method as \"Long-term Payment Behavior Sequence Folding\u201d, \u201cLBSF\u201d in short. Specifically, we fold behavior sequences based on the merchant field of payment behaviors, grouping payment behaviors by merchants and ordering payment behaviors within the same merchant chronologically. Folding sequences at the merchant level not only enables segmentation for parallel processing but also provides additional information gain.\nMoreover, we encode payment behaviors by integrating all available data fields, i.e., the payment's description, timing, and amount. With such a multi-field joint encoding mechanism, payment behaviors can be represented more comprehensively, preserving valuable details that enrich the context for long-term user behavior learning. For information melding within and across merchants, based on the parallelism of Transformer [19], sub-sequences at the merchant level can first be aggregated in parallel, followed by a secondary aggregation of merchant-level representations, to obtain the final user representation. In this way, LBSF can learn long-term user behavior sequences effectively.\nWe conduct extensive experiments on a real-world large-scale dataset provided by Tencent Mobile Payment to validate our method's effectiveness, demonstrating LBSF's ability to comprehensively characterize user financial profiles. Our main contributions are summarized as follows:\n\u2022 To our knowledge, we are the first to fold long behavior sequences based on the inherent characteristics of behaviors themselves. This reorganization of long-term behaviors empowers informative parallel processing and easy adaptation across applications.\n\u2022 We propose the Long-term Payment Behavior Sequence Folding (LBSF) method for financial risk assessment. LBSF folds long-term user payment behavior sequences at the merchant level to capture the patterns and changes of payment behaviors within and across merchants, with all available para-financial details leveraged via multi-field behavior encoding.\n\u2022 Experiments on a large-scale real-world dataset demonstrate the effectiveness and applicability of our proposed method LBSF."}, {"title": "II. RELATED WORK", "content": "The related research of this work can be divided into three categories: the research on financial risk assessment, sequential user behavior modeling for fraud detection, and Transformer-based methods for long-sequence modeling."}, {"title": "A. Financial Risk Assessment", "content": "One of the earliest attempts at financial risk assessment was made in 1968, as Altman [7] proposed a linear model based on various financial features to predict corporate bankruptcy. It marked the beginning when traditional financial institutions set up default risk rating procedures on their own. In this stage, statistical methods based on the fundamental characteristics and financial status of users dominated the field, which was systematically reviewed by Dimitras [8].\nAs the user community rapidly expanded and Artificial Intelligence technology developed, it became evident that machine learning methods could substantially enhance both the efficiency and accuracy of statistical approaches without relying on restrictive assumptions [6]. To name some, decision tree (DT) [10] and support vector machine (SVM) [11], [12] were among the widely employed techniques, utilizing extensive user features.\nHowever, accessing extensive user characteristics such as income, assets, and debts, which are available to traditional financial institutions, can present difficulties in online finance owing to regulatory restrictions. As user behavior data grows on online platforms, researchers have introduced deep learning models to model the accumulated behaviors. These models can detect different types of defaults, e.g., fraud [14], [20]\u2013[22], cash-out [23], [24], etc [25], [26]. A recent comprehensive review by Zhu and Ao [27] could provide more details."}, {"title": "B. User Behavior Sequence Modeling for Fraud Detection", "content": "Previous works have researched user behavior sequence modeling applied for fraud detection [14]\u2013[18]. By accounting for the order of user actions, this modeling approach enables a deeper comprehension of behavior correlations and a reflection of user intentions [28].\nFor fraud detection, Guo [14] incorporated the self-historical attention module and interactive module for LSTM to help identify repeated or cyclical behaviors. Cheng [15] proposed a spatial-temporal attention-based neural network (STAN) for credit card fraud detection, to jointly analyze the spatial and temporal information of sequential transactions. While these models use tailored attention mechanisms to capture contextual signals in behavior sequences, they may overlook the hierarchical information.\nConsidering the hierarchical information, SAH-RNN [16] incorporated web page structures into behavior sequences and applied dual attention mechanisms to perceive users' global and local intentions. NHFM [17] applied event and sequence extractors as a hierarchical structure to learn event and sequence representations. SHORING [18] consisted of the high-order interaction network and conditional sequence network to learn various symbolic expressions through sequence data. These works consider hierarchy in terms of web page structures or extracted events for additional information gain beyond the raw behaviors themselves.\nOur proposed method, however, delves into the inherent nature of payment behaviors. We reorganize and learn sequential behaviors to the merchant hierarchy, inherently reflecting users' financial status and consumption habits, and accordingly fully utilize textual information in addition to transaction timings and amounts. Consequently, the merchant-based embeddings are further learned as high-level sequences for the final user representations."}, {"title": "C. Transformer-based Long Sequence Modeling", "content": "Since our method employs Transformers as the backbone sequential model, we summarize Transformer-based approaches for long sequence modeling as follows. Transformers, with their innovative self-attention mechanism, have surpassed traditional sequential models like RNNs and LSTMs in efficacy and scalability [19]. They have become dominant across diverse domains, including language processing [29], [30], image analysis [31], and protein study [32]. However, Transformers' quadratic time and memory complexity for input length limit their application in domains requiring longer sequences [33]. In response to this operating problem, researchers have made attempts to design various variants of Transformers to scale to long sequences [34]\u2013[37]. For instance, Reformer [34] introduced Locality-Sensitive Hashing (LSH) attention and reversible residual layers to reduce the memory footprint. Transformer-XL [35] proposed a segment-level recurrence mechanism that connects multiple segments. Linformer [36] projected the length dimension of keys and values to a lower-dimensional representation with low-rank self-attention. Informer [37] combined ProbSparse self-attention mechanism and distilling operation to enhance the scalability of traditional Transformer architecture.\nPrevious studies have mainly concentrated on adapting conventional Transformers to handle general tasks regarding long sequence modeling. In contrast, our approach diverges from them by directing attention toward the intrinsic characteristics of long-term payment behavior data. Our primary goal is to develop a specialized methodology that not only tackles operational challenges but also facilitates the exploration of underlying correlations and trends within diverse, long-term payment behaviors."}, {"title": "III. PROBLEM FORMULATION", "content": "In this section, we first introduce the business setting in our work and then formulate our problem in this paper."}, {"title": "A. Business Setting", "content": "In this work, our business setup revolves around the online inclusive financial services provided to users by an online payment platform. Our primary objective is to predict the probability that a user will commit financial default based on user long-term payment behaviors, thereby determining whether to grant them access to a variety of inclusive financial services. By accurately assessing the risk of default, the platform can make informed decisions, ensuring that only trustworthy users are granted access to certain inclusive financial services. This not only helps in safeguarding the platform's financial stability but also enhances operational efficiency and user trust."}, {"title": "B. Problem Statement", "content": "In this paper, we formulate our task as a binary classification problem. According to the business setting, we assign a label $Y_n \\in \\{0, 1\\}$ to each user $u_n \\in U$ to indicate whether they are a defaulter ($y_n = 1$) or not.\nFor each user $u_n$, a payment behavior sequence $s_n = \\{s_{n1}, s_{n2}, ..., s_{nT}\\}$ with the length $T$ is provided, and each payment behavior $s_{ni}$ is attached with the attributes including the merchant name, the purchase description, the timing and the amount of the payment, denoted by $s_{ni} = (M_{ni}, d_{ni}, t_{ni}, U_{ni})$. Given a set of labeled users on an online payment platform $U_{train}$, our goal is to predict the default labels of some unlabeled users $U_{test} = U \\\\ U_{train}$ with the user long-term payment behaviors provided. Formally, the task is to learn a model $f_w$ to classify the unlabeled users based on their long-term payment behaviors:\n$f_w: \\{S_n\\}_{u_n \\in U} \\rightarrow Y$.\\label{eq:1}\\tag{1}"}, {"title": "IV. METHODOLOGY", "content": "In this section, we detail our proposed method LBSF. First, we give an overview of LBSF. Then, we demonstrate the dissection of LBSF, including each of its integral parts: long-term payment behavior reorganizing in Section IV-B, multi-field behavior encoding in Section IV-C, hierarchical sequence melding in Section IV-D, and across-merchant relational learning in Section IV-E."}, {"title": "A. Overview of LBSF", "content": "The architecture of LBSF is illustrated in Figure 2. LBSF reorganizes the sequence of user long-term payment behaviors based on merchant categorization. Subsequently, the sequence segments for each merchant are melded hierarchically using Transformers to derive a user embedding at the single-merchant level. Finally, high-level melding and relational learning across merchants are applied to synthesize these merchant-level user embeddings into a comprehensive final user representation. This representation is further fed to a classifier for financial risk assessment."}, {"title": "B. Long-term Payment Behavior Reorganizing", "content": "To better exploit the long-range dependencies and contextual insights in long-term user payment behaviors, building a hierarchical structure for behaviors appears a reasonable way. Divergent from previous methods that rely on external cues like web page structures [16] or events [17], [18] for hierarchy establishment, we segment and manage the entire sequence based on the intrinsic signals present within the raw payment behaviors, i.e., the merchants. Specifically, we reorganize the whole behavior sequence according to the merchant $m_{ni}$, preserving the chronological order within each merchant.\nAn example process of this merchant-level reorganizing is depicted in Figure 3. After the reorganization, the chaotic behavior sequence becomes well-organized, enabling some direct observations from various payment behaviors across and within merchants: The user always commuted by subway during this period. Early in the time window, he frequented an upscale restaurant and booked a flight via a travel app. But later from a certain point, he began opting for quick meals from a convenience store and buying basic groceries from a local market. Besides, through the same travel app, instead of booking flights, his new choice is cheap train tickets.\nAfter reorganizing the behaviors, the observed changes within and across merchants can reflect the evolving spending habits. This example may imply a relatively increased likelihood of financial default, as it initially involves a period of concentrated luxury spending followed by a transition to basic consumption. We believe such reorganizing at the merchant level can facilitate comprehending and capitalizing on trends and shifts of financial status within or across merchants.\nFor operation, note that the number of merchants $M$ is set. For each user $u_n$, we have $M$ merchants as $\\{m'_{n1}, m'_{n2}, \\dots, m'_{nM}\\}$ and corresponding $M$ merchant-level sub-sequences denoted by $\\{s'_{n1}, s'_{n2}, \\dots, s'_{M}\\}$ after sequence reorganizing. These sub-sequences are further learned by Transformers for fused embeddings at the merchant level."}, {"title": "C. Multi-field Behavior Encoding", "content": "Recall that user payment behavior data encompasses diverse fields, namely merchant name, purchase description, timing, and transaction amount. The key question that arises is how to effectively encode and integrate these varied data fields.\nWithin a payment behavior $s_{ni} = (M_{ni}, d_{ni}, t_{ni}, U_{ni})$, the transaction amount $U_{ni}$ is already numerical and the texts $M_{ni}, d_{ni}$ can be easily encoded by Transformers.\nFor time embedding, in this scenario, due to the relatively sparse payment behavior sequences of users, only relying on positional embeddings based on relative positions is insufficient to capture changes in user consumption habits. Taking each day's 24-hour cycle as an example, the timestamps when a user paid for midnight snacks at 23:00 and 0:00 should be closely embedded in terms of a cyclic pattern. But plain numerical time embeddings fail to achieve this. Therefore, we intend to better represent the periodicity of each time dimension, namely month, day, week, and hour. Considering the periodic nature of the sine/cosine function, a sine-cosine transformation-based time embedding is further proposed. Transaction time $t_{ni}$ is encoded by\n$\\phi(t, T) = (cos(2 \\pi t / T), sin(2 \\pi t / T),$ \\label{eq:2}\\tag{2}\nas in each dimension, e.g., in the hour dimension $T = 24$. Note that month, day, week, and hour are all encoded accordingly, and the embeddings of each are concatenated to form the general time embedding.\nHere, we have transformed the heterogeneous data into the embedding space for further integration. Note that the embeddings of $d_{ni}, t_{ni}$ are denoted by $\\tilde{d_{ni}}, \\tilde{t_{ni}}$ for simplicity. The embedding of a single behavior $e_{ni}$ is obtained by concatenation of $\\tilde{d_{ni}}, \\tilde{t_{ni}}, U_{ni}$ and dimensionality reduction through a fully connected layer. For user $U_n$, $\\{\\tilde{m}_{n1}, \\tilde{m}_{n2}, ..., \\tilde{m}_{nM}\\}$ represents the text embeddings of $M$ merchants $\\{m'_{n1}, m'_{n2}, \\dots, m'_{nM}\\}$."}, {"title": "D. Hierarchical Sequence Melding", "content": "Next, we elaborate on how to meld sub-sequences within and across merchants through Transformers respectively.\n1) Melding within a merchant: For a user $u_n$ and a merchant $m'_{nj} \\in \\{\\tilde{m}_{n1}, \\tilde{m}_{n2}, ..., \\tilde{m}_{nM}\\}$ patronized by $u_n$, the merchant-level sub-sequence of behavior embeddings is denoted as $s'_{nj} = \\{e_{nk}\\}_{m_{nk}=m'_{nj}}$. These embeddings are fed into a Transformer and then processed via average pooling to obtain a representation within the merchant $h^M_{nj}$:\n$h^M_{nj} = \\text{AveragePooling}(\\text{Transformer}(s'_{nj}))$ \\label{eq:3}\\tag{3}\nIn this way, the periodic patterns and consumption habits within the same merchant's payment behaviors can be better extracted. Then, the merchant representation of payment behaviors $h^M_{nj}$ is further fused with the text embedding of the merchant $\\tilde{m}_{nj}$ through a fully connected layer, producing the merchant embedding still denoted by $\\tilde{h}_{nj}$. With the fusion of semantic information, the traits and the tiers of the merchants are integrated into the merchant embeddings.\n2) Melding across merchants: After melding payment behaviors within each merchant in a parallel manner, for user $u_n$, we have a sequence of merchant embeddings: $h = \\{\\tilde{h}_{n1}, \\tilde{h}_{n2}, ..., \\tilde{h}_{nM}\\}$. Similar to melding within merchants, we utilize Transformer to learn across merchants to generate enhanced merchant embeddings :\n$h^{M'} = \\text{Transformer}(h)$ \\label{eq:4}\\tag{4}\nConsequently, we obtain a sequence of merchant embeddings $h^{M'} = \\{h^{M'}_{1}, h^{M'}_{2}, ..., h^{M'}_{M}\\}$ with more contexts and dependencies fused through the self-attention of Transformer."}, {"title": "E. Across-merchant Relational Learning", "content": "Across-merchant relational learning refers to understanding the correlations among different merchant embeddings. This process assigns weights to different merchants, leading to comprehensive user representations that merge merchant representations more effectively.\nInspired by Vision Transformer (ViT) [38], we consider the merchant embeddings extracted from a user payment behavior sequence as the patch embeddings partitioned from an image. A ViT-like self-attention mechanism is applied to accomplish across-merchant relational learning.\nOne key distinction of ViT compared to vanilla Transformers is the inclusion of a classification token, represented by [CLS]. This token [CLS] is integrated into the Transformer Encoder alongside the embeddings of individual merchants $\\{\\tilde{h}^{M'}_{1}, \\tilde{h}^{M'}_{2}, ..., \\tilde{h}^{M'}_{M}\\}$. During the self-attention process, the classification token attends to the merchant embeddings, allowing the model to capture global contextual information across all merchants in the sequence.\nAfter the self-attention process, the classification token is fused with the other merchant embeddings. This fusion process enables the model to aggregate information both locally, by considering individual merchants, and globally, by incorporating the global context represented by the classification token. Ultimately, the embedding $\\tilde{h}$ at [CLS] serves as a comprehensive representation of the entire input merchant embedding sequence, i.e., the final representation of user $u_n$. Utilizing a Multi-Layer Perceptron (MLP) as the classifier, the prediction of the user credit default is then accomplished.\n$\\hat{y}_n = \\text{MLP}(\\tilde{h})$ \\label{eq:5}\\tag{5}\nWe perform model training by minimizing the Binary Cross-Entropy Loss (BCELoss), with $N$ as the number of training samples:\n$\\mathcal{L}(y, \\hat{y}) = \\frac{1}{N} \\sum_{n=1}^{N} [y_n \\log(\\hat{y}_n) + (1 - y_n) \\log(1 - \\hat{y}_n)]$ \\label{eq:6}\\tag{6}\nIn summary, the training process of LBSF is illustrated in Algorithm 1."}, {"title": "V. EXPERIMENTAL SETUP", "content": "In this section, we present the details of our experimental setup, regarding the datasets, compared methods, implementation details, and metrics."}, {"title": "A. Datasets", "content": "We obtain a real-world financial risk assessment dataset from Tencent Mobile Payment\u00b9. This large-scale dataset collected the long-term payment behaviors of 458,744 users.\nFor data splits, the dataset includes 387,332 users for training (from March 24, 2020, to May 19, 2021), 36,021 users for validation (from May 20, 2021, to May 31, 2021), and 35,391 users for testing (from June 1, 2021, to June 16, 2021). For label annotation, we define users who default after being granted access to inclusive financial services as positive samples; otherwise as negative samples. Note that this dataset is sampled from the user corpus to maintain a positive rate among all included users of approximately 10.0%. The statistics of the dataset are presented in Table I."}, {"title": "B. Compared Methods", "content": "To adequately demonstrate the effectiveness of our proposed method LBSF, we compared LBSF with 13 baselines, categorized into three types: i.e., basic models, sequential models, and pre-training models.\n1) Basic Models: XGBoost [39] and MLP [40] are two widely used machine learning algorithms that we experimented with based on user statistical features.\n2) Sequential Models: BiLSTM [41] is a long short-term memory network that processes input sequences in both forward and backward directions. Transformer [19] is one of the most widely used sequential models. Various Transformer variants are proposed for scalability, among which we compare: Longformer [42] tailors Transformer with global attention mechanisms and sliding windows. Reformer [34] is a Transformer variant with locality-sensitive hashing attention. Informer [37] adapts Transformer to scale to long time series with Prob-Sparse attention and distillation. In addition to Transformer variants, STAN [15] is selected as an attention-based sequential model for credit card fraud detection.\nBesides, we also experimented with several newly proposed Transformer equivalents: RetNet [43] introduces a retention mechanism for improving sequence modeling. RWKV [44]"}, {"title": "VI. EXPERIMENTAL RESULTS", "content": "In this section, we analyze our experimental results on real-world datasets to demonstrate the efficacy of LBSF. Particularly, we aim to address the following research questions:\n\u2022 RQ1: Does LBSF outperform various baselines?\n\u2022 RQ2: How does each component of LBSF contribute to the performance enhancement?\n\u2022 RQ3: What does the merchant-level information reveal about the default users specifically identified by LBSF?"}, {"title": "A. Performance Comparison (RQ1)", "content": "We compare LBSF with various baselines on three subsets of varying periods (45 days, 90 days, and 180 days) from the Tencent Mobile Payment dataset to answer the first research question. These subsets consist of the same users but capture behaviors over time windows of different lengths. The AUC and Recall@10% scores are reported in Table II. Note that these two evaluation metrics exhibit a consistent trend. Our observations are as follows.\n1) Comparison with Baselines: Firstly, our proposed model LBSF consistently outperforms all baseline models on all subsets of varying time periods with only one exception: On the 45-day subset, Mamba achieves only slightly higher scores than LBSF by a margin of 0.46%, and our method still ranks second best among all models. Despite this exception, the effectiveness of LBSF is proven on real-world datasets of different lengths, indicating its applicability in business practice to identify potential defaulters.\nMoreover, across the types, the sequential models have shown generally more competitive performance than the basic and pre-training methods. For the basic and pre-training methods, this may be attributed to the subpar user profiles generated by statistical features or general proxy tasks, which fail to capture the specific patterns in user spending activities.\nAmong the sequential models, recently proposed Transformer equivalents including RetNet, RWKV, and Mamba have demonstrated significant promise in long sequence modeling, outperforming variants (the X-formers) that heavily depend on the basic architecture of vanilla Transformers. Given their leading performance, these up-to-date sequential models could also act as the backbone of our LBSF to enhance its potential even further, since our folding method is applicable to all end-to-end sequential models.\n2) Comparison of Sequence Length: Secondly, regarding the dimension of period length, models trained with longer-period payment behaviors achieve better performances. Across all the models, there is a clear trend of increasing performance with longer-period payment behavior sequences. The widely evident significance of long-term data underscores our initial premise that leveraging long-term user payment behaviors is crucial for effectively assessing financial risks, thereby enhancing the robustness and stability of inclusive finance.\nThe main experimental results have demonstrated the effectiveness and potential of LBSF, leading us to further investigate the contribution of each component of LBSF."}, {"title": "B. Ablation Study (RQ2)", "content": "To answer the second research question, we conducted an ablation study to show that every component of LBSF contributes to the performance increase on the 90-day subset. For ablation, we subdivide the specific designs of LBSF into four components, namely merchant folding, payment description embedding, payment timing embedding, and payment amount embedding, which are removed respectively in experiments.\nTable III displays the results of the ablation study of LBSF on the Tencent Mobile Payment dataset. The complete LBSF achieves the highest performance, affirming the effectiveness and necessity of our specialized designs for exploiting para-financial information, i.e., long-term user payment behaviors.\nTo remove merchant folding, we eliminate the merchant-based hierarchical structure and do not use merchant text embeddings, but keep the payments still chunked by merchants and then concatenated as a whole for input. We find out that the ablation of merchant folding leads to the largest performance degradation. This empirical finding aligns with our motivation, that the payment information at the merchant level can considerably reveal the patterns and changes in users' financial status and consumption habits, and should be explicitly highlighted in financial risk assessment.\nFrom payment embeddings, removals of different aspects are similar: As claimed in Section IV-C, a single behavior embedding is first obtained by concatenating the description embedding, the time embedding, and the amount embedding. Ablating the description or time or amount means excluding it in the concatenation. We can observe from the results that among the three aspects of payment behaviors, excluding the amount in the initial payment embedding results in the highest decrease in performance, which prompts us to prioritize payment amounts in future attempts in real-world practices."}, {"title": "C. Case Study (RQ3)", "content": "To answer the third research question, we present and analyze two representative defaulters spotted by LBSF. For each detected defaulter, we dig into their spending habits through the attention scores assigned to merchants, as produced and utilized in the across-merchant relative learning module detailed in Section IV-E.\nRecall that the attention scores of merchants represent the weights at which merchant embeddings contribute to the final user embedding, indicating the extent to which each merchant influences the final classification. By extracting the weights of merchants, we demonstrate that merchant-level folding can not only help detect defaulters overlooked by baseline methods but also provide pattern-like explanations for real-world operations. Using anonymized examples, referred to as Alice and Bob, we illustrate how specific spending habits observed across various merchants may be linked to defaults.\nSpecifically, we selected several top-ranked merchants based on their weights and counted the number of payments at these merchants over a certain period. By observing the trends in transaction frequency across different merchants, we aim to uncover the underlying long-term patterns of spending habits and financial well-being.\n1) Defaulter Alice: For Alice, Figure 4 illustrates the merchant weights and changes in consumption frequency over time at the four merchants with the highest weights. In the line graph, the horizontal axis represents time in weekly intervals, while the vertical axis indicates the number of payments. Each of these payment activities of Bob have rapidly increased in frequency, indicating a trend toward impulsive spending. This tendency of emotional consumption suggests a shift toward a more extravagant lifestyle, which could jeopardize his financial stability and lead to a higher risk of financial default. This observation may prompt us to focus more on frequent emotional spending in user long-term payment behaviors which may imply an addictive tendency.\nThe study of two interesting cases in experiments not only demonstrates the effectiveness and interpretability of LBSF but also inspires insights into user payment behavior patterns that can be leveraged in real-world financial risk assessment."}, {"title": "VII. CONCLUSION", "content": "In this paper, we proposed the Long-term Payment Behavior Sequence Folding (LBSF) method. LBSF folds payment behavior sequences using the merchant as an intrinsic criterion and employs multi-field behavior encoding for diverse payment details. By aggregating payment behavior sub-sequences at the merchant level and performing a secondary aggregation of merchant-level representations, LBSF effectively captures long-term patterns and changes in user financial behaviors, facilitating the characterization of user financial profiles. Our evaluation on a large-scale real-world dataset demonstrates LBSF's efficacy in leveraging long-term data to enhance financial risk assessment."}]}