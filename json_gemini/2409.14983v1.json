{"title": "Dynamic Integration of Task-Specific Adapters for Class Incremental Learning", "authors": ["Jiashuo Li", "Shaokun Wang", "Bo Qian", "Yuhang He", "Xing Wei", "Yihong Gong"], "abstract": "Non-exemplar class Incremental Learning (NECIL) enables\nmodels to continuously acquire new classes without retrain-ing from scratch and storing old task exemplars, addressing\nprivacy and storage issues. However, the absence of data from\nearlier tasks exacerbates the challenge of catastrophic for-getting in NECIL. In this paper, we propose a novel frame-work called Dynamic Integration of task-specific Adapters\n(DIA), which comprises two key components: Task-Specific\nAdapter Integration (TSAI) and Patch-Level Model Align-ment. TSAI boosts compositionality through a patch-level\nadapter integration strategy, which provides a more flexible\ncompositional solution while maintaining low computation\ncosts. Patch-Level Model Alignment maintains feature con-sistency and accurate decision boundaries via two special-ized mechanisms: Patch-Level Distillation Loss (PDL) and\nPatch-Level Feature Reconstruction method (PFR). Specif-ically, the PDL preserves feature-level consistency between\nsuccessive models by implementing a distillation loss based\non the contributions of patch tokens to new class learning.\nThe PFR facilitates accurate classifier alignment by recon-structing old class features from previous tasks that adapt to\nnew task knowledge. Extensive experiments validate the ef-fectiveness of our DIA, revealing significant improvements\non benchmark datasets in the NECIL setting, maintaining an\noptimal balance between computational complexity and ac-curacy. The full code implementation will be made pub-licly available upon the publication of this paper.", "sections": [{"title": "Introduction", "content": "Class Incremental Learning (CIL) has gained increasing at-tention within the expansive field of artificial intelligence re-search (Li et al. 2024b; Zhu et al. 2021b; Wang et al. 2022c;\nKurniawan et al. 2024; Li et al. 2024a; Wang et al. 2023a;\nBonato et al. 2024; Zhai et al. 2024a), offering the poten-tial for models to continuously learn new knowledge while\nmaintaining the knowledge of previously encountered old\nclasses. Replay-based CIL approaches (Zhu et al. 2021b; Li\nand Hoiem 2018a; Wang et al. 2022a; Zhou et al. 2023;\nRebuffi et al. 2017; Yan, Xie, and He 2021) require the\nstorage of exemplars from previous tasks, which presents\nchallenges in terms of memory limitations and privacy con-cerns. Benefiting from the advances in Pre-Trained Models\n(PTMs) (Dosovitskiy et al. 2020), Non-Exemplar Class In-cremental Learning (NECIL) has become a promising alter-native, enabling the incremental acquisition of knowledge\nwithout the need to maintain a buffer of old class exemplars.\nDespite the inherent ability of PTMs to produce gener-alizable features, which has led to superior performance in\nthe NECIL setting, NECIL remains challenging due to two\nprimary factors. First, As shown in Fig.1 (a), some stud-ies (Gao et al. 2023; Zhang et al. 2023; Zhou et al. 2024a)\nthat tune a shared parameter space for all tasks unable to\nsegregate parameters for each task. The mixing of parame-ters leads to task interference, which in turn causes catas-trophic forgetting. Particular PET-based methods (Wang\net al. 2022b,c; Smith et al. 2023; Gao, Cen, and Chang 2024;\nKurniawan et al. 2024) isolate task parameters by designing\ntask-specific prompts. However, these methods establish a\nstrong correlation between prompt selection and the class to-kens. This tight coupling impedes the model from leveraging\nintact old task parameters to reconstruct knowledge withoutold exemplars, undermining the model's capacity for effec-tive knowledge retention and reproduction in NECIL sce-narios. Moreover, these methods, requiring multiple forward\npropagations, significantly increase computational costs, as\nshown in Fig.1 (b). We summarize the above issues as the\ncompositionality deficiency.\nSecond, the absence of exemplars from old tasks prevents\nthe model from applying replay techniques to preserve old\ntask knowledge. Currently, PET-based methods (Wang et al.\n2022b,c; Smith et al. 2023; Gao, Cen, and Chang 2024) ne-glect the importance of maintaining consistency between in-crementally trained models. This neglect causes the model\nto easily overfit new tasks, focusing solely on information\nrelevant to new tasks while discarding others that may be\ncritical for old tasks. It also fails to adapt classifiers to the\ndecision boundary changes introduced by new tasks. There\nare prototype-based techniques (Zhang et al. 2023; Zhu et al.\n2021b; Wang et al. 2023b) that employ the Gaussian dis-tribution to model the distribution of old task features and\nalign the classifier through the generated features. However,\nas shown in Fig.1 (c), the features created by Gaussian sam-pling increasingly deviate from the actual features of real\nimages as new tasks are learned. We attribute the above\nissues to the model alignment deficiency.\nTo mitigate the above two challenges, we introduce\nthe Dynamic Integration of task-specific Adapters (DIA)\nframework, which comprises two main components: Task-Specific Adapter Integration (TSAI) and Patch-Level Model\nAlignment. Specifically, the TSAI module is designed to\nboost compositionality through a patch-level adapter inte-gration strategy, which provides a more flexible composi-tional solution while maintaining low computation costs.\nFurthermore, we demonstrate the knowledge retention and\nreconstruction potential of TSAI on a parameter factor-ization basis. Building these TSAI's capabilities, we pro-pose a patch-level model alignment strategy to maintain\nfeature consistency and accurate decision boundaries. The\nproposed model alignment strategy integrates two funda-mental parts: 1) The Patch-Level Distillation Loss (PDL)\nmaintains feature-level consistency between the old and new\nmodels by introducing a distillation loss based on the nor-malized distance of the patch tokens. PDL evaluates the con-tribution of patch tokens to the new task learning and pe-nalizes feature drift in non-contributory tokens to maintain\nfeature consistency. 2) The Patch-Level Feature Recon-struction (PFR) employs a normalized distance difference\nto retrieve patch tokens associated with previously acquired\ntask knowledge. These tokens, combined with old class pro-totypes, are then used to reconstruct old class features that\nadapt to the newly learned tasks.\nComprehensive experiments on four benchmark datasets\ndemonstrate the superiority of the proposed DIA method,\nwhich achieves state-of-the-art (SOTA) performance in the\nNECIL setting. Moreover, as shown in Fig.1 (a), our DIA\nmaintains up to a 90% decrease in computational complexity\nwhile maintaining SOTA performance.\nThe contributions can be summarized as follows:\n\u2022 We propose a novel framework entitled Dynamic Inte-gration of task-specific Adapters (DIA) for the NECIL problem, addressing compositionality and model align-ment deficiencies.\n\u2022 We introduce the Task-Specific Adapter Integration\n(TSAI) module to boost compositionality, which em-ploys a patch-level adapter integration strategy. We also\ndemonstrate its knowledge retention and reconstruction\ncapability through parameter factorization analysis.\n\u2022 We present a patch-level model alignment strategy based\non the knowledge retention and reconstruction capability\nof TSAI, incorporating PDL to maintain feature consis-tency and PFR to reconstruct old class features that adapt\nto new knowledge, improving classifier alignment.\n\u2022 We conduct extensive experiments across four bench-marks, where the proposed DIA achieves state-of-the-art\nperformance while maintaining an optimal balance be-tween computational complexity and accuracy."}, {"title": "Related Work", "content": "Parameter-Efficient Tuning: As an efficient alternative to\nfull fine-tuning, Adapter tuning (Houlsby et al. 2019) was\ninitially introduced to efficiently transfer large pre-trained\nmodels to downstream tasks in NLP tasks. Afterward, meth-ods such as Prompt-Tuning (Lester, Al-Rfou, and Constant\n2021) and Prefix-Tuning (Li and Liang 2021) adapt models\nby inserting learnable tokens explicitly tailored to the new\ntasks. Following the success of Vision Transformers (Doso-vitskiy et al. 2020; Liu et al. 2021), PET methods have been\nadapted for visual transfer learning. Notable examples in-clude Visual Prompt Tuning (VPT) (Jia et al. 2022) and\nAdapterFormer (Chen et al. 2022), which apply PET tech-niques to vision tasks. These methods achieve comparable\nor superior performance to full fine-tuning while maintain-ing efficiency. In this paper, we propose a Dynamic Inte-gration of task-specific Adapters framework for the NECIL\nproblem based on PET methods (Chen et al. 2022; Houlsby\net al. 2019).\nNon-exemplar Class Incremental Learning NECIL ap-proaches address privacy and memory concerns by elimi-nating the need for old task exemplars and employing vari-ous techniques such as regularization (Li and Hoiem 2018b;\nHuang et al. 2024; Yu et al. 2020), augmentation (Zhu et al.\n2021a,b; Kim, Park, and Han 2024), and model rectification-based (Wang et al. 2023b; Zhu et al. 2021b) methods to\nmaintain model performance across tasks. Currently, PTM-based methods that sequentially adjust the PTM to stream\ndata with new classes are a promising direction for NECIL.\nMost methods (Wang et al. 2022c,b; Smith et al. 2023;\nGao, Cen, and Chang 2024; Roy et al. 2024) focus on the\ninstance-level prompt selection to segregate task parameters.\nLAE (Gao et al. 2023) and ADAM (Zhou et al. 2024a) pro-pose unified frameworks for PET methods by model ensem-ble. SLCA (Zhang et al. 2023) extends the Gaussian mod-eling (Zhu et al. 2021b) of old task features to rectify clas-sifiers. EASE (Zhou et al. 2024b) utilizes adapters to ex-tract task-specific features through multiple forward propa-gations."}, {"title": "Problem Setup", "content": "In this paper, we focus on the NECIL setting, which pro-hibits storing exemplars from previous tasks. NECIL in-volves sequentially learning a set of $T$ tasks, denoted as\n${T}_{t=1}^T$, where each task $T_t = {D^t, C^t}$ consists of a cur-rent training set $D^t = {(I_i,y_i)}_{i=1}^{N_t}$ and a class label set\n$C^t = {c_i}_{i=1}^{M_t}$. In this context, $I_t$ is the input image, $y_i$ is\nthe class label for the $i$-th image belonging to $C^t$, $N_t$ rep-resents the number of images, and $M_t$ denotes the number\nof classes in $C^t$. There is no overlap between the classes of\ndifferent tasks, meaning $\\forall i, j, C^i \\cap C^j = \\emptyset$. After train-ing on a task $T^t$, the model is evaluated on all the classes\nencountered so far, $C_{1:t} = C_1 \\cup C_2 \\cup ... \\cup C_t$."}, {"title": "Overview", "content": "As illustrated in Fig.2, we propose the Dynamic Integration\nof task-specific Adapters (DIA) framework for the NECIL\nscenario. At incremental task t, we introduce a task-specific\nadapter $A^t,b$ parallel to the MLP layer and a task signa-ture vector $\\tau^{t,b}$ into each transformer block b. As shown in\nFig.2 (a), each image token is routed by the signature vectors\n${\\tau^t,b}_{i=1}^B$ to relevant adapters. These task-specific adapters\nindependently process the input token, and their outputs are\nmerged using scalars determined by the task signature vec-tors, yielding an integrated output. At task t, only $A^{t,b}$ and\n$\\tau^{t,b}$ are trainable. Leveraging TSAI's capacity for knowl-edge retention and reconstruction, along with the rich in-formation embedded in patch tokens, we introduce a patch-level model alignment mechanism at both the feature andclassifier levels. Firstly, as shown in Fig.2 (b), we compute\nthe Patch-Level Distillation Loss (PDL) based on the fea-ture drift between the patch tokens $p_n, p_o$ obtained from the\nmodel trained on task t and task t - 1. PDL penalizes the\nfeature drift in patch tokens that do not contribute to the new\ntask learning to preserve old task knowledge. Secondly, we\npropose a Patch-level Feature Reconstruction (PFR) method\nto reconstruct old class features without exemplars, as shown\nin Fig.2 (c). We identify patch tokens related to old task\nknowledge and integrate them with the old task prototypes.\nThe reconstructed features are utilized to calibrate the deci-sion boundaries of the classifier, adapting to the changes in\nfeature distribution."}, {"title": "Task-Specific Adapters Integration", "content": "The proposed TSAI aims to provide a more flexible compo-sitional solution by employing a patch-level adapter integra-tion strategy. To achieve this goal, we learn a task-specific\nadapter $A^{t,b}$, and a task signature vector $\\tau^{t,b} \\in R^d$ for each\nincremental task, where $d$ indicates feature dimension, $t$ rep-resents the incremental task id, and $b$ represents the block\nindex. For convenience, we omit block index b, as the com-putation is identical across transformer blocks.\nSpecifically, the task-specific adapter $A_t$ is a bottleneck\nmodule comprising a down-projection layer $W_{down} \\in R^{d\\times r}$,\nan up-projection layer $W_{up} \\in R^{r\\times d}$. This bottleneck module\nextends and adjusts the feature space by modifying the MLP\noutput through the residual connection via a scaling vector\n$\\tau_t$ obtained by $T_t$. For an input $X = [P_j]_{j=0}^L \\in R^{(L+1)\\times d}$\nwith $L+1$ image tokens, where $p_0 \\in R^d$ indicates the class\ntoken and $p_j \\in R^d, j>1$ indicate the patch token. The tasksignature vector $\\tau^t$ assigns scalar $s^t_j$ to image token $p_j$ to\nevaluate its task relevance:\n$p^t_j = s^t A_t(p_j) = s^t ReLU(p_jW_{down})W_{up}$,  (1)\n$s^t_j = <p_j, \\tau^t>, s^t = [s^t_j]_{j=0}^L$, (2)\nwhere, $p_j, \\tau^t$ represent normalized tensors $p_j = P_j/||P_j||_2,\n\\tau^t = \\tau^t/||\\tau^t||_2$, and $<\\cdot, \\cdot>$ represent the dot production.\nAfterwards, the output feature $o_j$ for token $p_j$ using one\nadapter $A^t$ can be calculated as follows:\n$o_j = MLP(p_j) + p^t_j + p_j$\n$= MLP(p_j) + s^t A_t (p_j) + p_j$. (3)\nFor incremental task $t>1$, the output feature $o_j^t$ of TSAI\nis integrated from multiple task-specific adapters ${A_i}_{i=1}^t$.\nWe use the softmax operation to normalize the scaling vector\n$[s_i^t]_{i=1}^t$ for patch token $p_j$, allowing the model to combine\nthe contributions from different adapters while maintaining\na balanced and stable output.\n$o_j^t = MLP(p_j) + \\sum_{i=1}^t s_i^t A_i(p_j) + p_j$\n$o = [o_j^t]_{i=1}^t \\quad \\hat{s} = [\\hat{s}_i^t]_{i=1}^t \\quad \\hat{s}_i^t = \\frac{e^{s_i^t}}{\\sum_{j=1}^t e^{s_j^t}}$, (5)\nwhere O is the output of TSAI for input X.\nAnalysis of knowledge of retention and reproduction:\nWe conducted an in-depth analysis of the parameter space\nfor each task-specific adapter, using matrix factorization\nto demonstrate that our proposed TSAI module can ef-fectively preserve and reproduce knowledge from previous\ntasks without needing exemplars from old tasks. In partic-ular, we start with no activation function to describe the\nknowledge retention mechanism under linear conditions and\nthen extend to nonlinear conditions. We provide a more de-tailed analysis in the supplementary material.\nTo avoid confusion, assume the input token is $p \\in R^m$\nand the adapter weight is $W = W_{down}W_{up} \\in R^{m\\times n}$, with\na matrix rank of r. The weight matrix can be decomposed\nthrough SVD without information loss:\n$W = Udiag(\\sigma)V, W = \\sum_i \\upsilon_i\\sigma_i v_i^T$, (6)\n$U = [u_i]_{i=1}^r \\in R^{n \\times m}, V = [v_i]_{i=1}^r \\in R^{r \\times n}$, (7)\nwhere diag($\\sigma$) is a diagonal matrix with singular values $\\sigma_i$\non the diagonal. U is an m \u00d7 r orthogonal matrix, with the\nsingular vectors $u_i$ as its columns. V is an r \u00d7 n orthogonal\nmatrix, with the singular vectors $v_i$ as its rows.\nthe output o can be formulated as:\n$o = A(p) = Wp = \\sum_i (u_i \\sigma_i v_i^T) p$\n$=\\sum_i v_i (u_i \\sigma_i p) = \\sum_i s_i v_i = V^T g(p)$ (8)\n$g(p) = diag(\\sigma) \\cdot U^*p = [s_i]_{i=1}^r \\in R^r$. (9)\nFrom the above derivation, we can observe that each task\nadapter allows the model to learn task-specific \"keys\" and\"values\" independent of the input features. The output o\nfor each input token p is obtained by weighting the task\nparameter space basis vectors $v_i$ through a linear function\n$g (\\cdot; U, diag(\\sigma))$ (a non-linear function when ReLU exists).\nTSAI ensures that the output o remains within the task sub-space, regardless of the input. We can leverage this property\nby designing appropriate loss functions to maintain feature\nconsistency under the NECIL setting."}, {"title": "Patch-Level Model Alignment", "content": "Due to the limitations of NECIL methods that do not store\nold class exemplars, mainstream methods do not perform\nmodel alignment or only align the classifier.\nBased on TSAI's knowledge retention and reconstruction\nability, as well as the rich information conveyed by patch\ntokens, we propose a patch-level distillation loss to main-tain feature consistency and a patch-level old class feature\nreconstruction method to align the classifier.\nPatch-Level Distillation Loss: To ensure that new tasks\ncan share and reuse old task knowledge while maintaining\nconsistent feature representations for old tasks, we propose\npatch-level distillation loss (PDL).\nAs shown in Fig.2 (b), during the training of task t, we\nobtain the output features $X^t$ and $X^o$ for the input image\nI from both the current model and the model trained on the\nprevious task t - 1.\n$X^o = [p_j^o]_{j=0}^L \\quad X^t = [p_j^t]_{j=0}^L \\in R^{(L+1) \\times d}$. (10)\nWe first compute the contribution of each patch token to\nthe learning of the new task based on the angular similarity:\n$\\alpha_{cos} = \\frac{p_o^T p_t}{||p_o||_2 ||p_t||_2}, \\alpha = \\frac{\\pi - arccos(\\alpha_{cos})}{\\pi}$, (11)\nhere, $\\alpha_{cos}$ and $\\alpha$ represent the cosine similarity and angu-lar similarity, respectively. We also conduct ablation experi-ments on different similarity metrics in Table 5.\nSecondly, we map patch tokens onto a hypersphere us-ing L2 normalization to ensure numerical stability. Then, we\nmeasure the feature drifts by calculating the distances be-tween the corresponding tokens on the hypersphere, as fol-lows:\n$D(p_o^t, p_j^t) = ||p_j^o - p_j^t||_2$. (12)\nWe allow greater flexibility for patch tokens that contribute\nsignificantly to new tasks. For patches that contribute less to\nnew tasks, we align their tokens with the output of the old\nmodel to maintain feature consistency with previous tasks.\nThus, the PDL loss function is defined as:\n$L_{pdl} = \\frac{1}{L} \\sum_{j=0}^L SG [\\alpha(p_o^t, p_j^t)] D(p_o^t, p_j^t)$, (13)\nwhere SG represents the stop gradient operation.\nPatch-Level Feature Reconstruction: As new incremental\ntasks are learned, the decision boundaries established from\nold tasks could be dramatically changed (Zhu et al. 2021b;"}, {"title": "Methods", "content": "Wang et al. 2023b). Towards this end, we propose a patch-level feature reconstruction method to generate old class fea-tures that adapt to the evolving model, providing better clas-sifier alignment.\nSpecifically, at each incremental task $t$, we compute and\nstore a class prototype $\\mu_k^t$ for each class k. When learning\nnew incremental tasks, we apply a normalized distance dif-ference $d(k,i,j)$ to measure the relevance between patch to-ken $P(i,j)$ and prototype $\\mu_k^t$, where $P(i,j)$ indicates the j-th\ntoken of X within the training batch.\n$\\delta(k,i,j) = \\frac{acos (\\mu_k^t, P(i,j)) - acos (P(i,0), P(i,j))}{acos (\\mu_k^t, P(i,j)) + Acos(P(i,0), P(i,j))}$, (14)\n$\\delta_i^{t}(k,i,j) = \\begin{cases}\n    0, & \\text{if } d(k,i,j) \\leq 0 \\\\\n    \\delta(k,i,j), & \\text{if } d(k,i,j) > 0\n\\end{cases}$, (15)\nWe retrieve the patch tokens p(i,j) whose $\\delta^t(k,i,j) > 0$\nand integrate them with prototype $\\mu$ using the exponen-tial moving average (EMA) (Morales-Brotons, Vogels, and\nHendrikx 2024) to generate old task feature $\\tilde{\\mu}$ as follows:\n$\\tilde{\\mu}_k^{t} = \\beta \\cdot \\mu_k + (1 - \\beta) \\sum_j w_{i,j}(i,j) p_{i,j}$,\n$[W(i,j)]_{i,j} = \\text{softmax} ((\\delta^t(k,i,j)]_{j=0}^l)$, $\\sum_j w_{i,j}(i,j) = 1$, (17)\nwhere $\\beta$ is a hyperparameter.\nIn each training batch, we randomly generate old task\nfeatures through our PFR and calibrate the classifier using\nthe CrossEntropy loss function as previous methods (Zhang"}, {"title": "Experiments", "content": "In this section, we first provide implementation details, then\npresent the experimental results with analyses, and finally\nshow ablation studies and visualization results. More de-tailed experimental results can be found in the supplemen-tary material.\nDataset: We conduct experiments on Cifar-100 (Krizhevsky\nand Hinton 2009), CUB-200 (Wah et al. 2011), ImageNet-R\n(Hendrycks et al. 2021a), and ImageNet-A (Hendrycks\net al. 2021b). These datasets contain typical CIL bench-marks and more challenging datasets with a significant\ndomain gap with ImageNet (i.e., the pre-trained dataset).\nThere are 100 classes in Cifar-100 and 200 classes in CUB,\nImageNet-R, and ImageNet-A. For all datasets, we follow\nthe class orders in (Zhou et al. 2024b).\nComparison methods: We compare our method with\nbenchmark PTM-based CIL methods in Table 1 and Table 3.\nWe divide them into three groups: (1) Prompt-based meth-ods: L2P (Wang et al. 2022c), DualPrompt (Wang et al.\n2022b), CODA-Prompt (Smith et al. 2023), CPrompt (Gao,\nCen, and Chang 2024), ConvPrompt (Roy et al. 2024),\nAdam-Prompt (Zhou et al. 2024a). (2) Adapter-based\nmethods: Adam-Adapter (Zhou et al. 2024a), EASE (Zhou\net al. 2024b), LAE (Gao et al. 2023), (3) Finetuning-based\nmethods: SLCA (Zhang et al. 2023), Adam-Ft (Zhou et al.\n2024a).\nTraining details: We adopt ViT-B/16 (Dosovitskiy et al.\n2020) as the pre-trained model, which is pre-trained on\nImageNet-21K (Russakovsky et al. 2015). The initial learn-ing rate is set to 0.025 and decays with cosine annealing. We\ntrain each task for 20 epochs with a batch size of 32 using\nNvidia 3090 GPUs with 24GB of RAM. The down projec-tion of adapters is set to 8 in our main experiments, indicated\nby DIA-r8 and the hyperparameter \u1e9e is set to 0.7.\nEvaluation metric: Following previous papers (Gao et al.\n2023; Zhou et al. 2024b), we denote the model's accuracy af-ter the t-th incremental task as $A^t$ and use $A^t = \\frac{1}{T}\\sum_{t=1}^T A^t$\nto represent the average accuracy over t incremental tasks.\nFor our evaluation, we specifically focus on two key mea-surements: $A_T$ (the accuracy after the final(T-th) incremen-tal task) and $\\bar{A^T}$ (the average accuracy across all T incre-mental tasks).\nComparison with SOTA Methods\nIn this section, we evaluate our proposed DIA method\non the ImageNet-R, ImageNet-A, CUB-200, and Cifar-100\ndatasets, equally dividing the classes into 10 incremental\ntasks. As shown in Table 1, our method achieves SOTA av-erage accuracies of 85.61%, 70.43%, 92.13%, and 94.29%\non four benchmark datasets, respectively.\nPrompt-based Methods: In comparison to prompt-based\napproaches, the proposed DIA demonstrates comprehen-sive improvements. When compared with the current SOTA\nmethod CPrompt (Gao, Cen, and Chang 2024), our DIA\nexhibits accuracy enhancements ranging from 1.76% to\n4.99% across all datasets. Moreover, the DIA-r08 requires\nfewer training parameters (merely 0.17M) and reduces the\nfloating-point operations (FLOPS) per image by 24.17%.\nConvPrompt (Roy et al. 2024) improves inference efficiency\nby introducing large language models. Our approach, how-ever, offers advantages in both computational efficiency and\naccuracy across all datasets, notably achieving 4.06% higher\naverage accuracy on ImageNet-R.\nAdapter-based Methods: In comparison to adapter-based\nmethods, our DIA still performs exceptionally well. Uti-lizing only 14.28% of the trainable parameters needed per\nincremental task, DIA-r08 outperforms EASE (Zhou et al.\n2024b) and Adam (Zhou et al. 2024a) across all benchmark\ndatasets. Moreover, DIA-r08 only needs 17.91B Flops to in-fer an image, reducing inference consumption by 90% com-pared to EASE (Zhou et al. 2024b) while improving ac-curacy. Specifically, DIA-r08 surpasses EASE (Zhou et al.\n2024b) by 3.88%, 5.09%, 1.62%, and 1.94% on ImageNet-R,\nImageNet-A, CUB-200, and Cifar-100, respectively. Our\nnotable improvements on ImageNet-R and ImageNet-A un-derscore that incorporating compositionality and leverag-ing knowledge from old tasks can significantly enhance the\nlearning of new classes that have a domain gap with the pre-trained data.\nFt-based Methods: Compared to finetuning-based meth-ods, our DIA not only achieves SOTA average accuracy\nacross four datasets but also saves 99.80% of the training\nparameters required per task compared to SLCA and Adam-"}, {"title": "Ablation Study", "content": "Component Analysis Our proposed DIA method consists\nof three main components: 1) Task-Specific Adapter Inte-gration (TSAI), 2) Patch-Level Distillation Loss (PDL), and\n3) Patch-Level Feature Reconstruction (PFR). To validate\nthe efficacy of each component, we conduct ablation exper-iments on two benchmark datasets: Cifar-100, which over-laps with the pre-training data, and ImageNet-R, which ex-hibits a domain gap from the pre-training data.\nThe first row in Table 2 shows the average and final accu-racy of the pre-trained image encoder with a learnable clas-sifier. The incorporation of the TSAI module yields perfor-mance comparable to SOTA methods on both Cifar-100 and\nImageNet-R datasets. This indicates that the patch-level in-tegration mechanism atop the adapter effectively reduces in-terference between new and old tasks while enhancing new\ntask learning, leading to substantial performance gains. TheMethods.This demonstrates that our proposed DIA strikes an ex-cellent balance between computational efficiency and per-formance.\nFeature Reconstruction Analysis: We investigate the im-pact of different old class feature reconstruction methods on\nclassifier alignment. As shown in Table 4, using a Gaussian\ndistribution to simulate old class features yields incremen-tal accuracies of only 93.51% and 93.79% on Cifar-100. In\ncontrast, our proposed PFR method, which leverages TSAI's\ncapability to retain old knowledge, achieves an average ac-curacy of 94.29%. This indicates that our PFR-based old\nfeature reconstruction method better adapts to the changes\nin old class features during the incremental process.\nWe also visualize the feature distributions of old classes\ngenerated by Gaussian sampling and compare them to the\nactual old class features on new tasks, as shown in Fig.3. In10th incremental task, we visualize the first 10 classes.\nFig.3 (a) shows features generated using a Gaussian distribu-tion, forming two distinct clusters with actual features, high-lighting a noticeable disparity. In contrast, Fig.3 (b) displays\nfeatures generated by PFR, which closely align with actual\nfeatures, forming a single cohesive cluster. This confirms the\neffectiveness of our proposed feature generation method and\ndemonstrates the DIA framework's ability to preserve and\nreproduce old knowledge.\nPDL ablation: We explore different similarity metrics to\nassess the contributions of patch tokens to new task learn-ing and analyze their impact on PDL. Specifically, we in-vestigate Euclidean distance (deu) (Zhai et al. 2024b), co-sine similarity (acos), and angular similarity (a) as shown\nin Table 5. The experimental results indicate that angular\nsimilarity yields the best performance, achieving SOTA re-sults across both datasets. In contrast, Euclidean distance\nperforms the worst, with a significant accuracy drop. We\nattribute this poor performance to the numerical instability\nof Euclidean distance, which is highly sensitive to varia-tions in numerical range and more prone to outliers. Addi-tionally, cosine similarity results in a slight performance de-cline, which occurs because it introduces negative loss val-ues, leading to the offsetting of losses between tokens."}, {"title": "Conclusion", "content": "In this paper, we propose a novel framework called Dynamic\nIntegration of task-specific Adapters (DIA), which con-sists of Task-Specific Adapter Integration (TSAI) and Patch"}]}