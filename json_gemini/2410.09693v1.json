{"title": "NEURAL SOLVER SELECTION FOR COMBINATORIAL \u039f\u03a1\u03a4\u0399\u039c\u0399\u0396\u0391TION", "authors": ["Chengrui Gao", "Haopu Shang", "Ke Xue", "Chao Qian"], "abstract": "Machine learning has increasingly been employed to solve NP-hard combinatorial optimization problems, resulting in the emergence of neural solvers that demonstrate remarkable performance, even with minimal domain-specific knowledge. To date, the community has created numerous open-source neural solvers with distinct motivations and inductive biases. While considerable efforts are devoted to designing powerful single solvers, our findings reveal that existing solvers typically demonstrate complementary performance across different problem instances. This suggests that significant improvements could be achieved through effective coordination of neural solvers at the instance level. In this work, we propose the first general framework to coordinate the neural solvers, which involves feature extraction, selection model, and selection strategy, aiming to allocate each instance to the most suitable solvers. To instantiate, we collect several typical neural solvers with state-of-the-art performance as alternatives, and explore various methods for each component of the framework. We evaluated our framework on two extensively studied combinatorial optimization problems, Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP). Experimental results show that the proposed framework can effectively distribute instances and the resulting composite solver can achieve significantly better performance (e.g., reduce the optimality gap by 0.88% on TSPLIB and 0.71% on CVRPLIB) than the best individual neural solver with little extra time cost. Our code is available at https://github.com/lamda-bbo/neural-solver-selection.", "sections": [{"title": "1 INTRODUCTION", "content": "Combinatorial Optimization Problems (COPs) involve finding an optimal solution over a set of combinatorial alternatives, which has broad and important applications such as logistics (Konstantakopoulos et al., 2022) and manufacturing (Zhang et al., 2019). To solve COPs, traditional approaches usually depend on heuristics designed by experts, requiring extensive domain knowledge and considerable effort. Recently, machine learning techniques have been introduced to automatically discover effective heuristics for COPs (Bengio et al., 2021; Cappart et al., 2023), leading to the burgeoning development of end-to-end neural solvers that employ deep neural networks to generate solutions for problem instances (Bello et al., 2017; Kool et al., 2019; Joshi et al., 2019). Compared to traditional approaches, these end-to-end neural solvers can not only get rid of the heavy reliance on expertise, but also realize better inference efficiency (Bello et al., 2017).\nTo enhance the capabilities of neural solvers, a variety of methods have been proposed, with intensive effort on the design of frameworks, network architectures, and training procedures. For example, to improve the performance across different distributions, Jiang et al. (2022) proposed adaptively joint training over varied distributions, and Bi et al. (2022) leveraged knowledge distillation to integrate the models trained on different distributions. For generalization on large-scale instances, Fu et al. (2021) implemented a divide-and-conquer strategy, Luo et al. (2023) proposed a heavy-decoder structure to better capture the relationship among nodes, while Gao et al. (2024)"}, {"title": "2 RELATED WORKS", "content": "Traditional approaches for COPs have achieved impressive results, but they often rely on problem-specific heuristics and domain knowledge by experts (Helsgaun, 2000; 2017). Instead, recent efforts focus on utilizing end-to-end learning methods. A prominent fashion is autoregression, which employs graph neural networks in an encoder-decoder framework and progressively extends a partial solution until a complete solution is constructed (Vinyals et al., 2015; Bello et al., 2017; Kool et al., 2019). However, these methods tend to exhibit poor generalization performance across distributions and scales (Joshi et al., 2022). To address the generalization issue, considerable efforts have been dedicated within the community. For example, Zhou et al. (2023) took various distributions and scales as different learning tasks and adopted meta-learning over them to obtain a generalizable model. Bi et al. (2022) leveraged knowledge distillation, where models trained on different distributions are utilized as teacher models for one generalizable student model. Liu et al. (2024) used the idea of prompt learning to realize zero-shot adaptation of the pertained model by selecting the most matched prompt for instances. More efforts in autoregressive methods include instance-conditioned adaptation (Zhou et al., 2024a), adversarial training (Wang et al., 2024) and nested local views (Fang et al., 2024), to name a few.\nAnother popular kind of end-to-end learning methods is non-regressive, which predicts or generates the distributions of potential solutions. Typically, Joshi et al. (2019); Ye et al. (2023) employed graph neural networks to predict the probability of components appearing in an optimal solution, represented with the form of heatmap. Diffusion models (Sun & Yang, 2023; Sanokowski et al., 2024) have also been adapted to generate the distribution of optimal solutions, demonstrating better expressiveness than classical push-forward generative models (Salmona et al., 2022)."}, {"title": "2.2 SOLVING COPS WITH MULTIPLE NEURAL SOLVERS", "content": "Recent studies have made preliminary attempts to integrate multiple neural solvers to enhance overall performance on COPs. For example, Jiang et al. (2023) adopted ensemble learning, where multiple neural solvers with identical architecture are trained on different instance distributions through Bootstrap sampling to ensure diversity. During inference, the outputs of all the solvers are gathered by average at each action step. Grinsztajn et al. (2023) proposed a population-based training method Poppy, where multiple decoders with a shared encoder are trained simultaneously as a population of solvers, with a reward targeting at maximizing the overall performance of the population. When solving a problem instance, each solver generates solutions independently, and the best solution is selected as the final result. However, these works suffer from heavy computation cost as multiple solvers have to be run for each instance. Even they propose to share a common encoder for each solver, experimental results still demonstrate undesired inference time (Grinsztajn et al., 2023). On the other hand, different solvers share the same neural architecture, which may limit the diversity and thus the final performance.\nConsider that the burgeoning community has proposed many methods from various perspectives, resulting in diverse end-to-end neural solvers with different inductive biases. Properly coordinating these neural solvers can potentially bring a significant improvement on overall performance. Motivated by the observation in Figure 1(a) and 1(b), we propose to select suitable ones from a pool"}, {"title": "3 THE PROPOSED FRAMEWORK", "content": "This section will introduce the proposed framework of coordinating neural solvers for COPs. In general, our target is learning to select the suitable solvers for each problem instance. To address this, our proposed framework comprises three key components:\n\u2022 Feature extraction: To select the most suitable neural solvers for each instance, it is essential to extract the instance features, which is challenging as the COPs are usually intricate. In this work, we first utilize the graph attention encoder (Kool et al., 2019) to encode COP instances, and further propose a refined graph encoder with pooling, which can leverage the hierarchical structures of COPs to obtain better features.\n\u2022 Selection model: We train a neural selection model with the graph encoder to identify the most suitable solvers. Specifically, we implement two loss functions from the perspectives of classification and ranking.\n\u2022 Selection strategies: Due to the complexity of COPs, it may be risky to rely solely on the selection model to consistently identify the most suitable solver. To address this, we propose compromise strategies that allow to allocate multiple solvers (if necessary) to a single instance based on the confidence levels of the selection model, pursuing better performance with limited extra cost.\nIn the following subsections, we will elaborate the three key components in our framework."}, {"title": "3.1 FEATURE EXTRACTION", "content": "For feature extraction, it depends on the COP to be solved. Here, we use the two most prevailing problems, TSP and CVPR, in the neural solver community for COPs (Kwon et al., 2020; Luo et al., 2023; Drakulic et al., 2023) as examples, which will also be employed in our experiments. TSP and CVRP involve finding optimal routes over a set of nodes. For TSP, the objective is to find the shortest possible route that visits each node exactly once and returns to the starting node. Each TSP instance consists of nodes distributed in Euclidean space. For CVRP, the goal is to plan routes for multiple vehicles to serve customer nodes with varying demands, starting and ending at a depot node, while minimizing the total travel distance and satisfying vehicle capacity constraints (Dantzig & Ramser, 1959). Both TSP and CVRP instances can be represented as fully connected graphs, where nodes correspond to locations (cities or customers). The graph representation makes them suitable for encoding using Graph Neural Networks (GNNs), which can effectively capture the structural information inherent in these problems (Khalil et al., 2017; Kool et al., 2019). In this paper, we design two types of GNN-based encoders tailored for TSP and CVRP instances as follows.\nWe take the CVRP as an example to describe the computation of the graph encoder. The raw features $x \\in \\mathbb{R}^{N\\times3}$ of a CVRP instance are a set of nodes $\\{(x_i, Y_i, m_i)|i \\in [N]\\}$, where $(x_i, Y_i)$ are the node coordinates, $m_i$ is the node demand, $N$ is the number of nodes, and $[N]$ denotes the set $\\{1,2,..., N\\}$. First, a linear layer is employed on every node for initial node embeddings, i.e., $H^0 = xW$, where $W \\in \\mathbb{R}^{3\\times d}$ are the weights and $d$ denotes the embedding dimension. Given initial embeddings, multiple graph attention layers (Veli\u010dkovi\u0107 et al., 2018; Kool et al., 2019) are applied to iteratively update the node embeddings as $H^l = AttentionLayer(H^{l-1})$, where $l \\in [L]$ and $L$ is the number of layers. Since the graphs of TSP and CVRP are both fully connected, the graph attention layer covers every pair of nodes and self-connections, which becomes similar to the self-attention mechanism (Vaswani et al., 2017). Details of the attention layer are provided in Appendix A.1. Finally, the node embeddings output by the last layer are averaged to form the instance representation, as most COP encoders (Khalil et al., 2017; Kool et al., 2019) did."}, {"title": "3.2 SELECTION MODEL", "content": "We employ a Multiple-Layer Perception (MLP) to predict compatibility scores of neural solvers, where a higher score indicates that it is more suitable to allocate the instance to the corresponding neural solver. This MLP model takes the instance representation and the instance scale N as input and outputs a score vector, where the value of each index is the score of the corresponding neural solver. In summary, the graph encoder and the MLP are cascaded to compose a neural selection model, which can produce the compatibility scores of individual solvers from the raw COP instance in an end-to-end manner. Advanced neural solver features can be incorporated for richer information, as discussed in Section 5. However, we find that even using fixed indices of neural solvers has already been effective, which will be clearly shown in our experiments."}, {"title": "3.3 SELECTION STRATEGIES", "content": "Considering that the intricate structures of COPs may pose great challenge to the selection model, besides greedy selection, we propose several compromise strategies that allow multiple solvers for a single instance based on the confidence level of the selection model, aiming to improve the overall performance with little extra cost.\nThe most straightforward approach is the greedy selection, which chooses the neural solver with the highest score. This method is efficient since only one solver is executed per instance. However, it may be inaccurate, potentially leading to sub-optimal performance.\nThe top-k selection method can be adopted for better optimality, where we select and execute the neural solvers with top-k scores for each instance, thus constructing a portfolio of multiple solvers. This approach increases the likelihood of including the optimal solver but incurs additional computational overhead due to the execution of multiple solvers.\nTo balance efficiency and effectiveness, we propose the rejection-based selection strategy, which adaptively selects greedy or top-k selection. Recognizing that the confidence of the greedy selection varies across instances, an advanced strategy is to employ the top-k selection for low-confidence instances to enhance performance and utilize only the greedy selection for high-confidence ones to minimize computational cost. To implement this strategy, we can use a confidence measure to determine whether to accept or reject the greedy selection. If the confidence in the greedy selection is below a threshold, we reject it and apply the top-k selection to the instance for improved optimality. In this paper, we adopt the simple yet effective softmax response (Hendrycks & Gimpel, 2017) as the confidence measure, and define the threshold by rejecting a certain fraction of test instances with the lowest confidence levels.\nWe further propose a top-p selection strategy that selects the smallest subset of solvers whose normalized scores (i.e., selection probabilities) sum up to at least p. The value of p is predefined or adjusted according to the time budget. Thus, this strategy adaptively determines the number of selected neural solvers by covering a certain amount of probability mass, rather than relying on a fixed number k."}, {"title": "4 EXPERIMENTS", "content": "To examine the effectiveness of our proposed selection framework, we conduct experiments on TSP and CVRP, investigating the following Research Questions (RQ): RQ1: How does the proposed selection framework perform compared to individual neural solvers? RQ2: How does the proposed selection framework perform when the problem distribution shifts and the problem scale increases? RQ3: How do different implementations of components affect the performance of the framework? We introduce the experimental settings in Section 4.1 and investigate the above RQs in Section 4.2. The code and data used in our experiments are provided in the supplementary materials."}, {"title": "4.1 EXPERIMENTAL SETTINGS", "content": "We generate synthetic TSP and CVRP instances by sampling node coordinates from Gaussian mixture distributions with randomized covariance matrices. In the case of CVRP, vehicle capacities are generated using either the scale-related capacity or the triangular distribution. We consider varying problem scales, where the scale N is sampled uniformly from [50, 500]. More details of the data generation process are provided in Appendix A.2.\nFor training, we generate 10,000 TSP and CVRP instances and apply 8-fold instance augmentation (Kwon et al., 2020). For test, we generate smaller synthetic datasets comprising 1,000 instances. Figures 1(a) and 1(b) in Section 1 are based on results from the CVRP test dataset. To evaluate the out-of-distribution performance, we utilize two well-known benchmarks with more complex problem distributions and larger problem scales (up to $N = 1002$): TSPLIB (Reinelt, 1991) and CVRPLIB Set-X (Uchoa et al., 2017). For TSPLIB, we select a subset of instances with $N \\le 1002$, and CVRPLIB Set-X includes instances ranging from $N = 100$ to $1000$. These problem scales are larger than the scale $N\\in [50, 500]$ of our training datasets.\nWe choose recent open-source neural solvers with state-of-the-art performance as the candidates, including Omni (Zhou et al., 2023), BQ (Drakulic et al., 2023), LEHD (Luo et al., 2023), DIFUSCO (Sun & Yang, 2023), T2T (Li et al., 2023), ELG (Gao et al., 2024), INVIT (Fang et al., 2024) and MVMoE (Zhou et al., 2024b). Greedy decoding is used for all the methods to avoid stochasticity. We set the pomo size to 100 and the augmentation number to 8 for the methods based on POMO (Kwon et al., 2020). The number of denoising steps is set to 50 and the number of 2-opt iterations is set to 100 for diffusion-based methods. These individual solvers constitute a neural solver zoo. Ideally, if we can always select the best solver from the zoo for each instance, the optimal performance is achieved, which is also the performance upper bound of our selection model. Considering that some neural solvers contribute little to the overall performance, we iteratively eliminate the least contributive solver from the candidates, resulting in a more compact neural solver zoo. This process reduces the zoo size to 7 solvers for TSP and 5 for CVRP. Further details of the elimination procedure are provided in Appendix A.3.\nFor the graph attention encoder, we set the number of layers to 4. For the hierarchical graph encoder, we use 2 blocks where each block has 2 attention layers. The embedding dimension is set to 128. Other hyperparameters of encoders can be found in Appendix A.1. The Adam optimizer (Kingma & Ba, 2015) is employed for training, where we set the learning rate to $1 \\times 10^{-4}$ and the weight decay to $1 \\times 10^{-6}$. The number of epochs is set to 50. The final model is chosen according to the performance on a validation dataset with 1,000 synthetic instances. We train 5 selection models using different random seeds and report the mean and standard deviation of their performance. For the top-k strategy, we set k = 2. For the rejection-based strategy, we reject the 20% of instances with the lowest confidence levels (i.e., the highest selection probability of all individual solvers), and apply top-2 selection to these rejected instances. For the top-p strategy, we set p = 0.5 for TSP and p = 0.8 for CVRP.\nFollowing previous studies, we employ the gap to the best-known solution $\\frac{C_I(\\hat{\\sigma}) - C_I(\\sigma^*)}{C_I(\\sigma^*)}$ as the performance metric, called optimality gap, where $\\hat{\\sigma}$ is the solution obtained by each method, $\\sigma^*$ is the best-known solution computed by extensive search of expert solvers (Helsgaun, 2017; Vidal, 2022), and $C_I(\\cdot)$ is the cost function of problem instance $I$. We also report the average time to evaluate efficiency, which includes both the running of neural solvers and selection."}, {"title": "4.2 EXPERIMENTAL RESULTS", "content": "In Table 1, we present the performance of several implementations of our selection framework on synthetic TSP and CVRP, alongside the results of the top-3 individual neural solvers*. We can observe that all implementations of our framework outperform the best neural solver on both TSP and CVRP, demonstrating the effectiveness of our framework. For example, using ranking loss and the top-k selection strategy with k = 2, our framework achieves average optimality gaps of 1.51% on TSP and 4.82% on CVRP, surpassing the best individual solver's gaps of 2.33% on TSP and 6.82% on CVRP, achieved by DIFUSCO and Omni, respectively. Moreover, except utilizing the top-k strategy, our selection framework is nearly as efficient as running a single solver. In some cases, our framework can obtain better optimality gaps while consuming even less time. For instance, using ranking loss and greedy selection on TSP leads to the average optimality gap 1.86% with 1.33s, while the best individual solver DIFUSCO achieves 2.33% gap with 1.45s. In Table 1, OPT (the fourth row) denotes the optimal performance for selection, which is obtained by running all individual solvers for each instance and selecting the best one. The best optimality gaps achieved by our selection framework (using ranking loss and top-k selection with k = 2) are close to OPT, with gaps of 1.51% on TSP and 4.81% on CVRP, compared to OPT's gaps of 1.24% on TSP and 4.64% on CVRP. Furthermore, our framework can offer significant speed advantages over OPT, e.g., consuming an average time of 2.56s on TSP, whereas OPT requires an average time of 8.93s. Note that complete results for all individual solvers are provided in Appendix A.10.\nThe top-k strategy enhances the performance by running a selected subset of the solver zoo for each instance, which certainly costs more time than individual solvers. For a fair comparison, we benchmark our top-k selection method against a solver portfolio of the same size k. We construct this solver portfolio by exhaustively enumerating all possible subsets of size k and selecting the one with the best overall performance. As shown in Appendix A.5, our top-k selection consistently outperforms the size-k solver portfolio across k = {1,2,3,4} on all datasets, i.e., TSP, CVRP, TSPLIB and CVRPLIB Set-X, demonstrating the effectiveness of our selection model."}, {"title": "How does the proposed selection framework perform when the problem distribution shifts and the problem scale increases?", "content": "We evaluate the generalization performance on two benchmarks, TSPLIB and CVRPLIB Set-X, which contain out-of-distribution and larger-scale instances. As shown in Table 2, all implementations of our selection framework generalize well, where the ranking model using top-k selection improves the optimality gap by 0.88% (i.e., 1.95%-1.07%) on TSPLIB and by 0.71% (i.e., 6.10%-5.39%) on CVRPLIB Set-X, compared to the best individual solvers T2T and ELG on these two benchmarks. These results show that our selection framework is robust against the distribution shifts and increases in problem scale."}, {"title": "How do different implementations affect performance?", "content": "We evaluate and compare different implementations of the three components in our framework:\nWe compare the manual features (Smith-Miles et al., 2010) (see Appendix A.4), graph attention encoder Kool et al. (2019), and hierarchical graph encoder in Table 3. All methods are trained using ranking loss, and we report the optimality gap with greedy selection. As shown in Table 3, even the simplest manual features perform well, achieving better results than the best individual solver across three datasets - TSP, CVRP, and TSPLIB. This further validates the effectiveness of our selection framework. Comparing the third and fourth columns, we observe that the graph attention encoder consistently outperforms manual features on all datasets, verifying the superiority of learned features. Furthermore, by comparing the fourth and fifth columns, we find that while the graph attention encoder has already been effective on synthetic datasets, introducing the hierarchical encoder can further improve generalization performance on out-of-distribution datasets, TSPLIB and CVRPLIB Set-X, which is quite important in practice. This enhanced generalization capability may be attributed to the hierarchical encoder's ability to leverage the inherent hierarchical structures in COPs. More ablation studies of the hierarchical encoder are provided in Appendix A.6."}, {"title": "5 CONCLUSION AND DISCUSSIONS", "content": "In this paper, we propose a general framework for neural solver selection for the first time, which can effectively select suitable solvers for each instance, leading to significantly better performance with little additional computational time, as validated by the extensive experiments on two well-studied COPS, TSP and CVRP. We hope this preliminary work can open a new line for the topic of neural combinatorial optimization. Within the proposed selection framework, we preliminarily investigate several implementations of the three key components: Feature extraction, training loss functions, and selection strategies. Techniques such as hierarchical graph encoder, ranking loss, rejection-based selection, and top-p selection notably enhance overall performance. Beyond the techniques presented, we discuss several promising avenues for further research under this framework.\nIn our implementation, we only extracted features for problem instances and used fixed indices for neural solvers, which assumes a static neural solver zoo and can not directly utilize any newly added neural solver during deployment. To enable zero-shot generalization to unseen neural solvers, it is essential to construct a smooth feature space for solvers, where those with similar preferences and biases are positioned closely together. Here we design a preliminary method for extracting features of neural solvers to facilitate generalization to unseen solvers. This method is based on the insight that a neural solver's preferences can be characterized by representative instances where it significantly outperforms other solvers. For each neural solver, we sort those instances where it performs the best in an ascending order according to the ratio of the objective value that the solver obtains to the runner-up objective value, and select top 1% as its representative instances. Each representative instance is then treated as a token, and we apply a transformer to learn a summary feature from these instance tokens, which serves as the feature representation of the neural solver. Detailed implementations and results are provided in Appendix A.9. The results show that the preliminary method enables generalization to unseen neural solvers, where adding an extra solver can improve the selection performance.\nFurthermore, advanced neural solver features should provide richer and deeper information than only using instance features to increase the capacity of the selection model. However, our preliminary method is based on the representative instances and fails to provide deeper information into the solvers' internal mechanisms. For future improvements, some approaches may be worth exploring, such as utilizing large language models to encode the code of neural solvers (Wu et al., 2024) or learning neural representations from their trained parameters (Kofinas et al., 2024), which can access internal solver information, and potentially improving selection performance.\nIn this paper, since the average runtime of most individual neural solvers is short (approximately 1-2 seconds), we ignored their time difference during the training of the selection model, and only used the objective values obtained by the neural solvers as supervision information (by classification or ranking). However, if there are some time-consuming learn-to-search solvers, such as NeuOpt (Ma et al., 2021; 2023) and local reconstruction methods (Kim et al., 2021; Ye et al., 2024), in the solver pool, the runtime should be considered in the performance ranking. In such cases, developing a runtime-aware selection method to balance computational time and solution optimality would be necessary. To address this, we could penalize"}]}