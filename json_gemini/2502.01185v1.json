{"title": "Deep Active Speech Cancellation with Multi-Band Mamba Network", "authors": ["Yehuda Mishaly", "Lior Wolf", "Eliya Nachmani"], "abstract": "We present a novel deep learning network for Active Speech Cancellation (ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively canceling both noise and speech signals. The proposed Multi-Band Mamba architecture segments input audio into distinct frequency bands, enabling precise anti-signal generation and improved phase alignment across frequencies. Additionally, we introduce an optimization-driven loss function that provides near-optimal supervisory signals for anti-signal generation. Experimental results demonstrate substantial performance gains, achieving up to 7.2dB improvement in ANC scenarios and 6.2dB in ASC, significantly outperforming existing methods. Audio samples are available at this link.", "sections": [{"title": "1. Introduction", "content": "Active Noise Cancellation (ANC) is a critical audio processing technique aimed at eliminating unwanted noise by generating an anti-noise signal (Lueg, 1936; Nelson & Elliott, 1991; Fuller et al., 1996; Hansen et al., 1997; Kuo & Morgan, 1999). ANC has practical applications in improving hearing devices for individuals with hearing impairments and reducing chronic noise exposure, thereby mitigating hearing loss risks. It also enhances focus, productivity, and listening experiences while reducing stress. Traditional ANC algorithms, like LMS and its deep learning variants (Zhang &\nWang, 2021; Park et al., 2023; Mostafavi & Cha, 2023; Cha\net al., 2023; Pike & Cheer, 2023; Singh et al., 2024), have\nbeen widely adopted. However, these methods face limitations when dealing with more complex and high-frequency audio signals, as they are primarily designed to target noise.\nThis paper addresses Active Speech Cancellation (ASC),\nwhich expands upon ANC by targeting the cancellation of\nboth noise and speech signals. To our knowledge, this is\nthe first work to actively cancel both noise and speech using\ndeep learning, setting it apart from existing methods and\nenabling new research directions.\nWe propose a novel Multi-Band Mamba architecture, which\npartitions input signals into frequency bands, enabling pre-\ncise anti-signal generation for improved phase alignment\nand cancellation. This design is particularly effective for\nspeech signals, as it accounts for their broader frequency\nspectrum, including high frequencies often under-addressed\nby other methods. Coupled with an optimization-driven loss\nfunction, this approach achieves improved performance in\ndynamic acoustic scenarios. Results demonstrate up to a\n7.2 dB improvement in ANC and a 6.2 dB gain in ASC\nfor speech signals, outperforming deep-learning based base-\nlines, which are considered state-of-the-art in the field."}, {"title": "2. Related Work", "content": "Active Noise Cancellation: The concept of ANC was first\nintroduced by Lueg (Lueg, 1936), focusing on sound oscil-\nlation cancellation. Given that ANC algorithms must adapt\nto variations in amplitude, phase, and noise source move-\nment (Nelson & Elliott, 1991; Fuller et al., 1996; Hansen\net al., 1997; Kuo & Morgan, 1999), most ANC algorithms\nare based on the Least Mean Squares (LMS) algorithm\n(Burgess, 1981), which is effective in echo cancellation.\nThe FxLMS (Filtered-x LMS) algorithm extends LMS by\nusing an adaptive filter to account for distortions in the pri-\nmary and secondary paths. Boucher et al. (1991) analyzed\nerrors in FxLMS due to inaccuracies in estimating the sec-\nondary path inverse, where nonlinear distortions degrade\nperformance. Several methods address these issues: the\nFiltered-S LMS (FSLMS) (Das & Panda, 2004) algorithm\nuses a Functional Link Artificial Neural Network (FLANN)\n(Patra et al., 1999) to handle nonlinearity, while the Volterra\nFiltered-x LMS (VFXLMS) (Tan & Jiang, 2001) employs\na multichannel structure. The Bilinear FxLMS (Kuo &\nWu, 2005) improves nonlinearity modeling, and the Leaky\nFxLMS (Tobias & Seara, 2005) introduces a leakage term\nto mitigate overfitting. The Tangential Hyperbolic Function-\nbased FxLMS (THF-FxLMS) (Ghasemi et al., 2016) mod-\nels saturation effects for enhanced performance. Gannot &\nYeredor (2003) proposed blind source separation for noise\ncancellation. Moreover, Oppenheim et al. (1994) proposed"}, {"title": "3. Method", "content": "Backgorund The signal processing framework of a typi-\ncal feedforward ANC system is detailed, emphasizing the\nroles of the primary and secondary acoustic paths. In such\nsystems, reference and error microphone are utilized to gen-\nerate a canceling signal that minimizes unwanted noise. The\nprimary path P(z) represents the acoustic transfer function\nfrom the noise source to the error microphone, while the\nsecondary path S(z) represents the acoustic transfer func-\ntion from the loudspeaker to the error microphone. The\nsignal captured by the reference microphone is denoted as\nx(n), while the signal captured by the error microphone is\ndenoted as e(n). These signals are fed into the ANC con-\ntroller, which generates a canceling signal y(n). The cancel-\ning signal is then played through a loudspeaker, referred to\nas fLS, producing fLS{y(n)}, which aims to suppress the\nunwanted noise near the error microphone. The loudspeaker\noutput fLS{y(n)}, after passing through the secondary path\nS(z), generates the anti-signal denoted by a(n). The rela-\ntionship is described by the following equation:\n$$a(n) = S(z) * fLS{y(n)}$$\nSimilarly, the reference signal x(n), transmitted through the\nprimary path P(z), produces the primary signal denoted by\nd(n), which is expressed as:\n$$d(n) = P(z) * x(n)$$\nThe error signal e(n), defined as the difference between the\nprimary signal d(n) and the anti-signal a(n), is defined as:\n$$e(n) = d(n) - a(n)$$"}, {"title": "3.1. DeepASC Architecture", "content": "Let x(n) be the reference signal such that 1 \u2264 n \u2264 M. The\nreference signal x(n) is decomposed into Q \u2208 N different\nfrequency bands x\u2081 (n), . . ., xq (n). These frequency bands\nare evenly divided such that for the maximum frequency F,\nthe i-th frequency band xi(n) covers the frequency range\n[(i - 1), ] where 1 \u2264 i \u2264 Q. In addition to the decom-\nposed bands, the original full-band signal x(n) is included\nas xo(n). Each band xi(n) (where 0 \u2264 i \u2264 Q, the zero\nindex is for the entire unfiltered band) is then processed\nthrough its own Mamba-Band block (MB-block). Each MB-\nblock comprises an encoder and a masking network that\nutilize Mamba-based layers. Within each MB-block, the\nencoder consists of a one-dimensional convolution layer Ei\nwith a kernel size k and a stride of k/2. The encoder trans-\nforms the i-th reference signal xi (n) into a two-dimensional\nlatent representation:\n$$Hi = Ei [xi]$$\nwhere H\u2081 \u2208 RB\u00d7C', with B Mk +1, C representing the\nnumber of channels after the convolution operator and xi is\nthe vector representation of xi(n) . The latent representation\nHi is then passed through the Mamba-based layers Bi to\nproduce the i-th masking signal Mi :\n$$Mi = Bi [Hi]$$\nThe MB-blocks estimates Q + 1 masks of the same latent\ndimension M\u2081 \u2208 RB\u00d7C. These masks are element-wise\nmultiplied with the encoder outputs Hi to produce masked\nhidden representations H\u2081:\n$$H\u2081 = H Mi$$\nThen, the masked hidden representations H\u00bf is concatenated\nover all frequency bands i, such that:\n$$H = concat [Ho, ..., HQ]$$\nWhere H ER(Q+1)\u00d7B\u00d7C. The hidden tensor H is then\nprocessed with a 2D convolution layer with a kernel size\nof 1 \u00d7 1 and one output channel that produces K \u2208 RB\u00d7C."}, {"title": "3.2. Optimization Objective", "content": "The training protocol for the proposed method consists of\ntwo distinct phases: (i) ANC loss minimization, and (ii) near\noptimal anti-signal optimization. Each phase employs the\nNMSE loss function (Eq. 4) but with different optimization\nobjectives.\nANC Loss: In the first phase, the optimization aims to\nminimize the residual error signal. Given a reference signal\nx(n) and the model output y(n), the error loss function is\ndefined as follows:\n$$LANC = NMSE [P * x, S * FLS{y}]$$\nwhere P and S represent the vectorized forms of the primary-path impulse response P(z) and the secondary-path impulse\nresponse S(z), respectively; x and y are the vectorized\nforms of the reference signal x(n) and the canceling signal\ny(n). The operator * denotes convolution. Both P and S are\nobtained from the simulator employed in our study.\nNear Optimal Anti-Signal Optimization (NOAS): A key\nchallenge in formulating ANC as a supervised learning prob-\nlem is defining a training objective that accounts for the\ncharacteristics of the secondary path S(z) and the primary\npath P(z). In an ANC algorithms, the output y(n) is pro-\ncessed by a nonlinearity function fLS and then propagated\nthrough the secondary path S(z). The training objective\naims to minimize the error signal e(n), which represents the\nresidual noise after cancellation.\nHowever, this process becomes problematic when the sec-\nondary path S(z) attenuates certain frequencies that are\npresent in the primary signal d(n). Under the vanilla loss\nfunction (e.g., Eq. 10), the model can be unfairly penalized\nfor high error signals in these attenuated frequency bands,\neven when it has generated an optimal anti-signal. This oc-\ncurs because the secondary path inherently suppresses these\nfrequencies, leading to residual energy in the error signal\ne(n). As a result, the training process encounters discrepan-\ncies that hinder the model's ability to learn effectively.\nTo address this challenge, we propose the NOAS loss func-\ntion. The NOAS loss symmetrically incorporates the sec-\nondary path S(z) on both sides of the NMSE calculation.\nBy doing so, it ensures that any frequencies nullified by\nS(z) are also excluded from the target, thereby mitigating\nthe contribution of these frequencies to the error signal.\nSpecifically, each reference signal x(n) is associated with\nits NOAS target y*(n). To determine the near-optimal anti-signal y* (n), we employ a gradient descent-based algorithm\nduring a pre-processing stage. This stage operates over each\nexample, solving the following optimization problem for\neach reference signal x(n):\n$$y* = arg min NMSE [P * x, S * FLS{F}]$$\nwhere y* is the near-optimal anti-signal. The optimization\nstarts with a random anti-signal and iteratively adjusts it to\nminimize the NMSE for the given reference signal x(n).\nThe resulting near-optimal anti-signal y*(n) is then used\nto form the target during the fine-tuning stage. In particu-\nlar, the near-optimal anti-signal y* (n) is used to define the\nfollowing loss function:\n$$LNOAS = NMSE [S * fLS{y*}, S * fLS{y}]$$\nNote that the optimization occurs in the S-projected space,\nrather than directly in the canceling signal space (i.e.\nNMSE [y*, y]). The S projection ensures consistency and\nleverages prior knowledge from the initial training phase.\nFurthermore, it is necessitated by the nature of convolu-\ntion, which is not a injective operation. As a result, multi-\nple distinct instances, denoted as y1,..., yn, may satisfy\nS * FLS{1} = = S * fLS{yn}. Consequently, even if\na trained model satisfies S * fLS{y} \u2248 P * x, it does not\nnecessarily follow that y \u2248 y*. This phenomenon is further\ncorroborated by the results in Table 1, which report NMSE\nmeasurements on audio samples from the train set. Prior to\nNOAS fine-tuning, the NMSE between [y*, y] is -9.85 dB,\nwhile the NMSE between [P * x, S * y] and [S * y*, S * y]\nare -16.53 dB and -18.53 dB, respectively.\nNotably, the NMSE between [S * y*, S * y] is the lowest.\nThis result aligns with the intuition that S * y* serves as\nfeasible optimization target for S * y, unlike P * x, which is\nconstrained by frequency limitations, as discussed earlier. A\nvisual intuition for this phenomenon is provided in Figure 3."}, {"title": "4. Experiments and Results", "content": "Datasets: The training data is sourced from the AudioSet\ndataset (Gemmeke et al., 2017), which we encompassed 248"}, {"title": "4.1. Noise Cancellation", "content": "Table 2 presents the NMSE for ANC algorithms across three\nnoise types-engine, factory, and babble-using 3-second\nsignal segments extracted from the NOISEX-92 dataset. For\neach noise type, the models were evaluated both without\nnonlinear distortions (where \u03b7\u00b2 = \u221e) and with nonlinear\ndistortions at n\u00b2 = 0.1 and n\u00b2 0.5. In the case of non-\ndeep learning-based methods, namely FxLMS and THF-\nFxLMS, gradient clipping at le 4 was applied due to\nthe sensitivity of these algorithms to the step size, which\ncaused instability during validation. The step sizes for these\nmethods were set to 0.05 for engine noise, 0.4 for factory\nnoise, and 0.3 for babble noise. The results indicate that\nthese algorithms perform suboptimally compared to deep\nlearning-based approaches.\nAmong the deep learning-based methods, and without con-sidering the nonlinearity saturation effect, the proposed\nDeepASC method achieves state-of-the-art results. Specifi-cally, for the case where n\u00b2 = \u221e it improves performance\nover the ARN method by 4.29 dB, 4.64 dB, and 7.26 dB\nfor engine, factory, and babble noise, respectively. In the\npresence of nonlinear distortions (\u03b7\u00b2 = 0.5), DeepASC con-tinues to outperform ARN, with improvements of 4.36 dB,\n4.62 dB, and 7.13 dB for engine, factory, and babble noise,\nrespectively. For more severe nonlinearity (\u03b7\u00b2 = 0.1), Deep-ASC still surpasses ARN with gains of 3.79 dB, 4.4 dB, and\n5.76 dB. Figures 4a, 4b, and 4c offer visual comparisons of\nthe different methods by plotting NMSE over time. These\nfigures illustrate that the proposed DeepASC method consis-tently achieves superior NMSE performance compared to\nARN, DeepANC, and FxLMS across almost every timestep.\nThe proposed method was also evaluated for speech en-hancement in the presence of noise using active noise can-cellation. The PESQ and STOI metrics, presented in Table\n4, compare the performance of DeepANC, ARN, and Deep-ASC (w/o NOAS) across various SNR levels in the presence\nof factory noise with nonlinear distortion of n\u00b2 = \u221e. The\nresults demonstrate that DeepASC outperforms ARN, show-ing improvements in PESQ scores by 0.7, 0.92, and 0.84\nat SNR levels of 5dB, 15dB, and 20dB, respectively. A\nsimilar trend is observed for STOI, with enhancements of\n0.08, 0.03, and 0.02 for the same SNR levels."}, {"title": "4.2. Speech Cancellation", "content": "Table 3 presents the average NMSE values for different\nANC algorithms across three speech datasets: TIMIT, Lib-riSpeech, and WSJ, with speech segments affected by vary-ing levels of nonlinear distortions. It is evident that speech\ncancellation is a more challenging task compared to noise\ncancellation, as reflected in the performance degradation of\nthe different algorithms.\nAs observed in the noise cancellation case, in speech cancel-lation, the non-deep learning methods-FxLMS and THF-FxLMS-demonstrate suboptimal performance compared\nto deep learning-based approaches. Among the deep learn-ing methods, DeepASC achieves the best overall results,\nsurpassing the other algorithms significantly.\nIn the case without nonlinear distortions (n\u00b2 = \u221e), Deep-ASC shows improvements over ARN by 6.13 dB, 4.78 dB,\nand 5.95 dB for the TIMIT, LibriSpeech, and WSJ datasets,\nrespectively. In the presence of moderate nonlinear distor-"}, {"title": "4.3. Real-World Simulation", "content": "We expanded our investigation to assess the performance of\nour method in real-world settings, testing it across various\nsimulation scenarios. This was necessary because the fixed\ntask acoustic setup, which relies on the image method, has\nlimitations regarding generalizability and real-world perfor-mance. We utilized the dataset from (Liebich et al., 2019),\nwhich includes acoustic paths from 23 individuals, mea-sured in the real world and encompassing both primary and\nsecondary paths. We applied DeepASC, along with baseline\napproaches, to the updated simulation conditions, evalu-ating their performance using Factory and Babble noise\nfrom the NoiseX-92 dataset and speech samples from the\nWSJ dataset. The results in Table 5 present the average\nNMSE across these categories. The results demonstrate that\nDeepASC consistently outperforms the alternative methods,\nachieving improvements of 2.80dB in the Factory noise,\n2.70dB in the Babble noise, and 1.53dB on the WSJ dataset."}, {"title": "4.4. Model Analysis", "content": "The number of frequency bands in the DeepASC archi-tecture is a critical hyperparameter affecting performance.Table 6 compares DeepASC's performance across differ-ent band configurations for the Factory noise, TIMIT, Lib-riSpeech, and WSJ datasets, with n\u00b2 = 0.5. The \"1-band\"models use a single full band, while the \"3-band\" and \"4-band\" models incorporate one medium band with two and\nthree smaller sub-bands, respectively. A 2-band model,which would require two full bands, was excluded as it falls\noutside the intended design of DeepASC.\nAs shown in Table 6, increasing the number of bands im-proves model performance. For example, the 4-band config-uration outperforms the 3-band variation by 0.58 dB, 0.19\ndB, 0.37 dB, and 0.48 dB on the Factory noise, TIMIT, Lib-riSpeech, and WSJ datasets, respectively. This enhancement\ncomes from the model's improved focus on sub-frequencybands, benefiting higher frequencies."}, {"title": "5. Conclusion", "content": "In this paper, we introduced a novel ASC approach using the\nMulti-Band Mamba architecture. By partitioning audio into\nfrequency bands, our method enhances anti-signal genera-\ntion and phase alignment. Combined with an optimization-\ndriven loss function, it achieves near-optimal performance,\nimproving both ANC and ASC outcomes. Our experimental\nresults demonstrate a significant performance boost com-\npared to state-of-the-art baselines, with improvements of\n7.2dB in ANC and 6.2dB in ASC for voice audio signals.\nThese results confirm the multi-band architecture's effective-ness in handling diverse frequencies and real-world acoustic\nenvironments, where traditional methods often fail. Our\napproach addresses key challenges in the field by effectively\nleveraging frequency decomposition and optimization-based\nanti-signal generation, paving the way for more advanced\naudio cancellation technologies."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field\nof Machine Learning. There are many potential societal"}, {"title": "A. Overview of an ANC System", "content": "To elucidate the acoustic dynamics of ANC systems in in-ear\nheadphones, Figure 6 presents a schematic representation\nof the Primary and Secondary acoustic paths.\nThe primary path P(z) characterizes the transfer function\nbetween the external noise, as captured by the reference\nmicrophone, and the error microphone. This path mod-\nels the propagation of ambient noise through the system.\nConversely, the secondary path S(z) represents the transfer\nfunction from the loudspeaker to the error microphone, en-compassing the acoustic feedback loop within the ear canal.\nThe schematic highlights the interaction between critical\nsystem components, including the processing unit, reference\nmicrophone, error microphone, and loudspeaker."}, {"title": "B. Ablation Study", "content": "To assess the contributions of the key components in the\nDeepASC architecture, we conducted an ablation study\nfocusing on multiband processing, band size (small vs.\nmedium), and the impact of NOAS optimization. Table\n9 presents the results of this analysis, reporting the NMSE\nacross four datasets: Factory, TIMIT, LibriSpeech, and WSJ,\nall evaluated under nonlinear distortion conditions (n\u00b2 =\n0.5).\nIn our notation, \"+ S - Multiband - NOAS\" refers to a small\nband configuration (8 mamba layers) without multiband\nprocessing or NOAS optimization, while \"+ S - Multiband\n+ NOAS\" refers to the same small band architecture with\nNOAS optimization applied. Similarly, \"+ M - Multiband -\nNOAS\" represents a medium band configuration (16 mamba\nlayers) without NOAS, and \"+ M - Multiband + NOAS\" ap-plies NOAS optimization to the same medium band model.\nThe Full Method is defined as a configuration that employs\none full medium band and two small sub-bands, with NOAS\noptimization applied.\nAll models were initially trained using the ANC loss func-\ntion defined in Eq. 10. Configurations with \"+ NOAS\"\nwere fine-tuned using NOAS optimization, whereas con-figurations with \"- NOAS\u201d were trained exclusively using\nthe ANC loss in Eq. 10. The results demonstrate that the\nremoval of NOAS optimization consistently degrades per-formance across all datasets. For instance, on the Factory\ndataset, applying NOAS optimization to the small band\nmodel leads to a performance improvement of 0.73dB,\nwhile the medium band model shows a larger improvement\nof 0.90dB. This trend holds across the other datasets, rein-forcing the crucial role of NOAS optimization in enhancingmodel performance. Multiband processing further improvesthe overall effectiveness of DeepASC. For example, the Full\nMethod consistently outperforms the \"+ M - Multiband +\nNOAS\" configuration, with gains of 0.14dB, 0.2dB, 0.16dB,\nand 0.2dB on the Factory, TIMIT, LibriSpeech, and WSJ\ndatasets, respectively. Interestingly, the performance of the\n\"+ S - Multiband - NOAS\" configuration is consistentlylower than that of the \"+ M - Multiband - NOAS\" variantacross all datasets. Specifically, the small band model under-performs by 1.73dB on Factory, 1.56dB on TIMIT, 1.68dBon LibriSpeech, and 1.66dB on WSJ. This indicates that\nwhile multiband processing is valuable, the choice of bandsize plays a significant role in the model's performance, withlarger band sizes, particularly when combined with NOAS,yielding the best results."}]}