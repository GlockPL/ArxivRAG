{"title": "Hypergraph-based Motion Generation with Multi-modal Interaction Relational Reasoning", "authors": ["Keshu Wu", "Yang Zhou", "Haotian Shi", "Dominique Lord", "Bin Ran", "Xinyue Ye"], "abstract": "The intricate nature of real-world driving environments, characterized by dynamic and diverse interactions among multiple vehicles and their possible future states, presents considerable challenges in accurately predicting the motion states of vehicles and handling the uncertainty inherent in the predictions. Addressing these challenges requires comprehensive modeling and reasoning to capture the implicit relations among vehicles and the corresponding diverse behaviors. This research introduces an integrated framework for autonomous vehicles (AVs) motion prediction to address these complexities, utilizing a novel Relational Hypergraph Interaction-informed Neural mOtion generator (RHINO). RHINO leverages hypergraph-based relational reasoning by integrating a multi-scale hypergraph neural network to model group-wise interactions among multiple vehicles and their multi-modal driving behaviors, thereby enhancing motion prediction accuracy and reliability. Experimental validation using real-world datasets demonstrates the superior performance of this framework in improving predictive accuracy and fostering socially aware automated driving in dynamic traffic scenarios.", "sections": [{"title": "1. Introduction", "content": "Understanding traffic interactions and the way they affect future vehicle trajectories is inherently complex [1]. In mixed traffic environments, where human-driven and automated vehicles coexist, this complexity is amplified, requiring precise interaction representation and behavior modeling for reliable motion prediction [2, 3, 4]. These scenarios often present dynamic interaction topologies with underlying relations, with interaction patterns as well topologies continuously evolving depending on the surrounding context as exampled by lane change maneuvers [5, 6]. These relationships play a crucial role in guiding each vehicle's decision-making processes. Additionally, each vehicle can display multiple possible modalities in driving intentions and behaviors, including both longitudinal (e.g., acceleration and braking) and lateral (e.g., lane-changing and lane-keeping) maneuvers [7, 8]. Furthermore, collective behaviors, arising from interactions within a group of vehicles and encompassing both cooperative and competitive behaviors [9, 10, 12, 11], further complicate the understanding of these interactions[13, 14, 15]. Figure 1 describes the interaction among multi-vehicles and the corresponding multi-modal driving behaviors. Therefore, it is necessary to model the interaction and multi-modality and reason the interaction relation to accurately capture interactions and forecast their future behaviors [16, 17, 18].\nEfforts have been made to address the challenges of vehicle interactions and driving behavior multi-modality. Three primary approaches have been developed: social operation methods, attention-driven methods, and graph-based techniques. Social operations use pooling mechanisms to generate socially acceptable trajectories by capturing the influence of surrounding agents [20, 21]. Attention-driven approaches use attention mechanisms to dynamically weigh neighboring agents' information [22, 23, 24]. Graph-based methods leverage graph structures to model non-Euclidean spatial dependencies, effectively handling varying interaction topologies and predicting dynamic interactions [25, 26, 27, 28]. These complex interactions create uncertainty, complicating the accurate forecasting of a single future trajectory with high confidence due to varying driving behaviors in identical situations [29, 30], driven by individual driver characteristics and psychological factors. Addressing the multi-modality of driving behaviors often involves introducing latent variables, categorized into those with explicit semantics and those without. Models with explicit semantics use latent variables to clearly represent driving intentions, identifying"}, {"title": "2. Problem Statement", "content": null}, {"title": "2.1. Problem Definition", "content": "The vehicle trajectory prediction in the dynamic realm of multi-vehicle interaction context of multi-lane highways involves determining the future movements of a target vehicle based on historical data and multi-modal predictions of its own state and the states of surrounding vehicles. This domain addresses two primary challenges: (i) multi-agent multi-modal trajectory prediction and (ii) prediction-guided motion generation after reasoning.\nThe objective of trajectory prediction is to estimate the future trajectories of the target vehicle and its surrounding vehicles, given their historical states. The historical states, spanning a time horizon [1,...,T], are represented as $\\mathbf{X}_{1:T} = \\{\\mathbf{X}_1, \\mathbf{X}_2, ..., \\mathbf{X}_T\\} \\in \\mathbb{R}^{T \\times N \\times C_1}$, where $N$ denotes the number of vehicles and $C_1$ denotes the number of features, including longitudinal and lateral positions and velocities. Each historical state $\\mathbf{X}_t = \\{\\mathbf{x}_i | \\forall i \\in [1, N], \\forall t \\in [1, T]\\} \\in \\mathbb{R}^{C_1}$ at time step $t$ captures these details for each vehicle $i$. Notably, the superscript refers to vehicle indices with $i = 1$ representing the target vehicle, and the subscript to time steps, with $C_1 = 4$ for the input data.\nThe prediction model, $H^{Pred}(\\cdot)$, provides preliminary predictions of multi-modal trajectory candidates $\\mathcal{M} \\mathbf{X}_{T+1:T+F}^{M} \\in \\mathbb{R}^{F \\times N \\times M \\times C_2}$ for all the $N$ vehicles over the future time horizon $[T+1, ..., T+F]$ with $M$ modes of driving behaviors. This model takes historical data $\\mathbf{X}_{1:T}$ as the input and outputs future longitudinal and lateral positions, where $C_2 = 2$. The forecasted states $\\mathcal{M} = \\{\\mathbf{x}_{i,m}^f | \\forall m \\in [1, M], \\forall i \\in [1, N], \\forall f \\in [1, F]\\}$ aim to estimate each vehicle's future trajectory for each behavior mode $m$ at time step $T + f$. This is mathematically formulated as:\n$$\n\\mathbf{X}_{T+1:T+F}^{M} = H^{Pred}(\\mathbf{X}_{1:T})\n$$\nBased on that, the motion generation model $H^{Gen}(\\cdot)$ is further developed to generate plausible trajectories considering the implicit group-wise interactions, using both historical states $\\mathbf{X}_{1:T}$ and preliminary multi-modal future trajectory candidates $\\mathbf{X}_{T+1:T+F}^{M}$ as the input. The generation model provides $K$ plausible trajectory $\\hat{\\mathbf{Y}} = \\{\\mathbf{Y}_{T+1:T+F}^{k_1}, ..., \\mathbf{Y}_{T+1:T+F}^{k_K}\\} \\in \\mathbb{R}^{F \\times N \\times K \\times C_2}$ for all the $N$ vehicles for the next $F$ time steps. Each generated state $\\hat{\\mathbf{Y}}_{T+f}^k = \\{\\hat{\\mathbf{y}}_{i,T+f}^k | \\forall k \\in [1, K], \\forall i \\in [1, N], \\forall f \\in [1, F]\\} \\in \\mathbb{R}^{C_2}$"}, {"title": "3. Methodology", "content": "Given the aforementioned problem, we first develop a customized framework architecture. Then, the vital components are further elaborated."}, {"title": "3.1. Framework Architecture", "content": "The proposed framework adopts an integrated architecture, as shown in Figure 3, which involves two major components:\n\u2022 GIRAFFE: Graph-based Interaction-awaRe Anticipative Feasible Future Estimator, which leverages graph representations to capture pair-wise interactions during both the historical and future time horizons, providing preliminary multi-modal trajectories prediction candidates for vehicles.\n\u2022 RHINO: Relational Hypergraph Interaction-informed Neural mOtion generator, which utilizes multi-scale hypergraph representations to model group-wise interactions and reason the interaction relations among the multi-modal behaviors. Built upon the preliminary multi-modal trajectories by GIRAFFE, RHINO will further generate plausible future trajectories for all vehicles in a probabilistic manner.\nThe subsequent sections will provide an in-depth explanation of the two principal frameworks."}, {"title": "3.2. GIRAFFE: Graph-based Motion Predictor", "content": "In our context, a graph representation $\\mathcal{G}$ is adopted by modeling $N$ vehicles as nodes $\\mathbf{V} \\in \\mathbb{R}^N$ and the pair-wise interaction as the edges $\\mathcal{E} \\in \\mathbb{R}^{N \\times N}$. Further, The feature matrix $\\mathbf{X} \\in \\mathbb{R}^{N \\times C}$ containing vehicle states (i.e., longitudinal and lateral position and speed) and the adjacency matrix $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ describing the interactions among nodes are further utilized to describe the graph. By that, we can define an Agent Graph as:\nDefinition 1 (Agent Graph). Let $\\mathcal{G}^a$ be a graph representing the motion states and interaction of $N$ agents, with each agent represented as a node. $\\mathcal{G}^a$ is expressed as\n$$\n\\mathcal{G}^a = (\\mathbf{V}^a, \\mathcal{E}^a; \\mathbf{X}^a, \\mathbf{A}^a)\n$$\nwhere $\\mathbf{V}^a \\in \\mathbb{R}^N$ denotes the node set, $\\mathcal{E}^a \\in [\\mathbb{R}^{N \\times N}]$ denotes the edge set, $\\mathbf{X}^a \\in \\mathbb{R}^{N \\times C}$ represents the feature tensor, $\\mathbf{A}^a \\in \\mathbb{R}^{N \\times N}$ indicates the adjacency matrix.\nTo better represent the interaction and relations of the predicted multi-agent multi-modal trajectory candidates with graphs, we expand each agent node to multiple nodes of the number of behavior modes based on our previous work [25], which further renders an Agent-Behavior Graph."}, {"title": "Definition 2 (Agent-Behavior Graph).", "content": "Let $\\mathcal{G}^b$ be a graph representation of the multi-modal motion states of $N$ agents, with each of $M$ behavior modes for each agent represented as a node. $\\mathcal{G}^b$ is expressed as\n$$\n\\mathcal{G}^b = (\\mathbf{V}^b, \\mathcal{E}^b; \\mathbf{X}^b, \\mathbf{A}^b)\n$$\nwhere $\\mathbf{V}^b \\in \\mathbb{R}^{|MN|}$ denotes the node set, $\\mathcal{E}^b \\in \\mathbb{R}^{|MN \\times MN|}$ denotes the edge set, $\\mathbf{X}^b \\in [\\mathbb{R}^{|MN| \\times C}$ represents the feature tensor, $\\mathbf{A}^b \\in [\\mathbb{R}^{|MN| \\times |MN|}$ indicates the adjacency matrix.\nThe transition from an Agent Graph $\\mathcal{G}^a$ to an Agent-Behavior Graph $\\mathcal{G}^b$ is by an expansion function $F^{expand}(\\cdot)$ as:"}, {"title": "Definition 3 (Agent Hypergraph).", "content": "Let $H^a$ be a hypergraph representation of the motion states of $N$ agents, with each agent represented as a node. The hypergraph $H^a$ is expressed as\n$$H^a = (\\mathbf{V}^a, \\mathbf{U}^a; \\mathbf{X}^a, \\mathbf{H}^a)$$\nwhere $\\mathbf{V}^a \\in \\mathbb{R}^N$ denotes the node set, $\\mathbf{U}^a \\in \\mathbb{R}^L$ denotes the edge set, $\\mathbf{X}^a \\in \\mathbb{R}^{N \\times C}$ represents the feature tensor, $\\mathbf{H}^a \\in \\mathbb{R}^{N \\times L}$ indicates the incidence matrix, where $\\mathbf{H}^a_{ij}$ indicates whether node $v_i$ is part of the hyperedge $u_j$.\nTo convert an Agent Graph $\\mathcal{G}^a$ into an Agent Hypergraph $H^a$, we introduce a transformation function $F^{transform}(.)$. This function enables the shift from a pairwise interaction framework to a higher-order interaction model represented by the hypergraph. Formally, the transformation is expressed as:"}, {"title": "Definition 4 (Agent-Behavior Hypergraph).", "content": "Let $\\mathcal{H}^b$ be a hypergraph representation of the multimodal motion states of $N$ agents, with each of $M$ behavior modes for each agent represented as a node. The hypergraph $\\mathcal{H}^b$ is expressed as\n$$\\mathcal{H}^b = (\\mathbf{V}^b, \\mathbf{U}^b; \\mathbf{X}^b, \\mathbf{H}^b)$$\nwhere $\\mathbf{V}^b \\in \\mathbb{R}^{|MN|}$ denotes the node set, $\\mathbf{U}^b \\in \\mathbb{R}^L$ denotes the edge set, $\\mathbf{X}^b \\in \\mathbb{R}^{|MN| \\times C}$ represents the feature tensor, $\\mathbf{H}^b \\in \\mathbb{R}^{|MN| \\times L}$ indicates the incidence matrix, where $\\mathbf{H}^b_{ij}$ indicates whether node $v_i$ is part of the hyperedge $u_j$.\nTo formally describe the process of transitioning from an Agent Hypergraph $H^a$ to an Agent-Behavior Hypergraph $\\mathcal{H}^b$, the expansion function $F^{expand}(.)$ is applied. This function decomposes each agent node into multiple behavior-specific nodes and updates the hyperedge structure accordingly. The behavior-specific nodes correspond to the different behavior modes, while the hyperedges represent the higher-order interactions among the behavior modes of different agents."}, {"title": "3.3.1. RHINO Framework Architecture", "content": "The core of RHINO is to learn a multi-scale Agent-Behavior Hypergraph, where nodes represent the behaviors of agents and hyperedges capture their group-wise interactions. This hypergraph is then used to learn agent and interaction embeddings to better understand the underlying interaction relations. We also incorporate a basic multi-agent trajectory generation system based on the CVAE framework to handle the stochasticity of each agent's potential behaviors and motion states, generating plausible trajectories for each vehicle.\nThus, as illustrated in Figure 7, RHINO comprises the following modules:\n\u2022 Hypergraph Relational Encoder, which transforms both the original historical states and predicted multi-agent multi-modal trajectories into hypergraphs, modeling and reasoning the underlying relation between the vehicles.\n\u2022 Posterior Distribution Learner, which captures the posterior distribution of the future trajectory given the historical states and the predicted multi-modal future motion states of all the vehicles in the vehicle group."}, {"title": "3.3.2. Hypergraph Relational Encoder", "content": "We employ two Hypergraph Relational Encoder modules: a Historical Hypergraph Relational Encoder for handling historical states and a Future Hypergraph Relational Encoder for predicted multi-agent multi-modal trajectories from GIRAFFE. For the Historical Hypergraph Relational Encoder, the input historical states $\\mathbf{X}_T$ form an Agent Hypergraph $\\mathcal{H}^a$. For the Future Hypergraph Relational Encoder, the predicted multi-agent multi-modal trajectories $\\mathbf{X}_{T+1:T+F}$ form an Agent-Behavior Hypergraph $\\mathcal{H}^b$, where each agent node is expanded into three lateral behavior nodes with corresponding predicted future states. Both modules share the same structure regardless of the input hypergraph types."}, {"title": "3.3.3. Posterior Distribution Learner", "content": "In our study, we incorporated multi-scale hypergraph embeddings into a multi-agent trajectory generation system using the CVAE framework [46] to address the stochastic nature of each agent's behavior, as shown in Figure 10. Here, we denote the historical trajectories $\\mathbf{X}_{1:T}$ as $\\mathbf{X}_T$, and denote the predicted future trajectories $\\mathbf{X}_{T+1:T+F}$ as $\\mathbf{X}_F$. Let log $p(\\mathbf{X}_F | \\mathbf{X}_T)$ denote the log-likelihood of predicted future trajectories $\\mathbf{X}_F$ given historical trajectories $\\mathbf{X}_T$. The corresponding Evidence Lower Bound (ELBO) is defined as follows:"}, {"title": "3.3.4. Motion Generator", "content": "The Motion Generator's objective is dual: to predict future trajectories and to reconstruct past trajectories from the given embeddings. The decoder accomplishes this by applying successive processing blocks, each contributing a residual that refines the trajectory estimates, as shown in Figure 11. The first processing block, $F_{Res1}$, takes the output embeddings $\\mathcal{V}^p$ and the target past trajectory $\\mathbf{X}_T$ to generate initial estimates of the future and reconstructed past trajectories $\\mathbf{X}_{F,1}$ and $\\mathbf{X}_{T,1}$ respectively.\n$$\\mathbf{X}_{F,1}, \\mathbf{X}_{T,1} = F_{Res1}(\\mathcal{V}^p, \\mathbf{X}_T)$$\nSubsequently, the second block, $F_{Res2}$, refines these estimates by considering the output embeddings and the residual of the past trajectory, which is the difference between the target past trajectory and the initial reconstructed past trajectory $\\mathbf{X}_T - \\mathbf{X}_{T,1}$. This results in the second set of residuals $\\mathbf{X}_{F,2}$ and $\\mathbf{X}_{T,2}$:\n$$\\mathbf{X}_{F,2}, \\mathbf{X}_{T,2} = F_{Res2}(\\mathcal{V}^p, \\mathbf{X}_T - \\mathbf{X}_{T,1})$$\nBoth $F_{Res1}$ and $F_{Res2}$ are composed of a GRU encoder for sequence encoding and two MLPs serving as the output header. The final predicted future trajectory $\\hat{\\mathbf{Y}}_F$ and the reconstructed past trajectory $\\hat{\\mathbf{X}}_T$ are obtained by summing the respective residuals from both processing blocks:"}, {"title": "4. Experiments and Results", "content": null}, {"title": "4.1. Data Preparations", "content": "This research leverages two open-source datasets for the purpose of model training and validation: the Next Generation Simulation (NGSIM) dataset [47],[48] and the HighD dataset [49]. The NGSIM dataset provides a comprehensive collection of vehicle trajectory data, capturing activity from the eastbound I-80 in the San Francisco Bay area and the southbound US 101 in Los Angeles. This dataset encapsulates real-world highway scenarios through overhead camera recordings at a sampling rate of 10Hz. The HighD dataset originates from aerial drone recordings executed at a 25 Hz frequency between 2017 and 2018 in the vicinity of Cologne, Germany. Spanning approximately 420 meters of bidirectional roadways, it records the movements of approximately 110,000 vehicles, encompassing both cars and trucks, traversing an aggregate distance of 45,000 km. After data pre-processing, the NGSIM dataset encompasses 662 thousand rows of data, capturing 1,380 individual trajectories, while the HighD dataset comprises 1.09 million data entries, including 3,913 individual trajectories. For the purpose of training and evaluation of the model, the partition of the data allocates 70% to the training set and 30% to the test set. For the temporal parameters of the model, we adopt $T = 30$ frames to represent the historical horizon and $F = 50$ frames to signify the prediction horizon."}, {"title": "4.2. Training and Evaluation Metrics", "content": null}, {"title": "Training loss of GIRAFFE.", "content": "The training loss function for GIRAFFE is a summation of three terms:"}, {"title": "Training loss of RHINO.", "content": "The training loss function for RHINO is also a summation of three components:"}, {"title": "5. Conclusions", "content": "In this study, we proposed a hypergraph enabled multi-modal probabilistic motion prediction framework with reasonings. This framework consists of two main components: GIRAFFE and RHINO. GIRAFFE focuses on predicting the interactive vehicular trajectories considering modalities. Based on that, RHINO, leveraging the flexibility and strengths on modeling the group-wise interactions, facilitate relational reasoning among vehicles and multi-modalities to render plausible vehicles trajectories. The framework extends traditional interaction models by introducing an agent-behavior hypergraph. This approach better aligns with traffic physics while being grounded in the mathematical rigor of hypergraph theory. Further, the approach employs representation learning to enable explicit interaction relational reasoning. This involves considering future relations and interactions and learning the posterior distribution to handle the stochasticity of behavior for each vehicle. As a result, the framework excels in capturing high-dimensional, group-wise interactions across various behavioral modalities.\nThe framework is tested using the NGSIM and HighD datasets. The results show that the proposed framework effectively models the interactions among groups of vehicles and their corresponding multi-modal behaviors. Comparative studies demonstrate that the framework outperforms prevailing algorithms in prediction accuracy. To further validate the effectiveness of each component, ablation studies were conducted, revealing that the full model performs best.\nSeveral potential extensions of the framework include incorporating road geometries, vehicle types, and real-time weather data to improve trajectory prediction. By integrating weather information from sources like the OpenWeather API, the system could adjust predictions based on conditions such as temperature, wind, and precipitation, enhancing safety and route optimization [51]. Additional enhancements, like traffic signal integration, V2V and V2I communication, and human driver intent, could further improve accuracy and reliability in dynamic urban environments, minimizing disruptions and fostering safer, more informed autonomous driving."}]}