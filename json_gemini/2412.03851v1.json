{"title": "FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems", "authors": ["Jiechao Gao", "Yuangang Li"], "abstract": "Personalized medication aims to tailor healthcare to individual patient characteristics. However, the heterogeneity of patient data across healthcare systems presents significant challenges to achieving accurate and effective personalized treat-ments. Ethical concerns further complicate the aggregation of large volumes of data from diverse institutions. Federated Learn-ing (FL) offers a promising decentralized solution by enabling col-laborative model training through the exchange of client models rather than raw data, thus preserving privacy. However, existing FL methods often suffer from retrogression during server aggre-gation, leading to a decline in model performance in real-world medical FL settings. To address data variability in distributed healthcare systems, we introduce Federated Meta-Learning for Personalized Medication (FedMetaMed), which combines feder-ated learning and meta-learning to create models that adapt to diverse patient data across healthcare systems. The FedMetaMed framework aims to produce superior personalized models for individual clients by addressing these limitations. Specifically, we introduce Cumulative Fourier Aggregation (CFA) at the server to improve stability and effectiveness in global knowledge aggregation. CFA achieves this by gradually integrating client models from low to high frequencies. At the client level, we implement a Collaborative Transfer Optimization (CTO) strategy with a three-step process-Retrieve, Reciprocate, and Refine-to enhance the personalized local model through seamless global knowledge transfer. Experiments on real-world medical imaging datasets demonstrate that FedMetaMed outperforms state-of-the-art FL methods, showing superior generalization even on out-of-distribution cohorts.", "sections": [{"title": "I. INTRODUCTION", "content": "To fully unlock the potential of precision medicine, it is essential to establish interoperability and broad accessibility of extensive medical datasets for researchers [1]. However, the current landscape poses significant challenges, as medical data are fragmented across numerous institutions, making centralized access and aggregation nearly impossible [2]. These challenges are not primarily technical-transferring heterogeneous data across organizations is feasible-but are instead rooted in legal and regulatory barriers [3]. Transferring patient-level data beyond healthcare providers is a complex, time-consuming process due to stringent legal and regulatory requirements. Given the scarcity and biased distribution of medical data, there is an increasing call for collaborative data sharing among medical institutions to enhance model perfor-mance in critical tasks like disease diagnosis [4]. Federated learning (FL) has emerged as a promising solution, enabling the use of distributed data sources while preserving privacy. In FL, instead of transmitting raw data, clients-represented by various devices or locations-share gradients of their locally trained model parameters with a central server. The server then performs a weighted aggregation of these gradients to update the global model, which is subsequently distributed back to all clients for further training iterations [5], [6].\nWhile federated learning leverages data from multi-ple clients, its performance struggles with heterogeneous datasets [7], as real-world data from different clients often focus on different tasks [8]\u2013[10]. Federated learning also faces scalability issues, as increased participants lead to communica-tion bottlenecks. Additionally, privacy concerns are heightened due to the sensitive nature of medical data, requiring robust protections during collaborative model training. Balancing collaboration effectiveness with strict privacy measures is a significant challenge in healthcare and addressing these scal-ability and privacy issues is essential for federated learning's successful integration into medical research and diagnostics, emphasizing the need for continued innovation in this space.\nIn real-world medical Federated Learning (FL) scenarios, variations in client data from different imaging devices, pro-tocols, and regional disease characteristics create disparities between local models [11]. This causes performance drops af-ter each communication cycle, as aggregated models lose prior knowledge and require re-adaptation during local training, disrupting effective knowledge sharing [12]. The decline in FL performance in these settings stems from two main factors. First, severe data diversity makes element-wise parameter averaging ineffective because parameters from different clients may represent different semantic patterns [13]. Representing parameters in the frequency domain allows for better align-"}, {"title": "II. RELATED WORK", "content": "Deep learning has shown exceptional potential in health-care, from activity recognition to personalized health models. However, centralized data collection is often impractical due to privacy concerns, as data is generated by numerous individuals and organizations reluctant to share sensitive information. FedAvg [14] has emerged as a solution, where locally trained models are averaged across clients, treating each as an inde-pendent and heterogeneous entity, while enabling collaborative healthcare applications such as identifying patients with sim-ilar clinical profiles.\nTo address varying data distributions among clients, Fed-Prox [15] introduced a proximal term to align local updates with the initial global model. Researchers like Brisimi et al. [16] have incorporated adaptation techniques into federated models to improve performance, while approaches like FedBN [17] and SiloBN [18] tackle feature shifts by preserving local batch normalization parameters, allowing each client to handle unique data distributions effectively. Personalized FL, which lets clients choose between the aggregated server model and intermediate client models during training, is particularly useful for medical applications.\nFrameworks such as FedHealth [19] for wearable health-care devices and FED-ROD [20] for balancing generalization and personalization demonstrate the versatility of federated methods in healthcare. Personalized FL approaches, though promising, often face limitations due to communication costs and server dependencies. Otoum et al. [21] analyzed data from various hospitals to identify patient phenotypes while keeping data siloed by hospital. Results showed that federated learning, which preserves data locality, achieved comparable accuracy and phenotype insights to a centralized model, thus safeguarding privacy [22]. Chen et al. [23] presented MetaFed, a framework that enables trustworthy Federated Learning (FL) across diverse federations without a central server. Using Cyclic Knowledge Distillation, MetaFed creates personalized models through two phases: common knowledge accumulation and personalized model refinement.\nAlthough several federated learning methods have been used in initial studies with clinical data, they tend to neglect the typ-ical challenges seen in analyzing biomedical datasets. Medical data has distinct characteristics due to ethical, legal, and social factors, along with imbalances in phenotype prevalence and cohort sizes."}, {"title": "III. METHODOLOGY", "content": "Federated learning leverages the combined computational power of diverse clients while preserving user privacy, en-abling model training across varied datasets. However, its effectiveness decreases when faced with heterogeneous data from different clients. To address this, we propose combining federated learning with meta-learning to create an adaptable model capable of handling diverse tasks. Meta-learning al-lows us to train a model that adapts to heterogeneous data, while federated learning facilitates training across decentral-ized datasets. By merging these principles, we introduce FedMetaMed-an adaptive federated learning framework de-signed for success with varied medical datasets. In standard federated learning, model parameters are aggregated, whereas in federated meta-learning, losses from multiple tasks are integrated. FedMetaMed utilizes this adaptive approach to optimize training across heterogeneous client data.\nIn our customized regression-resistant framework, our ob-jective is to collectively create a personalized model p with su-perior performance for each of the N models. These individual models $x_n$ (for n ranging from 1 to N) share the same network structure, allowing them to benefit from server aggregation, which is similar to previous federated learning approaches. For the nth model, the personalized model $I_n$ is trained locally with private data for Lepochs and then uploaded to the server. The server gathers the client models and combines them into server model, incorporating the high-frequency components unique to each client, using our FedMetaMed technique. Subsequently, these server models are transmitted"}, {"title": "A. Cumulative Fourier Aggregation", "content": "Our CFA (Cumulative Frequency Aggregation) is moti-vated by the observation that the low-frequency components of network parameters play a crucial role in determining the network's capability. To leverage this insight, our approach combines the relatively low-frequency components of data points from different clients to share knowledge, while retain-ing the high-frequency components that may contain client-specific information.\nSpecifically, in the case of a convolutional layer belonging to the nth client model, we begin by reshaping its parameter tensor $w_n \u2208 R^{A\u00d7B\u00d7c_1\u00d7c_2}$ into a 2-D matrix $w_n \u2208 R^{c_1A\u00d7c_2B}$ where A and B denote the output and input channels respectively, and $c_1$ and $c_2$ represent the spatial dimensions of the kernel. Next, we employ the Fourier transform to obtain the amplitude map $F_b$ and the phase map $F_q$, resulting in $F = F_b e^{iF_q}$. The procedure can be summarized as follows:\n$\\mathcal{F}(w_n)(a, b) = \\sum_{(i,j)} (w_n)(i, j) e^{-i \\frac{2\\pi}{N} (ai+bj)}, q^2 = -1$ (1)\nWe can efficiently implement the given process by utilizing the fast fourier transform. In order to gather the low-frequency elements for agglomeration, we utilize a low-frequency mask A. This mask mainly consists of zero values, except for the main region:\n$N(a,b) = 1_{(a,b) \\in [-sc_1A : s c_1A, -sc_2B : sc_2B]}$ (2)\nThe low-frequency threshold, denoted as s \u2208 (0,0.5) defines the range, and the center of $w_n$ is positioned at the coordinates (0,0). By taking the average of the low-frequency elements across all clients, the combined frequency components for the n-th client are computed as:\n$F_k(w_n) = (1 - M) \\cdot F_k(w'_n) + \\frac{1}{N} \\sum_{n=1}^N MF_k(w_n)$, (3)\nIn light of the fact that networks are typically trained to acquire low-frequency knowledge before high-frequency infor-mation, we propose a cumulative approach for implementing our CFA. This involves gradually increasing the value of $s = s_0 + (\\frac{s_1-s_0}{T}) * t$ during FL training, where $s_0$ and $s_1$ represents the initial and final low-frequency thresholds.\nAfter performing the inverse Fourier transform $\\mathcal{F}^{-1}$ on the amplitude and phase maps to revert them back to parameters, we achieve the aggregated parameters of the nth client as $w_n = \\mathcal{F}^{-1}([F_k(w_n), F_r(w_n)])$. Additionally, the identical"}, {"title": "B. Collaborative Transfer Optimization", "content": "Our CFA can mitigate the setback caused by clustering on the server, but when we directly update client models with the combined server parameters, it erases the acquired local knowledge and further worsens the optimization process in the next iteration. To address this issue, we introduce Collaborative Transfer Optimization (CTO), which tactfully merges exhaustive knowledge with local expertise instead of simply replacing it. Alongside an individualized local model q, each client also includes a client model c to receive the combined parameters from the server. The FedMetaMed CTO consists of three steps: Retrieve, Reciprocate, and Refine, to seamlessly transfer the exhaustive knowledge from the client c to the personalized local model q."}, {"title": "C. Retrieve", "content": "Upon receiving the aggregated model s from the server, the client c experiences a significant decline in performance caused by the aforementioned retrogress issue. Consequently, our initial approach involves utilizing the personalized local model q as a teacher to restore the client model c using its local knowledge. During this phase, the personalized local model q is guided by the cross entropy loss, while the client model c is optimized using a joint loss function $L_c$\n$L_c = L_{en} + \\sum_{j=1}^M q(y_i)log(\\frac{q(y_i)}{r(y_i)})$ (4)\nIn the given expression, $y_i$ represents the $i^{th}$ training sample, and M denotes the total number of training samples on the current client. The loss function used is $L_{en}$, which corre-sponds to cross-entropy. The terms q(yi) and r(yi) refer to the posterior probabilities of the client c and the personalized local model q, respectively. The second part of Equation 4 represents the Kullback-Leibler (KL) divergence, which aids the client c in swiftly recovering adaptability while enhancing performance. This particular step is crucial to ensure that the deputy model does not adversely impact the personalized local model in subsequent steps."}, {"title": "D. Reciprocate", "content": "When the client c achieves a performance level that is similar to the model q, indicated by $\\phi_{val}(c) > \\lambda \\phi \\phi_{val}(q)$ where $ \\phi_{val}$ represents a specific performance metric on the validation set, we initiate mutual learning. This process in-volves reciprocating exhaustive information between the client c and the personalized local model q. The objective of mutual learning is to interchange both overall knowledge and local knowledge between the two models. The client model cis supervised using Equation 5 while the personalized local model q is trained using the following loss function, denoted as $L_q$.\n$L_q = L_{en} + \\sum_{i=1}^N r(y_i)log(\\frac{r(y_i)}{q(y_i)})$ (5)\nThe client c facilitates the transfer of exhaustive knowledge from the server to the personalized local model q, as expressed in the second term of Equation. This process enhances the gen-eralization capabilities of all clients by promoting knowledge interchange."}, {"title": "E. Refine", "content": "Ultimately, when the client's performance, represented by \u0444 c, closely matches the personalized local model, represented by q, and satisfies the condition $\\phi(c) \\geq \\lambda \\phi \\phi(q)$, where 0 < $\\lambda_1$ < $\\lambda_2$ < 1, the client model c assumes the role of a teacher, guiding the personalized local model q further using Lq from the Equation 5. This process ensures that the maximum amount of global knowledge is transferred to the personalized local model."}, {"title": "F. Privacy Implications & Preservation", "content": "The personalized federated meta-learning model for dis-tributed systems leverages Cumulative Fourier Aggregation (CFA) at the server to enhance global knowledge integration by gradually combining client models across the frequency spectrum. A dedicated client model receives the aggregated server model, improving stability and effectiveness. To ad-dress privacy concerns, the model incorporates Collabora-tive Transfer Optimization (CTO) on the client side, using three steps-Retrieve, Reciprocate, and Refine-to smoothly transfer global knowledge to the personalized local model. Compared to existing approaches, this model stands out by combining Fourier Aggregation, Transfer Optimization, and multi-step refinement, offering a more robust solution to privacy preservation in federated learning."}, {"title": "IV. EXPERIMENTS", "content": "a) HAMK: In this research, we used the HAMK dataset, an open-source collection of 10,015 dermoscopic images categorized into seven classes. Like many medical imaging datasets, HAMK is highly imbalanced, with 67% of images labeled as nevi, 11% as melanoma, and the remaining 22% spread across five other classes. Ground truth labels in HAMK are based on histopathology in over 50% of cases, with the rest determined by follow-up exams, expert consensus, or in-vivo confocal microscopy. We selected HAMK for evaluation due to its unbalanced and heterogeneous nature. Table I details the sample counts for each class, and Figure 2 shows the client-wise distribution as a pie chart.\nb) MSK: The MSK dataset is from the Memorial Sloan-Kettering Cancer Center and used in ISIC lesion recogni-tion challenges. ISIC has compiled over 20,000 dermoscopy images from top clinical centers worldwide, captured using various devices. This dataset served as the basis for the 2016 benchmark challenge on dermoscopic image analysis."}, {"title": "V. CONCLUSION", "content": "In this study, we address the challenge of personalized medicine in distributed healthcare using Federated Learning (FL). Our goal is to enhance federated meta-learning for real-world personalized medical applications by introducing modifications at both the server and client levels. At the server, we implement a collaborative Fourier aggregation technique that progressively integrates global insights from low to high-frequency components. On the client side, we employ a three-step Retrieve-Reciprocate-Refine (RRR) ap-proach, which transfers global knowledge to the personalized model without overwriting it, effectively handling heterogene-ity issues. Through extensive experiments on a real-world dermoscopic FL dataset, we demonstrate that our framework outperforms existing state-of-the-art methods and generalizes well to an out-of-distribution cohort."}]}