{"title": "Differential Privacy Mechanisms in Neural Tangent Kernel Regression", "authors": ["Jiuxiang Gu", "Yingyu Liang", "Zhizhou Sha", "Zhenmei Shi", "Zhao Song"], "abstract": "Training data privacy is a fundamental problem in modern Artificial Intelligence (AI) applications, such as face recognition, recommendation systems, language generation, and many others, as it may contain sensitive user information related to legal issues. To fundamentally understand how privacy mechanisms work in AI applications, we study differential privacy (DP) in the Neural Tangent Kernel (NTK) regression setting, where DP is one of the most powerful tools for measuring privacy under statistical learning, and NTK is one of the most popular analysis frameworks for studying the learning mechanisms of deep neural networks. In our work, we can show provable guarantees for both differential privacy and test accuracy of our NTK regression. Furthermore, we conduct experiments on the basic image classification dataset CIFAR10 to demonstrate that NTK regression can preserve good accuracy under a modest privacy budget, supporting the validity of our analysis. To our knowledge, this is the first work to provide a DP guarantee for NTK regression.", "sections": [{"title": "1 Introduction", "content": "Artificial Intelligence (AI) applications are widely employed in daily human life and product activities, such as face recognition [PVZ15], recommendation systems [ZYST19], chat-based language generation [AAA+23], and many more. These applications intrinsically run deep-learning models that are trained on broad datasets, where many contain sensitive user information, e.g., a company trains a model on its user information to provide better-customized service. Consequently, there is a problem with user privacy information data leakage [LGF+23], which affects the AI company's reputation [LCL+23] and may cause severe legal issues [YLH+24, JHL+24]. Therefore, preserving the privacy of training data becomes a fundamental problem in deep learning.\nDifferential Privacy (DP) [DR14] was proposed to measure privacy rigorously and has been widely studied in many traditional statistical problems. Recently, many brilliant works have applied this powerful tool to machine learning settings. One line of work studies the classic machine learning task, e.g., [RBHT09] studies DP under the Support Vector Machine (SVM) model. However, these settings are still far from practical deep neural networks nowadays. The other line of work studies the DP in deep learning training, e.g., DP-SGD [ACG+16] provides DP guarantees for the Stochastic Gradient Descent (SGD) training algorithm. The issue in DP training is that the trade-off between privacy guarantees and test accuracy will worsen as training time increases. DP training may not be practical in today's training paradigm, i.e., pre-training with an adaptation in foundation models [BHA+21], as the per-training stage may involve billions of training steps.\nTo bridge the gap between practical deep learning models and practical differential privacy guarantees, in this work, we study DP Mechanisms in Neural Tangent Kernel [JGH18] (NTK) Regression. NTK is one of the most standard analysis frameworks for studying optimization and generalization in over-parameterized deep neural networks (DNN). NTK can connect the DNN training by SGD to kernel methods by using the kernel induced by gradient around the neural networks' initialization. Consequently, the DNN optimization can be viewed as NTK regression, and it retains almost the same generalization ability [ADH+19b] as kernel regression even though the DNN is in an over-parameterization regime.\nOur contributions. In this work, we use the \u201cGaussian Sampling Mechanism\u201d [GSY23] to add a positive semi-definite noise matrix to the neural tangent kernel matrix, and then we can show provable guarantees for both differential privacy and test accuracy of our NTK regression, i.e.,\nTheorem 1.1 (Main result, informal version of Theorem 4.10). Under proper conditions, for any test data x, we have NTK-regression is (e,d)-DP and has good utility under a large probability.\nFurthermore, we undertake experiments using the fundamental image classification dataset CIFAR10 to illustrate that NTK regression can maintain high accuracy with a modest privacy budget (see Figure 1 in Section 6.2). This effectively validates our analysis. To the best of our knowledge, this research is the first effort to offer a differential privacy (DP) guarantee for NTK regression.\nRoadmap Our paper is organized as follows. In Section 2, we provide an overview of Differential Privacy, the Neural Tangent Kernel (NTK), and its applications within the context of Differential Privacy. Section 3 introduces the definitions of both continuous and discrete versions of the Neural Tangent Kernel, along with the definition of NTK Regression. In Section 4, we provide definitions pertinent to the Gaussian Sampling Mechanism and explain how we modify this mechanism to render NTK Regression private. An overview of the techniques employed in this paper is discussed in Section 5. In Section 6, we conduct experiments on the CIFAR-10 dataset, demonstrating that our algorithm performs effectively with a small privacy budget. In Section 7, we offer a thorough"}, {"title": "2 Related Work", "content": "Differential Privacy Guarantee Analysis. Since the introduction of the concept of differential privacy (DP) by [DMNS06], it has emerged as a crucial standard for privacy protection, both theoretically and empirically [Dwo08, LLSY17, ZC22, PHK+23, YGZ+23]. DP offers a robust and measurable privacy definition that supports the design of algorithms with specific guarantees of privacy and accuracy [EMN22, AIMN23, LL23b, HY21, GKK+23, BLM+24, CAEM+22, EMNZ24, CNX22, Ste22, HKMN23, Nar22, Nar23, JLN+19, LL24, FL22, FLL24, LL23a, CSW+23, CAFL+22, DCL+24, FHS22, GLW21, GLL+23, LLH+22, GLL22, EKKL20, SYYZ23, DSWZ23, WZZ23, SWYZ23, GSY23] and many more. Furthermore, innovative mechanisms have been developed beyond conventional Laplace, Gaussian, and Exponential methods [DR14]. For instance, the truncated Laplace mechanism [GDGK20] has been demonstrated to achieve the tightest lower and upper bounds on minimum noise amplitude and power among all (\u20ac, \u03b4)-DP distributions.\nNeural Tangent Kernel. Numerous recent studies suggest that the analysis of optimization and generalization in deep learning should be closely integrated. NTK employs the first-order Taylor expansion to examine highly over-parameterized neural networks, from their initial states, as seen in references like [LL18, MRH+18, ZCZG18, JGH18, DZPS19, AZLS19b, ZG19, OS19, LXS+19, NXL+19, Yan19, SY19, DLL+19, AZLS19a, COB19, MMM19, OFLS19, ADH+19a, CG19, JT19, AZLL19, CCZG19, OS20, CB20, CFW+20, ZCZG20, GSJW20, LSS+20, BPSW21, ZGJ21, LLWA21, SWL21, MZ22, MOSW22, CCBG22, GMS23, QSS23, SY23, GQSW24, SZZ24, SWL24] and others. Consequently, the optimization of neural networks can be approached as a convex problem. The NTK technique has gained widespread application in various contexts, including preprocessing analysis [SYZ21, HSWZ22, ALS+23, SCL+23, SSLL23, SSL24, GQSW24], federated learning [LSY23], LoRA adaptation for large language models [HWAZ+21, XSW+24, SMF+23, GLL+24b, GLS+24a, MWY+23], and estimating scoring functions in diffusion models [HRX24, WHT24, GLL+24a, GLS+24b].\nDifferential Privacy in Machine Learning. Differential privacy (DP) is a thriving and potent method with extensive applications in the field of private machine learning [LDS+21]. This includes its use during the pre-training stage [ACG+16, PHK+23], the adaptation stage [B\u0415\u0420\u042022, SAMB24, LLB+24, YNB+21, LTLH21, SSC+22], and the inference stage [EW24, LPP+20]. Recently, [GAW+22, MJW+22, ZSZ+24] has integrated DP into large language models, and [WKW+23] applied DP into diffusion models. DP has also been widely used in classical machine learning and data structure settings, e.g., near-neighbor counting [AIMN23], permutation hashing [LL23b], BDD tree [HY21], counting tree [GKK+23], Jaccard similarity [ABS20] and many more."}, {"title": "3 Preliminary", "content": "In this section, we will first introduce some basic notations in Section 3.1. Then, we will introduce the definitions of the neural tangent kernel, both discrete and continuous versions in Section 3.2, the definitions and key component of NTK regression in Section 3.3."}, {"title": "3.1 Notations", "content": "For any positive n, let [n] denote the set {1,2,\u2026,n}. For any vector z \u2208 Rn. We define the l2-norm of a vector z as $||z||_2 := (\\Sigma_{i=1}^n z_i^2)^{1/2}$, the l\u2081-norm as $||z||_1 := \\Sigma_{i=1}^n |z_i|$, the l0-norm as the count of non-zero elements in z, and the l\u221e-norm as $||z||_\\infty := \\max_{i \\in [n]} |z_i|$. The transpose of vector z is indicated by z\u2122. The inner product between two vectors is denoted by (\u00b7,\u00b7), such that $(a, b) = \\Sigma_{i=1}^n a_i b_i$.\nFor any matrix A \u2208 Rm\u00d7n. We define the Frobenius norm of a matrix A as $||A||_F := (\\Sigma_{i\\in [m],j\\in [n]} A_{i,j}^2)^{1/2}$. We use $|| A||$ to denote the spectral/operator norm of matrix A.\nA function f(x) is said to be L-Lipschitz continuous if it satisfies the condition $|| f(x) - f (y) ||_2 \\leq L \\cdot ||x-y||_2$ for some constant L. Let D represent a given distribution. The notation x ~ D indicates that x is a random variable drawn from the distribution D. We employ E[] to represent the expectation operator and Pr[] to denote probability. Furthermore, we refer to a matrix as PSD to indicate that it is positive semi-definite.\nAs we have multiple indexes, to avoid confusion, we usually use i, j \u2208 [n] to index the training data, s, t \u2208 [d] to index the feature dimension, r \u2208 [m] to index neuron number."}, {"title": "3.2 Neural Tangent Kernel", "content": "Now, we are ready to introduce our key concept, the Neural Tangent Kernel induced by the Quadratic activation function. We will introduce Discrete Quadratic Kernel in Definition 3.1, and Continuous Quadratic Kernel in Definition 3.2.\nData. We have n training data points Dn = {(xi, Yi)}=1 = (X,Y), where x \u2208 Rd and y\u2208 {0,1}. We denote X = [x1,...,xn] \u2208 Rd\u00d7n and Y = [Y1,..., Yn]T \u2208 {\u22121,+1}n. We assume that $||x_i||_2 \\leq B$, \u2200i \u2208 [n].\nModels. We consider the two-layer neural network with quadratic activation function and m neurons\n$f(x) = \\sum_{r\\in[m]} a_r (w_r, x)^2$,\nwhere wr \u2208 Rd and ar \u2208 {\u22121,+1} for any r \u2208 [m].\nDefinition 3.1 (Discrete Quadratic NTK Kernel). We draw weights wr ~ N(0, \u03c3\u00b2Idxd) for any r \u2208 [m] and let them be fixed. Then, we define the discrete quadratic kernel matrix $H^{dis} \\in \\mathbb{R}^{n \\times n}$ corresponding to Dn, such that \u2200i, j \u2208 [n], we have\n$H^{dis}_{i,j} = \\frac{1}{m} \\sum_{r=1}^m ((w_r, x_i)x_i, (w_r, x_j)x_j)$.\nNote that Hdis is a PSD matrix, where a detailed proof can be found in Lemma B.1.\nDefinition 3.2 (Continuous Quadratic NTK Kernel). We define the continuous quadratic kernel matrix Hcts \u2208 Rn\u00d7n corresponding to D, such that \u2200i, j \u2208 [n], we have\n$H^{cts}_{i,j} = \\mathbb{E}_{w\\sim N(0,\\sigma^2I_{d \\times d})} ((w, x_i)x_i, (w, x_j)x_j)$."}, {"title": "3.3 NTK Regression", "content": "We begin by defining the classical kernel regression problem as follows:\nDefinition 3.3 (Classical kernel ridge regression [LSS+20]). If we have the following conditions:\n\u2022 Let feature map \u03c6 : Rd \u2192 F.\n\u2022 \u03bb > 0 is the regularization parameter.\nA classical kernel ridge regression problem can be written as\n$\\min_{w\\in \\mathbb{R}^n} \\frac{1}{2} ||Y - \\phi(X)w||_2^2 + \\frac{\\lambda}{2} ||w||_2^2$.\nThen, we are ready to introduce the NTK Regression problem as follows:\nDefinition 3.4 (NTK Regression [LSS+20]). If the following conditions are met:\n\u2022 Let K(, ) : Rd\u00d7Rd \u2192 R be a kernel function, i.e., $K(x, z) = \\frac{1}{m} \\sum_{r=1}^m ((w_r, x)x, (w_r, z)z), \u2200x, z \u2208 Rd$.\n\u2022 Let K \u2208 Rn\u00d7n be the kernel matrix with $K_{i,j} = K(x_i, x_j), \u2200i, j\\in [n] \\times [n]$.\n\u2022 Let \u03b1 \u2208 Rn be the solution to $(K + \u03bbI_n)\u03b1 = Y$. Namely, we have $\u03b1 = (K + \u03bbI_n)^{-1}Y$.\nThen, for any data x \u2208 Rd, the NTK Kernel Regression can be denoted as\n$f_x(x) = \\frac{1}{n} K(x, X)^T \u03b1$."}, {"title": "4 Main Results", "content": "In the NTK Regression definition, we have the expression $\u03b1 = (K+\u03bbI_n)^{-1}Y$ (see also Definition 3.4). To ensure the privacy of \u03b1, we initially focus on privatizing K. Subsequently, we demonstrate that \u03b1 remains private through the application of the Post-processing Lemma (see also Lemma A.6). Privatizing K is non-trivial, as K = Hdis, indicating that K is a positive semi-definite (PSD) matrix (see Lemma B.1). We denote K as the privacy-preserving counterpart of K. It is essential that K maintains the PSD property, a condition that classical mechanisms such as the Laplace Mechanism and Gaussian Mechanism cannot inherently guarantee for a private matrix. In the work by [GSY23], the \u201cGaussian Sampling Mechanism\u201d is employed to address this challenge, ensuring that the private version of the Attention Matrix also retains PSD. Adopting the same setup from [GSY23], we present our findings on the privacy and utility of the \u201cGaussian Sampling Mechanism\u201d in this section.\nIn Section 4.1, we provide several essential definitions used in our algorithm. In Section 4.2, we will adhere to the framework established in [GSY23] and elaborate on the functioning of the \"Gaussian Sampling Mechanism,\" along with its primary results and requirements. In Section 4.3, we will examine the utility implications of employing the \"Gaussian Sampling Mechanism.\" Additionally, we include a Remark that analyzes the trade-off between privacy and utility inherent in our approach. In Section 4.4, we introduce the final theorem of our algorithm, including both privacy guarantees and utility guarantees."}, {"title": "4.1 Key Concepts", "content": "To begin with, we will introduce the definition of neighboring dataset used in \"Gaussian Sampling Mechanism\".\nDefinition 4.1 (\u03b2-close neighbor dataset, [GSY23]). If we have below conditions,\n\u2022 Let B > 0 be a constant.\n\u2022 Let n be the number of data points.\n\u2022 Let dataset D = {(xi, Yi)}=1, where xi \u2208 Rd and $||x_i||_2 \\leq B$ for any i \u2208 [n].\nWe define D' be a neighbor dataset with one data point replacement of D. Without loss of generality, we have $D' = {(x_i, Y_i)}_{i=1}^{n-1} \\cup {(x'_n, Y_n)}$.Namely, we have D and D' only differ in the n-th item. Additionally, we assume that xn and x'm are \u00df-close. Namely, we have\n$||x_n - x'_n||_2 \\leq \u03b2$\nThere are also two essential definitions M and \u0394 used in the privacy proof of \"Gaussian Sampling Mechanism\", which need to satisfy M < \u0394, which is also the Condition 4 in Condition 4.4. We will begin by presenting the definition of M.\nDefinition 4.2 (Definition of M, [GSY23]). Let $M : (\\mathbb{R}^n)^d \\rightarrow \\mathbb{R}^{n \\times n}$ be a (randomized) algorithm that given a dataset of d points in Rn outputs a PSD matrix. Let Y, Y' \u2208 (Rn)d. Then, we define\n$M := ||M(Y)^{1/2}M(Y')^{-1}M(Y)^{1/2} - I||_F$\nAfterward, we proceed to define \u0394.\nDefinition 4.3 ( Definition of \u0394, [GSY23] ). If we have the following conditions:\n\u2022 Let \u0454 \u2208 (0,1) and \u03b4 \u2208 (0,1).\n\u2022 Let k denote the number of i.i.d. samples 91, 92,\u2026, gk from N(0, \u22111) output by Algorithm 1.\nWe define\n$\\Delta := \\min\\{ \\frac{\\epsilon}{\\sqrt{8k \\log(1/\\delta)}}, \\frac{\\epsilon}{8 \\log(1/\\delta)}\\ \\}$."}, {"title": "4.2 Gaussian Sampling Mechanism", "content": "In this section, we recapitulate the analytical outcomes of the \u201cGaussian Sampling Mechanism\" as presented in Theorem 4.5 from [GSY23]. The associated algorithm is detailed in Algorithm 1. Firstly, we outline the conditions employed in the \"Gaussian Sampling Mechanism\" as follows:\nCondition 4.4. We need the following conditions for DP:\n\u2022 Condition 1. Let \u0454 \u2208 (0,1), \u03b4\u2208 (0, 1), k \u2208N.\n\u2022 Condition 2. Let Y, Y' denote neighboring datasets, which differ by a single data element.\n\u2022 Condition 3. Let \u2206 be defined in Definition 4.3 and \u2206 < 1."}, {"title": "4.3 Utility of Gaussian Sampling Mechanism", "content": "In this section, we will provide utility guarantees under \"Gaussian Sampling Mechanism\". By Lemma 4.8, we will argue that, \u201cGaussian Sampling Mechanism\" provides good utility under differential privacy.\nWe start with introducing the necessary conditions used in proving the utility of \"Gaussian Sampling Mechanism\".\nCondition 4.7. We need the following conditions for Utility guarantees of \u201cGaussian Sampling Mechanism\u201d:\n\u2022 Condition 1. If D \u2208 Rn\u00d7d and D' \u2208 Rn\u00d7d are neighboring dataset (see Definition 4.1)\n\u2022 Condition 2. Let Hdis denote the discrete NTK kernel matrix generated by D (see Definition 3.1).\n\u2022 Condition 3. Let $N_{max}I_{n \\times n} > H^{dis} > N_{min}I_{n \\times n}$, for some Nmax, Ymin \u2208 R.\n\u2022 Condition 4. Let $\\tilde{H}^{dis}$ denote the private Hdis generated by Algorithm 1 with Hdis as the input.\n\u2022 Condition 5. Let K = Hdis, K = $\\tilde{H}^{dis}$ in Definition 3.4. Then we have $f_x^*(x)$ and $\\tilde{f}_x^*(x)$.\n\u2022 Condition 6. Let $\\sqrt{n}\u03c8/\u03b7_{min} < \u2206$, where \u2206 is defined in Definition 4.3.\n\u2022 Condition 7. Let $\u03c1 = O(\\sqrt{(n^2 + log(1/\u03b3))/k + (n^2 + log(1/\u03b3))/k})$.\n\u2022 Condition 8. Let $\u03c9 := 6d\u03c3^2B^4$.\n\u2022 Condition 9. Let \u03b3\u2208 (0, 1).\nWe then leverage Part 3 of Lemma 4.5 to derive the error between the outputs of the private and non-private NTK Regression, thereby demonstrating the utility of our algorithm.\nLemma 4.8 (Utility guarantees of \"Gaussian Sampling Mechanism\", informal version of Lemma E.4). If all conditions hold in Condition 4.7, then, with probability 1 - \u03b3, we have\n$|f_x^*(x) - \\tilde{f}_x^*(x)| \\leq O(\\frac{\u03c1 \\cdot N_{max} \\cdot W}{(\u03b7_{min} + \\lambda)^2})$"}, {"title": "4.4 Main Theorem", "content": "Then, we are ready to introduce our main result, including the privacy and utility of our algorithm.\nTheorem 4.10 (Main result, formal version of Theorem 1.1). If all conditions hold in Condition 4.4, Condition 4.6, and Condition 4.7, then, for any test data x, with probability 1 - \u03b4e - \u03b3, we have that f(x) is (e,d)-DP and\n$|f_x^*(x) - \\tilde{f}_x^*(x)| \\leq O(\\frac{\u03c1 \\cdot N_{max} \\cdot W}{(\u03b7_{min} + \\lambda)^2})$\nIt follows from directly combining Lemma 4.5, Lemma 4.8, and Lemma 5.1."}, {"title": "5 Technical Overview", "content": "In this section, we offer a succinct overview of the proof techniques employed throughout this paper."}, {"title": "5.1 Sensitivity of Continuous Quadratic NTK", "content": "Given that the Discrete Quadratic NTK is defined as $H^{dis}_{i,j} = \\frac{1}{m} \\sum_{r=1}^m ((w_r, x_i)x_i, (w_r, x_j)x_j)$ (see also Definition 3.1), analyzing its sensitivity when a single data point is altered in the training dataset poses a challenge. In contrast, the Continuous Quadratic NTK, which incorporates Expectation in its definition (refer to Definition 3.2), is significantly much easier to analyze. The discrepancy between the Discrete and Continuous versions of the NTK can be reconciled through Concentration inequalities. Consequently, we will start our analysis of NTK Regression by focusing on the Continuous Quadratic NTK.\nIn the \u201cGaussian Sampling Mechanism\u201d (see also Section 4.2), we defined the concept of neighboring datasets being \u1e9e-close (refer to Definition 4.1). We focus on examining the Lipschitz property of individual entries within the Continuous Quadratic NTK.\nWithout loss of generality, let us consider a dataset D of length n, and let neighboring datasets D and D' differ solely in their n-th data point. Consequently, as per the definition of the Continuous Quadratic NTK, the respective kernels Hcts and Hcts' will differ exclusively in their n-th row and n-th column.\nTo examine the Lipschitz property for the n-th row and n-th column, we must consider two distinct cases. Initially, we focus on the sole diagonal entry, the (n, n)-th element, in the Continuous Quadratic NTK. The Lipschitz property for this entry is given by (see also Lemma D.3):\n$|H^{cts}_{n,n} - H^{cts'}_{n,n}| \\leq 4\u03c3^2B^3 \\cdot ||x - x' ||_2$\nSubsequently, we will address the remaining 2n - 2 non-diagonal entries within the n-th row and n-th column, for which the Lipschitz property is as follows: (see also Lemma D.2). For all {(i, j) : (i = n, j \u2260 n)or(i \u2260 n, j = n), i, j \u2208 [n]}, we have\n$|H^{cts}_{i,j} - H^{cts'}_{i,j}| \\leq 2\u03c3^2 B^3 \\cdot ||x \u2212 x' ||_2$\nMoreover, we compute the sensitivity of the Continuous Quadratic NTK with respect to \u1e9e-close neighboring datasets. Leveraging the Lipschitz properties of the diagonal and non-diagonal entries discussed earlier, we derive the sensitivity of the Continuous Quadratic NTK as follows: (see also Lemma D.4)\n$||H^{cts} - H^{cts'} ||_F < O(\\sqrt{\u03b7\u03c3^2 B^3\u03b2})$"}, {"title": "5.2 Bridge the gap between Continuous and Discrete Quadratic NTKs", "content": "In the previous section, we established the sensitivity of the Continuous Quadratic NTK. Here, we aim to bridge the divide between the Continuous Quadratic NTK and Discrete Quadratic NTK. The underlying rationale is that the number of neurons, m, in the Discrete Quadratic NTK can be extremely large. With the help of this property, we invoke the strength of concentration inequalities, specifically Bernstein's Inequality, to demonstrate that with high probability, the discrepancy"}, {"title": "5.3 Sensitivity of PSD Matrix", "content": "In alignment with [GSY23], this section will present Lemma 5.1, which offers a calculation for M (refer to Definition 4.2). Utilizing this result and noting that A is dependent on k (see Definition 4.3), we can subsequently refine the sampling time k to satisfy Condition 4 as mentioned in Condition 4.4.\nLemma 5.1 (Sensitivity of PSD Matrix Hdis, informal version of Lemma D.15). If all conditions hold in Condition 4.6, then, with probability 1 \u2013 83, we have\n\u2022 Part 1.\n$||(H^{dis})^{-1/2}H^{dis'} (H^{dis})^{-1/2} - I|| \\leq \u03c8/\u03b7_{min}$\n\u2022 Part 2.\n$|| (H^{dis})^{-1/2} H^{dis'} (H^{dis})^{-1/2} - I||_F < \\sqrt{\u03b7}\u03c8/\u03b7_{min}$\nIn Lemma 5.1, Part 1 and Part 2 respectively establish the bounds for M (as defined in Definition 4.2) under the spectral norm and Frobenius norm. These findings offer insights into how to modify k in order to fulfill Condition 4 as required by Condition 4.4."}, {"title": "5.4 Privacy Guarantees for Private NTK Regression", "content": "In Lemma 4.5 and under Condition 4. in Condition 4.4, we need to compute M (as defined in Definition 4.2) for the Discrete Quadratic NTK.\nThe pivotal approach is to first utilize the sensitivity of the Discrete Quadratic NTK (refer to Lemma D.13) to establish the inequalities for positive semi-definite matrices (see Lemma D.14). Specifically, we obtain\n$(1 - \\frac{\u03c8}{\u03b7_{min}})H^{dis} < H^{dis'} < (1 + \\frac{\u03c8}{\u03b7_{min}})H^{dis}$\nBuilding on these inequalities, we can further demonstrate that (as shown in Lemma 5.1)\n$||(H^{dis})^{-1/2}H^{dis'} (H^{dis})^{-1/2} - I||_F < \\sqrt{\u03b7}\u03c8/\u03b7_{min}$\nConsequently, since $\u03c8 = O(\\sqrt{\u03b7}\u03c3^2 B^3\u03b2)$, by choosing a small \u00df, we achieve\n$M = ||(H^{dis})^{-1/2} H^{dis'} (H^{dis})^{-1/2} - I||_F < \u0394$\nwhich fulfills the requirements of Condition 4. in Condition 4.4. Thus, by Lemma 4.5, we establish the privacy guarantees for our algorithm."}, {"title": "5.5 Utility Guarantees for Private NTK Regression", "content": "In this section, we will present a comprehensive analysis of the utility guarantees for our private NTK Regression.\nRecall that in the definition of NTK Regression (refer to Definition 3.4), we have\n$f_x^*(x) = \\frac{1}{n} K(x, X)^T (K + \\lambda I_n)^{-1}Y$\nWe commence by establishing a bound on the spectral norm of $(K + \\lambda I_n)^{-1}$ as follows (see also Lemma E.3)\n$||(K + \\lambda I_n)^{-1} - (\\tilde{K} + \\lambda I_n)^{-1}|| \\leq O(\\frac{\u03c1 \\cdot \u03b7_{max}}{(N_{min} + \\lambda)^2})$\nHere, we employ the Moore-Penrose inverse (see also Lemma E.2) to address the inversion in $(K + \\lambda I_n)^{-1}$.\nUtilizing the spectral norm bound, we then derive bounds for the L2 norms of K(x, X) and Y. After selecting a small \u00df, we arrive at the final result that (see also Lemma 4.8)\n$|f_x^*(x) - \\tilde{f}_x^*(x)| \\leq O(\\frac{\u03c1 \\cdot N_{max} \\cdot W}{(\u03b7_{min} + \\lambda)^2})$\nThus, we have demonstrated that our private NTK Regression maintains high utility while simultaneously ensuring privacy.\nSimilar to other differential privacy algorithms, our algorithm encounters a trade-off between privacy and utility, where increased privacy typically results in a reduction in utility, and conversely. An in-depth examination of this trade-off is provided in Remark 4.9."}, {"title": "6 Experiments", "content": "This section will introduce the experimental methodology employed on the CIFAR-10 dataset. The corresponding results are visualized in Fig. 1. In Section 6.1, we enumerate all the parameters and the experimental setup we utilized. Section 6.2 presents a detailed analysis of the outcomes from our experiments."}, {"title": "6.1 Experiment Setup", "content": "Dataset. Our experiments are conducted on the CIFAR-10 dataset [KH+09], which comprises 10 distinct classes of colored images, including subjects such as airplanes, cats, and dogs. The dataset is partitioned into 50,000 training samples and 10,000 testing samples, with each image measuring 32 \u00d7 32 pixels and featuring RGB channels. Given that our NTK Regression is tailored for binary classification, we select two random classes from the 10 available classes to conduct the binary classification task. We randomly choose 1,000 images for training and 100 for testing.\nFeature Extraction. CIFAR-10 images possess a high-dimensional nature (32\u00d732\u00d73 = 3,072 dimensions), which poses a challenge for NTK Regression. To address this, we leverage the power of ResNet [HZRS16] to reduce the dimension. Following the approach of [Arn18], we employ ResNet-18 to encode the images and extract features from the network's last layer, yielding a 512-dimensional feature representation for each image.\nFeature Normalization. Prior to training our NTK Regression, we normalize all image features such that the L2 norm of each feature vector is equal to 1."}, {"title": "7 Discussion", "content": "DP in kernel and gradient. In DP-SGD [ACG+16], they add Gaussian noise on the gradient for privacy. As they are a first-order algorithm, their function sensitivity is more robust for single-step training. However, as discussed in Section 1, to guarantee DP for the whole training process, their DP Gaussian noise variance will increase as T becomes larger (see Theorem 1 in [ACG+16]). The DP-SGD will not be practical when T is too large. On the other hand, our NTK regression setting is a second-order algorithm involving kernel matrix inverse. Then, our key technical issues are (1) introducing a PSD noise matrix to keep kernel PSD property and (2) using L2 regularization to make the kernel sensitivity more robust (see more details in Section 5).\nWhere to add noise? The proper way to add noise is a fundamental problem in differential privacy. In the work, we add noise to the kernel function to make the neural tangent kernel private. The other option is to add noise on the parameter \u03b1 in Definition 3.4, but the issue is that the sensitivity of the matrix inverse operation is not robust, so the privacy guarantee will not be ideal in this case."}]}