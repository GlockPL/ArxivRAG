{"title": "Differential Privacy Mechanisms in Neural Tangent Kernel Regression", "authors": ["Jiuxiang Gu", "Yingyu Liang", "Zhizhou Sha", "Zhenmei Shi", "Zhao Song"], "abstract": "Training data privacy is a fundamental problem in modern Artificial Intelligence (AI) ap- plications, such as face recognition, recommendation systems, language generation, and many others, as it may contain sensitive user information related to legal issues. To fundamentally un- derstand how privacy mechanisms work in AI applications, we study differential privacy (DP) in the Neural Tangent Kernel (NTK) regression setting, where DP is one of the most powerful tools for measuring privacy under statistical learning, and NTK is one of the most popular analysis frameworks for studying the learning mechanisms of deep neural networks. In our work, we can show provable guarantees for both differential privacy and test accuracy of our NTK regression. Furthermore, we conduct experiments on the basic image classification dataset CIFAR10 to demonstrate that NTK regression can preserve good accuracy under a modest privacy budget, supporting the validity of our analysis. To our knowledge, this is the first work to provide a DP guarantee for NTK regression.", "sections": [{"title": "1 Introduction", "content": "Artificial Intelligence (AI) applications are widely employed in daily human life and product activ- ities, such as face recognition [PVZ15], recommendation systems [ZYST19], chat-based language generation [AAA+23], and many more. These applications intrinsically run deep-learning models that are trained on broad datasets, where many contain sensitive user information, e.g., a company trains a model on its user information to provide better-customized service. Consequently, there is a problem with user privacy information data leakage [LGF+23], which affects the AI company's reputation [LCL+23] and may cause severe legal issues [YLH+24, JHL+24]. Therefore, preserving the privacy of training data becomes a fundamental problem in deep learning. Differential Privacy (DP) [DR14] was proposed to measure privacy rigorously and has been widely studied in many traditional statistical problems. Recently, many brilliant works have applied this powerful tool to machine learning settings. One line of work studies the classic machine learning task, e.g., [RBHT09] studies DP under the Support Vector Machine (SVM) model. However, these settings are still far from practical deep neural networks nowadays. The other line of work studies the DP in deep learning training, e.g., DP-SGD [ACG+16] provides DP guarantees for the Stochastic Gradient Descent (SGD) training algorithm. The issue in DP training is that the trade-off between privacy guarantees and test accuracy will worsen as training time increases. DP training may not be practical in today's training paradigm, i.e., pre-training with an adaptation in foundation models [BHA+21], as the per-training stage may involve billions of training steps. To bridge the gap between practical deep learning models and practical differential privacy guarantees, in this work, we study DP Mechanisms in Neural Tangent Kernel [JGH18] (NTK) Regression. NTK is one of the most standard analysis frameworks for studying optimization and generalization in over-parameterized deep neural networks (DNN). NTK can connect the DNN training by SGD to kernel methods by using the kernel induced by gradient around the neural networks' initialization. Consequently, the DNN optimization can be viewed as NTK regression, and it retains almost the same generalization ability [ADH+19b] as kernel regression even though the DNN is in an over-parameterization regime. Our contributions. In this work, we use the \u201cGaussian Sampling Mechanism\u201d [GSY23] to add a positive semi-definite noise matrix to the neural tangent kernel matrix, and then we can show provable guarantees for both differential privacy and test accuracy of our NTK regression, i.e., Theorem 1.1 (Main result, informal version of Theorem 4.10). Under proper conditions, for any test data x, we have NTK-regression is (e,d)-DP and has good utility under a large probability. Furthermore, we undertake experiments using the fundamental image classification dataset CIFAR10 to illustrate that NTK regression can maintain high accuracy with a modest privacy budget (see Figure 1 in Section 6.2). This effectively validates our analysis. To the best of our knowledge, this research is the first effort to offer a differential privacy (DP) guarantee for NTK regression. Roadmap Our paper is organized as follows. In Section 2, we provide an overview of Differential Privacy, the Neural Tangent Kernel (NTK), and its applications within the context of Differential Privacy. Section 3 introduces the definitions of both continuous and discrete versions of the Neural Tangent Kernel, along with the definition of NTK Regression. In Section 4, we provide definitions pertinent to the Gaussian Sampling Mechanism and explain how we modify this mechanism to render NTK Regression private. An overview of the techniques employed in this paper is discussed in Section 5. In Section 6, we conduct experiments on the CIFAR-10 dataset, demonstrating that our algorithm performs effectively with a small privacy budget. In Section 7, we offer a thorough"}, {"title": "2 Related Work", "content": "Differential Privacy Guarantee Analysis. Since the introduction of the concept of differ- ential privacy (DP) by [DMNS06], it has emerged as a crucial standard for privacy protection, both theoretically and empirically [Dwo08, LLSY17, ZC22, PHK+23, YGZ+23]. DP offers a robust and measurable privacy definition that supports the design of algorithms with specific guaran- tees of privacy and accuracy [EMN22, AIMN23, LL23b, HY21, GKK+23, BLM+24, CAEM+22, EMNZ24, CNX22, Ste22, HKMN23, Nar22, Nar23, JLN+19, LL24, FL22, FLL24, LL23a, CSW+23, CAFL+22, DCL+24, FHS22, GLW21, GLL+23, LLH+22, GLL22, EKKL20, SYYZ23, DSWZ23, WZZ23, SWYZ23, GSY23] and many more. Furthermore, innovative mechanisms have been devel- oped beyond conventional Laplace, Gaussian, and Exponential methods [DR14]. For instance, the truncated Laplace mechanism [GDGK20] has been demonstrated to achieve the tightest lower and upper bounds on minimum noise amplitude and power among all (\u20ac, \u03b4)-DP distributions. Neural Tangent Kernel. Numerous recent studies suggest that the analysis of optimization and generalization in deep learning should be closely integrated. NTK employs the first-order Taylor expansion to examine highly over-parameterized neural networks, from their initial states, as seen in references like [LL18, MRH+18, ZCZG18, JGH18, DZPS19, AZLS19b, ZG19, OS19, LXS+19, NXL+19, Yan19, SY19, DLL+19, AZLS19a, COB19, MMM19, OFLS19, ADH+19a, CG19, JT19, AZLL19, CCZG19, OS20, CB20, CFW+20, ZCZG20, GSJW20, LSS+20, BPSW21, ZGJ21, LLWA21, SWL21, MZ22, MOSW22, CCBG22, GMS23, QSS23, SY23, GQSW24, SZZ24, SWL24] and others. Consequently, the optimization of neural networks can be approached as a convex problem. The NTK technique has gained widespread application in various contexts, including preprocessing analysis [SYZ21, HSWZ22, ALS+23, SCL+23, SSLL23, SSL24, GQSW24], federated learning [LSY23], LoRA adaptation for large language models [HWAZ+21, XSW+24, SMF+23, GLL+24b, GLS+24a, MWY+23], and estimating scoring functions in diffusion models [HRX24, WHT24, GLL+24a, GLS+24b]. Differential Privacy in Machine Learning. Differential privacy (DP) is a thriving and po- tent method with extensive applications in the field of private machine learning [LDS+21]. This includes its use during the pre-training stage [ACG+16, PHK+23], the adaptation stage [B\u0415\u0420\u042022, SAMB24, LLB+24, YNB+21, LTLH21, SSC+22], and the inference stage [EW24, LPP+20]. Re- cently, [GAW+22, MJW+22, ZSZ+24] has integrated DP into large language models, and [WKW+23] applied DP into diffusion models. DP has also been widely used in classical machine learning and data structure settings, e.g., near-neighbor counting [AIMN23], permutation hashing [LL23b], BDD tree [HY21], counting tree [GKK+23], Jaccard similarity [ABS20] and many more."}, {"title": "3 Preliminary", "content": "In this section, we will first introduce some basic notations in Section 3.1. Then, we will introduce the definitions of the neural tangent kernel, both discrete and continuous versions in Section 3.2, the definitions and key component of NTK regression in Section 3.3."}, {"title": "3.1 Notations", "content": "For any positive n, let [n] denote the set {1,2,\u2026,n}. For any vector $z \\in \\mathbb{R}^n$. We define the l2-norm of a vector z as $||z||_2 := (\\Sigma_{i=1}^n z_i^2)^{1/2}$, the l1-norm as $||z||_1 := \\sum_{i=1}^n |z_i|$, the l0-norm as the count of non-zero elements in z, and the $l_\\infty$-norm as $||z||_{\\infty} := \\max_{i\\in[n]} |z_i|$. The transpose of vector z is indicated by $z^\\top$. The inner product between two vectors is denoted by $\\langle\\cdot,\\cdot\\rangle$, such that $\\langle a, b\\rangle = \\sum_{i=1}^n a_i b_i$. For any matrix $A \\in \\mathbb{R}^{m\\times n}$. We define the Frobenius norm of a matrix A as $||A||_F := (\\Sigma_{i\\in[m],j\\in[n]} A_{i,j}^2)^{1/2}$. We use $||A||$ to denote the spectral/operator norm of matrix A. A function f(x) is said to be L-Lipschitz continuous if it satisfies the condition $||f(x) - f(y)||_2 \\le L \\cdot ||x - y||_2$ for some constant L. Let $\\mathcal{D}$ represent a given distribution. The notation $x \\sim \\mathcal{D}$ indicates that x is a random variable drawn from the distribution $\\mathcal{D}$. We employ $\\mathbb{E}[ ]$ to represent the expectation operator and $\\Pr[ ]$ to denote probability. Furthermore, we refer to a matrix as PSD to indicate that it is positive semi-definite. As we have multiple indexes, to avoid confusion, we usually use $i, j \\in [n]$ to index the training data, $s, t \\in [d]$ to index the feature dimension, $r \\in [m]$ to index neuron number."}, {"title": "3.2 Neural Tangent Kernel", "content": "Now, we are ready to introduce our key concept, the Neural Tangent Kernel induced by the Quadratic activation function. We will introduce Discrete Quadratic Kernel in Definition 3.1, and Continuous Quadratic Kernel in Definition 3.2. Data. We have n training data points $\\mathcal{D}_n = \\{(x_i, Y_i)\\}_{i=1}^n = (X,Y)$, where $x \\in \\mathbb{R}^d$ and $y\\in \\{0,1\\}$. We denote $X = [x_1,...,x_n] \\in \\mathbb{R}^{d\\times n}$ and $Y = [Y_1,..., Y_n]^T \\in \\{-1,+1\\}^n$. We assume that $||x_i||_2 \\le B, \\forall i \\in [n]$. Models. We consider the two-layer neural network with quadratic activation function and m neurons $$f(x) = \\sum_{r\\in[m]} a_r \\langle w_r, x \\rangle^2,$$ where $w_r \\in \\mathbb{R}^d$ and $a_r \\in \\{-1,+1\\}$ for any $r \\in [m]$. Definition 3.1 (Discrete Quadratic NTK Kernel). We draw weights $w_r \\sim \\mathcal{N}(0, \\sigma^2 \\mathbb{I}_{d\\times d})$ for any $r \\in [m]$ and let them be fixed. Then, we define the discrete quadratic kernel matrix $H^{dis} \\in \\mathbb{R}^{n\\times n}$ corresponding to $\\mathcal{D}_n$, such that $\\forall i, j \\in [n]$, we have $$H_{i,j}^{dis} = \\frac{1}{m} \\sum_{r=1}^m \\langle w_r, x_i x_i^\\top, w_r \\rangle \\langle w_r, x_j x_j^\\top \\rangle.$$ Note that $H^{dis}$ is a PSD matrix, where a detailed proof can be found in Lemma B.1. Definition 3.2 (Continuous Quadratic NTK Kernel). We define the continuous quadratic kernel matrix $H^{cts} \\in \\mathbb{R}^{n\\times n}$ corresponding to $\\mathcal{D}$, such that $\\forall i, j \\in [n]$, we have $$H_{i,j}^{cts} = \\mathbb{E}_{w\\sim\\mathcal{N}(0, \\sigma^2 \\mathbb{I}_{d\\times d})} \\langle w, x_i x_i^\\top, w \\rangle \\langle w, x_j x_j^\\top \\rangle.$$"}, {"title": "3.3 NTK Regression", "content": "We begin by defining the classical kernel regression problem as follows: Definition 3.3 (Classical kernel ridge regression [LSS+20]). If we have the following conditions: \u2022 Let feature map $\\phi: \\mathbb{R}^d \\rightarrow \\mathcal{F}$. \u2022 $\\lambda > 0$ is the regularization parameter. A classical kernel ridge regression problem can be written as $$\\min_{w\\in\\mathbb{R}^n} \\frac{1}{2} ||Y - \\phi(X)w||_2^2 + \\frac{\\lambda}{2} ||w||_2^2 .$$ Then, we are ready to introduce the NTK Regression problem as follows: Definition 3.4 (NTK Regression [LSS+20]). If the following conditions are met: \u2022 Let $K(\\cdot, \\cdot): \\mathbb{R}^{d\\times \\mathbb{R}^d} \\rightarrow \\mathbb{R}$ be a kernel function, i.e., $K(x, z) = \\frac{1}{m} \\sum_{r=1}^m \\langle w_r, x \\rangle x, \\langle w_r, z \\rangle z \\rangle, \\forall x, z \\in \\mathbb{R}^d$. \u2022 Let $K \\in \\mathbb{R}^{n\\times n}$ be the kernel matrix with $K_{i,j} = K(x_i, x_j), \\forall i, j\\in [n] \\times [n]$. \u2022 Let $\\alpha \\in \\mathbb{R}^n$ be the solution to $(K + \\lambda I_n)\\alpha = Y$. Namely, we have $\\alpha = (K + \\lambda I_n)^{-1}Y$. Then, for any data $x \\in \\mathbb{R}^d$, the NTK Kernel Regression can be denoted as $$f(x) = \\frac{1}{n} K(x, X)^T \\alpha.$$"}, {"title": "4 Main Results", "content": "In the NTK Regression definition, we have the expression $\\alpha = (K + \\lambda I_n)^{-1}Y$ (see also Definition 3.4). To ensure the privacy of \u03b1, we initially focus on privatizing K. Subsequently, we demonstrate that \u03b1 remains private through the application of the Post-processing Lemma (see also Lemma A.6). Privatizing K is non-trivial, as $K = H^{dis}$, indicating that K is a positive semi-definite (PSD) matrix (see Lemma B.1). We denote $\\hat{K}$ as the privacy-preserving counterpart of K. It is essential that $\\hat{K}$ maintains the PSD property, a condition that classical mechanisms such as the Laplace Mechanism and Gaussian Mechanism cannot inherently guarantee for a private matrix. In the work by [GSY23], the \u201cGaussian Sampling Mechanism\u201d is employed to address this challenge, ensuring that the private version of the Attention Matrix also retains PSD. Adopting the same setup from [GSY23], we present our findings on the privacy and utility of the \u201cGaussian Sampling Mechanism\u201d in this section. In Section 4.1, we provide several essential definitions used in our algorithm. In Section 4.2, we will adhere to the framework established in [GSY23] and elaborate on the functioning of the \u201cGaussian Sampling Mechanism,\u201d along with its primary results and requirements. In Section 4.3, we will examine the utility implications of employing the \u201cGaussian Sampling Mechanism.\u201d Additionally, we include a Remark that analyzes the trade-off between privacy and utility inherent in our approach. In Section 4.4, we introduce the final theorem of our algorithm, including both privacy guarantees and utility guarantees."}, {"title": "4.1 Key Concepts", "content": "To begin with, we will introduce the definition of neighboring dataset used in \"Gaussian Sampling Mechanism\". Definition 4.1 (\u03b2-close neighbor dataset, [GSY23]). If we have below conditions, \u2022 Let B > 0 be a constant. \u2022 Let n be the number of data points. \u2022 Let dataset $\\mathcal{D} = \\{(x_i, Y_i)\\}_{i=1}^n$, where $x_i \\in \\mathbb{R}^d$ and $||x_i||_2 \\le B$ for any $i \\in [n]$. We define $\\mathcal{D}'$ be a neighbor dataset with one data point replacement of $\\mathcal{D}$. Without loss of generality, we have $\\mathcal{D}' = \\{(x_i, Y_i)\\}_{i=1}^{n-1} \\cup \\{(x'_n, Y_n)\\}$. Namely, we have $\\mathcal{D}$ and $\\mathcal{D}'$ only differ in the n-th item. Additionally, we assume that $x_n$ and $x'_n$ are \u03b2-close. Namely, we have $$||x_n - x'_n||_2 \\le \\beta$$ There are also two essential definitions M and \u2206 used in the privacy proof of \u201cGaussian Sampling Mechanism\u201d, which need to satisfy $M < \\Delta$, which is also the Condition 4 in Condition 4.4. We will begin by presenting the definition of M. Definition 4.2 (Definition of M, [GSY23]). Let $M: (\\mathbb{R}^n)^d \\rightarrow \\mathbb{R}^{n\\times n}$ be a (randomized) algorithm that given a dataset of d points in $\\mathbb{R}^n$ outputs a PSD matrix. Let $Y, Y' \\in (\\mathbb{R}^n)^d$. Then, we define $$M := ||M(Y)^{1/2}M(Y')^{-1}M(Y)^{1/2} - I||_F$$ Afterward, we proceed to define \u0394. Definition 4.3 ( Definition of \u0394, [GSY23] ). If we have the following conditions: \u2022 Let $\\epsilon \\in (0,1)$ and $\\delta \\in (0,1)$. \u2022 Let k denote the number of i.i.d. samples $g_1, g_2,..., g_k$ from $N(0, \\Sigma)$ output by Algorithm 1. We define $$\\Delta := \\min \\Bigg \\{\\frac{\\epsilon}{\\sqrt{8k \\log(1/\\delta)}}, \\frac{\\epsilon}{8 \\log(1/\\delta)}\\Bigg \\}$$"}, {"title": "4.2 Gaussian Sampling Mechanism", "content": "In this section, we recapitulate the analytical outcomes of the \u201cGaussian Sampling Mechanism\" as presented in Theorem 4.5 from [GSY23]. The associated algorithm is detailed in Algorithm 1. Firstly, we outline the conditions employed in the \"Gaussian Sampling Mechanism\" as follows: Condition 4.4. We need the following conditions for DP: \u2022 Condition 1. Let $\\epsilon \\in (0,1)$, $\\delta \\in (0, 1)$, $k \\in\\mathbb{N}$. \u2022 Condition 2. Let Y, Y' denote neighboring datasets, which differ by a single data element. \u2022 Condition 3. Let \u2206 be defined in Definition 4.3 and $\u0394 < 1$."}, {"title": "4.3 Utility of Gaussian Sampling Mechanism", "content": "In this section, we will provide utility guarantees under \"Gaussian Sampling Mechanism\". By Lemma 4.8, we will argue that, \u201cGaussian Sampling Mechanism\" provides good utility under dif- ferential privacy. We start with introducing the necessary conditions used in proving the utility of \"Gaussian Sampling Mechanism\". Condition 4.7. We need the following conditions for Utility guarantees of \u201cGaussian Sampling Mechanism\": \u2022 Condition 1. If $\\mathcal{D} \\in \\mathbb{R}^{n\\times d}$ and $\\mathcal{D}' \\in \\mathbb{R}^{n\\times d}$ are neighboring dataset (see Definition 4.1) \u2022 Condition 2. Let $H^{dis}$ denote the discrete NTK kernel matrix generated by $\\mathcal{D}$ (see Defini- tion 3.1). \u2022 Condition 3. Let $N_{max}I_{n\\times n} > H^{dis} > N_{min}I_{n\\times n}$, for some $N_{max}, N_{min} \\in \\mathbb{R}$. \u2022 Condition 4. Let $\\hat{H}^{dis}$ denote the private $H^{dis}$ generated by Algorithm 1 with $H^{dis}$ as the input. \u2022 Condition 5. Let $K = H^{dis}$, $\\hat{K} = \\hat{H}^{dis}$ in Definition 3.4. Then we have $f_x^*$ and $\\hat{f_x}^*$. \u2022 Condition 6. Let $\\sqrt{n}\\psi/\\eta_{min} < \\Delta$, where $\\Delta$ is defined in Definition 4.3. \u2022 Condition 7. Let $\\rho = O(\\sqrt{(n^2 + \\log(1/\\gamma))/k + (n^2 + \\log(1/\\gamma))/k})$. \u2022 Condition 8. Let $\\omega := 6 d \\sigma^2 B^4$. \u2022 Condition 9. Let $\\gamma\\in (0, 1)$. We then leverage Part 3 of Lemma 4.5 to derive the error between the outputs of the private and non-private NTK Regression, thereby demonstrating the utility of our algorithm. Lemma 4.8 (Utility guarantees of \"Gaussian Sampling Mechanism\", informal version of Lemma E.4). If all conditions hold in Condition 4.7, then, with probability $1 - \\gamma$, we have $$|f^*(x) - \\hat{f}^*(x)| \\le O\\Big(\\frac{\\rho \\cdot N_{max} \\cdot \\omega}{(\\eta_{min} + \\lambda)^2}\\Big)$$"}, {"title": "4.4 Main Theorem", "content": "Then, we are ready to introduce our main result, including the privacy and utility of our algorithm. Theorem 4.10 (Main result, formal version of Theorem 1.1). If all conditions hold in Condi- tion 4.4, Condition 4.6, and Condition 4.7, then, for any test data x, with probability $1 - \\delta_3 - \\gamma$, we have that $\\hat{f}^*(x)$ is $(\\epsilon,\\delta)$-DP and $$|f^*(x) - \\hat{f}^*(x)| \\le O\\Big(\\frac{\\rho \\cdot N_{max} \\cdot \\omega}{(\\eta_{min} + \\lambda)^2}\\Big).$$ It follows from directly combining Lemma 4.5, Lemma 4.8, and Lemma 5.1."}, {"title": "5 Technical Overview", "content": "In this section, we offer a succinct overview of the proof techniques employed throughout this paper."}, {"title": "5.1 Sensitivity of Continuous Quadratic NTK", "content": "We begin by detailing the method for calculating the Sensitivity of the Continuous Quadratic NTK in Section 5.1. Subsequently, in Section 5.2, we utilize concentration inequalities, specifically Bernstein's Inequality, to narrow the gap between the Continuous Quadratic NTK and Discrete Quadratic NTK. In Section 5.3, we will delve into the sensitivity of the PSD matrix K, which is the matrix we aim to privatize. Concluding this overview, we present the approaches for establishing privacy guarantees and utility guarantees in Sections 5.4 and 5.5, respectively. Given that the Discrete Quadratic NTK is defined as $H_{i,j}^{dis} = \\frac{1}{m} \\sum_{r=1}^m \\langle w_r, x_i \\rangle x_i, \\langle w_r, x_j \\rangle x_j \\rangle$ (see also Definition 3.1), analyzing its sensitivity when a single data point is altered in the training dataset poses a challenge. In contrast, the Continuous Quadratic NTK, which incorporates Ex- pectation in its definition (refer to Definition 3.2), is significantly much easier to analyze. The discrepancy between the Discrete and Continuous versions of the NTK can be reconciled through Concentration inequalities. Consequently, we will start our analysis of NTK Regression by focusing on the Continuous Quadratic NTK. In the \u201cGaussian Sampling Mechanism\u201d (see also Section 4.2), we defined the concept of neigh- boring datasets being \u03b2-close (refer to Definition 4.1). We focus on examining the Lipschitz property of individual entries within the Continuous Quadratic NTK. Without loss of generality, let us consider a dataset $\\mathcal{D}$ of length n, and let neighboring datasets $\\mathcal{D}$ and $\\mathcal{D}'$ differ solely in their n-th data point. Consequently, as per the definition of the Continuous Quadratic NTK, the respective kernels $H^{cts}$ and $H^{cts'}$ will differ exclusively in their n-th row and n-th column. To examine the Lipschitz property for the n-th row and n-th column, we must consider two distinct cases. Initially, we focus on the sole diagonal entry, the (n, n)-th element, in the Continuous Quadratic NTK. The Lipschitz property for this entry is given by (see also Lemma D.3): $$|H_{n,n}^{cts} - H_{n,n}^{cts'}| \\le 4 \\sigma^2 B^3 \\cdot ||x - x' ||_2$$ Subsequently, we will address the remaining 2n - 2 non-diagonal entries within the n-th row and n-th column, for which the Lipschitz property is as follows: (see also Lemma D.2). For all $\\{(i, j) : (i = n, j \\neq n)or(i \\neq n, j = n), i, j \\in [n]\\}$, we have $$|H_{i,j}^{cts} - H_{i,j}^{cts'}| \\le 2 \\sigma^2 B^3 \\cdot ||x - x' ||_2$$ Moreover, we compute the sensitivity of the Continuous Quadratic NTK with respect to \u03b2-close neighboring datasets. Leveraging the Lipschitz properties of the diagonal and non-diagonal entries discussed earlier, we derive the sensitivity of the Continuous Quadratic NTK as follows: (see also Lemma D.4) $$||H^{cts} - H^{cts'} ||_F < O(\\sqrt{n \\sigma^2 B^3 \\beta})$$"}, {"title": "5.2 Bridge the gap between Continuous and Discrete Quadratic NTKs", "content": "In the previous section, we established the sensitivity of the Continuous Quadratic NTK. Here, we aim to bridge the divide between the Continuous Quadratic NTK and Discrete Quadratic NTK. The underlying rationale is that the number of neurons, m, in the Discrete Quadratic NTK can be extremely large. With the help of this property, we invoke the strength of concentration inequal- ities, specifically Bernstein's Inequality, to demonstrate that with high probability, the discrepancy"}, {"title": "5.3 Sensitivity of PSD Matrix", "content": "In alignment with [GSY23], this section will present Lemma 5.1, which offers a calculation for M (refer to Definition 4.2). Utilizing this result and noting that \u2206 is dependent on k (see Defini- tion 4.3), we can subsequently refine the sampling time k to satisfy Condition 4 as mentioned in Condition 4.4. Lemma 5.1 (Sensitivity of PSD Matrix $H^{dis}$, informal version of Lemma D.15). If all conditions hold in Condition 4.6, then, with probability $1 - \\delta_3$, we have \u2022 Part 1. $$||(H^{dis})^{-1/2}H^{dis'} (H^{dis})^{-1/2} - I|| \\le \\psi/\\eta_{min}$$ \u2022 Part 2. $$||(H^{dis})^{-1/2}H^{dis'} (H^{dis})^{-1/2} - I||_F < \\sqrt{n}\\psi/\\eta_{min}$$ In Lemma 5.1, Part 1 and Part 2 respectively establish the bounds for M (as defined in Definition 4.2) under the spectral norm and Frobenius norm. These findings offer insights into how to modify k in order to fulfill Condition 4 as required by Condition 4.4."}, {"title": "5.4 Privacy Guarantees for Private NTK Regression", "content": "In Lemma 4.5 and under Condition 4. in Condition 4.4, we need to compute M (as defined in Definition 4.2) for the Discrete Quadratic NTK. The pivotal approach is to first utilize the sensitivity of the Discrete Quadratic NTK (refer to Lemma D.13) to establish the inequalities for positive semi-definite matrices (see Lemma D.14). Specifically, we obtain $$(1 - \\psi/\\eta_{min})H^{dis} < H^{dis'} < (1 + \\psi//\\eta_{min})H^{dis}$$ Building on these inequalities, we can further demonstrate that (as shown in Lemma 5.1) $$||(H^{dis})^{-1/2}H^{dis'} (H^{dis})^{-1/2} - I||_F < \\sqrt{n}\\psi/\\eta_{min}$$ Consequently, since $\\psi = O(\\sqrt{n} \\sigma^2 B^3 \\beta)$, by choosing a small \u00df, we achieve $$M = ||(H^{dis})^{-1/2}H^{dis'} (H^{dis})^{-1/2} - I||_F < \\Delta$$ which fulfills the requirements of Condition 4. in Condition 4.4. Thus, by Lemma 4.5, we establish the privacy guarantees for our algorithm."}, {"title": "5.5 Utility Guarantees for Private NTK Regression", "content": "In this section, we will present a comprehensive analysis of the utility guarantees for our private NTK Regression. Recall that in the definition of NTK Regression (refer to Definition 3.4), we have $$f^*(x) = K(x, X)^T (K + \\lambda I_n)^{-1}Y$$ We commence by establishing a bound on the spectral norm of $(K + \\lambda I_n)^{-1}$ as follows (see also Lemma E.3) $$||(K + \\lambda I_n)^{-1} - (\\hat{K} + \\lambda I_n)^{-1}|| \\le O\\Big(\\frac{\\rho \\cdot N_{max}}{(\\eta_{min} + \\lambda)^2}\\Big)$$ Here, we employ the Moore-Penrose inverse (see also Lemma E.2) to address the inversion in $(K + \\lambda I_n)^{-1}$. Utilizing the spectral norm bound, we then derive bounds for the $L_2$ norms of K(x, X) and Y. After selecting a small \u00df, we arrive at the final result that (see also Lemma 4.8) $$|f^*(x) - \\hat{f}^*(x)| \\le O\\Big(\\frac{\\rho \\cdot N_{max} \\cdot \\omega}{(\\eta_{min} + \\lambda)^2}\\Big)$$ Thus, we have demonstrated that our private NTK Regression maintains high utility while simultaneously ensuring privacy. Similar to other differential privacy algorithms, our algorithm encounters a trade-off between privacy and utility, where increased privacy typically results in a reduction in utility, and conversely. An in-depth examination of this trade-off is provided in Remark 4.9."}, {"title": "6 Experiments", "content": "This section will introduce the experimental methodology employed on the CIFAR-10 dataset. The corresponding results are visualized in Fig. 1. In Section 6.1, we enumerate all the parameters and the experimental setup we utilized. Section 6.2 presents a detailed analysis of the outcomes from our experiments."}, {"title": "6.1 Experiment Setup", "content": "Dataset. Our experiments are conducted on the CIFAR-10 dataset [KH+09], which comprises 10 distinct classes of colored images, including subjects such as airplanes, cats, and dogs. The dataset is partitioned into 50,000 training samples and 10,000 testing samples, with each image measuring 32 \u00d7 32 pixels and featuring RGB channels. Given that our NTK Regression is tailored for binary classification, we select two random classes from the 10 available classes to conduct the binary classification task. We randomly choose 1,000 images for training and 100 for testing. Feature Extraction. CIFAR-10 images possess a high-dimensional nature (32\u00d732\u00d73 = 3,072 dimensions), which poses a challenge for NTK Regression. To address this, we leverage the power of ResNet [HZRS16] to reduce the dimension. Following the approach of [Arn18], we employ ResNet-18 to encode the images and extract features from the network's last layer, yielding a 512-dimensional feature representation for each image. Feature Normalization. Prior to training our NTK Regression, we normalize all image features such that the $L_2$ norm of each feature vector is equal to 1."}, {"title": "6.2 Main Results", "content": "In accordance with the experimental setup detailed in Section 6.1, we present the results in Fig. 1. During the execution of NTK Regression, we initially compute $H^{dis}$ (as defined in Definition 3.1) based on the quadratic activation between the training data and m neurons. As $H^{dis}$ is"}]}