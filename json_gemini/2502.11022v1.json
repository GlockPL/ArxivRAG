{"title": "MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation", "authors": ["Zhiqian Qin", "Yuanfeng Song", "Jinwei Lu", "Yuanwei Song", "Shuaimin Li", "Chen Jason Zhang"], "abstract": "Natural language interfaces for NoSQL databases are increasingly vital in the big data era, enabling users to interact with complex, unstructured data without deep technical expertise. However, most recent advancements focus on English, leaving a gap for multilingual support. This paper introduces MultiTEND, the first and largest multilingual benchmark for natural language to NoSQL query generation, covering six languages: English, German, French, Russian, Japanese and Mandarin Chinese. Using MultiTEND, we analyze challenges in translating natural language to NoSQL queries across diverse linguistic structures, including lexical and syntactic differences. Experiments show that performance accuracy in both English and non-English settings remains relatively low, with a 4%-6% gap across scenarios like fine-tuned SLM, zero-shot LLM, and RAG for LLM. To address the aforementioned challenges, we introduce MultiLink, a novel framework that bridges the multilingual input to NoSQL query generation gap through a Parallel Linking Process. It breaks down the task into multiple steps, integrating parallel multilingual processing, Chain-of-Thought (CoT) reasoning, and Retrieval-Augmented Generation (RAG) to tackle lexical and structural challenges inherent in multilingual NoSQL generation. MultiLink shows enhancements in all metrics for every language against the top baseline, boosting execution accuracy by about 15% for English and averaging a 10% improvement for non-English languages.", "sections": [{"title": "Introduction", "content": "In the age of big data, NoSQL databases have become indispensable tools for managing vast amounts of unstructured and semi-structured data (Han et al., 2011). Unlike traditional relational databases, NoSQL databases offer more flexibility in schema design and can handle a wide variety of data types, making them particularly suitable for modern applications such as social media (Bhogal and Choksi, 2015), e-commerce (Nalla and Reddy, 2022), and real-time analytics (Ta et al., 2016). Nonetheless, the intricacy and heterogeneity of NoSQL query languages present a formidable challenge, especially for users who may not have advanced technical skills.\nTo address this challenge, the development of natural language interfaces (NLIs) for NoSQL databases has gained increasing attention. These interfaces are designed to allow users to interact with NoSQL databases in natural language, thus simplifying access to complex data and lowering the technical barriers. By translating Natural Language Queries (NLQs) into executable NoSQL queries (i.e., Text-to-NoSQL (Lu et al., 2025)), these systems can significantly enhance user productivity and data accessibility. However, existing natural language to NoSQL query generation systems and benchmarks have predominantly focused on the English language. This limitation severely restricts the usability of these systems for non-English speakers, who represent a significant portion of the global population.\nTo address above-mentioned issue, we introduce MultiTEND, the first multilingual benchmark for natural language to NoSQL query generation, covering six diverse languages: English, German, French, Russian, Japanese, and Mandarin Chinese (Sec. 2.1). MultiTEND not only expands the scope of natural language to NoSQL query generation to a multilingual context but also imposes additional challenges to the Text-to-NoSQL tasks. Based on the findings from our experiments (Sec. 3.2), We categorize the challenges in MultiTEND into Structural Challenge and Lexical Challenge. In particular, the Structural Challenge refers to difficulties models face in multilingual intention mapping tasks due to syntactic differences across languages, hindering accurate mapping to NoSQL operators. Additionally, the Lexical Challenge represents the schema linking difficulties models face in multilingual settings due to lexical differences (e.g., Japanese hiragana and katakana, Russian Cyrillic characters, and morphological variations in German and French) and the complexity of NoSQL structures (e.g., nested documents and array processing).\nTo tackle these challenges, we propose MultiLink, a novel framework designed to bridge the gap from multilingual input to NoSQL query generation. Specifically, MultiTEND extracts accurate operator sketches and relevant fields from multilingual NLQs through a parallel linking process, enabling the model to effectively generate high-quality NoSQL queries even in multilingual contexts. Through the incorporation of three novel and specifically designed components, namely Intention-aware Multilingual Data Augmentation, Parallel Multilingual Sketch-Schema Prediction, and Retrieval-Augmented Chain-of-Thought Query Prediction, MultiLink effectively generates high-quality NoSQL queries tailored for multilingual scenarios.\nIn summary, our contributions are as follows:\n\u2022 We present MultiTEND, the largest multilingual benchmark for natural language to NoSQL query generation, which includes detailed construction methods and will be released to promote further research in this area.\n\u2022 We conduct detailed analysis on the MultiTEND dataset, identifying the lexical and structural challenges in multilingual NoSQL generation, which arise from lexical and syntactic differences across languages as well as the inherent structural complexity of NoSQL queries.\n\u2022 We introduce MultiLink, a novel framework designed for multilingual NoSQL query generation. By addressing both lexical and structural challenges through three innovative components, MultiLink achieves significantly better performance compared to other baselines in multilingual noSQL generation scenarios.\n\u2022 We conduct extensive experiments on MultiTEND, demonstrating its challenging nature and the effectiveness of our proposed model in addressing these challenges.\nThe rest of this paper is structured as follows: Section 2 reviews related work in the field. Section 3 describes the details of the MultiTEND dataset. Section 4 outlines the architecture and training of the MultiLink model. Section 5 presents the experimental setup and results. Finally, Section 6 concludes the paper and discusses future directions."}, {"title": "The MultiTEND Dataset", "content": "To address the limitation of existing datasets in the Text-to-NoSQL domain being solely constructed in English (Lu et al., 2025), we propose the first and the largest multilingual benchmark MultiTEND in this field, covering six languages: English, German, French, Russian, Japanese, and Mandarin Chinese. In this section, we'll introduce the dataset construction pipeline (Sec 2.2) and the manual correction processing (Sec 2.3)."}, {"title": "Dataset Construction Pipeline", "content": "We segment the dataset's translation content into DB fields, NLQs, and NoSQL queries, employing a combination of prompt engineering (Sahoo et al., 2024) and manual corrections to construct the dataset."}, {"title": "Translation of DB Fields", "content": "We interpret the task of translating database fields as obtaining relationship maps from English to five different languages for the database fields. We encapsulate instructions and contextual information conducive to accurate translation, such as the database schema, the fields to be translated, and the required output format into prompts (As shown in Appendix F.1) and utilize a large language model (LLM) to complete the translation process. The translation results undergo detailed human inspection and correction (as shown in Section 2.3), ultimately yielding five maps from English to each target language for every database. These well-checked maps are used for the translation of the databases, resulting in a total of 924 databases covering six languages, derived from the original 154 English-language databases (Figure 1)."}, {"title": "Translation of NLQs", "content": "We have established the following requirements for the translation of the NLQs: (i) Semantic alignment; (ii) Preservation of specific referenced values; (iii) Fluency in language expression. Among these, the requirement to preserve specific referenced values corresponds to multilingual database fields, where the actual database values remain consistent with the original English database to ensure data consistency. To achieve efficient and high-quality NLQ translation, we have designed a step-by-step, query-intent-based, structured Prompt with contextual examples for multilingual NLQ translation (Appendix F.1). By encouraging the model to think step-by-step, we ensure the fluency and accuracy of the translation. Finally, we perform manual verification and correction of the generated NLQ (Sec 2.3) to ensure that the translated NLQ meets the specified requirements."}, {"title": "Translation of NoSQL Queries", "content": "As mentioned earlier, for each database, we have already obtained five mapping tables from English to target language for the field names (Figure 1) and conducted manual reviews and corrections. Based on these well-reviewed mapping tables, we mapped the fields referenced in each NoSQL query from English to five different languages. For each translated NoSQL query, we first filter out incorrect queries by executing them and checking the execution results, then apply manual corrections to strictly ensure the accuracy of the translated NoSQL queries."}, {"title": "Manual Correction", "content": "As mentioned in Sec 2.2, we completed the translation of db fields, NLQs, and NoSQL queries empowered by LLM and conducted final manual inspections and corrections. We summarize some of the typical mistakes discovered during the inspection of translation process as follows. For the translation part of DB fields, we identified two typical error categories: Polysemy and Abbreviation. Polysemy: Some fields can have different meanings depending on the database scenario, which is one reason for the inappropriate translation of certain database fields. For example, the term 'Movements' in the 'Aircraft_Movements' field could refer to 'motion,' 'movement,' or more specifically, \u2018take-offs and landings.' By analyzing the data type and specific values of this field, it becomes evident that 'take-offs and landings' is the most suitable meaning within the context of aircraft operations. Abbreviation: Translating abbreviations in database fields, taking into account the database context, is inherently a challenging task. Such errors constituted a larger proportion of the issues we detected in the translation of db fields. For example, 'fname' might be incorrectly translated as\u2018f\u59d3\u540d\u2019whereas it should be translated as \u2018\u540d\u2019when considering its neighbor 'lname'; similarly, 'f_id' could mean 'flight ID' or 'file ID,' depending on the theme of the collection. Similarly, 'HS' from the 'soccer_2' database could stand for 'High School,' 'Home State,' or 'Historical Score.' However, upon examining the neighboring fields and specific values within the collection, it turns out that 'HS' actually means 'Historical Score.' In the translation part of NLQs, we found that most of the NLQs not meeting the requirements mentioned in Sec 2.2 were due to insufficient fluency in the language, such as translating \"How many papers are 'Atsushi Ohori' the author of?\" into \u201c\u6709\u591a\u5c11\u8bba\u6587\u662f\u2018Atsushi Ohori\u2019\u7684\u4f5c\u8005?\u201d. This result comes from directly translating 'are' and 'of' without considering the overall structure of the sentence.\nBased on the error cases observed during the aforementioned manual inspection process, we made several adjustments to the dataset aiming to ensure the following aspects: DB fields adhere to standard database design rules and feature precise translations of polysemous words and abbreviations, aligning them with the context of the database; NLQs maintain semantic consistency and are expressed fluently and naturally; and NoSQL query results are fully consistent with the original queries. For example, we carefully examined some abbreviated fields in the original database to ensure that these abbreviations, which are difficult to understand without context, accurately convey their original meanings after translation (e.g., \"fino\" remains equivalent to \"flight number\" after translation). Additionally, we paid special attention to potential field duplication issues after translation, particularly for fields originally distinguished by case or singular/plural forms, as such differences might result in identical expressions in the target language. For example, the collection name \"continents\" and the field name \u201cContinent\u201d might both"}, {"title": "Dataset Statistics and Analysis", "content": "After our multilingual extension of TEND (Lu et al., 2025), MultiTEND ultimately includes a total of 154 databases with different content, comprising 924 databases in total, and 101,789 (NLQ, NoSQL) pairs (including 20,351 distinct NoSQL queries). The count of 101,789 pairs is derived from the fact that each query corresponds to five NLQs, with each NLQ further represented in six language versions. Approximately 16.6% of all NoSQL queries use the find method (which includes filter, projection, sort, and limit operations), while the remaining queries use the aggregate method (implemented through pipelines, which include but are not limited to project, group, match, sort, limit, lookup, and count stages) (Detailed statistics of MultiTEND see Apendix B.1). Compared to other well-regarded datasets in different fields, such as Spider (Yu et al., 2018), NvBench (Luo et al., 2021b), OverpassQL (Staniek et al., 2024), and TEND (Lu et al., 2025), MultiTEND stands out for its vast scale and comprehensive multilingual coverage (as shown in Table 1). In terms of scale, MultiTEND boasts 101,789 NLQs and 20,351 corresponding queries, far surpassing other datasets like Spider, which has 10,181 NLQs and 5,693 queries; NvBench, with 25,750 NLQs and 7,247 queries; and TEND, featuring 17,020 NLQs and 3,404 queries. Regarding multilingual support, unlike other datasets that primarily offer data in English, MultiTEND supports six distinct languages, greatly broadening its applicability and research value. Additionally, MultiTEND's semi-automated construction process, which combines machine-generated data with manual verification, provides significant advantages in terms of scalability and efficiency during its development."}, {"title": "Analysis and Findings", "content": "To clarify the challenges posed by multilingual Text-to-NoSQL tasks for existing models, we conducted a series of experiments and derived key findings from the analysis of the experimental results (See Appendix B.2). Based on the findings, we categorize the challenges in MultiTEND into Structural Challenge and Lexical Challenge. (i) The Structural Challenge refers to the difficulties models face in performing intention mapping tasks in multilingual contexts, primarily due to significant syntactic differences across languages, which reduce the model's ability to understand and parse user intentions, making it harder to accurately map them to corresponding NoSQL operators. (ii) The Lexical Challenge refers to the difficulties models encounter in schema linking in multilingual environments, mainly stemming from lexical differences (e.g., Japanese hiragana and katakana, Russian Cyrillic characters, and morphological variations in German and French) and the complexity of NoSQL structures (e.g., nested documents and array processing). These factors collectively increase the model's comprehension difficulty, leading to a significant decline in mapping accuracy."}, {"title": "Method", "content": "To address the complex challenge of generating NoSQL queries from multilingual NLQs, we introduce the innovative MultiLink framework. This framework leverages a problem decomposition strategy and an efficient Parallel Linking Process to effectively address the challenges of multilingual NoSQL query generation. In this chapter, we provide a comprehensive overview of MultiLink."}, {"title": "Overview", "content": "As shown in Figure 2 and Algorithm 1, MultiLink is primarily divided into three key components: Intention-aware Multilingual Data Augmentation, Parallel Multilingual Sketch-Schema Predictor (including a NoSQL Sketch Generator and a Schema Linking Generator), and Retrieval-Augmented Chain-of-Thought Generator. By leveraging fine-tuned SLM (Small Language Model) technology, which combines low computational resource consumption, shorter training cycles, and sufficient performance to meet our task demands, and integrating it with our data augmentation approach, we achieve cost-effective and high-yield prediction of intention mapping and schema linking. This method specifically targets the extraction of lexical and structural challenges from multilingual NLQs and effectively empowers LLM by providing contextual information, enabling the generation of more accurate and reliable NoSQL queries without significantly exacerbating model hallucinations. To address these challenges, we employ English, a high-resource language, as a unified bridge for conveying operator information across languages, while utilizing the corresponding languages for schema linking to maintain the model's sensitivity to relevant fields in each language. Finally, through our efficient RAG (Retrieval-Augmented Generation (Lewis et al., 2020)) retrieval technique and a Chain-of-Thought prompting strategy, we consolidate the extracted information into structured contexts. This approach not only mitigates hallucinations in LLMs but also significantly enhances the accuracy of NoSQL generation in multilingual environments."}, {"title": "Intention-aware Multilingual Data Augmentation (MIND)", "content": "We augment the training data using a Intention-aware Chain-of-Thought (CoT) (Wei et al., 2022) guided multilingual query augmentation strategy. Given the original (NLQ, NoSQL) pairs from the TEND dataset, we employ a LLM to synthesize additional pairs with diverse querying intents(for detailed prompt example see F.2). The augmentation process involves the following steps: (1) analyzing the structural relationships between collections and fields in the MongoDB schema; (2) identifying logical relationships between fields and collections based on the NLQ and the referenced schema portions in the NoSQL query; (3) generating new NoSQL queries with completely different intents from the original queries; (4) creating NLQs that match the intents of the generated NoSQL queries and expanding them into paraphrased variants; and (5) synthesizing corresponding NLQs in multiple languages (e.g., German, French, Russian, Japanese, and Mandarin Chinese). This process not only increases the diversity of multilingual training data but also enhances the performance of the SLMs in intention mapping and schema linking, ensuring that our pipeline can effectively handle multilingual inputs."}, {"title": "Parallel Multilingual Sketch-Schema Predictor", "content": "The Parallel Multilingual Sketch-Schema Predictor is a key component of our pipeline, designed to address the lexical and structural challenges in multilingual NoSQL generation in parallel. The predictor consists of two parallel submodules: (i) the Multilingual NoSQL Sketch Generator, which maps multilingual NLQs intents to NoSQL operators via a unified intermediate representation (i.e., English); and (ii) the Monolingual Schema Linking Generator, which maps entity mentions in the NLQ to the corresponding schema elements in the target database. By executing these submodules in parallel, Sketch-Schema Predictor ensures high accuracy and efficiency in both operator and schema mapping across multilingual contexts."}, {"title": "Multilingual NoSQL Sketch Generator", "content": "To address the challenge in intention mapping exacerbated by lexical diversity and syntactic heterogeneity in multilingual contexts, we designed Multilingual NoSQL Sketch Generator, a sketch generator incorporating the mapping from intention to operator. We adopt English, a high-resource language, as a unified bridge for cross-lingual transfer of operator information. Given a multilingual NLQ, Sketch Generator, leveraging the power of an LLM, extracts and anchors the underlying query intent by translating both the NLQ and the database schema into English. The translated English NLQ, along with the corresponding database schema, is then fed into the fine-tuned SLM to generate an intermediate NoSQL sketch. This sketch reflects operator mappings (e.g., sort, filter, aunwind), but does not include precise schema field references. By unifying multilingual intentions into a single language (i.e., English), Sketch Generator efficiently and cost-effectively streamlines the operator mapping process and ensures consistency across languages."}, {"title": "Monolingual Schema Linking Generator", "content": "In the Multilingual Text-to-NoSQL task, models are typically required to have a thorough understanding of entity mentions across complex lexicons in different languages (e.g., hiragana and katakana in Japanese, Cyrillic characters in Russian, and the rich and varied lexical forms in German and French). At the same time, they must possess the ability to cross-linguistically map entity mentions in NLQ to the corresponding fields in the database schema. The nested and unstructured nature of NoSQL schemas further exacerbates the challenge in schema linking. Therefore, we designed an efficient format to express schema linking results, such as '# Collection1: Field1, Field2.sub_field,... \\n # Collection2:..' (e.g., \u2018#\u4ea7\u54c1: \u4ea7\u54c1\u4ef7\u683c, \u6295\u8bc9.\u5458\u5de5ID\\n# \u5458\u5de5:\u5458\u5de5ID\u2019). Based on this format, we constructed corresponding corpora for schema linking in different languages. Combined with a language classifier, the schema linking generator inputs the multilingual NLQs (e.g., \u201c\u767b\u5c71\u8005\u4e3a\u4f4d\u4e8e\u4e4c\u5e72\u8fbe\u7684\u5c71\u5cf0\u8bb0\u5f55\u7684\u6500\u767b\u65f6\u95f4\u662f\u4ec0\u4e48?\u201d) into a fine-tuned SLM (Schema Linking Model) trained on language-specific schema linking corpora, in order to accurately map the entity mentions in the NLQ to the corresponding schema elements in the target database(e.g., #\u5c71\u8109:\u56fd\u5bb6, \u767b\u5c71\u8005, \u767b\u5c71\u8005.\u65f6\u95f4). By employing separately fine-tuned SLMs for schema linking in each language, Schema Linking Generator ensures high accuracy in schema linking result, addressing the lexical challenges in multilingual NoSQL generation."}, {"title": "Retrieval-Augmented Chain-of-Thought Query Generator", "content": "The final module of our pipeline is the Retrieval-Augmented Chain-of-Thought Generator, which synthesizes the final NoSQL query by integrating the results from the previous steps. Given a multilingual NLQ, the Query Generator include: (i) the reference English NoSQL query with operator mappings (from Sketch Generator); (ii) the database schemas; (iii) the schema linking result of current NLQ (from Schema Linking Generator); and (iv) retrieved examples from the corresponding language example library created from the training data. Using a Retrieval-Augmented Chain-of-Thought reasoning approach, the Query Generator significantly enhances the reasoning capabilities of the LLM by referencing similar retrieved examples in the same language and guiding the query generation process step-by-step. By combining the results from Sketch Generator and Schema Linking Generator, the Query Generator addresses the inherent challenges of multilingual scenarios. Leveraging the enhanced reasoning capabilities of the LLM, Query Generator accurately synthesizes and utilizes key contextual information, generating precise and semantically consistent NoSQL queries with higher scores and better performance compared to baseline models."}, {"title": "Experiments and Analysis", "content": "We conducted cross-domain partitioning of the MultiTEND dataset for different languages, ensuring that the training set for each language contained the same sample content. The dataset was divided into original language-specific training and test sets at a ratio of 0.85:0.15, and the training and test sets for each language were merged to form a multilingual training set and test set encompassing six languages. For the additional dataset obtained through data augmentation,"}, {"title": "Performance Comparison", "content": "Table 3 presents the average performance of MultiLink and baseline methods across all languages in MultiTEND (For detailed per-language and per-metric analysis of MultiLink and all baselines, please refer to the Appendix E.1). As shown in Table 3, the fine-tuned Llama (Dubey et al., 2024) and LLM-based methods (Zero/Few-shot LLM, RAG for LLM) underperform below 50%, with Zero-shot LLM systematically exhibiting the weakest results due to deficiencies in query intent comprehension and critical failures in processing nested arrays/multi-set associations. While the approach of RAG for LLM with enhanced contextual information shows relatively better performance in the Execution Accuracy (EX) metric that directly reflects query execution outcomes. This suggests that neither pure fine-tuning nor direct reliance on LLM capabilities constitutes an effective solution for multilingual NoSQL challenges. Additionally, while SMART, which is designed for English contexts, performs averagely in multilingual NoSQL tasks, showing significantly different results between English and non-English languages (see Table 2). This indicates that existing Text-to-NoSQL systems, cannot be directly extended to non-English scenarios. In contrast, our proposed MultiLink framework demonstrates superior performance in multilingual environments, outperforming all existing models across every metric. Particularly noteworthy is its 11% absolute improvement over the best-performing baseline in the crucial EX metric. These results validate that MultiLink's design effectively addresses multilingual NoSQL generation challenges and produces high-quality queries. Due to space limitations, please refer to appendix E.1 for more detailed analysis."}, {"title": "Parameter Study", "content": "To explore the performance of UniLink under different parameters, we conducted a hyperparameter experiment on the number of retrieved examples (RAG num) using the test set of the MultiTEND dataset. As shown in Figure 3, the figures illustrate the execution accuracy (EX) of MultiLink under different RAG numbers across multiple languages (for complete metric results of the parameter study, see the appendix E.2). As the RAG number increases, MultiLink exhibits slight fluctuations in various metrics across different languages. The execution accuracy (EX) shows that English performs the best, with minor fluctuations around 67%; French and German are in the middle range, at 5860%; while Chinese, Japanese, and Russian are lower, consistently staying within the 54%-57% range. The average performance across all languages (represented by the red dashed line) shows a steady increase and stabilizes after reaching a RAG number of 6. This indicates that as the RAG number increases, the model's performance improves within a certain range, and MultiTEND achieves its best performance at a RAG number of 6."}, {"title": "Ablation Study", "content": "In this section, we conduct an ablation study to examine the contribution of each module in MultiLink. We first measure the results of MultiLink based on the complete pipeline designed. Then, we evaluate the contribution of each module by removing different key modules from MultiLink, specifically: (i) removing the Sketch Generator (w/o Sk-G); (ii) removing the Schema Linking Generator (w/o SL-G); (iii) using only the Retrieval-Augmented Chain-of-Thought Generator (only GEN); and (iv) using components without data augmentation (w/o AUG).\nAdditionally, we include the experimental results of Few-shot LLM and Retrieval-Augmented Generation (RAG) for LLM to compare with the ablation study results. This comparison aims to demonstrate that the high performance of MultiLink is not solely reliant on the inherent capabilities of the LLM itself, but rather stems from our designed complex and effective pipeline. The results of the ablation experiments are shown in Table 4. MultiLink with all processes included outperforms other configurations across all metrics to varying degrees. Among them, the performance of w/o Sk-G is relatively close to that of MultiLink with all processes included, while w/o SL-G demonstrates that the contextual information provided by the SL-G module is crucial, significantly aiding the LLM in generating more accurate queries. The results of w/o AUG are the lowest, proving that our data augmentation method substantially enhances the performance of each module in the model. Overall, on the EX metric, which best reflects the model's performance in real-world scenarios, MultiLink with all processes included outperforms all other configurations. This validates the effective contribution of all components in MultiLink to the overall framework.\nFurthermore, on the critical EX and EM metrics, MultiLink with all major processes included significantly outperforms Few-shot LLM, RAG for LLM, only GEN, and w/o AUG configurations. This indicates that the high accuracy of MultiLink does not directly stem from the inherent understanding and generation capabilities of the LLM itself, but rather primarily from the framework itself and the information provided by the SLM enhanced using our designed data augmentation method."}, {"title": "Conclusion", "content": "In this work, we introduce MultiTEND, a large-scale multilingual benchmark dataset for Text-to-NoSQL tasks encompassing six languages. To create this dataset, we developed a robust process that combines the capabilities of LLMs with human efforts. This approach ensures high-quality, semantically aligned, and contextually accurate database fields, NLQs, and NoSQL queries through thorough manual verification. Next, we identify the inherent challenges of multilingual Text-to-NoSQL tasks, including lexical variations and structural inconsistencies across languages. To address these issues, we propose MultiLink, a unified multilingual pipeline that breaks down the complex task into manageable steps, such as multilingual query augmentation and language-specific schema linking. Extensive experiments demonstrate that MultiLink excels in generating accurate and semantically consistent NoSQL queries across multiple languages, significantly outperforming existing baseline models.\nBuilding on this line of research, we aim to explore additional methodologies for text-to-NoSQL tasks as the next phase of our work. We anticipate that this work will not only contribute to the ongoing evolution of the NoSQL field but also inspire further innovations, fostering a dynamic research landscape similar to the advancements seen in the parallel text-to-SQL domain."}, {"title": "Limitation", "content": "We propose a unified multilingual Text-to-NoSQL pipeline, which effectively addresses the lexical and structural challenges in multilingual NoSQL generation by integrating context information generated from fine-tuned SLMs and adopting a multi-step approach that combines CoT and RAG prompting methods. Additionally, our designed data augmentation method further enhances the accuracy and quality of NoSQL query generation by the framework. However, our research in multilingual aspects is still limited to six languages (English, German, French, Russian, Japanese, and Mandarin Chinese), which only cover a portion of the mainstream languages within the Indo-European and Sino-Tibetan language families, while neglecting the needs of other language families. The experimental results are constrained by the limited scope of general-purpose LLMs. For instance, although we use relatively advanced and high-performance LLMs in our experiments, there is a lack of exploration into methods that could enable lower-performance but more cost-efficient LLMs to achieve similar results on this task. The pipeline requires high computational costs for LLMs. For example, in scenarios where LLMs are used in the pipeline, for obtaining higher-quality outputs, the long-context inputs with rich examples and step-by-step reasoning outputs, significantly increases token overhead. Therefore, future research could expand to include more widely used languages, explore the application of Text-to-NoSQL in low-resource or minority languages, and investigate the use of other LLM architectures or the development of more cost-effective and high-performance neural-based framework strategies."}, {"title": "Related Work", "content": "This study is closely related to the fields of Text-to-SQL and NoSQL Databases, as briefly surveyed below."}, {"title": "Text-to-SQL", "content": "Early research on Text-to-SQL primarily focused on meticulously designed rule-based methods, such as those in (Baik et al., 2020; Li and Jagadish, 2014a,b; Quamar et al., 2022; Sen et al., 2020), these methods used predefined rules or semantic parsers to translate NLQs into SQL but were inflexible and inadequate for handling increasingly complex database structures. With the rise of deep learning, the focus of Text-to-SQL research has gradually shifted towards methods that utilize deep neural networks, such as attention mechanisms (Liu et al., 2023) and graph-based encoding strategies (Hui et al., 2022; Li et al., 2023b; Qi et al., 2022; Wang et al., 2020; Xu et al., 2018; Zheng et al., 2022; Yu et al., 2021; Xiang et al., 2023). Alternatively, some approaches treat Text-to-SQL as a sequence-to-sequence problem by using encoder-decoder structured Pre-trained Language Models (PLMs) to generate SQL queries (Cai et al., 2018; Popescu et al., 2022; Qi et al., 2022).\nIn recent years, large language models (LLMs), which have demonstrated remarkable success across various domains, have also garnered increasing attention in the Text-to-SQL field (Dong et al., 2023; Gan et al., 2021; Gao et al., 2024; Li et al., 2023a; Lin et al., 2020; Pourreza and Rafiei, 2024; Qi et al., 2022; Rubin and Berant, 2021; Scholak et al., 2021). Current literature primarily focuses on two approaches with LLMs: prompt engineering and pretraining/fine-tuning. Prompt engineering methods typically involve using specific reasoning workflows which can be categorized into several reasoning modes, including Chain-of-Thought (CoT) (Wei et al., 2022) and its variants (Pourreza and Rafiei, 2024; Liu and Tan, 2023; Zhang et al., 2024b, 2023), Least-to-Most (Zhou et al., 2023; Gan et al., 2021; Arora et al., 2023), and Decomposition (Khot et al., 2023; Tai et al., 2023; Pourreza and Rafiei, 2024; Wang et al., 2025; Xie et al., 2024). To evaluate Text-to-SQL model performance in practical applications, several large-scale benchmark datasets have been developed and released, including WikiSQL (Zhong et al., 2017), Spider (Yu et al., 2018), KaggleDBQA (Lee et al., 2021), BIRD (Li et al., 2023c), and Bull (Zhang et al., 2024a) etc."}, {"title": "NoSQL Database", "content": "Traditional SQL databases face limitations with large-scale, unstructured, or semi-structured data in the internet and big data era, prompting the rise of NoSQL databases, which provide flexibility, scalability, and high performance in web applications and real-time data analysis (Moniruzzaman and Hossain, 2013). In the field of databases and NLP, current research primarily focuses on several key areas of NoSQL databases, including achieving scalability in data storage systems within large-scale user environments (Cattell, 2011), ensuring consistency in NoSQL databases (Diogo et al., 2019), addressing multi-tenant NoSQL data storage issues in cloud computing environments, particularly in scenarios involving resource and data sharing (Zeng, 2015), and realizing scalability, elasticity, and autonomy in database management systems (DBMS) within cloud computing environments (Agrawal et al., 2011). Despite the extensive research on NoSQL across various domains, its accessibility remains a challenge, especially for non-expert users. Although Text-to-NoSQL tasks have been proposed to address this issue, existing NoSQL generation primarily supports English and overlooks the needs of non-English users. To tackle this issue, we introduce the Multilingual Text-to-NoSQL task, which is based on existing Text-to-NoSQL research and not only aims to reduce the barrier for non-expert users to utilize NoSQL databases by automatically converting NLQs into NoSQL queries but also addresses the gap in existing Text-to-NoSQL tasks that mainly support English while neglecting non-English users' needs. In this task, we also introduce MultiTEND, the largest multilingual benchmark for natural language to NoSQL query generation."}, {"title": "More Experimental Details", "content": "We utilized a variety of popular neural network models", "follows": "n\u2022 Zero-shot LLM: The zero-shot prompting approach utilizes the inherent zero-shot learning capabilities of LLM", "LLM": "The few-shot prompting technique serves as a key mechanism for in-context learning (ICL)"}, {"LLM": "Retrieval-Augmented Generation (RAG) technology provides an alternative approach to support LLM in downstream tasks. Unlike direct few-shot prompting", "SLM": "Fine-tuning is another effective strategy for enhancing the performance of language models in specific downstream tasks, such as predicting NoSQL query generation. We fine tune SLM based on two different approaches (Monolingual Training and Multilingual Training) to compare the quality of NoSQL queries predicted by SLM based on single-target language training data and training data from multiple languages"}]}