{"title": "Modeling Melt Pool Features and Spatter Using Symbolic Regression and Machine Learning", "authors": ["Olabode T. Ajenifujah", "Amir Barati Farimani"], "abstract": "Additive manufacturing (AM) is a rapidly evolving technology that has attracted applications across a wide range of fields due to its ability to fabricate complex geometries. However, one of the key challenges in AM is achieving consistent print quality. This inconsistency is often attributed to uncontrolled melt pool dynamics, partly caused by spatter which can lead to defects. Therefore, capturing and controlling the evolution of the melt pool is crucial for enhancing process stability and part quality. In this study, we developed a framework to support decision-making in AM operations, facilitating quality control and minimizing defects via machine learning (ML) and polynomial symbolic regression models. We implemented experimentally validated computational tools as a cost-effective approach to collect large datasets from laser powder bed fusion (LPBF) processes. For a dataset consisting of 281 process conditions, parameters such as melt pool dimensions (length, width, depth), melt pool geometry (area, volume), and volume indicated as spatter were extracted. Using machine learning (ML) and polynomial symbolic regression models, a high R\u00b2 of over 95% was achieved in predicting the melt pool dimensions and geometry features for both the training and testing datasets, with either process conditions (power and velocity) or melt pool dimensions as the model inputs. In the case of volume indicated as spatter, R\u00b2 improved after logarithmic transforming the model inputs, which was either the process conditions or the melt pool dimensions. Among the investigated ML models, the ExtraTree", "sections": [{"title": "1. Introduction", "content": "Laser Powder Bed Fusion (LPBF) is a popular metal additive manufacturing (AM) process that has demonstrated high precision and remarkable performance in producing complex part geometries and internal structures with micron-scale precision. The operating process of Laser Powder Bed Fusion (LPBF) involves guiding a laser using a scanning galvanometer to selectively melt a layer of powder deposited on a build plate. Once solidification occurs, the next layer of powder is spread and the process is repeated iteratively until the final part is complete [1]. In addition, LPBF offers significant advantages, including design flexibility, an automated method for building parts directly at their location of use from CAD files, and reduced material waste. These benefits have contributed to its adoption in various industries, including aerospace, automotive, medicine, energy, and prototyping [2, 3]. However, despite its increasing application in different sectors, compared to other forms of manufacturing processes such as rolling, casting, and machining, LPBF still occupies a low market share, which is attributed to its low rate of part production and poor quality control. A popular approach to remediate low part production involves using multi-lasers, which, however, increases the defect formation rate. The efficacy of state-of-the-art methods for quality control is determined by comparing the properties and performance of the finished part with the target standard, whereby variability and suboptimal performance are still reported."}, {"title": "", "content": "Identifying optimal process conditions typically relies on costly and time-intensive trial-and-error experiments across a wide range of process parameters. This challenge has motivated the use of 3D numerical modeling tools, which can effectively capture the complex phenomena occurring during melting and provide insights into parameters that are difficult or impossible to measure using current state-of-the-art in situ experimental systems. However, a high-fidelity AM simulation package that will account for all of the complex physics in AM is computationally expensive. As a result, increasing attention is being directed towards a robust smart AM manufacturing tool, which has been dubbed a solution to match the desired properties and performance of parts and AM tools [4]. This approach entails developing a digital twin of the LPBF processes which will possess the capability to mirror the real-time evolution of the part-building processes with the display of the key measurements and also for-cast future events during laser-material interactions. This type of system will enhance the detection of faults or anomalies during the printing process and enable the development of a sensitive feed-forward or backward control system to mitigate or prevent the intricacies that may occur during the printing process.At the core of the digital twin will be an integration of experimental results, system modeling analysis, and a ML model. ML enables predictive and performance insights that can be difficult to uncover through traditional physics-based modeling approaches due to the high computation cost.\n[5-8]. Monitoring the formation and dynamic processes that occur in the melt pool is one of the crucial aspects of LBPF that can improve quality control by providing an understanding of the underlying processes taking place in relation not only to the process conditions, but also to the material types that govern the nature of the melt pool, microstructure, and mechanical properties [2]. Consequently, defect formation, such as porosity, surface roughness, residual stresses, warping, cracking, and delamination that can influence quality control, will be further elucidated and prevented.\nThe general characteristic of the melt pool that has been popularly monitored to under-"}, {"title": "", "content": "stand the formation of defects or the properties of built parts is dimensions [9-13], shape[14-\n18], temperature distribution [19\u201325], oxygen content [26-30], and pressure [28]. Many studies have been reported on coupling ML with monitoring parameters collected either through experimental or modeling methods as a reduced-order method. Xiao et al. [4] predicted the future area of the melt pool using the collection of parts built from the past history by initially filtering out the noise through a a convolutional neural network (CNN)-based model, then quantitatively predicted the area of future melt pools, using artificial neural network (ANN) trained with scanning history, particularly including past melt pools as inputs from built parts, which significantly reduced the average relative error magnitude (AREM) to 2.8%, compared to the 14.8% AREM of the existing Neighboring Effect Modeling Method (NBEM). Akbari et al. [31] predicted the dimensions of the melting pool using ML models, using process parameters and material properties curated from different source of published literatures. Zhang et al. [32] implemented LSTM-based approach to estimate the area of the meltpool with accuracy of 90.7 %, then used Melt Pool Generative Adversarial Network synthesizing the images of the melt pool and achieve a structural similarity score of 0.91. Wang et al. [33] implemented a machine learning-assisted approach based on a deep neural network to demodulate the optical signal to thermal distribution and significantly improve spatial resolution to 28.8 \u00b5m/pixel spatial resolution and 10 kHz sampling frequency, ideal for measuring the sharp thermal gradient and cooling rates in the L-PBF process. Scime et al. [34] used a high-speed camera to capture the molten pool images. An unsupervised learning algorithm was proposed to distinguish the molten pool and identify defects.\nExtending quality control to the monitoring of the spatter ejection from the melt pool can provide information on the state or stability of the melt pool as defects develop [35-\n38]. In-homogeneity fusion and thermal gradient caused by spatter can be a source of crack initiation sites [39]. The traveling spatter can absorb the laser radiation or reflect it, causing a fluctuation in the intensity of the laser [40]. Limited studies have been conducted"}, {"title": "", "content": "on augmenting ML models and spatter formation, and on this path, most of the work has focused on spatter detection by coupling ML with computer vision or classifying according to process conditions or signals [3, 41\u201345], which does not provide the underlying mechanisms to the ejection rate of spatter as a means of quality control. Previously, we implemented ML to classify and detect the slight variation in the measured parameters between the spatter and the melt pool at 5 \u00b5s, unveiling the ranking of the importance of different measured parameters towards spatter ejection. Complemented by an explainable AI technique known as SHapley Additive exPlanations (SHAP), we identify the range of feature values that positively contribute to spatter predictions [5].\nExpanding the boundaries of our previous investigations, in this work we conduct both machine learning (ML) regression and symbolic regression to predict melt pool features measured at a stable state, such as dimensions (length, width, and depth) and geometric properties (cross-sectional area and volume), as well as the volume indicated by spatter. We collected our data set of spatter count versus process conditions of different power/velocity from augmentation of OpenFOAM and FLOW-3D simulations via ML classification tasks as a reduced-order method for spatter predictions. The motivation behind the techniques lies on the trade-off between the capability and computational costs of both simulation tools. However, FLOW-3D incorporates certain restrictive assumptions to reduce computational costs, which limit its ability to simulate spatter accurately. Specifically, it approximates the keyhole gas dynamics using estimates of recoil pressure and mass transfer, rather than directly simulating them. Furthermore, FLOW-3D does not account for the tangential surface tension component [46, 47]. In contrast, our OpenFOAM model directly simulates keyhole gas dynamics and incorporates tangential surface tension. The analysis indicated that the melt pool features can be predicted with a high R\u00b2 value from the process conditions (power and velocity). Similarly, the volume indicated as spatter can be predicted with a high R2 value from either the process conditions or the melt pool dimensions, as shown in Fig. 1."}, {"title": "", "content": "Our findings not only demonstrate the interconnection between process conditions, melt pool features, and spatter counts but also provide an interpretable mathematical expression of the parameters derived from the input variables through symbolic regression models, which could be crucial for process optimization."}, {"title": "2. Methods", "content": ""}, {"title": "2.1. LPBF Simulation Tools", "content": "A CFD model was developed to analyze LPBF simulation using OpenFOAMv2012 using the icoReactingMultiphaseInterFoam (IRMIF) solver [2, 48, 49]. The IRMIF solver is based"}, {"title": "", "content": "on the volume-of-fluid (VOF) method, where each phase is immiscible, and a clear boundary between each phase is calculated. The IRMIF solver handles fluid mechanics, including turbulent flow, laser beam sources with arbitrary beam shapes, heat transfer, and phase transitions such as solidification, melting, and evaporation. However, the solver did not account for the Marangoni effect due to the absence of the tangential component of the surface tension. The continuity and transient Navier stokes equation as described in equation (3) and (4) respectively.\n$\\frac{\\partial\\rho}{\\partial t} + \\nabla \\cdot (\\rho u) = 0$ \n$\\frac{\\partial (\\rho u)}{\\partial t} + \\nabla (\\rho u u) = \\nabla \\{-p \\cdot I + \\mu [\\nabla u + (\\nabla u)^T] \\} + F$\nwhere $\\rho$ is the density, u is the fluid flow velocity vector, t is the time, p is the pressure,\nI is the identity tensor, $\\mu$ is the dynamic viscosity, and F is the volume force vector. The energy equation in equation (5) was used to compute the temperature field.\n$\\rho \\frac{\\delta E}{\\delta t} - \\rho E + \\nabla (\\lambda \\nabla T + \\overline{\\overline{T}} \\cdot \\hat{u}) \\pm Sh$\nwhere E is the mixed energy, $\\lambda$ is the thermal conductivity. Further detail about the simulation can be found in our previous work [5].\nFLOW-3D (v11.2) simulations are performed to accelerate process map development.\nFLOW-3D is a multiphysics simulation software produced by Flow Science, which provides more rapid estimations of the melt pool behavior than OpenFOAM. To create a dataset of FLOW-3D simulations, 281 SS316L single-track bare plate experiments are performed at varying processing parameters for a total length of 600 \u03bcs. During simulation, the FLOW-3D package solves the equations that describe mass transfer, momentum transfer, and energy transfer during the melting process. This simulation is carried out on a structured Cartesian mesh, with mesh elements sized at 10 \u00b5m. More specific information on the equations solved and the physical phenomena considered during the simulation can be found in [20, 24, 47,"}, {"title": "2.2. Spatter Process Map Generation", "content": "This study uses a range of computational techniques and machine learning methods to analyze OpenFOAM 3D simulation data and FLOW-3D to establish a spatter process map. Features such as position (x, y, z), velocity components ($U_x$, $U_y$, $U_z$), velocity magnitude, pressure, temperature, and density were extracted from the spatter and the melt pool following the methodology we previously outlined [5]. These features of the melt pool and the spatter were passed into the ML model for the classification task. The prediction of spatter on the FLOW-3D dataset necessitates the extraction of similar features from the FLOW-3D as the OpenFOAM. The results of 281 different process conditions from the FLOW-3D dataset were pre-processed to extract the liquid fraction from the simulation as the meltpool. The velocity magnitude is calculated from the three velocity components ($V_x$, $V_y$, $V_z$) using Equation (4), producing scalar values that represent the speed at each point in the 3D grid.\n$U_{magnitude} = \\sqrt{v_x^2 + v_y^2 + v_z^2}$ \nThe features of the OpenFOAM dataset (velocity components ($v_x$, $v_y$, $v_z$), velocity magnitude, pressure, temperature, and density) are entered into the ML model for training and testing purposes. Before using the trained ML model as an inference for FLOW-3D datasets, the FLOW-3D dataset is pre-processed by aligning the range of each feature with OpenFOAM dataset. The FLOW-3D data set that represents one process condition is a representative of the average of the feature from the point the melt pool is determined to be stable to the end of the simulations."}, {"title": "2.3. Ensemble Learning and Polynomial Regression", "content": "This study performs a regression task using the ML and polynomial regression models for the prediction of the features of the melting pool or the spatter as presented in Figure 1. The"}, {"title": "", "content": "following ML models are screened with the datasets: Extremely Randomized Trees (Extra-Trees), Extreme Gradient Boosting (XGB), Random Forest (RF), Bagging, and k-Nearest Neighbors (KNN). The descriptions of the ML model are in Appendix A.1.1. To predict the spatter count, two groups of features are identified, which are the process parameters and the dimensions of the melt pool. To predict the dimension and geometry of the melt pool, only the process parameters were implemented as input features of the model. These features are inputted into either the ML or polynomial regression models. Polynomial regression is particularly effective when linear models are insufficient to capture the complexity of the data. In this case, the degree of the polynomial was vary in the range 2-6, allowing for higher-order interactions among the independent variables. A pipeline was constructed that combined polynomial feature transformation and linear regression. This pipeline streamlined the process of applying polynomial transformation and fitting the regression model. The Linear Regression model was trained on the transformed features, establishing the relationship between the independent and dependent features. Following model training, the coefficients and intercepts of the regression model were extracted. These values were used to formulate the polynomial equation, which expresses the relationship between the input variables and the target variable. The equation provides an explicit representation of the learned model, highlighting the contribution of each feature interaction to the prediction of the desired variable. The predictive performance of the model was evaluated using the coefficient of determination (R\u00b2). The R\u00b2 score reflects the proportion of variance in the dependent variable explained by the independent variables, with higher values indicating a better fit."}, {"title": "3. Results and Discussion", "content": ""}, {"title": "3.1. Properties variations and correlations across process conditions", "content": "The melt pool dynamics in the LPBF process is shaped by a complex interplay of forces: gravity, Marangoni forces, buoyancy, and recoil pressure. Gravity exerts a uniform downward pull, influencing the overall shape and stability of the molten region. In contrast, Marangoni forces arise from surface tension gradients caused by temperature and compositional variations, driving fluid flow from hotter, lower-surface-tension regions to cooler, higher-surface-tension areas. These forces create convective currents that redistribute heat within the melt pool. Buoyancy, driven by density differences in the molten material due to temperature gradients, induces additional convective flows, with hotter, less dense material rising and cooler, denser material sinking. Together, gravity, Marangoni forces, and buoyancy determine the internal flow patterns and stability of the melt pool.\nThe recoil pressure, generated by rapid vaporization at the surface of the melt pool, introduces localized pressure gradients that push the molten material away from the high-energy impact zone. This force influences the depth and shape of the melt pool and plays a significant role in material expulsion and spatter formation. The effect of these forces varies across four primary process regions: high-power low-speed, high-power high-speed, low-power low-speed, and low-power high-speed. In the low-speed, high-power region, recoil pressure and Marangoni forces often dominate, deforming the melt pool and potentially creating keyholes. Significant energy is concentrated in a small area for an extended period of time, producing a deep and wide melt pool with high volume and intense spatter, as shown in Figure 2 (b, c, d, e, f) due to strong recoil pressure and Marangoni-driven recirculation. In the high-power, high-speed region, the laser moves quickly over the material, resulting in a long, narrow melt pool with moderate depth, area, and volume, as shown in Figure 2. Although the recoil pressure is high, the limited interaction time keeps the melt pool from becoming excessively deep or wide, and the generation of spatter is moderate."}, {"title": "", "content": "In the low-power low-speed region, the melt pool is shallow and broad with minimal spatter because a lower energy input produces less recoil pressure and vaporization. This configuration favors precision and surface quality over depth, making it suitable for applications where fine control is prioritized. Lastly, in the low-power high-speed region, the melt pool is very shallow and narrow, with negligible spatter because low-power and high-speed minimize melting. Gravity and buoyancy have a more pronounced effect in this region. Each of these regions produces distinct melt pool geometries, enabling manufacturers to tailor process parameters for specific design requirements, whether for high depth and volume or minimal surface impact."}, {"title": "3.2. Machine Learning regression prediction", "content": "The performance of five machine learning algorithms: Random forests (RF), extra trees (ExtraTree), bagging, k-nearest neighbors (KNN), and gradient boost (GB) were evaluated using input features derived from process conditions and melt pool dimensions. With process conditions (power and velocity) as input, the models can predict the dimensions of the melt pool (length, width, and depth), geometric features (area and volume) and the volume indicated as spatter as shown in Figure 1b. Furthermore, using the dimensions of the melting pool (length, width, and depth) as input, the models can predict the volume indicated as a spatter, as shown in Figure 1c. The hyperparameters implemented for the ML models, such as the number of estimators, the maximum depth, the number of neighbors, and the learning rates, are listed in Table 1. Table 2 summarizes the performance metrics used, including R2 scores for both training and testing sets, as well as mean absolute error (MAE) for both sets. The R2 score measures the proportion of variance in the dependent variable that is predictable from the independent variables, while the MAE quantifies the average magnitude of the prediction errors, regardless of their direction. Using power and velocity as the model input, the R\u00b2 predictions for the melt pool length data set show strong performance, with the training data set R2 values exceeding 98%, and the lowest R\u00b2 for the test dataset reaching 95.6% when using the ExtraTree model. Similarly, high R\u00b2 values were observed for depth, melt pool area, and volume, with R\u00b2 scores for training and test sets exceeding 97%. For depth, R\u00b2 values remained consistently high (> 97%) on both the training and the test data. However, a slight drop in the R2 prediction was observed for width, with the lowest values appearing in the KNN model, where the training and test R2 scores were 97.4% and 91%, respectively. A further drop in the prediction of the volume indicated as spatter; in this case, the most promising model was RF, with training and test R\u00b2 values of 94.1% and 83.4%, respectively.\nIntroducing logarithmic terms to the input was considered a strategy to improve accuracy,"}, {"title": "", "content": "as it can better capture nonlinear relationships between the variables. Upon adjusting the input of the model from power and velocity to power, velocity and log(Velocity), the ExtraTree model demonstrated the most significant improvement in test accuracy. The test accuracy of ExtraTree increased from 79.6% to 84.1%, while its training accuracy improved from 91.4% to 94.3%. This enhancement highlights the potential of input manipulation through logarithmic transformations to improve prediction accuracy by effectively modeling nonlinear dependencies.\nBecause power and velocity are fixed during a particular process operation, our results demonstrate that these process conditions can effectively predict the characteristics of a stable melt pool. When using the dimensions of the melt pool (length, width and depth) as inputs into the ML models to predict the volume indicated as a spatter, we observed an accuracy comparable to when power and velocity were used as inputs. The KNN model achieved the highest test accuracy at 82.3%, with a training accuracy of 85.8%. Although the Extra Tree model had the highest training accuracy at 90.5%, its test accuracy was slightly lower at 80.1%. Upon introducing logarithmic terms to the model input, changing them from length, width, and depth to log length, width, depth, log width, and log depth, the most significant improvement was observed in the Extra Tree model, with training and test accuracies reaching 95.8% and 87.5%, respectively. This improvement highlights the effectiveness of incorporating logarithmic terms to capture the nonlinear relationships within melt-pool dimensions, enhancing the prediction of volume indicated as spatter."}, {"title": "3.3. Polynomial regression prediction", "content": "To understand the relationship between the input and the output, polynomial regression was implemented, as it offers interpretability by breaking down the influence of each input variable and its interactions on the output prediction. This interpretability arises from the polynomial terms in the regression equation, where each term directly reflects the contribution of an input variable or a combination of variables to the overall prediction. Upon conducting polynomial fitting, where process conditions (power and velocity) were input while any of the melt pool dimension or geometry features served as the output, high performance was observed with training and testing R\u00b2 exceeding 94%, as shown in Figures 4 and 5, respectively, and their values listed in Table 3 with the corresponding degree of polynomial implemented. The lowest performance among the melt pool dimension and geometry features was with respect to width (training R\u00b2: 95% and testing R\u00b2: 95%). Achieving the reported performance for width required using a higher-order polynomial (degree 5), indicating complexity in calculating the width as more interacting terms are involved.\nA polynomial regression model was developed to predict the volume indicated as a spatter using four separate input features of which two sets of the process condition and the other two sets from melt pool dimensions: [Power, Velocity, and log(Velocity)] and [log(length), width, depth, log(width), and log(depth)], respectively. Logarithmic transformations were applied to the input process conditions and melt pool dimensions to enhance spatter prediction, as the logarithmic transformation can stabilize the variance across different ranges of the data. In addition, logarithmic transformations reduce skewness in variables. An improvement in both the training and the test accuracy was observed when a logarithmic transformation was applied to both the process condition and the input of the dimension of the melt pool. With respect to the process condition, we achieved increments of 8. 4% and 5. 3% in the training and testing R\u00b2 values, respectively, by applying the logarithmic terms. A sixth-degree polynomial model was identified as the best fit, indicating the need to express complex"}, {"title": "", "content": "non-linear interactions between these features in the process conditions. Concurrently, an improvement in performance was observed when a logarithmic transformation was applied to the melt pool dimensions as input into the polynomial regression model. Training and testing R2 increased by 6. 3% and 15. 5%, respectively, after the introduction of logarithmic terms.\nThe equations for different trained features are listed for the properties of the melt pool in Table 4, for the volume indicated as spatter in Tables 5 and Table A.6 in the Appendix. To quantify the importance of features in the equations, the absolute coefficients of the top contributing variables were extracted and their percentage contributions are shown in Figure 6. The generated equations indicate that the prediction of variables like length and depth depends more on the introduced power than on the velocity, while the width depends more on the velocity than on the power. At a particular velocity, the depth or length value will intuitively depend on the applied power, since the power influences the dynamics of the melt pool, the amount of liquid fraction and the rate of solidification. However, the fact that velocity has a stronger importance than power for the width suggests a low sensitivity of power over a wide range of velocities, as the melt pool motion and temperature gradient are influenced, making the stabilization of the width more dependent on velocity. The greater magnitude of length and depth range compared to width range, as shown in Figure 2 in the investigated process conditions, could have led to the strong importance of power in the geometry features of the melt pool (cross-sectional area and volume). Since the influence of power is more dominant in the equations for both length and depth, the dependency of the volume of the melt pool on these variables is likely influenced by power, as observed in Figure 6E. The effect of width, being more influenced by velocity, arises from the cross-sectional area but is not strong enough to dominate over the power. The term Velocity\u00b2 is the most important variable for the predicted volume indicated as spatter when the process condition was used as the input of the model, as shown in Figure 6 F. Upon applying a"}, {"title": "", "content": "logarithmic transformation to the process condition in Figure 6G, it was found that the top two ranking variables are \"Power\u00b3, Velocity\" and \"Power\u00b3, log(Velocity)\", indicating that they are highly influential in determining the volume indicated as a spatter when a logarithmic transformation is applied to the process conditions. In the case of applying the dimensions of the melt pool as input to the regression model, it was found that the width followed by the depth is the most important, as shown in Figure 6H. Upon applying a logarithmic transformation to the dimension of the melt pool in Figure 6 I, the width derivative in the form of log(width) and log(width)\u00b2 was found to be the first two variables to be most significant, indicating the prominent role of width before and after applying the logarithmic transformation to the prediction of volume indicated as spatter."}, {"title": "4. Conclusions", "content": "In this work, we analyze a spatter dataset collected by coupling OpenFOAM and FLOW-3D, leveraging the strengths of both simulation packages. OpenFOAM generates realistic spatter occurrences but is computationally expensive, while FLOW-3D is computationally efficient but lacks the physics to produce realistic spatter phenomena. With this configuration, we collected a dataset comprising melt pool length, width, depth, cross-sectional area, volume, and volume indicated as spatter. The performance of machine learning models and polynomial regression was evaluated on the collected parameters, showing high accuracy of 95% and above for melt pool dimensions and geometry features for both ML models and polynomial fitting. For predicting the volume indicated as spatter, the Extra-Trees model achieved the highest R\u00b2 scores of 0.97 and 0.88 for the training and testing datasets, respectively. Using polynomial fitting, we derived equations for each melt pool dimension,"}, {"title": "", "content": "geometry, and volume indicated as spatter based on model inputs, enhancing interpretability by showing how input variables influence the outputs. This findings open opportunities for robust control systems to monitor part production, minimize defect formation, and ensure repeatability in AM processes."}, {"title": "Declarations", "content": ""}, {"title": "Funding", "content": "This research was sponsored by the Army Research Laboratory and conducted under Cooperative Agreement Number W911NF-20-2-0175. The views and conclusions presented in this document are those of the authors and do not necessarily represent the official policies or positions of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes, despite any copyright notice herein."}, {"title": "Competing Interests", "content": "The authors have no competing interests to declare that are relevant to the content of this article."}, {"title": "Appendix A. OpenFOAM simulation domain", "content": ""}, {"title": "Appendix A.1. Machine learning prediction", "content": ""}, {"title": "Appendix A.1.1. Random Forest (RF)", "content": "Random forest regression is an ensemble method that enhances predictive accuracy by averaging multiple decision trees, which reduces overfitting [52]. This technique leverages random sampling of data and features, capturing complex interactions and improving generalization [53]. Known for its robustness in high-dimensional, nonlinear datasets, random forests also provide insights into feature importance, aiding model interpretability[54]."}, {"title": "Appendix A.1.2. The Extra Trees Regressor", "content": "The Extra Trees Regressor, or Extremely Randomized Trees, is an ensemble method similar to random forests but introduces more randomness to improve performance and reduce variance [55]. Instead of selecting optimal split"}, {"title": "Appendix A.1.3. Bagging Regressor", "content": "The Bagging Regressor is an ensemble method that improves prediction accuracy by combining the outputs of multiple base regressors trained on randomly sampled subsets of the data [57]. This technique, also known as bootstrap aggregation, reduces model variance and enhances generalization by averaging the predictions of each model, often resulting in more robust performance compared to a single model [53]. Bagging is particularly effective for high-variance models, such as decision trees, and can be customized with different base regressors to suit various tasks."}, {"title": "Appendix A.1.4. The K-Nearest Neighbors (KNN) Regressor", "content": "KNN Regressor is a non-parametric method that predicts the value of a target variable based on the average of its k closest data points (neighbors) in the feature space [58]. This approach is simple and effective for datasets where similar instances yield similar outputs, but its performance can be affected by high-dimensional data and may require scaling to handle features of different units effectively. The choice of k impacts the model's bias-variance trade-off, with smaller values leading to more variance and larger values resulting in smoother, potentially biased predictions [59]."}, {"title": "Appendix A.1.5. The Gradient Boosting (GB) Regressor", "content": "The Gradient Boosting Regressor is an ensemble learning method that builds a sequence of weak learners, typically decision trees, where each subsequent model corrects the errors of its predecessor [60]. By minimizing a loss function through gradient descent, it achieves high accuracy and handles complex, non-linear relationships well. Known for its"}]}