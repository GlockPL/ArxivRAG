{"title": "FUNDAMENTAL VISION-BASED NAVIGATION ALGORITHMS: INDIRECT SEQUENTIAL, BIASED DIFFUSION, AND DIRECT PATHING", "authors": ["Patrick Govoni", "Pawel Romanczuk"], "abstract": "Effective foraging in a predictable local environment requires coordinating movement with observable spatial context - in a word, navigation. Distinct from search, navigating to specific areas known to be valuable entails its own particularities. How space is understood through vision and parsed for navigation is often examined experimentally, with limited ability to manipulate sensory inputs and probe into the algorithmic level of decision-making.\nAs a generalizable, minimal alternative to empirical means, we evolve and study embodied neural networks to explore information processing algorithms an organism may use for visual spatial navigation. Surprisingly, three distinct classes of algorithms emerged, each with its own set of rules and tradeoffs, and each appear to be highly relevant to observable biological navigation behaviors.", "sections": [{"title": "1 Introduction", "content": "As dissipative systems, all biological beings are bound by the curse of having to find food. While some have evolved sedentary strategies, others need to move to ensure a steady flow of nutrients. When the location of food is unpredictable, this movement can be classified as a search problem. A classic approach to foraging, much has been written in regards to optimal search time and energy (Pyke et al., 1977), patch staying vs. leaving decisions (Hayden et al., 2011;\nDavidson and Hady, 2019; Wispinski et al., 2023; Chaturvedi et al., 2024), as well as corresponding movement patterns (B\u00e9nichou et al., 2005; Popp and Dornhaus, 2023). Whereas search strategies may prevail in unpredictable environments, organisms living in environments with some regularity in food location would benefit from the ability to return to known resource-abundant areas, e.g. a bee to a flower patch, a mouse to the kitchens of an apartment building, or a human foraging for mushrooms. Simply put, the organism must learn to navigate.\nForaging navigation involves correlating perceivable features with expected food location, requiring the external environment to be sensed and processed before effective movement is taken. Given its broad ubiquity across the animal kingdom and its informational importance (Zeil, 2023), this study focuses on vision as the sole sensory modality. Rather than analyzing how biology currently answers the navigation problem, a more conceptual approach that explores potential algorithms for connecting sensory information with useful action can offer unique insights.\nUsing Marr's levels to construct our hypothetical organism as an informational processing system (Bechtel and Shagrir, 2015; Krakauer et al., 2017): the computational level is tasked with navigating to an expected food location in a given environment, the algorithmic level relates to the strategy or behavior needed, and the implementational level translates perceptual input to movement. While the high level is fixed in a given environment and the low level is relatively"}, {"title": "2 Implementation", "content": "Visual input, stemming from a previous publication by our lab (Bastien and Romanczuk, 2020), was simulated as a one-hot encoded raycast from the agent to the boundary walls of the environment (Fig. 1). Though a simplification from 2D vision, collapsing the vertical dimension has been found to retain sufficient directional information for visual navigation (Wystrach et al., 2016; Zeil, 2023).\nTwo key hyperparameters govern the raycasting process: field of vision (FOV) and resolution. FOV stretches the limits of the raycast with respect to the agent, and resolution determines the number of rays to cast within these limits. The FOV was set at 40% or 144 degrees to mimic the functional visual field for humans, as measured by reaction time to discrimination tasks (Sanders, 1970), though the impact of FOV on navigation performance was also assessed (Fig. S1). The visual resolution (v) was minimally initialized at 8 for much of the analysis and was later varied to examine its effect on behavior (Fig. S2).\nFor basic perception, visual contact with walls was binary, not weighted by distance, while Weber-Fechner logarithmic scaling was applied for more complex vision, similar to how height is perceived by our eyes (Dehaene, 2003; Portugal and Svaiter, 2011; Buzs\u00e1ki and Mizuseki, 2014). In an unknown environment, an accurate distance estimation requires memory or prediction of wall height, or dynamic parallax inference, both of which require higher order computation and are prone to inaccuracies. Non-scaled vision represents minimum reliable environmental information, where only visual angles are available, and distance information was added at increasing attenuation levels to characterize increasing perceptual ability or memory. The scaling was calculated as follows:"}, {"title": "2.1 Perception", "content": ""}, {"title": "2.2 Environment + Task", "content": "The environment was designed to be minimally complex: a square grid with four distinctly perceivable walls. Using boundary walls rather than landmarks was to restrain ability to estimate distance via horizontal width, forcing the algorithm to rely soley on relative angles to grid corners. The agent was initialized in random locations and orientations for each simulation, driving the agents to learn an allocentric rather than egocentric representation of space.\nEnvironmental geometry provides the spatial reference needed for both orientation and location (Chan et al., 2012), here bound by the four corners, which can be viewed as landmarks without directly estimable depth. Although landmark and geometric encoding has been argued to be performed by separate modules (Wang and Spelke, 2002; Lee and Spelke, 2010; Doeller and Burgess, 2008; Doeller et al., 2008), in the present study the two are not differentiated.\nThe setup mirrors the classic Morris Water Maze, which tests spatial learning in mice and rats, as well as humans with a later variant of the setup (Schoenfeld et al., 2017). As for the former, rodents are placed in a cloudy pool of water and must find a hidden platform submerged below the surface. If placed in the same starting location every time, the rodents may learn an egocentric strategy by counting the number of strokes taken in each direction in order to reach the platform (Jiang et al., 2022). If placed in random locations and orientation however, the rodents must learn an allocentric strategy by correlating external visual cues with an effective trajectory. It is this second, more challenging version of the experiment that relates to our setup. Since the spatial context changes unpredictably, vestibular integration and within-trial memory are not critical components."}, {"title": "2.3 ANN Architecture", "content": "The agents' information processing consisted of three modules: a convolutional network (CNN), a multilayer perceptron (MLP), and a linear output layer. The CNN used is a simplified version of the ConvNeXt v2 architecture (Liu et al., 2022; Woo et al., 2023), a state-of-the-art design that outperforms earlier varitions in the CNN design space and rivals the best vision transformers. While simpler designs exist, the ConvNeXt was chosen for its separable depthwise and pointwise convolutions, where separate parameters act on the orthogonal depth and channel axes, enabling greater expressibility for relatively low additional computational cost. A transformer was not chosen since they lack biological inductive biases, such as translation equivariance, and due to their novelty, lack the understanding and tools currently available for CNNs (Khan et al., 2022).\nA simple MLP was chosen as recurrent memory allowing a more complex temporal representation of the environment was not the goal of the present study. Rather, temporal perceptual ability or memory was phenomenologically implemented by adding distance scaling to the visual encoding. The single network output was scaled through a Tanh and linear hat function, representing a ratio between turning angle and speed. This choice reflects an intuiting action space constraint that organisms need to slow down in order to turn.\nBeyond critical minimal values, depth and dimension of the CNN and MLP did not noticeably affect performance (Fig. S3, Fig. S4). Notably, two channel outputs for the CNN is insufficient for agents to reliably solve the task, possibly reflecting an intrinsic, minimal dimensionality to the navigation problem (Li et al., 2018)."}, {"title": "2.4 Evolutionary Algorithm", "content": "The network was optimized via an evolutionary strategies (ES) algorithm: Policy Gradient Parameter Exploration (PGPE) using the ClipUp optimizer (Sehnke et al., 2010; Toklu et al., 2020). ES uses population-based black-box optimization without gradient calculation, unlike reinforcment learning (RL) which optimizes a single agent, often via discounted rewards, by using backpropagation on a continuous differentiable objective function. ES entails less complexity than RL, as there is no need for differentiability, value function approximation, or temporal credit assignment (Majid et al., 2021). Additionally, the intrinsic exploration of the population-based approach can help navigate rugged fitness landscapes. The main drawback of ES, sample inefficiency, is acceptable given its parallelizability (Salimans et al., 2017). Among various ES algorithms, PGPE was chosen for its balance between performance and speed, with greater performance than OpenAI-ES and greater speed than CMA-ES (Ha, 2017). While the choice of initial random seed seems to cause issue to other types of RL algorithms, it did not affect our performance distribution (Fig. S5).\nFitness, or performance, was measured as the time taken to reach the patch plus the remaining distance. The former is the primary driver for judging how well the agent navigates, and the latter drives initial learning behavior. The relative weighting of each was varied in initial experiments but found to not make a significant difference."}, {"title": "3 Results", "content": "Training the networks to this simple navigation task and environment yielded expected relative performance distributions (Fig. 2). While only visual angle input is needed to adequately learn the task, performance and speed of convergence improves relative to the saliency of the added distance signal. At maximal distance input, performance approaches that of perfect trajectories straight to the patch, though with a long tail depicting the few initializations at the corners of the arena that result in a premature limit cycle locked in a corner (a case to be explained in detail later). Attenuated scaling reduces the utility of the distance information in the network. At \u03c3 = 0.2 signal variation is too subtle for the network to effectively use the information, slowing down learning rate and hindering performance, while at o = 0.2 the signal is not used at all.\nOn the other hand, an intriguing interplay of divergent individual signatures, despite convergence into classes or archetypes, was observed in the navigation trajectory space (Fig. 3). With angles-only vision, most trained agents from separate evolutionary runs tended to learn one of two separate strategies that we term \"Indirect Seqential\" and \"Biased Diffusive\". While adding distance scaling to the visual input resulted in a third class called \"Direct Pathing\". This clustering illustrates separate, competing potential wells in the algorithmic landscape, and as we will show, each class uses visual input and moves about the space with styles quite distinct from one another. It is clear that this approach yields substantial room to explore our previously posed questions on how the algorithmic level, i.e. navigation behavior, may be affected by different environmental, perceptual, and neuronal parameters."}, {"title": "3.1 Indirect Sequential", "content": "Perhaps the most striking of the three classes of algorithms are those that compose a sequence of route segments, scaffolded by distinct elliptical arcs sweeping across the arena (Fig. 3a). Tracing individual agent trajectories towards the patch involves long straight segments interrupted by sharp turns. Echoing indirect navigation through a grid-like city, these turns are often close to right angle, oftentimes travel is perpendicular to the destination, sometimes doubling back in the opposite direction before continuing. Though instead of buildings specifying route nodes, elliptical manifolds determine turn location, reducing the space of navigational possibilities to a compact route sequence. Despite a lack of distance perception, the agents learn to use spatial invariances in the environmental structure in order to reach the patch. However which invariances to use and how to compose them into an effective strategy varies between runs, as shown by the T-like, either clear or blurry, and plus sign patterns of the representative examples."}, {"title": "3.2 Biased Diffusive", "content": "The movement profile of the local sequential agents stands in stark contrast to the second class of algorithms, which can be distinguished by looping or ratchet-like trajectories, with a complete absence of major turn points (Fig. 3b). While overall progress is generally biased towards the direction of the patch, these agents have found their niche by regularly spinning around before continuing in the direction of the patch, as if they are looking around to sense relative global position.\nRather than learning which locations to stage major turns, they vary turning speed to dynamically bias their overall motion, turning faster when facing away and slower when facing towards the patch. The trajectory maps render clouds of agent trajectories with little apparent correlation amongst each other, illustrating in contrast to the previous group that there are no clear manifolds or sequence compositions, instead the process is diffusive. The more distributed profiles in the heading profile and polar histograms show the decreased relative importance of particular directions (Fig. 4b). The diagonal lines across their spatial profiles show the constant speed at which these agents turn.\nGiven the similarity between their trajectory maps and sperm chemotaxis, we temporally correlated orientation from initial heading (Armon et al., 2012):"}, {"title": "3.3 Direct Pathing", "content": "Until now, agents have not been able to perceive their distance from walls, relying instead on simple binary vision and relative angles. Adding distance information to the visual input gives rise to a third class of algorithms, allowing agents to navigate directly to the patch.\nAlthough superior in navigational performance, these trajectories require a more complex visual system, a tradeoff likely relevant in nature. These agents often immediately incorporate wall distances and align with the direction of the patch. Many instantiations of the direct pathing algorithm calculate unique paths for each potential initialization, resulting in spiky star-like trajectory maps as in the top example of Fig. 3c. Each differs in the degree common routes collapse as they approach the patch, resembling preferential alignment along entangled fast and slow nullclines.\nThe directness of their routes also shows up in their spatial profiles and polar histograms (Fig. 4c). After the initial heading calculation, the vast majority of movement is confined to a tight range along that same direction. The accuracy of their localization ability is demonstrated by the tight revolutions of the ending trajectories near the center of the patch, and the thin cyclical space in the left hand side of their spatial orientation profiles.\nThough there are some locations in the environment that catatrophically break the navigability of some instantiations. The circles at the four corners of the trajectory maps of the bottom right example in Fig. 3 and the corresponding low directedness shown in Fig. 4 reveal the existence of these condemned fates. Given the logarithmic nature of the distance scaling, agents perceiving a corner maxes out their turn, and each succesive orientation is still close enough to the corner that the perception-action loop traps the agent in position. Although more apparent and frequent when distance information is available, these cycles are sometimes observed in the corners for biased diffusive agents. These maladaptive limit cycles are apparently an edge case that do not occur often enough in the generational timeframe for the evolutionary algorithm to adequately account for. A caution for model choice, these artefacts are due in part to the deterministic nature of the networks.\nBy attenuating the distance signal, the evolvability of direct pathing algorithms decreases until the other two classes fully occupy the resulting space (Fig. 5 6). At a distance scaling factor of 0.4, the three classes coexist at a triple point, though as mentioned before, as continuums among each other rather than as clearly designated phases (Fig. S18). What"}, {"title": "4 Discussion", "content": "We trained simple yet expressive artificial neural network controlled agents to visually perceive a sparse grid environment and move to a hidden patch in a robust and efficient manner. By initializing the agents in random positions and orientations for each task iteration, they were forced to develop a perceptive-invariant, allocentric frame of reference to perform indirect spatial inference, correlating visual cues of the environment boundaries with movement towards the patch.\nThree distinct classes of algorithms emerged in order to accomplish this, each with a set of distinguishable features. The first class of agents navigate by composing a sequence of straight segments, indirectly oriented with respect to the patch, with major turns defined by elliptical-shaped manifolds. These manifolds designate spatially invariant thresholds which separate potentially distinct perception-action control regimes, and arise through a perceptual degeneracy in rotational and translational degrees of freedom. The second class uses the same manifolds to perceive the environment, though rather to dynamically adjust turning speed, resulting in diffusive motion biased towards the patch. And the third uses distance perception, i.e. memory and inference, to accurately determine near perfect paths directly to the patch. Described in terms of their perceptual preference and resulting behavior, these classes are termed indirect sequential, biased diffusive, and direct pathing, respectively.\nAngle-based algorithms (indirect sequential and biased diffusive), confer comparable performance though prefer different visual resolutions. Indirect sequential agents evolve more readily with lower visual resolution and biased diffusive with higher. While only requiring a lower quality visual signal and local observations, the indirect sequential agents are highly susceptible to visual angle noise throwing them off-course, whereas such noise does not affect the dynamic, globally perceptive process of the other class. The distance-based, direct pathing agents perform better than either angle-based class, resulting in an abrupt phase transition as the distance input is computationally usable however require a second informational dimension to their perceptual process.\nThe three classes can be separated by decorrelation time and entropic directedness. Decorrelation time indicates temporal persistence in heading, and directedness indicates directional potential in space, in other words if an agent is more likely to be traveling in one or many directions at a particular point. Biased diffusive has low measures for both, indirect sequential has medium, and direct pathing has high. While the three classes tend to cluster into distinct bins in this 2D phase space, they are not mutually exclusive. Hybrid forms share features across classes, using a mixture of information types and behaviors to construct their routes."}, {"title": "4.1 Convergent Behavior", "content": "A convergent learning hypothesis has recently emerged to explain the striking similarity between early parts of the visual cortex and convolutional neural networks, the latter of which contains only abstract biological detail and is trained on simple image classification tasks (Yamins et al., 2014; Khaligh-Razavi and Kriegeskorte, 2014; Lindsay, 2021). The hypothesis proposes that training a sufficiently expressive network to perform a task, whether biological or artificial, will ultimately result in similar learned task behavior and representations. Further evidence has started to accumulate as artificial networks trained on biological tasks have been used to generate neural control hypotheses (Lake et al., 2017; Haesemeyer et al., 2019; Musall et al., 2019; Hennig et al., 2021) Similarly, a \"universality hypothesis\" is being explored in the machine learning community, attempting to explain how a wide array of artificial neural network architectures and initializations can result in similar trained representations (Li et al., 2016; Raghu et al., 2017; Kornblith et al., 2019; Maheswaranathan et al., 2019; Olah et al., 2020; Chughtai et al., 2023; Ostrow et al., 2023)."}, {"title": "4.2 Convergent Behavior: Morris Water Maze", "content": "The three classes of navigational algorithms and trajectories, resulting simply from optimization towards effective navigation, appear to reflect rodent swimming paths observed in the Morris Water Maze (Rogers et al., 2017; Berkowitz et al., 2018). Having to rely on vision and their memory of previous attempts, rodents learn to navigate to a hidden platform. While the optimal choice is to take the direct path to the patch, many rodents travel in a clearly wrong direction before making a turn that takes them to the patch. Although often termed \"indirect search\", this pattern parallels behavior of the indirect sequential class (Cooke et al., 2020; Curdt et al., 2022). Other rodents instead walk towards the patch yet spin in circles as they approach, attributed as \"self-orienting movements\" or even \"nonsense movements\" of a \"directed search\" strategy (Graziano et al., 2003; Cooke et al., 2020; Curdt et al., 2022; Villarreal-Silva et al., 2022). In a similar way, biased diffusive agents rotate in a similar fashion to these trajectories.\nThe relative performance distributions of the three strategies corresponds closely to those of the two angle-based strategies and the slightly better performance of the distance-based, direct pathing class (Graziano et al., 2003; Cooke et al., 2020). The relative occurence frequencies are roughly on balance between the three classes, as seen for distance scaling factor of 0.45 in Fig. 6. This may be argued as an evolutionary optimal condition for the species, since each strategy is balanced by tradeoffs. Individual variation in visuo-spatial preference has been observed across populations of zebrafish, likely evolved as a population-level survival strategy (Yashina et al., 2019).\nThe observation of behavioral hybridization mirrors the recent studies that segment rodent navigation behavior observed in a single trial into multiple separate strategies (Gehring et al., 2015; Vouros et al., 2018). Rather than averaging the behavior across an entire episode and fitting it into a single class, each strategy may be used at different situations or frequencies. A more robust navigational strategy utilizing multiple algorithms however requires a different computa- tional medium than that tested in the present study, as it would involve a system of how to choose and when to switch behaviors."}, {"title": "4.3 Convergent Behavior: Binary Spatial Choice", "content": "This behavioral similarity between water-bound rodent and simulated agent trajectories presents an intriguing hypothesis: are the learned representations of the aritifical agents similar to those of the rodents?\nSuggestively, elliptical decision-making thresholds have appeared recently as governing spatial choice bifurcations (Sridhar et al., 2021; Gorbonos et al., 2024). Fruit flies, desert locusts, and zebrafish have each been observed to move towards the average of two choices until reaching a critical threshold and spontaneously force the decision towards one or the other option, even in sequence if more than two options are available. By simulating this behavior, Gorbonos et al has found elliptical geometry to define this threshold, spanning two options in much the same way ellipses defined by two adjacent corners govern navigational decisions in indirect sequential agents.\nA ring attractor model, using a spin system or a Hopfield network, reproduced these bifurcations through local excitation and global inhibition between choices. Rather than resulting from training perception-action loops for a navigation task, the model describes the emergence of choice between goal vectors. While the generated elliptical threshold is used to compose route segments for indirect spatial inference in our case, here it is used to mark when to choose to travel towards a particular goal or set of goals.\nDespite both computational and implementational level details are distinct from the present study, the representational space appears to have converged on a common element. In fact, this only compounds the argument of the fundamentality of this spatial decision-making algorithm."}, {"title": "4.4 Convergent Behavior: Sperm Chemotaxis", "content": "In a third case of convergent behavior, the biased diffusive trajectories mirror the helices of sperm cell chemotaxis (Friedrich and J\u00fclicher, 2007, 2008; Armon et al., 2012; Kaupp et al., 2008; Alvarez et al., 2014; Kromer et al., 2018; Jikeli et al., 2015; Ram\u00edrez-G\u00f3mez et al., 2020; Zaferani et al., 2021). Although not visually sampling environmental landmarks, sperm cells sample chemical concentrations to bias their motion up-gradient towards an egg. Distinct chemotactic behavior from slime molds, which measure concentration at different spatial points in their body to estimate the gradient, sperm as well as bacteria compare concentration across different points in time as they move (Alvarez et al., 2014). Bacteria temporally correlates concentration through modulating stochasticity, a process described as a biased random walk, while sperm deterministically modulates the curvature of their swimming path, constructing helices up a gradient (Alvarez et al., 2014). This results in sustained correlation oscillations in heading across time (\\((Armon et al., 2012)\\)), as in Fig. 4."}, {"title": "4.5 Vision vs. Vectors", "content": "The success of purely visual navigation algorithms, even without distance information, as well as the apparent similarity to rodent trajectories, provides evidence for the sufficiency of vision-based representations to guide navigational behavior. The leading hypothesis, cognitive maps, has been widely accepted as the way many organisms represent space, with place cells tuned to specific points along a scaffold of grid cells, collectively comprising a Euclidean graph (Epstein et al., 2017; Stachenfeld et al., 2017; Behrens et al., 2018; Bellmund et al., 2018). A major argument for such a representation is the ability to flexibly take novel shortcuts between two locations.\nThough the robustness of this ability has been put in question. Warren has argued that although a Euclidean structure would be convenient, several experiments have demonstrated consistent errors in direction estimation and route integration as well as systematic local feature biases (Warren et al., 2017; Warren, 2019; Ericson and Warren, 2020). Instead, a labeled graph or a network of views better describing the locality and bias observed.\nA unifying perspective suggest multiple parallel representations exist, including: Euclidean maps, route graphs, and local scene or image systems (Redish and Touretzky, 1998; Bottini and Doeller, 2020; Peer et al., 2021; Linton, 2021; Dilks et al., 2022). Each can benefit from partial information sharing from the other, such as using local observations to update angles between points on the map or route graphs (Kunz et al., 2021). Navigation via direct perception of the environment, the type explored in this study, aligns closely with the image-based representations of the parahippocampal place area, occipital place area, and retrosplenial complex (Peer et al., 2021; Dilks et al., 2022). Although distance information, kept abstract in the present study, perhaps arises from a cognitive map or cognitive graph representation."}, {"title": "4.6 Vision vs. Vectors: Individual Variation", "content": "Individuals seem to differ in preference of spatial representation, often illustrated as a continuum between map-based and route-based systems (Marchette et al., 2011; Anggraini et al., 2018; Boone et al., 2019; Spiers et al., 2022; Newcombe et al., 2023). While map-based navigation is often portrayed as superior (Weisberg and Newcombe, 2018), both systems appear to perform on par with each other (Marchette et al., 2011; Shelton et al., 2013), with slight advantages towards one or the other in their respective environment (Spiers et al., 2022). Recent evidence has proposed both reference frames to project into our understanding of the environment (Wang et al., 2020), likely with variable preferential ratios.\nIn context of the present study, this aligns with the continuum between direct pathing agents, which uses a spatial map to estimate distance to boundaries to interpolate patch location and direction, and the angle-based agents that use visual input to construct routes. Variation within the route-based navigation class does not seem to have been well-studied (Kunz et al., 2021), perhaps due to its perceived non-ideal nature. The usefulness of such strategies seems to be an under-explored area, whether it be computational simplicity or risk avoidance in an environment with potentially dangerous shortcuts.\nIntraspecies differentiation in navigation ability is not unique to humans. In a study by Yashina et al, individual zebrafish exhibited a variety of individually consistent strategies, differing in the way they use spatial cues to safely navigate their environment (Yashina et al., 2019). A notable recent study found consistent interspecies navigational ability between two birds, one food-caching and the other not (Payne et al., 2021). Payne et al demonstrates significant and expected"}, {"title": "4.7 Insect Visual Navigation", "content": "The cognitive flexibility required to construct parallel representations such as maps, graphs, and scence systems may be a luxury of a high amount space alloted to computation. Which representational framework central-place foraging insects use to return home or to a foraging patch and how they use visual information to effectively navigate is currently being contested from a number of angles (Hoinville and Wehner, 2018; Webb, 2019; M\u00f6el and Wystrach, 2020; Firlefyn et al., 2024), with the aim of exploring navigability under the computational constraint of their minimal neural systems.\nIn a similar way to mammalian debates, various perspectives argue over whether the framework includes an explicit map or a disjoint collection of routes and observations, whether visual perception is translated into a goal vector estimate or simply converted into a useful movement signal, and to what extent and at which point odometry, vector estimates, and view memory information is combined. Although egocentric view or route-based systems appear to have a stronger foundation to a much greater extent in insects than for other organisms, where studies on allocentric encoding currently dominate. It remains to be seen if such viewpoints are relevant to navigation frameworks in humans, rodents, birds, or fish.\nMany insect visual navigation systems have particular relevance to the model of the present study. Baddeley et al used a neural network to determine familiarity of present views with those previously experienced (Baddeley et al., 2012). Stone et al proposes Zernike moments, providing rotational invariant shape representations, to increase the catchment area of view-matching navigation (Stone et al., 2018). Le M\u00f6el et al demonstrates the effectiveness of using familiarity as well as anti-familiarity to make effective movement decisions (M\u00f6el and Wystrach, 2020). Firflefyn et al used convolutional networks trained to estimate a goal vector before calculating movements (Firlefyn et al., 2024). Hoinville and Wehner combines view matching with path integration, using both as dissociable systems that each estimate a goal vector (Hoinville and Wehner, 2018). While goal vectors clearly do exist (Nyberg et al., 2022), to what extent they drive navigational decisions remains unanswered, especially given how frequent animals make notably indirect trajectories to reach a goal. Not including them in a model, such as in ours, allows this alternative hypothesis to be explored.\nSeveral studies use a similar environment to the Morris Water Maze adapted for insect navigation, using heat as a deterrant rather than water. Crickets were found to successfully find the non-visible target, with theoretical extensions proposing center-of-mass landmark vector-based or image difference matching without vector calculation as two potential mechanisms (Wessnitzer et al., 2008; Mangan and Webb, 2009). A similar setup was used for Drosophila to investigate neural and visual receptive fields hypotheses (Ofstad et al., 2011; Dewar et al., 2015). Dewar et al finds that low resolution ring neuron receptive fields are sufficient for visual navigation, potentially marking a bridge between the CNN perceptual medium used in this study with those used in the binary choice tasks (Sridhar et al., 2021; Gorbonos et al., 2024), marking the similarity between the two approaches."}, {"title": "4.8 Visual Perception", "content": "Another outcome stems from the tradeoff between visual angle and distance information. While navigating directly to the patch takes the least amount of time, it is clear that it requires a greater amount of energy, whether that be regarded as sensory capability, attention, memory, computation ability, or a mix. However, navigation relying on simpler visual angle principles performs almost as well. Rather than analyzing navigational deficits by these angular strategies, we may find insight in asking what other dimensions may be enhanced as a result of simplifying the visual space, exploring the Pareto front of energy and performance (Pallasdies et al., 2021).\nOur minimal approach allows easier generalization and analysis, however carries a corresponding drawback. Biological organisms are not so simple. We used vision here as the only sensory modality, while animals can smell, hear, vestibulate, echolocate, and use a variety of other senses to make their way towards a goal. (Able, 1980; Bingman and Cheng,"}, {"title": "4.9 Real World Applicability", "content": "Through minimizing complexity, tractability is maximized, in terms of both the model to learn the task and for resulting behavior to be analyzed, as well as generality across environments and species. However this comes at the cost of reduced detail relative to real world environments and biological neural systems. Experimental paradigms such as the Morris Water Maze highlights specific aspects of navigational problem-solving ability, and thus can be used to isolate genetic or neural components necessary for such ability or to differentiate the range in ability across a population. Although in the wild, the need to get to a specific location without being able to directly perceive it is not often realized.\nThe cognitive flow of information is constrained, largely to a single visual process. Most biological organisms have access to some form of memory, likely enabling more complex spatial reasoning to be performed. Of course, flexible spatial adaptivity arises from recurrent connectivity, place cells, and grid cells (Batista et al., 2015; Banino et al., 2018; Cueva and Wei, 2018). Such inferential capability allows an agent to estimate distance to a goal (Nyberg et al., 2022), or prediction of future locations to plan trajectories (Stachenfeld et al., 2017; Dotson and Yartsev, 2021). Though such abilities are balanced by the energy required for the needed complexity in computation. Other navigational algorithms are unable to be learned in this cognitive model instantiation, such as using short-term memory to turn around and develop a global perspective, before moving straight along an inferred vector. Many more algorithmic variations are possible, but out of the scope for comparision in the present study. Rather than implementing such processes, the end result can be inferred to be similar to the direct pathing agents.\nThe action space simplifies the degrees of freedom to a ratio between speed and turning, constrained to only forward movement. Such limitations may mirror ant movement (Zeil, 2023) or rodent head-eye constrained perception (Holmgren et al., 2021), but the lack of lateral and backward directions are not directly comparable to human movement. Lateral movement, coupled with short-term memory, can be used to infer distance via parallax. Though similarly to enabling memory, increasing dimensionality in the action space effectively leads to the trajectory space of the direct pathing agents."}, {"title": "4.10 Navigation vs. Search", "content": "Navigation and search have been historically semantincally entangled, both enveloped by the term \"foraging\", yet the role of memory plays quite unique parts in both. Navigation involves travel towards a known destination, whether previously visited personally or not, and search involves travel to a known thing or place with unknown location. These two processes certainly overlap, as search may precede later navigation or navigation is only possible proximally and search is needed to reach an exact spot. As such, organisms may evolve a preference towards one or the other depending on what the environment allows or requires. For example, C. elegans has been found to evolve a search strategy with a few key gradient-following principles (Klein et al., 2017; Madirolas et al., 2023), while loggerhead turtles have developed trans-Pacific migratory behavior (Boyle et al., 2009). Though for many, both are needed."}, {"title": "4.11 Social Navigation", "content": "Taking one step further, for social animals in particular, navigational computation may be offloaded to others"}]}