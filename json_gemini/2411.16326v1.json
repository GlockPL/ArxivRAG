{"title": "BRAIN-LIKE EMERGENT PROPERTIES IN DEEP NETWORKS: IMPACT OF NETWORK\nARCHITECTURE, DATASETS AND TRAINING", "authors": ["Niranjan Rajesh", "Georgin Jacob", "SP Arun"], "abstract": "Despite the rapid pace at which deep networks are improving\non standardized vision benchmarks, they are still outperformed\nby humans on real-world vision tasks. This paradoxical lack\nof generalization could be addressed by making deep networks\nmore brain-like. Although several benchmarks have compared\nthe ability of deep networks to predict brain responses to\nnatural images, they do not capture subtle but important brain-\nlike emergent properties.\nTo resolve this issue, we report several well-known perceptual\nand neural emergent properties that can be tested on deep\nnetworks. To evaluate how various design factors impact\nbrain-like properties, we systematically evaluated over 30\nstate-of-the-art networks with varying network architectures,\ntraining datasets and training regimes.\nOur main findings are as follows. First, network architecture\nhad the strongest impact on brain-like properties compared\nto dataset and training regime variations. Second, networks\nvaried widely in their alignment to the brain with no single\nnetwork outperforming all others. Taken together, our results\ncomplement existing benchmarks by revealing brain-like prop-\nerties that are either emergent or lacking in state-of-the-art\ndeep networks.", "sections": [{"title": "INTRODUCTION", "content": "Every week or so, the vision community finds itself with a\nnew deep neural network (DNNs) with improved task per-\nformance. These improvements are attributed to changes in\none or more of three key components of the deep learning\nparadigm: network architecture, training data or the training\nregime [1, 2, 3, 4, 5, 6, 7, 8]. At the same time, it has been chal-\nlenging to translate improvements on standard benchmarks to\ntangible improvements on real-world vision tasks [9, 10]. This\nparadoxical lack of generalization to the real-world might be\nresolved by evaluating new networks not only for their task\nperformance, but on how closely they mimic the human visual\nsystem [11, 12, 13, 14, 15].\nThere are at least two fundamental issues with making a vision\nsystem similar to the brain. First, we need to have effective\nmeasures of similarity which can be optimized to create better\nvisual systems. Second, changes must be targeted where they\nwill have the greatest impact. It is unclear a priori which\nfactors in the deep learning paradigm (network architecture,\ndatasets, training) will have the greatest impact on making\nthem closer to the brain. We address both these issues in this\nstudy."}, {"title": "1.1 Overview and contributions", "content": "Our goal is two fold. First, we describe a set of perceptual\nand neural properties whose presence can be tested in deep\nnetworks. Second, we investigate how network architecture,"}, {"title": "2 RELATED WORK", "content": "Whether a given vision system or deep network is similar to\nthe brain has been assessed at multiple levels: performance,\nrepresentations or neural responses. However, most previous\ncomparisons have been made on natural images, which have a\nmix of both low-level and high-level features that can affect\nmeasures of similarity.\nMany studies have compared deep networks and brains on\nobject recognition tasks. While DNNs show human-level\nperformance on many vision tasks [16, 32, 17] with repre-\nsentations that align well with the brain [33, 34], they also\nshow a number of important differences. These differences\ninclude vulnerabilities to adversarial attacks [35, 36, 37, 38],\nbiases toward texture over shape [28, 39], preference for spe-\ncific object sizes [40, 41], heightened sensitivity to contextual\ncues [42], unique error patterns [43], systematic bias in ob-\nject representations[44] and limited generalization to out-of-\ndistribution data [45]. Recently, platforms have been devel-\noped to identify models that quantitatively align with neural\nactivity [18, 19, 20, 21]. However, these approaches might\ncarry biases from the optimization or regression algorithms\nthat could render them less brain-like overall [46] and they do\nnot give us a deeper understanding what about these networks\nmake them brain-like or not. A recent study has addressed\nthis issue by comparing a number of brain-like properties in\ndeep networks [47]. We extend this approach in our study."}, {"title": "3 METHODS", "content": "To systematically test for neural and perceptual brain-\nsimilarity in DNNs, we selected 15 well-known properties\nfrom visual psychology and neuroscience [47]. We then gath-\nered a collection of pre-trained, state-of-the-art models that\nsystematically captures variations in network architecture,\ntraining dataset, and training regime. We make our code\navailable at our OSF Repository."}, {"title": "3.1 Brain-like properties", "content": "For each model, we tested a total of 15 brain-like properties,\nas summarized below and detailed in Supplementary Section\nS1.\n\u2022 Object Normalization-pairs: The neural response\nto two objects is the average of the response to the\nindividual objects.\n\u2022 Object Normalization-triplets: The neural response\nto three objects is the average of the response to the\nindividual objects.\n\u2022 Scene Incongruence: Object categorization is more\naccurate when objects are presented in congruent\ncompared to incongruent scenes.\n\u2022 Mirror Confusion: Images reflected about the vertical\naxis are more similar than when reflected about the\nhorizontal axis."}, {"title": "3.2 Network Variations", "content": "We systematically evaluated a variety of pre-trained deep net-\nworks to explore how network architecture, image dataset, and\ntraining regime impact the emergence of perceptual effects\nin DNNs. For each experiment, we captured unit activations\nfrom the penultimate layer (or final classification probabilities\nin the case of scene incongruence) for the stimulus set and\ncomputed the effect strength as described in Supplementary\nSection S1.\nArchitecture selection. We selected models from the CNN\nand ViT families, trained on a supervised object recognition\ntask using the ImageNet dataset, to evaluate the impact of\narchitecture. These model families employ fundamentally dif-\nferent operations for processing data: CNNs use convolutional\noperations [2], while ViTs utilize self-attention mechanisms\nto extract visual features for object recognition [48, 4]. We\ntested two networks of each state-of-the-art models in both\nfamilies: VGGs [2], ResNets [3], Inception Nets [49, 24],\nConvNeXts [50], SWIN [51], and DeiT [52]. This wide range"}, {"title": "3.3 Brain Property Match Score", "content": "We devised a novel Brain Property Match (BPM) score for\neach network, which takes into account the sign of the effect\nstrength (which captures the presence/absence of the property)\nas well as the distance of the effect strength in the network\nfrom the brain, and combines this score across all tested prop-\nerties to arrive at a final composite score. Specifically, the\nBPM score for model k is a function of its multidimensional\ndistance D across all N properties relative to the brain:\n$BPM_k = \\frac{1}{1 + \\sum_{i=1}^N D_i}$\n$D = \\frac{\\|b_i - m_i\\|}{\\|b_i + \\lambda \\cdot m_i\\|}$ if $m_i > 0$ if $m \\leq 0$\nThus, the DNN is penalized by a factor of $\\lambda$ if its score is\nnegative and anti-brain like. When $\\lambda$ = 1, the BPM is identical\nto the $L_1$ norm. We selected $\\lambda$ = 2 for our evaluations, which\nmeans that any negative effect strength is penalized by a factor\nof 2 for deviating away from the brain. We obtained similar\nrankings of networks on varying this value. The resulting\nBPM scores for all tested networks are shown in Table 1."}, {"title": "4 RESULTS", "content": "We tested a total of 32 vision DNNs across architectural, train-\ning dataset and regime variations in order to investigate the\nemergence of brain-like perceptual and neural properties. In\neach case, we evaluated deep networks varying in a given\nfactor while holding others constant to study the impact of\nthat factor on all the brain-like properties tested."}, {"title": "4.1 Architecture variations", "content": "We evaluated 14 DNN architectures trained on the same\ndataset and training regime for a total of 15 brain-like proper-\nties (see Section 3 and Supplementary Section S1). Figure 2A\nshows the effect strength for each brain-like property for each\nnetwork, along with the empirically observed effect strength\nin brains. Note that positive values are brain-like, and negative\nvalues are anti-brain-like. To more clearly depict the presence\nor absence of each brain-like property, we binarized the effect\nstrength (Figure 2B). We report our observations below.\nBrain-like properties present in all architectures. Both\nCNN and ViT families consistently display some brain-\nlike properties like Object Normalization, Scene Incongru-\nence, Mirror Confusion and Correlated Sparseness across\nshapes/textures and morph-lines. These phenomena seem to\nbe emergent in networks optimized for object recognition re-\ngardless of architecture. Despite the presence of these effects,\narchitectures did vary in how close they are to the empirically\nobserved values from the brain. For example, in both sparse-\nness experiments, all CNN families have a closer effect to the\nbrain when compared to the ViTs. On the other hand, in Mir-\nror confusion, the closest effect to what is found in the brain\nis observed in the vanilla Vision Transformer architectures."}, {"title": "4.2 Training Dataset Variation", "content": "Next we investigated how varying the training dataset could\naffect the brain-like properties of networks. To this end, we\ntested two CNNs and a ViT network architecture. Each net-"}, {"title": "4.3 Training Regime Variation", "content": "Finally, we investigated networks varying in their training\nregime. We chose a ResNet50 and a vanilla ViT-base net-"}, {"title": "4.4 Comparison of all tested networks", "content": "The above results are based on a fine-grained comparison of\nthe impact of each factor on the presence of brain-like prop-\nerties while holding other factors constant. To obtain a more"}, {"title": "4.5 Layer-wise progression of brain-like properties", "content": "Having visualized the embedding of the penultimate layer of\neach network relative to the brain in 5A, we were inspired to"}, {"title": "4.6 Brain Property Match (BPM) score", "content": "Can we devise a composite metric to benchmark a network's\nsimilarity to the brain in terms of brain-like emergent prop-\nerties? We propose a Brain Property Match (BPM) score\n(see 3.3). This score is sensitive to two components: the\nabsolute difference of the DNN's effect strengths from the\nmeasured strength in brains and whether the effect is simply\npresent/absent in the network. Table 1 shows the ranking of all\ntested networks according to the BPM metric, as well as their\nranks according to the number of brain-like properties present\nin each network, and their ranks according to L1-norm simi\nlarity to the empirically effect strength observed in brains. We\nfind that networks ranked highly by BPM do not belong to the\nsame network architecture, training dataset or training regime\nsuggesting that varying each of these factors is causing some\nproperties to become brain-like at the expense of others. This\nis also evident from the L1-norm similarity rankings, because\nall networks seem equidistant from the brain. We note that\nthis does not match with the 2-dimensional embedding seen\nin the 5A, presumably because the 2 principal components\nexplain only 65% of the variance. We urge caution in using\nthe BPM score directly as a metric to be optimized, for sev-\neral reasons. First, the BPM score for brains is unequal in\nmagnitude across the brain-like properties tested. It could be"}, {"title": "5 DISCUSSION", "content": "In this work, we describe a set of brain-like emergent prop-\nerties that can be evaluated on any deep network, or for that\nmatter, any visual system with an accessible internal repre-\nsentation. We systematically tested these properties on 32\nstate-of-the-art DNNs that varied in their architecture, train-\ning dataset and training regime. Our main findings are as\nfollows. First, network architecture had the strongest impact\non the presence or absence of brain-like properties compared\nto dataset and training regime variations. Second, networks\nvaried widely in their alignment to the brain with no single\nnetwork achieving a very close match.\nOur study offers interesting insights into the design choices\nunder which the brain-like properties arise. Properties like\nobject normalization and mirror confusion are present in all\nnetworks, suggesting that they emerge with the demand of\nimage recognition. Some properties such as relative size, sur-\nface invariance and 3D processing are almost always absent,\nsuggesting that they may emerge only with specialized train-\ning. Some properties like Weber's law are present only in\nconvolutional networks, whereas global advantage is present\nin vanilla ViTs, suggesting that these effects arise largely due\nto network architecture. Finally, training dataset also mat-\nters, since face-trained CNNs lose occlusion processing and\nshape-texture sparseness while gaining the Thatcher effect.\nTaken together, our results offer insights into the presence of\nbrain-like emergent properties in deep networks. They raise\nthe intriguing possibility that training deep network to acquire\nthese properties could lead to more generalizable and robust\nbrain-like deep networks."}, {"title": "SUPPLEMENTARY S1 BRAIN PROPERTY EXPERIMENTS", "content": "In this section, we detail each of the 14 experiments used\nto assess the presence and magnitude of visual, brain-like\nqualitative effects in DNNs. These experiments were adopted\nfrom the work of Jacob et al [47]; we point the reader to their\nwork for more detailed accounts of each experiment.\n1&2 Multiple Object Normalization\nIn this experiment, we verify whether the neural response\nfor a group of objects is an average of the individual object\nresponses an effect observed in high-level monkey visual\nregions [64]. In order to measure this effect, we identify\nvisually active neural units for all possible positions within the\nimage where an object may appear and record the individual\nobject responses and the responses when all objects are shown\ntogether in the same image. We then compute the average\nslope of the multiple object response plotted as a function of\nthe sum of individual object responses. If the network exhibits\nmultiple object normalization, we should observe an average\nslope of 0.5 for pairs of objects (Effect 1) and 0.33 for object\ntriplets (Effect 2).\n3 Scene Incongruence\nA famous observation is the effect context plays in visual cate-\ngorization tasks in humans. When the background of an image\nis incongruent, in the semantic sense, to the object in the fore-\nground, humans see a fall in their categorization performance\n[65, 66]. We test the same effect here and compute a scene\nincongruence index SC with Accc being the average accuracy\nof the network on congruent object-scene images and Acci\nbeing the incongruent counterpart and taking the ratio of their\ndifferences:\n$SC = \\frac{Accc - Acci}{Accc + Acci}$\n4 Mirror Confusion\nIn this simple experiment we verify whether the neural repre-\nsentations of a DNN for a vertically flipped image is closer\nto the original image than a horizontally flipped image. This\neffect is commonly observed in human behavior and monkey\nneural data and is termed the mirror confusion effect [67]. We\ncompute a mirror confusion index as the following modulation\nindex where Dh and D, are the distances between the horizon-\ntally flipped image from the original image and the vertically\nflipped image from the original respectively.\n$MC = \\frac{Dh - Dv}{Dh + Dv}$\n5 Correlated Sparseness of Morphlines\nIn this experiment, visually active units for certain shapes are\nidentified and are shown parametric variations of the same\nshape (morphlines). To show the brain-like effect of correlated"}, {"title": "SUPPLEMENTARY S2: PRESENCE OF BRAIN PROPERTIES ACROSS ALL NETWORKS", "content": ""}, {"title": "SUPPLEMENTARY S3: QUANTIFICATION OF GROUPING EFFECT OF CATEGORIES", "content": ""}, {"title": "SUPPLEMENTARY S4: LAYERWISE EVOLUTION OF BRAIN PROPERTY SCORES FOR VGG16 AND VIT-B", "content": ""}]}