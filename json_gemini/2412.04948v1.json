{"title": "KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning", "authors": ["Peng Yu", "Cheng Deng", "Beiya Dai", "Xinbing Wang", "Ying Wen"], "abstract": "Autoregressive large language models (LLMs) pre-trained by next token prediction are inherently proficient in generative tasks. However, their performance on knowledge-driven tasks such as factual knowledge querying remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured knowledge bases, can provide reliable knowledge for LLMs, potentially compensating for their knowledge deficiencies. Aligning LLMs with explicit, structured knowledge from KGs has been a challenge; previous attempts either failed to effectively align knowledge representations or compromised the generative capabilities of LLMs, leading to less-than-optimal outcomes. This paper proposes KaLM, a Knowledge-aligned Language Modeling approach, which fine-tunes autoregressive LLMs to align with KG knowledge via the joint objective of explicit knowledge alignment and implicit knowledge alignment. The explicit knowledge alignment objective aims to directly optimize the knowledge representation of LLMs through dual-view knowledge graph contrastive learning. The implicit knowledge alignment objective focuses on incorporating textual patterns of knowledge into LLMs through triple completion language modeling. Notably, our method achieves a significant performance boost in evaluations of knowledge-driven tasks, specifically embedding-based knowledge graph completion and generation-based knowledge graph question answering.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) like PaLM 2 (Anil et al., 2023) and GPT-4 (Achiam et al., 2023) have recently made remarkable advancements in a wide range of natural language processing tasks (Li et al., 2022; Su et al., 2019). However, LLMs still face challenges in tasks requiring factual or domain-specific knowledge, resulting in unsatisfactory performance in knowledge-driven tasks. From the perspective of knowledge representation, LLMs serve as parametric knowledge bases, providing implicit, non-deterministic knowledge, while knowledge graphs (KGs) function as structured knowledge bases, offering explicit, deterministic knowledge. KGs, commonly organized as factual knowledge triples describing relations between entities, can serve as a reliable knowledge source for LLMs. Aligning LLMs with KG knowledge can enhance the knowledge reasoning capabilities of LLMs and improve their performance on knowledge-driven tasks, such as knowledge graph completion (KGC) and knowledge graph question answering (KGQA).\nAutoregressive LLMs pre-trained through next token prediction tasks often exhibit limitations in knowledge representation, leading to embeddings that lack diversity and specificity. This limitation becomes evident in tasks that demand distinctive sentence embeddings, such as dense retrieval and semantic search (Muennighoff, 2022; Ma et al., 2023). As demonstrated in Figure 1(a), the representations generated by LLMs tend to be overly homogeneous across different pieces of knowledge, undermining their effectiveness in applications requiring fine-grained semantic distinctions.\nThe concept of explicit knowledge alignment is introduced to directly optimize the knowledge representation within language models by devising direct knowledge training objectives. This strategy emerges in response to the observed degradation in knowledge representation within autoencoder-based pre-trained language models (PLMs), a phenomenon termed representation anisotropy (Ethayarajh, 2019). This issue is characterized by the clustering of learned token and sentence embeddings within a constrained area of the representation space, leading to a lack of distributional uniformity (Li et al., 2020). While previous efforts to address representation anisotropy have largely concentrated on promoting uniformity among token representations, they often overlook the critical"}, {"title": "2 Related Work", "content": "Our work is closely related to Knowledge Enhancement for LLMs and Representation Anisotropy of Language Models. A more detailed review of related work can be found in Appendix A.\nKnowledge Enhancement for LLMs Knowledge enhancement aims to incorporate factual and domain-specific knowledge into LLMs to address their knowledge deficiencies. This can be divided into retrieval-based augmentation and training-based integration. Retrieval-based knowledge augmentation methods leverage external retrieval modules to provide additional knowledge, aiming to improve the knowledge reasoning capability of LLMs (Sun et al., 2023; Jiang et al., 2023). However, this approach may lead to knowledge conflicts (Feng et al., 2023), where knowledge in LLMs and knowledge in the retrieved documents are inconsistent or the retrieved multiple documents are contradictory. Training-based knowledge integration methods involve using KG triple descriptions to pre-train or fine-tune LLMs, aiming to achieve knowledge alignment. These methods can be divided into explicit alignment (Wang et al., 2021b; Yasunaga et al., 2022) and implicit alignment (Yao et al., 2023; Zhang et al., 2023) based on whether they directly optimize the knowledge representation. Nevertheless, prior methods have either sacrificed the generative capability or lacked effective representation alignment. Our approach enhances the knowledge of LLMs via a unique joint objective of explicit alignment and implicit alignment, improving the quality of knowledge representations and generative knowledge reasoning capabilities.\nRepresentation Anisotropy of Language Models PLMs have long been plagued by representation anisotropy (Ethayarajh, 2019), where the learned token and sentence embeddings are confined to a narrow cone within the entire representation space. The issue of representation anisotropy not only results in model degradation (Su et al., 2022) but also leads to poor performance on discriminative tasks. Previous work on alleviating representation anisotropy has mainly focused on post-processing techniques such as normalizing flows (Li et al., 2020) or whitening operations (Su et al., 2021). Su et al. (2022) propose a contrastive training objective to encourage learning isotropic token representations. However, these methods mainly improve the isotropy of token representations without enhancing the discriminability of sentence representations. Our method improves the token-level and sentence-level representation anisotropy of LLMs through dual-view knowledge graph contrastive learning, and it has rigorous theoretical guarantees."}, {"title": "3 Knowledge-aligned Autoregressive Language Modeling", "content": "In this section, we introduce KaLM, a Knowledge-aligned Language Modeling approach for aligning LLMs with KG knowledge via the joint objective of explicit knowledge alignment and implicit knowledge alignment. The overview is shown in Figure 2.\n3.1 Notations and Preliminaries\nA KG G stores factual knowledge, denoted as G = (E,R,T,D). E and R are the set of entities and relations, respectively. D is the description set of all entities and relations. De and Dr are the textual description of entity e and relation r, respectively. T = {(h, r,t)|h, t \u2208 E,r \u2208 R} is the triple set. A triple (h, r, t) depicts the fact that there is a relation r between the head entity h and the tail entity t.\n3.2 Explicit Knowledge Alignment\nFor KG triples, the textual description of the tail entity and the concatenation of the textual descriptions of the head entity and relation can be seen as two distinct views of the same knowledge. This inspires KaLM to align representations of two distinct views of the same knowledge (i.e., from the same triple), while separating representations of different knowledge (i.e., from different triples).\nN\nThe LLM, denoted as ELLM, is fine-tuned with the dual-view knowledge graph contrastive learning loss. The training corpus contains paired textual descriptions, {(Dhr, Dt)}1, where Dt is the tail entity description, and Dhr is the concatenation of the head entity description and relation description. Given a training pair (Dhr, Dt), the same ELLM is used to compute the embeddings of Dhr and Dt independently. Moreover, we prepend the [bos] token to the beginning and append the [eos] token to the end of the textual description. The augmented input is fed into ELLM, and the hidden representation corresponding to the [eos] token from the last layer is used as the final embedding of the input.\nehr = ELLM([bos]hr\u2295 Dhr\u2295 [eos]hr),\net = ELLM([bos]t\u2295 Dt \u2295 [eos]t),\nwhere \u2295 is the operation to concatenate two strings and Dhr = Dh\u2295 Dr. For stable training, we adopt \u201c{\u201d as [bos]hr and \u201c}\u201d as [eos]hr, while using \u201c[\u201d as [bos]t and \u201c]\u201d as [eos]t.\nWe utilize the knowledge graph contrastive learning loss to directly optimize the knowledge representation of the LLM by encouraging semantically"}, {"title": "3.3 Implicit Knowledge Alignment", "content": "The implicit knowledge alignment objective focuses on incorporating textual patterns of knowledge into the LLM to prevent catastrophic forgetting of previous knowledge and maintain its generative capability. We constructed an instruction-tuning dataset based on the KG triple descriptions to fine-tune the model through triple completion language modeling. We also show that the implicit knowledge alignment objective can bring performance boosts on knowledge representation evaluations. This indicates that explicit alignment and implicit alignment are both imperative for effective knowledge alignment, as they both essentially necessitate a profound understanding of knowledge.\nWe follow the recipe of Stanford Alpaca (Taori et al., 2023) and use the provided template to construct the instruction-tuning dataset. The instruction passed to the template, abbreviated as inst, is: \u201cGiven the head entity and relation, write a tail entity that completes the triple\". The input and output are Dhr and Dt, respectively. The training objective for implicit knowledge alignment is:\n$L_{imp} = \\frac{1}{M} \\sum_{(D_{hr}, D_t)} \\log P(D_t | inst, D_{hr}),$ (3)\nwhere M is the instruction-tuning batch size."}, {"title": "3.4 Knowledge-aligned Language Modeling", "content": "The ultimate training objective of our proposed KaLM is the weighted average of Lexp and Limp:\n$L_{KALM} = L_{exp} + \\lambda \\cdot L_{imp},$ (4)\nwhere \u03bb is a hyperparameter that adjusts the relative weight between them. Notably, this formulation allows us to use different batch sizes for explicit knowledge alignment (N) and implicit knowledge alignment (M). Previous work has shown that a sufficiently large batch size is key to the success of contrastive representation learning (Chen et al., 2020). With Equation 4, we can significantly increase the explicit knowledge alignment batch size while keeping the implicit knowledge alignment batch size fixed to save computational resources."}, {"title": "4 Theoretical Analysis", "content": "We theoretically prove that the explicit knowledge alignment objective implemented through dual-view knowledge graph contrastive learning can facilitate knowledge representation alignment and alleviate the issue of representation anisotropy.\n4.1 Dual-view Contrastive Learning for Knowledge Representation Alignment\nThe outstanding performance of contrastive representation learning has attracted researchers to analyze its underlying reasons for success from a theoretical perspective. Wang and Isola (2020) identify"}, {"title": "5 Experiments", "content": "In this section, we assess the effectiveness of KaLM in knowledge alignment. The experimental setup is outlined in 5.1. In 5.2 and 5.3, we present results on knowledge graph completion (KGC) and knowledge graph question answering (KGQA). In 5.4, we provide further analysis of knowledge representation and present case studies of KGQA generations.\n5.1 Experimental Setup\nDatasets. We use WN18RR (Dettmers et al., 2018) and FB15k-237 (Toutanova and Chen, 2015) as the KGs for knowledge alignment training. WN18RR and FB15k-237 are derived from WordNet and Freebase, respectively (Bordes et al., 2013). We use the information provided by KG-BERT (Yao et al., 2019) for textual descriptions. Following Wang et al. (2022a), we add an inverse triple (t, r\u00af\u00b9, h) for each triple (h, r, t) in the triple set, where r\u00af1 is the inverse relation of the original relation r.\nModel Training. We choose Llama-2-7B, Llama-3-8B, and Mistral-7B as base LLMs and fine-tune them through the joint objective of explicit knowledge alignment and implicit knowledge alignment. To save computational resources for parameter-efficient fine-tuning, we use LoRA (Hu et al., 2021) to fine-tune the feed-forward network of the model.\nEvaluation Details. Experiments mainly focus on two aspects: knowledge representation assessment and knowledge inference evaluation. For knowledge representation assessment, we evaluate the embedding-based KGC task and illustrate the alleviation of representation anisotropy. We report five automated metrics: Mean Rank (MR), Mean Reciprocal Rank (MRR), and Hit@k (k \u2208 {1,3,10})."}, {"title": "5.2 Knowledge Representation Assessment", "content": "The embedding-based KGC results are shown in Table 1. The base LLM failed to finish this task, with all metrics lagging far behind. On the WN18RR dataset, our method surpasses prior methods by a substantial margin in terms of MR and Hit@10."}, {"title": "5.3 Knowledge Inference Evaluation", "content": "The generation-based KGQA results are depicted in Figure 3. Llama-2-7B performs poorly in entity prediction and relation prediction. Our method demonstrates a significant performance boost in all generation-based KGQA tasks, including head/tail entity prediction, relation prediction, and triple classification. Furthermore, despite a slight increase in perplexity (PPL) scores on Wikitext-103 (Merity et al., 2016) test set, our method still shows competitive performance in the MMLU test. The results demonstrate that KaLM achieves effective knowledge alignment, bringing in significantly improved KGQA performance while preserving the original generative and knowledge inference capabilities."}, {"title": "5.4 Visualization of Knowledge Representation and Case Studies", "content": "We provide visualization results to illustrate knowledge representation improvements. Figure 4 shows the sentence similarity matrix of Llama-2-7B and KaLM on Wikitext-103. The diagonal elements denote the similarity of the same sentence, so the values are always 1. From color intensity, it is evident that KaLM learns more discriminative sentence representations, while Llama-2-7B assigns high similarity for arbitrary sentences. The sentences are organized by celebrities and their careers, thus there should also be a high similarity between adjacent sentences. This phenomenon is reflected in the similarity matrix of KaLM in Figure 4(b), manifested in the smaller matrices with darker colors along the diagonal. More concretely, numerical analysis shows that after training with our method, the sentence-level anisotropy value significantly decreased from 0.83 to 0.21."}, {"title": "6 Conclusion", "content": "In this work, we show that the subpar performance of LLMs on knowledge-driven tasks stems from a lack of effective knowledge alignment. We present KaLM, a novel knowledge-aligned language modeling approach for aligning autoregressive LLMs with KG knowledge. Specifically, we identify two imperative objectives to achieve knowledge alignment: explicit knowledge alignment and implicit knowledge alignment. We conducted comprehensive experiments and analyses on embedding-based KGC and generation-based KGQA. Experimental results demonstrate that our method achieves effective knowledge alignment and consistently improves performance on knowledge-driven tasks."}, {"title": "Limitations", "content": "There are several future directions to improve this work. Firstly, due to the limitation of computational resources, we used the limited-scale LLMs to train and evaluate our method. Evaluations on larger-scale LLMs, such as the 13B and 70B models, can further validate the effectiveness of our approach. Secondly, we use a simple linear combination of explicit alignment loss and implicit alignment loss as the final training objective for KaLM. Further investigations into various forms of loss combinations remain to be explored to maximize the utility of knowledge-aligned language modeling. Finally, we can delve into the performance of the knowledge representations obtained from knowledge-aligned language modeling in cross-domain applications such as retrieval-augmented generation, to gain broader insights into the generalization capabilities of the proposed approach."}, {"title": "4.1 Dual-view Contrastive Learning for\nKnowledge Representation Alignment", "content": "The outstanding performance of contrastive repre-\nsentation learning has attracted researchers to ana-\nlyze its underlying reasons for success from a theo-\nretical perspective. Wang and Isola (2020) identify\n5\nalignment and uniformity as two key properties of\ncontrastive learning and propose two quantifiable\nmetrics to measure the quality of representations.\nWe concentrate on understanding the dual-view\nknowledge graph contrastive learning loss from the\nknowledge alignment and uniformity perspective.\nTo simplify the notation, we use f to denote ELLM.\nAlignment computes the expected distance be-\ntween positive pairs and encourages the learned\nrepresentations for positive pairs to be similar. Uni-\nformity evaluates the even distribution of represen-\ntations and encourages the separation of features\nfrom randomly selected negative samples."}, {"title": "4.2 Alleviation of Representation Anisotropy", "content": "We then prove that the dual-view knowledge graph\ncontrastive learning objective can directly alleviate\nrepresentation anisotropy and improve the discrim-\ninability of knowledge representations.\nLet E be the sentence embedding matrix of\n{D}1, where the i-th row of E is ei. Following\nEthayarajh (2019), the sentence-level representa-\ntion anisotropy value of {D}1 is defined as:\n$anisotropy {D} = \\frac{1}{N(N-1)} \\sum_{i=1}^{N} \\sum_{j=1,j\\neq i}^{N} e_i^T e_j$.\nWe can further derive the following theorem."}, {"title": "A More Detailed Review of Related Work", "content": "This work focuses on fine-tuning autoregressive\nLLMs to align with KG knowledge. Our work inter-\nsects with the following research areas: Knowledge\nEnhancement for LLMs, Knowledge Graph Com-\npletion, Contrastive Representation Learning, and\nRepresentation Anisotropy of Language Models.\nA.1 Knowledge Enhancement for LLMs\nKnowledge enhancement aims to incorporate fac-\ntual and domain-specific knowledge into LLMs\nto address their knowledge deficiencies. This can\nbe divided into retrieval-based knowledge augmen-\ntation and training-based knowledge integration.\nRetrieval-based knowledge augmentation methods\nleverage external retrieval modules to provide addi-\ntional knowledge, aiming to improve the knowl-\nedge reasoning capability of LLMs (Sun et al.,\n2023; Jiang et al., 2023). However, this approach\nmay lead to knowledge conflicts (Feng et al., 2023),\nwhere the knowledge in LLMs and the knowl-\nedge in the retrieved documents are inconsistent or\nthe retrieved multiple documents are contradictory.\nTraining-based knowledge integration methods in-\nvolve using the textual descriptions of KG triples\nto pre-train or fine-tune LLMs, aiming to achieve\nknowledge alignment. These methods can be cate-\ngorized into explicit alignment (Wang et al., 2021b;\nYasunaga et al., 2022) and implicit alignment (Yao\net al., 2023; Zhang et al., 2023) based on whether\nthey directly optimize the knowledge representa-\ntion. Nevertheless, these methods have either sacri-\nficed the generative capability or lacked effective\nrepresentation alignment. Our approach enhances\nthe knowledge of LLMs via a unique joint objective\nof explicit alignment and implicit alignment, im-\nproving the quality of knowledge representations\nand generative knowledge reasoning capabilities."}, {"title": "A.2 Knowledge Graph Completion", "content": "Knowledge graph completion (KGC) refers to in-\nferring missing triples from an incomplete KG,\nwhich can be used to evaluate the knowledge rea-\nsoning ability and knowledge representation quality\nof LLMs. Existing KGC methods can be catego-\nrized into structure-based and description-based.\nStructure-based methods represent entities and re-\nlations as fixed-dimensional vector embeddings\nand use scoring functions to assess the plausibility\nof triples (Bordes et al., 2013; Sun et al., 2019).\nDescription-based methods further incorporate the"}, {"title": "A.3 Contrastive Representation Learning", "content": "Contrastive learning has demonstrated remarkable\nsuccess in learning representations across various\ndomains (Chen et al., 2020; Liu et al., 2021; Gunel\net al., 2020). The goal is to learn representations\nthat capture shared information between positive\npairs while remaining invariant to perturbing noise.\nThe commonly used contrastive learning objectives\nshare a standardized design involving a softmax\nfunction over cosine similarity of paired features,\nwith a temperature parameter to control the penalty\nstrength on hard negative samples. Wang and Isola\n(2020) propose understanding contrastive learning\nthrough the lens of alignment and uniformity on the\nhypersphere. Wang and Liu (2021) show that tem-\nperature in the contrastive loss controls the strength\nof penalties over negative samples."}, {"title": "A.4 Representation Anisotropy of Language\nModels", "content": "PLMs have long been plagued by representation\nanisotropy (Ethayarajh, 2019), where the learned\ntoken and sentence representations are confined to a\nnarrow cone within the entire representation space.\nThe issue of representation anisotropy not only re-\nsults in model degradation (Su et al., 2022) but also\nleads to poor performance on discriminative tasks\n(Muennighoff, 2022). Previous work on alleviat-\ning representation anisotropy has mainly focused\non post-processing techniques such as normalizing\nflows (Li et al., 2020) or whitening operations (Su\net al., 2021) to obtain isotropic representations. Su\net al. (2022) propose a contrastive training objective\nto encourage learning isotropic token representa-\ntions. However, these methods mainly improve the\nisotropy of token representations without enhanc-\ning the discriminability of sentence representations.\nOur method improves the token-level and sentence-\nlevel representation anisotropy of LLMs through\ndual-view knowledge graph contrastive learning,\nand it has rigorous theoretical guarantees."}, {"title": "C.1 Dataset Details", "content": "WN18RR and FB15k-237 are commonly used KGs\nderived from WordNet and Freebase, respectively\n(Bordes et al., 2013). They have been carefully\nconstructed to prevent test set leakage by removing\ninverse relations. We use these datasets for training\nand evaluation. The statistics are shown in Table 2."}, {"title": "C.2 KaLM Implementation Details", "content": "We initially choose Llama-2-7B as the base LLM\nand fine-tune it through the training objective in\nEquation 4. We use varying batch sizes for ex-\nplicit knowledge alignment and implicit knowledge\nalignment. For WN18RR, we use a batch size of\n24 for explicit alignment and 4 for implicit align-\nment. For FB15k-237, the batch sizes are 40 for\nexplicit alignment and 6 for implicit alignment. To"}, {"title": "D.1 More Experiments on Knowledge\nRepresentation Assessment", "content": "In Table 5, we present additional knowledge repre-\nsentation results (the embedding-based KGC task)\nto demonstrate the effectiveness of KaLM in knowl-\nedge alignment. The best and second-best experi-\nmental results are indicated by bold and underline\ntexts, respectively. Overall, the proposed method\nachieved excellent performance on the embedding-\nbased KGC task, delivering impressive results in\nthe MR and Hit@10 metrics, while also being\nhighly competitive in other metrics.\nThe experimental results based on LLMs of dif-\nferent sources and scales demonstrate the effective-\nness and generalizability of our proposed method.\nUnder similar experimental settings, more pow-\nerful LLMs (such as Llama3-8B and Mistral-7B)\nachieved better metrics after being fine-tuned with\nKaLM, which also demonstrates the scalability of\nour method. It is worth noting that for LLMs of the\nsame origin but different scales (Pythia-6.9B and\nPythia-2.8B), the smaller-scale Pythia-2.8B bene-\nfited from a larger training batch size during fine-\ntuning. As a result, its final experimental metrics\nmatched or even surpassed those of the more pow-\nerful Pythia-6.9B model. This also highlights the\nimportance of large batch sizes for the embedding-\nbased KGC task, suggesting that using more pow-\nerful computing resources and larger GPU memory\ncould further enhance the effectiveness of the pro-\nposed KaLM method."}, {"title": "D.2 More Experiments on Knowledge\nInference Evaluation", "content": "In Figure 6, we present additional knowledge infer-\nence results (generation-based KGQA) to demon-"}]}