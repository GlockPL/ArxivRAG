{"title": "Open-Book Neural Algorithmic Reasoning", "authors": ["Hefei Li", "Chao Peng", "Chenyang Xu", "Zhengfeng Yang"], "abstract": "Neural algorithmic reasoning is an emerging area of machine learning that focuses\non building neural networks capable of solving complex algorithmic tasks. Recent\nadvancements predominantly follow the standard supervised learning paradigm\nfeeding an individual problem instance into the network each time and training it to\napproximate the execution steps of a classical algorithm. We challenge this mode\nand propose a novel open-book learning framework. In this framework, whether\nduring training or testing, the network can access and utilize all instances in the\ntraining dataset when reasoning for a given instance.\nEmpirical evaluation is conducted on the challenging CLRS Algorithmic Reasoning\nBenchmark, which consists of 30 diverse algorithmic tasks. Our open-book learning\nframework exhibits a significant enhancement in neural reasoning capabilities.\nFurther, we notice that there is recent literature suggesting that multi-task training\non CLRS can improve the reasoning accuracy of certain tasks, implying intrinsic\nconnections between different algorithmic tasks. We delve into this direction via\nthe open-book framework. When the network reasons for a specific task, we enable\nit to aggregate information from training instances of other tasks in an attention-\nbased manner. We show that this open-book attention mechanism offers insights\ninto the inherent relationships among various tasks in the benchmark and provides\na robust tool for interpretable multi-task training.", "sections": [{"title": "1 Introduction", "content": "Deep neural networks have achieved remarkable advancements in various areas, such as image\nprocessing [18, 6] and natural language processing [16, 21]. In recent years, as deep learning\ncontinues to evolve, there has been an increasing desire to see deep neural networks take on more\ncomplex tasks. Algorithmic reasoning tasks [27, 5, 28] have emerged as a particularly crucial category.\nIn classical domains, deep neural networks have demonstrated their ability to learn predictive patterns\nfrom training data. The aspiration now is to extend this capability to the field of algorithmic reasoning,\nwhich motivates a burgeoning domain Neural Algorithmic Reasoning (NAR).\nNeural algorithmic reasoning was initially coined by [30]. The central objective of this domain is\nto develop and train neural networks with the capability to imitate classical rule-based algorithms,\nsuch as sorting algorithms and graph algorithms. Networks built in this manner demonstrate the\nability to perform algorithmic computations similar to traditional algorithms in reasoning tasks,\nwhile showcasing improved computational efficiency compared to them [17]. Moreover, recent\nliterature [31, 22] shows that owing to the characteristics of deep learning, these networks exhibit\nflexibility in handling diverse input formats, making them robust even in scenarios where certain\ninput features are missing."}, {"title": "Challenging Benchmark for NAR", "content": "CLRS Algorithmic Reasoning Benchmark proposed by [26] is\ncurrently the most popular and definitive benchmark for evaluating the algorithmic capabilities of\nneural networks. This benchmark comprises 30 diverse algorithmic reasoning tasks extracted from\nthe foundational algorithms textbook \u201cIntroduction to Algorithms\u201d [4], including sorting, searching,\ndynamic programming, graph algorithms, string algorithms, and more. Beyond the task diversity,\nanother notable challenge of this benchmark is the significant differences in scale between problem\ninstances in the training and test sets. The test instances are substantially larger in scale compared to\nthose in the training set.\nThere have been many recent advances in exploring CLRS [7, 19, 2, 8, 24, 3]. As classical algorithms\ncan often be represented by graph structures, several successful approaches leverage the Graph\nNeural Network (GNN) framework, including models such as PGN [29] and MPNN [9]. In addition\nto directly applying these classical GNNs, the literature has observed that the execution of some\nclassical algorithms often relies on specific data structures. Consequently, there have been proposals\nto integrate classical GNNs with data structures like priority queues [12] or stacks [14] to enhance\nneural reasoning capabilities.\nHowever, we notice that all prior approaches predict algorithmic executions based solely on their\nparameters and the features of a single input. Although this mode is commonly used in traditional\nsupervised learning tasks [20, 1], it may not be well-suited for NAR due to the inherent difference\nbetween complicated reasoning tasks and traditional tasks like image processing. In practical\nscenarios, when recognizing images, extensive background knowledge is typically not required; but\nwhen faced with complex reasoning tasks, a substantial amount of background knowledge is often\nnecessary to complete various aspects of the reasoning process. In such situations, having real-time\nillustrative examples or formulas available for reference can significantly reduce our memory burden,\nthereby enhancing task completion. This naturally raises a question:"}, {"title": "1.1 Our Contributions", "content": "We explore the aforementioned question and introduce open-book neural algorithmic reasoning. In\nthis model, the neural architecture is enhanced with an additional memory component that stores\nrepresentations of instances in the training dataset. Whether during training or testing, whenever\nthe network engages in reasoning for a specific instance, it has the capability to leverage this\nsupplementary memory to aggregate information from other instances within the training set, akin to\nan open-book exam. The main results of the paper are summarized as follows:\n\u2022 We present a general framework for open-book NAR. This framework builds upon the foun-\ndation of previous NAR architectures by introducing two additional modules for embedding\nand information aggregation from the training set, and can seamlessly integrate with existing\nmethods. We further provide a detailed implementation of the framework, which is grounded\nin the cross-attention mechanism. This design not only caters to single-task training but also\nproves to be highly effective in scenarios involving multi-task training.\n\u2022 Empirical evaluations are conducted on the challenging CLRS Benchmark [26]. We incor-\nporate the proposed framework with three popular network architectures in the literature.\nThe results demonstrate that each architecture's reasoning capability can be improved signif-\nicantly when utilizing the training instances through the framework. Across the majority of\nthe reasoning tasks within the benchmark, the framework yields state-of-the-art results.\n\u2022 Multi-task training is also investigated in the paper. As highlighted in [11], on certain\nreasoning tasks, a generalist network trained on all datasets in CLRS outperforms the\nnetworks trained in a single-task manner. We provide an interpretation of this observation\nusing the proposed open-book framework. Specifically, when training a neural network to\nsolve a task, we input information from other task datasets into the framework for its use.\nThe results show that our open-book framework can nearly replicate the effects of multi-task\ntraining for each algorithmic task, while in some tasks, it even achieves higher accuracies.\nAdditionally, our attention-based implementation enables us to analyze the attention weights\nof various tasks, facilitating a deeper understanding of the intrinsic relationships among"}, {"title": "1.2 Other Related Work", "content": "Our work is closely aligned with the exploration of non-parametric models [23, 25, 13], where\nmodels abstain from training specific parameters and, instead, utilize dependencies among training\ndata points for predictions. Our framework can be viewed as a fusion of deep neural networks and\nnon-parametric models. We have noted analogous efforts in recent work within the field of image\nprocessing [15]. This work focuses on the CIFAR-10 dataset, employing self-attention mechanisms\namong different points in the dataset to finish image classification tasks."}, {"title": "2 Preliminaries", "content": "This section introduces the setting of an NAR dataset formally and outlines the standard paradigm\nemployed in NAR.\nNAR Dataset. The objective of an NAR task is to train a neural network such that it can imitate\neach execution step of a classical algorithm on given problem instances. Hence, a NAR dataset is\nlabeled by a specific problem and the algorithm employed to solve it. Each data point includes a\nproblem instance, represented by a graph structure, and the corresponding algorithm execution on that\ninstance, conveyed through a sequence of graph-structured states. Denote by $x$ the problem instance\nand by $y = \\{y^{(1)}, ..., y^{(t)}, ...\\}$ the algorithm execution, where $y^{(t)}$ signifies the graph-structured\nstates (e.g., the current nodes in the queue of breadth-first search) at the $t$-th step of the algorithm.\nTraining Objective. The training objective of the neural network is to perform sequential reasoning\ntasks over a given problem instance. At each step $t$, the network takes as input the pair $(x, y^{(t-1)})$ and produces the output $y^{(t)}$. This process enables the neural network to learn and predict the\nevolution of the algorithmic execution on the problem instance in a step-wise fashion.\nEncode-Processor-Decode Paradigm. To achieve the aforementioned step-wise objective, the\nliterature follows the standard encode-process-decode paradigm [10], which consists of three modules:\nEncoder, Processor, and Decoder. At each step $t$, the input $(x, y^{(t-1)})$ traverses through these\nmodules sequentially:\n\u2022 The encoder module encompasses multiple neural networks that operate on $(x, y^{(t-1)})$,\nthereby transforming it into a collection of graph-structured hidden states. Use $G = (V, E)$\nto denote the graph structure. Following this module, we obtain $h_v$ corresponding to each\nnode $v \\in V$, $h_{vu}$ associated with each edge $(v, u) \\in E$, and $h_G$ representing the hidden\nstate of the entire graph $G$.\n\u2022 The processor module usually consists of a graph neural network. This module maintains\nthe historical hidden states of nodes, edges, and the graph: $\\{h_v^{(t-1)}\\}_{v\\in V}$, $\\{h_{vu}^{(t-1)}\\}(v,u)\\in E$,\n$h_G^{(t-1)}$, and integrate them with the newly generated states $\\{h_v\\}$, $\\{h_{v,u}\\}, h_G$ to yield updated\nstates. We borrow the language of the message-passing architecture [9] to formalize this\nprocess. For brevity, the following focuses only on updating the state of each node $v$. At\neach step $t$, the node computes and aggregates messages $m_{uv}$ from its incoming edges,\nupdating its own hidden state:\n$z_v^{(t)} \\leftarrow f_1\\left(h_v, h_v^{(t-1)}\\right);$\n$M_v \\leftarrow \\bigoplus_{u:(u,v) \\in E} m_{uv}; m_{uv} \\leftarrow f_2\\left(z_v^{(t)}, z_v^{(t)}, h_{uv}, h_G\\right) (u, v) \\in E$;\n$h_v^{(t)} \\leftarrow f_3\\left(z_v^{(t)}, M_v\\right)$.\nDifferent processors employ different layers $f_1, f_2, f_3$, and aggregation function $\\bigoplus$.\n\u2022 The decoder module utilizes the states $h_v^{(t)}$ as input to forecast the algorithmic execution\n$y^{(t)}$ at step $t$. It is noteworthy that recent literature [11] also incorporates $x$ and $y^{(t-1)}$\nwithin this module."}, {"title": "3 Open-Book Reasoning", "content": "The paradigm above can be denoted by a function $F$ mapping $x$ to $y$ for each data point. Given a\nNAR dataset, this function implies a standard supervised learning mode: during a training step, a (or\na mini-batch of) random datapoint $(x, y)$ is selected. The loss between $F(x)$ and $y$ is then computed,\nand the parameters in $F$ are updated accordingly. In this section, we go beyond the individual $x \\rightarrow y$\nmode in conventional supervised learning, exploring a more general and practical learning paradigm."}, {"title": "3.1 Framework", "content": "We introduce an open-book reasoning framework. Within the framework, when the network is tasked\nwith solving problem instance $x$ and deducing $y$, it not only utilizes $x$ as input but is also allowed to\nleverage information from other data points within the training set during the reasoning process."}, {"title": "3.2 Attention-Based Implementation", "content": "Diverse implementations within the framework can be achieved by employing different functions for\n$f_e$ and $f_p$. For the ease of investigating multitask training, we adopt an attention mechanism-based\nimplementation. A description of the network implementation and training is given in Algorithm 1."}, {"title": "4 Experiments", "content": "This section evaluates the open-book implementation empirically on the CLRS benchmark. We aim\nto investigate the following three questions during the experiments:\n\u2022 For various processor architectures present in the literature, can the open-book framework\nconsistently enhance their empirical performances across the majority of the algorithmic\ntasks within the CLRS benchmark?\n\u2022 There is a recent literature [11] proposing a multi-task training approach for CLRS. They\ntrain a common network for various tasks in the benchmark and find that some tasks benefit\nfrom the multi-task approach, achieving higher accuracy than when trained individually.\nIn the context of the open-book setting, does this phenomenon imply that incorporating\ntraining sets from various tasks into the open-book framework may enhance the network's\nperformance on certain tasks?\n\u2022 Can the attention-based implementation serve as a robust tool for interpretable multi-task\ntraining? When integrating training sets from various tasks into the open-book framework for\na specific task, the network eventually learns attention weights in the open-book processor,\nsignifying the task's relevance to other tasks. Does this imply that if a task performs better\nin multi-task training than in single-task training, retaining only those tasks with prominent\nattention for multi-task training can still outperform single-task training?\nTo tackle these questions, we conduct three types of experiments: single-task augmenting, multi-task\naugmenting, and multi-task interpretation. Note that our \u201cmulti-task augmenting\u201d experiment differs\nessentially from traditional multi-task training; here, we still train the network for a specific task, but\nwith the inclusion of datasets from other tasks in the dataset encoder. Additional ablation experiments\nare also conducted (see the appendix). We initially outline the experimental setup and subsequently\ndelve into each experiment."}, {"title": "4.1 Setup", "content": "Baselines. We incorporate the open-book framework into three existing processor architectures:\nPGN [29], MPNN [9] and Triplet-GMPNN [11]. Given that the feature dimension of hidden states\nis set to 128 in the literature, we adjust the parameters of the dataset encoder and open-book\nprocessor to ensure seamless integration. The results (F1 scores) achieved by open-book reasoning\nare compared with them. Moreover, we also compare the performance with other recent architectures\nlike Memnet [26] and NPQ [12].\nComputational Details. The experiments are conducted on a machine equipped with an i7-13700K\nCPU, an RTX 4090 GPU, and an RTX A6000 GPU. The results are averaged over 4 runs. To ensure\nfair comparisons, we follow the widely-used experimental hyperparameter settings in [11], where the\nbatch size is 32 and the network is trained for 10,000 steps by Adam optimizer with a learning rate\nof 0.001. During each training and testing iteration, we allow Algorithm 1 to sample 240 auxiliary\ndata points and use only one attention head. The average training time for each reasoning task is\napproximately 0.5 GPU hours."}, {"title": "4.2 Single-Task Augmenting", "content": "This subsection considers a single-task environment: for each reasoning task in CLRS, both target\nand auxiliary data points in Algorithm 1 are sourced from its own dataset. We create comparison\ncharts for results on three existing architectures. We present one chart Figure 2 in the main body,"}, {"title": "4.3 Multi-Task Augmenting", "content": "This subsection considers a \"multi-task\" environment: for each task in CLRS, Algorithm 1 selects\ntarget points from its own dataset, while the sampled auxiliary points are drawn from all datasets in\nCLRS. Since CLRS comprises 30 datasets, in each iteration, we randomly sample 8 instances from\neach dataset, ensuring that the total number of auxiliary points remains the same as in the single-\ntask experiment, i.e., 240. Given that Triplet-GMPNN is the only architecture used for multi-task\ntraining in the literature, both this subsection and the following one \u201cmulti-task interpretation\u201d focus\nexclusively on the results obtained by integrating the open-book framework with Triplet-GMPNN.\nThe results are present in Figure 3. We find that incorporating data from different tasks into the\nopen-book processor indeed replicates multi-task training. Our multi-task augmented method closely\nmatches the previous multi-task training results, and even outperforms them on the vast majority of\ntasks. It is worth noting that multi-task training requires simultaneous training on all 30 algorithmic\ntasks, which is extremely time-consuming. If the goal is simply to enhance performance on a specific\ntask using multi-task training, the cost is substantial. However, with the open-book framework, we\ncan nearly achieve the effects of multi-task training on a target task in approximately the same amount\nof time it takes to train a single algorithm."}, {"title": "4.4 Multi-Task Interpretation", "content": "This subsection delves into interpreting multi-task training. In our multi-task augmenting experiments,\nthe acquired attention weights in the open-book processor reveal the significance of each task in\nrelation to others. Specifically, for each task, we aggregate the attention weights of each node at\nevery algorithmic step on each test instance. The resulting 30-dimensional vector is then normalized,\nserving as the total attention vector for that task relative to other tasks in the benchmark. Table 2\nshows the task with the highest attention weight for each task. Moreover, we present a heatmap\nregarding the attention weights among CLRS tasks in Appendix B.\nSurprisingly, the table indicates that the majority of tasks exhibit a preference for attention toward\ntasks outside their own categories, contrary to our initial expectations. Only four bolded pairs show\nhigh attention to tasks within the same category, with most of these being graph algorithms. An\nintuitive explanation for this phenomenon is that tasks within the same category might not contribute\nadditional information compared to the dataset used for training the task itself. Instead, tasks from\nother categories seem to play a crucial role in improving training accuracy."}, {"title": "4.5 Experimental Summary", "content": "The experiments address the three questions posed at the beginning of the section.\n\u2022 The open-book framework can significantly enhance the reasoning capabilities of various\nexisting architectures, yielding state-of-the-art results across the majority of tasks in CLRS.\n\u2022 By feeding data from various tasks into the dataset encoder, the framework can successfully\nreplicate the effects of multi-task training, and in most datasets, even outperform it."}, {"title": "5 Conclusion", "content": "This paper considers open-book neural algorithmic reasoning, introducing a novel open-book frame-\nwork accompanied by an attention-based implementation. Through empirical evaluations, we demon-\nstrate that this implementation not only enhances the reasoning capabilities of the existing architecture\nbut also functions as an effective tool for interpretable learning.\nSeveral interesting direction for future research exist, such as exploring more effective implementa-\ntions within the open-book framework. Note that although our current implementation demonstrates\nperformance improvements for the majority of tasks in CLRS, there are instances where the open-\nbook approach may yield counterproductive results. Refining the current architecture to ensure\nperformance enhancements across all tasks remains a significant challenge."}]}