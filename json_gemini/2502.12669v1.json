{"title": "Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research", "authors": ["Xiang Liu", "Penglei Sun", "Shuyan Chen", "Longhan Zhang", "Peijie Dong", "Huajie You", "Yongqi Zhang", "Chang Yan", "Xiaowen Chu", "Tong-yi Zhang"], "abstract": "The rapid advancement of perovskite solar cells (PSCs) has led to an exponential growth in research publications, creating an urgent need for efficient knowledge management and reasoning systems in this domain. We present a comprehensive knowledge-enhanced system for PSCs that integrates three key components. First, we develop Perovskite-KG, a domain-specific knowledge graph constructed from 1,517 research papers, containing 23,789 entities and 22,272 relationships. Second, we create two complementary datasets: Perovskite-Chat, comprising 55,101 high-quality question-answer pairs generated through a novel multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully curated materials science problems. Third, we introduce two specialized large language models: Perovskite-Chat-LLM for domain-specific knowledge assistance and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental results demonstrate that our system significantly outperforms existing models in both domain-specific knowledge retrieval and scientific reasoning tasks, providing researchers with effective tools for literature review, experimental design, and complex problem-solving in PSC research.", "sections": [{"title": "1 Introduction", "content": "Perovskite solar cells (PSCs) have emerged as one of the most promising next-generation photovoltaic technologies, achieving remarkable progress with power conversion efficiencies (PCEs) exceeding 27.0% within just over a decade (National Renewable Energy Laboratory, 2025; Snaith, 2018; Correa-Baena et al., 2017; Wu et al., 2021; Ang et al., 2022; Sathaye et al., 2011; Bogdanov et al., 2019). The rapid development of PSCs has generated an exponential growth in research publications, making it increasingly challenging for researchers to efficiently access and utilize the vast amount of knowledge in this field. This challenge is particularly acute given the complex interplay between material composition, fabrication processes, and device structure that characterizes PSC research.\nTraditional approaches to scientific knowledge management, such as literature reviews and databases, while valuable, are limited in their ability to capture the intricate relationships between different aspects of PSC research (Yang et al., 2024b; Han et al., 2025). Furthermore, existing artificial intelligence systems in materials science typically focus on either specific prediction tasks or general scientific knowledge, lacking the specialized capability to handle the unique characteristics of perovskite solar cell research (Han et al., 2025). This gap highlights the need for an integrated system that can both organize domain knowledge systematically and provide intelligent assistance to researchers.\nTo address these challenges, we present a comprehensive knowledge-enhanced system specifically designed for the perovskite solar cell domain, consisting of three key components. First, we develop Perovskite-KG, a domain-specific knowledge graph constructed from 1,517 research papers, containing 23,789 entities and 22,272 relationships across manufacturing processes, parameters, and performance metrics. Second, we create a multi-agent framework for generating high-quality instruction-tuning data, which not only reduces annotation costs but also ensures high reliability and low hallucination through the synergy of multiple specialized agents and expert guidance. This framework generates two complementary datasets: (1) Perovskite-Chat, an instruction-tuning dataset comprising 55,101 high-quality question-answer pairs generated from 2,214 high-impact papers using a novel multi-agent framework, and (2) Perovskite-Reasoning, a collection of 2,217 care-"}, {"title": "2 Related Work", "content": "2.1 LLM in Materials Science\nThe convergence of language modeling and computational materials science has unlocked transformative potential for accelerated discovery. Recent breakthroughs in domain-specific architectures (e.g., hierarchical attention mechanisms (Kononova et al., 2021) and multimodal fusion networks (Swain and Cole, 2016)) have addressed critical challenges in crystal structure prediction (Walker et al., 2021) and phase diagram analysis (Trewartha et al., 2022). As evidenced by the Materials Genome Initiative benchmarks (Tshitoyan et al., 2019), three principal research thrusts have emerged: (1) structured information extraction from heterogeneous corpora, (2) knowledge graph embeddings for composition-property relationships, and (3) neurosymbolic reasoning for synthesis pathway optimization.\nBuilding upon these foundations, knowledge-enhanced systems have achieved state-of-the-art performance through two complementary paradigms: graph-based approaches employing heterogeneous graph neural networks (HGNNs) now attain 89.7% accuracy on multi-hop material property queries (An et al., 2024), while agent-based frameworks demonstrate 18.7% improvement in autonomous experimental design through chain-of-thought prompting (Zhang et al., 2024a).\nThe field's maturation is further evidenced by systematic resource development: (i) The SciQAG framework (Wan et al., 2024) introduces a novel curriculum learning paradigm for generating 120K domain-specific QA pairs, reducing expert annotation requirements by 78%; (ii) Standardized evaluation now spans chemical synthesis (ChemLLM-Bench's reaction yield prediction task (Guo et al., 2023)), biomedical applications (MultiMedQA's toxicity prediction challenge (Singhal et al., 2023)), and cross-domain reasoning (SciEval's materials-device co-design track (Sun et al., 2023)).\n2.2 Knowledge Graph in Materials Science\nDomain-specific knowledge graphs have evolved into structured semantic frameworks that systematically consolidate heterogeneous multi-source data through machine-readable representations, enabling cross-domain knowledge integration to accelerate discovery pipelines (Pan et al., 2024; Song et al., 2024; Zhu et al., 2022). In materials informatics, current implementations manifest two distinct paradigms: literature-derived systems exemplified by MatKG (Venugopal and Olivetti, 2024) and DISCOMAT (Gupta et al., 2023), which employ NLP and graph techniques to extract material compositions from textual sources, while empirical architectures represented by MatSciKB (Zhang et al., 2024b), Propnet (Mrdjenovich et al., 2020), MekG (Statt et al., 2023), and MOF-KG (An et al., 2022) focus on encoding experimental provenance and computational models through graph-based representations of material lineages. However, these approaches face the challenges that manual curation processes with resource burdens, while existing extraction methods exhibit limited granularity in resolving complex synthesis-process-"}, {"title": "3 Perovskite-KG", "content": "\u2022 Document Filtering. Drawing upon expert knowledge, we have developed the schema for perovskite materials. This schema, shown in Appendix Table 5, integrates three ontologies {0i | or \u2208 schema}: fabrication, parameters, and performance. The fabrication ontology encompasses the procedures and conditions required to synthesize perovskite materials. The parameters ontology defines the ingredients, structural components, and other compositional aspects of the device. The performance ontology is concerned with the efficiency and functional characteristics of perovskite devices. Each ontology $o_i$ is further divided into sub-ontologies $so_i^{(j)}$, where $o_i = \\bigcup_{j=1}^{n_i} so_i^{(j)}$ and $n_i$ represents the number of sub-ontologies within $o_i$. Each sub-ontology $so_i^{(j)}$ provides a domain-specific description, denoted as $d_i^{(j)}$, along with a corresponding data type, denoted as $t_i^{(j)}$, that is relevant to its particular scope.\nFor each sub-ontology $so_i^{(j)}$ (e.g., \"Coating Parameter\" - \"Details about the coating method used in the material deposition process\" - \"Float\"), we create the prompts to query documents $D = {D_k | k = 1, . . ., m}$ using a large language model. These prompts facilitate the extraction of relevant information for each sub-ontology. The output $D_{filtered}^{(i,j)}$ is defined as:\n$D_{filtered}^{(i,j)} = {D_k \u2208 D | so_i^{(j)} \u2282 D_k}$, (1)\nwhere $D_{filtered}^{(i,j)}$ represents the set of filtered documents containing pertinent details for sub-ontology $so_i^{(j)}$ across the collection. This approach ensures a systematic and efficient retrieval of targeted information for each sub-ontology.\n\u2022 Knowledge Extracting. We employ a prompt function, denoted as $f_{prompt}(\u00b7)$, to transform the sub-ontology $[so_i^{(j)}, d_i^{(j)}, t_i^{(j)}]$ into a document prompt, represented as $f_{prompt}(so_i^{(j)}, d_i^{(j)}, t_i^{(j)})$. To extract the potential domain knowledge K, we utilize a pre-trained large language model (LLM), expressed as LLM(\u00b7; \u03b8), under a zero-shot setting where the parameters \u03b8 remain fixed. The whole pipeline can be formulated as below:\n$K = search LLM(f_{prompt}(so_i^{(j)}, d_i^{(j)}, t_i^{(j)}), D_{filtered}^{(i,j)}; \u03b8)$, (2)\nwhere the search function search(\u00b7) may involve an argmax operation to identify the highest-scoring output or a sampling approach to generate outputs according to the probability distribution specified by the adopted LLM(\u00b7; \u03b8).\nAfter extracting knowledge, we conduct quality control procedures to ensure accuracy and reliability. These procedures include entity disambiguation and relationship deduplication. Entity disambiguation in a knowledge graph aims to resolve ambiguity by identifying the unique entity that corresponds to an ambiguous mention, denoted as @mention, within a subgraph. The objective is to determine a distinct entity e* that accurately represents @mention. Relationship deduplication involves identifying and merging redundant relations in the"}, {"title": "4 Instruction Tuning Dataset Generation", "content": "In this section, we collect 2, 214 the top level publications papers in perovskite domain and design the instruction tuning dataset including question answering and multiple choice questions, containing 55, 101 instances around 4.4 million tokens, named Perovskite-Chat. Our experiments show that our perovskite instruction tuning dataset can effectively improve the performance of LLMs on perovskite related tasks.\nFigure 1 (b) illustrates this multi-agent framework for instruction tuning dataset generation. The process begins with expert guidance and academic literature from various sources (including Science, Nature, Elsevier, Springer, arXiv, and others) as inputs. The expert guidance is provided by the domain expert focus on 7 research categories, 21 research questions. Table 1 further expands this classification by presenting 21 specific research questions (Q1-Q21) organized within these seven categories, more details can be found in Appendix D.1. These inputs feed into a multi-agent system: (1) an Information Extraction Agent that processes the raw content, (2) a Quality Validation Agent that ensures data accuracy and relevance, and (3) a Document Summarization Agent that condenses and structures the information. This framework ensures systematic, high-quality data processing through multiple validation and refinement stages.\nLet D = {$d_1,...,d_n$} represent the collection of academic literature from various sources, and E = {$c_1, ..., c_7$} denote the expert guidance categories with corresponding research questions Q = {$q_1, ..., q_{21}$}. The multi-agent framework processes these inputs through three specialized agents:\nInformation Extraction:\n$A_{extract}(d_i) = {x_1, ..., x_k}$ (3)\nQuality Validation:\n$A_{validate}(x_j) = \\begin{cases}\n1, & \\text{if valid} \\\\\n0, & \\text{otherwise}\n\\end{cases}$ (4)\nDocument Summarization:\n$A_{summarize}(A_{validate}(A_{extract}(d_i))) = y$ (5)\nThe final instruction tuning dataset D is constructed as:\nD = {$(q_i, y_i) | q_i \u2208 Q,$\n$y_i = A_{summarize}(A_{validate}(A_{extract}(d_i)))$} (6)\nNext, we introduce Perovskite-Reasoning, a collection of 2,217 high-quality questions from materials science textbooks, designed to enhance reasoning capabilities in perovskite and materials science domains. Similar to S1 (Muennighoff et al., 2025) and LIMO (Ye et al., 2025), our dataset maintains data efficiency with fewer than 3,000 instances. The questions were sourced from hundreds of widely-used materials science and engineering textbooks, with a focus on perovskite solar cells and fundamental materials science concepts. Our rigorous selection process applied three key criteria: clarity of problem statements, solution completeness, and alignment with core materials science principles. Materials science professors conducted expert assessments to categorize questions by difficulty level, validated through student performance"}, {"title": "5 Perovskite-LLM", "content": "5.1 Experiment Design\nIn this section, we conduct the instruction tuning experiments on the Perovskite-Chat and Perovskite-Reasoning dataset. We select the LLaMA-3.1-8B-Instruct (Dubey et al., 2024) and Qwen-2.5-7B-Instruct (Yang et al., 2024a) as the baseline model, and Perovskite-Chat-LLM and Perovskite-Reasoning-LLM are fine-tuned version of LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct with Perovskite-Chat and Perovskite-Reasoning dataset.\nFor the training process, we use the full parameter fine-tuning method to fine-tune the Perovskite-LLM. The experiment is conducted on the A800 GPU server, with flash attention (Dao, 2024) and mixed precision training for efficient training. For more details about the training process, please refer"}, {"title": "6 Conclusion", "content": "In this work, we present a comprehensive knowledge-enhanced system for perovskite solar cell research, integrating three key components: (1) Perovskite-KG, a domain-specific knowledge graph containing 23,789 entities and 22,272 relationships; (2) multi-agent system for generating two complementary datasets, Perovskite-Chat and Perovskite-Reasoning, designed for domain-specific knowledge assistance and scientific reasoning respectively; and (3) two specialized large language models that demonstrate superior performance in both knowledge retrieval and reasoning tasks. Our experimental results show significant improvements over existing models, with Perovskite-Chat-LLM achieving state-of-the-"}, {"title": "A Additional Related Work", "content": "A.1 Multi-agent systems\nThe landscape of AI system architectures encompasses two distinct paradigms: multi-agent systems and autonomous agents (Zhuge et al., 2023; Hong et al., 2024a; Zhang et al., 2024c; Wang et al., 2023). While autonomous agents rely on independent decision-making capabilities, multi-agent systems excel through structured collaboration between specialized components. The latter approach offers practical advantages by building upon established expertise rather than requiring complex behavioral modeling.\nResearch in multi-agent frameworks has evolved along two primary trajectories. The first focuses on domain-agnostic systems that leverage collective intelligence for general problem-solving (Wei et al., 2022; Diao et al., 2024; Wang et al., 2022; Madaan et al., 2023; Wang et al., 2024). The second pathway explores domain-specific applications, with notable implementations in:\n\u2022 Code generation and debugging (Hong et al., 2024b; Ridnik et al., 2024; Zhong et al., 2024a)\n\u2022 Data analytics (Xie et al., 2024; Ye et al., 2024; Li et al., 2024; Zhou et al., 2023b)\n\u2022 Mathematical reasoning (Zhong et al., 2024b; Xu et al., 2024)\n\u2022 Knowledge retrieval (Nori et al., 2023; Zhou et al., 2024)\nDespite significant progress in identifying effective agent configurations for specific use cases, the field still faces the challenge of developing systematic approaches for new domains. This highlights the importance of research into automated methods for framework design and optimization.\nB Schema in Perovskite-KG\nTable 5 presents a comprehensive schema for the Perovskite-KG, organized into three main ontological categories: Fabrication, Parameters, and Performance. The Fabrication ontology encompasses process-related attributes such as coating parameters, methods, and annealing conditions. The Parameters ontology covers structural and compositional aspects including solvents, device architecture, and additives. The Performance ontology"}, {"title": "C Prompts", "content": "The system employs four specialized agents, each with carefully designed prompts to perform specific tasks in the perovskite solar cell knowledge processing pipeline:\n1. Information Extraction Agent (Table 6): Processes research papers using a structured set of 20 predefined questions across seven key categories, including device structure, performance enhancement, stability, and materials. The agent returns answers in a standardized JSON format, marking unavailable information as \"Not mentioned\" to maintain data quality.\n2. Verification Agent (Table 7): Validates extracted information by comparing it with source texts, focusing on maintaining accuracy of technical details like numerical values and material names. The agent provides both corrected content and justification for any modifications made.\n3. Organization Agent (Table 8): Synthesizes verified information from multiple sources into coherent, topic-focused responses. This agent ensures that complex technical information is presented in a logical and accessible manner.\n4. LLM-Judge (Table 9): Evaluates response quality across four key criteria: accuracy, completeness, relevance, and clarity. Using a 1-5 scoring system, this agent provides detailed assessments and explanations for each criterion, along with an overall evaluation summary.\nD Instruction Tuning Dataset\nD.1 Dataset Statistics\nThe research questions in perovskite solar cell studies are systematically categorized in Tables 1 and 10. Table 1 provides a high-level overview of seven major research categories, including Device Structure and Fabrication, Performance Enhancement Strategies, Performance Metrics Improvement, Sta-"}]}