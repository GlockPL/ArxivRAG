{"title": "KAE: A Property-based Method for Knowledge Graph Alignment and Extension", "authors": ["Daqian Shi", "Xiaoyue Li", "Fausto Giunchiglia"], "abstract": "A common solution to the semantic heterogeneity problem is to perform knowledge graph (KG) extension exploiting the information encoded in one or more candidate KGs, where the alignment between the reference KG and candidate KGs is considered the critical procedure. However, existing KG alignment methods mainly rely on entity type (etype) label matching as a prerequisite, which is poorly performing in practice or not applicable in some cases. In this paper, we design a machine learning-based framework for KG extension, including an alternative novel property-based alignment approach that allows aligning etypes on the basis of the properties used to define them. The main intuition is that it is properties that intentionally define the etype, and this definition is independent of the specific label used to name an etype, and of the specific hierarchical schema of KGs. Compared with the state-of-the-art, the experimental results show the validity of the KG alignment approach and the superiority of the proposed KG extension framework, both quantitatively and qualitatively.", "sections": [{"title": "1 Introduction", "content": "The semantic heterogeneity problem arises whenever there is a need to exploit knowledge graphs (KGs) from heterogeneous resources [36]. Here we focus on KGs where nodes are entities decorated by data properties and relations are object properties. Furthermore, we talk of entity type (etype) meaning the class to which an entity belongs, e.g., Person and Event. A solution of semantic heterogeneity is to perform KG extension that extends the reference KG by knowledge encoded in one or more candidate KGs. Meanwhile, KG alignment is an attractive topic that involves various tasks, e.g., well-known ontology matching (OM), where two practical tasks are considered critical steps to achieving KG extension. Firstly, the alignments between etypes from reference and candidate KGs [2, 21, 32], exploiting only schema level information, as it is the most often case in OM. Secondly, the alignments between reference etypes and candidate entities, exploiting additional information of entities, also known as etype recognition [43,47]. These two kinds of alignments are prerequisites for extending the reference KG at both the schema level and instance level, respectively.\nEtype alignment is a prepositive task during KG extension since etypes define the schema of collected entities in a KG. The reference KG can directly integrate candidate entities if their corresponding etypes align with reference etypes. Existing etype alignment methods mainly exploit natural language processing (NLP) based [14, 52] and structure-based [24, 35] techniques. Both techniques enforce etype label matching as a prerequisite. NLP-based methods utilize diverse lexical-based similarity metrics and synonym analysis to align etype labels, which raises limitations when applied in practice. Labels may suggest a wrong etype [49], where the same concept can be labeled differently by KGs. For instance, an eagle can be labeled as Bird in a general-purpose KG and Eagle in a domain-specific KG. In turn, the same label may present different concepts in heterogeneous KGs, which will also lead to wrong recognition results. Structure-based methods consider the KG hierarchy as an additional input, where the structure of a hierarchy is used to drive the label matching, e.g., it is suggested to perform label matching to sub-classes or super-classes. However, these methods may also mislead the conclusions as properties assigned to an etype in the hierarchy are cumulative and depend only on nodes in the path from the root and, therefore, do not depend on the order by which they are assigned [30]. In addition, the difference in taxonomy between KGs will increase the impact of such mistakes, e.g., the super-class of etype Eagle can be Animal in one KG and Bird in another KG. On the other hand, the alignments between etypes and entities (here we call etype recognition task) are also critical since the reference KG can also be extended by candidate entities that are not included in aligned etypes. However, it is not easy to identify such alignments due to the lexical labels are not applicable to alignment entities and etypes. For instance, entity apple can be a company, a fruit, or the name of a pet, but there is only trivial lexical similarity between entity apple and etypes company, fruit and pet. Thus, current NLP-based and structure-based methods poorly perform the etype recognition task either.\nAs a solution to the above problems, the main intuition of this paper is to align etypes/entities with reference etypes for KG extension on the basis of the properties used to define them. It is, in fact, the properties that are used to intentionally define an etype, and this definition is independent of the specific label and also independently of its hierarchy [27]. This allows us to think of etypes as being organized in hierarchies, where lower etypes inherit properties from upper etypes and where the entities populating an etype also populate all the upper etypes. In turn, it allows us to think of KG alignment as a problem of matching inheritance hierarchies, where etypes may or may not be populated with entities. In practice, most relevant KGs are associated with large numbers of properties, see, e.g., DBpedia [4] and OpenCyc [23]. And the reason for this is quite obvious, being that one of the purposes of KG extension is exactly that of extending the number of properties.\nIn this paper, we propose a machine learning (ML)-based framework to realize KG extension task, including an algorithm for generic KG alignment based on the above intuition of exploiting properties. We introduce a formalization strategy, where we organize a KG and its inner mappings between etypes/entities and properties based on the use of formal concept analysis (FCA) [27]. Then, we present three property-based metrics to measure the similarity between etypes and entities, where the metrics characterize the role that properties have in the definition of given etypes from different aspects. They capture the main idea that the number of aligned properties affects the contextual similarity between etypes and entities. The proposed similarity metrics and algorithm are applied in two key modules of the KG extension framework, i.e., etype alignment and KG extension modules. Finally, we will obtain an extended reference KG by integrating etypes and entities from the candidate KGs.\nOverall, the main contributions of this paper are as follows:\nWe design an ML-based framework for KG alignment and extension tasks, where etype alignment and etype recognition are introduced as two key procedures.\nWe proposed a novel set of property-based metrics for measuring contextual similarity between KGs while introducing an FCA-based KG formalization strategy.\nWe implement a classification-based method for KG alignment, which exploits the property-based information by our proposed metrics.\nWe compare our method with state-of-the-art etype recognition methods from several different perspectives. The experimental results show the validity of the similarity metrics and the superiority of the proposed KG extension framework, both quantitatively and qualitatively.\nThe rest of the paper is organized as follows. Section 2 discusses the motivation for exploiting properties for etype recognition and section 3 demonstrates how we formalize a KG and its inner mappings into FCA contexts. Section 4 introduces three specificity measurements and their corresponding property-based etype similarity metrics. In section 5, we describe the proposed ML-based KG extension framework and the details of individual modules. Then we discuss the experiment setups and experimental results in Section 6. Finally, we present the related work in Section 7 and conclude the paper in Section 8."}, {"title": "2 Intuitive Discussion", "content": "In the knowledge integration area, KG alignment and extension can be organized as sequential tasks, where KG alignment aims to align the knowledge from candidate KG and reference KG, and KG extension aims to integrate target information into the reference KG following the aligned knowledge. To clearly define the above-mentioned tasks, we define a KG as a hierarchy of concepts, where properties are used to describe them. Specifically, we define the schema of a KG and its inner relations as KGS = (C, P, R), where C = {C1, ..., Cn} being the classes of entities (i.e. etypes), P = {p1,\u2026,Pm} being the set of properties, R = {{Ci,T(Ci))|Ci \u2208 C'} being the set of correspondences between etypes and properties, and function T(Ci) returns properties associated with Ci. As for the entities I, we define I = {I1, ..., I\u2081} being the set of entities in KG, where each entity I\u2081 can be identified by one or several etypes. t(I\u2081) refers to the set of associations between entities and properties. We consider that the property pi is used to describe an etype C\u2081 or an entity I\u2081 when the property belongs to set T(Ci) or t(Ii), respectively. Thus, given a reference KGref and a candidate KGcand, considering the two cases in KG alignment, etype alignment task aims to align the candidate etypes Ccand with the reference etypes Cref, and etype recognition task aims to align the candidate entities Icand with Cref, where Ccand, Icand \u2208 KGcand, Cref \u2208 KGref\u00b9."}, {"title": "2.2 Observations and Motivations", "content": "Property is one of the most basic and critical elements for intentionally defining KG concepts, which is independent of the specific label used to name concepts and of the specific hierarchical schema of KGs [31]. For each KG schema, etypes play the role of categorization, and properties aim to draw sharp lines so that each entity in the domain falls determinately either in or out of each etype [29]. Meanwhile, we also have the following observations when comparing properties across different KGs:\nIn a specific KG, each etype is described by a set of properties, whereas most of the properties are distinguishable according to the belonging etypes and a small number of properties are shared across different etypes.\nSame or similar properties are shared across different KGs for describing same concepts."}, {"title": "3 Knowledge Graph Formalization", "content": "We formalize the relation between properties and KG concepts as associations to introduce the property information into the target KG tasks. At the schema level, the KG schema will be flattened into a set of triples, where each triple encodes information about etype-property associations, e.g., triple \u201corganization-domain-LocatedIn\" encodes the \"organization-LocatedIn\" association. Instance-level cases generally define triples as \"entity-property-entity\", where two associations are encoded. For instance, instance-level triple \"EiffelTower-LocatedIn-Paris\" encodes two entity-property associations \"EiffelTower-LocatedIn\" and \"LocatedIn-Paris\". We introduce FCA [27] to encode such associations as a formalization of the KGs we process. Notice that both the schema-level and instance-level associations are included in the formalization. Specifically, we have two working assumptions:\nWe consider both etypes C and entities I. Similar to general formalization methods [18,51], we associate an entity with its set of properties t(I\u2081). Different from general methods, we also associate an etype with its set of properties T(Ci).\nEtype characterization exploits not only the properties associated with it but also the properties which are associated with other concepts. Thus, we introduce the notion of unassociated properties and exploit this distinction in the formalization process.\nAs an example, the hierarchy of the KG schema is extracted from DBpedia [4]. In each box, etypes are presented in yellow and their properties in green. The arrow refers to the sub-class of relation between two etypes. We then formalize these etypes into an FCA context. We adopt the following conventions. The value box with a \u201c+1\u201d represents the fact the property is associated with the etype, e.g.,"}, {"title": "4 Property-based Similarity Metrics", "content": "One of the intuitions of our work is to identify etypes and entities by properties that are essential elements for defining KG concepts [30]. The reference etype tends to match with the candidate etype/entity when they have properties overlapped. Therefore, it is critical to measure the overlapped properties between etypes since etypes with completely overlapped properties rarely happen in real-world KGs [26]. Meanwhile, we also exploit the intuitions underlying the normalization of the \"get-specific\" heuristic provided in [33] to distinguish the weights of different overlapped properties. The key inspiration is that properties at different levels of specificity have different relevance in the etype recognition. In particular, a more specific property provides more information that allows for defining concepts. As a result, in this section, we introduce three notions of horizontal specificity, vertical specificity, and informational specificity and their corresponding similarity metrics for measuring the degree of overlapped properties."}, {"title": "4.1 Horizontal Specificity", "content": "For measuring the specificity of a property, a possible idea is to horizontally compare the number of etypes that are described by a specific property, namely the shareability of the property [30]. If a property is used to describe diverse etypes, it means that the property is not highly characterizing its associated etypes. Thus, for instance, in figure 1, the property name is used to describe Person, Place, Athlete and Artist, where name is a common property that appears in different contexts. Dually, settlement is a horizontally highly specific property since it is associated only with the etype Place. Based on this intuition, we consider the specificity of a property as related to its shareability. Therefore, we propose HS (Horizontal Specificity) for measuring property specificity. More precisely, HS aims to measure the number of etypes that are associated with the target property in a specific KG. We model HS as:\n\\(HSKG(E,p) = WE(P) * e^{\\lambda(1\u2212|\u039a\u03c1|)}\\)"}, {"title": "4.2 Vertical Specificity", "content": "Etypes are organized into classification hierarchies such that the upper-layer etypes represent more abstract or more general concepts, whereas the lower-layer etypes represent more concrete or more specific concepts [33,45]. Correspondingly, properties of upper-layer etypes are more general since they are used to describe general concepts, vice versa, properties of lower-layer etypes are more specific since they are used to describe specific concepts. We assume that lower-layer properties will contribute more to the identification of an etype since they are more specific. For instance, in Figure 1, as a lower-layer etype, Artist can be identified by the property academy award but not by the property name. Based on this intuition, we propose VS for capturing the vertical specificity, as follows:\n\\(VSKG(E,p) = WE(P) * \\frac{min layer(E)}{E \\in K_p}\\)"}, {"title": "4.3 Informational Specificity", "content": "Horizontal specificity allows measuring the shareability of properties, which is independent and does not change (increase/decrease) with the number of entities populating it. We take into account this fact by introducing the notion of informational specificity IS. The intuition is that IS will decrease when the entity counting increases. Thus, for instance, the IS of gold medalist decreases when there are increasing entities of athletes, as from the schema in Figure 2. Clearly, IS, differently from HS, can be used in the presence of entities. The definition of informational specificity is inspired by Kullback-Leibler divergence theory [54], which is introduced to measure the difference between two sample distributions Y and \u00dd. More specifically, given a known sample distribution Y, assume that a new coming attribute x changes Y to Y. Then, the Kullback-Leibler divergence theory demonstrates that the importance of x for defining Y is positively related to the difference between Y and Y. In the definition of informational specificity, we need to exploit some notions from information theory, where we apply informational entropy H(K) as:\n\\(H(K) = - \\frac{F(Ei)}{F(K)}  \\Sigma{F(E_i)}{log \\frac{F(Ei)}{F(K)}}\\)\nwhere K refers to any subset of K in a KG and |K| is the number of etypes included;\nH(\u00b7) represents the informational entropy of an etype set; Ei is a specific etype in set\nKu, thus Kv \u2265 1; F(E\u00bf) refers to the number of samples of etype Ei, and F(K)\nrefers to the number of all samples in K. Need to notice when we calculate the informational entropy for KGs without entities, F(E\u2081) = 1 since each KG includes one etype sample. For KGs with entities, F(E\u2081) and F(K) depend on the number of samples of the given etype and the subset of KG. After obtaining informational entropy, the"}, {"title": "4.4 Similarity Metrics", "content": "We have modeled the specificity of properties, which represent their weights for describing KGs from different measuring aspects. Then, we define three similarity metrics based on the corresponding specificity to measure the property overlapping between two concepts. Given two KGs, the reference KG A and candidate KG B, we define a function for calculating different similarities between etypes/entities from A and B based on their corresponding specificity:\n\\(Sim(Ea, Eb) = \\frac{1}{2} \\Sigma^k_{i=1} \\frac{\\frac{( SPC^A(Ea,Pi) + SPC^B(Eb, Pi))}{|prop(Ea)|}{|prop(Eb)|}}\\)"}, {"title": "5 The Proposed Method", "content": "In order to extend the reference KG by given candidate KGs, we propose a framework that exploits the FCA formalization and property-based similarity metrics defined above. The framework mainly consists of six modules, namely: KG parser, KG formalization module, property matcher, similarity calculation module, etype matcher, and KG extension module. Notice that modules are marked in different colors for distinguishing their usage."}, {"title": "5.1 Similarity Calculation Algorithm", "content": "The property-based similarity calculation is one of the critical parts of this work. We detail the calculation as SimilarityCalculation(\u00b7), as shown in Algorithm 1. After formalizing reference KGref and candidate KGcand, we assume that the two FCA contexts fa and fo are generated correspondingly. Then we obtain property matching pairs PM from the property matcher. To calculate the similarity of etypes, we need to generate candidate etypes pairs EM for further processing. For each candidate pair in EM, we check their correlated properties and update the specificity values to S\u0456\u0442\u043d, Simy and Sim\u2081, when their properties are aligned. After traversing all the candidate pairs, we obtain a complete etype similarity list L which will be used for training the ML model and aligning candidate etypes. Notice that we present the algorithm for calculating the horizontal similarity S\u0456\u0442\u0126 in algorithm 1, the metrics vertical similarity Simv and informational similarity Sim, will be calculated by the same algorithm where the only modification is to change HSKG(\u00b7) to V SKG(\u00b7) and ISKG(\u00b7), respectively."}, {"title": "5.2 Knowledge Graph Extension Algorithm", "content": "With the help of etype alignment results, we extend the reference KG by integrating the entities from the candidate KG KGcand, details are shown in Algorithm 2. For each etype Es that is aligned with etype Ea from KGcand, we directly add its properties and entities into Ea by addProperty(\u00b7) and addEntities(\u00b7), respectively. We also consider all subclasses of the aligned etype Et since the subclass inherit the properties of the etype and will bring new entities. If the subclass Esub of Et is not aligned with any other etypes in KGref, Esub and its associated properties and entities will be merged into Ea. Thus, we integrate candidate entities with KGref when their etypes are able to align with KGref. Then, the proposed property-based similarity metrics are applied to align the rest of the candidate entities with etype Eref from reference KG, namely function EtypeRecognizer(\u00b7). If we successfully match an etype En with the entity Enti, Enti will be merged into En, if not, Enti will be discarded. Need to notice that depending on the real-world application scenario and topic, the KG engineer will decide if it is needed to integrate the not aligned etypes with their correpsonding entities into KGref. Finally, all changes will be updated to KGref and we will obtain an extended KG KGext as the final result of our method."}, {"title": "5.3 Machine Learning-based Matchers", "content": "According to the Algorithm 2 and Figure 3, we can find there are three ML-based matchers in our proposed framework. Here we present more details of training and setting these matchers.\nEtype Matcher We develop an ML-based method that deals with etype matching as a binary classification task. The main idea is to predict if two incoming etypes are aligned with each other. For applying this method, a list of candidate pairs are generated by pairing etypes from KGcand and KGref. We will record candidate etype pairs EMali when the result of classification is \u201caligned\u201d. The proposed property-based similarity metrics SimH, Simy and Sim, are introduced to train the ML models for matching etypes. For better performance, we also exploit label-based and language-based similarity metrics, along with property-based similarity metrics for training the etype matcher.\nEtype Recognizer The strategy for developing an etype recognizer is very similar to the etype matcher, where we predict if candidate entities are aligned with target etypes. Thus, we will also generate candidate pairs that consist of entities from KGcand and etypes from KGref. Etypes from KGref will be outputted as the final recognition results. Compared to the etype matcher, the main difference is that the etype recognizer mainly uses property-based similarity metrics as features for model training since the lexical labels are not applicable to match entities and etypes. Thus, property-based similarity metrics SimH, Simy, and Sim\u2081 are applied for the etype recognizer.\nProperty Matcher The property matcher aims to align properties between KGs, where label-based and language-based similarity metrics are used for modeling training. The matching strategy is same as etype matcher. It is critical to obtain a powerful property matcher since both etype matcher and etype recognizer are based on the result of property matcher. In this section, we discuss the following solutions to reduce the effect of misaligned properties.\nUse of the formalization parameter WE(p). As we introduced in section 2, besides \"associated\" (positive) and \u201cunassociated\u201d (negative) properties, we also defined \"undefined\" properties (neutral). Since misaligned properties will not be used for similarity calculation, they are treated as \"undefined\" properties which will not affect the model training and reduce the additional interference. However, additional interference from misaligned properties appears if \u201cunassociated\u201d and \u201cundefined\u201d properties are not distinguished.\nUse of similarity metrics. Similar to lexical-based similarity metrics, our property-based similarity metrics also allow to match etypes by soft aligning, even if there are few properties not aligned. This will increase the robustness of our etype recognition approach."}, {"title": "6 Evaluation", "content": "In this section, we aim to evaluate our proposed method by two crucial steps during KG integration, including (1) etype alignment, and (2) etype recognition of entities. Thus, we organize this section as follows. Section 6.1 introduces the experimental setups, including the datasets we used, feature selection, and evaluation strategy. Sections 6.2 and 6.3 present the analysis and quantitative evaluation results, respectively. In section 6.4, we also demonstrate the ablation study to explain the setting of parameters."}, {"title": "6.1 Experimental Setup", "content": "Dataset Selection. For evaluating the result of etype alignment, we exploit the Ontology Alignment Evaluation Initiative (OAEI) as the main reference for the selection of the etype recognition problems. As of today, this in fact the major source of KG alignment problems. Our proposed method for KG extension involves extending a reference KG through one or more candidate KGs. This implies that the reference KG typically possesses a more comprehensive and high-quality schema, serving as a foundation for KG extension. Our approach focuses on KGs that incorporate etypes associated with a substantial number of properties and complete schemas. As a result, we have selected the following cases: the bibliographic ontology dataset (BiblioTrack) [20] and conference track (ConfTrack) [59] (ra110 version). From the bibliographic ontology dataset, we select #101-103 and series #301-304, which present real-life ontologies for bibliographic references from the web. We select the alignment between #101 and #304 as the training set for training our ML-based etype matcher, and the rest of the ontology alignments as the testing set. The conference track contains 16 ontologies, dealing with conference organizations, and 21 reference alignments. We set all 21 reference alignments from the conference track as the testing set to validate our etype matcher. Notice that we select the training and testing set from different datasets since we aim to prove the adaptation of our approach, which also prevents our approach from overfitting.\nFor validating the algorithm of etype recognition, we build a dataset called EnType, since there is no publicly released dataset for such etype recognition task between two KGs. We exploit DBpedia infobox dataset\u00b9\u00b9 as the reference KG for providing reference etypes. Because DBpedia is a general-purpose KG that contains common etypes in the real world, where sufficient properties are applied for describing these etypes. Then we select candidate entities from DBpedia, SUMO and several domain-specific datasets [53]. The entities we selected mainly according to common etypes, more specifically,"}, {"title": "6.2 Etype Alignment", "content": "Qualitative analysis. Table 2 provides representative examples to show the etype similarity metrics of candidate etype-etype pairs from cmt-confof (former four rows) and cmt-conference (latter four rows) in ConfTrack. Value box \"Match\" demonstrates if two etypes are referring to the same concept, where \u00d7 refers to a positive answer. We find that the value of our property-based similarity metrics indeed capture the contextual similarity between relevant etypes, where aligned etypes output higher values (e.g., paper-contribution), in turn, non-aligned etypes return lower values (e.g., person-document). With a broad observation of the metric values, we consider the property-based similarity metrics SimH, Simy and Sim, are valid for etype-etype pairs.\nQuantitative Evaluation. We apply two ML models to evaluate the validity of our proposed similar metrics on the etype alignment task, including XGBoost [16] and artificial"}, {"title": "6.3 Etype Recognition of Entities", "content": "Qualitative Analysis Table 4 presents some examples of similarity metrics between reference etypes and candidate entities from the dataset EnType. Similar to Table 2, the value box \"Match\" with \u00d7 refers to that the candidate entity is classified as the reference etype. Similar to what happened in candidate etype pairs, we find the similarity metrics of aligned candidate pairs return much higher values than unaligned pairs. Thus, we conclude the proposed similarity metrics are also valid for measuring etype-entity pairs.\nQuantitative Evaluation As for the evaluation of the etype recognizer, we involve two subsets EnTypeself and EnTypeGen in this experiment. The subset EnType Self contains candidate entities and reference etypes from the same KG, i.e., self recognition, which should be a relatively easier task. In turn, general recognition denotes the recognition on subset EnTypeGen, where candidate entities are selected from other resources. Table 5 shows the results of etype recognition (F\u2081-measure), where we exploit the same models as in the etype alignment task, i.e., ETRXGBoost and ETRANN. Two state-of-the-art methods [30,49] are also included in the experiment. Firstly, we can find that our methods ETR using the proposed property-based similarity metrics surpass two state-of-the-art methods significantly. For the self recognition group, ETRXGBoost performs better in two cases while ETRANN also achieves competitive results. For general recognition cases, the XGBoost-based ETR method keeps its stable performance and surpasses all comparing methods. We achieve promising results in both cases, which prove the validity of our similarity metrics and the etype recognition approach. Meanwhile, we find that the precision of the general recognition case is lower than that of self recognition, which follows the difficulty of the two cases.\nConsidering that etype recognition performance is affected by entity resolutions, we apply an additional experiment for aligning entities with more specific etypes. We select four sub-classes of etype person and organization and their corresponding entities as candidate pairs, respectively. We keep comparing ETRXGBoost, ETRANN and the same state-of-the-art methods in this experiment. Table 6 presents the F\u2081-measure of the recognition results. We can find our methods still achieve better recognition performance than other methods in each case. Both two models obtain promising overall performance on specific etype recognition, where ETRANN performs better on Comedian and Company, and ETRXGBoost leads the rest of the cases. The experimental results show that our metrics and approach can also be applied for specific instance-level etype recognition, which further supports the performance of KG extension algorithm."}, {"title": "6.4 Ablation Study", "content": "We demonstrate ablation studies in this section for validating the effectiveness of some specific components introduced in our KG extension framework.\nEffect of similarity metrics The first ablation study is to evaluate if each of the proposed property-based similarity metrics is effective. In this experiment, we test the backbones14 (B) which were used in the etype alignment and recognition tasks, respectively. Based on the backbones, we also design a controlled group that includes models trained without one of the property-based similarity metrics (i.e. B-Simy, B-SimH and B-Sim\u2081) and models trained without all metrics (i.e. B-L). If the backbones perform better than the corresponding models in the controlled group, we can quantitatively conclude that each of the property-based similarity metrics (Simy, SimH, Sim\u2081) contributes to the etype alignment and recognition tasks. Table 7 demonstrates the F1-measure of each group. We apply ConfTrack for etype alignment and EnTypeGen for etype recognition. Note that we select two models for both cases as Table 7 shows.\nWe find that backbones perform better than models in the controlled group, especially for models trained without all metrics. Thus, we consider all property-based similarity metrics contribute to better recognition performance. Particularly, Simy and SimH significantly affect the performance of etype alignment cases, and Sim, affects etype recognition cases more."}, {"title": "7 Case Study", "content": "This section aims to qualitatively analyze the KG extension performance of our proposed method by use cases. In the case of KG extension, we assume that there will be a reference KG extended based on one or more candidate KGs. We aim to simulate a real-world scenario, where people extend the general purpose KG by specific-domain KGs to enlarge its usability. We select the widely applied schema.org as the reference KG. For the candidate KGs, we introduce two specific-domain KGs Transportation15 and educationtrentino16. These two KGs are created for presenting local transportation and education, respectively. We selected these KGs because they provide very different examples in terms of the number of properties and etypes. Moreover, almost all their etypes labels are human understandable, which helps qualitative analysis.\nWe introduce four ranking metrics in the case study, namely Class Match Measure (CMM) [1], Density Measure (DEM) [1], Focus [26] and TF-IDF [46]. CMM aims to evaluate the coverage of a KG for the given search etypes, by looking for etypes in each KG that have labels matching a search term either exactly or partially. DEM is intended to approximate the representational density or information content of etypes and consequently the level of knowledge detail, considering etypes including the number of subclasses, the number of properties associated with that etype, the number of siblings, etc. Focus aims to evaluate KG by identifying informative etypes with higher categorization relevance, by using the properties associated with the target etypes. TF-IDF is also widely used for KG ranking by calculating relevance between potential KG with a specific term that describes the domain of interest. These metrics are used to evaluate the quality of the extended reference KG, where we compare the metrics on the original reference KG with the extended reference KG to see if the new-coming items from candidate KGs affect the quality of the reference KG. More specifically, we record the metrics for valid etypes in KG, and use the performance of these scores as a baseline, by selecting their scores for the top 15 etypes. The relevance of our approach is then measured in terms of accuracy (from 0 to 1) by checking how many etypes of ranking results are in the eypes ranking lists provided by the knowledge engineers. The output of this experiment is represented in Fig. 4.\nThe main observation is that our extended KG shows promising performance with all metrics. More specifically, with the given terms chosen by knowledge engineers, we can find the extended KG shows great categorization relevance by metric Focus. The scores of CMM and DEM also show promising scores, respectively, which demonstrates the quality of the knowledge coverage and the representational density. Our KG gains a fair score on metric TF-IDF since the reference schema.org is a general-purpose KG that contains pretty diverse concepts, which will affect the relevance with specific domain corpus to some extent. The second observation presents that the extended KG performs better than the original KG on most of the metrics. The increasing score of metric CMM presents that the new-coming items enlarge the coverage of the etypes in the KG. The improving DEM score shows the details of etypes from reference KG have been enhanced by the extended properties and subclasses. The increasing Focus score also presents a trend where categories can be better identified from a taxonomy perspective. Notice that the extended schema.org has even more diverse concepts after KG extension, which becomes a possible reason for the slight decrease in TF-IDF score. Overall, the experimental results in the case study demonstrate the ability of our method for KG alignment and extension."}, {"title": "8 Related Work", "content": "Ontology matching and schema alignment are attractive research topics in recent decades. In the early phases of the research, researchers mainly focused on string-based methods. String analysis techniques were defined including 1) string-based metrics (N-gram, Levenshtein, etc.), 2) syntactic operations (lemmatization, stop word removal, etc.) and 3) semantic analysis (synonyms, antonyms, etc.) [14]. Sun et al, [52] review a wide range of string similarity metrics and propose the ontology alignment method by selecting similarity metrics in different scales. Although string-based methods can lead to effective performance in many cases, selecting the right metric for matching specific datasets is the most challenging part. To solve this issue, an ensemble matching strategy is introduced in some studies [12,38], which apply multiple matchers based on different string-based metrics. The principle of these works is that the combined matchers are more powerful than individual ones. The structure of a KG has also been considered as important information for identifying etypes [5, 28]. Such studies suppose that two etypes are more likely to be aligned if they have the same super-class or sub-class. The LogMap system [35] uses a two-step matching strategy, that is, matches two etypes Ea and Eb by a lexical matcher, and then considers the etypes that are semantically close to Ea are more likely to be semantically close to Eb. AML [24] introduces an ontology matching system that consists of a string-based matcher and a structure-based matcher, building internal correspondences by exploiting is-a and part-of relationships.\nMachine learning techniques have been widely applied to this topic. Some studies model the etype matching task as a binary classification task, trying to encode the information like string and structure similarities as features for model training. Amrouch et al, [3] develop a decision tree model by exploiting lexical and semantic similarities of the etype labels to match schemas. By encoding the lexical similarity of the superclass and subclass as structure similarity, Bulygin and Stupnikov [13] improve the former method and achieve promising results. At the same time, formal concept analysis (FCA) lattices are applied in schema matching methods [15,51]. To refine the health records searching outputs, Cure et al, [18] exploit FCA and Semantic Query Expansion to assist the end-user in defining their queries and in refining the expanded search space. Stumme et al, [51] propose a bottom-up ontology merging approach by using FCA lattices to keep the ontology hierarchy."}, {"title": "8.2 Entity Type Recognition", "content": "According"}]}