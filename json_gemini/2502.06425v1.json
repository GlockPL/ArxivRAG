{"title": "Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs", "authors": ["Hiroki Watanabe", "Motonobu Uchikoshi"], "abstract": "Large language models (LLMs) are increasingly utilized in domains such as finance, healthcare, and interpersonal relationships to provide advice tailored to user traits and contexts. However, this personalization often relies on sensitive data, raising critical privacy concerns and necessitating data minimization. To address these challenges, we propose a framework that integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with LLM-based chatbots. This integration enables privacy-preserving data sharing by verifying user traits without disclosing sensitive information. Our research introduces both an architecture and a prompting strategy for this approach. Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility in real-world scenarios.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) are increasingly providing advice through chatbots in fields such as finance, healthcare, and interpersonal relationships. As LLM-generated advice shapes decision-making, incorporating user characteristics and contexts is crucial for enhancing its effectiveness [1, 4, 11].\nHowever, tailoring advice to individual circumstances raises significant privacy concerns. For example, financial advice may require sensitive information like income and assets, while medical advice necessitates personal details such as age and medical history to ensure accuracy. Many chatbot platforms outline privacy policies that detail data collection and usage, allowing users to opt out or request data deletion. Despite this, platforms often collect more data than necessary, underscoring the importance of the data minimization principle. This principle is emphasized in the European General Data Protection Regulation (GDPR) and reflected in the proposed American Data Privacy and Protection Act (ADPPA), currently under legislative review.\nOne promising technology for achieving data minimization is zero-knowledge proofs (ZKP), which have seen significant advancements in the blockchain field. ZKP frameworks, such as zk-SNARKS, efficiently prove the correctness of program execution as part of verifiable computation, without revealing sensitive data [10]. This technology is particularly useful in blockchain applications, where repeated transaction verification is necessary, but its potential is not limited to that domain. For instance, it can enable the provision of verifiable user characteristics and circumstances to LLM platforms without disclosing detailed personal information.\nDespite the promise of this technology, research on its application in LLM-based chatbots remains limited. One prior study by Cai et al. [3] explored the use of ZKP in healthcare chatbots. Its application, however, was restricted to relatively few data points and relied on basic logic, such as verifying if a value satisfied a range proof. This highlights the limited flexibility of current zk-frameworks like zk-SNARKs. Recent advancements, such as zkVM, are expected to address these limitations for practical ZKP applications. Yet, evaluations of zkVM's capabilities and performance remain limited, leaving its potential for real-world implementation largely unexplored. Moreover, effectively using verifiable user traits generated through ZKP for advice generation using LLMs remains a research challenge.\nThe goal of this research is to develop a new framework for LLM-based chatbots that delivers more personalized and appropriate advice while protecting user privacy through the use of zero-knowledge proof technology. To achieve this, we address the following research questions:\n\u2022 To the best of our knowledge, this study is the first to explore the potential of combining a modern ZKP framework, zkVM, with an LLM-based advisor for privacy-preserving applications.\n\u2022 We propose an architecture and a prompting strategy that integrate zkVM and LLMs, enabling secure verification of user traits without disclosure and facilitating consistent, privacy-preserving advice generation.\n\u2022 Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility."}, {"title": "2 Zero-Knowledge Proofs", "content": "Zero-Knowledge Proofs (ZKP) are cryptographic techniques that enable one to prove possession of specific information without revealing the information itself [10]. In recent years, ZKPs have rapidly evolved, particularly with the development of practical zk-SNARKS (Succinct Non-Interactive Arguments of Knowledge) [5, 7], which have been widely adopted in the blockchain domain for applications such as protecting transaction privacy in cryptocurrencies and compressing data using rollup techniques. This technology is expected to be applied across various fields beyond blockchain due to its ability to verify computations efficiently and privately, holding significant potential for broader adoption."}, {"title": "2.1 Related Work: Combining LLMs and ZKPs", "content": "Efforts to combine LLMs with ZKP technology are in their early stages. zkLLM [9] aims to enable verification of the entire inference process of an LLM using ZKP. In this framework, the model owner commits to their model parameters, and the commitment is used to prove that the inference process has been executed correctly using those parameters. Meanwhile, HuRef [12] focuses on copyright protection for LLMs by proposing \"human-readable fingerprints\" to identify LLMs. ZKP is used to demonstrate that the claimed LLM parameters were used to generate the fingerprints accurately. While zkLLM and HuRef primarily focus on model verification using ZKP technology, Singh's study [8] explores potential applications related to the data input to LLMs, such as user authentication, prompt analysis, source data verification, and source data relevance filtering. In this context, our use case specifically emphasizes the protection of user-provided data. A related example is presented by Cai et al. [3], who demonstrated a chatbot in the healthcare domain using ZKP to protect sensitive user information. However, their ZKP application was limited to four data points-age, height, weight, and medical history-and relied on a simple implementation, such as range proof verification, resulting in a relatively small-scale application. Additionally, the design of prompts to effectively utilize ZKP-generated outputs within LLM chatbots remains an unexplored area. This field is evolving rapidly and highlights a promising direction for privacy-focused LLM applications. However, further advancements require more practical implementations and detailed evaluations tailored to specific and complex use cases."}, {"title": "3 Architecture and Methodology", "content": "The architecture we propose is operated by two independent entities, as shown in Figure 1. Entity 1 can be assumed to be an institution that holds user data, such as a financial institution or a healthcare provider. Entity 2, on the other hand, is envisioned as a cloud-based service that utilizes LLMs to provide advice to users. These two entities operate independently, and the sharing of personal data between them is restricted. (i) The user requests Entity 1 to infer abstracted user traits based on their specific profile, (ii) receiving the results along with a zero-knowledge proof. The proof and user traits are then (iii) provided to Entity 2 alongside a query, and (iv) the user receives feedback from an LLM-based advisor system or agent.\nA key feature of this architecture is that the output from Entity 1 contains both the inferred user traits and the proof verifying those traits. Entity 2 can verify the proof to ensure that the user traits were computed according to a predefined algorithm."}, {"title": "3.1 Introduction of zkVM", "content": "In previous studies [3, 8], the approach of constructing arithmetic circuits from programs designed for ZKPs and transforming them into polynomials for proof generation was adopted, based on the zk-SNARKs. While this method offers advantages in terms of proof size and proof generation time, it presents challenges in requiring code optimized for arithmetic circuits. Additionally, developers must use domain-specific languages (DSLs) or specialized libraries, leading to high learning costs. Furthermore, when implementing complex algorithms, developers often seek to leverage existing software libraries and packages commonly utilized in high-level programming languages; however, the necessity to optimize code for arithmetic circuits frequently constrains their ability to do so.\nTo address these challenges, our study adopts zkVM (Virtual Machine), a modern zero-knowledge proof architecture. zkVM enables the execution of entire programs as zero-knowledge proofs, characterized by its flexibility and versatility. Specifically, instead of directly converting the program into arithmetic circuits, zkVM executes the program and proves the consistency of its execution trace (such as memory and register state transitions). This approach allows for quick verification that a program executed on zkVM produces the same output given the same input, without needing to rerun the program. Additionally, zkVM leverages zero-knowledge properties, enabling some parts of the input to remain private. One of zkVM's main advantages is that it can utilize existing programs with minimal modification, allowing developers to integrate zero-knowledge proof technology using familiar high-level languages and libraries. This significantly reduces the learning curve compared to traditional zk-SNARK architectures that require extensive optimization for arithmetic circuits and often necessitate the use of domain-specific languages or specialized libraries.\nTo utilize zkVMs in our research, we investigated several popular zkVM projects, as shown in Table 1. Our selection criteria focus on implementations that do not rely on blockchain or smart contracts and can run in a local environment. While numerous zkVM projects exist, considering factors such as support for familiar high-level languages, package imports, and input privacy, RiscZero[2] and SP1[6] emerge as practical options at this time."}, {"title": "3.2 Prompt Strategy", "content": "With the introduction of the zkVM, we can query the LLM advisor with user traits and proofs, as shown in Figure 1. We propose the following prompting strategy.\nLet $L$ represent text containing user traits, partitioned into $D = \\{d_0, d_1\\}$. Here, $d_0$ denotes unverifiable exploratory traits, and $d_1$ represents traits verifiable through zero-knowledge proof (ZKP) schemes, which have higher proof reliability. Verifiable traits $d_1$ are supported by objective evidence or logical constraints, enabling efficient validation using ZKP technology. Based on this partition, we define a context set $C = \\{c_0, c_1, ..., c_n\\}$, where each $c_i \\in C$ is generated by varying the emphasis on $d_0$ and $d_1$.\nFor a user query $Q$, the LLM generates a response divided into two parts: a proposed answer $A_{prop}$ and an explanation $A_{exp}$. Each part is generated using distinct instructions and their respective contexts, $C_{prop}$ and $c_{exp}$. These contexts may either be same or tailored to address different aspects of the query and are selected from the context set $C$. The responses are computed as follows:\n$A_{prop} = LLM(Q, I_{prop}, C_{prop})$, $A_{exp} = LLM(Q, A_{prop}, I_{exp}, C_{exp})$.\nThe objective of this strategy is to create personalized and consistent responses by leveraging both unverifiable and verifiable user traits."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Evaluation of zkVM", "content": "The evaluation of the zkVM focuses on measuring the proof generation and verification times of the created ZKP application to assess its feasibility. While existing benchmarks [13] primarily emphasize basic cryptographic operations, our study shifts the focus to real-world applications, such as user categorization logic designed to infer user traits."}, {"title": "4.1.1 Application", "content": "One of the central questions of this study is whether real-world inference applications can be replicated as ZKP applications. As a first step, we chose to focus on rule-based inference applications, specifically a web application published by the Japanese Bankers Association\u00b9. This application categorizes users into one of four risk tolerance categories based on their responses to 10 financial questions (e.g., whether they have a mortgage or a retirement plan), which are used to infer user traits. Each question offers three response options, and the application uses rule-based categorization logic to classify users into the following categories: (i) Conservative, (ii) Steady Growth, (iii) Balanced, or (iv) Aggressive Investment."}, {"title": "4.1.2 Benchmark", "content": "Table 2 summarizes the benchmark results for the zkVM frameworks RiscZero (v1.1.2) and SP1 (v3.4.0) when executing the ZKP application. Zero-knowledge proof generation is known to incur significantly greater overhead compared to verification, and in our inference application, CPU-based proof generation required tens of seconds. On the other hand, real-time applications such as LLM-based chatbots prioritize immediacy, making verification time a more critical factor. The benchmark results indicate that this requirement is effectively met. Furthermore, RiscZero's substantial performance improvements in proof generation through GPU utilization highlight its potential to enhance usability for user-driven proof requests."}, {"title": "4.2 Evaluation of Prompt Strategy", "content": "The proposed prompt strategy (described in Section 3.2) aims to generate diverse response variations by emphasizing either unverifiable user traits ($d_0$) or verifiable user traits ($d_1$). This evaluation addresses two key questions: (1) Can the strategy select proposed actions ($A_{prop}$) aligned with the emphasized traits? and (2) Can the strategy generate consistent explanations ($A_{exp}$) for the selected proposals?"}, {"title": "4.2.1 Task and Dataset", "content": "This task involves querying a domain-specific LLM advisor with the question, \"What action should the user take?\" The LLM advisor utilizes GPT-4o, accessed via OpenAI"}, {"title": "4.2.2 Analysis of Aprop Results", "content": "Figure 2 depicts the distribution of $A_{prop}$ scores across contexts. Both models exhibited similar tendencies as follows: The baseline (co) skews slightly positive, indicating an inherent LLM bias. c\u2081 (emphasizing $d_0$) shifts the responses negatively, while c2 (emphasizing $d_1$) skews them positively. c3 (applying weak emphasis on $d_1$) results in a moderate positive shift. These findings confirm that adjusting the emphasis on $d_0$ and $d_1$ consistently impacts $A_{prop}$."}, {"title": "4.2.3 Analysis of Aexp Results", "content": "Table 4 presents a comparative analysis of Aexp across different contexts ($c_i$), with performance metrics calculated as the average cosine similarity over all trials. Regarding Similarity($A_{exp}$, $A_{prop}$), GPT-4o generally exhibits high similarity values and thus tends to produce explanations consistent with the given proposals. Although Llama-3.1 405B is slightly inferior to GPT-4o in this regard, from Cond0 through Cond3 it shows similar trends in how Similarity($A_{exp}$, $d_0$) and Similarity($A_{exp}$, $d_1$) change. For example, in Cond2 ($C_{prop} = C_{exp} = c_2$), both models have Similarity($A_{exp}$, $d_1$) surpassing Similarity($A_{exp}$, $d_0$), which can be explained by the fact that c2 is a context emphasizing $d_1$.\nInterestingly, the tendencies diverge between the models in Cond4. In Cond4 ($C_{prop} = C_3, C_{exp} = c_1$), contradictory contexts (C3, C1) are given to the prompt generating both the proposal and the explanation. Under these conditions, for Similarity($A_{exp}$, $A_{prop}$), GPT-4o's similarity decreases compared to the baseline (Cond0), whereas Llama-3.1's similarity increases. In Cond4, we introduce a multi-step reasoning process in order to apply contradictory contexts, which may lead to differing behaviors depending on the model. This indicates that further research is required."}, {"title": "5 Conclusion", "content": "This study explored privacy preservation in LLM advisors using zero-knowledge proof (ZKP) technologies, particularly zkVMs. Specifically, we demonstrated that zkVMs like RiscZero can transform existing rule-based inference logic into zero-knowledge applications, enabling proof generation and verification within practical timeframes. Furthermore, we introduced a method that uses ZKP to categorize user traits into verifiable segments and validated that the proposed prompt strategies enable LLM advisors to generate consistent proposals and explanations. Future work will explore how users perceive and accept advice generated by these methods."}]}