{"title": "PROTOLENS: ADVANCING PROTOTYPE LEARNING FOR\nFINE-GRAINED INTERPRETABILITY IN TEXT CLASSIFICATION", "authors": ["Bowen Wei", "Ziwei Zhu"], "abstract": "Deep neural networks have achieved remarkable performance in various text-based tasks but often lack\ninterpretability, making them less suitable for applications where transparency is critical. To address\nthis, we propose ProtoLens, a novel prototype-based model that provides fine-grained, sub-sentence\nlevel interpretability for text classification. ProtoLens uses a Prototype-aware Span Extraction module\nto identify relevant text spans associated with learned prototypes and a Prototype Alignment mecha-\nnism to ensure prototypes are semantically meaningful throughout training. By aligning the prototype\nembeddings with human-understandable examples, ProtoLens provides interpretable predictions\nwhile maintaining competitive accuracy. Extensive experiments demonstrate that ProtoLens outper-\nforms both prototype-based and non-interpretable baselines on multiple text classification benchmarks.\nCode and data are available at https://anonymous.4open.science/r/ProtoLens-CEOB/.", "sections": [{"title": "1 Introduction", "content": "Deep neural networks (DNNs) have achieved remarkable success in various natural language processing tasks, including\ntext classification [Kowsari et al., 2019], sentiment analysis [Medhat et al., 2014], and question answering [Allam and\nHaggag, 2012]. However, their black-box nature presents significant challenges for interpretability, limiting their use in\nhigh-stakes applications where transparency, user trust, and accountability are paramount [Castelvecchi, 2016, Rudin,\n2019]. While post-hoc explanation methods attempt to address this [Jacovi et al., 2018, Mishra et al., 2017], they often\nlack faithfulness and consistency in explaining predictions [Rudin, 2019]. In contrast, inherently interpretable models\nguarantee transparency, facilitating understanding and trust in model outputs [Molnar, 2020].\nAmong various approaches aimed at enhancing model interpretability, prototype-based methods have emerged as a\nprominent line of research. It enables models to generate predictions by comparing inputs to prototypical examples,\nsimilar to human reasoning that relies on analogies to familiar cases Dong and Xing [2018], Hong et al. [2023], Zhang\net al. [2023], Ming et al. [2019a], Gautam et al. [2022], Ming et al. [2019b], Rajagopal et al. [2021], Sourati et al.\n[2023]. Such prototype-based models provide an intuitive form of interpretability, facilitating an understanding of\nmodel predictions through direct reference to interpretable examples. For instance, in a movie review classification task,\na prototype might represent a review like \"This movie was amazing, with stunning visuals and a gripping storyline\",\nwhich the model would use to classify new reviews with similar sentiments. The model can explain its classification of\na new review by showing how closely it matches this prototypical example.\nDespite the potential of prototype-based models for enhancing interpretability, existing approaches encounter significant\nlimitations in text-based applications [Hong et al., 2023, Ming et al., 2019a]. Typically, these models define prototypes\nat the instance/sentence level, which often lacks the granularity needed for fine interpretability in complex or lengthy\ntexts. For example, in a movie review like \"The visuals were stunning, but the plot was too predictable\", a sentence-level\nprototype might only capture the general sentiment of the review, missing the nuance that the visuals were positive,\nwhile the plot had negative aspects. This coarse granularity makes it challenging to provide insightful explanations when\ndifferent sentiments or nuances coexist within a single text. In contrast, more fine-grained prototype modeling, such"}, {"title": "2 Related Work", "content": "Post-hoc Explanations. Several post-hoc methods interpret DNN models by analyzing gradients or neuron activations,\nsuch as Integrated Gradients [Sayres et al., 2019, Qi et al., 2019], DeepLift [Li et al., 2021], and NeuroX [Nalls et al.,\n2015]. Tsang et al. [2018] proposed a hierarchical method to capture interaction effects, later adapted by Jin et al. [2019]\nfor text classification. In sentiment analysis, contextual decomposition [Murdoch et al., 2018] identifies sentiment\nwords and their contributions. Attention-based models, such as Bahdanau [2014], Rockt\u00e4schel et al. [2015], analyze\nattention weights, though Jain and Wallace [2019] question their explanatory power.\nPrototype-based Deep Neural Networks. Prototype-based deep neural networks enhance interpretability by using\nprototypes as intuitive references for decision-making, a concept with roots in traditional models [S\u00f8rgaard, 1991, Fikes\nand Kehler, 1985, Kim et al., 2014]. ProtoPNet [Chen et al., 2019] pioneered the integration of prototypical reasoning\ninto deep learning for image classification, while ProtoVAE [Gautam et al., 2022] advanced this with a variational\nautoencoder for diverse, interpretable prototypes. In text classification, ProSeNet [Ming et al., 2019a] introduced\nprototype-based reasoning, later extended by ProtoAttend [Arik and Pfister, 2020] with attention mechanisms for\ndynamic prototype selection. ProtoryNet [Hong et al., 2023] further evolved the field by modeling prototype trajectories\nfor improved interpretability across multiple domains."}, {"title": "3 Method", "content": "To deliver inherently interpretable predictions at a fine-grained level, we introduce ProtoLens, a prototype-based\ninterpretable neural network. ProtoLens is designed to overcome two primary challenges: (C1) How to effectively\nextract text spans associated with a given prototype to provide interpretable predictions? and (C2) How to ensure learned\nprototypes are semantically reasonable and effective for interpretation? To address C1, we propose a Prototy-Aware\nSpan Extraction module, which extracts most relevant text spans for prototypes by a Dirichlet Process Gaussian Mixture\nModel. To address C2, we design a Prototype Alignment mechanism to adaptively align prototype embeddings to\nrepresentative data samples through training. The overall model architecture is illustrated in Figure 2.\nModel Structure. Given a corpus of textual data \\(D = \\{(x_i, y_i)\\}\\), where \\(i = 1, . . . , N\\), each instance \\(x_i\\) is associated\nwith a label \\(y_i \\in Y\\), our model processes the text through a text encoder, such as BERT, \\(r : X \\rightarrow R^d\\), where \\(X\\)\nrepresents the space of text inputs and \\(d\\) is determined by the encoder architecture."}, {"title": "3.1 Prototype-aware Span Extraction", "content": "Given a text instance \\(x_i\\), we divide it into parts \\(x_i = (c_t)_{t=1}^T\\) using a sliding window approach, where \\(c_t\\) denotes the\nt-th part and \\(T\\) is the total number of parts. Each part is an n-gram span, with n as a hyperparameter controlling the"}, {"title": "3.1.1 Similarity Approximation via GMM", "content": "Effectively capturing the most relevant text spans that align with a prototype is challenging due to the complex\npatterns and information in the text. We apply a Dirichlet Process Gaussian Mixture Model (DPGMM) [G\u00f6r\u00fcr and\nEdward Rasmussen, 2010, Rasmussen, 1999] to model similarity distributions using Gaussian components, with higher\nsimilarity values highlighting important regions.\nThe learned Gaussian parameters correspond to high-similarity regions, thereby facilitating the identification of key\nrelevant text parts. This enhances the model's capability to capture complex distributions and improves interpretability\nby emphasizing critical text regions.\nGiven \\(\u0160_k\\), DPGMM leverages this similarity vector to determine the number of Gaussian components dynamically,\nfocusing on the most relevant parts and effectively capturing intricate relationships. Each \\(\u0161k\\) is approximated using up\nto \\(M\\) Gaussian components:\n\\[\n\u00a7_k = \\sum_{m=1}^M \u03c0_m \u00b7 N(\u00a7_k | \u00b5_m, \u03c3_m),\n\\]\nwhere \\(\u03c0_m\\) denotes the mixture weight, and \\(N(\u0161 | \u03bc_m, \u03c3_m)\\) represents the Gaussian distribution parameterized by the\nmean \\(\u00b5_m\\) and the standard deviation \\(\u03c3_m\\).\nTo model each similarity distribution as a mixture of Gaussian components, we use a neural network that takes a hidden\nrepresentation \\(h\\) as input, which is derived from \\(\u0161\\) via a two-layer MLP:\n\\[\nh = MLP(\u0161k),\n\\]\nThis hidden representation \\(h\\) is then used to generate the parameters of the Gaussian mixture, including the mixture\nweights \\(\u03c0\\), means \\(\u00b5\\), and standard deviations \\(\u03c3\\), allowing the model to approximate the similarity distribution effectively.\nMeans (\u03bc) and Standard Deviations (\u03c3). The parameters of the Gaussian components are computed as follows:\n\\[\n\u03bc = sigmoid(W_\u00b5h + b_\u00b5) \u00d7 T,\n\\]\n\\[\n\u03c3 = exp(W_\u03c3h + b_\u03c3),\n\\]\nwhere \\(\u03bc\\) and \\(\u03c3\\) are the mean and standard deviation for each of the \\(M\\) Gaussian components.\nMixture Weights (\u03c0). \u03a4\u03bf dynamically determine the mixture weights, we employ the Stick-Breaking Process [Ren\net al., 2011], with the Dirichlet Process (DP) [Teh et al., 2010] implicitly implemented through the stick-breaking\nformulation. The DP provides a nonparametric Bayesian approach that allows the model to determine the appropriate\nnumber of components adaptively, which is crucial for handling data with unknown complexity.\nWe define a maximum number of Gaussian components, \\(M\\), which represents the potential number of components for\napproximating the similarity distribution. The mixture weights \\(\u03c0_m\\) for each component \\(m\\) are generated as follows:\n\\[\nv_m = sigmoid(W_vh + b_v),\n\\]\n\\[\n\u03c0_m = v_m \\prod_{l=1}^{m-1} (1 \u2013 v_l), m = 1, ..., \u041c,\n\\]\nHere, \\(v_m\\) is computed by applying a sigmoid function to a linear transformation of the hidden representation \\(h\\). The\nStick-Breaking Process ensures that the mixture weights \\(\u03c0_m\\) sum to one and adaptively determine the number of active\ncomponents, enabling the model to capture complex and potentially multi-modal distributions."}, {"title": "3.1.2 Span Extraction", "content": "The learned \\(\u03bc\\) can be viewed as an anchor point, representing the location with the highest probability density between\nthe text instance and its corresponding prototype, identifying the most similar unit of the text for that prototype. We next\nextract the span based on the anchor, thereby capturing prototype-specific information. To achieve this, we introduce\na span function, as illustrated in Figure 8. In this context, \\(\u03bc\\) represents the anchor point, while \\(o\\) defines the range\naround the anchor, indicating how far from the anchor the model should be captured. The variable \\(x\\) refers to the\nrelative distance to \\(\u03bc\\). This function allows the model to focus on a specific area around \\(\u03bc\\), with the spread of this focus\ndetermined by \\(\u03c3\\).\nThe span function is computed as:\n\\[\nm_{\u03bc,\u03c3}(x) = min(max(\\frac{1}{R}(R + \u03c3 - |\u03bc - x|), 0), 1)\n\\]\nwhere \\(\u03bc\\) is the anchor (the position with the highest similarity), \\(\u03c3\\) controls how far from \\(\u00b5\\) the model should be captured,\nand \\(R\\) is a hyperparameter that adjusts the smoothness of the span."}, {"title": "3.2 Prototype Alignment", "content": "A core requirement for delivering interpretable classifications that are understandable for humans is to make sure\nlearned prototypes are semantically meaningful. The learned prototypes are represented as numerical embeddings,\nwhich are not inherently interpretable by human users and require further interpretation.\nHence, guidance is needed to ensure these prototype embeddings are semantically meaningful. To this end, we propose\na prototype alignment mechanism that maps the prototypes to representative sentences from the training data throughout\nthe learning process.\nRepresentative Candidates. We begin by encoding all sentences in the training samples into embeddings. In the\nembedding space, we apply the k-means clustering to group the sentences based on their semantic similarity. The top\n50 sentences closest to each cluster center obtained from the k-means algorithm serve as representative examples of\neach cluster, making them suitable candidates for aligning prototypes.\nPrototype Alignment. In Figure 9, we depict the prototype alignment process in ProtoLens. At one epoch during\ntraining, for each prototype with its current learned embedding \\(p_k\\), the top 3 most similar candidate sentences (green\ncircles) from the representative candidates are selected. These candidates are averaged to form a representative\nembedding \\(c_k\\) (purple cross), which encapsulates the meaning from actual training data. The prototype is then updated\ntowards \\(c_k\\) (orange arrow), resulting in an updated prototype \\(p'\\) (yellow star).\nSpecifically, \\(p_k\\) is updated towards \\(c_k\\) controlled by a weight factor \\(wk\\):\n\\[\n\u03c9_\u03ba = sigmoid(\u03b3\u00b7 (d_k \u2013 \u03c4)),\n\\]\nwhere \\(d_k\\) represents the Euclidean distance between \\(p_k\\) and \\(c_k\\), \\(\u03c4\\) is the movement threshold and \\(y\\) controls the\nsmoothness of the transition."}, {"title": "3.3 Learning Objectives", "content": "The learning objectives of the proposed model consist of three key components that contribute to both prediction\naccuracy and the interpretability of the learned representations."}, {"title": "3.3.1 GMM Loss", "content": "To approximate complex similarity distributions between text samples and prototypes, we employ a Negative Log-\nLikelihood (NLL) loss for GMM jointly trained with the model, which is given by:\n\\[\nL_{NLL} = - log(\\sum_{m=1}^M\u03c0_m. N(\u00a7 | \u00b5_m, \u03c3_m) + \u0454),\n\\]\nwhere \\(\u03c0_m\\), \\(\u00b5_m\\), and \\(\u03c3_m\\) are the mixture weights, means, and standard deviations of the \\(m\\)-th Gaussian component,\nrespectively, and \\(e\\) is a small constant added for numerical stability.\nThe overall loss for the GMM is defined as:\n\\[\nL_{GMM} = E[L_{NLL}] + LL1,\n\\]\nwhere an L\u2081 regularization term is introduced to promote sparsity in the mixture weights: \\(LL1 = \u03bb\\sum_{m=1}^M|\u03c0_m|\\), where\n\\(\u03bb\\) controls the regularization strength. This sparsity encourages the model to focus on a few significant Gaussian\ncomponents. \\(\u03bb\\) is set to 1e\u22123 for all experiments."}, {"title": "3.3.2 Diversity Loss", "content": "To promote diverse prototype representations and mitigate redundancy, we introduce a Diversity Loss based on cosine\ndistance:\n\\[\nL_{div} = \\sum_{i\u2260j} D_{ij},\n\\]\nwhere \\(D_{ij} = 1\\) - cos(\\(p_i, p_j\\)) be the cosine distance between prototypes. Minimizing this diversity loss enhances\ngeneralization and interpretability by maintaining a diverse set of prototypes."}, {"title": "3.3.3 Overall Objective", "content": "The final objective function for the proposed model is a weighted combination of the aforementioned loss components:\n\\[\nL = CrossEntropy(y, \u0177) + \\frac{\u03b1}{2}LGMM + \\frac{\u03b2}{2}L_{div},\n\\]\nwhere \\(y\\) represents the true labels, \\(\u0177\\) denotes the prediction, \\(\u03b1\\) and \\(\u03b2\\) are hyperparameters that control the balance\nbetween accuracy, Gaussian mixture modeling, and prototype diversity. \\(\u03b1\\) and \\(\u03b2\\) is set to le\u00af\u00b9 and 1e-3 for all\nexperiments, respectively."}, {"title": "4 Experiments", "content": "In this section, we conduct comprehensive experiments to evaluate the proposed model and answer the following\nresearch questions: RQ1: How does ProtoLens perform in terms of classification accuracy compared to state-of-the-\nart (SOTA) baselines? RQ2: What is the quality of the model interpretations? RQ3: What are the effects of the\nproposed Prototype Alignment mechanism and Diversity loss on ProtoLens? RQ4: What are the impacts of different\nhyperparameters on ProtoLens?"}, {"title": "4.1 Experimental Setup", "content": "Datasets. To evaluate the performance of ProtoLens, we conducted extensive experiments using five diverse sentiment\nclassification datasets, including IMDB, Yelp, Amazon, Hotel, and Steam. Details of these datasets are shown in\nAppendix A.\nReproducibility. The ProtoLens model was implemented using PyTorch. For training, the prototype number K is\nselected from {10, 20, 40, 50, 100}. The learning rate is selected from {1e \u2013 4, 1e \u2013 5, 5e \u2013 5}, with a decay of 10%\nevery 10 epochs. We used the AdamW optimizer Loshchilov [2017] with a batch size of 16 for 25 epochs and the\nn-gram size is selected from {1,3, 5, 7, 9}. The experiments were conducted on an NVIDIA A100 80GB GPU. Code\nand data are available at https://anonymous.4open.science/r/ProtoLens-CEOB/.\nBaselines. We compare ProtoLens against a range of baselines, encompassing both interpretable and non-interpretable\nmodels. The interpretable baselines include ProSeNet Ming et al. [2019a] and ProtoryNet [Hong et al., 2023], both\nare prototype-based methods that provide insights into their predictions via learned prototypical representations.\nAdditionally, we include a MPNet [Song et al., 2020a] and a Bag-of-Words model Zhang et al. [2010] using TF-IDF\nrepresentations and Logistic Regression for interpretable classification Hosmer Jr et al. [2013]."}, {"title": "4.2 Prediction Accuracy (RQ1)", "content": "We evaluate the accuracy of ProtoLens against several competitive baselines, including both prototype-based and\nnon-prototype-based methods. The results are presented in Table 1. ProtoLens consistently achieves the highest scores,\noutperforming the baselines in all cases. The consistently higher performance of ProtoLens demonstrates its effectiveness\nand robustness across diverse domains, highlighting its superiority in leveraging fine-grained interpretability without\nsacrificing predictive accuracy."}, {"title": "4.3 Model Interpretations (RQ2)", "content": "The interpretability of our proposed ProtoLens is two-fold. First, ProtoLens employs prototypes that are aligned with real\nsentences from the training set, representing concepts with assigned weights. For a given text instance, the model reveals\nwhich concepts are present and their respective importance for the prediction, resulting in intrinsic interpretability.\nSecond, ProtoLens extracts prototypical spans from the text that maximally activate the corresponding concept. Users\ncan intuitively inspect these concepts by comparing the selected spans from the input with the corresponding prototypes,\nproviding fine-grained, prototype-based interpretability."}, {"title": "4.3.1 Prototype Interpretation", "content": "In this section, we present an example of ProtoLens trained on the IMDB dataset with K = 10 prototypes. Figure 3\nshowcases five randomly selected prototypes along with their aligned sentence interpretations. These prototypes span a\nwide range of concepts, including acting, horror elements, humor, storyline, and film execution.\nWhat stands out is that ProtoLens achieves high accuracy while relying on concise and interpretable prototypes, often\nrepresented by short sentences. This allows for rapid and straightforward comprehension of the model's reasoning\nprocess. Each prototype captures key characteristics of the corresponding text, providing insightful interpretations for\nvarious aspects of the movie, such as acting quality, humor, or poor execution. This feature enhances both the model's\ninterpretability and usability, as users can easily relate the prototypes to human-understandable concepts, making the\npredictions more transparent. A detailed prototype interpretation for all datasets is provided in Appendix"}, {"title": "4.3.2 Classification Interpretation", "content": "When conducting classification on a text sample, ProtoLens extracts the most relevant spans from the sample for all\nprototypes. Similarities between spans and prototypes are then calculated to determine which concepts are activated for\nthe sample. Last, interpretable classification is delivered based on the similarities. We present a positive example in\nFigure 4 and a negative example in Figure 5, both from the IMDB dataset.\nAs shown in Figure 4, the top three prototypes with the highest similarity scores significantly influence the classification.\nPrototype 0 captures the concept of a \"highly entertaining flick\" (similarity score 0.708, sentiment weight 0.985),\nPrototype 2 reflects humor with the span \"crime comedy that's often very funny\" (score 0.549, weight 0.247), and\nPrototype 5 highlights good acting with \"some great actors playing these characters\" (score 0.730, weight 0.931). These\nprototypes, focusing on entertainment, comedy, and acting, lead the model to correctly predict a \"Positive\" sentiment.\nIn contrast, Figure 5 shows a negative example. The text activates prototype 4, reflecting dissatisfaction with special\neffects, as captured in the span \"problems with this film: 1 cheap special effects,\" with a similarity score of 0.657 and a\nsentiment weight of -0.956. Prototype 7 reflects frustration with the movie, highlighted by the span \"ended up watching\nit the whole 2 hours,\" scoring 0.676 with a weight of -0.809. Prototype 9 captures disappointment with the lack of\ncharacter development, aligned with the span \"there was no character development,\" with a similarity score of 0.664\nand weight of -0.756. These prototypes highlight negative aspects of the movie, leading the model to correctly predict\nthe sentiment as \"Negative\"."}, {"title": "4.4 Ablation Study (RQ3)", "content": "To demonstrate the effectiveness of the Prototype Alignment and Diversity Loss, we compare ProtoLens trained with\nand without these components. Prototype Alignment ensures that prototypes maintain their semantic faithfulness. The\nDiversity Loss encourages prototypes to be distinct, reducing redundancy in representation. The results, shown in\nTable 2, indicate that both the Prototype Alignment and Diversity Loss are essential for maintaining ProtoLens's high\nperformance and interpretability, as their removal leads to significant declines in accuracy across datasets. A detailed\nanalysis is provided in Appendix E."}, {"title": "4.5 Hyperparameter (RQ4)", "content": "We explored the impact of varying the number of prototypes K and n-gram sizes on ProtoLens's performance,\nidentifying dataset-specific optimal values that balance model complexity and classification accuracy. In conclusion,\nthe optimal number of prototypes K varies by dataset, with K = 50 performing best for Amazon and Yelp, K = 40\nfor IMDB, and K = 20 for Hotel, while an n-gram size of 5 consistently yields the best results across all datasets,\nbalancing complexity and performance. A detailed analysis is provided in Appendix F."}, {"title": "5 Conclusion", "content": "In this paper, we present ProtoLens, a prototype-based model offering fine-grained, sub-sentence level interpretability\nfor text classification. we introduce a Prototype-aware Span Extraction module with a Prototype Alignment mechanism\nto ensure prototypes remain semantically meaningful and aligned with human-understandable examples. Extensive\nexperiments across multiple benchmarks show that ProtoLens outperforms both prototype-based and non-interpretable\nbaselines in accuracy while providing more intuitive and detailed explanations."}, {"title": "6 Limitations", "content": "While ProtoLens offers significant advancements in interpretability through prototype-based reasoning and fine-grained\nsub-sentence level analysis, there are several limitations to consider. First, the quality of the learned prototypes heavily\ndepends on the training data. If the data contains inherent biases, these biases may be reflected in the prototypes,\npotentially leading to biased predictions or explanations. This limitation underscores the importance of careful data\ncuration and ongoing monitoring of the model's outputs to mitigate bias.\nSecond, ProtoLens currently focuses on text classification tasks and has not yet been evaluated on more complex natural\nlanguage processing (NLP) tasks such as machine translation or summarization. Adapting ProtoLens to these tasks may\nrequire significant architectural changes to maintain interpretability without compromising performance.\nFuture work could explore methods to address these limitations, such as developing techniques to automatically detect\nand mitigate biases, extending ProtoLens to more complex tasks, and improving the efficiency and user-friendliness of\nthe learned interpretations."}, {"title": "7 Ethics", "content": "We have carefully considered the ethical implications of our work. ProtoLens is designed to enhance interpretability in\ndeep neural networks, particularly for text classification tasks. By providing more transparent and intuitive explanations,\nProtoLens aims to improve trust and accountability in AI systems, which is crucial in high-stakes applications such as\nhealthcare, legal, and financial domains.\nWe are committed to ensuring that the use of ProtoLens is aligned with ethical standards, promoting transparency\nand fairness in decision-making processes. However, as with all AI models, there is a potential risk of misuse or bias\namplification if the model is trained on biased data. To mitigate this, we emphasize the importance of careful data\ncuration and ongoing monitoring of model outputs to identify and address any unintended biases. We encourage users\nof ProtoLens to conduct thorough bias audits and ensure that the model is applied in a fair and responsible manner.\nFurthermore, the datasets used in our experiments, including IMDB, Yelp, Amazon, Hotel, and Steam reviews, are\npublicly available and widely used in the research community. We have ensured that no personally identifiable\ninformation (PII) is present in the data, and that our use of these datasets complies with relevant ethical guidelines."}]}