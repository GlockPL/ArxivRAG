{"title": "A General Framework for Constraint-based Causal Learning", "authors": ["Kai Z. Teh", "Kayvan Sadeghi", "Terry Soo"], "abstract": "By representing any constraint-based causal learning algorithm via a placeholder property, we decompose\nthe correctness condition into a part relating the distribution and the true causal graph, and a part that depends\nsolely on the distribution. This provides a general framework to obtain correctness conditions for causal\nlearning, and has the following implications. We provide exact correctness conditions for the PC algorithm,\nwhich are then related to correctness conditions of some other existing causal discovery algorithms. We\nshow that the sparsest Markov representation condition is the weakest correctness condition resulting from\nexisting notions of minimality for maximal ancestral graphs and directed acyclic graphs. We also reason that\nadditional knowledge than just Pearl-minimality is necessary for causal learning beyond faithfulness.", "sections": [{"title": "1 INTRODUCTION", "content": "A main goal of graph-based causal inference is causal discovery\u2014given data, we would like to uncover the underlying causal\nstructure in the form of a true causal graph, on which conventional graph-based causal inference techniques hinge. We will\nmostly be concerned with the setting of observational data, such as when randomised control trials are unavailable. In the absence\nof interventional data, the true causal graph is only recoverable up to its graphical separations. Causal discovery approaches can\nbe categorised into score-based approaches (Chickering 2002) and constraint-based approaches (Spirtes et al. 2001), of which\nthe latter will be the focus of this work.\nConstraint-based approaches require the (untestable) assumption that the probabilistic dependency structure is a good\nrepresentation for the graphical structure of the true causal graph. A natural and common assumption is faithfulness, where every\nconditional independence in the data generating distribution is exactly represented by the true causal graph (Zhang and Spirtes\n2008). Under faithfulness, most constraint-based learning approaches such as the PC and SGS algorithms provably return the\ntrue causal graph, up to its graphical separations. However, simple examples show that faithfulness is easily violated, and can be\ntoo stringent in practice and theory (Uhler et al. 2013, Andersen 2013).\nEfforts to relax the faithfulness assumption include the sparsest permutation (SP) algorithm by Raskutti and Uhler (2018) and\nthe recent natural structure learning algorithms of Sadeghi and Soo (2022) and Teh et al. (2024), both of which provably return\nthe graphical separations of the true causal graph under strictly weaker assumptions than faithfulness.\nThis work will provide a framework which encompasses conditions under which all constraint-based causal learning algorithms\nwork, along with providing such conditions given any algorithm. From the framework: 1.) we provide exact conditions for\nwhen the PC algorithm works, and relate them to correctness conditions of some other existing algorithms; 2.) we show that the\nsparsest Markov representation condition is the weakest correctness condition resulting from existing notions of minimality for\nmaximal ancestral graphs and directed acyclic graphs; 3.) we reason that knowledge, in addition to that of just Pearl-minimality,\nis necessary for causal learning beyond faithfulness.\nThe structure of the paper is as follows: Section 2 covers the relevant background, Section 3 covers the theory of the main\nframework, and Sections 4 and 5 discuss implications and applications of the framework. The proofs will be given in the last\nsection."}, {"title": "2 PRELIMINARIES", "content": "Here, we will cover all the concepts and terminology relevant for this work.\n2.1 | Graphical Models\nLet G denote a graph over a finite set of nodes $V = \\{1, ..., n\\}$. We will consider three types of edges: directed ($\\rightarrow$), undirected\n(-), and bidirected edges ($\\leftrightarrow$). A path $\\pi$ between nodes $i_0$ and $i_n$ is a sequence of nodes $(i_0,..., i_n)$, such that for all\n$m \\in \\{0...,n-1\\}$, $i_m$ is adjacent to $i_{m+1}$, i.e. there exists an edge between $i_m$ and $i_{m+1}$; if for the sequence $(i_0, . . ., i_n)$ we have\n$i_0 = i_n$ in addition, the sequence is a cycle. For a path $(i_0, ..., i_n)$, if all edges between nodes $i_m$ and $i_{m+1}$ are directed as $i_m\\rightarrow i_{m+1}$\nthe path is a directed path; likewise, for a cycle $(i_0, . . ., i_n)$, if all edges between nodes $i_m$ and $i_{m+1}$ are directed as $i_m\\rightarrow i_{m+1}$,the\ncycle is a directed cycle. Given $C \\subseteq V$, let $an(C)$ denote the ancestors of $C$, the set of nodes such that there exists a directed path\nto some node $i \\in C$.\nThe most general class of graphs we consider are anterial graphs.\nDefinition 1 (Anterial graphs (Lauritzen and Sadeghi 2018)). A graph G over a set of nodes V, which may contain directed ($\\rightarrow$),\nundirected (-), and bidirected edges ($\\leftrightarrow$) is an anterial graph if the following omissions are satisfied.\n1. There does not exist a path $(i_0, ..., i_n)$ such that $i_0 \\rightarrow i_n$ and for all $m \\in \\{0, . . ., n - 1\\}$ the edge between nodes $i_m$ and $i_{m+1}$\nis either undirected (-) or directed as $i_m\\rightarrow i_{m+1}$.\n2. There does not exist a cycle $(i_0, ..., i_n)$ such that for $m \\in \\{0,...,n-1\\}$ the edge between nodes $i_m$ and $i_{m+1}$ is either\nundirected (-) or directed as $i_m\\rightarrow i_{m+1}$.\nAn ancestral graph is an anterial graph with the constraint that there are no arrowheads pointing into undirected edges, and a\ndirected acyclic graph (DAGs) is an anterial graph with only directed edges. Ancestral graphs can be seen as a generalisation of\na DAG causal model with unobserved variables (Zhang 2008).\nDefinition 2 (Ancestral graphs (Richardson and Spirtes 2002) and directed acyclic graphs). A graph G over a set of nodes V,\nwhich may contain directed ($\\rightarrow$), undirected (\u2014), and bidirected edges ($\\leftrightarrow$) is an ancestral graph if the following omissions are\nsatisfied.\n1. There does not exist nodes $i, j, k \\in V$ such that $i \u2014 j \\leftrightarrow k$ or $i \u2014 j \\leftarrow k$.\n2. There does not exist a directed path between nodes $i$ and $j$ such that $i \\leftrightarrow j$.\n3. There are no directed cycles in the graph.\nA graph G over a set of nodes V, which contains only directed edges ($\\rightarrow$) is a directed acyclic graph if there are no directed\ncycles in the graph.\nFor $A, B, C \\subseteq V$ disjoint, we let $A \\mathbb{I}_G B | C$ denote a graphical separation in G, between A and B given C. Anterial graphs\nhave a well-defined graphical separation (Lauritzen and Sadeghi 2018), which specialises to the classical d-separation (Pearl\n2009) in the case of DAGs and m-separation (Richardson and Spirtes 2002) in the case of ancestral graphs. We associate a joint\ndistribution P to the set of nodes V, and a random vector $X = (X_1, . . ., X_n)$ with the distribution P. We let $A \\perp B | C$ denote the\nconditional independence of $(X_i)_{i\\in A}$ and $(X_j)_{j\\in B}$ given $(X_k)_{k\\in C}$, which can be thought of as probabilistic separation.\nLet $J(P)$ denote the set triples corresponding to conditional independencies of distribution P, so that $(A, B, C) \\in J(P)$ if and\nonly if $A \\perp B | C$. Similarly, let $J(G)$ be the set of triples corresponding to graphical separations of graph G. The graphs $G_1$ and\n$G_2$ are Markov equivalent and belong in the same Markov equivalence class (MEC) if $J(G_1) = J(G_2)$. Throughout this work,\nfrom P, we will only be making use of the conditional independence structure captured by $J(P)$, thus we may refer to P and $J(P)$\ninterchangeably."}, {"title": "2.2 General Setting for Causal Learning", "content": "Let $G_0$ be the true causal graph, which we wish to partially recover from an observed distribution P, which is induced from\n$G_0$. The main goal of causal learning is to use observational data from the distribution P to recover a graph that belongs to the\nMEC of $G_0$. As with constraint-based causal learning, from P we will mostly be concerned with the conditional independencies\n$J(P)$ and by tacitly assuming the availability of a conditional independence oracle, we will always know whether or not a given\nconditional independence relation holds in the distribution.\nA causal learning algorithm aims to output a graph G(P) from an input distribution P, and if the output G(P) is Markov\nequivalent to the true causal graph $G_0$, then the algorithm is consistent. As in Sadeghi and Soo (2022), this paradigm can be\nsummarised diagrammatically:"}, {"title": "2.3 Assumptions in Causal Learning Literature", "content": "Here, we will introduce relations tying together graphical separations of a graph G and conditional independencies of a\ndistribution P. Often these relations are assumed on the true causal graph and its observational distribution, and the success of a\nlearning algorithm leans heavily on the assumed relation. Thus in the context of structure learning, these relations are often\nassumptions. Note that throughout we are merely stating the assumptions in the literature, not necessarily assuming them to be\ntrue here. The most fundamental relation is the Markov property.\nDefinition 3 (Markov property). A distribution P is Markovian to G if $J(G) \\subseteq J(P)$\u2014equivalently, for all disjoint $A, B, C \\subseteq V$,\nwe have\n$A \\mathbb{I}_G B | C \\Rightarrow A \\perp B | C$.\nIf P is induced from a structural equation model for a DAG G with independent noise, then the Markov property is satisfied.\nThe Markov property has many related forms, and the following pairwise version along with additional assumptions implies the\nMarkov property.\nDefinition 4 (Pairwise Markov Property). A distribution P is pairwise Markovian to G if for all nodes $i, j \\in V$, we have\n$i \\text{ not adjacent to } j \\text{ in } G \\Rightarrow i \\perp j | an(i, j)$.\nIf, in addition to Markov property, we have the reverse implication, then we have faithfulness, one of the strongest assumption\nin causal learning (Pearl 2009, Spirtes et al. 2001).\nDefinition 5 (Faithfulness). A distribution P is faithful to G if $J(G) = J(P)$\u2014equivalently, for all disjoint $A, B, C \\subseteq V$, we have\n$A \\mathbb{I}_G B | C \\Leftrightarrow A \\perp B | C$.\nRemark 1. There are stronger assumptions such as the $\\Lambda$-strong faithfulness (Zhang and Spirtes 2002), which essentially bounds\nthe strength of the conditional dependence to be above $\\Lambda$, in order to achieve consistency in conditional independence testing.\nSince we will not be concerned with testing in in this work, we will not include assumptions of this kind.\nA distribution P is graphical if there exists a graph G such that P is faithful to G.\nLet sk(G) denote the skeleton of graph G, formed by removing all arrowheads from edges in G. A v-configuration is a set of\nthree nodes $i, k, j \\in V$ such that i and j are adjacent to k, but i and j are not adjacent, and will be represented as $i \\sim k \\sim j$. A\nv-configuration oriented as $i\\rightarrow k \\leftarrow j$ is a collider, otherwise the v-configuration is a non-collider. To relate P with sk(G), we\nhave the following.\nDefinition 6 (The skeleton sk(P)). Given a distribution P, the skeleton sk(P) is the undirected graph with node set V, such that\nfor all $i, j \\in V$, we have i is adjacent to j if and only if there does not exist any $C \\subseteq V\\backslash \\{i,j\\}$ such that $i \\perp j | C$.\nDefinition 7 (Adjacency faithfulness). A distribution P is adjacency faithful with respect to (w.r.t.) G if sk(P) = sk(G)."}, {"title": "3 THEORY AND FRAMEWORK", "content": "Let G denote a class of graphs that is a subclass of anterial graphs. Throughout this section, we will not be making any\nassumptions on G, unless stated explicitly."}, {"title": "3.1 Comparing Consistency Conditions", "content": "Based on the formulation in Theorem 1, we can compare the strength of causal learning consistency conditions as follows.\nDefinition 15 (Support). Given a class of graphs G, and a property A relating distributions and graphs in G, the support of A is\ngiven by the class of tuples given by\n$supp(A) = \\{(P, G) : G \\in \\mathcal{G}, A(P, G) = T \\text{ and } U_A(P) = T \\}$.\nGiven two properties A and B, relating distributions and graphs, if $supp(A) \\subseteq supp(B)$, then we say that A and $U_A$ is stronger\nthan B and $U_B$.\nFrom Examples 1, 2, and 12, we see that in general given properties A and B relating distributions and graphs, $A(P, G) =\nT \\Rightarrow B(P, G) = T$ for all P and $G\\in \\mathcal{G}$ does not necessarily imply $supp(A) \\subseteq supp(B)$ nor $supp(B) \\subseteq supp(A)$. However, under\nsome conditions, we can relate supp(A) and supp(B).\nProposition 2 (Reversing the implication). Let A and B be properties relating distributions and graphs in $\\mathcal{G}$. Suppose that for\nall P, we have\n$\\exists G_p \\in \\mathcal{G} \\text{ such that } A(P, G_p) = T \\quad\\quad \\exists G'_p \\in \\mathcal{G} \\text{ such that } B(P, G'_p) = T$\nand A is a class property. If $A(P, G) = T \\Rightarrow B(P, G) = T$ for all P and $G \\in \\mathcal{G}$, then $supp(B) \\subseteq supp(A)$.\nProposition 3 (Preserving the implication). Suppose that for properties A and B relating distributions and graphs in $\\mathcal{G}$, for all\nP such that $A(P, G_p) = T$ for some $G_p \\in \\mathcal{G}$, we have the equality\n$\\{G \\in \\mathcal{G} : A(P, G) = T \\} = \\{G \\in \\mathcal{G} : B(P, G) = T\\}$.\nIf $A(P, G) = T \\Rightarrow B(P, G) = T$ for all P and $G \\in \\mathcal{G}$, then $supp(A) \\subseteq supp(B)$.\nPropositions 2 and 3 will be used in Section 5 to compare consistency conditions resulting from minimality notions from\nSection 2.3.\nA consequence of Proposition 2 is that we can formally include additional knowledge as a property E, and provide conditions\nunder which we can increase the support of A. We let $A \\wedge E$ be the conjunction of the properties, so that $(A\\wedge E)(P, G) = T$ if\nand only if $A(P, G) = T$ and $E(P, G) = T. See Example 15 when A is Pearl-minimality and the additional knowledge E is that\nthere are no colliders, so that $E(P, G) \\neq T$ when G contains colliders."}, {"title": "4 APPLICATIONS TO DAGS", "content": "In this section, we will study properties that will be used to identify colliders and non-colliders. We will restrict our attention to\n$\\mathcal{G}$ being the class of DAGs, and find exact consistency conditions for the PC algorithm.\n4.1 Locally Constructed Properties\nThe statement $U_A(P) = T$ tells us information about the property A via the uniqueness of the Markov equivalence class; this\ninformation, together with results characterising Markov equivalence from Verma and Pearl (1990) allows us to define locally\nconstructed properties for DAGS.\nAs in Section 3, we write $v(P, i \\sim k \\sim j) = T$ if given a distribution P and a v-configuration $i \\sim k \\sim j$ in sk(P), the distribution\nP satisfies the property v w.r.t. $i \\sim k \\sim j$; we refer to such a v as a local property. Given two local properties n and c, relating\ndistributions and v-configurations in sk(P), we define the following class of properties relating distributions and graphs:\nDefinition 16 ($\\mathcal{V}_{n.c}$). Given properties n and c relating distributions and v-configurations in sk(P), we write $\\mathcal{V}_{n.c}(P, G) = T$ if:\n1 sk(P) = sk(G).\n2 For every v-configuration $i \\sim k \\sim j$ in sk(P), we have\n$\\bullet$ $i\\sim k \\sim j$ is a collider in G $\\Rightarrow$ $c(P, i \\sim k \\sim j) = T$.\n$\\bullet$ $i\\sim k \\sim j$ is a non-collider in G $\\Rightarrow$ $n(P,i \\sim k \\sim j) = T$.\nIt is straightforward to see that $\\mathcal{V}_{n,c}$ is a class property. If the properties n and c do not simultaneously hold, then we have the\nfollowing form of $\\mathcal{V}_{n,c}$-uniqueness.\nProposition 4 ($\\mathcal{V}_{n,c}$ is a class property and $\\mathcal{V}_{n,c}$-uniqueness). Let n and c be local properties.\n1. $\\mathcal{V}_{n,c}$ is a class property.\n2. If for all P and all v-configurations $i \\sim k \\sim j$ in sk(P), we do not have\n$n(P, i\\sim k \\sim j) = T \\text{ and } c(P, i \\sim k \\sim j) = T,$\nthen $U_{\\mathcal{V}_{n.c}} (P) = T$ for all P such that $\\mathcal{V}_{n,c}(P, G_p) = T$ for some $G_p$.\nFrom local properties n and c, we define the (n, c)-orientation rule which encapsulates many orientations rules used in\nconstraint-based learning to assign colliders and non-colliders.\nDefinition 17 ((n, c)-orientation rule w.r.t. P). Given a distribution P, for all v-configurations $i \\sim k \\sim j$ in sk(P), the (n, c)-\norientation rule w.r.t. P assigns:\n1. $i \\sim k \\sim j$ as a collider if $n(P, i \\sim k \\sim j) \\neq T$.\n2. $i\\sim k\\sim j$ as a non-collider if $c(P, i \\sim k \\sim j) \\neq T$.\n3. $i\\sim k \\sim j$ as unassigned otherwise."}, {"title": "4.2 Exact Consistency Conditions for the PC algorithm", "content": "Depending on the computational implementation of the orientation rules of the PC algorithm (Spirtes and Glymour 1991), which\nall give the same output under the faithfulness assumption, we can obtain necessary and sufficient conditions for the PC algorithm\nusing Theorem 1. The recent causal-learn package in Python (Zheng et al. 2024) is an example of such implementations.\nThroughout this subsection, we assume that sk(G(P)) = sk(P) for the output G(P) of the PC algorithm. Since sk(G(P)) = sk(P),\nwe know that the corresponding property V that describes the algorithm via $\\mathcal{V}(P, G(P)) = T$ has to at least satisfy, for given P\nand G, that sk(P) = sk(G), i.e. if $\\mathcal{V}(P, G) = T$, then sk(P) = sk(G).\nPC orientation rules.\nDepending on the computational implementation of the PC algorithm, one of the following orientation rules is employed for\nall v-configurations $i \\sim k \\sim j$ in sk(P).\n1. If $\\forall C \\subseteq V \\backslash \\{i,j\\}$ s.t. $i \\perp j | C$, we have $k \\in C$, then assign $i \\sim k \\sim j$ as a non-collider; otherwise assign as a collider.\n2. If $\\forall C \\subseteq V \\backslash \\{i,j\\}$ s.t. $i \\perp j | C$, we have $k \\notin C$, then assign $i\\sim k \\sim j$ as a collider; otherwise assign as a non-collider.\n3. (a) If $\\forall C\\subseteq V \\backslash \\{i,j\\}$ s.t. $i \\perp j | C$, we have $k \\in C$, then assign $i \\sim k \\sim j$ as a non-collider.\n(b) If $\\forall C \\subseteq V \\backslash \\{i,j\\}$ s.t. $i \\perp j | C$, we have $k \\notin C$, then assign $i \\sim k \\sim j$ as a collider."}, {"title": "5 APPLICATIONS TO MINIMALITY", "content": "5.1 Comparing Consistency Conditions from Minimality Constraints\nFirst, we restrict our graph class $\\mathcal{G}$ to be DAGs, and substitute in variants of the minimality assumptions introduced in Section\n2.3 as the property in our framework. Proposition 1 can then be combined with Propositions 2 and 3 to obtain the following\nresult for DAGS:\nProposition 8 (SMR is the weakest amongst minimality, for DAGs). Let the graph class $\\mathcal{G}$ be DAGs. For a probability\ndistribution P and a DAG G on the same set of nodes V, consider the following properties:\n$\\bullet$ $M_1(P, G) = T$ if P is minimally Markovian w.r.t. G.\n$\\bullet$ $M_2(P, G) = T$ if G is a sparsest Markov graph of P.\n$\\bullet$ $M_3(P, G) = T$ if P is Pearl-minimal w.r.t. G.\n$\\bullet$ $M_4(P, G) = T$ if P is causally minimal w.r.t. G.\nThen $supp(M_1) \\subseteq supp(M_2)$ and $supp(M_4) \\subseteq supp(M_3) \\subseteq supp(M_2)$.\nRemark 6. In the case of DAGs, although the corresponding property V for Me-LoNS is stronger than $M_1$ (additionally requiring\nthe V-OUS and collider-stable condition), neither $supp(\\mathcal{V})$ nor $supp(M_2)$ contain each other (Teh et al. 2024, Example 2); this\ndoes not contradict $supp(M_1) \\subseteq supp(M_2)$ in Proposition 10 since implication is in general not preserved after taking the\nconjunction with the corresponding uniqueness.\nPreviously, Lam et al. (2022) proved the containment $supp(M_3) \\subset supp(M_2)$; our proof of this containment is different, by\nappealing to the conditions in Propositions 2 and 3 in Section 3.\nTo obtain analogous results for MAGs, we first obtain an analogous Proposition to Proposition 1, but for graph class $\\mathcal{G}$ being\nmaximal ancestral graphs (MAGs).\nProposition 9 (Proposition 1 for MAGs). For a given distribution P and a maximal ancestral graph G, the following statements\nimply the next:\n1. P is minimally Markovian w.r.t. G.\n2. G is a sparsest Markov graph of P.\n3. P is Pearl-minimal w.r.t. G.\n4. P is causally minimal w.r.t. G.\nAnalogously substituting in variants of the minimality assumptions introduced in Section 2.3 as the property in our framework,\nProposition 9 then can be combined with Propositions 2 and 3 to obtain the following:\nProposition 10 (SMR is the weakest amongst minimality, for MAGs). Let the graph class $\\mathcal{G}$ be MAGs. For a probability\ndistribution P and a maximal ancestral graph G on the same set of nodes V, consider the following properties:\n$\\bullet$ $M_1(P, G) = T$ if P is minimally Markovian w.r.t. G.\n$\\bullet$ $M_2(P, G) = T$ if G is a sparsest Markov graph of P.\n$\\bullet$ $M_3(P, G) = T$ if P is Pearl-minimal w.r.t. G."}, {"title": "5.2 Pearl-minimality as a Property Constraint", "content": "Given any graph class $\\mathcal{G}$, although our framework allows for any generic property, for some A taking the conjunction with $U_A$\nresults in some rather degenerate conditions.\nExample 12 (Just the Markov property). Given any class of graphs $\\mathcal{G}$, let $A(P, G) = T$ if P is Markovian to G. Then $A(P, G) = T$\nand $U_A(P) = T$ is equivalent to G being a complete graph and P not Markovian to any subgraph of G.\nExample 12 suggests that there should be constraints that a meaningful property should at least satisfy. These will be referred\nto as property constraints and will be thought of as a property C such that for any meaningful property A, if $A(P, G) = T$, then\n$C(P, G) = T$.\nThe following examples suggest the Pearl minimality property as a property constraint C for meaningful properties in the\ncontext of causal learning, i.e. for any meaningful property A, if $A(P, G) = T$, then P is Pearl-minimal to G.\nExample 13 (Degenerate $A$). For each distribution P fix an (arbitrarily) assigned graph $G_P$; here, we can further specify that P\nis not Markovian to $G_P$. Then for all P and $G \\in \\mathcal{G}$, let\n$A(P, G) = T \\Leftrightarrow$ G is Markov equivalent to $G_P$.\nIn this case there does not exist a property B such that $supp(A) \\subset supp(B)$, A thus results in a very weak consistency condition.\nHowever, an algorithm from the defined A simply returns the arbitrarily assigned MEC.\nCausal statements such as conditional exchangability and ignorability are conditional independence statements of the\njoint distribution of the interventional and observational marginals. Thus in our setting, the goal is to represent conditional\nindependence statements of the observational marginal distribution P using the graph G(P) $\\in \\mathcal{G}$. If P is not Markovian to G(P),"}, {"title": "5.3 The Necessity of Additional Knowledge", "content": "As remarked in Section 5.2, any property for causal learning should at least satisfy Pearl-minimality. In the absence of additional\nknowledge $\\mathcal{E}$ of how a property relates distribution P and true causal graph $G_0$ and algorithm output G(P), we apply Theorem 1\nas follows. We let M denote the corresponding property to Pearl-minimality. The required consistency condition from Corollary\n1 is that if $M(P,G_0) = T$ and $U_M(P) = T$, then an algorithm that always outputs a graph G(P) that is Pearl-minimal to\nP\u2014$M(P, G(P)) = T$, will be consistent.\nProposition 11 (Pearl-minimal-unique and graphical distributions are equivalent). Let $\\mathcal{G}$ be a class of graphs which contains\nDAGs and M be Pearl-minimality. If P is a distribution, then $U_M(P) = T \\Leftrightarrow$ P is graphical.\nRemark 9. Lam et al. (2022) proved that the set of distributions P such that $U_M(P) = T$ is exactly the set of graphical\ndistributions in the case of DAGs, and Proposition 11 is a simple extension of this fact to the case of any class of graphs\ncontaining DAGs, including anterial graphs.\nFrom Proposition 11, it can be seen that the resulting condition of $M(P, G_0) = T$ and $U_M(P) = T$ is equivalent to P being\nfaithful to $G_0$. Thus interventions or additional knowledge $\\mathcal{E}$ beyond Pearl-minimality M are necessary to further constrain the\nset of Pearl-minimal graphs in order to obtain a weaker consistency condition than faithfulness."}, {"title": "6 SUMMARY AND FUTURE WORK", "content": "This paper contributes a framework to derive consistency conditions encompassing any constraint-based causal learning algorithm\nby appropriate substitution of a placeholder property, from which we recover some consistency conditions of causal learning in\nliterature such as Raskutti and Uhler (2018) and Teh et al. (2024). Via our framework, given any causal learning algorithm, if we\ncan identify the property A that relates the output graph G(P) and input distribution P, using the same property A, we can then\nimmediately obtain consistency conditions for the algorithm. Note that the framework does not contain information as how to\nactually construct an output G(P) that satisfies property A.\nUsing the information provided by MEC-uniqueness, we then consider property $\\mathcal{V}_{n,c}$ constructed from local properties n and c\non v-configurations. From this, based on given PC orientation rules and their corresponding property $\\mathcal{V}_{n,c}$, we use our framework\nto provide necessary and sufficient consistency conditions for the PC algorithm, depending on the version of orientation rules\nimplemented in the actual computation, such as Zheng et al. (2024)\nFrom the framework, we see that any given property can be converted into a causal learning consistency condition by taking\nthe conjunction with its corresponding uniqueness. We then give some conditions when we can compare the strength of causal\nlearning consistency conditions obtained from different properties. Focusing on DAGs and MAGs, these conditions are used\nto show that the SMR condition is the weakest consistency conditions for causal learning obtainable from existing notions of\nminimality (Forster et al. 2018, Lam et al. 2022, Pearl 2009).\nBy reasoning the necessity of Pearl-minimality, we show that having only Pearl-minimality as the property would result in\nfaithfulness as the corresponding consistency condition. Thus knowledge, in addition to just Pearl-minimality, such as those in\nTable 1, is necessary for consistency conditions beyond faithfulness. Otherwise, motivated by Examples 15 and 16, our algorithm\nshould just provide all the MECs as options for consideration.\nFuture work include further developing the procedure of obtaining the Pearl-minimal graphs from J(P), perhaps by repeated\napplications of the contra-positive versions of the singleton transitive compositional graphoid axioms and ordered upward and\ndownward stability w.r.t. a pre-order (Sadeghi 2017), to the conditional dependencies of P. However, some care has to be taken\nwith selecting a pre-order since the Pearl-minimality constraint on J(G(P)) may be violated without an appropriate order.\nOther avenues include investigating different mechanisms of how a meaningful property can arise, such as from G being the\nsolution of a loss function optimisation, since these types of properties can be easily converted into an algorithm."}, {"title": "7 PROOFS", "content": "Proof of Theorem 1.\nGiven the distribution P, for the output of the algorithm G(P), we have A(P, G(P)) = T. For the true casual graph $G_0$, we\nhave A(P, $G_0$) = T. Since $U_A(P)$ = T, we have G(P) and $G_0$ are Markov equivalent.\nAssume that A is a class property and corresponds to the algorithm. Let G(P) be an output of the algorithm, we have\nA(P, G(P)) = T, and G(P) is Markov equivalent to the true causal graph $G_0$. Thus by definition of class property, we have\nA(P, $G_0$) = T. Assume $U_A(P) \\neq$ T, then we have that there exists an algorithm output G(P) that is not Markov equivalent to\n$G_0$, giving a contradiction.\nProof of Proposition 2. Let properties A and B, of which A is a class property, be such that A(P, G) = T $\\Rightarrow$ B(P, G) = T for\nall P and G. Thus each MEC on which A is T must also be T for B, giving the implication\n$U_B(P) = T \\Rightarrow U_A(P) = T$."}]}