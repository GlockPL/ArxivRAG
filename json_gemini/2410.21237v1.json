{"title": "Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce", "authors": ["Zhantao Yang", "Han Zhang", "Fangyi Chen", "Anudeepsekhar Bolimera", "Marios Savvides"], "abstract": "Knowledge Graph (KG) is playing an increasingly important role in various Al systems. For e-commerce, an efficient and low-cost automated knowledge graph construction method is the foundation of enabling various successful downstream applications. In this paper, we propose a novel method for constructing structured product knowledge graphs from raw product images. The method cooperatively leverages recent advances in the vision-language model (VLM) and large language model (LLM), fully automating the process and allowing timely graph updates. We also present a human-annotated e-commerce product dataset for benchmarking product property extraction in knowledge graph construction. Our method outperforms our baseline in all metrics and evaluated properties, demonstrating its effectiveness and bright usage potential.", "sections": [{"title": "1 Introduction", "content": "Knowledge graphs (KG), directed graphs representing information and relationships between entities, are commonly used for efficient information processing. In the domain of e-commerce, KGs play a crucial role in scaling up both inventory management and customer service by leveraging various applications [11, 15], including recommendation systems [9, 20, 21, 23, 25], question answering service [12, 22, 41], information and intention discovery [33], and knowledge completion [29].\nRecent studies [7, 24, 34, 40] show improvements extracting information from documents and texts for knowledge graph construction. However, in practice, due to the rapid changes in the fields of e-commerce, informative text descriptions of products are often expensive and time-consuming to acquire through human labeling. In contrast, raw images of products [16, 31] are widely available yet under-explored as sources of automated knowledge graph construction.\nIn this work, we explore how to establish an automatic process that directly uses product images as the primary sources to construct complex knowledge graphs. Without human-in-the-loop, the process of populating knowledge graphs particularly benefits the fast-paced e-commerce sector, where product catalogs are constantly evolving and expanding, so that timely update is achieved in such an environment. Moreover, product images contain essential information that is language-agnostic, semantic-rich, and involves subtle visual cues, ensuring accurate product representations toward multilingual and multicultural e-commerce platforms.\nDespite the advantages, establishing an automatic process for KG with product images is a non-trivial work and faces many challenges. Firstly, unlike documents and texts which directly include the entities, properties, and relationships, product images are complex and may contain distractions. Extracting useful information thus requires sophisticated image understanding. Secondly, not all relevant information for KG construction is directly visible or explicitly stated in the product image itself. For example, categorizing a chocolate image into candy requires the ability to reason based on common knowledge and contextual understanding. Thirdly, unconstrained triple generation may not fully capture the hierarchical nature of product properties in e-commerce. For instance, the category property can have a hierarchical relationship, \"chocolate\" falls under \"candy,\" which falls under \"food\". Many previous works construct KGs by either generating [17, 24, 40] or completing [3, 4] triples without additional constraints, which could result in graphs lacking depth and diversity if directly applied to e-commerce products.\nTo address these limitations, we propose a novel method that is equipped with the recent advances in vision-language models (VLMs) and large language models (LLMs), enabling hierarchical"}, {"title": "2 Related Work", "content": "Image understanding has made significant strides in recent years, particularly in the domain of text extraction from images. Image captioning models aim to generate natural language descriptions of images. Image captioning models like LEMON [10] are often based on encoder-decoder architectures. The encoder projects images into latent space, and a language decoder decodes semantic information into text descriptions. However, their outputs are often general and lack the specificity required in e-commerce applications. Image tagging models like RAM [37] take a step forward, focusing on identifying and labeling specific objects within an image, providing more fine-grained information, but still lacking the capability of identifying texts and concepts. The emergence of multimodal LLMs [32, 35], especially instruction-tuned large vision language models [13], provides a significant advancement in image understanding. These VLMs can output detailed descriptions based on user prompts, making it possible to align generated texts with desired properties.\nIn this work, we use InternVL2-8B [5, 6], a robust open-source VLM as our image description extractor. While the model provides detailed descriptions, this information is unstructured and may not contain all the required information for KG construction."}, {"title": "2.2 Knowledge Graph Construction", "content": "Knowledge graph construction aims to convert less organized raw data into more programmatically processable structured graphs. Recent advancements in deep learning and natural language processing (NLP) [1, 2, 14, 27] have significantly enabled studies in information extraction and knowledge graph construction, leading to improved data management and utilization. Due to the advancements in embedding training, some studies use embeddings to represent and discover complex structures in KGs. ComplEX [26] uses complex-valued embeddings to perform link prediction at a linear time and space complexity. KoPA [36] performs triple classification task by training an LLM adapter for injecting structural embedding. However, these works are limited to individual sub-tasks of completing a KG. Consequently, many works have shifted their attention to constructing knowledge graphs from documents [24, 28, 39] and texts [7, 34, 40]. These recent approaches have leveraged advancements in transformer [27] architecture based large language models (LLMs) trained on internet-scale datasets [18, 19] to enhance or construct knowledge graphs. For example, TKGCon [7] uses GPT-4 [1] to generate theme-related entities and relations from a theme-specific corpus to form KGs. However, few works are leveraging raw images for KG construction. In this work, we use Llama3.1 [8], in collaboration with a VLM to generate high-quality and diverse knowledge graphs for e-commerce product inventory."}, {"title": "3 Constrained Hierarchical Knowledge Graph Generation", "content": "In this section, we will show an overview of our Knowledge Graph construction method."}, {"title": "3.1 Method Overview", "content": "The knowledge graph construction can be roughly divided into two core stages. An abstract visualization of our method can be found in Figure 1.\n\u2022 Graph Initialization. When creating a new knowledge graph for an inventory or an e-commerce system, two components are used for initializing and preparing the knowledge graph: identifying target properties and creating schema. An empty inventory knowledge graph will be created once initialization is finished.\n\u2022 Cycle of Enrollment. An e-commerce inventory can grow continuously as more products are added. Therefore, our proposed method treats each product as the fundamental unit of graph creation. Our method cycles through four sequential steps for each product. A product-centric knowledge graph will be generated with four steps: Extracting, Formatting and Inferring, Hierarchy Expansion, and Graph Pruning. Each product knowledge graph will be added to the previous inventory KG.\n\u2022 Inventory Usage Once the knowledge graph is initialized, it can be loaded into a graph database and used in various downstream applications."}, {"title": "4 Introduction", "content": ""}, {"title": "4.1 Graph Initialization", "content": "Identifying Target Properties. The first step in the initialization phase is to identify and select the properties that will serve as the foundation of the knowledge graph. Not all entities and relationships are essential when utilizing a knowledge graph for e-commerce. The process of identifying target properties aims to determine the most relevant and valuable attributes for products in the inventory. This can be done automatically, manually, or semi-automatically. In automatic mode, the pipeline prompts an instruction-tuned LLM [8, 14] to list the most important properties when describing an e-commerce product. Alternatively, a person can designate the properties that are important for their system.\nCreating Schema. While the properties to be generated have been defined, it is important to standardize the structure and format of different products. The schema defines the data types of each property, which serves as a blueprint for each new product subgraph. By enforcing rules and constraints, the schema helps reduce the introduction of redundant or conflicting data when new products are added, which provides better scalability and downstream task efficiency. Enforcing data types also acts as a fail-safe, preventing LLMs from generating invalid information. In this work, we use a prompted autoregressive LLM to find the data type t that maximizes the predicted probability for each given property x:\n$t' = argmaxt' \u2208 \\{int,float,str,choices\\}P(t|x)$\nIf the data type of a property is identified as int or float, a unit of measurement is similarly predicted with an autoregressive LLM. The model predicts the next token following the prompt \"{property} of a product could be 5\". If the data type is identified as choices, LLM is prompted to generate diverse distinct choices that can generalize to most products, with an additional \"Other\" choice added.\nFollowing the above procedure, a complete schema can be created. A product subgraph takes the product name as the root node, all edges point to properties starting from the product root node. By default, we use the schema generated fully automatically:\n\u2022 Product Name: string\n\u2022 Category: choices [Electronics, Fashion, Home and Kitchen, Beauty and Personal Care, Food and Beverages, Sports and Outdoors, Baby and Kids Products, Health and Wellness, Automotive, Arts and Crafts, Pet Products, Office and School Supplies, Industrial and Scientific, Musical Instruments, Toys and Games, Others]\n\u2022 Brand: string\n\u2022 Price: float (USD)\n\u2022 Primary Package Color: choices [White, Black, Gray, Beige, Brown, Tan, Green, Red, Blue, Yellow, Light Blue, Pink, Baby Blue, Mint Green, Silver, Gold, Copper, Purple, Orange, Turquoise, Others]\n\u2022 Package Material: choices [Plastic, Paper, Cardboard, Glass, Metal, Wood, Fabric, Foam, Bamboo, Bioplastic, Molded Pulp, Corrugated, Others]\n\u2022 Package Shape: choices [Rectangular, Cylindrical, Spherical, Oval, Triangular, Irregular, Flat, Tubular, Conical, Geometric, Others]\n\u2022 Weight: float (kg)"}, {"title": "4.2 Cycle of Enrollment", "content": "With the graph initialized and the schema in place, individual products can be processed and added to the knowledge graph iteratively. The Cycle of Enrollment consists of four key steps: Extracting, Formatting and Inferring, Hierarchy Expansion, and Graph Pruning. Additionally, while we primarily focus on studying KG construction from product images, our method inherently supports textual product description as input by skipping the Extract phase. Each phase addresses specific challenges in constructing a reliable and hierarchical product knowledge graph for e-commerce.\nExtracting product descriptions from the raw image is the first step of enrolling an image. To tackle the challenge of extracting rich information from images, we employed a recent state-of-the-art open-source vision language model, InternVL2 [5, 6]. We first convert the generated schema into text descriptions to augment the original prompt. With schema description embedded in the user prompt, the VLM can generate unstructured or semi-structured text descriptions based on the input product image, ensuring that the generated descriptions cover all relevant product attributes. To maximize information coverage, we employ a multi-turn extraction process, where we prompt VLM to provide additional details in a second turn of the conversation. This will cover more visual cues compared to single-turn extraction to enable more accurate missing information inference in future steps. More turns are possible yet not employed for better speed and scalability.\nFormatting and Inferring generated description comes after information extraction. While visible information is already included in the text description, the information is not directly usable. Similar to the extracting phase, we use multi-turn conversation to align the response with the predefined schema. Since some information may not be available from the image, we use Llama3.1-70B [8] to first analyze all the extracted text descriptions, encouraging intermediate reasoning steps [30]. Then based on the reasoning, we prompt the model to infer the remaining properties. After the generation in the first turn, we use SGLang [38] for regular expression constrained generation. The output is forced to be generated in JSON format, strictly following the data type and schema structure. This guarantees that the response will always be generated reliably containing all requested properties, and additionally ensures the response can be parsed programmatically.\nHierarchical Expansion attempts to introduce additional entities between the product node and the abstract category node. This phase is crucial for enhancing the knowledge graph's structure and utility in e-commerce applications. An LLM is prompted to analyze and generate an intermediate entity between a category property and the product name. This expansion is repeated several times so that multiple intermediate entities are inserted. For example, the category link starts with \"Dark Chocolate Bar \u2192 Food and Beverage\", an intermediate nodes \"Chocolate\" and \"Dark Chocolate\" are sequentially added during the expansion. The resulting link becomes \"Dark Chocolate Bar \u2192 Dark Chocolate \u2192 Chocolate \u2192 Food and Beverage\". To further improve the diversity of the graph, multiple hierarchical expansions are performed in parallel, each independently choosing intermediate nodes from the predicted tokens with top-k sampling. By introducing multiple levels of abstraction, the system can represent products at various levels of breadth with more fine-grain relationships.\nPruning is the final step of enrolling a product. When properties are created with LLM free-form generation, there can be entities sharing exactly the same or similar meaning, these can be merged into one node. In our method, we applied a simple yet effective method that merges all properties that share the same words in different order or letter cases. This reduces the complexity of the final knowledge graph so that downstream tasks can be performed more efficiently.\nThis Cycle of Enrollment is executed for each product, allowing for the incremental growth of the knowledge graph and adapting to the rapid changes in the e-commerce domain. Because each product subgraph is generated independent of the size of the existing inventory, as shown in Figure 2. The linear scaling allows our approach to be scaled to a large inventory size without increasing the cost of generating the graph for each image."}, {"title": "4.3 Inventory Usage", "content": "In the final stage after the enrollment, one can easily leverage the KG to perform user-defined tasks. Apart from the classic product description retrieval and recommendation systems, our method enables intelligent attribute inquiry like packaging materials and weight estimation, offering users a diverse range of applications."}, {"title": "5 Experiment", "content": "In this section, we first gather a product image dataset. Then, we use our method to generate a knowledge graph following the method described in the previous section. We compare the ground truth annotation with generation results and evaluate the effectiveness of our method based on several metrics. Unless otherwise specified, we use InternVL2-8B in bfloat16 and Llama3.1-70B in int4. The experiments are conducted on 6 RTX 4090 GPUs."}, {"title": "5.1 Dataset Collection", "content": "We collected 120 images and their corresponding metadata using BlueCart Walmart Data Product API\u00b9. The result contains information such as image, product name, and other information displayed"}, {"title": "5.2 Results", "content": "In this part, we will show our performance on the collected dataset compared to a baseline method. We set our baseline by modifying the zero-shot KG construction method proposed in AutoKG [40] to generate triples from an image using the product name as the subject. Following AutoKG, we use property names as the list of predicates to prompt InternVL2, and the objects of the generated triples are treated as the predicted properties. In addition to the zero-shot baseline, we add our schema-augmented prompt to the start of the baseline prompt, providing additional context for the expected response. Then, we perform an ablation study on our method. First, we evaluate the performance of our complete method. We then conduct ablation studies by removing the multi-turn conversation during VLM information Extraction or excluding the intermediate LLM reasoning step during the Format and Infer stage, to assess the impact of these components on the overall results. We evaluated the following predictions against the annotation. Primary Package Color and Package Shape are categorical properties that can be directly observed from the image with little reasoning and inference. Package Material is a categorical property that can be directly observed from the image, but requires some prior knowledge (e.g., material texture) to infer. Category is a categorical property that cannot be directly observed from the image, and requires inference with prior knowledge and contextual reasoning on information like brand name. Weight is a numerical property that can be found on most of the product images, but due to non-standardized units of measurement across products, calculations are needed to convert to the unit in schema (kg).\nFor categorical properties, accuracy is used as the metric. For numerical property, we first compute the error ratio e between predicted value $u_{pred}$ and annotated value $u_{gt}$ by\n$e=\\frac{u_{pred} - u_{gt}}{u_{gt}}$\nThen we use accuracy@threshold as our metrics, where a prediction is considered correct if the error ratio e is strictly lower than the threshold. We report accuracy@0.01 and accuracy@0.05 for the numerical property. Table 1 shows our primary result against baseline and ablation studies. We also show a subgraph containing 3 enrolled products constructed our complete method in Figure 3."}, {"title": "5.3 Analysis", "content": "As shown in Table 1, our method exceeds directly prompting VLM for triple generation. By augmenting the baseline with our schema description, predictions for all categorical properties gain large improvements. We notice that this is mainly because when no schema descriptions are embedded in the prompt, VLM tends to give predictions that are not in the choices. Adding schema description provides contextual information for VLM to rectify its answers."}, {"title": "6 Limitations", "content": "While our work shows promising results on various metrics using high-quality images, additional work may be required for low-resolution images."}, {"title": "7 Conclusion", "content": "In this paper, we propose a novel method that fully automatically generates a knowledge graph from scratch using only image data. We propose several collaborative components to analyze and infer schema-compliant properties from each product image. We propose a benchmark for knowledge graph generation from images, with emphasis on the correctness of generated properties. We compare our method against an adaptation of a previous work [40], and perform ablation studies, showing the effectiveness of our method and several key features."}]}