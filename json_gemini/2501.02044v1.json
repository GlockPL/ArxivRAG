{"title": "Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT", "authors": ["Jianping He", "Laila Rasmy", "Degui Zhi", "Cui Tao"], "abstract": "Background: Electronic Health Records (EHRs) encompass valuable data essential for disease prediction. The application of artificial intelligence (AI), particularly deep learning, significantly enhances disease prediction by analyzing extensive EHR datasets to identify hidden patterns, facilitating early detection. Recently, numerous foundation models pretrained on extensive data have demonstrated efficacy in disease prediction using EHRs. However, there remains some unanswered questions on how to best utilize such models especially with very small fine-tuning cohorts. Methods: We utilized Med-BERT, an EHR-specific foundation model, and reformulated the disease binary prediction task into a token prediction task and a next visit mask token prediction task to align with Med-BERT's pretraining task format in order to improve the accuracy of pancreatic cancer (PaCa) prediction in both few-shot and fully supervised settings. Results: The reformulation of the task into a token prediction task, referred to as Med-BERT-Sum, demonstrates slightly superior performance in both few-shot scenarios and larger data samples. Furthermore, reformulating the prediction task as a Next Visit Mask Token Prediction task (Med-BERT-Mask) significantly outperforms the conventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to 7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These findings highlight that aligning the downstream task with Med-BERT's pretraining objectives substantially enhances the model's predictive capabilities, thereby improving its effectiveness in predicting both rare and common diseases. Conclusion: Reformatting disease prediction tasks to align with the pretraining of foundation models enhances prediction accuracy, leading to earlier detection and timely intervention. This approach improves treatment effectiveness, survival rates, and overall patient outcomes for PaCa and potentially other cancers.", "sections": [{"title": "1. Introduction", "content": "Pancreatic cancer (PaCa) is estimated to remain the fourth leading cause of cancer deaths in men, following lung, colon, and prostate cancers, and the third leading cause in women, following lung and breast cancers [1]. Patients diagnosed in the early stages of PaCa have the potential for a cure through a combination of surgery, chemotherapy, and"}, {"title": "2. Related Work", "content": "Numerous BERT variants, such as BioBERT [14] and ClinicalBERT [15], have been pretrained on clinical texts and are utilized for various clinical NLP tasks. These variations inherit the BERT architecture and pretraining tasks, specifically employing Masked language Model (MLM) objective during the pretraining stage to train most transformer based language models. Prompt tuning incorporates a prompt template-a text segment with mask tokens-into the initial input, transforming various downstream NLP tasks into MLM formats. This adjustment aligns target tasks with the pre-training structure, enhancing compatibility with the foundation models learned attentions within all BERT variants [16]."}, {"title": "3. Materials and Methods", "content": ""}, {"title": "3.1. Materials", "content": "To evaluate the added value of reformulating the disease prediction downstream task to MLM task to improve prediction accuracy, we utilized the same pancreatic cancer cohort used in the Med-BERT v2 study [13]. This cohort consists of 31,243 patients, including 12,273 cases and 18,970 controls. The dataset was split into training, validation, and test sets in a ratio of 7:1:2, resulting in up to 21,871 patients for fine-tuning, 3,124 patients for validation, and 6,248 patients for testing."}, {"title": "3.2. Methods", "content": ""}, {"title": "3.2.1. Reformulating PaCa Onset Task into Masked Language Model (LM)", "content": "As illustrated in Figure 1, visits 1, 2, up to visit i correspond to the patient's diagnosis, medications, and procedures until the current visit i. Comonly, the PaCa risk prediction task is approached as a binary classification problem. In contrast, our proposed approach is to estimate the probability of a pancreatic cancer ICD-10 code filling the position of a MASK token added to the next visit (i+1). This reformulates the PaCa prediction task into a MLM task. This prediction task reformulation was technically achievable through two main modifications. The first is the design of the outcome label. So instead of predicting directly if the patient will develop PaCa in the future (simple binary label: Yes/ No), we will predict if the patient will have any of the eight tokens representing the following ICD-10 codes for pancreatic cancer in any future visit, namely {C25.0 Malignant neoplasm of head of pancreas; C25.1 Malignant neoplasm of body of pancreas; C25.2 Malignant neoplasm of tail of pancreas; C25.3 Malignant neoplasm of pancreatic duct; C25.4 Malignant neoplasm of endocrine pancreas; C25.7 Malignant neoplasm of other parts of"}, {"title": "3.2.2. The Scheme of Utilizing Med-BERT for PaCa Onset Prediction", "content": "Figure 2 illustrates the scheme of utilizing Med-BERT for PaCa onset prediction. As illustrated in Figure 2, We used the full patient trajectory before the index date (visit i) in a sequential format where clinical codes including diagnosis, medication, and procedures are sorted by the event date and time within visits' sequences. We first mapped the clinical codes to the Med-BERT tokens. Then we project the data to the Med-BERT v2 model. Within Med-BERT, the tokens get projected to the token embedding layer and the visits sequence to the visit embedding layer to generate the static patient representation, which is then projected to the transformer layers to get the contextualized embeddings for each patient.\nIn the original PaCa onset prediction task, we initially derived patient contextualized representations with dimensions of [sequence length, embedding dimension]. Subsequently, by summing the values of the contextualized embeddings along the sequence length dimension, we generated a patient contextual vector with dimensions of [1, embedding dimension]. This patient contextual vector was then employed in the token prediction head as explained above in 3.2.1 as well as the model's binary classification prediction head to perform the PaCa onset prediction task. This approach is referred to as Med-BERT-BC in this paper."}, {"title": "3.2.3. Baseline Models", "content": "In our study, the baseline models employed include Logistic Regression (LR), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit (GRU), and Bidirectional GRU (BiGRU). These models were chosen due to their proven effectiveness in handling sequential data, allowing us to benchmark our proposed approach against well-established architectures in the field [4]."}, {"title": "3.2.4. Experimental Settings", "content": "We evaluated the model's performance using the Area Under the Receiver Operating Characteristic Curve (AUROC). The sequence length was fixed at 64, truncating any sequences that exceeded this length. Clinical diagnoses, procedures, and medications for each patient were arranged in reverse chronological order. By setting the sequence length to 64, we retained the most recent 64 codes up to the patient's last visit. The batch size was configured to 100. For the learning rate, we employed a value of 1e-3 for the Med-BERT models, GRU, and LSTM, while a learning rate of 1e-5 was used for BiGRU and BiLSTM."}, {"title": "4. Results", "content": "We assessed the performance of all models in both few-shot scenarios and fully supervised settings. The data sample sizes ranged in [10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000, 100000], as well as the full dataset. For data sizes of 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, and 1000, we used an equal split of positive and negative instances for both the training and validation datasets. For example, with a data size of 10, we utilized 5 positive instances and 5 negative instances for both fine-tuning and validation. For data sizes of 2000, 3000, 4000, 5000, and 100,000, we employed the entire validation dataset for validation, while maintaining an equal split of positive and negative instances for the fine-tuning dataset. For the full data size, the entire fine-tuning and validation datasets were used. Regardless of the experimental data size, the complete test dataset was used for testing. For each data size, we conducted 3 runs to calculate the mean and standard deviation of the AUROC.\nFigures 3, and 4 illustrate the AUC mean on the test set for Baseline Models, Med-BERT-BC, Med-BERT-Mask, and Med-BERT-Sum across data sample sizes ranging from 10 to 1000, and 1000 to 10000, respectively. The x-axis represents the training size, while the y-axis shows the AUC mean on the test set. From Figure 3 and Figure 4, it is evident that all models exhibit an increase in performance as the fine-tuning data size grows, indicating improved performance with more data. Notably, Med-BERT models, including Med-BERT-BC, Med-BERT-Sum and Med-BERT-Mask, consistently achieve significantly higher AUC scores compared to the baseline models, highlighting their superior performance.\nAs illustrated in Figure 3 and Figure 4, Med-BERT-Sum demonstrates a modest improvement in average AUC performance compared to Med-BERT-BC across almost all data sizes, highlighting the effectiveness of leveraging Med-BERT pretraining vocabulary token embeddings for the PaCa label tensor. Compared to Med-BERT-Sum, Med-BERT-Mask demonstrates a significant improvement in performance at very low fine-tuning sample sizes (10-500 samples) as shown in Supplementary Table 1. Furthermore, when compared to Med-BERT-BC, Med-BERT-Mask exhibits a marked increase in performance, with average AUC improvements ranging from 3% to 7% in few-shot scenarios with data sample sizes from 10 to 500 (Supplementary Table 1). This suggests that reformulating the prediction task into a MLM task enhances performance in few-shot settings.\nAs the training size increases, the performance of all three Med-BERT models stabilizes. When the data size is below 1000, Med-BERT-Mask continues to outperform the other models, achieving approximately 0.79 AUC with 1000 samples, which is 1% higher than Med-BERT-BC's 0.78 AUC. When the data size is larger than 1000, Med-BERT-BC and Med-BERT-Sum both exhibit performance improvements with increasing training sizes, with Med-BERT-BC reaching an AUC of approximately 0.82 at 10,000 samples. Med-BERT-Mask initially shows a decline in performance after 1000 samples, followed by a gradual improvement, but does not surpass the performance of Med-BERT-BC and Med-BERT-Sum beyond 1000 samples. Med-BERT-Sum achieves the highest AUC of approximately 0.83 with 10,000 training samples, consistently outperforming Med-BERT-Mask once the fine-tuning sample size exceeds 1000. Additionally, Med-BERT-Sum slightly surpasses Med-BERT-BC as training sizes increase, and consistently demonstrates superior performance compared to Med-BERT-BC across training sizes ranging from 2000 to the full fine-tuning set of 21,871 samples. These observations suggest that with sufficient training data, Med-BERT-BC performs well, while utilizing Med-BERT pretraining vocabulary token embeddings for the PaCa label tensor is advantageous in both few-shot scenarios and larger training cohorts.\nThe observed sharp decrease in AUC mean for training sizes between 40 and 50, as shown in Figure 3, may be attributed to the presence of outliers and the inherent variability in smaller datasets. To further validate the model's robustness, we conducted additional repeated experiments on smaller datasets with training sizes of less than 100, performing 10 runs to assess the consistency of the results. These findings are presented in Supplementary Figure 6. The results indicate that while outliers can occasionally impact performance in smaller datasets, the overall trend remains consistent. Notably, Med-BERT-Mask demonstrates robust performance with limited data, reinforcing the model's effectiveness under these conditions."}, {"title": "5. Discussion", "content": "Med-BERT-BC utilizes binary classification directly on the pancreatic cancer prediction task. Med-BERT-Sum uses the Med-BERT pretraining vocabulary token embeddings for the PaCa label tensor, which is the primary distinction from Med-BERT-BC. Med-BERT-Sum demonstrates slight superior performance compared to Med-BERT-BC across most data sizes (ranging from 10 to fully supervised setting), suggesting that utilizing the Med-BERT pretraining vocabulary token embeddings for the PaCa label tensor is effective for boosting Med-BERT. Med-BERT-Mask not only incorporates the Med-BERT pretraining vocabulary token embeddings but also reformulates the binary classification task into a MLM task, aligning with Med-BERT's pretraining objective. The observation that Med-BERT-Mask achieves significantly higher AUC scores compared to Med-BERT-BC with limited fine-tuning data underscores the efficacy of reformulating the PaCa prediction downstream task into a MLM framework as hypothesized. These findings collectively demonstrate that reformulating the PaCa prediction task into the formulation of the token prediction used for Med-BERT pre-training could enhance its predictive capabilities for pancreatic cancer even with the availability of few tens of cases data and equal numbers of controls. So for example with a 100 PaCa cases and 100 controls, we can fine-tune Med-BERT-Mask for PaCa prediction and achieve prediction accuracy of around 78%, which is similar to the AUC that can be achieved after fine-tuning a binary classification head on top of Med-BERT for 1000 samples. Consequently, this study encourages us to formulate disease prediction downstream tasks in a manner akin to the pretraining task format when utilizing foundation models like Med-BERT in order to maximize their performance in few shot settings.\nMed-BERT-Sum slightly outperforms Med-BERT-BC across all the data sizes, demonstrating the added value of using the pretraining vocabulary tokens as an intermediate label to predict. Med-BERT-Mask excels in few-shot scenarios due to its ability to effectively leverage pre-trained knowledge through task reformulation. This approach optimally utilizes the generalized patterns and representations from the pre-trained language model, enhancing performance with limited fine-tuning data. However, as the fine-tuning dataset size increases, the classification head can better converge in Med-BERT-BC, which allows the Med-BERT to learn more discriminative features tailored to the specific task of predicting PaCa onset. Therefore, the extensive task-specific data reduces the need for reformulation, as direct optimization yields better and stable results.\nIn the domain of clinical decision support, firstly, our method enhances the accuracy of PaCa prediction. By offering more reliable predictions, our approach can aid healthcare professionals in making better-informed decisions, ultimately leading to improved patient outcomes. This provides substantial benefits for the clinical field, including PaCa, other cancers, and even non-cancerous diseases. Furthermore, the challenge of diagnosing rare diseases is exacerbated by the limited datasets available for training models to achieve high performance with new patients. Our method's strong performance in few-shot scenarios demonstrates the feasibility of AI-based clinical decision support systems for rare diseases. This success addresses the unique challenge posed by infrequent diseases and encourages further innovation in AI-driven healthcare, potentially extending benefits to a broader range of medical applications.\nIf the clinical workflow incorporates BERT-based models like Med-BERT, our approach suggests reformulating the downstream task into a token prediction task (Med-BERT-Sum) or a masked token prediction task (Med-BERT-Mask) based on the availability of training data. Med-BERT-Mask is advantageous in scenarios with limited data, while Med-BERT-Sum performs better with larger datasets. If clinical workflows employ models that are not BERT-based, the downstream task can still be tailored to fit the pretraining task format of the specific model in use. This strategy involves analyzing the pretraining objective of the foundation model and reformulating the clinical prediction task to resemble this objective, which can significantly enhance the model's performance. However, we acknowledge the challenges in implementing this approach, such as the need for expertise in understanding and adapting the task formulations.\nOur method presents several limitations that warrant further investigation in future research. First, this study utilized the PaCa Onset Cohort, as employed in the original Med-BERT v2 study. Notably, this cohort is based on claims data, which is retrospective and generated for billing purposes rather than clinical objectives. Consequently, the sensitivity for pancreatic cancer within this dataset is relatively low. Furthermore, the recorded time for PaCa onset often lags behind the true diagnosis due to the inherent difficulty in diagnosing pancreatic cancer, which typically results in a billing entry only after a confirmed diagnosis. This characteristic leads to a high number of true positives, reducing the risk of false positives, and contributing to an elevated positive predictive value (PPV). Regarding the control group, we undertook rigorous steps to minimize false negatives by excluding all other cancer patients, including those with benign tumors, from the cohort. Ideally, validation against manual chart reviews would enhance accuracy; however, this study prioritized algorithm development, making this limitation beyond our current scope. In future work, we plan to utilize cohorts derived from clinical data instead of billing data to mitigate these issues. Additionally, the cohort used in this study provided a relatively balanced dataset for training and evaluation purposes. However, we acknowledge that this balanced distribution does not mirror real-world conditions, where the incidence of pancreatic cancer is significantly lower in the general population. In future research, addressing class imbalance during the cohort inclusion and exclusion stages will be critical. This could involve intentionally constructing an imbalanced cohort to better represent real-world scenarios, thereby enhancing the model's applicability in practice. Moreover, the current evaluation was restricted to the prediction of PaCa onset, which limits our understanding of the method's generalizability to different diseases and clinical contexts. To ensure robustness and broader applicability, future studies should incorporate evaluations across a diverse array of diseases, including various cancers and non-cancerous conditions. Finally, our testing was confined to a single clinical foundation model, Med-BERT. Future evaluations should extend to other clinical foundation models to comprehensively assess the method's performance."}, {"title": "6. Conclusions", "content": "In this study, we reformulated the downstream task of predicting the onset of PaCa to align with the token prediction used in Med-BERT pre-training. This reformulation enhanced Med-BERT fine-tuning efficacy, resulting in superior performance compared to the conventional BC prediction design in both few-shot and fully supervised settings. Our findings highlight the potential of leveraging foundation models more effectively by aligning downstream tasks with their pretraining objectives. This strategy offers a promising avenue for developing more robust AI clinical support systems for PaCa, other cancers, and non-cancerous diseases, thereby improving patient outcomes. Future research will focus on validating these findings across diverse cancer and non-cancer contexts, as well as on different foundation models, and exploring further optimizations to enhance cancer diagnosis systems.."}]}