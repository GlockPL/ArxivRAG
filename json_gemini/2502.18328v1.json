{"title": "FROM VISION TO SOUND: ADVANCING AUDIO ANOMALY\nDETECTION WITH VISION-BASED ALGORITHMS", "authors": ["Manuel Barusco", "Francesco Borsatti", "Davide Dalle Pezze", "Francesco Paissan", "Elisabetta Farella", "Gian Antonio Susto"], "abstract": "Recent advances in Visual Anomaly Detection (VAD) have introduced sophisticated algorithms\nleveraging embeddings generated by pre-trained feature extractors. Inspired by these developments,\nwe investigate the adaptation of such algorithms to the audio domain to address the problem of Audio\nAnomaly Detection (AAD). Unlike most existing AAD methods, which primarily classify anoma-\nlous samples, our approach introduces fine-grained temporal-frequency localization of anomalies\nwithin the spectrogram, significantly improving explainability. This capability enables a more pre-\ncise understanding of where and when anomalies occur, making the results more actionable for end\nusers. We evaluate our approach on industrial and environmental benchmarks, demonstrating the\neffectiveness of VAD techniques in detecting anomalies in audio signals. Moreover, they improve\nexplainability by enabling localized anomaly identification, making audio anomaly detection sys-\ntems more interpretable and practical.", "sections": [{"title": "1 Introduction", "content": "Audio anomaly detection (AAD) is the task of detecting unexpected or out-of-distribution sounds in audio sequences.\nThis task finds many real-world applications, especially in the industrial domain, e.g., for quality control and predictive\nmaintenance [1-3]. Beyond industry, AAD also plays a key role in environmental surveillance, enhancing public safety\nthrough the detection of anomalous acoustic events in urban areas [4-6]. Recently, AAD systems using deep neural\nnetworks have achieved remarkable accuracy [1,7,8]. In [9], the authors proposed using an autoencoder. While\nmore recent methods are proposed in literature [1, 10], usually based on the autoencoder concept, a major limitation\nof existing methods is their lack of explainability. These models operate as black boxes, providing anomaly scores\nwithout explaining which parts of the audio are responsible for the anomaly detection. This opacity limits their\nusability in critical applications where understanding the decision-making process is essential. Meanwhile, significant\nadvancements have been made in Visual Anomaly Detection (VAD). In particular, most recent algorithms propose to\nleverage embeddings from pre-trained feature extractors to detect anomalies on each patch in the feature map [11],\nas explained in Section 2.2. Therefore, they can predict anomaly scores at the pixel level; this makes them more\nexplainable, as they highlight the portions of the input images deemed out-of-distribution, commonly referred to as\nanomaly maps. These maps resemble the saliency maps used in recent audio explainability literature [12]. Given\ntheir high explainability and practical value, such techniques are highly valuable in real-world applications where\nunderstanding why an input is anomalous is as important as detecting the anomaly itself.\nBuilding on these insights, we explore the adaptation of VAD techniques to the audio domain, investigating their\neffectiveness in AAD and their ability to generate meaningful and explainable anomaly maps. Unlike most existing\nAAD methods, our approaches not only detect anomalous samples but also provide fine-grained temporal-frequency\nlocalization of anomalies within the spectrogram (Fig. 1). This feature significantly improves explainability, providing\nusers with clearer insights and facilitating more informed decision-making.\nAs an additional contribution, we also propose a novel set of evaluation metrics to assess how effectively algorithms\nidentify abnormal regions in spectrograms, addressing a significant gap in the current literature where such evaluation\nmethods are (to the best of our knowledge) absent."}, {"title": "2 Methodology", "content": "The following section describes the framework adopted to evaluate the VAD algorithms in the audio domain perform-\ning anomaly detection in the unsupervised setting. The framework is presented in Fig. 2. The practical advantage of\nconsidering an unsupervised setting is eliminating the need for an expensive and time-consuming process to acquire\nand label (rare) abnormal samples.\nMost of the current research in the field of VAD is focused on feature-based methods. Despite each algorithm pro-\ncessing the input images differently, most of them work on the embeddings produced by a pre-trained feature extractor.\nThe advantage of using a pre-trained model is that the obtained embeddings are generic and capture high-level features\nthat are usable across several contexts. Moreover, leveraging pre-trained models has the practical advantage of reduc-\ning computational costs, as they eliminate the need for expensive model training. Furthermore, when training a model\nfrom scratch using domain-specific audio data, the model may struggle to generate sufficiently rich representations\nthat can be used effectively.\nA peculiarity of VAD methods is that a generic feature map $H \\times W \\times C$ can be split into $H \\cdot W$ vectors of dimension\n$C$, and usually, their abnormality is assessed separately for each vector. Each of these vectors is associated with a\nspecific region (or patch) of the input image. In other words, when operating at the patch level, these methods focus\non small regions of the image rather than the image as a whole, which helps the model identify abnormal regions more\neasily and, by extension, classify the entire sample.\nMoreover, this helps to improve the explainability since the model can not only determine whether a sample is abnor-\nmal but can also identify the specific regions of the image that are considered suspicious (see Fig 1 for an example).\nGiven the many advantages of VAD algorithms, their adoption in the audio domain can have a significant impact.\nTherefore, we focus on applying features-based VAD methods to the audio domain. In our framework, after trans-\nforming the waveform into an adequate spectrogram, the produced spectrogram is used as input to a feature extractor\nto obtain an intermediate generic representation. In our process, an appropriate pre-trained model for the audio domain\nis selected to obtain good embedding representations (see Sec. 3.3). These embeddings are then used to train the VAD\nalgorithms (a brief description of each tested method is provided in Sec. 2.2), and the resulting output is used as a"}, {"title": "2.2 Considered VAD Approaches", "content": "Usually, the feature-based VAD algorithms are commonly categorized into four distinct groups: memory-bank ap-\nproaches, teacher-student approaches, one-class classification methods, and normalizing-flow approaches. For\neach tested method, we provide a brief description below:\nPatchCore: This is a memory-bank method that uses additional memory to store a set of patches embeddings [11].\nDuring inference, a nearest-neighbor lookup is applied to calculate the anomaly score of each input image patch.\nPadim: This is also a memory-bank method. However, instead of storing the patches embeddings, Padim proposes\nthat each patch position in the input image can be characterized by a multivariate Gaussian distribution. During the\ninference process, for a given test image, the Mahalanobis distance is computed for each patch, providing its anomaly\nscore [13].\nCFA: This is a memory-bank approach that, given the patch feature vectors, trains a Patch Descriptor Network (PDN)\nto increase the density of normal features vectors and make it easier to separate normal and abnormal patches [14].\nSTFPM: This approach belongs to the student-teacher category. As the name suggests, it utilizes an architecture com-\nprising two separate models: a student (randomly initialized) and a teacher (pre-trained). During training, the student\naims to produce the same embeddings as the teacher for the normal samples patches, causing during inference high\ndifferences when examining abnormal samples [15]."}, {"title": "3 Experimental Setting", "content": "In the current research literature, AAD is considered for two types of applications.\nThe first is industrial applications, where AAD can be used to detect equipment failures or abnormal behaviors. The\nsecond is environmental applications, where AAD can enhance urban safety or aid in environmental disaster preven-\ntion."}, {"title": "3.2 Metrics", "content": "Various evaluation metrics are commonly employed to assess the performance of AD techniques."}, {"title": "3.2.1 Sample-level", "content": "Traditional evaluation of AD techniques relies on multiple metrics to provide a comprehensive assessment of perfor-\nmance. At the sample level, two metrics are the most commonly employed: F1 and ROC. While ROC is useful since it\nis independent by a specific threshold, it is much less robust in the presence of imbalanced datasets, which is common\nin anomaly detection where the normal class is more frequent than the anomalous one."}, {"title": "3.2.2 Temporal-Frequency Localization", "content": "One of the key contributions of this work is to evaluate VAD algorithms for AAD beyond the sample-level analysis\nand focus on spectrogram analysis, enabling the detection of the specific anomalous regions of the spectrogram.\nWe introduce novel metrics to assess how effectively algorithms identify abnormal regions in spectrograms, addressing\na significant gap in the current literature where such evaluation methods are (to the best of our knowledge) absent.\nGiven the anomaly map produced by a VAD approach (see Fig. 4.b for an example) and the ground truth, the F1,\nROC and AU-PRO [20] metrics are calculated. The ground truth mask of the anomalous spectrogram is created by\nidentifying the top 40% most energy-intensive values in the spectrogram area where the anomalous sound is injected."}, {"title": "3.2.3 Temporal Localization", "content": "While the previous metrics allow the end user to achieve a high comprehension level of where the anomalous regions\nare located inside the spectrogram, they could be excessively informative. Therefore, we also evaluate the ability of the\nmodel to provide where the anomaly is present only on the temporal axis. Specifically, the model identifies all temporal\ninstants where an anomaly occurs. To define the ground truth on the temporal axis, for each temporal instant where\nthe anomaly sound is injected, we sum the values of all the frequencies $E_t = \\sum_{f=1}^{F} log(M_{t,f})$. Then, we define as\nanomalous all the temporal instants where the energy is above the 50-th percentile, formally: $Anomaly(t) = I\\{E_t>P_{50}\\}$\nwhere $P_{50}$ represents the 50th percentile of the values of the anomalous spectrogram and $I$ is the indicator function.\nGiven the model anomaly map $M$, we identify the anomaly score of a temporal instant $t$ as the average of the five most\nanomalous values in $M_t$. Using the ground truth and predictions as defined, we calculate the ROC and F1 metrics."}, {"title": "3.2.4 Faithfulness", "content": "In addition, we evaluate the ability of the model to isolate the audio signal from the input. This helps to understand\nhow well the model identifies the anomalous part of the spectrogram. To achieve this, we calculate the filtered audio\nas follows: $x' = x \\odot M$. Next, we assess the quality of the obtained signal using the metric Faithfulness on Spectra\n(FF v1) as defined in [21]. The metric is calculated by measuring the difference in model probability predictions\n(at the sample level) before and after the filtering. More formally, let's define the model as $f$ where $f(x)$ produces\nthe sample-level prediction of a generic sample $x$. Then we calculate FF as follows: $FF = f(x) - f(x')$. If the\nvalue is high, the prediction changes significantly, transitioning from a highly anomalous signal to a normal signal\n(or vice-versa). Therefore, if FF is high, the filtered signal was masked correctly, effectively removing the anomalous\npart from the contaminated signal. Since $x'$ can have holes in the spectrogram caused by areas in $M$ with very low\nanomaly scores, we formalized the Faithfulness on Spectra v2 (FF v2) which is calculated as before but considering\n$x' = x \\odot (1 - M) + bg \\odot M$ where $bg$ is the background sound used for generating the contaminated signal. $bg$ is\nused for covering the \"holes\" in the spectrogram."}, {"title": "3.3 Models", "content": "As discussed in Sec. 2, our tested methods perform on embedding produced by a pre-trained feature extractor. This\nmeans that they can exploit generic and high-level representations produced by models pre-trained on large datasets\nof similar domains. However, this also indicates that the quality of the representations produced by the chosen feature\nextractor significantly influences the performance of the VAD algorithms. In other words, selecting the most correct\nfeature extractor is an extremely relevant phase in obtaining good results.\nIn our work, we considered as a feature extractor the CNN14 from the CLAP model [22]. CNN14 is a convolutional\nneural network trained in a contrastive learning framework, where the model learns to match audio content with\ncorresponding text descriptions.\nFrom previous studies in VAD, the optimal choice of layers is a set that includes low-level, medium-level, and high-\nlevel layers [23]. This is because different layers represent different levels of resolution, and a representation that\ncombines different resolutions helps to look at both general and specific features. Therefore, we similarly select a\nset of layers that provide information on different resolution levels. Specifically, we select the layers conv_block2,\nconv_block3, conv_block4 We compare the VAD models with a Baseline introduced in [9], which is a simple autoen-coder."}, {"title": "4 Results", "content": "We begin by examining the results for the industrial domain (MIMII Dataset) and then continue examining the results\nfor the environmental domain (EnvMix Dataset).\nIn the MIMMI Dataset, we compare the baseline provided in [24] with our four tested VAD algorithms: CFA, Padim,\nPatchCore, and STFPM. Our results show that in three out of the four categories, the VAD algorithms show superior"}, {"title": "4.2 Explainability Results", "content": "As stated above, PatchCore performs well on audio signals of the EnvMix Dataset with high values of ROC for sample,\nspectrogram, and temporal levels. In other words, PatchCore obtains good results in identifying not only the presence\nof anomalies in the audio signal but also the localization of the anomaly in the spectrogram and which temporal\ninstants are associated with the anomalous signal. We can examine this deeply by visual examination, as shown in\nFig. 1. Here, the mixed signal is shown in the first plot, while in the second plot, the anomalous signal is added to the\nnormal signal to obtain the mixed audio. Then, the third figure shows the anomaly map produced by one of the VAD\nalgorithms. We can see visually how the model detects the part where the anomaly is present well.\nRegarding the Faithfulness metric, from the results reported in Tab. 2 we can see that the obtained values are quite low.\nThis is caused by the fact that the chosen AD models are very sensitive to every change in the input spectrogram: every\ndeviation from the normal input distribution is anomalous. We tried two versions of the metric that change the input\nspectrograms in two different ways. The FF v2 tries to tackle the problem by producing less anomalous spectrograms.\nHowever, in both cases, when the model produces a not-accurate anomaly map, the obtained spectrogram can have\nsome artifacts that can trigger the model again."}, {"title": "5 Conclusion", "content": "The results demonstrate the capacity of the VAD methods to identify anomalous samples, showing the potential of\nadapting VAD techniques to the audio domain.\nMoreover, this is achieved while enabling more explainable and practical audio anomaly detection systems by localiz-\ning the anomalous regions of the spectrogram. Unlike most existing approaches in the AAD literature, our approaches\ndetect anomalous samples and provide fine-grained temporal-frequency localization of anomalies within the spectro-\ngram. This added level of detail significantly enhances the explainability of the results, making them particularly\nvaluable for informed decision-making by end users.\nWhile the obtained results show the potential of VAD algorithms in the audio domain, future work is required to\nimprove the methods' performance to accompany the explainability results with strong detection performance.\nA promising future research direction is to explore the role of feature extractors by testing different models. This is\nbecause, for the tested VAD algorithms, the performance heavily depends on the quality of the used feature represen-\ntations. In particular, it would be interesting to analyze if employing self-supervised learning methods could help the\nmodel generate more effective feature representations for VAD algorithms.\nIn addition, while several novel metrics to evaluate the interpretability of the methods were introduced in this work, a\nbetter formalization of the Faithfulness metric for the AAD problem remains necessary."}]}