{"title": "Mathematics and Machine Creativity: A Survey on Bridging Mathematics with AI", "authors": ["Shizhe Liang", "Wei Zhang", "Tianyang Zhong"], "abstract": "This paper presents a comprehensive survey on the applications of artificial intelligence (AI) in mathematical research, highlighting the transformative role AI has begun to play in this domain. Traditionally, AI advancements have heavily relied on theoretical foundations from fields like mathematics and statistics. However, recent developments in AI, particularly in reinforcement learning (RL) and large language models (LLMs), have demonstrated the potential for AI to contribute back to mathematics, offering flexible algorithmic frameworks and powerful inductive reasoning capabilities that support various aspects of mathematical research. This survey aims to establish a bridge between AI and mathematics, providing insights into the mutual benefits and fostering deeper interdisciplinary understanding.\nIn particular, we argue that while current AI and LLMs may struggle with complex deductive reasoning, their inherent creativity holds significant potential to support and inspire mathematical research. This creative capability, often overlooked, could be the key to unlocking new perspectives and methodologies in mathematics. Furthermore, we address the lack of cross-disciplinary communication: mathematicians may not fully comprehend the latest advances in AI, while AI researchers frequently prioritize benchmarks and standardized testing over AI's applications in frontier mathematical research. This paper seeks to close that gap, offering a detailed exploration of AI's basic knowledge, its strengths, and its emerging applications in the mathematical sciences.", "sections": [{"title": "1. Introduction", "content": "In this transformative era, Artificial Intelligence (AI) has emerged as a catalyst for profound advancements, painting a vivid picture of a promising future of scientific discoveries [Zhong et al., 2024, Yang et al., 2024, Wang et al., 2024b]. From deep neural networks (DNNs) enhancing human decision-making to uncovering fascinating correlations within vast datasets [Samek et al., 2021], AI continues to revolutionize human approaches to complex challenges. More recently, the development of Large Language Models (LLMs) has marked a paradigm shift in AI, introducing unparalleled proficiency in processing and generating human-like language. This innovation has spurred significant progress across a wide array of domains, including healthcare, public health, engineering, science, agriculture, education, creative arts, humanities, and even mathematics, by automating complex problem-solving processes and enabling nuanced analysis of specialized texts [Zhong et al., 2024]. In mathematics and sciences, LLMs are paving the way for deeper exploration of the interplay between linguistic constructs and mathematical logic, thereby fostering new methods for tackling age-old problems.\nMathematical problems often present as intricate challenges without straightforward solutions, requiring individuals to rely on their reasoning and strategic planning to develop solutions [S\u00e4fstr\u00f6m et al., 2024]. Unlike routine tasks that can be addressed through established"}, {"title": "2. Background", "content": "This section offers a concise overview of the AI techniques featured in this survey, delving into their underlying principles, methodologies, and practical applications. Additionally, we explore the background of recent controversies regarding the mathematical capabilities of modern Large Language Models (LLMs). We then articulate our perspective and motivation for composing this article, aiming to contribute constructively to this ongoing dialogue and to highlight the potential synergies between AI and mathematics."}, {"title": "2.1. Background on AI", "content": "The evolution of artificial intelligence (AI) from traditional AI to generative AI marks a profound shift in computational paradigms. Traditional AI established the foundation of symbolic reasoning [Taghvaie et al., 2023]; Machine Learning (ML) provided powerful tools for data-driven analysis [Mahesh, 2020]; Reinforcement Learning (RL) offered novel approaches to dynamic systems [Kaelbling et al., 1996], and generative AI opened new frontiers in automation and discovery [Cao et al., 2023]. As AI technologies continue to evolve, their integration with mathematics promises further advancements in theory, application, and innovation.\nTraditional AI. Traditional AI relies on rule-based systems and symbolic reasoning, focusing on explicitly programmed logic and decision-making frameworks. These techniques prioritize deterministic solutions and are heavily rooted in formal logic and representation.\nSearch algorithms form the backbone of traditional AI, particularly in addressing combinatorial and optimization problems. For example, breadth-first search [Beamer et al., 2013] and depth-first search [Tarjan, 1972] were among the earliest strategies for exploring solution spaces systematically. However, naive exploration is inefficient or impractical when the search space is prohibitively large or dynamically changing, such as in game theory, planning, and decision-making processes. In such cases, heuristic search methods (a.k.a. best-first search), pruning methods [Fuller et al., 1973], and other optimization techniques are employed to narrow the search space, improving efficiency without compromising accuracy.\nSome traditional AI algorithms are used to solve combinatorial optimization problems, including those in graph theory [Zhang et al., 2017] and integer programming [Zhang et al., 2023]. Advanced search techniques like Monte-Carlo Tree Search (MCTS) [Coulom, 2007] will be frequently mentioned in Section 3.\nMachine Learning (ML). The advent of Machine Learning marked a transition from rule-based approaches to data-driven methodologies, emphasizing pattern recognition and statistical inference."}, {"title": "2.2. Our contributions", "content": "The question of whether AI can genuinely perform mathematical reasoning remains a subject of active debate. Critics highlight their limitations in handling abstract concepts and their challenges in contributing meaningfully to mathematical research, while proponents point to their potential as complementary tools for exploration and discovery. By positioning our work within this dialogue, we aim to provide a balanced perspective that acknowledges both the limitations and opportunities of these models. Our goal is to demonstrate how AI tools, despite their shortcomings, can complement mathematical research in meaningful ways, fostering a deeper understanding of the evolving role of AI in mathematics.\nThis survey examines three key applications of AI, including but not limited to LLMs, in mathematical research:\nMachine-assisted proofs (Section 3).\nPattern recognition and theoretical exploration (Section 4).\nExplicit construction of mathematical objects (Section 5).\nOur contributions are two-fold:\nBridging Disciplinary Gaps. Al researchers often focus on benchmarks and overlook the potential applications of AI in mathematical research. On the other hand, mathematicians may lack a deep understanding of AI's evolving capabilities. This survey aims to foster a shared knowledge base, bridge the divide between these communities and promote interdisciplinary collaboration."}, {"title": "3. Machine-Assisted Proofs", "content": "Theorem-proving is a cornerstone of mathematics. Consequently, machine-assisted proofs are probably one of the most intuitive applications of Artificial Intelligence (AI) in mathematics, yet they are also one of the most misunderstood. The term \"machine-assisted proofs\" actually encompasses a range of different tasks. In particular, the naive interpretation of this term, namely, \"fully independent, end-to-end, whole proof generation\", is a rather controversial one in this domain. In this section, we provide a comprehensive overview of the current landscape of machine-assisted proofs."}, {"title": "3.1. Motivation and foundational tools", "content": "The history of automated reasoning dates back to the 1950-60s [Newell and Simon, 1956, Davis, 1957, Davis and Putnam, 1960], and some practical mathematical tools became available in the 1970s [de Bruijn, 1970, Trybulec, 1991]. The motivation for developing such tools stemmed from the fact that proofs for some complex mathematical problems may be extremely lengthy, involving numerous logical steps or extensive case-by-case analysis (a.k.a. proof by exhaustion). For example, the proof of the four-color theorem, one of the most famous mathematical problems solved with computer assistance, involved the analysis of 633 subcases [Gonthier, 2008]. Computer algorithms, embedded with rigorous deductive rules, could assist mathematicians by verifying the correctness of a proof or by automatically handling the proof-by-exhaustion steps. It is important to note that in these practices the machine's role is complementary. Human users would provide all the creative reasoning steps, and machines would primarily support routine computation or verification. This stands in contrast to certain logic solvers, such as SAT (Boolean satisfiability problem) solvers or some first-order logic solvers, where machines independently produce answers without human intervention. These solvers are commonly referred to as automatic theorem provers (ATPs), and some notable examples include E [Schulz, 2002] and Vampire [Riazanov and Voronkov, 2002]. These tools have been shown to be useful in many situations and have been integrated into advanced tools to solve first-order subproblems [B\u00f6hme and Nipkow, 2010]. For a comprehensive overview of early automated reasoning and machine-assisted proof approaches, see the detailed article [Harrison et al., 2014].\nThe basic tools in the field of machine-assisted proofs include a formal language for expressing mathematical statements and a back-end program which interprets these statements. We will refer to the back-end program as proof engine. The formal language and the proof engine, much like a programming language and its interpreter, provide an unambiguous method of automated verification. These tools are usually organized into an interactive theorem-proving (ITP) environment, known as a proof assistant, where the user manually inputs the formal proof, and the proof engine performs verification. Some of the most popular proof assistants include Mizar [Trybulec, 1991], Metamath [Megill, 2006], Isabelle/HOL [Nipkow et al., 2002], Coq [The Coq development team, 2004] and Lean [Moura and Ullrich, 2021].\nProof assistants remain the most widely used paradigm today, yet they have two notable limitations:"}, {"title": "3.2. Automated formal proof generation", "content": "This subsection discusses recent advancements in addressing limitation 1, that traditional proof assistants are not effective at generating reasoning steps. New tools have been proposed with the capability of automatically generating proof steps or even complete proofs. Many such tools share several key characteristics:\nFormal input and output: Both their inputs and outputs are formatted in formal languages, ensuring compatibility with proof engines.\nInterfacing with proof assistants: They interface with (or are integrated into) existing proof assistants, which verify the correctness of the generated proof steps to ensure reliability.\nUse of Machine Learning: Many of these tools incorporate machine learning techniques to predict plausible proof steps.\nThere are a collection of tools that use techniques including neural networks or reinforcement learning for proof generation tasks. For example, Holophrasm [Whalen, 2016] is an automated theorem proving tool that generates proofs in Metamath formal language [Megill, 2006], and interfaces with Metamath's proof engine to ensure correctness. It employs recurrent neural networks (RNNs) to predict proof steps and can use tree search strategies to produce complete proofs. HOList [Bansal et al., 2019] is an automated theorem proving tool built on top of the HOL Light proof assistant [Harrison, 1996]. It follows a reinforcement learning paradigm when training the model to perform proof step generation, and uses simple breadth-first-search to find the correct sequence of proof steps during test time.\nGamePad [Huang et al., 2018] is an environment designed to explore various machine learning methods while interfacing with Coq [The Coq development team, 2004] proof assistant. The authors experimented multiple machine learning models for the task of predicting proof length and the task of predicting proof steps. ASTactic [Yang and Deng, 2019] also interfaces with Coq. It uses TreeLSTM [Tai et al., 2015] to train the proof step prediction model, and uses simple depth-first-search to find the correct sequence of proof steps during test time. Tactician [Blaauwbroek et al., 2020a, Blaauwbroek et al., 2020b] directly integrates with Coq. As an interactive tool, Tactician can makes proof step suggestions while empowers users to accept, modify, or reject the suggested steps. Tactician employs lightweight machine learning methods to predict proof steps, and is capable to generating complete proofs by utilizing search processes. The interactive nature of Tactician can be favorable to working mathematicians, and is embraced by some later works.\nTacticToe [Gauthier et al., 2021] and TacticZero [Wu et al., 2021] are automated theorem proving tools that interface with the HOL4 proof assistant [Slind and Norrish, 2008]. The former uses lightweight machine learning techniques for proof step prediction, and employs Monte Carlo Tree Search (MCTS) to produce complete proofs. The later leverages the deep reinforcement learning methodology to learn to perform proof step prediction as well complete proof generation.\nRecently, inspired by the wide applications of Large Language Models (LLMs) in scientific fields, many studies employed transformer [Vaswani et al., 2017]-based language models for developing automated theorem proving tools. One advantage of such approaches is that language models can effectively process sequential data of various formats, and can be trained with little human-label data, greatly simplifies the data pre-processing and labeling process of earlier approaches.\nGPT-f [Polu and Sutskever, 2020] is a language model-based automated theorem proving tool interfacing with Metamath. By training on large collection of mathematical data (e.g. math-related articles on arXiv) and existing Metamath proofs, GPT-f is able to generate new proof steps that adhere to the syntactic and semantic rules of Metamath. It employs a search process for whole proof generation by sampling multiple proof steps at each state. Proof Artifact"}, {"title": "3.3. Autoformalization", "content": "This subsection introduces recent advancements in addressing limitation 2, the learning cost of formal languages. Imagine a scenario where a mathematician wants to use a proof assistant to verify the correctness of a candidate natural language proof for a complex theorem. To do so, the user must first rewrite, or \"formalize\", the theorem and its proof in the corresponding formal language. However, formalization is \u201cnotoriously labor-intensive\" [Han et al., 2021]. For example, the formalization of the Kepler conjecture [Hales et al., 2017] took over 20 man-years of work [Szegedy, 2020]. Recently, autoformalization the development of systems that can automatically translate natural language mathematics into formal language has garnered significant interest among mathematicians and AI researchers. Conversely, the reverse process, known as informalization, involves translating formal mathematics into natural language. This task is generally easier to automate than autoformalization [Jiang et al., 2023a] and holds potential utility in specific contexts.\nDespite some early rule-based [Bancerek and Carlson, 1994, Bancerek, 2006] or statistical learning-based [Kaliszyk et al., 2015, Kaliszyk et al., 2017] approaches, [Wang et al., 2018, Wang et al., 2020] were the first to apply deep learning approaches to translating informal mathematics written in LATEX into formal mathematics written in Mizar [Trybulec, 1991]. They formulated autoinformalization as a neural translation task, and utilized recurrent neural networks to handle it. However, the fundamental difficulty is the scarcity of high quality natural language formal language (NL-FL) datasets datasets consisting of pairs of sequences expressing the same meaning in natural language and formal language.\nLarge Language Models (LLMs) provide a new opportunity to this domain. [Wu et al., 2022] noticed that existing LLMs (e.g. PaLM [Google Research, 2022] and Codex [Chen et al., 2021]) are capable of autoformalizing natural language statements into formal languages like Isabelle with merely in-context/few-shot learning. Their observations were confirmed by [Agrawal et al., 2022], who in addition used Codex to perform autoformalization of proofs. [Jiang et al., 2023b] experimented a slightly different autoformalization task on proofs: instead of asking the LLM to autoformalize all the details, they only ask for a formal proof sketch, that is, a partial proof that outlines high-level conjecture statements. They later invoked existing theorem proving tools to fill-in the gaps. We will revisit this work in the next subsection. Llemma [Azerbayev et al., 2024] is a series of LLMs trained primarily on mathematical contents (a.k.a. domain-specific LLMs for math). In addition to other mathematical reasoning tasks, it is able to autoformalize informal proofs into Isabelle formal language when provided with inputs of the format of (informal theorem, formal theorem, informal proof)-triples.\n[Patel et al., 2024], inspired by an error analysis provided in [Wu et al., 2022] that a majority of the autoformalization errors were due to the mismatch between natural language and formal definitions, experimented with a two-stage approach: (1) autoformalizing theorems to a formal language with placeholder names and (2) linking the placeholders to the actual definitions. [Lu et al., 2024b] introduced another technique, process-supervised verifier, which is trained using the feedback from the Lean 4 proof engine when training the autoformalization model. This"}, {"title": "3.4. End-to-End proof generation", "content": "In this last subsection we discuss end-to-end proof generation, by which we mean the process of taking as input a natural language mathematical statement and outputting a complete proof (in natural or formal language).\nGiven that autoformalization can translate natural language statements to formal statements, and that existing formal theorem-proving tools have reached reliable capabilities, a natural way is to combine these two components. Indeed many approaches followed this pipeline, though there are two clear difficulties:\n(i) This approach critically depends on the correctness of the autoformalization step.\n(ii) The formal language output is not easily understandable to humans.\nWe start by discussing the recent announcement from Google regarding their new math problem-solving model, AlphaProof, which reportedly achieved a silver-medal standard in IMO 2024 [AlphaProof and AlphaGeometry teams, 2024]. The model comprises two main components: a formalizer network and a solver network. The formalizer network is designed to translate natural language problems into Lean formal language, while the solver network generates formal proofs for these problems.\nHowever, we argue that AlphaProof's reported performance on IMO 2024 may be overestimated, and the claims surrounding it are exaggerated. First, it has been reported that during testing, the problems were not autoformalized by the formalizer, but were instead manually translated into formal language, and hence avoided difficulty (i) completely. Second, while official IMO participants solve problems within two sessions of 4.5 hours each, AlphaProof required up to three days to solve certain problems. These limitations highlight the need for a more cautious assessment of AlphaProof's capability of independently solving mathematical problems.\nDraft, Sketch, and Proof (DSP) [Jiang et al., 2023b] is a model that employs a similar but slightly different pipeline. They proposed using informal proofs to guide the generation of formal proofs. More precisely, DSP's workflow is divided into three stages: first, given an informal"}, {"title": "4. Pattern Recognition and Theoretical Exploration", "content": "Theorem proving is not the only task of mathematics. Terence Tao, one of the most renowned mathematicians, once noted that \"there's more to mathematics than rigor and proofs\" [Tao, 2016]. Indeed, theoretical breakthroughs often hinge on the ability to recognize hidden patterns, uncover deep connections between seemingly unrelated concepts, and develop intuitive frameworks that guide further exploration. In this section, we explore how AI can facilitate math theoretical discoveries through collaboration with human researchers.\nAs data technologies continue to advance and computational power steadily increases, the process of achieving theoretical breakthroughs in mathematics and other scientific disciplines is shifting. Traditional bottom-up, first-principle-driven methodologies are increasingly complemented by top-down, data-driven approaches [He, 2018, He, 2021, He, 2024]. In some subfields of mathematics, such as Combinatorics and Number Theory, large datasets, containing discrete but complex high-dimensional data, are becoming increasingly prevalent. While human researchers may struggle with identifying patterns within such data, supervised machine learning models, which are inherently designed as powerful function approximators, excel at uncovering patterns and relationships in data.\nThe complementarity between machine and human strengths forms the basis for a natural collaboration framework. Machines, leveraging their ability to detect patterns in mathematical"}, {"title": "5. Explicit Construction of Mathematical Objects", "content": "In this section, we examine how AI can assist in the explicit construction of mathematical objects. Here \"object\" is a generic term and we refrain from giving a precise definition. It can refer to examples/counterexamples, functions, sequences of operations, or even algorithms, as long as they are explicit and definitive. While this task shares similarities with the hypothesis search discussed in Section 4, it has a distinct focus: instead of suggesting patterns that later can be verified by humans, this task aims to construct objects explicitly. Notably, this area has already seen the development of two established frameworks: one leveraging reinforcement learning (RL) and the other utilizing language model-based search."}, {"title": "5.1. Reinforcement Learning (RL)-based Construction", "content": "Reinforcement learning (RL), the branch of machine learning centered on decision-making and sequential optimization, achieved great successes in games, such as the model AlphaZero [Silver et al., 2017] in the game of Go. Due to the flexibility of the RL-framework, recent studies have applied it for construction of mathematical objects.\nA series of studies [Gukov et al., 2020, Gukov et al., 2023] applied RL to Knot Theory. Recall that a knot is an embedding of the circle in the 3-D space. The standard embedding of the circle is also called the unknot. One of the fundamental computational question is to determine if a given knot is equivalent to the unknot, i.e. if a given knot can be continuously deformed into the unknot. [Gukov et al., 2020] used an RL framework to solve the problem of constructing a sequence of allowed operations that deforms a given knot to the unknot. In [Gukov et al., 2023], the knot is allowed to be deformed into more than one unknot, by allowing one more operation than before.\n[Wagner, 2021] applied RL to the construction of counterexamples to open conjectures in Combinatorics and Graph Theory. In their work, construction is formulated as a sequential decision-making process, where an object is constructed one piece at a time. Some human-designed heuristics (i.e. reward functions) will determine how good a state or action is and hence will guide the construction process. A similar approach was used in [Mehrabian et al., 2024] to for explicit construction in extremal graph theory.\nIn addition, RL was also used in [Fawzi et al., 2022] for constructing faster algorithms for matrix multiplication, in [Bidi et al., 2023] for constructing stabilizing controls for dynamic systems, and in [Farahmand et al., 2017] for designing PDE controls."}, {"title": "5.2. Language Model-based Construction", "content": "While RL can be applied to construction tasks where the construction process can be formulated a sequential decision-making process, language model-based approaches offer another versatile framework."}, {"title": "6. Public Acceptance and Impacts on Education", "content": "6.1. Public acceptance of new technologies for mathematics. Although computational tools have long been used to assist mathematical research, recent advancements in generative AI and Large Language Models (LLMs) have sparked an unprecedented surge of interest. In February 2024, Andrew Granville, a distinguished number theorist at the University of Montreal, posed a pivotal question at a UCLA workshop: \"We're looking at a particular question: will machines change math?\" Mathematics community are now engaging with this topic. Geordie Williamson of Univeristy of Syndney, for example, wrote \"there is great potential for interaction between mathematics and machine learning\", though \u201cin [his] experience, it remains hard to use deep learning to aid [his] mathematical research.\" [Williamson, 2023] Kevin Buzzard of Imperial College London noted, \"the fact that we have people like Fields medalists and other very famous big-shot mathematicians interested in the area now is an indication that it is 'hot' in a way that it did not used to be.\" [Castelvecchi, 2023] One such Fields Medalist, Terence Tao, has closely followed the advancements in AI-driven reasoning. Recently, he shared his insights: \"I have played a little bit with OpenAI's novel iteration of GPT, GPT-01-preview, which performs an initial reasoning step before running the LLM. It is certainly a more capable technology than previous iterations, though still struggling with the most advanced research mathematical tasks.\" [Tao, 2024]\nDespite this growing interest and promising developments, awareness of these tools remains uneven. Marijn Heule, a computer scientist at Carnegie Mellon University, observed that \"most mathematicians are completely unaware of these opportunities.\" As AI continues to evolve and refine its capabilities, it will likely challenge mathematicians to reconsider their methods, goals, and conceptual frameworks. In doing so, it may usher in a new era of mathematical exploration and collaboration one in which human reasoning and machine-generated insight interact to shape the future of the discipline."}, {"title": "6.2. Limits of AI capabilities", "content": "Although AI is steadily gaining traction in mathematical research, the prospect of AI independently conducting cutting-edge inquiries remains a significant challenge [Castelvecchi, 2023, He, 2024]. While future systems may become adept at generating sound proofs and mathematical objects, many researchers question whether they can truly innovate devising the kind of conceptual breakthroughs that define genuine mathematical creativity. At a recent symposium, experts stressed that current large language models (LLMs), which integrate symbolic and machine learning architectures, primarily operate within the confines of established structures drawn from their training data [Castelvecchi, 2023]. Such systems excel at rearranging learned information in linear or nonlinear forms to solve specific problems, but they have yet to demonstrate the capacity to introduce transformative new strategies akin to Galois's foundational use of group theory in polynomial analysis.\nErika Abraham, a computer scientist at RWTH Aachen University, further remarked, \"An AI system is only as smart as we program it to be.\" She elaborated that while AI might manage to prove certain theorems, it struggles to generate the abstract concepts that give rise to those theorems an integral component of mathematical innovation [Castelvecchi, 2023]. Melanie Mitchell, a cognitive scientist at the Santa Fe Institute, similarly observed that although AI can confirm the truth of established results, it falters at deriving the high-level abstractions needed to seed fundamentally new mathematical ideas [Castelvecchi, 2023].\nThese shortcomings are especially evident when AI tackles unsolved challenges like those presented in the new FrontierMath benchmark [Glazer et al., 2024]. Solving such complex"}, {"title": "6.3. Impacts on Mathematics Education", "content": "For decades, mathematics educators have grappled with how best to incorporate emerging technologies into their teaching and assessment practices [Kasneci et al., 2023, Engelbrecht and Borba, 2024]. Initially, tools like calculators were integrated into curricula to encourage the development and application of higher-order problem-solving skills, moving beyond rote computation and memorization. More recently, widely accessible digital resources including search engines and applications like Desmos or Photomath have further expanded the landscape of knowledge acquisition and problem-solving in mathematical education. As AI-driven tools and large language models (LLMs) such as GPT-40 and ol grow in sophistication, educators face a new set of challenges and opportunities [Kasneci et al., 2023].\nWhile AI can efficiently answer questions and deliver personalized learning experiences, it is crucial for educators to ensure that students engage with these technologies in ways that spark creativity, encourage collaboration, and inspire intellectual exploration, rather than simply relying on them as shortcuts to bypass meaningful learning [Zafrullah et al., 2023]. Recognizing that AI models can \u201challucinate\" and produce mathematically incorrect yet plausible-sounding responses, educators are increasingly committed to helping students develop the critical thinking skills necessary to detect and counter such errors. Importantly, the potential benefits of AI should not be dismissed. [Kumar et al., 2023] reported that LLM-based explanations positively impacted the study of high school-level mathematics Moreover, despite the presence of arithmetic errors and incorrect final answers, LLM-based explanations can still provide learning gain. For college-level mathematics education, [Collins et al., 2024] reported that, while machine-generated answers are sometimes incomplete or inaccurate, proactive interaction with these tools can still enrich students' learning experiences. This suggests the need for educators to reconsider their teaching methods and assessment strategies. Rather than assigning standardized, mechanically solvable exercises, teachers can encourage students to create their own examples, scrutinize the validity of AI-derived solutions, and actively reflect on their own reasoning.\nFrom an educational ethics standpoint, ensuring equitable access to AI technologies has emerged as a critical priority, as disparities in technology availability risk deepening existing educational inequalities [Engelbrecht and Borba, 2024]. Achieving this equity will require thoughtful policymaking, strategic resource allocation, and sustained efforts by educators, administrators, and governments. Organizations like the International Society for Technology in Education (ISTE) have begun providing guidance, encouraging teachers to carefully consider the full range of AI capabilities, potential risks, and ethical implications before integrating these tools into their classrooms [Zafrullah et al., 2023].\nAdditionally, Al's heavy reliance on large training corpora brings concerns about bias to the forefront. Since these models naturally mirror patterns embedded in their training data, they can inadvertently perpetuate stereotypes, inaccuracies, or other misleading notions. To counter these risks, it is essential for educators to equip students with the critical thinking skills needed to identify and question biased or unfounded assumptions arising from AI-generated solutions [Engelbrecht and Borba, 2024, Zafrullah et al., 2023].\nAs AI continues to advance, it stands poised to profoundly reshape mathematics education. By approaching these innovations thoughtfully\u2014balancing efficiency with critical engagement, striving for widespread accessibility, and consistently emphasizing conceptual depth educators can foster more meaningful, personalized, and transformative learning experiences. This integration of AI into mathematics teaching is far more than a simple technical upgrade; it represents a valuable opportunity for educators, policymakers, and researchers to reevaluate"}, {"title": "7. Conclusion", "content": "The evolving relationship between artificial intelligence and mathematics heralds a new era of collaborative inquiry. Yet, significant opportunities remain largely untapped, owing to challenges on both sides of the divide. On the one hand, despite AI models having reached saturation on many standard mathematical benchmarks, they often fall short when it comes to precise computation and advanced deductive reasoning, particularly in natural language contexts. Whether supplying models with more natural language data a common approach among AI researchers will lead to substantial improvements remains a subject of debate. On the other hand, many mathematicians are not fully aware of the capabilities modern AI systems offer.\nWhile present-day AI tools may still struggle with high-level reasoning and the creation of genuinely novel mathematical ideas, this article has shown that they excel at tasks such as suggesting formal proof steps, identifying patterns, generating plausible conjectures, and constructing mathematical objects especially when integrated with other problem-solving tools. These strengths underscore that AI's role as a complementary resource that can enhance our intellectual pursuits.\nInstead of either overestimating the potential of AI based solely on scaling laws or completely dismissing its usefulness, we argue that AI researchers and mathematicians must engage in more profound and sustained dialogue. By doing so, they can jointly develop new frameworks and methodologies for effective human-machine collaboration. Such an interdisciplinary effort will help bridge existing gaps in understanding and communication, ultimately enabling groundbreaking advancements that neither domain could achieve in isolation.\nMoreover, weaving AI into the fabric of mathematics education has the potential to democratize knowledge, foster critical thinking, and promote creative problem-solving. Nonetheless, this must be done responsibly. Ethical concerns such as inherent biases in AI models and unequal access to technological resources must be addressed to ensure that the benefits of this integration are distributed fairly and equitably.\nIn the final analysis, the true promise of AI in mathematics lies not in supplanting human insight, but in amplifying it. As we continue refining these technologies and their applications, thoughtful and strategic integration of AI will lead to a richer, more inclusive, and more innovative future for the mathematical sciences."}]}