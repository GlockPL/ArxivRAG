{"title": "Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BILSTM Hybrid Model", "authors": ["Mohaiminul Islam Bhuiyan", "Nur Shazwani Kamarudin", "Nur Hafieza Ismail"], "abstract": "Suicidal ideation detection is crucial for preventing suicides, a leading cause of death worldwide. Many individuals express suicidal thoughts on social media, offering a vital opportunity for early detection through advanced machine learning techniques. The identification of suicidal ideation in social media text is improved by utilising a hybrid framework that integrates Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (BiLSTM), enhanced with an attention mechanism. To enhance the interpretability of the model's predictions, Explainable AI (XAI) methods are applied, with a particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At first, the model managed to reach an accuracy of 92.81%. By applying fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The SHAP analysis revealed key features influencing the model's predictions, such as terms related to mental health struggles. This level of transparency boosts the model's credibility while helping mental health professionals understand and trust the predictions. This work highlights the potential for improving the accuracy and interpretability of detecting suicidal tendencies, making a valuable contribution to the progress of mental health monitoring systems. It emphasizes the significance of blending powerful machine learning methods with explainability to develop reliable and impactful mental health solutions.", "sections": [{"title": "INTRODUCTION", "content": "With the ongoing transformation of society through digital technologies, social media has become a key space for observing users' psychological states. How people communicate and express themselves on these platforms provides valuable insights into their mental health. One of the most pressing concerns revealed through online expressions is suicidal ideation, a growing public health issue that demands immediate attention. The World Health Organization (WHO) reports that around 800,000 individuals lose their lives to suicide each year [1], making it one of the primary causes of death worldwide. It is especially concerning that suicide ranks as the second most common cause of death among people aged 15 to 29. Suicide arises from a variety of complex factors, frequently associated with mental health conditions like depression, substance abuse, and psychosis, though these factors are complex and differ from person to person. Many people suffering from suicidal thoughts face a lack of support, and traditional methods of identifying suicidal ideation\u2014such as self-reporting are often unreliable due to fear of stigma or hospitalization, leading individuals to hide their true feelings.\nA promising approach for detecting suicidal ideation has emerged through the use of digital platforms, particularly social media, where individuals may express their struggles. The vast amount of data produced on these platforms serves as a valuable asset for predictive modeling. Advances in Machine Learning (ML) and Deep Learning (DL) [2] have made it possible to analyze social media posts for signs of suicidal ideation. Technologies such as Convolutional Neural Networks (CNN) [3], Recurrent Neural Networks (RNN), and hybrid models can detect subtle linguistic patterns and complex meanings in text that were once challenging to identify [4]. Despite their accuracy, many of these models function as \"black boxes,\" meaning they make predictions without offering clear explanations for how decisions were reached [5]. The absence of transparency poses a significant challenge in clinical settings, where knowing why a model makes a certain prediction is just as crucial as the prediction itself. To overcome this, Explainable AI (XAI) techniques have become vital, offering clearer insights into the factors that shape a model's decisions and making AI systems more understandable and trustworthy [6]. This added layer of transparency is particularly critical for healthcare and mental health applications, where trust in the model's output is vital for clinical use."}, {"title": "RELATED WORK", "content": "In recent years, there has been a growing focus on identifying suicidal thoughts through social media, driven by the increasing rates of suicide worldwide. Researchers have employed various machine learning (ML) [7] and deep learning (DL) techniques to tackle this issue, achieving promising results.\nRahaman et al. applied the XGBoost algorithm to identify suicidal ideation, using a dataset collected from multiple social media platforms. Their approach resulted in an accuracy of 89%. This study showcased how ensemble learning techniques can improve the accuracy of detecting suicidal thoughts from text-based data [8]. Jain et al. used the Random Forest (RF) method to distinguish between suicidal and non-suicidal texts. By analyzing a dataset of social media posts, their model reached an accuracy of 77.298%. Though the accuracy was lower than that of other models, the study emphasized the crucial role of feature selection and preprocessing in enhancing overall model performance [9]. Tadesse et al. created a model that integrated Convolutional Neural Networks (CNN) with Long Short-Term Memory (LSTM) networks. The model was trained on data from Reddit, specifically targeting subreddits discussing mental health topics. With an accuracy of 93.8%, the results highlighted the strength of hybrid models in recognizing both short-term patterns and long-term dependencies within text data [10].\nSchoene et al. explored the use of transformer-based models combined with Bidirectional Long Short-Term Memory (BiLSTM) networks. Using a comprehensive dataset from multiple social media platforms, they achieved an accuracy of 87.34%. This study showcased the potential of transformer architectures in enhancing the contextual understanding of suicidal ideation expressions [11]. Naghavi et al. employed an ensemble of decision trees (DT) to detect suicidal ideation from social media posts. Their model, trained on a dataset comprising various mental health-related subreddits, achieved an accuracy of 93%. The study emphasized the robustness of ensemble methods in handling diverse and noisy text data [12]. De Choudhury et al. (2016) analyzed Twitter data to identify users with suicidal ideation using linguistic features and social engagement metrics. Their approach provided valuable insights into the behavioral patterns of individuals expressing suicidal thoughts on social media [13]. Burnap et al. (2015) applied sentiment analysis and machine learning techniques to classify tweets related to suicidal behavior. They used a large dataset from Twitter and achieved significant results in early detection, underscoring the importance of real-time data analysis in preventing suicides [14].\nCoppersmith et al. carried out a study that used linguistic analysis along with machine learning methods to identify signs of suicidal ideation in social media posts. They used data from Twitter and demonstrated that specific linguistic markers could effectively indicate suicidal tendencies, achieving an accuracy of 85% [15]. Gaur et al. investigated a hybrid approach that combined CNN and LSTM to detect suicidal ideation. Their dataset included posts from various mental health forums and subreddits, and they achieved an accuracy of 92.5%. This study emphasized the importance of capturing both local and sequential patterns in text data for better prediction performance [16]. Sawhney et al. (2020) proposed a model integrating BERT (Bidirectional Encoder Representations from Transformers) with a BiLSTM network to identify suicidal thoughts. By applying their model to a large dataset from Twitter, they achieved an accuracy of 91.2%, demonstrating the strength of transformer-based models in capturing subtle contextual details in text [17]. Matero et al. designed a model that combined hierarchical attention networks with LSTM to identify suicidal ideation. Their study utilized data from Reddit and Twitter, achieving an accuracy of 88.7%. The hierarchical attention mechanism allowed their model to focus on different levels of textual information, improving interpretability and performance [18]. Wang et al. used a multi-task learning method to identify suicidal ideation and related mental"}, {"title": "METHODOLOGY", "content": "The dataset for this study was obtained from the Kaggle data repository and includes 232,074 samples in total. This dataset includes texts labeled as suicidal and non-suicidal, with an equal distribution of 116,037 samples in each category. The data for this study was gathered from Reddit's \u201cSuicideWatch\u201d and \u201cdepression\u201d subreddits, covering posts made between December 16, 2008, and January 2, 2021, for \"SuicideWatch,\" and from January 1, 2009, to January 2, 2021, for \"depression.\" To ensure a balanced dataset for training and evaluation, non-suicidal posts were sourced from the r/teenagers subreddit."}, {"title": "Data Pre-processing", "content": "Preparing data is a vital part of developing models, especially when handling text from social media. This type of data frequently includes noise, informal language, and irregularities that can affect the performance and accuracy of the model [20]. Proper preprocessing helps to clean and structure the data, ensuring better results and more reliable outcomes. The following preprocessing steps were undertaken:\n\u2022 Tokenization: Tokenization involves breaking down large sections of text into smaller pieces known as tokens. Depending on the method used, these tokens can represent individual words, parts of words, or even single characters. This process helps structure the text for easier analysis and interpretation. In the context of this experiment, tokenization was performed on the textual data, where each sentence was split into individual words (tokens). The process started by cleaning the text, converting it to lowercase, and removing punctuation, symbols, and any unrecognized characters. This step is crucial as it ensures consistency and reduces noise in the data. Following the cleaning, the Tokenizer class from the Keras library was employed to convert the cleaned text into a sequence of integers, where each unique word from the vocabulary was mapped to a specific index. In this experiment, a vocabulary size of 2000 unique words was specified, meaning the tokenizer considered only the most frequent 2000 words in the dataset and ignored the less frequent words. This process simplifies the model while enhancing its ability to concentrate on the most important and relevant words. After tokenizing the text, stopwords such as \"and\" or \"is\" that add little meaning-were removed. A rule-based stemmer was then used to reduce words to their root form, allowing different versions of the same word, like \"running\" and \"run,\" to be recognized as the same token.\n\u2022 Padding: Padding is a method used to make sure all input sequences are of equal length. This is especially important for neural networks, which need inputs to have consistent dimensions. In this experiment, after the text was tokenized into sequences of integers, the resulting sequences varied in length depending on the number of words in each input text. To ensure all inputs had the same shape, shorter sequences were padded to match the length of the longest one, while longer sequences were shortened when needed. This helped maintain uniformity for processing in neural networks. The maximum sequence length was set to 100 words in this experiment. Any sequence shorter than this length was padded with zeros at the beginning (pre-padding) to ensure uniformity across all input sequences. Padding guarantees that all sequences entering the model are of equal length, enabling efficient batch processing and preventing shorter sequences from negatively impacting the learning process. By padding the sequences to a fixed length, the model could focus on important patterns in the data without being affected by variations in the lengths of different input texts. This method also helps avoid potential bias caused by varying input sequence lengths during the model's training and testing phases."}, {"title": "Word Embedding", "content": "Word embedding plays an important role in processing Natural Language Processing (NLP) by representing words or phrases as dense vectors of real numbers. This technique captures the meaning of words by considering the context in which they appear within the text. In this experiment, word embedding was performed using the Word2Vec model from the gensim library. Word2Vec is a widely used technique for creating word embeddings, representing words within a continuous vector space. This approach allows words with similar meanings to have closely aligned vector representations. Unlike traditional one-hot encoding, which uses sparse binary vectors, Word2Vec places words in a lower-dimensional space, capturing their semantic relationships by analyzing how often they appear together in the text. For this experiment, a 100-dimensional Word2Vec model was trained using the cleaned text data to produce word embeddings. Every word in the vocabulary was represented by a 100-dimensional vector, with each dimension reflecting various aspects of the word's meaning. The Word2Vec model uses a sliding window approach, where it predicts a word based on its surrounding context (window size), learning meaningful representations. This helped capture the relationships between words that frequently appear together, such as synonyms or related concepts. Once the Word2Vec model was trained, an embedding matrix was created, where each word in the vocabulary was mapped to its corresponding vector from the Word2Vec model."}, {"title": "Proposed Hybrid Model", "content": "The initial model used to detect suicidal ideation was a CNN-BiLSTM hybrid model, leveraging the advantages of Convolutional Neural Networks (CNN) along with Bidirectional Long Short-Term Memory (BiLSTM) layers. This combination aimed to enhance performance by capturing both local patterns and long-range dependencies in the text. This hybrid architecture was specifically chosen to leverage the ability of CNNs to extract local patterns from text data and the capacity of BiLSTMs to capture long-term dependencies within sequences, which is crucial for understanding the context in social media posts. The following provides a detailed breakdown of each layer in the initial model and explains how each part plays a role in the overall operation of the neural network.\nThe model starts with a word embedding layer, which converts raw text into dense vector representations that reflect the meanings of words. This layer uses the Word2Vec technique, pre-trained on a large text corpus. Word embeddings enable the model to recognize relationships between words by analyzing their context, which is essential"}, {"title": "Fine Tuning", "content": "In the fine-tuned version of the CNN-BiLSTM model, several key improvements were introduced, optimizing various components to enhance the model's overall performance. The core structure-comprising convolutional layers, bidirectional LSTM units, and attention mechanisms-remained the same, but crucial refinements were made to reduce overfitting, improve generalization, and achieve more stable training.\nOne of the most significant improvements in the fine-tuned model was the use of optimized regularization tech-"}, {"title": "Performance Measure", "content": "\u2022 Accuracy Score: It measures the ratio of correctly classified comments out of the total number of comments in the test dataset. It's a simple and commonly used metric to evaluate classification performance.\nAccuracy = $\\frac{TP + TN}{TP+PP+TN + FN}$                                                                      (1)\n\u2022 True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN): These components collectively constitute the confusion matrix, offering a more comprehensive perspective on the classification performance. TP and TN represent correct classifications, while FP and FN indicate misclassification.\n\u2022 Precision: It measures the model's capability to accurately recognize a specific class. Precision can be formulated or defined as follows:\nPrecision = $\\frac{TP}{TP + FP}$                                                                (2)\n\u2022 Recall (Sensitivity): It calculates the ratio of actual positives that were accurately predicted by the model. Thus, recall can be formulated as follows:\nRecall = $\\frac{TP}{TP + FN}$                                                                (3)\n\u2022 F1-Score: It is the harmonic mean of precision and recall. It considers both precision and recall, resulting in a lower value compared to accuracy. The formula for calculating the F1-score looks like this:\nF1 = $\\frac{2x Precision \u00d7 Recall}{Precision + Recall}$                                                                (4)"}, {"title": "RESULTS AND DISCUSSION", "content": "To evaluate the proposed CNN-BiLSTM hybrid model, the dataset was divided into training, validation, and testing sets in an 80:10:10 ratio. The model was trained over 40 epochs with a batch size of 512, utilizing the Adam optimizer. Early stopping was applied with a patience of 4 epochs to avoid overfitting, and the learning rate was set at 0.0001.\nThe CNN-BiLSTM model performed exceptionally well throughout both training and evaluation. During training, it achieved a training accuracy of 98.54%, demonstrating its ability to correctly classify nearly all examples from the training set. Notably, the model also recorded a validation accuracy of 94.46%, reflecting its capacity to generalize effectively to new, unseen data. The close match between training and validation accuracy suggests the model avoided overfitting and successfully identified the key patterns within the data.\nOnce training was complete, the model was evaluated on a completely unseen test set. It achieved a test accuracy of 94.29%, confirming that the model maintained its strong performance when applied to new data. However, accuracy alone does not fully reflect the model's effectiveness in detecting suicidal ideation, so additional performance metrics were calculated for a more comprehensive evaluation.\nThe precision of the model was 0.9458, indicating that 94.58% of the model's positive predictions (instances classified as indicating suicidal ideation) were correct. Precision is a particularly important metric for this task, as misclassifying non-suicidal instances as suicidal (false positives) could lead to unnecessary concerns or interventions.\nThe model achieved a recall of 0.9400, indicating it correctly identified 94.00% of the true cases of suicidal ideation in the dataset. This high recall is essential, as failing to detect actual cases (false negatives) could lead to serious consequences. Additionally, the model recorded an F1 score of 0.9429, which reflects a strong balance between precision and recall. This score highlights the model's effectiveness in accurately detecting true cases while keeping false positives and false negatives to a minimum.\nThese results indicate that the fine-tuned CNN-BiLSTM model is highly effective at identifying suicidal ideation in text, achieving strong performance metrics and generalizing well to unseen data. These results demonstrate a significant improvement over the initial model performance, which had an accuracy of 92.81%. The fine-tuning and early stopping techniques were effective in optimizing the model's parameters and enhancing its generalization capability."}, {"title": "Explainability with SHAP", "content": "A significant aspect of this study is the use of explainability techniques to interpret the model's predictions. In this case, SHAP (SHapley Additive exPlanations) was applied to provide insight into how the model arrived at its decisions. SHAP is a valuable method that explains the predictions of machine learning models by assigning an importance score to each feature based on its contribution to a specific outcome. Rooted in game theory, SHAP offers a consistent way to measure feature importance by estimating how much each input affects the final prediction. In this study, SHAP helped identify which words or tokens played the largest role in determining whether a piece of text suggested suicidal ideation. This level of interpretability not only enhances trust in the model but also provides deeper insight into the factors driving its classifications."}, {"title": "CONCLUSION", "content": "The study introduced a CNN-BiLSTM hybrid model with an attention mechanism for detecting suicidal ideation from social media texts, showcasing significant results. By combining CNNs for capturing local textual patterns and BiLSTM for understanding broader context, enhanced by attention for focusing on key text segments, the model achieved notable predictive accuracy. Optimization through fine-tuning and early stopping improved accuracy from 92.81% to 94.29%, highlighting reduced overfitting and better generalization. The application of SHapley Additive exPla-nations (SHAP) as an Explainable AI technique added valuable interpretability, enabling insights into the model's decision-making process, thus promoting trust in its application for mental health monitoring.\nFuture research could explore ways to refine the model further. This could include expanding the model's ap-plication across a broader range of social media platforms to assess its generalizability across different types of user-generated content. Furthermore, there is potential to investigate more advanced pre-processing techniques to better handle noisy data typical of social media texts. Alternative neural network architectures, such as Transformer-based models, could also be explored to assess whether they offer performance improvements over the current CNN-BILSTM structure.\nIn addition, working with larger and more diverse datasets could further enhance the model's robustness, partic-ularly in capturing a wider range of linguistic nuances associated with suicidal ideation. More sophisticated XAI techniques could also be integrated, offering deeper insights into the model's decision-making process. This could"}, {"title": "Interpretation and Significance", "content": "By employing SHAP, we gain both local and global insights into the model's behavior. The force plot provides a localized view, allowing us to understand how specific words in a single post influenced that particular prediction. This instance-specific interpretability is essential for real-world applications where it is important to justify individual predictions. The summary plot, on the other hand, offers a broader perspective by showing the overall contribution of each word to the model's decisions across all posts in the dataset.\nThe use of SHAP ensures that the model's predictions are not only accurate but also transparent and explainable. In the context of suicidal ideation detection, where every decision must be carefully validated, SHAP provides a critical layer of interpretability. By visualizing which words push the model towards or away from identifying suicidal ideation, SHAP allows for a greater degree of trust and reliability in the model's predictions.\nSHAP-based explainability strengthens the model's applicability in the detection of suicidal ideation, providing a clearer understanding of how decisions are made. This interpretability is not only vital for model validation but also necessary for ethical considerations in deploying such models for mental health monitoring.\nIn this subsection, the performance of the proposed CNN-BiLSTM hybrid model with an attention mechanism is compared against various state-of-the-art models reported in the literature for suicidal ideation detection. The comparison focuses on the accuracy achieved by each model, providing a clear indication of the effectiveness of this approach relative to existing methods. The models selected for comparison include transformer-based models, ensemble learning techniques, and other deep learning architectures commonly used in this domain."}]}