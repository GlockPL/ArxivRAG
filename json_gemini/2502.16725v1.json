{"title": "DOSE3 : DIFFUSION-BASED OUT-OF-DISTRIBUTION\nDETECTION ON SE(3) TRAJECTORIES", "authors": ["Hongzhe Cheng", "Tianyou Zheng", "Tianyi Zhang", "Matthew Johnson-Roberson", "Weiming Zhi"], "abstract": "Out-Of-Distribution (OOD) detection, a fundamental machine learning task aimed\nat identifying abnormal samples, traditionally requires model retraining for dif-\nferent inlier distributions. While recent research demonstrates the applicability\nof diffusion models to OOD detection, existing approaches are limited to Eu-\nclidean or latent image spaces. Our work extends OOD detection to trajecto-\nries in the Special Euclidean Group in 3D (SE(3)), addressing a critical need in\ncomputer vision, robotics, and engineering applications that process object pose\nsequences in SE(3). We present Diffusion-based Out-of-distribution detection on\nSE(3) (DOSE3), a novel OOD framework that extends diffusion to a unified\nsample space of SE (3) pose sequences. Through extensive validation on multiple\nbenchmark datasets, we demonstrate DOSE3's superior performance compared\nto state-of-the-art OOD detection frameworks.", "sections": [{"title": "1 INTRODUCTION", "content": "OOD detection represents a fundamental machine learning challenge focused on identifying data\nsamples that deviate from expected inlier distributions. This capability is particularly crucial in\nsafety-critical applications like robotics and autonomous driving, where accurate identification of\nanomalous motion trajectory samples can prevent system failures. Recent ad-\nvances in OOD detection have explored various unsupervised approaches to learn inlier data rep-\nresentations. These include likelihood-based methods that employ different likelihood measures\nfor OOD determination, and reconstruction-based approaches that utilize pretrained generative models to assess sample sim-\nilarity. However, these methods\ntypically require dataset-specific training, necessitating retraining for different in-distribution (ID)\nand OOD datasets. Recent research has addressed this lim-\nitation by exploring single discriminative models for OOD detection. Our work similarly aims to\ndevelop unified OOD approaches that eliminate retraining requirements.\nCurrent trajectory OOD detection research primarily focuses on Latent Euclidean spaces, often over-\nlooking explicit manifold space structures. Our work targets OOD detection for rigid body pose\ndata, encompassing both position and orientation information. This type of data is fundamental\nto numerous applications in physics, engineering, and robotics that analyze object pose evolution\nover time. We present theoretical insights and practical al-\ngorithms for detecting OOD data in rigid body pose sequences. Our framework, Diffusion-based\nOut-of-distribution detection on SE(3) (DOSE3), introduces a novel unified generative approach\nfor trajectory space OOD detection. We define a manifold-specific diffusion process for rigid trans-\nformations on SE(3) and develop a high-dimensional OOD statistic for out-of-distribution sample\nidentification. We validate our approach using established robotics and automation datasets, creat-\ning benchmarks from Oxford RobotCar, KITTI, and\nIROS20. These datasets enable comprehensive evaluation across varying OOD\nsimilarity levels. Our key contributions include:"}, {"title": "2 RELATED WORK", "content": "OOD detection: OOD detection plays a crucial role in safety-critical applications such as au-\ntonomous driving. Existing methods can generally be categorized into likelihood-based and\nreconstruction-based approaches.\nLikelihood-based OOD detection methods involve training a model on ID data and deriving a likeli-\nhood statistic from test samples to serve as an OOD metric. Early work focused on learning discrim-\ninative representations to detect OOD samples and identify distributional shifts. More recent research has explored generative models due to their ability\nto model high-dimensional data and facilitate likelihood estimation. However,\nstudies have shown that generative models may assign higher likelihoods to OOD samples than to\nID ones.\nTo address this issue, various refinements have been proposed, including likelihood ratios , Watanabe-Akaike Information Criterion (WAIC), improved noise\ncontrastive priors, and Energy-based Model (EBM)s . How-\never, these enhancements remain ineffective in high-dimensional scenarios . Another approach considers measuring how typical a test input is , but this\nmethod suffers from poor performance at the sample level. Normalizing flows have also been investigated for OOD detection as they provide direct likelihood estimation,\nyet they still suffer from overconfidence issues.\nReconstruction-based OOD detection methods, on the other hand, aim to reconstruct input samples\nand compare them to their reconstructions to measure similarity. Early work used the reconstruction\nprobability of VAEs for anomaly detection. How-\never, later studies found that OOD samples can exhibit similar or even lower reconstruction errors\ncompared to ID samples, reducing the effectiveness of this approach .\nDiffusion-based OOD Detection: Diffusion models (DMs) have achieved remarkable performance\nin generative tasks across various modalities, including images, "}, {"title": "3 PRELIMINARIES", "content": "In this section, we first provide background on the architecture of diffusion models. We then discuss\nthe recent advancements in constructing Unified OOD detection models using diffusion models.\nFinally, we introduce the Special Euclidean Group in 3D, SE(3), and elaborate on its geometric\nstructure and related statistical foundations."}, {"title": "3.1 DENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)", "content": "Diffusion models have gained widespread attention in generative modeling due to their strong ability\nto synthesize high-fidelity data. These models employ a forward diffusion process, where data xo\nis gradually corrupted by adding Gaussian noise over T timesteps, ultimately producing a noisy\ndistribution x that approximates a standard normal distribution. The goal is to learn the reverse\ndiffusion process, which systematically denoises x\u012b to recover the original data distribution.\nAt the core of this reverse process is the e-model, typically implemented as a neural network trained\nto predict the noise e added at each timestep t. The forward diffusion process, expressed in equa-\ntion 1, illustrates how standard Gaussian noise is introduced to perturb the original sample x0. The\nbackward process, given in equation 2, employs the estimator model ee, which estimates the true\nGaussian noise e and enables data recovery by removing the noise.\n$$x_t = \\sqrt{\\bar{a}_t}x_0 + \\sqrt{1 - \\bar{a}_t}\\epsilon, \\quad \\epsilon \\sim N(0, I)$$\n$$x_{t-1} = \\frac{1}{\\sqrt{a_t}} \\Big( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar{a}_t}} \\epsilon_\\theta(x_t, t) \\Big) + \\sigma_t z$$\nwhere at, \u00dft, and \u0101t are predefined noise schedule parameters, and z ~ N(0, I).\nThe theoretical foundation of diffusion models is grounded in variational inference, where the ev-\nidence lower bound (ELBO) in equation 3 is maximized to ensure that the learned reverse process"}, {"title": "3.2 UNIFIED OUT-OF-DISTRIBUTION DETECTION", "content": "Traditional OOD detection methods, such as likelihood-based and reconstruction-based approaches,\nrequire retraining a new model for each specific inlier data distribution. This results in significant\ncomputational costs when switching between different OOD tasks and distributions. Recently, Heng\net al. (2024) introduced a new concept of Unified OOD detection, where a single unconditional\ndiffusion model is trained, and distributional information can be obtained from inlier distributions\nthat were unseen during training.\nThe theoretical foundation of this approach builds on the variance-preserving formulation used in\nDDPM. The difference between each denoising timestep is given in equation 4 and can be rewritten\nas:\n$$d\\mathbf{x}_t = -\\frac{1}{2} \\beta_t \\mathbf{x}_t dt + \\sqrt{\\beta_t} d\\mathbf{w}_t, \\quad \\mathbf{x}_0 \\sim p_0(\\mathbf{x})$$\n$$\\frac{d\\mathbf{x}_t}{dt} = \\frac{g(t)^2}{2\\sigma^2} [f(\\mathbf{x}_t, t) + \\frac{\\sigma^2}{g(t)^2} \\epsilon_{p(\\mathbf{x}_t, t)}]$$\nIn equation 6, we denote \u0444\u0442 and Vr as the marginals obtained by evolving two distinct distributions,\n\u03a6\u03bf and \u03c8\u03bf, using their respective probability flow ordinary differential equations (ODEs) from equa-\ntion 5.\n$$D_{KL}(\\phi_0 || \\psi_0) = \\frac{1}{2} \\int_0^T E_{\\mathbf{x}_t \\sim \\phi_t} [ \\frac{g(t)^2}{\\sigma^2} || \\epsilon_{\\phi}(\\mathbf{x}_t, t) - \\epsilon_{\\psi}(\\mathbf{x}_t, t) ||^2 ] dt + D_{KL}(\\phi_T || \\psi_T)$$\nHowever, the KL divergence remains dependent on the specific model estimators ef and ey in equa-\ntion 6. The key observation is that even when executing DDPM forward diffusion using an estimator\ne trained on a third distribution 0, the sample can still be successfully transformed into a standard\nGaussian distribution. This insight motivates the use of e-metrics extracted from an arbitrary\ndiffusion estimator\u2014to perform OOD detection on an inlier distribution 4."}, {"title": "3.3 THE SPECIAL EUCLIDEAN GROUP IN 3D", "content": "The Special Euclidean Group in 3D, denoted as SE(3), represents the space of rigid body transfor-\nmations, which consist of both rotations and translations. The transformation can be written as:\n$$T = \\begin{bmatrix} R & t \\\\ 0 & 1 \\end{bmatrix}$$"}, {"title": "4 METHOD", "content": "4.1 OVERVIEW\nHere, we present Diffusion-based Out-of-distribution detection on SE(3), DOSE3. DOSE3 in-\ntroduces a unified diffusion model for rigid pose trajectories, specifically designed to accommodate\nthe SE(3) manifold structure. We first detail DOSE3's model architecture for handling ordered\nsequences. We then introduce SE(3) Denoising Diffusion Probabilistic Models (SE(3) - DDPM),\noutlining their training and inference algorithms that incorporate rigid pose structure into the diffu-\nsion model. Finally, we explain how to utilize the diffusion estimator, a function naturally emerging\nfrom SE(3) - DDPM, to develop an OOD detection statistic for evaluating test samples."}, {"title": "4.2 ARCHITECTURAL DETAILS OF DOSE3", "content": "The UNet architecture, widely adopted in diffusion models for its effective encoder-decoder struc-\nture, enables high-fidelity data generation. Originally developed for biomedical image segmentation,\nUNet's symmetric design with skip connections preserves spatial information through its network\nlayers. While the original UNet employs 2D convolution layers with max pooling and up convolu-\ntion for dimensional adjustment, we modify this architecture for sequential data diffusion through\nthe following enhancements:\n1. Replace all convolution layers with 1D convolutions to process temporal structures in mo-\ntion trajectories."}, {"title": "4.3 TRAINING AND INFERENCE OF DOSE3", "content": "As discussed in section 3.3, the incorporation of rotation matrices from SE(3) format introduces\nmanifold space considerations that preclude direct application of classical diffusion algorithms. We\naddress three primary challenges: (1) The undefined nature of addition and scalar multiplication\noperations for rotation matrices; (2) The inability to guarantee valid rotation matrices when sampling\n3 \u00d7 3 matrices from N(0, I); (3) The inadequacy of simple L2 norm differences for measuring\ndistances/losses between rotation matrices. To overcome these challenges, we introduce the new\nSE(3) DDPM algorithm. While we apply standard Euclidean space diffusion to the translational\ncomponents of SE(3), we develop specialized techniques for handling manifold diffusion over the\nSO(3) rotation space.\nWe redefine the operators \u2208 SO(3) as follows. Essentially, we perform all operations after trans-\nforming the SO(3) data from manifold space into Euclidean tangent space by exponential and loga-\nrithmic map given by eq. (8) and eq. (9).\n$$R_1 \\oplus R_2 \\triangleq R_1 R_2$$\n$$k \\odot R_1 \\triangleq exp(k \\cdot log(R_1))$$\n$$k \\in \\mathbb{R}, R_1, R_2 \\in SO(3)$$\nWe then change the noise sampling method from standard Gaussian distribution to the Isotropic\nGaussian distribution on SO(3) distribution. Shown in equation 13, we first sample v\nfrom standard Gaussiance distribution, representing the tangent vector, and then use the exponential\nmap operation to transform it to the SO(3) space.\n$$I G_{S O(3)}(\\mu, \\sigma^2) = \\mu \\otimes v, \\quad v \\in \\mathbb{R}^3 \\sim \\mathcal{N}(0, \\sigma^2 I)$$"}, {"title": "4.4 OOD DETECTION", "content": "While likelihood-based OOD detection algorithms traditionally rely on generative model likelihood\nmeasures, the ELBO shown in equation 3 has proven inadequate for OOD tasks due to its tendency\nto overestimate OOD sample likelihood . Recent research demonstrates that the\ndiffusion estimator ee and its derivatives effectively capture data distribution characteristics and can\nbe obtained from a unified diffusion model without retraining. As shown in Equation 6, the norm\nof noise estimator e correlates with the divergence between different data distributions . Based on this insight, we define the following OOD statistics group for a diffusion model\nwith noise estimator 60, where the operator (x) = \u03a3\u03c7\n$$MetricGroup(\\epsilon_\\theta) = \\begin{bmatrix} \\Sigma_t (\\epsilon_\\theta(x_t, t))_1, \\Sigma_t (\\epsilon_\\theta(x_t, t))_2, \\Sigma_t (\\epsilon_\\theta(x_t, t))_3 \\\\ \\Sigma_t (\\frac{\\partial}{\\partial t} \\epsilon_\\theta(x_t, t))_1, \\Sigma_t (\\frac{\\partial}{\\partial t} \\epsilon_\\theta(x_t, t))_2, \\Sigma_t (\\frac{\\partial}{\\partial t} \\epsilon_\\theta(x_t, t))_3 \\end{bmatrix}$$\nwhere MetricGroup(60) \u2208 R6. For each sample xo, we apply the DDPM forward process to ob-\ntain the perturbed sample xt, then compute the metric group to derive final statistics. Given that"}, {"title": "5 EXPERIMENTS", "content": "5.1 EXPERIMENT SETUP\nTo evaluate DOSE3's validity, performance, and comprehensiveness, we conduct OOD testing\nusing the following SE(3) datasets:\n\u2022 Oxford RobotCar : This autonomous driving dataset encompasses\nover 1000 km of driving data from central Oxford, UK. It features multiple sensor modal-\nities, including high-resolution stereo and monocular cameras, 2D and 3D LiDAR scans,"}, {"title": "5.2 QUANTITATIVE EVALUATION OF E DISTRIBUTION AS AN OOD METRIC", "content": "We analyze the statistical distribution of ee from inlier data to assess its effectiveness as an OOD de-\ntection metric. Specifically, we investigate how the e\u0189 distribution of the SO(3) diffusion contributes\nto OOD sample identification. In fig. 5, we present a comparative analysis of e distributions between\nOxford RobotCar and KITTI datasets, using a model trained on KITTI. Our findings reveal that af-\nter translation data normalization, the translation e distributions show substantial overlap across\ndatasets, making them unsuitable as reliable OOD indicators. However, the rotation distribution,\nespecially along the z-axis, demonstrates clear dataset separation. For the KITTI-trained model, we\nobserve that KITTI's rotation distribution is centered at 0, aligning with standard Gaussian noise\nsampling characteristics. In contrast, the Oxford RobotCar dataset exhibits a notable rightward shift\nin its distribution, suggesting that reconstructing a KITTI sample from Oxford RobotCar input re-"}, {"title": "5.3 QUANTITATIVE RESULTS", "content": "Table 1 presents the OOD detection performance across datasets using the AUROC metric. All\nevaluated models underwent unsupervised training exclusively on the KITTI dataset. Our SE(3)"}, {"title": "5.4 ABLATIONS", "content": "5.4.1 TRAJECTORY DATASET USED FOR TRAINING\nDOSE3 strives to develop a single unified model for effective OOD detection. We evaluate both\nR3 and SE(3)-based diffusion models trained on different datasets. Table 2 presents these results,\nhighlighting two key findings:\n1. SE(3) diffusion consistently demonstrates robust OOD detection capabilities across various\ntraining datasets;\n2. SE(3) diffusion successfully performs OOD detection between two previously unseen\ndatasets during training.\nWe observe some performance degradation when training with the Oxford Robot Car dataset. This\nlimitation primarily stems from the dataset's restricted trajectory diversity. Both IROS and KITTI\ndatasets exhibit broader data distributions, encompassing more varied trajectory shapes. Conse-\nquently, when an Oxford-trained model attempts to distinguish between its own less diverse distri-\nbution and a highly varied dataset like IROS, the task becomes particularly challenging. Neverthe-\nless, these results underscore the advantages of our unified diffusion approach to OOD detection.\nBy requiring training on only a single dataset, our method significantly reduces the overall model\ntraining time."}, {"title": "5.4.2 NECESSITY OF ROTATIONAL DIFFUSION INFORMATION", "content": "We compare diffusion models trained on translation-only data versus those trained on complete\nSE(3) data to demonstrate the critical role of rotational information. Table 2 reveals that OOD"}, {"title": "5.4.3 SEQUENCE LENGTH OF THE TRAJECTORY", "content": "Table 3 presents the OOD detection performance for varying trajectory sequence lengths during\nKITTI dataset pre-training. The results demonstrate that DOSE3 maintains consistently excel-\nlent performance with near-perfect AUROC scores across all ID and OOD pairs, independent of\nsequence length. This robustness to sequence length variation highlights the model's stability and\ngeneralization capabilities."}, {"title": "5.4.4 DDPM FORWARD STEPS", "content": "Table 4 illustrates the relationship between DOSE3 performance and the number of DDPM steps.\nThe results indicate minimal variation in average AUROC scores across different step counts,\ndemonstrating DOSE3's resilience to changes in the number of DDPM steps."}, {"title": "6 CONCLUSIONS", "content": "Out-of-Distribution (OOD) detection plays a vital role in machine learning, particularly in safety-critical domains like autonomous driving and robotics where systems must reliably interact with thephysical world. In these applications, data typically consists of rigid object pose trajectories thatcapture both positional and rotational motion. While existing OOD detection approaches operateon assumed Euclidean latent spaces, we present DOSE3, a novel unified diffusion-based OODdetection framework specifically designed for SE(3) trajectory data. DOSE3 innovates by directlyincorporating manifold operations into the diffusion model and introduces a novel architecture thatextends DDPM to handle SE(3) manifold sequences. Through comprehensive empirical evaluationacross diverse real-world safety-critical datasets, we demonstrate DOSE3's robust performanceand effectiveness."}]}