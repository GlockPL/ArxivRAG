{"title": "Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model", "authors": ["Jie Wang", "Jin Wang", "Xuejie Zhang"], "abstract": "Metaphors are common in everyday language, and the identification and understanding of metaphors are facilitated by models to achieve a better understanding of the text. Metaphors are mainly identified and generated by pre-trained models in existing research, but situations, where tenors or vehicles are not included in the metaphor, cannot be handled. The problem can be effectively solved by using Large Language Models (LLMs), but significant room for exploration remains in this early-stage research area. A multi-stage generative heuristic-enhanced prompt framework is proposed in this study to enhance the ability of LLMs to recognize tenors, vehicles, and grounds in Chinese metaphors. In the first stage, a small model is trained to obtain the required confidence score for answer candidate generation. In the second stage, questions are clustered and sampled according to specific rules. Finally, the heuristic-enhanced prompt needed is formed by combining the generated answer candidates and demonstrations. The proposed model achieved 3rd place in Track 1 of Subtask 1, 1st place in Track 2 of Subtask 1, and 1st place in both tracks of Subtask 2 at the NLPCC-2024 Shared Task 9.", "sections": [{"title": "1 Introduction", "content": "Metaphor is an essential tool for reasoning and linguistic expression, the task is a crucial step toward the generation of human-like language. When machines learn the human habit of creating metaphors, the first step is to identify the tenors and vehicles in human-created metaphors. The tenor represents the subject, while the vehicle represents the comparative element.\nCurrently, proposed methods mainly focus on using neural networks, such as BiLSTM [1, 17, 19] and BERT [25, 4, 30] to identify tenors and vehicles in metaphors. Although the models used are different, they essentially work by identifying the probability that each token in the metaphor belongs to these two components to obtain tenors (\u672c\u4f53) and vehicles (\u55bb\u4f53). However, this approach is only practical for metaphors that are similes. The simile is a particular type of metaphor that compares tenors and vehicles of different categories using comparator words such as \"like\", \"as\", or \"than\" and tenors and vehicles will appear directly in the simile. For example, in the phrase \"\u95ea\u7535\u50cf\u706b\u86c7\" (lightning like a fire snake), \"\u95ea\u7535\" (lightning) is the tenor, and \"\u706b\u86c7\" (fire snake) is the vehicle.\nHowever, in many metaphors, tenors, and vehicles are not obvious. For example, in the phrase \"\u98de\u6d41\u76f4\u4e0b\u4e09\u5343\u5c3a,\u7591\u662f\u94f6\u6cb3\u843d\u4e5d\u5929\" (flying straight down three thousand feet, suspected to be the Milky Way falling into the sky), the tenor is \"\u7011\u5e03\" (waterfall), but \"\u7011\u5e03\" (waterfall) does not directly appear in the metaphor. Therefore, correctly identifying tenors and vehicles in metaphors is a significant step for metaphor generation tasks. In response to this situation, some studies have used pre-trained models for fine-tuning to generate tenors and vehicles in metaphors, such as T5 [22, 14] and BART [2, 3, 23]. However, this requires a considerable amount of computational resources and data, and these methods make it difficult to explain the reasoning behind metaphorical/literal judgments. Some studies [26, 5, 27, 21] have started using LLMs to identify metaphors and generate metaphors, constructing a series of examples through the use of metaphor theory, but manually constructed examples are expensive and may not necessarily be understandable to LLMs.\nConsidering the above situation, a multi-stage method is proposed to prompt large language models to correctly identify tenors, vehicles, and grounds (\u5171\u6027/\u55bb\u610f) in metaphors. In the first stage, answer candidates are generated by the DeBERTa model, which can help LLMs choose from multiple possible answers and prioritize those with higher confidence. In the second stage, demonstrations generated by LLMs do not require manual generation and can teach the underlying reasoning logic of metaphor recognition to the model without using metaphor theory.\nThe proposed system participated in the NLPCC-2024 Shared Task 9 1.\nThis shared task consists of two subtasks, each including two evaluation tracks. Our method achieved an accuracy of 0.959 in subtask1_track1, 0.979 in sub-task1_track2, 0.951 in subtask2_track1, and 0.941 in subtask2_track2. Except for ranking third in subtask1_track1, it ranked first in all other subtasks.\nThe rest of this paper is organized as follows. The related work on metaphor generation is introduced in Section 2. A detailed description of the proposed system and model is provided in Section 3. The experiment and results are discussed in Section 4. Finally, Section 5 presents the conclusion."}, {"title": "2 Related Work", "content": "Automated Metaphor Identification. Most current work [15, 9, 1, 17, 19] treats metaphor identification as a sequence labeling task using the BiLSTM architecture, outputting metaphorical label sequences for input word sequences (typically sentences). With the introduction of the Transformer, various models based on the Transformer, such as Bidirectional Encoder Representations from Transformers (BERT) [7], ROBERTa [16], DeBERTa [11], etc., have been widely used in various tasks of natural language processing and have achieved amazing"}, {"title": "3 Generative Heuristic-enhanced Prompt Framework Method", "content": "3.1 Task Description\nNLPCC-2024 Shared Task 9 uses machine learning techniques to generate Chinese metaphors by effectively identifying the ground or vehicle in the metaphoric relation. It is divided into two subtasks [21, 20]:\n\u2022 Subtask 1. Metaphor Generation involves creating a metaphor from a provided tuple consisting of TENOR, GROUND, and VEHICLE. The goal here is to synthesize a metaphor that aptly connects the subject (TENOR) with the object (VEHICLE), guided by the concept of the GROUND.\n\u2022 Subtask 2. Metaphor Components Identification, aimed at extracting the TENORS, GROUNDS, and VEHICLES from a symbolic sentence. This component requires identifying metaphor elements that correspond to the specified grounds.\n3.2 Stage I: Answer Candidates Generation\nEach sequence input to DeBERTa includes one question Q and a list of options A. Each question Q is represented as $[q_1, q_2, ..., q_n]$, each option list is"}, {"title": "4 Experiments", "content": "4.1 Dataset and Evaluation Metrics\nDatasets. Task 9 includes a training set of 34,463 metaphorical sentences with tenors, vehicles, and annotated grounds, and two validation sets of 500 sentences each, consistent with the test set format.\nMetrics. We use accuracy to evaluate the effectiveness of the model. For each task, two assessment tracks are provided:\n\u2022 Track 1: LLMs track. The Track encourages using large models to generate options directly. You can use your prompts, but please use a common prompt during the answer phase: \"The answer is {}.\".\n\u2022 Track 2: Rule-based track. The Track encourages using traditional language rules or machine learning-based methods to directly compare and draw conclusions about options A, B, C, and D.\n4.2 Implementation Details\nQwen2-plus was chosen as the LLM in the response generation stage due to its ability to generate high-quality Chinese responses. First, a vector representation for each question is computed using DeBERTa. Then, the question representations are processed by the k-means clustering algorithm to produce three clusters of questions. The checkpoint used for DeBERTa is IDEA-CCNL/Erlangshen-DeBERTa-v2-710M-Chinese 2. An AdamW optimizer with a learning rate of 2e-5 is used. Due to the limitation of computing resources, the batch size is set to 1. The weight decay is set to 0.01. The neural ranker is trained for 5 epochs.\n4.3 Empirical Results\nSince this task contains two subtasks, each subtask can submit results according to the requirements of Track 1 and Track 2. Therefore, there are four results in total: subtask1_track1, subtask1_track2, subtask2_track1, and subtask2_track2.\n4.4 Analysis and Discussion\nQuestion Clustering and Demonstration Sampling. When clustering the question using the k-means algorithm, the number of clusters was chosen as 3 based on the elbow method shown in Fig. 2a and Fig. 2c. The final clustering scatter plot is presented in Fig. 2b and Fig. 2d. Several methods of selecting"}, {"title": "5 Conclusion", "content": "A multi-stage framework was proposed to effectively enhance the ability of LLMs to recognize grounds and vehicles in Chinese metaphorical sentences. In the first stage, the DeBERTa model is used to generate answer candidates. Experiments have shown that introducing answer candidates in the prompt improves the recognition performance of LLMs, and this effect persists even when DeBERTa performs poorly. In the second stage, problems in the validation set are clustered, and representative problems are selected as examples. By introducing answer candidates, a heuristic-enhanced prompt is formed. Experiments have demonstrated that this method effectively improves the capability of LLMs. Additionally, ablation experiments reveal that answer candidates and the generated examples significantly contribute to the final results."}]}