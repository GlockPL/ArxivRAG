{"title": "COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models", "authors": ["Kehui Liu", "Zixin Tang", "Dong Wang", "Zhigang Wang", "Bin Zhao", "Xuelong Li"], "abstract": "Leveraging the powerful reasoning capabilities of large language models (LLMs), recent LLM-based robot task planning methods yield promising results. However, they mainly focus on single or multiple homogeneous robots on simple tasks. Practically, complex long-horizon tasks always require collaborations among multiple heterogeneous robots especially with more complex action spaces, which makes these tasks more challenging. To this end, we propose CO-HERENT, a novel LLM-based task planning framework for collaboration of heterogeneous multi-robot systems including quadrotors, robotic dogs, and robotic arms. Specifically, a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism is designed to decompose and assign actions for individual robots, where a centralized task assigner makes a task planning proposal to decompose the complex task into subtasks, and then assigns subtasks to robot executors. Each robot executor selects a feasible action to implement the assigned subtask and reports self-reflection feedback to the task assigner for plan adjustment. The PEFA loops until the task is completed. Moreover, we create a challenging heterogeneous multi-robot task planning benchmark encompassing 100 complex long-horizon tasks. The experimental results show that our work surpasses the previous methods by a large margin in terms of success rate and execution efficiency. The experimental videos, code, and benchmark are released at https://github.com/MrKeee/COHERENT.", "sections": [{"title": "I. INTRODUCTION", "content": "With the rapid development of deep learning technologies in robotics, learning-based methods with extensive data pro-duce impressive results both in single-robot [31], [32] and multi-robot systems [35]. However, even with the continuous expansion of datasets, the performances of these methods still struggle with generalization [36], [37]. The reason is that these methods lack comprehensive prior knowledge in dealing with unseen tasks, scenes and new robot types.\nEncouraged by the rich world knowledge of pre-trained large language models (LLMs) and their excellent capability in complex reasoning, many recent works [26], [27], [28] have utilized LLMs to analyze and decompose complex task instructions, achieving promising results in robot task planning. As shown in Figure 1(a), many single robot task planning methods leverage few-shot prompting techniques to generate multi-stage task and motion plans [29], and even robot control code [33], [22]. Compared to single-robot systems, multi-robot systems have attracted more attention since they are able to handle more complex tasks [2], [3], [4] in recent years. For homogeneous multi-robot systems, some works [5], [6], [25], [38] have found that the adoption of dia-logue and discussion between multiple LLM-enabled robots can release cognitive synergy ability, improve reasoning, and reduce hallucinations in complex tasks, as depicted in Figure 1(b). In [7] and [8], they try to generate detailed task planning via multi-turn dialogue and discussion among individual robots. However, there are many practical scenes that require collaborations between multiple heterogeneous robots, where each is characterized by different action skills. To generate correct task planning for heterogeneous robot systems, the challenge lies in accurately understanding each robot's action capabilities under changing environments, and conducting accurate task decomposition, allocation, and collaboration among different robots, which are not fully explored yet.\nTo this end, we present COHERENT, a novel LLM-based centralized hierarchical framework for heterogeneous multi-robot task planning as shown in Figure 1(c). Our framework conducts multiple Proposal-Execution-Feedback-Adjustment (PEFA) cycles between a centralized task assigner and indi-vidual robot executors to finish a complex long-horizon task. The centralized task assigner is instantiated by prompting an LLM to decompose high-level task instructions into subtasks and assign each subtask to different robots. Each robot"}, {"title": "II. RELATED WORKS", "content": "Prior works can be roughly classified into three categories: classic logic-based, learning-based, and LLMs-based. Classic logic-based methods [9], [10], [11], [12], primarily utiliz-ing Planning Domain Description Language (PDDL) [9], leverage predicate logic solvers for task planning. However, these methods are unsuitable for large-scale open world and unknown environment exploration. Learning-based methods [15], [14] are represented by hierarchical reinforcement learning (HRL), which demonstrates more adaptability and flexibility in handling dynamic environments. Despite the progress made in HRL [13], these methods continue to grapple with the well-recognized challenge of learning in-efficiency, which poses substantial hurdles in their practi-cal applicability within real-world environments. Recently, LLMs with powerful commonsense knowledge and reason-ing ability present a promising avenue for addressing these limitations [19]. Several studies have been proposed to tackle various complex scenarios, such as household manipulation [20], [23], [21], [22] and navigation [25], [24]. These LLM-based methods with zero-shot [26], [27] or few-shot [28] prompts demonstrate robust generalization toward novel in-structions and unseen environments."}, {"title": "B. Multi-robot Planners based on LLMs", "content": "According to the decision-making scheme, multi-robot planners based on LLMs can be categorized into two frameworks: decentralized and centralized. In dialogue-style methods [7], [8], [39], each robot delegated to an LLM agent exchanges its abilities and observations through communica-tions to determine the next action. For example, RoCo [7] proposes a multi-round dialogue framework with feedback to solve table-top manipulation tasks. Zhang et al. [8] propose a modular dialogue-style framework for embodied agents to plan, communicate, and cooperate in VirtualHome-Social [16], [17]. Liu et al. [39] utilizes the communication module to make ad hoc agent join the original team. However, the prompt length escalates considerably along with the number of robots involved and the iteration of dialogue [18], [7], resulting in unstable performance due to LLM's inferiority in long-context reasoning. Conversely, centralized methods [1], [18] utilize only one central LLM to decompose and allocate the work for all robots at each planning iteration. Chen et al. [18] compare both dialogue-style and centralized paradigms on four multi-agent 2D task scenarios, and demonstrate that centralized communication shows a better task success rate and token efficiency than the other. Unlike most studies merely involving homogeneous settings, in this paper, we focus on designing a heterogeneous multi-robot system in large-scale realistic environments."}, {"title": "III. METHOD", "content": "As shown in Figure 2, COHERENT conducts the task as-signment and robot execution in multiple loops of Proposal-Execution-Feedback-Adjustment (PEFA). We consider a liv-ing room scenario with a low sofa and a high dining table. Three types of robots are tasked with the task instruction I: Place the apple from the sofa to the dining table. This typical heterogeneous robot collaboration task requires a quadrotor to serve as a transport bridge between the robotic dog and the robotic arm. In this section, we detail the key components of our PEFA mechanism through this example."}, {"title": "A. Task Planning Proposal", "content": "As shown in Figure 2(a), a centralized Task Assigner LLM takes the instruction I as input. Meanwhile, it considers the task background, the capabilities and partial observations of all robots, historical dialogue records, and important notes within the prompt. Specifically, the task background describes our heterogeneous multi-robot settings, and each robot's capabilities are represented to distinguish different action spaces. The observations of each robot are converted into text from a graph structure, which is expressed by the relation(nodel, node2) format, e.g., ON (apple, coffee table), and just include visible objects in their respective rooms. Note that each robot is unaware of environments in other rooms and objects within closed containers. Dialogue history stores memories of historical task planning proposals and execution feedback as shown in in Figure 2(d), and important notes are defined by some critical tips for special situations, as the fixed prompts starting with keyword Note. The information is fused to form a long text prompt for Task Assigner LLM. The output is a task planning proposal, composed of one assigned robot and one subtask to be finished in the format <assigned robot>: subtask. The complete and detailed input/output formats are shown in the supplemental videos.\nIn the given example, using the prompts designed above as input, Task Assigner LLM assigns specific subtasks to different robots as the initial proposal in the format:\n1) <robotic dog>: pick up the <apple> and give it to <quadrotor>.\n2) <quadrotor>: transport the <apple> to the <dining table>.\n3) <robotic arm>: put the <apple> on the <dining table>.\nBased on the sequential order, the Task Assigner LLM outputs the first subtask to the Robot Executor LLM of the robotic dog in the next module. Each reasoning process and initial proposal will be stored in the dialogue history to update the next proposal with a different robot or plan."}, {"title": "B. Assigned Subtasks Execution", "content": "As shown in Figure 2(b), the Execution Module takes the proposal plan for the assigned robot as input and checks if the assigned subtask is executable by the assigned robot. Specifically, each assigned robot is equipped with one spe-cific Robot Execution LLM, whose prompt is construed by the proposal plan, capabilities, partial observations and an executable action list of the assigned robot. The action list is generated based on the current state and observations using predefined rules as shown in Table I. Note that the prompts of the different robots from the same robot type have the same capabilities but different observations and action list at each timestep. Considering the partial observation and limitations in the capability of the assigned robot, the action validation process will further determine whether it is executable in the physical world before outputting the action assigned to the robot. We assume that there is a robotic dog. For example, the action [puton] <apple> on <dining table> is not executable due to the height limitation. In such cases, the next Feedback Module analyzes the failure in detail and sends the feedback back to the Task Assigner. If the action is executable, it returns the task's progress to the Feedback Module and then proceeds to the next subtask.\nFor the example considered, the Robot Executor LLM acts as the action selection policy to select the most appropriate action, e.g., [grab] <apple>. However, when hallucina-tions occur, the proposal might instruct the robotic dog to"}, {"title": "C. Robot Execution Feedback", "content": "Using the results of the action validation process as input, the self-reflection provides low-level execution feedback for high-level subtask decomposition in the next iteration, enabling bottom-up task correction. As shown in Figure 2(c), this feedback includes corrections after action failures and progress updates after successful executions.\nSpecifically, failure feedback demonstrates the mistake in the subtask proposal or action execution. For the failure feedback, there are three typical situations. First, the proposal contains a fully wrong step to complete I, often caused by LLM hallucinations. Second, the subtask proposals are cor-rectly generated but assigned to the wrong robot, leading to execution issues. Third, even with the correct robot assigned, the action cannot be performed due to execution limitations. For the success feedback, the assigned robot will analyze whether the executed action fully satisfies the subtask. If the subtask requires multiple steps and the current action only partially completes it, the task's execution progress will be updated and fed back to the Task Assigner, indicating that the subtask is not fully completed and further actions are required until the assigned robot finishes its subtask.\nFor example, if the robotic dog grabs the apple, it will be instructed to move toward the quadrotor as the next step. However, if the robotic dog is not near the coffee table yet, the failure feedback will indicate that it is too far from the apple to grab. In the case of an incorrect task assignment to another robot, the feedback will clarify that the robot lacks the capability to complete the task, requiring the assistance of a different type of robot."}, {"title": "D. Subtask Proposal Adjustment", "content": "As shown in Figure 2(d), the Adjustment Module gath-ers all task-level information and appends the execution feedback to the dialogue history from the most recent five iterations to improve token efficiency, which sets a solid foundation for a new PEFA cycle. This module supports the correction to the next subtask, establishing a dynamic and adaptive assigning-execution loop for the long-horizon task I."}, {"title": "IV. EXPERIMENTS", "content": "As shown in Figure 3, we create a large-scale realistic embodied benchmark tailored for heterogeneous multi-robot collaboration, including quadrotors, robotic dogs, and robotic arms. Built upon the BEHAVIOR-1K platform [30], our benchmark covers 5 typical real-world scenes: 2 apartment scenes (S1, S2), 1 apartment with garden scene (S5), 1 grocery store (S3) and 1 restaurant (S4), with a wide range of interactive objects (both rigid and articulated) and various layouts (e.g., multi-room and multi-floor). The ground truth (GT) of each task represents the optimal number of steps for completion. Based on the minimum necessary number of robot types to perform each task, the benchmark is split into three categories :"}, {"title": "Experiment setting:", "content": "Our method is validated in the simulation environment of BEHAVIOR-1K platform [30], employing gpt-4-0125-preview as LLM to conduct all experiments. Considering the cost of the OpenAI API, we select 40 tasks from all 100 tasks in the benchmark for our experiments. These tasks are sourced from all 5 distinct simulation scenes in our benchmark. 8 tasks are verified in each simulation scene, comprising 2 mono-type tasks, 3 dual-type tasks, and 3 trio-type tasks. The selected tasks allow for a comparison of our method with other baselines across various types and levels of difficulty."}, {"title": "Compared methods:", "content": "Based on the different communica-tion architectures among multiple robots, we compare our method with three other approaches. In addition to LLM-based methods, we also compared two traditional tree search algorithms in task planning to demonstrate the effectiveness of our approach."}, {"title": "V. CONCLUSIONS", "content": "In this paper, we propose COHERENT, a novel frame-work designed to address task planning in heterogeneous multi-robot systems. Leveraging the reasoning capability of LLMs, we facilitate precise task allocation and timely im-provements through a continuous loop of proposal-execution-feedback-adjustment between the task assigner and various robot executors. Moreover, we propose a challenging bench-mark specifically tailored for heterogeneous multi-robot task planning, including 5 scenes and a total of 100 tasks across three types. Our method achieves the best results in this benchmark and has been successfully experimented in the real world."}, {"title": "Reason 1:", "content": "The dialogue-based method is more appropriate for robots to execute actions in parallel because each robot tends to select its own actions to achieve the objective. Lacking an understanding of other robots' capabilities and observations, it is challenging for each robot to make accu-rate judgments about the actions others should execute. This is the primary reason for the failure of such methods."}, {"title": "Reason 2:", "content": "Decisions made during the robot discussion process are not executed. However, subsequent robots tend to plan the next actions based on the assumption that previous actions in the dialogue have already been executed. This results in hallucinatory actions not existing in the current list of executable actions, causing failures in action parsing."}, {"title": "Reason 3:", "content": "The actions resulting from discussions among robots are often trapped in repetitive cycles, hindering progress toward the ultimate objective. The issues stem from decision-makers lacking comprehensive information and a long-term plan."}, {"title": "D. Real-world Experiment", "content": "To demonstrate the effectiveness of COHERENT in the real world, we conduct experiments with multiple hetero-geneous robots in real-world scenes. We utilize our self-developed swarm consisting of three quadrotors, a Unitree's Aliengo robotic dog equipped with a small mechanical arm on the back, and a Franka Panda robotic arm. The quadrotor swarm and robotic dog use LiDAR mapping for navigation, and the robotic arm is equipped with a wrist RGB-D camera to capture visual information. Grounding-DINO[34] is utilized for object detection to help grasping. Besides, the communication between different robots and the host computer is based on socket connections.\nAs shown in Figure 5, the user issues a voice command Go to the kitchen and get something to eat. The visual perception model identifies that the door to the kitchen is closed. Furthermore, the Task Assigner LLM decides to first have the robotic dog use its arm to open the door rather than let the quadrotor swarm pass the door. Then the quadrotor swarm collaborates with the robotic arm fixed in the kitchen to bring the cookies back. Our experiments prove that COHERENT can be extended to real-world environments in a zero-shot manner and exhibits generalization."}, {"title": "A. Benchmark", "content": "As shown in Figure 3, we create a large-scale realistic embodied benchmark tailored for heterogeneous multi-robot collaboration, including quadrotors, robotic dogs, and robotic arms. Built upon the BEHAVIOR-1K platform [30], our benchmark covers 5 typical real-world scenes: 2 apartment scenes (S1, S2), 1 apartment with garden scene (S5), 1 grocery store (S3) and 1 restaurant (S4), with a wide range of interactive objects (both rigid and articulated) and various layouts (e.g., multi-room and multi-floor). The ground truth (GT) of each task represents the optimal number of steps for completion. Based on the minimum necessary number of robot types to perform each task, the benchmark is split into three categories : \u2022 Mono-type Tasks represent a homogeneous setting that involves only one type of robot but multiple robots of the same type are allowed. These tasks are relatively simple with GT ranging from 4-8 steps. \u2022 Dual-type Tasks involve the collaboration between two types of robots due to the limited capabilities of single-type robots, with a GT step ranging from 8-12 steps. \u2022 Trio-type Tasks show the most complex heterogeneous setting, necessitating the meticulous collaboration among all three-type of robots. These tasks place high demands on the long-horizon inference capabilities of LLM-based planners, with GT within 10-16 steps. In total, our benchmark contains 32 mono-type tasks, 30 dual-type tasks, and 38 trio-type tasks."}, {"title": "B. Evaluation Metrics", "content": "In this paper, we adopt Success Rate (SR) and Average Step (AS) as the evaluation metrics. For each task, we manually design the optimal execution strategy steps as the ground truth. A task is considered successful if all objects reach their desired locations within twice the ground truth step count. For failed tasks, the execution step count is recorded as twice the ground truth plus one to facilitate uniform statistics. In summary, we aim to achieve higher success rates and fewer average steps."}, {"title": "C. Simulation Experiments", "content": "Experiment setting: Our method is validated in the simulation environment of BEHAVIOR-1K platform [30], employing gpt-4-0125-preview as LLM to conduct all experiments. Considering the cost of the OpenAI API, we select 40 tasks from all 100 tasks in the benchmark for our experiments. These tasks are sourced from all 5 distinct simulation scenes in our benchmark. 8 tasks are verified in each simulation scene, comprising 2 mono-type tasks, 3 dual-type tasks, and 3 trio-type tasks. The selected tasks allow for a comparison of our method with other baselines across various types and levels of difficulty. Compared methods: Based on the different communication architectures among multiple robots, we compare our method with three other approaches. In addition to LLM-based methods, we also compared two traditional tree search algorithms in task planning to demonstrate the effectiveness of our approach. \u2022 DMRS-1D: We implement DAMS-1D baseline as a variant of CoELA [8], which adopts a decentralized multi-robot system framework, allowing robots to de- \u2022 \u2022 \u2022 \u2022 termine the next step through dialogue. The last robot summarizes all the dialogue content to reach the final conclusion. DMRS-2D: Considering that robots speaking earlier in a dialogue round have access to less information, we design a two-round dialogue setting to mitigate the impact of information disparity [8]. CMRS: We design a primitive centralized multi-robot system [27] incorporating only a decision-making LLM. All information is stored in the prompt and then the central LLM outputs executable actions. Primitive MCTS: We employed the primitive Monte Carlo tree search algorithm [40] with a random rollout strategy and the ground-truth reward function. The actions of all robots collectively form the search space. LLM-MCTS: We compare an algorithm that integrates LLM with the Monte Carlo method [19] to enhance the effectiveness of primitive MCTS. LLMs are employed to serve as  \u03c0(\u03b1 | h) in PUCT to guide action selection during the simulation process. Additionally, we conduct ablation studies to evaluate the"}]}