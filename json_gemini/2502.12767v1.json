{"title": "R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs", "authors": ["Sumin Jo", "Junseong Choi", "Jiho Kim", "Edward Choi"], "abstract": "Recent studies have combined Large Language Models (LLMs) with Knowledge Graphs (KGS) to enhance reasoning, improving inference accuracy without additional training while mitigating hallucination. However, existing frameworks are often rigid, struggling to adapt to KG or task changes. They also rely heavily on powerful LLMs for reliable (i.e. trustworthy) reasoning. To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that separates reasoning into two roles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor (a high-capacity LLM) that makes final judgments. This design is cost-efficient for LLM inference while still maintaining strong reasoning accuracy. Additionally, R2-KG employs an Abstention mechanism, generating answers only when sufficient evidence is collected from KG, which significantly enhances reliability. Experiments across multiple KG-based reasoning tasks show that R2-KG consistently outperforms baselines in both accuracy and reliability, regardless of the inherent capability of LLMs used as the Operator. Further experiments reveal that the single-agent version of R2-KG, equipped with a strict self-consistency strategy, achieves significantly higher-than-baseline reliability while reducing inference cost. However, it also leads to a higher abstention rate in complex KGs. Our findings establish R2-KG as a flexible and cost-effective solution for KG-based reasoning. It reduces reliance on high-capacity LLMs while ensuring trustworthy inference.", "sections": [{"title": "1 Introduction", "content": "Recent studies have increasingly integrated Large Language Models (LLMs) with Knowledge Graphs (KGs) to perform knowledge-grounded reasoning (Xu et al., 2024; Kim et al., 2024; Gao et al., 2024; Luo et al., 2024; Ma et al., 2024a; Wang et al., 2024). This approach maximizes reasoning performance by combining the domain-specific knowledge of KGs with the strong reasoning abilities of LLMs (Pan et al., 2024; Zhu et al., 2024).\nHowever, existing LLM-based frameworks are often tailored to specific KGs and tasks, limiting their generalizability (Kim et al., 2023a; Sun et al., 2024; Ma et al., 2024b). These frameworks struggle when the KG changes (e.g., DBpedia (Lehmann et al., 2015) \u2192 Freebase (Bollacker et al., 2008)) or when a new task is introduced (e.g., question answering \u2192 fact verification). Furthermore, these approaches rely on a single LLM to handle the entire reasoning process, including subgraph retrieval and answer generation. As a result, performance is constrained by the reasoning capabilities of the chosen LLM. These limitations underscore the need for a generalizable and cost-efficient framework that remains independent of the KG structure and task type while reducing the reliance on powerful LLMs.\nTo address this, we propose R2-KG, a novel framework where two agents\u2014the Operator and the Supervisor-collaborate on KG-based reasoning tasks. The Operator explores the KG, which consists of numerous triple sets, identifying relevant paths from a given entity, and retrieving necessary information. It iteratively selects and expands linked triples [head_entity, relation, tail_entity]. Once the Operator deems the evidence sufficient, it calls the Supervisor, which evaluates the retrieved information. If inadequate, the Supervisor directs the Operator further exploration; otherwise, it generates the final answer. If sufficient evidence remains unavailable even after multiple iterations, the R2-KG abstains from answering (i.e., abstention mechanism). Our contributions are as follows:\n(1) Low/High-Capacity LLM Separation for Accuracy and Cost Efficiency-The Operator, responsible for KG exploration, employs a low-capacity LLM, while the Supervisor, responsible for verification, employs a high-capacity LLM. This separation improves reasoning performance while significantly reducing overall LLM cost. In simpler evidence collection processes, the Operator alone can be used to minimize inference cost, while the Supervisor is leveraged only for final answer generation, utilizing its superior reasoning capabilities.\n(2) KG & Task-Agnostic Design with Superior Performance\u2014With its modular design, R2-KG operates independently of specific KG structures or task types. To validate its effectiveness, we evaluate it on four KG-based reasoning benchmarks, covering fact verification (Kim et al., 2023b), single-label QA, multi-label QA (Yih et al., 2016; Zhang et al., 2017), and temporal QA (Saxena et al., 2021). Results show that R2-KG outperforms baselines equipped with the abstention mechanism. Notably, it achieves a 100% hit rate on MetaQA and improves micro F1 score by up to 87.8% over the baseline. Since micro F1 accounts for both precision and recall, this gain highlights the effectiveness of R2-KG in multi-label QA and fact verification, demonstrating its adaptability to diverse reasoning tasks.\n(3) Reliable KG-Based Reasoning Task-Reliability in KG-based reasoning is crucial, yet existing tasks focus only on accuracy. We introduce the Reliable KG-Based Reasoning Task, which evaluates whether a framework can abstain when evidence is insufficient, ensuring trustworthiness in critical applications. To measure reliability, we employ various metrics: coverage (i.e., the proportion of R2-KG generated final answer), as well as F1 scores and hit rate when it participates.\n(4) Consistent Reliability with Abstention Mechanism-Furthermore, we analyze the performance of R2-KG using various low-capacity LLMs as the Operator against baselines that rely on high-capacity LLMs throughout the entire process. The results show that R2-KG consistently achieves higher F1 scores and hit rates, with only the abstention rate varying. This highlights that R2-KG maintains cost-efficient advantage, reducing dependency on expensive high-capacity LLMs without compromising reliability (i.e., whether we can trust the answer of R2-KG).\n(5) Single-Agent Version with Strict Self-Consistency Strategy for Further Cost Savings-Additionally, we propose an even more cost-efficient method that does not require high-capacity LLMs as the Supervisor (i.e., single-agent version of R2-KG combined with strict self-consistency strategy (Wang et al., 2023b)). Here, the Operator alone conducts reasoning while enforcing a unanimous agreement criterion across multiple trials, ensuring high answer reliability without a high-capacity LLM. While this approach significantly reduces inference costs, it comes with a trade-off of a higher abstention rate, particularly in complex KGs with temporal information."}, {"title": "2 Related Works", "content": "Research on KG-based reasoning tasks can be broadly categorized into three approaches: embedding-based, semantic parsing-based, and retrieval-augmented (Lan et al., 2022; Ji et al., 2024; Mavromatis and Karypis, 2024). First, the embedding-based method projects the entities and relations of a KG into an embedding space (Saxena et al., 2020). This approach effectively captures complex relationships and multi-hop connections through vector operations.\nSecond, the semantic parsing-based method converts the task into a symbolic logic form (e.g., a SPARQL query (P\u00e9rez et al., 2009)) and executes it on the KG to derive the final answer (Sun et al., 2020; Park et al., 2021; Ye et al., 2022; Gu and Su, 2022; Yu et al., 2023). This approach has the advantage of handling complex queries, such as multi-hop reasoning, through intuitive queries that can be directly applied to the KG.\nThird, the retrieval-augmented method extracts relevant subgraphs from the KG to infer the answers. Recent studies have explored using LLMs for both retrieval and reasoning without additional training (Kim et al., 2023a; Wang et al., 2023a; Jiang et al., 2023; Li et al., 2023; Sun et al., 2024; Ma et al., 2024b). KG-GPT (Kim et al., 2023a)"}, {"title": "2.2 Enhancing Model Reliability via Abstention Mechanism", "content": "To mitigate LLM hallucination, the abstention mechanism has been adopted as a strategy to enhance reliability (Wen et al., 2024b). This mechanism allows the model to refrain from answering when the input query is ambiguous (Asai and Choi, 2021; Cole et al., 2023), goes against human values (Kirk et al., 2023), or exceeds the model's knowledge scope (Feng et al., 2024). The abstention mechanism has been actively explored in LLM-based question-answering tasks, particularly for long-document processing QA (Buchmann et al., 2024) and uncertainty estimation (Amayuelas et al., 2024; Wen et al., 2024a; Yang et al., 2024; Tomani et al., 2024), demonstrating notable improvements in reliability. However, its application in KG-based reasoning remains largely unexplored. We introduce Reliable KG-Based Reasoning Task, the first approach to integrate the abstention mechanism into KG-based reasoning."}, {"title": "3 Reliable KG-Based Reasoning Task", "content": "In this study, we propose the Reliable KG-Based Reasoning Task for the first time. This task serves as a benchmark for measuring reliability in KG-based reasoning, particularly in domains where trustworthy answers are critical, such as industrial applications and fact verification that utilize KGs. By evaluating reliability, this enables the selection of an appropriate framework based on the specific context. Unlike existing KG-based reasoning tasks that focus on generating a definitive answer a (e.g., True / False in fact verification or a direct response in QA) for a given query q (e.g., a query in fact verification or a question in QA), our task introduces the option to abstain when uncertainty arises. This allows the system to either withhold a response when sufficient evidence cannot be retrieved from the KG or avoid providing an unreliable answer based on ambiguous evidence."}, {"title": "3.2 Metrics", "content": "To evaluate the KG-based reasoning task incorporating the abstention mechanism, we measure four key metrics:\nCoverage: The fraction of samples for which a final answer is generated (i.e., the ratio of non-abstained samples).\nCoverage = $\\frac{|S|}{N}$\nwhere S denotes the set of non-abstained samples, and N represents the set of all samples, including abstained and non-abstained cases.\nMicro F1 Score: Computed on S in multi-label tasks using TP\u00bf, FP\u00bf, FN\u00bf, which represent the True Positives, False Positives, and False Negatives for each sample i, respectively.\nMicro F1 =$\\frac{2 \\times Total\\ Precision \\times Total\\ Recall}{Total\\ Precision + Total\\ Recall}$\n$Total Precision = \\frac{\\sum_{i \\in S} TP_i}{\\sum_{i \\in S}(TP_i + FP_i)}, Recall = \\frac{\\sum_{i \\in S} TP_i}{\\sum_{i \\in S}(TP_i + FN_i)}$\nSamplewise F1 Score: Calculated on S in multi-label tasks by computing F1 score for each sample and averaging over S.\nSamplewise F1 = $\\frac{1}{|S|} \\sum_{i \\in S} \\frac{2 \\times Precision \\times Recall_i}{Precision + Recall_i}$\n$Precision = \\frac{TP}{TP + FP}, Recall = \\frac{TP}{TP + FNi}$\nHit Rate: Applicable to both single-label and multi-label tasks. It is counted if any predicted label matches a ground-truth label. Note that the hit rate is the accuracy in binary tasks.\nHit rate = $\\frac{1}{|S|}\\sum_{i \\in S}(\\mathbb{1}(g_i \\in Y_i))$\nWhere $\\mathbb{1}(\\cdot)$ is the indicator function, $\\hat{g_i}$ is one of the framework's predicted label for sample i and $Y_i$ is the set of ground truth labels for sample i."}, {"title": "4 Method", "content": "Our R2-KG consists of three components: An Operator, which explores the KG via helper functions; a Server, which provides requested function output; and a Supervisor, which offers feedback or generates the final answer. Within an iteration limit T, the three components iteratively interacts, gathering triples Gt or relations Rt, at each step t. The Supervisor outputs the final answer once sufficient evidence is collected. If no answer is produced within T, the system returns an Abstention, indicating insufficient understanding of the query."}, {"title": "4.1 Operator", "content": "By leveraging helper functions (described below), the system retrieves relevant subgraphs from the KG. When the Operator requests a function call, the Server responds, and their interactions are stored for future reference. At each step t, the Operator determines the next exploration path based on the accumulated interaction history.\nFor multi-hop reasoning, R2-KG iteratively expands the subgraphs by accumulating relevant triples. Given a query where entity e0 and en are connected through n-hops, the intermediate entities are unknown. At an arbitrary step k, the Operator maintains $E_{seen}^{(t=k)} = {e_0,...,e_{m-1}, e_m}$, which is the set of entities explored up to the previous step, where $E_{seen}^{(t=0)} = {e_0}$. Each $e_i \\in E_{seen}$ is associated with relations $R(e_i) = {r_i^{(1)}, r_i^{(2)},..., r_i^{(n)}}$. In the next step, Operator selects a relevant $e^* \\in E_{seen}$ and one or more relevant relations $R^* \\subseteq R(e^*)$, retrieves the corresponding tail entities, and get a new triple set: ${(e^*, r^*,e_{m+1}) | r^* \\in R^*}$. This process continues until $e_{m+1}$ matches en.\nBy structuring reasoning in this way, R2-KG ensures that each step builds upon previously acquired knowledge, improving both exploration efficiency and reasoning accuracy. The Operator can invoke one or more following helper functions at each step t to facilitate KG exploration:\nGetRelation(e*): The Server returns all relations R(e*) connected to e* in the KG as follows:\ne* = arg max EntScore(e, q)\ne\u2208Eseen\nR(e*) = {ri | (e*, ri, ej) \u2208 KG, \u2200ej}\nThe Operator selects e* that is most relevant to q among Eseen using EntScore(e, q), which is a function that evaluates the relevance between e and q. Note that EntScore(\u00b7) is based not on an explicit implementation but on the inherent language understanding of the Operator.\nExploreKG(e*, R*(e*)): The Server returns G(e*, R*(e*)), a set of all triples such that e* \u2208 Eseen is connected to a tail entity(ej) via the relation ri \u2208 R*(e*). Note that R*(e*) is a subset of R(e*), which is returned by GetRelation() chosen by RelScore() as below:\nR*(e*) = {r | r \u2208 R(e*), RelScore(r, q) > threshold}\nG(e*, R*(e*)) = {(e*, ri, ej) | ri \u2208 R*(e*), ej \u2208 KG}\nRelScore(r, q) evaluates the relevance between r and q based on the inherent language understanding of the Operator. Along with the threshold, it is implicitly applied during the Operator's linguistic reasoning process to select several relations relevant to q.\nVerification (Gk, Rk): If the collected evidence is deemed sufficient, Operator invokes the Supervisor. The Operator provides the triple set Gk and relations Rk gathered up to the current step k(<T) to the Supervisor. If the Supervisor gives back an answer, the process terminates; otherwise, if feedback is given, the next iteration continues.\nkRk = \u222at=1Rt(e*), Gk = \u222at=1Gt(e*, R*(e*))"}, {"title": "4.2 Supervisor", "content": "The Supervisor performs its role only when the Operator invokes Verification(Gk, Rk). Upon invocation, the Supervisor receives the Gk and Rk and returns one of two possible outcomes to the Operator:\n1) Sufficient Evidence (answer): If sufficient information is available, the Supervisor generates a prediction and returns it to the Operator. The final reasoning path optimized for answer generation is constructed by the Supervisor based on its judgment, using Gk.\n2) Insufficient Evidence: If the information is deemed insufficient to make a judgment, feedback is provided to the Operator to collect more information. Based on Gk, Rk, and the q, the Supervisor advises which entity and relation combinations should be further explored."}, {"title": "4.3 Configurable Iteration Limit", "content": "During KG exploration, R2-KG requires at least two iterations to traverse a single hop and retrieve information about a new node. This is because calls to GetRelation(\u00b7) and ExploreKG(\u00b7) must occur in sequence, ensuring that relevant entity and relation are gathered step by step. Therefore, if a q involves N hops, it is recommended to set T to at least 2N. T serves as a hyperparameter, allowing users to adjust the level of reliability they seek from the framework. A lower T increases the rate of Abstain samples, while a higher T reduces this rate."}, {"title": "5 Experiments", "content": "To demonstrate that R2-KG is a plug-and-play approach independent of task and KG variation, we use four challenging benchmarks with diverse query difficulty, KG structures, and task formats. To reduce computational costs, we sample 1,000\u20131,500 instances from large test sets."}, {"title": "5.2 Baselines", "content": "For comparison, we set KG-GPT (Kim et al., 2023a), and ToG (Sun et al., 2024) as baselines, as both can handle various KG structures and tasks to some extent. KG-GPT is a general framework adaptable for fact verification and QA tasks. However, it does not explicitly incorporate an abstention mechanism, therefore we account for implicit Abstention when it is unable to generate an answer due to token length constraints or formatting issues. Additionally, due to the structural modifications required to adapt KG-GPT for WebQSP, we did not conduct experiments on this dataset. ToG is a framework where a single LLM both explores the KG and generates answers. When ToG exceeds the depth limit (i.e., hop limit, hyperparameter used in ToG), it relies on the LLM's parametric knowledge to generate answers, which we treat as Abstention. However, we could not conduct an experiment for CRONQUESTIONS because ToG is designed to handle only triple sets. Additionally, we assess GPT-40 mini's ability to generate answers without KG access. Since its outputs may not always match dataset labels exactly, we consider a prediction correct if it conveys the same conceptual meaning as the ground truth (e.g., treat America as equivalent to USA)."}, {"title": "5.3 Experimental Setting", "content": "For the Operator, we use six LLMs. We employ GPT-40 mini and GPT-40 (OpenAI, 2024a,b) as API-based models, and LLaMA-3.1-70B-Instruct (Meta, 2024), Mistral-Small-Instruct-2409 (Mistral, 2025), Qwen2.5-32B-Instruct, and Qwen2.5-14B-Instruct (Qwen, 2025) as open-source LLMs. The maximum token length was set to 8, 192 for CRONQUESTIONS and FactKG, and 16, 384 for MetaQA and WebQSP. Top-p and temperature were both set to 0.95. For the Supervisor, we use GPT-40. In the main experiment, T was set to 15. All experiments were conducted on a system equipped with two NVIDIA A100 GPUs and four NVIDIA RTX A6000 GPUs."}, {"title": "6 Main Results", "content": "As shown in Table 2, R2-KG significantly outperforms baselines in terms of F1 score across all four benchmarks. Even when using different low-capacity LLMs as the Operator, R2-KG achieves higher scores than ToG and KG-GPT that use GPT-40. Additionally, R2-KG achieves a hit rate of over 90% in three out of the four benchmarks, with MetaQA 3-hop reaching 100%. In WebQSP, TOG with GPT-40 mini marginally outperforms R2-KG in terms of hit rate, but R2-KG achieves significantly higher F1 scores, which is a more suitable metric for multi-label QA, demonstrating its superior reasoning performance. This distinction highlights the advantage of R2-KG not only in single-label QA but also in multi-label QA. The strong performance of R2-KG can be attributed to its Operator's ability to accumulate and utilize information from previous hops in multi-hop reasoning. Within a given T, the framework can revisit and adjust incorrect paths from prior steps, dynamically selecting alternative paths as needed. Furthermore, during inference, the Supervisor is not restricted to a single reasoning path but can flexibly combine relevant triples, leading to more accurate reasoning and answer generation."}, {"title": "6.2 Coverage Across Different LLMs", "content": "Note that R2-KG's coverage is the highest across all cases when using GPT-40 as the Operator. When using relatively low-capacity LLMs, the coverage decreases in varying degrees. The reason why high-capacity LLMs as a Operator achieve higher coverage is twofold: First, they excel at collecting key evidence, allowing them to request Verification() at the optimal moment. Second, their strong language understanding enables them to effectively use the feedback provided by the Supervisor. Table 2 clearly demonstrates that even when R2-KG employs a low-capacity LLM for the Operator, the F1 score and Hit Rate remain high despite a decrease in coverage. This highlights the advantage of R2-KG's separation of the Operator and Supervisor. Since R2-KG maintains answer reliability while only affecting coverage, users can confidently choose an Operator based on their budget constraints."}, {"title": "6.3 Case analysis of Abstention", "content": "Even when T is high, reasoning may still fail, leading to abstention. The most common cases are: (1) Repeated helper function requests\u2014The Operator redundantly calls the same function across multiple steps, even after retrieving the necessary information in previous steps. (2) Failure to interpret Supervisor's feedback\u2014The Operator struggles to incorporate the Supervisor's instructions, especially when directed to collect additional information about a specific entity's relation, failing to refine exploration in later steps. (3) Failure to extract an answer despite sufficient evidence-When the retrieved triple set is overly large, the Supervisor may misinterpret relationships between triples, leading to incorrect judgment. (4) Incorrect function call format\u2014The Operator does not follow the predefined format when calling a helper function, causing parsing issues that prevent information retrieval."}, {"title": "6.4 LLM Usage Statistics", "content": "Table 3 shows the average number of LLM calls per sample for Operator and Supervisor in R2-KG 's reasoning process. It was varied by dataset: the Operator was called between 5.94 and 8.63 requests per sample, while the Supervisor was called between 1.04 and 1.43 times. The Supervisor's call frequency tended to increase with the complexity and difficulty of the query. In comparison, KG-GPT requires at least 3 calls (i.e., Sentence Segmentation, Graph Retrieval, and Inference) to a high-capacity LLM, and ToG makes a minimum of 4 and maximum of 25 requests, depending on the number of reasoning path, which is closely related to the depth and width limit (i.e., hop limit, beam search width limit in KGs) used for ToG hyperparameter. R2-KG employs Low/High-Capacity LLM Separation for accuracy and cost efficiency, significantly reducing high-capacity LLM usage to an average of 1.28 calls per sample, making it both cost-effective and superior in performance."}, {"title": "7 Further Analysis", "content": null}, {"title": "7.1 Effect of Iteration Limit", "content": "Figure 3 illustrates the impact of T on coverage, F1 scores, and hit rate. At 5 < T < 15, coverage improves, whereas F1 scores and hit rate slightly decline. Since solving a query typically requires twice the minimum number of hops, lower T(= 5) causes early termination, leading to lower coverage but higher accuracy on simpler queries. At 10 < T < 15, increased evidence collection enhances coverage, though accuracy slightly drops as queries grow more complex. Beyond 20 iterations, coverage stabilizes while F1 scores and hit rates marginally decrease. This suggests that the optimal iteration range is 10-15 for benchmarks we used, as further steps mainly introduce redundant exploration that is unhelpful for reasoning."}, {"title": "7.2 Single-Agent Version of R2-KG with Strict Self-Consistency", "content": "To further reduce the cost of using a high-capacity LLM as the Supervisor, we leverage a self-consistency (Wang et al., 2023b) strategy where the Operator handles both evidence collection and answer generation (i.e., single-agent version of R2-KG). Without the Supervisor, the Operator assesses evidence sufficiency and generates answers within Verification(\u00b7). The reasoning process runs three trials per instance with T = 10, following these rules; First, unlike the typical majority-based self-consistency strategy, our approach enforces a stricter unanimous agreement criterion for the final prediction. Second, if no agreement is reached or if Abstention appears in any attempt, the final prediction is also Abstention. We apply three reasoning path strategies; Multi-Prompts-Three prompts with distinct few-shot examples for the same query. Query Paraphrasing\u2014Three semantically equivalent query variations. Top-p / Temperature Variation-Three different top-p / temperature settings for Operators.Table 4 presents the results. Note that coverage significantly decreased compared to the dual-agent version of R2-KG, while F1 scores and hit rate were comparable or slightly improved except for CRONQUESTIONS. Despite this, it still significantly outperformed baseline models, in terms of both hit rate (100% on MetaQA 3-hop) and micro F1 scores (WebQSP +55.8%, MetaQA 3-hop +80.2%, and CRONQUESTIONS +48.6%). These results demonstrate that one can obtain higher-than-baseline answer reliability at an even smaller inference cost (i.e. no high-capacity LLM) with a variant of R2-KG, especially Multi-Prompts generally showing high F1 scores and hit rate across all datasets. However, relying solely on low-capacity LLMs limits R2-KG's adaptability to complex KGs such as CRONQUESTIONS (i.e. KGs with temporal information), and the stricter filtering process inevitably results in the rejection of more model predictions, reducing coverage, and overall lower utility compared to the dual-agent version of R2-KG."}, {"title": "8 Conclusion", "content": "We propose R2-KG, the first general KG-based reasoning framework with an abstention mechanism, ensuring the reliability for various KG-based reasoning tasks. Separation of Operator and Supervisor reduced high-capacity LLM usage, leading to a cost-effective solution for KG-based reasoning. Moreover, in simpler KGs, the single-agent version of R2-KG with strict self-consistency can maintain reliability while further reducing cost."}, {"title": "Limitations", "content": "The Supervisor makes the final prediction based solely on the triple set and relation list collected by the Operator. Consequently, it cannot determine whether the retrieved information is minimal or exhaustive. In multi-label QA tasks, this limitation may cause underprediction, where the framework generates fewer answers than the actual number of correct labels. Additionally, if a query can be answered through multiple relation paths, the Supervisor may provide an answer as long as one valid path exists, potentially overlooking alternative correct paths. One way to mitigate this would be to involve the Supervisor in every iteration step, but this would remove the distinction between the Operator and Supervisor roles, increasing computational costs. These constraints stem from the trade-off between cost-effectiveness and reasoning efficiency. While the current design optimizes resource usage, it may not always capture all possible answers in complex reasoning scenarios."}, {"title": "Ethical Consideration", "content": "LLM-based KG reasoning requires substantial computational resources, which can contribute to environmental concerns. While our study proposes methods to reduce overall LLM usage, the reliance on large-scale models remains a consideration in terms of environmental impact."}, {"title": "3.1 Task Definition", "content": "In this study, we propose the Reliable KG-Based Reasoning Task for the first time. This task serves as a benchmark for measuring reliability in KG-based reasoning, particularly in domains where trustworthy answers are critical, such as industrial applications and fact verification that utilize KGs. By evaluating reliability, this enables the selection of an appropriate framework based on the specific context. Unlike existing KG-based reasoning tasks that focus on generating a definitive answer a (e.g., True / False in fact verification or a direct response in QA) for a given query q (e.g., a query in fact verification or a question in QA), our task introduces the option to abstain when uncertainty arises. This allows the system to either withhold a response when sufficient evidence cannot be retrieved from the KG or avoid providing an unreliable answer based on ambiguous evidence."}, {"title": "A Performance on 1-Hop and 2-Hop Questions", "content": "The MetaQA dataset consists of 1-hop, 2-hop, and 3-hop questions; however, our experiments focused exclusively on 3-hop questions. Given that the KG of MetaQA is relatively small and that 1-hop and 2-hop questions are considerably simpler than 3-hop questions, we excluded them from our primary evaluation. Nevertheless, to assess the R2-KG across different levels of task complexity, we randomly sampled 100 questions from 1-hop and 2-hop sets and evaluated the performance. As shown in Table 6, R2-KG exhibited strong performance with high coverage."}, {"title": "B Examples of the Two Excluded Question Types in CRONQUESTIONS", "content": "Unlike the three other datasets, CRONQUESTIONS is constructed with a five-element KG, where each quintuple follows the format: [head, relation, tail, start time, end time]. This structure includes temporal information, specifying the start and end years of an event. CRONQUESTIONS contains five types of reasoning tasks: Simple time, Simple entity, Before/After, First/Last, and Time Join. However, in our experiments, we excluded the Before/After and First/Last question types. The primary reason is that, while our framework predicts answers based on the KG, these question types often contain subjective ground truth labels that do not fully align with the available KG information. For example, this is the sample of Before/After question: \"Which team did Roberto Baggio play for before the Italy national football team?\" Using our framework, we can retrieve the following KG facts related to Roberto Baggio: [Roberto Baggio, member of sports team, ACF Fiorentina, 1985, 1990] [Roberto Baggio, member of sports team, Brescia Calcio, 2000, 2004] [Roberto Baggio, member of sports team, Vicenza Calcio, 1982, 1985] [Roberto Baggio, member of sports team, Juventus F.C., 1990, 1995] [Roberto Baggio, member of sports team, Italy national football team, 1988, 2004] [Roberto Baggio, member of sports team, A.C. Milan, 1995, 1997] [Roberto Baggio, member of sports team, Bologna F.C. 1909, 1997, 1998]. According to the KG, Roberto Baggio joined the Italy national football team in 1988. Before that, he played for Vicenza Calcio (starting in 1982) and ACF Fiorentina (starting in 1985), meaning both teams are valid answers. However, the ground truth label in the dataset only includes ACF Fiorentina, omitting Vicenza Calcio, despite it being a correct answer based on the KG. Due to this labeling inconsistency, objective evaluation of these question types becomes unreliable. As a result, we decided to exclude these types from our experiments."}, {"title": "C Prompt Structure and Usage", "content": "Each prompt for Operator consists of three components: Task description, Helper function explanations, and three few-shot examples. When using R2-KG, users only need to modify the few-shot examples to match the specific dataset while keeping the rest of the prompt unchanged. Examining the prompts reveals that when the Operator requests a helper function, the Operator can request multiple instances in a single iteration based on its needs. Additionally, it can request different types of functions simultaneously. The prompt for Supervisor contains the following elements: Task description, triples collected so far by the Operator, a relation list for each entity, and few-shot examples. The reason for explicitly including the entity-wise relation list is to ensure that when the Supervisor provides feedback to the Operator, it requests subgraphs that actually exist in the KG. During pilot testing, when the relation list was not provided, the system occasionally requested non-existent entity-relation pairs in the KG. This resulted in ineffective feedback and ultimately failed to assist the Operator in its KG exploration."}, {"title": "D Final Reasoning Path Construction", "content": "When sufficient evidences are given from Operator to Supervisor, then the Supervisor selects the necessary triples and constructs a final reasoning path that aligns with the claim structure. Assume that the given query is \"Which languages were used in the films directed by the same directors as [The Vanishing American]\" and Gk given by the Operator are as follows (tilde (~) represents the inverse direction of relation): [The Vanishing American, directed_by, George B. Seitz], [George B. Seitz, directed_by, The Last of the Mohicans], [George B. Seitz, ~directed_by, Love Finds Andy Hardy], [The Last of the Mohicans, in_language, English], [Love Finds Andy Hardy, in_language, French]. Then, Supervisor generates two final reasoning paths: (The Vanishing American-George B. Seitz-The Last of the Mohicans-English), and (The Vanishing American-George B. Seitz-Love"}, {"title": "FR2-KG Combined with Self-Consistency Strategy", "content": "Table 7 shows the result of combining the self-consistency strategy with the dual-agent approach. The Supervisor generated the final answer based on three trials, leading to stricter predictions. As a result, coverage was lower compared to using dual-agent R2-KG alone. For WebQSP and MetaQA, the F1 score was lower than that of a single trial of the dual-agent R2-KG, whereas the hit rate was significantly higher. This is because, applying the strict self-consistency technique, some multi-label predictions were filtered out, meaning the model did not perfectly match all ground truth labels but still correctly predicted at least one. For CRONQUESTIONS, coverage, F1 scores, and hit rate were relatively lower. This dataset contains a significantly higher number of ground truth labels than others, making it difficult for any single trial to cover all labels."}]}