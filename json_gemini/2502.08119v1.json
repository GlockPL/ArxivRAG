{"title": "Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles", "authors": ["Jiahao You", "Ziye Jia", "Chao Dong", "Qihui Wu", "Zhu Han"], "abstract": "The increasing deployment of unmanned surface vehicles (USVs) require computational support and coverage in applications such as maritime search and rescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerial services, and ground stations (GSs) can provide powerful supports, which can cooperate to help the USVs in complex scenarios. However, the collaboration between UAVs and GSs for USVs faces challenges of task uncertainties, USVs trajectory uncertainties, heterogeneities, and limited computational resources. To address these issues, we propose a cooperative UAV and GS based robust multi-access edge computing framework to assist USVs in completing computational tasks. Specifically, we formulate the optimization problem of joint task offloading and UAV trajectory to minimize the total execution time, which is in the form of mixed integer nonlinear programming and NP-hard to tackle. Therefore, we propose the algorithm of generative artificial intelligence-enhanced heterogeneous agent proximal policy optimization (GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actor network ability to model complex environments and extract high-level features, thereby allowing the algorithm to predict uncertainties and adapt to dynamic conditions. Additionally, GAI stabilizes the critic network, addressing the instability of multi-agent reinforcement learning approaches. Finally, extensive simulations demonstrate that the proposed algorithm outperforms the existing benchmark methods, thus highlighting the potentials in tackling intricate, cross-domain issues in the considered scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the increasing demand for unmanned surface vehicles (USVs) in applications such as maritime search and rescue highlights the need for robust computational support and flexible coverage [1]. To address these demands, unmanned aerial vehicles (UAVs) offer low-cost, flexible aerial services, while ground stations (GSs) provide powerful computational resources. The multi-access edge computing (MEC) framework can provide a distributed computing infrastructure that allows USVs to offload computationally intensive tasks to nearby UAVs and GSs, reducing latency and improving efficiency. Therefore, UAVs and GSs can cooperate within an MEC framework to assist USVs in tackling complex scenarios by complementing each other's capabilities [2]-[4].\nDespite the potential of this collaborative MEC framework, there exist several challenges. USVs often operate under trajectory uncertainties and limited computational resources, while task generation is inherently unpredictable. Additionally, the heterogeneity among USVs, UAVs, and GSs, which arises due to differing communication capabilities, and resource limitations, further complicates effective coordination [5]-\n[7]. These challenges necessitate advanced MEC frameworks capable of handling task uncertainties, dynamic conditions, and heterogeneous environments.\nExisting cooperative schemes for USVs, UAVs, and GSs within the MEC paradigm primarily focus on task allocation [8] or hybrid communication networks [9]. While these approaches improve coordination and enable computational offloading, they often struggle to address the inherent uncertainty and complexity of real-world applications. Multi-agent reinforcement learning (MARL) emerges as a promising approach within MEC, enabling agents to adaptively interact with dynamic environments [10], [11]. However, traditional MARL algorithms face limitations in extracting high-level features and maintaining training stability in the presence of environmental uncertainties. Generative artificial intelligence (GAI) offers a compelling solution to these challenges. By leveraging GAI models such as generative adversarial network (GAN) and transformer, MARL algorithms in MEC scenarios can achieve higher sampling efficiency, better generalization capabilities, and enhanced robustness to dynamic conditions. Specifically, GAI improves feature extractions in actor networks and stabilizes training for critic networks, addressing the limitations of traditional MARL [12], [13].\nIn this work, we propose a cooperative UAV and GS-based robust MEC framework to support USVs in completing computational tasks. The framework leverages the flexibility of UAVs and the computational power of GSs within an MEC environment to handle task uncertainties and USV trajectory randomness effectively. To optimize the collaboration, we"}, {"title": "II. SYSTEM MODEL", "content": "As shown in Fig. 1, the MEC framework consists of USVs, UAVs, and GSs. UAVs are equipped with MEC servers to assist USVs, while GSs provide powerful computational capabilities. The sets of USVs, UAVs, and GSs are denoted as $\\mathcal{S} = {1, 2, ..., I}$, $\\mathcal{U} = {1, 2, ..., J}$, and $\\mathcal{G} = {1, 2, ..., K}$, respectively. The system time duration is divided into discrete time slots $\\mathcal{T} = {1,2,...,T}$ with each slot of duration $\\tau$. Each USV $i \\in \\mathcal{S}$ generates a task $A_i(t) = {d_i(t), c_i(t)}$ at time $t$, where $d_i(t)$ is the data size, and $c_i(t)$ is the required computation in CPU cycles per bit. Task generation follows a poisson distribution with mean $\\lambda_i$. USVs perform tasks such as environmental monitoring and emergency response. The task execution involves three stages: local computation on USVs, transmission and computation on UAVs, and transmission and computation on GSs.\nCommunication Model\nUSV to UAV (U2U): The path loss between USV $i$ and UAV $j$ is modeled as\n$\\mathcal{E}_{i,j} (t) = \\frac{S_{L} - S_{NL}}{1 + a \\exp \\{-b[S_{i,j} (t) - a]}} + 20 \\lg (\\frac{4 \\pi f_c || l_i(t) - l_j(t)||}{C}) + S_{NL},$\n(1)\nin which $f_c$ denotes the carrier frequency, and $C$ represents the speed of light. $S_L, S_{NL}, a$, and $b$ are parameters characterizing the environment [14]. The average rate between USV $i$ and UAV $j$ is computed as\n$R_{i,j}^{u2u} (t) = B_{i,j}^{u2u} (t) \\log_2 (1 + \\frac{P_{i,j}^s}{\\mathcal{N}_{G}}),$\n(2)\nwhere $B_{i,j}^{u2u} (t)$ is the available bandwidth at UAV $j$ from USV $i$, $P_{i,j}^s$ represents the transmitting power of USV $i$, and $\\mathcal{N}_{G}$ indicates the power of the additive white Gaussian noise.\nUSV to GS (U2G): The channel power gain from USV $i$ to GS $k$ is\n$G_{i,k} (t) = G_0(||l_i(t) - l_k^g(t)||)^{-2},$\n(3)\nwhere $G_0$ is the channel power gain when $||l_i(t) - l_k^g(t)||^2$ equals 1m [3]. Consequently, the transmission rate from USV $i$ to GS $k$ is\n$R_{i,k}^{u2g} (t) = B_{i,k}^{u2g} (t) \\log_2 (1 + \\frac{P_{i,k}^s}{\\mathcal{N}_{G}}).$\n(4)\nwhere $B_{i,k}^{u2g} (t)$ represents the available bandwidth at GS $k$ from USV $i$.\nUSV Mobility Model\nThe positions of USVs, UAVs, and GSs are depicted by a three-dimensional cartesian coordinate system, i.e., $l_i(t) = (x_i(t), y_i(t), h_i(t))$, $l_j^u(t) = (x_j^u(t), y_j^u(t), h_j^u(t))$, and $l_k^g(t) = (x_k^g(t), y_k^g(t), h_k^g(t))$, respectively. It is assumed that USVs follow the Gauss-Markov mobility model [5], [15]. Specifically, the velocity of USV $i$ at time slot $t$ can be described as\n$v_i(t + 1) = \\mu v_i(t) + (1 - \\mu) \\overline{v} + \\sigma \\sqrt{1 - \\mu^2} w_i(t),$\n(5)\nwhere $v_i(t) = (v_x(t), v_y(t),0)$ denotes the velocity vector and $w_i(t) = (w_x(t), w_y(t), 0)$ represents an uncorrelated random Gaussian process $\\mathcal{N}(0, \\sigma^2)$. $\\mu$, $\\overline{v}$, and $\\sigma$ denote the memory level, asymptotic mean, and asymptotic standard deviation of velocity, respectively. Therefore, the location is updated as\n$l_i(t+1) = l_i(t) + v_i(t) \\tau.$\n(6)\nUAV Mobility Model\nTo save energy, UAVs maintain a constant altitude H above the ground, thereby preventing frequent ascents and descents. Consequently, we consider the horizontal flight of the UAV over the target area, which requires modeling the UAV's flight dynamics. In time slot $t$, the flying horizontal azimuth $\\theta_j(t)$ of UAV $j$ and the flying distance $k_j(t)$ should satisfy the following constraints\n$\\theta_j(t) \\in [0, 2\\pi], \\forall j \\in \\mathcal{U}, \\forall t \\in \\mathcal{T},$\n(7)\nand\n$k_j(t) \\in [0, k_{max}], \\forall j \\in \\mathcal{U}, \\forall t \\in \\mathcal{T},$\n(8)\nwhere $k_{max}$ represents the maximum distance a UAV can fly in time slot $t$, and the flying distance is calculated as\n$k_j(t) = ||l_j^u(t + 1) - l_j^u(t)||.$\n(9)\nAdditionally, the horizontal location coordinates $x$ and $y$ of UAV $j$ at time $t$ can be determined using the horizontal azimuth $\\theta_j(t)$ and the flying distance $k_j(t)$ as\n$x_j^u(t) = x_j^u(0) + \\sum_{t=1}^{t} k_j (t) \\cos(\\theta_j (t)),$\n(10)\nand\n$y_j^u(t) = y_j^u(0) + \\sum_{t=1}^{t} k_j (t) \\sin(\\theta_j (t)).$\n(11)\nTo ensure UAVs stay within the target area, which affect trajectory decisions, the following constraints should be satisfied:\n$0 \\leq x_j^u(t) \\leq x_{max},\\forall j \\in \\mathcal{U}, t \\in \\mathcal{T},$\n(12)\nand\n$0 \\leq y_j^u(t) \\leq y_{max}, \\forall j \\in \\mathcal{U}, t \\in \\mathcal{T},$\n(13)\nwhere $x_{max}$ and $y_{max}$ denote the maximum X and Y coordinate values of the target area, respectively.\nComputation Model\nIn each time slot $t$, the task $A_i(t)$ generated by USV $i$ can be processed locally or offloaded to a UAV $j$ or a GS $k$. The offloading decisions are represented by binary variables\n$p_{i,j}(t) = \\begin{cases} 1, & \\text{if USV } i \\text{ offloads to UAV } j, \\\\ 0, & \\text{otherwise.} \\end{cases},$\n(14)\nand\n$q_{i,k}(t) = \\begin{cases} 1, & \\text{if USV } i \\text{ offloads to GS } k, \\\\ 0, & \\text{otherwise.} \\end{cases}.$\n(15)\nIt is worth noting that for task $A_i(t)$, only one UAV and one GS can be selected for offloading computation within the same time slot, i.e.,\n$\\sum_{j=1}^{J} p_{i,j} (t) \\leq 1, \\forall i \\in \\mathcal{S}, t \\in \\mathcal{T},$\n(16)\nand\n$\\sum_{k=1}^{K} q_{i,k}(t) \\leq 1, \\forall i \\in \\mathcal{S}, t \\in \\mathcal{T}.$\n(17)\nLet $\\alpha_i(t), \\beta_i(t)$, and $\\gamma_i(t)$ denote the proportions of workload $A_i(t)$ processed by USV $i$, UAV $j$, and GS $k$, respectively, such that $\\alpha_i(t) + \\beta_i(t) + \\gamma_i(t) = 1$. The total workload can be expressed as\n$A_i(t) = \\alpha_i(t)A_i(t) + \\beta_i(t)A_i(t) + \\gamma_i(t)A_i(t).$\n(18)\nAt each time slot $t$, the dynamic changes in task queues for USVs, UAVs, and GSs are updated as\n$Q_i(t+1) = \\text{max}\\{0, Q_i(t) + \\alpha_i(t)d_i(t) - \\tau f_i \\},\\newline$\n(19)\n$Q_j^u(t + 1) = \\text{max}\\{0, \\sum_{i=1}^{I} p_{i,j} (t)Q_i(t) + \\beta_i(t)d_i(t) - \\tau f_j^u \\},\\newline$\n(20)\nand\n$Q_k^g(t + 1) = \\text{max}\\{0, \\sum_{i=1}^{I} q_{i,k}(t)Q_i(t) + \\gamma_i(t)d_i(t) - \\tau f_k^g \\},\\newline$\n(21)\nwhere $f_i, f_j^u$, and $f_k^g$ denote the computation resources of USV $i$, UAV $j$, and GS $k$, respectively.\nUSV based Computing: The local computation time for USV $i$ is\n$T_i^l(t) = \\frac{Q_i(t)c_i(t) + \\alpha_i(t)d_i(t)c_i(t)}{f_i}.$\n(22)\nUAV based Computing: If a task is offloaded to UAV $j$, the computation delay is\n$T_{i,j}^u(t) = p_{i,j}(t)(\\frac{Q_j^u(t)c_i(t)}{f_j^u} + \\frac{\\beta_i(t)d_i(t)c_i(t)}{f_j^u} + \\frac{Q_i(t)v_i(t)d_i(t)}{R_{i,j}^{u2u}(t)})$.\n(23)\nGS based Computing: For tasks offloaded to GS $k$, the computation delay is\n$T_{i,k}^g(t) = q_{i,k}(t)(\\frac{Q_k^g(t)c_i(t)}{f_k^g} + \\frac{\\gamma_i(t)d_i(t)c_i(t)}{f_k^g} + \\frac{Q_i(t)v_i(t)d_i(t)}{R_{i,k}^{u2g}(t)})$.\n(24)\nAs such, tasks can be processed on USVs, UAVs and GSs. Hence, the delay for the tasks generated by USV $i$ in time slot $t$ is calculated as\n$T_i(t) = T_i^l(t) + \\sum_{j=1}^{J} T_{i,j}^u(t) + \\sum_{k=1}^{K} T_{i,k}^g(t).$\n(25)\nConsequently, the cumulative time cost for all USV-generated tasks in $T$ is\n$\\Phi = \\sum_{t=1}^{T} \\sum_{i=1}^{I} T_i(t).$\n(26)\nProblem Formulation\nThe optimization problem is formulated is to minimize the total execution time by jointly optimizing the flight trajectories of UAVs (i.e., $\\mathcal{L} = {\\theta_j(t), k_j(t)|\\forall j \\in \\mathcal{U},t \\in \\mathcal{T}}$), offloading decisions (i.e., $\\mathcal{P} = {p_{i,j}(t)|\\forall i \\in \\mathcal{S}, j \\in \\mathcal{U},t \\in \\mathcal{T}}$ and $\\mathcal{Q} = {q_{i,k}|\\forall i \\in \\mathcal{S}, k \\in \\mathcal{G},t \\in \\mathcal{T}}$), and the task execution ratios (i.e., $\\alpha = {\\alpha_i(t)|\\forall i \\in \\mathcal{S}, t \\in \\mathcal{T}}$, $\\beta = {\\beta_i(t)|\\forall i \\in \\mathcal{S},t \\in \\mathcal{T}}$, and $\\gamma = {\\gamma_i(t)|\\forall i \\in \\mathcal{S}, t \\in \\mathcal{T}}$), i.e.,\n$\\begin{aligned}\\mathcal{P}0: & \\underset{\\mathcal{L},\\mathcal{P},\\mathcal{Q},\\alpha,\\beta, \\gamma}{\\text{min }} \\sum_{t=1}^{T} \\sum_{i=1}^{I} T_i(t) \\\\ & \\text { s.t. }(7), (8), (12)-(17), \\end{aligned}$\n(27a)\nNote that $\\mathcal{P}0$ is a MINLP, as it includes a non-convex objective function and discrete variables. Additionally, the dynamic positions of USVs and UAVs, random task arrivals, and uncertain resources available in each time slot increase the dynamic characteristics, which poses significant challenges for traditional optimization algorithms."}, {"title": "III. ALGORITHM DESIGN", "content": "To address the aforementioned issues and achieve efficient task offloading and UAV trajectory optimization, we design the GAI-HAPPO algorithm.\nMG Formulation\nThe problem can be modeled as a Markov game. USVs and UAVs can be regarded as $N = I + J$ agents, thus the problem is represented by the tuple $(\\mathcal{S},{\\mathcal{O}_{i},\\mathcal{O}_{j}^{u}}_{i \\in \\mathcal{S}, j \\in \\mathcal{U}}, {\\mathcal{A}_{i},\\mathcal{A}_{j}^{u}}_{i \\in \\mathcal{S}, j \\in \\mathcal{U}}, R, \\gamma)$.\nState Space: The state space represents the comprehensive set of variables that define the current status of the system at time $t$, i.e.,\n$s(t) = {l_i(t),l_j^u(t), l_k^g(t), Q_i(t), Q_j^u(t), Q_k^g(t)|i\\in \\mathcal{S}, j\\in \\mathcal{U}, k \\in \\mathcal{G}}.$\n(28)\nObservation Space: Each agent (USV or UAV) has its own observation space.\nUSV agent: The USV agent focuses on local computation and task offloading. Its observation space is\n$o_i^s(t) = {l_i(t), l_j^u(t),l_k^g(t), Q_i(t), Q_j^u(t), Q_k^g(t), A_i(t)| i\\in \\mathcal{S}, j\\in \\mathcal{U}, k \\in \\mathcal{G}}.$\nUAV agent: The UAV agent observation space is\n$o_j^u(t) = {l_i(t), l_j^u(t),l_k^g(t), Q_i(t), Q_j^u(t), Q_k^g(t), A_i(t)| i\\in \\mathcal{S}, j\\in \\mathcal{U}, k \\in \\mathcal{G}}.$\n(29)\n(30)\nAction Space: The action space defines the set of possible actions an agent can take at time $t$.\nUSV agent: The action space of the USV agent is represented as\n$a_i(t) = {p_{i,j} (t), q_{i,k}(t),\\alpha_i(t), \\beta_i(t), \\gamma_i(t)| i\\in \\mathcal{S}, j\\in \\mathcal{U}, k \\in \\mathcal{G}}.$\n(31)\nwhere the UAV needs to choose which UAV and GS to offload the tasks, as well as how to allocate the task proportions.\nUAV agent: The action space of the UAV agent is\n$a_j^u(t) = {\\theta_j(t), k_j(t)}.$\n(32)\nwhere the UAV needs to determine the flying azimuth and distance.\nReward Function: The reward function is based on the time required to process a single bit, considering the uncertainty of tasks and the complex variability of the environment. The reward function $r(t)$ can be expressed as\n$r(t) = \\sum_{i=1}^{I} d_i(t)/T_i(t).$\n(33)"}, {"title": "Algorithm 1 GAI-HAPPO", "content": "GAI-HAPPO integrates transformer-based actor networks and GAN-based critic networks to address heterogeneous multi-agent collaboration problems in MEC scenarios. Using linear transformations, the input data is transformed into query, key, and value matrices for self-attention calculations.\n$\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V,$\n(34)\nallowing the model to capture complex dependencies across states. The output is refined through fully connected layers to predict task ratios, associations, and trajectory parameters.\nFor the critic network, a GAN framework is employed to enhance stability and action-value estimation. The generator predicts state values $V(s_t)$, while the discriminator refines predictions through adversarial training. Their respective loss functions are defined as\n$L_D = -\\mathbb{E} [\\log D(s_t, V^{*}(s_t)) + \\log(1 - D(s_t, V(s_t)))],$\n(35)\nand\n$L_G = \\mathbb{E} [\\log(1 - D(s_t, V(s_t)))],$\n(36)\nensuring improved accuracy in value estimation.\nAlgorithm 1 leverages GAI to enhance MARL via a coordinated policy optimization process. As illustrated in Fig. 2, GAI-HAPPO uses a sequential update scheme to improve the collaboration in heterogeneous multi-agent systems [16]. Each agent policy $\\pi_i$ is parameterized by $\\theta^i$, creating a joint policy $\\pi$ parameterized by $\\theta = {\\theta_1,...,\\theta_n}$. During each iteration $k + 1$, with a permutation of agents $i_{1:n}$, each agent $i_m$ (where $m \\in {1, ..., n}$) sequentially optimizes its policy parameter. This optimization involves agent $i_m$ selecting a"}, {"title": "IV. SIMULATION RESULTS", "content": "To validate the effectiveness of the proposed GAI-HAPPO algorithm, we conduct numerical experiments and compare its performance with four benchmark algorithms:\nHAA2C: Expands the advantage actor-critic framework for heterogeneous MARL agents [16].\nHAPPO: An evolution of PPO, designed for collaboration in heterogeneous MARL systems [16]."}, {"title": "A. Parameter Setting", "content": "We simulate a 1,000m \u00d7 1,000m area with 6 USVs generating tasks, supported by 4 UAVs and 2 GSs for task processing. Each USV generates a computation-intensive task per time slot, and UAVs adjust positions dynamically to optimize task execution. Key parameters include path loss parameters (SL = 2.3, SNL = 34, and the mean task arrival rate \u03bb\u2081 = 15. The transmitting power is set to Ps = 1 W, and the maximum UAV flying distance per time slot is kmax = 30 m. The computation complexity for each task is ci(t) = 270 cycles/bit. The noise power is Ng = \u2212114 dBm. The learning rates for the algorithms are set to 5 \u00d7 10-5 and 10-4, respectively."}, {"title": "B. Evaluation on the Training of GAI-HAPPO and Benchmark Algorithms", "content": "Fig. 3 shows the training results for GAI-HAPPO and benchmark algorithms. GAI-HAPPO achieves the highest average rewards with excellent stability and convergence after 2,500 episodes. Transformer-HAPPO follows closely but exhibits greater volatility. GAN-HAPPO improves upon HAPPO, while HAA2C shows the weakest performance with lower rewards and poor convergence. These results highlight GAI-HAPPO's advantage in handling heterogeneous environments and dynamic conditions."}, {"title": "C. Performance with Different Numbers of USVs and UAVs", "content": "Fig. 4(a) shows the average execution delay as the number of USVs increases. GAI-HAPPO maintains low delays, demonstrating its scalability and efficiency. Transformer-HAPPO performs similarly but slightly lags at higher USV counts. GAN-HAPPO shows moderate scalability, while HAPPO and HAA2C exhibit significantly higher delays, struggling to handle increased loads."}, {"title": "V. CONCLUSIONS", "content": "In this paper, we design a cooperative UAV-GS-based MEC model to meet the computational and coverage demands of USVs in complex applications, such as environmental monitoring and maritime search and rescue. The framework efficiently supports USVs in completing computational tasks by combining the mobility and flexibility of UAVs with the robust computational power of GSs. To address the challenges of task uncertainties, USV trajectory unpredictability, device heterogeneity, and limited computational resources, we formulate a joint optimization problem involving task offloading and UAV trajectory planning, aimed at minimizing total execution time. In addition, we develop the GAI-HAPPO algorithm. GAI-HAPPO incorporates generative AI models to improve the actor network's ability to model complex environments, extract high-level features, and adapt to dynamic conditions, while also stabilizing the critic network to mitigate MARL instability. Extensive simulations show that our approach outperforms existing baseline methods by 22.8%, demonstrating its superior effectiveness in optimizing collaboration within MEC scenarios."}]}