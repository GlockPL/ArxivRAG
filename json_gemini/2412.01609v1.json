{"title": "Optimizing LoRa for Edge Computing with TinyML Pipeline for Channel Hopping", "authors": ["Marla Grunewald", "Mounir Bensalem", "Admela Jukan"], "abstract": "We propose to integrate long-distance Long Range (LoRa) communication solution for sending the data from IoT to the edge computing system, by taking advantage of its unlicensed nature and the potential for open source implementations that are common in edge computing. We propose a channel hoping optimization model and apply TinyML-based channel hoping model based for LoRa transmissions, as well as experimentally study a fast predictive algorithm to find free channels between edge and IoT devices. In the open source experimental setup that includes LoRa, TinyML and IoT-edge-cloud continuum, we integrate a novel application workflow and cloud-friendly protocol solutions in a case study of plant recommender application that combines concepts of microfarming and urban computing. In a LoRa-optimized edge computing setup, we engineer the application workflow, and apply collaborative filtering and various machine learning algorithms on application data collected to identify and recommend the planting schedule for a specific microfarm in an urban area. In the LoRa experiments, we measure the occurrence of packet loss, RSSI, and SNR, using a random channel hopping scheme to compare with our proposed TinyML method. The results show that it is feasible to use TinyML in microcontrollers for channel hopping, while proving the effectiveness of TinyML in learning to predict the best channel to select for LoRa transmission, and by improving the RSSI by up to 63%, SNR by up to 44% in comparison with a random hopping mechanism.", "sections": [{"title": "I. INTRODUCTION", "content": "Lora is a well-known long-distance communication protocol that relies on unlicensed spectrum and CSS modulation to fa-cilitate communication over longer distances [1]. In the rapidly evolving field of IoT-edge-cloud computing, also known as the compute continuum, the potential for integrating LoRa with IoT, edge and cloud computing carries the promise of further expanding the possibilities for new applications to evolve [2], [3]. When combined with edge computing, LoRa can help more efficient bandwidth utilization, whereby some tasks, like those that are machine learning based, can be offloaded from cloud to the edge. Especially in the context of compute contiuum which has enabled a wide availability of the open source libraries, integration of LoRa in the context of edge computing could also become more broadly available through open source. Also edge computing can benefit from LoRa communications by improving its connectivity and server load balancing, especially in remote areas.\nOptimizing LoRa for edge computing introduces multiple new research challenges. Currently, there are no protocols that convert LoRa communications into something usable by edge computing and such adaptations need to be done manually. Also, edge devices need an antenna, i.e., additional hardware, to operating at LoRa frequency. There are duty cycle restric-tions on almost all frequency ranges due to its unlicensed nature, which makes the communication fundamentally unreli-able and unscheduled. LoRa devices need to time synchronize, which makes the management of sending/receiving between the edge and IoT devices a challenge. From a more practical perspective, the availability of open source libraries as well as the hardware support are critical. For applications, which increasingly integrate ML and AI tools in a coordinated cloud-edge continuum, the data collection in IoT devices requires a more effective processing in the edge, which can also benefit from a collision-free LoRa transmission, especially when scaling up the number of devices.\nIn this paper, we optimize the performance of long-distance LongRange (LoRa) communication solution for sending the data from IoT to the edge computing system for a cloud-based application developed for urban living. The IoT devices in-clude sensors that collect and send data to the edge devices, for data processing, prediction and interface. We implement a ma-chine learning algorithm based on TinyML for collision-free channel assignment for LoRa transmissions to the edge, and propose a predictive mechanism to this end. In an open source experimental setup that includes LoRa, TinyML and IoT-edge-cloud continuum implementation, we integrate a novel plant recommendation application for urban gardening. We refer to our system as an urban computing continuum, which we define as a data, communication and computer infrastructure for urban microfarming. In our urban computing continuum, we propose and analyze a novel system architecture that can efficiently and seamlessly integrate LoRa communication, edge and cloud computing in one open system. The results show improvements transmission performance and reliability and a comparison is done do a random channel hopping mechanism. Furthermore, we show the performance of cosine similarity in predicting plant performance in different soils with different data sparsity values and compare a collection of ML algorithms for usability in the proposed continuum. The rest of the paper is organized as follows. Section II presents related work. Section III introduces the reference system architecture, including channel hopping optimization, the proposed TinyML pipeline for channel hopping and a discussion on the TinyMl placement in the system. Section IV presents a case study demonstrating the user of LoRa to transmit soil data for integration int an urban computing continuum, with the objective of recommending suitable plants to a user. The results of the experimental and simulated studies"}, {"title": "II. RELATED WORK", "content": "The integration of LoRa with IoT, edge and cloud comput-ing continuum is not a new endeavor, but has not been largely investigated in the research community. In [2], it was found that edge computing can facilitate more efficient bandwidth utilization in LoRa by offloading certain computational tasks from the cloud to the edge. Paper [3] employs edge computing with LoRa to transmit low resolution images, thereby reducing the overall energy consumption by performing image recog-nition operations at the edge rather than in the remote cloud. Lack of practical integration of LoRa can also be partially attributed to the already mentioned unavailability of the open source libraries, which however are common place in edge computing. In LoRa, the communication process involves a sending node, a LoRa gateway, and in the case of LoRaWAN, a server that is responsible for data processing and acts as a user interface [4]. Again, the number of available open source LoRa gateways remains limited [5]. Furthermore, the support for the open source gateways is not always guaranteed, such as Chirpstack; as of November 2024, Chirpstack provides support for a certain hardware category, such as LoRa shields from, e.g., Dragino or RAK wireless for a Raspberry Pi. In this paper, we use our open source implementation of the open-source LoRa gateway, as detailed in paper [5], to receive LoRa packets and forward them to the edge, where they are subsequently processed.\nTo optimize LoRa performance for edge computing, our work uses frequency hopping for faster switching the carrier frequency across multiple frequencies within a wide spectral band. One of the key decisions to be made in this regard is how to frequency hop and the subsequent execution are conducted in the edge node. Our approach to this end is in application of machine learning with TinyML for the purpose of channel assignment for forthcoming transmissions to ensure reliable communication and reduce collisions among LoRa transmissions. Our predictive mechanism which aims at minimizing collision is different from previous work, such as in [6] where a LoRa node randomly selects a frequency, or [7] which implements a cryptographic frequency hopping solution for the EU863-870MHz frequency spectrum. Paper [8] proposes a reinforcement learning-based algorithm that employs frequency hopping with consideration of factors such as bandwidth, frequency, transmission power and time slots to predict the optimal and collision-free channel for allocation; the reward function is based on energy consumption. While our objective shares a resemblance to this work, there are notable differences in our methodology and the factors we consider. In our approach, we employ a hopping algorithm with the objective of minimizing collision. This is achieved through the integration of channel sensing techniques, imple-mented at the edge and IoT nodes. In making the hopping decision, we take into account the base frequency as well as the history of channel occupation, which is novel.\nTiny Machine Learning (TinyML) is an increasingly promi-nent area within machine learning technologies and applica-tions [9], dedicated to enabling efficient data analysis on ultra-low-power devices. It integrates specialized HW, compressed algorithms, and tailored software to process data from always-on sensors, such as vision, audio, and biometric sensors, while maintaining power consumption in the milliwatt range or lower. Thus, TinyML is a suitable solution to adopt for leverag-ing intelligence in the end-nodes, and particularly for channel hopping decision making for LoRa networks. Paper [10] used tinyML for optimizing channel allocation within LoraWAN scenario, where end-nodes uses tiny ML to select LoraWAN channels, using ns3 simulations. In our work, as we implement the physical layer Lora for transmitting sensor data, using an experimental setup, considering sensing channel occupation state, and in order to decrease the number of collisions, we also propose a tiny ML based channel hopping solution, which we also experimentally evaluate. The placement of channel allocation function is also an open issue, i.e., whether in the end-node or gateway. Paper [11] developed a Q-learning-based channel allocation mechanism in the gateway (GW) that improves packet delivery ratio (PDR) performance by using the number of successfully received packets as the reward signal. In our approach, we analyze the optimal placement for the channel allocation mechanism, and provide a solution that shows that placing channel allocation function at the EN with the help of TinyML is better to providing a scalable and easy-to-integrate solution.\nAs proof-of-concept, we use an application case study in-spired by the concepts of urban computing and microfarming, which we proposed in our previous paper [12]. In [12] our main motivation was the application performance of the urban pendant to farming referred to as microfarming, a sustainable farming concept at a smaller scale implemented in urban gardens, typically at less than 5 acres of garden size [13], [14]. We combined this application with the concept of urban living [15], which ultimately led to the concept of urban computing continuum which we coined. In this paper, we majorly extend our previous paper [12] to focus on LoRa optimizations for this class of applications. More in detail, we focus on maximizing the channel occupancy using TinyML based frequency hopping. Furthermore, the communication and computation between the edge and the Lora gateway are integrated. Furthermore, the cloud-based functions of the application are extended through the deployment of cosine similarity on an extended dataset, evaluating five levels of spar-sity in our data. The database of plants which we use here has also been majorly extended and used to train the application ML models on this new data set for plant recommendations. All experimental setup and related code are open source 1."}, {"title": "III. SYSTEM DESCRIPTION", "content": "Figure 1 illustrates the integration of LoRa in an IoT/edge/-cloud compute continuum today. The continuum system ar-chitecture generally encompasses three types of devices with a range of capabilities that can jointly process, store and\n1https://gitlab.com/M4RL4/loraedgetinyml"}, {"title": "A. Reference Architecture", "content": "communicate data: IoT, edge, and cloud. Each type of devices has a specific computing capability and constraints as well as different delay, jitter and packet loss along the connections. IoT devices are constrained devices that collect data and send them to the more powerful type of devices, be in the edge or the cloud, such as for storage and processing. We assume that IoT devices are spread in N geographic IoT areas, where in each area there is a heterogeneous set of K devices, each equipped with a sensor and microcontroller unit. These units are collecting and sending data on a periodic basis to an edge server. The edge server can be located in close proximity to the IoT areas, such as in communal buildings in an urban setting. Let us assume that each IoT area has its own server, resulting in a total of S edge servers for N areas. Communication between the edge and the IoT devices is assumed using LoRa. For every area N, LoRa implements one gateway, GW in the edge. This gateways are hardware and software implementation of the LoRa transciever and can be implemented per server, or a group of servers in edge computing. In our approach, we implement one gateway per edge server. From the application perspective, data is collected in the IoT areas and pre-precessed in the edge computing part of the continuum, such as for machine learning inference to preprocess data and retrieve insight in the decision making process before moving data from the cloud. Finally, cloud based application processing enable more compute intensive tasks, such as training for machine learning.\nTo optimize LoRa for edge computing, the fundamental aspect to consider is the reliable transmission between edge and IoT devices, which requires the selection of optimal channel characteristics. The parameters that can be modified include bandwidth, coding rate, spreading factor and base frequency. Previous studies have demonstrated that certain combination of these parameters can impact the quality and range of LoRa transmissions. For instance, a spreading factor of 12 has been shown to enhance range at the cost of a lower data rate, whereas a spreading factor of 7 has been observed to reduce it therefore providing a bigger data rate [16]. While the identification of the optimal range and data rate combination for a single LoRa transmission in a remote area may be a relatively straightforward process, the same cannot be said for densely populated areas, where the task becomes considerably more challenging. LoRa operates on the license-free spectrum, which consequently results in competition with other radio modules that share the same frequency band. Consequently, the deployment of a larger-scale LoRa network in a densely used frequency band may encounter distinct challenges. To achieve a flexible and efficient LoRa network capable of operating in a densely used area, we propose a new frequency hopping mechanism that continuously seeks to identify less utilized sub-frequencies within a specified frequency band. This approach aims to balance the utilization of existing frequency bands, minimizing collisions and to ensure a fair and reliable usage of the given frequency band, by assuring stability, i.e., minimizing channel hopping. In addition to the analytical approach, this section also describes the channel hoping mechanisms that use TinyML (TML) implementation at the IoT nodes, and later analyzes the quality of the results obtained."}, {"title": "B. Channel Hopping Optimization", "content": "1) Problem Formulation: We define a set of LoRa end-nodes (EN)s in the IoT context, $\\mathcal{E} = \\{EN_1, ..., EN_N\\}$, and a set of LoRa gateways (GW)s in the edge computing context, $\\mathcal{G} = \\{GW_1, ..., GW_G\\}$. We define a set of frequencies to be used by end-nodes for LoRa transmission as $\\mathcal{F} = \\{f_1, ..., f_F\\}$, e.g., \\{868.1, 868.3, 868.5\\} MHz. We define a binary decision variable $X_{i,g,f}(T)$ for the channel allocation problem, given by:\n\n$X_{i,g,f}(T) =\\begin{cases}1 & \\text{if $EN_i$ sends to gateway $GW_g$ using frequency $f$ at time slot $T$}\\\\ 0 & \\text{otherwise}\\end{cases}$   (1)\n\nA collision occurs when two transmission events overlap, which is equivalent to the case when two ENs sends data to the same gateway at the same time slot using the same frequency. We denote by $C_{i,j,g,f}(T)$ the collision factor between two ENs $i$ and $j$, sending to the gateway $GW_g$ at time slot $T$, which is given as follows:\n\n$C_{i,j,g,f}(T) = X_{i,g,f}(T)X_{j,g,f}(T)$   (2)\n\nThe first objective of the channel collision avoidance problem is to minimize the number of collisions that occur when two IoT end-nodes are sending to the same edge gateway at the same time using the same frequency, during a period of time, and given by:\n\n$\\min \\bigg( O_1 = \\sum_{T=1}^{T} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\sum_{g=1}^{G} \\sum_{f=1}^{F} C_{i,j,g,f}(T) \\bigg)$   (3)"}, {"title": "B. Channel Hopping Optimization", "content": "Channel hopping can be used as a solution to avoid collision, whenever an end-node is sensing that the channel is already in use by another node. We introduce a hopping indicator binary variable $z_i(T)$ that gives 1 if the $EN_i$ hops to another channel at time slot $T$. Thus, the second objective function is the minimization of number of channel hoppings, assuming that the action of hopping is penalized as it introduces an overhead to the system.\n$\\min \\bigg( O_2 = \\sum_{i=1}^{N} \\sum_{\\tau=2}^{T} z_i(\\tau) \\bigg)$  (4)\n\nWe assume that each EN can use only one frequency to transmit the signal to one or more gateways, which can be given by the following constraint.\n\n$\\sum_{f=1}^{F} x_{i,g,f}(T) = 1, \\forall EN_i \\in \\mathcal{E}, \\forall GW_g \\in \\mathcal{G}, \\forall T$   (5)\n\nWe assume that a gateway g has limited channel capacity, represented by $M_g$ the number of channels at $GW_g$. Thus, we obtain the following constraint, considering the channel allocation a binary variable.\n\n$\\sum_{i=1}^{N} \\sum_{f=1}^{F} x_{i,g,f}(T) \\leq M_g, \\forall GW_g \\in \\mathcal{G}, \\forall T$   (6)\n\nWe define an integer decision variable $s_{i,g,f}(T)$ to set the number of symbols sent by $EN_i$ to gateway $GW_g$ using frequency $f$ at time slot $T$. The data transmitted to each gateway can be constrained by certain value that is frequency dependent, and can be expressed as follows:\n\n$\\sum_{i=1}^{N} s_{i,g,f}(T) \\leq B_f, \\forall GW_g \\in \\mathcal{G}, \\forall T \\forall f$   (7)\n\nFrom the IoT side, the data transmission capacity constraint per channel is given by:\n\n$B_{min} \\leq s_{i,g,f}(T) \\leq B_f, \\forall EN_i \\in \\mathcal{E}, \\forall GW_g \\in \\mathcal{G}, \\forall T \\forall f$ (8)\n\nwhere $B_{min}$ is the minimum number of symbols per packet. Let us assuming that each end-node has a certain amount of data $D_i$ to transmit during a period of time. We define the following constraint to achieve the full data transmission $D_i$.\n\n$\\sum_{T=1}^{T} \\sum_{g=1}^{G} \\sum_{f=1}^{F} X_{i,g,f}(T)s_{i,g,f}(T) = D_i, \\forall EN_i \\in \\mathcal{E}$   (9)\n\nIn this model, we consider that a channel hopping decision is taken when a collision occurs on a channel from the IoT end-node towards a LoRa gateway in the edge. If a collision happens on a frequency channel f, at time of sensing T\nfor any gateway g, i.e., $\\sum_{i=1}^{N} X_{i,g,f}(T-1) \\geq 2$, at time t, we force all ENs to frequency hop except for one EN; the latter executes a sensing-based channel hopping algorithm. To model this, we define an extra binary variable $\\delta_{g,f}(T) \\in \\{0,1\\}$ to force the model to hop the channels that are affected by collision. The three equation in (10) are the linear programming formulation of the statement \"if a>b then c=d\", where a = $\\sum_{i=1}^{N} X_{i,g,f}(T-1)$ is the number of nodes"}, {"title": "B. Channel Hopping Optimization", "content": "using the same channel at the same time, b = 2 meaning that if more than 2 nodes are using the same channel at the same time then the number of collisions is bigger than 1, c = 1 $x_{i,g,f}(T)$ is the number of nodes using the same channel at the same time at time slot $\\tau$, and d = 1 meaning that we force the system to leave only one node connected through the same channel, which is equivalent to hopping all the colliding channels.\n$\\sum_{i=1}^{N} x_{i,g,f}(\\tau - 1) \\geq 2 - M(1 - \\delta_{g,f}(t))$  \n\n$1- \\sum_{i=1}^{N} x_{i,g,f}(\\tau - 1) \\leq 2 + M\\delta_{g,f}(T)$  \n\n$1 - M(1 - \\delta_{g,f}(t)) \\leq \\sum_{i=1}^{N} x_{i,g,f}(\\tau) \\leq 1 + M(1 - \\delta_{g,f}(t))$  (10)\nwhere M is a big number.\nIn order to account the number of channel hoppings during a period of time, we define the constraints that set the value $z_i(T)$. If a channel is hopped, there is at least $x_{i,g,f}(T) - x_{i,g,f}(T-1) = 1$, so that $z_i(T)$ is bigger or equal to 1, and the expression is given as follows:\n\n$x_{i,g,f}(\\tau) - x_{i,g,f}(\\tau - 1) \\leq z_i(\\tau), \\forall EN_i \\in \\mathcal{E}$   (11)\n\nIf a channel is not hopped, all $x_{i,g,f}(\\tau) - x_{i,g,f}(\\tau - 1)$ will be 0 so $z_i(T)$ will be less or equal to 0, otherwise at least one channel will hop and with the absolute value, $z_i(T)$ bounded by at least 1.\n\n$z_i(\\tau) \\leq \\sum_{g=1}^{G} \\sum_{f=1}^{F} |x_{i,g,f}(\\tau) - x_{i,g,f}(\\tau - 1)|, \\forall EN_i \\in \\mathcal{E}$ (12)\n\nFinally, the Channel Hopping Optimization Problem can then formulated as follows:\n\n$\\min_{x,s} (\\alpha . O_1 + \\beta . O_2)$   (13)\n\nsubject to: Eq.(5), (6), (7), (8), (9), (10), (11), (12)\nwhere $\\alpha$ and $\\beta$ are weights associated to the two objective functions. The inequality (6) and (7) represents capacity con-straints inequalities which are similar to Knapsack inequality, allowing us to polynomialy reduce the problem to a Knapsack problem if we relax all the other constraints, which is still an NP-Complete problem. A MILP solution would be compu-tationally high, and cannot run on IoT devices. Furthermore, a MILP solution would not be scalable if we increase the number of channels to be used, number of end-nodes, number of gateways, or the number of time slots. We therefore resort to a more practical, ML-based solution to tackle the channel hopping decision making problem, as explained next."}, {"title": "C. Tiny ML Pipeline for Channel Hopping", "content": "We propose to automate the channel hopping decision using TinyML. The TinyML pipeline is illustrated in Figure 2. As the"}, {"title": "B. Channel Hopping Optimization", "content": "all gateways at time slot is modeled as:\n$A_{i,f}(1) = \\sum_{j=1}^{N} \\sum_{g=1}^{G} X_{j,9,f}(T)$   (14)\n\nEach end-node collects the channel availability data from different time slots. We assume that, at time t, we consider all data collected from ts time slots to be used in channel hopping, due to the assumed limited storage capability of the IoT nodes. The channel availability of all frequencies of a single data point and of the considered duration are represented as follows:\n\n$\\Delta_i(T) =\\{\\Delta_{i,f}(T)\\}f \\in [1..F]$,\n$\\Delta_i(t) =\\{\\Delta_i(t - t_s \\cdot r), ..., \\Delta_i(t - kr), ..., \\Delta_i(t)\\}$  (15)\n\nThe two other important type of data that will be used for channel hoppping decision are the RSSI and SNR values, which can be measured at the gateway and sent to the end-nodes as control messages. The RSSI and SNR will be stored in the end-nodes and updated periodically so that we keep a fixed amount of data entries, and can be presented as follows:\n\n$RSSI(t) = \\{RSSI_i(t - t_s \\cdot r), ..., RSSI_i(t)\\}$   (16)\n\n$SNR(t) = \\{SNR_i(t - t_s \\cdot r), ..., SNR_i(t)\\}$   (17)\n\nAfter collecting all the required data, a data set S is obtained. The data set S represented as follows will be formatted as a JSON file and used as an input for TinyML.\n\n$S = \\{s_i = (\\Delta_i(t), RSSI_i(t), SNR_i(t)), E_i, \\forall t\\}$   (18)\n\nThe output of the channel hopping scheme represents the channel decision $C_i$ at time t for EN. In order to collect the data of best channel choice at every time slot and every network state, we repeat the scenario with all possible options i.e. all possible channels, and then we label the data point with the channel that has highest RSSI. The final channel vector associated to our data set is given as follows:\n\n$C = \\{C_i = c_i(t), E_i, \\forall t\\}$   (19)"}, {"title": "B. Channel Hopping Optimization", "content": "2) Training and Compression: As developing a robust model converter requires significant engineering effort, we adopt the existing TensorFlow Lite (TFLite) toolchain [17]. The TFLite toolchain facilitates model compression and opti-mization, producing a FlatBuffer file that (TensorFlow Lite Micro) TFLM uses to load inference models in a micro-controller, such as ESP32 in our case. TensorFlow Lite enables a unified environment for both model development and execu-tion. We adopt a fully connected neural network architecture (FCNN) modeled using tensorflow and TFLite, and trained on the data set S as input and C as output, where the output layer is represented by a multi-class layer to model all possible channel selection possibilities. As the training is going to be in a capable server in the edge, a Tensorflow Lite Exporter is used to create a small version of the model with a size conforming to the micro-controller capacity and LoRa packet limitations. The created model will be then updated in the micro-controller through over-the-air (OTA) updates feature, by sending it through the gateway LoRa radio to the end-nodes."}, {"title": "D. Discussion on TinyML Placement", "content": "As previously mentioned, we place TinyML model in IoT end-nodes, as illustrated in Figures 2 and generalized in 3. However, also the placement at LoRa Gateways is an option. We now briefly discuss pros and cons of both choices.\nThe primary benefit of frequency hopping at the IoT end node is that if facilitates scalability, as all end nodes can be flashed using a unified code, which has practical significance. Furthermore, this makes it possible that the communication between the devices may adapt to the environmental condi-tions over time with the objective of achieving a balanced distribution of frequencies within a frequency band, even in comparison with other technologies operating in the same band. This approach could facilitate not only a reliable, low-collision operation of our communications, but also the avoidance of interference with other systems. This approach also facilitates scalable integration of newly added nodes. As a result of the bi-directional communication, the gateway is capable of send messages to the end-node about channels that are less frequently used. Consequently, the edge (gateway) and IoT (end-node) can transition to a less congested frequency when required, through the gateways monitoring of available frequencies and scanning of the spectrum.\nPlacing TinyML at the IoT nodes however has some dis-advantages. The primary disadvantage is that bidirectional communication between the end-node and the gateway is necessary for the end-node to receive information about the characteristics of the various candidate channels, including the RSSI and SNR. The issue with bidirectional communication is that while the gateway is engaged in transmission, it is unable to receive simultaneously, which may result in packet losses. The messages sent from the gateway may be minimal in their payload, which has the benefit of reducing the amount of air time required and therefor the risk of collision and of the gateway being unable to receive messages during that time. The primary objective here is to convey channel characteristics, rather than content, to the end nodes.\nTo overcome the above mentioned disadvantages, TinyML model can also be placed in the gateway, see Figure 4. This solution obviously requires only a one-way LoRa communi-cation channel between the IoT and edge. This is achieved through the use of RSSI and SNR values from the previ-ous transmissions, which determine the decision to hop the channel. The most significant drawback of this approach is that when scaling the system, each end node must be flashed with a channel set, without the option of changing the used channel later. This necessitates a manual scanning of the area in which the end-node is deployed to identify interference with other channels/devices. Consequently, this process is inherently static and does not provide for enough flexibility in real world deployments."}, {"title": "B. Channel Hopping Optimization", "content": "3) In-Chip Inference : As all gateways send control data as shown in figure 2, we propose a module called End-Node Manager to control the communication between the EN and the gateways, by storing control logs and running channel hopping algorithm with the help of TinyML. The End-Node Manager consists of two parts: a TinyML agent and a Telemetry Database. The tinyML agent is responsible on executing the channel hopping mechanism with the help of the trained TFLite model, which will decide the next channel to hop. The Telemetry Database is a small database designed to store the needed information described in (18), representing the input parameters for the TinyML model. The number of time steps ts is constrained by memory size of the micro-controller which defines the temporal memory used for prediction. Each time the Gateway sends a sensing data (control data) containing the channel availability, RSSI, SNR of the previous transmission, the TinyML agent will store them in the Telemetry and deletes the oldest entries to keep the size at the defined level."}, {"title": "IV. CASE STUDY: URBAN COMPUTING CONTIIUUM WITH PLANT RECOMMENDER APPLICATION", "content": "This section presents a case study of an urban computing continuum, which incorporates the proposed LoRa channel hopping and edge computing with a plant recommendation system for urban gardening. The plant recommender chooses the most a suitable plant for an urban microfarmer based on the unique composition of each gardens soil. In a LoRa-based urban computing continuum, we incorporate the collection of sensor data in an urban area and the processing of the gathered data to develop an application that benefits the people of that area. The following subsections provide a description of the application workflow engineering and various aspects of the application in the context of IoT-edge-cloud continuum."}, {"title": "A. Application workflow engineering", "content": "Figure 5 illustrates the proposed application workflow with LoRa, with the assumed distance between the garden and the edge in the range of non-LPWAN protocols. The process is initiated by the urban gardener via a front-end application,"}, {"title": "B. IoT context: Data Collection", "content": "The IoT context involves the aggregation of data. The data collection can be done via sensors, or data can also be entered manually by the user. We assume a heterogeneous set of IoT devices on low-power, resource-constrained hardware (e.g., microcontrollers) interfacing with different sensors. This can be implemented through the use of an IP68 ABS NPK sensor in conjunction with a DS18B20 temperature sensor and a Taidda soil ph sensor, for example. It is assumed that IoT devices communicate with gateway based on an optimized LoRa physical layer communication, whereby the channel selection is performed with TinyML, as previously described (not shown here due to the focus on application). The data transmitted via LoRa comprises solely the N,P,K, pH and temperature values, in addition to an identifier for the garden, resulting in a message length of approximately 20-30 bytes; the message length needs stay as short as possible, as this reduces the overall airtime of LoRa. The sensor data is therefore transmitted without any additional information, such as spacing or explanatory text and comprises only the raw sensor values and the ID, to be processed by the edge.\nAnother option for inputting data into the system is through the manual rating of plants. This allows for the system to work also without deploying IoT devices. Consequently, the user is required to enter the plant ratings to the the user interface. This approach, while low-cost as it does not involve sensor hardware, introduces sparsity into the data. The sparsity of data is a known problem which in our urban continuum can be dealt with in the cloud."}, {"title": "C. Edge context: inference and data processing", "content": "LoRa gateway is implemented in the edge. The gateways are required to utilize the same LoRa parameters, including Coding Rate, Spreading Factor, bandwidth and base frequency employed by the IoT device. Otherwise, they will not suc-cessfully receive the packets. The purpose of the gateway is to receive the messages and add the appropriate value to the raw application data, then forward the message to the edge with which it is connected. Consequently it converts the LoRa data from bytes to integers and addresses it to the correct labels, converting the message to JSON and sending it to the application database at the edge. Furthermore, for the application, edge manages end device IDs and users, in addition to the inference of the trained application machine learning model and the provision of feedback to the end user regarding the results of the recommendation. These application related functions are preformed in addition to the LoRa system functions exectued at the edge, such as the previously described TinyML training for LoRa channel hopping optimizations."}, {"title": "D. Cloud context: Collaborative Filtering", "content": "In the cloud, model training is performed on either the full application data set or on sparse data, such as based on manual ranking. Prior to training the ML models on sparse data, the sparse matrices undergo pre-processing, in which they are converted into complete matrices, thereby ensuring the suitability of the data set for the training process. The"}, {"title": "D. Cloud context: Collaborative Filtering", "content": "missing ratings are calculated from the sparse matrix using cosine similarity, thereby generating a complete ratings matrix for all listed plant and soil combinations. In the context of recommendation systems, the cosine similarity metric is calculated using the ratings of two items, in our use case these are the ratings for the plants, designated as \"x\" and \"y\", which depict two rows in the sparse matrix. The ratings on each soil represent the input data, an the cosine similarity is given by\n$cos(x, y) = \\frac{x \\cdot y}{||x|| ||y||}$   (20)\n\nThe sparse matrix $S\\in \\mathbb{N}^{mxn}$ is composed of natural numbers, e.g., $\\in$ [1..5"}]}