{"title": "The Design Space of Recent Al-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity", "authors": ["Runlong (Harry) Ye", "Patrick Yung Kang Lee", "Matthew Varona", "Michael Liut", "Oliver Huang", "Carolina Nobre"], "abstract": "Generative AI (GenAI) tools are radically expanding the scope and\ncapability of automation in knowledge work such as academic re-\nsearch. Al-assisted research tools show promise for augmenting\nhuman cognition and streamlining research processes, but could\npotentially increase automation bias and stifle critical thinking. We\nsurveyed the past three years of publications from leading HCI\nvenues. We closely examined 11 AI-assisted research tools, five\nemploying traditional AI approaches and six integrating GenAI, to\nexplore how these systems envision novel capabilities and design\nspaces. We consolidate four design recommendations that inform\ncognitive engagement when working with an Al research tool: Pro-\nviding user agency and control; enabling divergent and conver-\ngent thinking; supporting adaptability and flexibility; and ensur-\ning transparency and accuracy. We discuss how these ideas mark a\nshift in AI-assisted research tools from mimicking a researcher's es-\ntablished workflows to generative co-creation with the researcher\nand the opportunities this shift affords the research community.", "sections": [{"title": "1 Introduction", "content": "Generative AI (GenAI) is transforming the landscape of research\nand creative workflows by radically expanding the scope and ca-\npabilities of automation. Recent advancements in large language\nmodels (LLMs) are redefining the ways in which knowledge work-\nparticularly researchers - engage in the process of ideation,\nsensemaking, and scientific creativity. At the same time, the in-\ntegration of GenAI into research workflows raises critical ques-\ntions about its effects on human cognition. Although these sys-\ntems promise to augment human intelligence and streamline re-\nsearch processes, there is mounting evidence that overreliance on\nautomated output can lead to reductions in critical thinking and in-\ncreased automation bias [9, 15]. Furthermore, concerns have been\nraised about the potential of GenAI to steer users too heavily, thus\ndiminishing human capacity for interpretation and reflection [5].\nLatest developments in the AI industry further emphasize these\ntrends: OpenAI's release of Deep Research [2], an Al agent capa-\nble of independently synthesizing information from hundreds of\nonline sources to generate comprehensive research reports, high-\nlights the rapid push toward automation of knowledge work. Soon\nafter, Google unveiled its AI co-scientist [1], designed as a multi-\nagent system to accelerate scientific breakthroughs by augmenting\nhuman ingenuity with iterative hypothesis refinement, illustrates\nthe expanding role of AI in shaping scientific discovery.\nIn response to these challenges, a human-centered approach\nto AI [18] offers a promising alternative to preserve and improve\ncognitive engagement by having machines provide computational\npower while humans guide, interpret, and refine outputs.\nTo investigate these dynamics, we surveyed a collection of the\nlatest Al-powered research tools. We identified four dimensions to\nexamine the level of cognitive engagement provided by AI-powered\nresearch tools: User agency and control (Section 3.1); divergent\nand convergent thinking (Section 3.2); adaptability (Section 3.3);\nand accuracy (Section 3.4). By analyzing existing tools through this\nframework, we identify a space of design choices and potential pit-\nfalls. We highlight a widening gap between GenAI tools, which\noften guide users toward discovery; in contrast with traditional\nAl tools, which tend to mimic user workflows and provide greater\nuser autonomy (Section 4). Awareness of this distinction opens op-\nportunities for creating \"tools for thought\" (Section 5) that truly\nempower researchers, fostering deep cognitive engagement and\nmaximizing the benefits of GenAI while mitigating its risks."}, {"title": "2 Method", "content": "Our literature search focused on AI-assisted creative research tools\nin contrast to Al-assisted writing tools, creative research tools as-\nsist with the co-creation of concepts and ideas in the research pro-\ncess rather than merely improving stylistic or rhetorical choices\nin written research. In total, we surveyed 11 systems papers pub-\nlished in top HCI venues (i.e., CHI, CSCW, UIST, and ToCHI) over\nthe last three years (2022-2024)\u00b9; details can be found in Table 1.\nAs LLMs became widely used in 2022 with the release of Chat-\nGPT [12], this timeframe was chosen to reflect the period of sig-\nnificant growth in LLM popularity and adoption, allowing us to\ncapture the most relevant and impactful developments in GenAI-\ndriven research tools. Of the systems surveyed, six of the systems\nintegrate LLM-based functionalities, while the other five represent\na more traditional AI approach and employ machine learning tech-\nniques (e.g., Seq2Seq, BERT, RNN). By examining both GenAI and\ntraditional AI approaches, we aim to understand to what extent\nGenAI tools represent a fundamental shift in capabilities and de-\nsign considerations compared to more established AI approaches.\nThe thematic dimensions presented in Section 3 resulted from\nan iterative process among the authors. We engaged in extensive\ninternal discussions and consulted with an external expert special-\nizing in knowledge spaces and the role of AI in fostering creativ-\nity and sensemaking. This collaborative and iterative approach re-\nsulted in the four dimensions presented in the next section."}, {"title": "3 Design Space", "content": "A fundamental challenge in integrating Al-powered research tools\nis ensuring that users remain cognitively \"in the loop\" rather than\npassively accepting AI-generated output. While automation promises\nefficiency and rapid idea generation, it also risks encouraging users\nto rely too heavily on system outputs, which can diminish human\ncritical thinking and decision-making processes. We explore four\ndesign dimensions critical to navigating this tension."}, {"title": "3.1 User Agency and Control", "content": "Human-AI collaboration systems aim to improve productivity and\ncreativity by offloading certain tasks from humans to Al systems\nwhile keeping the user in the driver's seat. Providing user agency\nand control via source material participation, the ability to refine\nAI output, and the ability to reject and override automated actions\nare crucial to maintaining cognitive engagement from the user."}, {"title": "3.1.1 Engagement with source material.", "content": "For tools aimed at mak-\ning sense of existing text content (such as qualitative coding, the-\nmatic analysis, or literature reviews), there is a delicate balance to\nbe struck between AI assistance and user agency. While recent ad-\nvancements in LLM capabilities show promise in processing and\nsummarizing large amounts of text, users still have to engage with\nthe source text to build their own understanding and avoid model\noverreliance. One way to foster engagement is for user-selected\ntext highlights to drive content generation. Systems such as Syn-\nergi [8] and Threddy [6] integrate PDF readers that transform user-\nselected highlights into seeds for AI-driven research thread gen-\neration, while Relatedly [14] further refine this process by orga-\nnizing and highlighting overlapping research themes. Meanwhile,\nplatforms like Scholastic [4] and SenseMate [13] scaffold existing\nanalysis methods with cluster suggestions and strategic sampling.\nThe role of Al in these systems (such as Scholastic [4] and Sense-\nMate [13]) is to scaffold existing analysis methods with cluster sug-\ngestions and strategic sampling."}, {"title": "3.1.2 Refining Al output.", "content": "Human-centric AI tool design assumes\nthe user is the expert, giving them the power to modify the output\nprovided by the Al system. Most tools we reviewed allow users\nto edit and refine AI-generated artifacts to ensure that they meet\nthe user's goals. In Threddy [6], for example, users can manually\nclean up errors in references and links extracted from a paper snip-\npet. Beyond fixing errors, user editing can be designed into human-\nAl sensemaking systems to varying degrees. Arranging AI outputs\ninto a more interpretable structure (such as node-link diagrams [11,\n16] or outlines [8]) can foster deeper engagement with suggestions.\nFinally, iterating on prompts and queries can help users gradu-\nally incorporate new ideas and discoveries into AI output. This is\nnotably useful in cases such as the Analogical Search Engine [7],\nwhere users may not know exactly how to initially prompt but can\ngain and apply new information with each re-prompt."}, {"title": "3.1.3 Rejection and overriding.", "content": "One aspect of control that merits\nfurther consideration is the ability of users to reject, override, or\nignore model output. Rejection can manifest in systems implicitly.\nFor example, editing or curating AI output implies rejection of the\noriginal content in part or whole. However, most of the research\npapers we reviewed had Al assistance embedded in the system,\nwith minimal ability to \"turn off\" AI suggestions. One notable ex-\nception is SenseMate, which explicitly aims to provide AI theme\nsuggestions on demand rather than by default [13]. In SenseMate,\nAl suggestions are hidden by default; users can also see the reason-\ning for the theme suggestions and explicitly reject them. Similarly,\nScholastic's text clustering algorithm does not impose keywords\non clusters. Instead, users have the option of either developing in-\nternal mental models of the meaning of the cluster or providing\nthe algorithm with explicit codes that can be iterated on [4]."}, {"title": "3.2 Divergent and Convergent Thinking", "content": ""}, {"title": "3.2.1 Divergent Thinking.", "content": "Divergent thinking is essential for ex-\npanding the horizons of research. Al tools support this by generat-\ning exploratory questions and novel insights that researchers may\nnot have thought about. For example, the Analogical Search En-\ngine [7], DiscipLink [19], and IdeaSynth [16] provide functionali-\nties to explore creative connections in seemingly unrelated fields.\nHowever, when using an Al tool for divergent thinking is used\nin isolation, this approach can overwhelm users with many novel\nideas without providing the guidance necessary to narrow them\ndown or refine them effectively."}, {"title": "3.2.2 Convergent Thinking.", "content": "In convergent thinking, AI tools trans-\nform raw data into clear and structured insights, acting as intel-\nligent partners that help researchers distill complex information\ninto coherent narratives. These systems guide scholars in filtering\nand organizing diverse inputs so that essential themes emerge with\nclarity and precision.\nFor example, SenseMate [13] leverages rationale extraction mod-\nels to generate transparent theme recommendations and human-\ninterpretable explanations for qualitative coding. By grounding its\nsuggestions in data-driven rationale rather than relying on large\nlanguage models, SenseMate empowers even novice users to en-\ngage deeply with the source material while retaining full control\nover their coding decisions. Focusing on the same task, Collab-\nCoder [3] utilizes LLMs to automatically generate qualitative code\nsuggestions and facilitate structured group discussions, thereby\nbridging individual insights into a collective consensus. Comple-\nmenting these approaches, Scholastic [4] employs advanced visual\nanalytics to help teams organize and interpret complex datasets,\nwhile PaperWeaver [10] presents contextualized links that high-\nlight the most relevant insights. These convergent functionalities\nmake thematic grouping and filtering more efficient and transpar-\nent."}, {"title": "3.2.3 Mixed-Thinking.", "content": "Some tools strike a balance by supporting\nboth divergent and convergent thinking. Threddy [6], for example,\nallows users to input various requests so that LLM systems can\norganize ideas into coherent themes. They also leverage hierarchi-\ncal structures to discover new connections based on user input.\nSimilarly, Synergi [8] uses citation graphs and language models\nto expand research threads and consolidate them. However, these\nmixed-thinking approaches often leave users with limited control\nover the balance between exploration and refinement, which may\nhinder effective sensemaking. So while too much convergence might\nstifle creative exploration, too much divergence can cause cogni-\ntive overload. A well-designed research tool should support either\nor both modalities, but its user-facing capabilities should be made\ntransparent. In the design space of research tools, allowing users\nto control the levels of divergent and convergent functionality is\nkey to researcher autonomy."}, {"title": "3.3 Adaptability", "content": "Adaptability in AI-assisted research tools refers to a system's ca-\npacity to support the diversity of tasks, workflows, and preferences\nof researchers. Ways this could be supported in tooling include flex-\nible input mechanisms; fluid, nonlinear workflows; and context-\nsensitive design."}, {"title": "3.3.1 Flexible Input & Customization.", "content": "Systems that prioritize flex-\nible input mechanisms empower users to tailor the tool's behav-\nior from the outset. For example, the Analogical Search Engine [7]\nleverages a custom ranking algorithm that focuses on user-defined\n\"purposes\" and \"mechanisms\" to modulate search results accord-\ning to varying research objectives, allowing researchers to specify\nthe kind of analogical relationships they are seeking. Similarly, the\nBrainwriting tool [17] allows users to dictate main topics in addi- \ntion to divergent and convergent steps through a user-agnostic ap-\nproach. These approaches underscore the importance of customiza-\ntion as a means of preserving user agency and aligning system out-\nputs with specific investigative goals."}, {"title": "3.3.2 Fluid, Non-Linear Workflows.", "content": "A second facet of adaptabil-\nity is found in tools that support non-linear, iterative workflows.\nThe RQ Flow Editor in CoQuest [11] exemplifies this by eschew-\ning predefined categories and instead promoting continuous re-\nfinement of ideas through a mixed-initiative interaction where AI\nsuggests new research questions and users can provide feedback.\nLikewise, IdeaSynth [16] supports both literature-driven and idea-\ndriven explorations through dynamic facet generation and prompt\ncustomization, enabling users to decompose an initial idea into\nfiner-grained aspects and explore variations of them. Tools like\nScholastic [4] further demonstrate adaptability by allowing researchers\nto shift seamlessly between exploration, strategic sampling, and\ncoding - highlighting the value of fluid transitions in non-linear\nresearch processes via its interactive document and word cluster-\ning."}, {"title": "3.3.3 Mixed-Initiative & Context-Sensitive Design.", "content": "Adaptability also\nmanifests in systems that accommodate varied research approaches\nthrough mixed-initiative interactions and context-sensitive features.\nFor instance, Synergi [8] offers a mixed-initiative workflow that"}, {"title": "3.4 Accuracy", "content": "Ensuring that users receive accurate, unbiased, and contextually\nrelevant information is paramount in AI-assisted research tools. To\naddress challenges such as hallucination and contextual drift inher-\nent to large language models, researchers have developed multifac-\neted strategies that combine human oversight, contextual ground-\ning, and carefully managed efficiency-accuracy trade-offs."}, {"title": "3.4.1 Interactive Interfaces for Accuracy Validation.", "content": "A key design\npattern embeds interactive mechanisms that enable real-time ver-\nification of AI outputs by linking inferences directly to their orig-\ninal sources. For instance, SenseMate [13] employs a \"View Rea-\nson\" feature that highlights source phrases underlying a theme\nrecommendation, thus promoting local explainability and inviting\ncritical evaluation rather than passive acceptance. Similarly, Syn-\nergi [8] and PaperWeaver [10] enhance their LLM-generated sum-\nmaries by providing citation contexts and contextualized descrip-\ntions. Synergi groups related information to offer clear reference,\nwhile PaperWeaver uses aspect-based summaries (e.g., problem,\nmethod, findings) alongside paper comparisons to help researchers\nquickly assess the relevance of new publications."}, {"title": "3.4.2 Iterative Refinement and Human-in-the-Loop Strategies.", "content": "Com-\nplementing interactive validation, iterative refinement processes\nfurther emphasize human oversight. Scholastic [4] demonstrates\nthis approach by utilizing a machine-in-the-loop framework for\nqualitative text coding, wherein user feedback continuously refines\ncoding decisions through rationale extraction models that enhance\ntransparency and trust. Likewise, Threddy [6] and IdeaSynth [16]\nempower researchers to actively shape AI outputs. Threddy facili-\ntates the extraction and iterative organization of research threads,"}, {"title": "4 A Tale of Two AIs: Workflow Mimicry Versus\nGenerative Exploration", "content": "As we investigated the recent advancement of AI-assisted research\ntools, we noticed a subtle shift in the philosophy behind AI-powered\nresearch tools. Traditional AI/ML systems are designed to enhance\nestablished research workflows by automating well-defined tasks.\nFor example, the Analogical Search Engine [7] employs a token-\nlevel ranking algorithm to retrieve articles with similar \u201cpurposes\u201d\nand \"mechanisms\", while tools like SenseMate [13] and Scholas-\ntic [4] focus on organizing data and semi-automating qualitative\ncoding - all while keeping the researcher in control. Similarly, Threddy [6]\nutilizes various ML models to parse and structure PDF content. In\ncontrast, LLM-powered tools such as CoQuest [11], IdeaSynth [16],\nand Synergi [8] are gradually shifting the emphasis towards gen-\nerative exploration. These systems leverage the vast knowledge\nembedded in LLMs to generate novel content, suggest alternative\ndirections, and even reframe research problems, requiring users to\nselect and refine AI-generated options to actively advance their in-\nvestigation. Although this transition is still in its early stages, it\nmarks a notable turning point in how support is provided: tradi-\ntional systems mimic existing workflows with deterministic assis-\ntance, whereas LLM-enabled tools encourage dynamic, exploratory\nengagement. This evolving prospect invites further discussion on\nbalancing the design of research tools that not only streamline\ntasks but also enrich cognitive engagement, ensuring that researchers\nremain actively involved and creatively challenged throughout the\ndiscovery process."}, {"title": "5 Opportunities", "content": "GenAI-powered research tools present a significant opportunity\nto design truly mixed-initiative systems that put cognitive engage-\nment as a key design consideration. These systems can balance\nuser agency and control with the generative capabilities of LLMs,\nthereby encouraging both divergent ideation and convergent re-\nfinement while ensuring that researchers remain at the core of the\ninquiry process. Particularly, designers should remain mindful of\nautomation bias, where users may become overly reliant on AI-\ngenerated outputs."}, {"title": "In designing GenAI-powered research tools, it is crucial for de-", "content": "In designing GenAI-powered research tools, it is crucial for de-\nsigners to actively consider several interconnected dimensions: sup-\nporting user agency, encouraging both creative exploration and\nsystematic refinement, and ensuring adaptability and precision. In-\nstead of anticipating users to stay engaged, these deliberate design\nchoices empower researchers to interact critically with AI outputs,\nreducing risks such as automation bias. This approach invites users\nto actively shape their interaction, paving the way for a more in-\nnovative and rigorous future in scientific discovery."}]}